{"text": " Alright. Hello, everybody. I have quite an honor today. I am lucky enough to introduce Brandon Rhodes. He's a longtime Python developer, maintainer of several amateur astronomy libraries and a developer for Dropbox. He's also a Quizmaster extraordinaire, as some people got to find out last night. Today, he will be presenting on, oh, come on, who needs byte arrays? Without further ado, Brandon Rhodes. Welcome, everybody. I hope you're having a good time at PyCon and in Montreal. My topic today is indeed byte arrays. A very interesting recent addition to the Python ecosystem. Because in Python, normal string objects, the ones that we're accustomed to dealing with are immutable. They can't be changed or modified. This is true of the types available under both two and three. The original string type, STR, was renamed to bytes because of its low-level nature and then that synonym was also backported to Python 2. We will not talk much today about the newer Unicode byte strings that were renamed to the official string type of Python 3. We're going to be talking about those lower-level ones. The strings that don't pretend they have symbols inside of them so much as they know that their innards are really bytes. 8-bit codes, 0-255. For the most part, I will put that little B in front of the bytes strings that I type. It is optional under Python 2, but it becomes mandatory under Python 3. So if I write my strings like this, then it will work wherever you try this later if you want to see the examples run. Strings are immutable. What does that mean? It means that when you call methods, when you do things to them, the original object itself doesn't change. You get given a new object as the return value of the method you call. So if .lower returns to you a new string, you can still peek back and see that the original is untouched and unchanged. If you run split, you'll see that both of the objects you've been given are new string objects. The original is still unchanged. They do not allow assignment because that would make them change. It would make them mutate as the technical term in computer science. Now, immutability has led a long and very successful career in Python because it makes things simple. You don't pass a name to a function only to finally suddenly discover it's another name when it comes back. You don't pass a string or a block to someone, and suddenly it's a different string or block. It's a very, very simple model that if you have the word Python, you know it will always remain so. And it actually is one of the most parts of Python. That's the most functional programming languages where new results are returned instead of being written onto data structures you already hold. The string types are a primary example of that. But it sometimes is a little expensive in terms of allocation. Every time you want to make any little tweak to a string, it has to allocate a new one for you. That means a lot of data gets copied back and forth into new areas of memory. Not everybody is happy about that. And so Python 3 introduced and then it was back ported to Python 2, 6, and 7, the new byte array. It's a built-in. Python 2, 7, Python 3, you can just type byte array and you'll get access to that type, just like you can with stir and int and list. A byte array is a mutable string that is based, this is interesting, on Python 3's byte string, not the old stir string from Python 2. And that's an interesting problem, that it's based on Python 3's string, byte string type, because honestly, the Python 3 bytes type is designed to be awkward for string operations. Why? So you will want to be a good person and run the code before treating your data as characters. And this has led to Python 3 programmers tending to write code that is from the ground up prepared for internationalization and different alphabets because they think about the issue of decoding on the way in and encoding on the way back out because they have to. But we'll see it leads to some interesting behaviors. Just professionally, always be aware of using string types that wish you weren't using them. In Python 2, let's compare. We can build a string, we can ask its length, we can split it into pieces. Python 3's byte type, there's little B characters hanging out in front of our byte strings, but we can take the length, we can call a method like split. In Python 2, we can use those square brackets with a colon in order to do slicing and get back a copy of the inside of the string. The exact same thing works exactly the same way in Python 3. In Python 2, it's always a custom in Python that if something has a length, it should allow itself to be iterated or looped over. In Python 2, if you try looping over a string, you get out smaller strings, one character strings that are inside. What happens if you press enter for this line of code in Python 3? You get a syntax error. Syntax error, you failed to pay the Python 3 per intax. Python 3, it's kind of like an old text-based adventure game where you can tell the writer just threw an extra obstacle in your way because a room needed to be a little more complicated. You know, in seriousness, I've known Ruby, some Ruby programmers, this is actually a big debate in the Ruby community, Ruby makes parenthesis optional when calling a function. The Rubyists who never use the parenthesis always tell me they could never stand Python again. I always thought that was the oddest thing. Doesn't everyone want to type parenthesis whenever they ask their computer to do something? I must admit that once it was me who was suddenly having to type parenthesis, but they surely must still be wrong. Anyway. I did a conservative estimate of how much typing is cost me by these print statements in Python 3, and these are conservative estimates, and it's coming out to quite a bit of typing per year. I'm having to face going into Perendet just to write some Emax Lisp next week. Anyway, Python 3 wants them for this print statement, and what's another two perends when I've already typed so many? So once you get the print statement working, you're in for another surprise. Python 3 bytes type is not made of characters, it is made of numbers. This breaks a very important contract that for me existed with strings, which is that I can pull them into pieces with either indexing or slicing and know that they would go back together again. Now, there is a way around by asking for one element slices instead of looking up integer indexes, but clearly it doesn't want me to treat it like a string. So bytes objects, even if you learn some workarounds, are kind of an awkward fit for many of the tasks they're called upon to do. They're kind of this hybrid type between a list of numbers and a string. They're kind of in between, and they don't necessarily do either one perfectly well. And so why do I bring all of that up? Why do I rehearse these well-known issues with Python 3 bytes? Which, by the way, are being taken care of. Python 2.5 will, for example, reintroduce percent formatting for byte strings, because now that the experiment is in its fifth version, I think it is beginning to become clear that the real problem in Python 2 wasn't that strings were convenient, and so we ignore Unicode, it's that conversion could happen automatically without warning. And so they are beginning to add power back into Python 3 byte strings, but they probably will always be made of numbers now for backwards compatibility, and we bring all that up because the byte array that I will now talk about is a mutable version of Python 3's byte string, a mutable version of Python's most underpowered string type. So we'll just quickly look at a few possible applications and whether a mutable vector of bytes is able to accomplish things better or worse than traditional Python. So first, let's be fair to it. What if you actually want a list of numbers between 0 and 255? That never happens to me. So I invented, in those rare cases where you actually want to store bytes, if you had one, is the byte array a good choice? So I invented one. I wrote my first Bloom filter as preparation for this talk. A Bloom filter is a way to, let's say, you have a dictionary of words, and before you go look on disk for whether a word is in your dictionary, you want a quick way to knock out a lot of words, it's just not being candidates. What you can do is set up a big bit field and have a couple of hash functions that you throw the word elephant at them, and they identify some bits for you that belong to elephant. You give them the word Python. It's a different set of bits. The idea is that if you load up your dictionary by setting all of the bits for elephant and all of the bits for Python, then when you see those words later in a document, you can just check whether their bits are set to know if there's any possibility that elephant is in your dictionary, because many words will have sets of bits that aren't set at all, or several of which aren't set, and that you know could not have been in the dictionary you loaded. This is a nice example because it lets us do a pure math operation, in this case the in place oring of a byte in this array A with itself and with a bit that we create over here and set, and we can run through, set this up, and then when we want to test a word, go back in and use the reading version of square brackets, not in an assignment statement, but in an expression to read back the value of a bit. A nice exercise to see how does this thing perform storing and receiving a few tens of thousands of bytes. And by the way, the name A in the previous code can be either an old fashioned array dot array that's been around in Python forever, or a new fangled byte array. To this extent, they both provide the same interface. Each slot you can address gets you or lets you store a byte. And so with this application, I ran it both ways, and byte array scored its first victory, because it is so more specific than array dot array, which can also hold, I believe, floats and integers and other things like that, because the byte array's code path has almost no decisions, it's always going to store bytes, it is more than 7% faster for running that bloom array code, bloom filter code that I just showed you, than the old general purpose array, array object. So you might think that this is immediately an obviously a go to data structure for lists of eight bit numbers. I tried it another way. I want to know what's even faster than a byte array? A list of integers. 1% faster. If you just say, hey, Python, here's a one element list with a zero in it, make me a lot of these. A plain, I'm sorry, 2%, a plain list of int objects that happen to be in the range 0 to 255 will run even faster than the byte array. Why? Well, it's because, think of what the byte array is doing. It's storing real bytes, low level in your computer, that must each be translated into an int object address when the value is being handed out into your Python code, and then when an int object is handed back, it has to be changed back into a simple byte in order to be stored. The list skips all that, it just stores the addresses you give it. The byte array, by the way, doesn't have to pay any penalty to allocate or create any of those int objects, because it just so happens that the Python, the CPython interpreter, when it starts up, preallocates all of the integer objects negative 5 through 256 so that they never have to be created or destroyed over the lifetime of the interpreter. So when you ask the byte array, what's it positioned 100, and it wants to say 70, it can just grab the existing 70 integer object that always exists in memory and hand it back, so it's not having to go do a malloc or anything, it's not having to allocate new memory, but still it's having to do that step of translation, and it is honestly just simpler to store the pointer, to store the address of the 70 object. That's why the list object runs faster, and so this is interesting. We have this new special case container that's slightly slower than just using Python's well-honed default data types. A plain old list is a faster bit vector than the fancy new byte array, except if you're using PyPy, where they're all the same because it becomes the same C code under the hood of a machine code, I should say, and all three run much faster as well as being exactly equivalent. I tried it out, and PyPy in each case figured out I was trying to do exactly the same thing. Well, I guess they're done already, I'll just keep going. So for this first experiment, what if I need a list of integers between 0 and 255? My verdict is that the bit vector is space efficient. You don't choose it because it's going to be obviously faster, it's not, or obviously simpler, it's doing a little more under the hood, but the good old-fashioned list of integers has to store in each slot the address of the real integer object 70. The bit vector just stores the seven bits, the eight bits that represent 70, and therefore uses on a 64-bit machine, which is what I'll presume for all of these calculations, eight times less space. And the point of a bloom filter is to save space in RAM. That for bit operations is why you go to the byte array, because it stores bytes as honest to goodness bytes with no extra overhead per byte. It's a great way to get numbers between 0 and 255 packed in the minimum space possible. So it is a win, but not in the way you might initially expect. All right. Second, it is a reusable buffer. When you read a string in, you can't do anything to it because it's immutable, but a byte array can be reused. For a quick benchmark, I got a made a random file of a gigabyte of random data, read it with cat, so I was able to estimate that probably Python won't be able to do better than 0.11 seconds on my machine reading in the same data. I tried it with DD. Anyone here ever used DD to rewrite data? It took six times longer. Anyone know why? I S traced them, and it's because of the block size. DD alas is an old and crafty and low-level tool. While cat will zoom along with 128k blocks, so it asks the OS for some data and gets 128,000 bytes in a single shot, DD, because it's an old level for writing to ancient 70s block devices, reads and writes 512 bytes by default. Giving DD the same block size does make it perform the same. You can give it a block size of 128k and get 0.11 seconds just right there with cat, but interestingly enough, it's not the default, despite the fact that I seem to know all these people that think DD would be faster somehow by default. It's not. It's the same reads and writes. And cat is the Unix default. DD came from IBM. But this teaches us a first lesson that we will now apply. As we look at Python IO, we need to keep block size in mind. The size of the chunks you read determines how many chunks you need to read, determines how often you need to converse with the operating system, which is often the expense that can come to dominate your runtime. Here's how we do it in normal Python. Read a block and write the data back out. Note this is perfectly safe if an undersized block comes in because the string that I'm here calling data that comes back is labeled with its length. It could be 5 bytes, it could be 128k. Python strings know their length and so right can just ask the length and send that many bytes of data back out. My first attempt at doing a read into seemed to work at first until I noticed that every file I wrote, however big it was originally, the copy that I made with this routine would always be a multiple of my block size. Why is that? Because when I create one of these new byte arrays of, let's say 128k, what this loop was doing is reading some number of bytes, who knows how many come in in the next block of the file if I'm near the end, reads some number of bytes into my byte array, and then writes out the whole byte array, including all the junk at the end that's maybe not part of the current block of the file. I was doing my right of the whole 128k block without consulting the length to see if I should have been writing the entire 128k block. One fix is to simply use slicing, is to get that byte array called data and take from it to write each time the slice that is length long. So if I get a full-sized block, I'm writing out all of the data, but if I get only half a block at the end of the file, I only write that last half block out from the initial part of my byte array. What if we didn't want the expense, though, of having to do that, back one slide, expensive slicing operation, because asking a Python string, unicode string, or byte array for a slice creates a whole new one and copies as much data into the new one as you ask for with the limits you set in the slice. If we wanted to achieve zero copy, the people who added byte array to the language, they thought of that as well. They added a second feature that works with byte array called a memory view. A memory view is a sliceable object. Here I take the slice 3 colon 6 of that byte array that I create up there. It's a slice which has no memory of its own but is letting you reach into the memory it was sliced from to make the change. Essentially, this memory view, the V that I create here, is just a, essentially, it's like a string object, but the addresses that it wants to write to in memory are the addresses right there in the middle of the byte array. So when I try to set its index zero value, it really goes to index 3 in the real byte array. When I set item 1, it really goes to slot 4. When I set item 2, it goes to slot 5. It really is just creating an object that acts like it's a little byte array but is, in fact, just an offset. It's adding something to each index you use as you read and write from it. And this is what can help us in the situation we're in. Here is a zero copy version of my fixed code to try to read in lots of blocks. Before I was asking data, the byte array itself to do the slicing, and like all Python strings, it gives me a whole new one when I ask for a slice. Now, I'm looking at it through a memory view. So if I ask, let's say, for a view of, you know, if length is 128k and asking for all the data, it just gives me a little memory view object whose addresses are pointing at the whole block of data. A very cheap operation. And so memory views are often necessary to get any kind of performance out of the byte array when doing IO, especially when you can't predict how big the next delivery of information will be. Here are the runtimes of DD and cat that we discussed earlier. Compared to just plain old read with normal Python strings, read into my first version that was broken because it wasn't careful about how much it wrote does run slightly faster than the traditional Python way of doing things. But when you then pivot to using a slice byte array and slicing it, because you're copying every piece of data into memory twice, it's much more expensive, it is the memory view. It is that zero expense, very little expense, constant time expense, I should say, ability to slice without copying data that lets us create a correct version of a file copy while still slightly beating read and write and traditional strings. So that was a lot of work and we got a 4% speed up with byte array. Now, small blocks, things get worse for byte array because what will slicing here so often do, it creates a new object every time and creating one of these little view objects with its pointers into the part of the byte array I want to look at was fine when I was only doing it every few hundred K of data, but what if I'm like the defaults of DD and I'm going to be reading and writing 512 bytes at a time, what if I have to spin up a new memory view for every half K of data? Then things start to look very bad and, in fact, the memory view used correctly where you're careful of your lengths is simply a loss. It's much, reading where it just returns a Python string is really efficient. A write of a Python string is really efficient. You can easily get into situations with the fancy attempts one makes with a byte array to create more expensive IO than you had when you just used traditional immutable strings that, yes, required Python to build a new string for every call to read, but cut out all of the rest of that expense. I was sad for the byte array at this point in my talk. So I stared at the example. 20% slow down for a small block size, but then I thought of something. What if we don't always slice? Because when reading from a file, different from a network, when reading from a file, the normal case is that unless you're at the very end of the file, you're going to get as much as you ask for. Ask for 128 K, you're going to get it. The normal case is that the length equals the block size, and in that case, there's not only no reason to ask the byte array to take a slice of itself and copy all that data, there's no reason to use the view to limit the amount of data you're using from the block. You're going to use all of it. And so if you handle that special case, you don't incur an object creation step in order to get that right call started, and you slightly beat the performance of the traditional read write loop by 4%. Just like for the big block case. So even if your I.O. is in a situation where the block size will be varying or might be small, you can, if you're careful and cut and paste from my talk slides, you can run slightly faster than the traditional read and write with immutable strings. Python 2.7, by the way, has the same relative behaviors between those different choices on my machine slightly slower. And I think the lesson here is that it is just hard to beat old fashioned strings when you're pulling in data and then just immediately sending it back to the operating system over some other channel. It's really something how the good old fashioned immutable string that makes functional programmers' hearts sing is pretty much as good in this case as our weird side effect idea of constantly modifying this single byte array that we have created. So my verdict is that it is dangerous because it's so easy to write what looks like pretty code, it looks like almost the same little read write loop, but is going to operate substantially worse in situations that you might not think to test for unless you think of the small blocks case. The one advantage it does offer is a great memory profile because there's a link later to a great blog post online about someone writing an audio server that needed to keep lots of strings in a buffer and his memory usage was going through the roof because if you're constantly allocating and deallocating differently sized strings, because every call to read needs to make a new string to hand it back to you, then you can get a lot of memory fragmentation. If instead you have one byte array and you use it over and over and over and over, there's nothing happening to get fragmented. So don't do the byte array, I wouldn't do the byte array for the 4% speedup. I would do it because I wanted to control my memory profile, but only if I knew that was a problem in my application domain. All right, now we go on to another and more interesting situation using the byte array as the accumulator. Fun question for people doing new network programming, how many bytes will receive 1024 return? The answer is one. Or more if the network stack is in the mood, but you're only guaranteed one. And this is the opposite, a file IO. File IO, you ask for 128K, if there's 128K left in the file, it will wait for the disk to spin, it will wait for the head to be in the right place, it will leave you paused until a full 128K is ready for delivery, and then wake you back up. The network is the opposite. Receive will block only until at least a single byte is available and then set you off running to process it. And that can happen if your buffer size happens to be just a little less than the size of the last few packets that arrive. You can have a call to receive that finds only one or two bytes left, meaning unlike in the case where we were choosing our read size for files, usually it's the network, it's the clients you're communicating with that kind of decide how big your chunks of IOR when you're talking on the network. So you're always potentially in the case where you're dealing with little pieces of data. This fact, by the way, that you always are given an answer when even just a few bytes can be sent or received is why new network programmers tend to get into the, but it worked when I ran against local host problem. They get into that situation because when you run your server that you've just written and your little client that you've just written on local host, the OS will send enormous blocks of data back and forth between the two processes. Then they'll take it to their team and say, look what I wrote, try it between two different machines and it'll hang and never get all of the data because they didn't learn on local host that you receive will often just give you a few thousand bytes and you need to keep at it and watch until everything you need has arrived. So what is it like to use a traditional receive solution getting a new string each time holding the new data that's come in? This is what it looks like. Again, here we're getting lots of maybe little pieces of data which I'm simulating by only asking for a single Ethernet packet length. So even when I run this on local host, it'll pretend like packets are coming in. This is what many Python programmers start with. They just create an empty string and they plus equal more data to it each time. In Python tutorials, many of you will have seen this, the creating of the string and data plus equals more as an anti-pattern that you avoid because I tried running this. How long does the plus equals approach take? Infinity time. Meaning that I finally needed my laptop back so I killed it and I'll never know how long the loop would have taken to read my gigabyte of data. But when you do plus equals, you're asking Python to create a little string and then your first plus equals makes a slightly longer one. Your next plus equals through the loop creates a slightly longer one into which all the data from the second string has to be copied to make the third one. Then you go through the loop again and now you have to copy all that data again to make your fourth string. And if you have a million bytes to read, you wind up doing half a trillion operations. It's called an order in squared algorithm, generally to be avoided if you wanted to finish by lunchtime. So this is what we tell everyone to do. Pivot to keeping a list of blocks that you've received and join them together at the end in a single step. Python's much better at that. This actually finished on my laptop. It's the traditional way of accumulating data from the internet in Python or from a network. Took about a little more than a second to read in a gig of data in those small 1.5K chunks. Now, there is a version like read into, but that receives into a byte array you've already built instead of building a new string, but it now runs into a problem. When we do read into or receive into, where does it put the data? At the beginning of the array. And all of our incoming blocks will overwrite each other. What we want as more and more of blocks come in from the network is to arrange them along our byte array. So that memory view slicing expense that I added in its statement to avoid whenever possible in the previous code, it now becomes mandatory. Again, this ability with a view to write into byte locations that aren't at the beginning, but are somewhere in the middle of the byte array that you've built. The first block can go at the beginning, but you need to build a memory view to target the second block after the first block, the third block after that, and so forth. And so you need to build a memory view and you're going to need to use it to target that receive V into at subsequent positions inside of your big byte array. I'm presuming that you know the content like the head of time and have preallocated it and you're waiting to fill it with data. This takes about eight tenths of a second because we a bit of a win here because you haven't had to build a list, you haven't had to call join, you haven't built a bunch of intermediate data structures. It actually is a significant win when you need to keep the data that you're reading rather than just immediately passing it back to the OS. Another possibility I saw on someone's blog is to do an old fashioned receive of a new string and then try to do a byte array extend to grow your byte array with these new strings. It copies the data twice but does get rid of that join concatenation. It looks something like this, data.extend down there near the bottom. It is not a win over the normal way of using byte arrays because it turns out byte array extend is pretty inefficient. It asks for an iterator over its argument and then calls the iterator's next function over and over for every byte and then asks the int object what its value is so that it can then put it in an intermediate array and that involves having to increment and decrement the reference pointer of the integer it's given and by the time you're done you can compute that you've done at least 40 bytes of bandwidth to RAM even ignoring the instructions and stacks and arguments that are passing in order to get that single byte value extended onto the end of your byte array plus it doesn't write to your byte array. It writes to an intermediate buffer that it grows dynamically and then does the append when it's done so that should that iteration die part way through you don't wind up having modified the byte array some it wants to either succeed or fail as an atomic operation so that's why it's kind of slow kind of klugey but seeing that blog post made me ask a question does the byte array have an append operation that's any good? I mean surely the people writing it knew that we'd want to do that without spinning up an iterator and calling it 1500 times does it have an operation that's really good and yes it does I read the c code to find it now think about it where would you put the real extend operator the real ability to make your byte array longer obviously you'd hide it behind the operator that we've spent 20 years telling people to never use with string values this might be so difficult that some of you will never do it but if you can convince yourself to type this after all of this time this is actually something that byte arrays do magnificently just plus equal the additional data to your byte array and you will be even receive into's ability to grow your array with data so this case where we need to accumulate and keep the whole pay road is a real win for the byte array in all of the approaches and there don't seem to be sharp edges that can suddenly make it behave much worse than the the list and joint 33 speed up in that last version of the algorithm and cleaner code I mean admit it you've always wanted to just plus equal haven't you it's the natural way to write it in python and this is one of those neat intersections of the fast way with the way that looks good on the page as well so I'm not going to talk about send you might think I'll now get into the fact that send doesn't always send the whole payload but python has long had you covered here python sockets have for a very long time had a send all that sits in a loop in c sending shorter and shorter tails of your data until finally the os buffers have been able to receive it all so I don't see that we need byte arrays for that and I can declare the byte array the winner if you need an accumulator if you need to very quickly in a performance sensitive environment accumulate a lot of incoming data it is a noticeably good win with two different techniques that work pretty well I'll briefly mention that some people want a freestyle mutable string when they see the byte array they don't think of io they don't think of bloom filters and bit vectors they want to mess with a string they want a string that they can just change and all ish I have not found yet a good use for this and I'll sort of show you why it winds up being awkward you want to change part of a payload before using storing or retransmitting that would be the use case here because if you want to lowercase the whole thing you have to touch all the bytes anyway so you might as well build a new one good thing is that the byte array is mutable you can get it and change it but none of the methods that it shares with strings do mutation to it if you call dot upper on your byte array you get a new byte array so you have a mutable string type that does nothing string like mutably a byte array only changes when subjected to list like operations like assignment to an index or assignment to a slice or dot clear and so the result if you try writing a network algorithm or something with this is curious you have a mutable string that alas does no mutation precisely when you start calling its string methods want to lowercase a word well you're going to have to make a copy to call lower on you're going to have to do slicing giving you a copy call lower making another copy and then assignment to copy it a third time back into the data structure in order to get that accomplished there isn't I looked there isn't a lower into and an upper into that would let you do smaller grained uh manipulations that wrote directly to your new byte array can the memory view save us though it did in all of the previous occasions no because memory views don't do anything string like the moment you move to a memory view which lets you look at a piece of string efficiently you're not going to be able to do anything string like to it so you have to do a round trip out to a smaller string to do a manipulation and store data back to mutate a byte array without rewriting its whole content you're going to need indexes do you remember indexes back the first week before you'd found split strip and join and we're like doing everything like this you get to do it again if you decide to try mutating a byte array the byte array will let you enjoy those days all over again because all the mutation operations are powered only by indexes one hint regular expressions while they turned off a lot of other string like things were left turned on and do work against byte arrays and can help give you some useful indexes to use freestyle mutable string it's awkward I have here at the end of the slides some uh links and pointers to other documentation including the blog posts that inspired this talk and made me want to bring everything together in one place in conclusion the byte array it is a very memory efficient not faster but memory efficient store of byte integers should you ever need them it can help control memory fragmentation when doing uh high-performance i o because you don't have to create a new string but it's hard to make it faster in a reliable way be careful it's a great way to accumulate data that's coming in a piece at a time that's its real superpower and though it's very tempting for string operations it's also a bit underpowered and a bit awkward that's what I've learned so far thank you very much we are out of time so I will meet interested byte array fans outside the door in a few minutes", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.0, "text": " Alright. Hello, everybody. I have quite an honor today. I am lucky enough to introduce", "tokens": [50364, 2798, 13, 2425, 11, 2201, 13, 286, 362, 1596, 364, 5968, 965, 13, 286, 669, 6356, 1547, 281, 5366, 51164], "temperature": 0.0, "avg_logprob": -0.17967484214089133, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.13697659969329834}, {"id": 1, "seek": 0, "start": 16.0, "end": 22.400000000000002, "text": " Brandon Rhodes. He's a longtime Python developer, maintainer of several amateur astronomy libraries", "tokens": [51164, 22606, 45973, 13, 634, 311, 257, 44363, 15329, 10754, 11, 6909, 260, 295, 2940, 29339, 37844, 15148, 51484], "temperature": 0.0, "avg_logprob": -0.17967484214089133, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.13697659969329834}, {"id": 2, "seek": 0, "start": 22.400000000000002, "end": 28.240000000000002, "text": " and a developer for Dropbox. He's also a Quizmaster extraordinaire, as some people got to find", "tokens": [51484, 293, 257, 10754, 337, 17675, 4995, 13, 634, 311, 611, 257, 38020, 21640, 10149, 38431, 11, 382, 512, 561, 658, 281, 915, 51776], "temperature": 0.0, "avg_logprob": -0.17967484214089133, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.13697659969329834}, {"id": 3, "seek": 2824, "start": 28.24, "end": 34.0, "text": " out last night. Today, he will be presenting on, oh, come on, who needs byte arrays? Without", "tokens": [50364, 484, 1036, 1818, 13, 2692, 11, 415, 486, 312, 15578, 322, 11, 1954, 11, 808, 322, 11, 567, 2203, 40846, 41011, 30, 9129, 50652], "temperature": 0.0, "avg_logprob": -0.25295826484417094, "compression_ratio": 1.2901234567901234, "no_speech_prob": 0.013958264142274857}, {"id": 4, "seek": 2824, "start": 34.0, "end": 45.12, "text": " further ado, Brandon Rhodes.", "tokens": [50652, 3052, 22450, 11, 22606, 45973, 13, 51208], "temperature": 0.0, "avg_logprob": -0.25295826484417094, "compression_ratio": 1.2901234567901234, "no_speech_prob": 0.013958264142274857}, {"id": 5, "seek": 2824, "start": 45.12, "end": 50.599999999999994, "text": " Welcome, everybody. I hope you're having a good time at PyCon and in Montreal. My topic", "tokens": [51208, 4027, 11, 2201, 13, 286, 1454, 291, 434, 1419, 257, 665, 565, 412, 9953, 9838, 293, 294, 34180, 13, 1222, 4829, 51482], "temperature": 0.0, "avg_logprob": -0.25295826484417094, "compression_ratio": 1.2901234567901234, "no_speech_prob": 0.013958264142274857}, {"id": 6, "seek": 5060, "start": 50.6, "end": 59.08, "text": " today is indeed byte arrays. A very interesting recent addition to the Python ecosystem. Because", "tokens": [50364, 965, 307, 6451, 40846, 41011, 13, 316, 588, 1880, 5162, 4500, 281, 264, 15329, 11311, 13, 1436, 50788], "temperature": 0.0, "avg_logprob": -0.15436841620773564, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.36830154061317444}, {"id": 7, "seek": 5060, "start": 59.08, "end": 64.28, "text": " in Python, normal string objects, the ones that we're accustomed to dealing with are", "tokens": [50788, 294, 15329, 11, 2710, 6798, 6565, 11, 264, 2306, 300, 321, 434, 35980, 281, 6260, 365, 366, 51048], "temperature": 0.0, "avg_logprob": -0.15436841620773564, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.36830154061317444}, {"id": 8, "seek": 5060, "start": 64.28, "end": 74.2, "text": " immutable. They can't be changed or modified. This is true of the types available under", "tokens": [51048, 3397, 32148, 13, 814, 393, 380, 312, 3105, 420, 15873, 13, 639, 307, 2074, 295, 264, 3467, 2435, 833, 51544], "temperature": 0.0, "avg_logprob": -0.15436841620773564, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.36830154061317444}, {"id": 9, "seek": 7420, "start": 74.2, "end": 84.12, "text": " both two and three. The original string type, STR, was renamed to bytes because of its low-level", "tokens": [50364, 1293, 732, 293, 1045, 13, 440, 3380, 6798, 2010, 11, 43013, 11, 390, 40949, 281, 36088, 570, 295, 1080, 2295, 12, 12418, 50860], "temperature": 0.0, "avg_logprob": -0.2202012832850626, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.11860164254903793}, {"id": 10, "seek": 7420, "start": 84.12, "end": 91.80000000000001, "text": " nature and then that synonym was also backported to Python 2. We will not talk much today about", "tokens": [50860, 3687, 293, 550, 300, 5451, 12732, 390, 611, 646, 2707, 292, 281, 15329, 568, 13, 492, 486, 406, 751, 709, 965, 466, 51244], "temperature": 0.0, "avg_logprob": -0.2202012832850626, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.11860164254903793}, {"id": 11, "seek": 7420, "start": 91.80000000000001, "end": 102.92, "text": " the newer Unicode byte strings that were renamed to the official string type of Python 3. We're", "tokens": [51244, 264, 17628, 1156, 299, 1429, 40846, 13985, 300, 645, 40949, 281, 264, 4783, 6798, 2010, 295, 15329, 805, 13, 492, 434, 51800], "temperature": 0.0, "avg_logprob": -0.2202012832850626, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.11860164254903793}, {"id": 12, "seek": 10292, "start": 102.92, "end": 109.4, "text": " going to be talking about those lower-level ones. The strings that don't pretend they have symbols", "tokens": [50364, 516, 281, 312, 1417, 466, 729, 3126, 12, 12418, 2306, 13, 440, 13985, 300, 500, 380, 11865, 436, 362, 16944, 50688], "temperature": 0.0, "avg_logprob": -0.1573445951783812, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0017228765645995736}, {"id": 13, "seek": 10292, "start": 109.4, "end": 121.64, "text": " inside of them so much as they know that their innards are really bytes. 8-bit codes, 0-255.", "tokens": [50688, 1854, 295, 552, 370, 709, 382, 436, 458, 300, 641, 7714, 2287, 366, 534, 36088, 13, 1649, 12, 5260, 14211, 11, 1958, 12, 6074, 20, 13, 51300], "temperature": 0.0, "avg_logprob": -0.1573445951783812, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0017228765645995736}, {"id": 14, "seek": 10292, "start": 121.64, "end": 129.96, "text": " For the most part, I will put that little B in front of the bytes strings that I type. It is", "tokens": [51300, 1171, 264, 881, 644, 11, 286, 486, 829, 300, 707, 363, 294, 1868, 295, 264, 36088, 13985, 300, 286, 2010, 13, 467, 307, 51716], "temperature": 0.0, "avg_logprob": -0.1573445951783812, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0017228765645995736}, {"id": 15, "seek": 12996, "start": 130.04000000000002, "end": 137.56, "text": " optional under Python 2, but it becomes mandatory under Python 3. So if I write my strings like", "tokens": [50368, 17312, 833, 15329, 568, 11, 457, 309, 3643, 22173, 833, 15329, 805, 13, 407, 498, 286, 2464, 452, 13985, 411, 50744], "temperature": 0.0, "avg_logprob": -0.11476191878318787, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.00474934559315443}, {"id": 16, "seek": 12996, "start": 137.56, "end": 144.76000000000002, "text": " this, then it will work wherever you try this later if you want to see the examples run. Strings", "tokens": [50744, 341, 11, 550, 309, 486, 589, 8660, 291, 853, 341, 1780, 498, 291, 528, 281, 536, 264, 5110, 1190, 13, 8251, 1109, 51104], "temperature": 0.0, "avg_logprob": -0.11476191878318787, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.00474934559315443}, {"id": 17, "seek": 12996, "start": 144.76000000000002, "end": 150.36, "text": " are immutable. What does that mean? It means that when you call methods, when you do things to them,", "tokens": [51104, 366, 3397, 32148, 13, 708, 775, 300, 914, 30, 467, 1355, 300, 562, 291, 818, 7150, 11, 562, 291, 360, 721, 281, 552, 11, 51384], "temperature": 0.0, "avg_logprob": -0.11476191878318787, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.00474934559315443}, {"id": 18, "seek": 12996, "start": 150.36, "end": 156.60000000000002, "text": " the original object itself doesn't change. You get given a new object as the return value of the", "tokens": [51384, 264, 3380, 2657, 2564, 1177, 380, 1319, 13, 509, 483, 2212, 257, 777, 2657, 382, 264, 2736, 2158, 295, 264, 51696], "temperature": 0.0, "avg_logprob": -0.11476191878318787, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.00474934559315443}, {"id": 19, "seek": 15660, "start": 156.6, "end": 162.76, "text": " method you call. So if .lower returns to you a new string, you can still peek back and see that", "tokens": [50364, 3170, 291, 818, 13, 407, 498, 2411, 34598, 11247, 281, 291, 257, 777, 6798, 11, 291, 393, 920, 19604, 646, 293, 536, 300, 50672], "temperature": 0.0, "avg_logprob": -0.06917767472319551, "compression_ratio": 1.7627906976744185, "no_speech_prob": 0.0013449237449094653}, {"id": 20, "seek": 15660, "start": 162.76, "end": 168.35999999999999, "text": " the original is untouched and unchanged. If you run split, you'll see that both of the objects", "tokens": [50672, 264, 3380, 307, 1701, 36740, 293, 44553, 13, 759, 291, 1190, 7472, 11, 291, 603, 536, 300, 1293, 295, 264, 6565, 50952], "temperature": 0.0, "avg_logprob": -0.06917767472319551, "compression_ratio": 1.7627906976744185, "no_speech_prob": 0.0013449237449094653}, {"id": 21, "seek": 15660, "start": 168.35999999999999, "end": 176.04, "text": " you've been given are new string objects. The original is still unchanged. They do not allow", "tokens": [50952, 291, 600, 668, 2212, 366, 777, 6798, 6565, 13, 440, 3380, 307, 920, 44553, 13, 814, 360, 406, 2089, 51336], "temperature": 0.0, "avg_logprob": -0.06917767472319551, "compression_ratio": 1.7627906976744185, "no_speech_prob": 0.0013449237449094653}, {"id": 22, "seek": 15660, "start": 176.04, "end": 181.24, "text": " assignment because that would make them change. It would make them mutate as the technical term", "tokens": [51336, 15187, 570, 300, 576, 652, 552, 1319, 13, 467, 576, 652, 552, 5839, 473, 382, 264, 6191, 1433, 51596], "temperature": 0.0, "avg_logprob": -0.06917767472319551, "compression_ratio": 1.7627906976744185, "no_speech_prob": 0.0013449237449094653}, {"id": 23, "seek": 18124, "start": 181.32000000000002, "end": 188.28, "text": " in computer science. Now, immutability has led a long and very successful career in Python", "tokens": [50368, 294, 3820, 3497, 13, 823, 11, 3397, 325, 2310, 575, 4684, 257, 938, 293, 588, 4406, 3988, 294, 15329, 50716], "temperature": 0.0, "avg_logprob": -0.13468222088283963, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.03725763037800789}, {"id": 24, "seek": 18124, "start": 188.28, "end": 195.16, "text": " because it makes things simple. You don't pass a name to a function only to finally", "tokens": [50716, 570, 309, 1669, 721, 2199, 13, 509, 500, 380, 1320, 257, 1315, 281, 257, 2445, 787, 281, 2721, 51060], "temperature": 0.0, "avg_logprob": -0.13468222088283963, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.03725763037800789}, {"id": 25, "seek": 18124, "start": 195.16, "end": 200.76000000000002, "text": " suddenly discover it's another name when it comes back. You don't pass a string or a block to", "tokens": [51060, 5800, 4411, 309, 311, 1071, 1315, 562, 309, 1487, 646, 13, 509, 500, 380, 1320, 257, 6798, 420, 257, 3461, 281, 51340], "temperature": 0.0, "avg_logprob": -0.13468222088283963, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.03725763037800789}, {"id": 26, "seek": 18124, "start": 200.76000000000002, "end": 206.20000000000002, "text": " someone, and suddenly it's a different string or block. It's a very, very simple model that if", "tokens": [51340, 1580, 11, 293, 5800, 309, 311, 257, 819, 6798, 420, 3461, 13, 467, 311, 257, 588, 11, 588, 2199, 2316, 300, 498, 51612], "temperature": 0.0, "avg_logprob": -0.13468222088283963, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.03725763037800789}, {"id": 27, "seek": 20620, "start": 206.2, "end": 212.04, "text": " you have the word Python, you know it will always remain so. And it actually is one of the most", "tokens": [50364, 291, 362, 264, 1349, 15329, 11, 291, 458, 309, 486, 1009, 6222, 370, 13, 400, 309, 767, 307, 472, 295, 264, 881, 50656], "temperature": 0.0, "avg_logprob": -0.10216496314531491, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0007433053106069565}, {"id": 28, "seek": 20620, "start": 212.04, "end": 216.76, "text": " parts of Python. That's the most functional programming languages where new results are", "tokens": [50656, 3166, 295, 15329, 13, 663, 311, 264, 881, 11745, 9410, 8650, 689, 777, 3542, 366, 50892], "temperature": 0.0, "avg_logprob": -0.10216496314531491, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0007433053106069565}, {"id": 29, "seek": 20620, "start": 216.76, "end": 224.12, "text": " returned instead of being written onto data structures you already hold. The string types", "tokens": [50892, 8752, 2602, 295, 885, 3720, 3911, 1412, 9227, 291, 1217, 1797, 13, 440, 6798, 3467, 51260], "temperature": 0.0, "avg_logprob": -0.10216496314531491, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0007433053106069565}, {"id": 30, "seek": 20620, "start": 224.12, "end": 231.48, "text": " are a primary example of that. But it sometimes is a little expensive in terms of allocation.", "tokens": [51260, 366, 257, 6194, 1365, 295, 300, 13, 583, 309, 2171, 307, 257, 707, 5124, 294, 2115, 295, 27599, 13, 51628], "temperature": 0.0, "avg_logprob": -0.10216496314531491, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.0007433053106069565}, {"id": 31, "seek": 23148, "start": 231.48, "end": 236.92, "text": " Every time you want to make any little tweak to a string, it has to allocate a new one for you.", "tokens": [50364, 2048, 565, 291, 528, 281, 652, 604, 707, 29879, 281, 257, 6798, 11, 309, 575, 281, 35713, 257, 777, 472, 337, 291, 13, 50636], "temperature": 0.0, "avg_logprob": -0.09453054574819711, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.0009695417247712612}, {"id": 32, "seek": 23148, "start": 236.92, "end": 244.2, "text": " That means a lot of data gets copied back and forth into new areas of memory. Not everybody", "tokens": [50636, 663, 1355, 257, 688, 295, 1412, 2170, 25365, 646, 293, 5220, 666, 777, 3179, 295, 4675, 13, 1726, 2201, 51000], "temperature": 0.0, "avg_logprob": -0.09453054574819711, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.0009695417247712612}, {"id": 33, "seek": 23148, "start": 244.2, "end": 251.39999999999998, "text": " is happy about that. And so Python 3 introduced and then it was back ported to Python 2, 6,", "tokens": [51000, 307, 2055, 466, 300, 13, 400, 370, 15329, 805, 7268, 293, 550, 309, 390, 646, 2436, 292, 281, 15329, 568, 11, 1386, 11, 51360], "temperature": 0.0, "avg_logprob": -0.09453054574819711, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.0009695417247712612}, {"id": 34, "seek": 23148, "start": 251.39999999999998, "end": 258.52, "text": " and 7, the new byte array. It's a built-in. Python 2, 7, Python 3, you can just type byte array", "tokens": [51360, 293, 1614, 11, 264, 777, 40846, 10225, 13, 467, 311, 257, 3094, 12, 259, 13, 15329, 568, 11, 1614, 11, 15329, 805, 11, 291, 393, 445, 2010, 40846, 10225, 51716], "temperature": 0.0, "avg_logprob": -0.09453054574819711, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.0009695417247712612}, {"id": 35, "seek": 25852, "start": 258.52, "end": 265.64, "text": " and you'll get access to that type, just like you can with stir and int and list. A byte array", "tokens": [50364, 293, 291, 603, 483, 2105, 281, 300, 2010, 11, 445, 411, 291, 393, 365, 8946, 293, 560, 293, 1329, 13, 316, 40846, 10225, 50720], "temperature": 0.0, "avg_logprob": -0.13382549808449942, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0004042580840177834}, {"id": 36, "seek": 25852, "start": 266.44, "end": 276.12, "text": " is a mutable string that is based, this is interesting, on Python 3's byte string, not the", "tokens": [50760, 307, 257, 5839, 712, 6798, 300, 307, 2361, 11, 341, 307, 1880, 11, 322, 15329, 805, 311, 40846, 6798, 11, 406, 264, 51244], "temperature": 0.0, "avg_logprob": -0.13382549808449942, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0004042580840177834}, {"id": 37, "seek": 25852, "start": 276.12, "end": 283.79999999999995, "text": " old stir string from Python 2. And that's an interesting problem, that it's based on Python", "tokens": [51244, 1331, 8946, 6798, 490, 15329, 568, 13, 400, 300, 311, 364, 1880, 1154, 11, 300, 309, 311, 2361, 322, 15329, 51628], "temperature": 0.0, "avg_logprob": -0.13382549808449942, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0004042580840177834}, {"id": 38, "seek": 28380, "start": 283.8, "end": 294.6, "text": " 3's string, byte string type, because honestly, the Python 3 bytes type is designed to be awkward", "tokens": [50364, 805, 311, 6798, 11, 40846, 6798, 2010, 11, 570, 6095, 11, 264, 15329, 805, 36088, 2010, 307, 4761, 281, 312, 11411, 50904], "temperature": 0.0, "avg_logprob": -0.11792317558737363, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.004066829103976488}, {"id": 39, "seek": 28380, "start": 294.6, "end": 304.28000000000003, "text": " for string operations. Why? So you will want to be a good person and run the code before", "tokens": [50904, 337, 6798, 7705, 13, 1545, 30, 407, 291, 486, 528, 281, 312, 257, 665, 954, 293, 1190, 264, 3089, 949, 51388], "temperature": 0.0, "avg_logprob": -0.11792317558737363, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.004066829103976488}, {"id": 40, "seek": 28380, "start": 304.28000000000003, "end": 312.2, "text": " treating your data as characters. And this has led to Python 3 programmers tending to write code", "tokens": [51388, 15083, 428, 1412, 382, 4342, 13, 400, 341, 575, 4684, 281, 15329, 805, 41504, 256, 2029, 281, 2464, 3089, 51784], "temperature": 0.0, "avg_logprob": -0.11792317558737363, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.004066829103976488}, {"id": 41, "seek": 31220, "start": 312.28, "end": 317.8, "text": " that is from the ground up prepared for internationalization and different alphabets because they", "tokens": [50368, 300, 307, 490, 264, 2727, 493, 4927, 337, 5058, 2144, 293, 819, 419, 950, 455, 1385, 570, 436, 50644], "temperature": 0.0, "avg_logprob": -0.1059058956477953, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.0008033933700062335}, {"id": 42, "seek": 31220, "start": 317.8, "end": 323.96, "text": " think about the issue of decoding on the way in and encoding on the way back out because they", "tokens": [50644, 519, 466, 264, 2734, 295, 979, 8616, 322, 264, 636, 294, 293, 43430, 322, 264, 636, 646, 484, 570, 436, 50952], "temperature": 0.0, "avg_logprob": -0.1059058956477953, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.0008033933700062335}, {"id": 43, "seek": 31220, "start": 323.96, "end": 330.59999999999997, "text": " have to. But we'll see it leads to some interesting behaviors. Just professionally, always be aware", "tokens": [50952, 362, 281, 13, 583, 321, 603, 536, 309, 6689, 281, 512, 1880, 15501, 13, 1449, 27941, 11, 1009, 312, 3650, 51284], "temperature": 0.0, "avg_logprob": -0.1059058956477953, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.0008033933700062335}, {"id": 44, "seek": 31220, "start": 330.59999999999997, "end": 339.4, "text": " of using string types that wish you weren't using them. In Python 2, let's compare. We can build a", "tokens": [51284, 295, 1228, 6798, 3467, 300, 3172, 291, 4999, 380, 1228, 552, 13, 682, 15329, 568, 11, 718, 311, 6794, 13, 492, 393, 1322, 257, 51724], "temperature": 0.0, "avg_logprob": -0.1059058956477953, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.0008033933700062335}, {"id": 45, "seek": 33940, "start": 339.47999999999996, "end": 345.88, "text": " string, we can ask its length, we can split it into pieces. Python 3's byte type, there's little", "tokens": [50368, 6798, 11, 321, 393, 1029, 1080, 4641, 11, 321, 393, 7472, 309, 666, 3755, 13, 15329, 805, 311, 40846, 2010, 11, 456, 311, 707, 50688], "temperature": 0.0, "avg_logprob": -0.14127833572859616, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.001133135985583067}, {"id": 46, "seek": 33940, "start": 345.88, "end": 351.0, "text": " B characters hanging out in front of our byte strings, but we can take the length, we can call", "tokens": [50688, 363, 4342, 8345, 484, 294, 1868, 295, 527, 40846, 13985, 11, 457, 321, 393, 747, 264, 4641, 11, 321, 393, 818, 50944], "temperature": 0.0, "avg_logprob": -0.14127833572859616, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.001133135985583067}, {"id": 47, "seek": 33940, "start": 351.0, "end": 357.96, "text": " a method like split. In Python 2, we can use those square brackets with a colon in order to do", "tokens": [50944, 257, 3170, 411, 7472, 13, 682, 15329, 568, 11, 321, 393, 764, 729, 3732, 26179, 365, 257, 8255, 294, 1668, 281, 360, 51292], "temperature": 0.0, "avg_logprob": -0.14127833572859616, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.001133135985583067}, {"id": 48, "seek": 33940, "start": 357.96, "end": 364.67999999999995, "text": " slicing and get back a copy of the inside of the string. The exact same thing works exactly the", "tokens": [51292, 46586, 293, 483, 646, 257, 5055, 295, 264, 1854, 295, 264, 6798, 13, 440, 1900, 912, 551, 1985, 2293, 264, 51628], "temperature": 0.0, "avg_logprob": -0.14127833572859616, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.001133135985583067}, {"id": 49, "seek": 36468, "start": 364.68, "end": 372.6, "text": " same way in Python 3. In Python 2, it's always a custom in Python that if something has a length,", "tokens": [50364, 912, 636, 294, 15329, 805, 13, 682, 15329, 568, 11, 309, 311, 1009, 257, 2375, 294, 15329, 300, 498, 746, 575, 257, 4641, 11, 50760], "temperature": 0.0, "avg_logprob": -0.07627831776936848, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0008826226694509387}, {"id": 50, "seek": 36468, "start": 372.6, "end": 378.2, "text": " it should allow itself to be iterated or looped over. In Python 2, if you try looping over a", "tokens": [50760, 309, 820, 2089, 2564, 281, 312, 17138, 770, 420, 6367, 292, 670, 13, 682, 15329, 568, 11, 498, 291, 853, 6367, 278, 670, 257, 51040], "temperature": 0.0, "avg_logprob": -0.07627831776936848, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0008826226694509387}, {"id": 51, "seek": 36468, "start": 378.2, "end": 386.28000000000003, "text": " string, you get out smaller strings, one character strings that are inside. What happens if you", "tokens": [51040, 6798, 11, 291, 483, 484, 4356, 13985, 11, 472, 2517, 13985, 300, 366, 1854, 13, 708, 2314, 498, 291, 51444], "temperature": 0.0, "avg_logprob": -0.07627831776936848, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0008826226694509387}, {"id": 52, "seek": 38628, "start": 387.08, "end": 399.71999999999997, "text": " press enter for this line of code in Python 3? You get a syntax error. Syntax error, you failed to", "tokens": [50404, 1886, 3242, 337, 341, 1622, 295, 3089, 294, 15329, 805, 30, 509, 483, 257, 28431, 6713, 13, 3902, 580, 2797, 6713, 11, 291, 7612, 281, 51036], "temperature": 0.0, "avg_logprob": -0.14243512471516928, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.003536998527124524}, {"id": 53, "seek": 38628, "start": 399.71999999999997, "end": 410.28, "text": " pay the Python 3 per intax. Python 3, it's kind of like an old text-based adventure game where", "tokens": [51036, 1689, 264, 15329, 805, 680, 560, 2797, 13, 15329, 805, 11, 309, 311, 733, 295, 411, 364, 1331, 2487, 12, 6032, 9868, 1216, 689, 51564], "temperature": 0.0, "avg_logprob": -0.14243512471516928, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.003536998527124524}, {"id": 54, "seek": 38628, "start": 410.28, "end": 415.55999999999995, "text": " you can tell the writer just threw an extra obstacle in your way because a room needed to", "tokens": [51564, 291, 393, 980, 264, 9936, 445, 11918, 364, 2857, 23112, 294, 428, 636, 570, 257, 1808, 2978, 281, 51828], "temperature": 0.0, "avg_logprob": -0.14243512471516928, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.003536998527124524}, {"id": 55, "seek": 41556, "start": 415.56, "end": 433.32, "text": " be a little more complicated. You know, in seriousness, I've known Ruby, some Ruby programmers,", "tokens": [50364, 312, 257, 707, 544, 6179, 13, 509, 458, 11, 294, 44880, 11, 286, 600, 2570, 19907, 11, 512, 19907, 41504, 11, 51252], "temperature": 0.0, "avg_logprob": -0.1540054976940155, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.0011147765908390284}, {"id": 56, "seek": 41556, "start": 433.32, "end": 437.88, "text": " this is actually a big debate in the Ruby community, Ruby makes parenthesis optional", "tokens": [51252, 341, 307, 767, 257, 955, 7958, 294, 264, 19907, 1768, 11, 19907, 1669, 23350, 9374, 17312, 51480], "temperature": 0.0, "avg_logprob": -0.1540054976940155, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.0011147765908390284}, {"id": 57, "seek": 41556, "start": 437.88, "end": 443.72, "text": " when calling a function. The Rubyists who never use the parenthesis always tell me they could", "tokens": [51480, 562, 5141, 257, 2445, 13, 440, 19907, 1751, 567, 1128, 764, 264, 23350, 9374, 1009, 980, 385, 436, 727, 51772], "temperature": 0.0, "avg_logprob": -0.1540054976940155, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.0011147765908390284}, {"id": 58, "seek": 44372, "start": 443.72, "end": 450.04, "text": " never stand Python again. I always thought that was the oddest thing. Doesn't everyone want to", "tokens": [50364, 1128, 1463, 15329, 797, 13, 286, 1009, 1194, 300, 390, 264, 7401, 377, 551, 13, 12955, 380, 1518, 528, 281, 50680], "temperature": 0.0, "avg_logprob": -0.14093144260235688, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0041935984045267105}, {"id": 59, "seek": 44372, "start": 450.04, "end": 456.12, "text": " type parenthesis whenever they ask their computer to do something? I must admit that once it was", "tokens": [50680, 2010, 23350, 9374, 5699, 436, 1029, 641, 3820, 281, 360, 746, 30, 286, 1633, 9796, 300, 1564, 309, 390, 50984], "temperature": 0.0, "avg_logprob": -0.14093144260235688, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0041935984045267105}, {"id": 60, "seek": 44372, "start": 456.12, "end": 465.0, "text": " me who was suddenly having to type parenthesis, but they surely must still be wrong. Anyway.", "tokens": [50984, 385, 567, 390, 5800, 1419, 281, 2010, 23350, 9374, 11, 457, 436, 11468, 1633, 920, 312, 2085, 13, 5684, 13, 51428], "temperature": 0.0, "avg_logprob": -0.14093144260235688, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0041935984045267105}, {"id": 61, "seek": 46500, "start": 465.32, "end": 474.52, "text": " I did a conservative estimate of how much typing is cost me by these print statements in Python 3,", "tokens": [50380, 286, 630, 257, 13780, 12539, 295, 577, 709, 18444, 307, 2063, 385, 538, 613, 4482, 12363, 294, 15329, 805, 11, 50840], "temperature": 0.0, "avg_logprob": -0.2527898762324085, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.056606803089380264}, {"id": 62, "seek": 46500, "start": 474.52, "end": 482.76, "text": " and these are conservative estimates, and it's coming out to quite a bit of typing per year.", "tokens": [50840, 293, 613, 366, 13780, 20561, 11, 293, 309, 311, 1348, 484, 281, 1596, 257, 857, 295, 18444, 680, 1064, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2527898762324085, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.056606803089380264}, {"id": 63, "seek": 46500, "start": 482.76, "end": 489.88, "text": " I'm having to face going into Perendet just to write some Emax Lisp next week. Anyway, Python 3", "tokens": [51252, 286, 478, 1419, 281, 1851, 516, 666, 3026, 521, 302, 445, 281, 2464, 512, 462, 41167, 441, 7631, 958, 1243, 13, 5684, 11, 15329, 805, 51608], "temperature": 0.0, "avg_logprob": -0.2527898762324085, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.056606803089380264}, {"id": 64, "seek": 48988, "start": 489.88, "end": 494.6, "text": " wants them for this print statement, and what's another two perends when I've already typed so", "tokens": [50364, 2738, 552, 337, 341, 4482, 5629, 11, 293, 437, 311, 1071, 732, 680, 2581, 562, 286, 600, 1217, 33941, 370, 50600], "temperature": 0.0, "avg_logprob": -0.14764313016619002, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002530846686568111}, {"id": 65, "seek": 48988, "start": 494.6, "end": 506.44, "text": " many? So once you get the print statement working, you're in for another surprise. Python 3 bytes type", "tokens": [50600, 867, 30, 407, 1564, 291, 483, 264, 4482, 5629, 1364, 11, 291, 434, 294, 337, 1071, 6365, 13, 15329, 805, 36088, 2010, 51192], "temperature": 0.0, "avg_logprob": -0.14764313016619002, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002530846686568111}, {"id": 66, "seek": 48988, "start": 507.24, "end": 516.12, "text": " is not made of characters, it is made of numbers. This breaks a very important contract that for", "tokens": [51232, 307, 406, 1027, 295, 4342, 11, 309, 307, 1027, 295, 3547, 13, 639, 9857, 257, 588, 1021, 4364, 300, 337, 51676], "temperature": 0.0, "avg_logprob": -0.14764313016619002, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0002530846686568111}, {"id": 67, "seek": 51612, "start": 516.12, "end": 521.32, "text": " me existed with strings, which is that I can pull them into pieces with either indexing or", "tokens": [50364, 385, 13135, 365, 13985, 11, 597, 307, 300, 286, 393, 2235, 552, 666, 3755, 365, 2139, 8186, 278, 420, 50624], "temperature": 0.0, "avg_logprob": -0.0914419153903393, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015234338352456689}, {"id": 68, "seek": 51612, "start": 521.32, "end": 527.72, "text": " slicing and know that they would go back together again. Now, there is a way around by asking for", "tokens": [50624, 46586, 293, 458, 300, 436, 576, 352, 646, 1214, 797, 13, 823, 11, 456, 307, 257, 636, 926, 538, 3365, 337, 50944], "temperature": 0.0, "avg_logprob": -0.0914419153903393, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015234338352456689}, {"id": 69, "seek": 51612, "start": 527.72, "end": 536.84, "text": " one element slices instead of looking up integer indexes, but clearly it doesn't want me to treat", "tokens": [50944, 472, 4478, 19793, 2602, 295, 1237, 493, 24922, 8186, 279, 11, 457, 4448, 309, 1177, 380, 528, 385, 281, 2387, 51400], "temperature": 0.0, "avg_logprob": -0.0914419153903393, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015234338352456689}, {"id": 70, "seek": 51612, "start": 536.84, "end": 543.5600000000001, "text": " it like a string. So bytes objects, even if you learn some workarounds, are kind of an awkward fit", "tokens": [51400, 309, 411, 257, 6798, 13, 407, 36088, 6565, 11, 754, 498, 291, 1466, 512, 589, 289, 4432, 11, 366, 733, 295, 364, 11411, 3318, 51736], "temperature": 0.0, "avg_logprob": -0.0914419153903393, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015234338352456689}, {"id": 71, "seek": 54356, "start": 543.56, "end": 550.1999999999999, "text": " for many of the tasks they're called upon to do. They're kind of this hybrid type between a list of", "tokens": [50364, 337, 867, 295, 264, 9608, 436, 434, 1219, 3564, 281, 360, 13, 814, 434, 733, 295, 341, 13051, 2010, 1296, 257, 1329, 295, 50696], "temperature": 0.0, "avg_logprob": -0.08093397338669021, "compression_ratio": 1.5767195767195767, "no_speech_prob": 0.0009105867356993258}, {"id": 72, "seek": 54356, "start": 550.1999999999999, "end": 560.4399999999999, "text": " numbers and a string. They're kind of in between, and they don't necessarily do either one perfectly", "tokens": [50696, 3547, 293, 257, 6798, 13, 814, 434, 733, 295, 294, 1296, 11, 293, 436, 500, 380, 4725, 360, 2139, 472, 6239, 51208], "temperature": 0.0, "avg_logprob": -0.08093397338669021, "compression_ratio": 1.5767195767195767, "no_speech_prob": 0.0009105867356993258}, {"id": 73, "seek": 54356, "start": 560.4399999999999, "end": 567.7199999999999, "text": " well. And so why do I bring all of that up? Why do I rehearse these well-known issues with Python", "tokens": [51208, 731, 13, 400, 370, 983, 360, 286, 1565, 439, 295, 300, 493, 30, 1545, 360, 286, 14369, 11668, 613, 731, 12, 6861, 2663, 365, 15329, 51572], "temperature": 0.0, "avg_logprob": -0.08093397338669021, "compression_ratio": 1.5767195767195767, "no_speech_prob": 0.0009105867356993258}, {"id": 74, "seek": 56772, "start": 567.8000000000001, "end": 573.88, "text": " 3 bytes? Which, by the way, are being taken care of. Python 2.5 will, for example, reintroduce", "tokens": [50368, 805, 36088, 30, 3013, 11, 538, 264, 636, 11, 366, 885, 2726, 1127, 295, 13, 15329, 568, 13, 20, 486, 11, 337, 1365, 11, 319, 38132, 384, 50672], "temperature": 0.0, "avg_logprob": -0.12296411265497623, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.05325639247894287}, {"id": 75, "seek": 56772, "start": 573.88, "end": 581.32, "text": " percent formatting for byte strings, because now that the experiment is in its fifth version,", "tokens": [50672, 3043, 39366, 337, 40846, 13985, 11, 570, 586, 300, 264, 5120, 307, 294, 1080, 9266, 3037, 11, 51044], "temperature": 0.0, "avg_logprob": -0.12296411265497623, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.05325639247894287}, {"id": 76, "seek": 56772, "start": 581.88, "end": 586.84, "text": " I think it is beginning to become clear that the real problem in Python 2 wasn't that strings were", "tokens": [51072, 286, 519, 309, 307, 2863, 281, 1813, 1850, 300, 264, 957, 1154, 294, 15329, 568, 2067, 380, 300, 13985, 645, 51320], "temperature": 0.0, "avg_logprob": -0.12296411265497623, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.05325639247894287}, {"id": 77, "seek": 56772, "start": 586.84, "end": 592.84, "text": " convenient, and so we ignore Unicode, it's that conversion could happen automatically without", "tokens": [51320, 10851, 11, 293, 370, 321, 11200, 1156, 299, 1429, 11, 309, 311, 300, 14298, 727, 1051, 6772, 1553, 51620], "temperature": 0.0, "avg_logprob": -0.12296411265497623, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.05325639247894287}, {"id": 78, "seek": 59284, "start": 592.84, "end": 601.4, "text": " warning. And so they are beginning to add power back into Python 3 byte strings, but they probably", "tokens": [50364, 9164, 13, 400, 370, 436, 366, 2863, 281, 909, 1347, 646, 666, 15329, 805, 40846, 13985, 11, 457, 436, 1391, 50792], "temperature": 0.0, "avg_logprob": -0.08097214645214296, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0016223153797909617}, {"id": 79, "seek": 59284, "start": 601.4, "end": 607.4, "text": " will always be made of numbers now for backwards compatibility, and we bring all that up because", "tokens": [50792, 486, 1009, 312, 1027, 295, 3547, 586, 337, 12204, 34237, 11, 293, 321, 1565, 439, 300, 493, 570, 51092], "temperature": 0.0, "avg_logprob": -0.08097214645214296, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0016223153797909617}, {"id": 80, "seek": 59284, "start": 607.4, "end": 614.2800000000001, "text": " the byte array that I will now talk about is a mutable version of Python 3's byte string,", "tokens": [51092, 264, 40846, 10225, 300, 286, 486, 586, 751, 466, 307, 257, 5839, 712, 3037, 295, 15329, 805, 311, 40846, 6798, 11, 51436], "temperature": 0.0, "avg_logprob": -0.08097214645214296, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0016223153797909617}, {"id": 81, "seek": 59284, "start": 614.84, "end": 622.36, "text": " a mutable version of Python's most underpowered string type. So we'll just quickly look at", "tokens": [51464, 257, 5839, 712, 3037, 295, 15329, 311, 881, 833, 27178, 6798, 2010, 13, 407, 321, 603, 445, 2661, 574, 412, 51840], "temperature": 0.0, "avg_logprob": -0.08097214645214296, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0016223153797909617}, {"id": 82, "seek": 62236, "start": 622.36, "end": 629.4, "text": " a few possible applications and whether a mutable vector of bytes is able to accomplish things", "tokens": [50364, 257, 1326, 1944, 5821, 293, 1968, 257, 5839, 712, 8062, 295, 36088, 307, 1075, 281, 9021, 721, 50716], "temperature": 0.0, "avg_logprob": -0.07128174204221914, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00014877812645863742}, {"id": 83, "seek": 62236, "start": 629.4, "end": 637.8000000000001, "text": " better or worse than traditional Python. So first, let's be fair to it. What if you actually want", "tokens": [50716, 1101, 420, 5324, 813, 5164, 15329, 13, 407, 700, 11, 718, 311, 312, 3143, 281, 309, 13, 708, 498, 291, 767, 528, 51136], "temperature": 0.0, "avg_logprob": -0.07128174204221914, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00014877812645863742}, {"id": 84, "seek": 62236, "start": 637.8000000000001, "end": 648.6800000000001, "text": " a list of numbers between 0 and 255? That never happens to me. So I invented, in those rare cases", "tokens": [51136, 257, 1329, 295, 3547, 1296, 1958, 293, 3552, 20, 30, 663, 1128, 2314, 281, 385, 13, 407, 286, 14479, 11, 294, 729, 5892, 3331, 51680], "temperature": 0.0, "avg_logprob": -0.07128174204221914, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00014877812645863742}, {"id": 85, "seek": 64868, "start": 648.68, "end": 654.12, "text": " where you actually want to store bytes, if you had one, is the byte array a good choice? So I invented", "tokens": [50364, 689, 291, 767, 528, 281, 3531, 36088, 11, 498, 291, 632, 472, 11, 307, 264, 40846, 10225, 257, 665, 3922, 30, 407, 286, 14479, 50636], "temperature": 0.0, "avg_logprob": -0.09824061162263445, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.012766069732606411}, {"id": 86, "seek": 64868, "start": 654.12, "end": 661.8, "text": " one. I wrote my first Bloom filter as preparation for this talk. A Bloom filter is a way to, let's", "tokens": [50636, 472, 13, 286, 4114, 452, 700, 25927, 6608, 382, 13081, 337, 341, 751, 13, 316, 25927, 6608, 307, 257, 636, 281, 11, 718, 311, 51020], "temperature": 0.0, "avg_logprob": -0.09824061162263445, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.012766069732606411}, {"id": 87, "seek": 64868, "start": 661.8, "end": 667.64, "text": " say, you have a dictionary of words, and before you go look on disk for whether a word is in your", "tokens": [51020, 584, 11, 291, 362, 257, 25890, 295, 2283, 11, 293, 949, 291, 352, 574, 322, 12355, 337, 1968, 257, 1349, 307, 294, 428, 51312], "temperature": 0.0, "avg_logprob": -0.09824061162263445, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.012766069732606411}, {"id": 88, "seek": 64868, "start": 667.64, "end": 674.28, "text": " dictionary, you want a quick way to knock out a lot of words, it's just not being candidates.", "tokens": [51312, 25890, 11, 291, 528, 257, 1702, 636, 281, 6728, 484, 257, 688, 295, 2283, 11, 309, 311, 445, 406, 885, 11255, 13, 51644], "temperature": 0.0, "avg_logprob": -0.09824061162263445, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.012766069732606411}, {"id": 89, "seek": 67428, "start": 675.0, "end": 681.0, "text": " What you can do is set up a big bit field and have a couple of hash functions that you throw the", "tokens": [50400, 708, 291, 393, 360, 307, 992, 493, 257, 955, 857, 2519, 293, 362, 257, 1916, 295, 22019, 6828, 300, 291, 3507, 264, 50700], "temperature": 0.0, "avg_logprob": -0.0638040492409154, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.024383941665291786}, {"id": 90, "seek": 67428, "start": 681.0, "end": 687.8, "text": " word elephant at them, and they identify some bits for you that belong to elephant. You give them", "tokens": [50700, 1349, 19791, 412, 552, 11, 293, 436, 5876, 512, 9239, 337, 291, 300, 5784, 281, 19791, 13, 509, 976, 552, 51040], "temperature": 0.0, "avg_logprob": -0.0638040492409154, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.024383941665291786}, {"id": 91, "seek": 67428, "start": 687.8, "end": 693.88, "text": " the word Python. It's a different set of bits. The idea is that if you load up your dictionary", "tokens": [51040, 264, 1349, 15329, 13, 467, 311, 257, 819, 992, 295, 9239, 13, 440, 1558, 307, 300, 498, 291, 3677, 493, 428, 25890, 51344], "temperature": 0.0, "avg_logprob": -0.0638040492409154, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.024383941665291786}, {"id": 92, "seek": 67428, "start": 693.88, "end": 699.3199999999999, "text": " by setting all of the bits for elephant and all of the bits for Python, then when you see those", "tokens": [51344, 538, 3287, 439, 295, 264, 9239, 337, 19791, 293, 439, 295, 264, 9239, 337, 15329, 11, 550, 562, 291, 536, 729, 51616], "temperature": 0.0, "avg_logprob": -0.0638040492409154, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.024383941665291786}, {"id": 93, "seek": 69932, "start": 699.32, "end": 704.2800000000001, "text": " words later in a document, you can just check whether their bits are set to know if there's", "tokens": [50364, 2283, 1780, 294, 257, 4166, 11, 291, 393, 445, 1520, 1968, 641, 9239, 366, 992, 281, 458, 498, 456, 311, 50612], "temperature": 0.0, "avg_logprob": -0.08176939828055245, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0033720049541443586}, {"id": 94, "seek": 69932, "start": 704.2800000000001, "end": 711.1600000000001, "text": " any possibility that elephant is in your dictionary, because many words will have sets of bits that", "tokens": [50612, 604, 7959, 300, 19791, 307, 294, 428, 25890, 11, 570, 867, 2283, 486, 362, 6352, 295, 9239, 300, 50956], "temperature": 0.0, "avg_logprob": -0.08176939828055245, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0033720049541443586}, {"id": 95, "seek": 69932, "start": 711.1600000000001, "end": 716.12, "text": " aren't set at all, or several of which aren't set, and that you know could not have been in the", "tokens": [50956, 3212, 380, 992, 412, 439, 11, 420, 2940, 295, 597, 3212, 380, 992, 11, 293, 300, 291, 458, 727, 406, 362, 668, 294, 264, 51204], "temperature": 0.0, "avg_logprob": -0.08176939828055245, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0033720049541443586}, {"id": 96, "seek": 69932, "start": 716.12, "end": 721.96, "text": " dictionary you loaded. This is a nice example because it lets us do a pure math operation,", "tokens": [51204, 25890, 291, 13210, 13, 639, 307, 257, 1481, 1365, 570, 309, 6653, 505, 360, 257, 6075, 5221, 6916, 11, 51496], "temperature": 0.0, "avg_logprob": -0.08176939828055245, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0033720049541443586}, {"id": 97, "seek": 72196, "start": 722.0400000000001, "end": 735.4000000000001, "text": " in this case the in place oring of a byte in this array A with itself and with a bit that we create", "tokens": [50368, 294, 341, 1389, 264, 294, 1081, 420, 278, 295, 257, 40846, 294, 341, 10225, 316, 365, 2564, 293, 365, 257, 857, 300, 321, 1884, 51036], "temperature": 0.0, "avg_logprob": -0.1477142886111611, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.005991678684949875}, {"id": 98, "seek": 72196, "start": 735.4000000000001, "end": 742.2800000000001, "text": " over here and set, and we can run through, set this up, and then when we want to test a word,", "tokens": [51036, 670, 510, 293, 992, 11, 293, 321, 393, 1190, 807, 11, 992, 341, 493, 11, 293, 550, 562, 321, 528, 281, 1500, 257, 1349, 11, 51380], "temperature": 0.0, "avg_logprob": -0.1477142886111611, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.005991678684949875}, {"id": 99, "seek": 72196, "start": 742.2800000000001, "end": 748.6800000000001, "text": " go back in and use the reading version of square brackets, not in an assignment statement, but", "tokens": [51380, 352, 646, 294, 293, 764, 264, 3760, 3037, 295, 3732, 26179, 11, 406, 294, 364, 15187, 5629, 11, 457, 51700], "temperature": 0.0, "avg_logprob": -0.1477142886111611, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.005991678684949875}, {"id": 100, "seek": 74868, "start": 748.68, "end": 755.0, "text": " in an expression to read back the value of a bit. A nice exercise to see how does this thing", "tokens": [50364, 294, 364, 6114, 281, 1401, 646, 264, 2158, 295, 257, 857, 13, 316, 1481, 5380, 281, 536, 577, 775, 341, 551, 50680], "temperature": 0.0, "avg_logprob": -0.10452821980351987, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00228404370136559}, {"id": 101, "seek": 74868, "start": 755.0, "end": 762.3599999999999, "text": " perform storing and receiving a few tens of thousands of bytes. And by the way, the name A", "tokens": [50680, 2042, 26085, 293, 10040, 257, 1326, 10688, 295, 5383, 295, 36088, 13, 400, 538, 264, 636, 11, 264, 1315, 316, 51048], "temperature": 0.0, "avg_logprob": -0.10452821980351987, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00228404370136559}, {"id": 102, "seek": 74868, "start": 762.3599999999999, "end": 769.16, "text": " in the previous code can be either an old fashioned array dot array that's been around in Python", "tokens": [51048, 294, 264, 3894, 3089, 393, 312, 2139, 364, 1331, 40646, 10225, 5893, 10225, 300, 311, 668, 926, 294, 15329, 51388], "temperature": 0.0, "avg_logprob": -0.10452821980351987, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00228404370136559}, {"id": 103, "seek": 74868, "start": 769.16, "end": 775.0799999999999, "text": " forever, or a new fangled byte array. To this extent, they both provide the same interface. Each", "tokens": [51388, 5680, 11, 420, 257, 777, 283, 39101, 40846, 10225, 13, 1407, 341, 8396, 11, 436, 1293, 2893, 264, 912, 9226, 13, 6947, 51684], "temperature": 0.0, "avg_logprob": -0.10452821980351987, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00228404370136559}, {"id": 104, "seek": 77508, "start": 775.08, "end": 783.8000000000001, "text": " slot you can address gets you or lets you store a byte. And so with this application, I ran it", "tokens": [50364, 14747, 291, 393, 2985, 2170, 291, 420, 6653, 291, 3531, 257, 40846, 13, 400, 370, 365, 341, 3861, 11, 286, 5872, 309, 50800], "temperature": 0.0, "avg_logprob": -0.12060400155874398, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0010000631446018815}, {"id": 105, "seek": 77508, "start": 783.8000000000001, "end": 789.96, "text": " both ways, and byte array scored its first victory, because it is so more specific than", "tokens": [50800, 1293, 2098, 11, 293, 40846, 10225, 18139, 1080, 700, 9812, 11, 570, 309, 307, 370, 544, 2685, 813, 51108], "temperature": 0.0, "avg_logprob": -0.12060400155874398, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0010000631446018815}, {"id": 106, "seek": 77508, "start": 789.96, "end": 794.84, "text": " array dot array, which can also hold, I believe, floats and integers and other things like that,", "tokens": [51108, 10225, 5893, 10225, 11, 597, 393, 611, 1797, 11, 286, 1697, 11, 37878, 293, 41674, 293, 661, 721, 411, 300, 11, 51352], "temperature": 0.0, "avg_logprob": -0.12060400155874398, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0010000631446018815}, {"id": 107, "seek": 77508, "start": 794.84, "end": 799.8000000000001, "text": " because the byte array's code path has almost no decisions, it's always going to store bytes,", "tokens": [51352, 570, 264, 40846, 10225, 311, 3089, 3100, 575, 1920, 572, 5327, 11, 309, 311, 1009, 516, 281, 3531, 36088, 11, 51600], "temperature": 0.0, "avg_logprob": -0.12060400155874398, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0010000631446018815}, {"id": 108, "seek": 79980, "start": 800.3599999999999, "end": 806.76, "text": " it is more than 7% faster for running that bloom array code, bloom filter code that I just showed", "tokens": [50392, 309, 307, 544, 813, 1614, 4, 4663, 337, 2614, 300, 26899, 10225, 3089, 11, 26899, 6608, 3089, 300, 286, 445, 4712, 50712], "temperature": 0.0, "avg_logprob": -0.14176844466816296, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0002611283853184432}, {"id": 109, "seek": 79980, "start": 806.76, "end": 813.88, "text": " you, than the old general purpose array, array object. So you might think that this is immediately", "tokens": [50712, 291, 11, 813, 264, 1331, 2674, 4334, 10225, 11, 10225, 2657, 13, 407, 291, 1062, 519, 300, 341, 307, 4258, 51068], "temperature": 0.0, "avg_logprob": -0.14176844466816296, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0002611283853184432}, {"id": 110, "seek": 79980, "start": 813.88, "end": 821.24, "text": " an obviously a go to data structure for lists of eight bit numbers. I tried it another way.", "tokens": [51068, 364, 2745, 257, 352, 281, 1412, 3877, 337, 14511, 295, 3180, 857, 3547, 13, 286, 3031, 309, 1071, 636, 13, 51436], "temperature": 0.0, "avg_logprob": -0.14176844466816296, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0002611283853184432}, {"id": 111, "seek": 79980, "start": 822.1999999999999, "end": 827.0799999999999, "text": " I want to know what's even faster than a byte array? A list of integers.", "tokens": [51484, 286, 528, 281, 458, 437, 311, 754, 4663, 813, 257, 40846, 10225, 30, 316, 1329, 295, 41674, 13, 51728], "temperature": 0.0, "avg_logprob": -0.14176844466816296, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0002611283853184432}, {"id": 112, "seek": 82980, "start": 830.68, "end": 838.12, "text": " 1% faster. If you just say, hey, Python, here's a one element list with a zero in it,", "tokens": [50408, 502, 4, 4663, 13, 759, 291, 445, 584, 11, 4177, 11, 15329, 11, 510, 311, 257, 472, 4478, 1329, 365, 257, 4018, 294, 309, 11, 50780], "temperature": 0.0, "avg_logprob": -0.12786389296909548, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.00016860882169567049}, {"id": 113, "seek": 82980, "start": 838.12, "end": 844.76, "text": " make me a lot of these. A plain, I'm sorry, 2%, a plain list of int objects that happen", "tokens": [50780, 652, 385, 257, 688, 295, 613, 13, 316, 11121, 11, 286, 478, 2597, 11, 568, 8923, 257, 11121, 1329, 295, 560, 6565, 300, 1051, 51112], "temperature": 0.0, "avg_logprob": -0.12786389296909548, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.00016860882169567049}, {"id": 114, "seek": 82980, "start": 844.76, "end": 853.0, "text": " to be in the range 0 to 255 will run even faster than the byte array. Why? Well, it's because,", "tokens": [51112, 281, 312, 294, 264, 3613, 1958, 281, 3552, 20, 486, 1190, 754, 4663, 813, 264, 40846, 10225, 13, 1545, 30, 1042, 11, 309, 311, 570, 11, 51524], "temperature": 0.0, "avg_logprob": -0.12786389296909548, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.00016860882169567049}, {"id": 115, "seek": 82980, "start": 853.0, "end": 858.5999999999999, "text": " think of what the byte array is doing. It's storing real bytes, low level in your computer,", "tokens": [51524, 519, 295, 437, 264, 40846, 10225, 307, 884, 13, 467, 311, 26085, 957, 36088, 11, 2295, 1496, 294, 428, 3820, 11, 51804], "temperature": 0.0, "avg_logprob": -0.12786389296909548, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.00016860882169567049}, {"id": 116, "seek": 85860, "start": 858.6800000000001, "end": 867.72, "text": " that must each be translated into an int object address when the value is being handed out into", "tokens": [50368, 300, 1633, 1184, 312, 16805, 666, 364, 560, 2657, 2985, 562, 264, 2158, 307, 885, 16013, 484, 666, 50820], "temperature": 0.0, "avg_logprob": -0.09161065281301305, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.000552412704564631}, {"id": 117, "seek": 85860, "start": 867.72, "end": 876.9200000000001, "text": " your Python code, and then when an int object is handed back, it has to be changed back into", "tokens": [50820, 428, 15329, 3089, 11, 293, 550, 562, 364, 560, 2657, 307, 16013, 646, 11, 309, 575, 281, 312, 3105, 646, 666, 51280], "temperature": 0.0, "avg_logprob": -0.09161065281301305, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.000552412704564631}, {"id": 118, "seek": 85860, "start": 876.9200000000001, "end": 884.28, "text": " a simple byte in order to be stored. The list skips all that, it just stores the addresses you", "tokens": [51280, 257, 2199, 40846, 294, 1668, 281, 312, 12187, 13, 440, 1329, 1110, 2600, 439, 300, 11, 309, 445, 9512, 264, 16862, 291, 51648], "temperature": 0.0, "avg_logprob": -0.09161065281301305, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.000552412704564631}, {"id": 119, "seek": 88428, "start": 884.28, "end": 893.64, "text": " give it. The byte array, by the way, doesn't have to pay any penalty to allocate or create any of", "tokens": [50364, 976, 309, 13, 440, 40846, 10225, 11, 538, 264, 636, 11, 1177, 380, 362, 281, 1689, 604, 16263, 281, 35713, 420, 1884, 604, 295, 50832], "temperature": 0.0, "avg_logprob": -0.124055415391922, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0026699542067945004}, {"id": 120, "seek": 88428, "start": 893.64, "end": 899.3199999999999, "text": " those int objects, because it just so happens that the Python, the CPython interpreter, when it", "tokens": [50832, 729, 560, 6565, 11, 570, 309, 445, 370, 2314, 300, 264, 15329, 11, 264, 22431, 88, 11943, 34132, 11, 562, 309, 51116], "temperature": 0.0, "avg_logprob": -0.124055415391922, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0026699542067945004}, {"id": 121, "seek": 88428, "start": 899.3199999999999, "end": 906.12, "text": " starts up, preallocates all of the integer objects negative 5 through 256 so that they never have", "tokens": [51116, 3719, 493, 11, 659, 336, 905, 1024, 439, 295, 264, 24922, 6565, 3671, 1025, 807, 38882, 370, 300, 436, 1128, 362, 51456], "temperature": 0.0, "avg_logprob": -0.124055415391922, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0026699542067945004}, {"id": 122, "seek": 88428, "start": 906.12, "end": 911.3199999999999, "text": " to be created or destroyed over the lifetime of the interpreter. So when you ask the byte array,", "tokens": [51456, 281, 312, 2942, 420, 8937, 670, 264, 11364, 295, 264, 34132, 13, 407, 562, 291, 1029, 264, 40846, 10225, 11, 51716], "temperature": 0.0, "avg_logprob": -0.124055415391922, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0026699542067945004}, {"id": 123, "seek": 91132, "start": 911.32, "end": 917.1600000000001, "text": " what's it positioned 100, and it wants to say 70, it can just grab the existing 70 integer object", "tokens": [50364, 437, 311, 309, 24889, 2319, 11, 293, 309, 2738, 281, 584, 5285, 11, 309, 393, 445, 4444, 264, 6741, 5285, 24922, 2657, 50656], "temperature": 0.0, "avg_logprob": -0.11141522725423177, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0010809516534209251}, {"id": 124, "seek": 91132, "start": 917.1600000000001, "end": 922.12, "text": " that always exists in memory and hand it back, so it's not having to go do a malloc or anything,", "tokens": [50656, 300, 1009, 8198, 294, 4675, 293, 1011, 309, 646, 11, 370, 309, 311, 406, 1419, 281, 352, 360, 257, 16026, 905, 420, 1340, 11, 50904], "temperature": 0.0, "avg_logprob": -0.11141522725423177, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0010809516534209251}, {"id": 125, "seek": 91132, "start": 922.84, "end": 927.96, "text": " it's not having to allocate new memory, but still it's having to do that step of translation,", "tokens": [50940, 309, 311, 406, 1419, 281, 35713, 777, 4675, 11, 457, 920, 309, 311, 1419, 281, 360, 300, 1823, 295, 12853, 11, 51196], "temperature": 0.0, "avg_logprob": -0.11141522725423177, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0010809516534209251}, {"id": 126, "seek": 91132, "start": 927.96, "end": 934.2, "text": " and it is honestly just simpler to store the pointer, to store the address of the 70 object.", "tokens": [51196, 293, 309, 307, 6095, 445, 18587, 281, 3531, 264, 23918, 11, 281, 3531, 264, 2985, 295, 264, 5285, 2657, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11141522725423177, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0010809516534209251}, {"id": 127, "seek": 91132, "start": 934.2, "end": 940.36, "text": " That's why the list object runs faster, and so this is interesting. We have this new special case", "tokens": [51508, 663, 311, 983, 264, 1329, 2657, 6676, 4663, 11, 293, 370, 341, 307, 1880, 13, 492, 362, 341, 777, 2121, 1389, 51816], "temperature": 0.0, "avg_logprob": -0.11141522725423177, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0010809516534209251}, {"id": 128, "seek": 94036, "start": 940.36, "end": 948.6800000000001, "text": " container that's slightly slower than just using Python's well-honed default data types. A plain", "tokens": [50364, 10129, 300, 311, 4748, 14009, 813, 445, 1228, 15329, 311, 731, 12, 71, 19009, 7576, 1412, 3467, 13, 316, 11121, 50780], "temperature": 0.0, "avg_logprob": -0.12253626187642415, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00043048596126027405}, {"id": 129, "seek": 94036, "start": 948.6800000000001, "end": 955.16, "text": " old list is a faster bit vector than the fancy new byte array, except if you're using PyPy,", "tokens": [50780, 1331, 1329, 307, 257, 4663, 857, 8062, 813, 264, 10247, 777, 40846, 10225, 11, 3993, 498, 291, 434, 1228, 9953, 47, 88, 11, 51104], "temperature": 0.0, "avg_logprob": -0.12253626187642415, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00043048596126027405}, {"id": 130, "seek": 94036, "start": 955.8000000000001, "end": 960.52, "text": " where they're all the same because it becomes the same C code under the hood of a machine code,", "tokens": [51136, 689, 436, 434, 439, 264, 912, 570, 309, 3643, 264, 912, 383, 3089, 833, 264, 13376, 295, 257, 3479, 3089, 11, 51372], "temperature": 0.0, "avg_logprob": -0.12253626187642415, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00043048596126027405}, {"id": 131, "seek": 94036, "start": 960.52, "end": 966.84, "text": " I should say, and all three run much faster as well as being exactly equivalent. I tried it out,", "tokens": [51372, 286, 820, 584, 11, 293, 439, 1045, 1190, 709, 4663, 382, 731, 382, 885, 2293, 10344, 13, 286, 3031, 309, 484, 11, 51688], "temperature": 0.0, "avg_logprob": -0.12253626187642415, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00043048596126027405}, {"id": 132, "seek": 96684, "start": 966.84, "end": 970.6, "text": " and PyPy in each case figured out I was trying to do exactly the same thing.", "tokens": [50364, 293, 9953, 47, 88, 294, 1184, 1389, 8932, 484, 286, 390, 1382, 281, 360, 2293, 264, 912, 551, 13, 50552], "temperature": 0.0, "avg_logprob": -0.10675462670282486, "compression_ratio": 1.5358490566037737, "no_speech_prob": 0.0010984266409650445}, {"id": 133, "seek": 96684, "start": 972.12, "end": 978.44, "text": " Well, I guess they're done already, I'll just keep going. So for this first experiment,", "tokens": [50628, 1042, 11, 286, 2041, 436, 434, 1096, 1217, 11, 286, 603, 445, 1066, 516, 13, 407, 337, 341, 700, 5120, 11, 50944], "temperature": 0.0, "avg_logprob": -0.10675462670282486, "compression_ratio": 1.5358490566037737, "no_speech_prob": 0.0010984266409650445}, {"id": 134, "seek": 96684, "start": 978.44, "end": 985.4, "text": " what if I need a list of integers between 0 and 255? My verdict is that the bit vector", "tokens": [50944, 437, 498, 286, 643, 257, 1329, 295, 41674, 1296, 1958, 293, 3552, 20, 30, 1222, 33957, 307, 300, 264, 857, 8062, 51292], "temperature": 0.0, "avg_logprob": -0.10675462670282486, "compression_ratio": 1.5358490566037737, "no_speech_prob": 0.0010984266409650445}, {"id": 135, "seek": 96684, "start": 985.4, "end": 991.5600000000001, "text": " is space efficient. You don't choose it because it's going to be obviously faster,", "tokens": [51292, 307, 1901, 7148, 13, 509, 500, 380, 2826, 309, 570, 309, 311, 516, 281, 312, 2745, 4663, 11, 51600], "temperature": 0.0, "avg_logprob": -0.10675462670282486, "compression_ratio": 1.5358490566037737, "no_speech_prob": 0.0010984266409650445}, {"id": 136, "seek": 96684, "start": 991.5600000000001, "end": 995.1600000000001, "text": " it's not, or obviously simpler, it's doing a little more under the hood,", "tokens": [51600, 309, 311, 406, 11, 420, 2745, 18587, 11, 309, 311, 884, 257, 707, 544, 833, 264, 13376, 11, 51780], "temperature": 0.0, "avg_logprob": -0.10675462670282486, "compression_ratio": 1.5358490566037737, "no_speech_prob": 0.0010984266409650445}, {"id": 137, "seek": 99516, "start": 995.4, "end": 1005.0, "text": " but the good old-fashioned list of integers has to store in each slot the address of the real", "tokens": [50376, 457, 264, 665, 1331, 12, 37998, 1329, 295, 41674, 575, 281, 3531, 294, 1184, 14747, 264, 2985, 295, 264, 957, 50856], "temperature": 0.0, "avg_logprob": -0.17139368057250975, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.251708302646875e-05}, {"id": 138, "seek": 99516, "start": 1005.0, "end": 1013.3199999999999, "text": " integer object 70. The bit vector just stores the seven bits, the eight bits that represent 70,", "tokens": [50856, 24922, 2657, 5285, 13, 440, 857, 8062, 445, 9512, 264, 3407, 9239, 11, 264, 3180, 9239, 300, 2906, 5285, 11, 51272], "temperature": 0.0, "avg_logprob": -0.17139368057250975, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.251708302646875e-05}, {"id": 139, "seek": 99516, "start": 1013.3199999999999, "end": 1018.6, "text": " and therefore uses on a 64-bit machine, which is what I'll presume for all of these calculations,", "tokens": [51272, 293, 4412, 4960, 322, 257, 12145, 12, 5260, 3479, 11, 597, 307, 437, 286, 603, 43283, 337, 439, 295, 613, 20448, 11, 51536], "temperature": 0.0, "avg_logprob": -0.17139368057250975, "compression_ratio": 1.5185185185185186, "no_speech_prob": 7.251708302646875e-05}, {"id": 140, "seek": 101860, "start": 1018.6800000000001, "end": 1025.16, "text": " eight times less space. And the point of a bloom filter is to save space in RAM.", "tokens": [50368, 3180, 1413, 1570, 1901, 13, 400, 264, 935, 295, 257, 26899, 6608, 307, 281, 3155, 1901, 294, 14561, 13, 50692], "temperature": 0.0, "avg_logprob": -0.1057750245799189, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.006689331028610468}, {"id": 141, "seek": 101860, "start": 1025.72, "end": 1032.92, "text": " That for bit operations is why you go to the byte array, because it stores bytes as honest to", "tokens": [50720, 663, 337, 857, 7705, 307, 983, 291, 352, 281, 264, 40846, 10225, 11, 570, 309, 9512, 36088, 382, 3245, 281, 51080], "temperature": 0.0, "avg_logprob": -0.1057750245799189, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.006689331028610468}, {"id": 142, "seek": 101860, "start": 1032.92, "end": 1041.8, "text": " goodness bytes with no extra overhead per byte. It's a great way to get numbers between 0 and 255", "tokens": [51080, 8387, 36088, 365, 572, 2857, 19922, 680, 40846, 13, 467, 311, 257, 869, 636, 281, 483, 3547, 1296, 1958, 293, 3552, 20, 51524], "temperature": 0.0, "avg_logprob": -0.1057750245799189, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.006689331028610468}, {"id": 143, "seek": 104180, "start": 1041.8799999999999, "end": 1048.68, "text": " packed in the minimum space possible. So it is a win, but not in the way you might initially", "tokens": [50368, 13265, 294, 264, 7285, 1901, 1944, 13, 407, 309, 307, 257, 1942, 11, 457, 406, 294, 264, 636, 291, 1062, 9105, 50708], "temperature": 0.0, "avg_logprob": -0.10429454544215526, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0010646847076714039}, {"id": 144, "seek": 104180, "start": 1048.68, "end": 1056.2, "text": " expect. All right. Second, it is a reusable buffer. When you read a string in, you can't do", "tokens": [50708, 2066, 13, 1057, 558, 13, 5736, 11, 309, 307, 257, 41807, 21762, 13, 1133, 291, 1401, 257, 6798, 294, 11, 291, 393, 380, 360, 51084], "temperature": 0.0, "avg_logprob": -0.10429454544215526, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0010646847076714039}, {"id": 145, "seek": 104180, "start": 1056.2, "end": 1062.2, "text": " anything to it because it's immutable, but a byte array can be reused. For a quick benchmark,", "tokens": [51084, 1340, 281, 309, 570, 309, 311, 3397, 32148, 11, 457, 257, 40846, 10225, 393, 312, 319, 4717, 13, 1171, 257, 1702, 18927, 11, 51384], "temperature": 0.0, "avg_logprob": -0.10429454544215526, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0010646847076714039}, {"id": 146, "seek": 104180, "start": 1062.2, "end": 1069.6399999999999, "text": " I got a made a random file of a gigabyte of random data, read it with cat, so I was able to", "tokens": [51384, 286, 658, 257, 1027, 257, 4974, 3991, 295, 257, 8741, 34529, 295, 4974, 1412, 11, 1401, 309, 365, 3857, 11, 370, 286, 390, 1075, 281, 51756], "temperature": 0.0, "avg_logprob": -0.10429454544215526, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0010646847076714039}, {"id": 147, "seek": 106964, "start": 1069.72, "end": 1076.1200000000001, "text": " estimate that probably Python won't be able to do better than 0.11 seconds on my machine", "tokens": [50368, 12539, 300, 1391, 15329, 1582, 380, 312, 1075, 281, 360, 1101, 813, 1958, 13, 5348, 3949, 322, 452, 3479, 50688], "temperature": 0.0, "avg_logprob": -0.1066744327545166, "compression_ratio": 1.4093264248704662, "no_speech_prob": 0.0005699348403140903}, {"id": 148, "seek": 106964, "start": 1076.1200000000001, "end": 1081.48, "text": " reading in the same data. I tried it with DD. Anyone here ever used DD to rewrite data?", "tokens": [50688, 3760, 294, 264, 912, 1412, 13, 286, 3031, 309, 365, 30778, 13, 14643, 510, 1562, 1143, 30778, 281, 28132, 1412, 30, 50956], "temperature": 0.0, "avg_logprob": -0.1066744327545166, "compression_ratio": 1.4093264248704662, "no_speech_prob": 0.0005699348403140903}, {"id": 149, "seek": 106964, "start": 1083.0, "end": 1092.3600000000001, "text": " It took six times longer. Anyone know why? I S traced them, and it's because of the block size.", "tokens": [51032, 467, 1890, 2309, 1413, 2854, 13, 14643, 458, 983, 30, 286, 318, 38141, 552, 11, 293, 309, 311, 570, 295, 264, 3461, 2744, 13, 51500], "temperature": 0.0, "avg_logprob": -0.1066744327545166, "compression_ratio": 1.4093264248704662, "no_speech_prob": 0.0005699348403140903}, {"id": 150, "seek": 109236, "start": 1092.36, "end": 1101.08, "text": " DD alas is an old and crafty and low-level tool. While cat will zoom along with 128k blocks,", "tokens": [50364, 30778, 419, 296, 307, 364, 1331, 293, 8448, 88, 293, 2295, 12, 12418, 2290, 13, 3987, 3857, 486, 8863, 2051, 365, 29810, 74, 8474, 11, 50800], "temperature": 0.0, "avg_logprob": -0.1276558836301168, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.001699731219559908}, {"id": 151, "seek": 109236, "start": 1101.08, "end": 1107.3999999999999, "text": " so it asks the OS for some data and gets 128,000 bytes in a single shot,", "tokens": [50800, 370, 309, 8962, 264, 12731, 337, 512, 1412, 293, 2170, 29810, 11, 1360, 36088, 294, 257, 2167, 3347, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1276558836301168, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.001699731219559908}, {"id": 152, "seek": 109236, "start": 1108.4399999999998, "end": 1114.9199999999998, "text": " DD, because it's an old level for writing to ancient 70s block devices, reads and writes", "tokens": [51168, 30778, 11, 570, 309, 311, 364, 1331, 1496, 337, 3579, 281, 7832, 5285, 82, 3461, 5759, 11, 15700, 293, 13657, 51492], "temperature": 0.0, "avg_logprob": -0.1276558836301168, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.001699731219559908}, {"id": 153, "seek": 109236, "start": 1114.9199999999998, "end": 1121.3999999999999, "text": " 512 bytes by default. Giving DD the same block size does make it perform the same. You can give", "tokens": [51492, 1025, 4762, 36088, 538, 7576, 13, 28983, 30778, 264, 912, 3461, 2744, 775, 652, 309, 2042, 264, 912, 13, 509, 393, 976, 51816], "temperature": 0.0, "avg_logprob": -0.1276558836301168, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.001699731219559908}, {"id": 154, "seek": 112140, "start": 1121.48, "end": 1128.1200000000001, "text": " it a block size of 128k and get 0.11 seconds just right there with cat, but interestingly enough,", "tokens": [50368, 309, 257, 3461, 2744, 295, 29810, 74, 293, 483, 1958, 13, 5348, 3949, 445, 558, 456, 365, 3857, 11, 457, 25873, 1547, 11, 50700], "temperature": 0.0, "avg_logprob": -0.10797559738159179, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.00013131755986250937}, {"id": 155, "seek": 112140, "start": 1128.1200000000001, "end": 1132.2, "text": " it's not the default, despite the fact that I seem to know all these people that think DD", "tokens": [50700, 309, 311, 406, 264, 7576, 11, 7228, 264, 1186, 300, 286, 1643, 281, 458, 439, 613, 561, 300, 519, 30778, 50904], "temperature": 0.0, "avg_logprob": -0.10797559738159179, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.00013131755986250937}, {"id": 156, "seek": 112140, "start": 1132.2, "end": 1138.8400000000001, "text": " would be faster somehow by default. It's not. It's the same reads and writes. And cat is the", "tokens": [50904, 576, 312, 4663, 6063, 538, 7576, 13, 467, 311, 406, 13, 467, 311, 264, 912, 15700, 293, 13657, 13, 400, 3857, 307, 264, 51236], "temperature": 0.0, "avg_logprob": -0.10797559738159179, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.00013131755986250937}, {"id": 157, "seek": 112140, "start": 1138.8400000000001, "end": 1149.3200000000002, "text": " Unix default. DD came from IBM. But this teaches us a first lesson that we will now apply. As we", "tokens": [51236, 1156, 970, 7576, 13, 30778, 1361, 490, 23487, 13, 583, 341, 16876, 505, 257, 700, 6898, 300, 321, 486, 586, 3079, 13, 1018, 321, 51760], "temperature": 0.0, "avg_logprob": -0.10797559738159179, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.00013131755986250937}, {"id": 158, "seek": 114932, "start": 1149.32, "end": 1155.24, "text": " look at Python IO, we need to keep block size in mind. The size of the chunks you read determines", "tokens": [50364, 574, 412, 15329, 39839, 11, 321, 643, 281, 1066, 3461, 2744, 294, 1575, 13, 440, 2744, 295, 264, 24004, 291, 1401, 24799, 50660], "temperature": 0.0, "avg_logprob": -0.08270926116615214, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0018377875676378608}, {"id": 159, "seek": 114932, "start": 1155.24, "end": 1160.2, "text": " how many chunks you need to read, determines how often you need to converse with the operating", "tokens": [50660, 577, 867, 24004, 291, 643, 281, 1401, 11, 24799, 577, 2049, 291, 643, 281, 416, 4308, 365, 264, 7447, 50908], "temperature": 0.0, "avg_logprob": -0.08270926116615214, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0018377875676378608}, {"id": 160, "seek": 114932, "start": 1160.2, "end": 1166.52, "text": " system, which is often the expense that can come to dominate your runtime. Here's how we do it in", "tokens": [50908, 1185, 11, 597, 307, 2049, 264, 18406, 300, 393, 808, 281, 28246, 428, 34474, 13, 1692, 311, 577, 321, 360, 309, 294, 51224], "temperature": 0.0, "avg_logprob": -0.08270926116615214, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0018377875676378608}, {"id": 161, "seek": 114932, "start": 1166.52, "end": 1173.3999999999999, "text": " normal Python. Read a block and write the data back out. Note this is perfectly safe if an", "tokens": [51224, 2710, 15329, 13, 17604, 257, 3461, 293, 2464, 264, 1412, 646, 484, 13, 11633, 341, 307, 6239, 3273, 498, 364, 51568], "temperature": 0.0, "avg_logprob": -0.08270926116615214, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0018377875676378608}, {"id": 162, "seek": 117340, "start": 1173.4, "end": 1180.1200000000001, "text": " undersized block comes in because the string that I'm here calling data that comes back is labeled", "tokens": [50364, 16692, 1602, 3461, 1487, 294, 570, 264, 6798, 300, 286, 478, 510, 5141, 1412, 300, 1487, 646, 307, 21335, 50700], "temperature": 0.0, "avg_logprob": -0.09361265746640487, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.001622585579752922}, {"id": 163, "seek": 117340, "start": 1180.1200000000001, "end": 1188.44, "text": " with its length. It could be 5 bytes, it could be 128k. Python strings know their length and so", "tokens": [50700, 365, 1080, 4641, 13, 467, 727, 312, 1025, 36088, 11, 309, 727, 312, 29810, 74, 13, 15329, 13985, 458, 641, 4641, 293, 370, 51116], "temperature": 0.0, "avg_logprob": -0.09361265746640487, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.001622585579752922}, {"id": 164, "seek": 117340, "start": 1188.44, "end": 1195.96, "text": " right can just ask the length and send that many bytes of data back out. My first attempt at doing", "tokens": [51116, 558, 393, 445, 1029, 264, 4641, 293, 2845, 300, 867, 36088, 295, 1412, 646, 484, 13, 1222, 700, 5217, 412, 884, 51492], "temperature": 0.0, "avg_logprob": -0.09361265746640487, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.001622585579752922}, {"id": 165, "seek": 119596, "start": 1196.04, "end": 1204.6000000000001, "text": " a read into seemed to work at first until I noticed that every file I wrote, however big it was", "tokens": [50368, 257, 1401, 666, 6576, 281, 589, 412, 700, 1826, 286, 5694, 300, 633, 3991, 286, 4114, 11, 4461, 955, 309, 390, 50796], "temperature": 0.0, "avg_logprob": -0.10612474728937019, "compression_ratio": 1.425, "no_speech_prob": 0.014272913336753845}, {"id": 166, "seek": 119596, "start": 1205.32, "end": 1211.32, "text": " originally, the copy that I made with this routine would always be a multiple of my block size.", "tokens": [50832, 7993, 11, 264, 5055, 300, 286, 1027, 365, 341, 9927, 576, 1009, 312, 257, 3866, 295, 452, 3461, 2744, 13, 51132], "temperature": 0.0, "avg_logprob": -0.10612474728937019, "compression_ratio": 1.425, "no_speech_prob": 0.014272913336753845}, {"id": 167, "seek": 119596, "start": 1212.28, "end": 1219.64, "text": " Why is that? Because when I create one of these new byte arrays of, let's say 128k, what this", "tokens": [51180, 1545, 307, 300, 30, 1436, 562, 286, 1884, 472, 295, 613, 777, 40846, 41011, 295, 11, 718, 311, 584, 29810, 74, 11, 437, 341, 51548], "temperature": 0.0, "avg_logprob": -0.10612474728937019, "compression_ratio": 1.425, "no_speech_prob": 0.014272913336753845}, {"id": 168, "seek": 121964, "start": 1219.64, "end": 1226.2800000000002, "text": " loop was doing is reading some number of bytes, who knows how many come in in the next block of", "tokens": [50364, 6367, 390, 884, 307, 3760, 512, 1230, 295, 36088, 11, 567, 3255, 577, 867, 808, 294, 294, 264, 958, 3461, 295, 50696], "temperature": 0.0, "avg_logprob": -0.0764213353395462, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0011692739790305495}, {"id": 169, "seek": 121964, "start": 1226.2800000000002, "end": 1234.2, "text": " the file if I'm near the end, reads some number of bytes into my byte array, and then writes out", "tokens": [50696, 264, 3991, 498, 286, 478, 2651, 264, 917, 11, 15700, 512, 1230, 295, 36088, 666, 452, 40846, 10225, 11, 293, 550, 13657, 484, 51092], "temperature": 0.0, "avg_logprob": -0.0764213353395462, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0011692739790305495}, {"id": 170, "seek": 121964, "start": 1234.2, "end": 1239.5600000000002, "text": " the whole byte array, including all the junk at the end that's maybe not part of the current block", "tokens": [51092, 264, 1379, 40846, 10225, 11, 3009, 439, 264, 19109, 412, 264, 917, 300, 311, 1310, 406, 644, 295, 264, 2190, 3461, 51360], "temperature": 0.0, "avg_logprob": -0.0764213353395462, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0011692739790305495}, {"id": 171, "seek": 121964, "start": 1239.5600000000002, "end": 1248.5200000000002, "text": " of the file. I was doing my right of the whole 128k block without consulting the length to see", "tokens": [51360, 295, 264, 3991, 13, 286, 390, 884, 452, 558, 295, 264, 1379, 29810, 74, 3461, 1553, 23682, 264, 4641, 281, 536, 51808], "temperature": 0.0, "avg_logprob": -0.0764213353395462, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0011692739790305495}, {"id": 172, "seek": 124852, "start": 1248.52, "end": 1259.24, "text": " if I should have been writing the entire 128k block. One fix is to simply use slicing, is to get", "tokens": [50364, 498, 286, 820, 362, 668, 3579, 264, 2302, 29810, 74, 3461, 13, 1485, 3191, 307, 281, 2935, 764, 46586, 11, 307, 281, 483, 50900], "temperature": 0.0, "avg_logprob": -0.07294381581819974, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.00018514426483307034}, {"id": 173, "seek": 124852, "start": 1259.24, "end": 1269.08, "text": " that byte array called data and take from it to write each time the slice that is length long.", "tokens": [50900, 300, 40846, 10225, 1219, 1412, 293, 747, 490, 309, 281, 2464, 1184, 565, 264, 13153, 300, 307, 4641, 938, 13, 51392], "temperature": 0.0, "avg_logprob": -0.07294381581819974, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.00018514426483307034}, {"id": 174, "seek": 124852, "start": 1269.08, "end": 1275.8799999999999, "text": " So if I get a full-sized block, I'm writing out all of the data, but if I get only half a block", "tokens": [51392, 407, 498, 286, 483, 257, 1577, 12, 20614, 3461, 11, 286, 478, 3579, 484, 439, 295, 264, 1412, 11, 457, 498, 286, 483, 787, 1922, 257, 3461, 51732], "temperature": 0.0, "avg_logprob": -0.07294381581819974, "compression_ratio": 1.4947916666666667, "no_speech_prob": 0.00018514426483307034}, {"id": 175, "seek": 127588, "start": 1275.88, "end": 1282.7600000000002, "text": " at the end of the file, I only write that last half block out from the initial part of my byte", "tokens": [50364, 412, 264, 917, 295, 264, 3991, 11, 286, 787, 2464, 300, 1036, 1922, 3461, 484, 490, 264, 5883, 644, 295, 452, 40846, 50708], "temperature": 0.0, "avg_logprob": -0.08458342552185058, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.00077883864287287}, {"id": 176, "seek": 127588, "start": 1282.7600000000002, "end": 1290.68, "text": " array. What if we didn't want the expense, though, of having to do that, back one slide, expensive", "tokens": [50708, 10225, 13, 708, 498, 321, 994, 380, 528, 264, 18406, 11, 1673, 11, 295, 1419, 281, 360, 300, 11, 646, 472, 4137, 11, 5124, 51104], "temperature": 0.0, "avg_logprob": -0.08458342552185058, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.00077883864287287}, {"id": 177, "seek": 127588, "start": 1290.68, "end": 1298.44, "text": " slicing operation, because asking a Python string, unicode string, or byte array for a slice creates", "tokens": [51104, 46586, 6916, 11, 570, 3365, 257, 15329, 6798, 11, 517, 299, 1429, 6798, 11, 420, 40846, 10225, 337, 257, 13153, 7829, 51492], "temperature": 0.0, "avg_logprob": -0.08458342552185058, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.00077883864287287}, {"id": 178, "seek": 127588, "start": 1298.44, "end": 1305.5600000000002, "text": " a whole new one and copies as much data into the new one as you ask for with the limits you set in", "tokens": [51492, 257, 1379, 777, 472, 293, 14341, 382, 709, 1412, 666, 264, 777, 472, 382, 291, 1029, 337, 365, 264, 10406, 291, 992, 294, 51848], "temperature": 0.0, "avg_logprob": -0.08458342552185058, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.00077883864287287}, {"id": 179, "seek": 130556, "start": 1305.56, "end": 1312.12, "text": " the slice. If we wanted to achieve zero copy, the people who added byte array to the language,", "tokens": [50364, 264, 13153, 13, 759, 321, 1415, 281, 4584, 4018, 5055, 11, 264, 561, 567, 3869, 40846, 10225, 281, 264, 2856, 11, 50692], "temperature": 0.0, "avg_logprob": -0.08590828882504815, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.00026935554342344403}, {"id": 180, "seek": 130556, "start": 1312.6799999999998, "end": 1319.56, "text": " they thought of that as well. They added a second feature that works with byte array called a memory", "tokens": [50720, 436, 1194, 295, 300, 382, 731, 13, 814, 3869, 257, 1150, 4111, 300, 1985, 365, 40846, 10225, 1219, 257, 4675, 51064], "temperature": 0.0, "avg_logprob": -0.08590828882504815, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.00026935554342344403}, {"id": 181, "seek": 130556, "start": 1319.56, "end": 1329.3999999999999, "text": " view. A memory view is a sliceable object. Here I take the slice 3 colon 6 of that byte array that", "tokens": [51064, 1910, 13, 316, 4675, 1910, 307, 257, 13153, 712, 2657, 13, 1692, 286, 747, 264, 13153, 805, 8255, 1386, 295, 300, 40846, 10225, 300, 51556], "temperature": 0.0, "avg_logprob": -0.08590828882504815, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.00026935554342344403}, {"id": 182, "seek": 132940, "start": 1329.48, "end": 1338.68, "text": " I create up there. It's a slice which has no memory of its own but is letting you reach into the", "tokens": [50368, 286, 1884, 493, 456, 13, 467, 311, 257, 13153, 597, 575, 572, 4675, 295, 1080, 1065, 457, 307, 8295, 291, 2524, 666, 264, 50828], "temperature": 0.0, "avg_logprob": -0.09531558911824964, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007094626780599356}, {"id": 183, "seek": 132940, "start": 1338.68, "end": 1345.48, "text": " memory it was sliced from to make the change. Essentially, this memory view, the V that I", "tokens": [50828, 4675, 309, 390, 27098, 490, 281, 652, 264, 1319, 13, 23596, 11, 341, 4675, 1910, 11, 264, 691, 300, 286, 51168], "temperature": 0.0, "avg_logprob": -0.09531558911824964, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007094626780599356}, {"id": 184, "seek": 132940, "start": 1345.48, "end": 1353.48, "text": " create here, is just a, essentially, it's like a string object, but the addresses that it wants", "tokens": [51168, 1884, 510, 11, 307, 445, 257, 11, 4476, 11, 309, 311, 411, 257, 6798, 2657, 11, 457, 264, 16862, 300, 309, 2738, 51568], "temperature": 0.0, "avg_logprob": -0.09531558911824964, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007094626780599356}, {"id": 185, "seek": 132940, "start": 1353.48, "end": 1358.92, "text": " to write to in memory are the addresses right there in the middle of the byte array. So when I try", "tokens": [51568, 281, 2464, 281, 294, 4675, 366, 264, 16862, 558, 456, 294, 264, 2808, 295, 264, 40846, 10225, 13, 407, 562, 286, 853, 51840], "temperature": 0.0, "avg_logprob": -0.09531558911824964, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007094626780599356}, {"id": 186, "seek": 135892, "start": 1358.92, "end": 1370.92, "text": " to set its index zero value, it really goes to index 3 in the real byte array. When I set item 1,", "tokens": [50364, 281, 992, 1080, 8186, 4018, 2158, 11, 309, 534, 1709, 281, 8186, 805, 294, 264, 957, 40846, 10225, 13, 1133, 286, 992, 3174, 502, 11, 50964], "temperature": 0.0, "avg_logprob": -0.06912737128175335, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.00018512073438614607}, {"id": 187, "seek": 135892, "start": 1370.92, "end": 1378.2, "text": " it really goes to slot 4. When I set item 2, it goes to slot 5. It really is just creating an", "tokens": [50964, 309, 534, 1709, 281, 14747, 1017, 13, 1133, 286, 992, 3174, 568, 11, 309, 1709, 281, 14747, 1025, 13, 467, 534, 307, 445, 4084, 364, 51328], "temperature": 0.0, "avg_logprob": -0.06912737128175335, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.00018512073438614607}, {"id": 188, "seek": 135892, "start": 1378.2, "end": 1386.6000000000001, "text": " object that acts like it's a little byte array but is, in fact, just an offset. It's adding", "tokens": [51328, 2657, 300, 10672, 411, 309, 311, 257, 707, 40846, 10225, 457, 307, 11, 294, 1186, 11, 445, 364, 18687, 13, 467, 311, 5127, 51748], "temperature": 0.0, "avg_logprob": -0.06912737128175335, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.00018512073438614607}, {"id": 189, "seek": 138660, "start": 1386.6, "end": 1394.04, "text": " something to each index you use as you read and write from it. And this is what can help us in the", "tokens": [50364, 746, 281, 1184, 8186, 291, 764, 382, 291, 1401, 293, 2464, 490, 309, 13, 400, 341, 307, 437, 393, 854, 505, 294, 264, 50736], "temperature": 0.0, "avg_logprob": -0.07441112242246929, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0003249491273891181}, {"id": 190, "seek": 138660, "start": 1394.04, "end": 1402.9199999999998, "text": " situation we're in. Here is a zero copy version of my fixed code to try to read in lots of blocks.", "tokens": [50736, 2590, 321, 434, 294, 13, 1692, 307, 257, 4018, 5055, 3037, 295, 452, 6806, 3089, 281, 853, 281, 1401, 294, 3195, 295, 8474, 13, 51180], "temperature": 0.0, "avg_logprob": -0.07441112242246929, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0003249491273891181}, {"id": 191, "seek": 138660, "start": 1402.9199999999998, "end": 1409.56, "text": " Before I was asking data, the byte array itself to do the slicing, and like all Python strings,", "tokens": [51180, 4546, 286, 390, 3365, 1412, 11, 264, 40846, 10225, 2564, 281, 360, 264, 46586, 11, 293, 411, 439, 15329, 13985, 11, 51512], "temperature": 0.0, "avg_logprob": -0.07441112242246929, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.0003249491273891181}, {"id": 192, "seek": 140956, "start": 1409.6399999999999, "end": 1417.1599999999999, "text": " it gives me a whole new one when I ask for a slice. Now, I'm looking at it through a memory view.", "tokens": [50368, 309, 2709, 385, 257, 1379, 777, 472, 562, 286, 1029, 337, 257, 13153, 13, 823, 11, 286, 478, 1237, 412, 309, 807, 257, 4675, 1910, 13, 50744], "temperature": 0.0, "avg_logprob": -0.12637762421543158, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00467859348282218}, {"id": 193, "seek": 140956, "start": 1417.1599999999999, "end": 1424.44, "text": " So if I ask, let's say, for a view of, you know, if length is 128k and asking for all the data,", "tokens": [50744, 407, 498, 286, 1029, 11, 718, 311, 584, 11, 337, 257, 1910, 295, 11, 291, 458, 11, 498, 4641, 307, 29810, 74, 293, 3365, 337, 439, 264, 1412, 11, 51108], "temperature": 0.0, "avg_logprob": -0.12637762421543158, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00467859348282218}, {"id": 194, "seek": 140956, "start": 1424.44, "end": 1430.04, "text": " it just gives me a little memory view object whose addresses are pointing at the whole block of data.", "tokens": [51108, 309, 445, 2709, 385, 257, 707, 4675, 1910, 2657, 6104, 16862, 366, 12166, 412, 264, 1379, 3461, 295, 1412, 13, 51388], "temperature": 0.0, "avg_logprob": -0.12637762421543158, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00467859348282218}, {"id": 195, "seek": 140956, "start": 1430.04, "end": 1435.8799999999999, "text": " A very cheap operation. And so memory views are often necessary to get any kind of performance", "tokens": [51388, 316, 588, 7084, 6916, 13, 400, 370, 4675, 6809, 366, 2049, 4818, 281, 483, 604, 733, 295, 3389, 51680], "temperature": 0.0, "avg_logprob": -0.12637762421543158, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.00467859348282218}, {"id": 196, "seek": 143588, "start": 1435.88, "end": 1441.8000000000002, "text": " out of the byte array when doing IO, especially when you can't predict how big the next delivery", "tokens": [50364, 484, 295, 264, 40846, 10225, 562, 884, 39839, 11, 2318, 562, 291, 393, 380, 6069, 577, 955, 264, 958, 8982, 50660], "temperature": 0.0, "avg_logprob": -0.10761715049174295, "compression_ratio": 1.462686567164179, "no_speech_prob": 0.0007787526119500399}, {"id": 197, "seek": 143588, "start": 1441.8000000000002, "end": 1450.2800000000002, "text": " of information will be. Here are the runtimes of DD and cat that we discussed earlier. Compared to", "tokens": [50660, 295, 1589, 486, 312, 13, 1692, 366, 264, 49435, 1532, 295, 30778, 293, 3857, 300, 321, 7152, 3071, 13, 30539, 281, 51084], "temperature": 0.0, "avg_logprob": -0.10761715049174295, "compression_ratio": 1.462686567164179, "no_speech_prob": 0.0007787526119500399}, {"id": 198, "seek": 143588, "start": 1450.2800000000002, "end": 1460.0400000000002, "text": " just plain old read with normal Python strings, read into my first version that was broken because", "tokens": [51084, 445, 11121, 1331, 1401, 365, 2710, 15329, 13985, 11, 1401, 666, 452, 700, 3037, 300, 390, 5463, 570, 51572], "temperature": 0.0, "avg_logprob": -0.10761715049174295, "compression_ratio": 1.462686567164179, "no_speech_prob": 0.0007787526119500399}, {"id": 199, "seek": 146004, "start": 1460.12, "end": 1466.2, "text": " it wasn't careful about how much it wrote does run slightly faster than the traditional Python", "tokens": [50368, 309, 2067, 380, 5026, 466, 577, 709, 309, 4114, 775, 1190, 4748, 4663, 813, 264, 5164, 15329, 50672], "temperature": 0.0, "avg_logprob": -0.07180166805491728, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.00513553898781538}, {"id": 200, "seek": 146004, "start": 1466.2, "end": 1474.84, "text": " way of doing things. But when you then pivot to using a slice byte array and slicing it,", "tokens": [50672, 636, 295, 884, 721, 13, 583, 562, 291, 550, 14538, 281, 1228, 257, 13153, 40846, 10225, 293, 46586, 309, 11, 51104], "temperature": 0.0, "avg_logprob": -0.07180166805491728, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.00513553898781538}, {"id": 201, "seek": 146004, "start": 1474.84, "end": 1479.56, "text": " because you're copying every piece of data into memory twice, it's much more expensive,", "tokens": [51104, 570, 291, 434, 27976, 633, 2522, 295, 1412, 666, 4675, 6091, 11, 309, 311, 709, 544, 5124, 11, 51340], "temperature": 0.0, "avg_logprob": -0.07180166805491728, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.00513553898781538}, {"id": 202, "seek": 146004, "start": 1479.56, "end": 1487.6399999999999, "text": " it is the memory view. It is that zero expense, very little expense, constant time expense,", "tokens": [51340, 309, 307, 264, 4675, 1910, 13, 467, 307, 300, 4018, 18406, 11, 588, 707, 18406, 11, 5754, 565, 18406, 11, 51744], "temperature": 0.0, "avg_logprob": -0.07180166805491728, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.00513553898781538}, {"id": 203, "seek": 148764, "start": 1487.64, "end": 1494.76, "text": " I should say, ability to slice without copying data that lets us create a correct version of a", "tokens": [50364, 286, 820, 584, 11, 3485, 281, 13153, 1553, 27976, 1412, 300, 6653, 505, 1884, 257, 3006, 3037, 295, 257, 50720], "temperature": 0.0, "avg_logprob": -0.10447031429835728, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.00014423482934944332}, {"id": 204, "seek": 148764, "start": 1494.76, "end": 1506.3600000000001, "text": " file copy while still slightly beating read and write and traditional strings. So that was a lot", "tokens": [50720, 3991, 5055, 1339, 920, 4748, 13497, 1401, 293, 2464, 293, 5164, 13985, 13, 407, 300, 390, 257, 688, 51300], "temperature": 0.0, "avg_logprob": -0.10447031429835728, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.00014423482934944332}, {"id": 205, "seek": 148764, "start": 1506.3600000000001, "end": 1515.64, "text": " of work and we got a 4% speed up with byte array. Now, small blocks, things get worse for byte array", "tokens": [51300, 295, 589, 293, 321, 658, 257, 1017, 4, 3073, 493, 365, 40846, 10225, 13, 823, 11, 1359, 8474, 11, 721, 483, 5324, 337, 40846, 10225, 51764], "temperature": 0.0, "avg_logprob": -0.10447031429835728, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.00014423482934944332}, {"id": 206, "seek": 151564, "start": 1515.72, "end": 1521.72, "text": " because what will slicing here so often do, it creates a new object every time and creating", "tokens": [50368, 570, 437, 486, 46586, 510, 370, 2049, 360, 11, 309, 7829, 257, 777, 2657, 633, 565, 293, 4084, 50668], "temperature": 0.0, "avg_logprob": -0.11744446555773418, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.000687548192217946}, {"id": 207, "seek": 151564, "start": 1521.72, "end": 1526.92, "text": " one of these little view objects with its pointers into the part of the byte array I want to look at", "tokens": [50668, 472, 295, 613, 707, 1910, 6565, 365, 1080, 44548, 666, 264, 644, 295, 264, 40846, 10225, 286, 528, 281, 574, 412, 50928], "temperature": 0.0, "avg_logprob": -0.11744446555773418, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.000687548192217946}, {"id": 208, "seek": 151564, "start": 1526.92, "end": 1532.3600000000001, "text": " was fine when I was only doing it every few hundred K of data, but what if I'm like the", "tokens": [50928, 390, 2489, 562, 286, 390, 787, 884, 309, 633, 1326, 3262, 591, 295, 1412, 11, 457, 437, 498, 286, 478, 411, 264, 51200], "temperature": 0.0, "avg_logprob": -0.11744446555773418, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.000687548192217946}, {"id": 209, "seek": 151564, "start": 1532.3600000000001, "end": 1538.2, "text": " defaults of DD and I'm going to be reading and writing 512 bytes at a time, what if I have to", "tokens": [51200, 7576, 82, 295, 30778, 293, 286, 478, 516, 281, 312, 3760, 293, 3579, 1025, 4762, 36088, 412, 257, 565, 11, 437, 498, 286, 362, 281, 51492], "temperature": 0.0, "avg_logprob": -0.11744446555773418, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.000687548192217946}, {"id": 210, "seek": 153820, "start": 1538.28, "end": 1546.52, "text": " spin up a new memory view for every half K of data? Then things start to look very bad and,", "tokens": [50368, 6060, 493, 257, 777, 4675, 1910, 337, 633, 1922, 591, 295, 1412, 30, 1396, 721, 722, 281, 574, 588, 1578, 293, 11, 50780], "temperature": 0.0, "avg_logprob": -0.15443676961979397, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008439825847744942}, {"id": 211, "seek": 153820, "start": 1546.52, "end": 1552.1200000000001, "text": " in fact, the memory view used correctly where you're careful of your lengths is simply a loss.", "tokens": [50780, 294, 1186, 11, 264, 4675, 1910, 1143, 8944, 689, 291, 434, 5026, 295, 428, 26329, 307, 2935, 257, 4470, 13, 51060], "temperature": 0.0, "avg_logprob": -0.15443676961979397, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008439825847744942}, {"id": 212, "seek": 153820, "start": 1553.0, "end": 1561.96, "text": " It's much, reading where it just returns a Python string is really efficient. A write of a Python", "tokens": [51104, 467, 311, 709, 11, 3760, 689, 309, 445, 11247, 257, 15329, 6798, 307, 534, 7148, 13, 316, 2464, 295, 257, 15329, 51552], "temperature": 0.0, "avg_logprob": -0.15443676961979397, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008439825847744942}, {"id": 213, "seek": 156196, "start": 1561.96, "end": 1568.1200000000001, "text": " string is really efficient. You can easily get into situations with the fancy attempts one", "tokens": [50364, 6798, 307, 534, 7148, 13, 509, 393, 3612, 483, 666, 6851, 365, 264, 10247, 15257, 472, 50672], "temperature": 0.0, "avg_logprob": -0.08260676535693082, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.005551839247345924}, {"id": 214, "seek": 156196, "start": 1568.1200000000001, "end": 1575.08, "text": " makes with a byte array to create more expensive IO than you had when you just used traditional", "tokens": [50672, 1669, 365, 257, 40846, 10225, 281, 1884, 544, 5124, 39839, 813, 291, 632, 562, 291, 445, 1143, 5164, 51020], "temperature": 0.0, "avg_logprob": -0.08260676535693082, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.005551839247345924}, {"id": 215, "seek": 156196, "start": 1576.2, "end": 1581.96, "text": " immutable strings that, yes, required Python to build a new string for every call to read,", "tokens": [51076, 3397, 32148, 13985, 300, 11, 2086, 11, 4739, 15329, 281, 1322, 257, 777, 6798, 337, 633, 818, 281, 1401, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08260676535693082, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.005551839247345924}, {"id": 216, "seek": 156196, "start": 1581.96, "end": 1590.68, "text": " but cut out all of the rest of that expense. I was sad for the byte array at this point in my talk.", "tokens": [51364, 457, 1723, 484, 439, 295, 264, 1472, 295, 300, 18406, 13, 286, 390, 4227, 337, 264, 40846, 10225, 412, 341, 935, 294, 452, 751, 13, 51800], "temperature": 0.0, "avg_logprob": -0.08260676535693082, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.005551839247345924}, {"id": 217, "seek": 159196, "start": 1592.04, "end": 1604.04, "text": " So I stared at the example. 20% slow down for a small block size, but then I thought of something.", "tokens": [50368, 407, 286, 44738, 412, 264, 1365, 13, 945, 4, 2964, 760, 337, 257, 1359, 3461, 2744, 11, 457, 550, 286, 1194, 295, 746, 13, 50968], "temperature": 0.0, "avg_logprob": -0.10175848470150846, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0003918847651220858}, {"id": 218, "seek": 159196, "start": 1606.1200000000001, "end": 1610.92, "text": " What if we don't always slice? Because when reading from a file, different from a network,", "tokens": [51072, 708, 498, 321, 500, 380, 1009, 13153, 30, 1436, 562, 3760, 490, 257, 3991, 11, 819, 490, 257, 3209, 11, 51312], "temperature": 0.0, "avg_logprob": -0.10175848470150846, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0003918847651220858}, {"id": 219, "seek": 159196, "start": 1610.92, "end": 1615.24, "text": " when reading from a file, the normal case is that unless you're at the very end of the file,", "tokens": [51312, 562, 3760, 490, 257, 3991, 11, 264, 2710, 1389, 307, 300, 5969, 291, 434, 412, 264, 588, 917, 295, 264, 3991, 11, 51528], "temperature": 0.0, "avg_logprob": -0.10175848470150846, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0003918847651220858}, {"id": 220, "seek": 159196, "start": 1615.24, "end": 1621.32, "text": " you're going to get as much as you ask for. Ask for 128 K, you're going to get it. The normal case", "tokens": [51528, 291, 434, 516, 281, 483, 382, 709, 382, 291, 1029, 337, 13, 12320, 337, 29810, 591, 11, 291, 434, 516, 281, 483, 309, 13, 440, 2710, 1389, 51832], "temperature": 0.0, "avg_logprob": -0.10175848470150846, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.0003918847651220858}, {"id": 221, "seek": 162132, "start": 1621.32, "end": 1627.8, "text": " is that the length equals the block size, and in that case, there's not only no reason to ask the", "tokens": [50364, 307, 300, 264, 4641, 6915, 264, 3461, 2744, 11, 293, 294, 300, 1389, 11, 456, 311, 406, 787, 572, 1778, 281, 1029, 264, 50688], "temperature": 0.0, "avg_logprob": -0.06692840113784328, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.0004169887397438288}, {"id": 222, "seek": 162132, "start": 1627.8, "end": 1633.8, "text": " byte array to take a slice of itself and copy all that data, there's no reason to use the view to", "tokens": [50688, 40846, 10225, 281, 747, 257, 13153, 295, 2564, 293, 5055, 439, 300, 1412, 11, 456, 311, 572, 1778, 281, 764, 264, 1910, 281, 50988], "temperature": 0.0, "avg_logprob": -0.06692840113784328, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.0004169887397438288}, {"id": 223, "seek": 162132, "start": 1633.8, "end": 1638.52, "text": " limit the amount of data you're using from the block. You're going to use all of it.", "tokens": [50988, 4948, 264, 2372, 295, 1412, 291, 434, 1228, 490, 264, 3461, 13, 509, 434, 516, 281, 764, 439, 295, 309, 13, 51224], "temperature": 0.0, "avg_logprob": -0.06692840113784328, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.0004169887397438288}, {"id": 224, "seek": 162132, "start": 1638.52, "end": 1646.36, "text": " And so if you handle that special case, you don't incur an object creation step in order to get that", "tokens": [51224, 400, 370, 498, 291, 4813, 300, 2121, 1389, 11, 291, 500, 380, 35774, 364, 2657, 8016, 1823, 294, 1668, 281, 483, 300, 51616], "temperature": 0.0, "avg_logprob": -0.06692840113784328, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.0004169887397438288}, {"id": 225, "seek": 164636, "start": 1646.36, "end": 1656.4399999999998, "text": " right call started, and you slightly beat the performance of the traditional read write loop", "tokens": [50364, 558, 818, 1409, 11, 293, 291, 4748, 4224, 264, 3389, 295, 264, 5164, 1401, 2464, 6367, 50868], "temperature": 0.0, "avg_logprob": -0.18563065630324344, "compression_ratio": 1.318840579710145, "no_speech_prob": 0.003820946905761957}, {"id": 226, "seek": 164636, "start": 1657.1599999999999, "end": 1671.56, "text": " by 4%. Just like for the big block case. So even if your I.O. is in a situation where the", "tokens": [50904, 538, 1017, 6856, 1449, 411, 337, 264, 955, 3461, 1389, 13, 407, 754, 498, 428, 286, 13, 46, 13, 307, 294, 257, 2590, 689, 264, 51624], "temperature": 0.0, "avg_logprob": -0.18563065630324344, "compression_ratio": 1.318840579710145, "no_speech_prob": 0.003820946905761957}, {"id": 227, "seek": 167156, "start": 1671.6399999999999, "end": 1678.6, "text": " block size will be varying or might be small, you can, if you're careful and cut and paste from", "tokens": [50368, 3461, 2744, 486, 312, 22984, 420, 1062, 312, 1359, 11, 291, 393, 11, 498, 291, 434, 5026, 293, 1723, 293, 9163, 490, 50716], "temperature": 0.0, "avg_logprob": -0.07962999343872071, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0019866086076945066}, {"id": 228, "seek": 167156, "start": 1678.6, "end": 1686.12, "text": " my talk slides, you can run slightly faster than the traditional read and write with immutable", "tokens": [50716, 452, 751, 9788, 11, 291, 393, 1190, 4748, 4663, 813, 264, 5164, 1401, 293, 2464, 365, 3397, 32148, 51092], "temperature": 0.0, "avg_logprob": -0.07962999343872071, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0019866086076945066}, {"id": 229, "seek": 167156, "start": 1686.12, "end": 1692.36, "text": " strings. Python 2.7, by the way, has the same relative behaviors between those different choices", "tokens": [51092, 13985, 13, 15329, 568, 13, 22, 11, 538, 264, 636, 11, 575, 264, 912, 4972, 15501, 1296, 729, 819, 7994, 51404], "temperature": 0.0, "avg_logprob": -0.07962999343872071, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0019866086076945066}, {"id": 230, "seek": 167156, "start": 1692.36, "end": 1698.84, "text": " on my machine slightly slower. And I think the lesson here is that it is just hard to beat", "tokens": [51404, 322, 452, 3479, 4748, 14009, 13, 400, 286, 519, 264, 6898, 510, 307, 300, 309, 307, 445, 1152, 281, 4224, 51728], "temperature": 0.0, "avg_logprob": -0.07962999343872071, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0019866086076945066}, {"id": 231, "seek": 169884, "start": 1698.84, "end": 1703.3999999999999, "text": " old fashioned strings when you're pulling in data and then just immediately sending it back to", "tokens": [50364, 1331, 40646, 13985, 562, 291, 434, 8407, 294, 1412, 293, 550, 445, 4258, 7750, 309, 646, 281, 50592], "temperature": 0.0, "avg_logprob": -0.10919626951217651, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0016463669016957283}, {"id": 232, "seek": 169884, "start": 1703.3999999999999, "end": 1712.04, "text": " the operating system over some other channel. It's really something how the good old fashioned", "tokens": [50592, 264, 7447, 1185, 670, 512, 661, 2269, 13, 467, 311, 534, 746, 577, 264, 665, 1331, 40646, 51024], "temperature": 0.0, "avg_logprob": -0.10919626951217651, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0016463669016957283}, {"id": 233, "seek": 169884, "start": 1712.04, "end": 1719.6399999999999, "text": " immutable string that makes functional programmers' hearts sing is pretty much as good in this case", "tokens": [51024, 3397, 32148, 6798, 300, 1669, 11745, 41504, 6, 8852, 1522, 307, 1238, 709, 382, 665, 294, 341, 1389, 51404], "temperature": 0.0, "avg_logprob": -0.10919626951217651, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0016463669016957283}, {"id": 234, "seek": 169884, "start": 1719.6399999999999, "end": 1727.9599999999998, "text": " as our weird side effect idea of constantly modifying this single byte array that we have created.", "tokens": [51404, 382, 527, 3657, 1252, 1802, 1558, 295, 6460, 42626, 341, 2167, 40846, 10225, 300, 321, 362, 2942, 13, 51820], "temperature": 0.0, "avg_logprob": -0.10919626951217651, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0016463669016957283}, {"id": 235, "seek": 172796, "start": 1728.68, "end": 1733.96, "text": " So my verdict is that it is dangerous because it's so easy to write what looks like pretty code,", "tokens": [50400, 407, 452, 33957, 307, 300, 309, 307, 5795, 570, 309, 311, 370, 1858, 281, 2464, 437, 1542, 411, 1238, 3089, 11, 50664], "temperature": 0.0, "avg_logprob": -0.09092326597733931, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.0002867428120225668}, {"id": 236, "seek": 172796, "start": 1733.96, "end": 1738.76, "text": " it looks like almost the same little read write loop, but is going to operate substantially", "tokens": [50664, 309, 1542, 411, 1920, 264, 912, 707, 1401, 2464, 6367, 11, 457, 307, 516, 281, 9651, 30797, 50904], "temperature": 0.0, "avg_logprob": -0.09092326597733931, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.0002867428120225668}, {"id": 237, "seek": 172796, "start": 1738.76, "end": 1744.52, "text": " worse in situations that you might not think to test for unless you think of the small blocks case.", "tokens": [50904, 5324, 294, 6851, 300, 291, 1062, 406, 519, 281, 1500, 337, 5969, 291, 519, 295, 264, 1359, 8474, 1389, 13, 51192], "temperature": 0.0, "avg_logprob": -0.09092326597733931, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.0002867428120225668}, {"id": 238, "seek": 172796, "start": 1745.16, "end": 1753.72, "text": " The one advantage it does offer is a great memory profile because there's a link later to a great", "tokens": [51224, 440, 472, 5002, 309, 775, 2626, 307, 257, 869, 4675, 7964, 570, 456, 311, 257, 2113, 1780, 281, 257, 869, 51652], "temperature": 0.0, "avg_logprob": -0.09092326597733931, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.0002867428120225668}, {"id": 239, "seek": 175372, "start": 1753.72, "end": 1758.28, "text": " blog post online about someone writing an audio server that needed to keep lots of strings in", "tokens": [50364, 6968, 2183, 2950, 466, 1580, 3579, 364, 6278, 7154, 300, 2978, 281, 1066, 3195, 295, 13985, 294, 50592], "temperature": 0.0, "avg_logprob": -0.07785730361938477, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0714283138513565}, {"id": 240, "seek": 175372, "start": 1758.28, "end": 1763.08, "text": " a buffer and his memory usage was going through the roof because if you're constantly allocating", "tokens": [50592, 257, 21762, 293, 702, 4675, 14924, 390, 516, 807, 264, 8418, 570, 498, 291, 434, 6460, 12660, 990, 50832], "temperature": 0.0, "avg_logprob": -0.07785730361938477, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0714283138513565}, {"id": 241, "seek": 175372, "start": 1763.08, "end": 1767.48, "text": " and deallocating differently sized strings, because every call to read needs to make a new", "tokens": [50832, 293, 368, 336, 905, 990, 7614, 20004, 13985, 11, 570, 633, 818, 281, 1401, 2203, 281, 652, 257, 777, 51052], "temperature": 0.0, "avg_logprob": -0.07785730361938477, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0714283138513565}, {"id": 242, "seek": 175372, "start": 1767.48, "end": 1773.72, "text": " string to hand it back to you, then you can get a lot of memory fragmentation. If instead you have", "tokens": [51052, 6798, 281, 1011, 309, 646, 281, 291, 11, 550, 291, 393, 483, 257, 688, 295, 4675, 9241, 19631, 13, 759, 2602, 291, 362, 51364], "temperature": 0.0, "avg_logprob": -0.07785730361938477, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0714283138513565}, {"id": 243, "seek": 175372, "start": 1773.72, "end": 1779.88, "text": " one byte array and you use it over and over and over and over, there's nothing happening to get", "tokens": [51364, 472, 40846, 10225, 293, 291, 764, 309, 670, 293, 670, 293, 670, 293, 670, 11, 456, 311, 1825, 2737, 281, 483, 51672], "temperature": 0.0, "avg_logprob": -0.07785730361938477, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0714283138513565}, {"id": 244, "seek": 177988, "start": 1779.96, "end": 1785.16, "text": " fragmented. So don't do the byte array, I wouldn't do the byte array for the 4% speedup.", "tokens": [50368, 9241, 14684, 13, 407, 500, 380, 360, 264, 40846, 10225, 11, 286, 2759, 380, 360, 264, 40846, 10225, 337, 264, 1017, 4, 3073, 1010, 13, 50628], "temperature": 0.0, "avg_logprob": -0.114554077066401, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.001925277290865779}, {"id": 245, "seek": 177988, "start": 1786.7600000000002, "end": 1791.72, "text": " I would do it because I wanted to control my memory profile, but only if I knew that was a", "tokens": [50708, 286, 576, 360, 309, 570, 286, 1415, 281, 1969, 452, 4675, 7964, 11, 457, 787, 498, 286, 2586, 300, 390, 257, 50956], "temperature": 0.0, "avg_logprob": -0.114554077066401, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.001925277290865779}, {"id": 246, "seek": 177988, "start": 1791.72, "end": 1798.92, "text": " problem in my application domain. All right, now we go on to another and more interesting situation", "tokens": [50956, 1154, 294, 452, 3861, 9274, 13, 1057, 558, 11, 586, 321, 352, 322, 281, 1071, 293, 544, 1880, 2590, 51316], "temperature": 0.0, "avg_logprob": -0.114554077066401, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.001925277290865779}, {"id": 247, "seek": 177988, "start": 1798.92, "end": 1805.0, "text": " using the byte array as the accumulator. Fun question for people doing new network programming,", "tokens": [51316, 1228, 264, 40846, 10225, 382, 264, 12989, 16381, 13, 11166, 1168, 337, 561, 884, 777, 3209, 9410, 11, 51620], "temperature": 0.0, "avg_logprob": -0.114554077066401, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.001925277290865779}, {"id": 248, "seek": 180500, "start": 1805.0, "end": 1815.96, "text": " how many bytes will receive 1024 return? The answer is one. Or more if the network stack", "tokens": [50364, 577, 867, 36088, 486, 4774, 1266, 7911, 2736, 30, 440, 1867, 307, 472, 13, 1610, 544, 498, 264, 3209, 8630, 50912], "temperature": 0.0, "avg_logprob": -0.1325591041928246, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.021594688296318054}, {"id": 249, "seek": 180500, "start": 1815.96, "end": 1822.36, "text": " is in the mood, but you're only guaranteed one. And this is the opposite, a file IO. File IO,", "tokens": [50912, 307, 294, 264, 9268, 11, 457, 291, 434, 787, 18031, 472, 13, 400, 341, 307, 264, 6182, 11, 257, 3991, 39839, 13, 26196, 39839, 11, 51232], "temperature": 0.0, "avg_logprob": -0.1325591041928246, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.021594688296318054}, {"id": 250, "seek": 180500, "start": 1822.36, "end": 1829.0, "text": " you ask for 128K, if there's 128K left in the file, it will wait for the disk to spin, it will", "tokens": [51232, 291, 1029, 337, 29810, 42, 11, 498, 456, 311, 29810, 42, 1411, 294, 264, 3991, 11, 309, 486, 1699, 337, 264, 12355, 281, 6060, 11, 309, 486, 51564], "temperature": 0.0, "avg_logprob": -0.1325591041928246, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.021594688296318054}, {"id": 251, "seek": 180500, "start": 1829.0, "end": 1834.6, "text": " wait for the head to be in the right place, it will leave you paused until a full 128K is ready", "tokens": [51564, 1699, 337, 264, 1378, 281, 312, 294, 264, 558, 1081, 11, 309, 486, 1856, 291, 46860, 1826, 257, 1577, 29810, 42, 307, 1919, 51844], "temperature": 0.0, "avg_logprob": -0.1325591041928246, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.021594688296318054}, {"id": 252, "seek": 183460, "start": 1834.6, "end": 1840.04, "text": " for delivery, and then wake you back up. The network is the opposite. Receive will block", "tokens": [50364, 337, 8982, 11, 293, 550, 6634, 291, 646, 493, 13, 440, 3209, 307, 264, 6182, 13, 41962, 488, 486, 3461, 50636], "temperature": 0.0, "avg_logprob": -0.10655575008182736, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0005190602387301624}, {"id": 253, "seek": 183460, "start": 1840.04, "end": 1846.76, "text": " only until at least a single byte is available and then set you off running to process it.", "tokens": [50636, 787, 1826, 412, 1935, 257, 2167, 40846, 307, 2435, 293, 550, 992, 291, 766, 2614, 281, 1399, 309, 13, 50972], "temperature": 0.0, "avg_logprob": -0.10655575008182736, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0005190602387301624}, {"id": 254, "seek": 183460, "start": 1846.76, "end": 1853.32, "text": " And that can happen if your buffer size happens to be just a little less than the size of the last", "tokens": [50972, 400, 300, 393, 1051, 498, 428, 21762, 2744, 2314, 281, 312, 445, 257, 707, 1570, 813, 264, 2744, 295, 264, 1036, 51300], "temperature": 0.0, "avg_logprob": -0.10655575008182736, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0005190602387301624}, {"id": 255, "seek": 183460, "start": 1853.32, "end": 1859.0, "text": " few packets that arrive. You can have a call to receive that finds only one or two bytes left,", "tokens": [51300, 1326, 30364, 300, 8881, 13, 509, 393, 362, 257, 818, 281, 4774, 300, 10704, 787, 472, 420, 732, 36088, 1411, 11, 51584], "temperature": 0.0, "avg_logprob": -0.10655575008182736, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0005190602387301624}, {"id": 256, "seek": 185900, "start": 1859.64, "end": 1867.72, "text": " meaning unlike in the case where we were choosing our read size for files, usually it's the network,", "tokens": [50396, 3620, 8343, 294, 264, 1389, 689, 321, 645, 10875, 527, 1401, 2744, 337, 7098, 11, 2673, 309, 311, 264, 3209, 11, 50800], "temperature": 0.0, "avg_logprob": -0.06854460789607121, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.004463758785277605}, {"id": 257, "seek": 185900, "start": 1867.72, "end": 1874.04, "text": " it's the clients you're communicating with that kind of decide how big your chunks of IOR when", "tokens": [50800, 309, 311, 264, 6982, 291, 434, 17559, 365, 300, 733, 295, 4536, 577, 955, 428, 24004, 295, 286, 2483, 562, 51116], "temperature": 0.0, "avg_logprob": -0.06854460789607121, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.004463758785277605}, {"id": 258, "seek": 185900, "start": 1874.04, "end": 1878.12, "text": " you're talking on the network. So you're always potentially in the case where you're dealing", "tokens": [51116, 291, 434, 1417, 322, 264, 3209, 13, 407, 291, 434, 1009, 7263, 294, 264, 1389, 689, 291, 434, 6260, 51320], "temperature": 0.0, "avg_logprob": -0.06854460789607121, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.004463758785277605}, {"id": 259, "seek": 185900, "start": 1878.12, "end": 1884.76, "text": " with little pieces of data. This fact, by the way, that you always are given an answer when", "tokens": [51320, 365, 707, 3755, 295, 1412, 13, 639, 1186, 11, 538, 264, 636, 11, 300, 291, 1009, 366, 2212, 364, 1867, 562, 51652], "temperature": 0.0, "avg_logprob": -0.06854460789607121, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.004463758785277605}, {"id": 260, "seek": 188476, "start": 1884.76, "end": 1891.0, "text": " even just a few bytes can be sent or received is why new network programmers tend to get into the,", "tokens": [50364, 754, 445, 257, 1326, 36088, 393, 312, 2279, 420, 4613, 307, 983, 777, 3209, 41504, 3928, 281, 483, 666, 264, 11, 50676], "temperature": 0.0, "avg_logprob": -0.10154763135043057, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.001344621879979968}, {"id": 261, "seek": 188476, "start": 1891.0, "end": 1896.68, "text": " but it worked when I ran against local host problem. They get into that situation because", "tokens": [50676, 457, 309, 2732, 562, 286, 5872, 1970, 2654, 3975, 1154, 13, 814, 483, 666, 300, 2590, 570, 50960], "temperature": 0.0, "avg_logprob": -0.10154763135043057, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.001344621879979968}, {"id": 262, "seek": 188476, "start": 1896.68, "end": 1900.84, "text": " when you run your server that you've just written and your little client that you've just written", "tokens": [50960, 562, 291, 1190, 428, 7154, 300, 291, 600, 445, 3720, 293, 428, 707, 6423, 300, 291, 600, 445, 3720, 51168], "temperature": 0.0, "avg_logprob": -0.10154763135043057, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.001344621879979968}, {"id": 263, "seek": 188476, "start": 1900.84, "end": 1906.6, "text": " on local host, the OS will send enormous blocks of data back and forth between the two processes.", "tokens": [51168, 322, 2654, 3975, 11, 264, 12731, 486, 2845, 11322, 8474, 295, 1412, 646, 293, 5220, 1296, 264, 732, 7555, 13, 51456], "temperature": 0.0, "avg_logprob": -0.10154763135043057, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.001344621879979968}, {"id": 264, "seek": 188476, "start": 1908.12, "end": 1912.68, "text": " Then they'll take it to their team and say, look what I wrote, try it between two different", "tokens": [51532, 1396, 436, 603, 747, 309, 281, 641, 1469, 293, 584, 11, 574, 437, 286, 4114, 11, 853, 309, 1296, 732, 819, 51760], "temperature": 0.0, "avg_logprob": -0.10154763135043057, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.001344621879979968}, {"id": 265, "seek": 191268, "start": 1912.68, "end": 1917.96, "text": " machines and it'll hang and never get all of the data because they didn't learn on local host", "tokens": [50364, 8379, 293, 309, 603, 3967, 293, 1128, 483, 439, 295, 264, 1412, 570, 436, 994, 380, 1466, 322, 2654, 3975, 50628], "temperature": 0.0, "avg_logprob": -0.07632666491390613, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.00011957708920817822}, {"id": 266, "seek": 191268, "start": 1917.96, "end": 1923.4, "text": " that you receive will often just give you a few thousand bytes and you need to keep at it", "tokens": [50628, 300, 291, 4774, 486, 2049, 445, 976, 291, 257, 1326, 4714, 36088, 293, 291, 643, 281, 1066, 412, 309, 50900], "temperature": 0.0, "avg_logprob": -0.07632666491390613, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.00011957708920817822}, {"id": 267, "seek": 191268, "start": 1923.4, "end": 1930.92, "text": " and watch until everything you need has arrived. So what is it like to use a traditional receive", "tokens": [50900, 293, 1159, 1826, 1203, 291, 643, 575, 6678, 13, 407, 437, 307, 309, 411, 281, 764, 257, 5164, 4774, 51276], "temperature": 0.0, "avg_logprob": -0.07632666491390613, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.00011957708920817822}, {"id": 268, "seek": 191268, "start": 1930.92, "end": 1938.3600000000001, "text": " solution getting a new string each time holding the new data that's come in? This is what it looks", "tokens": [51276, 3827, 1242, 257, 777, 6798, 1184, 565, 5061, 264, 777, 1412, 300, 311, 808, 294, 30, 639, 307, 437, 309, 1542, 51648], "temperature": 0.0, "avg_logprob": -0.07632666491390613, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.00011957708920817822}, {"id": 269, "seek": 193836, "start": 1939.08, "end": 1945.56, "text": " like. Again, here we're getting lots of maybe little pieces of data which I'm simulating by", "tokens": [50400, 411, 13, 3764, 11, 510, 321, 434, 1242, 3195, 295, 1310, 707, 3755, 295, 1412, 597, 286, 478, 1034, 12162, 538, 50724], "temperature": 0.0, "avg_logprob": -0.1390444619315011, "compression_ratio": 1.427860696517413, "no_speech_prob": 0.0007204499561339617}, {"id": 270, "seek": 193836, "start": 1945.56, "end": 1952.9199999999998, "text": " only asking for a single Ethernet packet length. So even when I run this on local host, it'll pretend", "tokens": [50724, 787, 3365, 337, 257, 2167, 38636, 7129, 20300, 4641, 13, 407, 754, 562, 286, 1190, 341, 322, 2654, 3975, 11, 309, 603, 11865, 51092], "temperature": 0.0, "avg_logprob": -0.1390444619315011, "compression_ratio": 1.427860696517413, "no_speech_prob": 0.0007204499561339617}, {"id": 271, "seek": 193836, "start": 1952.9199999999998, "end": 1961.6399999999999, "text": " like packets are coming in. This is what many Python programmers start with. They just create", "tokens": [51092, 411, 30364, 366, 1348, 294, 13, 639, 307, 437, 867, 15329, 41504, 722, 365, 13, 814, 445, 1884, 51528], "temperature": 0.0, "avg_logprob": -0.1390444619315011, "compression_ratio": 1.427860696517413, "no_speech_prob": 0.0007204499561339617}, {"id": 272, "seek": 196164, "start": 1961.72, "end": 1969.5600000000002, "text": " an empty string and they plus equal more data to it each time. In Python tutorials, many of", "tokens": [50368, 364, 6707, 6798, 293, 436, 1804, 2681, 544, 1412, 281, 309, 1184, 565, 13, 682, 15329, 17616, 11, 867, 295, 50760], "temperature": 0.0, "avg_logprob": -0.08926412333612857, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.03838983550667763}, {"id": 273, "seek": 196164, "start": 1969.5600000000002, "end": 1974.92, "text": " you will have seen this, the creating of the string and data plus equals more as an anti-pattern", "tokens": [50760, 291, 486, 362, 1612, 341, 11, 264, 4084, 295, 264, 6798, 293, 1412, 1804, 6915, 544, 382, 364, 6061, 12, 79, 1161, 77, 51028], "temperature": 0.0, "avg_logprob": -0.08926412333612857, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.03838983550667763}, {"id": 274, "seek": 196164, "start": 1974.92, "end": 1979.72, "text": " that you avoid because I tried running this. How long does the plus equals approach take?", "tokens": [51028, 300, 291, 5042, 570, 286, 3031, 2614, 341, 13, 1012, 938, 775, 264, 1804, 6915, 3109, 747, 30, 51268], "temperature": 0.0, "avg_logprob": -0.08926412333612857, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.03838983550667763}, {"id": 275, "seek": 196164, "start": 1980.68, "end": 1986.3600000000001, "text": " Infinity time. Meaning that I finally needed my laptop back so I killed it and I'll never", "tokens": [51316, 34762, 565, 13, 19948, 300, 286, 2721, 2978, 452, 10732, 646, 370, 286, 4652, 309, 293, 286, 603, 1128, 51600], "temperature": 0.0, "avg_logprob": -0.08926412333612857, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.03838983550667763}, {"id": 276, "seek": 196164, "start": 1986.3600000000001, "end": 1990.92, "text": " know how long the loop would have taken to read my gigabyte of data. But when you do plus equals,", "tokens": [51600, 458, 577, 938, 264, 6367, 576, 362, 2726, 281, 1401, 452, 8741, 34529, 295, 1412, 13, 583, 562, 291, 360, 1804, 6915, 11, 51828], "temperature": 0.0, "avg_logprob": -0.08926412333612857, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.03838983550667763}, {"id": 277, "seek": 199092, "start": 1990.92, "end": 1996.2, "text": " you're asking Python to create a little string and then your first plus equals makes a slightly", "tokens": [50364, 291, 434, 3365, 15329, 281, 1884, 257, 707, 6798, 293, 550, 428, 700, 1804, 6915, 1669, 257, 4748, 50628], "temperature": 0.0, "avg_logprob": -0.04384687784555796, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0008413874893449247}, {"id": 278, "seek": 199092, "start": 1996.2, "end": 2001.4, "text": " longer one. Your next plus equals through the loop creates a slightly longer one into which", "tokens": [50628, 2854, 472, 13, 2260, 958, 1804, 6915, 807, 264, 6367, 7829, 257, 4748, 2854, 472, 666, 597, 50888], "temperature": 0.0, "avg_logprob": -0.04384687784555796, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0008413874893449247}, {"id": 279, "seek": 199092, "start": 2001.4, "end": 2006.44, "text": " all the data from the second string has to be copied to make the third one. Then you go through", "tokens": [50888, 439, 264, 1412, 490, 264, 1150, 6798, 575, 281, 312, 25365, 281, 652, 264, 2636, 472, 13, 1396, 291, 352, 807, 51140], "temperature": 0.0, "avg_logprob": -0.04384687784555796, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0008413874893449247}, {"id": 280, "seek": 199092, "start": 2006.44, "end": 2012.04, "text": " the loop again and now you have to copy all that data again to make your fourth string. And if you", "tokens": [51140, 264, 6367, 797, 293, 586, 291, 362, 281, 5055, 439, 300, 1412, 797, 281, 652, 428, 6409, 6798, 13, 400, 498, 291, 51420], "temperature": 0.0, "avg_logprob": -0.04384687784555796, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0008413874893449247}, {"id": 281, "seek": 199092, "start": 2012.04, "end": 2017.4, "text": " have a million bytes to read, you wind up doing half a trillion operations. It's called an order", "tokens": [51420, 362, 257, 2459, 36088, 281, 1401, 11, 291, 2468, 493, 884, 1922, 257, 18723, 7705, 13, 467, 311, 1219, 364, 1668, 51688], "temperature": 0.0, "avg_logprob": -0.04384687784555796, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0008413874893449247}, {"id": 282, "seek": 201740, "start": 2017.4, "end": 2022.1200000000001, "text": " in squared algorithm, generally to be avoided if you wanted to finish by lunchtime.", "tokens": [50364, 294, 8889, 9284, 11, 5101, 281, 312, 24890, 498, 291, 1415, 281, 2413, 538, 6349, 3766, 13, 50600], "temperature": 0.0, "avg_logprob": -0.07797637286486926, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0010638206731528044}, {"id": 283, "seek": 201740, "start": 2023.96, "end": 2029.88, "text": " So this is what we tell everyone to do. Pivot to keeping a list of blocks that you've received", "tokens": [50692, 407, 341, 307, 437, 321, 980, 1518, 281, 360, 13, 430, 13142, 281, 5145, 257, 1329, 295, 8474, 300, 291, 600, 4613, 50988], "temperature": 0.0, "avg_logprob": -0.07797637286486926, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0010638206731528044}, {"id": 284, "seek": 201740, "start": 2029.88, "end": 2036.1200000000001, "text": " and join them together at the end in a single step. Python's much better at that. This actually", "tokens": [50988, 293, 3917, 552, 1214, 412, 264, 917, 294, 257, 2167, 1823, 13, 15329, 311, 709, 1101, 412, 300, 13, 639, 767, 51300], "temperature": 0.0, "avg_logprob": -0.07797637286486926, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0010638206731528044}, {"id": 285, "seek": 201740, "start": 2036.1200000000001, "end": 2041.0, "text": " finished on my laptop. It's the traditional way of accumulating data from the internet", "tokens": [51300, 4335, 322, 452, 10732, 13, 467, 311, 264, 5164, 636, 295, 12989, 12162, 1412, 490, 264, 4705, 51544], "temperature": 0.0, "avg_logprob": -0.07797637286486926, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0010638206731528044}, {"id": 286, "seek": 201740, "start": 2041.0, "end": 2046.92, "text": " in Python or from a network. Took about a little more than a second to read in a gig of data", "tokens": [51544, 294, 15329, 420, 490, 257, 3209, 13, 38288, 466, 257, 707, 544, 813, 257, 1150, 281, 1401, 294, 257, 8741, 295, 1412, 51840], "temperature": 0.0, "avg_logprob": -0.07797637286486926, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0010638206731528044}, {"id": 287, "seek": 204692, "start": 2046.92, "end": 2056.6800000000003, "text": " in those small 1.5K chunks. Now, there is a version like read into, but that receives", "tokens": [50364, 294, 729, 1359, 502, 13, 20, 42, 24004, 13, 823, 11, 456, 307, 257, 3037, 411, 1401, 666, 11, 457, 300, 20717, 50852], "temperature": 0.0, "avg_logprob": -0.09936229469849892, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00012332029291428626}, {"id": 288, "seek": 204692, "start": 2056.6800000000003, "end": 2062.12, "text": " into a byte array you've already built instead of building a new string, but it now runs into a", "tokens": [50852, 666, 257, 40846, 10225, 291, 600, 1217, 3094, 2602, 295, 2390, 257, 777, 6798, 11, 457, 309, 586, 6676, 666, 257, 51124], "temperature": 0.0, "avg_logprob": -0.09936229469849892, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00012332029291428626}, {"id": 289, "seek": 204692, "start": 2062.12, "end": 2068.6, "text": " problem. When we do read into or receive into, where does it put the data? At the beginning of the", "tokens": [51124, 1154, 13, 1133, 321, 360, 1401, 666, 420, 4774, 666, 11, 689, 775, 309, 829, 264, 1412, 30, 1711, 264, 2863, 295, 264, 51448], "temperature": 0.0, "avg_logprob": -0.09936229469849892, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00012332029291428626}, {"id": 290, "seek": 204692, "start": 2068.6, "end": 2073.48, "text": " array. And all of our incoming blocks will overwrite each other. What we want as more and more", "tokens": [51448, 10225, 13, 400, 439, 295, 527, 22341, 8474, 486, 670, 21561, 1184, 661, 13, 708, 321, 528, 382, 544, 293, 544, 51692], "temperature": 0.0, "avg_logprob": -0.09936229469849892, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.00012332029291428626}, {"id": 291, "seek": 207348, "start": 2073.48, "end": 2079.48, "text": " of blocks come in from the network is to arrange them along our byte array. So that memory view", "tokens": [50364, 295, 8474, 808, 294, 490, 264, 3209, 307, 281, 9424, 552, 2051, 527, 40846, 10225, 13, 407, 300, 4675, 1910, 50664], "temperature": 0.0, "avg_logprob": -0.08576009891651294, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0014088264433667064}, {"id": 292, "seek": 207348, "start": 2079.48, "end": 2085.4, "text": " slicing expense that I added in its statement to avoid whenever possible in the previous code,", "tokens": [50664, 46586, 18406, 300, 286, 3869, 294, 1080, 5629, 281, 5042, 5699, 1944, 294, 264, 3894, 3089, 11, 50960], "temperature": 0.0, "avg_logprob": -0.08576009891651294, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0014088264433667064}, {"id": 293, "seek": 207348, "start": 2085.4, "end": 2093.2400000000002, "text": " it now becomes mandatory. Again, this ability with a view to write into byte locations that", "tokens": [50960, 309, 586, 3643, 22173, 13, 3764, 11, 341, 3485, 365, 257, 1910, 281, 2464, 666, 40846, 9253, 300, 51352], "temperature": 0.0, "avg_logprob": -0.08576009891651294, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0014088264433667064}, {"id": 294, "seek": 207348, "start": 2093.2400000000002, "end": 2098.12, "text": " aren't at the beginning, but are somewhere in the middle of the byte array that you've built.", "tokens": [51352, 3212, 380, 412, 264, 2863, 11, 457, 366, 4079, 294, 264, 2808, 295, 264, 40846, 10225, 300, 291, 600, 3094, 13, 51596], "temperature": 0.0, "avg_logprob": -0.08576009891651294, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0014088264433667064}, {"id": 295, "seek": 207348, "start": 2098.12, "end": 2102.52, "text": " The first block can go at the beginning, but you need to build a memory view to target the", "tokens": [51596, 440, 700, 3461, 393, 352, 412, 264, 2863, 11, 457, 291, 643, 281, 1322, 257, 4675, 1910, 281, 3779, 264, 51816], "temperature": 0.0, "avg_logprob": -0.08576009891651294, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0014088264433667064}, {"id": 296, "seek": 210252, "start": 2102.6, "end": 2110.84, "text": " second block after the first block, the third block after that, and so forth. And so you need", "tokens": [50368, 1150, 3461, 934, 264, 700, 3461, 11, 264, 2636, 3461, 934, 300, 11, 293, 370, 5220, 13, 400, 370, 291, 643, 50780], "temperature": 0.0, "avg_logprob": -0.12169282332710597, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0001088362987502478}, {"id": 297, "seek": 210252, "start": 2110.84, "end": 2118.28, "text": " to build a memory view and you're going to need to use it to target that receive V into at subsequent", "tokens": [50780, 281, 1322, 257, 4675, 1910, 293, 291, 434, 516, 281, 643, 281, 764, 309, 281, 3779, 300, 4774, 691, 666, 412, 19962, 51152], "temperature": 0.0, "avg_logprob": -0.12169282332710597, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0001088362987502478}, {"id": 298, "seek": 210252, "start": 2119.32, "end": 2125.08, "text": " positions inside of your big byte array. I'm presuming that you know the content", "tokens": [51204, 8432, 1854, 295, 428, 955, 40846, 10225, 13, 286, 478, 18028, 278, 300, 291, 458, 264, 2701, 51492], "temperature": 0.0, "avg_logprob": -0.12169282332710597, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0001088362987502478}, {"id": 299, "seek": 210252, "start": 2125.08, "end": 2129.32, "text": " like the head of time and have preallocated it and you're waiting to fill it with data.", "tokens": [51492, 411, 264, 1378, 295, 565, 293, 362, 659, 336, 905, 770, 309, 293, 291, 434, 3806, 281, 2836, 309, 365, 1412, 13, 51704], "temperature": 0.0, "avg_logprob": -0.12169282332710597, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0001088362987502478}, {"id": 300, "seek": 212932, "start": 2130.28, "end": 2136.28, "text": " This takes about eight tenths of a second because we a bit of a win here because you", "tokens": [50412, 639, 2516, 466, 3180, 27269, 82, 295, 257, 1150, 570, 321, 257, 857, 295, 257, 1942, 510, 570, 291, 50712], "temperature": 0.0, "avg_logprob": -0.07410350732043781, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.000260833534412086}, {"id": 301, "seek": 212932, "start": 2136.28, "end": 2140.76, "text": " haven't had to build a list, you haven't had to call join, you haven't built a bunch of intermediate", "tokens": [50712, 2378, 380, 632, 281, 1322, 257, 1329, 11, 291, 2378, 380, 632, 281, 818, 3917, 11, 291, 2378, 380, 3094, 257, 3840, 295, 19376, 50936], "temperature": 0.0, "avg_logprob": -0.07410350732043781, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.000260833534412086}, {"id": 302, "seek": 212932, "start": 2140.76, "end": 2146.84, "text": " data structures. It actually is a significant win when you need to keep the data that you're", "tokens": [50936, 1412, 9227, 13, 467, 767, 307, 257, 4776, 1942, 562, 291, 643, 281, 1066, 264, 1412, 300, 291, 434, 51240], "temperature": 0.0, "avg_logprob": -0.07410350732043781, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.000260833534412086}, {"id": 303, "seek": 212932, "start": 2146.84, "end": 2153.2400000000002, "text": " reading rather than just immediately passing it back to the OS. Another possibility I saw on", "tokens": [51240, 3760, 2831, 813, 445, 4258, 8437, 309, 646, 281, 264, 12731, 13, 3996, 7959, 286, 1866, 322, 51560], "temperature": 0.0, "avg_logprob": -0.07410350732043781, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.000260833534412086}, {"id": 304, "seek": 212932, "start": 2153.2400000000002, "end": 2158.44, "text": " someone's blog is to do an old fashioned receive of a new string and then try to do a byte array", "tokens": [51560, 1580, 311, 6968, 307, 281, 360, 364, 1331, 40646, 4774, 295, 257, 777, 6798, 293, 550, 853, 281, 360, 257, 40846, 10225, 51820], "temperature": 0.0, "avg_logprob": -0.07410350732043781, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.000260833534412086}, {"id": 305, "seek": 215844, "start": 2158.44, "end": 2165.08, "text": " extend to grow your byte array with these new strings. It copies the data twice but does get", "tokens": [50364, 10101, 281, 1852, 428, 40846, 10225, 365, 613, 777, 13985, 13, 467, 14341, 264, 1412, 6091, 457, 775, 483, 50696], "temperature": 0.0, "avg_logprob": -0.07850894793658189, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.000625843764282763}, {"id": 306, "seek": 215844, "start": 2165.08, "end": 2172.28, "text": " rid of that join concatenation. It looks something like this, data.extend down there near the bottom.", "tokens": [50696, 3973, 295, 300, 3917, 1588, 7186, 399, 13, 467, 1542, 746, 411, 341, 11, 1412, 13, 3828, 521, 760, 456, 2651, 264, 2767, 13, 51056], "temperature": 0.0, "avg_logprob": -0.07850894793658189, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.000625843764282763}, {"id": 307, "seek": 215844, "start": 2173.2400000000002, "end": 2181.0, "text": " It is not a win over the normal way of using byte arrays because it turns out byte array extend", "tokens": [51104, 467, 307, 406, 257, 1942, 670, 264, 2710, 636, 295, 1228, 40846, 41011, 570, 309, 4523, 484, 40846, 10225, 10101, 51492], "temperature": 0.0, "avg_logprob": -0.07850894793658189, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.000625843764282763}, {"id": 308, "seek": 218100, "start": 2181.0, "end": 2189.48, "text": " is pretty inefficient. It asks for an iterator over its argument and then calls the iterator's", "tokens": [50364, 307, 1238, 43495, 13, 467, 8962, 337, 364, 17138, 1639, 670, 1080, 6770, 293, 550, 5498, 264, 17138, 1639, 311, 50788], "temperature": 0.0, "avg_logprob": -0.10020371370537337, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.02714451216161251}, {"id": 309, "seek": 218100, "start": 2189.48, "end": 2195.32, "text": " next function over and over for every byte and then asks the int object what its value is", "tokens": [50788, 958, 2445, 670, 293, 670, 337, 633, 40846, 293, 550, 8962, 264, 560, 2657, 437, 1080, 2158, 307, 51080], "temperature": 0.0, "avg_logprob": -0.10020371370537337, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.02714451216161251}, {"id": 310, "seek": 218100, "start": 2196.2, "end": 2202.44, "text": " so that it can then put it in an intermediate array and that involves having to increment and", "tokens": [51124, 370, 300, 309, 393, 550, 829, 309, 294, 364, 19376, 10225, 293, 300, 11626, 1419, 281, 26200, 293, 51436], "temperature": 0.0, "avg_logprob": -0.10020371370537337, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.02714451216161251}, {"id": 311, "seek": 218100, "start": 2202.44, "end": 2207.16, "text": " decrement the reference pointer of the integer it's given and by the time you're done you can", "tokens": [51436, 6853, 518, 264, 6408, 23918, 295, 264, 24922, 309, 311, 2212, 293, 538, 264, 565, 291, 434, 1096, 291, 393, 51672], "temperature": 0.0, "avg_logprob": -0.10020371370537337, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.02714451216161251}, {"id": 312, "seek": 220716, "start": 2207.24, "end": 2212.6, "text": " compute that you've done at least 40 bytes of bandwidth to RAM even ignoring the instructions", "tokens": [50368, 14722, 300, 291, 600, 1096, 412, 1935, 3356, 36088, 295, 23647, 281, 14561, 754, 26258, 264, 9415, 50636], "temperature": 0.0, "avg_logprob": -0.07546985580260496, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.002630052389577031}, {"id": 313, "seek": 220716, "start": 2212.6, "end": 2219.64, "text": " and stacks and arguments that are passing in order to get that single byte value extended onto the", "tokens": [50636, 293, 30792, 293, 12869, 300, 366, 8437, 294, 1668, 281, 483, 300, 2167, 40846, 2158, 10913, 3911, 264, 50988], "temperature": 0.0, "avg_logprob": -0.07546985580260496, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.002630052389577031}, {"id": 314, "seek": 220716, "start": 2219.64, "end": 2227.7999999999997, "text": " end of your byte array plus it doesn't write to your byte array. It writes to an intermediate", "tokens": [50988, 917, 295, 428, 40846, 10225, 1804, 309, 1177, 380, 2464, 281, 428, 40846, 10225, 13, 467, 13657, 281, 364, 19376, 51396], "temperature": 0.0, "avg_logprob": -0.07546985580260496, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.002630052389577031}, {"id": 315, "seek": 220716, "start": 2227.7999999999997, "end": 2232.2799999999997, "text": " buffer that it grows dynamically and then does the append when it's done so that should that", "tokens": [51396, 21762, 300, 309, 13156, 43492, 293, 550, 775, 264, 34116, 562, 309, 311, 1096, 370, 300, 820, 300, 51620], "temperature": 0.0, "avg_logprob": -0.07546985580260496, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.002630052389577031}, {"id": 316, "seek": 223228, "start": 2232.36, "end": 2238.28, "text": " iteration die part way through you don't wind up having modified the byte array some it wants to", "tokens": [50368, 24784, 978, 644, 636, 807, 291, 500, 380, 2468, 493, 1419, 15873, 264, 40846, 10225, 512, 309, 2738, 281, 50664], "temperature": 0.0, "avg_logprob": -0.10924875217935313, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.005216663703322411}, {"id": 317, "seek": 223228, "start": 2238.28, "end": 2244.6800000000003, "text": " either succeed or fail as an atomic operation so that's why it's kind of slow kind of klugey", "tokens": [50664, 2139, 7754, 420, 3061, 382, 364, 22275, 6916, 370, 300, 311, 983, 309, 311, 733, 295, 2964, 733, 295, 350, 2781, 432, 88, 50984], "temperature": 0.0, "avg_logprob": -0.10924875217935313, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.005216663703322411}, {"id": 318, "seek": 223228, "start": 2245.6400000000003, "end": 2251.6400000000003, "text": " but seeing that blog post made me ask a question does the byte array have an append operation", "tokens": [51032, 457, 2577, 300, 6968, 2183, 1027, 385, 1029, 257, 1168, 775, 264, 40846, 10225, 362, 364, 34116, 6916, 51332], "temperature": 0.0, "avg_logprob": -0.10924875217935313, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.005216663703322411}, {"id": 319, "seek": 223228, "start": 2251.6400000000003, "end": 2257.2400000000002, "text": " that's any good? I mean surely the people writing it knew that we'd want to do that without spinning", "tokens": [51332, 300, 311, 604, 665, 30, 286, 914, 11468, 264, 561, 3579, 309, 2586, 300, 321, 1116, 528, 281, 360, 300, 1553, 15640, 51612], "temperature": 0.0, "avg_logprob": -0.10924875217935313, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.005216663703322411}, {"id": 320, "seek": 225724, "start": 2257.24, "end": 2265.0, "text": " up an iterator and calling it 1500 times does it have an operation that's really good and yes it", "tokens": [50364, 493, 364, 17138, 1639, 293, 5141, 309, 22671, 1413, 775, 309, 362, 364, 6916, 300, 311, 534, 665, 293, 2086, 309, 50752], "temperature": 0.0, "avg_logprob": -0.09491247665591357, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.001986811636015773}, {"id": 321, "seek": 225724, "start": 2265.0, "end": 2273.08, "text": " does I read the c code to find it now think about it where would you put the real extend operator", "tokens": [50752, 775, 286, 1401, 264, 269, 3089, 281, 915, 309, 586, 519, 466, 309, 689, 576, 291, 829, 264, 957, 10101, 12973, 51156], "temperature": 0.0, "avg_logprob": -0.09491247665591357, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.001986811636015773}, {"id": 322, "seek": 225724, "start": 2273.08, "end": 2279.8799999999997, "text": " the real ability to make your byte array longer obviously you'd hide it behind the operator", "tokens": [51156, 264, 957, 3485, 281, 652, 428, 40846, 10225, 2854, 2745, 291, 1116, 6479, 309, 2261, 264, 12973, 51496], "temperature": 0.0, "avg_logprob": -0.09491247665591357, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.001986811636015773}, {"id": 323, "seek": 225724, "start": 2279.8799999999997, "end": 2284.9199999999996, "text": " that we've spent 20 years telling people to never use with string values", "tokens": [51496, 300, 321, 600, 4418, 945, 924, 3585, 561, 281, 1128, 764, 365, 6798, 4190, 51748], "temperature": 0.0, "avg_logprob": -0.09491247665591357, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.001986811636015773}, {"id": 324, "seek": 228724, "start": 2288.12, "end": 2296.6, "text": " this might be so difficult that some of you will never do it but if you can convince yourself to", "tokens": [50408, 341, 1062, 312, 370, 2252, 300, 512, 295, 291, 486, 1128, 360, 309, 457, 498, 291, 393, 13447, 1803, 281, 50832], "temperature": 0.0, "avg_logprob": -0.10865616798400879, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.00026924198027700186}, {"id": 325, "seek": 228724, "start": 2296.6, "end": 2304.04, "text": " type this after all of this time this is actually something that byte arrays do magnificently just", "tokens": [50832, 2010, 341, 934, 439, 295, 341, 565, 341, 307, 767, 746, 300, 40846, 41011, 360, 21623, 2276, 445, 51204], "temperature": 0.0, "avg_logprob": -0.10865616798400879, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.00026924198027700186}, {"id": 326, "seek": 228724, "start": 2304.04, "end": 2312.3599999999997, "text": " plus equal the additional data to your byte array and you will be even receive into's ability", "tokens": [51204, 1804, 2681, 264, 4497, 1412, 281, 428, 40846, 10225, 293, 291, 486, 312, 754, 4774, 666, 311, 3485, 51620], "temperature": 0.0, "avg_logprob": -0.10865616798400879, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.00026924198027700186}, {"id": 327, "seek": 231236, "start": 2312.36, "end": 2319.7200000000003, "text": " to grow your array with data so this case where we need to accumulate and keep the whole pay road", "tokens": [50364, 281, 1852, 428, 10225, 365, 1412, 370, 341, 1389, 689, 321, 643, 281, 33384, 293, 1066, 264, 1379, 1689, 3060, 50732], "temperature": 0.0, "avg_logprob": -0.08001698504437457, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.005382745526731014}, {"id": 328, "seek": 231236, "start": 2319.7200000000003, "end": 2325.2400000000002, "text": " is a real win for the byte array in all of the approaches and there don't seem to be sharp edges", "tokens": [50732, 307, 257, 957, 1942, 337, 264, 40846, 10225, 294, 439, 295, 264, 11587, 293, 456, 500, 380, 1643, 281, 312, 8199, 8819, 51008], "temperature": 0.0, "avg_logprob": -0.08001698504437457, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.005382745526731014}, {"id": 329, "seek": 231236, "start": 2325.2400000000002, "end": 2332.76, "text": " that can suddenly make it behave much worse than the the list and joint 33 speed up in that last", "tokens": [51008, 300, 393, 5800, 652, 309, 15158, 709, 5324, 813, 264, 264, 1329, 293, 7225, 11816, 3073, 493, 294, 300, 1036, 51384], "temperature": 0.0, "avg_logprob": -0.08001698504437457, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.005382745526731014}, {"id": 330, "seek": 231236, "start": 2332.76, "end": 2339.8, "text": " version of the algorithm and cleaner code I mean admit it you've always wanted to just plus equal", "tokens": [51384, 3037, 295, 264, 9284, 293, 16532, 3089, 286, 914, 9796, 309, 291, 600, 1009, 1415, 281, 445, 1804, 2681, 51736], "temperature": 0.0, "avg_logprob": -0.08001698504437457, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.005382745526731014}, {"id": 331, "seek": 233980, "start": 2339.8, "end": 2344.84, "text": " haven't you it's the natural way to write it in python and this is one of those neat intersections", "tokens": [50364, 2378, 380, 291, 309, 311, 264, 3303, 636, 281, 2464, 309, 294, 38797, 293, 341, 307, 472, 295, 729, 10654, 47664, 50616], "temperature": 0.0, "avg_logprob": -0.045771842307232795, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00348028726875782}, {"id": 332, "seek": 233980, "start": 2344.84, "end": 2353.2400000000002, "text": " of the fast way with the way that looks good on the page as well so I'm not going to talk about", "tokens": [50616, 295, 264, 2370, 636, 365, 264, 636, 300, 1542, 665, 322, 264, 3028, 382, 731, 370, 286, 478, 406, 516, 281, 751, 466, 51036], "temperature": 0.0, "avg_logprob": -0.045771842307232795, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00348028726875782}, {"id": 333, "seek": 233980, "start": 2353.2400000000002, "end": 2357.7200000000003, "text": " send you might think I'll now get into the fact that send doesn't always send the whole payload", "tokens": [51036, 2845, 291, 1062, 519, 286, 603, 586, 483, 666, 264, 1186, 300, 2845, 1177, 380, 1009, 2845, 264, 1379, 30918, 51260], "temperature": 0.0, "avg_logprob": -0.045771842307232795, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00348028726875782}, {"id": 334, "seek": 233980, "start": 2357.7200000000003, "end": 2363.7200000000003, "text": " but python has long had you covered here python sockets have for a very long time had a send", "tokens": [51260, 457, 38797, 575, 938, 632, 291, 5343, 510, 38797, 370, 11984, 362, 337, 257, 588, 938, 565, 632, 257, 2845, 51560], "temperature": 0.0, "avg_logprob": -0.045771842307232795, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00348028726875782}, {"id": 335, "seek": 236372, "start": 2363.72, "end": 2371.08, "text": " all that sits in a loop in c sending shorter and shorter tails of your data until finally the os", "tokens": [50364, 439, 300, 12696, 294, 257, 6367, 294, 269, 7750, 11639, 293, 11639, 28537, 295, 428, 1412, 1826, 2721, 264, 3003, 50732], "temperature": 0.0, "avg_logprob": -0.07336134857006288, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.027133099734783173}, {"id": 336, "seek": 236372, "start": 2372.68, "end": 2377.56, "text": " buffers have been able to receive it all so I don't see that we need byte arrays for that", "tokens": [50812, 9204, 433, 362, 668, 1075, 281, 4774, 309, 439, 370, 286, 500, 380, 536, 300, 321, 643, 40846, 41011, 337, 300, 51056], "temperature": 0.0, "avg_logprob": -0.07336134857006288, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.027133099734783173}, {"id": 337, "seek": 236372, "start": 2377.56, "end": 2384.6, "text": " and I can declare the byte array the winner if you need an accumulator if you need to very quickly", "tokens": [51056, 293, 286, 393, 19710, 264, 40846, 10225, 264, 8507, 498, 291, 643, 364, 12989, 16381, 498, 291, 643, 281, 588, 2661, 51408], "temperature": 0.0, "avg_logprob": -0.07336134857006288, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.027133099734783173}, {"id": 338, "seek": 236372, "start": 2384.6, "end": 2391.3999999999996, "text": " in a performance sensitive environment accumulate a lot of incoming data it is a noticeably good", "tokens": [51408, 294, 257, 3389, 9477, 2823, 33384, 257, 688, 295, 22341, 1412, 309, 307, 257, 3449, 1188, 665, 51748], "temperature": 0.0, "avg_logprob": -0.07336134857006288, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.027133099734783173}, {"id": 339, "seek": 239140, "start": 2391.4, "end": 2397.1600000000003, "text": " win with two different techniques that work pretty well I'll briefly mention that some people want", "tokens": [50364, 1942, 365, 732, 819, 7512, 300, 589, 1238, 731, 286, 603, 10515, 2152, 300, 512, 561, 528, 50652], "temperature": 0.0, "avg_logprob": -0.06898642611759966, "compression_ratio": 1.748878923766816, "no_speech_prob": 0.006286772433668375}, {"id": 340, "seek": 239140, "start": 2397.1600000000003, "end": 2402.6, "text": " a freestyle mutable string when they see the byte array they don't think of io they don't think of", "tokens": [50652, 257, 40910, 5839, 712, 6798, 562, 436, 536, 264, 40846, 10225, 436, 500, 380, 519, 295, 19785, 436, 500, 380, 519, 295, 50924], "temperature": 0.0, "avg_logprob": -0.06898642611759966, "compression_ratio": 1.748878923766816, "no_speech_prob": 0.006286772433668375}, {"id": 341, "seek": 239140, "start": 2402.6, "end": 2409.48, "text": " bloom filters and bit vectors they want to mess with a string they want a string that they can just", "tokens": [50924, 26899, 15995, 293, 857, 18875, 436, 528, 281, 2082, 365, 257, 6798, 436, 528, 257, 6798, 300, 436, 393, 445, 51268], "temperature": 0.0, "avg_logprob": -0.06898642611759966, "compression_ratio": 1.748878923766816, "no_speech_prob": 0.006286772433668375}, {"id": 342, "seek": 239140, "start": 2409.48, "end": 2417.4, "text": " change and all ish I have not found yet a good use for this and I'll sort of show you why it", "tokens": [51268, 1319, 293, 439, 307, 71, 286, 362, 406, 1352, 1939, 257, 665, 764, 337, 341, 293, 286, 603, 1333, 295, 855, 291, 983, 309, 51664], "temperature": 0.0, "avg_logprob": -0.06898642611759966, "compression_ratio": 1.748878923766816, "no_speech_prob": 0.006286772433668375}, {"id": 343, "seek": 241740, "start": 2417.4, "end": 2424.12, "text": " winds up being awkward you want to change part of a payload before using storing or retransmitting", "tokens": [50364, 17765, 493, 885, 11411, 291, 528, 281, 1319, 644, 295, 257, 30918, 949, 1228, 26085, 420, 23106, 599, 76, 2414, 50700], "temperature": 0.0, "avg_logprob": -0.06492996215820312, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.007571886293590069}, {"id": 344, "seek": 241740, "start": 2424.12, "end": 2427.8, "text": " that would be the use case here because if you want to lowercase the whole thing you have to", "tokens": [50700, 300, 576, 312, 264, 764, 1389, 510, 570, 498, 291, 528, 281, 3126, 9765, 264, 1379, 551, 291, 362, 281, 50884], "temperature": 0.0, "avg_logprob": -0.06492996215820312, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.007571886293590069}, {"id": 345, "seek": 241740, "start": 2427.8, "end": 2432.6, "text": " touch all the bytes anyway so you might as well build a new one good thing is that the byte array", "tokens": [50884, 2557, 439, 264, 36088, 4033, 370, 291, 1062, 382, 731, 1322, 257, 777, 472, 665, 551, 307, 300, 264, 40846, 10225, 51124], "temperature": 0.0, "avg_logprob": -0.06492996215820312, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.007571886293590069}, {"id": 346, "seek": 241740, "start": 2432.6, "end": 2438.6, "text": " is mutable you can get it and change it but none of the methods that it shares with strings", "tokens": [51124, 307, 5839, 712, 291, 393, 483, 309, 293, 1319, 309, 457, 6022, 295, 264, 7150, 300, 309, 12182, 365, 13985, 51424], "temperature": 0.0, "avg_logprob": -0.06492996215820312, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.007571886293590069}, {"id": 347, "seek": 241740, "start": 2439.64, "end": 2446.92, "text": " do mutation to it if you call dot upper on your byte array you get a new byte array so you have", "tokens": [51476, 360, 27960, 281, 309, 498, 291, 818, 5893, 6597, 322, 428, 40846, 10225, 291, 483, 257, 777, 40846, 10225, 370, 291, 362, 51840], "temperature": 0.0, "avg_logprob": -0.06492996215820312, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.007571886293590069}, {"id": 348, "seek": 244692, "start": 2446.92, "end": 2454.76, "text": " a mutable string type that does nothing string like mutably a byte array only changes when subjected", "tokens": [50364, 257, 5839, 712, 6798, 2010, 300, 775, 1825, 6798, 411, 5839, 1188, 257, 40846, 10225, 787, 2962, 562, 32153, 50756], "temperature": 0.0, "avg_logprob": -0.04394713342189789, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.0004236206877976656}, {"id": 349, "seek": 244692, "start": 2454.76, "end": 2461.88, "text": " to list like operations like assignment to an index or assignment to a slice or dot clear", "tokens": [50756, 281, 1329, 411, 7705, 411, 15187, 281, 364, 8186, 420, 15187, 281, 257, 13153, 420, 5893, 1850, 51112], "temperature": 0.0, "avg_logprob": -0.04394713342189789, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.0004236206877976656}, {"id": 350, "seek": 244692, "start": 2461.88, "end": 2466.92, "text": " and so the result if you try writing a network algorithm or something with this is curious", "tokens": [51112, 293, 370, 264, 1874, 498, 291, 853, 3579, 257, 3209, 9284, 420, 746, 365, 341, 307, 6369, 51364], "temperature": 0.0, "avg_logprob": -0.04394713342189789, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.0004236206877976656}, {"id": 351, "seek": 244692, "start": 2466.92, "end": 2473.64, "text": " you have a mutable string that alas does no mutation precisely when you start calling", "tokens": [51364, 291, 362, 257, 5839, 712, 6798, 300, 419, 296, 775, 572, 27960, 13402, 562, 291, 722, 5141, 51700], "temperature": 0.0, "avg_logprob": -0.04394713342189789, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.0004236206877976656}, {"id": 352, "seek": 247364, "start": 2473.64, "end": 2480.6, "text": " its string methods want to lowercase a word well you're going to have to make a copy to call lower", "tokens": [50364, 1080, 6798, 7150, 528, 281, 3126, 9765, 257, 1349, 731, 291, 434, 516, 281, 362, 281, 652, 257, 5055, 281, 818, 3126, 50712], "temperature": 0.0, "avg_logprob": -0.06148783715216668, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.0006260991212911904}, {"id": 353, "seek": 247364, "start": 2480.6, "end": 2486.44, "text": " on you're going to have to do slicing giving you a copy call lower making another copy and then", "tokens": [50712, 322, 291, 434, 516, 281, 362, 281, 360, 46586, 2902, 291, 257, 5055, 818, 3126, 1455, 1071, 5055, 293, 550, 51004], "temperature": 0.0, "avg_logprob": -0.06148783715216668, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.0006260991212911904}, {"id": 354, "seek": 247364, "start": 2486.44, "end": 2493.24, "text": " assignment to copy it a third time back into the data structure in order to get that accomplished", "tokens": [51004, 15187, 281, 5055, 309, 257, 2636, 565, 646, 666, 264, 1412, 3877, 294, 1668, 281, 483, 300, 15419, 51344], "temperature": 0.0, "avg_logprob": -0.06148783715216668, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.0006260991212911904}, {"id": 355, "seek": 247364, "start": 2493.24, "end": 2499.7999999999997, "text": " there isn't I looked there isn't a lower into and an upper into that would let you do smaller", "tokens": [51344, 456, 1943, 380, 286, 2956, 456, 1943, 380, 257, 3126, 666, 293, 364, 6597, 666, 300, 576, 718, 291, 360, 4356, 51672], "temperature": 0.0, "avg_logprob": -0.06148783715216668, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.0006260991212911904}, {"id": 356, "seek": 249980, "start": 2499.8, "end": 2505.7200000000003, "text": " grained uh manipulations that wrote directly to your new byte array can the memory view save us", "tokens": [50364, 1295, 2001, 2232, 9258, 4136, 300, 4114, 3838, 281, 428, 777, 40846, 10225, 393, 264, 4675, 1910, 3155, 505, 50660], "temperature": 0.0, "avg_logprob": -0.04890845287805316, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.0013241791166365147}, {"id": 357, "seek": 249980, "start": 2505.7200000000003, "end": 2515.5600000000004, "text": " though it did in all of the previous occasions no because memory views don't do anything string", "tokens": [50660, 1673, 309, 630, 294, 439, 295, 264, 3894, 20641, 572, 570, 4675, 6809, 500, 380, 360, 1340, 6798, 51152], "temperature": 0.0, "avg_logprob": -0.04890845287805316, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.0013241791166365147}, {"id": 358, "seek": 249980, "start": 2515.5600000000004, "end": 2521.5600000000004, "text": " like the moment you move to a memory view which lets you look at a piece of string efficiently", "tokens": [51152, 411, 264, 1623, 291, 1286, 281, 257, 4675, 1910, 597, 6653, 291, 574, 412, 257, 2522, 295, 6798, 19621, 51452], "temperature": 0.0, "avg_logprob": -0.04890845287805316, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.0013241791166365147}, {"id": 359, "seek": 249980, "start": 2522.52, "end": 2527.2400000000002, "text": " you're not going to be able to do anything string like to it so you have to do a round", "tokens": [51500, 291, 434, 406, 516, 281, 312, 1075, 281, 360, 1340, 6798, 411, 281, 309, 370, 291, 362, 281, 360, 257, 3098, 51736], "temperature": 0.0, "avg_logprob": -0.04890845287805316, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.0013241791166365147}, {"id": 360, "seek": 252724, "start": 2527.24, "end": 2536.3599999999997, "text": " trip out to a smaller string to do a manipulation and store data back to mutate a byte array without", "tokens": [50364, 4931, 484, 281, 257, 4356, 6798, 281, 360, 257, 26475, 293, 3531, 1412, 646, 281, 5839, 473, 257, 40846, 10225, 1553, 50820], "temperature": 0.0, "avg_logprob": -0.055400454479715096, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.0010474910959601402}, {"id": 361, "seek": 252724, "start": 2536.3599999999997, "end": 2542.04, "text": " rewriting its whole content you're going to need indexes do you remember indexes back the first", "tokens": [50820, 319, 19868, 1080, 1379, 2701, 291, 434, 516, 281, 643, 8186, 279, 360, 291, 1604, 8186, 279, 646, 264, 700, 51104], "temperature": 0.0, "avg_logprob": -0.055400454479715096, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.0010474910959601402}, {"id": 362, "seek": 252724, "start": 2542.04, "end": 2548.6, "text": " week before you'd found split strip and join and we're like doing everything like this you get to", "tokens": [51104, 1243, 949, 291, 1116, 1352, 7472, 12828, 293, 3917, 293, 321, 434, 411, 884, 1203, 411, 341, 291, 483, 281, 51432], "temperature": 0.0, "avg_logprob": -0.055400454479715096, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.0010474910959601402}, {"id": 363, "seek": 252724, "start": 2548.6, "end": 2554.2799999999997, "text": " do it again if you decide to try mutating a byte array the byte array will let you enjoy those", "tokens": [51432, 360, 309, 797, 498, 291, 4536, 281, 853, 5839, 990, 257, 40846, 10225, 264, 40846, 10225, 486, 718, 291, 2103, 729, 51716], "temperature": 0.0, "avg_logprob": -0.055400454479715096, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.0010474910959601402}, {"id": 364, "seek": 255428, "start": 2554.28, "end": 2560.92, "text": " days all over again because all the mutation operations are powered only by indexes one hint", "tokens": [50364, 1708, 439, 670, 797, 570, 439, 264, 27960, 7705, 366, 17786, 787, 538, 8186, 279, 472, 12075, 50696], "temperature": 0.0, "avg_logprob": -0.08040185769399007, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0031690753530710936}, {"id": 365, "seek": 255428, "start": 2560.92, "end": 2567.4, "text": " regular expressions while they turned off a lot of other string like things were left turned on", "tokens": [50696, 3890, 15277, 1339, 436, 3574, 766, 257, 688, 295, 661, 6798, 411, 721, 645, 1411, 3574, 322, 51020], "temperature": 0.0, "avg_logprob": -0.08040185769399007, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0031690753530710936}, {"id": 366, "seek": 255428, "start": 2567.4, "end": 2574.1200000000003, "text": " and do work against byte arrays and can help give you some useful indexes to use freestyle", "tokens": [51020, 293, 360, 589, 1970, 40846, 41011, 293, 393, 854, 976, 291, 512, 4420, 8186, 279, 281, 764, 40910, 51356], "temperature": 0.0, "avg_logprob": -0.08040185769399007, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0031690753530710936}, {"id": 367, "seek": 255428, "start": 2574.1200000000003, "end": 2581.7200000000003, "text": " mutable string it's awkward I have here at the end of the slides some uh links and pointers to other", "tokens": [51356, 5839, 712, 6798, 309, 311, 11411, 286, 362, 510, 412, 264, 917, 295, 264, 9788, 512, 2232, 6123, 293, 44548, 281, 661, 51736], "temperature": 0.0, "avg_logprob": -0.08040185769399007, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.0031690753530710936}, {"id": 368, "seek": 258172, "start": 2581.72, "end": 2586.9199999999996, "text": " documentation including the blog posts that inspired this talk and made me want to bring", "tokens": [50364, 14333, 3009, 264, 6968, 12300, 300, 7547, 341, 751, 293, 1027, 385, 528, 281, 1565, 50624], "temperature": 0.0, "avg_logprob": -0.0893200837172471, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0020810358691960573}, {"id": 369, "seek": 258172, "start": 2586.9199999999996, "end": 2593.72, "text": " everything together in one place in conclusion the byte array it is a very memory efficient", "tokens": [50624, 1203, 1214, 294, 472, 1081, 294, 10063, 264, 40846, 10225, 309, 307, 257, 588, 4675, 7148, 50964], "temperature": 0.0, "avg_logprob": -0.0893200837172471, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0020810358691960573}, {"id": 370, "seek": 258172, "start": 2593.72, "end": 2601.0, "text": " not faster but memory efficient store of byte integers should you ever need them it can help", "tokens": [50964, 406, 4663, 457, 4675, 7148, 3531, 295, 40846, 41674, 820, 291, 1562, 643, 552, 309, 393, 854, 51328], "temperature": 0.0, "avg_logprob": -0.0893200837172471, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0020810358691960573}, {"id": 371, "seek": 258172, "start": 2601.0, "end": 2606.68, "text": " control memory fragmentation when doing uh high-performance i o because you don't have to create", "tokens": [51328, 1969, 4675, 9241, 19631, 562, 884, 2232, 1090, 12, 50242, 741, 277, 570, 291, 500, 380, 362, 281, 1884, 51612], "temperature": 0.0, "avg_logprob": -0.0893200837172471, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0020810358691960573}, {"id": 372, "seek": 260668, "start": 2606.68, "end": 2613.24, "text": " a new string but it's hard to make it faster in a reliable way be careful it's a great way to", "tokens": [50364, 257, 777, 6798, 457, 309, 311, 1152, 281, 652, 309, 4663, 294, 257, 12924, 636, 312, 5026, 309, 311, 257, 869, 636, 281, 50692], "temperature": 0.0, "avg_logprob": -0.038843240056719096, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.009696886874735355}, {"id": 373, "seek": 260668, "start": 2613.24, "end": 2618.8399999999997, "text": " accumulate data that's coming in a piece at a time that's its real superpower and though it's", "tokens": [50692, 33384, 1412, 300, 311, 1348, 294, 257, 2522, 412, 257, 565, 300, 311, 1080, 957, 45765, 293, 1673, 309, 311, 50972], "temperature": 0.0, "avg_logprob": -0.038843240056719096, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.009696886874735355}, {"id": 374, "seek": 260668, "start": 2618.8399999999997, "end": 2626.04, "text": " very tempting for string operations it's also a bit underpowered and a bit awkward that's what", "tokens": [50972, 588, 37900, 337, 6798, 7705, 309, 311, 611, 257, 857, 833, 27178, 293, 257, 857, 11411, 300, 311, 437, 51332], "temperature": 0.0, "avg_logprob": -0.038843240056719096, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.009696886874735355}, {"id": 375, "seek": 262604, "start": 2626.04, "end": 2644.84, "text": " I've learned so far thank you very much we are out of time so I will meet interested byte array", "tokens": [50364, 286, 600, 3264, 370, 1400, 1309, 291, 588, 709, 321, 366, 484, 295, 565, 370, 286, 486, 1677, 3102, 40846, 10225, 51304], "temperature": 0.0, "avg_logprob": -0.18164642333984374, "compression_ratio": 1.1585365853658536, "no_speech_prob": 0.004603974521160126}, {"id": 376, "seek": 264484, "start": 2644.84, "end": 2657.6400000000003, "text": " fans outside the door in a few minutes", "tokens": [50364, 4499, 2380, 264, 2853, 294, 257, 1326, 2077, 51004], "temperature": 0.0, "avg_logprob": -0.2774893804029985, "compression_ratio": 0.8260869565217391, "no_speech_prob": 0.36315807700157166}], "language": "en"}