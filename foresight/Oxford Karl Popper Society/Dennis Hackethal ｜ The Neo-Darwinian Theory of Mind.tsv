start	end	text
0	11080	So everyone can hear me then. Good afternoon. I'm very pleased to announce their speaker
11080	17240	today is Dennis Hackenthal, who is a software engineer, artificial intelligence researcher
17240	22680	and author of the book, A Window on Intelligence. And today we'll speak about the role of replicators
22680	28400	in creativity, a topic in which Dennis has written for Conjection Magazine in an article
28400	33280	called The Neodorinian Theory of Mind, which we've linked to on Twitter and which we'll
33280	39280	link to in the video as well. And I should also say that I think Conjection Magazine
39280	45080	is open to pictures from writers, for those of you who are interested in possibly contributing
45080	50960	an article to the website. And in general, I also really recommend checking out Conjection
50960	58200	Magazine, I think is a great initiative. And yeah, with that introduction, I give the floor
58200	62280	to Dennis. Dennis, thanks so much for joining us. And I look forward to your talk.
62280	68400	Hi, I'm glad to be here. It was very nice of you to invite me. And I should also mention
68400	71640	Logan Chipkin, who I think is behind this. So shout out to him as well.
71640	74560	Yeah, shout out to Logan.
74560	79960	Yeah, so I'm here to talk about what I call the Neodorinian Theory of Mind. Before I start,
79960	86160	I should say that to give credit where credit is due, I'm indebted to Karl Popper and David
86200	90320	Deutsch, because without their epistemological work, I could never have thought of what I'm
90320	95200	about to tell you. And also Richard Dawkins, who's influenced my thinking on evolution
95200	103320	quite a bit. And it occurred to me recently that maybe the Neodorinian Theory of the Mind
103320	108440	is much too grand a term. I think maybe it should be called the Neodorinian aspect of
108440	112520	the mind or the Neodorinian approach to the mind or something like that. I think that
112560	119520	would be a better name because I think theories of the mind are a dime a dozen and none of
119520	125440	them work. And otherwise, we could already build AGI, artificial general intelligence.
125440	133680	And so it might be better to choose a smaller name than that. But also there's some construction
133680	140760	going on outside. So apologies if you hear anything, if there's any noise. But yeah.
140800	146120	So the meat of the theory of the approach or whatever you want to call it is very simple.
148680	156320	But it does take just a moment to kind of sneak up on it. And so in the papyrian fashion,
156320	163000	what I'd like to do is I'd like to start with some problems. Some problems that I like to
163000	170600	think that the theory or the approach solves are, for example, one, how does the mind create
170600	179480	new conjectures? Two, how does memory work? Which includes things like why do we forget
179480	184440	things? Why are memories so unreliable? Why do some memories last longer than others? Those
184440	192320	kinds of things. And how did people evolve? And then lastly, I want to give by no means
192320	197200	any theories just some small pointers for why I think we are conscious of some things
197240	202880	and not of others. It's interesting to note that originally I only set out to solve the
202880	206880	problem of how people evolved. And then I later found that this approach also allows me to
206880	214280	solve these other problems. So I only have a few slides. This is the last slide. I'll leave
214280	223360	this open. I want to give, I actually want to start in biology. And then I'll tie this back in
223360	228840	with a mind later on. I promise they're related. And I'd like to talk about the origin of life
228840	236760	for a moment. And many have said that what happened there was so unlikely and incredible. It's
236760	243280	almost too good to be true that that happened. And as far as I understand it, there are still
243280	248760	some mysteries around it, what exactly happened there. But there are some good explanations
248840	254920	that I think give us a pretty good idea of what may have happened. And the theory that I
254920	262680	subscribe to is called the RNA world hypothesis. And the idea is basically that a long, long time
262680	269880	ago when the Earth had just formed, the oceans were still highly chemically active. And there were
269880	278720	molecules forming spontaneously in those oceans and disintegrating. And it was a big mess. It was
278760	286080	a big chaos in this so-called primordial soup. And what some of those molecules were is they were
286120	292040	enzymes, they were chemical catalysts. And what that means is that they were able to, they were,
292040	297560	they were able to cause a change in other molecules, for example, while retaining the ability to cause
297560	306080	those changes again at a later time, they didn't undergo any changes themselves. And what happened
306080	314760	then, so to say, that some of these molecules happened to, to cause chemical reactions that
314800	320840	produced some of their own components. So that in this primordial soup, over time, you would get
320840	326160	more and more of the building blocks of which these molecules themselves were made. And so what
326160	332240	I'm kind of sneaking up on is the role of replication in biological evolution. Because once
332240	339800	these molecules, once these enzymes get targeted enough, it makes sense to call them
339800	347200	replicators, because that is what they end up doing. They create a copy of themselves. So the
347200	354400	idea is that this way, gradually, we get replication happening in the primordial soup. But
354400	360840	this alone isn't enough for evolution to occur. You also need variation in selection. But I think
360840	369000	once you have replication, variation is bound to happen sooner or later, because replication is
369000	374440	not going to be perfect forever. And sooner or later, the replicators are going to make a mistake
374440	384640	during replication. And this is what introduces variants. And what you get then is you have, if
384640	390600	the variant is even fit enough still to keep replicating, what you get then is you have slightly
390600	395520	different kind of replicator. And if that is still able to replicate, now what you're getting is
395520	399800	you're getting two different pockets of this population. One pocket of the population is still
399800	406040	the old replicator, the copies of that replicator. And the new pocket of the population is this new
406040	411680	kind of replicator. And so then the question is, well, which one is better at replicating than
412560	420960	the other? And these differences in the rate of replication is what we call selection. I think
420960	428280	Richard Dawkins in his book, The Selfish Gene, I think he uses the technical term as the non-random
428280	437240	differential reproduction rate or something. And usually, because a replicator is already adapted
437240	443480	to replicating, that means that any variant, if a mutation is going to occur, more often than not,
443480	448960	it's going to be worse at replicating. So usually, you could expect that if the replicator mutates,
448960	459640	the mutant variant is going to have a harder time replicating. Because by definition, this is how
459640	465560	William Paley, I think, defined adaptation, something is adapted to something, for example,
465560	469480	replication, that by definition means that if you make any slight change to it, it's going to get
469480	477960	worse. It's very difficult to get it to make it better. But every now and then, a mutation can
477960	485240	lead to a benefit. And by benefit, I don't mean that there is some well-meaning force in the
485240	493160	biosphere. It just means that it helps the variant spread through the population of replicators at
493160	500760	the expense of its rivals. And I think it's important to keep things simple when it comes to the theory
500760	506360	of evolution. Really, all that the replicator wants to do, I say in scare quotes, it's not a
506360	511880	conscious being, but all the replicator wants to do is spread through the population of replicators.
511880	518600	So it's all it cares about. And sometimes, in service of that goal, complex adaptations can
518600	530440	arise. So I'm going to start tying this back in with the mind now. Carl Popper said that the
530440	538200	information that is stored in such replicators is adapted. And so therefore, it's knowledge.
538840	542680	Adapted information is knowledge. Or maybe that particular phrasing originated with David Deutsch.
542760	551160	And Popper's conjecture is that people also create human knowledge by evolution. So evolution, in
551160	558840	that sense, is not limited to the biosphere. Excuse me. Although there are important differences
558840	565080	between biological evolution and the evolution that occurs in our minds, there are strong parallels
565160	572840	are strong parallels between them. And so Popper offered this analogy of a new conjecture that
572840	579720	people come up with being analogous to the mutation of a gene and criticism being analogous to the
579720	586920	selection of a gene. And the old theories that we derive knowledge from the census, for example,
586920	593480	which is empiricism, or that we create them by extrapolating repeated observations, which is
593480	598840	inductivism, which is completely false, as Popper explained. And instead he argued that we
599560	605480	create knowledge by starting with problems, not with observations, which are conflicts between
605480	611880	ideas as David Deutsch defines them. And then we guess solutions to these problems and we criticize
611880	618440	them until we hopefully come up with a solution that we deem good enough to adopt tentatively.
619480	623000	And this is not only scientific knowledge that grows that way. All human knowledge grows that
623000	629640	way. And an example I like to give is that of losing your keys. If you're not sure where your
629640	634760	keys are, and let's say you need them now because you want to leave, really all you can do is guess
634760	641240	where they might be. So maybe you left them on the kitchen counter. So that is a tentative
641880	646200	solution to the problem. And then you can go look for them there. And if you don't find there,
646200	649560	then you know that your theory was false. And so you have to guess another solution, maybe they're
649560	653640	in your pocket or something. And if you find them there, that's great. Then you've made progress.
655240	662200	So knowledge, even in the most mundane scenarios like that, knowledge grows that way.
663000	672680	And I do think that Popper was right about all of this. And I even like to think of them as the
673560	677480	foremost artificial general intelligence researcher of this time, although I don't think
677480	684200	he would have called himself that. But as should be expected, if we're papyrans and fallibilists,
684200	689000	there are open problems with hispistemology. And these are some of the open problems.
689880	695240	The open problems I mentioned at the beginning are some of those. So just to reiterate them,
695240	702520	those were how does the mind create new conjectures? How does memory work? How did people evolve?
703480	705720	And then the big one is consciousness.
711080	718600	And to solve them, what I would like to suggest is the following, that if we can think of the
718600	728360	biosphere as an arena of self replicating genes, that analogously, we can think of the mind as an
728360	733880	arena of self replicating ideas. Now, having said that there are still many important differences
733880	738200	between the mind and the biosphere, I don't by no means do I want to equivocate those two.
739000	742760	But I do think there are strong parallels that may help us explain some things.
743640	753480	I should also mention, once I say replicating ideas, we may jump to memes, which are Richard
753480	760280	Dawkins idea of the cultural unit of a replicator. Those are not what I mean, just to clarify. Memes
760280	766840	are ideas that replicate across minds. Memes are not just funny pictures on the internet.
768280	774920	It's basically any idea that manages to jump from one mind to another, or at least enough minds that
774920	781960	it becomes meaningful to call it a meme. So a joke is a meme, but also catchy song could be a meme.
782760	788760	And with the example of the joke, I think this is an example David gives in his book.
789480	795800	You know, if the joke is good enough, then it causes the holder, the person who knows the joke,
795800	802440	to tell it to somebody else. And so now the joke is in two minds, not just one. And that's why
802440	807960	it's meaningful to call it a replicator. But again, I'm not talking about memes here. I'm only
807960	814760	talking about ideas that replicate strictly within a single mind. So it can help, I think, to just
814760	818840	think of a mind that's just cut off completely from the outside world to make things easier. So you
818840	823560	can just imagine a brain in a vat, if you like, doesn't have any access to the outside world.
823560	828440	And still, I think there would be self replicating ideas in the mind. It's also a nice way to
830440	835240	make sure that we can't accidentally adopt any empiricist or inductive notions if we just completely
835240	844120	disregard sense data. And so I think with this simple premise that the mind is an arena of
844120	853880	self replicating ideas, we can now start solving the problems that I mentioned. And I think when it
853880	863000	comes to the question of how people evolved, I would say that the evolution of the mind and
863080	869720	the evolution of people is analogous to the origin of life in the biosphere. Because I'd like to
869720	875080	suggest that the evolution of self replicating ideas in a mind happened analogously to the
875080	882280	evolution of self replicating molecules in the primordial soup. And I think what happened is,
883880	890200	well, so this is Popper again, so all organisms contain knowledge in the objective sense,
890920	896520	meaning, for example, wolves know how to hunt in packs and dogs know how to fetch balls, beavers
896520	901640	know how to build dams and so forth. This all takes knowledge. All of these activities have
901640	906920	the appearance of design. So we know that there must be knowledge behind them. And that knowledge
906920	912360	is stored in their genes. And so we could just call the knowledge that results in these behaviors.
912360	919480	We could call those ideas in the objective sense. And the set of all ideas that an organism has,
920200	929400	I call its idea pool. And some of these ideas, I think, act just like the enzymes,
929400	936200	those molecular catalysts from the primordial soup. They're able to make a change in other ideas
936200	945000	within the same organism without undergoing any net change themselves. And in one of our ancestors,
945000	951000	because of a genetic mutation, there was one such idea, one such catalyst, that happened to
951000	955720	promote the production of ideas of which it itself was made. But more technically speaking,
955720	960600	you could say that it happened to promote the production of source code of which it itself was
960600	966440	made. And then the same thing happened that happened in the primordial soup. Whenever that
966440	972440	catalyst happened to become a little more targeted, it produced more of its components more
972520	978040	faithfully, until at some point you could say it was targeted to meaningfully call it a replicator.
979160	984200	Except this time it's not a molecule that self replicates. It's not a material, a physical thing.
984200	988760	It's an abstract thing. It's an idea. And this thing now replicates over and over
989640	993720	during that single organism's lifetime. So in addition to biological evolution that we have
993720	998680	happening, we now have what we could call mental evolution happening during that single organism
998680	1004920	lifetime. I also call it runtime, the runtime of that software. And like I said, just like in
1004920	1010440	the primordial soup, once you have replication, well, replication is not perfect forever. Even
1010440	1015160	the best replicator makes mistakes every now and then. So sooner or later, variation and selection
1015160	1021080	will kick in. And that's how you get evolution in the mind. And so that's how you get a dynamically
1021080	1027400	changing idea pool, much like you have a dynamically changing gene pool in nature.
1028360	1035000	And this is how this organism can now create new knowledge, knowledge that was not genetically
1035000	1041800	given. And that's something people do all the time. Everyone in this column is doing it right now.
1041800	1047880	And I believe that this, what I've laid out is the underlying logic that allows them to do so.
1048120	1053800	So we've solved now the, I mean, hopefully, we've solved the problem of how people evolved.
1054680	1061080	And the second problem also, which is where do conjectures come from? I think they're just
1061080	1066360	the result of a long string of ideas replicating them perfectly, accidentally morphing into a new idea.
1069560	1073560	And we can also explain now how memory works. Memory,
1074280	1079960	as with so many things of the mind that are unfortunately explained on the level of the brain,
1080840	1087880	memory is often explained on the level of neurons. And so I'm going to butcher it probably, but
1087880	1095800	one idea that I've heard many times is that one set of neurons is said to encode one idea. And
1095800	1101480	then if that set is wired to another bundle of neurons, then whenever one thinks of one,
1102440	1105640	one also thinks of the other. So this is how associative memory is explained.
1106440	1111000	And also they say that the more you think of those ideas, the stronger the physical connection
1111000	1119000	that these neurons get. I think that's completely false. I think it's reductionist. And it also
1119000	1126600	sounds a bit like there might just be a tinge of Lamarck's use and disuse theory sprinkled in there.
1127320	1134360	But I think the reason that can't be true is that we know from computational universality,
1134360	1138280	here I'm influenced by David Deutsch again, that we know from computational universality
1138280	1144200	that we could simulate a mind on a computer, including that mind's memory, even if that
1144200	1151720	computer hardware doesn't have any neurons. So you don't need neurons. We need to explain
1152360	1158040	memory on the appropriate level of emergence. And that is software, not hardware.
1161480	1166200	And I think with this approach, the new Darwinian approach with the replicator approach,
1167800	1174280	we can answer the question of how memory works. In the biosphere, some species survive
1174280	1178440	for much longer than others, although it's really the genes that we're concerned with,
1178440	1185320	not with the animals themselves. And I think the same is true in a mind. Some self-replicating
1185320	1192680	ideas just manage to stick around longer in that mind's idea pool. And those replicators that are
1192680	1198440	longer lived than others and happen to encode events from the past, those are the ones that we call
1198440	1203640	memories. But there's nothing else that's special or different about them that separates them from
1203640	1209960	other ideas. I think memories are usually thought of as a special class of idea. I certainly used
1209960	1215960	to think of them that way, but I think that's wrong. And then when a certain population of ideas
1215960	1223480	and coding memory dies out, let's say because they can't compete with rival ideas in that idea
1223480	1231000	pool, then that's just what it means to forget something. And we can also explain why memories
1231000	1235640	are so unreliable. It's because replication isn't perfect and mutations happen eventually.
1236360	1243800	So memory is just an emergent phenomenon of that underlying pool of self-replicating ideas.
1243800	1249080	And memory being unreliable is just a special case of knowledge being unreliable.
1252840	1257640	And now just some small pointers for when it comes to consciousness. Why are we conscious
1257640	1265240	of some things and not others? Popper conjectured that consciousness has to do with disappointed
1265240	1270120	expectations. I think this was in his book, Objective Knowledge. If I recall correctly,
1270120	1277240	he gave this example of walking up a flight of stairs. And if you get to the top and you think
1277240	1282760	that there's one more step, but there isn't, we've all been there, it feels very weird. And you,
1283720	1290440	not only are you surprised at that sensation, but you also realize that you had an expectation
1290440	1296040	that there was another step. And you wouldn't have realized that if there had been another step.
1297080	1302200	So this is what why Popper argues that consciousness may have to do with disappointed
1302200	1312120	expectations. Something I'd like to add to that is that when we, for example,
1312680	1318920	when we're children and we learn how to ride a bike, initially this process is a very
1318920	1325320	conscious, effortful process. We're very aware of everything we're doing. We're aware of the
1325320	1330360	peddling. We're aware of keeping our balance. We're aware of steering and everything because
1330360	1336920	all of this requires error correcting. But as you get better at riding your bicycle,
1337080	1343800	as you get better at riding your bicycle, you become less aware of those things.
1344840	1350040	Until now, when I ride my bike, I don't really know how I do it anymore. I just do it,
1350040	1355480	but I couldn't tell you how I keep my balance, for example. And that allows me to free up my
1355480	1361000	attention and focus it on the road, for example, so that I can avoid potholes or avoid accidents.
1361800	1367800	So it seems to me that consciousness has to do with error correction, generally.
1368760	1376280	And I'd also like to add this observation that I think what's curious is that despite the mutations
1376280	1382360	of ideas that we know must be happening in our minds because mutations are inevitable,
1382360	1389480	we never seem to be aware of any junk ideas. But if mutations are usually detrimental,
1389880	1394280	and only rarely beneficial, that must mean that at any given moment, there are probably
1394280	1400920	many of these junk ideas in our minds, but we're never aware of them. I think that's curious.
1400920	1408600	So I conjecture that maybe a necessary condition for something to enter our consciousness
1409480	1415960	is that it be sufficiently adapted by some yet to be defined criterion. Now, to be clear,
1416920	1422440	none of this explains consciousness by any means, and it's not meant to. But these are just some
1422440	1431880	pointers. Something else that I think this approach allows us to do is we can start thinking, taking
1434760	1439400	maybe what Richard Dawkins would have called the genes I view, and we can take the
1440360	1447240	ideas view, ideas I view, I guess it would be called, and think about what it would be like for
1447240	1452600	an idea to live in that self-replicating pool of ideas. And we can think about different
1452600	1458680	replication strategies that these ideas may have and what effect this could have on the mind.
1460840	1466520	So now I do want to take it back to the level of memes for a moment. Dave, do I just conjecture
1466520	1471160	that there are two different replication strategies for memes, static and dynamic.
1472520	1480680	And I quote from the beginning of Affinity, a dynamic meme is an idea that relies on the
1480680	1487400	recipient's critical faculties to cause itself to be replicated. So these are ideas that,
1487400	1493480	broadly speaking, help progress and they help their holder make progress. They can at least.
1494440	1500760	And opposed to that are static memes or anti-rational memes. And those are quote,
1501320	1505560	an anti-rational meme is quote, an idea that relies on disabling the recipient's critical
1505560	1513640	faculties to cause itself to be replicated. So these are ideas that prevent criticism of themselves
1514440	1518040	and thereby prevent their holder from making much progress. And so
1518600	1525080	the David Deutsch calls the societies that are dominated by either kind of those memes,
1525080	1530440	static versus dynamic societies. And so static societies, he says, are the kinds of societies
1530440	1535640	which rarely ever change on timescales that the people living in those societies could notice.
1537160	1541800	Whereas the dynamic societies change rapidly and they can make rapid progress because they're
1541880	1547800	dominated by dynamic means. So those are the memes. But what I wonder is if we could
1548680	1554600	introduce the same replication strategies inside of minds. So instead of the level of society,
1555320	1560280	we're now looking at the level of the mind with ideas being the individual actors, not people.
1562360	1567000	Or ideas, or I should say the self replicating ideas in a mind being the actors, not memes being
1567000	1575160	the actors. And so that could then lead us to identify, say, certain minds as static
1575160	1581720	and certain minds as dynamic or more or less of one of the other. And then we could think about
1581720	1586600	how static minds differ from dynamic minds and maybe what that would mean for mental ailments
1586600	1594600	and their alleviation. Given the damage that static memes can do to static societies,
1595560	1601400	or societies, I would not be surprised if static ideas inside a mind can also do great damage to
1601400	1606520	that mind. And I would expect a static mind to have a much harder time making progress than a
1606520	1616440	dynamic mind. And perhaps, just like a static society, a mind that's dominated by static ideas
1616440	1622840	would be overly concerned with faithfully enacting some lifestyle and focusing too much on prevention
1622840	1627880	strategies, which isn't sustainable. I'm borrowing here from Dave Deutsche again, which isn't
1627880	1631800	sustainable because the mind would eventually encounter a problem that overwhelms completely.
1634600	1639640	So that's just an idea to play with. Maybe we can find something interesting there
1639640	1645800	when it comes to replication strategies inside minds. And then one last thing that I'd like to
1645800	1656360	mention when it comes to the approach itself is another reason or another explanation for why
1657080	1663640	you cannot download an idea from one mind to another, which is a direct conclusion from Popper's
1664920	1668360	critique of what he called instruction from without. It's not like we need another explanation,
1668360	1673720	but I think this maybe illustrates a little more. So as a thought experiment,
1674280	1680440	let's say that we have the technology to read people's minds or read their ideas somehow.
1680440	1683720	It doesn't matter how it works, but let's say you somehow connect their brain to a computer
1683720	1689000	interface, and then the program in that interface parses all the ideas in that brain and presents
1689000	1695160	their source code to you. So you could read them technically. And let's just say that's a given.
1695160	1700200	And let's say that you could then, via the same interface, you could connect to another person's
1700840	1707000	brain, and you could just copy-paste the idea from one brain to another. So technically,
1708680	1714360	couldn't we say that that would constitute a successful download of an idea from one mind to
1714360	1722760	another? And maybe we could, but even if so, I think it still wouldn't refute what Popper meant
1723480	1728200	when he said that instruction from without is impossible. And I think the reason is that
1728440	1733240	the transferred idea, once you copy and paste that idea, it most likely will not make it in the new
1733240	1738920	mind. It's a bit like taking a penguin from an arctic on a place you get in the African jungle.
1739880	1745880	That penguin is not going to survive, because I think our minds are all extremely different,
1745880	1751240	just like extremely different ecosystems. So placing an idea from one mind is not going to
1751240	1757320	make it. We shouldn't expect it to survive in the other mind. The idea, if we want to
1757320	1764920	get the second mind to have that idea, a much better approach, I think, is to get that mind to
1764920	1774680	evolve the idea itself, in other words, through persuasion. So this is the new Devonine approach,
1774680	1782520	more or less, in a nutshell. What I'd like to do is respond to some criticism that the approach
1782840	1793080	has received. And I'll start with Ella Hepner, who most notably has offered several different
1793080	1802600	criticisms of the theory. One such criticism says that replication is wasteful. It's computationally
1802600	1811480	wasteful. And so there wouldn't have been enough memory in our early ancestors' brains for ideas
1811480	1817240	to replicate. And now I mean memory in the sense of storage space, not in the sense of remembering
1817240	1825720	things. So my response to that is I'm not sure that that is true. Many complex animals already seem
1825720	1833000	to have enough spare memory to store additional information during their lifetimes. And in particular,
1833000	1839960	our ancestors must have had enough memory, at least memory that was free at the time of birth,
1840840	1846360	for them to copy and store relatively complex memes, at least complex compared to other animals'
1846360	1851960	memes. Now to be clear, they didn't replicate those memes creatively because this is pre
1852920	1858200	the evolution of minds. But as David Deutsch points out in the beginning of infinity,
1858200	1863800	meme evolution already drove the evolution of our ancestors. So there was already selection pressure
1864520	1870040	favoring the development of ever more free memory in our ancestors' brains so that they
1870040	1874200	could copy ever more complex memes. And that would have been space that our ancestors'
1874920	1882520	self-replicating ideas could have used. On the note of memory, I would think that
1883480	1890920	biological evolution, even long before the evolution of people, would have discovered
1890920	1896040	basic memory management solutions, such as garbage collection, for example. Garbage collection,
1897400	1901080	I don't have a computer science degree or anything, but my basic understanding is that garbage
1901080	1909400	collection is a way to monitor a program's memory usage and monitor its memory pressure.
1910200	1914920	And if you only have so much memory available on your computer and your program is using,
1914920	1920840	say, 95% of it, then the garbage collector will go in and look for any stale references
1920840	1924680	to data that you're not using anymore, that the program isn't using anymore, and then it just
1924680	1929960	deletes those references. Though I may be butchering now, but I think that's the gist of it.
1931480	1937400	And I would expect that evolution would have stumbled upon something like that much earlier,
1937400	1944760	because it seems to me that any organism that can store additional information during its lifetime
1944760	1948840	would eventually run into memory pressure issues. And so evolution must have evolved,
1948840	1954360	there must have been a solution to this problem. Also, these increases in memory that I think are
1954360	1961400	needed for those self-replicating ideas, they would have happened very gradually. So I'm not
1961400	1966440	suggesting that once self-replicating ideas came on the scene within minds that suddenly brains
1966440	1971480	had plenty of extra storage, certainly possible that initially there wasn't all that much extra
1972200	1980120	memory to go around, but maybe just enough to help that adaptation spread. And then there was
1980120	1984280	selection pressure, biological selection pressure to increase memory in humans brains if that
1984280	1990120	adaptation was helpful enough. By some accounts, there was a large and relatively sudden increase
1991240	1995720	in memory in our evolutionary history, and I've heard theories that attribute that to a change
1995720	2001320	in diet or upright posture or opposable thumbs and all that stuff, but it could also be possible
2001320	2006280	that that increase in memory in our brains was caused by the selection pressure I've just described.
2009400	2019080	And lastly, for this particular point, the claim that replication is wasteful or redundant
2021400	2027000	in the sense of being unnecessary, it reminds me a bit of, although this criticism is not meant
2027720	2032440	as a creationist standpoint, but it reminds me a bit of what a creationist might say about
2032440	2039000	replication and biological evolution. A creationist might think that genes carrying
2039800	2044520	the same knowledge millions of times over in each organism is unnecessary. To them, it might seem
2045320	2052200	much more parsimonious and efficient to simply say that a single entity, God, for example,
2052200	2056040	contains a single copy of all the knowledge that's required to create each organism,
2056040	2058280	and then each organism is just the result of him doing that.
2062360	2067640	Okay, then another criticism that Ella has offered is the self-replicating ideas. They sound
2067640	2071880	dangerous. They could have led to all sorts of dangerous behavior in our ancestors,
2072840	2079640	and so biological evolution would have selected against them. I don't think this is true either.
2080600	2089400	I think animals around us are evidence that they contain sophisticated knowledge with
2089400	2095640	enough reach to guard against unwanted behavior, for example,
2095640	2101480	being stuck in an endless loop or something. I've tried this. Even a well-behaved dog won't repeat
2101480	2108200	a trick forever when instructed to. It'll only do it so many times. It just stops at some point.
2108920	2117640	There seem to be built-in criteria that can override erroneous behavior. It seems to me that
2117640	2125800	biological evolution has already has built-in safeguards. Self-replicating ideas wouldn't
2125800	2129480	automatically have led to ever repeating behaviors or something that would
2130520	2136120	certainly cause death for the organism. I think actually the opposite is the case.
2137080	2144520	Self-replicating ideas were then and are beneficial, and they helped the genes spread
2144520	2153640	that code for them. Because whenever there was a detrimental genetic mutation present in an organism
2154600	2162600	that led to a bad mutation in one of those organisms' ideas, it was thanks to those
2162680	2167080	self-replicating ideas that there was an opportunity that broke in functionality
2167080	2174920	with working functionality. Because detrimental mutations are much more numerous than beneficial
2174920	2180440	ones, that actually means that the existence of self-replicating ideas was favored by biological
2180440	2185720	evolution up to a rate at which detrimental mutations occur. I think there would have been
2185720	2190520	strong selective pressure in favor of self-replicating ideas in mind because it would have helped the
2190520	2199880	genes spread. And then Ella has offered another approach that one could implement the same
2200440	2206840	algorithms, the same self-replicating idea pool without replication. And the idea is basically
2206840	2211960	you just have a single instance of each idea and a score or weight that you attribute to each,
2211960	2219560	and then increasing and decreasing the weight as you go. And David George recently independently
2219560	2227080	suggested this criticism as well. Now, it seems to me that denotationally that sounds
2227080	2233640	similar to my theory, and I think Ella in particular has in mind, although she's here,
2233640	2239640	she should correct me on this, but I think Ella in particular has in mind what's his name,
2239640	2245400	Donald Campbell's work on evolution, that you don't really need replication so the argument
2245400	2250040	goes, you just need variation and selection. Imperfect replication can be the source of
2251480	2260040	variation, but it need not be. Now, I've said in the past, and I'm still of the opinion that I'm
2260040	2266360	agnostic as to the question of necessity, but if we were to make this change, I think it would come
2266360	2272760	at some costs. The one thing that I think the New Darwinian approach, the approach that does adopt
2272760	2278440	replication brings to the table is that we can explain how people evolved. I'm not sure how we
2278440	2284440	would do that, because it allows us to explain with a very simple accidental small mutation.
2285240	2291560	I'm not sure this algorithm that would store and decrease weights, we would have to explain
2291560	2296520	how that one came about. That seems to require a different explanation that I'm not aware,
2296520	2302600	I'm not familiar with. And then the question is, when does it decide to mutate an idea and
2302680	2306680	why and how, and at which location in the idea source code?
2310280	2316280	It also seems to me that such an algorithm would make plant mutations, but in real evolution,
2316280	2327560	mutations are not planned. So, what I like about the, what I like about my approach is that
2328360	2332120	none of these questions need to be answered in explicit programming. These are all just
2332760	2336680	things that automatically fall out of having self-replicating ideas.
2338600	2342760	So, in a way, actually structurally speaking, maybe it's the pool of self-replicating ideas
2342760	2347240	that's more parsimonious, because you don't need to explicitly program any of these other things.
2347480	2361480	And if the goal of that approach is to, if the goal of that approach is to get rid of replication,
2361480	2367800	because it might be wasteful or redundant or whatever, then the thing is, let's say you'd
2367800	2372520	have one instance of an idea and you'd have a weight associated to it, and let's say at some
2372520	2378120	point this master algorithm decides to make a copy of it and mutate it, and so at that point
2378120	2383320	you would store a second entry, and over time you would get more and more entries in some registry
2383320	2393720	of ideas or whatever. And I think then you would still get source code that is shared among many
2393720	2400680	of these entries, and so it's a little bit similar to what Dawkins has pointed out with in regard to
2401480	2407560	the cisterns and the DNA versus the genes, which he defines separately. The cisterns,
2407560	2411640	or maybe butchering the term, but I think that's what is called the cisterns, are like the actual
2411640	2418440	section in the genome that code for eye color say, whereas the gene he defines as the longest
2418440	2422360	possible stretch of the genome that gets replicated over and over without changes.
2422920	2428120	You'd get a very similar phenomenon in this registry of ideas where you'd have sections
2428120	2433800	of those ideas that stay the same across those entries, and then that would be the replicator.
2434920	2439240	So although the idea is set out to get rid of replication, I'm not sure it actually does.
2441800	2447800	And I think what's nice about adopting replication is that it gives us consistency
2447800	2452600	with other evolutionary phenomena that we know exist and we know are powered by replication,
2452600	2457400	that's biological evolution and meme evolution, and I think that consistency is valuable
2458360	2461560	because it means that we can share knowledge between these different disciplines.
2464120	2468280	So I like to think that this new Darwinian approach has a unifying character and I think
2468280	2476680	that's worth keeping. And we couldn't, excuse me, we couldn't investigate the static and dynamic
2476680	2483080	replication strategies in the mind anymore without replication. Those really are replication
2483080	2491080	strategies and they don't work without replication. And then the last criticism that I'm familiar with
2491080	2499400	that Ella has offered is that it's unclear how the mind creates and discovers problems
2499400	2504600	and contradictions and that that's the driving force of creativity. So that's a really important
2504600	2512520	thing to answer. And I agree with that. So I want to clarify. My current idea is that
2513320	2519560	when there are populations of ideas that are competing in a mind, especially when they compete
2519560	2526920	fiercely over resources, memory, for example, then that leads to cognitive dissonance that
2526920	2531960	the cognitive dissonance that we experience when we experience a problem. And depending on the nature
2531960	2538680	or the fierceness of the competition that we may, a problem may seem interesting or annoying or
2538680	2544600	downright depressing, like I said, depending on the nature of the competition. And then when we solve
2544600	2550440	such a conflict, it could mean, for example, that there's a third population of ideas that
2550440	2556680	has evolved and operates as a sort of mediator, enabling the two conflicting populations to
2556680	2563800	coexist peacefully, or it could fight and win against both populations and largely replace them.
2563800	2569560	I think that's what might be happening when you have one theory that supersedes and explains
2569560	2573240	two conflicting ones, which then live on in the new theory as approximations.
2575560	2578840	Or it could just enable one of the two to win over the other.
2580920	2587000	And then recently, David Deutsch suggested that we need not mimic how biological evolution
2587000	2592120	created creativity, the same way that planes don't need to mimic birds to fly.
2592920	2597480	And I agree with that. I just, I don't know of any other way yet.
2601560	2608200	And, yeah, and I forget if I mentioned it, but he also just like, just like Ella Hepner
2608200	2614280	suggested that replication would be inefficient, that it wouldn't be necessarily the approach that
2614280	2622440	a programmer would take. So all these criticisms would be very helpful and have motivated me to
2622440	2629240	think more about this idea. But what strikes me is that I think none of these are conclusive
2629240	2635160	criticisms. And this brings me to something that many of them have in common. I think they're
2635160	2641240	along the lines of, they say something like self replicating ideas are not necessary to explain
2641240	2647880	the mind. And like I said, I agree with that. In fact, I'm pretty certain that my, that my
2647880	2660520	approach is wrong. What I'd like to find out is why. And I think the, a, an avenue that I would
2660520	2669240	find more, more productive is what, what is an explanation for why self replicating ideas
2669240	2675240	cannot be part of the mind, not why they need not. And like a real refutation of the idea
2675240	2680440	would be extremely helpful. That also brings me to what could change my mind about this,
2680440	2684920	this approach. That is one of them, just just an explanation of why it cannot involve self
2684920	2689880	replicating ideas. And then also an internal contradiction or something like that that I'm
2689880	2694040	unable to fix. At least that would, that would definitely constitute a big problem that I would
2694040	2701160	need to solve. I should point out that the idea that self replication, for example, would have hurt
2701960	2710200	the genes encoding that it would have hurt genes in biological evolution. I think that was a
2710200	2715800	candidate for why creativity cannot involve several self replicating ideas. So I think something
2715800	2722600	like that would be promising. And then lastly, some outstanding problems. There are still big
2722600	2728600	unknowns left. Like I said, consciousness is the big one. Something that I've been thinking about
2728600	2734840	recently is that when you, the, the approach kind of goes along the lines of, well, as long as you
2734840	2739880	have self replicating ideas, you kind of get variation automatically eventually because the
2739880	2746440	mind is messy. And therefore you also get selection automatically because different variants spread
2747400	2753000	with different rates at different rates. But if you actually write a self replicating computer
2753000	2758040	program, they're also called a quine. They don't ever mutate. You can run them a billion times in
2758040	2766920	a row. They don't mutate unless you force them to, but then mutations are planned. So that tells
2766920	2771320	me that the self replicating programs that people have written are too good at replication for
2771320	2778360	evolution to occur. And then there's the problem with evolutionary algorithms generally that David
2778360	2782920	Dorch has written about in the beginning infinity, which is that as a programmer, you can't really
2782920	2787960	tell if the knowledge that you find in the program after running it is knowledge that the
2787960	2792040	program created itself, or if that is knowledge that you as a program just happen to put into it
2792040	2797640	without realizing it, you leak that knowledge into the program. And so you can't really judge
2797640	2803800	whether the program is creative. You'd need to know to make that call. So we'd need to find a
2803800	2812600	solution for that before even trying to implement this theory. And yeah, so that is the approach.
2813720	2819560	And I'd be ready to take questions if there are any. Great. Thanks so much for the talk.
2819880	2827080	Um, yeah, so we have about 45 minutes of questions. And I think what we'll do is,
2827640	2834760	Dennis, if you could first close the presentation, because I think it's nice.
2838440	2839160	Go back to
2842120	2847960	And then I will open with a question. And then anyone who wants to answer,
2848040	2855320	who wants to ask a question can do so afterwards either by raising your hand, as I see David has
2855320	2864120	done, or by typing in the chat. Yeah, so the first question I had was, I really liked the idea set
2864120	2871960	out. And I like, especially explanation of memory. And this idea that memories are replicators and
2872440	2880440	the memories that you retain, other ones that have replicated best. But memory in my computer
2880440	2887240	is just accessible, like the files in my computer don't replicate. If I require an old file,
2888120	2893960	I get an exact copy of that file, and I just retrieve it as it was when I first stored it.
2895240	2900440	Why do you think that minds store memories differently? Why do you think that they will
2900440	2910120	have to replicate? Yes. I think it's sort of a quirk, maybe of the English language that we
2910120	2915720	use the term memory to refer to both of these phenomena, even though I think they describe
2915720	2922120	different things. Memory in the second sense, in the sense that your computer uses,
2922840	2929240	actually our brains have too, because they need to store data in that sense. And that
2929240	2934360	is just the plain old memory storage that you've described, and nothing changes. Like if I store
2935080	2939880	very rarely, because our hard drives are very reliable. So yeah, if you store a file on your
2939880	2945640	computer, it just stays there and it doesn't replicate. So this is, I think that is like a
2945640	2951000	lower level kind of memory phenomenon, like the direct interaction with the hardware for how to
2951000	2956440	store information. The kind of memory in the sense of remembering things,
2959480	2964440	I think it's just a different phenomenon. And that is the phenomenon that involves
2965080	2969880	the self-replicating ideas. So I would just distinguish between the two.
2970760	2976440	Very nice. Okay, thanks for your answer. Then I see that David has a raised hand. David,
2976440	2983960	go ahead and ask a few questions. Hi. Well, I too found that very persuasive,
2983960	2992680	and I also liked the way that it kind of explains features of the would otherwise
2992680	3000760	perhaps seem accidental features of the human mind and memory as well. I just,
3000760	3013560	I can't quite see the overall picture though. So in RNA world, there were, as it were,
3015000	3026840	genes, but no organisms. Right. And in the brain, in your picture, I think there's also
3027640	3036280	genes, but no organisms. Is that right, first of all? Yes, that is right. I've wondered if maybe
3036280	3042680	sometimes ideas, as they get more complex, as they replicate in the mind, if they stumble upon
3043480	3047720	a replication strategy, something like the genes stumbled upon when they invented organisms.
3047960	3058600	Well, yeah. Well, so the thing is that if you imagine a huge soup of RNA, then it doesn't have
3058600	3065000	an outside world. That is the only outside world it interacts with is other RNA molecules.
3065480	3080760	Things started happening in RNA world to make more sophisticated replicators when RNA started
3080760	3092120	manipulating things that aren't RNA and started, for example, making enzymes, making proteins,
3092760	3100520	and so on. So I would guess that there's only so far you can get by twisting RNA into different
3100520	3108600	shapes and trying to get them to produce more of those. But at some point, they invented enzymes.
3108600	3118680	And then, from then on, there's phenotypes. There's organisms. I, I, I don't know, I don't know,
3118680	3129400	there's organisms. I, I'm not, I'm not asking how you explain the origin of species, you know,
3129400	3138280	why a bunch of DNA just moves along through the world together. It's not that. It's, it's the,
3139080	3148840	it's, it's the, when it gets to encounter the non RNA world. And I think most selection in the
3148840	3161160	biosphere and most selection in the brain, I'm guessing, is caused by problems to do with the
3161640	3168600	non RNA, to do with the outside world. It's the outside world that causes things in the inner
3168600	3176840	world to come into conflict. Right. Okay. So, you know, I'm just kind of asking or asking for
3176840	3182200	comment or whatever. I mean, I don't have any objection to the idea. I think it's a great idea.
3182200	3189720	And, you know, please pursue it. Great. No, you know, I think that is a really helpful
3189800	3194120	pointer that is, I don't have an answer off the bat for you for that. I think that's something
3194120	3200120	I'd very much like to explore. So I'll, I'll keep thinking about it. Okay. Can't ask for more.
3202120	3209560	Oh, then Timothy, do you have a race time? Yeah. Hi, Dennis. Thanks for the talk. I really enjoyed
3209560	3217880	it. Hi. I think, I think one term that I'm sort of stumbling over in this framework is accidental.
3218600	3225640	How do you think about our sort of effectiveness at problem solving or the kind of deliberateness
3225640	3229880	of it in terms of this accidental idea creation?
3233080	3238760	Do I understand correctly that you're trying to square the purposeful thinking or the, at
3238760	3243960	least the purposeful, the feeling that we get that we're purposefully solving a problem, say,
3244040	3248200	with the notion that ideas mutate accidentally? Am I understanding that right?
3248200	3253640	Yeah. I mean, not just the feeling, the fact that we actually approach problems and solve them.
3254760	3265320	Right. Yeah. I do, I've thought about this too, and I think it's a really interesting
3265320	3275800	thing to explore. The, I think those things can be squared. And I think the way we introspect and
3275800	3282840	look at the way we solve problems is often deceptive. And this has led to ideas such as induction,
3282840	3288840	for example, where people even though they could not have induced from experience,
3288840	3296600	that's what they thought they did. So people can be mistaken about what they, what they're doing
3296600	3306520	when they solve problems. And the thing that ideas happen to morph into a new conjecture that,
3306520	3313720	that solves a problem, say, I think isn't really at odds with purposeful problem solving.
3313720	3319000	We, we purpose, we want to solve problems. That means we have ideas that we would like when
3319000	3325000	there's a conflict, we would like to solve it. And that idea exists even before we encounter a
3325000	3332600	solution to a problem. But the, the solution to the problem itself, we can't really move toward
3332600	3337960	in a targeted fashion because we don't know yet what it might be. It's unknowable in advance. We
3337960	3342360	only know it once we've evolved it. And at that point, we just kind of happened to know it.
3343320	3348920	I think that's just true of evolution generally is whether it's the gene or the self-replicating
3348920	3355560	idea in the mind. There's only, I think Popper called them happy accidents. There's only happy
3355560	3363800	accidents, or sometimes not so happy ones. That's, I think, all we have. We can't think of a solution
3363800	3371720	before we, before that idea mutates into one. Does that make sense? I'm not sure that I,
3371720	3373960	that I really put my finger on your, on your question.
3378760	3384680	I am not hearing the participants. Sorry, sorry, that, that, that does make sense. I'm not,
3385400	3389480	yeah, I'm not sure if it, it quite feels the gap for me, but I'm,
3392440	3397400	yeah, I'm not sure of a better way of framing it, but thanks for the, thanks for your response.
3397400	3405960	Okay, sure. Okay, then I see you have two more raised hands. I don't know who was first. I think
3405960	3411720	I'll go with Paarek. I, I think he must be asking your name. So, so go ahead.
3411720	3416840	That's all, yeah. That's Paarek. Thanks a million. Really enjoyed the talk, Dennis. Thanks a lot for
3416840	3424120	it. And so yeah, my question was sort of related to the last question a little bit, but you remarked,
3424920	3432280	I think about halfway through the talk about, there may be, because ideas will self-replicate,
3432280	3439400	there will be these junk ideas, which are analogous in some ways to, to junk DNA. So,
3439400	3452200	I guess my question is about the self-replication. So within this model is the replication a matter
3452200	3460280	of degree, so that the, the idea, which isn't the junk idea, which presumably is the one that
3460280	3467800	we're, we're then conscious of, you know, because you're, you were mentioning that we, we, there's
3467800	3474920	a lot that we're, we're unconscious of, and those would be the, the sort of the ridiculous answers,
3474920	3480440	let's say, to a problem or the ones that we don't get promoted into our awareness.
3481160	3489400	But the ones we are aware of, would those be more active replicators in, in, in this way, or, or
3489400	3497640	they're, so yeah, I guess it's sort of a two-part question. One is like, is the replication a
3497640	3505320	matter of degree? And secondly, are the, the ones we become conscious of, the sort of better at
3506280	3512520	causing their, their copying? Yeah, I'll, I'll, I'll try to answer the second one first.
3513880	3522440	They, I think being better at copying oneself is one way to just retain the, the faithfulness and
3522440	3530520	the, the coherence of an idea, for sure. So that if, if that idea wants and scare quotes to be,
3531160	3536600	to be thought of again, one, a good way to do that is to make sure that one retains one's
3536600	3546280	faithfulness. I could see that. Now, with regard to whether that makes it a more active replicator,
3546280	3553560	I don't know, I could certainly imagine that there are ideas with different replication rates.
3554200	3563320	One might replicate twice as often as the other. And if it can make up for, for, you know, the
3563320	3568760	mutations that might be introduced during that, the, the double replication, then it's fine.
3571080	3577720	So I guess it just depends on how reliable the replicator it is, or it is not very reliable,
3577720	3586200	but thanks to those mutations, it creates a new idea. And then that new idea is coherent enough
3586200	3591560	that you become aware of it. So that could also be the case. So I'm not sure that we could tie it to
3592280	3597880	the activity of a replicator per se. With regard to your, your first question, I'm not sure what
3597880	3604760	you mean by degree of replication. Yeah, I guess just to clarify it a little bit. So, you know, some
3608120	3612840	questions. So to, to bring it back to the analogy that within genes, there will be,
3614280	3620920	like the junk DNA is a replicator of sorts, although it's, it's not usually referred to
3620920	3627320	as a replicator because it's, it's not, you know, it would contribute within its environment,
3627320	3633880	it contributes to its copying more than, you know, a whole lot of other physical objects.
3634360	3640840	And both it's, you know, it's, it's, for some, it's maybe not worth calling a replicator because
3640840	3647720	it does so far less well than, than the ones we call replicators. So I was just wondering if that's
3647720	3654360	the same sort of implication that was being drawn between the analogy of junk ideas and junk DNA,
3654360	3659960	that they are sort of, they're still self replicating, but they're, they're less,
3660520	3668440	less good. I got you. Yeah. No, I think, I think absolutely that could happen. Yeah, you get,
3668440	3673240	you could through an, through mutation, you could get a junk idea that's, it's junk in the sense
3673240	3677640	of that doesn't result in a coherent idea anymore, but it's still kind of manages to get itself
3677640	3683080	replicated every now and then that could happen. Or sometimes the mutation might be so detrimental
3683080	3692360	that it's just, it dies immediately. Yeah. Then I see Danny has a raised hands. Danny, go ahead.
3694040	3699880	Hi Dennis. I really enjoyed the talk as well. And one of the things that I really like about this
3699880	3704840	theory, which is something that I've wondered about myself in the past, is the fact that
3705480	3710120	Popper's notion where we conjecture ideas, I've always wondered why the ideas that appear in
3710120	3716120	our conscious mind seem to be non random. You know, so the, you know, to take your example about
3716120	3720760	the keys, you know, some silly idea about your keys being somewhere that you've never been before,
3720760	3726200	that idea doesn't appear in your mind. So I suppose my question would be, do you have any conjectures
3726200	3734040	around what is happening in the mind in that moment when an idea, when that first idea appears in your
3734040	3741800	conscious mind? So what is happening when your mind quote unquote, like selects one idea to
3741800	3745960	present to you consciously? Have you, have you thought about that at all?
3747560	3754840	Yeah, I have. And one idea that I've just played with is that maybe what's happening is that
3757160	3761160	in the pocket of the population of ideas that's relevant to this problem,
3762040	3765960	um, maybe the idea that you've left your keys on a kitchen counter
3767480	3773480	is just very good at spreading through this pocket and it outnumbers rivals. And
3774600	3780600	that's why it gains a foothold in that niche. And maybe that is why you become aware of it. This
3780600	3786120	is just a, you know, purely conjectural, I'm making stuff up kind of thing. But
3786520	3793480	um, that's an idea I've played with. So, so more broadly than it's, you think it might be possible that
3794040	3800920	um, the distinction between, you know, the ideas in the conscious mind and the ideas in the unconscious
3800920	3808760	mind has something to do with, we'll say the number of, of replicas of an idea or, or am I maybe
3808760	3814040	stretching, stretching what you just said as Marlon? Well, I think it may have to do with that.
3814040	3823160	And um, it, it may have to do with one idea outnumbering or overwhelming,
3824760	3829080	or one population of that idea, like one set of replicas of that idea, outnumbering another
3829080	3834360	competing set. And that's why you don't think of the other set. I think that is one, one thing.
3834360	3840840	And then as I've mentioned, there's the thing about ideas competing fiercely and that constituting a
3840840	3846600	problem. That is also something that become aware. I would imagine that their ideas competing all the
3846600	3852040	time, countless ideas competing all the time in our minds, but the competition is so small and,
3852040	3858040	you know, the conflict is so small that you don't, you don't realize it. But because the, the key,
3858680	3863960	and the key example of the missing key, it must mean that just by virtue of you thinking and
3863960	3870760	recognizing it as a problem, it could mean that there were two populations of ideas
3871560	3879640	encoding, um, conflicting preferences. Say one, I want to leave, um, that is my preference,
3879640	3884520	conflicting with the idea that I can't find my key, so I can't leave. And this, this conflict is
3884520	3889160	both on both sides, the ideas are numerous enough that the conflict conflict is noticeable
3889800	3894680	that you, I mean, it's a bit circular because I'm trying to explain what we notice in terms of what
3894680	3900600	is noticeable. Um, but I'm suggesting that that is what makes it noticeable. Uh,
3902120	3905400	if that makes, I hope that makes sense. Yeah, yeah, I know it does. Thank you. Thank you.
3907240	3915560	Okay, I don't see other raised hands, so I will ask another question. And it has to do with
3916520	3926200	uh, these higher level concepts. So we, we, we also, like, you, you draw this picture of, of
3926200	3935080	single ideas, uh, evolving in a mind and, and partly you say that, for example, we
3936040	3941320	experienced suffering as a, as a consequence of competition between ideas. Uh, and I think what
3941320	3947160	I'm wondering is, like, where does the sense of self come in and where does, uh, this is kind of
3947160	3955640	related to the question of where does conscious problem solving come in? And, uh, just truly,
3955640	3961560	I mean, I can imagine there would be such an explanation of consciousness or, of, uh, maybe
3961560	3967320	that's asking too much, but where, where do these seemingly higher level, uh, entities come in? The
3967320	3973160	sense of self, uh, sense of direction, sense of purpose. Um, and yeah, this is kind of a vague
3973160	3978840	question that is pointing at something. I hope it's enough. No, no, it's a great question. Um, yeah,
3978840	3984520	I'm afraid it really is the big one. I don't have any, any good answers for you. I mean, I, I have
3984520	3990200	thought that there, that there is a sort of meta algorithm in the mind that, that we've inherited
3990200	3996280	from, from our ancestors that used to just be, um, responsible for interrupting, you know, bad
3996280	4002920	loops or stuff like that. But, um, and maybe that is, because it looks over the pool of replicating
4002920	4007240	ideas, that maybe that is why we have this, we, at least that's how we feel, that we have this
4007240	4012920	bird's eye view of our ideas. But I don't know. Uh, I would really like to know.
4014120	4018280	Yeah, same. But it's, yeah, as I said, it's, it's maybe too big of a question.
4020040	4024280	I see there's more race hands now. Uh, and I think Antonio was first. So,
4024280	4031080	Antonio, if you want to ask a question, go ahead. That's right. Thank you. Um, so I don't want to get
4031080	4039960	into a play of definitions, but what do you mean when you say an idea? And do you differentiate
4039960	4046200	it between the explicit content or the inexplicit content? Do you think it matters at all how they
4046200	4053160	are instantiated in the brain? What would be like the goal of an idea? Why wouldn't want to exist
4053160	4059720	in your brain in the first place? Because, yeah, unless you actually define what you mean by idea,
4060280	4065720	having self-replicating ideas doesn't say much about what's going on.
4067480	4072680	So the, the, what's throughout to me is when you said that, why would an idea want to be
4073320	4079400	in a, in a mind? I don't think it does. Um, this, the same way that there's no gene that wants to
4079400	4083160	be in the biosphere just kind of finds itself there. And because it's a replicator, it makes
4083160	4089960	ever more of itself. Um, there, there, there's nothing, um, you know, the, the, on the level
4089960	4094280	of the replicator, there's, there is no consciousness or purposeful purposefulness. So,
4095160	4101560	um, now when it comes to what, like, how, what do these ideas actually look like? How are they
4101560	4106040	implemented? Um, I have given this some thought now at the risk of it getting too technical.
4106040	4110600	I think of ideas the way they're stored in the brain when it comes to source code as
4111400	4117000	functions in the sense of the lambda calculus. And I do think there are important parallels
4117000	4121240	between, or not just parallels, I actually think they're the same between functions in the sense
4121240	4127320	of the lambda calculus and explanations. And so I use the term idea just for those functions.
4128600	4134360	Um, before just those functions, I should say. Um, so that would be my technical answer to
4134920	4143160	how our ideas implemented in the mind. Um, if that helps. Okay. If you imagine a brain,
4144040	4150360	a human brain, okay, human baby raised without language. Okay.
4152200	4158440	In 2021, now you can raise a human being without, say, speaking to it, to humor her, whatever.
4159320	4167560	Um, do you think that it will contain knowledge? Will it only contain like inexplicit knowledge,
4167560	4173560	but it will be able to move around, to hand, to eat, to feed, to interact with other human beings
4174680	4176520	purely on an inexplicit level?
4179000	4185160	Yeah. Um, I think so. I think, I mean, our ancestors at some point were in that stage,
4185160	4190760	right? Before the invention of language, presumably they had the same brain, the same genes.
4192360	4199240	Yeah. Um, no, I do think that language comes after. Um, you have creativity and that's what
4199240	4204280	allows you to learn language. It's not the other way around. Um, so yeah, I think there's plenty
4204280	4209880	of things that people can learn even without language and the inexplicit ideas will do.
4210440	4217240	And what is the mechanism of how they learn all these inexplicit ideas be different
4217240	4219160	to how they learn explicit ideas?
4220440	4226200	Um, I don't think so. I think the, the method and scare quotes of conjecture and criticism is universal.
4228440	4234120	I mean, yeah, I think it worked the same for, for explicit ideas as for inexplicit ideas.
4234680	4240600	And wouldn't it be more easy if the mechanism is the same to try to explain
4242040	4249240	how we learn inexplicit ideas before jumping to the explicit ones and having all these extra
4249240	4255000	dimensions of language of science, all these meta levels?
4256760	4258200	Um, I would agree. Yeah.
4258760	4262040	Yeah. Okay. I'll pause here and maybe we can
4263400	4270920	thank you. Yeah, go ahead, Dan. Okay. Hi. Hi, Dennis. I missed the beginning of your talk,
4270920	4277400	but I think this is a really important line of inquiry and my apology for exploring this.
4278120	4288360	Um, I, I feel like the area which needs to be fleshed out more is the selection
4289240	4298840	mechanism. And I wanted to mention that there is an existing theory called neural Darwinism,
4300120	4304360	but it seems to be that theory is more on the, to explain perception
4305240	4314040	rather than the formation of ideas. And in, in neural Darwinism, the idea is you have,
4314040	4319720	you have basically a bunch of, when, when, when, in a newborn brain, it's known like you have tons
4319720	4327720	of random connections and then there's sort of a pruning process. And the idea of neural Darwinism is
4328440	4335000	the different groups of neurons are selected by how faithfully they replicate the incoming
4335640	4347240	sensory data streams. With your, with your theory, you, you were talking about more of an internal
4347240	4357000	process, right? So I was thinking, when, when you need some kind of like world simulator,
4357720	4364440	to, to, to test different ideas, to see if it makes sense. And like, have you thought about how
4364440	4374920	there might be like a world simulator and then basically, so for example, with the missing
4374920	4381240	keys example, which is, which is really interesting one example, different parts of your brain would,
4381240	4391000	would be simulating different scenarios and sort of seeing if they, if, if,
4395160	4401880	if the idea, if, if the simulation maps onto the idea, like, like you'd have different ideas,
4404440	4410440	like you'd have an idea of the keys or location X, and then you'd run a simulation based on the,
4410440	4416120	all the information you know, and you see if it confirms that idea. Have you thought about anything
4416120	4430360	like that? Well, just to give a general answer, the, as I, as I said earlier, I like to just
4430360	4439000	leave sense data out of it completely. I mean, I do think that sense data is important to, to test
4439000	4447400	your theories. But so to make progress, sense data is important in that sense, but I don't think sense
4447400	4453160	data is required for, for creativity to work, or for any of the evolution that occurs in a mind to
4453160	4460360	work. And I mean, you could, you could simply ask, you know, if somebody is born, and I don't want to
4460360	4463560	put words in his mind, I think David does this in the beginning of infinity, and if somebody is born
4463560	4469400	blind, they're not any less creative. I mean, they might, they're still people. They're fully
4469400	4475160	qualified people, right? So they might have a harder time correcting some errors because they
4475160	4480680	don't have access to sense data from the eyes, but then they might creatively find other ways to,
4480680	4487000	to correct those errors. But what I, like I said, what I like to do is just leave sense data out of
4487000	4494600	it completely just to avoid any empiricist pitfalls. And I also like to leave the brain out of it
4494600	4501320	completely. And I like to think only in terms of the mind, just to avoid any, any accidental
4501320	4506840	reductionist mistakes. So I, so I, you know, the thing about neuronal structure is self replicating.
4508280	4513640	I don't know. I would, I was more just mentioning that for the audience's
4514600	4520600	benefit, not, not, I'm not saying that you should go in that direction. I actually think the
4520600	4525720	direction you're going, which is more at the higher, higher level, extracting away from the,
4527480	4532200	from the, the neural circuitry is, is, is very, is very interesting.
4535560	4541880	As I guess my question was really about the selection mechanism, like could, could you
4541880	4546840	elaborate more? Cause so far on the selection mechanism, cause so far you, I mean, at least for
4546840	4554040	the part I heard, you just mentioned, you know, some will be better at replicating than others, but
4556040	4563960	um, what is the selection? How is, how does selection occur? Is it context dependent or is
4564040	4571720	there some, how does that, how does that work? Yeah. So again, borrowing Dawkins definition of
4571720	4576600	selection, that is, it's the non random differential reproduction of a replicator in a pool of
4576600	4583240	replicators. Um, that is how I would describe the selection effect or the selection mechanism
4583240	4588200	in the pool of self replicating ideas in the mind as well. It's just the fact that once a
4588200	4595480	mutation arises, if the mutation either helps or harms the, the new copies ability to spread,
4595480	4600280	now you have differences in the rate of replication and that itself constitutes selection.
4600280	4606760	In addition to that, um, the, the, this meta algorithm, which by the way caught myself
4606760	4611240	not crediting the, uh, this, the, the idea of the meta algorithm originated with
4611800	4618440	a temple in a different context, but the, the meta algorithm could also, um,
4620520	4628040	have, you know, act as a sort of arbiter of ideas or select or arbiters, but impose additional
4628040	4635640	selection pressures on the idea pool. Um, now how in detail that would work, I think is depends on
4635640	4644200	what happens at runtime, um, because it might, it might, um, look at some ideas for what to do
4644200	4649720	and what selection pressures to enact on the idea pool itself. So there's some kind of feedback
4649720	4653240	loop there, but the details of it, the kinks I think need to be worked out there.
4658040	4665400	Okay. Then we have two questions in the chat by Taha. The first one is in the case of genes,
4666200	4672600	RNA, DNA, uh, we know what the replication unit is made of, a sequence of nucleotides.
4673240	4676200	What constitutes the replication unit of an, of an idea?
4678280	4686120	Yes, this is a great question. Um, I would, uh, I would follow Dawkins here who, who says, well,
4686680	4691160	you know, on the one hand we have the, the physical instance of the replicator,
4692040	4701560	um, which is the molecular structure itself. Um, but, um, so actually the terminology I use is that
4702440	4706680	that I would call an instance of a replicator, a physical instance of that replicator. And
4706680	4711720	although maybe I'm jumbling biological terms, but I would consider even that, um, physical
4711720	4717640	instance of that string of molecules itself, part of that replicator's phenotype, which may sound
4717720	4722280	a bit confusing until you realize that the replicator itself is actually an abstraction.
4723080	4729640	Um, the replicator is not physical. It has physical instant physical instantiations,
4729640	4736040	but the replicator is an abstraction because as Dawkins explains, the replicator is that part of
4736040	4741880	this, this string of DNA that manages to stay the same over many, many generations for, you know,
4741880	4749720	for as long as possible. And so this is just a chain of instances and that, of course, that chain
4749720	4755800	physically exists, but it also exists over time. And so some of the older chains, some of the older
4755800	4759320	part of the chain would already be gone at that point. And still we would consider all that part
4759320	4765720	of the same replicator. So it's abstract. Those are independent of the, the physical instantiation.
4766440	4774360	Um, but so the unit of, the unit of replication, in that sense, we could ask the same question
4774360	4783880	also when it comes to memes. Um, in the mind, I think are, are again these, the, again, at the
4783880	4788600	risk of sounding too technical, the functions in the sense of the lambda calculus, these little
4788600	4794360	programs, just think of them as programs, really. Um, those are the ones that replicate. And of
4794360	4799880	course they're going to have a physical instantiation in the physical memory now again, in the sense of
4799880	4806440	storing stuff, not in the sense of remembering stuff in the brain. Um, I think Dawkins even went
4806440	4813560	so far as to say one time that, you know, he proposed this conjecture that maybe we, if, if you have a
4813560	4817480	joke in your mind and I have a joke in my mind or in your brain, I have a joke in my brain,
4817480	4821880	that maybe that means that the neuronal structures and coding that joke are the same. So maybe
4822840	4829080	meme replication implies, uh, replication of neuronal structures across brains or something.
4829880	4834440	Um, actually I think I'm getting ahead of myself here. Um, so the replication unit of an idea
4835400	4839960	is the function in the sense of the lambda calculus. I hope that helps.
4840680	4846920	Yes, I think it makes sense. Just get a clear picture for myself. Do you mean that, uh,
4847400	4852280	there is, there is something that you and I have in common when we have the same idea in, in our
4852280	4857080	minds, or that we have a similarity when we have the same joke, then whatever is encoding that joke
4857080	4867880	in our, uh, in our brains has to be, uh, fundamentally the same thing. Like it is, it is encoding the
4867880	4872520	same abstraction, as you would say. And it might do so differently. It might use a different encoding,
4872520	4876760	a different encoding, but it is, they're both encoding the same abstractions in that sense.
4877960	4883240	Yeah, provided that enough error correction has gone into it, the, the, I agree, the abstraction
4883240	4891080	that, that encodes the idea in your mind should be roughly at least similar to, to the encoding
4891080	4896600	in my mind. Yes. Right. Okay. And then there's the second question, uh, also from Taha, uh,
4896600	4901560	which goes knowing that the sequence of a gene allows us to target it with a strip of DNA,
4902600	4905880	how can we do the same and target this specific idea?
4908040	4914280	Yeah. Um, that's also a really great question. Uh, well, if you, maybe we can go back to the,
4914280	4918680	the thought experiment I suggested earlier with the, with the brain interface that allows you to
4918680	4924200	connect to someone's brain and, you know, read the source code. I don't know how exactly you would
4924200	4931640	do that, but if you somehow manage to, and I think that process itself would involve
4932520	4939160	conjecture and refutation. So the brain interface may need to be a person, but, um,
4940200	4946680	if somehow you manage to do that and you, you can turn the zeros and ones in the brain somehow back
4946680	4953080	into, um, functions, you know, represent them as functions in the sense of the Lambda calculus,
4953080	4957240	then what you could do is you, at any point in that source code, you could make modifications or
4958280	4962520	split it or put something new in there. Um, all this stuff would be available to you.
4963320	4966600	Seems to me a challenge to, to make that happen, that, that interface.
4968040	4974600	Great. Um, then yeah, we, uh, we're almost through the 45 minutes
4975960	4981320	and I don't see any further questions, uh, unless someone has them now in which case,
4981640	4988680	please, please go ahead and ask. Um, uh, yeah, go ahead. Yeah, if you don't mind me asking a
4988680	4995400	second one, that's okay. So I was just wondering about like, uh, so do you think, uh, a conflict
4995400	5003480	or problems are a necessary precondition for a conjecture or, uh, because I was thinking about,
5003480	5011560	like in order for us to, um, identify a problem, would we first need to conjecture that a problem
5011560	5016520	exists? So in other words, there's like, let's take a simplistic, probably unrealistically
5016520	5025480	simplistic case. There's two conflicting ideas. Um, and, uh, we're, we're conjecturing solutions to
5025480	5033320	that problem. Do we need to conjecture that there is a problem? Uh, and then like just as a related
5033320	5040040	idea, uh, in order to conjecture anything in order for any new variation of an idea to, to come about,
5040840	5045160	does that kind of conflict need to, need to exist? If that makes sense.
5046760	5055480	Um, I think the answer is no for, because new ideas will just evolve by virtue of replication
5055480	5065640	being imperfect over time. Um, but when there is a conflict between ideas, um, that certainly
5065640	5071640	helps. And I would imagine that at least that is the main thing. Like I said, that we're consciously
5071640	5077560	aware of when we do come up with a new conjecture is, is because it is in response to a problem. So
5077560	5082040	I still think that problems are the raw material of creativity and so forth. Um, but strictly
5082040	5088920	speaking, no conjectures could arise just by virtue of, of imperfect replication. Okay. Okay. Thanks.
5091640	5093880	Okay. Uh, any other questions?
5098360	5105080	Antonio, go ahead. Thank you. Um, do you think there's a difference between
5106040	5113000	the perception of a problem, so this conflict between ideas and sensory perception in general?
5117000	5123640	Um, could you elaborate a little more? Yeah. Do you think there is, I mean, when you realize
5123640	5132120	that there is a conflict between two ideas, isn't this something you perceive via your senses?
5133080	5141320	Is there, is it a different physical structure, say from vision or from looking at the screen or
5141320	5147160	recognizing a bicycle? When you recognize that there is a problem between two ideas,
5147880	5155800	do you think it's a different object in a way than recognizing a physical object around you?
5156360	5163800	Um, I think those are, those are different things. Um, when we experience a problem,
5164840	5171400	um, experience, yeah. Right. When we experience a problem, I mean, maybe I use the term experience
5171400	5176520	differently, but this, the sensation we have, sensations also tricky term because it has sense,
5177400	5182040	but the, the sensation we have when we experience a problem with cognitive dissonance
5183000	5188600	need not result from sense data. It certainly can happen that you're, you know, with an optical
5188600	5192040	illusion, for example, you think you're looking at one thing, but it's actually another and you
5192040	5195080	can change, if you change your perspective, you see, and then you experience that problem,
5195080	5198600	that's a problem you want to solve, but the experience of the problem itself
5199720	5205320	as all experience, I think, is entirely within. That is not something that is induced somehow by,
5205320	5213000	by sensory data. And again, if I agree, I agree, but they're both inside, both when you perceive
5213000	5219080	a bicycle on the road and when you perceive a problem in your mind, both of them are inside you.
5219640	5226360	That's what I'm saying. Is there a difference? Yes. I think there's still a difference when
5226360	5231240	you just look at a bicycle and say you have, you know, I imagine that children learn this when
5231240	5236920	they're very young, they, they creatively conjecture recognition algorithms like shape
5236920	5241960	recognition algorithms so that later they can recognize bicycles. That stuff just happens
5241960	5248200	automatically. Once you see it, once you've created that algorithm, you just recognize bicycles,
5248200	5254760	unless you're horribly deformed or something. Whereas when you have a problem, there's something
5255880	5260760	unknown there. There's something mysterious there. So I still think those are qualitatively
5260840	5265240	different experiences. If that, if maybe if that's where you're getting at it, I don't know if I'm
5265240	5273640	answering the question. Okay. I don't think there is a difference, but yeah. Well, can you elaborate?
5273640	5278360	What, what is it? You think that is the same about it? I mean, at some point to a child,
5279720	5285400	seeing a bicycle was a mystery in the same way that when you think about supernovae or whatever,
5286120	5293320	it's a mystery for you. Right. There is no automatic thing going on. I mean, if at some point,
5294440	5300840	because if you're never exposed to bicycle, then you can be as old as you want, but at some point,
5301560	5310200	you will be mystified by this new object. So I see. Yeah, no, I think you're right that when,
5310200	5314280	for the, when, for the first time you see a bicycle that is a mystery, you know, what is that thing,
5314280	5321400	how does it work and how would I recognize it again? At like that first time, you're confronted
5321400	5325960	with a problem and you want to solve that problem. And in response to it, you learn about the bicycle
5325960	5331080	and you come up with a shape recognition algorithm for the bicycle and so forth. But once you have that,
5332520	5336280	now it's automatic. Now you can just recognize bicycles again. If I look at the window and I
5336280	5343080	see a bicycle that doesn't constitute a problem. So I would, I would still consider those two
5343080	5354760	different things. Well, fair enough. Yeah, I think aren't they just the same thing only one is subjected
5354760	5363800	to empirical criticism and the other is just an internal idea. I'm maybe well. Yeah. I mean,
5363800	5370760	your internal ideas, aren't they criticism? How do you experience? How do you think?
5371720	5374520	Don't you visualize your objections to something?
5376920	5380520	Why do we need to distinguish between these two worlds?
5381480	5385960	It's the same distinction as between science and philosophy, I think. And it's not really a
5385960	5392280	distinction. It's just a matter of where the criticisms come from. And it's useful in some
5392280	5399240	cases, but this is not a fundamental distinction, I think. I'm not sure if Dennis agrees with that,
5399720	5406920	this is how I would understand that. I do, although I still have the feeling that I can't
5406920	5412360	quite put my finger on, on what's your name, Antonio's question. So I feel that I haven't
5412360	5422840	really answered it satisfactorily. Yeah, well, maybe a topic for future discussion. I'm
5422840	5430120	afraid we've run out of time, though. And yeah, I just want to thank Dennis for his great talk. I
5430120	5439160	will do so as usual with appalling in emoji. There you go. And that was a lot of fun. It was
5439160	5443960	great to be here. Yeah, yeah. Thanks so much for coming. And again, I encourage everyone to check
5443960	5449960	out your article on the Conjection Magazine website, which we'll link to in the description of the
5449960	5458600	video. And yeah, so thank you for Logan for helping range this. Thank you and good luck.
5458600	5463720	Yeah, thank you. Okay, goodbye. Thank you, everybody.
