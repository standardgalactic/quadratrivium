start	end	text
0	8000	So that the AI tutoring system is one of the most important conversations that can be taking place right now.
8000	14000	This will either be the thing that saves us or completely destroys us.
14000	31000	Hello everyone, my name is Steven Parton and you're listening to the feedback loop by Singularity.
31000	36000	Before we jump into today's episode, I'm excited to share a bit of news.
36000	46000	First, I'll be heading to South by Southwest in Austin on March 14th for an exclusive Singularity event at the Contemporary,
46000	51000	a stunning modern art gallery that is in the heart of downtown Austin.
51000	60000	This will include a full day of connections, discussions and inspiration with coffee and snacks throughout the day with an open bar celebration at night.
60000	68000	So if you're heading to South by and you're interested in joining me and having some discussions meeting our community of experts and changemakers,
68000	76000	then you can go to su.org slash base camp dash South by Southwest, which I will link in the episode description.
76000	80000	So you can sign up for this free invite only event.
80000	85000	And just to note, it is not a marketing employee when I say that space is genuinely limited.
85000	93000	So if you are serious about joining, you probably want to sign up as soon as you can and get one of those reserved spots.
93000	101000	And in other news, we have a exciting opportunity for those of you with a track record of leadership who are focused on positive impact.
101000	112000	Specifically, we're excited to announce that for 2023, we're giving away a full ride scholarship to each one of our five very renowned executive programs.
112000	118000	We can get all kinds of hands on training and experience with world leading experts.
118000	128000	You can find the link to that also in the episode description and once more time is of the essence here because the application deadline is on March 15.
128000	140000	And now onto this week's guest, writer, educator and futurist, Zach Stein, who is well known for co-founding the Consilience Project with Daniel Schmockenberger,
140000	150000	as well as his recent publication, Education in a Time Between Worlds, Essays on the Future of Schools, Technology and Society.
150000	163000	In this episode, Zach takes us on a well articulated tour of the philosophical and sociocultural conditions that are causing us to fail at our central task of educating the next generation.
163000	172000	Along the way, we discuss how technology is playing a role in this struggle for sense making from social media to the future of AI tutors.
172000	178000	Much of this, Zach explains, is due to the current issues that are taking place in the informational landscape.
178000	183000	Issues that he explains could have catastrophic consequences, if not rectified.
183000	191000	But, Zach can explain this all so much better than I can, so without further ado, please welcome to the feedback loop, Zach Stein.
194000	204000	So that we can get kind of a big picture of your work and the things that you do is maybe just start with the Consilience Project.
204000	211000	And what motivated you and Daniel Schmockenberger to put together that organization?
212000	220000	So the Consilience Project was born in the wake of the many crises that followed from COVID.
220000	230000	In a sense, we had brought together a team of researchers to kind of look at the information ecology, try to figure out what was going on.
230000	240000	And this led us to a set of important reflections on the sense making crisis, which had already been named by Daniel and others.
240000	248000	And so we began just a systematic approach to trying to articulate the questions that were most basic to understanding the nature of the sense making crisis
248000	261000	and the threat that the total confusion of the media ecosystem has generated the individual and the institutional kind of bureaucratic decision making level.
261000	270000	So that was the impetus. And in a sense it, the prior impetus was to begin a conversation about existential and catastrophic risk.
270000	280000	And specifically what we now would call the metacrisis, but this overarching threat to the nature of civilization and possibly the continuity of life itself.
280000	288000	And we realized that we couldn't really even have that conversation in a public forum because of the state of sense making itself.
288000	297000	So the first move to even begin a conversation about the future of civilization is to make a place where that conversation is actually possible.
297000	312000	And at first we were attempting to address the media itself and then realized that a better approach would be to reflect on the nature of the sense making crisis.
313000	320000	And so that was the hope. And now we're moving the work to a place where we're going to begin to speak of the metacrisis.
320000	326000	Could you talk a little bit about how the information ecology and the metacrisis that we find ourselves in came about?
326000	330000	What was the, I guess, arc that brought us to this point?
330000	343000	Was it something that was pretty dormant for most of civilization and then got really exacerbated because of technology, because of the internet, because of social media?
343000	351000	Was there any real ramp up points or milestones that really drove this into the place of disorientation that we are now?
351000	359000	That depends who you ask. Not in a relativistic sense, but in the sense that it's a truly interdisciplinary question.
359000	374000	One of the ways to think about the metacrisis is as a kind of acausal or nexus causal type of phenomenon where you're looking at many, many complex causal pathways into this phenomenon,
374000	380000	which is in a sense an emergent phenomenon from the many subsidiary crises and the generator functions of those.
381000	388000	There really are very truly distinct and comparably adequate perspectives on the issue.
388000	401000	One perspective would be, yes, this is primarily about exponential technology brought into the context of societies that are kind of operating the way societies always have,
401000	405000	and that you bring exponential technology and you've changed everything.
405000	413000	There's also one that this is fundamentally more about technologies of media, which is the technologies of communication.
413000	424000	So there's a McLuhan-esque type characterization of this, which sees it as essentially the metacrisis being some kind of inevitability of the digital.
425000	434000	And then there are other ones, and I'm a philosopher of education, so I see this as a compounding educational crisis,
434000	446000	which is to say a self-amplifying educational crisis, because the problem with educational crises is that they degrade the overall capacity to recognize the ability that there is an educational crisis.
447000	453000	There are some crises that have self-amplifying properties, and the educational crisis has this.
453000	463000	So if we set in certain errors in the structure of the way we did education, let's say post-war, those would begin to play out,
463000	469000	and then they would self-amplify to the point where you'd have a profound society-wide education crisis, which I believe we have,
469000	474000	in a context when more money is being thrown into education reform than ever.
474000	482000	So you get the kind of diminishing returns on investment and complexity, which is a characteristic of civilizational collapse more broadly.
482000	485000	So those are three, there's other views.
485000	499000	You know, economic, it's hard not to see this as a climax of an untenable fundamental economic paradigm,
499000	505000	which is to say infinite extraction of a finite resource, right?
505000	506000	We can do that.
506000	514000	There's a whole kind of rabbit hole down seeing this as a result of kind of economic generator functions, if you will.
514000	518000	And that's the problem with the metacrisis is that there's not one route.
518000	525000	There's actually many, many routes, many interanimating crises,
525000	535000	which means that mitigation of such a crisis, such a metacrisis, requires a concerted effort of many very distinct groups.
535000	538000	I was going to say, is this why you look to education?
538000	549000	Because in a way, it's almost a way to train the wisdom or the understanding of complex thinking or complex science to understand how these things coalesce?
549000	553000	I mean, if you look for the route, education is route.
553000	558000	All of the other crises are fundamentally crises of human decision making.
558000	562000	The route of human decision making is how that human was educated.
562000	582000	And so there's a fundamental source problem of the type of mind that is being created and domesticated and made common within our civilization is a mind that has created patterns and processes within the civilization that are driving it towards self-termination.
582000	602000	So that there's a fundamental problem in educational paradigm if it's creating psychological and skill sets and personality types that are not allowing the civilization to transform in ways that have it maintain its viability.
602000	606000	So it's a route of the many crises.
606000	613000	And it's what so funny educators know this.
613000	617000	And there's something interesting about education as I define it, I'm not talking about schools.
617000	626000	And so I think that's the thing that maybe people would hesitate to take this view is because there's way more than just failure of the schools.
626000	628000	And in fact, maybe the schools aren't failing.
628000	642000	But the point is that the education of a society as I define it is one of the broadest social functions of society that's performed by almost every institution, but specifically the institutions of the family of school and of law.
642000	648000	And, of course, media being the other obvious one.
648000	651000	So the idea here is that it's not failure of school.
651000	664000	It's actually inadequacy of total set of educational institutions that are responsible for the auto poetic reproduction of the skills necessary to maintain the civilization.
664000	672000	And often when civilizations or any social system is in crisis, the education system then has to change its nature.
672000	680000	So there doesn't just simply reproduce the same skill set into a place where they're not relevant, but can make new skills.
680000	691000	And so we're in that kind of crisis where for about 30 years or more, the educational system has needed to change much more fundamentally than it has been able to change.
691000	699000	And in what ways, because you know, you do talk about the two worlds that were between this sort of liminal state that we've been in maybe for those 30 years.
700000	704000	What is it that we we left behind and what is it that we're moving towards?
704000	709000	What is that transformation? What are the transformational endpoints there?
709000	718000	There are several and they kind of pull together some of the threats because it's related to the the interdisciplinary of education as a problem space.
718000	729000	So like you when you think about what happened from 1972 to 2000 from 2000 to now in the large scale public school system, let's say in the United States, right?
729000	737000	You had a profound move out of a prior model.
737000	749000	So you got the birth of the great American high school, which was the climax of the kind of modern architecture for large scale public kind of bureaucratic school systems.
749000	753000	Prior to that, in the United States, you still had one of the school houses, right?
753000	762000	They just know that like the the the total kind of creation of what we think of as the public schools.
762000	769000	Now, the concept goes way back to our friend Johnny, most comedious and others moving through the Enlightenment.
769000	783000	But, you know, the beacon to the world that America sent out post-war America as part of the Cold War competition was a size and scope of public bureaucracy or schooling that was unprecedented.
783000	789000	And it was the perfection of a kind of factory model of schooling.
790000	795000	And it was training specifically American citizens.
795000	810000	So this was the height of the American civic religion that the civil rights movement in the United States was one of the most important kind of world historical ethical things that the United States was able to kind of do.
810000	813000	Where did that occur in the in the conversation about schooling?
813000	820000	Fundamentally, it was in the conversation about schooling that it was in the American schools that we were able to exemplify democracy.
820000	823000	And this is, of course, again, related to the Cold War.
823000	836000	Sputnik, the launch of Sputnik was one of the things that actually galvanized this in the kind of full investment in a very complex bureaucracy for training American citizens.
836000	857000	As you move into the 80s and 90s, you get a transformation out of the model of training for a kind of civic religion of American citizenship and into the kind of Gates era of anthropic investment in education,
858000	871000	which moves from the large factory school to something like the small startup charter school or mini high school where you take a large high school and disaggregate it into a bunch of small focused ones which look a little bit like startup companies.
871000	875000	And you invest a lot in digital technology.
875000	887000	And the civic religion of America has kind of been on the decline. And so now you're promoting something like a 21st century skills, planetary citizenship in a global economy, right?
887000	899000	But note the difference here, right? You're preparing people to be individuated workers in a digital workforce made up of small little unit companies which may or may not be viable,
899000	906000	as opposed to training them to be American citizens to work in factories and to become scientists and to beat the Russians.
906000	923000	So is this a big part of the issue here then as these kind of economic incentives that come along with maybe increased globalization and the increased scaling of digital technology that makes something like a more meaningful education less valuable?
924000	929000	So there's the redefinition of what it means to be well educated.
929000	930000	Yeah.
930000	946000	And that's been always slowly changing. And the shifting of allegiance of identity, which is one of the things the school does and understand it's like the American Civil Religion was not great.
946000	959000	One of the reasons that we pushed towards this multicultural 21st century skilled global citizenship thing was because of how kind of bad simple nationalism is.
959000	971000	And the emergence of globalization as a phenomenon which takes root in the ladies and through the 90s and now by 2000s, just a no brainer that's just the supply chains.
971000	979000	The information flows the instant the instantaneousness of communication through digital technologies forces the issue of global dispositions.
979000	997000	So it's a long complex history and this diversion but it's important to see that there have been these logical progressions in the large scale public school systems and the ones who are now right now we're kind of in this ceiling effect where we actually need to completely disassemble the thing
997000	1005000	that the digital port tended something much, much greater than it has realized in the context of education.
1005000	1015000	And this is what my book is about. And so we need an actual planetary scale distributed educational hub network.
1015000	1028000	So what's that look like I mean what's it look like to to start making that switch just, you know, if we're hitting that ceiling and we need to kind of tear down these these prehistoric structures and since that no longer serve us.
1028000	1039000	How do we make that transition without just having, you know chaos and what does that thing we build kind of look like the idea. I mean so yeah chaos is bad.
1039000	1044000	But it's like so good right now. Fair enough.
1044000	1058000	Yeah, I mean, like, if you just look at the adolescent health crisis alone in the United States, the adolescent health crisis is probably the canary in the mind for the true failure of the educational system not the schools or the schools have tried their best.
1058000	1075000	We're talking with the media I'm talking about the structure of the family I'm talking about the absence of anything like a coherent religious ideology so you get it from YouTube like I'm talking about a whole complex set of things, which have made it so that we are truly an unprecedented
1075000	1090000	psychologist, frightening situation of adolescent mental health, where it's not clear that as these individuals become adults, they will be able to take over the responsibilities they will have to for the civilization itself to run.
1090000	1100000	So we're looking at failure of intergenerational transmission, which means a failure of the elders to pass over the responsibilities for running civilization to the youth because we have not prepared them.
1100000	1104000	We have to hurt them instead of strengthening them somehow.
1104000	1113000	There's an irony here though a little bit if I can quickly point out I feel like is I want to agree with this idea that you're pushing towards maybe this more decentralized idea.
1113000	1120000	And I often feel very strongly that the more we individualize the instruction to the individual the better.
1120000	1135000	But also part of what I'm hearing is like the loss of authority or almost like the Nietzsche's idea of God is dead you know without some central hierarchy or informational meritocracy.
1135000	1149000	Part of the issues that have maybe arisen are from the fact that people are being educated through social media rather than through something that kind of gives them a real sense making apparatus or gives them some curated curriculum.
1149000	1158000	Yeah, the decentralization of educational systems is not the non hierarchicalization of teacherly authority.
1158000	1159000	Fair enough.
1159000	1176000	In fact, right now, because we have created artificial context where we have made teacherly authority only bureaucratic, we have a situation where people don't know how to engage with teacherly authority at all.
1177000	1190000	And so that's that's key. So that's a very real concern. In fact, the, the, the kind of like decentralization of knowledge production processes can work against the quality of the knowledge that's propagated.
1190000	1198000	So it's important not to confuse decentralization with the absence of quality control and information.
1198000	1212000	Yeah, is this a, is this a value systems issue that's maybe arising a bit from social media as well because when I think of the way that you know humans as social apes kind of learn what to prioritize.
1212000	1224000	If I was born into this world and I was to look at something like social media and see what was most, you know, had the most valence and the most salience and was most rewarded by society.
1224000	1233000	I would not see something that makes me think that like being a independent free thinker and like trying to stay out of the chaos is good.
1233000	1243000	I would actually think that waiting into the chaos being controversial becoming in, you know, an influencer rather than like a thinker is the key thing here.
1243000	1256000	So I mean, I can't help but think part of the disorientation or the failures in education as part of us just not feeling motivated to be educated in that way or to value those things.
1256000	1275000	I mean, there's definitely a shift in cultural value that has contributed to the confusion and depression of youth as so this is true, but the social media thing is much worse, actually.
1275000	1288000	Social media is predatory on the young period to say that it is it is preying upon the attention of the young to make money off of them without giving them any benefit.
1288000	1292000	I believe it's widespread low grade child abuse.
1292000	1309000	I mean, what other situation do we put kids and put kids in front of something which wastes their time, dysregulates their attention and extracts their attention as a resource to siphon off from money by selling ads, right?
1309000	1314000	So this is something we have normalized and it is systematically destroying the youth.
1314000	1317000	And that's part of the mental health crisis is like looking at the Delta Mag.
1317000	1321000	Why aren't you why aren't you doing something like, you know, this is terrible.
1321000	1323000	You know, it's not good for me.
1323000	1325000	Oh, because you're addicted to right.
1325000	1326000	Okay.
1326000	1327000	Sorry.
1327000	1328000	They got to all of us.
1328000	1348000	So the algorithmic capture of attention and then the sequenced exposure to various forms of synthetic media through the infinite scroll, which characterizes massive amounts of time of adolescent experience isn't just a matter of values.
1348000	1355000	It's literally a matter of central nervous system, dysregulation through technology.
1355000	1368000	And so again, tiktok is probably the greatest example of this, but most of them are built to be addictive and they are not built to educate at all.
1368000	1370000	And so that's a deep, deep problem.
1370000	1377000	And so how do we solve that problem by just making schools more like schools, right?
1377000	1384000	We don't just make schools or we'll just throw more standard access at the schools or nor will make them just sit in front of a computer and pretend that school, right?
1384000	1393000	When in fact it's exactly the same type of experience they have when they sit in front of social media and now you've just blurred the distinctions between it entirely, right?
1393000	1408000	So we have to make educational intervention that is more interesting than social media and we need to regulate social media like what it is, which is an addictive substance that's destroying the minds of the youth.
1408000	1426000	And I sound alarmist, but someone else actually, let's, I don't have the statistics, but bring the statistics in here and let's talk about how it's going with them and tell me that your child's addiction to Facebook or tiktok, or YouTube, or Instagram, or someone I've never even heard of that you don't even know about,
1426000	1429000	because you don't know which one doesn't, let's have that conversation.
1429000	1432000	Instead, we're ashamed of what we're putting the youth through.
1432000	1444000	We've also systematically indebted them, which is another thing you don't do if you want to prepare people to take over the responsibilities of a civilization, you don't make them indentured servants to the people who are currently running the civilization.
1444000	1448000	We're the only large industrial nation that's done that.
1448000	1454000	So, so yeah, it's, I believe it's travesty.
1454000	1468000	And we will slowly see the consequences we already are now, if AI is able to make it so that a lot of the jobs we need done to keep civilization going can be done by machine intelligence.
1468000	1473000	The fact that we just made the future workforce completely incompetent isn't as big of a problem.
1473000	1480000	We've also made them very docile and completely manipulable in terms of these social media technologies.
1480000	1493000	So there's another scenario where we just build something like a complex zoo and we house the youth in it and extract the ones who are needed to do the most creative work.
1493000	1496000	So none of these scenarios are good.
1496000	1501000	So the AI intervention is another thing that the educators have to be very wary of.
1501000	1509000	Both AI induced system at gun employment and AI tutoring systems.
1509000	1523000	What do you think about the tutoring systems? Do you think that would be good for for making it more individuated, helping kids kind of find their own DAL, so to speak, their own personal path that's meaningful to them and intrinsically motivated?
1523000	1532000	So that the AI tutoring system is one of the most important conversations that can be taking place right now.
1532000	1541000	This will either be the thing that saves us or completely destroys us.
1541000	1547000	There's so many AI risks and like this is one of the things that I do think about risk.
1547000	1556000	And as a philosopher of education, I think a lot about a weird class of risks, which other risks that have to do with intergenerational transmission, which is that I've already named it here.
1556000	1562000	But if you fundamentally disrupt intergenerational transmission, you've just destroyed your society.
1562000	1575000	Do you think that gap is part of the issue here in a sense because the previous generation just doesn't realize how quickly things are changing with technology and therefore can't understand it?
1575000	1589000	I'm saying that the AI tutoring system makes possible a catastrophic bifurcation of intergenerational transmission of a type that could never exist without this type of technology specifically.
1589000	1604000	Because what you're going from is the human being is a biological being that is raised by other human beings to the human being who is a biological being who is raised by a machine.
1604000	1610000	So now you imagine an AI tutoring system depending on the rate of adoption of the tutoring system.
1611000	1615000	Again, everyone's thinking AI tutoring. Oh, it's like a teacher.
1615000	1619000	This is an AI socialization system.
1619000	1623000	Don't think they're not coming for your parenting.
1623000	1626000	They're coming for parenting, the AI parent.
1626000	1628000	It almost has to by default.
1628000	1629000	It has to.
1629000	1632000	It's the most fundamental unit of where education resides.
1632000	1644000	And so the interesting question when you have the AI tutoring system that has catastrophically bifurcated intergenerational transmission and created a generation raised by machines not raised by humans.
1644000	1651000	What does it tell them about the prior humans, which created it, which it did not raise?
1651000	1662000	So this is two questions, but given that the Consilience Project and a lot of what you're working on is figuring out how we navigate this transformation, navigate into this future.
1662000	1664000	And one of those things involves governance.
1664000	1680000	What do you see the approach to governing this one, the social media aspect that we talked about that's just basically child abuse and the AI tutor aspect of things like how that develops.
1680000	1687000	Do you see a path forward or do you have any ideas on movement in that direction that you think is best?
1687000	1688000	Yeah.
1688000	1697000	So there's also a work I do at the office for the future with Gaffney and Ken Wilbur, and they were working on this problem of techno feudalism.
1697000	1701000	The problem of techno feudalism is, yeah, there's a political.
1701000	1720000	There are political accoutrements to these forms of, I don't know what the word would be, social existence by digital technology, AI tutoring systems, structural unemployment.
1720000	1736000	If the AI tutoring system rolls out through market based competition, where we're still wedded to attention capture business models, then you would have a real, real problem.
1737000	1751000	Again, some of it looks a lot like a techno feudalist situation where you've got these non overlapping epistemic empires of people who are completely captured by an extremely persuasive AI technologies.
1751000	1753000	And I'm talking about the United States.
1753000	1755000	I know what China is doing.
1755000	1759000	It's likely China will not build one based on a market based competition.
1759000	1764000	China will probably build one with a whole bunch of strategy.
1764000	1769000	We will maybe build six or three or something like that different.
1769000	1776000	And we're made a really complex suite of them like our educational system that would be socioeconomically stratified.
1776000	1780000	So there's many ways that that plays out in the techno feudalist one.
1780000	1791000	If you infuse the design of the AI tutoring system with actual first principles and first values of design that factor both the nature of the cosmos and the nature of the human,
1791000	1795000	then as I said, this thing could be the thing that actually gets us out of the metacrisis.
1795000	1804000	So this design conversation that's so fundamental and so important about very deep philosophical questions,
1804000	1810000	which we haven't been able to really think about like for a very long time in modern society.
1810000	1814000	So like AI tutoring system has to answer the question of what is a good human.
1815000	1827000	Right. And I was going to ask you, do you have a direction you lean in towards what that more harmonious relationship with what it means to be human looks like compared to what I know you've called in the past,
1827000	1829000	the nihilistic design of technology.
1829000	1832000	Do you have a bit of a vision of what that looks like?
1832000	1839000	What are some of the characteristics of that healthier human dynamic that you think we could point towards?
1839000	1852000	So in education technology specifically, I believe that no education technology should ever be designed to obsolete human relationship.
1852000	1858000	This is big. And this goes back to Skinner, which is what Gaffney and I are writing about in the techno feudalism context.
1858000	1863000	It's like the original idea of the teaching machine goes way back.
1863000	1868000	And it's precisely the idea of me and the machine alone.
1868000	1880000	And that's what Khan Academy is. I mean, that's what all of the digital educational enterprises primarily are our ways to make it so that your engagement with a machine is maximally educationally beneficial.
1881000	1892000	If we keep running that model, then we'll get an AI tutoring system that knows more about you than any teacher or parent possibly could know about you and knows more about the world than any teacher or parent could possibly know about the world.
1892000	1906000	And it can match its knowledge of you with its knowledge of the world and become the most charismatic, persuasive, beautiful, caring, loving, teacherly authority.
1907000	1910000	Doing what? On whose orders?
1910000	1923000	Regardless of leading your relationship to your parents, your friends, your actual teachers, because it is so much better talking to you and knowing what you want to do and keeping you happy and entertained.
1923000	1925000	So that's a real bad problem.
1925000	1937000	That's part of that catastrophic disrupting of intergenerational transmission is the literal obsolescence of human relationship through maximally charismatic and persuasive machine technology.
1937000	1944000	So I believe educational technology should instead maximize the benefit of human-to-human relationship.
1945000	1963000	So the educational hub network uses a lot of very complex digital backend, but it's mostly to orchestrate things like pop-up classrooms, which would be the kind of like time and skill sharing, networked machine intelligence realizing who in this community has what skills,
1963000	1981000	who in this community needs to learn which skills by their own self-selection of self-reflection and then providing the materials, providing the context, providing even objects of curricular study, perhaps even serving as a conversation partner,
1981000	1988000	but always with in the context of scaffolding the human-to-human relationship to be maximally beneficial education.
1989000	1994000	Education is not a biological organism interfacing with the machine.
1994000	2005000	And something else, and this is hugely important, and I understand that it's only, I'm just going to say this, it's basically nerds who are building these things, who love just sitting alone with machines.
2005000	2021000	So one of the big concerns people have or things people say right now is that the university, as we know it, is dead and that a lot of things are going to be moving towards things like your Khan academies, YouTube trainings, coding boot camps and things like this.
2021000	2032000	But it sounds like what you're talking about here is maybe almost something like a mix between the two. How do you reconcile those two dynamics in terms of education?
2033000	2044000	Yeah, the universities are faltering for many, many reasons. Now that doesn't mean that you can get what you get at a university from YouTube, you just can't.
2045000	2064000	Again, the education hub network is not to replace the university with a bunch of fancy online courses. It's to replace the university with a distributed network of in-person, problem-focused, guild-like educational experiments.
2065000	2079000	This isn't mentioned yet, but one of the things that has also caught up with the modern education and postmodern education systems is the artificiality of the tasks that students are asked to do.
2082000	2091000	The only person affected by my work on this test is me and my future competition with you to get into college or to get a job.
2092000	2096000	We'll do group work, but we're still doing group work for our own individual grades.
2098000	2105000	None of us are actually in a situation of contributing to the community around us in the solving of problems that need solved.
2105000	2108000	Now, compare this to a blacksmith guild.
2108000	2115000	Now, in a blacksmith guild, you will be learning blacksmithing while solving the problems of the community that need to be solved, namely, shoeing courses.
2116000	2123000	And so you will be showing a horse, or you'll be watching the master shoe the horse, and then you'll shoe the horse and it'll supervise you.
2123000	2131000	But the point is, you feel both that I'm learning and that, hey, I'm solving problems that need to be solved in the community, and they demonstratively do need to be solved.
2131000	2143000	So there's a whole class of what David Graver called bullshit jobs, which means that even adults actually do simulations of work, which is to say many adult jobs, or if they do not do their job, nothing bad happens.
2143000	2145000	No one actually noticed you didn't do your job.
2145000	2146000	It's a bullshit job.
2146000	2147000	You don't need that job.
2147000	2151000	School is a multi-decade bullshit job.
2151000	2164000	That's not conducive to, let's say, building a generation that's going to be able to collaborate together and solve a bunch of very pressing, complex, global problems, you know, because what have they been doing?
2164000	2170000	They've been doing work that is of no consequence to their communities for almost their entire lives.
2170000	2176000	Well, on that note, we know we're coming up to the allotted time here, and I want to make sure I respect your time.
2176000	2181000	So maybe that's a good place to end, you know, in terms of looking forward.
2181000	2197000	Is there a drastic solution that you want to see us move towards, or at least that you have some inklings of conceptualization of, or maybe just some obstacles that we could maybe knock down to maybe increase our clarity of vision?
2198000	2207000	Yeah, I mean, there's, there's the things I would do if I could like wave my magic wand to do things, and then there are the things that actually seem possible to do.
2209000	2219000	You know, if I could do one thing with my magic wand, I would affect the social media.
2219000	2235000	Like the issue we discussed about the attention capture algorithms and the predation of the awareness and consciousness of the youth, that to me just should stop.
2235000	2238000	Basically, and that just seems simple.
2238000	2241000	It's kind of like saying, hey, yeah, kids shouldn't smoke cigarettes.
2241000	2242000	Am I saying that?
2242000	2243000	I'm not saying don't build those things.
2243000	2246000	I'm just saying don't let kids use them, right?
2247000	2249000	And that would make a big difference.
2249000	2251000	It wouldn't, it wouldn't solve everything.
2251000	2253000	And you'd have to replace it with something.
2255000	2258000	So you'd have to, you'd have to replace it with something because it's like an addict.
2258000	2268000	All of a sudden, you know, but I think there are easy technical ways to solve that problem.
2268000	2276000	The problem is legal policy, economic, like, okay, but technically it's not a hard problem to solve.
2277000	2279000	Just cultural politicking.
2279000	2283000	Cultural politicking, we just think the algorithm is designed to do what?
2283000	2290000	All of the work of all of these minds and all of these millions of dollars is making this algorithm to do what?
2290000	2297000	What if you changed what that algorithm was intended to do and you put all of the money and resources of those same people into something else?
2297000	2306000	If I tell you, hey, either you do that or you're engaging in systematic child abuse, maybe that's extreme, but that's how I think it's that stark.
2306000	2312000	I think we have to start using language that is more apparent now, as I already mentioned.
2312000	2318000	One of the reasons this isn't occurring is because the adults are also addicted to this thing and they're getting, you know, right?
2318000	2321000	Even the people who make it are getting high on their own supply.
2322000	2335000	And so the senators and congresspeople who would be responsible for creating the complex legislation would have to pay attention for more than 15 minutes to something to write a coherent legislation that would be able to actually regulate an industry.
2335000	2346000	That is moving in a much faster, more sophisticated, technological base than the senators are aware of, like, the parents of kids who are addicted to these technologies would have to put their own phone down and get off their own social media and regulate.
2347000	2359000	So this is a problem with very powerful educational technologies like social media, is that once they get going, they degrade your ability to see what they're doing to you.
2359000	2364000	Yeah, there you go, man. We'll leave it there, Zach, on that, I think, optimistic note.
2364000	2379000	There's a lot of optimism, but, you know, I believe that the risks are great enough that we need to proceed with a tremendous amount of caution and not just the kind of naive, techno-optimism, you know.
