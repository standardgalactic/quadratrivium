1
00:00:00,000 --> 00:00:03,000
All right. Thanks for the intro.

2
00:00:03,000 --> 00:00:07,000
Indeed, the title of the paper is

3
00:00:07,000 --> 00:00:10,000
Solucidating the Descent Space of Diffusion Based Tensive Models.

4
00:00:10,000 --> 00:00:14,000
This is work with Tero, myself, Timo and Samuli from NVIDIA.

5
00:00:14,000 --> 00:00:20,000
The agenda here is to try and make sense

6
00:00:20,000 --> 00:00:24,000
of these recently immersed diffusion models,

7
00:00:24,000 --> 00:00:28,000
but really dig into the fundamentals

8
00:00:28,000 --> 00:00:32,000
and with that understanding then ask what are the best practices

9
00:00:32,000 --> 00:00:36,000
for designing and wanting these methods.

10
00:00:36,000 --> 00:00:41,000
So for a brief background on generative modelling,

11
00:00:41,000 --> 00:00:45,000
there are many ways to do it, but the idea is usually

12
00:00:45,000 --> 00:00:49,000
you have a dataset of something, for example in this case phase photos,

13
00:00:49,000 --> 00:00:52,000
but it could be anything, even not images,

14
00:00:52,000 --> 00:00:55,000
and you want to train some kind of a neural method

15
00:00:55,000 --> 00:00:59,000
for basically converting random numbers into random

16
00:00:59,000 --> 00:01:03,000
novel instances from that data distribution.

17
00:01:03,000 --> 00:01:07,000
And after recently GANs where the leading contender in this space,

18
00:01:07,000 --> 00:01:12,000
and these are from there, but now

19
00:01:12,000 --> 00:01:16,000
the denoising diffusion methods have really immersed

20
00:01:16,000 --> 00:01:20,000
as the leading contender here.

21
00:01:20,000 --> 00:01:24,000
So I'm sure we've all seen these superimpressive results

22
00:01:24,000 --> 00:01:28,000
from these models like a stable diffusion,

23
00:01:28,000 --> 00:01:32,000
and everything I'm going to say is basically stuff that runs

24
00:01:32,000 --> 00:01:36,000
at the bottom of these things, and that is in some way directly applicable

25
00:01:36,000 --> 00:01:40,000
to anything like this.

26
00:01:40,000 --> 00:01:44,000
Okay, so all of these methods, the denoising diffusion methods,

27
00:01:44,000 --> 00:01:48,000
the way they implement this idea is you start from pure random noise,

28
00:01:48,000 --> 00:01:53,000
you feed it to a neural denoiser, you keep feeding it,

29
00:01:53,000 --> 00:01:57,000
and reducing the noise level until it reveals a random image

30
00:01:57,000 --> 00:02:01,000
that was hiding underneath the noise, and now you've generated a random image,

31
00:02:01,000 --> 00:02:05,000
so this is a generative model.

32
00:02:05,000 --> 00:02:09,000
One concern with these methods is efficiency.

33
00:02:09,000 --> 00:02:13,000
You need to call this denoiser tens or even thousands of times in some methods

34
00:02:13,000 --> 00:02:17,000
to get the best quality. On the other hand,

35
00:02:17,000 --> 00:02:21,000
it's indeed a trade with the quality of the individual

36
00:02:21,000 --> 00:02:27,000
generative images and with the distribution as a whole.

37
00:02:27,000 --> 00:02:31,000
And these tradeoffs are not really well understood in this previous work.

38
00:02:31,000 --> 00:02:35,000
And some methods simply work better than others,

39
00:02:35,000 --> 00:02:39,000
and it's a bit of a folklore that this one seems to be

40
00:02:39,000 --> 00:02:43,000
good one, good and so on.

41
00:02:43,000 --> 00:02:47,000
And there are many ways to formulate the theory of these methods.

42
00:02:47,000 --> 00:02:51,000
There are, like, market chains, stochastic differential equations,

43
00:02:51,000 --> 00:02:55,000
and some more exotic ways. But when you kind of strip away

44
00:02:55,000 --> 00:02:59,000
all those fancy theories, in the end they all do something like this.

45
00:02:59,000 --> 00:03:03,000
But they differ, lastly,

46
00:03:03,000 --> 00:03:07,000
in practical design choices.

47
00:03:07,000 --> 00:03:11,000
Like at what rate do you reduce the noise level

48
00:03:11,000 --> 00:03:15,000
at different stages of the generation? Do you do this?

49
00:03:15,000 --> 00:03:19,000
Oh, it's showing.

50
00:03:19,000 --> 00:03:23,000
Does anyone know it?

51
00:03:27,000 --> 00:03:31,000
Yeah, thanks.

52
00:03:31,000 --> 00:03:35,000
Yeah, whether you do this deterministically

53
00:03:35,000 --> 00:03:39,000
or stochastically, we'll see the difference soon.

54
00:03:39,000 --> 00:03:43,000
How do you deal with vastly different

55
00:03:43,000 --> 00:03:47,000
single magnitudes at different stages of this process? Do you predict the signal

56
00:03:47,000 --> 00:03:51,000
or the noise? And so on.

57
00:03:51,000 --> 00:03:55,000
And given that ultimately these are the only differences between these existing methods,

58
00:03:55,000 --> 00:03:59,000
these must be the explanation for their vastly different performance

59
00:03:59,000 --> 00:04:03,000
characteristics also. And these are something we wanted to understand

60
00:04:03,000 --> 00:04:07,000
in this process and project.

61
00:04:07,000 --> 00:04:11,000
So we'll be building on the differential equation formulation

62
00:04:11,000 --> 00:04:15,000
from a couple of years back, where the images seem to evolve

63
00:04:15,000 --> 00:04:19,000
according to stochastic or an ordinary differential equation.

64
00:04:19,000 --> 00:04:23,000
And in principle it's known that this kind of generalizes

65
00:04:23,000 --> 00:04:27,000
all of those other methods. You can express them in this framework.

66
00:04:27,000 --> 00:04:31,000
But nobody has really gone through the work of getting their hands dirty

67
00:04:31,000 --> 00:04:35,000
and sorting everything into a sort of

68
00:04:35,000 --> 00:04:39,000
common framework where you could compare and

69
00:04:39,000 --> 00:04:43,000
understand the impact of these design choices. So that's the first thing

70
00:04:43,000 --> 00:04:47,000
we are going to be doing here. And armed

71
00:04:47,000 --> 00:04:51,000
with that knowledge, we'll then ask what are the best

72
00:04:51,000 --> 00:04:55,000
practices for running this sampling process, namely how do you

73
00:04:55,000 --> 00:04:59,000
manage this chain of denoising steps in the best possible way.

74
00:04:59,000 --> 00:05:03,000
First the deterministic version and then the stochastic version.

75
00:05:03,000 --> 00:05:07,000
And then finally we'll come to

76
00:05:07,000 --> 00:05:11,000
best practices for training these neural networks. How do you precondition them?

77
00:05:11,000 --> 00:05:15,000
How do you, what are the lost functions?

78
00:05:15,000 --> 00:05:19,000
Why does this keep coming back?

79
00:05:19,000 --> 00:05:23,000
Okay.

80
00:05:23,000 --> 00:05:27,000
And just one thing we won't be looking at

81
00:05:27,000 --> 00:05:31,000
the actual neural architectures like whether you should use the answer or not.

82
00:05:31,000 --> 00:05:35,000
We'll leave that for future work.

83
00:05:35,000 --> 00:05:39,000
So we'll be studying a few key works in this field.

84
00:05:39,000 --> 00:05:43,000
There's this paper that presents the so-called VBVE method.

85
00:05:43,000 --> 00:05:47,000
There's preserving, there's exploding and there's

86
00:05:47,000 --> 00:05:51,000
DDIM, denoising diffusion implicit model.

87
00:05:51,000 --> 00:05:55,000
It's not really that important for us what the difference is between these

88
00:05:55,000 --> 00:05:59,000
but on the face of it they look kind of like

89
00:05:59,000 --> 00:06:03,000
packages that you have to take as a whole.

90
00:06:03,000 --> 00:06:07,000
You cannot mix and match their properties.

91
00:06:07,000 --> 00:06:11,000
But this is not really true.

92
00:06:11,000 --> 00:06:15,000
The running theme in this paper

93
00:06:15,000 --> 00:06:19,000
is that we identify this complete and exhaustive set of

94
00:06:19,000 --> 00:06:23,000
design choices that completely characterize and reproduce

95
00:06:23,000 --> 00:06:27,000
any given method or at least these three methods and many others

96
00:06:27,000 --> 00:06:31,000
in this space. And this gives us sort of an

97
00:06:31,000 --> 00:06:35,000
extra view into the internals of these methods. We can ask

98
00:06:35,000 --> 00:06:39,000
what are the exact design choices they made about this and this aspect.

99
00:06:39,000 --> 00:06:43,000
Now don't worry. We won't be looking at slides

100
00:06:43,000 --> 00:06:47,000
like this. I'll try to keep it visual and intuitive

101
00:06:47,000 --> 00:06:51,000
to the extent possible. But the important point here is that this can be done

102
00:06:51,000 --> 00:06:55,000
and with this knowledge we can then ask what is the

103
00:06:55,000 --> 00:06:59,000
best choice for any given design point here.

104
00:06:59,000 --> 00:07:03,000
And that gives us our method, which will be building piece by piece

105
00:07:03,000 --> 00:07:07,000
and that then yields significantly improved results.

106
00:07:07,000 --> 00:07:11,000
And we'll be measuring our progress with the FID

107
00:07:11,000 --> 00:07:15,000
metric, which is sort of the current cost standard

108
00:07:15,000 --> 00:07:19,000
in evaluating any kinds of generative models.

109
00:07:19,000 --> 00:07:23,000
So let's start looking at how

110
00:07:23,000 --> 00:07:27,000
Song and Colleagues build this

111
00:07:27,000 --> 00:07:31,000
and I'll formulate this denoting diffusion problem

112
00:07:31,000 --> 00:07:35,000
using differential equations.

113
00:07:35,000 --> 00:07:39,000
So throughout this talk I'll be using this running toy example,

114
00:07:39,000 --> 00:07:43,000
which is actually one detoy example, which is actually quite

115
00:07:43,000 --> 00:07:47,000
actually in many ways completely representative of the actual thing that's going on

116
00:07:47,000 --> 00:07:51,000
with images. So in a way this is one of the images where

117
00:07:51,000 --> 00:07:55,000
you would have more dimensions on the x-axis,

118
00:07:55,000 --> 00:07:59,000
with actual high-dimensional images, like

119
00:07:59,000 --> 00:08:03,000
one megapixel image is a million numbers, so that would be a million dimensional space.

120
00:08:03,000 --> 00:08:07,000
But this describes the essential characteristics of it.

121
00:08:07,000 --> 00:08:11,000
So the point is we have some distribution of data.

122
00:08:11,000 --> 00:08:15,000
Let's imagine there are cat and dog photos or something

123
00:08:15,000 --> 00:08:19,000
and it happens to be this bimodal thing, so certain pixel values

124
00:08:19,000 --> 00:08:23,000
are more probable than others.

125
00:08:23,000 --> 00:08:27,000
We want to learn to produce novel samples from this distribution.

126
00:08:27,000 --> 00:08:31,000
We have a handful of examples, or let's say millions

127
00:08:31,000 --> 00:08:35,000
of examples, which is our data set, and based on those

128
00:08:35,000 --> 00:08:39,000
we want to learn to do this. So in this analogy

129
00:08:39,000 --> 00:08:43,000
one of the samples we have might be this dog photo.

130
00:08:43,000 --> 00:08:47,000
On the other axis

131
00:08:47,000 --> 00:08:51,000
we have increasing time, which is essentially increasing

132
00:08:51,000 --> 00:08:55,000
noise level. That's what we are going to be dealing with when we want to reduce this noise.

133
00:08:55,000 --> 00:08:59,000
But before we do that

134
00:08:59,000 --> 00:09:03,000
let's look at the easier direction of adding noise, like

135
00:09:03,000 --> 00:09:07,000
destroying an image. So if I start taking this

136
00:09:07,000 --> 00:09:11,000
image from the training data set, I gradually start adding noise onto it.

137
00:09:11,000 --> 00:09:15,000
I end up doing this random work in this pixel

138
00:09:15,000 --> 00:09:19,000
value space until the image is completely drowned under

139
00:09:19,000 --> 00:09:23,000
this white noise. And if I have a population of images

140
00:09:23,000 --> 00:09:27,000
in the end they'll all become

141
00:09:27,000 --> 00:09:31,000
indistinguishable white noise. So if I plot

142
00:09:31,000 --> 00:09:35,000
the density that these trajectories make

143
00:09:35,000 --> 00:09:39,000
it'll look like this. So the density of the data

144
00:09:39,000 --> 00:09:43,000
on the left edge becomes diffused over time until it's completely

145
00:09:43,000 --> 00:09:47,000
normally distributed at the end. And this is really nice now

146
00:09:47,000 --> 00:09:51,000
because it has disappeared again.

147
00:09:51,000 --> 00:09:55,000
No.

148
00:09:55,000 --> 00:09:59,000
I'll try

149
00:09:59,000 --> 00:10:03,000
one thing.

150
00:10:03,000 --> 00:10:07,000
I'll try one thing.

151
00:10:07,000 --> 00:10:11,000
I'll try one thing.

152
00:10:11,000 --> 00:10:15,000
Well, maybe we'll just leave

153
00:10:15,000 --> 00:10:19,000
it. Do you think we can do that?

154
00:10:19,000 --> 00:10:23,000
Yeah.

155
00:10:23,000 --> 00:10:27,000
Yeah, let me know if something important seems to be missing underneath it.

156
00:10:27,000 --> 00:10:31,000
So okay. Okay. So yeah, as I said

157
00:10:31,000 --> 00:10:35,000
we can sample from this normal distribution at the right edge. We just

158
00:10:35,000 --> 00:10:39,000
go random in PyTorch. And that'll give us a sample from that edge.

159
00:10:39,000 --> 00:10:43,000
And the magic is that there exists a way

160
00:10:43,000 --> 00:10:47,000
to sort of reverse this path we took earlier.

161
00:10:47,000 --> 00:10:51,000
So go backward in time and that will land us

162
00:10:51,000 --> 00:10:55,000
on the left edge where we have the density of the actual data. And that of course generates an image.

163
00:10:55,000 --> 00:10:59,000
And so if I have a population of these

164
00:10:59,000 --> 00:11:03,000
complete random noises, oops.

165
00:11:03,000 --> 00:11:07,000
Okay.

166
00:11:07,000 --> 00:11:11,000
Yeah, if I had many images I would have gotten

167
00:11:11,000 --> 00:11:15,000
different instances of the image. Okay.

168
00:11:15,000 --> 00:11:19,000
And what makes it stick is that this can be seen

169
00:11:19,000 --> 00:11:23,000
as a stochastic differential equation. In this example

170
00:11:23,000 --> 00:11:27,000
it's about the simplest one we have. When we go forward in time

171
00:11:27,000 --> 00:11:31,000
over a very short time period

172
00:11:31,000 --> 00:11:35,000
the change in image dx equals the omega, which is

173
00:11:35,000 --> 00:11:39,000
white noise. So that's just a mathematical expression

174
00:11:39,000 --> 00:11:43,000
of doing cumulative sum of random noise.

175
00:11:43,000 --> 00:11:47,000
Now the magic is that to this forward equation

176
00:11:47,000 --> 00:11:51,000
corresponds a backward version that has this same

177
00:11:51,000 --> 00:11:55,000
stochastic component, random walk component. But on top of that

178
00:11:55,000 --> 00:11:59,000
it has this term that kind of attracts the samples towards

179
00:11:59,000 --> 00:12:03,000
the data density. You see it's some kind of a gradient of the

180
00:12:03,000 --> 00:12:07,000
density p. But the problem of course is that this p is unknown

181
00:12:07,000 --> 00:12:11,000
and here is the axiomagic. This is a well known function

182
00:12:11,000 --> 00:12:15,000
from previous literature in data science

183
00:12:15,000 --> 00:12:19,000
called the score function and it has the property

184
00:12:19,000 --> 00:12:23,000
that you do not need to know the p if you have

185
00:12:23,000 --> 00:12:27,000
a least gross optimal denoiser for this data set d.

186
00:12:27,000 --> 00:12:31,000
So you can directly evaluate that formula above

187
00:12:31,000 --> 00:12:35,000
by the formula below. And this

188
00:12:35,000 --> 00:12:39,000
is an opportunity. We train a neural network to be such a denoiser

189
00:12:39,000 --> 00:12:43,000
and this means that we can run this kind of

190
00:12:43,000 --> 00:12:47,000
backward equation evolution using that

191
00:12:47,000 --> 00:12:51,000
denoiser.

192
00:12:51,000 --> 00:12:55,000
So some colleagues also present this deterministic variant of this

193
00:12:55,000 --> 00:12:59,000
where you don't have the stochastic term

194
00:12:59,000 --> 00:13:03,000
you only have this chord term scaled in some appropriate way.

195
00:13:03,000 --> 00:13:07,000
And this has a somewhat different like a visual character.

196
00:13:07,000 --> 00:13:11,000
You see it's kind of fading in and out instead of like

197
00:13:11,000 --> 00:13:15,000
jittering around. And this one actually provides

198
00:13:15,000 --> 00:13:19,000
a much cleaner view into this sampling dynamic. So we'll be looking at

199
00:13:19,000 --> 00:13:23,000
this first and then returning to the stochastic later.

200
00:13:23,000 --> 00:13:27,000
And with this I can now always draw this

201
00:13:27,000 --> 00:13:31,000
paint flow lines of this ODE. So the idea

202
00:13:31,000 --> 00:13:35,000
is that we are trying to somehow follow these lines to do the generation.

203
00:13:35,000 --> 00:13:39,000
And indeed the way that happens is by discretization

204
00:13:39,000 --> 00:13:43,000
I take little but macroscopic steps

205
00:13:43,000 --> 00:13:47,000
in this space I reduce the time and

206
00:13:47,000 --> 00:13:51,000
for any change in time I want to jump. The ODE formula

207
00:13:51,000 --> 00:13:55,000
tells me how much the image changes. And again

208
00:13:55,000 --> 00:13:59,000
the ODE formula is already does a neural network

209
00:13:59,000 --> 00:14:03,000
so the neural network tells us where to go on the next step.

210
00:14:03,000 --> 00:14:07,000
That's the general idea. And that gives me a step.

211
00:14:07,000 --> 00:14:11,000
I keep stepping until I hit time zero and that's my generated sample.

212
00:14:11,000 --> 00:14:15,000
With the SDEs we would have some kind of noise addition

213
00:14:15,000 --> 00:14:19,000
on top of this so we would kind of jitter it

214
00:14:19,000 --> 00:14:23,000
but I said we'll leave that for later.

215
00:14:23,000 --> 00:14:27,000
And now we've exactly reproduced this intuitive

216
00:14:27,000 --> 00:14:31,000
picture using differential equations.

217
00:14:31,000 --> 00:14:35,000
Okay so that was song and colleagues

218
00:14:35,000 --> 00:14:39,000
for our purposes. And let's now identify

219
00:14:39,000 --> 00:14:43,000
some design choices involved in making this kind of an ODE or SD.

220
00:14:43,000 --> 00:14:47,000
But before we do that we should understand what can go wrong

221
00:14:47,000 --> 00:14:51,000
in this process. What are the error sources? Well the obvious one

222
00:14:51,000 --> 00:14:55,000
because I might end up like in a different place than I should have

223
00:14:55,000 --> 00:14:59,000
when I do this sampling chain. So the obvious one is that if the network

224
00:14:59,000 --> 00:15:03,000
gives me an incorrect direction I end up moving in the incorrect

225
00:15:03,000 --> 00:15:07,000
direction and in the end I end up somewhat in the wrong place.

226
00:15:07,000 --> 00:15:11,000
It's more subtle than this but this is kind of a cartoon.

227
00:15:11,000 --> 00:15:15,000
The other source of error is that we are trying to approximate this continuous

228
00:15:15,000 --> 00:15:19,000
trajectory in green here using these linear

229
00:15:19,000 --> 00:15:23,000
segments. And

230
00:15:23,000 --> 00:15:27,000
if I try to jump too far at once the curve will kind of

231
00:15:27,000 --> 00:15:31,000
move away from my feet and I'll end up veering off

232
00:15:31,000 --> 00:15:35,000
this path. It's of course familiar to anyone who's done like a physical simulation

233
00:15:35,000 --> 00:15:39,000
with ODE. And

234
00:15:39,000 --> 00:15:43,000
the proof of solutions to that is to take more steps

235
00:15:43,000 --> 00:15:47,000
but that's exactly what we want to avoid because that directly means

236
00:15:47,000 --> 00:15:51,000
more compute to generate an image.

237
00:15:51,000 --> 00:15:55,000
Okay and so what we argue and what is underappreciated in previous

238
00:15:55,000 --> 00:15:59,000
work is that these two effects should be analysed

239
00:15:59,000 --> 00:16:03,000
or can be and should be analysed in isolation.

240
00:16:03,000 --> 00:16:07,000
You don't have to sample in a certain way just because you train your

241
00:16:07,000 --> 00:16:11,000
network in a certain way and so on you can decouple this. And indeed

242
00:16:11,000 --> 00:16:15,000
we'll be looking at sampling first and then coming back to the training later.

243
00:16:15,000 --> 00:16:19,000
Okay so I promise to show you some

244
00:16:19,000 --> 00:16:23,000
choices and here is one finally. So

245
00:16:23,000 --> 00:16:27,000
when I built this example I added noise at a constant rate

246
00:16:27,000 --> 00:16:31,000
over every time step and that gives me this simplicity, it gives me this schedule

247
00:16:31,000 --> 00:16:35,000
where the noise level increases as a square root of time

248
00:16:35,000 --> 00:16:39,000
because that's how the variance will grow linearly so the standard

249
00:16:39,000 --> 00:16:43,000
will go square root. That's what you get

250
00:16:43,000 --> 00:16:47,000
if you call random and then do a comp sum on top of it.

251
00:16:47,000 --> 00:16:51,000
Had I added it at a different rate I might have arrived at a schedule

252
00:16:51,000 --> 00:16:55,000
like this for example where the standard deviation is the gross linearity

253
00:16:55,000 --> 00:16:59,000
and indeed I could do any

254
00:16:59,000 --> 00:17:03,000
kind of a choice here. I could do something even something

255
00:17:03,000 --> 00:17:07,000
crazy like this way we schedule here in the middle if I wanted to

256
00:17:07,000 --> 00:17:11,000
for some reason. And indeed we generalise in the paper the

257
00:17:11,000 --> 00:17:15,000
ODE form or we reparametise it in such

258
00:17:15,000 --> 00:17:19,000
a way that we get a clear view into these effects.

259
00:17:19,000 --> 00:17:23,000
So we can parameterise the noise level we want to have reached

260
00:17:23,000 --> 00:17:27,000
by explicitly by this function sigma.

261
00:17:31,000 --> 00:17:35,000
But the real question is why would you want to do something like this.

262
00:17:35,000 --> 00:17:39,000
Well one reason for that could be that if you look at this picture for example

263
00:17:39,000 --> 00:17:43,000
you see almost nothing happens until

264
00:17:43,000 --> 00:17:47,000
at almost zero noise level suddenly curves rapidly

265
00:17:47,000 --> 00:17:51,000
to one of these two basins and

266
00:17:51,000 --> 00:17:55,000
there's high curvature there so we'd probably want to be careful

267
00:17:55,000 --> 00:17:59,000
in stepping. We'll want to take somehow be more careful in sampling

268
00:17:59,000 --> 00:18:03,000
that region and less careful you're in the bulk. So there's two ideas

269
00:18:03,000 --> 00:18:07,000
of how you might do that. You might

270
00:18:07,000 --> 00:18:11,000
first you might take shorter steps at the more difficult parts

271
00:18:11,000 --> 00:18:15,000
usually is the low noise levels because that's where the

272
00:18:15,000 --> 00:18:19,000
image details are usually built. The other alternative

273
00:18:19,000 --> 00:18:23,000
would be to instead warp the noise schedule in such a way

274
00:18:23,000 --> 00:18:27,000
that you just end up spending more time at these difficult parts.

275
00:18:27,000 --> 00:18:31,000
And it's tempting to think

276
00:18:31,000 --> 00:18:35,000
that these two approaches would be equivalent.

277
00:18:35,000 --> 00:18:39,000
And this is an implicit assumption I think that many previous works do.

278
00:18:39,000 --> 00:18:43,000
But this is simply not true because the error characteristics

279
00:18:43,000 --> 00:18:47,000
can be vastly different between these choices like the error that comes

280
00:18:47,000 --> 00:18:51,000
from this tracking this continuous curve

281
00:18:51,000 --> 00:18:55,000
and we'll see the effect of that later.

282
00:18:55,000 --> 00:18:59,000
So now we've identified the first pair of design choices here.

283
00:18:59,000 --> 00:19:03,000
The time steps and the noise schedule.

284
00:19:03,000 --> 00:19:07,000
But let's introduce a couple more.

285
00:19:07,000 --> 00:19:11,000
And this address is the following problem. I zoom out a little

286
00:19:11,000 --> 00:19:15,000
because in reality we add a ton of noise. So at the

287
00:19:15,000 --> 00:19:19,000
other extreme the noise level is very large. I've been showing this zoom in

288
00:19:19,000 --> 00:19:23,000
so we can easier see what's going on. But I zoomed out

289
00:19:23,000 --> 00:19:27,000
now to see what's here. So the issue

290
00:19:27,000 --> 00:19:31,000
if you don't do anything is that the signal magnitude grows

291
00:19:31,000 --> 00:19:35,000
as the noise level grows. You keep piling noise. The signal

292
00:19:35,000 --> 00:19:39,000
is quite simply bigger numerically like the values that

293
00:19:39,000 --> 00:19:43,000
are in your sensor. They are much larger at the high noise levels

294
00:19:43,000 --> 00:19:47,000
than in the low noise levels. And this is known to be really bad for neural network

295
00:19:47,000 --> 00:19:51,000
training dynamics. And these kind of

296
00:19:51,000 --> 00:19:55,000
effects are actually critical to deal with to get good performance.

297
00:19:55,000 --> 00:19:59,000
So the way many previous works approach this is by using

298
00:19:59,000 --> 00:20:03,000
something called variance preserving schedules where you effectively

299
00:20:03,000 --> 00:20:07,000
introduce this additional

300
00:20:07,000 --> 00:20:11,000
so called scale schedule where you squeeze

301
00:20:11,000 --> 00:20:15,000
the signal magnitude into this constant with constant

302
00:20:15,000 --> 00:20:19,000
variance tube. So that makes

303
00:20:19,000 --> 00:20:23,000
that's one way to make the network happy here.

304
00:20:23,000 --> 00:20:27,000
So we generalize this idea again by

305
00:20:27,000 --> 00:20:31,000
just formulating an OD that allows you to directly

306
00:20:31,000 --> 00:20:35,000
specify any arbitrary scale schedule. And viewing this slide

307
00:20:35,000 --> 00:20:39,000
it again becomes appropriate that the only thing that the scale schedule does

308
00:20:39,000 --> 00:20:43,000
is distort these flow lines in some way.

309
00:20:43,000 --> 00:20:47,000
So you are just doing a coordinate transform in a way on this XT plane.

310
00:20:47,000 --> 00:20:51,000
Now there is an alternative

311
00:20:51,000 --> 00:20:55,000
way to deal with this scaling issue. And it is quite

312
00:20:55,000 --> 00:20:59,000
simply this. Instead of changing the OD at all

313
00:20:59,000 --> 00:21:03,000
you could change your neural network in such a way that it has an initial scaling

314
00:21:03,000 --> 00:21:07,000
layer that uses the known single scale

315
00:21:07,000 --> 00:21:11,000
scale it to something that's palatable for the neural network.

316
00:21:11,000 --> 00:21:15,000
And again you might think that this is completely

317
00:21:15,000 --> 00:21:19,000
accurate with the OD, but this is simply not true because again the error characteristics

318
00:21:19,000 --> 00:21:23,000
are vastly different between these two cases. And I'll come

319
00:21:23,000 --> 00:21:27,000
back soon to how the chosen practice.

320
00:21:27,000 --> 00:21:31,000
But now we've identified a second set, second pair of these matrices.

321
00:21:31,000 --> 00:21:35,000
The scaling schedule and the

322
00:21:35,000 --> 00:21:39,000
scaling that happens inside the neural network itself.

323
00:21:39,000 --> 00:21:43,000
And that we kind of saw so-called preconditioning of the neural network.

324
00:21:43,000 --> 00:21:47,000
Okay, so now we have quite a few

325
00:21:47,000 --> 00:21:51,000
collected here. And

326
00:21:51,000 --> 00:21:55,000
at this point we can ask, like get our hands dirty

327
00:21:55,000 --> 00:21:59,000
go look at the appendices of these papers, read their code

328
00:21:59,000 --> 00:22:03,000
for the final ground truth and ask what

329
00:22:03,000 --> 00:22:07,000
formulas actually exactly reproduce their

330
00:22:07,000 --> 00:22:11,000
approaches. And they are these. Again don't worry, but don't even

331
00:22:11,000 --> 00:22:15,000
try to read them. But the question now is

332
00:22:15,000 --> 00:22:19,000
what choices should we actually make, which ones of these are good, which ones are

333
00:22:19,000 --> 00:22:23,000
suboptimal. And that's going to be the topic of the next section.

334
00:22:23,000 --> 00:22:27,000
And for now, we will be ignoring these neural network training

335
00:22:27,000 --> 00:22:31,000
aspects. We will be using pre-trained networks from previous work.

336
00:22:31,000 --> 00:22:35,000
We won't be retraining anything yet. We'll just try to improve the sampling.

337
00:22:35,000 --> 00:22:39,000
So now we move on to the deterministic sampling

338
00:22:39,000 --> 00:22:43,000
and actual prescriptions of what

339
00:22:43,000 --> 00:22:47,000
you might want to do. So first the noise schedule. Why would

340
00:22:47,000 --> 00:22:51,000
some of them be better than others? For example this way one must be

341
00:22:51,000 --> 00:22:55,000
terrible for some reason, but why?

342
00:22:55,000 --> 00:22:59,000
Well, now we get a clear view.

343
00:22:59,000 --> 00:23:03,000
Well, parameterizing things in this way gives us a

344
00:23:03,000 --> 00:23:07,000
quite a clear view to this. So let's zoom out again.

345
00:23:07,000 --> 00:23:11,000
And consider the fact that

346
00:23:11,000 --> 00:23:15,000
we are trying to follow these curving trajectories by following

347
00:23:15,000 --> 00:23:19,000
these linear tangents. And that's probably going to be more successful

348
00:23:19,000 --> 00:23:23,000
when the tangents happen to coincide with this curve trajectory.

349
00:23:23,000 --> 00:23:27,000
So when the trajectory is as straight as possible in other words.

350
00:23:27,000 --> 00:23:31,000
So if I use a bad schedule like this one, you see

351
00:23:31,000 --> 00:23:35,000
there's already a visible gap between the tangent and the curve.

352
00:23:35,000 --> 00:23:39,000
So you easily fall off if you try to step too much.

353
00:23:39,000 --> 00:23:43,000
And indeed if I show you this random family of different

354
00:23:43,000 --> 00:23:47,000
schedules, we see that some of them seem to be better in this regard than others.

355
00:23:47,000 --> 00:23:51,000
In particular this one.

356
00:23:51,000 --> 00:23:55,000
And this is actually the same schedule used in the previous work

357
00:23:55,000 --> 00:23:59,000
DDIM, which is known to be quite good.

358
00:23:59,000 --> 00:24:03,000
And this in a way explains it.

359
00:24:03,000 --> 00:24:07,000
So this is the schedule where standard deviation cross-lineally

360
00:24:07,000 --> 00:24:11,000
and we do not use any scaling. And indeed

361
00:24:11,000 --> 00:24:15,000
we'll be leaving the scaling for neural network parameterization.

362
00:24:15,000 --> 00:24:19,000
And the reason for that is that this scaling also introduces unwanted

363
00:24:19,000 --> 00:24:23,000
curvature into these lines.

364
00:24:23,000 --> 00:24:27,000
Yeah, it just turns them unnecessarily at some point.

365
00:24:27,000 --> 00:24:31,000
It's actually better to let the

366
00:24:31,000 --> 00:24:35,000
signal in the ODE grow from that perspective.

367
00:24:35,000 --> 00:24:39,000
As further, and yeah, with this the

368
00:24:39,000 --> 00:24:43,000
is the ODE becomes very simple. So as a further

369
00:24:43,000 --> 00:24:47,000
demonstration, like an actual mathematical fact about this

370
00:24:47,000 --> 00:24:51,000
schedule and why it allows us to take long steps is that

371
00:24:51,000 --> 00:24:55,000
if I took a step directly to times zero, then

372
00:24:55,000 --> 00:24:59,000
with this schedule and only this schedule

373
00:24:59,000 --> 00:25:03,000
the tangent is pointing directly to the output of the denoiser.

374
00:25:03,000 --> 00:25:07,000
And that's very nice because

375
00:25:07,000 --> 00:25:11,000
the denoiser output changes only very slowly during the

376
00:25:11,000 --> 00:25:15,000
sampling process. And this means that

377
00:25:15,000 --> 00:25:19,000
well, the direction you are going to doesn't change almost at all.

378
00:25:19,000 --> 00:25:23,000
So it means you can take long bold steps and you can consequently only take

379
00:25:23,000 --> 00:25:27,000
a few steps or many fewer steps than with the alternatives.

380
00:25:27,000 --> 00:25:31,000
Okay, and then I said we'll want to direct

381
00:25:31,000 --> 00:25:35,000
our efforts to the difficult places. Now we've tied our

382
00:25:35,000 --> 00:25:39,000
hands with the noise schedule. So the remaining tool

383
00:25:39,000 --> 00:25:43,000
is to take different length steps at different stages

384
00:25:43,000 --> 00:25:47,000
of the generation. And indeed, when you go look

385
00:25:47,000 --> 00:25:51,000
at the possibly implicit choices the previous methods have done,

386
00:25:51,000 --> 00:25:55,000
all of them take shorter steps at low noise levels

387
00:25:55,000 --> 00:25:59,000
because that's where the detail is built again.

388
00:25:59,000 --> 00:26:03,000
And yeah, we

389
00:26:03,000 --> 00:26:07,000
formulate this family of these discretizations

390
00:26:07,000 --> 00:26:11,000
like a polynomial step length growth and we find that there is a broad

391
00:26:11,000 --> 00:26:15,000
optimum of good schedules there.

392
00:26:15,000 --> 00:26:19,000
You can read those details in the paper.

393
00:26:19,000 --> 00:26:23,000
So there's one more thing that this ODE framework allows you to do

394
00:26:23,000 --> 00:26:27,000
which is not so clear with for example the Markov chain

395
00:26:27,000 --> 00:26:31,000
form lessons is use higher order solvers. So again

396
00:26:31,000 --> 00:26:35,000
there is going to be curvature and it can be quite

397
00:26:35,000 --> 00:26:39,000
rapid at places. So you can still fall off

398
00:26:39,000 --> 00:26:43,000
the track if you just naively follow tangent and that method

399
00:26:43,000 --> 00:26:47,000
of following the tangent of course is called the Euler method.

400
00:26:47,000 --> 00:26:51,000
But there are higher order schemes for example in the Hoin scheme you take a second

401
00:26:51,000 --> 00:26:55,000
tentative step and you move it back to where you started from

402
00:26:55,000 --> 00:26:59,000
and your access step is going to be the average of that and the initial one.

403
00:26:59,000 --> 00:27:03,000
And this makes you much better follow these trajectories.

404
00:27:03,000 --> 00:27:07,000
This of course has a cost. You need to take these sub steps.

405
00:27:07,000 --> 00:27:11,000
And what we find in the paper by extension we're studying this

406
00:27:11,000 --> 00:27:15,000
is that this Hoin method strikes the best balance between these higher order methods

407
00:27:15,000 --> 00:27:19,000
for sort of the extra bang for the buck.

408
00:27:19,000 --> 00:27:23,000
And the improvement is actually quite substantial.

409
00:27:23,000 --> 00:27:27,000
Okay, so those are the choices we made.

410
00:27:27,000 --> 00:27:31,000
And now we can evaluate. So we'll be evaluating

411
00:27:31,000 --> 00:27:35,000
these results throughout the talk on a couple of very competitive

412
00:27:35,000 --> 00:27:39,000
generation categories. Saifat Sen

413
00:27:39,000 --> 00:27:43,000
at Resolution 32 using it at Resolution 64.

414
00:27:43,000 --> 00:27:47,000
And I want to say a couple of words on this might sound

415
00:27:47,000 --> 00:27:51,000
like a useless toy example to you if you're used to seeing

416
00:27:51,000 --> 00:27:55,000
like outputs from stable diffusion or something.

417
00:27:55,000 --> 00:27:59,000
But the way also those methods work is they first

418
00:27:59,000 --> 00:28:03,000
they something like a 64 by 64 image and then they upsample it sequentially.

419
00:28:03,000 --> 00:28:07,000
And it turns out that generating the 64 image is the difficult part there.

420
00:28:07,000 --> 00:28:11,000
The upsampling just kind of it just kind of works.

421
00:28:11,000 --> 00:28:15,000
So this is highly indicative of

422
00:28:15,000 --> 00:28:19,000
improvements we get in very relevant

423
00:28:19,000 --> 00:28:23,000
very relevant classes of models.

424
00:28:23,000 --> 00:28:27,000
Okay, so if we look at the performance of the original

425
00:28:27,000 --> 00:28:31,000
samples from these works, from a few previous methods

426
00:28:31,000 --> 00:28:35,000
on these data sets, we see

427
00:28:35,000 --> 00:28:39,000
that we have the quality on the y-axis, the FID lower is

428
00:28:39,000 --> 00:28:43,000
better, and we have a number of samples we need to take, like number of steps

429
00:28:43,000 --> 00:28:47,000
or the function evaluations on the x-axis. We see that we need to take

430
00:28:47,000 --> 00:28:51,000
something like hundreds or even thousands of steps to get kind of

431
00:28:51,000 --> 00:28:55,000
saturate the quality to get the best quality that model gives you.

432
00:28:55,000 --> 00:28:59,000
So introducing the point sampler and our discretization schedule

433
00:28:59,000 --> 00:29:03,000
we vastly improved this. I noticed that

434
00:29:03,000 --> 00:29:07,000
the x-axis is logarithmic, so we've gone from like hundreds

435
00:29:07,000 --> 00:29:11,000
to dozens of evaluations.

436
00:29:11,000 --> 00:29:15,000
And further introducing the noise schedule

437
00:29:15,000 --> 00:29:19,000
and scaling schedule further improved the results by a large amount

438
00:29:19,000 --> 00:29:23,000
except in DDIM which was already using those schedules.

439
00:29:23,000 --> 00:29:27,000
So now we've already made it quite far here

440
00:29:27,000 --> 00:29:31,000
and using some super fancy

441
00:29:31,000 --> 00:29:35,000
higher audio, so it's not worth the effort.

442
00:29:35,000 --> 00:29:39,000
Okay, so now we've covered the deterministic sampling

443
00:29:39,000 --> 00:29:43,000
and let's next

444
00:29:43,000 --> 00:29:47,000
return to the question of SDE which we

445
00:29:47,000 --> 00:29:51,000
put on the back burner on the other slides. And remember

446
00:29:51,000 --> 00:29:55,000
instead of following these nice smooth flow trajectories

447
00:29:55,000 --> 00:29:59,000
the SDE sort of cheaters around as some kind of

448
00:29:59,000 --> 00:30:03,000
exploration around that baseline. So it can be interpreted as

449
00:30:03,000 --> 00:30:07,000
replacing the noise as you go on top of like reducing it.

450
00:30:07,000 --> 00:30:11,000
And the reason why people care about the SDE is of course

451
00:30:11,000 --> 00:30:15,000
well one reason is that that's where this stuff is derived from

452
00:30:15,000 --> 00:30:19,000
but the other is that in practice you tend to get better results when you use the SDE

453
00:30:19,000 --> 00:30:23,000
instead of the ODE, at least in previous work.

454
00:30:23,000 --> 00:30:27,000
And the reason for that will become apparent soon.

455
00:30:27,000 --> 00:30:31,000
But let's first generalize this idea a little.

456
00:30:31,000 --> 00:30:35,000
So in the paper we present this generalized version of the SDE

457
00:30:35,000 --> 00:30:39,000
which allows you to specify the strength of this exploration

458
00:30:39,000 --> 00:30:43,000
by this sort of noise replacement schedule.

459
00:30:43,000 --> 00:30:47,000
So especially when you set it to zero you get just the ODE

460
00:30:47,000 --> 00:30:51,000
boosting this factor. Or you can do more exotic schedules

461
00:30:51,000 --> 00:30:55,000
like something like this

462
00:30:55,000 --> 00:30:59,000
where you have it behave like an SDE in the middle and like the ODE

463
00:30:59,000 --> 00:31:03,000
and so on. And samples would look like this.

464
00:31:03,000 --> 00:31:07,000
But again that's the question of is this just a nice streak

465
00:31:07,000 --> 00:31:11,000
or like what's the point.

466
00:31:11,000 --> 00:31:15,000
And as I said empirically

467
00:31:15,000 --> 00:31:19,000
this improves the results. And now looking at this SDE

468
00:31:19,000 --> 00:31:23,000
the reason becomes somewhat apparent.

469
00:31:23,000 --> 00:31:27,000
So don't try to read it unless you're an expert in SDEs

470
00:31:27,000 --> 00:31:31,000
but we can recognize a couple of familiar parts here.

471
00:31:31,000 --> 00:31:35,000
So the first term in the SDE is actually just the ODE from the previous section.

472
00:31:35,000 --> 00:31:39,000
So that means that we still have this force

473
00:31:39,000 --> 00:31:43,000
that is driving us towards the distribution

474
00:31:43,000 --> 00:31:47,000
of flow lines. And the remainder we can identify

475
00:31:47,000 --> 00:31:51,000
some kind of a lens around diffusion stochastic difference equation

476
00:31:51,000 --> 00:31:55,000
which is a well-known thing from a long ago.

477
00:31:55,000 --> 00:31:59,000
It has this property that it makes the samples sort of explore your

478
00:31:59,000 --> 00:32:03,000
distribution and if the samples are not distributed correctly

479
00:32:03,000 --> 00:32:07,000
it will kind of reduce that error.

480
00:32:07,000 --> 00:32:11,000
So it has this healing property.

481
00:32:11,000 --> 00:32:15,000
And because we do make errors during the sampling it kind of actively corrects

482
00:32:15,000 --> 00:32:19,000
for them. And this is how it looks like. So let's take this extreme situation

483
00:32:19,000 --> 00:32:23,000
we have our samples to blue dots. And

484
00:32:23,000 --> 00:32:27,000
let's say they are really bad. They are not following the underlying distribution at all.

485
00:32:27,000 --> 00:32:31,000
They are skewed to one side.

486
00:32:31,000 --> 00:32:35,000
So if we keep following the ODE it does nothing to actually

487
00:32:35,000 --> 00:32:39,000
correct the skew and we completely miss the other basin of the days for example.

488
00:32:39,000 --> 00:32:43,000
So when I introduce stochasticity to this process

489
00:32:43,000 --> 00:32:47,000
it starts looking like this.

490
00:32:47,000 --> 00:32:51,000
So these samples do this kind of random exploration

491
00:32:51,000 --> 00:32:55,000
and gradually forget where they came from and forget the error

492
00:32:55,000 --> 00:32:59,000
in this opposition. And now we've covered both modes for example

493
00:32:59,000 --> 00:33:03,000
in the generated images on the left edge.

494
00:33:03,000 --> 00:33:07,000
So that's the sort of reason why stochasticity is helpful.

495
00:33:07,000 --> 00:33:11,000
No, arguably this is the only benefit of the SDE over the ODE.

496
00:33:11,000 --> 00:33:15,000
But there are also downsides in using SDEs.

497
00:33:15,000 --> 00:33:19,000
For example we would technically have to use these

498
00:33:19,000 --> 00:33:23,000
complicated solvers that are arguably designed for much more complicated

499
00:33:23,000 --> 00:33:27,000
cases where you have more general SDEs.

500
00:33:27,000 --> 00:33:31,000
So we asked the question could we instead directly combine the ODE solving

501
00:33:31,000 --> 00:33:35,000
with this idea of this

502
00:33:35,000 --> 00:33:39,000
churning of the noise, adding and removing it.

503
00:33:39,000 --> 00:33:43,000
And the answer is this.

504
00:33:43,000 --> 00:33:47,000
So this is a stochastic example we proposed in the paper.

505
00:33:47,000 --> 00:33:51,000
So we have our current noise image at noise level TTI.

506
00:33:51,000 --> 00:33:55,000
Remember in our parent recession the noise level is now

507
00:33:55,000 --> 00:33:59,000
completely equivalent with time.

508
00:33:59,000 --> 00:34:03,000
So we have two sub steps in one step.

509
00:34:03,000 --> 00:34:07,000
So first we add noise. So this represents the lens of an exploration.

510
00:34:07,000 --> 00:34:11,000
So we landed some random

511
00:34:11,000 --> 00:34:15,000
noisier image so the time increases here.

512
00:34:15,000 --> 00:34:19,000
And then we solved the ODE to where we actually wanted to go

513
00:34:19,000 --> 00:34:23,000
with say lower noise level.

514
00:34:23,000 --> 00:34:27,000
And that simply follows the flow line there.

515
00:34:27,000 --> 00:34:31,000
And in practice we do this with a single point step. So we keep alternating between

516
00:34:31,000 --> 00:34:35,000
this noise addition and the point step.

517
00:34:35,000 --> 00:34:39,000
And this brings us closer and closer to time zero as we want.

518
00:34:39,000 --> 00:34:43,000
But underneath it is the ODE running the show

519
00:34:43,000 --> 00:34:47,000
and guiding us along these lines.

520
00:34:47,000 --> 00:34:51,000
But on top of that we now have this jittering with correct servers.

521
00:34:51,000 --> 00:34:55,000
Okay, so this all sounds really nice.

522
00:34:55,000 --> 00:34:59,000
You get free error correction but it's not actually free

523
00:34:59,000 --> 00:35:03,000
because the lens event term is also an approximation of some continuous thing.

524
00:35:03,000 --> 00:35:07,000
And you introduce new error also when you make it.

525
00:35:07,000 --> 00:35:11,000
So it's actually a quite delicate balance of how much you should do this.

526
00:35:11,000 --> 00:35:15,000
And now with this clear view into this dynamics we actually find that it is really

527
00:35:15,000 --> 00:35:19,000
finicky. You need to tune the amount of stochasticity

528
00:35:19,000 --> 00:35:23,000
on a per data set per architecture basis.

529
00:35:23,000 --> 00:35:27,000
You get the benefits but it's really annoying.

530
00:35:27,000 --> 00:35:31,000
So it's a mixed bag.

531
00:35:31,000 --> 00:35:35,000
Nonetheless it is very useful. So if we compare the ODEs from the previous section

532
00:35:35,000 --> 00:35:39,000
their performance with just original SDE

533
00:35:39,000 --> 00:35:43,000
samples from these respective works.

534
00:35:43,000 --> 00:35:47,000
We see that the SDE solvers are simply better in the end

535
00:35:47,000 --> 00:35:51,000
but they are also very slow.

536
00:35:51,000 --> 00:35:55,000
Now applying all of these improvements

537
00:35:55,000 --> 00:35:59,000
with our method, with the optimal tune settings for this data set

538
00:35:59,000 --> 00:36:03,000
we read both much better quality

539
00:36:03,000 --> 00:36:07,000
at a much faster rate.

540
00:36:07,000 --> 00:36:11,000
And yeah, there's been some previous works

541
00:36:11,000 --> 00:36:15,000
that applied also higher order solvers.

542
00:36:15,000 --> 00:36:19,000
So I want to highlight one result here.

543
00:36:19,000 --> 00:36:23,000
This image net 64 highly competitive

544
00:36:23,000 --> 00:36:27,000
just with this change of schedule.

545
00:36:27,000 --> 00:36:31,000
We went from a pretty mediocre FID of 2.07 to 1.55

546
00:36:31,000 --> 00:36:35,000
which at the time of getting this result was state of the art

547
00:36:35,000 --> 00:36:39,000
but that record was broken before the publication

548
00:36:39,000 --> 00:36:43,000
but we'll have our events in a few slides.

549
00:36:43,000 --> 00:36:47,000
But just to show that this is just taking

550
00:36:47,000 --> 00:36:51,000
the existing network and using it better

551
00:36:51,000 --> 00:36:55,000
for improvements already.

552
00:36:55,000 --> 00:36:59,000
Okay, so that's it for deterministic sampling.

553
00:36:59,000 --> 00:37:03,000
At this point I have to say I'm going to go a bit overtime because of the hassle

554
00:37:03,000 --> 00:37:07,000
in the beginning and because this is kind of incompressible anyway.

555
00:37:07,000 --> 00:37:11,000
So if you need to leave then no problem.

556
00:37:11,000 --> 00:37:15,000
So yeah, that's it for stagastic sampling

557
00:37:15,000 --> 00:37:19,000
and for sampling as a whole.

558
00:37:19,000 --> 00:37:23,000
So just a brief recap.

559
00:37:23,000 --> 00:37:27,000
The way this works was that the role of the ODE

560
00:37:27,000 --> 00:37:31,000
is to give us the step direction

561
00:37:31,000 --> 00:37:35,000
which is given by the score function

562
00:37:35,000 --> 00:37:39,000
which is given by the score function

563
00:37:39,000 --> 00:37:43,000
which is given by the score function

564
00:37:43,000 --> 00:37:47,000
which is given by the score function

565
00:37:47,000 --> 00:37:51,000
which can be evaluated using a denoiser

566
00:37:51,000 --> 00:37:55,000
which can be approximated using the neural network

567
00:37:55,000 --> 00:37:59,000
and that is the role of the neural network.

568
00:37:59,000 --> 00:38:03,000
It tells you where to go in a single step or what's the direction you need to go to.

569
00:38:03,000 --> 00:38:07,000
And the theory says that as long as the denoiser does something

570
00:38:07,000 --> 00:38:11,000
that minimizes this loss, the L2 denoising loss

571
00:38:11,000 --> 00:38:15,000
the theory will be happy.

572
00:38:15,000 --> 00:38:19,000
And you can do this separately at every noise level

573
00:38:19,000 --> 00:38:23,000
so you can weight these loss according to the noise level also.

574
00:38:23,000 --> 00:38:27,000
But before we go to these loss weightings

575
00:38:27,000 --> 00:38:31,000
let's look at the denoiser itself.

576
00:38:31,000 --> 00:38:35,000
So I draw the CNN there in a bit of a hazy way

577
00:38:35,000 --> 00:38:39,000
and this is because it's actually a bad idea to directly connect the noise image to the input of the network

578
00:38:39,000 --> 00:38:43,000
or to read the denoised image from its output layer

579
00:38:43,000 --> 00:38:49,000
rather we'll want to wrap it between some kind of signal management layers

580
00:38:49,000 --> 00:38:53,000
to manage those signal scales

581
00:38:53,000 --> 00:38:57,000
of both the input and the output to standardize them somehow

582
00:38:57,000 --> 00:39:01,000
and also in this case we can often recycle stuff from the input

583
00:39:01,000 --> 00:39:05,000
because let's say if the input image is almost noise free

584
00:39:05,000 --> 00:39:07,000
then we don't really need to denoise much

585
00:39:07,000 --> 00:39:11,000
we should just copy what we know and only fix the remainder

586
00:39:11,000 --> 00:39:15,000
we're going to come to that soon.

587
00:39:15,000 --> 00:39:19,000
And this is super critical here.

588
00:39:19,000 --> 00:39:23,000
I mean this might sound like boring technical details

589
00:39:23,000 --> 00:39:27,000
but these kind of things really are critical for the success of the neural network training

590
00:39:27,000 --> 00:39:31,000
and we've seen this over and over again over the years.

591
00:39:31,000 --> 00:39:35,000
And in this case the noise levels vary so widely

592
00:39:35,000 --> 00:39:39,000
that this is extra critical here.

593
00:39:39,000 --> 00:39:43,000
So without too much to do here is how one of the previous methods, the VE method

594
00:39:43,000 --> 00:39:47,000
implements the denoiser.

595
00:39:47,000 --> 00:39:51,000
So the idea of this setup is that they are

596
00:39:51,000 --> 00:39:55,000
learning to predict the noise instead of the signal using those CNN layers.

597
00:39:55,000 --> 00:39:59,000
And the way that works, and I'll explain why soon

598
00:39:59,000 --> 00:40:03,000
the way that works is of course the loss will be happy

599
00:40:03,000 --> 00:40:07,000
if the denoiser can produce the clean image

600
00:40:07,000 --> 00:40:13,000
and we can interpret this model as having this kind of a skip connection

601
00:40:13,000 --> 00:40:17,000
so the noisy input goes through that.

602
00:40:17,000 --> 00:40:21,000
Now implicitly the task of the CNN will be to predict

603
00:40:21,000 --> 00:40:25,000
the negative of the noise component in that image

604
00:40:25,000 --> 00:40:31,000
and then they have an explicit layer that scales that noise to the known noise level.

605
00:40:31,000 --> 00:40:35,000
And so now when you add whatever came from the skip connection to this

606
00:40:35,000 --> 00:40:39,000
you get an estimate of the clean image.

607
00:40:39,000 --> 00:40:43,000
So this way they kind of turn it so that the CNN itself

608
00:40:43,000 --> 00:40:47,000
is concerned with the noise instead of like the signal.

609
00:40:47,000 --> 00:40:51,000
I'll explain soon why that is relevant.

610
00:40:51,000 --> 00:40:55,000
But first let's do the thing I promised to do a long ago.

611
00:40:55,000 --> 00:40:59,000
I said there's huge variations in the magnitude, just the numerical magnitude

612
00:40:59,000 --> 00:41:03,000
of these input signals.

613
00:41:03,000 --> 00:41:07,000
So fairs to accounts for that, which is problematic.

614
00:41:07,000 --> 00:41:11,000
And so we quite simply introduced this

615
00:41:11,000 --> 00:41:15,000
interscaling layer here that uses the known standard deviation of the noise

616
00:41:15,000 --> 00:41:19,000
to scale the image down.

617
00:41:19,000 --> 00:41:23,000
I want to highlight this not like a batch normalization or something.

618
00:41:23,000 --> 00:41:27,000
We know what the noise level is, we know what the signal magnitude should be.

619
00:41:27,000 --> 00:41:31,000
We divide by an appropriate formula.

620
00:41:31,000 --> 00:41:36,000
So that gives you one of the wishes we had on that orientation slide.

621
00:41:36,000 --> 00:41:40,000
On the output side we actually have something nice already.

622
00:41:40,000 --> 00:41:45,000
So this is very good because now the network only needs to produce

623
00:41:45,000 --> 00:41:49,000
a unit standard deviation output and this explicit scaling to the known noise level

624
00:41:49,000 --> 00:41:54,000
takes care of applying the actual like a magnitude of that noise.

625
00:41:54,000 --> 00:41:57,000
So this makes it again much easier for the neural network.

626
00:41:57,000 --> 00:42:01,000
It can always work with these standard sized signals.

627
00:42:01,000 --> 00:42:05,000
And that deals with the second hope we have there.

628
00:42:05,000 --> 00:42:11,000
But now the question of should we predict the noise or the signal and why?

629
00:42:11,000 --> 00:42:15,000
So it turns out this is actually a good idea at small noise levels

630
00:42:15,000 --> 00:42:19,000
but a bad idea at high noise levels.

631
00:42:19,000 --> 00:42:23,000
So I'll show you what happens at low noise levels.

632
00:42:23,000 --> 00:42:27,000
So if we have low noise, the stuff that goes through the skip connection

633
00:42:27,000 --> 00:42:30,000
is almost noise free already.

634
00:42:30,000 --> 00:42:33,000
And now the CNN predicts this negative noise component

635
00:42:33,000 --> 00:42:37,000
and it's scaled down by this very low noise level.

636
00:42:37,000 --> 00:42:43,000
And this is great because the neural network

637
00:42:43,000 --> 00:42:46,000
is actually the only source of error in this process.

638
00:42:46,000 --> 00:42:49,000
So if the network made errors, now we've downscaled them.

639
00:42:49,000 --> 00:42:52,000
So it doesn't really matter if the network is good or bad.

640
00:42:52,000 --> 00:42:55,000
We didn't do much error in this case.

641
00:42:55,000 --> 00:42:58,000
So that's great. We are sort of recycling what we already knew

642
00:42:58,000 --> 00:43:03,000
instead of trying to learn the identity function within your network.

643
00:43:03,000 --> 00:43:07,000
So that kind of deals with the third hope we had on the slide.

644
00:43:07,000 --> 00:43:11,000
But on high noise levels, the situation is reversed.

645
00:43:11,000 --> 00:43:14,000
Whatever comes through the skip connection is completely useless.

646
00:43:14,000 --> 00:43:19,000
It's a huge, huge noise signal with no signal at all.

647
00:43:19,000 --> 00:43:22,000
And now the CNN predicts what the noise is.

648
00:43:22,000 --> 00:43:25,000
And then it is massively boosted at this stage.

649
00:43:25,000 --> 00:43:30,000
So if the network made any errors, now there are going to be huge errors after this.

650
00:43:30,000 --> 00:43:33,000
And those are directly passed out of the denoiser.

651
00:43:33,000 --> 00:43:40,000
So now we've introduced a huge error into our stepping procedure in the ODE.

652
00:43:40,000 --> 00:43:44,000
It's also a bit of an absurd task because you're trying to subtract

653
00:43:44,000 --> 00:43:48,000
two massive signals to get a normal size signal.

654
00:43:48,000 --> 00:43:56,000
And kind of like trying to draw without two meter long pencil, not optimal.

655
00:43:56,000 --> 00:43:59,000
So instead what we'd like to do is somehow disable the skip connection

656
00:43:59,000 --> 00:44:02,000
when the noise level is high.

657
00:44:02,000 --> 00:44:08,000
And in that case, effectively the task of the CNN will be to just break the signal directly.

658
00:44:08,000 --> 00:44:10,000
There won't be any need to scale it up.

659
00:44:10,000 --> 00:44:13,000
So we won't end up boosting errors.

660
00:44:13,000 --> 00:44:17,000
And the way we implement that is by adding this sort of switch

661
00:44:17,000 --> 00:44:19,000
but in a continuous way.

662
00:44:19,000 --> 00:44:23,000
So we have this so-called skip scale, which when set to zero,

663
00:44:23,000 --> 00:44:25,000
effectively disables the skip connection.

664
00:44:25,000 --> 00:44:28,000
Set to one, you get the noise prediction.

665
00:44:28,000 --> 00:44:32,000
And furthermore, we make it so that it's actually a continuous value

666
00:44:32,000 --> 00:44:36,000
between zero and one that depends on the noise level.

667
00:44:36,000 --> 00:44:41,000
And if it's somewhere in between, that means that we are predicting

668
00:44:41,000 --> 00:44:50,000
some kind of a mixture of noise and the signal in this instead of just one of them.

669
00:44:50,000 --> 00:44:57,000
And there is a principle way of calculating what the optimal skip weight is.

670
00:44:57,000 --> 00:45:01,000
But I won't go there in the interest of time.

671
00:45:01,000 --> 00:45:05,000
We have it in the paper of Enix.

672
00:45:05,000 --> 00:45:10,000
And that deals with the remaining issues we had on this slide.

673
00:45:10,000 --> 00:45:13,000
And now we can look at what the previous works did and what we did.

674
00:45:13,000 --> 00:45:19,000
So these are the actual formulas that implement those ideas.

675
00:45:19,000 --> 00:45:22,000
Then there is the couple of training details.

676
00:45:22,000 --> 00:45:25,000
How should you weight the loss based on the noise level

677
00:45:25,000 --> 00:45:30,000
and how often should you show samples of different noise levels.

678
00:45:30,000 --> 00:45:35,000
So the general problem, if you don't deal with these issues,

679
00:45:35,000 --> 00:45:40,000
is that you might have a highly lopsided distribution of gradient feedback.

680
00:45:40,000 --> 00:45:49,000
So if you're not careful, you might be prodding the weights gently to one direction or the other.

681
00:45:49,000 --> 00:45:57,000
And then every few iterations you have this massive gradient smash on the weights and so on.

682
00:45:57,000 --> 00:46:01,000
And that's probably very bad for your training dynamics.

683
00:46:01,000 --> 00:46:07,000
So the role of the loss weighting or the scaling, the numerical scale in front of the loss term,

684
00:46:07,000 --> 00:46:16,000
should we be to just equalize the magnitude of the loss or equivalently equalize the magnitude of the gradient feedback that gives.

685
00:46:16,000 --> 00:46:23,000
And then the noise level distribution, maybe how often you show images of any given noise level.

686
00:46:23,000 --> 00:46:29,000
The role of that is to kind of direct your training efforts to the levels where you know it's relevant,

687
00:46:29,000 --> 00:46:31,000
where you can make an impact.

688
00:46:31,000 --> 00:46:37,000
And for that, in the paper, we have this sort of an important sampling argument that whatever we do,

689
00:46:37,000 --> 00:46:39,000
we end up with this kind of a loss curve.

690
00:46:39,000 --> 00:46:45,000
So we don't make much progress at very low and very high noise levels, but we do make a lot of progress in the middle.

691
00:46:45,000 --> 00:46:51,000
For example, at very low noise end, you're trying to predict noise from a noise free image.

692
00:46:51,000 --> 00:46:55,000
It's impossible, but it also doesn't matter if you can't do it.

693
00:46:55,000 --> 00:47:09,000
So we, based on this, we find that it's enough to, or suffice this to sort of have this very broad distribution

694
00:47:09,000 --> 00:47:17,000
of noise levels here that are targeted towards the levels where you know you can make progress.

695
00:47:17,000 --> 00:47:22,000
And this is a logarithmic scale on the x-axis, so it's a lot of normal distribution.

696
00:47:22,000 --> 00:47:24,000
So those are those sources.

697
00:47:24,000 --> 00:47:26,000
And it's starting to pretty full.

698
00:47:26,000 --> 00:47:30,000
There's one more thing, which I'll just keep in the interest of time.

699
00:47:30,000 --> 00:47:41,000
We have some mechanism presented in the paper for dealing with vastly like two small data sets when your network starts overfitting by this augmentation mechanism.

700
00:47:41,000 --> 00:47:43,000
You can look at it there.

701
00:47:43,000 --> 00:47:46,000
But yeah, let's not go there.

702
00:47:46,000 --> 00:47:50,000
It's really only relevant for various small data sets like Cypher.

703
00:47:50,000 --> 00:47:54,000
With ImageNet, we haven't found benefits from it, I think.

704
00:47:54,000 --> 00:47:58,000
Okay, so with all these improvements, we can stack them one by one.

705
00:47:58,000 --> 00:48:00,000
These are the lines here.

706
00:48:00,000 --> 00:48:10,000
And in the end, we get state-of-the-art results in various competitive categories.

707
00:48:10,000 --> 00:48:20,000
In deterministic sampling, we get an FID 179.97 on the Cypher categories, which might still be state-of-the-art.

708
00:48:20,000 --> 00:48:26,000
Also at very low sample counts compared to most previous work.

709
00:48:26,000 --> 00:48:28,000
That's more interestingly.

710
00:48:28,000 --> 00:48:30,000
Okay, that was with deterministic sampling.

711
00:48:30,000 --> 00:48:43,000
When we enable the stochastic sampling and tailor it for these architectures for ImageNet and use these retrained networks, we trained ourselves using these principles.

712
00:48:43,000 --> 00:48:50,000
We get an FID of 1.36, which was a state-of-the-art when this paper came out.

713
00:48:50,000 --> 00:48:56,000
It's been overtaken, I think in the last few weeks, possibly earlier.

714
00:48:57,000 --> 00:49:03,000
So all in all, we've turned this model that was okay-ish in the beginning.

715
00:49:03,000 --> 00:49:14,000
And by stacking all of these improvements, we get the best model in the world at that time for generating 64 ImageNet.

716
00:49:14,000 --> 00:49:23,000
Interestingly, the stochasticity is no longer helpful with Cypher in this resume or after the training improvement.

717
00:49:23,000 --> 00:49:29,000
And so it appears that the network has become so good that it doesn't make that many errors.

718
00:49:29,000 --> 00:49:36,000
And any exploration, lands and wine exploration you do, introduces more error than you are actually fixing with it.

719
00:49:36,000 --> 00:49:39,000
But this is still not the case with ImageNet.

720
00:49:39,000 --> 00:49:44,000
So there it's still pays to do stochasticity.

721
00:49:44,000 --> 00:49:50,000
Okay, so that was the, that was mostly it.

722
00:49:50,000 --> 00:49:54,000
Just a brief conclusion.

723
00:49:54,000 --> 00:50:01,000
So we've sort of exposed this completely modular design of these diffusion models.

724
00:50:01,000 --> 00:50:07,000
Instead of viewing them as tightly coupled packages where you can't change anything without breaking something,

725
00:50:07,000 --> 00:50:15,000
we show that you can pretty much change every, like you get a valid method no matter what you do as long as you follow these loose guidelines.

726
00:50:15,000 --> 00:50:22,000
And then with that knowledge, we get a clear view into what we should actually be doing with those choices.

727
00:50:22,000 --> 00:50:25,000
And doing so pays off in a big way.

728
00:50:25,000 --> 00:50:30,000
We get much improved quality at much, much more efficient models.

729
00:50:30,000 --> 00:50:34,000
One takeaway about stochasticity, it's a bit of a double edged sword.

730
00:50:34,000 --> 00:50:42,000
As said, it does help, but it also, it requires that annoying per case tuning.

731
00:50:42,000 --> 00:50:45,000
There are no clear principles how to do that tuning.

732
00:50:45,000 --> 00:50:50,000
There is also a danger that you can even have bugs in your code or something.

733
00:50:50,000 --> 00:50:54,000
And stochasticity will kind of fix them to an extent,

734
00:50:54,000 --> 00:50:59,000
which is of course not what you want to do if you're trying to understand what your potential improvements are,

735
00:50:59,000 --> 00:51:02,000
what their effect is and so on.

736
00:51:02,000 --> 00:51:07,000
Ideally, you'd be able to work in a completely deterministic setting.

737
00:51:07,000 --> 00:51:16,000
And if you want, then in the end just kind of reintroduce the stochasticity as the final, final cherry on the top.

738
00:51:16,000 --> 00:51:22,000
Okay, so we haven't talked about all the fancy stuff like higher resolutions, network architectures,

739
00:51:22,000 --> 00:51:24,000
classifier free guidance and so on.

740
00:51:24,000 --> 00:51:28,000
But probably many of these would be right for a similar principle of analysis.

741
00:51:28,000 --> 00:51:35,000
We hope this inspires you to also think about that kind of things and certainly we are.

742
00:51:35,000 --> 00:51:39,000
So with that, the code and everything is of course available.

743
00:51:39,000 --> 00:51:45,000
I would argue this is probably one of the better places to copy paste your code.

744
00:51:45,000 --> 00:51:53,000
If you want to experiment with stuff, it's very clean code based that directly implements these ideas.

745
00:51:53,000 --> 00:51:57,000
Yeah, so thank you for your attention.

746
00:52:04,000 --> 00:52:07,000
Hey, so we have time.

747
00:52:07,000 --> 00:52:09,000
Yeah, I have some.

748
00:52:09,000 --> 00:52:15,000
I just want to ask a question.

749
00:52:15,000 --> 00:52:18,000
All right.

750
00:52:27,000 --> 00:52:30,000
It probably has to do with the data's complexity.

751
00:52:30,000 --> 00:52:35,000
Seffari is maybe a bit too simplistic in the end.

752
00:52:35,000 --> 00:52:38,000
It's kind of learnable entirely.

753
00:52:38,000 --> 00:52:45,000
But it seems like that something like ImageNet, it's still so extremely cool.

