WEBVTT

00:00.000 --> 00:04.760
Suppose there is a game with the probability of winning of 1 third.

00:04.760 --> 00:10.080
And if you win, you will get 1.8 times the amount of money that you risk on the play.

00:10.080 --> 00:12.880
And if you lose, you lose the entire wager.

00:12.880 --> 00:18.200
Then, we can calculate the expected value of the payout by summing over all possible

00:18.200 --> 00:23.460
events of the probability of each event times the payout of each event.

00:23.460 --> 00:29.400
And once we calculate the expected value for this game, it comes out to a negative value.

00:29.400 --> 00:34.200
You have no edge at all in this game, so you may get lucky first few times, but there is

00:34.200 --> 00:36.640
no long-term winning strategy.

00:36.640 --> 00:43.000
So you will inevitably donate all your money to the house if you keep playing.

00:43.000 --> 00:47.080
Now let's consider a second game where if you win, you get paid the amount of money

00:47.080 --> 00:48.160
you risk.

00:48.160 --> 00:51.740
Or in other words, you double your betting amount.

00:51.740 --> 00:55.140
Suppose that you have a 100% chance of winning this game.

00:55.140 --> 00:59.740
And it doesn't quite matter what happens if you lose, since you are guaranteed to win.

00:59.740 --> 01:03.700
And you are expected to double your money each time you play the game.

01:03.700 --> 01:06.380
Then what is your long-term winning strategy?

01:06.380 --> 01:10.580
Well, you essentially have a money printer, so you might as well put your entire life

01:10.580 --> 01:12.700
savings on each play.

01:12.700 --> 01:16.820
Even better, you can maximize your profit by playing on a margin, meaning you should

01:16.820 --> 01:22.140
borrow the biggest amount of money that you possibly can, and put all your assets, including

01:22.140 --> 01:26.740
your kidney and liver, as a collateral for the margin.

01:26.740 --> 01:31.220
We looked at two extreme examples, one where you have no edge at all and there is no long-term

01:31.220 --> 01:35.740
winning strategy, and another where you are guaranteed to win each time and your winning

01:35.740 --> 01:38.780
strategy is to bet everything each time.

01:38.780 --> 01:43.820
So the real interesting problem is, when your expected payout is positive, but you are not

01:43.820 --> 01:46.580
guaranteed to win.

01:46.580 --> 01:49.900
Let's take a look at one such example.

01:49.900 --> 01:55.060
You should buy some S&P 500 index fund, which is a fund that takes top 500 American companies

01:55.060 --> 01:59.180
and averages them by their company's value.

01:59.180 --> 02:03.660
And let's say you implement a strategy to sell at a profit when the price doubles and

02:03.660 --> 02:08.220
cut your losses when the price drops by 25%.

02:08.220 --> 02:13.740
Taking the historical data starting from 2003 and back-testing this strategy, I calculated

02:13.740 --> 02:18.420
that the probability of win is roughly 59%.

02:18.420 --> 02:22.740
Because we are expected to win more, and each win pays much more than how much we lose

02:22.740 --> 02:28.780
each loss, the expected payout per play obviously has to be a positive value.

02:28.780 --> 02:34.020
This game definitely is worth playing, but how much should you risk each play?

02:34.020 --> 02:38.180
One possible strategy commonly used by the members of the subreddit Wall Street Pets

02:38.180 --> 02:43.100
is called Food Stamps or Lambo, which is a strategy to risk everything in order to maximize

02:43.100 --> 02:44.900
your potential profit.

02:44.900 --> 02:49.420
So for this strategy, we can maximize the expected value by maximizing the value of

02:49.420 --> 02:54.300
R, so you take 4x leverage to risk everything you own.

02:54.300 --> 03:00.860
Naively, that is the optimal strategy since you are maximizing the expected average profit.

03:00.860 --> 03:05.660
You make it lucky first few times, but if you continue to all-in each play, you will

03:05.660 --> 03:08.620
eventually lose everything.

03:08.620 --> 03:13.300
The very act of maximizing expected payout actually leads to ruin.

03:13.300 --> 03:19.020
So there must be a better long-term strategy, right?

03:19.020 --> 03:21.820
Let's start by defining the problem.

03:21.820 --> 03:25.260
Suppose there is a game where you know the probability of winning, which we will call

03:25.260 --> 03:31.860
P, and Q, the probability of losing, which equals 1-P.

03:31.860 --> 03:38.060
The game is repeated N times, and each play you will risk a fixed percentage, R, of your

03:38.060 --> 03:40.060
portfolio.

03:40.060 --> 03:45.060
And each time you win, you will gain T times R, and each time you lose, you will lose S

03:45.060 --> 03:46.820
times R.

03:46.820 --> 03:50.540
And let's put on some auxiliary conditions.

03:50.540 --> 03:56.380
The amount you can lose is at most your entire portfolio, so you cannot have a negative balance.

03:56.380 --> 03:59.140
And you are not guaranteed to win.

03:59.140 --> 04:03.620
And we want N to be sufficiently large since we are looking for our long-term sustainable

04:03.620 --> 04:05.140
strategy.

04:05.140 --> 04:10.740
So you are expected to win some and lose some, but still end up profitable in the long run.

04:10.740 --> 04:15.700
Then what fraction of your portfolio should you risk each play to maximize the long-term

04:15.700 --> 04:18.620
average profit?

04:18.620 --> 04:22.060
You may have noticed how we are restricted to binary scenarios.

04:22.060 --> 04:26.260
But in the real world, there are many games with more than two outcomes.

04:26.260 --> 04:32.980
For example, the Powerball Lottery has 9 different ways you can win, each with different payout.

04:32.980 --> 04:37.460
And you can't even have a game with a continuum of outcomes that depend on some continuous

04:37.460 --> 04:39.460
distribution.

04:39.460 --> 04:44.520
As interesting as those scenarios sound, they are too difficult to cover on a single video.

04:44.520 --> 04:50.420
So for this video, we will focus only on binary outcomes.

04:50.420 --> 04:54.180
Before we start solving the problem, I want to start with the answer so we can work our

04:54.180 --> 04:55.980
way towards it.

04:55.980 --> 05:01.260
So the optimal risk we should take per play is P, the probability of win, over S, the

05:01.260 --> 05:08.820
percentage loss per loss, minus Q, the probability of loss, over T, the percentage gain per win.

05:08.820 --> 05:13.820
The amount you should risk grows as the probability of win goes up, as the first term is linearly

05:13.820 --> 05:19.700
proportional with respect to P. And the optimal risk also goes up as percentage gain per win

05:19.700 --> 05:25.980
grows, since the second term is negative inversely proportional with respect to T.

05:25.980 --> 05:30.780
This intuitively makes sense as an investment is considered better if you win more and each

05:30.780 --> 05:33.260
time you win, you win more money.

05:33.260 --> 05:38.660
Similarly, the optimal risk decreases as the probability of loss and the amount of loss

05:38.660 --> 05:42.020
per loss goes up.

05:42.020 --> 05:45.820
This formula is known as the Kelly Criterion.

05:45.820 --> 05:49.380
It's best to look at some extreme cases of the formula.

05:49.380 --> 05:53.940
So if we have a perfectly balanced game with equal chance of win and loss, and equal gain

05:53.940 --> 05:59.900
and loss, the optimal risk is nothing, meaning this isn't a game worth playing.

05:59.900 --> 06:04.040
If we instead have a game where you're less likely to win and your gain per win is less

06:04.040 --> 06:09.020
than your losses, then your optimal R value comes out to negative.

06:09.020 --> 06:12.300
What this means is that you don't want to be playing the game, but you want to be sitting

06:12.300 --> 06:16.220
on the other side and taking a short position, being the casino or the insurance company

06:16.220 --> 06:18.580
stealing money from you.

06:18.580 --> 06:22.140
Now what if the game is extremely good in your favor?

06:22.140 --> 06:26.260
Then your R value can come out to something bigger than one, meaning you should invest

06:26.260 --> 06:33.020
not only your entire portfolio, but take a leverage and invest with borrowed money.

06:33.020 --> 06:37.100
Notice how I put quotation marks around the word average.

06:37.100 --> 06:40.940
The first question I want to ask is, what even is an average?

06:40.940 --> 06:46.020
There is a generalized mathematical definition of the word, as mathematicians love to abstractify

06:46.020 --> 06:47.260
everything.

06:47.260 --> 06:52.940
But for now, we will just think of it as some measure of central tendency, or a good representative

06:52.940 --> 06:55.460
element of a data set.

06:55.460 --> 07:00.500
And the average that we are all very familiar with is the arithmetic mean, or sometimes

07:00.500 --> 07:04.060
just call the mean when the context is clear.

07:04.060 --> 07:08.620
And we compute it by adding up all the numbers in the data set and dividing by how many numbers

07:08.620 --> 07:10.020
there are.

07:10.020 --> 07:15.860
There is another kind of mean called the quadratic mean, or sometimes called root mean squared.

07:15.860 --> 07:20.260
And we get it by taking the arithmetic mean of all the squares of numbers, then taking

07:20.260 --> 07:22.620
the square root.

07:22.620 --> 07:26.660
Another common mean that we use is called the harmonic mean, and we get it by taking

07:26.660 --> 07:31.540
the arithmetic mean of all the reciprocals, then taking the reciprocal.

07:31.540 --> 07:36.460
And using similar idea, we can extend the definition to work for all real numbers, except

07:36.460 --> 07:38.340
for zero.

07:38.340 --> 07:43.460
And even for zero, we can just take the limit as alpha goes to zero, to define the zero

07:43.460 --> 07:47.740
mean, which is known as the geometric mean.

07:47.740 --> 07:51.500
As alpha grows bigger, more weight is placed on bigger values.

07:51.500 --> 07:56.220
And as alpha gets smaller, more weight is placed on smaller values.

07:56.220 --> 08:01.420
So if we take the limit as alpha goes to negative infinity, we get the smallest value of the

08:01.420 --> 08:03.100
data set.

08:03.100 --> 08:08.900
And if we take the limit to the positive infinity, we get the maximum value.

08:08.900 --> 08:14.100
Now when is it appropriate to use these different types of means?

08:14.100 --> 08:18.660
One person having $3 and another person having $5.

08:18.660 --> 08:23.660
If Karl Marx saw this, he would want to equally distribute wealth.

08:23.660 --> 08:27.980
Then the most appropriate average would be the arithmetic mean.

08:27.980 --> 08:33.780
Now, consider a second situation where you are a successful day trader and triple your

08:33.780 --> 08:37.740
money the first year and five extra money the second year.

08:37.740 --> 08:40.700
Then what is your average growth per year?

08:40.700 --> 08:45.820
It is equivalent to roughly 3.873 xing your money each year.

08:45.820 --> 08:50.260
So when we have a compound growth and want to calculate average growth, geometric mean

08:50.260 --> 08:52.580
is the most appropriate.

08:52.580 --> 08:57.820
Now consider the next situation where person A can finish a task in three days and person

08:57.820 --> 09:00.420
B can finish a task in five days.

09:00.420 --> 09:05.500
Then what is the average number of days it takes a person to finish the task?

09:05.500 --> 09:10.300
If both of them are working on the task concurrently, we can add the rates together.

09:10.300 --> 09:13.580
And we can divide by two to get the average rate.

09:13.580 --> 09:18.420
So it means that person A can finish one third of a job per day and person B is working

09:18.420 --> 09:20.580
at one fifth of a job per day.

09:20.580 --> 09:25.340
Then it is equivalent as if each person was finishing four fifteen per day.

09:25.340 --> 09:30.340
So on average, it takes fifteen over four days to finish a task.

09:30.340 --> 09:34.460
And this is an appropriate situation to take the harmonic mean.

09:34.460 --> 09:39.740
Now, consider the next scenario where there are two chambers filled with the same homogenous

09:39.740 --> 09:41.340
ideal gas.

09:41.340 --> 09:45.100
And each chamber contains the same amount of gas.

09:45.100 --> 09:50.100
Now, suppose the mean speed of the molecules in the left chamber is three and the right

09:50.100 --> 09:52.140
chamber is five.

09:52.140 --> 09:54.980
So the right chamber is a bit hotter.

09:54.980 --> 10:01.340
Now once you connect the two chambers together, they will eventually reach a thermal equilibrium.

10:01.340 --> 10:05.460
And the mean speed of the molecules on both sides of the chamber will eventually balance

10:05.460 --> 10:08.580
out to a number between three and five.

10:08.580 --> 10:11.540
So what is this average speed after mixing?

10:11.540 --> 10:15.460
Well, we know that the temperature on the left and the right will eventually reach an

10:15.460 --> 10:17.580
arithmetic mean.

10:17.580 --> 10:22.820
And since temperature is, roughly speaking, the average kinetic energy of the molecules,

10:22.820 --> 10:25.940
it is proportional to the square of the mean speed.

10:25.940 --> 10:29.940
And for those of you who are curious what the constant of proportionality is, it is

10:29.940 --> 10:35.860
pi times the mass of the air molecule, all over eight times the Boltzmann constant.

10:35.860 --> 10:40.980
So now, to find the average mean velocity after the thermal equilibrium, we would have

10:40.980 --> 10:46.940
to take the root mean square of three and five.

10:46.940 --> 10:51.620
We looked at multiple different scenarios to use different kinds of means.

10:51.620 --> 10:55.700
Notice how as alpha grows bigger, the mean takes more weight of the bigger value, which

10:55.700 --> 10:57.900
is five.

10:57.900 --> 11:02.460
So from these four examples, the harmonic mean is the smallest and the quadratic mean

11:02.460 --> 11:05.380
is the biggest.

11:05.380 --> 11:08.460
There are two more averages that are very commonly used.

11:08.460 --> 11:11.380
How much does an average American make per year?

11:11.380 --> 11:16.060
And since there are ridiculous outliers, like billionaires which would skew the arithmetic

11:16.060 --> 11:23.220
mean too far to the right, and zero income people which would make geometric mean zero.

11:23.220 --> 11:27.500
Instead of any of the generalized means, we typically take the median in practice, which

11:27.500 --> 11:29.300
is the middle number.

11:29.300 --> 11:34.020
And it is a pretty good representative of how much an average person makes.

11:34.020 --> 11:37.180
And another commonly used average is the mode.

11:37.180 --> 11:43.700
So when we say an average American owns a smartphone, we probably mean most Americans.

11:43.700 --> 11:48.180
And the majority is a pretty good representative of an average person.

11:48.180 --> 11:56.420
Now, we have a solid notion of what an average is, so we are ready to take the first step.

11:56.420 --> 12:01.900
Each time we win, we gain t times r, so it is same as multiplying 1 plus tr to how much

12:01.900 --> 12:03.740
money we have.

12:03.740 --> 12:10.700
This essentially is the same as 30% gain really meaning 130% the original amount.

12:10.700 --> 12:15.860
And we can come up with something similar for each time we lose.

12:15.860 --> 12:21.100
Suppose we win k times out of n games, then we will lose n minus k games.

12:21.100 --> 12:25.980
I will call this big R for the total return, and we would want to multiply this to the

12:25.980 --> 12:30.140
initial capital to see how much money we have after n games.

12:30.140 --> 12:34.620
And for this expression, I want to use the convention that 0 to the power of 0 is equal

12:34.620 --> 12:41.700
to 1, which sounds like a nonsense, but suppose you all in each play, and if you get lucky,

12:41.700 --> 12:46.740
you have multiplied your money n times by the factor of 1 plus tr.

12:46.740 --> 12:51.260
And if you get unlucky just once, then you lost all your money.

12:51.260 --> 12:56.340
So to make sense out of this situation, we will choose to define that 0 to the 0 is equal

12:56.340 --> 12:58.960
to 1 for this expression.

12:58.960 --> 13:04.800
Of course we can treat this rigorously with limits, but we just want a model that works.

13:04.800 --> 13:09.760
Now we are expected to win about n times p games where p is the probability of winning

13:09.760 --> 13:14.320
1 game, and we are to lose about n times q games.

13:14.320 --> 13:18.240
So this is the average total return right?

13:18.240 --> 13:24.200
Earlier we have talked about all the different types of averages, and which one is this one?

13:24.200 --> 13:28.880
Well, to really make sense out of this, we need to introduce a new toolkit called random

13:28.880 --> 13:31.520
variables.

13:31.520 --> 13:35.360
Consider a scenario where you toss an unfair coin 3 times.

13:35.360 --> 13:40.080
There are 8 different events possible, and we can calculate the probability of each event

13:40.080 --> 13:45.240
by multiplication since each throw is independent.

13:45.240 --> 13:49.840
Then we can come up with a random variable for the total number of heads.

13:49.840 --> 13:55.680
So x of the event hht would be 2.

13:55.680 --> 13:58.720
This example illustrates what a random variable is.

13:58.720 --> 14:03.800
It simply is a function that takes an event and assigns a numerical value.

14:03.800 --> 14:09.320
And by doing so, we turn the raw non-numerical data such as sequence of heads and tails into

14:09.320 --> 14:12.840
numerical data, and it is much easier to work with.

14:12.840 --> 14:18.240
Well, that is the more modern interpretation, but before the rise of set theory and measure

14:18.240 --> 14:22.520
theory, mathematicians nively thought of it as a variable that can take on the values

14:22.520 --> 14:24.480
of a random event.

14:24.480 --> 14:30.880
And for this scenario, x can take on the values 0, 1, 2, and 3.

14:30.880 --> 14:36.320
And in either perspective, we can calculate the probability of x equaling 2 by adding

14:36.320 --> 14:40.360
probabilities of all possible ways of 2 heads showing up.

14:40.360 --> 14:43.020
And we could do this similar for 3.

14:43.020 --> 14:48.200
But what's the probability of 7 heads showing up out of 3 toss?

14:48.200 --> 14:52.960
That's just impossible, so the probability is 0.

14:52.960 --> 14:57.800
Now we can plot the probability for each values of the random variable, and we call

14:57.800 --> 15:02.280
this the probability mass function.

15:02.280 --> 15:06.880
This is one very specific example of a class of random variables that we call binomial

15:06.880 --> 15:08.680
random variable.

15:08.680 --> 15:13.880
Denoted b with two parameter n for the number of trials and p for the probability of winning

15:13.880 --> 15:20.680
one trial, and we can just write b when the context is clear.

15:20.680 --> 15:28.340
And since b represents the number of wins, it can take on the values from 0 to n.

15:28.340 --> 15:32.840
How do we calculate the probability of getting two wins out of four trials if the probability

15:32.840 --> 15:34.760
of winning is one-third?

15:34.760 --> 15:39.640
Well, there are six different ways you can win twice, and each of these events have a

15:39.640 --> 15:43.400
probability of one-third squared times two-third squared.

15:43.400 --> 15:48.560
And we can get six by taking four choose two.

15:48.560 --> 15:54.640
So doing the very same thing in general, the probability of b equaling k is n choose k

15:54.640 --> 16:00.480
times p to the k times q to the n minus k, where q is one minus p.

16:00.480 --> 16:05.840
Next, I want to come up with the notion of the arithmetic mean for random variables and

16:05.840 --> 16:10.320
how it compares with the arithmetic mean of a statistical data set.

16:10.320 --> 16:16.920
So let's say there are 10,000 independent experiments, each consisting of 10 dice throws.

16:16.920 --> 16:21.960
And for each experiment, we want to count the number of times six shows up.

16:21.960 --> 16:26.440
We can create a histogram to tally up the results, and we can see that it is fairly

16:26.440 --> 16:31.760
common to see six showing up one or two times, but getting ten sixes in a row is practically

16:31.760 --> 16:34.360
impossible.

16:34.360 --> 16:38.600
The probability model that represents one instance of the experiment is the binomial

16:38.600 --> 16:43.880
distribution of ten trials and the probability of winning equaling one-six.

16:43.880 --> 16:48.320
And if we plot the probability mass function, the shape is essentially identical to the

16:48.320 --> 16:53.120
histogram because as long as the number of experiments is large enough, the number of

16:53.120 --> 16:57.760
experiments where three-sixes came up out of the total number of experiments should

16:57.760 --> 17:02.680
approximately equal the probability of three-sixes showing up in a single experiment.

17:02.680 --> 17:06.320
And this holds for any other values as well.

17:06.320 --> 17:11.360
So we can define the expected value, which is the probability equivalent of the arithmetic

17:11.360 --> 17:16.940
mean by summing over the product of the value of the random variable times the probability

17:16.940 --> 17:18.840
of getting that value.

17:18.840 --> 17:23.160
And as long as the number of experiments are large enough, the arithmetic mean approaches

17:23.160 --> 17:25.240
the expected value.

17:25.240 --> 17:29.800
Now, what is the expected value of the binomial distribution?

17:29.800 --> 17:35.600
Well, this summation is fairly tricky to compute, so for those of you that are interested,

17:35.600 --> 17:39.400
I will leave a link in the description below for the derivation.

17:39.400 --> 17:44.680
So for now, let's take a small leap of faith and say it equals n times p.

17:44.680 --> 17:49.320
And it is a reasonable answer that agrees with our intuition since if we toss a coin

17:49.320 --> 17:52.480
hundred times, we expect about fifty heads.

17:52.480 --> 17:58.040
And if we toss a dice sixty times, we expect about ten ones.

17:58.040 --> 18:02.600
It should be clear now that we need to construct a random variable that depends on the binomial

18:02.600 --> 18:04.840
distribution for our problem.

18:04.840 --> 18:10.640
So now we introduce how transformation of random variables work.

18:10.640 --> 18:15.280
Suppose that x is a random variable that can take on the four values negative one, zero,

18:15.280 --> 18:20.520
one, and two, with each value having some probability.

18:20.520 --> 18:26.320
Then y to find as one over x can take on the reciprocals of the values of x.

18:26.320 --> 18:31.440
And the probabilities of each value of y is same as the probabilities of getting the corresponding

18:31.440 --> 18:32.440
x.

18:32.440 --> 18:37.920
So as an example, if we are trying to find the probability of y equaling one half, first

18:37.920 --> 18:42.680
substitute y for one over x, then solve for x.

18:42.680 --> 18:47.200
Notice how the plot of the probability mass function of y is out of order.

18:47.200 --> 18:52.720
So we just have to rearrange it to make it more intuitive to read.

18:52.720 --> 18:56.280
Now what if the transformation is not one to one?

18:56.280 --> 19:00.000
For example, consider the square transformation.

19:00.000 --> 19:04.720
Then y can only take on three values since both positive and negative one squared equals

19:04.720 --> 19:06.280
one.

19:06.280 --> 19:12.480
So if we are trying to calculate the probability of y equaling one, y is equal to x squared,

19:12.480 --> 19:20.360
and there are two possible values of x squared equaling one, so we have to add the two probabilities.

19:20.360 --> 19:25.000
So we have to redraw the PMF by merging the two values.

19:25.000 --> 19:30.000
This essentially is how transformations of all discrete random variables work.

19:30.000 --> 19:33.760
Now, how do we find the expected value of y?

19:33.760 --> 19:38.640
We can just use the definition of the expected value of y, which is the sum over all values

19:38.640 --> 19:43.080
of y times the probability of getting that value.

19:43.080 --> 19:48.280
We can instead just sum over all possible values of x squared times the probability of getting

19:48.280 --> 19:50.360
each value of x.

19:50.360 --> 19:57.040
And during the summation, values that were not one to one will appropriately add together.

19:57.040 --> 20:01.680
This essentially illustrates the proof of the discrete version of the law of the unconscious

20:01.680 --> 20:07.080
statistician, which is often called lotus, which is its acronym, and it is one of the

20:07.080 --> 20:10.600
most important theorems in probability theory.

20:10.600 --> 20:15.440
This theorem is significant since we can find the expected value of a transform distribution

20:15.440 --> 20:19.080
without knowing anything about the transform distribution.

20:19.760 --> 20:25.720
Now, we are ready to formally define r, the total return, as a random variable that depends

20:25.720 --> 20:28.400
on the binomial distribution.

20:28.400 --> 20:33.360
And this makes sense since b is a random variable that takes on the number of wins.

20:33.360 --> 20:40.760
And we want to repeatedly multiply 1 plus tr for each win and 1 minus sr for each loss.

20:40.760 --> 20:45.480
Let's try taking the expected value and see what happens.

20:45.480 --> 20:49.760
And we can use the lotus to evaluate the expected value.

20:49.760 --> 20:55.680
At this point, the summation looked too nasty, so I evaluated it using Wolfram Mathematica.

20:55.680 --> 21:00.320
So kudos to you if you can try and simplify it by hand.

21:00.320 --> 21:07.200
At this point, it's probably good to stop and think about what this means.

21:07.200 --> 21:12.000
In the very beginning, we informally introduced the random variable g to denote the net gain

21:12.000 --> 21:14.040
per single play.

21:14.040 --> 21:19.200
And we also calculated the expected value of net change per single play.

21:19.200 --> 21:25.680
So we can make the substitution for the expected value of the total return.

21:25.680 --> 21:31.400
This expression intuitively makes sense as if we have a net change of e of g per play,

21:31.400 --> 21:37.240
then we are on average multiplying by 1 plus e of g per play.

21:37.240 --> 21:41.880
And this expression is maximized if we take the little r, which is the risk, to be as

21:41.880 --> 21:44.240
big as possible.

21:44.240 --> 21:48.640
It's not too hard to see that maximizing the expected value is not the best strategy.

21:48.640 --> 21:53.360
But to provide a concrete example, suppose there is a game where you flip a fair coin

21:53.360 --> 21:59.280
and if you flip head, you quadruple your risk and if you flip tail, you lose your wager.

21:59.280 --> 22:03.800
And if we take the strategy to maximize the expected value of the total return, the only

22:03.800 --> 22:09.160
way we can win is to consecutively flip heads and if we flip just one tail, we lose all

22:09.160 --> 22:10.880
of our money.

22:10.880 --> 22:15.520
As the number of trials get larger, your chance of becoming rich approaches zero exponentially

22:15.520 --> 22:22.200
fast and you are almost certainly guaranteed to lose everything.

22:22.200 --> 22:24.880
Maximizing the expected value was not the best choice.

22:24.880 --> 22:29.120
So what if we maximize the median instead?

22:29.120 --> 22:34.240
For continuous distribution, the definition of median is obvious, which is the value that

22:34.240 --> 22:36.880
splits the probability into two halves.

22:36.880 --> 22:42.200
But we need a more general definition that works for discrete random variable as well.

22:42.200 --> 22:47.880
So the definition that we will use for median is any real value m such that the probability

22:47.880 --> 22:53.580
of x less than or equal to m is at least half and probability x is greater than or equal

22:53.580 --> 22:55.780
to m is at least half.

22:55.780 --> 23:00.520
So if we look at this binomial distribution x, the total probability less than or equal

23:00.520 --> 23:05.240
to two is more than half and the probability greater than or equal to two is also more

23:05.240 --> 23:06.740
than half.

23:06.740 --> 23:11.420
So for this distribution, the median is equal to two.

23:11.420 --> 23:16.300
Let's take a look at another binomial distribution which happens to be symmetric and bimodal

23:16.300 --> 23:20.940
and the total probability less than or equal to two and greater than or equal to two is

23:20.940 --> 23:22.380
at least half.

23:22.380 --> 23:27.900
So two is the median of this distribution and by the same reasoning, three is a median

23:27.900 --> 23:33.940
as well and if we take any number in between two and three such as 2.5 that satisfies the

23:33.940 --> 23:36.780
definition of median two.

23:36.780 --> 23:42.780
So for this case, the median is the set of closed interval from two to three.

23:42.780 --> 23:47.020
Then what is the median of a binomial distribution?

23:47.020 --> 23:51.340
It is the expected value rounded to the nearest integer.

23:51.340 --> 23:54.100
Well, that was a lie.

23:54.100 --> 23:59.340
We don't actually have a closed formula to find the median in terms of NMP but we do

23:59.340 --> 24:01.540
know a few things about it.

24:01.540 --> 24:07.420
And one thing for sure is that median could either take on Np rounded up or down or maybe

24:07.420 --> 24:09.980
both at the same time.

24:09.980 --> 24:14.220
This isn't something we could prove quickly but I want to provide an intuition for big

24:14.220 --> 24:19.700
values of N since we are interested in long term winning strategy.

24:19.700 --> 24:24.540
So for large values of N, the binomial distribution starts to look more and more like the bell

24:24.540 --> 24:30.580
curve so the mean and the median should roughly be equal to each other but since b can only

24:30.580 --> 24:34.740
take on integer values so does the median.

24:34.740 --> 24:39.540
For rest of the video, we will just approximate that the median of the binomial distribution

24:39.540 --> 24:43.540
is roughly equal to the mean.

24:43.540 --> 24:47.780
Now how do we compute the median of a transform distribution?

24:47.780 --> 24:54.380
For example, if we have some distribution x and if we apply a power to it, the probability

24:54.380 --> 24:59.060
mass function essentially looks the same since there was no rearrangement in the ordering

24:59.060 --> 25:04.700
of each bars so the median would be represented by the same bar on the left and the right

25:04.700 --> 25:10.020
so the median of the transform is the same as transform of the median.

25:10.020 --> 25:17.380
Now what if we apply a monotonically decreasing transformation like 2 to the negative x?

25:17.380 --> 25:23.780
Then the ordering completely flips but the middle is still the middle so the median commutes

25:23.780 --> 25:28.300
with the transformation for this case as well.

25:28.300 --> 25:32.700
But if we have a transformation that is not strictly increasing like the integer part

25:32.700 --> 25:39.220
of x divided by 3, I marked where the original median was with the blue arrow and since this

25:39.220 --> 25:47.300
function is not 1 to 1, we would have to merge the bars together.

25:47.300 --> 25:53.060
Since 4 was the original median, everything up to 4 is at least half so everything up

25:53.060 --> 25:56.940
to 5 is at least half as well.

25:56.940 --> 26:01.820
And everything down to 4 is at least half so everything down to 3 is at least half as

26:01.820 --> 26:02.940
well.

26:02.940 --> 26:09.580
So 1 which is the transform of 4 is the median of the new distribution.

26:09.580 --> 26:14.480
So we can just find the median of a transform by taking the transform of the median as long

26:14.480 --> 26:21.300
as g is a monotonic function, whether it's increasing or decreasing, strict or not.

26:21.300 --> 26:25.020
So can we find the median of the total return?

26:25.020 --> 26:31.700
We can write the transformation as a single exponent function.

26:31.700 --> 26:36.860
And if the base of the exponent is greater than 1, it is increasing.

26:36.860 --> 26:44.440
If it's equal to 1 then it is constant and if it's in between 0 and 1 then it is decreasing.

26:44.440 --> 26:49.620
If the base is 0 or negative, we run into some issues with the monotonicity.

26:49.620 --> 26:56.740
So if we restrict both the numerator 1 plus tr and the denominator 1 minus sr to be positive,

26:56.740 --> 27:00.900
we get a restriction of allowed range per r.

27:00.900 --> 27:05.940
Intuitively 1 over s is the maximum possible risk that we can take, which is equivalent

27:05.940 --> 27:07.780
to all in.

27:07.780 --> 27:11.740
But what does negative 1 over t signify?

27:11.740 --> 27:15.540
That actually is the maximum risk that we can possibly take if we are taking the short

27:15.540 --> 27:17.160
position.

27:17.160 --> 27:20.020
So now we have a reasonable range for r.

27:20.020 --> 27:24.580
And within this range, the transformation is monotonic so we can compute the median

27:24.580 --> 27:30.680
of big r by taking the transformation of the median of the binomial distribution.

27:30.680 --> 27:34.260
Then median can be approximated by np.

27:34.260 --> 27:40.040
So after some manipulation, we arrive at this expression.

27:40.040 --> 27:44.760
And we can think of this as a single variable function of the risk since other variables

27:44.760 --> 27:47.140
are fixed parameters.

27:47.140 --> 27:52.780
So this allows us to do some single variable differential calculus.

27:52.780 --> 27:57.260
1 over s and negative 1 over t are the roots of this function.

27:57.260 --> 28:01.320
So if we graph this function with respect to the risk, it looks something like an upside

28:01.320 --> 28:04.420
down parabola with a single maximum.

28:04.420 --> 28:08.920
I normalize the graph so that the peak is always at the same height since it is really

28:08.920 --> 28:11.080
what we want to know about.

28:11.080 --> 28:17.120
So if we vary the value of p, the probability of winning, the location of the maximum changes.

28:17.360 --> 28:21.880
But if we change the value of n, the shape of the graph changes but where the maximum

28:21.880 --> 28:23.760
is does not.

28:23.760 --> 28:27.560
And this illustrates one of the key techniques in calculus.

28:27.560 --> 28:31.680
Instead of finding the maximum of the original function, we can instead find the maximum

28:31.680 --> 28:35.800
of a transform function as long as the transform is monotonic.

28:35.800 --> 28:40.600
And we can take natural log as well which is a monotonic function since it splits products

28:40.600 --> 28:44.520
into sums and it makes calculus so much easier.

28:44.520 --> 28:49.520
Now let's take the derivative which turns logs into reciprocals and we have to pull

28:49.520 --> 28:52.640
out the coefficient by chain rule.

28:52.640 --> 28:58.240
And we set it equal to 0 in order to find that single maximum.

28:58.240 --> 29:03.360
At this point, all the heavy lifting is done so I will leave it to you to solve for r and

29:03.360 --> 29:09.880
get that r that maximizes the median is indeed the Kelly's formula.

29:09.880 --> 29:12.840
We computed the optimal risk for mean and median.

29:12.840 --> 29:17.160
So we might as well try the mode since those three are the averages you learn in elementary

29:17.160 --> 29:19.120
school statistics.

29:19.120 --> 29:23.960
And unlike median, mode is fairly intuitive to define for random variables.

29:23.960 --> 29:30.080
It simply is the value that gives the biggest probability and there can be multiple modes.

29:30.080 --> 29:34.640
Then what is the mode of a binomial distribution?

29:34.640 --> 29:38.880
Unlike the median, there is a closed formula in terms of NMP.

29:38.880 --> 29:44.640
But this is a bit of overkill and just like median, we will say that the mode is an integer

29:44.640 --> 29:51.560
value close to the expected value and we can approximate it using the expected value.

29:51.560 --> 29:55.560
Then what is the mode of a transformed random variable?

29:55.560 --> 30:00.480
If we simply take a discrete random variable and permute the values, then the biggest bar

30:00.480 --> 30:02.240
is still preserved.

30:02.240 --> 30:07.960
But if we merge some bars, what was originally the biggest may not be the new biggest.

30:07.960 --> 30:13.320
So one condition where mode commutes with G is that G is one to one.

30:13.320 --> 30:18.160
By the way, this only holds for discrete random variables and fails for continuous random

30:18.160 --> 30:19.840
variables in general.

30:19.840 --> 30:23.920
So if you can come up with an example, leave it in the comments below.

30:23.920 --> 30:27.200
Now what if we stack all the bars into one?

30:27.200 --> 30:30.680
That is, the transformation is a constant function.

30:30.680 --> 30:35.400
Then every single value, including what was originally the mode transformed into the new

30:35.400 --> 30:36.480
mode.

30:36.480 --> 30:40.240
So mode commutes with G if G is a constant function.

30:40.240 --> 30:44.680
I'm sure there are more interesting examples, but these two conditions are the ones we will

30:44.680 --> 30:49.040
be using.

30:49.040 --> 30:54.040
Just like how we did for median, the exponential function is either one to one or constant

30:54.040 --> 30:57.360
as long as the base of the exponent is greater than zero.

30:57.360 --> 31:00.800
And we found the appropriate conditions.

31:00.800 --> 31:04.320
So mode of the transform is transform of the mode.

31:04.320 --> 31:10.320
So it will simplify the exact same value that median came out to.

31:10.320 --> 31:18.720
So once we find the R that maximizes the mode, we will get Kelly's formula once again.

31:18.720 --> 31:23.360
If we plot the probability mass function of the binomial distribution, it looks roughly

31:23.360 --> 31:24.480
normal.

31:24.480 --> 31:29.400
But if we transform it to the total return, the ordering is preserved but the shape gets

31:29.400 --> 31:30.800
skewed.

31:30.800 --> 31:35.840
But if we instead plot this on a log scale, the shape becomes normal again.

31:35.840 --> 31:40.040
By the way, the choice of the base being 5 was completely arbitrary in terms of the

31:40.040 --> 31:45.160
shape that it gives, it just happened to give me the best picture.

31:45.160 --> 31:50.560
So this raises suspicion that there is an exponential or multiplicative behavior lurking

31:50.560 --> 31:52.160
in the background.

31:52.160 --> 31:56.200
So we should try taking the geometric mean.

31:56.200 --> 32:00.080
Just like how we defined the arithmetic mean for a random variable, we can generalize

32:00.080 --> 32:02.480
this for any mean.

32:02.480 --> 32:07.920
But things get pretty tricky if we send alpha to zero.

32:07.920 --> 32:12.480
And for the case of sample geometric mean, the limit approach the product of each data

32:12.480 --> 32:15.120
then taking the nth root.

32:15.120 --> 32:19.800
Now we will take a natural log on both sides since the power drops as the coefficient and

32:19.800 --> 32:22.840
product splits into sum.

32:22.840 --> 32:27.520
And once we exponentiate both sides, we have an alternative formula for geometric mean

32:27.520 --> 32:29.760
that does not have product in it.

32:29.760 --> 32:34.240
In fact, this looks much closer to the generalized formula above compared to the formula that

32:34.240 --> 32:35.920
involves the product.

32:35.920 --> 32:41.240
So it could be thought of as the missing link between the general form and the product form.

32:41.240 --> 32:45.760
In any case, we will use this formula in a similar way to define the geometric mean for

32:45.760 --> 32:48.760
a random variable.

32:48.760 --> 32:53.400
Let's first compute the expected value of the log of r, which can be evaluated using

32:53.400 --> 32:55.040
lotus.

32:55.040 --> 32:58.680
Then we can drop the powers and split up the sum.

32:58.680 --> 33:03.680
And by the linearity of summation, we can split up the sum into three separate summations

33:03.680 --> 33:10.840
and pulling out things that does not involve k outside of the summation.

33:10.840 --> 33:15.960
Notice how the circle part literally is the expected value of the binomial distribution.

33:15.960 --> 33:24.680
And the one in the blue circle is sum of each probability which should add to one.

33:24.680 --> 33:28.560
Now we can factor out like terms and make some substitutions.

33:28.560 --> 33:31.600
And this should look awfully familiar.

33:31.600 --> 33:36.200
Once we take the exponent to find the geometric mean, it comes out to exactly same expression

33:36.200 --> 33:38.320
as the median and the mode.

33:38.320 --> 33:42.720
And once again, we can derive the Kelly's formula from here.

33:42.720 --> 33:47.720
I want to wrap it up with the final remark that provides an interpretation of the formula.

33:47.720 --> 33:51.320
Since the geometric mean is supposed to be the multiplicative average, we can take the

33:51.320 --> 33:55.560
nth root to find the average net game per single play.

33:55.560 --> 34:00.880
If we win, we multiply by 1 plus tr to the principal capital, and if we lose, we multiply

34:00.880 --> 34:02.880
by 1 minus sr.

34:02.880 --> 34:07.760
So we can think of this as the average multiplier per single play.

34:07.760 --> 34:11.640
And if we instead find the geometric mean of the total return for the binomial random

34:11.640 --> 34:14.920
variable of one trial, we get this exact value as well.

