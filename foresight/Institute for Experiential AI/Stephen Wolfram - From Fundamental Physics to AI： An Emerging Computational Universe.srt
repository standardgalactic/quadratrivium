1
00:00:00,000 --> 00:00:08,840
So, welcome everybody, I have a pleasure to introduce Stephen Warfram, I know him many,

2
00:00:08,840 --> 00:00:14,600
many years because I was involved at some point in a different computer algebra system,

3
00:00:14,600 --> 00:00:22,180
you know he's the creator of Mathematica, he's the founder and CEO of Warfram Research,

4
00:00:22,180 --> 00:00:28,080
he also created this semantic search engine Warfram Alpha that you may be well aware of

5
00:00:28,080 --> 00:00:34,240
and now he's using language models, he's author of many books like A New Kind of Sciences

6
00:00:34,240 --> 00:00:41,680
and a very recent book on everything about physics and we are very happy that he accepted

7
00:00:41,680 --> 00:00:51,600
to come today to do the last distinguished lecture of the semester.

8
00:00:51,600 --> 00:00:58,360
So all right, let's talk about, so as far as I'm concerned the kind of the big idea

9
00:00:58,360 --> 00:01:06,000
that is kind of a defining idea probably of our century is this idea of computation and

10
00:01:06,000 --> 00:01:13,120
I kind of view it as being part of a long sequence of efforts that kind of span the

11
00:01:13,120 --> 00:01:18,560
history of our species I suppose in trying to formalize things.

12
00:01:18,560 --> 00:01:23,840
So you know the probably the first step in that was the creation of human language and

13
00:01:23,840 --> 00:01:29,180
the idea that one could instead of just sort of pointing at different rocks and so on,

14
00:01:29,180 --> 00:01:34,520
one could have a kind of symbolic term rock that represents the general category of things

15
00:01:34,520 --> 00:01:35,520
that are rocks.

16
00:01:35,520 --> 00:01:41,800
That was kind of a big step in being able to explain, in being able to abstract things

17
00:01:41,800 --> 00:01:46,880
from the world as it is to something that we can describe in a formal way and kind of

18
00:01:46,880 --> 00:01:52,440
I would say the next another big step in that was the creation of logic, the idea that

19
00:01:52,440 --> 00:01:57,280
one could take a collection of sentences that had the particular forms of particular forms

20
00:01:57,280 --> 00:02:04,280
and say there's something that we can abstract from all these sentences that is a representation

21
00:02:04,280 --> 00:02:10,440
of something that is formal that we can deduce from these sentences and it's kind of interesting

22
00:02:10,440 --> 00:02:15,640
that when we look at the chat GPs of this world and people are sort of amazed oh wow

23
00:02:15,680 --> 00:02:22,680
it manages to do logic well it's been trained from a you know trillion words of stuff that

24
00:02:23,320 --> 00:02:29,840
we humans have put out there on the web and that contains the same kind of forms of speech

25
00:02:29,840 --> 00:02:35,200
that you know Aristotle and folks like that used to originally construct logic it's able

26
00:02:35,200 --> 00:02:41,720
it's one is abstracting from the specifics of language to something that is a more formal

27
00:02:41,720 --> 00:02:44,360
representation of what's going on.

28
00:02:44,400 --> 00:02:49,720
I suppose in the kind of long arc of history the next big thing that's sort of an example

29
00:02:49,720 --> 00:02:56,200
of formalization of things in the world is mathematics that's another kind of way of

30
00:02:56,200 --> 00:03:02,960
formalizing what happens in the world describing things in terms of numbers and algebra and

31
00:03:02,960 --> 00:03:09,960
those sorts of things. And mathematics when it comes to science kind of the last 300 years

32
00:03:10,960 --> 00:03:17,960
sort of mathematics had been the kind of dominant form of formalization used in science

33
00:03:17,960 --> 00:03:22,640
logic was not particularly successful for as a formalization for science mathematics is

34
00:03:22,640 --> 00:03:29,640
sort of the winning one and that's something that has had continued until quite recently.

35
00:03:30,560 --> 00:03:35,520
The big thing that is sort of new last hundred years is this idea of computation the idea

36
00:03:35,560 --> 00:03:41,560
that there you can what is computation as far as I'm concerned it's you specify sort

37
00:03:41,560 --> 00:03:47,560
of precise rules and then you understand their consequences. In mathematics there are particular

38
00:03:47,560 --> 00:03:53,280
kinds of rules that are represented by I don't know algebra and integrals and calculus and

39
00:03:53,280 --> 00:03:58,080
things like that. There are particular kinds of rules that we study in mathematics computation

40
00:03:58,080 --> 00:04:03,440
is about the most general case of studying sort of given rules what are their consequences

41
00:04:03,440 --> 00:04:09,280
and by the way there's sort of a difference in the way that a particular time is handled

42
00:04:09,280 --> 00:04:13,880
when we think about computation as compared to when we think about for example mathematics

43
00:04:13,880 --> 00:04:18,360
in mathematics we might have some equation that has time as a parameter but we kind of

44
00:04:18,360 --> 00:04:22,160
expect we're going to get an answer where we get some formula where time appears in

45
00:04:22,160 --> 00:04:27,400
the formula but we can set that time to be any value we want. When we think about computation

46
00:04:27,400 --> 00:04:32,840
we're thinking about we're given these rules and now we're going to run these rules and

47
00:04:33,040 --> 00:04:38,480
we're going to see what happens we don't get to say oh I'm going to sort of set the value

48
00:04:38,480 --> 00:04:42,080
of time to be this we have to just run the rules and see what happens. Maybe I should

49
00:04:42,080 --> 00:04:49,080
explain some things that this is from the 1980s actually the kind of a big effort of

50
00:04:53,080 --> 00:05:00,080
the question that this I've been talking about kind of computation as a way of thinking

51
00:05:03,840 --> 00:05:09,720
kind of formalizing what happens in the world so one of the things I got interested in back

52
00:05:09,720 --> 00:05:15,800
at the beginning of the 1980s actually was if one is going to make models of nature what

53
00:05:15,800 --> 00:05:20,400
raw material one might one use to do that and kind of the traditional view had been

54
00:05:20,400 --> 00:05:24,960
used mathematical equations and so on my interest was to kind of generalize that and to see

55
00:05:24,960 --> 00:05:30,560
what happens if you use not equations but programs to represent things in the world

56
00:05:30,640 --> 00:05:36,200
and I have to say it's kind of a spoiler for the path of history but in the last 25 years

57
00:05:36,200 --> 00:05:42,040
or so there's been after 300 years of complete dominance of kind of mathematical equations

58
00:05:42,040 --> 00:05:46,880
as ways to model the world computation has become and programs and so on have kind of

59
00:05:46,880 --> 00:05:53,880
become the when new models are created that's almost always what new models get made with

60
00:05:53,880 --> 00:06:00,880
so but the question that I got interested in years ago is when you look at just simple

61
00:06:01,160 --> 00:06:08,160
if you just ask what what kinds of programs might nature use to do the things that it

62
00:06:08,200 --> 00:06:15,200
does and a particular category of such programs that I found convenient to look at are things

63
00:06:15,920 --> 00:06:23,680
that get called cellular automata this is an example of them it's just a line of cells

64
00:06:23,680 --> 00:06:29,560
each one is either black or white and in a series of steps you set the new color of

65
00:06:29,560 --> 00:06:34,000
the cell to be determined by rule that depends on the previous color of that cell and the

66
00:06:34,000 --> 00:06:41,000
previous colors of its two neighbors so if we take that we just say run run that let's

67
00:06:41,000 --> 00:06:48,000
let's let's let's run that for a few steps here let's just show this with a mesh okay

68
00:06:51,120 --> 00:06:56,440
so this is this is using that rule and at every at every cell at every step we're just

69
00:06:56,440 --> 00:07:01,240
applying that rule to determine what the color of the next step cell will be so we have a

70
00:07:01,240 --> 00:07:06,000
very simple rule we get very simple behavior it's kind of like you kind of you might expect

71
00:07:06,000 --> 00:07:10,400
that's what's going to happen well let's let's change this rule a bit let's say we have

72
00:07:10,400 --> 00:07:16,000
something like this we can change it see what it does that's what it does then let's change

73
00:07:16,000 --> 00:07:23,000
it again let's say we do this how we use that rule instead well now we get a slightly more

74
00:07:23,680 --> 00:07:28,400
complicated pattern if we keep it running a little bit longer we'll find that it makes

75
00:07:28,400 --> 00:07:34,480
a nice some kind of elaborate intricate but very nested structure and we might again say

76
00:07:34,480 --> 00:07:39,640
at this point oh you know if the rule is simple then even if the behavior is somehow intricate

77
00:07:39,640 --> 00:07:46,200
there will be some easy regularity to identify in that behavior okay so now you can ask the

78
00:07:46,200 --> 00:07:50,520
question if you're just sort of studying these things from a sort of science point of view

79
00:07:50,520 --> 00:07:54,600
you can ask the question well why don't I just do an experiment why don't I just point sort

80
00:07:54,600 --> 00:07:59,120
of a computational telescope out into this computational universe of possible programs

81
00:07:59,120 --> 00:08:04,760
just find out what's out there so we can try doing that and let's just make a table of

82
00:08:04,800 --> 00:08:15,800
these with any rule number here and let's do let's say the first 64 of these and this is the result

83
00:08:15,800 --> 00:08:21,960
we get so much of the time so ever every one of these pictures is a different rule that we're

84
00:08:21,960 --> 00:08:27,160
using a much of the time you see what happens is really pretty simple maybe there's stripes from

85
00:08:27,160 --> 00:08:32,280
alternating stripes but there's some fairly simple structure that's produced and here are some nice

86
00:08:32,320 --> 00:08:39,400
nested patterns and then this is my all-time favorite science discovery here's rule 30 in that

87
00:08:39,400 --> 00:08:44,040
numbering scheme it does something a bit different let's take a look at that in a bit more detail

88
00:08:44,040 --> 00:08:50,480
let's say let's look at the rule for it here it is and let's look at what it actually does and

89
00:08:50,480 --> 00:08:55,840
that's the result so what's really remarkable about this is the rule is simple starts off

90
00:08:55,840 --> 00:09:01,360
from just one black cell yet the behavior you get when you actually run this rule is something

91
00:09:01,440 --> 00:09:06,320
complicated in fact if you look at the center column of cells here for all practical purposes

92
00:09:06,320 --> 00:09:14,320
they seem completely random and this is this is kind of a big surprise to one's intuition because

93
00:09:14,320 --> 00:09:18,400
this idea that to make something complicated you have to go lots of effort that's what we kind of

94
00:09:18,400 --> 00:09:23,920
learn intuitively from doing engineering if you want to make a complicated thing you have to go to

95
00:09:23,920 --> 00:09:28,400
a lot of effort to build up this whole structure that's going to make that complicated thing but

96
00:09:28,400 --> 00:09:33,600
here we've got something where in a sense effortlessly from this very simple rule we're making a

97
00:09:33,600 --> 00:09:39,720
very complicated thing well back in the 1980s what I was excited about was what that means for

98
00:09:39,720 --> 00:09:48,120
understanding what happens in nature what happens in in in kind of the understanding how sort of

99
00:09:48,120 --> 00:09:53,880
complexity arises in systems in nature and realizing that this kind of phenomenon that we see in the

100
00:09:53,880 --> 00:09:59,680
computational universe seems to be the secret that nature has that lets it makes so many complicated

101
00:09:59,680 --> 00:10:04,200
things that in fact out in the computational universe of possible programs that should pretty

102
00:10:04,200 --> 00:10:10,680
common to find that even very simple rules can generate what appears to us to be very complicated

103
00:10:10,680 --> 00:10:16,200
behavior well maybe it's worthwhile to understand kind of what how we can understand this phenomenon

104
00:10:16,200 --> 00:10:21,040
that very simple rules can produce very complicated behavior what's sort of going on what are the

105
00:10:21,040 --> 00:10:28,840
broader scientific implications of that and the I suppose one of the one of the big the underlying

106
00:10:28,840 --> 00:10:34,680
principle that I kind of came up with in the 1990s now is this thing I call the principle of

107
00:10:34,680 --> 00:10:41,120
computational equivalence so here's how this works we think about what what is this thing doing we

108
00:10:41,120 --> 00:10:45,600
can think of it as doing a computation it's been given some input it's been given a rule it runs

109
00:10:45,720 --> 00:10:51,880
that that that rule with that input it generates some output it's it's a computation like a computer

110
00:10:51,880 --> 00:10:58,320
might run a computation the question is how sophisticated is that computation is that

111
00:10:58,320 --> 00:11:03,920
computation one that is somehow quite straightforward we could just jump ahead and we could do a

112
00:11:03,920 --> 00:11:10,280
better computation figure out the answer or is it the case that this computation is is is a

113
00:11:10,280 --> 00:11:14,840
sophisticated one so the big thing that was discovered about a hundred years ago now is this

114
00:11:14,920 --> 00:11:19,920
idea of universal computation the idea that there exist systems like Turing machines and so on

115
00:11:19,920 --> 00:11:26,000
that have the property that you can just have a fixed piece of hardware so to speak a fixed rule

116
00:11:26,000 --> 00:11:31,680
and yet by changing the initial conditions for the system you can make that system behave like any

117
00:11:31,680 --> 00:11:36,040
other computational system and that's sort of an important idea because it's the idea that makes

118
00:11:36,040 --> 00:11:42,520
software possible it's kind of the idea that drove essentially modern technology as it is but that

119
00:11:42,560 --> 00:11:50,440
idea is says there exists a system that you can build it's maybe it's a microprocessor with a

120
00:11:50,440 --> 00:11:55,200
billion transistors on it that is capable of universal computation what the principle of

121
00:11:55,200 --> 00:12:00,080
computational equivalence says is something much more extreme than that it says whenever you look

122
00:12:00,080 --> 00:12:04,280
at these systems in the computational universe when they're not doing things that are in a sense

123
00:12:04,280 --> 00:12:10,920
obviously trivial then they will tend to be doing things which are as sophisticated computations as

124
00:12:10,920 --> 00:12:17,880
anything can do so it's kind of saying that that something like this system here should be capable

125
00:12:17,880 --> 00:12:23,120
of for example universal computation but more to the point it's the computation you're seeing here

126
00:12:23,120 --> 00:12:28,160
is as sophisticated as the computation that any system can do so what are the consequences of

127
00:12:28,160 --> 00:12:33,560
this well one consequence is if we're trying to predict what this system does then we're doing

128
00:12:33,560 --> 00:12:40,400
that by doing a computation so if we expect that we can sort of jump ahead and say this system

129
00:12:40,400 --> 00:12:44,760
after a billion steps is going to do this what we have to believe is that the computation we can

130
00:12:44,760 --> 00:12:49,720
do is somehow more sophisticated than the computation the system can do so that we can kind of do

131
00:12:49,720 --> 00:12:54,000
that jumping ahead and seeing what the answer is going to be but the principle of computational

132
00:12:54,000 --> 00:12:58,280
equivalence says you're not going to be able to do that it says that the computation you get to do

133
00:12:58,280 --> 00:13:04,040
with your brain your computer your mathematics whatever else is just the same sophistication as

134
00:13:04,040 --> 00:13:09,120
the computation that this little system can do so you can't expect to be able to jump ahead like

135
00:13:09,200 --> 00:13:14,160
that and that leads to this phenomenon I call computational irreducibility which is this idea

136
00:13:14,160 --> 00:13:19,920
that there are things that happen computations that happen which are irreducible in the sense

137
00:13:19,920 --> 00:13:24,240
that to know what's going to get what consequences they're going to have you basically just have

138
00:13:24,240 --> 00:13:29,440
to run that computation and see what happens you can't expect to jump ahead and figure out the

139
00:13:29,440 --> 00:13:35,360
answer with with less steps than actually running essentially with less steps than actually running

140
00:13:35,360 --> 00:13:39,680
the system so here's an example let me show you an example of another one where it's kind of

141
00:13:39,680 --> 00:13:46,320
interesting to see what happens here let's say rule 110 so this one actually happens to grow

142
00:13:46,320 --> 00:13:54,000
only on one side but you see it makes this little structure let's run it for a thousand steps let's say

143
00:13:54,560 --> 00:13:59,040
and the question will be we have that little structure there is that structure going to die out

144
00:13:59,040 --> 00:14:03,680
or is that structure going to keep going forever well if we said if there wasn't computational

145
00:14:03,680 --> 00:14:10,160
irreducibility we could say well we expect there's just some some sophisticated formula we can make

146
00:14:10,160 --> 00:14:14,400
that can jump ahead and say that's what's going to happen in the end to this but with computational

147
00:14:14,400 --> 00:14:19,680
irreducibility the only way we can work out what's going to happen is essentially to follow the steps

148
00:14:19,680 --> 00:14:25,360
and see what happens and if we don't know how many steps we have to follow it's going to be in general

149
00:14:25,360 --> 00:14:29,600
a question which is sort of undecidable to us what's going to happen in the end well let's see

150
00:14:29,840 --> 00:14:34,240
you can run it I think there's three thousand steps enough yeah three thousand steps was enough

151
00:14:34,240 --> 00:14:39,840
we can if you can just about see it you'll see that it pretty much died out maybe it's still got some

152
00:14:39,840 --> 00:14:45,520
possible life to it but what's interesting is that we can't predict that without essentially running

153
00:14:45,520 --> 00:14:51,600
the rule and just seeing what happens so okay so there's so we have that we've discovered this

154
00:14:51,600 --> 00:14:56,960
phenomenon that even very simple rules in the computational universe can produce very complicated

155
00:14:57,040 --> 00:15:04,960
behavior can produce behavior that is uh is it turns out to often be similar to the kinds of

156
00:15:04,960 --> 00:15:10,080
behavior we see in the in the natural world also has this feature that even though we might have

157
00:15:10,080 --> 00:15:14,880
thought you know the big thing about science is you can always jump ahead and predict things

158
00:15:14,880 --> 00:15:19,680
computational irreducibility shows us that's not true there's sort of a fundamental limitation

159
00:15:19,680 --> 00:15:23,360
it's kind of from within science we see there's sort of a fundamental limitation

160
00:15:23,360 --> 00:15:29,440
that prevents that from happening and makes it it so that we kind of just have to simulate things

161
00:15:29,440 --> 00:15:35,200
to see what's going to happen okay so one question you might ask is we found out the very simple

162
00:15:35,200 --> 00:15:40,480
rules can produce very complicated behavior uh how far does that go what kinds of things can

163
00:15:40,480 --> 00:15:46,480
that do can it make you know can it make brain like things can it make universe like things what

164
00:15:46,480 --> 00:15:50,000
can it make let's talk about the universe first because it's sort of the biggest thing we can

165
00:15:50,000 --> 00:15:57,760
talk about um and uh the um so the question is if we look at the physical world what what's

166
00:15:57,760 --> 00:16:03,120
underneath what's the underlying structure of how the physical world gets made could the physical

167
00:16:03,120 --> 00:16:11,040
world in fact be something which can be represented by some simple computational process and people

168
00:16:11,040 --> 00:16:14,880
have wondered you know what what's the sort of fundamental theory of physics for a long time

169
00:16:14,880 --> 00:16:19,600
and people have different views of that and there's been kind of a a bunch of well it's going waves

170
00:16:19,600 --> 00:16:24,320
of optimism and pessimism but about a hundred years ago a lot of progress was made in the invention

171
00:16:24,320 --> 00:16:29,040
of kind of the the core theories of modern physics which are basically statistical mechanics

172
00:16:29,040 --> 00:16:33,200
the theory of kind of what you know things like gases with lots of molecules how that works

173
00:16:33,200 --> 00:16:37,520
the second law of thermodynamics things like that that's one bucket the second bucket uh

174
00:16:37,520 --> 00:16:41,920
is general relativity the theory of gravity and the structure of spacetime and the third bucket

175
00:16:41,920 --> 00:16:47,280
is quantum mechanics and the theory of very small things so to speak so those are the sort of the

176
00:16:47,520 --> 00:16:53,840
um the main uh there was sort of a big big advance a hundred years ago or so now in those

177
00:16:53,840 --> 00:17:00,960
kinds of areas um the question is okay so what's for example what's underneath those things are

178
00:17:00,960 --> 00:17:06,000
those just sort of arbitrary wheel in features of the universe or are they derivable in some way

179
00:17:06,720 --> 00:17:13,200
so this kind of seeing things like rule 30 makes one think well maybe there might be some very

180
00:17:13,280 --> 00:17:21,760
simple rule that might be able to to explain what's going on well back in the 1990s I started

181
00:17:21,760 --> 00:17:27,600
thinking about this made quite a bit of progress actually but the time I suppose physics was in a

182
00:17:27,600 --> 00:17:33,120
very um high self-esteem state and it was like string theory is going to solve it you don't

183
00:17:33,120 --> 00:17:39,760
need anything else so I worked on other things which turned out to be rather productive and

184
00:17:39,840 --> 00:17:45,120
then about four years ago now came back to this question having figured out a lot of other things

185
00:17:45,120 --> 00:17:50,080
in the intervening years and having built this big stack of technology I mean in in the the kind

186
00:17:50,080 --> 00:17:54,800
of rough summary of my life is that I've kind of alternated between doing basic science and

187
00:17:54,800 --> 00:17:59,840
developing tools and technology and it's been a pretty pretty good journey I would say because

188
00:17:59,840 --> 00:18:05,200
you know you do basic science it shows you what is conceivable to build in technology you then

189
00:18:05,200 --> 00:18:10,800
build the technology that creates tools that let you do more basic science and I managed to

190
00:18:10,800 --> 00:18:16,400
iterate this about five times so far in my life and it's built a pretty big tower and from the

191
00:18:16,400 --> 00:18:21,920
top of that tower we can now see some pretty neat basic science that's been really exciting to me

192
00:18:21,920 --> 00:18:25,680
in the last few years and let me let me tell you a little bit about that and then I'm going to

193
00:18:25,680 --> 00:18:30,400
tell you a bit about sort of how that connects to the practical world of of kind of computational

194
00:18:30,400 --> 00:18:37,520
x for all x and we'll talk about AI and and whatever else we can we can fit in there all right so

195
00:18:37,520 --> 00:18:42,240
let's talk about the fundamental theory of physics and what's underneath the stuff that

196
00:18:42,960 --> 00:18:48,960
we experience in the world let's see I probably have a nice visual summary here which I can perhaps use

197
00:18:52,720 --> 00:18:58,480
so this is sort of a visual summary of our physics project and as is often the case in

198
00:18:58,480 --> 00:19:02,640
science the first thing you have to do to make progress is to realize what was wrong before

199
00:19:03,280 --> 00:19:08,720
and one thing that's been assumed the last couple of thousand years is that space is something

200
00:19:08,720 --> 00:19:13,600
continuous that you can just sort of space is just this thing where you can say I'm going to put

201
00:19:13,600 --> 00:19:17,360
something at this particular coordinate position in space I'm going to put it at some arbitrary

202
00:19:17,360 --> 00:19:23,840
position in space turns out that seems to be wrong that space is not a continuous thing space is

203
00:19:23,840 --> 00:19:29,600
made of something and a hundred years ago people thought this might be the case actually

204
00:19:29,600 --> 00:19:33,360
because a hundred years ago there was a big a little bit more than a hundred years ago so the

205
00:19:33,360 --> 00:19:38,640
big argument was is matter continuous or discrete are there discrete molecules or is matter a

206
00:19:38,640 --> 00:19:45,280
continuous kind of thing same question for light well it turned out round 1900 people realized no

207
00:19:45,280 --> 00:19:52,480
molecules really exist matter is discrete and turns out and light by 1905 and so people realized

208
00:19:52,480 --> 00:19:57,600
photons really exist light is also discrete so you know matters discrete light is discrete what

209
00:19:57,600 --> 00:20:03,360
about space at that time and actually I just recently I just lost a few days actually learned

210
00:20:03,360 --> 00:20:08,640
even another place where sort of most of the physicists so to speak back in the early part of

211
00:20:08,640 --> 00:20:13,200
the 20th century thought that space was discrete but they couldn't make it work in fact Einstein

212
00:20:13,200 --> 00:20:18,240
has a nice quote from 1916 that basically says in the end space will turn out to be discrete

213
00:20:18,240 --> 00:20:23,680
but we don't have the tools necessary to see how that works now a hundred years later

214
00:20:23,680 --> 00:20:29,520
turns out we do so the sort of the first first sort of starting point is the realization that

215
00:20:29,520 --> 00:20:36,320
space is discrete space is made of discrete atoms of space an atom of space has nothing

216
00:20:36,880 --> 00:20:41,360
there's nothing you can say about it other than it's this it's this idealized point this idealized

217
00:20:41,360 --> 00:20:46,080
element the only thing that one can say about it is that it exists and it's unique and distinct

218
00:20:46,080 --> 00:20:51,440
from other atoms of space and then what can you say about the atoms of space well all you can

219
00:20:51,440 --> 00:20:55,200
say is how they're related to each other you can kind of think of the friend network of the

220
00:20:55,200 --> 00:21:02,240
atoms of space so you're kind of saying what and that's all you know about these things there's

221
00:21:02,240 --> 00:21:06,320
not they're not placed in any kind of you know you're not saying it's in three dimensions and

222
00:21:06,320 --> 00:21:11,600
you're placing this particular atom here and so on all you know is there's this giant network

223
00:21:11,600 --> 00:21:16,960
that represents the relations between the atoms of space and it's convenient to technically it's

224
00:21:16,960 --> 00:21:23,120
convenient to think about it as a hypergraph and an ordinary graph you have two nodes of the graph

225
00:21:23,120 --> 00:21:27,440
and they're they're connected by an edge and a hypergraph you can have any number of nodes

226
00:21:27,440 --> 00:21:32,080
connected by a hyper edge so it's just technically convenient to think about it as a hypergraph

227
00:21:32,080 --> 00:21:38,560
so the structure of space is this hypergraph of atoms of space and basically everything in the

228
00:21:38,560 --> 00:21:44,400
universe is just part of this giant hypergraph so all the things that we experience the you know the

229
00:21:44,400 --> 00:21:50,400
the electrons the black holes whatever else they're all just features of this giant hypergraph it's

230
00:21:50,400 --> 00:21:54,400
kind of like when you if you think about something like water there's a bunch of molecules bouncing

231
00:21:54,400 --> 00:21:59,520
around but you can have things like eddies vortices in the water which are structures that have some

232
00:21:59,520 --> 00:22:03,920
persistence and it's those kinds of structures that are like the things that we experience like

233
00:22:03,920 --> 00:22:08,960
electrons and so on so okay so the the sort of underlying data structure of the universe is this

234
00:22:08,960 --> 00:22:13,600
giant hypergraph made of atoms of space and by the way it's a it's a feature of doing very

235
00:22:13,600 --> 00:22:18,560
foundational things that there are many equivalent versions of this statement you can talk about it

236
00:22:18,560 --> 00:22:23,200
in terms of higher category theory you can talk about it in different terms but I think the most

237
00:22:23,200 --> 00:22:30,000
concrete version is it's this giant network that is this hypergraph so then what that's sort of the

238
00:22:30,000 --> 00:22:34,960
structure of space the structure of what how does time work by the way one of the things that's sort

239
00:22:34,960 --> 00:22:40,560
of a wrong turn in the 100 years ago was this idea that space and time are the same kind of thing

240
00:22:40,560 --> 00:22:44,800
it was a kind of idea that was introduced sort of as a mathematical convenience and then it

241
00:22:44,800 --> 00:22:49,280
became a thing that everybody explained oh space time is you know space and time are all connected

242
00:22:49,280 --> 00:22:53,680
together like that I don't think it's true time is actually something very different from space it

243
00:22:53,680 --> 00:23:00,080
turns out that the features of relativity theory that connect space and time emerge from the kind

244
00:23:00,080 --> 00:23:05,120
of large-scale properties of the system but they're not the intrinsic way to think about it so what

245
00:23:05,120 --> 00:23:10,800
is time well time is this kind of process of computation just like in that rule 30 cellular

246
00:23:10,800 --> 00:23:16,320
automaton we've got the series of steps those represent the progress of time and computational

247
00:23:16,320 --> 00:23:21,520
irreducibility kind of tells us there's some kind of irreducible thing achieved by the passage of

248
00:23:21,520 --> 00:23:28,160
time and so it is in the system instead of it being updating these cells with neighbors and so on

249
00:23:28,160 --> 00:23:35,840
it's you say we've got this we've got this graph and we have these rules that just say whenever you

250
00:23:35,840 --> 00:23:40,000
see a little piece of graph that looks like this rewrite it to a piece of graph that looks like

251
00:23:40,000 --> 00:23:44,400
that and so you keep doing that over and over again and you build up more and more elaborate

252
00:23:44,400 --> 00:23:48,800
kinds of graphs you get all kinds of complicated structures like this and one question is when

253
00:23:48,800 --> 00:23:53,520
you do that enough times what is the what what you know when you have a graph that has 10 to

254
00:23:53,520 --> 00:23:57,520
the 100 nodes or something in it you've built up this way what is the structure of that graph

255
00:23:58,240 --> 00:24:01,440
well it's a similar question to asking the question if you have a bunch of molecules

256
00:24:01,440 --> 00:24:06,800
bouncing around and they each interact according to some force law and so on what is the large-scale

257
00:24:06,800 --> 00:24:10,800
behavior of a whole collection of molecules and the answer we know in that case is it's like fluid

258
00:24:10,800 --> 00:24:15,040
dynamics that's what happens in something like water you've got these discrete molecules bouncing

259
00:24:15,040 --> 00:24:21,200
around the emergent kind of behavior of the system follows the laws of fluid mechanics

260
00:24:21,200 --> 00:24:25,840
okay so what's the analogous thing here well it's pretty neat because it turns out the analogous

261
00:24:25,840 --> 00:24:31,520
thing here is the thing follows the Einstein equations which are the the the corresponding

262
00:24:31,520 --> 00:24:38,080
laws for the structure of spacetime and so you can then derive from this very simple underlying

263
00:24:38,080 --> 00:24:43,040
set of rules that are about the rewriting of networks the large-scale limits of that with a

264
00:24:43,040 --> 00:24:50,240
bunch of footnotes that are a complicated story you can derive the fact that you get the structure

265
00:24:50,240 --> 00:24:55,280
of spacetime that that we observe now actually one of the things that's tricky is this thing

266
00:24:55,280 --> 00:24:58,720
doesn't have any space in it at the beginning it doesn't even know that it's in three dimensions

267
00:24:58,720 --> 00:25:03,120
for instance dimension is something that's an emergent property of the system where you're

268
00:25:03,120 --> 00:25:07,440
basically saying if you start from a given node in this in this graph and you say what how many

269
00:25:07,440 --> 00:25:11,920
nodes do you get to by going a certain distance on the graph a certain number of steps in the

270
00:25:11,920 --> 00:25:17,600
in the graph let's say you get to some number of nodes and that number of nodes grows like r

271
00:25:17,600 --> 00:25:23,360
the distance to the power d then you can identify that d as the dimension the effective dimension

272
00:25:23,360 --> 00:25:27,920
of the space so one of the consequences of this model is that space won't be precisely three

273
00:25:27,920 --> 00:25:31,760
dimensional there'll actually be dimension fluctuations probably the the beginning of the

274
00:25:31,760 --> 00:25:36,080
universe will be infinite dimensional gradually the universe kind of cools down to being the

275
00:25:36,080 --> 00:25:41,200
three dimensions we observe today and they're probably dimension fluctuations left over from

276
00:25:41,200 --> 00:25:45,760
the other universe and an interesting kind of current sort of can we figure out how this

277
00:25:45,760 --> 00:25:50,560
works question is what actual experimental signatures there are from such a phenomenon

278
00:25:51,440 --> 00:25:57,440
but anyway so so by the way let me just show you um see if I can find this uh yeah let me let me

279
00:25:57,440 --> 00:26:04,080
just show you in this model um this is kind of the uh what the the a version of the beginning

280
00:26:04,080 --> 00:26:09,760
of the universe in this kind of model where so we're we're seeing here the progressive rewriting

281
00:26:09,760 --> 00:26:17,760
of uh kind of this network of atoms of space and uh this is the first very small amount of time

282
00:26:17,760 --> 00:26:23,520
in at least one branch of the beginning of the universe um you have to keep going a long way

283
00:26:23,520 --> 00:26:27,520
to get to our current universe and because of computational irreducibility that's not something

284
00:26:27,520 --> 00:26:37,120
I'm going to be able to do on my laptop however the um uh the thing that um you can set things

285
00:26:37,120 --> 00:26:42,240
up to kind of see what would it be like if you had a much bigger chunk of space and this is an

286
00:26:42,240 --> 00:26:49,760
example yes okay so this is much later in the history of the universe these are two little

287
00:26:49,760 --> 00:26:55,440
black holes and what you'll see here is the the uh that sort of the background here is the structure

288
00:26:55,440 --> 00:27:00,160
of space and space is kind of knitted together by all these little rewrites that are happening if

289
00:27:00,160 --> 00:27:06,240
it wasn't for all these rewrites space would fall apart the space the the fact that there is this

290
00:27:06,480 --> 00:27:11,680
thing we can think of as space that is kind of it has extent is a consequence of the of the

291
00:27:11,680 --> 00:27:15,360
progression through time of all these rewrites but anyway here are two little black holes and you

292
00:27:15,360 --> 00:27:20,880
can see what they do the space is is wiggling around a lot these two little black holes actually

293
00:27:20,880 --> 00:27:26,480
feel the force of gravity um that's just a consequence of these rewrites and then those

294
00:27:26,480 --> 00:27:32,960
black holes merge well that's something that we observe in uh that's gravitational wave detectors

295
00:27:32,960 --> 00:27:37,280
have observed the merger of black holes these are incredibly tiny black holes turns out very

296
00:27:37,280 --> 00:27:41,280
conveniently the behavior of a very tiny black hole is pretty much the same as the behavior of a

297
00:27:41,280 --> 00:27:46,400
very big black hole so we can actually start to see and when when these black holes merge and this

298
00:27:46,400 --> 00:27:51,520
little simulation here um turns out they emit gravitational radiation and we can start seeing

299
00:27:51,520 --> 00:27:55,840
the properties of their gravitational radiation and one of the current frontier questions is

300
00:27:55,840 --> 00:28:01,440
whether there are features of that gravitational radiation that reveal the discreteness of space

301
00:28:01,440 --> 00:28:05,120
and uh I think I think it's it's fairly promising that there are although

302
00:28:05,120 --> 00:28:09,520
whether the magnitude of the the things is such that we can detect it now

303
00:28:09,520 --> 00:28:13,760
versus a hundred years from now we don't know yet that yet but anyway that's kind of

304
00:28:13,760 --> 00:28:19,920
how the the structure of space works in in these these kinds of models another thing to to mention

305
00:28:20,320 --> 00:28:31,680
is uh another so I mentioned this um um the um the the question of um these sort of three big

306
00:28:31,680 --> 00:28:38,160
theories of of 20th century physics statistical mechanics general relativity and quantum mechanics

307
00:28:38,160 --> 00:28:41,840
so we've got what I've been describing is the derivation of general relativity people didn't

308
00:28:41,840 --> 00:28:46,080
think general relativity was something you could derive from something lower level it looks like

309
00:28:46,080 --> 00:28:51,360
it is so the another piece to this is quantum mechanics and sort of the big idea of quantum

310
00:28:51,360 --> 00:28:57,200
mechanics is in classical physics you imagine that definite things happen in the world in

311
00:28:57,200 --> 00:29:01,680
quantum mechanics the big idea is that you know you throw a ball and it doesn't just follow a

312
00:29:01,680 --> 00:29:06,560
single trajectory it follows many possible trajectories and you just get to figure out

313
00:29:06,560 --> 00:29:12,400
what the probability of different things happening is well in our models we actually have no choice

314
00:29:12,400 --> 00:29:17,440
but to have quantum mechanics because what happens is that I talked about the rewriting of these

315
00:29:17,440 --> 00:29:22,000
hypergraphs that represent the structure of the space and everything in it there are many possible

316
00:29:22,000 --> 00:29:26,480
ways these rewritings can happen and the results of that is that you get what we call a multiway

317
00:29:26,480 --> 00:29:31,280
graph that represents all the different possible paths of history there can be different rewritings

318
00:29:31,280 --> 00:29:36,400
that happen there can be that can cause these paths of history to branch they can merge and so on

319
00:29:36,400 --> 00:29:41,440
so kind of the the big thing that happens that you get these multiway graphs multiway graphs are

320
00:29:41,440 --> 00:29:46,240
something pretty interesting that that sort of related to nondeterministic computation but in

321
00:29:46,240 --> 00:29:51,280
nondeterministic computation you tend to just say we're going to pick the one winning branch

322
00:29:51,280 --> 00:29:55,840
in multiway computation you're interested in sort of all the possible things that can happen

323
00:29:55,840 --> 00:30:00,000
and so you know you can kind of think about lots of different kinds of problems in these

324
00:30:00,000 --> 00:30:05,360
terms you know you've got a game like tic-tac-toe or something there are many possible paths you can

325
00:30:05,360 --> 00:30:12,000
follow to in the in the doing of that game and you can kind of look at the complete graph that

326
00:30:12,000 --> 00:30:16,800
you get let's see if I can just pull up a picture of that so you know a typical kind of thing would

327
00:30:16,800 --> 00:30:25,120
be here we go it's kind of a multiway graph that just shows given that you're starting with a blank

328
00:30:25,120 --> 00:30:29,840
tic-tac-toe simplified tic-tac-toe board you get this kind of graph of all these possibilities

329
00:30:29,920 --> 00:30:32,960
you keep going somewhere here probably there's a picture of the actual

330
00:30:33,920 --> 00:30:39,520
game and and what it takes to win the game and so on but that that's an example of a multiway

331
00:30:39,520 --> 00:30:46,640
graph in that particular case for just a the game of tic-tac-toe but the the whole point is

332
00:30:46,640 --> 00:30:51,440
there is also a multiway graph for the whole structure of our universe and the fact that

333
00:30:51,440 --> 00:30:56,400
there are these different paths is is the reason that we get quantum mechanics since it's slightly

334
00:30:56,400 --> 00:31:01,600
more complicated story we have when you when you kind of take a slice across all those paths

335
00:31:01,600 --> 00:31:06,000
you form this kind of space we call it branch real space the space of quantum branches

336
00:31:06,000 --> 00:31:10,720
which is kind of its own kind of space and just as you can think about kind of motion

337
00:31:10,720 --> 00:31:14,000
and physical space you can also think about motion and branch real space

338
00:31:14,000 --> 00:31:19,920
just as you can think about observing physical space we we notice that in physical space well

339
00:31:19,920 --> 00:31:27,360
okay the the we we are at a scale much larger than the atoms of space and so we aggregate when we

340
00:31:27,360 --> 00:31:33,440
observe what physical space is like what we're observing is this this vast aggregation of atoms

341
00:31:33,440 --> 00:31:39,200
of space and that's why space seems to us continuous well something a bit similar happens in quantum

342
00:31:39,200 --> 00:31:45,040
mechanics what happens is that just as we are extended in physical space we are also extended

343
00:31:45,040 --> 00:31:50,640
in branch real space and so a rather strange thing it has to do with the fact that an observer

344
00:31:50,640 --> 00:31:56,560
like us that has that is part of this universe that's branching emerging and so on the question

345
00:31:56,560 --> 00:32:02,000
of quantum mechanics becomes how does a branching brain perceive a branching universe and turns

346
00:32:02,000 --> 00:32:07,760
out that when you untangle those things the answer is quantum mechanics so okay just to

347
00:32:07,760 --> 00:32:15,760
finish on this in this branch for a second the the thing so one of the one of the questions would

348
00:32:15,760 --> 00:32:20,880
be okay so we've got this model for physics and we can say there's an underlying rule which if we

349
00:32:20,880 --> 00:32:26,320
run it for long enough we'll make our universe so the next question is well why did we get that rule

350
00:32:26,320 --> 00:32:32,160
and not another rule and that's it's sort of a you know that's a kind of the the Copernican thing

351
00:32:32,160 --> 00:32:37,040
would be to think there can't be anything special about the rule we got we just have to have some

352
00:32:37,040 --> 00:32:42,880
sort of very arbitrary rule well the the thing that I wondered about this for a while and then

353
00:32:42,880 --> 00:32:49,680
we realized that actually here's what's going on the the structure I mentioned that given a

354
00:32:49,680 --> 00:32:54,240
particular rule you apply to no possible ways and that's what gives you quantum mechanics

355
00:32:54,240 --> 00:32:59,120
but why do you have just one particular rule what happens if you apply all possible rules

356
00:32:59,120 --> 00:33:04,480
and you make something which is the result of taking all possible computational rules

357
00:33:04,480 --> 00:33:09,040
and running them and you can see that different rules will produce different results but then

358
00:33:09,040 --> 00:33:13,600
those results might converge again because when you run different rules again they'll converge to

359
00:33:13,600 --> 00:33:19,440
the same results and so on you get this big complicated entangled mess that is the the result

360
00:33:19,440 --> 00:33:24,080
of running all possible computations so you it's kind of you make this thing which is the

361
00:33:24,080 --> 00:33:29,200
entangled limit of all possible computations it's the thing we call the rule ad and it's kind of the

362
00:33:29,200 --> 00:33:34,080
it's an encapsulated object that represents everything that is computationally possible

363
00:33:34,640 --> 00:33:38,560
and it's a it's a kind of an interesting object because it's a very it's a necessary object it's

364
00:33:38,560 --> 00:33:44,720
not an object that you say oh it happens to exist in this way in that way it's just given the idea

365
00:33:44,720 --> 00:33:50,160
of computation there is just a single object that is this rule ad that represents all possible

366
00:33:50,160 --> 00:33:55,440
the entangled limit of all possible computations okay so so what so how do you make how do you take

367
00:33:55,440 --> 00:34:04,240
that and understand sort of how we we perceive physics and things like this well the key thing

368
00:34:04,800 --> 00:34:09,680
is this realization that we are a certain kind of observer of this rule ad we are it's a little

369
00:34:09,680 --> 00:34:14,560
bit of a brain twisting kind of thing because we are embedded within this rule ad we are part

370
00:34:14,560 --> 00:34:21,920
of this rule ad and we are observing what happens in the rule ad and turns out that there are we

371
00:34:21,920 --> 00:34:26,480
might say well well what we observe to be happening in the rule ad depends on what we are like as

372
00:34:26,480 --> 00:34:31,520
observers so the question is do we how much do we have to know about what we're like as observers

373
00:34:31,520 --> 00:34:36,160
to conclude what about what we will perceive happens in the rule ad okay so it turns out

374
00:34:36,160 --> 00:34:41,760
there are two key assumptions about us as observers both of which are pretty uncontroversial one is

375
00:34:41,760 --> 00:34:47,840
that we are computationally bounded we we can only in our sort of finite minds we can only fit a

376
00:34:47,840 --> 00:34:53,040
certain amount of computational effort it's point one point two is we believe we are persistent in

377
00:34:53,040 --> 00:34:58,640
time even though at every moment in time we might be made of different atoms of space we believe

378
00:34:58,640 --> 00:35:04,480
that we have a single thread of experience that continues throughout time so those are two assumptions

379
00:35:04,480 --> 00:35:08,640
so it turns out this is sort of the big result of the last few years it turns out those two

380
00:35:08,640 --> 00:35:15,760
assumptions are sufficient to derive the three big theories of 20th century physics so given this

381
00:35:15,760 --> 00:35:21,200
idea of the rule ad if you say what does an observer with those characteristics perceive in this big

382
00:35:21,200 --> 00:35:26,720
messy rule ad of all possible computations it turns out that an observer with those characteristics

383
00:35:26,720 --> 00:35:32,080
necessarily perceives actually the second rule of thermodynamics general relativity and quantum

384
00:35:32,080 --> 00:35:38,080
mechanics that's kind of a very interesting kind of I suppose philosophical moment that these are

385
00:35:38,080 --> 00:35:42,400
things which seemed like they were just features of the universe that happen to be the way they are

386
00:35:42,400 --> 00:35:47,920
but it isn't true that there instead there is this kind of necessary formal structure

387
00:35:47,920 --> 00:35:53,680
which for observers like us if we were not like we are if we were some kind of alien observers

388
00:35:53,680 --> 00:35:59,200
with different characteristics we would perceive a different physics but given that we are observers

389
00:36:00,000 --> 00:36:04,400
of the kind that we are we necessarily perceive these features of the physical world

390
00:36:04,400 --> 00:36:11,200
so that's that's kind of a that's a that's a sort of a big deal in in in thinking about physics

391
00:36:11,200 --> 00:36:15,520
it also turns out to have implications about mathematics and the kind of nature of mathematics

392
00:36:15,520 --> 00:36:20,400
and so on can talk about those but let me let me talk about some more practical kinds of things so

393
00:36:20,640 --> 00:36:27,520
we we've kind of understood something about this idea of computation that ends up sort of going all

394
00:36:27,520 --> 00:36:32,160
the way down it gives us the machine code for the universe it seems and it tells us things about

395
00:36:32,160 --> 00:36:38,880
sort of the sort of the big picture of what's computationally possible well it's okay so here

396
00:36:38,880 --> 00:36:47,200
we are as just humans hanging out in this rule ad and and and the question is how do we access

397
00:36:47,280 --> 00:36:53,520
this kind of this the the how do we what can we access of computation and so then we have the kind

398
00:36:53,520 --> 00:36:59,600
of interesting situation we are humans who think about things in certain ways and what do we you

399
00:36:59,600 --> 00:37:06,160
know how can we make use of this kind of power of computation that sort of is the intrinsic thing

400
00:37:06,160 --> 00:37:11,440
that runs the universe and so on and and what you start realizing is that you need some kind of bridge

401
00:37:11,440 --> 00:37:16,640
between the way we think about things and the sort of ocean of computational possibilities

402
00:37:17,200 --> 00:37:22,320
much of what's out there in the computational universe is stuff that is completely incomprehensible

403
00:37:22,320 --> 00:37:26,960
to us it's stuff where we can run all these cellular automata they make all these patterns

404
00:37:26,960 --> 00:37:30,800
we say we don't really know what the significance of this is they're not really connected to anything

405
00:37:30,800 --> 00:37:37,840
we know about most of the computational universe is completely alien to us and so the the question

406
00:37:37,840 --> 00:37:43,840
really becomes sort of how do we characterize the parts of the computational universe that we humans

407
00:37:43,840 --> 00:37:48,640
can connect to his sort of perhaps an interesting experiment I can show you something here this

408
00:37:48,640 --> 00:37:58,800
is looking with genitive AI um just looking at um the uh yeah this is um this is looking at um

409
00:37:58,800 --> 00:38:04,800
sort of a very tiny slice of the rule ad that has been set up to be aligned with the way we humans

410
00:38:04,800 --> 00:38:10,080
think about things because it's been it's a genitive AI trained on a few billion images

411
00:38:10,080 --> 00:38:14,080
and so what we're asking is if we look out into that sort of space of possible

412
00:38:15,440 --> 00:38:20,080
possible things that we can think of as a tiny slice of the rule yard what's out there and so we

413
00:38:20,080 --> 00:38:26,800
we said okay let's let's make a we initially say we're going to look for a cat and a party hat

414
00:38:27,360 --> 00:38:35,520
and um somewhere at the beginning there was um was a part of um of this uh of the space that

415
00:38:35,600 --> 00:38:41,040
has a nice cat there the question is what else is out there in the space if you go away from the

416
00:38:41,040 --> 00:38:46,240
cat and the party hat you go out um and you're you're going out into sort of this space of

417
00:38:46,240 --> 00:38:50,640
computational possibilities and what you find is there's sort of a cat island where things are

418
00:38:50,640 --> 00:38:57,840
sort of identifiably cat like but then most of sort of this space consists of things that

419
00:38:57,840 --> 00:39:01,920
well there's some definite structure there but it's not clear what we humans would say about

420
00:39:01,920 --> 00:39:07,520
that structure we don't really have a a way of thinking about that we think about so we can kind

421
00:39:07,520 --> 00:39:13,760
of think about think about these sort of blobs of of possibility that are concepts of things we've

422
00:39:13,760 --> 00:39:19,920
given human names to we've given words to their concepts we know about and then there's this vast

423
00:39:19,920 --> 00:39:25,680
area of kind of inter concept space kind of analogous to interstellar space where it's something

424
00:39:25,680 --> 00:39:32,320
that we haven't you know we humans have not conceived we don't have a way to that we brought

425
00:39:32,320 --> 00:39:38,000
that into our kind of world and so you might ask well what fraction of space is inter concept space

426
00:39:38,000 --> 00:39:44,480
in this very simple example that's a very sort of optimistic case one part and ten to the six

427
00:39:44,480 --> 00:39:51,520
hundred of the space is space that we understand uh the rest of it is all inter concept space

428
00:39:51,520 --> 00:39:56,640
concepts that we humans have not yet reached so you can kind of think about the the progress of

429
00:39:56,640 --> 00:40:02,000
of our uh intellect and science and so on as being this kind of colonization of what we call

430
00:40:02,000 --> 00:40:08,320
rural space of kind of gradually expanding in the domain of what we consider what we have concepts

431
00:40:08,320 --> 00:40:15,040
to describe it's some uh kind of a okay to make a slightly bizarre comment but but one thing you

432
00:40:15,040 --> 00:40:19,680
might wonder about is okay in the future of science and everything maybe the future of

433
00:40:19,680 --> 00:40:24,480
science is we expand in in rural space and we we eventually expand so that we fill all of rural

434
00:40:24,480 --> 00:40:29,360
space it turns out one should be careful what one wishes for because one feature of that

435
00:40:29,360 --> 00:40:35,760
is that in in in a sense went by by the time you have a mind that is that big it is not a coherent

436
00:40:35,760 --> 00:40:41,680
mind anymore and for it to coherently exist it has to be something that is limited in rural

437
00:40:41,680 --> 00:40:46,880
space by the time it fills the whole rulliard in no meaningful sense does it coherently exist

438
00:40:46,880 --> 00:40:53,840
so in a sense when you when you if you expand too far uh you you you no longer can can describe

439
00:40:53,840 --> 00:41:01,680
yourself as as coherently existing so okay so so there's there's this um uh this is kind of what

440
00:41:01,680 --> 00:41:07,920
what it looks like out in this sort of human aligned uh inter concept space this is this is

441
00:41:07,920 --> 00:41:14,400
kind of what what it looks like just in sort of out in the rulliard looking at different possible

442
00:41:14,400 --> 00:41:20,160
behaviors these are just cellular automata um but we can say well when we look at these things

443
00:41:20,160 --> 00:41:25,360
what are these things how do we describe them are they things that are relevant to to us yet do we

444
00:41:25,360 --> 00:41:30,720
yet have words for these things and the answer is typically no we've we've explored only this tiny

445
00:41:30,720 --> 00:41:36,320
slice okay but so what can we do with the slice that we're exploring well the big thing that i've

446
00:41:36,320 --> 00:41:42,640
spent much of my life actually doing is trying to build kind of a a a thing that is a bridge between

447
00:41:42,640 --> 00:41:48,880
the way we think about things and what's computationally possible and the way that what we what we

448
00:41:48,880 --> 00:41:54,000
need to do is to take the things that we care about that we think about and formalize them so we

449
00:41:54,000 --> 00:41:59,200
represent them computationally so that we can make use of kind of the power that exists in this

450
00:41:59,200 --> 00:42:04,400
computational universe and so that has been the the big effort to build what we call wolfman language

451
00:42:05,120 --> 00:42:12,560
um and sort of the goal there is is to be able to represent sort of everything in the world

452
00:42:12,560 --> 00:42:17,600
in a computational kind of way so i mean if i take um uh well let's just let's just say you

453
00:42:17,600 --> 00:42:24,400
know i have um i don't know some uh let's let's say i make some graph uh we can we can represent

454
00:42:24,400 --> 00:42:30,000
some random graph as as a computational kind of thing we could say i don't know let's work out

455
00:42:30,720 --> 00:42:35,920
let's just do some computation on that and the um uh um

456
00:42:37,760 --> 00:42:42,560
well we could take um uh we could take some let's see if i can um take an image here

457
00:42:43,600 --> 00:42:52,560
ah what if i do that um let's see there we go well terrible image but um we could we could say

458
00:42:52,560 --> 00:42:59,680
something like um uh well let's just say something like edge detect that image um or we could say

459
00:43:00,000 --> 00:43:06,400
we want it to be a little bit more optimistic let's see um how about we do this how about we say

460
00:43:09,520 --> 00:43:11,040
let's do this um

461
00:43:13,760 --> 00:43:19,600
let's take that image and let's say we want to just say identify what's in that image but let's

462
00:43:19,600 --> 00:43:26,480
let's run it this way so we're running some neural net we can look at um uh we may have to load in

463
00:43:26,480 --> 00:43:33,200
oh what earth is that i have no idea what that is um it's the back it's the backdrop okay

464
00:43:36,560 --> 00:43:40,960
okay let's see well let's let's see what happens if we say what's the word definition of that thing

465
00:43:42,560 --> 00:43:52,960
ha okay the um but it's kind of interesting to um uh we can look here if we say uh well that that

466
00:43:52,960 --> 00:44:00,000
thing will just be some neural net that um uh we can look at it's all the all the all the nasty

467
00:44:00,000 --> 00:44:06,800
innards of it we could for example just say let's just take the first uh five levels of the neural

468
00:44:06,800 --> 00:44:16,800
net or something and apply that to this picture um and uh and then maybe we can say uh make images

469
00:44:16,800 --> 00:44:22,640
out of those okay so that's kind of the the uh inside the mind of the neural net um what it's

470
00:44:22,640 --> 00:44:28,080
thinking about maybe we can just say let's let's just do this let's say make a feature space plot

471
00:44:28,080 --> 00:44:33,440
of those let's see if we can not very exciting it just decided that there were two clumps of

472
00:44:33,440 --> 00:44:37,280
things that was thinking about one seemed like they're mostly white one seems like they're mostly

473
00:44:37,280 --> 00:44:43,840
black so it goes um but but anyway the kind of the concept here is to make a computational

474
00:44:43,840 --> 00:44:49,760
language that can formalize the things we like to think about in computational terms

475
00:44:49,760 --> 00:44:55,200
so that we can do things uh so that we can use sort of the power of computation to operate on

476
00:44:55,200 --> 00:45:00,560
those kinds of things so for example there's the part of the the story is just knowing a lot about

477
00:45:00,560 --> 00:45:05,440
the world so we might say you know that's there's a list of words in English maybe we can say let's

478
00:45:05,440 --> 00:45:11,760
just take the first letter of each word and let's make a word cloud of those first letters

479
00:45:12,320 --> 00:45:17,520
and um this will give us oops what did I just do word list oh that's not what I want to do I wanted

480
00:45:17,520 --> 00:45:23,520
to say take just the first letters there okay there we go and so that gives us for for English

481
00:45:23,520 --> 00:45:27,280
the uh the sort of word cloud of first letters maybe we can just for fun let's try doing

482
00:45:28,080 --> 00:45:32,160
Spanish for example I don't know whether anybody knows what the what what part of a dictionary

483
00:45:32,160 --> 00:45:39,840
is most thumbed in the Spanish dictionary this predicts it will be C um the uh so um in any case

484
00:45:39,840 --> 00:45:45,600
the the kind of the goal here is to is to is to know things about the world so for example we could

485
00:45:45,600 --> 00:45:52,880
say um I don't know what we let's see what uh let's see what we what we know about Northeastern

486
00:45:52,880 --> 00:45:58,480
University as a as a thing let's see let's look at what properties we might know about Northeastern

487
00:45:58,480 --> 00:46:03,680
University okay let's say somebody was just telling me this number so let me just see what what it

488
00:46:03,680 --> 00:46:10,720
thinks that number is um okay let's see whether we know what that is as a function of time uh

489
00:46:12,400 --> 00:46:21,680
I don't know whether we will but um okay we have something some information here um okay so that

490
00:46:21,680 --> 00:46:27,920
claims to be the um the plot of the number of students as a function of time at Northeastern um

491
00:46:27,920 --> 00:46:33,200
but uh or we could we could say something like let's let's make a um uh I don't know where it

492
00:46:33,200 --> 00:46:40,080
thinks the computer is right now but maybe plausibly here I don't know we'll find out um let's say uh

493
00:46:43,760 --> 00:46:48,560
the somebody's figuring out why the why the plot looks like that

494
00:46:48,560 --> 00:46:54,160
I um it's um um the uh

495
00:46:56,960 --> 00:47:03,520
so let's see whether this um okay so that's just showing us a geodesk of 10 miles around where

496
00:47:03,520 --> 00:47:09,040
we are that's maybe maybe we can just make something just for fun that um has a uh uh

497
00:47:09,200 --> 00:47:19,920
let's say 10 to the 10 to the n miles and let's make a table of these

498
00:47:20,640 --> 00:47:29,280
with um n going from let's say 10th of a mile to let's let's try this so this should make a

499
00:47:29,280 --> 00:47:36,240
series of of kind of um there we go so this is um that's from from very nearby where it thinks the

500
00:47:36,240 --> 00:47:42,160
computer is to very far away where the um the the disk extends to most of the earth actually we

501
00:47:42,160 --> 00:47:49,680
could make that look better by saying let's say geo projection um would be I don't know what's a

502
00:47:49,680 --> 00:47:54,640
good example lambadas might be a good one so it won't make any difference to the local so what we

503
00:47:54,640 --> 00:47:59,520
get locally but it will make a difference when we get to um a larger part of the earth we should

504
00:47:59,520 --> 00:48:08,000
see something more sensible here it's probably it has to recompute all these projections of the

505
00:48:08,000 --> 00:48:13,520
earth so it might take it a little while but in any case the the kind of the big idea is just

506
00:48:13,520 --> 00:48:21,680
to be able to there we go um so that's kind of interesting the the um uh so you know the big

507
00:48:21,680 --> 00:48:28,640
idea is just to know about and to represent the kinds of things that we humans care about

508
00:48:28,720 --> 00:48:33,200
to represent them in computational terms and kind of this has been my effort over the last 40 years

509
00:48:33,200 --> 00:48:39,440
or so is to progressively represent more and more things about the world in this formal

510
00:48:39,440 --> 00:48:44,400
computational way so that we can compute from about them and this is something that's pretty

511
00:48:44,400 --> 00:48:50,320
important because it's something that it gives you this we have now this language for representing

512
00:48:50,320 --> 00:48:55,680
things computationally and if you think about sort of history the um the the a thing a bit like this

513
00:48:55,680 --> 00:49:01,040
that happened before maybe 500 years ago people had the idea of making notation for mathematics

514
00:49:01,040 --> 00:49:05,600
there had been kind of mathematics just described in words and then there started to be notation

515
00:49:05,600 --> 00:49:09,680
for mathematics plus signs and equal signs and things like that and then people started to be

516
00:49:09,680 --> 00:49:15,280
able to talk about mathematics in a streamlined way and then algebra got invented and then calculus

517
00:49:15,280 --> 00:49:20,880
and so on and that kind of spawned the possibility of all of the modern mathematical sciences and so

518
00:49:20,880 --> 00:49:27,600
kind of the question for today is what can we do with this idea of computation how can we use that

519
00:49:28,160 --> 00:49:34,480
in the world and what we realize is for any field x in an archaeology to zoology to whatever else

520
00:49:35,120 --> 00:49:40,480
there is a computational x that you could build which essentially takes the questions of that field

521
00:49:40,480 --> 00:49:45,520
and presents them thinks about them in a kind of formalized computational way and kind of my

522
00:49:45,520 --> 00:49:50,960
goal over the last 40 years has been to build kind of the notation the language to represent

523
00:49:50,960 --> 00:49:56,560
things computationally in the world and and that's um uh it's kind of I think the the thing that we've

524
00:49:56,560 --> 00:50:01,600
achieved at this point is is sort of having made this kind of full-scale computational language

525
00:50:01,600 --> 00:50:06,480
that allows us to represent things in the world computationally and I see you you have a microphone

526
00:50:06,480 --> 00:50:11,840
there and that this is a I could I could talk about I didn't even talk really about AI yet but I can

527
00:50:11,920 --> 00:50:15,600
talk a little bit about let me let me just say a couple of things about that and then then we'll

528
00:50:15,600 --> 00:50:20,320
then we'll move on to then maybe we can we can chat about it some more I mean I think the the

529
00:50:20,320 --> 00:50:25,680
one of the things that's been an interesting thing last year or so is that um uh the um

530
00:50:28,240 --> 00:50:34,800
we used to just have human users mostly um you know millions of people every day use many millions

531
00:50:34,800 --> 00:50:40,800
of people use our stuff as humans but now we have a new kind of user we also have AI's as users

532
00:50:40,800 --> 00:50:53,200
we also have LLMs that are writing um uh that are that are um are um using our technology here's

533
00:50:53,200 --> 00:50:59,200
an example this is a chat notebook and we can say something like um this is a you can say well

534
00:50:59,200 --> 00:51:12,560
let's make um I don't know make a circle that's half green and half blue and that this is now um

535
00:51:12,560 --> 00:51:18,320
let's see what what happens here I have no idea what this is going to do but um this might write

536
00:51:18,320 --> 00:51:25,280
some more from language code it might uh you know what I thought it was going to do usually

537
00:51:25,280 --> 00:51:29,920
tries to do is to actually run that code and see what happens well we can we can run it ourselves

538
00:51:29,920 --> 00:51:34,960
and see what it did it right okay not so bad um in that case it happened to get it right what's

539
00:51:34,960 --> 00:51:39,680
interesting actually is is what you see happening in these chat notebooks um you know we have this

540
00:51:39,680 --> 00:51:46,720
we made this plugin for for uh chat gpt back in when was it that must have been in March I think um

541
00:51:46,720 --> 00:51:53,040
and uh uh that gets pretty widely used but but what's perhaps more interesting is the kind of the

542
00:51:53,040 --> 00:51:58,320
the sort of collaboration that goes on between the human who has some idea what they're trying to do

543
00:51:58,320 --> 00:52:03,600
who try to types it in you get a piece of orphan language code our language is kind of unique in

544
00:52:03,600 --> 00:52:09,520
that it's a language that's intended to be read as well as to be written by humans so it's so the

545
00:52:09,520 --> 00:52:15,440
kind of the loop is typically you the the the thing that is difficult and this is the the part

546
00:52:15,440 --> 00:52:21,680
that is sort of the the education moment is how do you take the thing you might be thinking about

547
00:52:21,680 --> 00:52:27,840
and think about it computationally once you can do that you can begin to explain to the LLM oh this

548
00:52:27,840 --> 00:52:32,960
is roughly what I want to do you explain it in in in human language words it will make a piece of

549
00:52:32,960 --> 00:52:36,960
computational language you can then take that piece of computational language is that what I

550
00:52:36,960 --> 00:52:41,840
wanted I run it I build on it I make it this sort of brick that I start building my whole tower

551
00:52:41,840 --> 00:52:47,280
out of so this is kind of the but the the piece of this that is critical is how do you start

552
00:52:47,280 --> 00:52:52,240
thinking about the world computationally there's not something people teach typically they they

553
00:52:52,240 --> 00:52:56,640
should but they don't it's not what computer science is about computer science a wonderful field

554
00:52:56,640 --> 00:53:03,680
but it's not about that it's you know the thing that is the challenge to reach kind of computational

555
00:53:03,680 --> 00:53:08,480
x for all x which is kind of the future of pretty much every every field at this point because as

556
00:53:08,480 --> 00:53:14,400
I said sort of computation is the formalism is the formalization that we got to figure out how

557
00:53:14,400 --> 00:53:18,880
to do in the last century and it is the thing that is sort of driving the future of these

558
00:53:18,880 --> 00:53:24,240
intellectual areas and so then the question is what you know how do you get to the point where

559
00:53:24,240 --> 00:53:30,560
people can actually sort of conceptualize what they want to do in computational terms how do you

560
00:53:30,560 --> 00:53:35,040
how do you teach this kind of the how to think about things computationally it's not what people

561
00:53:35,040 --> 00:53:40,640
have usually done and actually I guess my project that I'm in the process of doing right now is

562
00:53:40,640 --> 00:53:45,760
actually just about to get started on is because it seems like I'm I'm in the strange position of

563
00:53:45,760 --> 00:53:49,840
being sort of having a responsibility to do this to sort of define what does it look like what is

564
00:53:49,840 --> 00:53:56,160
this kind of basic course that the people should teach very broadly about sort of how to think

565
00:53:56,160 --> 00:54:01,280
about the world computationally the mechanics of how you actually do computation well if people like

566
00:54:01,280 --> 00:54:06,560
like us have done our job most of that has been automated away the LLMs automate even another

567
00:54:06,640 --> 00:54:11,200
stage of that away but what's what's really at issue is how do you think about the world

568
00:54:11,200 --> 00:54:16,960
computationally and and sort of how do you how do you conceptualize that one last thing about AI

569
00:54:16,960 --> 00:54:23,360
the the we can talk about I wrote this whole explainer of chat GPT that some of you might have

570
00:54:23,360 --> 00:54:30,720
seen that that sort of led me to kind of a theory about what's actually going on in LLMs we can

571
00:54:30,720 --> 00:54:34,320
talk about that if people are interested in it but I think one of the things is sort of the

572
00:54:34,320 --> 00:54:38,480
future of AI and people say you know our AI is going to take over the world and what's going to

573
00:54:38,480 --> 00:54:47,760
happen and so on the the question of what does an AI want to do well you know an AI that's been

574
00:54:47,760 --> 00:54:52,400
aligned with what humans you know it's been trained from what humans do that's one thing

575
00:54:52,400 --> 00:54:58,880
but sort of an AI left to its own devices what does it do what you realize is AI's are creatures

576
00:54:58,880 --> 00:55:04,080
of the computational universe and there's just a lot of computational universe out there that AI

577
00:55:04,080 --> 00:55:09,360
sort of could explore and so the question then becomes well where do you want to go and that's

578
00:55:09,360 --> 00:55:13,360
not a question that the AI can there's no theoretical answer to that question there's this whole

579
00:55:13,360 --> 00:55:17,520
computational universe out there that you can explore the question that is the key question

580
00:55:17,520 --> 00:55:22,880
for us humans is well where do we want to explore what what is the what what direction do we want

581
00:55:22,880 --> 00:55:27,120
to go in this computational universe of possibilities and you know when it comes to

582
00:55:27,120 --> 00:55:32,960
sort of things that get automated by AI the kind of jobs that get automated by AI there are lots of

583
00:55:32,960 --> 00:55:37,360
things where we know where we want to go it's a question of the mechanism of how we get there

584
00:55:37,360 --> 00:55:41,920
and that's automatable but the question of where we actually want to go which of the choices we

585
00:55:41,920 --> 00:55:47,120
want to make that's almost by definition not automatable because that's something that we humans

586
00:55:47,120 --> 00:55:51,920
can arbitrarily choose so anyway that that's a that there's much more to say about this this

587
00:55:51,920 --> 00:55:58,400
topic and and so on but that that's just a few a few things maybe we can chat about all right well

588
00:55:58,400 --> 00:56:11,600
I should stop there thank you very much and and now we will go to the fireside chat with Stephen

589
00:56:11,600 --> 00:56:17,680
and Sam Fayad the secretary director of the institute and at the end we will have a Q&A with

590
00:56:17,680 --> 00:56:23,840
all the audience welcome everyone to to this portion where we are going to take audience

591
00:56:23,840 --> 00:56:30,000
questions and what we'll try to do is alternate between audience and some fireside chat questions

592
00:56:41,680 --> 00:56:48,240
issues that that came up late so let me let me start maybe with a question from me which is

593
00:56:49,040 --> 00:56:55,680
you know pretty practical over a decade ago maybe almost 15 years ago you launched

594
00:56:55,680 --> 00:57:02,720
well from alpha and it was a I mean in my opinion it was a very effective amazing semantic search

595
00:57:02,720 --> 00:57:10,080
based you know approach that's much more knowledge based than what we see today with with the LLMs

596
00:57:10,800 --> 00:57:17,680
and the autocomplete and all of that I would say one thing it's not about searching what what we

597
00:57:17,760 --> 00:57:22,880
what wolf mouth it does is it takes you know the natural language people the weird natural language

598
00:57:22,880 --> 00:57:28,880
people set up as questions and it converts that into computational language and then it tries to

599
00:57:28,880 --> 00:57:33,760
compute answers so there's no you know what one might think is there's the web out there and there's

600
00:57:33,760 --> 00:57:38,320
stuff to search for that's not what we're doing right what we've what we've tried to do is to

601
00:57:38,320 --> 00:57:43,680
sort of collect and curate all of this knowledge implement the actual algorithms and methods and

602
00:57:43,680 --> 00:57:49,360
so on and then compute and the thing that is sort of the interface to the humans is take that

603
00:57:50,160 --> 00:57:55,280
piece of natural language somebody types in and or says to a phone or whatever else it is

604
00:57:55,280 --> 00:58:00,000
and convert that into this precise computational language and then compute answers so that that's

605
00:58:00,000 --> 00:58:06,160
that's kind of that's the way I know and that's fair but there you used kind of what what we would

606
00:58:06,160 --> 00:58:11,840
consider concepts that are familiar to humans the way we think about the world yes versus

607
00:58:12,720 --> 00:58:18,320
today's other lambs are just building building weights now what happens for the autocomplete

608
00:58:18,320 --> 00:58:27,760
but what happened is somehow chat gpt took off much more than wolfram alpha any any kind of

609
00:58:27,760 --> 00:58:34,320
thinking or explanation as to why that but 14 years later the world's a bit different but I think

610
00:58:34,320 --> 00:58:41,120
also you know the set of people who want to write essays is a different set from the set of people

611
00:58:41,120 --> 00:58:47,120
who want to answer factual questions I mean you know wolf mouth are pretty widely used in

612
00:58:47,120 --> 00:58:51,120
intelligent assistance the thing that's more interesting is why did the intelligence assistants

613
00:58:51,120 --> 00:58:57,440
die just before LLMs happened and that's really more of a business question than it is a question

614
00:58:57,440 --> 00:59:03,120
of a business and execution question more than it is a question of technology I think but I think

615
00:59:03,120 --> 00:59:14,160
the you know what's what's the goal of alpha has been to to you know to take the question the

616
00:59:14,160 --> 00:59:19,200
things that questions that are answerable from factual questions about the world that are

617
00:59:19,200 --> 00:59:23,600
answerable that we can compute answers to and make it automatic to make those to do those

618
00:59:23,600 --> 00:59:30,000
computations and that's been a very successful thing now the combination of that LLMs are doing

619
00:59:30,000 --> 00:59:35,040
something different LLMs are doing things like writing essays and summarizing text and so on

620
00:59:35,040 --> 00:59:43,920
and I think it's worth remembering that you know LLMs took four billion web pages and you know

621
00:59:43,920 --> 00:59:50,560
what an LLM is doing is to give you something is to continue up from a prompt in a way that is

622
00:59:50,560 --> 00:59:58,160
typical of what the LLM read from the web and that's and now what's interesting is that a certain

623
00:59:58,160 --> 01:00:03,120
you know that things like logic were sort of extracted by the LLMs as a certain amount of

624
01:00:04,080 --> 01:00:09,360
factual information that the LLM sort of thinks it knows now the LLM will will regularly just

625
01:00:09,360 --> 01:00:13,920
make up stuff that's kind of roughly like what's out there might be like what some student might

626
01:00:13,920 --> 01:00:18,720
write as a as a well I'm going to write something is roughly right but it's actually total nonsense

627
01:00:19,600 --> 01:00:25,280
the the combination of the LLMs with computational system with Wolf-Malpha for example is pretty

628
01:00:25,280 --> 01:00:32,160
interesting the challenge is you know so back in well in last December actually talking to the

629
01:00:32,160 --> 01:00:38,240
opening AI guys and so on we figured out yes you know Wolf-Malpha has this is very convenient because

630
01:00:38,240 --> 01:00:43,600
there's this interface language and that interface language is English that both the LLMs understand

631
01:00:43,600 --> 01:00:49,920
and Wolf-Malpha understands and so if you can get the LLM to formulate its question in a way that is

632
01:00:50,000 --> 01:00:56,160
sort of a a crisp question it can just go ask Wolf-Malpha and so we built that capability

633
01:00:56,160 --> 01:01:00,640
interestingly we also built the capability of having the LLMs synthesize Wolf-Malpha language

634
01:01:00,640 --> 01:01:07,120
code because it had read and we we got a big chunk of training data of kind of you know pieces of

635
01:01:07,120 --> 01:01:11,520
Wolf-Malpha language code it had read a bunch of Wolf-Malpha language code and it was able to

636
01:01:11,520 --> 01:01:17,120
synthesize those things so now if you look at the the the plug-in for chat GPT at least as of

637
01:01:18,000 --> 01:01:22,800
few weeks ago I haven't looked more recently sort of interesting that about half of the what the

638
01:01:22,800 --> 01:01:28,720
LLM constructs is Wolf-Malpha queries and half of it is Wolf-Malpha language code and so and then

639
01:01:28,720 --> 01:01:34,080
it's running those things and it gives back the answer and often it does a good job I mean I would

640
01:01:34,080 --> 01:01:38,640
say that it's kind of it's kind of terrible because you know things like math word problems have been

641
01:01:38,640 --> 01:01:43,920
a long time kind of interesting AI test and there's a case where you know you give it this math word

642
01:01:43,920 --> 01:01:49,840
problem and the LLM correctly decodes it into this lovely piece of Wolf-Malpha language code

643
01:01:49,840 --> 01:01:56,000
we run the code we get an answer and I was writing something about this a few months ago and I'm

644
01:01:56,000 --> 01:02:01,200
about to put this thing in and I think I better actually check that the LLM you know correctly

645
01:02:01,200 --> 01:02:06,400
took the thing from the internal computation and gave the right answer and it didn't so at the very

646
01:02:06,400 --> 01:02:12,080
last stage the thing just you know went crazy I mean it's interesting you know we've been building

647
01:02:12,960 --> 01:02:18,960
an AI tutor for education purposes it's an interesting problem the number one thing to

648
01:02:18,960 --> 01:02:25,600
know about building AI tutors is it's not easy yes and that's but we've been building this and

649
01:02:25,600 --> 01:02:30,800
it's sort of interesting to see these this whole interface between sort of the computation

650
01:02:30,800 --> 01:02:37,280
this hard computation and the layer of kind of linguistic interface that exists that you know

651
01:02:37,280 --> 01:02:41,360
we think we're able I don't know we don't know yet but but it looks promising that we're able to

652
01:02:41,360 --> 01:02:47,040
actually provide that interfaces kind of in a personalized way to students and so on but I

653
01:02:47,040 --> 01:02:52,480
think I I think I diverted your question actually you give a good answer and you anticipated half

654
01:02:52,480 --> 01:02:57,680
my next question I want to switch over to the audience but because you anticipated half my

655
01:02:57,680 --> 01:03:10,400
question so using using the LLM or the chat GPT as kind of an alternative input interface to prompt

656
01:03:10,480 --> 01:03:14,640
alpha is one way to think about them working together is there another way do you think there's

657
01:03:14,640 --> 01:03:23,760
a way to leverage a lot of the knowledge encoded in alpha to help LLMs perform better well look

658
01:03:23,760 --> 01:03:30,880
the the fact that you have a few hundred billion weights that encode three things three kinds of

659
01:03:30,880 --> 01:03:36,560
things kind of the structure of language a certain amount of common sense and the third thing which

660
01:03:36,560 --> 01:03:41,680
is facts about the world facts about the world don't belong there they're an incredibly inefficient

661
01:03:41,680 --> 01:03:48,800
way to encode facts about the world and what will happen but it's not an easy research problem

662
01:03:48,800 --> 01:03:53,920
is to factor out facts about the world from the linguistic interface in the common sense

663
01:03:53,920 --> 01:03:59,280
now you know the fact is that the very interesting thing that's happened is that LLMs have discovered

664
01:03:59,280 --> 01:04:03,120
something that we probably should have discovered a couple thousand years ago which is that human

665
01:04:03,120 --> 01:04:07,840
language has that there's you know we've known about the syntactic structure of human language

666
01:04:07,840 --> 01:04:13,600
kind of the things like you know sentences have noun verb noun in them but what we what we haven't

667
01:04:13,600 --> 01:04:20,240
known is the more sophisticated construction kit that says the sentence you know the moon

668
01:04:21,120 --> 01:04:28,160
eight happiness or something that that sentence isn't a plausibly meaningful sentence except in

669
01:04:28,160 --> 01:04:33,600
some percent of poetic sense and so there's this kind of construction kit that goes beyond

670
01:04:33,600 --> 01:04:38,640
the mere sort of the the syntactic grammar of language there's kind of a semantic grammar

671
01:04:38,640 --> 01:04:44,560
of language I think that the LLMs kind of show us exists and so one question is if you say well

672
01:04:44,560 --> 01:04:49,760
can we extract that semantic grammar of language and if we do extract that how much has that actually

673
01:04:49,760 --> 01:04:55,840
removed the you know the LLMs are still useful as a thing to kind of you know right now we say okay

674
01:04:55,840 --> 01:05:02,400
well let's go from LLM you know human language to LLM to computational language but that's

675
01:05:03,040 --> 01:05:08,880
further than going from human language to a semantic grammar to to computational language

676
01:05:08,880 --> 01:05:14,720
and so in fact one thing we've been working on I long wanted to build this kind of what I've

677
01:05:14,720 --> 01:05:18,800
called in the past a semantic discourse language although I hate that name and if somebody can

678
01:05:18,800 --> 01:05:23,520
come up with a better one I'd like it um but that it's kind of a there's been sort of this idea

679
01:05:23,520 --> 01:05:28,400
that's existed well certainly since the 1600s since people like Leibniz and so on of making a

680
01:05:28,400 --> 01:05:34,800
kind of he used to call it the characteristic a universalis kind of universal language to represent

681
01:05:34,800 --> 01:05:41,040
things in some sort of formal way I've been long interested in building such a thing and and now

682
01:05:41,600 --> 01:05:47,200
with help from LLMs it's looking to be actually possible to do that and how that will interface

683
01:05:47,200 --> 01:05:51,760
with LLMs what it will look like in the end my guess is there'll be a layer of kind of neural

684
01:05:51,760 --> 01:06:00,800
neti kind of linguistic user interface going to computation and a semantic language that

685
01:06:01,520 --> 01:06:07,040
that then is the place where kind of the the more um where the crunchy computational stuff

686
01:06:07,040 --> 01:06:12,480
happens I mean the thing to realize about LLMs one thing to realize about LLMs is you know

687
01:06:12,480 --> 01:06:17,360
back in the day before we had any idea of formalization what humans figured out was just what

688
01:06:17,360 --> 01:06:21,920
they could figure out sort of off the top of their head um then we got these ideas of formalization

689
01:06:21,920 --> 01:06:27,760
and we started building these kind of bigger towers what LLMs are naturally able to do is the same

690
01:06:27,760 --> 01:06:31,600
kind of stuff we can do sort of off the top of our head and that's you know the architecture of an

691
01:06:31,600 --> 01:06:38,560
LLM is right now mostly you just say there's this you know you you've you've given a set of tokens

692
01:06:38,560 --> 01:06:44,720
that is what you've said so far you say to the network what should the next token be and it ripples

693
01:06:44,720 --> 01:06:48,880
through a few hundred layers of neural net and out comes the probabilities for what the next token

694
01:06:48,880 --> 01:06:53,200
should be and that's that's the whole story it's just rippling through that that and the only way

695
01:06:53,200 --> 01:06:59,040
that it ever gets to do sort of a more sophisticated computation is is kind of that that the next

696
01:06:59,040 --> 01:07:04,880
token it makes depends on all the previous tokens it made and that's a very thin way I mean there's

697
01:07:04,880 --> 01:07:08,640
a little bit you can you can kind of one fun thing we've been playing with recently it's what you

698
01:07:08,640 --> 01:07:13,920
might call quantum LLMs where instead of just looking at one path of what comes next you look at

699
01:07:13,920 --> 01:07:19,040
this whole whole network of what comes next and you can do things like path finding and that network

700
01:07:19,040 --> 01:07:23,600
so you can say I want to get to this particular thing at the end what is the path that gets me to

701
01:07:23,600 --> 01:07:28,320
that thing at the end and you can kind of think about that in a slightly different way but but

702
01:07:28,320 --> 01:07:33,280
fundamentally that they're just dealing with kind of they're these different things there's this

703
01:07:33,280 --> 01:07:38,720
invention of computation last last hundred years few hundred years which is this kind of different

704
01:07:38,720 --> 01:07:43,840
prong that we can build that is that's different from what sort of ordinary human thinking let

705
01:07:43,840 --> 01:07:51,920
let's one do so any questions from the audience let's start with you thank you for the very

706
01:07:51,920 --> 01:07:57,120
interesting talk my question is about the the part of your talk that had to do with

707
01:07:57,840 --> 01:08:01,280
deriving simple computational rules to explain essentially all the physics

708
01:08:01,520 --> 01:08:10,800
so I guess my my question has to do with the fact that you know we have these I guess you

709
01:08:10,800 --> 01:08:15,680
you call them math right physical principles things like Schrodinger's equation and things like this

710
01:08:15,680 --> 01:08:24,080
that you know quantum mechanics they allow us to make predictions about outcomes of experiments or

711
01:08:24,080 --> 01:08:29,120
you know the procession of a planet or something like this you know it allows us to make useful

712
01:08:29,120 --> 01:08:33,600
predictions about the world and if we have a computational set of rules that allow us to

713
01:08:33,600 --> 01:08:42,240
explain all of physics is there some way to go from those computational rules to mathematical

714
01:08:42,240 --> 01:08:47,200
principles or other sorts of principles that allow us to make useful predictions about the world

715
01:08:47,200 --> 01:08:53,840
that don't require running the computation and and how does that clash with this notion of

716
01:08:53,840 --> 01:08:58,720
computational irreducibility that you mentioned good question okay so slightly complicated I mean

717
01:08:58,960 --> 01:09:03,600
so first thing to say is sort of the main way that we validate that we know what we're talking

718
01:09:03,600 --> 01:09:08,240
about is that we can derive the existing mathematical laws if it wasn't for the fact that we could

719
01:09:08,240 --> 01:09:13,200
derive general relativity we wouldn't imagine that we have a good idea of what the sort of

720
01:09:13,200 --> 01:09:19,040
low-level machine code of spacetime is okay so first thing to say second thing is there are for

721
01:09:19,040 --> 01:09:25,600
example that black hole simulation that I showed actually is it's the method of going from this

722
01:09:25,680 --> 01:09:30,960
underlying discrete spacetime to deduce what happens seems to be at best competitive with

723
01:09:30,960 --> 01:09:34,880
and possibly much better than what people have done in the past which is to start from the

724
01:09:34,880 --> 01:09:39,360
mathematical equations and then kind of discretize them so that they can put them on a computer

725
01:09:39,360 --> 01:09:44,720
this is a you can think about it as a sort of an alternative way to by simulation figure out what's

726
01:09:44,720 --> 01:09:49,600
going to happen in the world and because in fact when you do it sort of mathematically

727
01:09:50,480 --> 01:09:55,440
when people work out black hole mergers they don't work out the pure algebraic math I mean they

728
01:09:55,440 --> 01:10:00,960
typically use mathematical to do a big pile of reduction of the original mathematical structure

729
01:10:00,960 --> 01:10:04,480
and then they turn it into something which is a bunch of partial differential equations

730
01:10:04,480 --> 01:10:08,800
which they discretize and run on a computer so this is this is kind of going the other way

731
01:10:08,800 --> 01:10:14,960
so that's that's one thing to say the the next thing is that the okay the a remarkable thing

732
01:10:14,960 --> 01:10:19,840
about the universe is that anything in it is predictable what you might think is given computational

733
01:10:19,840 --> 01:10:24,720
irreducibility the whole universe is going to be unpredictable one thing about computational

734
01:10:24,720 --> 01:10:29,040
irreducibility is whenever there's computational irreducibility there is always there are always

735
01:10:29,040 --> 01:10:34,160
an infinite number of slices of computational reducibility that exists so in other words

736
01:10:34,160 --> 01:10:39,040
when the whole thing is computationally irreducible you can always find some sub-piece

737
01:10:39,040 --> 01:10:45,360
that is computationally reducible and it's those sub-pieces that make up the laws that we find useful

738
01:10:45,360 --> 01:10:51,040
to be narratives about how the world works and that we kind of exist in and so the really the

739
01:10:51,120 --> 01:10:55,200
story of what's happened with our physics project is there's underlying computational

740
01:10:55,200 --> 01:11:02,400
irreducibility and for observers like us we pick out certain slices of computational reducibility

741
01:11:02,400 --> 01:11:07,360
those slices of computational reducibility correspond to the physical laws we know so one

742
01:11:07,360 --> 01:11:11,920
interesting question would be will there be a time when we found all physical laws or when we've

743
01:11:11,920 --> 01:11:17,280
made all inventions we figured out all of technology the answer is no and the the reason for that is

744
01:11:17,280 --> 01:11:22,480
because of computational irreducibility that we found a particular slice but there will be an

745
01:11:22,480 --> 01:11:27,440
infinite number of other slices and these are other views of the world other things we can say

746
01:11:27,440 --> 01:11:32,560
about the world that aren't that that are different from what we've said so far and in fact you can

747
01:11:32,560 --> 01:11:38,400
think of technology as being these little places where there's this whole amount of computational

748
01:11:38,400 --> 01:11:43,040
irreducibility but there's this little place where we discovered this thing where we could jump ahead

749
01:11:43,040 --> 01:11:47,600
this little little piece of reducibility and that's sort of a piece of technology in a sense that's

750
01:11:47,600 --> 01:11:52,080
kind of the the economic value that we're providing it's kind of like you could take all the components

751
01:11:52,080 --> 01:11:57,120
of an iPhone and they would have a certain value or you can put them all together into this iPhone

752
01:11:57,120 --> 01:12:01,040
and you've got this thing that you can think of as sort of a little piece of computational

753
01:12:01,040 --> 01:12:08,320
reducibility that that provides value economic or or sort of the ability to kind of do something

754
01:12:08,400 --> 01:12:13,120
we wouldn't otherwise be able to do so so the thing to realize is there's this sort of infinite

755
01:12:13,120 --> 01:12:21,200
set of possible laws to discover there's a and that's some that's the big question is which

756
01:12:21,200 --> 01:12:25,840
things do we humans care about there's an infinite set of things out there that could be discovered

757
01:12:25,840 --> 01:12:31,760
there's an infinite set of kind of things we can deduce about the world some of them we find useful

758
01:12:31,760 --> 01:12:37,040
we turn into technology and so on and some we just sort of shrug our shoulders and say we don't know

759
01:12:37,040 --> 01:12:41,760
what we're going to do with that like fluid turbulence is a good example of that for some

760
01:12:41,760 --> 01:12:47,920
purposes at least it's like the fluid behaves randomly what do we do with this it's not so I

761
01:12:47,920 --> 01:12:55,120
mean in terms of our so I mean I think our models provide some kind of almost philosophical framework

762
01:12:55,120 --> 01:13:00,800
for thinking about this kind of this kind of interplay between computational reducibility

763
01:13:00,800 --> 01:13:06,560
computational irreducibility the challenge right now with our models is there are things where they

764
01:13:06,560 --> 01:13:12,880
reproduce existing physics and there are places where they don't there are places where maybe there's

765
01:13:12,880 --> 01:13:17,680
a little corner where you see something that isn't existing physics and that's obviously really

766
01:13:17,680 --> 01:13:22,880
interesting because you can do experiments and find out if that's really true or not and that's

767
01:13:22,880 --> 01:13:28,160
that's it's a big it's it's a challenge because it's just a lot of technical detail of figuring

768
01:13:28,160 --> 01:13:32,240
out okay a photon is propagating through a piece of fractional dimensional space what does that

769
01:13:32,240 --> 01:13:36,960
actually do how does it affect this or that thing that you can measure but that's you know that's

770
01:13:36,960 --> 01:13:44,960
the challenge and and you know I think the as I say the the way to compute things that we have

771
01:13:44,960 --> 01:13:48,960
here it's a bit different from the existing way so for example in this case of general relativity

772
01:13:48,960 --> 01:13:53,680
we're able to actually do a bit better than existing methods same with quantum circuit

773
01:13:53,680 --> 01:14:01,520
optimization actually there's using our multiway system technology somebody who's been working on

774
01:14:01,760 --> 01:14:07,520
project sort of takes quantum circuits compiles them into multiway systems does optimization

775
01:14:07,520 --> 01:14:12,640
at that level and then turns them back into traditional quantum circuits and that won a

776
01:14:12,640 --> 01:14:16,960
competition a few months ago for the best sort of quantum circuit optimization which was kind of fun

777
01:14:18,480 --> 01:14:24,080
we actually Osama have a bunch of questions coming in from our virtual attendees so I will

778
01:14:24,240 --> 01:14:30,960
alternate okay so let me and what you said basically I mean the an interesting observation you made

779
01:14:30,960 --> 01:14:35,920
which is how interesting is that universe of computationally reducible things and how far

780
01:14:35,920 --> 01:14:44,320
can we get but my question is let's get a bit more pedantic a bit so before Sam Altman had his

781
01:14:45,280 --> 01:14:53,680
unfortunate incident with his board open AI was talking about a very near term big breakthrough

782
01:14:53,680 --> 01:14:59,200
in AI whether that's truth or rumor or whatever it doesn't matter I would like to ask you do you

783
01:14:59,200 --> 01:15:06,080
think there's an interesting kind of breakthrough class thing that could happen in the near term

784
01:15:06,080 --> 01:15:12,880
for AI at least in your intuition well I mean okay so look at the history of the AI okay so we've

785
01:15:12,880 --> 01:15:17,680
got you know McCulloch and Pitts wrote their paper in 1943 you know now we've got chat gbt it's

786
01:15:17,680 --> 01:15:21,360
actually pretty similar in architecture to what McCulloch and Pitts I was just looking at the

787
01:15:21,360 --> 01:15:26,080
McCulloch Pitts paper just a couple of days ago it's that they had this idea of what they called

788
01:15:26,080 --> 01:15:33,280
psychons they didn't make it but a lot else in that paper did make it the psychons were units

789
01:15:33,280 --> 01:15:41,200
of psychological activity basically the in any case the the you know I I personally have been a

790
01:15:41,200 --> 01:15:46,720
little bit involved in this business since probably about 1980 I first sort of tried to make neural

791
01:15:46,720 --> 01:15:51,760
nets do something around 1980 and I couldn't get them to do anything very interesting so and then

792
01:15:52,960 --> 01:15:58,320
you know in this you know neural nets were always kind of a sideshow type thing oh there might be

793
01:15:58,320 --> 01:16:03,600
models of brains we don't really know maybe brains don't work that way you know a neural net's useful

794
01:16:03,600 --> 01:16:08,080
as algorithms well they've been used for OCR but you know not clear how useful they are for other

795
01:16:08,080 --> 01:16:14,240
things they were always sort of a mysterious kind of sideshow type type thing and then 2011 kind of

796
01:16:14,240 --> 01:16:20,640
the sort of deep learning breakthrough in image recognition happened almost by accident and there

797
01:16:20,640 --> 01:16:26,160
was this jump in the ability to recognize not just the letters of the alphabet but also a few

798
01:16:26,160 --> 01:16:32,000
thousand other kinds of things in the world of cats and dogs and things like this and you know if

799
01:16:32,000 --> 01:16:37,280
you look at that time I think it reached like 85 percent success from that particular sort of jump

800
01:16:37,280 --> 01:16:43,680
in capability in the in the years since then there's been sort of gradual incremental sort of

801
01:16:43,680 --> 01:16:48,480
improvement in object recognition using neural nets you know the big breakthrough happened and then

802
01:16:48,480 --> 01:16:52,640
there's gradual improvement same things happen in a bunch of other areas whether it's speech to text

803
01:16:53,520 --> 01:17:00,320
other kinds of things the big breakthrough with LLMs that nobody expected was that one went from

804
01:17:00,400 --> 01:17:06,400
language models to just babbled rather uninterestingly to language models that made essays that seemed

805
01:17:06,400 --> 01:17:11,520
human like and that was a you know it's a big big breakthrough and I think we still don't understand

806
01:17:11,520 --> 01:17:18,720
why that really happened how that happened and you know it probably well you can speculate on

807
01:17:18,720 --> 01:17:22,960
on it's a science question it's a very interesting science question we've studied it a bit I can tell

808
01:17:22,960 --> 01:17:28,080
you a few I think this field of LLMs science is a really important area it should be more

809
01:17:28,080 --> 01:17:33,280
populated by physicists actually because that's the that's the domain that has a lot of the the

810
01:17:33,280 --> 01:17:38,080
kind of relevant expertise I mean you know I've been I've been pointing out for a while you know

811
01:17:38,080 --> 01:17:42,160
there's like you increase the temperature you know the chance that you pick a word that isn't the

812
01:17:42,160 --> 01:17:47,760
the most highest probability word to come next increase the temperature it looks like some

813
01:17:47,760 --> 01:17:52,400
student at our summer school this last year found there are two distinct phase transitions one where

814
01:17:52,400 --> 01:17:58,800
the LLM you increase the temperature the LLM stops making sense second it stops making syntactic

815
01:17:58,800 --> 01:18:03,120
sentences the two distinct transitions at definite temperatures why does that happen

816
01:18:03,920 --> 01:18:08,080
there's got to be an answer to that and it has some combination of physics question

817
01:18:08,080 --> 01:18:11,520
and a question about kind of the structure of knowledge and the structure of the way we think

818
01:18:11,520 --> 01:18:16,400
about things it's a it's a it's a thing that's out there and sort of LLM science but anyway what

819
01:18:16,400 --> 01:18:21,840
seems to have happened is there are these moments where there these kind of you know rapid you know

820
01:18:21,840 --> 01:18:26,720
these breakthroughs where things things change and then it's kind of an incremental process and this

821
01:18:26,720 --> 01:18:33,040
is typical of technology and science you know some methodology is you know is comes in some

822
01:18:33,040 --> 01:18:38,160
some something happens the way I see what's what's happened right now with LLMs the you know

823
01:18:38,160 --> 01:18:43,920
they have created the possibility of having rich linguistic interfaces to things and there are

824
01:18:43,920 --> 01:18:48,480
many applications for that and the question of what will be successful and what will not

825
01:18:48,560 --> 01:18:54,000
has to do with how you put a harness around that capability because it's like saying you know it's

826
01:18:54,000 --> 01:18:59,760
it's um uh the the you know the raw capability kind of I think is what it is it will get

827
01:18:59,760 --> 01:19:03,440
incrementally better but it is what it is and it's like a lot of things in machine learning people

828
01:19:03,440 --> 01:19:07,200
say oh I'm going to use machine learning for this or that there's a very simple heuristic

829
01:19:07,200 --> 01:19:11,440
machine learning is going to get you 80 percent maybe it's 90 percent maybe it's 93 percent you

830
01:19:11,440 --> 01:19:17,680
know and Wolf Malfoy we've now got to 98 success and in recognizing our you know natural language

831
01:19:17,680 --> 01:19:23,040
understanding but you know it's some percentage and some fraction of the time is going to fail

832
01:19:23,040 --> 01:19:29,920
if you've got a use case where getting 85 success is a win like you're saying here are possible

833
01:19:29,920 --> 01:19:35,440
search results are any of these what you're interested in then it's a win to have 85 success

834
01:19:35,440 --> 01:19:38,880
if you're trying to you know launch a rocket to the moon and it's got to actually

835
01:19:38,880 --> 01:19:43,520
go in the right trajectory 85 success is probably not going to be good enough yeah

836
01:19:43,520 --> 01:19:48,800
and so it's a bad use case and this is the kind of interplay between what's sort of computational

837
01:19:48,800 --> 01:19:54,080
and what's sort of LLM AI style and I think in terms of sort of the breakthroughs that will

838
01:19:54,080 --> 01:19:59,600
happen I mean I think you know there is more to be done this kind of quantum LLM thing there's

839
01:19:59,600 --> 01:20:05,680
more to be done with kind of where you can where you can go you know the planning aspects of sort

840
01:20:05,680 --> 01:20:10,480
of interfacing what amounts to sort of theorem proving techniques with kind of LLM techniques

841
01:20:10,480 --> 01:20:16,800
I'm not sure how well that's going to work the you know one of the lessons of kind of the

842
01:20:16,800 --> 01:20:22,560
developments of neural nets particularly has been anytime you think you can be clever turns out you

843
01:20:22,560 --> 01:20:28,240
it's not worthwhile and that's a it goes along with what I found in the computational universe

844
01:20:28,240 --> 01:20:32,960
you say oh I know I've got this particular kind of system I know it can't do anything interesting

845
01:20:32,960 --> 01:20:38,160
I can just foresee it can't do anything interesting you run the experiment my little statement to

846
01:20:38,160 --> 01:20:41,920
myself and people who work with me is you know the computational animals are always smarter than

847
01:20:41,920 --> 01:20:47,440
we are we you always it will do something that is completely unexpected and and that's been so

848
01:20:47,440 --> 01:20:52,240
you know I'm not sure whether sort of you know carefully orchestrating these things is ultimately

849
01:20:52,240 --> 01:20:57,920
going to make a difference as a practical matter you know video you know what we've done with text

850
01:20:57,920 --> 01:21:03,040
will be doable with video you can learn a lot on video there's a large corpus of video there'll be a

851
01:21:03,040 --> 01:21:08,080
bunch of there'll be a breakthrough as you know it manages to learn sort of intuitive physics

852
01:21:08,080 --> 01:21:12,240
from videos and things like this certain amount of human behavior stuff from videos probably

853
01:21:13,120 --> 01:21:17,600
and that will be you know that's another thing and and that's but I think what you'll see is

854
01:21:17,600 --> 01:21:23,920
these set of discrete sort of jumps as as different things become possible and you know the training

855
01:21:23,920 --> 01:21:28,480
data in the world is is you know we're kind of running out of that there's I mean there's a there's

856
01:21:28,560 --> 01:21:35,600
about a hundred billion not yet tapped actually we're involved in in possibility of tapping

857
01:21:35,600 --> 01:21:42,720
some more of that of other kinds of material that exists in textual form that hasn't yet been used

858
01:21:42,720 --> 01:21:46,960
for training I don't know how useful that will be I don't know at what point you saturate in terms

859
01:21:46,960 --> 01:21:53,040
of yes we know human language and yes we know common sense but my feeling is that the big value

860
01:21:53,040 --> 01:21:59,600
is coming in the application of of LLMs and so on and figuring out how you put

861
01:21:59,600 --> 01:22:04,960
the right harness around them to make them useful and and that's some and it's kind of in fact the

862
01:22:04,960 --> 01:22:08,720
the kind of you know we built into our language now a bunch of LLM functions

863
01:22:08,720 --> 01:22:13,600
where you can from the computational language you can access the LLM and that's a pretty useful

864
01:22:13,600 --> 01:22:19,280
way to sort of understand and and set up kind of the harness around the LLM to make the LLM do

865
01:22:19,280 --> 01:22:25,040
what it does well and then sort of the the computational structure go around that cool

866
01:22:25,680 --> 01:22:31,760
shall we take a question from online sure so a few a couple hundred people are still here

867
01:22:31,760 --> 01:22:39,040
with you till the very end I'm going to take a question from Michael Carell what's so great

868
01:22:39,040 --> 01:22:45,840
about computation as a metaphor structuring principle for physics or cognition we've been

869
01:22:45,840 --> 01:22:52,080
wrong about metaphors for cognition in the past parentheses the brain as watch telegraph switch

870
01:22:52,080 --> 01:22:59,600
board or even metaphors within computational views what makes us think we've gotten the right one

871
01:22:59,600 --> 01:23:06,080
this time okay so it's a good question I mean I think that the the thing that's interesting

872
01:23:06,800 --> 01:23:15,920
is that this idea of rules for specifying things that idea is pretty much as oldest civilization

873
01:23:16,560 --> 01:23:21,760
and it's you know the question of well is it this particular kind of rule is it the rule that

874
01:23:21,760 --> 01:23:27,280
runs with you know that makes a watch work is it the rule that wakes you know integrals work and

875
01:23:27,280 --> 01:23:35,120
so on those particulars yes those particulars are are specific possibilities the general idea

876
01:23:35,200 --> 01:23:42,320
that something follows some set of rules seems to be a you know a pretty fundamental idea I mean

877
01:23:42,320 --> 01:23:46,960
we're we're kind of stuck with that idea that's a that's a thing if we want to have a theory about

878
01:23:46,960 --> 01:23:53,040
how the world works then the idea that there are rules that determine what happens is something

879
01:23:53,040 --> 01:24:00,000
that we're pretty much stuck with but I think it's a it's a good you know did we did we finally make

880
01:24:00,000 --> 01:24:06,000
it well you know if it turns out the experiments get done and this theory of physics that we built

881
01:24:06,000 --> 01:24:13,360
is validated um it's you know frankly it's it it seems at this point to me at least quite impossible

882
01:24:13,360 --> 01:24:18,960
that it could not be true because too much has fit together for it to you know for it to be off track

883
01:24:18,960 --> 01:24:24,000
but if that happens then we can say well we reached you know in some direction we reached the end

884
01:24:24,000 --> 01:24:29,040
we know our universe is set up this way we can know that we can so another thing to explain

885
01:24:29,680 --> 01:24:36,560
whenever what is natural science you know natural science is this bridge between the universe as it is

886
01:24:37,200 --> 01:24:43,200
and our attempt to have a narrative in our minds for how the universe works so in other words the

887
01:24:43,200 --> 01:24:49,680
universe does what it does and the question is can we have a way of thinking about that that we

888
01:24:49,680 --> 01:24:56,560
can understand and so there may be many ways of thinking about it that that that is more on us

889
01:24:56,560 --> 01:25:01,200
than it is on the universe there may be many ways that aliens could understand the universe

890
01:25:01,200 --> 01:25:06,320
that are not the ways we understand the universe but I think that this idea of of operating according

891
01:25:06,320 --> 01:25:12,560
to rules is this thing that has been you know a feature of the way we have thought about things

892
01:25:12,560 --> 01:25:17,760
from the beginning of our of our history and that that seems like a pretty solid thing if we're

893
01:25:17,760 --> 01:25:23,280
trying to do this thing a bridging between the universe and and the way that the way that we

894
01:25:23,280 --> 01:25:28,640
think about things I want to say one thing about cognition and LLMs okay so so people had wondered

895
01:25:28,640 --> 01:25:34,160
for a long time how do brains work and people said well brains do things that are so sophisticated

896
01:25:34,160 --> 01:25:38,400
that even the laws of physics as we know them aren't sufficient to cover what brains do there

897
01:25:38,400 --> 01:25:45,040
must be some funky extra stuff quantum mechanics whatever else that's going on in brains LLMs

898
01:25:45,040 --> 01:25:49,840
are a very good data point that isn't true because people had said you know in order to do all these

899
01:25:49,920 --> 01:25:53,840
things that we do and all the language and everything like this we got to have all kinds of

900
01:25:53,840 --> 01:25:59,280
stuff we don't understand turns out just this neural net this simple rule-based neural net

901
01:25:59,280 --> 01:26:04,800
it pretty much does it and so you can and in fact what's happened in neuroscience for instances

902
01:26:04,800 --> 01:26:09,440
back in the day my my friends in neuroscience always said well we got these neural nets

903
01:26:09,440 --> 01:26:13,840
but they're not really models of brains they're really some idealization that may be useful for

904
01:26:13,840 --> 01:26:18,880
technology etc etc etc now that neural nets clearly do things that are very brain-like

905
01:26:18,880 --> 01:26:24,880
that that that narrative has reversed and now it's a question of well you know we've got we

906
01:26:24,880 --> 01:26:29,920
know what the core mechanisms are now let's see how we map those into what we can see biologically

907
01:26:32,160 --> 01:26:38,880
is your question quick all right so I don't know if you have a mic but you can I'll repeat your

908
01:26:38,880 --> 01:26:56,400
question just stated for example if we want to learn new interesting structures how can we use

909
01:26:56,400 --> 01:27:01,920
AI to discover them without you know doing simulation and then looking for patterns in those

910
01:27:01,920 --> 01:27:07,280
can we actually use it to find out yeah that's a good question right so the question is using AI

911
01:27:07,280 --> 01:27:11,920
go ahead yeah you know can AI solve science this is a there's a very current question

912
01:27:11,920 --> 01:27:18,240
and that's not a short question but anyway actually we have a project right now that is

913
01:27:18,800 --> 01:27:24,640
you know day by day is is making progress on this question so here's here's what we seem to be finding

914
01:27:24,640 --> 01:27:30,960
not not this this thing hasn't fully landed yet so I don't know the full story but so a question is

915
01:27:30,960 --> 01:27:35,360
what can you predict with another lamp what can another lamp predict I show it pictures of cellular

916
01:27:35,360 --> 01:27:40,160
automata things like this can it you know can it just say this is what's going to happen

917
01:27:40,160 --> 01:27:46,560
can it to what extent can it at least find the pockets of reducibility we don't know fully the

918
01:27:46,560 --> 01:27:50,560
answer to this but there's clearly a boundary we can see there are cases where it just doesn't work

919
01:27:50,560 --> 01:27:55,920
and there are cases where it definitely does work and so the you know this question of can it notice

920
01:27:55,920 --> 01:28:00,960
patterns that we haven't noticed so in protein folding for example there's been a fair degree

921
01:28:00,960 --> 01:28:05,920
of success a little bit less success perhaps than people sometimes imagine but there's been

922
01:28:05,920 --> 01:28:10,720
some success in taking I mean when you if you feed a random sequence of amino acids and say how

923
01:28:10,720 --> 01:28:16,000
does this fold the answer probably won't be right but in things that are at least somewhat close to

924
01:28:16,000 --> 01:28:20,400
proteins that have already been but whose structure is already known there's there's a lot that can

925
01:28:20,400 --> 01:28:26,640
be said and the question is why does that work and the general belief is that it works because

926
01:28:26,640 --> 01:28:32,160
there are aspects of protein structure which are features that we humans have not noticed

927
01:28:32,720 --> 01:28:39,440
that the that the system noticed okay and and so this idea that it's noticing things that we didn't

928
01:28:39,440 --> 01:28:44,480
notice is is going to be a very common thing I mean even even an image identifier that's telling

929
01:28:44,480 --> 01:28:50,080
cats from dogs how does it tell cats from dogs well it's found some feature of those pictures

930
01:28:50,080 --> 01:28:54,480
maybe it's the pointiness of the ears or something it's found some feature that allows it to make

931
01:28:54,480 --> 01:28:59,440
that distinction we don't you know that's not necessarily a feature that we know about it's

932
01:28:59,440 --> 01:29:04,320
also very hard for us to tell what feature it found because we don't have a way to kind of

933
01:29:04,320 --> 01:29:10,800
go inside its mind and convert its way of thinking about things to our ways of thinking about things

934
01:29:10,800 --> 01:29:17,440
so you know in terms of of what can we learn about science so first question is can the LLM

935
01:29:17,440 --> 01:29:22,320
when there is some sort of feature that allows prediction to happen can the LLM find that and

936
01:29:22,320 --> 01:29:26,880
be able to make predictions my guess is that that will be generally somewhat successful

937
01:29:26,880 --> 01:29:33,440
but I think computational irreducibility is kind of a big sort of you know it's a big monster

938
01:29:34,400 --> 01:29:38,320
at the gates there that will prevent certain kinds of things from from being possible but

939
01:29:38,320 --> 01:29:44,560
some things where a human could go and find these these rules yes the LLM might be able to do that

940
01:29:44,560 --> 01:29:52,800
more efficiently more automatically first point so second point is um in well another point is

941
01:29:52,800 --> 01:29:57,840
can the LLM invent something that is a way of explaining to us humans how something works

942
01:29:58,480 --> 01:30:06,240
that's essentially the problem of the AI tutor can the can the system learn enough about us humans

943
01:30:06,240 --> 01:30:11,840
that it can give us an explanation that is useful for us as humans and my guess is there'll be some

944
01:30:11,840 --> 01:30:16,560
success in that in other words if I want to learn some new thing you know how difficult is it to

945
01:30:16,560 --> 01:30:22,720
learn something well you know if I had an AI that knows everything I know for me personally I happen

946
01:30:22,720 --> 01:30:29,600
to be a enthusiast of personal data so there's 50 million words that I've said or written that are

947
01:30:29,600 --> 01:30:37,520
out there so I can train an LLM to be a pretty good you know simulation of me and given that what

948
01:30:38,080 --> 01:30:44,320
you know if I then if I know if the LLM knows or the AI knows what I know and then I say well

949
01:30:44,320 --> 01:30:50,080
I'm today I'm trying to learn about macroeconomics you know I want to you know how do I understand

950
01:30:50,080 --> 01:30:55,360
this there's a reasonable chance that the LLM is going to say well you can relate that to this thing

951
01:30:55,360 --> 01:31:00,400
you know and that thing you know and I have a much easier path to be able to learn those things

952
01:31:00,400 --> 01:31:05,600
it's another thing another thing to say about about what LLMs potentially do one of the

953
01:31:05,600 --> 01:31:10,960
interesting things that LLMs do is they essentially do what one might call sort of a generalization

954
01:31:10,960 --> 01:31:15,520
of statistics that relates to text so normally you know you have a bunch of numbers you say what's

955
01:31:15,520 --> 01:31:19,920
the mean what's the variance of these numbers these kinds of numerical sorts of things but if you've

956
01:31:19,920 --> 01:31:27,920
just got a big lump of text and you say what was the most popular hat style in the 1950s that's a

957
01:31:27,920 --> 01:31:32,480
textual question and that's a question where there's not you know turning that into numbers

958
01:31:32,480 --> 01:31:38,480
is not so easy but LLMs can actually go purely at the textual level and answer a question like that

959
01:31:38,480 --> 01:31:43,920
and so there's this pure sort of textual statistics you might call it it's not really statistics in

960
01:31:43,920 --> 01:31:49,280
the ordinary sense of numbers it's some new kind of thing that can be sort of deduced textually

961
01:31:49,280 --> 01:31:54,320
and I think the the other one thing that will happen is there are these you know one way that

962
01:31:54,320 --> 01:31:59,440
science advances is through these kind of analogies between one field and another to notice that oh

963
01:31:59,520 --> 01:32:04,160
what happens in metamathematics is like what happens in general activity well that's something

964
01:32:04,160 --> 01:32:07,760
that you know I'm very proud of being able to notice that as a human because I know something

965
01:32:07,760 --> 01:32:11,760
about those two fields and I can kind of connect them up but I suspect LLMs are going to be able

966
01:32:11,760 --> 01:32:15,840
to figure those kinds of things out too because they're going to be able to see that the structure

967
01:32:15,840 --> 01:32:22,320
just like they can they can kind of extract logic from just the patterns of sentences so they'll

968
01:32:22,320 --> 01:32:28,560
extract principles from from kind of the noticing that these two different areas work the way they

969
01:32:28,560 --> 01:32:33,840
work but I mean this question of can the LLM invent a formalism that is useful for us humans

970
01:32:33,840 --> 01:32:38,000
that's a that's an interesting good question I'll tell you one little micro data point so you know

971
01:32:38,000 --> 01:32:42,880
I spend a lot of my life doing computational language design and you know we quite often

972
01:32:42,880 --> 01:32:47,520
livestream these things and so on but one of the things that's new in the version of

973
01:32:47,520 --> 01:32:51,680
Wolfman language it's just about to come out is there are new functions that are in there

974
01:32:51,680 --> 01:32:58,080
that were suggested by an LLM so in other words the LLM has looked at all this code it knows what's

975
01:32:58,080 --> 01:33:03,360
people are asking about it's seen what's out there on the web it said oh there's a function

976
01:33:03,360 --> 01:33:08,400
you should have a function called digit sum and I think it even suggested that name and it's a

977
01:33:08,400 --> 01:33:13,680
pretty good idea it's taken sort of the average of what people out there want and yes you can you

978
01:33:13,680 --> 01:33:20,160
can digit sum is something that's a trivial kind of idiom in Wolfman language but it's noticed

979
01:33:20,160 --> 01:33:24,960
that that's an idiom that's a repeated idiom and that's kind of the essence of language design

980
01:33:24,960 --> 01:33:29,360
and so we're able to take that suggestion from LLM by the way in terms of how LLMs will be used

981
01:33:29,360 --> 01:33:34,160
compiling the wisdom of the crowds basically yes yes into I mean what one thing to say about how

982
01:33:34,160 --> 01:33:39,680
LLMs will be used I have a feeling one of the big uses of LLMs will be offline uses people are a

983
01:33:39,680 --> 01:33:44,640
lot of constant people are concentrating on I've got an LLM in the loop and I'm typing something

984
01:33:44,640 --> 01:33:50,240
and an LLM is responding to that for example for our purposes when we do data curation LLMs have

985
01:33:50,240 --> 01:33:57,120
basically speeded up many parts of our data curation pipeline by a matter of two not a hundred

986
01:33:57,120 --> 01:34:02,880
but two and two is worth having but it's not um but I think that these these offline uses where

987
01:34:02,880 --> 01:34:08,880
you use the wisdom of the LLM and then you burn it into a piece of technology that's going to be a

988
01:34:08,880 --> 01:34:14,800
an important thing given given that we'll well over time and before we I'm very bad at short

989
01:34:14,800 --> 01:34:20,640
answers I apologize I'll ask you one last question given your amazing optimism about

990
01:34:20,640 --> 01:34:26,480
the capabilities of LLMs now and you alluded to some of this in in your talk many have claimed

991
01:34:26,480 --> 01:34:36,720
that AI poses a future existential threat to humanity others disagree vehemently what's your

992
01:34:36,720 --> 01:34:43,680
view on this and what do you think are kind of the main AI threats of today but let's let's talk

993
01:34:43,680 --> 01:34:49,360
about the existence yeah yeah right I mean okay so you know more and more things in the world will

994
01:34:49,360 --> 01:34:55,840
be delegated to AIs that's just just as a matter of convenience because things have to happen quickly

995
01:34:55,840 --> 01:35:01,920
you know it's we're going to delegate stuff to AIs and then the question is okay so you know

996
01:35:02,480 --> 01:35:07,280
does something terrible happen as a result of that the thing to understand is there's all

997
01:35:07,280 --> 01:35:12,160
this stuff going on in the in the world of the AIs and the kind of underworld of the AIs the world

998
01:35:12,240 --> 01:35:16,800
is being run by AIs let's say and we say well we don't understand what these AIs are doing that's

999
01:35:16,800 --> 01:35:22,000
terrible how can we possibly exist in a situation where the world is being run by forces we don't

1000
01:35:22,000 --> 01:35:27,040
understand actually we've been there before because that's the situation we're in with nature

1001
01:35:27,040 --> 01:35:32,880
nature is doing a lot of stuff we don't understand and we have managed to find ways to exist we find

1002
01:35:32,880 --> 01:35:40,160
found niches where we can sort of carve out our existence you know within nature and it works just

1003
01:35:40,160 --> 01:35:45,280
fine I mean occasionally bad things happen you know hurricanes develop and bad things happen

1004
01:35:45,280 --> 01:35:50,960
and we don't understand quite why those happen and you know we gradually maybe can do a science of

1005
01:35:51,520 --> 01:35:56,480
you know the atmosphere or something and figure that out with AIs the same is going to happen

1006
01:35:56,480 --> 01:36:00,480
there's going to be lots of stuff that goes on and mostly it's going to be just fine and we

1007
01:36:00,480 --> 01:36:04,640
understand how to live in that niche and occasionally some crazy thing will happen

1008
01:36:04,640 --> 01:36:09,280
and we'll say we better build more science that allows us to understand sort of what's happening

1009
01:36:09,280 --> 01:36:15,200
in the underworld of the AIs so to speak so the first thing to say another thing to say is well is

1010
01:36:15,200 --> 01:36:19,360
there going to be anything for the humans anything left for the humans to do or we have automated

1011
01:36:19,360 --> 01:36:25,600
everything it's by definition we will not automate everything because a lot of what has to be done

1012
01:36:25,600 --> 01:36:31,520
is to figure out what we want to do and there is no sort of intrinsic way that the AI does that now

1013
01:36:31,520 --> 01:36:36,560
there's a practical matter I looked at the last 150 years or so of what what people have done as

1014
01:36:36,560 --> 01:36:42,160
occupations so to speak and here's what you see in you know in the 150 years ago agriculture was the

1015
01:36:42,160 --> 01:36:50,480
biggest chunk of sort of US occupations and then it got automated and so that chunk shrunk and you

1016
01:36:50,480 --> 01:36:54,320
see the same thing happening over and what happened to that chunk what happened to those people well

1017
01:36:54,320 --> 01:36:58,960
the answer is they went into lots of different occupations many of which were enabled by the

1018
01:36:58,960 --> 01:37:04,160
automation of agriculture and the same thing has happened over and over again that's something that

1019
01:37:04,160 --> 01:37:10,080
takes a lot of people to do it it ends up getting automated that thing goes to almost zero people

1020
01:37:10,080 --> 01:37:15,840
but those that the the very automation of that thing enables a bunch of new capabilities

1021
01:37:15,840 --> 01:37:21,120
which then provide a more fragmented kind of story and it's a pretty common thing you see in

1022
01:37:21,120 --> 01:37:25,600
in economies around the world more developed economies are more fragmented in terms of the

1023
01:37:25,600 --> 01:37:31,840
occupations people do and that's that seems to be you know as as you automate more you and what's

1024
01:37:31,840 --> 01:37:37,040
really happening there what's really happening there is the fragmented occupations are sort of

1025
01:37:37,040 --> 01:37:43,200
the frontiers where it's still like what are we going to do in this area and that's something that

1026
01:37:43,200 --> 01:37:48,160
takes humans and it's just like you know right now it's kind of fun to see the new occupations I'm

1027
01:37:48,160 --> 01:37:54,080
always I you know at a company I I often am entertained by the fact that I'll invent some

1028
01:37:54,080 --> 01:37:59,120
new job category of a thing that people have never heard of before like LLM scientist or

1029
01:37:59,200 --> 01:38:06,560
or you know AI psychologist or you know prompt engineer or prompt magician yes yes right exactly

1030
01:38:06,560 --> 01:38:10,240
and these are things that you know it's gosh those have never been and by the way prompt

1031
01:38:10,240 --> 01:38:14,800
engineering is a great use for the you know people say well you're going to be computer

1032
01:38:14,800 --> 01:38:19,120
programmer you're going to do stem type stuff the best prompt engineers are the best expository

1033
01:38:19,120 --> 01:38:26,480
writers so it's a different skill set that and that happens because the LLMs were trained on

1034
01:38:26,480 --> 01:38:30,800
you know the LLMs understand just like other humans understand and so it's sort of not surprising

1035
01:38:30,800 --> 01:38:35,920
that it's expository writing that turns out to be the important skill there so by the way the

1036
01:38:35,920 --> 01:38:40,560
combination of expository writing and computation is writing good computational language that that

1037
01:38:40,560 --> 01:38:46,400
in itself is another occupational area is is computation editors so to speak who can turn

1038
01:38:46,400 --> 01:38:50,720
bad computational language into good computational language and so on there are there are just these

1039
01:38:50,720 --> 01:38:56,960
many different opportunities that that get opened up so I'm you know I think us humans you know

1040
01:38:56,960 --> 01:39:01,360
it's worth realizing if you look at the sort of long arc of history and you say what do people do

1041
01:39:01,360 --> 01:39:06,240
a thousand years ago what do we do what do people even think was worth doing a thousand years ago

1042
01:39:06,240 --> 01:39:11,280
and then what do we do now many of the things we do today didn't look like they were worth doing a

1043
01:39:11,280 --> 01:39:16,240
thousand years ago I mean you know I walk on a treadmill why do you do that it's you know what

1044
01:39:16,240 --> 01:39:22,560
a crazy thing to do it's it so you know I think that's what we'll see and one of the things that's

1045
01:39:22,560 --> 01:39:27,760
funny about understanding history in the future and so on is that you might say oh you know everybody's

1046
01:39:27,760 --> 01:39:32,320
just going to be playing video games that's a terrible outcome looks to be a terrible outcome to me

1047
01:39:32,320 --> 01:39:39,840
right now from from my viewpoint and you know the you know in 2023 or whatever but it's you know to

1048
01:39:39,840 --> 01:39:45,840
the internal impression of the humans so to speak may be a very different story in terms of

1049
01:39:46,320 --> 01:39:51,920
of you know what will happen in terms of of sort of when the ai's run central banks when the ai's

1050
01:39:51,920 --> 01:39:57,600
do all these kinds of things and and many of those things will happen and and at a practical level

1051
01:39:57,600 --> 01:40:04,400
there's a question of what can you do with this how can we make the ai's do things we want to have

1052
01:40:04,400 --> 01:40:08,560
them do and not do the things we don't want to have them do so first question is well what do we

1053
01:40:08,560 --> 01:40:14,400
want to have them do and so you know I've thought a bit I will say this is a for me it's it's an

1054
01:40:14,400 --> 01:40:20,080
unfinished question I mean this first question is okay you're making constitution for the world

1055
01:40:20,080 --> 01:40:24,400
for a country let's say hopefully not for the whole world hopefully for individual countries

1056
01:40:24,400 --> 01:40:31,040
you're making constitution in modern times you've got ai's what do you what are the provisions for

1057
01:40:31,040 --> 01:40:37,120
example can an ai own things does an ai have to have an owner you know how do you decide what to

1058
01:40:37,120 --> 01:40:41,520
do do you have a democracy where people vote and and check boxes or do you have a prompt

1059
01:40:41,520 --> 01:40:46,400
autocracy where everybody writes you know a prompt and it gets fed into an ai and the ai

1060
01:40:46,400 --> 01:40:51,440
kind of decides what to do what do you do how do you think about what's possible and first question

1061
01:40:51,440 --> 01:40:57,600
is what you know is there a you know what do people want and the answer is obviously not everybody

1062
01:40:57,600 --> 01:41:02,720
is going to want the same thing and that's you know so the idea that you know there's the global

1063
01:41:02,720 --> 01:41:10,720
view this is this is a very bad idea I mean this is you know this is you know this this won't work

1064
01:41:11,360 --> 01:41:18,720
just as you know it hasn't just not a not a thing that that works in the way that humans who believe

1065
01:41:18,720 --> 01:41:24,720
in free will and things like that set the world up but so so first point is I think that you know

1066
01:41:24,720 --> 01:41:29,440
I've thought quite a bit about this kind of ai constitution question and what sorts of provisions

1067
01:41:29,440 --> 01:41:35,680
you might imagine in wanting to set up it's not easy to understand how those constraints get applied

1068
01:41:35,680 --> 01:41:40,320
etc etc etc and certainly there's not going to be one kind of this is the ai constitution of the

1069
01:41:40,320 --> 01:41:45,760
world we're finished type thing um but even figuring out those provisions is surprisingly hard

1070
01:41:45,760 --> 01:41:50,800
and and I've I've you know it's surprisingly little has been done on this second thing the thing

1071
01:41:50,800 --> 01:41:55,680
that I've now come to think more about because I think it's it's a more promising direction

1072
01:41:56,400 --> 01:42:01,680
is if one ai if there's just one ai in the world I think it's a very brittle situation

1073
01:42:02,240 --> 01:42:06,960
the reality is there's not going to be one ai in the world there's going to be a whole society of ai's

1074
01:42:06,960 --> 01:42:12,080
and the society of ai's will operate in some way that probably has many of the same dynamics as human

1075
01:42:12,080 --> 01:42:17,840
society and the society there will be some inexorable features of the ai society just as

1076
01:42:17,840 --> 01:42:22,480
presumably there are inexorable features of human society and economics and things like this

1077
01:42:22,480 --> 01:42:27,360
so there's a science question about what are those inexorable features what does the society of the

1078
01:42:27,360 --> 01:42:32,480
ai's look like and how do we you know are there dynamics for the society of ai let me give you

1079
01:42:32,480 --> 01:42:37,920
one example it's unthought out okay so but let me make a meta comment the meta comment is if you

1080
01:42:37,920 --> 01:42:43,200
look at the history of things like governance and democracy and so on you know big things happened

1081
01:42:43,200 --> 01:42:47,520
a few hundred years ago that was a time when there was a lot of political philosophy was being thought

1082
01:42:47,520 --> 01:42:52,480
about and people figured stuff out in political philosophy and that turned into actual governance

1083
01:42:52,480 --> 01:42:58,400
systems that have been reasonably successful over the last few hundred years and you know now is the

1084
01:42:58,400 --> 01:43:04,480
moment this is the great moment for political philosophy again it's you know and I don't know

1085
01:43:04,480 --> 01:43:09,520
that there are very many people who've stepped up to figuring this out but there will be ideas

1086
01:43:09,520 --> 01:43:14,560
that will be and they won't be promptocracies probably but it'll be something and there'll be

1087
01:43:14,560 --> 01:43:21,040
ideas that are different new ideas enabled by the fact that we live in an ai technological

1088
01:43:21,040 --> 01:43:26,160
society so to speak that that become possible I'll give you one example of a kind of thinking

1089
01:43:26,160 --> 01:43:31,680
and we will end on that example okay fine now maybe this is a this is maybe not an upper okay so

1090
01:43:31,680 --> 01:43:40,400
here's the question question is in human society people sort of to some sense do the right thing

1091
01:43:40,400 --> 01:43:46,480
because if they don't do the right thing they suffer for ai's that's a more complicated issue

1092
01:43:46,480 --> 01:43:53,440
because so far as we know ai's don't suffer so how do you get an ai to do the right thing if it

1093
01:43:53,440 --> 01:43:59,520
won't suffer by doing the wrong thing and and so but now what you realize is actually you already

1094
01:43:59,520 --> 01:44:05,840
have this issue with humans because you know internally to you how you feel but anything else

1095
01:44:05,920 --> 01:44:11,520
is an extrapolation it's just you're guessing that you have empathy for some other thing so okay

1096
01:44:11,520 --> 01:44:17,040
so you can you start thinking about the ai's and what is the operational again I'd say I haven't

1097
01:44:17,040 --> 01:44:21,200
figured this out but I just I give this as an example of the type of thinking I think one has to do

1098
01:44:21,920 --> 01:44:30,000
is is you know if there's an ai and it did the wrong thing and it is then removed from ai society

1099
01:44:30,160 --> 01:44:38,160
okay whether the ai internally suffered or not who cares because what matters to the world is that

1100
01:44:38,160 --> 01:44:43,440
it was removed from ai society so to speak and so what you realize is that that this kind of the

1101
01:44:43,440 --> 01:44:49,280
societal you know is there a dynamics of that society that causes the ai that did the wrong

1102
01:44:49,280 --> 01:44:55,200
thing to not be trusted by the other ai's etc etc etc that be to be sort of removed from ai society

1103
01:44:55,200 --> 01:45:01,440
having no kind of imagined not imagining that you are you know the ai itself is making this you

1104
01:45:01,440 --> 01:45:07,280
know making this decision it's as I say not properly thought out but that's just as a

1105
01:45:07,280 --> 01:45:12,320
for people interested in philosophy of these things that's just sort of a you know the beginnings

1106
01:45:12,320 --> 01:45:17,840
of a thought about how to think through you know sort of responsibility personal responsibility

1107
01:45:17,840 --> 01:45:23,440
in the time of ai interesting okay with that please join me in thanking Stephen for this

1108
01:45:24,000 --> 01:45:31,200
extra long edition of our distinguished lecture thank you thank you everyone and see you next

1109
01:45:31,200 --> 01:45:34,400
semester with the distinguished lecture series

