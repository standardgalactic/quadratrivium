So, welcome everybody, I have a pleasure to introduce Stephen Warfram, I know him many,
many years because I was involved at some point in a different computer algebra system,
you know he's the creator of Mathematica, he's the founder and CEO of Warfram Research,
he also created this semantic search engine Warfram Alpha that you may be well aware of
and now he's using language models, he's author of many books like A New Kind of Sciences
and a very recent book on everything about physics and we are very happy that he accepted
to come today to do the last distinguished lecture of the semester.
So all right, let's talk about, so as far as I'm concerned the kind of the big idea
that is kind of a defining idea probably of our century is this idea of computation and
I kind of view it as being part of a long sequence of efforts that kind of span the
history of our species I suppose in trying to formalize things.
So you know the probably the first step in that was the creation of human language and
the idea that one could instead of just sort of pointing at different rocks and so on,
one could have a kind of symbolic term rock that represents the general category of things
that are rocks.
That was kind of a big step in being able to explain, in being able to abstract things
from the world as it is to something that we can describe in a formal way and kind of
I would say the next another big step in that was the creation of logic, the idea that
one could take a collection of sentences that had the particular forms of particular forms
and say there's something that we can abstract from all these sentences that is a representation
of something that is formal that we can deduce from these sentences and it's kind of interesting
that when we look at the chat GPs of this world and people are sort of amazed oh wow
it manages to do logic well it's been trained from a you know trillion words of stuff that
we humans have put out there on the web and that contains the same kind of forms of speech
that you know Aristotle and folks like that used to originally construct logic it's able
it's one is abstracting from the specifics of language to something that is a more formal
representation of what's going on.
I suppose in the kind of long arc of history the next big thing that's sort of an example
of formalization of things in the world is mathematics that's another kind of way of
formalizing what happens in the world describing things in terms of numbers and algebra and
those sorts of things. And mathematics when it comes to science kind of the last 300 years
sort of mathematics had been the kind of dominant form of formalization used in science
logic was not particularly successful for as a formalization for science mathematics is
sort of the winning one and that's something that has had continued until quite recently.
The big thing that is sort of new last hundred years is this idea of computation the idea
that there you can what is computation as far as I'm concerned it's you specify sort
of precise rules and then you understand their consequences. In mathematics there are particular
kinds of rules that are represented by I don't know algebra and integrals and calculus and
things like that. There are particular kinds of rules that we study in mathematics computation
is about the most general case of studying sort of given rules what are their consequences
and by the way there's sort of a difference in the way that a particular time is handled
when we think about computation as compared to when we think about for example mathematics
in mathematics we might have some equation that has time as a parameter but we kind of
expect we're going to get an answer where we get some formula where time appears in
the formula but we can set that time to be any value we want. When we think about computation
we're thinking about we're given these rules and now we're going to run these rules and
we're going to see what happens we don't get to say oh I'm going to sort of set the value
of time to be this we have to just run the rules and see what happens. Maybe I should
explain some things that this is from the 1980s actually the kind of a big effort of
the question that this I've been talking about kind of computation as a way of thinking
kind of formalizing what happens in the world so one of the things I got interested in back
at the beginning of the 1980s actually was if one is going to make models of nature what
raw material one might one use to do that and kind of the traditional view had been
used mathematical equations and so on my interest was to kind of generalize that and to see
what happens if you use not equations but programs to represent things in the world
and I have to say it's kind of a spoiler for the path of history but in the last 25 years
or so there's been after 300 years of complete dominance of kind of mathematical equations
as ways to model the world computation has become and programs and so on have kind of
become the when new models are created that's almost always what new models get made with
so but the question that I got interested in years ago is when you look at just simple
if you just ask what what kinds of programs might nature use to do the things that it
does and a particular category of such programs that I found convenient to look at are things
that get called cellular automata this is an example of them it's just a line of cells
each one is either black or white and in a series of steps you set the new color of
the cell to be determined by rule that depends on the previous color of that cell and the
previous colors of its two neighbors so if we take that we just say run run that let's
let's let's let's run that for a few steps here let's just show this with a mesh okay
so this is this is using that rule and at every at every cell at every step we're just
applying that rule to determine what the color of the next step cell will be so we have a
very simple rule we get very simple behavior it's kind of like you kind of you might expect
that's what's going to happen well let's let's change this rule a bit let's say we have
something like this we can change it see what it does that's what it does then let's change
it again let's say we do this how we use that rule instead well now we get a slightly more
complicated pattern if we keep it running a little bit longer we'll find that it makes
a nice some kind of elaborate intricate but very nested structure and we might again say
at this point oh you know if the rule is simple then even if the behavior is somehow intricate
there will be some easy regularity to identify in that behavior okay so now you can ask the
question if you're just sort of studying these things from a sort of science point of view
you can ask the question well why don't I just do an experiment why don't I just point sort
of a computational telescope out into this computational universe of possible programs
just find out what's out there so we can try doing that and let's just make a table of
these with any rule number here and let's do let's say the first 64 of these and this is the result
we get so much of the time so ever every one of these pictures is a different rule that we're
using a much of the time you see what happens is really pretty simple maybe there's stripes from
alternating stripes but there's some fairly simple structure that's produced and here are some nice
nested patterns and then this is my all-time favorite science discovery here's rule 30 in that
numbering scheme it does something a bit different let's take a look at that in a bit more detail
let's say let's look at the rule for it here it is and let's look at what it actually does and
that's the result so what's really remarkable about this is the rule is simple starts off
from just one black cell yet the behavior you get when you actually run this rule is something
complicated in fact if you look at the center column of cells here for all practical purposes
they seem completely random and this is this is kind of a big surprise to one's intuition because
this idea that to make something complicated you have to go lots of effort that's what we kind of
learn intuitively from doing engineering if you want to make a complicated thing you have to go to
a lot of effort to build up this whole structure that's going to make that complicated thing but
here we've got something where in a sense effortlessly from this very simple rule we're making a
very complicated thing well back in the 1980s what I was excited about was what that means for
understanding what happens in nature what happens in in in kind of the understanding how sort of
complexity arises in systems in nature and realizing that this kind of phenomenon that we see in the
computational universe seems to be the secret that nature has that lets it makes so many complicated
things that in fact out in the computational universe of possible programs that should pretty
common to find that even very simple rules can generate what appears to us to be very complicated
behavior well maybe it's worthwhile to understand kind of what how we can understand this phenomenon
that very simple rules can produce very complicated behavior what's sort of going on what are the
broader scientific implications of that and the I suppose one of the one of the big the underlying
principle that I kind of came up with in the 1990s now is this thing I call the principle of
computational equivalence so here's how this works we think about what what is this thing doing we
can think of it as doing a computation it's been given some input it's been given a rule it runs
that that that rule with that input it generates some output it's it's a computation like a computer
might run a computation the question is how sophisticated is that computation is that
computation one that is somehow quite straightforward we could just jump ahead and we could do a
better computation figure out the answer or is it the case that this computation is is is a
sophisticated one so the big thing that was discovered about a hundred years ago now is this
idea of universal computation the idea that there exist systems like Turing machines and so on
that have the property that you can just have a fixed piece of hardware so to speak a fixed rule
and yet by changing the initial conditions for the system you can make that system behave like any
other computational system and that's sort of an important idea because it's the idea that makes
software possible it's kind of the idea that drove essentially modern technology as it is but that
idea is says there exists a system that you can build it's maybe it's a microprocessor with a
billion transistors on it that is capable of universal computation what the principle of
computational equivalence says is something much more extreme than that it says whenever you look
at these systems in the computational universe when they're not doing things that are in a sense
obviously trivial then they will tend to be doing things which are as sophisticated computations as
anything can do so it's kind of saying that that something like this system here should be capable
of for example universal computation but more to the point it's the computation you're seeing here
is as sophisticated as the computation that any system can do so what are the consequences of
this well one consequence is if we're trying to predict what this system does then we're doing
that by doing a computation so if we expect that we can sort of jump ahead and say this system
after a billion steps is going to do this what we have to believe is that the computation we can
do is somehow more sophisticated than the computation the system can do so that we can kind of do
that jumping ahead and seeing what the answer is going to be but the principle of computational
equivalence says you're not going to be able to do that it says that the computation you get to do
with your brain your computer your mathematics whatever else is just the same sophistication as
the computation that this little system can do so you can't expect to be able to jump ahead like
that and that leads to this phenomenon I call computational irreducibility which is this idea
that there are things that happen computations that happen which are irreducible in the sense
that to know what's going to get what consequences they're going to have you basically just have
to run that computation and see what happens you can't expect to jump ahead and figure out the
answer with with less steps than actually running essentially with less steps than actually running
the system so here's an example let me show you an example of another one where it's kind of
interesting to see what happens here let's say rule 110 so this one actually happens to grow
only on one side but you see it makes this little structure let's run it for a thousand steps let's say
and the question will be we have that little structure there is that structure going to die out
or is that structure going to keep going forever well if we said if there wasn't computational
irreducibility we could say well we expect there's just some some sophisticated formula we can make
that can jump ahead and say that's what's going to happen in the end to this but with computational
irreducibility the only way we can work out what's going to happen is essentially to follow the steps
and see what happens and if we don't know how many steps we have to follow it's going to be in general
a question which is sort of undecidable to us what's going to happen in the end well let's see
you can run it I think there's three thousand steps enough yeah three thousand steps was enough
we can if you can just about see it you'll see that it pretty much died out maybe it's still got some
possible life to it but what's interesting is that we can't predict that without essentially running
the rule and just seeing what happens so okay so there's so we have that we've discovered this
phenomenon that even very simple rules in the computational universe can produce very complicated
behavior can produce behavior that is uh is it turns out to often be similar to the kinds of
behavior we see in the in the natural world also has this feature that even though we might have
thought you know the big thing about science is you can always jump ahead and predict things
computational irreducibility shows us that's not true there's sort of a fundamental limitation
it's kind of from within science we see there's sort of a fundamental limitation
that prevents that from happening and makes it it so that we kind of just have to simulate things
to see what's going to happen okay so one question you might ask is we found out the very simple
rules can produce very complicated behavior uh how far does that go what kinds of things can
that do can it make you know can it make brain like things can it make universe like things what
can it make let's talk about the universe first because it's sort of the biggest thing we can
talk about um and uh the um so the question is if we look at the physical world what what's
underneath what's the underlying structure of how the physical world gets made could the physical
world in fact be something which can be represented by some simple computational process and people
have wondered you know what what's the sort of fundamental theory of physics for a long time
and people have different views of that and there's been kind of a a bunch of well it's going waves
of optimism and pessimism but about a hundred years ago a lot of progress was made in the invention
of kind of the the core theories of modern physics which are basically statistical mechanics
the theory of kind of what you know things like gases with lots of molecules how that works
the second law of thermodynamics things like that that's one bucket the second bucket uh
is general relativity the theory of gravity and the structure of spacetime and the third bucket
is quantum mechanics and the theory of very small things so to speak so those are the sort of the
um the main uh there was sort of a big big advance a hundred years ago or so now in those
kinds of areas um the question is okay so what's for example what's underneath those things are
those just sort of arbitrary wheel in features of the universe or are they derivable in some way
so this kind of seeing things like rule 30 makes one think well maybe there might be some very
simple rule that might be able to to explain what's going on well back in the 1990s I started
thinking about this made quite a bit of progress actually but the time I suppose physics was in a
very um high self-esteem state and it was like string theory is going to solve it you don't
need anything else so I worked on other things which turned out to be rather productive and
then about four years ago now came back to this question having figured out a lot of other things
in the intervening years and having built this big stack of technology I mean in in the the kind
of rough summary of my life is that I've kind of alternated between doing basic science and
developing tools and technology and it's been a pretty pretty good journey I would say because
you know you do basic science it shows you what is conceivable to build in technology you then
build the technology that creates tools that let you do more basic science and I managed to
iterate this about five times so far in my life and it's built a pretty big tower and from the
top of that tower we can now see some pretty neat basic science that's been really exciting to me
in the last few years and let me let me tell you a little bit about that and then I'm going to
tell you a bit about sort of how that connects to the practical world of of kind of computational
x for all x and we'll talk about AI and and whatever else we can we can fit in there all right so
let's talk about the fundamental theory of physics and what's underneath the stuff that
we experience in the world let's see I probably have a nice visual summary here which I can perhaps use
so this is sort of a visual summary of our physics project and as is often the case in
science the first thing you have to do to make progress is to realize what was wrong before
and one thing that's been assumed the last couple of thousand years is that space is something
continuous that you can just sort of space is just this thing where you can say I'm going to put
something at this particular coordinate position in space I'm going to put it at some arbitrary
position in space turns out that seems to be wrong that space is not a continuous thing space is
made of something and a hundred years ago people thought this might be the case actually
because a hundred years ago there was a big a little bit more than a hundred years ago so the
big argument was is matter continuous or discrete are there discrete molecules or is matter a
continuous kind of thing same question for light well it turned out round 1900 people realized no
molecules really exist matter is discrete and turns out and light by 1905 and so people realized
photons really exist light is also discrete so you know matters discrete light is discrete what
about space at that time and actually I just recently I just lost a few days actually learned
even another place where sort of most of the physicists so to speak back in the early part of
the 20th century thought that space was discrete but they couldn't make it work in fact Einstein
has a nice quote from 1916 that basically says in the end space will turn out to be discrete
but we don't have the tools necessary to see how that works now a hundred years later
turns out we do so the sort of the first first sort of starting point is the realization that
space is discrete space is made of discrete atoms of space an atom of space has nothing
there's nothing you can say about it other than it's this it's this idealized point this idealized
element the only thing that one can say about it is that it exists and it's unique and distinct
from other atoms of space and then what can you say about the atoms of space well all you can
say is how they're related to each other you can kind of think of the friend network of the
atoms of space so you're kind of saying what and that's all you know about these things there's
not they're not placed in any kind of you know you're not saying it's in three dimensions and
you're placing this particular atom here and so on all you know is there's this giant network
that represents the relations between the atoms of space and it's convenient to technically it's
convenient to think about it as a hypergraph and an ordinary graph you have two nodes of the graph
and they're they're connected by an edge and a hypergraph you can have any number of nodes
connected by a hyper edge so it's just technically convenient to think about it as a hypergraph
so the structure of space is this hypergraph of atoms of space and basically everything in the
universe is just part of this giant hypergraph so all the things that we experience the you know the
the electrons the black holes whatever else they're all just features of this giant hypergraph it's
kind of like when you if you think about something like water there's a bunch of molecules bouncing
around but you can have things like eddies vortices in the water which are structures that have some
persistence and it's those kinds of structures that are like the things that we experience like
electrons and so on so okay so the the sort of underlying data structure of the universe is this
giant hypergraph made of atoms of space and by the way it's a it's a feature of doing very
foundational things that there are many equivalent versions of this statement you can talk about it
in terms of higher category theory you can talk about it in different terms but I think the most
concrete version is it's this giant network that is this hypergraph so then what that's sort of the
structure of space the structure of what how does time work by the way one of the things that's sort
of a wrong turn in the 100 years ago was this idea that space and time are the same kind of thing
it was a kind of idea that was introduced sort of as a mathematical convenience and then it
became a thing that everybody explained oh space time is you know space and time are all connected
together like that I don't think it's true time is actually something very different from space it
turns out that the features of relativity theory that connect space and time emerge from the kind
of large-scale properties of the system but they're not the intrinsic way to think about it so what
is time well time is this kind of process of computation just like in that rule 30 cellular
automaton we've got the series of steps those represent the progress of time and computational
irreducibility kind of tells us there's some kind of irreducible thing achieved by the passage of
time and so it is in the system instead of it being updating these cells with neighbors and so on
it's you say we've got this we've got this graph and we have these rules that just say whenever you
see a little piece of graph that looks like this rewrite it to a piece of graph that looks like
that and so you keep doing that over and over again and you build up more and more elaborate
kinds of graphs you get all kinds of complicated structures like this and one question is when
you do that enough times what is the what what you know when you have a graph that has 10 to
the 100 nodes or something in it you've built up this way what is the structure of that graph
well it's a similar question to asking the question if you have a bunch of molecules
bouncing around and they each interact according to some force law and so on what is the large-scale
behavior of a whole collection of molecules and the answer we know in that case is it's like fluid
dynamics that's what happens in something like water you've got these discrete molecules bouncing
around the emergent kind of behavior of the system follows the laws of fluid mechanics
okay so what's the analogous thing here well it's pretty neat because it turns out the analogous
thing here is the thing follows the Einstein equations which are the the the corresponding
laws for the structure of spacetime and so you can then derive from this very simple underlying
set of rules that are about the rewriting of networks the large-scale limits of that with a
bunch of footnotes that are a complicated story you can derive the fact that you get the structure
of spacetime that that we observe now actually one of the things that's tricky is this thing
doesn't have any space in it at the beginning it doesn't even know that it's in three dimensions
for instance dimension is something that's an emergent property of the system where you're
basically saying if you start from a given node in this in this graph and you say what how many
nodes do you get to by going a certain distance on the graph a certain number of steps in the
in the graph let's say you get to some number of nodes and that number of nodes grows like r
the distance to the power d then you can identify that d as the dimension the effective dimension
of the space so one of the consequences of this model is that space won't be precisely three
dimensional there'll actually be dimension fluctuations probably the the beginning of the
universe will be infinite dimensional gradually the universe kind of cools down to being the
three dimensions we observe today and they're probably dimension fluctuations left over from
the other universe and an interesting kind of current sort of can we figure out how this
works question is what actual experimental signatures there are from such a phenomenon
but anyway so so by the way let me just show you um see if I can find this uh yeah let me let me
just show you in this model um this is kind of the uh what the the a version of the beginning
of the universe in this kind of model where so we're we're seeing here the progressive rewriting
of uh kind of this network of atoms of space and uh this is the first very small amount of time
in at least one branch of the beginning of the universe um you have to keep going a long way
to get to our current universe and because of computational irreducibility that's not something
I'm going to be able to do on my laptop however the um uh the thing that um you can set things
up to kind of see what would it be like if you had a much bigger chunk of space and this is an
example yes okay so this is much later in the history of the universe these are two little
black holes and what you'll see here is the the uh that sort of the background here is the structure
of space and space is kind of knitted together by all these little rewrites that are happening if
it wasn't for all these rewrites space would fall apart the space the the fact that there is this
thing we can think of as space that is kind of it has extent is a consequence of the of the
progression through time of all these rewrites but anyway here are two little black holes and you
can see what they do the space is is wiggling around a lot these two little black holes actually
feel the force of gravity um that's just a consequence of these rewrites and then those
black holes merge well that's something that we observe in uh that's gravitational wave detectors
have observed the merger of black holes these are incredibly tiny black holes turns out very
conveniently the behavior of a very tiny black hole is pretty much the same as the behavior of a
very big black hole so we can actually start to see and when when these black holes merge and this
little simulation here um turns out they emit gravitational radiation and we can start seeing
the properties of their gravitational radiation and one of the current frontier questions is
whether there are features of that gravitational radiation that reveal the discreteness of space
and uh I think I think it's it's fairly promising that there are although
whether the magnitude of the the things is such that we can detect it now
versus a hundred years from now we don't know yet that yet but anyway that's kind of
how the the structure of space works in in these these kinds of models another thing to to mention
is uh another so I mentioned this um um the um the the question of um these sort of three big
theories of of 20th century physics statistical mechanics general relativity and quantum mechanics
so we've got what I've been describing is the derivation of general relativity people didn't
think general relativity was something you could derive from something lower level it looks like
it is so the another piece to this is quantum mechanics and sort of the big idea of quantum
mechanics is in classical physics you imagine that definite things happen in the world in
quantum mechanics the big idea is that you know you throw a ball and it doesn't just follow a
single trajectory it follows many possible trajectories and you just get to figure out
what the probability of different things happening is well in our models we actually have no choice
but to have quantum mechanics because what happens is that I talked about the rewriting of these
hypergraphs that represent the structure of the space and everything in it there are many possible
ways these rewritings can happen and the results of that is that you get what we call a multiway
graph that represents all the different possible paths of history there can be different rewritings
that happen there can be that can cause these paths of history to branch they can merge and so on
so kind of the the big thing that happens that you get these multiway graphs multiway graphs are
something pretty interesting that that sort of related to nondeterministic computation but in
nondeterministic computation you tend to just say we're going to pick the one winning branch
in multiway computation you're interested in sort of all the possible things that can happen
and so you know you can kind of think about lots of different kinds of problems in these
terms you know you've got a game like tic-tac-toe or something there are many possible paths you can
follow to in the in the doing of that game and you can kind of look at the complete graph that
you get let's see if I can just pull up a picture of that so you know a typical kind of thing would
be here we go it's kind of a multiway graph that just shows given that you're starting with a blank
tic-tac-toe simplified tic-tac-toe board you get this kind of graph of all these possibilities
you keep going somewhere here probably there's a picture of the actual
game and and what it takes to win the game and so on but that that's an example of a multiway
graph in that particular case for just a the game of tic-tac-toe but the the whole point is
there is also a multiway graph for the whole structure of our universe and the fact that
there are these different paths is is the reason that we get quantum mechanics since it's slightly
more complicated story we have when you when you kind of take a slice across all those paths
you form this kind of space we call it branch real space the space of quantum branches
which is kind of its own kind of space and just as you can think about kind of motion
and physical space you can also think about motion and branch real space
just as you can think about observing physical space we we notice that in physical space well
okay the the we we are at a scale much larger than the atoms of space and so we aggregate when we
observe what physical space is like what we're observing is this this vast aggregation of atoms
of space and that's why space seems to us continuous well something a bit similar happens in quantum
mechanics what happens is that just as we are extended in physical space we are also extended
in branch real space and so a rather strange thing it has to do with the fact that an observer
like us that has that is part of this universe that's branching emerging and so on the question
of quantum mechanics becomes how does a branching brain perceive a branching universe and turns
out that when you untangle those things the answer is quantum mechanics so okay just to
finish on this in this branch for a second the the thing so one of the one of the questions would
be okay so we've got this model for physics and we can say there's an underlying rule which if we
run it for long enough we'll make our universe so the next question is well why did we get that rule
and not another rule and that's it's sort of a you know that's a kind of the the Copernican thing
would be to think there can't be anything special about the rule we got we just have to have some
sort of very arbitrary rule well the the thing that I wondered about this for a while and then
we realized that actually here's what's going on the the structure I mentioned that given a
particular rule you apply to no possible ways and that's what gives you quantum mechanics
but why do you have just one particular rule what happens if you apply all possible rules
and you make something which is the result of taking all possible computational rules
and running them and you can see that different rules will produce different results but then
those results might converge again because when you run different rules again they'll converge to
the same results and so on you get this big complicated entangled mess that is the the result
of running all possible computations so you it's kind of you make this thing which is the
entangled limit of all possible computations it's the thing we call the rule ad and it's kind of the
it's an encapsulated object that represents everything that is computationally possible
and it's a it's a kind of an interesting object because it's a very it's a necessary object it's
not an object that you say oh it happens to exist in this way in that way it's just given the idea
of computation there is just a single object that is this rule ad that represents all possible
the entangled limit of all possible computations okay so so what so how do you make how do you take
that and understand sort of how we we perceive physics and things like this well the key thing
is this realization that we are a certain kind of observer of this rule ad we are it's a little
bit of a brain twisting kind of thing because we are embedded within this rule ad we are part
of this rule ad and we are observing what happens in the rule ad and turns out that there are we
might say well well what we observe to be happening in the rule ad depends on what we are like as
observers so the question is do we how much do we have to know about what we're like as observers
to conclude what about what we will perceive happens in the rule ad okay so it turns out
there are two key assumptions about us as observers both of which are pretty uncontroversial one is
that we are computationally bounded we we can only in our sort of finite minds we can only fit a
certain amount of computational effort it's point one point two is we believe we are persistent in
time even though at every moment in time we might be made of different atoms of space we believe
that we have a single thread of experience that continues throughout time so those are two assumptions
so it turns out this is sort of the big result of the last few years it turns out those two
assumptions are sufficient to derive the three big theories of 20th century physics so given this
idea of the rule ad if you say what does an observer with those characteristics perceive in this big
messy rule ad of all possible computations it turns out that an observer with those characteristics
necessarily perceives actually the second rule of thermodynamics general relativity and quantum
mechanics that's kind of a very interesting kind of I suppose philosophical moment that these are
things which seemed like they were just features of the universe that happen to be the way they are
but it isn't true that there instead there is this kind of necessary formal structure
which for observers like us if we were not like we are if we were some kind of alien observers
with different characteristics we would perceive a different physics but given that we are observers
of the kind that we are we necessarily perceive these features of the physical world
so that's that's kind of a that's a that's a sort of a big deal in in in thinking about physics
it also turns out to have implications about mathematics and the kind of nature of mathematics
and so on can talk about those but let me let me talk about some more practical kinds of things so
we we've kind of understood something about this idea of computation that ends up sort of going all
the way down it gives us the machine code for the universe it seems and it tells us things about
sort of the sort of the big picture of what's computationally possible well it's okay so here
we are as just humans hanging out in this rule ad and and and the question is how do we access
this kind of this the the how do we what can we access of computation and so then we have the kind
of interesting situation we are humans who think about things in certain ways and what do we you
know how can we make use of this kind of power of computation that sort of is the intrinsic thing
that runs the universe and so on and and what you start realizing is that you need some kind of bridge
between the way we think about things and the sort of ocean of computational possibilities
much of what's out there in the computational universe is stuff that is completely incomprehensible
to us it's stuff where we can run all these cellular automata they make all these patterns
we say we don't really know what the significance of this is they're not really connected to anything
we know about most of the computational universe is completely alien to us and so the the question
really becomes sort of how do we characterize the parts of the computational universe that we humans
can connect to his sort of perhaps an interesting experiment I can show you something here this
is looking with genitive AI um just looking at um the uh yeah this is um this is looking at um
sort of a very tiny slice of the rule ad that has been set up to be aligned with the way we humans
think about things because it's been it's a genitive AI trained on a few billion images
and so what we're asking is if we look out into that sort of space of possible
possible things that we can think of as a tiny slice of the rule yard what's out there and so we
we said okay let's let's make a we initially say we're going to look for a cat and a party hat
and um somewhere at the beginning there was um was a part of um of this uh of the space that
has a nice cat there the question is what else is out there in the space if you go away from the
cat and the party hat you go out um and you're you're going out into sort of this space of
computational possibilities and what you find is there's sort of a cat island where things are
sort of identifiably cat like but then most of sort of this space consists of things that
well there's some definite structure there but it's not clear what we humans would say about
that structure we don't really have a a way of thinking about that we think about so we can kind
of think about think about these sort of blobs of of possibility that are concepts of things we've
given human names to we've given words to their concepts we know about and then there's this vast
area of kind of inter concept space kind of analogous to interstellar space where it's something
that we haven't you know we humans have not conceived we don't have a way to that we brought
that into our kind of world and so you might ask well what fraction of space is inter concept space
in this very simple example that's a very sort of optimistic case one part and ten to the six
hundred of the space is space that we understand uh the rest of it is all inter concept space
concepts that we humans have not yet reached so you can kind of think about the the progress of
of our uh intellect and science and so on as being this kind of colonization of what we call
rural space of kind of gradually expanding in the domain of what we consider what we have concepts
to describe it's some uh kind of a okay to make a slightly bizarre comment but but one thing you
might wonder about is okay in the future of science and everything maybe the future of
science is we expand in in rural space and we we eventually expand so that we fill all of rural
space it turns out one should be careful what one wishes for because one feature of that
is that in in in a sense went by by the time you have a mind that is that big it is not a coherent
mind anymore and for it to coherently exist it has to be something that is limited in rural
space by the time it fills the whole rulliard in no meaningful sense does it coherently exist
so in a sense when you when you if you expand too far uh you you you no longer can can describe
yourself as as coherently existing so okay so so there's there's this um uh this is kind of what
what it looks like out in this sort of human aligned uh inter concept space this is this is
kind of what what it looks like just in sort of out in the rulliard looking at different possible
behaviors these are just cellular automata um but we can say well when we look at these things
what are these things how do we describe them are they things that are relevant to to us yet do we
yet have words for these things and the answer is typically no we've we've explored only this tiny
slice okay but so what can we do with the slice that we're exploring well the big thing that i've
spent much of my life actually doing is trying to build kind of a a a thing that is a bridge between
the way we think about things and what's computationally possible and the way that what we what we
need to do is to take the things that we care about that we think about and formalize them so we
represent them computationally so that we can make use of kind of the power that exists in this
computational universe and so that has been the the big effort to build what we call wolfman language
um and sort of the goal there is is to be able to represent sort of everything in the world
in a computational kind of way so i mean if i take um uh well let's just let's just say you
know i have um i don't know some uh let's let's say i make some graph uh we can we can represent
some random graph as as a computational kind of thing we could say i don't know let's work out
let's just do some computation on that and the um uh um
well we could take um uh we could take some let's see if i can um take an image here
ah what if i do that um let's see there we go well terrible image but um we could we could say
something like um uh well let's just say something like edge detect that image um or we could say
we want it to be a little bit more optimistic let's see um how about we do this how about we say
let's do this um
let's take that image and let's say we want to just say identify what's in that image but let's
let's run it this way so we're running some neural net we can look at um uh we may have to load in
oh what earth is that i have no idea what that is um it's the back it's the backdrop okay
okay let's see well let's let's see what happens if we say what's the word definition of that thing
ha okay the um but it's kind of interesting to um uh we can look here if we say uh well that that
thing will just be some neural net that um uh we can look at it's all the all the all the nasty
innards of it we could for example just say let's just take the first uh five levels of the neural
net or something and apply that to this picture um and uh and then maybe we can say uh make images
out of those okay so that's kind of the the uh inside the mind of the neural net um what it's
thinking about maybe we can just say let's let's just do this let's say make a feature space plot
of those let's see if we can not very exciting it just decided that there were two clumps of
things that was thinking about one seemed like they're mostly white one seems like they're mostly
black so it goes um but but anyway the kind of the concept here is to make a computational
language that can formalize the things we like to think about in computational terms
so that we can do things uh so that we can use sort of the power of computation to operate on
those kinds of things so for example there's the part of the the story is just knowing a lot about
the world so we might say you know that's there's a list of words in English maybe we can say let's
just take the first letter of each word and let's make a word cloud of those first letters
and um this will give us oops what did I just do word list oh that's not what I want to do I wanted
to say take just the first letters there okay there we go and so that gives us for for English
the uh the sort of word cloud of first letters maybe we can just for fun let's try doing
Spanish for example I don't know whether anybody knows what the what what part of a dictionary
is most thumbed in the Spanish dictionary this predicts it will be C um the uh so um in any case
the the kind of the goal here is to is to is to know things about the world so for example we could
say um I don't know what we let's see what uh let's see what we what we know about Northeastern
University as a as a thing let's see let's look at what properties we might know about Northeastern
University okay let's say somebody was just telling me this number so let me just see what what it
thinks that number is um okay let's see whether we know what that is as a function of time uh
I don't know whether we will but um okay we have something some information here um okay so that
claims to be the um the plot of the number of students as a function of time at Northeastern um
but uh or we could we could say something like let's let's make a um uh I don't know where it
thinks the computer is right now but maybe plausibly here I don't know we'll find out um let's say uh
the somebody's figuring out why the why the plot looks like that
I um it's um um the uh
so let's see whether this um okay so that's just showing us a geodesk of 10 miles around where
we are that's maybe maybe we can just make something just for fun that um has a uh uh
let's say 10 to the 10 to the n miles and let's make a table of these
with um n going from let's say 10th of a mile to let's let's try this so this should make a
series of of kind of um there we go so this is um that's from from very nearby where it thinks the
computer is to very far away where the um the the disk extends to most of the earth actually we
could make that look better by saying let's say geo projection um would be I don't know what's a
good example lambadas might be a good one so it won't make any difference to the local so what we
get locally but it will make a difference when we get to um a larger part of the earth we should
see something more sensible here it's probably it has to recompute all these projections of the
earth so it might take it a little while but in any case the the kind of the big idea is just
to be able to there we go um so that's kind of interesting the the um uh so you know the big
idea is just to know about and to represent the kinds of things that we humans care about
to represent them in computational terms and kind of this has been my effort over the last 40 years
or so is to progressively represent more and more things about the world in this formal
computational way so that we can compute from about them and this is something that's pretty
important because it's something that it gives you this we have now this language for representing
things computationally and if you think about sort of history the um the the a thing a bit like this
that happened before maybe 500 years ago people had the idea of making notation for mathematics
there had been kind of mathematics just described in words and then there started to be notation
for mathematics plus signs and equal signs and things like that and then people started to be
able to talk about mathematics in a streamlined way and then algebra got invented and then calculus
and so on and that kind of spawned the possibility of all of the modern mathematical sciences and so
kind of the question for today is what can we do with this idea of computation how can we use that
in the world and what we realize is for any field x in an archaeology to zoology to whatever else
there is a computational x that you could build which essentially takes the questions of that field
and presents them thinks about them in a kind of formalized computational way and kind of my
goal over the last 40 years has been to build kind of the notation the language to represent
things computationally in the world and and that's um uh it's kind of I think the the thing that we've
achieved at this point is is sort of having made this kind of full-scale computational language
that allows us to represent things in the world computationally and I see you you have a microphone
there and that this is a I could I could talk about I didn't even talk really about AI yet but I can
talk a little bit about let me let me just say a couple of things about that and then then we'll
then we'll move on to then maybe we can we can chat about it some more I mean I think the the
one of the things that's been an interesting thing last year or so is that um uh the um
we used to just have human users mostly um you know millions of people every day use many millions
of people use our stuff as humans but now we have a new kind of user we also have AI's as users
we also have LLMs that are writing um uh that are that are um are um using our technology here's
an example this is a chat notebook and we can say something like um this is a you can say well
let's make um I don't know make a circle that's half green and half blue and that this is now um
let's see what what happens here I have no idea what this is going to do but um this might write
some more from language code it might uh you know what I thought it was going to do usually
tries to do is to actually run that code and see what happens well we can we can run it ourselves
and see what it did it right okay not so bad um in that case it happened to get it right what's
interesting actually is is what you see happening in these chat notebooks um you know we have this
we made this plugin for for uh chat gpt back in when was it that must have been in March I think um
and uh uh that gets pretty widely used but but what's perhaps more interesting is the kind of the
the sort of collaboration that goes on between the human who has some idea what they're trying to do
who try to types it in you get a piece of orphan language code our language is kind of unique in
that it's a language that's intended to be read as well as to be written by humans so it's so the
kind of the loop is typically you the the the thing that is difficult and this is the the part
that is sort of the the education moment is how do you take the thing you might be thinking about
and think about it computationally once you can do that you can begin to explain to the LLM oh this
is roughly what I want to do you explain it in in in human language words it will make a piece of
computational language you can then take that piece of computational language is that what I
wanted I run it I build on it I make it this sort of brick that I start building my whole tower
out of so this is kind of the but the the piece of this that is critical is how do you start
thinking about the world computationally there's not something people teach typically they they
should but they don't it's not what computer science is about computer science a wonderful field
but it's not about that it's you know the thing that is the challenge to reach kind of computational
x for all x which is kind of the future of pretty much every every field at this point because as
I said sort of computation is the formalism is the formalization that we got to figure out how
to do in the last century and it is the thing that is sort of driving the future of these
intellectual areas and so then the question is what you know how do you get to the point where
people can actually sort of conceptualize what they want to do in computational terms how do you
how do you teach this kind of the how to think about things computationally it's not what people
have usually done and actually I guess my project that I'm in the process of doing right now is
actually just about to get started on is because it seems like I'm I'm in the strange position of
being sort of having a responsibility to do this to sort of define what does it look like what is
this kind of basic course that the people should teach very broadly about sort of how to think
about the world computationally the mechanics of how you actually do computation well if people like
like us have done our job most of that has been automated away the LLMs automate even another
stage of that away but what's what's really at issue is how do you think about the world
computationally and and sort of how do you how do you conceptualize that one last thing about AI
the the we can talk about I wrote this whole explainer of chat GPT that some of you might have
seen that that sort of led me to kind of a theory about what's actually going on in LLMs we can
talk about that if people are interested in it but I think one of the things is sort of the
future of AI and people say you know our AI is going to take over the world and what's going to
happen and so on the the question of what does an AI want to do well you know an AI that's been
aligned with what humans you know it's been trained from what humans do that's one thing
but sort of an AI left to its own devices what does it do what you realize is AI's are creatures
of the computational universe and there's just a lot of computational universe out there that AI
sort of could explore and so the question then becomes well where do you want to go and that's
not a question that the AI can there's no theoretical answer to that question there's this whole
computational universe out there that you can explore the question that is the key question
for us humans is well where do we want to explore what what is the what what direction do we want
to go in this computational universe of possibilities and you know when it comes to
sort of things that get automated by AI the kind of jobs that get automated by AI there are lots of
things where we know where we want to go it's a question of the mechanism of how we get there
and that's automatable but the question of where we actually want to go which of the choices we
want to make that's almost by definition not automatable because that's something that we humans
can arbitrarily choose so anyway that that's a that there's much more to say about this this
topic and and so on but that that's just a few a few things maybe we can chat about all right well
I should stop there thank you very much and and now we will go to the fireside chat with Stephen
and Sam Fayad the secretary director of the institute and at the end we will have a Q&A with
all the audience welcome everyone to to this portion where we are going to take audience
questions and what we'll try to do is alternate between audience and some fireside chat questions
issues that that came up late so let me let me start maybe with a question from me which is
you know pretty practical over a decade ago maybe almost 15 years ago you launched
well from alpha and it was a I mean in my opinion it was a very effective amazing semantic search
based you know approach that's much more knowledge based than what we see today with with the LLMs
and the autocomplete and all of that I would say one thing it's not about searching what what we
what wolf mouth it does is it takes you know the natural language people the weird natural language
people set up as questions and it converts that into computational language and then it tries to
compute answers so there's no you know what one might think is there's the web out there and there's
stuff to search for that's not what we're doing right what we've what we've tried to do is to
sort of collect and curate all of this knowledge implement the actual algorithms and methods and
so on and then compute and the thing that is sort of the interface to the humans is take that
piece of natural language somebody types in and or says to a phone or whatever else it is
and convert that into this precise computational language and then compute answers so that that's
that's kind of that's the way I know and that's fair but there you used kind of what what we would
consider concepts that are familiar to humans the way we think about the world yes versus
today's other lambs are just building building weights now what happens for the autocomplete
but what happened is somehow chat gpt took off much more than wolfram alpha any any kind of
thinking or explanation as to why that but 14 years later the world's a bit different but I think
also you know the set of people who want to write essays is a different set from the set of people
who want to answer factual questions I mean you know wolf mouth are pretty widely used in
intelligent assistance the thing that's more interesting is why did the intelligence assistants
die just before LLMs happened and that's really more of a business question than it is a question
of a business and execution question more than it is a question of technology I think but I think
the you know what's what's the goal of alpha has been to to you know to take the question the
things that questions that are answerable from factual questions about the world that are
answerable that we can compute answers to and make it automatic to make those to do those
computations and that's been a very successful thing now the combination of that LLMs are doing
something different LLMs are doing things like writing essays and summarizing text and so on
and I think it's worth remembering that you know LLMs took four billion web pages and you know
what an LLM is doing is to give you something is to continue up from a prompt in a way that is
typical of what the LLM read from the web and that's and now what's interesting is that a certain
you know that things like logic were sort of extracted by the LLMs as a certain amount of
factual information that the LLM sort of thinks it knows now the LLM will will regularly just
make up stuff that's kind of roughly like what's out there might be like what some student might
write as a as a well I'm going to write something is roughly right but it's actually total nonsense
the the combination of the LLMs with computational system with Wolf-Malpha for example is pretty
interesting the challenge is you know so back in well in last December actually talking to the
opening AI guys and so on we figured out yes you know Wolf-Malpha has this is very convenient because
there's this interface language and that interface language is English that both the LLMs understand
and Wolf-Malpha understands and so if you can get the LLM to formulate its question in a way that is
sort of a a crisp question it can just go ask Wolf-Malpha and so we built that capability
interestingly we also built the capability of having the LLMs synthesize Wolf-Malpha language
code because it had read and we we got a big chunk of training data of kind of you know pieces of
Wolf-Malpha language code it had read a bunch of Wolf-Malpha language code and it was able to
synthesize those things so now if you look at the the the plug-in for chat GPT at least as of
few weeks ago I haven't looked more recently sort of interesting that about half of the what the
LLM constructs is Wolf-Malpha queries and half of it is Wolf-Malpha language code and so and then
it's running those things and it gives back the answer and often it does a good job I mean I would
say that it's kind of it's kind of terrible because you know things like math word problems have been
a long time kind of interesting AI test and there's a case where you know you give it this math word
problem and the LLM correctly decodes it into this lovely piece of Wolf-Malpha language code
we run the code we get an answer and I was writing something about this a few months ago and I'm
about to put this thing in and I think I better actually check that the LLM you know correctly
took the thing from the internal computation and gave the right answer and it didn't so at the very
last stage the thing just you know went crazy I mean it's interesting you know we've been building
an AI tutor for education purposes it's an interesting problem the number one thing to
know about building AI tutors is it's not easy yes and that's but we've been building this and
it's sort of interesting to see these this whole interface between sort of the computation
this hard computation and the layer of kind of linguistic interface that exists that you know
we think we're able I don't know we don't know yet but but it looks promising that we're able to
actually provide that interfaces kind of in a personalized way to students and so on but I
think I I think I diverted your question actually you give a good answer and you anticipated half
my next question I want to switch over to the audience but because you anticipated half my
question so using using the LLM or the chat GPT as kind of an alternative input interface to prompt
alpha is one way to think about them working together is there another way do you think there's
a way to leverage a lot of the knowledge encoded in alpha to help LLMs perform better well look
the the fact that you have a few hundred billion weights that encode three things three kinds of
things kind of the structure of language a certain amount of common sense and the third thing which
is facts about the world facts about the world don't belong there they're an incredibly inefficient
way to encode facts about the world and what will happen but it's not an easy research problem
is to factor out facts about the world from the linguistic interface in the common sense
now you know the fact is that the very interesting thing that's happened is that LLMs have discovered
something that we probably should have discovered a couple thousand years ago which is that human
language has that there's you know we've known about the syntactic structure of human language
kind of the things like you know sentences have noun verb noun in them but what we what we haven't
known is the more sophisticated construction kit that says the sentence you know the moon
eight happiness or something that that sentence isn't a plausibly meaningful sentence except in
some percent of poetic sense and so there's this kind of construction kit that goes beyond
the mere sort of the the syntactic grammar of language there's kind of a semantic grammar
of language I think that the LLMs kind of show us exists and so one question is if you say well
can we extract that semantic grammar of language and if we do extract that how much has that actually
removed the you know the LLMs are still useful as a thing to kind of you know right now we say okay
well let's go from LLM you know human language to LLM to computational language but that's
further than going from human language to a semantic grammar to to computational language
and so in fact one thing we've been working on I long wanted to build this kind of what I've
called in the past a semantic discourse language although I hate that name and if somebody can
come up with a better one I'd like it um but that it's kind of a there's been sort of this idea
that's existed well certainly since the 1600s since people like Leibniz and so on of making a
kind of he used to call it the characteristic a universalis kind of universal language to represent
things in some sort of formal way I've been long interested in building such a thing and and now
with help from LLMs it's looking to be actually possible to do that and how that will interface
with LLMs what it will look like in the end my guess is there'll be a layer of kind of neural
neti kind of linguistic user interface going to computation and a semantic language that
that then is the place where kind of the the more um where the crunchy computational stuff
happens I mean the thing to realize about LLMs one thing to realize about LLMs is you know
back in the day before we had any idea of formalization what humans figured out was just what
they could figure out sort of off the top of their head um then we got these ideas of formalization
and we started building these kind of bigger towers what LLMs are naturally able to do is the same
kind of stuff we can do sort of off the top of our head and that's you know the architecture of an
LLM is right now mostly you just say there's this you know you you've you've given a set of tokens
that is what you've said so far you say to the network what should the next token be and it ripples
through a few hundred layers of neural net and out comes the probabilities for what the next token
should be and that's that's the whole story it's just rippling through that that and the only way
that it ever gets to do sort of a more sophisticated computation is is kind of that that the next
token it makes depends on all the previous tokens it made and that's a very thin way I mean there's
a little bit you can you can kind of one fun thing we've been playing with recently it's what you
might call quantum LLMs where instead of just looking at one path of what comes next you look at
this whole whole network of what comes next and you can do things like path finding and that network
so you can say I want to get to this particular thing at the end what is the path that gets me to
that thing at the end and you can kind of think about that in a slightly different way but but
fundamentally that they're just dealing with kind of they're these different things there's this
invention of computation last last hundred years few hundred years which is this kind of different
prong that we can build that is that's different from what sort of ordinary human thinking let
let's one do so any questions from the audience let's start with you thank you for the very
interesting talk my question is about the the part of your talk that had to do with
deriving simple computational rules to explain essentially all the physics
so I guess my my question has to do with the fact that you know we have these I guess you
you call them math right physical principles things like Schrodinger's equation and things like this
that you know quantum mechanics they allow us to make predictions about outcomes of experiments or
you know the procession of a planet or something like this you know it allows us to make useful
predictions about the world and if we have a computational set of rules that allow us to
explain all of physics is there some way to go from those computational rules to mathematical
principles or other sorts of principles that allow us to make useful predictions about the world
that don't require running the computation and and how does that clash with this notion of
computational irreducibility that you mentioned good question okay so slightly complicated I mean
so first thing to say is sort of the main way that we validate that we know what we're talking
about is that we can derive the existing mathematical laws if it wasn't for the fact that we could
derive general relativity we wouldn't imagine that we have a good idea of what the sort of
low-level machine code of spacetime is okay so first thing to say second thing is there are for
example that black hole simulation that I showed actually is it's the method of going from this
underlying discrete spacetime to deduce what happens seems to be at best competitive with
and possibly much better than what people have done in the past which is to start from the
mathematical equations and then kind of discretize them so that they can put them on a computer
this is a you can think about it as a sort of an alternative way to by simulation figure out what's
going to happen in the world and because in fact when you do it sort of mathematically
when people work out black hole mergers they don't work out the pure algebraic math I mean they
typically use mathematical to do a big pile of reduction of the original mathematical structure
and then they turn it into something which is a bunch of partial differential equations
which they discretize and run on a computer so this is this is kind of going the other way
so that's that's one thing to say the the next thing is that the okay the a remarkable thing
about the universe is that anything in it is predictable what you might think is given computational
irreducibility the whole universe is going to be unpredictable one thing about computational
irreducibility is whenever there's computational irreducibility there is always there are always
an infinite number of slices of computational reducibility that exists so in other words
when the whole thing is computationally irreducible you can always find some sub-piece
that is computationally reducible and it's those sub-pieces that make up the laws that we find useful
to be narratives about how the world works and that we kind of exist in and so the really the
story of what's happened with our physics project is there's underlying computational
irreducibility and for observers like us we pick out certain slices of computational reducibility
those slices of computational reducibility correspond to the physical laws we know so one
interesting question would be will there be a time when we found all physical laws or when we've
made all inventions we figured out all of technology the answer is no and the the reason for that is
because of computational irreducibility that we found a particular slice but there will be an
infinite number of other slices and these are other views of the world other things we can say
about the world that aren't that that are different from what we've said so far and in fact you can
think of technology as being these little places where there's this whole amount of computational
irreducibility but there's this little place where we discovered this thing where we could jump ahead
this little little piece of reducibility and that's sort of a piece of technology in a sense that's
kind of the the economic value that we're providing it's kind of like you could take all the components
of an iPhone and they would have a certain value or you can put them all together into this iPhone
and you've got this thing that you can think of as sort of a little piece of computational
reducibility that that provides value economic or or sort of the ability to kind of do something
we wouldn't otherwise be able to do so so the thing to realize is there's this sort of infinite
set of possible laws to discover there's a and that's some that's the big question is which
things do we humans care about there's an infinite set of things out there that could be discovered
there's an infinite set of kind of things we can deduce about the world some of them we find useful
we turn into technology and so on and some we just sort of shrug our shoulders and say we don't know
what we're going to do with that like fluid turbulence is a good example of that for some
purposes at least it's like the fluid behaves randomly what do we do with this it's not so I
mean in terms of our so I mean I think our models provide some kind of almost philosophical framework
for thinking about this kind of this kind of interplay between computational reducibility
computational irreducibility the challenge right now with our models is there are things where they
reproduce existing physics and there are places where they don't there are places where maybe there's
a little corner where you see something that isn't existing physics and that's obviously really
interesting because you can do experiments and find out if that's really true or not and that's
that's it's a big it's it's a challenge because it's just a lot of technical detail of figuring
out okay a photon is propagating through a piece of fractional dimensional space what does that
actually do how does it affect this or that thing that you can measure but that's you know that's
the challenge and and you know I think the as I say the the way to compute things that we have
here it's a bit different from the existing way so for example in this case of general relativity
we're able to actually do a bit better than existing methods same with quantum circuit
optimization actually there's using our multiway system technology somebody who's been working on
project sort of takes quantum circuits compiles them into multiway systems does optimization
at that level and then turns them back into traditional quantum circuits and that won a
competition a few months ago for the best sort of quantum circuit optimization which was kind of fun
we actually Osama have a bunch of questions coming in from our virtual attendees so I will
alternate okay so let me and what you said basically I mean the an interesting observation you made
which is how interesting is that universe of computationally reducible things and how far
can we get but my question is let's get a bit more pedantic a bit so before Sam Altman had his
unfortunate incident with his board open AI was talking about a very near term big breakthrough
in AI whether that's truth or rumor or whatever it doesn't matter I would like to ask you do you
think there's an interesting kind of breakthrough class thing that could happen in the near term
for AI at least in your intuition well I mean okay so look at the history of the AI okay so we've
got you know McCulloch and Pitts wrote their paper in 1943 you know now we've got chat gbt it's
actually pretty similar in architecture to what McCulloch and Pitts I was just looking at the
McCulloch Pitts paper just a couple of days ago it's that they had this idea of what they called
psychons they didn't make it but a lot else in that paper did make it the psychons were units
of psychological activity basically the in any case the the you know I I personally have been a
little bit involved in this business since probably about 1980 I first sort of tried to make neural
nets do something around 1980 and I couldn't get them to do anything very interesting so and then
you know in this you know neural nets were always kind of a sideshow type thing oh there might be
models of brains we don't really know maybe brains don't work that way you know a neural net's useful
as algorithms well they've been used for OCR but you know not clear how useful they are for other
things they were always sort of a mysterious kind of sideshow type type thing and then 2011 kind of
the sort of deep learning breakthrough in image recognition happened almost by accident and there
was this jump in the ability to recognize not just the letters of the alphabet but also a few
thousand other kinds of things in the world of cats and dogs and things like this and you know if
you look at that time I think it reached like 85 percent success from that particular sort of jump
in capability in the in the years since then there's been sort of gradual incremental sort of
improvement in object recognition using neural nets you know the big breakthrough happened and then
there's gradual improvement same things happen in a bunch of other areas whether it's speech to text
other kinds of things the big breakthrough with LLMs that nobody expected was that one went from
language models to just babbled rather uninterestingly to language models that made essays that seemed
human like and that was a you know it's a big big breakthrough and I think we still don't understand
why that really happened how that happened and you know it probably well you can speculate on
on it's a science question it's a very interesting science question we've studied it a bit I can tell
you a few I think this field of LLMs science is a really important area it should be more
populated by physicists actually because that's the that's the domain that has a lot of the the
kind of relevant expertise I mean you know I've been I've been pointing out for a while you know
there's like you increase the temperature you know the chance that you pick a word that isn't the
the most highest probability word to come next increase the temperature it looks like some
student at our summer school this last year found there are two distinct phase transitions one where
the LLM you increase the temperature the LLM stops making sense second it stops making syntactic
sentences the two distinct transitions at definite temperatures why does that happen
there's got to be an answer to that and it has some combination of physics question
and a question about kind of the structure of knowledge and the structure of the way we think
about things it's a it's a it's a thing that's out there and sort of LLM science but anyway what
seems to have happened is there are these moments where there these kind of you know rapid you know
these breakthroughs where things things change and then it's kind of an incremental process and this
is typical of technology and science you know some methodology is you know is comes in some
some something happens the way I see what's what's happened right now with LLMs the you know
they have created the possibility of having rich linguistic interfaces to things and there are
many applications for that and the question of what will be successful and what will not
has to do with how you put a harness around that capability because it's like saying you know it's
it's um uh the the you know the raw capability kind of I think is what it is it will get
incrementally better but it is what it is and it's like a lot of things in machine learning people
say oh I'm going to use machine learning for this or that there's a very simple heuristic
machine learning is going to get you 80 percent maybe it's 90 percent maybe it's 93 percent you
know and Wolf Malfoy we've now got to 98 success and in recognizing our you know natural language
understanding but you know it's some percentage and some fraction of the time is going to fail
if you've got a use case where getting 85 success is a win like you're saying here are possible
search results are any of these what you're interested in then it's a win to have 85 success
if you're trying to you know launch a rocket to the moon and it's got to actually
go in the right trajectory 85 success is probably not going to be good enough yeah
and so it's a bad use case and this is the kind of interplay between what's sort of computational
and what's sort of LLM AI style and I think in terms of sort of the breakthroughs that will
happen I mean I think you know there is more to be done this kind of quantum LLM thing there's
more to be done with kind of where you can where you can go you know the planning aspects of sort
of interfacing what amounts to sort of theorem proving techniques with kind of LLM techniques
I'm not sure how well that's going to work the you know one of the lessons of kind of the
developments of neural nets particularly has been anytime you think you can be clever turns out you
it's not worthwhile and that's a it goes along with what I found in the computational universe
you say oh I know I've got this particular kind of system I know it can't do anything interesting
I can just foresee it can't do anything interesting you run the experiment my little statement to
myself and people who work with me is you know the computational animals are always smarter than
we are we you always it will do something that is completely unexpected and and that's been so
you know I'm not sure whether sort of you know carefully orchestrating these things is ultimately
going to make a difference as a practical matter you know video you know what we've done with text
will be doable with video you can learn a lot on video there's a large corpus of video there'll be a
bunch of there'll be a breakthrough as you know it manages to learn sort of intuitive physics
from videos and things like this certain amount of human behavior stuff from videos probably
and that will be you know that's another thing and and that's but I think what you'll see is
these set of discrete sort of jumps as as different things become possible and you know the training
data in the world is is you know we're kind of running out of that there's I mean there's a there's
about a hundred billion not yet tapped actually we're involved in in possibility of tapping
some more of that of other kinds of material that exists in textual form that hasn't yet been used
for training I don't know how useful that will be I don't know at what point you saturate in terms
of yes we know human language and yes we know common sense but my feeling is that the big value
is coming in the application of of LLMs and so on and figuring out how you put
the right harness around them to make them useful and and that's some and it's kind of in fact the
the kind of you know we built into our language now a bunch of LLM functions
where you can from the computational language you can access the LLM and that's a pretty useful
way to sort of understand and and set up kind of the harness around the LLM to make the LLM do
what it does well and then sort of the the computational structure go around that cool
shall we take a question from online sure so a few a couple hundred people are still here
with you till the very end I'm going to take a question from Michael Carell what's so great
about computation as a metaphor structuring principle for physics or cognition we've been
wrong about metaphors for cognition in the past parentheses the brain as watch telegraph switch
board or even metaphors within computational views what makes us think we've gotten the right one
this time okay so it's a good question I mean I think that the the thing that's interesting
is that this idea of rules for specifying things that idea is pretty much as oldest civilization
and it's you know the question of well is it this particular kind of rule is it the rule that
runs with you know that makes a watch work is it the rule that wakes you know integrals work and
so on those particulars yes those particulars are are specific possibilities the general idea
that something follows some set of rules seems to be a you know a pretty fundamental idea I mean
we're we're kind of stuck with that idea that's a that's a thing if we want to have a theory about
how the world works then the idea that there are rules that determine what happens is something
that we're pretty much stuck with but I think it's a it's a good you know did we did we finally make
it well you know if it turns out the experiments get done and this theory of physics that we built
is validated um it's you know frankly it's it it seems at this point to me at least quite impossible
that it could not be true because too much has fit together for it to you know for it to be off track
but if that happens then we can say well we reached you know in some direction we reached the end
we know our universe is set up this way we can know that we can so another thing to explain
whenever what is natural science you know natural science is this bridge between the universe as it is
and our attempt to have a narrative in our minds for how the universe works so in other words the
universe does what it does and the question is can we have a way of thinking about that that we
can understand and so there may be many ways of thinking about it that that that is more on us
than it is on the universe there may be many ways that aliens could understand the universe
that are not the ways we understand the universe but I think that this idea of of operating according
to rules is this thing that has been you know a feature of the way we have thought about things
from the beginning of our of our history and that that seems like a pretty solid thing if we're
trying to do this thing a bridging between the universe and and the way that the way that we
think about things I want to say one thing about cognition and LLMs okay so so people had wondered
for a long time how do brains work and people said well brains do things that are so sophisticated
that even the laws of physics as we know them aren't sufficient to cover what brains do there
must be some funky extra stuff quantum mechanics whatever else that's going on in brains LLMs
are a very good data point that isn't true because people had said you know in order to do all these
things that we do and all the language and everything like this we got to have all kinds of
stuff we don't understand turns out just this neural net this simple rule-based neural net
it pretty much does it and so you can and in fact what's happened in neuroscience for instances
back in the day my my friends in neuroscience always said well we got these neural nets
but they're not really models of brains they're really some idealization that may be useful for
technology etc etc etc now that neural nets clearly do things that are very brain-like
that that that narrative has reversed and now it's a question of well you know we've got we
know what the core mechanisms are now let's see how we map those into what we can see biologically
is your question quick all right so I don't know if you have a mic but you can I'll repeat your
question just stated for example if we want to learn new interesting structures how can we use
AI to discover them without you know doing simulation and then looking for patterns in those
can we actually use it to find out yeah that's a good question right so the question is using AI
go ahead yeah you know can AI solve science this is a there's a very current question
and that's not a short question but anyway actually we have a project right now that is
you know day by day is is making progress on this question so here's here's what we seem to be finding
not not this this thing hasn't fully landed yet so I don't know the full story but so a question is
what can you predict with another lamp what can another lamp predict I show it pictures of cellular
automata things like this can it you know can it just say this is what's going to happen
can it to what extent can it at least find the pockets of reducibility we don't know fully the
answer to this but there's clearly a boundary we can see there are cases where it just doesn't work
and there are cases where it definitely does work and so the you know this question of can it notice
patterns that we haven't noticed so in protein folding for example there's been a fair degree
of success a little bit less success perhaps than people sometimes imagine but there's been
some success in taking I mean when you if you feed a random sequence of amino acids and say how
does this fold the answer probably won't be right but in things that are at least somewhat close to
proteins that have already been but whose structure is already known there's there's a lot that can
be said and the question is why does that work and the general belief is that it works because
there are aspects of protein structure which are features that we humans have not noticed
that the that the system noticed okay and and so this idea that it's noticing things that we didn't
notice is is going to be a very common thing I mean even even an image identifier that's telling
cats from dogs how does it tell cats from dogs well it's found some feature of those pictures
maybe it's the pointiness of the ears or something it's found some feature that allows it to make
that distinction we don't you know that's not necessarily a feature that we know about it's
also very hard for us to tell what feature it found because we don't have a way to kind of
go inside its mind and convert its way of thinking about things to our ways of thinking about things
so you know in terms of of what can we learn about science so first question is can the LLM
when there is some sort of feature that allows prediction to happen can the LLM find that and
be able to make predictions my guess is that that will be generally somewhat successful
but I think computational irreducibility is kind of a big sort of you know it's a big monster
at the gates there that will prevent certain kinds of things from from being possible but
some things where a human could go and find these these rules yes the LLM might be able to do that
more efficiently more automatically first point so second point is um in well another point is
can the LLM invent something that is a way of explaining to us humans how something works
that's essentially the problem of the AI tutor can the can the system learn enough about us humans
that it can give us an explanation that is useful for us as humans and my guess is there'll be some
success in that in other words if I want to learn some new thing you know how difficult is it to
learn something well you know if I had an AI that knows everything I know for me personally I happen
to be a enthusiast of personal data so there's 50 million words that I've said or written that are
out there so I can train an LLM to be a pretty good you know simulation of me and given that what
you know if I then if I know if the LLM knows or the AI knows what I know and then I say well
I'm today I'm trying to learn about macroeconomics you know I want to you know how do I understand
this there's a reasonable chance that the LLM is going to say well you can relate that to this thing
you know and that thing you know and I have a much easier path to be able to learn those things
it's another thing another thing to say about about what LLMs potentially do one of the
interesting things that LLMs do is they essentially do what one might call sort of a generalization
of statistics that relates to text so normally you know you have a bunch of numbers you say what's
the mean what's the variance of these numbers these kinds of numerical sorts of things but if you've
just got a big lump of text and you say what was the most popular hat style in the 1950s that's a
textual question and that's a question where there's not you know turning that into numbers
is not so easy but LLMs can actually go purely at the textual level and answer a question like that
and so there's this pure sort of textual statistics you might call it it's not really statistics in
the ordinary sense of numbers it's some new kind of thing that can be sort of deduced textually
and I think the the other one thing that will happen is there are these you know one way that
science advances is through these kind of analogies between one field and another to notice that oh
what happens in metamathematics is like what happens in general activity well that's something
that you know I'm very proud of being able to notice that as a human because I know something
about those two fields and I can kind of connect them up but I suspect LLMs are going to be able
to figure those kinds of things out too because they're going to be able to see that the structure
just like they can they can kind of extract logic from just the patterns of sentences so they'll
extract principles from from kind of the noticing that these two different areas work the way they
work but I mean this question of can the LLM invent a formalism that is useful for us humans
that's a that's an interesting good question I'll tell you one little micro data point so you know
I spend a lot of my life doing computational language design and you know we quite often
livestream these things and so on but one of the things that's new in the version of
Wolfman language it's just about to come out is there are new functions that are in there
that were suggested by an LLM so in other words the LLM has looked at all this code it knows what's
people are asking about it's seen what's out there on the web it said oh there's a function
you should have a function called digit sum and I think it even suggested that name and it's a
pretty good idea it's taken sort of the average of what people out there want and yes you can you
can digit sum is something that's a trivial kind of idiom in Wolfman language but it's noticed
that that's an idiom that's a repeated idiom and that's kind of the essence of language design
and so we're able to take that suggestion from LLM by the way in terms of how LLMs will be used
compiling the wisdom of the crowds basically yes yes into I mean what one thing to say about how
LLMs will be used I have a feeling one of the big uses of LLMs will be offline uses people are a
lot of constant people are concentrating on I've got an LLM in the loop and I'm typing something
and an LLM is responding to that for example for our purposes when we do data curation LLMs have
basically speeded up many parts of our data curation pipeline by a matter of two not a hundred
but two and two is worth having but it's not um but I think that these these offline uses where
you use the wisdom of the LLM and then you burn it into a piece of technology that's going to be a
an important thing given given that we'll well over time and before we I'm very bad at short
answers I apologize I'll ask you one last question given your amazing optimism about
the capabilities of LLMs now and you alluded to some of this in in your talk many have claimed
that AI poses a future existential threat to humanity others disagree vehemently what's your
view on this and what do you think are kind of the main AI threats of today but let's let's talk
about the existence yeah yeah right I mean okay so you know more and more things in the world will
be delegated to AIs that's just just as a matter of convenience because things have to happen quickly
you know it's we're going to delegate stuff to AIs and then the question is okay so you know
does something terrible happen as a result of that the thing to understand is there's all
this stuff going on in the in the world of the AIs and the kind of underworld of the AIs the world
is being run by AIs let's say and we say well we don't understand what these AIs are doing that's
terrible how can we possibly exist in a situation where the world is being run by forces we don't
understand actually we've been there before because that's the situation we're in with nature
nature is doing a lot of stuff we don't understand and we have managed to find ways to exist we find
found niches where we can sort of carve out our existence you know within nature and it works just
fine I mean occasionally bad things happen you know hurricanes develop and bad things happen
and we don't understand quite why those happen and you know we gradually maybe can do a science of
you know the atmosphere or something and figure that out with AIs the same is going to happen
there's going to be lots of stuff that goes on and mostly it's going to be just fine and we
understand how to live in that niche and occasionally some crazy thing will happen
and we'll say we better build more science that allows us to understand sort of what's happening
in the underworld of the AIs so to speak so the first thing to say another thing to say is well is
there going to be anything for the humans anything left for the humans to do or we have automated
everything it's by definition we will not automate everything because a lot of what has to be done
is to figure out what we want to do and there is no sort of intrinsic way that the AI does that now
there's a practical matter I looked at the last 150 years or so of what what people have done as
occupations so to speak and here's what you see in you know in the 150 years ago agriculture was the
biggest chunk of sort of US occupations and then it got automated and so that chunk shrunk and you
see the same thing happening over and what happened to that chunk what happened to those people well
the answer is they went into lots of different occupations many of which were enabled by the
automation of agriculture and the same thing has happened over and over again that's something that
takes a lot of people to do it it ends up getting automated that thing goes to almost zero people
but those that the the very automation of that thing enables a bunch of new capabilities
which then provide a more fragmented kind of story and it's a pretty common thing you see in
in economies around the world more developed economies are more fragmented in terms of the
occupations people do and that's that seems to be you know as as you automate more you and what's
really happening there what's really happening there is the fragmented occupations are sort of
the frontiers where it's still like what are we going to do in this area and that's something that
takes humans and it's just like you know right now it's kind of fun to see the new occupations I'm
always I you know at a company I I often am entertained by the fact that I'll invent some
new job category of a thing that people have never heard of before like LLM scientist or
or you know AI psychologist or you know prompt engineer or prompt magician yes yes right exactly
and these are things that you know it's gosh those have never been and by the way prompt
engineering is a great use for the you know people say well you're going to be computer
programmer you're going to do stem type stuff the best prompt engineers are the best expository
writers so it's a different skill set that and that happens because the LLMs were trained on
you know the LLMs understand just like other humans understand and so it's sort of not surprising
that it's expository writing that turns out to be the important skill there so by the way the
combination of expository writing and computation is writing good computational language that that
in itself is another occupational area is is computation editors so to speak who can turn
bad computational language into good computational language and so on there are there are just these
many different opportunities that that get opened up so I'm you know I think us humans you know
it's worth realizing if you look at the sort of long arc of history and you say what do people do
a thousand years ago what do we do what do people even think was worth doing a thousand years ago
and then what do we do now many of the things we do today didn't look like they were worth doing a
thousand years ago I mean you know I walk on a treadmill why do you do that it's you know what
a crazy thing to do it's it so you know I think that's what we'll see and one of the things that's
funny about understanding history in the future and so on is that you might say oh you know everybody's
just going to be playing video games that's a terrible outcome looks to be a terrible outcome to me
right now from from my viewpoint and you know the you know in 2023 or whatever but it's you know to
the internal impression of the humans so to speak may be a very different story in terms of
of you know what will happen in terms of of sort of when the ai's run central banks when the ai's
do all these kinds of things and and many of those things will happen and and at a practical level
there's a question of what can you do with this how can we make the ai's do things we want to have
them do and not do the things we don't want to have them do so first question is well what do we
want to have them do and so you know I've thought a bit I will say this is a for me it's it's an
unfinished question I mean this first question is okay you're making constitution for the world
for a country let's say hopefully not for the whole world hopefully for individual countries
you're making constitution in modern times you've got ai's what do you what are the provisions for
example can an ai own things does an ai have to have an owner you know how do you decide what to
do do you have a democracy where people vote and and check boxes or do you have a prompt
autocracy where everybody writes you know a prompt and it gets fed into an ai and the ai
kind of decides what to do what do you do how do you think about what's possible and first question
is what you know is there a you know what do people want and the answer is obviously not everybody
is going to want the same thing and that's you know so the idea that you know there's the global
view this is this is a very bad idea I mean this is you know this is you know this this won't work
just as you know it hasn't just not a not a thing that that works in the way that humans who believe
in free will and things like that set the world up but so so first point is I think that you know
I've thought quite a bit about this kind of ai constitution question and what sorts of provisions
you might imagine in wanting to set up it's not easy to understand how those constraints get applied
etc etc etc and certainly there's not going to be one kind of this is the ai constitution of the
world we're finished type thing um but even figuring out those provisions is surprisingly hard
and and I've I've you know it's surprisingly little has been done on this second thing the thing
that I've now come to think more about because I think it's it's a more promising direction
is if one ai if there's just one ai in the world I think it's a very brittle situation
the reality is there's not going to be one ai in the world there's going to be a whole society of ai's
and the society of ai's will operate in some way that probably has many of the same dynamics as human
society and the society there will be some inexorable features of the ai society just as
presumably there are inexorable features of human society and economics and things like this
so there's a science question about what are those inexorable features what does the society of the
ai's look like and how do we you know are there dynamics for the society of ai let me give you
one example it's unthought out okay so but let me make a meta comment the meta comment is if you
look at the history of things like governance and democracy and so on you know big things happened
a few hundred years ago that was a time when there was a lot of political philosophy was being thought
about and people figured stuff out in political philosophy and that turned into actual governance
systems that have been reasonably successful over the last few hundred years and you know now is the
moment this is the great moment for political philosophy again it's you know and I don't know
that there are very many people who've stepped up to figuring this out but there will be ideas
that will be and they won't be promptocracies probably but it'll be something and there'll be
ideas that are different new ideas enabled by the fact that we live in an ai technological
society so to speak that that become possible I'll give you one example of a kind of thinking
and we will end on that example okay fine now maybe this is a this is maybe not an upper okay so
here's the question question is in human society people sort of to some sense do the right thing
because if they don't do the right thing they suffer for ai's that's a more complicated issue
because so far as we know ai's don't suffer so how do you get an ai to do the right thing if it
won't suffer by doing the wrong thing and and so but now what you realize is actually you already
have this issue with humans because you know internally to you how you feel but anything else
is an extrapolation it's just you're guessing that you have empathy for some other thing so okay
so you can you start thinking about the ai's and what is the operational again I'd say I haven't
figured this out but I just I give this as an example of the type of thinking I think one has to do
is is you know if there's an ai and it did the wrong thing and it is then removed from ai society
okay whether the ai internally suffered or not who cares because what matters to the world is that
it was removed from ai society so to speak and so what you realize is that that this kind of the
societal you know is there a dynamics of that society that causes the ai that did the wrong
thing to not be trusted by the other ai's etc etc etc that be to be sort of removed from ai society
having no kind of imagined not imagining that you are you know the ai itself is making this you
know making this decision it's as I say not properly thought out but that's just as a
for people interested in philosophy of these things that's just sort of a you know the beginnings
of a thought about how to think through you know sort of responsibility personal responsibility
in the time of ai interesting okay with that please join me in thanking Stephen for this
extra long edition of our distinguished lecture thank you thank you everyone and see you next
semester with the distinguished lecture series
