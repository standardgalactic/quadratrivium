start	end	text
0	7920	This animation was generated by a short piece of Python code.
7920	14120	It uses the math animation library manum from 3blue1brown to make this square fractal.
14120	19640	It is recursive, the squares are inside of themselves, and the code uses a recursive function
19640	21160	that calls itself.
21160	27000	I've used manum many times before in previous videos, but I did not write this code.
27000	33060	It was entirely written by ChatGPT, the AI program that can write programs.
33060	37760	This was its first try when I asked it to give me any creative animation using manum,
37760	38760	and that was GPT3.
38760	44280	Here's what GPT4 gave me for a similar prompt.
44280	48360	For this one, I changed a few parameters so it would add more branches and slow it down
48360	56360	a bit, but it was still mostly made by ChatGPT in one try.
56360	60740	It doesn't always work out that well of course, this one took a few tries.
60740	66420	The first time it tried to load the file path2yourheart.svg which does not exist at all, and the second
66420	70040	time it called this .weight function that doesn't exist.
70040	73440	It makes stuff up sometimes, what they call hallucinations.
73440	78720	Nonetheless, after explaining the problems to ChatGPT, it debugged its own mistake, tweaked
78720	83360	the code, and you get this weird pulsing star thing.
83360	87800	I have been having way too much fun playing with ChatGPT and doing all kinds of things
87800	90560	with it, especially creative coding challenges.
90560	95560	I would call ChatGPT creative for the same reason that I would call AI art creative.
95560	100960	It can intelligently combine the languages, methods, and ideas that it is trained on.
100960	109120	Just look at this self-portrait it made, again on the first try without any human revision.
109120	114280	All the manum animations you see in this video were at least partially written by ChatGPT.
114280	118560	Typically, it writes the brunt of the code, especially the boilerplate stuff, and then
118560	122000	I finish it up, focusing on the visual stuff.
122000	125800	Sometimes I'm just picking colors and tuning parameters, but often I'm debugging error
125800	128880	messages and rewriting code myself.
128880	135280	ChatGPT has major limitations, but is still a surprisingly helpful debugger and pair programmer.
135280	139840	It's made to program with you, and works best if you at least kind of know what you're
139840	140840	doing.
140840	144480	To try it on a more difficult task, I wanted to implement an upgraded version of an old
144480	147680	evolution simulator called Biomorphs.
147680	152880	The original Biomorphs worked by making variations of branching recursive tree structures and
152880	156880	allowing you to select one for the next generation, where you could then select again from its
156880	157880	offspring.
157880	161080	It's the kind of simple evolution simulator I love.
161080	165880	I asked ChatGPT to make a web page version of Biomorphs, but to creatively expand on
165880	171020	the original idea using 3.js, a 3D library for the browser.
171020	175480	This is its original output, with no human revisions, and it's a good start.
175480	179560	After a lot of back and forth and a few hours of pair programming and debugging, this is
179560	182840	what we ended up with, Biomorphs 3D.
182840	187560	It uses recursive branching structures of different multicolor 3D shapes, all determined
187560	189840	by a set of 11 genes.
189840	193160	You can click on the Biomorph you like the most, and the other three will turn into its
193160	197280	mutated offspring, and you can continuously evolve from there.
197280	201320	They can easily grow very large and complex and lag out your browser, but you can just
201320	203840	select for smaller ones.
203840	208160	The final product was much more of a joint effort, and while I did change some important
208160	212440	elements of the program, especially visual things that I couldn't show ChatGPT, most
212440	215640	of the code, by word count, is AI written.
215640	220760	I am not super familiar with 3.js, and I would absolutely say that ChatGPT made it
220760	226520	easier to get started with my idea, and not get stuck setting up the code or reading documentation.
226520	231920	That means I don't fully understand everything about this program, and debugging it was tricky.
231920	236400	It's a very simple project, and probably still has some hidden flaws and limitations,
236400	239200	but it is still fun to evolve the Biomorphs.
239200	242960	You can play with this program yourself, there's a link in the description.
242960	250560	In Biomorph Space, you can find suns with planets with moons, molecules, minerals, organic
250560	254240	shapes, trees, and atoms.
254240	259760	Have fun exploring.
259760	265640	ChatGPT, this young new programmer, is a very impressive and strange piece of software that
265640	268480	can write other pieces of software.
268480	273600	It is code that writes code, a programming program, if you will.
273600	277760	It's not a very traditional program, it is a large language model, which means it's
277760	284080	a big neural network that is trained to imitate a huge dataset of human written text and code.
284080	288040	As a piece of software, its source code is complex and layered.
288040	292600	In a sense, the largest and most important part of that source code is the data.
292600	297160	The data is compiled into the model through the training process.
297160	301640	I like to think of large language models as machines that sit on the end of a sentence
301640	305880	and generate the next most probable word, given all the previous words that came before,
305880	309400	including the ones it just generated.
309400	314560	These models are often derisively called glorified autocomplete, or next-word prediction machines,
314560	316440	which is a perfect description.
316440	320720	However, to make a model more conversational and controllable, you have to refine it with
320720	322600	more precise training.
322600	328240	ChatGPT was further trained using a novel method called RLHF, Reinforcement Learning
328240	333360	with Human Feedback, where good behavior is reinforced with positive rewards, and bad
333360	336440	behavior is discouraged with negative rewards.
336440	340360	The reward function is learned through human feedback, where people select the responses
340360	342200	they like the most.
342200	346240	Under this paradigm, the model is more of an agent playing a game, where the high score
346240	349240	comes from following human instructions.
349240	354800	These relatively simple methods and architectures, when scaled up with big models and huge, high-quality
354800	357880	datasets, turn out to work pretty well.
357880	362280	In terms of programming skill, GPT-4 is clearly limited, but still pretty good.
362280	366080	It's not the best programmer I've ever met, but it's also not the worst.
366080	368160	It certainly has broader knowledge than I do.
368160	370080	It can program in way more languages.
370080	374400	In one case, it even taught me about an obscure function in PyTorch that solved a problem
374400	379440	that I couldn't solve by searching the internet, and now I can generate fractals on my GPU.
379440	383280	All this it can do while telling some very bad jokes in the comments.
383280	386240	This is all great, but it's also a little scary.
386240	388760	Programming is my day job, and I like programming.
388760	394040	Do I really want ChatGPT to program everything for me?
394040	398040	For the moment, it cannot do that, but one can imagine a future model that is more of
398040	402840	a fully automatic programmer, something that could maybe interact with a command line,
402840	405600	as ChatGPT can sort of do now.
405600	410480	It could potentially write and execute files, read outputs and error messages, automatically
410480	414600	debug and converse with human managers.
414600	420040	Experimental AI agents like this already exist, like AutoGPT or BabyAGI.
420040	423960	Give it an initial starting prompt, a goal to accomplish, and it will run off on its
423960	424960	own.
424960	429800	These agents are powered by GPT-4, and take advantage of its many emergent capabilities,
429800	435720	things like hierarchical planning, breaking down tasks into sub-tasks and sub-sub-tasks.
435720	440200	They also use self-reflection, where the agent is automatically prompted to ask itself if
440200	443080	it really completed its instructions correctly.
443080	447000	This way, it can catch its own mistakes without being told what they are.
447000	452000	These agents do not work great, they will fail for most tasks, and often get caught
452000	453400	in infinite loops.
453400	456520	However, they can and will be improved upon.
456520	461400	A future version of GPT or some other language model could be trained specifically as an
461400	467040	autonomous agent, and could really start to be more of a fully automatic programmer.
467040	472400	Other kinds of auto-prompting GPT systems exist, such as Hugging GPT, which is specifically
472400	477080	designed to build machine learning programs by composing different AI models into a working
477080	478080	solution.
478080	482440	It's also not that reliable, but you can theoretically use it to build all kinds of
482440	483440	things.
483560	487560	It could even, if you think about it, build another large language model.
490560	496560	So, if ChatGPT is a programming program, no less a machine learning program that can
496560	502560	write machine learning programs, could ChatGPT program itself?
508000	512000	A piece of code that writes itself is called Aquine.
512000	516880	Here's an example, written by ChatGPT, probably just copied straight from its dataset.
516880	519480	This elegant little Python script is a Quine.
519480	523640	It takes no inputs and outputs exactly its own source code.
523640	528360	It is a self-replicating program, a replicator, and we can come up with different kinds of
528360	531280	replicators that aren't technically Quines.
531280	535600	For instance, here's a more custom script, also written by ChatGPT, that copies its own
535600	540800	file contents to a new file, then executes that file as a child process.
540800	545120	The child process then does exactly the same thing, makes a copy of itself, which then
545120	549520	makes a copy of itself, which then makes a copy of itself, which then stops after 10
549520	553080	files, otherwise it would fill my hard drive with copies of itself.
553080	557480	While the script is not technically a Quine in the strict sense, it still self-replicates,
557480	559720	and we might say it Quines.
559720	565360	A computer virus also Quines, by automatically copying itself from machine to machine, though
565360	568800	with much more nefarious purposes.
568800	571360	ChatGPT is not a Quine.
571360	575480	It was not trained on its own source code and thus can't reproduce itself unless we
575480	580240	give it its own source code as input, which, for a Quine, is considered cheating.
580240	584760	But let's cheat anyway, because this takes us to a very interesting place.
584760	589000	Rather than just self-replicating, could we give it its own source code and ask it to
589000	591520	self-improve?
591520	597180	Now, again, GPT's source code is an incredibly complex piece of software built from layers
597180	599600	of programs and processes and data.
599600	602440	There is no way to feed all of that into GPT.
602440	606860	But we could start by just giving it small pieces of its source code, say the stuff that
606860	610940	defines its architecture, or training process, or data cleaning, or whatever.
610940	616940	GPT4 might not be able to offer any improvements, but I bet it could come up with something.
616940	621980	Maybe it could optimize a small function, or just one line of code, fix some minor overlooked
621980	626840	bug, or just do some organization and documentation and commenting.
626840	630960	Throw that in with all the work of human developers and AI researchers, and the end
630960	634520	product would be the next iteration of GPT.
634520	637600	Could GPT4 help build GPT5?
637600	640560	Now, here's where things get interesting.
640560	646640	GPT5 would be a better programmer than GPT4, so let's give it its own source code again.
646640	652000	If it really is a better programmer, it will be able to improve itself even more than before.
652000	653400	You can see where this is going.
653400	655980	Do this over and over and over.
655980	660700	This is AI building AI, a strange loop.
660700	664500	If it gets advanced enough, you could do something like what AutoGPT does.
664500	666720	Let it be a fully automatic programmer.
666720	671900	Give it direct access to the entire project, the source code, the datasets, everything.
671900	677140	Let it read and write and execute files, plan and reflect and debug and train.
677140	682220	Maybe even innovate and experiment and test ideas, and iteratively improve on its own
682220	687820	next version piece by piece, alongside human developers, until it's ready for full deployment.
687820	692820	Now, it needs to be improving itself according to some goal or metric.
692820	696900	You would want it to improve as a chatbot, as well as a programmer, and across a growing
696900	699660	set of other tasks and domains.
699660	704940	You could use OpenAI's own evaluation framework and progressively tack on new metrics, tests,
704940	708260	games, and different types of inputs and outputs.
708260	711940	Its goals would also be defined with natural language and a starting prompt, like you do
711940	716180	with AutoGPT, and this would be a much more open-ended goal.
716180	718620	Something like, develop the next iteration of yourself.
718620	723180	It should be a truthful, unbiased, helpful, rational, friendly chatbot that is an excellent
723180	726100	programmer, etc., etc.
726100	730500	You could only really do any of this, of course, with a far more advanced model than GPT4,
730500	735600	but current chat GPT can already reflect on its own limitations and propose ideas for
735600	738500	how to self-improve.
739500	744060	Now, if you, like me, are skeptical that a next-word prediction machine with shallow
744060	748780	reasoning and hallucinatory knowledge could actually do any of this, simply consider the
748780	753660	fact that you don't need to solve all of these problems to get the process started.
753660	756620	You do not need to start with a perfect programmer.
756620	761620	All you need is a halfway decent programmer, one that is just barely good enough to make
761620	764820	the slightest improvement to its own source code.
764820	767980	The human developers would still be doing almost all the work.
767980	771980	Eventually, it may turn out that large language models need to be replaced with some other
771980	776300	completely different paradigm, but so long as we're still dealing with a program that
776300	781060	is good at writing programs, it should still be able to self-improve.
781060	787700	We should not underestimate the immense potential of self-replicating code and recursive self-improvement,
787700	789580	even from simple beginnings.
789580	793380	After all, we are the product of self-replicating code.
793380	794580	That is not a metaphor.
794580	799900	Your DNA, the stuff that makes you and your brain and your intelligence, is genetic code
799900	801980	that makes copies of itself.
801980	804540	It is code that writes code.
804540	806060	That writes code.
806060	807620	That writes code.
807620	814060	DNA self-improve through the slow process of mutation and natural selection, trial and
814060	815140	error.
815140	820700	By contrast, our programming program would evolve through deliberate, foresighted, goal-oriented
820700	821700	self-improvement.
822420	827540	It's like having an organism that can understand and edit its own genetic code, and thus make
827540	831140	itself better at editing its own genetic code.
831140	837660	A recursive self-improving AI might begin slowly, but gradually accelerate as improvements
837660	839780	accumulate and compound.
839780	844540	It's a positive feedback loop where it improves the thing that does the improving.
844540	849780	The smarter it gets, the smarter it can make itself in the next iteration and faster, too.
849780	854660	It's conceivable that a far future version of a self-improving language model could start
854660	858500	to outweigh the contributions of its human developers.
858500	863660	A really creative one could potentially invent novel algorithms or neural architectures or
863660	868420	new programming languages that we wouldn't fully understand.
868420	873860	One day, it could write the next iteration of itself without any human input at all.
873860	876740	What would the iteration after that look like?
876740	882540	Could it become super-intelligent, better than any human at any cognitive task?
882540	886380	At this point, things would really take off the breakneck pace of AI development.
886380	888500	Today will seem like a snail's pace.
888500	893700	The program will continue to improve and improve and improve faster and faster and faster,
893700	895020	smarter and smarter and smarter.
895020	908180	The process I've just described is called an intelligence explosion, and we seem to
908180	911020	have just walked through a recipe for one.
911020	916100	A self-improving AI causing an intelligence explosion is an idea that has been described
916100	922060	and predicted by many different people, and it is as promising as it is terrifying.
922060	927540	On one hand, a friendly super-intelligence could be the best thing we've ever made.
927540	934500	It could cure diseases and invent technology and help us solve monstrously difficult problems.
934500	941100	On the other hand, how could we possibly hope to understand or control such an explosive
941100	946420	process, one that results in something that is smarter than all of us?
946420	949700	There are many ways that this could go horribly wrong.
949700	954660	For instance, you could imagine a particularly nasty computer virus that's not only written
954660	962380	by an AI but is an AI, one which self-improves as it copies itself throughout the internet.
962380	967140	The essential ingredient to kick off this explosion, the fissile material for the atom
967140	973580	bomb of intelligence, is an AI program that is good at writing AI programs.
973580	978740	We are currently in an arms race to build ever more powerful and potent versions of
978740	980620	exactly that.
980620	983380	It seems we are building a bomb.
983380	989380	Can you see why there is growing anxiety in the AI community and a desire to slow things
989380	990380	down?
990380	995140	Okay, let's take a step back.
995140	1000260	An intelligence explosion is a bit of a science fiction idea, and it's prone to over-exaggeration
1000260	1002620	because it's fun to speculate about.
1002620	1008060	I'm not suggesting that tomorrow GPT-4 will wake up and start pumping out neurotoxins.
1008060	1013020	In practice, we will face many challenges before we get a truly self-improving AI, if
1013020	1015220	that's really possible.
1015220	1019300	Maybe development will be more linear, or taper off pretty quickly, or we could hit major
1019300	1020820	roadblocks.
1020820	1024740	Maybe the current tech tree we've invested so much in will just dead end once we run
1024740	1028340	out of data, and there will be no further way to improve it, no matter how good of a
1028340	1030660	programmer you are.
1030660	1034900	Maybe these next-word prediction machines just aren't powerful enough to recursively
1034900	1037140	self-improve.
1037140	1038740	But maybe they are.
1038740	1042940	No one really knows, including the people that made GPT-4.
1042940	1048060	The only way to know for sure is to try, and that's the scary part.
1048060	1053740	In my opinion, we shouldn't simply assume that self-improving language models are impossible
1053740	1055740	or completely safe.
1055740	1060660	It seems perfectly reasonable to me that a sufficiently competent programming program
1060660	1067100	tasked with recursive self-improvement is both possible and inherently unpredictable.
1067100	1071220	It may take a while to get there, but small-scale versions of self-improving language models
1071220	1073460	will probably be built soon.
1073460	1078540	There is currently an ongoing project for a self-improving auto-GPT, and I might play
1078540	1080980	around with the idea myself in the future.
1080980	1085380	These are safe, small-scale experiments that don't even touch the core model, but someone
1085380	1090180	with substantial resources could try building a full-scale version.
1090180	1095740	OpenAI could, for instance, specifically train a future GPT model to be good at programming
1095740	1101860	large, complex software, especially language models, and then directly ask it to self-improve.
1101860	1105260	The first iteration might not be great, but give it time.
1105260	1109020	If someone is going to seriously try making something like this, they should take the
1109020	1111060	risks seriously too.
1111060	1117020	You should not, for instance, give a self-replicating, self-improving AI direct access to the internet.
1117020	1120660	At least until you know it's properly aligned with human values.
1120660	1122660	But that's the subject of another video.
1122660	1127380	I know this sounds like science fiction, and it is, but science fiction has a way of becoming
1127380	1128620	reality.
1128620	1134260	Self-replication and self-improvement are powerful, explosive tools, and we must wield them with
1134260	1135900	great care.
1135900	1141220	If we do this right, we could create something that is less of a violent explosion, and more
1141220	1146340	of a beautiful, blooming intelligence, the most valuable of all inventions.
