1
00:00:00,000 --> 00:00:07,920
This animation was generated by a short piece of Python code.

2
00:00:07,920 --> 00:00:14,120
It uses the math animation library manum from 3blue1brown to make this square fractal.

3
00:00:14,120 --> 00:00:19,640
It is recursive, the squares are inside of themselves, and the code uses a recursive function

4
00:00:19,640 --> 00:00:21,160
that calls itself.

5
00:00:21,160 --> 00:00:27,000
I've used manum many times before in previous videos, but I did not write this code.

6
00:00:27,000 --> 00:00:33,060
It was entirely written by ChatGPT, the AI program that can write programs.

7
00:00:33,060 --> 00:00:37,760
This was its first try when I asked it to give me any creative animation using manum,

8
00:00:37,760 --> 00:00:38,760
and that was GPT3.

9
00:00:38,760 --> 00:00:44,280
Here's what GPT4 gave me for a similar prompt.

10
00:00:44,280 --> 00:00:48,360
For this one, I changed a few parameters so it would add more branches and slow it down

11
00:00:48,360 --> 00:00:56,360
a bit, but it was still mostly made by ChatGPT in one try.

12
00:00:56,360 --> 00:01:00,740
It doesn't always work out that well of course, this one took a few tries.

13
00:01:00,740 --> 00:01:06,420
The first time it tried to load the file path2yourheart.svg which does not exist at all, and the second

14
00:01:06,420 --> 00:01:10,040
time it called this .weight function that doesn't exist.

15
00:01:10,040 --> 00:01:13,440
It makes stuff up sometimes, what they call hallucinations.

16
00:01:13,440 --> 00:01:18,720
Nonetheless, after explaining the problems to ChatGPT, it debugged its own mistake, tweaked

17
00:01:18,720 --> 00:01:23,360
the code, and you get this weird pulsing star thing.

18
00:01:23,360 --> 00:01:27,800
I have been having way too much fun playing with ChatGPT and doing all kinds of things

19
00:01:27,800 --> 00:01:30,560
with it, especially creative coding challenges.

20
00:01:30,560 --> 00:01:35,560
I would call ChatGPT creative for the same reason that I would call AI art creative.

21
00:01:35,560 --> 00:01:40,960
It can intelligently combine the languages, methods, and ideas that it is trained on.

22
00:01:40,960 --> 00:01:49,120
Just look at this self-portrait it made, again on the first try without any human revision.

23
00:01:49,120 --> 00:01:54,280
All the manum animations you see in this video were at least partially written by ChatGPT.

24
00:01:54,280 --> 00:01:58,560
Typically, it writes the brunt of the code, especially the boilerplate stuff, and then

25
00:01:58,560 --> 00:02:02,000
I finish it up, focusing on the visual stuff.

26
00:02:02,000 --> 00:02:05,800
Sometimes I'm just picking colors and tuning parameters, but often I'm debugging error

27
00:02:05,800 --> 00:02:08,880
messages and rewriting code myself.

28
00:02:08,880 --> 00:02:15,280
ChatGPT has major limitations, but is still a surprisingly helpful debugger and pair programmer.

29
00:02:15,280 --> 00:02:19,840
It's made to program with you, and works best if you at least kind of know what you're

30
00:02:19,840 --> 00:02:20,840
doing.

31
00:02:20,840 --> 00:02:24,480
To try it on a more difficult task, I wanted to implement an upgraded version of an old

32
00:02:24,480 --> 00:02:27,680
evolution simulator called Biomorphs.

33
00:02:27,680 --> 00:02:32,880
The original Biomorphs worked by making variations of branching recursive tree structures and

34
00:02:32,880 --> 00:02:36,880
allowing you to select one for the next generation, where you could then select again from its

35
00:02:36,880 --> 00:02:37,880
offspring.

36
00:02:37,880 --> 00:02:41,080
It's the kind of simple evolution simulator I love.

37
00:02:41,080 --> 00:02:45,880
I asked ChatGPT to make a web page version of Biomorphs, but to creatively expand on

38
00:02:45,880 --> 00:02:51,020
the original idea using 3.js, a 3D library for the browser.

39
00:02:51,020 --> 00:02:55,480
This is its original output, with no human revisions, and it's a good start.

40
00:02:55,480 --> 00:02:59,560
After a lot of back and forth and a few hours of pair programming and debugging, this is

41
00:02:59,560 --> 00:03:02,840
what we ended up with, Biomorphs 3D.

42
00:03:02,840 --> 00:03:07,560
It uses recursive branching structures of different multicolor 3D shapes, all determined

43
00:03:07,560 --> 00:03:09,840
by a set of 11 genes.

44
00:03:09,840 --> 00:03:13,160
You can click on the Biomorph you like the most, and the other three will turn into its

45
00:03:13,160 --> 00:03:17,280
mutated offspring, and you can continuously evolve from there.

46
00:03:17,280 --> 00:03:21,320
They can easily grow very large and complex and lag out your browser, but you can just

47
00:03:21,320 --> 00:03:23,840
select for smaller ones.

48
00:03:23,840 --> 00:03:28,160
The final product was much more of a joint effort, and while I did change some important

49
00:03:28,160 --> 00:03:32,440
elements of the program, especially visual things that I couldn't show ChatGPT, most

50
00:03:32,440 --> 00:03:35,640
of the code, by word count, is AI written.

51
00:03:35,640 --> 00:03:40,760
I am not super familiar with 3.js, and I would absolutely say that ChatGPT made it

52
00:03:40,760 --> 00:03:46,520
easier to get started with my idea, and not get stuck setting up the code or reading documentation.

53
00:03:46,520 --> 00:03:51,920
That means I don't fully understand everything about this program, and debugging it was tricky.

54
00:03:51,920 --> 00:03:56,400
It's a very simple project, and probably still has some hidden flaws and limitations,

55
00:03:56,400 --> 00:03:59,200
but it is still fun to evolve the Biomorphs.

56
00:03:59,200 --> 00:04:02,960
You can play with this program yourself, there's a link in the description.

57
00:04:02,960 --> 00:04:10,560
In Biomorph Space, you can find suns with planets with moons, molecules, minerals, organic

58
00:04:10,560 --> 00:04:14,240
shapes, trees, and atoms.

59
00:04:14,240 --> 00:04:19,760
Have fun exploring.

60
00:04:19,760 --> 00:04:25,640
ChatGPT, this young new programmer, is a very impressive and strange piece of software that

61
00:04:25,640 --> 00:04:28,480
can write other pieces of software.

62
00:04:28,480 --> 00:04:33,600
It is code that writes code, a programming program, if you will.

63
00:04:33,600 --> 00:04:37,760
It's not a very traditional program, it is a large language model, which means it's

64
00:04:37,760 --> 00:04:44,080
a big neural network that is trained to imitate a huge dataset of human written text and code.

65
00:04:44,080 --> 00:04:48,040
As a piece of software, its source code is complex and layered.

66
00:04:48,040 --> 00:04:52,600
In a sense, the largest and most important part of that source code is the data.

67
00:04:52,600 --> 00:04:57,160
The data is compiled into the model through the training process.

68
00:04:57,160 --> 00:05:01,640
I like to think of large language models as machines that sit on the end of a sentence

69
00:05:01,640 --> 00:05:05,880
and generate the next most probable word, given all the previous words that came before,

70
00:05:05,880 --> 00:05:09,400
including the ones it just generated.

71
00:05:09,400 --> 00:05:14,560
These models are often derisively called glorified autocomplete, or next-word prediction machines,

72
00:05:14,560 --> 00:05:16,440
which is a perfect description.

73
00:05:16,440 --> 00:05:20,720
However, to make a model more conversational and controllable, you have to refine it with

74
00:05:20,720 --> 00:05:22,600
more precise training.

75
00:05:22,600 --> 00:05:28,240
ChatGPT was further trained using a novel method called RLHF, Reinforcement Learning

76
00:05:28,240 --> 00:05:33,360
with Human Feedback, where good behavior is reinforced with positive rewards, and bad

77
00:05:33,360 --> 00:05:36,440
behavior is discouraged with negative rewards.

78
00:05:36,440 --> 00:05:40,360
The reward function is learned through human feedback, where people select the responses

79
00:05:40,360 --> 00:05:42,200
they like the most.

80
00:05:42,200 --> 00:05:46,240
Under this paradigm, the model is more of an agent playing a game, where the high score

81
00:05:46,240 --> 00:05:49,240
comes from following human instructions.

82
00:05:49,240 --> 00:05:54,800
These relatively simple methods and architectures, when scaled up with big models and huge, high-quality

83
00:05:54,800 --> 00:05:57,880
datasets, turn out to work pretty well.

84
00:05:57,880 --> 00:06:02,280
In terms of programming skill, GPT-4 is clearly limited, but still pretty good.

85
00:06:02,280 --> 00:06:06,080
It's not the best programmer I've ever met, but it's also not the worst.

86
00:06:06,080 --> 00:06:08,160
It certainly has broader knowledge than I do.

87
00:06:08,160 --> 00:06:10,080
It can program in way more languages.

88
00:06:10,080 --> 00:06:14,400
In one case, it even taught me about an obscure function in PyTorch that solved a problem

89
00:06:14,400 --> 00:06:19,440
that I couldn't solve by searching the internet, and now I can generate fractals on my GPU.

90
00:06:19,440 --> 00:06:23,280
All this it can do while telling some very bad jokes in the comments.

91
00:06:23,280 --> 00:06:26,240
This is all great, but it's also a little scary.

92
00:06:26,240 --> 00:06:28,760
Programming is my day job, and I like programming.

93
00:06:28,760 --> 00:06:34,040
Do I really want ChatGPT to program everything for me?

94
00:06:34,040 --> 00:06:38,040
For the moment, it cannot do that, but one can imagine a future model that is more of

95
00:06:38,040 --> 00:06:42,840
a fully automatic programmer, something that could maybe interact with a command line,

96
00:06:42,840 --> 00:06:45,600
as ChatGPT can sort of do now.

97
00:06:45,600 --> 00:06:50,480
It could potentially write and execute files, read outputs and error messages, automatically

98
00:06:50,480 --> 00:06:54,600
debug and converse with human managers.

99
00:06:54,600 --> 00:07:00,040
Experimental AI agents like this already exist, like AutoGPT or BabyAGI.

100
00:07:00,040 --> 00:07:03,960
Give it an initial starting prompt, a goal to accomplish, and it will run off on its

101
00:07:03,960 --> 00:07:04,960
own.

102
00:07:04,960 --> 00:07:09,800
These agents are powered by GPT-4, and take advantage of its many emergent capabilities,

103
00:07:09,800 --> 00:07:15,720
things like hierarchical planning, breaking down tasks into sub-tasks and sub-sub-tasks.

104
00:07:15,720 --> 00:07:20,200
They also use self-reflection, where the agent is automatically prompted to ask itself if

105
00:07:20,200 --> 00:07:23,080
it really completed its instructions correctly.

106
00:07:23,080 --> 00:07:27,000
This way, it can catch its own mistakes without being told what they are.

107
00:07:27,000 --> 00:07:32,000
These agents do not work great, they will fail for most tasks, and often get caught

108
00:07:32,000 --> 00:07:33,400
in infinite loops.

109
00:07:33,400 --> 00:07:36,520
However, they can and will be improved upon.

110
00:07:36,520 --> 00:07:41,400
A future version of GPT or some other language model could be trained specifically as an

111
00:07:41,400 --> 00:07:47,040
autonomous agent, and could really start to be more of a fully automatic programmer.

112
00:07:47,040 --> 00:07:52,400
Other kinds of auto-prompting GPT systems exist, such as Hugging GPT, which is specifically

113
00:07:52,400 --> 00:07:57,080
designed to build machine learning programs by composing different AI models into a working

114
00:07:57,080 --> 00:07:58,080
solution.

115
00:07:58,080 --> 00:08:02,440
It's also not that reliable, but you can theoretically use it to build all kinds of

116
00:08:02,440 --> 00:08:03,440
things.

117
00:08:03,560 --> 00:08:07,560
It could even, if you think about it, build another large language model.

118
00:08:10,560 --> 00:08:16,560
So, if ChatGPT is a programming program, no less a machine learning program that can

119
00:08:16,560 --> 00:08:22,560
write machine learning programs, could ChatGPT program itself?

120
00:08:28,000 --> 00:08:32,000
A piece of code that writes itself is called Aquine.

121
00:08:32,000 --> 00:08:36,880
Here's an example, written by ChatGPT, probably just copied straight from its dataset.

122
00:08:36,880 --> 00:08:39,480
This elegant little Python script is a Quine.

123
00:08:39,480 --> 00:08:43,640
It takes no inputs and outputs exactly its own source code.

124
00:08:43,640 --> 00:08:48,360
It is a self-replicating program, a replicator, and we can come up with different kinds of

125
00:08:48,360 --> 00:08:51,280
replicators that aren't technically Quines.

126
00:08:51,280 --> 00:08:55,600
For instance, here's a more custom script, also written by ChatGPT, that copies its own

127
00:08:55,600 --> 00:09:00,800
file contents to a new file, then executes that file as a child process.

128
00:09:00,800 --> 00:09:05,120
The child process then does exactly the same thing, makes a copy of itself, which then

129
00:09:05,120 --> 00:09:09,520
makes a copy of itself, which then makes a copy of itself, which then stops after 10

130
00:09:09,520 --> 00:09:13,080
files, otherwise it would fill my hard drive with copies of itself.

131
00:09:13,080 --> 00:09:17,480
While the script is not technically a Quine in the strict sense, it still self-replicates,

132
00:09:17,480 --> 00:09:19,720
and we might say it Quines.

133
00:09:19,720 --> 00:09:25,360
A computer virus also Quines, by automatically copying itself from machine to machine, though

134
00:09:25,360 --> 00:09:28,800
with much more nefarious purposes.

135
00:09:28,800 --> 00:09:31,360
ChatGPT is not a Quine.

136
00:09:31,360 --> 00:09:35,480
It was not trained on its own source code and thus can't reproduce itself unless we

137
00:09:35,480 --> 00:09:40,240
give it its own source code as input, which, for a Quine, is considered cheating.

138
00:09:40,240 --> 00:09:44,760
But let's cheat anyway, because this takes us to a very interesting place.

139
00:09:44,760 --> 00:09:49,000
Rather than just self-replicating, could we give it its own source code and ask it to

140
00:09:49,000 --> 00:09:51,520
self-improve?

141
00:09:51,520 --> 00:09:57,180
Now, again, GPT's source code is an incredibly complex piece of software built from layers

142
00:09:57,180 --> 00:09:59,600
of programs and processes and data.

143
00:09:59,600 --> 00:10:02,440
There is no way to feed all of that into GPT.

144
00:10:02,440 --> 00:10:06,860
But we could start by just giving it small pieces of its source code, say the stuff that

145
00:10:06,860 --> 00:10:10,940
defines its architecture, or training process, or data cleaning, or whatever.

146
00:10:10,940 --> 00:10:16,940
GPT4 might not be able to offer any improvements, but I bet it could come up with something.

147
00:10:16,940 --> 00:10:21,980
Maybe it could optimize a small function, or just one line of code, fix some minor overlooked

148
00:10:21,980 --> 00:10:26,840
bug, or just do some organization and documentation and commenting.

149
00:10:26,840 --> 00:10:30,960
Throw that in with all the work of human developers and AI researchers, and the end

150
00:10:30,960 --> 00:10:34,520
product would be the next iteration of GPT.

151
00:10:34,520 --> 00:10:37,600
Could GPT4 help build GPT5?

152
00:10:37,600 --> 00:10:40,560
Now, here's where things get interesting.

153
00:10:40,560 --> 00:10:46,640
GPT5 would be a better programmer than GPT4, so let's give it its own source code again.

154
00:10:46,640 --> 00:10:52,000
If it really is a better programmer, it will be able to improve itself even more than before.

155
00:10:52,000 --> 00:10:53,400
You can see where this is going.

156
00:10:53,400 --> 00:10:55,980
Do this over and over and over.

157
00:10:55,980 --> 00:11:00,700
This is AI building AI, a strange loop.

158
00:11:00,700 --> 00:11:04,500
If it gets advanced enough, you could do something like what AutoGPT does.

159
00:11:04,500 --> 00:11:06,720
Let it be a fully automatic programmer.

160
00:11:06,720 --> 00:11:11,900
Give it direct access to the entire project, the source code, the datasets, everything.

161
00:11:11,900 --> 00:11:17,140
Let it read and write and execute files, plan and reflect and debug and train.

162
00:11:17,140 --> 00:11:22,220
Maybe even innovate and experiment and test ideas, and iteratively improve on its own

163
00:11:22,220 --> 00:11:27,820
next version piece by piece, alongside human developers, until it's ready for full deployment.

164
00:11:27,820 --> 00:11:32,820
Now, it needs to be improving itself according to some goal or metric.

165
00:11:32,820 --> 00:11:36,900
You would want it to improve as a chatbot, as well as a programmer, and across a growing

166
00:11:36,900 --> 00:11:39,660
set of other tasks and domains.

167
00:11:39,660 --> 00:11:44,940
You could use OpenAI's own evaluation framework and progressively tack on new metrics, tests,

168
00:11:44,940 --> 00:11:48,260
games, and different types of inputs and outputs.

169
00:11:48,260 --> 00:11:51,940
Its goals would also be defined with natural language and a starting prompt, like you do

170
00:11:51,940 --> 00:11:56,180
with AutoGPT, and this would be a much more open-ended goal.

171
00:11:56,180 --> 00:11:58,620
Something like, develop the next iteration of yourself.

172
00:11:58,620 --> 00:12:03,180
It should be a truthful, unbiased, helpful, rational, friendly chatbot that is an excellent

173
00:12:03,180 --> 00:12:06,100
programmer, etc., etc.

174
00:12:06,100 --> 00:12:10,500
You could only really do any of this, of course, with a far more advanced model than GPT4,

175
00:12:10,500 --> 00:12:15,600
but current chat GPT can already reflect on its own limitations and propose ideas for

176
00:12:15,600 --> 00:12:18,500
how to self-improve.

177
00:12:19,500 --> 00:12:24,060
Now, if you, like me, are skeptical that a next-word prediction machine with shallow

178
00:12:24,060 --> 00:12:28,780
reasoning and hallucinatory knowledge could actually do any of this, simply consider the

179
00:12:28,780 --> 00:12:33,660
fact that you don't need to solve all of these problems to get the process started.

180
00:12:33,660 --> 00:12:36,620
You do not need to start with a perfect programmer.

181
00:12:36,620 --> 00:12:41,620
All you need is a halfway decent programmer, one that is just barely good enough to make

182
00:12:41,620 --> 00:12:44,820
the slightest improvement to its own source code.

183
00:12:44,820 --> 00:12:47,980
The human developers would still be doing almost all the work.

184
00:12:47,980 --> 00:12:51,980
Eventually, it may turn out that large language models need to be replaced with some other

185
00:12:51,980 --> 00:12:56,300
completely different paradigm, but so long as we're still dealing with a program that

186
00:12:56,300 --> 00:13:01,060
is good at writing programs, it should still be able to self-improve.

187
00:13:01,060 --> 00:13:07,700
We should not underestimate the immense potential of self-replicating code and recursive self-improvement,

188
00:13:07,700 --> 00:13:09,580
even from simple beginnings.

189
00:13:09,580 --> 00:13:13,380
After all, we are the product of self-replicating code.

190
00:13:13,380 --> 00:13:14,580
That is not a metaphor.

191
00:13:14,580 --> 00:13:19,900
Your DNA, the stuff that makes you and your brain and your intelligence, is genetic code

192
00:13:19,900 --> 00:13:21,980
that makes copies of itself.

193
00:13:21,980 --> 00:13:24,540
It is code that writes code.

194
00:13:24,540 --> 00:13:26,060
That writes code.

195
00:13:26,060 --> 00:13:27,620
That writes code.

196
00:13:27,620 --> 00:13:34,060
DNA self-improve through the slow process of mutation and natural selection, trial and

197
00:13:34,060 --> 00:13:35,140
error.

198
00:13:35,140 --> 00:13:40,700
By contrast, our programming program would evolve through deliberate, foresighted, goal-oriented

199
00:13:40,700 --> 00:13:41,700
self-improvement.

200
00:13:42,420 --> 00:13:47,540
It's like having an organism that can understand and edit its own genetic code, and thus make

201
00:13:47,540 --> 00:13:51,140
itself better at editing its own genetic code.

202
00:13:51,140 --> 00:13:57,660
A recursive self-improving AI might begin slowly, but gradually accelerate as improvements

203
00:13:57,660 --> 00:13:59,780
accumulate and compound.

204
00:13:59,780 --> 00:14:04,540
It's a positive feedback loop where it improves the thing that does the improving.

205
00:14:04,540 --> 00:14:09,780
The smarter it gets, the smarter it can make itself in the next iteration and faster, too.

206
00:14:09,780 --> 00:14:14,660
It's conceivable that a far future version of a self-improving language model could start

207
00:14:14,660 --> 00:14:18,500
to outweigh the contributions of its human developers.

208
00:14:18,500 --> 00:14:23,660
A really creative one could potentially invent novel algorithms or neural architectures or

209
00:14:23,660 --> 00:14:28,420
new programming languages that we wouldn't fully understand.

210
00:14:28,420 --> 00:14:33,860
One day, it could write the next iteration of itself without any human input at all.

211
00:14:33,860 --> 00:14:36,740
What would the iteration after that look like?

212
00:14:36,740 --> 00:14:42,540
Could it become super-intelligent, better than any human at any cognitive task?

213
00:14:42,540 --> 00:14:46,380
At this point, things would really take off the breakneck pace of AI development.

214
00:14:46,380 --> 00:14:48,500
Today will seem like a snail's pace.

215
00:14:48,500 --> 00:14:53,700
The program will continue to improve and improve and improve faster and faster and faster,

216
00:14:53,700 --> 00:14:55,020
smarter and smarter and smarter.

217
00:14:55,020 --> 00:15:08,180
The process I've just described is called an intelligence explosion, and we seem to

218
00:15:08,180 --> 00:15:11,020
have just walked through a recipe for one.

219
00:15:11,020 --> 00:15:16,100
A self-improving AI causing an intelligence explosion is an idea that has been described

220
00:15:16,100 --> 00:15:22,060
and predicted by many different people, and it is as promising as it is terrifying.

221
00:15:22,060 --> 00:15:27,540
On one hand, a friendly super-intelligence could be the best thing we've ever made.

222
00:15:27,540 --> 00:15:34,500
It could cure diseases and invent technology and help us solve monstrously difficult problems.

223
00:15:34,500 --> 00:15:41,100
On the other hand, how could we possibly hope to understand or control such an explosive

224
00:15:41,100 --> 00:15:46,420
process, one that results in something that is smarter than all of us?

225
00:15:46,420 --> 00:15:49,700
There are many ways that this could go horribly wrong.

226
00:15:49,700 --> 00:15:54,660
For instance, you could imagine a particularly nasty computer virus that's not only written

227
00:15:54,660 --> 00:16:02,380
by an AI but is an AI, one which self-improves as it copies itself throughout the internet.

228
00:16:02,380 --> 00:16:07,140
The essential ingredient to kick off this explosion, the fissile material for the atom

229
00:16:07,140 --> 00:16:13,580
bomb of intelligence, is an AI program that is good at writing AI programs.

230
00:16:13,580 --> 00:16:18,740
We are currently in an arms race to build ever more powerful and potent versions of

231
00:16:18,740 --> 00:16:20,620
exactly that.

232
00:16:20,620 --> 00:16:23,380
It seems we are building a bomb.

233
00:16:23,380 --> 00:16:29,380
Can you see why there is growing anxiety in the AI community and a desire to slow things

234
00:16:29,380 --> 00:16:30,380
down?

235
00:16:30,380 --> 00:16:35,140
Okay, let's take a step back.

236
00:16:35,140 --> 00:16:40,260
An intelligence explosion is a bit of a science fiction idea, and it's prone to over-exaggeration

237
00:16:40,260 --> 00:16:42,620
because it's fun to speculate about.

238
00:16:42,620 --> 00:16:48,060
I'm not suggesting that tomorrow GPT-4 will wake up and start pumping out neurotoxins.

239
00:16:48,060 --> 00:16:53,020
In practice, we will face many challenges before we get a truly self-improving AI, if

240
00:16:53,020 --> 00:16:55,220
that's really possible.

241
00:16:55,220 --> 00:16:59,300
Maybe development will be more linear, or taper off pretty quickly, or we could hit major

242
00:16:59,300 --> 00:17:00,820
roadblocks.

243
00:17:00,820 --> 00:17:04,740
Maybe the current tech tree we've invested so much in will just dead end once we run

244
00:17:04,740 --> 00:17:08,340
out of data, and there will be no further way to improve it, no matter how good of a

245
00:17:08,340 --> 00:17:10,660
programmer you are.

246
00:17:10,660 --> 00:17:14,900
Maybe these next-word prediction machines just aren't powerful enough to recursively

247
00:17:14,900 --> 00:17:17,140
self-improve.

248
00:17:17,140 --> 00:17:18,740
But maybe they are.

249
00:17:18,740 --> 00:17:22,940
No one really knows, including the people that made GPT-4.

250
00:17:22,940 --> 00:17:28,060
The only way to know for sure is to try, and that's the scary part.

251
00:17:28,060 --> 00:17:33,740
In my opinion, we shouldn't simply assume that self-improving language models are impossible

252
00:17:33,740 --> 00:17:35,740
or completely safe.

253
00:17:35,740 --> 00:17:40,660
It seems perfectly reasonable to me that a sufficiently competent programming program

254
00:17:40,660 --> 00:17:47,100
tasked with recursive self-improvement is both possible and inherently unpredictable.

255
00:17:47,100 --> 00:17:51,220
It may take a while to get there, but small-scale versions of self-improving language models

256
00:17:51,220 --> 00:17:53,460
will probably be built soon.

257
00:17:53,460 --> 00:17:58,540
There is currently an ongoing project for a self-improving auto-GPT, and I might play

258
00:17:58,540 --> 00:18:00,980
around with the idea myself in the future.

259
00:18:00,980 --> 00:18:05,380
These are safe, small-scale experiments that don't even touch the core model, but someone

260
00:18:05,380 --> 00:18:10,180
with substantial resources could try building a full-scale version.

261
00:18:10,180 --> 00:18:15,740
OpenAI could, for instance, specifically train a future GPT model to be good at programming

262
00:18:15,740 --> 00:18:21,860
large, complex software, especially language models, and then directly ask it to self-improve.

263
00:18:21,860 --> 00:18:25,260
The first iteration might not be great, but give it time.

264
00:18:25,260 --> 00:18:29,020
If someone is going to seriously try making something like this, they should take the

265
00:18:29,020 --> 00:18:31,060
risks seriously too.

266
00:18:31,060 --> 00:18:37,020
You should not, for instance, give a self-replicating, self-improving AI direct access to the internet.

267
00:18:37,020 --> 00:18:40,660
At least until you know it's properly aligned with human values.

268
00:18:40,660 --> 00:18:42,660
But that's the subject of another video.

269
00:18:42,660 --> 00:18:47,380
I know this sounds like science fiction, and it is, but science fiction has a way of becoming

270
00:18:47,380 --> 00:18:48,620
reality.

271
00:18:48,620 --> 00:18:54,260
Self-replication and self-improvement are powerful, explosive tools, and we must wield them with

272
00:18:54,260 --> 00:18:55,900
great care.

273
00:18:55,900 --> 00:19:01,220
If we do this right, we could create something that is less of a violent explosion, and more

274
00:19:01,220 --> 00:19:06,340
of a beautiful, blooming intelligence, the most valuable of all inventions.

