WEBVTT

00:00.000 --> 00:07.920
This animation was generated by a short piece of Python code.

00:07.920 --> 00:14.120
It uses the math animation library manum from 3blue1brown to make this square fractal.

00:14.120 --> 00:19.640
It is recursive, the squares are inside of themselves, and the code uses a recursive function

00:19.640 --> 00:21.160
that calls itself.

00:21.160 --> 00:27.000
I've used manum many times before in previous videos, but I did not write this code.

00:27.000 --> 00:33.060
It was entirely written by ChatGPT, the AI program that can write programs.

00:33.060 --> 00:37.760
This was its first try when I asked it to give me any creative animation using manum,

00:37.760 --> 00:38.760
and that was GPT3.

00:38.760 --> 00:44.280
Here's what GPT4 gave me for a similar prompt.

00:44.280 --> 00:48.360
For this one, I changed a few parameters so it would add more branches and slow it down

00:48.360 --> 00:56.360
a bit, but it was still mostly made by ChatGPT in one try.

00:56.360 --> 01:00.740
It doesn't always work out that well of course, this one took a few tries.

01:00.740 --> 01:06.420
The first time it tried to load the file path2yourheart.svg which does not exist at all, and the second

01:06.420 --> 01:10.040
time it called this .weight function that doesn't exist.

01:10.040 --> 01:13.440
It makes stuff up sometimes, what they call hallucinations.

01:13.440 --> 01:18.720
Nonetheless, after explaining the problems to ChatGPT, it debugged its own mistake, tweaked

01:18.720 --> 01:23.360
the code, and you get this weird pulsing star thing.

01:23.360 --> 01:27.800
I have been having way too much fun playing with ChatGPT and doing all kinds of things

01:27.800 --> 01:30.560
with it, especially creative coding challenges.

01:30.560 --> 01:35.560
I would call ChatGPT creative for the same reason that I would call AI art creative.

01:35.560 --> 01:40.960
It can intelligently combine the languages, methods, and ideas that it is trained on.

01:40.960 --> 01:49.120
Just look at this self-portrait it made, again on the first try without any human revision.

01:49.120 --> 01:54.280
All the manum animations you see in this video were at least partially written by ChatGPT.

01:54.280 --> 01:58.560
Typically, it writes the brunt of the code, especially the boilerplate stuff, and then

01:58.560 --> 02:02.000
I finish it up, focusing on the visual stuff.

02:02.000 --> 02:05.800
Sometimes I'm just picking colors and tuning parameters, but often I'm debugging error

02:05.800 --> 02:08.880
messages and rewriting code myself.

02:08.880 --> 02:15.280
ChatGPT has major limitations, but is still a surprisingly helpful debugger and pair programmer.

02:15.280 --> 02:19.840
It's made to program with you, and works best if you at least kind of know what you're

02:19.840 --> 02:20.840
doing.

02:20.840 --> 02:24.480
To try it on a more difficult task, I wanted to implement an upgraded version of an old

02:24.480 --> 02:27.680
evolution simulator called Biomorphs.

02:27.680 --> 02:32.880
The original Biomorphs worked by making variations of branching recursive tree structures and

02:32.880 --> 02:36.880
allowing you to select one for the next generation, where you could then select again from its

02:36.880 --> 02:37.880
offspring.

02:37.880 --> 02:41.080
It's the kind of simple evolution simulator I love.

02:41.080 --> 02:45.880
I asked ChatGPT to make a web page version of Biomorphs, but to creatively expand on

02:45.880 --> 02:51.020
the original idea using 3.js, a 3D library for the browser.

02:51.020 --> 02:55.480
This is its original output, with no human revisions, and it's a good start.

02:55.480 --> 02:59.560
After a lot of back and forth and a few hours of pair programming and debugging, this is

02:59.560 --> 03:02.840
what we ended up with, Biomorphs 3D.

03:02.840 --> 03:07.560
It uses recursive branching structures of different multicolor 3D shapes, all determined

03:07.560 --> 03:09.840
by a set of 11 genes.

03:09.840 --> 03:13.160
You can click on the Biomorph you like the most, and the other three will turn into its

03:13.160 --> 03:17.280
mutated offspring, and you can continuously evolve from there.

03:17.280 --> 03:21.320
They can easily grow very large and complex and lag out your browser, but you can just

03:21.320 --> 03:23.840
select for smaller ones.

03:23.840 --> 03:28.160
The final product was much more of a joint effort, and while I did change some important

03:28.160 --> 03:32.440
elements of the program, especially visual things that I couldn't show ChatGPT, most

03:32.440 --> 03:35.640
of the code, by word count, is AI written.

03:35.640 --> 03:40.760
I am not super familiar with 3.js, and I would absolutely say that ChatGPT made it

03:40.760 --> 03:46.520
easier to get started with my idea, and not get stuck setting up the code or reading documentation.

03:46.520 --> 03:51.920
That means I don't fully understand everything about this program, and debugging it was tricky.

03:51.920 --> 03:56.400
It's a very simple project, and probably still has some hidden flaws and limitations,

03:56.400 --> 03:59.200
but it is still fun to evolve the Biomorphs.

03:59.200 --> 04:02.960
You can play with this program yourself, there's a link in the description.

04:02.960 --> 04:10.560
In Biomorph Space, you can find suns with planets with moons, molecules, minerals, organic

04:10.560 --> 04:14.240
shapes, trees, and atoms.

04:14.240 --> 04:19.760
Have fun exploring.

04:19.760 --> 04:25.640
ChatGPT, this young new programmer, is a very impressive and strange piece of software that

04:25.640 --> 04:28.480
can write other pieces of software.

04:28.480 --> 04:33.600
It is code that writes code, a programming program, if you will.

04:33.600 --> 04:37.760
It's not a very traditional program, it is a large language model, which means it's

04:37.760 --> 04:44.080
a big neural network that is trained to imitate a huge dataset of human written text and code.

04:44.080 --> 04:48.040
As a piece of software, its source code is complex and layered.

04:48.040 --> 04:52.600
In a sense, the largest and most important part of that source code is the data.

04:52.600 --> 04:57.160
The data is compiled into the model through the training process.

04:57.160 --> 05:01.640
I like to think of large language models as machines that sit on the end of a sentence

05:01.640 --> 05:05.880
and generate the next most probable word, given all the previous words that came before,

05:05.880 --> 05:09.400
including the ones it just generated.

05:09.400 --> 05:14.560
These models are often derisively called glorified autocomplete, or next-word prediction machines,

05:14.560 --> 05:16.440
which is a perfect description.

05:16.440 --> 05:20.720
However, to make a model more conversational and controllable, you have to refine it with

05:20.720 --> 05:22.600
more precise training.

05:22.600 --> 05:28.240
ChatGPT was further trained using a novel method called RLHF, Reinforcement Learning

05:28.240 --> 05:33.360
with Human Feedback, where good behavior is reinforced with positive rewards, and bad

05:33.360 --> 05:36.440
behavior is discouraged with negative rewards.

05:36.440 --> 05:40.360
The reward function is learned through human feedback, where people select the responses

05:40.360 --> 05:42.200
they like the most.

05:42.200 --> 05:46.240
Under this paradigm, the model is more of an agent playing a game, where the high score

05:46.240 --> 05:49.240
comes from following human instructions.

05:49.240 --> 05:54.800
These relatively simple methods and architectures, when scaled up with big models and huge, high-quality

05:54.800 --> 05:57.880
datasets, turn out to work pretty well.

05:57.880 --> 06:02.280
In terms of programming skill, GPT-4 is clearly limited, but still pretty good.

06:02.280 --> 06:06.080
It's not the best programmer I've ever met, but it's also not the worst.

06:06.080 --> 06:08.160
It certainly has broader knowledge than I do.

06:08.160 --> 06:10.080
It can program in way more languages.

06:10.080 --> 06:14.400
In one case, it even taught me about an obscure function in PyTorch that solved a problem

06:14.400 --> 06:19.440
that I couldn't solve by searching the internet, and now I can generate fractals on my GPU.

06:19.440 --> 06:23.280
All this it can do while telling some very bad jokes in the comments.

06:23.280 --> 06:26.240
This is all great, but it's also a little scary.

06:26.240 --> 06:28.760
Programming is my day job, and I like programming.

06:28.760 --> 06:34.040
Do I really want ChatGPT to program everything for me?

06:34.040 --> 06:38.040
For the moment, it cannot do that, but one can imagine a future model that is more of

06:38.040 --> 06:42.840
a fully automatic programmer, something that could maybe interact with a command line,

06:42.840 --> 06:45.600
as ChatGPT can sort of do now.

06:45.600 --> 06:50.480
It could potentially write and execute files, read outputs and error messages, automatically

06:50.480 --> 06:54.600
debug and converse with human managers.

06:54.600 --> 07:00.040
Experimental AI agents like this already exist, like AutoGPT or BabyAGI.

07:00.040 --> 07:03.960
Give it an initial starting prompt, a goal to accomplish, and it will run off on its

07:03.960 --> 07:04.960
own.

07:04.960 --> 07:09.800
These agents are powered by GPT-4, and take advantage of its many emergent capabilities,

07:09.800 --> 07:15.720
things like hierarchical planning, breaking down tasks into sub-tasks and sub-sub-tasks.

07:15.720 --> 07:20.200
They also use self-reflection, where the agent is automatically prompted to ask itself if

07:20.200 --> 07:23.080
it really completed its instructions correctly.

07:23.080 --> 07:27.000
This way, it can catch its own mistakes without being told what they are.

07:27.000 --> 07:32.000
These agents do not work great, they will fail for most tasks, and often get caught

07:32.000 --> 07:33.400
in infinite loops.

07:33.400 --> 07:36.520
However, they can and will be improved upon.

07:36.520 --> 07:41.400
A future version of GPT or some other language model could be trained specifically as an

07:41.400 --> 07:47.040
autonomous agent, and could really start to be more of a fully automatic programmer.

07:47.040 --> 07:52.400
Other kinds of auto-prompting GPT systems exist, such as Hugging GPT, which is specifically

07:52.400 --> 07:57.080
designed to build machine learning programs by composing different AI models into a working

07:57.080 --> 07:58.080
solution.

07:58.080 --> 08:02.440
It's also not that reliable, but you can theoretically use it to build all kinds of

08:02.440 --> 08:03.440
things.

08:03.560 --> 08:07.560
It could even, if you think about it, build another large language model.

08:10.560 --> 08:16.560
So, if ChatGPT is a programming program, no less a machine learning program that can

08:16.560 --> 08:22.560
write machine learning programs, could ChatGPT program itself?

08:28.000 --> 08:32.000
A piece of code that writes itself is called Aquine.

08:32.000 --> 08:36.880
Here's an example, written by ChatGPT, probably just copied straight from its dataset.

08:36.880 --> 08:39.480
This elegant little Python script is a Quine.

08:39.480 --> 08:43.640
It takes no inputs and outputs exactly its own source code.

08:43.640 --> 08:48.360
It is a self-replicating program, a replicator, and we can come up with different kinds of

08:48.360 --> 08:51.280
replicators that aren't technically Quines.

08:51.280 --> 08:55.600
For instance, here's a more custom script, also written by ChatGPT, that copies its own

08:55.600 --> 09:00.800
file contents to a new file, then executes that file as a child process.

09:00.800 --> 09:05.120
The child process then does exactly the same thing, makes a copy of itself, which then

09:05.120 --> 09:09.520
makes a copy of itself, which then makes a copy of itself, which then stops after 10

09:09.520 --> 09:13.080
files, otherwise it would fill my hard drive with copies of itself.

09:13.080 --> 09:17.480
While the script is not technically a Quine in the strict sense, it still self-replicates,

09:17.480 --> 09:19.720
and we might say it Quines.

09:19.720 --> 09:25.360
A computer virus also Quines, by automatically copying itself from machine to machine, though

09:25.360 --> 09:28.800
with much more nefarious purposes.

09:28.800 --> 09:31.360
ChatGPT is not a Quine.

09:31.360 --> 09:35.480
It was not trained on its own source code and thus can't reproduce itself unless we

09:35.480 --> 09:40.240
give it its own source code as input, which, for a Quine, is considered cheating.

09:40.240 --> 09:44.760
But let's cheat anyway, because this takes us to a very interesting place.

09:44.760 --> 09:49.000
Rather than just self-replicating, could we give it its own source code and ask it to

09:49.000 --> 09:51.520
self-improve?

09:51.520 --> 09:57.180
Now, again, GPT's source code is an incredibly complex piece of software built from layers

09:57.180 --> 09:59.600
of programs and processes and data.

09:59.600 --> 10:02.440
There is no way to feed all of that into GPT.

10:02.440 --> 10:06.860
But we could start by just giving it small pieces of its source code, say the stuff that

10:06.860 --> 10:10.940
defines its architecture, or training process, or data cleaning, or whatever.

10:10.940 --> 10:16.940
GPT4 might not be able to offer any improvements, but I bet it could come up with something.

10:16.940 --> 10:21.980
Maybe it could optimize a small function, or just one line of code, fix some minor overlooked

10:21.980 --> 10:26.840
bug, or just do some organization and documentation and commenting.

10:26.840 --> 10:30.960
Throw that in with all the work of human developers and AI researchers, and the end

10:30.960 --> 10:34.520
product would be the next iteration of GPT.

10:34.520 --> 10:37.600
Could GPT4 help build GPT5?

10:37.600 --> 10:40.560
Now, here's where things get interesting.

10:40.560 --> 10:46.640
GPT5 would be a better programmer than GPT4, so let's give it its own source code again.

10:46.640 --> 10:52.000
If it really is a better programmer, it will be able to improve itself even more than before.

10:52.000 --> 10:53.400
You can see where this is going.

10:53.400 --> 10:55.980
Do this over and over and over.

10:55.980 --> 11:00.700
This is AI building AI, a strange loop.

11:00.700 --> 11:04.500
If it gets advanced enough, you could do something like what AutoGPT does.

11:04.500 --> 11:06.720
Let it be a fully automatic programmer.

11:06.720 --> 11:11.900
Give it direct access to the entire project, the source code, the datasets, everything.

11:11.900 --> 11:17.140
Let it read and write and execute files, plan and reflect and debug and train.

11:17.140 --> 11:22.220
Maybe even innovate and experiment and test ideas, and iteratively improve on its own

11:22.220 --> 11:27.820
next version piece by piece, alongside human developers, until it's ready for full deployment.

11:27.820 --> 11:32.820
Now, it needs to be improving itself according to some goal or metric.

11:32.820 --> 11:36.900
You would want it to improve as a chatbot, as well as a programmer, and across a growing

11:36.900 --> 11:39.660
set of other tasks and domains.

11:39.660 --> 11:44.940
You could use OpenAI's own evaluation framework and progressively tack on new metrics, tests,

11:44.940 --> 11:48.260
games, and different types of inputs and outputs.

11:48.260 --> 11:51.940
Its goals would also be defined with natural language and a starting prompt, like you do

11:51.940 --> 11:56.180
with AutoGPT, and this would be a much more open-ended goal.

11:56.180 --> 11:58.620
Something like, develop the next iteration of yourself.

11:58.620 --> 12:03.180
It should be a truthful, unbiased, helpful, rational, friendly chatbot that is an excellent

12:03.180 --> 12:06.100
programmer, etc., etc.

12:06.100 --> 12:10.500
You could only really do any of this, of course, with a far more advanced model than GPT4,

12:10.500 --> 12:15.600
but current chat GPT can already reflect on its own limitations and propose ideas for

12:15.600 --> 12:18.500
how to self-improve.

12:19.500 --> 12:24.060
Now, if you, like me, are skeptical that a next-word prediction machine with shallow

12:24.060 --> 12:28.780
reasoning and hallucinatory knowledge could actually do any of this, simply consider the

12:28.780 --> 12:33.660
fact that you don't need to solve all of these problems to get the process started.

12:33.660 --> 12:36.620
You do not need to start with a perfect programmer.

12:36.620 --> 12:41.620
All you need is a halfway decent programmer, one that is just barely good enough to make

12:41.620 --> 12:44.820
the slightest improvement to its own source code.

12:44.820 --> 12:47.980
The human developers would still be doing almost all the work.

12:47.980 --> 12:51.980
Eventually, it may turn out that large language models need to be replaced with some other

12:51.980 --> 12:56.300
completely different paradigm, but so long as we're still dealing with a program that

12:56.300 --> 13:01.060
is good at writing programs, it should still be able to self-improve.

13:01.060 --> 13:07.700
We should not underestimate the immense potential of self-replicating code and recursive self-improvement,

13:07.700 --> 13:09.580
even from simple beginnings.

13:09.580 --> 13:13.380
After all, we are the product of self-replicating code.

13:13.380 --> 13:14.580
That is not a metaphor.

13:14.580 --> 13:19.900
Your DNA, the stuff that makes you and your brain and your intelligence, is genetic code

13:19.900 --> 13:21.980
that makes copies of itself.

13:21.980 --> 13:24.540
It is code that writes code.

13:24.540 --> 13:26.060
That writes code.

13:26.060 --> 13:27.620
That writes code.

13:27.620 --> 13:34.060
DNA self-improve through the slow process of mutation and natural selection, trial and

13:34.060 --> 13:35.140
error.

13:35.140 --> 13:40.700
By contrast, our programming program would evolve through deliberate, foresighted, goal-oriented

13:40.700 --> 13:41.700
self-improvement.

13:42.420 --> 13:47.540
It's like having an organism that can understand and edit its own genetic code, and thus make

13:47.540 --> 13:51.140
itself better at editing its own genetic code.

13:51.140 --> 13:57.660
A recursive self-improving AI might begin slowly, but gradually accelerate as improvements

13:57.660 --> 13:59.780
accumulate and compound.

13:59.780 --> 14:04.540
It's a positive feedback loop where it improves the thing that does the improving.

14:04.540 --> 14:09.780
The smarter it gets, the smarter it can make itself in the next iteration and faster, too.

14:09.780 --> 14:14.660
It's conceivable that a far future version of a self-improving language model could start

14:14.660 --> 14:18.500
to outweigh the contributions of its human developers.

14:18.500 --> 14:23.660
A really creative one could potentially invent novel algorithms or neural architectures or

14:23.660 --> 14:28.420
new programming languages that we wouldn't fully understand.

14:28.420 --> 14:33.860
One day, it could write the next iteration of itself without any human input at all.

14:33.860 --> 14:36.740
What would the iteration after that look like?

14:36.740 --> 14:42.540
Could it become super-intelligent, better than any human at any cognitive task?

14:42.540 --> 14:46.380
At this point, things would really take off the breakneck pace of AI development.

14:46.380 --> 14:48.500
Today will seem like a snail's pace.

14:48.500 --> 14:53.700
The program will continue to improve and improve and improve faster and faster and faster,

14:53.700 --> 14:55.020
smarter and smarter and smarter.

14:55.020 --> 15:08.180
The process I've just described is called an intelligence explosion, and we seem to

15:08.180 --> 15:11.020
have just walked through a recipe for one.

15:11.020 --> 15:16.100
A self-improving AI causing an intelligence explosion is an idea that has been described

15:16.100 --> 15:22.060
and predicted by many different people, and it is as promising as it is terrifying.

15:22.060 --> 15:27.540
On one hand, a friendly super-intelligence could be the best thing we've ever made.

15:27.540 --> 15:34.500
It could cure diseases and invent technology and help us solve monstrously difficult problems.

15:34.500 --> 15:41.100
On the other hand, how could we possibly hope to understand or control such an explosive

15:41.100 --> 15:46.420
process, one that results in something that is smarter than all of us?

15:46.420 --> 15:49.700
There are many ways that this could go horribly wrong.

15:49.700 --> 15:54.660
For instance, you could imagine a particularly nasty computer virus that's not only written

15:54.660 --> 16:02.380
by an AI but is an AI, one which self-improves as it copies itself throughout the internet.

16:02.380 --> 16:07.140
The essential ingredient to kick off this explosion, the fissile material for the atom

16:07.140 --> 16:13.580
bomb of intelligence, is an AI program that is good at writing AI programs.

16:13.580 --> 16:18.740
We are currently in an arms race to build ever more powerful and potent versions of

16:18.740 --> 16:20.620
exactly that.

16:20.620 --> 16:23.380
It seems we are building a bomb.

16:23.380 --> 16:29.380
Can you see why there is growing anxiety in the AI community and a desire to slow things

16:29.380 --> 16:30.380
down?

16:30.380 --> 16:35.140
Okay, let's take a step back.

16:35.140 --> 16:40.260
An intelligence explosion is a bit of a science fiction idea, and it's prone to over-exaggeration

16:40.260 --> 16:42.620
because it's fun to speculate about.

16:42.620 --> 16:48.060
I'm not suggesting that tomorrow GPT-4 will wake up and start pumping out neurotoxins.

16:48.060 --> 16:53.020
In practice, we will face many challenges before we get a truly self-improving AI, if

16:53.020 --> 16:55.220
that's really possible.

16:55.220 --> 16:59.300
Maybe development will be more linear, or taper off pretty quickly, or we could hit major

16:59.300 --> 17:00.820
roadblocks.

17:00.820 --> 17:04.740
Maybe the current tech tree we've invested so much in will just dead end once we run

17:04.740 --> 17:08.340
out of data, and there will be no further way to improve it, no matter how good of a

17:08.340 --> 17:10.660
programmer you are.

17:10.660 --> 17:14.900
Maybe these next-word prediction machines just aren't powerful enough to recursively

17:14.900 --> 17:17.140
self-improve.

17:17.140 --> 17:18.740
But maybe they are.

17:18.740 --> 17:22.940
No one really knows, including the people that made GPT-4.

17:22.940 --> 17:28.060
The only way to know for sure is to try, and that's the scary part.

17:28.060 --> 17:33.740
In my opinion, we shouldn't simply assume that self-improving language models are impossible

17:33.740 --> 17:35.740
or completely safe.

17:35.740 --> 17:40.660
It seems perfectly reasonable to me that a sufficiently competent programming program

17:40.660 --> 17:47.100
tasked with recursive self-improvement is both possible and inherently unpredictable.

17:47.100 --> 17:51.220
It may take a while to get there, but small-scale versions of self-improving language models

17:51.220 --> 17:53.460
will probably be built soon.

17:53.460 --> 17:58.540
There is currently an ongoing project for a self-improving auto-GPT, and I might play

17:58.540 --> 18:00.980
around with the idea myself in the future.

18:00.980 --> 18:05.380
These are safe, small-scale experiments that don't even touch the core model, but someone

18:05.380 --> 18:10.180
with substantial resources could try building a full-scale version.

18:10.180 --> 18:15.740
OpenAI could, for instance, specifically train a future GPT model to be good at programming

18:15.740 --> 18:21.860
large, complex software, especially language models, and then directly ask it to self-improve.

18:21.860 --> 18:25.260
The first iteration might not be great, but give it time.

18:25.260 --> 18:29.020
If someone is going to seriously try making something like this, they should take the

18:29.020 --> 18:31.060
risks seriously too.

18:31.060 --> 18:37.020
You should not, for instance, give a self-replicating, self-improving AI direct access to the internet.

18:37.020 --> 18:40.660
At least until you know it's properly aligned with human values.

18:40.660 --> 18:42.660
But that's the subject of another video.

18:42.660 --> 18:47.380
I know this sounds like science fiction, and it is, but science fiction has a way of becoming

18:47.380 --> 18:48.620
reality.

18:48.620 --> 18:54.260
Self-replication and self-improvement are powerful, explosive tools, and we must wield them with

18:54.260 --> 18:55.900
great care.

18:55.900 --> 19:01.220
If we do this right, we could create something that is less of a violent explosion, and more

19:01.220 --> 19:06.340
of a beautiful, blooming intelligence, the most valuable of all inventions.

