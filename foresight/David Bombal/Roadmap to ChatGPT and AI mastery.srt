1
00:00:00,000 --> 00:00:05,880
And I think one of the reasons that chat GPT and stuff have been so hyped recently is because most people don't know what it is.

2
00:00:05,880 --> 00:00:11,880
And so when you see it doing what it does, you think this thing must basically be a person, right?

3
00:00:11,880 --> 00:00:13,240
Because it's acting like one.

4
00:00:13,240 --> 00:00:18,000
And I should carry out this by saying I'm not selling short these incredible technologies.

5
00:00:18,000 --> 00:00:22,400
I'm just saying that it would be very silly to just completely use them blind and never check what they do, right?

6
00:00:22,400 --> 00:00:24,560
Because we know they just make stuff up a lot of the time.

7
00:00:24,560 --> 00:00:26,080
I'm glad you mentioned computer science.

8
00:00:26,160 --> 00:00:34,960
Do you think it's time for more of us to learn computer science-type stuff because of AI, like maths and all these computer science stuff and not really?

9
00:00:40,760 --> 00:00:44,040
I've been saying that you need to learn artificial intelligence or AI.

10
00:00:44,040 --> 00:00:48,040
Question that a lot of you have been asking me is, OK, so how do I learn that?

11
00:00:48,040 --> 00:00:49,480
So let's ask another friend.

12
00:00:51,680 --> 00:00:52,120
David.

13
00:00:52,120 --> 00:00:52,720
Yes.

14
00:00:52,720 --> 00:00:58,560
You've mentioned this before, but remind me which place do you recommend that I learn and others learn AI?

15
00:00:58,560 --> 00:01:00,120
I really like Brilliant.

16
00:01:00,120 --> 00:01:10,200
It's one of those places where you can go and a visual gamified way to learn concepts and mathematics behind AI and machine learning.

17
00:01:10,200 --> 00:01:12,560
You've recommended this a few times to me.

18
00:01:12,560 --> 00:01:18,640
The way you said it was, David, if you want to learn AI, I need to learn like statistics and stuff like that, right?

19
00:01:18,640 --> 00:01:29,280
Yes, they've got these roadmaps that actually helps you with calculus and learning statistics and linear algebra, all the stuff that you need to know for AI.

20
00:01:29,280 --> 00:01:29,840
I'll say this.

21
00:01:29,840 --> 00:01:32,200
David is on my team, really glad that he is.

22
00:01:32,200 --> 00:01:36,160
David has strengths that I don't have, and I think that's what's really important in life.

23
00:01:36,160 --> 00:01:37,840
You need to learn from others.

24
00:01:37,840 --> 00:01:39,880
David, well, tell us, you've done a lot of maths.

25
00:01:39,880 --> 00:01:41,360
You've done a lot of computer science.

26
00:01:41,360 --> 00:01:43,080
You've actually worked with AI stuff, right?

27
00:01:43,080 --> 00:01:47,520
I worked in the medical field for data science stuff.

28
00:01:48,400 --> 00:02:00,440
I really think you need to know all the statistics and calculus and linear algebra and the discrete mathematics that you need to learn, which actually makes a lot of coding a lot easier for you.

29
00:02:00,440 --> 00:02:00,960
That's brilliant.

30
00:02:00,960 --> 00:02:02,880
So I'm looking on their website now.

31
00:02:02,880 --> 00:02:07,400
The one that you've recommended that I go through is the Data Science Foundations, right?

32
00:02:07,400 --> 00:02:14,320
That's like probability, applied probability, statistics, fundamentals, and then an introduction to neural networks.

33
00:02:14,320 --> 00:02:16,480
And obviously, me being me, I just skipped all of that.

34
00:02:16,480 --> 00:02:18,240
They went straight to learning neural networks.

35
00:02:18,240 --> 00:02:22,000
But as David said, what I really like about this website is it's gamified, as he said.

36
00:02:22,000 --> 00:02:23,840
So really great way to get started.

37
00:02:23,840 --> 00:02:26,080
Really want to thank Brilliant for sponsoring this video.

38
00:02:26,080 --> 00:02:27,560
Brilliant, as they say in the UK.

39
00:02:27,560 --> 00:02:28,080
Thanks.

40
00:02:28,080 --> 00:02:31,560
Everyone, it's David Bombal back with Dr. Mike Pound.

41
00:02:31,560 --> 00:02:32,280
Mike, welcome.

42
00:02:32,280 --> 00:02:34,160
Thanks for having me back again.

43
00:02:34,160 --> 00:02:37,000
Mike, it feels like the sky's falling again.

44
00:02:37,000 --> 00:02:43,840
You know, we had this interview previously and it was all this hype about AI, but it seems to just be getting hotter and hotter.

45
00:02:43,880 --> 00:02:45,160
So tell me, is the sky falling?

46
00:02:45,160 --> 00:02:46,080
Am I going to lose my job?

47
00:02:46,080 --> 00:02:46,960
Is the future bleak?

48
00:02:46,960 --> 00:02:48,440
I think I think it'll be all right.

49
00:02:48,440 --> 00:02:50,440
Just relax.

50
00:02:50,440 --> 00:02:52,240
Relax.

51
00:02:52,240 --> 00:02:55,360
Um, just bring me into calm everything down a bit.

52
00:02:55,360 --> 00:03:02,480
That's, that's, you know, I think that the last six months particularly have been, you know, both unbelievable in terms of genuine hype,

53
00:03:02,480 --> 00:03:10,200
like things that are really exciting appearing and also obviously totally overboard hype that's just getting really quite silly and everyone needs to calm down.

54
00:03:10,200 --> 00:03:10,480
Right.

55
00:03:10,480 --> 00:03:13,000
So I think there's a bit of everything going on.

56
00:03:13,000 --> 00:03:17,600
Chat and GPT is an incredibly impressive tool that works very, very well.

57
00:03:17,600 --> 00:03:22,160
I've done some really fun tests of it where I push to see what it will do.

58
00:03:22,160 --> 00:03:25,480
And some of the things it will do are quite amazing, right?

59
00:03:25,480 --> 00:03:29,240
On the other hand, there are lots of things it doesn't do very well.

60
00:03:29,240 --> 00:03:34,000
And one of the big problems we have at the moment is it won't always tell you it's one of those things.

61
00:03:34,000 --> 00:03:37,000
And that's, I think, where we have something that needs addressing.

62
00:03:37,000 --> 00:03:40,760
I've done some tests and I mean, a lot of people I know have done tests.

63
00:03:40,760 --> 00:03:44,560
And it's amazing what it seems to be able to produce.

64
00:03:44,560 --> 00:03:49,760
I think the concern a lot of people have is like, Mike, I'm 18 years old or let's say I'm older.

65
00:03:49,760 --> 00:03:57,000
I want to switch careers to become a programmer or I want to get into cybersecurity or I want to be a network engineer, whatever, some technical role.

66
00:03:57,000 --> 00:04:02,240
And it feels like I'm just going to waste my time because Chat GPT is just going to obliterate jobs.

67
00:04:02,240 --> 00:04:10,240
The first thing I would observe is that it's very nice for some of these big tech companies, if that's the perception, because it makes them look very, very impressive, right?

68
00:04:10,240 --> 00:04:16,760
And so I think that the cynic in me a little bit is like, this is, you know, no PR is bad PR kind of a situation.

69
00:04:16,760 --> 00:04:23,400
They like to drop, you know, these tools get dropped as incredibly impressive tech demos and I'm not selling them short, right?

70
00:04:23,400 --> 00:04:29,000
Very impressive, but maybe not quite as impressive as they first appear on a service when you start to dig in.

71
00:04:29,000 --> 00:04:30,480
And I think that's what's really important.

72
00:04:30,480 --> 00:04:35,520
You know, in science, we spend a lot of time checking things and rechecking them, at least that's what we're supposed to do, right?

73
00:04:35,560 --> 00:04:41,520
So I, you know, a PhD student comes to my office with some results and they say, oh, we've got 95% accuracy on some task.

74
00:04:41,520 --> 00:04:48,760
And I think, OK, let's talk about which data you used and whether that's really true and whether when you use it on this new data, you're going to get that same result.

75
00:04:48,760 --> 00:04:55,120
And we spend ages going over and over the data again to make sure that when we actually publish it, it's really as accurate as possible.

76
00:04:55,120 --> 00:04:58,720
Large language models are maybe not operating in quite that same way.

77
00:04:58,720 --> 00:05:05,480
Yes, they release papers from time to time, but mostly they release these big websites where you can try them out and they do incredibly impressive stuff.

78
00:05:05,720 --> 00:05:08,640
And then and they lie very impressively as well, right?

79
00:05:08,640 --> 00:05:12,080
And I think that's the thing that we haven't quite got around.

80
00:05:12,080 --> 00:05:17,000
So, you know, suppose you're a programmer and you've been using co-pilot and you've been using chat.

81
00:05:17,000 --> 00:05:22,080
GPT also does code and you're a bit worried because it's just producing pretty decent code.

82
00:05:22,080 --> 00:05:26,960
Maybe you don't see it replacing you right now, but you could see in 10 years, maybe that's going to be a problem.

83
00:05:27,200 --> 00:05:30,520
I think the problem is at the moment is it's very difficult to know where it's going.

84
00:05:30,600 --> 00:05:38,040
I think a lot of researchers are suspicious of the idea that we can just make it continually bigger and bigger and more impressive and it will just get better and better.

85
00:05:38,040 --> 00:05:44,480
You know, when we talked about how these models work, they don't really have an internal model of what it is they're trying to do or anything, really.

86
00:05:44,480 --> 00:05:46,400
They just map text to other texts.

87
00:05:46,400 --> 00:05:55,080
You know, when I write a piece of computer code, what I'm really hoping to do is in my mind come up with an idea of the problem that needs to be solved

88
00:05:55,160 --> 00:06:04,120
and what the variables and things that I'm going to need start to get them down on paper and then start thinking about how would I manipulate those variables using code to produce the result that I want.

89
00:06:04,120 --> 00:06:05,920
Chat GPT doesn't really work that way.

90
00:06:05,920 --> 00:06:09,720
It just spits out code and it happens a lot of the time to look pretty good.

91
00:06:09,720 --> 00:06:13,560
At the moment, it's a tool to be used quite carefully, particularly with code.

92
00:06:13,560 --> 00:06:21,880
I wouldn't push anything chat GPT has written straight into production without, you know, quite a few tests because at the moment there's no grounding in reality.

93
00:06:21,960 --> 00:06:28,200
The reality is for training data, but once it's finished training, it's kind of random what it gets.

94
00:06:28,200 --> 00:06:34,360
And these things actually, I don't know if you've noticed this, David, but when you run it, it can produce different answers each time.

95
00:06:34,360 --> 00:06:39,040
And that's because it uses something called temperature to somewhat randomize its output.

96
00:06:39,040 --> 00:06:48,000
So instead of saying, OK, the next word in my output is going to be there, it will say, I think there's an 80% chance that it's there, but it's a 20% chance that it's so.

97
00:06:48,000 --> 00:06:52,840
And then what what the machine will do is say, well, OK, 20% of the time, then we'll pick a different word.

98
00:06:52,840 --> 00:06:58,480
And that way you can go in slightly different directions because if you didn't do that, it will just produce a save output every time.

99
00:06:58,480 --> 00:07:03,320
It's not it's not a random object, so it's not a random network in that sense.

100
00:07:03,320 --> 00:07:10,080
And so you can imagine a situation where there is a really good version of this program that it could write, but it randomly didn't and produce one below the bugs.

101
00:07:10,080 --> 00:07:12,120
So, you know, I mean, that's what I've experienced.

102
00:07:12,360 --> 00:07:19,200
Yeah. And you know, I suppose there's a question in my mind about how is there an efficiency saving if you have to order everything you're reading, right?

103
00:07:19,200 --> 00:07:22,800
Is reading code as fast as writing code or slower or faster?

104
00:07:22,800 --> 00:07:24,520
I'm I don't know, right?

105
00:07:24,520 --> 00:07:28,920
I'm undecided. I think sometimes for boilerplate code, probably pretty effective.

106
00:07:28,920 --> 00:07:37,120
If it's a sort of code, you know, write me a for loop to do X, Y and Z, probably works pretty well, as long as you're capable of quickly checking that.

107
00:07:37,120 --> 00:07:39,280
But then it didn't take me very long to write a for loop anyway.

108
00:07:39,360 --> 00:07:43,840
I'm undecided, I suppose, as to how much of a game change that will be.

109
00:07:43,840 --> 00:07:51,360
This said, I know there are developers that use it, and I know that the developers who claim, or at least they think they're much more efficient.

110
00:07:51,360 --> 00:08:00,800
I don't spend as much time coding as I'd like, because I'm I see, you know, as a professor in a university, I spend a lot of time teaching, a lot of time mentoring others and teaching people.

111
00:08:00,800 --> 00:08:04,920
So they do the coding and I sit there and look at it.

112
00:08:04,920 --> 00:08:07,160
I haven't had as much experience as some.

113
00:08:07,200 --> 00:08:14,920
Yeah, I mean, I think the concern is always, you know, younger young people are people trying to switch careers is, you know, I want to have a job for more than a year or five years.

114
00:08:16,160 --> 00:08:19,880
Is it worth putting all the effort in to learn this stuff if AI is just going to take it away?

115
00:08:19,880 --> 00:08:28,160
My gut tells me that AI isn't going to take it away anytime soon, because I think that I would argue that you need something more fundamental to understanding some of these problems.

116
00:08:28,160 --> 00:08:36,360
If you're going to write code to solve them than just a text production mechanism, that isn't to say that what it doesn't do, it's very impressive what it does.

117
00:08:36,360 --> 00:08:40,840
But I think that as you start to build up, you know, it's very, it's all very well saying like me a for loop to do this.

118
00:08:40,840 --> 00:08:50,240
But if you want to write your class structure and they and a really complicated system, that's such a more difficult, you know, it's like the difference between lane assist and self driving, right?

119
00:08:50,240 --> 00:08:58,400
And that's why we can we see lane assist exist, but self driving seems to be so hard to get to because of how much harder that is as a problem.

120
00:08:58,400 --> 00:09:02,160
And I think that it's very easy to fit a straight line upwards to these things.

121
00:09:02,160 --> 00:09:06,440
You say, well, they didn't do anything and now they're doing this, which means they're going to be doing this.

122
00:09:06,440 --> 00:09:09,080
It may get a lot harder and plateau out, right?

123
00:09:09,080 --> 00:09:12,040
We, you know, it's difficult to say for sure.

124
00:09:12,040 --> 00:09:18,120
I think that there's going to be a very strong need for people in the loop for a long time further.

125
00:09:18,120 --> 00:09:31,680
I mean, as an example, outside of programming in medical science, AI is obviously used quite a lot to help with diagnosis and things, but almost no AI systems are used just on their own with no human oversight.

126
00:09:31,680 --> 00:09:33,800
Because for a start, because we don't trust them yet.

127
00:09:33,800 --> 00:09:35,600
And also because patients don't trust them.

128
00:09:35,600 --> 00:09:40,680
Patients don't want an AI, even if it's good, making their health decisions, right?

129
00:09:40,680 --> 00:09:42,640
Like not yet, you know.

130
00:09:42,640 --> 00:09:45,720
And so I think also culturally, we're not quite ready.

131
00:09:45,720 --> 00:09:53,280
And I know a few companies that are not using co-pilot because they're not absolutely sure of the copyright on the code and think, you know, there's questions that haven't been answered.

132
00:09:53,280 --> 00:10:00,680
I think if you're looking for it to be a software developer or you're looking for a career in security or career in AI, there's still plenty of things to do.

133
00:10:00,680 --> 00:10:02,640
So I wouldn't personally worry about that.

134
00:10:02,640 --> 00:10:11,280
I think we mentioned this last time, and I want to give people firstly, you know, a way to make themselves more valuable and then a path to get there.

135
00:10:11,280 --> 00:10:18,200
You mentioned that, you know, if you attach AI to any skill that you've got, it's going to make you more valuable.

136
00:10:18,200 --> 00:10:19,840
I assume that's still the case.

137
00:10:19,840 --> 00:10:21,880
And then I want to ask you, Mike, how do I get there?

138
00:10:21,880 --> 00:10:24,640
And it also makes you more experienced at dealing with things like this.

139
00:10:24,640 --> 00:10:28,880
When something comes along, you can sit back and you can say, OK, how impressive is this?

140
00:10:28,880 --> 00:10:31,160
Let's think about what it's doing and how it works.

141
00:10:31,160 --> 00:10:39,400
And, you know, some understanding of how these things work, you don't have to understand deep down transformer networks if you want to understand roughly what they're doing and how they've been trained.

142
00:10:39,400 --> 00:10:45,720
Yeah, I would say some knowledge of statistical analysis and data, data processing in general is really, really important, right?

143
00:10:45,720 --> 00:10:46,960
People mock Excel.

144
00:10:46,960 --> 00:10:49,120
Excel is, I think, one of the best products ever written.

145
00:10:49,120 --> 00:10:50,880
It's totally ubiquitous.

146
00:10:50,880 --> 00:10:55,800
It's very powerful and it underpins the huge amounts of, you know, financial systems and other systems.

147
00:10:55,800 --> 00:10:58,720
I use it all the time for student marks, right?

148
00:10:58,720 --> 00:11:05,320
So, you know, you get a table of data that comes in and it doesn't make any sense what we're going to look at, how we're going to deal with this, right?

149
00:11:05,320 --> 00:11:07,800
And how we're going to make decisions based on this data.

150
00:11:07,800 --> 00:11:12,480
And things like data science and machine learning will help you deal with some of these problems.

151
00:11:12,480 --> 00:11:16,160
People who want to become experts in AI obviously need to delve a bit deeper.

152
00:11:16,160 --> 00:11:21,920
But I think for a lot of people, AI can just solve small problems in your pipeline that might make things a little bit easier.

153
00:11:21,920 --> 00:11:25,520
Having that extra string in your bow is not a terrible idea.

154
00:11:25,520 --> 00:11:30,960
So, in the previous videos, I told people you need to learn AI and it's something that I want to really focus on this year.

155
00:11:30,960 --> 00:11:34,680
And this is why I'm talking to you, you know, right in the beginning of the year.

156
00:11:34,680 --> 00:11:39,800
Have you got, like, courses, places that I can go to, books that I can read?

157
00:11:39,800 --> 00:11:47,320
Any recommendations of how do I go from, like, where I am now, zero knowledge to at least, you know, getting down that path to be able to put it on my resume?

158
00:11:47,320 --> 00:11:52,960
There are loads, there's loads of books and resources in Python to learn machine learning and data science.

159
00:11:52,960 --> 00:11:55,160
And that would be a great place to start.

160
00:11:55,160 --> 00:11:58,680
You know, I've said it before, many times, I have a love-hate relationship with Python.

161
00:11:58,680 --> 00:12:00,760
I like it sometimes and I don't like it other times.

162
00:12:00,760 --> 00:12:06,280
At the end of the day, there are libraries in Python that do quite incredible machine learning and make your life a lot easier.

163
00:12:06,280 --> 00:12:10,560
Right, so we've got things like scikit-learn, we've got TensorFlow and PyTorch, of course.

164
00:12:10,560 --> 00:12:16,200
But there are tutorials and books written around these things and they take you from, I don't know what this network is,

165
00:12:16,200 --> 00:12:19,360
to I can actually get one of these networks running on a machine.

166
00:12:19,360 --> 00:12:23,080
And it's often not that much code because of these libraries do a lot of heavy lifting for you.

167
00:12:23,120 --> 00:12:28,200
Often it becomes more plug-in building books together than it does writing your network layers from scratch,

168
00:12:28,200 --> 00:12:29,800
which we don't do anymore.

169
00:12:29,800 --> 00:12:33,960
You know, so you can start by just plugging some things together and I've got a rudimentary network

170
00:12:33,960 --> 00:12:36,720
that I don't really understand that's doing this classification.

171
00:12:36,720 --> 00:12:39,760
And before long, you've made your classification problem a little bit more complicated

172
00:12:39,760 --> 00:12:41,320
and you've got multi-class classification.

173
00:12:41,320 --> 00:12:44,960
I mean, you've got a slightly different data set and then you've solved a data augmentation problem

174
00:12:44,960 --> 00:12:49,000
and you can add these things in and slowly work towards a bit more experience.

175
00:12:49,000 --> 00:12:52,880
You know, I have a number of undergraduate project students every year.

176
00:12:52,880 --> 00:13:01,040
So in university, in the third year, you often do a dissertation, which is like a focused project over a whole year.

177
00:13:01,040 --> 00:13:05,720
Often most of my dissertation projects are going to be on AI and something like this.

178
00:13:05,720 --> 00:13:10,040
And, you know, these are students who've done some, you know, machine learning, maybe a little bit in their modules

179
00:13:10,040 --> 00:13:12,320
throughout their undergraduate and they know how to code.

180
00:13:12,320 --> 00:13:16,640
But a lot of it's new, you know, we pick it up and we run with it and we do some great stuff.

181
00:13:16,640 --> 00:13:20,640
I've got some students in the second year solving Rubik's cubes,

182
00:13:20,680 --> 00:13:23,400
using machine learning to detect where the colors are and things like this.

183
00:13:23,400 --> 00:13:24,680
And this is from scratch, right?

184
00:13:24,680 --> 00:13:29,120
So this is people who haven't done machine learning before and I can point them in the right direction.

185
00:13:29,120 --> 00:13:33,080
I think it is very doable and I think it's, you know, it's fun as well, right?

186
00:13:33,080 --> 00:13:36,080
There's nothing more satisfying to me than you've trained a network

187
00:13:36,080 --> 00:13:39,640
and it's just classifying really accurately whatever it was you wanted to do.

188
00:13:39,640 --> 00:13:43,200
Basically, my job is looking at numbers go up and I like when they go up.

189
00:13:43,200 --> 00:13:47,520
So Mike, I mean, I'd love to come to Nottingham University and attend your courses,

190
00:13:47,520 --> 00:13:50,520
but obviously I can't and so can, you know, most of us can't.

191
00:13:51,960 --> 00:13:56,680
Do you have any like resources or ideas that things, places I can go to to learn?

192
00:13:56,680 --> 00:14:00,960
Often the first course I recommend for everyone is to take Andrew Ung's Coursera course, right?

193
00:14:00,960 --> 00:14:01,840
Very popular.

194
00:14:01,840 --> 00:14:04,960
I mean, I don't know how many times it's been taken now, millions of times.

195
00:14:04,960 --> 00:14:07,360
It's Andrew Ung's course, a course on machine learning.

196
00:14:07,360 --> 00:14:10,000
There is a deep learning follow up to it, which I haven't I haven't done

197
00:14:10,000 --> 00:14:12,200
because probably I actually already know deep learning.

198
00:14:12,200 --> 00:14:14,880
But the machine learning course is really good.

199
00:14:14,920 --> 00:14:19,160
It's a good understanding of some of the key concepts in machine learning

200
00:14:19,160 --> 00:14:20,840
and not specifically about it.

201
00:14:20,840 --> 00:14:23,400
Yes, a little bit about how neural networks work and things like this.

202
00:14:23,400 --> 00:14:26,280
And it can be a little bit mathematical is my experience of it.

203
00:14:26,280 --> 00:14:30,240
But if you if you watch it anyway, you're going to pick up a lot of tips and tricks.

204
00:14:30,240 --> 00:14:33,880
So things like watching your network train over time

205
00:14:33,880 --> 00:14:37,840
and reacting to how that works and doesn't work and making decisions based on this.

206
00:14:37,840 --> 00:14:41,120
These are the things really I think that people who want to do machine learning

207
00:14:41,160 --> 00:14:45,160
in an applied way in a in a in a in a in a business or in an industry.

208
00:14:45,480 --> 00:14:46,720
That's what they need to be able to do.

209
00:14:46,720 --> 00:14:50,120
A lot of them are not going to be writing neural networks from scratch

210
00:14:50,120 --> 00:14:52,520
or designing the number of layers in your network.

211
00:14:52,720 --> 00:14:55,920
They're going to take a network that we know works and run it on some new data.

212
00:14:56,000 --> 00:14:58,760
And if that works great the first time, then that's fabulous.

213
00:14:58,760 --> 00:15:00,800
But if it doesn't, what do you do then?

214
00:15:00,960 --> 00:15:04,720
And these are things that you're going to learn and start learning that Coursera course.

215
00:15:04,720 --> 00:15:08,600
Joshua Bengio and others have written a book just called Deep Learning,

216
00:15:08,600 --> 00:15:09,680
which is very popular.

217
00:15:09,680 --> 00:15:13,160
Again, obviously, it can go into a little bit of heavy math detail,

218
00:15:13,440 --> 00:15:14,760
but it's very popular.

219
00:15:14,760 --> 00:15:16,400
I would say don't read it end to end.

220
00:15:16,400 --> 00:15:18,760
It's one to dip into while you're doing some tutorials

221
00:15:18,760 --> 00:15:20,400
to understand a bit more about the theory.

222
00:15:20,400 --> 00:15:24,360
And after that, personally, I would get I would do the PyTorch tutorials

223
00:15:24,480 --> 00:15:26,160
or the psychic learn tutorials.

224
00:15:26,160 --> 00:15:29,680
They can be directed at your own pace and they will include

225
00:15:29,880 --> 00:15:32,200
they'll give you experience in all those different things, right?

226
00:15:32,200 --> 00:15:34,760
There's there's tutorials on things like reinforcement learning,

227
00:15:34,760 --> 00:15:37,920
but also just standard CNNs and transformers and things like this.

228
00:15:38,000 --> 00:15:41,440
You know, and don't don't worry about you don't have to do all of those on day one.

229
00:15:41,520 --> 00:15:44,320
On day one, we're talking about what is classification?

230
00:15:44,320 --> 00:15:45,400
What is regression?

231
00:15:45,400 --> 00:15:47,440
Maybe get something little going, right?

232
00:15:47,440 --> 00:15:49,080
Really, you know, start yourself off

233
00:15:49,080 --> 00:15:51,920
size and slow and build up the complexity as we go, right?

234
00:15:52,040 --> 00:15:54,160
It's the same with any subject in computer science.

235
00:15:54,160 --> 00:15:55,720
You can't learn everything on the first day.

236
00:15:55,720 --> 00:15:57,680
So you just have to take it a little bit at a time.

237
00:15:57,680 --> 00:16:00,320
I'm glad you mentioned computer science.

238
00:16:00,320 --> 00:16:05,760
Do you think it's time to for more of us to learn computer science type stuff

239
00:16:05,760 --> 00:16:09,920
because of AI like maths and all these computer science stuff and not really?

240
00:16:09,920 --> 00:16:13,120
I think that it's it wouldn't it's not necessary for everyone to do that.

241
00:16:13,120 --> 00:16:16,320
I think that, you know, I would encourage everyone to do computer science,

242
00:16:16,320 --> 00:16:20,760
because I would, but I think that sometimes both computer science

243
00:16:20,760 --> 00:16:24,160
and industry have a sort of reverse snobbery about each other, right?

244
00:16:24,160 --> 00:16:25,320
Which I don't like very much.

245
00:16:25,320 --> 00:16:28,160
So, for example, computer scientists might say, well, if someone didn't do a degree,

246
00:16:28,160 --> 00:16:30,200
you know, what do we know about computers, right?

247
00:16:30,200 --> 00:16:31,080
Which is not true.

248
00:16:31,080 --> 00:16:34,800
And someone who's who got on fine without a degree might go,

249
00:16:34,800 --> 00:16:37,960
why will I go and get student loans and do a degree?

250
00:16:37,960 --> 00:16:39,800
And different paths are all valid.

251
00:16:39,800 --> 00:16:42,240
I don't know why we're having this conversation.

252
00:16:42,240 --> 00:16:45,960
And I think there are there are elements of maths in machine learning,

253
00:16:45,960 --> 00:16:49,560
which help, I suppose, me to understand it a bit better

254
00:16:49,560 --> 00:16:52,560
when someone comes with a particularly weird problem that doesn't, you know,

255
00:16:52,560 --> 00:16:54,920
they've added another layer and it's not training. Why is that?

256
00:16:55,280 --> 00:16:58,040
They also help me sometimes when I'm reading papers,

257
00:16:58,040 --> 00:17:00,800
because papers, they can have a lot of mathematical notation in.

258
00:17:00,800 --> 00:17:03,360
And sometimes that's not necessary and they've just added it in.

259
00:17:03,360 --> 00:17:06,960
But often it's just it's just to be absolutely clear about what they've done.

260
00:17:06,960 --> 00:17:10,160
And often the mathematical notation is necessary to achieve that

261
00:17:10,160 --> 00:17:12,720
rather than writing it in sort of flavourful text.

262
00:17:12,720 --> 00:17:16,840
But to begin with machine learning, you don't necessarily need to know those things.

263
00:17:16,840 --> 00:17:19,680
You know, you can train a network in PyTorch with a knowledge,

264
00:17:19,680 --> 00:17:22,840
a rudimentary knowledge of Python and following some tutorials,

265
00:17:22,840 --> 00:17:24,640
and you'll pick up the rest as you go.

266
00:17:24,640 --> 00:17:28,240
The really complicated maths like back propagation, which is how we train it,

267
00:17:28,240 --> 00:17:31,040
that's all taken care of under the hood. You don't see that.

268
00:17:31,040 --> 00:17:32,880
It's not something unless you're really interested.

269
00:17:32,880 --> 00:17:34,520
It's not something to concern yourself with.

270
00:17:34,520 --> 00:17:38,080
But I mean, the great thing is if I'm in industry, or I'm into cyber,

271
00:17:38,080 --> 00:17:44,080
or dev or whatever, I can really enhance my career prospects

272
00:17:44,080 --> 00:17:47,600
and the future by just adding this on to my skills.

273
00:17:47,640 --> 00:17:50,360
Yeah, but I also think that, and I mentioned it before,

274
00:17:50,520 --> 00:17:54,760
I think the other thing is it makes you much more resistant to hype

275
00:17:54,760 --> 00:17:56,560
and to concerns over things.

276
00:17:56,560 --> 00:17:59,040
And also when someone comes to you and says, oh, yeah, I've trained a neural network

277
00:17:59,040 --> 00:18:01,160
to do X, Y and Z, you can start to think,

278
00:18:01,240 --> 00:18:02,480
doesn't sound very likely, right?

279
00:18:02,480 --> 00:18:05,800
That sounds like the sort of thing that maybe is a bit fanciful, right?

280
00:18:05,800 --> 00:18:09,080
Let's deal with, let's look at their data and see if that's actually true,

281
00:18:09,080 --> 00:18:09,680
what they've done.

282
00:18:09,680 --> 00:18:13,480
And I think one of the reasons that chat GPT and stuff have been so hyped recently

283
00:18:13,480 --> 00:18:15,520
is because most people don't know what it is.

284
00:18:15,520 --> 00:18:17,480
And so when you see it doing what it does,

285
00:18:17,480 --> 00:18:21,520
you think this thing must basically be a person, right?

286
00:18:21,520 --> 00:18:22,880
Because it's acting like one.

287
00:18:22,880 --> 00:18:26,120
But actually, it's only acting like one in a very narrow thing.

288
00:18:26,440 --> 00:18:29,120
And we know how it's trained and how it's trained

289
00:18:29,120 --> 00:18:33,560
doesn't imply necessarily that it's got any human qualities, right?

290
00:18:33,560 --> 00:18:37,440
It might, but I don't, gut tells me not quite, right?

291
00:18:37,440 --> 00:18:41,040
But the point is that I can, I'm sort of more resistant to that in some sense,

292
00:18:41,040 --> 00:18:44,160
because I know how it works underneath.

293
00:18:44,160 --> 00:18:46,520
And I sort of think I've trained all these networks

294
00:18:46,520 --> 00:18:49,200
and this is a bigger version of networks that I've trained myself.

295
00:18:49,200 --> 00:18:51,400
I don't see what's different about,

296
00:18:51,400 --> 00:18:53,680
but so different about that that it would suddenly be

297
00:18:53,680 --> 00:18:56,640
unbelievable, be intelligent compared to anything else, if that makes sense.

298
00:18:56,680 --> 00:18:59,480
Some knowledge of how what some of these technologies are,

299
00:18:59,480 --> 00:19:04,760
just like knowledge of, you know, some companies trying to sell you a new firewall

300
00:19:04,760 --> 00:19:09,360
with next generation antivirus on it that has all kinds of machine learning.

301
00:19:09,360 --> 00:19:11,200
Well, if you understand a bit about machine learning,

302
00:19:11,200 --> 00:19:13,160
you'll know what it will and won't do, right?

303
00:19:13,160 --> 00:19:15,800
And that will allow you to make a better informed purchase decision.

304
00:19:15,800 --> 00:19:17,880
And the answer is it'll work pretty well, right?

305
00:19:17,880 --> 00:19:21,920
But nothing's perfect and machine learning is only as good as a training day to and so on.

306
00:19:21,920 --> 00:19:23,680
So there's lots of things you can ask.

307
00:19:23,680 --> 00:19:25,160
And you can ask really difficult questions

308
00:19:25,160 --> 00:19:27,080
instead of people that come and try and sell it to you.

309
00:19:27,080 --> 00:19:29,000
Especially with things like Twitter and the news,

310
00:19:29,000 --> 00:19:31,800
it's very easy to get carried away in this hype cycle, right?

311
00:19:31,800 --> 00:19:33,280
Lots of technologies have this.

312
00:19:33,280 --> 00:19:35,760
It's in the interest of these companies to make these massive models

313
00:19:35,760 --> 00:19:37,760
of incredibly impressive performance.

314
00:19:37,760 --> 00:19:41,520
I think we're a long way from full automation of a lot of these tasks,

315
00:19:41,520 --> 00:19:44,680
even if it might appear that way at a sort of superficial level.

316
00:19:44,680 --> 00:19:47,320
But on the other hand, they're really promising in some other ways, right?

317
00:19:47,320 --> 00:19:50,640
So one of the things that I found that chat GPT is really good at

318
00:19:50,640 --> 00:19:53,400
is paraphrasing text and vice versa.

319
00:19:53,440 --> 00:19:55,760
So you have a text that you don't quite understand,

320
00:19:55,760 --> 00:19:58,440
say, please can you read this and tell me what it means?

321
00:19:58,440 --> 00:20:02,080
Or please can you summarize these bullet points in an email or something like this?

322
00:20:02,080 --> 00:20:06,160
You know, these kind of functions, I think, are actually working really well, right?

323
00:20:06,160 --> 00:20:10,480
Because those are functions that rely on their text to text.

324
00:20:10,480 --> 00:20:12,040
They're meant for text to text, right?

325
00:20:12,040 --> 00:20:13,920
They are, that's kind of what they're for.

326
00:20:13,920 --> 00:20:16,240
And I think that those are ones that are really, really good.

327
00:20:16,240 --> 00:20:20,000
I think co-completion is useful when you're asking limited things

328
00:20:20,000 --> 00:20:22,320
that you can carefully check quite quickly.

329
00:20:22,320 --> 00:20:24,520
Don't ask it to produce a thousand lines of code

330
00:20:24,520 --> 00:20:27,680
that you expect them to all be perfect, because that's not what it will do, right?

331
00:20:27,680 --> 00:20:29,960
And you'll end up with a lot of weird bugs.

332
00:20:29,960 --> 00:20:32,680
Or, I mean, there was this paper that was released just the other day, actually,

333
00:20:32,680 --> 00:20:38,160
from Stanford that said that they audited code from about 30 to 35 researchers

334
00:20:38,160 --> 00:20:42,320
who some of them were using AI to produce some of the code

335
00:20:42,320 --> 00:20:43,520
and some of them weren't.

336
00:20:43,520 --> 00:20:46,880
And the AI produced code had more vulnerabilities in it.

337
00:20:46,880 --> 00:20:51,000
And that's because when the AI produces code that works,

338
00:20:51,040 --> 00:20:54,040
but let's say it uses ECB mode in AS,

339
00:20:54,040 --> 00:20:57,360
or it uses a slightly weak key derivation or something, I don't know,

340
00:20:57,360 --> 00:21:00,400
something subtle, if they don't know about that subject already,

341
00:21:00,400 --> 00:21:02,600
they might accept that change, if that makes sense, right?

342
00:21:02,600 --> 00:21:06,400
And actually, so this is why you need to still be an expert in your field,

343
00:21:06,400 --> 00:21:09,440
because you can't just rely on it to do it for you yet.

344
00:21:09,440 --> 00:21:11,120
You've got to be there saying,

345
00:21:11,120 --> 00:21:13,800
I think that's okay, or I don't think that's okay,

346
00:21:13,800 --> 00:21:15,240
and make those decisions for yourself.

347
00:21:15,240 --> 00:21:18,680
Yeah, I mean, it's a limited study, but it's not that limited,

348
00:21:18,680 --> 00:21:20,240
and it makes a very valid point.

349
00:21:20,240 --> 00:21:22,760
I think the real danger is people who...

350
00:21:22,760 --> 00:21:24,600
And I should carry out this by saying,

351
00:21:24,600 --> 00:21:27,480
I'm not selling short these incredible technologies.

352
00:21:27,480 --> 00:21:29,000
I'm just saying that it would be very silly

353
00:21:29,000 --> 00:21:31,840
to just completely use them blind and never check what they do, right?

354
00:21:31,840 --> 00:21:34,080
Because we know they just make stuff up a lot of the time.

355
00:21:34,080 --> 00:21:36,560
I think a bit of domain knowledge is always going to help.

356
00:21:36,560 --> 00:21:39,760
Yeah, I mean, it's interesting, because I did some tests with Cisco devices,

357
00:21:39,760 --> 00:21:41,480
and it's amazing.

358
00:21:41,480 --> 00:21:44,960
Like, first time it got it perfect, then I wanted to do it for a video,

359
00:21:44,960 --> 00:21:48,280
and then it wasn't good, and I did like five or six attempts,

360
00:21:48,280 --> 00:21:49,760
and none of them were perfect.

361
00:21:49,760 --> 00:21:50,600
Yeah, I think...

362
00:21:50,600 --> 00:21:53,320
And if I didn't know what it was doing, I would have accepted it.

363
00:21:53,320 --> 00:21:53,920
Sorry, go on.

364
00:21:53,920 --> 00:21:55,800
Yeah, and the other thing is that, you know,

365
00:21:55,800 --> 00:21:57,440
if you think about the data that it's trained on,

366
00:21:57,440 --> 00:22:00,640
it's got some 40 plus billion tokens, right?

367
00:22:00,640 --> 00:22:03,120
It's just internet text, we'll just leave it at that, right?

368
00:22:03,120 --> 00:22:04,360
Loads and loads of text.

369
00:22:04,360 --> 00:22:08,840
Cisco-related text is only going to form a very, very small fraction of that.

370
00:22:08,840 --> 00:22:11,200
There is very little evidence, because it's not got a world model,

371
00:22:11,200 --> 00:22:13,040
because it's not got an understanding of the world,

372
00:22:13,040 --> 00:22:16,200
where it can bring Cisco in and add it to its model.

373
00:22:16,200 --> 00:22:17,840
It's just doing text completion.

374
00:22:17,880 --> 00:22:20,760
And so, when something is underrepresented in the training set,

375
00:22:20,760 --> 00:22:23,160
it's going to probably be worse performing

376
00:22:23,160 --> 00:22:25,560
when it comes to actually running it later, right?

377
00:22:25,560 --> 00:22:29,240
So when you say, write me something in the style of Shakespeare,

378
00:22:29,240 --> 00:22:30,480
it's going to do really well,

379
00:22:30,480 --> 00:22:32,880
because there's Shakespeare all over the internet, right?

380
00:22:32,880 --> 00:22:35,360
Some tasks are going to be very solvable,

381
00:22:35,360 --> 00:22:36,080
because they're just...

382
00:22:36,080 --> 00:22:38,000
They're hugely represented in the training set,

383
00:22:38,000 --> 00:22:39,080
they work really well.

384
00:22:39,080 --> 00:22:41,040
And some tasks are really niche,

385
00:22:41,040 --> 00:22:42,400
and you probably don't know which ones are niche,

386
00:22:42,400 --> 00:22:43,800
because you haven't seen the training set.

387
00:22:43,800 --> 00:22:46,840
I say, write me a link expression, and it does it really well.

388
00:22:46,840 --> 00:22:48,840
And when I say, write me a link expression using some other thing,

389
00:22:48,840 --> 00:22:51,440
and that isn't in the training set, and it produces me a wrong answer.

390
00:22:51,440 --> 00:22:53,760
And I don't know until I run it whether that's the case.

391
00:22:53,760 --> 00:22:57,160
So I have to understand and be able to read that code,

392
00:22:57,160 --> 00:22:59,600
because otherwise I can't possibly put it into my system.

393
00:22:59,600 --> 00:23:02,560
And it goes back to the exact same problem with medicine, right?

394
00:23:02,560 --> 00:23:05,240
It might be that we're absolutely confident that this AI

395
00:23:05,240 --> 00:23:07,400
will look at this image and make the correct decision,

396
00:23:07,400 --> 00:23:08,800
but we're not absolutely sure.

397
00:23:08,800 --> 00:23:10,560
And while we're not absolutely sure,

398
00:23:10,560 --> 00:23:13,120
do we want to completely take a human out of a loop there?

399
00:23:13,120 --> 00:23:15,000
There's questions that we have to think about.

400
00:23:15,000 --> 00:23:19,640
So do you think it'll become like the AI might do a lot of the low-level donkey...

401
00:23:19,640 --> 00:23:23,760
I think that's much closer to what will happen.

402
00:23:23,760 --> 00:23:28,600
So I think there's a phrase in medicine called CAD, or computer-aided diagnosis.

403
00:23:28,600 --> 00:23:31,560
And the idea is that instead of the doctor not making a decision,

404
00:23:31,560 --> 00:23:34,480
the doctor will be guided into a decision by the AI saying,

405
00:23:34,480 --> 00:23:37,840
we've noticed these spots over here in this image, is that relevant to you?

406
00:23:37,840 --> 00:23:39,080
And it will speed them up, right?

407
00:23:39,080 --> 00:23:44,240
And if we can make doctors or medics 50% more efficient, that's a huge boost.

408
00:23:44,240 --> 00:23:46,280
Rather than try and put it all on the AI.

409
00:23:46,280 --> 00:23:47,760
And similarly, it works in code.

410
00:23:47,760 --> 00:23:49,280
If you can produce boilerplate code,

411
00:23:49,280 --> 00:23:53,040
if you can get it to bootstrap, spring boot, configuration files for you,

412
00:23:53,040 --> 00:23:54,600
fabulous, do that, right?

413
00:23:54,600 --> 00:23:58,680
And then that saves you half an hour to an hour of doing some actual code

414
00:23:58,680 --> 00:23:59,800
or making sure that it works.

415
00:23:59,800 --> 00:24:05,200
But what I would avoid doing is trying to have it write everything for you

416
00:24:05,200 --> 00:24:07,560
and replace yourself because I don't think it'll work.

417
00:24:07,560 --> 00:24:12,280
I think you'll end up really frustrated that your code doesn't get past any of your reviews

418
00:24:12,280 --> 00:24:14,160
because it doesn't work, right?

419
00:24:14,160 --> 00:24:15,560
I was going to say, I love what you said, though,

420
00:24:15,560 --> 00:24:17,960
because with that example at Stanford,

421
00:24:17,960 --> 00:24:21,600
if people had just accepted the code,

422
00:24:21,600 --> 00:24:25,760
there's hidden vulnerabilities in the code that wouldn't have been picked up.

423
00:24:25,760 --> 00:24:28,480
Yeah, and then there's a combination of issues, right?

424
00:24:28,480 --> 00:24:30,880
Is it that the developer needs to know more about these subjects

425
00:24:30,880 --> 00:24:33,280
or is it that there's someone that would normally be on that team

426
00:24:33,280 --> 00:24:34,480
that wasn't auditing that code,

427
00:24:34,480 --> 00:24:36,600
that would have been auditing that code at that time, you know?

428
00:24:36,600 --> 00:24:38,920
Because you have security teams sometimes who are specialists in this.

429
00:24:38,920 --> 00:24:40,520
But I think it's that same argument.

430
00:24:40,520 --> 00:24:44,720
In some ways, if someone has a small amount of knowledge of computer security,

431
00:24:44,720 --> 00:24:48,000
that might allow them to be more resistant when code appears that does this.

432
00:24:48,000 --> 00:24:49,320
And that's the same thing with the AI.

433
00:24:49,320 --> 00:24:53,440
If you know a little bit about AI, maybe you can better deal with it when something comes along.

434
00:24:53,440 --> 00:24:57,680
So I think a little bit of knowledge in lots of these things is often useful for that reason.

435
00:24:57,680 --> 00:24:59,920
Mike, so how has this affected like university life?

436
00:24:59,920 --> 00:25:06,680
Because I've heard people talk about how students can just get chat GPT to write their essays and stuff like that.

437
00:25:06,760 --> 00:25:10,920
And you can't see the difference between a student and a human, sorry, and a chat GPT.

438
00:25:10,920 --> 00:25:13,560
Yeah, I think it's very subject dependent.

439
00:25:13,560 --> 00:25:14,480
I think that's one thing.

440
00:25:14,480 --> 00:25:18,640
So what we've done is we've actually been running some tests, right?

441
00:25:18,640 --> 00:25:20,720
Because so, you know, it was very kind of open,

442
00:25:20,720 --> 00:25:22,600
they had to drop this tool just before exams.

443
00:25:23,280 --> 00:25:24,480
Yeah, exactly.

444
00:25:25,480 --> 00:25:27,720
Yeah, we've run some tests and I think it depends on it.

445
00:25:27,720 --> 00:25:32,240
If I show, I suppose we're doing a computer security exam, which actually I teach.

446
00:25:32,240 --> 00:25:35,400
So, you know, and I ask a very simple question,

447
00:25:35,640 --> 00:25:38,560
a question like what's a good encryption algorithm to use?

448
00:25:38,560 --> 00:25:40,040
Chat GPT can answer that.

449
00:25:40,040 --> 00:25:43,880
So it would be unwise of me to ask that question in an exam, I suppose, what we say.

450
00:25:43,880 --> 00:25:47,080
In some sense, I think it's another variant of a search engine.

451
00:25:47,080 --> 00:25:50,120
So if a student could, you know, we call it academic misconduct, right?

452
00:25:50,120 --> 00:25:52,080
If a student was going to use a search engine to do that,

453
00:25:52,080 --> 00:25:54,400
they could also have a go at using chat GPT.

454
00:25:54,400 --> 00:25:58,840
It has the advantage for that student that it's generating very plausible looking answers.

455
00:25:58,840 --> 00:26:00,800
Sometimes they're completely wrong, right?

456
00:26:00,800 --> 00:26:05,000
And those answers are going to get marked very far down when they come in front of a convenience.

457
00:26:05,000 --> 00:26:07,080
So I think your mileage may vary

458
00:26:07,080 --> 00:26:11,080
if you think you can get through a university degree using just AI tools.

459
00:26:11,080 --> 00:26:12,720
It's something we have to consider, right?

460
00:26:12,720 --> 00:26:14,400
Now, some of our exams are face-to-face.

461
00:26:14,400 --> 00:26:15,720
They aren't really affected, right?

462
00:26:15,720 --> 00:26:17,320
You know, we're talking about coursework essays,

463
00:26:17,320 --> 00:26:22,560
and I don't know, I haven't spoken too much to other schools in university and other subject areas,

464
00:26:22,560 --> 00:26:25,200
but obviously there are lots of essay-based subjects,

465
00:26:25,200 --> 00:26:27,960
but they require very well-written essays.

466
00:26:27,960 --> 00:26:31,760
Chat GPT has a habit of producing general answers to things,

467
00:26:32,000 --> 00:26:35,040
which are sometimes very detailed, but sometimes not quite so detailed.

468
00:26:35,040 --> 00:26:38,480
Again, I think that your mileage would vary if you tried this.

469
00:26:38,480 --> 00:26:43,080
I suspect that it is possible to tell that they're written by Chat GPT to an extent

470
00:26:43,080 --> 00:26:45,840
because it has a way of phrasing things that's quite common.

471
00:26:45,840 --> 00:26:48,040
I've noticed as I produce answers,

472
00:26:48,040 --> 00:26:52,680
but that isn't necessarily all the time, but that's going to be a problem.

473
00:26:52,680 --> 00:26:55,960
It's something that every university on earth is now looking at.

474
00:26:55,960 --> 00:26:58,960
Well, yeah, it's had a big impact.

475
00:26:59,040 --> 00:27:02,240
And you know, when you consider that this is just version one,

476
00:27:02,240 --> 00:27:04,920
and you know, there's going to be a Chat GPT 2 probably,

477
00:27:04,920 --> 00:27:09,440
and Microsoft might release one, and Google release one, and so on and so forth,

478
00:27:09,440 --> 00:27:11,720
there's always going to be one of these tools floating about.

479
00:27:11,720 --> 00:27:15,480
That we have to just be prepared and think about how that's going to work.

480
00:27:15,480 --> 00:27:18,440
I think, I mean, the examples I've seen which have worked really well is like,

481
00:27:18,440 --> 00:27:21,360
if I'm asked to write an essay about something,

482
00:27:21,360 --> 00:27:24,240
I can get it to write something that gives me a lot of ideas,

483
00:27:24,240 --> 00:27:26,640
and then I can just rephrase it in my own voice.

484
00:27:26,680 --> 00:27:29,760
But it helps you a lot from a study point of view, I suppose.

485
00:27:29,760 --> 00:27:31,080
Yeah, and I think it actually does.

486
00:27:31,080 --> 00:27:33,160
And I think, so anyway, that's a big positive, right?

487
00:27:33,160 --> 00:27:36,200
And there are some academics in this school, for example,

488
00:27:36,200 --> 00:27:41,880
and across the world, who operate in a kind of human computer interaction area,

489
00:27:41,880 --> 00:27:45,200
who are very interested in, could you end up writing a better essay

490
00:27:45,200 --> 00:27:47,520
if you worked with a computer to help you out, right?

491
00:27:47,520 --> 00:27:51,720
And in a way, is that not a win for the lecturers as well, if that's the case?

492
00:27:51,720 --> 00:27:53,480
Now, I agree with that to an extent.

493
00:27:53,480 --> 00:27:54,760
I think that's absolutely right.

494
00:27:54,760 --> 00:27:57,640
I think that maybe we can't solve that whole discussion in a month,

495
00:27:57,640 --> 00:27:59,480
right, which is how long it is until our exams.

496
00:27:59,480 --> 00:28:02,600
So, you know, the clock is ticking in somewhat,

497
00:28:02,600 --> 00:28:05,520
it's somewhat in the short term for these issues.

498
00:28:05,520 --> 00:28:09,080
But in the longer term, I think they're going to be really transformative in helping.

499
00:28:09,080 --> 00:28:12,040
You know, there are students who have, who are very, very intelligent,

500
00:28:12,040 --> 00:28:14,600
and they know all the subject area, but they're just not good at exams,

501
00:28:14,600 --> 00:28:16,920
they really struggle to get their thoughts down on paper.

502
00:28:16,920 --> 00:28:19,720
Maybe those students could really be helped by something like this,

503
00:28:19,720 --> 00:28:23,080
because if you give really specific prompts to chat GPT,

504
00:28:23,080 --> 00:28:24,360
you get much better answers.

505
00:28:24,360 --> 00:28:27,400
If a student knows what they're doing and can work with the AI,

506
00:28:27,400 --> 00:28:28,960
I think that's going to be much better.

507
00:28:28,960 --> 00:28:32,280
I mean, I suppose you could have said the same thing for Google,

508
00:28:32,280 --> 00:28:34,240
or, you know, using search engines for...

509
00:28:34,240 --> 00:28:37,040
Yeah, yeah, that's the point that's been made.

510
00:28:37,040 --> 00:28:41,200
I mean, in some ways, I see on Twitter a lot people compare these things to Google.

511
00:28:41,200 --> 00:28:43,880
I would not, because they're very different,

512
00:28:43,880 --> 00:28:45,880
and they don't have no source of actual data.

513
00:28:45,880 --> 00:28:47,640
That's a really important thing to remember.

514
00:28:47,640 --> 00:28:50,880
But they are a complementary tool in many ways,

515
00:28:50,880 --> 00:28:52,440
and they operate in a similar way.

516
00:28:52,480 --> 00:28:54,280
If you were going to try and answer an exam,

517
00:28:54,280 --> 00:28:56,600
you know, you would put the question in, you'd rephrase it,

518
00:28:56,600 --> 00:28:58,280
you'd see what came out, you'd see,

519
00:28:58,280 --> 00:29:01,320
does that look plausible, I'm going to try again, I'm going to edit it, and so on.

520
00:29:01,320 --> 00:29:05,080
In the same way that you would if you were using a search engine to write an essay as well.

521
00:29:05,080 --> 00:29:07,240
And using a search engine to write an essay,

522
00:29:07,240 --> 00:29:09,440
and I don't want to speak for every academic on the planet, right,

523
00:29:09,440 --> 00:29:12,840
but it's not necessarily plagiarism or misconduct,

524
00:29:12,840 --> 00:29:14,200
it depends on how you use it, right.

525
00:29:14,200 --> 00:29:16,960
You know, looking up sources online is absolutely to be encouraged.

526
00:29:16,960 --> 00:29:19,880
It depends on how you're doing this.

527
00:29:19,880 --> 00:29:22,880
I think in the long term we will get a nice balance, actually,

528
00:29:22,880 --> 00:29:25,680
between using it too much and not using it enough.

529
00:29:25,680 --> 00:29:27,800
And I think actually there's another thing, there's another aspect,

530
00:29:27,800 --> 00:29:29,800
which is I think this is plays into your,

531
00:29:29,800 --> 00:29:32,480
this is relevant to your channel's viewers,

532
00:29:32,480 --> 00:29:36,000
is that you shouldn't think of doing a degree or writing a coursework

533
00:29:36,000 --> 00:29:37,640
as just about getting a mark, right.

534
00:29:37,640 --> 00:29:39,000
That's very easy to think about that,

535
00:29:39,000 --> 00:29:42,960
but actually it's about learning something that you can then take and use in your career,

536
00:29:42,960 --> 00:29:43,680
or something like that, right.

537
00:29:43,680 --> 00:29:46,080
We don't teach people to programme, so they pass the exams.

538
00:29:46,080 --> 00:29:48,560
We teach them the programme so that they can go off and be software developers.

539
00:29:48,560 --> 00:29:50,760
If you used AI to write all your work for you,

540
00:29:50,760 --> 00:29:52,360
then you'd get out and you wouldn't be able to get a job

541
00:29:52,360 --> 00:29:53,600
and you wouldn't be able to work in that job

542
00:29:53,600 --> 00:29:56,040
because you wouldn't be able to do any of the computer science.

543
00:29:56,040 --> 00:29:58,040
Actually, I think that if you've got a lot,

544
00:29:58,040 --> 00:29:59,320
because I have quite a lot of learning

545
00:29:59,320 --> 00:30:01,080
and I love to learn about new topics,

546
00:30:01,080 --> 00:30:03,000
particularly, you know, about computer science,

547
00:30:03,000 --> 00:30:05,000
I would never use chat GPT to cheat

548
00:30:05,000 --> 00:30:07,360
because I wouldn't know any of it then, right.

549
00:30:07,360 --> 00:30:09,920
And you know, and I like to learn about these things.

550
00:30:09,920 --> 00:30:11,600
Now, if you want to become an expert in something,

551
00:30:11,600 --> 00:30:12,920
then you're going to need to learn it.

552
00:30:12,920 --> 00:30:15,560
You can't read what chat GPT wrote.

553
00:30:15,560 --> 00:30:17,600
A lot of it comes down to hoping that students

554
00:30:17,640 --> 00:30:19,000
and trying to encourage students to think

555
00:30:19,000 --> 00:30:20,840
that it's about the process of learning

556
00:30:20,840 --> 00:30:22,280
and where they get to at the end,

557
00:30:22,280 --> 00:30:26,080
rather than specifically about a series of kind of barriers

558
00:30:26,080 --> 00:30:28,080
of exams that they have to get through,

559
00:30:28,080 --> 00:30:32,280
which I think is not a good way to look at a degree or any course, really.

560
00:30:32,280 --> 00:30:35,400
You know, it's much better to think about where you'll be at the end, right,

561
00:30:35,400 --> 00:30:38,360
and you'll be in that much better position to do what you want to do next.

562
00:30:38,360 --> 00:30:41,240
That's exactly right. I mean, it's like certification exams.

563
00:30:41,240 --> 00:30:42,840
Same thing, you know, you can go and get all the answers

564
00:30:42,840 --> 00:30:45,240
or the cheater sites or you can actually learn something.

565
00:30:45,240 --> 00:30:47,680
And you haven't done yourself any favours if you get it off,

566
00:30:47,680 --> 00:30:49,120
because you might get a job based on that.

567
00:30:49,120 --> 00:30:50,360
It's not going to go well, right?

568
00:30:50,360 --> 00:30:52,560
Because you don't have any of the knowledge.

569
00:30:52,560 --> 00:30:55,120
You'll always feel like you don't have any of the knowledge as well, right?

570
00:30:55,120 --> 00:30:57,880
You know, actually, you don't take that long to learn these things

571
00:30:57,880 --> 00:30:59,560
if you really put yourself to it,

572
00:30:59,560 --> 00:31:01,880
and you'll be in such a much better position afterwards.

573
00:31:01,880 --> 00:31:05,160
Mike, as always, I really want to thank you for, you know, sharing your knowledge

574
00:31:05,160 --> 00:31:11,440
and, you know, separating the hype from, like, the worries about people's futures.

575
00:31:11,440 --> 00:31:12,720
Thanks so much for making a drill.

576
00:31:12,720 --> 00:31:14,480
Yeah, it's no problem. I'm glad to be on again.

577
00:31:14,520 --> 00:31:15,640
It's been really, really, really good.

578
00:31:15,640 --> 00:31:16,920
Brilliant. Thanks, Mike. Thanks.

