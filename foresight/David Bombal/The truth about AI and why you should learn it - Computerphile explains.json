{"text": " This is a fascinating story we have for you of a senior Google engineer who says one of the company's artificial intelligence systems has become a sentient being. He believed one of the company's artificial intelligence chatbots had become sentient. Engineer Blake Lemoine says a chatbot project he was working on called Lambda can express thoughts and feelings equivalent to that of a child. Google has rejected claims that one of its programs had advanced so much that it had become sentient. That's I think the big issue right is that a lot of people get bogged down deciding well what does sentient actually mean? Hey everyone it's David Bombal back with a very special guest Mike welcome. Oh thanks for having me. So Mike I've seen a lot of your videos on YouTube computer file millions of views on some of the topics that you've done but can you just introduce yourself to the audience for people who might not have seen those videos or don't know what you're doing because you're telling me offline YouTube isn't your main thing you do more than that. That's right yeah so actually in some sense YouTube isn't a side for me right it's just something I did because I thought it would be fun. I'm an academic at Nottingham associate professor and I work teaching security. I research teaching AI and computer vision. It just happened that we have some ties at Nottingham to Brady and Sean who do things like number file and computer file and so computer file was kind of fledgling it had a bit of it was a bit established when I when I started doing them and it kind of just took took off really. I think because I did topics on security and AI and things people thought those were interesting and so I get you know a lot of views on those now but it is still a bit peculiar when people say hello to me you know because I just turn up and do normal things the rest of the time. So you get stopped in the street and it has happened yeah my wife is never impressed when that happens she thinks this is ridiculous but you know it happens from time to time I do I do really enjoy it I get lots of emails from people saying thanks for your videos I enjoy them and that's that's why I do it that's that's what it's for for me. I loved what you said offline you know you someone said that they started computer science because of you. I've had a couple of emails like that and that's the those are the best emails right because I want people to learn about computer science I love computers I'm a massive geek basically I program for fun and the more people do that the more it's a win for me so you know if I can encourage a few people by doing videos but that's what I really want to do. That's fantastic one of the videos I watched obviously in preparation for this interview is this recent video that you put out about AI and that's going to be the topic that we want to talk about today so let me lead with this I get this these kind of emails all the time David is it worth me studying cyber security David is it worth me studying computers because AI are going to take all the jobs away and I think movies over the years like you know there's been so many of these movies where the robots take over and this can you talk about this and you can go into the details if you like but I think this this this sort of recent event that you spoke about in your video hasn't helped the conversation at all so can you tell us about that yeah in what your thoughts are about you know what happened yeah so no I absolutely agree but it didn't help the conversation about was okay I think in my video about was kind of what I tried to end with was basically it doesn't you know in some sense the nuances of where this AI is doesn't interest me that much all I know is it's not where they're suggesting it is at least that's you know that's what I think I suppose at the moment AI is very application driven right so a lot of it is supervised there are other ways of doing it but a lot of it's supervised which means that you have some kind of training set with some inputs and some outputs that you're trying to get the model to learn and then you just train the model until that happens that can work really really really well and so from my own research I do this on things like image segmentation where I'm trying to find objects in images and you know medical image segmentation and things like this but you know in practice if I then take that network and try and run it on street scenes it won't work because it's not trained on street scenes it doesn't know what they are it hasn't got any ability to go oh it's a street now you know and take what it's learned somewhere and apply it somewhere else you know retraining a network is really the only way to do it and that involves even more data right so I don't think at the moment it's realistic to suggest that there's going to be some general intelligence that can just do all of our jobs right you know you've seen github co-pilot that just produces text code and sometimes it will produce a useful function and sometimes it will produce a function full of bugs that you've got to then spend time fixing and have you actually saved any time I don't know the jury's out I think so I wouldn't worry at the moment I'm not worried I mean maybe designing things to replace myself is a huge mistake but I don't think we're there yet so I mean tell us just for people who haven't seen it um haven't seen your video and like haven't read perhaps what's going on there's this google person lambda yeah so what is lambda and what is what what what what was he basically saying um google lambda is a um it's what we call a large language model so it's basically a a very very large neural network designed in a certain way they're all designed in a very similar way and it has more parameters in it than we've ever seen really in a model right or GPT-3 is also very very big and so really what this brings to the table is not so much something new that we've never seen before in AI it's just it's just huge you know orders of magnitude bigger than the kind of networks I would use to do you know complex imaging tasks and what they've basically done is they've trained this this model to read a sentence and then predict what the next word will be and so you could imagine but if you wanted to do this by hand and you had infinite resources you could just look at every sentence that's ever been written by humans and work out for any given let's say 10 words what the next word will always be and if you did that and you had that list of all the possible inputs you do pretty well at generating sentences because at the end of the day that's what people say right this is you've got it on record as what they've said in the past you can just say those things again and so this model is one of those this model is one where you put in some sentences so you might put in a sentence that says what do you think about quantum physics and then what the model will do is predict the next likely word and it will probably say well I'm going to start by saying what I think is and then generate some plausible text on quantum physics because people have written about quantum physics before and that data is in the training set what it hasn't done is learned what quantum physics is or connected to an internet resource that has information on quantum physics and looked it up so in some sense it's a bit like the you know in Star Trek you've got the computer you can talk to and they often ask the computer to do things like you know put the shields up or whatever yeah computer dim lights it's like that but it's not connected to any kind of anything on the ship so it just talks to you and talks back but it never actions anything it never it never has you know it's just going from the text in the training set and I think that's something that's perhaps lost a bit in in when it when it's discussed it's but it's not connected to anything it doesn't even have a memory basically and so it can't reflect on past experience because it has no place to store past experience it has no record of those events and so when it produces sentences that look really really interesting they're actually just really interesting sounding sentences you know and I think so anyway I mean if I if I sort of digress slightly but you know in this particular case what happened was someone from Google who I think was in the ethics department I don't think he was actually responsible for developing this AI basically said look at this chat I've had with it don't you think it's sentient basically is what he said and the answer I think from me and pretty much everyone who understands these models was no it's no it's not and what and I think the thing that bothered me most about it was not particularly one person saying this because he's very entitled to his opinion right you know I think I think it was that the media took it massively seriously and it was all over everywhere is this the next thing and that bugs me somewhat because I don't think it helps for conversation like you say right people start people who don't know what a big a big model a big language model is are going to be a bit worried about this and there's really no reason at this time to be worried and like that bothers me slightly which is why I do my videos to try and tell people about it I mean the problem is the movies predict this happening and then people see this stuff in the news and it's like it's the end of the world and end of my job Arnold and the robots are going to take over so it really doesn't happen it doesn't it really doesn't help and I like what you said I mean in your video which I'll link below you said something that I thought was hilarious you said can python functions get lonely yeah can you explain what you were saying by that yeah so one of the one of the comments in the original chat transcript between this researcher and his friend and his colleague and this lambda AI was do you get lonely and it's spouted off a whole paragraph about how lonely it is and it doesn't make any sense because it's a function call right so you put in your words at the top it runs of what is essentially a big transformer network which is pre-trained on all this data and then it spits out words at the bottom which you read and then it stops executing right because there's no kind of ongoing process like there is in my I mean I like to think that when I'm not immediately saying something to you I'm still there's something going on in there right maybe I mean you know I can't prove it to you but but this is not the case you know and it's just like when you run I mean I made a joke about it but when you run you know reverse string in python you don't worry that it gets lonely the rest of time because it's not executing that's just some code that executed it finished executing and it just lies dormant in memory doing absolutely nothing of interest and that's for me kind of what this model is doing if they developed a model that was always on in some way like maybe it was always doing something and it had memory and it had storage I could I still probably would think I would need some convincing but it had any kind of you know higher level thought process but at least it would be plausible you know it would sort of think well at least it's got something going on in there but I just don't think it's designed that way it's designed as a very very big reverse string and you know I don't worry about those things being sentient yeah but it's crazy I mean I mean the well I mean in my opinion because they kind of they were implying that this AI or whatever was like a human or equivalent to a human and it seems like that's quite a stretch but in you know popular popular culture that's what people equate to AI it seems yeah that that really that that's I think the big issue right is is that a lot of people get bogged down deciding well what does sentient actually mean and that doesn't interest me because when anyone uses the word they're not using it in a different definition they're using it in the definition we think of as like termination and sky net right you know this this researcher wasn't saying I think it's sentient but I define sentience as something like a slightly combinated if statement right he was saying I think it's like a person and it's got memories and it's got experiences and it gets lonely and it needs a lot of feelings and yeah and and without with any with zero evidence to support this and indeed not so much evidence is just it doesn't even make sense so I think you have to be extremely careful using the word sentient not because you might have a different definition but because everyone has the actual same definition right which is actual you know human level cognitive ability but you know which so I don't spend a lot of time worrying about what the definition of sentience is because if I go to someone in the conversation and say this is sentient I think we both understand implicitly what that means to me to say that and so I don't I I think we're arguing about the definition is a bit silly because we actually all secretly agree on the definition yeah I mean I think for the general population I mean I'm not I'm not into the AI piece like you are and that's why you I want to talk to you about it you know I just think people go off movies and popular culture that's sort of what what people that's the impression they get and that's why it was so big on the news perhaps but can you explain AI versus machine learning and like what is machine learning what is AI and perhaps just take us down the road now yeah okay like teach us you know sort of the basics of the stuff yeah so AI is misused in the sense that it's now a catchall right and I will admit I do that to an extent myself and it's partly because I'm lazy right I think I think it's because it means I don't have to define the exact thing that I'm doing yeah at any given time car engines are slightly different but they all at the moment I mean I say they will the combustion engines all do much the same thing even though one's got more cylinders and one's got fewer cylinders and one has a turbo and one doesn't you don't say I you don't miss it well I don't go on about those details I just say I've got a car and it goes so AI I think is a catchall that includes machine learning so you've got AI as a big kind of thing of stuff with loads of stuff in it and even my maze solving video where I just do very simple looking around the corridors of the maze would be defined in some sense as AI right but the Dijkstra algorithm that we use to do network routing and things and other similar algorithms you could define them in some ways as AI because they adapt to messages coming in and they change weights and paths and things but we wouldn't go as far as to say they were you know anyway you know smart in some sense right so I think AI is quite a broad term and then there are things like genetic algorithms evolutionary algorithms which do slightly different things they are arguably less popular or less prevalent perhaps will be the right way to put it but they also come under the umbrella of AI so AI is this very big umbrella term which basically encompasses most most things where you could imagine it was sort of intelligence and then in that you've got machine learning and machine learning is just the idea that you want to try and program a computer without having to program it essentially you want to give it some examples or some other mechanism from which to learn and it comes up with its own rules for what it's going to do so a decision tree is a good example of a very simple you know conceptually simple machine learning approach where you have some kind of data and every time you make a decision you just you just split it in two so maybe you're trying to analyze financial data decide whether people get a new credit card right so the first decision you make is have they ever defaulted on a credit card yes goes this way no goes this way and then the next decision is okay what's their current credit limit it's it's above 7000 it goes this way below 7000 goes this way and you just split this data into two and two and two until at the end you get the actual nodes that have the decisions on right and it's machine learning because what you can do is you can you can basically create this tree but actually change the numbers and values in it and the decisions based on the data so you can say well actually maybe 7000 doesn't work that well we're going to have it at 6500 and change the thresholds and things and you can do this all automatically in the training process so that's the kind of thing we're talking about with machine learning now what happens of course is there's a big push in deep learning which I you know I can also talk about but yeah be great yeah because I mean we just hear the you know I just hear these buzzwords I mean preparing for this interview just like buzzword after buzzword after buzzword and I think a lot of us you know who are not in this sort of field but are interested in it you know so yeah if you can define as much and like yeah yeah sure so I mean so you've got yeah sorry you've got you've got ai right which is which is right here in some subset of actors machine learning which includes what I would kind of call traditional machine learning like support vector machines decision trees random forests right these are all linear regression even right where you're just fitting a line to us to some data and then we have things like slightly more complicated algorithms like artificial neural networks which they I mean they kind of take some inspiration from our brains but I would I would be very careful saying that to me I think you know to suggest it's like our brain is is is is iffy and so yeah yeah but they have their name yeah like that's what they're called and then what we've basically done recently is we've made them much much bigger right and we've introduced other terms like convolutional networks and transformers and things but for the sake of you know this sentence they're just bigger deeper networks that can learn more impressive functions so they can map that input to that output more effectively right because that's what you want to try and do you've got some data you've got some predictions you need to make on that data and your hope is that once you've trained it some new data comes along and you can make some good predictions right I mean let's think of an example suppose suppose I want to you know do um MRI segmentation for medical imaging right so I have 50 patients some of whom unfortunately have some kind of illness some of whom don't and I train the network to try and find the ones that have illness my hope is that when I then sort of fix that network in place and bring in some new patients it will be able to say whether they have that illness or not that's the idea and we'll have done that by basically reconfiguring itself based on the examples I gave it to begin with so doing a technology example it could be something like spotting is this a virus or is it just yeah exactly right and in fact you know modern antiviruses will include some kind of machine learning element probably so you know you might have features derived from so what we what we usually put into the front of a network is something we call features which is um our way of just saying input data right so sometimes you've crafted those features like you've chosen what you think is interesting features to give the network and sometimes you'll just shove something in like you know in antivirus you could you could choose things like how many system calls does it make or you know how many how many bytes is the executable or how many of this particular character does it have in the executable and you could choose those features because you think they are indicative sometimes of malware or not malware you stick them in some kind of a machine learning approach with a load of examples and then say right now change your weights and change your rules internally so that on this training set your prediction is accurate as possible right and so let's say you do that you have 100 000 malware and regular samples you give it to your AI and you just over and over again say right you got that one wrong reconfigure yourself so that next time you get a bit better at predicting it you do that over and over again and the hope is then that when a new virus comes along that you've never seen those same sort of should we say suspicious things exist in it and the network flags that up that's the idea so the the training data is like the the stuff you give it initially which would be this 100 000 like virus and not virus yeah and then you when you say weights you like it's basically saying like if it makes like a hundred system calls rather than 10 or you said some kind of threshold is that right yeah so okay so in a decision tree or something like that that's what would happen there would be some kind of threshold decision based at some point during it for a neural network it's a little bit more complicated and it's what you actually do is you treat all these weights just as numbers and you just calculate mathematical functions based on those numbers so what you might do is multiply all of those numbers that come in by some weights let's say you multiply one of them by two and one of them by negative four one of them by a half and then you add them all up and what that does is take a different amount of each one and then you and then you repeat that process over and over again to try and basically learn a complicated mathematical function that's really the only thing it does you know you're essentially trying to fit a really complicated curve through the data essentially so that you can distinguish between real and fake malware or you know regular executables and malware and and so the weight when I say weight what I'm really talking about is the parameters of my model which influence this mathematical function so the and then you would adjust the the the weights and the mathematical functions based on the result did it get did it's correctly determine that this was malware exactly so so let's suppose we were doing malware right so we think one an output of one means it's definitely malware and an output of zero means it's definitely not malware an output of 0.5 is not very useful to us because we don't know um what we do is we put in a piece of malware or many pieces of malware we run through let's say our deep neural network or whatever it is we're running and it will produce a value between zero and one and then we say well look you gave us a value of 0.7 but actually it was malware this time so you've got an error of 0.3 I wanted you to produce 0.3 higher for that one than you did so can you adjust your mathematical function to next time when I put that malware in produce a value of one and not a value of 0.7 now if you do that for one malware sample it's going to be the worst machine learning ever because you're just going to give it something else and it's going to go I don't know what you mean right because this is nonsense so you have to give it a lot of data and and I guess what you're trying to do is calculate the best average mathematical function that does the best job it can in the general case of all of these malware's right massively optimizing one malware is not useful because it's not going to generalize it's not going to apply in real world to some new malware so you put in 10, 20, 100 different malware at the same time and all of them are trying to go to one or go to zero and you're trying to change the weights to simultaneously do all of those at the same time that's that's what machine learning does basically for a neural network the process for actually doing this it's it's complicated to describe but it's it's fairly intuitive what you do is you because all these weights are involved in the calculation you put your features in for your malware you go all the way forward through the deep learning or the network then you calculate your error and then you go backwards adjusting the weights based on what you just found out right essentially and so if a weight doesn't have any impact on the decision because let's say it just sets everything to zero you won't adjust that weight because it's not useful you will only adjust the ones because you're calculating the influence that each of these weights has on the error you adjust all the ones that have the biggest impact and so the network will kind of try and find its way towards a good function you know and we use a process called stochastic gradient descent often to train this so what we're doing is we're picking random malwares and putting them in and that will often it will often get them wrong right because it's never seen any of these things before and so over time maybe you just nudge it slightly in a better direction and then over many thousands of looks it slowly converges on something that actually makes reasonable decisions that's you know that's the idea so it's a long process and is this what you would call supervised or is it this is definitely supervised so supervised is where you have your your your label ground truth what we was you know our we have labels for data so we're putting our data in we have some labels against which we can compare and that means that we have some idea of how right or wrong the network is in any given case right and that's very very useful and the majority despite what people might say the majority of deep learning or machine learning is supervised learning because it gets results the quickest if I want to detect some illness in MRI having examples of that illness is going to be much much easier so Mike supervised learning if I understand it right is you giving it examples of like you said actual malware or actual like in your MRI scans problems yeah and then you're supervising that it got it right and then you're correcting it yeah and it makes things much easier right so the majority of machine learning is supervised because it is simpler and easier to do if you work in applied areas like me where you're trying to get things to work really really well if you work in industry a lot of what you're trying to do is just minimize that error term you're trying to get as close to good predictions in for the majority of cases so getting some examples is going to get you to converge on that much much more quickly this is you know distinct from something like weakly supervised or unsupervised learning and there's lots of different variants so unsupervised learning is you don't have any labels right maybe the data is too big or the data is too hard to annotate or no one can agree on what the labels are and so the best you're going to be able to do is kind of partition the data into plausible groups so you can say well look we don't know exactly what all these things are but we know that this group is distinct from this group and that's unsupervised so an example would be suppose suppose you work for an online shop and you have a load of data on what different customers have bought one thing you might do is start trying to group customers into some kind of plausible groups based on roughly the things they they're not all going to have bought the exact same thing right so it's not going to be trivial but they might have bought so someone's buying mostly dog related stuff and someone's buying mostly technical gadgets and then what you can do is say well look I put all these people in the tech group and this guy bought this really nice new microphone or news camera so I'm going to recommend that now to other people in the group and maybe I get a few hits and I and I sell a few cameras that way um you can get much more complicatedness but that is an example of perhaps unsupervised learning where you don't need to have some kind of label for everyone you don't need to have labeled me ahead of time as a tech enthusiast you just need to look at the stuff I've been buying I know it's the same as always other people and know that that's interesting right rather than we know exactly what it means that's a great example so in other words you didn't tell the machine who the people were it discovered that based on the patterns of data right yeah and it didn't really even discover who they were it mostly just grouped them and that allowed us to make decisions based on the fact they were grouped now as that happens I've given this group a label of tech enthusiasts but of course you don't need to even know that you just need to know but on average they buy more TVs than everyone else so maybe send them emails about TVs you know it's that kind of idea you can still do supervised learning and other forms of learning with stuff like marketing and and recommender systems and things but you might imagine that that could be one way you would do it and I think it's a good example the problem I see like from listening to you is reality versus the movies or reality versus the news cycle because you always hear about google doing like um like teaching a machine to play chess or whatever the games are and it just like magically gets this done um and it teaches itself kind of like not even knowing what the the rules of the game are so that is a that's something called reinforcement learning a lot of the time reinforcement learning is still supervised learning okay it's just that you get the labels as you go from playing the game so the way it works is you know what you might do is you play a random game of chess where you literally move at random right and you lose and so you get a strong suggestion that maybe next time don't do that like that was stupid so now you move slightly less at random than you did before but it's still pretty bad and you lose again but you know learn a bit and this is basically how they train it so what you do is you play millions and millions and millions of games of chess and every time it goes well you just learn a little something about what was better than that time than what's the time before we're still talking about a network which is a big mathematical function right so we're still talking about something that has weights that you adjust so that when you put an input state in you get the best desirable output state which in this case of course is you won more often than you didn't for me I mean these are fascinating because they're trained in a very different way to the way I would train the network I come up with labeled data and I put it in like and I use the examples with reinforcement learning you have to start trying to give it rewards which is where it gets its labeled data from so is it is it is it is it better that you go 25 moves in chess before you lose or is it better that you checkmate regardless of how long it takes right you know because you might end up in a stalemate you know there's things with playing chess where you might say well look these other goals are also important or something like this and so you can spend a lot of time thinking about different ways you could train the network which I think I think is really interesting perhaps I'm misinterpreting it but it sounds like the hype cycle versus reality there's a big disconnect like the people have this vision that the robots are going to take over but you don't think that's going to happen like anytime soon right yeah I mean I well the funny thing is like I did a lecture once where where I said to everyone you know the char one hash function is absolutely fine right and then the next the next day yeah google released their their two pdfs that had the same char one hash right now that's embarrassing when that happens as a lecturer you know um so you know I don't want to say you know I don't want to say it could never happen what I would say is that the something that's really really good at go or something that's really really good at chess is really really good at chess and that is it right it will do nothing else right as far as I can tell human chess players are also good at other things and we we don't have that generalizability yet is this the age the difference between like specialized knowledge and yeah I mean again we could get bought we could get bogged down and what what the definition means but I think that our official general's urgency to most people watching is just something that kind of is a bit like a human right and certainly is very very general so you could say right this now is a totally different game learn to play it and it will go off and play it and it would still remember how to play chess and it could play all the games you know and it's just super it's super impressive though that doesn't exist will it exist I don't know I mean I think that if we keep making these models bigger we'll probably get to a point within a few decades where they are very impressive at a lot of different tasks but I still am not convinced yet that we've got any real strategy to get past the idea of just you need to like have a load of data right or a load of play a load of games my daughter can have a go at playing a semi-coherent game of chess just having been told the rules of chess and she didn't you know let's say she's not winning any competitions right not yet but she didn't need to play a million games against herself to work out what to do right there's something that she is doing but is much much more impressive than what this AI is doing that isn't to say the AI isn't incredibly impressive it's just very different I do think that the hype cycle is very different to what we actually see on the ground which is that basically a lot of the time I mean you know aside from playing games and reinforcement learning and large language models the majority of what people are doing is trying to find objects segment images and these things are mostly done in a supervised way and they don't generalize but we don't care because we were trying to find those specific objects so that's good and if we need them to do something else we'll retrain them to do something else yeah because my next question I think you've you've already given us the answer and maybe you can just elaborate is what is AI really good at compared and you know it just seems like it's like automation automation has its place but you still it takes like it's just correct me if I'm wrong but it seems to take away like low level tasks that are boring and monotonous or difficult for a human to do and then humans can concentrate on other things yeah what is AI really good at and where do you see it going yeah so AI is that automation is exactly what you what what you write on but with the caveat that you've got to have found a good way to train it to automate it won't just automate stuff you can't just stick it on a on a on a production line and say automate that for me because it did we won't know what to do so yeah from my point of view what AI is really good at is so before I worked in you know at machine learning and deep learning this was a normal computer vision researcher right and so I was you know this is like you know early 2010 something like this time before I mean literally deep learning appeared in about 2014 and before that we didn't have it right there were some networks but no one was really paying attention to them and everyone was just doing normal stuff right and what I would describe as image processing so if I wanted to find something in an image what I would be trying to do is come up with rules in my head about what I needed to do to that image to find those objects and then I would implement those rules and code so I'd say okay first of all go like we're trying to find you know something in MRI so first find all the bright pixels now find all the bright pixels but form a continuous blob that's of this size you know and I start and I try and design an algorithm to find whatever it was I was finding through these if statements and rules right it's just code and what machine learning lets me do is not worry about the the rules because the problem you have if you do if you do it by just coding is you get stuck in edge cases you get stuck on the you know you solve 90% of the issues pretty quickly because 90% of the images are trivial and then that 10% you just will never solve because they're just they don't apply the normal rules that everything else does and you know if you're looking at a sort of medical diagnosis AI or program that's a huge problem but you're just going to miss 10% because you couldn't deal with the edge cases and so from my point of view coming from image analysis that was what it let us solve it allows you because this mathematical function is very very complicated it can learn the edge cases if you give it sufficient numbers of them so you just so actually a lot of the time when I work with biologists or medics and and and they present the images I'll say these are all very nice but have you got any worse ones have you got any really bad ones because the more because the more bad stuff we give it the better it will get at at working when those things come along if you train your AI on a on a 3 or a 7 tesla MRI scanner which is super clear it won't work when you run it on a 1.5 you know so maybe you want to get samples from all the different scanners you know what I mean there's these kind of decisions it actually means that the problem is no longer one of which if statements do I need to write to get this to work it's now what kind of data and how do I present the data to this network to get it to work all right and that so it becomes much more about the input and output problem than it becomes about what you do in the middle which it just learns that's great I mean I just wanted to see if I understand the terms I see terms like artificial intelligence machine learning neural networks and deep learning we've covered all of those is that right yeah so I mean to go into some deep learning what I would say in terms of definition of deep learning is you know earlier I said that you might do I features for your problem right so suppose you're trying to sell cars what you might do is you might come up with some properties of cars that are relevant to its purchase price so you might say okay how many cylinders has it got how many how much horsepower has it got has it got leather seats right as it got air conditioning and you would have all these features and you come up with a list of let's say a hundred different properties of a car and you would stick them in some AI decision tree neural network doesn't matter and then it would spit out a value for you and you would train it on a bunch of examples and you would hopefully have a system that could really nicely predict the value of cars right now the problem is that suppose I've missed out a feature that's absolutely crucial to the value of cars suppose I forgot to put in the engine size and it turns out that 90 percent of the car's value is on how big the engine is right and so I've given it bad data then right and and then I have to go back and have to put data in again and I have to train it all again and you know it's a waste of time and what will actually happen if you try to implement a system where you missed out features is it would never work as well as you hoped and a car would come along that looked good on the features I did give it but actually had a really small engine and it would massively overvalue it or something like this right or undervalue it and you give away a really nice car for almost free what deep learning does is something called representation learning that's the because it's deeper it has the power to also learn the features as well as the decision based on those features so you might say well I can't bother to decide to decide all these features so I'm just going to dump the raw specs or a picture of the car in at the front and have it determine for me the value right and it would be looking at the size and model shape the color the size of the wheels and it would do all this and it would extract the features first inside the network and then it would use that to make a decision so deep learning is often described as just the same network but deeper but actually it's a different I think a different paradigm where you're basically no longer hand crafting what you put in you're just shoving all of it in and it works out what's useful and what's not and so you've explained neural networks already is all right yeah I mean so a neural network yeah so I we talked about how a neural network calculates a weighted sum so it takes some features at one layer and it waits them and then it calculates the sum of those for the next layer and we have something called an activation function in there as well which allows the basically it makes the function a lot more complex right it makes it non-linear makes it learn more powerful things modern deep networks actually have additional operations like convolutions and pooling operations which work on grids of data often right it doesn't have to but you know often they do so what you might do is instead of calculating a weighted sum of all the features you might slide a filter over the image to calculate filters at every location and so it's like a sort of a map of activations and then you might repeat that process over and over again so what what um deep networks are capable of doing convolutional networks is determining features across the whole image right or across the whole of the data stream and then repeating that process over and over again that's how they develop that's how they develop their representation learning right they use the filters to create interesting information before they make a decision you teach security at university but you're doing a lot of the ai side ai stuff as well um i think the the question a lot of people will be asking including myself is do i need to learn some kind of programming language and which language would it be would you recommend and do i need to learn like a whole bunch of math because it sounds like you know math is one of the or maths as we say in the uk is something that you have to it because you have to learn is that right to you know having having some idea of what's going on mathematically helps you from an intuition point of view right because i understand the back propagation process which is how the actual weights have adjusted and that allows me to understand what would happen if i connect two bits of network together in a weird shape or something like this but in practice actually day to day running of a deep network doesn't really involve any maths and and and there is some disagreement in the community about whether you really need to know math at all right you know i'm i sort of go back and forth i sometimes think it's useful and i sometimes think it's not i certainly don't think people should be if they don't like maths should be put off from having a go because i'm always an advocate for have a go at something you might really enjoy it right what i would say is that actually running a neural network doesn't require a lot of maths it just requires a bit of python basically so that's the language you normally use python um i have a love hate relationship with python i think but sometimes sometimes i just want to declare what my types are and stop having runtime errors for half an hour into something but what what they've done is they've got a lot of libraries like tensorflow and pytorch that operate but sit in python and then they they very very quickly go go down into C and CUDA for fast matrix multiplications which is all the stuff that goes on behind the scenes in your neural network so they're very very quick because they're not implemented end to end in python but python gives you a very convenient and nice way of doing all this you know loading the images it just appears as a kind of array you know you might have a list of images that you use for your data set and then you put that into a network and so on right you know a lot of it's just inputting out putting lists and dictionaries like the rest of python and so it makes things quite easy to use you know you'll have had a look at python but python for me is is a is a nice enough language in the sense that it's fairly easy to pick up particularly if you already know a language it's often language people recommend you start with anyway because it's fairly relaxed about syntax and just you making a total mess of it so that's you know that's always good um but doing going from knowledge of python to having implemented a deep network will not take you very long you will understand everything the first time but you can get give it a go and you can watch it training and you can start to you can start to pick up on what's going on and then you can make a change to the network and maybe improve your performance slightly do you have to write it from scratch or is like it's it's TensorFlow or something that like Google have created exactly they do a huge amount of heavy lifting right which is one of the reasons why you can kind of get away with not having always mathematical background so I mean I use PyTorch mainly and in PyTorch it handles all the weights and learning for you so you say I want my network to have this many layers and I want my layers to be like this and I want it to take an image of this size and turn it into a 10 class classification problem where I'm picking cats and dogs and airplanes or what have you and then it just trots off and does it and it just goes it goes puts the images in it it retrains the network and it puts the images in it retrains the network and it iterates and you can watch your learning rate really watch your loss function go down as it gets better and better every iteration instead eventually you can then just deploy it in some sort of production code or whatever and maybe without maybe test it first so but um you know like it does a huge amount there's a lot of mathematics behind the scenes not all of it particularly complicated but it's definitely a lot of it and it's all massively parallelized on a GPU and you know so you can actually get away with a few dozen lines of code to get a pretty nifty neural network going let's see that that's good to hear because you know when you start talking about the ins and outs it's like this sounds so complicated so it's like PyTorch just a library or something that you would import and then just you just send some commands to it yeah Torch started off as a machine learning library in um well it was written in C presumably but and CUDA but it was it was for Lua and again that's another language I have a should we say a very strong mixed opinions about however since then TensorFlow came along in Python I think it was seen as Python's more convenient for the majority of developers and so PyTorch spawned off Torch basically and is now the dominant library for this so TensorFlow is Google and PyTorch is Facebook AI or meta AI I suppose it is now and that's the one you would start with here if you were starting I yeah so this is it people have different opinions on this I think that the just give us your opinion because you know we I just sorry to interrupt I just want to put it this way I like to have parts like when I talk to experts like yourself it's like okay I'm new now how do I go from like knowing nothing to like at least getting started if so if you anything you can help me yeah well I mean I tell you what knowledge whatever yeah yeah yeah I would start with PyTorch personally right from a research point of view PyTorch is more flexible which helps me but it also doesn't require a lot of lines of code um to get running and it also does a nice thing where it doesn't hide away all of the details there's just enough detail in there that you can kind of type away and it'll kind of work but you do see the network going forward and learning and optimizing the weights and things like this there's a few lines of code but do that that you can kind of look at and go and then you kind of pick these things up right it's not a case that you just type PyTorch.train and pass it your input data and then it just does it and you have no idea what happened which I like because that wouldn't be fun right but also you wouldn't learn anything so I like PyTorch from that for that reason it also has a load of examples so if you go on the um if you go on the github repository for PyTorch or Torchvision you get the the whole you've got all the like core networks that are big from the literature in there and you've also got some examples of simple data problems and things like this that you can run from end to end and just basically run the file and it will start training a network and then you can delve in and see what it is it's actually doing. Do you need I think you mentioned a GPU do you need specific hardware or can you just run this on your laptop? You need you really need a um so PyTorch uses CUDA right so you really could do with using a um I don't know if PyTorch supports OpenCL I can't remember ideally you would have access to a CUDA enabled GPU that would make this process much much faster so as I mentioned the back end of of PyTorch and most of these deep learning libraries is written in C and CUDA and it's just massively parallelized matrix modifications most of the time and that is something that you don't want to be doing on a CPU right you can for very small networks run it on a CPU so if you download the simplest PyTorch example when you run it on a CPU it will run okay and you'll be able to see what happens. Anything with images anything where the dimensionality is high you're going to be waiting half an hour for it just to finish one pass and it won't get anything done. One other thing you might like to try is Google Colab so Google Colab is um is Google's public Jupiter notebook style laboratory environment that actually provides limited time but fair use access to GPUs to to have a go at these things right it's a it's a great place to go and you can also download loads of Colab notebooks existing implementations to test them out that's a great place to start you know I'm a big fan of Google Colab I think that as a platform it's really really useful um and you can actually pay us I mean I'm not I don't work for Google Colab you can pay a small subscription to get access to higher access or more preference more um should we say higher priority access to GPUs right that's what you know you can get um so it's it's like fair use normally so if you if you use it a lot you might have to wait for half a day or something. I mean in the best case scenario I'd come and attend one of your classes um but not everyone's going to be able to do that um do you have books or online courses or stuff that you would personally yeah so I mean what I always recommend to people is Andrew Ung's Coursera course on machine learning is a great place to start right now it's lower it's lower level so Andrew Ung is is is very well known in the machine learning community he's you know he's he's done a load of great work um his Coursera course is really good it's quite mathematical right so that isn't necessarily a problem you just have to go in knowing that's going to happen right but what it does do is it gives you a lot of information on stuff that we haven't really talked about so things like watching your learning rate your loss your your loss function go down right so if you if you draw a graph of your loss which is your error at the end of your network over time what should happen is it gets better and better right it goes down but it might not go down it might sort of do this a lot of machine learning is understanding what that means and what you could try and do to rectify that problem you know for the first for your first day of machine learning it's not important but over time some of the concepts that you talk about in this machine learning course will come in handy and there's a book by Yoshua Benjo called Deep Learning which also again a lot of maths in it but it covers a lot of the core concepts personally i'm a kind of i've always been a kind of learn by doing kind of a person right and so in what i like to do is just get on the pie torch or the TensorFlow tutorials and just start running some stuff and see what happens and if you know python or you know any language that's even plausibly similar to python you're you know you're going to have you're going to have a great time doing that i think especially for a lot of the audience if they starting out with us let's say there's younger people who starting their careers and i spoke about this in the beginning about you know people are worrying that this will take their jobs away but i'm assuming there's whenever i see the hype cycle there seems to be a lot of demand for ai skills huge demand yeah yeah there's a huge demand so i would say there's there's kind of you know you've got your different levels of sort of data analysts right so you've got people who are pretty good with a spreadsheet up to people who are working trying to train self-driving cars and things i suppose if i'm being sort of a bit bit random in my choices of job description and you know you've got anywhere in between there's huge demand everywhere so you know if you have any kind of data analysis ability if you can look at a table of data and start to pick out patterns and start to work out what's going on and make predictions on that data that's a really useful skill to have in lots and lots of jobs it's a very very um very very popular thing that people have so a lot we have a lot of graduates who graduate with a few modules in machine learning and a few modules in data analysis and things like this and they and they're in a really strong position these things are not you know you can learn these things yourself so you know you can go in i've got a data analysis course it's not very long obviously because you know youtube videos but i have some data analysis videos there are lots of data analysis videos on your youtube channel yeah yeah on our youtube channel computer file we have like a 10 part series on data analysis which is just kind of like a taster but you can have a go at that there's lots of stuff on data analysis data analysis and uh modeling and machine learning in some ways go hand in hand it's often good to have a little bit of a look at both of them because you know cleaning data for example like you get you get a spreadsheet of data but doesn't make any sense it's unwise just to stick that straight into a neural network and see what you get out because there could be some complete you know it could be missing values there could be errors they could all just have hugely different scales of data these are all things to think about so some knowledge of how to prepare that data for let's say a downstream task like machine learning it's a really useful thing to know how to do as well i love that you're teaching at the university you're teaching security cybersecurity type stuff but you're also doing AI so there you see that like that's a really good mix and i'm assuming based on what you've just said you know it's a really good idea if you if you if you're into cyber or want to get into cyber to you know add this to your skill set yeah i mean i would be hard pressed to find any career that wouldn't be at least helped a little bit by knowing some data analysis of machine learning because just it just comes up a lot right you know and and also i mean as you know we already spoke about how people can be misled by the hype cycle right and and you will be much more resistant to this if you understand how these things work and that's going to put you in a good position i yeah i i think that um so i as it happens i teach security i partly i find it really interesting so i try and cling on to that module with you know with a with a vice grip and not let anyone else have it um i also teach cryptography uh at at university as well and get you back for some more interviews man yeah right so yeah by all means but so those are subjects i find i don't actively research day to day but i do find very very interesting and i do have some collaborations with because we have actual security researchers working at nottingham in lots of places we have good collaborations with them there is obviously machine learning involved in quite a lot of security because it's a it's a it's one of many strategies for detecting malware or for anomaly detection or you know any smart system that's doing something but hopefully you don't have to program all the rules yourself so yeah it does it does help i've got i think i've got a project uh an undergraduate student starting who's going to look at malware detection with a bit of machine learning as well and so she can bring the knowledge of the malware i can bring the knowledge of the uh of mostly the ai you know and it'll be it'll be great mic i always like to ask this question um if you were talking to your younger self let's say you were 18 or you know i don't know let's say not everyone is 18 who watches these videos but let's say they were 25 30 whatever yeah what would you advise someone to do based on you know what you've seen i think if you're if you're really interested in it in a career in cyber security or a career in uh machine learning it's worth noting that not everyone has a degree that does those things and that's fine right it's also fine if you do have a degree i see people saying well you don't need a degree for this or you do need a degree for this i actually think learn the skills right and then you get a job based on your experience it's you know and you're going to have a great time i think that again it's not one of these debates i like to get into because everyone has their own career path that they want to follow if you're if you're if you did a degree in something completely different and you've worked in a job you're not really enjoying and you want to try something new i think that's absolutely fine have a go there's so many resources online that there weren't 20 30 years ago that there are you know people doing interviews and videos on different topics that you can just watch and learn about and as i say i'm a very hands-on person if i want to try and learn a skill i'm just going to try and do it and it will probably go really wrong the first time um so i think that practice right and this is true of coding as well i think i'm big big um believer but coding is mostly practice people say like how did you know that was going to be a bug because i've seen it so many times before you know like because it happens all the time i think yeah that would be what i would do find something you love doing and do more of that you know i program at home for fun and it's partly because i find it fun and also sometimes i want to learn something new i did a video a year or two ago on the enigma machine right i don't need to program the enigma machine for my job i just thought it was super interesting and i just sat at home and did it and i learned quite a lot actually about the whole process and the history of it by just having to implement the thing and so i think yeah i think crack on and learn would be what i would do i love that i mean and i just have to say this you are doctor uh mike you you you got phd yeah is that right in what in what was it in computer vision so i mean what i really love about this and um this is just my opinion so i don't want to put you on the spot but um i love that you as someone with a phd are not excluding excluding people who perhaps never had that opportunity and i love that you're encouraging everyone you know just to go for it don't let your limitations or yeah lack of resources stop you sorry i mean as it happens like i wasn't i was a pretty average student at school right i mean i i didn't i didn't do much much there wasn't much in terms of computer science um in at school when i was younger it was it was you know let's use microsoft word and and and let's try that out and so i didn't i barely did any computing at all i could only a little i could only a program a tiny bit when i arrived at university loads of people arrive at university with huge programming experience but and loads of people arrive with no programming experience and we always say to them you'll all be the same in the end right like that's the whole point of a degree and it's a whole point of what we teach i think that it's never too late to get to get into computers and learn about programming and stuff i try and teach people to program all the time i mean not all of them were interested which is annoying um but you know so like if it was up to me all my family would be able to program because i'd be giving them extra lessons but some of them want to do other things apparently but yeah i'm not i'm not a gate i don't want to be a gatekeeper because that's not going to get more people doing cool computer stuff there are some things where a massive specialism is important right you know i'm not proposing to go into a hospital and start surgery on people because you need a lot of training to do these things but i also think that if someone wanted to be a surgeon they should crack on and do the training right you know you know i think you can learn those skills um and you know we require if you're going to work at university we usually require a phd and that's something that universities require but there's a great deal i don't know about the real world and industry about people who are watching will know way more about than me and that's also fine right you know everyone's got their own expertise so i like to learn from those people and hope i can teach them a bit about the things i know about i love that i love that another thing i mean i i said 18 but i i get a lot of pushback sometimes on these videos and i'm not sure if you've heard this question before am i too old to start learning ai no um no i mean consider also that the majority of academics who are using ai aren't 18 year old fresh graduates they are researchers that have been doing it for decades because you know so we've all had to learn it from scratch as well right like i say deep learning only appeared in 2014 so it's been a mad rush since then there's loads of scope to learn um and i don't think it takes to get a little bit going it doesn't take that many hours you know if you want to do something you know around your job or whatever it is your current life situation is i think it's doable i love that any closing thoughts no i think um i hope people found it interesting right and i happy to come back and talk about more topics in detail but i think that you know i love um i love my job and telling people about stuff that i think is interesting so i would encourage those people to go off and and look into it in a bit more detail and have a go to download a pie talk tutorial and start running it and you'll train a deep network and then when someone goes all this deep learning is a bit scary you can go well actually i did that last week and it wasn't that wasn't that difficult yeah that that's what i'd suggest so for everyone watching please put in the comments below topics that you would like us to discuss definitely want to try and get mic back so um let us know what you want us to talk about uh computer file has a lot of fantastic videos that mic has created um so go and have a look at those i'll i'll link some of those below please give us your feedback mic thanks so much thanks so much love to be here", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.16, "text": " This is a fascinating story we have for you of a senior Google engineer who says one of", "tokens": [50364, 639, 307, 257, 10343, 1657, 321, 362, 337, 291, 295, 257, 7965, 3329, 11403, 567, 1619, 472, 295, 50672], "temperature": 0.0, "avg_logprob": -0.15370650675104952, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05651484802365303}, {"id": 1, "seek": 0, "start": 6.16, "end": 11.08, "text": " the company's artificial intelligence systems has become a sentient being.", "tokens": [50672, 264, 2237, 311, 11677, 7599, 3652, 575, 1813, 257, 2279, 1196, 885, 13, 50918], "temperature": 0.0, "avg_logprob": -0.15370650675104952, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05651484802365303}, {"id": 2, "seek": 0, "start": 11.08, "end": 16.16, "text": " He believed one of the company's artificial intelligence chatbots had become sentient.", "tokens": [50918, 634, 7847, 472, 295, 264, 2237, 311, 11677, 7599, 5081, 65, 1971, 632, 1813, 2279, 1196, 13, 51172], "temperature": 0.0, "avg_logprob": -0.15370650675104952, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05651484802365303}, {"id": 3, "seek": 0, "start": 16.16, "end": 22.64, "text": " Engineer Blake Lemoine says a chatbot project he was working on called Lambda can express", "tokens": [51172, 15808, 23451, 16905, 44454, 1619, 257, 5081, 18870, 1716, 415, 390, 1364, 322, 1219, 45691, 393, 5109, 51496], "temperature": 0.0, "avg_logprob": -0.15370650675104952, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05651484802365303}, {"id": 4, "seek": 0, "start": 22.64, "end": 26.16, "text": " thoughts and feelings equivalent to that of a child.", "tokens": [51496, 4598, 293, 6640, 10344, 281, 300, 295, 257, 1440, 13, 51672], "temperature": 0.0, "avg_logprob": -0.15370650675104952, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.05651484802365303}, {"id": 5, "seek": 2616, "start": 26.24, "end": 32.08, "text": " Google has rejected claims that one of its programs had advanced so much that it had become sentient.", "tokens": [50368, 3329, 575, 15749, 9441, 300, 472, 295, 1080, 4268, 632, 7339, 370, 709, 300, 309, 632, 1813, 2279, 1196, 13, 50660], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 6, "seek": 2616, "start": 32.08, "end": 37.04, "text": " That's I think the big issue right is that a lot of people get bogged down deciding well what", "tokens": [50660, 663, 311, 286, 519, 264, 955, 2734, 558, 307, 300, 257, 688, 295, 561, 483, 26132, 3004, 760, 17990, 731, 437, 50908], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 7, "seek": 2616, "start": 37.04, "end": 38.64, "text": " does sentient actually mean?", "tokens": [50908, 775, 2279, 1196, 767, 914, 30, 50988], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 8, "seek": 2616, "start": 46.32, "end": 49.519999999999996, "text": " Hey everyone it's David Bombal back with a very special guest Mike welcome.", "tokens": [51372, 1911, 1518, 309, 311, 4389, 19812, 2645, 646, 365, 257, 588, 2121, 8341, 6602, 2928, 13, 51532], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 9, "seek": 2616, "start": 49.519999999999996, "end": 50.64, "text": " Oh thanks for having me.", "tokens": [51532, 876, 3231, 337, 1419, 385, 13, 51588], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 10, "seek": 2616, "start": 50.64, "end": 55.760000000000005, "text": " So Mike I've seen a lot of your videos on YouTube computer file millions of views on", "tokens": [51588, 407, 6602, 286, 600, 1612, 257, 688, 295, 428, 2145, 322, 3088, 3820, 3991, 6803, 295, 6809, 322, 51844], "temperature": 0.0, "avg_logprob": -0.21618072585304185, "compression_ratio": 1.553030303030303, "no_speech_prob": 0.007802943699061871}, {"id": 11, "seek": 5576, "start": 55.76, "end": 59.519999999999996, "text": " some of the topics that you've done but can you just introduce yourself to the audience", "tokens": [50364, 512, 295, 264, 8378, 300, 291, 600, 1096, 457, 393, 291, 445, 5366, 1803, 281, 264, 4034, 50552], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 12, "seek": 5576, "start": 59.519999999999996, "end": 62.96, "text": " for people who might not have seen those videos or don't know what you're doing because you're", "tokens": [50552, 337, 561, 567, 1062, 406, 362, 1612, 729, 2145, 420, 500, 380, 458, 437, 291, 434, 884, 570, 291, 434, 50724], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 13, "seek": 5576, "start": 62.96, "end": 66.8, "text": " telling me offline YouTube isn't your main thing you do more than that.", "tokens": [50724, 3585, 385, 21857, 3088, 1943, 380, 428, 2135, 551, 291, 360, 544, 813, 300, 13, 50916], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 14, "seek": 5576, "start": 66.8, "end": 70.64, "text": " That's right yeah so actually in some sense YouTube isn't a side for me right it's just", "tokens": [50916, 663, 311, 558, 1338, 370, 767, 294, 512, 2020, 3088, 1943, 380, 257, 1252, 337, 385, 558, 309, 311, 445, 51108], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 15, "seek": 5576, "start": 70.64, "end": 72.47999999999999, "text": " something I did because I thought it would be fun.", "tokens": [51108, 746, 286, 630, 570, 286, 1194, 309, 576, 312, 1019, 13, 51200], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 16, "seek": 5576, "start": 72.47999999999999, "end": 77.68, "text": " I'm an academic at Nottingham associate professor and I work teaching security.", "tokens": [51200, 286, 478, 364, 7778, 412, 1726, 783, 4822, 14644, 8304, 293, 286, 589, 4571, 3825, 13, 51460], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 17, "seek": 5576, "start": 77.68, "end": 80.47999999999999, "text": " I research teaching AI and computer vision.", "tokens": [51460, 286, 2132, 4571, 7318, 293, 3820, 5201, 13, 51600], "temperature": 0.0, "avg_logprob": -0.08970886323510147, "compression_ratio": 1.7290969899665551, "no_speech_prob": 0.011126777157187462}, {"id": 18, "seek": 8048, "start": 80.48, "end": 87.2, "text": " It just happened that we have some ties at Nottingham to Brady and Sean who do things like", "tokens": [50364, 467, 445, 2011, 300, 321, 362, 512, 14039, 412, 1726, 783, 4822, 281, 31773, 293, 14839, 567, 360, 721, 411, 50700], "temperature": 0.0, "avg_logprob": -0.1102379317832204, "compression_ratio": 1.756554307116105, "no_speech_prob": 0.012985523790121078}, {"id": 19, "seek": 8048, "start": 87.2, "end": 91.92, "text": " number file and computer file and so computer file was kind of fledgling it had a bit of it", "tokens": [50700, 1230, 3991, 293, 3820, 3991, 293, 370, 3820, 3991, 390, 733, 295, 24114, 70, 1688, 309, 632, 257, 857, 295, 309, 50936], "temperature": 0.0, "avg_logprob": -0.1102379317832204, "compression_ratio": 1.756554307116105, "no_speech_prob": 0.012985523790121078}, {"id": 20, "seek": 8048, "start": 91.92, "end": 96.32000000000001, "text": " was a bit established when I when I started doing them and it kind of just took took off really.", "tokens": [50936, 390, 257, 857, 7545, 562, 286, 562, 286, 1409, 884, 552, 293, 309, 733, 295, 445, 1890, 1890, 766, 534, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1102379317832204, "compression_ratio": 1.756554307116105, "no_speech_prob": 0.012985523790121078}, {"id": 21, "seek": 8048, "start": 97.52000000000001, "end": 102.0, "text": " I think because I did topics on security and AI and things people thought those were interesting", "tokens": [51216, 286, 519, 570, 286, 630, 8378, 322, 3825, 293, 7318, 293, 721, 561, 1194, 729, 645, 1880, 51440], "temperature": 0.0, "avg_logprob": -0.1102379317832204, "compression_ratio": 1.756554307116105, "no_speech_prob": 0.012985523790121078}, {"id": 22, "seek": 8048, "start": 102.0, "end": 106.0, "text": " and so I get you know a lot of views on those now but it is still a bit peculiar when people", "tokens": [51440, 293, 370, 286, 483, 291, 458, 257, 688, 295, 6809, 322, 729, 586, 457, 309, 307, 920, 257, 857, 27149, 562, 561, 51640], "temperature": 0.0, "avg_logprob": -0.1102379317832204, "compression_ratio": 1.756554307116105, "no_speech_prob": 0.012985523790121078}, {"id": 23, "seek": 10600, "start": 106.0, "end": 111.6, "text": " say hello to me you know because I just turn up and do normal things the rest of the time.", "tokens": [50364, 584, 7751, 281, 385, 291, 458, 570, 286, 445, 1261, 493, 293, 360, 2710, 721, 264, 1472, 295, 264, 565, 13, 50644], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 24, "seek": 10600, "start": 111.6, "end": 116.64, "text": " So you get stopped in the street and it has happened yeah my wife is never impressed when", "tokens": [50644, 407, 291, 483, 5936, 294, 264, 4838, 293, 309, 575, 2011, 1338, 452, 3836, 307, 1128, 11679, 562, 50896], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 25, "seek": 10600, "start": 116.64, "end": 122.32, "text": " that happens she thinks this is ridiculous but you know it happens from time to time I do I do", "tokens": [50896, 300, 2314, 750, 7309, 341, 307, 11083, 457, 291, 458, 309, 2314, 490, 565, 281, 565, 286, 360, 286, 360, 51180], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 26, "seek": 10600, "start": 122.32, "end": 126.32, "text": " really enjoy it I get lots of emails from people saying thanks for your videos I enjoy them and", "tokens": [51180, 534, 2103, 309, 286, 483, 3195, 295, 12524, 490, 561, 1566, 3231, 337, 428, 2145, 286, 2103, 552, 293, 51380], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 27, "seek": 10600, "start": 126.32, "end": 130.08, "text": " that's that's why I do it that's that's what it's for for me.", "tokens": [51380, 300, 311, 300, 311, 983, 286, 360, 309, 300, 311, 300, 311, 437, 309, 311, 337, 337, 385, 13, 51568], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 28, "seek": 10600, "start": 130.08, "end": 135.36, "text": " I loved what you said offline you know you someone said that they started computer science because", "tokens": [51568, 286, 4333, 437, 291, 848, 21857, 291, 458, 291, 1580, 848, 300, 436, 1409, 3820, 3497, 570, 51832], "temperature": 0.0, "avg_logprob": -0.13213498890399933, "compression_ratio": 1.8408304498269896, "no_speech_prob": 0.04959358274936676}, {"id": 29, "seek": 13536, "start": 135.36, "end": 139.92000000000002, "text": " of you. I've had a couple of emails like that and that's the those are the best emails right because", "tokens": [50364, 295, 291, 13, 286, 600, 632, 257, 1916, 295, 12524, 411, 300, 293, 300, 311, 264, 729, 366, 264, 1151, 12524, 558, 570, 50592], "temperature": 0.0, "avg_logprob": -0.09414974848429362, "compression_ratio": 1.7279693486590038, "no_speech_prob": 0.0019826714415103197}, {"id": 30, "seek": 13536, "start": 139.92000000000002, "end": 144.72000000000003, "text": " I want people to learn about computer science I love computers I'm a massive geek basically", "tokens": [50592, 286, 528, 561, 281, 1466, 466, 3820, 3497, 286, 959, 10807, 286, 478, 257, 5994, 36162, 1936, 50832], "temperature": 0.0, "avg_logprob": -0.09414974848429362, "compression_ratio": 1.7279693486590038, "no_speech_prob": 0.0019826714415103197}, {"id": 31, "seek": 13536, "start": 144.72000000000003, "end": 150.48000000000002, "text": " I program for fun and the more people do that the more it's a win for me so you know if I can", "tokens": [50832, 286, 1461, 337, 1019, 293, 264, 544, 561, 360, 300, 264, 544, 309, 311, 257, 1942, 337, 385, 370, 291, 458, 498, 286, 393, 51120], "temperature": 0.0, "avg_logprob": -0.09414974848429362, "compression_ratio": 1.7279693486590038, "no_speech_prob": 0.0019826714415103197}, {"id": 32, "seek": 13536, "start": 150.48000000000002, "end": 154.0, "text": " encourage a few people by doing videos but that's what I really want to do.", "tokens": [51120, 5373, 257, 1326, 561, 538, 884, 2145, 457, 300, 311, 437, 286, 534, 528, 281, 360, 13, 51296], "temperature": 0.0, "avg_logprob": -0.09414974848429362, "compression_ratio": 1.7279693486590038, "no_speech_prob": 0.0019826714415103197}, {"id": 33, "seek": 13536, "start": 154.0, "end": 158.8, "text": " That's fantastic one of the videos I watched obviously in preparation for this interview", "tokens": [51296, 663, 311, 5456, 472, 295, 264, 2145, 286, 6337, 2745, 294, 13081, 337, 341, 4049, 51536], "temperature": 0.0, "avg_logprob": -0.09414974848429362, "compression_ratio": 1.7279693486590038, "no_speech_prob": 0.0019826714415103197}, {"id": 34, "seek": 15880, "start": 158.8, "end": 165.76000000000002, "text": " is this recent video that you put out about AI and that's going to be the topic that we", "tokens": [50364, 307, 341, 5162, 960, 300, 291, 829, 484, 466, 7318, 293, 300, 311, 516, 281, 312, 264, 4829, 300, 321, 50712], "temperature": 0.0, "avg_logprob": -0.09421122475956263, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.1342141032218933}, {"id": 35, "seek": 15880, "start": 165.76000000000002, "end": 171.52, "text": " want to talk about today so let me lead with this I get this these kind of emails all the time", "tokens": [50712, 528, 281, 751, 466, 965, 370, 718, 385, 1477, 365, 341, 286, 483, 341, 613, 733, 295, 12524, 439, 264, 565, 51000], "temperature": 0.0, "avg_logprob": -0.09421122475956263, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.1342141032218933}, {"id": 36, "seek": 15880, "start": 172.08, "end": 177.76000000000002, "text": " David is it worth me studying cyber security David is it worth me studying computers because AI", "tokens": [51028, 4389, 307, 309, 3163, 385, 7601, 13411, 3825, 4389, 307, 309, 3163, 385, 7601, 10807, 570, 7318, 51312], "temperature": 0.0, "avg_logprob": -0.09421122475956263, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.1342141032218933}, {"id": 37, "seek": 15880, "start": 177.76000000000002, "end": 183.60000000000002, "text": " are going to take all the jobs away and I think movies over the years like you know there's been", "tokens": [51312, 366, 516, 281, 747, 439, 264, 4782, 1314, 293, 286, 519, 6233, 670, 264, 924, 411, 291, 458, 456, 311, 668, 51604], "temperature": 0.0, "avg_logprob": -0.09421122475956263, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.1342141032218933}, {"id": 38, "seek": 18360, "start": 183.6, "end": 190.0, "text": " so many of these movies where the robots take over and this can you talk about this and you can go", "tokens": [50364, 370, 867, 295, 613, 6233, 689, 264, 14733, 747, 670, 293, 341, 393, 291, 751, 466, 341, 293, 291, 393, 352, 50684], "temperature": 0.0, "avg_logprob": -0.08323555499051524, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.06930344551801682}, {"id": 39, "seek": 18360, "start": 190.0, "end": 196.24, "text": " into the details if you like but I think this this this sort of recent event that you spoke about", "tokens": [50684, 666, 264, 4365, 498, 291, 411, 457, 286, 519, 341, 341, 341, 1333, 295, 5162, 2280, 300, 291, 7179, 466, 50996], "temperature": 0.0, "avg_logprob": -0.08323555499051524, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.06930344551801682}, {"id": 40, "seek": 18360, "start": 196.24, "end": 200.79999999999998, "text": " in your video hasn't helped the conversation at all so can you tell us about that yeah in what your", "tokens": [50996, 294, 428, 960, 6132, 380, 4254, 264, 3761, 412, 439, 370, 393, 291, 980, 505, 466, 300, 1338, 294, 437, 428, 51224], "temperature": 0.0, "avg_logprob": -0.08323555499051524, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.06930344551801682}, {"id": 41, "seek": 18360, "start": 200.79999999999998, "end": 205.2, "text": " thoughts are about you know what happened yeah so no I absolutely agree but it didn't help the", "tokens": [51224, 4598, 366, 466, 291, 458, 437, 2011, 1338, 370, 572, 286, 3122, 3986, 457, 309, 994, 380, 854, 264, 51444], "temperature": 0.0, "avg_logprob": -0.08323555499051524, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.06930344551801682}, {"id": 42, "seek": 18360, "start": 205.2, "end": 209.28, "text": " conversation about was okay I think in my video about was kind of what I tried to end with was", "tokens": [51444, 3761, 466, 390, 1392, 286, 519, 294, 452, 960, 466, 390, 733, 295, 437, 286, 3031, 281, 917, 365, 390, 51648], "temperature": 0.0, "avg_logprob": -0.08323555499051524, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.06930344551801682}, {"id": 43, "seek": 20928, "start": 209.28, "end": 214.72, "text": " basically it doesn't you know in some sense the nuances of where this AI is doesn't interest me that", "tokens": [50364, 1936, 309, 1177, 380, 291, 458, 294, 512, 2020, 264, 38775, 295, 689, 341, 7318, 307, 1177, 380, 1179, 385, 300, 50636], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 44, "seek": 20928, "start": 214.72, "end": 219.76, "text": " much all I know is it's not where they're suggesting it is at least that's you know that's what I think", "tokens": [50636, 709, 439, 286, 458, 307, 309, 311, 406, 689, 436, 434, 18094, 309, 307, 412, 1935, 300, 311, 291, 458, 300, 311, 437, 286, 519, 50888], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 45, "seek": 20928, "start": 219.76, "end": 225.84, "text": " I suppose at the moment AI is very application driven right so a lot of it is supervised there", "tokens": [50888, 286, 7297, 412, 264, 1623, 7318, 307, 588, 3861, 9555, 558, 370, 257, 688, 295, 309, 307, 46533, 456, 51192], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 46, "seek": 20928, "start": 225.84, "end": 229.76, "text": " are other ways of doing it but a lot of it's supervised which means that you have some kind", "tokens": [51192, 366, 661, 2098, 295, 884, 309, 457, 257, 688, 295, 309, 311, 46533, 597, 1355, 300, 291, 362, 512, 733, 51388], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 47, "seek": 20928, "start": 229.76, "end": 233.44, "text": " of training set with some inputs and some outputs that you're trying to get the model to learn and", "tokens": [51388, 295, 3097, 992, 365, 512, 15743, 293, 512, 23930, 300, 291, 434, 1382, 281, 483, 264, 2316, 281, 1466, 293, 51572], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 48, "seek": 20928, "start": 233.44, "end": 238.32, "text": " then you just train the model until that happens that can work really really really well and so", "tokens": [51572, 550, 291, 445, 3847, 264, 2316, 1826, 300, 2314, 300, 393, 589, 534, 534, 534, 731, 293, 370, 51816], "temperature": 0.0, "avg_logprob": -0.06736424021477247, "compression_ratio": 1.946843853820598, "no_speech_prob": 0.06692498922348022}, {"id": 49, "seek": 23832, "start": 238.4, "end": 242.72, "text": " from my own research I do this on things like image segmentation where I'm trying to find objects", "tokens": [50368, 490, 452, 1065, 2132, 286, 360, 341, 322, 721, 411, 3256, 9469, 399, 689, 286, 478, 1382, 281, 915, 6565, 50584], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 50, "seek": 23832, "start": 242.72, "end": 247.84, "text": " in images and you know medical image segmentation and things like this but you know in practice if", "tokens": [50584, 294, 5267, 293, 291, 458, 4625, 3256, 9469, 399, 293, 721, 411, 341, 457, 291, 458, 294, 3124, 498, 50840], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 51, "seek": 23832, "start": 247.84, "end": 251.44, "text": " I then take that network and try and run it on street scenes it won't work because it's not", "tokens": [50840, 286, 550, 747, 300, 3209, 293, 853, 293, 1190, 309, 322, 4838, 8026, 309, 1582, 380, 589, 570, 309, 311, 406, 51020], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 52, "seek": 23832, "start": 251.44, "end": 256.24, "text": " trained on street scenes it doesn't know what they are it hasn't got any ability to go oh it's a street", "tokens": [51020, 8895, 322, 4838, 8026, 309, 1177, 380, 458, 437, 436, 366, 309, 6132, 380, 658, 604, 3485, 281, 352, 1954, 309, 311, 257, 4838, 51260], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 53, "seek": 23832, "start": 256.24, "end": 260.88, "text": " now you know and take what it's learned somewhere and apply it somewhere else you know retraining", "tokens": [51260, 586, 291, 458, 293, 747, 437, 309, 311, 3264, 4079, 293, 3079, 309, 4079, 1646, 291, 458, 49356, 1760, 51492], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 54, "seek": 23832, "start": 260.88, "end": 267.2, "text": " a network is really the only way to do it and that involves even more data right so I don't think", "tokens": [51492, 257, 3209, 307, 534, 264, 787, 636, 281, 360, 309, 293, 300, 11626, 754, 544, 1412, 558, 370, 286, 500, 380, 519, 51808], "temperature": 0.0, "avg_logprob": -0.058444688646055815, "compression_ratio": 1.96, "no_speech_prob": 0.0011300953337922692}, {"id": 55, "seek": 26720, "start": 267.2, "end": 270.88, "text": " at the moment it's realistic to suggest that there's going to be some general", "tokens": [50364, 412, 264, 1623, 309, 311, 12465, 281, 3402, 300, 456, 311, 516, 281, 312, 512, 2674, 50548], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 56, "seek": 26720, "start": 270.88, "end": 275.59999999999997, "text": " intelligence that can just do all of our jobs right you know you've seen github co-pilot that", "tokens": [50548, 7599, 300, 393, 445, 360, 439, 295, 527, 4782, 558, 291, 458, 291, 600, 1612, 290, 355, 836, 598, 12, 79, 31516, 300, 50784], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 57, "seek": 26720, "start": 275.59999999999997, "end": 280.8, "text": " just produces text code and sometimes it will produce a useful function and sometimes it will", "tokens": [50784, 445, 14725, 2487, 3089, 293, 2171, 309, 486, 5258, 257, 4420, 2445, 293, 2171, 309, 486, 51044], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 58, "seek": 26720, "start": 280.8, "end": 285.03999999999996, "text": " produce a function full of bugs that you've got to then spend time fixing and have you actually", "tokens": [51044, 5258, 257, 2445, 1577, 295, 15120, 300, 291, 600, 658, 281, 550, 3496, 565, 19442, 293, 362, 291, 767, 51256], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 59, "seek": 26720, "start": 285.03999999999996, "end": 290.71999999999997, "text": " saved any time I don't know the jury's out I think so I wouldn't worry at the moment I'm not worried", "tokens": [51256, 6624, 604, 565, 286, 500, 380, 458, 264, 19516, 311, 484, 286, 519, 370, 286, 2759, 380, 3292, 412, 264, 1623, 286, 478, 406, 5804, 51540], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 60, "seek": 26720, "start": 290.71999999999997, "end": 296.08, "text": " I mean maybe designing things to replace myself is a huge mistake but I don't think we're there yet", "tokens": [51540, 286, 914, 1310, 14685, 721, 281, 7406, 2059, 307, 257, 2603, 6146, 457, 286, 500, 380, 519, 321, 434, 456, 1939, 51808], "temperature": 0.0, "avg_logprob": -0.0568597743760294, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.006366386543959379}, {"id": 61, "seek": 29608, "start": 296.08, "end": 299.76, "text": " so I mean tell us just for people who haven't seen it um haven't seen your video and like haven't", "tokens": [50364, 370, 286, 914, 980, 505, 445, 337, 561, 567, 2378, 380, 1612, 309, 1105, 2378, 380, 1612, 428, 960, 293, 411, 2378, 380, 50548], "temperature": 0.0, "avg_logprob": -0.08919527634330418, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.004674633964896202}, {"id": 62, "seek": 29608, "start": 299.76, "end": 306.0, "text": " read perhaps what's going on there's this google person lambda yeah so what is lambda and what is", "tokens": [50548, 1401, 4317, 437, 311, 516, 322, 456, 311, 341, 20742, 954, 13607, 1338, 370, 437, 307, 13607, 293, 437, 307, 50860], "temperature": 0.0, "avg_logprob": -0.08919527634330418, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.004674633964896202}, {"id": 63, "seek": 29608, "start": 306.56, "end": 311.76, "text": " what what what what was he basically saying um google lambda is a um it's what we call a large", "tokens": [50888, 437, 437, 437, 437, 390, 415, 1936, 1566, 1105, 20742, 13607, 307, 257, 1105, 309, 311, 437, 321, 818, 257, 2416, 51148], "temperature": 0.0, "avg_logprob": -0.08919527634330418, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.004674633964896202}, {"id": 64, "seek": 29608, "start": 311.76, "end": 317.36, "text": " language model so it's basically a a very very large neural network designed in a certain way", "tokens": [51148, 2856, 2316, 370, 309, 311, 1936, 257, 257, 588, 588, 2416, 18161, 3209, 4761, 294, 257, 1629, 636, 51428], "temperature": 0.0, "avg_logprob": -0.08919527634330418, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.004674633964896202}, {"id": 65, "seek": 29608, "start": 317.36, "end": 322.0, "text": " they're all designed in a very similar way and it has more parameters in it than we've ever seen", "tokens": [51428, 436, 434, 439, 4761, 294, 257, 588, 2531, 636, 293, 309, 575, 544, 9834, 294, 309, 813, 321, 600, 1562, 1612, 51660], "temperature": 0.0, "avg_logprob": -0.08919527634330418, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.004674633964896202}, {"id": 66, "seek": 32200, "start": 322.0, "end": 327.04, "text": " really in a model right or GPT-3 is also very very big and so really what this brings to the", "tokens": [50364, 534, 294, 257, 2316, 558, 420, 26039, 51, 12, 18, 307, 611, 588, 588, 955, 293, 370, 534, 437, 341, 5607, 281, 264, 50616], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 67, "seek": 32200, "start": 327.04, "end": 332.32, "text": " table is not so much something new that we've never seen before in AI it's just it's just huge", "tokens": [50616, 3199, 307, 406, 370, 709, 746, 777, 300, 321, 600, 1128, 1612, 949, 294, 7318, 309, 311, 445, 309, 311, 445, 2603, 50880], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 68, "seek": 32200, "start": 332.32, "end": 335.36, "text": " you know orders of magnitude bigger than the kind of networks I would use to do", "tokens": [50880, 291, 458, 9470, 295, 15668, 3801, 813, 264, 733, 295, 9590, 286, 576, 764, 281, 360, 51032], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 69, "seek": 32200, "start": 336.08, "end": 340.24, "text": " you know complex imaging tasks and what they've basically done is they've trained this this model", "tokens": [51068, 291, 458, 3997, 25036, 9608, 293, 437, 436, 600, 1936, 1096, 307, 436, 600, 8895, 341, 341, 2316, 51276], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 70, "seek": 32200, "start": 340.24, "end": 345.2, "text": " to read a sentence and then predict what the next word will be and so you could imagine but if you", "tokens": [51276, 281, 1401, 257, 8174, 293, 550, 6069, 437, 264, 958, 1349, 486, 312, 293, 370, 291, 727, 3811, 457, 498, 291, 51524], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 71, "seek": 32200, "start": 345.2, "end": 348.8, "text": " wanted to do this by hand and you had infinite resources you could just look at every sentence", "tokens": [51524, 1415, 281, 360, 341, 538, 1011, 293, 291, 632, 13785, 3593, 291, 727, 445, 574, 412, 633, 8174, 51704], "temperature": 0.0, "avg_logprob": -0.05919345219930013, "compression_ratio": 1.7802547770700636, "no_speech_prob": 0.09907273948192596}, {"id": 72, "seek": 34880, "start": 348.8, "end": 354.24, "text": " that's ever been written by humans and work out for any given let's say 10 words what the next word", "tokens": [50364, 300, 311, 1562, 668, 3720, 538, 6255, 293, 589, 484, 337, 604, 2212, 718, 311, 584, 1266, 2283, 437, 264, 958, 1349, 50636], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 73, "seek": 34880, "start": 354.24, "end": 359.04, "text": " will always be and if you did that and you had that list of all the possible inputs you do pretty", "tokens": [50636, 486, 1009, 312, 293, 498, 291, 630, 300, 293, 291, 632, 300, 1329, 295, 439, 264, 1944, 15743, 291, 360, 1238, 50876], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 74, "seek": 34880, "start": 359.04, "end": 363.44, "text": " well at generating sentences because at the end of the day that's what people say right this is", "tokens": [50876, 731, 412, 17746, 16579, 570, 412, 264, 917, 295, 264, 786, 300, 311, 437, 561, 584, 558, 341, 307, 51096], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 75, "seek": 34880, "start": 363.44, "end": 367.36, "text": " you've got it on record as what they've said in the past you can just say those things again and so", "tokens": [51096, 291, 600, 658, 309, 322, 2136, 382, 437, 436, 600, 848, 294, 264, 1791, 291, 393, 445, 584, 729, 721, 797, 293, 370, 51292], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 76, "seek": 34880, "start": 367.36, "end": 371.28000000000003, "text": " this model is one of those this model is one where you put in some sentences so you might put in a", "tokens": [51292, 341, 2316, 307, 472, 295, 729, 341, 2316, 307, 472, 689, 291, 829, 294, 512, 16579, 370, 291, 1062, 829, 294, 257, 51488], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 77, "seek": 34880, "start": 371.28000000000003, "end": 376.64, "text": " sentence that says what do you think about quantum physics and then what the model will do is predict", "tokens": [51488, 8174, 300, 1619, 437, 360, 291, 519, 466, 13018, 10649, 293, 550, 437, 264, 2316, 486, 360, 307, 6069, 51756], "temperature": 0.0, "avg_logprob": -0.059307609285627096, "compression_ratio": 1.9038461538461537, "no_speech_prob": 0.03245151787996292}, {"id": 78, "seek": 37664, "start": 376.64, "end": 383.44, "text": " the next likely word and it will probably say well I'm going to start by saying what I think is", "tokens": [50364, 264, 958, 3700, 1349, 293, 309, 486, 1391, 584, 731, 286, 478, 516, 281, 722, 538, 1566, 437, 286, 519, 307, 50704], "temperature": 0.0, "avg_logprob": -0.04633048761670835, "compression_ratio": 1.8134328358208955, "no_speech_prob": 0.004065748769789934}, {"id": 79, "seek": 37664, "start": 383.44, "end": 389.68, "text": " and then generate some plausible text on quantum physics because people have written about quantum", "tokens": [50704, 293, 550, 8460, 512, 39925, 2487, 322, 13018, 10649, 570, 561, 362, 3720, 466, 13018, 51016], "temperature": 0.0, "avg_logprob": -0.04633048761670835, "compression_ratio": 1.8134328358208955, "no_speech_prob": 0.004065748769789934}, {"id": 80, "seek": 37664, "start": 389.68, "end": 394.71999999999997, "text": " physics before and that data is in the training set what it hasn't done is learned what quantum", "tokens": [51016, 10649, 949, 293, 300, 1412, 307, 294, 264, 3097, 992, 437, 309, 6132, 380, 1096, 307, 3264, 437, 13018, 51268], "temperature": 0.0, "avg_logprob": -0.04633048761670835, "compression_ratio": 1.8134328358208955, "no_speech_prob": 0.004065748769789934}, {"id": 81, "seek": 37664, "start": 394.71999999999997, "end": 398.96, "text": " physics is or connected to an internet resource that has information on quantum physics and looked", "tokens": [51268, 10649, 307, 420, 4582, 281, 364, 4705, 7684, 300, 575, 1589, 322, 13018, 10649, 293, 2956, 51480], "temperature": 0.0, "avg_logprob": -0.04633048761670835, "compression_ratio": 1.8134328358208955, "no_speech_prob": 0.004065748769789934}, {"id": 82, "seek": 37664, "start": 398.96, "end": 404.0, "text": " it up so in some sense it's a bit like the you know in Star Trek you've got the computer you can", "tokens": [51480, 309, 493, 370, 294, 512, 2020, 309, 311, 257, 857, 411, 264, 291, 458, 294, 5705, 25845, 291, 600, 658, 264, 3820, 291, 393, 51732], "temperature": 0.0, "avg_logprob": -0.04633048761670835, "compression_ratio": 1.8134328358208955, "no_speech_prob": 0.004065748769789934}, {"id": 83, "seek": 40400, "start": 404.0, "end": 408.24, "text": " talk to and they often ask the computer to do things like you know put the shields up or whatever", "tokens": [50364, 751, 281, 293, 436, 2049, 1029, 264, 3820, 281, 360, 721, 411, 291, 458, 829, 264, 33466, 493, 420, 2035, 50576], "temperature": 0.0, "avg_logprob": -0.056011014065500034, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.006690038833767176}, {"id": 84, "seek": 40400, "start": 408.24, "end": 415.2, "text": " yeah computer dim lights it's like that but it's not connected to any kind of anything on the ship", "tokens": [50576, 1338, 3820, 5013, 5811, 309, 311, 411, 300, 457, 309, 311, 406, 4582, 281, 604, 733, 295, 1340, 322, 264, 5374, 50924], "temperature": 0.0, "avg_logprob": -0.056011014065500034, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.006690038833767176}, {"id": 85, "seek": 40400, "start": 415.2, "end": 421.52, "text": " so it just talks to you and talks back but it never actions anything it never it never has you", "tokens": [50924, 370, 309, 445, 6686, 281, 291, 293, 6686, 646, 457, 309, 1128, 5909, 1340, 309, 1128, 309, 1128, 575, 291, 51240], "temperature": 0.0, "avg_logprob": -0.056011014065500034, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.006690038833767176}, {"id": 86, "seek": 40400, "start": 421.52, "end": 426.56, "text": " know it's just going from the text in the training set and I think that's something that's perhaps", "tokens": [51240, 458, 309, 311, 445, 516, 490, 264, 2487, 294, 264, 3097, 992, 293, 286, 519, 300, 311, 746, 300, 311, 4317, 51492], "temperature": 0.0, "avg_logprob": -0.056011014065500034, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.006690038833767176}, {"id": 87, "seek": 40400, "start": 426.56, "end": 431.92, "text": " lost a bit in in when it when it's discussed it's but it's not connected to anything it doesn't even", "tokens": [51492, 2731, 257, 857, 294, 294, 562, 309, 562, 309, 311, 7152, 309, 311, 457, 309, 311, 406, 4582, 281, 1340, 309, 1177, 380, 754, 51760], "temperature": 0.0, "avg_logprob": -0.056011014065500034, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.006690038833767176}, {"id": 88, "seek": 43192, "start": 431.92, "end": 438.0, "text": " have a memory basically and so it can't reflect on past experience because it has no place to store", "tokens": [50364, 362, 257, 4675, 1936, 293, 370, 309, 393, 380, 5031, 322, 1791, 1752, 570, 309, 575, 572, 1081, 281, 3531, 50668], "temperature": 0.0, "avg_logprob": -0.04506206512451172, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.0395202599465847}, {"id": 89, "seek": 43192, "start": 438.0, "end": 443.12, "text": " past experience it has no record of those events and so when it produces sentences that look really", "tokens": [50668, 1791, 1752, 309, 575, 572, 2136, 295, 729, 3931, 293, 370, 562, 309, 14725, 16579, 300, 574, 534, 50924], "temperature": 0.0, "avg_logprob": -0.04506206512451172, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.0395202599465847}, {"id": 90, "seek": 43192, "start": 443.12, "end": 448.16, "text": " really interesting they're actually just really interesting sounding sentences you know and I", "tokens": [50924, 534, 1880, 436, 434, 767, 445, 534, 1880, 24931, 16579, 291, 458, 293, 286, 51176], "temperature": 0.0, "avg_logprob": -0.04506206512451172, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.0395202599465847}, {"id": 91, "seek": 43192, "start": 448.16, "end": 452.96000000000004, "text": " think so anyway I mean if I if I sort of digress slightly but you know in this particular case", "tokens": [51176, 519, 370, 4033, 286, 914, 498, 286, 498, 286, 1333, 295, 2528, 735, 4748, 457, 291, 458, 294, 341, 1729, 1389, 51416], "temperature": 0.0, "avg_logprob": -0.04506206512451172, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.0395202599465847}, {"id": 92, "seek": 43192, "start": 452.96000000000004, "end": 457.36, "text": " what happened was someone from Google who I think was in the ethics department I don't think he was", "tokens": [51416, 437, 2011, 390, 1580, 490, 3329, 567, 286, 519, 390, 294, 264, 19769, 5882, 286, 500, 380, 519, 415, 390, 51636], "temperature": 0.0, "avg_logprob": -0.04506206512451172, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.0395202599465847}, {"id": 93, "seek": 45736, "start": 457.36, "end": 463.12, "text": " actually responsible for developing this AI basically said look at this chat I've had with it", "tokens": [50364, 767, 6250, 337, 6416, 341, 7318, 1936, 848, 574, 412, 341, 5081, 286, 600, 632, 365, 309, 50652], "temperature": 0.0, "avg_logprob": -0.053648311441594904, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.2712410092353821}, {"id": 94, "seek": 45736, "start": 463.12, "end": 467.92, "text": " don't you think it's sentient basically is what he said and the answer I think from me and pretty", "tokens": [50652, 500, 380, 291, 519, 309, 311, 2279, 1196, 1936, 307, 437, 415, 848, 293, 264, 1867, 286, 519, 490, 385, 293, 1238, 50892], "temperature": 0.0, "avg_logprob": -0.053648311441594904, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.2712410092353821}, {"id": 95, "seek": 45736, "start": 467.92, "end": 472.72, "text": " much everyone who understands these models was no it's no it's not and what and I think the thing", "tokens": [50892, 709, 1518, 567, 15146, 613, 5245, 390, 572, 309, 311, 572, 309, 311, 406, 293, 437, 293, 286, 519, 264, 551, 51132], "temperature": 0.0, "avg_logprob": -0.053648311441594904, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.2712410092353821}, {"id": 96, "seek": 45736, "start": 472.72, "end": 477.12, "text": " that bothered me most about it was not particularly one person saying this because he's very entitled", "tokens": [51132, 300, 22996, 385, 881, 466, 309, 390, 406, 4098, 472, 954, 1566, 341, 570, 415, 311, 588, 17838, 51352], "temperature": 0.0, "avg_logprob": -0.053648311441594904, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.2712410092353821}, {"id": 97, "seek": 45736, "start": 477.12, "end": 482.40000000000003, "text": " to his opinion right you know I think I think it was that the media took it massively seriously and", "tokens": [51352, 281, 702, 4800, 558, 291, 458, 286, 519, 286, 519, 309, 390, 300, 264, 3021, 1890, 309, 29379, 6638, 293, 51616], "temperature": 0.0, "avg_logprob": -0.053648311441594904, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.2712410092353821}, {"id": 98, "seek": 48240, "start": 482.4, "end": 487.52, "text": " it was all over everywhere is this the next thing and that bugs me somewhat because I don't think it", "tokens": [50364, 309, 390, 439, 670, 5315, 307, 341, 264, 958, 551, 293, 300, 15120, 385, 8344, 570, 286, 500, 380, 519, 309, 50620], "temperature": 0.0, "avg_logprob": -0.057900113718850274, "compression_ratio": 1.8659003831417624, "no_speech_prob": 0.02360948547720909}, {"id": 99, "seek": 48240, "start": 487.52, "end": 493.12, "text": " helps for conversation like you say right people start people who don't know what a big a big model", "tokens": [50620, 3665, 337, 3761, 411, 291, 584, 558, 561, 722, 561, 567, 500, 380, 458, 437, 257, 955, 257, 955, 2316, 50900], "temperature": 0.0, "avg_logprob": -0.057900113718850274, "compression_ratio": 1.8659003831417624, "no_speech_prob": 0.02360948547720909}, {"id": 100, "seek": 48240, "start": 493.12, "end": 496.79999999999995, "text": " a big language model is are going to be a bit worried about this and there's really no reason", "tokens": [50900, 257, 955, 2856, 2316, 307, 366, 516, 281, 312, 257, 857, 5804, 466, 341, 293, 456, 311, 534, 572, 1778, 51084], "temperature": 0.0, "avg_logprob": -0.057900113718850274, "compression_ratio": 1.8659003831417624, "no_speech_prob": 0.02360948547720909}, {"id": 101, "seek": 48240, "start": 496.79999999999995, "end": 501.67999999999995, "text": " at this time to be worried and like that bothers me slightly which is why I do my videos to try and", "tokens": [51084, 412, 341, 565, 281, 312, 5804, 293, 411, 300, 33980, 385, 4748, 597, 307, 983, 286, 360, 452, 2145, 281, 853, 293, 51328], "temperature": 0.0, "avg_logprob": -0.057900113718850274, "compression_ratio": 1.8659003831417624, "no_speech_prob": 0.02360948547720909}, {"id": 102, "seek": 48240, "start": 501.67999999999995, "end": 507.84, "text": " tell people about it I mean the problem is the movies predict this happening and then people", "tokens": [51328, 980, 561, 466, 309, 286, 914, 264, 1154, 307, 264, 6233, 6069, 341, 2737, 293, 550, 561, 51636], "temperature": 0.0, "avg_logprob": -0.057900113718850274, "compression_ratio": 1.8659003831417624, "no_speech_prob": 0.02360948547720909}, {"id": 103, "seek": 50784, "start": 507.84, "end": 514.16, "text": " see this stuff in the news and it's like it's the end of the world and end of my job Arnold and the", "tokens": [50364, 536, 341, 1507, 294, 264, 2583, 293, 309, 311, 411, 309, 311, 264, 917, 295, 264, 1002, 293, 917, 295, 452, 1691, 30406, 293, 264, 50680], "temperature": 0.0, "avg_logprob": -0.07991266665251359, "compression_ratio": 1.8327137546468402, "no_speech_prob": 0.04719904810190201}, {"id": 104, "seek": 50784, "start": 514.16, "end": 519.4399999999999, "text": " robots are going to take over so it really doesn't happen it doesn't it really doesn't help and I", "tokens": [50680, 14733, 366, 516, 281, 747, 670, 370, 309, 534, 1177, 380, 1051, 309, 1177, 380, 309, 534, 1177, 380, 854, 293, 286, 50944], "temperature": 0.0, "avg_logprob": -0.07991266665251359, "compression_ratio": 1.8327137546468402, "no_speech_prob": 0.04719904810190201}, {"id": 105, "seek": 50784, "start": 519.4399999999999, "end": 522.56, "text": " like what you said I mean in your video which I'll link below you said something that I thought was", "tokens": [50944, 411, 437, 291, 848, 286, 914, 294, 428, 960, 597, 286, 603, 2113, 2507, 291, 848, 746, 300, 286, 1194, 390, 51100], "temperature": 0.0, "avg_logprob": -0.07991266665251359, "compression_ratio": 1.8327137546468402, "no_speech_prob": 0.04719904810190201}, {"id": 106, "seek": 50784, "start": 522.56, "end": 530.16, "text": " hilarious you said can python functions get lonely yeah can you explain what you were saying by that", "tokens": [51100, 19796, 291, 848, 393, 38797, 6828, 483, 14236, 1338, 393, 291, 2903, 437, 291, 645, 1566, 538, 300, 51480], "temperature": 0.0, "avg_logprob": -0.07991266665251359, "compression_ratio": 1.8327137546468402, "no_speech_prob": 0.04719904810190201}, {"id": 107, "seek": 50784, "start": 530.16, "end": 535.28, "text": " yeah so one of the one of the comments in the original chat transcript between this researcher", "tokens": [51480, 1338, 370, 472, 295, 264, 472, 295, 264, 3053, 294, 264, 3380, 5081, 24444, 1296, 341, 21751, 51736], "temperature": 0.0, "avg_logprob": -0.07991266665251359, "compression_ratio": 1.8327137546468402, "no_speech_prob": 0.04719904810190201}, {"id": 108, "seek": 53528, "start": 535.28, "end": 541.04, "text": " and his friend and his colleague and this lambda AI was do you get lonely and it's spouted off a whole", "tokens": [50364, 293, 702, 1277, 293, 702, 13532, 293, 341, 13607, 7318, 390, 360, 291, 483, 14236, 293, 309, 311, 637, 346, 292, 766, 257, 1379, 50652], "temperature": 0.0, "avg_logprob": -0.0744571055262542, "compression_ratio": 1.7821428571428573, "no_speech_prob": 0.09752091020345688}, {"id": 109, "seek": 53528, "start": 541.04, "end": 547.4399999999999, "text": " paragraph about how lonely it is and it doesn't make any sense because it's a function call right so", "tokens": [50652, 18865, 466, 577, 14236, 309, 307, 293, 309, 1177, 380, 652, 604, 2020, 570, 309, 311, 257, 2445, 818, 558, 370, 50972], "temperature": 0.0, "avg_logprob": -0.0744571055262542, "compression_ratio": 1.7821428571428573, "no_speech_prob": 0.09752091020345688}, {"id": 110, "seek": 53528, "start": 547.4399999999999, "end": 552.56, "text": " you put in your words at the top it runs of what is essentially a big transformer network which is", "tokens": [50972, 291, 829, 294, 428, 2283, 412, 264, 1192, 309, 6676, 295, 437, 307, 4476, 257, 955, 31782, 3209, 597, 307, 51228], "temperature": 0.0, "avg_logprob": -0.0744571055262542, "compression_ratio": 1.7821428571428573, "no_speech_prob": 0.09752091020345688}, {"id": 111, "seek": 53528, "start": 552.56, "end": 557.8399999999999, "text": " pre-trained on all this data and then it spits out words at the bottom which you read and then it", "tokens": [51228, 659, 12, 17227, 2001, 322, 439, 341, 1412, 293, 550, 309, 637, 1208, 484, 2283, 412, 264, 2767, 597, 291, 1401, 293, 550, 309, 51492], "temperature": 0.0, "avg_logprob": -0.0744571055262542, "compression_ratio": 1.7821428571428573, "no_speech_prob": 0.09752091020345688}, {"id": 112, "seek": 53528, "start": 557.8399999999999, "end": 562.16, "text": " stops executing right because there's no kind of ongoing process like there is in my I mean I like", "tokens": [51492, 10094, 32368, 558, 570, 456, 311, 572, 733, 295, 10452, 1399, 411, 456, 307, 294, 452, 286, 914, 286, 411, 51708], "temperature": 0.0, "avg_logprob": -0.0744571055262542, "compression_ratio": 1.7821428571428573, "no_speech_prob": 0.09752091020345688}, {"id": 113, "seek": 56216, "start": 562.24, "end": 565.12, "text": " to think that when I'm not immediately saying something to you I'm still there's something", "tokens": [50368, 281, 519, 300, 562, 286, 478, 406, 4258, 1566, 746, 281, 291, 286, 478, 920, 456, 311, 746, 50512], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 114, "seek": 56216, "start": 565.12, "end": 570.7199999999999, "text": " going on in there right maybe I mean you know I can't prove it to you but but this is not the", "tokens": [50512, 516, 322, 294, 456, 558, 1310, 286, 914, 291, 458, 286, 393, 380, 7081, 309, 281, 291, 457, 457, 341, 307, 406, 264, 50792], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 115, "seek": 56216, "start": 570.7199999999999, "end": 574.9599999999999, "text": " case you know and it's just like when you run I mean I made a joke about it but when you run", "tokens": [50792, 1389, 291, 458, 293, 309, 311, 445, 411, 562, 291, 1190, 286, 914, 286, 1027, 257, 7647, 466, 309, 457, 562, 291, 1190, 51004], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 116, "seek": 56216, "start": 574.9599999999999, "end": 579.1999999999999, "text": " you know reverse string in python you don't worry that it gets lonely the rest of time because it's", "tokens": [51004, 291, 458, 9943, 6798, 294, 38797, 291, 500, 380, 3292, 300, 309, 2170, 14236, 264, 1472, 295, 565, 570, 309, 311, 51216], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 117, "seek": 56216, "start": 579.1999999999999, "end": 584.16, "text": " not executing that's just some code that executed it finished executing and it just lies dormant", "tokens": [51216, 406, 32368, 300, 311, 445, 512, 3089, 300, 17577, 309, 4335, 32368, 293, 309, 445, 9134, 12521, 394, 51464], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 118, "seek": 56216, "start": 584.16, "end": 589.52, "text": " in memory doing absolutely nothing of interest and that's for me kind of what this model is doing", "tokens": [51464, 294, 4675, 884, 3122, 1825, 295, 1179, 293, 300, 311, 337, 385, 733, 295, 437, 341, 2316, 307, 884, 51732], "temperature": 0.0, "avg_logprob": -0.04605238227283254, "compression_ratio": 1.9259259259259258, "no_speech_prob": 0.05734245479106903}, {"id": 119, "seek": 58952, "start": 590.0799999999999, "end": 595.28, "text": " if they developed a model that was always on in some way like maybe it was always doing something", "tokens": [50392, 498, 436, 4743, 257, 2316, 300, 390, 1009, 322, 294, 512, 636, 411, 1310, 309, 390, 1009, 884, 746, 50652], "temperature": 0.0, "avg_logprob": -0.06301262619298532, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.009687244892120361}, {"id": 120, "seek": 58952, "start": 595.28, "end": 600.24, "text": " and it had memory and it had storage I could I still probably would think I would need some", "tokens": [50652, 293, 309, 632, 4675, 293, 309, 632, 6725, 286, 727, 286, 920, 1391, 576, 519, 286, 576, 643, 512, 50900], "temperature": 0.0, "avg_logprob": -0.06301262619298532, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.009687244892120361}, {"id": 121, "seek": 58952, "start": 600.24, "end": 605.12, "text": " convincing but it had any kind of you know higher level thought process but at least it would be", "tokens": [50900, 24823, 457, 309, 632, 604, 733, 295, 291, 458, 2946, 1496, 1194, 1399, 457, 412, 1935, 309, 576, 312, 51144], "temperature": 0.0, "avg_logprob": -0.06301262619298532, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.009687244892120361}, {"id": 122, "seek": 58952, "start": 605.12, "end": 609.76, "text": " plausible you know it would sort of think well at least it's got something going on in there", "tokens": [51144, 39925, 291, 458, 309, 576, 1333, 295, 519, 731, 412, 1935, 309, 311, 658, 746, 516, 322, 294, 456, 51376], "temperature": 0.0, "avg_logprob": -0.06301262619298532, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.009687244892120361}, {"id": 123, "seek": 58952, "start": 609.76, "end": 615.12, "text": " but I just don't think it's designed that way it's designed as a very very big reverse string", "tokens": [51376, 457, 286, 445, 500, 380, 519, 309, 311, 4761, 300, 636, 309, 311, 4761, 382, 257, 588, 588, 955, 9943, 6798, 51644], "temperature": 0.0, "avg_logprob": -0.06301262619298532, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.009687244892120361}, {"id": 124, "seek": 61512, "start": 615.12, "end": 619.68, "text": " and you know I don't worry about those things being sentient yeah but it's crazy I mean I mean", "tokens": [50364, 293, 291, 458, 286, 500, 380, 3292, 466, 729, 721, 885, 2279, 1196, 1338, 457, 309, 311, 3219, 286, 914, 286, 914, 50592], "temperature": 0.0, "avg_logprob": -0.08088132791351854, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.0013644180726259947}, {"id": 125, "seek": 61512, "start": 619.68, "end": 626.72, "text": " the well I mean in my opinion because they kind of they were implying that this AI or whatever", "tokens": [50592, 264, 731, 286, 914, 294, 452, 4800, 570, 436, 733, 295, 436, 645, 704, 7310, 300, 341, 7318, 420, 2035, 50944], "temperature": 0.0, "avg_logprob": -0.08088132791351854, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.0013644180726259947}, {"id": 126, "seek": 61512, "start": 626.72, "end": 630.4, "text": " was like a human or equivalent to a human and it seems like that's quite a stretch", "tokens": [50944, 390, 411, 257, 1952, 420, 10344, 281, 257, 1952, 293, 309, 2544, 411, 300, 311, 1596, 257, 5985, 51128], "temperature": 0.0, "avg_logprob": -0.08088132791351854, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.0013644180726259947}, {"id": 127, "seek": 61512, "start": 630.4, "end": 636.48, "text": " but in you know popular popular culture that's what people equate to AI it seems yeah that that", "tokens": [51128, 457, 294, 291, 458, 3743, 3743, 3713, 300, 311, 437, 561, 1267, 473, 281, 7318, 309, 2544, 1338, 300, 300, 51432], "temperature": 0.0, "avg_logprob": -0.08088132791351854, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.0013644180726259947}, {"id": 128, "seek": 61512, "start": 636.48, "end": 641.6800000000001, "text": " really that that's I think the big issue right is is that a lot of people get bogged down deciding", "tokens": [51432, 534, 300, 300, 311, 286, 519, 264, 955, 2734, 558, 307, 307, 300, 257, 688, 295, 561, 483, 26132, 3004, 760, 17990, 51692], "temperature": 0.0, "avg_logprob": -0.08088132791351854, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.0013644180726259947}, {"id": 129, "seek": 64168, "start": 641.68, "end": 645.52, "text": " well what does sentient actually mean and that doesn't interest me because when anyone uses the", "tokens": [50364, 731, 437, 775, 2279, 1196, 767, 914, 293, 300, 1177, 380, 1179, 385, 570, 562, 2878, 4960, 264, 50556], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 130, "seek": 64168, "start": 645.52, "end": 649.76, "text": " word they're not using it in a different definition they're using it in the definition we think of", "tokens": [50556, 1349, 436, 434, 406, 1228, 309, 294, 257, 819, 7123, 436, 434, 1228, 309, 294, 264, 7123, 321, 519, 295, 50768], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 131, "seek": 64168, "start": 649.76, "end": 655.04, "text": " as like termination and sky net right you know this this researcher wasn't saying I think it's", "tokens": [50768, 382, 411, 1433, 2486, 293, 5443, 2533, 558, 291, 458, 341, 341, 21751, 2067, 380, 1566, 286, 519, 309, 311, 51032], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 132, "seek": 64168, "start": 655.04, "end": 659.68, "text": " sentient but I define sentience as something like a slightly combinated if statement right he was", "tokens": [51032, 2279, 1196, 457, 286, 6964, 2279, 1182, 382, 746, 411, 257, 4748, 2512, 5410, 498, 5629, 558, 415, 390, 51264], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 133, "seek": 64168, "start": 659.68, "end": 664.2399999999999, "text": " saying I think it's like a person and it's got memories and it's got experiences and it gets", "tokens": [51264, 1566, 286, 519, 309, 311, 411, 257, 954, 293, 309, 311, 658, 8495, 293, 309, 311, 658, 5235, 293, 309, 2170, 51492], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 134, "seek": 64168, "start": 664.2399999999999, "end": 669.5999999999999, "text": " lonely and it needs a lot of feelings and yeah and and without with any with zero evidence to", "tokens": [51492, 14236, 293, 309, 2203, 257, 688, 295, 6640, 293, 1338, 293, 293, 1553, 365, 604, 365, 4018, 4467, 281, 51760], "temperature": 0.0, "avg_logprob": -0.10012360201537154, "compression_ratio": 1.9793103448275862, "no_speech_prob": 0.05782225728034973}, {"id": 135, "seek": 66960, "start": 669.6, "end": 673.36, "text": " support this and indeed not so much evidence is just it doesn't even make sense so I think you have", "tokens": [50364, 1406, 341, 293, 6451, 406, 370, 709, 4467, 307, 445, 309, 1177, 380, 754, 652, 2020, 370, 286, 519, 291, 362, 50552], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 136, "seek": 66960, "start": 673.36, "end": 677.52, "text": " to be extremely careful using the word sentient not because you might have a different definition", "tokens": [50552, 281, 312, 4664, 5026, 1228, 264, 1349, 2279, 1196, 406, 570, 291, 1062, 362, 257, 819, 7123, 50760], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 137, "seek": 66960, "start": 677.52, "end": 683.36, "text": " but because everyone has the actual same definition right which is actual you know human level", "tokens": [50760, 457, 570, 1518, 575, 264, 3539, 912, 7123, 558, 597, 307, 3539, 291, 458, 1952, 1496, 51052], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 138, "seek": 66960, "start": 683.36, "end": 688.32, "text": " cognitive ability but you know which so I don't spend a lot of time worrying about what the", "tokens": [51052, 15605, 3485, 457, 291, 458, 597, 370, 286, 500, 380, 3496, 257, 688, 295, 565, 18788, 466, 437, 264, 51300], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 139, "seek": 66960, "start": 688.32, "end": 692.72, "text": " definition of sentience is because if I go to someone in the conversation and say this is sentient", "tokens": [51300, 7123, 295, 2279, 1182, 307, 570, 498, 286, 352, 281, 1580, 294, 264, 3761, 293, 584, 341, 307, 2279, 1196, 51520], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 140, "seek": 66960, "start": 692.72, "end": 698.0, "text": " I think we both understand implicitly what that means to me to say that and so I don't I I think", "tokens": [51520, 286, 519, 321, 1293, 1223, 26947, 356, 437, 300, 1355, 281, 385, 281, 584, 300, 293, 370, 286, 500, 380, 286, 286, 519, 51784], "temperature": 0.0, "avg_logprob": -0.062101540198692906, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.015856172889471054}, {"id": 141, "seek": 69800, "start": 698.0, "end": 702.72, "text": " we're arguing about the definition is a bit silly because we actually all secretly agree on the", "tokens": [50364, 321, 434, 19697, 466, 264, 7123, 307, 257, 857, 11774, 570, 321, 767, 439, 22611, 3986, 322, 264, 50600], "temperature": 0.0, "avg_logprob": -0.061526248329564145, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0030634694267064333}, {"id": 142, "seek": 69800, "start": 702.72, "end": 707.92, "text": " definition yeah I mean I think for the general population I mean I'm not I'm not into the AI", "tokens": [50600, 7123, 1338, 286, 914, 286, 519, 337, 264, 2674, 4415, 286, 914, 286, 478, 406, 286, 478, 406, 666, 264, 7318, 50860], "temperature": 0.0, "avg_logprob": -0.061526248329564145, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0030634694267064333}, {"id": 143, "seek": 69800, "start": 707.92, "end": 712.24, "text": " piece like you are and that's why you I want to talk to you about it you know I just think people", "tokens": [50860, 2522, 411, 291, 366, 293, 300, 311, 983, 291, 286, 528, 281, 751, 281, 291, 466, 309, 291, 458, 286, 445, 519, 561, 51076], "temperature": 0.0, "avg_logprob": -0.061526248329564145, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0030634694267064333}, {"id": 144, "seek": 69800, "start": 712.24, "end": 717.04, "text": " go off movies and popular culture that's sort of what what people that's the impression they get", "tokens": [51076, 352, 766, 6233, 293, 3743, 3713, 300, 311, 1333, 295, 437, 437, 561, 300, 311, 264, 9995, 436, 483, 51316], "temperature": 0.0, "avg_logprob": -0.061526248329564145, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0030634694267064333}, {"id": 145, "seek": 69800, "start": 717.04, "end": 723.2, "text": " and that's why it was so big on the news perhaps but can you explain AI versus machine learning and", "tokens": [51316, 293, 300, 311, 983, 309, 390, 370, 955, 322, 264, 2583, 4317, 457, 393, 291, 2903, 7318, 5717, 3479, 2539, 293, 51624], "temperature": 0.0, "avg_logprob": -0.061526248329564145, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0030634694267064333}, {"id": 146, "seek": 72320, "start": 723.2, "end": 728.32, "text": " like what is machine learning what is AI and perhaps just take us down the road now yeah okay", "tokens": [50364, 411, 437, 307, 3479, 2539, 437, 307, 7318, 293, 4317, 445, 747, 505, 760, 264, 3060, 586, 1338, 1392, 50620], "temperature": 0.0, "avg_logprob": -0.09426875074370568, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.055548541247844696}, {"id": 147, "seek": 72320, "start": 728.32, "end": 733.84, "text": " like teach us you know sort of the basics of the stuff yeah so AI is misused in the sense that it's", "tokens": [50620, 411, 2924, 505, 291, 458, 1333, 295, 264, 14688, 295, 264, 1507, 1338, 370, 7318, 307, 3346, 4717, 294, 264, 2020, 300, 309, 311, 50896], "temperature": 0.0, "avg_logprob": -0.09426875074370568, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.055548541247844696}, {"id": 148, "seek": 72320, "start": 733.84, "end": 739.2, "text": " now a catchall right and I will admit I do that to an extent myself and it's partly because I'm", "tokens": [50896, 586, 257, 3745, 336, 558, 293, 286, 486, 9796, 286, 360, 300, 281, 364, 8396, 2059, 293, 309, 311, 17031, 570, 286, 478, 51164], "temperature": 0.0, "avg_logprob": -0.09426875074370568, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.055548541247844696}, {"id": 149, "seek": 72320, "start": 739.2, "end": 743.9200000000001, "text": " lazy right I think I think it's because it means I don't have to define the exact thing that I'm", "tokens": [51164, 14847, 558, 286, 519, 286, 519, 309, 311, 570, 309, 1355, 286, 500, 380, 362, 281, 6964, 264, 1900, 551, 300, 286, 478, 51400], "temperature": 0.0, "avg_logprob": -0.09426875074370568, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.055548541247844696}, {"id": 150, "seek": 72320, "start": 743.9200000000001, "end": 748.4000000000001, "text": " doing yeah at any given time car engines are slightly different but they all at the moment I", "tokens": [51400, 884, 1338, 412, 604, 2212, 565, 1032, 12982, 366, 4748, 819, 457, 436, 439, 412, 264, 1623, 286, 51624], "temperature": 0.0, "avg_logprob": -0.09426875074370568, "compression_ratio": 1.7675276752767528, "no_speech_prob": 0.055548541247844696}, {"id": 151, "seek": 74840, "start": 748.4, "end": 753.76, "text": " mean I say they will the combustion engines all do much the same thing even though one's got more", "tokens": [50364, 914, 286, 584, 436, 486, 264, 28121, 12982, 439, 360, 709, 264, 912, 551, 754, 1673, 472, 311, 658, 544, 50632], "temperature": 0.0, "avg_logprob": -0.0750620897151222, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.009990200400352478}, {"id": 152, "seek": 74840, "start": 753.76, "end": 758.0, "text": " cylinders and one's got fewer cylinders and one has a turbo and one doesn't you don't say I you", "tokens": [50632, 42166, 293, 472, 311, 658, 13366, 42166, 293, 472, 575, 257, 20902, 293, 472, 1177, 380, 291, 500, 380, 584, 286, 291, 50844], "temperature": 0.0, "avg_logprob": -0.0750620897151222, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.009990200400352478}, {"id": 153, "seek": 74840, "start": 758.0, "end": 762.0, "text": " don't miss it well I don't go on about those details I just say I've got a car and it goes", "tokens": [50844, 500, 380, 1713, 309, 731, 286, 500, 380, 352, 322, 466, 729, 4365, 286, 445, 584, 286, 600, 658, 257, 1032, 293, 309, 1709, 51044], "temperature": 0.0, "avg_logprob": -0.0750620897151222, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.009990200400352478}, {"id": 154, "seek": 74840, "start": 762.0, "end": 766.9599999999999, "text": " so AI I think is a catchall that includes machine learning so you've got AI as a big kind of", "tokens": [51044, 370, 7318, 286, 519, 307, 257, 3745, 336, 300, 5974, 3479, 2539, 370, 291, 600, 658, 7318, 382, 257, 955, 733, 295, 51292], "temperature": 0.0, "avg_logprob": -0.0750620897151222, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.009990200400352478}, {"id": 155, "seek": 74840, "start": 767.6, "end": 772.8, "text": " thing of stuff with loads of stuff in it and even my maze solving video where I just do very simple", "tokens": [51324, 551, 295, 1507, 365, 12668, 295, 1507, 294, 309, 293, 754, 452, 33032, 12606, 960, 689, 286, 445, 360, 588, 2199, 51584], "temperature": 0.0, "avg_logprob": -0.0750620897151222, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.009990200400352478}, {"id": 156, "seek": 77280, "start": 773.3599999999999, "end": 779.04, "text": " looking around the corridors of the maze would be defined in some sense as AI right but the", "tokens": [50392, 1237, 926, 264, 46920, 295, 264, 33032, 576, 312, 7642, 294, 512, 2020, 382, 7318, 558, 457, 264, 50676], "temperature": 0.0, "avg_logprob": -0.06251368391404458, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.093670554459095}, {"id": 157, "seek": 77280, "start": 779.04, "end": 784.3199999999999, "text": " Dijkstra algorithm that we use to do network routing and things and other similar algorithms", "tokens": [50676, 413, 6940, 19639, 9284, 300, 321, 764, 281, 360, 3209, 32722, 293, 721, 293, 661, 2531, 14642, 50940], "temperature": 0.0, "avg_logprob": -0.06251368391404458, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.093670554459095}, {"id": 158, "seek": 77280, "start": 784.3199999999999, "end": 789.28, "text": " you could define them in some ways as AI because they adapt to messages coming in and they change", "tokens": [50940, 291, 727, 6964, 552, 294, 512, 2098, 382, 7318, 570, 436, 6231, 281, 7897, 1348, 294, 293, 436, 1319, 51188], "temperature": 0.0, "avg_logprob": -0.06251368391404458, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.093670554459095}, {"id": 159, "seek": 77280, "start": 789.28, "end": 795.12, "text": " weights and paths and things but we wouldn't go as far as to say they were you know anyway you know", "tokens": [51188, 17443, 293, 14518, 293, 721, 457, 321, 2759, 380, 352, 382, 1400, 382, 281, 584, 436, 645, 291, 458, 4033, 291, 458, 51480], "temperature": 0.0, "avg_logprob": -0.06251368391404458, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.093670554459095}, {"id": 160, "seek": 77280, "start": 795.12, "end": 800.3199999999999, "text": " smart in some sense right so I think AI is quite a broad term and then there are things like genetic", "tokens": [51480, 4069, 294, 512, 2020, 558, 370, 286, 519, 7318, 307, 1596, 257, 4152, 1433, 293, 550, 456, 366, 721, 411, 12462, 51740], "temperature": 0.0, "avg_logprob": -0.06251368391404458, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.093670554459095}, {"id": 161, "seek": 80032, "start": 800.32, "end": 805.12, "text": " algorithms evolutionary algorithms which do slightly different things they are arguably less", "tokens": [50364, 14642, 27567, 14642, 597, 360, 4748, 819, 721, 436, 366, 26771, 1570, 50604], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 162, "seek": 80032, "start": 805.12, "end": 809.84, "text": " popular or less prevalent perhaps will be the right way to put it but they also come under the", "tokens": [50604, 3743, 420, 1570, 30652, 4317, 486, 312, 264, 558, 636, 281, 829, 309, 457, 436, 611, 808, 833, 264, 50840], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 163, "seek": 80032, "start": 809.84, "end": 815.44, "text": " umbrella of AI so AI is this very big umbrella term which basically encompasses most most things", "tokens": [50840, 21925, 295, 7318, 370, 7318, 307, 341, 588, 955, 21925, 1433, 597, 1936, 49866, 881, 881, 721, 51120], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 164, "seek": 80032, "start": 815.44, "end": 820.1600000000001, "text": " where you could imagine it was sort of intelligence and then in that you've got machine learning and", "tokens": [51120, 689, 291, 727, 3811, 309, 390, 1333, 295, 7599, 293, 550, 294, 300, 291, 600, 658, 3479, 2539, 293, 51356], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 165, "seek": 80032, "start": 820.1600000000001, "end": 825.0400000000001, "text": " machine learning is just the idea that you want to try and program a computer without having to", "tokens": [51356, 3479, 2539, 307, 445, 264, 1558, 300, 291, 528, 281, 853, 293, 1461, 257, 3820, 1553, 1419, 281, 51600], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 166, "seek": 80032, "start": 825.0400000000001, "end": 829.7600000000001, "text": " program it essentially you want to give it some examples or some other mechanism from which to", "tokens": [51600, 1461, 309, 4476, 291, 528, 281, 976, 309, 512, 5110, 420, 512, 661, 7513, 490, 597, 281, 51836], "temperature": 0.0, "avg_logprob": -0.05939433492463211, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.004394153598695993}, {"id": 167, "seek": 82976, "start": 829.76, "end": 835.92, "text": " learn and it comes up with its own rules for what it's going to do so a decision tree is a good", "tokens": [50364, 1466, 293, 309, 1487, 493, 365, 1080, 1065, 4474, 337, 437, 309, 311, 516, 281, 360, 370, 257, 3537, 4230, 307, 257, 665, 50672], "temperature": 0.0, "avg_logprob": -0.049423234803336005, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.002096792683005333}, {"id": 168, "seek": 82976, "start": 835.92, "end": 841.68, "text": " example of a very simple you know conceptually simple machine learning approach where you have", "tokens": [50672, 1365, 295, 257, 588, 2199, 291, 458, 3410, 671, 2199, 3479, 2539, 3109, 689, 291, 362, 50960], "temperature": 0.0, "avg_logprob": -0.049423234803336005, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.002096792683005333}, {"id": 169, "seek": 82976, "start": 841.68, "end": 847.4399999999999, "text": " some kind of data and every time you make a decision you just you just split it in two so maybe you're", "tokens": [50960, 512, 733, 295, 1412, 293, 633, 565, 291, 652, 257, 3537, 291, 445, 291, 445, 7472, 309, 294, 732, 370, 1310, 291, 434, 51248], "temperature": 0.0, "avg_logprob": -0.049423234803336005, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.002096792683005333}, {"id": 170, "seek": 82976, "start": 847.4399999999999, "end": 852.4, "text": " trying to analyze financial data decide whether people get a new credit card right so the first", "tokens": [51248, 1382, 281, 12477, 4669, 1412, 4536, 1968, 561, 483, 257, 777, 5397, 2920, 558, 370, 264, 700, 51496], "temperature": 0.0, "avg_logprob": -0.049423234803336005, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.002096792683005333}, {"id": 171, "seek": 82976, "start": 852.4, "end": 857.28, "text": " decision you make is have they ever defaulted on a credit card yes goes this way no goes this way", "tokens": [51496, 3537, 291, 652, 307, 362, 436, 1562, 7576, 292, 322, 257, 5397, 2920, 2086, 1709, 341, 636, 572, 1709, 341, 636, 51740], "temperature": 0.0, "avg_logprob": -0.049423234803336005, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.002096792683005333}, {"id": 172, "seek": 85728, "start": 857.36, "end": 862.24, "text": " and then the next decision is okay what's their current credit limit it's it's above 7000 it goes", "tokens": [50368, 293, 550, 264, 958, 3537, 307, 1392, 437, 311, 641, 2190, 5397, 4948, 309, 311, 309, 311, 3673, 1614, 1360, 309, 1709, 50612], "temperature": 0.0, "avg_logprob": -0.05678579157049006, "compression_ratio": 1.9183673469387754, "no_speech_prob": 0.0035851169377565384}, {"id": 173, "seek": 85728, "start": 862.24, "end": 867.4399999999999, "text": " this way below 7000 goes this way and you just split this data into two and two and two until at", "tokens": [50612, 341, 636, 2507, 1614, 1360, 1709, 341, 636, 293, 291, 445, 7472, 341, 1412, 666, 732, 293, 732, 293, 732, 1826, 412, 50872], "temperature": 0.0, "avg_logprob": -0.05678579157049006, "compression_ratio": 1.9183673469387754, "no_speech_prob": 0.0035851169377565384}, {"id": 174, "seek": 85728, "start": 867.4399999999999, "end": 872.16, "text": " the end you get the actual nodes that have the decisions on right and it's machine learning", "tokens": [50872, 264, 917, 291, 483, 264, 3539, 13891, 300, 362, 264, 5327, 322, 558, 293, 309, 311, 3479, 2539, 51108], "temperature": 0.0, "avg_logprob": -0.05678579157049006, "compression_ratio": 1.9183673469387754, "no_speech_prob": 0.0035851169377565384}, {"id": 175, "seek": 85728, "start": 872.16, "end": 876.56, "text": " because what you can do is you can you can basically create this tree but actually change", "tokens": [51108, 570, 437, 291, 393, 360, 307, 291, 393, 291, 393, 1936, 1884, 341, 4230, 457, 767, 1319, 51328], "temperature": 0.0, "avg_logprob": -0.05678579157049006, "compression_ratio": 1.9183673469387754, "no_speech_prob": 0.0035851169377565384}, {"id": 176, "seek": 85728, "start": 876.56, "end": 882.3199999999999, "text": " the numbers and values in it and the decisions based on the data so you can say well actually", "tokens": [51328, 264, 3547, 293, 4190, 294, 309, 293, 264, 5327, 2361, 322, 264, 1412, 370, 291, 393, 584, 731, 767, 51616], "temperature": 0.0, "avg_logprob": -0.05678579157049006, "compression_ratio": 1.9183673469387754, "no_speech_prob": 0.0035851169377565384}, {"id": 177, "seek": 88232, "start": 882.4000000000001, "end": 888.32, "text": " maybe 7000 doesn't work that well we're going to have it at 6500 and change the thresholds and things", "tokens": [50368, 1310, 1614, 1360, 1177, 380, 589, 300, 731, 321, 434, 516, 281, 362, 309, 412, 1386, 7526, 293, 1319, 264, 14678, 82, 293, 721, 50664], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 178, "seek": 88232, "start": 888.32, "end": 892.48, "text": " and you can do this all automatically in the training process so that's the kind of thing", "tokens": [50664, 293, 291, 393, 360, 341, 439, 6772, 294, 264, 3097, 1399, 370, 300, 311, 264, 733, 295, 551, 50872], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 179, "seek": 88232, "start": 892.48, "end": 897.12, "text": " we're talking about with machine learning now what happens of course is there's a big push in", "tokens": [50872, 321, 434, 1417, 466, 365, 3479, 2539, 586, 437, 2314, 295, 1164, 307, 456, 311, 257, 955, 2944, 294, 51104], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 180, "seek": 88232, "start": 897.12, "end": 901.0400000000001, "text": " deep learning which I you know I can also talk about but yeah be great yeah because I mean we just", "tokens": [51104, 2452, 2539, 597, 286, 291, 458, 286, 393, 611, 751, 466, 457, 1338, 312, 869, 1338, 570, 286, 914, 321, 445, 51300], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 181, "seek": 88232, "start": 901.0400000000001, "end": 904.48, "text": " hear the you know I just hear these buzzwords I mean preparing for this interview just like", "tokens": [51300, 1568, 264, 291, 458, 286, 445, 1568, 613, 13036, 13832, 286, 914, 10075, 337, 341, 4049, 445, 411, 51472], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 182, "seek": 88232, "start": 904.48, "end": 908.8800000000001, "text": " buzzword after buzzword after buzzword and I think a lot of us you know who are not in this sort of", "tokens": [51472, 13036, 7462, 934, 13036, 7462, 934, 13036, 7462, 293, 286, 519, 257, 688, 295, 505, 291, 458, 567, 366, 406, 294, 341, 1333, 295, 51692], "temperature": 0.0, "avg_logprob": -0.08304977416992188, "compression_ratio": 1.8885245901639345, "no_speech_prob": 0.005993570201098919}, {"id": 183, "seek": 90888, "start": 908.88, "end": 913.84, "text": " field but are interested in it you know so yeah if you can define as much and like yeah yeah sure so", "tokens": [50364, 2519, 457, 366, 3102, 294, 309, 291, 458, 370, 1338, 498, 291, 393, 6964, 382, 709, 293, 411, 1338, 1338, 988, 370, 50612], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 184, "seek": 90888, "start": 913.84, "end": 918.96, "text": " I mean so you've got yeah sorry you've got you've got ai right which is which is right here in some", "tokens": [50612, 286, 914, 370, 291, 600, 658, 1338, 2597, 291, 600, 658, 291, 600, 658, 9783, 558, 597, 307, 597, 307, 558, 510, 294, 512, 50868], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 185, "seek": 90888, "start": 918.96, "end": 922.8, "text": " subset of actors machine learning which includes what I would kind of call traditional machine", "tokens": [50868, 25993, 295, 10037, 3479, 2539, 597, 5974, 437, 286, 576, 733, 295, 818, 5164, 3479, 51060], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 186, "seek": 90888, "start": 922.8, "end": 927.6, "text": " learning like support vector machines decision trees random forests right these are all linear", "tokens": [51060, 2539, 411, 1406, 8062, 8379, 3537, 5852, 4974, 21700, 558, 613, 366, 439, 8213, 51300], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 187, "seek": 90888, "start": 927.6, "end": 932.48, "text": " regression even right where you're just fitting a line to us to some data and then we have things", "tokens": [51300, 24590, 754, 558, 689, 291, 434, 445, 15669, 257, 1622, 281, 505, 281, 512, 1412, 293, 550, 321, 362, 721, 51544], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 188, "seek": 90888, "start": 932.48, "end": 938.72, "text": " like slightly more complicated algorithms like artificial neural networks which they I mean they", "tokens": [51544, 411, 4748, 544, 6179, 14642, 411, 11677, 18161, 9590, 597, 436, 286, 914, 436, 51856], "temperature": 0.0, "avg_logprob": -0.14498795920271215, "compression_ratio": 1.9180327868852458, "no_speech_prob": 0.015372378751635551}, {"id": 189, "seek": 93872, "start": 938.72, "end": 944.88, "text": " kind of take some inspiration from our brains but I would I would be very careful saying that to me", "tokens": [50364, 733, 295, 747, 512, 10249, 490, 527, 15442, 457, 286, 576, 286, 576, 312, 588, 5026, 1566, 300, 281, 385, 50672], "temperature": 0.0, "avg_logprob": -0.10327977532739038, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.00120114057790488}, {"id": 190, "seek": 93872, "start": 944.88, "end": 952.1600000000001, "text": " I think you know to suggest it's like our brain is is is is iffy and so yeah yeah but they have", "tokens": [50672, 286, 519, 291, 458, 281, 3402, 309, 311, 411, 527, 3567, 307, 307, 307, 307, 498, 22522, 293, 370, 1338, 1338, 457, 436, 362, 51036], "temperature": 0.0, "avg_logprob": -0.10327977532739038, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.00120114057790488}, {"id": 191, "seek": 93872, "start": 952.1600000000001, "end": 956.8000000000001, "text": " their name yeah like that's what they're called and then what we've basically done recently", "tokens": [51036, 641, 1315, 1338, 411, 300, 311, 437, 436, 434, 1219, 293, 550, 437, 321, 600, 1936, 1096, 3938, 51268], "temperature": 0.0, "avg_logprob": -0.10327977532739038, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.00120114057790488}, {"id": 192, "seek": 93872, "start": 957.6800000000001, "end": 961.6, "text": " is we've made them much much bigger right and we've introduced other terms like convolutional", "tokens": [51312, 307, 321, 600, 1027, 552, 709, 709, 3801, 558, 293, 321, 600, 7268, 661, 2115, 411, 45216, 304, 51508], "temperature": 0.0, "avg_logprob": -0.10327977532739038, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.00120114057790488}, {"id": 193, "seek": 93872, "start": 961.6, "end": 967.44, "text": " networks and transformers and things but for the sake of you know this sentence they're just bigger", "tokens": [51508, 9590, 293, 4088, 433, 293, 721, 457, 337, 264, 9717, 295, 291, 458, 341, 8174, 436, 434, 445, 3801, 51800], "temperature": 0.0, "avg_logprob": -0.10327977532739038, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.00120114057790488}, {"id": 194, "seek": 96744, "start": 967.44, "end": 972.72, "text": " deeper networks that can learn more impressive functions so they can map that input to that", "tokens": [50364, 7731, 9590, 300, 393, 1466, 544, 8992, 6828, 370, 436, 393, 4471, 300, 4846, 281, 300, 50628], "temperature": 0.0, "avg_logprob": -0.06283759195870216, "compression_ratio": 1.8409090909090908, "no_speech_prob": 0.001030273619107902}, {"id": 195, "seek": 96744, "start": 972.72, "end": 977.12, "text": " output more effectively right because that's what you want to try and do you've got some data", "tokens": [50628, 5598, 544, 8659, 558, 570, 300, 311, 437, 291, 528, 281, 853, 293, 360, 291, 600, 658, 512, 1412, 50848], "temperature": 0.0, "avg_logprob": -0.06283759195870216, "compression_ratio": 1.8409090909090908, "no_speech_prob": 0.001030273619107902}, {"id": 196, "seek": 96744, "start": 977.12, "end": 981.6, "text": " you've got some predictions you need to make on that data and your hope is that once you've trained", "tokens": [50848, 291, 600, 658, 512, 21264, 291, 643, 281, 652, 322, 300, 1412, 293, 428, 1454, 307, 300, 1564, 291, 600, 8895, 51072], "temperature": 0.0, "avg_logprob": -0.06283759195870216, "compression_ratio": 1.8409090909090908, "no_speech_prob": 0.001030273619107902}, {"id": 197, "seek": 96744, "start": 981.6, "end": 986.32, "text": " it some new data comes along and you can make some good predictions right I mean let's think of an", "tokens": [51072, 309, 512, 777, 1412, 1487, 2051, 293, 291, 393, 652, 512, 665, 21264, 558, 286, 914, 718, 311, 519, 295, 364, 51308], "temperature": 0.0, "avg_logprob": -0.06283759195870216, "compression_ratio": 1.8409090909090908, "no_speech_prob": 0.001030273619107902}, {"id": 198, "seek": 96744, "start": 986.32, "end": 994.48, "text": " example suppose suppose I want to you know do um MRI segmentation for medical imaging right so I have", "tokens": [51308, 1365, 7297, 7297, 286, 528, 281, 291, 458, 360, 1105, 32812, 9469, 399, 337, 4625, 25036, 558, 370, 286, 362, 51716], "temperature": 0.0, "avg_logprob": -0.06283759195870216, "compression_ratio": 1.8409090909090908, "no_speech_prob": 0.001030273619107902}, {"id": 199, "seek": 99448, "start": 994.5600000000001, "end": 998.48, "text": " 50 patients some of whom unfortunately have some kind of illness some of whom don't", "tokens": [50368, 2625, 4209, 512, 295, 7101, 7015, 362, 512, 733, 295, 10152, 512, 295, 7101, 500, 380, 50564], "temperature": 0.0, "avg_logprob": -0.0494102775503736, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.004599748179316521}, {"id": 200, "seek": 99448, "start": 998.48, "end": 1003.44, "text": " and I train the network to try and find the ones that have illness my hope is that when I then", "tokens": [50564, 293, 286, 3847, 264, 3209, 281, 853, 293, 915, 264, 2306, 300, 362, 10152, 452, 1454, 307, 300, 562, 286, 550, 50812], "temperature": 0.0, "avg_logprob": -0.0494102775503736, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.004599748179316521}, {"id": 201, "seek": 99448, "start": 1003.44, "end": 1008.96, "text": " sort of fix that network in place and bring in some new patients it will be able to say whether", "tokens": [50812, 1333, 295, 3191, 300, 3209, 294, 1081, 293, 1565, 294, 512, 777, 4209, 309, 486, 312, 1075, 281, 584, 1968, 51088], "temperature": 0.0, "avg_logprob": -0.0494102775503736, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.004599748179316521}, {"id": 202, "seek": 99448, "start": 1008.96, "end": 1014.32, "text": " they have that illness or not that's the idea and we'll have done that by basically reconfiguring", "tokens": [51088, 436, 362, 300, 10152, 420, 406, 300, 311, 264, 1558, 293, 321, 603, 362, 1096, 300, 538, 1936, 9993, 20646, 1345, 51356], "temperature": 0.0, "avg_logprob": -0.0494102775503736, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.004599748179316521}, {"id": 203, "seek": 99448, "start": 1014.32, "end": 1020.0, "text": " itself based on the examples I gave it to begin with so doing a technology example it could be", "tokens": [51356, 2564, 2361, 322, 264, 5110, 286, 2729, 309, 281, 1841, 365, 370, 884, 257, 2899, 1365, 309, 727, 312, 51640], "temperature": 0.0, "avg_logprob": -0.0494102775503736, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.004599748179316521}, {"id": 204, "seek": 102000, "start": 1020.0, "end": 1025.2, "text": " something like spotting is this a virus or is it just yeah exactly right and in fact you know", "tokens": [50364, 746, 411, 4008, 783, 307, 341, 257, 5752, 420, 307, 309, 445, 1338, 2293, 558, 293, 294, 1186, 291, 458, 50624], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 205, "seek": 102000, "start": 1025.2, "end": 1029.6, "text": " modern antiviruses will include some kind of machine learning element probably so you know you", "tokens": [50624, 4363, 2511, 592, 347, 8355, 486, 4090, 512, 733, 295, 3479, 2539, 4478, 1391, 370, 291, 458, 291, 50844], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 206, "seek": 102000, "start": 1029.6, "end": 1034.16, "text": " might have features derived from so what we what we usually put into the front of a network is", "tokens": [50844, 1062, 362, 4122, 18949, 490, 370, 437, 321, 437, 321, 2673, 829, 666, 264, 1868, 295, 257, 3209, 307, 51072], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 207, "seek": 102000, "start": 1034.16, "end": 1040.56, "text": " something we call features which is um our way of just saying input data right so sometimes you've", "tokens": [51072, 746, 321, 818, 4122, 597, 307, 1105, 527, 636, 295, 445, 1566, 4846, 1412, 558, 370, 2171, 291, 600, 51392], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 208, "seek": 102000, "start": 1040.56, "end": 1044.4, "text": " crafted those features like you've chosen what you think is interesting features to give the network", "tokens": [51392, 36213, 729, 4122, 411, 291, 600, 8614, 437, 291, 519, 307, 1880, 4122, 281, 976, 264, 3209, 51584], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 209, "seek": 102000, "start": 1044.4, "end": 1048.8, "text": " and sometimes you'll just shove something in like you know in antivirus you could you could choose", "tokens": [51584, 293, 2171, 291, 603, 445, 35648, 746, 294, 411, 291, 458, 294, 2511, 592, 9619, 291, 727, 291, 727, 2826, 51804], "temperature": 0.0, "avg_logprob": -0.07214951702928919, "compression_ratio": 1.9795918367346939, "no_speech_prob": 0.04137355089187622}, {"id": 210, "seek": 104880, "start": 1048.8799999999999, "end": 1053.44, "text": " things like how many system calls does it make or you know how many how many bytes is the executable", "tokens": [50368, 721, 411, 577, 867, 1185, 5498, 775, 309, 652, 420, 291, 458, 577, 867, 577, 867, 36088, 307, 264, 7568, 712, 50596], "temperature": 0.0, "avg_logprob": -0.0668873185092963, "compression_ratio": 1.8807692307692307, "no_speech_prob": 0.010641192086040974}, {"id": 211, "seek": 104880, "start": 1053.44, "end": 1057.84, "text": " or how many of this particular character does it have in the executable and you could choose those", "tokens": [50596, 420, 577, 867, 295, 341, 1729, 2517, 775, 309, 362, 294, 264, 7568, 712, 293, 291, 727, 2826, 729, 50816], "temperature": 0.0, "avg_logprob": -0.0668873185092963, "compression_ratio": 1.8807692307692307, "no_speech_prob": 0.010641192086040974}, {"id": 212, "seek": 104880, "start": 1057.84, "end": 1062.8799999999999, "text": " features because you think they are indicative sometimes of malware or not malware you stick", "tokens": [50816, 4122, 570, 291, 519, 436, 366, 47513, 2171, 295, 40747, 420, 406, 40747, 291, 2897, 51068], "temperature": 0.0, "avg_logprob": -0.0668873185092963, "compression_ratio": 1.8807692307692307, "no_speech_prob": 0.010641192086040974}, {"id": 213, "seek": 104880, "start": 1062.8799999999999, "end": 1069.76, "text": " them in some kind of a machine learning approach with a load of examples and then say right now", "tokens": [51068, 552, 294, 512, 733, 295, 257, 3479, 2539, 3109, 365, 257, 3677, 295, 5110, 293, 550, 584, 558, 586, 51412], "temperature": 0.0, "avg_logprob": -0.0668873185092963, "compression_ratio": 1.8807692307692307, "no_speech_prob": 0.010641192086040974}, {"id": 214, "seek": 104880, "start": 1069.76, "end": 1076.3999999999999, "text": " change your weights and change your rules internally so that on this training set your prediction is", "tokens": [51412, 1319, 428, 17443, 293, 1319, 428, 4474, 19501, 370, 300, 322, 341, 3097, 992, 428, 17630, 307, 51744], "temperature": 0.0, "avg_logprob": -0.0668873185092963, "compression_ratio": 1.8807692307692307, "no_speech_prob": 0.010641192086040974}, {"id": 215, "seek": 107640, "start": 1076.48, "end": 1083.52, "text": " accurate as possible right and so let's say you do that you have 100 000 malware and regular samples", "tokens": [50368, 8559, 382, 1944, 558, 293, 370, 718, 311, 584, 291, 360, 300, 291, 362, 2319, 13711, 40747, 293, 3890, 10938, 50720], "temperature": 0.0, "avg_logprob": -0.06477124907753684, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.009101429022848606}, {"id": 216, "seek": 107640, "start": 1083.52, "end": 1088.4, "text": " you give it to your AI and you just over and over again say right you got that one wrong", "tokens": [50720, 291, 976, 309, 281, 428, 7318, 293, 291, 445, 670, 293, 670, 797, 584, 558, 291, 658, 300, 472, 2085, 50964], "temperature": 0.0, "avg_logprob": -0.06477124907753684, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.009101429022848606}, {"id": 217, "seek": 107640, "start": 1089.2800000000002, "end": 1093.52, "text": " reconfigure yourself so that next time you get a bit better at predicting it you do that over", "tokens": [51008, 9993, 20646, 540, 1803, 370, 300, 958, 565, 291, 483, 257, 857, 1101, 412, 32884, 309, 291, 360, 300, 670, 51220], "temperature": 0.0, "avg_logprob": -0.06477124907753684, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.009101429022848606}, {"id": 218, "seek": 107640, "start": 1093.52, "end": 1098.0800000000002, "text": " and over again and the hope is then that when a new virus comes along that you've never seen", "tokens": [51220, 293, 670, 797, 293, 264, 1454, 307, 550, 300, 562, 257, 777, 5752, 1487, 2051, 300, 291, 600, 1128, 1612, 51448], "temperature": 0.0, "avg_logprob": -0.06477124907753684, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.009101429022848606}, {"id": 219, "seek": 107640, "start": 1098.88, "end": 1104.4, "text": " those same sort of should we say suspicious things exist in it and the network flags that up", "tokens": [51488, 729, 912, 1333, 295, 820, 321, 584, 17931, 721, 2514, 294, 309, 293, 264, 3209, 23265, 300, 493, 51764], "temperature": 0.0, "avg_logprob": -0.06477124907753684, "compression_ratio": 1.7900763358778626, "no_speech_prob": 0.009101429022848606}, {"id": 220, "seek": 110440, "start": 1104.4, "end": 1109.2, "text": " that's the idea so the the training data is like the the stuff you give it initially which would be", "tokens": [50364, 300, 311, 264, 1558, 370, 264, 264, 3097, 1412, 307, 411, 264, 264, 1507, 291, 976, 309, 9105, 597, 576, 312, 50604], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 221, "seek": 110440, "start": 1109.2, "end": 1115.0400000000002, "text": " this 100 000 like virus and not virus yeah and then you when you say weights you like it's basically", "tokens": [50604, 341, 2319, 13711, 411, 5752, 293, 406, 5752, 1338, 293, 550, 291, 562, 291, 584, 17443, 291, 411, 309, 311, 1936, 50896], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 222, "seek": 110440, "start": 1115.0400000000002, "end": 1120.96, "text": " saying like if it makes like a hundred system calls rather than 10 or you said some kind of", "tokens": [50896, 1566, 411, 498, 309, 1669, 411, 257, 3262, 1185, 5498, 2831, 813, 1266, 420, 291, 848, 512, 733, 295, 51192], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 223, "seek": 110440, "start": 1120.96, "end": 1125.44, "text": " threshold is that right yeah so okay so in a decision tree or something like that that's what", "tokens": [51192, 14678, 307, 300, 558, 1338, 370, 1392, 370, 294, 257, 3537, 4230, 420, 746, 411, 300, 300, 311, 437, 51416], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 224, "seek": 110440, "start": 1125.44, "end": 1129.2800000000002, "text": " would happen there would be some kind of threshold decision based at some point during it for a", "tokens": [51416, 576, 1051, 456, 576, 312, 512, 733, 295, 14678, 3537, 2361, 412, 512, 935, 1830, 309, 337, 257, 51608], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 225, "seek": 110440, "start": 1129.2800000000002, "end": 1132.3200000000002, "text": " neural network it's a little bit more complicated and it's what you actually do is you treat all", "tokens": [51608, 18161, 3209, 309, 311, 257, 707, 857, 544, 6179, 293, 309, 311, 437, 291, 767, 360, 307, 291, 2387, 439, 51760], "temperature": 0.0, "avg_logprob": -0.08267875151200728, "compression_ratio": 1.93, "no_speech_prob": 0.0023204279132187366}, {"id": 226, "seek": 113232, "start": 1132.32, "end": 1136.6399999999999, "text": " these weights just as numbers and you just calculate mathematical functions based on those", "tokens": [50364, 613, 17443, 445, 382, 3547, 293, 291, 445, 8873, 18894, 6828, 2361, 322, 729, 50580], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 227, "seek": 113232, "start": 1136.6399999999999, "end": 1141.76, "text": " numbers so what you might do is multiply all of those numbers that come in by some weights", "tokens": [50580, 3547, 370, 437, 291, 1062, 360, 307, 12972, 439, 295, 729, 3547, 300, 808, 294, 538, 512, 17443, 50836], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 228, "seek": 113232, "start": 1141.76, "end": 1146.6399999999999, "text": " let's say you multiply one of them by two and one of them by negative four one of them by a half", "tokens": [50836, 718, 311, 584, 291, 12972, 472, 295, 552, 538, 732, 293, 472, 295, 552, 538, 3671, 1451, 472, 295, 552, 538, 257, 1922, 51080], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 229, "seek": 113232, "start": 1146.6399999999999, "end": 1150.3999999999999, "text": " and then you add them all up and what that does is take a different amount of each one", "tokens": [51080, 293, 550, 291, 909, 552, 439, 493, 293, 437, 300, 775, 307, 747, 257, 819, 2372, 295, 1184, 472, 51268], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 230, "seek": 113232, "start": 1150.3999999999999, "end": 1154.72, "text": " and then you and then you repeat that process over and over again to try and basically learn a", "tokens": [51268, 293, 550, 291, 293, 550, 291, 7149, 300, 1399, 670, 293, 670, 797, 281, 853, 293, 1936, 1466, 257, 51484], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 231, "seek": 113232, "start": 1154.72, "end": 1159.04, "text": " complicated mathematical function that's really the only thing it does you know you're essentially", "tokens": [51484, 6179, 18894, 2445, 300, 311, 534, 264, 787, 551, 309, 775, 291, 458, 291, 434, 4476, 51700], "temperature": 0.0, "avg_logprob": -0.0409241149095985, "compression_ratio": 2.04014598540146, "no_speech_prob": 0.009385264478623867}, {"id": 232, "seek": 115904, "start": 1159.04, "end": 1163.6, "text": " trying to fit a really complicated curve through the data essentially so that you can distinguish", "tokens": [50364, 1382, 281, 3318, 257, 534, 6179, 7605, 807, 264, 1412, 4476, 370, 300, 291, 393, 20206, 50592], "temperature": 0.0, "avg_logprob": -0.0818604936405104, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.003793217707425356}, {"id": 233, "seek": 115904, "start": 1163.6, "end": 1173.04, "text": " between real and fake malware or you know regular executables and malware and and so the weight", "tokens": [50592, 1296, 957, 293, 7592, 40747, 420, 291, 458, 3890, 7568, 2965, 293, 40747, 293, 293, 370, 264, 3364, 51064], "temperature": 0.0, "avg_logprob": -0.0818604936405104, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.003793217707425356}, {"id": 234, "seek": 115904, "start": 1173.04, "end": 1177.2, "text": " when I say weight what I'm really talking about is the parameters of my model which influence", "tokens": [51064, 562, 286, 584, 3364, 437, 286, 478, 534, 1417, 466, 307, 264, 9834, 295, 452, 2316, 597, 6503, 51272], "temperature": 0.0, "avg_logprob": -0.0818604936405104, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.003793217707425356}, {"id": 235, "seek": 115904, "start": 1177.2, "end": 1182.56, "text": " this mathematical function so the and then you would adjust the the the weights and the mathematical", "tokens": [51272, 341, 18894, 2445, 370, 264, 293, 550, 291, 576, 4369, 264, 264, 264, 17443, 293, 264, 18894, 51540], "temperature": 0.0, "avg_logprob": -0.0818604936405104, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.003793217707425356}, {"id": 236, "seek": 115904, "start": 1182.56, "end": 1188.56, "text": " functions based on the result did it get did it's correctly determine that this was malware", "tokens": [51540, 6828, 2361, 322, 264, 1874, 630, 309, 483, 630, 309, 311, 8944, 6997, 300, 341, 390, 40747, 51840], "temperature": 0.0, "avg_logprob": -0.0818604936405104, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.003793217707425356}, {"id": 237, "seek": 118856, "start": 1188.8799999999999, "end": 1193.36, "text": " exactly so so let's suppose we were doing malware right so we think one an output of one means it's", "tokens": [50380, 2293, 370, 370, 718, 311, 7297, 321, 645, 884, 40747, 558, 370, 321, 519, 472, 364, 5598, 295, 472, 1355, 309, 311, 50604], "temperature": 0.0, "avg_logprob": -0.0632165789604187, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0013003794010728598}, {"id": 238, "seek": 118856, "start": 1193.36, "end": 1198.48, "text": " definitely malware and an output of zero means it's definitely not malware an output of 0.5 is", "tokens": [50604, 2138, 40747, 293, 364, 5598, 295, 4018, 1355, 309, 311, 2138, 406, 40747, 364, 5598, 295, 1958, 13, 20, 307, 50860], "temperature": 0.0, "avg_logprob": -0.0632165789604187, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0013003794010728598}, {"id": 239, "seek": 118856, "start": 1198.48, "end": 1205.12, "text": " not very useful to us because we don't know um what we do is we put in a piece of malware or many", "tokens": [50860, 406, 588, 4420, 281, 505, 570, 321, 500, 380, 458, 1105, 437, 321, 360, 307, 321, 829, 294, 257, 2522, 295, 40747, 420, 867, 51192], "temperature": 0.0, "avg_logprob": -0.0632165789604187, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0013003794010728598}, {"id": 240, "seek": 118856, "start": 1205.12, "end": 1210.0, "text": " pieces of malware we run through let's say our deep neural network or whatever it is we're running", "tokens": [51192, 3755, 295, 40747, 321, 1190, 807, 718, 311, 584, 527, 2452, 18161, 3209, 420, 2035, 309, 307, 321, 434, 2614, 51436], "temperature": 0.0, "avg_logprob": -0.0632165789604187, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0013003794010728598}, {"id": 241, "seek": 118856, "start": 1210.0, "end": 1214.8, "text": " and it will produce a value between zero and one and then we say well look you gave us a value of", "tokens": [51436, 293, 309, 486, 5258, 257, 2158, 1296, 4018, 293, 472, 293, 550, 321, 584, 731, 574, 291, 2729, 505, 257, 2158, 295, 51676], "temperature": 0.0, "avg_logprob": -0.0632165789604187, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0013003794010728598}, {"id": 242, "seek": 121480, "start": 1214.8, "end": 1221.12, "text": " 0.7 but actually it was malware this time so you've got an error of 0.3 I wanted you to produce", "tokens": [50364, 1958, 13, 22, 457, 767, 309, 390, 40747, 341, 565, 370, 291, 600, 658, 364, 6713, 295, 1958, 13, 18, 286, 1415, 291, 281, 5258, 50680], "temperature": 0.0, "avg_logprob": -0.05067400669488381, "compression_ratio": 1.7793594306049823, "no_speech_prob": 0.02000412344932556}, {"id": 243, "seek": 121480, "start": 1221.12, "end": 1227.12, "text": " 0.3 higher for that one than you did so can you adjust your mathematical function to next time when", "tokens": [50680, 1958, 13, 18, 2946, 337, 300, 472, 813, 291, 630, 370, 393, 291, 4369, 428, 18894, 2445, 281, 958, 565, 562, 50980], "temperature": 0.0, "avg_logprob": -0.05067400669488381, "compression_ratio": 1.7793594306049823, "no_speech_prob": 0.02000412344932556}, {"id": 244, "seek": 121480, "start": 1227.12, "end": 1232.48, "text": " I put that malware in produce a value of one and not a value of 0.7 now if you do that for one malware", "tokens": [50980, 286, 829, 300, 40747, 294, 5258, 257, 2158, 295, 472, 293, 406, 257, 2158, 295, 1958, 13, 22, 586, 498, 291, 360, 300, 337, 472, 40747, 51248], "temperature": 0.0, "avg_logprob": -0.05067400669488381, "compression_ratio": 1.7793594306049823, "no_speech_prob": 0.02000412344932556}, {"id": 245, "seek": 121480, "start": 1232.48, "end": 1236.72, "text": " sample it's going to be the worst machine learning ever because you're just going to give it something", "tokens": [51248, 6889, 309, 311, 516, 281, 312, 264, 5855, 3479, 2539, 1562, 570, 291, 434, 445, 516, 281, 976, 309, 746, 51460], "temperature": 0.0, "avg_logprob": -0.05067400669488381, "compression_ratio": 1.7793594306049823, "no_speech_prob": 0.02000412344932556}, {"id": 246, "seek": 121480, "start": 1236.72, "end": 1240.8799999999999, "text": " else and it's going to go I don't know what you mean right because this is nonsense so you have to", "tokens": [51460, 1646, 293, 309, 311, 516, 281, 352, 286, 500, 380, 458, 437, 291, 914, 558, 570, 341, 307, 14925, 370, 291, 362, 281, 51668], "temperature": 0.0, "avg_logprob": -0.05067400669488381, "compression_ratio": 1.7793594306049823, "no_speech_prob": 0.02000412344932556}, {"id": 247, "seek": 124088, "start": 1240.96, "end": 1245.68, "text": " give it a lot of data and and I guess what you're trying to do is calculate the best average", "tokens": [50368, 976, 309, 257, 688, 295, 1412, 293, 293, 286, 2041, 437, 291, 434, 1382, 281, 360, 307, 8873, 264, 1151, 4274, 50604], "temperature": 0.0, "avg_logprob": -0.07625766349049796, "compression_ratio": 1.8125, "no_speech_prob": 0.019686399027705193}, {"id": 248, "seek": 124088, "start": 1245.68, "end": 1251.8400000000001, "text": " mathematical function that does the best job it can in the general case of all of these malware's", "tokens": [50604, 18894, 2445, 300, 775, 264, 1151, 1691, 309, 393, 294, 264, 2674, 1389, 295, 439, 295, 613, 40747, 311, 50912], "temperature": 0.0, "avg_logprob": -0.07625766349049796, "compression_ratio": 1.8125, "no_speech_prob": 0.019686399027705193}, {"id": 249, "seek": 124088, "start": 1251.8400000000001, "end": 1257.5200000000002, "text": " right massively optimizing one malware is not useful because it's not going to generalize it's", "tokens": [50912, 558, 29379, 40425, 472, 40747, 307, 406, 4420, 570, 309, 311, 406, 516, 281, 2674, 1125, 309, 311, 51196], "temperature": 0.0, "avg_logprob": -0.07625766349049796, "compression_ratio": 1.8125, "no_speech_prob": 0.019686399027705193}, {"id": 250, "seek": 124088, "start": 1257.5200000000002, "end": 1263.6000000000001, "text": " not going to apply in real world to some new malware so you put in 10, 20, 100 different", "tokens": [51196, 406, 516, 281, 3079, 294, 957, 1002, 281, 512, 777, 40747, 370, 291, 829, 294, 1266, 11, 945, 11, 2319, 819, 51500], "temperature": 0.0, "avg_logprob": -0.07625766349049796, "compression_ratio": 1.8125, "no_speech_prob": 0.019686399027705193}, {"id": 251, "seek": 124088, "start": 1263.6000000000001, "end": 1268.64, "text": " malware at the same time and all of them are trying to go to one or go to zero and you're", "tokens": [51500, 40747, 412, 264, 912, 565, 293, 439, 295, 552, 366, 1382, 281, 352, 281, 472, 420, 352, 281, 4018, 293, 291, 434, 51752], "temperature": 0.0, "avg_logprob": -0.07625766349049796, "compression_ratio": 1.8125, "no_speech_prob": 0.019686399027705193}, {"id": 252, "seek": 126864, "start": 1268.64, "end": 1273.3600000000001, "text": " trying to change the weights to simultaneously do all of those at the same time that's that's what", "tokens": [50364, 1382, 281, 1319, 264, 17443, 281, 16561, 360, 439, 295, 729, 412, 264, 912, 565, 300, 311, 300, 311, 437, 50600], "temperature": 0.0, "avg_logprob": -0.06874111586926031, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.001476521953009069}, {"id": 253, "seek": 126864, "start": 1273.3600000000001, "end": 1278.8000000000002, "text": " machine learning does basically for a neural network the process for actually doing this it's", "tokens": [50600, 3479, 2539, 775, 1936, 337, 257, 18161, 3209, 264, 1399, 337, 767, 884, 341, 309, 311, 50872], "temperature": 0.0, "avg_logprob": -0.06874111586926031, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.001476521953009069}, {"id": 254, "seek": 126864, "start": 1278.8000000000002, "end": 1284.24, "text": " it's complicated to describe but it's it's fairly intuitive what you do is you because all these", "tokens": [50872, 309, 311, 6179, 281, 6786, 457, 309, 311, 309, 311, 6457, 21769, 437, 291, 360, 307, 291, 570, 439, 613, 51144], "temperature": 0.0, "avg_logprob": -0.06874111586926031, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.001476521953009069}, {"id": 255, "seek": 126864, "start": 1284.24, "end": 1288.8000000000002, "text": " weights are involved in the calculation you put your features in for your malware you go all the", "tokens": [51144, 17443, 366, 3288, 294, 264, 17108, 291, 829, 428, 4122, 294, 337, 428, 40747, 291, 352, 439, 264, 51372], "temperature": 0.0, "avg_logprob": -0.06874111586926031, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.001476521953009069}, {"id": 256, "seek": 126864, "start": 1288.8000000000002, "end": 1294.5600000000002, "text": " way forward through the deep learning or the network then you calculate your error and then", "tokens": [51372, 636, 2128, 807, 264, 2452, 2539, 420, 264, 3209, 550, 291, 8873, 428, 6713, 293, 550, 51660], "temperature": 0.0, "avg_logprob": -0.06874111586926031, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.001476521953009069}, {"id": 257, "seek": 129456, "start": 1294.56, "end": 1299.6799999999998, "text": " you go backwards adjusting the weights based on what you just found out right essentially and so", "tokens": [50364, 291, 352, 12204, 23559, 264, 17443, 2361, 322, 437, 291, 445, 1352, 484, 558, 4476, 293, 370, 50620], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 258, "seek": 129456, "start": 1299.6799999999998, "end": 1304.0, "text": " if a weight doesn't have any impact on the decision because let's say it just sets everything to zero", "tokens": [50620, 498, 257, 3364, 1177, 380, 362, 604, 2712, 322, 264, 3537, 570, 718, 311, 584, 309, 445, 6352, 1203, 281, 4018, 50836], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 259, "seek": 129456, "start": 1304.0, "end": 1307.52, "text": " you won't adjust that weight because it's not useful you will only adjust the ones because", "tokens": [50836, 291, 1582, 380, 4369, 300, 3364, 570, 309, 311, 406, 4420, 291, 486, 787, 4369, 264, 2306, 570, 51012], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 260, "seek": 129456, "start": 1307.52, "end": 1311.6799999999998, "text": " you're calculating the influence that each of these weights has on the error you adjust all", "tokens": [51012, 291, 434, 28258, 264, 6503, 300, 1184, 295, 613, 17443, 575, 322, 264, 6713, 291, 4369, 439, 51220], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 261, "seek": 129456, "start": 1311.6799999999998, "end": 1317.84, "text": " the ones that have the biggest impact and so the network will kind of try and find its way", "tokens": [51220, 264, 2306, 300, 362, 264, 3880, 2712, 293, 370, 264, 3209, 486, 733, 295, 853, 293, 915, 1080, 636, 51528], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 262, "seek": 129456, "start": 1317.84, "end": 1322.8, "text": " towards a good function you know and we use a process called stochastic gradient descent often", "tokens": [51528, 3030, 257, 665, 2445, 291, 458, 293, 321, 764, 257, 1399, 1219, 342, 8997, 2750, 16235, 23475, 2049, 51776], "temperature": 0.0, "avg_logprob": -0.05027138802313035, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.014050930738449097}, {"id": 263, "seek": 132280, "start": 1322.8, "end": 1327.2, "text": " to train this so what we're doing is we're picking random malwares and putting them in", "tokens": [50364, 281, 3847, 341, 370, 437, 321, 434, 884, 307, 321, 434, 8867, 4974, 2806, 4151, 495, 293, 3372, 552, 294, 50584], "temperature": 0.0, "avg_logprob": -0.059901031287940776, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.014676470309495926}, {"id": 264, "seek": 132280, "start": 1327.2, "end": 1331.2, "text": " and that will often it will often get them wrong right because it's never seen any of these things", "tokens": [50584, 293, 300, 486, 2049, 309, 486, 2049, 483, 552, 2085, 558, 570, 309, 311, 1128, 1612, 604, 295, 613, 721, 50784], "temperature": 0.0, "avg_logprob": -0.059901031287940776, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.014676470309495926}, {"id": 265, "seek": 132280, "start": 1331.2, "end": 1337.52, "text": " before and so over time maybe you just nudge it slightly in a better direction and then over many", "tokens": [50784, 949, 293, 370, 670, 565, 1310, 291, 445, 297, 16032, 309, 4748, 294, 257, 1101, 3513, 293, 550, 670, 867, 51100], "temperature": 0.0, "avg_logprob": -0.059901031287940776, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.014676470309495926}, {"id": 266, "seek": 132280, "start": 1337.52, "end": 1343.2, "text": " thousands of looks it slowly converges on something that actually makes reasonable decisions that's", "tokens": [51100, 5383, 295, 1542, 309, 5692, 9652, 2880, 322, 746, 300, 767, 1669, 10585, 5327, 300, 311, 51384], "temperature": 0.0, "avg_logprob": -0.059901031287940776, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.014676470309495926}, {"id": 267, "seek": 132280, "start": 1343.2, "end": 1348.24, "text": " you know that's the idea so it's a long process and is this what you would call supervised or is it", "tokens": [51384, 291, 458, 300, 311, 264, 1558, 370, 309, 311, 257, 938, 1399, 293, 307, 341, 437, 291, 576, 818, 46533, 420, 307, 309, 51636], "temperature": 0.0, "avg_logprob": -0.059901031287940776, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.014676470309495926}, {"id": 268, "seek": 134824, "start": 1348.96, "end": 1354.08, "text": " this is definitely supervised so supervised is where you have your your your label ground truth", "tokens": [50400, 341, 307, 2138, 46533, 370, 46533, 307, 689, 291, 362, 428, 428, 428, 7645, 2727, 3494, 50656], "temperature": 0.0, "avg_logprob": -0.07330972073124904, "compression_ratio": 1.9469387755102041, "no_speech_prob": 0.012181613594293594}, {"id": 269, "seek": 134824, "start": 1354.08, "end": 1358.16, "text": " what we was you know our we have labels for data so we're putting our data in we have some labels", "tokens": [50656, 437, 321, 390, 291, 458, 527, 321, 362, 16949, 337, 1412, 370, 321, 434, 3372, 527, 1412, 294, 321, 362, 512, 16949, 50860], "temperature": 0.0, "avg_logprob": -0.07330972073124904, "compression_ratio": 1.9469387755102041, "no_speech_prob": 0.012181613594293594}, {"id": 270, "seek": 134824, "start": 1358.16, "end": 1362.8, "text": " against which we can compare and that means that we have some idea of how right or wrong", "tokens": [50860, 1970, 597, 321, 393, 6794, 293, 300, 1355, 300, 321, 362, 512, 1558, 295, 577, 558, 420, 2085, 51092], "temperature": 0.0, "avg_logprob": -0.07330972073124904, "compression_ratio": 1.9469387755102041, "no_speech_prob": 0.012181613594293594}, {"id": 271, "seek": 134824, "start": 1362.8, "end": 1367.36, "text": " the network is in any given case right and that's very very useful and the majority despite what", "tokens": [51092, 264, 3209, 307, 294, 604, 2212, 1389, 558, 293, 300, 311, 588, 588, 4420, 293, 264, 6286, 7228, 437, 51320], "temperature": 0.0, "avg_logprob": -0.07330972073124904, "compression_ratio": 1.9469387755102041, "no_speech_prob": 0.012181613594293594}, {"id": 272, "seek": 134824, "start": 1367.36, "end": 1373.2, "text": " people might say the majority of deep learning or machine learning is supervised learning because", "tokens": [51320, 561, 1062, 584, 264, 6286, 295, 2452, 2539, 420, 3479, 2539, 307, 46533, 2539, 570, 51612], "temperature": 0.0, "avg_logprob": -0.07330972073124904, "compression_ratio": 1.9469387755102041, "no_speech_prob": 0.012181613594293594}, {"id": 273, "seek": 137320, "start": 1373.2, "end": 1379.92, "text": " it gets results the quickest if I want to detect some illness in MRI having examples of that illness", "tokens": [50364, 309, 2170, 3542, 264, 49403, 498, 286, 528, 281, 5531, 512, 10152, 294, 32812, 1419, 5110, 295, 300, 10152, 50700], "temperature": 0.0, "avg_logprob": -0.09905501299126204, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.02028004452586174}, {"id": 274, "seek": 137320, "start": 1380.56, "end": 1386.32, "text": " is going to be much much easier so Mike supervised learning if I understand it right is you giving", "tokens": [50732, 307, 516, 281, 312, 709, 709, 3571, 370, 6602, 46533, 2539, 498, 286, 1223, 309, 558, 307, 291, 2902, 51020], "temperature": 0.0, "avg_logprob": -0.09905501299126204, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.02028004452586174}, {"id": 275, "seek": 137320, "start": 1386.32, "end": 1393.6000000000001, "text": " it examples of like you said actual malware or actual like in your MRI scans problems yeah and", "tokens": [51020, 309, 5110, 295, 411, 291, 848, 3539, 40747, 420, 3539, 411, 294, 428, 32812, 35116, 2740, 1338, 293, 51384], "temperature": 0.0, "avg_logprob": -0.09905501299126204, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.02028004452586174}, {"id": 276, "seek": 137320, "start": 1393.6000000000001, "end": 1398.0800000000002, "text": " then you're supervising that it got it right and then you're correcting it yeah and it makes", "tokens": [51384, 550, 291, 434, 37971, 3436, 300, 309, 658, 309, 558, 293, 550, 291, 434, 47032, 309, 1338, 293, 309, 1669, 51608], "temperature": 0.0, "avg_logprob": -0.09905501299126204, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.02028004452586174}, {"id": 277, "seek": 139808, "start": 1398.08, "end": 1402.8, "text": " things much easier right so the majority of machine learning is supervised because it is", "tokens": [50364, 721, 709, 3571, 558, 370, 264, 6286, 295, 3479, 2539, 307, 46533, 570, 309, 307, 50600], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 278, "seek": 139808, "start": 1402.8, "end": 1406.96, "text": " simpler and easier to do if you work in applied areas like me where you're trying to get things to", "tokens": [50600, 18587, 293, 3571, 281, 360, 498, 291, 589, 294, 6456, 3179, 411, 385, 689, 291, 434, 1382, 281, 483, 721, 281, 50808], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 279, "seek": 139808, "start": 1406.96, "end": 1411.04, "text": " work really really well if you work in industry a lot of what you're trying to do is just minimize", "tokens": [50808, 589, 534, 534, 731, 498, 291, 589, 294, 3518, 257, 688, 295, 437, 291, 434, 1382, 281, 360, 307, 445, 17522, 51012], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 280, "seek": 139808, "start": 1411.04, "end": 1415.84, "text": " that error term you're trying to get as close to good predictions in for the majority of cases", "tokens": [51012, 300, 6713, 1433, 291, 434, 1382, 281, 483, 382, 1998, 281, 665, 21264, 294, 337, 264, 6286, 295, 3331, 51252], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 281, "seek": 139808, "start": 1415.84, "end": 1420.56, "text": " so getting some examples is going to get you to converge on that much much more quickly this is", "tokens": [51252, 370, 1242, 512, 5110, 307, 516, 281, 483, 291, 281, 41881, 322, 300, 709, 709, 544, 2661, 341, 307, 51488], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 282, "seek": 139808, "start": 1420.56, "end": 1424.6399999999999, "text": " you know distinct from something like weakly supervised or unsupervised learning and there's", "tokens": [51488, 291, 458, 10644, 490, 746, 411, 5336, 356, 46533, 420, 2693, 12879, 24420, 2539, 293, 456, 311, 51692], "temperature": 0.0, "avg_logprob": -0.04622595650809152, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.061254702508449554}, {"id": 283, "seek": 142464, "start": 1424.64, "end": 1428.88, "text": " lots of different variants so unsupervised learning is you don't have any labels right maybe", "tokens": [50364, 3195, 295, 819, 21669, 370, 2693, 12879, 24420, 2539, 307, 291, 500, 380, 362, 604, 16949, 558, 1310, 50576], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 284, "seek": 142464, "start": 1428.88, "end": 1435.1200000000001, "text": " the data is too big or the data is too hard to annotate or no one can agree on what the labels are", "tokens": [50576, 264, 1412, 307, 886, 955, 420, 264, 1412, 307, 886, 1152, 281, 25339, 473, 420, 572, 472, 393, 3986, 322, 437, 264, 16949, 366, 50888], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 285, "seek": 142464, "start": 1435.1200000000001, "end": 1439.2800000000002, "text": " and so the best you're going to be able to do is kind of partition the data into plausible groups", "tokens": [50888, 293, 370, 264, 1151, 291, 434, 516, 281, 312, 1075, 281, 360, 307, 733, 295, 24808, 264, 1412, 666, 39925, 3935, 51096], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 286, "seek": 142464, "start": 1439.92, "end": 1443.6000000000001, "text": " so you can say well look we don't know exactly what all these things are but we know that this", "tokens": [51128, 370, 291, 393, 584, 731, 574, 321, 500, 380, 458, 2293, 437, 439, 613, 721, 366, 457, 321, 458, 300, 341, 51312], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 287, "seek": 142464, "start": 1443.6000000000001, "end": 1447.76, "text": " group is distinct from this group and that's unsupervised so an example would be suppose", "tokens": [51312, 1594, 307, 10644, 490, 341, 1594, 293, 300, 311, 2693, 12879, 24420, 370, 364, 1365, 576, 312, 7297, 51520], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 288, "seek": 142464, "start": 1447.76, "end": 1452.5600000000002, "text": " suppose you work for an online shop and you have a load of data on what different customers have bought", "tokens": [51520, 7297, 291, 589, 337, 364, 2950, 3945, 293, 291, 362, 257, 3677, 295, 1412, 322, 437, 819, 4581, 362, 4243, 51760], "temperature": 0.0, "avg_logprob": -0.03597825765609741, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.012000647373497486}, {"id": 289, "seek": 145256, "start": 1453.2, "end": 1458.1599999999999, "text": " one thing you might do is start trying to group customers into some kind of plausible groups", "tokens": [50396, 472, 551, 291, 1062, 360, 307, 722, 1382, 281, 1594, 4581, 666, 512, 733, 295, 39925, 3935, 50644], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 290, "seek": 145256, "start": 1458.1599999999999, "end": 1461.44, "text": " based on roughly the things they they're not all going to have bought the exact same thing right", "tokens": [50644, 2361, 322, 9810, 264, 721, 436, 436, 434, 406, 439, 516, 281, 362, 4243, 264, 1900, 912, 551, 558, 50808], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 291, "seek": 145256, "start": 1461.44, "end": 1466.0, "text": " so it's not going to be trivial but they might have bought so someone's buying mostly dog related", "tokens": [50808, 370, 309, 311, 406, 516, 281, 312, 26703, 457, 436, 1062, 362, 4243, 370, 1580, 311, 6382, 5240, 3000, 4077, 51036], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 292, "seek": 145256, "start": 1466.0, "end": 1470.0, "text": " stuff and someone's buying mostly technical gadgets and then what you can do is say well look", "tokens": [51036, 1507, 293, 1580, 311, 6382, 5240, 6191, 37635, 293, 550, 437, 291, 393, 360, 307, 584, 731, 574, 51236], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 293, "seek": 145256, "start": 1470.0, "end": 1474.0, "text": " I put all these people in the tech group and this guy bought this really nice new microphone or", "tokens": [51236, 286, 829, 439, 613, 561, 294, 264, 7553, 1594, 293, 341, 2146, 4243, 341, 534, 1481, 777, 10952, 420, 51436], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 294, "seek": 145256, "start": 1474.0, "end": 1478.6399999999999, "text": " news camera so I'm going to recommend that now to other people in the group and maybe I get a few", "tokens": [51436, 2583, 2799, 370, 286, 478, 516, 281, 2748, 300, 586, 281, 661, 561, 294, 264, 1594, 293, 1310, 286, 483, 257, 1326, 51668], "temperature": 0.0, "avg_logprob": -0.06858687437781992, "compression_ratio": 1.9491525423728813, "no_speech_prob": 0.005206361413002014}, {"id": 295, "seek": 147864, "start": 1478.64, "end": 1483.76, "text": " hits and I and I sell a few cameras that way um you can get much more complicatedness but that is", "tokens": [50364, 8664, 293, 286, 293, 286, 3607, 257, 1326, 8622, 300, 636, 1105, 291, 393, 483, 709, 544, 6179, 1287, 457, 300, 307, 50620], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 296, "seek": 147864, "start": 1483.76, "end": 1489.2800000000002, "text": " an example of perhaps unsupervised learning where you don't need to have some kind of label", "tokens": [50620, 364, 1365, 295, 4317, 2693, 12879, 24420, 2539, 689, 291, 500, 380, 643, 281, 362, 512, 733, 295, 7645, 50896], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 297, "seek": 147864, "start": 1489.2800000000002, "end": 1493.0400000000002, "text": " for everyone you don't need to have labeled me ahead of time as a tech enthusiast you just need", "tokens": [50896, 337, 1518, 291, 500, 380, 643, 281, 362, 21335, 385, 2286, 295, 565, 382, 257, 7553, 18076, 525, 291, 445, 643, 51084], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 298, "seek": 147864, "start": 1493.0400000000002, "end": 1497.44, "text": " to look at the stuff I've been buying I know it's the same as always other people and know", "tokens": [51084, 281, 574, 412, 264, 1507, 286, 600, 668, 6382, 286, 458, 309, 311, 264, 912, 382, 1009, 661, 561, 293, 458, 51304], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 299, "seek": 147864, "start": 1497.44, "end": 1501.68, "text": " that that's interesting right rather than we know exactly what it means that's a great example so in", "tokens": [51304, 300, 300, 311, 1880, 558, 2831, 813, 321, 458, 2293, 437, 309, 1355, 300, 311, 257, 869, 1365, 370, 294, 51516], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 300, "seek": 147864, "start": 1501.68, "end": 1508.0800000000002, "text": " other words you didn't tell the machine who the people were it discovered that based on the", "tokens": [51516, 661, 2283, 291, 994, 380, 980, 264, 3479, 567, 264, 561, 645, 309, 6941, 300, 2361, 322, 264, 51836], "temperature": 0.0, "avg_logprob": -0.06708093572545934, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.021882422268390656}, {"id": 301, "seek": 150808, "start": 1508.1599999999999, "end": 1512.3999999999999, "text": " patterns of data right yeah and it didn't really even discover who they were it mostly just grouped", "tokens": [50368, 8294, 295, 1412, 558, 1338, 293, 309, 994, 380, 534, 754, 4411, 567, 436, 645, 309, 5240, 445, 41877, 50580], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 302, "seek": 150808, "start": 1512.3999999999999, "end": 1516.8, "text": " them and that allowed us to make decisions based on the fact they were grouped now as that happens", "tokens": [50580, 552, 293, 300, 4350, 505, 281, 652, 5327, 2361, 322, 264, 1186, 436, 645, 41877, 586, 382, 300, 2314, 50800], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 303, "seek": 150808, "start": 1516.8, "end": 1521.52, "text": " I've given this group a label of tech enthusiasts but of course you don't need to even know that", "tokens": [50800, 286, 600, 2212, 341, 1594, 257, 7645, 295, 7553, 45873, 457, 295, 1164, 291, 500, 380, 643, 281, 754, 458, 300, 51036], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 304, "seek": 150808, "start": 1521.52, "end": 1525.6, "text": " you just need to know but on average they buy more TVs than everyone else so maybe send them", "tokens": [51036, 291, 445, 643, 281, 458, 457, 322, 4274, 436, 2256, 544, 38085, 813, 1518, 1646, 370, 1310, 2845, 552, 51240], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 305, "seek": 150808, "start": 1525.6, "end": 1530.56, "text": " emails about TVs you know it's that kind of idea you can still do supervised learning and other", "tokens": [51240, 12524, 466, 38085, 291, 458, 309, 311, 300, 733, 295, 1558, 291, 393, 920, 360, 46533, 2539, 293, 661, 51488], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 306, "seek": 150808, "start": 1530.56, "end": 1535.1999999999998, "text": " forms of learning with stuff like marketing and and recommender systems and things but you might", "tokens": [51488, 6422, 295, 2539, 365, 1507, 411, 6370, 293, 293, 2748, 260, 3652, 293, 721, 457, 291, 1062, 51720], "temperature": 0.0, "avg_logprob": -0.05760547146201134, "compression_ratio": 1.809968847352025, "no_speech_prob": 0.004064504988491535}, {"id": 307, "seek": 153520, "start": 1535.2, "end": 1540.4, "text": " imagine that that could be one way you would do it and I think it's a good example the problem I see", "tokens": [50364, 3811, 300, 300, 727, 312, 472, 636, 291, 576, 360, 309, 293, 286, 519, 309, 311, 257, 665, 1365, 264, 1154, 286, 536, 50624], "temperature": 0.0, "avg_logprob": -0.06455777309559009, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.021919043734669685}, {"id": 308, "seek": 153520, "start": 1540.4, "end": 1545.8400000000001, "text": " like from listening to you is reality versus the movies or reality versus the news cycle", "tokens": [50624, 411, 490, 4764, 281, 291, 307, 4103, 5717, 264, 6233, 420, 4103, 5717, 264, 2583, 6586, 50896], "temperature": 0.0, "avg_logprob": -0.06455777309559009, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.021919043734669685}, {"id": 309, "seek": 153520, "start": 1545.8400000000001, "end": 1552.48, "text": " because you always hear about google doing like um like teaching a machine to play chess or whatever", "tokens": [50896, 570, 291, 1009, 1568, 466, 20742, 884, 411, 1105, 411, 4571, 257, 3479, 281, 862, 24122, 420, 2035, 51228], "temperature": 0.0, "avg_logprob": -0.06455777309559009, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.021919043734669685}, {"id": 310, "seek": 153520, "start": 1552.48, "end": 1558.8, "text": " the games are and it just like magically gets this done um and it teaches itself kind of like not", "tokens": [51228, 264, 2813, 366, 293, 309, 445, 411, 39763, 2170, 341, 1096, 1105, 293, 309, 16876, 2564, 733, 295, 411, 406, 51544], "temperature": 0.0, "avg_logprob": -0.06455777309559009, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.021919043734669685}, {"id": 311, "seek": 153520, "start": 1558.8, "end": 1563.2, "text": " even knowing what the the rules of the game are so that is a that's something called reinforcement", "tokens": [51544, 754, 5276, 437, 264, 264, 4474, 295, 264, 1216, 366, 370, 300, 307, 257, 300, 311, 746, 1219, 29280, 51764], "temperature": 0.0, "avg_logprob": -0.06455777309559009, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.021919043734669685}, {"id": 312, "seek": 156320, "start": 1563.2, "end": 1568.48, "text": " learning a lot of the time reinforcement learning is still supervised learning okay it's just that", "tokens": [50364, 2539, 257, 688, 295, 264, 565, 29280, 2539, 307, 920, 46533, 2539, 1392, 309, 311, 445, 300, 50628], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 313, "seek": 156320, "start": 1568.48, "end": 1574.0800000000002, "text": " you get the labels as you go from playing the game so the way it works is you know what you might do", "tokens": [50628, 291, 483, 264, 16949, 382, 291, 352, 490, 2433, 264, 1216, 370, 264, 636, 309, 1985, 307, 291, 458, 437, 291, 1062, 360, 50908], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 314, "seek": 156320, "start": 1574.0800000000002, "end": 1578.88, "text": " is you play a random game of chess where you literally move at random right and you lose", "tokens": [50908, 307, 291, 862, 257, 4974, 1216, 295, 24122, 689, 291, 3736, 1286, 412, 4974, 558, 293, 291, 3624, 51148], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 315, "seek": 156320, "start": 1578.88, "end": 1583.44, "text": " and so you get a strong suggestion that maybe next time don't do that like that was stupid", "tokens": [51148, 293, 370, 291, 483, 257, 2068, 16541, 300, 1310, 958, 565, 500, 380, 360, 300, 411, 300, 390, 6631, 51376], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 316, "seek": 156320, "start": 1583.44, "end": 1587.8400000000001, "text": " so now you move slightly less at random than you did before but it's still pretty bad", "tokens": [51376, 370, 586, 291, 1286, 4748, 1570, 412, 4974, 813, 291, 630, 949, 457, 309, 311, 920, 1238, 1578, 51596], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 317, "seek": 156320, "start": 1587.8400000000001, "end": 1591.76, "text": " and you lose again but you know learn a bit and this is basically how they train it so what you", "tokens": [51596, 293, 291, 3624, 797, 457, 291, 458, 1466, 257, 857, 293, 341, 307, 1936, 577, 436, 3847, 309, 370, 437, 291, 51792], "temperature": 0.0, "avg_logprob": -0.0426086242382343, "compression_ratio": 1.9615384615384615, "no_speech_prob": 0.05480658635497093}, {"id": 318, "seek": 159176, "start": 1591.76, "end": 1596.32, "text": " do is you play millions and millions and millions of games of chess and every time it goes well", "tokens": [50364, 360, 307, 291, 862, 6803, 293, 6803, 293, 6803, 295, 2813, 295, 24122, 293, 633, 565, 309, 1709, 731, 50592], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 319, "seek": 159176, "start": 1596.96, "end": 1601.44, "text": " you just learn a little something about what was better than that time than what's the time before", "tokens": [50624, 291, 445, 1466, 257, 707, 746, 466, 437, 390, 1101, 813, 300, 565, 813, 437, 311, 264, 565, 949, 50848], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 320, "seek": 159176, "start": 1601.44, "end": 1605.6, "text": " we're still talking about a network which is a big mathematical function right so we're still", "tokens": [50848, 321, 434, 920, 1417, 466, 257, 3209, 597, 307, 257, 955, 18894, 2445, 558, 370, 321, 434, 920, 51056], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 321, "seek": 159176, "start": 1605.6, "end": 1610.56, "text": " talking about something that has weights that you adjust so that when you put an input state in", "tokens": [51056, 1417, 466, 746, 300, 575, 17443, 300, 291, 4369, 370, 300, 562, 291, 829, 364, 4846, 1785, 294, 51304], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 322, "seek": 159176, "start": 1610.56, "end": 1615.36, "text": " you get the best desirable output state which in this case of course is you won more often than you", "tokens": [51304, 291, 483, 264, 1151, 30533, 5598, 1785, 597, 294, 341, 1389, 295, 1164, 307, 291, 1582, 544, 2049, 813, 291, 51544], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 323, "seek": 159176, "start": 1615.36, "end": 1620.16, "text": " didn't for me I mean these are fascinating because they're trained in a very different way to the", "tokens": [51544, 994, 380, 337, 385, 286, 914, 613, 366, 10343, 570, 436, 434, 8895, 294, 257, 588, 819, 636, 281, 264, 51784], "temperature": 0.0, "avg_logprob": -0.04997272044420242, "compression_ratio": 1.9530201342281879, "no_speech_prob": 0.006088806316256523}, {"id": 324, "seek": 162016, "start": 1620.24, "end": 1624.8000000000002, "text": " way I would train the network I come up with labeled data and I put it in like and I use the", "tokens": [50368, 636, 286, 576, 3847, 264, 3209, 286, 808, 493, 365, 21335, 1412, 293, 286, 829, 309, 294, 411, 293, 286, 764, 264, 50596], "temperature": 0.0, "avg_logprob": -0.054847219534087596, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.015106781385838985}, {"id": 325, "seek": 162016, "start": 1624.8000000000002, "end": 1630.0, "text": " examples with reinforcement learning you have to start trying to give it rewards which is where it", "tokens": [50596, 5110, 365, 29280, 2539, 291, 362, 281, 722, 1382, 281, 976, 309, 17203, 597, 307, 689, 309, 50856], "temperature": 0.0, "avg_logprob": -0.054847219534087596, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.015106781385838985}, {"id": 326, "seek": 162016, "start": 1630.0, "end": 1637.44, "text": " gets its labeled data from so is it is it is it is it better that you go 25 moves in chess before", "tokens": [50856, 2170, 1080, 21335, 1412, 490, 370, 307, 309, 307, 309, 307, 309, 307, 309, 1101, 300, 291, 352, 3552, 6067, 294, 24122, 949, 51228], "temperature": 0.0, "avg_logprob": -0.054847219534087596, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.015106781385838985}, {"id": 327, "seek": 162016, "start": 1637.44, "end": 1641.6000000000001, "text": " you lose or is it better that you checkmate regardless of how long it takes right you know", "tokens": [51228, 291, 3624, 420, 307, 309, 1101, 300, 291, 1520, 13963, 10060, 295, 577, 938, 309, 2516, 558, 291, 458, 51436], "temperature": 0.0, "avg_logprob": -0.054847219534087596, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.015106781385838985}, {"id": 328, "seek": 162016, "start": 1641.6000000000001, "end": 1646.88, "text": " because you might end up in a stalemate you know there's things with playing chess where you might", "tokens": [51436, 570, 291, 1062, 917, 493, 294, 257, 49875, 443, 473, 291, 458, 456, 311, 721, 365, 2433, 24122, 689, 291, 1062, 51700], "temperature": 0.0, "avg_logprob": -0.054847219534087596, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.015106781385838985}, {"id": 329, "seek": 164688, "start": 1646.88, "end": 1650.4, "text": " say well look these other goals are also important or something like this and so you can spend a lot", "tokens": [50364, 584, 731, 574, 613, 661, 5493, 366, 611, 1021, 420, 746, 411, 341, 293, 370, 291, 393, 3496, 257, 688, 50540], "temperature": 0.0, "avg_logprob": -0.07778606591401277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.021496176719665527}, {"id": 330, "seek": 164688, "start": 1650.4, "end": 1654.8000000000002, "text": " of time thinking about different ways you could train the network which I think I think is really", "tokens": [50540, 295, 565, 1953, 466, 819, 2098, 291, 727, 3847, 264, 3209, 597, 286, 519, 286, 519, 307, 534, 50760], "temperature": 0.0, "avg_logprob": -0.07778606591401277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.021496176719665527}, {"id": 331, "seek": 164688, "start": 1654.8000000000002, "end": 1661.0400000000002, "text": " interesting perhaps I'm misinterpreting it but it sounds like the hype cycle versus reality", "tokens": [50760, 1880, 4317, 286, 478, 3346, 5106, 3712, 783, 309, 457, 309, 3263, 411, 264, 24144, 6586, 5717, 4103, 51072], "temperature": 0.0, "avg_logprob": -0.07778606591401277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.021496176719665527}, {"id": 332, "seek": 164688, "start": 1661.0400000000002, "end": 1667.0400000000002, "text": " there's a big disconnect like the people have this vision that the robots are going to take over", "tokens": [51072, 456, 311, 257, 955, 14299, 411, 264, 561, 362, 341, 5201, 300, 264, 14733, 366, 516, 281, 747, 670, 51372], "temperature": 0.0, "avg_logprob": -0.07778606591401277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.021496176719665527}, {"id": 333, "seek": 164688, "start": 1667.0400000000002, "end": 1671.5200000000002, "text": " but you don't think that's going to happen like anytime soon right yeah I mean I well the funny", "tokens": [51372, 457, 291, 500, 380, 519, 300, 311, 516, 281, 1051, 411, 13038, 2321, 558, 1338, 286, 914, 286, 731, 264, 4074, 51596], "temperature": 0.0, "avg_logprob": -0.07778606591401277, "compression_ratio": 1.7822878228782288, "no_speech_prob": 0.021496176719665527}, {"id": 334, "seek": 167152, "start": 1671.52, "end": 1676.8, "text": " thing is like I did a lecture once where where I said to everyone you know the char one hash function", "tokens": [50364, 551, 307, 411, 286, 630, 257, 7991, 1564, 689, 689, 286, 848, 281, 1518, 291, 458, 264, 1290, 472, 22019, 2445, 50628], "temperature": 0.0, "avg_logprob": -0.1048984198734678, "compression_ratio": 2.062761506276151, "no_speech_prob": 0.1492525190114975}, {"id": 335, "seek": 167152, "start": 1676.8, "end": 1683.36, "text": " is absolutely fine right and then the next the next day yeah google released their their two pdfs", "tokens": [50628, 307, 3122, 2489, 558, 293, 550, 264, 958, 264, 958, 786, 1338, 20742, 4736, 641, 641, 732, 280, 67, 16883, 50956], "temperature": 0.0, "avg_logprob": -0.1048984198734678, "compression_ratio": 2.062761506276151, "no_speech_prob": 0.1492525190114975}, {"id": 336, "seek": 167152, "start": 1683.36, "end": 1687.52, "text": " that had the same char one hash right now that's embarrassing when that happens as a lecturer you", "tokens": [50956, 300, 632, 264, 912, 1290, 472, 22019, 558, 586, 300, 311, 17299, 562, 300, 2314, 382, 257, 49881, 291, 51164], "temperature": 0.0, "avg_logprob": -0.1048984198734678, "compression_ratio": 2.062761506276151, "no_speech_prob": 0.1492525190114975}, {"id": 337, "seek": 167152, "start": 1687.52, "end": 1692.24, "text": " know um so you know I don't want to say you know I don't want to say it could never happen what I", "tokens": [51164, 458, 1105, 370, 291, 458, 286, 500, 380, 528, 281, 584, 291, 458, 286, 500, 380, 528, 281, 584, 309, 727, 1128, 1051, 437, 286, 51400], "temperature": 0.0, "avg_logprob": -0.1048984198734678, "compression_ratio": 2.062761506276151, "no_speech_prob": 0.1492525190114975}, {"id": 338, "seek": 167152, "start": 1692.24, "end": 1695.84, "text": " would say is that the something that's really really good at go or something that's really really", "tokens": [51400, 576, 584, 307, 300, 264, 746, 300, 311, 534, 534, 665, 412, 352, 420, 746, 300, 311, 534, 534, 51580], "temperature": 0.0, "avg_logprob": -0.1048984198734678, "compression_ratio": 2.062761506276151, "no_speech_prob": 0.1492525190114975}, {"id": 339, "seek": 169584, "start": 1695.84, "end": 1703.04, "text": " good at chess is really really good at chess and that is it right it will do nothing else right", "tokens": [50364, 665, 412, 24122, 307, 534, 534, 665, 412, 24122, 293, 300, 307, 309, 558, 309, 486, 360, 1825, 1646, 558, 50724], "temperature": 0.0, "avg_logprob": -0.1474415718972146, "compression_ratio": 1.825925925925926, "no_speech_prob": 0.08234653621912003}, {"id": 340, "seek": 169584, "start": 1703.04, "end": 1708.8, "text": " as far as I can tell human chess players are also good at other things and we we don't have that", "tokens": [50724, 382, 1400, 382, 286, 393, 980, 1952, 24122, 4150, 366, 611, 665, 412, 661, 721, 293, 321, 321, 500, 380, 362, 300, 51012], "temperature": 0.0, "avg_logprob": -0.1474415718972146, "compression_ratio": 1.825925925925926, "no_speech_prob": 0.08234653621912003}, {"id": 341, "seek": 169584, "start": 1708.8, "end": 1716.6399999999999, "text": " generalizability yet is this the age the difference between like specialized knowledge and yeah I mean", "tokens": [51012, 2674, 590, 2310, 1939, 307, 341, 264, 3205, 264, 2649, 1296, 411, 19813, 3601, 293, 1338, 286, 914, 51404], "temperature": 0.0, "avg_logprob": -0.1474415718972146, "compression_ratio": 1.825925925925926, "no_speech_prob": 0.08234653621912003}, {"id": 342, "seek": 169584, "start": 1716.6399999999999, "end": 1720.56, "text": " again we could get bought we could get bogged down and what what the definition means but I think", "tokens": [51404, 797, 321, 727, 483, 4243, 321, 727, 483, 26132, 3004, 760, 293, 437, 437, 264, 7123, 1355, 457, 286, 519, 51600], "temperature": 0.0, "avg_logprob": -0.1474415718972146, "compression_ratio": 1.825925925925926, "no_speech_prob": 0.08234653621912003}, {"id": 343, "seek": 169584, "start": 1720.56, "end": 1725.12, "text": " that our official general's urgency to most people watching is just something that kind of is a bit", "tokens": [51600, 300, 527, 4783, 2674, 311, 29734, 281, 881, 561, 1976, 307, 445, 746, 300, 733, 295, 307, 257, 857, 51828], "temperature": 0.0, "avg_logprob": -0.1474415718972146, "compression_ratio": 1.825925925925926, "no_speech_prob": 0.08234653621912003}, {"id": 344, "seek": 172512, "start": 1725.12, "end": 1731.04, "text": " like a human right and certainly is very very general so you could say right this now is a totally", "tokens": [50364, 411, 257, 1952, 558, 293, 3297, 307, 588, 588, 2674, 370, 291, 727, 584, 558, 341, 586, 307, 257, 3879, 50660], "temperature": 0.0, "avg_logprob": -0.05750205413154934, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.013172789476811886}, {"id": 345, "seek": 172512, "start": 1731.04, "end": 1734.56, "text": " different game learn to play it and it will go off and play it and it would still remember how to", "tokens": [50660, 819, 1216, 1466, 281, 862, 309, 293, 309, 486, 352, 766, 293, 862, 309, 293, 309, 576, 920, 1604, 577, 281, 50836], "temperature": 0.0, "avg_logprob": -0.05750205413154934, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.013172789476811886}, {"id": 346, "seek": 172512, "start": 1734.56, "end": 1738.56, "text": " play chess and it could play all the games you know and it's just super it's super impressive", "tokens": [50836, 862, 24122, 293, 309, 727, 862, 439, 264, 2813, 291, 458, 293, 309, 311, 445, 1687, 309, 311, 1687, 8992, 51036], "temperature": 0.0, "avg_logprob": -0.05750205413154934, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.013172789476811886}, {"id": 347, "seek": 172512, "start": 1738.56, "end": 1744.08, "text": " though that doesn't exist will it exist I don't know I mean I think that if we keep making these", "tokens": [51036, 1673, 300, 1177, 380, 2514, 486, 309, 2514, 286, 500, 380, 458, 286, 914, 286, 519, 300, 498, 321, 1066, 1455, 613, 51312], "temperature": 0.0, "avg_logprob": -0.05750205413154934, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.013172789476811886}, {"id": 348, "seek": 172512, "start": 1744.08, "end": 1750.0, "text": " models bigger we'll probably get to a point within a few decades where they are very impressive at a", "tokens": [51312, 5245, 3801, 321, 603, 1391, 483, 281, 257, 935, 1951, 257, 1326, 7878, 689, 436, 366, 588, 8992, 412, 257, 51608], "temperature": 0.0, "avg_logprob": -0.05750205413154934, "compression_ratio": 1.8277153558052435, "no_speech_prob": 0.013172789476811886}, {"id": 349, "seek": 175000, "start": 1750.0, "end": 1756.32, "text": " lot of different tasks but I still am not convinced yet that we've got any real strategy to get past", "tokens": [50364, 688, 295, 819, 9608, 457, 286, 920, 669, 406, 12561, 1939, 300, 321, 600, 658, 604, 957, 5206, 281, 483, 1791, 50680], "temperature": 0.0, "avg_logprob": -0.06267785217802403, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.15575186908245087}, {"id": 350, "seek": 175000, "start": 1756.32, "end": 1760.8, "text": " the idea of just you need to like have a load of data right or a load of play a load of games", "tokens": [50680, 264, 1558, 295, 445, 291, 643, 281, 411, 362, 257, 3677, 295, 1412, 558, 420, 257, 3677, 295, 862, 257, 3677, 295, 2813, 50904], "temperature": 0.0, "avg_logprob": -0.06267785217802403, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.15575186908245087}, {"id": 351, "seek": 175000, "start": 1760.8, "end": 1767.28, "text": " my daughter can have a go at playing a semi-coherent game of chess just having been told the rules of", "tokens": [50904, 452, 4653, 393, 362, 257, 352, 412, 2433, 257, 12909, 12, 1291, 511, 317, 1216, 295, 24122, 445, 1419, 668, 1907, 264, 4474, 295, 51228], "temperature": 0.0, "avg_logprob": -0.06267785217802403, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.15575186908245087}, {"id": 352, "seek": 175000, "start": 1767.28, "end": 1771.28, "text": " chess and she didn't you know let's say she's not winning any competitions right not yet", "tokens": [51228, 24122, 293, 750, 994, 380, 291, 458, 718, 311, 584, 750, 311, 406, 8224, 604, 26185, 558, 406, 1939, 51428], "temperature": 0.0, "avg_logprob": -0.06267785217802403, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.15575186908245087}, {"id": 353, "seek": 175000, "start": 1771.28, "end": 1774.96, "text": " but she didn't need to play a million games against herself to work out what to do right", "tokens": [51428, 457, 750, 994, 380, 643, 281, 862, 257, 2459, 2813, 1970, 7530, 281, 589, 484, 437, 281, 360, 558, 51612], "temperature": 0.0, "avg_logprob": -0.06267785217802403, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.15575186908245087}, {"id": 354, "seek": 177496, "start": 1774.96, "end": 1780.8, "text": " there's something that she is doing but is much much more impressive than what this AI is doing", "tokens": [50364, 456, 311, 746, 300, 750, 307, 884, 457, 307, 709, 709, 544, 8992, 813, 437, 341, 7318, 307, 884, 50656], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 355, "seek": 177496, "start": 1780.8, "end": 1784.8, "text": " that isn't to say the AI isn't incredibly impressive it's just very different I do think", "tokens": [50656, 300, 1943, 380, 281, 584, 264, 7318, 1943, 380, 6252, 8992, 309, 311, 445, 588, 819, 286, 360, 519, 50856], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 356, "seek": 177496, "start": 1784.8, "end": 1789.2, "text": " that the hype cycle is very different to what we actually see on the ground which is that basically", "tokens": [50856, 300, 264, 24144, 6586, 307, 588, 819, 281, 437, 321, 767, 536, 322, 264, 2727, 597, 307, 300, 1936, 51076], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 357, "seek": 177496, "start": 1789.2, "end": 1794.72, "text": " a lot of the time I mean you know aside from playing games and reinforcement learning and large", "tokens": [51076, 257, 688, 295, 264, 565, 286, 914, 291, 458, 7359, 490, 2433, 2813, 293, 29280, 2539, 293, 2416, 51352], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 358, "seek": 177496, "start": 1794.72, "end": 1799.52, "text": " language models the majority of what people are doing is trying to find objects segment images", "tokens": [51352, 2856, 5245, 264, 6286, 295, 437, 561, 366, 884, 307, 1382, 281, 915, 6565, 9469, 5267, 51592], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 359, "seek": 177496, "start": 1800.24, "end": 1804.72, "text": " and these things are mostly done in a supervised way and they don't generalize but we don't", "tokens": [51628, 293, 613, 721, 366, 5240, 1096, 294, 257, 46533, 636, 293, 436, 500, 380, 2674, 1125, 457, 321, 500, 380, 51852], "temperature": 0.0, "avg_logprob": -0.0566456413269043, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.07898063957691193}, {"id": 360, "seek": 180472, "start": 1804.72, "end": 1808.56, "text": " care because we were trying to find those specific objects so that's good and if we need them to do", "tokens": [50364, 1127, 570, 321, 645, 1382, 281, 915, 729, 2685, 6565, 370, 300, 311, 665, 293, 498, 321, 643, 552, 281, 360, 50556], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 361, "seek": 180472, "start": 1808.56, "end": 1812.08, "text": " something else we'll retrain them to do something else yeah because my next question I think you've", "tokens": [50556, 746, 1646, 321, 603, 1533, 7146, 552, 281, 360, 746, 1646, 1338, 570, 452, 958, 1168, 286, 519, 291, 600, 50732], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 362, "seek": 180472, "start": 1812.08, "end": 1816.4, "text": " you've already given us the answer and maybe you can just elaborate is what is AI really good at", "tokens": [50732, 291, 600, 1217, 2212, 505, 264, 1867, 293, 1310, 291, 393, 445, 20945, 307, 437, 307, 7318, 534, 665, 412, 50948], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 363, "seek": 180472, "start": 1816.4, "end": 1822.24, "text": " compared and you know it just seems like it's like automation automation has its place but you still", "tokens": [50948, 5347, 293, 291, 458, 309, 445, 2544, 411, 309, 311, 411, 17769, 17769, 575, 1080, 1081, 457, 291, 920, 51240], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 364, "seek": 180472, "start": 1822.24, "end": 1826.72, "text": " it takes like it's just correct me if I'm wrong but it seems to take away like low level tasks that", "tokens": [51240, 309, 2516, 411, 309, 311, 445, 3006, 385, 498, 286, 478, 2085, 457, 309, 2544, 281, 747, 1314, 411, 2295, 1496, 9608, 300, 51464], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 365, "seek": 180472, "start": 1826.72, "end": 1830.88, "text": " are boring and monotonous or difficult for a human to do and then humans can concentrate on other", "tokens": [51464, 366, 9989, 293, 1108, 27794, 563, 420, 2252, 337, 257, 1952, 281, 360, 293, 550, 6255, 393, 18089, 322, 661, 51672], "temperature": 0.0, "avg_logprob": -0.08211861909741033, "compression_ratio": 1.8478260869565217, "no_speech_prob": 0.003058294765651226}, {"id": 366, "seek": 183088, "start": 1830.88, "end": 1837.0400000000002, "text": " things yeah what is AI really good at and where do you see it going yeah so AI is that automation", "tokens": [50364, 721, 1338, 437, 307, 7318, 534, 665, 412, 293, 689, 360, 291, 536, 309, 516, 1338, 370, 7318, 307, 300, 17769, 50672], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 367, "seek": 183088, "start": 1837.0400000000002, "end": 1841.2, "text": " is exactly what you what what you write on but with the caveat that you've got to have found a good", "tokens": [50672, 307, 2293, 437, 291, 437, 437, 291, 2464, 322, 457, 365, 264, 43012, 300, 291, 600, 658, 281, 362, 1352, 257, 665, 50880], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 368, "seek": 183088, "start": 1841.2, "end": 1845.8400000000001, "text": " way to train it to automate it won't just automate stuff you can't just stick it on a on a on a", "tokens": [50880, 636, 281, 3847, 309, 281, 31605, 309, 1582, 380, 445, 31605, 1507, 291, 393, 380, 445, 2897, 309, 322, 257, 322, 257, 322, 257, 51112], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 369, "seek": 183088, "start": 1845.8400000000001, "end": 1850.72, "text": " production line and say automate that for me because it did we won't know what to do so yeah", "tokens": [51112, 4265, 1622, 293, 584, 31605, 300, 337, 385, 570, 309, 630, 321, 1582, 380, 458, 437, 281, 360, 370, 1338, 51356], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 370, "seek": 183088, "start": 1850.72, "end": 1855.44, "text": " from my point of view what AI is really good at is so before I worked in you know at machine", "tokens": [51356, 490, 452, 935, 295, 1910, 437, 7318, 307, 534, 665, 412, 307, 370, 949, 286, 2732, 294, 291, 458, 412, 3479, 51592], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 371, "seek": 183088, "start": 1855.44, "end": 1859.5200000000002, "text": " learning and deep learning this was a normal computer vision researcher right and so I was", "tokens": [51592, 2539, 293, 2452, 2539, 341, 390, 257, 2710, 3820, 5201, 21751, 558, 293, 370, 286, 390, 51796], "temperature": 0.0, "avg_logprob": -0.0708719267361406, "compression_ratio": 1.893687707641196, "no_speech_prob": 0.013113848865032196}, {"id": 372, "seek": 185952, "start": 1859.6, "end": 1864.32, "text": " you know this is like you know early 2010 something like this time before I mean literally deep", "tokens": [50368, 291, 458, 341, 307, 411, 291, 458, 2440, 9657, 746, 411, 341, 565, 949, 286, 914, 3736, 2452, 50604], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 373, "seek": 185952, "start": 1864.32, "end": 1869.76, "text": " learning appeared in about 2014 and before that we didn't have it right there were some networks", "tokens": [50604, 2539, 8516, 294, 466, 8227, 293, 949, 300, 321, 994, 380, 362, 309, 558, 456, 645, 512, 9590, 50876], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 374, "seek": 185952, "start": 1869.76, "end": 1873.52, "text": " but no one was really paying attention to them and everyone was just doing normal stuff right and", "tokens": [50876, 457, 572, 472, 390, 534, 6229, 3202, 281, 552, 293, 1518, 390, 445, 884, 2710, 1507, 558, 293, 51064], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 375, "seek": 185952, "start": 1873.52, "end": 1877.68, "text": " what I would describe as image processing so if I wanted to find something in an image what I would", "tokens": [51064, 437, 286, 576, 6786, 382, 3256, 9007, 370, 498, 286, 1415, 281, 915, 746, 294, 364, 3256, 437, 286, 576, 51272], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 376, "seek": 185952, "start": 1877.68, "end": 1883.2, "text": " be trying to do is come up with rules in my head about what I needed to do to that image to find", "tokens": [51272, 312, 1382, 281, 360, 307, 808, 493, 365, 4474, 294, 452, 1378, 466, 437, 286, 2978, 281, 360, 281, 300, 3256, 281, 915, 51548], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 377, "seek": 185952, "start": 1883.2, "end": 1887.44, "text": " those objects and then I would implement those rules and code so I'd say okay first of all go", "tokens": [51548, 729, 6565, 293, 550, 286, 576, 4445, 729, 4474, 293, 3089, 370, 286, 1116, 584, 1392, 700, 295, 439, 352, 51760], "temperature": 0.0, "avg_logprob": -0.08193070651920698, "compression_ratio": 1.832807570977918, "no_speech_prob": 0.029246600344777107}, {"id": 378, "seek": 188744, "start": 1887.52, "end": 1891.28, "text": " like we're trying to find you know something in MRI so first find all the bright pixels", "tokens": [50368, 411, 321, 434, 1382, 281, 915, 291, 458, 746, 294, 32812, 370, 700, 915, 439, 264, 4730, 18668, 50556], "temperature": 0.0, "avg_logprob": -0.05705996496336801, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.006381500046700239}, {"id": 379, "seek": 188744, "start": 1891.28, "end": 1897.3600000000001, "text": " now find all the bright pixels but form a continuous blob that's of this size you know and I start", "tokens": [50556, 586, 915, 439, 264, 4730, 18668, 457, 1254, 257, 10957, 46115, 300, 311, 295, 341, 2744, 291, 458, 293, 286, 722, 50860], "temperature": 0.0, "avg_logprob": -0.05705996496336801, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.006381500046700239}, {"id": 380, "seek": 188744, "start": 1897.3600000000001, "end": 1903.76, "text": " and I try and design an algorithm to find whatever it was I was finding through these if statements", "tokens": [50860, 293, 286, 853, 293, 1715, 364, 9284, 281, 915, 2035, 309, 390, 286, 390, 5006, 807, 613, 498, 12363, 51180], "temperature": 0.0, "avg_logprob": -0.05705996496336801, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.006381500046700239}, {"id": 381, "seek": 188744, "start": 1903.76, "end": 1908.16, "text": " and rules right it's just code and what machine learning lets me do is not worry about the the", "tokens": [51180, 293, 4474, 558, 309, 311, 445, 3089, 293, 437, 3479, 2539, 6653, 385, 360, 307, 406, 3292, 466, 264, 264, 51400], "temperature": 0.0, "avg_logprob": -0.05705996496336801, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.006381500046700239}, {"id": 382, "seek": 188744, "start": 1908.16, "end": 1912.56, "text": " rules because the problem you have if you do if you do it by just coding is you get stuck in edge", "tokens": [51400, 4474, 570, 264, 1154, 291, 362, 498, 291, 360, 498, 291, 360, 309, 538, 445, 17720, 307, 291, 483, 5541, 294, 4691, 51620], "temperature": 0.0, "avg_logprob": -0.05705996496336801, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.006381500046700239}, {"id": 383, "seek": 191256, "start": 1912.56, "end": 1918.8799999999999, "text": " cases you get stuck on the you know you solve 90% of the issues pretty quickly because 90%", "tokens": [50364, 3331, 291, 483, 5541, 322, 264, 291, 458, 291, 5039, 4289, 4, 295, 264, 2663, 1238, 2661, 570, 4289, 4, 50680], "temperature": 0.0, "avg_logprob": -0.07978495529719762, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.11503491550683975}, {"id": 384, "seek": 191256, "start": 1918.8799999999999, "end": 1924.1599999999999, "text": " of the images are trivial and then that 10% you just will never solve because they're just they", "tokens": [50680, 295, 264, 5267, 366, 26703, 293, 550, 300, 1266, 4, 291, 445, 486, 1128, 5039, 570, 436, 434, 445, 436, 50944], "temperature": 0.0, "avg_logprob": -0.07978495529719762, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.11503491550683975}, {"id": 385, "seek": 191256, "start": 1924.1599999999999, "end": 1929.04, "text": " don't apply the normal rules that everything else does and you know if you're looking at a sort of", "tokens": [50944, 500, 380, 3079, 264, 2710, 4474, 300, 1203, 1646, 775, 293, 291, 458, 498, 291, 434, 1237, 412, 257, 1333, 295, 51188], "temperature": 0.0, "avg_logprob": -0.07978495529719762, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.11503491550683975}, {"id": 386, "seek": 191256, "start": 1929.04, "end": 1934.8, "text": " medical diagnosis AI or program that's a huge problem but you're just going to miss 10% because", "tokens": [51188, 4625, 15217, 7318, 420, 1461, 300, 311, 257, 2603, 1154, 457, 291, 434, 445, 516, 281, 1713, 1266, 4, 570, 51476], "temperature": 0.0, "avg_logprob": -0.07978495529719762, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.11503491550683975}, {"id": 387, "seek": 191256, "start": 1934.8, "end": 1940.32, "text": " you couldn't deal with the edge cases and so from my point of view coming from image analysis", "tokens": [51476, 291, 2809, 380, 2028, 365, 264, 4691, 3331, 293, 370, 490, 452, 935, 295, 1910, 1348, 490, 3256, 5215, 51752], "temperature": 0.0, "avg_logprob": -0.07978495529719762, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.11503491550683975}, {"id": 388, "seek": 194032, "start": 1940.32, "end": 1944.3999999999999, "text": " that was what it let us solve it allows you because this mathematical function is very very", "tokens": [50364, 300, 390, 437, 309, 718, 505, 5039, 309, 4045, 291, 570, 341, 18894, 2445, 307, 588, 588, 50568], "temperature": 0.0, "avg_logprob": -0.06936976692893289, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.003168469062075019}, {"id": 389, "seek": 194032, "start": 1944.3999999999999, "end": 1949.6799999999998, "text": " complicated it can learn the edge cases if you give it sufficient numbers of them so you just so", "tokens": [50568, 6179, 309, 393, 1466, 264, 4691, 3331, 498, 291, 976, 309, 11563, 3547, 295, 552, 370, 291, 445, 370, 50832], "temperature": 0.0, "avg_logprob": -0.06936976692893289, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.003168469062075019}, {"id": 390, "seek": 194032, "start": 1949.6799999999998, "end": 1954.6399999999999, "text": " actually a lot of the time when I work with biologists or medics and and and they present the", "tokens": [50832, 767, 257, 688, 295, 264, 565, 562, 286, 589, 365, 3228, 12256, 420, 1205, 1167, 293, 293, 293, 436, 1974, 264, 51080], "temperature": 0.0, "avg_logprob": -0.06936976692893289, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.003168469062075019}, {"id": 391, "seek": 194032, "start": 1954.6399999999999, "end": 1958.8, "text": " images I'll say these are all very nice but have you got any worse ones have you got any really", "tokens": [51080, 5267, 286, 603, 584, 613, 366, 439, 588, 1481, 457, 362, 291, 658, 604, 5324, 2306, 362, 291, 658, 604, 534, 51288], "temperature": 0.0, "avg_logprob": -0.06936976692893289, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.003168469062075019}, {"id": 392, "seek": 194032, "start": 1958.8, "end": 1964.32, "text": " bad ones because the more because the more bad stuff we give it the better it will get at at", "tokens": [51288, 1578, 2306, 570, 264, 544, 570, 264, 544, 1578, 1507, 321, 976, 309, 264, 1101, 309, 486, 483, 412, 412, 51564], "temperature": 0.0, "avg_logprob": -0.06936976692893289, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.003168469062075019}, {"id": 393, "seek": 196432, "start": 1964.32, "end": 1970.32, "text": " working when those things come along if you train your AI on a on a 3 or a 7 tesla MRI scanner", "tokens": [50364, 1364, 562, 729, 721, 808, 2051, 498, 291, 3847, 428, 7318, 322, 257, 322, 257, 805, 420, 257, 1614, 20018, 875, 32812, 30211, 50664], "temperature": 0.0, "avg_logprob": -0.09416738620474319, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.40621259808540344}, {"id": 394, "seek": 196432, "start": 1970.32, "end": 1975.36, "text": " which is super clear it won't work when you run it on a 1.5 you know so maybe you want to get", "tokens": [50664, 597, 307, 1687, 1850, 309, 1582, 380, 589, 562, 291, 1190, 309, 322, 257, 502, 13, 20, 291, 458, 370, 1310, 291, 528, 281, 483, 50916], "temperature": 0.0, "avg_logprob": -0.09416738620474319, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.40621259808540344}, {"id": 395, "seek": 196432, "start": 1975.36, "end": 1978.8, "text": " samples from all the different scanners you know what I mean there's these kind of decisions", "tokens": [50916, 10938, 490, 439, 264, 819, 795, 25792, 291, 458, 437, 286, 914, 456, 311, 613, 733, 295, 5327, 51088], "temperature": 0.0, "avg_logprob": -0.09416738620474319, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.40621259808540344}, {"id": 396, "seek": 196432, "start": 1978.8, "end": 1983.9199999999998, "text": " it actually means that the problem is no longer one of which if statements do I need to write to", "tokens": [51088, 309, 767, 1355, 300, 264, 1154, 307, 572, 2854, 472, 295, 597, 498, 12363, 360, 286, 643, 281, 2464, 281, 51344], "temperature": 0.0, "avg_logprob": -0.09416738620474319, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.40621259808540344}, {"id": 397, "seek": 196432, "start": 1983.9199999999998, "end": 1989.4399999999998, "text": " get this to work it's now what kind of data and how do I present the data to this network to get", "tokens": [51344, 483, 341, 281, 589, 309, 311, 586, 437, 733, 295, 1412, 293, 577, 360, 286, 1974, 264, 1412, 281, 341, 3209, 281, 483, 51620], "temperature": 0.0, "avg_logprob": -0.09416738620474319, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.40621259808540344}, {"id": 398, "seek": 198944, "start": 1989.44, "end": 1994.16, "text": " it to work all right and that so it becomes much more about the input and output problem", "tokens": [50364, 309, 281, 589, 439, 558, 293, 300, 370, 309, 3643, 709, 544, 466, 264, 4846, 293, 5598, 1154, 50600], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 399, "seek": 198944, "start": 1994.16, "end": 1998.3200000000002, "text": " than it becomes about what you do in the middle which it just learns that's great I mean I just", "tokens": [50600, 813, 309, 3643, 466, 437, 291, 360, 294, 264, 2808, 597, 309, 445, 27152, 300, 311, 869, 286, 914, 286, 445, 50808], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 400, "seek": 198944, "start": 1998.3200000000002, "end": 2002.56, "text": " wanted to see if I understand the terms I see terms like artificial intelligence machine learning", "tokens": [50808, 1415, 281, 536, 498, 286, 1223, 264, 2115, 286, 536, 2115, 411, 11677, 7599, 3479, 2539, 51020], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 401, "seek": 198944, "start": 2002.56, "end": 2006.48, "text": " neural networks and deep learning we've covered all of those is that right yeah so I mean to go into", "tokens": [51020, 18161, 9590, 293, 2452, 2539, 321, 600, 5343, 439, 295, 729, 307, 300, 558, 1338, 370, 286, 914, 281, 352, 666, 51216], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 402, "seek": 198944, "start": 2006.48, "end": 2012.64, "text": " some deep learning what I would say in terms of definition of deep learning is you know earlier", "tokens": [51216, 512, 2452, 2539, 437, 286, 576, 584, 294, 2115, 295, 7123, 295, 2452, 2539, 307, 291, 458, 3071, 51524], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 403, "seek": 198944, "start": 2012.64, "end": 2016.72, "text": " I said that you might do I features for your problem right so suppose you're trying to sell", "tokens": [51524, 286, 848, 300, 291, 1062, 360, 286, 4122, 337, 428, 1154, 558, 370, 7297, 291, 434, 1382, 281, 3607, 51728], "temperature": 0.0, "avg_logprob": -0.07926323657899391, "compression_ratio": 1.890728476821192, "no_speech_prob": 0.07354480028152466}, {"id": 404, "seek": 201672, "start": 2016.96, "end": 2021.84, "text": " cars what you might do is you might come up with some properties of cars that are relevant to its", "tokens": [50376, 5163, 437, 291, 1062, 360, 307, 291, 1062, 808, 493, 365, 512, 7221, 295, 5163, 300, 366, 7340, 281, 1080, 50620], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 405, "seek": 201672, "start": 2021.84, "end": 2026.24, "text": " purchase price so you might say okay how many cylinders has it got how many how much horsepower", "tokens": [50620, 8110, 3218, 370, 291, 1062, 584, 1392, 577, 867, 42166, 575, 309, 658, 577, 867, 577, 709, 25250, 50840], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 406, "seek": 201672, "start": 2026.24, "end": 2030.48, "text": " has it got has it got leather seats right as it got air conditioning and you would have all these", "tokens": [50840, 575, 309, 658, 575, 309, 658, 12821, 11069, 558, 382, 309, 658, 1988, 21901, 293, 291, 576, 362, 439, 613, 51052], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 407, "seek": 201672, "start": 2030.48, "end": 2034.24, "text": " features and you come up with a list of let's say a hundred different properties of a car and you", "tokens": [51052, 4122, 293, 291, 808, 493, 365, 257, 1329, 295, 718, 311, 584, 257, 3262, 819, 7221, 295, 257, 1032, 293, 291, 51240], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 408, "seek": 201672, "start": 2034.24, "end": 2039.28, "text": " would stick them in some AI decision tree neural network doesn't matter and then it would spit out", "tokens": [51240, 576, 2897, 552, 294, 512, 7318, 3537, 4230, 18161, 3209, 1177, 380, 1871, 293, 550, 309, 576, 22127, 484, 51492], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 409, "seek": 201672, "start": 2039.28, "end": 2043.6000000000001, "text": " a value for you and you would train it on a bunch of examples and you would hopefully have a system", "tokens": [51492, 257, 2158, 337, 291, 293, 291, 576, 3847, 309, 322, 257, 3840, 295, 5110, 293, 291, 576, 4696, 362, 257, 1185, 51708], "temperature": 0.0, "avg_logprob": -0.08319435263038578, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.026685331016778946}, {"id": 410, "seek": 204360, "start": 2043.6, "end": 2048.96, "text": " that could really nicely predict the value of cars right now the problem is that suppose I've", "tokens": [50364, 300, 727, 534, 9594, 6069, 264, 2158, 295, 5163, 558, 586, 264, 1154, 307, 300, 7297, 286, 600, 50632], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 411, "seek": 204360, "start": 2048.96, "end": 2054.0, "text": " missed out a feature that's absolutely crucial to the value of cars suppose I forgot to put in", "tokens": [50632, 6721, 484, 257, 4111, 300, 311, 3122, 11462, 281, 264, 2158, 295, 5163, 7297, 286, 5298, 281, 829, 294, 50884], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 412, "seek": 204360, "start": 2054.0, "end": 2058.4, "text": " the engine size and it turns out that 90 percent of the car's value is on how big the engine is", "tokens": [50884, 264, 2848, 2744, 293, 309, 4523, 484, 300, 4289, 3043, 295, 264, 1032, 311, 2158, 307, 322, 577, 955, 264, 2848, 307, 51104], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 413, "seek": 204360, "start": 2058.4, "end": 2062.88, "text": " right and so I've given it bad data then right and and then I have to go back and have to put", "tokens": [51104, 558, 293, 370, 286, 600, 2212, 309, 1578, 1412, 550, 558, 293, 293, 550, 286, 362, 281, 352, 646, 293, 362, 281, 829, 51328], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 414, "seek": 204360, "start": 2062.88, "end": 2066.4, "text": " data in again and I have to train it all again and you know it's a waste of time and what will", "tokens": [51328, 1412, 294, 797, 293, 286, 362, 281, 3847, 309, 439, 797, 293, 291, 458, 309, 311, 257, 5964, 295, 565, 293, 437, 486, 51504], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 415, "seek": 204360, "start": 2066.4, "end": 2070.48, "text": " actually happen if you try to implement a system where you missed out features is it would never", "tokens": [51504, 767, 1051, 498, 291, 853, 281, 4445, 257, 1185, 689, 291, 6721, 484, 4122, 307, 309, 576, 1128, 51708], "temperature": 0.0, "avg_logprob": -0.07997259432381958, "compression_ratio": 1.9, "no_speech_prob": 0.022565610706806183}, {"id": 416, "seek": 207048, "start": 2070.48, "end": 2077.2, "text": " work as well as you hoped and a car would come along that looked good on the features I did give it", "tokens": [50364, 589, 382, 731, 382, 291, 19737, 293, 257, 1032, 576, 808, 2051, 300, 2956, 665, 322, 264, 4122, 286, 630, 976, 309, 50700], "temperature": 0.0, "avg_logprob": -0.07355150742964311, "compression_ratio": 1.8745247148288973, "no_speech_prob": 0.027532491832971573}, {"id": 417, "seek": 207048, "start": 2077.2, "end": 2081.44, "text": " but actually had a really small engine and it would massively overvalue it or something like this", "tokens": [50700, 457, 767, 632, 257, 534, 1359, 2848, 293, 309, 576, 29379, 670, 29155, 309, 420, 746, 411, 341, 50912], "temperature": 0.0, "avg_logprob": -0.07355150742964311, "compression_ratio": 1.8745247148288973, "no_speech_prob": 0.027532491832971573}, {"id": 418, "seek": 207048, "start": 2081.44, "end": 2085.68, "text": " right or undervalue it and you give away a really nice car for almost free what deep learning does", "tokens": [50912, 558, 420, 833, 29155, 309, 293, 291, 976, 1314, 257, 534, 1481, 1032, 337, 1920, 1737, 437, 2452, 2539, 775, 51124], "temperature": 0.0, "avg_logprob": -0.07355150742964311, "compression_ratio": 1.8745247148288973, "no_speech_prob": 0.027532491832971573}, {"id": 419, "seek": 207048, "start": 2085.68, "end": 2091.2, "text": " is something called representation learning that's the because it's deeper it has the power to also", "tokens": [51124, 307, 746, 1219, 10290, 2539, 300, 311, 264, 570, 309, 311, 7731, 309, 575, 264, 1347, 281, 611, 51400], "temperature": 0.0, "avg_logprob": -0.07355150742964311, "compression_ratio": 1.8745247148288973, "no_speech_prob": 0.027532491832971573}, {"id": 420, "seek": 207048, "start": 2091.2, "end": 2095.84, "text": " learn the features as well as the decision based on those features so you might say well I can't", "tokens": [51400, 1466, 264, 4122, 382, 731, 382, 264, 3537, 2361, 322, 729, 4122, 370, 291, 1062, 584, 731, 286, 393, 380, 51632], "temperature": 0.0, "avg_logprob": -0.07355150742964311, "compression_ratio": 1.8745247148288973, "no_speech_prob": 0.027532491832971573}, {"id": 421, "seek": 209584, "start": 2095.84, "end": 2100.8, "text": " bother to decide to decide all these features so I'm just going to dump the raw specs or a picture", "tokens": [50364, 8677, 281, 4536, 281, 4536, 439, 613, 4122, 370, 286, 478, 445, 516, 281, 11430, 264, 8936, 27911, 420, 257, 3036, 50612], "temperature": 0.0, "avg_logprob": -0.06969837171841511, "compression_ratio": 1.8953488372093024, "no_speech_prob": 0.04196660965681076}, {"id": 422, "seek": 209584, "start": 2100.8, "end": 2106.96, "text": " of the car in at the front and have it determine for me the value right and it would be looking at", "tokens": [50612, 295, 264, 1032, 294, 412, 264, 1868, 293, 362, 309, 6997, 337, 385, 264, 2158, 558, 293, 309, 576, 312, 1237, 412, 50920], "temperature": 0.0, "avg_logprob": -0.06969837171841511, "compression_ratio": 1.8953488372093024, "no_speech_prob": 0.04196660965681076}, {"id": 423, "seek": 209584, "start": 2106.96, "end": 2112.0, "text": " the size and model shape the color the size of the wheels and it would do all this and it would", "tokens": [50920, 264, 2744, 293, 2316, 3909, 264, 2017, 264, 2744, 295, 264, 10046, 293, 309, 576, 360, 439, 341, 293, 309, 576, 51172], "temperature": 0.0, "avg_logprob": -0.06969837171841511, "compression_ratio": 1.8953488372093024, "no_speech_prob": 0.04196660965681076}, {"id": 424, "seek": 209584, "start": 2112.0, "end": 2118.0, "text": " extract the features first inside the network and then it would use that to make a decision so deep", "tokens": [51172, 8947, 264, 4122, 700, 1854, 264, 3209, 293, 550, 309, 576, 764, 300, 281, 652, 257, 3537, 370, 2452, 51472], "temperature": 0.0, "avg_logprob": -0.06969837171841511, "compression_ratio": 1.8953488372093024, "no_speech_prob": 0.04196660965681076}, {"id": 425, "seek": 209584, "start": 2118.0, "end": 2124.0, "text": " learning is often described as just the same network but deeper but actually it's a different I", "tokens": [51472, 2539, 307, 2049, 7619, 382, 445, 264, 912, 3209, 457, 7731, 457, 767, 309, 311, 257, 819, 286, 51772], "temperature": 0.0, "avg_logprob": -0.06969837171841511, "compression_ratio": 1.8953488372093024, "no_speech_prob": 0.04196660965681076}, {"id": 426, "seek": 212400, "start": 2124.0, "end": 2129.84, "text": " think a different paradigm where you're basically no longer hand crafting what you put in you're", "tokens": [50364, 519, 257, 819, 24709, 689, 291, 434, 1936, 572, 2854, 1011, 29048, 437, 291, 829, 294, 291, 434, 50656], "temperature": 0.0, "avg_logprob": -0.07212496655327934, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.00076540547888726}, {"id": 427, "seek": 212400, "start": 2129.84, "end": 2134.96, "text": " just shoving all of it in and it works out what's useful and what's not and so you've explained", "tokens": [50656, 445, 2223, 798, 439, 295, 309, 294, 293, 309, 1985, 484, 437, 311, 4420, 293, 437, 311, 406, 293, 370, 291, 600, 8825, 50912], "temperature": 0.0, "avg_logprob": -0.07212496655327934, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.00076540547888726}, {"id": 428, "seek": 212400, "start": 2134.96, "end": 2140.16, "text": " neural networks already is all right yeah I mean so a neural network yeah so I we talked about how", "tokens": [50912, 18161, 9590, 1217, 307, 439, 558, 1338, 286, 914, 370, 257, 18161, 3209, 1338, 370, 286, 321, 2825, 466, 577, 51172], "temperature": 0.0, "avg_logprob": -0.07212496655327934, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.00076540547888726}, {"id": 429, "seek": 212400, "start": 2140.16, "end": 2146.24, "text": " a neural network calculates a weighted sum so it takes some features at one layer and it waits", "tokens": [51172, 257, 18161, 3209, 4322, 1024, 257, 32807, 2408, 370, 309, 2516, 512, 4122, 412, 472, 4583, 293, 309, 40597, 51476], "temperature": 0.0, "avg_logprob": -0.07212496655327934, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.00076540547888726}, {"id": 430, "seek": 212400, "start": 2146.24, "end": 2149.68, "text": " them and then it calculates the sum of those for the next layer and we have something called an", "tokens": [51476, 552, 293, 550, 309, 4322, 1024, 264, 2408, 295, 729, 337, 264, 958, 4583, 293, 321, 362, 746, 1219, 364, 51648], "temperature": 0.0, "avg_logprob": -0.07212496655327934, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.00076540547888726}, {"id": 431, "seek": 214968, "start": 2149.68, "end": 2154.48, "text": " activation function in there as well which allows the basically it makes the function a lot more", "tokens": [50364, 24433, 2445, 294, 456, 382, 731, 597, 4045, 264, 1936, 309, 1669, 264, 2445, 257, 688, 544, 50604], "temperature": 0.0, "avg_logprob": -0.10153817176818848, "compression_ratio": 1.83203125, "no_speech_prob": 0.00829536933451891}, {"id": 432, "seek": 214968, "start": 2154.48, "end": 2160.48, "text": " complex right it makes it non-linear makes it learn more powerful things modern deep networks", "tokens": [50604, 3997, 558, 309, 1669, 309, 2107, 12, 28263, 1669, 309, 1466, 544, 4005, 721, 4363, 2452, 9590, 50904], "temperature": 0.0, "avg_logprob": -0.10153817176818848, "compression_ratio": 1.83203125, "no_speech_prob": 0.00829536933451891}, {"id": 433, "seek": 214968, "start": 2160.48, "end": 2167.12, "text": " actually have additional operations like convolutions and pooling operations which work on", "tokens": [50904, 767, 362, 4497, 7705, 411, 3754, 15892, 293, 7005, 278, 7705, 597, 589, 322, 51236], "temperature": 0.0, "avg_logprob": -0.10153817176818848, "compression_ratio": 1.83203125, "no_speech_prob": 0.00829536933451891}, {"id": 434, "seek": 214968, "start": 2167.12, "end": 2171.9199999999996, "text": " grids of data often right it doesn't have to but you know often they do so what you might do", "tokens": [51236, 677, 3742, 295, 1412, 2049, 558, 309, 1177, 380, 362, 281, 457, 291, 458, 2049, 436, 360, 370, 437, 291, 1062, 360, 51476], "temperature": 0.0, "avg_logprob": -0.10153817176818848, "compression_ratio": 1.83203125, "no_speech_prob": 0.00829536933451891}, {"id": 435, "seek": 214968, "start": 2172.56, "end": 2177.7599999999998, "text": " is instead of calculating a weighted sum of all the features you might slide a filter over the", "tokens": [51508, 307, 2602, 295, 28258, 257, 32807, 2408, 295, 439, 264, 4122, 291, 1062, 4137, 257, 6608, 670, 264, 51768], "temperature": 0.0, "avg_logprob": -0.10153817176818848, "compression_ratio": 1.83203125, "no_speech_prob": 0.00829536933451891}, {"id": 436, "seek": 217776, "start": 2177.76, "end": 2184.7200000000003, "text": " image to calculate filters at every location and so it's like a sort of a map of activations", "tokens": [50364, 3256, 281, 8873, 15995, 412, 633, 4914, 293, 370, 309, 311, 411, 257, 1333, 295, 257, 4471, 295, 2430, 763, 50712], "temperature": 0.0, "avg_logprob": -0.056465564387859685, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.002386458683758974}, {"id": 437, "seek": 217776, "start": 2184.7200000000003, "end": 2189.6000000000004, "text": " and then you might repeat that process over and over again so what what um deep networks are capable", "tokens": [50712, 293, 550, 291, 1062, 7149, 300, 1399, 670, 293, 670, 797, 370, 437, 437, 1105, 2452, 9590, 366, 8189, 50956], "temperature": 0.0, "avg_logprob": -0.056465564387859685, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.002386458683758974}, {"id": 438, "seek": 217776, "start": 2189.6000000000004, "end": 2195.92, "text": " of doing convolutional networks is determining features across the whole image right or across", "tokens": [50956, 295, 884, 45216, 304, 9590, 307, 23751, 4122, 2108, 264, 1379, 3256, 558, 420, 2108, 51272], "temperature": 0.0, "avg_logprob": -0.056465564387859685, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.002386458683758974}, {"id": 439, "seek": 217776, "start": 2195.92, "end": 2200.5600000000004, "text": " the whole of the data stream and then repeating that process over and over again that's how they", "tokens": [51272, 264, 1379, 295, 264, 1412, 4309, 293, 550, 18617, 300, 1399, 670, 293, 670, 797, 300, 311, 577, 436, 51504], "temperature": 0.0, "avg_logprob": -0.056465564387859685, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.002386458683758974}, {"id": 440, "seek": 217776, "start": 2200.5600000000004, "end": 2205.36, "text": " develop that's how they develop their representation learning right they use the filters to create", "tokens": [51504, 1499, 300, 311, 577, 436, 1499, 641, 10290, 2539, 558, 436, 764, 264, 15995, 281, 1884, 51744], "temperature": 0.0, "avg_logprob": -0.056465564387859685, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.002386458683758974}, {"id": 441, "seek": 220536, "start": 2205.36, "end": 2210.56, "text": " interesting information before they make a decision you teach security at university but", "tokens": [50364, 1880, 1589, 949, 436, 652, 257, 3537, 291, 2924, 3825, 412, 5454, 457, 50624], "temperature": 0.0, "avg_logprob": -0.08720211549238725, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.00817100703716278}, {"id": 442, "seek": 220536, "start": 2210.56, "end": 2216.2400000000002, "text": " you're doing a lot of the ai side ai stuff as well um i think the the question a lot of people will", "tokens": [50624, 291, 434, 884, 257, 688, 295, 264, 9783, 1252, 9783, 1507, 382, 731, 1105, 741, 519, 264, 264, 1168, 257, 688, 295, 561, 486, 50908], "temperature": 0.0, "avg_logprob": -0.08720211549238725, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.00817100703716278}, {"id": 443, "seek": 220536, "start": 2216.2400000000002, "end": 2220.88, "text": " be asking including myself is do i need to learn some kind of programming language and which language", "tokens": [50908, 312, 3365, 3009, 2059, 307, 360, 741, 643, 281, 1466, 512, 733, 295, 9410, 2856, 293, 597, 2856, 51140], "temperature": 0.0, "avg_logprob": -0.08720211549238725, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.00817100703716278}, {"id": 444, "seek": 220536, "start": 2220.88, "end": 2224.88, "text": " would it be would you recommend and do i need to learn like a whole bunch of math because it sounds", "tokens": [51140, 576, 309, 312, 576, 291, 2748, 293, 360, 741, 643, 281, 1466, 411, 257, 1379, 3840, 295, 5221, 570, 309, 3263, 51340], "temperature": 0.0, "avg_logprob": -0.08720211549238725, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.00817100703716278}, {"id": 445, "seek": 220536, "start": 2224.88, "end": 2228.8, "text": " like you know math is one of the or maths as we say in the uk is something that you have to", "tokens": [51340, 411, 291, 458, 5221, 307, 472, 295, 264, 420, 36287, 382, 321, 584, 294, 264, 26769, 307, 746, 300, 291, 362, 281, 51536], "temperature": 0.0, "avg_logprob": -0.08720211549238725, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.00817100703716278}, {"id": 446, "seek": 222880, "start": 2229.6000000000004, "end": 2237.6800000000003, "text": " it because you have to learn is that right to you know having having some idea of what's going", "tokens": [50404, 309, 570, 291, 362, 281, 1466, 307, 300, 558, 281, 291, 458, 1419, 1419, 512, 1558, 295, 437, 311, 516, 50808], "temperature": 0.0, "avg_logprob": -0.10078905066665338, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.021867826581001282}, {"id": 447, "seek": 222880, "start": 2237.6800000000003, "end": 2242.0, "text": " on mathematically helps you from an intuition point of view right because i understand the back", "tokens": [50808, 322, 44003, 3665, 291, 490, 364, 24002, 935, 295, 1910, 558, 570, 741, 1223, 264, 646, 51024], "temperature": 0.0, "avg_logprob": -0.10078905066665338, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.021867826581001282}, {"id": 448, "seek": 222880, "start": 2242.0, "end": 2245.92, "text": " propagation process which is how the actual weights have adjusted and that allows me to", "tokens": [51024, 38377, 1399, 597, 307, 577, 264, 3539, 17443, 362, 19871, 293, 300, 4045, 385, 281, 51220], "temperature": 0.0, "avg_logprob": -0.10078905066665338, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.021867826581001282}, {"id": 449, "seek": 222880, "start": 2245.92, "end": 2250.0, "text": " understand what would happen if i connect two bits of network together in a weird shape or", "tokens": [51220, 1223, 437, 576, 1051, 498, 741, 1745, 732, 9239, 295, 3209, 1214, 294, 257, 3657, 3909, 420, 51424], "temperature": 0.0, "avg_logprob": -0.10078905066665338, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.021867826581001282}, {"id": 450, "seek": 222880, "start": 2250.0, "end": 2255.6000000000004, "text": " something like this but in practice actually day to day running of a deep network doesn't really", "tokens": [51424, 746, 411, 341, 457, 294, 3124, 767, 786, 281, 786, 2614, 295, 257, 2452, 3209, 1177, 380, 534, 51704], "temperature": 0.0, "avg_logprob": -0.10078905066665338, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.021867826581001282}, {"id": 451, "seek": 225560, "start": 2255.6, "end": 2261.52, "text": " involve any maths and and and there is some disagreement in the community about whether", "tokens": [50364, 9494, 604, 36287, 293, 293, 293, 456, 307, 512, 38947, 294, 264, 1768, 466, 1968, 50660], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 452, "seek": 225560, "start": 2261.52, "end": 2265.36, "text": " you really need to know math at all right you know i'm i sort of go back and forth i sometimes", "tokens": [50660, 291, 534, 643, 281, 458, 5221, 412, 439, 558, 291, 458, 741, 478, 741, 1333, 295, 352, 646, 293, 5220, 741, 2171, 50852], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 453, "seek": 225560, "start": 2265.36, "end": 2268.72, "text": " think it's useful and i sometimes think it's not i certainly don't think people should be if they", "tokens": [50852, 519, 309, 311, 4420, 293, 741, 2171, 519, 309, 311, 406, 741, 3297, 500, 380, 519, 561, 820, 312, 498, 436, 51020], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 454, "seek": 225560, "start": 2268.72, "end": 2273.8399999999997, "text": " don't like maths should be put off from having a go because i'm always an advocate for have a go at", "tokens": [51020, 500, 380, 411, 36287, 820, 312, 829, 766, 490, 1419, 257, 352, 570, 741, 478, 1009, 364, 14608, 337, 362, 257, 352, 412, 51276], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 455, "seek": 225560, "start": 2273.8399999999997, "end": 2278.7999999999997, "text": " something you might really enjoy it right what i would say is that actually running a neural network", "tokens": [51276, 746, 291, 1062, 534, 2103, 309, 558, 437, 741, 576, 584, 307, 300, 767, 2614, 257, 18161, 3209, 51524], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 456, "seek": 225560, "start": 2278.7999999999997, "end": 2283.52, "text": " doesn't require a lot of maths it just requires a bit of python basically so that's the language", "tokens": [51524, 1177, 380, 3651, 257, 688, 295, 36287, 309, 445, 7029, 257, 857, 295, 38797, 1936, 370, 300, 311, 264, 2856, 51760], "temperature": 0.0, "avg_logprob": -0.06284084893707045, "compression_ratio": 1.8950819672131147, "no_speech_prob": 0.06454885005950928}, {"id": 457, "seek": 228352, "start": 2283.52, "end": 2288.32, "text": " you normally use python um i have a love hate relationship with python i think but sometimes", "tokens": [50364, 291, 5646, 764, 38797, 1105, 741, 362, 257, 959, 4700, 2480, 365, 38797, 741, 519, 457, 2171, 50604], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 458, "seek": 228352, "start": 2288.32, "end": 2292.64, "text": " sometimes i just want to declare what my types are and stop having runtime errors for half an hour", "tokens": [50604, 2171, 741, 445, 528, 281, 19710, 437, 452, 3467, 366, 293, 1590, 1419, 34474, 13603, 337, 1922, 364, 1773, 50820], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 459, "seek": 228352, "start": 2292.64, "end": 2296.72, "text": " into something but what what they've done is they've got a lot of libraries like tensorflow and", "tokens": [50820, 666, 746, 457, 437, 437, 436, 600, 1096, 307, 436, 600, 658, 257, 688, 295, 15148, 411, 40863, 10565, 293, 51024], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 460, "seek": 228352, "start": 2296.72, "end": 2302.96, "text": " pytorch that operate but sit in python and then they they very very quickly go go down into C", "tokens": [51024, 10664, 21151, 339, 300, 9651, 457, 1394, 294, 38797, 293, 550, 436, 436, 588, 588, 2661, 352, 352, 760, 666, 383, 51336], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 461, "seek": 228352, "start": 2302.96, "end": 2308.32, "text": " and CUDA for fast matrix multiplications which is all the stuff that goes on behind the scenes", "tokens": [51336, 293, 29777, 7509, 337, 2370, 8141, 17596, 763, 597, 307, 439, 264, 1507, 300, 1709, 322, 2261, 264, 8026, 51604], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 462, "seek": 228352, "start": 2308.32, "end": 2312.56, "text": " in your neural network so they're very very quick because they're not implemented end to end in python", "tokens": [51604, 294, 428, 18161, 3209, 370, 436, 434, 588, 588, 1702, 570, 436, 434, 406, 12270, 917, 281, 917, 294, 38797, 51816], "temperature": 0.0, "avg_logprob": -0.09799440090472882, "compression_ratio": 1.809375, "no_speech_prob": 0.07046140730381012}, {"id": 463, "seek": 231256, "start": 2313.12, "end": 2319.52, "text": " but python gives you a very convenient and nice way of doing all this you know loading the images", "tokens": [50392, 457, 38797, 2709, 291, 257, 588, 10851, 293, 1481, 636, 295, 884, 439, 341, 291, 458, 15114, 264, 5267, 50712], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 464, "seek": 231256, "start": 2319.52, "end": 2323.6, "text": " it just appears as a kind of array you know you might have a list of images that you use for", "tokens": [50712, 309, 445, 7038, 382, 257, 733, 295, 10225, 291, 458, 291, 1062, 362, 257, 1329, 295, 5267, 300, 291, 764, 337, 50916], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 465, "seek": 231256, "start": 2323.6, "end": 2328.4, "text": " your data set and then you put that into a network and so on right you know a lot of it's just inputting", "tokens": [50916, 428, 1412, 992, 293, 550, 291, 829, 300, 666, 257, 3209, 293, 370, 322, 558, 291, 458, 257, 688, 295, 309, 311, 445, 4846, 783, 51156], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 466, "seek": 231256, "start": 2328.4, "end": 2332.88, "text": " out putting lists and dictionaries like the rest of python and so it makes things quite easy to use", "tokens": [51156, 484, 3372, 14511, 293, 22352, 4889, 411, 264, 1472, 295, 38797, 293, 370, 309, 1669, 721, 1596, 1858, 281, 764, 51380], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 467, "seek": 231256, "start": 2332.88, "end": 2337.04, "text": " you know you'll have had a look at python but python for me is is a is a nice enough language", "tokens": [51380, 291, 458, 291, 603, 362, 632, 257, 574, 412, 38797, 457, 38797, 337, 385, 307, 307, 257, 307, 257, 1481, 1547, 2856, 51588], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 468, "seek": 231256, "start": 2337.04, "end": 2340.56, "text": " in the sense that it's fairly easy to pick up particularly if you already know a language", "tokens": [51588, 294, 264, 2020, 300, 309, 311, 6457, 1858, 281, 1888, 493, 4098, 498, 291, 1217, 458, 257, 2856, 51764], "temperature": 0.0, "avg_logprob": -0.05564521199507679, "compression_ratio": 1.9364548494983278, "no_speech_prob": 0.003068570513278246}, {"id": 469, "seek": 234056, "start": 2340.64, "end": 2345.36, "text": " it's often language people recommend you start with anyway because it's fairly relaxed about", "tokens": [50368, 309, 311, 2049, 2856, 561, 2748, 291, 722, 365, 4033, 570, 309, 311, 6457, 14628, 466, 50604], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 470, "seek": 234056, "start": 2345.36, "end": 2351.7599999999998, "text": " syntax and just you making a total mess of it so that's you know that's always good um but doing", "tokens": [50604, 28431, 293, 445, 291, 1455, 257, 3217, 2082, 295, 309, 370, 300, 311, 291, 458, 300, 311, 1009, 665, 1105, 457, 884, 50924], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 471, "seek": 234056, "start": 2351.7599999999998, "end": 2356.72, "text": " going from knowledge of python to having implemented a deep network will not take you very long you", "tokens": [50924, 516, 490, 3601, 295, 38797, 281, 1419, 12270, 257, 2452, 3209, 486, 406, 747, 291, 588, 938, 291, 51172], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 472, "seek": 234056, "start": 2356.72, "end": 2361.04, "text": " will understand everything the first time but you can get give it a go and you can watch it training", "tokens": [51172, 486, 1223, 1203, 264, 700, 565, 457, 291, 393, 483, 976, 309, 257, 352, 293, 291, 393, 1159, 309, 3097, 51388], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 473, "seek": 234056, "start": 2361.04, "end": 2365.68, "text": " and you can start to you can start to pick up on what's going on and then you can make a change", "tokens": [51388, 293, 291, 393, 722, 281, 291, 393, 722, 281, 1888, 493, 322, 437, 311, 516, 322, 293, 550, 291, 393, 652, 257, 1319, 51620], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 474, "seek": 234056, "start": 2365.68, "end": 2369.52, "text": " to the network and maybe improve your performance slightly do you have to write it from scratch", "tokens": [51620, 281, 264, 3209, 293, 1310, 3470, 428, 3389, 4748, 360, 291, 362, 281, 2464, 309, 490, 8459, 51812], "temperature": 0.0, "avg_logprob": -0.06110073603116549, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.00608925661072135}, {"id": 475, "seek": 236952, "start": 2369.52, "end": 2374.0, "text": " or is like it's it's TensorFlow or something that like Google have created exactly they do", "tokens": [50364, 420, 307, 411, 309, 311, 309, 311, 37624, 420, 746, 300, 411, 3329, 362, 2942, 2293, 436, 360, 50588], "temperature": 0.0, "avg_logprob": -0.1003338386272562, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.01998049207031727}, {"id": 476, "seek": 236952, "start": 2374.0, "end": 2378.08, "text": " a huge amount of heavy lifting right which is one of the reasons why you can kind of get away", "tokens": [50588, 257, 2603, 2372, 295, 4676, 15798, 558, 597, 307, 472, 295, 264, 4112, 983, 291, 393, 733, 295, 483, 1314, 50792], "temperature": 0.0, "avg_logprob": -0.1003338386272562, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.01998049207031727}, {"id": 477, "seek": 236952, "start": 2378.08, "end": 2385.04, "text": " with not having always mathematical background so I mean I use PyTorch mainly and in PyTorch", "tokens": [50792, 365, 406, 1419, 1009, 18894, 3678, 370, 286, 914, 286, 764, 9953, 51, 284, 339, 8704, 293, 294, 9953, 51, 284, 339, 51140], "temperature": 0.0, "avg_logprob": -0.1003338386272562, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.01998049207031727}, {"id": 478, "seek": 236952, "start": 2385.04, "end": 2391.2, "text": " it handles all the weights and learning for you so you say I want my network to have this many", "tokens": [51140, 309, 18722, 439, 264, 17443, 293, 2539, 337, 291, 370, 291, 584, 286, 528, 452, 3209, 281, 362, 341, 867, 51448], "temperature": 0.0, "avg_logprob": -0.1003338386272562, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.01998049207031727}, {"id": 479, "seek": 236952, "start": 2391.2, "end": 2395.44, "text": " layers and I want my layers to be like this and I want it to take an image of this size and turn it", "tokens": [51448, 7914, 293, 286, 528, 452, 7914, 281, 312, 411, 341, 293, 286, 528, 309, 281, 747, 364, 3256, 295, 341, 2744, 293, 1261, 309, 51660], "temperature": 0.0, "avg_logprob": -0.1003338386272562, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.01998049207031727}, {"id": 480, "seek": 239544, "start": 2395.44, "end": 2401.2000000000003, "text": " into a 10 class classification problem where I'm picking cats and dogs and airplanes or what have", "tokens": [50364, 666, 257, 1266, 1508, 21538, 1154, 689, 286, 478, 8867, 11111, 293, 7197, 293, 32947, 420, 437, 362, 50652], "temperature": 0.0, "avg_logprob": -0.08913443110010645, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.06539267301559448}, {"id": 481, "seek": 239544, "start": 2401.2000000000003, "end": 2406.96, "text": " you and then it just trots off and does it and it just goes it goes puts the images in it it", "tokens": [50652, 291, 293, 550, 309, 445, 504, 1971, 766, 293, 775, 309, 293, 309, 445, 1709, 309, 1709, 8137, 264, 5267, 294, 309, 309, 50940], "temperature": 0.0, "avg_logprob": -0.08913443110010645, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.06539267301559448}, {"id": 482, "seek": 239544, "start": 2406.96, "end": 2411.12, "text": " retrains the network and it puts the images in it retrains the network and it iterates and you can", "tokens": [50940, 1533, 424, 1292, 264, 3209, 293, 309, 8137, 264, 5267, 294, 309, 1533, 424, 1292, 264, 3209, 293, 309, 17138, 1024, 293, 291, 393, 51148], "temperature": 0.0, "avg_logprob": -0.08913443110010645, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.06539267301559448}, {"id": 483, "seek": 239544, "start": 2411.12, "end": 2416.8, "text": " watch your learning rate really watch your loss function go down as it gets better and better", "tokens": [51148, 1159, 428, 2539, 3314, 534, 1159, 428, 4470, 2445, 352, 760, 382, 309, 2170, 1101, 293, 1101, 51432], "temperature": 0.0, "avg_logprob": -0.08913443110010645, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.06539267301559448}, {"id": 484, "seek": 239544, "start": 2416.8, "end": 2421.04, "text": " every iteration instead eventually you can then just deploy it in some sort of production code or", "tokens": [51432, 633, 24784, 2602, 4728, 291, 393, 550, 445, 7274, 309, 294, 512, 1333, 295, 4265, 3089, 420, 51644], "temperature": 0.0, "avg_logprob": -0.08913443110010645, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.06539267301559448}, {"id": 485, "seek": 242104, "start": 2421.04, "end": 2427.2799999999997, "text": " whatever and maybe without maybe test it first so but um you know like it does a huge amount", "tokens": [50364, 2035, 293, 1310, 1553, 1310, 1500, 309, 700, 370, 457, 1105, 291, 458, 411, 309, 775, 257, 2603, 2372, 50676], "temperature": 0.0, "avg_logprob": -0.07585703123600111, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.021578097715973854}, {"id": 486, "seek": 242104, "start": 2427.2799999999997, "end": 2431.92, "text": " there's a lot of mathematics behind the scenes not all of it particularly complicated but it's", "tokens": [50676, 456, 311, 257, 688, 295, 18666, 2261, 264, 8026, 406, 439, 295, 309, 4098, 6179, 457, 309, 311, 50908], "temperature": 0.0, "avg_logprob": -0.07585703123600111, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.021578097715973854}, {"id": 487, "seek": 242104, "start": 2431.92, "end": 2438.16, "text": " definitely a lot of it and it's all massively parallelized on a GPU and you know so you can", "tokens": [50908, 2138, 257, 688, 295, 309, 293, 309, 311, 439, 29379, 8952, 1602, 322, 257, 18407, 293, 291, 458, 370, 291, 393, 51220], "temperature": 0.0, "avg_logprob": -0.07585703123600111, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.021578097715973854}, {"id": 488, "seek": 242104, "start": 2438.16, "end": 2444.72, "text": " actually get away with a few dozen lines of code to get a pretty nifty neural network going", "tokens": [51220, 767, 483, 1314, 365, 257, 1326, 16654, 3876, 295, 3089, 281, 483, 257, 1238, 297, 37177, 18161, 3209, 516, 51548], "temperature": 0.0, "avg_logprob": -0.07585703123600111, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.021578097715973854}, {"id": 489, "seek": 242104, "start": 2444.72, "end": 2448.0, "text": " let's see that that's good to hear because you know when you start talking about the ins and", "tokens": [51548, 718, 311, 536, 300, 300, 311, 665, 281, 1568, 570, 291, 458, 562, 291, 722, 1417, 466, 264, 1028, 293, 51712], "temperature": 0.0, "avg_logprob": -0.07585703123600111, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.021578097715973854}, {"id": 490, "seek": 244800, "start": 2448.0, "end": 2452.56, "text": " outs it's like this sounds so complicated so it's like PyTorch just a library or something that you", "tokens": [50364, 14758, 309, 311, 411, 341, 3263, 370, 6179, 370, 309, 311, 411, 9953, 51, 284, 339, 445, 257, 6405, 420, 746, 300, 291, 50592], "temperature": 0.0, "avg_logprob": -0.11262785649932591, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.02251533418893814}, {"id": 491, "seek": 244800, "start": 2452.56, "end": 2457.2, "text": " would import and then just you just send some commands to it yeah Torch started off as a", "tokens": [50592, 576, 974, 293, 550, 445, 291, 445, 2845, 512, 16901, 281, 309, 1338, 7160, 339, 1409, 766, 382, 257, 50824], "temperature": 0.0, "avg_logprob": -0.11262785649932591, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.02251533418893814}, {"id": 492, "seek": 244800, "start": 2457.2, "end": 2463.36, "text": " machine learning library in um well it was written in C presumably but and CUDA but it was it was for", "tokens": [50824, 3479, 2539, 6405, 294, 1105, 731, 309, 390, 3720, 294, 383, 26742, 457, 293, 29777, 7509, 457, 309, 390, 309, 390, 337, 51132], "temperature": 0.0, "avg_logprob": -0.11262785649932591, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.02251533418893814}, {"id": 493, "seek": 244800, "start": 2463.36, "end": 2468.16, "text": " Lua and again that's another language I have a should we say a very strong mixed opinions about", "tokens": [51132, 441, 4398, 293, 797, 300, 311, 1071, 2856, 286, 362, 257, 820, 321, 584, 257, 588, 2068, 7467, 11819, 466, 51372], "temperature": 0.0, "avg_logprob": -0.11262785649932591, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.02251533418893814}, {"id": 494, "seek": 244800, "start": 2468.88, "end": 2473.6, "text": " however since then TensorFlow came along in Python I think it was seen as Python's more", "tokens": [51408, 4461, 1670, 550, 37624, 1361, 2051, 294, 15329, 286, 519, 309, 390, 1612, 382, 15329, 311, 544, 51644], "temperature": 0.0, "avg_logprob": -0.11262785649932591, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.02251533418893814}, {"id": 495, "seek": 247360, "start": 2473.68, "end": 2479.2, "text": " convenient for the majority of developers and so PyTorch spawned off Torch basically and is now", "tokens": [50368, 10851, 337, 264, 6286, 295, 8849, 293, 370, 9953, 51, 284, 339, 17088, 292, 766, 7160, 339, 1936, 293, 307, 586, 50644], "temperature": 0.0, "avg_logprob": -0.08969265954536304, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027119021397083998}, {"id": 496, "seek": 247360, "start": 2479.2, "end": 2487.52, "text": " the dominant library for this so TensorFlow is Google and PyTorch is Facebook AI or meta AI I", "tokens": [50644, 264, 15657, 6405, 337, 341, 370, 37624, 307, 3329, 293, 9953, 51, 284, 339, 307, 4384, 7318, 420, 19616, 7318, 286, 51060], "temperature": 0.0, "avg_logprob": -0.08969265954536304, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027119021397083998}, {"id": 497, "seek": 247360, "start": 2487.52, "end": 2492.48, "text": " suppose it is now and that's the one you would start with here if you were starting I yeah so", "tokens": [51060, 7297, 309, 307, 586, 293, 300, 311, 264, 472, 291, 576, 722, 365, 510, 498, 291, 645, 2891, 286, 1338, 370, 51308], "temperature": 0.0, "avg_logprob": -0.08969265954536304, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027119021397083998}, {"id": 498, "seek": 247360, "start": 2492.48, "end": 2496.4, "text": " this is it people have different opinions on this I think that the just give us your opinion", "tokens": [51308, 341, 307, 309, 561, 362, 819, 11819, 322, 341, 286, 519, 300, 264, 445, 976, 505, 428, 4800, 51504], "temperature": 0.0, "avg_logprob": -0.08969265954536304, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027119021397083998}, {"id": 499, "seek": 247360, "start": 2496.4, "end": 2501.2799999999997, "text": " because you know we I just sorry to interrupt I just want to put it this way I like to have", "tokens": [51504, 570, 291, 458, 321, 286, 445, 2597, 281, 12729, 286, 445, 528, 281, 829, 309, 341, 636, 286, 411, 281, 362, 51748], "temperature": 0.0, "avg_logprob": -0.08969265954536304, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027119021397083998}, {"id": 500, "seek": 250128, "start": 2501.28, "end": 2506.96, "text": " parts like when I talk to experts like yourself it's like okay I'm new now how do I go from like", "tokens": [50364, 3166, 411, 562, 286, 751, 281, 8572, 411, 1803, 309, 311, 411, 1392, 286, 478, 777, 586, 577, 360, 286, 352, 490, 411, 50648], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 501, "seek": 250128, "start": 2506.96, "end": 2511.2000000000003, "text": " knowing nothing to like at least getting started if so if you anything you can help me yeah well I", "tokens": [50648, 5276, 1825, 281, 411, 412, 1935, 1242, 1409, 498, 370, 498, 291, 1340, 291, 393, 854, 385, 1338, 731, 286, 50860], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 502, "seek": 250128, "start": 2511.2000000000003, "end": 2515.28, "text": " mean I tell you what knowledge whatever yeah yeah yeah I would start with PyTorch personally", "tokens": [50860, 914, 286, 980, 291, 437, 3601, 2035, 1338, 1338, 1338, 286, 576, 722, 365, 9953, 51, 284, 339, 5665, 51064], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 503, "seek": 250128, "start": 2515.28, "end": 2520.1600000000003, "text": " right from a research point of view PyTorch is more flexible which helps me but it also doesn't", "tokens": [51064, 558, 490, 257, 2132, 935, 295, 1910, 9953, 51, 284, 339, 307, 544, 11358, 597, 3665, 385, 457, 309, 611, 1177, 380, 51308], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 504, "seek": 250128, "start": 2520.1600000000003, "end": 2526.6400000000003, "text": " require a lot of lines of code um to get running and it also does a nice thing where it doesn't hide", "tokens": [51308, 3651, 257, 688, 295, 3876, 295, 3089, 1105, 281, 483, 2614, 293, 309, 611, 775, 257, 1481, 551, 689, 309, 1177, 380, 6479, 51632], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 505, "seek": 250128, "start": 2526.6400000000003, "end": 2530.5600000000004, "text": " away all of the details there's just enough detail in there that you can kind of type away and it'll", "tokens": [51632, 1314, 439, 295, 264, 4365, 456, 311, 445, 1547, 2607, 294, 456, 300, 291, 393, 733, 295, 2010, 1314, 293, 309, 603, 51828], "temperature": 0.0, "avg_logprob": -0.07448862649344064, "compression_ratio": 1.83125, "no_speech_prob": 0.01563490368425846}, {"id": 506, "seek": 253056, "start": 2530.56, "end": 2536.0, "text": " kind of work but you do see the network going forward and learning and optimizing the weights", "tokens": [50364, 733, 295, 589, 457, 291, 360, 536, 264, 3209, 516, 2128, 293, 2539, 293, 40425, 264, 17443, 50636], "temperature": 0.0, "avg_logprob": -0.052742501609345786, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.007548781111836433}, {"id": 507, "seek": 253056, "start": 2536.0, "end": 2539.92, "text": " and things like this there's a few lines of code but do that that you can kind of look at and go", "tokens": [50636, 293, 721, 411, 341, 456, 311, 257, 1326, 3876, 295, 3089, 457, 360, 300, 300, 291, 393, 733, 295, 574, 412, 293, 352, 50832], "temperature": 0.0, "avg_logprob": -0.052742501609345786, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.007548781111836433}, {"id": 508, "seek": 253056, "start": 2540.4, "end": 2546.48, "text": " and then you kind of pick these things up right it's not a case that you just type PyTorch.train", "tokens": [50856, 293, 550, 291, 733, 295, 1888, 613, 721, 493, 558, 309, 311, 406, 257, 1389, 300, 291, 445, 2010, 9953, 51, 284, 339, 13, 83, 7146, 51160], "temperature": 0.0, "avg_logprob": -0.052742501609345786, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.007548781111836433}, {"id": 509, "seek": 253056, "start": 2546.48, "end": 2550.96, "text": " and pass it your input data and then it just does it and you have no idea what happened", "tokens": [51160, 293, 1320, 309, 428, 4846, 1412, 293, 550, 309, 445, 775, 309, 293, 291, 362, 572, 1558, 437, 2011, 51384], "temperature": 0.0, "avg_logprob": -0.052742501609345786, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.007548781111836433}, {"id": 510, "seek": 253056, "start": 2550.96, "end": 2556.88, "text": " which I like because that wouldn't be fun right but also you wouldn't learn anything so I like", "tokens": [51384, 597, 286, 411, 570, 300, 2759, 380, 312, 1019, 558, 457, 611, 291, 2759, 380, 1466, 1340, 370, 286, 411, 51680], "temperature": 0.0, "avg_logprob": -0.052742501609345786, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.007548781111836433}, {"id": 511, "seek": 255688, "start": 2556.88, "end": 2563.28, "text": " PyTorch from that for that reason it also has a load of examples so if you go on the um if you", "tokens": [50364, 9953, 51, 284, 339, 490, 300, 337, 300, 1778, 309, 611, 575, 257, 3677, 295, 5110, 370, 498, 291, 352, 322, 264, 1105, 498, 291, 50684], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 512, "seek": 255688, "start": 2563.28, "end": 2568.0, "text": " go on the github repository for PyTorch or Torchvision you get the the whole you've got all the like", "tokens": [50684, 352, 322, 264, 290, 355, 836, 25841, 337, 9953, 51, 284, 339, 420, 7160, 339, 6763, 291, 483, 264, 264, 1379, 291, 600, 658, 439, 264, 411, 50920], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 513, "seek": 255688, "start": 2568.0, "end": 2573.92, "text": " core networks that are big from the literature in there and you've also got some examples of simple", "tokens": [50920, 4965, 9590, 300, 366, 955, 490, 264, 10394, 294, 456, 293, 291, 600, 611, 658, 512, 5110, 295, 2199, 51216], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 514, "seek": 255688, "start": 2573.92, "end": 2577.6, "text": " data problems and things like this that you can run from end to end and just basically run the", "tokens": [51216, 1412, 2740, 293, 721, 411, 341, 300, 291, 393, 1190, 490, 917, 281, 917, 293, 445, 1936, 1190, 264, 51400], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 515, "seek": 255688, "start": 2577.6, "end": 2581.04, "text": " file and it will start training a network and then you can delve in and see what it is it's", "tokens": [51400, 3991, 293, 309, 486, 722, 3097, 257, 3209, 293, 550, 291, 393, 43098, 294, 293, 536, 437, 309, 307, 309, 311, 51572], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 516, "seek": 255688, "start": 2581.04, "end": 2585.2000000000003, "text": " actually doing. Do you need I think you mentioned a GPU do you need specific hardware or can you", "tokens": [51572, 767, 884, 13, 1144, 291, 643, 286, 519, 291, 2835, 257, 18407, 360, 291, 643, 2685, 8837, 420, 393, 291, 51780], "temperature": 0.0, "avg_logprob": -0.08860710407125538, "compression_ratio": 1.8557692307692308, "no_speech_prob": 0.012163985520601273}, {"id": 517, "seek": 258520, "start": 2585.2, "end": 2592.0, "text": " just run this on your laptop? You need you really need a um so PyTorch uses CUDA right so you really", "tokens": [50364, 445, 1190, 341, 322, 428, 10732, 30, 509, 643, 291, 534, 643, 257, 1105, 370, 9953, 51, 284, 339, 4960, 29777, 7509, 558, 370, 291, 534, 50704], "temperature": 0.0, "avg_logprob": -0.10077240753173829, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.0017959633842110634}, {"id": 518, "seek": 258520, "start": 2592.0, "end": 2596.96, "text": " could do with using a um I don't know if PyTorch supports OpenCL I can't remember ideally you", "tokens": [50704, 727, 360, 365, 1228, 257, 1105, 286, 500, 380, 458, 498, 9953, 51, 284, 339, 9346, 7238, 22458, 286, 393, 380, 1604, 22915, 291, 50952], "temperature": 0.0, "avg_logprob": -0.10077240753173829, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.0017959633842110634}, {"id": 519, "seek": 258520, "start": 2596.96, "end": 2603.04, "text": " would have access to a CUDA enabled GPU that would make this process much much faster so as I mentioned", "tokens": [50952, 576, 362, 2105, 281, 257, 29777, 7509, 15172, 18407, 300, 576, 652, 341, 1399, 709, 709, 4663, 370, 382, 286, 2835, 51256], "temperature": 0.0, "avg_logprob": -0.10077240753173829, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.0017959633842110634}, {"id": 520, "seek": 258520, "start": 2603.04, "end": 2608.7999999999997, "text": " the back end of of PyTorch and most of these deep learning libraries is written in C and CUDA and it's", "tokens": [51256, 264, 646, 917, 295, 295, 9953, 51, 284, 339, 293, 881, 295, 613, 2452, 2539, 15148, 307, 3720, 294, 383, 293, 29777, 7509, 293, 309, 311, 51544], "temperature": 0.0, "avg_logprob": -0.10077240753173829, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.0017959633842110634}, {"id": 521, "seek": 258520, "start": 2608.7999999999997, "end": 2614.0, "text": " just massively parallelized matrix modifications most of the time and that is something that you", "tokens": [51544, 445, 29379, 8952, 1602, 8141, 26881, 881, 295, 264, 565, 293, 300, 307, 746, 300, 291, 51804], "temperature": 0.0, "avg_logprob": -0.10077240753173829, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.0017959633842110634}, {"id": 522, "seek": 261400, "start": 2614.0, "end": 2618.56, "text": " don't want to be doing on a CPU right you can for very small networks run it on a CPU so if you", "tokens": [50364, 500, 380, 528, 281, 312, 884, 322, 257, 13199, 558, 291, 393, 337, 588, 1359, 9590, 1190, 309, 322, 257, 13199, 370, 498, 291, 50592], "temperature": 0.0, "avg_logprob": -0.07673022004424548, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.009255476295948029}, {"id": 523, "seek": 261400, "start": 2618.56, "end": 2623.84, "text": " download the simplest PyTorch example when you run it on a CPU it will run okay and you'll be able to", "tokens": [50592, 5484, 264, 22811, 9953, 51, 284, 339, 1365, 562, 291, 1190, 309, 322, 257, 13199, 309, 486, 1190, 1392, 293, 291, 603, 312, 1075, 281, 50856], "temperature": 0.0, "avg_logprob": -0.07673022004424548, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.009255476295948029}, {"id": 524, "seek": 261400, "start": 2623.84, "end": 2629.2, "text": " see what happens. Anything with images anything where the dimensionality is high you're going to be", "tokens": [50856, 536, 437, 2314, 13, 11998, 365, 5267, 1340, 689, 264, 10139, 1860, 307, 1090, 291, 434, 516, 281, 312, 51124], "temperature": 0.0, "avg_logprob": -0.07673022004424548, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.009255476295948029}, {"id": 525, "seek": 261400, "start": 2629.2, "end": 2633.76, "text": " waiting half an hour for it just to finish one pass and it won't get anything done. One other", "tokens": [51124, 3806, 1922, 364, 1773, 337, 309, 445, 281, 2413, 472, 1320, 293, 309, 1582, 380, 483, 1340, 1096, 13, 1485, 661, 51352], "temperature": 0.0, "avg_logprob": -0.07673022004424548, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.009255476295948029}, {"id": 526, "seek": 261400, "start": 2633.76, "end": 2641.44, "text": " thing you might like to try is Google Colab so Google Colab is um is Google's public Jupiter", "tokens": [51352, 551, 291, 1062, 411, 281, 853, 307, 3329, 4004, 455, 370, 3329, 4004, 455, 307, 1105, 307, 3329, 311, 1908, 24567, 51736], "temperature": 0.0, "avg_logprob": -0.07673022004424548, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.009255476295948029}, {"id": 527, "seek": 264144, "start": 2641.44, "end": 2646.96, "text": " notebook style laboratory environment that actually provides limited time but fair use", "tokens": [50364, 21060, 3758, 16523, 2823, 300, 767, 6417, 5567, 565, 457, 3143, 764, 50640], "temperature": 0.0, "avg_logprob": -0.08245467324542184, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.020285457372665405}, {"id": 528, "seek": 264144, "start": 2646.96, "end": 2652.08, "text": " access to GPUs to to have a go at these things right it's a it's a great place to go and you", "tokens": [50640, 2105, 281, 18407, 82, 281, 281, 362, 257, 352, 412, 613, 721, 558, 309, 311, 257, 309, 311, 257, 869, 1081, 281, 352, 293, 291, 50896], "temperature": 0.0, "avg_logprob": -0.08245467324542184, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.020285457372665405}, {"id": 529, "seek": 264144, "start": 2652.08, "end": 2657.2000000000003, "text": " can also download loads of Colab notebooks existing implementations to test them out that's a great", "tokens": [50896, 393, 611, 5484, 12668, 295, 4004, 455, 43782, 6741, 4445, 763, 281, 1500, 552, 484, 300, 311, 257, 869, 51152], "temperature": 0.0, "avg_logprob": -0.08245467324542184, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.020285457372665405}, {"id": 530, "seek": 264144, "start": 2657.2000000000003, "end": 2662.32, "text": " place to start you know I'm a big fan of Google Colab I think that as a platform it's really really", "tokens": [51152, 1081, 281, 722, 291, 458, 286, 478, 257, 955, 3429, 295, 3329, 4004, 455, 286, 519, 300, 382, 257, 3663, 309, 311, 534, 534, 51408], "temperature": 0.0, "avg_logprob": -0.08245467324542184, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.020285457372665405}, {"id": 531, "seek": 264144, "start": 2662.32, "end": 2667.2000000000003, "text": " useful um and you can actually pay us I mean I'm not I don't work for Google Colab you can pay a", "tokens": [51408, 4420, 1105, 293, 291, 393, 767, 1689, 505, 286, 914, 286, 478, 406, 286, 500, 380, 589, 337, 3329, 4004, 455, 291, 393, 1689, 257, 51652], "temperature": 0.0, "avg_logprob": -0.08245467324542184, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.020285457372665405}, {"id": 532, "seek": 266720, "start": 2667.2799999999997, "end": 2673.9199999999996, "text": " small subscription to get access to higher access or more preference more um should we say higher", "tokens": [50368, 1359, 17231, 281, 483, 2105, 281, 2946, 2105, 420, 544, 17502, 544, 1105, 820, 321, 584, 2946, 50700], "temperature": 0.0, "avg_logprob": -0.09108835253222235, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.016296176239848137}, {"id": 533, "seek": 266720, "start": 2673.9199999999996, "end": 2679.04, "text": " priority access to GPUs right that's what you know you can get um so it's it's like fair use", "tokens": [50700, 9365, 2105, 281, 18407, 82, 558, 300, 311, 437, 291, 458, 291, 393, 483, 1105, 370, 309, 311, 309, 311, 411, 3143, 764, 50956], "temperature": 0.0, "avg_logprob": -0.09108835253222235, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.016296176239848137}, {"id": 534, "seek": 266720, "start": 2679.04, "end": 2682.96, "text": " normally so if you if you use it a lot you might have to wait for half a day or something.", "tokens": [50956, 5646, 370, 498, 291, 498, 291, 764, 309, 257, 688, 291, 1062, 362, 281, 1699, 337, 1922, 257, 786, 420, 746, 13, 51152], "temperature": 0.0, "avg_logprob": -0.09108835253222235, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.016296176239848137}, {"id": 535, "seek": 266720, "start": 2682.96, "end": 2687.8399999999997, "text": " I mean in the best case scenario I'd come and attend one of your classes um but not everyone's", "tokens": [51152, 286, 914, 294, 264, 1151, 1389, 9005, 286, 1116, 808, 293, 6888, 472, 295, 428, 5359, 1105, 457, 406, 1518, 311, 51396], "temperature": 0.0, "avg_logprob": -0.09108835253222235, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.016296176239848137}, {"id": 536, "seek": 266720, "start": 2687.8399999999997, "end": 2693.04, "text": " going to be able to do that um do you have books or online courses or stuff that you would personally", "tokens": [51396, 516, 281, 312, 1075, 281, 360, 300, 1105, 360, 291, 362, 3642, 420, 2950, 7712, 420, 1507, 300, 291, 576, 5665, 51656], "temperature": 0.0, "avg_logprob": -0.09108835253222235, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.016296176239848137}, {"id": 537, "seek": 269304, "start": 2693.7599999999998, "end": 2698.56, "text": " yeah so I mean what I always recommend to people is Andrew Ung's Coursera course on", "tokens": [50400, 1338, 370, 286, 914, 437, 286, 1009, 2748, 281, 561, 307, 10110, 43559, 311, 383, 5067, 1663, 1164, 322, 50640], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 538, "seek": 269304, "start": 2698.56, "end": 2703.36, "text": " machine learning is a great place to start right now it's lower it's lower level so Andrew Ung is", "tokens": [50640, 3479, 2539, 307, 257, 869, 1081, 281, 722, 558, 586, 309, 311, 3126, 309, 311, 3126, 1496, 370, 10110, 43559, 307, 50880], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 539, "seek": 269304, "start": 2703.36, "end": 2708.4, "text": " is is very well known in the machine learning community he's you know he's he's done a load", "tokens": [50880, 307, 307, 588, 731, 2570, 294, 264, 3479, 2539, 1768, 415, 311, 291, 458, 415, 311, 415, 311, 1096, 257, 3677, 51132], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 540, "seek": 269304, "start": 2708.4, "end": 2713.36, "text": " of great work um his Coursera course is really good it's quite mathematical right so that isn't", "tokens": [51132, 295, 869, 589, 1105, 702, 383, 5067, 1663, 1164, 307, 534, 665, 309, 311, 1596, 18894, 558, 370, 300, 1943, 380, 51380], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 541, "seek": 269304, "start": 2713.36, "end": 2717.2, "text": " necessarily a problem you just have to go in knowing that's going to happen right but what it", "tokens": [51380, 4725, 257, 1154, 291, 445, 362, 281, 352, 294, 5276, 300, 311, 516, 281, 1051, 558, 457, 437, 309, 51572], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 542, "seek": 269304, "start": 2717.2, "end": 2722.24, "text": " does do is it gives you a lot of information on stuff that we haven't really talked about so things", "tokens": [51572, 775, 360, 307, 309, 2709, 291, 257, 688, 295, 1589, 322, 1507, 300, 321, 2378, 380, 534, 2825, 466, 370, 721, 51824], "temperature": 0.0, "avg_logprob": -0.09358524574952967, "compression_ratio": 1.8519736842105263, "no_speech_prob": 0.08608167618513107}, {"id": 543, "seek": 272224, "start": 2722.24, "end": 2726.7999999999997, "text": " like watching your learning rate your loss your your loss function go down right so if you if you", "tokens": [50364, 411, 1976, 428, 2539, 3314, 428, 4470, 428, 428, 4470, 2445, 352, 760, 558, 370, 498, 291, 498, 291, 50592], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 544, "seek": 272224, "start": 2726.7999999999997, "end": 2731.7599999999998, "text": " draw a graph of your loss which is your error at the end of your network over time what should", "tokens": [50592, 2642, 257, 4295, 295, 428, 4470, 597, 307, 428, 6713, 412, 264, 917, 295, 428, 3209, 670, 565, 437, 820, 50840], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 545, "seek": 272224, "start": 2731.7599999999998, "end": 2735.68, "text": " happen is it gets better and better right it goes down but it might not go down it might", "tokens": [50840, 1051, 307, 309, 2170, 1101, 293, 1101, 558, 309, 1709, 760, 457, 309, 1062, 406, 352, 760, 309, 1062, 51036], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 546, "seek": 272224, "start": 2735.68, "end": 2739.7599999999998, "text": " sort of do this a lot of machine learning is understanding what that means and what you could", "tokens": [51036, 1333, 295, 360, 341, 257, 688, 295, 3479, 2539, 307, 3701, 437, 300, 1355, 293, 437, 291, 727, 51240], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 547, "seek": 272224, "start": 2739.7599999999998, "end": 2743.52, "text": " try and do to rectify that problem you know for the first for your first day of machine learning", "tokens": [51240, 853, 293, 360, 281, 11048, 2505, 300, 1154, 291, 458, 337, 264, 700, 337, 428, 700, 786, 295, 3479, 2539, 51428], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 548, "seek": 272224, "start": 2743.52, "end": 2748.16, "text": " it's not important but over time some of the concepts that you talk about in this machine", "tokens": [51428, 309, 311, 406, 1021, 457, 670, 565, 512, 295, 264, 10392, 300, 291, 751, 466, 294, 341, 3479, 51660], "temperature": 0.0, "avg_logprob": -0.056235067546367645, "compression_ratio": 2.0586080586080584, "no_speech_prob": 0.010969109833240509}, {"id": 549, "seek": 274816, "start": 2748.24, "end": 2754.16, "text": " learning course will come in handy and there's a book by Yoshua Benjo called Deep Learning which", "tokens": [50368, 2539, 1164, 486, 808, 294, 13239, 293, 456, 311, 257, 1446, 538, 38949, 4398, 3964, 5134, 1219, 14895, 15205, 597, 50664], "temperature": 0.0, "avg_logprob": -0.10162648584088708, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.2663028836250305}, {"id": 550, "seek": 274816, "start": 2754.16, "end": 2759.7599999999998, "text": " also again a lot of maths in it but it covers a lot of the core concepts personally i'm a kind of", "tokens": [50664, 611, 797, 257, 688, 295, 36287, 294, 309, 457, 309, 10538, 257, 688, 295, 264, 4965, 10392, 5665, 741, 478, 257, 733, 295, 50944], "temperature": 0.0, "avg_logprob": -0.10162648584088708, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.2663028836250305}, {"id": 551, "seek": 274816, "start": 2759.7599999999998, "end": 2765.8399999999997, "text": " i've always been a kind of learn by doing kind of a person right and so in what i like to do is just", "tokens": [50944, 741, 600, 1009, 668, 257, 733, 295, 1466, 538, 884, 733, 295, 257, 954, 558, 293, 370, 294, 437, 741, 411, 281, 360, 307, 445, 51248], "temperature": 0.0, "avg_logprob": -0.10162648584088708, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.2663028836250305}, {"id": 552, "seek": 274816, "start": 2765.8399999999997, "end": 2770.0, "text": " get on the pie torch or the TensorFlow tutorials and just start running some stuff and see what", "tokens": [51248, 483, 322, 264, 1730, 27822, 420, 264, 37624, 17616, 293, 445, 722, 2614, 512, 1507, 293, 536, 437, 51456], "temperature": 0.0, "avg_logprob": -0.10162648584088708, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.2663028836250305}, {"id": 553, "seek": 274816, "start": 2770.0, "end": 2774.72, "text": " happens and if you know python or you know any language that's even plausibly similar to python", "tokens": [51456, 2314, 293, 498, 291, 458, 38797, 420, 291, 458, 604, 2856, 300, 311, 754, 34946, 3545, 2531, 281, 38797, 51692], "temperature": 0.0, "avg_logprob": -0.10162648584088708, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.2663028836250305}, {"id": 554, "seek": 277472, "start": 2774.72, "end": 2778.08, "text": " you're you know you're going to have you're going to have a great time doing that i think", "tokens": [50364, 291, 434, 291, 458, 291, 434, 516, 281, 362, 291, 434, 516, 281, 362, 257, 869, 565, 884, 300, 741, 519, 50532], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 555, "seek": 277472, "start": 2778.64, "end": 2782.0, "text": " especially for a lot of the audience if they starting out with us let's say there's younger", "tokens": [50560, 2318, 337, 257, 688, 295, 264, 4034, 498, 436, 2891, 484, 365, 505, 718, 311, 584, 456, 311, 7037, 50728], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 556, "seek": 277472, "start": 2782.0, "end": 2786.3199999999997, "text": " people who starting their careers and i spoke about this in the beginning about you know people", "tokens": [50728, 561, 567, 2891, 641, 16409, 293, 741, 7179, 466, 341, 294, 264, 2863, 466, 291, 458, 561, 50944], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 557, "seek": 277472, "start": 2786.3199999999997, "end": 2790.9599999999996, "text": " are worrying that this will take their jobs away but i'm assuming there's whenever i see the hype", "tokens": [50944, 366, 18788, 300, 341, 486, 747, 641, 4782, 1314, 457, 741, 478, 11926, 456, 311, 5699, 741, 536, 264, 24144, 51176], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 558, "seek": 277472, "start": 2790.9599999999996, "end": 2797.9199999999996, "text": " cycle there seems to be a lot of demand for ai skills huge demand yeah yeah there's a huge", "tokens": [51176, 6586, 456, 2544, 281, 312, 257, 688, 295, 4733, 337, 9783, 3942, 2603, 4733, 1338, 1338, 456, 311, 257, 2603, 51524], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 559, "seek": 277472, "start": 2797.9199999999996, "end": 2801.04, "text": " demand so i would say there's there's kind of you know you've got your different levels of", "tokens": [51524, 4733, 370, 741, 576, 584, 456, 311, 456, 311, 733, 295, 291, 458, 291, 600, 658, 428, 819, 4358, 295, 51680], "temperature": 0.0, "avg_logprob": -0.09692523315662646, "compression_ratio": 1.9892857142857143, "no_speech_prob": 0.0031669852323830128}, {"id": 560, "seek": 280104, "start": 2801.04, "end": 2805.12, "text": " sort of data analysts right so you've got people who are pretty good with a spreadsheet up to people", "tokens": [50364, 1333, 295, 1412, 31388, 558, 370, 291, 600, 658, 561, 567, 366, 1238, 665, 365, 257, 27733, 493, 281, 561, 50568], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 561, "seek": 280104, "start": 2805.12, "end": 2809.84, "text": " who are working trying to train self-driving cars and things i suppose if i'm being sort of a bit", "tokens": [50568, 567, 366, 1364, 1382, 281, 3847, 2698, 12, 47094, 5163, 293, 721, 741, 7297, 498, 741, 478, 885, 1333, 295, 257, 857, 50804], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 562, "seek": 280104, "start": 2809.84, "end": 2814.16, "text": " bit random in my choices of job description and you know you've got anywhere in between there's", "tokens": [50804, 857, 4974, 294, 452, 7994, 295, 1691, 3855, 293, 291, 458, 291, 600, 658, 4992, 294, 1296, 456, 311, 51020], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 563, "seek": 280104, "start": 2814.16, "end": 2819.6, "text": " huge demand everywhere so you know if you have any kind of data analysis ability if you can look at", "tokens": [51020, 2603, 4733, 5315, 370, 291, 458, 498, 291, 362, 604, 733, 295, 1412, 5215, 3485, 498, 291, 393, 574, 412, 51292], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 564, "seek": 280104, "start": 2819.6, "end": 2824.32, "text": " a table of data and start to pick out patterns and start to work out what's going on and make", "tokens": [51292, 257, 3199, 295, 1412, 293, 722, 281, 1888, 484, 8294, 293, 722, 281, 589, 484, 437, 311, 516, 322, 293, 652, 51528], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 565, "seek": 280104, "start": 2824.32, "end": 2829.36, "text": " predictions on that data that's a really useful skill to have in lots and lots of jobs it's a very", "tokens": [51528, 21264, 322, 300, 1412, 300, 311, 257, 534, 4420, 5389, 281, 362, 294, 3195, 293, 3195, 295, 4782, 309, 311, 257, 588, 51780], "temperature": 0.0, "avg_logprob": -0.060605436131574104, "compression_ratio": 1.8935483870967742, "no_speech_prob": 0.01669817417860031}, {"id": 566, "seek": 282936, "start": 2829.36, "end": 2834.7200000000003, "text": " very um very very popular thing that people have so a lot we have a lot of graduates who graduate", "tokens": [50364, 588, 1105, 588, 588, 3743, 551, 300, 561, 362, 370, 257, 688, 321, 362, 257, 688, 295, 13577, 567, 8080, 50632], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 567, "seek": 282936, "start": 2834.7200000000003, "end": 2839.76, "text": " with a few modules in machine learning and a few modules in data analysis and things like this and", "tokens": [50632, 365, 257, 1326, 16679, 294, 3479, 2539, 293, 257, 1326, 16679, 294, 1412, 5215, 293, 721, 411, 341, 293, 50884], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 568, "seek": 282936, "start": 2839.76, "end": 2843.6800000000003, "text": " they and they're in a really strong position these things are not you know you can learn these things", "tokens": [50884, 436, 293, 436, 434, 294, 257, 534, 2068, 2535, 613, 721, 366, 406, 291, 458, 291, 393, 1466, 613, 721, 51080], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 569, "seek": 282936, "start": 2843.6800000000003, "end": 2847.52, "text": " yourself so you know you can go in i've got a data analysis course it's not very long obviously", "tokens": [51080, 1803, 370, 291, 458, 291, 393, 352, 294, 741, 600, 658, 257, 1412, 5215, 1164, 309, 311, 406, 588, 938, 2745, 51272], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 570, "seek": 282936, "start": 2847.52, "end": 2852.1600000000003, "text": " because you know youtube videos but i have some data analysis videos there are lots of data analysis", "tokens": [51272, 570, 291, 458, 12487, 2145, 457, 741, 362, 512, 1412, 5215, 2145, 456, 366, 3195, 295, 1412, 5215, 51504], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 571, "seek": 282936, "start": 2852.1600000000003, "end": 2856.1600000000003, "text": " videos on your youtube channel yeah yeah on our youtube channel computer file we have like a 10", "tokens": [51504, 2145, 322, 428, 12487, 2269, 1338, 1338, 322, 527, 12487, 2269, 3820, 3991, 321, 362, 411, 257, 1266, 51704], "temperature": 0.0, "avg_logprob": -0.0683036730839656, "compression_ratio": 2.141304347826087, "no_speech_prob": 0.019075891003012657}, {"id": 572, "seek": 285616, "start": 2856.16, "end": 2860.48, "text": " part series on data analysis which is just kind of like a taster but you can have a go at that", "tokens": [50364, 644, 2638, 322, 1412, 5215, 597, 307, 445, 733, 295, 411, 257, 256, 1727, 457, 291, 393, 362, 257, 352, 412, 300, 50580], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 573, "seek": 285616, "start": 2860.48, "end": 2866.24, "text": " there's lots of stuff on data analysis data analysis and uh modeling and machine learning in some", "tokens": [50580, 456, 311, 3195, 295, 1507, 322, 1412, 5215, 1412, 5215, 293, 2232, 15983, 293, 3479, 2539, 294, 512, 50868], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 574, "seek": 285616, "start": 2866.24, "end": 2870.64, "text": " ways go hand in hand it's often good to have a little bit of a look at both of them because", "tokens": [50868, 2098, 352, 1011, 294, 1011, 309, 311, 2049, 665, 281, 362, 257, 707, 857, 295, 257, 574, 412, 1293, 295, 552, 570, 51088], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 575, "seek": 285616, "start": 2871.3599999999997, "end": 2876.08, "text": " you know cleaning data for example like you get you get a spreadsheet of data but doesn't make any", "tokens": [51124, 291, 458, 8924, 1412, 337, 1365, 411, 291, 483, 291, 483, 257, 27733, 295, 1412, 457, 1177, 380, 652, 604, 51360], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 576, "seek": 285616, "start": 2876.08, "end": 2880.56, "text": " sense it's unwise just to stick that straight into a neural network and see what you get out because", "tokens": [51360, 2020, 309, 311, 517, 3711, 445, 281, 2897, 300, 2997, 666, 257, 18161, 3209, 293, 536, 437, 291, 483, 484, 570, 51584], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 577, "seek": 285616, "start": 2880.56, "end": 2885.3599999999997, "text": " there could be some complete you know it could be missing values there could be errors they could", "tokens": [51584, 456, 727, 312, 512, 3566, 291, 458, 309, 727, 312, 5361, 4190, 456, 727, 312, 13603, 436, 727, 51824], "temperature": 0.0, "avg_logprob": -0.04970295164320204, "compression_ratio": 1.9464882943143813, "no_speech_prob": 0.07888233661651611}, {"id": 578, "seek": 288536, "start": 2885.36, "end": 2890.08, "text": " all just have hugely different scales of data these are all things to think about so some knowledge", "tokens": [50364, 439, 445, 362, 27417, 819, 17408, 295, 1412, 613, 366, 439, 721, 281, 519, 466, 370, 512, 3601, 50600], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 579, "seek": 288536, "start": 2890.08, "end": 2894.6400000000003, "text": " of how to prepare that data for let's say a downstream task like machine learning it's a", "tokens": [50600, 295, 577, 281, 5940, 300, 1412, 337, 718, 311, 584, 257, 30621, 5633, 411, 3479, 2539, 309, 311, 257, 50828], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 580, "seek": 288536, "start": 2894.6400000000003, "end": 2898.96, "text": " really useful thing to know how to do as well i love that you're teaching at the university you're", "tokens": [50828, 534, 4420, 551, 281, 458, 577, 281, 360, 382, 731, 741, 959, 300, 291, 434, 4571, 412, 264, 5454, 291, 434, 51044], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 581, "seek": 288536, "start": 2898.96, "end": 2904.48, "text": " teaching security cybersecurity type stuff but you're also doing AI so there you see that like", "tokens": [51044, 4571, 3825, 38765, 2010, 1507, 457, 291, 434, 611, 884, 7318, 370, 456, 291, 536, 300, 411, 51320], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 582, "seek": 288536, "start": 2904.48, "end": 2909.04, "text": " that's a really good mix and i'm assuming based on what you've just said you know it's a really good", "tokens": [51320, 300, 311, 257, 534, 665, 2890, 293, 741, 478, 11926, 2361, 322, 437, 291, 600, 445, 848, 291, 458, 309, 311, 257, 534, 665, 51548], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 583, "seek": 288536, "start": 2909.04, "end": 2913.2000000000003, "text": " idea if you if you if you're into cyber or want to get into cyber to you know add this to your", "tokens": [51548, 1558, 498, 291, 498, 291, 498, 291, 434, 666, 13411, 420, 528, 281, 483, 666, 13411, 281, 291, 458, 909, 341, 281, 428, 51756], "temperature": 0.0, "avg_logprob": -0.05530434496262494, "compression_ratio": 1.9395973154362416, "no_speech_prob": 0.002001717686653137}, {"id": 584, "seek": 291320, "start": 2913.2799999999997, "end": 2917.12, "text": " skill set yeah i mean i would be hard pressed to find any career that wouldn't be at least helped", "tokens": [50368, 5389, 992, 1338, 741, 914, 741, 576, 312, 1152, 17355, 281, 915, 604, 3988, 300, 2759, 380, 312, 412, 1935, 4254, 50560], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 585, "seek": 291320, "start": 2917.12, "end": 2920.96, "text": " a little bit by knowing some data analysis of machine learning because just it just comes up a", "tokens": [50560, 257, 707, 857, 538, 5276, 512, 1412, 5215, 295, 3479, 2539, 570, 445, 309, 445, 1487, 493, 257, 50752], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 586, "seek": 291320, "start": 2920.96, "end": 2927.12, "text": " lot right you know and and also i mean as you know we already spoke about how people can be misled", "tokens": [50752, 688, 558, 291, 458, 293, 293, 611, 741, 914, 382, 291, 458, 321, 1217, 7179, 466, 577, 561, 393, 312, 3346, 1493, 51060], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 587, "seek": 291320, "start": 2927.12, "end": 2932.64, "text": " by the hype cycle right and and you will be much more resistant to this if you understand how these", "tokens": [51060, 538, 264, 24144, 6586, 558, 293, 293, 291, 486, 312, 709, 544, 20383, 281, 341, 498, 291, 1223, 577, 613, 51336], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 588, "seek": 291320, "start": 2932.64, "end": 2938.3199999999997, "text": " things work and that's going to put you in a good position i yeah i i think that um so i as it happens", "tokens": [51336, 721, 589, 293, 300, 311, 516, 281, 829, 291, 294, 257, 665, 2535, 741, 1338, 741, 741, 519, 300, 1105, 370, 741, 382, 309, 2314, 51620], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 589, "seek": 291320, "start": 2938.3199999999997, "end": 2942.24, "text": " i teach security i partly i find it really interesting so i try and cling on to that module", "tokens": [51620, 741, 2924, 3825, 741, 17031, 741, 915, 309, 534, 1880, 370, 741, 853, 293, 35986, 322, 281, 300, 10088, 51816], "temperature": 0.0, "avg_logprob": -0.08703200937175065, "compression_ratio": 1.808641975308642, "no_speech_prob": 0.02726978436112404}, {"id": 590, "seek": 294224, "start": 2942.24, "end": 2948.56, "text": " with you know with a with a vice grip and not let anyone else have it um i also teach cryptography", "tokens": [50364, 365, 291, 458, 365, 257, 365, 257, 11964, 12007, 293, 406, 718, 2878, 1646, 362, 309, 1105, 741, 611, 2924, 9844, 5820, 50680], "temperature": 0.0, "avg_logprob": -0.11644142920817804, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.0022421744652092457}, {"id": 591, "seek": 294224, "start": 2948.56, "end": 2954.0, "text": " uh at at university as well and get you back for some more interviews man yeah right so yeah by", "tokens": [50680, 2232, 412, 412, 5454, 382, 731, 293, 483, 291, 646, 337, 512, 544, 12318, 587, 1338, 558, 370, 1338, 538, 50952], "temperature": 0.0, "avg_logprob": -0.11644142920817804, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.0022421744652092457}, {"id": 592, "seek": 294224, "start": 2954.0, "end": 2959.04, "text": " all means but so those are subjects i find i don't actively research day to day but i do find very", "tokens": [50952, 439, 1355, 457, 370, 729, 366, 13066, 741, 915, 741, 500, 380, 13022, 2132, 786, 281, 786, 457, 741, 360, 915, 588, 51204], "temperature": 0.0, "avg_logprob": -0.11644142920817804, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.0022421744652092457}, {"id": 593, "seek": 294224, "start": 2959.04, "end": 2962.9599999999996, "text": " very interesting and i do have some collaborations with because we have actual security researchers", "tokens": [51204, 588, 1880, 293, 741, 360, 362, 512, 36908, 365, 570, 321, 362, 3539, 3825, 10309, 51400], "temperature": 0.0, "avg_logprob": -0.11644142920817804, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.0022421744652092457}, {"id": 594, "seek": 294224, "start": 2962.9599999999996, "end": 2966.9599999999996, "text": " working at nottingham in lots of places we have good collaborations with them there is obviously", "tokens": [51400, 1364, 412, 406, 783, 4822, 294, 3195, 295, 3190, 321, 362, 665, 36908, 365, 552, 456, 307, 2745, 51600], "temperature": 0.0, "avg_logprob": -0.11644142920817804, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.0022421744652092457}, {"id": 595, "seek": 296696, "start": 2966.96, "end": 2972.0, "text": " machine learning involved in quite a lot of security because it's a it's a it's one of many", "tokens": [50364, 3479, 2539, 3288, 294, 1596, 257, 688, 295, 3825, 570, 309, 311, 257, 309, 311, 257, 309, 311, 472, 295, 867, 50616], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 596, "seek": 296696, "start": 2972.0, "end": 2978.16, "text": " strategies for detecting malware or for anomaly detection or you know any smart system that's", "tokens": [50616, 9029, 337, 40237, 40747, 420, 337, 42737, 17784, 420, 291, 458, 604, 4069, 1185, 300, 311, 50924], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 597, "seek": 296696, "start": 2978.16, "end": 2982.56, "text": " doing something but hopefully you don't have to program all the rules yourself so yeah it does it", "tokens": [50924, 884, 746, 457, 4696, 291, 500, 380, 362, 281, 1461, 439, 264, 4474, 1803, 370, 1338, 309, 775, 309, 51144], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 598, "seek": 296696, "start": 2982.56, "end": 2986.8, "text": " does help i've got i think i've got a project uh an undergraduate student starting who's going to", "tokens": [51144, 775, 854, 741, 600, 658, 741, 519, 741, 600, 658, 257, 1716, 2232, 364, 19113, 3107, 2891, 567, 311, 516, 281, 51356], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 599, "seek": 296696, "start": 2986.8, "end": 2990.56, "text": " look at malware detection with a bit of machine learning as well and so she can bring the knowledge", "tokens": [51356, 574, 412, 40747, 17784, 365, 257, 857, 295, 3479, 2539, 382, 731, 293, 370, 750, 393, 1565, 264, 3601, 51544], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 600, "seek": 296696, "start": 2990.56, "end": 2995.2, "text": " of the malware i can bring the knowledge of the uh of mostly the ai you know and it'll be it'll be", "tokens": [51544, 295, 264, 40747, 741, 393, 1565, 264, 3601, 295, 264, 2232, 295, 5240, 264, 9783, 291, 458, 293, 309, 603, 312, 309, 603, 312, 51776], "temperature": 0.0, "avg_logprob": -0.05745635459672159, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.4129082262516022}, {"id": 601, "seek": 299520, "start": 2995.2, "end": 2999.7599999999998, "text": " great mic i always like to ask this question um if you were talking to your younger self let's say", "tokens": [50364, 869, 3123, 741, 1009, 411, 281, 1029, 341, 1168, 1105, 498, 291, 645, 1417, 281, 428, 7037, 2698, 718, 311, 584, 50592], "temperature": 0.0, "avg_logprob": -0.09744362871186073, "compression_ratio": 1.813868613138686, "no_speech_prob": 0.024199457839131355}, {"id": 602, "seek": 299520, "start": 2999.7599999999998, "end": 3005.3599999999997, "text": " you were 18 or you know i don't know let's say not everyone is 18 who watches these videos but let's", "tokens": [50592, 291, 645, 2443, 420, 291, 458, 741, 500, 380, 458, 718, 311, 584, 406, 1518, 307, 2443, 567, 17062, 613, 2145, 457, 718, 311, 50872], "temperature": 0.0, "avg_logprob": -0.09744362871186073, "compression_ratio": 1.813868613138686, "no_speech_prob": 0.024199457839131355}, {"id": 603, "seek": 299520, "start": 3005.3599999999997, "end": 3010.16, "text": " say they were 25 30 whatever yeah what would you advise someone to do based on you know what you've", "tokens": [50872, 584, 436, 645, 3552, 2217, 2035, 1338, 437, 576, 291, 18312, 1580, 281, 360, 2361, 322, 291, 458, 437, 291, 600, 51112], "temperature": 0.0, "avg_logprob": -0.09744362871186073, "compression_ratio": 1.813868613138686, "no_speech_prob": 0.024199457839131355}, {"id": 604, "seek": 299520, "start": 3010.16, "end": 3015.4399999999996, "text": " seen i think if you're if you're really interested in it in a career in cyber security or a career in", "tokens": [51112, 1612, 741, 519, 498, 291, 434, 498, 291, 434, 534, 3102, 294, 309, 294, 257, 3988, 294, 13411, 3825, 420, 257, 3988, 294, 51376], "temperature": 0.0, "avg_logprob": -0.09744362871186073, "compression_ratio": 1.813868613138686, "no_speech_prob": 0.024199457839131355}, {"id": 605, "seek": 299520, "start": 3015.4399999999996, "end": 3020.96, "text": " uh machine learning it's worth noting that not everyone has a degree that does those things and", "tokens": [51376, 2232, 3479, 2539, 309, 311, 3163, 26801, 300, 406, 1518, 575, 257, 4314, 300, 775, 729, 721, 293, 51652], "temperature": 0.0, "avg_logprob": -0.09744362871186073, "compression_ratio": 1.813868613138686, "no_speech_prob": 0.024199457839131355}, {"id": 606, "seek": 302096, "start": 3020.96, "end": 3025.52, "text": " that's fine right it's also fine if you do have a degree i see people saying well you don't need a", "tokens": [50364, 300, 311, 2489, 558, 309, 311, 611, 2489, 498, 291, 360, 362, 257, 4314, 741, 536, 561, 1566, 731, 291, 500, 380, 643, 257, 50592], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 607, "seek": 302096, "start": 3025.52, "end": 3030.32, "text": " degree for this or you do need a degree for this i actually think learn the skills right and then", "tokens": [50592, 4314, 337, 341, 420, 291, 360, 643, 257, 4314, 337, 341, 741, 767, 519, 1466, 264, 3942, 558, 293, 550, 50832], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 608, "seek": 302096, "start": 3030.32, "end": 3034.4, "text": " you get a job based on your experience it's you know and you're going to have a great time i think", "tokens": [50832, 291, 483, 257, 1691, 2361, 322, 428, 1752, 309, 311, 291, 458, 293, 291, 434, 516, 281, 362, 257, 869, 565, 741, 519, 51036], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 609, "seek": 302096, "start": 3034.4, "end": 3037.76, "text": " that again it's not one of these debates i like to get into because everyone has their own career", "tokens": [51036, 300, 797, 309, 311, 406, 472, 295, 613, 24203, 741, 411, 281, 483, 666, 570, 1518, 575, 641, 1065, 3988, 51204], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 610, "seek": 302096, "start": 3037.76, "end": 3041.6, "text": " path that they want to follow if you're if you're if you did a degree in something completely different", "tokens": [51204, 3100, 300, 436, 528, 281, 1524, 498, 291, 434, 498, 291, 434, 498, 291, 630, 257, 4314, 294, 746, 2584, 819, 51396], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 611, "seek": 302096, "start": 3041.6, "end": 3044.7200000000003, "text": " and you've worked in a job you're not really enjoying and you want to try something new i think", "tokens": [51396, 293, 291, 600, 2732, 294, 257, 1691, 291, 434, 406, 534, 9929, 293, 291, 528, 281, 853, 746, 777, 741, 519, 51552], "temperature": 0.0, "avg_logprob": -0.054396125820133236, "compression_ratio": 1.9966329966329965, "no_speech_prob": 0.050207141786813736}, {"id": 612, "seek": 304472, "start": 3044.72, "end": 3050.72, "text": " that's absolutely fine have a go there's so many resources online that there weren't 20 30 years ago", "tokens": [50364, 300, 311, 3122, 2489, 362, 257, 352, 456, 311, 370, 867, 3593, 2950, 300, 456, 4999, 380, 945, 2217, 924, 2057, 50664], "temperature": 0.0, "avg_logprob": -0.07778659661610922, "compression_ratio": 1.74822695035461, "no_speech_prob": 0.14947383105754852}, {"id": 613, "seek": 304472, "start": 3051.2799999999997, "end": 3055.2799999999997, "text": " that there are you know people doing interviews and videos on different topics that you can just", "tokens": [50692, 300, 456, 366, 291, 458, 561, 884, 12318, 293, 2145, 322, 819, 8378, 300, 291, 393, 445, 50892], "temperature": 0.0, "avg_logprob": -0.07778659661610922, "compression_ratio": 1.74822695035461, "no_speech_prob": 0.14947383105754852}, {"id": 614, "seek": 304472, "start": 3055.2799999999997, "end": 3060.72, "text": " watch and learn about and as i say i'm a very hands-on person if i want to try and learn a skill", "tokens": [50892, 1159, 293, 1466, 466, 293, 382, 741, 584, 741, 478, 257, 588, 2377, 12, 266, 954, 498, 741, 528, 281, 853, 293, 1466, 257, 5389, 51164], "temperature": 0.0, "avg_logprob": -0.07778659661610922, "compression_ratio": 1.74822695035461, "no_speech_prob": 0.14947383105754852}, {"id": 615, "seek": 304472, "start": 3060.72, "end": 3066.48, "text": " i'm just going to try and do it and it will probably go really wrong the first time um so i think that", "tokens": [51164, 741, 478, 445, 516, 281, 853, 293, 360, 309, 293, 309, 486, 1391, 352, 534, 2085, 264, 700, 565, 1105, 370, 741, 519, 300, 51452], "temperature": 0.0, "avg_logprob": -0.07778659661610922, "compression_ratio": 1.74822695035461, "no_speech_prob": 0.14947383105754852}, {"id": 616, "seek": 304472, "start": 3067.12, "end": 3073.12, "text": " practice right and this is true of coding as well i think i'm big big um believer but coding is", "tokens": [51484, 3124, 558, 293, 341, 307, 2074, 295, 17720, 382, 731, 741, 519, 741, 478, 955, 955, 1105, 23892, 457, 17720, 307, 51784], "temperature": 0.0, "avg_logprob": -0.07778659661610922, "compression_ratio": 1.74822695035461, "no_speech_prob": 0.14947383105754852}, {"id": 617, "seek": 307312, "start": 3073.2, "end": 3076.96, "text": " mostly practice people say like how did you know that was going to be a bug because i've seen it", "tokens": [50368, 5240, 3124, 561, 584, 411, 577, 630, 291, 458, 300, 390, 516, 281, 312, 257, 7426, 570, 741, 600, 1612, 309, 50556], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 618, "seek": 307312, "start": 3076.96, "end": 3081.6, "text": " so many times before you know like because it happens all the time i think yeah that would be", "tokens": [50556, 370, 867, 1413, 949, 291, 458, 411, 570, 309, 2314, 439, 264, 565, 741, 519, 1338, 300, 576, 312, 50788], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 619, "seek": 307312, "start": 3081.6, "end": 3086.4, "text": " what i would do find something you love doing and do more of that you know i program at home for fun", "tokens": [50788, 437, 741, 576, 360, 915, 746, 291, 959, 884, 293, 360, 544, 295, 300, 291, 458, 741, 1461, 412, 1280, 337, 1019, 51028], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 620, "seek": 307312, "start": 3086.4, "end": 3090.64, "text": " and it's partly because i find it fun and also sometimes i want to learn something new i did a", "tokens": [51028, 293, 309, 311, 17031, 570, 741, 915, 309, 1019, 293, 611, 2171, 741, 528, 281, 1466, 746, 777, 741, 630, 257, 51240], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 621, "seek": 307312, "start": 3090.64, "end": 3095.7599999999998, "text": " video a year or two ago on the enigma machine right i don't need to program the enigma machine", "tokens": [51240, 960, 257, 1064, 420, 732, 2057, 322, 264, 465, 16150, 3479, 558, 741, 500, 380, 643, 281, 1461, 264, 465, 16150, 3479, 51496], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 622, "seek": 307312, "start": 3095.7599999999998, "end": 3099.44, "text": " for my job i just thought it was super interesting and i just sat at home and did it and i learned", "tokens": [51496, 337, 452, 1691, 741, 445, 1194, 309, 390, 1687, 1880, 293, 741, 445, 3227, 412, 1280, 293, 630, 309, 293, 741, 3264, 51680], "temperature": 0.0, "avg_logprob": -0.04201287073446504, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.034035686403512955}, {"id": 623, "seek": 309944, "start": 3099.44, "end": 3103.76, "text": " quite a lot actually about the whole process and the history of it by just having to implement the", "tokens": [50364, 1596, 257, 688, 767, 466, 264, 1379, 1399, 293, 264, 2503, 295, 309, 538, 445, 1419, 281, 4445, 264, 50580], "temperature": 0.0, "avg_logprob": -0.07291543868280226, "compression_ratio": 1.8976377952755905, "no_speech_prob": 0.046363383531570435}, {"id": 624, "seek": 309944, "start": 3103.76, "end": 3109.2000000000003, "text": " thing and so i think yeah i think crack on and learn would be what i would do i love that i mean", "tokens": [50580, 551, 293, 370, 741, 519, 1338, 741, 519, 6226, 322, 293, 1466, 576, 312, 437, 741, 576, 360, 741, 959, 300, 741, 914, 50852], "temperature": 0.0, "avg_logprob": -0.07291543868280226, "compression_ratio": 1.8976377952755905, "no_speech_prob": 0.046363383531570435}, {"id": 625, "seek": 309944, "start": 3109.2000000000003, "end": 3116.4, "text": " and i just have to say this you are doctor uh mike you you you got phd yeah is that right in", "tokens": [50852, 293, 741, 445, 362, 281, 584, 341, 291, 366, 4631, 2232, 43357, 291, 291, 291, 658, 903, 67, 1338, 307, 300, 558, 294, 51212], "temperature": 0.0, "avg_logprob": -0.07291543868280226, "compression_ratio": 1.8976377952755905, "no_speech_prob": 0.046363383531570435}, {"id": 626, "seek": 309944, "start": 3116.4, "end": 3121.28, "text": " what in what was it in computer vision so i mean what i really love about this and um this is just", "tokens": [51212, 437, 294, 437, 390, 309, 294, 3820, 5201, 370, 741, 914, 437, 741, 534, 959, 466, 341, 293, 1105, 341, 307, 445, 51456], "temperature": 0.0, "avg_logprob": -0.07291543868280226, "compression_ratio": 1.8976377952755905, "no_speech_prob": 0.046363383531570435}, {"id": 627, "seek": 309944, "start": 3121.28, "end": 3128.08, "text": " my opinion so i don't want to put you on the spot but um i love that you as someone with a phd", "tokens": [51456, 452, 4800, 370, 741, 500, 380, 528, 281, 829, 291, 322, 264, 4008, 457, 1105, 741, 959, 300, 291, 382, 1580, 365, 257, 903, 67, 51796], "temperature": 0.0, "avg_logprob": -0.07291543868280226, "compression_ratio": 1.8976377952755905, "no_speech_prob": 0.046363383531570435}, {"id": 628, "seek": 312808, "start": 3128.88, "end": 3134.3199999999997, "text": " are not excluding excluding people who perhaps never had that opportunity and i love that you're", "tokens": [50404, 366, 406, 49999, 49999, 561, 567, 4317, 1128, 632, 300, 2650, 293, 741, 959, 300, 291, 434, 50676], "temperature": 0.0, "avg_logprob": -0.08748100571713205, "compression_ratio": 1.8131868131868132, "no_speech_prob": 0.013988056220114231}, {"id": 629, "seek": 312808, "start": 3134.3199999999997, "end": 3139.84, "text": " encouraging everyone you know just to go for it don't let your limitations or yeah lack of resources", "tokens": [50676, 14580, 1518, 291, 458, 445, 281, 352, 337, 309, 500, 380, 718, 428, 15705, 420, 1338, 5011, 295, 3593, 50952], "temperature": 0.0, "avg_logprob": -0.08748100571713205, "compression_ratio": 1.8131868131868132, "no_speech_prob": 0.013988056220114231}, {"id": 630, "seek": 312808, "start": 3139.84, "end": 3144.24, "text": " stop you sorry i mean as it happens like i wasn't i was a pretty average student at school right i", "tokens": [50952, 1590, 291, 2597, 741, 914, 382, 309, 2314, 411, 741, 2067, 380, 741, 390, 257, 1238, 4274, 3107, 412, 1395, 558, 741, 51172], "temperature": 0.0, "avg_logprob": -0.08748100571713205, "compression_ratio": 1.8131868131868132, "no_speech_prob": 0.013988056220114231}, {"id": 631, "seek": 312808, "start": 3144.24, "end": 3150.0, "text": " mean i i didn't i didn't do much much there wasn't much in terms of computer science um in at school", "tokens": [51172, 914, 741, 741, 994, 380, 741, 994, 380, 360, 709, 709, 456, 2067, 380, 709, 294, 2115, 295, 3820, 3497, 1105, 294, 412, 1395, 51460], "temperature": 0.0, "avg_logprob": -0.08748100571713205, "compression_ratio": 1.8131868131868132, "no_speech_prob": 0.013988056220114231}, {"id": 632, "seek": 312808, "start": 3150.0, "end": 3155.6, "text": " when i was younger it was it was you know let's use microsoft word and and and let's try that out", "tokens": [51460, 562, 741, 390, 7037, 309, 390, 309, 390, 291, 458, 718, 311, 764, 3123, 7856, 1349, 293, 293, 293, 718, 311, 853, 300, 484, 51740], "temperature": 0.0, "avg_logprob": -0.08748100571713205, "compression_ratio": 1.8131868131868132, "no_speech_prob": 0.013988056220114231}, {"id": 633, "seek": 315560, "start": 3155.6, "end": 3159.52, "text": " and so i didn't i barely did any computing at all i could only a little i could only a program", "tokens": [50364, 293, 370, 741, 994, 380, 741, 10268, 630, 604, 15866, 412, 439, 741, 727, 787, 257, 707, 741, 727, 787, 257, 1461, 50560], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 634, "seek": 315560, "start": 3159.52, "end": 3165.2, "text": " a tiny bit when i arrived at university loads of people arrive at university with huge programming", "tokens": [50560, 257, 5870, 857, 562, 741, 6678, 412, 5454, 12668, 295, 561, 8881, 412, 5454, 365, 2603, 9410, 50844], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 635, "seek": 315560, "start": 3165.2, "end": 3169.8399999999997, "text": " experience but and loads of people arrive with no programming experience and we always say to them", "tokens": [50844, 1752, 457, 293, 12668, 295, 561, 8881, 365, 572, 9410, 1752, 293, 321, 1009, 584, 281, 552, 51076], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 636, "seek": 315560, "start": 3169.8399999999997, "end": 3174.64, "text": " you'll all be the same in the end right like that's the whole point of a degree and it's a whole", "tokens": [51076, 291, 603, 439, 312, 264, 912, 294, 264, 917, 558, 411, 300, 311, 264, 1379, 935, 295, 257, 4314, 293, 309, 311, 257, 1379, 51316], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 637, "seek": 315560, "start": 3174.64, "end": 3179.2799999999997, "text": " point of what we teach i think that it's never too late to get to get into computers and learn", "tokens": [51316, 935, 295, 437, 321, 2924, 741, 519, 300, 309, 311, 1128, 886, 3469, 281, 483, 281, 483, 666, 10807, 293, 1466, 51548], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 638, "seek": 315560, "start": 3179.2799999999997, "end": 3182.7999999999997, "text": " about programming and stuff i try and teach people to program all the time i mean not all of them", "tokens": [51548, 466, 9410, 293, 1507, 741, 853, 293, 2924, 561, 281, 1461, 439, 264, 565, 741, 914, 406, 439, 295, 552, 51724], "temperature": 0.0, "avg_logprob": -0.07517316606309679, "compression_ratio": 2.0492957746478875, "no_speech_prob": 0.012111177667975426}, {"id": 639, "seek": 318280, "start": 3182.8, "end": 3188.2400000000002, "text": " were interested which is annoying um but you know so like if it was up to me all my family", "tokens": [50364, 645, 3102, 597, 307, 11304, 1105, 457, 291, 458, 370, 411, 498, 309, 390, 493, 281, 385, 439, 452, 1605, 50636], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 640, "seek": 318280, "start": 3188.2400000000002, "end": 3191.76, "text": " would be able to program because i'd be giving them extra lessons but some of them want to do", "tokens": [50636, 576, 312, 1075, 281, 1461, 570, 741, 1116, 312, 2902, 552, 2857, 8820, 457, 512, 295, 552, 528, 281, 360, 50812], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 641, "seek": 318280, "start": 3191.76, "end": 3196.1600000000003, "text": " other things apparently but yeah i'm not i'm not a gate i don't want to be a gatekeeper because", "tokens": [50812, 661, 721, 7970, 457, 1338, 741, 478, 406, 741, 478, 406, 257, 8539, 741, 500, 380, 528, 281, 312, 257, 8539, 23083, 570, 51032], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 642, "seek": 318280, "start": 3196.96, "end": 3201.28, "text": " that's not going to get more people doing cool computer stuff there are some things where a", "tokens": [51072, 300, 311, 406, 516, 281, 483, 544, 561, 884, 1627, 3820, 1507, 456, 366, 512, 721, 689, 257, 51288], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 643, "seek": 318280, "start": 3201.28, "end": 3205.6000000000004, "text": " massive specialism is important right you know i'm not proposing to go into a hospital and start", "tokens": [51288, 5994, 2121, 1434, 307, 1021, 558, 291, 458, 741, 478, 406, 29939, 281, 352, 666, 257, 4530, 293, 722, 51504], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 644, "seek": 318280, "start": 3205.6000000000004, "end": 3209.44, "text": " surgery on people because you need a lot of training to do these things but i also think", "tokens": [51504, 7930, 322, 561, 570, 291, 643, 257, 688, 295, 3097, 281, 360, 613, 721, 457, 741, 611, 519, 51696], "temperature": 0.0, "avg_logprob": -0.071346767020948, "compression_ratio": 1.8476821192052981, "no_speech_prob": 0.09344654530286789}, {"id": 645, "seek": 320944, "start": 3209.44, "end": 3213.84, "text": " that if someone wanted to be a surgeon they should crack on and do the training right you know you", "tokens": [50364, 300, 498, 1580, 1415, 281, 312, 257, 22913, 436, 820, 6226, 322, 293, 360, 264, 3097, 558, 291, 458, 291, 50584], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 646, "seek": 320944, "start": 3213.84, "end": 3219.76, "text": " know i think you can learn those skills um and you know we require if you're going to work at", "tokens": [50584, 458, 741, 519, 291, 393, 1466, 729, 3942, 1105, 293, 291, 458, 321, 3651, 498, 291, 434, 516, 281, 589, 412, 50880], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 647, "seek": 320944, "start": 3219.76, "end": 3225.04, "text": " university we usually require a phd and that's something that universities require but there's", "tokens": [50880, 5454, 321, 2673, 3651, 257, 903, 67, 293, 300, 311, 746, 300, 11779, 3651, 457, 456, 311, 51144], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 648, "seek": 320944, "start": 3225.04, "end": 3228.7200000000003, "text": " a great deal i don't know about the real world and industry about people who are watching will", "tokens": [51144, 257, 869, 2028, 741, 500, 380, 458, 466, 264, 957, 1002, 293, 3518, 466, 561, 567, 366, 1976, 486, 51328], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 649, "seek": 320944, "start": 3228.7200000000003, "end": 3233.6, "text": " know way more about than me and that's also fine right you know everyone's got their own expertise", "tokens": [51328, 458, 636, 544, 466, 813, 385, 293, 300, 311, 611, 2489, 558, 291, 458, 1518, 311, 658, 641, 1065, 11769, 51572], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 650, "seek": 320944, "start": 3233.6, "end": 3238.4, "text": " so i like to learn from those people and hope i can teach them a bit about the things i know about", "tokens": [51572, 370, 741, 411, 281, 1466, 490, 729, 561, 293, 1454, 741, 393, 2924, 552, 257, 857, 466, 264, 721, 741, 458, 466, 51812], "temperature": 0.0, "avg_logprob": -0.04770893082582861, "compression_ratio": 1.939799331103679, "no_speech_prob": 0.09023798257112503}, {"id": 651, "seek": 323840, "start": 3238.4, "end": 3243.92, "text": " i love that i love that another thing i mean i i said 18 but i i get a lot of pushback sometimes", "tokens": [50364, 741, 959, 300, 741, 959, 300, 1071, 551, 741, 914, 741, 741, 848, 2443, 457, 741, 741, 483, 257, 688, 295, 2944, 3207, 2171, 50640], "temperature": 0.0, "avg_logprob": -0.06388720222141432, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0021387548185884953}, {"id": 652, "seek": 323840, "start": 3243.92, "end": 3249.12, "text": " on these videos and i'm not sure if you've heard this question before am i too old to start learning", "tokens": [50640, 322, 613, 2145, 293, 741, 478, 406, 988, 498, 291, 600, 2198, 341, 1168, 949, 669, 741, 886, 1331, 281, 722, 2539, 50900], "temperature": 0.0, "avg_logprob": -0.06388720222141432, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0021387548185884953}, {"id": 653, "seek": 323840, "start": 3249.12, "end": 3255.92, "text": " ai no um no i mean consider also that the majority of academics who are using ai aren't", "tokens": [50900, 9783, 572, 1105, 572, 741, 914, 1949, 611, 300, 264, 6286, 295, 25695, 567, 366, 1228, 9783, 3212, 380, 51240], "temperature": 0.0, "avg_logprob": -0.06388720222141432, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0021387548185884953}, {"id": 654, "seek": 323840, "start": 3256.56, "end": 3262.56, "text": " 18 year old fresh graduates they are researchers that have been doing it for decades because you", "tokens": [51272, 2443, 1064, 1331, 4451, 13577, 436, 366, 10309, 300, 362, 668, 884, 309, 337, 7878, 570, 291, 51572], "temperature": 0.0, "avg_logprob": -0.06388720222141432, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0021387548185884953}, {"id": 655, "seek": 323840, "start": 3262.56, "end": 3266.32, "text": " know so we've all had to learn it from scratch as well right like i say deep learning only appeared", "tokens": [51572, 458, 370, 321, 600, 439, 632, 281, 1466, 309, 490, 8459, 382, 731, 558, 411, 741, 584, 2452, 2539, 787, 8516, 51760], "temperature": 0.0, "avg_logprob": -0.06388720222141432, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0021387548185884953}, {"id": 656, "seek": 326632, "start": 3266.32, "end": 3272.4, "text": " in 2014 so it's been a mad rush since then there's loads of scope to learn um and i don't think it", "tokens": [50364, 294, 8227, 370, 309, 311, 668, 257, 5244, 9300, 1670, 550, 456, 311, 12668, 295, 11923, 281, 1466, 1105, 293, 741, 500, 380, 519, 309, 50668], "temperature": 0.0, "avg_logprob": -0.04704516675291943, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.01514589786529541}, {"id": 657, "seek": 326632, "start": 3272.4, "end": 3276.48, "text": " takes to get a little bit going it doesn't take that many hours you know if you want to do something", "tokens": [50668, 2516, 281, 483, 257, 707, 857, 516, 309, 1177, 380, 747, 300, 867, 2496, 291, 458, 498, 291, 528, 281, 360, 746, 50872], "temperature": 0.0, "avg_logprob": -0.04704516675291943, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.01514589786529541}, {"id": 658, "seek": 326632, "start": 3276.48, "end": 3280.88, "text": " you know around your job or whatever it is your current life situation is i think it's doable", "tokens": [50872, 291, 458, 926, 428, 1691, 420, 2035, 309, 307, 428, 2190, 993, 2590, 307, 741, 519, 309, 311, 41183, 51092], "temperature": 0.0, "avg_logprob": -0.04704516675291943, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.01514589786529541}, {"id": 659, "seek": 326632, "start": 3280.88, "end": 3286.7200000000003, "text": " i love that any closing thoughts no i think um i hope people found it interesting right and i", "tokens": [51092, 741, 959, 300, 604, 10377, 4598, 572, 741, 519, 1105, 741, 1454, 561, 1352, 309, 1880, 558, 293, 741, 51384], "temperature": 0.0, "avg_logprob": -0.04704516675291943, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.01514589786529541}, {"id": 660, "seek": 326632, "start": 3286.7200000000003, "end": 3291.84, "text": " happy to come back and talk about more topics in detail but i think that you know i love um i love", "tokens": [51384, 2055, 281, 808, 646, 293, 751, 466, 544, 8378, 294, 2607, 457, 741, 519, 300, 291, 458, 741, 959, 1105, 741, 959, 51640], "temperature": 0.0, "avg_logprob": -0.04704516675291943, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.01514589786529541}, {"id": 661, "seek": 329184, "start": 3291.84, "end": 3295.6800000000003, "text": " my job and telling people about stuff that i think is interesting so i would encourage", "tokens": [50364, 452, 1691, 293, 3585, 561, 466, 1507, 300, 741, 519, 307, 1880, 370, 741, 576, 5373, 50556], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 662, "seek": 329184, "start": 3295.6800000000003, "end": 3299.6000000000004, "text": " those people to go off and and look into it in a bit more detail and have a go to download a", "tokens": [50556, 729, 561, 281, 352, 766, 293, 293, 574, 666, 309, 294, 257, 857, 544, 2607, 293, 362, 257, 352, 281, 5484, 257, 50752], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 663, "seek": 329184, "start": 3299.6000000000004, "end": 3303.2000000000003, "text": " pie talk tutorial and start running it and you'll train a deep network and then when someone goes", "tokens": [50752, 1730, 751, 7073, 293, 722, 2614, 309, 293, 291, 603, 3847, 257, 2452, 3209, 293, 550, 562, 1580, 1709, 50932], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 664, "seek": 329184, "start": 3303.2000000000003, "end": 3306.4, "text": " all this deep learning is a bit scary you can go well actually i did that last week and it wasn't", "tokens": [50932, 439, 341, 2452, 2539, 307, 257, 857, 6958, 291, 393, 352, 731, 767, 741, 630, 300, 1036, 1243, 293, 309, 2067, 380, 51092], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 665, "seek": 329184, "start": 3306.4, "end": 3311.28, "text": " that wasn't that difficult yeah that that's what i'd suggest so for everyone watching please put", "tokens": [51092, 300, 2067, 380, 300, 2252, 1338, 300, 300, 311, 437, 741, 1116, 3402, 370, 337, 1518, 1976, 1767, 829, 51336], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 666, "seek": 329184, "start": 3311.28, "end": 3315.76, "text": " in the comments below topics that you would like us to discuss definitely want to try and get mic", "tokens": [51336, 294, 264, 3053, 2507, 8378, 300, 291, 576, 411, 505, 281, 2248, 2138, 528, 281, 853, 293, 483, 3123, 51560], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 667, "seek": 329184, "start": 3315.76, "end": 3320.88, "text": " back so um let us know what you want us to talk about uh computer file has a lot of fantastic", "tokens": [51560, 646, 370, 1105, 718, 505, 458, 437, 291, 528, 505, 281, 751, 466, 2232, 3820, 3991, 575, 257, 688, 295, 5456, 51816], "temperature": 0.0, "avg_logprob": -0.06707359908463119, "compression_ratio": 1.8292011019283747, "no_speech_prob": 0.05992065370082855}, {"id": 668, "seek": 332088, "start": 3320.88, "end": 3324.88, "text": " videos that mic has created um so go and have a look at those i'll i'll link some of those below", "tokens": [50364, 2145, 300, 3123, 575, 2942, 1105, 370, 352, 293, 362, 257, 574, 412, 729, 741, 603, 741, 603, 2113, 512, 295, 729, 2507, 50564], "temperature": 0.0, "avg_logprob": -0.1732527559453791, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.05763382837176323}, {"id": 669, "seek": 332088, "start": 3325.6800000000003, "end": 3336.8, "text": " please give us your feedback mic thanks so much thanks so much love to be here", "tokens": [50604, 1767, 976, 505, 428, 5824, 3123, 3231, 370, 709, 3231, 370, 709, 959, 281, 312, 510, 51160], "temperature": 0.0, "avg_logprob": -0.1732527559453791, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.05763382837176323}], "language": "en"}