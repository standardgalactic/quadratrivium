1
00:00:00,000 --> 00:00:06,160
This is a fascinating story we have for you of a senior Google engineer who says one of

2
00:00:06,160 --> 00:00:11,080
the company's artificial intelligence systems has become a sentient being.

3
00:00:11,080 --> 00:00:16,160
He believed one of the company's artificial intelligence chatbots had become sentient.

4
00:00:16,160 --> 00:00:22,640
Engineer Blake Lemoine says a chatbot project he was working on called Lambda can express

5
00:00:22,640 --> 00:00:26,160
thoughts and feelings equivalent to that of a child.

6
00:00:26,240 --> 00:00:32,080
Google has rejected claims that one of its programs had advanced so much that it had become sentient.

7
00:00:32,080 --> 00:00:37,040
That's I think the big issue right is that a lot of people get bogged down deciding well what

8
00:00:37,040 --> 00:00:38,640
does sentient actually mean?

9
00:00:46,320 --> 00:00:49,520
Hey everyone it's David Bombal back with a very special guest Mike welcome.

10
00:00:49,520 --> 00:00:50,640
Oh thanks for having me.

11
00:00:50,640 --> 00:00:55,760
So Mike I've seen a lot of your videos on YouTube computer file millions of views on

12
00:00:55,760 --> 00:00:59,520
some of the topics that you've done but can you just introduce yourself to the audience

13
00:00:59,520 --> 00:01:02,960
for people who might not have seen those videos or don't know what you're doing because you're

14
00:01:02,960 --> 00:01:06,800
telling me offline YouTube isn't your main thing you do more than that.

15
00:01:06,800 --> 00:01:10,640
That's right yeah so actually in some sense YouTube isn't a side for me right it's just

16
00:01:10,640 --> 00:01:12,480
something I did because I thought it would be fun.

17
00:01:12,480 --> 00:01:17,680
I'm an academic at Nottingham associate professor and I work teaching security.

18
00:01:17,680 --> 00:01:20,480
I research teaching AI and computer vision.

19
00:01:20,480 --> 00:01:27,200
It just happened that we have some ties at Nottingham to Brady and Sean who do things like

20
00:01:27,200 --> 00:01:31,920
number file and computer file and so computer file was kind of fledgling it had a bit of it

21
00:01:31,920 --> 00:01:36,320
was a bit established when I when I started doing them and it kind of just took took off really.

22
00:01:37,520 --> 00:01:42,000
I think because I did topics on security and AI and things people thought those were interesting

23
00:01:42,000 --> 00:01:46,000
and so I get you know a lot of views on those now but it is still a bit peculiar when people

24
00:01:46,000 --> 00:01:51,600
say hello to me you know because I just turn up and do normal things the rest of the time.

25
00:01:51,600 --> 00:01:56,640
So you get stopped in the street and it has happened yeah my wife is never impressed when

26
00:01:56,640 --> 00:02:02,320
that happens she thinks this is ridiculous but you know it happens from time to time I do I do

27
00:02:02,320 --> 00:02:06,320
really enjoy it I get lots of emails from people saying thanks for your videos I enjoy them and

28
00:02:06,320 --> 00:02:10,080
that's that's why I do it that's that's what it's for for me.

29
00:02:10,080 --> 00:02:15,360
I loved what you said offline you know you someone said that they started computer science because

30
00:02:15,360 --> 00:02:19,920
of you. I've had a couple of emails like that and that's the those are the best emails right because

31
00:02:19,920 --> 00:02:24,720
I want people to learn about computer science I love computers I'm a massive geek basically

32
00:02:24,720 --> 00:02:30,480
I program for fun and the more people do that the more it's a win for me so you know if I can

33
00:02:30,480 --> 00:02:34,000
encourage a few people by doing videos but that's what I really want to do.

34
00:02:34,000 --> 00:02:38,800
That's fantastic one of the videos I watched obviously in preparation for this interview

35
00:02:38,800 --> 00:02:45,760
is this recent video that you put out about AI and that's going to be the topic that we

36
00:02:45,760 --> 00:02:51,520
want to talk about today so let me lead with this I get this these kind of emails all the time

37
00:02:52,080 --> 00:02:57,760
David is it worth me studying cyber security David is it worth me studying computers because AI

38
00:02:57,760 --> 00:03:03,600
are going to take all the jobs away and I think movies over the years like you know there's been

39
00:03:03,600 --> 00:03:10,000
so many of these movies where the robots take over and this can you talk about this and you can go

40
00:03:10,000 --> 00:03:16,240
into the details if you like but I think this this this sort of recent event that you spoke about

41
00:03:16,240 --> 00:03:20,800
in your video hasn't helped the conversation at all so can you tell us about that yeah in what your

42
00:03:20,800 --> 00:03:25,200
thoughts are about you know what happened yeah so no I absolutely agree but it didn't help the

43
00:03:25,200 --> 00:03:29,280
conversation about was okay I think in my video about was kind of what I tried to end with was

44
00:03:29,280 --> 00:03:34,720
basically it doesn't you know in some sense the nuances of where this AI is doesn't interest me that

45
00:03:34,720 --> 00:03:39,760
much all I know is it's not where they're suggesting it is at least that's you know that's what I think

46
00:03:39,760 --> 00:03:45,840
I suppose at the moment AI is very application driven right so a lot of it is supervised there

47
00:03:45,840 --> 00:03:49,760
are other ways of doing it but a lot of it's supervised which means that you have some kind

48
00:03:49,760 --> 00:03:53,440
of training set with some inputs and some outputs that you're trying to get the model to learn and

49
00:03:53,440 --> 00:03:58,320
then you just train the model until that happens that can work really really really well and so

50
00:03:58,400 --> 00:04:02,720
from my own research I do this on things like image segmentation where I'm trying to find objects

51
00:04:02,720 --> 00:04:07,840
in images and you know medical image segmentation and things like this but you know in practice if

52
00:04:07,840 --> 00:04:11,440
I then take that network and try and run it on street scenes it won't work because it's not

53
00:04:11,440 --> 00:04:16,240
trained on street scenes it doesn't know what they are it hasn't got any ability to go oh it's a street

54
00:04:16,240 --> 00:04:20,880
now you know and take what it's learned somewhere and apply it somewhere else you know retraining

55
00:04:20,880 --> 00:04:27,200
a network is really the only way to do it and that involves even more data right so I don't think

56
00:04:27,200 --> 00:04:30,880
at the moment it's realistic to suggest that there's going to be some general

57
00:04:30,880 --> 00:04:35,600
intelligence that can just do all of our jobs right you know you've seen github co-pilot that

58
00:04:35,600 --> 00:04:40,800
just produces text code and sometimes it will produce a useful function and sometimes it will

59
00:04:40,800 --> 00:04:45,040
produce a function full of bugs that you've got to then spend time fixing and have you actually

60
00:04:45,040 --> 00:04:50,720
saved any time I don't know the jury's out I think so I wouldn't worry at the moment I'm not worried

61
00:04:50,720 --> 00:04:56,080
I mean maybe designing things to replace myself is a huge mistake but I don't think we're there yet

62
00:04:56,080 --> 00:04:59,760
so I mean tell us just for people who haven't seen it um haven't seen your video and like haven't

63
00:04:59,760 --> 00:05:06,000
read perhaps what's going on there's this google person lambda yeah so what is lambda and what is

64
00:05:06,560 --> 00:05:11,760
what what what what was he basically saying um google lambda is a um it's what we call a large

65
00:05:11,760 --> 00:05:17,360
language model so it's basically a a very very large neural network designed in a certain way

66
00:05:17,360 --> 00:05:22,000
they're all designed in a very similar way and it has more parameters in it than we've ever seen

67
00:05:22,000 --> 00:05:27,040
really in a model right or GPT-3 is also very very big and so really what this brings to the

68
00:05:27,040 --> 00:05:32,320
table is not so much something new that we've never seen before in AI it's just it's just huge

69
00:05:32,320 --> 00:05:35,360
you know orders of magnitude bigger than the kind of networks I would use to do

70
00:05:36,080 --> 00:05:40,240
you know complex imaging tasks and what they've basically done is they've trained this this model

71
00:05:40,240 --> 00:05:45,200
to read a sentence and then predict what the next word will be and so you could imagine but if you

72
00:05:45,200 --> 00:05:48,800
wanted to do this by hand and you had infinite resources you could just look at every sentence

73
00:05:48,800 --> 00:05:54,240
that's ever been written by humans and work out for any given let's say 10 words what the next word

74
00:05:54,240 --> 00:05:59,040
will always be and if you did that and you had that list of all the possible inputs you do pretty

75
00:05:59,040 --> 00:06:03,440
well at generating sentences because at the end of the day that's what people say right this is

76
00:06:03,440 --> 00:06:07,360
you've got it on record as what they've said in the past you can just say those things again and so

77
00:06:07,360 --> 00:06:11,280
this model is one of those this model is one where you put in some sentences so you might put in a

78
00:06:11,280 --> 00:06:16,640
sentence that says what do you think about quantum physics and then what the model will do is predict

79
00:06:16,640 --> 00:06:23,440
the next likely word and it will probably say well I'm going to start by saying what I think is

80
00:06:23,440 --> 00:06:29,680
and then generate some plausible text on quantum physics because people have written about quantum

81
00:06:29,680 --> 00:06:34,720
physics before and that data is in the training set what it hasn't done is learned what quantum

82
00:06:34,720 --> 00:06:38,960
physics is or connected to an internet resource that has information on quantum physics and looked

83
00:06:38,960 --> 00:06:44,000
it up so in some sense it's a bit like the you know in Star Trek you've got the computer you can

84
00:06:44,000 --> 00:06:48,240
talk to and they often ask the computer to do things like you know put the shields up or whatever

85
00:06:48,240 --> 00:06:55,200
yeah computer dim lights it's like that but it's not connected to any kind of anything on the ship

86
00:06:55,200 --> 00:07:01,520
so it just talks to you and talks back but it never actions anything it never it never has you

87
00:07:01,520 --> 00:07:06,560
know it's just going from the text in the training set and I think that's something that's perhaps

88
00:07:06,560 --> 00:07:11,920
lost a bit in in when it when it's discussed it's but it's not connected to anything it doesn't even

89
00:07:11,920 --> 00:07:18,000
have a memory basically and so it can't reflect on past experience because it has no place to store

90
00:07:18,000 --> 00:07:23,120
past experience it has no record of those events and so when it produces sentences that look really

91
00:07:23,120 --> 00:07:28,160
really interesting they're actually just really interesting sounding sentences you know and I

92
00:07:28,160 --> 00:07:32,960
think so anyway I mean if I if I sort of digress slightly but you know in this particular case

93
00:07:32,960 --> 00:07:37,360
what happened was someone from Google who I think was in the ethics department I don't think he was

94
00:07:37,360 --> 00:07:43,120
actually responsible for developing this AI basically said look at this chat I've had with it

95
00:07:43,120 --> 00:07:47,920
don't you think it's sentient basically is what he said and the answer I think from me and pretty

96
00:07:47,920 --> 00:07:52,720
much everyone who understands these models was no it's no it's not and what and I think the thing

97
00:07:52,720 --> 00:07:57,120
that bothered me most about it was not particularly one person saying this because he's very entitled

98
00:07:57,120 --> 00:08:02,400
to his opinion right you know I think I think it was that the media took it massively seriously and

99
00:08:02,400 --> 00:08:07,520
it was all over everywhere is this the next thing and that bugs me somewhat because I don't think it

100
00:08:07,520 --> 00:08:13,120
helps for conversation like you say right people start people who don't know what a big a big model

101
00:08:13,120 --> 00:08:16,800
a big language model is are going to be a bit worried about this and there's really no reason

102
00:08:16,800 --> 00:08:21,680
at this time to be worried and like that bothers me slightly which is why I do my videos to try and

103
00:08:21,680 --> 00:08:27,840
tell people about it I mean the problem is the movies predict this happening and then people

104
00:08:27,840 --> 00:08:34,160
see this stuff in the news and it's like it's the end of the world and end of my job Arnold and the

105
00:08:34,160 --> 00:08:39,440
robots are going to take over so it really doesn't happen it doesn't it really doesn't help and I

106
00:08:39,440 --> 00:08:42,560
like what you said I mean in your video which I'll link below you said something that I thought was

107
00:08:42,560 --> 00:08:50,160
hilarious you said can python functions get lonely yeah can you explain what you were saying by that

108
00:08:50,160 --> 00:08:55,280
yeah so one of the one of the comments in the original chat transcript between this researcher

109
00:08:55,280 --> 00:09:01,040
and his friend and his colleague and this lambda AI was do you get lonely and it's spouted off a whole

110
00:09:01,040 --> 00:09:07,440
paragraph about how lonely it is and it doesn't make any sense because it's a function call right so

111
00:09:07,440 --> 00:09:12,560
you put in your words at the top it runs of what is essentially a big transformer network which is

112
00:09:12,560 --> 00:09:17,840
pre-trained on all this data and then it spits out words at the bottom which you read and then it

113
00:09:17,840 --> 00:09:22,160
stops executing right because there's no kind of ongoing process like there is in my I mean I like

114
00:09:22,240 --> 00:09:25,120
to think that when I'm not immediately saying something to you I'm still there's something

115
00:09:25,120 --> 00:09:30,720
going on in there right maybe I mean you know I can't prove it to you but but this is not the

116
00:09:30,720 --> 00:09:34,960
case you know and it's just like when you run I mean I made a joke about it but when you run

117
00:09:34,960 --> 00:09:39,200
you know reverse string in python you don't worry that it gets lonely the rest of time because it's

118
00:09:39,200 --> 00:09:44,160
not executing that's just some code that executed it finished executing and it just lies dormant

119
00:09:44,160 --> 00:09:49,520
in memory doing absolutely nothing of interest and that's for me kind of what this model is doing

120
00:09:50,080 --> 00:09:55,280
if they developed a model that was always on in some way like maybe it was always doing something

121
00:09:55,280 --> 00:10:00,240
and it had memory and it had storage I could I still probably would think I would need some

122
00:10:00,240 --> 00:10:05,120
convincing but it had any kind of you know higher level thought process but at least it would be

123
00:10:05,120 --> 00:10:09,760
plausible you know it would sort of think well at least it's got something going on in there

124
00:10:09,760 --> 00:10:15,120
but I just don't think it's designed that way it's designed as a very very big reverse string

125
00:10:15,120 --> 00:10:19,680
and you know I don't worry about those things being sentient yeah but it's crazy I mean I mean

126
00:10:19,680 --> 00:10:26,720
the well I mean in my opinion because they kind of they were implying that this AI or whatever

127
00:10:26,720 --> 00:10:30,400
was like a human or equivalent to a human and it seems like that's quite a stretch

128
00:10:30,400 --> 00:10:36,480
but in you know popular popular culture that's what people equate to AI it seems yeah that that

129
00:10:36,480 --> 00:10:41,680
really that that's I think the big issue right is is that a lot of people get bogged down deciding

130
00:10:41,680 --> 00:10:45,520
well what does sentient actually mean and that doesn't interest me because when anyone uses the

131
00:10:45,520 --> 00:10:49,760
word they're not using it in a different definition they're using it in the definition we think of

132
00:10:49,760 --> 00:10:55,040
as like termination and sky net right you know this this researcher wasn't saying I think it's

133
00:10:55,040 --> 00:10:59,680
sentient but I define sentience as something like a slightly combinated if statement right he was

134
00:10:59,680 --> 00:11:04,240
saying I think it's like a person and it's got memories and it's got experiences and it gets

135
00:11:04,240 --> 00:11:09,600
lonely and it needs a lot of feelings and yeah and and without with any with zero evidence to

136
00:11:09,600 --> 00:11:13,360
support this and indeed not so much evidence is just it doesn't even make sense so I think you have

137
00:11:13,360 --> 00:11:17,520
to be extremely careful using the word sentient not because you might have a different definition

138
00:11:17,520 --> 00:11:23,360
but because everyone has the actual same definition right which is actual you know human level

139
00:11:23,360 --> 00:11:28,320
cognitive ability but you know which so I don't spend a lot of time worrying about what the

140
00:11:28,320 --> 00:11:32,720
definition of sentience is because if I go to someone in the conversation and say this is sentient

141
00:11:32,720 --> 00:11:38,000
I think we both understand implicitly what that means to me to say that and so I don't I I think

142
00:11:38,000 --> 00:11:42,720
we're arguing about the definition is a bit silly because we actually all secretly agree on the

143
00:11:42,720 --> 00:11:47,920
definition yeah I mean I think for the general population I mean I'm not I'm not into the AI

144
00:11:47,920 --> 00:11:52,240
piece like you are and that's why you I want to talk to you about it you know I just think people

145
00:11:52,240 --> 00:11:57,040
go off movies and popular culture that's sort of what what people that's the impression they get

146
00:11:57,040 --> 00:12:03,200
and that's why it was so big on the news perhaps but can you explain AI versus machine learning and

147
00:12:03,200 --> 00:12:08,320
like what is machine learning what is AI and perhaps just take us down the road now yeah okay

148
00:12:08,320 --> 00:12:13,840
like teach us you know sort of the basics of the stuff yeah so AI is misused in the sense that it's

149
00:12:13,840 --> 00:12:19,200
now a catchall right and I will admit I do that to an extent myself and it's partly because I'm

150
00:12:19,200 --> 00:12:23,920
lazy right I think I think it's because it means I don't have to define the exact thing that I'm

151
00:12:23,920 --> 00:12:28,400
doing yeah at any given time car engines are slightly different but they all at the moment I

152
00:12:28,400 --> 00:12:33,760
mean I say they will the combustion engines all do much the same thing even though one's got more

153
00:12:33,760 --> 00:12:38,000
cylinders and one's got fewer cylinders and one has a turbo and one doesn't you don't say I you

154
00:12:38,000 --> 00:12:42,000
don't miss it well I don't go on about those details I just say I've got a car and it goes

155
00:12:42,000 --> 00:12:46,960
so AI I think is a catchall that includes machine learning so you've got AI as a big kind of

156
00:12:47,600 --> 00:12:52,800
thing of stuff with loads of stuff in it and even my maze solving video where I just do very simple

157
00:12:53,360 --> 00:12:59,040
looking around the corridors of the maze would be defined in some sense as AI right but the

158
00:12:59,040 --> 00:13:04,320
Dijkstra algorithm that we use to do network routing and things and other similar algorithms

159
00:13:04,320 --> 00:13:09,280
you could define them in some ways as AI because they adapt to messages coming in and they change

160
00:13:09,280 --> 00:13:15,120
weights and paths and things but we wouldn't go as far as to say they were you know anyway you know

161
00:13:15,120 --> 00:13:20,320
smart in some sense right so I think AI is quite a broad term and then there are things like genetic

162
00:13:20,320 --> 00:13:25,120
algorithms evolutionary algorithms which do slightly different things they are arguably less

163
00:13:25,120 --> 00:13:29,840
popular or less prevalent perhaps will be the right way to put it but they also come under the

164
00:13:29,840 --> 00:13:35,440
umbrella of AI so AI is this very big umbrella term which basically encompasses most most things

165
00:13:35,440 --> 00:13:40,160
where you could imagine it was sort of intelligence and then in that you've got machine learning and

166
00:13:40,160 --> 00:13:45,040
machine learning is just the idea that you want to try and program a computer without having to

167
00:13:45,040 --> 00:13:49,760
program it essentially you want to give it some examples or some other mechanism from which to

168
00:13:49,760 --> 00:13:55,920
learn and it comes up with its own rules for what it's going to do so a decision tree is a good

169
00:13:55,920 --> 00:14:01,680
example of a very simple you know conceptually simple machine learning approach where you have

170
00:14:01,680 --> 00:14:07,440
some kind of data and every time you make a decision you just you just split it in two so maybe you're

171
00:14:07,440 --> 00:14:12,400
trying to analyze financial data decide whether people get a new credit card right so the first

172
00:14:12,400 --> 00:14:17,280
decision you make is have they ever defaulted on a credit card yes goes this way no goes this way

173
00:14:17,360 --> 00:14:22,240
and then the next decision is okay what's their current credit limit it's it's above 7000 it goes

174
00:14:22,240 --> 00:14:27,440
this way below 7000 goes this way and you just split this data into two and two and two until at

175
00:14:27,440 --> 00:14:32,160
the end you get the actual nodes that have the decisions on right and it's machine learning

176
00:14:32,160 --> 00:14:36,560
because what you can do is you can you can basically create this tree but actually change

177
00:14:36,560 --> 00:14:42,320
the numbers and values in it and the decisions based on the data so you can say well actually

178
00:14:42,400 --> 00:14:48,320
maybe 7000 doesn't work that well we're going to have it at 6500 and change the thresholds and things

179
00:14:48,320 --> 00:14:52,480
and you can do this all automatically in the training process so that's the kind of thing

180
00:14:52,480 --> 00:14:57,120
we're talking about with machine learning now what happens of course is there's a big push in

181
00:14:57,120 --> 00:15:01,040
deep learning which I you know I can also talk about but yeah be great yeah because I mean we just

182
00:15:01,040 --> 00:15:04,480
hear the you know I just hear these buzzwords I mean preparing for this interview just like

183
00:15:04,480 --> 00:15:08,880
buzzword after buzzword after buzzword and I think a lot of us you know who are not in this sort of

184
00:15:08,880 --> 00:15:13,840
field but are interested in it you know so yeah if you can define as much and like yeah yeah sure so

185
00:15:13,840 --> 00:15:18,960
I mean so you've got yeah sorry you've got you've got ai right which is which is right here in some

186
00:15:18,960 --> 00:15:22,800
subset of actors machine learning which includes what I would kind of call traditional machine

187
00:15:22,800 --> 00:15:27,600
learning like support vector machines decision trees random forests right these are all linear

188
00:15:27,600 --> 00:15:32,480
regression even right where you're just fitting a line to us to some data and then we have things

189
00:15:32,480 --> 00:15:38,720
like slightly more complicated algorithms like artificial neural networks which they I mean they

190
00:15:38,720 --> 00:15:44,880
kind of take some inspiration from our brains but I would I would be very careful saying that to me

191
00:15:44,880 --> 00:15:52,160
I think you know to suggest it's like our brain is is is is iffy and so yeah yeah but they have

192
00:15:52,160 --> 00:15:56,800
their name yeah like that's what they're called and then what we've basically done recently

193
00:15:57,680 --> 00:16:01,600
is we've made them much much bigger right and we've introduced other terms like convolutional

194
00:16:01,600 --> 00:16:07,440
networks and transformers and things but for the sake of you know this sentence they're just bigger

195
00:16:07,440 --> 00:16:12,720
deeper networks that can learn more impressive functions so they can map that input to that

196
00:16:12,720 --> 00:16:17,120
output more effectively right because that's what you want to try and do you've got some data

197
00:16:17,120 --> 00:16:21,600
you've got some predictions you need to make on that data and your hope is that once you've trained

198
00:16:21,600 --> 00:16:26,320
it some new data comes along and you can make some good predictions right I mean let's think of an

199
00:16:26,320 --> 00:16:34,480
example suppose suppose I want to you know do um MRI segmentation for medical imaging right so I have

200
00:16:34,560 --> 00:16:38,480
50 patients some of whom unfortunately have some kind of illness some of whom don't

201
00:16:38,480 --> 00:16:43,440
and I train the network to try and find the ones that have illness my hope is that when I then

202
00:16:43,440 --> 00:16:48,960
sort of fix that network in place and bring in some new patients it will be able to say whether

203
00:16:48,960 --> 00:16:54,320
they have that illness or not that's the idea and we'll have done that by basically reconfiguring

204
00:16:54,320 --> 00:17:00,000
itself based on the examples I gave it to begin with so doing a technology example it could be

205
00:17:00,000 --> 00:17:05,200
something like spotting is this a virus or is it just yeah exactly right and in fact you know

206
00:17:05,200 --> 00:17:09,600
modern antiviruses will include some kind of machine learning element probably so you know you

207
00:17:09,600 --> 00:17:14,160
might have features derived from so what we what we usually put into the front of a network is

208
00:17:14,160 --> 00:17:20,560
something we call features which is um our way of just saying input data right so sometimes you've

209
00:17:20,560 --> 00:17:24,400
crafted those features like you've chosen what you think is interesting features to give the network

210
00:17:24,400 --> 00:17:28,800
and sometimes you'll just shove something in like you know in antivirus you could you could choose

211
00:17:28,880 --> 00:17:33,440
things like how many system calls does it make or you know how many how many bytes is the executable

212
00:17:33,440 --> 00:17:37,840
or how many of this particular character does it have in the executable and you could choose those

213
00:17:37,840 --> 00:17:42,880
features because you think they are indicative sometimes of malware or not malware you stick

214
00:17:42,880 --> 00:17:49,760
them in some kind of a machine learning approach with a load of examples and then say right now

215
00:17:49,760 --> 00:17:56,400
change your weights and change your rules internally so that on this training set your prediction is

216
00:17:56,480 --> 00:18:03,520
accurate as possible right and so let's say you do that you have 100 000 malware and regular samples

217
00:18:03,520 --> 00:18:08,400
you give it to your AI and you just over and over again say right you got that one wrong

218
00:18:09,280 --> 00:18:13,520
reconfigure yourself so that next time you get a bit better at predicting it you do that over

219
00:18:13,520 --> 00:18:18,080
and over again and the hope is then that when a new virus comes along that you've never seen

220
00:18:18,880 --> 00:18:24,400
those same sort of should we say suspicious things exist in it and the network flags that up

221
00:18:24,400 --> 00:18:29,200
that's the idea so the the training data is like the the stuff you give it initially which would be

222
00:18:29,200 --> 00:18:35,040
this 100 000 like virus and not virus yeah and then you when you say weights you like it's basically

223
00:18:35,040 --> 00:18:40,960
saying like if it makes like a hundred system calls rather than 10 or you said some kind of

224
00:18:40,960 --> 00:18:45,440
threshold is that right yeah so okay so in a decision tree or something like that that's what

225
00:18:45,440 --> 00:18:49,280
would happen there would be some kind of threshold decision based at some point during it for a

226
00:18:49,280 --> 00:18:52,320
neural network it's a little bit more complicated and it's what you actually do is you treat all

227
00:18:52,320 --> 00:18:56,640
these weights just as numbers and you just calculate mathematical functions based on those

228
00:18:56,640 --> 00:19:01,760
numbers so what you might do is multiply all of those numbers that come in by some weights

229
00:19:01,760 --> 00:19:06,640
let's say you multiply one of them by two and one of them by negative four one of them by a half

230
00:19:06,640 --> 00:19:10,400
and then you add them all up and what that does is take a different amount of each one

231
00:19:10,400 --> 00:19:14,720
and then you and then you repeat that process over and over again to try and basically learn a

232
00:19:14,720 --> 00:19:19,040
complicated mathematical function that's really the only thing it does you know you're essentially

233
00:19:19,040 --> 00:19:23,600
trying to fit a really complicated curve through the data essentially so that you can distinguish

234
00:19:23,600 --> 00:19:33,040
between real and fake malware or you know regular executables and malware and and so the weight

235
00:19:33,040 --> 00:19:37,200
when I say weight what I'm really talking about is the parameters of my model which influence

236
00:19:37,200 --> 00:19:42,560
this mathematical function so the and then you would adjust the the the weights and the mathematical

237
00:19:42,560 --> 00:19:48,560
functions based on the result did it get did it's correctly determine that this was malware

238
00:19:48,880 --> 00:19:53,360
exactly so so let's suppose we were doing malware right so we think one an output of one means it's

239
00:19:53,360 --> 00:19:58,480
definitely malware and an output of zero means it's definitely not malware an output of 0.5 is

240
00:19:58,480 --> 00:20:05,120
not very useful to us because we don't know um what we do is we put in a piece of malware or many

241
00:20:05,120 --> 00:20:10,000
pieces of malware we run through let's say our deep neural network or whatever it is we're running

242
00:20:10,000 --> 00:20:14,800
and it will produce a value between zero and one and then we say well look you gave us a value of

243
00:20:14,800 --> 00:20:21,120
0.7 but actually it was malware this time so you've got an error of 0.3 I wanted you to produce

244
00:20:21,120 --> 00:20:27,120
0.3 higher for that one than you did so can you adjust your mathematical function to next time when

245
00:20:27,120 --> 00:20:32,480
I put that malware in produce a value of one and not a value of 0.7 now if you do that for one malware

246
00:20:32,480 --> 00:20:36,720
sample it's going to be the worst machine learning ever because you're just going to give it something

247
00:20:36,720 --> 00:20:40,880
else and it's going to go I don't know what you mean right because this is nonsense so you have to

248
00:20:40,960 --> 00:20:45,680
give it a lot of data and and I guess what you're trying to do is calculate the best average

249
00:20:45,680 --> 00:20:51,840
mathematical function that does the best job it can in the general case of all of these malware's

250
00:20:51,840 --> 00:20:57,520
right massively optimizing one malware is not useful because it's not going to generalize it's

251
00:20:57,520 --> 00:21:03,600
not going to apply in real world to some new malware so you put in 10, 20, 100 different

252
00:21:03,600 --> 00:21:08,640
malware at the same time and all of them are trying to go to one or go to zero and you're

253
00:21:08,640 --> 00:21:13,360
trying to change the weights to simultaneously do all of those at the same time that's that's what

254
00:21:13,360 --> 00:21:18,800
machine learning does basically for a neural network the process for actually doing this it's

255
00:21:18,800 --> 00:21:24,240
it's complicated to describe but it's it's fairly intuitive what you do is you because all these

256
00:21:24,240 --> 00:21:28,800
weights are involved in the calculation you put your features in for your malware you go all the

257
00:21:28,800 --> 00:21:34,560
way forward through the deep learning or the network then you calculate your error and then

258
00:21:34,560 --> 00:21:39,680
you go backwards adjusting the weights based on what you just found out right essentially and so

259
00:21:39,680 --> 00:21:44,000
if a weight doesn't have any impact on the decision because let's say it just sets everything to zero

260
00:21:44,000 --> 00:21:47,520
you won't adjust that weight because it's not useful you will only adjust the ones because

261
00:21:47,520 --> 00:21:51,680
you're calculating the influence that each of these weights has on the error you adjust all

262
00:21:51,680 --> 00:21:57,840
the ones that have the biggest impact and so the network will kind of try and find its way

263
00:21:57,840 --> 00:22:02,800
towards a good function you know and we use a process called stochastic gradient descent often

264
00:22:02,800 --> 00:22:07,200
to train this so what we're doing is we're picking random malwares and putting them in

265
00:22:07,200 --> 00:22:11,200
and that will often it will often get them wrong right because it's never seen any of these things

266
00:22:11,200 --> 00:22:17,520
before and so over time maybe you just nudge it slightly in a better direction and then over many

267
00:22:17,520 --> 00:22:23,200
thousands of looks it slowly converges on something that actually makes reasonable decisions that's

268
00:22:23,200 --> 00:22:28,240
you know that's the idea so it's a long process and is this what you would call supervised or is it

269
00:22:28,960 --> 00:22:34,080
this is definitely supervised so supervised is where you have your your your label ground truth

270
00:22:34,080 --> 00:22:38,160
what we was you know our we have labels for data so we're putting our data in we have some labels

271
00:22:38,160 --> 00:22:42,800
against which we can compare and that means that we have some idea of how right or wrong

272
00:22:42,800 --> 00:22:47,360
the network is in any given case right and that's very very useful and the majority despite what

273
00:22:47,360 --> 00:22:53,200
people might say the majority of deep learning or machine learning is supervised learning because

274
00:22:53,200 --> 00:22:59,920
it gets results the quickest if I want to detect some illness in MRI having examples of that illness

275
00:23:00,560 --> 00:23:06,320
is going to be much much easier so Mike supervised learning if I understand it right is you giving

276
00:23:06,320 --> 00:23:13,600
it examples of like you said actual malware or actual like in your MRI scans problems yeah and

277
00:23:13,600 --> 00:23:18,080
then you're supervising that it got it right and then you're correcting it yeah and it makes

278
00:23:18,080 --> 00:23:22,800
things much easier right so the majority of machine learning is supervised because it is

279
00:23:22,800 --> 00:23:26,960
simpler and easier to do if you work in applied areas like me where you're trying to get things to

280
00:23:26,960 --> 00:23:31,040
work really really well if you work in industry a lot of what you're trying to do is just minimize

281
00:23:31,040 --> 00:23:35,840
that error term you're trying to get as close to good predictions in for the majority of cases

282
00:23:35,840 --> 00:23:40,560
so getting some examples is going to get you to converge on that much much more quickly this is

283
00:23:40,560 --> 00:23:44,640
you know distinct from something like weakly supervised or unsupervised learning and there's

284
00:23:44,640 --> 00:23:48,880
lots of different variants so unsupervised learning is you don't have any labels right maybe

285
00:23:48,880 --> 00:23:55,120
the data is too big or the data is too hard to annotate or no one can agree on what the labels are

286
00:23:55,120 --> 00:23:59,280
and so the best you're going to be able to do is kind of partition the data into plausible groups

287
00:23:59,920 --> 00:24:03,600
so you can say well look we don't know exactly what all these things are but we know that this

288
00:24:03,600 --> 00:24:07,760
group is distinct from this group and that's unsupervised so an example would be suppose

289
00:24:07,760 --> 00:24:12,560
suppose you work for an online shop and you have a load of data on what different customers have bought

290
00:24:13,200 --> 00:24:18,160
one thing you might do is start trying to group customers into some kind of plausible groups

291
00:24:18,160 --> 00:24:21,440
based on roughly the things they they're not all going to have bought the exact same thing right

292
00:24:21,440 --> 00:24:26,000
so it's not going to be trivial but they might have bought so someone's buying mostly dog related

293
00:24:26,000 --> 00:24:30,000
stuff and someone's buying mostly technical gadgets and then what you can do is say well look

294
00:24:30,000 --> 00:24:34,000
I put all these people in the tech group and this guy bought this really nice new microphone or

295
00:24:34,000 --> 00:24:38,640
news camera so I'm going to recommend that now to other people in the group and maybe I get a few

296
00:24:38,640 --> 00:24:43,760
hits and I and I sell a few cameras that way um you can get much more complicatedness but that is

297
00:24:43,760 --> 00:24:49,280
an example of perhaps unsupervised learning where you don't need to have some kind of label

298
00:24:49,280 --> 00:24:53,040
for everyone you don't need to have labeled me ahead of time as a tech enthusiast you just need

299
00:24:53,040 --> 00:24:57,440
to look at the stuff I've been buying I know it's the same as always other people and know

300
00:24:57,440 --> 00:25:01,680
that that's interesting right rather than we know exactly what it means that's a great example so in

301
00:25:01,680 --> 00:25:08,080
other words you didn't tell the machine who the people were it discovered that based on the

302
00:25:08,160 --> 00:25:12,400
patterns of data right yeah and it didn't really even discover who they were it mostly just grouped

303
00:25:12,400 --> 00:25:16,800
them and that allowed us to make decisions based on the fact they were grouped now as that happens

304
00:25:16,800 --> 00:25:21,520
I've given this group a label of tech enthusiasts but of course you don't need to even know that

305
00:25:21,520 --> 00:25:25,600
you just need to know but on average they buy more TVs than everyone else so maybe send them

306
00:25:25,600 --> 00:25:30,560
emails about TVs you know it's that kind of idea you can still do supervised learning and other

307
00:25:30,560 --> 00:25:35,200
forms of learning with stuff like marketing and and recommender systems and things but you might

308
00:25:35,200 --> 00:25:40,400
imagine that that could be one way you would do it and I think it's a good example the problem I see

309
00:25:40,400 --> 00:25:45,840
like from listening to you is reality versus the movies or reality versus the news cycle

310
00:25:45,840 --> 00:25:52,480
because you always hear about google doing like um like teaching a machine to play chess or whatever

311
00:25:52,480 --> 00:25:58,800
the games are and it just like magically gets this done um and it teaches itself kind of like not

312
00:25:58,800 --> 00:26:03,200
even knowing what the the rules of the game are so that is a that's something called reinforcement

313
00:26:03,200 --> 00:26:08,480
learning a lot of the time reinforcement learning is still supervised learning okay it's just that

314
00:26:08,480 --> 00:26:14,080
you get the labels as you go from playing the game so the way it works is you know what you might do

315
00:26:14,080 --> 00:26:18,880
is you play a random game of chess where you literally move at random right and you lose

316
00:26:18,880 --> 00:26:23,440
and so you get a strong suggestion that maybe next time don't do that like that was stupid

317
00:26:23,440 --> 00:26:27,840
so now you move slightly less at random than you did before but it's still pretty bad

318
00:26:27,840 --> 00:26:31,760
and you lose again but you know learn a bit and this is basically how they train it so what you

319
00:26:31,760 --> 00:26:36,320
do is you play millions and millions and millions of games of chess and every time it goes well

320
00:26:36,960 --> 00:26:41,440
you just learn a little something about what was better than that time than what's the time before

321
00:26:41,440 --> 00:26:45,600
we're still talking about a network which is a big mathematical function right so we're still

322
00:26:45,600 --> 00:26:50,560
talking about something that has weights that you adjust so that when you put an input state in

323
00:26:50,560 --> 00:26:55,360
you get the best desirable output state which in this case of course is you won more often than you

324
00:26:55,360 --> 00:27:00,160
didn't for me I mean these are fascinating because they're trained in a very different way to the

325
00:27:00,240 --> 00:27:04,800
way I would train the network I come up with labeled data and I put it in like and I use the

326
00:27:04,800 --> 00:27:10,000
examples with reinforcement learning you have to start trying to give it rewards which is where it

327
00:27:10,000 --> 00:27:17,440
gets its labeled data from so is it is it is it is it better that you go 25 moves in chess before

328
00:27:17,440 --> 00:27:21,600
you lose or is it better that you checkmate regardless of how long it takes right you know

329
00:27:21,600 --> 00:27:26,880
because you might end up in a stalemate you know there's things with playing chess where you might

330
00:27:26,880 --> 00:27:30,400
say well look these other goals are also important or something like this and so you can spend a lot

331
00:27:30,400 --> 00:27:34,800
of time thinking about different ways you could train the network which I think I think is really

332
00:27:34,800 --> 00:27:41,040
interesting perhaps I'm misinterpreting it but it sounds like the hype cycle versus reality

333
00:27:41,040 --> 00:27:47,040
there's a big disconnect like the people have this vision that the robots are going to take over

334
00:27:47,040 --> 00:27:51,520
but you don't think that's going to happen like anytime soon right yeah I mean I well the funny

335
00:27:51,520 --> 00:27:56,800
thing is like I did a lecture once where where I said to everyone you know the char one hash function

336
00:27:56,800 --> 00:28:03,360
is absolutely fine right and then the next the next day yeah google released their their two pdfs

337
00:28:03,360 --> 00:28:07,520
that had the same char one hash right now that's embarrassing when that happens as a lecturer you

338
00:28:07,520 --> 00:28:12,240
know um so you know I don't want to say you know I don't want to say it could never happen what I

339
00:28:12,240 --> 00:28:15,840
would say is that the something that's really really good at go or something that's really really

340
00:28:15,840 --> 00:28:23,040
good at chess is really really good at chess and that is it right it will do nothing else right

341
00:28:23,040 --> 00:28:28,800
as far as I can tell human chess players are also good at other things and we we don't have that

342
00:28:28,800 --> 00:28:36,640
generalizability yet is this the age the difference between like specialized knowledge and yeah I mean

343
00:28:36,640 --> 00:28:40,560
again we could get bought we could get bogged down and what what the definition means but I think

344
00:28:40,560 --> 00:28:45,120
that our official general's urgency to most people watching is just something that kind of is a bit

345
00:28:45,120 --> 00:28:51,040
like a human right and certainly is very very general so you could say right this now is a totally

346
00:28:51,040 --> 00:28:54,560
different game learn to play it and it will go off and play it and it would still remember how to

347
00:28:54,560 --> 00:28:58,560
play chess and it could play all the games you know and it's just super it's super impressive

348
00:28:58,560 --> 00:29:04,080
though that doesn't exist will it exist I don't know I mean I think that if we keep making these

349
00:29:04,080 --> 00:29:10,000
models bigger we'll probably get to a point within a few decades where they are very impressive at a

350
00:29:10,000 --> 00:29:16,320
lot of different tasks but I still am not convinced yet that we've got any real strategy to get past

351
00:29:16,320 --> 00:29:20,800
the idea of just you need to like have a load of data right or a load of play a load of games

352
00:29:20,800 --> 00:29:27,280
my daughter can have a go at playing a semi-coherent game of chess just having been told the rules of

353
00:29:27,280 --> 00:29:31,280
chess and she didn't you know let's say she's not winning any competitions right not yet

354
00:29:31,280 --> 00:29:34,960
but she didn't need to play a million games against herself to work out what to do right

355
00:29:34,960 --> 00:29:40,800
there's something that she is doing but is much much more impressive than what this AI is doing

356
00:29:40,800 --> 00:29:44,800
that isn't to say the AI isn't incredibly impressive it's just very different I do think

357
00:29:44,800 --> 00:29:49,200
that the hype cycle is very different to what we actually see on the ground which is that basically

358
00:29:49,200 --> 00:29:54,720
a lot of the time I mean you know aside from playing games and reinforcement learning and large

359
00:29:54,720 --> 00:29:59,520
language models the majority of what people are doing is trying to find objects segment images

360
00:30:00,240 --> 00:30:04,720
and these things are mostly done in a supervised way and they don't generalize but we don't

361
00:30:04,720 --> 00:30:08,560
care because we were trying to find those specific objects so that's good and if we need them to do

362
00:30:08,560 --> 00:30:12,080
something else we'll retrain them to do something else yeah because my next question I think you've

363
00:30:12,080 --> 00:30:16,400
you've already given us the answer and maybe you can just elaborate is what is AI really good at

364
00:30:16,400 --> 00:30:22,240
compared and you know it just seems like it's like automation automation has its place but you still

365
00:30:22,240 --> 00:30:26,720
it takes like it's just correct me if I'm wrong but it seems to take away like low level tasks that

366
00:30:26,720 --> 00:30:30,880
are boring and monotonous or difficult for a human to do and then humans can concentrate on other

367
00:30:30,880 --> 00:30:37,040
things yeah what is AI really good at and where do you see it going yeah so AI is that automation

368
00:30:37,040 --> 00:30:41,200
is exactly what you what what you write on but with the caveat that you've got to have found a good

369
00:30:41,200 --> 00:30:45,840
way to train it to automate it won't just automate stuff you can't just stick it on a on a on a

370
00:30:45,840 --> 00:30:50,720
production line and say automate that for me because it did we won't know what to do so yeah

371
00:30:50,720 --> 00:30:55,440
from my point of view what AI is really good at is so before I worked in you know at machine

372
00:30:55,440 --> 00:30:59,520
learning and deep learning this was a normal computer vision researcher right and so I was

373
00:30:59,600 --> 00:31:04,320
you know this is like you know early 2010 something like this time before I mean literally deep

374
00:31:04,320 --> 00:31:09,760
learning appeared in about 2014 and before that we didn't have it right there were some networks

375
00:31:09,760 --> 00:31:13,520
but no one was really paying attention to them and everyone was just doing normal stuff right and

376
00:31:13,520 --> 00:31:17,680
what I would describe as image processing so if I wanted to find something in an image what I would

377
00:31:17,680 --> 00:31:23,200
be trying to do is come up with rules in my head about what I needed to do to that image to find

378
00:31:23,200 --> 00:31:27,440
those objects and then I would implement those rules and code so I'd say okay first of all go

379
00:31:27,520 --> 00:31:31,280
like we're trying to find you know something in MRI so first find all the bright pixels

380
00:31:31,280 --> 00:31:37,360
now find all the bright pixels but form a continuous blob that's of this size you know and I start

381
00:31:37,360 --> 00:31:43,760
and I try and design an algorithm to find whatever it was I was finding through these if statements

382
00:31:43,760 --> 00:31:48,160
and rules right it's just code and what machine learning lets me do is not worry about the the

383
00:31:48,160 --> 00:31:52,560
rules because the problem you have if you do if you do it by just coding is you get stuck in edge

384
00:31:52,560 --> 00:31:58,880
cases you get stuck on the you know you solve 90% of the issues pretty quickly because 90%

385
00:31:58,880 --> 00:32:04,160
of the images are trivial and then that 10% you just will never solve because they're just they

386
00:32:04,160 --> 00:32:09,040
don't apply the normal rules that everything else does and you know if you're looking at a sort of

387
00:32:09,040 --> 00:32:14,800
medical diagnosis AI or program that's a huge problem but you're just going to miss 10% because

388
00:32:14,800 --> 00:32:20,320
you couldn't deal with the edge cases and so from my point of view coming from image analysis

389
00:32:20,320 --> 00:32:24,400
that was what it let us solve it allows you because this mathematical function is very very

390
00:32:24,400 --> 00:32:29,680
complicated it can learn the edge cases if you give it sufficient numbers of them so you just so

391
00:32:29,680 --> 00:32:34,640
actually a lot of the time when I work with biologists or medics and and and they present the

392
00:32:34,640 --> 00:32:38,800
images I'll say these are all very nice but have you got any worse ones have you got any really

393
00:32:38,800 --> 00:32:44,320
bad ones because the more because the more bad stuff we give it the better it will get at at

394
00:32:44,320 --> 00:32:50,320
working when those things come along if you train your AI on a on a 3 or a 7 tesla MRI scanner

395
00:32:50,320 --> 00:32:55,360
which is super clear it won't work when you run it on a 1.5 you know so maybe you want to get

396
00:32:55,360 --> 00:32:58,800
samples from all the different scanners you know what I mean there's these kind of decisions

397
00:32:58,800 --> 00:33:03,920
it actually means that the problem is no longer one of which if statements do I need to write to

398
00:33:03,920 --> 00:33:09,440
get this to work it's now what kind of data and how do I present the data to this network to get

399
00:33:09,440 --> 00:33:14,160
it to work all right and that so it becomes much more about the input and output problem

400
00:33:14,160 --> 00:33:18,320
than it becomes about what you do in the middle which it just learns that's great I mean I just

401
00:33:18,320 --> 00:33:22,560
wanted to see if I understand the terms I see terms like artificial intelligence machine learning

402
00:33:22,560 --> 00:33:26,480
neural networks and deep learning we've covered all of those is that right yeah so I mean to go into

403
00:33:26,480 --> 00:33:32,640
some deep learning what I would say in terms of definition of deep learning is you know earlier

404
00:33:32,640 --> 00:33:36,720
I said that you might do I features for your problem right so suppose you're trying to sell

405
00:33:36,960 --> 00:33:41,840
cars what you might do is you might come up with some properties of cars that are relevant to its

406
00:33:41,840 --> 00:33:46,240
purchase price so you might say okay how many cylinders has it got how many how much horsepower

407
00:33:46,240 --> 00:33:50,480
has it got has it got leather seats right as it got air conditioning and you would have all these

408
00:33:50,480 --> 00:33:54,240
features and you come up with a list of let's say a hundred different properties of a car and you

409
00:33:54,240 --> 00:33:59,280
would stick them in some AI decision tree neural network doesn't matter and then it would spit out

410
00:33:59,280 --> 00:34:03,600
a value for you and you would train it on a bunch of examples and you would hopefully have a system

411
00:34:03,600 --> 00:34:08,960
that could really nicely predict the value of cars right now the problem is that suppose I've

412
00:34:08,960 --> 00:34:14,000
missed out a feature that's absolutely crucial to the value of cars suppose I forgot to put in

413
00:34:14,000 --> 00:34:18,400
the engine size and it turns out that 90 percent of the car's value is on how big the engine is

414
00:34:18,400 --> 00:34:22,880
right and so I've given it bad data then right and and then I have to go back and have to put

415
00:34:22,880 --> 00:34:26,400
data in again and I have to train it all again and you know it's a waste of time and what will

416
00:34:26,400 --> 00:34:30,480
actually happen if you try to implement a system where you missed out features is it would never

417
00:34:30,480 --> 00:34:37,200
work as well as you hoped and a car would come along that looked good on the features I did give it

418
00:34:37,200 --> 00:34:41,440
but actually had a really small engine and it would massively overvalue it or something like this

419
00:34:41,440 --> 00:34:45,680
right or undervalue it and you give away a really nice car for almost free what deep learning does

420
00:34:45,680 --> 00:34:51,200
is something called representation learning that's the because it's deeper it has the power to also

421
00:34:51,200 --> 00:34:55,840
learn the features as well as the decision based on those features so you might say well I can't

422
00:34:55,840 --> 00:35:00,800
bother to decide to decide all these features so I'm just going to dump the raw specs or a picture

423
00:35:00,800 --> 00:35:06,960
of the car in at the front and have it determine for me the value right and it would be looking at

424
00:35:06,960 --> 00:35:12,000
the size and model shape the color the size of the wheels and it would do all this and it would

425
00:35:12,000 --> 00:35:18,000
extract the features first inside the network and then it would use that to make a decision so deep

426
00:35:18,000 --> 00:35:24,000
learning is often described as just the same network but deeper but actually it's a different I

427
00:35:24,000 --> 00:35:29,840
think a different paradigm where you're basically no longer hand crafting what you put in you're

428
00:35:29,840 --> 00:35:34,960
just shoving all of it in and it works out what's useful and what's not and so you've explained

429
00:35:34,960 --> 00:35:40,160
neural networks already is all right yeah I mean so a neural network yeah so I we talked about how

430
00:35:40,160 --> 00:35:46,240
a neural network calculates a weighted sum so it takes some features at one layer and it waits

431
00:35:46,240 --> 00:35:49,680
them and then it calculates the sum of those for the next layer and we have something called an

432
00:35:49,680 --> 00:35:54,480
activation function in there as well which allows the basically it makes the function a lot more

433
00:35:54,480 --> 00:36:00,480
complex right it makes it non-linear makes it learn more powerful things modern deep networks

434
00:36:00,480 --> 00:36:07,120
actually have additional operations like convolutions and pooling operations which work on

435
00:36:07,120 --> 00:36:11,920
grids of data often right it doesn't have to but you know often they do so what you might do

436
00:36:12,560 --> 00:36:17,760
is instead of calculating a weighted sum of all the features you might slide a filter over the

437
00:36:17,760 --> 00:36:24,720
image to calculate filters at every location and so it's like a sort of a map of activations

438
00:36:24,720 --> 00:36:29,600
and then you might repeat that process over and over again so what what um deep networks are capable

439
00:36:29,600 --> 00:36:35,920
of doing convolutional networks is determining features across the whole image right or across

440
00:36:35,920 --> 00:36:40,560
the whole of the data stream and then repeating that process over and over again that's how they

441
00:36:40,560 --> 00:36:45,360
develop that's how they develop their representation learning right they use the filters to create

442
00:36:45,360 --> 00:36:50,560
interesting information before they make a decision you teach security at university but

443
00:36:50,560 --> 00:36:56,240
you're doing a lot of the ai side ai stuff as well um i think the the question a lot of people will

444
00:36:56,240 --> 00:37:00,880
be asking including myself is do i need to learn some kind of programming language and which language

445
00:37:00,880 --> 00:37:04,880
would it be would you recommend and do i need to learn like a whole bunch of math because it sounds

446
00:37:04,880 --> 00:37:08,800
like you know math is one of the or maths as we say in the uk is something that you have to

447
00:37:09,600 --> 00:37:17,680
it because you have to learn is that right to you know having having some idea of what's going

448
00:37:17,680 --> 00:37:22,000
on mathematically helps you from an intuition point of view right because i understand the back

449
00:37:22,000 --> 00:37:25,920
propagation process which is how the actual weights have adjusted and that allows me to

450
00:37:25,920 --> 00:37:30,000
understand what would happen if i connect two bits of network together in a weird shape or

451
00:37:30,000 --> 00:37:35,600
something like this but in practice actually day to day running of a deep network doesn't really

452
00:37:35,600 --> 00:37:41,520
involve any maths and and and there is some disagreement in the community about whether

453
00:37:41,520 --> 00:37:45,360
you really need to know math at all right you know i'm i sort of go back and forth i sometimes

454
00:37:45,360 --> 00:37:48,720
think it's useful and i sometimes think it's not i certainly don't think people should be if they

455
00:37:48,720 --> 00:37:53,840
don't like maths should be put off from having a go because i'm always an advocate for have a go at

456
00:37:53,840 --> 00:37:58,800
something you might really enjoy it right what i would say is that actually running a neural network

457
00:37:58,800 --> 00:38:03,520
doesn't require a lot of maths it just requires a bit of python basically so that's the language

458
00:38:03,520 --> 00:38:08,320
you normally use python um i have a love hate relationship with python i think but sometimes

459
00:38:08,320 --> 00:38:12,640
sometimes i just want to declare what my types are and stop having runtime errors for half an hour

460
00:38:12,640 --> 00:38:16,720
into something but what what they've done is they've got a lot of libraries like tensorflow and

461
00:38:16,720 --> 00:38:22,960
pytorch that operate but sit in python and then they they very very quickly go go down into C

462
00:38:22,960 --> 00:38:28,320
and CUDA for fast matrix multiplications which is all the stuff that goes on behind the scenes

463
00:38:28,320 --> 00:38:32,560
in your neural network so they're very very quick because they're not implemented end to end in python

464
00:38:33,120 --> 00:38:39,520
but python gives you a very convenient and nice way of doing all this you know loading the images

465
00:38:39,520 --> 00:38:43,600
it just appears as a kind of array you know you might have a list of images that you use for

466
00:38:43,600 --> 00:38:48,400
your data set and then you put that into a network and so on right you know a lot of it's just inputting

467
00:38:48,400 --> 00:38:52,880
out putting lists and dictionaries like the rest of python and so it makes things quite easy to use

468
00:38:52,880 --> 00:38:57,040
you know you'll have had a look at python but python for me is is a is a nice enough language

469
00:38:57,040 --> 00:39:00,560
in the sense that it's fairly easy to pick up particularly if you already know a language

470
00:39:00,640 --> 00:39:05,360
it's often language people recommend you start with anyway because it's fairly relaxed about

471
00:39:05,360 --> 00:39:11,760
syntax and just you making a total mess of it so that's you know that's always good um but doing

472
00:39:11,760 --> 00:39:16,720
going from knowledge of python to having implemented a deep network will not take you very long you

473
00:39:16,720 --> 00:39:21,040
will understand everything the first time but you can get give it a go and you can watch it training

474
00:39:21,040 --> 00:39:25,680
and you can start to you can start to pick up on what's going on and then you can make a change

475
00:39:25,680 --> 00:39:29,520
to the network and maybe improve your performance slightly do you have to write it from scratch

476
00:39:29,520 --> 00:39:34,000
or is like it's it's TensorFlow or something that like Google have created exactly they do

477
00:39:34,000 --> 00:39:38,080
a huge amount of heavy lifting right which is one of the reasons why you can kind of get away

478
00:39:38,080 --> 00:39:45,040
with not having always mathematical background so I mean I use PyTorch mainly and in PyTorch

479
00:39:45,040 --> 00:39:51,200
it handles all the weights and learning for you so you say I want my network to have this many

480
00:39:51,200 --> 00:39:55,440
layers and I want my layers to be like this and I want it to take an image of this size and turn it

481
00:39:55,440 --> 00:40:01,200
into a 10 class classification problem where I'm picking cats and dogs and airplanes or what have

482
00:40:01,200 --> 00:40:06,960
you and then it just trots off and does it and it just goes it goes puts the images in it it

483
00:40:06,960 --> 00:40:11,120
retrains the network and it puts the images in it retrains the network and it iterates and you can

484
00:40:11,120 --> 00:40:16,800
watch your learning rate really watch your loss function go down as it gets better and better

485
00:40:16,800 --> 00:40:21,040
every iteration instead eventually you can then just deploy it in some sort of production code or

486
00:40:21,040 --> 00:40:27,280
whatever and maybe without maybe test it first so but um you know like it does a huge amount

487
00:40:27,280 --> 00:40:31,920
there's a lot of mathematics behind the scenes not all of it particularly complicated but it's

488
00:40:31,920 --> 00:40:38,160
definitely a lot of it and it's all massively parallelized on a GPU and you know so you can

489
00:40:38,160 --> 00:40:44,720
actually get away with a few dozen lines of code to get a pretty nifty neural network going

490
00:40:44,720 --> 00:40:48,000
let's see that that's good to hear because you know when you start talking about the ins and

491
00:40:48,000 --> 00:40:52,560
outs it's like this sounds so complicated so it's like PyTorch just a library or something that you

492
00:40:52,560 --> 00:40:57,200
would import and then just you just send some commands to it yeah Torch started off as a

493
00:40:57,200 --> 00:41:03,360
machine learning library in um well it was written in C presumably but and CUDA but it was it was for

494
00:41:03,360 --> 00:41:08,160
Lua and again that's another language I have a should we say a very strong mixed opinions about

495
00:41:08,880 --> 00:41:13,600
however since then TensorFlow came along in Python I think it was seen as Python's more

496
00:41:13,680 --> 00:41:19,200
convenient for the majority of developers and so PyTorch spawned off Torch basically and is now

497
00:41:19,200 --> 00:41:27,520
the dominant library for this so TensorFlow is Google and PyTorch is Facebook AI or meta AI I

498
00:41:27,520 --> 00:41:32,480
suppose it is now and that's the one you would start with here if you were starting I yeah so

499
00:41:32,480 --> 00:41:36,400
this is it people have different opinions on this I think that the just give us your opinion

500
00:41:36,400 --> 00:41:41,280
because you know we I just sorry to interrupt I just want to put it this way I like to have

501
00:41:41,280 --> 00:41:46,960
parts like when I talk to experts like yourself it's like okay I'm new now how do I go from like

502
00:41:46,960 --> 00:41:51,200
knowing nothing to like at least getting started if so if you anything you can help me yeah well I

503
00:41:51,200 --> 00:41:55,280
mean I tell you what knowledge whatever yeah yeah yeah I would start with PyTorch personally

504
00:41:55,280 --> 00:42:00,160
right from a research point of view PyTorch is more flexible which helps me but it also doesn't

505
00:42:00,160 --> 00:42:06,640
require a lot of lines of code um to get running and it also does a nice thing where it doesn't hide

506
00:42:06,640 --> 00:42:10,560
away all of the details there's just enough detail in there that you can kind of type away and it'll

507
00:42:10,560 --> 00:42:16,000
kind of work but you do see the network going forward and learning and optimizing the weights

508
00:42:16,000 --> 00:42:19,920
and things like this there's a few lines of code but do that that you can kind of look at and go

509
00:42:20,400 --> 00:42:26,480
and then you kind of pick these things up right it's not a case that you just type PyTorch.train

510
00:42:26,480 --> 00:42:30,960
and pass it your input data and then it just does it and you have no idea what happened

511
00:42:30,960 --> 00:42:36,880
which I like because that wouldn't be fun right but also you wouldn't learn anything so I like

512
00:42:36,880 --> 00:42:43,280
PyTorch from that for that reason it also has a load of examples so if you go on the um if you

513
00:42:43,280 --> 00:42:48,000
go on the github repository for PyTorch or Torchvision you get the the whole you've got all the like

514
00:42:48,000 --> 00:42:53,920
core networks that are big from the literature in there and you've also got some examples of simple

515
00:42:53,920 --> 00:42:57,600
data problems and things like this that you can run from end to end and just basically run the

516
00:42:57,600 --> 00:43:01,040
file and it will start training a network and then you can delve in and see what it is it's

517
00:43:01,040 --> 00:43:05,200
actually doing. Do you need I think you mentioned a GPU do you need specific hardware or can you

518
00:43:05,200 --> 00:43:12,000
just run this on your laptop? You need you really need a um so PyTorch uses CUDA right so you really

519
00:43:12,000 --> 00:43:16,960
could do with using a um I don't know if PyTorch supports OpenCL I can't remember ideally you

520
00:43:16,960 --> 00:43:23,040
would have access to a CUDA enabled GPU that would make this process much much faster so as I mentioned

521
00:43:23,040 --> 00:43:28,800
the back end of of PyTorch and most of these deep learning libraries is written in C and CUDA and it's

522
00:43:28,800 --> 00:43:34,000
just massively parallelized matrix modifications most of the time and that is something that you

523
00:43:34,000 --> 00:43:38,560
don't want to be doing on a CPU right you can for very small networks run it on a CPU so if you

524
00:43:38,560 --> 00:43:43,840
download the simplest PyTorch example when you run it on a CPU it will run okay and you'll be able to

525
00:43:43,840 --> 00:43:49,200
see what happens. Anything with images anything where the dimensionality is high you're going to be

526
00:43:49,200 --> 00:43:53,760
waiting half an hour for it just to finish one pass and it won't get anything done. One other

527
00:43:53,760 --> 00:44:01,440
thing you might like to try is Google Colab so Google Colab is um is Google's public Jupiter

528
00:44:01,440 --> 00:44:06,960
notebook style laboratory environment that actually provides limited time but fair use

529
00:44:06,960 --> 00:44:12,080
access to GPUs to to have a go at these things right it's a it's a great place to go and you

530
00:44:12,080 --> 00:44:17,200
can also download loads of Colab notebooks existing implementations to test them out that's a great

531
00:44:17,200 --> 00:44:22,320
place to start you know I'm a big fan of Google Colab I think that as a platform it's really really

532
00:44:22,320 --> 00:44:27,200
useful um and you can actually pay us I mean I'm not I don't work for Google Colab you can pay a

533
00:44:27,280 --> 00:44:33,920
small subscription to get access to higher access or more preference more um should we say higher

534
00:44:33,920 --> 00:44:39,040
priority access to GPUs right that's what you know you can get um so it's it's like fair use

535
00:44:39,040 --> 00:44:42,960
normally so if you if you use it a lot you might have to wait for half a day or something.

536
00:44:42,960 --> 00:44:47,840
I mean in the best case scenario I'd come and attend one of your classes um but not everyone's

537
00:44:47,840 --> 00:44:53,040
going to be able to do that um do you have books or online courses or stuff that you would personally

538
00:44:53,760 --> 00:44:58,560
yeah so I mean what I always recommend to people is Andrew Ung's Coursera course on

539
00:44:58,560 --> 00:45:03,360
machine learning is a great place to start right now it's lower it's lower level so Andrew Ung is

540
00:45:03,360 --> 00:45:08,400
is is very well known in the machine learning community he's you know he's he's done a load

541
00:45:08,400 --> 00:45:13,360
of great work um his Coursera course is really good it's quite mathematical right so that isn't

542
00:45:13,360 --> 00:45:17,200
necessarily a problem you just have to go in knowing that's going to happen right but what it

543
00:45:17,200 --> 00:45:22,240
does do is it gives you a lot of information on stuff that we haven't really talked about so things

544
00:45:22,240 --> 00:45:26,800
like watching your learning rate your loss your your loss function go down right so if you if you

545
00:45:26,800 --> 00:45:31,760
draw a graph of your loss which is your error at the end of your network over time what should

546
00:45:31,760 --> 00:45:35,680
happen is it gets better and better right it goes down but it might not go down it might

547
00:45:35,680 --> 00:45:39,760
sort of do this a lot of machine learning is understanding what that means and what you could

548
00:45:39,760 --> 00:45:43,520
try and do to rectify that problem you know for the first for your first day of machine learning

549
00:45:43,520 --> 00:45:48,160
it's not important but over time some of the concepts that you talk about in this machine

550
00:45:48,240 --> 00:45:54,160
learning course will come in handy and there's a book by Yoshua Benjo called Deep Learning which

551
00:45:54,160 --> 00:45:59,760
also again a lot of maths in it but it covers a lot of the core concepts personally i'm a kind of

552
00:45:59,760 --> 00:46:05,840
i've always been a kind of learn by doing kind of a person right and so in what i like to do is just

553
00:46:05,840 --> 00:46:10,000
get on the pie torch or the TensorFlow tutorials and just start running some stuff and see what

554
00:46:10,000 --> 00:46:14,720
happens and if you know python or you know any language that's even plausibly similar to python

555
00:46:14,720 --> 00:46:18,080
you're you know you're going to have you're going to have a great time doing that i think

556
00:46:18,640 --> 00:46:22,000
especially for a lot of the audience if they starting out with us let's say there's younger

557
00:46:22,000 --> 00:46:26,320
people who starting their careers and i spoke about this in the beginning about you know people

558
00:46:26,320 --> 00:46:30,960
are worrying that this will take their jobs away but i'm assuming there's whenever i see the hype

559
00:46:30,960 --> 00:46:37,920
cycle there seems to be a lot of demand for ai skills huge demand yeah yeah there's a huge

560
00:46:37,920 --> 00:46:41,040
demand so i would say there's there's kind of you know you've got your different levels of

561
00:46:41,040 --> 00:46:45,120
sort of data analysts right so you've got people who are pretty good with a spreadsheet up to people

562
00:46:45,120 --> 00:46:49,840
who are working trying to train self-driving cars and things i suppose if i'm being sort of a bit

563
00:46:49,840 --> 00:46:54,160
bit random in my choices of job description and you know you've got anywhere in between there's

564
00:46:54,160 --> 00:46:59,600
huge demand everywhere so you know if you have any kind of data analysis ability if you can look at

565
00:46:59,600 --> 00:47:04,320
a table of data and start to pick out patterns and start to work out what's going on and make

566
00:47:04,320 --> 00:47:09,360
predictions on that data that's a really useful skill to have in lots and lots of jobs it's a very

567
00:47:09,360 --> 00:47:14,720
very um very very popular thing that people have so a lot we have a lot of graduates who graduate

568
00:47:14,720 --> 00:47:19,760
with a few modules in machine learning and a few modules in data analysis and things like this and

569
00:47:19,760 --> 00:47:23,680
they and they're in a really strong position these things are not you know you can learn these things

570
00:47:23,680 --> 00:47:27,520
yourself so you know you can go in i've got a data analysis course it's not very long obviously

571
00:47:27,520 --> 00:47:32,160
because you know youtube videos but i have some data analysis videos there are lots of data analysis

572
00:47:32,160 --> 00:47:36,160
videos on your youtube channel yeah yeah on our youtube channel computer file we have like a 10

573
00:47:36,160 --> 00:47:40,480
part series on data analysis which is just kind of like a taster but you can have a go at that

574
00:47:40,480 --> 00:47:46,240
there's lots of stuff on data analysis data analysis and uh modeling and machine learning in some

575
00:47:46,240 --> 00:47:50,640
ways go hand in hand it's often good to have a little bit of a look at both of them because

576
00:47:51,360 --> 00:47:56,080
you know cleaning data for example like you get you get a spreadsheet of data but doesn't make any

577
00:47:56,080 --> 00:48:00,560
sense it's unwise just to stick that straight into a neural network and see what you get out because

578
00:48:00,560 --> 00:48:05,360
there could be some complete you know it could be missing values there could be errors they could

579
00:48:05,360 --> 00:48:10,080
all just have hugely different scales of data these are all things to think about so some knowledge

580
00:48:10,080 --> 00:48:14,640
of how to prepare that data for let's say a downstream task like machine learning it's a

581
00:48:14,640 --> 00:48:18,960
really useful thing to know how to do as well i love that you're teaching at the university you're

582
00:48:18,960 --> 00:48:24,480
teaching security cybersecurity type stuff but you're also doing AI so there you see that like

583
00:48:24,480 --> 00:48:29,040
that's a really good mix and i'm assuming based on what you've just said you know it's a really good

584
00:48:29,040 --> 00:48:33,200
idea if you if you if you're into cyber or want to get into cyber to you know add this to your

585
00:48:33,280 --> 00:48:37,120
skill set yeah i mean i would be hard pressed to find any career that wouldn't be at least helped

586
00:48:37,120 --> 00:48:40,960
a little bit by knowing some data analysis of machine learning because just it just comes up a

587
00:48:40,960 --> 00:48:47,120
lot right you know and and also i mean as you know we already spoke about how people can be misled

588
00:48:47,120 --> 00:48:52,640
by the hype cycle right and and you will be much more resistant to this if you understand how these

589
00:48:52,640 --> 00:48:58,320
things work and that's going to put you in a good position i yeah i i think that um so i as it happens

590
00:48:58,320 --> 00:49:02,240
i teach security i partly i find it really interesting so i try and cling on to that module

591
00:49:02,240 --> 00:49:08,560
with you know with a with a vice grip and not let anyone else have it um i also teach cryptography

592
00:49:08,560 --> 00:49:14,000
uh at at university as well and get you back for some more interviews man yeah right so yeah by

593
00:49:14,000 --> 00:49:19,040
all means but so those are subjects i find i don't actively research day to day but i do find very

594
00:49:19,040 --> 00:49:22,960
very interesting and i do have some collaborations with because we have actual security researchers

595
00:49:22,960 --> 00:49:26,960
working at nottingham in lots of places we have good collaborations with them there is obviously

596
00:49:26,960 --> 00:49:32,000
machine learning involved in quite a lot of security because it's a it's a it's one of many

597
00:49:32,000 --> 00:49:38,160
strategies for detecting malware or for anomaly detection or you know any smart system that's

598
00:49:38,160 --> 00:49:42,560
doing something but hopefully you don't have to program all the rules yourself so yeah it does it

599
00:49:42,560 --> 00:49:46,800
does help i've got i think i've got a project uh an undergraduate student starting who's going to

600
00:49:46,800 --> 00:49:50,560
look at malware detection with a bit of machine learning as well and so she can bring the knowledge

601
00:49:50,560 --> 00:49:55,200
of the malware i can bring the knowledge of the uh of mostly the ai you know and it'll be it'll be

602
00:49:55,200 --> 00:49:59,760
great mic i always like to ask this question um if you were talking to your younger self let's say

603
00:49:59,760 --> 00:50:05,360
you were 18 or you know i don't know let's say not everyone is 18 who watches these videos but let's

604
00:50:05,360 --> 00:50:10,160
say they were 25 30 whatever yeah what would you advise someone to do based on you know what you've

605
00:50:10,160 --> 00:50:15,440
seen i think if you're if you're really interested in it in a career in cyber security or a career in

606
00:50:15,440 --> 00:50:20,960
uh machine learning it's worth noting that not everyone has a degree that does those things and

607
00:50:20,960 --> 00:50:25,520
that's fine right it's also fine if you do have a degree i see people saying well you don't need a

608
00:50:25,520 --> 00:50:30,320
degree for this or you do need a degree for this i actually think learn the skills right and then

609
00:50:30,320 --> 00:50:34,400
you get a job based on your experience it's you know and you're going to have a great time i think

610
00:50:34,400 --> 00:50:37,760
that again it's not one of these debates i like to get into because everyone has their own career

611
00:50:37,760 --> 00:50:41,600
path that they want to follow if you're if you're if you did a degree in something completely different

612
00:50:41,600 --> 00:50:44,720
and you've worked in a job you're not really enjoying and you want to try something new i think

613
00:50:44,720 --> 00:50:50,720
that's absolutely fine have a go there's so many resources online that there weren't 20 30 years ago

614
00:50:51,280 --> 00:50:55,280
that there are you know people doing interviews and videos on different topics that you can just

615
00:50:55,280 --> 00:51:00,720
watch and learn about and as i say i'm a very hands-on person if i want to try and learn a skill

616
00:51:00,720 --> 00:51:06,480
i'm just going to try and do it and it will probably go really wrong the first time um so i think that

617
00:51:07,120 --> 00:51:13,120
practice right and this is true of coding as well i think i'm big big um believer but coding is

618
00:51:13,200 --> 00:51:16,960
mostly practice people say like how did you know that was going to be a bug because i've seen it

619
00:51:16,960 --> 00:51:21,600
so many times before you know like because it happens all the time i think yeah that would be

620
00:51:21,600 --> 00:51:26,400
what i would do find something you love doing and do more of that you know i program at home for fun

621
00:51:26,400 --> 00:51:30,640
and it's partly because i find it fun and also sometimes i want to learn something new i did a

622
00:51:30,640 --> 00:51:35,760
video a year or two ago on the enigma machine right i don't need to program the enigma machine

623
00:51:35,760 --> 00:51:39,440
for my job i just thought it was super interesting and i just sat at home and did it and i learned

624
00:51:39,440 --> 00:51:43,760
quite a lot actually about the whole process and the history of it by just having to implement the

625
00:51:43,760 --> 00:51:49,200
thing and so i think yeah i think crack on and learn would be what i would do i love that i mean

626
00:51:49,200 --> 00:51:56,400
and i just have to say this you are doctor uh mike you you you got phd yeah is that right in

627
00:51:56,400 --> 00:52:01,280
what in what was it in computer vision so i mean what i really love about this and um this is just

628
00:52:01,280 --> 00:52:08,080
my opinion so i don't want to put you on the spot but um i love that you as someone with a phd

629
00:52:08,880 --> 00:52:14,320
are not excluding excluding people who perhaps never had that opportunity and i love that you're

630
00:52:14,320 --> 00:52:19,840
encouraging everyone you know just to go for it don't let your limitations or yeah lack of resources

631
00:52:19,840 --> 00:52:24,240
stop you sorry i mean as it happens like i wasn't i was a pretty average student at school right i

632
00:52:24,240 --> 00:52:30,000
mean i i didn't i didn't do much much there wasn't much in terms of computer science um in at school

633
00:52:30,000 --> 00:52:35,600
when i was younger it was it was you know let's use microsoft word and and and let's try that out

634
00:52:35,600 --> 00:52:39,520
and so i didn't i barely did any computing at all i could only a little i could only a program

635
00:52:39,520 --> 00:52:45,200
a tiny bit when i arrived at university loads of people arrive at university with huge programming

636
00:52:45,200 --> 00:52:49,840
experience but and loads of people arrive with no programming experience and we always say to them

637
00:52:49,840 --> 00:52:54,640
you'll all be the same in the end right like that's the whole point of a degree and it's a whole

638
00:52:54,640 --> 00:52:59,280
point of what we teach i think that it's never too late to get to get into computers and learn

639
00:52:59,280 --> 00:53:02,800
about programming and stuff i try and teach people to program all the time i mean not all of them

640
00:53:02,800 --> 00:53:08,240
were interested which is annoying um but you know so like if it was up to me all my family

641
00:53:08,240 --> 00:53:11,760
would be able to program because i'd be giving them extra lessons but some of them want to do

642
00:53:11,760 --> 00:53:16,160
other things apparently but yeah i'm not i'm not a gate i don't want to be a gatekeeper because

643
00:53:16,960 --> 00:53:21,280
that's not going to get more people doing cool computer stuff there are some things where a

644
00:53:21,280 --> 00:53:25,600
massive specialism is important right you know i'm not proposing to go into a hospital and start

645
00:53:25,600 --> 00:53:29,440
surgery on people because you need a lot of training to do these things but i also think

646
00:53:29,440 --> 00:53:33,840
that if someone wanted to be a surgeon they should crack on and do the training right you know you

647
00:53:33,840 --> 00:53:39,760
know i think you can learn those skills um and you know we require if you're going to work at

648
00:53:39,760 --> 00:53:45,040
university we usually require a phd and that's something that universities require but there's

649
00:53:45,040 --> 00:53:48,720
a great deal i don't know about the real world and industry about people who are watching will

650
00:53:48,720 --> 00:53:53,600
know way more about than me and that's also fine right you know everyone's got their own expertise

651
00:53:53,600 --> 00:53:58,400
so i like to learn from those people and hope i can teach them a bit about the things i know about

652
00:53:58,400 --> 00:54:03,920
i love that i love that another thing i mean i i said 18 but i i get a lot of pushback sometimes

653
00:54:03,920 --> 00:54:09,120
on these videos and i'm not sure if you've heard this question before am i too old to start learning

654
00:54:09,120 --> 00:54:15,920
ai no um no i mean consider also that the majority of academics who are using ai aren't

655
00:54:16,560 --> 00:54:22,560
18 year old fresh graduates they are researchers that have been doing it for decades because you

656
00:54:22,560 --> 00:54:26,320
know so we've all had to learn it from scratch as well right like i say deep learning only appeared

657
00:54:26,320 --> 00:54:32,400
in 2014 so it's been a mad rush since then there's loads of scope to learn um and i don't think it

658
00:54:32,400 --> 00:54:36,480
takes to get a little bit going it doesn't take that many hours you know if you want to do something

659
00:54:36,480 --> 00:54:40,880
you know around your job or whatever it is your current life situation is i think it's doable

660
00:54:40,880 --> 00:54:46,720
i love that any closing thoughts no i think um i hope people found it interesting right and i

661
00:54:46,720 --> 00:54:51,840
happy to come back and talk about more topics in detail but i think that you know i love um i love

662
00:54:51,840 --> 00:54:55,680
my job and telling people about stuff that i think is interesting so i would encourage

663
00:54:55,680 --> 00:54:59,600
those people to go off and and look into it in a bit more detail and have a go to download a

664
00:54:59,600 --> 00:55:03,200
pie talk tutorial and start running it and you'll train a deep network and then when someone goes

665
00:55:03,200 --> 00:55:06,400
all this deep learning is a bit scary you can go well actually i did that last week and it wasn't

666
00:55:06,400 --> 00:55:11,280
that wasn't that difficult yeah that that's what i'd suggest so for everyone watching please put

667
00:55:11,280 --> 00:55:15,760
in the comments below topics that you would like us to discuss definitely want to try and get mic

668
00:55:15,760 --> 00:55:20,880
back so um let us know what you want us to talk about uh computer file has a lot of fantastic

669
00:55:20,880 --> 00:55:24,880
videos that mic has created um so go and have a look at those i'll i'll link some of those below

670
00:55:25,680 --> 00:55:36,800
please give us your feedback mic thanks so much thanks so much love to be here

