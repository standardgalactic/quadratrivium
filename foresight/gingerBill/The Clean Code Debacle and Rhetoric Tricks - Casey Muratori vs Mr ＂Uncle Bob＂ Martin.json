{"text": " Hello and welcome, I am Gingerbell and today I'll be talking about the fiasco that has happened between Casey Muratori and Mr. Robert C. Martin. But before that I'm going to explain why the history got here and I'm going to also explain some stuff. I'm not going to try and criticise clean code itself. Casey Muratori has been trying to do this in the long discussions he's had with Mr. Robert C. Martin already. But it's one of those things where I just want to kind of show the rhetoric tricks of Mr. Robert C. Martin himself. So before we get to that start off, let's begin with the thing that started it all, which was this video that Casey made public from his thing. It's called clean code, horrible performance, where they say 22 minutes long video, him showing the examples of what clean code is and going into a more, let's say more like simplified code, which is more optimised performance and showing the cost. Hey, if you do it the clean code where you're going to be 15 to 25 times slower as your performance, do you want to take that hit? Understand what the costs are kind of you. And again, this is this view has also taken our context is blown up by mad. It's nearly half a million views so far at the moment at the time of recording. And so it's clearly gone viral across the programming world. Unfortunately, because it went viral, a lot of the context got lost. And because the context got lost. People just adding their own context into it without even bothering to learn it. So the context was this comes from a series that Casey's been doing on computer hands.com, where it's a performance awareness course. So specifically the this is the programming course he's been doing to performance awareness stuff. And this is a subscribed based thing on the on the on here. And he's been doing many different topics on here as I was able to learn how to performance awareness. Specifically, this was the blog post and he made completely public for everybody showing all the code showing all this stuff. So then you can see a whole video is all kind of transcribed down. And it's part of a series. It's not the beginning of the fifth series is quite in the middle. So it's kind of like, Oh, okay, we're not starting from a random place. So and also when people say and talk about the context of this Casey understands this like, look, reminder, I don't think clean code is bad just because of performance. My recent video is about poor performance, because it's part of a course on performance. This is the context many people lost. And he's been doing this for decades is saying so I recommend reading these tweets, I will try and provide all of the links to everything I'm showing today in the description or the do blue do whatever you want to do down below on YouTube. So be here. So yeah, hello. Good. So give a background. He's picked up the attention of Robert, Mr. Robert C Martin, which he colloquially calls himself Uncle Bob. For this talk, I'm just going to call him Mr. Martin, because I just prefer saying Mr. Martin, insert your guesses as to why. But yeah, he is very well known for my mainly three things, which is the agile manifesto, he helped develop that solid the solid principles. So the agile manifesto and solid principles, which again, many people know from the world, especially that he wrote it in his in his book, which is first in design as principles and design patterns, as it says on here. And he's also in this thing known for clean code. So clean with capital C code with capital C trademarked. This is his particular thing, the capital C clean code thing. Okay. And this is what he kind of tries to describe. So to get to show my biases and my background, I am the creator of the program language here. And the only program language is the general purpose program language with the distinct typing built for high performance modern systems and data order programming. So clearly, I'm showing my biases, and I'm cleaning on more like case and oratory side when it comes to this discussion. And also, I work at Django effects on emogen and liquid gen and geo gen, which are all high performance real time pieces software like simulations, again, engines for fire, smoke and explosions in real time. So clearly, I work in an industry where we really care about high performance real time stuff. So clearly, I'm showing my biases straight away. So people understand what's going on. Okay, so now you know, that's on the way. Can we explain what clean code is before we get into this? So sure. So there is this kind of little document I found the other day, and it's been well actively updated by looks only eight hours ago at this time of recording. And today's date is the March the 30th, I believe. Yes, March the 30th. So it's very active or someone's updated there's probably some typos and such we can even see the revisions. And yeah, it's just some, hey, just capitalizing some straw. That was all it was. Now, many people have seen to have liked this clearly over 5000 stars and over 1000 forks of this gist, as well gist or I don't know we pronounce it on GitHub, and explained some of the began your principles or points about clean code. Now there's many of this. This is the thing about which is why clean code capital C thing trademarked by Mr Martin is very popular because there's many of these rules, which no one would disagree with, like follow standard conventions. Yeah, because conventions are a good thing because then you're working on the same sun, only break them when you need to keep it simple, stupid, you're fine, whatever. Boy Scott rule, leave the camp around cleaner than you found it, always find the root cause you're no problem like this, yada, yada. Now some of these are things, okay, some of these are not essential. These are accidental. Like, again, follow standard conventions. That's not a unique to clean code, is it? You can do that in any philosophy out there. It's not a unique principle to clean code itself. But some things like, for instance, I would say more essential to clean code or prefer polymorphism to if or else cases. And separate multi floating code. I'm not even sure what that means. Use dependency injection. Follow the law of Demeter or many other things, many other things like here, like, Oh, use small functions functions, they only do one thing use descriptive names, like getting that descriptive names, everyone agrees to that to a certain extent, prefer fewer arguments have no side effects. So be more functional, it means more and more rather than be like, have side effects itself, like be more imperative relying on like global state or modifying state or whatever, don't use flag arguments, yada, yada, like, okay, some of these people will agree with some people will disagree with them. But here's where the the problem is with some of this is that for the most part, some of these rules, people will agree with some of them don't. One of the particular is like small rules for me, I actually disagree with this particular thing. There was a post here, this is on Jonathan blows blog old, very old blog, actually, this one 2016. But he's actually even older than that, because it's an old email response between him and john Carmack. So this is john Carmack explaining effectively, what he preferred for the things is not the clean code up. This is what I wanted was the wrong one. Whoops. Let's go to the blog post again. And it's this one here. So I accidentally clicked the wrong button then. So this is john inline code. And john Carmack in the email is explained, actually, he doesn't like the separate single functions here. It's better just have one big function and then comment them. Now, some people might say be a bit easier to manage looking at re things. Yeah, for code reviews, in a big corporate setting, it might be easier looking a single function. But there's a few things you have to understand functions have costs. If you split these things into multiple functions, this is a one is an extra cost. Yes, is a minor cost when calling a function. But like that most people don't care about that cost, unless you're doing particular things like you're worried about stack stacks or anything like that. Like, okay, most things don't care. One thing it does do is it does actually doesn't mean it's very easy to optimize for the optimizer. And I know how compilers work because I work on them for kind of a living. And if you have things in line, one, it's not hard to read by just using comments everywhere or block codes or anything like that. I think it's just as easy. And if you've got text editors, which are use collapsible things, that's great. That's okay, no problems, just deal with it that way. But then it's like, okay, but the optimizer can be ready, doesn't have to worry about trying to inline that function. And then now optimize the new inline function that's been got in line is out of another function. So there's that. And also you can usually start to see easy patterns as well. If you start manually inlining things, it's not hard to read. Yes, okay, you've got 10,000 lines, but most people's IDs and text editors are very easy for code folding, code searching, code and organization. We're not living in the 80s anymore, or even the 70s, to be honest, because even small talk had better options than this. I'm not saying I'm a big fan of small talk. But again, the tooling is the argument going small function is more of a, hey, it's our code review practices, big corporations, testing practices, and also maybe just tooling practices. So that's one thing. But it's going to recommend highly reading this article, I really do from 2014, again, it's from 2007, as it says here, I recommend it. But what I'm trying to get out here about the word clean code, and I'm not even talking about the actual discussion that Casey Motoria, they've been having yet, because I want to try to build up a picture here, as you can probably tell, trying to be a storyteller, not very good at it, but let's carry on with it, is that the concept of clean code is what I want to the term it capital C, capital C on both of them, trademarked for Mr. Martin, is what I'm going to dub a pork barrel name. So a pork barrel is a thing that America, American English, but it's kind of a you have this bill, and it has a particular thing like citizens against government waste. But it also has all of these things that are nothing even related to the actual name of the bill. And to keep it in American context, because I know most people watching going to be Americans, so I'm not going to use an English example, or another European example, like Germans, I'm just going to use American example, I've run recent one as well, is the Inflation Reduction Act of 2022. The name of it, the Inflation Reduction Act. Okay, now I'm trying to be again, I'm not an American, don't really care politics, but I think most people would agree, this act did not reduce inflation, in fact, it printed more money, and more excess money, that money was not being in high demand. So it increased inflation, in fact, it had loads of other things in there to do with not to do with inflation. But a really clever political rhetoric trick is to say, oh, you don't like this bill, we must like inflation, you're bad, everyone dislikes inflation. So you must be, oh, you can't be against this bill, can you? It's like, but this doesn't, ah, no, no, it doesn't inflation. How dare you don't want to, like, you can do this trick. And again, it's not a political side either, literally all political parties or politicians, I do this trick. Some countries like to do, like, oh, we're just getting names from bills. But then they'll give them a name anyway, like a colloquial one to refer to it rather than giving it like a letter or a number or some random numbers or something like that bill. And they'll just say, look, no, this is what we're going to call it. Because technically internally, the Americans do, but they give them a proper name and also a very long title. Again, this is to provide for the reconciliation pursuant to Title II of the S Con Rez 14, I'm just reading it as it says on here. And it's like, okay, but that's a good example from a political standpoint. I'm just keeping it here, trying to keep it politically neutral. I don't really care about the old politics, but it's just one of those funny things that show, hey, this is a trick, because Mr. Martin will actually continually do this throughout. And it will trick, do a lot of pivoting and a lot of these poor barrel names. Okay. So let's just say this is a good example of this bad code. Just say no. And it's like, okay, so what's good code then? Because then it's, phrases in the, oh, it's clean code, obviously. Now there was another tweet, I tried to find, but I couldn't find it's probably been lost to the Twitter search, or it's just been deleted, whatever. But he will commonly do this, Mr. Martin go like, oh, the opposite of bad code is clean code with a capital C trademarked, which is interesting. Because that means anything that's not clean code is a bad code. Yeah, let's not get there. But again, very clear, careful on this, I'm not going to criticize him. I'm actually like, in admiration of his rhetoric, he's a politician level when it comes to rhetoric, I mean this. And it's like, this is really good. Like he's really good at it. But again, he's been doing it for nearly 50 years. He is what 70 years old. He's been doing this sort of job since what, God, even the early 90s. So it, okay, worst, like, it's 30 years, he's been doing this, he's probably been doing it for 40. Okay, that's what he does for a living. He's very good at this rhetoric. So that's why I'm like, I'm kind of admiring it into a certain extent, in a weird Machiavellian sense. But sure, let's carry on with this, shall we? I've got some more things. Another thing in here, he says, when this whole thing happened when he was talking about it, oh, no, people don't like this code. But then he says, some people do this. And again, I've shown you, he's very good, he's very good at knowing memes. He's not an old man, he's an old man, but he's up to date with a lot of the stuff. And it sounds like silly, but it's not a book, or the concept, it's a Cartesian pandering immature behavior. The author batches everyone, and then he just shows this claim like, hey, I know how to play your joke. Like, and he does, he's not that bad. But then there's other things. So here's like, Casey Motori comes up with, I mean, he's talking about people criticising, and then he replies to this, this is where kind of the start of the conversation is happening. So Casey has says in this, even if true, to what extent would you tolerate the, yes, clean code is much slower, but it's about programmer productivity for other products. Would you want a car that went only five miles per hour, because the designers could do less work to make that car? Now, Mr. Martin replies to what the auto owners notice he does a pivot. This is a pivot. And also, it doesn't answer the question. He says, the automated mobile industry takes advantage of every productivity tool they can reduce their enormous manpower cost of designing and manufacturing cars. As a result, cars have gotten exponentially better over the decades, because the extra productivity translates to better designs. Yes. But do you think they for their programming, they're using clean code? Principles. In fact, we know they don't, especially after he's Mercer and stuff like that, but they have to adhere to certain other things. And like, they're probably not doing clean, clean code stuff. Now, I know the most things have started to relax, especially when it comes to, like, Android Auto and I'm like, Apple Car play and stuff like that, it's, they're stuff a buggy. But that's kind of like, Oh, it's your phone. That's a different thing. It's just we're interfacing with it and whatever. And it's interesting. He does this because he does it again, when someone replies to it and anything here. But he's kind of a, he knows what he's doing when he says these arguments. That's not answering the question. All I'm going to say is that just watch that. Okay. Another thing is this is when it starts, this was the beginning of his, I wash your thoughts and he says, Oh, I've commented on this before clean code is made for programmer performance, not algorithmic performance. If you need the latter, then write in C or assemble and live with the high cost of development. So few things there already, PI programmer performance and algorithmic performance. Okay, so program performance, it's the, in the contrast, how do you measure that thing? How would you know if that your approach is better than another approach? And if you need the latter, write in C and assemble, okay, it's assembly, I would call this, but yeah, and then high cost of, so he's already implying that writing in C is going to be a much higher cost of development than writing in another language. It might be, but you should only write it in because you need the performance. And it's like, okay, what? Look at the framing. He knows what he's doing. I'm not saying he's an idiot. He's very smart. Okay, I'm sorry. I'm picturing it. I can already see which side I'm in, but I'm just trying to explain the rhetoric tricks. So this is another thing is like the clean code to reply to later with the automatic ability. I've got these switching around. It doesn't matter. People says, how do you measure readability of the code by reading it? So obvious. But it's like, when people say measure, they usually mean a quantifiable thing rather than a qualifying thing. So this equality and a quantity are two distinct ontological categories, okay, or epistemological, the many different things, which is not going to philosophy too much, but you cannot quantify a quality and never qualify a quantity in a sense. They're different things like, Hey, I have a tape measure here. Yeah, I can say it's got the, I say it's quality of being good and round and green and stuff like that. And these aren't even very good qualities, to be honest with you, but it has quantities. I know it's mass just by dropping it. That's what you need to do. That's absolutely fine. And it masters. I'm just trying to explain the gravity thing. So clearly it's got mass and we can measure that relative to other things that weigh things. So we know how much this is weighs. This is probably weighs about, I don't know, eight ounces. So 225 grams ish. That's quite heavy, actually, surprisingly, it's not even a good one. But there's kind of the thing. So you can actually think you can sort of say, Oh, how, how green is where we can measure the reflectings of it and then see how much it reflects back a certain light and some wavelengths and such like this. You can say all these quantities and you're, these are quantities, okay, but I want to go into too much clearly. I used to be a quantum metrologist. So I know a lot of you may excuse measurements and all this stuff. But this is a clever trick by reading it. That is not a quantity. And people are wanting to question how do you measure when we want an objective measurement? What do you mean is they want a quantity? But he goes out by doing this. So this was a big long twist post I've been here, where Lawrence Crow again, the community anyway says people on hand made hating on Casey's videos about performance, while their company is spending double digits of percentages of their revenue on Amazon web server bills to serve three forms and a database view. And it's like, okay, this is great nightlight discussion. Talking about this. And then Mr. Martin says here is his, his analysis was correct. His rhetoric is abyssin, disingenuous. And the overall point was extraordinary narrow. Clean code is about increasing programmer performance. He keeps it straight this not computer performance. What are some real life life non-trial view code bases support the hypothesis that strict clean code increases program performance replies with a mean. Again, he knows what he's doing. I'm not like, this is really cool. Like he knows what he's doing. But yeah, so you don't have any of his tools that some says it. So the Vittorio reminded me of a thing for the people I got into a discussion with him around about this time. And I kind of partially convinced him about like, well, you need you've not go evidence for why one's better than the other. Like show why how do you know one's better than the other? It's kind of that question. Like how do you know what measurements are using what quantifiable or even qualifiable things are you showing? Like, can you just show me the evidence? And then he goes, he knows this for a fact, he says, the problem with scientific data is it's controlled in controlled experiments and realistic software environments are economically feasible. You're asking for something you'll never get. And yet you still decide. So look around and that's just so it's especially your seniors. So first of all, it's just the first part of this thing here is we have no evidence for our claims. But it's okay, because your associate seniors may agree with me already. Nice little pairing here doesn't do the same thing. Okay. That's the first thing. But then someone said like they said they use over the 10 lines of code sometimes wrong seniors, I guess, and someone saying like, well, we've got my seniors don't agree with you. So sometimes, of course, your seniors were correct. I presume they also told you that or else be your smaller well named functions are better than really badly named functions is like, okay, notice the bad pairing there already. A well named function is better than a badly named function. Agreed. Smaller function may not be better than a long function. But notice is smaller well named functions are better than really badly named functions. Never talked about the length of it. I know it's like a minor word difference. But he knows what he's doing. And also he just changed the topic and it's a pivot. He's gone from being the scientific data to now to well, trust your the trust the authorities of your seniors or elders or whatever, like, that's going to authority rather than going to like empirical data. Nice little pivot. He knows exactly what he's doing. So another one here is always remember that computers operate on f in character one f in character to times he's trying not to swear here. No matter what lovely subroutines you might be using some replies, what about Sunday? Well, the context of the problem was JavaScript in a browser. I'm like, what context I even tried to search through the other tweets. There was no context. So, yeah. Okay, carry on. Another one. Someone has recently equated clean code over engineering. That is, of course, an oxymoron. An over engine code is by definition not clean and makes me wonder if those who complain so loudly have actually stood at the target of their complaints. It's like, see the see the problem. So if he's over engineered, it can't be clean code. Even though I've seen many clean code, which I've classes over and engineered. In fact, I think clean code by default is kind of open engineered like it doesn't it's assuming this could be open to change even though it's a close set of problems, which I'll get onto a bit later. So then talking about this for tour of Rome, a shot we had earlier, I was discussing with him previously. And he was kind of like, Oh, well, I can make it even faster. If you just change the entire style of it and just have a raise of separate types. And I was just like, you being honest, but this was the conversation I had even trying to confuse it like to not, he was kind of being a bit confused, but also trying to be like explaining. And we kind of got to a point where like, Oh, okay, like, first off, you've been a bit disingenuous here, man, with the argument, but fine. This is not Mr. Martin anymore. This is just me explaining like there are people who are trying not saying to defend him, but not understanding like Casey's point in this discussion. So again, before I'm going to read this article, I recommend reading this clean code, horror performance, YouTube video, again, links are in the description for all of these links. So don't worry, they'll be there. So now I've done the 20 minutes spiel at the beginning of this video. Let's get to the meat and potatoes of this entire thing, which is the written down talk. Now this is quite interesting. And this written down talk is effectively a written discussion between Casey Meritori and Mr. Martin. And they are both discussing with it, and it's been split into different things. And I'll explain some points as I come along. And so other little tricks. So first off, I'm just going to try and read it. I recommend reading this again, links in the description below for everything. So Casey starts off with thank you taking the time. And he's just kind of asking questions like so most explanations on clean code, I've seen that you include all things I mentioned in the video, like preferring inheritance hierarchies to ifstapes, which means like I remember if we look back to the the where was the guest I found completely lost it already now. It was here, right? Here it was here. Yeah, here's the design rules. Like that some some size, that's not Mr. Martin's himself. But yeah, but it sounds like you were surprised to hear me say that like all these different things he said is I look Martin's going to disconnect. I'm not sure there is one. And interesting, he just says there is no like disconnect. And Casey just asking questions about this. So Casey is asking a basic question here like look, we're both familiar with Visual Studio and Clang, and it would be a reason more that you're calling the back and uses it every day. I use these every day. I use LLVM and Visual Studio every day. Are you calling these a vast majority of software that require less than one things? And then he would go like, Oh, these are very specialized software, the only few in existence, and only a few that have actually become popular. And then talks about why this case and like actually talks about all these different things here, like, okay, speed is not necessarily an issue. But you can summarize, I'm trying to summarize it. But then the first trick he does, this is going to be consistent throughout here, is the nanoseconds, microseconds and milliseconds framing. I will tell you this. So what it will do here is making sure that passing code preserves nanoseconds can have a big effect. Or he says, I assiduously counted microseconds when it mattered. Nanoseconds were way beyond anything I could imagine. And so then Casey kind of questions, is a case of like, it sounds like most software that Casey actually uses and so with myself would when nanoseconds actually matter. In other words, Visual Studio, LLVM, GCC, Microsoft Word, PowerPoint, Excel, Firefox, Chrome, FFMPEG, there's a type of that, but TensorFlow, Linux, Windows, macOS, all of these. And Martin goes again, Mr. Martin goes like, oh, not exactly, rather my experience abroad, and does all the stuff. And then talks about this other applications we have modules in the millisecond range. And he says, sort of these time ranges. It's very like, he's trying to get the reader, because he knows people reading this, to think about it, well, most problems are in there at ranges of milliseconds. So we can worry about nanoseconds. Most people aren't have to worry about the automizer nanoseconds. But it's like, you know, death by 1000 cuts, and 1000 milliseconds is a microsecond, 1000 microseconds is a millisecond. So if you do things 1000 times badly, and you can, you've now gotten to the other domain into the other module, as he was calling this, the time module. Okay, fine by me, not necessarily criticizing that way of thinking, but it's a very weird framing, which, like, even if I read here, so for example, I'm currently working on an application in which the vast majority of modules work well at the millisecond level, but a require a 20 x per better performance. My strategy has been to write the millisecond modules in closure, because while slow, which is very convenient language, the microsecond modules I wrote in Java, which were much more faster, more convenient, far less convenient. So it's like, okay, so if I use them all like Java, it's easier, it's much less convenient, but I can write faster code, compared to closure, which is, I write code quicker, but it's not going to be as powerful as that. And those bits, these mergers again, because closure and Java both work on the JVM, so they can interact with each other pretty easily, ish. But he's just talking about the other things here. Now, one thing I found interesting is this slash here. You'll see in a minute, right, he only wrote a book, and he said, oh, I wrote a book on clean code, don't you know? I've only focused on the millisecond side of the problem, not the nanosecond. It's like, well, I'm not walking about the performance of the code anymore. But like Casey just goes town on the question. So Bob answers a very short question, milliseconds, of course. And then he answers again. Now, he might be asking, wait, why is he answered twice? Well, he went back in history and added some code text. He rewrote history. Yeah. I'll say no more. But yeah, he keeps going on about this, and it's very interesting. So now here's another problem he kind of talks about. And he talks about the actual he says he's now actually finished watching the video, because he didn't actually watch the video when he started discussing with the only watch the first bit of it until I've got enough of this. It's like, you're not going to have discussion with someone you've not even watched the entirety of but you think you're confident, you know, you can talk about it. I'm like, interesting. If you're that confident, it usually means you're not actually talking about the thing itself. Yeah. Yeah. But he says, you notice a nice little pattern. I love that basic form of the like some coefficient times the length times the width. And in those moments, I only think programs and mathematicians mathematicians can truly appreciate. It's like, oh, yeah, yeah, like that was fine. Isn't that lovely? And that's fine, whatever. But Casey comes up, okay, that sounds great. I think we've gotten to the same page because he was actually talking about this, not this. Because he says, I've just finished watching it. So I'm going to add this bit back in to make it split it up. Again, take it as you wish. What I'm trying to say is above paragraphs, above the box, and there's just like, look, Casey has read and looked a lot of it. Like, what you're talking about, he seems like these nanoseconds even matter, like everything seems to be nanoseconds modules, which he says, like, all this makes no sense. And then he again, he replies with, well, I'm one of the signatories of the agile manifesto who still believes to be a bit up front of architecture design. Okay, why bring that up? Sure, but fine. This is the bottom line, of course, is that single factor analysis is always suboptimal. There's no one true way point. I've always made several times in clean code. And it's like, but they may not be one true way, but you do kind of suggest there's a default you should go to. And there are arguments for that. Okay. Casey has a lot of questions to ask already, all of this. Again, I recommend watching this. Now, Casey says here is like, I watched a multi part series at six parts six, and it's like nine hours he watched, not once in that one second of it of that nine hours was in to go to get towards performance. And again, Mr. Martin says it's fair criticism, absolutely fine, no problems. But again, I'm just going to show you here, it's like, yeah, so thank you for the nudge kind of thing. Like, oh, next time I'll do, I'll put a nudge in towards performance. It's like, been doing this for decades. Hmm. Okay, so clearly you don't see, like, but like, he's kind of butchering up trying to be polite or like, as you would, like you're trying to be a conversation light always be polite someone as well and try and be nice and kind to a certain extent, maybe always nice, but kind at least kind. But yeah, it's always kind of those kind of things and after some reflection, blah, blah, blah. I'm just trying to go through over this again. This is like, it's fine, not just all the conversation again, it's a lovely conversation between two people trying to be just being honest between each other, not being horrible. Casey was also showing off this video, which if I believe it's correct, he was just kind of they were just joking about how slow is right GitHub, literally intent of just slowing down along with the paragraph God. And they actually found after a while, why this was the case. The thing they found out was that it was the code was looking back to the beginning of the paragraph, looking for a colon, if it found a colon, and it was near the beginning, it was going to then expand this to be a emoji. That was what the bug that think the slowness was. So if you just, as Bob made his joke, like, oh, if I just replace everything, the spaces with the colons is instant, there's no slowdown because it's found the colon, found it's not an emoji and doesn't do the search anymore. And that's how slow, like, even though they were talking about the complaining like slow codes, like, look how dumb this algorithm was in the web browser. And it's just trying to do this. Now, one little thing I found a bit weird, he says, I created this using going vi and I use this like replacement thing, because really, I'm an old C hacker at heart. I'm like, what? What does that even mean? This just seems like a, I'm an old C hacker at heart. I'm like, this has this is one, this is just, you're like vi or vim or whatever you want to stuff. And then you've just done a regex for text replacement. And this has nothing to do with C. I know what he's trying to say. Oh, it's just really low level I'm doing all this. I'm like, what? Sorry, we just need one of those things like the what? Right, kind of bit interesting here. So then there's the again, recommend if you want to read the links in the bar for all this. So you don't I'm not trying to read the descriptions here. I'm just trying to go over it. So now they figured out the things, the slowness of GitHub, they've gone gone back pivoting up back to this talking about the stuff about clean code again, capital C, capital trademarked, and explaining all that. And some of the weird things like for instance, the descriptive names things, like, I think everybody agrees with the descriptive names. This is not clean code exclusive to clean code tests. This is one where he's more of a test driven development, while cases more of a, it's more of a how they do frame it later on. In fact, I think Mr. Martin rephrases this quite well, that he prefers like why you should write a test if you don't see a reason not to. And cases more in the camp, I write a test when I need a reason to kind of thing. And they're just they're not bad. One's more test driven. One's more of a, like a more of a base of regression kind of thing or like other testing is more of a, I'll write tests when I need to because I do have tests in general, it's just not a like unit tests or general tests of everything code coverage and all that lot. It's a different thing. I'm not going to criticize test driven development because it's not necessarily bad in certain domains, but in certain other domains, it's kind of like not it seems like you're writing more tests than the actual code, which is not necessarily productive. But whatever, or useful and as many things in here, yes, it says like, look, cases, I do test as well. But then again, here's the difference he writes. So Mr. Martin says, I appreciate tests, unless there's a good reason to this and Mr. Martin and Casey write tests when there is no good reason to when there's a good reason to. So it's kind of a different distinction here. Now he actually starts quoting again from his book talking about this and he and he kind of distinguishes between the operand primal and operation primal he's calling here. So it's kind of the difference between I'm going to call operands operands variance in this case, because it's a variance and operation. So they're not using the same hoe gets a little confusing for me. So now they're kind of talking about the different benefits of using one of these two things. And great stuff here. But then there's one other term that he brings up in here, which is dependencies. And he's using this in a very, not the way that most people would use the term dependencies. So a good example of this would be is calling dependency inversion. So I'm just going to read right, I'm going to say what he's written because it's, I'm not going to paraphrase it very well if I don't, it says here, that would be the bottom line if there was one other thing, okay, about dependencies, the cases of switch statements create an outbound network of dependencies towards lower level modules and modules in this case, he's talking about like timing and such like that, that kind of module in this context. Yeah, each case may call to out to these other modules making the fan out of the switch statement very high. So he's trying to argue against switch statements and trying to say, look, if you go for the more polymorphic approach, like the inheritance base approach, we have like a v table with sub typing, which is what I would class is inheritance to begin with any of the emergent concept of those two things joined together. And he's saying this is going to be making it the fan out of the switch and very high that this is going to be much bigger. Because it was caramel says any change to one of these lower level modules can force the switch statement cases, which statement the video, he's usually prefers the inheritance style not always, you'll get into that can force switch statement and all higher level modules to depend on on that switch statement to recompile and deploy it. That can be a very large cost. On the other hand, if one uses dynamic polymorphism, object oriented, instead of a switch statement, then those compile time dependencies are inverted. The lower level modules become sub types that depends on the high level base type. And the source code depends is then point in the opposite direction of the control flow. This is dependency inversion. It prevents changes at the low level modules from forcing a wave of recompilation redeployment from sweeping through the system towards high level modules. So this is just a really weird confusing terminology is just made up in a weird way. I'm saying who has made it like no, he kind of actually has. I tried searching for this and it's like, it's not consistent what people mean by that term. And also, when people talk about dependencies, they usually mean like third party code, usually, or sometimes they talk about dependencies like, Hey, what does it very dependent on the things like all the bits in the thing like he's talking about modules, but that these concept of a module is much more like a class than a library. So it's kind of a very more old fashioned approach before like libraries and packages and modules were more like standardized in other languages, obviously, but whatever. This is why I'm going to confuse because the argument he's trying to make. And this is the thing I would personally try to understand as well is that between the the variance and the operations, the switch statement is closed to the number of variants. But it's open to the number of operations. Like for instance, you can always add more operations really easily. You just add a new function with another switch statement inside of it. And you've now added a new operation to all of these different variants. Yeah. Whilst the inheritance style is much more open to is more open to various operations this time. So it's a closed set of operations, but open to numerous amount of different variants. This is the whole point you have a base class and variants like subtyping from it, the whole point you have subtypes or whatever, and it's more open that way. So it's a lot more useful to be doing. If that makes any sense. Yeah, hopefully that's clear. So that's kind of the argument. Now my point personal view is that which is getting talking in the thing here with the commentary search is that the most the time you actually have a close set of variants, and usually you want to add more operations in practice. So because if you've got a close set of variants, why pretending as if it's completely open, which is what inheritance is for, it allows everybody to add more variants, even if you don't have control of that capability, you just extend to it and it's abstracted away. But most people within their own code base, like it's not going to be used by third party people ever, usually, pretty much isn't. So you in that case, it's very close set of opera, it's close at variance you have. And usually when you're modifying code, you actually want to add more operations. It's kind of like a different thing. And they're solving different problems. You have to understand this. It's just that the weird oddity here is their argument is actually, you know, the, the, the inherent style approach, which has all of the operations for each variant bundled with that variant, it's easier to manage. And the going on about like managing all these different dependencies and talking about how many different places you have to deal with. In case you just correctly point out like, Hey, it's just a different win in different ways, like this independence in version thing, is you're just trying to get complexity. And again, Mr. Martin says, yeah, like for every program composed of O operations and T types has complexity of O times T. If we use O, we can cruise T with minimal disruption to increasing O and vice versa. Well, it's like the switch same as you have increased operations within disruption, but disrupts source code. Now, I don't think this is true. I don't think the disruption is actually even equivalent because it's weird. I know we shouldn't be talking about much about this is not really clean code anymore, but it kind of is related to it. It's just the, but practically, how would you know which one is more true the case? In my opinion, personal experience, we've always had a close set of variants. Like if you want to have a new one, fine. But that variant doesn't really like, okay, we got updated every single place. Now I use Odin. So my switch statements will yell at me if I'm missing a case by default. It says, Oh, you've not handled this particular operation for this particular variant, like in this particular case. And I just need to handle it. Okay, great. That's just better. I know C and C++ and summer languages don't do this by default, but Odin does. So clearly, that's just a better language can solve those problems. It's not really a or better tooling in general. It's not really a inherent thing. It's just a tooling problem then. But then this is where it gets a bit weird. He starts breaking things down to source code management about runtime source code dependency inversion, and just make some terms up which are not colloquially understood to be meant in that context. But again, it's the right a lot of text. Try and make people understand how he thinks. And then Casey just write small amounts. It's the it is a very big politician thing pad it out. Very good rhetoric. I mean, he's great at this. This is where I'm praising him, by the way. So again, read it for yourself, make your own opinion. If you disagree with me tip can tell me in the comments below. Tell me where I'm wrong. Please tell me where I'm mischaracterizing me. If I'm being too harsh, if I'm not being harsh enough, if I might work, look, I'm not even it's fine. But he then it is fine, like just just read it. He's talking about these different things here, like he's procedural, so it's itself statements, which statements, whatever. And he's calling this a run time to high run time dependency, when actually, no, we're gonna make this compile time dispensary when it's on the type site. No, you just switched them around. They're both the same. So yeah. So one thing he brings up here, which I thought was interesting. And it through this bit, as well as the second part, these starts up, I'll explain why he does that in a minute. He brings up, I would call the canonical case for inheritance. So the canonical case of inheritance is the data stream. So sorry, if I've been a bit rambling all day, I'm just trying to understand it because it is weirdly flowing as well. Like the actual thing isn't like, it's a weird discussion. But so I apologize for that and also apologize for my rambling as well. So hopefully that's okay. But again, should be all clarified here. Here he does the canonical case for inheritance, which is literally a stream, a data stream, a file or something like that, and explains that Oh, these have standard operations, a close set of operations like open, close, read, write, and seek. Again, these are the five standard functions of the Unix IO driver. And again, these are very standard functions on all operating systems. So they actually map really well to the inheritance style of doing things, the very dynamic polymorphism is he's referring it to here, which is, yeah, it's dynamic dispatch. Subtype polymorphism with v tables. Yeah, that's what it is. But he's calling it dynamic polymorphism, which is not common term, but he's whatever is using his own terminology as he needs. But it's saying like, okay, we've got a closed set of operations, but we have so many different things like files could be anything, they could be a file, it could be a directory, they could be a piece of hardware on your device, they could be just a general socket, there could be anything. It's like, it's open to be whatever it could be. This is literally the canonical case. Why is the canonical case? Because operating systems make these files an object. They are an object. That's what they have. Like they're an abstracted away opaque thing with a open like close interface as to what they are. So he's trying to argue like this is what you meant to do. Now, there's a lovely lovely thing here is saying like, well, this clearly has to be a thing. And that's why he's trying to get down this route. He's trying to take the canonical case to show to Casey that hey, you need inheritance sometimes. And this is the great way. He's completely forgot the conversation is talking about clean code, which will bite him in the book later to use an American phrase later. But then there's one this weird thing he does here, where all of a sudden he talks about this hypothetical compiler, which would be able to you could write in the in the oopy stage, like an inheritance style, and then completely the compiler would magically make this be a switch statement if necessary, which is kind of interesting because it's like, what what benefits would you get from that? Because it seems to be now a textual benefit. It's like, you're talking about, oh, it's all clumped together. A new variant or you know, like, but you've some weird things. He just says it's just a really weird hypothetical scenario just kind of goes into. And they go on for this for a little while. And Casey's like, I don't understand what you're talking about. Like this doesn't make no difference, even with this hypothetical case. So Casey goes on a bit more further here, just mentoring different things. And talk, I try to get what the benefit of dependency inversion is anyway, and to begin with. And the go on about this, like, look, you've got a clothes interface with opaque stuff, and different ways of dealing with it. And then we talk about this payroll thing that they do all these different things. I recommend reading it. But it is going to be this. Like this is an oopy thing, obviously, you've just defined it to be because it is is defined to be oopy, sorry. Yeah, okay. Yeah, yeah, yeah, yeah. But again, Casey also kind of says it could just be sound line functions. There's no reason, whatever, whatever, that's not a problem. Where am I looking for now? I'm sorry, I'm just trying to skip through this because it just goes on for quite a while. Okay, so Casey says that hypothetically, you could just not do this and have it just a union. Because in the example that Casey does when he does the union, the shapes example in the video is, is this actually a union? It's what I would call a fat struct union or an open open union where it has a variant and then just open fields. So it's kind of like a table like thing, a fat struct is a term that's Ryan Flurry kind of popularized. And it's kind of just like, here's a table of data, all the fields available. But hey, how you can just switch on it like all this and just do whatever you need to do and just access the data when necessary. In case you're saying, look, hypothetically, you could do this, you could just have a file type with all the data that responds to this in this union and deal with it. Because in practice, there's actually only a certain set of files you could have, you could even have the general case where it's, it, it will be like a V table. Sometimes it won't use a V tail, but you can always optimize off that. And there's many different things he's discussing here and such. And he's talking about the union case. Now, Martin, Mr. Martin goes here and says, look, it seems like come on, come on, wild up at the agreement on just about everything other than per individual preference. And it's like, no, he's trying to say, look, but we don't disagree. It's like, actually, why are you having this conversation? If you don't disagree, you clearly do actually. And you'll show this later on in part two of this written document. And he says, thank you for the union collaboration. Now I understand what you're talking about unions, which is like, okay. And he says, I'll quibble you a bit on the difference between operand and operation, but I don't think the quibble is particularly important. In the end, it's just all functions regardless of how you spell it. As for human issue, performance is a human issue. The computer doesn't know how fast or slow an algorithm runs, but I think that that horse is dead now. And it's like, no, it isn't. This is kind of the point. And he goes back to his microseconds, different module things again. And then he then goes, look, we put a break in here to write extra bit more to go rewrite history and says, look, I'm going to continue us now in the second document, which is the number two. Because he's trying to like make break here, and then reframe the entire question in the second document, it's a pivot and a reframe at the same time, clever rhetoric trick. If you want to do that in an argument, you do that all the time, you reframe the question. So it's now they're not even talking about the original thing again. And he's tried to do this. So that's what he's done here. Right. So right at the beginning. And then Casey's reframed it and put it put it into the beginning. So he's first. So Casey knew what he was doing. So just don't let's not do that, shall we? Yeah. So Casey wasn't stupid. He's talking about all this goes back to the payroll example with all this kind of thing. And Casey's trying to say is like, look, this is not an open problem. You haven't got an open set of variants. It seems like it's an extremely well defined problem. So why does this need to be like operand, operand, primal design was in like variant open, rather than variant closed. And then operation open. So this seems to be both closed. Like it's very weird. Like what, what are you trying to have in like save developer cycles with like, where's this kind of thing coming from? And then this has been moved to because he reframed it. It's fine. No problems. He's talking about the programmer cycles thing. This is the thing he gave this random file he added in here, which is the, oh, great. Let's do a code golf example, shall we? Cute surprise. It's like the point is the program cycles, waste management, programming cycles, it's like, yeah, you just gave me a code golf example. The worst case of readability possible, like, but it's a code golf. That's the whole point. People write those things to be compact and human. Like that's what you're trying to say. Like we're trying to make it easier on like, can you prove my belief not mathematically, just as I'm sure that you cannot mathematically prove that your favorite style saves more or less programmer cycles than mine. It's like, so he's already admitting that actually you can't prove my style is worse than yours style. And it's like, because programmer cycles, like this is a qualitative thing. He knows he can't measure it. She's actually, I don't think that's true to be honest with you. It's just that no one's really bothered to do the science because programming isn't really young discipline or 70 years at best really as a discipline. So it has no evolutionary like pressure on there yet to say which which things are good or bad. So people just say random things. So it is literally just like, great, there's not really much science in computer science. Rather, again, I'm glad the rest of the world calls it informatics for a reason. I don't know why we don't we call it computer science, even though it's not an empirical science and it's close to mathematics, but even then it's not really in practice is close to engineering. It's just confusing term. Okay, confusing term. The dynamic was a dynamic building and other type of just from typos, whatever I make more than this might be in day to day life. And he's talking about this. So it says, do we agree so far about this? And it's like cases kind of like, well, we don't just worry about certain things in the general like in the specific, I'm still asking the same question about this data stream thing you're talking about. Then Mr. Martin brings up again, the like, hey, here's something like the read write thing for a C. These helper functions don't you know to do all the stuff? It's like, but if you had to do it in your case, we'd have to do a switch statement like this wouldn't we don't you know? Oh, it's like, look at all the different variations you could hypothetically do this just ugly. Don't you know it's ugly? By the way, if you this is, this is gonna tangent anyway, I've been writing the Odin core library and you actually have to do this anyway. Like if you actually have to do like you do the read at the OS read functions, because the console on Windows at least does not act like a normal file. In fact, the console on Windows is a UTF 16 document. So that means you have to write UTF 16 files. If you actually write a UTFT thing to it, you then you have to do a conversion to do it onto those. It's actually like already or you have to do this edge case. And not just that the console has other things in it, which are not handled the same as an old file again. So it's a very kind of have to do this. This is how real world code is not even purely like, oh, the operating system has dealt this properly. It's like, no, I still have to check if it's a console specifically and then deal with it. So it's like, I know like, this is not working. Like, yeah, it actually looks closer to this in real life, even with the, the abstraction on top of what a file is, but I digress. Yeah. But yeah, it's just interesting. And then again, many different breaks can different edits here different sections is breaking it up. The VTab we use by Unix, again, most operating systems do this as well. Things change around significantly. The idos can be loaded at any time, the iodevice, yeah, that's true. That's took in this details we're talking about. He's talking about code reuse, great example says the cases. I apologize for trying to be very specific, but I really want to be actually get to the exact proposal. And it wasn't clear from what could you actually tell me what the OS interface looks like and how it's implemented. You said, I guess that depends on a lot on the language and the application. But my understanding is that we're talking about the OS side. So, and again, it's the, how does the OS implement this, like the, the stream, the file, compared to how we're doing it in a language is very different. And not just that, again, I thought we were talking about clean code. But why has it gone down this digression? Just you wait. Let's go get that. Don't worry. Okay, we're talking about get all crap. Okay, because it just changed. That's, I can probably guess which day this was written on as well. Like you're saying it seems like it looks like this somewhere. Is it actually a base class? Is it whatever? Now, Mr. Martin says, okay, here's kind of the general interface that he's writing C++. Again, he's not answering the question he's asked. He's done another thing. Whatever, kind of missed the point again. And then he's saying, look, look, if we look at the, he's trying to say this is less like the code is easy to manage whatever. Like, yeah, but you've just chosen the canonical example. And he says, look, if I do the dynamic polymorphism case, so inheritance, I create, I create this file of three files and have to leave them with a switch case. I've now all of this and look at all these different things I have to define. I'm like, and cases, well, hold on, since I'm the switch proponent, at least I get to write it, please. Look again, look what he's just done. He says, well, I've just shown you how to do it. And look, it's just more complicated. I've had to write files. Oh, no, I'm like cases like, hold on, hold on. Yeah, and it's kind of doing like this. So it goes on and on, we just discuss things, but it's like cases like I want to know what the operating system again. And it's different. Okay. And then cases like we're not even talking about machine cycles again, I'm just focusing on the program cycles again, what like he's doing again. So I'm like paraphrasing this poorly ish, but it's kind of just like, I'm trying to show the techniques that he's doing here that he knows he's doing it. He isn't an idiot. I'm trying to be very careful like this. Mr. Martin knows exactly what he's doing. Like he's now just made another document on here, which only he talks about. And it's just he's trying to suggest like, oh, this is the clean code stuff. And then he's saying this is what clean code is. And I've just got the summation seems to correlate with what I most people think it is. Because I miss people people keep this understanding me kind of view. And it's like, wait a minute. So choose carefully names, not unique. Keep function small. Why keep classes small. Why manage your dependencies, vague as anything. Literally, be careful with side effects. Okay. Yeah, express yourself in code where possible. How else you meant to express yourself in code away? It's your programming. Use polymorphers when the type changes fast in the operations. This is new stuff he's added now. You switched when operating change fast in the types. Why? Why? And at what cost? And what Harvard evidence have you got? This is better. And like, you compare it to this and like, you sure? Okay, when possible, create designs where things that can change fast that change fast are types. Why keep asking this question? Here's in his even in his summarizations of here, he's actually saying, we'll prefer polymorphism. So now he's in like, well, I don't see how you got to that conclusion where like, I'm against switch tamers or something. I'll clear and prefer like default before like all this and like, you're literally saying it in here in this summarized document. If I'm misinterpreting it, please tell me again, in the comments or something. I'm just really confused. Like, what? Right. So Casey comes back again, and he's talking about the internals of this. It's like, okay, find the device, then you read it and you do this. This is how ring versions, if you understand how they work internally. Okay, great. There's class, here's the operations. And it's that looks, you can always do it this way around. And look, I've got a different way of doing it. So just a union based approach now, with all the data inside of it doing all what we need, whatever. And that thing that's just is actually trying to show the actual things internally, isn't it? But yeah, it's kind of like, look, now I don't like vtables, because obviously pretty much everywhere, because I find them hard to control. So I prefer this. So he says, look, I have a, not a vtable, but just inline things itself, it's not a table, just inline functions. So instead of a class, you've now just got inline methods. And this is just general handling thing, which is interesting. By the way, that should be more better for performance in general, because a vtable is usually a pointer to a structure of a function tape, like function pointers, whilst if you're embedding the function pointers, you've got rid of that indirection. So you've actually got it will be faster in general as well, because you've got rid of the indirection. It always has a better chance to optimize and even it has slightly better chance of inlining and slightly. But yeah, that's how compilers work. Sorry, rambling again, again. But I'm getting off the digression. But cases kind of saying like, look, we could just handle it for each of them that we could actually have one callback, just one, and we could directly embed it in the structure. So it's not even in directed anymore. And then we switch on this. Now this is interesting. You could do it for every single operation. And then look the codes in one place for this thing. We've now got the best of both worlds in many ways. And why wouldn't you prefer this way? I think now interestingly, I'm just going to like slightly digression here going into Odin. And this is what we actually do for the allocator. And I've been doing this for like a decade, maybe even before Odin. There is the thing sorry, apologize for the digression. This is clearly unscripted if you didn't guess. Here's the allocator. So we know that we have a built in concept from an allocator and allocator is just a little data structure with a pointer to a procedure and appointed to the data. So 16 bytes, you can easily copy this around. So it's usually not even appointed to the allocator, it's just the allocator itself in memory. And you just get the values. So that's what you're doing. So there's not an indirection again, because it has to be a pointer. And notice it's just in line with the function. And not just there's only one function you think, but there's loads of different allocation operations like yes, it's one function, you take all the arguments in, and you change the allocation mode is an allocation alloc free, free or resize query features query and for an alloc non zero. Because sometimes you want to be allocated without a zero, but by default you want zeroed because it's quite useful. And also it's pretty much free if you're using like virtual memory, like allocating zero memory is pretty much free. Because it has to be for security benefits. There's no option to not get it if you ask for virtual memory. So I'm just trying to show here that I already take advantage of this kind of approach. And then within every single allocator, I have a switch statement which then pairs each operation together. So I'm just trying to get off my digression a bit here. So this is what case is kind of trying to say and you could do this. So you're not having the full on inheritance style, you just have a switch you could do the blend of the two. And there are benefits to this, obviously. And you'd have all of this lovely. So because in either case, but this is larger rather than because it's solely look look up map look up now and to a specific device and it can be used in either design. Anyway, over the course of the development of the OS, I think the implementation saves programmers and cycles potentially a lot of them compared to the one I understand believed you favored by the clean code method. Again, which is interesting because the casey one is closer to being like, sub typing to a sentence, but there isn't sub typing, it's just like, here's the abstract thing with a function pointer, deal with it. Which is kind of close to inheritance, but it's not just one. And it sounds like a minor difference people say, oh, it's equivalent. It's like, but it isn't equivalent. In fact, it will be faster. You can easily measure it. It'll be easier to maintain because everything's in there. And not just that, if you add a new operation into there, every single one will just yell at you anyway, because you've not implemented it. So if you've got a language that tells you that switch name is not necessarily C or C++, maybe modern C++, I know, I think. And sometimes C with the, when you have warnings all and everything will tell you switch name is missing certain cases. But yeah. And cases look, I don't know if it's a bit of an extract and file, because I'm sick, but it was the first one you brought up. And it happened to be the contrast, the two designs in my opinion. So it works, works for me as Casey is saying here. Here's why I think an enum based design deserves the programmer cycles. In most systems, you don't know all the functions that are going to be used ahead of time when operating costs are hard boundary, like a driver, using operation codes instead of virtual function calls allows you to add more functions dynamically without recompiling all our drivers. In any modern operating system, multi-threading is a concern. But this is especially true for an operating system, having the protocol be structured based with an operation code allows us to trivially buffer operations in things like IO rings and other intermediaries, intermediaries, without writing any new code. The entire system remains identical. Yeah, I'm just trying to do this. And you just said, this is by the way, it seems like almost happens in almost all systems, OOP systems, I see, I'm trying to get around pronunciation, say, because eventually they need to serialize or something similar. And so they have to write my version as well as the version as their version, but they don't seem to realize how much time they're wasting. Like, yeah, this is clarifying this point. People think this seems like the clean code will actually save time, but it's actually no, you're now forcing another person to write the same thing again. And you are actually wasting time, you think you're saving things. But again, if you want to know if you're saving time, you're making a statement like this will save programmer cycles, like a claim, show the evidence. And don't just say, well, my your seniors may agree with me, because they were convinced by my argument. It's like, yeah, but where's the evidence, regardless of this authority, this later argument by authority. It is the after a while, many people will come out the phase and like, oh, I don't do this anyway. But some people don't. And it's like, okay, I never really went through the OOP phase myself. Going a bit of a digression here. Sorry, this is completely random today. I know. Very, very unstructured. But I went through the modern C++ like 11 phase. So that's what 12 years ago now, probably a bit before actually, because it was C plus plus zero x for a long time. And I remember learning all that stuff. And that was the thing I got caught. I wasn't really necessarily the OOP phase. It was that phase. I was learning all that stuff. And it was a while took me a few years and after was like, I'm doing all this extra code, writing loads, and I'm not getting any more productive. In fact, it's how hard to maintain. I'm writing literally 10 times more code than I needed. And they kept telling people kept people kept telling me because I was kind of trusting these people who were more thought they were more experienced with me or they thought they knew more because they've been doing it for longer. And they were talking from positions of authority to a certain extent that they were going, Oh, of course. Like, of course, this is going better because I'm telling you it's going to be better. I'm like, and then I was kind of believing them. And I was like, it doesn't seem like I'm trusting them. But it didn't it didn't seem to the case when I just started programming back to like a normal basic C style with switch statements in many cases, and just like normal standalone functions, no, not even using methods. I got more productive. My code got smaller, got easier to read, just by not doing any of that. And it was kind of like not using not doing any of the stupid templates, not doing stupid any of the ownership semantics. I'm not saying ownership semantics stupid. I'm just saying the being everywhere was like, look, I just kind of went to more pod data was a plain old data data kind of style old fashioned C style, my code just got easier to read more maintainable and just everything like from a personal perspective, again, I cannot measure this. And the only way I can convince people say, here's my code, here's this normal code, which one define easier to read. And that's the only way that's not a measuring that's just still like a personal preference thing in the day. This is the problem in these discussions. And it is just getting down to that. It's like one side is there is an empirical thing to a certain extent, which I'm going to comment right at the end. I will get to this, don't worry. But he talks about this saying here at any point things, if we would like to buy third parties to allow communication with channels on the devices, blah, blah, blah, okay, we're talking about the IO stuff, fine. We're getting nearly getting the answers. So Mr. Martin says, okay, I think I see where we're going. So let me say, sure, looks good to me, the bullet points you added are after the fact are all quite valid. And the design you picks works well in this case. In the first point, you assume that operations will increase beyond the two original proposed, as we both agreed, as I wrote in the clean code, which, by the way, is not the same as your clean code. Right, when operation periphery more rapidly type switch statements are better. So there's that line alone is or another rhetoric trick, lovely one, in fact, in my opinion. In the first point, you assume that operations will increase beyond the two originally proposed. Okay, as we both agreed, I don't think Casey agreed to anything. And secondly, Casey's not calling what he claims clean code, he's trying to understand what your clean code is Casey never says his code is clean code, because yours is Mr. Martin's clean code with a capital C trademark to kind of think. Yeah. So another little kind of trick he does already any can't help himself really. So when operations profite more rapidly type switch statements are better. In point two and three, you raise the specter of multi threatening, you are of course correct that queuing operations is a lot easier. If you request packets of the same type you design no argument there. And the last point proposed a kind of hook for unknown and unspecified possibilities in the future. Yeah, so what he says is like, okay, you have the general cases and then have a hook for the unknown cases like the open cases. Okay, if you think those unknown cases and special are likely, then you should have considered them earlier. But then that raises a number of other concerns that we should not likely address in this document. It's like, no, no, no. So I think I'll let pass. No, why? Because if you didn't, he has to let that pass because it then kind of defeats his point. Because the inheritance approach, which is preferred by clean code, is saying that the open case is the open set of variants, the open set of operands is the general case. It isn't. Because if you've got a close set, which you know, like pretty much always know that 99% of the time 99.99% of the time is going to be going to be closed, like pretty much going to be that small set. So you're optimizing for them. And then you've got this, the unknown hook cases allow the user to add their own callbacks in there. Fine. That's fine. But it says, it says, unlike to consider the head of time, it's like, yeah, but you're assuming that those unknown cases are just as common as the known cases. And that is actually designing the API. Now the thing is, if you're optimizing for the general case, and then you allow a hook in, that hook is not going to be is not going to be any slower than if you design it to be always a general case than the specific cases. That's the point he's trying to say here. Like, that's why he's letting it pass, because it is literally just as fast to do it that way, then to design it all the way around as if it was always unknown, as if it was always dynamic polymorphism. Sorry, just say inheritance, be easier, because technically what it is in this case. So now where are we? You propose a solution that uses dynamic polymorphism, select two types, and then a switch same to select operations. I have no problem with this. It works well and satisfies my concerns about dependency inversion. I'm like, but it isn't the same kind of dynamic polymorphism that you've ever recommended to anybody. So this isn't technically key and code. In fact, anybody who would a clean code advocate would read Casey's code of, let me go back to it, this and go, that's not clean. So this leads to the problem of clean code is whatever Mr. Martin says it is at that moment. It's not like anyone could actually agree on what clean code is because it changes from time to time. It's not a well-structured thing. And he's like, that's fine. It's like, then why don't you just call it Mr. Martin style? Because it clearly doesn't work. It's not clean. And it clearly doesn't work the way he wants it to in every single case. But then you shouldn't do it like a dogmatic. And it's like, it's a weird trick. He says, look, don't be dogmatic. Don't follow these the rules. But then it's like, well, I won't, I don't agree with it anyway. Well, you clearly have some of these rules, don't you? It's like, it's that clever trick again. It's the pork barrel naming again. It's the rhetoric over rhetoric over again. I'm like, look, even if Mr. Martin style increased programmer cycles, the decrease of wasted programmer cycles, like, whatever. Great. But how do you prove this is the case? And we're getting to the end now, and we're just going to do here. So I'm going to read the best of it. So, so Mr. Martin's your proposed solution time with thing blah, blah, blah, blah. What do you got to this? I will say, however, that that is an ironic that after your video and after all the stress that you have been put on saving machine cycles, you eventually chose a design that sacrifices machine cycles to save programmer cycles. After all, on the OS side, this is where he thinks he has won the argument. Ready? This is what he's tried. He's tried a trick. He's tried to do it because he took the canonical case of a stream. After all, on the OS side, you've you've got to package up all the quest packets and it's the dynamically dispatched handler and then run the operation ID through a switch. And I think we wind up in the same place when operations proflate more rapidly than tights, we both use switches, you don't, you do not do this. I've read your code, your public code, you don't do this. But he's saying he does just pretend you believe it. Okay. When tight for a plate more rapidly than operations, we both use dynamic dispatch, we are both willing to sacrifice machine cycles to save programmer cycles. No. Also the way again, how Casey structured it will be better because it's not technically how many levels in direction do you have before like technically here has one level of indirection, which is a function pointer compared to normal inheritance, which is three levels of indirection. Why? You've got a pointer to the object, pointer to the vtable, then a pointer to the function. Guess which one's going to be faster? Just have a hesitant guess. Okay. And not just that, you've then have to go all through this indirection compared to having one, which is probably going to be in the literally cash already in the cash ready to be called. No problem. It's going to be easily predictable as well for the CPU. It's a very different thing, very different operation that is to a generalized vtable. So no, they are not equivalent, even in performance. One will be quicker than the other. I'm not doing this video. I could do another video if you'd like, but like we could prove it, one's going to be quicker. Single indirection compared to triple indirection. Okay. So when we are two individuals on the same eye and the only difference being that I wear this shirt and I don't know how to pronounce that word with clean code and you have one with clean code, I'm like, thank you for simulating the debate. I appreciate your candor and the civility that you exercise to and if, if not everywhere, I've come to experience your respect, your knowledge and blah, blah, blah, blah, whatever. So the first thing is this is a really dodgy thing. Casey and even cases, well, I disagree with most of that. But if we're ending here, I'll just finish my final responses for Gail poster poster posterity. And that is the thing. See how he tried to end it. And I'm going to read through Casey. I'm not going to comment on it now. I'm just going to read it for the end of this video because we've already been going on too long. Sorry. So I apologize for my rambling in between. I hope it's kind of an enjoyable if not, and I apologize again. So I'm just going to read through this. I'm just going to read Casey stuff. This is all Casey, not me. So regarding as I wrote in clean code, which by the way is not the same as your clean code? Well, the point is of discussion was your you to elaborate on what is not the same. But you're designed for the IO system looks exactly like my clean code example of virtual function for every operation, one class per element in the system with no predication. So what are these differences that you're referring to? Now would be the now would be the time to explain what they are since that was the point of the concrete example. If these are a bad example for accelerators, straighten the differences, that's fine. But it was the first one you gave to assumed that it would be the one you want to use. Regarding when operations proliferate more rapidly than types, switch teams are better. That was not the case here. In no way are operations proliferating more rapidly than types in the system. Vendors will add drivers to the OS constantly, perhaps monthly or even weekly, whereas the number of operations in a particular system tends to go much more slowly, once every few months at a maximum, but more likely once a year for something like the aniosis subsystem. It isn't the opposite of what you said. This is an important distinction, because what I'm demonstrating here is the opposite of your rule. This is showing that even in the case where types proliferate far more rapidly than operations, as in the case of drivers in an OS, the principle doesn't work. Enums are better in both cases, specifically because you have potentially thousands of types in the system, all different drivers, all the vendors have ever shipped. Adding a single operation, however rarely, can cost massive programmer cycles to the unnecessary work multiplication across types, the V-tapels course. Another way to say this would be enums are more important in a system where type proliferate rapidly, not less. Regarding, you eventually chose a design that sacrificed machine cycles to save program cycles. I did no such thing. The design achieves both, like why I like it. It's drastically faster to use something like a packet-based system than something that is originally proposed design, because you do not take a ring transition on every operation. New OS IO APIs are not all designed this way. This user writes data without taking in talking to the OS, and a kernel thread picks up those data writes. Nobody ever makes a function call, except occasionally to ensure the kernel thread hasn't gone to sleep. This is what I mean by the bullet point, if at some point we decide users should be able to do multi-threading book IO ops. I am talking about the necessity that actually occurred in both Linux and Windows of removing their frequency of ring transitions for saving CPU cycles. None of this is trading CPU cycles for programmer cycles. It's achieving both. The Linux kernel design of the IOU ring looks like my design. That did not add to save programmer cycles. They added it because they wanted the highest possible IO throughput. This is an almost universal principle of modern OS design. Anything that can be turned into data writes should be, and function calls should be minimized. It's been true for GPUs, for NICs, and for our example disk IO. And the last bullet point is regarding, and so I think we wind up in the same place when dynamic operations proliferate more rapidly than types we both use, switches, when types proliferate more openly than operations we both use dynamic dispatch. Again, I don't see how you got there. Obviously types are proliferating more rapidly in this system, so that is part, is true. If we didn't believe drivers are proliferating rapidly, why are we loading them dynamically? And I thought that was the entire point of the example, but perhaps more importantly, we are not using dynamic dispatch here in the way that you've been suggesting. As I was pointing out earlier, I said that when I proposed the design process, I would also do the inside drivers themselves. I would not duplicate drivers to remove if statements and switch statements inside a driver that allowed the drive to handle multiple similar devices. The only reason that there are function pointers in this system is because the problem definition required that we load the driver from a different module, and we are not presuming a JIT or something that can weld, wield, weld things together for us. That introduces a mandatory cut so we cannot get rid of it because the problem is defined to contain it. But note that this is not the same between our two approaches. I have a function pointer there because it's required, and you'll note I minimized the number of all the way down to one. I didn't put it in there because I think it saves program time. In fact, I'm not really sure I want it there at all. I haven't actually implemented this particular system in an OS, so it's somewhat off the top of my head, but it's very impossible that if I actually went to write this, I wouldn't include that function pointer at all. Instead, I might just have the OS thread reading the queue, sorry, the OS thread reading the queue, and pre-filtering the packets for quota permissions, then updating a shared memory access that lets the driver know it can process the packets directly without actually implementing. I can't say that's for sure what I would do, but it's probably something I would try. So thanks for overstating the similarity of our approaches, but I think that they're similar, then I guess that's just where we end up. Thanks for taking the time to create this thread which pushed the GitHub emoji to check a well beyond its limits. Sorry, I had to read all that, but yeah, that was all right. So this is kind of the point I was trying to point out is that case was saying this isn't what you were showing, and the point where I say like Mr. Martin thought he won the argument, like you need to use this style, is by using the canonical case of requiring it, which is the canonical case is a data stream, a canonical case of like you've got different operations fixed interface, but you've got an opaque different what it actually variant type, whatever it is. And then they talk about actually how does it implement the operating system case, it actually just shows that actually effective this is how you do it in Linux. We don't know how Windows works kind of, we can reverse engineer it, but like it's not the source code, it's not public obviously, because it's a closed source operating system. But that's kind of the the issue that's going on here. Mr. Martin thought he won by showing like you already just did dynamic dispatch. In case you went, you just find it to have it. And in fact, I didn't even require multiple functions acquired one, it's not tripling direct to any single interaction. And I just had a switch name in there, because this is also how the operating system does it. And it's better for literally CPU cycles and reduced programmer cycles. It's not one or the other. So hopefully this is okay. And I'm done now. I was just going to do this. And I was talking about this, we've already discussed this, what I've seen was I did a tweet on it mildly. And there were some other things I was talking about here on to talk about Mr. Martin, but I didn't in the end be honest with you. It was more of a, I'm just showing the rhetoric styles of Mr. Martin. That was it. So I hope you've enjoyed this. I apologize. This is about 120 minutes long. So thank you for putting up with all this. I wanted to end off with this little thing here is what I wanted in for. So we already had this in his code, but someone commented here saying, look, I says, but there's kinds of environments though, the parsimony is important nowadays, far and few between the vast majority of software requires less than 1% of modern processing. This is the first section we read. What's more processes are so cheap and available that is a trivial matter to add more of them to the system. Someone replied, I should know this person by the way personally, we do not consider it good engineering practice of the person wrote it, not the quote, good engineering practice to consume a resource lavishly just because it happens to be cheap in the class of it or Nicholas worth one of my actual programming idols out there. And I love this quote because it's kind of as viet slaw of worth slaw. However, it doesn't care. It's either name by or bind value. It doesn't matter. And then Mr. Martin replies, that depends upon the, which resource you are talking about computer cycles, computer cycle, programmer cycles, which should you trade against? And again, I don't see what being the odds, but simpler code is easier to write. Our bubble source is simpler. The tricky again, it's another trick. It was just last showing the rhetoric trick. Simple is actually an overloaded term in programming. And it's an overloaded term in English, because simply you need to mean the opposite of complicated, or it can mean the opposite of complex. And in the case of complex, the technical term would be simplex. So is it simple as in not complicated or simple as in simplex? And he has just done this on purpose. And he knows it very well by saying, well, bullsaw is simplex, but it's very expensive. Multiply and multiply by repeat about it. So it's simple. Actually, that's how, that's how like AMD processors, not AMD ARM processors actually work, by the way, they don't technically implement multiplication. x86 does, by the way, ARM does AMD 64. Sorry, I should say, AMD 64 does an x86 in general. It's actually one of the only, it's very, very, you find a processor that does this, but they did it. Linear searches are simple. Like, yeah, they are simplex. They also may be simpler, faster as well, but they might not be. Like, there's a reason. But this is the trick. So I just want to end on that note. So I hope you've enjoyed this. Please remember to like that smash button, and to comment in the description below. And again, if you want to read any of these links before, I will post them in the description of the doobly-doo below below here. And hopefully you've enjoyed this. This is a very unstructured ranty talking about Mr. Martin's rhetoric style with regards to clean code, how, and at the end, effectively, he just stated exactly what most people thought clean code was stating, and Casey went, so I was right about what clean code was. Okay, thank you. So goodbye, everyone, and stay tuned for the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.72, "text": " Hello and welcome, I am Gingerbell and today I'll be talking about the fiasco that has", "tokens": [50364, 2425, 293, 2928, 11, 286, 669, 34637, 7100, 293, 965, 286, 603, 312, 1417, 466, 264, 283, 4609, 1291, 300, 575, 50700], "temperature": 0.0, "avg_logprob": -0.25413001211065994, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.5883620381355286}, {"id": 1, "seek": 0, "start": 6.72, "end": 12.84, "text": " happened between Casey Muratori and Mr. Robert C. Martin. But before that I'm going to explain", "tokens": [50700, 2011, 1296, 27369, 9373, 39842, 293, 2221, 13, 7977, 383, 13, 9184, 13, 583, 949, 300, 286, 478, 516, 281, 2903, 51006], "temperature": 0.0, "avg_logprob": -0.25413001211065994, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.5883620381355286}, {"id": 2, "seek": 0, "start": 12.84, "end": 16.240000000000002, "text": " why the history got here and I'm going to also explain some stuff. I'm not going to", "tokens": [51006, 983, 264, 2503, 658, 510, 293, 286, 478, 516, 281, 611, 2903, 512, 1507, 13, 286, 478, 406, 516, 281, 51176], "temperature": 0.0, "avg_logprob": -0.25413001211065994, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.5883620381355286}, {"id": 3, "seek": 0, "start": 16.240000000000002, "end": 23.6, "text": " try and criticise clean code itself. Casey Muratori has been trying to do this in the", "tokens": [51176, 853, 293, 7850, 908, 2541, 3089, 2564, 13, 27369, 9373, 39842, 575, 668, 1382, 281, 360, 341, 294, 264, 51544], "temperature": 0.0, "avg_logprob": -0.25413001211065994, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.5883620381355286}, {"id": 4, "seek": 0, "start": 23.6, "end": 29.64, "text": " long discussions he's had with Mr. Robert C. Martin already. But it's one of those things", "tokens": [51544, 938, 11088, 415, 311, 632, 365, 2221, 13, 7977, 383, 13, 9184, 1217, 13, 583, 309, 311, 472, 295, 729, 721, 51846], "temperature": 0.0, "avg_logprob": -0.25413001211065994, "compression_ratio": 1.715953307392996, "no_speech_prob": 0.5883620381355286}, {"id": 5, "seek": 2964, "start": 29.64, "end": 33.88, "text": " where I just want to kind of show the rhetoric tricks of Mr. Robert C. Martin himself. So", "tokens": [50364, 689, 286, 445, 528, 281, 733, 295, 855, 264, 29604, 11733, 295, 2221, 13, 7977, 383, 13, 9184, 3647, 13, 407, 50576], "temperature": 0.0, "avg_logprob": -0.2228372731340041, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.03131387382745743}, {"id": 6, "seek": 2964, "start": 33.88, "end": 39.8, "text": " before we get to that start off, let's begin with the thing that started it all, which", "tokens": [50576, 949, 321, 483, 281, 300, 722, 766, 11, 718, 311, 1841, 365, 264, 551, 300, 1409, 309, 439, 11, 597, 50872], "temperature": 0.0, "avg_logprob": -0.2228372731340041, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.03131387382745743}, {"id": 7, "seek": 2964, "start": 39.8, "end": 46.96, "text": " was this video that Casey made public from his thing. It's called clean code, horrible", "tokens": [50872, 390, 341, 960, 300, 27369, 1027, 1908, 490, 702, 551, 13, 467, 311, 1219, 2541, 3089, 11, 9263, 51230], "temperature": 0.0, "avg_logprob": -0.2228372731340041, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.03131387382745743}, {"id": 8, "seek": 2964, "start": 46.96, "end": 52.68, "text": " performance, where they say 22 minutes long video, him showing the examples of what clean", "tokens": [51230, 3389, 11, 689, 436, 584, 5853, 2077, 938, 960, 11, 796, 4099, 264, 5110, 295, 437, 2541, 51516], "temperature": 0.0, "avg_logprob": -0.2228372731340041, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.03131387382745743}, {"id": 9, "seek": 2964, "start": 52.68, "end": 57.400000000000006, "text": " code is and going into a more, let's say more like simplified code, which is more optimised", "tokens": [51516, 3089, 307, 293, 516, 666, 257, 544, 11, 718, 311, 584, 544, 411, 26335, 3089, 11, 597, 307, 544, 5028, 2640, 51752], "temperature": 0.0, "avg_logprob": -0.2228372731340041, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.03131387382745743}, {"id": 10, "seek": 5740, "start": 57.4, "end": 60.72, "text": " performance and showing the cost. Hey, if you do it the clean code where you're going", "tokens": [50364, 3389, 293, 4099, 264, 2063, 13, 1911, 11, 498, 291, 360, 309, 264, 2541, 3089, 689, 291, 434, 516, 50530], "temperature": 0.0, "avg_logprob": -0.22189150818991005, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.09019695222377777}, {"id": 11, "seek": 5740, "start": 60.72, "end": 66.28, "text": " to be 15 to 25 times slower as your performance, do you want to take that hit? Understand what", "tokens": [50530, 281, 312, 2119, 281, 3552, 1413, 14009, 382, 428, 3389, 11, 360, 291, 528, 281, 747, 300, 2045, 30, 26093, 437, 50808], "temperature": 0.0, "avg_logprob": -0.22189150818991005, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.09019695222377777}, {"id": 12, "seek": 5740, "start": 66.28, "end": 71.16, "text": " the costs are kind of you. And again, this is this view has also taken our context is", "tokens": [50808, 264, 5497, 366, 733, 295, 291, 13, 400, 797, 11, 341, 307, 341, 1910, 575, 611, 2726, 527, 4319, 307, 51052], "temperature": 0.0, "avg_logprob": -0.22189150818991005, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.09019695222377777}, {"id": 13, "seek": 5740, "start": 71.16, "end": 76.2, "text": " blown up by mad. It's nearly half a million views so far at the moment at the time of", "tokens": [51052, 16479, 493, 538, 5244, 13, 467, 311, 6217, 1922, 257, 2459, 6809, 370, 1400, 412, 264, 1623, 412, 264, 565, 295, 51304], "temperature": 0.0, "avg_logprob": -0.22189150818991005, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.09019695222377777}, {"id": 14, "seek": 5740, "start": 76.2, "end": 82.44, "text": " recording. And so it's clearly gone viral across the programming world. Unfortunately,", "tokens": [51304, 6613, 13, 400, 370, 309, 311, 4448, 2780, 16132, 2108, 264, 9410, 1002, 13, 8590, 11, 51616], "temperature": 0.0, "avg_logprob": -0.22189150818991005, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.09019695222377777}, {"id": 15, "seek": 8244, "start": 82.44, "end": 91.0, "text": " because it went viral, a lot of the context got lost. And because the context got lost.", "tokens": [50364, 570, 309, 1437, 16132, 11, 257, 688, 295, 264, 4319, 658, 2731, 13, 400, 570, 264, 4319, 658, 2731, 13, 50792], "temperature": 0.0, "avg_logprob": -0.17890860817649148, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.7049831748008728}, {"id": 16, "seek": 8244, "start": 91.0, "end": 95.08, "text": " People just adding their own context into it without even bothering to learn it. So the", "tokens": [50792, 3432, 445, 5127, 641, 1065, 4319, 666, 309, 1553, 754, 31432, 281, 1466, 309, 13, 407, 264, 50996], "temperature": 0.0, "avg_logprob": -0.17890860817649148, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.7049831748008728}, {"id": 17, "seek": 8244, "start": 95.08, "end": 101.28, "text": " context was this comes from a series that Casey's been doing on computer hands.com,", "tokens": [50996, 4319, 390, 341, 1487, 490, 257, 2638, 300, 27369, 311, 668, 884, 322, 3820, 2377, 13, 1112, 11, 51306], "temperature": 0.0, "avg_logprob": -0.17890860817649148, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.7049831748008728}, {"id": 18, "seek": 8244, "start": 101.28, "end": 106.28, "text": " where it's a performance awareness course. So specifically the this is the programming", "tokens": [51306, 689, 309, 311, 257, 3389, 8888, 1164, 13, 407, 4682, 264, 341, 307, 264, 9410, 51556], "temperature": 0.0, "avg_logprob": -0.17890860817649148, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.7049831748008728}, {"id": 19, "seek": 8244, "start": 106.28, "end": 110.64, "text": " course he's been doing to performance awareness stuff. And this is a subscribed based thing", "tokens": [51556, 1164, 415, 311, 668, 884, 281, 3389, 8888, 1507, 13, 400, 341, 307, 257, 16665, 2361, 551, 51774], "temperature": 0.0, "avg_logprob": -0.17890860817649148, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.7049831748008728}, {"id": 20, "seek": 11064, "start": 110.68, "end": 116.24, "text": " on the on the on here. And he's been doing many different topics on here as I was able", "tokens": [50366, 322, 264, 322, 264, 322, 510, 13, 400, 415, 311, 668, 884, 867, 819, 8378, 322, 510, 382, 286, 390, 1075, 50644], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 21, "seek": 11064, "start": 116.24, "end": 121.12, "text": " to learn how to performance awareness. Specifically, this was the blog post and he made completely", "tokens": [50644, 281, 1466, 577, 281, 3389, 8888, 13, 26058, 11, 341, 390, 264, 6968, 2183, 293, 415, 1027, 2584, 50888], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 22, "seek": 11064, "start": 121.12, "end": 124.92, "text": " public for everybody showing all the code showing all this stuff. So then you can see", "tokens": [50888, 1908, 337, 2201, 4099, 439, 264, 3089, 4099, 439, 341, 1507, 13, 407, 550, 291, 393, 536, 51078], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 23, "seek": 11064, "start": 124.92, "end": 129.32, "text": " a whole video is all kind of transcribed down. And it's part of a series. It's not the beginning", "tokens": [51078, 257, 1379, 960, 307, 439, 733, 295, 1145, 18732, 760, 13, 400, 309, 311, 644, 295, 257, 2638, 13, 467, 311, 406, 264, 2863, 51298], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 24, "seek": 11064, "start": 129.32, "end": 133.24, "text": " of the fifth series is quite in the middle. So it's kind of like, Oh, okay, we're not", "tokens": [51298, 295, 264, 9266, 2638, 307, 1596, 294, 264, 2808, 13, 407, 309, 311, 733, 295, 411, 11, 876, 11, 1392, 11, 321, 434, 406, 51494], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 25, "seek": 11064, "start": 133.24, "end": 138.72, "text": " starting from a random place. So and also when people say and talk about the context", "tokens": [51494, 2891, 490, 257, 4974, 1081, 13, 407, 293, 611, 562, 561, 584, 293, 751, 466, 264, 4319, 51768], "temperature": 0.0, "avg_logprob": -0.20380934256094474, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.2777881622314453}, {"id": 26, "seek": 13872, "start": 138.72, "end": 142.6, "text": " of this Casey understands this like, look, reminder, I don't think clean code is bad", "tokens": [50364, 295, 341, 27369, 15146, 341, 411, 11, 574, 11, 13548, 11, 286, 500, 380, 519, 2541, 3089, 307, 1578, 50558], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 27, "seek": 13872, "start": 142.6, "end": 146.6, "text": " just because of performance. My recent video is about poor performance, because it's part", "tokens": [50558, 445, 570, 295, 3389, 13, 1222, 5162, 960, 307, 466, 4716, 3389, 11, 570, 309, 311, 644, 50758], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 28, "seek": 13872, "start": 146.6, "end": 151.0, "text": " of a course on performance. This is the context many people lost. And he's been doing this", "tokens": [50758, 295, 257, 1164, 322, 3389, 13, 639, 307, 264, 4319, 867, 561, 2731, 13, 400, 415, 311, 668, 884, 341, 50978], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 29, "seek": 13872, "start": 151.0, "end": 154.56, "text": " for decades is saying so I recommend reading these tweets, I will try and provide all of", "tokens": [50978, 337, 7878, 307, 1566, 370, 286, 2748, 3760, 613, 25671, 11, 286, 486, 853, 293, 2893, 439, 295, 51156], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 30, "seek": 13872, "start": 154.56, "end": 159.12, "text": " the links to everything I'm showing today in the description or the do blue do whatever", "tokens": [51156, 264, 6123, 281, 1203, 286, 478, 4099, 965, 294, 264, 3855, 420, 264, 360, 3344, 360, 2035, 51384], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 31, "seek": 13872, "start": 159.12, "end": 165.68, "text": " you want to do down below on YouTube. So be here. So yeah, hello. Good. So give a background.", "tokens": [51384, 291, 528, 281, 360, 760, 2507, 322, 3088, 13, 407, 312, 510, 13, 407, 1338, 11, 7751, 13, 2205, 13, 407, 976, 257, 3678, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1760678217961238, "compression_ratio": 1.6492307692307693, "no_speech_prob": 0.07742304354906082}, {"id": 32, "seek": 16568, "start": 165.68, "end": 171.32, "text": " He's picked up the attention of Robert, Mr. Robert C Martin, which he colloquially calls", "tokens": [50364, 634, 311, 6183, 493, 264, 3202, 295, 7977, 11, 2221, 13, 7977, 383, 9184, 11, 597, 415, 1263, 29826, 2270, 5498, 50646], "temperature": 0.0, "avg_logprob": -0.22236931324005127, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.6610419750213623}, {"id": 33, "seek": 16568, "start": 171.32, "end": 176.4, "text": " himself Uncle Bob. For this talk, I'm just going to call him Mr. Martin, because I just", "tokens": [50646, 3647, 12347, 6085, 13, 1171, 341, 751, 11, 286, 478, 445, 516, 281, 818, 796, 2221, 13, 9184, 11, 570, 286, 445, 50900], "temperature": 0.0, "avg_logprob": -0.22236931324005127, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.6610419750213623}, {"id": 34, "seek": 16568, "start": 176.4, "end": 182.92000000000002, "text": " prefer saying Mr. Martin, insert your guesses as to why. But yeah, he is very well known", "tokens": [50900, 4382, 1566, 2221, 13, 9184, 11, 8969, 428, 42703, 382, 281, 983, 13, 583, 1338, 11, 415, 307, 588, 731, 2570, 51226], "temperature": 0.0, "avg_logprob": -0.22236931324005127, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.6610419750213623}, {"id": 35, "seek": 16568, "start": 182.92000000000002, "end": 189.08, "text": " for my mainly three things, which is the agile manifesto, he helped develop that solid the", "tokens": [51226, 337, 452, 8704, 1045, 721, 11, 597, 307, 264, 30072, 10067, 78, 11, 415, 4254, 1499, 300, 5100, 264, 51534], "temperature": 0.0, "avg_logprob": -0.22236931324005127, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.6610419750213623}, {"id": 36, "seek": 16568, "start": 189.08, "end": 195.12, "text": " solid principles. So the agile manifesto and solid principles, which again, many people", "tokens": [51534, 5100, 9156, 13, 407, 264, 30072, 10067, 78, 293, 5100, 9156, 11, 597, 797, 11, 867, 561, 51836], "temperature": 0.0, "avg_logprob": -0.22236931324005127, "compression_ratio": 1.669172932330827, "no_speech_prob": 0.6610419750213623}, {"id": 37, "seek": 19512, "start": 195.16, "end": 199.0, "text": " know from the world, especially that he wrote it in his in his book, which is first in design", "tokens": [50366, 458, 490, 264, 1002, 11, 2318, 300, 415, 4114, 309, 294, 702, 294, 702, 1446, 11, 597, 307, 700, 294, 1715, 50558], "temperature": 0.0, "avg_logprob": -0.2534372724335769, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.23528164625167847}, {"id": 38, "seek": 19512, "start": 199.0, "end": 204.64000000000001, "text": " as principles and design patterns, as it says on here. And he's also in this thing known", "tokens": [50558, 382, 9156, 293, 1715, 8294, 11, 382, 309, 1619, 322, 510, 13, 400, 415, 311, 611, 294, 341, 551, 2570, 50840], "temperature": 0.0, "avg_logprob": -0.2534372724335769, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.23528164625167847}, {"id": 39, "seek": 19512, "start": 204.64000000000001, "end": 211.28, "text": " for clean code. So clean with capital C code with capital C trademarked. This is his particular", "tokens": [50840, 337, 2541, 3089, 13, 407, 2541, 365, 4238, 383, 3089, 365, 4238, 383, 31361, 292, 13, 639, 307, 702, 1729, 51172], "temperature": 0.0, "avg_logprob": -0.2534372724335769, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.23528164625167847}, {"id": 40, "seek": 19512, "start": 211.28, "end": 217.6, "text": " thing, the capital C clean code thing. Okay. And this is what he kind of tries to describe.", "tokens": [51172, 551, 11, 264, 4238, 383, 2541, 3089, 551, 13, 1033, 13, 400, 341, 307, 437, 415, 733, 295, 9898, 281, 6786, 13, 51488], "temperature": 0.0, "avg_logprob": -0.2534372724335769, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.23528164625167847}, {"id": 41, "seek": 19512, "start": 217.6, "end": 225.08, "text": " So to get to show my biases and my background, I am the creator of the program language here.", "tokens": [51488, 407, 281, 483, 281, 855, 452, 32152, 293, 452, 3678, 11, 286, 669, 264, 14181, 295, 264, 1461, 2856, 510, 13, 51862], "temperature": 0.0, "avg_logprob": -0.2534372724335769, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.23528164625167847}, {"id": 42, "seek": 22508, "start": 225.08, "end": 228.20000000000002, "text": " And the only program language is the general purpose program language with the distinct", "tokens": [50364, 400, 264, 787, 1461, 2856, 307, 264, 2674, 4334, 1461, 2856, 365, 264, 10644, 50520], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 43, "seek": 22508, "start": 228.20000000000002, "end": 233.24, "text": " typing built for high performance modern systems and data order programming. So clearly, I'm", "tokens": [50520, 18444, 3094, 337, 1090, 3389, 4363, 3652, 293, 1412, 1668, 9410, 13, 407, 4448, 11, 286, 478, 50772], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 44, "seek": 22508, "start": 233.24, "end": 237.56, "text": " showing my biases, and I'm cleaning on more like case and oratory side when it comes to", "tokens": [50772, 4099, 452, 32152, 11, 293, 286, 478, 8924, 322, 544, 411, 1389, 293, 420, 4745, 1252, 562, 309, 1487, 281, 50988], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 45, "seek": 22508, "start": 237.56, "end": 243.24, "text": " this discussion. And also, I work at Django effects on emogen and liquid gen and geo gen,", "tokens": [50988, 341, 5017, 13, 400, 611, 11, 286, 589, 412, 33464, 17150, 5065, 322, 846, 8799, 293, 6553, 1049, 293, 43198, 1049, 11, 51272], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 46, "seek": 22508, "start": 243.24, "end": 247.32000000000002, "text": " which are all high performance real time pieces software like simulations, again, engines", "tokens": [51272, 597, 366, 439, 1090, 3389, 957, 565, 3755, 4722, 411, 35138, 11, 797, 11, 12982, 51476], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 47, "seek": 22508, "start": 247.32000000000002, "end": 251.4, "text": " for fire, smoke and explosions in real time. So clearly, I work in an industry where we", "tokens": [51476, 337, 2610, 11, 8439, 293, 36872, 294, 957, 565, 13, 407, 4448, 11, 286, 589, 294, 364, 3518, 689, 321, 51680], "temperature": 0.0, "avg_logprob": -0.2645409068123239, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.006344555411487818}, {"id": 48, "seek": 25140, "start": 251.4, "end": 255.16, "text": " really care about high performance real time stuff. So clearly, I'm showing my biases straight", "tokens": [50364, 534, 1127, 466, 1090, 3389, 957, 565, 1507, 13, 407, 4448, 11, 286, 478, 4099, 452, 32152, 2997, 50552], "temperature": 0.0, "avg_logprob": -0.11867297196588597, "compression_ratio": 1.5993150684931507, "no_speech_prob": 0.10419740527868271}, {"id": 49, "seek": 25140, "start": 255.16, "end": 261.72, "text": " away. So people understand what's going on. Okay, so now you know, that's on the way. Can", "tokens": [50552, 1314, 13, 407, 561, 1223, 437, 311, 516, 322, 13, 1033, 11, 370, 586, 291, 458, 11, 300, 311, 322, 264, 636, 13, 1664, 50880], "temperature": 0.0, "avg_logprob": -0.11867297196588597, "compression_ratio": 1.5993150684931507, "no_speech_prob": 0.10419740527868271}, {"id": 50, "seek": 25140, "start": 261.72, "end": 266.76, "text": " we explain what clean code is before we get into this? So sure. So there is this kind of", "tokens": [50880, 321, 2903, 437, 2541, 3089, 307, 949, 321, 483, 666, 341, 30, 407, 988, 13, 407, 456, 307, 341, 733, 295, 51132], "temperature": 0.0, "avg_logprob": -0.11867297196588597, "compression_ratio": 1.5993150684931507, "no_speech_prob": 0.10419740527868271}, {"id": 51, "seek": 25140, "start": 266.76, "end": 271.32, "text": " little document I found the other day, and it's been well actively updated by looks only eight", "tokens": [51132, 707, 4166, 286, 1352, 264, 661, 786, 11, 293, 309, 311, 668, 731, 13022, 10588, 538, 1542, 787, 3180, 51360], "temperature": 0.0, "avg_logprob": -0.11867297196588597, "compression_ratio": 1.5993150684931507, "no_speech_prob": 0.10419740527868271}, {"id": 52, "seek": 25140, "start": 271.32, "end": 278.44, "text": " hours ago at this time of recording. And today's date is the March the 30th, I believe. Yes, March", "tokens": [51360, 2496, 2057, 412, 341, 565, 295, 6613, 13, 400, 965, 311, 4002, 307, 264, 6129, 264, 2217, 392, 11, 286, 1697, 13, 1079, 11, 6129, 51716], "temperature": 0.0, "avg_logprob": -0.11867297196588597, "compression_ratio": 1.5993150684931507, "no_speech_prob": 0.10419740527868271}, {"id": 53, "seek": 27844, "start": 278.44, "end": 283.0, "text": " the 30th. So it's very active or someone's updated there's probably some typos and such", "tokens": [50364, 264, 2217, 392, 13, 407, 309, 311, 588, 4967, 420, 1580, 311, 10588, 456, 311, 1391, 512, 2125, 329, 293, 1270, 50592], "temperature": 0.0, "avg_logprob": -0.20403172175089518, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.039343297481536865}, {"id": 54, "seek": 27844, "start": 283.0, "end": 287.96, "text": " we can even see the revisions. And yeah, it's just some, hey, just capitalizing some straw.", "tokens": [50592, 321, 393, 754, 536, 264, 3698, 4252, 13, 400, 1338, 11, 309, 311, 445, 512, 11, 4177, 11, 445, 4238, 3319, 512, 10099, 13, 50840], "temperature": 0.0, "avg_logprob": -0.20403172175089518, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.039343297481536865}, {"id": 55, "seek": 27844, "start": 287.96, "end": 292.92, "text": " That was all it was. Now, many people have seen to have liked this clearly over 5000 stars and", "tokens": [50840, 663, 390, 439, 309, 390, 13, 823, 11, 867, 561, 362, 1612, 281, 362, 4501, 341, 4448, 670, 23777, 6105, 293, 51088], "temperature": 0.0, "avg_logprob": -0.20403172175089518, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.039343297481536865}, {"id": 56, "seek": 27844, "start": 292.92, "end": 298.28, "text": " over 1000 forks of this gist, as well gist or I don't know we pronounce it on GitHub,", "tokens": [51088, 670, 9714, 337, 1694, 295, 341, 290, 468, 11, 382, 731, 290, 468, 420, 286, 500, 380, 458, 321, 19567, 309, 322, 23331, 11, 51356], "temperature": 0.0, "avg_logprob": -0.20403172175089518, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.039343297481536865}, {"id": 57, "seek": 27844, "start": 299.08, "end": 305.24, "text": " and explained some of the began your principles or points about clean code. Now there's many", "tokens": [51396, 293, 8825, 512, 295, 264, 4283, 428, 9156, 420, 2793, 466, 2541, 3089, 13, 823, 456, 311, 867, 51704], "temperature": 0.0, "avg_logprob": -0.20403172175089518, "compression_ratio": 1.5950704225352113, "no_speech_prob": 0.039343297481536865}, {"id": 58, "seek": 30524, "start": 305.32, "end": 309.40000000000003, "text": " of this. This is the thing about which is why clean code capital C thing trademarked by Mr", "tokens": [50368, 295, 341, 13, 639, 307, 264, 551, 466, 597, 307, 983, 2541, 3089, 4238, 383, 551, 31361, 292, 538, 2221, 50572], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 59, "seek": 30524, "start": 309.40000000000003, "end": 314.2, "text": " Martin is very popular because there's many of these rules, which no one would disagree with,", "tokens": [50572, 9184, 307, 588, 3743, 570, 456, 311, 867, 295, 613, 4474, 11, 597, 572, 472, 576, 14091, 365, 11, 50812], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 60, "seek": 30524, "start": 314.2, "end": 317.8, "text": " like follow standard conventions. Yeah, because conventions are a good thing because then you're", "tokens": [50812, 411, 1524, 3832, 33520, 13, 865, 11, 570, 33520, 366, 257, 665, 551, 570, 550, 291, 434, 50992], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 61, "seek": 30524, "start": 317.8, "end": 322.68, "text": " working on the same sun, only break them when you need to keep it simple, stupid, you're fine,", "tokens": [50992, 1364, 322, 264, 912, 3295, 11, 787, 1821, 552, 562, 291, 643, 281, 1066, 309, 2199, 11, 6631, 11, 291, 434, 2489, 11, 51236], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 62, "seek": 30524, "start": 322.68, "end": 327.0, "text": " whatever. Boy Scott rule, leave the camp around cleaner than you found it, always find the root", "tokens": [51236, 2035, 13, 9486, 6659, 4978, 11, 1856, 264, 2255, 926, 16532, 813, 291, 1352, 309, 11, 1009, 915, 264, 5593, 51452], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 63, "seek": 30524, "start": 327.0, "end": 332.52, "text": " cause you're no problem like this, yada, yada. Now some of these are things, okay, some of these are", "tokens": [51452, 3082, 291, 434, 572, 1154, 411, 341, 11, 288, 1538, 11, 288, 1538, 13, 823, 512, 295, 613, 366, 721, 11, 1392, 11, 512, 295, 613, 366, 51728], "temperature": 0.0, "avg_logprob": -0.16939498356410435, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.2742225229740143}, {"id": 64, "seek": 33252, "start": 332.76, "end": 337.24, "text": " not essential. These are accidental. Like, again, follow standard conventions. That's not", "tokens": [50376, 406, 7115, 13, 1981, 366, 38094, 13, 1743, 11, 797, 11, 1524, 3832, 33520, 13, 663, 311, 406, 50600], "temperature": 0.0, "avg_logprob": -0.17949812515922214, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.04327751696109772}, {"id": 65, "seek": 33252, "start": 337.96, "end": 342.91999999999996, "text": " a unique to clean code, is it? You can do that in any philosophy out there. It's not a unique", "tokens": [50636, 257, 3845, 281, 2541, 3089, 11, 307, 309, 30, 509, 393, 360, 300, 294, 604, 10675, 484, 456, 13, 467, 311, 406, 257, 3845, 50884], "temperature": 0.0, "avg_logprob": -0.17949812515922214, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.04327751696109772}, {"id": 66, "seek": 33252, "start": 342.91999999999996, "end": 348.28, "text": " principle to clean code itself. But some things like, for instance, I would say more essential", "tokens": [50884, 8665, 281, 2541, 3089, 2564, 13, 583, 512, 721, 411, 11, 337, 5197, 11, 286, 576, 584, 544, 7115, 51152], "temperature": 0.0, "avg_logprob": -0.17949812515922214, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.04327751696109772}, {"id": 67, "seek": 33252, "start": 348.28, "end": 354.52, "text": " to clean code or prefer polymorphism to if or else cases. And separate multi floating code.", "tokens": [51152, 281, 2541, 3089, 420, 4382, 6754, 76, 18191, 1434, 281, 498, 420, 1646, 3331, 13, 400, 4994, 4825, 12607, 3089, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17949812515922214, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.04327751696109772}, {"id": 68, "seek": 33252, "start": 354.52, "end": 360.2, "text": " I'm not even sure what that means. Use dependency injection. Follow the law of Demeter or many", "tokens": [51464, 286, 478, 406, 754, 988, 437, 300, 1355, 13, 8278, 33621, 22873, 13, 9876, 264, 2101, 295, 4686, 2398, 420, 867, 51748], "temperature": 0.0, "avg_logprob": -0.17949812515922214, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.04327751696109772}, {"id": 69, "seek": 36020, "start": 360.2, "end": 364.03999999999996, "text": " other things, many other things like here, like, Oh, use small functions functions, they only do", "tokens": [50364, 661, 721, 11, 867, 661, 721, 411, 510, 11, 411, 11, 876, 11, 764, 1359, 6828, 6828, 11, 436, 787, 360, 50556], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 70, "seek": 36020, "start": 364.03999999999996, "end": 367.96, "text": " one thing use descriptive names, like getting that descriptive names, everyone agrees to that to a", "tokens": [50556, 472, 551, 764, 42585, 5288, 11, 411, 1242, 300, 42585, 5288, 11, 1518, 26383, 281, 300, 281, 257, 50752], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 71, "seek": 36020, "start": 367.96, "end": 373.0, "text": " certain extent, prefer fewer arguments have no side effects. So be more functional, it means more", "tokens": [50752, 1629, 8396, 11, 4382, 13366, 12869, 362, 572, 1252, 5065, 13, 407, 312, 544, 11745, 11, 309, 1355, 544, 51004], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 72, "seek": 36020, "start": 373.0, "end": 377.56, "text": " and more rather than be like, have side effects itself, like be more imperative relying on like", "tokens": [51004, 293, 544, 2831, 813, 312, 411, 11, 362, 1252, 5065, 2564, 11, 411, 312, 544, 32490, 24140, 322, 411, 51232], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 73, "seek": 36020, "start": 377.56, "end": 381.88, "text": " global state or modifying state or whatever, don't use flag arguments, yada, yada, like, okay,", "tokens": [51232, 4338, 1785, 420, 42626, 1785, 420, 2035, 11, 500, 380, 764, 7166, 12869, 11, 288, 1538, 11, 288, 1538, 11, 411, 11, 1392, 11, 51448], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 74, "seek": 36020, "start": 382.68, "end": 387.48, "text": " some of these people will agree with some people will disagree with them. But here's where the", "tokens": [51488, 512, 295, 613, 561, 486, 3986, 365, 512, 561, 486, 14091, 365, 552, 13, 583, 510, 311, 689, 264, 51728], "temperature": 0.0, "avg_logprob": -0.239185931077644, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.182118222117424}, {"id": 75, "seek": 38748, "start": 387.8, "end": 394.68, "text": " the problem is with some of this is that for the most part, some of these rules,", "tokens": [50380, 264, 1154, 307, 365, 512, 295, 341, 307, 300, 337, 264, 881, 644, 11, 512, 295, 613, 4474, 11, 50724], "temperature": 0.0, "avg_logprob": -0.21791811156691165, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.012027952820062637}, {"id": 76, "seek": 38748, "start": 394.68, "end": 398.36, "text": " people will agree with some of them don't. One of the particular is like small rules for me,", "tokens": [50724, 561, 486, 3986, 365, 512, 295, 552, 500, 380, 13, 1485, 295, 264, 1729, 307, 411, 1359, 4474, 337, 385, 11, 50908], "temperature": 0.0, "avg_logprob": -0.21791811156691165, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.012027952820062637}, {"id": 77, "seek": 38748, "start": 398.36, "end": 402.68, "text": " I actually disagree with this particular thing. There was a post here, this is on Jonathan", "tokens": [50908, 286, 767, 14091, 365, 341, 1729, 551, 13, 821, 390, 257, 2183, 510, 11, 341, 307, 322, 15471, 51124], "temperature": 0.0, "avg_logprob": -0.21791811156691165, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.012027952820062637}, {"id": 78, "seek": 38748, "start": 402.68, "end": 406.92, "text": " blows blog old, very old blog, actually, this one 2016. But he's actually even older than that,", "tokens": [51124, 18458, 6968, 1331, 11, 588, 1331, 6968, 11, 767, 11, 341, 472, 6549, 13, 583, 415, 311, 767, 754, 4906, 813, 300, 11, 51336], "temperature": 0.0, "avg_logprob": -0.21791811156691165, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.012027952820062637}, {"id": 79, "seek": 38748, "start": 406.92, "end": 414.28000000000003, "text": " because it's an old email response between him and john Carmack. So this is john Carmack explaining", "tokens": [51336, 570, 309, 311, 364, 1331, 3796, 4134, 1296, 796, 293, 35097, 44530, 501, 13, 407, 341, 307, 35097, 44530, 501, 13468, 51704], "temperature": 0.0, "avg_logprob": -0.21791811156691165, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.012027952820062637}, {"id": 80, "seek": 41428, "start": 414.35999999999996, "end": 419.88, "text": " effectively, what he preferred for the things is not the clean code up. This is what I wanted", "tokens": [50368, 8659, 11, 437, 415, 16494, 337, 264, 721, 307, 406, 264, 2541, 3089, 493, 13, 639, 307, 437, 286, 1415, 50644], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 81, "seek": 41428, "start": 419.88, "end": 425.71999999999997, "text": " was the wrong one. Whoops. Let's go to the blog post again. And it's this one here. So I accidentally", "tokens": [50644, 390, 264, 2085, 472, 13, 45263, 13, 961, 311, 352, 281, 264, 6968, 2183, 797, 13, 400, 309, 311, 341, 472, 510, 13, 407, 286, 15715, 50936], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 82, "seek": 41428, "start": 425.71999999999997, "end": 429.88, "text": " clicked the wrong button then. So this is john inline code. And john Carmack in the email is", "tokens": [50936, 23370, 264, 2085, 2960, 550, 13, 407, 341, 307, 35097, 294, 1889, 3089, 13, 400, 35097, 44530, 501, 294, 264, 3796, 307, 51144], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 83, "seek": 41428, "start": 429.88, "end": 434.11999999999995, "text": " explained, actually, he doesn't like the separate single functions here. It's better just have", "tokens": [51144, 8825, 11, 767, 11, 415, 1177, 380, 411, 264, 4994, 2167, 6828, 510, 13, 467, 311, 1101, 445, 362, 51356], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 84, "seek": 41428, "start": 434.11999999999995, "end": 438.03999999999996, "text": " one big function and then comment them. Now, some people might say be a bit easier to manage", "tokens": [51356, 472, 955, 2445, 293, 550, 2871, 552, 13, 823, 11, 512, 561, 1062, 584, 312, 257, 857, 3571, 281, 3067, 51552], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 85, "seek": 41428, "start": 438.03999999999996, "end": 442.28, "text": " looking at re things. Yeah, for code reviews, in a big corporate setting, it might be easier", "tokens": [51552, 1237, 412, 319, 721, 13, 865, 11, 337, 3089, 10229, 11, 294, 257, 955, 10896, 3287, 11, 309, 1062, 312, 3571, 51764], "temperature": 0.0, "avg_logprob": -0.1556741284652495, "compression_ratio": 1.693452380952381, "no_speech_prob": 0.06391288340091705}, {"id": 86, "seek": 44228, "start": 442.28, "end": 446.2, "text": " looking a single function. But there's a few things you have to understand functions have", "tokens": [50364, 1237, 257, 2167, 2445, 13, 583, 456, 311, 257, 1326, 721, 291, 362, 281, 1223, 6828, 362, 50560], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 87, "seek": 44228, "start": 446.2, "end": 450.35999999999996, "text": " costs. If you split these things into multiple functions, this is a one is an extra cost. Yes,", "tokens": [50560, 5497, 13, 759, 291, 7472, 613, 721, 666, 3866, 6828, 11, 341, 307, 257, 472, 307, 364, 2857, 2063, 13, 1079, 11, 50768], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 88, "seek": 44228, "start": 450.35999999999996, "end": 454.76, "text": " is a minor cost when calling a function. But like that most people don't care about that cost,", "tokens": [50768, 307, 257, 6696, 2063, 562, 5141, 257, 2445, 13, 583, 411, 300, 881, 561, 500, 380, 1127, 466, 300, 2063, 11, 50988], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 89, "seek": 44228, "start": 455.47999999999996, "end": 459.32, "text": " unless you're doing particular things like you're worried about stack stacks or anything like that.", "tokens": [51024, 5969, 291, 434, 884, 1729, 721, 411, 291, 434, 5804, 466, 8630, 30792, 420, 1340, 411, 300, 13, 51216], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 90, "seek": 44228, "start": 459.32, "end": 463.55999999999995, "text": " Like, okay, most things don't care. One thing it does do is it does actually doesn't mean it's", "tokens": [51216, 1743, 11, 1392, 11, 881, 721, 500, 380, 1127, 13, 1485, 551, 309, 775, 360, 307, 309, 775, 767, 1177, 380, 914, 309, 311, 51428], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 91, "seek": 44228, "start": 463.55999999999995, "end": 467.79999999999995, "text": " very easy to optimize for the optimizer. And I know how compilers work because I work on them for", "tokens": [51428, 588, 1858, 281, 19719, 337, 264, 5028, 6545, 13, 400, 286, 458, 577, 715, 388, 433, 589, 570, 286, 589, 322, 552, 337, 51640], "temperature": 0.0, "avg_logprob": -0.135074601756583, "compression_ratio": 1.8511326860841424, "no_speech_prob": 0.0447324700653553}, {"id": 92, "seek": 46780, "start": 467.8, "end": 473.0, "text": " kind of a living. And if you have things in line, one, it's not hard to read by just using", "tokens": [50364, 733, 295, 257, 2647, 13, 400, 498, 291, 362, 721, 294, 1622, 11, 472, 11, 309, 311, 406, 1152, 281, 1401, 538, 445, 1228, 50624], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 93, "seek": 46780, "start": 473.0, "end": 476.92, "text": " comments everywhere or block codes or anything like that. I think it's just as easy. And if you've", "tokens": [50624, 3053, 5315, 420, 3461, 14211, 420, 1340, 411, 300, 13, 286, 519, 309, 311, 445, 382, 1858, 13, 400, 498, 291, 600, 50820], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 94, "seek": 46780, "start": 476.92, "end": 483.40000000000003, "text": " got text editors, which are use collapsible things, that's great. That's okay, no problems, just deal", "tokens": [50820, 658, 2487, 31446, 11, 597, 366, 764, 16567, 964, 721, 11, 300, 311, 869, 13, 663, 311, 1392, 11, 572, 2740, 11, 445, 2028, 51144], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 95, "seek": 46780, "start": 483.40000000000003, "end": 487.40000000000003, "text": " with it that way. But then it's like, okay, but the optimizer can be ready, doesn't have to worry", "tokens": [51144, 365, 309, 300, 636, 13, 583, 550, 309, 311, 411, 11, 1392, 11, 457, 264, 5028, 6545, 393, 312, 1919, 11, 1177, 380, 362, 281, 3292, 51344], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 96, "seek": 46780, "start": 487.40000000000003, "end": 491.24, "text": " about trying to inline that function. And then now optimize the new inline function that's been", "tokens": [51344, 466, 1382, 281, 294, 1889, 300, 2445, 13, 400, 550, 586, 19719, 264, 777, 294, 1889, 2445, 300, 311, 668, 51536], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 97, "seek": 46780, "start": 491.24, "end": 497.0, "text": " got in line is out of another function. So there's that. And also you can usually start to see easy", "tokens": [51536, 658, 294, 1622, 307, 484, 295, 1071, 2445, 13, 407, 456, 311, 300, 13, 400, 611, 291, 393, 2673, 722, 281, 536, 1858, 51824], "temperature": 0.0, "avg_logprob": -0.11156952303219465, "compression_ratio": 1.8, "no_speech_prob": 0.05336606130003929}, {"id": 98, "seek": 49700, "start": 497.0, "end": 501.8, "text": " patterns as well. If you start manually inlining things, it's not hard to read. Yes, okay, you've", "tokens": [50364, 8294, 382, 731, 13, 759, 291, 722, 16945, 294, 31079, 721, 11, 309, 311, 406, 1152, 281, 1401, 13, 1079, 11, 1392, 11, 291, 600, 50604], "temperature": 0.0, "avg_logprob": -0.1794603741358197, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.023800157010555267}, {"id": 99, "seek": 49700, "start": 501.8, "end": 506.92, "text": " got 10,000 lines, but most people's IDs and text editors are very easy for code folding, code", "tokens": [50604, 658, 1266, 11, 1360, 3876, 11, 457, 881, 561, 311, 48212, 293, 2487, 31446, 366, 588, 1858, 337, 3089, 25335, 11, 3089, 50860], "temperature": 0.0, "avg_logprob": -0.1794603741358197, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.023800157010555267}, {"id": 100, "seek": 49700, "start": 506.92, "end": 513.16, "text": " searching, code and organization. We're not living in the 80s anymore, or even the 70s,", "tokens": [50860, 10808, 11, 3089, 293, 4475, 13, 492, 434, 406, 2647, 294, 264, 4688, 82, 3602, 11, 420, 754, 264, 5285, 82, 11, 51172], "temperature": 0.0, "avg_logprob": -0.1794603741358197, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.023800157010555267}, {"id": 101, "seek": 49700, "start": 513.16, "end": 516.44, "text": " to be honest, because even small talk had better options than this. I'm not saying I'm a big fan", "tokens": [51172, 281, 312, 3245, 11, 570, 754, 1359, 751, 632, 1101, 3956, 813, 341, 13, 286, 478, 406, 1566, 286, 478, 257, 955, 3429, 51336], "temperature": 0.0, "avg_logprob": -0.1794603741358197, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.023800157010555267}, {"id": 102, "seek": 49700, "start": 516.44, "end": 521.64, "text": " of small talk. But again, the tooling is the argument going small function is more of a, hey,", "tokens": [51336, 295, 1359, 751, 13, 583, 797, 11, 264, 46593, 307, 264, 6770, 516, 1359, 2445, 307, 544, 295, 257, 11, 4177, 11, 51596], "temperature": 0.0, "avg_logprob": -0.1794603741358197, "compression_ratio": 1.6095890410958904, "no_speech_prob": 0.023800157010555267}, {"id": 103, "seek": 52164, "start": 521.64, "end": 528.84, "text": " it's our code review practices, big corporations, testing practices, and also maybe just tooling", "tokens": [50364, 309, 311, 527, 3089, 3131, 7525, 11, 955, 17676, 11, 4997, 7525, 11, 293, 611, 1310, 445, 46593, 50724], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 104, "seek": 52164, "start": 528.84, "end": 533.3199999999999, "text": " practices. So that's one thing. But it's going to recommend highly reading this article, I really", "tokens": [50724, 7525, 13, 407, 300, 311, 472, 551, 13, 583, 309, 311, 516, 281, 2748, 5405, 3760, 341, 7222, 11, 286, 534, 50948], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 105, "seek": 52164, "start": 533.3199999999999, "end": 539.72, "text": " do from 2014, again, it's from 2007, as it says here, I recommend it. But what I'm trying to get", "tokens": [50948, 360, 490, 8227, 11, 797, 11, 309, 311, 490, 12656, 11, 382, 309, 1619, 510, 11, 286, 2748, 309, 13, 583, 437, 286, 478, 1382, 281, 483, 51268], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 106, "seek": 52164, "start": 539.72, "end": 542.6, "text": " out here about the word clean code, and I'm not even talking about the actual discussion that", "tokens": [51268, 484, 510, 466, 264, 1349, 2541, 3089, 11, 293, 286, 478, 406, 754, 1417, 466, 264, 3539, 5017, 300, 51412], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 107, "seek": 52164, "start": 542.6, "end": 546.6, "text": " Casey Motoria, they've been having yet, because I want to try to build up a picture here, as you", "tokens": [51412, 27369, 8956, 8172, 11, 436, 600, 668, 1419, 1939, 11, 570, 286, 528, 281, 853, 281, 1322, 493, 257, 3036, 510, 11, 382, 291, 51612], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 108, "seek": 52164, "start": 546.6, "end": 550.36, "text": " can probably tell, trying to be a storyteller, not very good at it, but let's carry on with it,", "tokens": [51612, 393, 1391, 980, 11, 1382, 281, 312, 257, 17541, 14983, 11, 406, 588, 665, 412, 309, 11, 457, 718, 311, 3985, 322, 365, 309, 11, 51800], "temperature": 0.0, "avg_logprob": -0.17724114495354729, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.10514476895332336}, {"id": 109, "seek": 55036, "start": 550.36, "end": 554.04, "text": " is that the concept of clean code is what I want to the term it capital C, capital", "tokens": [50364, 307, 300, 264, 3410, 295, 2541, 3089, 307, 437, 286, 528, 281, 264, 1433, 309, 4238, 383, 11, 4238, 50548], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 110, "seek": 55036, "start": 554.6800000000001, "end": 559.72, "text": " C on both of them, trademarked for Mr. Martin, is what I'm going to dub a pork barrel name.", "tokens": [50580, 383, 322, 1293, 295, 552, 11, 31361, 292, 337, 2221, 13, 9184, 11, 307, 437, 286, 478, 516, 281, 18540, 257, 10208, 13257, 1315, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 111, "seek": 55036, "start": 560.6, "end": 565.48, "text": " So a pork barrel is a thing that America, American English, but it's kind of a", "tokens": [50876, 407, 257, 10208, 13257, 307, 257, 551, 300, 3374, 11, 2665, 3669, 11, 457, 309, 311, 733, 295, 257, 51120], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 112, "seek": 55036, "start": 567.4, "end": 571.24, "text": " you have this bill, and it has a particular thing like citizens against government waste.", "tokens": [51216, 291, 362, 341, 2961, 11, 293, 309, 575, 257, 1729, 551, 411, 7180, 1970, 2463, 5964, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 113, "seek": 55036, "start": 571.24, "end": 575.32, "text": " But it also has all of these things that are nothing even related to the actual name of the", "tokens": [51408, 583, 309, 611, 575, 439, 295, 613, 721, 300, 366, 1825, 754, 4077, 281, 264, 3539, 1315, 295, 264, 51612], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 114, "seek": 55036, "start": 575.32, "end": 579.64, "text": " bill. And to keep it in American context, because I know most people watching going to be Americans,", "tokens": [51612, 2961, 13, 400, 281, 1066, 309, 294, 2665, 4319, 11, 570, 286, 458, 881, 561, 1976, 516, 281, 312, 6280, 11, 51828], "temperature": 0.0, "avg_logprob": -0.1245373747402564, "compression_ratio": 1.7573770491803278, "no_speech_prob": 0.005325923208147287}, {"id": 115, "seek": 58036, "start": 581.16, "end": 584.52, "text": " so I'm not going to use an English example, or another European example, like", "tokens": [50404, 370, 286, 478, 406, 516, 281, 764, 364, 3669, 1365, 11, 420, 1071, 6473, 1365, 11, 411, 50572], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 116, "seek": 58036, "start": 584.52, "end": 587.08, "text": " Germans, I'm just going to use American example, I've run recent one as well,", "tokens": [50572, 18116, 11, 286, 478, 445, 516, 281, 764, 2665, 1365, 11, 286, 600, 1190, 5162, 472, 382, 731, 11, 50700], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 117, "seek": 58036, "start": 587.72, "end": 593.24, "text": " is the Inflation Reduction Act of 2022. The name of it, the Inflation Reduction Act.", "tokens": [50732, 307, 264, 682, 3423, 399, 4477, 27549, 3251, 295, 20229, 13, 440, 1315, 295, 309, 11, 264, 682, 3423, 399, 4477, 27549, 3251, 13, 51008], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 118, "seek": 58036, "start": 594.52, "end": 598.6800000000001, "text": " Okay, now I'm trying to be again, I'm not an American, don't really care politics, but I think", "tokens": [51072, 1033, 11, 586, 286, 478, 1382, 281, 312, 797, 11, 286, 478, 406, 364, 2665, 11, 500, 380, 534, 1127, 7341, 11, 457, 286, 519, 51280], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 119, "seek": 58036, "start": 598.6800000000001, "end": 603.5600000000001, "text": " most people would agree, this act did not reduce inflation, in fact, it printed more money,", "tokens": [51280, 881, 561, 576, 3986, 11, 341, 605, 630, 406, 5407, 15860, 11, 294, 1186, 11, 309, 13567, 544, 1460, 11, 51524], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 120, "seek": 58036, "start": 604.52, "end": 607.72, "text": " and more excess money, that money was not being in high demand.", "tokens": [51572, 293, 544, 9310, 1460, 11, 300, 1460, 390, 406, 885, 294, 1090, 4733, 13, 51732], "temperature": 0.0, "avg_logprob": -0.150047761157043, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.00768829183652997}, {"id": 121, "seek": 60772, "start": 608.6800000000001, "end": 612.36, "text": " So it increased inflation, in fact, it had loads of other things in there to do with", "tokens": [50412, 407, 309, 6505, 15860, 11, 294, 1186, 11, 309, 632, 12668, 295, 661, 721, 294, 456, 281, 360, 365, 50596], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 122, "seek": 60772, "start": 612.36, "end": 618.2, "text": " not to do with inflation. But a really clever political rhetoric trick is to say, oh, you", "tokens": [50596, 406, 281, 360, 365, 15860, 13, 583, 257, 534, 13494, 3905, 29604, 4282, 307, 281, 584, 11, 1954, 11, 291, 50888], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 123, "seek": 60772, "start": 618.2, "end": 622.0400000000001, "text": " don't like this bill, we must like inflation, you're bad, everyone dislikes inflation.", "tokens": [50888, 500, 380, 411, 341, 2961, 11, 321, 1633, 411, 15860, 11, 291, 434, 1578, 11, 1518, 43186, 8916, 15860, 13, 51080], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 124, "seek": 60772, "start": 622.6800000000001, "end": 626.84, "text": " So you must be, oh, you can't be against this bill, can you? It's like, but this doesn't,", "tokens": [51112, 407, 291, 1633, 312, 11, 1954, 11, 291, 393, 380, 312, 1970, 341, 2961, 11, 393, 291, 30, 467, 311, 411, 11, 457, 341, 1177, 380, 11, 51320], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 125, "seek": 60772, "start": 626.84, "end": 630.9200000000001, "text": " ah, no, no, it doesn't inflation. How dare you don't want to, like, you can do this trick. And", "tokens": [51320, 3716, 11, 572, 11, 572, 11, 309, 1177, 380, 15860, 13, 1012, 8955, 291, 500, 380, 528, 281, 11, 411, 11, 291, 393, 360, 341, 4282, 13, 400, 51524], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 126, "seek": 60772, "start": 630.9200000000001, "end": 634.2, "text": " again, it's not a political side either, literally all political parties or politicians,", "tokens": [51524, 797, 11, 309, 311, 406, 257, 3905, 1252, 2139, 11, 3736, 439, 3905, 8265, 420, 14756, 11, 51688], "temperature": 0.0, "avg_logprob": -0.16474648837385505, "compression_ratio": 1.931407942238267, "no_speech_prob": 0.05245485156774521}, {"id": 127, "seek": 63420, "start": 634.9200000000001, "end": 640.44, "text": " I do this trick. Some countries like to do, like, oh, we're just getting names from bills.", "tokens": [50400, 286, 360, 341, 4282, 13, 2188, 3517, 411, 281, 360, 11, 411, 11, 1954, 11, 321, 434, 445, 1242, 5288, 490, 12433, 13, 50676], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 128, "seek": 63420, "start": 640.44, "end": 643.8000000000001, "text": " But then they'll give them a name anyway, like a colloquial one to refer to it rather than giving", "tokens": [50676, 583, 550, 436, 603, 976, 552, 257, 1315, 4033, 11, 411, 257, 1263, 29826, 831, 472, 281, 2864, 281, 309, 2831, 813, 2902, 50844], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 129, "seek": 63420, "start": 643.8000000000001, "end": 647.6400000000001, "text": " it like a letter or a number or some random numbers or something like that bill. And they'll", "tokens": [50844, 309, 411, 257, 5063, 420, 257, 1230, 420, 512, 4974, 3547, 420, 746, 411, 300, 2961, 13, 400, 436, 603, 51036], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 130, "seek": 63420, "start": 647.6400000000001, "end": 650.84, "text": " just say, look, no, this is what we're going to call it. Because technically internally,", "tokens": [51036, 445, 584, 11, 574, 11, 572, 11, 341, 307, 437, 321, 434, 516, 281, 818, 309, 13, 1436, 12120, 19501, 11, 51196], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 131, "seek": 63420, "start": 651.48, "end": 655.5600000000001, "text": " the Americans do, but they give them a proper name and also a very long title. Again, this is", "tokens": [51228, 264, 6280, 360, 11, 457, 436, 976, 552, 257, 2296, 1315, 293, 611, 257, 588, 938, 4876, 13, 3764, 11, 341, 307, 51432], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 132, "seek": 63420, "start": 655.5600000000001, "end": 661.96, "text": " to provide for the reconciliation pursuant to Title II of the S Con Rez 14, I'm just reading it", "tokens": [51432, 281, 2893, 337, 264, 31281, 7088, 84, 394, 281, 26768, 6351, 295, 264, 318, 2656, 1300, 89, 3499, 11, 286, 478, 445, 3760, 309, 51752], "temperature": 0.0, "avg_logprob": -0.13496925717308408, "compression_ratio": 1.7337461300309598, "no_speech_prob": 0.15483197569847107}, {"id": 133, "seek": 66196, "start": 662.0400000000001, "end": 666.36, "text": " as it says on here. And it's like, okay, but that's a good example from a political standpoint.", "tokens": [50368, 382, 309, 1619, 322, 510, 13, 400, 309, 311, 411, 11, 1392, 11, 457, 300, 311, 257, 665, 1365, 490, 257, 3905, 15827, 13, 50584], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 134, "seek": 66196, "start": 666.36, "end": 669.0, "text": " I'm just keeping it here, trying to keep it politically neutral. I don't really care about", "tokens": [50584, 286, 478, 445, 5145, 309, 510, 11, 1382, 281, 1066, 309, 21154, 10598, 13, 286, 500, 380, 534, 1127, 466, 50716], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 135, "seek": 66196, "start": 669.0, "end": 672.52, "text": " the old politics, but it's just one of those funny things that show, hey, this is a trick,", "tokens": [50716, 264, 1331, 7341, 11, 457, 309, 311, 445, 472, 295, 729, 4074, 721, 300, 855, 11, 4177, 11, 341, 307, 257, 4282, 11, 50892], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 136, "seek": 66196, "start": 673.48, "end": 678.44, "text": " because Mr. Martin will actually continually do this throughout. And it will trick, do a lot of", "tokens": [50940, 570, 2221, 13, 9184, 486, 767, 22277, 360, 341, 3710, 13, 400, 309, 486, 4282, 11, 360, 257, 688, 295, 51188], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 137, "seek": 66196, "start": 678.44, "end": 683.32, "text": " pivoting and a lot of these poor barrel names. Okay. So let's just say this is a good example", "tokens": [51188, 14538, 278, 293, 257, 688, 295, 613, 4716, 13257, 5288, 13, 1033, 13, 407, 718, 311, 445, 584, 341, 307, 257, 665, 1365, 51432], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 138, "seek": 66196, "start": 683.32, "end": 688.6, "text": " of this bad code. Just say no. And it's like, okay, so what's good code then? Because then it's,", "tokens": [51432, 295, 341, 1578, 3089, 13, 1449, 584, 572, 13, 400, 309, 311, 411, 11, 1392, 11, 370, 437, 311, 665, 3089, 550, 30, 1436, 550, 309, 311, 11, 51696], "temperature": 0.0, "avg_logprob": -0.1543271039661608, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.09240967780351639}, {"id": 139, "seek": 68860, "start": 689.4, "end": 693.16, "text": " phrases in the, oh, it's clean code, obviously. Now there was another tweet, I tried to find,", "tokens": [50404, 20312, 294, 264, 11, 1954, 11, 309, 311, 2541, 3089, 11, 2745, 13, 823, 456, 390, 1071, 15258, 11, 286, 3031, 281, 915, 11, 50592], "temperature": 0.0, "avg_logprob": -0.15591939290364584, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.20398074388504028}, {"id": 140, "seek": 68860, "start": 693.16, "end": 698.12, "text": " but I couldn't find it's probably been lost to the Twitter search, or it's just been deleted,", "tokens": [50592, 457, 286, 2809, 380, 915, 309, 311, 1391, 668, 2731, 281, 264, 5794, 3164, 11, 420, 309, 311, 445, 668, 22981, 11, 50840], "temperature": 0.0, "avg_logprob": -0.15591939290364584, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.20398074388504028}, {"id": 141, "seek": 68860, "start": 698.12, "end": 703.16, "text": " whatever. But he will commonly do this, Mr. Martin go like, oh, the opposite of bad code is clean", "tokens": [50840, 2035, 13, 583, 415, 486, 12719, 360, 341, 11, 2221, 13, 9184, 352, 411, 11, 1954, 11, 264, 6182, 295, 1578, 3089, 307, 2541, 51092], "temperature": 0.0, "avg_logprob": -0.15591939290364584, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.20398074388504028}, {"id": 142, "seek": 68860, "start": 703.16, "end": 708.28, "text": " code with a capital C trademarked, which is interesting. Because that means anything that's", "tokens": [51092, 3089, 365, 257, 4238, 383, 31361, 292, 11, 597, 307, 1880, 13, 1436, 300, 1355, 1340, 300, 311, 51348], "temperature": 0.0, "avg_logprob": -0.15591939290364584, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.20398074388504028}, {"id": 143, "seek": 68860, "start": 708.28, "end": 716.52, "text": " not clean code is a bad code. Yeah, let's not get there. But again, very clear, careful on this,", "tokens": [51348, 406, 2541, 3089, 307, 257, 1578, 3089, 13, 865, 11, 718, 311, 406, 483, 456, 13, 583, 797, 11, 588, 1850, 11, 5026, 322, 341, 11, 51760], "temperature": 0.0, "avg_logprob": -0.15591939290364584, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.20398074388504028}, {"id": 144, "seek": 71652, "start": 716.52, "end": 721.0799999999999, "text": " I'm not going to criticize him. I'm actually like, in admiration of his rhetoric, he's", "tokens": [50364, 286, 478, 406, 516, 281, 31010, 796, 13, 286, 478, 767, 411, 11, 294, 44597, 295, 702, 29604, 11, 415, 311, 50592], "temperature": 0.0, "avg_logprob": -0.13192031632608442, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.10339729487895966}, {"id": 145, "seek": 71652, "start": 721.0799999999999, "end": 726.36, "text": " a politician level when it comes to rhetoric, I mean this. And it's like, this is really good.", "tokens": [50592, 257, 26453, 1496, 562, 309, 1487, 281, 29604, 11, 286, 914, 341, 13, 400, 309, 311, 411, 11, 341, 307, 534, 665, 13, 50856], "temperature": 0.0, "avg_logprob": -0.13192031632608442, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.10339729487895966}, {"id": 146, "seek": 71652, "start": 726.36, "end": 731.4, "text": " Like he's really good at it. But again, he's been doing it for nearly 50 years. He is what 70 years", "tokens": [50856, 1743, 415, 311, 534, 665, 412, 309, 13, 583, 797, 11, 415, 311, 668, 884, 309, 337, 6217, 2625, 924, 13, 634, 307, 437, 5285, 924, 51108], "temperature": 0.0, "avg_logprob": -0.13192031632608442, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.10339729487895966}, {"id": 147, "seek": 71652, "start": 731.4, "end": 738.28, "text": " old. He's been doing this sort of job since what, God, even the early 90s. So it, okay,", "tokens": [51108, 1331, 13, 634, 311, 668, 884, 341, 1333, 295, 1691, 1670, 437, 11, 1265, 11, 754, 264, 2440, 4289, 82, 13, 407, 309, 11, 1392, 11, 51452], "temperature": 0.0, "avg_logprob": -0.13192031632608442, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.10339729487895966}, {"id": 148, "seek": 71652, "start": 739.64, "end": 745.4, "text": " worst, like, it's 30 years, he's been doing this, he's probably been doing it for 40. Okay,", "tokens": [51520, 5855, 11, 411, 11, 309, 311, 2217, 924, 11, 415, 311, 668, 884, 341, 11, 415, 311, 1391, 668, 884, 309, 337, 3356, 13, 1033, 11, 51808], "temperature": 0.0, "avg_logprob": -0.13192031632608442, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.10339729487895966}, {"id": 149, "seek": 74540, "start": 745.4, "end": 749.24, "text": " that's what he does for a living. He's very good at this rhetoric. So that's why I'm like,", "tokens": [50364, 300, 311, 437, 415, 775, 337, 257, 2647, 13, 634, 311, 588, 665, 412, 341, 29604, 13, 407, 300, 311, 983, 286, 478, 411, 11, 50556], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 150, "seek": 74540, "start": 749.24, "end": 753.3199999999999, "text": " I'm kind of admiring it into a certain extent, in a weird Machiavellian sense.", "tokens": [50556, 286, 478, 733, 295, 5910, 5057, 309, 666, 257, 1629, 8396, 11, 294, 257, 3657, 12089, 654, 48592, 952, 2020, 13, 50760], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 151, "seek": 74540, "start": 754.12, "end": 757.4, "text": " But sure, let's carry on with this, shall we? I've got some more things. Another thing in here,", "tokens": [50800, 583, 988, 11, 718, 311, 3985, 322, 365, 341, 11, 4393, 321, 30, 286, 600, 658, 512, 544, 721, 13, 3996, 551, 294, 510, 11, 50964], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 152, "seek": 74540, "start": 757.4, "end": 760.76, "text": " he says, when this whole thing happened when he was talking about it, oh, no,", "tokens": [50964, 415, 1619, 11, 562, 341, 1379, 551, 2011, 562, 415, 390, 1417, 466, 309, 11, 1954, 11, 572, 11, 51132], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 153, "seek": 74540, "start": 762.12, "end": 764.6, "text": " people don't like this code. But then he says, some people do this. And again,", "tokens": [51200, 561, 500, 380, 411, 341, 3089, 13, 583, 550, 415, 1619, 11, 512, 561, 360, 341, 13, 400, 797, 11, 51324], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 154, "seek": 74540, "start": 764.6, "end": 767.48, "text": " I've shown you, he's very good, he's very good at knowing memes. He's not an old man, he's an old", "tokens": [51324, 286, 600, 4898, 291, 11, 415, 311, 588, 665, 11, 415, 311, 588, 665, 412, 5276, 29730, 13, 634, 311, 406, 364, 1331, 587, 11, 415, 311, 364, 1331, 51468], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 155, "seek": 74540, "start": 767.48, "end": 771.72, "text": " man, but he's up to date with a lot of the stuff. And it sounds like silly, but it's not a book,", "tokens": [51468, 587, 11, 457, 415, 311, 493, 281, 4002, 365, 257, 688, 295, 264, 1507, 13, 400, 309, 3263, 411, 11774, 11, 457, 309, 311, 406, 257, 1446, 11, 51680], "temperature": 0.0, "avg_logprob": -0.13429905417186966, "compression_ratio": 1.7988338192419826, "no_speech_prob": 0.05342445150017738}, {"id": 156, "seek": 77172, "start": 771.72, "end": 775.8000000000001, "text": " or the concept, it's a Cartesian pandering immature behavior. The author batches everyone,", "tokens": [50364, 420, 264, 3410, 11, 309, 311, 257, 22478, 42434, 4565, 1794, 49539, 5223, 13, 440, 3793, 15245, 279, 1518, 11, 50568], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 157, "seek": 77172, "start": 775.8000000000001, "end": 778.52, "text": " and then he just shows this claim like, hey, I know how to play your joke.", "tokens": [50568, 293, 550, 415, 445, 3110, 341, 3932, 411, 11, 4177, 11, 286, 458, 577, 281, 862, 428, 7647, 13, 50704], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 158, "seek": 77172, "start": 779.24, "end": 783.24, "text": " Like, and he does, he's not that bad. But then there's other things. So here's like,", "tokens": [50740, 1743, 11, 293, 415, 775, 11, 415, 311, 406, 300, 1578, 13, 583, 550, 456, 311, 661, 721, 13, 407, 510, 311, 411, 11, 50940], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 159, "seek": 77172, "start": 783.24, "end": 788.52, "text": " Casey Motori comes up with, I mean, he's talking about people criticising, and then he replies to", "tokens": [50940, 27369, 8956, 7386, 1487, 493, 365, 11, 286, 914, 11, 415, 311, 1417, 466, 561, 7850, 3436, 11, 293, 550, 415, 42289, 281, 51204], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 160, "seek": 77172, "start": 788.52, "end": 792.76, "text": " this, this is where kind of the start of the conversation is happening. So Casey has says", "tokens": [51204, 341, 11, 341, 307, 689, 733, 295, 264, 722, 295, 264, 3761, 307, 2737, 13, 407, 27369, 575, 1619, 51416], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 161, "seek": 77172, "start": 792.76, "end": 797.64, "text": " in this, even if true, to what extent would you tolerate the, yes, clean code is much slower,", "tokens": [51416, 294, 341, 11, 754, 498, 2074, 11, 281, 437, 8396, 576, 291, 25773, 264, 11, 2086, 11, 2541, 3089, 307, 709, 14009, 11, 51660], "temperature": 0.0, "avg_logprob": -0.18058208680488694, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.11072101444005966}, {"id": 162, "seek": 79764, "start": 797.64, "end": 802.1999999999999, "text": " but it's about programmer productivity for other products. Would you want a car that went only", "tokens": [50364, 457, 309, 311, 466, 32116, 15604, 337, 661, 3383, 13, 6068, 291, 528, 257, 1032, 300, 1437, 787, 50592], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 163, "seek": 79764, "start": 802.1999999999999, "end": 806.68, "text": " five miles per hour, because the designers could do less work to make that car? Now,", "tokens": [50592, 1732, 6193, 680, 1773, 11, 570, 264, 16196, 727, 360, 1570, 589, 281, 652, 300, 1032, 30, 823, 11, 50816], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 164, "seek": 79764, "start": 807.4, "end": 812.76, "text": " Mr. Martin replies to what the auto owners notice he does a pivot. This is a pivot. And also,", "tokens": [50852, 2221, 13, 9184, 42289, 281, 437, 264, 8399, 7710, 3449, 415, 775, 257, 14538, 13, 639, 307, 257, 14538, 13, 400, 611, 11, 51120], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 165, "seek": 79764, "start": 812.76, "end": 818.12, "text": " it doesn't answer the question. He says, the automated mobile industry takes advantage of", "tokens": [51120, 309, 1177, 380, 1867, 264, 1168, 13, 634, 1619, 11, 264, 18473, 6013, 3518, 2516, 5002, 295, 51388], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 166, "seek": 79764, "start": 818.12, "end": 822.84, "text": " every productivity tool they can reduce their enormous manpower cost of designing and manufacturing", "tokens": [51388, 633, 15604, 2290, 436, 393, 5407, 641, 11322, 587, 9513, 2063, 295, 14685, 293, 11096, 51624], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 167, "seek": 79764, "start": 822.84, "end": 827.16, "text": " cars. As a result, cars have gotten exponentially better over the decades, because the extra productivity", "tokens": [51624, 5163, 13, 1018, 257, 1874, 11, 5163, 362, 5768, 37330, 1101, 670, 264, 7878, 11, 570, 264, 2857, 15604, 51840], "temperature": 0.0, "avg_logprob": -0.18083262634277344, "compression_ratio": 1.7242424242424241, "no_speech_prob": 0.06345586478710175}, {"id": 168, "seek": 82716, "start": 827.16, "end": 834.4399999999999, "text": " translates to better designs. Yes. But do you think they for their programming, they're using", "tokens": [50364, 28468, 281, 1101, 11347, 13, 1079, 13, 583, 360, 291, 519, 436, 337, 641, 9410, 11, 436, 434, 1228, 50728], "temperature": 0.0, "avg_logprob": -0.2095448478819832, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.005898885894566774}, {"id": 169, "seek": 82716, "start": 834.4399999999999, "end": 840.92, "text": " clean code? Principles. In fact, we know they don't, especially after he's Mercer and stuff like that,", "tokens": [50728, 2541, 3089, 30, 38372, 2622, 13, 682, 1186, 11, 321, 458, 436, 500, 380, 11, 2318, 934, 415, 311, 6124, 1776, 293, 1507, 411, 300, 11, 51052], "temperature": 0.0, "avg_logprob": -0.2095448478819832, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.005898885894566774}, {"id": 170, "seek": 82716, "start": 840.92, "end": 844.52, "text": " but they have to adhere to certain other things. And like, they're probably not doing clean,", "tokens": [51052, 457, 436, 362, 281, 33584, 281, 1629, 661, 721, 13, 400, 411, 11, 436, 434, 1391, 406, 884, 2541, 11, 51232], "temperature": 0.0, "avg_logprob": -0.2095448478819832, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.005898885894566774}, {"id": 171, "seek": 82716, "start": 844.52, "end": 848.8399999999999, "text": " clean code stuff. Now, I know the most things have started to relax, especially when it comes to,", "tokens": [51232, 2541, 3089, 1507, 13, 823, 11, 286, 458, 264, 881, 721, 362, 1409, 281, 5789, 11, 2318, 562, 309, 1487, 281, 11, 51448], "temperature": 0.0, "avg_logprob": -0.2095448478819832, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.005898885894566774}, {"id": 172, "seek": 82716, "start": 848.8399999999999, "end": 854.92, "text": " like, Android Auto and I'm like, Apple Car play and stuff like that, it's, they're stuff a buggy.", "tokens": [51448, 411, 11, 8853, 13738, 293, 286, 478, 411, 11, 6373, 2741, 862, 293, 1507, 411, 300, 11, 309, 311, 11, 436, 434, 1507, 257, 7426, 1480, 13, 51752], "temperature": 0.0, "avg_logprob": -0.2095448478819832, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.005898885894566774}, {"id": 173, "seek": 85492, "start": 854.92, "end": 858.1999999999999, "text": " But that's kind of like, Oh, it's your phone. That's a different thing. It's just we're interfacing", "tokens": [50364, 583, 300, 311, 733, 295, 411, 11, 876, 11, 309, 311, 428, 2593, 13, 663, 311, 257, 819, 551, 13, 467, 311, 445, 321, 434, 14510, 5615, 50528], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 174, "seek": 85492, "start": 858.1999999999999, "end": 862.52, "text": " with it and whatever. And it's interesting. He does this because he does it again, when someone", "tokens": [50528, 365, 309, 293, 2035, 13, 400, 309, 311, 1880, 13, 634, 775, 341, 570, 415, 775, 309, 797, 11, 562, 1580, 50744], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 175, "seek": 85492, "start": 863.24, "end": 868.1999999999999, "text": " replies to it and anything here. But he's kind of a, he knows what he's doing when he says these", "tokens": [50780, 42289, 281, 309, 293, 1340, 510, 13, 583, 415, 311, 733, 295, 257, 11, 415, 3255, 437, 415, 311, 884, 562, 415, 1619, 613, 51028], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 176, "seek": 85492, "start": 868.1999999999999, "end": 874.92, "text": " arguments. That's not answering the question. All I'm going to say is that just watch that. Okay.", "tokens": [51028, 12869, 13, 663, 311, 406, 13430, 264, 1168, 13, 1057, 286, 478, 516, 281, 584, 307, 300, 445, 1159, 300, 13, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 177, "seek": 85492, "start": 874.92, "end": 878.04, "text": " Another thing is this is when it starts, this was the beginning of his, I wash your thoughts and", "tokens": [51364, 3996, 551, 307, 341, 307, 562, 309, 3719, 11, 341, 390, 264, 2863, 295, 702, 11, 286, 5675, 428, 4598, 293, 51520], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 178, "seek": 85492, "start": 878.04, "end": 882.36, "text": " he says, Oh, I've commented on this before clean code is made for programmer performance,", "tokens": [51520, 415, 1619, 11, 876, 11, 286, 600, 26940, 322, 341, 949, 2541, 3089, 307, 1027, 337, 32116, 3389, 11, 51736], "temperature": 0.0, "avg_logprob": -0.18153899788056443, "compression_ratio": 1.7699386503067485, "no_speech_prob": 0.0304733794182539}, {"id": 179, "seek": 88236, "start": 882.36, "end": 888.12, "text": " not algorithmic performance. If you need the latter, then write in C or assemble and live with", "tokens": [50364, 406, 9284, 299, 3389, 13, 759, 291, 643, 264, 18481, 11, 550, 2464, 294, 383, 420, 22364, 293, 1621, 365, 50652], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 180, "seek": 88236, "start": 888.12, "end": 894.36, "text": " the high cost of development. So few things there already, PI programmer performance and", "tokens": [50652, 264, 1090, 2063, 295, 3250, 13, 407, 1326, 721, 456, 1217, 11, 27176, 32116, 3389, 293, 50964], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 181, "seek": 88236, "start": 894.36, "end": 899.5600000000001, "text": " algorithmic performance. Okay, so program performance, it's the, in the contrast, how do you measure", "tokens": [50964, 9284, 299, 3389, 13, 1033, 11, 370, 1461, 3389, 11, 309, 311, 264, 11, 294, 264, 8712, 11, 577, 360, 291, 3481, 51224], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 182, "seek": 88236, "start": 899.5600000000001, "end": 903.64, "text": " that thing? How would you know if that your approach is better than another approach? And if", "tokens": [51224, 300, 551, 30, 1012, 576, 291, 458, 498, 300, 428, 3109, 307, 1101, 813, 1071, 3109, 30, 400, 498, 51428], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 183, "seek": 88236, "start": 903.64, "end": 907.0, "text": " you need the latter, write in C and assemble, okay, it's assembly, I would call this, but yeah,", "tokens": [51428, 291, 643, 264, 18481, 11, 2464, 294, 383, 293, 22364, 11, 1392, 11, 309, 311, 12103, 11, 286, 576, 818, 341, 11, 457, 1338, 11, 51596], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 184, "seek": 88236, "start": 907.0, "end": 910.36, "text": " and then high cost of, so he's already implying that writing in C", "tokens": [51596, 293, 550, 1090, 2063, 295, 11, 370, 415, 311, 1217, 704, 7310, 300, 3579, 294, 383, 51764], "temperature": 0.0, "avg_logprob": -0.1883449120955034, "compression_ratio": 1.9113475177304964, "no_speech_prob": 0.015130528248846531}, {"id": 185, "seek": 91036, "start": 911.16, "end": 914.6800000000001, "text": " is going to be a much higher cost of development than writing in another language.", "tokens": [50404, 307, 516, 281, 312, 257, 709, 2946, 2063, 295, 3250, 813, 3579, 294, 1071, 2856, 13, 50580], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 186, "seek": 91036, "start": 914.6800000000001, "end": 918.6, "text": " It might be, but you should only write it in because you need the performance. And it's like,", "tokens": [50580, 467, 1062, 312, 11, 457, 291, 820, 787, 2464, 309, 294, 570, 291, 643, 264, 3389, 13, 400, 309, 311, 411, 11, 50776], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 187, "seek": 91036, "start": 919.4, "end": 925.72, "text": " okay, what? Look at the framing. He knows what he's doing. I'm not saying he's an idiot. He's", "tokens": [50816, 1392, 11, 437, 30, 2053, 412, 264, 28971, 13, 634, 3255, 437, 415, 311, 884, 13, 286, 478, 406, 1566, 415, 311, 364, 14270, 13, 634, 311, 51132], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 188, "seek": 91036, "start": 925.72, "end": 929.96, "text": " very smart. Okay, I'm sorry. I'm picturing it. I can already see which side I'm in, but I'm just", "tokens": [51132, 588, 4069, 13, 1033, 11, 286, 478, 2597, 13, 286, 478, 2317, 1345, 309, 13, 286, 393, 1217, 536, 597, 1252, 286, 478, 294, 11, 457, 286, 478, 445, 51344], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 189, "seek": 91036, "start": 929.96, "end": 933.8000000000001, "text": " trying to explain the rhetoric tricks. So this is another thing is like the clean code to reply", "tokens": [51344, 1382, 281, 2903, 264, 29604, 11733, 13, 407, 341, 307, 1071, 551, 307, 411, 264, 2541, 3089, 281, 16972, 51536], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 190, "seek": 91036, "start": 933.8000000000001, "end": 937.24, "text": " to later with the automatic ability. I've got these switching around. It doesn't matter. People", "tokens": [51536, 281, 1780, 365, 264, 12509, 3485, 13, 286, 600, 658, 613, 16493, 926, 13, 467, 1177, 380, 1871, 13, 3432, 51708], "temperature": 0.0, "avg_logprob": -0.2026446465732289, "compression_ratio": 1.6587537091988132, "no_speech_prob": 0.02658749185502529}, {"id": 191, "seek": 93724, "start": 937.32, "end": 942.6, "text": " says, how do you measure readability of the code by reading it? So obvious. But it's like,", "tokens": [50368, 1619, 11, 577, 360, 291, 3481, 1401, 2310, 295, 264, 3089, 538, 3760, 309, 30, 407, 6322, 13, 583, 309, 311, 411, 11, 50632], "temperature": 0.0, "avg_logprob": -0.2033241199997236, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.014035307802259922}, {"id": 192, "seek": 93724, "start": 942.6, "end": 947.88, "text": " when people say measure, they usually mean a quantifiable thing rather than a qualifying thing.", "tokens": [50632, 562, 561, 584, 3481, 11, 436, 2673, 914, 257, 4426, 30876, 551, 2831, 813, 257, 41793, 551, 13, 50896], "temperature": 0.0, "avg_logprob": -0.2033241199997236, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.014035307802259922}, {"id": 193, "seek": 93724, "start": 947.88, "end": 954.12, "text": " So this equality and a quantity are two distinct ontological categories, okay, or", "tokens": [50896, 407, 341, 14949, 293, 257, 11275, 366, 732, 10644, 6592, 4383, 10479, 11, 1392, 11, 420, 51208], "temperature": 0.0, "avg_logprob": -0.2033241199997236, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.014035307802259922}, {"id": 194, "seek": 93724, "start": 954.12, "end": 957.08, "text": " epistemological, the many different things, which is not going to philosophy too much, but", "tokens": [51208, 2388, 43958, 4383, 11, 264, 867, 819, 721, 11, 597, 307, 406, 516, 281, 10675, 886, 709, 11, 457, 51356], "temperature": 0.0, "avg_logprob": -0.2033241199997236, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.014035307802259922}, {"id": 195, "seek": 93724, "start": 957.08, "end": 962.04, "text": " you cannot quantify a quality and never qualify a quantity in a sense. They're different things", "tokens": [51356, 291, 2644, 40421, 257, 3125, 293, 1128, 20276, 257, 11275, 294, 257, 2020, 13, 814, 434, 819, 721, 51604], "temperature": 0.0, "avg_logprob": -0.2033241199997236, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.014035307802259922}, {"id": 196, "seek": 96204, "start": 962.12, "end": 970.92, "text": " like, Hey, I have a tape measure here. Yeah, I can say it's got the, I say it's quality of being good", "tokens": [50368, 411, 11, 1911, 11, 286, 362, 257, 7314, 3481, 510, 13, 865, 11, 286, 393, 584, 309, 311, 658, 264, 11, 286, 584, 309, 311, 3125, 295, 885, 665, 50808], "temperature": 0.0, "avg_logprob": -0.17190948246032234, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.05284507945179939}, {"id": 197, "seek": 96204, "start": 970.92, "end": 975.16, "text": " and round and green and stuff like that. And these aren't even very good qualities, to be", "tokens": [50808, 293, 3098, 293, 3092, 293, 1507, 411, 300, 13, 400, 613, 3212, 380, 754, 588, 665, 16477, 11, 281, 312, 51020], "temperature": 0.0, "avg_logprob": -0.17190948246032234, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.05284507945179939}, {"id": 198, "seek": 96204, "start": 975.16, "end": 981.4, "text": " honest with you, but it has quantities. I know it's mass just by dropping it. That's what you need to", "tokens": [51020, 3245, 365, 291, 11, 457, 309, 575, 22927, 13, 286, 458, 309, 311, 2758, 445, 538, 13601, 309, 13, 663, 311, 437, 291, 643, 281, 51332], "temperature": 0.0, "avg_logprob": -0.17190948246032234, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.05284507945179939}, {"id": 199, "seek": 96204, "start": 981.4, "end": 985.0, "text": " do. That's absolutely fine. And it masters. I'm just trying to explain the gravity thing. So", "tokens": [51332, 360, 13, 663, 311, 3122, 2489, 13, 400, 309, 19294, 13, 286, 478, 445, 1382, 281, 2903, 264, 12110, 551, 13, 407, 51512], "temperature": 0.0, "avg_logprob": -0.17190948246032234, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.05284507945179939}, {"id": 200, "seek": 96204, "start": 985.0, "end": 988.28, "text": " clearly it's got mass and we can measure that relative to other things that weigh things. So", "tokens": [51512, 4448, 309, 311, 658, 2758, 293, 321, 393, 3481, 300, 4972, 281, 661, 721, 300, 13843, 721, 13, 407, 51676], "temperature": 0.0, "avg_logprob": -0.17190948246032234, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.05284507945179939}, {"id": 201, "seek": 98828, "start": 988.28, "end": 994.52, "text": " we know how much this is weighs. This is probably weighs about, I don't know, eight ounces. So 225", "tokens": [50364, 321, 458, 577, 709, 341, 307, 24911, 13, 639, 307, 1391, 24911, 466, 11, 286, 500, 380, 458, 11, 3180, 27343, 13, 407, 5853, 20, 50676], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 202, "seek": 98828, "start": 994.52, "end": 1001.72, "text": " grams ish. That's quite heavy, actually, surprisingly, it's not even a good one. But there's kind of", "tokens": [50676, 11899, 307, 71, 13, 663, 311, 1596, 4676, 11, 767, 11, 17600, 11, 309, 311, 406, 754, 257, 665, 472, 13, 583, 456, 311, 733, 295, 51036], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 203, "seek": 98828, "start": 1001.72, "end": 1005.3199999999999, "text": " the thing. So you can actually think you can sort of say, Oh, how, how green is where we can measure", "tokens": [51036, 264, 551, 13, 407, 291, 393, 767, 519, 291, 393, 1333, 295, 584, 11, 876, 11, 577, 11, 577, 3092, 307, 689, 321, 393, 3481, 51216], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 204, "seek": 98828, "start": 1005.3199999999999, "end": 1008.76, "text": " the reflectings of it and then see how much it reflects back a certain light and some wavelengths", "tokens": [51216, 264, 5031, 1109, 295, 309, 293, 550, 536, 577, 709, 309, 18926, 646, 257, 1629, 1442, 293, 512, 47424, 51388], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 205, "seek": 98828, "start": 1008.76, "end": 1012.76, "text": " and such like this. You can say all these quantities and you're, these are quantities,", "tokens": [51388, 293, 1270, 411, 341, 13, 509, 393, 584, 439, 613, 22927, 293, 291, 434, 11, 613, 366, 22927, 11, 51588], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 206, "seek": 98828, "start": 1012.76, "end": 1016.4399999999999, "text": " okay, but I want to go into too much clearly. I used to be a quantum metrologist. So I know", "tokens": [51588, 1392, 11, 457, 286, 528, 281, 352, 666, 886, 709, 4448, 13, 286, 1143, 281, 312, 257, 13018, 1131, 20978, 468, 13, 407, 286, 458, 51772], "temperature": 0.0, "avg_logprob": -0.2004446765176611, "compression_ratio": 1.7537993920972645, "no_speech_prob": 0.024471769109368324}, {"id": 207, "seek": 101644, "start": 1016.44, "end": 1020.9200000000001, "text": " a lot of you may excuse measurements and all this stuff. But this is a clever trick by reading it.", "tokens": [50364, 257, 688, 295, 291, 815, 8960, 15383, 293, 439, 341, 1507, 13, 583, 341, 307, 257, 13494, 4282, 538, 3760, 309, 13, 50588], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 208, "seek": 101644, "start": 1021.8800000000001, "end": 1026.04, "text": " That is not a quantity. And people are wanting to question how do you measure when we want an", "tokens": [50636, 663, 307, 406, 257, 11275, 13, 400, 561, 366, 7935, 281, 1168, 577, 360, 291, 3481, 562, 321, 528, 364, 50844], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 209, "seek": 101644, "start": 1026.04, "end": 1032.2, "text": " objective measurement? What do you mean is they want a quantity? But he goes out by doing this.", "tokens": [50844, 10024, 13160, 30, 708, 360, 291, 914, 307, 436, 528, 257, 11275, 30, 583, 415, 1709, 484, 538, 884, 341, 13, 51152], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 210, "seek": 101644, "start": 1032.2, "end": 1036.28, "text": " So this was a big long twist post I've been here, where Lawrence Crow again,", "tokens": [51152, 407, 341, 390, 257, 955, 938, 8203, 2183, 286, 600, 668, 510, 11, 689, 22787, 27072, 797, 11, 51356], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 211, "seek": 101644, "start": 1037.0800000000002, "end": 1040.8400000000001, "text": " the community anyway says people on hand made hating on Casey's videos about performance,", "tokens": [51396, 264, 1768, 4033, 1619, 561, 322, 1011, 1027, 45082, 322, 27369, 311, 2145, 466, 3389, 11, 51584], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 212, "seek": 101644, "start": 1040.8400000000001, "end": 1044.52, "text": " while their company is spending double digits of percentages of their revenue on", "tokens": [51584, 1339, 641, 2237, 307, 6434, 3834, 27011, 295, 42270, 295, 641, 9324, 322, 51768], "temperature": 0.0, "avg_logprob": -0.27066329217726187, "compression_ratio": 1.6645962732919255, "no_speech_prob": 0.00804964080452919}, {"id": 213, "seek": 104452, "start": 1044.6, "end": 1048.6, "text": " Amazon web server bills to serve three forms and a database view. And it's like, okay,", "tokens": [50368, 6795, 3670, 7154, 12433, 281, 4596, 1045, 6422, 293, 257, 8149, 1910, 13, 400, 309, 311, 411, 11, 1392, 11, 50568], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 214, "seek": 104452, "start": 1048.6, "end": 1053.32, "text": " this is great nightlight discussion. Talking about this. And then Mr. Martin says here is his,", "tokens": [50568, 341, 307, 869, 1818, 2764, 5017, 13, 22445, 466, 341, 13, 400, 550, 2221, 13, 9184, 1619, 510, 307, 702, 11, 50804], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 215, "seek": 104452, "start": 1053.32, "end": 1057.4, "text": " his analysis was correct. His rhetoric is abyssin, disingenuous. And the overall point was", "tokens": [50804, 702, 5215, 390, 3006, 13, 2812, 29604, 307, 410, 749, 19767, 11, 717, 12343, 12549, 13, 400, 264, 4787, 935, 390, 51008], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 216, "seek": 104452, "start": 1057.4, "end": 1061.32, "text": " extraordinary narrow. Clean code is about increasing programmer performance. He keeps", "tokens": [51008, 10581, 9432, 13, 18463, 3089, 307, 466, 5662, 32116, 3389, 13, 634, 5965, 51204], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 217, "seek": 104452, "start": 1061.32, "end": 1066.52, "text": " it straight this not computer performance. What are some real life life non-trial view", "tokens": [51204, 309, 2997, 341, 406, 3820, 3389, 13, 708, 366, 512, 957, 993, 993, 2107, 12, 83, 7111, 1910, 51464], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 218, "seek": 104452, "start": 1066.52, "end": 1070.44, "text": " code bases support the hypothesis that strict clean code increases program performance", "tokens": [51464, 3089, 17949, 1406, 264, 17291, 300, 10910, 2541, 3089, 8637, 1461, 3389, 51660], "temperature": 0.0, "avg_logprob": -0.25895287008846507, "compression_ratio": 1.72168284789644, "no_speech_prob": 0.02193531021475792}, {"id": 219, "seek": 107044, "start": 1071.0800000000002, "end": 1071.96, "text": " replies with a mean.", "tokens": [50396, 42289, 365, 257, 914, 13, 50440], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 220, "seek": 107044, "start": 1075.56, "end": 1080.3600000000001, "text": " Again, he knows what he's doing. I'm not like, this is really cool. Like he knows what he's doing.", "tokens": [50620, 3764, 11, 415, 3255, 437, 415, 311, 884, 13, 286, 478, 406, 411, 11, 341, 307, 534, 1627, 13, 1743, 415, 3255, 437, 415, 311, 884, 13, 50860], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 221, "seek": 107044, "start": 1080.3600000000001, "end": 1083.56, "text": " But yeah, so you don't have any of his tools that some says it. So the Vittorio", "tokens": [50860, 583, 1338, 11, 370, 291, 500, 380, 362, 604, 295, 702, 3873, 300, 512, 1619, 309, 13, 407, 264, 691, 593, 284, 1004, 51020], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 222, "seek": 107044, "start": 1083.56, "end": 1087.0800000000002, "text": " reminded me of a thing for the people I got into a discussion with him around about this time.", "tokens": [51020, 15920, 385, 295, 257, 551, 337, 264, 561, 286, 658, 666, 257, 5017, 365, 796, 926, 466, 341, 565, 13, 51196], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 223, "seek": 107044, "start": 1087.0800000000002, "end": 1092.52, "text": " And I kind of partially convinced him about like, well, you need you've not go evidence for why one's", "tokens": [51196, 400, 286, 733, 295, 18886, 12561, 796, 466, 411, 11, 731, 11, 291, 643, 291, 600, 406, 352, 4467, 337, 983, 472, 311, 51468], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 224, "seek": 107044, "start": 1092.52, "end": 1096.2, "text": " better than the other. Like show why how do you know one's better than the other? It's kind of", "tokens": [51468, 1101, 813, 264, 661, 13, 1743, 855, 983, 577, 360, 291, 458, 472, 311, 1101, 813, 264, 661, 30, 467, 311, 733, 295, 51652], "temperature": 0.0, "avg_logprob": -0.2091110794632523, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.08340835571289062}, {"id": 225, "seek": 109620, "start": 1096.28, "end": 1100.1200000000001, "text": " that question. Like how do you know what measurements are using what quantifiable or even", "tokens": [50368, 300, 1168, 13, 1743, 577, 360, 291, 458, 437, 15383, 366, 1228, 437, 4426, 30876, 420, 754, 50560], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 226, "seek": 109620, "start": 1100.1200000000001, "end": 1103.88, "text": " qualifiable things are you showing? Like, can you just show me the evidence? And then he goes,", "tokens": [50560, 4101, 30876, 721, 366, 291, 4099, 30, 1743, 11, 393, 291, 445, 855, 385, 264, 4467, 30, 400, 550, 415, 1709, 11, 50748], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 227, "seek": 109620, "start": 1103.88, "end": 1108.2, "text": " he knows this for a fact, he says, the problem with scientific data is it's controlled in", "tokens": [50748, 415, 3255, 341, 337, 257, 1186, 11, 415, 1619, 11, 264, 1154, 365, 8134, 1412, 307, 309, 311, 10164, 294, 50964], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 228, "seek": 109620, "start": 1108.2, "end": 1111.64, "text": " controlled experiments and realistic software environments are economically feasible. You're", "tokens": [50964, 10164, 12050, 293, 12465, 4722, 12388, 366, 26811, 26648, 13, 509, 434, 51136], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 229, "seek": 109620, "start": 1111.64, "end": 1116.44, "text": " asking for something you'll never get. And yet you still decide. So look around and that's just", "tokens": [51136, 3365, 337, 746, 291, 603, 1128, 483, 13, 400, 1939, 291, 920, 4536, 13, 407, 574, 926, 293, 300, 311, 445, 51376], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 230, "seek": 109620, "start": 1116.44, "end": 1119.88, "text": " so it's especially your seniors. So first of all, it's just the first part of this thing here is", "tokens": [51376, 370, 309, 311, 2318, 428, 21069, 13, 407, 700, 295, 439, 11, 309, 311, 445, 264, 700, 644, 295, 341, 551, 510, 307, 51548], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 231, "seek": 109620, "start": 1120.52, "end": 1126.1200000000001, "text": " we have no evidence for our claims. But it's okay, because your associate seniors may agree", "tokens": [51580, 321, 362, 572, 4467, 337, 527, 9441, 13, 583, 309, 311, 1392, 11, 570, 428, 14644, 21069, 815, 3986, 51860], "temperature": 0.0, "avg_logprob": -0.1911852518717448, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.16424790024757385}, {"id": 232, "seek": 112612, "start": 1126.12, "end": 1135.4799999999998, "text": " with me already. Nice little pairing here doesn't do the same thing. Okay. That's the first thing.", "tokens": [50364, 365, 385, 1217, 13, 5490, 707, 32735, 510, 1177, 380, 360, 264, 912, 551, 13, 1033, 13, 663, 311, 264, 700, 551, 13, 50832], "temperature": 0.0, "avg_logprob": -0.21825436888069943, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.005662186536937952}, {"id": 233, "seek": 112612, "start": 1136.6, "end": 1140.6, "text": " But then someone said like they said they use over the 10 lines of code sometimes wrong seniors,", "tokens": [50888, 583, 550, 1580, 848, 411, 436, 848, 436, 764, 670, 264, 1266, 3876, 295, 3089, 2171, 2085, 21069, 11, 51088], "temperature": 0.0, "avg_logprob": -0.21825436888069943, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.005662186536937952}, {"id": 234, "seek": 112612, "start": 1140.6, "end": 1144.6, "text": " I guess, and someone saying like, well, we've got my seniors don't agree with you. So sometimes,", "tokens": [51088, 286, 2041, 11, 293, 1580, 1566, 411, 11, 731, 11, 321, 600, 658, 452, 21069, 500, 380, 3986, 365, 291, 13, 407, 2171, 11, 51288], "temperature": 0.0, "avg_logprob": -0.21825436888069943, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.005662186536937952}, {"id": 235, "seek": 112612, "start": 1144.6, "end": 1149.1599999999999, "text": " of course, your seniors were correct. I presume they also told you that or else be your smaller", "tokens": [51288, 295, 1164, 11, 428, 21069, 645, 3006, 13, 286, 43283, 436, 611, 1907, 291, 300, 420, 1646, 312, 428, 4356, 51516], "temperature": 0.0, "avg_logprob": -0.21825436888069943, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.005662186536937952}, {"id": 236, "seek": 112612, "start": 1149.1599999999999, "end": 1153.8799999999999, "text": " well named functions are better than really badly named functions is like, okay, notice the bad", "tokens": [51516, 731, 4926, 6828, 366, 1101, 813, 534, 13425, 4926, 6828, 307, 411, 11, 1392, 11, 3449, 264, 1578, 51752], "temperature": 0.0, "avg_logprob": -0.21825436888069943, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.005662186536937952}, {"id": 237, "seek": 115388, "start": 1153.88, "end": 1158.1200000000001, "text": " pairing there already. A well named function is better than a badly named function. Agreed.", "tokens": [50364, 32735, 456, 1217, 13, 316, 731, 4926, 2445, 307, 1101, 813, 257, 13425, 4926, 2445, 13, 29324, 292, 13, 50576], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 238, "seek": 115388, "start": 1158.7600000000002, "end": 1163.16, "text": " Smaller function may not be better than a long function. But notice is smaller well named", "tokens": [50608, 15287, 260, 2445, 815, 406, 312, 1101, 813, 257, 938, 2445, 13, 583, 3449, 307, 4356, 731, 4926, 50828], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 239, "seek": 115388, "start": 1163.16, "end": 1166.8400000000001, "text": " functions are better than really badly named functions. Never talked about the length of it.", "tokens": [50828, 6828, 366, 1101, 813, 534, 13425, 4926, 6828, 13, 7344, 2825, 466, 264, 4641, 295, 309, 13, 51012], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 240, "seek": 115388, "start": 1169.0, "end": 1173.64, "text": " I know it's like a minor word difference. But he knows what he's doing. And also he just changed", "tokens": [51120, 286, 458, 309, 311, 411, 257, 6696, 1349, 2649, 13, 583, 415, 3255, 437, 415, 311, 884, 13, 400, 611, 415, 445, 3105, 51352], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 241, "seek": 115388, "start": 1173.64, "end": 1177.48, "text": " the topic and it's a pivot. He's gone from being the scientific data to now to well, trust your", "tokens": [51352, 264, 4829, 293, 309, 311, 257, 14538, 13, 634, 311, 2780, 490, 885, 264, 8134, 1412, 281, 586, 281, 731, 11, 3361, 428, 51544], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 242, "seek": 115388, "start": 1177.48, "end": 1183.0, "text": " the trust the authorities of your seniors or elders or whatever, like, that's going to authority", "tokens": [51544, 264, 3361, 264, 12076, 295, 428, 21069, 420, 22737, 420, 2035, 11, 411, 11, 300, 311, 516, 281, 8281, 51820], "temperature": 0.0, "avg_logprob": -0.16645177683435886, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.012044871225953102}, {"id": 243, "seek": 118300, "start": 1183.08, "end": 1188.76, "text": " rather than going to like empirical data. Nice little pivot. He knows exactly what he's doing.", "tokens": [50368, 2831, 813, 516, 281, 411, 31886, 1412, 13, 5490, 707, 14538, 13, 634, 3255, 2293, 437, 415, 311, 884, 13, 50652], "temperature": 0.0, "avg_logprob": -0.1671966789043055, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.01970086246728897}, {"id": 244, "seek": 118300, "start": 1189.96, "end": 1194.68, "text": " So another one here is always remember that computers operate on f in character one f in", "tokens": [50712, 407, 1071, 472, 510, 307, 1009, 1604, 300, 10807, 9651, 322, 283, 294, 2517, 472, 283, 294, 50948], "temperature": 0.0, "avg_logprob": -0.1671966789043055, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.01970086246728897}, {"id": 245, "seek": 118300, "start": 1194.68, "end": 1199.0, "text": " character to times he's trying not to swear here. No matter what lovely subroutines you might be", "tokens": [50948, 2517, 281, 1413, 415, 311, 1382, 406, 281, 11902, 510, 13, 883, 1871, 437, 7496, 1422, 81, 346, 1652, 291, 1062, 312, 51164], "temperature": 0.0, "avg_logprob": -0.1671966789043055, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.01970086246728897}, {"id": 246, "seek": 118300, "start": 1199.0, "end": 1203.16, "text": " using some replies, what about Sunday? Well, the context of the problem was JavaScript in a browser.", "tokens": [51164, 1228, 512, 42289, 11, 437, 466, 7776, 30, 1042, 11, 264, 4319, 295, 264, 1154, 390, 15778, 294, 257, 11185, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1671966789043055, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.01970086246728897}, {"id": 247, "seek": 118300, "start": 1203.16, "end": 1209.0, "text": " I'm like, what context I even tried to search through the other tweets. There was no context.", "tokens": [51372, 286, 478, 411, 11, 437, 4319, 286, 754, 3031, 281, 3164, 807, 264, 661, 25671, 13, 821, 390, 572, 4319, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1671966789043055, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.01970086246728897}, {"id": 248, "seek": 120900, "start": 1209.72, "end": 1220.76, "text": " So, yeah. Okay, carry on. Another one. Someone has recently equated clean code", "tokens": [50400, 407, 11, 1338, 13, 1033, 11, 3985, 322, 13, 3996, 472, 13, 8734, 575, 3938, 1267, 770, 2541, 3089, 50952], "temperature": 0.0, "avg_logprob": -0.20502295213587143, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.015416792593896389}, {"id": 249, "seek": 120900, "start": 1220.76, "end": 1226.84, "text": " over engineering. That is, of course, an oxymoron. An over engine code is by definition not clean", "tokens": [50952, 670, 7043, 13, 663, 307, 11, 295, 1164, 11, 364, 5976, 4199, 284, 266, 13, 1107, 670, 2848, 3089, 307, 538, 7123, 406, 2541, 51256], "temperature": 0.0, "avg_logprob": -0.20502295213587143, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.015416792593896389}, {"id": 250, "seek": 120900, "start": 1226.84, "end": 1230.12, "text": " and makes me wonder if those who complain so loudly have actually stood at the target of", "tokens": [51256, 293, 1669, 385, 2441, 498, 729, 567, 11024, 370, 22958, 362, 767, 9371, 412, 264, 3779, 295, 51420], "temperature": 0.0, "avg_logprob": -0.20502295213587143, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.015416792593896389}, {"id": 251, "seek": 123012, "start": 1230.12, "end": 1238.12, "text": " their complaints. It's like, see the see the problem. So if he's over engineered, it can't be", "tokens": [50364, 641, 19585, 13, 467, 311, 411, 11, 536, 264, 536, 264, 1154, 13, 407, 498, 415, 311, 670, 38648, 11, 309, 393, 380, 312, 50764], "temperature": 0.0, "avg_logprob": -0.21055540999745934, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.2019377499818802}, {"id": 252, "seek": 123012, "start": 1238.12, "end": 1242.6, "text": " clean code. Even though I've seen many clean code, which I've classes over and engineered. In fact,", "tokens": [50764, 2541, 3089, 13, 2754, 1673, 286, 600, 1612, 867, 2541, 3089, 11, 597, 286, 600, 5359, 670, 293, 38648, 13, 682, 1186, 11, 50988], "temperature": 0.0, "avg_logprob": -0.21055540999745934, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.2019377499818802}, {"id": 253, "seek": 123012, "start": 1242.6, "end": 1247.7199999999998, "text": " I think clean code by default is kind of open engineered like it doesn't it's assuming this", "tokens": [50988, 286, 519, 2541, 3089, 538, 7576, 307, 733, 295, 1269, 38648, 411, 309, 1177, 380, 309, 311, 11926, 341, 51244], "temperature": 0.0, "avg_logprob": -0.21055540999745934, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.2019377499818802}, {"id": 254, "seek": 123012, "start": 1247.7199999999998, "end": 1253.1599999999999, "text": " could be open to change even though it's a close set of problems, which I'll get onto a bit later.", "tokens": [51244, 727, 312, 1269, 281, 1319, 754, 1673, 309, 311, 257, 1998, 992, 295, 2740, 11, 597, 286, 603, 483, 3911, 257, 857, 1780, 13, 51516], "temperature": 0.0, "avg_logprob": -0.21055540999745934, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.2019377499818802}, {"id": 255, "seek": 123012, "start": 1254.76, "end": 1258.1999999999998, "text": " So then talking about this for tour of Rome, a shot we had earlier, I was discussing with him", "tokens": [51596, 407, 550, 1417, 466, 341, 337, 3512, 295, 12043, 11, 257, 3347, 321, 632, 3071, 11, 286, 390, 10850, 365, 796, 51768], "temperature": 0.0, "avg_logprob": -0.21055540999745934, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.2019377499818802}, {"id": 256, "seek": 125820, "start": 1258.2, "end": 1262.44, "text": " previously. And he was kind of like, Oh, well, I can make it even faster. If you just change the", "tokens": [50364, 8046, 13, 400, 415, 390, 733, 295, 411, 11, 876, 11, 731, 11, 286, 393, 652, 309, 754, 4663, 13, 759, 291, 445, 1319, 264, 50576], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 257, "seek": 125820, "start": 1262.44, "end": 1266.28, "text": " entire style of it and just have a raise of separate types. And I was just like, you being honest,", "tokens": [50576, 2302, 3758, 295, 309, 293, 445, 362, 257, 5300, 295, 4994, 3467, 13, 400, 286, 390, 445, 411, 11, 291, 885, 3245, 11, 50768], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 258, "seek": 125820, "start": 1266.28, "end": 1270.44, "text": " but this was the conversation I had even trying to confuse it like to not, he was kind of being", "tokens": [50768, 457, 341, 390, 264, 3761, 286, 632, 754, 1382, 281, 28584, 309, 411, 281, 406, 11, 415, 390, 733, 295, 885, 50976], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 259, "seek": 125820, "start": 1270.44, "end": 1273.0800000000002, "text": " a bit confused, but also trying to be like explaining. And we kind of got to a point where", "tokens": [50976, 257, 857, 9019, 11, 457, 611, 1382, 281, 312, 411, 13468, 13, 400, 321, 733, 295, 658, 281, 257, 935, 689, 51108], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 260, "seek": 125820, "start": 1273.0800000000002, "end": 1277.8, "text": " like, Oh, okay, like, first off, you've been a bit disingenuous here, man, with the argument,", "tokens": [51108, 411, 11, 876, 11, 1392, 11, 411, 11, 700, 766, 11, 291, 600, 668, 257, 857, 717, 12343, 12549, 510, 11, 587, 11, 365, 264, 6770, 11, 51344], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 261, "seek": 125820, "start": 1277.8, "end": 1281.56, "text": " but fine. This is not Mr. Martin anymore. This is just me explaining like there are people who are", "tokens": [51344, 457, 2489, 13, 639, 307, 406, 2221, 13, 9184, 3602, 13, 639, 307, 445, 385, 13468, 411, 456, 366, 561, 567, 366, 51532], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 262, "seek": 125820, "start": 1281.56, "end": 1285.96, "text": " trying not saying to defend him, but not understanding like Casey's point in this", "tokens": [51532, 1382, 406, 1566, 281, 8602, 796, 11, 457, 406, 3701, 411, 27369, 311, 935, 294, 341, 51752], "temperature": 0.0, "avg_logprob": -0.1447892105370237, "compression_ratio": 1.8664772727272727, "no_speech_prob": 0.15961630642414093}, {"id": 263, "seek": 128596, "start": 1285.96, "end": 1291.0, "text": " discussion. So again, before I'm going to read this article, I recommend reading this clean", "tokens": [50364, 5017, 13, 407, 797, 11, 949, 286, 478, 516, 281, 1401, 341, 7222, 11, 286, 2748, 3760, 341, 2541, 50616], "temperature": 0.0, "avg_logprob": -0.11521987747727779, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.050315987318754196}, {"id": 264, "seek": 128596, "start": 1291.0, "end": 1296.1200000000001, "text": " code, horror performance, YouTube video, again, links are in the description for all of these", "tokens": [50616, 3089, 11, 11501, 3389, 11, 3088, 960, 11, 797, 11, 6123, 366, 294, 264, 3855, 337, 439, 295, 613, 50872], "temperature": 0.0, "avg_logprob": -0.11521987747727779, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.050315987318754196}, {"id": 265, "seek": 128596, "start": 1296.1200000000001, "end": 1300.6000000000001, "text": " links. So don't worry, they'll be there. So now I've done the 20 minutes spiel at the beginning", "tokens": [50872, 6123, 13, 407, 500, 380, 3292, 11, 436, 603, 312, 456, 13, 407, 586, 286, 600, 1096, 264, 945, 2077, 637, 1187, 412, 264, 2863, 51096], "temperature": 0.0, "avg_logprob": -0.11521987747727779, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.050315987318754196}, {"id": 266, "seek": 128596, "start": 1300.6000000000001, "end": 1306.76, "text": " of this video. Let's get to the meat and potatoes of this entire thing, which is the written down", "tokens": [51096, 295, 341, 960, 13, 961, 311, 483, 281, 264, 4615, 293, 11811, 295, 341, 2302, 551, 11, 597, 307, 264, 3720, 760, 51404], "temperature": 0.0, "avg_logprob": -0.11521987747727779, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.050315987318754196}, {"id": 267, "seek": 128596, "start": 1307.88, "end": 1315.4, "text": " talk. Now this is quite interesting. And this written down talk is effectively a written", "tokens": [51460, 751, 13, 823, 341, 307, 1596, 1880, 13, 400, 341, 3720, 760, 751, 307, 8659, 257, 3720, 51836], "temperature": 0.0, "avg_logprob": -0.11521987747727779, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.050315987318754196}, {"id": 268, "seek": 131540, "start": 1315.4, "end": 1320.76, "text": " discussion between Casey Meritori and Mr. Martin. And they are both discussing with it,", "tokens": [50364, 5017, 1296, 27369, 6124, 3029, 72, 293, 2221, 13, 9184, 13, 400, 436, 366, 1293, 10850, 365, 309, 11, 50632], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 269, "seek": 131540, "start": 1320.76, "end": 1325.0, "text": " and it's been split into different things. And I'll explain some points as I come along.", "tokens": [50632, 293, 309, 311, 668, 7472, 666, 819, 721, 13, 400, 286, 603, 2903, 512, 2793, 382, 286, 808, 2051, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 270, "seek": 131540, "start": 1325.0, "end": 1328.3600000000001, "text": " And so other little tricks. So first off, I'm just going to try and read it. I recommend", "tokens": [50844, 400, 370, 661, 707, 11733, 13, 407, 700, 766, 11, 286, 478, 445, 516, 281, 853, 293, 1401, 309, 13, 286, 2748, 51012], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 271, "seek": 131540, "start": 1328.3600000000001, "end": 1332.44, "text": " reading this again, links in the description below for everything. So Casey starts off with", "tokens": [51012, 3760, 341, 797, 11, 6123, 294, 264, 3855, 2507, 337, 1203, 13, 407, 27369, 3719, 766, 365, 51216], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 272, "seek": 131540, "start": 1332.44, "end": 1337.0, "text": " thank you taking the time. And he's just kind of asking questions like so most explanations", "tokens": [51216, 1309, 291, 1940, 264, 565, 13, 400, 415, 311, 445, 733, 295, 3365, 1651, 411, 370, 881, 28708, 51444], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 273, "seek": 131540, "start": 1337.0, "end": 1341.3200000000002, "text": " on clean code, I've seen that you include all things I mentioned in the video, like", "tokens": [51444, 322, 2541, 3089, 11, 286, 600, 1612, 300, 291, 4090, 439, 721, 286, 2835, 294, 264, 960, 11, 411, 51660], "temperature": 0.0, "avg_logprob": -0.13714280239371365, "compression_ratio": 1.7305194805194806, "no_speech_prob": 0.04441429674625397}, {"id": 274, "seek": 134132, "start": 1341.32, "end": 1346.04, "text": " preferring inheritance hierarchies to ifstapes, which means like I remember if we look back", "tokens": [50364, 4382, 2937, 32122, 35250, 530, 281, 498, 372, 569, 279, 11, 597, 1355, 411, 286, 1604, 498, 321, 574, 646, 50600], "temperature": 0.0, "avg_logprob": -0.23373287128952314, "compression_ratio": 1.59375, "no_speech_prob": 0.053403981029987335}, {"id": 275, "seek": 134132, "start": 1346.76, "end": 1351.24, "text": " to the the where was the guest I found completely lost it already now.", "tokens": [50636, 281, 264, 264, 689, 390, 264, 8341, 286, 1352, 2584, 2731, 309, 1217, 586, 13, 50860], "temperature": 0.0, "avg_logprob": -0.23373287128952314, "compression_ratio": 1.59375, "no_speech_prob": 0.053403981029987335}, {"id": 276, "seek": 134132, "start": 1353.32, "end": 1358.4399999999998, "text": " It was here, right? Here it was here. Yeah, here's the design rules.", "tokens": [50964, 467, 390, 510, 11, 558, 30, 1692, 309, 390, 510, 13, 865, 11, 510, 311, 264, 1715, 4474, 13, 51220], "temperature": 0.0, "avg_logprob": -0.23373287128952314, "compression_ratio": 1.59375, "no_speech_prob": 0.053403981029987335}, {"id": 277, "seek": 134132, "start": 1360.2, "end": 1364.4399999999998, "text": " Like that some some size, that's not Mr. Martin's himself. But yeah, but it sounds like", "tokens": [51308, 1743, 300, 512, 512, 2744, 11, 300, 311, 406, 2221, 13, 9184, 311, 3647, 13, 583, 1338, 11, 457, 309, 3263, 411, 51520], "temperature": 0.0, "avg_logprob": -0.23373287128952314, "compression_ratio": 1.59375, "no_speech_prob": 0.053403981029987335}, {"id": 278, "seek": 134132, "start": 1364.4399999999998, "end": 1367.6399999999999, "text": " you were surprised to hear me say that like all these different things he said is I look", "tokens": [51520, 291, 645, 6100, 281, 1568, 385, 584, 300, 411, 439, 613, 819, 721, 415, 848, 307, 286, 574, 51680], "temperature": 0.0, "avg_logprob": -0.23373287128952314, "compression_ratio": 1.59375, "no_speech_prob": 0.053403981029987335}, {"id": 279, "seek": 136764, "start": 1368.6000000000001, "end": 1374.2, "text": " Martin's going to disconnect. I'm not sure there is one. And interesting, he just says there is no", "tokens": [50412, 9184, 311, 516, 281, 14299, 13, 286, 478, 406, 988, 456, 307, 472, 13, 400, 1880, 11, 415, 445, 1619, 456, 307, 572, 50692], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 280, "seek": 136764, "start": 1374.2, "end": 1378.8400000000001, "text": " like disconnect. And Casey just asking questions about this. So Casey is asking a basic question", "tokens": [50692, 411, 14299, 13, 400, 27369, 445, 3365, 1651, 466, 341, 13, 407, 27369, 307, 3365, 257, 3875, 1168, 50924], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 281, "seek": 136764, "start": 1378.8400000000001, "end": 1382.44, "text": " here like look, we're both familiar with Visual Studio and Clang, and it would be a reason more", "tokens": [50924, 510, 411, 574, 11, 321, 434, 1293, 4963, 365, 23187, 13500, 293, 2033, 656, 11, 293, 309, 576, 312, 257, 1778, 544, 51104], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 282, "seek": 136764, "start": 1382.44, "end": 1386.92, "text": " that you're calling the back and uses it every day. I use these every day. I use LLVM and Visual", "tokens": [51104, 300, 291, 434, 5141, 264, 646, 293, 4960, 309, 633, 786, 13, 286, 764, 613, 633, 786, 13, 286, 764, 441, 43, 53, 44, 293, 23187, 51328], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 283, "seek": 136764, "start": 1386.92, "end": 1390.6000000000001, "text": " Studio every day. Are you calling these a vast majority of software that require less than", "tokens": [51328, 13500, 633, 786, 13, 2014, 291, 5141, 613, 257, 8369, 6286, 295, 4722, 300, 3651, 1570, 813, 51512], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 284, "seek": 136764, "start": 1390.6000000000001, "end": 1395.24, "text": " one things? And then he would go like, Oh, these are very specialized software, the only few in", "tokens": [51512, 472, 721, 30, 400, 550, 415, 576, 352, 411, 11, 876, 11, 613, 366, 588, 19813, 4722, 11, 264, 787, 1326, 294, 51744], "temperature": 0.0, "avg_logprob": -0.20853323332020934, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.021262694150209427}, {"id": 285, "seek": 139524, "start": 1395.24, "end": 1399.56, "text": " existence, and only a few that have actually become popular. And then talks about why this case", "tokens": [50364, 9123, 11, 293, 787, 257, 1326, 300, 362, 767, 1813, 3743, 13, 400, 550, 6686, 466, 983, 341, 1389, 50580], "temperature": 0.0, "avg_logprob": -0.15720521678095278, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.04071154445409775}, {"id": 286, "seek": 139524, "start": 1399.56, "end": 1403.72, "text": " and like actually talks about all these different things here, like, okay, speed is not necessarily", "tokens": [50580, 293, 411, 767, 6686, 466, 439, 613, 819, 721, 510, 11, 411, 11, 1392, 11, 3073, 307, 406, 4725, 50788], "temperature": 0.0, "avg_logprob": -0.15720521678095278, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.04071154445409775}, {"id": 287, "seek": 139524, "start": 1403.72, "end": 1408.44, "text": " an issue. But you can summarize, I'm trying to summarize it. But then the first trick he does,", "tokens": [50788, 364, 2734, 13, 583, 291, 393, 20858, 11, 286, 478, 1382, 281, 20858, 309, 13, 583, 550, 264, 700, 4282, 415, 775, 11, 51024], "temperature": 0.0, "avg_logprob": -0.15720521678095278, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.04071154445409775}, {"id": 288, "seek": 139524, "start": 1409.48, "end": 1414.44, "text": " this is going to be consistent throughout here, is the nanoseconds, microseconds and milliseconds", "tokens": [51076, 341, 307, 516, 281, 312, 8398, 3710, 510, 11, 307, 264, 14067, 541, 28750, 11, 3123, 37841, 28750, 293, 34184, 51324], "temperature": 0.0, "avg_logprob": -0.15720521678095278, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.04071154445409775}, {"id": 289, "seek": 139524, "start": 1414.44, "end": 1423.0, "text": " framing. I will tell you this. So what it will do here is making sure that passing code preserves", "tokens": [51324, 28971, 13, 286, 486, 980, 291, 341, 13, 407, 437, 309, 486, 360, 510, 307, 1455, 988, 300, 8437, 3089, 1183, 9054, 51752], "temperature": 0.0, "avg_logprob": -0.15720521678095278, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.04071154445409775}, {"id": 290, "seek": 142300, "start": 1423.08, "end": 1429.4, "text": " nanoseconds can have a big effect. Or he says, I assiduously counted microseconds when it mattered.", "tokens": [50368, 14067, 541, 28750, 393, 362, 257, 955, 1802, 13, 1610, 415, 1619, 11, 286, 1256, 327, 84, 5098, 20150, 3123, 37841, 28750, 562, 309, 44282, 13, 50684], "temperature": 0.0, "avg_logprob": -0.17972366511821747, "compression_ratio": 1.5596026490066226, "no_speech_prob": 0.015257388353347778}, {"id": 291, "seek": 142300, "start": 1429.4, "end": 1436.28, "text": " Nanoseconds were way beyond anything I could imagine. And so then Casey kind of questions,", "tokens": [50684, 18852, 541, 28750, 645, 636, 4399, 1340, 286, 727, 3811, 13, 400, 370, 550, 27369, 733, 295, 1651, 11, 51028], "temperature": 0.0, "avg_logprob": -0.17972366511821747, "compression_ratio": 1.5596026490066226, "no_speech_prob": 0.015257388353347778}, {"id": 292, "seek": 142300, "start": 1436.28, "end": 1441.32, "text": " is a case of like, it sounds like most software that Casey actually uses and so with myself would", "tokens": [51028, 307, 257, 1389, 295, 411, 11, 309, 3263, 411, 881, 4722, 300, 27369, 767, 4960, 293, 370, 365, 2059, 576, 51280], "temperature": 0.0, "avg_logprob": -0.17972366511821747, "compression_ratio": 1.5596026490066226, "no_speech_prob": 0.015257388353347778}, {"id": 293, "seek": 142300, "start": 1441.32, "end": 1445.64, "text": " when nanoseconds actually matter. In other words, Visual Studio, LLVM, GCC, Microsoft Word,", "tokens": [51280, 562, 14067, 541, 28750, 767, 1871, 13, 682, 661, 2283, 11, 23187, 13500, 11, 441, 43, 53, 44, 11, 460, 11717, 11, 8116, 8725, 11, 51496], "temperature": 0.0, "avg_logprob": -0.17972366511821747, "compression_ratio": 1.5596026490066226, "no_speech_prob": 0.015257388353347778}, {"id": 294, "seek": 142300, "start": 1445.64, "end": 1450.12, "text": " PowerPoint, Excel, Firefox, Chrome, FFMPEG, there's a type of that, but TensorFlow, Linux,", "tokens": [51496, 25584, 11, 19060, 11, 46613, 11, 15327, 11, 479, 37, 44, 5208, 38, 11, 456, 311, 257, 2010, 295, 300, 11, 457, 37624, 11, 18734, 11, 51720], "temperature": 0.0, "avg_logprob": -0.17972366511821747, "compression_ratio": 1.5596026490066226, "no_speech_prob": 0.015257388353347778}, {"id": 295, "seek": 145012, "start": 1450.1999999999998, "end": 1456.4399999999998, "text": " Windows, macOS, all of these. And Martin goes again, Mr. Martin goes like, oh, not exactly,", "tokens": [50368, 8591, 11, 7912, 4367, 11, 439, 295, 613, 13, 400, 9184, 1709, 797, 11, 2221, 13, 9184, 1709, 411, 11, 1954, 11, 406, 2293, 11, 50680], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 296, "seek": 145012, "start": 1456.4399999999998, "end": 1460.6, "text": " rather my experience abroad, and does all the stuff. And then talks about this other applications", "tokens": [50680, 2831, 452, 1752, 12637, 11, 293, 775, 439, 264, 1507, 13, 400, 550, 6686, 466, 341, 661, 5821, 50888], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 297, "seek": 145012, "start": 1460.6, "end": 1463.8, "text": " we have modules in the millisecond range. And he says, sort of these time ranges.", "tokens": [50888, 321, 362, 16679, 294, 264, 27940, 18882, 3613, 13, 400, 415, 1619, 11, 1333, 295, 613, 565, 22526, 13, 51048], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 298, "seek": 145012, "start": 1464.76, "end": 1469.9599999999998, "text": " It's very like, he's trying to get the reader, because he knows people reading this, to think", "tokens": [51096, 467, 311, 588, 411, 11, 415, 311, 1382, 281, 483, 264, 15149, 11, 570, 415, 3255, 561, 3760, 341, 11, 281, 519, 51356], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 299, "seek": 145012, "start": 1469.9599999999998, "end": 1473.6399999999999, "text": " about it, well, most problems are in there at ranges of milliseconds. So we can worry about", "tokens": [51356, 466, 309, 11, 731, 11, 881, 2740, 366, 294, 456, 412, 22526, 295, 34184, 13, 407, 321, 393, 3292, 466, 51540], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 300, "seek": 145012, "start": 1473.6399999999999, "end": 1477.4799999999998, "text": " nanoseconds. Most people aren't have to worry about the automizer nanoseconds. But it's like,", "tokens": [51540, 14067, 541, 28750, 13, 4534, 561, 3212, 380, 362, 281, 3292, 466, 264, 3553, 6545, 14067, 541, 28750, 13, 583, 309, 311, 411, 11, 51732], "temperature": 0.0, "avg_logprob": -0.20441838385353625, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.05422309786081314}, {"id": 301, "seek": 147748, "start": 1478.1200000000001, "end": 1483.48, "text": " you know, death by 1000 cuts, and 1000 milliseconds is a microsecond, 1000 microseconds is a", "tokens": [50396, 291, 458, 11, 2966, 538, 9714, 9992, 11, 293, 9714, 34184, 307, 257, 3123, 37841, 18882, 11, 9714, 3123, 37841, 28750, 307, 257, 50664], "temperature": 0.0, "avg_logprob": -0.14674814542134604, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.028089813888072968}, {"id": 302, "seek": 147748, "start": 1483.48, "end": 1489.88, "text": " millisecond. So if you do things 1000 times badly, and you can, you've now gotten to the other", "tokens": [50664, 27940, 18882, 13, 407, 498, 291, 360, 721, 9714, 1413, 13425, 11, 293, 291, 393, 11, 291, 600, 586, 5768, 281, 264, 661, 50984], "temperature": 0.0, "avg_logprob": -0.14674814542134604, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.028089813888072968}, {"id": 303, "seek": 147748, "start": 1489.88, "end": 1497.24, "text": " domain into the other module, as he was calling this, the time module. Okay, fine by me, not", "tokens": [50984, 9274, 666, 264, 661, 10088, 11, 382, 415, 390, 5141, 341, 11, 264, 565, 10088, 13, 1033, 11, 2489, 538, 385, 11, 406, 51352], "temperature": 0.0, "avg_logprob": -0.14674814542134604, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.028089813888072968}, {"id": 304, "seek": 147748, "start": 1497.24, "end": 1502.3600000000001, "text": " necessarily criticizing that way of thinking, but it's a very weird framing, which,", "tokens": [51352, 4725, 45474, 300, 636, 295, 1953, 11, 457, 309, 311, 257, 588, 3657, 28971, 11, 597, 11, 51608], "temperature": 0.0, "avg_logprob": -0.14674814542134604, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.028089813888072968}, {"id": 305, "seek": 150236, "start": 1502.9199999999998, "end": 1508.1999999999998, "text": " like, even if I read here, so for example, I'm currently working on an application in which", "tokens": [50392, 411, 11, 754, 498, 286, 1401, 510, 11, 370, 337, 1365, 11, 286, 478, 4362, 1364, 322, 364, 3861, 294, 597, 50656], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 306, "seek": 150236, "start": 1508.1999999999998, "end": 1512.6799999999998, "text": " the vast majority of modules work well at the millisecond level, but a require a 20 x per", "tokens": [50656, 264, 8369, 6286, 295, 16679, 589, 731, 412, 264, 27940, 18882, 1496, 11, 457, 257, 3651, 257, 945, 2031, 680, 50880], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 307, "seek": 150236, "start": 1512.6799999999998, "end": 1516.6, "text": " better performance. My strategy has been to write the millisecond modules in closure,", "tokens": [50880, 1101, 3389, 13, 1222, 5206, 575, 668, 281, 2464, 264, 27940, 18882, 16679, 294, 24653, 11, 51076], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 308, "seek": 150236, "start": 1516.6, "end": 1520.4399999999998, "text": " because while slow, which is very convenient language, the microsecond modules I wrote in", "tokens": [51076, 570, 1339, 2964, 11, 597, 307, 588, 10851, 2856, 11, 264, 3123, 37841, 18882, 16679, 286, 4114, 294, 51268], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 309, "seek": 150236, "start": 1520.4399999999998, "end": 1524.52, "text": " Java, which were much more faster, more convenient, far less convenient. So it's like, okay, so if", "tokens": [51268, 10745, 11, 597, 645, 709, 544, 4663, 11, 544, 10851, 11, 1400, 1570, 10851, 13, 407, 309, 311, 411, 11, 1392, 11, 370, 498, 51472], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 310, "seek": 150236, "start": 1524.52, "end": 1529.24, "text": " I use them all like Java, it's easier, it's much less convenient, but I can write faster code,", "tokens": [51472, 286, 764, 552, 439, 411, 10745, 11, 309, 311, 3571, 11, 309, 311, 709, 1570, 10851, 11, 457, 286, 393, 2464, 4663, 3089, 11, 51708], "temperature": 0.0, "avg_logprob": -0.18958061106883697, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.01836250349879265}, {"id": 311, "seek": 152924, "start": 1529.8, "end": 1533.72, "text": " compared to closure, which is, I write code quicker, but it's not going to be as", "tokens": [50392, 5347, 281, 24653, 11, 597, 307, 11, 286, 2464, 3089, 16255, 11, 457, 309, 311, 406, 516, 281, 312, 382, 50588], "temperature": 0.0, "avg_logprob": -0.23751778489961398, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.02675015851855278}, {"id": 312, "seek": 152924, "start": 1533.72, "end": 1537.24, "text": " powerful as that. And those bits, these mergers again, because closure and Java both work on the", "tokens": [50588, 4005, 382, 300, 13, 400, 729, 9239, 11, 613, 3551, 9458, 797, 11, 570, 24653, 293, 10745, 1293, 589, 322, 264, 50764], "temperature": 0.0, "avg_logprob": -0.23751778489961398, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.02675015851855278}, {"id": 313, "seek": 152924, "start": 1537.24, "end": 1543.24, "text": " JVM, so they can interact with each other pretty easily, ish. But he's just talking about the other", "tokens": [50764, 508, 53, 44, 11, 370, 436, 393, 4648, 365, 1184, 661, 1238, 3612, 11, 307, 71, 13, 583, 415, 311, 445, 1417, 466, 264, 661, 51064], "temperature": 0.0, "avg_logprob": -0.23751778489961398, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.02675015851855278}, {"id": 314, "seek": 152924, "start": 1543.24, "end": 1550.6, "text": " things here. Now, one thing I found interesting is this slash here. You'll see in a minute,", "tokens": [51064, 721, 510, 13, 823, 11, 472, 551, 286, 1352, 1880, 307, 341, 17330, 510, 13, 509, 603, 536, 294, 257, 3456, 11, 51432], "temperature": 0.0, "avg_logprob": -0.23751778489961398, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.02675015851855278}, {"id": 315, "seek": 152924, "start": 1551.56, "end": 1555.08, "text": " right, he only wrote a book, and he said, oh, I wrote a book on clean code, don't you know?", "tokens": [51480, 558, 11, 415, 787, 4114, 257, 1446, 11, 293, 415, 848, 11, 1954, 11, 286, 4114, 257, 1446, 322, 2541, 3089, 11, 500, 380, 291, 458, 30, 51656], "temperature": 0.0, "avg_logprob": -0.23751778489961398, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.02675015851855278}, {"id": 316, "seek": 155508, "start": 1555.6399999999999, "end": 1559.96, "text": " I've only focused on the millisecond side of the problem, not the nanosecond. It's like,", "tokens": [50392, 286, 600, 787, 5178, 322, 264, 27940, 18882, 1252, 295, 264, 1154, 11, 406, 264, 14067, 541, 18882, 13, 467, 311, 411, 11, 50608], "temperature": 0.0, "avg_logprob": -0.1504760876036527, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.02540205419063568}, {"id": 317, "seek": 155508, "start": 1559.96, "end": 1565.32, "text": " well, I'm not walking about the performance of the code anymore. But like Casey just goes", "tokens": [50608, 731, 11, 286, 478, 406, 4494, 466, 264, 3389, 295, 264, 3089, 3602, 13, 583, 411, 27369, 445, 1709, 50876], "temperature": 0.0, "avg_logprob": -0.1504760876036527, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.02540205419063568}, {"id": 318, "seek": 155508, "start": 1565.32, "end": 1569.56, "text": " town on the question. So Bob answers a very short question, milliseconds, of course.", "tokens": [50876, 3954, 322, 264, 1168, 13, 407, 6085, 6338, 257, 588, 2099, 1168, 11, 34184, 11, 295, 1164, 13, 51088], "temperature": 0.0, "avg_logprob": -0.1504760876036527, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.02540205419063568}, {"id": 319, "seek": 155508, "start": 1571.48, "end": 1576.52, "text": " And then he answers again. Now, he might be asking, wait, why is he answered twice?", "tokens": [51184, 400, 550, 415, 6338, 797, 13, 823, 11, 415, 1062, 312, 3365, 11, 1699, 11, 983, 307, 415, 10103, 6091, 30, 51436], "temperature": 0.0, "avg_logprob": -0.1504760876036527, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.02540205419063568}, {"id": 320, "seek": 155508, "start": 1576.52, "end": 1581.96, "text": " Well, he went back in history and added some code text. He rewrote history. Yeah.", "tokens": [51436, 1042, 11, 415, 1437, 646, 294, 2503, 293, 3869, 512, 3089, 2487, 13, 634, 319, 7449, 1370, 2503, 13, 865, 13, 51708], "temperature": 0.0, "avg_logprob": -0.1504760876036527, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.02540205419063568}, {"id": 321, "seek": 158196, "start": 1582.28, "end": 1588.44, "text": " I'll say no more. But yeah, he keeps going on about this, and it's very interesting. So now", "tokens": [50380, 286, 603, 584, 572, 544, 13, 583, 1338, 11, 415, 5965, 516, 322, 466, 341, 11, 293, 309, 311, 588, 1880, 13, 407, 586, 50688], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 322, "seek": 158196, "start": 1588.44, "end": 1592.68, "text": " here's another problem he kind of talks about. And he talks about the actual he says he's now", "tokens": [50688, 510, 311, 1071, 1154, 415, 733, 295, 6686, 466, 13, 400, 415, 6686, 466, 264, 3539, 415, 1619, 415, 311, 586, 50900], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 323, "seek": 158196, "start": 1592.68, "end": 1596.6000000000001, "text": " actually finished watching the video, because he didn't actually watch the video when he started", "tokens": [50900, 767, 4335, 1976, 264, 960, 11, 570, 415, 994, 380, 767, 1159, 264, 960, 562, 415, 1409, 51096], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 324, "seek": 158196, "start": 1596.6000000000001, "end": 1600.2, "text": " discussing with the only watch the first bit of it until I've got enough of this. It's like,", "tokens": [51096, 10850, 365, 264, 787, 1159, 264, 700, 857, 295, 309, 1826, 286, 600, 658, 1547, 295, 341, 13, 467, 311, 411, 11, 51276], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 325, "seek": 158196, "start": 1600.2, "end": 1604.8400000000001, "text": " you're not going to have discussion with someone you've not even watched the entirety of but you", "tokens": [51276, 291, 434, 406, 516, 281, 362, 5017, 365, 1580, 291, 600, 406, 754, 6337, 264, 31557, 295, 457, 291, 51508], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 326, "seek": 158196, "start": 1604.8400000000001, "end": 1609.48, "text": " think you're confident, you know, you can talk about it. I'm like, interesting. If you're that", "tokens": [51508, 519, 291, 434, 6679, 11, 291, 458, 11, 291, 393, 751, 466, 309, 13, 286, 478, 411, 11, 1880, 13, 759, 291, 434, 300, 51740], "temperature": 0.0, "avg_logprob": -0.14152774404972157, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.018251487985253334}, {"id": 327, "seek": 160948, "start": 1609.48, "end": 1615.16, "text": " confident, it usually means you're not actually talking about the thing itself.", "tokens": [50364, 6679, 11, 309, 2673, 1355, 291, 434, 406, 767, 1417, 466, 264, 551, 2564, 13, 50648], "temperature": 0.0, "avg_logprob": -0.2118705259550602, "compression_ratio": 1.6872586872586872, "no_speech_prob": 0.00801402609795332}, {"id": 328, "seek": 160948, "start": 1618.28, "end": 1623.4, "text": " Yeah. Yeah. But he says, you notice a nice little pattern. I love that basic form of", "tokens": [50804, 865, 13, 865, 13, 583, 415, 1619, 11, 291, 3449, 257, 1481, 707, 5102, 13, 286, 959, 300, 3875, 1254, 295, 51060], "temperature": 0.0, "avg_logprob": -0.2118705259550602, "compression_ratio": 1.6872586872586872, "no_speech_prob": 0.00801402609795332}, {"id": 329, "seek": 160948, "start": 1623.4, "end": 1627.24, "text": " the like some coefficient times the length times the width. And in those moments, I only think", "tokens": [51060, 264, 411, 512, 17619, 1413, 264, 4641, 1413, 264, 11402, 13, 400, 294, 729, 6065, 11, 286, 787, 519, 51252], "temperature": 0.0, "avg_logprob": -0.2118705259550602, "compression_ratio": 1.6872586872586872, "no_speech_prob": 0.00801402609795332}, {"id": 330, "seek": 160948, "start": 1627.24, "end": 1631.56, "text": " programs and mathematicians mathematicians can truly appreciate. It's like, oh, yeah, yeah,", "tokens": [51252, 4268, 293, 32811, 2567, 32811, 2567, 393, 4908, 4449, 13, 467, 311, 411, 11, 1954, 11, 1338, 11, 1338, 11, 51468], "temperature": 0.0, "avg_logprob": -0.2118705259550602, "compression_ratio": 1.6872586872586872, "no_speech_prob": 0.00801402609795332}, {"id": 331, "seek": 160948, "start": 1631.56, "end": 1637.64, "text": " like that was fine. Isn't that lovely? And that's fine, whatever. But Casey comes up,", "tokens": [51468, 411, 300, 390, 2489, 13, 6998, 380, 300, 7496, 30, 400, 300, 311, 2489, 11, 2035, 13, 583, 27369, 1487, 493, 11, 51772], "temperature": 0.0, "avg_logprob": -0.2118705259550602, "compression_ratio": 1.6872586872586872, "no_speech_prob": 0.00801402609795332}, {"id": 332, "seek": 163764, "start": 1637.64, "end": 1640.76, "text": " okay, that sounds great. I think we've gotten to the same page because he was actually talking about", "tokens": [50364, 1392, 11, 300, 3263, 869, 13, 286, 519, 321, 600, 5768, 281, 264, 912, 3028, 570, 415, 390, 767, 1417, 466, 50520], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 333, "seek": 163764, "start": 1641.48, "end": 1646.6000000000001, "text": " this, not this. Because he says, I've just finished watching it. So I'm going to add this bit back", "tokens": [50556, 341, 11, 406, 341, 13, 1436, 415, 1619, 11, 286, 600, 445, 4335, 1976, 309, 13, 407, 286, 478, 516, 281, 909, 341, 857, 646, 50812], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 334, "seek": 163764, "start": 1646.6000000000001, "end": 1653.64, "text": " in to make it split it up. Again, take it as you wish. What I'm trying to say is above paragraphs,", "tokens": [50812, 294, 281, 652, 309, 7472, 309, 493, 13, 3764, 11, 747, 309, 382, 291, 3172, 13, 708, 286, 478, 1382, 281, 584, 307, 3673, 48910, 11, 51164], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 335, "seek": 163764, "start": 1653.64, "end": 1657.3200000000002, "text": " above the box, and there's just like, look, Casey has read and looked a lot of it. Like,", "tokens": [51164, 3673, 264, 2424, 11, 293, 456, 311, 445, 411, 11, 574, 11, 27369, 575, 1401, 293, 2956, 257, 688, 295, 309, 13, 1743, 11, 51348], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 336, "seek": 163764, "start": 1657.3200000000002, "end": 1661.0, "text": " what you're talking about, he seems like these nanoseconds even matter, like everything seems", "tokens": [51348, 437, 291, 434, 1417, 466, 11, 415, 2544, 411, 613, 14067, 541, 28750, 754, 1871, 11, 411, 1203, 2544, 51532], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 337, "seek": 163764, "start": 1661.0, "end": 1665.96, "text": " to be nanoseconds modules, which he says, like, all this makes no sense. And then he again,", "tokens": [51532, 281, 312, 14067, 541, 28750, 16679, 11, 597, 415, 1619, 11, 411, 11, 439, 341, 1669, 572, 2020, 13, 400, 550, 415, 797, 11, 51780], "temperature": 0.0, "avg_logprob": -0.19113973231097453, "compression_ratio": 1.763076923076923, "no_speech_prob": 0.042008690536022186}, {"id": 338, "seek": 166596, "start": 1665.96, "end": 1669.56, "text": " he replies with, well, I'm one of the signatories of the agile manifesto who still believes to be", "tokens": [50364, 415, 42289, 365, 11, 731, 11, 286, 478, 472, 295, 264, 1465, 30077, 295, 264, 30072, 10067, 78, 567, 920, 12307, 281, 312, 50544], "temperature": 0.0, "avg_logprob": -0.1437864459928919, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.00937607605010271}, {"id": 339, "seek": 166596, "start": 1669.56, "end": 1677.88, "text": " a bit up front of architecture design. Okay, why bring that up? Sure, but fine. This is the", "tokens": [50544, 257, 857, 493, 1868, 295, 9482, 1715, 13, 1033, 11, 983, 1565, 300, 493, 30, 4894, 11, 457, 2489, 13, 639, 307, 264, 50960], "temperature": 0.0, "avg_logprob": -0.1437864459928919, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.00937607605010271}, {"id": 340, "seek": 166596, "start": 1677.88, "end": 1681.48, "text": " bottom line, of course, is that single factor analysis is always suboptimal. There's no one", "tokens": [50960, 2767, 1622, 11, 295, 1164, 11, 307, 300, 2167, 5952, 5215, 307, 1009, 1422, 5747, 10650, 13, 821, 311, 572, 472, 51140], "temperature": 0.0, "avg_logprob": -0.1437864459928919, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.00937607605010271}, {"id": 341, "seek": 166596, "start": 1681.48, "end": 1684.92, "text": " true way point. I've always made several times in clean code. And it's like,", "tokens": [51140, 2074, 636, 935, 13, 286, 600, 1009, 1027, 2940, 1413, 294, 2541, 3089, 13, 400, 309, 311, 411, 11, 51312], "temperature": 0.0, "avg_logprob": -0.1437864459928919, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.00937607605010271}, {"id": 342, "seek": 166596, "start": 1686.6000000000001, "end": 1690.28, "text": " but they may not be one true way, but you do kind of suggest there's a default you should go to.", "tokens": [51396, 457, 436, 815, 406, 312, 472, 2074, 636, 11, 457, 291, 360, 733, 295, 3402, 456, 311, 257, 7576, 291, 820, 352, 281, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1437864459928919, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.00937607605010271}, {"id": 343, "seek": 169028, "start": 1690.36, "end": 1701.24, "text": " And there are arguments for that. Okay. Casey has a lot of questions to ask already,", "tokens": [50368, 400, 456, 366, 12869, 337, 300, 13, 1033, 13, 27369, 575, 257, 688, 295, 1651, 281, 1029, 1217, 11, 50912], "temperature": 0.0, "avg_logprob": -0.2277665729365073, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.08969958126544952}, {"id": 344, "seek": 169028, "start": 1701.24, "end": 1704.92, "text": " all of this. Again, I recommend watching this. Now, Casey says here is like, I watched a multi", "tokens": [50912, 439, 295, 341, 13, 3764, 11, 286, 2748, 1976, 341, 13, 823, 11, 27369, 1619, 510, 307, 411, 11, 286, 6337, 257, 4825, 51096], "temperature": 0.0, "avg_logprob": -0.2277665729365073, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.08969958126544952}, {"id": 345, "seek": 169028, "start": 1704.92, "end": 1710.12, "text": " part series at six parts six, and it's like nine hours he watched, not once in that one second", "tokens": [51096, 644, 2638, 412, 2309, 3166, 2309, 11, 293, 309, 311, 411, 4949, 2496, 415, 6337, 11, 406, 1564, 294, 300, 472, 1150, 51356], "temperature": 0.0, "avg_logprob": -0.2277665729365073, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.08969958126544952}, {"id": 346, "seek": 169028, "start": 1710.12, "end": 1714.52, "text": " of it of that nine hours was in to go to get towards performance. And again, Mr. Martin says", "tokens": [51356, 295, 309, 295, 300, 4949, 2496, 390, 294, 281, 352, 281, 483, 3030, 3389, 13, 400, 797, 11, 2221, 13, 9184, 1619, 51576], "temperature": 0.0, "avg_logprob": -0.2277665729365073, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.08969958126544952}, {"id": 347, "seek": 169028, "start": 1714.52, "end": 1718.76, "text": " it's fair criticism, absolutely fine, no problems. But again, I'm just going to show you here,", "tokens": [51576, 309, 311, 3143, 15835, 11, 3122, 2489, 11, 572, 2740, 13, 583, 797, 11, 286, 478, 445, 516, 281, 855, 291, 510, 11, 51788], "temperature": 0.0, "avg_logprob": -0.2277665729365073, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.08969958126544952}, {"id": 348, "seek": 171876, "start": 1718.76, "end": 1722.44, "text": " it's like, yeah, so thank you for the nudge kind of thing. Like, oh, next time I'll do,", "tokens": [50364, 309, 311, 411, 11, 1338, 11, 370, 1309, 291, 337, 264, 297, 16032, 733, 295, 551, 13, 1743, 11, 1954, 11, 958, 565, 286, 603, 360, 11, 50548], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 349, "seek": 171876, "start": 1722.44, "end": 1726.76, "text": " I'll put a nudge in towards performance. It's like, been doing this for decades.", "tokens": [50548, 286, 603, 829, 257, 297, 16032, 294, 3030, 3389, 13, 467, 311, 411, 11, 668, 884, 341, 337, 7878, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 350, "seek": 171876, "start": 1729.8, "end": 1732.92, "text": " Hmm. Okay, so clearly you don't see, like, but like,", "tokens": [50916, 8239, 13, 1033, 11, 370, 4448, 291, 500, 380, 536, 11, 411, 11, 457, 411, 11, 51072], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 351, "seek": 171876, "start": 1734.36, "end": 1737.24, "text": " he's kind of butchering up trying to be polite or like, as you would, like you're trying to be a", "tokens": [51144, 415, 311, 733, 295, 457, 339, 1794, 493, 1382, 281, 312, 25171, 420, 411, 11, 382, 291, 576, 11, 411, 291, 434, 1382, 281, 312, 257, 51288], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 352, "seek": 171876, "start": 1737.24, "end": 1740.52, "text": " conversation light always be polite someone as well and try and be nice and kind to a certain", "tokens": [51288, 3761, 1442, 1009, 312, 25171, 1580, 382, 731, 293, 853, 293, 312, 1481, 293, 733, 281, 257, 1629, 51452], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 353, "seek": 171876, "start": 1740.52, "end": 1746.52, "text": " extent, maybe always nice, but kind at least kind. But yeah, it's always kind of those kind of things", "tokens": [51452, 8396, 11, 1310, 1009, 1481, 11, 457, 733, 412, 1935, 733, 13, 583, 1338, 11, 309, 311, 1009, 733, 295, 729, 733, 295, 721, 51752], "temperature": 0.0, "avg_logprob": -0.20009780094541352, "compression_ratio": 1.842293906810036, "no_speech_prob": 0.11210896819829941}, {"id": 354, "seek": 174652, "start": 1746.52, "end": 1752.44, "text": " and after some reflection, blah, blah, blah. I'm just trying to go through over this again.", "tokens": [50364, 293, 934, 512, 12914, 11, 12288, 11, 12288, 11, 12288, 13, 286, 478, 445, 1382, 281, 352, 807, 670, 341, 797, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 355, "seek": 174652, "start": 1753.32, "end": 1756.12, "text": " This is like, it's fine, not just all the conversation again, it's a lovely conversation", "tokens": [50704, 639, 307, 411, 11, 309, 311, 2489, 11, 406, 445, 439, 264, 3761, 797, 11, 309, 311, 257, 7496, 3761, 50844], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 356, "seek": 174652, "start": 1756.12, "end": 1758.92, "text": " between two people trying to be just being honest between each other, not being horrible.", "tokens": [50844, 1296, 732, 561, 1382, 281, 312, 445, 885, 3245, 1296, 1184, 661, 11, 406, 885, 9263, 13, 50984], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 357, "seek": 174652, "start": 1760.76, "end": 1764.84, "text": " Casey was also showing off this video, which if I believe it's correct, he was just kind of", "tokens": [51076, 27369, 390, 611, 4099, 766, 341, 960, 11, 597, 498, 286, 1697, 309, 311, 3006, 11, 415, 390, 445, 733, 295, 51280], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 358, "seek": 174652, "start": 1764.84, "end": 1769.08, "text": " they were just joking about how slow is right GitHub, literally intent of just slowing down", "tokens": [51280, 436, 645, 445, 17396, 466, 577, 2964, 307, 558, 23331, 11, 3736, 8446, 295, 445, 26958, 760, 51492], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 359, "seek": 174652, "start": 1769.08, "end": 1773.96, "text": " along with the paragraph God. And they actually found after a while, why this was the case.", "tokens": [51492, 2051, 365, 264, 18865, 1265, 13, 400, 436, 767, 1352, 934, 257, 1339, 11, 983, 341, 390, 264, 1389, 13, 51736], "temperature": 0.0, "avg_logprob": -0.2341803339601473, "compression_ratio": 1.7556270096463023, "no_speech_prob": 0.025018412619829178}, {"id": 360, "seek": 177396, "start": 1774.8400000000001, "end": 1780.1200000000001, "text": " The thing they found out was that it was the code was looking back to the beginning of the", "tokens": [50408, 440, 551, 436, 1352, 484, 390, 300, 309, 390, 264, 3089, 390, 1237, 646, 281, 264, 2863, 295, 264, 50672], "temperature": 0.0, "avg_logprob": -0.1884950207125756, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.018459606915712357}, {"id": 361, "seek": 177396, "start": 1780.1200000000001, "end": 1783.72, "text": " paragraph, looking for a colon, if it found a colon, and it was near the beginning,", "tokens": [50672, 18865, 11, 1237, 337, 257, 8255, 11, 498, 309, 1352, 257, 8255, 11, 293, 309, 390, 2651, 264, 2863, 11, 50852], "temperature": 0.0, "avg_logprob": -0.1884950207125756, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.018459606915712357}, {"id": 362, "seek": 177396, "start": 1784.3600000000001, "end": 1791.24, "text": " it was going to then expand this to be a emoji. That was what the bug that think the slowness was.", "tokens": [50884, 309, 390, 516, 281, 550, 5268, 341, 281, 312, 257, 31595, 13, 663, 390, 437, 264, 7426, 300, 519, 264, 1061, 648, 442, 390, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1884950207125756, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.018459606915712357}, {"id": 363, "seek": 177396, "start": 1791.24, "end": 1795.56, "text": " So if you just, as Bob made his joke, like, oh, if I just replace everything, the spaces with", "tokens": [51228, 407, 498, 291, 445, 11, 382, 6085, 1027, 702, 7647, 11, 411, 11, 1954, 11, 498, 286, 445, 7406, 1203, 11, 264, 7673, 365, 51444], "temperature": 0.0, "avg_logprob": -0.1884950207125756, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.018459606915712357}, {"id": 364, "seek": 177396, "start": 1795.56, "end": 1799.88, "text": " the colons is instant, there's no slowdown because it's found the colon, found it's not an emoji", "tokens": [51444, 264, 1173, 892, 307, 9836, 11, 456, 311, 572, 2964, 5093, 570, 309, 311, 1352, 264, 8255, 11, 1352, 309, 311, 406, 364, 31595, 51660], "temperature": 0.0, "avg_logprob": -0.1884950207125756, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.018459606915712357}, {"id": 365, "seek": 179988, "start": 1799.88, "end": 1804.2, "text": " and doesn't do the search anymore. And that's how slow, like, even though they were talking", "tokens": [50364, 293, 1177, 380, 360, 264, 3164, 3602, 13, 400, 300, 311, 577, 2964, 11, 411, 11, 754, 1673, 436, 645, 1417, 50580], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 366, "seek": 179988, "start": 1804.2, "end": 1807.96, "text": " about the complaining like slow codes, like, look how dumb this algorithm was in the web", "tokens": [50580, 466, 264, 20740, 411, 2964, 14211, 11, 411, 11, 574, 577, 10316, 341, 9284, 390, 294, 264, 3670, 50768], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 367, "seek": 179988, "start": 1807.96, "end": 1811.5600000000002, "text": " browser. And it's just trying to do this. Now, one little thing I found a bit weird,", "tokens": [50768, 11185, 13, 400, 309, 311, 445, 1382, 281, 360, 341, 13, 823, 11, 472, 707, 551, 286, 1352, 257, 857, 3657, 11, 50948], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 368, "seek": 179988, "start": 1811.5600000000002, "end": 1815.96, "text": " he says, I created this using going vi and I use this like replacement thing, because really,", "tokens": [50948, 415, 1619, 11, 286, 2942, 341, 1228, 516, 1932, 293, 286, 764, 341, 411, 14419, 551, 11, 570, 534, 11, 51168], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 369, "seek": 179988, "start": 1815.96, "end": 1823.5600000000002, "text": " I'm an old C hacker at heart. I'm like, what? What does that even mean? This just seems like a,", "tokens": [51168, 286, 478, 364, 1331, 383, 38155, 412, 1917, 13, 286, 478, 411, 11, 437, 30, 708, 775, 300, 754, 914, 30, 639, 445, 2544, 411, 257, 11, 51548], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 370, "seek": 179988, "start": 1823.5600000000002, "end": 1829.64, "text": " I'm an old C hacker at heart. I'm like, this has this is one, this is just, you're like vi or", "tokens": [51548, 286, 478, 364, 1331, 383, 38155, 412, 1917, 13, 286, 478, 411, 11, 341, 575, 341, 307, 472, 11, 341, 307, 445, 11, 291, 434, 411, 1932, 420, 51852], "temperature": 0.0, "avg_logprob": -0.202117919921875, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.599122941493988}, {"id": 371, "seek": 182964, "start": 1829.72, "end": 1834.92, "text": " vim or whatever you want to stuff. And then you've just done a regex for text replacement. And", "tokens": [50368, 371, 332, 420, 2035, 291, 528, 281, 1507, 13, 400, 550, 291, 600, 445, 1096, 257, 319, 432, 87, 337, 2487, 14419, 13, 400, 50628], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 372, "seek": 182964, "start": 1837.16, "end": 1841.16, "text": " this has nothing to do with C. I know what he's trying to say. Oh, it's just really low level", "tokens": [50740, 341, 575, 1825, 281, 360, 365, 383, 13, 286, 458, 437, 415, 311, 1382, 281, 584, 13, 876, 11, 309, 311, 445, 534, 2295, 1496, 50940], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 373, "seek": 182964, "start": 1841.16, "end": 1846.8400000000001, "text": " I'm doing all this. I'm like, what? Sorry, we just need one of those things like the what?", "tokens": [50940, 286, 478, 884, 439, 341, 13, 286, 478, 411, 11, 437, 30, 4919, 11, 321, 445, 643, 472, 295, 729, 721, 411, 264, 437, 30, 51224], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 374, "seek": 182964, "start": 1847.8000000000002, "end": 1851.4, "text": " Right, kind of bit interesting here. So then there's the again, recommend if you want to", "tokens": [51272, 1779, 11, 733, 295, 857, 1880, 510, 13, 407, 550, 456, 311, 264, 797, 11, 2748, 498, 291, 528, 281, 51452], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 375, "seek": 182964, "start": 1851.4, "end": 1853.8000000000002, "text": " read the links in the bar for all this. So you don't I'm not trying to read the", "tokens": [51452, 1401, 264, 6123, 294, 264, 2159, 337, 439, 341, 13, 407, 291, 500, 380, 286, 478, 406, 1382, 281, 1401, 264, 51572], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 376, "seek": 182964, "start": 1853.8000000000002, "end": 1858.6000000000001, "text": " descriptions here. I'm just trying to go over it. So now they figured out the things,", "tokens": [51572, 24406, 510, 13, 286, 478, 445, 1382, 281, 352, 670, 309, 13, 407, 586, 436, 8932, 484, 264, 721, 11, 51812], "temperature": 0.0, "avg_logprob": -0.23209624322468803, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.00954684242606163}, {"id": 377, "seek": 185860, "start": 1858.6799999999998, "end": 1862.1999999999998, "text": " the slowness of GitHub, they've gone gone back pivoting up back to this talking about the stuff", "tokens": [50368, 264, 1061, 648, 442, 295, 23331, 11, 436, 600, 2780, 2780, 646, 14538, 278, 493, 646, 281, 341, 1417, 466, 264, 1507, 50544], "temperature": 0.0, "avg_logprob": -0.14972898893267195, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.009829697199165821}, {"id": 378, "seek": 185860, "start": 1862.1999999999998, "end": 1868.12, "text": " about clean code again, capital C, capital trademarked, and explaining all that. And", "tokens": [50544, 466, 2541, 3089, 797, 11, 4238, 383, 11, 4238, 31361, 292, 11, 293, 13468, 439, 300, 13, 400, 50840], "temperature": 0.0, "avg_logprob": -0.14972898893267195, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.009829697199165821}, {"id": 379, "seek": 185860, "start": 1869.0, "end": 1872.6799999999998, "text": " some of the weird things like for instance, the descriptive names things, like,", "tokens": [50884, 512, 295, 264, 3657, 721, 411, 337, 5197, 11, 264, 42585, 5288, 721, 11, 411, 11, 51068], "temperature": 0.0, "avg_logprob": -0.14972898893267195, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.009829697199165821}, {"id": 380, "seek": 185860, "start": 1873.6399999999999, "end": 1877.9599999999998, "text": " I think everybody agrees with the descriptive names. This is not clean code exclusive to clean", "tokens": [51116, 286, 519, 2201, 26383, 365, 264, 42585, 5288, 13, 639, 307, 406, 2541, 3089, 13005, 281, 2541, 51332], "temperature": 0.0, "avg_logprob": -0.14972898893267195, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.009829697199165821}, {"id": 381, "seek": 185860, "start": 1877.9599999999998, "end": 1886.04, "text": " code tests. This is one where he's more of a test driven development, while cases more of a,", "tokens": [51332, 3089, 6921, 13, 639, 307, 472, 689, 415, 311, 544, 295, 257, 1500, 9555, 3250, 11, 1339, 3331, 544, 295, 257, 11, 51736], "temperature": 0.0, "avg_logprob": -0.14972898893267195, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.009829697199165821}, {"id": 382, "seek": 188604, "start": 1886.04, "end": 1890.6, "text": " it's more of a how they do frame it later on. In fact, I think Mr. Martin rephrases this quite", "tokens": [50364, 309, 311, 544, 295, 257, 577, 436, 360, 3920, 309, 1780, 322, 13, 682, 1186, 11, 286, 519, 2221, 13, 9184, 319, 44598, 1957, 341, 1596, 50592], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 383, "seek": 188604, "start": 1890.6, "end": 1896.36, "text": " well, that he prefers like why you should write a test if you don't see a reason not to. And cases", "tokens": [50592, 731, 11, 300, 415, 44334, 411, 983, 291, 820, 2464, 257, 1500, 498, 291, 500, 380, 536, 257, 1778, 406, 281, 13, 400, 3331, 50880], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 384, "seek": 188604, "start": 1896.36, "end": 1900.28, "text": " more in the camp, I write a test when I need a reason to kind of thing. And they're just", "tokens": [50880, 544, 294, 264, 2255, 11, 286, 2464, 257, 1500, 562, 286, 643, 257, 1778, 281, 733, 295, 551, 13, 400, 436, 434, 445, 51076], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 385, "seek": 188604, "start": 1900.28, "end": 1904.2, "text": " they're not bad. One's more test driven. One's more of a, like a more of a base of regression", "tokens": [51076, 436, 434, 406, 1578, 13, 1485, 311, 544, 1500, 9555, 13, 1485, 311, 544, 295, 257, 11, 411, 257, 544, 295, 257, 3096, 295, 24590, 51272], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 386, "seek": 188604, "start": 1904.2, "end": 1908.44, "text": " kind of thing or like other testing is more of a, I'll write tests when I need to because", "tokens": [51272, 733, 295, 551, 420, 411, 661, 4997, 307, 544, 295, 257, 11, 286, 603, 2464, 6921, 562, 286, 643, 281, 570, 51484], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 387, "seek": 188604, "start": 1908.44, "end": 1913.8, "text": " I do have tests in general, it's just not a like unit tests or general tests of everything", "tokens": [51484, 286, 360, 362, 6921, 294, 2674, 11, 309, 311, 445, 406, 257, 411, 4985, 6921, 420, 2674, 6921, 295, 1203, 51752], "temperature": 0.0, "avg_logprob": -0.19148964975394456, "compression_ratio": 1.9140893470790379, "no_speech_prob": 0.019163403660058975}, {"id": 388, "seek": 191380, "start": 1913.8, "end": 1918.84, "text": " code coverage and all that lot. It's a different thing. I'm not going to criticize test driven", "tokens": [50364, 3089, 9645, 293, 439, 300, 688, 13, 467, 311, 257, 819, 551, 13, 286, 478, 406, 516, 281, 31010, 1500, 9555, 50616], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 389, "seek": 191380, "start": 1918.84, "end": 1922.2, "text": " development because it's not necessarily bad in certain domains, but in certain other domains,", "tokens": [50616, 3250, 570, 309, 311, 406, 4725, 1578, 294, 1629, 25514, 11, 457, 294, 1629, 661, 25514, 11, 50784], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 390, "seek": 191380, "start": 1922.2, "end": 1928.2, "text": " it's kind of like not it seems like you're writing more tests than the actual code,", "tokens": [50784, 309, 311, 733, 295, 411, 406, 309, 2544, 411, 291, 434, 3579, 544, 6921, 813, 264, 3539, 3089, 11, 51084], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 391, "seek": 191380, "start": 1928.2, "end": 1933.96, "text": " which is not necessarily productive. But whatever, or useful and as many things in here,", "tokens": [51084, 597, 307, 406, 4725, 13304, 13, 583, 2035, 11, 420, 4420, 293, 382, 867, 721, 294, 510, 11, 51372], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 392, "seek": 191380, "start": 1935.0, "end": 1938.6, "text": " yes, it says like, look, cases, I do test as well. But then again, here's the difference he", "tokens": [51424, 2086, 11, 309, 1619, 411, 11, 574, 11, 3331, 11, 286, 360, 1500, 382, 731, 13, 583, 550, 797, 11, 510, 311, 264, 2649, 415, 51604], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 393, "seek": 191380, "start": 1938.6, "end": 1941.8, "text": " writes. So Mr. Martin says, I appreciate tests, unless there's a good reason to this and Mr.", "tokens": [51604, 13657, 13, 407, 2221, 13, 9184, 1619, 11, 286, 4449, 6921, 11, 5969, 456, 311, 257, 665, 1778, 281, 341, 293, 2221, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22613121645293965, "compression_ratio": 1.7420382165605095, "no_speech_prob": 0.04133886098861694}, {"id": 394, "seek": 194180, "start": 1941.8, "end": 1946.12, "text": " Martin and Casey write tests when there is no good reason to when there's a good reason to.", "tokens": [50364, 9184, 293, 27369, 2464, 6921, 562, 456, 307, 572, 665, 1778, 281, 562, 456, 311, 257, 665, 1778, 281, 13, 50580], "temperature": 0.0, "avg_logprob": -0.1555760417665754, "compression_ratio": 1.894736842105263, "no_speech_prob": 0.006721386685967445}, {"id": 395, "seek": 194180, "start": 1946.12, "end": 1951.1599999999999, "text": " So it's kind of a different distinction here. Now he actually starts quoting again from his", "tokens": [50580, 407, 309, 311, 733, 295, 257, 819, 16844, 510, 13, 823, 415, 767, 3719, 41552, 797, 490, 702, 50832], "temperature": 0.0, "avg_logprob": -0.1555760417665754, "compression_ratio": 1.894736842105263, "no_speech_prob": 0.006721386685967445}, {"id": 396, "seek": 194180, "start": 1951.1599999999999, "end": 1956.84, "text": " book talking about this and he and he kind of distinguishes between the operand primal and", "tokens": [50832, 1446, 1417, 466, 341, 293, 415, 293, 415, 733, 295, 11365, 16423, 1296, 264, 2208, 474, 2886, 304, 293, 51116], "temperature": 0.0, "avg_logprob": -0.1555760417665754, "compression_ratio": 1.894736842105263, "no_speech_prob": 0.006721386685967445}, {"id": 397, "seek": 194180, "start": 1958.36, "end": 1962.9199999999998, "text": " operation primal he's calling here. So it's kind of the difference between I'm going to call operands", "tokens": [51192, 6916, 2886, 304, 415, 311, 5141, 510, 13, 407, 309, 311, 733, 295, 264, 2649, 1296, 286, 478, 516, 281, 818, 2208, 2967, 51420], "temperature": 0.0, "avg_logprob": -0.1555760417665754, "compression_ratio": 1.894736842105263, "no_speech_prob": 0.006721386685967445}, {"id": 398, "seek": 194180, "start": 1964.04, "end": 1968.9199999999998, "text": " operands variance in this case, because it's a variance and operation. So they're not using", "tokens": [51476, 2208, 2967, 21977, 294, 341, 1389, 11, 570, 309, 311, 257, 21977, 293, 6916, 13, 407, 436, 434, 406, 1228, 51720], "temperature": 0.0, "avg_logprob": -0.1555760417665754, "compression_ratio": 1.894736842105263, "no_speech_prob": 0.006721386685967445}, {"id": 399, "seek": 196892, "start": 1968.92, "end": 1972.52, "text": " the same hoe gets a little confusing for me. So now they're kind of talking about the different", "tokens": [50364, 264, 912, 19709, 2170, 257, 707, 13181, 337, 385, 13, 407, 586, 436, 434, 733, 295, 1417, 466, 264, 819, 50544], "temperature": 0.0, "avg_logprob": -0.10707878444505775, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.016432788223028183}, {"id": 400, "seek": 196892, "start": 1972.52, "end": 1977.64, "text": " benefits of using one of these two things. And great stuff here. But then there's one other", "tokens": [50544, 5311, 295, 1228, 472, 295, 613, 732, 721, 13, 400, 869, 1507, 510, 13, 583, 550, 456, 311, 472, 661, 50800], "temperature": 0.0, "avg_logprob": -0.10707878444505775, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.016432788223028183}, {"id": 401, "seek": 196892, "start": 1977.64, "end": 1982.92, "text": " term that he brings up in here, which is dependencies. And he's using this in a very,", "tokens": [50800, 1433, 300, 415, 5607, 493, 294, 510, 11, 597, 307, 36606, 13, 400, 415, 311, 1228, 341, 294, 257, 588, 11, 51064], "temperature": 0.0, "avg_logprob": -0.10707878444505775, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.016432788223028183}, {"id": 402, "seek": 196892, "start": 1984.6000000000001, "end": 1990.76, "text": " not the way that most people would use the term dependencies. So a good example of this would", "tokens": [51148, 406, 264, 636, 300, 881, 561, 576, 764, 264, 1433, 36606, 13, 407, 257, 665, 1365, 295, 341, 576, 51456], "temperature": 0.0, "avg_logprob": -0.10707878444505775, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.016432788223028183}, {"id": 403, "seek": 196892, "start": 1990.76, "end": 1995.8000000000002, "text": " be is calling dependency inversion. So I'm just going to read right, I'm going to say what he's", "tokens": [51456, 312, 307, 5141, 33621, 43576, 13, 407, 286, 478, 445, 516, 281, 1401, 558, 11, 286, 478, 516, 281, 584, 437, 415, 311, 51708], "temperature": 0.0, "avg_logprob": -0.10707878444505775, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.016432788223028183}, {"id": 404, "seek": 199580, "start": 1995.8, "end": 2001.72, "text": " written because it's, I'm not going to paraphrase it very well if I don't, it says here, that would", "tokens": [50364, 3720, 570, 309, 311, 11, 286, 478, 406, 516, 281, 36992, 1703, 651, 309, 588, 731, 498, 286, 500, 380, 11, 309, 1619, 510, 11, 300, 576, 50660], "temperature": 0.0, "avg_logprob": -0.12942324186626233, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.021265825256705284}, {"id": 405, "seek": 199580, "start": 2001.72, "end": 2007.3999999999999, "text": " be the bottom line if there was one other thing, okay, about dependencies, the cases of switch", "tokens": [50660, 312, 264, 2767, 1622, 498, 456, 390, 472, 661, 551, 11, 1392, 11, 466, 36606, 11, 264, 3331, 295, 3679, 50944], "temperature": 0.0, "avg_logprob": -0.12942324186626233, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.021265825256705284}, {"id": 406, "seek": 199580, "start": 2007.3999999999999, "end": 2013.08, "text": " statements create an outbound network of dependencies towards lower level modules and", "tokens": [50944, 12363, 1884, 364, 484, 18767, 3209, 295, 36606, 3030, 3126, 1496, 16679, 293, 51228], "temperature": 0.0, "avg_logprob": -0.12942324186626233, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.021265825256705284}, {"id": 407, "seek": 199580, "start": 2013.08, "end": 2017.1599999999999, "text": " modules in this case, he's talking about like timing and such like that, that kind of module", "tokens": [51228, 16679, 294, 341, 1389, 11, 415, 311, 1417, 466, 411, 10822, 293, 1270, 411, 300, 11, 300, 733, 295, 10088, 51432], "temperature": 0.0, "avg_logprob": -0.12942324186626233, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.021265825256705284}, {"id": 408, "seek": 199580, "start": 2017.1599999999999, "end": 2022.76, "text": " in this context. Yeah, each case may call to out to these other modules making the fan out of the", "tokens": [51432, 294, 341, 4319, 13, 865, 11, 1184, 1389, 815, 818, 281, 484, 281, 613, 661, 16679, 1455, 264, 3429, 484, 295, 264, 51712], "temperature": 0.0, "avg_logprob": -0.12942324186626233, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.021265825256705284}, {"id": 409, "seek": 202276, "start": 2022.84, "end": 2027.48, "text": " switch statement very high. So he's trying to argue against switch statements and trying to say, look,", "tokens": [50368, 3679, 5629, 588, 1090, 13, 407, 415, 311, 1382, 281, 9695, 1970, 3679, 12363, 293, 1382, 281, 584, 11, 574, 11, 50600], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 410, "seek": 202276, "start": 2028.12, "end": 2031.8, "text": " if you go for the more polymorphic approach, like the inheritance base approach, we have like a v", "tokens": [50632, 498, 291, 352, 337, 264, 544, 6754, 76, 18191, 299, 3109, 11, 411, 264, 32122, 3096, 3109, 11, 321, 362, 411, 257, 371, 50816], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 411, "seek": 202276, "start": 2031.8, "end": 2036.36, "text": " table with sub typing, which is what I would class is inheritance to begin with any of the emergent", "tokens": [50816, 3199, 365, 1422, 18444, 11, 597, 307, 437, 286, 576, 1508, 307, 32122, 281, 1841, 365, 604, 295, 264, 4345, 6930, 51044], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 412, "seek": 202276, "start": 2036.36, "end": 2041.4, "text": " concept of those two things joined together. And he's saying this is going to be making it the fan", "tokens": [51044, 3410, 295, 729, 732, 721, 6869, 1214, 13, 400, 415, 311, 1566, 341, 307, 516, 281, 312, 1455, 309, 264, 3429, 51296], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 413, "seek": 202276, "start": 2041.4, "end": 2047.8799999999999, "text": " out of the switch and very high that this is going to be much bigger. Because it was caramel says", "tokens": [51296, 484, 295, 264, 3679, 293, 588, 1090, 300, 341, 307, 516, 281, 312, 709, 3801, 13, 1436, 309, 390, 22793, 1619, 51620], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 414, "seek": 202276, "start": 2047.8799999999999, "end": 2052.36, "text": " any change to one of these lower level modules can force the switch statement cases, which", "tokens": [51620, 604, 1319, 281, 472, 295, 613, 3126, 1496, 16679, 393, 3464, 264, 3679, 5629, 3331, 11, 597, 51844], "temperature": 0.0, "avg_logprob": -0.1974677348482436, "compression_ratio": 1.872611464968153, "no_speech_prob": 0.011410634964704514}, {"id": 415, "seek": 205236, "start": 2052.36, "end": 2058.28, "text": " statement the video, he's usually prefers the inheritance style not always, you'll get into", "tokens": [50364, 5629, 264, 960, 11, 415, 311, 2673, 44334, 264, 32122, 3758, 406, 1009, 11, 291, 603, 483, 666, 50660], "temperature": 0.0, "avg_logprob": -0.1571225753197303, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.007060972973704338}, {"id": 416, "seek": 205236, "start": 2058.28, "end": 2063.32, "text": " that can force switch statement and all higher level modules to depend on on that switch statement", "tokens": [50660, 300, 393, 3464, 3679, 5629, 293, 439, 2946, 1496, 16679, 281, 5672, 322, 322, 300, 3679, 5629, 50912], "temperature": 0.0, "avg_logprob": -0.1571225753197303, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.007060972973704338}, {"id": 417, "seek": 205236, "start": 2063.32, "end": 2069.0, "text": " to recompile and deploy it. That can be a very large cost. On the other hand, if one uses dynamic", "tokens": [50912, 281, 48000, 794, 293, 7274, 309, 13, 663, 393, 312, 257, 588, 2416, 2063, 13, 1282, 264, 661, 1011, 11, 498, 472, 4960, 8546, 51196], "temperature": 0.0, "avg_logprob": -0.1571225753197303, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.007060972973704338}, {"id": 418, "seek": 205236, "start": 2069.0, "end": 2073.48, "text": " polymorphism, object oriented, instead of a switch statement, then those compile time", "tokens": [51196, 6754, 76, 18191, 1434, 11, 2657, 21841, 11, 2602, 295, 257, 3679, 5629, 11, 550, 729, 31413, 565, 51420], "temperature": 0.0, "avg_logprob": -0.1571225753197303, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.007060972973704338}, {"id": 419, "seek": 205236, "start": 2073.48, "end": 2078.52, "text": " dependencies are inverted. The lower level modules become sub types that depends on the", "tokens": [51420, 36606, 366, 38969, 13, 440, 3126, 1496, 16679, 1813, 1422, 3467, 300, 5946, 322, 264, 51672], "temperature": 0.0, "avg_logprob": -0.1571225753197303, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.007060972973704338}, {"id": 420, "seek": 207852, "start": 2078.52, "end": 2082.92, "text": " high level base type. And the source code depends is then point in the opposite direction of the", "tokens": [50364, 1090, 1496, 3096, 2010, 13, 400, 264, 4009, 3089, 5946, 307, 550, 935, 294, 264, 6182, 3513, 295, 264, 50584], "temperature": 0.0, "avg_logprob": -0.15371063163688592, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.02477818913757801}, {"id": 421, "seek": 207852, "start": 2082.92, "end": 2089.32, "text": " control flow. This is dependency inversion. It prevents changes at the low level modules from", "tokens": [50584, 1969, 3095, 13, 639, 307, 33621, 43576, 13, 467, 22367, 2962, 412, 264, 2295, 1496, 16679, 490, 50904], "temperature": 0.0, "avg_logprob": -0.15371063163688592, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.02477818913757801}, {"id": 422, "seek": 207852, "start": 2089.32, "end": 2094.04, "text": " forcing a wave of recompilation redeployment from sweeping through the system towards high level", "tokens": [50904, 19030, 257, 5772, 295, 48000, 16067, 14328, 2384, 518, 490, 33285, 807, 264, 1185, 3030, 1090, 1496, 51140], "temperature": 0.0, "avg_logprob": -0.15371063163688592, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.02477818913757801}, {"id": 423, "seek": 207852, "start": 2094.04, "end": 2100.6, "text": " modules. So this is just a really weird confusing terminology is just made up in a weird way. I'm", "tokens": [51140, 16679, 13, 407, 341, 307, 445, 257, 534, 3657, 13181, 27575, 307, 445, 1027, 493, 294, 257, 3657, 636, 13, 286, 478, 51468], "temperature": 0.0, "avg_logprob": -0.15371063163688592, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.02477818913757801}, {"id": 424, "seek": 207852, "start": 2100.6, "end": 2105.56, "text": " saying who has made it like no, he kind of actually has. I tried searching for this and it's like,", "tokens": [51468, 1566, 567, 575, 1027, 309, 411, 572, 11, 415, 733, 295, 767, 575, 13, 286, 3031, 10808, 337, 341, 293, 309, 311, 411, 11, 51716], "temperature": 0.0, "avg_logprob": -0.15371063163688592, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.02477818913757801}, {"id": 425, "seek": 210556, "start": 2105.64, "end": 2109.72, "text": " it's not consistent what people mean by that term. And also, when people talk about dependencies,", "tokens": [50368, 309, 311, 406, 8398, 437, 561, 914, 538, 300, 1433, 13, 400, 611, 11, 562, 561, 751, 466, 36606, 11, 50572], "temperature": 0.0, "avg_logprob": -0.15558930130692217, "compression_ratio": 1.8669201520912548, "no_speech_prob": 0.07322093099355698}, {"id": 426, "seek": 210556, "start": 2109.72, "end": 2114.52, "text": " they usually mean like third party code, usually, or sometimes they talk about dependencies like,", "tokens": [50572, 436, 2673, 914, 411, 2636, 3595, 3089, 11, 2673, 11, 420, 2171, 436, 751, 466, 36606, 411, 11, 50812], "temperature": 0.0, "avg_logprob": -0.15558930130692217, "compression_ratio": 1.8669201520912548, "no_speech_prob": 0.07322093099355698}, {"id": 427, "seek": 210556, "start": 2114.52, "end": 2117.64, "text": " Hey, what does it very dependent on the things like all the bits in the thing like he's talking", "tokens": [50812, 1911, 11, 437, 775, 309, 588, 12334, 322, 264, 721, 411, 439, 264, 9239, 294, 264, 551, 411, 415, 311, 1417, 50968], "temperature": 0.0, "avg_logprob": -0.15558930130692217, "compression_ratio": 1.8669201520912548, "no_speech_prob": 0.07322093099355698}, {"id": 428, "seek": 210556, "start": 2117.64, "end": 2125.08, "text": " about modules, but that these concept of a module is much more like a class than a library. So it's", "tokens": [50968, 466, 16679, 11, 457, 300, 613, 3410, 295, 257, 10088, 307, 709, 544, 411, 257, 1508, 813, 257, 6405, 13, 407, 309, 311, 51340], "temperature": 0.0, "avg_logprob": -0.15558930130692217, "compression_ratio": 1.8669201520912548, "no_speech_prob": 0.07322093099355698}, {"id": 429, "seek": 210556, "start": 2125.08, "end": 2131.4, "text": " kind of a very more old fashioned approach before like libraries and packages and modules were more", "tokens": [51340, 733, 295, 257, 588, 544, 1331, 40646, 3109, 949, 411, 15148, 293, 17401, 293, 16679, 645, 544, 51656], "temperature": 0.0, "avg_logprob": -0.15558930130692217, "compression_ratio": 1.8669201520912548, "no_speech_prob": 0.07322093099355698}, {"id": 430, "seek": 213140, "start": 2131.4, "end": 2137.2400000000002, "text": " like standardized in other languages, obviously, but whatever. This is why I'm going to confuse", "tokens": [50364, 411, 31677, 294, 661, 8650, 11, 2745, 11, 457, 2035, 13, 639, 307, 983, 286, 478, 516, 281, 28584, 50656], "temperature": 0.0, "avg_logprob": -0.10702850200511792, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.030043693259358406}, {"id": 431, "seek": 213140, "start": 2137.2400000000002, "end": 2141.88, "text": " because the argument he's trying to make. And this is the thing I would personally try to understand", "tokens": [50656, 570, 264, 6770, 415, 311, 1382, 281, 652, 13, 400, 341, 307, 264, 551, 286, 576, 5665, 853, 281, 1223, 50888], "temperature": 0.0, "avg_logprob": -0.10702850200511792, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.030043693259358406}, {"id": 432, "seek": 213140, "start": 2141.88, "end": 2149.4, "text": " as well is that between the the variance and the operations, the switch statement is closed to the", "tokens": [50888, 382, 731, 307, 300, 1296, 264, 264, 21977, 293, 264, 7705, 11, 264, 3679, 5629, 307, 5395, 281, 264, 51264], "temperature": 0.0, "avg_logprob": -0.10702850200511792, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.030043693259358406}, {"id": 433, "seek": 213140, "start": 2149.4, "end": 2154.04, "text": " number of variants. But it's open to the number of operations. Like for instance, you can always", "tokens": [51264, 1230, 295, 21669, 13, 583, 309, 311, 1269, 281, 264, 1230, 295, 7705, 13, 1743, 337, 5197, 11, 291, 393, 1009, 51496], "temperature": 0.0, "avg_logprob": -0.10702850200511792, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.030043693259358406}, {"id": 434, "seek": 213140, "start": 2154.04, "end": 2159.0, "text": " add more operations really easily. You just add a new function with another switch statement inside", "tokens": [51496, 909, 544, 7705, 534, 3612, 13, 509, 445, 909, 257, 777, 2445, 365, 1071, 3679, 5629, 1854, 51744], "temperature": 0.0, "avg_logprob": -0.10702850200511792, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.030043693259358406}, {"id": 435, "seek": 215900, "start": 2159.0, "end": 2163.4, "text": " of it. And you've now added a new operation to all of these different variants. Yeah.", "tokens": [50364, 295, 309, 13, 400, 291, 600, 586, 3869, 257, 777, 6916, 281, 439, 295, 613, 819, 21669, 13, 865, 13, 50584], "temperature": 0.0, "avg_logprob": -0.15551651848687065, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.014409896917641163}, {"id": 436, "seek": 215900, "start": 2164.84, "end": 2173.48, "text": " Whilst the inheritance style is much more open to is more open to various operations this time. So", "tokens": [50656, 45790, 264, 32122, 3758, 307, 709, 544, 1269, 281, 307, 544, 1269, 281, 3683, 7705, 341, 565, 13, 407, 51088], "temperature": 0.0, "avg_logprob": -0.15551651848687065, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.014409896917641163}, {"id": 437, "seek": 215900, "start": 2173.48, "end": 2177.0, "text": " it's a closed set of operations, but open to numerous amount of different variants. This is", "tokens": [51088, 309, 311, 257, 5395, 992, 295, 7705, 11, 457, 1269, 281, 12546, 2372, 295, 819, 21669, 13, 639, 307, 51264], "temperature": 0.0, "avg_logprob": -0.15551651848687065, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.014409896917641163}, {"id": 438, "seek": 215900, "start": 2177.0, "end": 2181.0, "text": " the whole point you have a base class and variants like subtyping from it, the whole point you have", "tokens": [51264, 264, 1379, 935, 291, 362, 257, 3096, 1508, 293, 21669, 411, 1422, 874, 3381, 490, 309, 11, 264, 1379, 935, 291, 362, 51464], "temperature": 0.0, "avg_logprob": -0.15551651848687065, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.014409896917641163}, {"id": 439, "seek": 215900, "start": 2181.0, "end": 2186.04, "text": " subtypes or whatever, and it's more open that way. So it's a lot more useful to be doing.", "tokens": [51464, 1422, 874, 5190, 420, 2035, 11, 293, 309, 311, 544, 1269, 300, 636, 13, 407, 309, 311, 257, 688, 544, 4420, 281, 312, 884, 13, 51716], "temperature": 0.0, "avg_logprob": -0.15551651848687065, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.014409896917641163}, {"id": 440, "seek": 218604, "start": 2186.84, "end": 2196.2799999999997, "text": " If that makes any sense. Yeah, hopefully that's clear. So that's kind of the argument. Now my", "tokens": [50404, 759, 300, 1669, 604, 2020, 13, 865, 11, 4696, 300, 311, 1850, 13, 407, 300, 311, 733, 295, 264, 6770, 13, 823, 452, 50876], "temperature": 0.0, "avg_logprob": -0.14228596470572732, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.008541860617697239}, {"id": 441, "seek": 218604, "start": 2196.2799999999997, "end": 2202.36, "text": " point personal view is that which is getting talking in the thing here with the commentary", "tokens": [50876, 935, 2973, 1910, 307, 300, 597, 307, 1242, 1417, 294, 264, 551, 510, 365, 264, 23527, 51180], "temperature": 0.0, "avg_logprob": -0.14228596470572732, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.008541860617697239}, {"id": 442, "seek": 218604, "start": 2202.36, "end": 2205.56, "text": " search is that the most the time you actually have a close set of variants, and usually you", "tokens": [51180, 3164, 307, 300, 264, 881, 264, 565, 291, 767, 362, 257, 1998, 992, 295, 21669, 11, 293, 2673, 291, 51340], "temperature": 0.0, "avg_logprob": -0.14228596470572732, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.008541860617697239}, {"id": 443, "seek": 218604, "start": 2205.56, "end": 2209.64, "text": " want to add more operations in practice. So because if you've got a close set of variants,", "tokens": [51340, 528, 281, 909, 544, 7705, 294, 3124, 13, 407, 570, 498, 291, 600, 658, 257, 1998, 992, 295, 21669, 11, 51544], "temperature": 0.0, "avg_logprob": -0.14228596470572732, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.008541860617697239}, {"id": 444, "seek": 220964, "start": 2210.44, "end": 2215.72, "text": " why pretending as if it's completely open, which is what inheritance is for, it allows", "tokens": [50404, 983, 22106, 382, 498, 309, 311, 2584, 1269, 11, 597, 307, 437, 32122, 307, 337, 11, 309, 4045, 50668], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 445, "seek": 220964, "start": 2216.3599999999997, "end": 2220.92, "text": " everybody to add more variants, even if you don't have control of that capability, you just", "tokens": [50700, 2201, 281, 909, 544, 21669, 11, 754, 498, 291, 500, 380, 362, 1969, 295, 300, 13759, 11, 291, 445, 50928], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 446, "seek": 220964, "start": 2220.92, "end": 2225.56, "text": " extend to it and it's abstracted away. But most people within their own code base, like it's not", "tokens": [50928, 10101, 281, 309, 293, 309, 311, 12649, 292, 1314, 13, 583, 881, 561, 1951, 641, 1065, 3089, 3096, 11, 411, 309, 311, 406, 51160], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 447, "seek": 220964, "start": 2225.56, "end": 2231.48, "text": " going to be used by third party people ever, usually, pretty much isn't. So you in that case,", "tokens": [51160, 516, 281, 312, 1143, 538, 2636, 3595, 561, 1562, 11, 2673, 11, 1238, 709, 1943, 380, 13, 407, 291, 294, 300, 1389, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 448, "seek": 220964, "start": 2231.48, "end": 2235.56, "text": " it's very close set of opera, it's close at variance you have. And usually when you're", "tokens": [51456, 309, 311, 588, 1998, 992, 295, 22202, 11, 309, 311, 1998, 412, 21977, 291, 362, 13, 400, 2673, 562, 291, 434, 51660], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 449, "seek": 220964, "start": 2235.56, "end": 2237.96, "text": " modifying code, you actually want to add more operations. It's kind of like a", "tokens": [51660, 42626, 3089, 11, 291, 767, 528, 281, 909, 544, 7705, 13, 467, 311, 733, 295, 411, 257, 51780], "temperature": 0.0, "avg_logprob": -0.1710704662181713, "compression_ratio": 1.7225806451612904, "no_speech_prob": 0.08447577804327011}, {"id": 450, "seek": 223796, "start": 2238.76, "end": 2241.32, "text": " different thing. And they're solving different problems. You have to understand this. It's just", "tokens": [50404, 819, 551, 13, 400, 436, 434, 12606, 819, 2740, 13, 509, 362, 281, 1223, 341, 13, 467, 311, 445, 50532], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 451, "seek": 223796, "start": 2241.32, "end": 2248.68, "text": " that the weird oddity here is their argument is actually, you know, the, the, the inherent style", "tokens": [50532, 300, 264, 3657, 7401, 507, 510, 307, 641, 6770, 307, 767, 11, 291, 458, 11, 264, 11, 264, 11, 264, 26387, 3758, 50900], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 452, "seek": 223796, "start": 2248.68, "end": 2252.92, "text": " approach, which has all of the operations for each variant bundled with that variant,", "tokens": [50900, 3109, 11, 597, 575, 439, 295, 264, 7705, 337, 1184, 17501, 13882, 1493, 365, 300, 17501, 11, 51112], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 453, "seek": 223796, "start": 2253.96, "end": 2257.8, "text": " it's easier to manage. And the going on about like managing all these different", "tokens": [51164, 309, 311, 3571, 281, 3067, 13, 400, 264, 516, 322, 466, 411, 11642, 439, 613, 819, 51356], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 454, "seek": 223796, "start": 2257.8, "end": 2260.6, "text": " dependencies and talking about how many different places you have to deal with.", "tokens": [51356, 36606, 293, 1417, 466, 577, 867, 819, 3190, 291, 362, 281, 2028, 365, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 455, "seek": 223796, "start": 2260.6, "end": 2264.04, "text": " In case you just correctly point out like, Hey, it's just a different win in different ways,", "tokens": [51496, 682, 1389, 291, 445, 8944, 935, 484, 411, 11, 1911, 11, 309, 311, 445, 257, 819, 1942, 294, 819, 2098, 11, 51668], "temperature": 0.0, "avg_logprob": -0.1577020660648501, "compression_ratio": 1.824742268041237, "no_speech_prob": 0.028437089174985886}, {"id": 456, "seek": 226404, "start": 2264.12, "end": 2269.32, "text": " like this independence in version thing, is you're just trying to get complexity. And again,", "tokens": [50368, 411, 341, 14640, 294, 3037, 551, 11, 307, 291, 434, 445, 1382, 281, 483, 14024, 13, 400, 797, 11, 50628], "temperature": 0.0, "avg_logprob": -0.2880297785219939, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.034863926470279694}, {"id": 457, "seek": 226404, "start": 2269.32, "end": 2274.12, "text": " Mr. Martin says, yeah, like for every program composed of O operations and T types has complexity", "tokens": [50628, 2221, 13, 9184, 1619, 11, 1338, 11, 411, 337, 633, 1461, 18204, 295, 422, 7705, 293, 314, 3467, 575, 14024, 50868], "temperature": 0.0, "avg_logprob": -0.2880297785219939, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.034863926470279694}, {"id": 458, "seek": 226404, "start": 2274.12, "end": 2279.96, "text": " of O times T. If we use O, we can cruise T with minimal disruption to increasing O and vice versa.", "tokens": [50868, 295, 422, 1413, 314, 13, 759, 321, 764, 422, 11, 321, 393, 17754, 314, 365, 13206, 28751, 281, 5662, 422, 293, 11964, 25650, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2880297785219939, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.034863926470279694}, {"id": 459, "seek": 226404, "start": 2279.96, "end": 2283.08, "text": " Well, it's like the switch same as you have increased operations within disruption, but", "tokens": [51160, 1042, 11, 309, 311, 411, 264, 3679, 912, 382, 291, 362, 6505, 7705, 1951, 28751, 11, 457, 51316], "temperature": 0.0, "avg_logprob": -0.2880297785219939, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.034863926470279694}, {"id": 460, "seek": 226404, "start": 2284.04, "end": 2288.2, "text": " disrupts source code. Now, I don't think this is true. I don't think the disruption is actually", "tokens": [51364, 14124, 82, 4009, 3089, 13, 823, 11, 286, 500, 380, 519, 341, 307, 2074, 13, 286, 500, 380, 519, 264, 28751, 307, 767, 51572], "temperature": 0.0, "avg_logprob": -0.2880297785219939, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.034863926470279694}, {"id": 461, "seek": 228820, "start": 2288.2, "end": 2297.0, "text": " even equivalent because it's weird. I know we shouldn't be talking about much about this is", "tokens": [50364, 754, 10344, 570, 309, 311, 3657, 13, 286, 458, 321, 4659, 380, 312, 1417, 466, 709, 466, 341, 307, 50804], "temperature": 0.0, "avg_logprob": -0.18244505710289127, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.05575697869062424}, {"id": 462, "seek": 228820, "start": 2297.0, "end": 2304.2799999999997, "text": " not really clean code anymore, but it kind of is related to it. It's just the, but practically,", "tokens": [50804, 406, 534, 2541, 3089, 3602, 11, 457, 309, 733, 295, 307, 4077, 281, 309, 13, 467, 311, 445, 264, 11, 457, 15667, 11, 51168], "temperature": 0.0, "avg_logprob": -0.18244505710289127, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.05575697869062424}, {"id": 463, "seek": 228820, "start": 2304.2799999999997, "end": 2307.56, "text": " how would you know which one is more true the case? In my opinion, personal experience, we've", "tokens": [51168, 577, 576, 291, 458, 597, 472, 307, 544, 2074, 264, 1389, 30, 682, 452, 4800, 11, 2973, 1752, 11, 321, 600, 51332], "temperature": 0.0, "avg_logprob": -0.18244505710289127, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.05575697869062424}, {"id": 464, "seek": 228820, "start": 2307.56, "end": 2311.48, "text": " always had a close set of variants. Like if you want to have a new one, fine. But that variant", "tokens": [51332, 1009, 632, 257, 1998, 992, 295, 21669, 13, 1743, 498, 291, 528, 281, 362, 257, 777, 472, 11, 2489, 13, 583, 300, 17501, 51528], "temperature": 0.0, "avg_logprob": -0.18244505710289127, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.05575697869062424}, {"id": 465, "seek": 228820, "start": 2311.48, "end": 2315.96, "text": " doesn't really like, okay, we got updated every single place. Now I use Odin. So my switch statements", "tokens": [51528, 1177, 380, 534, 411, 11, 1392, 11, 321, 658, 10588, 633, 2167, 1081, 13, 823, 286, 764, 12210, 259, 13, 407, 452, 3679, 12363, 51752], "temperature": 0.0, "avg_logprob": -0.18244505710289127, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.05575697869062424}, {"id": 466, "seek": 231596, "start": 2315.96, "end": 2321.08, "text": " will yell at me if I'm missing a case by default. It says, Oh, you've not handled this particular", "tokens": [50364, 486, 20525, 412, 385, 498, 286, 478, 5361, 257, 1389, 538, 7576, 13, 467, 1619, 11, 876, 11, 291, 600, 406, 18033, 341, 1729, 50620], "temperature": 0.0, "avg_logprob": -0.12363849099226824, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.03987042233347893}, {"id": 467, "seek": 231596, "start": 2321.08, "end": 2325.64, "text": " operation for this particular variant, like in this particular case. And I just need to handle it.", "tokens": [50620, 6916, 337, 341, 1729, 17501, 11, 411, 294, 341, 1729, 1389, 13, 400, 286, 445, 643, 281, 4813, 309, 13, 50848], "temperature": 0.0, "avg_logprob": -0.12363849099226824, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.03987042233347893}, {"id": 468, "seek": 231596, "start": 2325.64, "end": 2329.64, "text": " Okay, great. That's just better. I know C and C++ and summer languages don't do this by default,", "tokens": [50848, 1033, 11, 869, 13, 663, 311, 445, 1101, 13, 286, 458, 383, 293, 383, 25472, 293, 4266, 8650, 500, 380, 360, 341, 538, 7576, 11, 51048], "temperature": 0.0, "avg_logprob": -0.12363849099226824, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.03987042233347893}, {"id": 469, "seek": 231596, "start": 2329.64, "end": 2333.64, "text": " but Odin does. So clearly, that's just a better language can solve those problems. It's not really", "tokens": [51048, 457, 12210, 259, 775, 13, 407, 4448, 11, 300, 311, 445, 257, 1101, 2856, 393, 5039, 729, 2740, 13, 467, 311, 406, 534, 51248], "temperature": 0.0, "avg_logprob": -0.12363849099226824, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.03987042233347893}, {"id": 470, "seek": 231596, "start": 2333.64, "end": 2339.88, "text": " a or better tooling in general. It's not really a inherent thing. It's just a tooling problem then.", "tokens": [51248, 257, 420, 1101, 46593, 294, 2674, 13, 467, 311, 406, 534, 257, 26387, 551, 13, 467, 311, 445, 257, 46593, 1154, 550, 13, 51560], "temperature": 0.0, "avg_logprob": -0.12363849099226824, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.03987042233347893}, {"id": 471, "seek": 233988, "start": 2340.6, "end": 2345.88, "text": " But then this is where it gets a bit weird. He starts breaking things down to source code", "tokens": [50400, 583, 550, 341, 307, 689, 309, 2170, 257, 857, 3657, 13, 634, 3719, 7697, 721, 760, 281, 4009, 3089, 50664], "temperature": 0.0, "avg_logprob": -0.1454110364301489, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.1418066769838333}, {"id": 472, "seek": 233988, "start": 2345.88, "end": 2351.32, "text": " management about runtime source code dependency inversion, and just make some terms up which", "tokens": [50664, 4592, 466, 34474, 4009, 3089, 33621, 43576, 11, 293, 445, 652, 512, 2115, 493, 597, 50936], "temperature": 0.0, "avg_logprob": -0.1454110364301489, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.1418066769838333}, {"id": 473, "seek": 233988, "start": 2351.32, "end": 2356.36, "text": " are not colloquially understood to be meant in that context. But again, it's the right a lot of text.", "tokens": [50936, 366, 406, 1263, 29826, 2270, 7320, 281, 312, 4140, 294, 300, 4319, 13, 583, 797, 11, 309, 311, 264, 558, 257, 688, 295, 2487, 13, 51188], "temperature": 0.0, "avg_logprob": -0.1454110364301489, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.1418066769838333}, {"id": 474, "seek": 233988, "start": 2358.52, "end": 2362.12, "text": " Try and make people understand how he thinks. And then Casey just write small amounts.", "tokens": [51296, 6526, 293, 652, 561, 1223, 577, 415, 7309, 13, 400, 550, 27369, 445, 2464, 1359, 11663, 13, 51476], "temperature": 0.0, "avg_logprob": -0.1454110364301489, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.1418066769838333}, {"id": 475, "seek": 233988, "start": 2363.0, "end": 2366.6800000000003, "text": " It's the it is a very big politician thing pad it out. Very good rhetoric. I mean,", "tokens": [51520, 467, 311, 264, 309, 307, 257, 588, 955, 26453, 551, 6887, 309, 484, 13, 4372, 665, 29604, 13, 286, 914, 11, 51704], "temperature": 0.0, "avg_logprob": -0.1454110364301489, "compression_ratio": 1.6272401433691757, "no_speech_prob": 0.1418066769838333}, {"id": 476, "seek": 236668, "start": 2366.68, "end": 2371.56, "text": " he's great at this. This is where I'm praising him, by the way. So again, read it for yourself,", "tokens": [50364, 415, 311, 869, 412, 341, 13, 639, 307, 689, 286, 478, 42941, 796, 11, 538, 264, 636, 13, 407, 797, 11, 1401, 309, 337, 1803, 11, 50608], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 477, "seek": 236668, "start": 2371.56, "end": 2375.0, "text": " make your own opinion. If you disagree with me tip can tell me in the comments below.", "tokens": [50608, 652, 428, 1065, 4800, 13, 759, 291, 14091, 365, 385, 4125, 393, 980, 385, 294, 264, 3053, 2507, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 478, "seek": 236668, "start": 2375.0, "end": 2378.6, "text": " Tell me where I'm wrong. Please tell me where I'm mischaracterizing me. If I'm being too harsh,", "tokens": [50780, 5115, 385, 689, 286, 478, 2085, 13, 2555, 980, 385, 689, 286, 478, 3346, 7374, 14125, 3319, 385, 13, 759, 286, 478, 885, 886, 14897, 11, 50960], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 479, "seek": 236668, "start": 2378.6, "end": 2384.6, "text": " if I'm not being harsh enough, if I might work, look, I'm not even it's fine. But he then it is fine,", "tokens": [50960, 498, 286, 478, 406, 885, 14897, 1547, 11, 498, 286, 1062, 589, 11, 574, 11, 286, 478, 406, 754, 309, 311, 2489, 13, 583, 415, 550, 309, 307, 2489, 11, 51260], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 480, "seek": 236668, "start": 2384.6, "end": 2387.3199999999997, "text": " like just just read it. He's talking about these different things here, like he's", "tokens": [51260, 411, 445, 445, 1401, 309, 13, 634, 311, 1417, 466, 613, 819, 721, 510, 11, 411, 415, 311, 51396], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 481, "seek": 236668, "start": 2387.3199999999997, "end": 2391.24, "text": " procedural, so it's itself statements, which statements, whatever. And he's calling this a", "tokens": [51396, 43951, 11, 370, 309, 311, 2564, 12363, 11, 597, 12363, 11, 2035, 13, 400, 415, 311, 5141, 341, 257, 51592], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 482, "seek": 236668, "start": 2391.24, "end": 2394.68, "text": " run time to high run time dependency, when actually, no, we're gonna make this compile time", "tokens": [51592, 1190, 565, 281, 1090, 1190, 565, 33621, 11, 562, 767, 11, 572, 11, 321, 434, 799, 652, 341, 31413, 565, 51764], "temperature": 0.0, "avg_logprob": -0.2686989663661211, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.15052203834056854}, {"id": 483, "seek": 239468, "start": 2394.68, "end": 2399.3999999999996, "text": " dispensary when it's on the type site. No, you just switched them around. They're both the same.", "tokens": [50364, 4920, 694, 822, 562, 309, 311, 322, 264, 2010, 3621, 13, 883, 11, 291, 445, 16858, 552, 926, 13, 814, 434, 1293, 264, 912, 13, 50600], "temperature": 0.0, "avg_logprob": -0.17748838258021085, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.007324654143303633}, {"id": 484, "seek": 239468, "start": 2400.12, "end": 2401.0, "text": " So yeah.", "tokens": [50636, 407, 1338, 13, 50680], "temperature": 0.0, "avg_logprob": -0.17748838258021085, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.007324654143303633}, {"id": 485, "seek": 239468, "start": 2407.3199999999997, "end": 2413.16, "text": " So one thing he brings up here, which I thought was interesting. And it through this bit, as well", "tokens": [50996, 407, 472, 551, 415, 5607, 493, 510, 11, 597, 286, 1194, 390, 1880, 13, 400, 309, 807, 341, 857, 11, 382, 731, 51288], "temperature": 0.0, "avg_logprob": -0.17748838258021085, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.007324654143303633}, {"id": 486, "seek": 239468, "start": 2413.16, "end": 2417.48, "text": " as the second part, these starts up, I'll explain why he does that in a minute. He brings up, I", "tokens": [51288, 382, 264, 1150, 644, 11, 613, 3719, 493, 11, 286, 603, 2903, 983, 415, 775, 300, 294, 257, 3456, 13, 634, 5607, 493, 11, 286, 51504], "temperature": 0.0, "avg_logprob": -0.17748838258021085, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.007324654143303633}, {"id": 487, "seek": 239468, "start": 2417.48, "end": 2424.2799999999997, "text": " would call the canonical case for inheritance. So the canonical case of inheritance is the", "tokens": [51504, 576, 818, 264, 46491, 1389, 337, 32122, 13, 407, 264, 46491, 1389, 295, 32122, 307, 264, 51844], "temperature": 0.0, "avg_logprob": -0.17748838258021085, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.007324654143303633}, {"id": 488, "seek": 242428, "start": 2424.28, "end": 2429.88, "text": " data stream. So sorry, if I've been a bit rambling all day, I'm just trying to understand it because", "tokens": [50364, 1412, 4309, 13, 407, 2597, 11, 498, 286, 600, 668, 257, 857, 367, 19391, 439, 786, 11, 286, 478, 445, 1382, 281, 1223, 309, 570, 50644], "temperature": 0.0, "avg_logprob": -0.13284642243188274, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.008309831842780113}, {"id": 489, "seek": 242428, "start": 2429.88, "end": 2435.4, "text": " it is weirdly flowing as well. Like the actual thing isn't like, it's a weird discussion. But so", "tokens": [50644, 309, 307, 48931, 13974, 382, 731, 13, 1743, 264, 3539, 551, 1943, 380, 411, 11, 309, 311, 257, 3657, 5017, 13, 583, 370, 50920], "temperature": 0.0, "avg_logprob": -0.13284642243188274, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.008309831842780113}, {"id": 490, "seek": 242428, "start": 2435.4, "end": 2439.0800000000004, "text": " I apologize for that and also apologize for my rambling as well. So hopefully that's okay. But", "tokens": [50920, 286, 12328, 337, 300, 293, 611, 12328, 337, 452, 367, 19391, 382, 731, 13, 407, 4696, 300, 311, 1392, 13, 583, 51104], "temperature": 0.0, "avg_logprob": -0.13284642243188274, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.008309831842780113}, {"id": 491, "seek": 242428, "start": 2439.0800000000004, "end": 2444.76, "text": " again, should be all clarified here. Here he does the canonical case for inheritance, which is", "tokens": [51104, 797, 11, 820, 312, 439, 47605, 510, 13, 1692, 415, 775, 264, 46491, 1389, 337, 32122, 11, 597, 307, 51388], "temperature": 0.0, "avg_logprob": -0.13284642243188274, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.008309831842780113}, {"id": 492, "seek": 242428, "start": 2444.76, "end": 2449.96, "text": " literally a stream, a data stream, a file or something like that, and explains that Oh, these", "tokens": [51388, 3736, 257, 4309, 11, 257, 1412, 4309, 11, 257, 3991, 420, 746, 411, 300, 11, 293, 13948, 300, 876, 11, 613, 51648], "temperature": 0.0, "avg_logprob": -0.13284642243188274, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.008309831842780113}, {"id": 493, "seek": 244996, "start": 2450.04, "end": 2454.84, "text": " have standard operations, a close set of operations like open, close, read, write, and seek. Again,", "tokens": [50368, 362, 3832, 7705, 11, 257, 1998, 992, 295, 7705, 411, 1269, 11, 1998, 11, 1401, 11, 2464, 11, 293, 8075, 13, 3764, 11, 50608], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 494, "seek": 244996, "start": 2454.84, "end": 2458.2, "text": " these are the five standard functions of the Unix IO driver. And again, these are very", "tokens": [50608, 613, 366, 264, 1732, 3832, 6828, 295, 264, 1156, 970, 39839, 6787, 13, 400, 797, 11, 613, 366, 588, 50776], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 495, "seek": 244996, "start": 2458.2, "end": 2463.7200000000003, "text": " standard functions on all operating systems. So they actually map really well to the", "tokens": [50776, 3832, 6828, 322, 439, 7447, 3652, 13, 407, 436, 767, 4471, 534, 731, 281, 264, 51052], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 496, "seek": 244996, "start": 2463.7200000000003, "end": 2467.88, "text": " inheritance style of doing things, the very dynamic polymorphism is he's referring it to here,", "tokens": [51052, 32122, 3758, 295, 884, 721, 11, 264, 588, 8546, 6754, 76, 18191, 1434, 307, 415, 311, 13761, 309, 281, 510, 11, 51260], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 497, "seek": 244996, "start": 2467.88, "end": 2475.64, "text": " which is, yeah, it's dynamic dispatch. Subtype polymorphism with v tables. Yeah,", "tokens": [51260, 597, 307, 11, 1338, 11, 309, 311, 8546, 36729, 13, 8511, 20467, 6754, 76, 18191, 1434, 365, 371, 8020, 13, 865, 11, 51648], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 498, "seek": 244996, "start": 2475.64, "end": 2479.32, "text": " that's what it is. But he's calling it dynamic polymorphism, which is not common term, but he's", "tokens": [51648, 300, 311, 437, 309, 307, 13, 583, 415, 311, 5141, 309, 8546, 6754, 76, 18191, 1434, 11, 597, 307, 406, 2689, 1433, 11, 457, 415, 311, 51832], "temperature": 0.0, "avg_logprob": -0.18527417864118303, "compression_ratio": 1.89198606271777, "no_speech_prob": 0.06941791623830795}, {"id": 499, "seek": 247932, "start": 2479.32, "end": 2484.6000000000004, "text": " whatever is using his own terminology as he needs. But it's saying like, okay, we've got a", "tokens": [50364, 2035, 307, 1228, 702, 1065, 27575, 382, 415, 2203, 13, 583, 309, 311, 1566, 411, 11, 1392, 11, 321, 600, 658, 257, 50628], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 500, "seek": 247932, "start": 2484.6000000000004, "end": 2487.6400000000003, "text": " closed set of operations, but we have so many different things like files could be anything,", "tokens": [50628, 5395, 992, 295, 7705, 11, 457, 321, 362, 370, 867, 819, 721, 411, 7098, 727, 312, 1340, 11, 50780], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 501, "seek": 247932, "start": 2487.6400000000003, "end": 2491.56, "text": " they could be a file, it could be a directory, they could be a piece of hardware on your device,", "tokens": [50780, 436, 727, 312, 257, 3991, 11, 309, 727, 312, 257, 21120, 11, 436, 727, 312, 257, 2522, 295, 8837, 322, 428, 4302, 11, 50976], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 502, "seek": 247932, "start": 2491.56, "end": 2495.7200000000003, "text": " they could be just a general socket, there could be anything. It's like, it's open to be whatever", "tokens": [50976, 436, 727, 312, 445, 257, 2674, 19741, 11, 456, 727, 312, 1340, 13, 467, 311, 411, 11, 309, 311, 1269, 281, 312, 2035, 51184], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 503, "seek": 247932, "start": 2495.7200000000003, "end": 2502.76, "text": " it could be. This is literally the canonical case. Why is the canonical case? Because operating", "tokens": [51184, 309, 727, 312, 13, 639, 307, 3736, 264, 46491, 1389, 13, 1545, 307, 264, 46491, 1389, 30, 1436, 7447, 51536], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 504, "seek": 247932, "start": 2502.76, "end": 2508.44, "text": " systems make these files an object. They are an object. That's what they have. Like they're an", "tokens": [51536, 3652, 652, 613, 7098, 364, 2657, 13, 814, 366, 364, 2657, 13, 663, 311, 437, 436, 362, 13, 1743, 436, 434, 364, 51820], "temperature": 0.0, "avg_logprob": -0.12986863589455896, "compression_ratio": 1.8966666666666667, "no_speech_prob": 0.015404700301587582}, {"id": 505, "seek": 250844, "start": 2508.44, "end": 2513.64, "text": " abstracted away opaque thing with a open like close interface as to what they are.", "tokens": [50364, 12649, 292, 1314, 42687, 551, 365, 257, 1269, 411, 1998, 9226, 382, 281, 437, 436, 366, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13736587192701258, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0016385517083108425}, {"id": 506, "seek": 250844, "start": 2515.7200000000003, "end": 2521.0, "text": " So he's trying to argue like this is what you meant to do. Now, there's a lovely lovely thing", "tokens": [50728, 407, 415, 311, 1382, 281, 9695, 411, 341, 307, 437, 291, 4140, 281, 360, 13, 823, 11, 456, 311, 257, 7496, 7496, 551, 50992], "temperature": 0.0, "avg_logprob": -0.13736587192701258, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0016385517083108425}, {"id": 507, "seek": 250844, "start": 2521.0, "end": 2524.28, "text": " here is saying like, well, this clearly has to be a thing. And that's why he's trying to get down", "tokens": [50992, 510, 307, 1566, 411, 11, 731, 11, 341, 4448, 575, 281, 312, 257, 551, 13, 400, 300, 311, 983, 415, 311, 1382, 281, 483, 760, 51156], "temperature": 0.0, "avg_logprob": -0.13736587192701258, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0016385517083108425}, {"id": 508, "seek": 250844, "start": 2524.28, "end": 2528.76, "text": " this route. He's trying to take the canonical case to show to Casey that hey, you need inheritance", "tokens": [51156, 341, 7955, 13, 634, 311, 1382, 281, 747, 264, 46491, 1389, 281, 855, 281, 27369, 300, 4177, 11, 291, 643, 32122, 51380], "temperature": 0.0, "avg_logprob": -0.13736587192701258, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0016385517083108425}, {"id": 509, "seek": 250844, "start": 2528.76, "end": 2533.2400000000002, "text": " sometimes. And this is the great way. He's completely forgot the conversation is talking", "tokens": [51380, 2171, 13, 400, 341, 307, 264, 869, 636, 13, 634, 311, 2584, 5298, 264, 3761, 307, 1417, 51604], "temperature": 0.0, "avg_logprob": -0.13736587192701258, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0016385517083108425}, {"id": 510, "seek": 253324, "start": 2533.24, "end": 2538.8399999999997, "text": " about clean code, which will bite him in the book later to use an American phrase later.", "tokens": [50364, 466, 2541, 3089, 11, 597, 486, 7988, 796, 294, 264, 1446, 1780, 281, 764, 364, 2665, 9535, 1780, 13, 50644], "temperature": 0.0, "avg_logprob": -0.1545599993537454, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.06385155022144318}, {"id": 511, "seek": 253324, "start": 2541.24, "end": 2546.6, "text": " But then there's one this weird thing he does here, where all of a sudden he talks about this", "tokens": [50764, 583, 550, 456, 311, 472, 341, 3657, 551, 415, 775, 510, 11, 689, 439, 295, 257, 3990, 415, 6686, 466, 341, 51032], "temperature": 0.0, "avg_logprob": -0.1545599993537454, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.06385155022144318}, {"id": 512, "seek": 253324, "start": 2546.6, "end": 2554.12, "text": " hypothetical compiler, which would be able to you could write in the in the oopy stage,", "tokens": [51032, 33053, 31958, 11, 597, 576, 312, 1075, 281, 291, 727, 2464, 294, 264, 294, 264, 277, 19680, 3233, 11, 51408], "temperature": 0.0, "avg_logprob": -0.1545599993537454, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.06385155022144318}, {"id": 513, "seek": 253324, "start": 2554.12, "end": 2560.2799999999997, "text": " like an inheritance style, and then completely the compiler would magically make this be a", "tokens": [51408, 411, 364, 32122, 3758, 11, 293, 550, 2584, 264, 31958, 576, 39763, 652, 341, 312, 257, 51716], "temperature": 0.0, "avg_logprob": -0.1545599993537454, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.06385155022144318}, {"id": 514, "seek": 256028, "start": 2560.28, "end": 2563.4, "text": " switch statement if necessary, which is kind of interesting because it's like,", "tokens": [50364, 3679, 5629, 498, 4818, 11, 597, 307, 733, 295, 1880, 570, 309, 311, 411, 11, 50520], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 515, "seek": 256028, "start": 2565.0, "end": 2568.1200000000003, "text": " what what benefits would you get from that? Because it seems to be now a textual benefit.", "tokens": [50600, 437, 437, 5311, 576, 291, 483, 490, 300, 30, 1436, 309, 2544, 281, 312, 586, 257, 2487, 901, 5121, 13, 50756], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 516, "seek": 256028, "start": 2568.1200000000003, "end": 2571.0800000000004, "text": " It's like, you're talking about, oh, it's all clumped together. A new variant or you know,", "tokens": [50756, 467, 311, 411, 11, 291, 434, 1417, 466, 11, 1954, 11, 309, 311, 439, 596, 1420, 292, 1214, 13, 316, 777, 17501, 420, 291, 458, 11, 50904], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 517, "seek": 256028, "start": 2571.0800000000004, "end": 2576.36, "text": " like, but you've some weird things. He just says it's just a really weird hypothetical", "tokens": [50904, 411, 11, 457, 291, 600, 512, 3657, 721, 13, 634, 445, 1619, 309, 311, 445, 257, 534, 3657, 33053, 51168], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 518, "seek": 256028, "start": 2576.36, "end": 2580.92, "text": " scenario just kind of goes into. And they go on for this for a little while. And Casey's like,", "tokens": [51168, 9005, 445, 733, 295, 1709, 666, 13, 400, 436, 352, 322, 337, 341, 337, 257, 707, 1339, 13, 400, 27369, 311, 411, 11, 51396], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 519, "seek": 256028, "start": 2580.92, "end": 2583.6400000000003, "text": " I don't understand what you're talking about. Like this doesn't make no difference,", "tokens": [51396, 286, 500, 380, 1223, 437, 291, 434, 1417, 466, 13, 1743, 341, 1177, 380, 652, 572, 2649, 11, 51532], "temperature": 0.0, "avg_logprob": -0.21157441315827547, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.018223823979496956}, {"id": 520, "seek": 258364, "start": 2584.6, "end": 2590.2799999999997, "text": " even with this hypothetical case. So Casey goes on a bit more further here, just mentoring", "tokens": [50412, 754, 365, 341, 33053, 1389, 13, 407, 27369, 1709, 322, 257, 857, 544, 3052, 510, 11, 445, 30257, 50696], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 521, "seek": 258364, "start": 2590.2799999999997, "end": 2594.7599999999998, "text": " different things. And talk, I try to get what the benefit of dependency inversion is anyway,", "tokens": [50696, 819, 721, 13, 400, 751, 11, 286, 853, 281, 483, 437, 264, 5121, 295, 33621, 43576, 307, 4033, 11, 50920], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 522, "seek": 258364, "start": 2594.7599999999998, "end": 2599.8799999999997, "text": " and to begin with. And the go on about this, like, look, you've got a clothes interface with opaque", "tokens": [50920, 293, 281, 1841, 365, 13, 400, 264, 352, 322, 466, 341, 11, 411, 11, 574, 11, 291, 600, 658, 257, 5534, 9226, 365, 42687, 51176], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 523, "seek": 258364, "start": 2599.8799999999997, "end": 2604.6, "text": " stuff, and different ways of dealing with it. And then we talk about this payroll thing that", "tokens": [51176, 1507, 11, 293, 819, 2098, 295, 6260, 365, 309, 13, 400, 550, 321, 751, 466, 341, 36873, 551, 300, 51412], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 524, "seek": 258364, "start": 2604.6, "end": 2607.8799999999997, "text": " they do all these different things. I recommend reading it. But it is going to be this.", "tokens": [51412, 436, 360, 439, 613, 819, 721, 13, 286, 2748, 3760, 309, 13, 583, 309, 307, 516, 281, 312, 341, 13, 51576], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 525, "seek": 258364, "start": 2609.8799999999997, "end": 2613.56, "text": " Like this is an oopy thing, obviously, you've just defined it to be because it is is defined", "tokens": [51676, 1743, 341, 307, 364, 277, 19680, 551, 11, 2745, 11, 291, 600, 445, 7642, 309, 281, 312, 570, 309, 307, 307, 7642, 51860], "temperature": 0.0, "avg_logprob": -0.20927908841301412, "compression_ratio": 1.7909967845659165, "no_speech_prob": 0.1092824712395668}, {"id": 526, "seek": 261356, "start": 2613.64, "end": 2621.24, "text": " to be oopy, sorry. Yeah, okay. Yeah, yeah, yeah, yeah. But again, Casey also kind of says it", "tokens": [50368, 281, 312, 277, 19680, 11, 2597, 13, 865, 11, 1392, 13, 865, 11, 1338, 11, 1338, 11, 1338, 13, 583, 797, 11, 27369, 611, 733, 295, 1619, 309, 50748], "temperature": 0.0, "avg_logprob": -0.1872606724500656, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.011614449322223663}, {"id": 527, "seek": 261356, "start": 2621.24, "end": 2625.08, "text": " could just be sound line functions. There's no reason, whatever, whatever, that's not a problem.", "tokens": [50748, 727, 445, 312, 1626, 1622, 6828, 13, 821, 311, 572, 1778, 11, 2035, 11, 2035, 11, 300, 311, 406, 257, 1154, 13, 50940], "temperature": 0.0, "avg_logprob": -0.1872606724500656, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.011614449322223663}, {"id": 528, "seek": 261356, "start": 2625.08, "end": 2628.52, "text": " Where am I looking for now? I'm sorry, I'm just trying to skip through this because it just goes", "tokens": [50940, 2305, 669, 286, 1237, 337, 586, 30, 286, 478, 2597, 11, 286, 478, 445, 1382, 281, 10023, 807, 341, 570, 309, 445, 1709, 51112], "temperature": 0.0, "avg_logprob": -0.1872606724500656, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.011614449322223663}, {"id": 529, "seek": 261356, "start": 2628.52, "end": 2636.2799999999997, "text": " on for quite a while. Okay, so Casey says that hypothetically, you could just not do this and", "tokens": [51112, 322, 337, 1596, 257, 1339, 13, 1033, 11, 370, 27369, 1619, 300, 24371, 22652, 11, 291, 727, 445, 406, 360, 341, 293, 51500], "temperature": 0.0, "avg_logprob": -0.1872606724500656, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.011614449322223663}, {"id": 530, "seek": 261356, "start": 2636.2799999999997, "end": 2640.84, "text": " have it just a union. Because in the example that Casey does when he does the union, the shapes", "tokens": [51500, 362, 309, 445, 257, 11671, 13, 1436, 294, 264, 1365, 300, 27369, 775, 562, 415, 775, 264, 11671, 11, 264, 10854, 51728], "temperature": 0.0, "avg_logprob": -0.1872606724500656, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.011614449322223663}, {"id": 531, "seek": 264084, "start": 2640.84, "end": 2646.6000000000004, "text": " example in the video is, is this actually a union? It's what I would call a fat struct union or an", "tokens": [50364, 1365, 294, 264, 960, 307, 11, 307, 341, 767, 257, 11671, 30, 467, 311, 437, 286, 576, 818, 257, 4046, 6594, 11671, 420, 364, 50652], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 532, "seek": 264084, "start": 2646.6000000000004, "end": 2649.88, "text": " open open union where it has a variant and then just open fields. So it's kind of like a table", "tokens": [50652, 1269, 1269, 11671, 689, 309, 575, 257, 17501, 293, 550, 445, 1269, 7909, 13, 407, 309, 311, 733, 295, 411, 257, 3199, 50816], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 533, "seek": 264084, "start": 2649.88, "end": 2657.2400000000002, "text": " like thing, a fat struct is a term that's Ryan Flurry kind of popularized. And it's kind of", "tokens": [50816, 411, 551, 11, 257, 4046, 6594, 307, 257, 1433, 300, 311, 9116, 3235, 30614, 733, 295, 3743, 1602, 13, 400, 309, 311, 733, 295, 51184], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 534, "seek": 264084, "start": 2657.2400000000002, "end": 2661.7200000000003, "text": " just like, here's a table of data, all the fields available. But hey, how you can just switch on", "tokens": [51184, 445, 411, 11, 510, 311, 257, 3199, 295, 1412, 11, 439, 264, 7909, 2435, 13, 583, 4177, 11, 577, 291, 393, 445, 3679, 322, 51408], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 535, "seek": 264084, "start": 2661.7200000000003, "end": 2665.1600000000003, "text": " it like all this and just do whatever you need to do and just access the data when necessary.", "tokens": [51408, 309, 411, 439, 341, 293, 445, 360, 2035, 291, 643, 281, 360, 293, 445, 2105, 264, 1412, 562, 4818, 13, 51580], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 536, "seek": 264084, "start": 2665.1600000000003, "end": 2669.0, "text": " In case you're saying, look, hypothetically, you could do this, you could just have a file type", "tokens": [51580, 682, 1389, 291, 434, 1566, 11, 574, 11, 24371, 22652, 11, 291, 727, 360, 341, 11, 291, 727, 445, 362, 257, 3991, 2010, 51772], "temperature": 0.0, "avg_logprob": -0.15198285690206564, "compression_ratio": 1.8101265822784811, "no_speech_prob": 0.039518196135759354}, {"id": 537, "seek": 266900, "start": 2669.0, "end": 2673.4, "text": " with all the data that responds to this in this union and deal with it. Because in practice,", "tokens": [50364, 365, 439, 264, 1412, 300, 27331, 281, 341, 294, 341, 11671, 293, 2028, 365, 309, 13, 1436, 294, 3124, 11, 50584], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 538, "seek": 266900, "start": 2673.4, "end": 2677.72, "text": " there's actually only a certain set of files you could have, you could even have the general case", "tokens": [50584, 456, 311, 767, 787, 257, 1629, 992, 295, 7098, 291, 727, 362, 11, 291, 727, 754, 362, 264, 2674, 1389, 50800], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 539, "seek": 266900, "start": 2677.72, "end": 2682.12, "text": " where it's, it, it will be like a V table. Sometimes it won't use a V tail, but you can always", "tokens": [50800, 689, 309, 311, 11, 309, 11, 309, 486, 312, 411, 257, 691, 3199, 13, 4803, 309, 1582, 380, 764, 257, 691, 6838, 11, 457, 291, 393, 1009, 51020], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 540, "seek": 266900, "start": 2682.12, "end": 2687.08, "text": " optimize off that. And there's many different things he's discussing here and such. And he's", "tokens": [51020, 19719, 766, 300, 13, 400, 456, 311, 867, 819, 721, 415, 311, 10850, 510, 293, 1270, 13, 400, 415, 311, 51268], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 541, "seek": 266900, "start": 2687.08, "end": 2691.72, "text": " talking about the union case. Now, Martin, Mr. Martin goes here and says, look, it seems like", "tokens": [51268, 1417, 466, 264, 11671, 1389, 13, 823, 11, 9184, 11, 2221, 13, 9184, 1709, 510, 293, 1619, 11, 574, 11, 309, 2544, 411, 51500], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 542, "seek": 266900, "start": 2691.72, "end": 2696.52, "text": " come on, come on, wild up at the agreement on just about everything other than per individual", "tokens": [51500, 808, 322, 11, 808, 322, 11, 4868, 493, 412, 264, 8106, 322, 445, 466, 1203, 661, 813, 680, 2609, 51740], "temperature": 0.0, "avg_logprob": -0.16243951970880682, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.017317581921815872}, {"id": 543, "seek": 269652, "start": 2696.6, "end": 2701.48, "text": " preference. And it's like, no, he's trying to say, look, but we don't disagree. It's like,", "tokens": [50368, 17502, 13, 400, 309, 311, 411, 11, 572, 11, 415, 311, 1382, 281, 584, 11, 574, 11, 457, 321, 500, 380, 14091, 13, 467, 311, 411, 11, 50612], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 544, "seek": 269652, "start": 2701.48, "end": 2705.48, "text": " actually, why are you having this conversation? If you don't disagree, you clearly do actually.", "tokens": [50612, 767, 11, 983, 366, 291, 1419, 341, 3761, 30, 759, 291, 500, 380, 14091, 11, 291, 4448, 360, 767, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 545, "seek": 269652, "start": 2705.48, "end": 2710.6, "text": " And you'll show this later on in part two of this written document. And he says,", "tokens": [50812, 400, 291, 603, 855, 341, 1780, 322, 294, 644, 732, 295, 341, 3720, 4166, 13, 400, 415, 1619, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 546, "seek": 269652, "start": 2710.6, "end": 2713.32, "text": " thank you for the union collaboration. Now I understand what you're talking about unions,", "tokens": [51068, 1309, 291, 337, 264, 11671, 9363, 13, 823, 286, 1223, 437, 291, 434, 1417, 466, 24914, 11, 51204], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 547, "seek": 269652, "start": 2713.32, "end": 2718.28, "text": " which is like, okay. And he says, I'll quibble you a bit on the difference between operand", "tokens": [51204, 597, 307, 411, 11, 1392, 13, 400, 415, 1619, 11, 286, 603, 421, 897, 638, 291, 257, 857, 322, 264, 2649, 1296, 2208, 474, 51452], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 548, "seek": 269652, "start": 2718.28, "end": 2721.96, "text": " and operation, but I don't think the quibble is particularly important. In the end, it's just", "tokens": [51452, 293, 6916, 11, 457, 286, 500, 380, 519, 264, 421, 897, 638, 307, 4098, 1021, 13, 682, 264, 917, 11, 309, 311, 445, 51636], "temperature": 0.0, "avg_logprob": -0.1055743760532803, "compression_ratio": 1.7828947368421053, "no_speech_prob": 0.02368193119764328}, {"id": 549, "seek": 272196, "start": 2721.96, "end": 2726.68, "text": " all functions regardless of how you spell it. As for human issue, performance is a human issue.", "tokens": [50364, 439, 6828, 10060, 295, 577, 291, 9827, 309, 13, 1018, 337, 1952, 2734, 11, 3389, 307, 257, 1952, 2734, 13, 50600], "temperature": 0.0, "avg_logprob": -0.1869258575439453, "compression_ratio": 1.6654929577464788, "no_speech_prob": 0.09720506519079208}, {"id": 550, "seek": 272196, "start": 2726.68, "end": 2730.76, "text": " The computer doesn't know how fast or slow an algorithm runs, but I think that that horse is", "tokens": [50600, 440, 3820, 1177, 380, 458, 577, 2370, 420, 2964, 364, 9284, 6676, 11, 457, 286, 519, 300, 300, 6832, 307, 50804], "temperature": 0.0, "avg_logprob": -0.1869258575439453, "compression_ratio": 1.6654929577464788, "no_speech_prob": 0.09720506519079208}, {"id": 551, "seek": 272196, "start": 2730.76, "end": 2737.4, "text": " dead now. And it's like, no, it isn't. This is kind of the point. And he goes back to his", "tokens": [50804, 3116, 586, 13, 400, 309, 311, 411, 11, 572, 11, 309, 1943, 380, 13, 639, 307, 733, 295, 264, 935, 13, 400, 415, 1709, 646, 281, 702, 51136], "temperature": 0.0, "avg_logprob": -0.1869258575439453, "compression_ratio": 1.6654929577464788, "no_speech_prob": 0.09720506519079208}, {"id": 552, "seek": 272196, "start": 2737.4, "end": 2742.6, "text": " microseconds, different module things again. And then he then goes, look, we put a break in here", "tokens": [51136, 3123, 37841, 28750, 11, 819, 10088, 721, 797, 13, 400, 550, 415, 550, 1709, 11, 574, 11, 321, 829, 257, 1821, 294, 510, 51396], "temperature": 0.0, "avg_logprob": -0.1869258575439453, "compression_ratio": 1.6654929577464788, "no_speech_prob": 0.09720506519079208}, {"id": 553, "seek": 272196, "start": 2742.6, "end": 2747.64, "text": " to write extra bit more to go rewrite history and says, look, I'm going to continue us now in the", "tokens": [51396, 281, 2464, 2857, 857, 544, 281, 352, 28132, 2503, 293, 1619, 11, 574, 11, 286, 478, 516, 281, 2354, 505, 586, 294, 264, 51648], "temperature": 0.0, "avg_logprob": -0.1869258575439453, "compression_ratio": 1.6654929577464788, "no_speech_prob": 0.09720506519079208}, {"id": 554, "seek": 274764, "start": 2747.64, "end": 2755.3199999999997, "text": " second document, which is the number two. Because he's trying to like make break here,", "tokens": [50364, 1150, 4166, 11, 597, 307, 264, 1230, 732, 13, 1436, 415, 311, 1382, 281, 411, 652, 1821, 510, 11, 50748], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 555, "seek": 274764, "start": 2755.3199999999997, "end": 2759.24, "text": " and then reframe the entire question in the second document, it's a pivot and a reframe", "tokens": [50748, 293, 550, 13334, 529, 264, 2302, 1168, 294, 264, 1150, 4166, 11, 309, 311, 257, 14538, 293, 257, 13334, 529, 50944], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 556, "seek": 274764, "start": 2759.24, "end": 2763.96, "text": " at the same time, clever rhetoric trick. If you want to do that in an argument, you do that all", "tokens": [50944, 412, 264, 912, 565, 11, 13494, 29604, 4282, 13, 759, 291, 528, 281, 360, 300, 294, 364, 6770, 11, 291, 360, 300, 439, 51180], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 557, "seek": 274764, "start": 2763.96, "end": 2766.92, "text": " the time, you reframe the question. So it's now they're not even talking about the original thing", "tokens": [51180, 264, 565, 11, 291, 13334, 529, 264, 1168, 13, 407, 309, 311, 586, 436, 434, 406, 754, 1417, 466, 264, 3380, 551, 51328], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 558, "seek": 274764, "start": 2766.92, "end": 2771.4, "text": " again. And he's tried to do this. So that's what he's done here. Right. So right at the beginning.", "tokens": [51328, 797, 13, 400, 415, 311, 3031, 281, 360, 341, 13, 407, 300, 311, 437, 415, 311, 1096, 510, 13, 1779, 13, 407, 558, 412, 264, 2863, 13, 51552], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 559, "seek": 274764, "start": 2773.0, "end": 2776.52, "text": " And then Casey's reframed it and put it put it into the beginning. So he's first. So Casey", "tokens": [51632, 400, 550, 27369, 311, 1895, 2356, 292, 309, 293, 829, 309, 829, 309, 666, 264, 2863, 13, 407, 415, 311, 700, 13, 407, 27369, 51808], "temperature": 0.0, "avg_logprob": -0.11613043202649827, "compression_ratio": 1.9175257731958764, "no_speech_prob": 0.05982985347509384}, {"id": 560, "seek": 277652, "start": 2776.52, "end": 2784.92, "text": " knew what he was doing. So just don't let's not do that, shall we? Yeah. So Casey wasn't stupid.", "tokens": [50364, 2586, 437, 415, 390, 884, 13, 407, 445, 500, 380, 718, 311, 406, 360, 300, 11, 4393, 321, 30, 865, 13, 407, 27369, 2067, 380, 6631, 13, 50784], "temperature": 0.0, "avg_logprob": -0.11561569658297936, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.021855873987078667}, {"id": 561, "seek": 277652, "start": 2786.92, "end": 2790.44, "text": " He's talking about all this goes back to the payroll example with all this kind of thing.", "tokens": [50884, 634, 311, 1417, 466, 439, 341, 1709, 646, 281, 264, 36873, 1365, 365, 439, 341, 733, 295, 551, 13, 51060], "temperature": 0.0, "avg_logprob": -0.11561569658297936, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.021855873987078667}, {"id": 562, "seek": 277652, "start": 2791.08, "end": 2796.68, "text": " And Casey's trying to say is like, look, this is not an open problem. You haven't got an open set", "tokens": [51092, 400, 27369, 311, 1382, 281, 584, 307, 411, 11, 574, 11, 341, 307, 406, 364, 1269, 1154, 13, 509, 2378, 380, 658, 364, 1269, 992, 51372], "temperature": 0.0, "avg_logprob": -0.11561569658297936, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.021855873987078667}, {"id": 563, "seek": 277652, "start": 2796.68, "end": 2804.84, "text": " of variants. It seems like it's an extremely well defined problem. So why does this need to be like", "tokens": [51372, 295, 21669, 13, 467, 2544, 411, 309, 311, 364, 4664, 731, 7642, 1154, 13, 407, 983, 775, 341, 643, 281, 312, 411, 51780], "temperature": 0.0, "avg_logprob": -0.11561569658297936, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.021855873987078667}, {"id": 564, "seek": 280484, "start": 2804.92, "end": 2811.88, "text": " operand, operand, primal design was in like variant open, rather than variant closed. And then", "tokens": [50368, 2208, 474, 11, 2208, 474, 11, 2886, 304, 1715, 390, 294, 411, 17501, 1269, 11, 2831, 813, 17501, 5395, 13, 400, 550, 50716], "temperature": 0.0, "avg_logprob": -0.23837103725464875, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.016495050862431526}, {"id": 565, "seek": 280484, "start": 2811.88, "end": 2816.44, "text": " operation open. So this seems to be both closed. Like it's very weird. Like what, what are you", "tokens": [50716, 6916, 1269, 13, 407, 341, 2544, 281, 312, 1293, 5395, 13, 1743, 309, 311, 588, 3657, 13, 1743, 437, 11, 437, 366, 291, 50944], "temperature": 0.0, "avg_logprob": -0.23837103725464875, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.016495050862431526}, {"id": 566, "seek": 280484, "start": 2816.44, "end": 2819.88, "text": " trying to have in like save developer cycles with like, where's this kind of thing coming from?", "tokens": [50944, 1382, 281, 362, 294, 411, 3155, 10754, 17796, 365, 411, 11, 689, 311, 341, 733, 295, 551, 1348, 490, 30, 51116], "temperature": 0.0, "avg_logprob": -0.23837103725464875, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.016495050862431526}, {"id": 567, "seek": 280484, "start": 2822.04, "end": 2828.76, "text": " And then this has been moved to because he reframed it. It's fine. No problems. He's talking", "tokens": [51224, 400, 550, 341, 575, 668, 4259, 281, 570, 415, 1895, 2356, 292, 309, 13, 467, 311, 2489, 13, 883, 2740, 13, 634, 311, 1417, 51560], "temperature": 0.0, "avg_logprob": -0.23837103725464875, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.016495050862431526}, {"id": 568, "seek": 280484, "start": 2828.76, "end": 2833.96, "text": " about the programmer cycles thing. This is the thing he gave this random file he added in here,", "tokens": [51560, 466, 264, 32116, 17796, 551, 13, 639, 307, 264, 551, 415, 2729, 341, 4974, 3991, 415, 3869, 294, 510, 11, 51820], "temperature": 0.0, "avg_logprob": -0.23837103725464875, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.016495050862431526}, {"id": 569, "seek": 283396, "start": 2834.6, "end": 2838.28, "text": " which is the, oh, great. Let's do a code golf example, shall we?", "tokens": [50396, 597, 307, 264, 11, 1954, 11, 869, 13, 961, 311, 360, 257, 3089, 12880, 1365, 11, 4393, 321, 30, 50580], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 570, "seek": 283396, "start": 2845.0, "end": 2847.88, "text": " Cute surprise. It's like the point is the program cycles, waste management,", "tokens": [50916, 29121, 6365, 13, 467, 311, 411, 264, 935, 307, 264, 1461, 17796, 11, 5964, 4592, 11, 51060], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 571, "seek": 283396, "start": 2847.88, "end": 2850.76, "text": " programming cycles, it's like, yeah, you just gave me a code golf example.", "tokens": [51060, 9410, 17796, 11, 309, 311, 411, 11, 1338, 11, 291, 445, 2729, 385, 257, 3089, 12880, 1365, 13, 51204], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 572, "seek": 283396, "start": 2851.56, "end": 2855.7200000000003, "text": " The worst case of readability possible, like, but it's a code golf. That's the whole point.", "tokens": [51244, 440, 5855, 1389, 295, 1401, 2310, 1944, 11, 411, 11, 457, 309, 311, 257, 3089, 12880, 13, 663, 311, 264, 1379, 935, 13, 51452], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 573, "seek": 283396, "start": 2855.7200000000003, "end": 2858.92, "text": " People write those things to be compact and human. Like that's what you're trying to say.", "tokens": [51452, 3432, 2464, 729, 721, 281, 312, 14679, 293, 1952, 13, 1743, 300, 311, 437, 291, 434, 1382, 281, 584, 13, 51612], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 574, "seek": 283396, "start": 2858.92, "end": 2862.04, "text": " Like we're trying to make it easier on like, can you prove my belief not mathematically,", "tokens": [51612, 1743, 321, 434, 1382, 281, 652, 309, 3571, 322, 411, 11, 393, 291, 7081, 452, 7107, 406, 44003, 11, 51768], "temperature": 0.0, "avg_logprob": -0.23519101993058078, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.01063920184969902}, {"id": 575, "seek": 286204, "start": 2862.04, "end": 2866.2, "text": " just as I'm sure that you cannot mathematically prove that your favorite style saves more or", "tokens": [50364, 445, 382, 286, 478, 988, 300, 291, 2644, 44003, 7081, 300, 428, 2954, 3758, 19155, 544, 420, 50572], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 576, "seek": 286204, "start": 2866.2, "end": 2870.84, "text": " less programmer cycles than mine. It's like, so he's already admitting that actually you", "tokens": [50572, 1570, 32116, 17796, 813, 3892, 13, 467, 311, 411, 11, 370, 415, 311, 1217, 44056, 300, 767, 291, 50804], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 577, "seek": 286204, "start": 2870.84, "end": 2875.56, "text": " can't prove my style is worse than yours style. And it's like, because programmer cycles, like", "tokens": [50804, 393, 380, 7081, 452, 3758, 307, 5324, 813, 6342, 3758, 13, 400, 309, 311, 411, 11, 570, 32116, 17796, 11, 411, 51040], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 578, "seek": 286204, "start": 2875.56, "end": 2880.7599999999998, "text": " this is a qualitative thing. He knows he can't measure it. She's actually, I don't think that's", "tokens": [51040, 341, 307, 257, 31312, 551, 13, 634, 3255, 415, 393, 380, 3481, 309, 13, 1240, 311, 767, 11, 286, 500, 380, 519, 300, 311, 51300], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 579, "seek": 286204, "start": 2880.7599999999998, "end": 2883.72, "text": " true to be honest with you. It's just that no one's really bothered to do the science because", "tokens": [51300, 2074, 281, 312, 3245, 365, 291, 13, 467, 311, 445, 300, 572, 472, 311, 534, 22996, 281, 360, 264, 3497, 570, 51448], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 580, "seek": 286204, "start": 2884.6, "end": 2889.56, "text": " programming isn't really young discipline or 70 years at best really as a discipline. So it has", "tokens": [51492, 9410, 1943, 380, 534, 2037, 13635, 420, 5285, 924, 412, 1151, 534, 382, 257, 13635, 13, 407, 309, 575, 51740], "temperature": 0.0, "avg_logprob": -0.15034574537134882, "compression_ratio": 1.842622950819672, "no_speech_prob": 0.013627673499286175}, {"id": 581, "seek": 288956, "start": 2889.56, "end": 2893.7999999999997, "text": " no evolutionary like pressure on there yet to say which which things are good or bad. So people", "tokens": [50364, 572, 27567, 411, 3321, 322, 456, 1939, 281, 584, 597, 597, 721, 366, 665, 420, 1578, 13, 407, 561, 50576], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 582, "seek": 288956, "start": 2893.7999999999997, "end": 2898.68, "text": " just say random things. So it is literally just like, great, there's not really much science in", "tokens": [50576, 445, 584, 4974, 721, 13, 407, 309, 307, 3736, 445, 411, 11, 869, 11, 456, 311, 406, 534, 709, 3497, 294, 50820], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 583, "seek": 288956, "start": 2898.68, "end": 2903.08, "text": " computer science. Rather, again, I'm glad the rest of the world calls it informatics for a reason.", "tokens": [50820, 3820, 3497, 13, 16571, 11, 797, 11, 286, 478, 5404, 264, 1472, 295, 264, 1002, 5498, 309, 1356, 30292, 337, 257, 1778, 13, 51040], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 584, "seek": 288956, "start": 2903.64, "end": 2906.84, "text": " I don't know why we don't we call it computer science, even though it's not an empirical", "tokens": [51068, 286, 500, 380, 458, 983, 321, 500, 380, 321, 818, 309, 3820, 3497, 11, 754, 1673, 309, 311, 406, 364, 31886, 51228], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 585, "seek": 288956, "start": 2906.84, "end": 2911.32, "text": " science and it's close to mathematics, but even then it's not really in practice is close to", "tokens": [51228, 3497, 293, 309, 311, 1998, 281, 18666, 11, 457, 754, 550, 309, 311, 406, 534, 294, 3124, 307, 1998, 281, 51452], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 586, "seek": 288956, "start": 2911.32, "end": 2917.56, "text": " engineering. It's just confusing term. Okay, confusing term. The dynamic was a dynamic", "tokens": [51452, 7043, 13, 467, 311, 445, 13181, 1433, 13, 1033, 11, 13181, 1433, 13, 440, 8546, 390, 257, 8546, 51764], "temperature": 0.0, "avg_logprob": -0.13520041634054744, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.014582082629203796}, {"id": 587, "seek": 291756, "start": 2917.56, "end": 2921.48, "text": " building and other type of just from typos, whatever I make more than this might be in day", "tokens": [50364, 2390, 293, 661, 2010, 295, 445, 490, 2125, 329, 11, 2035, 286, 652, 544, 813, 341, 1062, 312, 294, 786, 50560], "temperature": 0.0, "avg_logprob": -0.21893485647733094, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.02913706563413143}, {"id": 588, "seek": 291756, "start": 2921.48, "end": 2927.16, "text": " to day life. And he's talking about this. So it says, do we agree so far about this? And it's like", "tokens": [50560, 281, 786, 993, 13, 400, 415, 311, 1417, 466, 341, 13, 407, 309, 1619, 11, 360, 321, 3986, 370, 1400, 466, 341, 30, 400, 309, 311, 411, 50844], "temperature": 0.0, "avg_logprob": -0.21893485647733094, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.02913706563413143}, {"id": 589, "seek": 291756, "start": 2932.04, "end": 2935.24, "text": " cases kind of like, well, we don't just worry about certain things in the general like in", "tokens": [51088, 3331, 733, 295, 411, 11, 731, 11, 321, 500, 380, 445, 3292, 466, 1629, 721, 294, 264, 2674, 411, 294, 51248], "temperature": 0.0, "avg_logprob": -0.21893485647733094, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.02913706563413143}, {"id": 590, "seek": 291756, "start": 2935.24, "end": 2938.92, "text": " the specific, I'm still asking the same question about this data stream thing you're talking about.", "tokens": [51248, 264, 2685, 11, 286, 478, 920, 3365, 264, 912, 1168, 466, 341, 1412, 4309, 551, 291, 434, 1417, 466, 13, 51432], "temperature": 0.0, "avg_logprob": -0.21893485647733094, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.02913706563413143}, {"id": 591, "seek": 291756, "start": 2939.7999999999997, "end": 2946.52, "text": " Then Mr. Martin brings up again, the like, hey, here's something like the read write thing for a", "tokens": [51476, 1396, 2221, 13, 9184, 5607, 493, 797, 11, 264, 411, 11, 4177, 11, 510, 311, 746, 411, 264, 1401, 2464, 551, 337, 257, 51812], "temperature": 0.0, "avg_logprob": -0.21893485647733094, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.02913706563413143}, {"id": 592, "seek": 294652, "start": 2946.52, "end": 2953.0, "text": " C. These helper functions don't you know to do all the stuff? It's like, but if you had to do it in", "tokens": [50364, 383, 13, 1981, 36133, 6828, 500, 380, 291, 458, 281, 360, 439, 264, 1507, 30, 467, 311, 411, 11, 457, 498, 291, 632, 281, 360, 309, 294, 50688], "temperature": 0.0, "avg_logprob": -0.22086856548602765, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.06536619365215302}, {"id": 593, "seek": 294652, "start": 2953.0, "end": 2957.32, "text": " your case, we'd have to do a switch statement like this wouldn't we don't you know? Oh, it's like,", "tokens": [50688, 428, 1389, 11, 321, 1116, 362, 281, 360, 257, 3679, 5629, 411, 341, 2759, 380, 321, 500, 380, 291, 458, 30, 876, 11, 309, 311, 411, 11, 50904], "temperature": 0.0, "avg_logprob": -0.22086856548602765, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.06536619365215302}, {"id": 594, "seek": 294652, "start": 2958.12, "end": 2961.96, "text": " look at all the different variations you could hypothetically do this just ugly. Don't you know", "tokens": [50944, 574, 412, 439, 264, 819, 17840, 291, 727, 24371, 22652, 360, 341, 445, 12246, 13, 1468, 380, 291, 458, 51136], "temperature": 0.0, "avg_logprob": -0.22086856548602765, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.06536619365215302}, {"id": 595, "seek": 294652, "start": 2961.96, "end": 2967.32, "text": " it's ugly? By the way, if you this is, this is gonna tangent anyway, I've been writing the", "tokens": [51136, 309, 311, 12246, 30, 3146, 264, 636, 11, 498, 291, 341, 307, 11, 341, 307, 799, 27747, 4033, 11, 286, 600, 668, 3579, 264, 51404], "temperature": 0.0, "avg_logprob": -0.22086856548602765, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.06536619365215302}, {"id": 596, "seek": 294652, "start": 2967.32, "end": 2971.8, "text": " Odin core library and you actually have to do this anyway. Like if you actually have to do like", "tokens": [51404, 12210, 259, 4965, 6405, 293, 291, 767, 362, 281, 360, 341, 4033, 13, 1743, 498, 291, 767, 362, 281, 360, 411, 51628], "temperature": 0.0, "avg_logprob": -0.22086856548602765, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.06536619365215302}, {"id": 597, "seek": 297180, "start": 2971.8, "end": 2976.6800000000003, "text": " you do the read at the OS read functions, because the console on Windows at least does not act", "tokens": [50364, 291, 360, 264, 1401, 412, 264, 12731, 1401, 6828, 11, 570, 264, 11076, 322, 8591, 412, 1935, 775, 406, 605, 50608], "temperature": 0.0, "avg_logprob": -0.15969931624317898, "compression_ratio": 1.8222222222222222, "no_speech_prob": 0.07957880198955536}, {"id": 598, "seek": 297180, "start": 2976.6800000000003, "end": 2982.6000000000004, "text": " like a normal file. In fact, the console on Windows is a UTF 16 document. So that means you have to", "tokens": [50608, 411, 257, 2710, 3991, 13, 682, 1186, 11, 264, 11076, 322, 8591, 307, 257, 624, 20527, 3165, 4166, 13, 407, 300, 1355, 291, 362, 281, 50904], "temperature": 0.0, "avg_logprob": -0.15969931624317898, "compression_ratio": 1.8222222222222222, "no_speech_prob": 0.07957880198955536}, {"id": 599, "seek": 297180, "start": 2982.6000000000004, "end": 2988.92, "text": " write UTF 16 files. If you actually write a UTFT thing to it, you then you have to do a conversion", "tokens": [50904, 2464, 624, 20527, 3165, 7098, 13, 759, 291, 767, 2464, 257, 624, 20527, 51, 551, 281, 309, 11, 291, 550, 291, 362, 281, 360, 257, 14298, 51220], "temperature": 0.0, "avg_logprob": -0.15969931624317898, "compression_ratio": 1.8222222222222222, "no_speech_prob": 0.07957880198955536}, {"id": 600, "seek": 297180, "start": 2988.92, "end": 2992.1200000000003, "text": " to do it onto those. It's actually like already or you have to do this edge case. And not just that", "tokens": [51220, 281, 360, 309, 3911, 729, 13, 467, 311, 767, 411, 1217, 420, 291, 362, 281, 360, 341, 4691, 1389, 13, 400, 406, 445, 300, 51380], "temperature": 0.0, "avg_logprob": -0.15969931624317898, "compression_ratio": 1.8222222222222222, "no_speech_prob": 0.07957880198955536}, {"id": 601, "seek": 297180, "start": 2992.1200000000003, "end": 2999.0800000000004, "text": " the console has other things in it, which are not handled the same as an old file again. So it's a", "tokens": [51380, 264, 11076, 575, 661, 721, 294, 309, 11, 597, 366, 406, 18033, 264, 912, 382, 364, 1331, 3991, 797, 13, 407, 309, 311, 257, 51728], "temperature": 0.0, "avg_logprob": -0.15969931624317898, "compression_ratio": 1.8222222222222222, "no_speech_prob": 0.07957880198955536}, {"id": 602, "seek": 299908, "start": 2999.08, "end": 3006.52, "text": " very kind of have to do this. This is how real world code is not even purely like, oh, the operating", "tokens": [50364, 588, 733, 295, 362, 281, 360, 341, 13, 639, 307, 577, 957, 1002, 3089, 307, 406, 754, 17491, 411, 11, 1954, 11, 264, 7447, 50736], "temperature": 0.0, "avg_logprob": -0.1344946254383434, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.012230049818754196}, {"id": 603, "seek": 299908, "start": 3006.52, "end": 3010.68, "text": " system has dealt this properly. It's like, no, I still have to check if it's a console specifically", "tokens": [50736, 1185, 575, 15991, 341, 6108, 13, 467, 311, 411, 11, 572, 11, 286, 920, 362, 281, 1520, 498, 309, 311, 257, 11076, 4682, 50944], "temperature": 0.0, "avg_logprob": -0.1344946254383434, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.012230049818754196}, {"id": 604, "seek": 299908, "start": 3010.68, "end": 3017.7999999999997, "text": " and then deal with it. So it's like, I know like, this is not working. Like, yeah, it actually looks", "tokens": [50944, 293, 550, 2028, 365, 309, 13, 407, 309, 311, 411, 11, 286, 458, 411, 11, 341, 307, 406, 1364, 13, 1743, 11, 1338, 11, 309, 767, 1542, 51300], "temperature": 0.0, "avg_logprob": -0.1344946254383434, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.012230049818754196}, {"id": 605, "seek": 299908, "start": 3017.7999999999997, "end": 3024.36, "text": " closer to this in real life, even with the, the abstraction on top of what a file is, but I digress.", "tokens": [51300, 4966, 281, 341, 294, 957, 993, 11, 754, 365, 264, 11, 264, 37765, 322, 1192, 295, 437, 257, 3991, 307, 11, 457, 286, 2528, 735, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1344946254383434, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.012230049818754196}, {"id": 606, "seek": 302436, "start": 3024.6800000000003, "end": 3032.6, "text": " Yeah. But yeah, it's just interesting. And then again, many different breaks can different edits", "tokens": [50380, 865, 13, 583, 1338, 11, 309, 311, 445, 1880, 13, 400, 550, 797, 11, 867, 819, 9857, 393, 819, 41752, 50776], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 607, "seek": 302436, "start": 3032.6, "end": 3036.52, "text": " here different sections is breaking it up. The VTab we use by Unix, again, most operating systems", "tokens": [50776, 510, 819, 10863, 307, 7697, 309, 493, 13, 440, 691, 51, 455, 321, 764, 538, 1156, 970, 11, 797, 11, 881, 7447, 3652, 50972], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 608, "seek": 302436, "start": 3036.52, "end": 3041.48, "text": " do this as well. Things change around significantly. The idos can be loaded at any time, the iodevice,", "tokens": [50972, 360, 341, 382, 731, 13, 9514, 1319, 926, 10591, 13, 440, 4496, 329, 393, 312, 13210, 412, 604, 565, 11, 264, 741, 1429, 85, 573, 11, 51220], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 609, "seek": 302436, "start": 3041.48, "end": 3046.2000000000003, "text": " yeah, that's true. That's took in this details we're talking about. He's talking about code reuse,", "tokens": [51220, 1338, 11, 300, 311, 2074, 13, 663, 311, 1890, 294, 341, 4365, 321, 434, 1417, 466, 13, 634, 311, 1417, 466, 3089, 26225, 11, 51456], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 610, "seek": 302436, "start": 3046.2000000000003, "end": 3050.04, "text": " great example says the cases. I apologize for trying to be very specific, but I really want to be", "tokens": [51456, 869, 1365, 1619, 264, 3331, 13, 286, 12328, 337, 1382, 281, 312, 588, 2685, 11, 457, 286, 534, 528, 281, 312, 51648], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 611, "seek": 302436, "start": 3050.04, "end": 3054.1200000000003, "text": " actually get to the exact proposal. And it wasn't clear from what could you actually tell me what", "tokens": [51648, 767, 483, 281, 264, 1900, 11494, 13, 400, 309, 2067, 380, 1850, 490, 437, 727, 291, 767, 980, 385, 437, 51852], "temperature": 0.0, "avg_logprob": -0.3274237400776631, "compression_ratio": 1.7159420289855072, "no_speech_prob": 0.05889023840427399}, {"id": 612, "seek": 305412, "start": 3054.12, "end": 3057.88, "text": " the OS interface looks like and how it's implemented. You said, I guess that depends on a lot on", "tokens": [50364, 264, 12731, 9226, 1542, 411, 293, 577, 309, 311, 12270, 13, 509, 848, 11, 286, 2041, 300, 5946, 322, 257, 688, 322, 50552], "temperature": 0.0, "avg_logprob": -0.15016948993389423, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.020415818318724632}, {"id": 613, "seek": 305412, "start": 3057.88, "end": 3062.3599999999997, "text": " the language and the application. But my understanding is that we're talking about the OS side. So, and", "tokens": [50552, 264, 2856, 293, 264, 3861, 13, 583, 452, 3701, 307, 300, 321, 434, 1417, 466, 264, 12731, 1252, 13, 407, 11, 293, 50776], "temperature": 0.0, "avg_logprob": -0.15016948993389423, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.020415818318724632}, {"id": 614, "seek": 305412, "start": 3062.3599999999997, "end": 3068.12, "text": " again, it's the, how does the OS implement this, like the, the stream, the file, compared to how", "tokens": [50776, 797, 11, 309, 311, 264, 11, 577, 775, 264, 12731, 4445, 341, 11, 411, 264, 11, 264, 4309, 11, 264, 3991, 11, 5347, 281, 577, 51064], "temperature": 0.0, "avg_logprob": -0.15016948993389423, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.020415818318724632}, {"id": 615, "seek": 305412, "start": 3068.12, "end": 3072.6, "text": " we're doing it in a language is very different. And not just that, again, I thought we were talking", "tokens": [51064, 321, 434, 884, 309, 294, 257, 2856, 307, 588, 819, 13, 400, 406, 445, 300, 11, 797, 11, 286, 1194, 321, 645, 1417, 51288], "temperature": 0.0, "avg_logprob": -0.15016948993389423, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.020415818318724632}, {"id": 616, "seek": 305412, "start": 3072.6, "end": 3079.7999999999997, "text": " about clean code. But why has it gone down this digression? Just you wait. Let's go get that. Don't", "tokens": [51288, 466, 2541, 3089, 13, 583, 983, 575, 309, 2780, 760, 341, 2528, 2775, 30, 1449, 291, 1699, 13, 961, 311, 352, 483, 300, 13, 1468, 380, 51648], "temperature": 0.0, "avg_logprob": -0.15016948993389423, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.020415818318724632}, {"id": 617, "seek": 307980, "start": 3079.8, "end": 3085.6400000000003, "text": " worry. Okay, we're talking about get all crap. Okay, because it just changed. That's, I can probably", "tokens": [50364, 3292, 13, 1033, 11, 321, 434, 1417, 466, 483, 439, 12426, 13, 1033, 11, 570, 309, 445, 3105, 13, 663, 311, 11, 286, 393, 1391, 50656], "temperature": 0.0, "avg_logprob": -0.23173979825751725, "compression_ratio": 1.6179401993355482, "no_speech_prob": 0.09910307824611664}, {"id": 618, "seek": 307980, "start": 3085.6400000000003, "end": 3090.1200000000003, "text": " guess which day this was written on as well. Like you're saying it seems like it looks like this", "tokens": [50656, 2041, 597, 786, 341, 390, 3720, 322, 382, 731, 13, 1743, 291, 434, 1566, 309, 2544, 411, 309, 1542, 411, 341, 50880], "temperature": 0.0, "avg_logprob": -0.23173979825751725, "compression_ratio": 1.6179401993355482, "no_speech_prob": 0.09910307824611664}, {"id": 619, "seek": 307980, "start": 3090.1200000000003, "end": 3095.4, "text": " somewhere. Is it actually a base class? Is it whatever? Now, Mr. Martin says, okay, here's kind", "tokens": [50880, 4079, 13, 1119, 309, 767, 257, 3096, 1508, 30, 1119, 309, 2035, 30, 823, 11, 2221, 13, 9184, 1619, 11, 1392, 11, 510, 311, 733, 51144], "temperature": 0.0, "avg_logprob": -0.23173979825751725, "compression_ratio": 1.6179401993355482, "no_speech_prob": 0.09910307824611664}, {"id": 620, "seek": 307980, "start": 3095.4, "end": 3099.96, "text": " of the general interface that he's writing C++. Again, he's not answering the question he's asked.", "tokens": [51144, 295, 264, 2674, 9226, 300, 415, 311, 3579, 383, 25472, 13, 3764, 11, 415, 311, 406, 13430, 264, 1168, 415, 311, 2351, 13, 51372], "temperature": 0.0, "avg_logprob": -0.23173979825751725, "compression_ratio": 1.6179401993355482, "no_speech_prob": 0.09910307824611664}, {"id": 621, "seek": 307980, "start": 3099.96, "end": 3109.5600000000004, "text": " He's done another thing. Whatever, kind of missed the point again. And then he's saying, look,", "tokens": [51372, 634, 311, 1096, 1071, 551, 13, 8541, 11, 733, 295, 6721, 264, 935, 797, 13, 400, 550, 415, 311, 1566, 11, 574, 11, 51852], "temperature": 0.0, "avg_logprob": -0.23173979825751725, "compression_ratio": 1.6179401993355482, "no_speech_prob": 0.09910307824611664}, {"id": 622, "seek": 310956, "start": 3109.64, "end": 3113.64, "text": " look, if we look at the, he's trying to say this is less like the code is easy to manage whatever.", "tokens": [50368, 574, 11, 498, 321, 574, 412, 264, 11, 415, 311, 1382, 281, 584, 341, 307, 1570, 411, 264, 3089, 307, 1858, 281, 3067, 2035, 13, 50568], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 623, "seek": 310956, "start": 3113.64, "end": 3117.96, "text": " Like, yeah, but you've just chosen the canonical example. And he says, look, if I do the dynamic", "tokens": [50568, 1743, 11, 1338, 11, 457, 291, 600, 445, 8614, 264, 46491, 1365, 13, 400, 415, 1619, 11, 574, 11, 498, 286, 360, 264, 8546, 50784], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 624, "seek": 310956, "start": 3117.96, "end": 3123.32, "text": " polymorphism case, so inheritance, I create, I create this file of three files and have to leave", "tokens": [50784, 6754, 76, 18191, 1434, 1389, 11, 370, 32122, 11, 286, 1884, 11, 286, 1884, 341, 3991, 295, 1045, 7098, 293, 362, 281, 1856, 51052], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 625, "seek": 310956, "start": 3123.32, "end": 3127.24, "text": " them with a switch case. I've now all of this and look at all these different things I have to define.", "tokens": [51052, 552, 365, 257, 3679, 1389, 13, 286, 600, 586, 439, 295, 341, 293, 574, 412, 439, 613, 819, 721, 286, 362, 281, 6964, 13, 51248], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 626, "seek": 310956, "start": 3127.24, "end": 3133.0, "text": " I'm like, and cases, well, hold on, since I'm the switch proponent, at least I get to write it,", "tokens": [51248, 286, 478, 411, 11, 293, 3331, 11, 731, 11, 1797, 322, 11, 1670, 286, 478, 264, 3679, 2365, 30365, 11, 412, 1935, 286, 483, 281, 2464, 309, 11, 51536], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 627, "seek": 310956, "start": 3133.0, "end": 3137.64, "text": " please. Look again, look what he's just done. He says, well, I've just shown you how to do it.", "tokens": [51536, 1767, 13, 2053, 797, 11, 574, 437, 415, 311, 445, 1096, 13, 634, 1619, 11, 731, 11, 286, 600, 445, 4898, 291, 577, 281, 360, 309, 13, 51768], "temperature": 0.0, "avg_logprob": -0.17029370394620028, "compression_ratio": 1.7650602409638554, "no_speech_prob": 0.02243300899863243}, {"id": 628, "seek": 313764, "start": 3137.64, "end": 3141.3199999999997, "text": " And look, it's just more complicated. I've had to write files. Oh, no, I'm like cases like,", "tokens": [50364, 400, 574, 11, 309, 311, 445, 544, 6179, 13, 286, 600, 632, 281, 2464, 7098, 13, 876, 11, 572, 11, 286, 478, 411, 3331, 411, 11, 50548], "temperature": 0.0, "avg_logprob": -0.23227180540561676, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.08501216769218445}, {"id": 629, "seek": 313764, "start": 3142.7599999999998, "end": 3150.44, "text": " hold on, hold on. Yeah, and it's kind of doing like this. So it goes on and on,", "tokens": [50620, 1797, 322, 11, 1797, 322, 13, 865, 11, 293, 309, 311, 733, 295, 884, 411, 341, 13, 407, 309, 1709, 322, 293, 322, 11, 51004], "temperature": 0.0, "avg_logprob": -0.23227180540561676, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.08501216769218445}, {"id": 630, "seek": 313764, "start": 3150.44, "end": 3153.64, "text": " we just discuss things, but it's like cases like I want to know what the operating system again.", "tokens": [51004, 321, 445, 2248, 721, 11, 457, 309, 311, 411, 3331, 411, 286, 528, 281, 458, 437, 264, 7447, 1185, 797, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23227180540561676, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.08501216769218445}, {"id": 631, "seek": 313764, "start": 3156.04, "end": 3159.7999999999997, "text": " And it's different. Okay. And then cases like we're not even talking about machine cycles again,", "tokens": [51284, 400, 309, 311, 819, 13, 1033, 13, 400, 550, 3331, 411, 321, 434, 406, 754, 1417, 466, 3479, 17796, 797, 11, 51472], "temperature": 0.0, "avg_logprob": -0.23227180540561676, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.08501216769218445}, {"id": 632, "seek": 313764, "start": 3159.7999999999997, "end": 3163.72, "text": " I'm just focusing on the program cycles again, what like he's doing again. So I'm like paraphrasing", "tokens": [51472, 286, 478, 445, 8416, 322, 264, 1461, 17796, 797, 11, 437, 411, 415, 311, 884, 797, 13, 407, 286, 478, 411, 36992, 1703, 3349, 51668], "temperature": 0.0, "avg_logprob": -0.23227180540561676, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.08501216769218445}, {"id": 633, "seek": 316372, "start": 3163.72, "end": 3169.72, "text": " this poorly ish, but it's kind of just like, I'm trying to show the techniques that he's doing here", "tokens": [50364, 341, 22271, 307, 71, 11, 457, 309, 311, 733, 295, 445, 411, 11, 286, 478, 1382, 281, 855, 264, 7512, 300, 415, 311, 884, 510, 50664], "temperature": 0.0, "avg_logprob": -0.09881384670734406, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.12856554985046387}, {"id": 634, "seek": 316372, "start": 3169.72, "end": 3175.48, "text": " that he knows he's doing it. He isn't an idiot. I'm trying to be very careful like this. Mr.", "tokens": [50664, 300, 415, 3255, 415, 311, 884, 309, 13, 634, 1943, 380, 364, 14270, 13, 286, 478, 1382, 281, 312, 588, 5026, 411, 341, 13, 2221, 13, 50952], "temperature": 0.0, "avg_logprob": -0.09881384670734406, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.12856554985046387}, {"id": 635, "seek": 316372, "start": 3175.48, "end": 3179.3999999999996, "text": " Martin knows exactly what he's doing. Like he's now just made another document on here,", "tokens": [50952, 9184, 3255, 2293, 437, 415, 311, 884, 13, 1743, 415, 311, 586, 445, 1027, 1071, 4166, 322, 510, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09881384670734406, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.12856554985046387}, {"id": 636, "seek": 316372, "start": 3179.3999999999996, "end": 3184.12, "text": " which only he talks about. And it's just he's trying to suggest like, oh, this is the clean code", "tokens": [51148, 597, 787, 415, 6686, 466, 13, 400, 309, 311, 445, 415, 311, 1382, 281, 3402, 411, 11, 1954, 11, 341, 307, 264, 2541, 3089, 51384], "temperature": 0.0, "avg_logprob": -0.09881384670734406, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.12856554985046387}, {"id": 637, "seek": 316372, "start": 3184.12, "end": 3189.3199999999997, "text": " stuff. And then he's saying this is what clean code is. And I've just got the summation seems", "tokens": [51384, 1507, 13, 400, 550, 415, 311, 1566, 341, 307, 437, 2541, 3089, 307, 13, 400, 286, 600, 445, 658, 264, 28811, 2544, 51644], "temperature": 0.0, "avg_logprob": -0.09881384670734406, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.12856554985046387}, {"id": 638, "seek": 318932, "start": 3189.4, "end": 3194.2000000000003, "text": " to correlate with what I most people think it is. Because I miss people people keep this understanding", "tokens": [50368, 281, 48742, 365, 437, 286, 881, 561, 519, 309, 307, 13, 1436, 286, 1713, 561, 561, 1066, 341, 3701, 50608], "temperature": 0.0, "avg_logprob": -0.21250764947188527, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12919080257415771}, {"id": 639, "seek": 318932, "start": 3194.2000000000003, "end": 3199.7200000000003, "text": " me kind of view. And it's like, wait a minute. So choose carefully names, not unique. Keep function", "tokens": [50608, 385, 733, 295, 1910, 13, 400, 309, 311, 411, 11, 1699, 257, 3456, 13, 407, 2826, 7500, 5288, 11, 406, 3845, 13, 5527, 2445, 50884], "temperature": 0.0, "avg_logprob": -0.21250764947188527, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12919080257415771}, {"id": 640, "seek": 318932, "start": 3199.7200000000003, "end": 3206.04, "text": " small. Why keep classes small. Why manage your dependencies, vague as anything. Literally,", "tokens": [50884, 1359, 13, 1545, 1066, 5359, 1359, 13, 1545, 3067, 428, 36606, 11, 24247, 382, 1340, 13, 23768, 11, 51200], "temperature": 0.0, "avg_logprob": -0.21250764947188527, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12919080257415771}, {"id": 641, "seek": 318932, "start": 3206.04, "end": 3212.92, "text": " be careful with side effects. Okay. Yeah, express yourself in code where possible. How else you", "tokens": [51200, 312, 5026, 365, 1252, 5065, 13, 1033, 13, 865, 11, 5109, 1803, 294, 3089, 689, 1944, 13, 1012, 1646, 291, 51544], "temperature": 0.0, "avg_logprob": -0.21250764947188527, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12919080257415771}, {"id": 642, "seek": 318932, "start": 3212.92, "end": 3217.56, "text": " meant to express yourself in code away? It's your programming. Use polymorphers when the type", "tokens": [51544, 4140, 281, 5109, 1803, 294, 3089, 1314, 30, 467, 311, 428, 9410, 13, 8278, 6754, 76, 18191, 433, 562, 264, 2010, 51776], "temperature": 0.0, "avg_logprob": -0.21250764947188527, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.12919080257415771}, {"id": 643, "seek": 321756, "start": 3217.56, "end": 3221.7999999999997, "text": " changes fast in the operations. This is new stuff he's added now. You switched when operating", "tokens": [50364, 2962, 2370, 294, 264, 7705, 13, 639, 307, 777, 1507, 415, 311, 3869, 586, 13, 509, 16858, 562, 7447, 50576], "temperature": 0.0, "avg_logprob": -0.19741585434124034, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.04214996099472046}, {"id": 644, "seek": 321756, "start": 3221.7999999999997, "end": 3230.92, "text": " change fast in the types. Why? Why? And at what cost? And what Harvard evidence have you got?", "tokens": [50576, 1319, 2370, 294, 264, 3467, 13, 1545, 30, 1545, 30, 400, 412, 437, 2063, 30, 400, 437, 13378, 4467, 362, 291, 658, 30, 51032], "temperature": 0.0, "avg_logprob": -0.19741585434124034, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.04214996099472046}, {"id": 645, "seek": 321756, "start": 3230.92, "end": 3237.72, "text": " This is better. And like, you compare it to this and like, you sure? Okay, when possible,", "tokens": [51032, 639, 307, 1101, 13, 400, 411, 11, 291, 6794, 309, 281, 341, 293, 411, 11, 291, 988, 30, 1033, 11, 562, 1944, 11, 51372], "temperature": 0.0, "avg_logprob": -0.19741585434124034, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.04214996099472046}, {"id": 646, "seek": 321756, "start": 3237.72, "end": 3244.84, "text": " create designs where things that can change fast that change fast are types. Why keep asking this", "tokens": [51372, 1884, 11347, 689, 721, 300, 393, 1319, 2370, 300, 1319, 2370, 366, 3467, 13, 1545, 1066, 3365, 341, 51728], "temperature": 0.0, "avg_logprob": -0.19741585434124034, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.04214996099472046}, {"id": 647, "seek": 324484, "start": 3244.84, "end": 3250.2000000000003, "text": " question? Here's in his even in his summarizations of here, he's actually saying, we'll prefer", "tokens": [50364, 1168, 30, 1692, 311, 294, 702, 754, 294, 702, 14611, 14455, 295, 510, 11, 415, 311, 767, 1566, 11, 321, 603, 4382, 50632], "temperature": 0.0, "avg_logprob": -0.21542158652478316, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.22186069190502167}, {"id": 648, "seek": 324484, "start": 3250.2000000000003, "end": 3255.48, "text": " polymorphism. So now he's in like, well, I don't see how you got to that conclusion where like,", "tokens": [50632, 6754, 76, 18191, 1434, 13, 407, 586, 415, 311, 294, 411, 11, 731, 11, 286, 500, 380, 536, 577, 291, 658, 281, 300, 10063, 689, 411, 11, 50896], "temperature": 0.0, "avg_logprob": -0.21542158652478316, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.22186069190502167}, {"id": 649, "seek": 324484, "start": 3255.48, "end": 3259.6400000000003, "text": " I'm against switch tamers or something. I'll clear and prefer like default before like all this", "tokens": [50896, 286, 478, 1970, 3679, 7677, 433, 420, 746, 13, 286, 603, 1850, 293, 4382, 411, 7576, 949, 411, 439, 341, 51104], "temperature": 0.0, "avg_logprob": -0.21542158652478316, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.22186069190502167}, {"id": 650, "seek": 324484, "start": 3259.6400000000003, "end": 3266.1200000000003, "text": " and like, you're literally saying it in here in this summarized document. If I'm misinterpreting", "tokens": [51104, 293, 411, 11, 291, 434, 3736, 1566, 309, 294, 510, 294, 341, 14611, 1602, 4166, 13, 759, 286, 478, 3346, 5106, 3712, 783, 51428], "temperature": 0.0, "avg_logprob": -0.21542158652478316, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.22186069190502167}, {"id": 651, "seek": 324484, "start": 3266.1200000000003, "end": 3272.2000000000003, "text": " it, please tell me again, in the comments or something. I'm just really confused. Like, what?", "tokens": [51428, 309, 11, 1767, 980, 385, 797, 11, 294, 264, 3053, 420, 746, 13, 286, 478, 445, 534, 9019, 13, 1743, 11, 437, 30, 51732], "temperature": 0.0, "avg_logprob": -0.21542158652478316, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.22186069190502167}, {"id": 652, "seek": 327220, "start": 3272.7599999999998, "end": 3279.56, "text": " Right. So Casey comes back again, and he's talking about the internals of this. It's like, okay,", "tokens": [50392, 1779, 13, 407, 27369, 1487, 646, 797, 11, 293, 415, 311, 1417, 466, 264, 2154, 1124, 295, 341, 13, 467, 311, 411, 11, 1392, 11, 50732], "temperature": 0.0, "avg_logprob": -0.16669529676437378, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.014406509697437286}, {"id": 653, "seek": 327220, "start": 3279.56, "end": 3283.64, "text": " find the device, then you read it and you do this. This is how ring versions, if you understand how", "tokens": [50732, 915, 264, 4302, 11, 550, 291, 1401, 309, 293, 291, 360, 341, 13, 639, 307, 577, 4875, 9606, 11, 498, 291, 1223, 577, 50936], "temperature": 0.0, "avg_logprob": -0.16669529676437378, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.014406509697437286}, {"id": 654, "seek": 327220, "start": 3283.64, "end": 3289.48, "text": " they work internally. Okay, great. There's class, here's the operations. And it's that looks,", "tokens": [50936, 436, 589, 19501, 13, 1033, 11, 869, 13, 821, 311, 1508, 11, 510, 311, 264, 7705, 13, 400, 309, 311, 300, 1542, 11, 51228], "temperature": 0.0, "avg_logprob": -0.16669529676437378, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.014406509697437286}, {"id": 655, "seek": 327220, "start": 3289.48, "end": 3293.24, "text": " you can always do it this way around. And look, I've got a different way of doing it. So just a", "tokens": [51228, 291, 393, 1009, 360, 309, 341, 636, 926, 13, 400, 574, 11, 286, 600, 658, 257, 819, 636, 295, 884, 309, 13, 407, 445, 257, 51416], "temperature": 0.0, "avg_logprob": -0.16669529676437378, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.014406509697437286}, {"id": 656, "seek": 327220, "start": 3293.24, "end": 3299.3199999999997, "text": " union based approach now, with all the data inside of it doing all what we need, whatever.", "tokens": [51416, 11671, 2361, 3109, 586, 11, 365, 439, 264, 1412, 1854, 295, 309, 884, 439, 437, 321, 643, 11, 2035, 13, 51720], "temperature": 0.0, "avg_logprob": -0.16669529676437378, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.014406509697437286}, {"id": 657, "seek": 329932, "start": 3299.6400000000003, "end": 3305.2400000000002, "text": " And that thing that's just is actually trying to show the actual things internally, isn't", "tokens": [50380, 400, 300, 551, 300, 311, 445, 307, 767, 1382, 281, 855, 264, 3539, 721, 19501, 11, 1943, 380, 50660], "temperature": 0.0, "avg_logprob": -0.19755470275878906, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.013602755032479763}, {"id": 658, "seek": 329932, "start": 3305.2400000000002, "end": 3310.04, "text": " it? But yeah, it's kind of like, look, now I don't like vtables, because obviously pretty", "tokens": [50660, 309, 30, 583, 1338, 11, 309, 311, 733, 295, 411, 11, 574, 11, 586, 286, 500, 380, 411, 371, 83, 2965, 11, 570, 2745, 1238, 50900], "temperature": 0.0, "avg_logprob": -0.19755470275878906, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.013602755032479763}, {"id": 659, "seek": 329932, "start": 3310.04, "end": 3314.52, "text": " much everywhere, because I find them hard to control. So I prefer this. So he says, look,", "tokens": [50900, 709, 5315, 11, 570, 286, 915, 552, 1152, 281, 1969, 13, 407, 286, 4382, 341, 13, 407, 415, 1619, 11, 574, 11, 51124], "temperature": 0.0, "avg_logprob": -0.19755470275878906, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.013602755032479763}, {"id": 660, "seek": 329932, "start": 3314.52, "end": 3320.92, "text": " I have a, not a vtable, but just inline things itself, it's not a table, just inline functions.", "tokens": [51124, 286, 362, 257, 11, 406, 257, 371, 23811, 11, 457, 445, 294, 1889, 721, 2564, 11, 309, 311, 406, 257, 3199, 11, 445, 294, 1889, 6828, 13, 51444], "temperature": 0.0, "avg_logprob": -0.19755470275878906, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.013602755032479763}, {"id": 661, "seek": 329932, "start": 3320.92, "end": 3326.92, "text": " So instead of a class, you've now just got inline methods. And this is just general handling", "tokens": [51444, 407, 2602, 295, 257, 1508, 11, 291, 600, 586, 445, 658, 294, 1889, 7150, 13, 400, 341, 307, 445, 2674, 13175, 51744], "temperature": 0.0, "avg_logprob": -0.19755470275878906, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.013602755032479763}, {"id": 662, "seek": 332692, "start": 3327.48, "end": 3331.56, "text": " thing, which is interesting. By the way, that should be more better for performance in general,", "tokens": [50392, 551, 11, 597, 307, 1880, 13, 3146, 264, 636, 11, 300, 820, 312, 544, 1101, 337, 3389, 294, 2674, 11, 50596], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 663, "seek": 332692, "start": 3331.56, "end": 3336.52, "text": " because a vtable is usually a pointer to a structure of a function tape, like function pointers,", "tokens": [50596, 570, 257, 371, 23811, 307, 2673, 257, 23918, 281, 257, 3877, 295, 257, 2445, 7314, 11, 411, 2445, 44548, 11, 50844], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 664, "seek": 332692, "start": 3337.16, "end": 3340.44, "text": " whilst if you're embedding the function pointers, you've got rid of that indirection. So you've", "tokens": [50876, 18534, 498, 291, 434, 12240, 3584, 264, 2445, 44548, 11, 291, 600, 658, 3973, 295, 300, 1016, 621, 882, 13, 407, 291, 600, 51040], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 665, "seek": 332692, "start": 3340.44, "end": 3344.04, "text": " actually got it will be faster in general as well, because you've got rid of the indirection.", "tokens": [51040, 767, 658, 309, 486, 312, 4663, 294, 2674, 382, 731, 11, 570, 291, 600, 658, 3973, 295, 264, 1016, 621, 882, 13, 51220], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 666, "seek": 332692, "start": 3344.04, "end": 3349.32, "text": " It always has a better chance to optimize and even it has slightly better chance of inlining", "tokens": [51220, 467, 1009, 575, 257, 1101, 2931, 281, 19719, 293, 754, 309, 575, 4748, 1101, 2931, 295, 294, 31079, 51484], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 667, "seek": 332692, "start": 3349.32, "end": 3355.56, "text": " and slightly. But yeah, that's how compilers work. Sorry, rambling again, again. But I'm", "tokens": [51484, 293, 4748, 13, 583, 1338, 11, 300, 311, 577, 715, 388, 433, 589, 13, 4919, 11, 367, 19391, 797, 11, 797, 13, 583, 286, 478, 51796], "temperature": 0.0, "avg_logprob": -0.14498861071089625, "compression_ratio": 1.8862876254180603, "no_speech_prob": 0.0809265524148941}, {"id": 668, "seek": 335556, "start": 3355.56, "end": 3358.68, "text": " getting off the digression. But cases kind of saying like, look, we could just handle it for", "tokens": [50364, 1242, 766, 264, 2528, 2775, 13, 583, 3331, 733, 295, 1566, 411, 11, 574, 11, 321, 727, 445, 4813, 309, 337, 50520], "temperature": 0.0, "avg_logprob": -0.10876187556931953, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.013953727670013905}, {"id": 669, "seek": 335556, "start": 3358.68, "end": 3364.04, "text": " each of them that we could actually have one callback, just one, and we could directly embed", "tokens": [50520, 1184, 295, 552, 300, 321, 727, 767, 362, 472, 818, 3207, 11, 445, 472, 11, 293, 321, 727, 3838, 12240, 50788], "temperature": 0.0, "avg_logprob": -0.10876187556931953, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.013953727670013905}, {"id": 670, "seek": 335556, "start": 3364.04, "end": 3369.32, "text": " it in the structure. So it's not even in directed anymore. And then we switch on this. Now this is", "tokens": [50788, 309, 294, 264, 3877, 13, 407, 309, 311, 406, 754, 294, 12898, 3602, 13, 400, 550, 321, 3679, 322, 341, 13, 823, 341, 307, 51052], "temperature": 0.0, "avg_logprob": -0.10876187556931953, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.013953727670013905}, {"id": 671, "seek": 335556, "start": 3369.32, "end": 3373.7999999999997, "text": " interesting. You could do it for every single operation. And then look the codes in one place", "tokens": [51052, 1880, 13, 509, 727, 360, 309, 337, 633, 2167, 6916, 13, 400, 550, 574, 264, 14211, 294, 472, 1081, 51276], "temperature": 0.0, "avg_logprob": -0.10876187556931953, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.013953727670013905}, {"id": 672, "seek": 335556, "start": 3373.7999999999997, "end": 3380.36, "text": " for this thing. We've now got the best of both worlds in many ways. And why wouldn't you prefer", "tokens": [51276, 337, 341, 551, 13, 492, 600, 586, 658, 264, 1151, 295, 1293, 13401, 294, 867, 2098, 13, 400, 983, 2759, 380, 291, 4382, 51604], "temperature": 0.0, "avg_logprob": -0.10876187556931953, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.013953727670013905}, {"id": 673, "seek": 338036, "start": 3380.36, "end": 3386.6, "text": " this way? I think now interestingly, I'm just going to like slightly digression here going into", "tokens": [50364, 341, 636, 30, 286, 519, 586, 25873, 11, 286, 478, 445, 516, 281, 411, 4748, 2528, 2775, 510, 516, 666, 50676], "temperature": 0.0, "avg_logprob": -0.19678791945542745, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.04285343736410141}, {"id": 674, "seek": 338036, "start": 3386.6, "end": 3391.48, "text": " Odin. And this is what we actually do for the allocator. And I've been doing this for like a", "tokens": [50676, 12210, 259, 13, 400, 341, 307, 437, 321, 767, 360, 337, 264, 12660, 1639, 13, 400, 286, 600, 668, 884, 341, 337, 411, 257, 50920], "temperature": 0.0, "avg_logprob": -0.19678791945542745, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.04285343736410141}, {"id": 675, "seek": 338036, "start": 3391.48, "end": 3399.7200000000003, "text": " decade, maybe even before Odin. There is the thing sorry, apologize for the digression. This is", "tokens": [50920, 10378, 11, 1310, 754, 949, 12210, 259, 13, 821, 307, 264, 551, 2597, 11, 12328, 337, 264, 2528, 2775, 13, 639, 307, 51332], "temperature": 0.0, "avg_logprob": -0.19678791945542745, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.04285343736410141}, {"id": 676, "seek": 338036, "start": 3399.7200000000003, "end": 3404.84, "text": " clearly unscripted if you didn't guess. Here's the allocator. So we know that we have a built in", "tokens": [51332, 4448, 2693, 5944, 292, 498, 291, 994, 380, 2041, 13, 1692, 311, 264, 12660, 1639, 13, 407, 321, 458, 300, 321, 362, 257, 3094, 294, 51588], "temperature": 0.0, "avg_logprob": -0.19678791945542745, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.04285343736410141}, {"id": 677, "seek": 338036, "start": 3404.84, "end": 3408.28, "text": " concept from an allocator and allocator is just a little data structure with a pointer to a procedure", "tokens": [51588, 3410, 490, 364, 12660, 1639, 293, 12660, 1639, 307, 445, 257, 707, 1412, 3877, 365, 257, 23918, 281, 257, 10747, 51760], "temperature": 0.0, "avg_logprob": -0.19678791945542745, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.04285343736410141}, {"id": 678, "seek": 340828, "start": 3409.0, "end": 3414.92, "text": " and appointed to the data. So 16 bytes, you can easily copy this around. So it's usually not", "tokens": [50400, 293, 17653, 281, 264, 1412, 13, 407, 3165, 36088, 11, 291, 393, 3612, 5055, 341, 926, 13, 407, 309, 311, 2673, 406, 50696], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 679, "seek": 340828, "start": 3414.92, "end": 3418.52, "text": " even appointed to the allocator, it's just the allocator itself in memory. And you just get the", "tokens": [50696, 754, 17653, 281, 264, 12660, 1639, 11, 309, 311, 445, 264, 12660, 1639, 2564, 294, 4675, 13, 400, 291, 445, 483, 264, 50876], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 680, "seek": 340828, "start": 3418.52, "end": 3422.6000000000004, "text": " values. So that's what you're doing. So there's not an indirection again, because it has to be a", "tokens": [50876, 4190, 13, 407, 300, 311, 437, 291, 434, 884, 13, 407, 456, 311, 406, 364, 1016, 621, 882, 797, 11, 570, 309, 575, 281, 312, 257, 51080], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 681, "seek": 340828, "start": 3422.6000000000004, "end": 3426.2000000000003, "text": " pointer. And notice it's just in line with the function. And not just there's only one function", "tokens": [51080, 23918, 13, 400, 3449, 309, 311, 445, 294, 1622, 365, 264, 2445, 13, 400, 406, 445, 456, 311, 787, 472, 2445, 51260], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 682, "seek": 340828, "start": 3426.2000000000003, "end": 3429.5600000000004, "text": " you think, but there's loads of different allocation operations like yes, it's one function,", "tokens": [51260, 291, 519, 11, 457, 456, 311, 12668, 295, 819, 27599, 7705, 411, 2086, 11, 309, 311, 472, 2445, 11, 51428], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 683, "seek": 340828, "start": 3429.5600000000004, "end": 3433.96, "text": " you take all the arguments in, and you change the allocation mode is an allocation alloc free,", "tokens": [51428, 291, 747, 439, 264, 12869, 294, 11, 293, 291, 1319, 264, 27599, 4391, 307, 364, 27599, 12660, 1737, 11, 51648], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 684, "seek": 340828, "start": 3433.96, "end": 3437.6400000000003, "text": " free or resize query features query and for an alloc non zero. Because sometimes you want to be", "tokens": [51648, 1737, 420, 50069, 14581, 4122, 14581, 293, 337, 364, 12660, 2107, 4018, 13, 1436, 2171, 291, 528, 281, 312, 51832], "temperature": 0.0, "avg_logprob": -0.14834455164467417, "compression_ratio": 1.9558823529411764, "no_speech_prob": 0.025067387148737907}, {"id": 685, "seek": 343764, "start": 3437.64, "end": 3442.04, "text": " allocated without a zero, but by default you want zeroed because it's quite useful. And also it's", "tokens": [50364, 29772, 1553, 257, 4018, 11, 457, 538, 7576, 291, 528, 4018, 292, 570, 309, 311, 1596, 4420, 13, 400, 611, 309, 311, 50584], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 686, "seek": 343764, "start": 3442.04, "end": 3446.3599999999997, "text": " pretty much free if you're using like virtual memory, like allocating zero memory is pretty much", "tokens": [50584, 1238, 709, 1737, 498, 291, 434, 1228, 411, 6374, 4675, 11, 411, 12660, 990, 4018, 4675, 307, 1238, 709, 50800], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 687, "seek": 343764, "start": 3446.3599999999997, "end": 3451.48, "text": " free. Because it has to be for security benefits. There's no option to not get it if you ask for", "tokens": [50800, 1737, 13, 1436, 309, 575, 281, 312, 337, 3825, 5311, 13, 821, 311, 572, 3614, 281, 406, 483, 309, 498, 291, 1029, 337, 51056], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 688, "seek": 343764, "start": 3451.48, "end": 3457.08, "text": " virtual memory. So I'm just trying to show here that I already take advantage of this kind of", "tokens": [51056, 6374, 4675, 13, 407, 286, 478, 445, 1382, 281, 855, 510, 300, 286, 1217, 747, 5002, 295, 341, 733, 295, 51336], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 689, "seek": 343764, "start": 3457.08, "end": 3461.3199999999997, "text": " approach. And then within every single allocator, I have a switch statement which then pairs each", "tokens": [51336, 3109, 13, 400, 550, 1951, 633, 2167, 12660, 1639, 11, 286, 362, 257, 3679, 5629, 597, 550, 15494, 1184, 51548], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 690, "seek": 343764, "start": 3461.3199999999997, "end": 3466.12, "text": " operation together. So I'm just trying to get off my digression a bit here. So this is what case", "tokens": [51548, 6916, 1214, 13, 407, 286, 478, 445, 1382, 281, 483, 766, 452, 2528, 2775, 257, 857, 510, 13, 407, 341, 307, 437, 1389, 51788], "temperature": 0.0, "avg_logprob": -0.0898928165435791, "compression_ratio": 1.7956656346749227, "no_speech_prob": 0.011654616333544254}, {"id": 691, "seek": 346612, "start": 3466.12, "end": 3469.7999999999997, "text": " is kind of trying to say and you could do this. So you're not having the full on inheritance style,", "tokens": [50364, 307, 733, 295, 1382, 281, 584, 293, 291, 727, 360, 341, 13, 407, 291, 434, 406, 1419, 264, 1577, 322, 32122, 3758, 11, 50548], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 692, "seek": 346612, "start": 3469.7999999999997, "end": 3473.56, "text": " you just have a switch you could do the blend of the two. And there are benefits to this,", "tokens": [50548, 291, 445, 362, 257, 3679, 291, 727, 360, 264, 10628, 295, 264, 732, 13, 400, 456, 366, 5311, 281, 341, 11, 50736], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 693, "seek": 346612, "start": 3473.56, "end": 3479.16, "text": " obviously. And you'd have all of this lovely. So because in either case, but this is larger", "tokens": [50736, 2745, 13, 400, 291, 1116, 362, 439, 295, 341, 7496, 13, 407, 570, 294, 2139, 1389, 11, 457, 341, 307, 4833, 51016], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 694, "seek": 346612, "start": 3479.16, "end": 3483.3199999999997, "text": " rather than because it's solely look look up map look up now and to a specific device and it can", "tokens": [51016, 2831, 813, 570, 309, 311, 23309, 574, 574, 493, 4471, 574, 493, 586, 293, 281, 257, 2685, 4302, 293, 309, 393, 51224], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 695, "seek": 346612, "start": 3483.3199999999997, "end": 3487.48, "text": " be used in either design. Anyway, over the course of the development of the OS, I think the implementation", "tokens": [51224, 312, 1143, 294, 2139, 1715, 13, 5684, 11, 670, 264, 1164, 295, 264, 3250, 295, 264, 12731, 11, 286, 519, 264, 11420, 51432], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 696, "seek": 346612, "start": 3487.48, "end": 3492.04, "text": " saves programmers and cycles potentially a lot of them compared to the one I understand believed", "tokens": [51432, 19155, 41504, 293, 17796, 7263, 257, 688, 295, 552, 5347, 281, 264, 472, 286, 1223, 7847, 51660], "temperature": 0.0, "avg_logprob": -0.15770749078280683, "compression_ratio": 1.7852760736196318, "no_speech_prob": 0.05680948868393898}, {"id": 697, "seek": 349204, "start": 3492.04, "end": 3498.12, "text": " you favored by the clean code method. Again, which is interesting because the casey one is", "tokens": [50364, 291, 44420, 538, 264, 2541, 3089, 3170, 13, 3764, 11, 597, 307, 1880, 570, 264, 1389, 88, 472, 307, 50668], "temperature": 0.0, "avg_logprob": -0.19070006543257106, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.017863338813185692}, {"id": 698, "seek": 349204, "start": 3498.12, "end": 3502.84, "text": " closer to being like, sub typing to a sentence, but there isn't sub typing, it's just like,", "tokens": [50668, 4966, 281, 885, 411, 11, 1422, 18444, 281, 257, 8174, 11, 457, 456, 1943, 380, 1422, 18444, 11, 309, 311, 445, 411, 11, 50904], "temperature": 0.0, "avg_logprob": -0.19070006543257106, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.017863338813185692}, {"id": 699, "seek": 349204, "start": 3502.84, "end": 3508.2, "text": " here's the abstract thing with a function pointer, deal with it. Which is kind of close to inheritance,", "tokens": [50904, 510, 311, 264, 12649, 551, 365, 257, 2445, 23918, 11, 2028, 365, 309, 13, 3013, 307, 733, 295, 1998, 281, 32122, 11, 51172], "temperature": 0.0, "avg_logprob": -0.19070006543257106, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.017863338813185692}, {"id": 700, "seek": 349204, "start": 3508.2, "end": 3512.7599999999998, "text": " but it's not just one. And it sounds like a minor difference people say, oh, it's equivalent. It's", "tokens": [51172, 457, 309, 311, 406, 445, 472, 13, 400, 309, 3263, 411, 257, 6696, 2649, 561, 584, 11, 1954, 11, 309, 311, 10344, 13, 467, 311, 51400], "temperature": 0.0, "avg_logprob": -0.19070006543257106, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.017863338813185692}, {"id": 701, "seek": 349204, "start": 3512.7599999999998, "end": 3518.04, "text": " like, but it isn't equivalent. In fact, it will be faster. You can easily measure it. It'll be easier", "tokens": [51400, 411, 11, 457, 309, 1943, 380, 10344, 13, 682, 1186, 11, 309, 486, 312, 4663, 13, 509, 393, 3612, 3481, 309, 13, 467, 603, 312, 3571, 51664], "temperature": 0.0, "avg_logprob": -0.19070006543257106, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.017863338813185692}, {"id": 702, "seek": 351804, "start": 3518.04, "end": 3521.88, "text": " to maintain because everything's in there. And not just that, if you add a new operation into", "tokens": [50364, 281, 6909, 570, 1203, 311, 294, 456, 13, 400, 406, 445, 300, 11, 498, 291, 909, 257, 777, 6916, 666, 50556], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 703, "seek": 351804, "start": 3521.88, "end": 3524.92, "text": " there, every single one will just yell at you anyway, because you've not implemented it.", "tokens": [50556, 456, 11, 633, 2167, 472, 486, 445, 20525, 412, 291, 4033, 11, 570, 291, 600, 406, 12270, 309, 13, 50708], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 704, "seek": 351804, "start": 3526.2799999999997, "end": 3529.96, "text": " So if you've got a language that tells you that switch name is not necessarily C or C++,", "tokens": [50776, 407, 498, 291, 600, 658, 257, 2856, 300, 5112, 291, 300, 3679, 1315, 307, 406, 4725, 383, 420, 383, 25472, 11, 50960], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 705, "seek": 351804, "start": 3529.96, "end": 3535.48, "text": " maybe modern C++, I know, I think. And sometimes C with the, when you have warnings all and", "tokens": [50960, 1310, 4363, 383, 25472, 11, 286, 458, 11, 286, 519, 13, 400, 2171, 383, 365, 264, 11, 562, 291, 362, 30009, 439, 293, 51236], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 706, "seek": 351804, "start": 3535.48, "end": 3538.36, "text": " everything will tell you switch name is missing certain cases. But yeah.", "tokens": [51236, 1203, 486, 980, 291, 3679, 1315, 307, 5361, 1629, 3331, 13, 583, 1338, 13, 51380], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 707, "seek": 351804, "start": 3541.16, "end": 3544.04, "text": " And cases look, I don't know if it's a bit of an extract and file, because I'm sick,", "tokens": [51520, 400, 3331, 574, 11, 286, 500, 380, 458, 498, 309, 311, 257, 857, 295, 364, 8947, 293, 3991, 11, 570, 286, 478, 4998, 11, 51664], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 708, "seek": 351804, "start": 3544.04, "end": 3547.08, "text": " but it was the first one you brought up. And it happened to be the contrast,", "tokens": [51664, 457, 309, 390, 264, 700, 472, 291, 3038, 493, 13, 400, 309, 2011, 281, 312, 264, 8712, 11, 51816], "temperature": 0.0, "avg_logprob": -0.26294885450793853, "compression_ratio": 1.7640117994100295, "no_speech_prob": 0.08848204463720322}, {"id": 709, "seek": 354708, "start": 3547.08, "end": 3550.7599999999998, "text": " the two designs in my opinion. So it works, works for me as Casey is saying here.", "tokens": [50364, 264, 732, 11347, 294, 452, 4800, 13, 407, 309, 1985, 11, 1985, 337, 385, 382, 27369, 307, 1566, 510, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 710, "seek": 354708, "start": 3551.96, "end": 3557.7999999999997, "text": " Here's why I think an enum based design deserves the programmer cycles. In most systems, you don't", "tokens": [50608, 1692, 311, 983, 286, 519, 364, 465, 449, 2361, 1715, 17037, 264, 32116, 17796, 13, 682, 881, 3652, 11, 291, 500, 380, 50900], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 711, "seek": 354708, "start": 3557.7999999999997, "end": 3561.56, "text": " know all the functions that are going to be used ahead of time when operating costs are hard boundary,", "tokens": [50900, 458, 439, 264, 6828, 300, 366, 516, 281, 312, 1143, 2286, 295, 565, 562, 7447, 5497, 366, 1152, 12866, 11, 51088], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 712, "seek": 354708, "start": 3561.56, "end": 3565.48, "text": " like a driver, using operation codes instead of virtual function calls allows you to add more", "tokens": [51088, 411, 257, 6787, 11, 1228, 6916, 14211, 2602, 295, 6374, 2445, 5498, 4045, 291, 281, 909, 544, 51284], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 713, "seek": 354708, "start": 3565.48, "end": 3571.08, "text": " functions dynamically without recompiling all our drivers. In any modern operating system,", "tokens": [51284, 6828, 43492, 1553, 48000, 4883, 439, 527, 11590, 13, 682, 604, 4363, 7447, 1185, 11, 51564], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 714, "seek": 354708, "start": 3571.08, "end": 3574.52, "text": " multi-threading is a concern. But this is especially true for an operating system,", "tokens": [51564, 4825, 12, 392, 35908, 307, 257, 3136, 13, 583, 341, 307, 2318, 2074, 337, 364, 7447, 1185, 11, 51736], "temperature": 0.0, "avg_logprob": -0.1321790786016555, "compression_ratio": 1.7381703470031546, "no_speech_prob": 0.00453293789178133}, {"id": 715, "seek": 357452, "start": 3574.52, "end": 3580.2, "text": " having the protocol be structured based with an operation code allows us to trivially buffer", "tokens": [50364, 1419, 264, 10336, 312, 18519, 2361, 365, 364, 6916, 3089, 4045, 505, 281, 1376, 85, 2270, 21762, 50648], "temperature": 0.0, "avg_logprob": -0.22345390319824218, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.03295924514532089}, {"id": 716, "seek": 357452, "start": 3580.2, "end": 3587.32, "text": " operations in things like IO rings and other intermediaries, intermediaries, without writing", "tokens": [50648, 7705, 294, 721, 411, 39839, 11136, 293, 661, 15184, 4889, 11, 15184, 4889, 11, 1553, 3579, 51004], "temperature": 0.0, "avg_logprob": -0.22345390319824218, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.03295924514532089}, {"id": 717, "seek": 357452, "start": 3587.32, "end": 3592.68, "text": " any new code. The entire system remains identical. Yeah, I'm just trying to do this. And you just", "tokens": [51004, 604, 777, 3089, 13, 440, 2302, 1185, 7023, 14800, 13, 865, 11, 286, 478, 445, 1382, 281, 360, 341, 13, 400, 291, 445, 51272], "temperature": 0.0, "avg_logprob": -0.22345390319824218, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.03295924514532089}, {"id": 718, "seek": 357452, "start": 3592.68, "end": 3596.92, "text": " said, this is by the way, it seems like almost happens in almost all systems, OOP systems,", "tokens": [51272, 848, 11, 341, 307, 538, 264, 636, 11, 309, 2544, 411, 1920, 2314, 294, 1920, 439, 3652, 11, 422, 12059, 3652, 11, 51484], "temperature": 0.0, "avg_logprob": -0.22345390319824218, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.03295924514532089}, {"id": 719, "seek": 357452, "start": 3596.92, "end": 3601.64, "text": " I see, I'm trying to get around pronunciation, say, because eventually they need to serialize", "tokens": [51484, 286, 536, 11, 286, 478, 1382, 281, 483, 926, 23338, 11, 584, 11, 570, 4728, 436, 643, 281, 17436, 1125, 51720], "temperature": 0.0, "avg_logprob": -0.22345390319824218, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.03295924514532089}, {"id": 720, "seek": 360164, "start": 3601.72, "end": 3607.8799999999997, "text": " or something similar. And so they have to write my version as well as the version as their version,", "tokens": [50368, 420, 746, 2531, 13, 400, 370, 436, 362, 281, 2464, 452, 3037, 382, 731, 382, 264, 3037, 382, 641, 3037, 11, 50676], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 721, "seek": 360164, "start": 3607.8799999999997, "end": 3610.8399999999997, "text": " but they don't seem to realize how much time they're wasting. Like, yeah, this is", "tokens": [50676, 457, 436, 500, 380, 1643, 281, 4325, 577, 709, 565, 436, 434, 20457, 13, 1743, 11, 1338, 11, 341, 307, 50824], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 722, "seek": 360164, "start": 3611.72, "end": 3616.2799999999997, "text": " clarifying this point. People think this seems like the clean code will actually save time,", "tokens": [50868, 6093, 5489, 341, 935, 13, 3432, 519, 341, 2544, 411, 264, 2541, 3089, 486, 767, 3155, 565, 11, 51096], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 723, "seek": 360164, "start": 3616.2799999999997, "end": 3618.7599999999998, "text": " but it's actually no, you're now forcing another person to write the same thing again.", "tokens": [51096, 457, 309, 311, 767, 572, 11, 291, 434, 586, 19030, 1071, 954, 281, 2464, 264, 912, 551, 797, 13, 51220], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 724, "seek": 360164, "start": 3619.4, "end": 3622.92, "text": " And you are actually wasting time, you think you're saving things. But again,", "tokens": [51252, 400, 291, 366, 767, 20457, 565, 11, 291, 519, 291, 434, 6816, 721, 13, 583, 797, 11, 51428], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 725, "seek": 360164, "start": 3622.92, "end": 3626.44, "text": " if you want to know if you're saving time, you're making a statement like this will save", "tokens": [51428, 498, 291, 528, 281, 458, 498, 291, 434, 6816, 565, 11, 291, 434, 1455, 257, 5629, 411, 341, 486, 3155, 51604], "temperature": 0.0, "avg_logprob": -0.15628257278324098, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.021898960694670677}, {"id": 726, "seek": 362644, "start": 3626.52, "end": 3631.2400000000002, "text": " programmer cycles, like a claim, show the evidence. And don't just say, well,", "tokens": [50368, 32116, 17796, 11, 411, 257, 3932, 11, 855, 264, 4467, 13, 400, 500, 380, 445, 584, 11, 731, 11, 50604], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 727, "seek": 362644, "start": 3631.2400000000002, "end": 3637.32, "text": " my your seniors may agree with me, because they were convinced by my argument. It's like, yeah,", "tokens": [50604, 452, 428, 21069, 815, 3986, 365, 385, 11, 570, 436, 645, 12561, 538, 452, 6770, 13, 467, 311, 411, 11, 1338, 11, 50908], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 728, "seek": 362644, "start": 3637.32, "end": 3641.8, "text": " but where's the evidence, regardless of this authority, this later argument by authority.", "tokens": [50908, 457, 689, 311, 264, 4467, 11, 10060, 295, 341, 8281, 11, 341, 1780, 6770, 538, 8281, 13, 51132], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 729, "seek": 362644, "start": 3643.0, "end": 3647.7200000000003, "text": " It is the after a while, many people will come out the phase and like, oh, I don't do this", "tokens": [51192, 467, 307, 264, 934, 257, 1339, 11, 867, 561, 486, 808, 484, 264, 5574, 293, 411, 11, 1954, 11, 286, 500, 380, 360, 341, 51428], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 730, "seek": 362644, "start": 3647.7200000000003, "end": 3652.36, "text": " anyway. But some people don't. And it's like, okay, I never really went through the OOP phase", "tokens": [51428, 4033, 13, 583, 512, 561, 500, 380, 13, 400, 309, 311, 411, 11, 1392, 11, 286, 1128, 534, 1437, 807, 264, 422, 12059, 5574, 51660], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 731, "seek": 362644, "start": 3652.36, "end": 3655.96, "text": " myself. Going a bit of a digression here. Sorry, this is completely random today. I know.", "tokens": [51660, 2059, 13, 10963, 257, 857, 295, 257, 2528, 2775, 510, 13, 4919, 11, 341, 307, 2584, 4974, 965, 13, 286, 458, 13, 51840], "temperature": 0.0, "avg_logprob": -0.19224134404608545, "compression_ratio": 1.6918238993710693, "no_speech_prob": 0.13414280116558075}, {"id": 732, "seek": 365644, "start": 3656.68, "end": 3663.32, "text": " Very, very unstructured. But I went through the modern C++ like 11 phase. So that's what", "tokens": [50376, 4372, 11, 588, 18799, 46847, 13, 583, 286, 1437, 807, 264, 4363, 383, 25472, 411, 2975, 5574, 13, 407, 300, 311, 437, 50708], "temperature": 0.0, "avg_logprob": -0.1494576611856776, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.009860973805189133}, {"id": 733, "seek": 365644, "start": 3663.32, "end": 3669.64, "text": " 12 years ago now, probably a bit before actually, because it was C plus plus zero x for a long time.", "tokens": [50708, 2272, 924, 2057, 586, 11, 1391, 257, 857, 949, 767, 11, 570, 309, 390, 383, 1804, 1804, 4018, 2031, 337, 257, 938, 565, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1494576611856776, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.009860973805189133}, {"id": 734, "seek": 365644, "start": 3671.7200000000003, "end": 3674.76, "text": " And I remember learning all that stuff. And that was the thing I got caught. I wasn't really", "tokens": [51128, 400, 286, 1604, 2539, 439, 300, 1507, 13, 400, 300, 390, 264, 551, 286, 658, 5415, 13, 286, 2067, 380, 534, 51280], "temperature": 0.0, "avg_logprob": -0.1494576611856776, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.009860973805189133}, {"id": 735, "seek": 365644, "start": 3674.76, "end": 3678.84, "text": " necessarily the OOP phase. It was that phase. I was learning all that stuff. And it was a while", "tokens": [51280, 4725, 264, 422, 12059, 5574, 13, 467, 390, 300, 5574, 13, 286, 390, 2539, 439, 300, 1507, 13, 400, 309, 390, 257, 1339, 51484], "temperature": 0.0, "avg_logprob": -0.1494576611856776, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.009860973805189133}, {"id": 736, "seek": 365644, "start": 3678.84, "end": 3683.2400000000002, "text": " took me a few years and after was like, I'm doing all this extra code, writing loads, and I'm not", "tokens": [51484, 1890, 385, 257, 1326, 924, 293, 934, 390, 411, 11, 286, 478, 884, 439, 341, 2857, 3089, 11, 3579, 12668, 11, 293, 286, 478, 406, 51704], "temperature": 0.0, "avg_logprob": -0.1494576611856776, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.009860973805189133}, {"id": 737, "seek": 368324, "start": 3683.24, "end": 3687.64, "text": " getting any more productive. In fact, it's how hard to maintain. I'm writing literally 10 times", "tokens": [50364, 1242, 604, 544, 13304, 13, 682, 1186, 11, 309, 311, 577, 1152, 281, 6909, 13, 286, 478, 3579, 3736, 1266, 1413, 50584], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 738, "seek": 368324, "start": 3687.64, "end": 3691.3199999999997, "text": " more code than I needed. And they kept telling people kept people kept telling me because I was", "tokens": [50584, 544, 3089, 813, 286, 2978, 13, 400, 436, 4305, 3585, 561, 4305, 561, 4305, 3585, 385, 570, 286, 390, 50768], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 739, "seek": 368324, "start": 3691.3199999999997, "end": 3695.16, "text": " kind of trusting these people who were more thought they were more experienced with me or", "tokens": [50768, 733, 295, 28235, 613, 561, 567, 645, 544, 1194, 436, 645, 544, 6751, 365, 385, 420, 50960], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 740, "seek": 368324, "start": 3695.16, "end": 3697.9599999999996, "text": " they thought they knew more because they've been doing it for longer. And they were talking from", "tokens": [50960, 436, 1194, 436, 2586, 544, 570, 436, 600, 668, 884, 309, 337, 2854, 13, 400, 436, 645, 1417, 490, 51100], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 741, "seek": 368324, "start": 3697.9599999999996, "end": 3702.8399999999997, "text": " positions of authority to a certain extent that they were going, Oh, of course.", "tokens": [51100, 8432, 295, 8281, 281, 257, 1629, 8396, 300, 436, 645, 516, 11, 876, 11, 295, 1164, 13, 51344], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 742, "seek": 368324, "start": 3705.08, "end": 3707.9599999999996, "text": " Like, of course, this is going better because I'm telling you it's going to be better. I'm like,", "tokens": [51456, 1743, 11, 295, 1164, 11, 341, 307, 516, 1101, 570, 286, 478, 3585, 291, 309, 311, 516, 281, 312, 1101, 13, 286, 478, 411, 11, 51600], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 743, "seek": 368324, "start": 3707.9599999999996, "end": 3711.24, "text": " and then I was kind of believing them. And I was like, it doesn't seem like I'm trusting them.", "tokens": [51600, 293, 550, 286, 390, 733, 295, 16594, 552, 13, 400, 286, 390, 411, 11, 309, 1177, 380, 1643, 411, 286, 478, 28235, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16041325611673343, "compression_ratio": 1.9578313253012047, "no_speech_prob": 0.11763187497854233}, {"id": 744, "seek": 371124, "start": 3711.8799999999997, "end": 3715.3999999999996, "text": " But it didn't it didn't seem to the case when I just started programming back to like a normal", "tokens": [50396, 583, 309, 994, 380, 309, 994, 380, 1643, 281, 264, 1389, 562, 286, 445, 1409, 9410, 646, 281, 411, 257, 2710, 50572], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 745, "seek": 371124, "start": 3715.3999999999996, "end": 3719.4799999999996, "text": " basic C style with switch statements in many cases, and just like normal standalone functions,", "tokens": [50572, 3875, 383, 3758, 365, 3679, 12363, 294, 867, 3331, 11, 293, 445, 411, 2710, 37454, 6828, 11, 50776], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 746, "seek": 371124, "start": 3719.4799999999996, "end": 3724.2799999999997, "text": " no, not even using methods. I got more productive. My code got smaller, got easier to read,", "tokens": [50776, 572, 11, 406, 754, 1228, 7150, 13, 286, 658, 544, 13304, 13, 1222, 3089, 658, 4356, 11, 658, 3571, 281, 1401, 11, 51016], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 747, "seek": 371124, "start": 3725.16, "end": 3730.4399999999996, "text": " just by not doing any of that. And it was kind of like not using not doing any of the stupid", "tokens": [51060, 445, 538, 406, 884, 604, 295, 300, 13, 400, 309, 390, 733, 295, 411, 406, 1228, 406, 884, 604, 295, 264, 6631, 51324], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 748, "seek": 371124, "start": 3730.4399999999996, "end": 3734.3599999999997, "text": " templates, not doing stupid any of the ownership semantics. I'm not saying ownership semantics", "tokens": [51324, 21165, 11, 406, 884, 6631, 604, 295, 264, 15279, 4361, 45298, 13, 286, 478, 406, 1566, 15279, 4361, 45298, 51520], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 749, "seek": 371124, "start": 3734.3599999999997, "end": 3739.24, "text": " stupid. I'm just saying the being everywhere was like, look, I just kind of went to more", "tokens": [51520, 6631, 13, 286, 478, 445, 1566, 264, 885, 5315, 390, 411, 11, 574, 11, 286, 445, 733, 295, 1437, 281, 544, 51764], "temperature": 0.0, "avg_logprob": -0.15989067975212545, "compression_ratio": 1.878787878787879, "no_speech_prob": 0.017948590219020844}, {"id": 750, "seek": 373924, "start": 3739.24, "end": 3744.7599999999998, "text": " pod data was a plain old data data kind of style old fashioned C style, my code just got", "tokens": [50364, 714, 67, 1412, 390, 257, 11121, 1331, 1412, 1412, 733, 295, 3758, 1331, 40646, 383, 3758, 11, 452, 3089, 445, 658, 50640], "temperature": 0.0, "avg_logprob": -0.13348478131589636, "compression_ratio": 1.8046875, "no_speech_prob": 0.050124675035476685}, {"id": 751, "seek": 373924, "start": 3744.7599999999998, "end": 3749.16, "text": " easier to read more maintainable and just everything like from a personal perspective,", "tokens": [50640, 3571, 281, 1401, 544, 6909, 712, 293, 445, 1203, 411, 490, 257, 2973, 4585, 11, 50860], "temperature": 0.0, "avg_logprob": -0.13348478131589636, "compression_ratio": 1.8046875, "no_speech_prob": 0.050124675035476685}, {"id": 752, "seek": 373924, "start": 3749.16, "end": 3753.7999999999997, "text": " again, I cannot measure this. And the only way I can convince people say, here's my code, here's", "tokens": [50860, 797, 11, 286, 2644, 3481, 341, 13, 400, 264, 787, 636, 286, 393, 13447, 561, 584, 11, 510, 311, 452, 3089, 11, 510, 311, 51092], "temperature": 0.0, "avg_logprob": -0.13348478131589636, "compression_ratio": 1.8046875, "no_speech_prob": 0.050124675035476685}, {"id": 753, "seek": 373924, "start": 3753.7999999999997, "end": 3758.12, "text": " this normal code, which one define easier to read. And that's the only way that's not a measuring", "tokens": [51092, 341, 2710, 3089, 11, 597, 472, 6964, 3571, 281, 1401, 13, 400, 300, 311, 264, 787, 636, 300, 311, 406, 257, 13389, 51308], "temperature": 0.0, "avg_logprob": -0.13348478131589636, "compression_ratio": 1.8046875, "no_speech_prob": 0.050124675035476685}, {"id": 754, "seek": 373924, "start": 3758.12, "end": 3761.8799999999997, "text": " that's just still like a personal preference thing in the day. This is the problem in these", "tokens": [51308, 300, 311, 445, 920, 411, 257, 2973, 17502, 551, 294, 264, 786, 13, 639, 307, 264, 1154, 294, 613, 51496], "temperature": 0.0, "avg_logprob": -0.13348478131589636, "compression_ratio": 1.8046875, "no_speech_prob": 0.050124675035476685}, {"id": 755, "seek": 376188, "start": 3761.88, "end": 3771.7200000000003, "text": " discussions. And it is just getting down to that. It's like one side is there is an empirical", "tokens": [50364, 11088, 13, 400, 309, 307, 445, 1242, 760, 281, 300, 13, 467, 311, 411, 472, 1252, 307, 456, 307, 364, 31886, 50856], "temperature": 0.0, "avg_logprob": -0.18958542264741043, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.2583109736442566}, {"id": 756, "seek": 376188, "start": 3771.7200000000003, "end": 3776.2000000000003, "text": " thing to a certain extent, which I'm going to comment right at the end. I will get to this,", "tokens": [50856, 551, 281, 257, 1629, 8396, 11, 597, 286, 478, 516, 281, 2871, 558, 412, 264, 917, 13, 286, 486, 483, 281, 341, 11, 51080], "temperature": 0.0, "avg_logprob": -0.18958542264741043, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.2583109736442566}, {"id": 757, "seek": 376188, "start": 3776.2000000000003, "end": 3781.8, "text": " don't worry. But he talks about this saying here at any point things, if we would like to", "tokens": [51080, 500, 380, 3292, 13, 583, 415, 6686, 466, 341, 1566, 510, 412, 604, 935, 721, 11, 498, 321, 576, 411, 281, 51360], "temperature": 0.0, "avg_logprob": -0.18958542264741043, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.2583109736442566}, {"id": 758, "seek": 376188, "start": 3781.8, "end": 3784.28, "text": " buy third parties to allow communication with channels on the devices, blah, blah, blah,", "tokens": [51360, 2256, 2636, 8265, 281, 2089, 6101, 365, 9235, 322, 264, 5759, 11, 12288, 11, 12288, 11, 12288, 11, 51484], "temperature": 0.0, "avg_logprob": -0.18958542264741043, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.2583109736442566}, {"id": 759, "seek": 376188, "start": 3784.28, "end": 3788.6, "text": " okay, we're talking about the IO stuff, fine. We're getting nearly getting the answers. So", "tokens": [51484, 1392, 11, 321, 434, 1417, 466, 264, 39839, 1507, 11, 2489, 13, 492, 434, 1242, 6217, 1242, 264, 6338, 13, 407, 51700], "temperature": 0.0, "avg_logprob": -0.18958542264741043, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.2583109736442566}, {"id": 760, "seek": 378860, "start": 3788.6, "end": 3792.52, "text": " Mr. Martin says, okay, I think I see where we're going. So let me say, sure, looks good to me,", "tokens": [50364, 2221, 13, 9184, 1619, 11, 1392, 11, 286, 519, 286, 536, 689, 321, 434, 516, 13, 407, 718, 385, 584, 11, 988, 11, 1542, 665, 281, 385, 11, 50560], "temperature": 0.0, "avg_logprob": -0.13805743626185826, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.014887663535773754}, {"id": 761, "seek": 378860, "start": 3792.52, "end": 3797.64, "text": " the bullet points you added are after the fact are all quite valid. And the design you picks", "tokens": [50560, 264, 11632, 2793, 291, 3869, 366, 934, 264, 1186, 366, 439, 1596, 7363, 13, 400, 264, 1715, 291, 16137, 50816], "temperature": 0.0, "avg_logprob": -0.13805743626185826, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.014887663535773754}, {"id": 762, "seek": 378860, "start": 3797.64, "end": 3801.48, "text": " works well in this case. In the first point, you assume that operations will increase beyond", "tokens": [50816, 1985, 731, 294, 341, 1389, 13, 682, 264, 700, 935, 11, 291, 6552, 300, 7705, 486, 3488, 4399, 51008], "temperature": 0.0, "avg_logprob": -0.13805743626185826, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.014887663535773754}, {"id": 763, "seek": 378860, "start": 3801.48, "end": 3808.2, "text": " the two original proposed, as we both agreed, as I wrote in the clean code, which, by the way,", "tokens": [51008, 264, 732, 3380, 10348, 11, 382, 321, 1293, 9166, 11, 382, 286, 4114, 294, 264, 2541, 3089, 11, 597, 11, 538, 264, 636, 11, 51344], "temperature": 0.0, "avg_logprob": -0.13805743626185826, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.014887663535773754}, {"id": 764, "seek": 378860, "start": 3808.2, "end": 3814.2799999999997, "text": " is not the same as your clean code. Right, when operation periphery more rapidly type", "tokens": [51344, 307, 406, 264, 912, 382, 428, 2541, 3089, 13, 1779, 11, 562, 6916, 26807, 88, 544, 12910, 2010, 51648], "temperature": 0.0, "avg_logprob": -0.13805743626185826, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.014887663535773754}, {"id": 765, "seek": 381428, "start": 3814.28, "end": 3822.1200000000003, "text": " switch statements are better. So there's that line alone is or another rhetoric trick,", "tokens": [50364, 3679, 12363, 366, 1101, 13, 407, 456, 311, 300, 1622, 3312, 307, 420, 1071, 29604, 4282, 11, 50756], "temperature": 0.0, "avg_logprob": -0.1363108049739491, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.032547369599342346}, {"id": 766, "seek": 381428, "start": 3822.1200000000003, "end": 3827.0800000000004, "text": " lovely one, in fact, in my opinion. In the first point, you assume that operations will increase", "tokens": [50756, 7496, 472, 11, 294, 1186, 11, 294, 452, 4800, 13, 682, 264, 700, 935, 11, 291, 6552, 300, 7705, 486, 3488, 51004], "temperature": 0.0, "avg_logprob": -0.1363108049739491, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.032547369599342346}, {"id": 767, "seek": 381428, "start": 3827.0800000000004, "end": 3835.5600000000004, "text": " beyond the two originally proposed. Okay, as we both agreed, I don't think Casey agreed to anything.", "tokens": [51004, 4399, 264, 732, 7993, 10348, 13, 1033, 11, 382, 321, 1293, 9166, 11, 286, 500, 380, 519, 27369, 9166, 281, 1340, 13, 51428], "temperature": 0.0, "avg_logprob": -0.1363108049739491, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.032547369599342346}, {"id": 768, "seek": 381428, "start": 3836.92, "end": 3840.84, "text": " And secondly, Casey's not calling what he claims clean code, he's trying to understand", "tokens": [51496, 400, 26246, 11, 27369, 311, 406, 5141, 437, 415, 9441, 2541, 3089, 11, 415, 311, 1382, 281, 1223, 51692], "temperature": 0.0, "avg_logprob": -0.1363108049739491, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.032547369599342346}, {"id": 769, "seek": 384084, "start": 3840.84, "end": 3846.6800000000003, "text": " what your clean code is Casey never says his code is clean code, because yours is Mr. Martin's", "tokens": [50364, 437, 428, 2541, 3089, 307, 27369, 1128, 1619, 702, 3089, 307, 2541, 3089, 11, 570, 6342, 307, 2221, 13, 9184, 311, 50656], "temperature": 0.0, "avg_logprob": -0.1693255278441283, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.011681973934173584}, {"id": 770, "seek": 384084, "start": 3846.6800000000003, "end": 3855.4, "text": " clean code with a capital C trademark to kind of think. Yeah. So another little kind of trick he", "tokens": [50656, 2541, 3089, 365, 257, 4238, 383, 31361, 281, 733, 295, 519, 13, 865, 13, 407, 1071, 707, 733, 295, 4282, 415, 51092], "temperature": 0.0, "avg_logprob": -0.1693255278441283, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.011681973934173584}, {"id": 771, "seek": 384084, "start": 3855.4, "end": 3860.76, "text": " does already any can't help himself really. So when operations profite more rapidly type switch", "tokens": [51092, 775, 1217, 604, 393, 380, 854, 3647, 534, 13, 407, 562, 7705, 1740, 642, 544, 12910, 2010, 3679, 51360], "temperature": 0.0, "avg_logprob": -0.1693255278441283, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.011681973934173584}, {"id": 772, "seek": 384084, "start": 3860.76, "end": 3864.92, "text": " statements are better. In point two and three, you raise the specter of multi threatening,", "tokens": [51360, 12363, 366, 1101, 13, 682, 935, 732, 293, 1045, 11, 291, 5300, 264, 6177, 260, 295, 4825, 20768, 11, 51568], "temperature": 0.0, "avg_logprob": -0.1693255278441283, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.011681973934173584}, {"id": 773, "seek": 384084, "start": 3864.92, "end": 3869.4, "text": " you are of course correct that queuing operations is a lot easier. If you request packets of the", "tokens": [51568, 291, 366, 295, 1164, 3006, 300, 631, 9635, 7705, 307, 257, 688, 3571, 13, 759, 291, 5308, 30364, 295, 264, 51792], "temperature": 0.0, "avg_logprob": -0.1693255278441283, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.011681973934173584}, {"id": 774, "seek": 386940, "start": 3869.48, "end": 3874.6, "text": " same type you design no argument there. And the last point proposed a kind of hook for unknown", "tokens": [50368, 912, 2010, 291, 1715, 572, 6770, 456, 13, 400, 264, 1036, 935, 10348, 257, 733, 295, 6328, 337, 9841, 50624], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 775, "seek": 386940, "start": 3874.6, "end": 3880.12, "text": " and unspecified possibilities in the future. Yeah, so what he says is like, okay, you have the general", "tokens": [50624, 293, 2693, 494, 66, 2587, 12178, 294, 264, 2027, 13, 865, 11, 370, 437, 415, 1619, 307, 411, 11, 1392, 11, 291, 362, 264, 2674, 50900], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 776, "seek": 386940, "start": 3880.12, "end": 3884.44, "text": " cases and then have a hook for the unknown cases like the open cases. Okay, if you think those", "tokens": [50900, 3331, 293, 550, 362, 257, 6328, 337, 264, 9841, 3331, 411, 264, 1269, 3331, 13, 1033, 11, 498, 291, 519, 729, 51116], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 777, "seek": 386940, "start": 3884.44, "end": 3888.76, "text": " unknown cases and special are likely, then you should have considered them earlier. But then", "tokens": [51116, 9841, 3331, 293, 2121, 366, 3700, 11, 550, 291, 820, 362, 4888, 552, 3071, 13, 583, 550, 51332], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 778, "seek": 386940, "start": 3888.76, "end": 3892.84, "text": " that raises a number of other concerns that we should not likely address in this document. It's", "tokens": [51332, 300, 19658, 257, 1230, 295, 661, 7389, 300, 321, 820, 406, 3700, 2985, 294, 341, 4166, 13, 467, 311, 51536], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 779, "seek": 386940, "start": 3892.84, "end": 3897.7200000000003, "text": " like, no, no, no. So I think I'll let pass. No, why? Because if you didn't, he has to let that pass", "tokens": [51536, 411, 11, 572, 11, 572, 11, 572, 13, 407, 286, 519, 286, 603, 718, 1320, 13, 883, 11, 983, 30, 1436, 498, 291, 994, 380, 11, 415, 575, 281, 718, 300, 1320, 51780], "temperature": 0.0, "avg_logprob": -0.1170462653750465, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.06330984085798264}, {"id": 780, "seek": 389772, "start": 3897.72, "end": 3901.8799999999997, "text": " because it then kind of defeats his point. Because the inheritance approach, which is", "tokens": [50364, 570, 309, 550, 733, 295, 7486, 1720, 702, 935, 13, 1436, 264, 32122, 3109, 11, 597, 307, 50572], "temperature": 0.0, "avg_logprob": -0.14467351576861212, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.014346059411764145}, {"id": 781, "seek": 389772, "start": 3901.8799999999997, "end": 3906.7599999999998, "text": " preferred by clean code, is saying that the open case is the open set of variants, the open set of", "tokens": [50572, 16494, 538, 2541, 3089, 11, 307, 1566, 300, 264, 1269, 1389, 307, 264, 1269, 992, 295, 21669, 11, 264, 1269, 992, 295, 50816], "temperature": 0.0, "avg_logprob": -0.14467351576861212, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.014346059411764145}, {"id": 782, "seek": 389772, "start": 3906.7599999999998, "end": 3912.6, "text": " operands is the general case. It isn't. Because if you've got a close set, which you know, like", "tokens": [50816, 2208, 2967, 307, 264, 2674, 1389, 13, 467, 1943, 380, 13, 1436, 498, 291, 600, 658, 257, 1998, 992, 11, 597, 291, 458, 11, 411, 51108], "temperature": 0.0, "avg_logprob": -0.14467351576861212, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.014346059411764145}, {"id": 783, "seek": 389772, "start": 3912.6, "end": 3917.9599999999996, "text": " pretty much always know that 99% of the time 99.99% of the time is going to be", "tokens": [51108, 1238, 709, 1009, 458, 300, 11803, 4, 295, 264, 565, 11803, 13, 8494, 4, 295, 264, 565, 307, 516, 281, 312, 51376], "temperature": 0.0, "avg_logprob": -0.14467351576861212, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.014346059411764145}, {"id": 784, "seek": 389772, "start": 3921.48, "end": 3925.56, "text": " going to be closed, like pretty much going to be that small set. So you're optimizing for them.", "tokens": [51552, 516, 281, 312, 5395, 11, 411, 1238, 709, 516, 281, 312, 300, 1359, 992, 13, 407, 291, 434, 40425, 337, 552, 13, 51756], "temperature": 0.0, "avg_logprob": -0.14467351576861212, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.014346059411764145}, {"id": 785, "seek": 392556, "start": 3925.56, "end": 3931.08, "text": " And then you've got this, the unknown hook cases allow the user to add their own callbacks in there.", "tokens": [50364, 400, 550, 291, 600, 658, 341, 11, 264, 9841, 6328, 3331, 2089, 264, 4195, 281, 909, 641, 1065, 818, 17758, 294, 456, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1460126599957866, "compression_ratio": 1.788679245283019, "no_speech_prob": 0.006001898553222418}, {"id": 786, "seek": 392556, "start": 3931.08, "end": 3936.04, "text": " Fine. That's fine. But it says, it says, unlike to consider the head of time, it's like, yeah,", "tokens": [50640, 12024, 13, 663, 311, 2489, 13, 583, 309, 1619, 11, 309, 1619, 11, 8343, 281, 1949, 264, 1378, 295, 565, 11, 309, 311, 411, 11, 1338, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1460126599957866, "compression_ratio": 1.788679245283019, "no_speech_prob": 0.006001898553222418}, {"id": 787, "seek": 392556, "start": 3936.04, "end": 3941.64, "text": " but you're assuming that those unknown cases are just as common as the known cases. And", "tokens": [50888, 457, 291, 434, 11926, 300, 729, 9841, 3331, 366, 445, 382, 2689, 382, 264, 2570, 3331, 13, 400, 51168], "temperature": 0.0, "avg_logprob": -0.1460126599957866, "compression_ratio": 1.788679245283019, "no_speech_prob": 0.006001898553222418}, {"id": 788, "seek": 392556, "start": 3943.48, "end": 3948.84, "text": " that is actually designing the API. Now the thing is, if you're optimizing for the general case,", "tokens": [51260, 300, 307, 767, 14685, 264, 9362, 13, 823, 264, 551, 307, 11, 498, 291, 434, 40425, 337, 264, 2674, 1389, 11, 51528], "temperature": 0.0, "avg_logprob": -0.1460126599957866, "compression_ratio": 1.788679245283019, "no_speech_prob": 0.006001898553222418}, {"id": 789, "seek": 392556, "start": 3948.84, "end": 3953.4, "text": " and then you allow a hook in, that hook is not going to be is not going to be any slower than", "tokens": [51528, 293, 550, 291, 2089, 257, 6328, 294, 11, 300, 6328, 307, 406, 516, 281, 312, 307, 406, 516, 281, 312, 604, 14009, 813, 51756], "temperature": 0.0, "avg_logprob": -0.1460126599957866, "compression_ratio": 1.788679245283019, "no_speech_prob": 0.006001898553222418}, {"id": 790, "seek": 395340, "start": 3953.4, "end": 3959.1600000000003, "text": " if you design it to be always a general case than the specific cases. That's the point he's", "tokens": [50364, 498, 291, 1715, 309, 281, 312, 1009, 257, 2674, 1389, 813, 264, 2685, 3331, 13, 663, 311, 264, 935, 415, 311, 50652], "temperature": 0.0, "avg_logprob": -0.15188125871185565, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0032617077231407166}, {"id": 791, "seek": 395340, "start": 3959.1600000000003, "end": 3964.44, "text": " trying to say here. Like, that's why he's letting it pass, because it is literally just as fast", "tokens": [50652, 1382, 281, 584, 510, 13, 1743, 11, 300, 311, 983, 415, 311, 8295, 309, 1320, 11, 570, 309, 307, 3736, 445, 382, 2370, 50916], "temperature": 0.0, "avg_logprob": -0.15188125871185565, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0032617077231407166}, {"id": 792, "seek": 395340, "start": 3965.56, "end": 3968.92, "text": " to do it that way, then to design it all the way around as if it was always unknown,", "tokens": [50972, 281, 360, 309, 300, 636, 11, 550, 281, 1715, 309, 439, 264, 636, 926, 382, 498, 309, 390, 1009, 9841, 11, 51140], "temperature": 0.0, "avg_logprob": -0.15188125871185565, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0032617077231407166}, {"id": 793, "seek": 395340, "start": 3969.7200000000003, "end": 3975.8, "text": " as if it was always dynamic polymorphism. Sorry, just say inheritance, be easier,", "tokens": [51180, 382, 498, 309, 390, 1009, 8546, 6754, 76, 18191, 1434, 13, 4919, 11, 445, 584, 32122, 11, 312, 3571, 11, 51484], "temperature": 0.0, "avg_logprob": -0.15188125871185565, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0032617077231407166}, {"id": 794, "seek": 395340, "start": 3975.8, "end": 3982.6, "text": " because technically what it is in this case. So now where are we? You propose a solution that", "tokens": [51484, 570, 12120, 437, 309, 307, 294, 341, 1389, 13, 407, 586, 689, 366, 321, 30, 509, 17421, 257, 3827, 300, 51824], "temperature": 0.0, "avg_logprob": -0.15188125871185565, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0032617077231407166}, {"id": 795, "seek": 398260, "start": 3982.6, "end": 3986.7599999999998, "text": " uses dynamic polymorphism, select two types, and then a switch same to select operations.", "tokens": [50364, 4960, 8546, 6754, 76, 18191, 1434, 11, 3048, 732, 3467, 11, 293, 550, 257, 3679, 912, 281, 3048, 7705, 13, 50572], "temperature": 0.0, "avg_logprob": -0.15162454332624162, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.005534919444471598}, {"id": 796, "seek": 398260, "start": 3986.7599999999998, "end": 3991.88, "text": " I have no problem with this. It works well and satisfies my concerns about dependency inversion.", "tokens": [50572, 286, 362, 572, 1154, 365, 341, 13, 467, 1985, 731, 293, 44271, 452, 7389, 466, 33621, 43576, 13, 50828], "temperature": 0.0, "avg_logprob": -0.15162454332624162, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.005534919444471598}, {"id": 797, "seek": 398260, "start": 3991.88, "end": 3997.24, "text": " I'm like, but it isn't the same kind of dynamic polymorphism that you've ever", "tokens": [50828, 286, 478, 411, 11, 457, 309, 1943, 380, 264, 912, 733, 295, 8546, 6754, 76, 18191, 1434, 300, 291, 600, 1562, 51096], "temperature": 0.0, "avg_logprob": -0.15162454332624162, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.005534919444471598}, {"id": 798, "seek": 398260, "start": 3998.12, "end": 4002.8399999999997, "text": " recommended to anybody. So this isn't technically key and code. In fact, anybody who", "tokens": [51140, 9628, 281, 4472, 13, 407, 341, 1943, 380, 12120, 2141, 293, 3089, 13, 682, 1186, 11, 4472, 567, 51376], "temperature": 0.0, "avg_logprob": -0.15162454332624162, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.005534919444471598}, {"id": 799, "seek": 398260, "start": 4002.8399999999997, "end": 4008.2, "text": " would a clean code advocate would read Casey's code of, let me go back to it, this and go,", "tokens": [51376, 576, 257, 2541, 3089, 14608, 576, 1401, 27369, 311, 3089, 295, 11, 718, 385, 352, 646, 281, 309, 11, 341, 293, 352, 11, 51644], "temperature": 0.0, "avg_logprob": -0.15162454332624162, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.005534919444471598}, {"id": 800, "seek": 400820, "start": 4008.2, "end": 4015.3999999999996, "text": " that's not clean. So this leads to the problem of clean code is whatever Mr. Martin says it is", "tokens": [50364, 300, 311, 406, 2541, 13, 407, 341, 6689, 281, 264, 1154, 295, 2541, 3089, 307, 2035, 2221, 13, 9184, 1619, 309, 307, 50724], "temperature": 0.0, "avg_logprob": -0.11956817873062627, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.039308663457632065}, {"id": 801, "seek": 400820, "start": 4015.3999999999996, "end": 4020.2799999999997, "text": " at that moment. It's not like anyone could actually agree on what clean code is because", "tokens": [50724, 412, 300, 1623, 13, 467, 311, 406, 411, 2878, 727, 767, 3986, 322, 437, 2541, 3089, 307, 570, 50968], "temperature": 0.0, "avg_logprob": -0.11956817873062627, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.039308663457632065}, {"id": 802, "seek": 400820, "start": 4020.2799999999997, "end": 4023.7999999999997, "text": " it changes from time to time. It's not a well-structured thing. And he's like, that's fine.", "tokens": [50968, 309, 2962, 490, 565, 281, 565, 13, 467, 311, 406, 257, 731, 12, 372, 46847, 551, 13, 400, 415, 311, 411, 11, 300, 311, 2489, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11956817873062627, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.039308663457632065}, {"id": 803, "seek": 400820, "start": 4023.7999999999997, "end": 4029.64, "text": " It's like, then why don't you just call it Mr. Martin style? Because it clearly doesn't work.", "tokens": [51144, 467, 311, 411, 11, 550, 983, 500, 380, 291, 445, 818, 309, 2221, 13, 9184, 3758, 30, 1436, 309, 4448, 1177, 380, 589, 13, 51436], "temperature": 0.0, "avg_logprob": -0.11956817873062627, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.039308663457632065}, {"id": 804, "seek": 400820, "start": 4030.3599999999997, "end": 4034.3599999999997, "text": " It's not clean. And it clearly doesn't work the way he wants it to in every single case.", "tokens": [51472, 467, 311, 406, 2541, 13, 400, 309, 4448, 1177, 380, 589, 264, 636, 415, 2738, 309, 281, 294, 633, 2167, 1389, 13, 51672], "temperature": 0.0, "avg_logprob": -0.11956817873062627, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.039308663457632065}, {"id": 805, "seek": 403436, "start": 4034.36, "end": 4038.28, "text": " But then you shouldn't do it like a dogmatic. And it's like, it's a weird trick. He says,", "tokens": [50364, 583, 550, 291, 4659, 380, 360, 309, 411, 257, 3000, 25915, 13, 400, 309, 311, 411, 11, 309, 311, 257, 3657, 4282, 13, 634, 1619, 11, 50560], "temperature": 0.0, "avg_logprob": -0.19365839193795473, "compression_ratio": 1.7944664031620554, "no_speech_prob": 0.028607577085494995}, {"id": 806, "seek": 403436, "start": 4038.28, "end": 4043.0, "text": " look, don't be dogmatic. Don't follow these the rules. But then it's like, well, I won't,", "tokens": [50560, 574, 11, 500, 380, 312, 3000, 25915, 13, 1468, 380, 1524, 613, 264, 4474, 13, 583, 550, 309, 311, 411, 11, 731, 11, 286, 1582, 380, 11, 50796], "temperature": 0.0, "avg_logprob": -0.19365839193795473, "compression_ratio": 1.7944664031620554, "no_speech_prob": 0.028607577085494995}, {"id": 807, "seek": 403436, "start": 4043.0, "end": 4046.44, "text": " I don't agree with it anyway. Well, you clearly have some of these rules, don't you? It's like,", "tokens": [50796, 286, 500, 380, 3986, 365, 309, 4033, 13, 1042, 11, 291, 4448, 362, 512, 295, 613, 4474, 11, 500, 380, 291, 30, 467, 311, 411, 11, 50968], "temperature": 0.0, "avg_logprob": -0.19365839193795473, "compression_ratio": 1.7944664031620554, "no_speech_prob": 0.028607577085494995}, {"id": 808, "seek": 403436, "start": 4047.6400000000003, "end": 4053.4, "text": " it's that clever trick again. It's the pork barrel naming again. It's the rhetoric over", "tokens": [51028, 309, 311, 300, 13494, 4282, 797, 13, 467, 311, 264, 10208, 13257, 25290, 797, 13, 467, 311, 264, 29604, 670, 51316], "temperature": 0.0, "avg_logprob": -0.19365839193795473, "compression_ratio": 1.7944664031620554, "no_speech_prob": 0.028607577085494995}, {"id": 809, "seek": 403436, "start": 4053.4, "end": 4061.2400000000002, "text": " rhetoric over again. I'm like, look, even if Mr. Martin style increased programmer cycles,", "tokens": [51316, 29604, 670, 797, 13, 286, 478, 411, 11, 574, 11, 754, 498, 2221, 13, 9184, 3758, 6505, 32116, 17796, 11, 51708], "temperature": 0.0, "avg_logprob": -0.19365839193795473, "compression_ratio": 1.7944664031620554, "no_speech_prob": 0.028607577085494995}, {"id": 810, "seek": 406124, "start": 4061.9599999999996, "end": 4067.8799999999997, "text": " the decrease of wasted programmer cycles, like, whatever. Great. But how do you prove this is", "tokens": [50400, 264, 11514, 295, 19496, 32116, 17796, 11, 411, 11, 2035, 13, 3769, 13, 583, 577, 360, 291, 7081, 341, 307, 50696], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 811, "seek": 406124, "start": 4067.8799999999997, "end": 4073.56, "text": " the case? And we're getting to the end now, and we're just going to do here. So I'm going to", "tokens": [50696, 264, 1389, 30, 400, 321, 434, 1242, 281, 264, 917, 586, 11, 293, 321, 434, 445, 516, 281, 360, 510, 13, 407, 286, 478, 516, 281, 50980], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 812, "seek": 406124, "start": 4073.56, "end": 4076.9199999999996, "text": " read the best of it. So, so Mr. Martin's your proposed solution time with thing blah, blah,", "tokens": [50980, 1401, 264, 1151, 295, 309, 13, 407, 11, 370, 2221, 13, 9184, 311, 428, 10348, 3827, 565, 365, 551, 12288, 11, 12288, 11, 51148], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 813, "seek": 406124, "start": 4076.9199999999996, "end": 4080.6, "text": " blah, blah. What do you got to this? I will say, however, that that is an ironic that after your", "tokens": [51148, 12288, 11, 12288, 13, 708, 360, 291, 658, 281, 341, 30, 286, 486, 584, 11, 4461, 11, 300, 300, 307, 364, 33719, 300, 934, 428, 51332], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 814, "seek": 406124, "start": 4080.6, "end": 4084.12, "text": " video and after all the stress that you have been put on saving machine cycles, you eventually", "tokens": [51332, 960, 293, 934, 439, 264, 4244, 300, 291, 362, 668, 829, 322, 6816, 3479, 17796, 11, 291, 4728, 51508], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 815, "seek": 406124, "start": 4084.12, "end": 4089.72, "text": " chose a design that sacrifices machine cycles to save programmer cycles. After all, on the OS side,", "tokens": [51508, 5111, 257, 1715, 300, 25094, 3479, 17796, 281, 3155, 32116, 17796, 13, 2381, 439, 11, 322, 264, 12731, 1252, 11, 51788], "temperature": 0.0, "avg_logprob": -0.21837049023858432, "compression_ratio": 1.78125, "no_speech_prob": 0.05644654855132103}, {"id": 816, "seek": 409124, "start": 4091.3999999999996, "end": 4096.599999999999, "text": " this is where he thinks he has won the argument. Ready? This is what he's tried. He's tried a trick.", "tokens": [50372, 341, 307, 689, 415, 7309, 415, 575, 1582, 264, 6770, 13, 9944, 30, 639, 307, 437, 415, 311, 3031, 13, 634, 311, 3031, 257, 4282, 13, 50632], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 817, "seek": 409124, "start": 4097.48, "end": 4102.12, "text": " He's tried to do it because he took the canonical case of a stream. After all, on the OS side,", "tokens": [50676, 634, 311, 3031, 281, 360, 309, 570, 415, 1890, 264, 46491, 1389, 295, 257, 4309, 13, 2381, 439, 11, 322, 264, 12731, 1252, 11, 50908], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 818, "seek": 409124, "start": 4102.12, "end": 4106.92, "text": " you've you've got to package up all the quest packets and it's the dynamically dispatched", "tokens": [50908, 291, 600, 291, 600, 658, 281, 7372, 493, 439, 264, 866, 30364, 293, 309, 311, 264, 43492, 4920, 24102, 51148], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 819, "seek": 409124, "start": 4106.92, "end": 4112.599999999999, "text": " handler and then run the operation ID through a switch. And I think we wind up in the same place", "tokens": [51148, 41967, 293, 550, 1190, 264, 6916, 7348, 807, 257, 3679, 13, 400, 286, 519, 321, 2468, 493, 294, 264, 912, 1081, 51432], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 820, "seek": 409124, "start": 4112.599999999999, "end": 4116.5199999999995, "text": " when operations proflate more rapidly than tights, we both use switches, you don't,", "tokens": [51432, 562, 7705, 1740, 17593, 544, 12910, 813, 4524, 82, 11, 321, 1293, 764, 19458, 11, 291, 500, 380, 11, 51628], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 821, "seek": 409124, "start": 4117.16, "end": 4120.44, "text": " you do not do this. I've read your code, your public code, you don't do this.", "tokens": [51660, 291, 360, 406, 360, 341, 13, 286, 600, 1401, 428, 3089, 11, 428, 1908, 3089, 11, 291, 500, 380, 360, 341, 13, 51824], "temperature": 0.0, "avg_logprob": -0.15700236956278482, "compression_ratio": 1.7605177993527508, "no_speech_prob": 0.01159720215946436}, {"id": 822, "seek": 412124, "start": 4121.639999999999, "end": 4126.679999999999, "text": " But he's saying he does just pretend you believe it. Okay. When tight for a plate more rapidly", "tokens": [50384, 583, 415, 311, 1566, 415, 775, 445, 11865, 291, 1697, 309, 13, 1033, 13, 1133, 4524, 337, 257, 5924, 544, 12910, 50636], "temperature": 0.0, "avg_logprob": -0.18239833286830356, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.00337440543808043}, {"id": 823, "seek": 412124, "start": 4126.679999999999, "end": 4131.16, "text": " than operations, we both use dynamic dispatch, we are both willing to sacrifice machine cycles to", "tokens": [50636, 813, 7705, 11, 321, 1293, 764, 8546, 36729, 11, 321, 366, 1293, 4950, 281, 11521, 3479, 17796, 281, 50860], "temperature": 0.0, "avg_logprob": -0.18239833286830356, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.00337440543808043}, {"id": 824, "seek": 412124, "start": 4131.16, "end": 4140.12, "text": " save programmer cycles. No. Also the way again, how Casey structured it will be better because", "tokens": [50860, 3155, 32116, 17796, 13, 883, 13, 2743, 264, 636, 797, 11, 577, 27369, 18519, 309, 486, 312, 1101, 570, 51308], "temperature": 0.0, "avg_logprob": -0.18239833286830356, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.00337440543808043}, {"id": 825, "seek": 412124, "start": 4140.12, "end": 4144.84, "text": " it's not technically how many levels in direction do you have before like technically here has", "tokens": [51308, 309, 311, 406, 12120, 577, 867, 4358, 294, 3513, 360, 291, 362, 949, 411, 12120, 510, 575, 51544], "temperature": 0.0, "avg_logprob": -0.18239833286830356, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.00337440543808043}, {"id": 826, "seek": 412124, "start": 4144.84, "end": 4148.44, "text": " one level of indirection, which is a function pointer compared to normal inheritance, which", "tokens": [51544, 472, 1496, 295, 1016, 621, 882, 11, 597, 307, 257, 2445, 23918, 5347, 281, 2710, 32122, 11, 597, 51724], "temperature": 0.0, "avg_logprob": -0.18239833286830356, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.00337440543808043}, {"id": 827, "seek": 414844, "start": 4148.44, "end": 4153.32, "text": " is three levels of indirection. Why? You've got a pointer to the object, pointer to the vtable,", "tokens": [50364, 307, 1045, 4358, 295, 1016, 621, 882, 13, 1545, 30, 509, 600, 658, 257, 23918, 281, 264, 2657, 11, 23918, 281, 264, 371, 23811, 11, 50608], "temperature": 0.0, "avg_logprob": -0.16308213806152344, "compression_ratio": 1.76, "no_speech_prob": 0.001324342330917716}, {"id": 828, "seek": 414844, "start": 4153.32, "end": 4162.36, "text": " then a pointer to the function. Guess which one's going to be faster? Just have a hesitant guess.", "tokens": [50608, 550, 257, 23918, 281, 264, 2445, 13, 17795, 597, 472, 311, 516, 281, 312, 4663, 30, 1449, 362, 257, 36290, 2041, 13, 51060], "temperature": 0.0, "avg_logprob": -0.16308213806152344, "compression_ratio": 1.76, "no_speech_prob": 0.001324342330917716}, {"id": 829, "seek": 414844, "start": 4163.4, "end": 4167.48, "text": " Okay. And not just that, you've then have to go all through this indirection compared to having one,", "tokens": [51112, 1033, 13, 400, 406, 445, 300, 11, 291, 600, 550, 362, 281, 352, 439, 807, 341, 1016, 621, 882, 5347, 281, 1419, 472, 11, 51316], "temperature": 0.0, "avg_logprob": -0.16308213806152344, "compression_ratio": 1.76, "no_speech_prob": 0.001324342330917716}, {"id": 830, "seek": 414844, "start": 4167.48, "end": 4171.799999999999, "text": " which is probably going to be in the literally cash already in the cash ready to be called.", "tokens": [51316, 597, 307, 1391, 516, 281, 312, 294, 264, 3736, 6388, 1217, 294, 264, 6388, 1919, 281, 312, 1219, 13, 51532], "temperature": 0.0, "avg_logprob": -0.16308213806152344, "compression_ratio": 1.76, "no_speech_prob": 0.001324342330917716}, {"id": 831, "seek": 414844, "start": 4171.799999999999, "end": 4176.04, "text": " No problem. It's going to be easily predictable as well for the CPU. It's a very different thing,", "tokens": [51532, 883, 1154, 13, 467, 311, 516, 281, 312, 3612, 27737, 382, 731, 337, 264, 13199, 13, 467, 311, 257, 588, 819, 551, 11, 51744], "temperature": 0.0, "avg_logprob": -0.16308213806152344, "compression_ratio": 1.76, "no_speech_prob": 0.001324342330917716}, {"id": 832, "seek": 417604, "start": 4176.68, "end": 4183.4, "text": " very different operation that is to a generalized vtable. So no, they are not equivalent,", "tokens": [50396, 588, 819, 6916, 300, 307, 281, 257, 44498, 371, 23811, 13, 407, 572, 11, 436, 366, 406, 10344, 11, 50732], "temperature": 0.0, "avg_logprob": -0.16969812833345854, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.025924229994416237}, {"id": 833, "seek": 417604, "start": 4183.4, "end": 4187.72, "text": " even in performance. One will be quicker than the other. I'm not doing this video. I could do", "tokens": [50732, 754, 294, 3389, 13, 1485, 486, 312, 16255, 813, 264, 661, 13, 286, 478, 406, 884, 341, 960, 13, 286, 727, 360, 50948], "temperature": 0.0, "avg_logprob": -0.16969812833345854, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.025924229994416237}, {"id": 834, "seek": 417604, "start": 4187.72, "end": 4190.68, "text": " another video if you'd like, but like we could prove it, one's going to be quicker.", "tokens": [50948, 1071, 960, 498, 291, 1116, 411, 11, 457, 411, 321, 727, 7081, 309, 11, 472, 311, 516, 281, 312, 16255, 13, 51096], "temperature": 0.0, "avg_logprob": -0.16969812833345854, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.025924229994416237}, {"id": 835, "seek": 417604, "start": 4191.72, "end": 4197.72, "text": " Single indirection compared to triple indirection. Okay. So when we are two individuals on the same", "tokens": [51148, 31248, 1016, 621, 882, 5347, 281, 15508, 1016, 621, 882, 13, 1033, 13, 407, 562, 321, 366, 732, 5346, 322, 264, 912, 51448], "temperature": 0.0, "avg_logprob": -0.16969812833345854, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.025924229994416237}, {"id": 836, "seek": 417604, "start": 4197.72, "end": 4203.56, "text": " eye and the only difference being that I wear this shirt and I don't know how to pronounce that word", "tokens": [51448, 3313, 293, 264, 787, 2649, 885, 300, 286, 3728, 341, 8336, 293, 286, 500, 380, 458, 577, 281, 19567, 300, 1349, 51740], "temperature": 0.0, "avg_logprob": -0.16969812833345854, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.025924229994416237}, {"id": 837, "seek": 420356, "start": 4204.04, "end": 4206.92, "text": " with clean code and you have one with clean code, I'm like,", "tokens": [50388, 365, 2541, 3089, 293, 291, 362, 472, 365, 2541, 3089, 11, 286, 478, 411, 11, 50532], "temperature": 0.0, "avg_logprob": -0.20228695665669238, "compression_ratio": 1.726923076923077, "no_speech_prob": 0.08562377840280533}, {"id": 838, "seek": 420356, "start": 4207.72, "end": 4211.8, "text": " thank you for simulating the debate. I appreciate your candor and the civility that you exercise to", "tokens": [50572, 1309, 291, 337, 1034, 12162, 264, 7958, 13, 286, 4449, 428, 3955, 284, 293, 264, 13779, 1140, 300, 291, 5380, 281, 50776], "temperature": 0.0, "avg_logprob": -0.20228695665669238, "compression_ratio": 1.726923076923077, "no_speech_prob": 0.08562377840280533}, {"id": 839, "seek": 420356, "start": 4211.8, "end": 4215.4800000000005, "text": " and if, if not everywhere, I've come to experience your respect, your knowledge and blah, blah, blah,", "tokens": [50776, 293, 498, 11, 498, 406, 5315, 11, 286, 600, 808, 281, 1752, 428, 3104, 11, 428, 3601, 293, 12288, 11, 12288, 11, 12288, 11, 50960], "temperature": 0.0, "avg_logprob": -0.20228695665669238, "compression_ratio": 1.726923076923077, "no_speech_prob": 0.08562377840280533}, {"id": 840, "seek": 420356, "start": 4215.4800000000005, "end": 4222.68, "text": " blah, whatever. So the first thing is this is a really dodgy thing. Casey and even cases,", "tokens": [50960, 12288, 11, 2035, 13, 407, 264, 700, 551, 307, 341, 307, 257, 534, 13886, 1480, 551, 13, 27369, 293, 754, 3331, 11, 51320], "temperature": 0.0, "avg_logprob": -0.20228695665669238, "compression_ratio": 1.726923076923077, "no_speech_prob": 0.08562377840280533}, {"id": 841, "seek": 420356, "start": 4222.68, "end": 4227.64, "text": " well, I disagree with most of that. But if we're ending here, I'll just finish my final responses", "tokens": [51320, 731, 11, 286, 14091, 365, 881, 295, 300, 13, 583, 498, 321, 434, 8121, 510, 11, 286, 603, 445, 2413, 452, 2572, 13019, 51568], "temperature": 0.0, "avg_logprob": -0.20228695665669238, "compression_ratio": 1.726923076923077, "no_speech_prob": 0.08562377840280533}, {"id": 842, "seek": 422764, "start": 4227.64, "end": 4235.240000000001, "text": " for Gail poster poster posterity. And that is the thing. See how he tried to end it. And I'm", "tokens": [50364, 337, 460, 864, 17171, 17171, 17171, 507, 13, 400, 300, 307, 264, 551, 13, 3008, 577, 415, 3031, 281, 917, 309, 13, 400, 286, 478, 50744], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 843, "seek": 422764, "start": 4235.240000000001, "end": 4238.52, "text": " going to read through Casey. I'm not going to comment on it now. I'm just going to read it for", "tokens": [50744, 516, 281, 1401, 807, 27369, 13, 286, 478, 406, 516, 281, 2871, 322, 309, 586, 13, 286, 478, 445, 516, 281, 1401, 309, 337, 50908], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 844, "seek": 422764, "start": 4238.52, "end": 4242.200000000001, "text": " the end of this video because we've already been going on too long. Sorry. So I apologize", "tokens": [50908, 264, 917, 295, 341, 960, 570, 321, 600, 1217, 668, 516, 322, 886, 938, 13, 4919, 13, 407, 286, 12328, 51092], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 845, "seek": 422764, "start": 4243.0, "end": 4248.360000000001, "text": " for my rambling in between. I hope it's kind of an enjoyable if not, and I apologize again. So", "tokens": [51132, 337, 452, 367, 19391, 294, 1296, 13, 286, 1454, 309, 311, 733, 295, 364, 20305, 498, 406, 11, 293, 286, 12328, 797, 13, 407, 51400], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 846, "seek": 422764, "start": 4248.360000000001, "end": 4251.320000000001, "text": " I'm just going to read through this. I'm just going to read Casey stuff. This is all Casey,", "tokens": [51400, 286, 478, 445, 516, 281, 1401, 807, 341, 13, 286, 478, 445, 516, 281, 1401, 27369, 1507, 13, 639, 307, 439, 27369, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 847, "seek": 422764, "start": 4251.320000000001, "end": 4256.76, "text": " not me. So regarding as I wrote in clean code, which by the way is not the same as your clean", "tokens": [51548, 406, 385, 13, 407, 8595, 382, 286, 4114, 294, 2541, 3089, 11, 597, 538, 264, 636, 307, 406, 264, 912, 382, 428, 2541, 51820], "temperature": 0.0, "avg_logprob": -0.1099840799967448, "compression_ratio": 1.9044368600682593, "no_speech_prob": 0.17265798151493073}, {"id": 848, "seek": 425676, "start": 4256.76, "end": 4262.84, "text": " code? Well, the point is of discussion was your you to elaborate on what is not the same. But", "tokens": [50364, 3089, 30, 1042, 11, 264, 935, 307, 295, 5017, 390, 428, 291, 281, 20945, 322, 437, 307, 406, 264, 912, 13, 583, 50668], "temperature": 0.0, "avg_logprob": -0.12360644340515137, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.028406932950019836}, {"id": 849, "seek": 425676, "start": 4262.84, "end": 4267.400000000001, "text": " you're designed for the IO system looks exactly like my clean code example of virtual function", "tokens": [50668, 291, 434, 4761, 337, 264, 39839, 1185, 1542, 2293, 411, 452, 2541, 3089, 1365, 295, 6374, 2445, 50896], "temperature": 0.0, "avg_logprob": -0.12360644340515137, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.028406932950019836}, {"id": 850, "seek": 425676, "start": 4267.400000000001, "end": 4273.400000000001, "text": " for every operation, one class per element in the system with no predication. So what are these", "tokens": [50896, 337, 633, 6916, 11, 472, 1508, 680, 4478, 294, 264, 1185, 365, 572, 3852, 8758, 13, 407, 437, 366, 613, 51196], "temperature": 0.0, "avg_logprob": -0.12360644340515137, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.028406932950019836}, {"id": 851, "seek": 425676, "start": 4273.400000000001, "end": 4278.92, "text": " differences that you're referring to? Now would be the now would be the time to explain what they", "tokens": [51196, 7300, 300, 291, 434, 13761, 281, 30, 823, 576, 312, 264, 586, 576, 312, 264, 565, 281, 2903, 437, 436, 51472], "temperature": 0.0, "avg_logprob": -0.12360644340515137, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.028406932950019836}, {"id": 852, "seek": 425676, "start": 4278.92, "end": 4284.6, "text": " are since that was the point of the concrete example. If these are a bad example for accelerators,", "tokens": [51472, 366, 1670, 300, 390, 264, 935, 295, 264, 9859, 1365, 13, 759, 613, 366, 257, 1578, 1365, 337, 10172, 3391, 11, 51756], "temperature": 0.0, "avg_logprob": -0.12360644340515137, "compression_ratio": 1.7056737588652482, "no_speech_prob": 0.028406932950019836}, {"id": 853, "seek": 428460, "start": 4284.76, "end": 4290.4400000000005, "text": " straighten the differences, that's fine. But it was the first one you gave to assumed that it would", "tokens": [50372, 32777, 264, 7300, 11, 300, 311, 2489, 13, 583, 309, 390, 264, 700, 472, 291, 2729, 281, 15895, 300, 309, 576, 50656], "temperature": 0.0, "avg_logprob": -0.1799690670437283, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.006283178925514221}, {"id": 854, "seek": 428460, "start": 4290.4400000000005, "end": 4299.4800000000005, "text": " be the one you want to use. Regarding when operations proliferate more rapidly than types,", "tokens": [50656, 312, 264, 472, 291, 528, 281, 764, 13, 35523, 562, 7705, 24398, 9361, 473, 544, 12910, 813, 3467, 11, 51108], "temperature": 0.0, "avg_logprob": -0.1799690670437283, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.006283178925514221}, {"id": 855, "seek": 428460, "start": 4299.4800000000005, "end": 4304.4400000000005, "text": " switch teams are better. That was not the case here. In no way are operations proliferating", "tokens": [51108, 3679, 5491, 366, 1101, 13, 663, 390, 406, 264, 1389, 510, 13, 682, 572, 636, 366, 7705, 24398, 9361, 990, 51356], "temperature": 0.0, "avg_logprob": -0.1799690670437283, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.006283178925514221}, {"id": 856, "seek": 428460, "start": 4304.4400000000005, "end": 4310.68, "text": " more rapidly than types in the system. Vendors will add drivers to the OS constantly, perhaps", "tokens": [51356, 544, 12910, 813, 3467, 294, 264, 1185, 13, 691, 521, 830, 486, 909, 11590, 281, 264, 12731, 6460, 11, 4317, 51668], "temperature": 0.0, "avg_logprob": -0.1799690670437283, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.006283178925514221}, {"id": 857, "seek": 431068, "start": 4310.76, "end": 4315.240000000001, "text": " monthly or even weekly, whereas the number of operations in a particular system tends to go", "tokens": [50368, 12878, 420, 754, 12460, 11, 9735, 264, 1230, 295, 7705, 294, 257, 1729, 1185, 12258, 281, 352, 50592], "temperature": 0.0, "avg_logprob": -0.09709934602703965, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.012815061025321484}, {"id": 858, "seek": 431068, "start": 4315.240000000001, "end": 4320.6, "text": " much more slowly, once every few months at a maximum, but more likely once a year for something like", "tokens": [50592, 709, 544, 5692, 11, 1564, 633, 1326, 2493, 412, 257, 6674, 11, 457, 544, 3700, 1564, 257, 1064, 337, 746, 411, 50860], "temperature": 0.0, "avg_logprob": -0.09709934602703965, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.012815061025321484}, {"id": 859, "seek": 431068, "start": 4320.6, "end": 4328.52, "text": " the aniosis subsystem. It isn't the opposite of what you said. This is an important distinction,", "tokens": [50860, 264, 364, 48783, 2090, 9321, 13, 467, 1943, 380, 264, 6182, 295, 437, 291, 848, 13, 639, 307, 364, 1021, 16844, 11, 51256], "temperature": 0.0, "avg_logprob": -0.09709934602703965, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.012815061025321484}, {"id": 860, "seek": 431068, "start": 4328.52, "end": 4334.280000000001, "text": " because what I'm demonstrating here is the opposite of your rule. This is showing that even in the", "tokens": [51256, 570, 437, 286, 478, 29889, 510, 307, 264, 6182, 295, 428, 4978, 13, 639, 307, 4099, 300, 754, 294, 264, 51544], "temperature": 0.0, "avg_logprob": -0.09709934602703965, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.012815061025321484}, {"id": 861, "seek": 431068, "start": 4334.280000000001, "end": 4340.4400000000005, "text": " case where types proliferate far more rapidly than operations, as in the case of drivers in an OS,", "tokens": [51544, 1389, 689, 3467, 24398, 9361, 473, 1400, 544, 12910, 813, 7705, 11, 382, 294, 264, 1389, 295, 11590, 294, 364, 12731, 11, 51852], "temperature": 0.0, "avg_logprob": -0.09709934602703965, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.012815061025321484}, {"id": 862, "seek": 434044, "start": 4340.44, "end": 4348.2, "text": " the principle doesn't work. Enums are better in both cases, specifically because you have", "tokens": [50364, 264, 8665, 1177, 380, 589, 13, 2193, 8099, 366, 1101, 294, 1293, 3331, 11, 4682, 570, 291, 362, 50752], "temperature": 0.0, "avg_logprob": -0.1510429033418981, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0015934814000502229}, {"id": 863, "seek": 434044, "start": 4348.839999999999, "end": 4354.919999999999, "text": " potentially thousands of types in the system, all different drivers, all the vendors have ever shipped.", "tokens": [50784, 7263, 5383, 295, 3467, 294, 264, 1185, 11, 439, 819, 11590, 11, 439, 264, 22056, 362, 1562, 25312, 13, 51088], "temperature": 0.0, "avg_logprob": -0.1510429033418981, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0015934814000502229}, {"id": 864, "seek": 434044, "start": 4355.879999999999, "end": 4360.919999999999, "text": " Adding a single operation, however rarely, can cost massive programmer cycles to the", "tokens": [51136, 31204, 257, 2167, 6916, 11, 4461, 13752, 11, 393, 2063, 5994, 32116, 17796, 281, 264, 51388], "temperature": 0.0, "avg_logprob": -0.1510429033418981, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0015934814000502229}, {"id": 865, "seek": 434044, "start": 4360.919999999999, "end": 4367.639999999999, "text": " unnecessary work multiplication across types, the V-tapels course. Another way to say this would", "tokens": [51388, 19350, 589, 27290, 2108, 3467, 11, 264, 691, 12, 83, 569, 1625, 1164, 13, 3996, 636, 281, 584, 341, 576, 51724], "temperature": 0.0, "avg_logprob": -0.1510429033418981, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0015934814000502229}, {"id": 866, "seek": 436764, "start": 4367.64, "end": 4373.72, "text": " be enums are more important in a system where type proliferate rapidly, not less. Regarding,", "tokens": [50364, 312, 465, 8099, 366, 544, 1021, 294, 257, 1185, 689, 2010, 24398, 9361, 473, 12910, 11, 406, 1570, 13, 35523, 11, 50668], "temperature": 0.0, "avg_logprob": -0.1616476706738742, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.03408351168036461}, {"id": 867, "seek": 436764, "start": 4373.72, "end": 4377.56, "text": " you eventually chose a design that sacrificed machine cycles to save program cycles.", "tokens": [50668, 291, 4728, 5111, 257, 1715, 300, 32021, 3479, 17796, 281, 3155, 1461, 17796, 13, 50860], "temperature": 0.0, "avg_logprob": -0.1616476706738742, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.03408351168036461}, {"id": 868, "seek": 436764, "start": 4378.12, "end": 4385.240000000001, "text": " I did no such thing. The design achieves both, like why I like it. It's drastically faster to", "tokens": [50888, 286, 630, 572, 1270, 551, 13, 440, 1715, 3538, 977, 1293, 11, 411, 983, 286, 411, 309, 13, 467, 311, 29673, 4663, 281, 51244], "temperature": 0.0, "avg_logprob": -0.1616476706738742, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.03408351168036461}, {"id": 869, "seek": 436764, "start": 4385.240000000001, "end": 4389.160000000001, "text": " use something like a packet-based system than something that is originally proposed design,", "tokens": [51244, 764, 746, 411, 257, 20300, 12, 6032, 1185, 813, 746, 300, 307, 7993, 10348, 1715, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1616476706738742, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.03408351168036461}, {"id": 870, "seek": 436764, "start": 4389.8, "end": 4396.92, "text": " because you do not take a ring transition on every operation. New OS IO APIs are not all designed", "tokens": [51472, 570, 291, 360, 406, 747, 257, 4875, 6034, 322, 633, 6916, 13, 1873, 12731, 39839, 21445, 366, 406, 439, 4761, 51828], "temperature": 0.0, "avg_logprob": -0.1616476706738742, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.03408351168036461}, {"id": 871, "seek": 439692, "start": 4396.92, "end": 4402.76, "text": " this way. This user writes data without taking in talking to the OS, and a kernel thread picks up", "tokens": [50364, 341, 636, 13, 639, 4195, 13657, 1412, 1553, 1940, 294, 1417, 281, 264, 12731, 11, 293, 257, 28256, 7207, 16137, 493, 50656], "temperature": 0.0, "avg_logprob": -0.10720818131058305, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.006088636349886656}, {"id": 872, "seek": 439692, "start": 4402.76, "end": 4408.12, "text": " those data writes. Nobody ever makes a function call, except occasionally to ensure the kernel", "tokens": [50656, 729, 1412, 13657, 13, 9297, 1562, 1669, 257, 2445, 818, 11, 3993, 16895, 281, 5586, 264, 28256, 50924], "temperature": 0.0, "avg_logprob": -0.10720818131058305, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.006088636349886656}, {"id": 873, "seek": 439692, "start": 4408.12, "end": 4414.28, "text": " thread hasn't gone to sleep. This is what I mean by the bullet point, if at some point we decide", "tokens": [50924, 7207, 6132, 380, 2780, 281, 2817, 13, 639, 307, 437, 286, 914, 538, 264, 11632, 935, 11, 498, 412, 512, 935, 321, 4536, 51232], "temperature": 0.0, "avg_logprob": -0.10720818131058305, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.006088636349886656}, {"id": 874, "seek": 439692, "start": 4414.28, "end": 4418.92, "text": " users should be able to do multi-threading book IO ops. I am talking about the necessity that", "tokens": [51232, 5022, 820, 312, 1075, 281, 360, 4825, 12, 392, 35908, 1446, 39839, 44663, 13, 286, 669, 1417, 466, 264, 24217, 300, 51464], "temperature": 0.0, "avg_logprob": -0.10720818131058305, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.006088636349886656}, {"id": 875, "seek": 439692, "start": 4418.92, "end": 4423.88, "text": " actually occurred in both Linux and Windows of removing their frequency of ring transitions", "tokens": [51464, 767, 11068, 294, 1293, 18734, 293, 8591, 295, 12720, 641, 7893, 295, 4875, 23767, 51712], "temperature": 0.0, "avg_logprob": -0.10720818131058305, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.006088636349886656}, {"id": 876, "seek": 442388, "start": 4423.88, "end": 4429.32, "text": " for saving CPU cycles. None of this is trading CPU cycles for programmer cycles. It's achieving", "tokens": [50364, 337, 6816, 13199, 17796, 13, 14492, 295, 341, 307, 9529, 13199, 17796, 337, 32116, 17796, 13, 467, 311, 19626, 50636], "temperature": 0.0, "avg_logprob": -0.09324051204480623, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.04871781915426254}, {"id": 877, "seek": 442388, "start": 4429.32, "end": 4435.96, "text": " both. The Linux kernel design of the IOU ring looks like my design. That did not add to save", "tokens": [50636, 1293, 13, 440, 18734, 28256, 1715, 295, 264, 286, 4807, 4875, 1542, 411, 452, 1715, 13, 663, 630, 406, 909, 281, 3155, 50968], "temperature": 0.0, "avg_logprob": -0.09324051204480623, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.04871781915426254}, {"id": 878, "seek": 442388, "start": 4435.96, "end": 4440.92, "text": " programmer cycles. They added it because they wanted the highest possible IO throughput. This is an", "tokens": [50968, 32116, 17796, 13, 814, 3869, 309, 570, 436, 1415, 264, 6343, 1944, 39839, 44629, 13, 639, 307, 364, 51216], "temperature": 0.0, "avg_logprob": -0.09324051204480623, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.04871781915426254}, {"id": 879, "seek": 442388, "start": 4440.92, "end": 4446.52, "text": " almost universal principle of modern OS design. Anything that can be turned into data writes", "tokens": [51216, 1920, 11455, 8665, 295, 4363, 12731, 1715, 13, 11998, 300, 393, 312, 3574, 666, 1412, 13657, 51496], "temperature": 0.0, "avg_logprob": -0.09324051204480623, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.04871781915426254}, {"id": 880, "seek": 442388, "start": 4446.52, "end": 4452.76, "text": " should be, and function calls should be minimized. It's been true for GPUs, for NICs, and for our", "tokens": [51496, 820, 312, 11, 293, 2445, 5498, 820, 312, 4464, 1602, 13, 467, 311, 668, 2074, 337, 18407, 82, 11, 337, 426, 2532, 82, 11, 293, 337, 527, 51808], "temperature": 0.0, "avg_logprob": -0.09324051204480623, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.04871781915426254}, {"id": 881, "seek": 445276, "start": 4452.76, "end": 4458.280000000001, "text": " example disk IO. And the last bullet point is regarding, and so I think we wind up in the", "tokens": [50364, 1365, 12355, 39839, 13, 400, 264, 1036, 11632, 935, 307, 8595, 11, 293, 370, 286, 519, 321, 2468, 493, 294, 264, 50640], "temperature": 0.0, "avg_logprob": -0.1179088715019576, "compression_ratio": 1.7951807228915662, "no_speech_prob": 0.008574523963034153}, {"id": 882, "seek": 445276, "start": 4458.280000000001, "end": 4464.2, "text": " same place when dynamic operations proliferate more rapidly than types we both use, switches,", "tokens": [50640, 912, 1081, 562, 8546, 7705, 24398, 9361, 473, 544, 12910, 813, 3467, 321, 1293, 764, 11, 19458, 11, 50936], "temperature": 0.0, "avg_logprob": -0.1179088715019576, "compression_ratio": 1.7951807228915662, "no_speech_prob": 0.008574523963034153}, {"id": 883, "seek": 445276, "start": 4464.2, "end": 4468.6, "text": " when types proliferate more openly than operations we both use dynamic dispatch. Again,", "tokens": [50936, 562, 3467, 24398, 9361, 473, 544, 23109, 813, 7705, 321, 1293, 764, 8546, 36729, 13, 3764, 11, 51156], "temperature": 0.0, "avg_logprob": -0.1179088715019576, "compression_ratio": 1.7951807228915662, "no_speech_prob": 0.008574523963034153}, {"id": 884, "seek": 445276, "start": 4468.6, "end": 4474.280000000001, "text": " I don't see how you got there. Obviously types are proliferating more rapidly in this system,", "tokens": [51156, 286, 500, 380, 536, 577, 291, 658, 456, 13, 7580, 3467, 366, 24398, 9361, 990, 544, 12910, 294, 341, 1185, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1179088715019576, "compression_ratio": 1.7951807228915662, "no_speech_prob": 0.008574523963034153}, {"id": 885, "seek": 445276, "start": 4474.280000000001, "end": 4479.56, "text": " so that is part, is true. If we didn't believe drivers are proliferating rapidly,", "tokens": [51440, 370, 300, 307, 644, 11, 307, 2074, 13, 759, 321, 994, 380, 1697, 11590, 366, 24398, 9361, 990, 12910, 11, 51704], "temperature": 0.0, "avg_logprob": -0.1179088715019576, "compression_ratio": 1.7951807228915662, "no_speech_prob": 0.008574523963034153}, {"id": 886, "seek": 447956, "start": 4479.64, "end": 4485.64, "text": " why are we loading them dynamically? And I thought that was the entire point of the example,", "tokens": [50368, 983, 366, 321, 15114, 552, 43492, 30, 400, 286, 1194, 300, 390, 264, 2302, 935, 295, 264, 1365, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10905481093000657, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.005352657288312912}, {"id": 887, "seek": 447956, "start": 4485.64, "end": 4490.52, "text": " but perhaps more importantly, we are not using dynamic dispatch here in the way that you've been", "tokens": [50668, 457, 4317, 544, 8906, 11, 321, 366, 406, 1228, 8546, 36729, 510, 294, 264, 636, 300, 291, 600, 668, 50912], "temperature": 0.0, "avg_logprob": -0.10905481093000657, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.005352657288312912}, {"id": 888, "seek": 447956, "start": 4490.52, "end": 4494.84, "text": " suggesting. As I was pointing out earlier, I said that when I proposed the design process,", "tokens": [50912, 18094, 13, 1018, 286, 390, 12166, 484, 3071, 11, 286, 848, 300, 562, 286, 10348, 264, 1715, 1399, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10905481093000657, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.005352657288312912}, {"id": 889, "seek": 447956, "start": 4494.84, "end": 4500.120000000001, "text": " I would also do the inside drivers themselves. I would not duplicate drivers to remove if", "tokens": [51128, 286, 576, 611, 360, 264, 1854, 11590, 2969, 13, 286, 576, 406, 23976, 11590, 281, 4159, 498, 51392], "temperature": 0.0, "avg_logprob": -0.10905481093000657, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.005352657288312912}, {"id": 890, "seek": 447956, "start": 4500.120000000001, "end": 4504.120000000001, "text": " statements and switch statements inside a driver that allowed the drive to handle multiple similar", "tokens": [51392, 12363, 293, 3679, 12363, 1854, 257, 6787, 300, 4350, 264, 3332, 281, 4813, 3866, 2531, 51592], "temperature": 0.0, "avg_logprob": -0.10905481093000657, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.005352657288312912}, {"id": 891, "seek": 450412, "start": 4504.12, "end": 4510.36, "text": " devices. The only reason that there are function pointers in this system is because the problem", "tokens": [50364, 5759, 13, 440, 787, 1778, 300, 456, 366, 2445, 44548, 294, 341, 1185, 307, 570, 264, 1154, 50676], "temperature": 0.0, "avg_logprob": -0.08837069065198985, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.1195380911231041}, {"id": 892, "seek": 450412, "start": 4510.36, "end": 4515.88, "text": " definition required that we load the driver from a different module, and we are not presuming a JIT", "tokens": [50676, 7123, 4739, 300, 321, 3677, 264, 6787, 490, 257, 819, 10088, 11, 293, 321, 366, 406, 18028, 278, 257, 508, 3927, 50952], "temperature": 0.0, "avg_logprob": -0.08837069065198985, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.1195380911231041}, {"id": 893, "seek": 450412, "start": 4515.88, "end": 4522.44, "text": " or something that can weld, wield, weld things together for us. That introduces a mandatory", "tokens": [50952, 420, 746, 300, 393, 13964, 11, 35982, 11, 13964, 721, 1214, 337, 505, 13, 663, 31472, 257, 22173, 51280], "temperature": 0.0, "avg_logprob": -0.08837069065198985, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.1195380911231041}, {"id": 894, "seek": 450412, "start": 4522.44, "end": 4528.599999999999, "text": " cut so we cannot get rid of it because the problem is defined to contain it. But note that this is", "tokens": [51280, 1723, 370, 321, 2644, 483, 3973, 295, 309, 570, 264, 1154, 307, 7642, 281, 5304, 309, 13, 583, 3637, 300, 341, 307, 51588], "temperature": 0.0, "avg_logprob": -0.08837069065198985, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.1195380911231041}, {"id": 895, "seek": 450412, "start": 4528.599999999999, "end": 4533.0, "text": " not the same between our two approaches. I have a function pointer there because it's required,", "tokens": [51588, 406, 264, 912, 1296, 527, 732, 11587, 13, 286, 362, 257, 2445, 23918, 456, 570, 309, 311, 4739, 11, 51808], "temperature": 0.0, "avg_logprob": -0.08837069065198985, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.1195380911231041}, {"id": 896, "seek": 453300, "start": 4533.72, "end": 4538.6, "text": " and you'll note I minimized the number of all the way down to one. I didn't put it in there", "tokens": [50400, 293, 291, 603, 3637, 286, 4464, 1602, 264, 1230, 295, 439, 264, 636, 760, 281, 472, 13, 286, 994, 380, 829, 309, 294, 456, 50644], "temperature": 0.0, "avg_logprob": -0.08589462311037126, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.024271953850984573}, {"id": 897, "seek": 453300, "start": 4538.6, "end": 4543.16, "text": " because I think it saves program time. In fact, I'm not really sure I want it there at all. I", "tokens": [50644, 570, 286, 519, 309, 19155, 1461, 565, 13, 682, 1186, 11, 286, 478, 406, 534, 988, 286, 528, 309, 456, 412, 439, 13, 286, 50872], "temperature": 0.0, "avg_logprob": -0.08589462311037126, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.024271953850984573}, {"id": 898, "seek": 453300, "start": 4543.16, "end": 4547.88, "text": " haven't actually implemented this particular system in an OS, so it's somewhat off the top of my head,", "tokens": [50872, 2378, 380, 767, 12270, 341, 1729, 1185, 294, 364, 12731, 11, 370, 309, 311, 8344, 766, 264, 1192, 295, 452, 1378, 11, 51108], "temperature": 0.0, "avg_logprob": -0.08589462311037126, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.024271953850984573}, {"id": 899, "seek": 453300, "start": 4547.88, "end": 4552.76, "text": " but it's very impossible that if I actually went to write this, I wouldn't include that function", "tokens": [51108, 457, 309, 311, 588, 6243, 300, 498, 286, 767, 1437, 281, 2464, 341, 11, 286, 2759, 380, 4090, 300, 2445, 51352], "temperature": 0.0, "avg_logprob": -0.08589462311037126, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.024271953850984573}, {"id": 900, "seek": 453300, "start": 4552.76, "end": 4559.8, "text": " pointer at all. Instead, I might just have the OS thread reading the queue, sorry, the OS thread", "tokens": [51352, 23918, 412, 439, 13, 7156, 11, 286, 1062, 445, 362, 264, 12731, 7207, 3760, 264, 18639, 11, 2597, 11, 264, 12731, 7207, 51704], "temperature": 0.0, "avg_logprob": -0.08589462311037126, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.024271953850984573}, {"id": 901, "seek": 455980, "start": 4559.8, "end": 4567.0, "text": " reading the queue, and pre-filtering the packets for quota permissions, then updating a shared", "tokens": [50364, 3760, 264, 18639, 11, 293, 659, 12, 19776, 34200, 264, 30364, 337, 45171, 32723, 11, 550, 25113, 257, 5507, 50724], "temperature": 0.0, "avg_logprob": -0.10686727870594372, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.0407724492251873}, {"id": 902, "seek": 455980, "start": 4567.0, "end": 4572.68, "text": " memory access that lets the driver know it can process the packets directly without actually", "tokens": [50724, 4675, 2105, 300, 6653, 264, 6787, 458, 309, 393, 1399, 264, 30364, 3838, 1553, 767, 51008], "temperature": 0.0, "avg_logprob": -0.10686727870594372, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.0407724492251873}, {"id": 903, "seek": 455980, "start": 4572.68, "end": 4578.6, "text": " implementing. I can't say that's for sure what I would do, but it's probably something I would try.", "tokens": [51008, 18114, 13, 286, 393, 380, 584, 300, 311, 337, 988, 437, 286, 576, 360, 11, 457, 309, 311, 1391, 746, 286, 576, 853, 13, 51304], "temperature": 0.0, "avg_logprob": -0.10686727870594372, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.0407724492251873}, {"id": 904, "seek": 455980, "start": 4578.6, "end": 4583.88, "text": " So thanks for overstating the similarity of our approaches, but I think that they're similar,", "tokens": [51304, 407, 3231, 337, 48834, 990, 264, 32194, 295, 527, 11587, 11, 457, 286, 519, 300, 436, 434, 2531, 11, 51568], "temperature": 0.0, "avg_logprob": -0.10686727870594372, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.0407724492251873}, {"id": 905, "seek": 455980, "start": 4583.88, "end": 4589.0, "text": " then I guess that's just where we end up. Thanks for taking the time to create this thread which", "tokens": [51568, 550, 286, 2041, 300, 311, 445, 689, 321, 917, 493, 13, 2561, 337, 1940, 264, 565, 281, 1884, 341, 7207, 597, 51824], "temperature": 0.0, "avg_logprob": -0.10686727870594372, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.0407724492251873}, {"id": 906, "seek": 458900, "start": 4589.0, "end": 4594.68, "text": " pushed the GitHub emoji to check a well beyond its limits. Sorry, I had to read all that, but yeah,", "tokens": [50364, 9152, 264, 23331, 31595, 281, 1520, 257, 731, 4399, 1080, 10406, 13, 4919, 11, 286, 632, 281, 1401, 439, 300, 11, 457, 1338, 11, 50648], "temperature": 0.0, "avg_logprob": -0.15536761283874512, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.015067562460899353}, {"id": 907, "seek": 458900, "start": 4594.68, "end": 4598.68, "text": " that was all right. So this is kind of the point I was trying to point out is that case was saying", "tokens": [50648, 300, 390, 439, 558, 13, 407, 341, 307, 733, 295, 264, 935, 286, 390, 1382, 281, 935, 484, 307, 300, 1389, 390, 1566, 50848], "temperature": 0.0, "avg_logprob": -0.15536761283874512, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.015067562460899353}, {"id": 908, "seek": 458900, "start": 4598.68, "end": 4604.2, "text": " this isn't what you were showing, and the point where I say like Mr. Martin thought he won the", "tokens": [50848, 341, 1943, 380, 437, 291, 645, 4099, 11, 293, 264, 935, 689, 286, 584, 411, 2221, 13, 9184, 1194, 415, 1582, 264, 51124], "temperature": 0.0, "avg_logprob": -0.15536761283874512, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.015067562460899353}, {"id": 909, "seek": 458900, "start": 4604.2, "end": 4609.8, "text": " argument, like you need to use this style, is by using the canonical case of requiring it,", "tokens": [51124, 6770, 11, 411, 291, 643, 281, 764, 341, 3758, 11, 307, 538, 1228, 264, 46491, 1389, 295, 24165, 309, 11, 51404], "temperature": 0.0, "avg_logprob": -0.15536761283874512, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.015067562460899353}, {"id": 910, "seek": 458900, "start": 4609.8, "end": 4613.24, "text": " which is the canonical case is a data stream, a canonical case of like you've got different", "tokens": [51404, 597, 307, 264, 46491, 1389, 307, 257, 1412, 4309, 11, 257, 46491, 1389, 295, 411, 291, 600, 658, 819, 51576], "temperature": 0.0, "avg_logprob": -0.15536761283874512, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.015067562460899353}, {"id": 911, "seek": 461324, "start": 4613.24, "end": 4619.24, "text": " operations fixed interface, but you've got an opaque different what it actually variant type,", "tokens": [50364, 7705, 6806, 9226, 11, 457, 291, 600, 658, 364, 42687, 819, 437, 309, 767, 17501, 2010, 11, 50664], "temperature": 0.0, "avg_logprob": -0.19962750684033642, "compression_ratio": 1.75, "no_speech_prob": 0.2390878051519394}, {"id": 912, "seek": 461324, "start": 4619.24, "end": 4623.32, "text": " whatever it is. And then they talk about actually how does it implement the operating system case,", "tokens": [50664, 2035, 309, 307, 13, 400, 550, 436, 751, 466, 767, 577, 775, 309, 4445, 264, 7447, 1185, 1389, 11, 50868], "temperature": 0.0, "avg_logprob": -0.19962750684033642, "compression_ratio": 1.75, "no_speech_prob": 0.2390878051519394}, {"id": 913, "seek": 461324, "start": 4623.32, "end": 4626.679999999999, "text": " it actually just shows that actually effective this is how you do it in Linux. We don't know how", "tokens": [50868, 309, 767, 445, 3110, 300, 767, 4942, 341, 307, 577, 291, 360, 309, 294, 18734, 13, 492, 500, 380, 458, 577, 51036], "temperature": 0.0, "avg_logprob": -0.19962750684033642, "compression_ratio": 1.75, "no_speech_prob": 0.2390878051519394}, {"id": 914, "seek": 461324, "start": 4626.679999999999, "end": 4630.599999999999, "text": " Windows works kind of, we can reverse engineer it, but like it's not the source code, it's not", "tokens": [51036, 8591, 1985, 733, 295, 11, 321, 393, 9943, 11403, 309, 11, 457, 411, 309, 311, 406, 264, 4009, 3089, 11, 309, 311, 406, 51232], "temperature": 0.0, "avg_logprob": -0.19962750684033642, "compression_ratio": 1.75, "no_speech_prob": 0.2390878051519394}, {"id": 915, "seek": 461324, "start": 4630.599999999999, "end": 4637.639999999999, "text": " public obviously, because it's a closed source operating system. But that's kind of the the", "tokens": [51232, 1908, 2745, 11, 570, 309, 311, 257, 5395, 4009, 7447, 1185, 13, 583, 300, 311, 733, 295, 264, 264, 51584], "temperature": 0.0, "avg_logprob": -0.19962750684033642, "compression_ratio": 1.75, "no_speech_prob": 0.2390878051519394}, {"id": 916, "seek": 463764, "start": 4637.64, "end": 4644.280000000001, "text": " issue that's going on here. Mr. Martin thought he won by showing like you already just did dynamic", "tokens": [50364, 2734, 300, 311, 516, 322, 510, 13, 2221, 13, 9184, 1194, 415, 1582, 538, 4099, 411, 291, 1217, 445, 630, 8546, 50696], "temperature": 0.0, "avg_logprob": -0.14584893939875754, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.05170374736189842}, {"id": 917, "seek": 463764, "start": 4644.280000000001, "end": 4649.96, "text": " dispatch. In case you went, you just find it to have it. And in fact, I didn't even require multiple", "tokens": [50696, 36729, 13, 682, 1389, 291, 1437, 11, 291, 445, 915, 309, 281, 362, 309, 13, 400, 294, 1186, 11, 286, 994, 380, 754, 3651, 3866, 50980], "temperature": 0.0, "avg_logprob": -0.14584893939875754, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.05170374736189842}, {"id": 918, "seek": 463764, "start": 4649.96, "end": 4655.160000000001, "text": " functions acquired one, it's not tripling direct to any single interaction. And I just had a switch", "tokens": [50980, 6828, 17554, 472, 11, 309, 311, 406, 1376, 11970, 2047, 281, 604, 2167, 9285, 13, 400, 286, 445, 632, 257, 3679, 51240], "temperature": 0.0, "avg_logprob": -0.14584893939875754, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.05170374736189842}, {"id": 919, "seek": 463764, "start": 4655.160000000001, "end": 4658.12, "text": " name in there, because this is also how the operating system does it. And it's better for", "tokens": [51240, 1315, 294, 456, 11, 570, 341, 307, 611, 577, 264, 7447, 1185, 775, 309, 13, 400, 309, 311, 1101, 337, 51388], "temperature": 0.0, "avg_logprob": -0.14584893939875754, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.05170374736189842}, {"id": 920, "seek": 463764, "start": 4658.12, "end": 4664.200000000001, "text": " literally CPU cycles and reduced programmer cycles. It's not one or the other. So hopefully this is", "tokens": [51388, 3736, 13199, 17796, 293, 9212, 32116, 17796, 13, 467, 311, 406, 472, 420, 264, 661, 13, 407, 4696, 341, 307, 51692], "temperature": 0.0, "avg_logprob": -0.14584893939875754, "compression_ratio": 1.6409395973154361, "no_speech_prob": 0.05170374736189842}, {"id": 921, "seek": 466420, "start": 4664.2, "end": 4669.4, "text": " okay. And I'm done now. I was just going to do this. And I was talking about this, we've already", "tokens": [50364, 1392, 13, 400, 286, 478, 1096, 586, 13, 286, 390, 445, 516, 281, 360, 341, 13, 400, 286, 390, 1417, 466, 341, 11, 321, 600, 1217, 50624], "temperature": 0.0, "avg_logprob": -0.11899783198994801, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.1125931665301323}, {"id": 922, "seek": 466420, "start": 4669.4, "end": 4674.36, "text": " discussed this, what I've seen was I did a tweet on it mildly. And there were some other things", "tokens": [50624, 7152, 341, 11, 437, 286, 600, 1612, 390, 286, 630, 257, 15258, 322, 309, 15154, 356, 13, 400, 456, 645, 512, 661, 721, 50872], "temperature": 0.0, "avg_logprob": -0.11899783198994801, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.1125931665301323}, {"id": 923, "seek": 466420, "start": 4674.36, "end": 4678.2, "text": " I was talking about here on to talk about Mr. Martin, but I didn't in the end be honest with you.", "tokens": [50872, 286, 390, 1417, 466, 510, 322, 281, 751, 466, 2221, 13, 9184, 11, 457, 286, 994, 380, 294, 264, 917, 312, 3245, 365, 291, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11899783198994801, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.1125931665301323}, {"id": 924, "seek": 466420, "start": 4679.88, "end": 4685.32, "text": " It was more of a, I'm just showing the rhetoric styles of Mr. Martin. That was it. So I hope you've", "tokens": [51148, 467, 390, 544, 295, 257, 11, 286, 478, 445, 4099, 264, 29604, 13273, 295, 2221, 13, 9184, 13, 663, 390, 309, 13, 407, 286, 1454, 291, 600, 51420], "temperature": 0.0, "avg_logprob": -0.11899783198994801, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.1125931665301323}, {"id": 925, "seek": 466420, "start": 4685.32, "end": 4691.72, "text": " enjoyed this. I apologize. This is about 120 minutes long. So thank you for putting up with", "tokens": [51420, 4626, 341, 13, 286, 12328, 13, 639, 307, 466, 10411, 2077, 938, 13, 407, 1309, 291, 337, 3372, 493, 365, 51740], "temperature": 0.0, "avg_logprob": -0.11899783198994801, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.1125931665301323}, {"id": 926, "seek": 469172, "start": 4691.72, "end": 4697.320000000001, "text": " all this. I wanted to end off with this little thing here is what I wanted in for. So we already", "tokens": [50364, 439, 341, 13, 286, 1415, 281, 917, 766, 365, 341, 707, 551, 510, 307, 437, 286, 1415, 294, 337, 13, 407, 321, 1217, 50644], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 927, "seek": 469172, "start": 4697.320000000001, "end": 4702.12, "text": " had this in his code, but someone commented here saying, look, I says, but there's kinds of environments", "tokens": [50644, 632, 341, 294, 702, 3089, 11, 457, 1580, 26940, 510, 1566, 11, 574, 11, 286, 1619, 11, 457, 456, 311, 3685, 295, 12388, 50884], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 928, "seek": 469172, "start": 4702.12, "end": 4705.56, "text": " though, the parsimony is important nowadays, far and few between the vast majority of software", "tokens": [50884, 1673, 11, 264, 21156, 332, 2526, 307, 1021, 13434, 11, 1400, 293, 1326, 1296, 264, 8369, 6286, 295, 4722, 51056], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 929, "seek": 469172, "start": 4705.56, "end": 4709.88, "text": " requires less than 1% of modern processing. This is the first section we read. What's more", "tokens": [51056, 7029, 1570, 813, 502, 4, 295, 4363, 9007, 13, 639, 307, 264, 700, 3541, 321, 1401, 13, 708, 311, 544, 51272], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 930, "seek": 469172, "start": 4709.88, "end": 4713.400000000001, "text": " processes are so cheap and available that is a trivial matter to add more of them to the system.", "tokens": [51272, 7555, 366, 370, 7084, 293, 2435, 300, 307, 257, 26703, 1871, 281, 909, 544, 295, 552, 281, 264, 1185, 13, 51448], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 931, "seek": 469172, "start": 4713.400000000001, "end": 4717.88, "text": " Someone replied, I should know this person by the way personally, we do not consider it", "tokens": [51448, 8734, 20345, 11, 286, 820, 458, 341, 954, 538, 264, 636, 5665, 11, 321, 360, 406, 1949, 309, 51672], "temperature": 0.0, "avg_logprob": -0.19620296728872036, "compression_ratio": 1.6973293768545994, "no_speech_prob": 0.04088657349348068}, {"id": 932, "seek": 471788, "start": 4717.88, "end": 4721.56, "text": " good engineering practice of the person wrote it, not the quote, good engineering practice to", "tokens": [50364, 665, 7043, 3124, 295, 264, 954, 4114, 309, 11, 406, 264, 6513, 11, 665, 7043, 3124, 281, 50548], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 933, "seek": 471788, "start": 4721.56, "end": 4726.4400000000005, "text": " consume a resource lavishly just because it happens to be cheap in the class of it or Nicholas worth", "tokens": [50548, 14732, 257, 7684, 20923, 742, 356, 445, 570, 309, 2314, 281, 312, 7084, 294, 264, 1508, 295, 309, 420, 22924, 3163, 50792], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 934, "seek": 471788, "start": 4726.4400000000005, "end": 4730.12, "text": " one of my actual programming idols out there. And I love this quote because it's kind of as", "tokens": [50792, 472, 295, 452, 3539, 9410, 29959, 484, 456, 13, 400, 286, 959, 341, 6513, 570, 309, 311, 733, 295, 382, 50976], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 935, "seek": 471788, "start": 4730.12, "end": 4734.4400000000005, "text": " viet slaw of worth slaw. However, it doesn't care. It's either name by or bind value. It doesn't", "tokens": [50976, 371, 1684, 262, 5901, 295, 3163, 262, 5901, 13, 2908, 11, 309, 1177, 380, 1127, 13, 467, 311, 2139, 1315, 538, 420, 14786, 2158, 13, 467, 1177, 380, 51192], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 936, "seek": 471788, "start": 4734.4400000000005, "end": 4739.4800000000005, "text": " matter. And then Mr. Martin replies, that depends upon the, which resource you are talking about", "tokens": [51192, 1871, 13, 400, 550, 2221, 13, 9184, 42289, 11, 300, 5946, 3564, 264, 11, 597, 7684, 291, 366, 1417, 466, 51444], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 937, "seek": 471788, "start": 4739.4800000000005, "end": 4743.400000000001, "text": " computer cycles, computer cycle, programmer cycles, which should you trade against? And again,", "tokens": [51444, 3820, 17796, 11, 3820, 6586, 11, 32116, 17796, 11, 597, 820, 291, 4923, 1970, 30, 400, 797, 11, 51640], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 938, "seek": 471788, "start": 4743.400000000001, "end": 4747.16, "text": " I don't see what being the odds, but simpler code is easier to write. Our bubble source is", "tokens": [51640, 286, 500, 380, 536, 437, 885, 264, 17439, 11, 457, 18587, 3089, 307, 3571, 281, 2464, 13, 2621, 12212, 4009, 307, 51828], "temperature": 0.0, "avg_logprob": -0.3271255019288626, "compression_ratio": 1.8246575342465754, "no_speech_prob": 0.08270195871591568}, {"id": 939, "seek": 474716, "start": 4747.16, "end": 4751.639999999999, "text": " simpler. The tricky again, it's another trick. It was just last showing the rhetoric trick.", "tokens": [50364, 18587, 13, 440, 12414, 797, 11, 309, 311, 1071, 4282, 13, 467, 390, 445, 1036, 4099, 264, 29604, 4282, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1425696331521739, "compression_ratio": 1.872, "no_speech_prob": 0.010111089795827866}, {"id": 940, "seek": 474716, "start": 4751.639999999999, "end": 4759.16, "text": " Simple is actually an overloaded term in programming. And it's an overloaded term in English,", "tokens": [50588, 21532, 307, 767, 364, 28777, 292, 1433, 294, 9410, 13, 400, 309, 311, 364, 28777, 292, 1433, 294, 3669, 11, 50964], "temperature": 0.0, "avg_logprob": -0.1425696331521739, "compression_ratio": 1.872, "no_speech_prob": 0.010111089795827866}, {"id": 941, "seek": 474716, "start": 4759.16, "end": 4763.24, "text": " because simply you need to mean the opposite of complicated, or it can mean the opposite of", "tokens": [50964, 570, 2935, 291, 643, 281, 914, 264, 6182, 295, 6179, 11, 420, 309, 393, 914, 264, 6182, 295, 51168], "temperature": 0.0, "avg_logprob": -0.1425696331521739, "compression_ratio": 1.872, "no_speech_prob": 0.010111089795827866}, {"id": 942, "seek": 474716, "start": 4763.24, "end": 4768.36, "text": " complex. And in the case of complex, the technical term would be simplex. So is it simple as in", "tokens": [51168, 3997, 13, 400, 294, 264, 1389, 295, 3997, 11, 264, 6191, 1433, 576, 312, 2199, 87, 13, 407, 307, 309, 2199, 382, 294, 51424], "temperature": 0.0, "avg_logprob": -0.1425696331521739, "compression_ratio": 1.872, "no_speech_prob": 0.010111089795827866}, {"id": 943, "seek": 474716, "start": 4768.36, "end": 4774.68, "text": " not complicated or simple as in simplex? And he has just done this on purpose. And he knows it", "tokens": [51424, 406, 6179, 420, 2199, 382, 294, 2199, 87, 30, 400, 415, 575, 445, 1096, 341, 322, 4334, 13, 400, 415, 3255, 309, 51740], "temperature": 0.0, "avg_logprob": -0.1425696331521739, "compression_ratio": 1.872, "no_speech_prob": 0.010111089795827866}, {"id": 944, "seek": 477468, "start": 4774.68, "end": 4780.92, "text": " very well by saying, well, bullsaw is simplex, but it's very expensive. Multiply and multiply by", "tokens": [50364, 588, 731, 538, 1566, 11, 731, 11, 4693, 82, 1607, 307, 2199, 87, 11, 457, 309, 311, 588, 5124, 13, 31150, 356, 293, 12972, 538, 50676], "temperature": 0.0, "avg_logprob": -0.2835548966019242, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.19370760023593903}, {"id": 945, "seek": 477468, "start": 4780.92, "end": 4785.88, "text": " repeat about it. So it's simple. Actually, that's how, that's how like AMD processors, not AMD ARM", "tokens": [50676, 7149, 466, 309, 13, 407, 309, 311, 2199, 13, 5135, 11, 300, 311, 577, 11, 300, 311, 577, 411, 34808, 27751, 11, 406, 34808, 45209, 50924], "temperature": 0.0, "avg_logprob": -0.2835548966019242, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.19370760023593903}, {"id": 946, "seek": 477468, "start": 4785.88, "end": 4791.320000000001, "text": " processors actually work, by the way, they don't technically implement multiplication. x86 does,", "tokens": [50924, 27751, 767, 589, 11, 538, 264, 636, 11, 436, 500, 380, 12120, 4445, 27290, 13, 2031, 22193, 775, 11, 51196], "temperature": 0.0, "avg_logprob": -0.2835548966019242, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.19370760023593903}, {"id": 947, "seek": 477468, "start": 4791.320000000001, "end": 4798.52, "text": " by the way, ARM does AMD 64. Sorry, I should say, AMD 64 does an x86 in general. It's actually one", "tokens": [51196, 538, 264, 636, 11, 45209, 775, 34808, 12145, 13, 4919, 11, 286, 820, 584, 11, 34808, 12145, 775, 364, 2031, 22193, 294, 2674, 13, 467, 311, 767, 472, 51556], "temperature": 0.0, "avg_logprob": -0.2835548966019242, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.19370760023593903}, {"id": 948, "seek": 477468, "start": 4798.52, "end": 4803.08, "text": " of the only, it's very, very, you find a processor that does this, but they did it. Linear searches", "tokens": [51556, 295, 264, 787, 11, 309, 311, 588, 11, 588, 11, 291, 915, 257, 15321, 300, 775, 341, 11, 457, 436, 630, 309, 13, 14670, 289, 26701, 51784], "temperature": 0.0, "avg_logprob": -0.2835548966019242, "compression_ratio": 1.7854545454545454, "no_speech_prob": 0.19370760023593903}, {"id": 949, "seek": 480308, "start": 4803.08, "end": 4806.6, "text": " are simple. Like, yeah, they are simplex. They also may be simpler, faster as well, but they might", "tokens": [50364, 366, 2199, 13, 1743, 11, 1338, 11, 436, 366, 2199, 87, 13, 814, 611, 815, 312, 18587, 11, 4663, 382, 731, 11, 457, 436, 1062, 50540], "temperature": 0.0, "avg_logprob": -0.1426954847393614, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.09972038865089417}, {"id": 950, "seek": 480308, "start": 4806.6, "end": 4814.5199999999995, "text": " not be. Like, there's a reason. But this is the trick. So I just want to end on that note. So I hope", "tokens": [50540, 406, 312, 13, 1743, 11, 456, 311, 257, 1778, 13, 583, 341, 307, 264, 4282, 13, 407, 286, 445, 528, 281, 917, 322, 300, 3637, 13, 407, 286, 1454, 50936], "temperature": 0.0, "avg_logprob": -0.1426954847393614, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.09972038865089417}, {"id": 951, "seek": 480308, "start": 4814.5199999999995, "end": 4821.48, "text": " you've enjoyed this. Please remember to like that smash button, and to comment in the description", "tokens": [50936, 291, 600, 4626, 341, 13, 2555, 1604, 281, 411, 300, 17960, 2960, 11, 293, 281, 2871, 294, 264, 3855, 51284], "temperature": 0.0, "avg_logprob": -0.1426954847393614, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.09972038865089417}, {"id": 952, "seek": 480308, "start": 4821.48, "end": 4825.24, "text": " below. And again, if you want to read any of these links before, I will post them in the description", "tokens": [51284, 2507, 13, 400, 797, 11, 498, 291, 528, 281, 1401, 604, 295, 613, 6123, 949, 11, 286, 486, 2183, 552, 294, 264, 3855, 51472], "temperature": 0.0, "avg_logprob": -0.1426954847393614, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.09972038865089417}, {"id": 953, "seek": 480308, "start": 4825.24, "end": 4830.04, "text": " of the doobly-doo below below here. And hopefully you've enjoyed this. This is a very unstructured", "tokens": [51472, 295, 264, 360, 996, 356, 12, 48302, 2507, 2507, 510, 13, 400, 4696, 291, 600, 4626, 341, 13, 639, 307, 257, 588, 18799, 46847, 51712], "temperature": 0.0, "avg_logprob": -0.1426954847393614, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.09972038865089417}, {"id": 954, "seek": 483004, "start": 4830.12, "end": 4837.24, "text": " ranty talking about Mr. Martin's rhetoric style with regards to clean code, how, and at the end,", "tokens": [50368, 45332, 88, 1417, 466, 2221, 13, 9184, 311, 29604, 3758, 365, 14258, 281, 2541, 3089, 11, 577, 11, 293, 412, 264, 917, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1409768131044176, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.060652896761894226}, {"id": 955, "seek": 483004, "start": 4837.24, "end": 4841.64, "text": " effectively, he just stated exactly what most people thought clean code was stating, and Casey", "tokens": [50724, 8659, 11, 415, 445, 11323, 2293, 437, 881, 561, 1194, 2541, 3089, 390, 26688, 11, 293, 27369, 50944], "temperature": 0.0, "avg_logprob": -0.1409768131044176, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.060652896761894226}, {"id": 956, "seek": 483004, "start": 4841.64, "end": 4850.44, "text": " went, so I was right about what clean code was. Okay, thank you. So goodbye, everyone, and stay", "tokens": [50944, 1437, 11, 370, 286, 390, 558, 466, 437, 2541, 3089, 390, 13, 1033, 11, 1309, 291, 13, 407, 12084, 11, 1518, 11, 293, 1754, 51384], "temperature": 0.0, "avg_logprob": -0.1409768131044176, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.060652896761894226}, {"id": 957, "seek": 485044, "start": 4850.44, "end": 4852.44, "text": " tuned for the next video.", "tokens": [50364, 10870, 337, 264, 958, 960, 13, 50464], "temperature": 0.0, "avg_logprob": -0.4425128565894233, "compression_ratio": 0.7575757575757576, "no_speech_prob": 0.3060910999774933}], "language": "en"}