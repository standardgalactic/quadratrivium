Hello and welcome, I am Gingerbell and today I'll be talking about the fiasco that has
happened between Casey Muratori and Mr. Robert C. Martin. But before that I'm going to explain
why the history got here and I'm going to also explain some stuff. I'm not going to
try and criticise clean code itself. Casey Muratori has been trying to do this in the
long discussions he's had with Mr. Robert C. Martin already. But it's one of those things
where I just want to kind of show the rhetoric tricks of Mr. Robert C. Martin himself. So
before we get to that start off, let's begin with the thing that started it all, which
was this video that Casey made public from his thing. It's called clean code, horrible
performance, where they say 22 minutes long video, him showing the examples of what clean
code is and going into a more, let's say more like simplified code, which is more optimised
performance and showing the cost. Hey, if you do it the clean code where you're going
to be 15 to 25 times slower as your performance, do you want to take that hit? Understand what
the costs are kind of you. And again, this is this view has also taken our context is
blown up by mad. It's nearly half a million views so far at the moment at the time of
recording. And so it's clearly gone viral across the programming world. Unfortunately,
because it went viral, a lot of the context got lost. And because the context got lost.
People just adding their own context into it without even bothering to learn it. So the
context was this comes from a series that Casey's been doing on computer hands.com,
where it's a performance awareness course. So specifically the this is the programming
course he's been doing to performance awareness stuff. And this is a subscribed based thing
on the on the on here. And he's been doing many different topics on here as I was able
to learn how to performance awareness. Specifically, this was the blog post and he made completely
public for everybody showing all the code showing all this stuff. So then you can see
a whole video is all kind of transcribed down. And it's part of a series. It's not the beginning
of the fifth series is quite in the middle. So it's kind of like, Oh, okay, we're not
starting from a random place. So and also when people say and talk about the context
of this Casey understands this like, look, reminder, I don't think clean code is bad
just because of performance. My recent video is about poor performance, because it's part
of a course on performance. This is the context many people lost. And he's been doing this
for decades is saying so I recommend reading these tweets, I will try and provide all of
the links to everything I'm showing today in the description or the do blue do whatever
you want to do down below on YouTube. So be here. So yeah, hello. Good. So give a background.
He's picked up the attention of Robert, Mr. Robert C Martin, which he colloquially calls
himself Uncle Bob. For this talk, I'm just going to call him Mr. Martin, because I just
prefer saying Mr. Martin, insert your guesses as to why. But yeah, he is very well known
for my mainly three things, which is the agile manifesto, he helped develop that solid the
solid principles. So the agile manifesto and solid principles, which again, many people
know from the world, especially that he wrote it in his in his book, which is first in design
as principles and design patterns, as it says on here. And he's also in this thing known
for clean code. So clean with capital C code with capital C trademarked. This is his particular
thing, the capital C clean code thing. Okay. And this is what he kind of tries to describe.
So to get to show my biases and my background, I am the creator of the program language here.
And the only program language is the general purpose program language with the distinct
typing built for high performance modern systems and data order programming. So clearly, I'm
showing my biases, and I'm cleaning on more like case and oratory side when it comes to
this discussion. And also, I work at Django effects on emogen and liquid gen and geo gen,
which are all high performance real time pieces software like simulations, again, engines
for fire, smoke and explosions in real time. So clearly, I work in an industry where we
really care about high performance real time stuff. So clearly, I'm showing my biases straight
away. So people understand what's going on. Okay, so now you know, that's on the way. Can
we explain what clean code is before we get into this? So sure. So there is this kind of
little document I found the other day, and it's been well actively updated by looks only eight
hours ago at this time of recording. And today's date is the March the 30th, I believe. Yes, March
the 30th. So it's very active or someone's updated there's probably some typos and such
we can even see the revisions. And yeah, it's just some, hey, just capitalizing some straw.
That was all it was. Now, many people have seen to have liked this clearly over 5000 stars and
over 1000 forks of this gist, as well gist or I don't know we pronounce it on GitHub,
and explained some of the began your principles or points about clean code. Now there's many
of this. This is the thing about which is why clean code capital C thing trademarked by Mr
Martin is very popular because there's many of these rules, which no one would disagree with,
like follow standard conventions. Yeah, because conventions are a good thing because then you're
working on the same sun, only break them when you need to keep it simple, stupid, you're fine,
whatever. Boy Scott rule, leave the camp around cleaner than you found it, always find the root
cause you're no problem like this, yada, yada. Now some of these are things, okay, some of these are
not essential. These are accidental. Like, again, follow standard conventions. That's not
a unique to clean code, is it? You can do that in any philosophy out there. It's not a unique
principle to clean code itself. But some things like, for instance, I would say more essential
to clean code or prefer polymorphism to if or else cases. And separate multi floating code.
I'm not even sure what that means. Use dependency injection. Follow the law of Demeter or many
other things, many other things like here, like, Oh, use small functions functions, they only do
one thing use descriptive names, like getting that descriptive names, everyone agrees to that to a
certain extent, prefer fewer arguments have no side effects. So be more functional, it means more
and more rather than be like, have side effects itself, like be more imperative relying on like
global state or modifying state or whatever, don't use flag arguments, yada, yada, like, okay,
some of these people will agree with some people will disagree with them. But here's where the
the problem is with some of this is that for the most part, some of these rules,
people will agree with some of them don't. One of the particular is like small rules for me,
I actually disagree with this particular thing. There was a post here, this is on Jonathan
blows blog old, very old blog, actually, this one 2016. But he's actually even older than that,
because it's an old email response between him and john Carmack. So this is john Carmack explaining
effectively, what he preferred for the things is not the clean code up. This is what I wanted
was the wrong one. Whoops. Let's go to the blog post again. And it's this one here. So I accidentally
clicked the wrong button then. So this is john inline code. And john Carmack in the email is
explained, actually, he doesn't like the separate single functions here. It's better just have
one big function and then comment them. Now, some people might say be a bit easier to manage
looking at re things. Yeah, for code reviews, in a big corporate setting, it might be easier
looking a single function. But there's a few things you have to understand functions have
costs. If you split these things into multiple functions, this is a one is an extra cost. Yes,
is a minor cost when calling a function. But like that most people don't care about that cost,
unless you're doing particular things like you're worried about stack stacks or anything like that.
Like, okay, most things don't care. One thing it does do is it does actually doesn't mean it's
very easy to optimize for the optimizer. And I know how compilers work because I work on them for
kind of a living. And if you have things in line, one, it's not hard to read by just using
comments everywhere or block codes or anything like that. I think it's just as easy. And if you've
got text editors, which are use collapsible things, that's great. That's okay, no problems, just deal
with it that way. But then it's like, okay, but the optimizer can be ready, doesn't have to worry
about trying to inline that function. And then now optimize the new inline function that's been
got in line is out of another function. So there's that. And also you can usually start to see easy
patterns as well. If you start manually inlining things, it's not hard to read. Yes, okay, you've
got 10,000 lines, but most people's IDs and text editors are very easy for code folding, code
searching, code and organization. We're not living in the 80s anymore, or even the 70s,
to be honest, because even small talk had better options than this. I'm not saying I'm a big fan
of small talk. But again, the tooling is the argument going small function is more of a, hey,
it's our code review practices, big corporations, testing practices, and also maybe just tooling
practices. So that's one thing. But it's going to recommend highly reading this article, I really
do from 2014, again, it's from 2007, as it says here, I recommend it. But what I'm trying to get
out here about the word clean code, and I'm not even talking about the actual discussion that
Casey Motoria, they've been having yet, because I want to try to build up a picture here, as you
can probably tell, trying to be a storyteller, not very good at it, but let's carry on with it,
is that the concept of clean code is what I want to the term it capital C, capital
C on both of them, trademarked for Mr. Martin, is what I'm going to dub a pork barrel name.
So a pork barrel is a thing that America, American English, but it's kind of a
you have this bill, and it has a particular thing like citizens against government waste.
But it also has all of these things that are nothing even related to the actual name of the
bill. And to keep it in American context, because I know most people watching going to be Americans,
so I'm not going to use an English example, or another European example, like
Germans, I'm just going to use American example, I've run recent one as well,
is the Inflation Reduction Act of 2022. The name of it, the Inflation Reduction Act.
Okay, now I'm trying to be again, I'm not an American, don't really care politics, but I think
most people would agree, this act did not reduce inflation, in fact, it printed more money,
and more excess money, that money was not being in high demand.
So it increased inflation, in fact, it had loads of other things in there to do with
not to do with inflation. But a really clever political rhetoric trick is to say, oh, you
don't like this bill, we must like inflation, you're bad, everyone dislikes inflation.
So you must be, oh, you can't be against this bill, can you? It's like, but this doesn't,
ah, no, no, it doesn't inflation. How dare you don't want to, like, you can do this trick. And
again, it's not a political side either, literally all political parties or politicians,
I do this trick. Some countries like to do, like, oh, we're just getting names from bills.
But then they'll give them a name anyway, like a colloquial one to refer to it rather than giving
it like a letter or a number or some random numbers or something like that bill. And they'll
just say, look, no, this is what we're going to call it. Because technically internally,
the Americans do, but they give them a proper name and also a very long title. Again, this is
to provide for the reconciliation pursuant to Title II of the S Con Rez 14, I'm just reading it
as it says on here. And it's like, okay, but that's a good example from a political standpoint.
I'm just keeping it here, trying to keep it politically neutral. I don't really care about
the old politics, but it's just one of those funny things that show, hey, this is a trick,
because Mr. Martin will actually continually do this throughout. And it will trick, do a lot of
pivoting and a lot of these poor barrel names. Okay. So let's just say this is a good example
of this bad code. Just say no. And it's like, okay, so what's good code then? Because then it's,
phrases in the, oh, it's clean code, obviously. Now there was another tweet, I tried to find,
but I couldn't find it's probably been lost to the Twitter search, or it's just been deleted,
whatever. But he will commonly do this, Mr. Martin go like, oh, the opposite of bad code is clean
code with a capital C trademarked, which is interesting. Because that means anything that's
not clean code is a bad code. Yeah, let's not get there. But again, very clear, careful on this,
I'm not going to criticize him. I'm actually like, in admiration of his rhetoric, he's
a politician level when it comes to rhetoric, I mean this. And it's like, this is really good.
Like he's really good at it. But again, he's been doing it for nearly 50 years. He is what 70 years
old. He's been doing this sort of job since what, God, even the early 90s. So it, okay,
worst, like, it's 30 years, he's been doing this, he's probably been doing it for 40. Okay,
that's what he does for a living. He's very good at this rhetoric. So that's why I'm like,
I'm kind of admiring it into a certain extent, in a weird Machiavellian sense.
But sure, let's carry on with this, shall we? I've got some more things. Another thing in here,
he says, when this whole thing happened when he was talking about it, oh, no,
people don't like this code. But then he says, some people do this. And again,
I've shown you, he's very good, he's very good at knowing memes. He's not an old man, he's an old
man, but he's up to date with a lot of the stuff. And it sounds like silly, but it's not a book,
or the concept, it's a Cartesian pandering immature behavior. The author batches everyone,
and then he just shows this claim like, hey, I know how to play your joke.
Like, and he does, he's not that bad. But then there's other things. So here's like,
Casey Motori comes up with, I mean, he's talking about people criticising, and then he replies to
this, this is where kind of the start of the conversation is happening. So Casey has says
in this, even if true, to what extent would you tolerate the, yes, clean code is much slower,
but it's about programmer productivity for other products. Would you want a car that went only
five miles per hour, because the designers could do less work to make that car? Now,
Mr. Martin replies to what the auto owners notice he does a pivot. This is a pivot. And also,
it doesn't answer the question. He says, the automated mobile industry takes advantage of
every productivity tool they can reduce their enormous manpower cost of designing and manufacturing
cars. As a result, cars have gotten exponentially better over the decades, because the extra productivity
translates to better designs. Yes. But do you think they for their programming, they're using
clean code? Principles. In fact, we know they don't, especially after he's Mercer and stuff like that,
but they have to adhere to certain other things. And like, they're probably not doing clean,
clean code stuff. Now, I know the most things have started to relax, especially when it comes to,
like, Android Auto and I'm like, Apple Car play and stuff like that, it's, they're stuff a buggy.
But that's kind of like, Oh, it's your phone. That's a different thing. It's just we're interfacing
with it and whatever. And it's interesting. He does this because he does it again, when someone
replies to it and anything here. But he's kind of a, he knows what he's doing when he says these
arguments. That's not answering the question. All I'm going to say is that just watch that. Okay.
Another thing is this is when it starts, this was the beginning of his, I wash your thoughts and
he says, Oh, I've commented on this before clean code is made for programmer performance,
not algorithmic performance. If you need the latter, then write in C or assemble and live with
the high cost of development. So few things there already, PI programmer performance and
algorithmic performance. Okay, so program performance, it's the, in the contrast, how do you measure
that thing? How would you know if that your approach is better than another approach? And if
you need the latter, write in C and assemble, okay, it's assembly, I would call this, but yeah,
and then high cost of, so he's already implying that writing in C
is going to be a much higher cost of development than writing in another language.
It might be, but you should only write it in because you need the performance. And it's like,
okay, what? Look at the framing. He knows what he's doing. I'm not saying he's an idiot. He's
very smart. Okay, I'm sorry. I'm picturing it. I can already see which side I'm in, but I'm just
trying to explain the rhetoric tricks. So this is another thing is like the clean code to reply
to later with the automatic ability. I've got these switching around. It doesn't matter. People
says, how do you measure readability of the code by reading it? So obvious. But it's like,
when people say measure, they usually mean a quantifiable thing rather than a qualifying thing.
So this equality and a quantity are two distinct ontological categories, okay, or
epistemological, the many different things, which is not going to philosophy too much, but
you cannot quantify a quality and never qualify a quantity in a sense. They're different things
like, Hey, I have a tape measure here. Yeah, I can say it's got the, I say it's quality of being good
and round and green and stuff like that. And these aren't even very good qualities, to be
honest with you, but it has quantities. I know it's mass just by dropping it. That's what you need to
do. That's absolutely fine. And it masters. I'm just trying to explain the gravity thing. So
clearly it's got mass and we can measure that relative to other things that weigh things. So
we know how much this is weighs. This is probably weighs about, I don't know, eight ounces. So 225
grams ish. That's quite heavy, actually, surprisingly, it's not even a good one. But there's kind of
the thing. So you can actually think you can sort of say, Oh, how, how green is where we can measure
the reflectings of it and then see how much it reflects back a certain light and some wavelengths
and such like this. You can say all these quantities and you're, these are quantities,
okay, but I want to go into too much clearly. I used to be a quantum metrologist. So I know
a lot of you may excuse measurements and all this stuff. But this is a clever trick by reading it.
That is not a quantity. And people are wanting to question how do you measure when we want an
objective measurement? What do you mean is they want a quantity? But he goes out by doing this.
So this was a big long twist post I've been here, where Lawrence Crow again,
the community anyway says people on hand made hating on Casey's videos about performance,
while their company is spending double digits of percentages of their revenue on
Amazon web server bills to serve three forms and a database view. And it's like, okay,
this is great nightlight discussion. Talking about this. And then Mr. Martin says here is his,
his analysis was correct. His rhetoric is abyssin, disingenuous. And the overall point was
extraordinary narrow. Clean code is about increasing programmer performance. He keeps
it straight this not computer performance. What are some real life life non-trial view
code bases support the hypothesis that strict clean code increases program performance
replies with a mean.
Again, he knows what he's doing. I'm not like, this is really cool. Like he knows what he's doing.
But yeah, so you don't have any of his tools that some says it. So the Vittorio
reminded me of a thing for the people I got into a discussion with him around about this time.
And I kind of partially convinced him about like, well, you need you've not go evidence for why one's
better than the other. Like show why how do you know one's better than the other? It's kind of
that question. Like how do you know what measurements are using what quantifiable or even
qualifiable things are you showing? Like, can you just show me the evidence? And then he goes,
he knows this for a fact, he says, the problem with scientific data is it's controlled in
controlled experiments and realistic software environments are economically feasible. You're
asking for something you'll never get. And yet you still decide. So look around and that's just
so it's especially your seniors. So first of all, it's just the first part of this thing here is
we have no evidence for our claims. But it's okay, because your associate seniors may agree
with me already. Nice little pairing here doesn't do the same thing. Okay. That's the first thing.
But then someone said like they said they use over the 10 lines of code sometimes wrong seniors,
I guess, and someone saying like, well, we've got my seniors don't agree with you. So sometimes,
of course, your seniors were correct. I presume they also told you that or else be your smaller
well named functions are better than really badly named functions is like, okay, notice the bad
pairing there already. A well named function is better than a badly named function. Agreed.
Smaller function may not be better than a long function. But notice is smaller well named
functions are better than really badly named functions. Never talked about the length of it.
I know it's like a minor word difference. But he knows what he's doing. And also he just changed
the topic and it's a pivot. He's gone from being the scientific data to now to well, trust your
the trust the authorities of your seniors or elders or whatever, like, that's going to authority
rather than going to like empirical data. Nice little pivot. He knows exactly what he's doing.
So another one here is always remember that computers operate on f in character one f in
character to times he's trying not to swear here. No matter what lovely subroutines you might be
using some replies, what about Sunday? Well, the context of the problem was JavaScript in a browser.
I'm like, what context I even tried to search through the other tweets. There was no context.
So, yeah. Okay, carry on. Another one. Someone has recently equated clean code
over engineering. That is, of course, an oxymoron. An over engine code is by definition not clean
and makes me wonder if those who complain so loudly have actually stood at the target of
their complaints. It's like, see the see the problem. So if he's over engineered, it can't be
clean code. Even though I've seen many clean code, which I've classes over and engineered. In fact,
I think clean code by default is kind of open engineered like it doesn't it's assuming this
could be open to change even though it's a close set of problems, which I'll get onto a bit later.
So then talking about this for tour of Rome, a shot we had earlier, I was discussing with him
previously. And he was kind of like, Oh, well, I can make it even faster. If you just change the
entire style of it and just have a raise of separate types. And I was just like, you being honest,
but this was the conversation I had even trying to confuse it like to not, he was kind of being
a bit confused, but also trying to be like explaining. And we kind of got to a point where
like, Oh, okay, like, first off, you've been a bit disingenuous here, man, with the argument,
but fine. This is not Mr. Martin anymore. This is just me explaining like there are people who are
trying not saying to defend him, but not understanding like Casey's point in this
discussion. So again, before I'm going to read this article, I recommend reading this clean
code, horror performance, YouTube video, again, links are in the description for all of these
links. So don't worry, they'll be there. So now I've done the 20 minutes spiel at the beginning
of this video. Let's get to the meat and potatoes of this entire thing, which is the written down
talk. Now this is quite interesting. And this written down talk is effectively a written
discussion between Casey Meritori and Mr. Martin. And they are both discussing with it,
and it's been split into different things. And I'll explain some points as I come along.
And so other little tricks. So first off, I'm just going to try and read it. I recommend
reading this again, links in the description below for everything. So Casey starts off with
thank you taking the time. And he's just kind of asking questions like so most explanations
on clean code, I've seen that you include all things I mentioned in the video, like
preferring inheritance hierarchies to ifstapes, which means like I remember if we look back
to the the where was the guest I found completely lost it already now.
It was here, right? Here it was here. Yeah, here's the design rules.
Like that some some size, that's not Mr. Martin's himself. But yeah, but it sounds like
you were surprised to hear me say that like all these different things he said is I look
Martin's going to disconnect. I'm not sure there is one. And interesting, he just says there is no
like disconnect. And Casey just asking questions about this. So Casey is asking a basic question
here like look, we're both familiar with Visual Studio and Clang, and it would be a reason more
that you're calling the back and uses it every day. I use these every day. I use LLVM and Visual
Studio every day. Are you calling these a vast majority of software that require less than
one things? And then he would go like, Oh, these are very specialized software, the only few in
existence, and only a few that have actually become popular. And then talks about why this case
and like actually talks about all these different things here, like, okay, speed is not necessarily
an issue. But you can summarize, I'm trying to summarize it. But then the first trick he does,
this is going to be consistent throughout here, is the nanoseconds, microseconds and milliseconds
framing. I will tell you this. So what it will do here is making sure that passing code preserves
nanoseconds can have a big effect. Or he says, I assiduously counted microseconds when it mattered.
Nanoseconds were way beyond anything I could imagine. And so then Casey kind of questions,
is a case of like, it sounds like most software that Casey actually uses and so with myself would
when nanoseconds actually matter. In other words, Visual Studio, LLVM, GCC, Microsoft Word,
PowerPoint, Excel, Firefox, Chrome, FFMPEG, there's a type of that, but TensorFlow, Linux,
Windows, macOS, all of these. And Martin goes again, Mr. Martin goes like, oh, not exactly,
rather my experience abroad, and does all the stuff. And then talks about this other applications
we have modules in the millisecond range. And he says, sort of these time ranges.
It's very like, he's trying to get the reader, because he knows people reading this, to think
about it, well, most problems are in there at ranges of milliseconds. So we can worry about
nanoseconds. Most people aren't have to worry about the automizer nanoseconds. But it's like,
you know, death by 1000 cuts, and 1000 milliseconds is a microsecond, 1000 microseconds is a
millisecond. So if you do things 1000 times badly, and you can, you've now gotten to the other
domain into the other module, as he was calling this, the time module. Okay, fine by me, not
necessarily criticizing that way of thinking, but it's a very weird framing, which,
like, even if I read here, so for example, I'm currently working on an application in which
the vast majority of modules work well at the millisecond level, but a require a 20 x per
better performance. My strategy has been to write the millisecond modules in closure,
because while slow, which is very convenient language, the microsecond modules I wrote in
Java, which were much more faster, more convenient, far less convenient. So it's like, okay, so if
I use them all like Java, it's easier, it's much less convenient, but I can write faster code,
compared to closure, which is, I write code quicker, but it's not going to be as
powerful as that. And those bits, these mergers again, because closure and Java both work on the
JVM, so they can interact with each other pretty easily, ish. But he's just talking about the other
things here. Now, one thing I found interesting is this slash here. You'll see in a minute,
right, he only wrote a book, and he said, oh, I wrote a book on clean code, don't you know?
I've only focused on the millisecond side of the problem, not the nanosecond. It's like,
well, I'm not walking about the performance of the code anymore. But like Casey just goes
town on the question. So Bob answers a very short question, milliseconds, of course.
And then he answers again. Now, he might be asking, wait, why is he answered twice?
Well, he went back in history and added some code text. He rewrote history. Yeah.
I'll say no more. But yeah, he keeps going on about this, and it's very interesting. So now
here's another problem he kind of talks about. And he talks about the actual he says he's now
actually finished watching the video, because he didn't actually watch the video when he started
discussing with the only watch the first bit of it until I've got enough of this. It's like,
you're not going to have discussion with someone you've not even watched the entirety of but you
think you're confident, you know, you can talk about it. I'm like, interesting. If you're that
confident, it usually means you're not actually talking about the thing itself.
Yeah. Yeah. But he says, you notice a nice little pattern. I love that basic form of
the like some coefficient times the length times the width. And in those moments, I only think
programs and mathematicians mathematicians can truly appreciate. It's like, oh, yeah, yeah,
like that was fine. Isn't that lovely? And that's fine, whatever. But Casey comes up,
okay, that sounds great. I think we've gotten to the same page because he was actually talking about
this, not this. Because he says, I've just finished watching it. So I'm going to add this bit back
in to make it split it up. Again, take it as you wish. What I'm trying to say is above paragraphs,
above the box, and there's just like, look, Casey has read and looked a lot of it. Like,
what you're talking about, he seems like these nanoseconds even matter, like everything seems
to be nanoseconds modules, which he says, like, all this makes no sense. And then he again,
he replies with, well, I'm one of the signatories of the agile manifesto who still believes to be
a bit up front of architecture design. Okay, why bring that up? Sure, but fine. This is the
bottom line, of course, is that single factor analysis is always suboptimal. There's no one
true way point. I've always made several times in clean code. And it's like,
but they may not be one true way, but you do kind of suggest there's a default you should go to.
And there are arguments for that. Okay. Casey has a lot of questions to ask already,
all of this. Again, I recommend watching this. Now, Casey says here is like, I watched a multi
part series at six parts six, and it's like nine hours he watched, not once in that one second
of it of that nine hours was in to go to get towards performance. And again, Mr. Martin says
it's fair criticism, absolutely fine, no problems. But again, I'm just going to show you here,
it's like, yeah, so thank you for the nudge kind of thing. Like, oh, next time I'll do,
I'll put a nudge in towards performance. It's like, been doing this for decades.
Hmm. Okay, so clearly you don't see, like, but like,
he's kind of butchering up trying to be polite or like, as you would, like you're trying to be a
conversation light always be polite someone as well and try and be nice and kind to a certain
extent, maybe always nice, but kind at least kind. But yeah, it's always kind of those kind of things
and after some reflection, blah, blah, blah. I'm just trying to go through over this again.
This is like, it's fine, not just all the conversation again, it's a lovely conversation
between two people trying to be just being honest between each other, not being horrible.
Casey was also showing off this video, which if I believe it's correct, he was just kind of
they were just joking about how slow is right GitHub, literally intent of just slowing down
along with the paragraph God. And they actually found after a while, why this was the case.
The thing they found out was that it was the code was looking back to the beginning of the
paragraph, looking for a colon, if it found a colon, and it was near the beginning,
it was going to then expand this to be a emoji. That was what the bug that think the slowness was.
So if you just, as Bob made his joke, like, oh, if I just replace everything, the spaces with
the colons is instant, there's no slowdown because it's found the colon, found it's not an emoji
and doesn't do the search anymore. And that's how slow, like, even though they were talking
about the complaining like slow codes, like, look how dumb this algorithm was in the web
browser. And it's just trying to do this. Now, one little thing I found a bit weird,
he says, I created this using going vi and I use this like replacement thing, because really,
I'm an old C hacker at heart. I'm like, what? What does that even mean? This just seems like a,
I'm an old C hacker at heart. I'm like, this has this is one, this is just, you're like vi or
vim or whatever you want to stuff. And then you've just done a regex for text replacement. And
this has nothing to do with C. I know what he's trying to say. Oh, it's just really low level
I'm doing all this. I'm like, what? Sorry, we just need one of those things like the what?
Right, kind of bit interesting here. So then there's the again, recommend if you want to
read the links in the bar for all this. So you don't I'm not trying to read the
descriptions here. I'm just trying to go over it. So now they figured out the things,
the slowness of GitHub, they've gone gone back pivoting up back to this talking about the stuff
about clean code again, capital C, capital trademarked, and explaining all that. And
some of the weird things like for instance, the descriptive names things, like,
I think everybody agrees with the descriptive names. This is not clean code exclusive to clean
code tests. This is one where he's more of a test driven development, while cases more of a,
it's more of a how they do frame it later on. In fact, I think Mr. Martin rephrases this quite
well, that he prefers like why you should write a test if you don't see a reason not to. And cases
more in the camp, I write a test when I need a reason to kind of thing. And they're just
they're not bad. One's more test driven. One's more of a, like a more of a base of regression
kind of thing or like other testing is more of a, I'll write tests when I need to because
I do have tests in general, it's just not a like unit tests or general tests of everything
code coverage and all that lot. It's a different thing. I'm not going to criticize test driven
development because it's not necessarily bad in certain domains, but in certain other domains,
it's kind of like not it seems like you're writing more tests than the actual code,
which is not necessarily productive. But whatever, or useful and as many things in here,
yes, it says like, look, cases, I do test as well. But then again, here's the difference he
writes. So Mr. Martin says, I appreciate tests, unless there's a good reason to this and Mr.
Martin and Casey write tests when there is no good reason to when there's a good reason to.
So it's kind of a different distinction here. Now he actually starts quoting again from his
book talking about this and he and he kind of distinguishes between the operand primal and
operation primal he's calling here. So it's kind of the difference between I'm going to call operands
operands variance in this case, because it's a variance and operation. So they're not using
the same hoe gets a little confusing for me. So now they're kind of talking about the different
benefits of using one of these two things. And great stuff here. But then there's one other
term that he brings up in here, which is dependencies. And he's using this in a very,
not the way that most people would use the term dependencies. So a good example of this would
be is calling dependency inversion. So I'm just going to read right, I'm going to say what he's
written because it's, I'm not going to paraphrase it very well if I don't, it says here, that would
be the bottom line if there was one other thing, okay, about dependencies, the cases of switch
statements create an outbound network of dependencies towards lower level modules and
modules in this case, he's talking about like timing and such like that, that kind of module
in this context. Yeah, each case may call to out to these other modules making the fan out of the
switch statement very high. So he's trying to argue against switch statements and trying to say, look,
if you go for the more polymorphic approach, like the inheritance base approach, we have like a v
table with sub typing, which is what I would class is inheritance to begin with any of the emergent
concept of those two things joined together. And he's saying this is going to be making it the fan
out of the switch and very high that this is going to be much bigger. Because it was caramel says
any change to one of these lower level modules can force the switch statement cases, which
statement the video, he's usually prefers the inheritance style not always, you'll get into
that can force switch statement and all higher level modules to depend on on that switch statement
to recompile and deploy it. That can be a very large cost. On the other hand, if one uses dynamic
polymorphism, object oriented, instead of a switch statement, then those compile time
dependencies are inverted. The lower level modules become sub types that depends on the
high level base type. And the source code depends is then point in the opposite direction of the
control flow. This is dependency inversion. It prevents changes at the low level modules from
forcing a wave of recompilation redeployment from sweeping through the system towards high level
modules. So this is just a really weird confusing terminology is just made up in a weird way. I'm
saying who has made it like no, he kind of actually has. I tried searching for this and it's like,
it's not consistent what people mean by that term. And also, when people talk about dependencies,
they usually mean like third party code, usually, or sometimes they talk about dependencies like,
Hey, what does it very dependent on the things like all the bits in the thing like he's talking
about modules, but that these concept of a module is much more like a class than a library. So it's
kind of a very more old fashioned approach before like libraries and packages and modules were more
like standardized in other languages, obviously, but whatever. This is why I'm going to confuse
because the argument he's trying to make. And this is the thing I would personally try to understand
as well is that between the the variance and the operations, the switch statement is closed to the
number of variants. But it's open to the number of operations. Like for instance, you can always
add more operations really easily. You just add a new function with another switch statement inside
of it. And you've now added a new operation to all of these different variants. Yeah.
Whilst the inheritance style is much more open to is more open to various operations this time. So
it's a closed set of operations, but open to numerous amount of different variants. This is
the whole point you have a base class and variants like subtyping from it, the whole point you have
subtypes or whatever, and it's more open that way. So it's a lot more useful to be doing.
If that makes any sense. Yeah, hopefully that's clear. So that's kind of the argument. Now my
point personal view is that which is getting talking in the thing here with the commentary
search is that the most the time you actually have a close set of variants, and usually you
want to add more operations in practice. So because if you've got a close set of variants,
why pretending as if it's completely open, which is what inheritance is for, it allows
everybody to add more variants, even if you don't have control of that capability, you just
extend to it and it's abstracted away. But most people within their own code base, like it's not
going to be used by third party people ever, usually, pretty much isn't. So you in that case,
it's very close set of opera, it's close at variance you have. And usually when you're
modifying code, you actually want to add more operations. It's kind of like a
different thing. And they're solving different problems. You have to understand this. It's just
that the weird oddity here is their argument is actually, you know, the, the, the inherent style
approach, which has all of the operations for each variant bundled with that variant,
it's easier to manage. And the going on about like managing all these different
dependencies and talking about how many different places you have to deal with.
In case you just correctly point out like, Hey, it's just a different win in different ways,
like this independence in version thing, is you're just trying to get complexity. And again,
Mr. Martin says, yeah, like for every program composed of O operations and T types has complexity
of O times T. If we use O, we can cruise T with minimal disruption to increasing O and vice versa.
Well, it's like the switch same as you have increased operations within disruption, but
disrupts source code. Now, I don't think this is true. I don't think the disruption is actually
even equivalent because it's weird. I know we shouldn't be talking about much about this is
not really clean code anymore, but it kind of is related to it. It's just the, but practically,
how would you know which one is more true the case? In my opinion, personal experience, we've
always had a close set of variants. Like if you want to have a new one, fine. But that variant
doesn't really like, okay, we got updated every single place. Now I use Odin. So my switch statements
will yell at me if I'm missing a case by default. It says, Oh, you've not handled this particular
operation for this particular variant, like in this particular case. And I just need to handle it.
Okay, great. That's just better. I know C and C++ and summer languages don't do this by default,
but Odin does. So clearly, that's just a better language can solve those problems. It's not really
a or better tooling in general. It's not really a inherent thing. It's just a tooling problem then.
But then this is where it gets a bit weird. He starts breaking things down to source code
management about runtime source code dependency inversion, and just make some terms up which
are not colloquially understood to be meant in that context. But again, it's the right a lot of text.
Try and make people understand how he thinks. And then Casey just write small amounts.
It's the it is a very big politician thing pad it out. Very good rhetoric. I mean,
he's great at this. This is where I'm praising him, by the way. So again, read it for yourself,
make your own opinion. If you disagree with me tip can tell me in the comments below.
Tell me where I'm wrong. Please tell me where I'm mischaracterizing me. If I'm being too harsh,
if I'm not being harsh enough, if I might work, look, I'm not even it's fine. But he then it is fine,
like just just read it. He's talking about these different things here, like he's
procedural, so it's itself statements, which statements, whatever. And he's calling this a
run time to high run time dependency, when actually, no, we're gonna make this compile time
dispensary when it's on the type site. No, you just switched them around. They're both the same.
So yeah.
So one thing he brings up here, which I thought was interesting. And it through this bit, as well
as the second part, these starts up, I'll explain why he does that in a minute. He brings up, I
would call the canonical case for inheritance. So the canonical case of inheritance is the
data stream. So sorry, if I've been a bit rambling all day, I'm just trying to understand it because
it is weirdly flowing as well. Like the actual thing isn't like, it's a weird discussion. But so
I apologize for that and also apologize for my rambling as well. So hopefully that's okay. But
again, should be all clarified here. Here he does the canonical case for inheritance, which is
literally a stream, a data stream, a file or something like that, and explains that Oh, these
have standard operations, a close set of operations like open, close, read, write, and seek. Again,
these are the five standard functions of the Unix IO driver. And again, these are very
standard functions on all operating systems. So they actually map really well to the
inheritance style of doing things, the very dynamic polymorphism is he's referring it to here,
which is, yeah, it's dynamic dispatch. Subtype polymorphism with v tables. Yeah,
that's what it is. But he's calling it dynamic polymorphism, which is not common term, but he's
whatever is using his own terminology as he needs. But it's saying like, okay, we've got a
closed set of operations, but we have so many different things like files could be anything,
they could be a file, it could be a directory, they could be a piece of hardware on your device,
they could be just a general socket, there could be anything. It's like, it's open to be whatever
it could be. This is literally the canonical case. Why is the canonical case? Because operating
systems make these files an object. They are an object. That's what they have. Like they're an
abstracted away opaque thing with a open like close interface as to what they are.
So he's trying to argue like this is what you meant to do. Now, there's a lovely lovely thing
here is saying like, well, this clearly has to be a thing. And that's why he's trying to get down
this route. He's trying to take the canonical case to show to Casey that hey, you need inheritance
sometimes. And this is the great way. He's completely forgot the conversation is talking
about clean code, which will bite him in the book later to use an American phrase later.
But then there's one this weird thing he does here, where all of a sudden he talks about this
hypothetical compiler, which would be able to you could write in the in the oopy stage,
like an inheritance style, and then completely the compiler would magically make this be a
switch statement if necessary, which is kind of interesting because it's like,
what what benefits would you get from that? Because it seems to be now a textual benefit.
It's like, you're talking about, oh, it's all clumped together. A new variant or you know,
like, but you've some weird things. He just says it's just a really weird hypothetical
scenario just kind of goes into. And they go on for this for a little while. And Casey's like,
I don't understand what you're talking about. Like this doesn't make no difference,
even with this hypothetical case. So Casey goes on a bit more further here, just mentoring
different things. And talk, I try to get what the benefit of dependency inversion is anyway,
and to begin with. And the go on about this, like, look, you've got a clothes interface with opaque
stuff, and different ways of dealing with it. And then we talk about this payroll thing that
they do all these different things. I recommend reading it. But it is going to be this.
Like this is an oopy thing, obviously, you've just defined it to be because it is is defined
to be oopy, sorry. Yeah, okay. Yeah, yeah, yeah, yeah. But again, Casey also kind of says it
could just be sound line functions. There's no reason, whatever, whatever, that's not a problem.
Where am I looking for now? I'm sorry, I'm just trying to skip through this because it just goes
on for quite a while. Okay, so Casey says that hypothetically, you could just not do this and
have it just a union. Because in the example that Casey does when he does the union, the shapes
example in the video is, is this actually a union? It's what I would call a fat struct union or an
open open union where it has a variant and then just open fields. So it's kind of like a table
like thing, a fat struct is a term that's Ryan Flurry kind of popularized. And it's kind of
just like, here's a table of data, all the fields available. But hey, how you can just switch on
it like all this and just do whatever you need to do and just access the data when necessary.
In case you're saying, look, hypothetically, you could do this, you could just have a file type
with all the data that responds to this in this union and deal with it. Because in practice,
there's actually only a certain set of files you could have, you could even have the general case
where it's, it, it will be like a V table. Sometimes it won't use a V tail, but you can always
optimize off that. And there's many different things he's discussing here and such. And he's
talking about the union case. Now, Martin, Mr. Martin goes here and says, look, it seems like
come on, come on, wild up at the agreement on just about everything other than per individual
preference. And it's like, no, he's trying to say, look, but we don't disagree. It's like,
actually, why are you having this conversation? If you don't disagree, you clearly do actually.
And you'll show this later on in part two of this written document. And he says,
thank you for the union collaboration. Now I understand what you're talking about unions,
which is like, okay. And he says, I'll quibble you a bit on the difference between operand
and operation, but I don't think the quibble is particularly important. In the end, it's just
all functions regardless of how you spell it. As for human issue, performance is a human issue.
The computer doesn't know how fast or slow an algorithm runs, but I think that that horse is
dead now. And it's like, no, it isn't. This is kind of the point. And he goes back to his
microseconds, different module things again. And then he then goes, look, we put a break in here
to write extra bit more to go rewrite history and says, look, I'm going to continue us now in the
second document, which is the number two. Because he's trying to like make break here,
and then reframe the entire question in the second document, it's a pivot and a reframe
at the same time, clever rhetoric trick. If you want to do that in an argument, you do that all
the time, you reframe the question. So it's now they're not even talking about the original thing
again. And he's tried to do this. So that's what he's done here. Right. So right at the beginning.
And then Casey's reframed it and put it put it into the beginning. So he's first. So Casey
knew what he was doing. So just don't let's not do that, shall we? Yeah. So Casey wasn't stupid.
He's talking about all this goes back to the payroll example with all this kind of thing.
And Casey's trying to say is like, look, this is not an open problem. You haven't got an open set
of variants. It seems like it's an extremely well defined problem. So why does this need to be like
operand, operand, primal design was in like variant open, rather than variant closed. And then
operation open. So this seems to be both closed. Like it's very weird. Like what, what are you
trying to have in like save developer cycles with like, where's this kind of thing coming from?
And then this has been moved to because he reframed it. It's fine. No problems. He's talking
about the programmer cycles thing. This is the thing he gave this random file he added in here,
which is the, oh, great. Let's do a code golf example, shall we?
Cute surprise. It's like the point is the program cycles, waste management,
programming cycles, it's like, yeah, you just gave me a code golf example.
The worst case of readability possible, like, but it's a code golf. That's the whole point.
People write those things to be compact and human. Like that's what you're trying to say.
Like we're trying to make it easier on like, can you prove my belief not mathematically,
just as I'm sure that you cannot mathematically prove that your favorite style saves more or
less programmer cycles than mine. It's like, so he's already admitting that actually you
can't prove my style is worse than yours style. And it's like, because programmer cycles, like
this is a qualitative thing. He knows he can't measure it. She's actually, I don't think that's
true to be honest with you. It's just that no one's really bothered to do the science because
programming isn't really young discipline or 70 years at best really as a discipline. So it has
no evolutionary like pressure on there yet to say which which things are good or bad. So people
just say random things. So it is literally just like, great, there's not really much science in
computer science. Rather, again, I'm glad the rest of the world calls it informatics for a reason.
I don't know why we don't we call it computer science, even though it's not an empirical
science and it's close to mathematics, but even then it's not really in practice is close to
engineering. It's just confusing term. Okay, confusing term. The dynamic was a dynamic
building and other type of just from typos, whatever I make more than this might be in day
to day life. And he's talking about this. So it says, do we agree so far about this? And it's like
cases kind of like, well, we don't just worry about certain things in the general like in
the specific, I'm still asking the same question about this data stream thing you're talking about.
Then Mr. Martin brings up again, the like, hey, here's something like the read write thing for a
C. These helper functions don't you know to do all the stuff? It's like, but if you had to do it in
your case, we'd have to do a switch statement like this wouldn't we don't you know? Oh, it's like,
look at all the different variations you could hypothetically do this just ugly. Don't you know
it's ugly? By the way, if you this is, this is gonna tangent anyway, I've been writing the
Odin core library and you actually have to do this anyway. Like if you actually have to do like
you do the read at the OS read functions, because the console on Windows at least does not act
like a normal file. In fact, the console on Windows is a UTF 16 document. So that means you have to
write UTF 16 files. If you actually write a UTFT thing to it, you then you have to do a conversion
to do it onto those. It's actually like already or you have to do this edge case. And not just that
the console has other things in it, which are not handled the same as an old file again. So it's a
very kind of have to do this. This is how real world code is not even purely like, oh, the operating
system has dealt this properly. It's like, no, I still have to check if it's a console specifically
and then deal with it. So it's like, I know like, this is not working. Like, yeah, it actually looks
closer to this in real life, even with the, the abstraction on top of what a file is, but I digress.
Yeah. But yeah, it's just interesting. And then again, many different breaks can different edits
here different sections is breaking it up. The VTab we use by Unix, again, most operating systems
do this as well. Things change around significantly. The idos can be loaded at any time, the iodevice,
yeah, that's true. That's took in this details we're talking about. He's talking about code reuse,
great example says the cases. I apologize for trying to be very specific, but I really want to be
actually get to the exact proposal. And it wasn't clear from what could you actually tell me what
the OS interface looks like and how it's implemented. You said, I guess that depends on a lot on
the language and the application. But my understanding is that we're talking about the OS side. So, and
again, it's the, how does the OS implement this, like the, the stream, the file, compared to how
we're doing it in a language is very different. And not just that, again, I thought we were talking
about clean code. But why has it gone down this digression? Just you wait. Let's go get that. Don't
worry. Okay, we're talking about get all crap. Okay, because it just changed. That's, I can probably
guess which day this was written on as well. Like you're saying it seems like it looks like this
somewhere. Is it actually a base class? Is it whatever? Now, Mr. Martin says, okay, here's kind
of the general interface that he's writing C++. Again, he's not answering the question he's asked.
He's done another thing. Whatever, kind of missed the point again. And then he's saying, look,
look, if we look at the, he's trying to say this is less like the code is easy to manage whatever.
Like, yeah, but you've just chosen the canonical example. And he says, look, if I do the dynamic
polymorphism case, so inheritance, I create, I create this file of three files and have to leave
them with a switch case. I've now all of this and look at all these different things I have to define.
I'm like, and cases, well, hold on, since I'm the switch proponent, at least I get to write it,
please. Look again, look what he's just done. He says, well, I've just shown you how to do it.
And look, it's just more complicated. I've had to write files. Oh, no, I'm like cases like,
hold on, hold on. Yeah, and it's kind of doing like this. So it goes on and on,
we just discuss things, but it's like cases like I want to know what the operating system again.
And it's different. Okay. And then cases like we're not even talking about machine cycles again,
I'm just focusing on the program cycles again, what like he's doing again. So I'm like paraphrasing
this poorly ish, but it's kind of just like, I'm trying to show the techniques that he's doing here
that he knows he's doing it. He isn't an idiot. I'm trying to be very careful like this. Mr.
Martin knows exactly what he's doing. Like he's now just made another document on here,
which only he talks about. And it's just he's trying to suggest like, oh, this is the clean code
stuff. And then he's saying this is what clean code is. And I've just got the summation seems
to correlate with what I most people think it is. Because I miss people people keep this understanding
me kind of view. And it's like, wait a minute. So choose carefully names, not unique. Keep function
small. Why keep classes small. Why manage your dependencies, vague as anything. Literally,
be careful with side effects. Okay. Yeah, express yourself in code where possible. How else you
meant to express yourself in code away? It's your programming. Use polymorphers when the type
changes fast in the operations. This is new stuff he's added now. You switched when operating
change fast in the types. Why? Why? And at what cost? And what Harvard evidence have you got?
This is better. And like, you compare it to this and like, you sure? Okay, when possible,
create designs where things that can change fast that change fast are types. Why keep asking this
question? Here's in his even in his summarizations of here, he's actually saying, we'll prefer
polymorphism. So now he's in like, well, I don't see how you got to that conclusion where like,
I'm against switch tamers or something. I'll clear and prefer like default before like all this
and like, you're literally saying it in here in this summarized document. If I'm misinterpreting
it, please tell me again, in the comments or something. I'm just really confused. Like, what?
Right. So Casey comes back again, and he's talking about the internals of this. It's like, okay,
find the device, then you read it and you do this. This is how ring versions, if you understand how
they work internally. Okay, great. There's class, here's the operations. And it's that looks,
you can always do it this way around. And look, I've got a different way of doing it. So just a
union based approach now, with all the data inside of it doing all what we need, whatever.
And that thing that's just is actually trying to show the actual things internally, isn't
it? But yeah, it's kind of like, look, now I don't like vtables, because obviously pretty
much everywhere, because I find them hard to control. So I prefer this. So he says, look,
I have a, not a vtable, but just inline things itself, it's not a table, just inline functions.
So instead of a class, you've now just got inline methods. And this is just general handling
thing, which is interesting. By the way, that should be more better for performance in general,
because a vtable is usually a pointer to a structure of a function tape, like function pointers,
whilst if you're embedding the function pointers, you've got rid of that indirection. So you've
actually got it will be faster in general as well, because you've got rid of the indirection.
It always has a better chance to optimize and even it has slightly better chance of inlining
and slightly. But yeah, that's how compilers work. Sorry, rambling again, again. But I'm
getting off the digression. But cases kind of saying like, look, we could just handle it for
each of them that we could actually have one callback, just one, and we could directly embed
it in the structure. So it's not even in directed anymore. And then we switch on this. Now this is
interesting. You could do it for every single operation. And then look the codes in one place
for this thing. We've now got the best of both worlds in many ways. And why wouldn't you prefer
this way? I think now interestingly, I'm just going to like slightly digression here going into
Odin. And this is what we actually do for the allocator. And I've been doing this for like a
decade, maybe even before Odin. There is the thing sorry, apologize for the digression. This is
clearly unscripted if you didn't guess. Here's the allocator. So we know that we have a built in
concept from an allocator and allocator is just a little data structure with a pointer to a procedure
and appointed to the data. So 16 bytes, you can easily copy this around. So it's usually not
even appointed to the allocator, it's just the allocator itself in memory. And you just get the
values. So that's what you're doing. So there's not an indirection again, because it has to be a
pointer. And notice it's just in line with the function. And not just there's only one function
you think, but there's loads of different allocation operations like yes, it's one function,
you take all the arguments in, and you change the allocation mode is an allocation alloc free,
free or resize query features query and for an alloc non zero. Because sometimes you want to be
allocated without a zero, but by default you want zeroed because it's quite useful. And also it's
pretty much free if you're using like virtual memory, like allocating zero memory is pretty much
free. Because it has to be for security benefits. There's no option to not get it if you ask for
virtual memory. So I'm just trying to show here that I already take advantage of this kind of
approach. And then within every single allocator, I have a switch statement which then pairs each
operation together. So I'm just trying to get off my digression a bit here. So this is what case
is kind of trying to say and you could do this. So you're not having the full on inheritance style,
you just have a switch you could do the blend of the two. And there are benefits to this,
obviously. And you'd have all of this lovely. So because in either case, but this is larger
rather than because it's solely look look up map look up now and to a specific device and it can
be used in either design. Anyway, over the course of the development of the OS, I think the implementation
saves programmers and cycles potentially a lot of them compared to the one I understand believed
you favored by the clean code method. Again, which is interesting because the casey one is
closer to being like, sub typing to a sentence, but there isn't sub typing, it's just like,
here's the abstract thing with a function pointer, deal with it. Which is kind of close to inheritance,
but it's not just one. And it sounds like a minor difference people say, oh, it's equivalent. It's
like, but it isn't equivalent. In fact, it will be faster. You can easily measure it. It'll be easier
to maintain because everything's in there. And not just that, if you add a new operation into
there, every single one will just yell at you anyway, because you've not implemented it.
So if you've got a language that tells you that switch name is not necessarily C or C++,
maybe modern C++, I know, I think. And sometimes C with the, when you have warnings all and
everything will tell you switch name is missing certain cases. But yeah.
And cases look, I don't know if it's a bit of an extract and file, because I'm sick,
but it was the first one you brought up. And it happened to be the contrast,
the two designs in my opinion. So it works, works for me as Casey is saying here.
Here's why I think an enum based design deserves the programmer cycles. In most systems, you don't
know all the functions that are going to be used ahead of time when operating costs are hard boundary,
like a driver, using operation codes instead of virtual function calls allows you to add more
functions dynamically without recompiling all our drivers. In any modern operating system,
multi-threading is a concern. But this is especially true for an operating system,
having the protocol be structured based with an operation code allows us to trivially buffer
operations in things like IO rings and other intermediaries, intermediaries, without writing
any new code. The entire system remains identical. Yeah, I'm just trying to do this. And you just
said, this is by the way, it seems like almost happens in almost all systems, OOP systems,
I see, I'm trying to get around pronunciation, say, because eventually they need to serialize
or something similar. And so they have to write my version as well as the version as their version,
but they don't seem to realize how much time they're wasting. Like, yeah, this is
clarifying this point. People think this seems like the clean code will actually save time,
but it's actually no, you're now forcing another person to write the same thing again.
And you are actually wasting time, you think you're saving things. But again,
if you want to know if you're saving time, you're making a statement like this will save
programmer cycles, like a claim, show the evidence. And don't just say, well,
my your seniors may agree with me, because they were convinced by my argument. It's like, yeah,
but where's the evidence, regardless of this authority, this later argument by authority.
It is the after a while, many people will come out the phase and like, oh, I don't do this
anyway. But some people don't. And it's like, okay, I never really went through the OOP phase
myself. Going a bit of a digression here. Sorry, this is completely random today. I know.
Very, very unstructured. But I went through the modern C++ like 11 phase. So that's what
12 years ago now, probably a bit before actually, because it was C plus plus zero x for a long time.
And I remember learning all that stuff. And that was the thing I got caught. I wasn't really
necessarily the OOP phase. It was that phase. I was learning all that stuff. And it was a while
took me a few years and after was like, I'm doing all this extra code, writing loads, and I'm not
getting any more productive. In fact, it's how hard to maintain. I'm writing literally 10 times
more code than I needed. And they kept telling people kept people kept telling me because I was
kind of trusting these people who were more thought they were more experienced with me or
they thought they knew more because they've been doing it for longer. And they were talking from
positions of authority to a certain extent that they were going, Oh, of course.
Like, of course, this is going better because I'm telling you it's going to be better. I'm like,
and then I was kind of believing them. And I was like, it doesn't seem like I'm trusting them.
But it didn't it didn't seem to the case when I just started programming back to like a normal
basic C style with switch statements in many cases, and just like normal standalone functions,
no, not even using methods. I got more productive. My code got smaller, got easier to read,
just by not doing any of that. And it was kind of like not using not doing any of the stupid
templates, not doing stupid any of the ownership semantics. I'm not saying ownership semantics
stupid. I'm just saying the being everywhere was like, look, I just kind of went to more
pod data was a plain old data data kind of style old fashioned C style, my code just got
easier to read more maintainable and just everything like from a personal perspective,
again, I cannot measure this. And the only way I can convince people say, here's my code, here's
this normal code, which one define easier to read. And that's the only way that's not a measuring
that's just still like a personal preference thing in the day. This is the problem in these
discussions. And it is just getting down to that. It's like one side is there is an empirical
thing to a certain extent, which I'm going to comment right at the end. I will get to this,
don't worry. But he talks about this saying here at any point things, if we would like to
buy third parties to allow communication with channels on the devices, blah, blah, blah,
okay, we're talking about the IO stuff, fine. We're getting nearly getting the answers. So
Mr. Martin says, okay, I think I see where we're going. So let me say, sure, looks good to me,
the bullet points you added are after the fact are all quite valid. And the design you picks
works well in this case. In the first point, you assume that operations will increase beyond
the two original proposed, as we both agreed, as I wrote in the clean code, which, by the way,
is not the same as your clean code. Right, when operation periphery more rapidly type
switch statements are better. So there's that line alone is or another rhetoric trick,
lovely one, in fact, in my opinion. In the first point, you assume that operations will increase
beyond the two originally proposed. Okay, as we both agreed, I don't think Casey agreed to anything.
And secondly, Casey's not calling what he claims clean code, he's trying to understand
what your clean code is Casey never says his code is clean code, because yours is Mr. Martin's
clean code with a capital C trademark to kind of think. Yeah. So another little kind of trick he
does already any can't help himself really. So when operations profite more rapidly type switch
statements are better. In point two and three, you raise the specter of multi threatening,
you are of course correct that queuing operations is a lot easier. If you request packets of the
same type you design no argument there. And the last point proposed a kind of hook for unknown
and unspecified possibilities in the future. Yeah, so what he says is like, okay, you have the general
cases and then have a hook for the unknown cases like the open cases. Okay, if you think those
unknown cases and special are likely, then you should have considered them earlier. But then
that raises a number of other concerns that we should not likely address in this document. It's
like, no, no, no. So I think I'll let pass. No, why? Because if you didn't, he has to let that pass
because it then kind of defeats his point. Because the inheritance approach, which is
preferred by clean code, is saying that the open case is the open set of variants, the open set of
operands is the general case. It isn't. Because if you've got a close set, which you know, like
pretty much always know that 99% of the time 99.99% of the time is going to be
going to be closed, like pretty much going to be that small set. So you're optimizing for them.
And then you've got this, the unknown hook cases allow the user to add their own callbacks in there.
Fine. That's fine. But it says, it says, unlike to consider the head of time, it's like, yeah,
but you're assuming that those unknown cases are just as common as the known cases. And
that is actually designing the API. Now the thing is, if you're optimizing for the general case,
and then you allow a hook in, that hook is not going to be is not going to be any slower than
if you design it to be always a general case than the specific cases. That's the point he's
trying to say here. Like, that's why he's letting it pass, because it is literally just as fast
to do it that way, then to design it all the way around as if it was always unknown,
as if it was always dynamic polymorphism. Sorry, just say inheritance, be easier,
because technically what it is in this case. So now where are we? You propose a solution that
uses dynamic polymorphism, select two types, and then a switch same to select operations.
I have no problem with this. It works well and satisfies my concerns about dependency inversion.
I'm like, but it isn't the same kind of dynamic polymorphism that you've ever
recommended to anybody. So this isn't technically key and code. In fact, anybody who
would a clean code advocate would read Casey's code of, let me go back to it, this and go,
that's not clean. So this leads to the problem of clean code is whatever Mr. Martin says it is
at that moment. It's not like anyone could actually agree on what clean code is because
it changes from time to time. It's not a well-structured thing. And he's like, that's fine.
It's like, then why don't you just call it Mr. Martin style? Because it clearly doesn't work.
It's not clean. And it clearly doesn't work the way he wants it to in every single case.
But then you shouldn't do it like a dogmatic. And it's like, it's a weird trick. He says,
look, don't be dogmatic. Don't follow these the rules. But then it's like, well, I won't,
I don't agree with it anyway. Well, you clearly have some of these rules, don't you? It's like,
it's that clever trick again. It's the pork barrel naming again. It's the rhetoric over
rhetoric over again. I'm like, look, even if Mr. Martin style increased programmer cycles,
the decrease of wasted programmer cycles, like, whatever. Great. But how do you prove this is
the case? And we're getting to the end now, and we're just going to do here. So I'm going to
read the best of it. So, so Mr. Martin's your proposed solution time with thing blah, blah,
blah, blah. What do you got to this? I will say, however, that that is an ironic that after your
video and after all the stress that you have been put on saving machine cycles, you eventually
chose a design that sacrifices machine cycles to save programmer cycles. After all, on the OS side,
this is where he thinks he has won the argument. Ready? This is what he's tried. He's tried a trick.
He's tried to do it because he took the canonical case of a stream. After all, on the OS side,
you've you've got to package up all the quest packets and it's the dynamically dispatched
handler and then run the operation ID through a switch. And I think we wind up in the same place
when operations proflate more rapidly than tights, we both use switches, you don't,
you do not do this. I've read your code, your public code, you don't do this.
But he's saying he does just pretend you believe it. Okay. When tight for a plate more rapidly
than operations, we both use dynamic dispatch, we are both willing to sacrifice machine cycles to
save programmer cycles. No. Also the way again, how Casey structured it will be better because
it's not technically how many levels in direction do you have before like technically here has
one level of indirection, which is a function pointer compared to normal inheritance, which
is three levels of indirection. Why? You've got a pointer to the object, pointer to the vtable,
then a pointer to the function. Guess which one's going to be faster? Just have a hesitant guess.
Okay. And not just that, you've then have to go all through this indirection compared to having one,
which is probably going to be in the literally cash already in the cash ready to be called.
No problem. It's going to be easily predictable as well for the CPU. It's a very different thing,
very different operation that is to a generalized vtable. So no, they are not equivalent,
even in performance. One will be quicker than the other. I'm not doing this video. I could do
another video if you'd like, but like we could prove it, one's going to be quicker.
Single indirection compared to triple indirection. Okay. So when we are two individuals on the same
eye and the only difference being that I wear this shirt and I don't know how to pronounce that word
with clean code and you have one with clean code, I'm like,
thank you for simulating the debate. I appreciate your candor and the civility that you exercise to
and if, if not everywhere, I've come to experience your respect, your knowledge and blah, blah, blah,
blah, whatever. So the first thing is this is a really dodgy thing. Casey and even cases,
well, I disagree with most of that. But if we're ending here, I'll just finish my final responses
for Gail poster poster posterity. And that is the thing. See how he tried to end it. And I'm
going to read through Casey. I'm not going to comment on it now. I'm just going to read it for
the end of this video because we've already been going on too long. Sorry. So I apologize
for my rambling in between. I hope it's kind of an enjoyable if not, and I apologize again. So
I'm just going to read through this. I'm just going to read Casey stuff. This is all Casey,
not me. So regarding as I wrote in clean code, which by the way is not the same as your clean
code? Well, the point is of discussion was your you to elaborate on what is not the same. But
you're designed for the IO system looks exactly like my clean code example of virtual function
for every operation, one class per element in the system with no predication. So what are these
differences that you're referring to? Now would be the now would be the time to explain what they
are since that was the point of the concrete example. If these are a bad example for accelerators,
straighten the differences, that's fine. But it was the first one you gave to assumed that it would
be the one you want to use. Regarding when operations proliferate more rapidly than types,
switch teams are better. That was not the case here. In no way are operations proliferating
more rapidly than types in the system. Vendors will add drivers to the OS constantly, perhaps
monthly or even weekly, whereas the number of operations in a particular system tends to go
much more slowly, once every few months at a maximum, but more likely once a year for something like
the aniosis subsystem. It isn't the opposite of what you said. This is an important distinction,
because what I'm demonstrating here is the opposite of your rule. This is showing that even in the
case where types proliferate far more rapidly than operations, as in the case of drivers in an OS,
the principle doesn't work. Enums are better in both cases, specifically because you have
potentially thousands of types in the system, all different drivers, all the vendors have ever shipped.
Adding a single operation, however rarely, can cost massive programmer cycles to the
unnecessary work multiplication across types, the V-tapels course. Another way to say this would
be enums are more important in a system where type proliferate rapidly, not less. Regarding,
you eventually chose a design that sacrificed machine cycles to save program cycles.
I did no such thing. The design achieves both, like why I like it. It's drastically faster to
use something like a packet-based system than something that is originally proposed design,
because you do not take a ring transition on every operation. New OS IO APIs are not all designed
this way. This user writes data without taking in talking to the OS, and a kernel thread picks up
those data writes. Nobody ever makes a function call, except occasionally to ensure the kernel
thread hasn't gone to sleep. This is what I mean by the bullet point, if at some point we decide
users should be able to do multi-threading book IO ops. I am talking about the necessity that
actually occurred in both Linux and Windows of removing their frequency of ring transitions
for saving CPU cycles. None of this is trading CPU cycles for programmer cycles. It's achieving
both. The Linux kernel design of the IOU ring looks like my design. That did not add to save
programmer cycles. They added it because they wanted the highest possible IO throughput. This is an
almost universal principle of modern OS design. Anything that can be turned into data writes
should be, and function calls should be minimized. It's been true for GPUs, for NICs, and for our
example disk IO. And the last bullet point is regarding, and so I think we wind up in the
same place when dynamic operations proliferate more rapidly than types we both use, switches,
when types proliferate more openly than operations we both use dynamic dispatch. Again,
I don't see how you got there. Obviously types are proliferating more rapidly in this system,
so that is part, is true. If we didn't believe drivers are proliferating rapidly,
why are we loading them dynamically? And I thought that was the entire point of the example,
but perhaps more importantly, we are not using dynamic dispatch here in the way that you've been
suggesting. As I was pointing out earlier, I said that when I proposed the design process,
I would also do the inside drivers themselves. I would not duplicate drivers to remove if
statements and switch statements inside a driver that allowed the drive to handle multiple similar
devices. The only reason that there are function pointers in this system is because the problem
definition required that we load the driver from a different module, and we are not presuming a JIT
or something that can weld, wield, weld things together for us. That introduces a mandatory
cut so we cannot get rid of it because the problem is defined to contain it. But note that this is
not the same between our two approaches. I have a function pointer there because it's required,
and you'll note I minimized the number of all the way down to one. I didn't put it in there
because I think it saves program time. In fact, I'm not really sure I want it there at all. I
haven't actually implemented this particular system in an OS, so it's somewhat off the top of my head,
but it's very impossible that if I actually went to write this, I wouldn't include that function
pointer at all. Instead, I might just have the OS thread reading the queue, sorry, the OS thread
reading the queue, and pre-filtering the packets for quota permissions, then updating a shared
memory access that lets the driver know it can process the packets directly without actually
implementing. I can't say that's for sure what I would do, but it's probably something I would try.
So thanks for overstating the similarity of our approaches, but I think that they're similar,
then I guess that's just where we end up. Thanks for taking the time to create this thread which
pushed the GitHub emoji to check a well beyond its limits. Sorry, I had to read all that, but yeah,
that was all right. So this is kind of the point I was trying to point out is that case was saying
this isn't what you were showing, and the point where I say like Mr. Martin thought he won the
argument, like you need to use this style, is by using the canonical case of requiring it,
which is the canonical case is a data stream, a canonical case of like you've got different
operations fixed interface, but you've got an opaque different what it actually variant type,
whatever it is. And then they talk about actually how does it implement the operating system case,
it actually just shows that actually effective this is how you do it in Linux. We don't know how
Windows works kind of, we can reverse engineer it, but like it's not the source code, it's not
public obviously, because it's a closed source operating system. But that's kind of the the
issue that's going on here. Mr. Martin thought he won by showing like you already just did dynamic
dispatch. In case you went, you just find it to have it. And in fact, I didn't even require multiple
functions acquired one, it's not tripling direct to any single interaction. And I just had a switch
name in there, because this is also how the operating system does it. And it's better for
literally CPU cycles and reduced programmer cycles. It's not one or the other. So hopefully this is
okay. And I'm done now. I was just going to do this. And I was talking about this, we've already
discussed this, what I've seen was I did a tweet on it mildly. And there were some other things
I was talking about here on to talk about Mr. Martin, but I didn't in the end be honest with you.
It was more of a, I'm just showing the rhetoric styles of Mr. Martin. That was it. So I hope you've
enjoyed this. I apologize. This is about 120 minutes long. So thank you for putting up with
all this. I wanted to end off with this little thing here is what I wanted in for. So we already
had this in his code, but someone commented here saying, look, I says, but there's kinds of environments
though, the parsimony is important nowadays, far and few between the vast majority of software
requires less than 1% of modern processing. This is the first section we read. What's more
processes are so cheap and available that is a trivial matter to add more of them to the system.
Someone replied, I should know this person by the way personally, we do not consider it
good engineering practice of the person wrote it, not the quote, good engineering practice to
consume a resource lavishly just because it happens to be cheap in the class of it or Nicholas worth
one of my actual programming idols out there. And I love this quote because it's kind of as
viet slaw of worth slaw. However, it doesn't care. It's either name by or bind value. It doesn't
matter. And then Mr. Martin replies, that depends upon the, which resource you are talking about
computer cycles, computer cycle, programmer cycles, which should you trade against? And again,
I don't see what being the odds, but simpler code is easier to write. Our bubble source is
simpler. The tricky again, it's another trick. It was just last showing the rhetoric trick.
Simple is actually an overloaded term in programming. And it's an overloaded term in English,
because simply you need to mean the opposite of complicated, or it can mean the opposite of
complex. And in the case of complex, the technical term would be simplex. So is it simple as in
not complicated or simple as in simplex? And he has just done this on purpose. And he knows it
very well by saying, well, bullsaw is simplex, but it's very expensive. Multiply and multiply by
repeat about it. So it's simple. Actually, that's how, that's how like AMD processors, not AMD ARM
processors actually work, by the way, they don't technically implement multiplication. x86 does,
by the way, ARM does AMD 64. Sorry, I should say, AMD 64 does an x86 in general. It's actually one
of the only, it's very, very, you find a processor that does this, but they did it. Linear searches
are simple. Like, yeah, they are simplex. They also may be simpler, faster as well, but they might
not be. Like, there's a reason. But this is the trick. So I just want to end on that note. So I hope
you've enjoyed this. Please remember to like that smash button, and to comment in the description
below. And again, if you want to read any of these links before, I will post them in the description
of the doobly-doo below below here. And hopefully you've enjoyed this. This is a very unstructured
ranty talking about Mr. Martin's rhetoric style with regards to clean code, how, and at the end,
effectively, he just stated exactly what most people thought clean code was stating, and Casey
went, so I was right about what clean code was. Okay, thank you. So goodbye, everyone, and stay
tuned for the next video.
