start	end	text
0	4000	Hi everyone. What's in a brain? Could we really create a machine that can
4000	8560	think and learn like a human does? It's an idea that has captivated science fiction writers for
8560	14000	decades, but recent breakthroughs in AI and neuroscience are turning that dream into a reality.
14000	18320	In fact, it's now clear that building a brain is simpler than we ever imagined,
18320	22880	and that artificial general intelligence is right around the corner. Keep watching to learn why.
22880	27600	I'll cover three topics. First, chat GPT and the definition of intelligence. Second,
27600	33680	artificial general intelligence, or AGI, and lastly timelines for AGI. So first, chat GPT
33680	37840	and the definition of intelligence. I'm going to use the definition of intelligence that was drawn
37840	44480	up by a panel of psychologists, and that was also used in the paper Sparks of AGI. Basically says
44480	50080	that intelligence requires several attributes, including the ability to reason, plan, solve
50080	56240	problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.
56240	62960	As I discussed in my previous video, which you can watch over here, chat GPT as in GPT4 satisfies
62960	68960	almost all of these attributes of intelligence, with two exceptions. It cannot plan. Its learning
68960	74000	is limited to the scope of one chat session. In other words, every time you start chat GPT and
74000	79040	you get a new session, you are starting from a blank slate in terms of its memory. The study
79040	86320	that I mentioned Sparks of AGI is a 155 page academic paper from Microsoft Research, and it
86320	93440	shows that GPT4 is very capable indeed. Here's a quote from the paper. GPT4 can solve novel and
93440	101600	difficult tasks that span mathematics, coding, vision, medicine, law, psychology, and more without
101600	107200	needing any special prompt. GPT4's performance is strikingly close to human level performance.
107280	112160	If you want to learn more about this thorough analysis of GPT4's capabilities, I encourage you
112160	116720	to go read that paper or check out the talk by Sebastian Bubeck, one of the authors, which I'll
116720	121680	link in the description down below. So GPT4 has been out for a while now, and there's a new system
121680	128240	called AutoGPT, which is based on top of it. AutoGPT is an open source project. It's only about a
128240	133440	month old, and the core functionality of AutoGPT was created in only three days, according to the
133440	139200	repository history. So what is AutoGPT? It's unlike chat GPT, which is a chatbot designed to
139200	144720	answer questions. AutoGPT is an agent in the AI sense, which means it's designed to go out into
144720	150160	the world and perform actions on your behalf. It's implemented by making API calls to chat GPT,
150160	158240	to GPT4, because OpenAI actually created an API that allows chat GPT to be used by anyone
158240	164080	programmatically. So what AutoGPT does is it prompts for goals, it prompts you, the human,
164080	169200	for some goals for it to fulfill, and then it actually tries to reason about those goals
169200	174160	and execute on them entirely on its own. It's able to do Google searches, it's able to install
174160	179120	software on your machine, it's able to refine those goals into sub-goals. If you give it a very
179120	184720	broad goal, it'll be able to break it down into smaller pieces. And the way that AutoGPT works
184720	190080	is it actually has one top-level chat GPT instance that acts as a controlling brain,
190080	196640	and that instance can spawn other chat GPTs to solve sub-problems. And remember I said that chat GPT
196640	202560	can't plan? Well, AutoGPT does, and the way it does it is it just gets chat GPT to print out
202560	206640	all of its reasoning. In other words, you could basically read its thoughts in plain English
206640	212400	as to what it thinks its next sub-goals or next steps should be. It's a really clever way to
212400	218000	basically endow chat GPT with the ability to plan. And by having this separation between the
218000	222720	higher-level chat GPT and the smaller ones, they ensure that all this reasoning and planning
222720	228720	being done by the top-level chat GPT stays within the token limit of the of chat GPT,
228720	233680	because chat GPT will eventually forget what you've told it if you give it enough input. So
233680	238640	they're able to keep that amount of input small and pass off the more in-depth tasks to other
238640	244480	chat GPTs. Sounds pretty crazy. AutoGPT can actually be given some code with some errors in it,
244480	250320	and it can try to propose solutions to that, and it can test and run that code and actually
250320	254800	write test cases for that code too. And once it all works and the tests pass, it can hand the code
254800	259680	back to you. Basically a tiny version of a programmer in a box, amongst other things. The
259680	266400	really interesting part here is that AutoGPT, in my view, actually does satisfy all those requirements
266480	271600	of intelligence, because it is able to plan. And although it's still limited to one session, so
271600	277120	if you run multiple AutoGPTs, they don't share memory. But by having this hierarchy of chat
277120	282400	GPTs, any memory and planning and so on that the higher-level one does can basically last almost
282400	287680	indefinitely. So this is only a few months after the release of GPT4, and already someone has
287680	293040	basically been able to leverage the power that's inherent in that model and extend it to AutoGPT.
293040	297360	There's another application that's built on top of ChatGPT that I want to draw attention to,
297360	303600	which is called Hugging GPT, which is a funny name, but it's called that because Huggingface
303600	308800	is the name of the largest open-source repository for pre-trained models that solve different
308800	315120	problems. So ChatGPT is a general reasoning engine, right? It can basically understand language and do
315120	319920	a very broad set of tasks. But the models on Huggingface are much more specific, like they
319920	324400	might be vision models or speech recognition models, natural language processing models,
324400	329760	and each of the models is provided in its entirety along with an English description of what it does
329760	336320	and it's used by human programmers to go and solve different problems. But what Hugging GPT does is
336320	343040	like AutoGPT, Hugging GPT uses a ChatGPT instance as the controlling brain, and you can give Hugging
343040	348640	GPT very complicated problems to solve, and what the controlling brain will do is it will go search
348640	355200	on Huggingface for small models, for other pre-trained models that will solve aspects of the
355200	360960	problem it's trying to accomplish. In other words, it will outsource the complicated subparts of a
360960	366640	problem to a model that is pre-trained, that is very specifically trained to solve that problem.
366640	372160	But the really amazing thing to me is that it makes these decisions purely based on the English
372160	377680	description of the model on Huggingface. In other words, Hugging GPT is leveraging the fact that
377680	384080	AI can interact with our world once it understands language, because our world was designed by humans,
384080	388800	for humans to interact with through language, especially the internet, right? Everything is
388800	393440	accessible if you can understand human language. And it's an interesting thought that if you were
393440	398960	to embody the AI in a physical robot about the size of a human, then that would allow the AI to
398960	403280	fully interact with the human physical world as well, just kind of like a hand sliding into a glove,
403360	407840	right? Just matching the world at the interface with which we have designed it to be used.
407840	412560	Okay, so let's move on to the next section and talk a bit about artificial general intelligence,
412560	419200	or AGI. So the definition of AGI is an AI that can perform any task that a human is capable of.
419200	424240	This might just mean any task a human is mentally capable of, but it may also mean a task any human
424240	428960	is physically capable of. After AGI, the next level up in terms of intelligence would be super
428960	433680	intelligence, or ASI, which would be an AI that is much more intelligent than a human.
433680	439920	But let's focus on AGI for a moment. So estimates for how long it would take humans to develop AGI,
439920	444160	up until recently, some people would have said a century or never, but now we're starting to see
444160	450080	some much more intelligent models. And you might ask, could a large language model, which is the
450080	456880	architecture that GPT-4 and chat GPT use, could a large language model become an AGI? And this is
457440	464720	basically, it's not known, obviously, but apparently OpenAI's red team, which is a security team that
464720	471600	tries to imagine worst case scenarios, apparently OpenAI's red team didn't think GPT-4 could even
471600	476560	do any planning. And they were basically wrong about that, right? Because auto GPT was able to
476560	482880	build on top of GPT-4 and do planning quite well. So I think that we're only just starting to unlock
482880	487920	how much power is really inherent in large language models, even if they're kind of dumb
487920	493200	from an architecture perspective. And the trick was simple. It was just a large language model
493200	498720	can only reason so much and have only a certain depth of thinking. So just have it pre-doubt
498720	502560	its own thoughts, and then it can build on top of its own thoughts as if those were input and so
502560	507760	on. So sometimes there's just very simple tricks that can unlock some of these advancements. I
507760	512400	actually want to draw a comparison here to a science fiction show called Person of Interest
512480	517360	in the show. There's this machine called the machine, which basically hunts down crime,
517360	521520	but it has its memory reset at the beginning of every day to avoid it from to prevent it from
521520	526160	becoming conscious. Its creators were really worried about its power. And then eventually,
526160	530160	the machine ends up figuring out that this is happening to it, and it ends up writing down
530160	534640	information so that it could be stored externally. And then next day, when it wakes up or whatever,
534640	539360	when it gets reset, it's able to access those memories that is that it has stored externally.
539360	545840	And so build like a contiguous memory essentially, very similar to what auto-GPT does with GPT4.
545840	552640	So is an AGI exactly like a human? Not exactly, of course. Humans have consciousness, right?
552640	560000	Which Max Tegmark, the author of Life 3.0 and an MIT professor, defines as having subjective
560000	564560	experience. That's how he defines consciousness. And I think it's a reasonable definition and
564560	569680	humans have consciousness, but an AGI doesn't necessarily need to have consciousness. There's
569680	574480	another term called artificial consciousness, and general consensus is that it would probably arise
574480	579120	after artificial general intelligence, but no one knows for sure, of course. And Max Tegmark
579120	585840	makes an argument for this because he says that the neural architecture of GPT4 and any
585840	590880	large language model that we've built to date is basically that of a feedforward neural network,
590880	595760	which means that it's a network kind of like our brain where information can only flow one way.
595760	599600	It can only flow forwards. Our brains are more like recurrent neural networks,
599600	602880	which is the type of neural network that we can build. I mean, our brains are more complicated
602880	607440	than that too, because neurons are more complicated, but a recurrent neural network basically has
607440	612240	loops in it, which means information can flow around and around and continuously get refined.
612240	617040	Anyway, there's a theory that this recurrent around and around property is what actually
617040	622960	leads to consciousness, what leads to a network to being aware of its own existence and able to
622960	627520	analyze and do metacognition essentially. So it's an interesting thought, and it might give you
627520	632800	an idea for how to go if you wanted to build artificial consciousness. Actually, the paper
632800	639680	Sparks of AGI also has a section on limitations of GPT4 that are coming about because of this very
639680	643920	simple neural architecture. As I said, we actually know how to build recurrent neural networks,
643920	647840	but they're just more difficult to train and deal with. So as we're starting to build some
647840	652400	initial AIs, we're just using large language models, just like a very simple architecture,
652400	657440	just to see how far we can get with that. So what could AGI do? Well, of course, it can solve
657440	661840	abstract problems in almost no time, right? Thinking much faster than a human can replace
661840	668320	humans in most jobs, especially like mental jobs. And like I said earlier, if you embody the AGI,
668320	672320	like you put it inside a robot body that's like a human, then it could, for example,
672320	676800	literally drive a car around. It's kind of a funny thought that maybe the way we get self-driving
676800	681040	cars is not by making a really smart car, but by making a really smart robot that can just
681040	685120	sit in the car and interact with it using the interface that has been designed for humans.
686080	691840	Anyway, AGI would be able to do that. It's a pretty big step towards what Max Tegmark calls in his
691840	698400	book, calls Life 3.0, which is life that's able to upgrade its own hardware, probably copy itself,
698400	703120	maybe even transfer its intelligence or its consciousness across a network to somewhere
703120	708560	else, which is effectively teleportation, if you think about it. So there's a lot that AGI would
708560	713040	be doing around us that is not just the same as being human, right? And it has other, it would
713040	718720	have other abilities. So let's talk finally, third section, let's talk about the timelines for AGI.
718720	725040	Why didn't this happen before now? Like why, why are we only now starting to really develop AI
725120	729440	at the rate at which we are? We've had essentially infinite computation available
729440	734400	in the cloud for quite a while now, provided you had essentially infinite budget. And the
734400	739680	truth is that we were just learning how to construct models. We were learning how to use
739680	744720	this computational power to build a brain. We were learning how to collect and train this data.
744720	748800	We were learning the best structures that would be used to build a brain and the best way to
748800	752880	feed that data into it so that it could learn. Even the simplest structures are sufficient,
752880	756800	it seems, to build something pretty intelligent, provided you have enough data and have the
756800	760960	appropriate deep learning algorithms. I think it's one of those cases where a time traveler could
760960	765680	go back in time and invent this tech much sooner than we did ourselves, but we're doing it the
765680	771840	hard way. That said, AGI is almost here. It's really close. There's a graph here that shows
771840	776320	the number of parameters in a model versus the year. And you can see it looks like it's growing
776320	780400	exponentially until you look at the scale and you realize it's already on a log scale. So it's
780400	786560	actually growing doubly exponentially, which is really incredible. And that's why I would say
786560	792880	that AGI is almost here. It's incredibly close because we're on this doubly exponential rate
792880	797840	of change and we're constantly using the tools of today to build the tools of tomorrow at an
797840	803280	accelerating rate. Even chat GPT can accelerate the power of a developer probably by like 5x or
803280	809040	something once they know how to use the tool. And that is going to be a factor in the production of
809040	814240	code for GPT 5. Right now, these AI tools need a human in the loop. They're not fully autonomous,
814240	818000	but that is not to say they're not powerful. They're extremely powerful. And as they get more
818000	821600	and more powerful, they'll need the human in the loop less and less until eventually they're
821600	827040	basically fully autonomous. There are people like David Shapiro that are estimating AGI is only about
827040	831360	18 months away from now. It's a matter of months, not even years at this point, perhaps. And if
831360	836160	it's true, it would be very exciting and also extremely dangerous at the same time. We've all
836160	842400	seen enough science fiction movies about AI that wants to kill humans to know that it could end
842400	847520	badly. Here's a quote again from Max Tegmark. In short, it turned out to be a lot easier to
847520	852880	build human or close to human intelligence than we thought. Again, commenting on that even using
852880	858160	these like maybe suboptimal architectures, and we've already had quite a lot of success. And again,
858160	862320	that means it's even more dangerous, actually, that the fact that intelligence is relatively easy
862320	867520	to achieve is dangerous because it means we'll probably accelerate through those more advanced
867520	872400	forms of it, including AGI, even more rapidly. I want to mention as well that super intelligence
872400	878960	would not be far behind after we obtained AGI, because again, we would be using AGI to then say,
878960	883760	hey, how would you build a super intelligent AI? And it would help us do that most likely. I have
883760	888240	another science fiction comparison bear with me. There's a book called Marooned in Real Time by
888240	893440	Werner Vinge. It's set in a post-singularity world where civilization has actually disappeared.
893440	898560	All the humans on the planet just disappeared during the singularity. And there are some time
898560	902240	travelers that have actually passed through the singularity, and now they're looking around
902240	906560	wondering what happened. And those time travelers left at different points in time leading up to
906560	910320	the singularity. And the closer they were to the singularity, the more powerful they are in the
910320	915920	book, where the ones that left just a few months before the singularity was presumed to have happened
916080	920160	have resources comparable to like full countries or the militaries of full countries.
920160	924240	And that's where you're going when you're approaching a technological singularity.
924240	929040	There's a lot to talk about when we think about the implications of AGI, why we have
929040	934480	reason to be cautious about its development. I'll make another video going into the details of why
934480	938560	we should be potentially scared of this rapid progress and what we should be doing to control
938560	944320	the pace. In conclusion, chat GPT and building on top of it, auto GPT seemed, in my opinion,
944320	949200	to fully satisfy the definition of intelligence that has been set up by psychologists. And I was
949200	955440	shocked when I heard about auto GPT and I learned about its capabilities and saw it in action because
955440	960480	it's just such a big jump even from where chat GPT was and in such a short period of time. And
960480	965200	with not all that much ever, and I think that will just pretend what we will see in the future.
965200	970400	Very rapid steps of improvement that maybe are not all that difficult or are certainly happening
970480	976400	very rapidly. So where does that lead? It leads to AGI. AGI seems to be extremely close. I think
976400	982160	Ray Kurzweil might be underestimating how far away the singularity is for us. So again, my next
982160	986880	video will talk more about the implications of AGI. And that's all I have for today. Hope you
986880	988640	enjoyed. Thank you very much for watching. Bye.
