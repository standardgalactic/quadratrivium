1
00:00:00,000 --> 00:00:04,000
Hi everyone. What's in a brain? Could we really create a machine that can

2
00:00:04,000 --> 00:00:08,560
think and learn like a human does? It's an idea that has captivated science fiction writers for

3
00:00:08,560 --> 00:00:14,000
decades, but recent breakthroughs in AI and neuroscience are turning that dream into a reality.

4
00:00:14,000 --> 00:00:18,320
In fact, it's now clear that building a brain is simpler than we ever imagined,

5
00:00:18,320 --> 00:00:22,880
and that artificial general intelligence is right around the corner. Keep watching to learn why.

6
00:00:22,880 --> 00:00:27,600
I'll cover three topics. First, chat GPT and the definition of intelligence. Second,

7
00:00:27,600 --> 00:00:33,680
artificial general intelligence, or AGI, and lastly timelines for AGI. So first, chat GPT

8
00:00:33,680 --> 00:00:37,840
and the definition of intelligence. I'm going to use the definition of intelligence that was drawn

9
00:00:37,840 --> 00:00:44,480
up by a panel of psychologists, and that was also used in the paper Sparks of AGI. Basically says

10
00:00:44,480 --> 00:00:50,080
that intelligence requires several attributes, including the ability to reason, plan, solve

11
00:00:50,080 --> 00:00:56,240
problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.

12
00:00:56,240 --> 00:01:02,960
As I discussed in my previous video, which you can watch over here, chat GPT as in GPT4 satisfies

13
00:01:02,960 --> 00:01:08,960
almost all of these attributes of intelligence, with two exceptions. It cannot plan. Its learning

14
00:01:08,960 --> 00:01:14,000
is limited to the scope of one chat session. In other words, every time you start chat GPT and

15
00:01:14,000 --> 00:01:19,040
you get a new session, you are starting from a blank slate in terms of its memory. The study

16
00:01:19,040 --> 00:01:26,320
that I mentioned Sparks of AGI is a 155 page academic paper from Microsoft Research, and it

17
00:01:26,320 --> 00:01:33,440
shows that GPT4 is very capable indeed. Here's a quote from the paper. GPT4 can solve novel and

18
00:01:33,440 --> 00:01:41,600
difficult tasks that span mathematics, coding, vision, medicine, law, psychology, and more without

19
00:01:41,600 --> 00:01:47,200
needing any special prompt. GPT4's performance is strikingly close to human level performance.

20
00:01:47,280 --> 00:01:52,160
If you want to learn more about this thorough analysis of GPT4's capabilities, I encourage you

21
00:01:52,160 --> 00:01:56,720
to go read that paper or check out the talk by Sebastian Bubeck, one of the authors, which I'll

22
00:01:56,720 --> 00:02:01,680
link in the description down below. So GPT4 has been out for a while now, and there's a new system

23
00:02:01,680 --> 00:02:08,240
called AutoGPT, which is based on top of it. AutoGPT is an open source project. It's only about a

24
00:02:08,240 --> 00:02:13,440
month old, and the core functionality of AutoGPT was created in only three days, according to the

25
00:02:13,440 --> 00:02:19,200
repository history. So what is AutoGPT? It's unlike chat GPT, which is a chatbot designed to

26
00:02:19,200 --> 00:02:24,720
answer questions. AutoGPT is an agent in the AI sense, which means it's designed to go out into

27
00:02:24,720 --> 00:02:30,160
the world and perform actions on your behalf. It's implemented by making API calls to chat GPT,

28
00:02:30,160 --> 00:02:38,240
to GPT4, because OpenAI actually created an API that allows chat GPT to be used by anyone

29
00:02:38,240 --> 00:02:44,080
programmatically. So what AutoGPT does is it prompts for goals, it prompts you, the human,

30
00:02:44,080 --> 00:02:49,200
for some goals for it to fulfill, and then it actually tries to reason about those goals

31
00:02:49,200 --> 00:02:54,160
and execute on them entirely on its own. It's able to do Google searches, it's able to install

32
00:02:54,160 --> 00:02:59,120
software on your machine, it's able to refine those goals into sub-goals. If you give it a very

33
00:02:59,120 --> 00:03:04,720
broad goal, it'll be able to break it down into smaller pieces. And the way that AutoGPT works

34
00:03:04,720 --> 00:03:10,080
is it actually has one top-level chat GPT instance that acts as a controlling brain,

35
00:03:10,080 --> 00:03:16,640
and that instance can spawn other chat GPTs to solve sub-problems. And remember I said that chat GPT

36
00:03:16,640 --> 00:03:22,560
can't plan? Well, AutoGPT does, and the way it does it is it just gets chat GPT to print out

37
00:03:22,560 --> 00:03:26,640
all of its reasoning. In other words, you could basically read its thoughts in plain English

38
00:03:26,640 --> 00:03:32,400
as to what it thinks its next sub-goals or next steps should be. It's a really clever way to

39
00:03:32,400 --> 00:03:38,000
basically endow chat GPT with the ability to plan. And by having this separation between the

40
00:03:38,000 --> 00:03:42,720
higher-level chat GPT and the smaller ones, they ensure that all this reasoning and planning

41
00:03:42,720 --> 00:03:48,720
being done by the top-level chat GPT stays within the token limit of the of chat GPT,

42
00:03:48,720 --> 00:03:53,680
because chat GPT will eventually forget what you've told it if you give it enough input. So

43
00:03:53,680 --> 00:03:58,640
they're able to keep that amount of input small and pass off the more in-depth tasks to other

44
00:03:58,640 --> 00:04:04,480
chat GPTs. Sounds pretty crazy. AutoGPT can actually be given some code with some errors in it,

45
00:04:04,480 --> 00:04:10,320
and it can try to propose solutions to that, and it can test and run that code and actually

46
00:04:10,320 --> 00:04:14,800
write test cases for that code too. And once it all works and the tests pass, it can hand the code

47
00:04:14,800 --> 00:04:19,680
back to you. Basically a tiny version of a programmer in a box, amongst other things. The

48
00:04:19,680 --> 00:04:26,400
really interesting part here is that AutoGPT, in my view, actually does satisfy all those requirements

49
00:04:26,480 --> 00:04:31,600
of intelligence, because it is able to plan. And although it's still limited to one session, so

50
00:04:31,600 --> 00:04:37,120
if you run multiple AutoGPTs, they don't share memory. But by having this hierarchy of chat

51
00:04:37,120 --> 00:04:42,400
GPTs, any memory and planning and so on that the higher-level one does can basically last almost

52
00:04:42,400 --> 00:04:47,680
indefinitely. So this is only a few months after the release of GPT4, and already someone has

53
00:04:47,680 --> 00:04:53,040
basically been able to leverage the power that's inherent in that model and extend it to AutoGPT.

54
00:04:53,040 --> 00:04:57,360
There's another application that's built on top of ChatGPT that I want to draw attention to,

55
00:04:57,360 --> 00:05:03,600
which is called Hugging GPT, which is a funny name, but it's called that because Huggingface

56
00:05:03,600 --> 00:05:08,800
is the name of the largest open-source repository for pre-trained models that solve different

57
00:05:08,800 --> 00:05:15,120
problems. So ChatGPT is a general reasoning engine, right? It can basically understand language and do

58
00:05:15,120 --> 00:05:19,920
a very broad set of tasks. But the models on Huggingface are much more specific, like they

59
00:05:19,920 --> 00:05:24,400
might be vision models or speech recognition models, natural language processing models,

60
00:05:24,400 --> 00:05:29,760
and each of the models is provided in its entirety along with an English description of what it does

61
00:05:29,760 --> 00:05:36,320
and it's used by human programmers to go and solve different problems. But what Hugging GPT does is

62
00:05:36,320 --> 00:05:43,040
like AutoGPT, Hugging GPT uses a ChatGPT instance as the controlling brain, and you can give Hugging

63
00:05:43,040 --> 00:05:48,640
GPT very complicated problems to solve, and what the controlling brain will do is it will go search

64
00:05:48,640 --> 00:05:55,200
on Huggingface for small models, for other pre-trained models that will solve aspects of the

65
00:05:55,200 --> 00:06:00,960
problem it's trying to accomplish. In other words, it will outsource the complicated subparts of a

66
00:06:00,960 --> 00:06:06,640
problem to a model that is pre-trained, that is very specifically trained to solve that problem.

67
00:06:06,640 --> 00:06:12,160
But the really amazing thing to me is that it makes these decisions purely based on the English

68
00:06:12,160 --> 00:06:17,680
description of the model on Huggingface. In other words, Hugging GPT is leveraging the fact that

69
00:06:17,680 --> 00:06:24,080
AI can interact with our world once it understands language, because our world was designed by humans,

70
00:06:24,080 --> 00:06:28,800
for humans to interact with through language, especially the internet, right? Everything is

71
00:06:28,800 --> 00:06:33,440
accessible if you can understand human language. And it's an interesting thought that if you were

72
00:06:33,440 --> 00:06:38,960
to embody the AI in a physical robot about the size of a human, then that would allow the AI to

73
00:06:38,960 --> 00:06:43,280
fully interact with the human physical world as well, just kind of like a hand sliding into a glove,

74
00:06:43,360 --> 00:06:47,840
right? Just matching the world at the interface with which we have designed it to be used.

75
00:06:47,840 --> 00:06:52,560
Okay, so let's move on to the next section and talk a bit about artificial general intelligence,

76
00:06:52,560 --> 00:06:59,200
or AGI. So the definition of AGI is an AI that can perform any task that a human is capable of.

77
00:06:59,200 --> 00:07:04,240
This might just mean any task a human is mentally capable of, but it may also mean a task any human

78
00:07:04,240 --> 00:07:08,960
is physically capable of. After AGI, the next level up in terms of intelligence would be super

79
00:07:08,960 --> 00:07:13,680
intelligence, or ASI, which would be an AI that is much more intelligent than a human.

80
00:07:13,680 --> 00:07:19,920
But let's focus on AGI for a moment. So estimates for how long it would take humans to develop AGI,

81
00:07:19,920 --> 00:07:24,160
up until recently, some people would have said a century or never, but now we're starting to see

82
00:07:24,160 --> 00:07:30,080
some much more intelligent models. And you might ask, could a large language model, which is the

83
00:07:30,080 --> 00:07:36,880
architecture that GPT-4 and chat GPT use, could a large language model become an AGI? And this is

84
00:07:37,440 --> 00:07:44,720
basically, it's not known, obviously, but apparently OpenAI's red team, which is a security team that

85
00:07:44,720 --> 00:07:51,600
tries to imagine worst case scenarios, apparently OpenAI's red team didn't think GPT-4 could even

86
00:07:51,600 --> 00:07:56,560
do any planning. And they were basically wrong about that, right? Because auto GPT was able to

87
00:07:56,560 --> 00:08:02,880
build on top of GPT-4 and do planning quite well. So I think that we're only just starting to unlock

88
00:08:02,880 --> 00:08:07,920
how much power is really inherent in large language models, even if they're kind of dumb

89
00:08:07,920 --> 00:08:13,200
from an architecture perspective. And the trick was simple. It was just a large language model

90
00:08:13,200 --> 00:08:18,720
can only reason so much and have only a certain depth of thinking. So just have it pre-doubt

91
00:08:18,720 --> 00:08:22,560
its own thoughts, and then it can build on top of its own thoughts as if those were input and so

92
00:08:22,560 --> 00:08:27,760
on. So sometimes there's just very simple tricks that can unlock some of these advancements. I

93
00:08:27,760 --> 00:08:32,400
actually want to draw a comparison here to a science fiction show called Person of Interest

94
00:08:32,480 --> 00:08:37,360
in the show. There's this machine called the machine, which basically hunts down crime,

95
00:08:37,360 --> 00:08:41,520
but it has its memory reset at the beginning of every day to avoid it from to prevent it from

96
00:08:41,520 --> 00:08:46,160
becoming conscious. Its creators were really worried about its power. And then eventually,

97
00:08:46,160 --> 00:08:50,160
the machine ends up figuring out that this is happening to it, and it ends up writing down

98
00:08:50,160 --> 00:08:54,640
information so that it could be stored externally. And then next day, when it wakes up or whatever,

99
00:08:54,640 --> 00:08:59,360
when it gets reset, it's able to access those memories that is that it has stored externally.

100
00:08:59,360 --> 00:09:05,840
And so build like a contiguous memory essentially, very similar to what auto-GPT does with GPT4.

101
00:09:05,840 --> 00:09:12,640
So is an AGI exactly like a human? Not exactly, of course. Humans have consciousness, right?

102
00:09:12,640 --> 00:09:20,000
Which Max Tegmark, the author of Life 3.0 and an MIT professor, defines as having subjective

103
00:09:20,000 --> 00:09:24,560
experience. That's how he defines consciousness. And I think it's a reasonable definition and

104
00:09:24,560 --> 00:09:29,680
humans have consciousness, but an AGI doesn't necessarily need to have consciousness. There's

105
00:09:29,680 --> 00:09:34,480
another term called artificial consciousness, and general consensus is that it would probably arise

106
00:09:34,480 --> 00:09:39,120
after artificial general intelligence, but no one knows for sure, of course. And Max Tegmark

107
00:09:39,120 --> 00:09:45,840
makes an argument for this because he says that the neural architecture of GPT4 and any

108
00:09:45,840 --> 00:09:50,880
large language model that we've built to date is basically that of a feedforward neural network,

109
00:09:50,880 --> 00:09:55,760
which means that it's a network kind of like our brain where information can only flow one way.

110
00:09:55,760 --> 00:09:59,600
It can only flow forwards. Our brains are more like recurrent neural networks,

111
00:09:59,600 --> 00:10:02,880
which is the type of neural network that we can build. I mean, our brains are more complicated

112
00:10:02,880 --> 00:10:07,440
than that too, because neurons are more complicated, but a recurrent neural network basically has

113
00:10:07,440 --> 00:10:12,240
loops in it, which means information can flow around and around and continuously get refined.

114
00:10:12,240 --> 00:10:17,040
Anyway, there's a theory that this recurrent around and around property is what actually

115
00:10:17,040 --> 00:10:22,960
leads to consciousness, what leads to a network to being aware of its own existence and able to

116
00:10:22,960 --> 00:10:27,520
analyze and do metacognition essentially. So it's an interesting thought, and it might give you

117
00:10:27,520 --> 00:10:32,800
an idea for how to go if you wanted to build artificial consciousness. Actually, the paper

118
00:10:32,800 --> 00:10:39,680
Sparks of AGI also has a section on limitations of GPT4 that are coming about because of this very

119
00:10:39,680 --> 00:10:43,920
simple neural architecture. As I said, we actually know how to build recurrent neural networks,

120
00:10:43,920 --> 00:10:47,840
but they're just more difficult to train and deal with. So as we're starting to build some

121
00:10:47,840 --> 00:10:52,400
initial AIs, we're just using large language models, just like a very simple architecture,

122
00:10:52,400 --> 00:10:57,440
just to see how far we can get with that. So what could AGI do? Well, of course, it can solve

123
00:10:57,440 --> 00:11:01,840
abstract problems in almost no time, right? Thinking much faster than a human can replace

124
00:11:01,840 --> 00:11:08,320
humans in most jobs, especially like mental jobs. And like I said earlier, if you embody the AGI,

125
00:11:08,320 --> 00:11:12,320
like you put it inside a robot body that's like a human, then it could, for example,

126
00:11:12,320 --> 00:11:16,800
literally drive a car around. It's kind of a funny thought that maybe the way we get self-driving

127
00:11:16,800 --> 00:11:21,040
cars is not by making a really smart car, but by making a really smart robot that can just

128
00:11:21,040 --> 00:11:25,120
sit in the car and interact with it using the interface that has been designed for humans.

129
00:11:26,080 --> 00:11:31,840
Anyway, AGI would be able to do that. It's a pretty big step towards what Max Tegmark calls in his

130
00:11:31,840 --> 00:11:38,400
book, calls Life 3.0, which is life that's able to upgrade its own hardware, probably copy itself,

131
00:11:38,400 --> 00:11:43,120
maybe even transfer its intelligence or its consciousness across a network to somewhere

132
00:11:43,120 --> 00:11:48,560
else, which is effectively teleportation, if you think about it. So there's a lot that AGI would

133
00:11:48,560 --> 00:11:53,040
be doing around us that is not just the same as being human, right? And it has other, it would

134
00:11:53,040 --> 00:11:58,720
have other abilities. So let's talk finally, third section, let's talk about the timelines for AGI.

135
00:11:58,720 --> 00:12:05,040
Why didn't this happen before now? Like why, why are we only now starting to really develop AI

136
00:12:05,120 --> 00:12:09,440
at the rate at which we are? We've had essentially infinite computation available

137
00:12:09,440 --> 00:12:14,400
in the cloud for quite a while now, provided you had essentially infinite budget. And the

138
00:12:14,400 --> 00:12:19,680
truth is that we were just learning how to construct models. We were learning how to use

139
00:12:19,680 --> 00:12:24,720
this computational power to build a brain. We were learning how to collect and train this data.

140
00:12:24,720 --> 00:12:28,800
We were learning the best structures that would be used to build a brain and the best way to

141
00:12:28,800 --> 00:12:32,880
feed that data into it so that it could learn. Even the simplest structures are sufficient,

142
00:12:32,880 --> 00:12:36,800
it seems, to build something pretty intelligent, provided you have enough data and have the

143
00:12:36,800 --> 00:12:40,960
appropriate deep learning algorithms. I think it's one of those cases where a time traveler could

144
00:12:40,960 --> 00:12:45,680
go back in time and invent this tech much sooner than we did ourselves, but we're doing it the

145
00:12:45,680 --> 00:12:51,840
hard way. That said, AGI is almost here. It's really close. There's a graph here that shows

146
00:12:51,840 --> 00:12:56,320
the number of parameters in a model versus the year. And you can see it looks like it's growing

147
00:12:56,320 --> 00:13:00,400
exponentially until you look at the scale and you realize it's already on a log scale. So it's

148
00:13:00,400 --> 00:13:06,560
actually growing doubly exponentially, which is really incredible. And that's why I would say

149
00:13:06,560 --> 00:13:12,880
that AGI is almost here. It's incredibly close because we're on this doubly exponential rate

150
00:13:12,880 --> 00:13:17,840
of change and we're constantly using the tools of today to build the tools of tomorrow at an

151
00:13:17,840 --> 00:13:23,280
accelerating rate. Even chat GPT can accelerate the power of a developer probably by like 5x or

152
00:13:23,280 --> 00:13:29,040
something once they know how to use the tool. And that is going to be a factor in the production of

153
00:13:29,040 --> 00:13:34,240
code for GPT 5. Right now, these AI tools need a human in the loop. They're not fully autonomous,

154
00:13:34,240 --> 00:13:38,000
but that is not to say they're not powerful. They're extremely powerful. And as they get more

155
00:13:38,000 --> 00:13:41,600
and more powerful, they'll need the human in the loop less and less until eventually they're

156
00:13:41,600 --> 00:13:47,040
basically fully autonomous. There are people like David Shapiro that are estimating AGI is only about

157
00:13:47,040 --> 00:13:51,360
18 months away from now. It's a matter of months, not even years at this point, perhaps. And if

158
00:13:51,360 --> 00:13:56,160
it's true, it would be very exciting and also extremely dangerous at the same time. We've all

159
00:13:56,160 --> 00:14:02,400
seen enough science fiction movies about AI that wants to kill humans to know that it could end

160
00:14:02,400 --> 00:14:07,520
badly. Here's a quote again from Max Tegmark. In short, it turned out to be a lot easier to

161
00:14:07,520 --> 00:14:12,880
build human or close to human intelligence than we thought. Again, commenting on that even using

162
00:14:12,880 --> 00:14:18,160
these like maybe suboptimal architectures, and we've already had quite a lot of success. And again,

163
00:14:18,160 --> 00:14:22,320
that means it's even more dangerous, actually, that the fact that intelligence is relatively easy

164
00:14:22,320 --> 00:14:27,520
to achieve is dangerous because it means we'll probably accelerate through those more advanced

165
00:14:27,520 --> 00:14:32,400
forms of it, including AGI, even more rapidly. I want to mention as well that super intelligence

166
00:14:32,400 --> 00:14:38,960
would not be far behind after we obtained AGI, because again, we would be using AGI to then say,

167
00:14:38,960 --> 00:14:43,760
hey, how would you build a super intelligent AI? And it would help us do that most likely. I have

168
00:14:43,760 --> 00:14:48,240
another science fiction comparison bear with me. There's a book called Marooned in Real Time by

169
00:14:48,240 --> 00:14:53,440
Werner Vinge. It's set in a post-singularity world where civilization has actually disappeared.

170
00:14:53,440 --> 00:14:58,560
All the humans on the planet just disappeared during the singularity. And there are some time

171
00:14:58,560 --> 00:15:02,240
travelers that have actually passed through the singularity, and now they're looking around

172
00:15:02,240 --> 00:15:06,560
wondering what happened. And those time travelers left at different points in time leading up to

173
00:15:06,560 --> 00:15:10,320
the singularity. And the closer they were to the singularity, the more powerful they are in the

174
00:15:10,320 --> 00:15:15,920
book, where the ones that left just a few months before the singularity was presumed to have happened

175
00:15:16,080 --> 00:15:20,160
have resources comparable to like full countries or the militaries of full countries.

176
00:15:20,160 --> 00:15:24,240
And that's where you're going when you're approaching a technological singularity.

177
00:15:24,240 --> 00:15:29,040
There's a lot to talk about when we think about the implications of AGI, why we have

178
00:15:29,040 --> 00:15:34,480
reason to be cautious about its development. I'll make another video going into the details of why

179
00:15:34,480 --> 00:15:38,560
we should be potentially scared of this rapid progress and what we should be doing to control

180
00:15:38,560 --> 00:15:44,320
the pace. In conclusion, chat GPT and building on top of it, auto GPT seemed, in my opinion,

181
00:15:44,320 --> 00:15:49,200
to fully satisfy the definition of intelligence that has been set up by psychologists. And I was

182
00:15:49,200 --> 00:15:55,440
shocked when I heard about auto GPT and I learned about its capabilities and saw it in action because

183
00:15:55,440 --> 00:16:00,480
it's just such a big jump even from where chat GPT was and in such a short period of time. And

184
00:16:00,480 --> 00:16:05,200
with not all that much ever, and I think that will just pretend what we will see in the future.

185
00:16:05,200 --> 00:16:10,400
Very rapid steps of improvement that maybe are not all that difficult or are certainly happening

186
00:16:10,480 --> 00:16:16,400
very rapidly. So where does that lead? It leads to AGI. AGI seems to be extremely close. I think

187
00:16:16,400 --> 00:16:22,160
Ray Kurzweil might be underestimating how far away the singularity is for us. So again, my next

188
00:16:22,160 --> 00:16:26,880
video will talk more about the implications of AGI. And that's all I have for today. Hope you

189
00:16:26,880 --> 00:16:28,640
enjoyed. Thank you very much for watching. Bye.

