WEBVTT

00:00.000 --> 00:04.000
Hi everyone. What's in a brain? Could we really create a machine that can

00:04.000 --> 00:08.560
think and learn like a human does? It's an idea that has captivated science fiction writers for

00:08.560 --> 00:14.000
decades, but recent breakthroughs in AI and neuroscience are turning that dream into a reality.

00:14.000 --> 00:18.320
In fact, it's now clear that building a brain is simpler than we ever imagined,

00:18.320 --> 00:22.880
and that artificial general intelligence is right around the corner. Keep watching to learn why.

00:22.880 --> 00:27.600
I'll cover three topics. First, chat GPT and the definition of intelligence. Second,

00:27.600 --> 00:33.680
artificial general intelligence, or AGI, and lastly timelines for AGI. So first, chat GPT

00:33.680 --> 00:37.840
and the definition of intelligence. I'm going to use the definition of intelligence that was drawn

00:37.840 --> 00:44.480
up by a panel of psychologists, and that was also used in the paper Sparks of AGI. Basically says

00:44.480 --> 00:50.080
that intelligence requires several attributes, including the ability to reason, plan, solve

00:50.080 --> 00:56.240
problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.

00:56.240 --> 01:02.960
As I discussed in my previous video, which you can watch over here, chat GPT as in GPT4 satisfies

01:02.960 --> 01:08.960
almost all of these attributes of intelligence, with two exceptions. It cannot plan. Its learning

01:08.960 --> 01:14.000
is limited to the scope of one chat session. In other words, every time you start chat GPT and

01:14.000 --> 01:19.040
you get a new session, you are starting from a blank slate in terms of its memory. The study

01:19.040 --> 01:26.320
that I mentioned Sparks of AGI is a 155 page academic paper from Microsoft Research, and it

01:26.320 --> 01:33.440
shows that GPT4 is very capable indeed. Here's a quote from the paper. GPT4 can solve novel and

01:33.440 --> 01:41.600
difficult tasks that span mathematics, coding, vision, medicine, law, psychology, and more without

01:41.600 --> 01:47.200
needing any special prompt. GPT4's performance is strikingly close to human level performance.

01:47.280 --> 01:52.160
If you want to learn more about this thorough analysis of GPT4's capabilities, I encourage you

01:52.160 --> 01:56.720
to go read that paper or check out the talk by Sebastian Bubeck, one of the authors, which I'll

01:56.720 --> 02:01.680
link in the description down below. So GPT4 has been out for a while now, and there's a new system

02:01.680 --> 02:08.240
called AutoGPT, which is based on top of it. AutoGPT is an open source project. It's only about a

02:08.240 --> 02:13.440
month old, and the core functionality of AutoGPT was created in only three days, according to the

02:13.440 --> 02:19.200
repository history. So what is AutoGPT? It's unlike chat GPT, which is a chatbot designed to

02:19.200 --> 02:24.720
answer questions. AutoGPT is an agent in the AI sense, which means it's designed to go out into

02:24.720 --> 02:30.160
the world and perform actions on your behalf. It's implemented by making API calls to chat GPT,

02:30.160 --> 02:38.240
to GPT4, because OpenAI actually created an API that allows chat GPT to be used by anyone

02:38.240 --> 02:44.080
programmatically. So what AutoGPT does is it prompts for goals, it prompts you, the human,

02:44.080 --> 02:49.200
for some goals for it to fulfill, and then it actually tries to reason about those goals

02:49.200 --> 02:54.160
and execute on them entirely on its own. It's able to do Google searches, it's able to install

02:54.160 --> 02:59.120
software on your machine, it's able to refine those goals into sub-goals. If you give it a very

02:59.120 --> 03:04.720
broad goal, it'll be able to break it down into smaller pieces. And the way that AutoGPT works

03:04.720 --> 03:10.080
is it actually has one top-level chat GPT instance that acts as a controlling brain,

03:10.080 --> 03:16.640
and that instance can spawn other chat GPTs to solve sub-problems. And remember I said that chat GPT

03:16.640 --> 03:22.560
can't plan? Well, AutoGPT does, and the way it does it is it just gets chat GPT to print out

03:22.560 --> 03:26.640
all of its reasoning. In other words, you could basically read its thoughts in plain English

03:26.640 --> 03:32.400
as to what it thinks its next sub-goals or next steps should be. It's a really clever way to

03:32.400 --> 03:38.000
basically endow chat GPT with the ability to plan. And by having this separation between the

03:38.000 --> 03:42.720
higher-level chat GPT and the smaller ones, they ensure that all this reasoning and planning

03:42.720 --> 03:48.720
being done by the top-level chat GPT stays within the token limit of the of chat GPT,

03:48.720 --> 03:53.680
because chat GPT will eventually forget what you've told it if you give it enough input. So

03:53.680 --> 03:58.640
they're able to keep that amount of input small and pass off the more in-depth tasks to other

03:58.640 --> 04:04.480
chat GPTs. Sounds pretty crazy. AutoGPT can actually be given some code with some errors in it,

04:04.480 --> 04:10.320
and it can try to propose solutions to that, and it can test and run that code and actually

04:10.320 --> 04:14.800
write test cases for that code too. And once it all works and the tests pass, it can hand the code

04:14.800 --> 04:19.680
back to you. Basically a tiny version of a programmer in a box, amongst other things. The

04:19.680 --> 04:26.400
really interesting part here is that AutoGPT, in my view, actually does satisfy all those requirements

04:26.480 --> 04:31.600
of intelligence, because it is able to plan. And although it's still limited to one session, so

04:31.600 --> 04:37.120
if you run multiple AutoGPTs, they don't share memory. But by having this hierarchy of chat

04:37.120 --> 04:42.400
GPTs, any memory and planning and so on that the higher-level one does can basically last almost

04:42.400 --> 04:47.680
indefinitely. So this is only a few months after the release of GPT4, and already someone has

04:47.680 --> 04:53.040
basically been able to leverage the power that's inherent in that model and extend it to AutoGPT.

04:53.040 --> 04:57.360
There's another application that's built on top of ChatGPT that I want to draw attention to,

04:57.360 --> 05:03.600
which is called Hugging GPT, which is a funny name, but it's called that because Huggingface

05:03.600 --> 05:08.800
is the name of the largest open-source repository for pre-trained models that solve different

05:08.800 --> 05:15.120
problems. So ChatGPT is a general reasoning engine, right? It can basically understand language and do

05:15.120 --> 05:19.920
a very broad set of tasks. But the models on Huggingface are much more specific, like they

05:19.920 --> 05:24.400
might be vision models or speech recognition models, natural language processing models,

05:24.400 --> 05:29.760
and each of the models is provided in its entirety along with an English description of what it does

05:29.760 --> 05:36.320
and it's used by human programmers to go and solve different problems. But what Hugging GPT does is

05:36.320 --> 05:43.040
like AutoGPT, Hugging GPT uses a ChatGPT instance as the controlling brain, and you can give Hugging

05:43.040 --> 05:48.640
GPT very complicated problems to solve, and what the controlling brain will do is it will go search

05:48.640 --> 05:55.200
on Huggingface for small models, for other pre-trained models that will solve aspects of the

05:55.200 --> 06:00.960
problem it's trying to accomplish. In other words, it will outsource the complicated subparts of a

06:00.960 --> 06:06.640
problem to a model that is pre-trained, that is very specifically trained to solve that problem.

06:06.640 --> 06:12.160
But the really amazing thing to me is that it makes these decisions purely based on the English

06:12.160 --> 06:17.680
description of the model on Huggingface. In other words, Hugging GPT is leveraging the fact that

06:17.680 --> 06:24.080
AI can interact with our world once it understands language, because our world was designed by humans,

06:24.080 --> 06:28.800
for humans to interact with through language, especially the internet, right? Everything is

06:28.800 --> 06:33.440
accessible if you can understand human language. And it's an interesting thought that if you were

06:33.440 --> 06:38.960
to embody the AI in a physical robot about the size of a human, then that would allow the AI to

06:38.960 --> 06:43.280
fully interact with the human physical world as well, just kind of like a hand sliding into a glove,

06:43.360 --> 06:47.840
right? Just matching the world at the interface with which we have designed it to be used.

06:47.840 --> 06:52.560
Okay, so let's move on to the next section and talk a bit about artificial general intelligence,

06:52.560 --> 06:59.200
or AGI. So the definition of AGI is an AI that can perform any task that a human is capable of.

06:59.200 --> 07:04.240
This might just mean any task a human is mentally capable of, but it may also mean a task any human

07:04.240 --> 07:08.960
is physically capable of. After AGI, the next level up in terms of intelligence would be super

07:08.960 --> 07:13.680
intelligence, or ASI, which would be an AI that is much more intelligent than a human.

07:13.680 --> 07:19.920
But let's focus on AGI for a moment. So estimates for how long it would take humans to develop AGI,

07:19.920 --> 07:24.160
up until recently, some people would have said a century or never, but now we're starting to see

07:24.160 --> 07:30.080
some much more intelligent models. And you might ask, could a large language model, which is the

07:30.080 --> 07:36.880
architecture that GPT-4 and chat GPT use, could a large language model become an AGI? And this is

07:37.440 --> 07:44.720
basically, it's not known, obviously, but apparently OpenAI's red team, which is a security team that

07:44.720 --> 07:51.600
tries to imagine worst case scenarios, apparently OpenAI's red team didn't think GPT-4 could even

07:51.600 --> 07:56.560
do any planning. And they were basically wrong about that, right? Because auto GPT was able to

07:56.560 --> 08:02.880
build on top of GPT-4 and do planning quite well. So I think that we're only just starting to unlock

08:02.880 --> 08:07.920
how much power is really inherent in large language models, even if they're kind of dumb

08:07.920 --> 08:13.200
from an architecture perspective. And the trick was simple. It was just a large language model

08:13.200 --> 08:18.720
can only reason so much and have only a certain depth of thinking. So just have it pre-doubt

08:18.720 --> 08:22.560
its own thoughts, and then it can build on top of its own thoughts as if those were input and so

08:22.560 --> 08:27.760
on. So sometimes there's just very simple tricks that can unlock some of these advancements. I

08:27.760 --> 08:32.400
actually want to draw a comparison here to a science fiction show called Person of Interest

08:32.480 --> 08:37.360
in the show. There's this machine called the machine, which basically hunts down crime,

08:37.360 --> 08:41.520
but it has its memory reset at the beginning of every day to avoid it from to prevent it from

08:41.520 --> 08:46.160
becoming conscious. Its creators were really worried about its power. And then eventually,

08:46.160 --> 08:50.160
the machine ends up figuring out that this is happening to it, and it ends up writing down

08:50.160 --> 08:54.640
information so that it could be stored externally. And then next day, when it wakes up or whatever,

08:54.640 --> 08:59.360
when it gets reset, it's able to access those memories that is that it has stored externally.

08:59.360 --> 09:05.840
And so build like a contiguous memory essentially, very similar to what auto-GPT does with GPT4.

09:05.840 --> 09:12.640
So is an AGI exactly like a human? Not exactly, of course. Humans have consciousness, right?

09:12.640 --> 09:20.000
Which Max Tegmark, the author of Life 3.0 and an MIT professor, defines as having subjective

09:20.000 --> 09:24.560
experience. That's how he defines consciousness. And I think it's a reasonable definition and

09:24.560 --> 09:29.680
humans have consciousness, but an AGI doesn't necessarily need to have consciousness. There's

09:29.680 --> 09:34.480
another term called artificial consciousness, and general consensus is that it would probably arise

09:34.480 --> 09:39.120
after artificial general intelligence, but no one knows for sure, of course. And Max Tegmark

09:39.120 --> 09:45.840
makes an argument for this because he says that the neural architecture of GPT4 and any

09:45.840 --> 09:50.880
large language model that we've built to date is basically that of a feedforward neural network,

09:50.880 --> 09:55.760
which means that it's a network kind of like our brain where information can only flow one way.

09:55.760 --> 09:59.600
It can only flow forwards. Our brains are more like recurrent neural networks,

09:59.600 --> 10:02.880
which is the type of neural network that we can build. I mean, our brains are more complicated

10:02.880 --> 10:07.440
than that too, because neurons are more complicated, but a recurrent neural network basically has

10:07.440 --> 10:12.240
loops in it, which means information can flow around and around and continuously get refined.

10:12.240 --> 10:17.040
Anyway, there's a theory that this recurrent around and around property is what actually

10:17.040 --> 10:22.960
leads to consciousness, what leads to a network to being aware of its own existence and able to

10:22.960 --> 10:27.520
analyze and do metacognition essentially. So it's an interesting thought, and it might give you

10:27.520 --> 10:32.800
an idea for how to go if you wanted to build artificial consciousness. Actually, the paper

10:32.800 --> 10:39.680
Sparks of AGI also has a section on limitations of GPT4 that are coming about because of this very

10:39.680 --> 10:43.920
simple neural architecture. As I said, we actually know how to build recurrent neural networks,

10:43.920 --> 10:47.840
but they're just more difficult to train and deal with. So as we're starting to build some

10:47.840 --> 10:52.400
initial AIs, we're just using large language models, just like a very simple architecture,

10:52.400 --> 10:57.440
just to see how far we can get with that. So what could AGI do? Well, of course, it can solve

10:57.440 --> 11:01.840
abstract problems in almost no time, right? Thinking much faster than a human can replace

11:01.840 --> 11:08.320
humans in most jobs, especially like mental jobs. And like I said earlier, if you embody the AGI,

11:08.320 --> 11:12.320
like you put it inside a robot body that's like a human, then it could, for example,

11:12.320 --> 11:16.800
literally drive a car around. It's kind of a funny thought that maybe the way we get self-driving

11:16.800 --> 11:21.040
cars is not by making a really smart car, but by making a really smart robot that can just

11:21.040 --> 11:25.120
sit in the car and interact with it using the interface that has been designed for humans.

11:26.080 --> 11:31.840
Anyway, AGI would be able to do that. It's a pretty big step towards what Max Tegmark calls in his

11:31.840 --> 11:38.400
book, calls Life 3.0, which is life that's able to upgrade its own hardware, probably copy itself,

11:38.400 --> 11:43.120
maybe even transfer its intelligence or its consciousness across a network to somewhere

11:43.120 --> 11:48.560
else, which is effectively teleportation, if you think about it. So there's a lot that AGI would

11:48.560 --> 11:53.040
be doing around us that is not just the same as being human, right? And it has other, it would

11:53.040 --> 11:58.720
have other abilities. So let's talk finally, third section, let's talk about the timelines for AGI.

11:58.720 --> 12:05.040
Why didn't this happen before now? Like why, why are we only now starting to really develop AI

12:05.120 --> 12:09.440
at the rate at which we are? We've had essentially infinite computation available

12:09.440 --> 12:14.400
in the cloud for quite a while now, provided you had essentially infinite budget. And the

12:14.400 --> 12:19.680
truth is that we were just learning how to construct models. We were learning how to use

12:19.680 --> 12:24.720
this computational power to build a brain. We were learning how to collect and train this data.

12:24.720 --> 12:28.800
We were learning the best structures that would be used to build a brain and the best way to

12:28.800 --> 12:32.880
feed that data into it so that it could learn. Even the simplest structures are sufficient,

12:32.880 --> 12:36.800
it seems, to build something pretty intelligent, provided you have enough data and have the

12:36.800 --> 12:40.960
appropriate deep learning algorithms. I think it's one of those cases where a time traveler could

12:40.960 --> 12:45.680
go back in time and invent this tech much sooner than we did ourselves, but we're doing it the

12:45.680 --> 12:51.840
hard way. That said, AGI is almost here. It's really close. There's a graph here that shows

12:51.840 --> 12:56.320
the number of parameters in a model versus the year. And you can see it looks like it's growing

12:56.320 --> 13:00.400
exponentially until you look at the scale and you realize it's already on a log scale. So it's

13:00.400 --> 13:06.560
actually growing doubly exponentially, which is really incredible. And that's why I would say

13:06.560 --> 13:12.880
that AGI is almost here. It's incredibly close because we're on this doubly exponential rate

13:12.880 --> 13:17.840
of change and we're constantly using the tools of today to build the tools of tomorrow at an

13:17.840 --> 13:23.280
accelerating rate. Even chat GPT can accelerate the power of a developer probably by like 5x or

13:23.280 --> 13:29.040
something once they know how to use the tool. And that is going to be a factor in the production of

13:29.040 --> 13:34.240
code for GPT 5. Right now, these AI tools need a human in the loop. They're not fully autonomous,

13:34.240 --> 13:38.000
but that is not to say they're not powerful. They're extremely powerful. And as they get more

13:38.000 --> 13:41.600
and more powerful, they'll need the human in the loop less and less until eventually they're

13:41.600 --> 13:47.040
basically fully autonomous. There are people like David Shapiro that are estimating AGI is only about

13:47.040 --> 13:51.360
18 months away from now. It's a matter of months, not even years at this point, perhaps. And if

13:51.360 --> 13:56.160
it's true, it would be very exciting and also extremely dangerous at the same time. We've all

13:56.160 --> 14:02.400
seen enough science fiction movies about AI that wants to kill humans to know that it could end

14:02.400 --> 14:07.520
badly. Here's a quote again from Max Tegmark. In short, it turned out to be a lot easier to

14:07.520 --> 14:12.880
build human or close to human intelligence than we thought. Again, commenting on that even using

14:12.880 --> 14:18.160
these like maybe suboptimal architectures, and we've already had quite a lot of success. And again,

14:18.160 --> 14:22.320
that means it's even more dangerous, actually, that the fact that intelligence is relatively easy

14:22.320 --> 14:27.520
to achieve is dangerous because it means we'll probably accelerate through those more advanced

14:27.520 --> 14:32.400
forms of it, including AGI, even more rapidly. I want to mention as well that super intelligence

14:32.400 --> 14:38.960
would not be far behind after we obtained AGI, because again, we would be using AGI to then say,

14:38.960 --> 14:43.760
hey, how would you build a super intelligent AI? And it would help us do that most likely. I have

14:43.760 --> 14:48.240
another science fiction comparison bear with me. There's a book called Marooned in Real Time by

14:48.240 --> 14:53.440
Werner Vinge. It's set in a post-singularity world where civilization has actually disappeared.

14:53.440 --> 14:58.560
All the humans on the planet just disappeared during the singularity. And there are some time

14:58.560 --> 15:02.240
travelers that have actually passed through the singularity, and now they're looking around

15:02.240 --> 15:06.560
wondering what happened. And those time travelers left at different points in time leading up to

15:06.560 --> 15:10.320
the singularity. And the closer they were to the singularity, the more powerful they are in the

15:10.320 --> 15:15.920
book, where the ones that left just a few months before the singularity was presumed to have happened

15:16.080 --> 15:20.160
have resources comparable to like full countries or the militaries of full countries.

15:20.160 --> 15:24.240
And that's where you're going when you're approaching a technological singularity.

15:24.240 --> 15:29.040
There's a lot to talk about when we think about the implications of AGI, why we have

15:29.040 --> 15:34.480
reason to be cautious about its development. I'll make another video going into the details of why

15:34.480 --> 15:38.560
we should be potentially scared of this rapid progress and what we should be doing to control

15:38.560 --> 15:44.320
the pace. In conclusion, chat GPT and building on top of it, auto GPT seemed, in my opinion,

15:44.320 --> 15:49.200
to fully satisfy the definition of intelligence that has been set up by psychologists. And I was

15:49.200 --> 15:55.440
shocked when I heard about auto GPT and I learned about its capabilities and saw it in action because

15:55.440 --> 16:00.480
it's just such a big jump even from where chat GPT was and in such a short period of time. And

16:00.480 --> 16:05.200
with not all that much ever, and I think that will just pretend what we will see in the future.

16:05.200 --> 16:10.400
Very rapid steps of improvement that maybe are not all that difficult or are certainly happening

16:10.480 --> 16:16.400
very rapidly. So where does that lead? It leads to AGI. AGI seems to be extremely close. I think

16:16.400 --> 16:22.160
Ray Kurzweil might be underestimating how far away the singularity is for us. So again, my next

16:22.160 --> 16:26.880
video will talk more about the implications of AGI. And that's all I have for today. Hope you

16:26.880 --> 16:28.640
enjoyed. Thank you very much for watching. Bye.

