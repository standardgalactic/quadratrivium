{"text": " Let's start by asking the most basic question, what is a vector? And a vector is really just two pieces of information. Direction and length, or what's also called magnitude. Two different words for the same thing. Now length is a very physical visual concept, right? It's something we can see, it's something we can measure. And the same with direction, it's our orientation, it's a very visual thing. So vectors to begin with most intuitively fit on a graph. They fit in a place where we can visualize them. And so how could we attempt to capture direction and length? Well you know, I think an arrow does a pretty good job. This for instance, for instance, captures direction, it's moving in the northeast direction, and it also clearly has a certain length. And so this is a vector, and that's exactly how we graph vectors. Just as arrows. This is also a vector, it's pointing in a certain direction, it has a certain length, as is this. So is this, this is a vector. Even though it doesn't start at the origin, it's clearly pointing in a certain direction, so it has direction, and it clearly also has length. So vectors need not start at the origin, they can start anywhere. This is also a vector, it's pointing in a certain direction, and it has a certain length. Okay, that's great. Now let's look at a specific example. Here is a vector, and I want to first of all name that vector. So I'm just going to call it V, and I'm going to put a little arrow over the top of it, to make sure that we know that this is a vector. So the vector V, and now I want to capture this information. I want to capture the information that arrow is telling us, without needing to draw it. So I'm not going to write this like this, I'm not going to say V is equal to this arrow, that's too ambiguous. I need something more definite, something with more structure. Well, this vector moves over a certain amount in the x direction. Let's say for example, it moves over 3 in the x direction. It also moves a certain amount up in the y direction. Let's say for example, it moves up 1. Well now I can say that this vector is equal to its components. So that's a new word for us. It's equal to its x component, which is 3, how much it moves over in x, and its y component, which is 1, which is how much it moves up in y. So again, this is the x component and the y component. And now anyone in the world looking at this vector, V equal to 3, 1, can go ahead and draw that vector if they want to. They know exactly which vector we're talking about when we write that. Just a bit of notation here, this is also written as a column. And it's the exact same information, it's just vertical now. And again, this is still the x component and still the y component. Okay, let's look at another example. Let's look at, let's say the vector u. And let's say it has the components negative 2, 3. Well that simply means we're moving over negative 2 in x and up 3 in y. So maybe something right around here. So this would be 3 in y and negative 2 in the x direction. And there's our vector. Nothing to it. And of course we could have written this as a column vector, negative 2, 3, if we wanted to. Okay, so we have that down. But what about direction and length? Does this capture direction and length? These just have, just using two components, how does that tell us direction and length? Well it tells us direction because this is the vector that moves over 3 in x and up 1 in y. That's its direction, over 3 up 1. It points in that direction. But what about length? Well that's what we're going to talk about in the next video. But I'll give you a clue. We've formed a right triangle here. The components tell us the length of the base and the length of the height of the triangle. And what we're trying to find is this length here which is the hypotenuse of the right triangle. So maybe you know some formula or theorem that tells you how to find the length of the hypotenuse of a right triangle. And if you do then you can figure out the length of this vector. And that's what we're going to do in the next video. See you then. Let's find the length of v equal to 3 1. But before we do that let's just get some notation out of the way. When we're talking about the length of a vector we write these double bars around it. Almost like a double absolute value around the vector. And now this is read the length of v. So going back to our vector v we have its x component is 3 and its y component is 1. So that simply means we've moved over 3 in the x direction and up 1 in the y direction. And now we've formed a right triangle. And it turns out that the length of this vector is just the hypotenuse of this triangle. And so we can just use the Pythagorean theorem. The length of v squared is equal to the 3 squared, the base squared plus the height squared. So 3 squared plus 1 squared. This is directly a direct application of the Pythagorean theorem. And so that implies if we just take the square root of both sides that the length of v is equal to the square root of 3 squared plus 1 squared. Which simplifies to the square root of 10. And it's really just as simple as that. All we're doing when we're finding the length of a vector is finding the hypotenuse of a right triangle using the Pythagorean theorem. Okay, let's look at another example. Let's say we have something like u is equal to negative 2, 7. So let's draw that. We're going to move over by 2 and up by 7. So something like that. So we've moved over negative 2 and we've moved up by 7. So maybe I'll erase that. There we go. Okay, and now the length of u again is just given by the Pythagorean theorem. And we can just skip right to the final step. And this is just going to be equal to the square root of negative 2 squared plus 7 squared. Which turns out to be 53, the square root of 53. And that's it. It's as simple as that. Okay, let's do another example here. How about w is equal to 3 negative 2. Just making stuff up. Well, then the length of w is just going to be the square root of 3 squared plus negative 2 squared. So we have 9 plus 4, so this is 13. This is the square root of 13. And we could graph that if we wanted to. We're going to go over 3 down by 2, so it's going to look something like that. And again, this is down 2 over 3. We're just talking about the hypotenuse of a right triangle. Okay, so I hope this was helpful, and I'll see you in the next video. Now that we have the basics of vectors down, we should start asking things like what can we do with vectors? Can we add vectors, for example? And the answer is yes, we can add vectors. And let's see how we would do that. So u plus v, or v plus u, I should say, v plus u is simply going to be, we're going to take the two vectors and add them. So I'm running out every step here. And how do we do this? Well, we just add their corresponding components together. So the first component of v plus u is just going to be the first component of v, which is 3, plus the first component of u. And you can see, just visually, you can see what's happening here. The second component of v plus u is just the second component of v plus the second component of u, which in our case just becomes 4, 6. So when we add vectors together, we get a new vector. And here we got the vector 4, 6. Okay, so just to save some space, let me erase these steps here. Move this over. Okay, so let's now look at this on a graph. Here is u and v, u and yellow, v and blue. Real quick, because I haven't mentioned this yet, vectors have two things. One is called a tail, it's starting point, and the other is called a head, it's ending point. I mean, they have more than two things, I guess, but they have a head and a tail. So when we add vectors, we line up their tails at a common point. Here we pick the origin just because it's convenient. So we line up their tails at that common point. And then to add them, we just take, we're going along v and then we take u and place its tail to the head of v. So you can see what this corresponds to, this is like going along u plus v. Or sorry, going along v plus u. And now the new vector is just the vector that starts at their common starting point and ends at that addition. Sorry about that. So that new vector is the vector u, I'm sorry, v plus u. And we know it has components four or six. Which makes sense if we think about it, v took us over three in the x direction and u took us over one more, so that would be four. So the new vector v plus u went over four and x and we could do a similar thing to show that it went up six and y. Okay, what else? Well, notice that we could have, if we wanted to, have gone along u first and then added v. And we would have got to the same point, which means we would have gotten the same vector. So u plus v is the same vector as v plus u. Which tells us that vector addition must be commutative. Vector addition must be commutative. And we'll prove that in a few videos from now. We'll prove that vector addition is commutative, but just visually this is kind of a geometric proof that it must be. Okay, that's vector addition. See you in the next video. Can we multiply vectors by numbers? And the answer is yes. So let's just see an example of that. If we want to multiply v by two, so two v. I'll just write it like this, two v. Component wise, this is just two times this vector. Which, we just take that two and we multiply each component by it. So this becomes, I'll write out each step here. This is two times one and then two times two, which of course simplifies to two four. The vector two four. And we call two, this number two, we call it a scalar multiple. And there's a good reason we call it that, because what it does is it scales the vector. And let me show you that. Here is our original vector, just v. Here is two v. It's twice as large. In fact, let me put regular v back. You can see there's v and when we multiply by two, it makes it twice as long. It changes the length by two, by a factor of two. Okay, there's nothing fancy about that. We can also check out what happens when we take v and we multiply by a half. It makes it half as big, half as long. What I really want to talk about is what happens when we take v and we multiply it by negative one. Well, then it flips the direction of v. Now v is going in the opposite direction. And what happens to the components? Well, that's relatively easy to figure out. Oops, I didn't need to erase those. If we take negative one times v, which I'll just abbreviate as negative v. This is negative one times one two, which simply turns out to be negative one, negative two. And it flips the direction of v. And why is that so important? Well, now we can talk about vector subtraction. We have a negative v here, and we know this works because we can multiply by that scalar of negative one. And now we have a way to talk about vector subtraction. So let's go ahead and do that. See you then. Let's take a look at vector subtraction. This is going to work the same way that it works for real numbers. If we want to do something like u minus v, this is really just the same thing as doing u plus negative v. And we know how to multiply v by negative one. That's simple enough. We're going to have u, which is three three, plus a negative four, negative one. Okay, simple enough. We do that addition and we get four, or sorry, three plus negative four is negative one. Three minus one is two. And so this subtraction is just this new vector, negative one, two. Simple enough. So now let's take a look at that on a graph. Here we have v in blue and u in orange. And now we can graph negative v. So it's just v, but pointing in the opposite direction. So there's negative v. And now to do this subtraction, we're really just doing u plus negative v. So we're just going to take the head to tail approach. We go up u and then we add negative v. And we get to this new vector, u minus v. There's our new vector. But notice that vectors, since they're translational, we can move them anywhere in the plane. We can draw u minus v here. And close off that parallelogram. This is the same vector as u minus v over there. So this is still u minus v. We just moved it over. And that's pretty interesting because that tells us that u minus v is the vector that points from the head of v to the head of u. So make sure you see that. Points from the head of v to the head of u. In fact, let me remove that. Maybe you can see it better. Okay, so we're going to use that fact when we prove something about the dot product a few videos from now. See that. Okay, so here we have a vector with three components. And now we can think of these as the x component and the y component just like before. And now we're adding in the z component. And so we have three components. We need to graph this vector in three-dimensional space. So we have these three axes here, the x axes, the y axis, and the z axis. And to graph this, all we need to do is move over one and x and four and y. So that takes us to about this point. And I'm going to draw a line from the origin to that point where we've moved to. So this is one and x, four and y. And then we just need to move up three in the z direction. And that will take us to our vector. So our vector moves one and x, four and y, and three and z. And there it is right there. Now to help with a sense of depth, I find it helpful to dash these lines here. And now that dashed line is like the shadow of v onto the xy plane. And then I also like to dash this line up for height. I just think it gives us a better sense of depth and clarity. Okay, and that's it. There's really nothing more to graphing vectors in three dimensions. I don't think you'll be asked to do that very often. But vectors with three components behave exactly the same as vectors with three components. Everything we learned for vectors with two components applies to vectors with three components, including addition, subtraction, multiplying by scalar, the translational property of vectors, so on and so forth. Okay, see you in the next video. Oh, one thing real quick. If you've never seen three-dimensional axes before, let me just explain that to you. Why they look the way they do. It's as if our whole life when we've been looking at the xy plane, it's as if we've been looking straight down the z axis. Straight down the z axis. So if we had an xy plane, here's x and y, z would be at the origin coming out straight at us. And because it's coming out straight at us, we really, we can't see it. If it were at even a slight angle, we would see it like this. This would be z coming out at us. And that's exactly what we have here. We've just chosen to rotate things. So you could see that the x kind of swings down and y swings down into its place and z rotates up. So things are rotated, but it's really, it should seem familiar in that sense once you realize what's going on. Okay, anyways, I hope that was helpful. I'll see you in the next video. Let's talk about finding the length of a vector that has three components. So here we have the vector v equal to 1, 4, 3. And I want to find its length. In a previous video, we've graphed this vector. And I want to point your attention to the fact that we have a right triangle here. This dashed line and this dashed line form the base and the height of the triangle. And the vector is the hypotenuse. And I'll draw in a little square symbol so maybe you can see it better. There's a triangle there. It's a little bit at an angle to us, but it's definitely a right triangle sitting there. Okay, so knowing that we can just apply the Pythagorean theorem. And the length of v is simply the square root of the base of that triangle squared plus the height of the triangle squared. So now all we have to do is figure out what is the base and what is the height of that triangle. Well the height is easy. The height is how far we go up in z. And we're just going up three units in z. So the height is just simply three. Okay, take care of that. This is b squared plus three squared. Now what about b? Well if you look closely you'll notice that there's another right triangle right here. And that triangle, or what I should say is b is the hypotenuse of this triangle that I've filled in with yellow. In fact let me pull that triangle out. So this is the triangle I'm talking about. b is the hypotenuse. Once again for clarity, this is the triangle that I've pulled out. It's this triangle here. Okay well what are the sides of this triangle? We know that we moved over one there and four here. So we can just apply the Pythagorean theorem again. And we can say that b now is equal to one squared, the square root of one squared plus four squared. That's what b is. Well now that we have a term for b, let's go ahead and plug that in. So we have b which is the square root of one squared plus four squared. And now b is being squared. And then plus three squared. Well something really nice just happened. Look at, we have a square root being squared. And so that square root just simply goes away. So this whole thing simplifies to the square root of one squared plus four squared because that square root went away plus three squared. Now compare that to the components of v. You'll see that the length of v is simply the square root of the sum of the squares of the components. And that's kind of a lot of words to say all at once. But we just take each component, we square it, we add them together and we take the square root. Okay let's do another example. Let's say we have u is equal to, I don't know one, negative six, four. What is the length of u? Well we don't need to go through the whole process that we went through. Just remember, as long as we understand what we did we can just remember that the end result is just going to be, we take each component, we square it, we add them all together and we take the square root. So simply the square root of one squared plus negative six squared plus four squared. And that's it. If you want we can do another example. How about negative three zero nine? So the length of w is equal to, what am I doing? It's equal to the square root of negative three squared plus zero squared plus nine squared. And there you have it. There's the length of a vector with three components. If you're wondering what happens, if you have more than three components, let me show you that quickly. And I might make a separate video about this, but let's say we had something like v is equal to v1, v2, v3, and v4. So now we have four components. The length of v, you might be able to guess what it's going to be, the square root of v1 squared plus v2 squared plus v3 squared plus v4 squared. And if you had five components, you'd do the same thing. You'd just add, tack that fifth one on at the end. If you had six, you would do the same thing, just tack those on. So that's the vector length for vectors with more than two components. Okay, see you in the next video. Okay, here we have three vectors, v, u, and w. And so far we've looked at vectors with two components, and when we were graphing them or thinking about them visually, we thought about them in the plane, in two dimensions. When we had a vector with three components, we graphed this in three dimensions. And in fact, we even labeled this as the x, y, and z component corresponding to the x, y, and z axes. When we go to higher dimensions, dimensions greater than three, so here we have a vector w with n dimensions. Let's say, for example, that n is four. So this vector has four components. Now we don't try and graph this anymore. Anytime a vector has more than three components, we really can't graph it. We can't visualize it. We don't have a good way to graph four or five or six dimensions. But the beauty of linear algebra and the power of linear algebra is the fact that we can take what we know from here and from here, for that matter, and we can push those concepts to higher dimensions to four dimensions, five dimensions, a hundred dimensions, a thousand dimensions. You know, we don't have to graph things, but the tools that we've created will still apply. Okay. So let's talk about some technical details here. One is the fact that vectors are ordered lists of numbers. They're ordered lists of components, right? First, this vector has the component v1 and then it has v2. We already talked about the order, how the order matters. Well, that means that v is what's called a two-tuple. And a tuple is nothing more than an ordered list of elements. v is an ordered list of real numbers, an ordered list of components. So v is a two-tuple. It's a two-tuple because there's two of them. Just like u is a three-tuple, it's an ordered list of three components. And w is an n-tuple. It's an ordered list of n-components. Okay. Now we have the tools for talking about the definition of rn. And rn is really just the set of all n-tuples of real numbers. So, for example, if you have a vector with two components, that is an element of r2. Because r2 is the set of all two-tuples. Well, v is just one of those two-tuples. So v must be in r2. And r2, we can loosely think of it as this plane. I mean, we haven't defined what a dimension is, but we can think of it as the two-dimensional plane. So this is r2. Just like u is an element of r3. r3 is all three-tuples of real numbers. And u just happens to be one of those three-tuples of real numbers. So u is in r3. And r3 we can think of as the three dimensions. And again, we haven't formally defined dimension, but we can think of it like that. w, similar to the rest, is an element of rn. rn is the set of all n-tuples of real numbers. w is an n-tuple of real numbers. So it's in rn. w is an element of rn. Okay, so I know this is a lot all at once, but really what's important here is this notation. To me, that's what's important. This is going to come up all the time. We're going to use it throughout the rest of the course. And if it helps you remember, just remember that the number up here is going to be the same as the number of components. So we can read this if we want. Instead of v is an element of r2, we could just read this as v is a vector with two components. u is a vector with three components. w is a vector with n components. Okay, so I just wanted to lay this out there so that we're all on the same page, and we'll move from here. See you then. Oh, also, we'll expand upon this idea of w, or sorry, of a vector in rn, how we can work with that and abstract some of the ideas that we learned in two and three dimensions. Okay, see you then. Okay, so here we've seen the length of a vector with two components. In fact, we just used the Pythagorean theorem to figure out this length. It's just the square root of the first component squared plus the second component squared. In three dimensions, in a vector with three components, we derived this length using the Pythagorean theorem twice in a row, and you can go back and watch that video if you want, and we found the length of a vector in r3 is just the square root of u1 squared plus u2 squared plus u3 squared. A vector in rn, the length is defined to be as follows. This is just equal to the square root of w1 squared plus w2 squared plus everything in between, so w3 squared plus w4 squared, so on, all the way up till you get to the last component. So it's really you just take each component individually, you square it, you add all those together, and then you take the square root. That's how you find the length of any vector. Okay, just figured I would fill you in on that. See you in the next video. Here we're being asked to prove that vector addition is commutative and associative, so this will be our first proof in the linear algebra course. First of all, let's just define three vectors, u, v, and w are all in rn, so they're three vectors with n components, and let's figure out what we're trying to prove. So we're trying to prove that vector addition is commutative, so u plus v is the same as v plus u, and associative, so u plus v in parentheses plus w is the same as u plus v plus w. Okay, so how are we going to do this? Excuse me. First of all, let's just start with u plus v. So here's u plus v. And what is this equal to? So what's the definition of vector addition? Well, we've already gone over this. It's u1 plus v1 comma u2 plus v2, and that keeps going until you get to the last component, un plus vn, and this is the new vector. This is the vector u plus v. Okay, well, remember, these are real numbers. The components of vectors in rn are real numbers, and so we can use the commutative property of addition of real numbers to switch those around. So this is the same as v1 plus u1 because those are just real numbers, and addition of real numbers is commutative. v2 plus u2, and you keep going until you get to the end, vn plus un. Well, now here, this is the definition of v plus u. That's how we define v plus u. And so we have a simple algebraic proof here that u plus v is equal to v plus u. It's not really formal, there's no formal writings, but I think you can see clearly it's a proof. Okay, how about proving that vector addition is associative? Well, I want you to pause and try that on your own, but the strategy is going to be the same. What we did is we went ahead and used the properties of real numbers, the fact that real numbers are commutative, to prove that vectors are commutative. And we're going to use that same strategy for associative, for the associative property. Okay, pause and try that on your own. Okay, hopefully you're back from pausing the video and trying to prove that vectors are associative. And now let's go through it. So we have u plus v plus w. Well, we know that u plus v is going to be its own vector. It's going to be the vector u1 plus v1. And I'm just going to leave off the second component. We all, you've seen it enough times. We know what's happening. Down to u n plus v n. So that's this whole vector here. We can think of u plus v as its own new vector, plus w. And again, I'm going to leave off the second one and just write it like that. Okay, well, now we're just adding two vectors together. And we know how to do that. We take the first component of the first vector, which is u1 plus v1. That's the first component of that vector. And then we add the first component of the other vector, which is just w1. And we do that for each component, each of the components, until we get to u n plus v n plus w n. Okay, and now, again, we have real numbers here and real numbers are associative. Addition of real numbers is associative. And so we're just going to use that property of real numbers. So this is the same thing as u1 plus v1 plus w1. Remember, these components are just real numbers, so the associative property of addition holds. Okay, and we'll do that all the way through all of these components. And we're almost done. And now we can break this up into the vector u. u1 all the way to u n plus the vector v1 plus w1 all the way to the end, the n plus w n. And this, of course, is just u plus v plus w. And so we've proved that vector addition is associative. So again, it's a really simple method. All we're doing is a really simple process. That's the word I was looking for. All we're doing is taking the vectors, breaking them down into their components. And since the components are real numbers, we can use the properties of real numbers on the component level. And then we're kind of pulling things back out into vectors. Okay, I hope this was helpful. We'll see the rest of the properties of vectors in the next video. See you then. Okay, here are some of the algebraic properties of vectors. I encourage you to try and prove all of these. We just proved that vector addition is commutative, so that's number one here. We just proved that in the last video. Very similarly to the way we proved that, you could prove all of these if you know properties of real numbers. You know addition for real numbers is associative, and that's what we have here in step number two, so you probably can prove that pretty easily. When you add a real number to zero, you get that real number back. So you can go through all of these pretty easily. And like I said, just use the properties of real numbers that you know. One interesting thing here is we have this thing called the zero vector. And the zero vector is a little bit different than zero. It's a vector whose components are all zero. And that distinction is somewhat important because we can't add just a regular number zero to a vector. We have to add a vector to a vector. So when we do this addition, we need this to be a zero vector, so we can add each of the components together. But okay, so this is just for reference. You can view it at any time. I hope they'll have a reference sheet on the website that you can look at and print off. So we can use these from now on with vectors. See you in the next video. So if you've been following along so far, you may have noticed that we haven't talked about multiplying two vectors. And that's because there's a couple different ways to multiply vectors or to define a product of vectors. And one really interesting and useful one is called the dot product. So when you see this dot here that indicates the dot product, and the way the dot product is defined is maybe somewhat surprising. The way that we do this is we do u1 times v1 plus u2 times v2. Plus u3 times v3, so on and so on. All the way until we get to the end, un plus un times vn. Why is that surprising? Why is that a surprising way to define a product of two vectors? Well, look at the result. What kind of object is this? It's a number. These two things are numbers. When we multiply them, we just get a real number plus another real number. All the way across. When we add all these up, that's just a single number. So you multiply two vectors and you just get a number out. So you don't even get a vector back when you multiply two vectors with a dot product. So this is sometimes called the scalar product for that reason that the result is a scalar. It's a real number, a constant. Those are all different ways of saying the same thing. So for slightly different notation and maybe a little bit more concise notation, is we could use summation notation or sigma notation and just write this like this. So we sum up all the components from one to n, the products of those components. So if you're comfortable and familiar with sigma notation, this is one way to write it. I personally actually prefer this way up here because it's a little bit more informative, I think. It's a little bit easier to see just right away without interpreting the sigma notation. Anyways, that's that. Let's do an example. So if we have u is equal to 1, negative 2, and 5, and v is equal to 4, 3, and 1. So what is this dot product? Well, we just do exactly what it says. 1 times 4 plus negative 2 times 3 plus 5 times 1. So we get 4 minus 6 plus 5. That looks like 3 to me. So maybe what I should have written was this is u minus v, or sorry, u dot v. u dot v is equal to this. We're taking u1 times v1 plus u2 times v2 plus u3 times vt, v3. And then we're just simplifying the numbers and it comes out to 3. So this maybe seems a little bit bizarre, but we'll see in the coming videos why this dot product is really useful. See you then. Let's look at some interesting consequences of the dot product. And the first one that I want to look at is the consequence it has for the definition of the length of a vector. It turns out that because the way the dot product is defined, we can think of the length of the vector as the square root of the vector dotted with itself. And why does that make any sense? Well, if we think about what this is equal to, this dot product here is just u1 times u1, which is u1 squared, plus u2 times u2, which is u2 squared, plus all the way up to un times un, so un squared. So that just comes from the definition of a dot product. We take each of the components, we multiply them together, and we add them up. And we already said that this is how we are going to define the length of a vector. Remember, we did this in two dimensions where we used the Pythagorean theorem to find the length of a vector. In more dimensions, we just keep adding the squares of the components. If we have any more components we have, we square them and we add them underneath the square root. So that's the length of a vector, and so it makes sense that the square root of u dot u is the length of the vector. Also notice that, you know, this is a pretty natural follow up, but the length of a vector squared, that means, is equal to the vector dotted with itself. So we just squared both sides of this. Okay, that's pretty cool. What else? Well, the more interesting thing that happens is it has to do with the angle between two vectors. So let's say this is u, and this is v, and this is theta. Well, what if we did u minus v? We already talked about what u minus v is. It's the vector that points from v to u. Now, we've drawn a triangle here. What we can do is we can use the law of cosines to help us figure out this angle in here, or to help us figure out this side, u minus v. So the law of cosines tells us that the length of the side we're trying to find, u minus v, so this is going all the way back to your geometry class, and you can look up the law of cosines if you don't remember it, but that length squared is equal to the length of one of the sides, that's u, the length of u squared plus the length of v squared minus the length of u times the length of v. So I know that these length symbols get really tedious, but I'm just going to keep going with them here. So minus the length of u times the length of v times the cosine of the angle between them. So this comes from the law of cosines. It's really just saying c squared is equal to a squared plus b squared minus ab cos theta. You might remember it better that way, but that's what we have. We have a side u minus v and a side u and a side v. So what we're going to do now is we're going to examine this side. So let's pull that side out and look at it separately. So we have the length of u minus v squared, well that's just u minus v dotted with u minus v, so let's do that. u minus v dotted with itself. And now there's some properties of dot products that I haven't told you about that are going to become useful here, like commutativity, but we'll see that in action. So u dot u, well we just talked about that, that's the length of u squared, so let's write that as that. u dot u is the length of u squared. And then we have u dot, oh I have dot products in there, sorry that's a mistake, this should be u minus v, u minus v. So u dotted with minus v, that's minus, so let me write that on the side, minus u v, well minus u dot v. And then we have minus v dot u, so that's minus v dot u, but like I just said the dot product is commutative, so this becomes, when we add those two together we just get minus two u dot v. So I hope that was relatively clear. We're just foiling this out with the dot product. So based on what we just talked about that's minus two times u dot v. So just to be explicit, really explicit here, that was this u coming over here and this v coming this way. So I had to pause the video because my phone was ringing, but yeah like I was saying this, u comes and multiplies that v, this v comes and multiplies that u, so we get minus two u dot v. And then finally the v dotted with itself, well it's both negative so that's going to be plus the length of v squared. This is just v dot v, turns out to be. So this is what the left hand side of the equation becomes. So why don't we substitute that into this, the law of cosines essentially, what we have. So this is u squared, the length of u squared, minus two u dot v, plus the length of v squared, is equal to the length of u squared. So this is now the right hand side of the equation from up there, plus the length of v squared, minus the length of u times the length of v times the cosine of the angle between them. Okay so now we get to do a lot of canceling here, so let's see. This and this are going to go away, we can subtract those from both sides, those are going to go away. Oh jeez I did something terribly wrong here. This is not the law of cosines, we need a minus two. That means we need a minus two down here. And then we can divide the minus two on both sides though, so that's pretty cool. So sorry for forgetting that for the whole video. And what do we end up with after we do all that crazy cancellation? Well we just end up with u dot v on this side is equal to the length of u times the length of v times the cosine of the angle between them. And now that is really cool because as long as we're given the vectors u and v, we could figure out what u dot v is based on the definition, sum up the products of the components, and then we can figure out the lengths, we know how to do that, we just take the square root of the sum of the square of the components, and then we have this cosine of theta so we can solve for theta, and we can figure out the angle between two vectors just knowing what the two vectors are. So that's really cool. So in fact, remember that this proof came from the law of cosines which only really works in two dimensions, we're talking about a triangle. So when we go to higher dimensions we take it as a definition that the cosine of theta is equal to u dot v divided by the length of u times the length of v. So that just comes because we just divided by length of u, length of v. So notice two things happen here. One, we have an alternate definition for the dot product or an alternate way to express the dot product. And also now we have a way to express the angle between two vectors in terms of the dot product. And that's really cool. So I hope this helps. I'll see you in the next video. Let's use what we know about the dot product to find the angle between these two vectors. So what we're going to do is remember our little formula which says that the cosine of the angle between two vectors is equal to u dot v divided by the length of u times the length of v. So if we want to find the angle between two vectors we have to do just a few computations. We have to find the dot product and then we have to find the length of each vector. So let's go through that. So the dot product of u and v, so u dot v, u dot v is equal to two times one, that's two, plus one times one, that's one, plus negative two times one, that's just negative two or minus two. So this comes out to be one. So the dot product is one, let's do the length of u now in the length of v. So the length of u is equal to the square root of two squared plus one squared plus negative two squared. So two squared is four, plus one squared is one, plus negative two squared is four, so plus four. So this is the square root of nine if we add those together and the square root of nine is just three. And now let's do the length of v. So all we're doing is just doing the necessary computations based on this formula and we derived this formula in the last video. So if you're curious about that go back and watch that. So now we have one squared, well that's just one, plus one squared, well that's one, plus one squared, that's one. So this is the square root of three. So we have our necessary pieces here, so let's put them all together. So we have the cosine of the angle between the two vectors is equal to the dot product of the two vectors, which we found was equal to one, divided by the length of u, that's three times the length of v, that's the square root of three. So this is the cosine of the angle, so to find the angle theta is just equal to the arc cos or the inverse cos of one divided by three times the square root of three. And now to find this we would have to use a calculator or a table of values. And so I'll spare us the pain, but you should maybe do that on your calculator just to make sure you get the right answer. And this comes out to 1.37 radians, or I should write this is approximately equal, rounding a little bit or truncating. So this is approximately equal to 1.37 radians, and if your calculator is in degree mode, then that's approximately 78.9 degrees. Okay, so nothing too terribly difficult. We just got to compute the dot product, compute the length of the vectors, and everything falls into place. Okay, see you in the next video. In the last video we learned the definition of the cosine between two vectors. In fact, we pretty much derived this, so we said the cosine of the angle between two vectors is u dot v divided by the length of u times the length of v. So let's see what we can determine about two vectors when they're perpendicular. So if two vectors are perpendicular, what we say is they're orthogonal. So that's the word we use for perpendicular vectors. And let's see what we can determine. So u and v here. So this angle, of course, is pi over 2, or 90 degrees. And what does that mean? Well, by our definition of the angle between two vectors, that means that the cosine of pi over 2 is equal to this dot product. And while I'm writing this, think about what is the cosine of pi over 2? What is that equal to? We know what it is, it's just a number, right? Well, the cosine of pi over 2 is zero. So all three of these things are equal, and they're all equal to zero. Excuse me. So what does that tell us? Well, that tells us that u dot v must be equal to zero. So this implies that u dot v is equal to zero. And that's because the denominator here will never make this fraction zero. Okay, so if the vectors are orthogonal, then the dot product is zero. And in fact, that works in the other direction. If the dot product is zero, the vectors are orthogonal. So now we have a definition of orthogonal. Two vectors are orthogonal. So two, well, let me write this, two vectors u and v are orthogonal if and only if. If you've never seen this before, this is shorthand notation for if and only if. Two vectors are u and v are orthogonal if and only if u dot v is equal to zero. So now we have a nice, easy way to test if two vectors are orthogonal. So let's take a look at that. So let's take some two easy vectors with just two components and see what happens. So let's say u is equal to negative three, four, and v is equal to four, three. So let's do their dot product really quickly. u dot v is equal to negative three times four, negative three times four, plus four times three. Well, it's pretty clear this is negative 12 plus 12, so that's zero. So by definition, these two vectors are orthogonal. So let's take a look at what they look like if we were to graph them. So u is negative three, so go over three up four, negative three four, so it's kind of a rough sketch. And then v is positive four and up three, so about there. And even though this is just a rough sketch, it seems pretty reasonable that these two vectors are orthogonal. That looks to be about 90 degrees in there. And we know for certain, because this dot product is zero, we know for certain that they are orthogonal. And just by the sketch, they, you know, that kind of confirms in our mind if we had any doubt that they are indeed orthogonal. Okay, so this is the definition of orthogonal. I'll see you in the next video. Okay, here we have a proof to do, we need to prove that the diagonals of a parallelogram are perpendicular if and only if the length of their sides are equal. Okay, so the first thing that I want to do is just get some intuition about what we're actually trying to prove and write a mathematical statement of what we're trying to prove. So kind of convert these words into math. The first thing I'm going to do is just draw a parallelogram to see what's going on. So here are two vectors, u and v, and we know we can make a parallelogram out of them. So here's, well, let me switch to a thinner brush. So here's u and here is v. And we know we can make a parallelogram out of them, so let's do that. Oh, and I should tell you that I made these vectors exactly equal in length because it says that we want them to be equal in length, so I wanted to see what was going on with that. And now we know how to create the diagonals, right? If we do head-to-tail addition, we can get this main diagonal and we know that that's u plus v. And then how do we get the other diagonal? Well, the other diagonal is just u minus v, so that is here, u minus v. We talked about that in vector subtraction. The vector pointing from the head of one vector to the head of the other is vector subtraction, essentially. Okay, so we have our two diagonals. Let's see if we can convert this statement into some math. So what we're trying to prove is that the diagonals, u plus v, are perpendicular, right? U plus v and u minus v, we're trying to prove that these are perpendicular. So we could say that their dot product is zero, so the diagonals are perpendicular. That's this statement, the diagonals are perpendicular. If and only if the length of their sides are equal. So this is length of u is equal to length of v. Okay, so now we have a proof and we need to go in both directions. So let's go forward first. Let's say assume that the dot product is zero. So assume that the diagonals are perpendicular or orthogonal. We're going to assume this and now we need to prove that the lengths are equal. Okay, well let's just see what happens through this equation if we expand it out. So that equation implies what is the dot product expanded here? So we're going to have u dot u, which we know is the length of u squared, minus u dot v plus v dot u. And then we're going to get minus the length of v squared because this is just minus v dot v. Okay, the dot product is commutative and so u dot v is the same thing as v dot u. So we have a minus v dot u dot v here and a plus u dot v, so those are going to cancel out. Oh, and I kind of made a mistake here, sorry about that. This is an implication. The fact that this is equal to zero implies that this statement is equal to zero because all we did was expand it out, which in turn, let me switch colors here, well maybe not, maybe I'll leave it where it was, which in turn implies that the length of u squared minus the length of v squared, oops I forgot my vector there, is equal to zero, which again implies that the length of u squared is equal to the length of v squared. Well, length of vectors are always positive and so we could take the square root and not really worry about messing up this equality because we're not going to need the negative part of the square root because we know both of these lengths are positive. So we take the square root of both sides and we get exactly what we wanted, that the length of u is equal to the length of v. Okay, so we proved that if the vectors, if the diagonals are perpendicular, then their lengths must be equal. Let's go ahead and prove that if the lengths are equal then the vectors must be perpendicular. So I'm just going to write this kind of backwards implies arrow just to indicate we're doing the other part of the proof now. So we're going to assume that the lengths are equal and what we want to get to is that the vectors are perpendicular, or the diagonals are perpendicular. So we're going to assume this. Now this doesn't seem, it seems like well where do we go from here? How do we construct a proof out of just this equality? Well what I would do is I would say, okay, consider the dot product of u plus v dotted with u minus v. So the dot product of the diagonals. Now we're not going to say that this is equal to zero, we can't do that. That's what we're trying to prove but we can just see what comes out when we take this dot product. We know that this dot product exists, we have two vectors, we can take their dot products. Okay, so let's do that. Well this is equal to, that dot product is equal to, well we already did this. It was the length of u squared minus the u dot v plus u dot v. I just commuted there, it would be v dot u but I just commuted the two vectors. And then minus the length of v squared. And this is equal to the length of u squared minus the length of v squared. Since u is equal to v we can substitute one and for the other and we know of course that this is equal to zero. So we took the dot product and we found out that yes the dot product is equal to zero. So that's it, we're done with our proof. We've proved that if the lengths are equal the dot product is zero. We've proved that if the dot product is zero then the lengths are equal. And again just one more time, when I say that the dot product is zero what I'm implying by definition is that these two vectors are perpendicular. And of course from the beginning of the video those two vectors represent the diagonals. Okay, so that's somewhat of an interesting proof. The diagonals of a parallelogram are only perpendicular if and only if the lengths of the sides are equal. Okay, see you in the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.0, "text": " Let's start by asking the most basic question, what is a vector?", "tokens": [50364, 961, 311, 722, 538, 3365, 264, 881, 3875, 1168, 11, 437, 307, 257, 8062, 30, 50664], "temperature": 0.0, "avg_logprob": -0.18285093988691056, "compression_ratio": 1.3630573248407643, "no_speech_prob": 0.026317903771996498}, {"id": 1, "seek": 0, "start": 6.0, "end": 12.0, "text": " And a vector is really just two pieces of information.", "tokens": [50664, 400, 257, 8062, 307, 534, 445, 732, 3755, 295, 1589, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18285093988691056, "compression_ratio": 1.3630573248407643, "no_speech_prob": 0.026317903771996498}, {"id": 2, "seek": 0, "start": 12.0, "end": 19.0, "text": " Direction and length, or what's also called magnitude.", "tokens": [50964, 5822, 882, 293, 4641, 11, 420, 437, 311, 611, 1219, 15668, 13, 51314], "temperature": 0.0, "avg_logprob": -0.18285093988691056, "compression_ratio": 1.3630573248407643, "no_speech_prob": 0.026317903771996498}, {"id": 3, "seek": 0, "start": 19.0, "end": 24.0, "text": " Two different words for the same thing.", "tokens": [51314, 4453, 819, 2283, 337, 264, 912, 551, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18285093988691056, "compression_ratio": 1.3630573248407643, "no_speech_prob": 0.026317903771996498}, {"id": 4, "seek": 2400, "start": 24.0, "end": 30.0, "text": " Now length is a very physical visual concept, right?", "tokens": [50364, 823, 4641, 307, 257, 588, 4001, 5056, 3410, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.0966635178296994, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0049780127592384815}, {"id": 5, "seek": 2400, "start": 30.0, "end": 33.0, "text": " It's something we can see, it's something we can measure.", "tokens": [50664, 467, 311, 746, 321, 393, 536, 11, 309, 311, 746, 321, 393, 3481, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0966635178296994, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0049780127592384815}, {"id": 6, "seek": 2400, "start": 33.0, "end": 40.0, "text": " And the same with direction, it's our orientation, it's a very visual thing.", "tokens": [50814, 400, 264, 912, 365, 3513, 11, 309, 311, 527, 14764, 11, 309, 311, 257, 588, 5056, 551, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0966635178296994, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0049780127592384815}, {"id": 7, "seek": 2400, "start": 40.0, "end": 46.0, "text": " So vectors to begin with most intuitively fit on a graph.", "tokens": [51164, 407, 18875, 281, 1841, 365, 881, 46506, 3318, 322, 257, 4295, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0966635178296994, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0049780127592384815}, {"id": 8, "seek": 2400, "start": 46.0, "end": 51.0, "text": " They fit in a place where we can visualize them.", "tokens": [51464, 814, 3318, 294, 257, 1081, 689, 321, 393, 23273, 552, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0966635178296994, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0049780127592384815}, {"id": 9, "seek": 5100, "start": 51.0, "end": 58.0, "text": " And so how could we attempt to capture direction and length?", "tokens": [50364, 400, 370, 577, 727, 321, 5217, 281, 7983, 3513, 293, 4641, 30, 50714], "temperature": 0.0, "avg_logprob": -0.11840377619237076, "compression_ratio": 1.585, "no_speech_prob": 0.0004802455077879131}, {"id": 10, "seek": 5100, "start": 58.0, "end": 64.0, "text": " Well you know, I think an arrow does a pretty good job.", "tokens": [50714, 1042, 291, 458, 11, 286, 519, 364, 11610, 775, 257, 1238, 665, 1691, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11840377619237076, "compression_ratio": 1.585, "no_speech_prob": 0.0004802455077879131}, {"id": 11, "seek": 5100, "start": 64.0, "end": 69.0, "text": " This for instance, for instance, captures direction, it's moving in the northeast direction,", "tokens": [51014, 639, 337, 5197, 11, 337, 5197, 11, 27986, 3513, 11, 309, 311, 2684, 294, 264, 40984, 3513, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11840377619237076, "compression_ratio": 1.585, "no_speech_prob": 0.0004802455077879131}, {"id": 12, "seek": 5100, "start": 69.0, "end": 74.0, "text": " and it also clearly has a certain length.", "tokens": [51264, 293, 309, 611, 4448, 575, 257, 1629, 4641, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11840377619237076, "compression_ratio": 1.585, "no_speech_prob": 0.0004802455077879131}, {"id": 13, "seek": 5100, "start": 74.0, "end": 79.0, "text": " And so this is a vector, and that's exactly how we graph vectors.", "tokens": [51514, 400, 370, 341, 307, 257, 8062, 11, 293, 300, 311, 2293, 577, 321, 4295, 18875, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11840377619237076, "compression_ratio": 1.585, "no_speech_prob": 0.0004802455077879131}, {"id": 14, "seek": 7900, "start": 79.0, "end": 83.0, "text": " Just as arrows.", "tokens": [50364, 1449, 382, 19669, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 15, "seek": 7900, "start": 83.0, "end": 91.0, "text": " This is also a vector, it's pointing in a certain direction, it has a certain length, as is this.", "tokens": [50564, 639, 307, 611, 257, 8062, 11, 309, 311, 12166, 294, 257, 1629, 3513, 11, 309, 575, 257, 1629, 4641, 11, 382, 307, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 16, "seek": 7900, "start": 91.0, "end": 95.0, "text": " So is this, this is a vector.", "tokens": [50964, 407, 307, 341, 11, 341, 307, 257, 8062, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 17, "seek": 7900, "start": 95.0, "end": 99.0, "text": " Even though it doesn't start at the origin, it's clearly pointing in a certain direction,", "tokens": [51164, 2754, 1673, 309, 1177, 380, 722, 412, 264, 4957, 11, 309, 311, 4448, 12166, 294, 257, 1629, 3513, 11, 51364], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 18, "seek": 7900, "start": 99.0, "end": 103.0, "text": " so it has direction, and it clearly also has length.", "tokens": [51364, 370, 309, 575, 3513, 11, 293, 309, 4448, 611, 575, 4641, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 19, "seek": 7900, "start": 103.0, "end": 108.0, "text": " So vectors need not start at the origin, they can start anywhere.", "tokens": [51564, 407, 18875, 643, 406, 722, 412, 264, 4957, 11, 436, 393, 722, 4992, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06096536914507548, "compression_ratio": 1.9234972677595628, "no_speech_prob": 0.00043729000026360154}, {"id": 20, "seek": 10800, "start": 108.0, "end": 115.0, "text": " This is also a vector, it's pointing in a certain direction, and it has a certain length.", "tokens": [50364, 639, 307, 611, 257, 8062, 11, 309, 311, 12166, 294, 257, 1629, 3513, 11, 293, 309, 575, 257, 1629, 4641, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08652994070160255, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0008829959551803768}, {"id": 21, "seek": 10800, "start": 115.0, "end": 118.0, "text": " Okay, that's great.", "tokens": [50714, 1033, 11, 300, 311, 869, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08652994070160255, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0008829959551803768}, {"id": 22, "seek": 10800, "start": 118.0, "end": 123.0, "text": " Now let's look at a specific example.", "tokens": [50864, 823, 718, 311, 574, 412, 257, 2685, 1365, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08652994070160255, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0008829959551803768}, {"id": 23, "seek": 10800, "start": 123.0, "end": 130.0, "text": " Here is a vector, and I want to first of all name that vector.", "tokens": [51114, 1692, 307, 257, 8062, 11, 293, 286, 528, 281, 700, 295, 439, 1315, 300, 8062, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08652994070160255, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0008829959551803768}, {"id": 24, "seek": 10800, "start": 130.0, "end": 136.0, "text": " So I'm just going to call it V, and I'm going to put a little arrow over the top of it,", "tokens": [51464, 407, 286, 478, 445, 516, 281, 818, 309, 691, 11, 293, 286, 478, 516, 281, 829, 257, 707, 11610, 670, 264, 1192, 295, 309, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08652994070160255, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0008829959551803768}, {"id": 25, "seek": 13600, "start": 136.0, "end": 140.0, "text": " to make sure that we know that this is a vector.", "tokens": [50364, 281, 652, 988, 300, 321, 458, 300, 341, 307, 257, 8062, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07656895970723715, "compression_ratio": 1.76, "no_speech_prob": 0.0031723000574856997}, {"id": 26, "seek": 13600, "start": 140.0, "end": 150.0, "text": " So the vector V, and now I want to capture this information.", "tokens": [50564, 407, 264, 8062, 691, 11, 293, 586, 286, 528, 281, 7983, 341, 1589, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07656895970723715, "compression_ratio": 1.76, "no_speech_prob": 0.0031723000574856997}, {"id": 27, "seek": 13600, "start": 150.0, "end": 157.0, "text": " I want to capture the information that arrow is telling us, without needing to draw it.", "tokens": [51064, 286, 528, 281, 7983, 264, 1589, 300, 11610, 307, 3585, 505, 11, 1553, 18006, 281, 2642, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07656895970723715, "compression_ratio": 1.76, "no_speech_prob": 0.0031723000574856997}, {"id": 28, "seek": 13600, "start": 157.0, "end": 164.0, "text": " So I'm not going to write this like this, I'm not going to say V is equal to this arrow, that's too ambiguous.", "tokens": [51414, 407, 286, 478, 406, 516, 281, 2464, 341, 411, 341, 11, 286, 478, 406, 516, 281, 584, 691, 307, 2681, 281, 341, 11610, 11, 300, 311, 886, 39465, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07656895970723715, "compression_ratio": 1.76, "no_speech_prob": 0.0031723000574856997}, {"id": 29, "seek": 16400, "start": 164.0, "end": 172.0, "text": " I need something more definite, something with more structure.", "tokens": [50364, 286, 643, 746, 544, 25131, 11, 746, 365, 544, 3877, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07319011995869298, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.0015486745396628976}, {"id": 30, "seek": 16400, "start": 172.0, "end": 179.0, "text": " Well, this vector moves over a certain amount in the x direction.", "tokens": [50764, 1042, 11, 341, 8062, 6067, 670, 257, 1629, 2372, 294, 264, 2031, 3513, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07319011995869298, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.0015486745396628976}, {"id": 31, "seek": 16400, "start": 179.0, "end": 184.0, "text": " Let's say for example, it moves over 3 in the x direction.", "tokens": [51114, 961, 311, 584, 337, 1365, 11, 309, 6067, 670, 805, 294, 264, 2031, 3513, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07319011995869298, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.0015486745396628976}, {"id": 32, "seek": 16400, "start": 184.0, "end": 191.0, "text": " It also moves a certain amount up in the y direction.", "tokens": [51364, 467, 611, 6067, 257, 1629, 2372, 493, 294, 264, 288, 3513, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07319011995869298, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.0015486745396628976}, {"id": 33, "seek": 19100, "start": 191.0, "end": 196.0, "text": " Let's say for example, it moves up 1.", "tokens": [50364, 961, 311, 584, 337, 1365, 11, 309, 6067, 493, 502, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09323538929583078, "compression_ratio": 1.69375, "no_speech_prob": 0.0008295662701129913}, {"id": 34, "seek": 19100, "start": 196.0, "end": 202.0, "text": " Well now I can say that this vector is equal to its components.", "tokens": [50614, 1042, 586, 286, 393, 584, 300, 341, 8062, 307, 2681, 281, 1080, 6677, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09323538929583078, "compression_ratio": 1.69375, "no_speech_prob": 0.0008295662701129913}, {"id": 35, "seek": 19100, "start": 202.0, "end": 205.0, "text": " So that's a new word for us.", "tokens": [50914, 407, 300, 311, 257, 777, 1349, 337, 505, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09323538929583078, "compression_ratio": 1.69375, "no_speech_prob": 0.0008295662701129913}, {"id": 36, "seek": 19100, "start": 205.0, "end": 220.0, "text": " It's equal to its x component, which is 3, how much it moves over in x, and its y component, which is 1, which is how much it moves up in y.", "tokens": [51064, 467, 311, 2681, 281, 1080, 2031, 6542, 11, 597, 307, 805, 11, 577, 709, 309, 6067, 670, 294, 2031, 11, 293, 1080, 288, 6542, 11, 597, 307, 502, 11, 597, 307, 577, 709, 309, 6067, 493, 294, 288, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09323538929583078, "compression_ratio": 1.69375, "no_speech_prob": 0.0008295662701129913}, {"id": 37, "seek": 22000, "start": 220.0, "end": 238.0, "text": " So again, this is the x component and the y component.", "tokens": [50364, 407, 797, 11, 341, 307, 264, 2031, 6542, 293, 264, 288, 6542, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12071609497070312, "compression_ratio": 1.359375, "no_speech_prob": 0.0028006986249238253}, {"id": 38, "seek": 22000, "start": 238.0, "end": 246.0, "text": " And now anyone in the world looking at this vector, V equal to 3, 1, can go ahead and draw that vector if they want to.", "tokens": [51264, 400, 586, 2878, 294, 264, 1002, 1237, 412, 341, 8062, 11, 691, 2681, 281, 805, 11, 502, 11, 393, 352, 2286, 293, 2642, 300, 8062, 498, 436, 528, 281, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12071609497070312, "compression_ratio": 1.359375, "no_speech_prob": 0.0028006986249238253}, {"id": 39, "seek": 24600, "start": 246.0, "end": 253.0, "text": " They know exactly which vector we're talking about when we write that.", "tokens": [50364, 814, 458, 2293, 597, 8062, 321, 434, 1417, 466, 562, 321, 2464, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07512901811038747, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.07691492885351181}, {"id": 40, "seek": 24600, "start": 253.0, "end": 264.0, "text": " Just a bit of notation here, this is also written as a column.", "tokens": [50714, 1449, 257, 857, 295, 24657, 510, 11, 341, 307, 611, 3720, 382, 257, 7738, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07512901811038747, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.07691492885351181}, {"id": 41, "seek": 24600, "start": 264.0, "end": 268.0, "text": " And it's the exact same information, it's just vertical now.", "tokens": [51264, 400, 309, 311, 264, 1900, 912, 1589, 11, 309, 311, 445, 9429, 586, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07512901811038747, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.07691492885351181}, {"id": 42, "seek": 26800, "start": 268.0, "end": 277.0, "text": " And again, this is still the x component and still the y component.", "tokens": [50364, 400, 797, 11, 341, 307, 920, 264, 2031, 6542, 293, 920, 264, 288, 6542, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1368961984461004, "compression_ratio": 1.4019607843137254, "no_speech_prob": 0.19665424525737762}, {"id": 43, "seek": 26800, "start": 277.0, "end": 279.0, "text": " Okay, let's look at another example.", "tokens": [50814, 1033, 11, 718, 311, 574, 412, 1071, 1365, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1368961984461004, "compression_ratio": 1.4019607843137254, "no_speech_prob": 0.19665424525737762}, {"id": 44, "seek": 26800, "start": 279.0, "end": 287.0, "text": " Let's look at, let's say the vector u.", "tokens": [50914, 961, 311, 574, 412, 11, 718, 311, 584, 264, 8062, 344, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1368961984461004, "compression_ratio": 1.4019607843137254, "no_speech_prob": 0.19665424525737762}, {"id": 45, "seek": 28700, "start": 287.0, "end": 298.0, "text": " And let's say it has the components negative 2, 3.", "tokens": [50364, 400, 718, 311, 584, 309, 575, 264, 6677, 3671, 568, 11, 805, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08156285210261269, "compression_ratio": 1.4503311258278146, "no_speech_prob": 0.02975444681942463}, {"id": 46, "seek": 28700, "start": 298.0, "end": 303.0, "text": " Well that simply means we're moving over negative 2 in x and up 3 in y.", "tokens": [50914, 1042, 300, 2935, 1355, 321, 434, 2684, 670, 3671, 568, 294, 2031, 293, 493, 805, 294, 288, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08156285210261269, "compression_ratio": 1.4503311258278146, "no_speech_prob": 0.02975444681942463}, {"id": 47, "seek": 28700, "start": 303.0, "end": 308.0, "text": " So maybe something right around here.", "tokens": [51164, 407, 1310, 746, 558, 926, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08156285210261269, "compression_ratio": 1.4503311258278146, "no_speech_prob": 0.02975444681942463}, {"id": 48, "seek": 28700, "start": 308.0, "end": 313.0, "text": " So this would be 3 in y and negative 2 in the x direction.", "tokens": [51414, 407, 341, 576, 312, 805, 294, 288, 293, 3671, 568, 294, 264, 2031, 3513, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08156285210261269, "compression_ratio": 1.4503311258278146, "no_speech_prob": 0.02975444681942463}, {"id": 49, "seek": 31300, "start": 313.0, "end": 321.0, "text": " And there's our vector.", "tokens": [50364, 400, 456, 311, 527, 8062, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08669138536220644, "compression_ratio": 1.190909090909091, "no_speech_prob": 0.025175750255584717}, {"id": 50, "seek": 31300, "start": 321.0, "end": 324.0, "text": " Nothing to it.", "tokens": [50764, 6693, 281, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08669138536220644, "compression_ratio": 1.190909090909091, "no_speech_prob": 0.025175750255584717}, {"id": 51, "seek": 31300, "start": 324.0, "end": 340.0, "text": " And of course we could have written this as a column vector, negative 2, 3, if we wanted to.", "tokens": [50914, 400, 295, 1164, 321, 727, 362, 3720, 341, 382, 257, 7738, 8062, 11, 3671, 568, 11, 805, 11, 498, 321, 1415, 281, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08669138536220644, "compression_ratio": 1.190909090909091, "no_speech_prob": 0.025175750255584717}, {"id": 52, "seek": 34000, "start": 340.0, "end": 346.0, "text": " Okay, so we have that down.", "tokens": [50364, 1033, 11, 370, 321, 362, 300, 760, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11907251358032227, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.005219656974077225}, {"id": 53, "seek": 34000, "start": 346.0, "end": 354.0, "text": " But what about direction and length?", "tokens": [50664, 583, 437, 466, 3513, 293, 4641, 30, 51064], "temperature": 0.0, "avg_logprob": -0.11907251358032227, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.005219656974077225}, {"id": 54, "seek": 34000, "start": 354.0, "end": 357.0, "text": " Does this capture direction and length?", "tokens": [51064, 4402, 341, 7983, 3513, 293, 4641, 30, 51214], "temperature": 0.0, "avg_logprob": -0.11907251358032227, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.005219656974077225}, {"id": 55, "seek": 34000, "start": 357.0, "end": 364.0, "text": " These just have, just using two components, how does that tell us direction and length?", "tokens": [51214, 1981, 445, 362, 11, 445, 1228, 732, 6677, 11, 577, 775, 300, 980, 505, 3513, 293, 4641, 30, 51564], "temperature": 0.0, "avg_logprob": -0.11907251358032227, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.005219656974077225}, {"id": 56, "seek": 36400, "start": 364.0, "end": 370.0, "text": " Well it tells us direction because this is the vector that moves over 3 in x and up 1 in y.", "tokens": [50364, 1042, 309, 5112, 505, 3513, 570, 341, 307, 264, 8062, 300, 6067, 670, 805, 294, 2031, 293, 493, 502, 294, 288, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 57, "seek": 36400, "start": 370.0, "end": 373.0, "text": " That's its direction, over 3 up 1.", "tokens": [50664, 663, 311, 1080, 3513, 11, 670, 805, 493, 502, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 58, "seek": 36400, "start": 373.0, "end": 375.0, "text": " It points in that direction.", "tokens": [50814, 467, 2793, 294, 300, 3513, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 59, "seek": 36400, "start": 375.0, "end": 378.0, "text": " But what about length?", "tokens": [50914, 583, 437, 466, 4641, 30, 51064], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 60, "seek": 36400, "start": 378.0, "end": 381.0, "text": " Well that's what we're going to talk about in the next video.", "tokens": [51064, 1042, 300, 311, 437, 321, 434, 516, 281, 751, 466, 294, 264, 958, 960, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 61, "seek": 36400, "start": 381.0, "end": 385.0, "text": " But I'll give you a clue.", "tokens": [51214, 583, 286, 603, 976, 291, 257, 13602, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 62, "seek": 36400, "start": 385.0, "end": 390.0, "text": " We've formed a right triangle here.", "tokens": [51414, 492, 600, 8693, 257, 558, 13369, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07468765576680501, "compression_ratio": 1.532994923857868, "no_speech_prob": 0.0012447877088561654}, {"id": 63, "seek": 39000, "start": 390.0, "end": 397.0, "text": " The components tell us the length of the base and the length of the height of the triangle.", "tokens": [50364, 440, 6677, 980, 505, 264, 4641, 295, 264, 3096, 293, 264, 4641, 295, 264, 6681, 295, 264, 13369, 13, 50714], "temperature": 0.0, "avg_logprob": -0.044856944254466465, "compression_ratio": 1.9954545454545454, "no_speech_prob": 0.00043053124682046473}, {"id": 64, "seek": 39000, "start": 397.0, "end": 402.0, "text": " And what we're trying to find is this length here which is the hypotenuse of the right triangle.", "tokens": [50714, 400, 437, 321, 434, 1382, 281, 915, 307, 341, 4641, 510, 597, 307, 264, 7420, 21990, 438, 295, 264, 558, 13369, 13, 50964], "temperature": 0.0, "avg_logprob": -0.044856944254466465, "compression_ratio": 1.9954545454545454, "no_speech_prob": 0.00043053124682046473}, {"id": 65, "seek": 39000, "start": 402.0, "end": 409.0, "text": " So maybe you know some formula or theorem that tells you how to find the length of the hypotenuse of a right triangle.", "tokens": [50964, 407, 1310, 291, 458, 512, 8513, 420, 20904, 300, 5112, 291, 577, 281, 915, 264, 4641, 295, 264, 7420, 21990, 438, 295, 257, 558, 13369, 13, 51314], "temperature": 0.0, "avg_logprob": -0.044856944254466465, "compression_ratio": 1.9954545454545454, "no_speech_prob": 0.00043053124682046473}, {"id": 66, "seek": 39000, "start": 409.0, "end": 414.0, "text": " And if you do then you can figure out the length of this vector.", "tokens": [51314, 400, 498, 291, 360, 550, 291, 393, 2573, 484, 264, 4641, 295, 341, 8062, 13, 51564], "temperature": 0.0, "avg_logprob": -0.044856944254466465, "compression_ratio": 1.9954545454545454, "no_speech_prob": 0.00043053124682046473}, {"id": 67, "seek": 39000, "start": 414.0, "end": 419.0, "text": " And that's what we're going to do in the next video. See you then.", "tokens": [51564, 400, 300, 311, 437, 321, 434, 516, 281, 360, 294, 264, 958, 960, 13, 3008, 291, 550, 13, 51814], "temperature": 0.0, "avg_logprob": -0.044856944254466465, "compression_ratio": 1.9954545454545454, "no_speech_prob": 0.00043053124682046473}, {"id": 68, "seek": 41900, "start": 419.0, "end": 424.0, "text": " Let's find the length of v equal to 3 1.", "tokens": [50364, 961, 311, 915, 264, 4641, 295, 371, 2681, 281, 805, 502, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10291996980324769, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.01168593019247055}, {"id": 69, "seek": 41900, "start": 424.0, "end": 427.0, "text": " But before we do that let's just get some notation out of the way.", "tokens": [50614, 583, 949, 321, 360, 300, 718, 311, 445, 483, 512, 24657, 484, 295, 264, 636, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10291996980324769, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.01168593019247055}, {"id": 70, "seek": 41900, "start": 427.0, "end": 433.0, "text": " When we're talking about the length of a vector we write these double bars around it.", "tokens": [50764, 1133, 321, 434, 1417, 466, 264, 4641, 295, 257, 8062, 321, 2464, 613, 3834, 10228, 926, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10291996980324769, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.01168593019247055}, {"id": 71, "seek": 41900, "start": 433.0, "end": 438.0, "text": " Almost like a double absolute value around the vector.", "tokens": [51064, 12627, 411, 257, 3834, 8236, 2158, 926, 264, 8062, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10291996980324769, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.01168593019247055}, {"id": 72, "seek": 41900, "start": 438.0, "end": 443.0, "text": " And now this is read the length of v.", "tokens": [51314, 400, 586, 341, 307, 1401, 264, 4641, 295, 371, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10291996980324769, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.01168593019247055}, {"id": 73, "seek": 44300, "start": 444.0, "end": 452.0, "text": " So going back to our vector v we have its x component is 3 and its y component is 1.", "tokens": [50414, 407, 516, 646, 281, 527, 8062, 371, 321, 362, 1080, 2031, 6542, 307, 805, 293, 1080, 288, 6542, 307, 502, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09471730862633657, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.0006878350977785885}, {"id": 74, "seek": 44300, "start": 452.0, "end": 462.0, "text": " So that simply means we've moved over 3 in the x direction and up 1 in the y direction.", "tokens": [50814, 407, 300, 2935, 1355, 321, 600, 4259, 670, 805, 294, 264, 2031, 3513, 293, 493, 502, 294, 264, 288, 3513, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09471730862633657, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.0006878350977785885}, {"id": 75, "seek": 44300, "start": 462.0, "end": 467.0, "text": " And now we've formed a right triangle.", "tokens": [51314, 400, 586, 321, 600, 8693, 257, 558, 13369, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09471730862633657, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.0006878350977785885}, {"id": 76, "seek": 46700, "start": 467.0, "end": 478.0, "text": " And it turns out that the length of this vector is just the hypotenuse of this triangle.", "tokens": [50364, 400, 309, 4523, 484, 300, 264, 4641, 295, 341, 8062, 307, 445, 264, 7420, 21990, 438, 295, 341, 13369, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0757566358222336, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.000335340533638373}, {"id": 77, "seek": 46700, "start": 478.0, "end": 481.0, "text": " And so we can just use the Pythagorean theorem.", "tokens": [50914, 400, 370, 321, 393, 445, 764, 264, 9953, 392, 559, 25885, 20904, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0757566358222336, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.000335340533638373}, {"id": 78, "seek": 46700, "start": 481.0, "end": 491.0, "text": " The length of v squared is equal to the 3 squared, the base squared plus the height squared.", "tokens": [51064, 440, 4641, 295, 371, 8889, 307, 2681, 281, 264, 805, 8889, 11, 264, 3096, 8889, 1804, 264, 6681, 8889, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0757566358222336, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.000335340533638373}, {"id": 79, "seek": 49100, "start": 491.0, "end": 497.0, "text": " So 3 squared plus 1 squared.", "tokens": [50364, 407, 805, 8889, 1804, 502, 8889, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06863614015801009, "compression_ratio": 1.3008130081300813, "no_speech_prob": 0.0005033145425841212}, {"id": 80, "seek": 49100, "start": 497.0, "end": 506.0, "text": " This is directly a direct application of the Pythagorean theorem.", "tokens": [50664, 639, 307, 3838, 257, 2047, 3861, 295, 264, 9953, 392, 559, 25885, 20904, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06863614015801009, "compression_ratio": 1.3008130081300813, "no_speech_prob": 0.0005033145425841212}, {"id": 81, "seek": 49100, "start": 506.0, "end": 512.0, "text": " And so that implies if we just take the square root of both sides", "tokens": [51114, 400, 370, 300, 18779, 498, 321, 445, 747, 264, 3732, 5593, 295, 1293, 4881, 51414], "temperature": 0.0, "avg_logprob": -0.06863614015801009, "compression_ratio": 1.3008130081300813, "no_speech_prob": 0.0005033145425841212}, {"id": 82, "seek": 51200, "start": 512.0, "end": 532.0, "text": " that the length of v is equal to the square root of 3 squared plus 1 squared.", "tokens": [50364, 300, 264, 4641, 295, 371, 307, 2681, 281, 264, 3732, 5593, 295, 805, 8889, 1804, 502, 8889, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05577714653576121, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.014062406495213509}, {"id": 83, "seek": 51200, "start": 532.0, "end": 540.0, "text": " Which simplifies to the square root of 10.", "tokens": [51364, 3013, 6883, 11221, 281, 264, 3732, 5593, 295, 1266, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05577714653576121, "compression_ratio": 1.411764705882353, "no_speech_prob": 0.014062406495213509}, {"id": 84, "seek": 54000, "start": 540.0, "end": 543.0, "text": " And it's really just as simple as that.", "tokens": [50364, 400, 309, 311, 534, 445, 382, 2199, 382, 300, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09156428534409096, "compression_ratio": 1.435374149659864, "no_speech_prob": 0.0010321607114747167}, {"id": 85, "seek": 54000, "start": 543.0, "end": 554.0, "text": " All we're doing when we're finding the length of a vector is finding the hypotenuse of a right triangle using the Pythagorean theorem.", "tokens": [50514, 1057, 321, 434, 884, 562, 321, 434, 5006, 264, 4641, 295, 257, 8062, 307, 5006, 264, 7420, 21990, 438, 295, 257, 558, 13369, 1228, 264, 9953, 392, 559, 25885, 20904, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09156428534409096, "compression_ratio": 1.435374149659864, "no_speech_prob": 0.0010321607114747167}, {"id": 86, "seek": 54000, "start": 554.0, "end": 561.0, "text": " Okay, let's look at another example.", "tokens": [51064, 1033, 11, 718, 311, 574, 412, 1071, 1365, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09156428534409096, "compression_ratio": 1.435374149659864, "no_speech_prob": 0.0010321607114747167}, {"id": 87, "seek": 56100, "start": 561.0, "end": 581.0, "text": " Let's say we have something like u is equal to negative 2, 7.", "tokens": [50364, 961, 311, 584, 321, 362, 746, 411, 344, 307, 2681, 281, 3671, 568, 11, 1614, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09123914718627929, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.0013458119938150048}, {"id": 88, "seek": 56100, "start": 581.0, "end": 582.0, "text": " So let's draw that.", "tokens": [51364, 407, 718, 311, 2642, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09123914718627929, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.0013458119938150048}, {"id": 89, "seek": 56100, "start": 582.0, "end": 585.0, "text": " We're going to move over by 2 and up by 7.", "tokens": [51414, 492, 434, 516, 281, 1286, 670, 538, 568, 293, 493, 538, 1614, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09123914718627929, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.0013458119938150048}, {"id": 90, "seek": 56100, "start": 585.0, "end": 588.0, "text": " So something like that.", "tokens": [51564, 407, 746, 411, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09123914718627929, "compression_ratio": 1.2869565217391303, "no_speech_prob": 0.0013458119938150048}, {"id": 91, "seek": 58800, "start": 588.0, "end": 599.0, "text": " So we've moved over negative 2 and we've moved up by 7.", "tokens": [50364, 407, 321, 600, 4259, 670, 3671, 568, 293, 321, 600, 4259, 493, 538, 1614, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10727951492088428, "compression_ratio": 1.371069182389937, "no_speech_prob": 0.000732142070773989}, {"id": 92, "seek": 58800, "start": 599.0, "end": 601.0, "text": " So maybe I'll erase that.", "tokens": [50914, 407, 1310, 286, 603, 23525, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10727951492088428, "compression_ratio": 1.371069182389937, "no_speech_prob": 0.000732142070773989}, {"id": 93, "seek": 58800, "start": 601.0, "end": 605.0, "text": " There we go.", "tokens": [51014, 821, 321, 352, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10727951492088428, "compression_ratio": 1.371069182389937, "no_speech_prob": 0.000732142070773989}, {"id": 94, "seek": 58800, "start": 605.0, "end": 610.0, "text": " Okay, and now the length of u again is just given by the Pythagorean theorem.", "tokens": [51214, 1033, 11, 293, 586, 264, 4641, 295, 344, 797, 307, 445, 2212, 538, 264, 9953, 392, 559, 25885, 20904, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10727951492088428, "compression_ratio": 1.371069182389937, "no_speech_prob": 0.000732142070773989}, {"id": 95, "seek": 58800, "start": 610.0, "end": 617.0, "text": " And we can just skip right to the final step.", "tokens": [51464, 400, 321, 393, 445, 10023, 558, 281, 264, 2572, 1823, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10727951492088428, "compression_ratio": 1.371069182389937, "no_speech_prob": 0.000732142070773989}, {"id": 96, "seek": 61700, "start": 617.0, "end": 630.0, "text": " And this is just going to be equal to the square root of negative 2 squared plus 7 squared.", "tokens": [50364, 400, 341, 307, 445, 516, 281, 312, 2681, 281, 264, 3732, 5593, 295, 3671, 568, 8889, 1804, 1614, 8889, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06185561093417081, "compression_ratio": 1.4206349206349207, "no_speech_prob": 0.0023965733125805855}, {"id": 97, "seek": 61700, "start": 630.0, "end": 638.0, "text": " Which turns out to be 53, the square root of 53.", "tokens": [51014, 3013, 4523, 484, 281, 312, 21860, 11, 264, 3732, 5593, 295, 21860, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06185561093417081, "compression_ratio": 1.4206349206349207, "no_speech_prob": 0.0023965733125805855}, {"id": 98, "seek": 61700, "start": 638.0, "end": 639.0, "text": " And that's it.", "tokens": [51414, 400, 300, 311, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06185561093417081, "compression_ratio": 1.4206349206349207, "no_speech_prob": 0.0023965733125805855}, {"id": 99, "seek": 61700, "start": 639.0, "end": 645.0, "text": " It's as simple as that.", "tokens": [51464, 467, 311, 382, 2199, 382, 300, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06185561093417081, "compression_ratio": 1.4206349206349207, "no_speech_prob": 0.0023965733125805855}, {"id": 100, "seek": 64500, "start": 645.0, "end": 649.0, "text": " Okay, let's do another example here.", "tokens": [50364, 1033, 11, 718, 311, 360, 1071, 1365, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11390865594148636, "compression_ratio": 1.0434782608695652, "no_speech_prob": 0.002323053078725934}, {"id": 101, "seek": 64500, "start": 649.0, "end": 666.0, "text": " How about w is equal to 3 negative 2.", "tokens": [50564, 1012, 466, 261, 307, 2681, 281, 805, 3671, 568, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11390865594148636, "compression_ratio": 1.0434782608695652, "no_speech_prob": 0.002323053078725934}, {"id": 102, "seek": 64500, "start": 666.0, "end": 668.0, "text": " Just making stuff up.", "tokens": [51414, 1449, 1455, 1507, 493, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11390865594148636, "compression_ratio": 1.0434782608695652, "no_speech_prob": 0.002323053078725934}, {"id": 103, "seek": 66800, "start": 668.0, "end": 685.0, "text": " Well, then the length of w is just going to be the square root of 3 squared plus negative 2 squared.", "tokens": [50364, 1042, 11, 550, 264, 4641, 295, 261, 307, 445, 516, 281, 312, 264, 3732, 5593, 295, 805, 8889, 1804, 3671, 568, 8889, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07227701299330767, "compression_ratio": 1.4273504273504274, "no_speech_prob": 0.0033764997497200966}, {"id": 104, "seek": 66800, "start": 685.0, "end": 688.0, "text": " So we have 9 plus 4, so this is 13.", "tokens": [51214, 407, 321, 362, 1722, 1804, 1017, 11, 370, 341, 307, 3705, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07227701299330767, "compression_ratio": 1.4273504273504274, "no_speech_prob": 0.0033764997497200966}, {"id": 105, "seek": 66800, "start": 688.0, "end": 692.0, "text": " This is the square root of 13.", "tokens": [51364, 639, 307, 264, 3732, 5593, 295, 3705, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07227701299330767, "compression_ratio": 1.4273504273504274, "no_speech_prob": 0.0033764997497200966}, {"id": 106, "seek": 69200, "start": 692.0, "end": 694.0, "text": " And we could graph that if we wanted to.", "tokens": [50364, 400, 321, 727, 4295, 300, 498, 321, 1415, 281, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 107, "seek": 69200, "start": 694.0, "end": 699.0, "text": " We're going to go over 3 down by 2, so it's going to look something like that.", "tokens": [50464, 492, 434, 516, 281, 352, 670, 805, 760, 538, 568, 11, 370, 309, 311, 516, 281, 574, 746, 411, 300, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 108, "seek": 69200, "start": 699.0, "end": 703.0, "text": " And again, this is down 2 over 3.", "tokens": [50714, 400, 797, 11, 341, 307, 760, 568, 670, 805, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 109, "seek": 69200, "start": 703.0, "end": 710.0, "text": " We're just talking about the hypotenuse of a right triangle.", "tokens": [50914, 492, 434, 445, 1417, 466, 264, 7420, 21990, 438, 295, 257, 558, 13369, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 110, "seek": 69200, "start": 710.0, "end": 716.0, "text": " Okay, so I hope this was helpful, and I'll see you in the next video.", "tokens": [51264, 1033, 11, 370, 286, 1454, 341, 390, 4961, 11, 293, 286, 603, 536, 291, 294, 264, 958, 960, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 111, "seek": 69200, "start": 716.0, "end": 719.0, "text": " Now that we have the basics of vectors down,", "tokens": [51564, 823, 300, 321, 362, 264, 14688, 295, 18875, 760, 11, 51714], "temperature": 0.0, "avg_logprob": -0.06796080238965092, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.018543409183621407}, {"id": 112, "seek": 71900, "start": 719.0, "end": 723.0, "text": " we should start asking things like what can we do with vectors?", "tokens": [50364, 321, 820, 722, 3365, 721, 411, 437, 393, 321, 360, 365, 18875, 30, 50564], "temperature": 0.0, "avg_logprob": -0.09081088579618014, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.043356046080589294}, {"id": 113, "seek": 71900, "start": 723.0, "end": 727.0, "text": " Can we add vectors, for example?", "tokens": [50564, 1664, 321, 909, 18875, 11, 337, 1365, 30, 50764], "temperature": 0.0, "avg_logprob": -0.09081088579618014, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.043356046080589294}, {"id": 114, "seek": 71900, "start": 727.0, "end": 730.0, "text": " And the answer is yes, we can add vectors.", "tokens": [50764, 400, 264, 1867, 307, 2086, 11, 321, 393, 909, 18875, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09081088579618014, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.043356046080589294}, {"id": 115, "seek": 71900, "start": 730.0, "end": 735.0, "text": " And let's see how we would do that.", "tokens": [50914, 400, 718, 311, 536, 577, 321, 576, 360, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09081088579618014, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.043356046080589294}, {"id": 116, "seek": 73500, "start": 735.0, "end": 740.0, "text": " So u plus v, or v plus u, I should say,", "tokens": [50364, 407, 344, 1804, 371, 11, 420, 371, 1804, 344, 11, 286, 820, 584, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10754798863032093, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.013634800910949707}, {"id": 117, "seek": 73500, "start": 740.0, "end": 750.0, "text": " v plus u is simply going to be, we're going to take the two vectors and add them.", "tokens": [50614, 371, 1804, 344, 307, 2935, 516, 281, 312, 11, 321, 434, 516, 281, 747, 264, 732, 18875, 293, 909, 552, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10754798863032093, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.013634800910949707}, {"id": 118, "seek": 73500, "start": 750.0, "end": 757.0, "text": " So I'm running out every step here.", "tokens": [51114, 407, 286, 478, 2614, 484, 633, 1823, 510, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10754798863032093, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.013634800910949707}, {"id": 119, "seek": 73500, "start": 757.0, "end": 759.0, "text": " And how do we do this?", "tokens": [51464, 400, 577, 360, 321, 360, 341, 30, 51564], "temperature": 0.0, "avg_logprob": -0.10754798863032093, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.013634800910949707}, {"id": 120, "seek": 73500, "start": 759.0, "end": 763.0, "text": " Well, we just add their corresponding components together.", "tokens": [51564, 1042, 11, 321, 445, 909, 641, 11760, 6677, 1214, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10754798863032093, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.013634800910949707}, {"id": 121, "seek": 76300, "start": 763.0, "end": 769.0, "text": " So the first component of v plus u is just going to be the first component of v,", "tokens": [50364, 407, 264, 700, 6542, 295, 371, 1804, 344, 307, 445, 516, 281, 312, 264, 700, 6542, 295, 371, 11, 50664], "temperature": 0.0, "avg_logprob": -0.058417283095322646, "compression_ratio": 2.172932330827068, "no_speech_prob": 0.0027147347573190928}, {"id": 122, "seek": 76300, "start": 769.0, "end": 775.0, "text": " which is 3, plus the first component of u.", "tokens": [50664, 597, 307, 805, 11, 1804, 264, 700, 6542, 295, 344, 13, 50964], "temperature": 0.0, "avg_logprob": -0.058417283095322646, "compression_ratio": 2.172932330827068, "no_speech_prob": 0.0027147347573190928}, {"id": 123, "seek": 76300, "start": 775.0, "end": 779.0, "text": " And you can see, just visually, you can see what's happening here.", "tokens": [50964, 400, 291, 393, 536, 11, 445, 19622, 11, 291, 393, 536, 437, 311, 2737, 510, 13, 51164], "temperature": 0.0, "avg_logprob": -0.058417283095322646, "compression_ratio": 2.172932330827068, "no_speech_prob": 0.0027147347573190928}, {"id": 124, "seek": 76300, "start": 779.0, "end": 786.0, "text": " The second component of v plus u is just the second component of v plus the second component of u,", "tokens": [51164, 440, 1150, 6542, 295, 371, 1804, 344, 307, 445, 264, 1150, 6542, 295, 371, 1804, 264, 1150, 6542, 295, 344, 11, 51514], "temperature": 0.0, "avg_logprob": -0.058417283095322646, "compression_ratio": 2.172932330827068, "no_speech_prob": 0.0027147347573190928}, {"id": 125, "seek": 78600, "start": 786.0, "end": 794.0, "text": " which in our case just becomes 4, 6.", "tokens": [50364, 597, 294, 527, 1389, 445, 3643, 1017, 11, 1386, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07855468163123498, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.005384117364883423}, {"id": 126, "seek": 78600, "start": 794.0, "end": 798.0, "text": " So when we add vectors together, we get a new vector.", "tokens": [50764, 407, 562, 321, 909, 18875, 1214, 11, 321, 483, 257, 777, 8062, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07855468163123498, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.005384117364883423}, {"id": 127, "seek": 78600, "start": 798.0, "end": 806.0, "text": " And here we got the vector 4, 6.", "tokens": [50964, 400, 510, 321, 658, 264, 8062, 1017, 11, 1386, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07855468163123498, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.005384117364883423}, {"id": 128, "seek": 78600, "start": 806.0, "end": 811.0, "text": " Okay, so just to save some space, let me erase these steps here.", "tokens": [51364, 1033, 11, 370, 445, 281, 3155, 512, 1901, 11, 718, 385, 23525, 613, 4439, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07855468163123498, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.005384117364883423}, {"id": 129, "seek": 78600, "start": 811.0, "end": 815.0, "text": " Move this over.", "tokens": [51614, 10475, 341, 670, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07855468163123498, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.005384117364883423}, {"id": 130, "seek": 81500, "start": 815.0, "end": 821.0, "text": " Okay, so let's now look at this on a graph.", "tokens": [50364, 1033, 11, 370, 718, 311, 586, 574, 412, 341, 322, 257, 4295, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07310299354024452, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.00044418752077035606}, {"id": 131, "seek": 81500, "start": 821.0, "end": 828.0, "text": " Here is u and v, u and yellow, v and blue.", "tokens": [50664, 1692, 307, 344, 293, 371, 11, 344, 293, 5566, 11, 371, 293, 3344, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07310299354024452, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.00044418752077035606}, {"id": 132, "seek": 81500, "start": 828.0, "end": 833.0, "text": " Real quick, because I haven't mentioned this yet, vectors have two things.", "tokens": [51014, 8467, 1702, 11, 570, 286, 2378, 380, 2835, 341, 1939, 11, 18875, 362, 732, 721, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07310299354024452, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.00044418752077035606}, {"id": 133, "seek": 81500, "start": 833.0, "end": 839.0, "text": " One is called a tail, it's starting point, and the other is called a head, it's ending point.", "tokens": [51264, 1485, 307, 1219, 257, 6838, 11, 309, 311, 2891, 935, 11, 293, 264, 661, 307, 1219, 257, 1378, 11, 309, 311, 8121, 935, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07310299354024452, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.00044418752077035606}, {"id": 134, "seek": 81500, "start": 839.0, "end": 844.0, "text": " I mean, they have more than two things, I guess, but they have a head and a tail.", "tokens": [51564, 286, 914, 11, 436, 362, 544, 813, 732, 721, 11, 286, 2041, 11, 457, 436, 362, 257, 1378, 293, 257, 6838, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07310299354024452, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.00044418752077035606}, {"id": 135, "seek": 84400, "start": 844.0, "end": 849.0, "text": " So when we add vectors, we line up their tails at a common point.", "tokens": [50364, 407, 562, 321, 909, 18875, 11, 321, 1622, 493, 641, 28537, 412, 257, 2689, 935, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08552075405510104, "compression_ratio": 1.748768472906404, "no_speech_prob": 0.0008558265399187803}, {"id": 136, "seek": 84400, "start": 849.0, "end": 852.0, "text": " Here we pick the origin just because it's convenient.", "tokens": [50614, 1692, 321, 1888, 264, 4957, 445, 570, 309, 311, 10851, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08552075405510104, "compression_ratio": 1.748768472906404, "no_speech_prob": 0.0008558265399187803}, {"id": 137, "seek": 84400, "start": 852.0, "end": 855.0, "text": " So we line up their tails at that common point.", "tokens": [50764, 407, 321, 1622, 493, 641, 28537, 412, 300, 2689, 935, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08552075405510104, "compression_ratio": 1.748768472906404, "no_speech_prob": 0.0008558265399187803}, {"id": 138, "seek": 84400, "start": 855.0, "end": 867.0, "text": " And then to add them, we just take, we're going along v and then we take u and place its tail to the head of v.", "tokens": [50914, 400, 550, 281, 909, 552, 11, 321, 445, 747, 11, 321, 434, 516, 2051, 371, 293, 550, 321, 747, 344, 293, 1081, 1080, 6838, 281, 264, 1378, 295, 371, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08552075405510104, "compression_ratio": 1.748768472906404, "no_speech_prob": 0.0008558265399187803}, {"id": 139, "seek": 84400, "start": 867.0, "end": 872.0, "text": " So you can see what this corresponds to, this is like going along u plus v.", "tokens": [51514, 407, 291, 393, 536, 437, 341, 23249, 281, 11, 341, 307, 411, 516, 2051, 344, 1804, 371, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08552075405510104, "compression_ratio": 1.748768472906404, "no_speech_prob": 0.0008558265399187803}, {"id": 140, "seek": 87200, "start": 872.0, "end": 878.0, "text": " Or sorry, going along v plus u.", "tokens": [50364, 1610, 2597, 11, 516, 2051, 371, 1804, 344, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08375250908636278, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.002889506286010146}, {"id": 141, "seek": 87200, "start": 878.0, "end": 887.0, "text": " And now the new vector is just the vector that starts at their common starting point and ends at that addition.", "tokens": [50664, 400, 586, 264, 777, 8062, 307, 445, 264, 8062, 300, 3719, 412, 641, 2689, 2891, 935, 293, 5314, 412, 300, 4500, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08375250908636278, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.002889506286010146}, {"id": 142, "seek": 87200, "start": 887.0, "end": 891.0, "text": " Sorry about that.", "tokens": [51114, 4919, 466, 300, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08375250908636278, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.002889506286010146}, {"id": 143, "seek": 87200, "start": 891.0, "end": 901.0, "text": " So that new vector is the vector u, I'm sorry, v plus u.", "tokens": [51314, 407, 300, 777, 8062, 307, 264, 8062, 344, 11, 286, 478, 2597, 11, 371, 1804, 344, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08375250908636278, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.002889506286010146}, {"id": 144, "seek": 90100, "start": 901.0, "end": 908.0, "text": " And we know it has components four or six.", "tokens": [50364, 400, 321, 458, 309, 575, 6677, 1451, 420, 2309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1180579632143431, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.0013249412877485156}, {"id": 145, "seek": 90100, "start": 908.0, "end": 918.0, "text": " Which makes sense if we think about it, v took us over three in the x direction and u took us over one more, so that would be four.", "tokens": [50714, 3013, 1669, 2020, 498, 321, 519, 466, 309, 11, 371, 1890, 505, 670, 1045, 294, 264, 2031, 3513, 293, 344, 1890, 505, 670, 472, 544, 11, 370, 300, 576, 312, 1451, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1180579632143431, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.0013249412877485156}, {"id": 146, "seek": 90100, "start": 918.0, "end": 930.0, "text": " So the new vector v plus u went over four and x and we could do a similar thing to show that it went up six and y.", "tokens": [51214, 407, 264, 777, 8062, 371, 1804, 344, 1437, 670, 1451, 293, 2031, 293, 321, 727, 360, 257, 2531, 551, 281, 855, 300, 309, 1437, 493, 2309, 293, 288, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1180579632143431, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.0013249412877485156}, {"id": 147, "seek": 93000, "start": 931.0, "end": 944.0, "text": " Okay, what else? Well, notice that we could have, if we wanted to, have gone along u first and then added v.", "tokens": [50414, 1033, 11, 437, 1646, 30, 1042, 11, 3449, 300, 321, 727, 362, 11, 498, 321, 1415, 281, 11, 362, 2780, 2051, 344, 700, 293, 550, 3869, 371, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1325911769160518, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.001700641238130629}, {"id": 148, "seek": 93000, "start": 944.0, "end": 950.0, "text": " And we would have got to the same point, which means we would have gotten the same vector.", "tokens": [51064, 400, 321, 576, 362, 658, 281, 264, 912, 935, 11, 597, 1355, 321, 576, 362, 5768, 264, 912, 8062, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1325911769160518, "compression_ratio": 1.4962406015037595, "no_speech_prob": 0.001700641238130629}, {"id": 149, "seek": 95000, "start": 950.0, "end": 957.0, "text": " So u plus v is the same vector as v plus u.", "tokens": [50364, 407, 344, 1804, 371, 307, 264, 912, 8062, 382, 371, 1804, 344, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0826133546375093, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0015011468203738332}, {"id": 150, "seek": 95000, "start": 957.0, "end": 963.0, "text": " Which tells us that vector addition must be commutative.", "tokens": [50714, 3013, 5112, 505, 300, 8062, 4500, 1633, 312, 800, 325, 1166, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0826133546375093, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0015011468203738332}, {"id": 151, "seek": 95000, "start": 963.0, "end": 969.0, "text": " Vector addition must be commutative.", "tokens": [51014, 691, 20814, 4500, 1633, 312, 800, 325, 1166, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0826133546375093, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0015011468203738332}, {"id": 152, "seek": 96900, "start": 969.0, "end": 981.0, "text": " And we'll prove that in a few videos from now.", "tokens": [50364, 400, 321, 603, 7081, 300, 294, 257, 1326, 2145, 490, 586, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1191486180838892, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.0010482765501365066}, {"id": 153, "seek": 96900, "start": 981.0, "end": 988.0, "text": " We'll prove that vector addition is commutative, but just visually this is kind of a geometric proof that it must be.", "tokens": [50964, 492, 603, 7081, 300, 8062, 4500, 307, 800, 325, 1166, 11, 457, 445, 19622, 341, 307, 733, 295, 257, 33246, 8177, 300, 309, 1633, 312, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1191486180838892, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.0010482765501365066}, {"id": 154, "seek": 96900, "start": 988.0, "end": 995.0, "text": " Okay, that's vector addition. See you in the next video.", "tokens": [51314, 1033, 11, 300, 311, 8062, 4500, 13, 3008, 291, 294, 264, 958, 960, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1191486180838892, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.0010482765501365066}, {"id": 155, "seek": 99900, "start": 999.0, "end": 1004.0, "text": " Can we multiply vectors by numbers? And the answer is yes.", "tokens": [50364, 1664, 321, 12972, 18875, 538, 3547, 30, 400, 264, 1867, 307, 2086, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13929975205573483, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.15596868097782135}, {"id": 156, "seek": 99900, "start": 1004.0, "end": 1008.0, "text": " So let's just see an example of that.", "tokens": [50614, 407, 718, 311, 445, 536, 364, 1365, 295, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13929975205573483, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.15596868097782135}, {"id": 157, "seek": 99900, "start": 1008.0, "end": 1015.0, "text": " If we want to multiply v by two, so two v. I'll just write it like this, two v.", "tokens": [50814, 759, 321, 528, 281, 12972, 371, 538, 732, 11, 370, 732, 371, 13, 286, 603, 445, 2464, 309, 411, 341, 11, 732, 371, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13929975205573483, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.15596868097782135}, {"id": 158, "seek": 99900, "start": 1015.0, "end": 1024.0, "text": " Component wise, this is just two times this vector.", "tokens": [51164, 6620, 30365, 10829, 11, 341, 307, 445, 732, 1413, 341, 8062, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13929975205573483, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.15596868097782135}, {"id": 159, "seek": 102400, "start": 1024.0, "end": 1029.0, "text": " Which, we just take that two and we multiply each component by it.", "tokens": [50364, 3013, 11, 321, 445, 747, 300, 732, 293, 321, 12972, 1184, 6542, 538, 309, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0981509224061043, "compression_ratio": 1.4932432432432432, "no_speech_prob": 0.001956905471161008}, {"id": 160, "seek": 102400, "start": 1029.0, "end": 1034.0, "text": " So this becomes, I'll write out each step here.", "tokens": [50614, 407, 341, 3643, 11, 286, 603, 2464, 484, 1184, 1823, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0981509224061043, "compression_ratio": 1.4932432432432432, "no_speech_prob": 0.001956905471161008}, {"id": 161, "seek": 102400, "start": 1034.0, "end": 1044.0, "text": " This is two times one and then two times two, which of course simplifies to two four.", "tokens": [50864, 639, 307, 732, 1413, 472, 293, 550, 732, 1413, 732, 11, 597, 295, 1164, 6883, 11221, 281, 732, 1451, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0981509224061043, "compression_ratio": 1.4932432432432432, "no_speech_prob": 0.001956905471161008}, {"id": 162, "seek": 102400, "start": 1044.0, "end": 1051.0, "text": " The vector two four.", "tokens": [51364, 440, 8062, 732, 1451, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0981509224061043, "compression_ratio": 1.4932432432432432, "no_speech_prob": 0.001956905471161008}, {"id": 163, "seek": 105100, "start": 1051.0, "end": 1056.0, "text": " And we call two, this number two, we call it a scalar multiple.", "tokens": [50364, 400, 321, 818, 732, 11, 341, 1230, 732, 11, 321, 818, 309, 257, 39684, 3866, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08048592862628755, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.001284223049879074}, {"id": 164, "seek": 105100, "start": 1056.0, "end": 1068.0, "text": " And there's a good reason we call it that, because what it does is it scales the vector.", "tokens": [50614, 400, 456, 311, 257, 665, 1778, 321, 818, 309, 300, 11, 570, 437, 309, 775, 307, 309, 17408, 264, 8062, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08048592862628755, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.001284223049879074}, {"id": 165, "seek": 105100, "start": 1068.0, "end": 1074.0, "text": " And let me show you that. Here is our original vector, just v.", "tokens": [51214, 400, 718, 385, 855, 291, 300, 13, 1692, 307, 527, 3380, 8062, 11, 445, 371, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08048592862628755, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.001284223049879074}, {"id": 166, "seek": 105100, "start": 1074.0, "end": 1079.0, "text": " Here is two v. It's twice as large. In fact, let me put regular v back.", "tokens": [51514, 1692, 307, 732, 371, 13, 467, 311, 6091, 382, 2416, 13, 682, 1186, 11, 718, 385, 829, 3890, 371, 646, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08048592862628755, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.001284223049879074}, {"id": 167, "seek": 107900, "start": 1079.0, "end": 1084.0, "text": " You can see there's v and when we multiply by two, it makes it twice as long.", "tokens": [50364, 509, 393, 536, 456, 311, 371, 293, 562, 321, 12972, 538, 732, 11, 309, 1669, 309, 6091, 382, 938, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10946921842644014, "compression_ratio": 1.6453488372093024, "no_speech_prob": 0.016912367194890976}, {"id": 168, "seek": 107900, "start": 1084.0, "end": 1095.0, "text": " It changes the length by two, by a factor of two.", "tokens": [50614, 467, 2962, 264, 4641, 538, 732, 11, 538, 257, 5952, 295, 732, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10946921842644014, "compression_ratio": 1.6453488372093024, "no_speech_prob": 0.016912367194890976}, {"id": 169, "seek": 107900, "start": 1095.0, "end": 1097.0, "text": " Okay, there's nothing fancy about that.", "tokens": [51164, 1033, 11, 456, 311, 1825, 10247, 466, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10946921842644014, "compression_ratio": 1.6453488372093024, "no_speech_prob": 0.016912367194890976}, {"id": 170, "seek": 107900, "start": 1097.0, "end": 1102.0, "text": " We can also check out what happens when we take v and we multiply by a half.", "tokens": [51264, 492, 393, 611, 1520, 484, 437, 2314, 562, 321, 747, 371, 293, 321, 12972, 538, 257, 1922, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10946921842644014, "compression_ratio": 1.6453488372093024, "no_speech_prob": 0.016912367194890976}, {"id": 171, "seek": 107900, "start": 1102.0, "end": 1106.0, "text": " It makes it half as big, half as long.", "tokens": [51514, 467, 1669, 309, 1922, 382, 955, 11, 1922, 382, 938, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10946921842644014, "compression_ratio": 1.6453488372093024, "no_speech_prob": 0.016912367194890976}, {"id": 172, "seek": 110600, "start": 1106.0, "end": 1114.0, "text": " What I really want to talk about is what happens when we take v and we multiply it by negative one.", "tokens": [50364, 708, 286, 534, 528, 281, 751, 466, 307, 437, 2314, 562, 321, 747, 371, 293, 321, 12972, 309, 538, 3671, 472, 13, 50764], "temperature": 0.0, "avg_logprob": -0.104367767061506, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00505980895832181}, {"id": 173, "seek": 110600, "start": 1114.0, "end": 1118.0, "text": " Well, then it flips the direction of v.", "tokens": [50764, 1042, 11, 550, 309, 40249, 264, 3513, 295, 371, 13, 50964], "temperature": 0.0, "avg_logprob": -0.104367767061506, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00505980895832181}, {"id": 174, "seek": 110600, "start": 1118.0, "end": 1122.0, "text": " Now v is going in the opposite direction.", "tokens": [50964, 823, 371, 307, 516, 294, 264, 6182, 3513, 13, 51164], "temperature": 0.0, "avg_logprob": -0.104367767061506, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00505980895832181}, {"id": 175, "seek": 110600, "start": 1122.0, "end": 1125.0, "text": " And what happens to the components?", "tokens": [51164, 400, 437, 2314, 281, 264, 6677, 30, 51314], "temperature": 0.0, "avg_logprob": -0.104367767061506, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00505980895832181}, {"id": 176, "seek": 110600, "start": 1125.0, "end": 1130.0, "text": " Well, that's relatively easy to figure out.", "tokens": [51314, 1042, 11, 300, 311, 7226, 1858, 281, 2573, 484, 13, 51564], "temperature": 0.0, "avg_logprob": -0.104367767061506, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.00505980895832181}, {"id": 177, "seek": 113000, "start": 1130.0, "end": 1132.0, "text": " Oops, I didn't need to erase those.", "tokens": [50364, 21726, 11, 286, 994, 380, 643, 281, 23525, 729, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 178, "seek": 113000, "start": 1132.0, "end": 1138.0, "text": " If we take negative one times v, which I'll just abbreviate as negative v.", "tokens": [50464, 759, 321, 747, 3671, 472, 1413, 371, 11, 597, 286, 603, 445, 35839, 473, 382, 3671, 371, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 179, "seek": 113000, "start": 1138.0, "end": 1147.0, "text": " This is negative one times one two, which simply turns out to be negative one, negative two.", "tokens": [50764, 639, 307, 3671, 472, 1413, 472, 732, 11, 597, 2935, 4523, 484, 281, 312, 3671, 472, 11, 3671, 732, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 180, "seek": 113000, "start": 1147.0, "end": 1151.0, "text": " And it flips the direction of v.", "tokens": [51214, 400, 309, 40249, 264, 3513, 295, 371, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 181, "seek": 113000, "start": 1151.0, "end": 1153.0, "text": " And why is that so important?", "tokens": [51414, 400, 983, 307, 300, 370, 1021, 30, 51514], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 182, "seek": 113000, "start": 1153.0, "end": 1157.0, "text": " Well, now we can talk about vector subtraction.", "tokens": [51514, 1042, 11, 586, 321, 393, 751, 466, 8062, 16390, 313, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0817863941192627, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0069033424369990826}, {"id": 183, "seek": 115700, "start": 1157.0, "end": 1166.0, "text": " We have a negative v here, and we know this works because we can multiply by that scalar of negative one.", "tokens": [50364, 492, 362, 257, 3671, 371, 510, 11, 293, 321, 458, 341, 1985, 570, 321, 393, 12972, 538, 300, 39684, 295, 3671, 472, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05491820047068041, "compression_ratio": 1.6185567010309279, "no_speech_prob": 0.0005883926060050726}, {"id": 184, "seek": 115700, "start": 1166.0, "end": 1169.0, "text": " And now we have a way to talk about vector subtraction.", "tokens": [50814, 400, 586, 321, 362, 257, 636, 281, 751, 466, 8062, 16390, 313, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05491820047068041, "compression_ratio": 1.6185567010309279, "no_speech_prob": 0.0005883926060050726}, {"id": 185, "seek": 115700, "start": 1169.0, "end": 1173.0, "text": " So let's go ahead and do that. See you then.", "tokens": [50964, 407, 718, 311, 352, 2286, 293, 360, 300, 13, 3008, 291, 550, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05491820047068041, "compression_ratio": 1.6185567010309279, "no_speech_prob": 0.0005883926060050726}, {"id": 186, "seek": 115700, "start": 1173.0, "end": 1176.0, "text": " Let's take a look at vector subtraction.", "tokens": [51164, 961, 311, 747, 257, 574, 412, 8062, 16390, 313, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05491820047068041, "compression_ratio": 1.6185567010309279, "no_speech_prob": 0.0005883926060050726}, {"id": 187, "seek": 115700, "start": 1176.0, "end": 1181.0, "text": " This is going to work the same way that it works for real numbers.", "tokens": [51314, 639, 307, 516, 281, 589, 264, 912, 636, 300, 309, 1985, 337, 957, 3547, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05491820047068041, "compression_ratio": 1.6185567010309279, "no_speech_prob": 0.0005883926060050726}, {"id": 188, "seek": 118100, "start": 1181.0, "end": 1200.0, "text": " If we want to do something like u minus v, this is really just the same thing as doing u plus negative v.", "tokens": [50364, 759, 321, 528, 281, 360, 746, 411, 344, 3175, 371, 11, 341, 307, 534, 445, 264, 912, 551, 382, 884, 344, 1804, 3671, 371, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08381185726243623, "compression_ratio": 1.3181818181818181, "no_speech_prob": 0.002672916278243065}, {"id": 189, "seek": 118100, "start": 1200.0, "end": 1203.0, "text": " And we know how to multiply v by negative one.", "tokens": [51314, 400, 321, 458, 577, 281, 12972, 371, 538, 3671, 472, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08381185726243623, "compression_ratio": 1.3181818181818181, "no_speech_prob": 0.002672916278243065}, {"id": 190, "seek": 118100, "start": 1203.0, "end": 1205.0, "text": " That's simple enough.", "tokens": [51464, 663, 311, 2199, 1547, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08381185726243623, "compression_ratio": 1.3181818181818181, "no_speech_prob": 0.002672916278243065}, {"id": 191, "seek": 120500, "start": 1205.0, "end": 1221.0, "text": " We're going to have u, which is three three, plus a negative four, negative one.", "tokens": [50364, 492, 434, 516, 281, 362, 344, 11, 597, 307, 1045, 1045, 11, 1804, 257, 3671, 1451, 11, 3671, 472, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20028011753874006, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.2507918179035187}, {"id": 192, "seek": 120500, "start": 1221.0, "end": 1225.0, "text": " Okay, simple enough.", "tokens": [51164, 1033, 11, 2199, 1547, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20028011753874006, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.2507918179035187}, {"id": 193, "seek": 120500, "start": 1225.0, "end": 1233.0, "text": " We do that addition and we get four, or sorry, three plus negative four is negative one.", "tokens": [51364, 492, 360, 300, 4500, 293, 321, 483, 1451, 11, 420, 2597, 11, 1045, 1804, 3671, 1451, 307, 3671, 472, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20028011753874006, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.2507918179035187}, {"id": 194, "seek": 123300, "start": 1233.0, "end": 1236.0, "text": " Three minus one is two.", "tokens": [50364, 6244, 3175, 472, 307, 732, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 195, "seek": 123300, "start": 1236.0, "end": 1242.0, "text": " And so this subtraction is just this new vector, negative one, two.", "tokens": [50514, 400, 370, 341, 16390, 313, 307, 445, 341, 777, 8062, 11, 3671, 472, 11, 732, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 196, "seek": 123300, "start": 1242.0, "end": 1245.0, "text": " Simple enough.", "tokens": [50814, 21532, 1547, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 197, "seek": 123300, "start": 1245.0, "end": 1247.0, "text": " So now let's take a look at that on a graph.", "tokens": [50964, 407, 586, 718, 311, 747, 257, 574, 412, 300, 322, 257, 4295, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 198, "seek": 123300, "start": 1247.0, "end": 1256.0, "text": " Here we have v in blue and u in orange.", "tokens": [51064, 1692, 321, 362, 371, 294, 3344, 293, 344, 294, 7671, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 199, "seek": 123300, "start": 1256.0, "end": 1258.0, "text": " And now we can graph negative v.", "tokens": [51514, 400, 586, 321, 393, 4295, 3671, 371, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 200, "seek": 123300, "start": 1258.0, "end": 1262.0, "text": " So it's just v, but pointing in the opposite direction.", "tokens": [51614, 407, 309, 311, 445, 371, 11, 457, 12166, 294, 264, 6182, 3513, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07062262158061183, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0014778897166252136}, {"id": 201, "seek": 126200, "start": 1262.0, "end": 1265.0, "text": " So there's negative v.", "tokens": [50364, 407, 456, 311, 3671, 371, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06004968616697523, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0024722202215343714}, {"id": 202, "seek": 126200, "start": 1265.0, "end": 1271.0, "text": " And now to do this subtraction, we're really just doing u plus negative v.", "tokens": [50514, 400, 586, 281, 360, 341, 16390, 313, 11, 321, 434, 534, 445, 884, 344, 1804, 3671, 371, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06004968616697523, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0024722202215343714}, {"id": 203, "seek": 126200, "start": 1271.0, "end": 1273.0, "text": " So we're just going to take the head to tail approach.", "tokens": [50814, 407, 321, 434, 445, 516, 281, 747, 264, 1378, 281, 6838, 3109, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06004968616697523, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0024722202215343714}, {"id": 204, "seek": 126200, "start": 1273.0, "end": 1279.0, "text": " We go up u and then we add negative v.", "tokens": [50914, 492, 352, 493, 344, 293, 550, 321, 909, 3671, 371, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06004968616697523, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0024722202215343714}, {"id": 205, "seek": 126200, "start": 1279.0, "end": 1290.0, "text": " And we get to this new vector, u minus v.", "tokens": [51214, 400, 321, 483, 281, 341, 777, 8062, 11, 344, 3175, 371, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06004968616697523, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0024722202215343714}, {"id": 206, "seek": 129000, "start": 1290.0, "end": 1293.0, "text": " There's our new vector.", "tokens": [50364, 821, 311, 527, 777, 8062, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 207, "seek": 129000, "start": 1293.0, "end": 1298.0, "text": " But notice that vectors, since they're translational, we can move them anywhere in the plane.", "tokens": [50514, 583, 3449, 300, 18875, 11, 1670, 436, 434, 5105, 1478, 11, 321, 393, 1286, 552, 4992, 294, 264, 5720, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 208, "seek": 129000, "start": 1298.0, "end": 1303.0, "text": " We can draw u minus v here.", "tokens": [50764, 492, 393, 2642, 344, 3175, 371, 510, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 209, "seek": 129000, "start": 1303.0, "end": 1305.0, "text": " And close off that parallelogram.", "tokens": [51014, 400, 1998, 766, 300, 8952, 12820, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 210, "seek": 129000, "start": 1305.0, "end": 1309.0, "text": " This is the same vector as u minus v over there.", "tokens": [51114, 639, 307, 264, 912, 8062, 382, 344, 3175, 371, 670, 456, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 211, "seek": 129000, "start": 1309.0, "end": 1311.0, "text": " So this is still u minus v.", "tokens": [51314, 407, 341, 307, 920, 344, 3175, 371, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 212, "seek": 129000, "start": 1311.0, "end": 1315.0, "text": " We just moved it over.", "tokens": [51414, 492, 445, 4259, 309, 670, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07340669057455408, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0011694382410496473}, {"id": 213, "seek": 131500, "start": 1315.0, "end": 1326.0, "text": " And that's pretty interesting because that tells us that u minus v is the vector that points from the head of v to the head of u.", "tokens": [50364, 400, 300, 311, 1238, 1880, 570, 300, 5112, 505, 300, 344, 3175, 371, 307, 264, 8062, 300, 2793, 490, 264, 1378, 295, 371, 281, 264, 1378, 295, 344, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08745060602823894, "compression_ratio": 1.72, "no_speech_prob": 9.610092820366845e-05}, {"id": 214, "seek": 131500, "start": 1326.0, "end": 1328.0, "text": " So make sure you see that.", "tokens": [50914, 407, 652, 988, 291, 536, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08745060602823894, "compression_ratio": 1.72, "no_speech_prob": 9.610092820366845e-05}, {"id": 215, "seek": 131500, "start": 1328.0, "end": 1330.0, "text": " Points from the head of v to the head of u.", "tokens": [51014, 44763, 490, 264, 1378, 295, 371, 281, 264, 1378, 295, 344, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08745060602823894, "compression_ratio": 1.72, "no_speech_prob": 9.610092820366845e-05}, {"id": 216, "seek": 131500, "start": 1330.0, "end": 1332.0, "text": " In fact, let me remove that.", "tokens": [51114, 682, 1186, 11, 718, 385, 4159, 300, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08745060602823894, "compression_ratio": 1.72, "no_speech_prob": 9.610092820366845e-05}, {"id": 217, "seek": 131500, "start": 1332.0, "end": 1340.0, "text": " Maybe you can see it better.", "tokens": [51214, 2704, 291, 393, 536, 309, 1101, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08745060602823894, "compression_ratio": 1.72, "no_speech_prob": 9.610092820366845e-05}, {"id": 218, "seek": 134000, "start": 1340.0, "end": 1346.0, "text": " Okay, so we're going to use that fact when we prove something about the dot product a few videos from now.", "tokens": [50364, 1033, 11, 370, 321, 434, 516, 281, 764, 300, 1186, 562, 321, 7081, 746, 466, 264, 5893, 1674, 257, 1326, 2145, 490, 586, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08367367386817932, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.06006130203604698}, {"id": 219, "seek": 134000, "start": 1346.0, "end": 1349.0, "text": " See that.", "tokens": [50664, 3008, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08367367386817932, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.06006130203604698}, {"id": 220, "seek": 134000, "start": 1349.0, "end": 1354.0, "text": " Okay, so here we have a vector with three components.", "tokens": [50814, 1033, 11, 370, 510, 321, 362, 257, 8062, 365, 1045, 6677, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08367367386817932, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.06006130203604698}, {"id": 221, "seek": 134000, "start": 1354.0, "end": 1360.0, "text": " And now we can think of these as the x component and the y component just like before.", "tokens": [51064, 400, 586, 321, 393, 519, 295, 613, 382, 264, 2031, 6542, 293, 264, 288, 6542, 445, 411, 949, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08367367386817932, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.06006130203604698}, {"id": 222, "seek": 134000, "start": 1360.0, "end": 1366.0, "text": " And now we're adding in the z component.", "tokens": [51364, 400, 586, 321, 434, 5127, 294, 264, 710, 6542, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08367367386817932, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.06006130203604698}, {"id": 223, "seek": 136600, "start": 1366.0, "end": 1368.0, "text": " And so we have three components.", "tokens": [50364, 400, 370, 321, 362, 1045, 6677, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10177835604039634, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0004878296167589724}, {"id": 224, "seek": 136600, "start": 1368.0, "end": 1371.0, "text": " We need to graph this vector in three-dimensional space.", "tokens": [50464, 492, 643, 281, 4295, 341, 8062, 294, 1045, 12, 18759, 1901, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10177835604039634, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0004878296167589724}, {"id": 225, "seek": 136600, "start": 1371.0, "end": 1379.0, "text": " So we have these three axes here, the x axes, the y axis, and the z axis.", "tokens": [50614, 407, 321, 362, 613, 1045, 35387, 510, 11, 264, 2031, 35387, 11, 264, 288, 10298, 11, 293, 264, 710, 10298, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10177835604039634, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0004878296167589724}, {"id": 226, "seek": 136600, "start": 1379.0, "end": 1390.0, "text": " And to graph this, all we need to do is move over one and x and four and y.", "tokens": [51014, 400, 281, 4295, 341, 11, 439, 321, 643, 281, 360, 307, 1286, 670, 472, 293, 2031, 293, 1451, 293, 288, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10177835604039634, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0004878296167589724}, {"id": 227, "seek": 136600, "start": 1390.0, "end": 1392.0, "text": " So that takes us to about this point.", "tokens": [51564, 407, 300, 2516, 505, 281, 466, 341, 935, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10177835604039634, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0004878296167589724}, {"id": 228, "seek": 139200, "start": 1392.0, "end": 1398.0, "text": " And I'm going to draw a line from the origin to that point where we've moved to.", "tokens": [50364, 400, 286, 478, 516, 281, 2642, 257, 1622, 490, 264, 4957, 281, 300, 935, 689, 321, 600, 4259, 281, 13, 50664], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 229, "seek": 139200, "start": 1398.0, "end": 1400.0, "text": " So this is one and x, four and y.", "tokens": [50664, 407, 341, 307, 472, 293, 2031, 11, 1451, 293, 288, 13, 50764], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 230, "seek": 139200, "start": 1400.0, "end": 1407.0, "text": " And then we just need to move up three in the z direction.", "tokens": [50764, 400, 550, 321, 445, 643, 281, 1286, 493, 1045, 294, 264, 710, 3513, 13, 51114], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 231, "seek": 139200, "start": 1407.0, "end": 1410.0, "text": " And that will take us to our vector.", "tokens": [51114, 400, 300, 486, 747, 505, 281, 527, 8062, 13, 51264], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 232, "seek": 139200, "start": 1410.0, "end": 1416.0, "text": " So our vector moves one and x, four and y, and three and z.", "tokens": [51264, 407, 527, 8062, 6067, 472, 293, 2031, 11, 1451, 293, 288, 11, 293, 1045, 293, 710, 13, 51564], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 233, "seek": 139200, "start": 1416.0, "end": 1421.0, "text": " And there it is right there.", "tokens": [51564, 400, 456, 309, 307, 558, 456, 13, 51814], "temperature": 0.0, "avg_logprob": -0.053442555925120476, "compression_ratio": 1.689265536723164, "no_speech_prob": 0.0006461777375079691}, {"id": 234, "seek": 142100, "start": 1421.0, "end": 1435.0, "text": " Now to help with a sense of depth, I find it helpful to dash these lines here.", "tokens": [50364, 823, 281, 854, 365, 257, 2020, 295, 7161, 11, 286, 915, 309, 4961, 281, 8240, 613, 3876, 510, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06718282041878536, "compression_ratio": 1.492537313432836, "no_speech_prob": 0.0006877866107970476}, {"id": 235, "seek": 142100, "start": 1435.0, "end": 1440.0, "text": " And now that dashed line is like the shadow of v onto the xy plane.", "tokens": [51064, 400, 586, 300, 8240, 292, 1622, 307, 411, 264, 8576, 295, 371, 3911, 264, 2031, 88, 5720, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06718282041878536, "compression_ratio": 1.492537313432836, "no_speech_prob": 0.0006877866107970476}, {"id": 236, "seek": 142100, "start": 1440.0, "end": 1446.0, "text": " And then I also like to dash this line up for height.", "tokens": [51314, 400, 550, 286, 611, 411, 281, 8240, 341, 1622, 493, 337, 6681, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06718282041878536, "compression_ratio": 1.492537313432836, "no_speech_prob": 0.0006877866107970476}, {"id": 237, "seek": 144600, "start": 1446.0, "end": 1453.0, "text": " I just think it gives us a better sense of depth and clarity.", "tokens": [50364, 286, 445, 519, 309, 2709, 505, 257, 1101, 2020, 295, 7161, 293, 16992, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 238, "seek": 144600, "start": 1453.0, "end": 1455.0, "text": " Okay, and that's it.", "tokens": [50714, 1033, 11, 293, 300, 311, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 239, "seek": 144600, "start": 1455.0, "end": 1458.0, "text": " There's really nothing more to graphing vectors in three dimensions.", "tokens": [50814, 821, 311, 534, 1825, 544, 281, 1295, 79, 571, 18875, 294, 1045, 12819, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 240, "seek": 144600, "start": 1458.0, "end": 1461.0, "text": " I don't think you'll be asked to do that very often.", "tokens": [50964, 286, 500, 380, 519, 291, 603, 312, 2351, 281, 360, 300, 588, 2049, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 241, "seek": 144600, "start": 1461.0, "end": 1468.0, "text": " But vectors with three components behave exactly the same as vectors with three components.", "tokens": [51114, 583, 18875, 365, 1045, 6677, 15158, 2293, 264, 912, 382, 18875, 365, 1045, 6677, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 242, "seek": 144600, "start": 1468.0, "end": 1473.0, "text": " Everything we learned for vectors with two components applies to vectors with three components,", "tokens": [51464, 5471, 321, 3264, 337, 18875, 365, 732, 6677, 13165, 281, 18875, 365, 1045, 6677, 11, 51714], "temperature": 0.0, "avg_logprob": -0.05840607612363754, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.011330020613968372}, {"id": 243, "seek": 147300, "start": 1473.0, "end": 1482.0, "text": " including addition, subtraction, multiplying by scalar, the translational property of vectors, so on and so forth.", "tokens": [50364, 3009, 4500, 11, 16390, 313, 11, 30955, 538, 39684, 11, 264, 5105, 1478, 4707, 295, 18875, 11, 370, 322, 293, 370, 5220, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 244, "seek": 147300, "start": 1482.0, "end": 1485.0, "text": " Okay, see you in the next video.", "tokens": [50814, 1033, 11, 536, 291, 294, 264, 958, 960, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 245, "seek": 147300, "start": 1485.0, "end": 1487.0, "text": " Oh, one thing real quick.", "tokens": [50964, 876, 11, 472, 551, 957, 1702, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 246, "seek": 147300, "start": 1487.0, "end": 1492.0, "text": " If you've never seen three-dimensional axes before, let me just explain that to you.", "tokens": [51064, 759, 291, 600, 1128, 1612, 1045, 12, 18759, 35387, 949, 11, 718, 385, 445, 2903, 300, 281, 291, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 247, "seek": 147300, "start": 1492.0, "end": 1496.0, "text": " Why they look the way they do.", "tokens": [51314, 1545, 436, 574, 264, 636, 436, 360, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 248, "seek": 147300, "start": 1496.0, "end": 1500.0, "text": " It's as if our whole life when we've been looking at the xy plane,", "tokens": [51514, 467, 311, 382, 498, 527, 1379, 993, 562, 321, 600, 668, 1237, 412, 264, 2031, 88, 5720, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08315865847529197, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.008983656764030457}, {"id": 249, "seek": 150000, "start": 1500.0, "end": 1507.0, "text": " it's as if we've been looking straight down the z axis.", "tokens": [50364, 309, 311, 382, 498, 321, 600, 668, 1237, 2997, 760, 264, 710, 10298, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 250, "seek": 150000, "start": 1507.0, "end": 1512.0, "text": " Straight down the z axis.", "tokens": [50714, 26908, 760, 264, 710, 10298, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 251, "seek": 150000, "start": 1512.0, "end": 1518.0, "text": " So if we had an xy plane,", "tokens": [50964, 407, 498, 321, 632, 364, 2031, 88, 5720, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 252, "seek": 150000, "start": 1518.0, "end": 1521.0, "text": " here's x and y,", "tokens": [51264, 510, 311, 2031, 293, 288, 11, 51414], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 253, "seek": 150000, "start": 1521.0, "end": 1524.0, "text": " z would be at the origin coming out straight at us.", "tokens": [51414, 710, 576, 312, 412, 264, 4957, 1348, 484, 2997, 412, 505, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 254, "seek": 150000, "start": 1524.0, "end": 1529.0, "text": " And because it's coming out straight at us, we really, we can't see it.", "tokens": [51564, 400, 570, 309, 311, 1348, 484, 2997, 412, 505, 11, 321, 534, 11, 321, 393, 380, 536, 309, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10712635517120361, "compression_ratio": 1.6802721088435375, "no_speech_prob": 0.007576504722237587}, {"id": 255, "seek": 152900, "start": 1529.0, "end": 1535.0, "text": " If it were at even a slight angle, we would see it like this.", "tokens": [50364, 759, 309, 645, 412, 754, 257, 4036, 5802, 11, 321, 576, 536, 309, 411, 341, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07468103433584238, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005192666430957615}, {"id": 256, "seek": 152900, "start": 1535.0, "end": 1539.0, "text": " This would be z coming out at us.", "tokens": [50664, 639, 576, 312, 710, 1348, 484, 412, 505, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07468103433584238, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005192666430957615}, {"id": 257, "seek": 152900, "start": 1539.0, "end": 1541.0, "text": " And that's exactly what we have here.", "tokens": [50864, 400, 300, 311, 2293, 437, 321, 362, 510, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07468103433584238, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005192666430957615}, {"id": 258, "seek": 152900, "start": 1541.0, "end": 1543.0, "text": " We've just chosen to rotate things.", "tokens": [50964, 492, 600, 445, 8614, 281, 13121, 721, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07468103433584238, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005192666430957615}, {"id": 259, "seek": 152900, "start": 1543.0, "end": 1550.0, "text": " So you could see that the x kind of swings down and y swings down into its place and z rotates up.", "tokens": [51064, 407, 291, 727, 536, 300, 264, 2031, 733, 295, 32386, 760, 293, 288, 32386, 760, 666, 1080, 1081, 293, 710, 42133, 493, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07468103433584238, "compression_ratio": 1.5141242937853108, "no_speech_prob": 0.0005192666430957615}, {"id": 260, "seek": 155000, "start": 1550.0, "end": 1561.0, "text": " So things are rotated, but it's really, it should seem familiar in that sense once you realize what's going on.", "tokens": [50364, 407, 721, 366, 42146, 11, 457, 309, 311, 534, 11, 309, 820, 1643, 4963, 294, 300, 2020, 1564, 291, 4325, 437, 311, 516, 322, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1095497835250128, "compression_ratio": 1.4593301435406698, "no_speech_prob": 0.0035934040788561106}, {"id": 261, "seek": 155000, "start": 1561.0, "end": 1565.0, "text": " Okay, anyways, I hope that was helpful. I'll see you in the next video.", "tokens": [50914, 1033, 11, 13448, 11, 286, 1454, 300, 390, 4961, 13, 286, 603, 536, 291, 294, 264, 958, 960, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1095497835250128, "compression_ratio": 1.4593301435406698, "no_speech_prob": 0.0035934040788561106}, {"id": 262, "seek": 155000, "start": 1565.0, "end": 1571.0, "text": " Let's talk about finding the length of a vector that has three components.", "tokens": [51114, 961, 311, 751, 466, 5006, 264, 4641, 295, 257, 8062, 300, 575, 1045, 6677, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1095497835250128, "compression_ratio": 1.4593301435406698, "no_speech_prob": 0.0035934040788561106}, {"id": 263, "seek": 155000, "start": 1571.0, "end": 1577.0, "text": " So here we have the vector v equal to 1, 4, 3.", "tokens": [51414, 407, 510, 321, 362, 264, 8062, 371, 2681, 281, 502, 11, 1017, 11, 805, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1095497835250128, "compression_ratio": 1.4593301435406698, "no_speech_prob": 0.0035934040788561106}, {"id": 264, "seek": 157700, "start": 1577.0, "end": 1582.0, "text": " And I want to find its length.", "tokens": [50364, 400, 286, 528, 281, 915, 1080, 4641, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08630704268431053, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0018384645227342844}, {"id": 265, "seek": 157700, "start": 1582.0, "end": 1586.0, "text": " In a previous video, we've graphed this vector.", "tokens": [50614, 682, 257, 3894, 960, 11, 321, 600, 4295, 292, 341, 8062, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08630704268431053, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0018384645227342844}, {"id": 266, "seek": 157700, "start": 1586.0, "end": 1594.0, "text": " And I want to point your attention to the fact that we have a right triangle here.", "tokens": [50814, 400, 286, 528, 281, 935, 428, 3202, 281, 264, 1186, 300, 321, 362, 257, 558, 13369, 510, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08630704268431053, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0018384645227342844}, {"id": 267, "seek": 157700, "start": 1594.0, "end": 1602.0, "text": " This dashed line and this dashed line form the base and the height of the triangle.", "tokens": [51214, 639, 8240, 292, 1622, 293, 341, 8240, 292, 1622, 1254, 264, 3096, 293, 264, 6681, 295, 264, 13369, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08630704268431053, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0018384645227342844}, {"id": 268, "seek": 157700, "start": 1602.0, "end": 1606.0, "text": " And the vector is the hypotenuse.", "tokens": [51614, 400, 264, 8062, 307, 264, 7420, 21990, 438, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08630704268431053, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0018384645227342844}, {"id": 269, "seek": 160600, "start": 1606.0, "end": 1613.0, "text": " And I'll draw in a little square symbol so maybe you can see it better.", "tokens": [50364, 400, 286, 603, 2642, 294, 257, 707, 3732, 5986, 370, 1310, 291, 393, 536, 309, 1101, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07539569630342371, "compression_ratio": 1.4678362573099415, "no_speech_prob": 0.0007553527830168605}, {"id": 270, "seek": 160600, "start": 1613.0, "end": 1623.0, "text": " There's a triangle there. It's a little bit at an angle to us, but it's definitely a right triangle sitting there.", "tokens": [50714, 821, 311, 257, 13369, 456, 13, 467, 311, 257, 707, 857, 412, 364, 5802, 281, 505, 11, 457, 309, 311, 2138, 257, 558, 13369, 3798, 456, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07539569630342371, "compression_ratio": 1.4678362573099415, "no_speech_prob": 0.0007553527830168605}, {"id": 271, "seek": 160600, "start": 1623.0, "end": 1630.0, "text": " Okay, so knowing that we can just apply the Pythagorean theorem.", "tokens": [51214, 1033, 11, 370, 5276, 300, 321, 393, 445, 3079, 264, 9953, 392, 559, 25885, 20904, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07539569630342371, "compression_ratio": 1.4678362573099415, "no_speech_prob": 0.0007553527830168605}, {"id": 272, "seek": 163000, "start": 1630.0, "end": 1645.0, "text": " And the length of v is simply the square root of the base of that triangle squared plus the height of the triangle squared.", "tokens": [50364, 400, 264, 4641, 295, 371, 307, 2935, 264, 3732, 5593, 295, 264, 3096, 295, 300, 13369, 8889, 1804, 264, 6681, 295, 264, 13369, 8889, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05639940721017343, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0012065260671079159}, {"id": 273, "seek": 163000, "start": 1645.0, "end": 1651.0, "text": " So now all we have to do is figure out what is the base and what is the height of that triangle.", "tokens": [51114, 407, 586, 439, 321, 362, 281, 360, 307, 2573, 484, 437, 307, 264, 3096, 293, 437, 307, 264, 6681, 295, 300, 13369, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05639940721017343, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0012065260671079159}, {"id": 274, "seek": 165100, "start": 1651.0, "end": 1657.0, "text": " Well the height is easy. The height is how far we go up in z.", "tokens": [50364, 1042, 264, 6681, 307, 1858, 13, 440, 6681, 307, 577, 1400, 321, 352, 493, 294, 710, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11248191665200626, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009125051088631153}, {"id": 275, "seek": 165100, "start": 1657.0, "end": 1660.0, "text": " And we're just going up three units in z.", "tokens": [50664, 400, 321, 434, 445, 516, 493, 1045, 6815, 294, 710, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11248191665200626, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009125051088631153}, {"id": 276, "seek": 165100, "start": 1660.0, "end": 1664.0, "text": " So the height is just simply three.", "tokens": [50814, 407, 264, 6681, 307, 445, 2935, 1045, 13, 51014], "temperature": 0.0, "avg_logprob": -0.11248191665200626, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009125051088631153}, {"id": 277, "seek": 165100, "start": 1664.0, "end": 1673.0, "text": " Okay, take care of that. This is b squared plus three squared.", "tokens": [51014, 1033, 11, 747, 1127, 295, 300, 13, 639, 307, 272, 8889, 1804, 1045, 8889, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11248191665200626, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009125051088631153}, {"id": 278, "seek": 165100, "start": 1673.0, "end": 1678.0, "text": " Now what about b?", "tokens": [51464, 823, 437, 466, 272, 30, 51714], "temperature": 0.0, "avg_logprob": -0.11248191665200626, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009125051088631153}, {"id": 279, "seek": 167800, "start": 1678.0, "end": 1690.0, "text": " Well if you look closely you'll notice that there's another right triangle right here.", "tokens": [50364, 1042, 498, 291, 574, 8185, 291, 603, 3449, 300, 456, 311, 1071, 558, 13369, 558, 510, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07616079330444336, "compression_ratio": 1.4420289855072463, "no_speech_prob": 0.0009696846827864647}, {"id": 280, "seek": 167800, "start": 1690.0, "end": 1701.0, "text": " And that triangle, or what I should say is b is the hypotenuse of this triangle that I've filled in with yellow.", "tokens": [50964, 400, 300, 13369, 11, 420, 437, 286, 820, 584, 307, 272, 307, 264, 7420, 21990, 438, 295, 341, 13369, 300, 286, 600, 6412, 294, 365, 5566, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07616079330444336, "compression_ratio": 1.4420289855072463, "no_speech_prob": 0.0009696846827864647}, {"id": 281, "seek": 170100, "start": 1701.0, "end": 1715.0, "text": " In fact let me pull that triangle out.", "tokens": [50364, 682, 1186, 718, 385, 2235, 300, 13369, 484, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09261555590872038, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.008984738029539585}, {"id": 282, "seek": 170100, "start": 1715.0, "end": 1718.0, "text": " So this is the triangle I'm talking about.", "tokens": [51064, 407, 341, 307, 264, 13369, 286, 478, 1417, 466, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09261555590872038, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.008984738029539585}, {"id": 283, "seek": 170100, "start": 1718.0, "end": 1723.0, "text": " b is the hypotenuse.", "tokens": [51214, 272, 307, 264, 7420, 21990, 438, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09261555590872038, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.008984738029539585}, {"id": 284, "seek": 170100, "start": 1723.0, "end": 1727.0, "text": " Once again for clarity, this is the triangle that I've pulled out.", "tokens": [51464, 3443, 797, 337, 16992, 11, 341, 307, 264, 13369, 300, 286, 600, 7373, 484, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09261555590872038, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.008984738029539585}, {"id": 285, "seek": 170100, "start": 1727.0, "end": 1730.0, "text": " It's this triangle here.", "tokens": [51664, 467, 311, 341, 13369, 510, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09261555590872038, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.008984738029539585}, {"id": 286, "seek": 173000, "start": 1730.0, "end": 1733.0, "text": " Okay well what are the sides of this triangle?", "tokens": [50364, 1033, 731, 437, 366, 264, 4881, 295, 341, 13369, 30, 50514], "temperature": 0.0, "avg_logprob": -0.07104818961199592, "compression_ratio": 1.5304878048780488, "no_speech_prob": 0.0008558597764931619}, {"id": 287, "seek": 173000, "start": 1733.0, "end": 1740.0, "text": " We know that we moved over one there and four here.", "tokens": [50514, 492, 458, 300, 321, 4259, 670, 472, 456, 293, 1451, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07104818961199592, "compression_ratio": 1.5304878048780488, "no_speech_prob": 0.0008558597764931619}, {"id": 288, "seek": 173000, "start": 1740.0, "end": 1744.0, "text": " So we can just apply the Pythagorean theorem again.", "tokens": [50864, 407, 321, 393, 445, 3079, 264, 9953, 392, 559, 25885, 20904, 797, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07104818961199592, "compression_ratio": 1.5304878048780488, "no_speech_prob": 0.0008558597764931619}, {"id": 289, "seek": 173000, "start": 1744.0, "end": 1759.0, "text": " And we can say that b now is equal to one squared, the square root of one squared plus four squared.", "tokens": [51064, 400, 321, 393, 584, 300, 272, 586, 307, 2681, 281, 472, 8889, 11, 264, 3732, 5593, 295, 472, 8889, 1804, 1451, 8889, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07104818961199592, "compression_ratio": 1.5304878048780488, "no_speech_prob": 0.0008558597764931619}, {"id": 290, "seek": 175900, "start": 1759.0, "end": 1763.0, "text": " That's what b is.", "tokens": [50364, 663, 311, 437, 272, 307, 13, 50564], "temperature": 0.0, "avg_logprob": -0.051585893241726626, "compression_ratio": 1.3982300884955752, "no_speech_prob": 0.0010986943962052464}, {"id": 291, "seek": 175900, "start": 1763.0, "end": 1774.0, "text": " Well now that we have a term for b, let's go ahead and plug that in.", "tokens": [50564, 1042, 586, 300, 321, 362, 257, 1433, 337, 272, 11, 718, 311, 352, 2286, 293, 5452, 300, 294, 13, 51114], "temperature": 0.0, "avg_logprob": -0.051585893241726626, "compression_ratio": 1.3982300884955752, "no_speech_prob": 0.0010986943962052464}, {"id": 292, "seek": 175900, "start": 1774.0, "end": 1784.0, "text": " So we have b which is the square root of one squared plus four squared.", "tokens": [51114, 407, 321, 362, 272, 597, 307, 264, 3732, 5593, 295, 472, 8889, 1804, 1451, 8889, 13, 51614], "temperature": 0.0, "avg_logprob": -0.051585893241726626, "compression_ratio": 1.3982300884955752, "no_speech_prob": 0.0010986943962052464}, {"id": 293, "seek": 178400, "start": 1784.0, "end": 1789.0, "text": " And now b is being squared.", "tokens": [50364, 400, 586, 272, 307, 885, 8889, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10124835428201927, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0041985404677689075}, {"id": 294, "seek": 178400, "start": 1789.0, "end": 1801.0, "text": " And then plus three squared.", "tokens": [50614, 400, 550, 1804, 1045, 8889, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10124835428201927, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0041985404677689075}, {"id": 295, "seek": 178400, "start": 1801.0, "end": 1803.0, "text": " Well something really nice just happened.", "tokens": [51214, 1042, 746, 534, 1481, 445, 2011, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10124835428201927, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0041985404677689075}, {"id": 296, "seek": 178400, "start": 1803.0, "end": 1806.0, "text": " Look at, we have a square root being squared.", "tokens": [51314, 2053, 412, 11, 321, 362, 257, 3732, 5593, 885, 8889, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10124835428201927, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0041985404677689075}, {"id": 297, "seek": 178400, "start": 1806.0, "end": 1811.0, "text": " And so that square root just simply goes away.", "tokens": [51464, 400, 370, 300, 3732, 5593, 445, 2935, 1709, 1314, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10124835428201927, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0041985404677689075}, {"id": 298, "seek": 181100, "start": 1811.0, "end": 1820.0, "text": " So this whole thing simplifies to the square root of one squared plus four squared", "tokens": [50364, 407, 341, 1379, 551, 6883, 11221, 281, 264, 3732, 5593, 295, 472, 8889, 1804, 1451, 8889, 50814], "temperature": 0.0, "avg_logprob": -0.08100288413291754, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0005192887620069087}, {"id": 299, "seek": 181100, "start": 1820.0, "end": 1830.0, "text": " because that square root went away plus three squared.", "tokens": [50814, 570, 300, 3732, 5593, 1437, 1314, 1804, 1045, 8889, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08100288413291754, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0005192887620069087}, {"id": 300, "seek": 181100, "start": 1830.0, "end": 1835.0, "text": " Now compare that to the components of v.", "tokens": [51314, 823, 6794, 300, 281, 264, 6677, 295, 371, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08100288413291754, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0005192887620069087}, {"id": 301, "seek": 183500, "start": 1835.0, "end": 1847.0, "text": " You'll see that the length of v is simply the square root of the sum of the squares of the components.", "tokens": [50364, 509, 603, 536, 300, 264, 4641, 295, 371, 307, 2935, 264, 3732, 5593, 295, 264, 2408, 295, 264, 19368, 295, 264, 6677, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05113845986205262, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.002800715621560812}, {"id": 302, "seek": 183500, "start": 1847.0, "end": 1851.0, "text": " And that's kind of a lot of words to say all at once.", "tokens": [50964, 400, 300, 311, 733, 295, 257, 688, 295, 2283, 281, 584, 439, 412, 1564, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05113845986205262, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.002800715621560812}, {"id": 303, "seek": 183500, "start": 1851.0, "end": 1858.0, "text": " But we just take each component, we square it, we add them together and we take the square root.", "tokens": [51164, 583, 321, 445, 747, 1184, 6542, 11, 321, 3732, 309, 11, 321, 909, 552, 1214, 293, 321, 747, 264, 3732, 5593, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05113845986205262, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.002800715621560812}, {"id": 304, "seek": 183500, "start": 1858.0, "end": 1863.0, "text": " Okay let's do another example.", "tokens": [51514, 1033, 718, 311, 360, 1071, 1365, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05113845986205262, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.002800715621560812}, {"id": 305, "seek": 186300, "start": 1863.0, "end": 1880.0, "text": " Let's say we have u is equal to, I don't know one, negative six, four.", "tokens": [50364, 961, 311, 584, 321, 362, 344, 307, 2681, 281, 11, 286, 500, 380, 458, 472, 11, 3671, 2309, 11, 1451, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08925383824568528, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0010161986574530602}, {"id": 306, "seek": 186300, "start": 1880.0, "end": 1885.0, "text": " What is the length of u?", "tokens": [51214, 708, 307, 264, 4641, 295, 344, 30, 51464], "temperature": 0.0, "avg_logprob": -0.08925383824568528, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0010161986574530602}, {"id": 307, "seek": 186300, "start": 1885.0, "end": 1889.0, "text": " Well we don't need to go through the whole process that we went through.", "tokens": [51464, 1042, 321, 500, 380, 643, 281, 352, 807, 264, 1379, 1399, 300, 321, 1437, 807, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08925383824568528, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0010161986574530602}, {"id": 308, "seek": 188900, "start": 1889.0, "end": 1897.0, "text": " Just remember, as long as we understand what we did we can just remember that the end result is just going to be,", "tokens": [50364, 1449, 1604, 11, 382, 938, 382, 321, 1223, 437, 321, 630, 321, 393, 445, 1604, 300, 264, 917, 1874, 307, 445, 516, 281, 312, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10650382103858055, "compression_ratio": 1.7094972067039107, "no_speech_prob": 0.09805707633495331}, {"id": 309, "seek": 188900, "start": 1897.0, "end": 1905.0, "text": " we take each component, we square it, we add them all together and we take the square root.", "tokens": [50764, 321, 747, 1184, 6542, 11, 321, 3732, 309, 11, 321, 909, 552, 439, 1214, 293, 321, 747, 264, 3732, 5593, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10650382103858055, "compression_ratio": 1.7094972067039107, "no_speech_prob": 0.09805707633495331}, {"id": 310, "seek": 188900, "start": 1905.0, "end": 1910.0, "text": " So simply the square root of one squared plus negative six squared plus four squared.", "tokens": [51164, 407, 2935, 264, 3732, 5593, 295, 472, 8889, 1804, 3671, 2309, 8889, 1804, 1451, 8889, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10650382103858055, "compression_ratio": 1.7094972067039107, "no_speech_prob": 0.09805707633495331}, {"id": 311, "seek": 188900, "start": 1910.0, "end": 1913.0, "text": " And that's it.", "tokens": [51414, 400, 300, 311, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10650382103858055, "compression_ratio": 1.7094972067039107, "no_speech_prob": 0.09805707633495331}, {"id": 312, "seek": 191300, "start": 1913.0, "end": 1922.0, "text": " If you want we can do another example.", "tokens": [50364, 759, 291, 528, 321, 393, 360, 1071, 1365, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1074270551854914, "compression_ratio": 1.0136986301369864, "no_speech_prob": 0.008577044121921062}, {"id": 313, "seek": 191300, "start": 1922.0, "end": 1932.0, "text": " How about negative three zero nine?", "tokens": [50814, 1012, 466, 3671, 1045, 4018, 4949, 30, 51314], "temperature": 0.0, "avg_logprob": -0.1074270551854914, "compression_ratio": 1.0136986301369864, "no_speech_prob": 0.008577044121921062}, {"id": 314, "seek": 193200, "start": 1932.0, "end": 1950.0, "text": " So the length of w is equal to, what am I doing?", "tokens": [50364, 407, 264, 4641, 295, 261, 307, 2681, 281, 11, 437, 669, 286, 884, 30, 51264], "temperature": 0.0, "avg_logprob": -0.0894561064870734, "compression_ratio": 1.396039603960396, "no_speech_prob": 0.0051394496113061905}, {"id": 315, "seek": 193200, "start": 1950.0, "end": 1959.0, "text": " It's equal to the square root of negative three squared plus zero squared plus nine squared.", "tokens": [51264, 467, 311, 2681, 281, 264, 3732, 5593, 295, 3671, 1045, 8889, 1804, 4018, 8889, 1804, 4949, 8889, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0894561064870734, "compression_ratio": 1.396039603960396, "no_speech_prob": 0.0051394496113061905}, {"id": 316, "seek": 195900, "start": 1959.0, "end": 1964.0, "text": " And there you have it. There's the length of a vector with three components.", "tokens": [50364, 400, 456, 291, 362, 309, 13, 821, 311, 264, 4641, 295, 257, 8062, 365, 1045, 6677, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0828143736211265, "compression_ratio": 1.4653465346534653, "no_speech_prob": 0.02800036408007145}, {"id": 317, "seek": 195900, "start": 1964.0, "end": 1970.0, "text": " If you're wondering what happens, if you have more than three components, let me show you that quickly.", "tokens": [50614, 759, 291, 434, 6359, 437, 2314, 11, 498, 291, 362, 544, 813, 1045, 6677, 11, 718, 385, 855, 291, 300, 2661, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0828143736211265, "compression_ratio": 1.4653465346534653, "no_speech_prob": 0.02800036408007145}, {"id": 318, "seek": 195900, "start": 1970.0, "end": 1987.0, "text": " And I might make a separate video about this, but let's say we had something like v is equal to v1, v2, v3, and v4.", "tokens": [50914, 400, 286, 1062, 652, 257, 4994, 960, 466, 341, 11, 457, 718, 311, 584, 321, 632, 746, 411, 371, 307, 2681, 281, 371, 16, 11, 371, 17, 11, 371, 18, 11, 293, 371, 19, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0828143736211265, "compression_ratio": 1.4653465346534653, "no_speech_prob": 0.02800036408007145}, {"id": 319, "seek": 198700, "start": 1987.0, "end": 1992.0, "text": " So now we have four components.", "tokens": [50364, 407, 586, 321, 362, 1451, 6677, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06799384086362777, "compression_ratio": 1.101123595505618, "no_speech_prob": 0.008845909498631954}, {"id": 320, "seek": 198700, "start": 1992.0, "end": 2004.0, "text": " The length of v, you might be able to guess what it's going to be,", "tokens": [50614, 440, 4641, 295, 371, 11, 291, 1062, 312, 1075, 281, 2041, 437, 309, 311, 516, 281, 312, 11, 51214], "temperature": 0.0, "avg_logprob": -0.06799384086362777, "compression_ratio": 1.101123595505618, "no_speech_prob": 0.008845909498631954}, {"id": 321, "seek": 200400, "start": 2004.0, "end": 2020.0, "text": " the square root of v1 squared plus v2 squared plus v3 squared plus v4 squared.", "tokens": [50364, 264, 3732, 5593, 295, 371, 16, 8889, 1804, 371, 17, 8889, 1804, 371, 18, 8889, 1804, 371, 19, 8889, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08025732040405273, "compression_ratio": 1.6733333333333333, "no_speech_prob": 0.10085582733154297}, {"id": 322, "seek": 200400, "start": 2020.0, "end": 2023.0, "text": " And if you had five components, you'd do the same thing.", "tokens": [51164, 400, 498, 291, 632, 1732, 6677, 11, 291, 1116, 360, 264, 912, 551, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08025732040405273, "compression_ratio": 1.6733333333333333, "no_speech_prob": 0.10085582733154297}, {"id": 323, "seek": 200400, "start": 2023.0, "end": 2027.0, "text": " You'd just add, tack that fifth one on at the end.", "tokens": [51314, 509, 1116, 445, 909, 11, 9426, 300, 9266, 472, 322, 412, 264, 917, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08025732040405273, "compression_ratio": 1.6733333333333333, "no_speech_prob": 0.10085582733154297}, {"id": 324, "seek": 200400, "start": 2027.0, "end": 2031.0, "text": " If you had six, you would do the same thing, just tack those on.", "tokens": [51514, 759, 291, 632, 2309, 11, 291, 576, 360, 264, 912, 551, 11, 445, 9426, 729, 322, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08025732040405273, "compression_ratio": 1.6733333333333333, "no_speech_prob": 0.10085582733154297}, {"id": 325, "seek": 203100, "start": 2031.0, "end": 2037.0, "text": " So that's the vector length for vectors with more than two components.", "tokens": [50364, 407, 300, 311, 264, 8062, 4641, 337, 18875, 365, 544, 813, 732, 6677, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07992400364442305, "compression_ratio": 1.675257731958763, "no_speech_prob": 0.0019266644958406687}, {"id": 326, "seek": 203100, "start": 2037.0, "end": 2042.0, "text": " Okay, see you in the next video.", "tokens": [50664, 1033, 11, 536, 291, 294, 264, 958, 960, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07992400364442305, "compression_ratio": 1.675257731958763, "no_speech_prob": 0.0019266644958406687}, {"id": 327, "seek": 203100, "start": 2042.0, "end": 2046.0, "text": " Okay, here we have three vectors, v, u, and w.", "tokens": [50914, 1033, 11, 510, 321, 362, 1045, 18875, 11, 371, 11, 344, 11, 293, 261, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07992400364442305, "compression_ratio": 1.675257731958763, "no_speech_prob": 0.0019266644958406687}, {"id": 328, "seek": 203100, "start": 2046.0, "end": 2051.0, "text": " And so far we've looked at vectors with two components,", "tokens": [51114, 400, 370, 1400, 321, 600, 2956, 412, 18875, 365, 732, 6677, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07992400364442305, "compression_ratio": 1.675257731958763, "no_speech_prob": 0.0019266644958406687}, {"id": 329, "seek": 203100, "start": 2051.0, "end": 2060.0, "text": " and when we were graphing them or thinking about them visually, we thought about them in the plane, in two dimensions.", "tokens": [51364, 293, 562, 321, 645, 1295, 79, 571, 552, 420, 1953, 466, 552, 19622, 11, 321, 1194, 466, 552, 294, 264, 5720, 11, 294, 732, 12819, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07992400364442305, "compression_ratio": 1.675257731958763, "no_speech_prob": 0.0019266644958406687}, {"id": 330, "seek": 206000, "start": 2061.0, "end": 2069.0, "text": " When we had a vector with three components, we graphed this in three dimensions.", "tokens": [50414, 1133, 321, 632, 257, 8062, 365, 1045, 6677, 11, 321, 4295, 292, 341, 294, 1045, 12819, 13, 50814], "temperature": 0.0, "avg_logprob": -0.112152754091749, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.002050632843747735}, {"id": 331, "seek": 206000, "start": 2069.0, "end": 2089.0, "text": " And in fact, we even labeled this as the x, y, and z component corresponding to the x, y, and z axes.", "tokens": [50814, 400, 294, 1186, 11, 321, 754, 21335, 341, 382, 264, 2031, 11, 288, 11, 293, 710, 6542, 11760, 281, 264, 2031, 11, 288, 11, 293, 710, 35387, 13, 51814], "temperature": 0.0, "avg_logprob": -0.112152754091749, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.002050632843747735}, {"id": 332, "seek": 208900, "start": 2090.0, "end": 2099.0, "text": " When we go to higher dimensions, dimensions greater than three,", "tokens": [50414, 1133, 321, 352, 281, 2946, 12819, 11, 12819, 5044, 813, 1045, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1113654300570488, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.0001584344863658771}, {"id": 333, "seek": 208900, "start": 2099.0, "end": 2104.0, "text": " so here we have a vector w with n dimensions.", "tokens": [50864, 370, 510, 321, 362, 257, 8062, 261, 365, 297, 12819, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1113654300570488, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.0001584344863658771}, {"id": 334, "seek": 208900, "start": 2104.0, "end": 2109.0, "text": " Let's say, for example, that n is four.", "tokens": [51114, 961, 311, 584, 11, 337, 1365, 11, 300, 297, 307, 1451, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1113654300570488, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.0001584344863658771}, {"id": 335, "seek": 208900, "start": 2109.0, "end": 2112.0, "text": " So this vector has four components.", "tokens": [51364, 407, 341, 8062, 575, 1451, 6677, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1113654300570488, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.0001584344863658771}, {"id": 336, "seek": 208900, "start": 2112.0, "end": 2116.0, "text": " Now we don't try and graph this anymore.", "tokens": [51514, 823, 321, 500, 380, 853, 293, 4295, 341, 3602, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1113654300570488, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.0001584344863658771}, {"id": 337, "seek": 211600, "start": 2116.0, "end": 2122.0, "text": " Anytime a vector has more than three components, we really can't graph it.", "tokens": [50364, 39401, 257, 8062, 575, 544, 813, 1045, 6677, 11, 321, 534, 393, 380, 4295, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09349001326212068, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.0001795205462258309}, {"id": 338, "seek": 211600, "start": 2122.0, "end": 2123.0, "text": " We can't visualize it.", "tokens": [50664, 492, 393, 380, 23273, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09349001326212068, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.0001795205462258309}, {"id": 339, "seek": 211600, "start": 2123.0, "end": 2129.0, "text": " We don't have a good way to graph four or five or six dimensions.", "tokens": [50714, 492, 500, 380, 362, 257, 665, 636, 281, 4295, 1451, 420, 1732, 420, 2309, 12819, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09349001326212068, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.0001795205462258309}, {"id": 340, "seek": 211600, "start": 2129.0, "end": 2133.0, "text": " But the beauty of linear algebra and the power of linear algebra", "tokens": [51014, 583, 264, 6643, 295, 8213, 21989, 293, 264, 1347, 295, 8213, 21989, 51214], "temperature": 0.0, "avg_logprob": -0.09349001326212068, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.0001795205462258309}, {"id": 341, "seek": 211600, "start": 2133.0, "end": 2141.0, "text": " is the fact that we can take what we know from here and from here, for that matter,", "tokens": [51214, 307, 264, 1186, 300, 321, 393, 747, 437, 321, 458, 490, 510, 293, 490, 510, 11, 337, 300, 1871, 11, 51614], "temperature": 0.0, "avg_logprob": -0.09349001326212068, "compression_ratio": 1.616580310880829, "no_speech_prob": 0.0001795205462258309}, {"id": 342, "seek": 214100, "start": 2141.0, "end": 2152.0, "text": " and we can push those concepts to higher dimensions to four dimensions, five dimensions, a hundred dimensions, a thousand dimensions.", "tokens": [50364, 293, 321, 393, 2944, 729, 10392, 281, 2946, 12819, 281, 1451, 12819, 11, 1732, 12819, 11, 257, 3262, 12819, 11, 257, 4714, 12819, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12926936149597168, "compression_ratio": 1.582191780821918, "no_speech_prob": 0.00039818722871132195}, {"id": 343, "seek": 214100, "start": 2152.0, "end": 2164.0, "text": " You know, we don't have to graph things, but the tools that we've created will still apply.", "tokens": [50914, 509, 458, 11, 321, 500, 380, 362, 281, 4295, 721, 11, 457, 264, 3873, 300, 321, 600, 2942, 486, 920, 3079, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12926936149597168, "compression_ratio": 1.582191780821918, "no_speech_prob": 0.00039818722871132195}, {"id": 344, "seek": 214100, "start": 2164.0, "end": 2167.0, "text": " Okay.", "tokens": [51514, 1033, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12926936149597168, "compression_ratio": 1.582191780821918, "no_speech_prob": 0.00039818722871132195}, {"id": 345, "seek": 216700, "start": 2167.0, "end": 2173.0, "text": " So let's talk about some technical details here.", "tokens": [50364, 407, 718, 311, 751, 466, 512, 6191, 4365, 510, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09342501197062747, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0002531473874114454}, {"id": 346, "seek": 216700, "start": 2173.0, "end": 2179.0, "text": " One is the fact that vectors are ordered lists of numbers.", "tokens": [50664, 1485, 307, 264, 1186, 300, 18875, 366, 8866, 14511, 295, 3547, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09342501197062747, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0002531473874114454}, {"id": 347, "seek": 216700, "start": 2179.0, "end": 2181.0, "text": " They're ordered lists of components, right?", "tokens": [50964, 814, 434, 8866, 14511, 295, 6677, 11, 558, 30, 51064], "temperature": 0.0, "avg_logprob": -0.09342501197062747, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0002531473874114454}, {"id": 348, "seek": 216700, "start": 2181.0, "end": 2186.0, "text": " First, this vector has the component v1 and then it has v2.", "tokens": [51064, 2386, 11, 341, 8062, 575, 264, 6542, 371, 16, 293, 550, 309, 575, 371, 17, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09342501197062747, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0002531473874114454}, {"id": 349, "seek": 216700, "start": 2186.0, "end": 2191.0, "text": " We already talked about the order, how the order matters.", "tokens": [51314, 492, 1217, 2825, 466, 264, 1668, 11, 577, 264, 1668, 7001, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09342501197062747, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0002531473874114454}, {"id": 350, "seek": 219100, "start": 2191.0, "end": 2201.0, "text": " Well, that means that v is what's called a two-tuple.", "tokens": [50364, 1042, 11, 300, 1355, 300, 371, 307, 437, 311, 1219, 257, 732, 12, 9179, 781, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06675669550895691, "compression_ratio": 1.7191780821917808, "no_speech_prob": 0.00013982020027469844}, {"id": 351, "seek": 219100, "start": 2201.0, "end": 2206.0, "text": " And a tuple is nothing more than an ordered list of elements.", "tokens": [50864, 400, 257, 2604, 781, 307, 1825, 544, 813, 364, 8866, 1329, 295, 4959, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06675669550895691, "compression_ratio": 1.7191780821917808, "no_speech_prob": 0.00013982020027469844}, {"id": 352, "seek": 219100, "start": 2206.0, "end": 2212.0, "text": " v is an ordered list of real numbers, an ordered list of components.", "tokens": [51114, 371, 307, 364, 8866, 1329, 295, 957, 3547, 11, 364, 8866, 1329, 295, 6677, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06675669550895691, "compression_ratio": 1.7191780821917808, "no_speech_prob": 0.00013982020027469844}, {"id": 353, "seek": 219100, "start": 2212.0, "end": 2214.0, "text": " So v is a two-tuple.", "tokens": [51414, 407, 371, 307, 257, 732, 12, 9179, 781, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06675669550895691, "compression_ratio": 1.7191780821917808, "no_speech_prob": 0.00013982020027469844}, {"id": 354, "seek": 219100, "start": 2214.0, "end": 2218.0, "text": " It's a two-tuple because there's two of them.", "tokens": [51514, 467, 311, 257, 732, 12, 9179, 781, 570, 456, 311, 732, 295, 552, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06675669550895691, "compression_ratio": 1.7191780821917808, "no_speech_prob": 0.00013982020027469844}, {"id": 355, "seek": 221800, "start": 2218.0, "end": 2223.0, "text": " Just like u is a three-tuple, it's an ordered list of three components.", "tokens": [50364, 1449, 411, 344, 307, 257, 1045, 12, 9179, 781, 11, 309, 311, 364, 8866, 1329, 295, 1045, 6677, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07664173040817034, "compression_ratio": 1.5, "no_speech_prob": 0.0006070511299185455}, {"id": 356, "seek": 221800, "start": 2223.0, "end": 2228.0, "text": " And w is an n-tuple.", "tokens": [50614, 400, 261, 307, 364, 297, 12, 9179, 781, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07664173040817034, "compression_ratio": 1.5, "no_speech_prob": 0.0006070511299185455}, {"id": 357, "seek": 221800, "start": 2228.0, "end": 2236.0, "text": " It's an ordered list of n-components.", "tokens": [50864, 467, 311, 364, 8866, 1329, 295, 297, 12, 21541, 40496, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07664173040817034, "compression_ratio": 1.5, "no_speech_prob": 0.0006070511299185455}, {"id": 358, "seek": 221800, "start": 2236.0, "end": 2238.0, "text": " Okay.", "tokens": [51264, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07664173040817034, "compression_ratio": 1.5, "no_speech_prob": 0.0006070511299185455}, {"id": 359, "seek": 221800, "start": 2238.0, "end": 2247.0, "text": " Now we have the tools for talking about the definition of rn.", "tokens": [51364, 823, 321, 362, 264, 3873, 337, 1417, 466, 264, 7123, 295, 367, 77, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07664173040817034, "compression_ratio": 1.5, "no_speech_prob": 0.0006070511299185455}, {"id": 360, "seek": 224700, "start": 2247.0, "end": 2259.0, "text": " And rn is really just the set of all n-tuples of real numbers.", "tokens": [50364, 400, 367, 77, 307, 534, 445, 264, 992, 295, 439, 297, 12, 9179, 2622, 295, 957, 3547, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0633151468477751, "compression_ratio": 1.198019801980198, "no_speech_prob": 0.00047282534069381654}, {"id": 361, "seek": 224700, "start": 2259.0, "end": 2269.0, "text": " So, for example, if you have a vector with two components,", "tokens": [50964, 407, 11, 337, 1365, 11, 498, 291, 362, 257, 8062, 365, 732, 6677, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0633151468477751, "compression_ratio": 1.198019801980198, "no_speech_prob": 0.00047282534069381654}, {"id": 362, "seek": 226900, "start": 2269.0, "end": 2277.0, "text": " that is an element of r2.", "tokens": [50364, 300, 307, 364, 4478, 295, 367, 17, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08343112468719482, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.0009697373607195914}, {"id": 363, "seek": 226900, "start": 2277.0, "end": 2282.0, "text": " Because r2 is the set of all two-tuples.", "tokens": [50764, 1436, 367, 17, 307, 264, 992, 295, 439, 732, 12, 9179, 2622, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08343112468719482, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.0009697373607195914}, {"id": 364, "seek": 226900, "start": 2282.0, "end": 2289.0, "text": " Well, v is just one of those two-tuples.", "tokens": [51014, 1042, 11, 371, 307, 445, 472, 295, 729, 732, 12, 9179, 2622, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08343112468719482, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.0009697373607195914}, {"id": 365, "seek": 226900, "start": 2289.0, "end": 2292.0, "text": " So v must be in r2.", "tokens": [51364, 407, 371, 1633, 312, 294, 367, 17, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08343112468719482, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.0009697373607195914}, {"id": 366, "seek": 226900, "start": 2292.0, "end": 2296.0, "text": " And r2, we can loosely think of it as this plane.", "tokens": [51514, 400, 367, 17, 11, 321, 393, 37966, 519, 295, 309, 382, 341, 5720, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08343112468719482, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.0009697373607195914}, {"id": 367, "seek": 229600, "start": 2296.0, "end": 2299.0, "text": " I mean, we haven't defined what a dimension is,", "tokens": [50364, 286, 914, 11, 321, 2378, 380, 7642, 437, 257, 10139, 307, 11, 50514], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 368, "seek": 229600, "start": 2299.0, "end": 2302.0, "text": " but we can think of it as the two-dimensional plane.", "tokens": [50514, 457, 321, 393, 519, 295, 309, 382, 264, 732, 12, 18759, 5720, 13, 50664], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 369, "seek": 229600, "start": 2302.0, "end": 2307.0, "text": " So this is r2.", "tokens": [50664, 407, 341, 307, 367, 17, 13, 50914], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 370, "seek": 229600, "start": 2307.0, "end": 2314.0, "text": " Just like u is an element of r3.", "tokens": [50914, 1449, 411, 344, 307, 364, 4478, 295, 367, 18, 13, 51264], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 371, "seek": 229600, "start": 2314.0, "end": 2319.0, "text": " r3 is all three-tuples of real numbers.", "tokens": [51264, 367, 18, 307, 439, 1045, 12, 9179, 2622, 295, 957, 3547, 13, 51514], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 372, "seek": 229600, "start": 2319.0, "end": 2324.0, "text": " And u just happens to be one of those three-tuples of real numbers.", "tokens": [51514, 400, 344, 445, 2314, 281, 312, 472, 295, 729, 1045, 12, 9179, 2622, 295, 957, 3547, 13, 51764], "temperature": 0.0, "avg_logprob": -0.037275530043102446, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00048784585669636726}, {"id": 373, "seek": 232400, "start": 2324.0, "end": 2327.0, "text": " So u is in r3.", "tokens": [50364, 407, 344, 307, 294, 367, 18, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0893760547041893, "compression_ratio": 1.4360902255639099, "no_speech_prob": 0.0043310560286045074}, {"id": 374, "seek": 232400, "start": 2327.0, "end": 2332.0, "text": " And r3 we can think of as the three dimensions.", "tokens": [50514, 400, 367, 18, 321, 393, 519, 295, 382, 264, 1045, 12819, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0893760547041893, "compression_ratio": 1.4360902255639099, "no_speech_prob": 0.0043310560286045074}, {"id": 375, "seek": 232400, "start": 2332.0, "end": 2335.0, "text": " And again, we haven't formally defined dimension,", "tokens": [50764, 400, 797, 11, 321, 2378, 380, 25983, 7642, 10139, 11, 50914], "temperature": 0.0, "avg_logprob": -0.0893760547041893, "compression_ratio": 1.4360902255639099, "no_speech_prob": 0.0043310560286045074}, {"id": 376, "seek": 232400, "start": 2335.0, "end": 2338.0, "text": " but we can think of it like that.", "tokens": [50914, 457, 321, 393, 519, 295, 309, 411, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0893760547041893, "compression_ratio": 1.4360902255639099, "no_speech_prob": 0.0043310560286045074}, {"id": 377, "seek": 232400, "start": 2338.0, "end": 2349.0, "text": " w, similar to the rest, is an element of rn.", "tokens": [51064, 261, 11, 2531, 281, 264, 1472, 11, 307, 364, 4478, 295, 367, 77, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0893760547041893, "compression_ratio": 1.4360902255639099, "no_speech_prob": 0.0043310560286045074}, {"id": 378, "seek": 234900, "start": 2349.0, "end": 2355.0, "text": " rn is the set of all n-tuples of real numbers.", "tokens": [50364, 367, 77, 307, 264, 992, 295, 439, 297, 12, 9179, 2622, 295, 957, 3547, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 379, "seek": 234900, "start": 2355.0, "end": 2358.0, "text": " w is an n-tuple of real numbers.", "tokens": [50664, 261, 307, 364, 297, 12, 9179, 781, 295, 957, 3547, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 380, "seek": 234900, "start": 2358.0, "end": 2362.0, "text": " So it's in rn.", "tokens": [50814, 407, 309, 311, 294, 367, 77, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 381, "seek": 234900, "start": 2362.0, "end": 2368.0, "text": " w is an element of rn.", "tokens": [51014, 261, 307, 364, 4478, 295, 367, 77, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 382, "seek": 234900, "start": 2368.0, "end": 2371.0, "text": " Okay, so I know this is a lot all at once,", "tokens": [51314, 1033, 11, 370, 286, 458, 341, 307, 257, 688, 439, 412, 1564, 11, 51464], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 383, "seek": 234900, "start": 2371.0, "end": 2375.0, "text": " but really what's important here is this notation.", "tokens": [51464, 457, 534, 437, 311, 1021, 510, 307, 341, 24657, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 384, "seek": 234900, "start": 2375.0, "end": 2377.0, "text": " To me, that's what's important.", "tokens": [51664, 1407, 385, 11, 300, 311, 437, 311, 1021, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07816580975993295, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.0011694647837430239}, {"id": 385, "seek": 237700, "start": 2377.0, "end": 2379.0, "text": " This is going to come up all the time.", "tokens": [50364, 639, 307, 516, 281, 808, 493, 439, 264, 565, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 386, "seek": 237700, "start": 2379.0, "end": 2382.0, "text": " We're going to use it throughout the rest of the course.", "tokens": [50464, 492, 434, 516, 281, 764, 309, 3710, 264, 1472, 295, 264, 1164, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 387, "seek": 237700, "start": 2382.0, "end": 2384.0, "text": " And if it helps you remember,", "tokens": [50614, 400, 498, 309, 3665, 291, 1604, 11, 50714], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 388, "seek": 237700, "start": 2384.0, "end": 2386.0, "text": " just remember that the number up here", "tokens": [50714, 445, 1604, 300, 264, 1230, 493, 510, 50814], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 389, "seek": 237700, "start": 2386.0, "end": 2391.0, "text": " is going to be the same as the number of components.", "tokens": [50814, 307, 516, 281, 312, 264, 912, 382, 264, 1230, 295, 6677, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 390, "seek": 237700, "start": 2391.0, "end": 2395.0, "text": " So we can read this if we want.", "tokens": [51064, 407, 321, 393, 1401, 341, 498, 321, 528, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 391, "seek": 237700, "start": 2395.0, "end": 2397.0, "text": " Instead of v is an element of r2,", "tokens": [51264, 7156, 295, 371, 307, 364, 4478, 295, 367, 17, 11, 51364], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 392, "seek": 237700, "start": 2397.0, "end": 2402.0, "text": " we could just read this as v is a vector with two components.", "tokens": [51364, 321, 727, 445, 1401, 341, 382, 371, 307, 257, 8062, 365, 732, 6677, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 393, "seek": 237700, "start": 2402.0, "end": 2404.0, "text": " u is a vector with three components.", "tokens": [51614, 344, 307, 257, 8062, 365, 1045, 6677, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0523722995411266, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.002322901738807559}, {"id": 394, "seek": 240400, "start": 2404.0, "end": 2409.0, "text": " w is a vector with n components.", "tokens": [50364, 261, 307, 257, 8062, 365, 297, 6677, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 395, "seek": 240400, "start": 2409.0, "end": 2411.0, "text": " Okay, so I just wanted to lay this out there", "tokens": [50614, 1033, 11, 370, 286, 445, 1415, 281, 2360, 341, 484, 456, 50714], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 396, "seek": 240400, "start": 2411.0, "end": 2413.0, "text": " so that we're all on the same page,", "tokens": [50714, 370, 300, 321, 434, 439, 322, 264, 912, 3028, 11, 50814], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 397, "seek": 240400, "start": 2413.0, "end": 2414.0, "text": " and we'll move from here.", "tokens": [50814, 293, 321, 603, 1286, 490, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 398, "seek": 240400, "start": 2414.0, "end": 2416.0, "text": " See you then.", "tokens": [50864, 3008, 291, 550, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 399, "seek": 240400, "start": 2416.0, "end": 2424.0, "text": " Oh, also, we'll expand upon this idea of w,", "tokens": [50964, 876, 11, 611, 11, 321, 603, 5268, 3564, 341, 1558, 295, 261, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 400, "seek": 240400, "start": 2424.0, "end": 2426.0, "text": " or sorry, of a vector in rn,", "tokens": [51364, 420, 2597, 11, 295, 257, 8062, 294, 367, 77, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 401, "seek": 240400, "start": 2426.0, "end": 2428.0, "text": " how we can work with that", "tokens": [51464, 577, 321, 393, 589, 365, 300, 51564], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 402, "seek": 240400, "start": 2428.0, "end": 2432.0, "text": " and abstract some of the ideas", "tokens": [51564, 293, 12649, 512, 295, 264, 3487, 51764], "temperature": 0.0, "avg_logprob": -0.08839834112870065, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.00036827512667514384}, {"id": 403, "seek": 243200, "start": 2432.0, "end": 2435.0, "text": " that we learned in two and three dimensions.", "tokens": [50364, 300, 321, 3264, 294, 732, 293, 1045, 12819, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 404, "seek": 243200, "start": 2435.0, "end": 2439.0, "text": " Okay, see you then.", "tokens": [50514, 1033, 11, 536, 291, 550, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 405, "seek": 243200, "start": 2439.0, "end": 2443.0, "text": " Okay, so here we've seen the length of a vector", "tokens": [50714, 1033, 11, 370, 510, 321, 600, 1612, 264, 4641, 295, 257, 8062, 50914], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 406, "seek": 243200, "start": 2443.0, "end": 2446.0, "text": " with two components.", "tokens": [50914, 365, 732, 6677, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 407, "seek": 243200, "start": 2446.0, "end": 2448.0, "text": " In fact, we just used the Pythagorean theorem", "tokens": [51064, 682, 1186, 11, 321, 445, 1143, 264, 9953, 392, 559, 25885, 20904, 51164], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 408, "seek": 243200, "start": 2448.0, "end": 2450.0, "text": " to figure out this length.", "tokens": [51164, 281, 2573, 484, 341, 4641, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 409, "seek": 243200, "start": 2450.0, "end": 2453.0, "text": " It's just the square root of the first component squared", "tokens": [51264, 467, 311, 445, 264, 3732, 5593, 295, 264, 700, 6542, 8889, 51414], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 410, "seek": 243200, "start": 2453.0, "end": 2457.0, "text": " plus the second component squared.", "tokens": [51414, 1804, 264, 1150, 6542, 8889, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 411, "seek": 243200, "start": 2457.0, "end": 2460.0, "text": " In three dimensions, in a vector with three components,", "tokens": [51614, 682, 1045, 12819, 11, 294, 257, 8062, 365, 1045, 6677, 11, 51764], "temperature": 0.0, "avg_logprob": -0.07326781381036818, "compression_ratio": 1.7969543147208122, "no_speech_prob": 0.00043051692773588}, {"id": 412, "seek": 246000, "start": 2460.0, "end": 2462.0, "text": " we derived this length", "tokens": [50364, 321, 18949, 341, 4641, 50464], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 413, "seek": 246000, "start": 2462.0, "end": 2465.0, "text": " using the Pythagorean theorem twice in a row,", "tokens": [50464, 1228, 264, 9953, 392, 559, 25885, 20904, 6091, 294, 257, 5386, 11, 50614], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 414, "seek": 246000, "start": 2465.0, "end": 2467.0, "text": " and you can go back and watch that video if you want,", "tokens": [50614, 293, 291, 393, 352, 646, 293, 1159, 300, 960, 498, 291, 528, 11, 50714], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 415, "seek": 246000, "start": 2467.0, "end": 2471.0, "text": " and we found the length of a vector in r3", "tokens": [50714, 293, 321, 1352, 264, 4641, 295, 257, 8062, 294, 367, 18, 50914], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 416, "seek": 246000, "start": 2471.0, "end": 2475.0, "text": " is just the square root of u1 squared plus u2 squared", "tokens": [50914, 307, 445, 264, 3732, 5593, 295, 344, 16, 8889, 1804, 344, 17, 8889, 51114], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 417, "seek": 246000, "start": 2475.0, "end": 2478.0, "text": " plus u3 squared.", "tokens": [51114, 1804, 344, 18, 8889, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 418, "seek": 246000, "start": 2478.0, "end": 2483.0, "text": " A vector in rn, the length is defined to be as follows.", "tokens": [51264, 316, 8062, 294, 367, 77, 11, 264, 4641, 307, 7642, 281, 312, 382, 10002, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08394921367818658, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.0012064999900758266}, {"id": 419, "seek": 249000, "start": 2490.0, "end": 2497.0, "text": " This is just equal to the square root of w1 squared", "tokens": [50364, 639, 307, 445, 2681, 281, 264, 3732, 5593, 295, 261, 16, 8889, 50714], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 420, "seek": 249000, "start": 2497.0, "end": 2502.0, "text": " plus w2 squared plus everything in between,", "tokens": [50714, 1804, 261, 17, 8889, 1804, 1203, 294, 1296, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 421, "seek": 249000, "start": 2502.0, "end": 2506.0, "text": " so w3 squared plus w4 squared, so on,", "tokens": [50964, 370, 261, 18, 8889, 1804, 261, 19, 8889, 11, 370, 322, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 422, "seek": 249000, "start": 2506.0, "end": 2513.0, "text": " all the way up till you get to the last component.", "tokens": [51164, 439, 264, 636, 493, 4288, 291, 483, 281, 264, 1036, 6542, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 423, "seek": 249000, "start": 2513.0, "end": 2516.0, "text": " So it's really you just take each component individually,", "tokens": [51514, 407, 309, 311, 534, 291, 445, 747, 1184, 6542, 16652, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 424, "seek": 249000, "start": 2516.0, "end": 2519.0, "text": " you square it, you add all those together,", "tokens": [51664, 291, 3732, 309, 11, 291, 909, 439, 729, 1214, 11, 51814], "temperature": 0.0, "avg_logprob": -0.09749005436897278, "compression_ratio": 1.6863905325443787, "no_speech_prob": 0.002251632511615753}, {"id": 425, "seek": 251900, "start": 2519.0, "end": 2521.0, "text": " and then you take the square root.", "tokens": [50364, 293, 550, 291, 747, 264, 3732, 5593, 13, 50464], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 426, "seek": 251900, "start": 2521.0, "end": 2524.0, "text": " That's how you find the length of any vector.", "tokens": [50464, 663, 311, 577, 291, 915, 264, 4641, 295, 604, 8062, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 427, "seek": 251900, "start": 2524.0, "end": 2532.0, "text": " Okay, just figured I would fill you in on that.", "tokens": [50614, 1033, 11, 445, 8932, 286, 576, 2836, 291, 294, 322, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 428, "seek": 251900, "start": 2532.0, "end": 2535.0, "text": " See you in the next video.", "tokens": [51014, 3008, 291, 294, 264, 958, 960, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 429, "seek": 251900, "start": 2535.0, "end": 2537.0, "text": " Here we're being asked to prove that vector addition", "tokens": [51164, 1692, 321, 434, 885, 2351, 281, 7081, 300, 8062, 4500, 51264], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 430, "seek": 251900, "start": 2537.0, "end": 2540.0, "text": " is commutative and associative,", "tokens": [51264, 307, 800, 325, 1166, 293, 4180, 1166, 11, 51414], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 431, "seek": 251900, "start": 2540.0, "end": 2545.0, "text": " so this will be our first proof in the linear algebra course.", "tokens": [51414, 370, 341, 486, 312, 527, 700, 8177, 294, 264, 8213, 21989, 1164, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05804523019229665, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0026722364127635956}, {"id": 432, "seek": 254500, "start": 2546.0, "end": 2550.0, "text": " First of all, let's just define three vectors,", "tokens": [50414, 2386, 295, 439, 11, 718, 311, 445, 6964, 1045, 18875, 11, 50614], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 433, "seek": 254500, "start": 2550.0, "end": 2553.0, "text": " u, v, and w are all in rn,", "tokens": [50614, 344, 11, 371, 11, 293, 261, 366, 439, 294, 367, 77, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 434, "seek": 254500, "start": 2553.0, "end": 2556.0, "text": " so they're three vectors with n components,", "tokens": [50764, 370, 436, 434, 1045, 18875, 365, 297, 6677, 11, 50914], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 435, "seek": 254500, "start": 2556.0, "end": 2560.0, "text": " and let's figure out what we're trying to prove.", "tokens": [50914, 293, 718, 311, 2573, 484, 437, 321, 434, 1382, 281, 7081, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 436, "seek": 254500, "start": 2560.0, "end": 2563.0, "text": " So we're trying to prove that vector addition is commutative,", "tokens": [51114, 407, 321, 434, 1382, 281, 7081, 300, 8062, 4500, 307, 800, 325, 1166, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 437, "seek": 254500, "start": 2563.0, "end": 2566.0, "text": " so u plus v is the same as v plus u,", "tokens": [51264, 370, 344, 1804, 371, 307, 264, 912, 382, 371, 1804, 344, 11, 51414], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 438, "seek": 254500, "start": 2566.0, "end": 2571.0, "text": " and associative, so u plus v in parentheses plus w", "tokens": [51414, 293, 4180, 1166, 11, 370, 344, 1804, 371, 294, 34153, 1804, 261, 51664], "temperature": 0.0, "avg_logprob": -0.08067212785993304, "compression_ratio": 1.76536312849162, "no_speech_prob": 0.0005441838293336332}, {"id": 439, "seek": 257100, "start": 2571.0, "end": 2575.0, "text": " is the same as u plus v plus w.", "tokens": [50364, 307, 264, 912, 382, 344, 1804, 371, 1804, 261, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 440, "seek": 257100, "start": 2575.0, "end": 2578.0, "text": " Okay, so how are we going to do this?", "tokens": [50564, 1033, 11, 370, 577, 366, 321, 516, 281, 360, 341, 30, 50714], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 441, "seek": 257100, "start": 2578.0, "end": 2581.0, "text": " Excuse me.", "tokens": [50714, 11359, 385, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 442, "seek": 257100, "start": 2581.0, "end": 2591.0, "text": " First of all, let's just start with u plus v.", "tokens": [50864, 2386, 295, 439, 11, 718, 311, 445, 722, 365, 344, 1804, 371, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 443, "seek": 257100, "start": 2591.0, "end": 2596.0, "text": " So here's u plus v.", "tokens": [51364, 407, 510, 311, 344, 1804, 371, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 444, "seek": 257100, "start": 2596.0, "end": 2599.0, "text": " And what is this equal to?", "tokens": [51614, 400, 437, 307, 341, 2681, 281, 30, 51764], "temperature": 0.0, "avg_logprob": -0.07996317790104793, "compression_ratio": 1.3206106870229009, "no_speech_prob": 0.0018385795410722494}, {"id": 445, "seek": 259900, "start": 2599.0, "end": 2602.0, "text": " So what's the definition of vector addition?", "tokens": [50364, 407, 437, 311, 264, 7123, 295, 8062, 4500, 30, 50514], "temperature": 0.0, "avg_logprob": -0.10883792932482733, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.00023049737501423806}, {"id": 446, "seek": 259900, "start": 2602.0, "end": 2604.0, "text": " Well, we've already gone over this.", "tokens": [50514, 1042, 11, 321, 600, 1217, 2780, 670, 341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10883792932482733, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.00023049737501423806}, {"id": 447, "seek": 259900, "start": 2604.0, "end": 2614.0, "text": " It's u1 plus v1 comma u2 plus v2,", "tokens": [50614, 467, 311, 344, 16, 1804, 371, 16, 22117, 344, 17, 1804, 371, 17, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10883792932482733, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.00023049737501423806}, {"id": 448, "seek": 259900, "start": 2614.0, "end": 2617.0, "text": " and that keeps going until you get to the last component,", "tokens": [51114, 293, 300, 5965, 516, 1826, 291, 483, 281, 264, 1036, 6542, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10883792932482733, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.00023049737501423806}, {"id": 449, "seek": 259900, "start": 2617.0, "end": 2624.0, "text": " un plus vn, and this is the new vector.", "tokens": [51264, 344, 77, 1804, 371, 77, 11, 293, 341, 307, 264, 777, 8062, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10883792932482733, "compression_ratio": 1.4228187919463087, "no_speech_prob": 0.00023049737501423806}, {"id": 450, "seek": 262400, "start": 2624.0, "end": 2629.0, "text": " This is the vector u plus v.", "tokens": [50364, 639, 307, 264, 8062, 344, 1804, 371, 13, 50614], "temperature": 0.0, "avg_logprob": -0.053062350519241824, "compression_ratio": 1.5103448275862068, "no_speech_prob": 0.00018522156460676342}, {"id": 451, "seek": 262400, "start": 2629.0, "end": 2635.0, "text": " Okay, well, remember, these are real numbers.", "tokens": [50614, 1033, 11, 731, 11, 1604, 11, 613, 366, 957, 3547, 13, 50914], "temperature": 0.0, "avg_logprob": -0.053062350519241824, "compression_ratio": 1.5103448275862068, "no_speech_prob": 0.00018522156460676342}, {"id": 452, "seek": 262400, "start": 2635.0, "end": 2641.0, "text": " The components of vectors in rn are real numbers,", "tokens": [50914, 440, 6677, 295, 18875, 294, 367, 77, 366, 957, 3547, 11, 51214], "temperature": 0.0, "avg_logprob": -0.053062350519241824, "compression_ratio": 1.5103448275862068, "no_speech_prob": 0.00018522156460676342}, {"id": 453, "seek": 262400, "start": 2641.0, "end": 2645.0, "text": " and so we can use the commutative property of addition", "tokens": [51214, 293, 370, 321, 393, 764, 264, 800, 325, 1166, 4707, 295, 4500, 51414], "temperature": 0.0, "avg_logprob": -0.053062350519241824, "compression_ratio": 1.5103448275862068, "no_speech_prob": 0.00018522156460676342}, {"id": 454, "seek": 262400, "start": 2645.0, "end": 2650.0, "text": " of real numbers to switch those around.", "tokens": [51414, 295, 957, 3547, 281, 3679, 729, 926, 13, 51664], "temperature": 0.0, "avg_logprob": -0.053062350519241824, "compression_ratio": 1.5103448275862068, "no_speech_prob": 0.00018522156460676342}, {"id": 455, "seek": 265000, "start": 2650.0, "end": 2655.0, "text": " So this is the same as v1 plus u1", "tokens": [50364, 407, 341, 307, 264, 912, 382, 371, 16, 1804, 344, 16, 50614], "temperature": 0.0, "avg_logprob": -0.06951015714615111, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.00025314957019872963}, {"id": 456, "seek": 265000, "start": 2655.0, "end": 2657.0, "text": " because those are just real numbers,", "tokens": [50614, 570, 729, 366, 445, 957, 3547, 11, 50714], "temperature": 0.0, "avg_logprob": -0.06951015714615111, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.00025314957019872963}, {"id": 457, "seek": 265000, "start": 2657.0, "end": 2661.0, "text": " and addition of real numbers is commutative.", "tokens": [50714, 293, 4500, 295, 957, 3547, 307, 800, 325, 1166, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06951015714615111, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.00025314957019872963}, {"id": 458, "seek": 265000, "start": 2661.0, "end": 2667.0, "text": " v2 plus u2, and you keep going until you get to the end,", "tokens": [50914, 371, 17, 1804, 344, 17, 11, 293, 291, 1066, 516, 1826, 291, 483, 281, 264, 917, 11, 51214], "temperature": 0.0, "avg_logprob": -0.06951015714615111, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.00025314957019872963}, {"id": 459, "seek": 265000, "start": 2667.0, "end": 2673.0, "text": " vn plus un.", "tokens": [51214, 371, 77, 1804, 344, 77, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06951015714615111, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.00025314957019872963}, {"id": 460, "seek": 267300, "start": 2673.0, "end": 2683.0, "text": " Well, now here, this is the definition of v plus u.", "tokens": [50364, 1042, 11, 586, 510, 11, 341, 307, 264, 7123, 295, 371, 1804, 344, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06058200667886173, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.0010649089235812426}, {"id": 461, "seek": 267300, "start": 2683.0, "end": 2688.0, "text": " That's how we define v plus u.", "tokens": [50864, 663, 311, 577, 321, 6964, 371, 1804, 344, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06058200667886173, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.0010649089235812426}, {"id": 462, "seek": 267300, "start": 2688.0, "end": 2692.0, "text": " And so we have a simple algebraic proof here", "tokens": [51114, 400, 370, 321, 362, 257, 2199, 21989, 299, 8177, 510, 51314], "temperature": 0.0, "avg_logprob": -0.06058200667886173, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.0010649089235812426}, {"id": 463, "seek": 267300, "start": 2692.0, "end": 2695.0, "text": " that u plus v is equal to v plus u.", "tokens": [51314, 300, 344, 1804, 371, 307, 2681, 281, 371, 1804, 344, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06058200667886173, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.0010649089235812426}, {"id": 464, "seek": 267300, "start": 2695.0, "end": 2698.0, "text": " It's not really formal, there's no formal writings,", "tokens": [51464, 467, 311, 406, 534, 9860, 11, 456, 311, 572, 9860, 30083, 11, 51614], "temperature": 0.0, "avg_logprob": -0.06058200667886173, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.0010649089235812426}, {"id": 465, "seek": 269800, "start": 2698.0, "end": 2704.0, "text": " but I think you can see clearly it's a proof.", "tokens": [50364, 457, 286, 519, 291, 393, 536, 4448, 309, 311, 257, 8177, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 466, "seek": 269800, "start": 2704.0, "end": 2713.0, "text": " Okay, how about proving that vector addition is associative?", "tokens": [50664, 1033, 11, 577, 466, 27221, 300, 8062, 4500, 307, 4180, 1166, 30, 51114], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 467, "seek": 269800, "start": 2713.0, "end": 2716.0, "text": " Well, I want you to pause and try that on your own,", "tokens": [51114, 1042, 11, 286, 528, 291, 281, 10465, 293, 853, 300, 322, 428, 1065, 11, 51264], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 468, "seek": 269800, "start": 2716.0, "end": 2718.0, "text": " but the strategy is going to be the same.", "tokens": [51264, 457, 264, 5206, 307, 516, 281, 312, 264, 912, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 469, "seek": 269800, "start": 2718.0, "end": 2722.0, "text": " What we did is we went ahead and used the properties of real numbers,", "tokens": [51364, 708, 321, 630, 307, 321, 1437, 2286, 293, 1143, 264, 7221, 295, 957, 3547, 11, 51564], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 470, "seek": 269800, "start": 2722.0, "end": 2725.0, "text": " the fact that real numbers are commutative,", "tokens": [51564, 264, 1186, 300, 957, 3547, 366, 800, 325, 1166, 11, 51714], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 471, "seek": 269800, "start": 2725.0, "end": 2727.0, "text": " to prove that vectors are commutative.", "tokens": [51714, 281, 7081, 300, 18875, 366, 800, 325, 1166, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0588772540189782, "compression_ratio": 1.6495327102803738, "no_speech_prob": 0.004133216571062803}, {"id": 472, "seek": 272700, "start": 2727.0, "end": 2730.0, "text": " And we're going to use that same strategy for associative,", "tokens": [50364, 400, 321, 434, 516, 281, 764, 300, 912, 5206, 337, 4180, 1166, 11, 50514], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 473, "seek": 272700, "start": 2730.0, "end": 2733.0, "text": " for the associative property.", "tokens": [50514, 337, 264, 4180, 1166, 4707, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 474, "seek": 272700, "start": 2733.0, "end": 2741.0, "text": " Okay, pause and try that on your own.", "tokens": [50664, 1033, 11, 10465, 293, 853, 300, 322, 428, 1065, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 475, "seek": 272700, "start": 2741.0, "end": 2743.0, "text": " Okay, hopefully you're back from pausing the video", "tokens": [51064, 1033, 11, 4696, 291, 434, 646, 490, 2502, 7981, 264, 960, 51164], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 476, "seek": 272700, "start": 2743.0, "end": 2746.0, "text": " and trying to prove that vectors are associative.", "tokens": [51164, 293, 1382, 281, 7081, 300, 18875, 366, 4180, 1166, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 477, "seek": 272700, "start": 2746.0, "end": 2749.0, "text": " And now let's go through it.", "tokens": [51314, 400, 586, 718, 311, 352, 807, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05766618914074368, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00029594884836114943}, {"id": 478, "seek": 274900, "start": 2749.0, "end": 2763.0, "text": " So we have u plus v plus w.", "tokens": [50364, 407, 321, 362, 344, 1804, 371, 1804, 261, 13, 51064], "temperature": 0.0, "avg_logprob": -0.04936987559000651, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0005527695175260305}, {"id": 479, "seek": 274900, "start": 2763.0, "end": 2769.0, "text": " Well, we know that u plus v is going to be its own vector.", "tokens": [51064, 1042, 11, 321, 458, 300, 344, 1804, 371, 307, 516, 281, 312, 1080, 1065, 8062, 13, 51364], "temperature": 0.0, "avg_logprob": -0.04936987559000651, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0005527695175260305}, {"id": 480, "seek": 274900, "start": 2769.0, "end": 2774.0, "text": " It's going to be the vector u1 plus v1.", "tokens": [51364, 467, 311, 516, 281, 312, 264, 8062, 344, 16, 1804, 371, 16, 13, 51614], "temperature": 0.0, "avg_logprob": -0.04936987559000651, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0005527695175260305}, {"id": 481, "seek": 274900, "start": 2774.0, "end": 2777.0, "text": " And I'm just going to leave off the second component.", "tokens": [51614, 400, 286, 478, 445, 516, 281, 1856, 766, 264, 1150, 6542, 13, 51764], "temperature": 0.0, "avg_logprob": -0.04936987559000651, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0005527695175260305}, {"id": 482, "seek": 277700, "start": 2777.0, "end": 2779.0, "text": " We all, you've seen it enough times.", "tokens": [50364, 492, 439, 11, 291, 600, 1612, 309, 1547, 1413, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1630207379659017, "compression_ratio": 1.392, "no_speech_prob": 0.004609329625964165}, {"id": 483, "seek": 277700, "start": 2779.0, "end": 2781.0, "text": " We know what's happening.", "tokens": [50464, 492, 458, 437, 311, 2737, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1630207379659017, "compression_ratio": 1.392, "no_speech_prob": 0.004609329625964165}, {"id": 484, "seek": 277700, "start": 2781.0, "end": 2786.0, "text": " Down to u n plus v n.", "tokens": [50564, 9506, 281, 344, 297, 1804, 371, 297, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1630207379659017, "compression_ratio": 1.392, "no_speech_prob": 0.004609329625964165}, {"id": 485, "seek": 277700, "start": 2786.0, "end": 2792.0, "text": " So that's this whole vector here.", "tokens": [50814, 407, 300, 311, 341, 1379, 8062, 510, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1630207379659017, "compression_ratio": 1.392, "no_speech_prob": 0.004609329625964165}, {"id": 486, "seek": 277700, "start": 2792.0, "end": 2802.0, "text": " We can think of u plus v as its own new vector, plus w.", "tokens": [51114, 492, 393, 519, 295, 344, 1804, 371, 382, 1080, 1065, 777, 8062, 11, 1804, 261, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1630207379659017, "compression_ratio": 1.392, "no_speech_prob": 0.004609329625964165}, {"id": 487, "seek": 280200, "start": 2803.0, "end": 2806.0, "text": " And again, I'm going to leave off the second one", "tokens": [50414, 400, 797, 11, 286, 478, 516, 281, 1856, 766, 264, 1150, 472, 50564], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 488, "seek": 280200, "start": 2806.0, "end": 2813.0, "text": " and just write it like that.", "tokens": [50564, 293, 445, 2464, 309, 411, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 489, "seek": 280200, "start": 2813.0, "end": 2818.0, "text": " Okay, well, now we're just adding two vectors together.", "tokens": [50914, 1033, 11, 731, 11, 586, 321, 434, 445, 5127, 732, 18875, 1214, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 490, "seek": 280200, "start": 2818.0, "end": 2819.0, "text": " And we know how to do that.", "tokens": [51164, 400, 321, 458, 577, 281, 360, 300, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 491, "seek": 280200, "start": 2819.0, "end": 2822.0, "text": " We take the first component of the first vector,", "tokens": [51214, 492, 747, 264, 700, 6542, 295, 264, 700, 8062, 11, 51364], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 492, "seek": 280200, "start": 2822.0, "end": 2825.0, "text": " which is u1 plus v1.", "tokens": [51364, 597, 307, 344, 16, 1804, 371, 16, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 493, "seek": 280200, "start": 2825.0, "end": 2828.0, "text": " That's the first component of that vector.", "tokens": [51514, 663, 311, 264, 700, 6542, 295, 300, 8062, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 494, "seek": 280200, "start": 2828.0, "end": 2831.0, "text": " And then we add the first component of the other vector,", "tokens": [51664, 400, 550, 321, 909, 264, 700, 6542, 295, 264, 661, 8062, 11, 51814], "temperature": 0.0, "avg_logprob": -0.06567814423865878, "compression_ratio": 1.7513227513227514, "no_speech_prob": 0.00048784707905724645}, {"id": 495, "seek": 283100, "start": 2831.0, "end": 2834.0, "text": " which is just w1.", "tokens": [50364, 597, 307, 445, 261, 16, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10341953348230433, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0008295396692119539}, {"id": 496, "seek": 283100, "start": 2834.0, "end": 2840.0, "text": " And we do that for each component, each of the components,", "tokens": [50514, 400, 321, 360, 300, 337, 1184, 6542, 11, 1184, 295, 264, 6677, 11, 50814], "temperature": 0.0, "avg_logprob": -0.10341953348230433, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0008295396692119539}, {"id": 497, "seek": 283100, "start": 2840.0, "end": 2850.0, "text": " until we get to u n plus v n plus w n.", "tokens": [50814, 1826, 321, 483, 281, 344, 297, 1804, 371, 297, 1804, 261, 297, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10341953348230433, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0008295396692119539}, {"id": 498, "seek": 283100, "start": 2850.0, "end": 2857.0, "text": " Okay, and now, again, we have real numbers here", "tokens": [51314, 1033, 11, 293, 586, 11, 797, 11, 321, 362, 957, 3547, 510, 51664], "temperature": 0.0, "avg_logprob": -0.10341953348230433, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0008295396692119539}, {"id": 499, "seek": 285700, "start": 2857.0, "end": 2860.0, "text": " and real numbers are associative.", "tokens": [50364, 293, 957, 3547, 366, 4180, 1166, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 500, "seek": 285700, "start": 2860.0, "end": 2862.0, "text": " Addition of real numbers is associative.", "tokens": [50514, 5349, 849, 295, 957, 3547, 307, 4180, 1166, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 501, "seek": 285700, "start": 2862.0, "end": 2868.0, "text": " And so we're just going to use that property of real numbers.", "tokens": [50614, 400, 370, 321, 434, 445, 516, 281, 764, 300, 4707, 295, 957, 3547, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 502, "seek": 285700, "start": 2868.0, "end": 2878.0, "text": " So this is the same thing as u1 plus v1 plus w1.", "tokens": [50914, 407, 341, 307, 264, 912, 551, 382, 344, 16, 1804, 371, 16, 1804, 261, 16, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 503, "seek": 285700, "start": 2878.0, "end": 2880.0, "text": " Remember, these components are just real numbers,", "tokens": [51414, 5459, 11, 613, 6677, 366, 445, 957, 3547, 11, 51514], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 504, "seek": 285700, "start": 2880.0, "end": 2885.0, "text": " so the associative property of addition holds.", "tokens": [51514, 370, 264, 4180, 1166, 4707, 295, 4500, 9190, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06809153312291855, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.00039202856714837253}, {"id": 505, "seek": 288500, "start": 2885.0, "end": 2900.0, "text": " Okay, and we'll do that all the way through all of these components.", "tokens": [50364, 1033, 11, 293, 321, 603, 360, 300, 439, 264, 636, 807, 439, 295, 613, 6677, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06410051527477446, "compression_ratio": 1.2522522522522523, "no_speech_prob": 0.0016742430161684752}, {"id": 506, "seek": 288500, "start": 2900.0, "end": 2905.0, "text": " And we're almost done.", "tokens": [51114, 400, 321, 434, 1920, 1096, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06410051527477446, "compression_ratio": 1.2522522522522523, "no_speech_prob": 0.0016742430161684752}, {"id": 507, "seek": 288500, "start": 2905.0, "end": 2914.0, "text": " And now we can break this up into the vector u.", "tokens": [51364, 400, 586, 321, 393, 1821, 341, 493, 666, 264, 8062, 344, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06410051527477446, "compression_ratio": 1.2522522522522523, "no_speech_prob": 0.0016742430161684752}, {"id": 508, "seek": 291400, "start": 2914.0, "end": 2932.0, "text": " u1 all the way to u n plus the vector v1 plus w1", "tokens": [50364, 344, 16, 439, 264, 636, 281, 344, 297, 1804, 264, 8062, 371, 16, 1804, 261, 16, 51264], "temperature": 0.0, "avg_logprob": -0.1352658680507115, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.014500665478408337}, {"id": 509, "seek": 291400, "start": 2932.0, "end": 2941.0, "text": " all the way to the end, the n plus w n.", "tokens": [51264, 439, 264, 636, 281, 264, 917, 11, 264, 297, 1804, 261, 297, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1352658680507115, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.014500665478408337}, {"id": 510, "seek": 294100, "start": 2941.0, "end": 2954.0, "text": " And this, of course, is just u plus v plus w.", "tokens": [50364, 400, 341, 11, 295, 1164, 11, 307, 445, 344, 1804, 371, 1804, 261, 13, 51014], "temperature": 0.0, "avg_logprob": -0.04822218045592308, "compression_ratio": 1.1590909090909092, "no_speech_prob": 0.0069030579179525375}, {"id": 511, "seek": 294100, "start": 2954.0, "end": 2963.0, "text": " And so we've proved that vector addition is associative.", "tokens": [51014, 400, 370, 321, 600, 14617, 300, 8062, 4500, 307, 4180, 1166, 13, 51464], "temperature": 0.0, "avg_logprob": -0.04822218045592308, "compression_ratio": 1.1590909090909092, "no_speech_prob": 0.0069030579179525375}, {"id": 512, "seek": 296300, "start": 2963.0, "end": 2971.0, "text": " So again, it's a really simple method.", "tokens": [50364, 407, 797, 11, 309, 311, 257, 534, 2199, 3170, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 513, "seek": 296300, "start": 2971.0, "end": 2974.0, "text": " All we're doing is a really simple process.", "tokens": [50764, 1057, 321, 434, 884, 307, 257, 534, 2199, 1399, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 514, "seek": 296300, "start": 2974.0, "end": 2976.0, "text": " That's the word I was looking for.", "tokens": [50914, 663, 311, 264, 1349, 286, 390, 1237, 337, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 515, "seek": 296300, "start": 2976.0, "end": 2979.0, "text": " All we're doing is taking the vectors,", "tokens": [51014, 1057, 321, 434, 884, 307, 1940, 264, 18875, 11, 51164], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 516, "seek": 296300, "start": 2979.0, "end": 2981.0, "text": " breaking them down into their components.", "tokens": [51164, 7697, 552, 760, 666, 641, 6677, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 517, "seek": 296300, "start": 2981.0, "end": 2984.0, "text": " And since the components are real numbers,", "tokens": [51264, 400, 1670, 264, 6677, 366, 957, 3547, 11, 51414], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 518, "seek": 296300, "start": 2984.0, "end": 2988.0, "text": " we can use the properties of real numbers on the component level.", "tokens": [51414, 321, 393, 764, 264, 7221, 295, 957, 3547, 322, 264, 6542, 1496, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 519, "seek": 296300, "start": 2988.0, "end": 2992.0, "text": " And then we're kind of pulling things back out into vectors.", "tokens": [51614, 400, 550, 321, 434, 733, 295, 8407, 721, 646, 484, 666, 18875, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07508875660060607, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.06094856560230255}, {"id": 520, "seek": 299200, "start": 2992.0, "end": 2994.0, "text": " Okay, I hope this was helpful.", "tokens": [50364, 1033, 11, 286, 1454, 341, 390, 4961, 13, 50464], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 521, "seek": 299200, "start": 2994.0, "end": 2998.0, "text": " We'll see the rest of the properties of vectors in the next video.", "tokens": [50464, 492, 603, 536, 264, 1472, 295, 264, 7221, 295, 18875, 294, 264, 958, 960, 13, 50664], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 522, "seek": 299200, "start": 2998.0, "end": 3000.0, "text": " See you then.", "tokens": [50664, 3008, 291, 550, 13, 50764], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 523, "seek": 299200, "start": 3000.0, "end": 3005.0, "text": " Okay, here are some of the algebraic properties of vectors.", "tokens": [50764, 1033, 11, 510, 366, 512, 295, 264, 21989, 299, 7221, 295, 18875, 13, 51014], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 524, "seek": 299200, "start": 3005.0, "end": 3008.0, "text": " I encourage you to try and prove all of these.", "tokens": [51014, 286, 5373, 291, 281, 853, 293, 7081, 439, 295, 613, 13, 51164], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 525, "seek": 299200, "start": 3008.0, "end": 3011.0, "text": " We just proved that vector addition is commutative,", "tokens": [51164, 492, 445, 14617, 300, 8062, 4500, 307, 800, 325, 1166, 11, 51314], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 526, "seek": 299200, "start": 3011.0, "end": 3013.0, "text": " so that's number one here.", "tokens": [51314, 370, 300, 311, 1230, 472, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 527, "seek": 299200, "start": 3013.0, "end": 3015.0, "text": " We just proved that in the last video.", "tokens": [51414, 492, 445, 14617, 300, 294, 264, 1036, 960, 13, 51514], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 528, "seek": 299200, "start": 3015.0, "end": 3017.0, "text": " Very similarly to the way we proved that,", "tokens": [51514, 4372, 14138, 281, 264, 636, 321, 14617, 300, 11, 51614], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 529, "seek": 299200, "start": 3017.0, "end": 3021.0, "text": " you could prove all of these if you know properties of real numbers.", "tokens": [51614, 291, 727, 7081, 439, 295, 613, 498, 291, 458, 7221, 295, 957, 3547, 13, 51814], "temperature": 0.0, "avg_logprob": -0.04111169024211604, "compression_ratio": 1.902127659574468, "no_speech_prob": 0.016389768570661545}, {"id": 530, "seek": 302100, "start": 3022.0, "end": 3026.0, "text": " You know addition for real numbers is associative,", "tokens": [50414, 509, 458, 4500, 337, 957, 3547, 307, 4180, 1166, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 531, "seek": 302100, "start": 3026.0, "end": 3028.0, "text": " and that's what we have here in step number two,", "tokens": [50614, 293, 300, 311, 437, 321, 362, 510, 294, 1823, 1230, 732, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 532, "seek": 302100, "start": 3028.0, "end": 3031.0, "text": " so you probably can prove that pretty easily.", "tokens": [50714, 370, 291, 1391, 393, 7081, 300, 1238, 3612, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 533, "seek": 302100, "start": 3031.0, "end": 3034.0, "text": " When you add a real number to zero,", "tokens": [50864, 1133, 291, 909, 257, 957, 1230, 281, 4018, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 534, "seek": 302100, "start": 3034.0, "end": 3037.0, "text": " you get that real number back.", "tokens": [51014, 291, 483, 300, 957, 1230, 646, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 535, "seek": 302100, "start": 3037.0, "end": 3040.0, "text": " So you can go through all of these pretty easily.", "tokens": [51164, 407, 291, 393, 352, 807, 439, 295, 613, 1238, 3612, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 536, "seek": 302100, "start": 3040.0, "end": 3047.0, "text": " And like I said, just use the properties of real numbers that you know.", "tokens": [51314, 400, 411, 286, 848, 11, 445, 764, 264, 7221, 295, 957, 3547, 300, 291, 458, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10430494944254558, "compression_ratio": 1.67, "no_speech_prob": 0.004330351948738098}, {"id": 537, "seek": 304700, "start": 3047.0, "end": 3053.0, "text": " One interesting thing here is we have this thing called the zero vector.", "tokens": [50364, 1485, 1880, 551, 510, 307, 321, 362, 341, 551, 1219, 264, 4018, 8062, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 538, "seek": 304700, "start": 3053.0, "end": 3056.0, "text": " And the zero vector is a little bit different than zero.", "tokens": [50664, 400, 264, 4018, 8062, 307, 257, 707, 857, 819, 813, 4018, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 539, "seek": 304700, "start": 3056.0, "end": 3060.0, "text": " It's a vector whose components are all zero.", "tokens": [50814, 467, 311, 257, 8062, 6104, 6677, 366, 439, 4018, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 540, "seek": 304700, "start": 3060.0, "end": 3063.0, "text": " And that distinction is somewhat important", "tokens": [51014, 400, 300, 16844, 307, 8344, 1021, 51164], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 541, "seek": 304700, "start": 3063.0, "end": 3068.0, "text": " because we can't add just a regular number zero to a vector.", "tokens": [51164, 570, 321, 393, 380, 909, 445, 257, 3890, 1230, 4018, 281, 257, 8062, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 542, "seek": 304700, "start": 3068.0, "end": 3071.0, "text": " We have to add a vector to a vector.", "tokens": [51414, 492, 362, 281, 909, 257, 8062, 281, 257, 8062, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 543, "seek": 304700, "start": 3071.0, "end": 3074.0, "text": " So when we do this addition, we need this to be a zero vector,", "tokens": [51564, 407, 562, 321, 360, 341, 4500, 11, 321, 643, 341, 281, 312, 257, 4018, 8062, 11, 51714], "temperature": 0.0, "avg_logprob": -0.06117284054658851, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.00048025549040175974}, {"id": 544, "seek": 307400, "start": 3074.0, "end": 3078.0, "text": " so we can add each of the components together.", "tokens": [50364, 370, 321, 393, 909, 1184, 295, 264, 6677, 1214, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 545, "seek": 307400, "start": 3078.0, "end": 3080.0, "text": " But okay, so this is just for reference.", "tokens": [50564, 583, 1392, 11, 370, 341, 307, 445, 337, 6408, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 546, "seek": 307400, "start": 3080.0, "end": 3082.0, "text": " You can view it at any time.", "tokens": [50664, 509, 393, 1910, 309, 412, 604, 565, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 547, "seek": 307400, "start": 3082.0, "end": 3085.0, "text": " I hope they'll have a reference sheet on the website", "tokens": [50764, 286, 1454, 436, 603, 362, 257, 6408, 8193, 322, 264, 3144, 50914], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 548, "seek": 307400, "start": 3085.0, "end": 3087.0, "text": " that you can look at and print off.", "tokens": [50914, 300, 291, 393, 574, 412, 293, 4482, 766, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 549, "seek": 307400, "start": 3087.0, "end": 3092.0, "text": " So we can use these from now on with vectors.", "tokens": [51014, 407, 321, 393, 764, 613, 490, 586, 322, 365, 18875, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 550, "seek": 307400, "start": 3092.0, "end": 3094.0, "text": " See you in the next video.", "tokens": [51264, 3008, 291, 294, 264, 958, 960, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 551, "seek": 307400, "start": 3094.0, "end": 3097.0, "text": " So if you've been following along so far,", "tokens": [51364, 407, 498, 291, 600, 668, 3480, 2051, 370, 1400, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 552, "seek": 307400, "start": 3097.0, "end": 3101.0, "text": " you may have noticed that we haven't talked about multiplying two vectors.", "tokens": [51514, 291, 815, 362, 5694, 300, 321, 2378, 380, 2825, 466, 30955, 732, 18875, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08626700314608488, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.006902541033923626}, {"id": 553, "seek": 310100, "start": 3102.0, "end": 3107.0, "text": " And that's because there's a couple different ways to multiply vectors", "tokens": [50414, 400, 300, 311, 570, 456, 311, 257, 1916, 819, 2098, 281, 12972, 18875, 50664], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 554, "seek": 310100, "start": 3107.0, "end": 3110.0, "text": " or to define a product of vectors.", "tokens": [50664, 420, 281, 6964, 257, 1674, 295, 18875, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 555, "seek": 310100, "start": 3110.0, "end": 3113.0, "text": " And one really interesting and useful one is called the dot product.", "tokens": [50814, 400, 472, 534, 1880, 293, 4420, 472, 307, 1219, 264, 5893, 1674, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 556, "seek": 310100, "start": 3113.0, "end": 3117.0, "text": " So when you see this dot here that indicates the dot product,", "tokens": [50964, 407, 562, 291, 536, 341, 5893, 510, 300, 16203, 264, 5893, 1674, 11, 51164], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 557, "seek": 310100, "start": 3117.0, "end": 3122.0, "text": " and the way the dot product is defined is maybe somewhat surprising.", "tokens": [51164, 293, 264, 636, 264, 5893, 1674, 307, 7642, 307, 1310, 8344, 8830, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 558, "seek": 310100, "start": 3122.0, "end": 3130.0, "text": " The way that we do this is we do u1 times v1 plus u2 times v2.", "tokens": [51414, 440, 636, 300, 321, 360, 341, 307, 321, 360, 344, 16, 1413, 371, 16, 1804, 344, 17, 1413, 371, 17, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06922007621602809, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.0023229329381138086}, {"id": 559, "seek": 313100, "start": 3131.0, "end": 3134.0, "text": " Plus u3 times v3, so on and so on.", "tokens": [50364, 7721, 344, 18, 1413, 371, 18, 11, 370, 322, 293, 370, 322, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 560, "seek": 313100, "start": 3134.0, "end": 3142.0, "text": " All the way until we get to the end, un plus un times vn.", "tokens": [50514, 1057, 264, 636, 1826, 321, 483, 281, 264, 917, 11, 344, 77, 1804, 517, 1413, 371, 77, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 561, "seek": 313100, "start": 3142.0, "end": 3144.0, "text": " Why is that surprising?", "tokens": [50914, 1545, 307, 300, 8830, 30, 51014], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 562, "seek": 313100, "start": 3144.0, "end": 3148.0, "text": " Why is that a surprising way to define a product of two vectors?", "tokens": [51014, 1545, 307, 300, 257, 8830, 636, 281, 6964, 257, 1674, 295, 732, 18875, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 563, "seek": 313100, "start": 3148.0, "end": 3150.0, "text": " Well, look at the result.", "tokens": [51214, 1042, 11, 574, 412, 264, 1874, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 564, "seek": 313100, "start": 3150.0, "end": 3153.0, "text": " What kind of object is this?", "tokens": [51314, 708, 733, 295, 2657, 307, 341, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 565, "seek": 313100, "start": 3153.0, "end": 3155.0, "text": " It's a number.", "tokens": [51464, 467, 311, 257, 1230, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 566, "seek": 313100, "start": 3155.0, "end": 3157.0, "text": " These two things are numbers.", "tokens": [51564, 1981, 732, 721, 366, 3547, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 567, "seek": 313100, "start": 3157.0, "end": 3160.0, "text": " When we multiply them, we just get a real number plus another real number.", "tokens": [51664, 1133, 321, 12972, 552, 11, 321, 445, 483, 257, 957, 1230, 1804, 1071, 957, 1230, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1047767432960304, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0007096346816979349}, {"id": 568, "seek": 316000, "start": 3160.0, "end": 3162.0, "text": " All the way across.", "tokens": [50364, 1057, 264, 636, 2108, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 569, "seek": 316000, "start": 3162.0, "end": 3165.0, "text": " When we add all these up, that's just a single number.", "tokens": [50464, 1133, 321, 909, 439, 613, 493, 11, 300, 311, 445, 257, 2167, 1230, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 570, "seek": 316000, "start": 3165.0, "end": 3168.0, "text": " So you multiply two vectors and you just get a number out.", "tokens": [50614, 407, 291, 12972, 732, 18875, 293, 291, 445, 483, 257, 1230, 484, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 571, "seek": 316000, "start": 3168.0, "end": 3173.0, "text": " So you don't even get a vector back when you multiply two vectors with a dot product.", "tokens": [50764, 407, 291, 500, 380, 754, 483, 257, 8062, 646, 562, 291, 12972, 732, 18875, 365, 257, 5893, 1674, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 572, "seek": 316000, "start": 3173.0, "end": 3178.0, "text": " So this is sometimes called the scalar product for that reason that the result is a scalar.", "tokens": [51014, 407, 341, 307, 2171, 1219, 264, 39684, 1674, 337, 300, 1778, 300, 264, 1874, 307, 257, 39684, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 573, "seek": 316000, "start": 3178.0, "end": 3180.0, "text": " It's a real number, a constant.", "tokens": [51264, 467, 311, 257, 957, 1230, 11, 257, 5754, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 574, "seek": 316000, "start": 3180.0, "end": 3184.0, "text": " Those are all different ways of saying the same thing.", "tokens": [51364, 3950, 366, 439, 819, 2098, 295, 1566, 264, 912, 551, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 575, "seek": 316000, "start": 3184.0, "end": 3189.0, "text": " So for slightly different notation and maybe a little bit more concise notation,", "tokens": [51564, 407, 337, 4748, 819, 24657, 293, 1310, 257, 707, 857, 544, 44882, 24657, 11, 51814], "temperature": 0.0, "avg_logprob": -0.07004660614265883, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.0034829904325306416}, {"id": 576, "seek": 318900, "start": 3189.0, "end": 3199.0, "text": " is we could use summation notation or sigma notation and just write this like this.", "tokens": [50364, 307, 321, 727, 764, 28811, 24657, 420, 12771, 24657, 293, 445, 2464, 341, 411, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08129989095481045, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.005137789994478226}, {"id": 577, "seek": 318900, "start": 3199.0, "end": 3206.0, "text": " So we sum up all the components from one to n, the products of those components.", "tokens": [50864, 407, 321, 2408, 493, 439, 264, 6677, 490, 472, 281, 297, 11, 264, 3383, 295, 729, 6677, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08129989095481045, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.005137789994478226}, {"id": 578, "seek": 318900, "start": 3206.0, "end": 3211.0, "text": " So if you're comfortable and familiar with sigma notation, this is one way to write it.", "tokens": [51214, 407, 498, 291, 434, 4619, 293, 4963, 365, 12771, 24657, 11, 341, 307, 472, 636, 281, 2464, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08129989095481045, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.005137789994478226}, {"id": 579, "seek": 318900, "start": 3211.0, "end": 3217.0, "text": " I personally actually prefer this way up here because it's a little bit more informative, I think.", "tokens": [51464, 286, 5665, 767, 4382, 341, 636, 493, 510, 570, 309, 311, 257, 707, 857, 544, 27759, 11, 286, 519, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08129989095481045, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.005137789994478226}, {"id": 580, "seek": 321700, "start": 3217.0, "end": 3222.0, "text": " It's a little bit easier to see just right away without interpreting the sigma notation.", "tokens": [50364, 467, 311, 257, 707, 857, 3571, 281, 536, 445, 558, 1314, 1553, 37395, 264, 12771, 24657, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10151695560764622, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.014061539433896542}, {"id": 581, "seek": 321700, "start": 3222.0, "end": 3225.0, "text": " Anyways, that's that.", "tokens": [50614, 15585, 11, 300, 311, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10151695560764622, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.014061539433896542}, {"id": 582, "seek": 321700, "start": 3225.0, "end": 3229.0, "text": " Let's do an example.", "tokens": [50764, 961, 311, 360, 364, 1365, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10151695560764622, "compression_ratio": 1.212962962962963, "no_speech_prob": 0.014061539433896542}, {"id": 583, "seek": 322900, "start": 3229.0, "end": 3255.0, "text": " So if we have u is equal to 1, negative 2, and 5, and v is equal to 4, 3, and 1.", "tokens": [50364, 407, 498, 321, 362, 344, 307, 2681, 281, 502, 11, 3671, 568, 11, 293, 1025, 11, 293, 371, 307, 2681, 281, 1017, 11, 805, 11, 293, 502, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08900473175979243, "compression_ratio": 1.1978021978021978, "no_speech_prob": 0.07801767438650131}, {"id": 584, "seek": 322900, "start": 3255.0, "end": 3258.0, "text": " So what is this dot product?", "tokens": [51664, 407, 437, 307, 341, 5893, 1674, 30, 51814], "temperature": 0.0, "avg_logprob": -0.08900473175979243, "compression_ratio": 1.1978021978021978, "no_speech_prob": 0.07801767438650131}, {"id": 585, "seek": 325800, "start": 3258.0, "end": 3260.0, "text": " Well, we just do exactly what it says.", "tokens": [50364, 1042, 11, 321, 445, 360, 2293, 437, 309, 1619, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09225114510983837, "compression_ratio": 1.2702702702702702, "no_speech_prob": 0.01342535950243473}, {"id": 586, "seek": 325800, "start": 3260.0, "end": 3270.0, "text": " 1 times 4 plus negative 2 times 3 plus 5 times 1.", "tokens": [50464, 502, 1413, 1017, 1804, 3671, 568, 1413, 805, 1804, 1025, 1413, 502, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09225114510983837, "compression_ratio": 1.2702702702702702, "no_speech_prob": 0.01342535950243473}, {"id": 587, "seek": 325800, "start": 3270.0, "end": 3275.0, "text": " So we get 4 minus 6 plus 5.", "tokens": [50964, 407, 321, 483, 1017, 3175, 1386, 1804, 1025, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09225114510983837, "compression_ratio": 1.2702702702702702, "no_speech_prob": 0.01342535950243473}, {"id": 588, "seek": 325800, "start": 3275.0, "end": 3280.0, "text": " That looks like 3 to me.", "tokens": [51214, 663, 1542, 411, 805, 281, 385, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09225114510983837, "compression_ratio": 1.2702702702702702, "no_speech_prob": 0.01342535950243473}, {"id": 589, "seek": 328000, "start": 3281.0, "end": 3291.0, "text": " So maybe what I should have written was this is u minus v, or sorry, u dot v.", "tokens": [50414, 407, 1310, 437, 286, 820, 362, 3720, 390, 341, 307, 344, 3175, 371, 11, 420, 2597, 11, 344, 5893, 371, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1244648679902282, "compression_ratio": 1.4355828220858895, "no_speech_prob": 0.04884194955229759}, {"id": 590, "seek": 328000, "start": 3291.0, "end": 3294.0, "text": " u dot v is equal to this.", "tokens": [50914, 344, 5893, 371, 307, 2681, 281, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1244648679902282, "compression_ratio": 1.4355828220858895, "no_speech_prob": 0.04884194955229759}, {"id": 591, "seek": 328000, "start": 3294.0, "end": 3300.0, "text": " We're taking u1 times v1 plus u2 times v2 plus u3 times vt, v3.", "tokens": [51064, 492, 434, 1940, 344, 16, 1413, 371, 16, 1804, 344, 17, 1413, 371, 17, 1804, 344, 18, 1413, 371, 83, 11, 371, 18, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1244648679902282, "compression_ratio": 1.4355828220858895, "no_speech_prob": 0.04884194955229759}, {"id": 592, "seek": 328000, "start": 3300.0, "end": 3306.0, "text": " And then we're just simplifying the numbers and it comes out to 3.", "tokens": [51364, 400, 550, 321, 434, 445, 6883, 5489, 264, 3547, 293, 309, 1487, 484, 281, 805, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1244648679902282, "compression_ratio": 1.4355828220858895, "no_speech_prob": 0.04884194955229759}, {"id": 593, "seek": 330600, "start": 3306.0, "end": 3314.0, "text": " So this maybe seems a little bit bizarre, but we'll see in the coming videos why this dot product is really useful.", "tokens": [50364, 407, 341, 1310, 2544, 257, 707, 857, 18265, 11, 457, 321, 603, 536, 294, 264, 1348, 2145, 983, 341, 5893, 1674, 307, 534, 4420, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06010196083470395, "compression_ratio": 1.5612244897959184, "no_speech_prob": 0.039030302315950394}, {"id": 594, "seek": 330600, "start": 3314.0, "end": 3316.0, "text": " See you then.", "tokens": [50764, 3008, 291, 550, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06010196083470395, "compression_ratio": 1.5612244897959184, "no_speech_prob": 0.039030302315950394}, {"id": 595, "seek": 330600, "start": 3316.0, "end": 3320.0, "text": " Let's look at some interesting consequences of the dot product.", "tokens": [50864, 961, 311, 574, 412, 512, 1880, 10098, 295, 264, 5893, 1674, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06010196083470395, "compression_ratio": 1.5612244897959184, "no_speech_prob": 0.039030302315950394}, {"id": 596, "seek": 330600, "start": 3320.0, "end": 3328.0, "text": " And the first one that I want to look at is the consequence it has for the definition of the length of a vector.", "tokens": [51064, 400, 264, 700, 472, 300, 286, 528, 281, 574, 412, 307, 264, 18326, 309, 575, 337, 264, 7123, 295, 264, 4641, 295, 257, 8062, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06010196083470395, "compression_ratio": 1.5612244897959184, "no_speech_prob": 0.039030302315950394}, {"id": 597, "seek": 332800, "start": 3328.0, "end": 3338.0, "text": " It turns out that because the way the dot product is defined, we can think of the length of the vector as the square root of the vector dotted with itself.", "tokens": [50364, 467, 4523, 484, 300, 570, 264, 636, 264, 5893, 1674, 307, 7642, 11, 321, 393, 519, 295, 264, 4641, 295, 264, 8062, 382, 264, 3732, 5593, 295, 264, 8062, 37459, 365, 2564, 13, 50864], "temperature": 0.0, "avg_logprob": -0.068196318870367, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.011330747045576572}, {"id": 598, "seek": 332800, "start": 3338.0, "end": 3341.0, "text": " And why does that make any sense?", "tokens": [50864, 400, 983, 775, 300, 652, 604, 2020, 30, 51014], "temperature": 0.0, "avg_logprob": -0.068196318870367, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.011330747045576572}, {"id": 599, "seek": 332800, "start": 3341.0, "end": 3353.0, "text": " Well, if we think about what this is equal to, this dot product here is just u1 times u1, which is u1 squared, plus u2 times u2,", "tokens": [51014, 1042, 11, 498, 321, 519, 466, 437, 341, 307, 2681, 281, 11, 341, 5893, 1674, 510, 307, 445, 344, 16, 1413, 344, 16, 11, 597, 307, 344, 16, 8889, 11, 1804, 344, 17, 1413, 344, 17, 11, 51614], "temperature": 0.0, "avg_logprob": -0.068196318870367, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.011330747045576572}, {"id": 600, "seek": 335300, "start": 3353.0, "end": 3360.0, "text": " which is u2 squared, plus all the way up to un times un, so un squared.", "tokens": [50364, 597, 307, 344, 17, 8889, 11, 1804, 439, 264, 636, 493, 281, 517, 1413, 517, 11, 370, 517, 8889, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 601, "seek": 335300, "start": 3360.0, "end": 3362.0, "text": " So that just comes from the definition of a dot product.", "tokens": [50714, 407, 300, 445, 1487, 490, 264, 7123, 295, 257, 5893, 1674, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 602, "seek": 335300, "start": 3362.0, "end": 3366.0, "text": " We take each of the components, we multiply them together, and we add them up.", "tokens": [50814, 492, 747, 1184, 295, 264, 6677, 11, 321, 12972, 552, 1214, 11, 293, 321, 909, 552, 493, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 603, "seek": 335300, "start": 3366.0, "end": 3370.0, "text": " And we already said that this is how we are going to define the length of a vector.", "tokens": [51014, 400, 321, 1217, 848, 300, 341, 307, 577, 321, 366, 516, 281, 6964, 264, 4641, 295, 257, 8062, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 604, "seek": 335300, "start": 3370.0, "end": 3376.0, "text": " Remember, we did this in two dimensions where we used the Pythagorean theorem to find the length of a vector.", "tokens": [51214, 5459, 11, 321, 630, 341, 294, 732, 12819, 689, 321, 1143, 264, 9953, 392, 559, 25885, 20904, 281, 915, 264, 4641, 295, 257, 8062, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 605, "seek": 335300, "start": 3376.0, "end": 3380.0, "text": " In more dimensions, we just keep adding the squares of the components.", "tokens": [51514, 682, 544, 12819, 11, 321, 445, 1066, 5127, 264, 19368, 295, 264, 6677, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07804238209958936, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.026349661871790886}, {"id": 606, "seek": 338000, "start": 3380.0, "end": 3385.0, "text": " If we have any more components we have, we square them and we add them underneath the square root.", "tokens": [50364, 759, 321, 362, 604, 544, 6677, 321, 362, 11, 321, 3732, 552, 293, 321, 909, 552, 7223, 264, 3732, 5593, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1328068394814768, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.06557346880435944}, {"id": 607, "seek": 338000, "start": 3385.0, "end": 3393.0, "text": " So that's the length of a vector, and so it makes sense that the square root of u dot u is the length of the vector.", "tokens": [50614, 407, 300, 311, 264, 4641, 295, 257, 8062, 11, 293, 370, 309, 1669, 2020, 300, 264, 3732, 5593, 295, 344, 5893, 344, 307, 264, 4641, 295, 264, 8062, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1328068394814768, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.06557346880435944}, {"id": 608, "seek": 338000, "start": 3393.0, "end": 3408.0, "text": " Also notice that, you know, this is a pretty natural follow up, but the length of a vector squared, that means, is equal to the vector dotted with itself.", "tokens": [51014, 2743, 3449, 300, 11, 291, 458, 11, 341, 307, 257, 1238, 3303, 1524, 493, 11, 457, 264, 4641, 295, 257, 8062, 8889, 11, 300, 1355, 11, 307, 2681, 281, 264, 8062, 37459, 365, 2564, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1328068394814768, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.06557346880435944}, {"id": 609, "seek": 340800, "start": 3408.0, "end": 3412.0, "text": " So we just squared both sides of this.", "tokens": [50364, 407, 321, 445, 8889, 1293, 4881, 295, 341, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12297044481549944, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.016651494428515434}, {"id": 610, "seek": 340800, "start": 3412.0, "end": 3418.0, "text": " Okay, that's pretty cool.", "tokens": [50564, 1033, 11, 300, 311, 1238, 1627, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12297044481549944, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.016651494428515434}, {"id": 611, "seek": 340800, "start": 3418.0, "end": 3420.0, "text": " What else?", "tokens": [50864, 708, 1646, 30, 50964], "temperature": 0.0, "avg_logprob": -0.12297044481549944, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.016651494428515434}, {"id": 612, "seek": 340800, "start": 3420.0, "end": 3432.0, "text": " Well, the more interesting thing that happens is it has to do with the angle between two vectors.", "tokens": [50964, 1042, 11, 264, 544, 1880, 551, 300, 2314, 307, 309, 575, 281, 360, 365, 264, 5802, 1296, 732, 18875, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12297044481549944, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.016651494428515434}, {"id": 613, "seek": 343200, "start": 3432.0, "end": 3441.0, "text": " So let's say this is u, and this is v, and this is theta.", "tokens": [50364, 407, 718, 311, 584, 341, 307, 344, 11, 293, 341, 307, 371, 11, 293, 341, 307, 9725, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08762757856767256, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.029750632122159004}, {"id": 614, "seek": 343200, "start": 3441.0, "end": 3447.0, "text": " Well, what if we did u minus v? We already talked about what u minus v is.", "tokens": [50814, 1042, 11, 437, 498, 321, 630, 344, 3175, 371, 30, 492, 1217, 2825, 466, 437, 344, 3175, 371, 307, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08762757856767256, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.029750632122159004}, {"id": 615, "seek": 343200, "start": 3447.0, "end": 3451.0, "text": " It's the vector that points from v to u.", "tokens": [51114, 467, 311, 264, 8062, 300, 2793, 490, 371, 281, 344, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08762757856767256, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.029750632122159004}, {"id": 616, "seek": 343200, "start": 3451.0, "end": 3459.0, "text": " Now, we've drawn a triangle here. What we can do is we can use the law of cosines to help us figure out this angle in here,", "tokens": [51314, 823, 11, 321, 600, 10117, 257, 13369, 510, 13, 708, 321, 393, 360, 307, 321, 393, 764, 264, 2101, 295, 3792, 1652, 281, 854, 505, 2573, 484, 341, 5802, 294, 510, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08762757856767256, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.029750632122159004}, {"id": 617, "seek": 345900, "start": 3459.0, "end": 3464.0, "text": " or to help us figure out this side, u minus v.", "tokens": [50364, 420, 281, 854, 505, 2573, 484, 341, 1252, 11, 344, 3175, 371, 13, 50614], "temperature": 0.0, "avg_logprob": -0.04789932250976563, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.0021155907306820154}, {"id": 618, "seek": 345900, "start": 3464.0, "end": 3472.0, "text": " So the law of cosines tells us that the length of the side we're trying to find, u minus v,", "tokens": [50614, 407, 264, 2101, 295, 3792, 1652, 5112, 505, 300, 264, 4641, 295, 264, 1252, 321, 434, 1382, 281, 915, 11, 344, 3175, 371, 11, 51014], "temperature": 0.0, "avg_logprob": -0.04789932250976563, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.0021155907306820154}, {"id": 619, "seek": 345900, "start": 3472.0, "end": 3479.0, "text": " so this is going all the way back to your geometry class, and you can look up the law of cosines if you don't remember it,", "tokens": [51014, 370, 341, 307, 516, 439, 264, 636, 646, 281, 428, 18426, 1508, 11, 293, 291, 393, 574, 493, 264, 2101, 295, 3792, 1652, 498, 291, 500, 380, 1604, 309, 11, 51364], "temperature": 0.0, "avg_logprob": -0.04789932250976563, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.0021155907306820154}, {"id": 620, "seek": 347900, "start": 3479.0, "end": 3487.0, "text": " but that length squared is equal to the length of one of the sides, that's u,", "tokens": [50364, 457, 300, 4641, 8889, 307, 2681, 281, 264, 4641, 295, 472, 295, 264, 4881, 11, 300, 311, 344, 11, 50764], "temperature": 0.0, "avg_logprob": -0.054632210069232516, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.18226398527622223}, {"id": 621, "seek": 347900, "start": 3487.0, "end": 3501.0, "text": " the length of u squared plus the length of v squared minus the length of u times the length of v.", "tokens": [50764, 264, 4641, 295, 344, 8889, 1804, 264, 4641, 295, 371, 8889, 3175, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 13, 51464], "temperature": 0.0, "avg_logprob": -0.054632210069232516, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.18226398527622223}, {"id": 622, "seek": 347900, "start": 3501.0, "end": 3507.0, "text": " So I know that these length symbols get really tedious, but I'm just going to keep going with them here.", "tokens": [51464, 407, 286, 458, 300, 613, 4641, 16944, 483, 534, 38284, 11, 457, 286, 478, 445, 516, 281, 1066, 516, 365, 552, 510, 13, 51764], "temperature": 0.0, "avg_logprob": -0.054632210069232516, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.18226398527622223}, {"id": 623, "seek": 350700, "start": 3507.0, "end": 3513.0, "text": " So minus the length of u times the length of v times the cosine of the angle between them.", "tokens": [50364, 407, 3175, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 1413, 264, 23565, 295, 264, 5802, 1296, 552, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07320366012916137, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0034830202348530293}, {"id": 624, "seek": 350700, "start": 3513.0, "end": 3521.0, "text": " So this comes from the law of cosines. It's really just saying c squared is equal to a squared plus b squared minus ab cos theta.", "tokens": [50664, 407, 341, 1487, 490, 264, 2101, 295, 3792, 1652, 13, 467, 311, 534, 445, 1566, 269, 8889, 307, 2681, 281, 257, 8889, 1804, 272, 8889, 3175, 410, 3792, 9725, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07320366012916137, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0034830202348530293}, {"id": 625, "seek": 350700, "start": 3521.0, "end": 3527.0, "text": " You might remember it better that way, but that's what we have. We have a side u minus v and a side u and a side v.", "tokens": [51064, 509, 1062, 1604, 309, 1101, 300, 636, 11, 457, 300, 311, 437, 321, 362, 13, 492, 362, 257, 1252, 344, 3175, 371, 293, 257, 1252, 344, 293, 257, 1252, 371, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07320366012916137, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0034830202348530293}, {"id": 626, "seek": 352700, "start": 3527.0, "end": 3532.0, "text": " So what we're going to do now is we're going to examine this side.", "tokens": [50364, 407, 437, 321, 434, 516, 281, 360, 586, 307, 321, 434, 516, 281, 17496, 341, 1252, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10165429424929928, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.11119488626718521}, {"id": 627, "seek": 352700, "start": 3532.0, "end": 3536.0, "text": " So let's pull that side out and look at it separately.", "tokens": [50614, 407, 718, 311, 2235, 300, 1252, 484, 293, 574, 412, 309, 14759, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10165429424929928, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.11119488626718521}, {"id": 628, "seek": 352700, "start": 3536.0, "end": 3546.0, "text": " So we have the length of u minus v squared, well that's just u minus v dotted with u minus v, so let's do that.", "tokens": [50814, 407, 321, 362, 264, 4641, 295, 344, 3175, 371, 8889, 11, 731, 300, 311, 445, 344, 3175, 371, 37459, 365, 344, 3175, 371, 11, 370, 718, 311, 360, 300, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10165429424929928, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.11119488626718521}, {"id": 629, "seek": 352700, "start": 3546.0, "end": 3552.0, "text": " u minus v dotted with itself.", "tokens": [51314, 344, 3175, 371, 37459, 365, 2564, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10165429424929928, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.11119488626718521}, {"id": 630, "seek": 355200, "start": 3552.0, "end": 3562.0, "text": " And now there's some properties of dot products that I haven't told you about that are going to become useful here,", "tokens": [50364, 400, 586, 456, 311, 512, 7221, 295, 5893, 3383, 300, 286, 2378, 380, 1907, 291, 466, 300, 366, 516, 281, 1813, 4420, 510, 11, 50864], "temperature": 0.0, "avg_logprob": -0.10300469118006089, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.001324949087575078}, {"id": 631, "seek": 355200, "start": 3562.0, "end": 3566.0, "text": " like commutativity, but we'll see that in action.", "tokens": [50864, 411, 800, 325, 30142, 11, 457, 321, 603, 536, 300, 294, 3069, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10300469118006089, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.001324949087575078}, {"id": 632, "seek": 355200, "start": 3566.0, "end": 3572.0, "text": " So u dot u, well we just talked about that, that's the length of u squared, so let's write that as that.", "tokens": [51064, 407, 344, 5893, 344, 11, 731, 321, 445, 2825, 466, 300, 11, 300, 311, 264, 4641, 295, 344, 8889, 11, 370, 718, 311, 2464, 300, 382, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10300469118006089, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.001324949087575078}, {"id": 633, "seek": 355200, "start": 3572.0, "end": 3580.0, "text": " u dot u is the length of u squared.", "tokens": [51364, 344, 5893, 344, 307, 264, 4641, 295, 344, 8889, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10300469118006089, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.001324949087575078}, {"id": 634, "seek": 358000, "start": 3580.0, "end": 3590.0, "text": " And then we have u dot, oh I have dot products in there, sorry that's a mistake, this should be u minus v, u minus v.", "tokens": [50364, 400, 550, 321, 362, 344, 5893, 11, 1954, 286, 362, 5893, 3383, 294, 456, 11, 2597, 300, 311, 257, 6146, 11, 341, 820, 312, 344, 3175, 371, 11, 344, 3175, 371, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12880117752972772, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.007120718248188496}, {"id": 635, "seek": 358000, "start": 3590.0, "end": 3606.0, "text": " So u dotted with minus v, that's minus, so let me write that on the side, minus u v, well minus u dot v.", "tokens": [50864, 407, 344, 37459, 365, 3175, 371, 11, 300, 311, 3175, 11, 370, 718, 385, 2464, 300, 322, 264, 1252, 11, 3175, 344, 371, 11, 731, 3175, 344, 5893, 371, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12880117752972772, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.007120718248188496}, {"id": 636, "seek": 360600, "start": 3606.0, "end": 3616.0, "text": " And then we have minus v dot u, so that's minus v dot u, but like I just said the dot product is commutative,", "tokens": [50364, 400, 550, 321, 362, 3175, 371, 5893, 344, 11, 370, 300, 311, 3175, 371, 5893, 344, 11, 457, 411, 286, 445, 848, 264, 5893, 1674, 307, 800, 325, 1166, 11, 50864], "temperature": 0.0, "avg_logprob": -0.07899345325518257, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02368409000337124}, {"id": 637, "seek": 360600, "start": 3616.0, "end": 3623.0, "text": " so this becomes, when we add those two together we just get minus two u dot v.", "tokens": [50864, 370, 341, 3643, 11, 562, 321, 909, 729, 732, 1214, 321, 445, 483, 3175, 732, 344, 5893, 371, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07899345325518257, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02368409000337124}, {"id": 638, "seek": 360600, "start": 3623.0, "end": 3626.0, "text": " So I hope that was relatively clear.", "tokens": [51214, 407, 286, 1454, 300, 390, 7226, 1850, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07899345325518257, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02368409000337124}, {"id": 639, "seek": 360600, "start": 3626.0, "end": 3632.0, "text": " We're just foiling this out with the dot product.", "tokens": [51364, 492, 434, 445, 726, 4883, 341, 484, 365, 264, 5893, 1674, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07899345325518257, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02368409000337124}, {"id": 640, "seek": 363200, "start": 3632.0, "end": 3642.0, "text": " So based on what we just talked about that's minus two times u dot v.", "tokens": [50364, 407, 2361, 322, 437, 321, 445, 2825, 466, 300, 311, 3175, 732, 1413, 344, 5893, 371, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09139713327935402, "compression_ratio": 1.4426229508196722, "no_speech_prob": 0.031138816848397255}, {"id": 641, "seek": 363200, "start": 3642.0, "end": 3652.0, "text": " So just to be explicit, really explicit here, that was this u coming over here and this v coming this way.", "tokens": [50864, 407, 445, 281, 312, 13691, 11, 534, 13691, 510, 11, 300, 390, 341, 344, 1348, 670, 510, 293, 341, 371, 1348, 341, 636, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09139713327935402, "compression_ratio": 1.4426229508196722, "no_speech_prob": 0.031138816848397255}, {"id": 642, "seek": 365200, "start": 3652.0, "end": 3659.0, "text": " So I had to pause the video because my phone was ringing, but yeah like I was saying this, u comes and multiplies that v,", "tokens": [50364, 407, 286, 632, 281, 10465, 264, 960, 570, 452, 2593, 390, 18423, 11, 457, 1338, 411, 286, 390, 1566, 341, 11, 344, 1487, 293, 12788, 530, 300, 371, 11, 50714], "temperature": 0.0, "avg_logprob": -0.13182062904040018, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.5270366668701172}, {"id": 643, "seek": 365200, "start": 3659.0, "end": 3664.0, "text": " this v comes and multiplies that u, so we get minus two u dot v.", "tokens": [50714, 341, 371, 1487, 293, 12788, 530, 300, 344, 11, 370, 321, 483, 3175, 732, 344, 5893, 371, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13182062904040018, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.5270366668701172}, {"id": 644, "seek": 365200, "start": 3664.0, "end": 3675.0, "text": " And then finally the v dotted with itself, well it's both negative so that's going to be plus the length of v squared.", "tokens": [50964, 400, 550, 2721, 264, 371, 37459, 365, 2564, 11, 731, 309, 311, 1293, 3671, 370, 300, 311, 516, 281, 312, 1804, 264, 4641, 295, 371, 8889, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13182062904040018, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.5270366668701172}, {"id": 645, "seek": 365200, "start": 3675.0, "end": 3679.0, "text": " This is just v dot v, turns out to be.", "tokens": [51514, 639, 307, 445, 371, 5893, 371, 11, 4523, 484, 281, 312, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13182062904040018, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.5270366668701172}, {"id": 646, "seek": 367900, "start": 3679.0, "end": 3682.0, "text": " So this is what the left hand side of the equation becomes.", "tokens": [50364, 407, 341, 307, 437, 264, 1411, 1011, 1252, 295, 264, 5367, 3643, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1446644186973572, "compression_ratio": 1.3214285714285714, "no_speech_prob": 0.01743912510573864}, {"id": 647, "seek": 367900, "start": 3682.0, "end": 3692.0, "text": " So why don't we substitute that into this, the law of cosines essentially, what we have.", "tokens": [50514, 407, 983, 500, 380, 321, 15802, 300, 666, 341, 11, 264, 2101, 295, 3792, 1652, 4476, 11, 437, 321, 362, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1446644186973572, "compression_ratio": 1.3214285714285714, "no_speech_prob": 0.01743912510573864}, {"id": 648, "seek": 369200, "start": 3692.0, "end": 3712.0, "text": " So this is u squared, the length of u squared, minus two u dot v, plus the length of v squared, is equal to the length of u squared.", "tokens": [50364, 407, 341, 307, 344, 8889, 11, 264, 4641, 295, 344, 8889, 11, 3175, 732, 344, 5893, 371, 11, 1804, 264, 4641, 295, 371, 8889, 11, 307, 2681, 281, 264, 4641, 295, 344, 8889, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11026008667484406, "compression_ratio": 1.9322033898305084, "no_speech_prob": 0.5232464075088501}, {"id": 649, "seek": 369200, "start": 3712.0, "end": 3720.0, "text": " So this is now the right hand side of the equation from up there, plus the length of v squared,", "tokens": [51364, 407, 341, 307, 586, 264, 558, 1011, 1252, 295, 264, 5367, 490, 493, 456, 11, 1804, 264, 4641, 295, 371, 8889, 11, 51764], "temperature": 0.0, "avg_logprob": -0.11026008667484406, "compression_ratio": 1.9322033898305084, "no_speech_prob": 0.5232464075088501}, {"id": 650, "seek": 372000, "start": 3720.0, "end": 3730.0, "text": " minus the length of u times the length of v times the cosine of the angle between them.", "tokens": [50364, 3175, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 1413, 264, 23565, 295, 264, 5802, 1296, 552, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08007621765136719, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.12586839497089386}, {"id": 651, "seek": 372000, "start": 3730.0, "end": 3737.0, "text": " Okay so now we get to do a lot of canceling here, so let's see.", "tokens": [50864, 1033, 370, 586, 321, 483, 281, 360, 257, 688, 295, 10373, 278, 510, 11, 370, 718, 311, 536, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08007621765136719, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.12586839497089386}, {"id": 652, "seek": 372000, "start": 3737.0, "end": 3742.0, "text": " This and this are going to go away, we can subtract those from both sides, those are going to go away.", "tokens": [51214, 639, 293, 341, 366, 516, 281, 352, 1314, 11, 321, 393, 16390, 729, 490, 1293, 4881, 11, 729, 366, 516, 281, 352, 1314, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08007621765136719, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.12586839497089386}, {"id": 653, "seek": 372000, "start": 3742.0, "end": 3745.0, "text": " Oh jeez I did something terribly wrong here.", "tokens": [51464, 876, 1506, 4371, 286, 630, 746, 22903, 2085, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08007621765136719, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.12586839497089386}, {"id": 654, "seek": 372000, "start": 3745.0, "end": 3749.0, "text": " This is not the law of cosines, we need a minus two.", "tokens": [51614, 639, 307, 406, 264, 2101, 295, 3792, 1652, 11, 321, 643, 257, 3175, 732, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08007621765136719, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.12586839497089386}, {"id": 655, "seek": 374900, "start": 3749.0, "end": 3752.0, "text": " That means we need a minus two down here.", "tokens": [50364, 663, 1355, 321, 643, 257, 3175, 732, 760, 510, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07443981617689133, "compression_ratio": 1.4876543209876543, "no_speech_prob": 0.0035932790488004684}, {"id": 656, "seek": 374900, "start": 3752.0, "end": 3758.0, "text": " And then we can divide the minus two on both sides though, so that's pretty cool.", "tokens": [50514, 400, 550, 321, 393, 9845, 264, 3175, 732, 322, 1293, 4881, 1673, 11, 370, 300, 311, 1238, 1627, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07443981617689133, "compression_ratio": 1.4876543209876543, "no_speech_prob": 0.0035932790488004684}, {"id": 657, "seek": 374900, "start": 3758.0, "end": 3760.0, "text": " So sorry for forgetting that for the whole video.", "tokens": [50814, 407, 2597, 337, 25428, 300, 337, 264, 1379, 960, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07443981617689133, "compression_ratio": 1.4876543209876543, "no_speech_prob": 0.0035932790488004684}, {"id": 658, "seek": 374900, "start": 3760.0, "end": 3764.0, "text": " And what do we end up with after we do all that crazy cancellation?", "tokens": [50914, 400, 437, 360, 321, 917, 493, 365, 934, 321, 360, 439, 300, 3219, 45867, 30, 51114], "temperature": 0.0, "avg_logprob": -0.07443981617689133, "compression_ratio": 1.4876543209876543, "no_speech_prob": 0.0035932790488004684}, {"id": 659, "seek": 376400, "start": 3764.0, "end": 3784.0, "text": " Well we just end up with u dot v on this side is equal to the length of u times the length of v times the cosine of the angle between them.", "tokens": [50364, 1042, 321, 445, 917, 493, 365, 344, 5893, 371, 322, 341, 1252, 307, 2681, 281, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 1413, 264, 23565, 295, 264, 5802, 1296, 552, 13, 51364], "temperature": 0.0, "avg_logprob": -0.054846376986116975, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.07368025183677673}, {"id": 660, "seek": 378400, "start": 3784.0, "end": 3793.0, "text": " And now that is really cool because as long as we're given the vectors u and v, we could figure out what u dot v is based on the definition,", "tokens": [50364, 400, 586, 300, 307, 534, 1627, 570, 382, 938, 382, 321, 434, 2212, 264, 18875, 344, 293, 371, 11, 321, 727, 2573, 484, 437, 344, 5893, 371, 307, 2361, 322, 264, 7123, 11, 50814], "temperature": 0.0, "avg_logprob": -0.09030256465989717, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.43358293175697327}, {"id": 661, "seek": 378400, "start": 3793.0, "end": 3800.0, "text": " sum up the products of the components, and then we can figure out the lengths, we know how to do that,", "tokens": [50814, 2408, 493, 264, 3383, 295, 264, 6677, 11, 293, 550, 321, 393, 2573, 484, 264, 26329, 11, 321, 458, 577, 281, 360, 300, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09030256465989717, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.43358293175697327}, {"id": 662, "seek": 378400, "start": 3800.0, "end": 3805.0, "text": " we just take the square root of the sum of the square of the components,", "tokens": [51164, 321, 445, 747, 264, 3732, 5593, 295, 264, 2408, 295, 264, 3732, 295, 264, 6677, 11, 51414], "temperature": 0.0, "avg_logprob": -0.09030256465989717, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.43358293175697327}, {"id": 663, "seek": 378400, "start": 3805.0, "end": 3809.0, "text": " and then we have this cosine of theta so we can solve for theta,", "tokens": [51414, 293, 550, 321, 362, 341, 23565, 295, 9725, 370, 321, 393, 5039, 337, 9725, 11, 51614], "temperature": 0.0, "avg_logprob": -0.09030256465989717, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.43358293175697327}, {"id": 664, "seek": 380900, "start": 3809.0, "end": 3814.0, "text": " and we can figure out the angle between two vectors just knowing what the two vectors are.", "tokens": [50364, 293, 321, 393, 2573, 484, 264, 5802, 1296, 732, 18875, 445, 5276, 437, 264, 732, 18875, 366, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09094337494142594, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.019413072615861893}, {"id": 665, "seek": 380900, "start": 3814.0, "end": 3815.0, "text": " So that's really cool.", "tokens": [50614, 407, 300, 311, 534, 1627, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09094337494142594, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.019413072615861893}, {"id": 666, "seek": 380900, "start": 3815.0, "end": 3829.0, "text": " So in fact, remember that this proof came from the law of cosines which only really works in two dimensions, we're talking about a triangle.", "tokens": [50664, 407, 294, 1186, 11, 1604, 300, 341, 8177, 1361, 490, 264, 2101, 295, 3792, 1652, 597, 787, 534, 1985, 294, 732, 12819, 11, 321, 434, 1417, 466, 257, 13369, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09094337494142594, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.019413072615861893}, {"id": 667, "seek": 382900, "start": 3829.0, "end": 3854.0, "text": " So when we go to higher dimensions we take it as a definition that the cosine of theta is equal to u dot v divided by the length of u times the length of v.", "tokens": [50364, 407, 562, 321, 352, 281, 2946, 12819, 321, 747, 309, 382, 257, 7123, 300, 264, 23565, 295, 9725, 307, 2681, 281, 344, 5893, 371, 6666, 538, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06878596645290569, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003884069388732314}, {"id": 668, "seek": 382900, "start": 3854.0, "end": 3858.0, "text": " So that just comes because we just divided by length of u, length of v.", "tokens": [51614, 407, 300, 445, 1487, 570, 321, 445, 6666, 538, 4641, 295, 344, 11, 4641, 295, 371, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06878596645290569, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003884069388732314}, {"id": 669, "seek": 385800, "start": 3858.0, "end": 3862.0, "text": " So notice two things happen here.", "tokens": [50364, 407, 3449, 732, 721, 1051, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 670, "seek": 385800, "start": 3862.0, "end": 3870.0, "text": " One, we have an alternate definition for the dot product or an alternate way to express the dot product.", "tokens": [50564, 1485, 11, 321, 362, 364, 18873, 7123, 337, 264, 5893, 1674, 420, 364, 18873, 636, 281, 5109, 264, 5893, 1674, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 671, "seek": 385800, "start": 3870.0, "end": 3878.0, "text": " And also now we have a way to express the angle between two vectors in terms of the dot product.", "tokens": [50964, 400, 611, 586, 321, 362, 257, 636, 281, 5109, 264, 5802, 1296, 732, 18875, 294, 2115, 295, 264, 5893, 1674, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 672, "seek": 385800, "start": 3878.0, "end": 3880.0, "text": " And that's really cool.", "tokens": [51364, 400, 300, 311, 534, 1627, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 673, "seek": 385800, "start": 3880.0, "end": 3881.0, "text": " So I hope this helps.", "tokens": [51464, 407, 286, 1454, 341, 3665, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 674, "seek": 385800, "start": 3881.0, "end": 3883.0, "text": " I'll see you in the next video.", "tokens": [51514, 286, 603, 536, 291, 294, 264, 958, 960, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08983702319008964, "compression_ratio": 1.729281767955801, "no_speech_prob": 0.05831851065158844}, {"id": 675, "seek": 388300, "start": 3883.0, "end": 3888.0, "text": " Let's use what we know about the dot product to find the angle between these two vectors.", "tokens": [50364, 961, 311, 764, 437, 321, 458, 466, 264, 5893, 1674, 281, 915, 264, 5802, 1296, 613, 732, 18875, 13, 50614], "temperature": 0.0, "avg_logprob": -0.04506505980636134, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.675094485282898}, {"id": 676, "seek": 388300, "start": 3888.0, "end": 3912.0, "text": " So what we're going to do is remember our little formula which says that the cosine of the angle between two vectors is equal to u dot v divided by the length of u times the length of v.", "tokens": [50614, 407, 437, 321, 434, 516, 281, 360, 307, 1604, 527, 707, 8513, 597, 1619, 300, 264, 23565, 295, 264, 5802, 1296, 732, 18875, 307, 2681, 281, 344, 5893, 371, 6666, 538, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 13, 51814], "temperature": 0.0, "avg_logprob": -0.04506505980636134, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.675094485282898}, {"id": 677, "seek": 391200, "start": 3912.0, "end": 3917.0, "text": " So if we want to find the angle between two vectors we have to do just a few computations.", "tokens": [50364, 407, 498, 321, 528, 281, 915, 264, 5802, 1296, 732, 18875, 321, 362, 281, 360, 445, 257, 1326, 2807, 763, 13, 50614], "temperature": 0.0, "avg_logprob": -0.053100516579367894, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05919630080461502}, {"id": 678, "seek": 391200, "start": 3917.0, "end": 3925.0, "text": " We have to find the dot product and then we have to find the length of each vector.", "tokens": [50614, 492, 362, 281, 915, 264, 5893, 1674, 293, 550, 321, 362, 281, 915, 264, 4641, 295, 1184, 8062, 13, 51014], "temperature": 0.0, "avg_logprob": -0.053100516579367894, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05919630080461502}, {"id": 679, "seek": 391200, "start": 3925.0, "end": 3928.0, "text": " So let's go through that.", "tokens": [51014, 407, 718, 311, 352, 807, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.053100516579367894, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.05919630080461502}, {"id": 680, "seek": 392800, "start": 3928.0, "end": 3950.0, "text": " So the dot product of u and v, so u dot v, u dot v is equal to two times one, that's two, plus one times one, that's one, plus negative two times one, that's just negative two or minus two.", "tokens": [50364, 407, 264, 5893, 1674, 295, 344, 293, 371, 11, 370, 344, 5893, 371, 11, 344, 5893, 371, 307, 2681, 281, 732, 1413, 472, 11, 300, 311, 732, 11, 1804, 472, 1413, 472, 11, 300, 311, 472, 11, 1804, 3671, 732, 1413, 472, 11, 300, 311, 445, 3671, 732, 420, 3175, 732, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08415532834602124, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.26269763708114624}, {"id": 681, "seek": 392800, "start": 3950.0, "end": 3956.0, "text": " So this comes out to be one.", "tokens": [51464, 407, 341, 1487, 484, 281, 312, 472, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08415532834602124, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.26269763708114624}, {"id": 682, "seek": 395600, "start": 3956.0, "end": 3960.0, "text": " So the dot product is one, let's do the length of u now in the length of v.", "tokens": [50364, 407, 264, 5893, 1674, 307, 472, 11, 718, 311, 360, 264, 4641, 295, 344, 586, 294, 264, 4641, 295, 371, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07226576676239839, "compression_ratio": 2.1627906976744184, "no_speech_prob": 0.027578461915254593}, {"id": 683, "seek": 395600, "start": 3960.0, "end": 3972.0, "text": " So the length of u is equal to the square root of two squared plus one squared plus negative two squared.", "tokens": [50564, 407, 264, 4641, 295, 344, 307, 2681, 281, 264, 3732, 5593, 295, 732, 8889, 1804, 472, 8889, 1804, 3671, 732, 8889, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07226576676239839, "compression_ratio": 2.1627906976744184, "no_speech_prob": 0.027578461915254593}, {"id": 684, "seek": 395600, "start": 3972.0, "end": 3979.0, "text": " So two squared is four, plus one squared is one, plus negative two squared is four, so plus four.", "tokens": [51164, 407, 732, 8889, 307, 1451, 11, 1804, 472, 8889, 307, 472, 11, 1804, 3671, 732, 8889, 307, 1451, 11, 370, 1804, 1451, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07226576676239839, "compression_ratio": 2.1627906976744184, "no_speech_prob": 0.027578461915254593}, {"id": 685, "seek": 397900, "start": 3979.0, "end": 3986.0, "text": " So this is the square root of nine if we add those together and the square root of nine is just three.", "tokens": [50364, 407, 341, 307, 264, 3732, 5593, 295, 4949, 498, 321, 909, 729, 1214, 293, 264, 3732, 5593, 295, 4949, 307, 445, 1045, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07319309836939762, "compression_ratio": 1.9464285714285714, "no_speech_prob": 0.3921082317829132}, {"id": 686, "seek": 397900, "start": 3986.0, "end": 3990.0, "text": " And now let's do the length of v.", "tokens": [50714, 400, 586, 718, 311, 360, 264, 4641, 295, 371, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07319309836939762, "compression_ratio": 1.9464285714285714, "no_speech_prob": 0.3921082317829132}, {"id": 687, "seek": 397900, "start": 3990.0, "end": 3998.0, "text": " So all we're doing is just doing the necessary computations based on this formula and we derived this formula in the last video.", "tokens": [50914, 407, 439, 321, 434, 884, 307, 445, 884, 264, 4818, 2807, 763, 2361, 322, 341, 8513, 293, 321, 18949, 341, 8513, 294, 264, 1036, 960, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07319309836939762, "compression_ratio": 1.9464285714285714, "no_speech_prob": 0.3921082317829132}, {"id": 688, "seek": 397900, "start": 3998.0, "end": 4001.0, "text": " So if you're curious about that go back and watch that.", "tokens": [51314, 407, 498, 291, 434, 6369, 466, 300, 352, 646, 293, 1159, 300, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07319309836939762, "compression_ratio": 1.9464285714285714, "no_speech_prob": 0.3921082317829132}, {"id": 689, "seek": 397900, "start": 4001.0, "end": 4007.0, "text": " So now we have one squared, well that's just one, plus one squared, well that's one, plus one squared, that's one.", "tokens": [51464, 407, 586, 321, 362, 472, 8889, 11, 731, 300, 311, 445, 472, 11, 1804, 472, 8889, 11, 731, 300, 311, 472, 11, 1804, 472, 8889, 11, 300, 311, 472, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07319309836939762, "compression_ratio": 1.9464285714285714, "no_speech_prob": 0.3921082317829132}, {"id": 690, "seek": 400700, "start": 4007.0, "end": 4012.0, "text": " So this is the square root of three.", "tokens": [50364, 407, 341, 307, 264, 3732, 5593, 295, 1045, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06654495133294, "compression_ratio": 1.8342245989304813, "no_speech_prob": 0.013635692186653614}, {"id": 691, "seek": 400700, "start": 4012.0, "end": 4018.0, "text": " So we have our necessary pieces here, so let's put them all together.", "tokens": [50614, 407, 321, 362, 527, 4818, 3755, 510, 11, 370, 718, 311, 829, 552, 439, 1214, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06654495133294, "compression_ratio": 1.8342245989304813, "no_speech_prob": 0.013635692186653614}, {"id": 692, "seek": 400700, "start": 4018.0, "end": 4029.0, "text": " So we have the cosine of the angle between the two vectors is equal to the dot product of the two vectors, which we found was equal to one,", "tokens": [50914, 407, 321, 362, 264, 23565, 295, 264, 5802, 1296, 264, 732, 18875, 307, 2681, 281, 264, 5893, 1674, 295, 264, 732, 18875, 11, 597, 321, 1352, 390, 2681, 281, 472, 11, 51464], "temperature": 0.0, "avg_logprob": -0.06654495133294, "compression_ratio": 1.8342245989304813, "no_speech_prob": 0.013635692186653614}, {"id": 693, "seek": 400700, "start": 4029.0, "end": 4036.0, "text": " divided by the length of u, that's three times the length of v, that's the square root of three.", "tokens": [51464, 6666, 538, 264, 4641, 295, 344, 11, 300, 311, 1045, 1413, 264, 4641, 295, 371, 11, 300, 311, 264, 3732, 5593, 295, 1045, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06654495133294, "compression_ratio": 1.8342245989304813, "no_speech_prob": 0.013635692186653614}, {"id": 694, "seek": 403600, "start": 4036.0, "end": 4055.0, "text": " So this is the cosine of the angle, so to find the angle theta is just equal to the arc cos or the inverse cos of one divided by three times the square root of three.", "tokens": [50364, 407, 341, 307, 264, 23565, 295, 264, 5802, 11, 370, 281, 915, 264, 5802, 9725, 307, 445, 2681, 281, 264, 10346, 3792, 420, 264, 17340, 3792, 295, 472, 6666, 538, 1045, 1413, 264, 3732, 5593, 295, 1045, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10092771437860304, "compression_ratio": 1.5677419354838709, "no_speech_prob": 0.0015977362636476755}, {"id": 695, "seek": 403600, "start": 4055.0, "end": 4062.0, "text": " And now to find this we would have to use a calculator or a table of values.", "tokens": [51314, 400, 586, 281, 915, 341, 321, 576, 362, 281, 764, 257, 24993, 420, 257, 3199, 295, 4190, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10092771437860304, "compression_ratio": 1.5677419354838709, "no_speech_prob": 0.0015977362636476755}, {"id": 696, "seek": 406200, "start": 4062.0, "end": 4069.0, "text": " And so I'll spare us the pain, but you should maybe do that on your calculator just to make sure you get the right answer.", "tokens": [50364, 400, 370, 286, 603, 13798, 505, 264, 1822, 11, 457, 291, 820, 1310, 360, 300, 322, 428, 24993, 445, 281, 652, 988, 291, 483, 264, 558, 1867, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08912617713212967, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.15393708646297455}, {"id": 697, "seek": 406200, "start": 4069.0, "end": 4080.0, "text": " And this comes out to 1.37 radians, or I should write this is approximately equal, rounding a little bit or truncating.", "tokens": [50714, 400, 341, 1487, 484, 281, 502, 13, 12851, 2843, 2567, 11, 420, 286, 820, 2464, 341, 307, 10447, 2681, 11, 48237, 257, 707, 857, 420, 504, 409, 66, 990, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08912617713212967, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.15393708646297455}, {"id": 698, "seek": 408000, "start": 4080.0, "end": 4095.0, "text": " So this is approximately equal to 1.37 radians, and if your calculator is in degree mode, then that's approximately 78.9 degrees.", "tokens": [50364, 407, 341, 307, 10447, 2681, 281, 502, 13, 12851, 2843, 2567, 11, 293, 498, 428, 24993, 307, 294, 4314, 4391, 11, 550, 300, 311, 10447, 26369, 13, 24, 5310, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09605665448345715, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.425706684589386}, {"id": 699, "seek": 408000, "start": 4095.0, "end": 4098.0, "text": " Okay, so nothing too terribly difficult.", "tokens": [51114, 1033, 11, 370, 1825, 886, 22903, 2252, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09605665448345715, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.425706684589386}, {"id": 700, "seek": 408000, "start": 4098.0, "end": 4104.0, "text": " We just got to compute the dot product, compute the length of the vectors, and everything falls into place.", "tokens": [51264, 492, 445, 658, 281, 14722, 264, 5893, 1674, 11, 14722, 264, 4641, 295, 264, 18875, 11, 293, 1203, 8804, 666, 1081, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09605665448345715, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.425706684589386}, {"id": 701, "seek": 408000, "start": 4104.0, "end": 4107.0, "text": " Okay, see you in the next video.", "tokens": [51564, 1033, 11, 536, 291, 294, 264, 958, 960, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09605665448345715, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.425706684589386}, {"id": 702, "seek": 410700, "start": 4107.0, "end": 4113.0, "text": " In the last video we learned the definition of the cosine between two vectors.", "tokens": [50364, 682, 264, 1036, 960, 321, 3264, 264, 7123, 295, 264, 23565, 1296, 732, 18875, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05314433097839356, "compression_ratio": 1.701086956521739, "no_speech_prob": 0.0070107439532876015}, {"id": 703, "seek": 410700, "start": 4113.0, "end": 4122.0, "text": " In fact, we pretty much derived this, so we said the cosine of the angle between two vectors is u dot v divided by the length of u times the length of v.", "tokens": [50664, 682, 1186, 11, 321, 1238, 709, 18949, 341, 11, 370, 321, 848, 264, 23565, 295, 264, 5802, 1296, 732, 18875, 307, 344, 5893, 371, 6666, 538, 264, 4641, 295, 344, 1413, 264, 4641, 295, 371, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05314433097839356, "compression_ratio": 1.701086956521739, "no_speech_prob": 0.0070107439532876015}, {"id": 704, "seek": 410700, "start": 4122.0, "end": 4130.0, "text": " So let's see what we can determine about two vectors when they're perpendicular.", "tokens": [51114, 407, 718, 311, 536, 437, 321, 393, 6997, 466, 732, 18875, 562, 436, 434, 26734, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05314433097839356, "compression_ratio": 1.701086956521739, "no_speech_prob": 0.0070107439532876015}, {"id": 705, "seek": 413000, "start": 4130.0, "end": 4136.0, "text": " So if two vectors are perpendicular, what we say is they're orthogonal.", "tokens": [50364, 407, 498, 732, 18875, 366, 26734, 11, 437, 321, 584, 307, 436, 434, 41488, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 706, "seek": 413000, "start": 4136.0, "end": 4140.0, "text": " So that's the word we use for perpendicular vectors.", "tokens": [50664, 407, 300, 311, 264, 1349, 321, 764, 337, 26734, 18875, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 707, "seek": 413000, "start": 4140.0, "end": 4142.0, "text": " And let's see what we can determine.", "tokens": [50864, 400, 718, 311, 536, 437, 321, 393, 6997, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 708, "seek": 413000, "start": 4142.0, "end": 4144.0, "text": " So u and v here.", "tokens": [50964, 407, 344, 293, 371, 510, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 709, "seek": 413000, "start": 4144.0, "end": 4151.0, "text": " So this angle, of course, is pi over 2, or 90 degrees.", "tokens": [51064, 407, 341, 5802, 11, 295, 1164, 11, 307, 3895, 670, 568, 11, 420, 4289, 5310, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 710, "seek": 413000, "start": 4151.0, "end": 4153.0, "text": " And what does that mean?", "tokens": [51414, 400, 437, 775, 300, 914, 30, 51514], "temperature": 0.0, "avg_logprob": -0.09903247015816825, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.0029348365496844053}, {"id": 711, "seek": 415300, "start": 4153.0, "end": 4169.0, "text": " Well, by our definition of the angle between two vectors, that means that the cosine of pi over 2 is equal to this dot product.", "tokens": [50364, 1042, 11, 538, 527, 7123, 295, 264, 5802, 1296, 732, 18875, 11, 300, 1355, 300, 264, 23565, 295, 3895, 670, 568, 307, 2681, 281, 341, 5893, 1674, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0659710545288889, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.016401492059230804}, {"id": 712, "seek": 415300, "start": 4169.0, "end": 4173.0, "text": " And while I'm writing this, think about what is the cosine of pi over 2?", "tokens": [51164, 400, 1339, 286, 478, 3579, 341, 11, 519, 466, 437, 307, 264, 23565, 295, 3895, 670, 568, 30, 51364], "temperature": 0.0, "avg_logprob": -0.0659710545288889, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.016401492059230804}, {"id": 713, "seek": 415300, "start": 4173.0, "end": 4175.0, "text": " What is that equal to?", "tokens": [51364, 708, 307, 300, 2681, 281, 30, 51464], "temperature": 0.0, "avg_logprob": -0.0659710545288889, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.016401492059230804}, {"id": 714, "seek": 415300, "start": 4175.0, "end": 4181.0, "text": " We know what it is, it's just a number, right?", "tokens": [51464, 492, 458, 437, 309, 307, 11, 309, 311, 445, 257, 1230, 11, 558, 30, 51764], "temperature": 0.0, "avg_logprob": -0.0659710545288889, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.016401492059230804}, {"id": 715, "seek": 418100, "start": 4181.0, "end": 4185.0, "text": " Well, the cosine of pi over 2 is zero.", "tokens": [50364, 1042, 11, 264, 23565, 295, 3895, 670, 568, 307, 4018, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 716, "seek": 418100, "start": 4185.0, "end": 4191.0, "text": " So all three of these things are equal, and they're all equal to zero.", "tokens": [50564, 407, 439, 1045, 295, 613, 721, 366, 2681, 11, 293, 436, 434, 439, 2681, 281, 4018, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 717, "seek": 418100, "start": 4191.0, "end": 4194.0, "text": " Excuse me.", "tokens": [50864, 11359, 385, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 718, "seek": 418100, "start": 4194.0, "end": 4196.0, "text": " So what does that tell us?", "tokens": [51014, 407, 437, 775, 300, 980, 505, 30, 51114], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 719, "seek": 418100, "start": 4196.0, "end": 4203.0, "text": " Well, that tells us that u dot v must be equal to zero.", "tokens": [51114, 1042, 11, 300, 5112, 505, 300, 344, 5893, 371, 1633, 312, 2681, 281, 4018, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 720, "seek": 418100, "start": 4203.0, "end": 4209.0, "text": " So this implies that u dot v is equal to zero.", "tokens": [51464, 407, 341, 18779, 300, 344, 5893, 371, 307, 2681, 281, 4018, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08441806744925584, "compression_ratio": 1.6556291390728477, "no_speech_prob": 0.0006070670206099749}, {"id": 721, "seek": 420900, "start": 4209.0, "end": 4214.0, "text": " And that's because the denominator here will never make this fraction zero.", "tokens": [50364, 400, 300, 311, 570, 264, 20687, 510, 486, 1128, 652, 341, 14135, 4018, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 722, "seek": 420900, "start": 4214.0, "end": 4220.0, "text": " Okay, so if the vectors are orthogonal, then the dot product is zero.", "tokens": [50614, 1033, 11, 370, 498, 264, 18875, 366, 41488, 11, 550, 264, 5893, 1674, 307, 4018, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 723, "seek": 420900, "start": 4220.0, "end": 4222.0, "text": " And in fact, that works in the other direction.", "tokens": [50914, 400, 294, 1186, 11, 300, 1985, 294, 264, 661, 3513, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 724, "seek": 420900, "start": 4222.0, "end": 4226.0, "text": " If the dot product is zero, the vectors are orthogonal.", "tokens": [51014, 759, 264, 5893, 1674, 307, 4018, 11, 264, 18875, 366, 41488, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 725, "seek": 420900, "start": 4226.0, "end": 4229.0, "text": " So now we have a definition of orthogonal.", "tokens": [51214, 407, 586, 321, 362, 257, 7123, 295, 41488, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 726, "seek": 420900, "start": 4229.0, "end": 4232.0, "text": " Two vectors are orthogonal.", "tokens": [51364, 4453, 18875, 366, 41488, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05765600557680483, "compression_ratio": 1.807909604519774, "no_speech_prob": 0.0002034219360211864}, {"id": 727, "seek": 423200, "start": 4232.0, "end": 4240.0, "text": " So two, well, let me write this, two vectors u and v are orthogonal if and only if.", "tokens": [50364, 407, 732, 11, 731, 11, 718, 385, 2464, 341, 11, 732, 18875, 344, 293, 371, 366, 41488, 498, 293, 787, 498, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10025304087092367, "compression_ratio": 1.8208092485549132, "no_speech_prob": 0.0009697297355160117}, {"id": 728, "seek": 423200, "start": 4240.0, "end": 4245.0, "text": " If you've never seen this before, this is shorthand notation for if and only if.", "tokens": [50764, 759, 291, 600, 1128, 1612, 341, 949, 11, 341, 307, 402, 2652, 474, 24657, 337, 498, 293, 787, 498, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10025304087092367, "compression_ratio": 1.8208092485549132, "no_speech_prob": 0.0009697297355160117}, {"id": 729, "seek": 423200, "start": 4245.0, "end": 4256.0, "text": " Two vectors are u and v are orthogonal if and only if u dot v is equal to zero.", "tokens": [51014, 4453, 18875, 366, 344, 293, 371, 366, 41488, 498, 293, 787, 498, 344, 5893, 371, 307, 2681, 281, 4018, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10025304087092367, "compression_ratio": 1.8208092485549132, "no_speech_prob": 0.0009697297355160117}, {"id": 730, "seek": 423200, "start": 4256.0, "end": 4261.0, "text": " So now we have a nice, easy way to test if two vectors are orthogonal.", "tokens": [51564, 407, 586, 321, 362, 257, 1481, 11, 1858, 636, 281, 1500, 498, 732, 18875, 366, 41488, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10025304087092367, "compression_ratio": 1.8208092485549132, "no_speech_prob": 0.0009697297355160117}, {"id": 731, "seek": 426100, "start": 4261.0, "end": 4266.0, "text": " So let's take a look at that.", "tokens": [50364, 407, 718, 311, 747, 257, 574, 412, 300, 13, 50614], "temperature": 0.0, "avg_logprob": -0.056992556367601664, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009697092464193702}, {"id": 732, "seek": 426100, "start": 4266.0, "end": 4272.0, "text": " So let's take some two easy vectors with just two components and see what happens.", "tokens": [50614, 407, 718, 311, 747, 512, 732, 1858, 18875, 365, 445, 732, 6677, 293, 536, 437, 2314, 13, 50914], "temperature": 0.0, "avg_logprob": -0.056992556367601664, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009697092464193702}, {"id": 733, "seek": 426100, "start": 4272.0, "end": 4288.0, "text": " So let's say u is equal to negative three, four, and v is equal to four, three.", "tokens": [50914, 407, 718, 311, 584, 344, 307, 2681, 281, 3671, 1045, 11, 1451, 11, 293, 371, 307, 2681, 281, 1451, 11, 1045, 13, 51714], "temperature": 0.0, "avg_logprob": -0.056992556367601664, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009697092464193702}, {"id": 734, "seek": 428800, "start": 4288.0, "end": 4292.0, "text": " So let's do their dot product really quickly.", "tokens": [50364, 407, 718, 311, 360, 641, 5893, 1674, 534, 2661, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07250172158946162, "compression_ratio": 1.5748502994011977, "no_speech_prob": 0.00044421435450203717}, {"id": 735, "seek": 428800, "start": 4292.0, "end": 4305.0, "text": " u dot v is equal to negative three times four, negative three times four, plus four times three.", "tokens": [50564, 344, 5893, 371, 307, 2681, 281, 3671, 1045, 1413, 1451, 11, 3671, 1045, 1413, 1451, 11, 1804, 1451, 1413, 1045, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07250172158946162, "compression_ratio": 1.5748502994011977, "no_speech_prob": 0.00044421435450203717}, {"id": 736, "seek": 428800, "start": 4305.0, "end": 4311.0, "text": " Well, it's pretty clear this is negative 12 plus 12, so that's zero.", "tokens": [51214, 1042, 11, 309, 311, 1238, 1850, 341, 307, 3671, 2272, 1804, 2272, 11, 370, 300, 311, 4018, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07250172158946162, "compression_ratio": 1.5748502994011977, "no_speech_prob": 0.00044421435450203717}, {"id": 737, "seek": 428800, "start": 4311.0, "end": 4315.0, "text": " So by definition, these two vectors are orthogonal.", "tokens": [51514, 407, 538, 7123, 11, 613, 732, 18875, 366, 41488, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07250172158946162, "compression_ratio": 1.5748502994011977, "no_speech_prob": 0.00044421435450203717}, {"id": 738, "seek": 431500, "start": 4315.0, "end": 4321.0, "text": " So let's take a look at what they look like if we were to graph them.", "tokens": [50364, 407, 718, 311, 747, 257, 574, 412, 437, 436, 574, 411, 498, 321, 645, 281, 4295, 552, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09617945642182321, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.008576687425374985}, {"id": 739, "seek": 431500, "start": 4321.0, "end": 4332.0, "text": " So u is negative three, so go over three up four, negative three four, so it's kind of a rough sketch.", "tokens": [50664, 407, 344, 307, 3671, 1045, 11, 370, 352, 670, 1045, 493, 1451, 11, 3671, 1045, 1451, 11, 370, 309, 311, 733, 295, 257, 5903, 12325, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09617945642182321, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.008576687425374985}, {"id": 740, "seek": 431500, "start": 4332.0, "end": 4339.0, "text": " And then v is positive four and up three, so about there.", "tokens": [51214, 400, 550, 371, 307, 3353, 1451, 293, 493, 1045, 11, 370, 466, 456, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09617945642182321, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.008576687425374985}, {"id": 741, "seek": 433900, "start": 4339.0, "end": 4347.0, "text": " And even though this is just a rough sketch, it seems pretty reasonable that these two vectors are orthogonal.", "tokens": [50364, 400, 754, 1673, 341, 307, 445, 257, 5903, 12325, 11, 309, 2544, 1238, 10585, 300, 613, 732, 18875, 366, 41488, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06777938910290203, "compression_ratio": 1.802325581395349, "no_speech_prob": 0.01406178530305624}, {"id": 742, "seek": 433900, "start": 4347.0, "end": 4350.0, "text": " That looks to be about 90 degrees in there.", "tokens": [50764, 663, 1542, 281, 312, 466, 4289, 5310, 294, 456, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06777938910290203, "compression_ratio": 1.802325581395349, "no_speech_prob": 0.01406178530305624}, {"id": 743, "seek": 433900, "start": 4350.0, "end": 4356.0, "text": " And we know for certain, because this dot product is zero, we know for certain that they are orthogonal.", "tokens": [50914, 400, 321, 458, 337, 1629, 11, 570, 341, 5893, 1674, 307, 4018, 11, 321, 458, 337, 1629, 300, 436, 366, 41488, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06777938910290203, "compression_ratio": 1.802325581395349, "no_speech_prob": 0.01406178530305624}, {"id": 744, "seek": 433900, "start": 4356.0, "end": 4363.0, "text": " And just by the sketch, they, you know, that kind of confirms in our mind if we had any doubt that they are indeed orthogonal.", "tokens": [51214, 400, 445, 538, 264, 12325, 11, 436, 11, 291, 458, 11, 300, 733, 295, 39982, 294, 527, 1575, 498, 321, 632, 604, 6385, 300, 436, 366, 6451, 41488, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06777938910290203, "compression_ratio": 1.802325581395349, "no_speech_prob": 0.01406178530305624}, {"id": 745, "seek": 433900, "start": 4363.0, "end": 4368.0, "text": " Okay, so this is the definition of orthogonal. I'll see you in the next video.", "tokens": [51564, 1033, 11, 370, 341, 307, 264, 7123, 295, 41488, 13, 286, 603, 536, 291, 294, 264, 958, 960, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06777938910290203, "compression_ratio": 1.802325581395349, "no_speech_prob": 0.01406178530305624}, {"id": 746, "seek": 436800, "start": 4368.0, "end": 4381.0, "text": " Okay, here we have a proof to do, we need to prove that the diagonals of a parallelogram are perpendicular if and only if the length of their sides are equal.", "tokens": [50364, 1033, 11, 510, 321, 362, 257, 8177, 281, 360, 11, 321, 643, 281, 7081, 300, 264, 17405, 1124, 295, 257, 8952, 12820, 366, 26734, 498, 293, 787, 498, 264, 4641, 295, 641, 4881, 366, 2681, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06561884880065919, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.01321822963654995}, {"id": 747, "seek": 436800, "start": 4381.0, "end": 4393.0, "text": " Okay, so the first thing that I want to do is just get some intuition about what we're actually trying to prove and write a mathematical statement of what we're trying to prove.", "tokens": [51014, 1033, 11, 370, 264, 700, 551, 300, 286, 528, 281, 360, 307, 445, 483, 512, 24002, 466, 437, 321, 434, 767, 1382, 281, 7081, 293, 2464, 257, 18894, 5629, 295, 437, 321, 434, 1382, 281, 7081, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06561884880065919, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.01321822963654995}, {"id": 748, "seek": 436800, "start": 4393.0, "end": 4397.0, "text": " So kind of convert these words into math.", "tokens": [51614, 407, 733, 295, 7620, 613, 2283, 666, 5221, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06561884880065919, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.01321822963654995}, {"id": 749, "seek": 439700, "start": 4397.0, "end": 4401.0, "text": " The first thing I'm going to do is just draw a parallelogram to see what's going on.", "tokens": [50364, 440, 700, 551, 286, 478, 516, 281, 360, 307, 445, 2642, 257, 8952, 12820, 281, 536, 437, 311, 516, 322, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08909579685756139, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.009707692079246044}, {"id": 750, "seek": 439700, "start": 4401.0, "end": 4406.0, "text": " So here are two vectors, u and v, and we know we can make a parallelogram out of them.", "tokens": [50564, 407, 510, 366, 732, 18875, 11, 344, 293, 371, 11, 293, 321, 458, 321, 393, 652, 257, 8952, 12820, 484, 295, 552, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08909579685756139, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.009707692079246044}, {"id": 751, "seek": 439700, "start": 4406.0, "end": 4411.0, "text": " So here's, well, let me switch to a thinner brush.", "tokens": [50814, 407, 510, 311, 11, 731, 11, 718, 385, 3679, 281, 257, 21905, 5287, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08909579685756139, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.009707692079246044}, {"id": 752, "seek": 439700, "start": 4411.0, "end": 4415.0, "text": " So here's u and here is v.", "tokens": [51064, 407, 510, 311, 344, 293, 510, 307, 371, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08909579685756139, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.009707692079246044}, {"id": 753, "seek": 439700, "start": 4415.0, "end": 4420.0, "text": " And we know we can make a parallelogram out of them, so let's do that.", "tokens": [51264, 400, 321, 458, 321, 393, 652, 257, 8952, 12820, 484, 295, 552, 11, 370, 718, 311, 360, 300, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08909579685756139, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.009707692079246044}, {"id": 754, "seek": 442000, "start": 4420.0, "end": 4430.0, "text": " Oh, and I should tell you that I made these vectors exactly equal in length because it says that we want them to be equal in length, so I wanted to see what was going on with that.", "tokens": [50364, 876, 11, 293, 286, 820, 980, 291, 300, 286, 1027, 613, 18875, 2293, 2681, 294, 4641, 570, 309, 1619, 300, 321, 528, 552, 281, 312, 2681, 294, 4641, 11, 370, 286, 1415, 281, 536, 437, 390, 516, 322, 365, 300, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06571622227513513, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.010326377116143703}, {"id": 755, "seek": 442000, "start": 4430.0, "end": 4445.0, "text": " And now we know how to create the diagonals, right? If we do head-to-tail addition, we can get this main diagonal and we know that that's u plus v.", "tokens": [50864, 400, 586, 321, 458, 577, 281, 1884, 264, 17405, 1124, 11, 558, 30, 759, 321, 360, 1378, 12, 1353, 12, 14430, 4500, 11, 321, 393, 483, 341, 2135, 21539, 293, 321, 458, 300, 300, 311, 344, 1804, 371, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06571622227513513, "compression_ratio": 1.5922330097087378, "no_speech_prob": 0.010326377116143703}, {"id": 756, "seek": 444500, "start": 4445.0, "end": 4452.0, "text": " And then how do we get the other diagonal?", "tokens": [50364, 400, 550, 577, 360, 321, 483, 264, 661, 21539, 30, 50714], "temperature": 0.0, "avg_logprob": -0.10549580388598973, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.00734522333368659}, {"id": 757, "seek": 444500, "start": 4452.0, "end": 4467.0, "text": " Well, the other diagonal is just u minus v, so that is here, u minus v.", "tokens": [50714, 1042, 11, 264, 661, 21539, 307, 445, 344, 3175, 371, 11, 370, 300, 307, 510, 11, 344, 3175, 371, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10549580388598973, "compression_ratio": 1.3255813953488371, "no_speech_prob": 0.00734522333368659}, {"id": 758, "seek": 446700, "start": 4467.0, "end": 4478.0, "text": " We talked about that in vector subtraction. The vector pointing from the head of one vector to the head of the other is vector subtraction, essentially.", "tokens": [50364, 492, 2825, 466, 300, 294, 8062, 16390, 313, 13, 440, 8062, 12166, 490, 264, 1378, 295, 472, 8062, 281, 264, 1378, 295, 264, 661, 307, 8062, 16390, 313, 11, 4476, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0749308188756307, "compression_ratio": 1.5246913580246915, "no_speech_prob": 0.16016456484794617}, {"id": 759, "seek": 446700, "start": 4478.0, "end": 4483.0, "text": " Okay, so we have our two diagonals. Let's see if we can convert this statement into some math.", "tokens": [50914, 1033, 11, 370, 321, 362, 527, 732, 17405, 1124, 13, 961, 311, 536, 498, 321, 393, 7620, 341, 5629, 666, 512, 5221, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0749308188756307, "compression_ratio": 1.5246913580246915, "no_speech_prob": 0.16016456484794617}, {"id": 760, "seek": 448300, "start": 4483.0, "end": 4495.0, "text": " So what we're trying to prove is that the diagonals, u plus v, are perpendicular, right?", "tokens": [50364, 407, 437, 321, 434, 1382, 281, 7081, 307, 300, 264, 17405, 1124, 11, 344, 1804, 371, 11, 366, 26734, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.08422509483669115, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.12417665123939514}, {"id": 761, "seek": 448300, "start": 4495.0, "end": 4502.0, "text": " U plus v and u minus v, we're trying to prove that these are perpendicular.", "tokens": [50964, 624, 1804, 371, 293, 344, 3175, 371, 11, 321, 434, 1382, 281, 7081, 300, 613, 366, 26734, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08422509483669115, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.12417665123939514}, {"id": 762, "seek": 450200, "start": 4502.0, "end": 4509.0, "text": " So we could say that their dot product is zero, so the diagonals are perpendicular.", "tokens": [50364, 407, 321, 727, 584, 300, 641, 5893, 1674, 307, 4018, 11, 370, 264, 17405, 1124, 366, 26734, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09850562649008668, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.03676442801952362}, {"id": 763, "seek": 450200, "start": 4509.0, "end": 4518.0, "text": " That's this statement, the diagonals are perpendicular. If and only if the length of their sides are equal.", "tokens": [50714, 663, 311, 341, 5629, 11, 264, 17405, 1124, 366, 26734, 13, 759, 293, 787, 498, 264, 4641, 295, 641, 4881, 366, 2681, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09850562649008668, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.03676442801952362}, {"id": 764, "seek": 450200, "start": 4518.0, "end": 4525.0, "text": " So this is length of u is equal to length of v.", "tokens": [51164, 407, 341, 307, 4641, 295, 344, 307, 2681, 281, 4641, 295, 371, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09850562649008668, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.03676442801952362}, {"id": 765, "seek": 450200, "start": 4525.0, "end": 4531.0, "text": " Okay, so now we have a proof and we need to go in both directions.", "tokens": [51514, 1033, 11, 370, 586, 321, 362, 257, 8177, 293, 321, 643, 281, 352, 294, 1293, 11095, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09850562649008668, "compression_ratio": 1.6721311475409837, "no_speech_prob": 0.03676442801952362}, {"id": 766, "seek": 453100, "start": 4531.0, "end": 4548.0, "text": " So let's go forward first. Let's say assume that the dot product is zero.", "tokens": [50364, 407, 718, 311, 352, 2128, 700, 13, 961, 311, 584, 6552, 300, 264, 5893, 1674, 307, 4018, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1456272670200893, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.0003920322051271796}, {"id": 767, "seek": 453100, "start": 4548.0, "end": 4557.0, "text": " So assume that the diagonals are perpendicular or orthogonal.", "tokens": [51214, 407, 6552, 300, 264, 17405, 1124, 366, 26734, 420, 41488, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1456272670200893, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.0003920322051271796}, {"id": 768, "seek": 455700, "start": 4557.0, "end": 4562.0, "text": " We're going to assume this and now we need to prove that the lengths are equal.", "tokens": [50364, 492, 434, 516, 281, 6552, 341, 293, 586, 321, 643, 281, 7081, 300, 264, 26329, 366, 2681, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06962450061525617, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.051065593957901}, {"id": 769, "seek": 455700, "start": 4562.0, "end": 4568.0, "text": " Okay, well let's just see what happens through this equation if we expand it out.", "tokens": [50614, 1033, 11, 731, 718, 311, 445, 536, 437, 2314, 807, 341, 5367, 498, 321, 5268, 309, 484, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06962450061525617, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.051065593957901}, {"id": 770, "seek": 455700, "start": 4568.0, "end": 4573.0, "text": " So that equation implies what is the dot product expanded here?", "tokens": [50914, 407, 300, 5367, 18779, 437, 307, 264, 5893, 1674, 14342, 510, 30, 51164], "temperature": 0.0, "avg_logprob": -0.06962450061525617, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.051065593957901}, {"id": 771, "seek": 457300, "start": 4573.0, "end": 4595.0, "text": " So we're going to have u dot u, which we know is the length of u squared, minus u dot v plus v dot u.", "tokens": [50364, 407, 321, 434, 516, 281, 362, 344, 5893, 344, 11, 597, 321, 458, 307, 264, 4641, 295, 344, 8889, 11, 3175, 344, 5893, 371, 1804, 371, 5893, 344, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16461171525897403, "compression_ratio": 1.160919540229885, "no_speech_prob": 0.5268000364303589}, {"id": 772, "seek": 459500, "start": 4595.0, "end": 4604.0, "text": " And then we're going to get minus the length of v squared because this is just minus v dot v.", "tokens": [50364, 400, 550, 321, 434, 516, 281, 483, 3175, 264, 4641, 295, 371, 8889, 570, 341, 307, 445, 3175, 371, 5893, 371, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0763435810804367, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.34468546509742737}, {"id": 773, "seek": 459500, "start": 4604.0, "end": 4611.0, "text": " Okay, the dot product is commutative and so u dot v is the same thing as v dot u.", "tokens": [50814, 1033, 11, 264, 5893, 1674, 307, 800, 325, 1166, 293, 370, 344, 5893, 371, 307, 264, 912, 551, 382, 371, 5893, 344, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0763435810804367, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.34468546509742737}, {"id": 774, "seek": 459500, "start": 4611.0, "end": 4617.0, "text": " So we have a minus v dot u dot v here and a plus u dot v, so those are going to cancel out.", "tokens": [51164, 407, 321, 362, 257, 3175, 371, 5893, 344, 5893, 371, 510, 293, 257, 1804, 344, 5893, 371, 11, 370, 729, 366, 516, 281, 10373, 484, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0763435810804367, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.34468546509742737}, {"id": 775, "seek": 459500, "start": 4617.0, "end": 4621.0, "text": " Oh, and I kind of made a mistake here, sorry about that.", "tokens": [51464, 876, 11, 293, 286, 733, 295, 1027, 257, 6146, 510, 11, 2597, 466, 300, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0763435810804367, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.34468546509742737}, {"id": 776, "seek": 462100, "start": 4621.0, "end": 4624.0, "text": " This is an implication.", "tokens": [50364, 639, 307, 364, 37814, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11032497882843018, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.03845984488725662}, {"id": 777, "seek": 462100, "start": 4624.0, "end": 4632.0, "text": " The fact that this is equal to zero implies that this statement is equal to zero because all we did was expand it out,", "tokens": [50514, 440, 1186, 300, 341, 307, 2681, 281, 4018, 18779, 300, 341, 5629, 307, 2681, 281, 4018, 570, 439, 321, 630, 390, 5268, 309, 484, 11, 50914], "temperature": 0.0, "avg_logprob": -0.11032497882843018, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.03845984488725662}, {"id": 778, "seek": 462100, "start": 4632.0, "end": 4638.0, "text": " which in turn, let me switch colors here, well maybe not, maybe I'll leave it where it was,", "tokens": [50914, 597, 294, 1261, 11, 718, 385, 3679, 4577, 510, 11, 731, 1310, 406, 11, 1310, 286, 603, 1856, 309, 689, 309, 390, 11, 51214], "temperature": 0.0, "avg_logprob": -0.11032497882843018, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.03845984488725662}, {"id": 779, "seek": 462100, "start": 4638.0, "end": 4648.0, "text": " which in turn implies that the length of u squared minus the length of v squared,", "tokens": [51214, 597, 294, 1261, 18779, 300, 264, 4641, 295, 344, 8889, 3175, 264, 4641, 295, 371, 8889, 11, 51714], "temperature": 0.0, "avg_logprob": -0.11032497882843018, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.03845984488725662}, {"id": 780, "seek": 464800, "start": 4648.0, "end": 4652.0, "text": " oops I forgot my vector there, is equal to zero,", "tokens": [50364, 34166, 286, 5298, 452, 8062, 456, 11, 307, 2681, 281, 4018, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09481107132344306, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0035934648476541042}, {"id": 781, "seek": 464800, "start": 4652.0, "end": 4663.0, "text": " which again implies that the length of u squared is equal to the length of v squared.", "tokens": [50564, 597, 797, 18779, 300, 264, 4641, 295, 344, 8889, 307, 2681, 281, 264, 4641, 295, 371, 8889, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09481107132344306, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0035934648476541042}, {"id": 782, "seek": 464800, "start": 4663.0, "end": 4668.0, "text": " Well, length of vectors are always positive and so we could take the square root", "tokens": [51114, 1042, 11, 4641, 295, 18875, 366, 1009, 3353, 293, 370, 321, 727, 747, 264, 3732, 5593, 51364], "temperature": 0.0, "avg_logprob": -0.09481107132344306, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0035934648476541042}, {"id": 783, "seek": 464800, "start": 4668.0, "end": 4675.0, "text": " and not really worry about messing up this equality because we're not going to need the negative part of the square root", "tokens": [51364, 293, 406, 534, 3292, 466, 23258, 493, 341, 14949, 570, 321, 434, 406, 516, 281, 643, 264, 3671, 644, 295, 264, 3732, 5593, 51714], "temperature": 0.0, "avg_logprob": -0.09481107132344306, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0035934648476541042}, {"id": 784, "seek": 467500, "start": 4675.0, "end": 4680.0, "text": " because we know both of these lengths are positive.", "tokens": [50364, 570, 321, 458, 1293, 295, 613, 26329, 366, 3353, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08381563158177618, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0006878412677906454}, {"id": 785, "seek": 467500, "start": 4680.0, "end": 4686.0, "text": " So we take the square root of both sides and we get exactly what we wanted,", "tokens": [50614, 407, 321, 747, 264, 3732, 5593, 295, 1293, 4881, 293, 321, 483, 2293, 437, 321, 1415, 11, 50914], "temperature": 0.0, "avg_logprob": -0.08381563158177618, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0006878412677906454}, {"id": 786, "seek": 467500, "start": 4686.0, "end": 4693.0, "text": " that the length of u is equal to the length of v.", "tokens": [50914, 300, 264, 4641, 295, 344, 307, 2681, 281, 264, 4641, 295, 371, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08381563158177618, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0006878412677906454}, {"id": 787, "seek": 467500, "start": 4693.0, "end": 4700.0, "text": " Okay, so we proved that if the vectors, if the diagonals are perpendicular,", "tokens": [51264, 1033, 11, 370, 321, 14617, 300, 498, 264, 18875, 11, 498, 264, 17405, 1124, 366, 26734, 11, 51614], "temperature": 0.0, "avg_logprob": -0.08381563158177618, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0006878412677906454}, {"id": 788, "seek": 470000, "start": 4700.0, "end": 4703.0, "text": " then their lengths must be equal.", "tokens": [50364, 550, 641, 26329, 1633, 312, 2681, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09471203069217869, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.0017545734299346805}, {"id": 789, "seek": 470000, "start": 4703.0, "end": 4714.0, "text": " Let's go ahead and prove that if the lengths are equal then the vectors must be perpendicular.", "tokens": [50514, 961, 311, 352, 2286, 293, 7081, 300, 498, 264, 26329, 366, 2681, 550, 264, 18875, 1633, 312, 26734, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09471203069217869, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.0017545734299346805}, {"id": 790, "seek": 470000, "start": 4714.0, "end": 4725.0, "text": " So I'm just going to write this kind of backwards implies arrow just to indicate we're doing the other part of the proof now.", "tokens": [51064, 407, 286, 478, 445, 516, 281, 2464, 341, 733, 295, 12204, 18779, 11610, 445, 281, 13330, 321, 434, 884, 264, 661, 644, 295, 264, 8177, 586, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09471203069217869, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.0017545734299346805}, {"id": 791, "seek": 472500, "start": 4725.0, "end": 4737.0, "text": " So we're going to assume that the lengths are equal and what we want to get to is that the vectors are perpendicular,", "tokens": [50364, 407, 321, 434, 516, 281, 6552, 300, 264, 26329, 366, 2681, 293, 437, 321, 528, 281, 483, 281, 307, 300, 264, 18875, 366, 26734, 11, 50964], "temperature": 0.0, "avg_logprob": -0.08170146706663532, "compression_ratio": 1.7055555555555555, "no_speech_prob": 0.0018101322930306196}, {"id": 792, "seek": 472500, "start": 4737.0, "end": 4740.0, "text": " or the diagonals are perpendicular.", "tokens": [50964, 420, 264, 17405, 1124, 366, 26734, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08170146706663532, "compression_ratio": 1.7055555555555555, "no_speech_prob": 0.0018101322930306196}, {"id": 793, "seek": 472500, "start": 4740.0, "end": 4742.0, "text": " So we're going to assume this.", "tokens": [51114, 407, 321, 434, 516, 281, 6552, 341, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08170146706663532, "compression_ratio": 1.7055555555555555, "no_speech_prob": 0.0018101322930306196}, {"id": 794, "seek": 472500, "start": 4742.0, "end": 4746.0, "text": " Now this doesn't seem, it seems like well where do we go from here?", "tokens": [51214, 823, 341, 1177, 380, 1643, 11, 309, 2544, 411, 731, 689, 360, 321, 352, 490, 510, 30, 51414], "temperature": 0.0, "avg_logprob": -0.08170146706663532, "compression_ratio": 1.7055555555555555, "no_speech_prob": 0.0018101322930306196}, {"id": 795, "seek": 472500, "start": 4746.0, "end": 4752.0, "text": " How do we construct a proof out of just this equality?", "tokens": [51414, 1012, 360, 321, 7690, 257, 8177, 484, 295, 445, 341, 14949, 30, 51714], "temperature": 0.0, "avg_logprob": -0.08170146706663532, "compression_ratio": 1.7055555555555555, "no_speech_prob": 0.0018101322930306196}, {"id": 796, "seek": 475200, "start": 4752.0, "end": 4768.0, "text": " Well what I would do is I would say, okay, consider the dot product of u plus v dotted with u minus v.", "tokens": [50364, 1042, 437, 286, 576, 360, 307, 286, 576, 584, 11, 1392, 11, 1949, 264, 5893, 1674, 295, 344, 1804, 371, 37459, 365, 344, 3175, 371, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08078578927300194, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0012065233895555139}, {"id": 797, "seek": 475200, "start": 4768.0, "end": 4770.0, "text": " So the dot product of the diagonals.", "tokens": [51164, 407, 264, 5893, 1674, 295, 264, 17405, 1124, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08078578927300194, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0012065233895555139}, {"id": 798, "seek": 475200, "start": 4770.0, "end": 4774.0, "text": " Now we're not going to say that this is equal to zero, we can't do that.", "tokens": [51264, 823, 321, 434, 406, 516, 281, 584, 300, 341, 307, 2681, 281, 4018, 11, 321, 393, 380, 360, 300, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08078578927300194, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0012065233895555139}, {"id": 799, "seek": 475200, "start": 4774.0, "end": 4779.0, "text": " That's what we're trying to prove but we can just see what comes out when we take this dot product.", "tokens": [51464, 663, 311, 437, 321, 434, 1382, 281, 7081, 457, 321, 393, 445, 536, 437, 1487, 484, 562, 321, 747, 341, 5893, 1674, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08078578927300194, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0012065233895555139}, {"id": 800, "seek": 477900, "start": 4779.0, "end": 4785.0, "text": " We know that this dot product exists, we have two vectors, we can take their dot products.", "tokens": [50364, 492, 458, 300, 341, 5893, 1674, 8198, 11, 321, 362, 732, 18875, 11, 321, 393, 747, 641, 5893, 3383, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10202614036766258, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.009412160143256187}, {"id": 801, "seek": 477900, "start": 4785.0, "end": 4788.0, "text": " Okay, so let's do that.", "tokens": [50664, 1033, 11, 370, 718, 311, 360, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10202614036766258, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.009412160143256187}, {"id": 802, "seek": 477900, "start": 4788.0, "end": 4795.0, "text": " Well this is equal to, that dot product is equal to, well we already did this.", "tokens": [50814, 1042, 341, 307, 2681, 281, 11, 300, 5893, 1674, 307, 2681, 281, 11, 731, 321, 1217, 630, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10202614036766258, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.009412160143256187}, {"id": 803, "seek": 477900, "start": 4795.0, "end": 4807.0, "text": " It was the length of u squared minus the u dot v plus u dot v.", "tokens": [51164, 467, 390, 264, 4641, 295, 344, 8889, 3175, 264, 344, 5893, 371, 1804, 344, 5893, 371, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10202614036766258, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.009412160143256187}, {"id": 804, "seek": 480700, "start": 4807.0, "end": 4813.0, "text": " I just commuted there, it would be v dot u but I just commuted the two vectors.", "tokens": [50364, 286, 445, 800, 4866, 456, 11, 309, 576, 312, 371, 5893, 344, 457, 286, 445, 800, 4866, 264, 732, 18875, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08604931397871537, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.00912510696798563}, {"id": 805, "seek": 480700, "start": 4813.0, "end": 4819.0, "text": " And then minus the length of v squared.", "tokens": [50664, 400, 550, 3175, 264, 4641, 295, 371, 8889, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08604931397871537, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.00912510696798563}, {"id": 806, "seek": 480700, "start": 4819.0, "end": 4835.0, "text": " And this is equal to the length of u squared minus the length of v squared.", "tokens": [50964, 400, 341, 307, 2681, 281, 264, 4641, 295, 344, 8889, 3175, 264, 4641, 295, 371, 8889, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08604931397871537, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.00912510696798563}, {"id": 807, "seek": 483500, "start": 4835.0, "end": 4841.0, "text": " Since u is equal to v we can substitute one and for the other and we know of course that this is equal to zero.", "tokens": [50364, 4162, 344, 307, 2681, 281, 371, 321, 393, 15802, 472, 293, 337, 264, 661, 293, 321, 458, 295, 1164, 300, 341, 307, 2681, 281, 4018, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08728739294675317, "compression_ratio": 2.146892655367232, "no_speech_prob": 0.32728111743927}, {"id": 808, "seek": 483500, "start": 4841.0, "end": 4847.0, "text": " So we took the dot product and we found out that yes the dot product is equal to zero.", "tokens": [50664, 407, 321, 1890, 264, 5893, 1674, 293, 321, 1352, 484, 300, 2086, 264, 5893, 1674, 307, 2681, 281, 4018, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08728739294675317, "compression_ratio": 2.146892655367232, "no_speech_prob": 0.32728111743927}, {"id": 809, "seek": 483500, "start": 4847.0, "end": 4851.0, "text": " So that's it, we're done with our proof.", "tokens": [50964, 407, 300, 311, 309, 11, 321, 434, 1096, 365, 527, 8177, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08728739294675317, "compression_ratio": 2.146892655367232, "no_speech_prob": 0.32728111743927}, {"id": 810, "seek": 483500, "start": 4851.0, "end": 4854.0, "text": " We've proved that if the lengths are equal the dot product is zero.", "tokens": [51164, 492, 600, 14617, 300, 498, 264, 26329, 366, 2681, 264, 5893, 1674, 307, 4018, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08728739294675317, "compression_ratio": 2.146892655367232, "no_speech_prob": 0.32728111743927}, {"id": 811, "seek": 483500, "start": 4854.0, "end": 4859.0, "text": " We've proved that if the dot product is zero then the lengths are equal.", "tokens": [51314, 492, 600, 14617, 300, 498, 264, 5893, 1674, 307, 4018, 550, 264, 26329, 366, 2681, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08728739294675317, "compression_ratio": 2.146892655367232, "no_speech_prob": 0.32728111743927}, {"id": 812, "seek": 485900, "start": 4859.0, "end": 4871.0, "text": " And again just one more time, when I say that the dot product is zero what I'm implying by definition is that these two vectors are perpendicular.", "tokens": [50364, 400, 797, 445, 472, 544, 565, 11, 562, 286, 584, 300, 264, 5893, 1674, 307, 4018, 437, 286, 478, 704, 7310, 538, 7123, 307, 300, 613, 732, 18875, 366, 26734, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10394285013387491, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.019713040441274643}, {"id": 813, "seek": 485900, "start": 4871.0, "end": 4877.0, "text": " And of course from the beginning of the video those two vectors represent the diagonals.", "tokens": [50964, 400, 295, 1164, 490, 264, 2863, 295, 264, 960, 729, 732, 18875, 2906, 264, 17405, 1124, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10394285013387491, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.019713040441274643}, {"id": 814, "seek": 485900, "start": 4877.0, "end": 4881.0, "text": " Okay, so that's somewhat of an interesting proof.", "tokens": [51264, 1033, 11, 370, 300, 311, 8344, 295, 364, 1880, 8177, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10394285013387491, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.019713040441274643}, {"id": 815, "seek": 485900, "start": 4881.0, "end": 4888.0, "text": " The diagonals of a parallelogram are only perpendicular if and only if the lengths of the sides are equal.", "tokens": [51464, 440, 17405, 1124, 295, 257, 8952, 12820, 366, 787, 26734, 498, 293, 787, 498, 264, 26329, 295, 264, 4881, 366, 2681, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10394285013387491, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.019713040441274643}, {"id": 816, "seek": 488800, "start": 4888.0, "end": 4890.0, "text": " Okay, see you in the next video.", "tokens": [50364, 1033, 11, 536, 291, 294, 264, 958, 960, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1267199913660685, "compression_ratio": 0.8, "no_speech_prob": 0.4041590392589569}], "language": "en"}