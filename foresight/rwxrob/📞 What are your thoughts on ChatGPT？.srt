1
00:00:00,000 --> 00:00:02,020
to start recording.

2
00:00:02,020 --> 00:00:03,720
What are your thoughts on chat, GPT?

3
00:00:05,520 --> 00:00:07,640
So here's the thing.

4
00:00:09,720 --> 00:00:10,560
Why?

5
00:00:12,800 --> 00:00:14,560
That's what I have to say.

6
00:00:14,560 --> 00:00:19,560
Why are people interested in this?

7
00:00:23,440 --> 00:00:25,120
I just don't get it.

8
00:00:25,120 --> 00:00:26,320
I just don't get it.

9
00:00:26,320 --> 00:00:28,240
I have watched all this stuff.

10
00:00:29,240 --> 00:00:32,880
I don't understand what its purpose is.

11
00:00:32,880 --> 00:00:35,040
Personally, I mean, let's go back and read it, okay?

12
00:00:35,040 --> 00:00:35,880
So it says here,

13
00:00:35,880 --> 00:00:39,400
chat GPT is a prototype artificial intelligence chat bot.

14
00:00:39,400 --> 00:00:40,360
Join the club.

15
00:00:40,360 --> 00:00:41,960
I mean, how many other chat bots have we had?

16
00:00:41,960 --> 00:00:44,000
Okay, so maybe this was not going to become

17
00:00:44,000 --> 00:00:47,000
like a masochistic, narcissistic Nazi

18
00:00:47,000 --> 00:00:48,560
like the Twitter bot before.

19
00:00:49,760 --> 00:00:51,100
This is apparently really polite.

20
00:00:51,100 --> 00:00:52,720
I'm sure they trained it to be really, really polite.

21
00:00:52,720 --> 00:00:54,680
Apparently it's really, really polite.

22
00:00:54,680 --> 00:00:57,240
I was scrolling through a thing and it said,

23
00:00:57,240 --> 00:01:01,480
the most polite, clueless bot you'll ever see.

24
00:01:03,440 --> 00:01:06,000
If it's wrong, at least it's wrong politely.

25
00:01:06,000 --> 00:01:08,120
Hopefully it focuses on usability and dialogue.

26
00:01:08,120 --> 00:01:10,280
The chat bot uses a large language model trained

27
00:01:10,280 --> 00:01:11,440
with reinforcement learning

28
00:01:11,440 --> 00:01:13,160
and it's based on GPT 3.5 architecture.

29
00:01:13,160 --> 00:01:15,320
It's also beta, by the way.

30
00:01:15,320 --> 00:01:16,920
It's not final, right?

31
00:01:18,800 --> 00:01:22,080
It's an open prototype,

32
00:01:23,080 --> 00:01:27,920
not finished.

33
00:01:27,920 --> 00:01:28,760
How about that?

34
00:01:28,760 --> 00:01:30,240
So I'll put that there.

35
00:01:30,240 --> 00:01:31,440
Look, if you want to use it, that's fine.

36
00:01:31,440 --> 00:01:32,320
I am not going to judge you.

37
00:01:32,320 --> 00:01:33,680
I just think it's a waste of time.

38
00:01:33,680 --> 00:01:35,840
So many things are a waste of time today.

39
00:01:35,840 --> 00:01:37,760
And to me, that's a waste of time.

40
00:01:37,760 --> 00:01:38,840
Chat bot uses like,

41
00:01:40,400 --> 00:01:43,880
it says here chat GPT was launched in November, 2022

42
00:01:43,880 --> 00:01:47,080
and is garnered attention as its detailed responses

43
00:01:47,080 --> 00:01:48,120
and well-reasoned answers,

44
00:01:48,120 --> 00:01:50,080
although its accuracy has been criticized.

45
00:01:52,680 --> 00:01:55,440
Well-reasoned wrong answers.

46
00:01:55,440 --> 00:02:00,440
And people are like, I mean, there was an entire article

47
00:02:03,960 --> 00:02:04,880
that came across my feed.

48
00:02:04,880 --> 00:02:09,240
It was like, oh, this is the end of essays as we know them.

49
00:02:09,240 --> 00:02:12,400
It's had GPT, GPT going to destroy, you know,

50
00:02:12,400 --> 00:02:15,120
scholastic achievement through essay writing and stuff.

51
00:02:15,120 --> 00:02:16,880
I'm like, no, it's not.

52
00:02:16,880 --> 00:02:18,240
It's not.

53
00:02:18,240 --> 00:02:19,840
It's not.

54
00:02:19,840 --> 00:02:21,280
I mean, it might help you a little bit.

55
00:02:21,280 --> 00:02:23,480
It's like, it's all of these chat bot things,

56
00:02:23,480 --> 00:02:25,160
including the coding one,

57
00:02:25,160 --> 00:02:27,720
all they really are is they're catering to people

58
00:02:27,720 --> 00:02:30,840
who are copy pasta people,

59
00:02:30,840 --> 00:02:32,080
copy pasta people,

60
00:02:32,080 --> 00:02:36,080
the people who don't do any original thinking

61
00:02:36,080 --> 00:02:39,520
who go out and they want to use this thing like,

62
00:02:39,520 --> 00:02:40,360
oh, that's cool.

63
00:02:40,360 --> 00:02:42,600
They don't actually validate that it's true.

64
00:02:42,600 --> 00:02:46,320
Now, if they did, if they did, if they did,

65
00:02:46,320 --> 00:02:50,000
if they did, then it could be a nice suggestion, right?

66
00:02:50,000 --> 00:02:51,240
And I think that's fine.

67
00:02:51,240 --> 00:02:52,880
And it's not just because I'm old that I don't like it.

68
00:02:52,880 --> 00:02:56,480
It's because it's inaccurate

69
00:02:56,480 --> 00:02:58,400
and it's dangerous to trust an AI

70
00:02:58,400 --> 00:03:01,320
that you're not backing up with personal experience.

71
00:03:01,320 --> 00:03:02,440
This is, do I have to, I mean,

72
00:03:02,440 --> 00:03:05,000
how many fictional sci-fies have there been?

73
00:03:06,840 --> 00:03:08,760
This is part of the evolution of AI, right?

74
00:03:08,760 --> 00:03:10,480
I mean, there was a time, there was a time

75
00:03:10,480 --> 00:03:13,120
when if you were to hear a computer-generated voice,

76
00:03:13,120 --> 00:03:15,040
you would go, what the hell did they say?

77
00:03:15,040 --> 00:03:16,360
And now you can't even tell the difference

78
00:03:16,360 --> 00:03:17,600
between computer-generated voices.

79
00:03:17,600 --> 00:03:19,120
So it's going in the right direction.

80
00:03:19,120 --> 00:03:19,960
I don't have any problem with that.

81
00:03:19,960 --> 00:03:21,400
And it needs to go in the right direction.

82
00:03:21,400 --> 00:03:24,600
But right now, why are you wasting time on it?

83
00:03:24,600 --> 00:03:26,800
And there's an unusually large number of people

84
00:03:26,800 --> 00:03:27,840
coming at me with this.

85
00:03:27,840 --> 00:03:29,520
What do you think of Chad GPT?

86
00:03:29,520 --> 00:03:31,560
Who are college students?

87
00:03:33,400 --> 00:03:35,840
And I had one person in here, I'm gonna get them out of me.

88
00:03:35,840 --> 00:03:38,160
I think they're in here right now, actually.

89
00:03:38,160 --> 00:03:39,560
Please don't get mad.

90
00:03:39,560 --> 00:03:42,320
But they said, all I can say is it took

91
00:03:42,320 --> 00:03:44,160
what was otherwise a three-hour assignment

92
00:03:44,160 --> 00:03:46,360
and turned it into 30 minutes.

93
00:03:46,360 --> 00:03:49,640
That's exactly, that's almost word for word what they said.

94
00:03:49,640 --> 00:03:53,280
And I'm thinking to myself, how is that possible?

95
00:03:53,280 --> 00:03:56,600
How is that possible that this thing,

96
00:03:56,600 --> 00:03:58,400
whether, and I don't know the assignment,

97
00:03:58,400 --> 00:04:00,160
I think it was a coding assignment,

98
00:04:00,160 --> 00:04:05,160
that this thing can, oh wow, there's a good one.

99
00:04:05,520 --> 00:04:07,240
I've come up with a set of rules that describe,

100
00:04:07,240 --> 00:04:11,080
ooh, very cool, a code on a tech rail,

101
00:04:11,080 --> 00:04:12,600
ooh, we'll have to go look at that one, Kima.

102
00:04:12,600 --> 00:04:13,600
Yeah, that's very cool.

103
00:04:13,600 --> 00:04:18,040
So the point is, if it was taking you three hours

104
00:04:18,040 --> 00:04:19,560
to do an assignment, whatever it was before,

105
00:04:19,560 --> 00:04:21,640
and it's now taking you 30 minutes

106
00:04:21,640 --> 00:04:24,160
because you have a chatbot that's helping you out,

107
00:04:25,240 --> 00:04:26,520
there's something wrong.

108
00:04:26,520 --> 00:04:27,880
I mean, there's something wrong.

109
00:04:27,880 --> 00:04:31,480
You're either not learning it, not learning it properly,

110
00:04:31,480 --> 00:04:34,800
or, I mean, there's an outside chance

111
00:04:34,800 --> 00:04:37,400
that it's doing the grunt work for you

112
00:04:37,400 --> 00:04:38,960
and that you're still doing the learning

113
00:04:38,960 --> 00:04:40,240
and it's filling in all the blanks

114
00:04:40,240 --> 00:04:41,600
and everything that it would take you longer to type,

115
00:04:41,600 --> 00:04:44,040
especially if you're like a slow typer or something.

116
00:04:44,040 --> 00:04:46,000
And I suppose there's a certain number of people

117
00:04:46,000 --> 00:04:48,320
who are slow typers who can't compose thoughts very easily

118
00:04:48,360 --> 00:04:50,120
and it helps them put the language together

119
00:04:50,120 --> 00:04:52,000
and it's like, yeah, okay, that sounds right.

120
00:04:52,000 --> 00:04:56,440
I, this, my fear with any of these AI things

121
00:04:56,440 --> 00:04:59,560
is just like any other fear is it's like,

122
00:04:59,560 --> 00:05:02,160
they're gonna make us soft.

123
00:05:02,160 --> 00:05:03,760
You know, and that's been something

124
00:05:03,760 --> 00:05:05,880
that old people have been saying, you know,

125
00:05:05,880 --> 00:05:06,920
just the dawn of time.

126
00:05:06,920 --> 00:05:09,200
There were people who didn't wanna get on railroad trains

127
00:05:09,200 --> 00:05:10,680
because they thought it was too fast

128
00:05:10,680 --> 00:05:11,760
and everybody was gonna die.

129
00:05:11,760 --> 00:05:13,080
A lot of people did die, by the way.

130
00:05:13,080 --> 00:05:16,240
And there's actually in Arizona, we opened a geocache there

131
00:05:16,240 --> 00:05:18,560
where there were two trains that were on the same track

132
00:05:18,560 --> 00:05:21,360
and there was, you know, hundreds of hundred people

133
00:05:21,360 --> 00:05:23,920
radically destroyed in an instant

134
00:05:23,920 --> 00:05:25,840
when they're two cranes collided at head.

135
00:05:25,840 --> 00:05:29,080
So there are definitely concerns about these things

136
00:05:29,080 --> 00:05:31,120
as they come out and, you know, should we be doing it?

137
00:05:31,120 --> 00:05:32,680
I was like, yes, we should be definitely trying them out

138
00:05:32,680 --> 00:05:36,360
and experimenting and stuff like that, but to what extent?

139
00:05:36,360 --> 00:05:41,360
I mean, you know, if, honestly, this chat,

140
00:05:42,800 --> 00:05:43,800
I don't know about the coding one.

141
00:05:43,800 --> 00:05:45,440
This is just a chat bot, right?

142
00:05:45,440 --> 00:05:46,960
But the coding one, which is kind of related

143
00:05:46,960 --> 00:05:49,680
in conversation, that one will get you fired

144
00:05:49,680 --> 00:05:52,840
from a company if they find out if they're using it.

145
00:05:52,840 --> 00:05:54,920
Not just because you don't know what you're doing,

146
00:05:54,920 --> 00:05:58,920
but because it's been trained on proprietary source code

147
00:05:58,920 --> 00:06:03,920
that has a indeterminate legal pedigree.

148
00:06:04,800 --> 00:06:06,480
And nobody likes to talk about this.

149
00:06:06,480 --> 00:06:08,280
They all like to talk about how cool, you know,

150
00:06:08,280 --> 00:06:12,360
open AI chat is, I mean, this is a different company, right?

151
00:06:12,360 --> 00:06:13,560
That was the Microsoft thing.

152
00:06:13,560 --> 00:06:15,760
It's the code, whatever, I forget the name of it.

153
00:06:15,760 --> 00:06:18,160
But if you're using that, you're actually taking your career

154
00:06:18,160 --> 00:06:20,160
in your own hands and I wouldn't tell anybody you are.

155
00:06:20,160 --> 00:06:22,000
And I think to a lesser degree,

156
00:06:22,000 --> 00:06:24,400
the chat GPT thing is the same thing.

157
00:06:24,400 --> 00:06:27,320
If you, let's say, for example, let's say for example,

158
00:06:27,320 --> 00:06:29,600
that you save three hours on an essay assignment

159
00:06:29,600 --> 00:06:34,600
by using chat GPT, yeah, they'll work out the legal issues

160
00:06:35,720 --> 00:06:37,760
the tech is too powerful not to use.

161
00:06:37,760 --> 00:06:40,000
I don't think that's true at all.

162
00:06:40,000 --> 00:06:42,520
I must say, I know you're a huge AI fan

163
00:06:42,520 --> 00:06:45,240
and I am not, I am not a fan of it at all.

164
00:06:46,680 --> 00:06:49,760
To me, it's just copy, past, past on steroids.

165
00:06:49,760 --> 00:06:50,600
That's all it is.

166
00:06:50,600 --> 00:06:53,080
And so what it's causing is it's causing a bunch of people

167
00:06:53,080 --> 00:06:56,960
to not learn shit and that's fine.

168
00:06:56,960 --> 00:06:58,920
And this, I mean, I've said it before,

169
00:06:58,920 --> 00:07:00,840
I predicted that everybody should be learning AI

170
00:07:00,840 --> 00:07:01,960
and how to train models properly

171
00:07:01,960 --> 00:07:05,200
because if this is a step in the right direction

172
00:07:05,200 --> 00:07:07,080
where the number of people are gonna be doing

173
00:07:07,080 --> 00:07:09,320
actual programming is gonna go down.

174
00:07:09,320 --> 00:07:11,200
And there's a story I tell about this

175
00:07:11,200 --> 00:07:13,520
that is related to this

176
00:07:13,520 --> 00:07:15,560
because the way that AIs are trained,

177
00:07:15,560 --> 00:07:17,560
including this one that I've been slamming on,

178
00:07:17,560 --> 00:07:19,040
the way that they're trained is organic.

179
00:07:19,040 --> 00:07:20,840
It's closer to how nature does things

180
00:07:20,840 --> 00:07:22,640
than the algorithmic models.

181
00:07:22,640 --> 00:07:25,440
And I have a story about this I wanna tell really quick.

182
00:07:26,720 --> 00:07:28,400
Imagine an AI tutor that can teach kids

183
00:07:28,400 --> 00:07:29,600
in third-world countries.

184
00:07:30,680 --> 00:07:35,680
Wrongly, he'll turn them into white supremacists

185
00:07:36,320 --> 00:07:38,240
even though they're in Africa.

186
00:07:38,240 --> 00:07:40,560
I mean, if it was a Twitter bot, that's what it would do.

187
00:07:40,600 --> 00:07:41,880
Look, we're getting there.

188
00:07:41,880 --> 00:07:43,720
We're getting there, we're just not there, right?

189
00:07:43,720 --> 00:07:46,480
So, that's what I'm saying.

190
00:07:46,480 --> 00:07:49,080
Better than what we have right now, which is nothing.

191
00:07:49,080 --> 00:07:51,560
Well, I mean, it's like there's societal ills

192
00:07:51,560 --> 00:07:53,120
out there to look at.

193
00:07:53,120 --> 00:07:58,040
I'm not anti-AI, I'm just like, I'm like,

194
00:07:58,040 --> 00:07:59,920
so on the one hand, I do think we need to learn

195
00:07:59,920 --> 00:08:01,440
how to train models properly.

196
00:08:01,440 --> 00:08:04,360
I just watched a huge conference.

197
00:08:04,360 --> 00:08:06,680
I almost gave up where I work.

198
00:08:06,680 --> 00:08:08,080
There was this huge, huge conference,

199
00:08:08,080 --> 00:08:10,800
a whole day conference about AI at the place that I work.

200
00:08:11,920 --> 00:08:13,800
And it's crazy, it's crazy.

201
00:08:13,800 --> 00:08:15,920
In fact, the whole future of AI and the focus of it

202
00:08:15,920 --> 00:08:19,160
is not even on writing code, it's on the data.

203
00:08:19,160 --> 00:08:22,200
It's on, and they went through a bunch of examples

204
00:08:22,200 --> 00:08:24,000
of how they were sampling the data

205
00:08:24,000 --> 00:08:27,160
and increasing the data samples so that they were good

206
00:08:27,160 --> 00:08:29,600
because the higher the quality and then put data,

207
00:08:29,600 --> 00:08:30,960
the higher the quality of AI.

208
00:08:30,960 --> 00:08:32,440
And you should see the AI's that haven't,

209
00:08:32,440 --> 00:08:34,280
I wish I could talk about it.

210
00:08:35,240 --> 00:08:36,920
The AI that is going down,

211
00:08:36,920 --> 00:08:38,480
because people may not know,

212
00:08:38,480 --> 00:08:40,640
I support a machine learning group.

213
00:08:40,640 --> 00:08:43,080
I do the SRE and the Kubernetes stuff

214
00:08:43,080 --> 00:08:45,720
and some of the REST API development for,

215
00:08:45,720 --> 00:08:49,160
to support high performance computing machine learning group

216
00:08:49,160 --> 00:08:51,720
and one of the biggest companies in the entire world

217
00:08:53,040 --> 00:08:56,120
who's radically making radical advantage,

218
00:08:56,120 --> 00:08:58,360
taking radical advantage of AI and data.

219
00:08:58,360 --> 00:08:59,800
And it's absolutely amazing.

220
00:08:59,800 --> 00:09:01,160
And they have their own, they're so big,

221
00:09:01,160 --> 00:09:03,800
they have actually, they have their annual conference on it.

222
00:09:03,800 --> 00:09:05,120
And I was just there.

223
00:09:06,440 --> 00:09:08,640
And it's absolutely phenomenally awesome.

224
00:09:08,640 --> 00:09:10,360
So either I'm gonna go camping over the week,

225
00:09:10,360 --> 00:09:11,320
over the Christmas break,

226
00:09:11,320 --> 00:09:14,280
I'm actually gonna start sticking my finger into AI

227
00:09:14,280 --> 00:09:16,760
and learning some of the, doing some Kaggle stuff

228
00:09:16,760 --> 00:09:18,520
and learning, if you're not learning

229
00:09:18,520 --> 00:09:22,200
how to do data science and this kind of thing

230
00:09:22,200 --> 00:09:24,200
and all you're focused on is algorithmic programming

231
00:09:24,200 --> 00:09:26,360
and stuff, I mean, you should see how long it takes me.

232
00:09:26,360 --> 00:09:28,000
Have you seen, I mean, it takes me forever

233
00:09:28,000 --> 00:09:30,520
to just do basic parsing of a string

234
00:09:30,520 --> 00:09:31,520
or something like that.

235
00:09:31,520 --> 00:09:32,920
I mean, I'm relatively fast,

236
00:09:32,960 --> 00:09:36,720
but the amount of time it takes to write code

237
00:09:36,720 --> 00:09:38,200
compared to the amount of time

238
00:09:38,200 --> 00:09:41,240
that it takes organically to train a model

239
00:09:41,240 --> 00:09:42,520
and to get the data in place

240
00:09:42,520 --> 00:09:46,040
and then let that thing write the code is substantial.

241
00:09:46,040 --> 00:09:47,920
And you know, Masi and others here are saying that,

242
00:09:47,920 --> 00:09:51,480
they're like, this is too powerful for it to not take over.

243
00:09:51,480 --> 00:09:55,480
And the chat GPT is not directly related to the coding thing,

244
00:09:55,480 --> 00:09:56,320
but it's the same idea.

245
00:09:56,320 --> 00:09:57,880
The idea is it'll do the thinking for you

246
00:09:57,880 --> 00:09:59,440
and it'll write your essay for you.

247
00:09:59,440 --> 00:10:02,360
And so, I mean, that's, I just,

248
00:10:02,360 --> 00:10:03,400
on the one side it's good,

249
00:10:03,400 --> 00:10:04,680
on the other side it's really bad.

250
00:10:04,680 --> 00:10:07,360
So let me tell you a story about the good stuff, okay?

251
00:10:07,360 --> 00:10:10,000
So there, I would give anything

252
00:10:10,000 --> 00:10:11,080
for the reference to this yet.

253
00:10:11,080 --> 00:10:15,000
I read this in 2014, I think it was.

254
00:10:15,000 --> 00:10:19,320
And I was studying this philosophical difference

255
00:10:19,320 --> 00:10:23,960
between algorithmic approaches to solutions

256
00:10:23,960 --> 00:10:27,000
and natural organic solutions.

257
00:10:27,040 --> 00:10:30,560
And the specific example was,

258
00:10:31,840 --> 00:10:32,760
and I've told the story before,

259
00:10:32,760 --> 00:10:35,360
but the specific example was a cam.

260
00:10:35,360 --> 00:10:37,080
You know what a cam is, right?

261
00:10:37,080 --> 00:10:39,160
It was a cam, like a camshaft in a car,

262
00:10:39,160 --> 00:10:40,720
but it wasn't a car, it was a factory.

263
00:10:40,720 --> 00:10:45,600
It was a factory in New England someplace in the Northeast.

264
00:10:45,600 --> 00:10:48,200
And, you know, back, you know,

265
00:10:48,200 --> 00:10:49,720
where there's a lot of manufacturing going.

266
00:10:49,720 --> 00:10:53,480
And then the story goes that they,

267
00:10:54,560 --> 00:10:55,960
I wish I could find, if anybody can find it,

268
00:10:55,960 --> 00:10:57,480
please give me a reference.

269
00:10:57,480 --> 00:10:59,920
But the device broke down.

270
00:10:59,920 --> 00:11:02,400
And so the production line was down.

271
00:11:02,400 --> 00:11:04,400
And this is a production line that was,

272
00:11:04,400 --> 00:11:05,520
you know, core of the business

273
00:11:05,520 --> 00:11:07,280
and they were losing all this money.

274
00:11:07,280 --> 00:11:10,120
And well, every day it was down, they were losing money.

275
00:11:10,120 --> 00:11:14,880
And this cam, it was this very complicated mechanical process

276
00:11:14,880 --> 00:11:18,120
that had to be done exactly that way,

277
00:11:18,120 --> 00:11:20,520
had been created somewhat organically

278
00:11:20,520 --> 00:11:22,600
and it had been tailored and it had been shaved off

279
00:11:22,600 --> 00:11:23,440
and everything.

280
00:11:23,960 --> 00:11:25,360
And so they had to, you know,

281
00:11:25,360 --> 00:11:28,840
they wanted this very unique cam was the core.

282
00:11:28,840 --> 00:11:31,640
It was the heart of everything on the assembly line

283
00:11:31,640 --> 00:11:33,680
and they couldn't recreate it.

284
00:11:33,680 --> 00:11:36,160
And so they hired, they paid all of this money

285
00:11:36,160 --> 00:11:40,280
to all of these people to do, to fix it.

286
00:11:40,280 --> 00:11:41,440
They brought in theorists,

287
00:11:41,440 --> 00:11:45,080
they brought in the Beth Mathematicians, you know,

288
00:11:45,080 --> 00:11:47,240
and they said, okay, hey, let's, you know,

289
00:11:47,240 --> 00:11:50,440
and they designed lots of failures.

290
00:11:51,440 --> 00:11:54,800
So they would put together all these amazing things

291
00:11:54,800 --> 00:11:57,280
and then they didn't work.

292
00:11:57,280 --> 00:11:58,640
They just didn't work

293
00:11:58,640 --> 00:12:00,400
because they weren't organic enough.

294
00:12:00,400 --> 00:12:01,240
They weren't natural enough.

295
00:12:01,240 --> 00:12:03,880
So then they brought in another team

296
00:12:03,880 --> 00:12:06,800
and I don't remember the specifics of the team,

297
00:12:06,800 --> 00:12:08,880
but this team did the same thing.

298
00:12:08,880 --> 00:12:10,800
They recreated the process that was used

299
00:12:10,800 --> 00:12:12,160
to create the first cam.

300
00:12:12,160 --> 00:12:15,440
And it took them longer to do all the stuff,

301
00:12:15,440 --> 00:12:16,400
but it actually worked.

302
00:12:16,400 --> 00:12:18,960
And what they did is they started with something

303
00:12:18,960 --> 00:12:23,640
that was the best approximation of, you know,

304
00:12:23,640 --> 00:12:24,640
that they could come up with

305
00:12:24,640 --> 00:12:25,840
and they used this stuff from, you know,

306
00:12:25,840 --> 00:12:28,280
the other mathematicians that people had given them

307
00:12:28,280 --> 00:12:29,680
and they put that in there

308
00:12:29,680 --> 00:12:31,080
and then they ran it for a while

309
00:12:31,080 --> 00:12:32,040
and then they would go in

310
00:12:32,040 --> 00:12:33,480
and then they would shave, they had the machinist

311
00:12:33,480 --> 00:12:34,840
and they would shave off part of it

312
00:12:34,840 --> 00:12:36,120
and then they would run it again

313
00:12:36,120 --> 00:12:37,600
and then they would shave off a little bit more

314
00:12:37,600 --> 00:12:38,520
and they would run it again.

315
00:12:38,520 --> 00:12:40,960
And then it was, so it was this fail faster idea, right?

316
00:12:40,960 --> 00:12:44,640
And that idea of adjusting for failure

317
00:12:44,640 --> 00:12:46,800
and training a device,

318
00:12:46,800 --> 00:12:49,000
that's exactly how machine learning works.

319
00:12:49,000 --> 00:12:50,240
So as I understand it.

320
00:12:50,240 --> 00:12:53,240
So having that, you know,

321
00:12:53,240 --> 00:12:55,480
and that got them the solution that they wanted to.

322
00:12:55,480 --> 00:13:00,480
And that process of natural learning that went on,

323
00:13:01,320 --> 00:13:04,280
I mean, natural learning has got a very specific meaning

324
00:13:04,280 --> 00:13:05,480
in the AI world.

325
00:13:05,480 --> 00:13:08,200
And that's, I'm sorry, natural intelligence,

326
00:13:08,200 --> 00:13:10,280
not natural learning, natural intelligence is the goal.

327
00:13:10,280 --> 00:13:14,640
Natural intelligence is when the intelligence is self-aware

328
00:13:14,640 --> 00:13:16,120
and everything and there's a lot of debate

329
00:13:16,120 --> 00:13:17,880
about whether that'll ever be a thing.

330
00:13:17,880 --> 00:13:22,080
But the point of it was that the organic approach,

331
00:13:22,080 --> 00:13:24,520
you know, fail and adjust, fail and fix,

332
00:13:24,520 --> 00:13:27,360
fail and fix, fail and fix is what got them the solution.

333
00:13:27,360 --> 00:13:29,920
And no amount of programming and algorithm

334
00:13:29,920 --> 00:13:31,760
at thinking is in the best minds could get it.

335
00:13:31,760 --> 00:13:33,680
It had to be incrementally done.

336
00:13:33,680 --> 00:13:35,720
And I really appreciate that story

337
00:13:35,720 --> 00:13:37,440
because that's how I do most things.

338
00:13:37,440 --> 00:13:38,840
I'm a very practical guy.

339
00:13:38,840 --> 00:13:41,380
I have a hard time, I mean, I can visualize certain things,

340
00:13:41,380 --> 00:13:43,400
but when it comes to like lead code algorithms

341
00:13:43,400 --> 00:13:45,600
and stuff like that, I don't really do well with them.

342
00:13:45,600 --> 00:13:49,520
But if I can see it working, I can modify what's working

343
00:13:49,520 --> 00:13:51,360
and get it to the point where it's working.

344
00:13:51,360 --> 00:13:53,080
And then if I just look at all the code, I'm like,

345
00:13:53,080 --> 00:13:54,840
okay, I understand how this code's working

346
00:13:54,840 --> 00:13:56,600
because I tweaked it all along the way.

347
00:13:56,600 --> 00:13:58,560
And sometimes there's a refactor along the way

348
00:13:58,560 --> 00:14:00,680
in there too, because, you know, like, hey, you know,

349
00:14:00,680 --> 00:14:02,960
this is not as efficient as it could be.

350
00:14:02,960 --> 00:14:06,360
But, you know, it's avoiding the premature optimization

351
00:14:06,360 --> 00:14:07,920
kind of thing, general intelligence.

352
00:14:07,920 --> 00:14:10,080
Yes, that's what I was looking for.

353
00:14:10,080 --> 00:14:10,920
That's three body problem.

354
00:14:10,920 --> 00:14:12,600
And yeah, that's the one I was looking for.

355
00:14:13,080 --> 00:14:17,560
So, you know, these things are all super fascinating.

356
00:14:17,560 --> 00:14:19,760
Chat, GPT is a part of it.

357
00:14:19,760 --> 00:14:22,680
It's definitely a thing that I think needs to exist.

358
00:14:23,800 --> 00:14:26,160
I just feel like so many people

359
00:14:26,160 --> 00:14:28,440
are like freaking out about it right now.

360
00:14:29,680 --> 00:14:31,280
And I have to ask myself,

361
00:14:31,280 --> 00:14:33,080
isn't there something better you could be doing

362
00:14:33,080 --> 00:14:34,280
with your time?

363
00:14:34,280 --> 00:14:37,720
But that's not my business, do what you want with your time.

364
00:14:37,720 --> 00:14:39,880
I mean, I waste my time plenty good.

365
00:14:39,880 --> 00:14:43,040
So, you know, if you want to play around, then fine.

366
00:14:43,040 --> 00:14:44,120
I don't, I don't.

367
00:14:44,120 --> 00:14:45,840
I have no intention of doing it.

368
00:14:47,160 --> 00:14:48,800
If I could train my own chatbot,

369
00:14:48,800 --> 00:14:50,600
which I am interested in doing,

370
00:14:50,600 --> 00:14:55,680
my goal with AI is to create my,

371
00:14:55,680 --> 00:14:57,200
you know how they say second brain, right?

372
00:14:57,200 --> 00:14:59,600
Second brain is another word for Zettlecasten.

373
00:14:59,600 --> 00:15:03,920
So I have, I've now, I'm up to like 1800 content nodes,

374
00:15:03,920 --> 00:15:06,920
knowledge nodes in my current Zettlecasten.

375
00:15:06,920 --> 00:15:09,200
I have three other knowledge bases

376
00:15:09,200 --> 00:15:12,800
that have over a thousand content nodes in each of them.

377
00:15:12,800 --> 00:15:15,240
And I am in the process of bringing all of those over.

378
00:15:15,240 --> 00:15:19,000
So it's like almost everything that I've ever written about.

379
00:15:19,000 --> 00:15:21,920
And once I get all of that content in one place,

380
00:15:21,920 --> 00:15:26,920
I really want to see how I could put

381
00:15:27,280 --> 00:15:31,320
some machine learning algorithmic stuff,

382
00:15:31,320 --> 00:15:32,360
not machine algorithms,

383
00:15:32,360 --> 00:15:35,200
but I want to see if I could build

384
00:15:35,200 --> 00:15:39,160
some machine learning into my own data stuff, right?

385
00:15:39,160 --> 00:15:41,840
And then, and then of course the extension of this is that,

386
00:15:41,840 --> 00:15:44,400
you know, the exchange grid, the knowledge exchange grid,

387
00:15:44,400 --> 00:15:47,480
once I can get, so let's say, let's say that I have,

388
00:15:47,480 --> 00:15:49,640
I know, text pregeneration, stuff like that, right?

389
00:15:49,640 --> 00:15:51,760
So I'm already doing templates and stuff,

390
00:15:51,760 --> 00:15:52,800
but I mean, it's very possible

391
00:15:52,800 --> 00:15:53,880
that I could do the template generation

392
00:15:53,880 --> 00:15:55,080
automatically through AI.

393
00:15:56,640 --> 00:15:59,800
But something else that's interesting that interests me is that,

394
00:15:59,800 --> 00:16:01,800
is that's just my corpus, right?

395
00:16:01,800 --> 00:16:03,840
I just have my data, my Zettlecasten,

396
00:16:03,840 --> 00:16:06,680
but the goal, and then we're probably like five years out

397
00:16:06,680 --> 00:16:09,480
on this, is to eventually be able to follow multiple other

398
00:16:09,480 --> 00:16:12,440
people and have a cash copy of their Zettlecasten

399
00:16:12,440 --> 00:16:13,520
with me as well.

400
00:16:13,520 --> 00:16:16,360
And, you know, you take that to the nth degree,

401
00:16:16,360 --> 00:16:18,160
if I've got a thousand people,

402
00:16:18,160 --> 00:16:20,520
and there are people that I personally have curated,

403
00:16:20,520 --> 00:16:22,520
my ring of trust about knowledge and that stuff,

404
00:16:22,520 --> 00:16:25,640
now I've created a corpus of data

405
00:16:25,640 --> 00:16:29,760
that's extremely compelling when it comes to not just

406
00:16:29,760 --> 00:16:32,640
searching, but making suggestions.

407
00:16:33,560 --> 00:16:37,440
And then, then we could put,

408
00:16:37,440 --> 00:16:39,000
is that what they call it, chat by utility?

409
00:16:39,000 --> 00:16:41,600
Yeah, and then I would put on top of that,

410
00:16:41,600 --> 00:16:43,880
I would start to layer in the AI,

411
00:16:43,880 --> 00:16:46,480
and then I could have the AI suggest things to me,

412
00:16:46,480 --> 00:16:48,960
or when I start writing about something,

413
00:16:48,960 --> 00:16:52,120
I would love to have another T-Mex window open that's like,

414
00:16:52,120 --> 00:16:53,880
dude, you've already talked about this over here,

415
00:16:53,880 --> 00:16:55,480
and here, and here, and here, here's the other thing,

416
00:16:55,480 --> 00:16:57,040
and have it dynamically see,

417
00:16:57,040 --> 00:16:59,640
not just from the keywords that I'm using,

418
00:16:59,640 --> 00:17:01,260
which is, you know, a start,

419
00:17:01,260 --> 00:17:03,020
but I wanted to see, well, you know,

420
00:17:03,020 --> 00:17:06,300
you've written similarly to this,

421
00:17:06,300 --> 00:17:08,540
or somebody has written similarly to this,

422
00:17:08,540 --> 00:17:10,780
you know, and you see this kind of thing already

423
00:17:10,780 --> 00:17:13,980
in like, trouble ticket issues,

424
00:17:13,980 --> 00:17:18,860
and stuff like that, that we submit to GitHub,

425
00:17:18,860 --> 00:17:19,700
or anything like that, you know,

426
00:17:19,700 --> 00:17:20,540
you start typing things like,

427
00:17:20,540 --> 00:17:22,460
are you sure it's not this problem right here, right?

428
00:17:22,460 --> 00:17:26,580
So there's already, you know, code to do this,

429
00:17:26,580 --> 00:17:28,620
and that's kind of the, you know,

430
00:17:28,620 --> 00:17:30,260
phase two of the whole keg thing,

431
00:17:30,260 --> 00:17:33,100
you know, phase one is to get the knowledge,

432
00:17:33,100 --> 00:17:35,100
you know, really stable and collectible,

433
00:17:35,100 --> 00:17:37,020
and phase two is kind of exchange it,

434
00:17:37,020 --> 00:17:39,220
I guess it's apparently phase three,

435
00:17:39,220 --> 00:17:41,220
phase three would be processing the data,

436
00:17:41,220 --> 00:17:44,020
that would be processing all the knowledge,

437
00:17:44,020 --> 00:17:45,620
it's not going to fall about it.

438
00:17:47,140 --> 00:17:50,420
They did it for the reason of spam, yeah, I mean, yeah,

439
00:17:50,420 --> 00:17:52,700
I just would never want to put it,

440
00:17:52,700 --> 00:17:54,700
I mean, it's bad enough having a chat bot, you know,

441
00:17:54,700 --> 00:17:56,980
do one thing, the hardest part about all of this

442
00:17:56,980 --> 00:17:59,780
is going to be being able to determine who's real,

443
00:17:59,780 --> 00:18:03,180
and that's already becoming a thing, right?

444
00:18:03,180 --> 00:18:06,260
I mean, I imagine there's a lot of like, you know,

445
00:18:06,260 --> 00:18:08,620
porn and cheating sites that are going to love these,

446
00:18:08,620 --> 00:18:12,140
these AIs, because they're just going to be

447
00:18:12,140 --> 00:18:14,900
the best, you know, pretend girls ever,

448
00:18:14,900 --> 00:18:19,100
yeah, NPCs will be awesome, yeah,

449
00:18:19,100 --> 00:18:21,660
has apps now that check for secrets,

450
00:18:21,660 --> 00:18:24,260
check for dependency security flaws, yeah, yeah.

451
00:18:25,380 --> 00:18:26,660
Yeah, and there's like, there's chat,

452
00:18:26,660 --> 00:18:31,060
yeah, I mean, all of those sorts of things are stuff

453
00:18:31,060 --> 00:18:32,180
that I definitely want to add in.

454
00:18:32,180 --> 00:18:34,140
So I'm not, it's not that I'm against chat bots,

455
00:18:34,140 --> 00:18:35,740
I'm definitely adding a chat bot,

456
00:18:35,740 --> 00:18:38,260
I've already started adding a Twitch chat bot,

457
00:18:38,260 --> 00:18:42,620
which what I want it to do is like, you know,

458
00:18:42,620 --> 00:18:44,500
I have all these commands, right?

459
00:18:44,500 --> 00:18:46,260
But I hate maintaining the commands,

460
00:18:46,260 --> 00:18:49,140
so what I would rather have my chat bot do,

461
00:18:49,140 --> 00:18:51,540
my Twitch chat bot, what I would rather have it do

462
00:18:51,540 --> 00:18:55,060
is I would rather have it become intimately familiar

463
00:18:55,060 --> 00:18:57,380
with my Zettelkasten, right?

464
00:18:57,380 --> 00:19:01,860
So if somebody starts chatting about something,

465
00:19:01,860 --> 00:19:03,940
and Masi's already made some really amazing stuff

466
00:19:03,940 --> 00:19:06,380
on this level, if somebody starts chatting about something,

467
00:19:06,380 --> 00:19:10,260
I want my chat bot to score potentially a response

468
00:19:10,260 --> 00:19:12,140
and say, okay, somebody's talking like this,

469
00:19:12,140 --> 00:19:14,540
somebody used a question mark, somebody's doing whatever.

470
00:19:14,540 --> 00:19:17,660
And he'll say, if you're asking about this,

471
00:19:17,660 --> 00:19:19,580
this is what I was trying to do, right?

472
00:19:19,580 --> 00:19:21,900
So I would really love to be able to create

473
00:19:21,900 --> 00:19:25,660
kind of a proactive customer service-like bot in my Twitch

474
00:19:25,660 --> 00:19:27,780
that answers all of the mundane questions for me

475
00:19:27,780 --> 00:19:30,260
without people having to go to the commands, right?

476
00:19:30,260 --> 00:19:31,460
I mean, they go to the commands

477
00:19:31,460 --> 00:19:32,660
and then they have to filter through the commands

478
00:19:32,660 --> 00:19:33,780
and they have to find the right one,

479
00:19:33,780 --> 00:19:36,300
and sometimes they do and there's kind of a path through there,

480
00:19:36,300 --> 00:19:37,700
but I have to maintain all of that.

481
00:19:37,700 --> 00:19:40,380
And maintaining the commands, I actually was looking at it,

482
00:19:40,380 --> 00:19:42,620
I've got like 200, 300 commands.

483
00:19:42,620 --> 00:19:45,380
Yeah, if I train it on my Zett as my corp,

484
00:19:45,380 --> 00:19:48,540
yeah, then I would be, so then somebody asks a question

485
00:19:48,540 --> 00:19:51,820
and all I have to do is write.

486
00:19:52,100 --> 00:19:55,260
I don't have to go in and create all the interlinking

487
00:19:55,260 --> 00:19:57,980
and stuff like that inside of a specific,

488
00:19:57,980 --> 00:19:59,060
commands database.

489
00:19:59,060 --> 00:20:01,020
I just maintain my Zodacast and answer questions

490
00:20:01,020 --> 00:20:01,980
just like I'm doing right now,

491
00:20:01,980 --> 00:20:04,900
and then I include links to YouTube and stuff like that.

492
00:20:04,900 --> 00:20:06,780
And the links are identifiable

493
00:20:06,780 --> 00:20:08,540
because they've got the YouTube emoji on them.

494
00:20:08,540 --> 00:20:11,100
So my chat bot could be intelligent and say,

495
00:20:11,100 --> 00:20:13,540
hey, well, there's actually these YouTube videos on this too.

496
00:20:13,540 --> 00:20:18,020
And it could proactively engage with anybody in my chat

497
00:20:18,020 --> 00:20:19,940
while I'm writing and doing the work.

498
00:20:19,940 --> 00:20:22,980
And then I, I mean, it might not be as personal,

499
00:20:22,980 --> 00:20:25,460
but it could be very valuable.

500
00:20:25,460 --> 00:20:28,860
I think that personal broadcasting,

501
00:20:28,860 --> 00:20:30,900
as we do it now on this coworking kind of thing,

502
00:20:30,900 --> 00:20:32,100
is going to progress.

503
00:20:32,100 --> 00:20:34,980
I think, yeah, take care.

504
00:20:34,980 --> 00:20:37,340
It's, I think that this is one of those things

505
00:20:37,340 --> 00:20:40,420
that is going to progress

506
00:20:40,420 --> 00:20:41,700
and it's gonna become more valuable.

507
00:20:41,700 --> 00:20:44,660
Right now it's just kind of a fascination.

508
00:20:45,660 --> 00:20:50,660
But the day that I can point a chat GPT at my Zodacast

509
00:20:51,540 --> 00:20:54,340
and have it automatically train itself

510
00:20:54,340 --> 00:20:58,140
and get 90% accuracy on when to participate in my chat

511
00:20:58,140 --> 00:21:01,500
and about answering questions on my behalf as an AI,

512
00:21:01,500 --> 00:21:05,540
that's the time when I will become extremely interested in it.

513
00:21:05,540 --> 00:21:07,260
I will become extremely interested in it

514
00:21:07,260 --> 00:21:08,780
because then it's saving me time.

515
00:21:08,780 --> 00:21:11,020
That's what AI potentially could do.

516
00:21:11,020 --> 00:21:14,060
And, you know, somebody mentioned the teaching thing.

517
00:21:14,260 --> 00:21:16,260
I think there's another,

518
00:21:16,260 --> 00:21:21,260
I understand chat GPT is a subset of instructional GPT.

519
00:21:21,300 --> 00:21:22,660
Did you guys read about that?

520
00:21:22,660 --> 00:21:23,740
So there's another GPT.

521
00:21:23,740 --> 00:21:26,620
It's like, I think it's called instruction GPT.

522
00:21:26,620 --> 00:21:30,180
It's actually designed for training and teaching

523
00:21:30,180 --> 00:21:32,020
and stuff like that, more than just a random chat one.

524
00:21:32,020 --> 00:21:33,740
The random chat one is to get, you know,

525
00:21:33,740 --> 00:21:35,180
people's interest and stuff.

526
00:21:35,180 --> 00:21:37,740
So that actually does, does, is interesting to me.

527
00:21:37,740 --> 00:21:40,060
I think teaching is fine.

528
00:21:41,060 --> 00:21:46,060
I think that there, yeah,

529
00:21:47,260 --> 00:21:49,060
if there was some way to have it correct.

530
00:21:49,060 --> 00:21:51,620
So that's kind of, I mean, the thing of it,

531
00:21:51,620 --> 00:21:52,780
mostly that would be really cool

532
00:21:52,780 --> 00:21:54,860
is if you had a bot that was running, right?

533
00:21:54,860 --> 00:21:56,140
So if you had a bot that was running,

534
00:21:56,140 --> 00:21:58,740
it was trained off of your corpus and Zodacast then,

535
00:21:58,740 --> 00:22:00,500
it could chime in every once in a while

536
00:22:00,500 --> 00:22:02,220
and maybe it would get things wrong.

537
00:22:02,220 --> 00:22:04,460
It would say, well, that's not really the right answer there.

538
00:22:04,460 --> 00:22:05,740
Here's the right answer.

539
00:22:05,740 --> 00:22:08,900
And then it could take its correction,

540
00:22:08,900 --> 00:22:10,980
add it to its algorithm and say,

541
00:22:10,980 --> 00:22:13,060
so that whole thing that you have to do with AI,

542
00:22:13,060 --> 00:22:14,420
where you have to constantly correct it

543
00:22:14,420 --> 00:22:15,580
when it gets stuff wrong, right?

544
00:22:15,580 --> 00:22:17,100
But it learns.

545
00:22:17,100 --> 00:22:18,940
Every time it gets something wrong in a chat,

546
00:22:18,940 --> 00:22:20,820
we could laugh about it and I could correct it

547
00:22:20,820 --> 00:22:23,220
and then it would get that answer right next time.

548
00:22:23,220 --> 00:22:26,420
And then we could just keep going like that,

549
00:22:26,420 --> 00:22:27,260
you know what I mean?

550
00:22:27,260 --> 00:22:28,860
And it could try really hard

551
00:22:28,860 --> 00:22:31,180
and I could just kind of train it

552
00:22:31,180 --> 00:22:33,860
along with everybody else while I'm not here.

553
00:22:33,860 --> 00:22:38,860
So the idea of setting up like a SkiZix,

554
00:22:38,940 --> 00:22:40,540
so I used to name my bot,

555
00:22:40,540 --> 00:22:44,380
an interactive bot that dynamically learns

556
00:22:44,380 --> 00:22:46,980
by attempting to answer popular, frequent,

557
00:22:46,980 --> 00:22:48,220
unasked questions and getting them wrong

558
00:22:48,220 --> 00:22:49,340
and having it be corrected,

559
00:22:49,340 --> 00:22:52,660
that's like crazy, crazy compelling for me.

560
00:22:52,660 --> 00:22:54,340
And that's just from a customer service perspective,

561
00:22:54,340 --> 00:22:55,980
but from an educational perspective and all that.

562
00:22:55,980 --> 00:23:00,060
Now, if you're gonna start asking my bot about everything

563
00:23:00,060 --> 00:23:02,140
and putting that in your essay,

564
00:23:03,780 --> 00:23:05,300
I don't know how I feel about that.

565
00:23:05,300 --> 00:23:07,740
Maybe it's just making searching efficient.

566
00:23:07,740 --> 00:23:08,880
I mean, I say that all the time.

567
00:23:08,880 --> 00:23:10,200
I say if you wanna be in good in tech,

568
00:23:10,200 --> 00:23:11,480
you gotta be a really good researcher,

569
00:23:11,480 --> 00:23:12,400
be able to search fast.

570
00:23:12,400 --> 00:23:15,880
Well, if you have a bot that's doing all the searching

571
00:23:15,880 --> 00:23:17,880
for you all the time and you're just asking your bot

572
00:23:17,880 --> 00:23:20,720
about that's more likely to get the right answer,

573
00:23:20,720 --> 00:23:25,720
then, you know, as it takes four gigabytes of GP RAM

574
00:23:26,040 --> 00:23:28,100
to train these modern models, really.

575
00:23:30,040 --> 00:23:32,460
Yeah, well, there's a lot of them, yeah.

576
00:23:33,800 --> 00:23:34,640
Yeah, I don't know.

577
00:23:34,640 --> 00:23:37,440
It'd be interesting to see how much I could do.

578
00:23:37,440 --> 00:23:39,240
I mean, I do have my thing over here.

579
00:23:39,240 --> 00:23:42,240
So, I'm trying to figure out how much I could actually do

580
00:23:42,240 --> 00:23:45,360
that, it'd have to have a lot of data too, right?

581
00:23:45,360 --> 00:23:46,200
So,

582
00:23:49,520 --> 00:23:54,520
oh no, no, that would not be a thing to get, yes.

583
00:23:56,320 --> 00:23:58,280
So, that's my opinion on it.

584
00:23:59,440 --> 00:24:01,120
Yeah, I'm kind of underwhelmed with it,

585
00:24:01,120 --> 00:24:02,760
but I know that it's going in the right direction.

586
00:24:02,760 --> 00:24:03,840
I guess I'm kind of annoyed

587
00:24:03,840 --> 00:24:06,360
because everybody's asking me about it.

588
00:24:06,360 --> 00:24:08,800
And I'm like, well, what are you using it for?

589
00:24:08,800 --> 00:24:11,520
And every time I ask what they're using it for,

590
00:24:12,640 --> 00:24:14,760
it's, well, it's making me do my homework faster.

591
00:24:14,760 --> 00:24:17,840
And I'm like, oh my God, it's like,

592
00:24:17,840 --> 00:24:19,160
but I don't know if that's bad.

593
00:24:19,160 --> 00:24:20,520
I think it's bad.

594
00:24:20,520 --> 00:24:21,760
I think it's bad because people are not doing

595
00:24:21,760 --> 00:24:23,240
their own research.

596
00:24:23,240 --> 00:24:24,440
It's one of two things.

597
00:24:24,440 --> 00:24:25,960
They're either not doing their own research

598
00:24:25,960 --> 00:24:28,960
or it's facilitating their research, right?

599
00:24:28,960 --> 00:24:33,320
If it's the second, then I'm all for that.

600
00:24:33,320 --> 00:24:34,920
I mean, the terminal makes you faster

601
00:24:34,920 --> 00:24:37,160
during your own research, so why not an AI?

602
00:24:38,600 --> 00:24:43,440
So, you know, if you shut learning, yeah.

603
00:24:44,840 --> 00:24:47,880
So, I think that's it.

604
00:24:47,880 --> 00:24:52,680
I mean, I don't have any inclination to play with it.

605
00:24:52,680 --> 00:24:53,920
I got too many other things to make right now,

606
00:24:53,920 --> 00:24:58,920
but as I said, if it were gonna make my Twitch bot

607
00:24:59,040 --> 00:25:01,400
more intelligent so that it could help people

608
00:25:01,400 --> 00:25:04,600
learn more quickly and save me some time,

609
00:25:04,600 --> 00:25:06,480
then that's a good thing.

610
00:25:06,480 --> 00:25:07,320
That's a good thing.

611
00:25:07,320 --> 00:25:09,720
So, I'll try to keep my thoughts open on that,

612
00:25:09,720 --> 00:25:12,680
but Project Matters and Ceaseless are on board.

613
00:25:12,680 --> 00:25:13,720
It will replace jobs.

614
00:25:13,720 --> 00:25:16,320
Then I'm fine with it, use it as an education.

615
00:25:16,320 --> 00:25:18,880
They can't have it, just won't want it.

616
00:25:18,880 --> 00:25:21,880
Why would they have it replace jobs?

617
00:25:21,880 --> 00:25:23,200
I don't understand that statement at all.

618
00:25:23,200 --> 00:25:24,400
I've heard that before.

619
00:25:25,720 --> 00:25:28,620
This chat bot is no word near replacing anyone.

620
00:25:29,880 --> 00:25:34,380
I mean, even the people who operated the front desk

621
00:25:34,860 --> 00:25:37,380
like the place that took my piss for my drug test.

622
00:25:39,740 --> 00:25:44,740
Even they are not replaceable yet by this.

623
00:25:45,140 --> 00:25:49,340
I mean, I just, I don't see it being that reliable.

624
00:25:49,340 --> 00:25:51,200
And they were pretty damn bad.

625
00:25:54,100 --> 00:25:56,140
I don't even want to talk about it.

626
00:25:56,140 --> 00:25:58,420
Oh, I'm sorry, as you're here at 3.58,

627
00:25:58,420 --> 00:26:00,380
at 12.58 and not one o'clock,

628
00:26:00,380 --> 00:26:02,660
you need to wait until one o'clock.

629
00:26:02,660 --> 00:26:03,500
Really?

630
00:26:03,620 --> 00:26:04,460
I just don't even want to.

631
00:26:04,460 --> 00:26:06,060
It's a different thing completely.

632
00:26:06,060 --> 00:26:08,220
I just had to go through.

633
00:26:08,220 --> 00:26:11,140
I had to wait in line for like two hours

634
00:26:11,140 --> 00:26:12,140
to get a drug test.

635
00:26:12,140 --> 00:26:12,980
My phone died.

636
00:26:12,980 --> 00:26:14,100
I had to come back the next day

637
00:26:14,100 --> 00:26:15,860
and wait again for two hours.

638
00:26:18,140 --> 00:26:21,020
See, any of those things that could be improved by AI,

639
00:26:21,020 --> 00:26:22,180
I'm down.

640
00:26:22,180 --> 00:26:23,020
I'm down.

641
00:26:24,300 --> 00:26:27,380
I'm down with those things being approved.

642
00:26:27,380 --> 00:26:28,820
Corporations are going to use it eventually

643
00:26:28,820 --> 00:26:30,540
and people should use it as well as benefit them.

644
00:26:30,540 --> 00:26:31,780
Yeah, for sure.

645
00:26:31,780 --> 00:26:32,780
Teachers are next.

646
00:26:33,780 --> 00:26:35,740
At least the current way of teaching.

647
00:26:35,740 --> 00:26:37,820
Well, I think the current way of teaching is totally broken.

648
00:26:37,820 --> 00:26:40,580
So I am all about having...

649
00:26:42,620 --> 00:26:47,620
I am all about the education getting disrupted by AI.

650
00:26:48,100 --> 00:26:51,060
And it's not completely untrue that the way

651
00:26:51,060 --> 00:26:53,580
that education is happening now could be taken over

652
00:26:53,580 --> 00:26:55,700
by an AI, absolutely.

653
00:26:55,700 --> 00:26:56,740
Absolutely.

654
00:26:56,740 --> 00:27:01,300
It's like, okay, I'm gonna tell you about a topic in general

655
00:27:01,300 --> 00:27:02,980
and I'm gonna sit here and blah, blah, blah.

656
00:27:02,980 --> 00:27:04,900
And you're gonna take notes and there's no ability

657
00:27:04,900 --> 00:27:07,380
for us to interact except for off hours.

658
00:27:07,380 --> 00:27:11,300
And then you get like an hour possibly with a TA.

659
00:27:11,300 --> 00:27:14,620
You know, the entire model for modern education

660
00:27:14,620 --> 00:27:16,260
is totally broken.

661
00:27:16,260 --> 00:27:17,780
It's totally broken.

662
00:27:17,780 --> 00:27:21,700
And it could easily be replaced by AI.

663
00:27:21,700 --> 00:27:23,380
I completely agree with that.

664
00:27:24,540 --> 00:27:27,340
But if you take the true learning model,

665
00:27:27,340 --> 00:27:29,420
the Art of Ex thing that we talked about,

666
00:27:29,420 --> 00:27:32,420
then where you're failing faster and you're being organic

667
00:27:32,460 --> 00:27:36,540
and you have a one-on-one mentor who knows you personally,

668
00:27:36,540 --> 00:27:37,780
I think we're a ways from that.

669
00:27:37,780 --> 00:27:40,260
I do think that AI could get there.

670
00:27:40,260 --> 00:27:44,860
I think that AI could have a strong chance

671
00:27:44,860 --> 00:27:48,140
at learning about you and learning about your interests

672
00:27:48,140 --> 00:27:50,220
and learning about what you struggle with and learning.

673
00:27:50,220 --> 00:27:54,140
I think those things for education could be really cool.

674
00:27:54,140 --> 00:27:55,380
I mean, think about that.

675
00:27:55,380 --> 00:27:59,540
That you could have an AI that becomes trained

676
00:27:59,540 --> 00:28:01,980
on your regular failures.

677
00:28:01,980 --> 00:28:04,780
So maybe you're learning a foreign language

678
00:28:04,780 --> 00:28:08,060
and you get imperative declension wrong in Russian

679
00:28:08,060 --> 00:28:09,220
all the time.

680
00:28:09,220 --> 00:28:11,860
It's like the thing, it's constantly doing the assessments

681
00:28:11,860 --> 00:28:13,900
and everything that a teacher would be doing

682
00:28:13,900 --> 00:28:16,300
and then never doing anything, just giving you an F, right?

683
00:28:16,300 --> 00:28:18,060
It would be adapting and saying,

684
00:28:18,060 --> 00:28:20,340
hey, okay, I know you have trouble with this one thing,

685
00:28:20,340 --> 00:28:21,940
so I'm gonna give you more of these things.

686
00:28:21,940 --> 00:28:26,140
So the potential to have AI adapt to our weaknesses

687
00:28:26,140 --> 00:28:27,180
as we're learning,

688
00:28:27,180 --> 00:28:28,500
maybe we don't remember things very well.

689
00:28:28,500 --> 00:28:30,060
That would be me, right?

690
00:28:30,060 --> 00:28:32,900
So it would be more about repetition.

691
00:28:32,900 --> 00:28:35,100
I think that there's a tremendous potential there

692
00:28:35,100 --> 00:28:36,500
for that, I really do.

693
00:28:37,580 --> 00:28:39,180
Intermediate with video graphics, not just text.

694
00:28:39,180 --> 00:28:40,140
So whole learning path,

695
00:28:40,140 --> 00:28:41,580
focus on the way of learning with custom graphics

696
00:28:41,580 --> 00:28:42,740
to explain, yeah.

697
00:28:42,740 --> 00:28:43,700
Well, and that's another thing too.

698
00:28:43,700 --> 00:28:45,060
I mean, there's a book out there

699
00:28:45,060 --> 00:28:46,220
called Multiple Intelligences

700
00:28:46,220 --> 00:28:49,500
and it talks about all the different ways that we learn.

701
00:28:49,500 --> 00:28:51,980
Thomas, what's his name, Sir Ken.

702
00:28:51,980 --> 00:28:53,140
Sir Ken talks about this.

703
00:28:53,140 --> 00:28:56,260
The woman who created the Juilliard Academy failed.

704
00:28:56,260 --> 00:28:58,380
She failed out of all her classes

705
00:28:58,380 --> 00:28:59,620
and they took her to a specialist

706
00:28:59,660 --> 00:29:01,020
and she was moving around

707
00:29:01,020 --> 00:29:04,340
and the specialist said to the parents, look at her.

708
00:29:04,340 --> 00:29:05,260
And she goes, what?

709
00:29:05,260 --> 00:29:07,220
And he goes, she has to be moving.

710
00:29:07,220 --> 00:29:08,580
They got her in a special school

711
00:29:08,580 --> 00:29:10,740
that was dynamic for dynamic learners

712
00:29:10,740 --> 00:29:13,180
who were walking around, had to be moving to learning.

713
00:29:13,180 --> 00:29:14,300
And she excelled.

714
00:29:14,300 --> 00:29:16,620
She excelled so much, she made the most,

715
00:29:16,620 --> 00:29:17,980
she made Juilliard Academy out of it.

716
00:29:17,980 --> 00:29:20,700
If they had written her off because of her learning style,

717
00:29:20,700 --> 00:29:25,100
and that is one way that AI can adapt.

718
00:29:25,100 --> 00:29:26,380
I mean, everybody knows a teacher,

719
00:29:26,380 --> 00:29:27,460
the best teachers in the world

720
00:29:27,460 --> 00:29:29,460
are the ones who are able to adapt to the individual peak.

721
00:29:29,460 --> 00:29:31,220
Students, right?

722
00:29:31,220 --> 00:29:33,740
And there's tons and tons of horrible teachers

723
00:29:33,740 --> 00:29:35,140
who don't adapt at all.

724
00:29:35,140 --> 00:29:38,220
They stay in their methods, they do their thing.

725
00:29:38,220 --> 00:29:41,100
It's like you adapt to them or you die and get an F

726
00:29:41,100 --> 00:29:42,300
and you have to take it over again

727
00:29:42,300 --> 00:29:43,260
and spend all the money.

728
00:29:43,260 --> 00:29:44,860
There's plenty of that.

729
00:29:44,860 --> 00:29:48,660
But if you, so the good teachers who adapt

730
00:29:48,660 --> 00:29:52,460
and make things engaging and change their methods

731
00:29:52,460 --> 00:29:56,460
or allow God forbid one student to do one project

732
00:29:56,460 --> 00:29:57,780
that's different than another student

733
00:29:57,780 --> 00:29:59,980
because of the way that they learn.

734
00:29:59,980 --> 00:30:04,980
I mean, how do you set up a rubric for that?

735
00:30:07,940 --> 00:30:09,140
You can't.

736
00:30:09,140 --> 00:30:12,420
But if you have an AI, maybe an AI kind of thing

737
00:30:12,420 --> 00:30:16,060
is gonna get us into this closer to one-on-one education,

738
00:30:16,060 --> 00:30:18,220
which is the holy grail.

739
00:30:18,220 --> 00:30:20,580
One-on-one education has been the way humans

740
00:30:20,580 --> 00:30:23,960
have been learning best since the dawn of time.

741
00:30:23,960 --> 00:30:26,260
There's overwhelming evidence of this,

742
00:30:26,260 --> 00:30:28,820
but nobody accepts that evidence

743
00:30:28,820 --> 00:30:32,600
because it's too impractical to do.

744
00:30:32,600 --> 00:30:34,300
At least they say, I don't think it is.

745
00:30:34,300 --> 00:30:36,180
I think that if they were to actually economically,

746
00:30:36,180 --> 00:30:38,580
I think they can make it work, but they don't.

747
00:30:38,580 --> 00:30:39,700
And in order to make it work,

748
00:30:39,700 --> 00:30:43,020
you'd have to have mentors adapted to a different,

749
00:30:43,020 --> 00:30:45,300
I mean, when you had back in the old days,

750
00:30:45,300 --> 00:30:47,580
it was like one-on-one and if that pairing didn't work,

751
00:30:47,580 --> 00:30:49,540
you would find a different guru or a different master

752
00:30:49,540 --> 00:30:50,380
and you would go to that person.

753
00:30:50,380 --> 00:30:53,020
You would go to one person for their mastery in this thing

754
00:30:53,020 --> 00:30:54,300
and another person in a mastery in this thing.

755
00:30:54,300 --> 00:30:56,180
That's true education.

756
00:30:56,180 --> 00:30:59,780
And that's not happening in the traditional system,

757
00:30:59,780 --> 00:31:01,380
but AI could potentially do it.

758
00:31:01,380 --> 00:31:03,900
AI could potentially do it, it could.

759
00:31:03,900 --> 00:31:06,300
Yeah, reviews on game writers versus 10 years ago.

760
00:31:06,300 --> 00:31:08,900
Oh yeah, yes.

761
00:31:08,900 --> 00:31:13,780
Yeah, based on consensus.

762
00:31:13,780 --> 00:31:15,220
Well, I think one of the things

763
00:31:15,220 --> 00:31:18,500
that individual instruction like that is going to get both.

764
00:31:18,500 --> 00:31:23,500
This is something interesting about what I want to say here.

765
00:31:26,380 --> 00:31:27,700
Homeschooling.

766
00:31:27,700 --> 00:31:29,700
So that's, okay, so I live in the South, right?

767
00:31:29,700 --> 00:31:31,340
I live in North Carolina.

768
00:31:31,340 --> 00:31:35,860
And ironically, there's extreme agreement

769
00:31:37,500 --> 00:31:41,940
between very, very right-wing conservatives

770
00:31:41,940 --> 00:31:45,340
and very, very leftist progressives

771
00:31:47,020 --> 00:31:49,020
on this topic of homeschooling.

772
00:31:50,500 --> 00:31:52,220
Now, I don't know if that's a good thing or a bad thing,

773
00:31:52,260 --> 00:31:55,700
but they agree that the current system

774
00:31:55,700 --> 00:31:57,620
does not meet their needs.

775
00:31:57,620 --> 00:31:58,860
Now, the one people agree

776
00:31:58,860 --> 00:32:00,540
because they don't think mathematics

777
00:32:00,540 --> 00:32:01,740
and science are a priority

778
00:32:01,740 --> 00:32:04,420
and that faith in Jesus is all that matters.

779
00:32:04,420 --> 00:32:06,060
I was told that to my face

780
00:32:06,060 --> 00:32:09,300
when my son was denied access to such a school

781
00:32:09,300 --> 00:32:11,660
because he didn't have enough belief in Jesus

782
00:32:11,660 --> 00:32:14,220
according to their method, because we were Mormon.

783
00:32:14,220 --> 00:32:15,460
That's a true story.

784
00:32:17,820 --> 00:32:20,260
But they had, we thought more direct instruction

785
00:32:20,260 --> 00:32:22,540
would be better, but it turns out, no.

786
00:32:22,540 --> 00:32:24,820
They literally told us math and sciences

787
00:32:24,820 --> 00:32:26,820
are secondary to faith in Jesus.

788
00:32:26,820 --> 00:32:30,820
And we're like, okay, we'll be moving on now.

789
00:32:30,820 --> 00:32:32,620
And then you have the other people

790
00:32:32,620 --> 00:32:35,420
who are all about the mass and the sciences

791
00:32:35,420 --> 00:32:38,020
and playing in mud and stuff like that

792
00:32:38,020 --> 00:32:39,620
in kind of the hippie education.

793
00:32:39,620 --> 00:32:41,100
And believe it or not,

794
00:32:43,980 --> 00:32:47,260
so believe it or not, those two camps

795
00:32:47,260 --> 00:32:48,660
both want the same thing.

796
00:32:48,660 --> 00:32:52,180
They want the government to get out of the way

797
00:32:52,180 --> 00:32:54,180
when it comes to education

798
00:32:54,180 --> 00:32:56,060
because they believe that education

799
00:32:56,060 --> 00:32:57,180
can't be done properly

800
00:32:57,180 --> 00:33:02,180
through any kind of singularly interested association

801
00:33:02,500 --> 00:33:05,460
and all the problems that are coming up in education

802
00:33:05,460 --> 00:33:07,420
are all related to this thing.

803
00:33:07,420 --> 00:33:10,700
I just don't know if it's a good thing or bad thing

804
00:33:10,700 --> 00:33:14,020
to let people even get more in their sandbox.

805
00:33:14,020 --> 00:33:16,660
I mean, I think, I don't know.

806
00:33:16,660 --> 00:33:18,860
I don't know, it's a really divisive topic.

807
00:33:20,660 --> 00:33:23,100
Interested both South Carolina power stations

808
00:33:23,100 --> 00:33:23,940
have been talking this week.

809
00:33:23,940 --> 00:33:25,100
Oh, I know.

810
00:33:25,100 --> 00:33:26,740
I know, I was here.

811
00:33:26,740 --> 00:33:28,360
Dude, I saw it.

812
00:33:28,360 --> 00:33:30,380
I don't want to talk about it right now.

813
00:33:30,380 --> 00:33:32,260
We can talk about that at a different time.

814
00:33:32,260 --> 00:33:35,980
No, they confirmed it was an act of terrorism in our state.

815
00:33:35,980 --> 00:33:37,200
So we're Ireland now.

816
00:33:38,820 --> 00:33:40,640
Yeah, it's in my state.

817
00:33:40,640 --> 00:33:43,520
I'm seeing it on the news all the time.

818
00:33:43,520 --> 00:33:44,960
It's not even far away.

819
00:33:45,960 --> 00:33:48,200
Yeah, so we are Ireland.

820
00:33:48,200 --> 00:33:49,720
America is officially Ireland.

821
00:33:50,680 --> 00:33:55,680
We're getting attacked by domestic terrorists.

822
00:33:56,040 --> 00:33:58,240
They took out our power grid for two days.

823
00:33:59,120 --> 00:34:02,360
Yep, let's talk about that another time.

824
00:34:02,360 --> 00:34:04,360
I don't know if AI is gonna help with that.

