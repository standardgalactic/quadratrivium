Go. So, lots of changes if you've been following the keg and the peg and stuff I've been doing over
the years. I went to bed last night with my head working on a bunch of problems. I woke up and I
just had an idea I had to finish and I've been working on it straight since, God, I don't know,
like eight o'clock this morning. It's somewhat related to work. Don't worry, I'll make up the
work time tomorrow and the next day and the next day, but this is really important because it's
so key to everything else that I'm doing. So, let me try to stick with the highlights
and hell, why don't I actually make a, use my YouTube thing. We're going to make a directory
for this. We'll call it updates on peg. Actually, let's call it something more specific than let's say
a peg in scanner interface and functions. So, what I've done
so I mentioned, I mentioned the other day that interface
and functions. Is that right? Peg and scanner interface and functions. Yeah, I mean,
and she'll have a tool to do all that. So, okay, so
so my my peg in scanner implementation now conforms
now conforms to a common peg in not scanner interface so that other scanners can be implemented.
My people that conform to it.
So, the reason that I made an interface, why an interface
so that the library of scanner functions of scan functions
can be interchangeable
with different scanner implementations. And if that's, that is the main reason.
And let me show you what I mean by that. So, if you go to, so this is all, by the way,
this is all I actually put in the thing related in here. So, here's the pages that
we're going to. We're going to HTTP, github.com, rdxrub, peg in, peg in dash spec.
And that's pretty much it. If you go there, you'll find everything.
It used to be that I had it all over the place. And I used to have, there's this,
there's peg in dot dev, but that's kind of, it's kind of older,
but a little older and out of date. So, it's still there. I'm reforming the spec as we go.
So, we want, okay, so let me, let me show you why. So, if we go to the peg in scanner itself here,
right? So, I mean, what is the end goal? The end goal is for us to be able to parse any kind
of language. And we started with base ML, or base MD. Now, you'll remember I was basic MD.
I was writing a basic MD scanner. And here is the, the, the, so this was all brought about because
of this. So, I'm just going to put all of this precipitated by the basic, basic MD, parser,
that I was right. I mean, a scanner, parser, AST. So, I started writing that last night.
And that was all good and everything. But it became clear to me that there, I mean,
some of these functions, I'm going to show you one, some of these functions that I have written,
I have written them so many times. I swear, I have written, so like, I don't know how many,
so I didn't, thank God I didn't post it to YouTube. I'm not going to force it on you.
But I did, I must have written a, you know, a white space or an end of line parser,
probably a dozen times, different ways. Because I don't have, I haven't had a standardized way
to abstract the scanner stuff in a way that didn't require rewriting a scanner. I mean,
I've written probably, including an extremely complicated one. If you go back in my YouTube
videos, there's something I was writing, it was called go, was it go, go compatible,
peg in expressions? And it was actually go code that could be passed into symbols,
that could be passed into another function that would parse it, and then it would, you know,
it would do its thing. It was pretty cool. But every time I've written one, and then the most
recent iteration of my scanner that I wrote, I just ripped all that crap out. I was like,
I want the ultimate and minimal. And thank God I did that because I actually ended up
coming up with, so here's an implementation of the new scanner interface
that anybody can write. And all it has is, I mean, some of this stuff is internal,
but you know, this, let me show you the interface first, actually. So let's start with the interface.
So the scanner interface is in my types. The scanner interface is just a scanner. It's a
rune scanner that is aware of the beginning and ending of each rune that it scans, which can
be more than one byte, right? So people know this. So you can imagine a cursor going, you know,
through the, through the screen like this, like with an emoji on there. And sometimes it's a thing.
So in fact, the scanner has this idea of a rune cursor. And I used, I mean, I thought with
myself about whether to call it cursor or not, I didn't end up keeping a concept of cursor here,
but I might find I had it embedded and everything. I don't want to get into it.
So ultimately, a scanner is, it's a bytes buffer. And this is another reason I put this in the
peg. So this thing, all of this used to be under rtbx-rob slash scan. I had my own rune scanner
in there. But I realized, and I'm going to put this in my conclusions. So I realized that,
that my rtbx-rob scan was actually very peg specific. And what I mean by that is that
so a couple of really important specific assumptions are made by peg. Peg assumes
that you have infinite memory, which is, you know, the polar opposite of parsing when you're
using anything that you would get out of the Dragon Booker and computer science class.
And so, I mean, that's a huge thing. So if someone comes across my scanner, they're going to say,
oh, a scanner, cool, you know, they'll make think it's a finite automata, you know,
single look ahead kind of scanner. And they, they're like, what the hell is this thing?
It just flipped my whole data source, you know, byte, byte buffer and into memory. I mean, that's,
that's like, that's like an unorthodox thing to do. That's a sacrilege in this. You know,
that's what peg does. So, so I realized that the scanner that I have built and been using the most
recent one, which I've used all over the place, I'm using it all over the place. I'm using it in
Bonsai and everything is actually, in fact, I think I just broke Bonsai by, no, I didn't.
Bonsai's got its own scanner, never mind. Anyway, so I went ahead and, and implemented,
and I actually also deprecated the other one by, because I moved the entire scanner
into the Pagan package or the Pagan, Pagan module, because why? Because it's Pagan centric.
It's Pagan centric because a Pagan centric scanner, you can't even use it unless you load up a buffer.
And, you know, that's completely unheard of in other circles. So, so that was the first major
thing. That did mean, however, though, that the, the other one that I have, which I'm leaving out
there, because I'm pretty sure I have some dependencies on this scanner. And it's also
listed in my awesome go list and things. And I have some pretty intense breaking changes that I
added to this since version 10, because I changed some of the internal references and everything.
And the more I got changing it, the more I, see right here, it says fulfills Pagan scanner face.
It actually doesn't do that anymore. I broke that when I was doing the move. And then this is the
most accurate thing. So I've moved this entire scanner over to RTX ROM Pagan. And it is, you know,
implemented as, under the types. Good night. So it's implemented in the type here,
under types, you can see the scanner is here. It gives you the cursor type and a scanner type.
And you can look it up and it has a mark going to go to and scan and to finish.
I mean, nothing fancy there, right? And then I implemented, they included, you know,
reference implementation of the scanner that I use for the Pagan stuff. And this gets me to
where I was going with base, basic marked, my basic markdown parser. So, so here we have Pagan,
we have, so this is, this is the exact code that was in this other place. That's just been moved
and cleaned up. And I mean, really cleaned up and had some, some other things added to it.
For example, the fulfillment of the interface so that it can be replaced with something else at
any time. And let me, let me talk to you about why I decided to make it an interface again.
I mean, I started talking about that. But if you go to, so here's the interface, but as I was working
on basic MD, I started realizing that parsing end of line and end of block and paragraphs and,
you know, all of these things that are listed in Pagan are things that I need to do all the time.
In fact, I just add it in paragraph, right? These are things that I already need all the time.
And I'm like, I've always have intended to write, I mean, I've been really kind of hung up on
creating a code generator for all of stuff that, so you write Pagan and you end up with different
types of code, right? But to be more practical, I've started realizing all I really need to do
is write a scanner function for each of these and then reuse them. And then the ones that I,
that aren't in Pagan, that are specific to basic markdown or whatever, I'm writing Keg or whatever,
I can actually write those using exactly the same function signature. And I could even put them in
packages, you know, as a collection of first class functions, because they all accept the scanner
interface. And that is, you know, that is go interfaces shining the brightest, right? Because
that's what's exactly what you want to do with it. So what does that mean? So I have the scanner
implementation here, and I can, I actually chose to make this implementation fast and abstract,
so that if somebody chose to use it, they could use the direct references to the byte buffers
and stuff like that, so they can bypass the indirection from the interface method calls,
which is the reason I didn't do it originally, right? If you look at the highest performance
parsers out there, they do not have a lot of functional indirection, right? It's actually
one of the biggest complaints I have about the current code generator for Pagan that Quint
mostly made, and I last two years ago, is it has a ton of function indirection in it. And that's
been something I've been kind of like, irrationally hung up on. And I think I finally hit the middle,
the middle of the road here. So this particular reference implementation, which is a part of
Pagan, comes with a struct that you can use directly if you want to, which I probably will
do and really quick and dirty, you know, I mean, not the quick and the quick and dirty stuff,
I'll probably will use the abstractions because they're easier to remember and you can just,
you know, you can just swap them in and out. I don't need performance, right? But if I'm like,
really want to make a low level, really intensely often, you know, parsed grammar, then I can go
ahead and bypass the use of those things as long as I don't want to reuse any of the stuff I've
already write in Pagan, which brought me to think, oh, damn, you know, let's say I make a,
here's, here's my work, my workflow. Okay, so my, I imagine the workflow of making a grammar
or something like this, right? So in fact, this is even in a slide at Brian Ford, Brian, I was
looking at Brian Ford's peg stuff, and he has this in a slide about, you know, traditional
thing, use Lex and Yak and blah, blah, blah, and, and then, but, you know, the pragmatic way
approach to doing parsing these days is to write, you know, a generic kind of specification and
then to write a recursive descent parser. It's the standard way, the practical way to do parsing.
And let's say I want to do that, right? So I want to write a grammar, but I want to write it
quickly. Now, the quickest way to do it would be to do cogeneration with, you know, from Pagan
notation, which is something I still want to do. That's nothing that Pagan, that Brian Ford ever
wanted to do. You kind of wanted to get away from it because he realized it was just, it's just as
fast to just write your own recursive descent functional parser and, and then be done with it.
You don't have to deal with all the intricacies of cogeneration, not being exactly what you want.
You just write it, right? And, and I'm kind of on board with that idea because, you know,
it's, it's quite a bit of work to get it to generate just the way you want to. And then
which, which cogeneration method do you want? Do you want it to be highly efficient? Do you want
it to be used functional so it can be easily maintained? Are you going to rerun the generator
every time? Is it just giving you the first version? And, and so at a certain point,
you kind of come to the conclusion that probably the fastest way to create a parser is to just
write the thing because then, you know, you're going to, you're, you're going to be done. You're
going to be done with it and you're going to be able to move on to other things. So, um, and,
and that's kind of where I am. So, uh, also realized, uh, fastest way to develop, uh,
parser is to write Pagan and then function and then scanners
functions for recursive descent. Uh,
I mean, it really is. So by the time, you know, you get all the thing, just writing the Pagan
itself is good. I mean, that kind of gets you thinking about how it's supposed to be implemented,
but you're also not wrestling with Pagan syntax and stuff, uh, in case you get it wrong. Now,
you should probably do that, but let's say you don't represent it perfectly and Pagan,
who cares? The Pagan is just there to help you understand what the parser is going to,
how it's going to behave. Um, and then you can, you know, compare it to that, you know, just,
just, you know, visually and get to your, get to your point, but you can get busy kind of writing
your parser. So, so, but, you know, along those, those lines, assuming that you're going to write
a parser, right? You're going to go ahead and write a parser. What are the obvious building
blocks? I mean, code generation is awesome and everything, but, but what, what would be the
other way to do this if you didn't have code generation? Well, it gets pretty obvious that
it would be a standardized library of scan functions, uh, that, that you regularly reuse,
right? And if you, as long as you make those export in your public, make those public, you can,
you can pull them in and you can tweak them and make them more efficient and other people can
contribute their own. And, and you have, you know, you ended up getting this ecosystem of scanners,
uh, of, you know, because that's really, the scanners are really the secret because if you
have a scanner, you can scan it and if it scans successfully and you would get a true at the
end of that. I mean, and this is very hastily, right? If at the end, if you get a true after that,
you're done. You're under the next thing. If you don't get a true, then you're guaranteed that
the scanner didn't do any advancement because it snapped back. And you're going to see this all
over in, in my implementation of functions, which we'll show you in a second, because that is how
you do this. And, and that is exactly how Brian Ford talks about it in his paper. It's like the
difference between, you know, the traditional scanner and, you know, parser kind of approach.
And this is that you can scan ahead as far as you want and you can keep track of how many
matches you have. So you can be very greedy if you want and say, okay, so did I find anything?
Yes, I found like 10 of them. And then I keep scanning and like, oh, hey, well, like, okay,
I stopped. So then I like roll back to the last one that was successful. Or if there were none
that were successful, I roll back the scanner all the way to the beginning. So, so this idea of
snapping the scanner back and moving it and around a thing, that's a very fundamental part of the PEG
architectural approach. Because you have memory, you have memory that you can fly around in. And
very quickly, by the way, I mean, you know, moving pointers around in memory is crazy, crazy fast.
And you've only had to do the one load. And so, you know, all these things that are doing like
single byte loads, in order to do that, you've already had to buffer your data at some point. So
you've already had to do the buffering. So, so the thing is cool about PEG is it assumes that
you're just going to buffer all of that upfront. And then you're going to break up your content
into manageable chunks that fit within, you know, reasonable amount of memory that you're
going to be parsing. You should put limitations in there and stuff. And that's a part of the grammar
design, which is another reason that PEG is a fail, because as wonderful as it is, it does not allow
you to put limitations and constraints on this size, which is why I made PEG in. So when I say
things like, I only want, you know, two end of lines here, I can specify two end of lines. There's
no way in the original PEG specification example to indicate amount, which I just think is crazy,
given the fact of, that regular expressions in ABNF have been doing it forever, and ABNF, but
PEG decided not to do that. So that's one of the reasons I made PEG in, because we clearly want
the combination of those things. All right, so let me go back to here. So I went ahead and I
implemented a white space function right now. I could have probably automated this, but let's
look at what it looks like. So if we go into the PEG and scan, and you're probably wondering, well,
why did you name it scan? Because I wanted it to read well. So let me show you the, the examples
here. These are go testable examples, and they are public. You'll remember maybe when I did basic
MD that I kept a bunch of my scanning, not public. I was like, because I didn't want people to become
dependent on my scanner functions, right? I mean, I'm just making a basic markdown part. So I don't
want people to be, you know, including my thing, because they want my specific implementations
of these. And that's one of the reasons I started thinking, hmm, I should probably think more deeply
about some of these scan functions that are going to be reusable. And I should probably put them
somewhere where they could easily be reused by me and others. And that's what got me to do this.
So I've created a convention called sum, which is just a nice happy way. It's like, you know,
go, they like have must and compile and things like that. So I created a convention where you
put sum in front. These are all documenting the design considerations on the read me page, by the
way. But sum means, you know, zero or more white space or one or more white space. So if I have
example sum WS, so, and then I the reason I named this sub package scan is so that we would get
these wonderful readable lines here scan dot sum white space and then pass in the scanner.
Now you might be asking as many, many people will tell you that have done scanners that
they implement the scanner as a class, which I think is disastrously bad architectural decision,
because you cannot do anything with it at all. And tell you expand the class,
that is the primary reason that people like Jim Copeland and others hate class based object
oriented programming. It is so concrete, you can never extend it, not without re implementing the
class or subclassing it by doing it this way. I can use first class functions is a very functional
approach. I can use first class functions if I want, I can use it from a package, whatever,
because the scanner is an argument to the function. And so as long as the scanner fulfills the
interface, this is why interfaces are king. This is why interfaces are part of solid,
even in modern Java development. If you're not doing this, if you're writing a scanner,
writing a class and extending the class with all of the different types and then having to do that
every time you're doing it wrong, in my opinion, because you're never going to be able to extend
that in any way that's going to be reusable for anybody. And maybe you don't care about that.
I do. I want it to be reusable. I want to, I want to create, ultimately, I want to build up,
you know, hundreds or more scan functions that can be used with anything whatsoever
that implements the scanner interface. And that's why interfaces are so amazing.
So I pass a scanner interface, I say scan some WS and I get a true or false. So this prints out
false because the first number is a one. Now I added a constructor. There's really not constructors
and go, but it's the closest word for it. And this takes an optional argument. Now constructors are
very, very high level. So they don't have to be performant, right? Especially since you're not
going to be buffering a lot. So I put an optional parameter to on the constructor. If you pass in
a string or a reader or a bytes buffer, any of those things, it will work. And it will just
slurp all of the thing into memory. And then it will allow the scanner to work on that, that bytes
buffer. And so then we do this to say, so, so you can see here, we, we, it's, you see, it was false
that it's not currently the scan WS failed here. Because why? And you'll notice too that it didn't
advance the, it didn't advance the, it's not supposed to. That actually looks like a mistake.
That might be a mistake. Let me check here. Oh, no, no, no, no. Okay, let's do this.
Wait, what? Advance to nothing at all output.
Example sum WS. I think I might have a problem with this one. Anyway, it's supposed to,
I just barely fixed these. That's why I want to make sure it's okay.
Sum WS. Is it not, isn't that working? I'm going to go try something. Go test,
run sum WS. Well, let's turn a trace on. Oh, this is cool. I finally got traced to working again.
So trace, that'll turn trace on. And when we run it, we should be able to see every step of the way.
So the first call to scan, got it. That's what with the first, that's every time,
every time scan gets called, it prints it. So scan, scan the one in, and that shows us the,
from between zero and one, and then what's left in the buffer and there's a space.
And then it shows we scanned a, a space and that was between one and two. It could be one and three,
depending on the size of the rune. And then as the buffer is empty. So, so that shows it's doing
what we wanted to, I just was, oh, I know why. It's doing that because it's actually, because
this actually did do some scanning and it did not reset. Actually, that's a, that's a, that's a
mistake. That's a mistake. I need to fix this. This, because it didn't scan, it should not have
advanced the buffer at all. It should have been, I've got to do this. This is a nice catch.
And again, this is just, this is the bug in this, in the scanner function only not the scanner itself.
Trace is internal. Trace is, Trace is a part of this scanner implementation. It's not part of
the forced interface. No, it's not. You don't have to have a scanner in there. It's, that's part
of this scanner implementation. So, you know, I don't want to burden people with those kind of
details that they, they want to do their own, they can, right? So, I mean, but yeah, you could
extend that and do what you want with it. So this is, this is actually wrong. This should have been
x00 and it should have been
zero to zero and then it should have been a one here. That's what it should be. And then when
you do the scan, it should go through and then it should have been a one and a zero to one.
And then, and then that should have left us with a space and it should have been false and then
it should have been true. This one should have probably printed true. Yeah. Something might
be wrong with that today. All right. So that, that's how it should look. So let's, that means
there's a problem with my function, my scan function, which is what I was debugging before,
but let me show you how to do this. So there may actually be a problem with my mark and I'm,
I'm hoping not to, I think, I think that might be, there might be something wrong with my mark,
which is relatively new. But the point is, I don't know if you saw the functions I was writing
yesterday, but these are way, way simpler, right? They just have to scan and check what the runes are
and scan again and the, the idiom is the same no matter what. You take a, you take a bookmark to
it at the beginning and you revert back to the bookmark if you're, if you didn't find anything,
right? And you leave things as they are. Otherwise you let the scanner happily proceed along
and it's not like there's a lot of cash in there so that you, you know, you'd have problems there.
But yeah, I have, I have a problem with this one. I got to come back to that. I can't see it right
out hand, but so this is actually, you know, this, this is supposed to scan as much white
space as possible. I think the problem is, I don't know, we might be getting ruined. I don't
know, I'll have to go debug this one. But if, if I wanted to just debug this one too, I could
also just do this. I could just do s.trace and turn on the tracing in here while I'm doing this
debugging. I can put it there in the test either way. Oh, it's not, that's right. I forgot about
that. Man, this is going to be interesting. Yeah. Cause you just said, is that in the, is that in the
debug output? Interesting. Yeah, I just realized I'm saying, because I locked down the interface
and I'm going to keep a bunch of stuff out of here. I'm not going to be able to do because,
because this is, expects a scanner interface and that means only things that are, are defined in
the scanner interface can, can turn on. I wonder if we should make trace into the part of the
interface. We should say you need to implement some form of activating trace. I don't think we
should. I mean, I think, I think we should leave that in the tests stuff because people can set up
their own test cases and then, and then call it that way. I, I, I don't know. I thought about it
for a second though. This is just as good, right? Having the trace appear. Because this is, is, is
using a specific scanner that fulfills the, the interface and therefore it can have extra things
in it like trace. The other one doesn't have anything, any knowledge of it at all. And it
shouldn't, right? We don't, that's again, I want to, I want to double check that everybody understands
this. So we do not want people writing, you know, Pagan or any
scanners functions that are going to be doing fancy things that are not defined by the interface.
Because if you do, then they won't work with interchangeably with other scanners.
And that, that's not ideal, right? We want to be able to have people write
very highly optimized scanners however they want. I mean, all of them obviously are going to have the,
the downside of having to call out to a function to do their thing. But that's,
it's not too bad. But that way people can supplement the scanner that I've made or make
their own or something like that. And they can, they can share all of these scan functions with
each other. And we can make libraries of scan functions that do different amazing things. So
it's basically like creating a library of regular expressions. And if you look at
the Pagan stuff that I've been doing, you can see that we've got a lot of functions to write.
So over the next year or two, I'll be implementing individual scan functions
for the different types of stuff that is included here and in our tokens. And yes, we're going to
have, we're going to have functions for things that are strictly static. And the reason is that
is to keep everything functional because we need to be able to pass the scanner to it, right?
We don't, if we didn't do that, we would have different kinds of dependencies. We would have
dependencies on the Pagan like implementation to some degree, I think. And so that, I mean,
it's not that much extra. Before I was like calling out to a function just to parse the
references to the other functions. So there is, it's not going to be any less performant than
any of the other stuff. And that's really premature optimization. If somebody really,
really, really wants that level of performance, they probably should write their own scanner and,
and, you know, maybe just use some of the scan functions without, without it and not, and not
bibbed. So, but I will be writing like, I'll probably be auto generating a bunch of go code to,
to, you know, to, to, to, to stand for each one of these, these scan functions. And then they'll
all be under scan dot whatever. So I'll be able to just on any project, just be able to import
artifacts, Rob slash Pagan slash scan, and I can get any and all of these that I want.
And it's not that big, actually, because it's just text parsing, right? It, it seems big because
it's a lot of code for us to write, but it, but it's most of it's going to get inlined and the
size of the package isn't going to be too big. And, and then we can, we get kind of like this
regular expression engine that's on steroids, because now we can just write our own recursive
descent parsers as easily or if not easier than we could write regex, you know, complex
regex expressions. And that, that to me is kind of the Holy Grail, because that's what I want to do.
I, I have like four or five grammars that I want to finish that I'm kind of waiting on.
And this is, that's, that's where, that's where it leaves us. All right. So I need to come back
and fix this white space one. Let's go back and look at one that maybe works better. So
here we have, and I put the pagan line up here. So an end of the line is, you know,
we scan the found Boolean stuff. We don't really need that. I could have just done a return right
here and call it a day and not gotten all the way down here. And the reason I didn't do that
initially is because I wanted to think about how this code could be auto generated. But
now that I'm looking at it, I am totally okay doing that. So, so we can just do a return true there.
Here we can just do a return true. Yeah. And if we make it down this far,
that means we didn't find it. And we need to do that. So that this is, this is not hungry.
If you're using something that's hungry. Yeah, you might, you might have a different problem,
right? Because, you know, you need to, yeah, you need to, if you're having something that's like
hungry and greedy, you need to like count all the fines and you'll see that, you'll see that kind
of thing happening over time. Oopsie, did I refer to found in here? Return false. So I mean,
that's a simplification we can do. Again, these are, I want these to be highly optimized. Another
reason, by the way, that I think code generation is probably the wrong way to go. And the more I
keep coming back to this, the more I think that hand crafting a recursive descent parser from a huge
library of existing scanners, scan scan functions is a better idea. Because of this problem that you
just saw, the optimization I just made is the kind of thing that would take an extreme amount of
intelligence in the code to be able to write it in a code generator. Whereas if I'm just writing
the parser, I can take, I can do tricks and stuff inside of my functional parser to make it really,
really optimized for this particular scenario, you know, and, and I can do things that couldn't be
done if I were to just to generalize the generation of this code from the syntax. So what I'm saying,
and I'm going to put this in here is that I am, I'm kind of souring on the idea of code generation.
So I'm souring on the idea of Pagan to code generation, because it's removing, you know,
it, it, it prevents, it precludes optimizations that only, that only a person could do.
And, you know, people definitely do this. And if you're going to, I mean, at the end of the day,
we're writing a compiler when we do that kind of thing. And, you know, there are people that have
spent their entire lives dedicated to compiler optimizations. Well, one of the reasons that
having a human write a scan function is better is because depending on the language they're writing
it for, they might already know how the compiler is going to inline that code. So, so, you know,
having some generic size rendering of the code may not be able to take advantage of those things.
And, you know, premature optimization, yes, right, we want to avoid premature optimization, but,
but at the same time, we don't want to be forced into doing things that, that we could do
because we know about them later on. We could come back to the code
and we could actually say, well, okay, let's optimize this one, because this is that my
pagan function for parsing, you know, wide space, the most important thing that I'm ever going to
write, it's going to be used by millions of people or whatever. And, and I should really,
really optimize that one function. And then everybody can spend their time optimizing the
functions that we have for parsing those specific things. And we can maintain a community library
of this, rather than having everybody write the best, you know, their own wide space parser,
right? So we can actually have a collective community of contributions that from people
who know about parsing, or really, you know, amazing Go specialists who have, have, you know,
know how to optimize code based on what they're, what they know about inlining. So, so yeah,
no more code generation, just a lot of pre-generated libraries that are immediately importable.
And then we can just write, you know, in if statements and switch statements, and you can
write your own thing really quickly. And I think that's really going to be the new normal
useful form overlooks. Yeah. And so, so, so yeah, I think, I think, I think that that's,
that's kind of how I am with this. That is why you're developing anything. Yeah. I, I, I think
that the code generation thing, I mean, this doesn't mean we're not going to do some code
generation, right? But we're going to statefully code generate like all the functions for the,
the 200 or so Unicode classes, which by the way, already have functions. Yeah. So for those kind
of things, we're just, that's exactly how Go does it, by the way. Go takes that document,
and it generates the Go code from straight up from the, from the Unicode specification document.
And it has a, you know, a whole library of, of, you know, true or false kind of things, right?
But it's not a scanner. And so the only thing we're going to have to do in the Go one is
basically the same idea, but we're going to say, okay, is this thing a thing? And then,
and then we'll make a sum variation as well, so that it'll be like one or more of those things,
right? And, and all that code will get auto generated. So we'll have a pretty big library
of scanners that'll be developed that you can then make your recursive descent
parsers from. And maybe we can get somebody else to actually think it's a good idea besides me.
Optimizing a lot first is that you can find you don't need the functions you're optimizing. No,
that's right. So I'm saying, so a lot of them, yeah, you could combine the two things together
or something, right? Yeah. So, so I think, I think I'm kind of happy with this where we're
going with this now. Now I still have this, this bug here, my white space bug. But the other one
is fine. Let's, let's try to run that one. Let's do run. What was it the end of line? End of line,
I think, right? Oops, we need to let's turn scanning on end of line. So you can see it
end line. Then there's lots of in lines. So she was the carriage feed one. Actually,
let's just turn it on for the whole, the whole scanner. Yeah, scanner scanner has a trace for
the whole entire package if you want to turn tracing on on everything.
Yeah. Trace equals, I'm probably have to do an init here. Trace equals one.
Yeah, that's going to say you need to put that in an init. All right, fine.
This is just for now. There's other testing ways to do this, but I'll just do that for now.
So we could go test. So actually, this is going to show every single parts that we did.
I'm so happy with this. So when you turn the trace on, when you turn it on this way,
it'll actually give you like the full thing. So here it was, it was, it, it read the first
carriage return and then a line return and then another line return. So that, that was that one
that we did. And there's another one. So these are all the different ones. There's no other printing
statements going on in there, but you can kind of watch what's getting parsed as you go
and check on it. And you can go, go look at that and see if you like it.
But yeah, I mean, it's working without that portal pass. I just got that white space one
I have to figure out. So I think that's enough for this video. I just, I just wanted to show
where I was. Some of the, I mean, I don't got the, the, the end paragraph turns out to be end block.
So remember yesterday I was doing basic markdown and I was like, hmm, we need to
delineate our blocks. Well, what is, what do we have? We have any number of spaces
and then a greedy include of, of white space and line returns, you know, and that's what this is.
So I had to actually re, I had to rewrite it and say, do I have the end of,
do I have the end of the data? Do I have an end of line and then the end of the data?
Or do I have two end of lines, which are, you know, the greedy thing and then the white space
splat and, you know, peg, uh, repeat operators are greedy by default. So that says, grab as
much white space as you can. As far as I know, I might have that wrong, but grab as much white
space as you can and then make sure you have this at the end, right? Now it may be that I have to,
uh, uh, if I were to put this up here in the front, then it would be non greedy. So it would
it would get, you know, it would, it would get the first one. So the first match of,
I had that happening before I had the first match of, of a line of double line returns
and it got the first one. So that's how you, you do non greedy is you put that stuff up in front
here, but you have to kind of look at the peg and syntax, the peg syntax to get that. That's,
that's from Brian Ford. That's not for me. Uh, but, and I still have to go look it up here as well.
But it's, I, once you get it, it's much easier than regular expressions. It's not,
actually it has positive negative look ahead and all that kind of thing,
which regular expressions, depending on which engine you're using, don't really do well.
Not to mention, you know, the ability to capture thing. So, and, and I use the,
I use the block here and go to, uh, which I actually prefer to for loops because
they just are so much cleaner. Um, because you just know you're going to go up to the top again
and you know, you know, the thing I like about it's much easier. I mean, it's much harder to
write an infinite loop with a labeled block than it is with an infinite forever loop,
which is just for, and I used to do them that way. Um, because, I mean, you definitely can,
but you have to explicitly create an infinite loop that keeps going to the top again, right? So,
it's kind of like a do while. Um, and you see this all the time in parsers. This is in go, it's in,
and goes compiler for the language that go to is a very real, uh, solid thing to use for,
uh, for compilers and for parsers and scanners. And it saves you from any kind of functional
recursion, which is the devil when it comes to performance and parsers because you hit, you hit,
um, you hit, you know, you hit, uh, indirection functional loops, uh, functional recursion loops
and stuff like that. Some languages is the preferred way to do it, but, but, but most
of the languages or not, most of them want you to just stay within there and kind of
figure out a way to short circuit and go back up to the top. And it's more performant that way too.
So this one has to have the whole notion of a found Boolean in it because even if I find one,
I still want to look for more. I still keep wanting to look for more until I get,
I'm greedily get the, the last one, right? And I, before I added a notion of a, of a found loop in
that I, I wasn't getting everything. And so what it does is it keeps getting stuff until it hits
something that is not valid. And it's like, okay, I finally run out, but did I ever find anything
along the way? I was like, Oh yeah. Okay. Well, what was the last one that I did find? And, and then,
you know, it can, it can tell you that thing. Um, and, and that's what the go to is. Um, this is
actually wrong. I'm just realizing I have some problems with this. Yeah. It's funny because
now that it's cleaner and I've got to spend my whole day fixing up all of this syntax, I can see
that this is probably wrong because this is, this is going to, uh, this is, if it, if, oh no, no,
I'm sorry. No, I'm, I'm sorry. This is only if it's not found. Yeah. This is only if it's not
found. Yeah. So scanners do not advance. So the rule, this is a kind of a hard thing to,
to come up with when you're trying to figure out how to make your parsers and functions and stuff.
But the easiest rule is for a scanner is if it scans, it returns true and it advances the scanner.
If it doesn't to the next thing, right to the beginning of the next thing, it doesn't scan
that thing. It puts it right to the beginning of it. If it doesn't, if it doesn't scan anything,
it needs to leave the scanner exactly how it was before it was called. And in order to accomplish
that, you need to take a bookmark so that you can snap back to it, right? And I put go to here,
I could probably do snap, but that would people think I would snap the shouting or whatever,
go to use the one I'm going to use there. So, so that actually sets it to the cursor and the
cursor is three things. It's the byte index in the buffer by buffer array of the, uh, you know,
of, of the first item in, in the room, the first bite of the room. Uh, it is the room itself,
a copy of the room. That's what, that's what we get when we set, when we get, when we get,
go get dot rune. Um, and, and it is, um, it's also the, uh, uh, the, the, the, uh, end, the end of
the room. So the, the byte pointing to the byte array to the beginning of the next thing, which is
like maybe one or two, three things away. And that's, that's, that's where we got this thing.
So we get like a three to four. If, if I were to scan like, uh, uh, tomato emoji, um, and I
don't know where to go back to mark point, if it found the end of paragraph, it considers it advanced
and no more go back to mark the point. You don't need to mark the point because the scan automatically
advanced it. Yeah. Because any of the scans that fail, I'm pretty sure I'm gonna have to go back
but there, there are cases, uh, uh, yeah, I read that. I have that book. I wrote that years ago,
a couple of years ago. I have the PDF somewhere. Yeah, actually bought it. Uh, it's, there's that,
there's that one. There's two or three go scanners in the go code base. And then there's a website
that has right your own, uh, scanner and go. There's like, those are the three main things
that I'd recommend if you want to start doing this kind of fun stuff. Um, but yeah, they're,
they're pretty cool. Um, and you know, I'm obsessed with parsing. I'm not very good at it,
but I'm obsessed with it. So, so anyway, um, mostly I'm obsessed with language and so
grammars are a part of language and that's why I like it so much. Um, this is something I don't
understand. What I want to do is I want to be able to specify my bonsai command lines from a pagan.
Wouldn't that be cool? Uh, there, there, there is a writing compilers. Oh really?
Yeah. I have to go look at that one. Um, so, so yeah, I mean a compiler is the next step,
right? It's like bringing it all together and doing something with the thing you get out of it.
And we, we don't have any AST, any notions of AST going on yet. That is coming. Uh, I already
have all the data structures for that developed that I'm going to use for my AST. Um, and,
but yeah. So, you know, you got to have push and pop for ASTs. It's like crazy. Um,
yeah. I mean the hardest part, the hardest part with the AST, and we're going to get into this,
is how to throw away, uh, elements of the tree that you, you can't just pop back and kind of,
you know, you can't just pop back to the latest bookmark when you're doing parsing because you
have all this data that you parse that you can't throw away. And it's very complicated. You can't
throw it away because you don't know how much of it to throw away. And, and that's, that's going to
be a big piece of this that might, that might, you know, I still have other things to do. This
isn't my main, my main thing. So, uh, but I, I am interested in this. Um, so far the test case on
this is so good, so important that you have lots of test cases on this. I'm pretty sure this one
is good. Um, but I don't know, we'll go take a look at it later. And, and, and you know, that,
but I, here's the thing, I don't want to have to keep revising all of my parsers. I wrote,
I mean, I, I, I'm going to go back and open up my old pagan, uh, dev, uh,
you know, I wrote an entire recursive descent parser for the pagan language itself, if I have them.
Uh, and so that's going to be something that we're going to come up with later, but, um,
but, but so I don't, I don't, I don't know, I don't know how that's going to,
that's going to end up going down. Uh, because I, I want to be able to pull out some of that
stuff from here and just reuse it because I, I've already got all the algorithms there and I can
just reuse those algorithms. So that's pretty much it for YouTube. So if you want to stay tuned and
to watch stuff about the pagan and keg stuff, uh, I'm probably not going to be working on much of
this. I hopefully not the rest of this week. I have got a ton of work to catch up on, uh, that
I'll be doing like for the rest of tonight and tomorrow morning early and, um, and we'll be,
yeah, I'm going to be doing, you know, a lot of that stuff. Um, but this is sort of related to
stuff we want to do at work in terms of like documentation validation. That's where it
came from originally. And that's, if you want to stay tuned, we, we'll do some more of that. I,
I am going to implement basic and D M D is, uh, as a, as a grammar and I'm going to be using this
and we should get pretty high performance on it actually. Uh, we should have performance that
rivals gold mark, uh, which because it doesn't have as much to do. Uh, so we should have performance
that rivals gold mark, which is pretty much the go to standard for, uh, markdown parsing and go
right now. And we'll be able to compare and do some benchmarks on that a little bit later.
Um, so have fun parsing and come on by sometime. Talk to you later.
