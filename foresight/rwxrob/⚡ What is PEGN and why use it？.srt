1
00:00:00,000 --> 00:00:03,600
So, what is Pagan and why use it?

2
00:00:03,600 --> 00:00:07,960
So Pagan, I've talked about this a lot, but I'm going to go through and review it again.

3
00:00:07,960 --> 00:00:14,120
So Pagan is a language that I wrote, you can go to pagan.dev, I think I still have that

4
00:00:14,120 --> 00:00:15,120
up there.

5
00:00:15,120 --> 00:00:19,880
I've been using it a lot because I'm using Pagan to write KML.

6
00:00:19,880 --> 00:00:23,760
Sometimes you need a language to write a language, it's called a meta language, and that's what

7
00:00:23,760 --> 00:00:25,160
Pagan is, you can go here and read about it.

8
00:00:25,160 --> 00:00:29,140
So Pagan is a language for defining languages, more precisely as universal notation for expressing

9
00:00:29,140 --> 00:00:33,620
any grammar, including natural language, which I'm very proud of, in a way that is easy

10
00:00:33,620 --> 00:00:37,100
to parse cognitively and programmatically without any specific application or implementation

11
00:00:37,100 --> 00:00:38,420
in mind.

12
00:00:38,420 --> 00:00:44,820
And this is the problem with Pagan, which is from Brian Ford, which I'll get to.

13
00:00:44,820 --> 00:00:50,300
Pagan builds on the best of the existing meta data structures such as Pagan, ABNF, EBNF,

14
00:00:50,300 --> 00:00:51,300
and JSON.

15
00:00:51,300 --> 00:00:54,460
If you've ever read the GoLang specification, it's all an EBNF, it's very common for people

16
00:00:54,460 --> 00:00:58,980
to write language specifications, an EBNF, it's more common to see ABNF for things like

17
00:00:59,820 --> 00:01:04,100
Internet IRFCs and IRFCs, things like that.

18
00:01:04,100 --> 00:01:08,700
But ABNF, you can't even use characters in it, you have to use hexadecimal notation for

19
00:01:08,700 --> 00:01:10,740
everything, just because it's so precise.

20
00:01:10,740 --> 00:01:13,700
It's like, how do I define the HTTP protocol?

21
00:01:13,700 --> 00:01:15,100
Go read ABNF for that.

22
00:01:15,100 --> 00:01:20,420
Now, ABNF allows ranges and stuff like that, Pagan does not do that, Pagan is a very, very

23
00:01:20,420 --> 00:01:28,380
friendly kind of flying in the face of traditional parsing mentality, primarily by saying we

24
00:01:28,380 --> 00:01:33,660
have infinite memory in our assumption, our base assumption, rather than saying we only

25
00:01:33,660 --> 00:01:37,020
have one byte of memory, which is what all the other parsers do.

26
00:01:37,020 --> 00:01:41,700
I am absolutely obsessed with parsing, I think it's so fun.

27
00:01:41,700 --> 00:01:45,780
If I was going to have done a computer science thing, I would have really, really obsessed

28
00:01:45,780 --> 00:01:46,780
about parsing.

29
00:01:46,780 --> 00:01:51,260
And I've already written in Pagan parser some time ago, a couple years back, and we've

30
00:01:51,260 --> 00:01:56,140
had lots of people use Pagan, Quint comes to mind, Quint, if you're out there, thank

31
00:01:56,140 --> 00:01:57,140
you for your contributions.

32
00:01:57,260 --> 00:02:02,620
Quint has actually got his Pagan parser that we kind of collaborated on running in production

33
00:02:02,620 --> 00:02:08,500
for a rather large company that I won't say.

34
00:02:08,500 --> 00:02:12,020
But it is a way of specifying languages, and so what does that actually mean?

35
00:02:12,020 --> 00:02:15,540
So the motivation here, let me just keep reading here, and then I'll close this up.

36
00:02:15,540 --> 00:02:19,660
So the motivation, technology increases complexity, the need for a better human-computer interaction

37
00:02:19,660 --> 00:02:24,140
becomes more pronounced, creating language grammars quickly and simply has become a critical

38
00:02:24,140 --> 00:02:25,140
need.

39
00:02:25,140 --> 00:02:29,100
And there's something that I have found out recently has got the name Fluid APIs, and

40
00:02:29,100 --> 00:02:30,860
that's why I made Bonsai.

41
00:02:30,860 --> 00:02:35,500
So Bonsai defines a natural language API that could be spoken on the command line as opposed

42
00:02:35,500 --> 00:02:40,340
to demanding dashes and get off and all that other crap, which is another project I made

43
00:02:40,340 --> 00:02:41,340
related to this.

44
00:02:41,340 --> 00:02:45,940
But Pagan is somewhat related to the same need, because we need a way to define domain-specific

45
00:02:45,940 --> 00:02:47,540
languages very quickly.

46
00:02:47,540 --> 00:02:51,500
The way that I learned about Pagan, quite frankly, yet again, TJ Hollowaycheck, I was

47
00:02:51,500 --> 00:02:57,340
following him and he wrote his own domain-specific language for parsing and querying logs for

48
00:02:57,340 --> 00:03:02,580
his APEX, one of his projects on his APEX company, and he used Pagan for that.

49
00:03:02,580 --> 00:03:08,580
And so I found Pagan, I actually helped contribute to one of the GoPeg parsers that's out there,

50
00:03:08,580 --> 00:03:11,580
and then I realized that it didn't have enough, and I needed to add a little bit more, and

51
00:03:11,580 --> 00:03:13,620
so I made Pagan.

52
00:03:13,620 --> 00:03:16,980
So Pagan has decided to keep things by allowing any data to be represented as a grammar and

53
00:03:16,980 --> 00:03:20,900
breaking it down into universal data form, it can be composed, combined, and analyzed

54
00:03:20,900 --> 00:03:21,900
in a remarkable way.

55
00:03:21,900 --> 00:03:28,900
So my eventual dream is to allow Pagan notation to replace regular expressions.

56
00:03:28,900 --> 00:03:34,380
Regular expressions are nice and all, but when it comes to structured data and the ASTs

57
00:03:34,380 --> 00:03:36,380
that are produced by it, it was really, really problematic.

58
00:03:36,380 --> 00:03:39,140
Whether it be simple counting all the words in a document, creating a simple query language

59
00:03:39,140 --> 00:03:44,060
to make searching logs easier, coding a human-friendly interface to an otherwise complicated web

60
00:03:44,060 --> 00:03:50,020
API, simplifying the parsing of a form of common markup, implementing a fully-programmed

61
00:03:50,020 --> 00:03:53,900
language that leverages LVM to quickly create high-performance compilers, or developing a

62
00:03:53,900 --> 00:03:57,340
binary language for moisture evaporators, ah, Star Wars joke.

63
00:03:57,340 --> 00:04:00,580
Pagan addresses these issues by prioritizing the creation of other language grammars without

64
00:04:00,580 --> 00:04:04,780
weighing them down with any specific bias, and I keep hitting that point because that's

65
00:04:04,780 --> 00:04:08,780
why all of the Pagan parsers that are out there right now, Guido van Rosen, Pagan of

66
00:04:08,780 --> 00:04:13,140
the Python creator, obsessed with Pagan, there's lots of videos from him trying to re-implement

67
00:04:13,140 --> 00:04:14,740
the entire grammar of Python and Pagan.

68
00:04:14,740 --> 00:04:19,420
I don't know if he ever made it through that or not, but lots and lots of implementations

69
00:04:19,420 --> 00:04:24,460
of Pagan that forced you to use that specific language, and so Pagan, the N in Pagan stands

70
00:04:24,460 --> 00:04:27,020
for notation, which means we don't care.

71
00:04:27,020 --> 00:04:33,380
It means we are not associated with any specific language, and therefore it's universal.

72
00:04:33,380 --> 00:04:36,940
It's now, and see, Python, is it okay?

73
00:04:36,940 --> 00:04:38,380
Weighing it down is specific bias commitment.

74
00:04:38,380 --> 00:04:43,580
In fact, Pagan is so flexible it can also be used to define written language as a music

75
00:04:43,580 --> 00:04:44,580
notation.

76
00:04:44,580 --> 00:04:49,100
Pagan grammars are exploding, but inconsistent in 2004, Pagan grammars have exploded in popularity

77
00:04:49,660 --> 00:04:50,780
and that's when I started this.

78
00:04:50,780 --> 00:04:52,940
God, that was, I mean, that's not true.

79
00:04:52,940 --> 00:04:55,540
I started, that's when they came become popular.

80
00:04:55,540 --> 00:04:58,500
I didn't get into it and probably tell, I want to say 2020.

81
00:04:58,500 --> 00:05:01,180
I was already streaming, so it'd be like 2021, 20.

82
00:05:01,180 --> 00:05:06,100
Anyway, Brian Ford's example, Pagan grammar is all but ignored.

83
00:05:06,100 --> 00:05:07,940
It's also incorrect.

84
00:05:07,940 --> 00:05:11,580
While we were going through the parsing of his example, we realized it violates his own

85
00:05:11,580 --> 00:05:13,380
syntax.

86
00:05:13,380 --> 00:05:15,380
I still haven't ever told Brian that.

87
00:05:15,380 --> 00:05:20,740
His example is invalid, Peg, according to his own specification.

88
00:05:20,740 --> 00:05:24,620
I don't think he actually ever tested it with a parser or anything.

89
00:05:24,620 --> 00:05:29,500
We actually found that out very surprisingly, quit when we were going through making our

90
00:05:29,500 --> 00:05:32,260
own parser, and we use this example.

91
00:05:32,260 --> 00:05:35,060
So Brian Ford's example, Pagan grammar is all but ignored as people continue to build

92
00:05:35,060 --> 00:05:37,500
on their own syntax as a very little resemblance to the original.

93
00:05:37,500 --> 00:05:40,420
I think that's probably why it doesn't work, because he just threw it in there because

94
00:05:40,420 --> 00:05:43,380
everyone else has got their own idea of what it should be.

95
00:05:43,380 --> 00:05:45,140
There are more implementation code than Peg.

96
00:05:45,140 --> 00:05:49,020
This is demonstrated by many projects that contain both a grammar file for becoming acquainted

97
00:05:49,020 --> 00:05:52,780
with the syntax and another virtually identical file containing additional implementation

98
00:05:52,780 --> 00:05:55,700
specific to the code, a specific implementation language.

99
00:05:55,700 --> 00:05:57,500
So this is how it goes, right?

100
00:05:57,500 --> 00:06:05,180
You run your code through this and through the parser, right?

101
00:06:05,180 --> 00:06:09,540
And then the parser will actually, if you do a Peg parser, right, it'll actually generate

102
00:06:09,540 --> 00:06:10,540
code for you.

103
00:06:10,540 --> 00:06:14,420
It'll generate parser code in your target language, and, you know, like Lex and Yak

104
00:06:14,420 --> 00:06:17,380
and all those other things, except for its much more modern approach.

105
00:06:17,380 --> 00:06:21,740
And so there's lots of them out there, you can go look at them.

106
00:06:21,740 --> 00:06:25,740
So anyway, this redundancy and specialization are not only less sustainable, but they're

107
00:06:25,740 --> 00:06:30,180
also highly rigid and counterproductive, and you can't exchange them with anybody else.

108
00:06:30,180 --> 00:06:33,900
Pagan is a language grammar specification that does not allow implementation code so

109
00:06:33,900 --> 00:06:37,580
that the resulting grammar specifications stand on their own, allowing their creation

110
00:06:37,580 --> 00:06:41,780
of any variety of lunches and co-generators in different language implementations.

111
00:06:41,780 --> 00:06:47,340
Even different design variations in the same implementation language, AST, callbacks, etc.

112
00:06:47,340 --> 00:06:55,100
I'm going to get there, but Pagan actually defines the AST format as well, which is not

113
00:06:55,100 --> 00:06:58,300
included in any other thing.

114
00:06:58,300 --> 00:07:04,260
So I mean, having the AST, which is, you know, the thing that you care about when you run

115
00:07:04,260 --> 00:07:09,700
some code through a parser, you want the AST then so you can check for the syntax properly,

116
00:07:09,700 --> 00:07:13,580
or you can, you know, create your compile in any number of ways, or you can transpile

117
00:07:13,580 --> 00:07:14,580
or whatever.

118
00:07:14,580 --> 00:07:15,580
You have to have an AST.

119
00:07:15,580 --> 00:07:21,380
I mean, there are implementations that don't use an AST because it takes, it's a minimally,

120
00:07:21,380 --> 00:07:23,300
you know, slower to do that.

121
00:07:23,300 --> 00:07:25,860
That's the compile part of regular expressions, by the way.

122
00:07:25,860 --> 00:07:29,980
When you say you have to compile a regular expression, you're pretty much building a binary

123
00:07:29,980 --> 00:07:33,180
that's going to give you an internal AST really quickly.

124
00:07:33,180 --> 00:07:34,780
And then, you know, it's kind of internal.

125
00:07:34,780 --> 00:07:37,700
I don't even know if there's an AST for most regular expressions, actually.

126
00:07:37,700 --> 00:07:41,900
But these days you want the AST because that's the thing that's going to give it to you.

127
00:07:41,900 --> 00:07:46,500
So like if you do, if you do pandoc, let's say you take, pandoc actually has this built

128
00:07:46,500 --> 00:07:52,500
in, you can do pandoc t, is it raw?

129
00:07:52,500 --> 00:07:54,140
You can do JSON if you want.

130
00:07:54,140 --> 00:07:58,780
So JSON, this is a representation of this document in an AST.

131
00:07:58,780 --> 00:08:00,700
It's a very simple document, right?

132
00:08:00,700 --> 00:08:06,420
And it's parsed using pandoc with the specification for markdown, pandoc markdown.

133
00:08:06,420 --> 00:08:09,540
And this is the resulting JSON version of the AST.

134
00:08:09,540 --> 00:08:11,180
Now, there's another one.

135
00:08:11,180 --> 00:08:14,540
I don't know the name of it.

136
00:08:14,540 --> 00:08:15,540
Is it dead?

137
00:08:15,540 --> 00:08:18,380
I don't know what the name of it is.

138
00:08:18,380 --> 00:08:19,380
I want to say raw.

139
00:08:19,380 --> 00:08:20,380
Maybe it's data.

140
00:08:20,380 --> 00:08:24,820
It might be AST, data.

141
00:08:24,820 --> 00:08:26,420
I wish pandoc had completion.

142
00:08:26,420 --> 00:08:27,420
It does not have completion.

143
00:08:27,420 --> 00:08:29,140
There's another number of reasons I don't like it.

144
00:08:29,140 --> 00:08:30,620
Oh wait, maybe it does have completion.

145
00:08:30,620 --> 00:08:32,140
When did it add it?

146
00:08:32,140 --> 00:08:35,300
Maybe it already said, I always had it, I just forgot.

147
00:08:35,300 --> 00:08:36,300
Which is the one we want.

148
00:08:36,300 --> 00:08:43,500
We want not GFM, we want not LaTeX native.

149
00:08:43,500 --> 00:08:44,500
There we go.

150
00:08:44,500 --> 00:08:53,620
So this is the internal Haskell AST that is used by pandoc.

151
00:08:53,620 --> 00:08:59,460
So it tells you the thing, so you have a header, and then you have a string, and then

152
00:08:59,460 --> 00:09:03,060
another string, space, space, string, space, string, space, space.

153
00:09:03,060 --> 00:09:06,140
So this is Haskell is the perfect language for writing ASTs.

154
00:09:06,140 --> 00:09:11,660
I want you to notice something here that all of the nodes that are parsed in the AST

155
00:09:11,660 --> 00:09:12,820
have three elements to them.

156
00:09:12,820 --> 00:09:16,620
They have the type.

157
00:09:16,620 --> 00:09:22,660
I think they have an array of how many there are, and then they have the actual content.

158
00:09:22,660 --> 00:09:23,660
I can't remember.

159
00:09:23,660 --> 00:09:25,460
Oh no, no, that's a variation on a header.

160
00:09:25,460 --> 00:09:27,240
It must be an attribute of it, whatever.

161
00:09:27,240 --> 00:09:31,500
So that's the AST, and you need an AST if you're going to do anything.

162
00:09:31,500 --> 00:09:34,180
It's a Haskell data representation, yeah.

163
00:09:34,180 --> 00:09:40,500
This is a Haskell data representation of, and I don't know, they have nodes with attributes

164
00:09:40,500 --> 00:09:41,740
which I hate.

165
00:09:41,740 --> 00:09:47,140
So Pagan does not allow attributes for a reason.

166
00:09:47,140 --> 00:09:49,940
You can never decide whether you want your node to have attributes or not, or you want

167
00:09:49,940 --> 00:09:52,860
it to just have the attributes to just be subnodes.

168
00:09:52,860 --> 00:09:54,460
And so Pagan doesn't allow that.

169
00:09:54,460 --> 00:10:02,500
It's a pretty deep comment, and if you don't know about parsers and stuff, but it's really

170
00:10:02,500 --> 00:10:03,500
a...

171
00:10:03,500 --> 00:10:04,500
ASTs are all over the place, by the way.

172
00:10:04,500 --> 00:10:07,660
If you go look at the web page, this is an AST.

173
00:10:07,660 --> 00:10:08,660
This is an A...

174
00:10:08,660 --> 00:10:11,460
Any time you look at this, this is an AST.

175
00:10:11,460 --> 00:10:17,400
The reason node is called node is because the document object model is a specification

176
00:10:17,400 --> 00:10:18,940
of how to parse the thing.

177
00:10:18,940 --> 00:10:22,060
That was at one point defined through something else.

178
00:10:22,060 --> 00:10:24,700
It can get tricky without properties and attributes.

179
00:10:24,700 --> 00:10:29,540
I haven't had any problem with it so far because you can just define...

180
00:10:29,540 --> 00:10:32,100
You don't want to have one type have a different attribute to it.

181
00:10:32,100 --> 00:10:39,500
I mean, like H1, H2, H3, you can actually have a parent, and then you can have the child

182
00:10:39,500 --> 00:10:40,500
be the attribute.

183
00:10:40,500 --> 00:10:45,620
It does get a little bit harder to traverse it, but it can be done.

184
00:10:45,620 --> 00:10:53,580
So anyway, Pagan doesn't allow for properties like that, and neither does Peg, actually.

185
00:10:53,580 --> 00:10:59,180
Strictly speaking, though, I mean, you could use Peg or Pagan, and then just...

186
00:10:59,180 --> 00:11:01,340
I mean, the AST is...

187
00:11:01,340 --> 00:11:06,300
You could use your own AST instead of the one that I have in here, if you wanted.

188
00:11:06,300 --> 00:11:08,060
But original Peg lacks specificity.

189
00:11:08,060 --> 00:11:10,900
For yours, ABNF and ABNF provided a cruising level of specificity.

190
00:11:10,900 --> 00:11:13,900
Yeah, I don't trust this channel.

191
00:11:13,900 --> 00:11:16,140
You have to switch, yes.

192
00:11:16,140 --> 00:11:18,140
But it's very stateful.

193
00:11:18,140 --> 00:11:21,540
So it's like one state at a time, and that's what I like about it.

194
00:11:21,540 --> 00:11:24,500
It's not some variation on the state.

195
00:11:24,500 --> 00:11:29,420
You see all different variations in node trees when people are doing this kind of thing.

196
00:11:29,420 --> 00:11:33,860
There's people that will make all the nodes the same, and then they'll have attributes

197
00:11:33,860 --> 00:11:37,180
on each of the nodes, and that's the only distinction between all the nodes.

198
00:11:37,180 --> 00:11:39,460
And there's a million ways to model this.

199
00:11:39,460 --> 00:11:41,500
And my favorite is to just...

200
00:11:41,500 --> 00:11:47,540
You either have a node that's apparent that has children, or you have a node that is a

201
00:11:47,540 --> 00:11:52,580
leaf and that is an attribute or whatever in this case.

202
00:11:52,580 --> 00:11:56,500
So anyway, ABNF and ABNF provided a cruising level of specificity in their grammars, but

203
00:11:56,500 --> 00:12:01,140
lack of obvious advantages of order priority and a simplicity of the original ASCII Peg

204
00:12:01,140 --> 00:12:02,140
grammar.

205
00:12:02,140 --> 00:12:06,780
For example, Pagan adds count and min max to provide limits and adds unicode tokens.

206
00:12:06,780 --> 00:12:09,140
So there's no unicode tokens in ABNF at all.

207
00:12:09,140 --> 00:12:11,860
You have to do everything based on that.

208
00:12:11,860 --> 00:12:20,300
In fact, they created an extension to ABNF to allow for...

209
00:12:20,300 --> 00:12:24,700
There's one of the data things from ABNF had to be expanded.

210
00:12:24,700 --> 00:12:28,100
I actually wrote a VIM syntax header for ABNF if anybody's wondering too.

211
00:12:28,100 --> 00:12:32,540
If you ever just want to open an ABNF VIM file and have it actually make sense, then

212
00:12:32,540 --> 00:12:36,500
I updated it to include some of the new stuff from the latest extension to ABNF.

213
00:12:36,500 --> 00:12:40,840
I was obsessed with ABNF for a long time because I was just looking for a way to specify

214
00:12:40,840 --> 00:12:44,140
grammars and those are the only ways until I made Pagan.

215
00:12:44,140 --> 00:12:47,940
So the hope is that Pagan's language itself can be more explicit, better performing and

216
00:12:47,940 --> 00:12:51,860
readable replacement for grammar, meta languages, and inline regular expressions.

217
00:12:51,860 --> 00:12:54,700
Code generators producing parses of different types and different implementation languages

218
00:12:54,700 --> 00:12:58,020
can be created from the same grammar specification expressed in Pagan.

219
00:12:58,020 --> 00:13:02,340
In other words, you can take a Pagan thing and you can run it through a code generator

220
00:13:02,340 --> 00:13:04,620
and generate Ruby code.

221
00:13:04,620 --> 00:13:05,820
You could generate Rust code.

222
00:13:05,820 --> 00:13:06,980
You could generate Perl code.

223
00:13:06,980 --> 00:13:08,420
You could generate C code.

224
00:13:08,420 --> 00:13:12,420
It doesn't matter because there's nothing specific, language specific in Pagan and that's the

225
00:13:12,420 --> 00:13:17,220
biggest selling point of all of the whole thing.

226
00:13:17,220 --> 00:13:20,580
Pagan parses and center libraries can even provide highly optimized handling of Pagan

227
00:13:20,580 --> 00:13:24,980
grammars, including directly in code as strings and constants, much like compiled regular

228
00:13:24,980 --> 00:13:28,380
expressions are handled today, but with much greater clarity and efficiency.

229
00:13:28,380 --> 00:13:35,540
So for example, when you use a regular expression, you have the parenthesized list, but it's a

230
00:13:35,540 --> 00:13:37,060
linked list.

231
00:13:37,060 --> 00:13:39,060
It's not a structure.

232
00:13:39,060 --> 00:13:42,980
It does kind of make one, but you just get an array out of it.

233
00:13:42,980 --> 00:13:47,100
You have to know the number and you have to figure out where your parentheses are inside

234
00:13:47,100 --> 00:13:51,580
of this other thing to see whether it's number one or two because you have to unpack the

235
00:13:51,580 --> 00:13:58,980
parentheses in your brain in order to understand what integer it becomes in terms of index.

236
00:13:58,980 --> 00:14:02,620
And with Pagan, you don't have to do that because you get an AST out of it.

237
00:14:02,620 --> 00:14:04,900
You get a standardized AST out of it every time.

238
00:14:04,900 --> 00:14:07,220
You always get the same one and that is a structure.

239
00:14:07,220 --> 00:14:11,780
It's a full structure that you can walk however you want and do it.

240
00:14:11,780 --> 00:14:14,780
So that, in my opinion, might be slightly slower than regular expressions, but it gives

241
00:14:14,780 --> 00:14:19,100
you more power when you're dealing with grammars and specifying them.

242
00:14:19,460 --> 00:14:24,020
A progressive best example is what is itself, which is specified in Pagan.

243
00:14:24,020 --> 00:14:26,620
Here's another example, the JSON specification in Pagan.

244
00:14:26,620 --> 00:14:33,660
So Pagan is itself specified in Pagan and this is an old one.

245
00:14:33,660 --> 00:14:37,820
Yeah, this is, that link is broken.

246
00:14:37,820 --> 00:14:40,420
I got to fix that, obviously.

247
00:14:40,420 --> 00:14:42,020
I haven't picked up Pagan for a long time.

248
00:14:42,020 --> 00:14:44,540
I've used it for lots of things, but this site needs to be fixed.

249
00:14:44,540 --> 00:14:49,060
So here's the JSON RFC according to RCA 259.

250
00:14:49,060 --> 00:14:52,500
This is the implementation of JSON in Pagan.

251
00:14:52,500 --> 00:14:56,860
And you have the overall grammar, grammar is a conventional name for the top level node.

252
00:14:56,860 --> 00:15:02,180
And then you have the white space and then a value or whatever and then more white space.

253
00:15:02,180 --> 00:15:05,420
And I use the actual terminology from the thing.

254
00:15:05,420 --> 00:15:08,980
There are syntax conventions for the name.

255
00:15:08,980 --> 00:15:15,020
So if they're initial caps, those are kind of easily to identify.

256
00:15:15,020 --> 00:15:18,740
The other couple of things when you have two, I don't want to teach you all Pagan right

257
00:15:18,740 --> 00:15:22,780
now, take forever, but two dashes, this is pretty significant.

258
00:15:22,780 --> 00:15:32,860
The two dashes signifies a substantial node or a semantic, what I call a semantic node.

259
00:15:32,860 --> 00:15:35,100
That means capture it.

260
00:15:35,100 --> 00:15:42,300
If we don't have that, it's just a simplification of code so that, you know, the spec of the

261
00:15:42,300 --> 00:15:44,540
Pagan spec code can become simpler.

262
00:15:44,540 --> 00:15:48,820
So anytime you see value, value is all of these things, right?

263
00:15:48,820 --> 00:15:52,780
But this says don't make value a node.

264
00:15:52,780 --> 00:15:57,420
It just says this is how we refer to value so I can put value down here later.

265
00:15:57,420 --> 00:15:59,620
And then, but any of these things would be a node.

266
00:15:59,620 --> 00:16:02,580
If there's a node, it would be implemented at that point, it would be captured.

267
00:16:02,580 --> 00:16:10,180
So an object is a significant node and it would, you know, it's just, I mean, it's basically

268
00:16:10,180 --> 00:16:11,180
the same as peg.

269
00:16:11,180 --> 00:16:16,020
You get a bracket and then zero or more white spaces and then a member and then you go down

270
00:16:16,020 --> 00:16:17,020
and what's a member?

271
00:16:17,020 --> 00:16:24,140
A member is a string plus a colon plus a value and then you get, you know, zero or more

272
00:16:24,140 --> 00:16:27,980
of this, you know, sort of thing combined together.

273
00:16:27,980 --> 00:16:30,620
In that sense, if you know regular expressions, you can see this.

274
00:16:30,620 --> 00:16:35,100
One of the things that's nice about this is it is a lot easier to read than regular expressions.

275
00:16:35,100 --> 00:16:43,100
We do have an entire standard subset of predefined tokens like DQ and everything, which APNF

276
00:16:43,100 --> 00:16:47,100
has also done so you can just use those if you already know them.

277
00:16:47,100 --> 00:16:51,580
In fact, anything that's lowercase is considered a class and some of the classes can be used

278
00:16:51,580 --> 00:16:57,740
without specifying them because they're assumed there to be coming from the, the peg and specification

279
00:16:57,740 --> 00:16:58,740
itself.

280
00:16:58,740 --> 00:17:00,940
So they're predefined such as WS.

281
00:17:00,940 --> 00:17:12,980
And that includes every positive span range and things like that, digit and stuff.

282
00:17:12,980 --> 00:17:15,580
And so, yeah, so digit is another class.

283
00:17:15,580 --> 00:17:22,540
Actually, I think digit is a token, you know, there's differences between classes and tokens.

284
00:17:22,540 --> 00:17:29,460
Class is like one of these set and the other one, a specific token is like this exact

285
00:17:29,460 --> 00:17:34,060
single character or, you know, three characters or something like that.

286
00:17:34,060 --> 00:17:38,500
And so, the other thing that's cool about peg and peg is that they're left to right

287
00:17:38,500 --> 00:17:42,860
versus ABNF and EBNF, which are like, when you specify something with a slash and EBNF

288
00:17:42,860 --> 00:17:46,980
and EBNF, it can be any of those things at any order.

289
00:17:46,980 --> 00:17:53,940
And the really, really, really great simplification of peg is it's guaranteed to match first left

290
00:17:53,940 --> 00:17:55,100
wins.

291
00:17:55,100 --> 00:17:56,580
So you put the stuff to the left.

292
00:17:56,580 --> 00:18:05,020
So for example, in my specification for, for Kegumel, you know, wait, let me go see

293
00:18:05,020 --> 00:18:06,020
you.

294
00:18:06,020 --> 00:18:07,020
Where is my spec?

295
00:18:07,020 --> 00:18:08,020
Is it over here?

296
00:18:08,020 --> 00:18:09,020
Okay.

297
00:18:09,020 --> 00:18:13,100
So in my specification for Kegumel, let's, let's do the, let's do the, the, you see here

298
00:18:13,100 --> 00:18:17,180
I have bulleted and then numbered and then figure, right?

299
00:18:17,180 --> 00:18:24,500
Well, if I was going to do those bulleted, right, a bulleted list begins, I'm not bulleted,

300
00:18:24,500 --> 00:18:27,060
let's, let's do, let's do spans, spans are better.

301
00:18:27,060 --> 00:18:28,380
So let's do strong emphasis.

302
00:18:28,380 --> 00:18:33,900
The reason strong emphasis first, even though you might not want to list it that way is

303
00:18:33,900 --> 00:18:41,940
because strong emphasis for me is three stars plus, you know, something and that this is

304
00:18:41,940 --> 00:18:44,020
the part that's kind of interesting.

305
00:18:44,020 --> 00:18:52,500
So right here, we're going to put a plane and so then we can put a plane.

306
00:18:52,500 --> 00:18:58,740
So it's a, you know, it's a plane span and followed by another token, right?

307
00:18:58,740 --> 00:19:04,620
And so, so there, the reason that's the strongest are that the reason that that one comes first,

308
00:19:04,620 --> 00:19:15,220
of course, is because the strong one has two and the emphasis one, which is italic is just

309
00:19:15,220 --> 00:19:16,220
one.

310
00:19:16,220 --> 00:19:20,500
Now, what if I put, so if I was trying to specify this in EB enough, you see how problematic

311
00:19:20,500 --> 00:19:21,700
this would be?

312
00:19:21,700 --> 00:19:26,740
By just placing the order to check for each one, I can have tokens that would otherwise

313
00:19:26,740 --> 00:19:28,180
be included in the other tokens.

314
00:19:28,180 --> 00:19:31,700
This is where you get all the craziness with XML and everything because they don't have

315
00:19:31,700 --> 00:19:35,740
the idea of, well, first look for this, and I can't tell you how valuable this is when

316
00:19:35,740 --> 00:19:38,980
it comes to code generation or just writing the code by hand, because just by looking

317
00:19:38,980 --> 00:19:45,500
at the peg and I know right away what comes first, I know that I need to write, I need

318
00:19:45,500 --> 00:19:52,460
to check for a strong emphasis token before I check for an emphasis token so that I can

319
00:19:52,460 --> 00:19:59,180
fail out or, you know, go to or hand off to the next, to the next parser, the next token

320
00:19:59,180 --> 00:20:05,300
parser, because I have the order and I know, I keep talking about this, but that is such

321
00:20:05,300 --> 00:20:10,900
a huge thing when it comes to writing parsers, because otherwise you just don't know.

322
00:20:10,900 --> 00:20:17,540
And it's really nice because it keeps the syntax of Kegamel or Bonzai.

323
00:20:17,540 --> 00:20:18,540
Very simple.

324
00:20:18,540 --> 00:20:22,540
I'm a huge fan of just one way to do things in a markdown language like this.

325
00:20:22,540 --> 00:20:26,500
And so I just use stars all the time, and even though you can use underscores in any

326
00:20:26,500 --> 00:20:30,300
number of combinations, infinite number of combinations, which to represent in a grammar

327
00:20:30,300 --> 00:20:35,100
would be crazy hard, not to mention putting an unnecessary amount of overload on a parser.

328
00:20:35,100 --> 00:20:37,860
And if you're going to make a specification for something that's going to potentially

329
00:20:37,860 --> 00:20:39,900
be capturing all the knowledge of the world.

330
00:20:39,900 --> 00:20:42,500
We want to be optimized in our parsing.

331
00:20:42,500 --> 00:20:47,440
And so this is one of those cases where we just want one best way to do it.

332
00:20:47,440 --> 00:20:49,420
Other grammars would nest them.

333
00:20:49,420 --> 00:20:53,020
Lots of grammars would nest these, and you can represent these as nested, but I do not

334
00:20:53,020 --> 00:20:55,260
ever want to do that.

335
00:20:55,260 --> 00:20:56,540
And neither does medium.

336
00:20:56,540 --> 00:20:59,380
Medium does not allow you to nest your grammar, to nest your emphasis.

337
00:20:59,380 --> 00:21:03,680
You cannot have italics in something that's already been bolded.

338
00:21:03,680 --> 00:21:07,260
And if you've ever played around with any kind of syntax highlighters or Vim plugins

339
00:21:07,260 --> 00:21:13,860
or anything like that, you have experienced a broken emphasis highlighter, something that

340
00:21:13,860 --> 00:21:20,780
gets it wrong because it wasn't well specified, or it thinks it's got a span when it really

341
00:21:20,780 --> 00:21:23,180
doesn't because it's on a different line.

342
00:21:23,180 --> 00:21:27,860
Or I'm guarantee you, if you spend any amount of time doing any kind of syntax highlighting

343
00:21:27,860 --> 00:21:30,860
stuff, you will find something that's really broken.

344
00:21:30,860 --> 00:21:34,540
And it's really too bad because of that.

345
00:21:34,540 --> 00:21:37,340
So for my particular grammar, and this is one of the reasons I made Pagan, I wanted

346
00:21:37,340 --> 00:21:43,220
to be able to very precisely specify, I wanted to be very precise in my specification of

347
00:21:43,220 --> 00:21:46,940
the grammar, and to keep it deliberately simple.

348
00:21:46,940 --> 00:21:51,100
And people might accuse me of keeping it too simple, and they're like, why is it simple?

349
00:21:51,100 --> 00:21:52,500
I was like, because I don't need more.

350
00:21:52,500 --> 00:21:54,740
But it's not as simple as Godoc, for example.

351
00:21:54,740 --> 00:21:56,980
Godoc doesn't have anything.

352
00:21:56,980 --> 00:21:58,380
Godoc is even worse.

353
00:21:58,380 --> 00:21:59,820
It's just text.

354
00:21:59,820 --> 00:22:03,540
And you can indent something by four spaces to get it to be the same.

355
00:22:03,540 --> 00:22:06,180
And headers are lines by themselves.

356
00:22:06,180 --> 00:22:07,540
So there is a grammar there.

357
00:22:07,540 --> 00:22:08,540
It's just not specified.

358
00:22:08,540 --> 00:22:11,780
You have to go read the Go source code to understand what the grammar is.

359
00:22:11,780 --> 00:22:12,780
This is why I made Pagan.

360
00:22:12,780 --> 00:22:16,740
At least when somebody comes to me and says, OK, I said, well, what's Kegelman, I don't

361
00:22:16,740 --> 00:22:17,740
want to have to learn another thing.

362
00:22:17,740 --> 00:22:18,740
I said, you probably already know it.

363
00:22:18,740 --> 00:22:19,940
I was like, how do you know it?

364
00:22:19,940 --> 00:22:20,940
Well, do you know Markdown?

365
00:22:20,940 --> 00:22:21,940
Yeah.

366
00:22:21,940 --> 00:22:27,860
So it's a simplified version of Pandoc Markdown, which means it's got semantic div brakes and

367
00:22:27,860 --> 00:22:33,500
it's got math support, which GitHub now has.

368
00:22:34,460 --> 00:22:35,460
That's what Pagan is.

369
00:22:35,460 --> 00:22:37,300
Pagan is a way to specify a language.

370
00:22:37,300 --> 00:22:39,100
You can go read more about it if you want to get into the details.

371
00:22:39,100 --> 00:22:41,300
I feel like I've gone too far in the details already.

372
00:22:41,300 --> 00:22:45,940
I do think it's important that I mentioned that the grammar, the Pagan itself does specify

373
00:22:45,940 --> 00:22:48,420
the AST to be used.

374
00:22:48,420 --> 00:22:54,820
I am seriously considering a revamp of this AST at some point.

375
00:22:54,820 --> 00:23:03,180
So the format for the AST, the text version of the AST is also written in Pagan.

376
00:23:03,260 --> 00:23:07,460
You can go read that if you want, or you can actually look at the long form.

377
00:23:07,460 --> 00:23:10,140
I'm trying to find an example.

378
00:23:10,140 --> 00:23:17,260
So here is a long form example of the JSON AST.

379
00:23:17,260 --> 00:23:29,700
So this is the AST of the JSON file itself, but in compact form, it's actually extremely

380
00:23:29,700 --> 00:23:30,700
compact.

381
00:23:30,740 --> 00:23:42,060
It's the smallest text-based JSON compatible, human readable AST that you can get, and it

382
00:23:42,060 --> 00:23:43,460
can be easily expanded.

383
00:23:43,460 --> 00:23:46,700
So that was by design.

384
00:23:46,700 --> 00:23:50,980
When I looked at the native Haskell, this was all inspired by Pandoc.

385
00:23:50,980 --> 00:23:53,380
Pandoc's JSON AST is abysmally bad.

386
00:23:53,380 --> 00:23:55,340
I mean, let me just show you.

387
00:23:55,340 --> 00:23:57,300
I talked about this earlier, but I'm going to talk about it again.

388
00:23:57,300 --> 00:23:59,620
I just love salmon on this particular thing.

389
00:23:59,660 --> 00:24:05,060
So when you do Pandoc, I mean, they didn't have as much information as they do now.

390
00:24:05,060 --> 00:24:07,180
It's too bad because they can't go back and redo it.

391
00:24:07,180 --> 00:24:12,140
But I don't know if you can see this, but so they have strings here, right?

392
00:24:12,140 --> 00:24:17,140
They have spaces, like a space, meaning white space, and then Kegamel.

393
00:24:17,140 --> 00:24:20,700
And they have, first of all, they have way too many, too much, like two verbose rich

394
00:24:20,700 --> 00:24:21,700
thing.

395
00:24:21,700 --> 00:24:27,500
But what I really, really don't like is when they have strings, I'm trying to find one.

396
00:24:27,500 --> 00:24:28,500
There's no one there.

397
00:24:28,500 --> 00:24:29,500
Okay.

398
00:24:29,500 --> 00:24:38,100
So here, this right here, string C documentation slash docs.

399
00:24:38,100 --> 00:24:39,100
What is that?

400
00:24:39,100 --> 00:24:40,100
Oh, this is a link.

401
00:24:40,100 --> 00:24:41,100
Okay.

402
00:24:41,100 --> 00:24:46,420
So we have a link and the properties of the link are, and it's got all the properties

403
00:24:46,420 --> 00:24:49,820
in order, so they're not named.

404
00:24:49,820 --> 00:24:55,580
And what I'm trying to show you is that they, when they have strings, the strings include

405
00:24:55,580 --> 00:24:56,980
quotes on them and stuff like that.

406
00:24:56,980 --> 00:24:59,900
So let me see if I can find another version.

407
00:24:59,900 --> 00:25:10,740
So if I have, I don't know, let me see if I can find one, pandoc-tjson, read me.

408
00:25:10,740 --> 00:25:13,980
Did I just go to look at the same one again?

409
00:25:13,980 --> 00:25:14,980
I did.

410
00:25:14,980 --> 00:25:17,500
And it's in the spec, ml spec.

411
00:25:17,500 --> 00:25:18,580
All right.

412
00:25:18,580 --> 00:25:22,460
So let's go, let's look at this, read me.

413
00:25:22,460 --> 00:25:23,460
Okay.

414
00:25:23,460 --> 00:25:24,460
So look at this one.

415
00:25:24,940 --> 00:25:29,340
So you know, you have the links here, you have the types, you have a soft break and it,

416
00:25:29,340 --> 00:25:31,060
it deliberately uses long words.

417
00:25:31,060 --> 00:25:32,980
There's no way to make it shorter.

418
00:25:32,980 --> 00:25:39,580
So the, the textual ASTs that are generated from pandoc are so fucking long that, and

419
00:25:39,580 --> 00:25:45,020
the standard instruction from pandoc, if you want to write your own conversions is to convert

420
00:25:45,020 --> 00:25:51,220
to the JSON AST and, and then walk the, the JSON AST and parse that and produce your other

421
00:25:51,220 --> 00:25:52,220
thing.

422
00:25:52,220 --> 00:25:54,420
And I guarantee you, you, you should see how long it takes to do that.

423
00:25:54,900 --> 00:26:01,740
Because this thing is a monstrously big waste and it also gets tons of stuff wrong.

424
00:26:01,740 --> 00:26:08,900
So for example, it, it deliberately lumps together, uh, quoted content as a string.

425
00:26:08,900 --> 00:26:12,860
So for example, or a parenthesized word as a string, it doesn't consider the idea of

426
00:26:12,860 --> 00:26:15,740
fields and then words and then things like that.

427
00:26:15,740 --> 00:26:17,740
It's, it's so, it's just a mess.

428
00:26:17,740 --> 00:26:21,780
And that's, I, I, look, I really, really appreciate that we have pandoc.

429
00:26:21,780 --> 00:26:23,700
I don't want it to be misunderstood.

430
00:26:23,700 --> 00:26:26,460
I think it's so great that we have it, uh, JQ.

431
00:26:26,460 --> 00:26:30,620
I could pipe it through JQ, but yeah, uh, Jeff needs some love.

432
00:26:30,660 --> 00:26:31,500
Yeah, it does.

433
00:26:31,500 --> 00:26:36,140
So, and they could actually make a different representation.

434
00:26:36,140 --> 00:26:40,660
You could probably do a Haskell, uh, you know, PR and, and do that.

435
00:26:40,660 --> 00:26:43,460
But the, the, the, yeah, they probably prefer Haskell reformos.

436
00:26:43,620 --> 00:26:44,060
I agree.

437
00:26:44,340 --> 00:26:48,180
But the, the, the point is, is that, I mean, if you're going to tell somebody that

438
00:26:48,180 --> 00:26:53,580
you're a standard way of supporting other conversion method out methods is to,

439
00:26:53,620 --> 00:26:54,820
and by the way, you can make your own.

440
00:26:54,820 --> 00:26:57,380
You can write your own Lua plugins that will render the whole entire thing.

441
00:26:57,660 --> 00:26:58,940
It's beautiful Haskell.

442
00:26:58,940 --> 00:27:02,020
If you get into the functional program, if you, if you want a really good example

443
00:27:02,020 --> 00:27:07,500
of when functional programming really shines, uh, you know, pandoc is a good example

444
00:27:07,500 --> 00:27:12,100
of that because it was Haskell is like Taylor made for parsing syntaxes and

445
00:27:12,100 --> 00:27:12,740
grammars and stuff.

446
00:27:12,740 --> 00:27:13,940
It's just so perfect for it.

447
00:27:14,300 --> 00:27:18,860
And, and, you know, I imagine, uh, you know, Lisper or Lang or something,

448
00:27:18,980 --> 00:27:20,260
uh, would be just as good.

449
00:27:20,620 --> 00:27:23,140
Uh, but, but that's, you know, that's my experience with Haskell too.

450
00:27:23,540 --> 00:27:29,660
Um, and, you know, it's super fast, but, but, I mean, it, it does lack a lot in the,

451
00:27:29,700 --> 00:27:36,340
in the, you know, the, the, to me, the AST is really core because if you want to have

452
00:27:36,380 --> 00:27:42,820
a, the ability to make a conversion from one thing into anything else, uh, it's so

453
00:27:42,820 --> 00:27:44,140
important that you get that AST, right?

454
00:27:44,140 --> 00:27:47,260
Because then everybody else can render it however they want to.

455
00:27:47,260 --> 00:27:50,140
Well, you've just created a data model for the thing that you're

456
00:27:50,140 --> 00:27:52,100
representing, whatever it is, a document or whatever.

457
00:27:52,380 --> 00:27:54,180
And, and, and that's really core of the whole thing.

458
00:27:54,180 --> 00:27:56,820
And the people who made pandoc, of course, are not web people.

459
00:27:56,820 --> 00:28:00,620
They are, you know, publishers and Haskell people and academics and they're

460
00:28:00,620 --> 00:28:05,220
over at Berkeley and, you know, JGM's an amazing spearheaded common mark and a

461
00:28:05,220 --> 00:28:06,220
bunch of other amazing things.

462
00:28:06,220 --> 00:28:08,300
And I, I've had some interactions with JGM.

463
00:28:08,300 --> 00:28:12,780
JGM is completely 100% unimpressed with anything I've ever done, which is fine

464
00:28:13,260 --> 00:28:17,620
because, but I'm doing things that I need, uh, and yeah, including Peg.

465
00:28:17,620 --> 00:28:22,020
And I, I ran Peg and by him and he was like, why am I, well, you know, why Peg?

466
00:28:22,020 --> 00:28:23,820
And he doesn't, he's not interested.

467
00:28:23,820 --> 00:28:24,980
He just, he got his answer.

468
00:28:24,980 --> 00:28:28,980
He's a philosophy major and he's a great guy, but, uh, a philosophy professor.

469
00:28:29,300 --> 00:28:35,340
So, um, anyway, here's the parent nodes, uh, given the following data example, you

470
00:28:35,340 --> 00:28:40,500
get this copyright and, and, um, yeah, here you get another AST.

471
00:28:40,500 --> 00:28:42,420
No, no AST node attributes.

472
00:28:42,660 --> 00:28:44,660
Summary node 2 data structure models, a lot for attributes.

473
00:28:44,660 --> 00:28:48,620
Peg and Stacy does not, since attributes can more, uh, efficiently and precisely

474
00:28:48,620 --> 00:28:53,340
indicated by adding an additional parameter parent or terminal type, which is

475
00:28:53,340 --> 00:28:54,500
another word for leaf node.

476
00:28:54,980 --> 00:28:57,100
Uh, Peg was conceived originally developed by me.

477
00:28:57,580 --> 00:29:00,820
Uh, I'm working with tokenizers and text generation.

478
00:29:00,820 --> 00:29:01,300
Oh, nice.

479
00:29:01,860 --> 00:29:04,660
Uh, while creating grammars, uh, was needed for artifacts knowledge net.

480
00:29:04,660 --> 00:29:08,700
That's keg, uh, easy mark, data mark, mate, man, I can update this.

481
00:29:09,020 --> 00:29:13,140
These are all of the different, uh, base QL, all of the ones that I've been doing.

482
00:29:13,660 --> 00:29:15,740
Uh, live coding streams.

483
00:29:17,100 --> 00:29:19,700
Others to update and contribute it and help this is, that's, I got to update them.

484
00:29:20,220 --> 00:29:22,060
Uh, related tools to Vimplug and Emacs.

485
00:29:22,180 --> 00:29:23,500
I don't have them in plugin done yet.

486
00:29:23,540 --> 00:29:25,740
I need to other efforts out there.

487
00:29:25,740 --> 00:29:26,660
You can go look at peg leg.

488
00:29:26,660 --> 00:29:28,780
That's the one I helped contribute to go peg.

489
00:29:28,780 --> 00:29:30,660
It's the one I contributed to actually space on peg.

490
00:29:30,660 --> 00:29:34,860
Look, uh, the Python ones, the Guido one that, that they added 3.9 and Python, I

491
00:29:34,860 --> 00:29:38,380
think, uh, Pigeon Pigeon pest.rs, which I was so excited about.

492
00:29:38,380 --> 00:29:42,380
Turned out it's crap and antler antler has been his Java is all about Java.

493
00:29:42,380 --> 00:29:46,860
But it's, it's exactly in the same sort of space, uh, for defining grammars and

494
00:29:46,860 --> 00:29:47,940
stuff, but it's Java only.

495
00:29:48,500 --> 00:29:52,300
Um, from a peg a grammar specifications, blah, blah, blah, go read that.

496
00:29:52,900 --> 00:29:57,500
Uh, linking documentation with definitions, uh, legal considerations, what

497
00:29:57,500 --> 00:29:59,820
adoption is blah, mime type.

498
00:29:59,900 --> 00:30:03,220
I'm, I'm hoping to get X dash Pagan from my type, but I haven't submitted that yet.

499
00:30:03,620 --> 00:30:10,700
Trademarks, uh, blah, blah, licensing, it's Apache tube, uh, attribution,

500
00:30:10,700 --> 00:30:14,740
patents, uh, contributing, IFC, or you can't see the race.

501
00:30:14,740 --> 00:30:17,580
So I would like to get this eventually submitted, but I don't want, I want to

502
00:30:17,580 --> 00:30:21,100
use it for like a year or two and have all the tools done for it before I do that.

503
00:30:21,420 --> 00:30:25,820
Um, Pagan has, Pagan parsering has been used in production at at least one

504
00:30:25,820 --> 00:30:29,780
company that I know of besides mine, uh, for over a year and a half at this point.

505
00:30:30,180 --> 00:30:34,540
And so if you're wondering whether it's worthy of abuse and there has been, uh,

506
00:30:34,540 --> 00:30:38,540
some tweaking to the specification in that time based on, uh, you know, the

507
00:30:38,540 --> 00:30:41,260
very intense usage that's happening over in that other company.

508
00:30:41,740 --> 00:30:44,620
Um, so, so it's out there.

509
00:30:44,620 --> 00:30:45,700
You can go use it if you want.

510
00:30:45,700 --> 00:30:46,500
You can play around with it.

511
00:30:46,740 --> 00:30:48,700
If you ever want to write your own language, you probably can.

512
00:30:48,940 --> 00:30:51,940
I, I may very well do, uh, write a book about Pagan.

513
00:30:52,380 --> 00:30:54,900
Uh, I'm, I'm all about writing books these days.

514
00:30:54,900 --> 00:30:56,860
Um, I got to finish the terminal velocity.

515
00:30:56,860 --> 00:30:58,180
That's the book I'm working on right now.

516
00:30:58,660 --> 00:31:03,660
And after that, uh, you know, these other books in spaces that are not covered by

517
00:31:03,660 --> 00:31:05,380
anything, uh, will be all right.

518
00:31:05,380 --> 00:31:09,380
I mean, write a book about bonsai, write a book about Pagan and, uh, some of these

519
00:31:09,380 --> 00:31:11,140
other things so that people can take them and use them.

520
00:31:11,820 --> 00:31:13,380
So that's all I have to say about that.

