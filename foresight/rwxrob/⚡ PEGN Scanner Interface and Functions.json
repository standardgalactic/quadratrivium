{"text": " Go. So, lots of changes if you've been following the keg and the peg and stuff I've been doing over the years. I went to bed last night with my head working on a bunch of problems. I woke up and I just had an idea I had to finish and I've been working on it straight since, God, I don't know, like eight o'clock this morning. It's somewhat related to work. Don't worry, I'll make up the work time tomorrow and the next day and the next day, but this is really important because it's so key to everything else that I'm doing. So, let me try to stick with the highlights and hell, why don't I actually make a, use my YouTube thing. We're going to make a directory for this. We'll call it updates on peg. Actually, let's call it something more specific than let's say a peg in scanner interface and functions. So, what I've done so I mentioned, I mentioned the other day that interface and functions. Is that right? Peg and scanner interface and functions. Yeah, I mean, and she'll have a tool to do all that. So, okay, so so my my peg in scanner implementation now conforms now conforms to a common peg in not scanner interface so that other scanners can be implemented. My people that conform to it. So, the reason that I made an interface, why an interface so that the library of scanner functions of scan functions can be interchangeable with different scanner implementations. And if that's, that is the main reason. And let me show you what I mean by that. So, if you go to, so this is all, by the way, this is all I actually put in the thing related in here. So, here's the pages that we're going to. We're going to HTTP, github.com, rdxrub, peg in, peg in dash spec. And that's pretty much it. If you go there, you'll find everything. It used to be that I had it all over the place. And I used to have, there's this, there's peg in dot dev, but that's kind of, it's kind of older, but a little older and out of date. So, it's still there. I'm reforming the spec as we go. So, we want, okay, so let me, let me show you why. So, if we go to the peg in scanner itself here, right? So, I mean, what is the end goal? The end goal is for us to be able to parse any kind of language. And we started with base ML, or base MD. Now, you'll remember I was basic MD. I was writing a basic MD scanner. And here is the, the, the, so this was all brought about because of this. So, I'm just going to put all of this precipitated by the basic, basic MD, parser, that I was right. I mean, a scanner, parser, AST. So, I started writing that last night. And that was all good and everything. But it became clear to me that there, I mean, some of these functions, I'm going to show you one, some of these functions that I have written, I have written them so many times. I swear, I have written, so like, I don't know how many, so I didn't, thank God I didn't post it to YouTube. I'm not going to force it on you. But I did, I must have written a, you know, a white space or an end of line parser, probably a dozen times, different ways. Because I don't have, I haven't had a standardized way to abstract the scanner stuff in a way that didn't require rewriting a scanner. I mean, I've written probably, including an extremely complicated one. If you go back in my YouTube videos, there's something I was writing, it was called go, was it go, go compatible, peg in expressions? And it was actually go code that could be passed into symbols, that could be passed into another function that would parse it, and then it would, you know, it would do its thing. It was pretty cool. But every time I've written one, and then the most recent iteration of my scanner that I wrote, I just ripped all that crap out. I was like, I want the ultimate and minimal. And thank God I did that because I actually ended up coming up with, so here's an implementation of the new scanner interface that anybody can write. And all it has is, I mean, some of this stuff is internal, but you know, this, let me show you the interface first, actually. So let's start with the interface. So the scanner interface is in my types. The scanner interface is just a scanner. It's a rune scanner that is aware of the beginning and ending of each rune that it scans, which can be more than one byte, right? So people know this. So you can imagine a cursor going, you know, through the, through the screen like this, like with an emoji on there. And sometimes it's a thing. So in fact, the scanner has this idea of a rune cursor. And I used, I mean, I thought with myself about whether to call it cursor or not, I didn't end up keeping a concept of cursor here, but I might find I had it embedded and everything. I don't want to get into it. So ultimately, a scanner is, it's a bytes buffer. And this is another reason I put this in the peg. So this thing, all of this used to be under rtbx-rob slash scan. I had my own rune scanner in there. But I realized, and I'm going to put this in my conclusions. So I realized that, that my rtbx-rob scan was actually very peg specific. And what I mean by that is that so a couple of really important specific assumptions are made by peg. Peg assumes that you have infinite memory, which is, you know, the polar opposite of parsing when you're using anything that you would get out of the Dragon Booker and computer science class. And so, I mean, that's a huge thing. So if someone comes across my scanner, they're going to say, oh, a scanner, cool, you know, they'll make think it's a finite automata, you know, single look ahead kind of scanner. And they, they're like, what the hell is this thing? It just flipped my whole data source, you know, byte, byte buffer and into memory. I mean, that's, that's like, that's like an unorthodox thing to do. That's a sacrilege in this. You know, that's what peg does. So, so I realized that the scanner that I have built and been using the most recent one, which I've used all over the place, I'm using it all over the place. I'm using it in Bonsai and everything is actually, in fact, I think I just broke Bonsai by, no, I didn't. Bonsai's got its own scanner, never mind. Anyway, so I went ahead and, and implemented, and I actually also deprecated the other one by, because I moved the entire scanner into the Pagan package or the Pagan, Pagan module, because why? Because it's Pagan centric. It's Pagan centric because a Pagan centric scanner, you can't even use it unless you load up a buffer. And, you know, that's completely unheard of in other circles. So, so that was the first major thing. That did mean, however, though, that the, the other one that I have, which I'm leaving out there, because I'm pretty sure I have some dependencies on this scanner. And it's also listed in my awesome go list and things. And I have some pretty intense breaking changes that I added to this since version 10, because I changed some of the internal references and everything. And the more I got changing it, the more I, see right here, it says fulfills Pagan scanner face. It actually doesn't do that anymore. I broke that when I was doing the move. And then this is the most accurate thing. So I've moved this entire scanner over to RTX ROM Pagan. And it is, you know, implemented as, under the types. Good night. So it's implemented in the type here, under types, you can see the scanner is here. It gives you the cursor type and a scanner type. And you can look it up and it has a mark going to go to and scan and to finish. I mean, nothing fancy there, right? And then I implemented, they included, you know, reference implementation of the scanner that I use for the Pagan stuff. And this gets me to where I was going with base, basic marked, my basic markdown parser. So, so here we have Pagan, we have, so this is, this is the exact code that was in this other place. That's just been moved and cleaned up. And I mean, really cleaned up and had some, some other things added to it. For example, the fulfillment of the interface so that it can be replaced with something else at any time. And let me, let me talk to you about why I decided to make it an interface again. I mean, I started talking about that. But if you go to, so here's the interface, but as I was working on basic MD, I started realizing that parsing end of line and end of block and paragraphs and, you know, all of these things that are listed in Pagan are things that I need to do all the time. In fact, I just add it in paragraph, right? These are things that I already need all the time. And I'm like, I've always have intended to write, I mean, I've been really kind of hung up on creating a code generator for all of stuff that, so you write Pagan and you end up with different types of code, right? But to be more practical, I've started realizing all I really need to do is write a scanner function for each of these and then reuse them. And then the ones that I, that aren't in Pagan, that are specific to basic markdown or whatever, I'm writing Keg or whatever, I can actually write those using exactly the same function signature. And I could even put them in packages, you know, as a collection of first class functions, because they all accept the scanner interface. And that is, you know, that is go interfaces shining the brightest, right? Because that's what's exactly what you want to do with it. So what does that mean? So I have the scanner implementation here, and I can, I actually chose to make this implementation fast and abstract, so that if somebody chose to use it, they could use the direct references to the byte buffers and stuff like that, so they can bypass the indirection from the interface method calls, which is the reason I didn't do it originally, right? If you look at the highest performance parsers out there, they do not have a lot of functional indirection, right? It's actually one of the biggest complaints I have about the current code generator for Pagan that Quint mostly made, and I last two years ago, is it has a ton of function indirection in it. And that's been something I've been kind of like, irrationally hung up on. And I think I finally hit the middle, the middle of the road here. So this particular reference implementation, which is a part of Pagan, comes with a struct that you can use directly if you want to, which I probably will do and really quick and dirty, you know, I mean, not the quick and the quick and dirty stuff, I'll probably will use the abstractions because they're easier to remember and you can just, you know, you can just swap them in and out. I don't need performance, right? But if I'm like, really want to make a low level, really intensely often, you know, parsed grammar, then I can go ahead and bypass the use of those things as long as I don't want to reuse any of the stuff I've already write in Pagan, which brought me to think, oh, damn, you know, let's say I make a, here's, here's my work, my workflow. Okay, so my, I imagine the workflow of making a grammar or something like this, right? So in fact, this is even in a slide at Brian Ford, Brian, I was looking at Brian Ford's peg stuff, and he has this in a slide about, you know, traditional thing, use Lex and Yak and blah, blah, blah, and, and then, but, you know, the pragmatic way approach to doing parsing these days is to write, you know, a generic kind of specification and then to write a recursive descent parser. It's the standard way, the practical way to do parsing. And let's say I want to do that, right? So I want to write a grammar, but I want to write it quickly. Now, the quickest way to do it would be to do cogeneration with, you know, from Pagan notation, which is something I still want to do. That's nothing that Pagan, that Brian Ford ever wanted to do. You kind of wanted to get away from it because he realized it was just, it's just as fast to just write your own recursive descent functional parser and, and then be done with it. You don't have to deal with all the intricacies of cogeneration, not being exactly what you want. You just write it, right? And, and I'm kind of on board with that idea because, you know, it's, it's quite a bit of work to get it to generate just the way you want to. And then which, which cogeneration method do you want? Do you want it to be highly efficient? Do you want it to be used functional so it can be easily maintained? Are you going to rerun the generator every time? Is it just giving you the first version? And, and so at a certain point, you kind of come to the conclusion that probably the fastest way to create a parser is to just write the thing because then, you know, you're going to, you're, you're going to be done. You're going to be done with it and you're going to be able to move on to other things. So, um, and, and that's kind of where I am. So, uh, also realized, uh, fastest way to develop, uh, parser is to write Pagan and then function and then scanners functions for recursive descent. Uh, I mean, it really is. So by the time, you know, you get all the thing, just writing the Pagan itself is good. I mean, that kind of gets you thinking about how it's supposed to be implemented, but you're also not wrestling with Pagan syntax and stuff, uh, in case you get it wrong. Now, you should probably do that, but let's say you don't represent it perfectly and Pagan, who cares? The Pagan is just there to help you understand what the parser is going to, how it's going to behave. Um, and then you can, you know, compare it to that, you know, just, just, you know, visually and get to your, get to your point, but you can get busy kind of writing your parser. So, so, but, you know, along those, those lines, assuming that you're going to write a parser, right? You're going to go ahead and write a parser. What are the obvious building blocks? I mean, code generation is awesome and everything, but, but what, what would be the other way to do this if you didn't have code generation? Well, it gets pretty obvious that it would be a standardized library of scan functions, uh, that, that you regularly reuse, right? And if you, as long as you make those export in your public, make those public, you can, you can pull them in and you can tweak them and make them more efficient and other people can contribute their own. And, and you have, you know, you ended up getting this ecosystem of scanners, uh, of, you know, because that's really, the scanners are really the secret because if you have a scanner, you can scan it and if it scans successfully and you would get a true at the end of that. I mean, and this is very hastily, right? If at the end, if you get a true after that, you're done. You're under the next thing. If you don't get a true, then you're guaranteed that the scanner didn't do any advancement because it snapped back. And you're going to see this all over in, in my implementation of functions, which we'll show you in a second, because that is how you do this. And, and that is exactly how Brian Ford talks about it in his paper. It's like the difference between, you know, the traditional scanner and, you know, parser kind of approach. And this is that you can scan ahead as far as you want and you can keep track of how many matches you have. So you can be very greedy if you want and say, okay, so did I find anything? Yes, I found like 10 of them. And then I keep scanning and like, oh, hey, well, like, okay, I stopped. So then I like roll back to the last one that was successful. Or if there were none that were successful, I roll back the scanner all the way to the beginning. So, so this idea of snapping the scanner back and moving it and around a thing, that's a very fundamental part of the PEG architectural approach. Because you have memory, you have memory that you can fly around in. And very quickly, by the way, I mean, you know, moving pointers around in memory is crazy, crazy fast. And you've only had to do the one load. And so, you know, all these things that are doing like single byte loads, in order to do that, you've already had to buffer your data at some point. So you've already had to do the buffering. So, so the thing is cool about PEG is it assumes that you're just going to buffer all of that upfront. And then you're going to break up your content into manageable chunks that fit within, you know, reasonable amount of memory that you're going to be parsing. You should put limitations in there and stuff. And that's a part of the grammar design, which is another reason that PEG is a fail, because as wonderful as it is, it does not allow you to put limitations and constraints on this size, which is why I made PEG in. So when I say things like, I only want, you know, two end of lines here, I can specify two end of lines. There's no way in the original PEG specification example to indicate amount, which I just think is crazy, given the fact of, that regular expressions in ABNF have been doing it forever, and ABNF, but PEG decided not to do that. So that's one of the reasons I made PEG in, because we clearly want the combination of those things. All right, so let me go back to here. So I went ahead and I implemented a white space function right now. I could have probably automated this, but let's look at what it looks like. So if we go into the PEG and scan, and you're probably wondering, well, why did you name it scan? Because I wanted it to read well. So let me show you the, the examples here. These are go testable examples, and they are public. You'll remember maybe when I did basic MD that I kept a bunch of my scanning, not public. I was like, because I didn't want people to become dependent on my scanner functions, right? I mean, I'm just making a basic markdown part. So I don't want people to be, you know, including my thing, because they want my specific implementations of these. And that's one of the reasons I started thinking, hmm, I should probably think more deeply about some of these scan functions that are going to be reusable. And I should probably put them somewhere where they could easily be reused by me and others. And that's what got me to do this. So I've created a convention called sum, which is just a nice happy way. It's like, you know, go, they like have must and compile and things like that. So I created a convention where you put sum in front. These are all documenting the design considerations on the read me page, by the way. But sum means, you know, zero or more white space or one or more white space. So if I have example sum WS, so, and then I the reason I named this sub package scan is so that we would get these wonderful readable lines here scan dot sum white space and then pass in the scanner. Now you might be asking as many, many people will tell you that have done scanners that they implement the scanner as a class, which I think is disastrously bad architectural decision, because you cannot do anything with it at all. And tell you expand the class, that is the primary reason that people like Jim Copeland and others hate class based object oriented programming. It is so concrete, you can never extend it, not without re implementing the class or subclassing it by doing it this way. I can use first class functions is a very functional approach. I can use first class functions if I want, I can use it from a package, whatever, because the scanner is an argument to the function. And so as long as the scanner fulfills the interface, this is why interfaces are king. This is why interfaces are part of solid, even in modern Java development. If you're not doing this, if you're writing a scanner, writing a class and extending the class with all of the different types and then having to do that every time you're doing it wrong, in my opinion, because you're never going to be able to extend that in any way that's going to be reusable for anybody. And maybe you don't care about that. I do. I want it to be reusable. I want to, I want to create, ultimately, I want to build up, you know, hundreds or more scan functions that can be used with anything whatsoever that implements the scanner interface. And that's why interfaces are so amazing. So I pass a scanner interface, I say scan some WS and I get a true or false. So this prints out false because the first number is a one. Now I added a constructor. There's really not constructors and go, but it's the closest word for it. And this takes an optional argument. Now constructors are very, very high level. So they don't have to be performant, right? Especially since you're not going to be buffering a lot. So I put an optional parameter to on the constructor. If you pass in a string or a reader or a bytes buffer, any of those things, it will work. And it will just slurp all of the thing into memory. And then it will allow the scanner to work on that, that bytes buffer. And so then we do this to say, so, so you can see here, we, we, it's, you see, it was false that it's not currently the scan WS failed here. Because why? And you'll notice too that it didn't advance the, it didn't advance the, it's not supposed to. That actually looks like a mistake. That might be a mistake. Let me check here. Oh, no, no, no, no. Okay, let's do this. Wait, what? Advance to nothing at all output. Example sum WS. I think I might have a problem with this one. Anyway, it's supposed to, I just barely fixed these. That's why I want to make sure it's okay. Sum WS. Is it not, isn't that working? I'm going to go try something. Go test, run sum WS. Well, let's turn a trace on. Oh, this is cool. I finally got traced to working again. So trace, that'll turn trace on. And when we run it, we should be able to see every step of the way. So the first call to scan, got it. That's what with the first, that's every time, every time scan gets called, it prints it. So scan, scan the one in, and that shows us the, from between zero and one, and then what's left in the buffer and there's a space. And then it shows we scanned a, a space and that was between one and two. It could be one and three, depending on the size of the rune. And then as the buffer is empty. So, so that shows it's doing what we wanted to, I just was, oh, I know why. It's doing that because it's actually, because this actually did do some scanning and it did not reset. Actually, that's a, that's a, that's a mistake. That's a mistake. I need to fix this. This, because it didn't scan, it should not have advanced the buffer at all. It should have been, I've got to do this. This is a nice catch. And again, this is just, this is the bug in this, in the scanner function only not the scanner itself. Trace is internal. Trace is, Trace is a part of this scanner implementation. It's not part of the forced interface. No, it's not. You don't have to have a scanner in there. It's, that's part of this scanner implementation. So, you know, I don't want to burden people with those kind of details that they, they want to do their own, they can, right? So, I mean, but yeah, you could extend that and do what you want with it. So this is, this is actually wrong. This should have been x00 and it should have been zero to zero and then it should have been a one here. That's what it should be. And then when you do the scan, it should go through and then it should have been a one and a zero to one. And then, and then that should have left us with a space and it should have been false and then it should have been true. This one should have probably printed true. Yeah. Something might be wrong with that today. All right. So that, that's how it should look. So let's, that means there's a problem with my function, my scan function, which is what I was debugging before, but let me show you how to do this. So there may actually be a problem with my mark and I'm, I'm hoping not to, I think, I think that might be, there might be something wrong with my mark, which is relatively new. But the point is, I don't know if you saw the functions I was writing yesterday, but these are way, way simpler, right? They just have to scan and check what the runes are and scan again and the, the idiom is the same no matter what. You take a, you take a bookmark to it at the beginning and you revert back to the bookmark if you're, if you didn't find anything, right? And you leave things as they are. Otherwise you let the scanner happily proceed along and it's not like there's a lot of cash in there so that you, you know, you'd have problems there. But yeah, I have, I have a problem with this one. I got to come back to that. I can't see it right out hand, but so this is actually, you know, this, this is supposed to scan as much white space as possible. I think the problem is, I don't know, we might be getting ruined. I don't know, I'll have to go debug this one. But if, if I wanted to just debug this one too, I could also just do this. I could just do s.trace and turn on the tracing in here while I'm doing this debugging. I can put it there in the test either way. Oh, it's not, that's right. I forgot about that. Man, this is going to be interesting. Yeah. Cause you just said, is that in the, is that in the debug output? Interesting. Yeah, I just realized I'm saying, because I locked down the interface and I'm going to keep a bunch of stuff out of here. I'm not going to be able to do because, because this is, expects a scanner interface and that means only things that are, are defined in the scanner interface can, can turn on. I wonder if we should make trace into the part of the interface. We should say you need to implement some form of activating trace. I don't think we should. I mean, I think, I think we should leave that in the tests stuff because people can set up their own test cases and then, and then call it that way. I, I, I don't know. I thought about it for a second though. This is just as good, right? Having the trace appear. Because this is, is, is using a specific scanner that fulfills the, the interface and therefore it can have extra things in it like trace. The other one doesn't have anything, any knowledge of it at all. And it shouldn't, right? We don't, that's again, I want to, I want to double check that everybody understands this. So we do not want people writing, you know, Pagan or any scanners functions that are going to be doing fancy things that are not defined by the interface. Because if you do, then they won't work with interchangeably with other scanners. And that, that's not ideal, right? We want to be able to have people write very highly optimized scanners however they want. I mean, all of them obviously are going to have the, the downside of having to call out to a function to do their thing. But that's, it's not too bad. But that way people can supplement the scanner that I've made or make their own or something like that. And they can, they can share all of these scan functions with each other. And we can make libraries of scan functions that do different amazing things. So it's basically like creating a library of regular expressions. And if you look at the Pagan stuff that I've been doing, you can see that we've got a lot of functions to write. So over the next year or two, I'll be implementing individual scan functions for the different types of stuff that is included here and in our tokens. And yes, we're going to have, we're going to have functions for things that are strictly static. And the reason is that is to keep everything functional because we need to be able to pass the scanner to it, right? We don't, if we didn't do that, we would have different kinds of dependencies. We would have dependencies on the Pagan like implementation to some degree, I think. And so that, I mean, it's not that much extra. Before I was like calling out to a function just to parse the references to the other functions. So there is, it's not going to be any less performant than any of the other stuff. And that's really premature optimization. If somebody really, really, really wants that level of performance, they probably should write their own scanner and, and, you know, maybe just use some of the scan functions without, without it and not, and not bibbed. So, but I will be writing like, I'll probably be auto generating a bunch of go code to, to, you know, to, to, to, to stand for each one of these, these scan functions. And then they'll all be under scan dot whatever. So I'll be able to just on any project, just be able to import artifacts, Rob slash Pagan slash scan, and I can get any and all of these that I want. And it's not that big, actually, because it's just text parsing, right? It, it seems big because it's a lot of code for us to write, but it, but it's most of it's going to get inlined and the size of the package isn't going to be too big. And, and then we can, we get kind of like this regular expression engine that's on steroids, because now we can just write our own recursive descent parsers as easily or if not easier than we could write regex, you know, complex regex expressions. And that, that to me is kind of the Holy Grail, because that's what I want to do. I, I have like four or five grammars that I want to finish that I'm kind of waiting on. And this is, that's, that's where, that's where it leaves us. All right. So I need to come back and fix this white space one. Let's go back and look at one that maybe works better. So here we have, and I put the pagan line up here. So an end of the line is, you know, we scan the found Boolean stuff. We don't really need that. I could have just done a return right here and call it a day and not gotten all the way down here. And the reason I didn't do that initially is because I wanted to think about how this code could be auto generated. But now that I'm looking at it, I am totally okay doing that. So, so we can just do a return true there. Here we can just do a return true. Yeah. And if we make it down this far, that means we didn't find it. And we need to do that. So that this is, this is not hungry. If you're using something that's hungry. Yeah, you might, you might have a different problem, right? Because, you know, you need to, yeah, you need to, if you're having something that's like hungry and greedy, you need to like count all the fines and you'll see that, you'll see that kind of thing happening over time. Oopsie, did I refer to found in here? Return false. So I mean, that's a simplification we can do. Again, these are, I want these to be highly optimized. Another reason, by the way, that I think code generation is probably the wrong way to go. And the more I keep coming back to this, the more I think that hand crafting a recursive descent parser from a huge library of existing scanners, scan scan functions is a better idea. Because of this problem that you just saw, the optimization I just made is the kind of thing that would take an extreme amount of intelligence in the code to be able to write it in a code generator. Whereas if I'm just writing the parser, I can take, I can do tricks and stuff inside of my functional parser to make it really, really optimized for this particular scenario, you know, and, and I can do things that couldn't be done if I were to just to generalize the generation of this code from the syntax. So what I'm saying, and I'm going to put this in here is that I am, I'm kind of souring on the idea of code generation. So I'm souring on the idea of Pagan to code generation, because it's removing, you know, it, it, it prevents, it precludes optimizations that only, that only a person could do. And, you know, people definitely do this. And if you're going to, I mean, at the end of the day, we're writing a compiler when we do that kind of thing. And, you know, there are people that have spent their entire lives dedicated to compiler optimizations. Well, one of the reasons that having a human write a scan function is better is because depending on the language they're writing it for, they might already know how the compiler is going to inline that code. So, so, you know, having some generic size rendering of the code may not be able to take advantage of those things. And, you know, premature optimization, yes, right, we want to avoid premature optimization, but, but at the same time, we don't want to be forced into doing things that, that we could do because we know about them later on. We could come back to the code and we could actually say, well, okay, let's optimize this one, because this is that my pagan function for parsing, you know, wide space, the most important thing that I'm ever going to write, it's going to be used by millions of people or whatever. And, and I should really, really optimize that one function. And then everybody can spend their time optimizing the functions that we have for parsing those specific things. And we can maintain a community library of this, rather than having everybody write the best, you know, their own wide space parser, right? So we can actually have a collective community of contributions that from people who know about parsing, or really, you know, amazing Go specialists who have, have, you know, know how to optimize code based on what they're, what they know about inlining. So, so yeah, no more code generation, just a lot of pre-generated libraries that are immediately importable. And then we can just write, you know, in if statements and switch statements, and you can write your own thing really quickly. And I think that's really going to be the new normal useful form overlooks. Yeah. And so, so, so yeah, I think, I think, I think that that's, that's kind of how I am with this. That is why you're developing anything. Yeah. I, I, I think that the code generation thing, I mean, this doesn't mean we're not going to do some code generation, right? But we're going to statefully code generate like all the functions for the, the 200 or so Unicode classes, which by the way, already have functions. Yeah. So for those kind of things, we're just, that's exactly how Go does it, by the way. Go takes that document, and it generates the Go code from straight up from the, from the Unicode specification document. And it has a, you know, a whole library of, of, you know, true or false kind of things, right? But it's not a scanner. And so the only thing we're going to have to do in the Go one is basically the same idea, but we're going to say, okay, is this thing a thing? And then, and then we'll make a sum variation as well, so that it'll be like one or more of those things, right? And, and all that code will get auto generated. So we'll have a pretty big library of scanners that'll be developed that you can then make your recursive descent parsers from. And maybe we can get somebody else to actually think it's a good idea besides me. Optimizing a lot first is that you can find you don't need the functions you're optimizing. No, that's right. So I'm saying, so a lot of them, yeah, you could combine the two things together or something, right? Yeah. So, so I think, I think I'm kind of happy with this where we're going with this now. Now I still have this, this bug here, my white space bug. But the other one is fine. Let's, let's try to run that one. Let's do run. What was it the end of line? End of line, I think, right? Oops, we need to let's turn scanning on end of line. So you can see it end line. Then there's lots of in lines. So she was the carriage feed one. Actually, let's just turn it on for the whole, the whole scanner. Yeah, scanner scanner has a trace for the whole entire package if you want to turn tracing on on everything. Yeah. Trace equals, I'm probably have to do an init here. Trace equals one. Yeah, that's going to say you need to put that in an init. All right, fine. This is just for now. There's other testing ways to do this, but I'll just do that for now. So we could go test. So actually, this is going to show every single parts that we did. I'm so happy with this. So when you turn the trace on, when you turn it on this way, it'll actually give you like the full thing. So here it was, it was, it, it read the first carriage return and then a line return and then another line return. So that, that was that one that we did. And there's another one. So these are all the different ones. There's no other printing statements going on in there, but you can kind of watch what's getting parsed as you go and check on it. And you can go, go look at that and see if you like it. But yeah, I mean, it's working without that portal pass. I just got that white space one I have to figure out. So I think that's enough for this video. I just, I just wanted to show where I was. Some of the, I mean, I don't got the, the, the end paragraph turns out to be end block. So remember yesterday I was doing basic markdown and I was like, hmm, we need to delineate our blocks. Well, what is, what do we have? We have any number of spaces and then a greedy include of, of white space and line returns, you know, and that's what this is. So I had to actually re, I had to rewrite it and say, do I have the end of, do I have the end of the data? Do I have an end of line and then the end of the data? Or do I have two end of lines, which are, you know, the greedy thing and then the white space splat and, you know, peg, uh, repeat operators are greedy by default. So that says, grab as much white space as you can. As far as I know, I might have that wrong, but grab as much white space as you can and then make sure you have this at the end, right? Now it may be that I have to, uh, uh, if I were to put this up here in the front, then it would be non greedy. So it would it would get, you know, it would, it would get the first one. So the first match of, I had that happening before I had the first match of, of a line of double line returns and it got the first one. So that's how you, you do non greedy is you put that stuff up in front here, but you have to kind of look at the peg and syntax, the peg syntax to get that. That's, that's from Brian Ford. That's not for me. Uh, but, and I still have to go look it up here as well. But it's, I, once you get it, it's much easier than regular expressions. It's not, actually it has positive negative look ahead and all that kind of thing, which regular expressions, depending on which engine you're using, don't really do well. Not to mention, you know, the ability to capture thing. So, and, and I use the, I use the block here and go to, uh, which I actually prefer to for loops because they just are so much cleaner. Um, because you just know you're going to go up to the top again and you know, you know, the thing I like about it's much easier. I mean, it's much harder to write an infinite loop with a labeled block than it is with an infinite forever loop, which is just for, and I used to do them that way. Um, because, I mean, you definitely can, but you have to explicitly create an infinite loop that keeps going to the top again, right? So, it's kind of like a do while. Um, and you see this all the time in parsers. This is in go, it's in, and goes compiler for the language that go to is a very real, uh, solid thing to use for, uh, for compilers and for parsers and scanners. And it saves you from any kind of functional recursion, which is the devil when it comes to performance and parsers because you hit, you hit, um, you hit, you know, you hit, uh, indirection functional loops, uh, functional recursion loops and stuff like that. Some languages is the preferred way to do it, but, but, but most of the languages or not, most of them want you to just stay within there and kind of figure out a way to short circuit and go back up to the top. And it's more performant that way too. So this one has to have the whole notion of a found Boolean in it because even if I find one, I still want to look for more. I still keep wanting to look for more until I get, I'm greedily get the, the last one, right? And I, before I added a notion of a, of a found loop in that I, I wasn't getting everything. And so what it does is it keeps getting stuff until it hits something that is not valid. And it's like, okay, I finally run out, but did I ever find anything along the way? I was like, Oh yeah. Okay. Well, what was the last one that I did find? And, and then, you know, it can, it can tell you that thing. Um, and, and that's what the go to is. Um, this is actually wrong. I'm just realizing I have some problems with this. Yeah. It's funny because now that it's cleaner and I've got to spend my whole day fixing up all of this syntax, I can see that this is probably wrong because this is, this is going to, uh, this is, if it, if, oh no, no, I'm sorry. No, I'm, I'm sorry. This is only if it's not found. Yeah. This is only if it's not found. Yeah. So scanners do not advance. So the rule, this is a kind of a hard thing to, to come up with when you're trying to figure out how to make your parsers and functions and stuff. But the easiest rule is for a scanner is if it scans, it returns true and it advances the scanner. If it doesn't to the next thing, right to the beginning of the next thing, it doesn't scan that thing. It puts it right to the beginning of it. If it doesn't, if it doesn't scan anything, it needs to leave the scanner exactly how it was before it was called. And in order to accomplish that, you need to take a bookmark so that you can snap back to it, right? And I put go to here, I could probably do snap, but that would people think I would snap the shouting or whatever, go to use the one I'm going to use there. So, so that actually sets it to the cursor and the cursor is three things. It's the byte index in the buffer by buffer array of the, uh, you know, of, of the first item in, in the room, the first bite of the room. Uh, it is the room itself, a copy of the room. That's what, that's what we get when we set, when we get, when we get, go get dot rune. Um, and, and it is, um, it's also the, uh, uh, the, the, the, uh, end, the end of the room. So the, the byte pointing to the byte array to the beginning of the next thing, which is like maybe one or two, three things away. And that's, that's, that's where we got this thing. So we get like a three to four. If, if I were to scan like, uh, uh, tomato emoji, um, and I don't know where to go back to mark point, if it found the end of paragraph, it considers it advanced and no more go back to mark the point. You don't need to mark the point because the scan automatically advanced it. Yeah. Because any of the scans that fail, I'm pretty sure I'm gonna have to go back but there, there are cases, uh, uh, yeah, I read that. I have that book. I wrote that years ago, a couple of years ago. I have the PDF somewhere. Yeah, actually bought it. Uh, it's, there's that, there's that one. There's two or three go scanners in the go code base. And then there's a website that has right your own, uh, scanner and go. There's like, those are the three main things that I'd recommend if you want to start doing this kind of fun stuff. Um, but yeah, they're, they're pretty cool. Um, and you know, I'm obsessed with parsing. I'm not very good at it, but I'm obsessed with it. So, so anyway, um, mostly I'm obsessed with language and so grammars are a part of language and that's why I like it so much. Um, this is something I don't understand. What I want to do is I want to be able to specify my bonsai command lines from a pagan. Wouldn't that be cool? Uh, there, there, there is a writing compilers. Oh really? Yeah. I have to go look at that one. Um, so, so yeah, I mean a compiler is the next step, right? It's like bringing it all together and doing something with the thing you get out of it. And we, we don't have any AST, any notions of AST going on yet. That is coming. Uh, I already have all the data structures for that developed that I'm going to use for my AST. Um, and, but yeah. So, you know, you got to have push and pop for ASTs. It's like crazy. Um, yeah. I mean the hardest part, the hardest part with the AST, and we're going to get into this, is how to throw away, uh, elements of the tree that you, you can't just pop back and kind of, you know, you can't just pop back to the latest bookmark when you're doing parsing because you have all this data that you parse that you can't throw away. And it's very complicated. You can't throw it away because you don't know how much of it to throw away. And, and that's, that's going to be a big piece of this that might, that might, you know, I still have other things to do. This isn't my main, my main thing. So, uh, but I, I am interested in this. Um, so far the test case on this is so good, so important that you have lots of test cases on this. I'm pretty sure this one is good. Um, but I don't know, we'll go take a look at it later. And, and, and you know, that, but I, here's the thing, I don't want to have to keep revising all of my parsers. I wrote, I mean, I, I, I'm going to go back and open up my old pagan, uh, dev, uh, you know, I wrote an entire recursive descent parser for the pagan language itself, if I have them. Uh, and so that's going to be something that we're going to come up with later, but, um, but, but so I don't, I don't, I don't know, I don't know how that's going to, that's going to end up going down. Uh, because I, I want to be able to pull out some of that stuff from here and just reuse it because I, I've already got all the algorithms there and I can just reuse those algorithms. So that's pretty much it for YouTube. So if you want to stay tuned and to watch stuff about the pagan and keg stuff, uh, I'm probably not going to be working on much of this. I hopefully not the rest of this week. I have got a ton of work to catch up on, uh, that I'll be doing like for the rest of tonight and tomorrow morning early and, um, and we'll be, yeah, I'm going to be doing, you know, a lot of that stuff. Um, but this is sort of related to stuff we want to do at work in terms of like documentation validation. That's where it came from originally. And that's, if you want to stay tuned, we, we'll do some more of that. I, I am going to implement basic and D M D is, uh, as a, as a grammar and I'm going to be using this and we should get pretty high performance on it actually. Uh, we should have performance that rivals gold mark, uh, which because it doesn't have as much to do. Uh, so we should have performance that rivals gold mark, which is pretty much the go to standard for, uh, markdown parsing and go right now. And we'll be able to compare and do some benchmarks on that a little bit later. Um, so have fun parsing and come on by sometime. Talk to you later.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.96, "text": " Go. So, lots of changes if you've been following the keg and the peg and stuff I've been doing over", "tokens": [50364, 1037, 13, 407, 11, 3195, 295, 2962, 498, 291, 600, 668, 3480, 264, 803, 70, 293, 264, 17199, 293, 1507, 286, 600, 668, 884, 670, 50712], "temperature": 0.0, "avg_logprob": -0.17023229598999023, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.06938254088163376}, {"id": 1, "seek": 0, "start": 6.96, "end": 14.0, "text": " the years. I went to bed last night with my head working on a bunch of problems. I woke up and I", "tokens": [50712, 264, 924, 13, 286, 1437, 281, 2901, 1036, 1818, 365, 452, 1378, 1364, 322, 257, 3840, 295, 2740, 13, 286, 12852, 493, 293, 286, 51064], "temperature": 0.0, "avg_logprob": -0.17023229598999023, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.06938254088163376}, {"id": 2, "seek": 0, "start": 14.0, "end": 20.72, "text": " just had an idea I had to finish and I've been working on it straight since, God, I don't know,", "tokens": [51064, 445, 632, 364, 1558, 286, 632, 281, 2413, 293, 286, 600, 668, 1364, 322, 309, 2997, 1670, 11, 1265, 11, 286, 500, 380, 458, 11, 51400], "temperature": 0.0, "avg_logprob": -0.17023229598999023, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.06938254088163376}, {"id": 3, "seek": 0, "start": 20.72, "end": 25.52, "text": " like eight o'clock this morning. It's somewhat related to work. Don't worry, I'll make up the", "tokens": [51400, 411, 3180, 277, 6, 9023, 341, 2446, 13, 467, 311, 8344, 4077, 281, 589, 13, 1468, 380, 3292, 11, 286, 603, 652, 493, 264, 51640], "temperature": 0.0, "avg_logprob": -0.17023229598999023, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.06938254088163376}, {"id": 4, "seek": 2552, "start": 25.52, "end": 32.4, "text": " work time tomorrow and the next day and the next day, but this is really important because it's", "tokens": [50364, 589, 565, 4153, 293, 264, 958, 786, 293, 264, 958, 786, 11, 457, 341, 307, 534, 1021, 570, 309, 311, 50708], "temperature": 0.0, "avg_logprob": -0.1300249502692424, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.021280352026224136}, {"id": 5, "seek": 2552, "start": 32.4, "end": 39.84, "text": " so key to everything else that I'm doing. So, let me try to stick with the highlights", "tokens": [50708, 370, 2141, 281, 1203, 1646, 300, 286, 478, 884, 13, 407, 11, 718, 385, 853, 281, 2897, 365, 264, 14254, 51080], "temperature": 0.0, "avg_logprob": -0.1300249502692424, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.021280352026224136}, {"id": 6, "seek": 2552, "start": 41.28, "end": 49.36, "text": " and hell, why don't I actually make a, use my YouTube thing. We're going to make a directory", "tokens": [51152, 293, 4921, 11, 983, 500, 380, 286, 767, 652, 257, 11, 764, 452, 3088, 551, 13, 492, 434, 516, 281, 652, 257, 21120, 51556], "temperature": 0.0, "avg_logprob": -0.1300249502692424, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.021280352026224136}, {"id": 7, "seek": 4936, "start": 49.36, "end": 60.480000000000004, "text": " for this. We'll call it updates on peg. Actually, let's call it something more specific than let's say", "tokens": [50364, 337, 341, 13, 492, 603, 818, 309, 9205, 322, 17199, 13, 5135, 11, 718, 311, 818, 309, 746, 544, 2685, 813, 718, 311, 584, 50920], "temperature": 0.0, "avg_logprob": -0.19996472767421178, "compression_ratio": 1.146067415730337, "no_speech_prob": 0.0367545410990715}, {"id": 8, "seek": 6048, "start": 60.48, "end": 86.47999999999999, "text": " a peg in scanner interface and functions. So, what I've done", "tokens": [50364, 257, 17199, 294, 30211, 9226, 293, 6828, 13, 407, 11, 437, 286, 600, 1096, 51664], "temperature": 0.0, "avg_logprob": -0.34482983981861787, "compression_ratio": 0.9090909090909091, "no_speech_prob": 0.18232397735118866}, {"id": 9, "seek": 9048, "start": 90.88000000000001, "end": 97.92, "text": " so I mentioned, I mentioned the other day that interface", "tokens": [50384, 370, 286, 2835, 11, 286, 2835, 264, 661, 786, 300, 9226, 50736], "temperature": 0.0, "avg_logprob": -0.3088243537478977, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.006192449014633894}, {"id": 10, "seek": 9048, "start": 100.88000000000001, "end": 108.32000000000001, "text": " and functions. Is that right? Peg and scanner interface and functions. Yeah, I mean,", "tokens": [50884, 293, 6828, 13, 1119, 300, 558, 30, 28007, 293, 30211, 9226, 293, 6828, 13, 865, 11, 286, 914, 11, 51256], "temperature": 0.0, "avg_logprob": -0.3088243537478977, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.006192449014633894}, {"id": 11, "seek": 10832, "start": 108.32, "end": 116.55999999999999, "text": " and she'll have a tool to do all that. So, okay, so", "tokens": [50364, 293, 750, 603, 362, 257, 2290, 281, 360, 439, 300, 13, 407, 11, 1392, 11, 370, 50776], "temperature": 0.0, "avg_logprob": -0.3285285711288452, "compression_ratio": 0.9107142857142857, "no_speech_prob": 0.06367863714694977}, {"id": 12, "seek": 11656, "start": 116.56, "end": 127.12, "text": " so my my peg in scanner implementation now conforms", "tokens": [50364, 370, 452, 452, 17199, 294, 30211, 11420, 586, 18975, 82, 50892], "temperature": 0.0, "avg_logprob": -0.33233936854771207, "compression_ratio": 1.5578947368421052, "no_speech_prob": 0.0020187734626233578}, {"id": 13, "seek": 11656, "start": 130.88, "end": 145.28, "text": " now conforms to a common peg in not scanner interface so that other scanners can be implemented.", "tokens": [51080, 586, 18975, 82, 281, 257, 2689, 17199, 294, 406, 30211, 9226, 370, 300, 661, 795, 25792, 393, 312, 12270, 13, 51800], "temperature": 0.0, "avg_logprob": -0.33233936854771207, "compression_ratio": 1.5578947368421052, "no_speech_prob": 0.0020187734626233578}, {"id": 14, "seek": 14656, "start": 147.52, "end": 151.52, "text": " My people that conform to it.", "tokens": [50412, 1222, 561, 300, 18975, 281, 309, 13, 50612], "temperature": 0.0, "avg_logprob": -0.307288972955001, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.0003920119779650122}, {"id": 15, "seek": 14656, "start": 157.28, "end": 162.0, "text": " So, the reason that I made an interface, why an interface", "tokens": [50900, 407, 11, 264, 1778, 300, 286, 1027, 364, 9226, 11, 983, 364, 9226, 51136], "temperature": 0.0, "avg_logprob": -0.307288972955001, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.0003920119779650122}, {"id": 16, "seek": 14656, "start": 165.28, "end": 170.08, "text": " so that the library of scanner functions of scan functions", "tokens": [51300, 370, 300, 264, 6405, 295, 30211, 6828, 295, 11049, 6828, 51540], "temperature": 0.0, "avg_logprob": -0.307288972955001, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.0003920119779650122}, {"id": 17, "seek": 17008, "start": 170.8, "end": 176.64000000000001, "text": " can be interchangeable", "tokens": [50400, 393, 312, 30358, 712, 50692], "temperature": 0.0, "avg_logprob": -0.17749575206211635, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.006288920994848013}, {"id": 18, "seek": 17008, "start": 179.52, "end": 188.88000000000002, "text": " with different scanner implementations. And if that's, that is the main reason.", "tokens": [50836, 365, 819, 30211, 4445, 763, 13, 400, 498, 300, 311, 11, 300, 307, 264, 2135, 1778, 13, 51304], "temperature": 0.0, "avg_logprob": -0.17749575206211635, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.006288920994848013}, {"id": 19, "seek": 17008, "start": 190.0, "end": 196.24, "text": " And let me show you what I mean by that. So, if you go to, so this is all, by the way,", "tokens": [51360, 400, 718, 385, 855, 291, 437, 286, 914, 538, 300, 13, 407, 11, 498, 291, 352, 281, 11, 370, 341, 307, 439, 11, 538, 264, 636, 11, 51672], "temperature": 0.0, "avg_logprob": -0.17749575206211635, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.006288920994848013}, {"id": 20, "seek": 19624, "start": 196.24, "end": 204.56, "text": " this is all I actually put in the thing related in here. So, here's the pages that", "tokens": [50364, 341, 307, 439, 286, 767, 829, 294, 264, 551, 4077, 294, 510, 13, 407, 11, 510, 311, 264, 7183, 300, 50780], "temperature": 0.0, "avg_logprob": -0.23023775308439048, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012621003203094006}, {"id": 21, "seek": 19624, "start": 204.56, "end": 214.96, "text": " we're going to. We're going to HTTP, github.com, rdxrub, peg in, peg in dash spec.", "tokens": [50780, 321, 434, 516, 281, 13, 492, 434, 516, 281, 33283, 11, 290, 355, 836, 13, 1112, 11, 367, 67, 87, 81, 836, 11, 17199, 294, 11, 17199, 294, 8240, 1608, 13, 51300], "temperature": 0.0, "avg_logprob": -0.23023775308439048, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012621003203094006}, {"id": 22, "seek": 19624, "start": 217.04000000000002, "end": 219.76000000000002, "text": " And that's pretty much it. If you go there, you'll find everything.", "tokens": [51404, 400, 300, 311, 1238, 709, 309, 13, 759, 291, 352, 456, 11, 291, 603, 915, 1203, 13, 51540], "temperature": 0.0, "avg_logprob": -0.23023775308439048, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012621003203094006}, {"id": 23, "seek": 19624, "start": 220.72, "end": 223.60000000000002, "text": " It used to be that I had it all over the place. And I used to have, there's this,", "tokens": [51588, 467, 1143, 281, 312, 300, 286, 632, 309, 439, 670, 264, 1081, 13, 400, 286, 1143, 281, 362, 11, 456, 311, 341, 11, 51732], "temperature": 0.0, "avg_logprob": -0.23023775308439048, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012621003203094006}, {"id": 24, "seek": 22360, "start": 223.6, "end": 228.4, "text": " there's peg in dot dev, but that's kind of, it's kind of older,", "tokens": [50364, 456, 311, 17199, 294, 5893, 1905, 11, 457, 300, 311, 733, 295, 11, 309, 311, 733, 295, 4906, 11, 50604], "temperature": 0.0, "avg_logprob": -0.16822046256927123, "compression_ratio": 1.58125, "no_speech_prob": 0.0012447835179045796}, {"id": 25, "seek": 22360, "start": 232.56, "end": 240.4, "text": " but a little older and out of date. So, it's still there. I'm reforming the spec as we go.", "tokens": [50812, 457, 257, 707, 4906, 293, 484, 295, 4002, 13, 407, 11, 309, 311, 920, 456, 13, 286, 478, 8290, 278, 264, 1608, 382, 321, 352, 13, 51204], "temperature": 0.0, "avg_logprob": -0.16822046256927123, "compression_ratio": 1.58125, "no_speech_prob": 0.0012447835179045796}, {"id": 26, "seek": 22360, "start": 243.35999999999999, "end": 251.84, "text": " So, we want, okay, so let me, let me show you why. So, if we go to the peg in scanner itself here,", "tokens": [51352, 407, 11, 321, 528, 11, 1392, 11, 370, 718, 385, 11, 718, 385, 855, 291, 983, 13, 407, 11, 498, 321, 352, 281, 264, 17199, 294, 30211, 2564, 510, 11, 51776], "temperature": 0.0, "avg_logprob": -0.16822046256927123, "compression_ratio": 1.58125, "no_speech_prob": 0.0012447835179045796}, {"id": 27, "seek": 25184, "start": 251.84, "end": 258.72, "text": " right? So, I mean, what is the end goal? The end goal is for us to be able to parse any kind", "tokens": [50364, 558, 30, 407, 11, 286, 914, 11, 437, 307, 264, 917, 3387, 30, 440, 917, 3387, 307, 337, 505, 281, 312, 1075, 281, 48377, 604, 733, 50708], "temperature": 0.0, "avg_logprob": -0.14673456331578696, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0015977326547726989}, {"id": 28, "seek": 25184, "start": 258.72, "end": 264.96, "text": " of language. And we started with base ML, or base MD. Now, you'll remember I was basic MD.", "tokens": [50708, 295, 2856, 13, 400, 321, 1409, 365, 3096, 21601, 11, 420, 3096, 22521, 13, 823, 11, 291, 603, 1604, 286, 390, 3875, 22521, 13, 51020], "temperature": 0.0, "avg_logprob": -0.14673456331578696, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0015977326547726989}, {"id": 29, "seek": 25184, "start": 264.96, "end": 273.04, "text": " I was writing a basic MD scanner. And here is the, the, the, so this was all brought about because", "tokens": [51020, 286, 390, 3579, 257, 3875, 22521, 30211, 13, 400, 510, 307, 264, 11, 264, 11, 264, 11, 370, 341, 390, 439, 3038, 466, 570, 51424], "temperature": 0.0, "avg_logprob": -0.14673456331578696, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0015977326547726989}, {"id": 30, "seek": 27304, "start": 273.04, "end": 292.64000000000004, "text": " of this. So, I'm just going to put all of this precipitated by the basic, basic MD, parser,", "tokens": [50364, 295, 341, 13, 407, 11, 286, 478, 445, 516, 281, 829, 439, 295, 341, 23354, 18266, 538, 264, 3875, 11, 3875, 22521, 11, 21156, 260, 11, 51344], "temperature": 0.0, "avg_logprob": -0.22349188245576004, "compression_ratio": 1.3432835820895523, "no_speech_prob": 0.0037652887403964996}, {"id": 31, "seek": 27304, "start": 292.64000000000004, "end": 300.88, "text": " that I was right. I mean, a scanner, parser, AST. So, I started writing that last night.", "tokens": [51344, 300, 286, 390, 558, 13, 286, 914, 11, 257, 30211, 11, 21156, 260, 11, 316, 6840, 13, 407, 11, 286, 1409, 3579, 300, 1036, 1818, 13, 51756], "temperature": 0.0, "avg_logprob": -0.22349188245576004, "compression_ratio": 1.3432835820895523, "no_speech_prob": 0.0037652887403964996}, {"id": 32, "seek": 30088, "start": 300.88, "end": 306.71999999999997, "text": " And that was all good and everything. But it became clear to me that there, I mean,", "tokens": [50364, 400, 300, 390, 439, 665, 293, 1203, 13, 583, 309, 3062, 1850, 281, 385, 300, 456, 11, 286, 914, 11, 50656], "temperature": 0.0, "avg_logprob": -0.14668621122837067, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0014103285502642393}, {"id": 33, "seek": 30088, "start": 306.71999999999997, "end": 310.32, "text": " some of these functions, I'm going to show you one, some of these functions that I have written,", "tokens": [50656, 512, 295, 613, 6828, 11, 286, 478, 516, 281, 855, 291, 472, 11, 512, 295, 613, 6828, 300, 286, 362, 3720, 11, 50836], "temperature": 0.0, "avg_logprob": -0.14668621122837067, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0014103285502642393}, {"id": 34, "seek": 30088, "start": 310.32, "end": 317.68, "text": " I have written them so many times. I swear, I have written, so like, I don't know how many,", "tokens": [50836, 286, 362, 3720, 552, 370, 867, 1413, 13, 286, 11902, 11, 286, 362, 3720, 11, 370, 411, 11, 286, 500, 380, 458, 577, 867, 11, 51204], "temperature": 0.0, "avg_logprob": -0.14668621122837067, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0014103285502642393}, {"id": 35, "seek": 30088, "start": 317.68, "end": 320.48, "text": " so I didn't, thank God I didn't post it to YouTube. I'm not going to force it on you.", "tokens": [51204, 370, 286, 994, 380, 11, 1309, 1265, 286, 994, 380, 2183, 309, 281, 3088, 13, 286, 478, 406, 516, 281, 3464, 309, 322, 291, 13, 51344], "temperature": 0.0, "avg_logprob": -0.14668621122837067, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0014103285502642393}, {"id": 36, "seek": 30088, "start": 321.04, "end": 328.4, "text": " But I did, I must have written a, you know, a white space or an end of line parser,", "tokens": [51372, 583, 286, 630, 11, 286, 1633, 362, 3720, 257, 11, 291, 458, 11, 257, 2418, 1901, 420, 364, 917, 295, 1622, 21156, 260, 11, 51740], "temperature": 0.0, "avg_logprob": -0.14668621122837067, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0014103285502642393}, {"id": 37, "seek": 32840, "start": 328.4, "end": 335.03999999999996, "text": " probably a dozen times, different ways. Because I don't have, I haven't had a standardized way", "tokens": [50364, 1391, 257, 16654, 1413, 11, 819, 2098, 13, 1436, 286, 500, 380, 362, 11, 286, 2378, 380, 632, 257, 31677, 636, 50696], "temperature": 0.0, "avg_logprob": -0.09097030981263118, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.035141054540872574}, {"id": 38, "seek": 32840, "start": 337.84, "end": 345.2, "text": " to abstract the scanner stuff in a way that didn't require rewriting a scanner. I mean,", "tokens": [50836, 281, 12649, 264, 30211, 1507, 294, 257, 636, 300, 994, 380, 3651, 319, 19868, 257, 30211, 13, 286, 914, 11, 51204], "temperature": 0.0, "avg_logprob": -0.09097030981263118, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.035141054540872574}, {"id": 39, "seek": 32840, "start": 345.2, "end": 350.08, "text": " I've written probably, including an extremely complicated one. If you go back in my YouTube", "tokens": [51204, 286, 600, 3720, 1391, 11, 3009, 364, 4664, 6179, 472, 13, 759, 291, 352, 646, 294, 452, 3088, 51448], "temperature": 0.0, "avg_logprob": -0.09097030981263118, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.035141054540872574}, {"id": 40, "seek": 35008, "start": 350.08, "end": 357.84, "text": " videos, there's something I was writing, it was called go, was it go, go compatible,", "tokens": [50364, 2145, 11, 456, 311, 746, 286, 390, 3579, 11, 309, 390, 1219, 352, 11, 390, 309, 352, 11, 352, 18218, 11, 50752], "temperature": 0.0, "avg_logprob": -0.15304488466497054, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.14802289009094238}, {"id": 41, "seek": 35008, "start": 357.84, "end": 363.76, "text": " peg in expressions? And it was actually go code that could be passed into symbols,", "tokens": [50752, 17199, 294, 15277, 30, 400, 309, 390, 767, 352, 3089, 300, 727, 312, 4678, 666, 16944, 11, 51048], "temperature": 0.0, "avg_logprob": -0.15304488466497054, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.14802289009094238}, {"id": 42, "seek": 35008, "start": 363.76, "end": 367.52, "text": " that could be passed into another function that would parse it, and then it would, you know,", "tokens": [51048, 300, 727, 312, 4678, 666, 1071, 2445, 300, 576, 48377, 309, 11, 293, 550, 309, 576, 11, 291, 458, 11, 51236], "temperature": 0.0, "avg_logprob": -0.15304488466497054, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.14802289009094238}, {"id": 43, "seek": 35008, "start": 367.52, "end": 371.84, "text": " it would do its thing. It was pretty cool. But every time I've written one, and then the most", "tokens": [51236, 309, 576, 360, 1080, 551, 13, 467, 390, 1238, 1627, 13, 583, 633, 565, 286, 600, 3720, 472, 11, 293, 550, 264, 881, 51452], "temperature": 0.0, "avg_logprob": -0.15304488466497054, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.14802289009094238}, {"id": 44, "seek": 35008, "start": 371.84, "end": 378.4, "text": " recent iteration of my scanner that I wrote, I just ripped all that crap out. I was like,", "tokens": [51452, 5162, 24784, 295, 452, 30211, 300, 286, 4114, 11, 286, 445, 22780, 439, 300, 12426, 484, 13, 286, 390, 411, 11, 51780], "temperature": 0.0, "avg_logprob": -0.15304488466497054, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.14802289009094238}, {"id": 45, "seek": 37840, "start": 378.4, "end": 383.84, "text": " I want the ultimate and minimal. And thank God I did that because I actually ended up", "tokens": [50364, 286, 528, 264, 9705, 293, 13206, 13, 400, 1309, 1265, 286, 630, 300, 570, 286, 767, 4590, 493, 50636], "temperature": 0.0, "avg_logprob": -0.0983584941118613, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.00015356121002696455}, {"id": 46, "seek": 37840, "start": 384.79999999999995, "end": 387.84, "text": " coming up with, so here's an implementation of the new scanner interface", "tokens": [50684, 1348, 493, 365, 11, 370, 510, 311, 364, 11420, 295, 264, 777, 30211, 9226, 50836], "temperature": 0.0, "avg_logprob": -0.0983584941118613, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.00015356121002696455}, {"id": 47, "seek": 37840, "start": 391.12, "end": 397.44, "text": " that anybody can write. And all it has is, I mean, some of this stuff is internal,", "tokens": [51000, 300, 4472, 393, 2464, 13, 400, 439, 309, 575, 307, 11, 286, 914, 11, 512, 295, 341, 1507, 307, 6920, 11, 51316], "temperature": 0.0, "avg_logprob": -0.0983584941118613, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.00015356121002696455}, {"id": 48, "seek": 37840, "start": 398.15999999999997, "end": 403.52, "text": " but you know, this, let me show you the interface first, actually. So let's start with the interface.", "tokens": [51352, 457, 291, 458, 11, 341, 11, 718, 385, 855, 291, 264, 9226, 700, 11, 767, 13, 407, 718, 311, 722, 365, 264, 9226, 13, 51620], "temperature": 0.0, "avg_logprob": -0.0983584941118613, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.00015356121002696455}, {"id": 49, "seek": 40352, "start": 403.76, "end": 413.44, "text": " So the scanner interface is in my types. The scanner interface is just a scanner. It's a", "tokens": [50376, 407, 264, 30211, 9226, 307, 294, 452, 3467, 13, 440, 30211, 9226, 307, 445, 257, 30211, 13, 467, 311, 257, 50860], "temperature": 0.0, "avg_logprob": -0.12661155389279735, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.00013982107338961214}, {"id": 50, "seek": 40352, "start": 413.44, "end": 419.84, "text": " rune scanner that is aware of the beginning and ending of each rune that it scans, which can", "tokens": [50860, 1190, 68, 30211, 300, 307, 3650, 295, 264, 2863, 293, 8121, 295, 1184, 1190, 68, 300, 309, 35116, 11, 597, 393, 51180], "temperature": 0.0, "avg_logprob": -0.12661155389279735, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.00013982107338961214}, {"id": 51, "seek": 40352, "start": 419.84, "end": 424.0, "text": " be more than one byte, right? So people know this. So you can imagine a cursor going, you know,", "tokens": [51180, 312, 544, 813, 472, 40846, 11, 558, 30, 407, 561, 458, 341, 13, 407, 291, 393, 3811, 257, 28169, 516, 11, 291, 458, 11, 51388], "temperature": 0.0, "avg_logprob": -0.12661155389279735, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.00013982107338961214}, {"id": 52, "seek": 40352, "start": 424.0, "end": 428.08, "text": " through the, through the screen like this, like with an emoji on there. And sometimes it's a thing.", "tokens": [51388, 807, 264, 11, 807, 264, 2568, 411, 341, 11, 411, 365, 364, 31595, 322, 456, 13, 400, 2171, 309, 311, 257, 551, 13, 51592], "temperature": 0.0, "avg_logprob": -0.12661155389279735, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.00013982107338961214}, {"id": 53, "seek": 42808, "start": 428.08, "end": 434.24, "text": " So in fact, the scanner has this idea of a rune cursor. And I used, I mean, I thought with", "tokens": [50364, 407, 294, 1186, 11, 264, 30211, 575, 341, 1558, 295, 257, 1190, 68, 28169, 13, 400, 286, 1143, 11, 286, 914, 11, 286, 1194, 365, 50672], "temperature": 0.0, "avg_logprob": -0.1733671872670414, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0008040628163143992}, {"id": 54, "seek": 42808, "start": 434.24, "end": 438.08, "text": " myself about whether to call it cursor or not, I didn't end up keeping a concept of cursor here,", "tokens": [50672, 2059, 466, 1968, 281, 818, 309, 28169, 420, 406, 11, 286, 994, 380, 917, 493, 5145, 257, 3410, 295, 28169, 510, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1733671872670414, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0008040628163143992}, {"id": 55, "seek": 42808, "start": 438.08, "end": 441.36, "text": " but I might find I had it embedded and everything. I don't want to get into it.", "tokens": [50864, 457, 286, 1062, 915, 286, 632, 309, 16741, 293, 1203, 13, 286, 500, 380, 528, 281, 483, 666, 309, 13, 51028], "temperature": 0.0, "avg_logprob": -0.1733671872670414, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0008040628163143992}, {"id": 56, "seek": 42808, "start": 441.36, "end": 446.0, "text": " So ultimately, a scanner is, it's a bytes buffer. And this is another reason I put this in the", "tokens": [51028, 407, 6284, 11, 257, 30211, 307, 11, 309, 311, 257, 36088, 21762, 13, 400, 341, 307, 1071, 1778, 286, 829, 341, 294, 264, 51260], "temperature": 0.0, "avg_logprob": -0.1733671872670414, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0008040628163143992}, {"id": 57, "seek": 42808, "start": 446.0, "end": 450.56, "text": " peg. So this thing, all of this used to be under rtbx-rob slash scan. I had my own rune scanner", "tokens": [51260, 17199, 13, 407, 341, 551, 11, 439, 295, 341, 1143, 281, 312, 833, 367, 83, 65, 87, 12, 16614, 17330, 11049, 13, 286, 632, 452, 1065, 1190, 68, 30211, 51488], "temperature": 0.0, "avg_logprob": -0.1733671872670414, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.0008040628163143992}, {"id": 58, "seek": 45056, "start": 450.56, "end": 460.8, "text": " in there. But I realized, and I'm going to put this in my conclusions. So I realized that,", "tokens": [50364, 294, 456, 13, 583, 286, 5334, 11, 293, 286, 478, 516, 281, 829, 341, 294, 452, 22865, 13, 407, 286, 5334, 300, 11, 50876], "temperature": 0.0, "avg_logprob": -0.10253050707388615, "compression_ratio": 1.4659090909090908, "no_speech_prob": 0.15200158953666687}, {"id": 59, "seek": 45056, "start": 460.8, "end": 473.28, "text": " that my rtbx-rob scan was actually very peg specific. And what I mean by that is that", "tokens": [50876, 300, 452, 367, 83, 65, 87, 12, 16614, 11049, 390, 767, 588, 17199, 2685, 13, 400, 437, 286, 914, 538, 300, 307, 300, 51500], "temperature": 0.0, "avg_logprob": -0.10253050707388615, "compression_ratio": 1.4659090909090908, "no_speech_prob": 0.15200158953666687}, {"id": 60, "seek": 45056, "start": 474.0, "end": 480.16, "text": " so a couple of really important specific assumptions are made by peg. Peg assumes", "tokens": [51536, 370, 257, 1916, 295, 534, 1021, 2685, 17695, 366, 1027, 538, 17199, 13, 28007, 37808, 51844], "temperature": 0.0, "avg_logprob": -0.10253050707388615, "compression_ratio": 1.4659090909090908, "no_speech_prob": 0.15200158953666687}, {"id": 61, "seek": 48016, "start": 480.16, "end": 484.40000000000003, "text": " that you have infinite memory, which is, you know, the polar opposite of parsing when you're", "tokens": [50364, 300, 291, 362, 13785, 4675, 11, 597, 307, 11, 291, 458, 11, 264, 12367, 6182, 295, 21156, 278, 562, 291, 434, 50576], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 62, "seek": 48016, "start": 484.40000000000003, "end": 488.40000000000003, "text": " using anything that you would get out of the Dragon Booker and computer science class.", "tokens": [50576, 1228, 1340, 300, 291, 576, 483, 484, 295, 264, 11517, 9476, 260, 293, 3820, 3497, 1508, 13, 50776], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 63, "seek": 48016, "start": 489.92, "end": 493.28000000000003, "text": " And so, I mean, that's a huge thing. So if someone comes across my scanner, they're going to say,", "tokens": [50852, 400, 370, 11, 286, 914, 11, 300, 311, 257, 2603, 551, 13, 407, 498, 1580, 1487, 2108, 452, 30211, 11, 436, 434, 516, 281, 584, 11, 51020], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 64, "seek": 48016, "start": 493.28000000000003, "end": 497.04, "text": " oh, a scanner, cool, you know, they'll make think it's a finite automata, you know,", "tokens": [51020, 1954, 11, 257, 30211, 11, 1627, 11, 291, 458, 11, 436, 603, 652, 519, 309, 311, 257, 19362, 3553, 3274, 11, 291, 458, 11, 51208], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 65, "seek": 48016, "start": 497.04, "end": 500.48, "text": " single look ahead kind of scanner. And they, they're like, what the hell is this thing?", "tokens": [51208, 2167, 574, 2286, 733, 295, 30211, 13, 400, 436, 11, 436, 434, 411, 11, 437, 264, 4921, 307, 341, 551, 30, 51380], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 66, "seek": 48016, "start": 500.48, "end": 507.6, "text": " It just flipped my whole data source, you know, byte, byte buffer and into memory. I mean, that's,", "tokens": [51380, 467, 445, 26273, 452, 1379, 1412, 4009, 11, 291, 458, 11, 40846, 11, 40846, 21762, 293, 666, 4675, 13, 286, 914, 11, 300, 311, 11, 51736], "temperature": 0.0, "avg_logprob": -0.14812598357329498, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.003706756280735135}, {"id": 67, "seek": 50760, "start": 507.6, "end": 513.28, "text": " that's like, that's like an unorthodox thing to do. That's a sacrilege in this. You know,", "tokens": [50364, 300, 311, 411, 11, 300, 311, 411, 364, 517, 2652, 22189, 551, 281, 360, 13, 663, 311, 257, 4899, 470, 35754, 294, 341, 13, 509, 458, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1527066188575947, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0005883981939405203}, {"id": 68, "seek": 50760, "start": 513.28, "end": 520.08, "text": " that's what peg does. So, so I realized that the scanner that I have built and been using the most", "tokens": [50648, 300, 311, 437, 17199, 775, 13, 407, 11, 370, 286, 5334, 300, 264, 30211, 300, 286, 362, 3094, 293, 668, 1228, 264, 881, 50988], "temperature": 0.0, "avg_logprob": -0.1527066188575947, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0005883981939405203}, {"id": 69, "seek": 50760, "start": 520.08, "end": 522.96, "text": " recent one, which I've used all over the place, I'm using it all over the place. I'm using it in", "tokens": [50988, 5162, 472, 11, 597, 286, 600, 1143, 439, 670, 264, 1081, 11, 286, 478, 1228, 309, 439, 670, 264, 1081, 13, 286, 478, 1228, 309, 294, 51132], "temperature": 0.0, "avg_logprob": -0.1527066188575947, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0005883981939405203}, {"id": 70, "seek": 50760, "start": 522.96, "end": 531.6800000000001, "text": " Bonsai and everything is actually, in fact, I think I just broke Bonsai by, no, I didn't.", "tokens": [51132, 363, 892, 1301, 293, 1203, 307, 767, 11, 294, 1186, 11, 286, 519, 286, 445, 6902, 363, 892, 1301, 538, 11, 572, 11, 286, 994, 380, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1527066188575947, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0005883981939405203}, {"id": 71, "seek": 53168, "start": 531.68, "end": 540.0799999999999, "text": " Bonsai's got its own scanner, never mind. Anyway, so I went ahead and, and implemented,", "tokens": [50364, 363, 892, 1301, 311, 658, 1080, 1065, 30211, 11, 1128, 1575, 13, 5684, 11, 370, 286, 1437, 2286, 293, 11, 293, 12270, 11, 50784], "temperature": 0.0, "avg_logprob": -0.16529783230383419, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.015905430540442467}, {"id": 72, "seek": 53168, "start": 540.0799999999999, "end": 544.9599999999999, "text": " and I actually also deprecated the other one by, because I moved the entire scanner", "tokens": [50784, 293, 286, 767, 611, 1367, 13867, 770, 264, 661, 472, 538, 11, 570, 286, 4259, 264, 2302, 30211, 51028], "temperature": 0.0, "avg_logprob": -0.16529783230383419, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.015905430540442467}, {"id": 73, "seek": 53168, "start": 545.5999999999999, "end": 551.52, "text": " into the Pagan package or the Pagan, Pagan module, because why? Because it's Pagan centric.", "tokens": [51060, 666, 264, 430, 14167, 7372, 420, 264, 430, 14167, 11, 430, 14167, 10088, 11, 570, 983, 30, 1436, 309, 311, 430, 14167, 1489, 1341, 13, 51356], "temperature": 0.0, "avg_logprob": -0.16529783230383419, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.015905430540442467}, {"id": 74, "seek": 53168, "start": 551.52, "end": 556.64, "text": " It's Pagan centric because a Pagan centric scanner, you can't even use it unless you load up a buffer.", "tokens": [51356, 467, 311, 430, 14167, 1489, 1341, 570, 257, 430, 14167, 1489, 1341, 30211, 11, 291, 393, 380, 754, 764, 309, 5969, 291, 3677, 493, 257, 21762, 13, 51612], "temperature": 0.0, "avg_logprob": -0.16529783230383419, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.015905430540442467}, {"id": 75, "seek": 55664, "start": 557.1999999999999, "end": 563.1999999999999, "text": " And, you know, that's completely unheard of in other circles. So, so that was the first major", "tokens": [50392, 400, 11, 291, 458, 11, 300, 311, 2584, 517, 42915, 295, 294, 661, 13040, 13, 407, 11, 370, 300, 390, 264, 700, 2563, 50692], "temperature": 0.0, "avg_logprob": -0.11497210634165797, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004609442315995693}, {"id": 76, "seek": 55664, "start": 563.1999999999999, "end": 568.16, "text": " thing. That did mean, however, though, that the, the other one that I have, which I'm leaving out", "tokens": [50692, 551, 13, 663, 630, 914, 11, 4461, 11, 1673, 11, 300, 264, 11, 264, 661, 472, 300, 286, 362, 11, 597, 286, 478, 5012, 484, 50940], "temperature": 0.0, "avg_logprob": -0.11497210634165797, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004609442315995693}, {"id": 77, "seek": 55664, "start": 568.16, "end": 572.16, "text": " there, because I'm pretty sure I have some dependencies on this scanner. And it's also", "tokens": [50940, 456, 11, 570, 286, 478, 1238, 988, 286, 362, 512, 36606, 322, 341, 30211, 13, 400, 309, 311, 611, 51140], "temperature": 0.0, "avg_logprob": -0.11497210634165797, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004609442315995693}, {"id": 78, "seek": 55664, "start": 572.16, "end": 577.4399999999999, "text": " listed in my awesome go list and things. And I have some pretty intense breaking changes that I", "tokens": [51140, 10052, 294, 452, 3476, 352, 1329, 293, 721, 13, 400, 286, 362, 512, 1238, 9447, 7697, 2962, 300, 286, 51404], "temperature": 0.0, "avg_logprob": -0.11497210634165797, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004609442315995693}, {"id": 79, "seek": 55664, "start": 577.4399999999999, "end": 583.36, "text": " added to this since version 10, because I changed some of the internal references and everything.", "tokens": [51404, 3869, 281, 341, 1670, 3037, 1266, 11, 570, 286, 3105, 512, 295, 264, 6920, 15400, 293, 1203, 13, 51700], "temperature": 0.0, "avg_logprob": -0.11497210634165797, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004609442315995693}, {"id": 80, "seek": 58336, "start": 583.36, "end": 588.64, "text": " And the more I got changing it, the more I, see right here, it says fulfills Pagan scanner face.", "tokens": [50364, 400, 264, 544, 286, 658, 4473, 309, 11, 264, 544, 286, 11, 536, 558, 510, 11, 309, 1619, 8081, 2565, 430, 14167, 30211, 1851, 13, 50628], "temperature": 0.0, "avg_logprob": -0.18037336012896368, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.002472552238032222}, {"id": 81, "seek": 58336, "start": 588.64, "end": 595.04, "text": " It actually doesn't do that anymore. I broke that when I was doing the move. And then this is the", "tokens": [50628, 467, 767, 1177, 380, 360, 300, 3602, 13, 286, 6902, 300, 562, 286, 390, 884, 264, 1286, 13, 400, 550, 341, 307, 264, 50948], "temperature": 0.0, "avg_logprob": -0.18037336012896368, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.002472552238032222}, {"id": 82, "seek": 58336, "start": 595.04, "end": 603.12, "text": " most accurate thing. So I've moved this entire scanner over to RTX ROM Pagan. And it is, you know,", "tokens": [50948, 881, 8559, 551, 13, 407, 286, 600, 4259, 341, 2302, 30211, 670, 281, 44573, 41678, 430, 14167, 13, 400, 309, 307, 11, 291, 458, 11, 51352], "temperature": 0.0, "avg_logprob": -0.18037336012896368, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.002472552238032222}, {"id": 83, "seek": 58336, "start": 603.12, "end": 610.5600000000001, "text": " implemented as, under the types. Good night. So it's implemented in the type here,", "tokens": [51352, 12270, 382, 11, 833, 264, 3467, 13, 2205, 1818, 13, 407, 309, 311, 12270, 294, 264, 2010, 510, 11, 51724], "temperature": 0.0, "avg_logprob": -0.18037336012896368, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.002472552238032222}, {"id": 84, "seek": 61056, "start": 611.28, "end": 616.88, "text": " under types, you can see the scanner is here. It gives you the cursor type and a scanner type.", "tokens": [50400, 833, 3467, 11, 291, 393, 536, 264, 30211, 307, 510, 13, 467, 2709, 291, 264, 28169, 2010, 293, 257, 30211, 2010, 13, 50680], "temperature": 0.0, "avg_logprob": -0.22124660809834798, "compression_ratio": 1.7325581395348837, "no_speech_prob": 0.0019266753224655986}, {"id": 85, "seek": 61056, "start": 617.4399999999999, "end": 620.88, "text": " And you can look it up and it has a mark going to go to and scan and to finish.", "tokens": [50708, 400, 291, 393, 574, 309, 493, 293, 309, 575, 257, 1491, 516, 281, 352, 281, 293, 11049, 293, 281, 2413, 13, 50880], "temperature": 0.0, "avg_logprob": -0.22124660809834798, "compression_ratio": 1.7325581395348837, "no_speech_prob": 0.0019266753224655986}, {"id": 86, "seek": 61056, "start": 621.4399999999999, "end": 626.4799999999999, "text": " I mean, nothing fancy there, right? And then I implemented, they included, you know,", "tokens": [50908, 286, 914, 11, 1825, 10247, 456, 11, 558, 30, 400, 550, 286, 12270, 11, 436, 5556, 11, 291, 458, 11, 51160], "temperature": 0.0, "avg_logprob": -0.22124660809834798, "compression_ratio": 1.7325581395348837, "no_speech_prob": 0.0019266753224655986}, {"id": 87, "seek": 61056, "start": 626.4799999999999, "end": 630.9599999999999, "text": " reference implementation of the scanner that I use for the Pagan stuff. And this gets me to", "tokens": [51160, 6408, 11420, 295, 264, 30211, 300, 286, 764, 337, 264, 430, 14167, 1507, 13, 400, 341, 2170, 385, 281, 51384], "temperature": 0.0, "avg_logprob": -0.22124660809834798, "compression_ratio": 1.7325581395348837, "no_speech_prob": 0.0019266753224655986}, {"id": 88, "seek": 61056, "start": 630.9599999999999, "end": 639.52, "text": " where I was going with base, basic marked, my basic markdown parser. So, so here we have Pagan,", "tokens": [51384, 689, 286, 390, 516, 365, 3096, 11, 3875, 12658, 11, 452, 3875, 1491, 5093, 21156, 260, 13, 407, 11, 370, 510, 321, 362, 430, 14167, 11, 51812], "temperature": 0.0, "avg_logprob": -0.22124660809834798, "compression_ratio": 1.7325581395348837, "no_speech_prob": 0.0019266753224655986}, {"id": 89, "seek": 63952, "start": 639.52, "end": 645.84, "text": " we have, so this is, this is the exact code that was in this other place. That's just been moved", "tokens": [50364, 321, 362, 11, 370, 341, 307, 11, 341, 307, 264, 1900, 3089, 300, 390, 294, 341, 661, 1081, 13, 663, 311, 445, 668, 4259, 50680], "temperature": 0.0, "avg_logprob": -0.08677342224121094, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.000535760831553489}, {"id": 90, "seek": 63952, "start": 645.84, "end": 652.56, "text": " and cleaned up. And I mean, really cleaned up and had some, some other things added to it.", "tokens": [50680, 293, 16146, 493, 13, 400, 286, 914, 11, 534, 16146, 493, 293, 632, 512, 11, 512, 661, 721, 3869, 281, 309, 13, 51016], "temperature": 0.0, "avg_logprob": -0.08677342224121094, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.000535760831553489}, {"id": 91, "seek": 63952, "start": 652.56, "end": 657.76, "text": " For example, the fulfillment of the interface so that it can be replaced with something else at", "tokens": [51016, 1171, 1365, 11, 264, 32615, 295, 264, 9226, 370, 300, 309, 393, 312, 10772, 365, 746, 1646, 412, 51276], "temperature": 0.0, "avg_logprob": -0.08677342224121094, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.000535760831553489}, {"id": 92, "seek": 63952, "start": 657.76, "end": 664.3199999999999, "text": " any time. And let me, let me talk to you about why I decided to make it an interface again.", "tokens": [51276, 604, 565, 13, 400, 718, 385, 11, 718, 385, 751, 281, 291, 466, 983, 286, 3047, 281, 652, 309, 364, 9226, 797, 13, 51604], "temperature": 0.0, "avg_logprob": -0.08677342224121094, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.000535760831553489}, {"id": 93, "seek": 63952, "start": 664.3199999999999, "end": 669.28, "text": " I mean, I started talking about that. But if you go to, so here's the interface, but as I was working", "tokens": [51604, 286, 914, 11, 286, 1409, 1417, 466, 300, 13, 583, 498, 291, 352, 281, 11, 370, 510, 311, 264, 9226, 11, 457, 382, 286, 390, 1364, 51852], "temperature": 0.0, "avg_logprob": -0.08677342224121094, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.000535760831553489}, {"id": 94, "seek": 66928, "start": 669.28, "end": 676.9599999999999, "text": " on basic MD, I started realizing that parsing end of line and end of block and paragraphs and,", "tokens": [50364, 322, 3875, 22521, 11, 286, 1409, 16734, 300, 21156, 278, 917, 295, 1622, 293, 917, 295, 3461, 293, 48910, 293, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10392257902357313, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.0034830693621188402}, {"id": 95, "seek": 66928, "start": 676.9599999999999, "end": 682.56, "text": " you know, all of these things that are listed in Pagan are things that I need to do all the time.", "tokens": [50748, 291, 458, 11, 439, 295, 613, 721, 300, 366, 10052, 294, 430, 14167, 366, 721, 300, 286, 643, 281, 360, 439, 264, 565, 13, 51028], "temperature": 0.0, "avg_logprob": -0.10392257902357313, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.0034830693621188402}, {"id": 96, "seek": 66928, "start": 682.56, "end": 687.12, "text": " In fact, I just add it in paragraph, right? These are things that I already need all the time.", "tokens": [51028, 682, 1186, 11, 286, 445, 909, 309, 294, 18865, 11, 558, 30, 1981, 366, 721, 300, 286, 1217, 643, 439, 264, 565, 13, 51256], "temperature": 0.0, "avg_logprob": -0.10392257902357313, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.0034830693621188402}, {"id": 97, "seek": 66928, "start": 688.0, "end": 693.28, "text": " And I'm like, I've always have intended to write, I mean, I've been really kind of hung up on", "tokens": [51300, 400, 286, 478, 411, 11, 286, 600, 1009, 362, 10226, 281, 2464, 11, 286, 914, 11, 286, 600, 668, 534, 733, 295, 5753, 493, 322, 51564], "temperature": 0.0, "avg_logprob": -0.10392257902357313, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.0034830693621188402}, {"id": 98, "seek": 66928, "start": 693.28, "end": 698.72, "text": " creating a code generator for all of stuff that, so you write Pagan and you end up with different", "tokens": [51564, 4084, 257, 3089, 19265, 337, 439, 295, 1507, 300, 11, 370, 291, 2464, 430, 14167, 293, 291, 917, 493, 365, 819, 51836], "temperature": 0.0, "avg_logprob": -0.10392257902357313, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.0034830693621188402}, {"id": 99, "seek": 69872, "start": 698.72, "end": 706.24, "text": " types of code, right? But to be more practical, I've started realizing all I really need to do", "tokens": [50364, 3467, 295, 3089, 11, 558, 30, 583, 281, 312, 544, 8496, 11, 286, 600, 1409, 16734, 439, 286, 534, 643, 281, 360, 50740], "temperature": 0.0, "avg_logprob": -0.11131434096503504, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.0013249812182039022}, {"id": 100, "seek": 69872, "start": 706.24, "end": 711.76, "text": " is write a scanner function for each of these and then reuse them. And then the ones that I,", "tokens": [50740, 307, 2464, 257, 30211, 2445, 337, 1184, 295, 613, 293, 550, 26225, 552, 13, 400, 550, 264, 2306, 300, 286, 11, 51016], "temperature": 0.0, "avg_logprob": -0.11131434096503504, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.0013249812182039022}, {"id": 101, "seek": 69872, "start": 712.88, "end": 718.08, "text": " that aren't in Pagan, that are specific to basic markdown or whatever, I'm writing Keg or whatever,", "tokens": [51072, 300, 3212, 380, 294, 430, 14167, 11, 300, 366, 2685, 281, 3875, 1491, 5093, 420, 2035, 11, 286, 478, 3579, 591, 1146, 420, 2035, 11, 51332], "temperature": 0.0, "avg_logprob": -0.11131434096503504, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.0013249812182039022}, {"id": 102, "seek": 69872, "start": 718.08, "end": 726.08, "text": " I can actually write those using exactly the same function signature. And I could even put them in", "tokens": [51332, 286, 393, 767, 2464, 729, 1228, 2293, 264, 912, 2445, 13397, 13, 400, 286, 727, 754, 829, 552, 294, 51732], "temperature": 0.0, "avg_logprob": -0.11131434096503504, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.0013249812182039022}, {"id": 103, "seek": 72608, "start": 726.8000000000001, "end": 731.84, "text": " packages, you know, as a collection of first class functions, because they all accept the scanner", "tokens": [50400, 17401, 11, 291, 458, 11, 382, 257, 5765, 295, 700, 1508, 6828, 11, 570, 436, 439, 3241, 264, 30211, 50652], "temperature": 0.0, "avg_logprob": -0.11226431878058465, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0007793460972607136}, {"id": 104, "seek": 72608, "start": 731.84, "end": 739.76, "text": " interface. And that is, you know, that is go interfaces shining the brightest, right? Because", "tokens": [50652, 9226, 13, 400, 300, 307, 11, 291, 458, 11, 300, 307, 352, 28416, 18269, 264, 36271, 11, 558, 30, 1436, 51048], "temperature": 0.0, "avg_logprob": -0.11226431878058465, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0007793460972607136}, {"id": 105, "seek": 72608, "start": 739.76, "end": 746.88, "text": " that's what's exactly what you want to do with it. So what does that mean? So I have the scanner", "tokens": [51048, 300, 311, 437, 311, 2293, 437, 291, 528, 281, 360, 365, 309, 13, 407, 437, 775, 300, 914, 30, 407, 286, 362, 264, 30211, 51404], "temperature": 0.0, "avg_logprob": -0.11226431878058465, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0007793460972607136}, {"id": 106, "seek": 72608, "start": 746.88, "end": 755.76, "text": " implementation here, and I can, I actually chose to make this implementation fast and abstract,", "tokens": [51404, 11420, 510, 11, 293, 286, 393, 11, 286, 767, 5111, 281, 652, 341, 11420, 2370, 293, 12649, 11, 51848], "temperature": 0.0, "avg_logprob": -0.11226431878058465, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0007793460972607136}, {"id": 107, "seek": 75576, "start": 755.76, "end": 761.28, "text": " so that if somebody chose to use it, they could use the direct references to the byte buffers", "tokens": [50364, 370, 300, 498, 2618, 5111, 281, 764, 309, 11, 436, 727, 764, 264, 2047, 15400, 281, 264, 40846, 9204, 433, 50640], "temperature": 0.0, "avg_logprob": -0.07670393935194961, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00044418798643164337}, {"id": 108, "seek": 75576, "start": 761.28, "end": 766.4, "text": " and stuff like that, so they can bypass the indirection from the interface method calls,", "tokens": [50640, 293, 1507, 411, 300, 11, 370, 436, 393, 24996, 264, 1016, 621, 882, 490, 264, 9226, 3170, 5498, 11, 50896], "temperature": 0.0, "avg_logprob": -0.07670393935194961, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00044418798643164337}, {"id": 109, "seek": 75576, "start": 766.4, "end": 771.2, "text": " which is the reason I didn't do it originally, right? If you look at the highest performance", "tokens": [50896, 597, 307, 264, 1778, 286, 994, 380, 360, 309, 7993, 11, 558, 30, 759, 291, 574, 412, 264, 6343, 3389, 51136], "temperature": 0.0, "avg_logprob": -0.07670393935194961, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00044418798643164337}, {"id": 110, "seek": 75576, "start": 771.2, "end": 775.4399999999999, "text": " parsers out there, they do not have a lot of functional indirection, right? It's actually", "tokens": [51136, 21156, 433, 484, 456, 11, 436, 360, 406, 362, 257, 688, 295, 11745, 1016, 621, 882, 11, 558, 30, 467, 311, 767, 51348], "temperature": 0.0, "avg_logprob": -0.07670393935194961, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00044418798643164337}, {"id": 111, "seek": 75576, "start": 775.4399999999999, "end": 780.88, "text": " one of the biggest complaints I have about the current code generator for Pagan that Quint", "tokens": [51348, 472, 295, 264, 3880, 19585, 286, 362, 466, 264, 2190, 3089, 19265, 337, 430, 14167, 300, 2326, 686, 51620], "temperature": 0.0, "avg_logprob": -0.07670393935194961, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00044418798643164337}, {"id": 112, "seek": 78088, "start": 780.88, "end": 787.28, "text": " mostly made, and I last two years ago, is it has a ton of function indirection in it. And that's", "tokens": [50364, 5240, 1027, 11, 293, 286, 1036, 732, 924, 2057, 11, 307, 309, 575, 257, 2952, 295, 2445, 1016, 621, 882, 294, 309, 13, 400, 300, 311, 50684], "temperature": 0.0, "avg_logprob": -0.09051888275146484, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.060077957808971405}, {"id": 113, "seek": 78088, "start": 787.28, "end": 793.92, "text": " been something I've been kind of like, irrationally hung up on. And I think I finally hit the middle,", "tokens": [50684, 668, 746, 286, 600, 668, 733, 295, 411, 11, 3418, 2405, 379, 5753, 493, 322, 13, 400, 286, 519, 286, 2721, 2045, 264, 2808, 11, 51016], "temperature": 0.0, "avg_logprob": -0.09051888275146484, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.060077957808971405}, {"id": 114, "seek": 78088, "start": 793.92, "end": 798.56, "text": " the middle of the road here. So this particular reference implementation, which is a part of", "tokens": [51016, 264, 2808, 295, 264, 3060, 510, 13, 407, 341, 1729, 6408, 11420, 11, 597, 307, 257, 644, 295, 51248], "temperature": 0.0, "avg_logprob": -0.09051888275146484, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.060077957808971405}, {"id": 115, "seek": 78088, "start": 798.56, "end": 806.16, "text": " Pagan, comes with a struct that you can use directly if you want to, which I probably will", "tokens": [51248, 430, 14167, 11, 1487, 365, 257, 6594, 300, 291, 393, 764, 3838, 498, 291, 528, 281, 11, 597, 286, 1391, 486, 51628], "temperature": 0.0, "avg_logprob": -0.09051888275146484, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.060077957808971405}, {"id": 116, "seek": 78088, "start": 806.16, "end": 809.92, "text": " do and really quick and dirty, you know, I mean, not the quick and the quick and dirty stuff,", "tokens": [51628, 360, 293, 534, 1702, 293, 9360, 11, 291, 458, 11, 286, 914, 11, 406, 264, 1702, 293, 264, 1702, 293, 9360, 1507, 11, 51816], "temperature": 0.0, "avg_logprob": -0.09051888275146484, "compression_ratio": 1.730909090909091, "no_speech_prob": 0.060077957808971405}, {"id": 117, "seek": 80992, "start": 810.0, "end": 812.9599999999999, "text": " I'll probably will use the abstractions because they're easier to remember and you can just,", "tokens": [50368, 286, 603, 1391, 486, 764, 264, 12649, 626, 570, 436, 434, 3571, 281, 1604, 293, 291, 393, 445, 11, 50516], "temperature": 0.0, "avg_logprob": -0.1301522217979727, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005059834104031324}, {"id": 118, "seek": 80992, "start": 812.9599999999999, "end": 817.4399999999999, "text": " you know, you can just swap them in and out. I don't need performance, right? But if I'm like,", "tokens": [50516, 291, 458, 11, 291, 393, 445, 18135, 552, 294, 293, 484, 13, 286, 500, 380, 643, 3389, 11, 558, 30, 583, 498, 286, 478, 411, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1301522217979727, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005059834104031324}, {"id": 119, "seek": 80992, "start": 817.4399999999999, "end": 823.12, "text": " really want to make a low level, really intensely often, you know, parsed grammar, then I can go", "tokens": [50740, 534, 528, 281, 652, 257, 2295, 1496, 11, 534, 43235, 2049, 11, 291, 458, 11, 21156, 292, 22317, 11, 550, 286, 393, 352, 51024], "temperature": 0.0, "avg_logprob": -0.1301522217979727, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005059834104031324}, {"id": 120, "seek": 80992, "start": 823.12, "end": 834.4, "text": " ahead and bypass the use of those things as long as I don't want to reuse any of the stuff I've", "tokens": [51024, 2286, 293, 24996, 264, 764, 295, 729, 721, 382, 938, 382, 286, 500, 380, 528, 281, 26225, 604, 295, 264, 1507, 286, 600, 51588], "temperature": 0.0, "avg_logprob": -0.1301522217979727, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005059834104031324}, {"id": 121, "seek": 80992, "start": 834.4, "end": 839.04, "text": " already write in Pagan, which brought me to think, oh, damn, you know, let's say I make a,", "tokens": [51588, 1217, 2464, 294, 430, 14167, 11, 597, 3038, 385, 281, 519, 11, 1954, 11, 8151, 11, 291, 458, 11, 718, 311, 584, 286, 652, 257, 11, 51820], "temperature": 0.0, "avg_logprob": -0.1301522217979727, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005059834104031324}, {"id": 122, "seek": 83904, "start": 840.0, "end": 844.7199999999999, "text": " here's, here's my work, my workflow. Okay, so my, I imagine the workflow of making a grammar", "tokens": [50412, 510, 311, 11, 510, 311, 452, 589, 11, 452, 20993, 13, 1033, 11, 370, 452, 11, 286, 3811, 264, 20993, 295, 1455, 257, 22317, 50648], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 123, "seek": 83904, "start": 844.7199999999999, "end": 848.7199999999999, "text": " or something like this, right? So in fact, this is even in a slide at Brian Ford, Brian, I was", "tokens": [50648, 420, 746, 411, 341, 11, 558, 30, 407, 294, 1186, 11, 341, 307, 754, 294, 257, 4137, 412, 10765, 11961, 11, 10765, 11, 286, 390, 50848], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 124, "seek": 83904, "start": 848.7199999999999, "end": 852.3199999999999, "text": " looking at Brian Ford's peg stuff, and he has this in a slide about, you know, traditional", "tokens": [50848, 1237, 412, 10765, 11961, 311, 17199, 1507, 11, 293, 415, 575, 341, 294, 257, 4137, 466, 11, 291, 458, 11, 5164, 51028], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 125, "seek": 83904, "start": 852.3199999999999, "end": 857.1999999999999, "text": " thing, use Lex and Yak and blah, blah, blah, and, and then, but, you know, the pragmatic way", "tokens": [51028, 551, 11, 764, 24086, 293, 31484, 293, 12288, 11, 12288, 11, 12288, 11, 293, 11, 293, 550, 11, 457, 11, 291, 458, 11, 264, 46904, 636, 51272], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 126, "seek": 83904, "start": 857.1999999999999, "end": 863.1999999999999, "text": " approach to doing parsing these days is to write, you know, a generic kind of specification and", "tokens": [51272, 3109, 281, 884, 21156, 278, 613, 1708, 307, 281, 2464, 11, 291, 458, 11, 257, 19577, 733, 295, 31256, 293, 51572], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 127, "seek": 83904, "start": 863.1999999999999, "end": 868.16, "text": " then to write a recursive descent parser. It's the standard way, the practical way to do parsing.", "tokens": [51572, 550, 281, 2464, 257, 20560, 488, 23475, 21156, 260, 13, 467, 311, 264, 3832, 636, 11, 264, 8496, 636, 281, 360, 21156, 278, 13, 51820], "temperature": 0.0, "avg_logprob": -0.2036353148423232, "compression_ratio": 1.8167202572347267, "no_speech_prob": 0.0012446721084415913}, {"id": 128, "seek": 86816, "start": 868.7199999999999, "end": 872.7199999999999, "text": " And let's say I want to do that, right? So I want to write a grammar, but I want to write it", "tokens": [50392, 400, 718, 311, 584, 286, 528, 281, 360, 300, 11, 558, 30, 407, 286, 528, 281, 2464, 257, 22317, 11, 457, 286, 528, 281, 2464, 309, 50592], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 129, "seek": 86816, "start": 872.7199999999999, "end": 879.36, "text": " quickly. Now, the quickest way to do it would be to do cogeneration with, you know, from Pagan", "tokens": [50592, 2661, 13, 823, 11, 264, 49403, 636, 281, 360, 309, 576, 312, 281, 360, 598, 30372, 365, 11, 291, 458, 11, 490, 430, 14167, 50924], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 130, "seek": 86816, "start": 879.36, "end": 884.24, "text": " notation, which is something I still want to do. That's nothing that Pagan, that Brian Ford ever", "tokens": [50924, 24657, 11, 597, 307, 746, 286, 920, 528, 281, 360, 13, 663, 311, 1825, 300, 430, 14167, 11, 300, 10765, 11961, 1562, 51168], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 131, "seek": 86816, "start": 884.24, "end": 887.92, "text": " wanted to do. You kind of wanted to get away from it because he realized it was just, it's just as", "tokens": [51168, 1415, 281, 360, 13, 509, 733, 295, 1415, 281, 483, 1314, 490, 309, 570, 415, 5334, 309, 390, 445, 11, 309, 311, 445, 382, 51352], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 132, "seek": 86816, "start": 887.92, "end": 892.8, "text": " fast to just write your own recursive descent functional parser and, and then be done with it.", "tokens": [51352, 2370, 281, 445, 2464, 428, 1065, 20560, 488, 23475, 11745, 21156, 260, 293, 11, 293, 550, 312, 1096, 365, 309, 13, 51596], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 133, "seek": 86816, "start": 892.8, "end": 896.48, "text": " You don't have to deal with all the intricacies of cogeneration, not being exactly what you want.", "tokens": [51596, 509, 500, 380, 362, 281, 2028, 365, 439, 264, 30242, 20330, 295, 598, 30372, 11, 406, 885, 2293, 437, 291, 528, 13, 51780], "temperature": 0.0, "avg_logprob": -0.11239444508272059, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.0016484307125210762}, {"id": 134, "seek": 89648, "start": 896.48, "end": 901.6800000000001, "text": " You just write it, right? And, and I'm kind of on board with that idea because, you know,", "tokens": [50364, 509, 445, 2464, 309, 11, 558, 30, 400, 11, 293, 286, 478, 733, 295, 322, 3150, 365, 300, 1558, 570, 11, 291, 458, 11, 50624], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 135, "seek": 89648, "start": 902.4, "end": 905.9200000000001, "text": " it's, it's quite a bit of work to get it to generate just the way you want to. And then", "tokens": [50660, 309, 311, 11, 309, 311, 1596, 257, 857, 295, 589, 281, 483, 309, 281, 8460, 445, 264, 636, 291, 528, 281, 13, 400, 550, 50836], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 136, "seek": 89648, "start": 905.9200000000001, "end": 911.6, "text": " which, which cogeneration method do you want? Do you want it to be highly efficient? Do you want", "tokens": [50836, 597, 11, 597, 598, 30372, 3170, 360, 291, 528, 30, 1144, 291, 528, 309, 281, 312, 5405, 7148, 30, 1144, 291, 528, 51120], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 137, "seek": 89648, "start": 911.6, "end": 914.96, "text": " it to be used functional so it can be easily maintained? Are you going to rerun the generator", "tokens": [51120, 309, 281, 312, 1143, 11745, 370, 309, 393, 312, 3612, 17578, 30, 2014, 291, 516, 281, 43819, 409, 264, 19265, 51288], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 138, "seek": 89648, "start": 914.96, "end": 919.76, "text": " every time? Is it just giving you the first version? And, and so at a certain point,", "tokens": [51288, 633, 565, 30, 1119, 309, 445, 2902, 291, 264, 700, 3037, 30, 400, 11, 293, 370, 412, 257, 1629, 935, 11, 51528], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 139, "seek": 89648, "start": 919.76, "end": 924.88, "text": " you kind of come to the conclusion that probably the fastest way to create a parser is to just", "tokens": [51528, 291, 733, 295, 808, 281, 264, 10063, 300, 1391, 264, 14573, 636, 281, 1884, 257, 21156, 260, 307, 281, 445, 51784], "temperature": 0.0, "avg_logprob": -0.08327041494435278, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0012065485352650285}, {"id": 140, "seek": 92488, "start": 924.88, "end": 930.56, "text": " write the thing because then, you know, you're going to, you're, you're going to be done. You're", "tokens": [50364, 2464, 264, 551, 570, 550, 11, 291, 458, 11, 291, 434, 516, 281, 11, 291, 434, 11, 291, 434, 516, 281, 312, 1096, 13, 509, 434, 50648], "temperature": 0.0, "avg_logprob": -0.11292527142693015, "compression_ratio": 1.7922077922077921, "no_speech_prob": 0.004198496695607901}, {"id": 141, "seek": 92488, "start": 930.56, "end": 935.28, "text": " going to be done with it and you're going to be able to move on to other things. So, um, and,", "tokens": [50648, 516, 281, 312, 1096, 365, 309, 293, 291, 434, 516, 281, 312, 1075, 281, 1286, 322, 281, 661, 721, 13, 407, 11, 1105, 11, 293, 11, 50884], "temperature": 0.0, "avg_logprob": -0.11292527142693015, "compression_ratio": 1.7922077922077921, "no_speech_prob": 0.004198496695607901}, {"id": 142, "seek": 92488, "start": 935.28, "end": 945.68, "text": " and that's kind of where I am. So, uh, also realized, uh, fastest way to develop, uh,", "tokens": [50884, 293, 300, 311, 733, 295, 689, 286, 669, 13, 407, 11, 2232, 11, 611, 5334, 11, 2232, 11, 14573, 636, 281, 1499, 11, 2232, 11, 51404], "temperature": 0.0, "avg_logprob": -0.11292527142693015, "compression_ratio": 1.7922077922077921, "no_speech_prob": 0.004198496695607901}, {"id": 143, "seek": 94568, "start": 946.64, "end": 953.3599999999999, "text": " parser is to write Pagan and then function and then scanners", "tokens": [50412, 21156, 260, 307, 281, 2464, 430, 14167, 293, 550, 2445, 293, 550, 795, 25792, 50748], "temperature": 0.0, "avg_logprob": -0.14665342569351197, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.034097589552402496}, {"id": 144, "seek": 94568, "start": 956.4799999999999, "end": 961.8399999999999, "text": " functions for recursive descent. Uh,", "tokens": [50904, 6828, 337, 20560, 488, 23475, 13, 4019, 11, 51172], "temperature": 0.0, "avg_logprob": -0.14665342569351197, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.034097589552402496}, {"id": 145, "seek": 94568, "start": 963.92, "end": 968.4799999999999, "text": " I mean, it really is. So by the time, you know, you get all the thing, just writing the Pagan", "tokens": [51276, 286, 914, 11, 309, 534, 307, 13, 407, 538, 264, 565, 11, 291, 458, 11, 291, 483, 439, 264, 551, 11, 445, 3579, 264, 430, 14167, 51504], "temperature": 0.0, "avg_logprob": -0.14665342569351197, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.034097589552402496}, {"id": 146, "seek": 94568, "start": 968.4799999999999, "end": 974.0, "text": " itself is good. I mean, that kind of gets you thinking about how it's supposed to be implemented,", "tokens": [51504, 2564, 307, 665, 13, 286, 914, 11, 300, 733, 295, 2170, 291, 1953, 466, 577, 309, 311, 3442, 281, 312, 12270, 11, 51780], "temperature": 0.0, "avg_logprob": -0.14665342569351197, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.034097589552402496}, {"id": 147, "seek": 97400, "start": 974.08, "end": 979.68, "text": " but you're also not wrestling with Pagan syntax and stuff, uh, in case you get it wrong. Now,", "tokens": [50368, 457, 291, 434, 611, 406, 19274, 365, 430, 14167, 28431, 293, 1507, 11, 2232, 11, 294, 1389, 291, 483, 309, 2085, 13, 823, 11, 50648], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 148, "seek": 97400, "start": 979.68, "end": 984.08, "text": " you should probably do that, but let's say you don't represent it perfectly and Pagan,", "tokens": [50648, 291, 820, 1391, 360, 300, 11, 457, 718, 311, 584, 291, 500, 380, 2906, 309, 6239, 293, 430, 14167, 11, 50868], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 149, "seek": 97400, "start": 984.08, "end": 989.44, "text": " who cares? The Pagan is just there to help you understand what the parser is going to,", "tokens": [50868, 567, 12310, 30, 440, 430, 14167, 307, 445, 456, 281, 854, 291, 1223, 437, 264, 21156, 260, 307, 516, 281, 11, 51136], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 150, "seek": 97400, "start": 989.44, "end": 993.52, "text": " how it's going to behave. Um, and then you can, you know, compare it to that, you know, just,", "tokens": [51136, 577, 309, 311, 516, 281, 15158, 13, 3301, 11, 293, 550, 291, 393, 11, 291, 458, 11, 6794, 309, 281, 300, 11, 291, 458, 11, 445, 11, 51340], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 151, "seek": 97400, "start": 993.52, "end": 997.52, "text": " just, you know, visually and get to your, get to your point, but you can get busy kind of writing", "tokens": [51340, 445, 11, 291, 458, 11, 19622, 293, 483, 281, 428, 11, 483, 281, 428, 935, 11, 457, 291, 393, 483, 5856, 733, 295, 3579, 51540], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 152, "seek": 97400, "start": 997.52, "end": 1003.04, "text": " your parser. So, so, but, you know, along those, those lines, assuming that you're going to write", "tokens": [51540, 428, 21156, 260, 13, 407, 11, 370, 11, 457, 11, 291, 458, 11, 2051, 729, 11, 729, 3876, 11, 11926, 300, 291, 434, 516, 281, 2464, 51816], "temperature": 0.0, "avg_logprob": -0.0798034362303905, "compression_ratio": 1.8382838283828382, "no_speech_prob": 0.0021155744325369596}, {"id": 153, "seek": 100304, "start": 1003.04, "end": 1006.64, "text": " a parser, right? You're going to go ahead and write a parser. What are the obvious building", "tokens": [50364, 257, 21156, 260, 11, 558, 30, 509, 434, 516, 281, 352, 2286, 293, 2464, 257, 21156, 260, 13, 708, 366, 264, 6322, 2390, 50544], "temperature": 0.0, "avg_logprob": -0.10170678531422335, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.010012729093432426}, {"id": 154, "seek": 100304, "start": 1006.64, "end": 1010.48, "text": " blocks? I mean, code generation is awesome and everything, but, but what, what would be the", "tokens": [50544, 8474, 30, 286, 914, 11, 3089, 5125, 307, 3476, 293, 1203, 11, 457, 11, 457, 437, 11, 437, 576, 312, 264, 50736], "temperature": 0.0, "avg_logprob": -0.10170678531422335, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.010012729093432426}, {"id": 155, "seek": 100304, "start": 1010.48, "end": 1015.68, "text": " other way to do this if you didn't have code generation? Well, it gets pretty obvious that", "tokens": [50736, 661, 636, 281, 360, 341, 498, 291, 994, 380, 362, 3089, 5125, 30, 1042, 11, 309, 2170, 1238, 6322, 300, 50996], "temperature": 0.0, "avg_logprob": -0.10170678531422335, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.010012729093432426}, {"id": 156, "seek": 100304, "start": 1015.68, "end": 1023.76, "text": " it would be a standardized library of scan functions, uh, that, that you regularly reuse,", "tokens": [50996, 309, 576, 312, 257, 31677, 6405, 295, 11049, 6828, 11, 2232, 11, 300, 11, 300, 291, 11672, 26225, 11, 51400], "temperature": 0.0, "avg_logprob": -0.10170678531422335, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.010012729093432426}, {"id": 157, "seek": 100304, "start": 1024.72, "end": 1029.6, "text": " right? And if you, as long as you make those export in your public, make those public, you can,", "tokens": [51448, 558, 30, 400, 498, 291, 11, 382, 938, 382, 291, 652, 729, 10725, 294, 428, 1908, 11, 652, 729, 1908, 11, 291, 393, 11, 51692], "temperature": 0.0, "avg_logprob": -0.10170678531422335, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.010012729093432426}, {"id": 158, "seek": 102960, "start": 1029.6, "end": 1033.12, "text": " you can pull them in and you can tweak them and make them more efficient and other people can", "tokens": [50364, 291, 393, 2235, 552, 294, 293, 291, 393, 29879, 552, 293, 652, 552, 544, 7148, 293, 661, 561, 393, 50540], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 159, "seek": 102960, "start": 1033.12, "end": 1037.84, "text": " contribute their own. And, and you have, you know, you ended up getting this ecosystem of scanners,", "tokens": [50540, 10586, 641, 1065, 13, 400, 11, 293, 291, 362, 11, 291, 458, 11, 291, 4590, 493, 1242, 341, 11311, 295, 795, 25792, 11, 50776], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 160, "seek": 102960, "start": 1038.3999999999999, "end": 1043.28, "text": " uh, of, you know, because that's really, the scanners are really the secret because if you", "tokens": [50804, 2232, 11, 295, 11, 291, 458, 11, 570, 300, 311, 534, 11, 264, 795, 25792, 366, 534, 264, 4054, 570, 498, 291, 51048], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 161, "seek": 102960, "start": 1043.28, "end": 1048.3999999999999, "text": " have a scanner, you can scan it and if it scans successfully and you would get a true at the", "tokens": [51048, 362, 257, 30211, 11, 291, 393, 11049, 309, 293, 498, 309, 35116, 10727, 293, 291, 576, 483, 257, 2074, 412, 264, 51304], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 162, "seek": 102960, "start": 1048.3999999999999, "end": 1053.04, "text": " end of that. I mean, and this is very hastily, right? If at the end, if you get a true after that,", "tokens": [51304, 917, 295, 300, 13, 286, 914, 11, 293, 341, 307, 588, 6581, 953, 11, 558, 30, 759, 412, 264, 917, 11, 498, 291, 483, 257, 2074, 934, 300, 11, 51536], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 163, "seek": 102960, "start": 1053.04, "end": 1058.08, "text": " you're done. You're under the next thing. If you don't get a true, then you're guaranteed that", "tokens": [51536, 291, 434, 1096, 13, 509, 434, 833, 264, 958, 551, 13, 759, 291, 500, 380, 483, 257, 2074, 11, 550, 291, 434, 18031, 300, 51788], "temperature": 0.0, "avg_logprob": -0.11134207876105058, "compression_ratio": 1.9488054607508531, "no_speech_prob": 0.0031725631561130285}, {"id": 164, "seek": 105808, "start": 1058.08, "end": 1062.56, "text": " the scanner didn't do any advancement because it snapped back. And you're going to see this all", "tokens": [50364, 264, 30211, 994, 380, 360, 604, 35764, 570, 309, 41396, 646, 13, 400, 291, 434, 516, 281, 536, 341, 439, 50588], "temperature": 0.0, "avg_logprob": -0.0934227534702846, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.004754955414682627}, {"id": 165, "seek": 105808, "start": 1062.56, "end": 1066.96, "text": " over in, in my implementation of functions, which we'll show you in a second, because that is how", "tokens": [50588, 670, 294, 11, 294, 452, 11420, 295, 6828, 11, 597, 321, 603, 855, 291, 294, 257, 1150, 11, 570, 300, 307, 577, 50808], "temperature": 0.0, "avg_logprob": -0.0934227534702846, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.004754955414682627}, {"id": 166, "seek": 105808, "start": 1067.84, "end": 1073.84, "text": " you do this. And, and that is exactly how Brian Ford talks about it in his paper. It's like the", "tokens": [50852, 291, 360, 341, 13, 400, 11, 293, 300, 307, 2293, 577, 10765, 11961, 6686, 466, 309, 294, 702, 3035, 13, 467, 311, 411, 264, 51152], "temperature": 0.0, "avg_logprob": -0.0934227534702846, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.004754955414682627}, {"id": 167, "seek": 105808, "start": 1073.84, "end": 1079.52, "text": " difference between, you know, the traditional scanner and, you know, parser kind of approach.", "tokens": [51152, 2649, 1296, 11, 291, 458, 11, 264, 5164, 30211, 293, 11, 291, 458, 11, 21156, 260, 733, 295, 3109, 13, 51436], "temperature": 0.0, "avg_logprob": -0.0934227534702846, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.004754955414682627}, {"id": 168, "seek": 105808, "start": 1079.52, "end": 1084.96, "text": " And this is that you can scan ahead as far as you want and you can keep track of how many", "tokens": [51436, 400, 341, 307, 300, 291, 393, 11049, 2286, 382, 1400, 382, 291, 528, 293, 291, 393, 1066, 2837, 295, 577, 867, 51708], "temperature": 0.0, "avg_logprob": -0.0934227534702846, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.004754955414682627}, {"id": 169, "seek": 108496, "start": 1084.96, "end": 1090.8, "text": " matches you have. So you can be very greedy if you want and say, okay, so did I find anything?", "tokens": [50364, 10676, 291, 362, 13, 407, 291, 393, 312, 588, 28228, 498, 291, 528, 293, 584, 11, 1392, 11, 370, 630, 286, 915, 1340, 30, 50656], "temperature": 0.0, "avg_logprob": -0.10197113096251968, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.031141147017478943}, {"id": 170, "seek": 108496, "start": 1090.8, "end": 1094.64, "text": " Yes, I found like 10 of them. And then I keep scanning and like, oh, hey, well, like, okay,", "tokens": [50656, 1079, 11, 286, 1352, 411, 1266, 295, 552, 13, 400, 550, 286, 1066, 27019, 293, 411, 11, 1954, 11, 4177, 11, 731, 11, 411, 11, 1392, 11, 50848], "temperature": 0.0, "avg_logprob": -0.10197113096251968, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.031141147017478943}, {"id": 171, "seek": 108496, "start": 1094.64, "end": 1099.6000000000001, "text": " I stopped. So then I like roll back to the last one that was successful. Or if there were none", "tokens": [50848, 286, 5936, 13, 407, 550, 286, 411, 3373, 646, 281, 264, 1036, 472, 300, 390, 4406, 13, 1610, 498, 456, 645, 6022, 51096], "temperature": 0.0, "avg_logprob": -0.10197113096251968, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.031141147017478943}, {"id": 172, "seek": 108496, "start": 1099.6000000000001, "end": 1105.44, "text": " that were successful, I roll back the scanner all the way to the beginning. So, so this idea of", "tokens": [51096, 300, 645, 4406, 11, 286, 3373, 646, 264, 30211, 439, 264, 636, 281, 264, 2863, 13, 407, 11, 370, 341, 1558, 295, 51388], "temperature": 0.0, "avg_logprob": -0.10197113096251968, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.031141147017478943}, {"id": 173, "seek": 108496, "start": 1105.44, "end": 1111.8400000000001, "text": " snapping the scanner back and moving it and around a thing, that's a very fundamental part of the PEG", "tokens": [51388, 42727, 264, 30211, 646, 293, 2684, 309, 293, 926, 257, 551, 11, 300, 311, 257, 588, 8088, 644, 295, 264, 24346, 38, 51708], "temperature": 0.0, "avg_logprob": -0.10197113096251968, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.031141147017478943}, {"id": 174, "seek": 111184, "start": 1111.9199999999998, "end": 1117.6799999999998, "text": " architectural approach. Because you have memory, you have memory that you can fly around in. And", "tokens": [50368, 26621, 3109, 13, 1436, 291, 362, 4675, 11, 291, 362, 4675, 300, 291, 393, 3603, 926, 294, 13, 400, 50656], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 175, "seek": 111184, "start": 1117.6799999999998, "end": 1122.32, "text": " very quickly, by the way, I mean, you know, moving pointers around in memory is crazy, crazy fast.", "tokens": [50656, 588, 2661, 11, 538, 264, 636, 11, 286, 914, 11, 291, 458, 11, 2684, 44548, 926, 294, 4675, 307, 3219, 11, 3219, 2370, 13, 50888], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 176, "seek": 111184, "start": 1123.04, "end": 1126.6399999999999, "text": " And you've only had to do the one load. And so, you know, all these things that are doing like", "tokens": [50924, 400, 291, 600, 787, 632, 281, 360, 264, 472, 3677, 13, 400, 370, 11, 291, 458, 11, 439, 613, 721, 300, 366, 884, 411, 51104], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 177, "seek": 111184, "start": 1126.6399999999999, "end": 1131.84, "text": " single byte loads, in order to do that, you've already had to buffer your data at some point. So", "tokens": [51104, 2167, 40846, 12668, 11, 294, 1668, 281, 360, 300, 11, 291, 600, 1217, 632, 281, 21762, 428, 1412, 412, 512, 935, 13, 407, 51364], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 178, "seek": 111184, "start": 1131.84, "end": 1135.84, "text": " you've already had to do the buffering. So, so the thing is cool about PEG is it assumes that", "tokens": [51364, 291, 600, 1217, 632, 281, 360, 264, 9204, 1794, 13, 407, 11, 370, 264, 551, 307, 1627, 466, 24346, 38, 307, 309, 37808, 300, 51564], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 179, "seek": 111184, "start": 1135.84, "end": 1139.52, "text": " you're just going to buffer all of that upfront. And then you're going to break up your content", "tokens": [51564, 291, 434, 445, 516, 281, 21762, 439, 295, 300, 30264, 13, 400, 550, 291, 434, 516, 281, 1821, 493, 428, 2701, 51748], "temperature": 0.0, "avg_logprob": -0.07389169731396157, "compression_ratio": 1.9169435215946844, "no_speech_prob": 0.020329587161540985}, {"id": 180, "seek": 113952, "start": 1139.52, "end": 1142.8799999999999, "text": " into manageable chunks that fit within, you know, reasonable amount of memory that you're", "tokens": [50364, 666, 38798, 24004, 300, 3318, 1951, 11, 291, 458, 11, 10585, 2372, 295, 4675, 300, 291, 434, 50532], "temperature": 0.0, "avg_logprob": -0.11215413665771484, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0015977569855749607}, {"id": 181, "seek": 113952, "start": 1142.8799999999999, "end": 1147.52, "text": " going to be parsing. You should put limitations in there and stuff. And that's a part of the grammar", "tokens": [50532, 516, 281, 312, 21156, 278, 13, 509, 820, 829, 15705, 294, 456, 293, 1507, 13, 400, 300, 311, 257, 644, 295, 264, 22317, 50764], "temperature": 0.0, "avg_logprob": -0.11215413665771484, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0015977569855749607}, {"id": 182, "seek": 113952, "start": 1147.52, "end": 1153.2, "text": " design, which is another reason that PEG is a fail, because as wonderful as it is, it does not allow", "tokens": [50764, 1715, 11, 597, 307, 1071, 1778, 300, 24346, 38, 307, 257, 3061, 11, 570, 382, 3715, 382, 309, 307, 11, 309, 775, 406, 2089, 51048], "temperature": 0.0, "avg_logprob": -0.11215413665771484, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0015977569855749607}, {"id": 183, "seek": 113952, "start": 1153.2, "end": 1158.72, "text": " you to put limitations and constraints on this size, which is why I made PEG in. So when I say", "tokens": [51048, 291, 281, 829, 15705, 293, 18491, 322, 341, 2744, 11, 597, 307, 983, 286, 1027, 24346, 38, 294, 13, 407, 562, 286, 584, 51324], "temperature": 0.0, "avg_logprob": -0.11215413665771484, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0015977569855749607}, {"id": 184, "seek": 113952, "start": 1159.28, "end": 1167.6, "text": " things like, I only want, you know, two end of lines here, I can specify two end of lines. There's", "tokens": [51352, 721, 411, 11, 286, 787, 528, 11, 291, 458, 11, 732, 917, 295, 3876, 510, 11, 286, 393, 16500, 732, 917, 295, 3876, 13, 821, 311, 51768], "temperature": 0.0, "avg_logprob": -0.11215413665771484, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0015977569855749607}, {"id": 185, "seek": 116760, "start": 1167.6, "end": 1176.24, "text": " no way in the original PEG specification example to indicate amount, which I just think is crazy,", "tokens": [50364, 572, 636, 294, 264, 3380, 24346, 38, 31256, 1365, 281, 13330, 2372, 11, 597, 286, 445, 519, 307, 3219, 11, 50796], "temperature": 0.0, "avg_logprob": -0.14536738786541048, "compression_ratio": 1.5906040268456376, "no_speech_prob": 0.002115596318617463}, {"id": 186, "seek": 116760, "start": 1176.24, "end": 1181.76, "text": " given the fact of, that regular expressions in ABNF have been doing it forever, and ABNF, but", "tokens": [50796, 2212, 264, 1186, 295, 11, 300, 3890, 15277, 294, 13838, 45, 37, 362, 668, 884, 309, 5680, 11, 293, 13838, 45, 37, 11, 457, 51072], "temperature": 0.0, "avg_logprob": -0.14536738786541048, "compression_ratio": 1.5906040268456376, "no_speech_prob": 0.002115596318617463}, {"id": 187, "seek": 116760, "start": 1181.76, "end": 1186.1599999999999, "text": " PEG decided not to do that. So that's one of the reasons I made PEG in, because we clearly want", "tokens": [51072, 24346, 38, 3047, 406, 281, 360, 300, 13, 407, 300, 311, 472, 295, 264, 4112, 286, 1027, 24346, 38, 294, 11, 570, 321, 4448, 528, 51292], "temperature": 0.0, "avg_logprob": -0.14536738786541048, "compression_ratio": 1.5906040268456376, "no_speech_prob": 0.002115596318617463}, {"id": 188, "seek": 116760, "start": 1186.1599999999999, "end": 1191.04, "text": " the combination of those things. All right, so let me go back to here. So I went ahead and I", "tokens": [51292, 264, 6562, 295, 729, 721, 13, 1057, 558, 11, 370, 718, 385, 352, 646, 281, 510, 13, 407, 286, 1437, 2286, 293, 286, 51536], "temperature": 0.0, "avg_logprob": -0.14536738786541048, "compression_ratio": 1.5906040268456376, "no_speech_prob": 0.002115596318617463}, {"id": 189, "seek": 116760, "start": 1191.04, "end": 1195.12, "text": " implemented a white space function right now. I could have probably automated this, but let's", "tokens": [51536, 12270, 257, 2418, 1901, 2445, 558, 586, 13, 286, 727, 362, 1391, 18473, 341, 11, 457, 718, 311, 51740], "temperature": 0.0, "avg_logprob": -0.14536738786541048, "compression_ratio": 1.5906040268456376, "no_speech_prob": 0.002115596318617463}, {"id": 190, "seek": 119512, "start": 1195.12, "end": 1200.8799999999999, "text": " look at what it looks like. So if we go into the PEG and scan, and you're probably wondering, well,", "tokens": [50364, 574, 412, 437, 309, 1542, 411, 13, 407, 498, 321, 352, 666, 264, 24346, 38, 293, 11049, 11, 293, 291, 434, 1391, 6359, 11, 731, 11, 50652], "temperature": 0.0, "avg_logprob": -0.13056526897109558, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.0009399299742653966}, {"id": 191, "seek": 119512, "start": 1200.8799999999999, "end": 1206.08, "text": " why did you name it scan? Because I wanted it to read well. So let me show you the, the examples", "tokens": [50652, 983, 630, 291, 1315, 309, 11049, 30, 1436, 286, 1415, 309, 281, 1401, 731, 13, 407, 718, 385, 855, 291, 264, 11, 264, 5110, 50912], "temperature": 0.0, "avg_logprob": -0.13056526897109558, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.0009399299742653966}, {"id": 192, "seek": 119512, "start": 1206.08, "end": 1212.56, "text": " here. These are go testable examples, and they are public. You'll remember maybe when I did basic", "tokens": [50912, 510, 13, 1981, 366, 352, 1500, 712, 5110, 11, 293, 436, 366, 1908, 13, 509, 603, 1604, 1310, 562, 286, 630, 3875, 51236], "temperature": 0.0, "avg_logprob": -0.13056526897109558, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.0009399299742653966}, {"id": 193, "seek": 119512, "start": 1212.56, "end": 1219.52, "text": " MD that I kept a bunch of my scanning, not public. I was like, because I didn't want people to become", "tokens": [51236, 22521, 300, 286, 4305, 257, 3840, 295, 452, 27019, 11, 406, 1908, 13, 286, 390, 411, 11, 570, 286, 994, 380, 528, 561, 281, 1813, 51584], "temperature": 0.0, "avg_logprob": -0.13056526897109558, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.0009399299742653966}, {"id": 194, "seek": 121952, "start": 1219.52, "end": 1226.48, "text": " dependent on my scanner functions, right? I mean, I'm just making a basic markdown part. So I don't", "tokens": [50364, 12334, 322, 452, 30211, 6828, 11, 558, 30, 286, 914, 11, 286, 478, 445, 1455, 257, 3875, 1491, 5093, 644, 13, 407, 286, 500, 380, 50712], "temperature": 0.0, "avg_logprob": -0.06440577109654745, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.06753809750080109}, {"id": 195, "seek": 121952, "start": 1226.48, "end": 1231.44, "text": " want people to be, you know, including my thing, because they want my specific implementations", "tokens": [50712, 528, 561, 281, 312, 11, 291, 458, 11, 3009, 452, 551, 11, 570, 436, 528, 452, 2685, 4445, 763, 50960], "temperature": 0.0, "avg_logprob": -0.06440577109654745, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.06753809750080109}, {"id": 196, "seek": 121952, "start": 1231.44, "end": 1235.92, "text": " of these. And that's one of the reasons I started thinking, hmm, I should probably think more deeply", "tokens": [50960, 295, 613, 13, 400, 300, 311, 472, 295, 264, 4112, 286, 1409, 1953, 11, 16478, 11, 286, 820, 1391, 519, 544, 8760, 51184], "temperature": 0.0, "avg_logprob": -0.06440577109654745, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.06753809750080109}, {"id": 197, "seek": 121952, "start": 1235.92, "end": 1241.76, "text": " about some of these scan functions that are going to be reusable. And I should probably put them", "tokens": [51184, 466, 512, 295, 613, 11049, 6828, 300, 366, 516, 281, 312, 41807, 13, 400, 286, 820, 1391, 829, 552, 51476], "temperature": 0.0, "avg_logprob": -0.06440577109654745, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.06753809750080109}, {"id": 198, "seek": 121952, "start": 1241.76, "end": 1247.68, "text": " somewhere where they could easily be reused by me and others. And that's what got me to do this.", "tokens": [51476, 4079, 689, 436, 727, 3612, 312, 319, 4717, 538, 385, 293, 2357, 13, 400, 300, 311, 437, 658, 385, 281, 360, 341, 13, 51772], "temperature": 0.0, "avg_logprob": -0.06440577109654745, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.06753809750080109}, {"id": 199, "seek": 124768, "start": 1247.76, "end": 1252.64, "text": " So I've created a convention called sum, which is just a nice happy way. It's like, you know,", "tokens": [50368, 407, 286, 600, 2942, 257, 10286, 1219, 2408, 11, 597, 307, 445, 257, 1481, 2055, 636, 13, 467, 311, 411, 11, 291, 458, 11, 50612], "temperature": 0.0, "avg_logprob": -0.1505081787109375, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.00017400221258867532}, {"id": 200, "seek": 124768, "start": 1252.64, "end": 1256.8, "text": " go, they like have must and compile and things like that. So I created a convention where you", "tokens": [50612, 352, 11, 436, 411, 362, 1633, 293, 31413, 293, 721, 411, 300, 13, 407, 286, 2942, 257, 10286, 689, 291, 50820], "temperature": 0.0, "avg_logprob": -0.1505081787109375, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.00017400221258867532}, {"id": 201, "seek": 124768, "start": 1256.8, "end": 1260.8, "text": " put sum in front. These are all documenting the design considerations on the read me page, by the", "tokens": [50820, 829, 2408, 294, 1868, 13, 1981, 366, 439, 42360, 264, 1715, 24070, 322, 264, 1401, 385, 3028, 11, 538, 264, 51020], "temperature": 0.0, "avg_logprob": -0.1505081787109375, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.00017400221258867532}, {"id": 202, "seek": 124768, "start": 1260.8, "end": 1268.72, "text": " way. But sum means, you know, zero or more white space or one or more white space. So if I have", "tokens": [51020, 636, 13, 583, 2408, 1355, 11, 291, 458, 11, 4018, 420, 544, 2418, 1901, 420, 472, 420, 544, 2418, 1901, 13, 407, 498, 286, 362, 51416], "temperature": 0.0, "avg_logprob": -0.1505081787109375, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.00017400221258867532}, {"id": 203, "seek": 124768, "start": 1268.72, "end": 1273.44, "text": " example sum WS, so, and then I the reason I named this sub package scan is so that we would get", "tokens": [51416, 1365, 2408, 343, 50, 11, 370, 11, 293, 550, 286, 264, 1778, 286, 4926, 341, 1422, 7372, 11049, 307, 370, 300, 321, 576, 483, 51652], "temperature": 0.0, "avg_logprob": -0.1505081787109375, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.00017400221258867532}, {"id": 204, "seek": 127344, "start": 1273.44, "end": 1279.3600000000001, "text": " these wonderful readable lines here scan dot sum white space and then pass in the scanner.", "tokens": [50364, 613, 3715, 49857, 3876, 510, 11049, 5893, 2408, 2418, 1901, 293, 550, 1320, 294, 264, 30211, 13, 50660], "temperature": 0.0, "avg_logprob": -0.12400643418474895, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.01798420213162899}, {"id": 205, "seek": 127344, "start": 1279.3600000000001, "end": 1284.16, "text": " Now you might be asking as many, many people will tell you that have done scanners that", "tokens": [50660, 823, 291, 1062, 312, 3365, 382, 867, 11, 867, 561, 486, 980, 291, 300, 362, 1096, 795, 25792, 300, 50900], "temperature": 0.0, "avg_logprob": -0.12400643418474895, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.01798420213162899}, {"id": 206, "seek": 127344, "start": 1284.16, "end": 1290.72, "text": " they implement the scanner as a class, which I think is disastrously bad architectural decision,", "tokens": [50900, 436, 4445, 264, 30211, 382, 257, 1508, 11, 597, 286, 519, 307, 42103, 81, 5098, 1578, 26621, 3537, 11, 51228], "temperature": 0.0, "avg_logprob": -0.12400643418474895, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.01798420213162899}, {"id": 207, "seek": 127344, "start": 1290.72, "end": 1297.8400000000001, "text": " because you cannot do anything with it at all. And tell you expand the class,", "tokens": [51228, 570, 291, 2644, 360, 1340, 365, 309, 412, 439, 13, 400, 980, 291, 5268, 264, 1508, 11, 51584], "temperature": 0.0, "avg_logprob": -0.12400643418474895, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.01798420213162899}, {"id": 208, "seek": 129784, "start": 1297.84, "end": 1303.52, "text": " that is the primary reason that people like Jim Copeland and others hate class based object", "tokens": [50364, 300, 307, 264, 6194, 1778, 300, 561, 411, 6637, 11579, 15280, 293, 2357, 4700, 1508, 2361, 2657, 50648], "temperature": 0.0, "avg_logprob": -0.1181802749633789, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.019122714176774025}, {"id": 209, "seek": 129784, "start": 1303.52, "end": 1310.1599999999999, "text": " oriented programming. It is so concrete, you can never extend it, not without re implementing the", "tokens": [50648, 21841, 9410, 13, 467, 307, 370, 9859, 11, 291, 393, 1128, 10101, 309, 11, 406, 1553, 319, 18114, 264, 50980], "temperature": 0.0, "avg_logprob": -0.1181802749633789, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.019122714176774025}, {"id": 210, "seek": 129784, "start": 1310.1599999999999, "end": 1315.6, "text": " class or subclassing it by doing it this way. I can use first class functions is a very functional", "tokens": [50980, 1508, 420, 1422, 11665, 278, 309, 538, 884, 309, 341, 636, 13, 286, 393, 764, 700, 1508, 6828, 307, 257, 588, 11745, 51252], "temperature": 0.0, "avg_logprob": -0.1181802749633789, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.019122714176774025}, {"id": 211, "seek": 129784, "start": 1315.6, "end": 1319.84, "text": " approach. I can use first class functions if I want, I can use it from a package, whatever,", "tokens": [51252, 3109, 13, 286, 393, 764, 700, 1508, 6828, 498, 286, 528, 11, 286, 393, 764, 309, 490, 257, 7372, 11, 2035, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1181802749633789, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.019122714176774025}, {"id": 212, "seek": 129784, "start": 1319.84, "end": 1327.04, "text": " because the scanner is an argument to the function. And so as long as the scanner fulfills the", "tokens": [51464, 570, 264, 30211, 307, 364, 6770, 281, 264, 2445, 13, 400, 370, 382, 938, 382, 264, 30211, 8081, 2565, 264, 51824], "temperature": 0.0, "avg_logprob": -0.1181802749633789, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.019122714176774025}, {"id": 213, "seek": 132704, "start": 1327.12, "end": 1331.84, "text": " interface, this is why interfaces are king. This is why interfaces are part of solid,", "tokens": [50368, 9226, 11, 341, 307, 983, 28416, 366, 4867, 13, 639, 307, 983, 28416, 366, 644, 295, 5100, 11, 50604], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 214, "seek": 132704, "start": 1331.84, "end": 1336.96, "text": " even in modern Java development. If you're not doing this, if you're writing a scanner,", "tokens": [50604, 754, 294, 4363, 10745, 3250, 13, 759, 291, 434, 406, 884, 341, 11, 498, 291, 434, 3579, 257, 30211, 11, 50860], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 215, "seek": 132704, "start": 1336.96, "end": 1341.84, "text": " writing a class and extending the class with all of the different types and then having to do that", "tokens": [50860, 3579, 257, 1508, 293, 24360, 264, 1508, 365, 439, 295, 264, 819, 3467, 293, 550, 1419, 281, 360, 300, 51104], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 216, "seek": 132704, "start": 1341.84, "end": 1345.12, "text": " every time you're doing it wrong, in my opinion, because you're never going to be able to extend", "tokens": [51104, 633, 565, 291, 434, 884, 309, 2085, 11, 294, 452, 4800, 11, 570, 291, 434, 1128, 516, 281, 312, 1075, 281, 10101, 51268], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 217, "seek": 132704, "start": 1345.12, "end": 1349.2, "text": " that in any way that's going to be reusable for anybody. And maybe you don't care about that.", "tokens": [51268, 300, 294, 604, 636, 300, 311, 516, 281, 312, 41807, 337, 4472, 13, 400, 1310, 291, 500, 380, 1127, 466, 300, 13, 51472], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 218, "seek": 132704, "start": 1349.2, "end": 1354.0, "text": " I do. I want it to be reusable. I want to, I want to create, ultimately, I want to build up,", "tokens": [51472, 286, 360, 13, 286, 528, 309, 281, 312, 41807, 13, 286, 528, 281, 11, 286, 528, 281, 1884, 11, 6284, 11, 286, 528, 281, 1322, 493, 11, 51712], "temperature": 0.0, "avg_logprob": -0.08669730978952327, "compression_ratio": 1.9238754325259515, "no_speech_prob": 0.004468088038265705}, {"id": 219, "seek": 135400, "start": 1354.0, "end": 1360.88, "text": " you know, hundreds or more scan functions that can be used with anything whatsoever", "tokens": [50364, 291, 458, 11, 6779, 420, 544, 11049, 6828, 300, 393, 312, 1143, 365, 1340, 17076, 50708], "temperature": 0.0, "avg_logprob": -0.1218744260924203, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0011694752611219883}, {"id": 220, "seek": 135400, "start": 1360.88, "end": 1365.44, "text": " that implements the scanner interface. And that's why interfaces are so amazing.", "tokens": [50708, 300, 704, 17988, 264, 30211, 9226, 13, 400, 300, 311, 983, 28416, 366, 370, 2243, 13, 50936], "temperature": 0.0, "avg_logprob": -0.1218744260924203, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0011694752611219883}, {"id": 221, "seek": 135400, "start": 1365.44, "end": 1370.88, "text": " So I pass a scanner interface, I say scan some WS and I get a true or false. So this prints out", "tokens": [50936, 407, 286, 1320, 257, 30211, 9226, 11, 286, 584, 11049, 512, 343, 50, 293, 286, 483, 257, 2074, 420, 7908, 13, 407, 341, 22305, 484, 51208], "temperature": 0.0, "avg_logprob": -0.1218744260924203, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0011694752611219883}, {"id": 222, "seek": 135400, "start": 1370.88, "end": 1378.0, "text": " false because the first number is a one. Now I added a constructor. There's really not constructors", "tokens": [51208, 7908, 570, 264, 700, 1230, 307, 257, 472, 13, 823, 286, 3869, 257, 47479, 13, 821, 311, 534, 406, 7690, 830, 51564], "temperature": 0.0, "avg_logprob": -0.1218744260924203, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0011694752611219883}, {"id": 223, "seek": 135400, "start": 1378.0, "end": 1382.8, "text": " and go, but it's the closest word for it. And this takes an optional argument. Now constructors are", "tokens": [51564, 293, 352, 11, 457, 309, 311, 264, 13699, 1349, 337, 309, 13, 400, 341, 2516, 364, 17312, 6770, 13, 823, 7690, 830, 366, 51804], "temperature": 0.0, "avg_logprob": -0.1218744260924203, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0011694752611219883}, {"id": 224, "seek": 138280, "start": 1382.8, "end": 1386.96, "text": " very, very high level. So they don't have to be performant, right? Especially since you're not", "tokens": [50364, 588, 11, 588, 1090, 1496, 13, 407, 436, 500, 380, 362, 281, 312, 2042, 394, 11, 558, 30, 8545, 1670, 291, 434, 406, 50572], "temperature": 0.0, "avg_logprob": -0.1362439230376599, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.002980792662128806}, {"id": 225, "seek": 138280, "start": 1386.96, "end": 1393.52, "text": " going to be buffering a lot. So I put an optional parameter to on the constructor. If you pass in", "tokens": [50572, 516, 281, 312, 9204, 1794, 257, 688, 13, 407, 286, 829, 364, 17312, 13075, 281, 322, 264, 47479, 13, 759, 291, 1320, 294, 50900], "temperature": 0.0, "avg_logprob": -0.1362439230376599, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.002980792662128806}, {"id": 226, "seek": 138280, "start": 1393.52, "end": 1401.76, "text": " a string or a reader or a bytes buffer, any of those things, it will work. And it will just", "tokens": [50900, 257, 6798, 420, 257, 15149, 420, 257, 36088, 21762, 11, 604, 295, 729, 721, 11, 309, 486, 589, 13, 400, 309, 486, 445, 51312], "temperature": 0.0, "avg_logprob": -0.1362439230376599, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.002980792662128806}, {"id": 227, "seek": 138280, "start": 1402.48, "end": 1408.24, "text": " slurp all of the thing into memory. And then it will allow the scanner to work on that, that bytes", "tokens": [51348, 1061, 20130, 439, 295, 264, 551, 666, 4675, 13, 400, 550, 309, 486, 2089, 264, 30211, 281, 589, 322, 300, 11, 300, 36088, 51636], "temperature": 0.0, "avg_logprob": -0.1362439230376599, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.002980792662128806}, {"id": 228, "seek": 140824, "start": 1408.24, "end": 1413.52, "text": " buffer. And so then we do this to say, so, so you can see here, we, we, it's, you see, it was false", "tokens": [50364, 21762, 13, 400, 370, 550, 321, 360, 341, 281, 584, 11, 370, 11, 370, 291, 393, 536, 510, 11, 321, 11, 321, 11, 309, 311, 11, 291, 536, 11, 309, 390, 7908, 50628], "temperature": 0.0, "avg_logprob": -0.16637866250399885, "compression_ratio": 1.721461187214612, "no_speech_prob": 0.0029809586703777313}, {"id": 229, "seek": 140824, "start": 1413.52, "end": 1420.24, "text": " that it's not currently the scan WS failed here. Because why? And you'll notice too that it didn't", "tokens": [50628, 300, 309, 311, 406, 4362, 264, 11049, 343, 50, 7612, 510, 13, 1436, 983, 30, 400, 291, 603, 3449, 886, 300, 309, 994, 380, 50964], "temperature": 0.0, "avg_logprob": -0.16637866250399885, "compression_ratio": 1.721461187214612, "no_speech_prob": 0.0029809586703777313}, {"id": 230, "seek": 140824, "start": 1420.24, "end": 1426.8, "text": " advance the, it didn't advance the, it's not supposed to. That actually looks like a mistake.", "tokens": [50964, 7295, 264, 11, 309, 994, 380, 7295, 264, 11, 309, 311, 406, 3442, 281, 13, 663, 767, 1542, 411, 257, 6146, 13, 51292], "temperature": 0.0, "avg_logprob": -0.16637866250399885, "compression_ratio": 1.721461187214612, "no_speech_prob": 0.0029809586703777313}, {"id": 231, "seek": 140824, "start": 1428.16, "end": 1432.48, "text": " That might be a mistake. Let me check here. Oh, no, no, no, no. Okay, let's do this.", "tokens": [51360, 663, 1062, 312, 257, 6146, 13, 961, 385, 1520, 510, 13, 876, 11, 572, 11, 572, 11, 572, 11, 572, 13, 1033, 11, 718, 311, 360, 341, 13, 51576], "temperature": 0.0, "avg_logprob": -0.16637866250399885, "compression_ratio": 1.721461187214612, "no_speech_prob": 0.0029809586703777313}, {"id": 232, "seek": 143248, "start": 1433.2, "end": 1439.28, "text": " Wait, what? Advance to nothing at all output.", "tokens": [50400, 3802, 11, 437, 30, 44425, 281, 1825, 412, 439, 5598, 13, 50704], "temperature": 0.0, "avg_logprob": -0.21259329784875627, "compression_ratio": 1.3980099502487562, "no_speech_prob": 0.009558823890984058}, {"id": 233, "seek": 143248, "start": 1440.96, "end": 1446.16, "text": " Example sum WS. I think I might have a problem with this one. Anyway, it's supposed to,", "tokens": [50788, 24755, 781, 2408, 343, 50, 13, 286, 519, 286, 1062, 362, 257, 1154, 365, 341, 472, 13, 5684, 11, 309, 311, 3442, 281, 11, 51048], "temperature": 0.0, "avg_logprob": -0.21259329784875627, "compression_ratio": 1.3980099502487562, "no_speech_prob": 0.009558823890984058}, {"id": 234, "seek": 143248, "start": 1446.8, "end": 1449.6, "text": " I just barely fixed these. That's why I want to make sure it's okay.", "tokens": [51080, 286, 445, 10268, 6806, 613, 13, 663, 311, 983, 286, 528, 281, 652, 988, 309, 311, 1392, 13, 51220], "temperature": 0.0, "avg_logprob": -0.21259329784875627, "compression_ratio": 1.3980099502487562, "no_speech_prob": 0.009558823890984058}, {"id": 235, "seek": 143248, "start": 1450.64, "end": 1456.4, "text": " Sum WS. Is it not, isn't that working? I'm going to go try something. Go test,", "tokens": [51272, 8626, 343, 50, 13, 1119, 309, 406, 11, 1943, 380, 300, 1364, 30, 286, 478, 516, 281, 352, 853, 746, 13, 1037, 1500, 11, 51560], "temperature": 0.0, "avg_logprob": -0.21259329784875627, "compression_ratio": 1.3980099502487562, "no_speech_prob": 0.009558823890984058}, {"id": 236, "seek": 145640, "start": 1456.4, "end": 1467.1200000000001, "text": " run sum WS. Well, let's turn a trace on. Oh, this is cool. I finally got traced to working again.", "tokens": [50364, 1190, 2408, 343, 50, 13, 1042, 11, 718, 311, 1261, 257, 13508, 322, 13, 876, 11, 341, 307, 1627, 13, 286, 2721, 658, 38141, 281, 1364, 797, 13, 50900], "temperature": 0.0, "avg_logprob": -0.16222529691808363, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.000666688836645335}, {"id": 237, "seek": 145640, "start": 1468.0800000000002, "end": 1475.3600000000001, "text": " So trace, that'll turn trace on. And when we run it, we should be able to see every step of the way.", "tokens": [50948, 407, 13508, 11, 300, 603, 1261, 13508, 322, 13, 400, 562, 321, 1190, 309, 11, 321, 820, 312, 1075, 281, 536, 633, 1823, 295, 264, 636, 13, 51312], "temperature": 0.0, "avg_logprob": -0.16222529691808363, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.000666688836645335}, {"id": 238, "seek": 145640, "start": 1476.64, "end": 1484.0, "text": " So the first call to scan, got it. That's what with the first, that's every time,", "tokens": [51376, 407, 264, 700, 818, 281, 11049, 11, 658, 309, 13, 663, 311, 437, 365, 264, 700, 11, 300, 311, 633, 565, 11, 51744], "temperature": 0.0, "avg_logprob": -0.16222529691808363, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.000666688836645335}, {"id": 239, "seek": 148400, "start": 1484.0, "end": 1488.72, "text": " every time scan gets called, it prints it. So scan, scan the one in, and that shows us the,", "tokens": [50364, 633, 565, 11049, 2170, 1219, 11, 309, 22305, 309, 13, 407, 11049, 11, 11049, 264, 472, 294, 11, 293, 300, 3110, 505, 264, 11, 50600], "temperature": 0.0, "avg_logprob": -0.15120780012989773, "compression_ratio": 1.8943089430894309, "no_speech_prob": 0.0028893756680190563}, {"id": 240, "seek": 148400, "start": 1488.72, "end": 1491.92, "text": " from between zero and one, and then what's left in the buffer and there's a space.", "tokens": [50600, 490, 1296, 4018, 293, 472, 11, 293, 550, 437, 311, 1411, 294, 264, 21762, 293, 456, 311, 257, 1901, 13, 50760], "temperature": 0.0, "avg_logprob": -0.15120780012989773, "compression_ratio": 1.8943089430894309, "no_speech_prob": 0.0028893756680190563}, {"id": 241, "seek": 148400, "start": 1491.92, "end": 1496.56, "text": " And then it shows we scanned a, a space and that was between one and two. It could be one and three,", "tokens": [50760, 400, 550, 309, 3110, 321, 45089, 257, 11, 257, 1901, 293, 300, 390, 1296, 472, 293, 732, 13, 467, 727, 312, 472, 293, 1045, 11, 50992], "temperature": 0.0, "avg_logprob": -0.15120780012989773, "compression_ratio": 1.8943089430894309, "no_speech_prob": 0.0028893756680190563}, {"id": 242, "seek": 148400, "start": 1496.56, "end": 1502.4, "text": " depending on the size of the rune. And then as the buffer is empty. So, so that shows it's doing", "tokens": [50992, 5413, 322, 264, 2744, 295, 264, 1190, 68, 13, 400, 550, 382, 264, 21762, 307, 6707, 13, 407, 11, 370, 300, 3110, 309, 311, 884, 51284], "temperature": 0.0, "avg_logprob": -0.15120780012989773, "compression_ratio": 1.8943089430894309, "no_speech_prob": 0.0028893756680190563}, {"id": 243, "seek": 148400, "start": 1502.4, "end": 1510.88, "text": " what we wanted to, I just was, oh, I know why. It's doing that because it's actually, because", "tokens": [51284, 437, 321, 1415, 281, 11, 286, 445, 390, 11, 1954, 11, 286, 458, 983, 13, 467, 311, 884, 300, 570, 309, 311, 767, 11, 570, 51708], "temperature": 0.0, "avg_logprob": -0.15120780012989773, "compression_ratio": 1.8943089430894309, "no_speech_prob": 0.0028893756680190563}, {"id": 244, "seek": 151088, "start": 1510.88, "end": 1516.3200000000002, "text": " this actually did do some scanning and it did not reset. Actually, that's a, that's a, that's a", "tokens": [50364, 341, 767, 630, 360, 512, 27019, 293, 309, 630, 406, 14322, 13, 5135, 11, 300, 311, 257, 11, 300, 311, 257, 11, 300, 311, 257, 50636], "temperature": 0.0, "avg_logprob": -0.12793028532569087, "compression_ratio": 1.935483870967742, "no_speech_prob": 0.0017545766895636916}, {"id": 245, "seek": 151088, "start": 1516.3200000000002, "end": 1522.3200000000002, "text": " mistake. That's a mistake. I need to fix this. This, because it didn't scan, it should not have", "tokens": [50636, 6146, 13, 663, 311, 257, 6146, 13, 286, 643, 281, 3191, 341, 13, 639, 11, 570, 309, 994, 380, 11049, 11, 309, 820, 406, 362, 50936], "temperature": 0.0, "avg_logprob": -0.12793028532569087, "compression_ratio": 1.935483870967742, "no_speech_prob": 0.0017545766895636916}, {"id": 246, "seek": 151088, "start": 1522.3200000000002, "end": 1525.7600000000002, "text": " advanced the buffer at all. It should have been, I've got to do this. This is a nice catch.", "tokens": [50936, 7339, 264, 21762, 412, 439, 13, 467, 820, 362, 668, 11, 286, 600, 658, 281, 360, 341, 13, 639, 307, 257, 1481, 3745, 13, 51108], "temperature": 0.0, "avg_logprob": -0.12793028532569087, "compression_ratio": 1.935483870967742, "no_speech_prob": 0.0017545766895636916}, {"id": 247, "seek": 151088, "start": 1527.3600000000001, "end": 1531.92, "text": " And again, this is just, this is the bug in this, in the scanner function only not the scanner itself.", "tokens": [51188, 400, 797, 11, 341, 307, 445, 11, 341, 307, 264, 7426, 294, 341, 11, 294, 264, 30211, 2445, 787, 406, 264, 30211, 2564, 13, 51416], "temperature": 0.0, "avg_logprob": -0.12793028532569087, "compression_ratio": 1.935483870967742, "no_speech_prob": 0.0017545766895636916}, {"id": 248, "seek": 151088, "start": 1533.2800000000002, "end": 1538.0800000000002, "text": " Trace is internal. Trace is, Trace is a part of this scanner implementation. It's not part of", "tokens": [51484, 1765, 617, 307, 6920, 13, 1765, 617, 307, 11, 1765, 617, 307, 257, 644, 295, 341, 30211, 11420, 13, 467, 311, 406, 644, 295, 51724], "temperature": 0.0, "avg_logprob": -0.12793028532569087, "compression_ratio": 1.935483870967742, "no_speech_prob": 0.0017545766895636916}, {"id": 249, "seek": 153808, "start": 1538.08, "end": 1544.56, "text": " the forced interface. No, it's not. You don't have to have a scanner in there. It's, that's part", "tokens": [50364, 264, 7579, 9226, 13, 883, 11, 309, 311, 406, 13, 509, 500, 380, 362, 281, 362, 257, 30211, 294, 456, 13, 467, 311, 11, 300, 311, 644, 50688], "temperature": 0.0, "avg_logprob": -0.10704831096613518, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.002472532680258155}, {"id": 250, "seek": 153808, "start": 1544.56, "end": 1549.52, "text": " of this scanner implementation. So, you know, I don't want to burden people with those kind of", "tokens": [50688, 295, 341, 30211, 11420, 13, 407, 11, 291, 458, 11, 286, 500, 380, 528, 281, 12578, 561, 365, 729, 733, 295, 50936], "temperature": 0.0, "avg_logprob": -0.10704831096613518, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.002472532680258155}, {"id": 251, "seek": 153808, "start": 1549.52, "end": 1556.8, "text": " details that they, they want to do their own, they can, right? So, I mean, but yeah, you could", "tokens": [50936, 4365, 300, 436, 11, 436, 528, 281, 360, 641, 1065, 11, 436, 393, 11, 558, 30, 407, 11, 286, 914, 11, 457, 1338, 11, 291, 727, 51300], "temperature": 0.0, "avg_logprob": -0.10704831096613518, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.002472532680258155}, {"id": 252, "seek": 153808, "start": 1556.8, "end": 1561.1999999999998, "text": " extend that and do what you want with it. So this is, this is actually wrong. This should have been", "tokens": [51300, 10101, 300, 293, 360, 437, 291, 528, 365, 309, 13, 407, 341, 307, 11, 341, 307, 767, 2085, 13, 639, 820, 362, 668, 51520], "temperature": 0.0, "avg_logprob": -0.10704831096613518, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.002472532680258155}, {"id": 253, "seek": 156120, "start": 1561.2, "end": 1564.4, "text": " x00 and it should have been", "tokens": [50364, 2031, 628, 293, 309, 820, 362, 668, 50524], "temperature": 0.0, "avg_logprob": -0.12618449756077357, "compression_ratio": 2.1164383561643834, "no_speech_prob": 0.025954773649573326}, {"id": 254, "seek": 156120, "start": 1566.4, "end": 1572.32, "text": " zero to zero and then it should have been a one here. That's what it should be. And then when", "tokens": [50624, 4018, 281, 4018, 293, 550, 309, 820, 362, 668, 257, 472, 510, 13, 663, 311, 437, 309, 820, 312, 13, 400, 550, 562, 50920], "temperature": 0.0, "avg_logprob": -0.12618449756077357, "compression_ratio": 2.1164383561643834, "no_speech_prob": 0.025954773649573326}, {"id": 255, "seek": 156120, "start": 1572.32, "end": 1579.1200000000001, "text": " you do the scan, it should go through and then it should have been a one and a zero to one.", "tokens": [50920, 291, 360, 264, 11049, 11, 309, 820, 352, 807, 293, 550, 309, 820, 362, 668, 257, 472, 293, 257, 4018, 281, 472, 13, 51260], "temperature": 0.0, "avg_logprob": -0.12618449756077357, "compression_ratio": 2.1164383561643834, "no_speech_prob": 0.025954773649573326}, {"id": 256, "seek": 156120, "start": 1581.1200000000001, "end": 1587.8400000000001, "text": " And then, and then that should have left us with a space and it should have been false and then", "tokens": [51360, 400, 550, 11, 293, 550, 300, 820, 362, 1411, 505, 365, 257, 1901, 293, 309, 820, 362, 668, 7908, 293, 550, 51696], "temperature": 0.0, "avg_logprob": -0.12618449756077357, "compression_ratio": 2.1164383561643834, "no_speech_prob": 0.025954773649573326}, {"id": 257, "seek": 158784, "start": 1587.84, "end": 1597.52, "text": " it should have been true. This one should have probably printed true. Yeah. Something might", "tokens": [50364, 309, 820, 362, 668, 2074, 13, 639, 472, 820, 362, 1391, 13567, 2074, 13, 865, 13, 6595, 1062, 50848], "temperature": 0.0, "avg_logprob": -0.09956672327305244, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.0002959539706353098}, {"id": 258, "seek": 158784, "start": 1597.52, "end": 1604.0, "text": " be wrong with that today. All right. So that, that's how it should look. So let's, that means", "tokens": [50848, 312, 2085, 365, 300, 965, 13, 1057, 558, 13, 407, 300, 11, 300, 311, 577, 309, 820, 574, 13, 407, 718, 311, 11, 300, 1355, 51172], "temperature": 0.0, "avg_logprob": -0.09956672327305244, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.0002959539706353098}, {"id": 259, "seek": 158784, "start": 1604.0, "end": 1608.48, "text": " there's a problem with my function, my scan function, which is what I was debugging before,", "tokens": [51172, 456, 311, 257, 1154, 365, 452, 2445, 11, 452, 11049, 2445, 11, 597, 307, 437, 286, 390, 45592, 949, 11, 51396], "temperature": 0.0, "avg_logprob": -0.09956672327305244, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.0002959539706353098}, {"id": 260, "seek": 158784, "start": 1608.48, "end": 1612.48, "text": " but let me show you how to do this. So there may actually be a problem with my mark and I'm,", "tokens": [51396, 457, 718, 385, 855, 291, 577, 281, 360, 341, 13, 407, 456, 815, 767, 312, 257, 1154, 365, 452, 1491, 293, 286, 478, 11, 51596], "temperature": 0.0, "avg_logprob": -0.09956672327305244, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.0002959539706353098}, {"id": 261, "seek": 158784, "start": 1612.48, "end": 1616.08, "text": " I'm hoping not to, I think, I think that might be, there might be something wrong with my mark,", "tokens": [51596, 286, 478, 7159, 406, 281, 11, 286, 519, 11, 286, 519, 300, 1062, 312, 11, 456, 1062, 312, 746, 2085, 365, 452, 1491, 11, 51776], "temperature": 0.0, "avg_logprob": -0.09956672327305244, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.0002959539706353098}, {"id": 262, "seek": 161608, "start": 1616.08, "end": 1619.6799999999998, "text": " which is relatively new. But the point is, I don't know if you saw the functions I was writing", "tokens": [50364, 597, 307, 7226, 777, 13, 583, 264, 935, 307, 11, 286, 500, 380, 458, 498, 291, 1866, 264, 6828, 286, 390, 3579, 50544], "temperature": 0.0, "avg_logprob": -0.09744476893591503, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.0010321945883333683}, {"id": 263, "seek": 161608, "start": 1619.6799999999998, "end": 1627.6799999999998, "text": " yesterday, but these are way, way simpler, right? They just have to scan and check what the runes are", "tokens": [50544, 5186, 11, 457, 613, 366, 636, 11, 636, 18587, 11, 558, 30, 814, 445, 362, 281, 11049, 293, 1520, 437, 264, 1190, 279, 366, 50944], "temperature": 0.0, "avg_logprob": -0.09744476893591503, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.0010321945883333683}, {"id": 264, "seek": 161608, "start": 1628.32, "end": 1634.96, "text": " and scan again and the, the idiom is the same no matter what. You take a, you take a bookmark to", "tokens": [50976, 293, 11049, 797, 293, 264, 11, 264, 18014, 298, 307, 264, 912, 572, 1871, 437, 13, 509, 747, 257, 11, 291, 747, 257, 1446, 5638, 281, 51308], "temperature": 0.0, "avg_logprob": -0.09744476893591503, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.0010321945883333683}, {"id": 265, "seek": 161608, "start": 1634.96, "end": 1640.0, "text": " it at the beginning and you revert back to the bookmark if you're, if you didn't find anything,", "tokens": [51308, 309, 412, 264, 2863, 293, 291, 319, 3281, 646, 281, 264, 1446, 5638, 498, 291, 434, 11, 498, 291, 994, 380, 915, 1340, 11, 51560], "temperature": 0.0, "avg_logprob": -0.09744476893591503, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.0010321945883333683}, {"id": 266, "seek": 161608, "start": 1640.0, "end": 1645.1999999999998, "text": " right? And you leave things as they are. Otherwise you let the scanner happily proceed along", "tokens": [51560, 558, 30, 400, 291, 1856, 721, 382, 436, 366, 13, 10328, 291, 718, 264, 30211, 19909, 8991, 2051, 51820], "temperature": 0.0, "avg_logprob": -0.09744476893591503, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.0010321945883333683}, {"id": 267, "seek": 164520, "start": 1645.76, "end": 1649.44, "text": " and it's not like there's a lot of cash in there so that you, you know, you'd have problems there.", "tokens": [50392, 293, 309, 311, 406, 411, 456, 311, 257, 688, 295, 6388, 294, 456, 370, 300, 291, 11, 291, 458, 11, 291, 1116, 362, 2740, 456, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1303209221881369, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.002472519176080823}, {"id": 268, "seek": 164520, "start": 1652.0800000000002, "end": 1655.1200000000001, "text": " But yeah, I have, I have a problem with this one. I got to come back to that. I can't see it right", "tokens": [50708, 583, 1338, 11, 286, 362, 11, 286, 362, 257, 1154, 365, 341, 472, 13, 286, 658, 281, 808, 646, 281, 300, 13, 286, 393, 380, 536, 309, 558, 50860], "temperature": 0.0, "avg_logprob": -0.1303209221881369, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.002472519176080823}, {"id": 269, "seek": 164520, "start": 1655.1200000000001, "end": 1661.04, "text": " out hand, but so this is actually, you know, this, this is supposed to scan as much white", "tokens": [50860, 484, 1011, 11, 457, 370, 341, 307, 767, 11, 291, 458, 11, 341, 11, 341, 307, 3442, 281, 11049, 382, 709, 2418, 51156], "temperature": 0.0, "avg_logprob": -0.1303209221881369, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.002472519176080823}, {"id": 270, "seek": 164520, "start": 1661.04, "end": 1669.6000000000001, "text": " space as possible. I think the problem is, I don't know, we might be getting ruined. I don't", "tokens": [51156, 1901, 382, 1944, 13, 286, 519, 264, 1154, 307, 11, 286, 500, 380, 458, 11, 321, 1062, 312, 1242, 17013, 13, 286, 500, 380, 51584], "temperature": 0.0, "avg_logprob": -0.1303209221881369, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.002472519176080823}, {"id": 271, "seek": 164520, "start": 1669.6000000000001, "end": 1673.2, "text": " know, I'll have to go debug this one. But if, if I wanted to just debug this one too, I could", "tokens": [51584, 458, 11, 286, 603, 362, 281, 352, 24083, 341, 472, 13, 583, 498, 11, 498, 286, 1415, 281, 445, 24083, 341, 472, 886, 11, 286, 727, 51764], "temperature": 0.0, "avg_logprob": -0.1303209221881369, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.002472519176080823}, {"id": 272, "seek": 167320, "start": 1673.2, "end": 1679.92, "text": " also just do this. I could just do s.trace and turn on the tracing in here while I'm doing this", "tokens": [50364, 611, 445, 360, 341, 13, 286, 727, 445, 360, 262, 13, 6903, 617, 293, 1261, 322, 264, 25262, 294, 510, 1339, 286, 478, 884, 341, 50700], "temperature": 0.0, "avg_logprob": -0.11164856840063024, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.004331355914473534}, {"id": 273, "seek": 167320, "start": 1679.92, "end": 1687.44, "text": " debugging. I can put it there in the test either way. Oh, it's not, that's right. I forgot about", "tokens": [50700, 45592, 13, 286, 393, 829, 309, 456, 294, 264, 1500, 2139, 636, 13, 876, 11, 309, 311, 406, 11, 300, 311, 558, 13, 286, 5298, 466, 51076], "temperature": 0.0, "avg_logprob": -0.11164856840063024, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.004331355914473534}, {"id": 274, "seek": 167320, "start": 1687.44, "end": 1692.0, "text": " that. Man, this is going to be interesting. Yeah. Cause you just said, is that in the, is that in the", "tokens": [51076, 300, 13, 2458, 11, 341, 307, 516, 281, 312, 1880, 13, 865, 13, 10865, 291, 445, 848, 11, 307, 300, 294, 264, 11, 307, 300, 294, 264, 51304], "temperature": 0.0, "avg_logprob": -0.11164856840063024, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.004331355914473534}, {"id": 275, "seek": 167320, "start": 1692.0, "end": 1702.0800000000002, "text": " debug output? Interesting. Yeah, I just realized I'm saying, because I locked down the interface", "tokens": [51304, 24083, 5598, 30, 14711, 13, 865, 11, 286, 445, 5334, 286, 478, 1566, 11, 570, 286, 9376, 760, 264, 9226, 51808], "temperature": 0.0, "avg_logprob": -0.11164856840063024, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.004331355914473534}, {"id": 276, "seek": 170208, "start": 1702.08, "end": 1704.8, "text": " and I'm going to keep a bunch of stuff out of here. I'm not going to be able to do because,", "tokens": [50364, 293, 286, 478, 516, 281, 1066, 257, 3840, 295, 1507, 484, 295, 510, 13, 286, 478, 406, 516, 281, 312, 1075, 281, 360, 570, 11, 50500], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 277, "seek": 170208, "start": 1704.8, "end": 1708.96, "text": " because this is, expects a scanner interface and that means only things that are, are defined in", "tokens": [50500, 570, 341, 307, 11, 33280, 257, 30211, 9226, 293, 300, 1355, 787, 721, 300, 366, 11, 366, 7642, 294, 50708], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 278, "seek": 170208, "start": 1708.96, "end": 1713.52, "text": " the scanner interface can, can turn on. I wonder if we should make trace into the part of the", "tokens": [50708, 264, 30211, 9226, 393, 11, 393, 1261, 322, 13, 286, 2441, 498, 321, 820, 652, 13508, 666, 264, 644, 295, 264, 50936], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 279, "seek": 170208, "start": 1713.52, "end": 1718.24, "text": " interface. We should say you need to implement some form of activating trace. I don't think we", "tokens": [50936, 9226, 13, 492, 820, 584, 291, 643, 281, 4445, 512, 1254, 295, 42481, 13508, 13, 286, 500, 380, 519, 321, 51172], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 280, "seek": 170208, "start": 1718.24, "end": 1723.6799999999998, "text": " should. I mean, I think, I think we should leave that in the tests stuff because people can set up", "tokens": [51172, 820, 13, 286, 914, 11, 286, 519, 11, 286, 519, 321, 820, 1856, 300, 294, 264, 6921, 1507, 570, 561, 393, 992, 493, 51444], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 281, "seek": 170208, "start": 1723.6799999999998, "end": 1727.9199999999998, "text": " their own test cases and then, and then call it that way. I, I, I don't know. I thought about it", "tokens": [51444, 641, 1065, 1500, 3331, 293, 550, 11, 293, 550, 818, 309, 300, 636, 13, 286, 11, 286, 11, 286, 500, 380, 458, 13, 286, 1194, 466, 309, 51656], "temperature": 0.0, "avg_logprob": -0.11911384531315541, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.006289447657763958}, {"id": 282, "seek": 172792, "start": 1727.92, "end": 1734.16, "text": " for a second though. This is just as good, right? Having the trace appear. Because this is, is, is", "tokens": [50364, 337, 257, 1150, 1673, 13, 639, 307, 445, 382, 665, 11, 558, 30, 10222, 264, 13508, 4204, 13, 1436, 341, 307, 11, 307, 11, 307, 50676], "temperature": 0.0, "avg_logprob": -0.13727802276611328, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.013221939094364643}, {"id": 283, "seek": 172792, "start": 1734.16, "end": 1741.1200000000001, "text": " using a specific scanner that fulfills the, the interface and therefore it can have extra things", "tokens": [50676, 1228, 257, 2685, 30211, 300, 8081, 2565, 264, 11, 264, 9226, 293, 4412, 309, 393, 362, 2857, 721, 51024], "temperature": 0.0, "avg_logprob": -0.13727802276611328, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.013221939094364643}, {"id": 284, "seek": 172792, "start": 1741.1200000000001, "end": 1744.5600000000002, "text": " in it like trace. The other one doesn't have anything, any knowledge of it at all. And it", "tokens": [51024, 294, 309, 411, 13508, 13, 440, 661, 472, 1177, 380, 362, 1340, 11, 604, 3601, 295, 309, 412, 439, 13, 400, 309, 51196], "temperature": 0.0, "avg_logprob": -0.13727802276611328, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.013221939094364643}, {"id": 285, "seek": 172792, "start": 1744.5600000000002, "end": 1749.1200000000001, "text": " shouldn't, right? We don't, that's again, I want to, I want to double check that everybody understands", "tokens": [51196, 4659, 380, 11, 558, 30, 492, 500, 380, 11, 300, 311, 797, 11, 286, 528, 281, 11, 286, 528, 281, 3834, 1520, 300, 2201, 15146, 51424], "temperature": 0.0, "avg_logprob": -0.13727802276611328, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.013221939094364643}, {"id": 286, "seek": 174912, "start": 1749.1999999999998, "end": 1755.6799999999998, "text": " this. So we do not want people writing, you know, Pagan or any", "tokens": [50368, 341, 13, 407, 321, 360, 406, 528, 561, 3579, 11, 291, 458, 11, 430, 14167, 420, 604, 50692], "temperature": 0.0, "avg_logprob": -0.10821412557578948, "compression_ratio": 1.585, "no_speech_prob": 0.355692595243454}, {"id": 287, "seek": 174912, "start": 1758.8799999999999, "end": 1765.04, "text": " scanners functions that are going to be doing fancy things that are not defined by the interface.", "tokens": [50852, 795, 25792, 6828, 300, 366, 516, 281, 312, 884, 10247, 721, 300, 366, 406, 7642, 538, 264, 9226, 13, 51160], "temperature": 0.0, "avg_logprob": -0.10821412557578948, "compression_ratio": 1.585, "no_speech_prob": 0.355692595243454}, {"id": 288, "seek": 174912, "start": 1765.6, "end": 1770.56, "text": " Because if you do, then they won't work with interchangeably with other scanners.", "tokens": [51188, 1436, 498, 291, 360, 11, 550, 436, 1582, 380, 589, 365, 30358, 1188, 365, 661, 795, 25792, 13, 51436], "temperature": 0.0, "avg_logprob": -0.10821412557578948, "compression_ratio": 1.585, "no_speech_prob": 0.355692595243454}, {"id": 289, "seek": 174912, "start": 1771.6799999999998, "end": 1775.84, "text": " And that, that's not ideal, right? We want to be able to have people write", "tokens": [51492, 400, 300, 11, 300, 311, 406, 7157, 11, 558, 30, 492, 528, 281, 312, 1075, 281, 362, 561, 2464, 51700], "temperature": 0.0, "avg_logprob": -0.10821412557578948, "compression_ratio": 1.585, "no_speech_prob": 0.355692595243454}, {"id": 290, "seek": 177584, "start": 1775.84, "end": 1780.0, "text": " very highly optimized scanners however they want. I mean, all of them obviously are going to have the,", "tokens": [50364, 588, 5405, 26941, 795, 25792, 4461, 436, 528, 13, 286, 914, 11, 439, 295, 552, 2745, 366, 516, 281, 362, 264, 11, 50572], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 291, "seek": 177584, "start": 1780.0, "end": 1783.52, "text": " the downside of having to call out to a function to do their thing. But that's,", "tokens": [50572, 264, 25060, 295, 1419, 281, 818, 484, 281, 257, 2445, 281, 360, 641, 551, 13, 583, 300, 311, 11, 50748], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 292, "seek": 177584, "start": 1783.52, "end": 1787.1999999999998, "text": " it's not too bad. But that way people can supplement the scanner that I've made or make", "tokens": [50748, 309, 311, 406, 886, 1578, 13, 583, 300, 636, 561, 393, 15436, 264, 30211, 300, 286, 600, 1027, 420, 652, 50932], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 293, "seek": 177584, "start": 1787.1999999999998, "end": 1791.6799999999998, "text": " their own or something like that. And they can, they can share all of these scan functions with", "tokens": [50932, 641, 1065, 420, 746, 411, 300, 13, 400, 436, 393, 11, 436, 393, 2073, 439, 295, 613, 11049, 6828, 365, 51156], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 294, "seek": 177584, "start": 1791.6799999999998, "end": 1796.3999999999999, "text": " each other. And we can make libraries of scan functions that do different amazing things. So", "tokens": [51156, 1184, 661, 13, 400, 321, 393, 652, 15148, 295, 11049, 6828, 300, 360, 819, 2243, 721, 13, 407, 51392], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 295, "seek": 177584, "start": 1796.3999999999999, "end": 1800.48, "text": " it's basically like creating a library of regular expressions. And if you look at", "tokens": [51392, 309, 311, 1936, 411, 4084, 257, 6405, 295, 3890, 15277, 13, 400, 498, 291, 574, 412, 51596], "temperature": 0.0, "avg_logprob": -0.09635696115419846, "compression_ratio": 1.8277027027027026, "no_speech_prob": 0.010651488788425922}, {"id": 296, "seek": 180048, "start": 1801.04, "end": 1808.4, "text": " the Pagan stuff that I've been doing, you can see that we've got a lot of functions to write.", "tokens": [50392, 264, 430, 14167, 1507, 300, 286, 600, 668, 884, 11, 291, 393, 536, 300, 321, 600, 658, 257, 688, 295, 6828, 281, 2464, 13, 50760], "temperature": 0.0, "avg_logprob": -0.09173738039456882, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.0031725792214274406}, {"id": 297, "seek": 180048, "start": 1808.4, "end": 1814.16, "text": " So over the next year or two, I'll be implementing individual scan functions", "tokens": [50760, 407, 670, 264, 958, 1064, 420, 732, 11, 286, 603, 312, 18114, 2609, 11049, 6828, 51048], "temperature": 0.0, "avg_logprob": -0.09173738039456882, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.0031725792214274406}, {"id": 298, "seek": 180048, "start": 1814.72, "end": 1822.4, "text": " for the different types of stuff that is included here and in our tokens. And yes, we're going to", "tokens": [51076, 337, 264, 819, 3467, 295, 1507, 300, 307, 5556, 510, 293, 294, 527, 22667, 13, 400, 2086, 11, 321, 434, 516, 281, 51460], "temperature": 0.0, "avg_logprob": -0.09173738039456882, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.0031725792214274406}, {"id": 299, "seek": 180048, "start": 1822.4, "end": 1828.64, "text": " have, we're going to have functions for things that are strictly static. And the reason is that", "tokens": [51460, 362, 11, 321, 434, 516, 281, 362, 6828, 337, 721, 300, 366, 20792, 13437, 13, 400, 264, 1778, 307, 300, 51772], "temperature": 0.0, "avg_logprob": -0.09173738039456882, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.0031725792214274406}, {"id": 300, "seek": 182864, "start": 1828.64, "end": 1833.2, "text": " is to keep everything functional because we need to be able to pass the scanner to it, right?", "tokens": [50364, 307, 281, 1066, 1203, 11745, 570, 321, 643, 281, 312, 1075, 281, 1320, 264, 30211, 281, 309, 11, 558, 30, 50592], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 301, "seek": 182864, "start": 1834.96, "end": 1838.64, "text": " We don't, if we didn't do that, we would have different kinds of dependencies. We would have", "tokens": [50680, 492, 500, 380, 11, 498, 321, 994, 380, 360, 300, 11, 321, 576, 362, 819, 3685, 295, 36606, 13, 492, 576, 362, 50864], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 302, "seek": 182864, "start": 1838.64, "end": 1845.6000000000001, "text": " dependencies on the Pagan like implementation to some degree, I think. And so that, I mean,", "tokens": [50864, 36606, 322, 264, 430, 14167, 411, 11420, 281, 512, 4314, 11, 286, 519, 13, 400, 370, 300, 11, 286, 914, 11, 51212], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 303, "seek": 182864, "start": 1845.6000000000001, "end": 1850.64, "text": " it's not that much extra. Before I was like calling out to a function just to parse the", "tokens": [51212, 309, 311, 406, 300, 709, 2857, 13, 4546, 286, 390, 411, 5141, 484, 281, 257, 2445, 445, 281, 48377, 264, 51464], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 304, "seek": 182864, "start": 1850.64, "end": 1854.24, "text": " references to the other functions. So there is, it's not going to be any less performant than", "tokens": [51464, 15400, 281, 264, 661, 6828, 13, 407, 456, 307, 11, 309, 311, 406, 516, 281, 312, 604, 1570, 2042, 394, 813, 51644], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 305, "seek": 182864, "start": 1854.24, "end": 1857.92, "text": " any of the other stuff. And that's really premature optimization. If somebody really,", "tokens": [51644, 604, 295, 264, 661, 1507, 13, 400, 300, 311, 534, 34877, 19618, 13, 759, 2618, 534, 11, 51828], "temperature": 0.0, "avg_logprob": -0.08466312973587602, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.009707448072731495}, {"id": 306, "seek": 185792, "start": 1857.92, "end": 1863.1200000000001, "text": " really, really wants that level of performance, they probably should write their own scanner and,", "tokens": [50364, 534, 11, 534, 2738, 300, 1496, 295, 3389, 11, 436, 1391, 820, 2464, 641, 1065, 30211, 293, 11, 50624], "temperature": 0.0, "avg_logprob": -0.1589220903051181, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0013249438488855958}, {"id": 307, "seek": 185792, "start": 1863.1200000000001, "end": 1868.16, "text": " and, you know, maybe just use some of the scan functions without, without it and not, and not", "tokens": [50624, 293, 11, 291, 458, 11, 1310, 445, 764, 512, 295, 264, 11049, 6828, 1553, 11, 1553, 309, 293, 406, 11, 293, 406, 50876], "temperature": 0.0, "avg_logprob": -0.1589220903051181, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0013249438488855958}, {"id": 308, "seek": 185792, "start": 1868.16, "end": 1874.88, "text": " bibbed. So, but I will be writing like, I'll probably be auto generating a bunch of go code to,", "tokens": [50876, 24557, 2883, 13, 407, 11, 457, 286, 486, 312, 3579, 411, 11, 286, 603, 1391, 312, 8399, 17746, 257, 3840, 295, 352, 3089, 281, 11, 51212], "temperature": 0.0, "avg_logprob": -0.1589220903051181, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0013249438488855958}, {"id": 309, "seek": 185792, "start": 1875.6000000000001, "end": 1881.3600000000001, "text": " to, you know, to, to, to, to stand for each one of these, these scan functions. And then they'll", "tokens": [51248, 281, 11, 291, 458, 11, 281, 11, 281, 11, 281, 11, 281, 1463, 337, 1184, 472, 295, 613, 11, 613, 11049, 6828, 13, 400, 550, 436, 603, 51536], "temperature": 0.0, "avg_logprob": -0.1589220903051181, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0013249438488855958}, {"id": 310, "seek": 185792, "start": 1881.3600000000001, "end": 1886.0800000000002, "text": " all be under scan dot whatever. So I'll be able to just on any project, just be able to import", "tokens": [51536, 439, 312, 833, 11049, 5893, 2035, 13, 407, 286, 603, 312, 1075, 281, 445, 322, 604, 1716, 11, 445, 312, 1075, 281, 974, 51772], "temperature": 0.0, "avg_logprob": -0.1589220903051181, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0013249438488855958}, {"id": 311, "seek": 188608, "start": 1886.08, "end": 1892.48, "text": " artifacts, Rob slash Pagan slash scan, and I can get any and all of these that I want.", "tokens": [50364, 24617, 11, 5424, 17330, 430, 14167, 17330, 11049, 11, 293, 286, 393, 483, 604, 293, 439, 295, 613, 300, 286, 528, 13, 50684], "temperature": 0.0, "avg_logprob": -0.14890538729154146, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.009124775417149067}, {"id": 312, "seek": 188608, "start": 1894.08, "end": 1899.12, "text": " And it's not that big, actually, because it's just text parsing, right? It, it seems big because", "tokens": [50764, 400, 309, 311, 406, 300, 955, 11, 767, 11, 570, 309, 311, 445, 2487, 21156, 278, 11, 558, 30, 467, 11, 309, 2544, 955, 570, 51016], "temperature": 0.0, "avg_logprob": -0.14890538729154146, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.009124775417149067}, {"id": 313, "seek": 188608, "start": 1899.12, "end": 1902.8, "text": " it's a lot of code for us to write, but it, but it's most of it's going to get inlined and the", "tokens": [51016, 309, 311, 257, 688, 295, 3089, 337, 505, 281, 2464, 11, 457, 309, 11, 457, 309, 311, 881, 295, 309, 311, 516, 281, 483, 294, 13564, 293, 264, 51200], "temperature": 0.0, "avg_logprob": -0.14890538729154146, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.009124775417149067}, {"id": 314, "seek": 188608, "start": 1902.8, "end": 1907.12, "text": " size of the package isn't going to be too big. And, and then we can, we get kind of like this", "tokens": [51200, 2744, 295, 264, 7372, 1943, 380, 516, 281, 312, 886, 955, 13, 400, 11, 293, 550, 321, 393, 11, 321, 483, 733, 295, 411, 341, 51416], "temperature": 0.0, "avg_logprob": -0.14890538729154146, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.009124775417149067}, {"id": 315, "seek": 188608, "start": 1907.12, "end": 1912.8, "text": " regular expression engine that's on steroids, because now we can just write our own recursive", "tokens": [51416, 3890, 6114, 2848, 300, 311, 322, 45717, 11, 570, 586, 321, 393, 445, 2464, 527, 1065, 20560, 488, 51700], "temperature": 0.0, "avg_logprob": -0.14890538729154146, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.009124775417149067}, {"id": 316, "seek": 191280, "start": 1912.8, "end": 1917.68, "text": " descent parsers as easily or if not easier than we could write regex, you know, complex", "tokens": [50364, 23475, 21156, 433, 382, 3612, 420, 498, 406, 3571, 813, 321, 727, 2464, 319, 432, 87, 11, 291, 458, 11, 3997, 50608], "temperature": 0.0, "avg_logprob": -0.11396848794185754, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.0017545648152008653}, {"id": 317, "seek": 191280, "start": 1917.68, "end": 1921.68, "text": " regex expressions. And that, that to me is kind of the Holy Grail, because that's what I want to do.", "tokens": [50608, 319, 432, 87, 15277, 13, 400, 300, 11, 300, 281, 385, 307, 733, 295, 264, 6295, 8985, 388, 11, 570, 300, 311, 437, 286, 528, 281, 360, 13, 50808], "temperature": 0.0, "avg_logprob": -0.11396848794185754, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.0017545648152008653}, {"id": 318, "seek": 191280, "start": 1921.68, "end": 1925.52, "text": " I, I have like four or five grammars that I want to finish that I'm kind of waiting on.", "tokens": [50808, 286, 11, 286, 362, 411, 1451, 420, 1732, 17570, 685, 300, 286, 528, 281, 2413, 300, 286, 478, 733, 295, 3806, 322, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11396848794185754, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.0017545648152008653}, {"id": 319, "seek": 191280, "start": 1925.52, "end": 1932.56, "text": " And this is, that's, that's where, that's where it leaves us. All right. So I need to come back", "tokens": [51000, 400, 341, 307, 11, 300, 311, 11, 300, 311, 689, 11, 300, 311, 689, 309, 5510, 505, 13, 1057, 558, 13, 407, 286, 643, 281, 808, 646, 51352], "temperature": 0.0, "avg_logprob": -0.11396848794185754, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.0017545648152008653}, {"id": 320, "seek": 191280, "start": 1932.56, "end": 1936.1599999999999, "text": " and fix this white space one. Let's go back and look at one that maybe works better. So", "tokens": [51352, 293, 3191, 341, 2418, 1901, 472, 13, 961, 311, 352, 646, 293, 574, 412, 472, 300, 1310, 1985, 1101, 13, 407, 51532], "temperature": 0.0, "avg_logprob": -0.11396848794185754, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.0017545648152008653}, {"id": 321, "seek": 193616, "start": 1936.88, "end": 1942.48, "text": " here we have, and I put the pagan line up here. So an end of the line is, you know,", "tokens": [50400, 510, 321, 362, 11, 293, 286, 829, 264, 38238, 1622, 493, 510, 13, 407, 364, 917, 295, 264, 1622, 307, 11, 291, 458, 11, 50680], "temperature": 0.0, "avg_logprob": -0.1336582616432426, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.004609479568898678}, {"id": 322, "seek": 193616, "start": 1942.48, "end": 1949.28, "text": " we scan the found Boolean stuff. We don't really need that. I could have just done a return right", "tokens": [50680, 321, 11049, 264, 1352, 23351, 28499, 1507, 13, 492, 500, 380, 534, 643, 300, 13, 286, 727, 362, 445, 1096, 257, 2736, 558, 51020], "temperature": 0.0, "avg_logprob": -0.1336582616432426, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.004609479568898678}, {"id": 323, "seek": 193616, "start": 1949.28, "end": 1958.88, "text": " here and call it a day and not gotten all the way down here. And the reason I didn't do that", "tokens": [51020, 510, 293, 818, 309, 257, 786, 293, 406, 5768, 439, 264, 636, 760, 510, 13, 400, 264, 1778, 286, 994, 380, 360, 300, 51500], "temperature": 0.0, "avg_logprob": -0.1336582616432426, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.004609479568898678}, {"id": 324, "seek": 193616, "start": 1958.88, "end": 1965.8400000000001, "text": " initially is because I wanted to think about how this code could be auto generated. But", "tokens": [51500, 9105, 307, 570, 286, 1415, 281, 519, 466, 577, 341, 3089, 727, 312, 8399, 10833, 13, 583, 51848], "temperature": 0.0, "avg_logprob": -0.1336582616432426, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.004609479568898678}, {"id": 325, "seek": 196584, "start": 1965.9199999999998, "end": 1973.84, "text": " now that I'm looking at it, I am totally okay doing that. So, so we can just do a return true there.", "tokens": [50368, 586, 300, 286, 478, 1237, 412, 309, 11, 286, 669, 3879, 1392, 884, 300, 13, 407, 11, 370, 321, 393, 445, 360, 257, 2736, 2074, 456, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09281085301371454, "compression_ratio": 1.7095238095238094, "no_speech_prob": 0.00045829478767700493}, {"id": 326, "seek": 196584, "start": 1975.52, "end": 1981.6799999999998, "text": " Here we can just do a return true. Yeah. And if we make it down this far,", "tokens": [50848, 1692, 321, 393, 445, 360, 257, 2736, 2074, 13, 865, 13, 400, 498, 321, 652, 309, 760, 341, 1400, 11, 51156], "temperature": 0.0, "avg_logprob": -0.09281085301371454, "compression_ratio": 1.7095238095238094, "no_speech_prob": 0.00045829478767700493}, {"id": 327, "seek": 196584, "start": 1982.56, "end": 1987.6799999999998, "text": " that means we didn't find it. And we need to do that. So that this is, this is not hungry.", "tokens": [51200, 300, 1355, 321, 994, 380, 915, 309, 13, 400, 321, 643, 281, 360, 300, 13, 407, 300, 341, 307, 11, 341, 307, 406, 8067, 13, 51456], "temperature": 0.0, "avg_logprob": -0.09281085301371454, "compression_ratio": 1.7095238095238094, "no_speech_prob": 0.00045829478767700493}, {"id": 328, "seek": 196584, "start": 1988.32, "end": 1992.9599999999998, "text": " If you're using something that's hungry. Yeah, you might, you might have a different problem,", "tokens": [51488, 759, 291, 434, 1228, 746, 300, 311, 8067, 13, 865, 11, 291, 1062, 11, 291, 1062, 362, 257, 819, 1154, 11, 51720], "temperature": 0.0, "avg_logprob": -0.09281085301371454, "compression_ratio": 1.7095238095238094, "no_speech_prob": 0.00045829478767700493}, {"id": 329, "seek": 199296, "start": 1992.96, "end": 2002.08, "text": " right? Because, you know, you need to, yeah, you need to, if you're having something that's like", "tokens": [50364, 558, 30, 1436, 11, 291, 458, 11, 291, 643, 281, 11, 1338, 11, 291, 643, 281, 11, 498, 291, 434, 1419, 746, 300, 311, 411, 50820], "temperature": 0.0, "avg_logprob": -0.12494286128452846, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.002980888821184635}, {"id": 330, "seek": 199296, "start": 2002.08, "end": 2006.72, "text": " hungry and greedy, you need to like count all the fines and you'll see that, you'll see that kind", "tokens": [50820, 8067, 293, 28228, 11, 291, 643, 281, 411, 1207, 439, 264, 37989, 293, 291, 603, 536, 300, 11, 291, 603, 536, 300, 733, 51052], "temperature": 0.0, "avg_logprob": -0.12494286128452846, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.002980888821184635}, {"id": 331, "seek": 199296, "start": 2006.72, "end": 2017.3600000000001, "text": " of thing happening over time. Oopsie, did I refer to found in here? Return false. So I mean,", "tokens": [51052, 295, 551, 2737, 670, 565, 13, 21726, 414, 11, 630, 286, 2864, 281, 1352, 294, 510, 30, 24350, 7908, 13, 407, 286, 914, 11, 51584], "temperature": 0.0, "avg_logprob": -0.12494286128452846, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.002980888821184635}, {"id": 332, "seek": 199296, "start": 2017.3600000000001, "end": 2021.76, "text": " that's a simplification we can do. Again, these are, I want these to be highly optimized. Another", "tokens": [51584, 300, 311, 257, 6883, 3774, 321, 393, 360, 13, 3764, 11, 613, 366, 11, 286, 528, 613, 281, 312, 5405, 26941, 13, 3996, 51804], "temperature": 0.0, "avg_logprob": -0.12494286128452846, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.002980888821184635}, {"id": 333, "seek": 202176, "start": 2021.76, "end": 2027.84, "text": " reason, by the way, that I think code generation is probably the wrong way to go. And the more I", "tokens": [50364, 1778, 11, 538, 264, 636, 11, 300, 286, 519, 3089, 5125, 307, 1391, 264, 2085, 636, 281, 352, 13, 400, 264, 544, 286, 50668], "temperature": 0.0, "avg_logprob": -0.11513812416478207, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.008576663210988045}, {"id": 334, "seek": 202176, "start": 2027.84, "end": 2033.52, "text": " keep coming back to this, the more I think that hand crafting a recursive descent parser from a huge", "tokens": [50668, 1066, 1348, 646, 281, 341, 11, 264, 544, 286, 519, 300, 1011, 29048, 257, 20560, 488, 23475, 21156, 260, 490, 257, 2603, 50952], "temperature": 0.0, "avg_logprob": -0.11513812416478207, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.008576663210988045}, {"id": 335, "seek": 202176, "start": 2033.52, "end": 2039.92, "text": " library of existing scanners, scan scan functions is a better idea. Because of this problem that you", "tokens": [50952, 6405, 295, 6741, 795, 25792, 11, 11049, 11049, 6828, 307, 257, 1101, 1558, 13, 1436, 295, 341, 1154, 300, 291, 51272], "temperature": 0.0, "avg_logprob": -0.11513812416478207, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.008576663210988045}, {"id": 336, "seek": 202176, "start": 2039.92, "end": 2047.12, "text": " just saw, the optimization I just made is the kind of thing that would take an extreme amount of", "tokens": [51272, 445, 1866, 11, 264, 19618, 286, 445, 1027, 307, 264, 733, 295, 551, 300, 576, 747, 364, 8084, 2372, 295, 51632], "temperature": 0.0, "avg_logprob": -0.11513812416478207, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.008576663210988045}, {"id": 337, "seek": 204712, "start": 2047.6799999999998, "end": 2052.4, "text": " intelligence in the code to be able to write it in a code generator. Whereas if I'm just writing", "tokens": [50392, 7599, 294, 264, 3089, 281, 312, 1075, 281, 2464, 309, 294, 257, 3089, 19265, 13, 13813, 498, 286, 478, 445, 3579, 50628], "temperature": 0.0, "avg_logprob": -0.09064420379034363, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.00857690628618002}, {"id": 338, "seek": 204712, "start": 2052.4, "end": 2058.0, "text": " the parser, I can take, I can do tricks and stuff inside of my functional parser to make it really,", "tokens": [50628, 264, 21156, 260, 11, 286, 393, 747, 11, 286, 393, 360, 11733, 293, 1507, 1854, 295, 452, 11745, 21156, 260, 281, 652, 309, 534, 11, 50908], "temperature": 0.0, "avg_logprob": -0.09064420379034363, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.00857690628618002}, {"id": 339, "seek": 204712, "start": 2058.0, "end": 2064.72, "text": " really optimized for this particular scenario, you know, and, and I can do things that couldn't be", "tokens": [50908, 534, 26941, 337, 341, 1729, 9005, 11, 291, 458, 11, 293, 11, 293, 286, 393, 360, 721, 300, 2809, 380, 312, 51244], "temperature": 0.0, "avg_logprob": -0.09064420379034363, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.00857690628618002}, {"id": 340, "seek": 204712, "start": 2064.72, "end": 2070.48, "text": " done if I were to just to generalize the generation of this code from the syntax. So what I'm saying,", "tokens": [51244, 1096, 498, 286, 645, 281, 445, 281, 2674, 1125, 264, 5125, 295, 341, 3089, 490, 264, 28431, 13, 407, 437, 286, 478, 1566, 11, 51532], "temperature": 0.0, "avg_logprob": -0.09064420379034363, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.00857690628618002}, {"id": 341, "seek": 207048, "start": 2071.12, "end": 2078.0, "text": " and I'm going to put this in here is that I am, I'm kind of souring on the idea of code generation.", "tokens": [50396, 293, 286, 478, 516, 281, 829, 341, 294, 510, 307, 300, 286, 669, 11, 286, 478, 733, 295, 11006, 278, 322, 264, 1558, 295, 3089, 5125, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1529296636581421, "compression_ratio": 1.504, "no_speech_prob": 0.09804686158895493}, {"id": 342, "seek": 207048, "start": 2079.92, "end": 2093.28, "text": " So I'm souring on the idea of Pagan to code generation, because it's removing, you know,", "tokens": [50836, 407, 286, 478, 11006, 278, 322, 264, 1558, 295, 430, 14167, 281, 3089, 5125, 11, 570, 309, 311, 12720, 11, 291, 458, 11, 51504], "temperature": 0.0, "avg_logprob": -0.1529296636581421, "compression_ratio": 1.504, "no_speech_prob": 0.09804686158895493}, {"id": 343, "seek": 209328, "start": 2093.84, "end": 2104.0800000000004, "text": " it, it, it prevents, it precludes optimizations that only, that only a person could do.", "tokens": [50392, 309, 11, 309, 11, 309, 22367, 11, 309, 4346, 1471, 279, 5028, 14455, 300, 787, 11, 300, 787, 257, 954, 727, 360, 13, 50904], "temperature": 0.0, "avg_logprob": -0.08198195457458496, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.006097178906202316}, {"id": 344, "seek": 209328, "start": 2105.2000000000003, "end": 2109.6000000000004, "text": " And, you know, people definitely do this. And if you're going to, I mean, at the end of the day,", "tokens": [50960, 400, 11, 291, 458, 11, 561, 2138, 360, 341, 13, 400, 498, 291, 434, 516, 281, 11, 286, 914, 11, 412, 264, 917, 295, 264, 786, 11, 51180], "temperature": 0.0, "avg_logprob": -0.08198195457458496, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.006097178906202316}, {"id": 345, "seek": 209328, "start": 2109.6000000000004, "end": 2115.2000000000003, "text": " we're writing a compiler when we do that kind of thing. And, you know, there are people that have", "tokens": [51180, 321, 434, 3579, 257, 31958, 562, 321, 360, 300, 733, 295, 551, 13, 400, 11, 291, 458, 11, 456, 366, 561, 300, 362, 51460], "temperature": 0.0, "avg_logprob": -0.08198195457458496, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.006097178906202316}, {"id": 346, "seek": 209328, "start": 2115.2000000000003, "end": 2120.5600000000004, "text": " spent their entire lives dedicated to compiler optimizations. Well, one of the reasons that", "tokens": [51460, 4418, 641, 2302, 2909, 8374, 281, 31958, 5028, 14455, 13, 1042, 11, 472, 295, 264, 4112, 300, 51728], "temperature": 0.0, "avg_logprob": -0.08198195457458496, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.006097178906202316}, {"id": 347, "seek": 212056, "start": 2120.56, "end": 2125.84, "text": " having a human write a scan function is better is because depending on the language they're writing", "tokens": [50364, 1419, 257, 1952, 2464, 257, 11049, 2445, 307, 1101, 307, 570, 5413, 322, 264, 2856, 436, 434, 3579, 50628], "temperature": 0.0, "avg_logprob": -0.0693759507146375, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.006096961442381144}, {"id": 348, "seek": 212056, "start": 2125.84, "end": 2134.24, "text": " it for, they might already know how the compiler is going to inline that code. So, so, you know,", "tokens": [50628, 309, 337, 11, 436, 1062, 1217, 458, 577, 264, 31958, 307, 516, 281, 294, 1889, 300, 3089, 13, 407, 11, 370, 11, 291, 458, 11, 51048], "temperature": 0.0, "avg_logprob": -0.0693759507146375, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.006096961442381144}, {"id": 349, "seek": 212056, "start": 2134.24, "end": 2139.2, "text": " having some generic size rendering of the code may not be able to take advantage of those things.", "tokens": [51048, 1419, 512, 19577, 2744, 22407, 295, 264, 3089, 815, 406, 312, 1075, 281, 747, 5002, 295, 729, 721, 13, 51296], "temperature": 0.0, "avg_logprob": -0.0693759507146375, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.006096961442381144}, {"id": 350, "seek": 212056, "start": 2139.2, "end": 2144.32, "text": " And, you know, premature optimization, yes, right, we want to avoid premature optimization, but,", "tokens": [51296, 400, 11, 291, 458, 11, 34877, 19618, 11, 2086, 11, 558, 11, 321, 528, 281, 5042, 34877, 19618, 11, 457, 11, 51552], "temperature": 0.0, "avg_logprob": -0.0693759507146375, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.006096961442381144}, {"id": 351, "seek": 212056, "start": 2144.32, "end": 2149.92, "text": " but at the same time, we don't want to be forced into doing things that, that we could do", "tokens": [51552, 457, 412, 264, 912, 565, 11, 321, 500, 380, 528, 281, 312, 7579, 666, 884, 721, 300, 11, 300, 321, 727, 360, 51832], "temperature": 0.0, "avg_logprob": -0.0693759507146375, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.006096961442381144}, {"id": 352, "seek": 215056, "start": 2150.96, "end": 2155.12, "text": " because we know about them later on. We could come back to the code", "tokens": [50384, 570, 321, 458, 466, 552, 1780, 322, 13, 492, 727, 808, 646, 281, 264, 3089, 50592], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 353, "seek": 215056, "start": 2155.12, "end": 2158.88, "text": " and we could actually say, well, okay, let's optimize this one, because this is that my", "tokens": [50592, 293, 321, 727, 767, 584, 11, 731, 11, 1392, 11, 718, 311, 19719, 341, 472, 11, 570, 341, 307, 300, 452, 50780], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 354, "seek": 215056, "start": 2158.88, "end": 2164.24, "text": " pagan function for parsing, you know, wide space, the most important thing that I'm ever going to", "tokens": [50780, 38238, 2445, 337, 21156, 278, 11, 291, 458, 11, 4874, 1901, 11, 264, 881, 1021, 551, 300, 286, 478, 1562, 516, 281, 51048], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 355, "seek": 215056, "start": 2164.24, "end": 2168.08, "text": " write, it's going to be used by millions of people or whatever. And, and I should really,", "tokens": [51048, 2464, 11, 309, 311, 516, 281, 312, 1143, 538, 6803, 295, 561, 420, 2035, 13, 400, 11, 293, 286, 820, 534, 11, 51240], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 356, "seek": 215056, "start": 2168.08, "end": 2173.12, "text": " really optimize that one function. And then everybody can spend their time optimizing the", "tokens": [51240, 534, 19719, 300, 472, 2445, 13, 400, 550, 2201, 393, 3496, 641, 565, 40425, 264, 51492], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 357, "seek": 215056, "start": 2173.12, "end": 2179.52, "text": " functions that we have for parsing those specific things. And we can maintain a community library", "tokens": [51492, 6828, 300, 321, 362, 337, 21156, 278, 729, 2685, 721, 13, 400, 321, 393, 6909, 257, 1768, 6405, 51812], "temperature": 0.0, "avg_logprob": -0.11057306274654359, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0007096485351212323}, {"id": 358, "seek": 217952, "start": 2179.52, "end": 2183.6, "text": " of this, rather than having everybody write the best, you know, their own wide space parser,", "tokens": [50364, 295, 341, 11, 2831, 813, 1419, 2201, 2464, 264, 1151, 11, 291, 458, 11, 641, 1065, 4874, 1901, 21156, 260, 11, 50568], "temperature": 0.0, "avg_logprob": -0.1145940245243541, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.001455008750781417}, {"id": 359, "seek": 217952, "start": 2184.56, "end": 2189.36, "text": " right? So we can actually have a collective community of contributions that from people", "tokens": [50616, 558, 30, 407, 321, 393, 767, 362, 257, 12590, 1768, 295, 15725, 300, 490, 561, 50856], "temperature": 0.0, "avg_logprob": -0.1145940245243541, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.001455008750781417}, {"id": 360, "seek": 217952, "start": 2189.36, "end": 2194.64, "text": " who know about parsing, or really, you know, amazing Go specialists who have, have, you know,", "tokens": [50856, 567, 458, 466, 21156, 278, 11, 420, 534, 11, 291, 458, 11, 2243, 1037, 25476, 567, 362, 11, 362, 11, 291, 458, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1145940245243541, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.001455008750781417}, {"id": 361, "seek": 217952, "start": 2194.64, "end": 2199.6, "text": " know how to optimize code based on what they're, what they know about inlining. So, so yeah,", "tokens": [51120, 458, 577, 281, 19719, 3089, 2361, 322, 437, 436, 434, 11, 437, 436, 458, 466, 294, 31079, 13, 407, 11, 370, 1338, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1145940245243541, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.001455008750781417}, {"id": 362, "seek": 217952, "start": 2199.6, "end": 2206.56, "text": " no more code generation, just a lot of pre-generated libraries that are immediately importable.", "tokens": [51368, 572, 544, 3089, 5125, 11, 445, 257, 688, 295, 659, 12, 21848, 770, 15148, 300, 366, 4258, 974, 712, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1145940245243541, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.001455008750781417}, {"id": 363, "seek": 220656, "start": 2206.56, "end": 2211.2799999999997, "text": " And then we can just write, you know, in if statements and switch statements, and you can", "tokens": [50364, 400, 550, 321, 393, 445, 2464, 11, 291, 458, 11, 294, 498, 12363, 293, 3679, 12363, 11, 293, 291, 393, 50600], "temperature": 0.0, "avg_logprob": -0.13435102911556468, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.00128426484297961}, {"id": 364, "seek": 220656, "start": 2211.2799999999997, "end": 2215.36, "text": " write your own thing really quickly. And I think that's really going to be the new normal", "tokens": [50600, 2464, 428, 1065, 551, 534, 2661, 13, 400, 286, 519, 300, 311, 534, 516, 281, 312, 264, 777, 2710, 50804], "temperature": 0.0, "avg_logprob": -0.13435102911556468, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.00128426484297961}, {"id": 365, "seek": 220656, "start": 2217.12, "end": 2225.92, "text": " useful form overlooks. Yeah. And so, so, so yeah, I think, I think, I think that that's,", "tokens": [50892, 4420, 1254, 37826, 82, 13, 865, 13, 400, 370, 11, 370, 11, 370, 1338, 11, 286, 519, 11, 286, 519, 11, 286, 519, 300, 300, 311, 11, 51332], "temperature": 0.0, "avg_logprob": -0.13435102911556468, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.00128426484297961}, {"id": 366, "seek": 220656, "start": 2225.92, "end": 2234.32, "text": " that's kind of how I am with this. That is why you're developing anything. Yeah. I, I, I think", "tokens": [51332, 300, 311, 733, 295, 577, 286, 669, 365, 341, 13, 663, 307, 983, 291, 434, 6416, 1340, 13, 865, 13, 286, 11, 286, 11, 286, 519, 51752], "temperature": 0.0, "avg_logprob": -0.13435102911556468, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.00128426484297961}, {"id": 367, "seek": 223432, "start": 2234.4, "end": 2238.6400000000003, "text": " that the code generation thing, I mean, this doesn't mean we're not going to do some code", "tokens": [50368, 300, 264, 3089, 5125, 551, 11, 286, 914, 11, 341, 1177, 380, 914, 321, 434, 406, 516, 281, 360, 512, 3089, 50580], "temperature": 0.0, "avg_logprob": -0.09131637289504374, "compression_ratio": 1.8, "no_speech_prob": 0.011685884557664394}, {"id": 368, "seek": 223432, "start": 2238.6400000000003, "end": 2244.88, "text": " generation, right? But we're going to statefully code generate like all the functions for the,", "tokens": [50580, 5125, 11, 558, 30, 583, 321, 434, 516, 281, 1785, 2277, 3089, 8460, 411, 439, 264, 6828, 337, 264, 11, 50892], "temperature": 0.0, "avg_logprob": -0.09131637289504374, "compression_ratio": 1.8, "no_speech_prob": 0.011685884557664394}, {"id": 369, "seek": 223432, "start": 2244.88, "end": 2252.1600000000003, "text": " the 200 or so Unicode classes, which by the way, already have functions. Yeah. So for those kind", "tokens": [50892, 264, 2331, 420, 370, 1156, 299, 1429, 5359, 11, 597, 538, 264, 636, 11, 1217, 362, 6828, 13, 865, 13, 407, 337, 729, 733, 51256], "temperature": 0.0, "avg_logprob": -0.09131637289504374, "compression_ratio": 1.8, "no_speech_prob": 0.011685884557664394}, {"id": 370, "seek": 223432, "start": 2252.1600000000003, "end": 2256.32, "text": " of things, we're just, that's exactly how Go does it, by the way. Go takes that document,", "tokens": [51256, 295, 721, 11, 321, 434, 445, 11, 300, 311, 2293, 577, 1037, 775, 309, 11, 538, 264, 636, 13, 1037, 2516, 300, 4166, 11, 51464], "temperature": 0.0, "avg_logprob": -0.09131637289504374, "compression_ratio": 1.8, "no_speech_prob": 0.011685884557664394}, {"id": 371, "seek": 223432, "start": 2256.32, "end": 2261.6800000000003, "text": " and it generates the Go code from straight up from the, from the Unicode specification document.", "tokens": [51464, 293, 309, 23815, 264, 1037, 3089, 490, 2997, 493, 490, 264, 11, 490, 264, 1156, 299, 1429, 31256, 4166, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09131637289504374, "compression_ratio": 1.8, "no_speech_prob": 0.011685884557664394}, {"id": 372, "seek": 226168, "start": 2261.68, "end": 2267.44, "text": " And it has a, you know, a whole library of, of, you know, true or false kind of things, right?", "tokens": [50364, 400, 309, 575, 257, 11, 291, 458, 11, 257, 1379, 6405, 295, 11, 295, 11, 291, 458, 11, 2074, 420, 7908, 733, 295, 721, 11, 558, 30, 50652], "temperature": 0.0, "avg_logprob": -0.08934689451147008, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0005883883568458259}, {"id": 373, "seek": 226168, "start": 2269.2, "end": 2275.2799999999997, "text": " But it's not a scanner. And so the only thing we're going to have to do in the Go one is", "tokens": [50740, 583, 309, 311, 406, 257, 30211, 13, 400, 370, 264, 787, 551, 321, 434, 516, 281, 362, 281, 360, 294, 264, 1037, 472, 307, 51044], "temperature": 0.0, "avg_logprob": -0.08934689451147008, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0005883883568458259}, {"id": 374, "seek": 226168, "start": 2275.2799999999997, "end": 2280.7999999999997, "text": " basically the same idea, but we're going to say, okay, is this thing a thing? And then,", "tokens": [51044, 1936, 264, 912, 1558, 11, 457, 321, 434, 516, 281, 584, 11, 1392, 11, 307, 341, 551, 257, 551, 30, 400, 550, 11, 51320], "temperature": 0.0, "avg_logprob": -0.08934689451147008, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0005883883568458259}, {"id": 375, "seek": 226168, "start": 2280.7999999999997, "end": 2286.72, "text": " and then we'll make a sum variation as well, so that it'll be like one or more of those things,", "tokens": [51320, 293, 550, 321, 603, 652, 257, 2408, 12990, 382, 731, 11, 370, 300, 309, 603, 312, 411, 472, 420, 544, 295, 729, 721, 11, 51616], "temperature": 0.0, "avg_logprob": -0.08934689451147008, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0005883883568458259}, {"id": 376, "seek": 228672, "start": 2286.72, "end": 2292.7999999999997, "text": " right? And, and all that code will get auto generated. So we'll have a pretty big library", "tokens": [50364, 558, 30, 400, 11, 293, 439, 300, 3089, 486, 483, 8399, 10833, 13, 407, 321, 603, 362, 257, 1238, 955, 6405, 50668], "temperature": 0.0, "avg_logprob": -0.11121423835428353, "compression_ratio": 1.625, "no_speech_prob": 0.006692496594041586}, {"id": 377, "seek": 228672, "start": 2292.7999999999997, "end": 2297.3599999999997, "text": " of scanners that'll be developed that you can then make your recursive descent", "tokens": [50668, 295, 795, 25792, 300, 603, 312, 4743, 300, 291, 393, 550, 652, 428, 20560, 488, 23475, 50896], "temperature": 0.0, "avg_logprob": -0.11121423835428353, "compression_ratio": 1.625, "no_speech_prob": 0.006692496594041586}, {"id": 378, "seek": 228672, "start": 2297.3599999999997, "end": 2303.04, "text": " parsers from. And maybe we can get somebody else to actually think it's a good idea besides me.", "tokens": [50896, 21156, 433, 490, 13, 400, 1310, 321, 393, 483, 2618, 1646, 281, 767, 519, 309, 311, 257, 665, 1558, 11868, 385, 13, 51180], "temperature": 0.0, "avg_logprob": -0.11121423835428353, "compression_ratio": 1.625, "no_speech_prob": 0.006692496594041586}, {"id": 379, "seek": 228672, "start": 2306.8799999999997, "end": 2310.24, "text": " Optimizing a lot first is that you can find you don't need the functions you're optimizing. No,", "tokens": [51372, 35013, 3319, 257, 688, 700, 307, 300, 291, 393, 915, 291, 500, 380, 643, 264, 6828, 291, 434, 40425, 13, 883, 11, 51540], "temperature": 0.0, "avg_logprob": -0.11121423835428353, "compression_ratio": 1.625, "no_speech_prob": 0.006692496594041586}, {"id": 380, "seek": 228672, "start": 2310.24, "end": 2315.12, "text": " that's right. So I'm saying, so a lot of them, yeah, you could combine the two things together", "tokens": [51540, 300, 311, 558, 13, 407, 286, 478, 1566, 11, 370, 257, 688, 295, 552, 11, 1338, 11, 291, 727, 10432, 264, 732, 721, 1214, 51784], "temperature": 0.0, "avg_logprob": -0.11121423835428353, "compression_ratio": 1.625, "no_speech_prob": 0.006692496594041586}, {"id": 381, "seek": 231512, "start": 2315.12, "end": 2322.3199999999997, "text": " or something, right? Yeah. So, so I think, I think I'm kind of happy with this where we're", "tokens": [50364, 420, 746, 11, 558, 30, 865, 13, 407, 11, 370, 286, 519, 11, 286, 519, 286, 478, 733, 295, 2055, 365, 341, 689, 321, 434, 50724], "temperature": 0.0, "avg_logprob": -0.14130871946161444, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0010649332543835044}, {"id": 382, "seek": 231512, "start": 2322.3199999999997, "end": 2329.92, "text": " going with this now. Now I still have this, this bug here, my white space bug. But the other one", "tokens": [50724, 516, 365, 341, 586, 13, 823, 286, 920, 362, 341, 11, 341, 7426, 510, 11, 452, 2418, 1901, 7426, 13, 583, 264, 661, 472, 51104], "temperature": 0.0, "avg_logprob": -0.14130871946161444, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0010649332543835044}, {"id": 383, "seek": 231512, "start": 2329.92, "end": 2340.24, "text": " is fine. Let's, let's try to run that one. Let's do run. What was it the end of line? End of line,", "tokens": [51104, 307, 2489, 13, 961, 311, 11, 718, 311, 853, 281, 1190, 300, 472, 13, 961, 311, 360, 1190, 13, 708, 390, 309, 264, 917, 295, 1622, 30, 6967, 295, 1622, 11, 51620], "temperature": 0.0, "avg_logprob": -0.14130871946161444, "compression_ratio": 1.545945945945946, "no_speech_prob": 0.0010649332543835044}, {"id": 384, "seek": 234024, "start": 2340.24, "end": 2347.3599999999997, "text": " I think, right? Oops, we need to let's turn scanning on end of line. So you can see it", "tokens": [50364, 286, 519, 11, 558, 30, 21726, 11, 321, 643, 281, 718, 311, 1261, 27019, 322, 917, 295, 1622, 13, 407, 291, 393, 536, 309, 50720], "temperature": 0.0, "avg_logprob": -0.18685506184895834, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.0030752462334930897}, {"id": 385, "seek": 234024, "start": 2349.2799999999997, "end": 2358.56, "text": " end line. Then there's lots of in lines. So she was the carriage feed one. Actually,", "tokens": [50816, 917, 1622, 13, 1396, 456, 311, 3195, 295, 294, 3876, 13, 407, 750, 390, 264, 31811, 3154, 472, 13, 5135, 11, 51280], "temperature": 0.0, "avg_logprob": -0.18685506184895834, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.0030752462334930897}, {"id": 386, "seek": 234024, "start": 2358.56, "end": 2365.2799999999997, "text": " let's just turn it on for the whole, the whole scanner. Yeah, scanner scanner has a trace for", "tokens": [51280, 718, 311, 445, 1261, 309, 322, 337, 264, 1379, 11, 264, 1379, 30211, 13, 865, 11, 30211, 30211, 575, 257, 13508, 337, 51616], "temperature": 0.0, "avg_logprob": -0.18685506184895834, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.0030752462334930897}, {"id": 387, "seek": 236528, "start": 2365.28, "end": 2369.2000000000003, "text": " the whole entire package if you want to turn tracing on on everything.", "tokens": [50364, 264, 1379, 2302, 7372, 498, 291, 528, 281, 1261, 25262, 322, 322, 1203, 13, 50560], "temperature": 0.0, "avg_logprob": -0.19535289340549045, "compression_ratio": 1.5778894472361809, "no_speech_prob": 0.003945220727473497}, {"id": 388, "seek": 236528, "start": 2371.84, "end": 2380.5600000000004, "text": " Yeah. Trace equals, I'm probably have to do an init here. Trace equals one.", "tokens": [50692, 865, 13, 1765, 617, 6915, 11, 286, 478, 1391, 362, 281, 360, 364, 3157, 510, 13, 1765, 617, 6915, 472, 13, 51128], "temperature": 0.0, "avg_logprob": -0.19535289340549045, "compression_ratio": 1.5778894472361809, "no_speech_prob": 0.003945220727473497}, {"id": 389, "seek": 236528, "start": 2381.44, "end": 2385.36, "text": " Yeah, that's going to say you need to put that in an init. All right, fine.", "tokens": [51172, 865, 11, 300, 311, 516, 281, 584, 291, 643, 281, 829, 300, 294, 364, 3157, 13, 1057, 558, 11, 2489, 13, 51368], "temperature": 0.0, "avg_logprob": -0.19535289340549045, "compression_ratio": 1.5778894472361809, "no_speech_prob": 0.003945220727473497}, {"id": 390, "seek": 236528, "start": 2387.36, "end": 2392.7200000000003, "text": " This is just for now. There's other testing ways to do this, but I'll just do that for now.", "tokens": [51468, 639, 307, 445, 337, 586, 13, 821, 311, 661, 4997, 2098, 281, 360, 341, 11, 457, 286, 603, 445, 360, 300, 337, 586, 13, 51736], "temperature": 0.0, "avg_logprob": -0.19535289340549045, "compression_ratio": 1.5778894472361809, "no_speech_prob": 0.003945220727473497}, {"id": 391, "seek": 239272, "start": 2392.7999999999997, "end": 2399.68, "text": " So we could go test. So actually, this is going to show every single parts that we did.", "tokens": [50368, 407, 321, 727, 352, 1500, 13, 407, 767, 11, 341, 307, 516, 281, 855, 633, 2167, 3166, 300, 321, 630, 13, 50712], "temperature": 0.0, "avg_logprob": -0.12562368749603023, "compression_ratio": 1.9008264462809918, "no_speech_prob": 0.0002378164790570736}, {"id": 392, "seek": 239272, "start": 2400.3199999999997, "end": 2406.3999999999996, "text": " I'm so happy with this. So when you turn the trace on, when you turn it on this way,", "tokens": [50744, 286, 478, 370, 2055, 365, 341, 13, 407, 562, 291, 1261, 264, 13508, 322, 11, 562, 291, 1261, 309, 322, 341, 636, 11, 51048], "temperature": 0.0, "avg_logprob": -0.12562368749603023, "compression_ratio": 1.9008264462809918, "no_speech_prob": 0.0002378164790570736}, {"id": 393, "seek": 239272, "start": 2406.3999999999996, "end": 2412.3999999999996, "text": " it'll actually give you like the full thing. So here it was, it was, it, it read the first", "tokens": [51048, 309, 603, 767, 976, 291, 411, 264, 1577, 551, 13, 407, 510, 309, 390, 11, 309, 390, 11, 309, 11, 309, 1401, 264, 700, 51348], "temperature": 0.0, "avg_logprob": -0.12562368749603023, "compression_ratio": 1.9008264462809918, "no_speech_prob": 0.0002378164790570736}, {"id": 394, "seek": 239272, "start": 2412.3999999999996, "end": 2417.6, "text": " carriage return and then a line return and then another line return. So that, that was that one", "tokens": [51348, 31811, 2736, 293, 550, 257, 1622, 2736, 293, 550, 1071, 1622, 2736, 13, 407, 300, 11, 300, 390, 300, 472, 51608], "temperature": 0.0, "avg_logprob": -0.12562368749603023, "compression_ratio": 1.9008264462809918, "no_speech_prob": 0.0002378164790570736}, {"id": 395, "seek": 239272, "start": 2417.6, "end": 2420.56, "text": " that we did. And there's another one. So these are all the different ones. There's no other printing", "tokens": [51608, 300, 321, 630, 13, 400, 456, 311, 1071, 472, 13, 407, 613, 366, 439, 264, 819, 2306, 13, 821, 311, 572, 661, 14699, 51756], "temperature": 0.0, "avg_logprob": -0.12562368749603023, "compression_ratio": 1.9008264462809918, "no_speech_prob": 0.0002378164790570736}, {"id": 396, "seek": 242056, "start": 2420.56, "end": 2424.88, "text": " statements going on in there, but you can kind of watch what's getting parsed as you go", "tokens": [50364, 12363, 516, 322, 294, 456, 11, 457, 291, 393, 733, 295, 1159, 437, 311, 1242, 21156, 292, 382, 291, 352, 50580], "temperature": 0.0, "avg_logprob": -0.15662516195943035, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.013221511617302895}, {"id": 397, "seek": 242056, "start": 2426.56, "end": 2429.84, "text": " and check on it. And you can go, go look at that and see if you like it.", "tokens": [50664, 293, 1520, 322, 309, 13, 400, 291, 393, 352, 11, 352, 574, 412, 300, 293, 536, 498, 291, 411, 309, 13, 50828], "temperature": 0.0, "avg_logprob": -0.15662516195943035, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.013221511617302895}, {"id": 398, "seek": 242056, "start": 2431.44, "end": 2434.24, "text": " But yeah, I mean, it's working without that portal pass. I just got that white space one", "tokens": [50908, 583, 1338, 11, 286, 914, 11, 309, 311, 1364, 1553, 300, 14982, 1320, 13, 286, 445, 658, 300, 2418, 1901, 472, 51048], "temperature": 0.0, "avg_logprob": -0.15662516195943035, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.013221511617302895}, {"id": 399, "seek": 242056, "start": 2434.24, "end": 2438.7999999999997, "text": " I have to figure out. So I think that's enough for this video. I just, I just wanted to show", "tokens": [51048, 286, 362, 281, 2573, 484, 13, 407, 286, 519, 300, 311, 1547, 337, 341, 960, 13, 286, 445, 11, 286, 445, 1415, 281, 855, 51276], "temperature": 0.0, "avg_logprob": -0.15662516195943035, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.013221511617302895}, {"id": 400, "seek": 242056, "start": 2439.36, "end": 2445.68, "text": " where I was. Some of the, I mean, I don't got the, the, the end paragraph turns out to be end block.", "tokens": [51304, 689, 286, 390, 13, 2188, 295, 264, 11, 286, 914, 11, 286, 500, 380, 658, 264, 11, 264, 11, 264, 917, 18865, 4523, 484, 281, 312, 917, 3461, 13, 51620], "temperature": 0.0, "avg_logprob": -0.15662516195943035, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.013221511617302895}, {"id": 401, "seek": 244568, "start": 2446.3999999999996, "end": 2450.8799999999997, "text": " So remember yesterday I was doing basic markdown and I was like, hmm, we need to", "tokens": [50400, 407, 1604, 5186, 286, 390, 884, 3875, 1491, 5093, 293, 286, 390, 411, 11, 16478, 11, 321, 643, 281, 50624], "temperature": 0.0, "avg_logprob": -0.11707737775352912, "compression_ratio": 1.8, "no_speech_prob": 0.004069938324391842}, {"id": 402, "seek": 244568, "start": 2450.8799999999997, "end": 2455.2799999999997, "text": " delineate our blocks. Well, what is, what do we have? We have any number of spaces", "tokens": [50624, 1103, 533, 473, 527, 8474, 13, 1042, 11, 437, 307, 11, 437, 360, 321, 362, 30, 492, 362, 604, 1230, 295, 7673, 50844], "temperature": 0.0, "avg_logprob": -0.11707737775352912, "compression_ratio": 1.8, "no_speech_prob": 0.004069938324391842}, {"id": 403, "seek": 244568, "start": 2456.7999999999997, "end": 2464.24, "text": " and then a greedy include of, of white space and line returns, you know, and that's what this is.", "tokens": [50920, 293, 550, 257, 28228, 4090, 295, 11, 295, 2418, 1901, 293, 1622, 11247, 11, 291, 458, 11, 293, 300, 311, 437, 341, 307, 13, 51292], "temperature": 0.0, "avg_logprob": -0.11707737775352912, "compression_ratio": 1.8, "no_speech_prob": 0.004069938324391842}, {"id": 404, "seek": 244568, "start": 2464.24, "end": 2468.72, "text": " So I had to actually re, I had to rewrite it and say, do I have the end of,", "tokens": [51292, 407, 286, 632, 281, 767, 319, 11, 286, 632, 281, 28132, 309, 293, 584, 11, 360, 286, 362, 264, 917, 295, 11, 51516], "temperature": 0.0, "avg_logprob": -0.11707737775352912, "compression_ratio": 1.8, "no_speech_prob": 0.004069938324391842}, {"id": 405, "seek": 244568, "start": 2468.72, "end": 2474.3199999999997, "text": " do I have the end of the data? Do I have an end of line and then the end of the data?", "tokens": [51516, 360, 286, 362, 264, 917, 295, 264, 1412, 30, 1144, 286, 362, 364, 917, 295, 1622, 293, 550, 264, 917, 295, 264, 1412, 30, 51796], "temperature": 0.0, "avg_logprob": -0.11707737775352912, "compression_ratio": 1.8, "no_speech_prob": 0.004069938324391842}, {"id": 406, "seek": 247432, "start": 2474.32, "end": 2478.96, "text": " Or do I have two end of lines, which are, you know, the greedy thing and then the white space", "tokens": [50364, 1610, 360, 286, 362, 732, 917, 295, 3876, 11, 597, 366, 11, 291, 458, 11, 264, 28228, 551, 293, 550, 264, 2418, 1901, 50596], "temperature": 0.0, "avg_logprob": -0.12495946172458022, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008295600418932736}, {"id": 407, "seek": 247432, "start": 2478.96, "end": 2484.6400000000003, "text": " splat and, you know, peg, uh, repeat operators are greedy by default. So that says, grab as", "tokens": [50596, 4732, 267, 293, 11, 291, 458, 11, 17199, 11, 2232, 11, 7149, 19077, 366, 28228, 538, 7576, 13, 407, 300, 1619, 11, 4444, 382, 50880], "temperature": 0.0, "avg_logprob": -0.12495946172458022, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008295600418932736}, {"id": 408, "seek": 247432, "start": 2484.6400000000003, "end": 2488.7200000000003, "text": " much white space as you can. As far as I know, I might have that wrong, but grab as much white", "tokens": [50880, 709, 2418, 1901, 382, 291, 393, 13, 1018, 1400, 382, 286, 458, 11, 286, 1062, 362, 300, 2085, 11, 457, 4444, 382, 709, 2418, 51084], "temperature": 0.0, "avg_logprob": -0.12495946172458022, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008295600418932736}, {"id": 409, "seek": 247432, "start": 2488.7200000000003, "end": 2496.0, "text": " space as you can and then make sure you have this at the end, right? Now it may be that I have to,", "tokens": [51084, 1901, 382, 291, 393, 293, 550, 652, 988, 291, 362, 341, 412, 264, 917, 11, 558, 30, 823, 309, 815, 312, 300, 286, 362, 281, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12495946172458022, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008295600418932736}, {"id": 410, "seek": 247432, "start": 2497.28, "end": 2504.2400000000002, "text": " uh, uh, if I were to put this up here in the front, then it would be non greedy. So it would", "tokens": [51512, 2232, 11, 2232, 11, 498, 286, 645, 281, 829, 341, 493, 510, 294, 264, 1868, 11, 550, 309, 576, 312, 2107, 28228, 13, 407, 309, 576, 51860], "temperature": 0.0, "avg_logprob": -0.12495946172458022, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008295600418932736}, {"id": 411, "seek": 250432, "start": 2504.7200000000003, "end": 2510.1600000000003, "text": " it would get, you know, it would, it would get the first one. So the first match of,", "tokens": [50384, 309, 576, 483, 11, 291, 458, 11, 309, 576, 11, 309, 576, 483, 264, 700, 472, 13, 407, 264, 700, 2995, 295, 11, 50656], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 412, "seek": 250432, "start": 2510.1600000000003, "end": 2514.6400000000003, "text": " I had that happening before I had the first match of, of a line of double line returns", "tokens": [50656, 286, 632, 300, 2737, 949, 286, 632, 264, 700, 2995, 295, 11, 295, 257, 1622, 295, 3834, 1622, 11247, 50880], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 413, "seek": 250432, "start": 2514.6400000000003, "end": 2519.2000000000003, "text": " and it got the first one. So that's how you, you do non greedy is you put that stuff up in front", "tokens": [50880, 293, 309, 658, 264, 700, 472, 13, 407, 300, 311, 577, 291, 11, 291, 360, 2107, 28228, 307, 291, 829, 300, 1507, 493, 294, 1868, 51108], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 414, "seek": 250432, "start": 2519.2000000000003, "end": 2522.88, "text": " here, but you have to kind of look at the peg and syntax, the peg syntax to get that. That's,", "tokens": [51108, 510, 11, 457, 291, 362, 281, 733, 295, 574, 412, 264, 17199, 293, 28431, 11, 264, 17199, 28431, 281, 483, 300, 13, 663, 311, 11, 51292], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 415, "seek": 250432, "start": 2522.88, "end": 2528.56, "text": " that's from Brian Ford. That's not for me. Uh, but, and I still have to go look it up here as well.", "tokens": [51292, 300, 311, 490, 10765, 11961, 13, 663, 311, 406, 337, 385, 13, 4019, 11, 457, 11, 293, 286, 920, 362, 281, 352, 574, 309, 493, 510, 382, 731, 13, 51576], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 416, "seek": 250432, "start": 2528.56, "end": 2531.52, "text": " But it's, I, once you get it, it's much easier than regular expressions. It's not,", "tokens": [51576, 583, 309, 311, 11, 286, 11, 1564, 291, 483, 309, 11, 309, 311, 709, 3571, 813, 3890, 15277, 13, 467, 311, 406, 11, 51724], "temperature": 0.0, "avg_logprob": -0.11360839650600771, "compression_ratio": 1.872852233676976, "no_speech_prob": 0.0012447823537513614}, {"id": 417, "seek": 253152, "start": 2531.68, "end": 2534.32, "text": " actually it has positive negative look ahead and all that kind of thing,", "tokens": [50372, 767, 309, 575, 3353, 3671, 574, 2286, 293, 439, 300, 733, 295, 551, 11, 50504], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 418, "seek": 253152, "start": 2534.32, "end": 2537.68, "text": " which regular expressions, depending on which engine you're using, don't really do well.", "tokens": [50504, 597, 3890, 15277, 11, 5413, 322, 597, 2848, 291, 434, 1228, 11, 500, 380, 534, 360, 731, 13, 50672], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 419, "seek": 253152, "start": 2538.88, "end": 2542.64, "text": " Not to mention, you know, the ability to capture thing. So, and, and I use the,", "tokens": [50732, 1726, 281, 2152, 11, 291, 458, 11, 264, 3485, 281, 7983, 551, 13, 407, 11, 293, 11, 293, 286, 764, 264, 11, 50920], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 420, "seek": 253152, "start": 2542.64, "end": 2548.96, "text": " I use the block here and go to, uh, which I actually prefer to for loops because", "tokens": [50920, 286, 764, 264, 3461, 510, 293, 352, 281, 11, 2232, 11, 597, 286, 767, 4382, 281, 337, 16121, 570, 51236], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 421, "seek": 253152, "start": 2549.92, "end": 2555.68, "text": " they just are so much cleaner. Um, because you just know you're going to go up to the top again", "tokens": [51284, 436, 445, 366, 370, 709, 16532, 13, 3301, 11, 570, 291, 445, 458, 291, 434, 516, 281, 352, 493, 281, 264, 1192, 797, 51572], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 422, "seek": 253152, "start": 2555.68, "end": 2561.04, "text": " and you know, you know, the thing I like about it's much easier. I mean, it's much harder to", "tokens": [51572, 293, 291, 458, 11, 291, 458, 11, 264, 551, 286, 411, 466, 309, 311, 709, 3571, 13, 286, 914, 11, 309, 311, 709, 6081, 281, 51840], "temperature": 0.0, "avg_logprob": -0.12540894967538338, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.008061561733484268}, {"id": 423, "seek": 256104, "start": 2561.04, "end": 2567.52, "text": " write an infinite loop with a labeled block than it is with an infinite forever loop,", "tokens": [50364, 2464, 364, 13785, 6367, 365, 257, 21335, 3461, 813, 309, 307, 365, 364, 13785, 5680, 6367, 11, 50688], "temperature": 0.0, "avg_logprob": -0.12155500742105338, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0022517130710184574}, {"id": 424, "seek": 256104, "start": 2567.52, "end": 2573.04, "text": " which is just for, and I used to do them that way. Um, because, I mean, you definitely can,", "tokens": [50688, 597, 307, 445, 337, 11, 293, 286, 1143, 281, 360, 552, 300, 636, 13, 3301, 11, 570, 11, 286, 914, 11, 291, 2138, 393, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12155500742105338, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0022517130710184574}, {"id": 425, "seek": 256104, "start": 2573.04, "end": 2578.56, "text": " but you have to explicitly create an infinite loop that keeps going to the top again, right? So,", "tokens": [50964, 457, 291, 362, 281, 20803, 1884, 364, 13785, 6367, 300, 5965, 516, 281, 264, 1192, 797, 11, 558, 30, 407, 11, 51240], "temperature": 0.0, "avg_logprob": -0.12155500742105338, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0022517130710184574}, {"id": 426, "seek": 256104, "start": 2578.56, "end": 2585.12, "text": " it's kind of like a do while. Um, and you see this all the time in parsers. This is in go, it's in,", "tokens": [51240, 309, 311, 733, 295, 411, 257, 360, 1339, 13, 3301, 11, 293, 291, 536, 341, 439, 264, 565, 294, 21156, 433, 13, 639, 307, 294, 352, 11, 309, 311, 294, 11, 51568], "temperature": 0.0, "avg_logprob": -0.12155500742105338, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0022517130710184574}, {"id": 427, "seek": 258512, "start": 2585.12, "end": 2592.08, "text": " and goes compiler for the language that go to is a very real, uh, solid thing to use for,", "tokens": [50364, 293, 1709, 31958, 337, 264, 2856, 300, 352, 281, 307, 257, 588, 957, 11, 2232, 11, 5100, 551, 281, 764, 337, 11, 50712], "temperature": 0.0, "avg_logprob": -0.1357572021484375, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.012052963487803936}, {"id": 428, "seek": 258512, "start": 2592.88, "end": 2597.92, "text": " uh, for compilers and for parsers and scanners. And it saves you from any kind of functional", "tokens": [50752, 2232, 11, 337, 715, 388, 433, 293, 337, 21156, 433, 293, 795, 25792, 13, 400, 309, 19155, 291, 490, 604, 733, 295, 11745, 51004], "temperature": 0.0, "avg_logprob": -0.1357572021484375, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.012052963487803936}, {"id": 429, "seek": 258512, "start": 2597.92, "end": 2602.48, "text": " recursion, which is the devil when it comes to performance and parsers because you hit, you hit,", "tokens": [51004, 20560, 313, 11, 597, 307, 264, 13297, 562, 309, 1487, 281, 3389, 293, 21156, 433, 570, 291, 2045, 11, 291, 2045, 11, 51232], "temperature": 0.0, "avg_logprob": -0.1357572021484375, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.012052963487803936}, {"id": 430, "seek": 258512, "start": 2602.48, "end": 2607.44, "text": " um, you hit, you know, you hit, uh, indirection functional loops, uh, functional recursion loops", "tokens": [51232, 1105, 11, 291, 2045, 11, 291, 458, 11, 291, 2045, 11, 2232, 11, 1016, 621, 882, 11745, 16121, 11, 2232, 11, 11745, 20560, 313, 16121, 51480], "temperature": 0.0, "avg_logprob": -0.1357572021484375, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.012052963487803936}, {"id": 431, "seek": 258512, "start": 2607.44, "end": 2612.0, "text": " and stuff like that. Some languages is the preferred way to do it, but, but, but most", "tokens": [51480, 293, 1507, 411, 300, 13, 2188, 8650, 307, 264, 16494, 636, 281, 360, 309, 11, 457, 11, 457, 11, 457, 881, 51708], "temperature": 0.0, "avg_logprob": -0.1357572021484375, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.012052963487803936}, {"id": 432, "seek": 261200, "start": 2612.08, "end": 2616.32, "text": " of the languages or not, most of them want you to just stay within there and kind of", "tokens": [50368, 295, 264, 8650, 420, 406, 11, 881, 295, 552, 528, 291, 281, 445, 1754, 1951, 456, 293, 733, 295, 50580], "temperature": 0.0, "avg_logprob": -0.11776362359523773, "compression_ratio": 1.7, "no_speech_prob": 0.006487792357802391}, {"id": 433, "seek": 261200, "start": 2616.32, "end": 2620.32, "text": " figure out a way to short circuit and go back up to the top. And it's more performant that way too.", "tokens": [50580, 2573, 484, 257, 636, 281, 2099, 9048, 293, 352, 646, 493, 281, 264, 1192, 13, 400, 309, 311, 544, 2042, 394, 300, 636, 886, 13, 50780], "temperature": 0.0, "avg_logprob": -0.11776362359523773, "compression_ratio": 1.7, "no_speech_prob": 0.006487792357802391}, {"id": 434, "seek": 261200, "start": 2620.96, "end": 2627.84, "text": " So this one has to have the whole notion of a found Boolean in it because even if I find one,", "tokens": [50812, 407, 341, 472, 575, 281, 362, 264, 1379, 10710, 295, 257, 1352, 23351, 28499, 294, 309, 570, 754, 498, 286, 915, 472, 11, 51156], "temperature": 0.0, "avg_logprob": -0.11776362359523773, "compression_ratio": 1.7, "no_speech_prob": 0.006487792357802391}, {"id": 435, "seek": 261200, "start": 2627.84, "end": 2632.16, "text": " I still want to look for more. I still keep wanting to look for more until I get,", "tokens": [51156, 286, 920, 528, 281, 574, 337, 544, 13, 286, 920, 1066, 7935, 281, 574, 337, 544, 1826, 286, 483, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11776362359523773, "compression_ratio": 1.7, "no_speech_prob": 0.006487792357802391}, {"id": 436, "seek": 261200, "start": 2632.16, "end": 2637.2, "text": " I'm greedily get the, the last one, right? And I, before I added a notion of a, of a found loop in", "tokens": [51372, 286, 478, 29230, 953, 483, 264, 11, 264, 1036, 472, 11, 558, 30, 400, 286, 11, 949, 286, 3869, 257, 10710, 295, 257, 11, 295, 257, 1352, 6367, 294, 51624], "temperature": 0.0, "avg_logprob": -0.11776362359523773, "compression_ratio": 1.7, "no_speech_prob": 0.006487792357802391}, {"id": 437, "seek": 263720, "start": 2637.2, "end": 2642.0, "text": " that I, I wasn't getting everything. And so what it does is it keeps getting stuff until it hits", "tokens": [50364, 300, 286, 11, 286, 2067, 380, 1242, 1203, 13, 400, 370, 437, 309, 775, 307, 309, 5965, 1242, 1507, 1826, 309, 8664, 50604], "temperature": 0.0, "avg_logprob": -0.0891935652580814, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.013221985660493374}, {"id": 438, "seek": 263720, "start": 2642.0, "end": 2648.3199999999997, "text": " something that is not valid. And it's like, okay, I finally run out, but did I ever find anything", "tokens": [50604, 746, 300, 307, 406, 7363, 13, 400, 309, 311, 411, 11, 1392, 11, 286, 2721, 1190, 484, 11, 457, 630, 286, 1562, 915, 1340, 50920], "temperature": 0.0, "avg_logprob": -0.0891935652580814, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.013221985660493374}, {"id": 439, "seek": 263720, "start": 2648.3199999999997, "end": 2654.16, "text": " along the way? I was like, Oh yeah. Okay. Well, what was the last one that I did find? And, and then,", "tokens": [50920, 2051, 264, 636, 30, 286, 390, 411, 11, 876, 1338, 13, 1033, 13, 1042, 11, 437, 390, 264, 1036, 472, 300, 286, 630, 915, 30, 400, 11, 293, 550, 11, 51212], "temperature": 0.0, "avg_logprob": -0.0891935652580814, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.013221985660493374}, {"id": 440, "seek": 263720, "start": 2654.16, "end": 2660.96, "text": " you know, it can, it can tell you that thing. Um, and, and that's what the go to is. Um, this is", "tokens": [51212, 291, 458, 11, 309, 393, 11, 309, 393, 980, 291, 300, 551, 13, 3301, 11, 293, 11, 293, 300, 311, 437, 264, 352, 281, 307, 13, 3301, 11, 341, 307, 51552], "temperature": 0.0, "avg_logprob": -0.0891935652580814, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.013221985660493374}, {"id": 441, "seek": 263720, "start": 2660.96, "end": 2666.3999999999996, "text": " actually wrong. I'm just realizing I have some problems with this. Yeah. It's funny because", "tokens": [51552, 767, 2085, 13, 286, 478, 445, 16734, 286, 362, 512, 2740, 365, 341, 13, 865, 13, 467, 311, 4074, 570, 51824], "temperature": 0.0, "avg_logprob": -0.0891935652580814, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.013221985660493374}, {"id": 442, "seek": 266640, "start": 2666.4, "end": 2670.7200000000003, "text": " now that it's cleaner and I've got to spend my whole day fixing up all of this syntax, I can see", "tokens": [50364, 586, 300, 309, 311, 16532, 293, 286, 600, 658, 281, 3496, 452, 1379, 786, 19442, 493, 439, 295, 341, 28431, 11, 286, 393, 536, 50580], "temperature": 0.0, "avg_logprob": -0.08529744448361697, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.0020506521686911583}, {"id": 443, "seek": 266640, "start": 2670.7200000000003, "end": 2677.28, "text": " that this is probably wrong because this is, this is going to, uh, this is, if it, if, oh no, no,", "tokens": [50580, 300, 341, 307, 1391, 2085, 570, 341, 307, 11, 341, 307, 516, 281, 11, 2232, 11, 341, 307, 11, 498, 309, 11, 498, 11, 1954, 572, 11, 572, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08529744448361697, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.0020506521686911583}, {"id": 444, "seek": 266640, "start": 2677.28, "end": 2683.04, "text": " I'm sorry. No, I'm, I'm sorry. This is only if it's not found. Yeah. This is only if it's not", "tokens": [50908, 286, 478, 2597, 13, 883, 11, 286, 478, 11, 286, 478, 2597, 13, 639, 307, 787, 498, 309, 311, 406, 1352, 13, 865, 13, 639, 307, 787, 498, 309, 311, 406, 51196], "temperature": 0.0, "avg_logprob": -0.08529744448361697, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.0020506521686911583}, {"id": 445, "seek": 266640, "start": 2683.04, "end": 2688.2400000000002, "text": " found. Yeah. So scanners do not advance. So the rule, this is a kind of a hard thing to,", "tokens": [51196, 1352, 13, 865, 13, 407, 795, 25792, 360, 406, 7295, 13, 407, 264, 4978, 11, 341, 307, 257, 733, 295, 257, 1152, 551, 281, 11, 51456], "temperature": 0.0, "avg_logprob": -0.08529744448361697, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.0020506521686911583}, {"id": 446, "seek": 266640, "start": 2688.2400000000002, "end": 2692.2400000000002, "text": " to come up with when you're trying to figure out how to make your parsers and functions and stuff.", "tokens": [51456, 281, 808, 493, 365, 562, 291, 434, 1382, 281, 2573, 484, 577, 281, 652, 428, 21156, 433, 293, 6828, 293, 1507, 13, 51656], "temperature": 0.0, "avg_logprob": -0.08529744448361697, "compression_ratio": 1.803030303030303, "no_speech_prob": 0.0020506521686911583}, {"id": 447, "seek": 269224, "start": 2692.24, "end": 2700.9599999999996, "text": " But the easiest rule is for a scanner is if it scans, it returns true and it advances the scanner.", "tokens": [50364, 583, 264, 12889, 4978, 307, 337, 257, 30211, 307, 498, 309, 35116, 11, 309, 11247, 2074, 293, 309, 25297, 264, 30211, 13, 50800], "temperature": 0.0, "avg_logprob": -0.07960472684918028, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.0031726076267659664}, {"id": 448, "seek": 269224, "start": 2701.52, "end": 2705.68, "text": " If it doesn't to the next thing, right to the beginning of the next thing, it doesn't scan", "tokens": [50828, 759, 309, 1177, 380, 281, 264, 958, 551, 11, 558, 281, 264, 2863, 295, 264, 958, 551, 11, 309, 1177, 380, 11049, 51036], "temperature": 0.0, "avg_logprob": -0.07960472684918028, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.0031726076267659664}, {"id": 449, "seek": 269224, "start": 2705.68, "end": 2711.04, "text": " that thing. It puts it right to the beginning of it. If it doesn't, if it doesn't scan anything,", "tokens": [51036, 300, 551, 13, 467, 8137, 309, 558, 281, 264, 2863, 295, 309, 13, 759, 309, 1177, 380, 11, 498, 309, 1177, 380, 11049, 1340, 11, 51304], "temperature": 0.0, "avg_logprob": -0.07960472684918028, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.0031726076267659664}, {"id": 450, "seek": 269224, "start": 2711.04, "end": 2717.68, "text": " it needs to leave the scanner exactly how it was before it was called. And in order to accomplish", "tokens": [51304, 309, 2203, 281, 1856, 264, 30211, 2293, 577, 309, 390, 949, 309, 390, 1219, 13, 400, 294, 1668, 281, 9021, 51636], "temperature": 0.0, "avg_logprob": -0.07960472684918028, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.0031726076267659664}, {"id": 451, "seek": 271768, "start": 2717.68, "end": 2724.72, "text": " that, you need to take a bookmark so that you can snap back to it, right? And I put go to here,", "tokens": [50364, 300, 11, 291, 643, 281, 747, 257, 1446, 5638, 370, 300, 291, 393, 13650, 646, 281, 309, 11, 558, 30, 400, 286, 829, 352, 281, 510, 11, 50716], "temperature": 0.0, "avg_logprob": -0.17449282882805156, "compression_ratio": 1.797709923664122, "no_speech_prob": 0.00609730975702405}, {"id": 452, "seek": 271768, "start": 2724.72, "end": 2729.2, "text": " I could probably do snap, but that would people think I would snap the shouting or whatever,", "tokens": [50716, 286, 727, 1391, 360, 13650, 11, 457, 300, 576, 561, 519, 286, 576, 13650, 264, 20382, 420, 2035, 11, 50940], "temperature": 0.0, "avg_logprob": -0.17449282882805156, "compression_ratio": 1.797709923664122, "no_speech_prob": 0.00609730975702405}, {"id": 453, "seek": 271768, "start": 2729.2, "end": 2732.64, "text": " go to use the one I'm going to use there. So, so that actually sets it to the cursor and the", "tokens": [50940, 352, 281, 764, 264, 472, 286, 478, 516, 281, 764, 456, 13, 407, 11, 370, 300, 767, 6352, 309, 281, 264, 28169, 293, 264, 51112], "temperature": 0.0, "avg_logprob": -0.17449282882805156, "compression_ratio": 1.797709923664122, "no_speech_prob": 0.00609730975702405}, {"id": 454, "seek": 271768, "start": 2732.64, "end": 2739.8399999999997, "text": " cursor is three things. It's the byte index in the buffer by buffer array of the, uh, you know,", "tokens": [51112, 28169, 307, 1045, 721, 13, 467, 311, 264, 40846, 8186, 294, 264, 21762, 538, 21762, 10225, 295, 264, 11, 2232, 11, 291, 458, 11, 51472], "temperature": 0.0, "avg_logprob": -0.17449282882805156, "compression_ratio": 1.797709923664122, "no_speech_prob": 0.00609730975702405}, {"id": 455, "seek": 271768, "start": 2739.8399999999997, "end": 2745.8399999999997, "text": " of, of the first item in, in the room, the first bite of the room. Uh, it is the room itself,", "tokens": [51472, 295, 11, 295, 264, 700, 3174, 294, 11, 294, 264, 1808, 11, 264, 700, 7988, 295, 264, 1808, 13, 4019, 11, 309, 307, 264, 1808, 2564, 11, 51772], "temperature": 0.0, "avg_logprob": -0.17449282882805156, "compression_ratio": 1.797709923664122, "no_speech_prob": 0.00609730975702405}, {"id": 456, "seek": 274584, "start": 2745.84, "end": 2749.1200000000003, "text": " a copy of the room. That's what, that's what we get when we set, when we get, when we get,", "tokens": [50364, 257, 5055, 295, 264, 1808, 13, 663, 311, 437, 11, 300, 311, 437, 321, 483, 562, 321, 992, 11, 562, 321, 483, 11, 562, 321, 483, 11, 50528], "temperature": 0.0, "avg_logprob": -0.1319640399963875, "compression_ratio": 1.9390862944162437, "no_speech_prob": 0.006097228731960058}, {"id": 457, "seek": 274584, "start": 2749.1200000000003, "end": 2762.08, "text": " go get dot rune. Um, and, and it is, um, it's also the, uh, uh, the, the, the, uh, end, the end of", "tokens": [50528, 352, 483, 5893, 1190, 68, 13, 3301, 11, 293, 11, 293, 309, 307, 11, 1105, 11, 309, 311, 611, 264, 11, 2232, 11, 2232, 11, 264, 11, 264, 11, 264, 11, 2232, 11, 917, 11, 264, 917, 295, 51176], "temperature": 0.0, "avg_logprob": -0.1319640399963875, "compression_ratio": 1.9390862944162437, "no_speech_prob": 0.006097228731960058}, {"id": 458, "seek": 274584, "start": 2762.08, "end": 2769.44, "text": " the room. So the, the byte pointing to the byte array to the beginning of the next thing, which is", "tokens": [51176, 264, 1808, 13, 407, 264, 11, 264, 40846, 12166, 281, 264, 40846, 10225, 281, 264, 2863, 295, 264, 958, 551, 11, 597, 307, 51544], "temperature": 0.0, "avg_logprob": -0.1319640399963875, "compression_ratio": 1.9390862944162437, "no_speech_prob": 0.006097228731960058}, {"id": 459, "seek": 274584, "start": 2769.44, "end": 2773.6000000000004, "text": " like maybe one or two, three things away. And that's, that's, that's where we got this thing.", "tokens": [51544, 411, 1310, 472, 420, 732, 11, 1045, 721, 1314, 13, 400, 300, 311, 11, 300, 311, 11, 300, 311, 689, 321, 658, 341, 551, 13, 51752], "temperature": 0.0, "avg_logprob": -0.1319640399963875, "compression_ratio": 1.9390862944162437, "no_speech_prob": 0.006097228731960058}, {"id": 460, "seek": 277360, "start": 2773.6, "end": 2781.52, "text": " So we get like a three to four. If, if I were to scan like, uh, uh, tomato emoji, um, and I", "tokens": [50364, 407, 321, 483, 411, 257, 1045, 281, 1451, 13, 759, 11, 498, 286, 645, 281, 11049, 411, 11, 2232, 11, 2232, 11, 9288, 31595, 11, 1105, 11, 293, 286, 50760], "temperature": 0.0, "avg_logprob": -0.1498708724975586, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.003172533819451928}, {"id": 461, "seek": 277360, "start": 2781.52, "end": 2785.92, "text": " don't know where to go back to mark point, if it found the end of paragraph, it considers it advanced", "tokens": [50760, 500, 380, 458, 689, 281, 352, 646, 281, 1491, 935, 11, 498, 309, 1352, 264, 917, 295, 18865, 11, 309, 33095, 309, 7339, 50980], "temperature": 0.0, "avg_logprob": -0.1498708724975586, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.003172533819451928}, {"id": 462, "seek": 277360, "start": 2785.92, "end": 2791.52, "text": " and no more go back to mark the point. You don't need to mark the point because the scan automatically", "tokens": [50980, 293, 572, 544, 352, 646, 281, 1491, 264, 935, 13, 509, 500, 380, 643, 281, 1491, 264, 935, 570, 264, 11049, 6772, 51260], "temperature": 0.0, "avg_logprob": -0.1498708724975586, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.003172533819451928}, {"id": 463, "seek": 277360, "start": 2791.52, "end": 2798.16, "text": " advanced it. Yeah. Because any of the scans that fail, I'm pretty sure I'm gonna have to go back", "tokens": [51260, 7339, 309, 13, 865, 13, 1436, 604, 295, 264, 35116, 300, 3061, 11, 286, 478, 1238, 988, 286, 478, 799, 362, 281, 352, 646, 51592], "temperature": 0.0, "avg_logprob": -0.1498708724975586, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.003172533819451928}, {"id": 464, "seek": 279816, "start": 2798.56, "end": 2805.12, "text": " but there, there are cases, uh, uh, yeah, I read that. I have that book. I wrote that years ago,", "tokens": [50384, 457, 456, 11, 456, 366, 3331, 11, 2232, 11, 2232, 11, 1338, 11, 286, 1401, 300, 13, 286, 362, 300, 1446, 13, 286, 4114, 300, 924, 2057, 11, 50712], "temperature": 0.0, "avg_logprob": -0.1207817049993985, "compression_ratio": 1.7835820895522387, "no_speech_prob": 0.008315234445035458}, {"id": 465, "seek": 279816, "start": 2805.12, "end": 2812.24, "text": " a couple of years ago. I have the PDF somewhere. Yeah, actually bought it. Uh, it's, there's that,", "tokens": [50712, 257, 1916, 295, 924, 2057, 13, 286, 362, 264, 17752, 4079, 13, 865, 11, 767, 4243, 309, 13, 4019, 11, 309, 311, 11, 456, 311, 300, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1207817049993985, "compression_ratio": 1.7835820895522387, "no_speech_prob": 0.008315234445035458}, {"id": 466, "seek": 279816, "start": 2812.24, "end": 2818.72, "text": " there's that one. There's two or three go scanners in the go code base. And then there's a website", "tokens": [51068, 456, 311, 300, 472, 13, 821, 311, 732, 420, 1045, 352, 795, 25792, 294, 264, 352, 3089, 3096, 13, 400, 550, 456, 311, 257, 3144, 51392], "temperature": 0.0, "avg_logprob": -0.1207817049993985, "compression_ratio": 1.7835820895522387, "no_speech_prob": 0.008315234445035458}, {"id": 467, "seek": 279816, "start": 2818.72, "end": 2822.56, "text": " that has right your own, uh, scanner and go. There's like, those are the three main things", "tokens": [51392, 300, 575, 558, 428, 1065, 11, 2232, 11, 30211, 293, 352, 13, 821, 311, 411, 11, 729, 366, 264, 1045, 2135, 721, 51584], "temperature": 0.0, "avg_logprob": -0.1207817049993985, "compression_ratio": 1.7835820895522387, "no_speech_prob": 0.008315234445035458}, {"id": 468, "seek": 279816, "start": 2822.56, "end": 2827.6, "text": " that I'd recommend if you want to start doing this kind of fun stuff. Um, but yeah, they're,", "tokens": [51584, 300, 286, 1116, 2748, 498, 291, 528, 281, 722, 884, 341, 733, 295, 1019, 1507, 13, 3301, 11, 457, 1338, 11, 436, 434, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1207817049993985, "compression_ratio": 1.7835820895522387, "no_speech_prob": 0.008315234445035458}, {"id": 469, "seek": 282760, "start": 2827.6, "end": 2833.52, "text": " they're pretty cool. Um, and you know, I'm obsessed with parsing. I'm not very good at it,", "tokens": [50364, 436, 434, 1238, 1627, 13, 3301, 11, 293, 291, 458, 11, 286, 478, 16923, 365, 21156, 278, 13, 286, 478, 406, 588, 665, 412, 309, 11, 50660], "temperature": 0.0, "avg_logprob": -0.15882374130132546, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.007344691548496485}, {"id": 470, "seek": 282760, "start": 2833.52, "end": 2839.44, "text": " but I'm obsessed with it. So, so anyway, um, mostly I'm obsessed with language and so", "tokens": [50660, 457, 286, 478, 16923, 365, 309, 13, 407, 11, 370, 4033, 11, 1105, 11, 5240, 286, 478, 16923, 365, 2856, 293, 370, 50956], "temperature": 0.0, "avg_logprob": -0.15882374130132546, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.007344691548496485}, {"id": 471, "seek": 282760, "start": 2840.24, "end": 2846.3199999999997, "text": " grammars are a part of language and that's why I like it so much. Um, this is something I don't", "tokens": [50996, 17570, 685, 366, 257, 644, 295, 2856, 293, 300, 311, 983, 286, 411, 309, 370, 709, 13, 3301, 11, 341, 307, 746, 286, 500, 380, 51300], "temperature": 0.0, "avg_logprob": -0.15882374130132546, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.007344691548496485}, {"id": 472, "seek": 282760, "start": 2846.3199999999997, "end": 2850.7999999999997, "text": " understand. What I want to do is I want to be able to specify my bonsai command lines from a pagan.", "tokens": [51300, 1223, 13, 708, 286, 528, 281, 360, 307, 286, 528, 281, 312, 1075, 281, 16500, 452, 33922, 1301, 5622, 3876, 490, 257, 38238, 13, 51524], "temperature": 0.0, "avg_logprob": -0.15882374130132546, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.007344691548496485}, {"id": 473, "seek": 282760, "start": 2850.7999999999997, "end": 2857.2, "text": " Wouldn't that be cool? Uh, there, there, there is a writing compilers. Oh really?", "tokens": [51524, 26291, 380, 300, 312, 1627, 30, 4019, 11, 456, 11, 456, 11, 456, 307, 257, 3579, 715, 388, 433, 13, 876, 534, 30, 51844], "temperature": 0.0, "avg_logprob": -0.15882374130132546, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.007344691548496485}, {"id": 474, "seek": 285760, "start": 2857.7599999999998, "end": 2864.72, "text": " Yeah. I have to go look at that one. Um, so, so yeah, I mean a compiler is the next step,", "tokens": [50372, 865, 13, 286, 362, 281, 352, 574, 412, 300, 472, 13, 3301, 11, 370, 11, 370, 1338, 11, 286, 914, 257, 31958, 307, 264, 958, 1823, 11, 50720], "temperature": 0.0, "avg_logprob": -0.13052517434825067, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.00047283852472901344}, {"id": 475, "seek": 285760, "start": 2864.72, "end": 2867.8399999999997, "text": " right? It's like bringing it all together and doing something with the thing you get out of it.", "tokens": [50720, 558, 30, 467, 311, 411, 5062, 309, 439, 1214, 293, 884, 746, 365, 264, 551, 291, 483, 484, 295, 309, 13, 50876], "temperature": 0.0, "avg_logprob": -0.13052517434825067, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.00047283852472901344}, {"id": 476, "seek": 285760, "start": 2867.8399999999997, "end": 2872.88, "text": " And we, we don't have any AST, any notions of AST going on yet. That is coming. Uh, I already", "tokens": [50876, 400, 321, 11, 321, 500, 380, 362, 604, 316, 6840, 11, 604, 35799, 295, 316, 6840, 516, 322, 1939, 13, 663, 307, 1348, 13, 4019, 11, 286, 1217, 51128], "temperature": 0.0, "avg_logprob": -0.13052517434825067, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.00047283852472901344}, {"id": 477, "seek": 285760, "start": 2872.88, "end": 2878.16, "text": " have all the data structures for that developed that I'm going to use for my AST. Um, and,", "tokens": [51128, 362, 439, 264, 1412, 9227, 337, 300, 4743, 300, 286, 478, 516, 281, 764, 337, 452, 316, 6840, 13, 3301, 11, 293, 11, 51392], "temperature": 0.0, "avg_logprob": -0.13052517434825067, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.00047283852472901344}, {"id": 478, "seek": 285760, "start": 2879.04, "end": 2884.0, "text": " but yeah. So, you know, you got to have push and pop for ASTs. It's like crazy. Um,", "tokens": [51436, 457, 1338, 13, 407, 11, 291, 458, 11, 291, 658, 281, 362, 2944, 293, 1665, 337, 316, 6840, 82, 13, 467, 311, 411, 3219, 13, 3301, 11, 51684], "temperature": 0.0, "avg_logprob": -0.13052517434825067, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.00047283852472901344}, {"id": 479, "seek": 288400, "start": 2884.32, "end": 2890.16, "text": " yeah. I mean the hardest part, the hardest part with the AST, and we're going to get into this,", "tokens": [50380, 1338, 13, 286, 914, 264, 13158, 644, 11, 264, 13158, 644, 365, 264, 316, 6840, 11, 293, 321, 434, 516, 281, 483, 666, 341, 11, 50672], "temperature": 0.0, "avg_logprob": -0.10265662783668154, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.0002868497103918344}, {"id": 480, "seek": 288400, "start": 2890.16, "end": 2899.2, "text": " is how to throw away, uh, elements of the tree that you, you can't just pop back and kind of,", "tokens": [50672, 307, 577, 281, 3507, 1314, 11, 2232, 11, 4959, 295, 264, 4230, 300, 291, 11, 291, 393, 380, 445, 1665, 646, 293, 733, 295, 11, 51124], "temperature": 0.0, "avg_logprob": -0.10265662783668154, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.0002868497103918344}, {"id": 481, "seek": 288400, "start": 2899.2, "end": 2903.84, "text": " you know, you can't just pop back to the latest bookmark when you're doing parsing because you", "tokens": [51124, 291, 458, 11, 291, 393, 380, 445, 1665, 646, 281, 264, 6792, 1446, 5638, 562, 291, 434, 884, 21156, 278, 570, 291, 51356], "temperature": 0.0, "avg_logprob": -0.10265662783668154, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.0002868497103918344}, {"id": 482, "seek": 288400, "start": 2903.84, "end": 2909.44, "text": " have all this data that you parse that you can't throw away. And it's very complicated. You can't", "tokens": [51356, 362, 439, 341, 1412, 300, 291, 48377, 300, 291, 393, 380, 3507, 1314, 13, 400, 309, 311, 588, 6179, 13, 509, 393, 380, 51636], "temperature": 0.0, "avg_logprob": -0.10265662783668154, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.0002868497103918344}, {"id": 483, "seek": 290944, "start": 2909.44, "end": 2914.4, "text": " throw it away because you don't know how much of it to throw away. And, and that's, that's going to", "tokens": [50364, 3507, 309, 1314, 570, 291, 500, 380, 458, 577, 709, 295, 309, 281, 3507, 1314, 13, 400, 11, 293, 300, 311, 11, 300, 311, 516, 281, 50612], "temperature": 0.0, "avg_logprob": -0.0987481809642217, "compression_ratio": 1.8059701492537314, "no_speech_prob": 0.039635542780160904}, {"id": 484, "seek": 290944, "start": 2914.4, "end": 2920.4, "text": " be a big piece of this that might, that might, you know, I still have other things to do. This", "tokens": [50612, 312, 257, 955, 2522, 295, 341, 300, 1062, 11, 300, 1062, 11, 291, 458, 11, 286, 920, 362, 661, 721, 281, 360, 13, 639, 50912], "temperature": 0.0, "avg_logprob": -0.0987481809642217, "compression_ratio": 1.8059701492537314, "no_speech_prob": 0.039635542780160904}, {"id": 485, "seek": 290944, "start": 2920.4, "end": 2927.28, "text": " isn't my main, my main thing. So, uh, but I, I am interested in this. Um, so far the test case on", "tokens": [50912, 1943, 380, 452, 2135, 11, 452, 2135, 551, 13, 407, 11, 2232, 11, 457, 286, 11, 286, 669, 3102, 294, 341, 13, 3301, 11, 370, 1400, 264, 1500, 1389, 322, 51256], "temperature": 0.0, "avg_logprob": -0.0987481809642217, "compression_ratio": 1.8059701492537314, "no_speech_prob": 0.039635542780160904}, {"id": 486, "seek": 290944, "start": 2927.28, "end": 2930.32, "text": " this is so good, so important that you have lots of test cases on this. I'm pretty sure this one", "tokens": [51256, 341, 307, 370, 665, 11, 370, 1021, 300, 291, 362, 3195, 295, 1500, 3331, 322, 341, 13, 286, 478, 1238, 988, 341, 472, 51408], "temperature": 0.0, "avg_logprob": -0.0987481809642217, "compression_ratio": 1.8059701492537314, "no_speech_prob": 0.039635542780160904}, {"id": 487, "seek": 290944, "start": 2930.32, "end": 2937.2000000000003, "text": " is good. Um, but I don't know, we'll go take a look at it later. And, and, and you know, that,", "tokens": [51408, 307, 665, 13, 3301, 11, 457, 286, 500, 380, 458, 11, 321, 603, 352, 747, 257, 574, 412, 309, 1780, 13, 400, 11, 293, 11, 293, 291, 458, 11, 300, 11, 51752], "temperature": 0.0, "avg_logprob": -0.0987481809642217, "compression_ratio": 1.8059701492537314, "no_speech_prob": 0.039635542780160904}, {"id": 488, "seek": 293720, "start": 2937.2, "end": 2942.3999999999996, "text": " but I, here's the thing, I don't want to have to keep revising all of my parsers. I wrote,", "tokens": [50364, 457, 286, 11, 510, 311, 264, 551, 11, 286, 500, 380, 528, 281, 362, 281, 1066, 3698, 3436, 439, 295, 452, 21156, 433, 13, 286, 4114, 11, 50624], "temperature": 0.0, "avg_logprob": -0.1705021077936346, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0029808487743139267}, {"id": 489, "seek": 293720, "start": 2943.2, "end": 2948.8799999999997, "text": " I mean, I, I, I'm going to go back and open up my old pagan, uh, dev, uh,", "tokens": [50664, 286, 914, 11, 286, 11, 286, 11, 286, 478, 516, 281, 352, 646, 293, 1269, 493, 452, 1331, 38238, 11, 2232, 11, 1905, 11, 2232, 11, 50948], "temperature": 0.0, "avg_logprob": -0.1705021077936346, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0029808487743139267}, {"id": 490, "seek": 293720, "start": 2949.68, "end": 2955.52, "text": " you know, I wrote an entire recursive descent parser for the pagan language itself, if I have them.", "tokens": [50988, 291, 458, 11, 286, 4114, 364, 2302, 20560, 488, 23475, 21156, 260, 337, 264, 38238, 2856, 2564, 11, 498, 286, 362, 552, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1705021077936346, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0029808487743139267}, {"id": 491, "seek": 293720, "start": 2956.56, "end": 2964.8799999999997, "text": " Uh, and so that's going to be something that we're going to come up with later, but, um,", "tokens": [51332, 4019, 11, 293, 370, 300, 311, 516, 281, 312, 746, 300, 321, 434, 516, 281, 808, 493, 365, 1780, 11, 457, 11, 1105, 11, 51748], "temperature": 0.0, "avg_logprob": -0.1705021077936346, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0029808487743139267}, {"id": 492, "seek": 296488, "start": 2965.6800000000003, "end": 2968.6400000000003, "text": " but, but so I don't, I don't, I don't know, I don't know how that's going to,", "tokens": [50404, 457, 11, 457, 370, 286, 500, 380, 11, 286, 500, 380, 11, 286, 500, 380, 458, 11, 286, 500, 380, 458, 577, 300, 311, 516, 281, 11, 50552], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 493, "seek": 296488, "start": 2968.6400000000003, "end": 2972.96, "text": " that's going to end up going down. Uh, because I, I want to be able to pull out some of that", "tokens": [50552, 300, 311, 516, 281, 917, 493, 516, 760, 13, 4019, 11, 570, 286, 11, 286, 528, 281, 312, 1075, 281, 2235, 484, 512, 295, 300, 50768], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 494, "seek": 296488, "start": 2972.96, "end": 2976.4, "text": " stuff from here and just reuse it because I, I've already got all the algorithms there and I can", "tokens": [50768, 1507, 490, 510, 293, 445, 26225, 309, 570, 286, 11, 286, 600, 1217, 658, 439, 264, 14642, 456, 293, 286, 393, 50940], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 495, "seek": 296488, "start": 2976.4, "end": 2982.08, "text": " just reuse those algorithms. So that's pretty much it for YouTube. So if you want to stay tuned and", "tokens": [50940, 445, 26225, 729, 14642, 13, 407, 300, 311, 1238, 709, 309, 337, 3088, 13, 407, 498, 291, 528, 281, 1754, 10870, 293, 51224], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 496, "seek": 296488, "start": 2982.08, "end": 2985.92, "text": " to watch stuff about the pagan and keg stuff, uh, I'm probably not going to be working on much of", "tokens": [51224, 281, 1159, 1507, 466, 264, 38238, 293, 803, 70, 1507, 11, 2232, 11, 286, 478, 1391, 406, 516, 281, 312, 1364, 322, 709, 295, 51416], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 497, "seek": 296488, "start": 2985.92, "end": 2991.2000000000003, "text": " this. I hopefully not the rest of this week. I have got a ton of work to catch up on, uh, that", "tokens": [51416, 341, 13, 286, 4696, 406, 264, 1472, 295, 341, 1243, 13, 286, 362, 658, 257, 2952, 295, 589, 281, 3745, 493, 322, 11, 2232, 11, 300, 51680], "temperature": 0.0, "avg_logprob": -0.0949090081940657, "compression_ratio": 1.9243986254295533, "no_speech_prob": 0.005729606840759516}, {"id": 498, "seek": 299120, "start": 2991.2, "end": 2997.6, "text": " I'll be doing like for the rest of tonight and tomorrow morning early and, um, and we'll be,", "tokens": [50364, 286, 603, 312, 884, 411, 337, 264, 1472, 295, 4440, 293, 4153, 2446, 2440, 293, 11, 1105, 11, 293, 321, 603, 312, 11, 50684], "temperature": 0.0, "avg_logprob": -0.13656205071343316, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.020961076021194458}, {"id": 499, "seek": 299120, "start": 2997.6, "end": 3004.3199999999997, "text": " yeah, I'm going to be doing, you know, a lot of that stuff. Um, but this is sort of related to", "tokens": [50684, 1338, 11, 286, 478, 516, 281, 312, 884, 11, 291, 458, 11, 257, 688, 295, 300, 1507, 13, 3301, 11, 457, 341, 307, 1333, 295, 4077, 281, 51020], "temperature": 0.0, "avg_logprob": -0.13656205071343316, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.020961076021194458}, {"id": 500, "seek": 299120, "start": 3004.3199999999997, "end": 3008.0, "text": " stuff we want to do at work in terms of like documentation validation. That's where it", "tokens": [51020, 1507, 321, 528, 281, 360, 412, 589, 294, 2115, 295, 411, 14333, 24071, 13, 663, 311, 689, 309, 51204], "temperature": 0.0, "avg_logprob": -0.13656205071343316, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.020961076021194458}, {"id": 501, "seek": 299120, "start": 3008.0, "end": 3011.7599999999998, "text": " came from originally. And that's, if you want to stay tuned, we, we'll do some more of that. I,", "tokens": [51204, 1361, 490, 7993, 13, 400, 300, 311, 11, 498, 291, 528, 281, 1754, 10870, 11, 321, 11, 321, 603, 360, 512, 544, 295, 300, 13, 286, 11, 51392], "temperature": 0.0, "avg_logprob": -0.13656205071343316, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.020961076021194458}, {"id": 502, "seek": 299120, "start": 3011.7599999999998, "end": 3018.48, "text": " I am going to implement basic and D M D is, uh, as a, as a grammar and I'm going to be using this", "tokens": [51392, 286, 669, 516, 281, 4445, 3875, 293, 413, 376, 413, 307, 11, 2232, 11, 382, 257, 11, 382, 257, 22317, 293, 286, 478, 516, 281, 312, 1228, 341, 51728], "temperature": 0.0, "avg_logprob": -0.13656205071343316, "compression_ratio": 1.7080291970802919, "no_speech_prob": 0.020961076021194458}, {"id": 503, "seek": 301848, "start": 3018.48, "end": 3023.76, "text": " and we should get pretty high performance on it actually. Uh, we should have performance that", "tokens": [50364, 293, 321, 820, 483, 1238, 1090, 3389, 322, 309, 767, 13, 4019, 11, 321, 820, 362, 3389, 300, 50628], "temperature": 0.0, "avg_logprob": -0.09781462947527568, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03161303699016571}, {"id": 504, "seek": 301848, "start": 3023.76, "end": 3030.08, "text": " rivals gold mark, uh, which because it doesn't have as much to do. Uh, so we should have performance", "tokens": [50628, 33303, 3821, 1491, 11, 2232, 11, 597, 570, 309, 1177, 380, 362, 382, 709, 281, 360, 13, 4019, 11, 370, 321, 820, 362, 3389, 50944], "temperature": 0.0, "avg_logprob": -0.09781462947527568, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03161303699016571}, {"id": 505, "seek": 301848, "start": 3030.08, "end": 3035.2, "text": " that rivals gold mark, which is pretty much the go to standard for, uh, markdown parsing and go", "tokens": [50944, 300, 33303, 3821, 1491, 11, 597, 307, 1238, 709, 264, 352, 281, 3832, 337, 11, 2232, 11, 1491, 5093, 21156, 278, 293, 352, 51200], "temperature": 0.0, "avg_logprob": -0.09781462947527568, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03161303699016571}, {"id": 506, "seek": 301848, "start": 3035.2, "end": 3039.36, "text": " right now. And we'll be able to compare and do some benchmarks on that a little bit later.", "tokens": [51200, 558, 586, 13, 400, 321, 603, 312, 1075, 281, 6794, 293, 360, 512, 43751, 322, 300, 257, 707, 857, 1780, 13, 51408], "temperature": 0.0, "avg_logprob": -0.09781462947527568, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03161303699016571}, {"id": 507, "seek": 303936, "start": 3039.36, "end": 3051.2000000000003, "text": " Um, so have fun parsing and come on by sometime. Talk to you later.", "tokens": [50404, 3301, 11, 370, 362, 1019, 21156, 278, 293, 808, 322, 538, 15053, 13, 8780, 281, 291, 1780, 13, 50956], "temperature": 0.0, "avg_logprob": -0.3213225319271996, "compression_ratio": 0.9436619718309859, "no_speech_prob": 0.05581080913543701}], "language": "en"}