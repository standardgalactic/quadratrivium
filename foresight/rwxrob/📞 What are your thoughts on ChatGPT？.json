{"text": " to start recording. What are your thoughts on chat, GPT? So here's the thing. Why? That's what I have to say. Why are people interested in this? I just don't get it. I just don't get it. I have watched all this stuff. I don't understand what its purpose is. Personally, I mean, let's go back and read it, okay? So it says here, chat GPT is a prototype artificial intelligence chat bot. Join the club. I mean, how many other chat bots have we had? Okay, so maybe this was not going to become like a masochistic, narcissistic Nazi like the Twitter bot before. This is apparently really polite. I'm sure they trained it to be really, really polite. Apparently it's really, really polite. I was scrolling through a thing and it said, the most polite, clueless bot you'll ever see. If it's wrong, at least it's wrong politely. Hopefully it focuses on usability and dialogue. The chat bot uses a large language model trained with reinforcement learning and it's based on GPT 3.5 architecture. It's also beta, by the way. It's not final, right? It's an open prototype, not finished. How about that? So I'll put that there. Look, if you want to use it, that's fine. I am not going to judge you. I just think it's a waste of time. So many things are a waste of time today. And to me, that's a waste of time. Chat bot uses like, it says here chat GPT was launched in November, 2022 and is garnered attention as its detailed responses and well-reasoned answers, although its accuracy has been criticized. Well-reasoned wrong answers. And people are like, I mean, there was an entire article that came across my feed. It was like, oh, this is the end of essays as we know them. It's had GPT, GPT going to destroy, you know, scholastic achievement through essay writing and stuff. I'm like, no, it's not. It's not. It's not. I mean, it might help you a little bit. It's like, it's all of these chat bot things, including the coding one, all they really are is they're catering to people who are copy pasta people, copy pasta people, the people who don't do any original thinking who go out and they want to use this thing like, oh, that's cool. They don't actually validate that it's true. Now, if they did, if they did, if they did, if they did, then it could be a nice suggestion, right? And I think that's fine. And it's not just because I'm old that I don't like it. It's because it's inaccurate and it's dangerous to trust an AI that you're not backing up with personal experience. This is, do I have to, I mean, how many fictional sci-fies have there been? This is part of the evolution of AI, right? I mean, there was a time, there was a time when if you were to hear a computer-generated voice, you would go, what the hell did they say? And now you can't even tell the difference between computer-generated voices. So it's going in the right direction. I don't have any problem with that. And it needs to go in the right direction. But right now, why are you wasting time on it? And there's an unusually large number of people coming at me with this. What do you think of Chad GPT? Who are college students? And I had one person in here, I'm gonna get them out of me. I think they're in here right now, actually. Please don't get mad. But they said, all I can say is it took what was otherwise a three-hour assignment and turned it into 30 minutes. That's exactly, that's almost word for word what they said. And I'm thinking to myself, how is that possible? How is that possible that this thing, whether, and I don't know the assignment, I think it was a coding assignment, that this thing can, oh wow, there's a good one. I've come up with a set of rules that describe, ooh, very cool, a code on a tech rail, ooh, we'll have to go look at that one, Kima. Yeah, that's very cool. So the point is, if it was taking you three hours to do an assignment, whatever it was before, and it's now taking you 30 minutes because you have a chatbot that's helping you out, there's something wrong. I mean, there's something wrong. You're either not learning it, not learning it properly, or, I mean, there's an outside chance that it's doing the grunt work for you and that you're still doing the learning and it's filling in all the blanks and everything that it would take you longer to type, especially if you're like a slow typer or something. And I suppose there's a certain number of people who are slow typers who can't compose thoughts very easily and it helps them put the language together and it's like, yeah, okay, that sounds right. I, this, my fear with any of these AI things is just like any other fear is it's like, they're gonna make us soft. You know, and that's been something that old people have been saying, you know, just the dawn of time. There were people who didn't wanna get on railroad trains because they thought it was too fast and everybody was gonna die. A lot of people did die, by the way. And there's actually in Arizona, we opened a geocache there where there were two trains that were on the same track and there was, you know, hundreds of hundred people radically destroyed in an instant when they're two cranes collided at head. So there are definitely concerns about these things as they come out and, you know, should we be doing it? I was like, yes, we should be definitely trying them out and experimenting and stuff like that, but to what extent? I mean, you know, if, honestly, this chat, I don't know about the coding one. This is just a chat bot, right? But the coding one, which is kind of related in conversation, that one will get you fired from a company if they find out if they're using it. Not just because you don't know what you're doing, but because it's been trained on proprietary source code that has a indeterminate legal pedigree. And nobody likes to talk about this. They all like to talk about how cool, you know, open AI chat is, I mean, this is a different company, right? That was the Microsoft thing. It's the code, whatever, I forget the name of it. But if you're using that, you're actually taking your career in your own hands and I wouldn't tell anybody you are. And I think to a lesser degree, the chat GPT thing is the same thing. If you, let's say, for example, let's say for example, that you save three hours on an essay assignment by using chat GPT, yeah, they'll work out the legal issues the tech is too powerful not to use. I don't think that's true at all. I must say, I know you're a huge AI fan and I am not, I am not a fan of it at all. To me, it's just copy, past, past on steroids. That's all it is. And so what it's causing is it's causing a bunch of people to not learn shit and that's fine. And this, I mean, I've said it before, I predicted that everybody should be learning AI and how to train models properly because if this is a step in the right direction where the number of people are gonna be doing actual programming is gonna go down. And there's a story I tell about this that is related to this because the way that AIs are trained, including this one that I've been slamming on, the way that they're trained is organic. It's closer to how nature does things than the algorithmic models. And I have a story about this I wanna tell really quick. Imagine an AI tutor that can teach kids in third-world countries. Wrongly, he'll turn them into white supremacists even though they're in Africa. I mean, if it was a Twitter bot, that's what it would do. Look, we're getting there. We're getting there, we're just not there, right? So, that's what I'm saying. Better than what we have right now, which is nothing. Well, I mean, it's like there's societal ills out there to look at. I'm not anti-AI, I'm just like, I'm like, so on the one hand, I do think we need to learn how to train models properly. I just watched a huge conference. I almost gave up where I work. There was this huge, huge conference, a whole day conference about AI at the place that I work. And it's crazy, it's crazy. In fact, the whole future of AI and the focus of it is not even on writing code, it's on the data. It's on, and they went through a bunch of examples of how they were sampling the data and increasing the data samples so that they were good because the higher the quality and then put data, the higher the quality of AI. And you should see the AI's that haven't, I wish I could talk about it. The AI that is going down, because people may not know, I support a machine learning group. I do the SRE and the Kubernetes stuff and some of the REST API development for, to support high performance computing machine learning group and one of the biggest companies in the entire world who's radically making radical advantage, taking radical advantage of AI and data. And it's absolutely amazing. And they have their own, they're so big, they have actually, they have their annual conference on it. And I was just there. And it's absolutely phenomenally awesome. So either I'm gonna go camping over the week, over the Christmas break, I'm actually gonna start sticking my finger into AI and learning some of the, doing some Kaggle stuff and learning, if you're not learning how to do data science and this kind of thing and all you're focused on is algorithmic programming and stuff, I mean, you should see how long it takes me. Have you seen, I mean, it takes me forever to just do basic parsing of a string or something like that. I mean, I'm relatively fast, but the amount of time it takes to write code compared to the amount of time that it takes organically to train a model and to get the data in place and then let that thing write the code is substantial. And you know, Masi and others here are saying that, they're like, this is too powerful for it to not take over. And the chat GPT is not directly related to the coding thing, but it's the same idea. The idea is it'll do the thinking for you and it'll write your essay for you. And so, I mean, that's, I just, on the one side it's good, on the other side it's really bad. So let me tell you a story about the good stuff, okay? So there, I would give anything for the reference to this yet. I read this in 2014, I think it was. And I was studying this philosophical difference between algorithmic approaches to solutions and natural organic solutions. And the specific example was, and I've told the story before, but the specific example was a cam. You know what a cam is, right? It was a cam, like a camshaft in a car, but it wasn't a car, it was a factory. It was a factory in New England someplace in the Northeast. And, you know, back, you know, where there's a lot of manufacturing going. And then the story goes that they, I wish I could find, if anybody can find it, please give me a reference. But the device broke down. And so the production line was down. And this is a production line that was, you know, core of the business and they were losing all this money. And well, every day it was down, they were losing money. And this cam, it was this very complicated mechanical process that had to be done exactly that way, had been created somewhat organically and it had been tailored and it had been shaved off and everything. And so they had to, you know, they wanted this very unique cam was the core. It was the heart of everything on the assembly line and they couldn't recreate it. And so they hired, they paid all of this money to all of these people to do, to fix it. They brought in theorists, they brought in the Beth Mathematicians, you know, and they said, okay, hey, let's, you know, and they designed lots of failures. So they would put together all these amazing things and then they didn't work. They just didn't work because they weren't organic enough. They weren't natural enough. So then they brought in another team and I don't remember the specifics of the team, but this team did the same thing. They recreated the process that was used to create the first cam. And it took them longer to do all the stuff, but it actually worked. And what they did is they started with something that was the best approximation of, you know, that they could come up with and they used this stuff from, you know, the other mathematicians that people had given them and they put that in there and then they ran it for a while and then they would go in and then they would shave, they had the machinist and they would shave off part of it and then they would run it again and then they would shave off a little bit more and they would run it again. And then it was, so it was this fail faster idea, right? And that idea of adjusting for failure and training a device, that's exactly how machine learning works. So as I understand it. So having that, you know, and that got them the solution that they wanted to. And that process of natural learning that went on, I mean, natural learning has got a very specific meaning in the AI world. And that's, I'm sorry, natural intelligence, not natural learning, natural intelligence is the goal. Natural intelligence is when the intelligence is self-aware and everything and there's a lot of debate about whether that'll ever be a thing. But the point of it was that the organic approach, you know, fail and adjust, fail and fix, fail and fix, fail and fix is what got them the solution. And no amount of programming and algorithm at thinking is in the best minds could get it. It had to be incrementally done. And I really appreciate that story because that's how I do most things. I'm a very practical guy. I have a hard time, I mean, I can visualize certain things, but when it comes to like lead code algorithms and stuff like that, I don't really do well with them. But if I can see it working, I can modify what's working and get it to the point where it's working. And then if I just look at all the code, I'm like, okay, I understand how this code's working because I tweaked it all along the way. And sometimes there's a refactor along the way in there too, because, you know, like, hey, you know, this is not as efficient as it could be. But, you know, it's avoiding the premature optimization kind of thing, general intelligence. Yes, that's what I was looking for. That's three body problem. And yeah, that's the one I was looking for. So, you know, these things are all super fascinating. Chat, GPT is a part of it. It's definitely a thing that I think needs to exist. I just feel like so many people are like freaking out about it right now. And I have to ask myself, isn't there something better you could be doing with your time? But that's not my business, do what you want with your time. I mean, I waste my time plenty good. So, you know, if you want to play around, then fine. I don't, I don't. I have no intention of doing it. If I could train my own chatbot, which I am interested in doing, my goal with AI is to create my, you know how they say second brain, right? Second brain is another word for Zettlecasten. So I have, I've now, I'm up to like 1800 content nodes, knowledge nodes in my current Zettlecasten. I have three other knowledge bases that have over a thousand content nodes in each of them. And I am in the process of bringing all of those over. So it's like almost everything that I've ever written about. And once I get all of that content in one place, I really want to see how I could put some machine learning algorithmic stuff, not machine algorithms, but I want to see if I could build some machine learning into my own data stuff, right? And then, and then of course the extension of this is that, you know, the exchange grid, the knowledge exchange grid, once I can get, so let's say, let's say that I have, I know, text pregeneration, stuff like that, right? So I'm already doing templates and stuff, but I mean, it's very possible that I could do the template generation automatically through AI. But something else that's interesting that interests me is that, is that's just my corpus, right? I just have my data, my Zettlecasten, but the goal, and then we're probably like five years out on this, is to eventually be able to follow multiple other people and have a cash copy of their Zettlecasten with me as well. And, you know, you take that to the nth degree, if I've got a thousand people, and there are people that I personally have curated, my ring of trust about knowledge and that stuff, now I've created a corpus of data that's extremely compelling when it comes to not just searching, but making suggestions. And then, then we could put, is that what they call it, chat by utility? Yeah, and then I would put on top of that, I would start to layer in the AI, and then I could have the AI suggest things to me, or when I start writing about something, I would love to have another T-Mex window open that's like, dude, you've already talked about this over here, and here, and here, and here, here's the other thing, and have it dynamically see, not just from the keywords that I'm using, which is, you know, a start, but I wanted to see, well, you know, you've written similarly to this, or somebody has written similarly to this, you know, and you see this kind of thing already in like, trouble ticket issues, and stuff like that, that we submit to GitHub, or anything like that, you know, you start typing things like, are you sure it's not this problem right here, right? So there's already, you know, code to do this, and that's kind of the, you know, phase two of the whole keg thing, you know, phase one is to get the knowledge, you know, really stable and collectible, and phase two is kind of exchange it, I guess it's apparently phase three, phase three would be processing the data, that would be processing all the knowledge, it's not going to fall about it. They did it for the reason of spam, yeah, I mean, yeah, I just would never want to put it, I mean, it's bad enough having a chat bot, you know, do one thing, the hardest part about all of this is going to be being able to determine who's real, and that's already becoming a thing, right? I mean, I imagine there's a lot of like, you know, porn and cheating sites that are going to love these, these AIs, because they're just going to be the best, you know, pretend girls ever, yeah, NPCs will be awesome, yeah, has apps now that check for secrets, check for dependency security flaws, yeah, yeah. Yeah, and there's like, there's chat, yeah, I mean, all of those sorts of things are stuff that I definitely want to add in. So I'm not, it's not that I'm against chat bots, I'm definitely adding a chat bot, I've already started adding a Twitch chat bot, which what I want it to do is like, you know, I have all these commands, right? But I hate maintaining the commands, so what I would rather have my chat bot do, my Twitch chat bot, what I would rather have it do is I would rather have it become intimately familiar with my Zettelkasten, right? So if somebody starts chatting about something, and Masi's already made some really amazing stuff on this level, if somebody starts chatting about something, I want my chat bot to score potentially a response and say, okay, somebody's talking like this, somebody used a question mark, somebody's doing whatever. And he'll say, if you're asking about this, this is what I was trying to do, right? So I would really love to be able to create kind of a proactive customer service-like bot in my Twitch that answers all of the mundane questions for me without people having to go to the commands, right? I mean, they go to the commands and then they have to filter through the commands and they have to find the right one, and sometimes they do and there's kind of a path through there, but I have to maintain all of that. And maintaining the commands, I actually was looking at it, I've got like 200, 300 commands. Yeah, if I train it on my Zett as my corp, yeah, then I would be, so then somebody asks a question and all I have to do is write. I don't have to go in and create all the interlinking and stuff like that inside of a specific, commands database. I just maintain my Zodacast and answer questions just like I'm doing right now, and then I include links to YouTube and stuff like that. And the links are identifiable because they've got the YouTube emoji on them. So my chat bot could be intelligent and say, hey, well, there's actually these YouTube videos on this too. And it could proactively engage with anybody in my chat while I'm writing and doing the work. And then I, I mean, it might not be as personal, but it could be very valuable. I think that personal broadcasting, as we do it now on this coworking kind of thing, is going to progress. I think, yeah, take care. It's, I think that this is one of those things that is going to progress and it's gonna become more valuable. Right now it's just kind of a fascination. But the day that I can point a chat GPT at my Zodacast and have it automatically train itself and get 90% accuracy on when to participate in my chat and about answering questions on my behalf as an AI, that's the time when I will become extremely interested in it. I will become extremely interested in it because then it's saving me time. That's what AI potentially could do. And, you know, somebody mentioned the teaching thing. I think there's another, I understand chat GPT is a subset of instructional GPT. Did you guys read about that? So there's another GPT. It's like, I think it's called instruction GPT. It's actually designed for training and teaching and stuff like that, more than just a random chat one. The random chat one is to get, you know, people's interest and stuff. So that actually does, does, is interesting to me. I think teaching is fine. I think that there, yeah, if there was some way to have it correct. So that's kind of, I mean, the thing of it, mostly that would be really cool is if you had a bot that was running, right? So if you had a bot that was running, it was trained off of your corpus and Zodacast then, it could chime in every once in a while and maybe it would get things wrong. It would say, well, that's not really the right answer there. Here's the right answer. And then it could take its correction, add it to its algorithm and say, so that whole thing that you have to do with AI, where you have to constantly correct it when it gets stuff wrong, right? But it learns. Every time it gets something wrong in a chat, we could laugh about it and I could correct it and then it would get that answer right next time. And then we could just keep going like that, you know what I mean? And it could try really hard and I could just kind of train it along with everybody else while I'm not here. So the idea of setting up like a SkiZix, so I used to name my bot, an interactive bot that dynamically learns by attempting to answer popular, frequent, unasked questions and getting them wrong and having it be corrected, that's like crazy, crazy compelling for me. And that's just from a customer service perspective, but from an educational perspective and all that. Now, if you're gonna start asking my bot about everything and putting that in your essay, I don't know how I feel about that. Maybe it's just making searching efficient. I mean, I say that all the time. I say if you wanna be in good in tech, you gotta be a really good researcher, be able to search fast. Well, if you have a bot that's doing all the searching for you all the time and you're just asking your bot about that's more likely to get the right answer, then, you know, as it takes four gigabytes of GP RAM to train these modern models, really. Yeah, well, there's a lot of them, yeah. Yeah, I don't know. It'd be interesting to see how much I could do. I mean, I do have my thing over here. So, I'm trying to figure out how much I could actually do that, it'd have to have a lot of data too, right? So, oh no, no, that would not be a thing to get, yes. So, that's my opinion on it. Yeah, I'm kind of underwhelmed with it, but I know that it's going in the right direction. I guess I'm kind of annoyed because everybody's asking me about it. And I'm like, well, what are you using it for? And every time I ask what they're using it for, it's, well, it's making me do my homework faster. And I'm like, oh my God, it's like, but I don't know if that's bad. I think it's bad. I think it's bad because people are not doing their own research. It's one of two things. They're either not doing their own research or it's facilitating their research, right? If it's the second, then I'm all for that. I mean, the terminal makes you faster during your own research, so why not an AI? So, you know, if you shut learning, yeah. So, I think that's it. I mean, I don't have any inclination to play with it. I got too many other things to make right now, but as I said, if it were gonna make my Twitch bot more intelligent so that it could help people learn more quickly and save me some time, then that's a good thing. That's a good thing. So, I'll try to keep my thoughts open on that, but Project Matters and Ceaseless are on board. It will replace jobs. Then I'm fine with it, use it as an education. They can't have it, just won't want it. Why would they have it replace jobs? I don't understand that statement at all. I've heard that before. This chat bot is no word near replacing anyone. I mean, even the people who operated the front desk like the place that took my piss for my drug test. Even they are not replaceable yet by this. I mean, I just, I don't see it being that reliable. And they were pretty damn bad. I don't even want to talk about it. Oh, I'm sorry, as you're here at 3.58, at 12.58 and not one o'clock, you need to wait until one o'clock. Really? I just don't even want to. It's a different thing completely. I just had to go through. I had to wait in line for like two hours to get a drug test. My phone died. I had to come back the next day and wait again for two hours. See, any of those things that could be improved by AI, I'm down. I'm down. I'm down with those things being approved. Corporations are going to use it eventually and people should use it as well as benefit them. Yeah, for sure. Teachers are next. At least the current way of teaching. Well, I think the current way of teaching is totally broken. So I am all about having... I am all about the education getting disrupted by AI. And it's not completely untrue that the way that education is happening now could be taken over by an AI, absolutely. Absolutely. It's like, okay, I'm gonna tell you about a topic in general and I'm gonna sit here and blah, blah, blah. And you're gonna take notes and there's no ability for us to interact except for off hours. And then you get like an hour possibly with a TA. You know, the entire model for modern education is totally broken. It's totally broken. And it could easily be replaced by AI. I completely agree with that. But if you take the true learning model, the Art of Ex thing that we talked about, then where you're failing faster and you're being organic and you have a one-on-one mentor who knows you personally, I think we're a ways from that. I do think that AI could get there. I think that AI could have a strong chance at learning about you and learning about your interests and learning about what you struggle with and learning. I think those things for education could be really cool. I mean, think about that. That you could have an AI that becomes trained on your regular failures. So maybe you're learning a foreign language and you get imperative declension wrong in Russian all the time. It's like the thing, it's constantly doing the assessments and everything that a teacher would be doing and then never doing anything, just giving you an F, right? It would be adapting and saying, hey, okay, I know you have trouble with this one thing, so I'm gonna give you more of these things. So the potential to have AI adapt to our weaknesses as we're learning, maybe we don't remember things very well. That would be me, right? So it would be more about repetition. I think that there's a tremendous potential there for that, I really do. Intermediate with video graphics, not just text. So whole learning path, focus on the way of learning with custom graphics to explain, yeah. Well, and that's another thing too. I mean, there's a book out there called Multiple Intelligences and it talks about all the different ways that we learn. Thomas, what's his name, Sir Ken. Sir Ken talks about this. The woman who created the Juilliard Academy failed. She failed out of all her classes and they took her to a specialist and she was moving around and the specialist said to the parents, look at her. And she goes, what? And he goes, she has to be moving. They got her in a special school that was dynamic for dynamic learners who were walking around, had to be moving to learning. And she excelled. She excelled so much, she made the most, she made Juilliard Academy out of it. If they had written her off because of her learning style, and that is one way that AI can adapt. I mean, everybody knows a teacher, the best teachers in the world are the ones who are able to adapt to the individual peak. Students, right? And there's tons and tons of horrible teachers who don't adapt at all. They stay in their methods, they do their thing. It's like you adapt to them or you die and get an F and you have to take it over again and spend all the money. There's plenty of that. But if you, so the good teachers who adapt and make things engaging and change their methods or allow God forbid one student to do one project that's different than another student because of the way that they learn. I mean, how do you set up a rubric for that? You can't. But if you have an AI, maybe an AI kind of thing is gonna get us into this closer to one-on-one education, which is the holy grail. One-on-one education has been the way humans have been learning best since the dawn of time. There's overwhelming evidence of this, but nobody accepts that evidence because it's too impractical to do. At least they say, I don't think it is. I think that if they were to actually economically, I think they can make it work, but they don't. And in order to make it work, you'd have to have mentors adapted to a different, I mean, when you had back in the old days, it was like one-on-one and if that pairing didn't work, you would find a different guru or a different master and you would go to that person. You would go to one person for their mastery in this thing and another person in a mastery in this thing. That's true education. And that's not happening in the traditional system, but AI could potentially do it. AI could potentially do it, it could. Yeah, reviews on game writers versus 10 years ago. Oh yeah, yes. Yeah, based on consensus. Well, I think one of the things that individual instruction like that is going to get both. This is something interesting about what I want to say here. Homeschooling. So that's, okay, so I live in the South, right? I live in North Carolina. And ironically, there's extreme agreement between very, very right-wing conservatives and very, very leftist progressives on this topic of homeschooling. Now, I don't know if that's a good thing or a bad thing, but they agree that the current system does not meet their needs. Now, the one people agree because they don't think mathematics and science are a priority and that faith in Jesus is all that matters. I was told that to my face when my son was denied access to such a school because he didn't have enough belief in Jesus according to their method, because we were Mormon. That's a true story. But they had, we thought more direct instruction would be better, but it turns out, no. They literally told us math and sciences are secondary to faith in Jesus. And we're like, okay, we'll be moving on now. And then you have the other people who are all about the mass and the sciences and playing in mud and stuff like that in kind of the hippie education. And believe it or not, so believe it or not, those two camps both want the same thing. They want the government to get out of the way when it comes to education because they believe that education can't be done properly through any kind of singularly interested association and all the problems that are coming up in education are all related to this thing. I just don't know if it's a good thing or bad thing to let people even get more in their sandbox. I mean, I think, I don't know. I don't know, it's a really divisive topic. Interested both South Carolina power stations have been talking this week. Oh, I know. I know, I was here. Dude, I saw it. I don't want to talk about it right now. We can talk about that at a different time. No, they confirmed it was an act of terrorism in our state. So we're Ireland now. Yeah, it's in my state. I'm seeing it on the news all the time. It's not even far away. Yeah, so we are Ireland. America is officially Ireland. We're getting attacked by domestic terrorists. They took out our power grid for two days. Yep, let's talk about that another time. I don't know if AI is gonna help with that.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.02, "text": " to start recording.", "tokens": [50364, 281, 722, 6613, 13, 50465], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 1, "seek": 0, "start": 2.02, "end": 3.72, "text": " What are your thoughts on chat, GPT?", "tokens": [50465, 708, 366, 428, 4598, 322, 5081, 11, 26039, 51, 30, 50550], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 2, "seek": 0, "start": 5.5200000000000005, "end": 7.640000000000001, "text": " So here's the thing.", "tokens": [50640, 407, 510, 311, 264, 551, 13, 50746], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 3, "seek": 0, "start": 9.72, "end": 10.56, "text": " Why?", "tokens": [50850, 1545, 30, 50892], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 4, "seek": 0, "start": 12.8, "end": 14.56, "text": " That's what I have to say.", "tokens": [51004, 663, 311, 437, 286, 362, 281, 584, 13, 51092], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 5, "seek": 0, "start": 14.56, "end": 19.56, "text": " Why are people interested in this?", "tokens": [51092, 1545, 366, 561, 3102, 294, 341, 30, 51342], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 6, "seek": 0, "start": 23.44, "end": 25.12, "text": " I just don't get it.", "tokens": [51536, 286, 445, 500, 380, 483, 309, 13, 51620], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 7, "seek": 0, "start": 25.12, "end": 26.32, "text": " I just don't get it.", "tokens": [51620, 286, 445, 500, 380, 483, 309, 13, 51680], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 8, "seek": 0, "start": 26.32, "end": 28.240000000000002, "text": " I have watched all this stuff.", "tokens": [51680, 286, 362, 6337, 439, 341, 1507, 13, 51776], "temperature": 0.0, "avg_logprob": -0.28695434179061496, "compression_ratio": 1.4662162162162162, "no_speech_prob": 0.023318616673350334}, {"id": 9, "seek": 2824, "start": 29.24, "end": 32.879999999999995, "text": " I don't understand what its purpose is.", "tokens": [50414, 286, 500, 380, 1223, 437, 1080, 4334, 307, 13, 50596], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 10, "seek": 2824, "start": 32.879999999999995, "end": 35.04, "text": " Personally, I mean, let's go back and read it, okay?", "tokens": [50596, 21079, 11, 286, 914, 11, 718, 311, 352, 646, 293, 1401, 309, 11, 1392, 30, 50704], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 11, "seek": 2824, "start": 35.04, "end": 35.879999999999995, "text": " So it says here,", "tokens": [50704, 407, 309, 1619, 510, 11, 50746], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 12, "seek": 2824, "start": 35.879999999999995, "end": 39.4, "text": " chat GPT is a prototype artificial intelligence chat bot.", "tokens": [50746, 5081, 26039, 51, 307, 257, 19475, 11677, 7599, 5081, 10592, 13, 50922], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 13, "seek": 2824, "start": 39.4, "end": 40.36, "text": " Join the club.", "tokens": [50922, 19642, 264, 6482, 13, 50970], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 14, "seek": 2824, "start": 40.36, "end": 41.96, "text": " I mean, how many other chat bots have we had?", "tokens": [50970, 286, 914, 11, 577, 867, 661, 5081, 35410, 362, 321, 632, 30, 51050], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 15, "seek": 2824, "start": 41.96, "end": 44.0, "text": " Okay, so maybe this was not going to become", "tokens": [51050, 1033, 11, 370, 1310, 341, 390, 406, 516, 281, 1813, 51152], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 16, "seek": 2824, "start": 44.0, "end": 47.0, "text": " like a masochistic, narcissistic Nazi", "tokens": [51152, 411, 257, 2300, 8997, 3142, 11, 25771, 3142, 23592, 51302], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 17, "seek": 2824, "start": 47.0, "end": 48.56, "text": " like the Twitter bot before.", "tokens": [51302, 411, 264, 5794, 10592, 949, 13, 51380], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 18, "seek": 2824, "start": 49.76, "end": 51.099999999999994, "text": " This is apparently really polite.", "tokens": [51440, 639, 307, 7970, 534, 25171, 13, 51507], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 19, "seek": 2824, "start": 51.099999999999994, "end": 52.72, "text": " I'm sure they trained it to be really, really polite.", "tokens": [51507, 286, 478, 988, 436, 8895, 309, 281, 312, 534, 11, 534, 25171, 13, 51588], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 20, "seek": 2824, "start": 52.72, "end": 54.68, "text": " Apparently it's really, really polite.", "tokens": [51588, 16755, 309, 311, 534, 11, 534, 25171, 13, 51686], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 21, "seek": 2824, "start": 54.68, "end": 57.239999999999995, "text": " I was scrolling through a thing and it said,", "tokens": [51686, 286, 390, 29053, 807, 257, 551, 293, 309, 848, 11, 51814], "temperature": 0.0, "avg_logprob": -0.18239995878036708, "compression_ratio": 1.6864686468646866, "no_speech_prob": 0.01281086914241314}, {"id": 22, "seek": 5724, "start": 57.24, "end": 61.480000000000004, "text": " the most polite, clueless bot you'll ever see.", "tokens": [50364, 264, 881, 25171, 11, 596, 3483, 442, 10592, 291, 603, 1562, 536, 13, 50576], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 23, "seek": 5724, "start": 63.440000000000005, "end": 66.0, "text": " If it's wrong, at least it's wrong politely.", "tokens": [50674, 759, 309, 311, 2085, 11, 412, 1935, 309, 311, 2085, 1180, 1959, 13, 50802], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 24, "seek": 5724, "start": 66.0, "end": 68.12, "text": " Hopefully it focuses on usability and dialogue.", "tokens": [50802, 10429, 309, 16109, 322, 46878, 293, 10221, 13, 50908], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 25, "seek": 5724, "start": 68.12, "end": 70.28, "text": " The chat bot uses a large language model trained", "tokens": [50908, 440, 5081, 10592, 4960, 257, 2416, 2856, 2316, 8895, 51016], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 26, "seek": 5724, "start": 70.28, "end": 71.44, "text": " with reinforcement learning", "tokens": [51016, 365, 29280, 2539, 51074], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 27, "seek": 5724, "start": 71.44, "end": 73.16, "text": " and it's based on GPT 3.5 architecture.", "tokens": [51074, 293, 309, 311, 2361, 322, 26039, 51, 805, 13, 20, 9482, 13, 51160], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 28, "seek": 5724, "start": 73.16, "end": 75.32000000000001, "text": " It's also beta, by the way.", "tokens": [51160, 467, 311, 611, 9861, 11, 538, 264, 636, 13, 51268], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 29, "seek": 5724, "start": 75.32000000000001, "end": 76.92, "text": " It's not final, right?", "tokens": [51268, 467, 311, 406, 2572, 11, 558, 30, 51348], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 30, "seek": 5724, "start": 78.8, "end": 82.08, "text": " It's an open prototype,", "tokens": [51442, 467, 311, 364, 1269, 19475, 11, 51606], "temperature": 0.0, "avg_logprob": -0.2003716468811035, "compression_ratio": 1.5045454545454546, "no_speech_prob": 0.0001634436921449378}, {"id": 31, "seek": 8208, "start": 83.08, "end": 87.92, "text": " not finished.", "tokens": [50414, 406, 4335, 13, 50656], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 32, "seek": 8208, "start": 87.92, "end": 88.75999999999999, "text": " How about that?", "tokens": [50656, 1012, 466, 300, 30, 50698], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 33, "seek": 8208, "start": 88.75999999999999, "end": 90.24, "text": " So I'll put that there.", "tokens": [50698, 407, 286, 603, 829, 300, 456, 13, 50772], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 34, "seek": 8208, "start": 90.24, "end": 91.44, "text": " Look, if you want to use it, that's fine.", "tokens": [50772, 2053, 11, 498, 291, 528, 281, 764, 309, 11, 300, 311, 2489, 13, 50832], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 35, "seek": 8208, "start": 91.44, "end": 92.32, "text": " I am not going to judge you.", "tokens": [50832, 286, 669, 406, 516, 281, 6995, 291, 13, 50876], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 36, "seek": 8208, "start": 92.32, "end": 93.67999999999999, "text": " I just think it's a waste of time.", "tokens": [50876, 286, 445, 519, 309, 311, 257, 5964, 295, 565, 13, 50944], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 37, "seek": 8208, "start": 93.67999999999999, "end": 95.84, "text": " So many things are a waste of time today.", "tokens": [50944, 407, 867, 721, 366, 257, 5964, 295, 565, 965, 13, 51052], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 38, "seek": 8208, "start": 95.84, "end": 97.75999999999999, "text": " And to me, that's a waste of time.", "tokens": [51052, 400, 281, 385, 11, 300, 311, 257, 5964, 295, 565, 13, 51148], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 39, "seek": 8208, "start": 97.75999999999999, "end": 98.84, "text": " Chat bot uses like,", "tokens": [51148, 27503, 10592, 4960, 411, 11, 51202], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 40, "seek": 8208, "start": 100.4, "end": 103.88, "text": " it says here chat GPT was launched in November, 2022", "tokens": [51280, 309, 1619, 510, 5081, 26039, 51, 390, 8730, 294, 7674, 11, 20229, 51454], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 41, "seek": 8208, "start": 103.88, "end": 107.08, "text": " and is garnered attention as its detailed responses", "tokens": [51454, 293, 307, 25067, 4073, 3202, 382, 1080, 9942, 13019, 51614], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 42, "seek": 8208, "start": 107.08, "end": 108.12, "text": " and well-reasoned answers,", "tokens": [51614, 293, 731, 12, 265, 1258, 292, 6338, 11, 51666], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 43, "seek": 8208, "start": 108.12, "end": 110.08, "text": " although its accuracy has been criticized.", "tokens": [51666, 4878, 1080, 14170, 575, 668, 28011, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24387456409966768, "compression_ratio": 1.5904059040590406, "no_speech_prob": 0.000552742276340723}, {"id": 44, "seek": 11208, "start": 112.67999999999999, "end": 115.44, "text": " Well-reasoned wrong answers.", "tokens": [50394, 1042, 12, 265, 1258, 292, 2085, 6338, 13, 50532], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 45, "seek": 11208, "start": 115.44, "end": 120.44, "text": " And people are like, I mean, there was an entire article", "tokens": [50532, 400, 561, 366, 411, 11, 286, 914, 11, 456, 390, 364, 2302, 7222, 50782], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 46, "seek": 11208, "start": 123.96, "end": 124.88, "text": " that came across my feed.", "tokens": [50958, 300, 1361, 2108, 452, 3154, 13, 51004], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 47, "seek": 11208, "start": 124.88, "end": 129.24, "text": " It was like, oh, this is the end of essays as we know them.", "tokens": [51004, 467, 390, 411, 11, 1954, 11, 341, 307, 264, 917, 295, 35123, 382, 321, 458, 552, 13, 51222], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 48, "seek": 11208, "start": 129.24, "end": 132.4, "text": " It's had GPT, GPT going to destroy, you know,", "tokens": [51222, 467, 311, 632, 26039, 51, 11, 26039, 51, 516, 281, 5293, 11, 291, 458, 11, 51380], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 49, "seek": 11208, "start": 132.4, "end": 135.12, "text": " scholastic achievement through essay writing and stuff.", "tokens": [51380, 6946, 2750, 15838, 807, 16238, 3579, 293, 1507, 13, 51516], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 50, "seek": 11208, "start": 135.12, "end": 136.88, "text": " I'm like, no, it's not.", "tokens": [51516, 286, 478, 411, 11, 572, 11, 309, 311, 406, 13, 51604], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 51, "seek": 11208, "start": 136.88, "end": 138.24, "text": " It's not.", "tokens": [51604, 467, 311, 406, 13, 51672], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 52, "seek": 11208, "start": 138.24, "end": 139.84, "text": " It's not.", "tokens": [51672, 467, 311, 406, 13, 51752], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 53, "seek": 11208, "start": 139.84, "end": 141.28, "text": " I mean, it might help you a little bit.", "tokens": [51752, 286, 914, 11, 309, 1062, 854, 291, 257, 707, 857, 13, 51824], "temperature": 0.0, "avg_logprob": -0.23565654594357274, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.01743076927959919}, {"id": 54, "seek": 14128, "start": 141.28, "end": 143.48, "text": " It's like, it's all of these chat bot things,", "tokens": [50364, 467, 311, 411, 11, 309, 311, 439, 295, 613, 5081, 10592, 721, 11, 50474], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 55, "seek": 14128, "start": 143.48, "end": 145.16, "text": " including the coding one,", "tokens": [50474, 3009, 264, 17720, 472, 11, 50558], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 56, "seek": 14128, "start": 145.16, "end": 147.72, "text": " all they really are is they're catering to people", "tokens": [50558, 439, 436, 534, 366, 307, 436, 434, 21557, 278, 281, 561, 50686], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 57, "seek": 14128, "start": 147.72, "end": 150.84, "text": " who are copy pasta people,", "tokens": [50686, 567, 366, 5055, 13296, 561, 11, 50842], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 58, "seek": 14128, "start": 150.84, "end": 152.08, "text": " copy pasta people,", "tokens": [50842, 5055, 13296, 561, 11, 50904], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 59, "seek": 14128, "start": 152.08, "end": 156.08, "text": " the people who don't do any original thinking", "tokens": [50904, 264, 561, 567, 500, 380, 360, 604, 3380, 1953, 51104], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 60, "seek": 14128, "start": 156.08, "end": 159.52, "text": " who go out and they want to use this thing like,", "tokens": [51104, 567, 352, 484, 293, 436, 528, 281, 764, 341, 551, 411, 11, 51276], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 61, "seek": 14128, "start": 159.52, "end": 160.36, "text": " oh, that's cool.", "tokens": [51276, 1954, 11, 300, 311, 1627, 13, 51318], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 62, "seek": 14128, "start": 160.36, "end": 162.6, "text": " They don't actually validate that it's true.", "tokens": [51318, 814, 500, 380, 767, 29562, 300, 309, 311, 2074, 13, 51430], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 63, "seek": 14128, "start": 162.6, "end": 166.32, "text": " Now, if they did, if they did, if they did,", "tokens": [51430, 823, 11, 498, 436, 630, 11, 498, 436, 630, 11, 498, 436, 630, 11, 51616], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 64, "seek": 14128, "start": 166.32, "end": 170.0, "text": " if they did, then it could be a nice suggestion, right?", "tokens": [51616, 498, 436, 630, 11, 550, 309, 727, 312, 257, 1481, 16541, 11, 558, 30, 51800], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 65, "seek": 14128, "start": 170.0, "end": 171.24, "text": " And I think that's fine.", "tokens": [51800, 400, 286, 519, 300, 311, 2489, 13, 51862], "temperature": 0.0, "avg_logprob": -0.17015430701040005, "compression_ratio": 1.8865546218487395, "no_speech_prob": 0.0005883650737814605}, {"id": 66, "seek": 17124, "start": 171.24, "end": 172.88, "text": " And it's not just because I'm old that I don't like it.", "tokens": [50364, 400, 309, 311, 406, 445, 570, 286, 478, 1331, 300, 286, 500, 380, 411, 309, 13, 50446], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 67, "seek": 17124, "start": 172.88, "end": 176.48000000000002, "text": " It's because it's inaccurate", "tokens": [50446, 467, 311, 570, 309, 311, 46443, 50626], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 68, "seek": 17124, "start": 176.48000000000002, "end": 178.4, "text": " and it's dangerous to trust an AI", "tokens": [50626, 293, 309, 311, 5795, 281, 3361, 364, 7318, 50722], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 69, "seek": 17124, "start": 178.4, "end": 181.32000000000002, "text": " that you're not backing up with personal experience.", "tokens": [50722, 300, 291, 434, 406, 19373, 493, 365, 2973, 1752, 13, 50868], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 70, "seek": 17124, "start": 181.32000000000002, "end": 182.44, "text": " This is, do I have to, I mean,", "tokens": [50868, 639, 307, 11, 360, 286, 362, 281, 11, 286, 914, 11, 50924], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 71, "seek": 17124, "start": 182.44, "end": 185.0, "text": " how many fictional sci-fies have there been?", "tokens": [50924, 577, 867, 28911, 2180, 12, 69, 530, 362, 456, 668, 30, 51052], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 72, "seek": 17124, "start": 186.84, "end": 188.76000000000002, "text": " This is part of the evolution of AI, right?", "tokens": [51144, 639, 307, 644, 295, 264, 9303, 295, 7318, 11, 558, 30, 51240], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 73, "seek": 17124, "start": 188.76000000000002, "end": 190.48000000000002, "text": " I mean, there was a time, there was a time", "tokens": [51240, 286, 914, 11, 456, 390, 257, 565, 11, 456, 390, 257, 565, 51326], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 74, "seek": 17124, "start": 190.48000000000002, "end": 193.12, "text": " when if you were to hear a computer-generated voice,", "tokens": [51326, 562, 498, 291, 645, 281, 1568, 257, 3820, 12, 21848, 770, 3177, 11, 51458], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 75, "seek": 17124, "start": 193.12, "end": 195.04000000000002, "text": " you would go, what the hell did they say?", "tokens": [51458, 291, 576, 352, 11, 437, 264, 4921, 630, 436, 584, 30, 51554], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 76, "seek": 17124, "start": 195.04000000000002, "end": 196.36, "text": " And now you can't even tell the difference", "tokens": [51554, 400, 586, 291, 393, 380, 754, 980, 264, 2649, 51620], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 77, "seek": 17124, "start": 196.36, "end": 197.60000000000002, "text": " between computer-generated voices.", "tokens": [51620, 1296, 3820, 12, 21848, 770, 9802, 13, 51682], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 78, "seek": 17124, "start": 197.60000000000002, "end": 199.12, "text": " So it's going in the right direction.", "tokens": [51682, 407, 309, 311, 516, 294, 264, 558, 3513, 13, 51758], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 79, "seek": 17124, "start": 199.12, "end": 199.96, "text": " I don't have any problem with that.", "tokens": [51758, 286, 500, 380, 362, 604, 1154, 365, 300, 13, 51800], "temperature": 0.0, "avg_logprob": -0.12748609112866352, "compression_ratio": 1.7876923076923077, "no_speech_prob": 0.0003920170711353421}, {"id": 80, "seek": 19996, "start": 199.96, "end": 201.4, "text": " And it needs to go in the right direction.", "tokens": [50364, 400, 309, 2203, 281, 352, 294, 264, 558, 3513, 13, 50436], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 81, "seek": 19996, "start": 201.4, "end": 204.6, "text": " But right now, why are you wasting time on it?", "tokens": [50436, 583, 558, 586, 11, 983, 366, 291, 20457, 565, 322, 309, 30, 50596], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 82, "seek": 19996, "start": 204.6, "end": 206.8, "text": " And there's an unusually large number of people", "tokens": [50596, 400, 456, 311, 364, 10054, 671, 2416, 1230, 295, 561, 50706], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 83, "seek": 19996, "start": 206.8, "end": 207.84, "text": " coming at me with this.", "tokens": [50706, 1348, 412, 385, 365, 341, 13, 50758], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 84, "seek": 19996, "start": 207.84, "end": 209.52, "text": " What do you think of Chad GPT?", "tokens": [50758, 708, 360, 291, 519, 295, 22268, 26039, 51, 30, 50842], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 85, "seek": 19996, "start": 209.52, "end": 211.56, "text": " Who are college students?", "tokens": [50842, 2102, 366, 3859, 1731, 30, 50944], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 86, "seek": 19996, "start": 213.4, "end": 215.84, "text": " And I had one person in here, I'm gonna get them out of me.", "tokens": [51036, 400, 286, 632, 472, 954, 294, 510, 11, 286, 478, 799, 483, 552, 484, 295, 385, 13, 51158], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 87, "seek": 19996, "start": 215.84, "end": 218.16, "text": " I think they're in here right now, actually.", "tokens": [51158, 286, 519, 436, 434, 294, 510, 558, 586, 11, 767, 13, 51274], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 88, "seek": 19996, "start": 218.16, "end": 219.56, "text": " Please don't get mad.", "tokens": [51274, 2555, 500, 380, 483, 5244, 13, 51344], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 89, "seek": 19996, "start": 219.56, "end": 222.32, "text": " But they said, all I can say is it took", "tokens": [51344, 583, 436, 848, 11, 439, 286, 393, 584, 307, 309, 1890, 51482], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 90, "seek": 19996, "start": 222.32, "end": 224.16, "text": " what was otherwise a three-hour assignment", "tokens": [51482, 437, 390, 5911, 257, 1045, 12, 18048, 15187, 51574], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 91, "seek": 19996, "start": 224.16, "end": 226.36, "text": " and turned it into 30 minutes.", "tokens": [51574, 293, 3574, 309, 666, 2217, 2077, 13, 51684], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 92, "seek": 19996, "start": 226.36, "end": 229.64000000000001, "text": " That's exactly, that's almost word for word what they said.", "tokens": [51684, 663, 311, 2293, 11, 300, 311, 1920, 1349, 337, 1349, 437, 436, 848, 13, 51848], "temperature": 0.0, "avg_logprob": -0.15248744518725904, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004044415254611522}, {"id": 93, "seek": 22964, "start": 229.64, "end": 233.27999999999997, "text": " And I'm thinking to myself, how is that possible?", "tokens": [50364, 400, 286, 478, 1953, 281, 2059, 11, 577, 307, 300, 1944, 30, 50546], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 94, "seek": 22964, "start": 233.27999999999997, "end": 236.6, "text": " How is that possible that this thing,", "tokens": [50546, 1012, 307, 300, 1944, 300, 341, 551, 11, 50712], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 95, "seek": 22964, "start": 236.6, "end": 238.39999999999998, "text": " whether, and I don't know the assignment,", "tokens": [50712, 1968, 11, 293, 286, 500, 380, 458, 264, 15187, 11, 50802], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 96, "seek": 22964, "start": 238.39999999999998, "end": 240.16, "text": " I think it was a coding assignment,", "tokens": [50802, 286, 519, 309, 390, 257, 17720, 15187, 11, 50890], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 97, "seek": 22964, "start": 240.16, "end": 245.16, "text": " that this thing can, oh wow, there's a good one.", "tokens": [50890, 300, 341, 551, 393, 11, 1954, 6076, 11, 456, 311, 257, 665, 472, 13, 51140], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 98, "seek": 22964, "start": 245.51999999999998, "end": 247.23999999999998, "text": " I've come up with a set of rules that describe,", "tokens": [51158, 286, 600, 808, 493, 365, 257, 992, 295, 4474, 300, 6786, 11, 51244], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 99, "seek": 22964, "start": 247.23999999999998, "end": 251.07999999999998, "text": " ooh, very cool, a code on a tech rail,", "tokens": [51244, 17024, 11, 588, 1627, 11, 257, 3089, 322, 257, 7553, 8765, 11, 51436], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 100, "seek": 22964, "start": 251.07999999999998, "end": 252.6, "text": " ooh, we'll have to go look at that one, Kima.", "tokens": [51436, 17024, 11, 321, 603, 362, 281, 352, 574, 412, 300, 472, 11, 591, 4775, 13, 51512], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 101, "seek": 22964, "start": 252.6, "end": 253.6, "text": " Yeah, that's very cool.", "tokens": [51512, 865, 11, 300, 311, 588, 1627, 13, 51562], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 102, "seek": 22964, "start": 253.6, "end": 258.03999999999996, "text": " So the point is, if it was taking you three hours", "tokens": [51562, 407, 264, 935, 307, 11, 498, 309, 390, 1940, 291, 1045, 2496, 51784], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 103, "seek": 22964, "start": 258.03999999999996, "end": 259.56, "text": " to do an assignment, whatever it was before,", "tokens": [51784, 281, 360, 364, 15187, 11, 2035, 309, 390, 949, 11, 51860], "temperature": 0.0, "avg_logprob": -0.17461764812469482, "compression_ratio": 1.758490566037736, "no_speech_prob": 0.0002098728873534128}, {"id": 104, "seek": 25956, "start": 259.56, "end": 261.64, "text": " and it's now taking you 30 minutes", "tokens": [50364, 293, 309, 311, 586, 1940, 291, 2217, 2077, 50468], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 105, "seek": 25956, "start": 261.64, "end": 264.16, "text": " because you have a chatbot that's helping you out,", "tokens": [50468, 570, 291, 362, 257, 5081, 18870, 300, 311, 4315, 291, 484, 11, 50594], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 106, "seek": 25956, "start": 265.24, "end": 266.52, "text": " there's something wrong.", "tokens": [50648, 456, 311, 746, 2085, 13, 50712], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 107, "seek": 25956, "start": 266.52, "end": 267.88, "text": " I mean, there's something wrong.", "tokens": [50712, 286, 914, 11, 456, 311, 746, 2085, 13, 50780], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 108, "seek": 25956, "start": 267.88, "end": 271.48, "text": " You're either not learning it, not learning it properly,", "tokens": [50780, 509, 434, 2139, 406, 2539, 309, 11, 406, 2539, 309, 6108, 11, 50960], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 109, "seek": 25956, "start": 271.48, "end": 274.8, "text": " or, I mean, there's an outside chance", "tokens": [50960, 420, 11, 286, 914, 11, 456, 311, 364, 2380, 2931, 51126], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 110, "seek": 25956, "start": 274.8, "end": 277.4, "text": " that it's doing the grunt work for you", "tokens": [51126, 300, 309, 311, 884, 264, 677, 2760, 589, 337, 291, 51256], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 111, "seek": 25956, "start": 277.4, "end": 278.96, "text": " and that you're still doing the learning", "tokens": [51256, 293, 300, 291, 434, 920, 884, 264, 2539, 51334], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 112, "seek": 25956, "start": 278.96, "end": 280.24, "text": " and it's filling in all the blanks", "tokens": [51334, 293, 309, 311, 10623, 294, 439, 264, 8247, 82, 51398], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 113, "seek": 25956, "start": 280.24, "end": 281.6, "text": " and everything that it would take you longer to type,", "tokens": [51398, 293, 1203, 300, 309, 576, 747, 291, 2854, 281, 2010, 11, 51466], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 114, "seek": 25956, "start": 281.6, "end": 284.04, "text": " especially if you're like a slow typer or something.", "tokens": [51466, 2318, 498, 291, 434, 411, 257, 2964, 1104, 610, 420, 746, 13, 51588], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 115, "seek": 25956, "start": 284.04, "end": 286.0, "text": " And I suppose there's a certain number of people", "tokens": [51588, 400, 286, 7297, 456, 311, 257, 1629, 1230, 295, 561, 51686], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 116, "seek": 25956, "start": 286.0, "end": 288.32, "text": " who are slow typers who can't compose thoughts very easily", "tokens": [51686, 567, 366, 2964, 2125, 433, 567, 393, 380, 35925, 4598, 588, 3612, 51802], "temperature": 0.0, "avg_logprob": -0.12454053817256805, "compression_ratio": 1.9060402684563758, "no_speech_prob": 0.0005192667013034225}, {"id": 117, "seek": 28832, "start": 288.36, "end": 290.12, "text": " and it helps them put the language together", "tokens": [50366, 293, 309, 3665, 552, 829, 264, 2856, 1214, 50454], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 118, "seek": 28832, "start": 290.12, "end": 292.0, "text": " and it's like, yeah, okay, that sounds right.", "tokens": [50454, 293, 309, 311, 411, 11, 1338, 11, 1392, 11, 300, 3263, 558, 13, 50548], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 119, "seek": 28832, "start": 292.0, "end": 296.44, "text": " I, this, my fear with any of these AI things", "tokens": [50548, 286, 11, 341, 11, 452, 4240, 365, 604, 295, 613, 7318, 721, 50770], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 120, "seek": 28832, "start": 296.44, "end": 299.56, "text": " is just like any other fear is it's like,", "tokens": [50770, 307, 445, 411, 604, 661, 4240, 307, 309, 311, 411, 11, 50926], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 121, "seek": 28832, "start": 299.56, "end": 302.15999999999997, "text": " they're gonna make us soft.", "tokens": [50926, 436, 434, 799, 652, 505, 2787, 13, 51056], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 122, "seek": 28832, "start": 302.15999999999997, "end": 303.76, "text": " You know, and that's been something", "tokens": [51056, 509, 458, 11, 293, 300, 311, 668, 746, 51136], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 123, "seek": 28832, "start": 303.76, "end": 305.88, "text": " that old people have been saying, you know,", "tokens": [51136, 300, 1331, 561, 362, 668, 1566, 11, 291, 458, 11, 51242], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 124, "seek": 28832, "start": 305.88, "end": 306.92, "text": " just the dawn of time.", "tokens": [51242, 445, 264, 18192, 295, 565, 13, 51294], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 125, "seek": 28832, "start": 306.92, "end": 309.2, "text": " There were people who didn't wanna get on railroad trains", "tokens": [51294, 821, 645, 561, 567, 994, 380, 1948, 483, 322, 30073, 16329, 51408], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 126, "seek": 28832, "start": 309.2, "end": 310.68, "text": " because they thought it was too fast", "tokens": [51408, 570, 436, 1194, 309, 390, 886, 2370, 51482], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 127, "seek": 28832, "start": 310.68, "end": 311.76, "text": " and everybody was gonna die.", "tokens": [51482, 293, 2201, 390, 799, 978, 13, 51536], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 128, "seek": 28832, "start": 311.76, "end": 313.08, "text": " A lot of people did die, by the way.", "tokens": [51536, 316, 688, 295, 561, 630, 978, 11, 538, 264, 636, 13, 51602], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 129, "seek": 28832, "start": 313.08, "end": 316.24, "text": " And there's actually in Arizona, we opened a geocache there", "tokens": [51602, 400, 456, 311, 767, 294, 14723, 11, 321, 5625, 257, 1519, 905, 6000, 456, 51760], "temperature": 0.0, "avg_logprob": -0.18074306688810649, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0019874107092618942}, {"id": 130, "seek": 31624, "start": 316.24, "end": 318.56, "text": " where there were two trains that were on the same track", "tokens": [50364, 689, 456, 645, 732, 16329, 300, 645, 322, 264, 912, 2837, 50480], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 131, "seek": 31624, "start": 318.56, "end": 321.36, "text": " and there was, you know, hundreds of hundred people", "tokens": [50480, 293, 456, 390, 11, 291, 458, 11, 6779, 295, 3262, 561, 50620], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 132, "seek": 31624, "start": 321.36, "end": 323.92, "text": " radically destroyed in an instant", "tokens": [50620, 35508, 8937, 294, 364, 9836, 50748], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 133, "seek": 31624, "start": 323.92, "end": 325.84000000000003, "text": " when they're two cranes collided at head.", "tokens": [50748, 562, 436, 434, 732, 941, 12779, 1263, 2112, 412, 1378, 13, 50844], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 134, "seek": 31624, "start": 325.84000000000003, "end": 329.08, "text": " So there are definitely concerns about these things", "tokens": [50844, 407, 456, 366, 2138, 7389, 466, 613, 721, 51006], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 135, "seek": 31624, "start": 329.08, "end": 331.12, "text": " as they come out and, you know, should we be doing it?", "tokens": [51006, 382, 436, 808, 484, 293, 11, 291, 458, 11, 820, 321, 312, 884, 309, 30, 51108], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 136, "seek": 31624, "start": 331.12, "end": 332.68, "text": " I was like, yes, we should be definitely trying them out", "tokens": [51108, 286, 390, 411, 11, 2086, 11, 321, 820, 312, 2138, 1382, 552, 484, 51186], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 137, "seek": 31624, "start": 332.68, "end": 336.36, "text": " and experimenting and stuff like that, but to what extent?", "tokens": [51186, 293, 29070, 293, 1507, 411, 300, 11, 457, 281, 437, 8396, 30, 51370], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 138, "seek": 31624, "start": 336.36, "end": 341.36, "text": " I mean, you know, if, honestly, this chat,", "tokens": [51370, 286, 914, 11, 291, 458, 11, 498, 11, 6095, 11, 341, 5081, 11, 51620], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 139, "seek": 31624, "start": 342.8, "end": 343.8, "text": " I don't know about the coding one.", "tokens": [51692, 286, 500, 380, 458, 466, 264, 17720, 472, 13, 51742], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 140, "seek": 31624, "start": 343.8, "end": 345.44, "text": " This is just a chat bot, right?", "tokens": [51742, 639, 307, 445, 257, 5081, 10592, 11, 558, 30, 51824], "temperature": 0.0, "avg_logprob": -0.20186517593708445, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.00030532380333170295}, {"id": 141, "seek": 34544, "start": 345.44, "end": 346.96, "text": " But the coding one, which is kind of related", "tokens": [50364, 583, 264, 17720, 472, 11, 597, 307, 733, 295, 4077, 50440], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 142, "seek": 34544, "start": 346.96, "end": 349.68, "text": " in conversation, that one will get you fired", "tokens": [50440, 294, 3761, 11, 300, 472, 486, 483, 291, 11777, 50576], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 143, "seek": 34544, "start": 349.68, "end": 352.84, "text": " from a company if they find out if they're using it.", "tokens": [50576, 490, 257, 2237, 498, 436, 915, 484, 498, 436, 434, 1228, 309, 13, 50734], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 144, "seek": 34544, "start": 352.84, "end": 354.92, "text": " Not just because you don't know what you're doing,", "tokens": [50734, 1726, 445, 570, 291, 500, 380, 458, 437, 291, 434, 884, 11, 50838], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 145, "seek": 34544, "start": 354.92, "end": 358.92, "text": " but because it's been trained on proprietary source code", "tokens": [50838, 457, 570, 309, 311, 668, 8895, 322, 38992, 4009, 3089, 51038], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 146, "seek": 34544, "start": 358.92, "end": 363.92, "text": " that has a indeterminate legal pedigree.", "tokens": [51038, 300, 575, 257, 1016, 35344, 13923, 5089, 5670, 328, 701, 13, 51288], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 147, "seek": 34544, "start": 364.8, "end": 366.48, "text": " And nobody likes to talk about this.", "tokens": [51332, 400, 5079, 5902, 281, 751, 466, 341, 13, 51416], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 148, "seek": 34544, "start": 366.48, "end": 368.28, "text": " They all like to talk about how cool, you know,", "tokens": [51416, 814, 439, 411, 281, 751, 466, 577, 1627, 11, 291, 458, 11, 51506], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 149, "seek": 34544, "start": 368.28, "end": 372.36, "text": " open AI chat is, I mean, this is a different company, right?", "tokens": [51506, 1269, 7318, 5081, 307, 11, 286, 914, 11, 341, 307, 257, 819, 2237, 11, 558, 30, 51710], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 150, "seek": 34544, "start": 372.36, "end": 373.56, "text": " That was the Microsoft thing.", "tokens": [51710, 663, 390, 264, 8116, 551, 13, 51770], "temperature": 0.0, "avg_logprob": -0.13432909351910732, "compression_ratio": 1.627177700348432, "no_speech_prob": 0.00020987038442399353}, {"id": 151, "seek": 37356, "start": 373.56, "end": 375.76, "text": " It's the code, whatever, I forget the name of it.", "tokens": [50364, 467, 311, 264, 3089, 11, 2035, 11, 286, 2870, 264, 1315, 295, 309, 13, 50474], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 152, "seek": 37356, "start": 375.76, "end": 378.16, "text": " But if you're using that, you're actually taking your career", "tokens": [50474, 583, 498, 291, 434, 1228, 300, 11, 291, 434, 767, 1940, 428, 3988, 50594], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 153, "seek": 37356, "start": 378.16, "end": 380.16, "text": " in your own hands and I wouldn't tell anybody you are.", "tokens": [50594, 294, 428, 1065, 2377, 293, 286, 2759, 380, 980, 4472, 291, 366, 13, 50694], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 154, "seek": 37356, "start": 380.16, "end": 382.0, "text": " And I think to a lesser degree,", "tokens": [50694, 400, 286, 519, 281, 257, 22043, 4314, 11, 50786], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 155, "seek": 37356, "start": 382.0, "end": 384.4, "text": " the chat GPT thing is the same thing.", "tokens": [50786, 264, 5081, 26039, 51, 551, 307, 264, 912, 551, 13, 50906], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 156, "seek": 37356, "start": 384.4, "end": 387.32, "text": " If you, let's say, for example, let's say for example,", "tokens": [50906, 759, 291, 11, 718, 311, 584, 11, 337, 1365, 11, 718, 311, 584, 337, 1365, 11, 51052], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 157, "seek": 37356, "start": 387.32, "end": 389.6, "text": " that you save three hours on an essay assignment", "tokens": [51052, 300, 291, 3155, 1045, 2496, 322, 364, 16238, 15187, 51166], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 158, "seek": 37356, "start": 389.6, "end": 394.6, "text": " by using chat GPT, yeah, they'll work out the legal issues", "tokens": [51166, 538, 1228, 5081, 26039, 51, 11, 1338, 11, 436, 603, 589, 484, 264, 5089, 2663, 51416], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 159, "seek": 37356, "start": 395.72, "end": 397.76, "text": " the tech is too powerful not to use.", "tokens": [51472, 264, 7553, 307, 886, 4005, 406, 281, 764, 13, 51574], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 160, "seek": 37356, "start": 397.76, "end": 400.0, "text": " I don't think that's true at all.", "tokens": [51574, 286, 500, 380, 519, 300, 311, 2074, 412, 439, 13, 51686], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 161, "seek": 37356, "start": 400.0, "end": 402.52, "text": " I must say, I know you're a huge AI fan", "tokens": [51686, 286, 1633, 584, 11, 286, 458, 291, 434, 257, 2603, 7318, 3429, 51812], "temperature": 0.0, "avg_logprob": -0.17695948033550984, "compression_ratio": 1.7195945945945945, "no_speech_prob": 0.002631434705108404}, {"id": 162, "seek": 40252, "start": 402.52, "end": 405.24, "text": " and I am not, I am not a fan of it at all.", "tokens": [50364, 293, 286, 669, 406, 11, 286, 669, 406, 257, 3429, 295, 309, 412, 439, 13, 50500], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 163, "seek": 40252, "start": 406.68, "end": 409.76, "text": " To me, it's just copy, past, past on steroids.", "tokens": [50572, 1407, 385, 11, 309, 311, 445, 5055, 11, 1791, 11, 1791, 322, 45717, 13, 50726], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 164, "seek": 40252, "start": 409.76, "end": 410.59999999999997, "text": " That's all it is.", "tokens": [50726, 663, 311, 439, 309, 307, 13, 50768], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 165, "seek": 40252, "start": 410.59999999999997, "end": 413.08, "text": " And so what it's causing is it's causing a bunch of people", "tokens": [50768, 400, 370, 437, 309, 311, 9853, 307, 309, 311, 9853, 257, 3840, 295, 561, 50892], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 166, "seek": 40252, "start": 413.08, "end": 416.96, "text": " to not learn shit and that's fine.", "tokens": [50892, 281, 406, 1466, 4611, 293, 300, 311, 2489, 13, 51086], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 167, "seek": 40252, "start": 416.96, "end": 418.91999999999996, "text": " And this, I mean, I've said it before,", "tokens": [51086, 400, 341, 11, 286, 914, 11, 286, 600, 848, 309, 949, 11, 51184], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 168, "seek": 40252, "start": 418.91999999999996, "end": 420.84, "text": " I predicted that everybody should be learning AI", "tokens": [51184, 286, 19147, 300, 2201, 820, 312, 2539, 7318, 51280], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 169, "seek": 40252, "start": 420.84, "end": 421.96, "text": " and how to train models properly", "tokens": [51280, 293, 577, 281, 3847, 5245, 6108, 51336], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 170, "seek": 40252, "start": 421.96, "end": 425.2, "text": " because if this is a step in the right direction", "tokens": [51336, 570, 498, 341, 307, 257, 1823, 294, 264, 558, 3513, 51498], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 171, "seek": 40252, "start": 425.2, "end": 427.08, "text": " where the number of people are gonna be doing", "tokens": [51498, 689, 264, 1230, 295, 561, 366, 799, 312, 884, 51592], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 172, "seek": 40252, "start": 427.08, "end": 429.32, "text": " actual programming is gonna go down.", "tokens": [51592, 3539, 9410, 307, 799, 352, 760, 13, 51704], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 173, "seek": 40252, "start": 429.32, "end": 431.2, "text": " And there's a story I tell about this", "tokens": [51704, 400, 456, 311, 257, 1657, 286, 980, 466, 341, 51798], "temperature": 0.0, "avg_logprob": -0.16769801172716864, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.0003799329570028931}, {"id": 174, "seek": 43120, "start": 431.2, "end": 433.52, "text": " that is related to this", "tokens": [50364, 300, 307, 4077, 281, 341, 50480], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 175, "seek": 43120, "start": 433.52, "end": 435.56, "text": " because the way that AIs are trained,", "tokens": [50480, 570, 264, 636, 300, 316, 6802, 366, 8895, 11, 50582], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 176, "seek": 43120, "start": 435.56, "end": 437.56, "text": " including this one that I've been slamming on,", "tokens": [50582, 3009, 341, 472, 300, 286, 600, 668, 25617, 2810, 322, 11, 50682], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 177, "seek": 43120, "start": 437.56, "end": 439.03999999999996, "text": " the way that they're trained is organic.", "tokens": [50682, 264, 636, 300, 436, 434, 8895, 307, 10220, 13, 50756], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 178, "seek": 43120, "start": 439.03999999999996, "end": 440.84, "text": " It's closer to how nature does things", "tokens": [50756, 467, 311, 4966, 281, 577, 3687, 775, 721, 50846], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 179, "seek": 43120, "start": 440.84, "end": 442.64, "text": " than the algorithmic models.", "tokens": [50846, 813, 264, 9284, 299, 5245, 13, 50936], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 180, "seek": 43120, "start": 442.64, "end": 445.44, "text": " And I have a story about this I wanna tell really quick.", "tokens": [50936, 400, 286, 362, 257, 1657, 466, 341, 286, 1948, 980, 534, 1702, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 181, "seek": 43120, "start": 446.71999999999997, "end": 448.4, "text": " Imagine an AI tutor that can teach kids", "tokens": [51140, 11739, 364, 7318, 35613, 300, 393, 2924, 2301, 51224], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 182, "seek": 43120, "start": 448.4, "end": 449.59999999999997, "text": " in third-world countries.", "tokens": [51224, 294, 2636, 12, 13217, 3517, 13, 51284], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 183, "seek": 43120, "start": 450.68, "end": 455.68, "text": " Wrongly, he'll turn them into white supremacists", "tokens": [51338, 28150, 356, 11, 415, 603, 1261, 552, 666, 2418, 23710, 326, 1751, 51588], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 184, "seek": 43120, "start": 456.32, "end": 458.24, "text": " even though they're in Africa.", "tokens": [51620, 754, 1673, 436, 434, 294, 7349, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 185, "seek": 43120, "start": 458.24, "end": 460.56, "text": " I mean, if it was a Twitter bot, that's what it would do.", "tokens": [51716, 286, 914, 11, 498, 309, 390, 257, 5794, 10592, 11, 300, 311, 437, 309, 576, 360, 13, 51832], "temperature": 0.0, "avg_logprob": -0.1903710748157362, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00048775848699733615}, {"id": 186, "seek": 46056, "start": 460.6, "end": 461.88, "text": " Look, we're getting there.", "tokens": [50366, 2053, 11, 321, 434, 1242, 456, 13, 50430], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 187, "seek": 46056, "start": 461.88, "end": 463.72, "text": " We're getting there, we're just not there, right?", "tokens": [50430, 492, 434, 1242, 456, 11, 321, 434, 445, 406, 456, 11, 558, 30, 50522], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 188, "seek": 46056, "start": 463.72, "end": 466.48, "text": " So, that's what I'm saying.", "tokens": [50522, 407, 11, 300, 311, 437, 286, 478, 1566, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 189, "seek": 46056, "start": 466.48, "end": 469.08, "text": " Better than what we have right now, which is nothing.", "tokens": [50660, 15753, 813, 437, 321, 362, 558, 586, 11, 597, 307, 1825, 13, 50790], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 190, "seek": 46056, "start": 469.08, "end": 471.56, "text": " Well, I mean, it's like there's societal ills", "tokens": [50790, 1042, 11, 286, 914, 11, 309, 311, 411, 456, 311, 33472, 220, 2565, 50914], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 191, "seek": 46056, "start": 471.56, "end": 473.12, "text": " out there to look at.", "tokens": [50914, 484, 456, 281, 574, 412, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 192, "seek": 46056, "start": 473.12, "end": 478.04, "text": " I'm not anti-AI, I'm just like, I'm like,", "tokens": [50992, 286, 478, 406, 6061, 12, 48698, 11, 286, 478, 445, 411, 11, 286, 478, 411, 11, 51238], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 193, "seek": 46056, "start": 478.04, "end": 479.92, "text": " so on the one hand, I do think we need to learn", "tokens": [51238, 370, 322, 264, 472, 1011, 11, 286, 360, 519, 321, 643, 281, 1466, 51332], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 194, "seek": 46056, "start": 479.92, "end": 481.44, "text": " how to train models properly.", "tokens": [51332, 577, 281, 3847, 5245, 6108, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 195, "seek": 46056, "start": 481.44, "end": 484.36, "text": " I just watched a huge conference.", "tokens": [51408, 286, 445, 6337, 257, 2603, 7586, 13, 51554], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 196, "seek": 46056, "start": 484.36, "end": 486.68, "text": " I almost gave up where I work.", "tokens": [51554, 286, 1920, 2729, 493, 689, 286, 589, 13, 51670], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 197, "seek": 46056, "start": 486.68, "end": 488.08, "text": " There was this huge, huge conference,", "tokens": [51670, 821, 390, 341, 2603, 11, 2603, 7586, 11, 51740], "temperature": 0.0, "avg_logprob": -0.1339951753616333, "compression_ratio": 1.7470817120622568, "no_speech_prob": 0.0005526996101252735}, {"id": 198, "seek": 48808, "start": 488.08, "end": 490.8, "text": " a whole day conference about AI at the place that I work.", "tokens": [50364, 257, 1379, 786, 7586, 466, 7318, 412, 264, 1081, 300, 286, 589, 13, 50500], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 199, "seek": 48808, "start": 491.91999999999996, "end": 493.8, "text": " And it's crazy, it's crazy.", "tokens": [50556, 400, 309, 311, 3219, 11, 309, 311, 3219, 13, 50650], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 200, "seek": 48808, "start": 493.8, "end": 495.91999999999996, "text": " In fact, the whole future of AI and the focus of it", "tokens": [50650, 682, 1186, 11, 264, 1379, 2027, 295, 7318, 293, 264, 1879, 295, 309, 50756], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 201, "seek": 48808, "start": 495.91999999999996, "end": 499.15999999999997, "text": " is not even on writing code, it's on the data.", "tokens": [50756, 307, 406, 754, 322, 3579, 3089, 11, 309, 311, 322, 264, 1412, 13, 50918], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 202, "seek": 48808, "start": 499.15999999999997, "end": 502.2, "text": " It's on, and they went through a bunch of examples", "tokens": [50918, 467, 311, 322, 11, 293, 436, 1437, 807, 257, 3840, 295, 5110, 51070], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 203, "seek": 48808, "start": 502.2, "end": 504.0, "text": " of how they were sampling the data", "tokens": [51070, 295, 577, 436, 645, 21179, 264, 1412, 51160], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 204, "seek": 48808, "start": 504.0, "end": 507.15999999999997, "text": " and increasing the data samples so that they were good", "tokens": [51160, 293, 5662, 264, 1412, 10938, 370, 300, 436, 645, 665, 51318], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 205, "seek": 48808, "start": 507.15999999999997, "end": 509.59999999999997, "text": " because the higher the quality and then put data,", "tokens": [51318, 570, 264, 2946, 264, 3125, 293, 550, 829, 1412, 11, 51440], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 206, "seek": 48808, "start": 509.59999999999997, "end": 510.96, "text": " the higher the quality of AI.", "tokens": [51440, 264, 2946, 264, 3125, 295, 7318, 13, 51508], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 207, "seek": 48808, "start": 510.96, "end": 512.4399999999999, "text": " And you should see the AI's that haven't,", "tokens": [51508, 400, 291, 820, 536, 264, 7318, 311, 300, 2378, 380, 11, 51582], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 208, "seek": 48808, "start": 512.4399999999999, "end": 514.28, "text": " I wish I could talk about it.", "tokens": [51582, 286, 3172, 286, 727, 751, 466, 309, 13, 51674], "temperature": 0.0, "avg_logprob": -0.2157750373339131, "compression_ratio": 1.86328125, "no_speech_prob": 0.003591985208913684}, {"id": 209, "seek": 51428, "start": 515.24, "end": 516.92, "text": " The AI that is going down,", "tokens": [50412, 440, 7318, 300, 307, 516, 760, 11, 50496], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 210, "seek": 51428, "start": 516.92, "end": 518.48, "text": " because people may not know,", "tokens": [50496, 570, 561, 815, 406, 458, 11, 50574], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 211, "seek": 51428, "start": 518.48, "end": 520.64, "text": " I support a machine learning group.", "tokens": [50574, 286, 1406, 257, 3479, 2539, 1594, 13, 50682], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 212, "seek": 51428, "start": 520.64, "end": 523.0799999999999, "text": " I do the SRE and the Kubernetes stuff", "tokens": [50682, 286, 360, 264, 318, 3850, 293, 264, 23145, 1507, 50804], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 213, "seek": 51428, "start": 523.0799999999999, "end": 525.72, "text": " and some of the REST API development for,", "tokens": [50804, 293, 512, 295, 264, 497, 14497, 9362, 3250, 337, 11, 50936], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 214, "seek": 51428, "start": 525.72, "end": 529.16, "text": " to support high performance computing machine learning group", "tokens": [50936, 281, 1406, 1090, 3389, 15866, 3479, 2539, 1594, 51108], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 215, "seek": 51428, "start": 529.16, "end": 531.72, "text": " and one of the biggest companies in the entire world", "tokens": [51108, 293, 472, 295, 264, 3880, 3431, 294, 264, 2302, 1002, 51236], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 216, "seek": 51428, "start": 533.04, "end": 536.12, "text": " who's radically making radical advantage,", "tokens": [51302, 567, 311, 35508, 1455, 12001, 5002, 11, 51456], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 217, "seek": 51428, "start": 536.12, "end": 538.36, "text": " taking radical advantage of AI and data.", "tokens": [51456, 1940, 12001, 5002, 295, 7318, 293, 1412, 13, 51568], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 218, "seek": 51428, "start": 538.36, "end": 539.8, "text": " And it's absolutely amazing.", "tokens": [51568, 400, 309, 311, 3122, 2243, 13, 51640], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 219, "seek": 51428, "start": 539.8, "end": 541.16, "text": " And they have their own, they're so big,", "tokens": [51640, 400, 436, 362, 641, 1065, 11, 436, 434, 370, 955, 11, 51708], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 220, "seek": 51428, "start": 541.16, "end": 543.8, "text": " they have actually, they have their annual conference on it.", "tokens": [51708, 436, 362, 767, 11, 436, 362, 641, 9784, 7586, 322, 309, 13, 51840], "temperature": 0.0, "avg_logprob": -0.16325509078859343, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.00043049309169873595}, {"id": 221, "seek": 54380, "start": 543.8, "end": 545.12, "text": " And I was just there.", "tokens": [50364, 400, 286, 390, 445, 456, 13, 50430], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 222, "seek": 54380, "start": 546.4399999999999, "end": 548.64, "text": " And it's absolutely phenomenally awesome.", "tokens": [50496, 400, 309, 311, 3122, 9388, 379, 3476, 13, 50606], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 223, "seek": 54380, "start": 548.64, "end": 550.3599999999999, "text": " So either I'm gonna go camping over the week,", "tokens": [50606, 407, 2139, 286, 478, 799, 352, 19470, 670, 264, 1243, 11, 50692], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 224, "seek": 54380, "start": 550.3599999999999, "end": 551.3199999999999, "text": " over the Christmas break,", "tokens": [50692, 670, 264, 5272, 1821, 11, 50740], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 225, "seek": 54380, "start": 551.3199999999999, "end": 554.28, "text": " I'm actually gonna start sticking my finger into AI", "tokens": [50740, 286, 478, 767, 799, 722, 13465, 452, 5984, 666, 7318, 50888], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 226, "seek": 54380, "start": 554.28, "end": 556.76, "text": " and learning some of the, doing some Kaggle stuff", "tokens": [50888, 293, 2539, 512, 295, 264, 11, 884, 512, 48751, 22631, 1507, 51012], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 227, "seek": 54380, "start": 556.76, "end": 558.52, "text": " and learning, if you're not learning", "tokens": [51012, 293, 2539, 11, 498, 291, 434, 406, 2539, 51100], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 228, "seek": 54380, "start": 558.52, "end": 562.1999999999999, "text": " how to do data science and this kind of thing", "tokens": [51100, 577, 281, 360, 1412, 3497, 293, 341, 733, 295, 551, 51284], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 229, "seek": 54380, "start": 562.1999999999999, "end": 564.1999999999999, "text": " and all you're focused on is algorithmic programming", "tokens": [51284, 293, 439, 291, 434, 5178, 322, 307, 9284, 299, 9410, 51384], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 230, "seek": 54380, "start": 564.1999999999999, "end": 566.3599999999999, "text": " and stuff, I mean, you should see how long it takes me.", "tokens": [51384, 293, 1507, 11, 286, 914, 11, 291, 820, 536, 577, 938, 309, 2516, 385, 13, 51492], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 231, "seek": 54380, "start": 566.3599999999999, "end": 568.0, "text": " Have you seen, I mean, it takes me forever", "tokens": [51492, 3560, 291, 1612, 11, 286, 914, 11, 309, 2516, 385, 5680, 51574], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 232, "seek": 54380, "start": 568.0, "end": 570.52, "text": " to just do basic parsing of a string", "tokens": [51574, 281, 445, 360, 3875, 21156, 278, 295, 257, 6798, 51700], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 233, "seek": 54380, "start": 570.52, "end": 571.52, "text": " or something like that.", "tokens": [51700, 420, 746, 411, 300, 13, 51750], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 234, "seek": 54380, "start": 571.52, "end": 572.92, "text": " I mean, I'm relatively fast,", "tokens": [51750, 286, 914, 11, 286, 478, 7226, 2370, 11, 51820], "temperature": 0.0, "avg_logprob": -0.14785476247216486, "compression_ratio": 1.7784810126582278, "no_speech_prob": 0.0002611536765471101}, {"id": 235, "seek": 57292, "start": 572.9599999999999, "end": 576.7199999999999, "text": " but the amount of time it takes to write code", "tokens": [50366, 457, 264, 2372, 295, 565, 309, 2516, 281, 2464, 3089, 50554], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 236, "seek": 57292, "start": 576.7199999999999, "end": 578.1999999999999, "text": " compared to the amount of time", "tokens": [50554, 5347, 281, 264, 2372, 295, 565, 50628], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 237, "seek": 57292, "start": 578.1999999999999, "end": 581.24, "text": " that it takes organically to train a model", "tokens": [50628, 300, 309, 2516, 1798, 984, 281, 3847, 257, 2316, 50780], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 238, "seek": 57292, "start": 581.24, "end": 582.52, "text": " and to get the data in place", "tokens": [50780, 293, 281, 483, 264, 1412, 294, 1081, 50844], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 239, "seek": 57292, "start": 582.52, "end": 586.04, "text": " and then let that thing write the code is substantial.", "tokens": [50844, 293, 550, 718, 300, 551, 2464, 264, 3089, 307, 16726, 13, 51020], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 240, "seek": 57292, "start": 586.04, "end": 587.92, "text": " And you know, Masi and others here are saying that,", "tokens": [51020, 400, 291, 458, 11, 5224, 72, 293, 2357, 510, 366, 1566, 300, 11, 51114], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 241, "seek": 57292, "start": 587.92, "end": 591.4799999999999, "text": " they're like, this is too powerful for it to not take over.", "tokens": [51114, 436, 434, 411, 11, 341, 307, 886, 4005, 337, 309, 281, 406, 747, 670, 13, 51292], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 242, "seek": 57292, "start": 591.4799999999999, "end": 595.4799999999999, "text": " And the chat GPT is not directly related to the coding thing,", "tokens": [51292, 400, 264, 5081, 26039, 51, 307, 406, 3838, 4077, 281, 264, 17720, 551, 11, 51492], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 243, "seek": 57292, "start": 595.4799999999999, "end": 596.3199999999999, "text": " but it's the same idea.", "tokens": [51492, 457, 309, 311, 264, 912, 1558, 13, 51534], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 244, "seek": 57292, "start": 596.3199999999999, "end": 597.88, "text": " The idea is it'll do the thinking for you", "tokens": [51534, 440, 1558, 307, 309, 603, 360, 264, 1953, 337, 291, 51612], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 245, "seek": 57292, "start": 597.88, "end": 599.4399999999999, "text": " and it'll write your essay for you.", "tokens": [51612, 293, 309, 603, 2464, 428, 16238, 337, 291, 13, 51690], "temperature": 0.0, "avg_logprob": -0.13688119958948206, "compression_ratio": 1.8352490421455938, "no_speech_prob": 8.219245501095429e-05}, {"id": 246, "seek": 59944, "start": 599.44, "end": 602.36, "text": " And so, I mean, that's, I just,", "tokens": [50364, 400, 370, 11, 286, 914, 11, 300, 311, 11, 286, 445, 11, 50510], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 247, "seek": 59944, "start": 602.36, "end": 603.4000000000001, "text": " on the one side it's good,", "tokens": [50510, 322, 264, 472, 1252, 309, 311, 665, 11, 50562], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 248, "seek": 59944, "start": 603.4000000000001, "end": 604.6800000000001, "text": " on the other side it's really bad.", "tokens": [50562, 322, 264, 661, 1252, 309, 311, 534, 1578, 13, 50626], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 249, "seek": 59944, "start": 604.6800000000001, "end": 607.36, "text": " So let me tell you a story about the good stuff, okay?", "tokens": [50626, 407, 718, 385, 980, 291, 257, 1657, 466, 264, 665, 1507, 11, 1392, 30, 50760], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 250, "seek": 59944, "start": 607.36, "end": 610.0, "text": " So there, I would give anything", "tokens": [50760, 407, 456, 11, 286, 576, 976, 1340, 50892], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 251, "seek": 59944, "start": 610.0, "end": 611.08, "text": " for the reference to this yet.", "tokens": [50892, 337, 264, 6408, 281, 341, 1939, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 252, "seek": 59944, "start": 611.08, "end": 615.0, "text": " I read this in 2014, I think it was.", "tokens": [50946, 286, 1401, 341, 294, 8227, 11, 286, 519, 309, 390, 13, 51142], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 253, "seek": 59944, "start": 615.0, "end": 619.32, "text": " And I was studying this philosophical difference", "tokens": [51142, 400, 286, 390, 7601, 341, 25066, 2649, 51358], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 254, "seek": 59944, "start": 619.32, "end": 623.96, "text": " between algorithmic approaches to solutions", "tokens": [51358, 1296, 9284, 299, 11587, 281, 6547, 51590], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 255, "seek": 59944, "start": 623.96, "end": 627.0, "text": " and natural organic solutions.", "tokens": [51590, 293, 3303, 10220, 6547, 13, 51742], "temperature": 0.0, "avg_logprob": -0.1520478637130172, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0002779956557787955}, {"id": 256, "seek": 62700, "start": 627.04, "end": 630.56, "text": " And the specific example was,", "tokens": [50366, 400, 264, 2685, 1365, 390, 11, 50542], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 257, "seek": 62700, "start": 631.84, "end": 632.76, "text": " and I've told the story before,", "tokens": [50606, 293, 286, 600, 1907, 264, 1657, 949, 11, 50652], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 258, "seek": 62700, "start": 632.76, "end": 635.36, "text": " but the specific example was a cam.", "tokens": [50652, 457, 264, 2685, 1365, 390, 257, 1945, 13, 50782], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 259, "seek": 62700, "start": 635.36, "end": 637.08, "text": " You know what a cam is, right?", "tokens": [50782, 509, 458, 437, 257, 1945, 307, 11, 558, 30, 50868], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 260, "seek": 62700, "start": 637.08, "end": 639.16, "text": " It was a cam, like a camshaft in a car,", "tokens": [50868, 467, 390, 257, 1945, 11, 411, 257, 1945, 82, 25127, 294, 257, 1032, 11, 50972], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 261, "seek": 62700, "start": 639.16, "end": 640.72, "text": " but it wasn't a car, it was a factory.", "tokens": [50972, 457, 309, 2067, 380, 257, 1032, 11, 309, 390, 257, 9265, 13, 51050], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 262, "seek": 62700, "start": 640.72, "end": 645.6, "text": " It was a factory in New England someplace in the Northeast.", "tokens": [51050, 467, 390, 257, 9265, 294, 1873, 8196, 37126, 294, 264, 42150, 13, 51294], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 263, "seek": 62700, "start": 645.6, "end": 648.2, "text": " And, you know, back, you know,", "tokens": [51294, 400, 11, 291, 458, 11, 646, 11, 291, 458, 11, 51424], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 264, "seek": 62700, "start": 648.2, "end": 649.72, "text": " where there's a lot of manufacturing going.", "tokens": [51424, 689, 456, 311, 257, 688, 295, 11096, 516, 13, 51500], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 265, "seek": 62700, "start": 649.72, "end": 653.48, "text": " And then the story goes that they,", "tokens": [51500, 400, 550, 264, 1657, 1709, 300, 436, 11, 51688], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 266, "seek": 62700, "start": 654.56, "end": 655.96, "text": " I wish I could find, if anybody can find it,", "tokens": [51742, 286, 3172, 286, 727, 915, 11, 498, 4472, 393, 915, 309, 11, 51812], "temperature": 0.0, "avg_logprob": -0.19129547928318832, "compression_ratio": 1.773109243697479, "no_speech_prob": 7.483865192625672e-05}, {"id": 267, "seek": 65596, "start": 655.96, "end": 657.48, "text": " please give me a reference.", "tokens": [50364, 1767, 976, 385, 257, 6408, 13, 50440], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 268, "seek": 65596, "start": 657.48, "end": 659.9200000000001, "text": " But the device broke down.", "tokens": [50440, 583, 264, 4302, 6902, 760, 13, 50562], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 269, "seek": 65596, "start": 659.9200000000001, "end": 662.4000000000001, "text": " And so the production line was down.", "tokens": [50562, 400, 370, 264, 4265, 1622, 390, 760, 13, 50686], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 270, "seek": 65596, "start": 662.4000000000001, "end": 664.4000000000001, "text": " And this is a production line that was,", "tokens": [50686, 400, 341, 307, 257, 4265, 1622, 300, 390, 11, 50786], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 271, "seek": 65596, "start": 664.4000000000001, "end": 665.52, "text": " you know, core of the business", "tokens": [50786, 291, 458, 11, 4965, 295, 264, 1606, 50842], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 272, "seek": 65596, "start": 665.52, "end": 667.2800000000001, "text": " and they were losing all this money.", "tokens": [50842, 293, 436, 645, 7027, 439, 341, 1460, 13, 50930], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 273, "seek": 65596, "start": 667.2800000000001, "end": 670.12, "text": " And well, every day it was down, they were losing money.", "tokens": [50930, 400, 731, 11, 633, 786, 309, 390, 760, 11, 436, 645, 7027, 1460, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 274, "seek": 65596, "start": 670.12, "end": 674.88, "text": " And this cam, it was this very complicated mechanical process", "tokens": [51072, 400, 341, 1945, 11, 309, 390, 341, 588, 6179, 12070, 1399, 51310], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 275, "seek": 65596, "start": 674.88, "end": 678.12, "text": " that had to be done exactly that way,", "tokens": [51310, 300, 632, 281, 312, 1096, 2293, 300, 636, 11, 51472], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 276, "seek": 65596, "start": 678.12, "end": 680.52, "text": " had been created somewhat organically", "tokens": [51472, 632, 668, 2942, 8344, 1798, 984, 51592], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 277, "seek": 65596, "start": 680.52, "end": 682.6, "text": " and it had been tailored and it had been shaved off", "tokens": [51592, 293, 309, 632, 668, 34858, 293, 309, 632, 668, 37980, 766, 51696], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 278, "seek": 65596, "start": 682.6, "end": 683.44, "text": " and everything.", "tokens": [51696, 293, 1203, 13, 51738], "temperature": 0.0, "avg_logprob": -0.1564510868441674, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.0015483689494431019}, {"id": 279, "seek": 68344, "start": 683.96, "end": 685.36, "text": " And so they had to, you know,", "tokens": [50390, 400, 370, 436, 632, 281, 11, 291, 458, 11, 50460], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 280, "seek": 68344, "start": 685.36, "end": 688.84, "text": " they wanted this very unique cam was the core.", "tokens": [50460, 436, 1415, 341, 588, 3845, 1945, 390, 264, 4965, 13, 50634], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 281, "seek": 68344, "start": 688.84, "end": 691.6400000000001, "text": " It was the heart of everything on the assembly line", "tokens": [50634, 467, 390, 264, 1917, 295, 1203, 322, 264, 12103, 1622, 50774], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 282, "seek": 68344, "start": 691.6400000000001, "end": 693.6800000000001, "text": " and they couldn't recreate it.", "tokens": [50774, 293, 436, 2809, 380, 25833, 309, 13, 50876], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 283, "seek": 68344, "start": 693.6800000000001, "end": 696.1600000000001, "text": " And so they hired, they paid all of this money", "tokens": [50876, 400, 370, 436, 13144, 11, 436, 4835, 439, 295, 341, 1460, 51000], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 284, "seek": 68344, "start": 696.1600000000001, "end": 700.2800000000001, "text": " to all of these people to do, to fix it.", "tokens": [51000, 281, 439, 295, 613, 561, 281, 360, 11, 281, 3191, 309, 13, 51206], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 285, "seek": 68344, "start": 700.2800000000001, "end": 701.44, "text": " They brought in theorists,", "tokens": [51206, 814, 3038, 294, 27423, 1751, 11, 51264], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 286, "seek": 68344, "start": 701.44, "end": 705.08, "text": " they brought in the Beth Mathematicians, you know,", "tokens": [51264, 436, 3038, 294, 264, 14011, 15776, 14911, 2567, 11, 291, 458, 11, 51446], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 287, "seek": 68344, "start": 705.08, "end": 707.24, "text": " and they said, okay, hey, let's, you know,", "tokens": [51446, 293, 436, 848, 11, 1392, 11, 4177, 11, 718, 311, 11, 291, 458, 11, 51554], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 288, "seek": 68344, "start": 707.24, "end": 710.44, "text": " and they designed lots of failures.", "tokens": [51554, 293, 436, 4761, 3195, 295, 20774, 13, 51714], "temperature": 0.0, "avg_logprob": -0.44035247166951497, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.009121710434556007}, {"id": 289, "seek": 71044, "start": 711.44, "end": 714.8000000000001, "text": " So they would put together all these amazing things", "tokens": [50414, 407, 436, 576, 829, 1214, 439, 613, 2243, 721, 50582], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 290, "seek": 71044, "start": 714.8000000000001, "end": 717.2800000000001, "text": " and then they didn't work.", "tokens": [50582, 293, 550, 436, 994, 380, 589, 13, 50706], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 291, "seek": 71044, "start": 717.2800000000001, "end": 718.6400000000001, "text": " They just didn't work", "tokens": [50706, 814, 445, 994, 380, 589, 50774], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 292, "seek": 71044, "start": 718.6400000000001, "end": 720.4000000000001, "text": " because they weren't organic enough.", "tokens": [50774, 570, 436, 4999, 380, 10220, 1547, 13, 50862], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 293, "seek": 71044, "start": 720.4000000000001, "end": 721.24, "text": " They weren't natural enough.", "tokens": [50862, 814, 4999, 380, 3303, 1547, 13, 50904], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 294, "seek": 71044, "start": 721.24, "end": 723.8800000000001, "text": " So then they brought in another team", "tokens": [50904, 407, 550, 436, 3038, 294, 1071, 1469, 51036], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 295, "seek": 71044, "start": 723.8800000000001, "end": 726.8000000000001, "text": " and I don't remember the specifics of the team,", "tokens": [51036, 293, 286, 500, 380, 1604, 264, 28454, 295, 264, 1469, 11, 51182], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 296, "seek": 71044, "start": 726.8000000000001, "end": 728.8800000000001, "text": " but this team did the same thing.", "tokens": [51182, 457, 341, 1469, 630, 264, 912, 551, 13, 51286], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 297, "seek": 71044, "start": 728.8800000000001, "end": 730.8000000000001, "text": " They recreated the process that was used", "tokens": [51286, 814, 850, 26559, 264, 1399, 300, 390, 1143, 51382], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 298, "seek": 71044, "start": 730.8000000000001, "end": 732.1600000000001, "text": " to create the first cam.", "tokens": [51382, 281, 1884, 264, 700, 1945, 13, 51450], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 299, "seek": 71044, "start": 732.1600000000001, "end": 735.44, "text": " And it took them longer to do all the stuff,", "tokens": [51450, 400, 309, 1890, 552, 2854, 281, 360, 439, 264, 1507, 11, 51614], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 300, "seek": 71044, "start": 735.44, "end": 736.4000000000001, "text": " but it actually worked.", "tokens": [51614, 457, 309, 767, 2732, 13, 51662], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 301, "seek": 71044, "start": 736.4000000000001, "end": 738.96, "text": " And what they did is they started with something", "tokens": [51662, 400, 437, 436, 630, 307, 436, 1409, 365, 746, 51790], "temperature": 0.0, "avg_logprob": -0.12976795106422245, "compression_ratio": 1.8249027237354085, "no_speech_prob": 0.0003682569367811084}, {"id": 302, "seek": 73896, "start": 738.96, "end": 743.64, "text": " that was the best approximation of, you know,", "tokens": [50364, 300, 390, 264, 1151, 28023, 295, 11, 291, 458, 11, 50598], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 303, "seek": 73896, "start": 743.64, "end": 744.64, "text": " that they could come up with", "tokens": [50598, 300, 436, 727, 808, 493, 365, 50648], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 304, "seek": 73896, "start": 744.64, "end": 745.84, "text": " and they used this stuff from, you know,", "tokens": [50648, 293, 436, 1143, 341, 1507, 490, 11, 291, 458, 11, 50708], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 305, "seek": 73896, "start": 745.84, "end": 748.2800000000001, "text": " the other mathematicians that people had given them", "tokens": [50708, 264, 661, 32811, 2567, 300, 561, 632, 2212, 552, 50830], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 306, "seek": 73896, "start": 748.2800000000001, "end": 749.6800000000001, "text": " and they put that in there", "tokens": [50830, 293, 436, 829, 300, 294, 456, 50900], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 307, "seek": 73896, "start": 749.6800000000001, "end": 751.08, "text": " and then they ran it for a while", "tokens": [50900, 293, 550, 436, 5872, 309, 337, 257, 1339, 50970], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 308, "seek": 73896, "start": 751.08, "end": 752.0400000000001, "text": " and then they would go in", "tokens": [50970, 293, 550, 436, 576, 352, 294, 51018], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 309, "seek": 73896, "start": 752.0400000000001, "end": 753.48, "text": " and then they would shave, they had the machinist", "tokens": [51018, 293, 550, 436, 576, 25544, 11, 436, 632, 264, 2246, 259, 468, 51090], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 310, "seek": 73896, "start": 753.48, "end": 754.84, "text": " and they would shave off part of it", "tokens": [51090, 293, 436, 576, 25544, 766, 644, 295, 309, 51158], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 311, "seek": 73896, "start": 754.84, "end": 756.12, "text": " and then they would run it again", "tokens": [51158, 293, 550, 436, 576, 1190, 309, 797, 51222], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 312, "seek": 73896, "start": 756.12, "end": 757.6, "text": " and then they would shave off a little bit more", "tokens": [51222, 293, 550, 436, 576, 25544, 766, 257, 707, 857, 544, 51296], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 313, "seek": 73896, "start": 757.6, "end": 758.52, "text": " and they would run it again.", "tokens": [51296, 293, 436, 576, 1190, 309, 797, 13, 51342], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 314, "seek": 73896, "start": 758.52, "end": 760.96, "text": " And then it was, so it was this fail faster idea, right?", "tokens": [51342, 400, 550, 309, 390, 11, 370, 309, 390, 341, 3061, 4663, 1558, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 315, "seek": 73896, "start": 760.96, "end": 764.64, "text": " And that idea of adjusting for failure", "tokens": [51464, 400, 300, 1558, 295, 23559, 337, 7763, 51648], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 316, "seek": 73896, "start": 764.64, "end": 766.8000000000001, "text": " and training a device,", "tokens": [51648, 293, 3097, 257, 4302, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1608659768406349, "compression_ratio": 2.1515151515151514, "no_speech_prob": 0.0019264932489022613}, {"id": 317, "seek": 76680, "start": 766.8, "end": 769.0, "text": " that's exactly how machine learning works.", "tokens": [50364, 300, 311, 2293, 577, 3479, 2539, 1985, 13, 50474], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 318, "seek": 76680, "start": 769.0, "end": 770.24, "text": " So as I understand it.", "tokens": [50474, 407, 382, 286, 1223, 309, 13, 50536], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 319, "seek": 76680, "start": 770.24, "end": 773.24, "text": " So having that, you know,", "tokens": [50536, 407, 1419, 300, 11, 291, 458, 11, 50686], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 320, "seek": 76680, "start": 773.24, "end": 775.4799999999999, "text": " and that got them the solution that they wanted to.", "tokens": [50686, 293, 300, 658, 552, 264, 3827, 300, 436, 1415, 281, 13, 50798], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 321, "seek": 76680, "start": 775.4799999999999, "end": 780.4799999999999, "text": " And that process of natural learning that went on,", "tokens": [50798, 400, 300, 1399, 295, 3303, 2539, 300, 1437, 322, 11, 51048], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 322, "seek": 76680, "start": 781.3199999999999, "end": 784.28, "text": " I mean, natural learning has got a very specific meaning", "tokens": [51090, 286, 914, 11, 3303, 2539, 575, 658, 257, 588, 2685, 3620, 51238], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 323, "seek": 76680, "start": 784.28, "end": 785.4799999999999, "text": " in the AI world.", "tokens": [51238, 294, 264, 7318, 1002, 13, 51298], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 324, "seek": 76680, "start": 785.4799999999999, "end": 788.1999999999999, "text": " And that's, I'm sorry, natural intelligence,", "tokens": [51298, 400, 300, 311, 11, 286, 478, 2597, 11, 3303, 7599, 11, 51434], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 325, "seek": 76680, "start": 788.1999999999999, "end": 790.28, "text": " not natural learning, natural intelligence is the goal.", "tokens": [51434, 406, 3303, 2539, 11, 3303, 7599, 307, 264, 3387, 13, 51538], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 326, "seek": 76680, "start": 790.28, "end": 794.64, "text": " Natural intelligence is when the intelligence is self-aware", "tokens": [51538, 20137, 7599, 307, 562, 264, 7599, 307, 2698, 12, 17074, 51756], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 327, "seek": 76680, "start": 794.64, "end": 796.12, "text": " and everything and there's a lot of debate", "tokens": [51756, 293, 1203, 293, 456, 311, 257, 688, 295, 7958, 51830], "temperature": 0.0, "avg_logprob": -0.18138197601818648, "compression_ratio": 1.9109311740890689, "no_speech_prob": 0.0005883718840777874}, {"id": 328, "seek": 79612, "start": 796.12, "end": 797.88, "text": " about whether that'll ever be a thing.", "tokens": [50364, 466, 1968, 300, 603, 1562, 312, 257, 551, 13, 50452], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 329, "seek": 79612, "start": 797.88, "end": 802.08, "text": " But the point of it was that the organic approach,", "tokens": [50452, 583, 264, 935, 295, 309, 390, 300, 264, 10220, 3109, 11, 50662], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 330, "seek": 79612, "start": 802.08, "end": 804.52, "text": " you know, fail and adjust, fail and fix,", "tokens": [50662, 291, 458, 11, 3061, 293, 4369, 11, 3061, 293, 3191, 11, 50784], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 331, "seek": 79612, "start": 804.52, "end": 807.36, "text": " fail and fix, fail and fix is what got them the solution.", "tokens": [50784, 3061, 293, 3191, 11, 3061, 293, 3191, 307, 437, 658, 552, 264, 3827, 13, 50926], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 332, "seek": 79612, "start": 807.36, "end": 809.92, "text": " And no amount of programming and algorithm", "tokens": [50926, 400, 572, 2372, 295, 9410, 293, 9284, 51054], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 333, "seek": 79612, "start": 809.92, "end": 811.76, "text": " at thinking is in the best minds could get it.", "tokens": [51054, 412, 1953, 307, 294, 264, 1151, 9634, 727, 483, 309, 13, 51146], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 334, "seek": 79612, "start": 811.76, "end": 813.68, "text": " It had to be incrementally done.", "tokens": [51146, 467, 632, 281, 312, 26200, 379, 1096, 13, 51242], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 335, "seek": 79612, "start": 813.68, "end": 815.72, "text": " And I really appreciate that story", "tokens": [51242, 400, 286, 534, 4449, 300, 1657, 51344], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 336, "seek": 79612, "start": 815.72, "end": 817.44, "text": " because that's how I do most things.", "tokens": [51344, 570, 300, 311, 577, 286, 360, 881, 721, 13, 51430], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 337, "seek": 79612, "start": 817.44, "end": 818.84, "text": " I'm a very practical guy.", "tokens": [51430, 286, 478, 257, 588, 8496, 2146, 13, 51500], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 338, "seek": 79612, "start": 818.84, "end": 821.38, "text": " I have a hard time, I mean, I can visualize certain things,", "tokens": [51500, 286, 362, 257, 1152, 565, 11, 286, 914, 11, 286, 393, 23273, 1629, 721, 11, 51627], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 339, "seek": 79612, "start": 821.38, "end": 823.4, "text": " but when it comes to like lead code algorithms", "tokens": [51627, 457, 562, 309, 1487, 281, 411, 1477, 3089, 14642, 51728], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 340, "seek": 79612, "start": 823.4, "end": 825.6, "text": " and stuff like that, I don't really do well with them.", "tokens": [51728, 293, 1507, 411, 300, 11, 286, 500, 380, 534, 360, 731, 365, 552, 13, 51838], "temperature": 0.0, "avg_logprob": -0.13393855544756045, "compression_ratio": 1.7732919254658386, "no_speech_prob": 0.001032068976201117}, {"id": 341, "seek": 82560, "start": 825.6, "end": 829.52, "text": " But if I can see it working, I can modify what's working", "tokens": [50364, 583, 498, 286, 393, 536, 309, 1364, 11, 286, 393, 16927, 437, 311, 1364, 50560], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 342, "seek": 82560, "start": 829.52, "end": 831.36, "text": " and get it to the point where it's working.", "tokens": [50560, 293, 483, 309, 281, 264, 935, 689, 309, 311, 1364, 13, 50652], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 343, "seek": 82560, "start": 831.36, "end": 833.08, "text": " And then if I just look at all the code, I'm like,", "tokens": [50652, 400, 550, 498, 286, 445, 574, 412, 439, 264, 3089, 11, 286, 478, 411, 11, 50738], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 344, "seek": 82560, "start": 833.08, "end": 834.84, "text": " okay, I understand how this code's working", "tokens": [50738, 1392, 11, 286, 1223, 577, 341, 3089, 311, 1364, 50826], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 345, "seek": 82560, "start": 834.84, "end": 836.6, "text": " because I tweaked it all along the way.", "tokens": [50826, 570, 286, 6986, 7301, 309, 439, 2051, 264, 636, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 346, "seek": 82560, "start": 836.6, "end": 838.5600000000001, "text": " And sometimes there's a refactor along the way", "tokens": [50914, 400, 2171, 456, 311, 257, 1895, 15104, 2051, 264, 636, 51012], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 347, "seek": 82560, "start": 838.5600000000001, "end": 840.6800000000001, "text": " in there too, because, you know, like, hey, you know,", "tokens": [51012, 294, 456, 886, 11, 570, 11, 291, 458, 11, 411, 11, 4177, 11, 291, 458, 11, 51118], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 348, "seek": 82560, "start": 840.6800000000001, "end": 842.96, "text": " this is not as efficient as it could be.", "tokens": [51118, 341, 307, 406, 382, 7148, 382, 309, 727, 312, 13, 51232], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 349, "seek": 82560, "start": 842.96, "end": 846.36, "text": " But, you know, it's avoiding the premature optimization", "tokens": [51232, 583, 11, 291, 458, 11, 309, 311, 20220, 264, 34877, 19618, 51402], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 350, "seek": 82560, "start": 846.36, "end": 847.9200000000001, "text": " kind of thing, general intelligence.", "tokens": [51402, 733, 295, 551, 11, 2674, 7599, 13, 51480], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 351, "seek": 82560, "start": 847.9200000000001, "end": 850.08, "text": " Yes, that's what I was looking for.", "tokens": [51480, 1079, 11, 300, 311, 437, 286, 390, 1237, 337, 13, 51588], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 352, "seek": 82560, "start": 850.08, "end": 850.9200000000001, "text": " That's three body problem.", "tokens": [51588, 663, 311, 1045, 1772, 1154, 13, 51630], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 353, "seek": 82560, "start": 850.9200000000001, "end": 852.6, "text": " And yeah, that's the one I was looking for.", "tokens": [51630, 400, 1338, 11, 300, 311, 264, 472, 286, 390, 1237, 337, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14313659442247018, "compression_ratio": 1.8580645161290323, "no_speech_prob": 0.0002234049461549148}, {"id": 354, "seek": 85260, "start": 853.08, "end": 857.5600000000001, "text": " So, you know, these things are all super fascinating.", "tokens": [50388, 407, 11, 291, 458, 11, 613, 721, 366, 439, 1687, 10343, 13, 50612], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 355, "seek": 85260, "start": 857.5600000000001, "end": 859.76, "text": " Chat, GPT is a part of it.", "tokens": [50612, 27503, 11, 26039, 51, 307, 257, 644, 295, 309, 13, 50722], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 356, "seek": 85260, "start": 859.76, "end": 862.6800000000001, "text": " It's definitely a thing that I think needs to exist.", "tokens": [50722, 467, 311, 2138, 257, 551, 300, 286, 519, 2203, 281, 2514, 13, 50868], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 357, "seek": 85260, "start": 863.8000000000001, "end": 866.16, "text": " I just feel like so many people", "tokens": [50924, 286, 445, 841, 411, 370, 867, 561, 51042], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 358, "seek": 85260, "start": 866.16, "end": 868.44, "text": " are like freaking out about it right now.", "tokens": [51042, 366, 411, 14612, 484, 466, 309, 558, 586, 13, 51156], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 359, "seek": 85260, "start": 869.6800000000001, "end": 871.28, "text": " And I have to ask myself,", "tokens": [51218, 400, 286, 362, 281, 1029, 2059, 11, 51298], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 360, "seek": 85260, "start": 871.28, "end": 873.08, "text": " isn't there something better you could be doing", "tokens": [51298, 1943, 380, 456, 746, 1101, 291, 727, 312, 884, 51388], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 361, "seek": 85260, "start": 873.08, "end": 874.28, "text": " with your time?", "tokens": [51388, 365, 428, 565, 30, 51448], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 362, "seek": 85260, "start": 874.28, "end": 877.72, "text": " But that's not my business, do what you want with your time.", "tokens": [51448, 583, 300, 311, 406, 452, 1606, 11, 360, 437, 291, 528, 365, 428, 565, 13, 51620], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 363, "seek": 85260, "start": 877.72, "end": 879.88, "text": " I mean, I waste my time plenty good.", "tokens": [51620, 286, 914, 11, 286, 5964, 452, 565, 7140, 665, 13, 51728], "temperature": 0.0, "avg_logprob": -0.16867122487125233, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.000245357834501192}, {"id": 364, "seek": 87988, "start": 879.88, "end": 883.04, "text": " So, you know, if you want to play around, then fine.", "tokens": [50364, 407, 11, 291, 458, 11, 498, 291, 528, 281, 862, 926, 11, 550, 2489, 13, 50522], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 365, "seek": 87988, "start": 883.04, "end": 884.12, "text": " I don't, I don't.", "tokens": [50522, 286, 500, 380, 11, 286, 500, 380, 13, 50576], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 366, "seek": 87988, "start": 884.12, "end": 885.84, "text": " I have no intention of doing it.", "tokens": [50576, 286, 362, 572, 7789, 295, 884, 309, 13, 50662], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 367, "seek": 87988, "start": 887.16, "end": 888.8, "text": " If I could train my own chatbot,", "tokens": [50728, 759, 286, 727, 3847, 452, 1065, 5081, 18870, 11, 50810], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 368, "seek": 87988, "start": 888.8, "end": 890.6, "text": " which I am interested in doing,", "tokens": [50810, 597, 286, 669, 3102, 294, 884, 11, 50900], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 369, "seek": 87988, "start": 890.6, "end": 895.68, "text": " my goal with AI is to create my,", "tokens": [50900, 452, 3387, 365, 7318, 307, 281, 1884, 452, 11, 51154], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 370, "seek": 87988, "start": 895.68, "end": 897.2, "text": " you know how they say second brain, right?", "tokens": [51154, 291, 458, 577, 436, 584, 1150, 3567, 11, 558, 30, 51230], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 371, "seek": 87988, "start": 897.2, "end": 899.6, "text": " Second brain is another word for Zettlecasten.", "tokens": [51230, 5736, 3567, 307, 1071, 1349, 337, 1176, 28444, 3734, 268, 13, 51350], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 372, "seek": 87988, "start": 899.6, "end": 903.92, "text": " So I have, I've now, I'm up to like 1800 content nodes,", "tokens": [51350, 407, 286, 362, 11, 286, 600, 586, 11, 286, 478, 493, 281, 411, 24327, 2701, 13891, 11, 51566], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 373, "seek": 87988, "start": 903.92, "end": 906.92, "text": " knowledge nodes in my current Zettlecasten.", "tokens": [51566, 3601, 13891, 294, 452, 2190, 1176, 28444, 3734, 268, 13, 51716], "temperature": 0.0, "avg_logprob": -0.18730726696196057, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00015842868015170097}, {"id": 374, "seek": 90692, "start": 906.92, "end": 909.1999999999999, "text": " I have three other knowledge bases", "tokens": [50364, 286, 362, 1045, 661, 3601, 17949, 50478], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 375, "seek": 90692, "start": 909.1999999999999, "end": 912.8, "text": " that have over a thousand content nodes in each of them.", "tokens": [50478, 300, 362, 670, 257, 4714, 2701, 13891, 294, 1184, 295, 552, 13, 50658], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 376, "seek": 90692, "start": 912.8, "end": 915.24, "text": " And I am in the process of bringing all of those over.", "tokens": [50658, 400, 286, 669, 294, 264, 1399, 295, 5062, 439, 295, 729, 670, 13, 50780], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 377, "seek": 90692, "start": 915.24, "end": 919.0, "text": " So it's like almost everything that I've ever written about.", "tokens": [50780, 407, 309, 311, 411, 1920, 1203, 300, 286, 600, 1562, 3720, 466, 13, 50968], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 378, "seek": 90692, "start": 919.0, "end": 921.92, "text": " And once I get all of that content in one place,", "tokens": [50968, 400, 1564, 286, 483, 439, 295, 300, 2701, 294, 472, 1081, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 379, "seek": 90692, "start": 921.92, "end": 926.92, "text": " I really want to see how I could put", "tokens": [51114, 286, 534, 528, 281, 536, 577, 286, 727, 829, 51364], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 380, "seek": 90692, "start": 927.28, "end": 931.3199999999999, "text": " some machine learning algorithmic stuff,", "tokens": [51382, 512, 3479, 2539, 9284, 299, 1507, 11, 51584], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 381, "seek": 90692, "start": 931.3199999999999, "end": 932.36, "text": " not machine algorithms,", "tokens": [51584, 406, 3479, 14642, 11, 51636], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 382, "seek": 90692, "start": 932.36, "end": 935.1999999999999, "text": " but I want to see if I could build", "tokens": [51636, 457, 286, 528, 281, 536, 498, 286, 727, 1322, 51778], "temperature": 0.0, "avg_logprob": -0.10116150265648252, "compression_ratio": 1.7012987012987013, "no_speech_prob": 0.00039202513289637864}, {"id": 383, "seek": 93520, "start": 935.2, "end": 939.1600000000001, "text": " some machine learning into my own data stuff, right?", "tokens": [50364, 512, 3479, 2539, 666, 452, 1065, 1412, 1507, 11, 558, 30, 50562], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 384, "seek": 93520, "start": 939.1600000000001, "end": 941.84, "text": " And then, and then of course the extension of this is that,", "tokens": [50562, 400, 550, 11, 293, 550, 295, 1164, 264, 10320, 295, 341, 307, 300, 11, 50696], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 385, "seek": 93520, "start": 941.84, "end": 944.4000000000001, "text": " you know, the exchange grid, the knowledge exchange grid,", "tokens": [50696, 291, 458, 11, 264, 7742, 10748, 11, 264, 3601, 7742, 10748, 11, 50824], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 386, "seek": 93520, "start": 944.4000000000001, "end": 947.48, "text": " once I can get, so let's say, let's say that I have,", "tokens": [50824, 1564, 286, 393, 483, 11, 370, 718, 311, 584, 11, 718, 311, 584, 300, 286, 362, 11, 50978], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 387, "seek": 93520, "start": 947.48, "end": 949.6400000000001, "text": " I know, text pregeneration, stuff like that, right?", "tokens": [50978, 286, 458, 11, 2487, 659, 30372, 11, 1507, 411, 300, 11, 558, 30, 51086], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 388, "seek": 93520, "start": 949.6400000000001, "end": 951.76, "text": " So I'm already doing templates and stuff,", "tokens": [51086, 407, 286, 478, 1217, 884, 21165, 293, 1507, 11, 51192], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 389, "seek": 93520, "start": 951.76, "end": 952.8000000000001, "text": " but I mean, it's very possible", "tokens": [51192, 457, 286, 914, 11, 309, 311, 588, 1944, 51244], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 390, "seek": 93520, "start": 952.8000000000001, "end": 953.88, "text": " that I could do the template generation", "tokens": [51244, 300, 286, 727, 360, 264, 12379, 5125, 51298], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 391, "seek": 93520, "start": 953.88, "end": 955.08, "text": " automatically through AI.", "tokens": [51298, 6772, 807, 7318, 13, 51358], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 392, "seek": 93520, "start": 956.6400000000001, "end": 959.8000000000001, "text": " But something else that's interesting that interests me is that,", "tokens": [51436, 583, 746, 1646, 300, 311, 1880, 300, 8847, 385, 307, 300, 11, 51594], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 393, "seek": 93520, "start": 959.8000000000001, "end": 961.8000000000001, "text": " is that's just my corpus, right?", "tokens": [51594, 307, 300, 311, 445, 452, 1181, 31624, 11, 558, 30, 51694], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 394, "seek": 93520, "start": 961.8000000000001, "end": 963.84, "text": " I just have my data, my Zettlecasten,", "tokens": [51694, 286, 445, 362, 452, 1412, 11, 452, 1176, 28444, 3734, 268, 11, 51796], "temperature": 0.0, "avg_logprob": -0.17831382751464844, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.00026116991648450494}, {"id": 395, "seek": 96384, "start": 963.84, "end": 966.6800000000001, "text": " but the goal, and then we're probably like five years out", "tokens": [50364, 457, 264, 3387, 11, 293, 550, 321, 434, 1391, 411, 1732, 924, 484, 50506], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 396, "seek": 96384, "start": 966.6800000000001, "end": 969.48, "text": " on this, is to eventually be able to follow multiple other", "tokens": [50506, 322, 341, 11, 307, 281, 4728, 312, 1075, 281, 1524, 3866, 661, 50646], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 397, "seek": 96384, "start": 969.48, "end": 972.44, "text": " people and have a cash copy of their Zettlecasten", "tokens": [50646, 561, 293, 362, 257, 6388, 5055, 295, 641, 1176, 28444, 3734, 268, 50794], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 398, "seek": 96384, "start": 972.44, "end": 973.52, "text": " with me as well.", "tokens": [50794, 365, 385, 382, 731, 13, 50848], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 399, "seek": 96384, "start": 973.52, "end": 976.36, "text": " And, you know, you take that to the nth degree,", "tokens": [50848, 400, 11, 291, 458, 11, 291, 747, 300, 281, 264, 297, 392, 4314, 11, 50990], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 400, "seek": 96384, "start": 976.36, "end": 978.1600000000001, "text": " if I've got a thousand people,", "tokens": [50990, 498, 286, 600, 658, 257, 4714, 561, 11, 51080], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 401, "seek": 96384, "start": 978.1600000000001, "end": 980.52, "text": " and there are people that I personally have curated,", "tokens": [51080, 293, 456, 366, 561, 300, 286, 5665, 362, 47851, 11, 51198], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 402, "seek": 96384, "start": 980.52, "end": 982.52, "text": " my ring of trust about knowledge and that stuff,", "tokens": [51198, 452, 4875, 295, 3361, 466, 3601, 293, 300, 1507, 11, 51298], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 403, "seek": 96384, "start": 982.52, "end": 985.64, "text": " now I've created a corpus of data", "tokens": [51298, 586, 286, 600, 2942, 257, 1181, 31624, 295, 1412, 51454], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 404, "seek": 96384, "start": 985.64, "end": 989.76, "text": " that's extremely compelling when it comes to not just", "tokens": [51454, 300, 311, 4664, 20050, 562, 309, 1487, 281, 406, 445, 51660], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 405, "seek": 96384, "start": 989.76, "end": 992.64, "text": " searching, but making suggestions.", "tokens": [51660, 10808, 11, 457, 1455, 13396, 13, 51804], "temperature": 0.0, "avg_logprob": -0.17409425032766243, "compression_ratio": 1.667808219178082, "no_speech_prob": 0.0004305212351027876}, {"id": 406, "seek": 99264, "start": 993.56, "end": 997.4399999999999, "text": " And then, then we could put,", "tokens": [50410, 400, 550, 11, 550, 321, 727, 829, 11, 50604], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 407, "seek": 99264, "start": 997.4399999999999, "end": 999.0, "text": " is that what they call it, chat by utility?", "tokens": [50604, 307, 300, 437, 436, 818, 309, 11, 5081, 538, 14877, 30, 50682], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 408, "seek": 99264, "start": 999.0, "end": 1001.6, "text": " Yeah, and then I would put on top of that,", "tokens": [50682, 865, 11, 293, 550, 286, 576, 829, 322, 1192, 295, 300, 11, 50812], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 409, "seek": 99264, "start": 1001.6, "end": 1003.88, "text": " I would start to layer in the AI,", "tokens": [50812, 286, 576, 722, 281, 4583, 294, 264, 7318, 11, 50926], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 410, "seek": 99264, "start": 1003.88, "end": 1006.48, "text": " and then I could have the AI suggest things to me,", "tokens": [50926, 293, 550, 286, 727, 362, 264, 7318, 3402, 721, 281, 385, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 411, "seek": 99264, "start": 1006.48, "end": 1008.96, "text": " or when I start writing about something,", "tokens": [51056, 420, 562, 286, 722, 3579, 466, 746, 11, 51180], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 412, "seek": 99264, "start": 1008.96, "end": 1012.12, "text": " I would love to have another T-Mex window open that's like,", "tokens": [51180, 286, 576, 959, 281, 362, 1071, 314, 12, 44, 3121, 4910, 1269, 300, 311, 411, 11, 51338], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 413, "seek": 99264, "start": 1012.12, "end": 1013.88, "text": " dude, you've already talked about this over here,", "tokens": [51338, 6449, 11, 291, 600, 1217, 2825, 466, 341, 670, 510, 11, 51426], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 414, "seek": 99264, "start": 1013.88, "end": 1015.48, "text": " and here, and here, and here, here's the other thing,", "tokens": [51426, 293, 510, 11, 293, 510, 11, 293, 510, 11, 510, 311, 264, 661, 551, 11, 51506], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 415, "seek": 99264, "start": 1015.48, "end": 1017.04, "text": " and have it dynamically see,", "tokens": [51506, 293, 362, 309, 43492, 536, 11, 51584], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 416, "seek": 99264, "start": 1017.04, "end": 1019.64, "text": " not just from the keywords that I'm using,", "tokens": [51584, 406, 445, 490, 264, 21009, 300, 286, 478, 1228, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 417, "seek": 99264, "start": 1019.64, "end": 1021.26, "text": " which is, you know, a start,", "tokens": [51714, 597, 307, 11, 291, 458, 11, 257, 722, 11, 51795], "temperature": 0.0, "avg_logprob": -0.1983732086381102, "compression_ratio": 1.8467153284671534, "no_speech_prob": 0.0008040338871069252}, {"id": 418, "seek": 102126, "start": 1021.26, "end": 1023.02, "text": " but I wanted to see, well, you know,", "tokens": [50364, 457, 286, 1415, 281, 536, 11, 731, 11, 291, 458, 11, 50452], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 419, "seek": 102126, "start": 1023.02, "end": 1026.3, "text": " you've written similarly to this,", "tokens": [50452, 291, 600, 3720, 14138, 281, 341, 11, 50616], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 420, "seek": 102126, "start": 1026.3, "end": 1028.54, "text": " or somebody has written similarly to this,", "tokens": [50616, 420, 2618, 575, 3720, 14138, 281, 341, 11, 50728], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 421, "seek": 102126, "start": 1028.54, "end": 1030.78, "text": " you know, and you see this kind of thing already", "tokens": [50728, 291, 458, 11, 293, 291, 536, 341, 733, 295, 551, 1217, 50840], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 422, "seek": 102126, "start": 1030.78, "end": 1033.98, "text": " in like, trouble ticket issues,", "tokens": [50840, 294, 411, 11, 5253, 10550, 2663, 11, 51000], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 423, "seek": 102126, "start": 1033.98, "end": 1038.86, "text": " and stuff like that, that we submit to GitHub,", "tokens": [51000, 293, 1507, 411, 300, 11, 300, 321, 10315, 281, 23331, 11, 51244], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 424, "seek": 102126, "start": 1038.86, "end": 1039.7, "text": " or anything like that, you know,", "tokens": [51244, 420, 1340, 411, 300, 11, 291, 458, 11, 51286], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 425, "seek": 102126, "start": 1039.7, "end": 1040.54, "text": " you start typing things like,", "tokens": [51286, 291, 722, 18444, 721, 411, 11, 51328], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 426, "seek": 102126, "start": 1040.54, "end": 1042.46, "text": " are you sure it's not this problem right here, right?", "tokens": [51328, 366, 291, 988, 309, 311, 406, 341, 1154, 558, 510, 11, 558, 30, 51424], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 427, "seek": 102126, "start": 1042.46, "end": 1046.58, "text": " So there's already, you know, code to do this,", "tokens": [51424, 407, 456, 311, 1217, 11, 291, 458, 11, 3089, 281, 360, 341, 11, 51630], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 428, "seek": 102126, "start": 1046.58, "end": 1048.62, "text": " and that's kind of the, you know,", "tokens": [51630, 293, 300, 311, 733, 295, 264, 11, 291, 458, 11, 51732], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 429, "seek": 102126, "start": 1048.62, "end": 1050.26, "text": " phase two of the whole keg thing,", "tokens": [51732, 5574, 732, 295, 264, 1379, 803, 70, 551, 11, 51814], "temperature": 0.0, "avg_logprob": -0.17753308159964426, "compression_ratio": 1.9465020576131686, "no_speech_prob": 0.0004441748606041074}, {"id": 430, "seek": 105026, "start": 1050.26, "end": 1053.1, "text": " you know, phase one is to get the knowledge,", "tokens": [50364, 291, 458, 11, 5574, 472, 307, 281, 483, 264, 3601, 11, 50506], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 431, "seek": 105026, "start": 1053.1, "end": 1055.1, "text": " you know, really stable and collectible,", "tokens": [50506, 291, 458, 11, 534, 8351, 293, 2500, 964, 11, 50606], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 432, "seek": 105026, "start": 1055.1, "end": 1057.02, "text": " and phase two is kind of exchange it,", "tokens": [50606, 293, 5574, 732, 307, 733, 295, 7742, 309, 11, 50702], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 433, "seek": 105026, "start": 1057.02, "end": 1059.22, "text": " I guess it's apparently phase three,", "tokens": [50702, 286, 2041, 309, 311, 7970, 5574, 1045, 11, 50812], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 434, "seek": 105026, "start": 1059.22, "end": 1061.22, "text": " phase three would be processing the data,", "tokens": [50812, 5574, 1045, 576, 312, 9007, 264, 1412, 11, 50912], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 435, "seek": 105026, "start": 1061.22, "end": 1064.02, "text": " that would be processing all the knowledge,", "tokens": [50912, 300, 576, 312, 9007, 439, 264, 3601, 11, 51052], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 436, "seek": 105026, "start": 1064.02, "end": 1065.62, "text": " it's not going to fall about it.", "tokens": [51052, 309, 311, 406, 516, 281, 2100, 466, 309, 13, 51132], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 437, "seek": 105026, "start": 1067.14, "end": 1070.42, "text": " They did it for the reason of spam, yeah, I mean, yeah,", "tokens": [51208, 814, 630, 309, 337, 264, 1778, 295, 24028, 11, 1338, 11, 286, 914, 11, 1338, 11, 51372], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 438, "seek": 105026, "start": 1070.42, "end": 1072.7, "text": " I just would never want to put it,", "tokens": [51372, 286, 445, 576, 1128, 528, 281, 829, 309, 11, 51486], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 439, "seek": 105026, "start": 1072.7, "end": 1074.7, "text": " I mean, it's bad enough having a chat bot, you know,", "tokens": [51486, 286, 914, 11, 309, 311, 1578, 1547, 1419, 257, 5081, 10592, 11, 291, 458, 11, 51586], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 440, "seek": 105026, "start": 1074.7, "end": 1076.98, "text": " do one thing, the hardest part about all of this", "tokens": [51586, 360, 472, 551, 11, 264, 13158, 644, 466, 439, 295, 341, 51700], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 441, "seek": 105026, "start": 1076.98, "end": 1079.78, "text": " is going to be being able to determine who's real,", "tokens": [51700, 307, 516, 281, 312, 885, 1075, 281, 6997, 567, 311, 957, 11, 51840], "temperature": 0.0, "avg_logprob": -0.22126954438670582, "compression_ratio": 1.894927536231884, "no_speech_prob": 0.000804037437774241}, {"id": 442, "seek": 107978, "start": 1079.78, "end": 1083.18, "text": " and that's already becoming a thing, right?", "tokens": [50364, 293, 300, 311, 1217, 5617, 257, 551, 11, 558, 30, 50534], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 443, "seek": 107978, "start": 1083.18, "end": 1086.26, "text": " I mean, I imagine there's a lot of like, you know,", "tokens": [50534, 286, 914, 11, 286, 3811, 456, 311, 257, 688, 295, 411, 11, 291, 458, 11, 50688], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 444, "seek": 107978, "start": 1086.26, "end": 1088.62, "text": " porn and cheating sites that are going to love these,", "tokens": [50688, 19444, 293, 18309, 7533, 300, 366, 516, 281, 959, 613, 11, 50806], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 445, "seek": 107978, "start": 1088.62, "end": 1092.1399999999999, "text": " these AIs, because they're just going to be", "tokens": [50806, 613, 316, 6802, 11, 570, 436, 434, 445, 516, 281, 312, 50982], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 446, "seek": 107978, "start": 1092.1399999999999, "end": 1094.8999999999999, "text": " the best, you know, pretend girls ever,", "tokens": [50982, 264, 1151, 11, 291, 458, 11, 11865, 4519, 1562, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 447, "seek": 107978, "start": 1094.8999999999999, "end": 1099.1, "text": " yeah, NPCs will be awesome, yeah,", "tokens": [51120, 1338, 11, 28787, 82, 486, 312, 3476, 11, 1338, 11, 51330], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 448, "seek": 107978, "start": 1099.1, "end": 1101.66, "text": " has apps now that check for secrets,", "tokens": [51330, 575, 7733, 586, 300, 1520, 337, 14093, 11, 51458], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 449, "seek": 107978, "start": 1101.66, "end": 1104.26, "text": " check for dependency security flaws, yeah, yeah.", "tokens": [51458, 1520, 337, 33621, 3825, 27108, 11, 1338, 11, 1338, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 450, "seek": 107978, "start": 1105.3799999999999, "end": 1106.66, "text": " Yeah, and there's like, there's chat,", "tokens": [51644, 865, 11, 293, 456, 311, 411, 11, 456, 311, 5081, 11, 51708], "temperature": 0.0, "avg_logprob": -0.1848590456206223, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.00027800933457911015}, {"id": 451, "seek": 110666, "start": 1106.66, "end": 1111.0600000000002, "text": " yeah, I mean, all of those sorts of things are stuff", "tokens": [50364, 1338, 11, 286, 914, 11, 439, 295, 729, 7527, 295, 721, 366, 1507, 50584], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 452, "seek": 110666, "start": 1111.0600000000002, "end": 1112.18, "text": " that I definitely want to add in.", "tokens": [50584, 300, 286, 2138, 528, 281, 909, 294, 13, 50640], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 453, "seek": 110666, "start": 1112.18, "end": 1114.14, "text": " So I'm not, it's not that I'm against chat bots,", "tokens": [50640, 407, 286, 478, 406, 11, 309, 311, 406, 300, 286, 478, 1970, 5081, 35410, 11, 50738], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 454, "seek": 110666, "start": 1114.14, "end": 1115.74, "text": " I'm definitely adding a chat bot,", "tokens": [50738, 286, 478, 2138, 5127, 257, 5081, 10592, 11, 50818], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 455, "seek": 110666, "start": 1115.74, "end": 1118.26, "text": " I've already started adding a Twitch chat bot,", "tokens": [50818, 286, 600, 1217, 1409, 5127, 257, 22222, 5081, 10592, 11, 50944], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 456, "seek": 110666, "start": 1118.26, "end": 1122.6200000000001, "text": " which what I want it to do is like, you know,", "tokens": [50944, 597, 437, 286, 528, 309, 281, 360, 307, 411, 11, 291, 458, 11, 51162], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 457, "seek": 110666, "start": 1122.6200000000001, "end": 1124.5, "text": " I have all these commands, right?", "tokens": [51162, 286, 362, 439, 613, 16901, 11, 558, 30, 51256], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 458, "seek": 110666, "start": 1124.5, "end": 1126.26, "text": " But I hate maintaining the commands,", "tokens": [51256, 583, 286, 4700, 14916, 264, 16901, 11, 51344], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 459, "seek": 110666, "start": 1126.26, "end": 1129.14, "text": " so what I would rather have my chat bot do,", "tokens": [51344, 370, 437, 286, 576, 2831, 362, 452, 5081, 10592, 360, 11, 51488], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 460, "seek": 110666, "start": 1129.14, "end": 1131.5400000000002, "text": " my Twitch chat bot, what I would rather have it do", "tokens": [51488, 452, 22222, 5081, 10592, 11, 437, 286, 576, 2831, 362, 309, 360, 51608], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 461, "seek": 110666, "start": 1131.5400000000002, "end": 1135.0600000000002, "text": " is I would rather have it become intimately familiar", "tokens": [51608, 307, 286, 576, 2831, 362, 309, 1813, 560, 5401, 4963, 51784], "temperature": 0.0, "avg_logprob": -0.0980382617429006, "compression_ratio": 1.971311475409836, "no_speech_prob": 0.0015977032016962767}, {"id": 462, "seek": 113506, "start": 1135.06, "end": 1137.3799999999999, "text": " with my Zettelkasten, right?", "tokens": [50364, 365, 452, 1176, 3093, 338, 74, 47552, 11, 558, 30, 50480], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 463, "seek": 113506, "start": 1137.3799999999999, "end": 1141.86, "text": " So if somebody starts chatting about something,", "tokens": [50480, 407, 498, 2618, 3719, 24654, 466, 746, 11, 50704], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 464, "seek": 113506, "start": 1141.86, "end": 1143.94, "text": " and Masi's already made some really amazing stuff", "tokens": [50704, 293, 5224, 72, 311, 1217, 1027, 512, 534, 2243, 1507, 50808], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 465, "seek": 113506, "start": 1143.94, "end": 1146.3799999999999, "text": " on this level, if somebody starts chatting about something,", "tokens": [50808, 322, 341, 1496, 11, 498, 2618, 3719, 24654, 466, 746, 11, 50930], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 466, "seek": 113506, "start": 1146.3799999999999, "end": 1150.26, "text": " I want my chat bot to score potentially a response", "tokens": [50930, 286, 528, 452, 5081, 10592, 281, 6175, 7263, 257, 4134, 51124], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 467, "seek": 113506, "start": 1150.26, "end": 1152.1399999999999, "text": " and say, okay, somebody's talking like this,", "tokens": [51124, 293, 584, 11, 1392, 11, 2618, 311, 1417, 411, 341, 11, 51218], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 468, "seek": 113506, "start": 1152.1399999999999, "end": 1154.54, "text": " somebody used a question mark, somebody's doing whatever.", "tokens": [51218, 2618, 1143, 257, 1168, 1491, 11, 2618, 311, 884, 2035, 13, 51338], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 469, "seek": 113506, "start": 1154.54, "end": 1157.6599999999999, "text": " And he'll say, if you're asking about this,", "tokens": [51338, 400, 415, 603, 584, 11, 498, 291, 434, 3365, 466, 341, 11, 51494], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 470, "seek": 113506, "start": 1157.6599999999999, "end": 1159.58, "text": " this is what I was trying to do, right?", "tokens": [51494, 341, 307, 437, 286, 390, 1382, 281, 360, 11, 558, 30, 51590], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 471, "seek": 113506, "start": 1159.58, "end": 1161.8999999999999, "text": " So I would really love to be able to create", "tokens": [51590, 407, 286, 576, 534, 959, 281, 312, 1075, 281, 1884, 51706], "temperature": 0.0, "avg_logprob": -0.12517297835577101, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.003706766292452812}, {"id": 472, "seek": 116190, "start": 1161.9, "end": 1165.66, "text": " kind of a proactive customer service-like bot in my Twitch", "tokens": [50364, 733, 295, 257, 28028, 5474, 2643, 12, 4092, 10592, 294, 452, 22222, 50552], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 473, "seek": 116190, "start": 1165.66, "end": 1167.7800000000002, "text": " that answers all of the mundane questions for me", "tokens": [50552, 300, 6338, 439, 295, 264, 43497, 1651, 337, 385, 50658], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 474, "seek": 116190, "start": 1167.7800000000002, "end": 1170.26, "text": " without people having to go to the commands, right?", "tokens": [50658, 1553, 561, 1419, 281, 352, 281, 264, 16901, 11, 558, 30, 50782], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 475, "seek": 116190, "start": 1170.26, "end": 1171.46, "text": " I mean, they go to the commands", "tokens": [50782, 286, 914, 11, 436, 352, 281, 264, 16901, 50842], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 476, "seek": 116190, "start": 1171.46, "end": 1172.66, "text": " and then they have to filter through the commands", "tokens": [50842, 293, 550, 436, 362, 281, 6608, 807, 264, 16901, 50902], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 477, "seek": 116190, "start": 1172.66, "end": 1173.7800000000002, "text": " and they have to find the right one,", "tokens": [50902, 293, 436, 362, 281, 915, 264, 558, 472, 11, 50958], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 478, "seek": 116190, "start": 1173.7800000000002, "end": 1176.3000000000002, "text": " and sometimes they do and there's kind of a path through there,", "tokens": [50958, 293, 2171, 436, 360, 293, 456, 311, 733, 295, 257, 3100, 807, 456, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 479, "seek": 116190, "start": 1176.3000000000002, "end": 1177.7, "text": " but I have to maintain all of that.", "tokens": [51084, 457, 286, 362, 281, 6909, 439, 295, 300, 13, 51154], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 480, "seek": 116190, "start": 1177.7, "end": 1180.38, "text": " And maintaining the commands, I actually was looking at it,", "tokens": [51154, 400, 14916, 264, 16901, 11, 286, 767, 390, 1237, 412, 309, 11, 51288], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 481, "seek": 116190, "start": 1180.38, "end": 1182.6200000000001, "text": " I've got like 200, 300 commands.", "tokens": [51288, 286, 600, 658, 411, 2331, 11, 6641, 16901, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 482, "seek": 116190, "start": 1182.6200000000001, "end": 1185.38, "text": " Yeah, if I train it on my Zett as my corp,", "tokens": [51400, 865, 11, 498, 286, 3847, 309, 322, 452, 1176, 3093, 382, 452, 1181, 79, 11, 51538], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 483, "seek": 116190, "start": 1185.38, "end": 1188.5400000000002, "text": " yeah, then I would be, so then somebody asks a question", "tokens": [51538, 1338, 11, 550, 286, 576, 312, 11, 370, 550, 2618, 8962, 257, 1168, 51696], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 484, "seek": 116190, "start": 1188.5400000000002, "end": 1191.8200000000002, "text": " and all I have to do is write.", "tokens": [51696, 293, 439, 286, 362, 281, 360, 307, 2464, 13, 51860], "temperature": 0.0, "avg_logprob": -0.1285800020137947, "compression_ratio": 1.878125, "no_speech_prob": 0.008314688690006733}, {"id": 485, "seek": 119182, "start": 1192.1, "end": 1195.26, "text": " I don't have to go in and create all the interlinking", "tokens": [50378, 286, 500, 380, 362, 281, 352, 294, 293, 1884, 439, 264, 728, 75, 12408, 50536], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 486, "seek": 119182, "start": 1195.26, "end": 1197.98, "text": " and stuff like that inside of a specific,", "tokens": [50536, 293, 1507, 411, 300, 1854, 295, 257, 2685, 11, 50672], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 487, "seek": 119182, "start": 1197.98, "end": 1199.06, "text": " commands database.", "tokens": [50672, 16901, 8149, 13, 50726], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 488, "seek": 119182, "start": 1199.06, "end": 1201.02, "text": " I just maintain my Zodacast and answer questions", "tokens": [50726, 286, 445, 6909, 452, 1176, 378, 326, 525, 293, 1867, 1651, 50824], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 489, "seek": 119182, "start": 1201.02, "end": 1201.98, "text": " just like I'm doing right now,", "tokens": [50824, 445, 411, 286, 478, 884, 558, 586, 11, 50872], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 490, "seek": 119182, "start": 1201.98, "end": 1204.8999999999999, "text": " and then I include links to YouTube and stuff like that.", "tokens": [50872, 293, 550, 286, 4090, 6123, 281, 3088, 293, 1507, 411, 300, 13, 51018], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 491, "seek": 119182, "start": 1204.8999999999999, "end": 1206.78, "text": " And the links are identifiable", "tokens": [51018, 400, 264, 6123, 366, 2473, 30876, 51112], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 492, "seek": 119182, "start": 1206.78, "end": 1208.54, "text": " because they've got the YouTube emoji on them.", "tokens": [51112, 570, 436, 600, 658, 264, 3088, 31595, 322, 552, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 493, "seek": 119182, "start": 1208.54, "end": 1211.1, "text": " So my chat bot could be intelligent and say,", "tokens": [51200, 407, 452, 5081, 10592, 727, 312, 13232, 293, 584, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 494, "seek": 119182, "start": 1211.1, "end": 1213.54, "text": " hey, well, there's actually these YouTube videos on this too.", "tokens": [51328, 4177, 11, 731, 11, 456, 311, 767, 613, 3088, 2145, 322, 341, 886, 13, 51450], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 495, "seek": 119182, "start": 1213.54, "end": 1218.02, "text": " And it could proactively engage with anybody in my chat", "tokens": [51450, 400, 309, 727, 447, 45679, 4683, 365, 4472, 294, 452, 5081, 51674], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 496, "seek": 119182, "start": 1218.02, "end": 1219.9399999999998, "text": " while I'm writing and doing the work.", "tokens": [51674, 1339, 286, 478, 3579, 293, 884, 264, 589, 13, 51770], "temperature": 0.0, "avg_logprob": -0.1640382646680712, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.0003920030139852315}, {"id": 497, "seek": 121994, "start": 1219.94, "end": 1222.98, "text": " And then I, I mean, it might not be as personal,", "tokens": [50364, 400, 550, 286, 11, 286, 914, 11, 309, 1062, 406, 312, 382, 2973, 11, 50516], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 498, "seek": 121994, "start": 1222.98, "end": 1225.46, "text": " but it could be very valuable.", "tokens": [50516, 457, 309, 727, 312, 588, 8263, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 499, "seek": 121994, "start": 1225.46, "end": 1228.8600000000001, "text": " I think that personal broadcasting,", "tokens": [50640, 286, 519, 300, 2973, 30024, 11, 50810], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 500, "seek": 121994, "start": 1228.8600000000001, "end": 1230.9, "text": " as we do it now on this coworking kind of thing,", "tokens": [50810, 382, 321, 360, 309, 586, 322, 341, 31998, 278, 733, 295, 551, 11, 50912], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 501, "seek": 121994, "start": 1230.9, "end": 1232.1000000000001, "text": " is going to progress.", "tokens": [50912, 307, 516, 281, 4205, 13, 50972], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 502, "seek": 121994, "start": 1232.1000000000001, "end": 1234.98, "text": " I think, yeah, take care.", "tokens": [50972, 286, 519, 11, 1338, 11, 747, 1127, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 503, "seek": 121994, "start": 1234.98, "end": 1237.3400000000001, "text": " It's, I think that this is one of those things", "tokens": [51116, 467, 311, 11, 286, 519, 300, 341, 307, 472, 295, 729, 721, 51234], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 504, "seek": 121994, "start": 1237.3400000000001, "end": 1240.42, "text": " that is going to progress", "tokens": [51234, 300, 307, 516, 281, 4205, 51388], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 505, "seek": 121994, "start": 1240.42, "end": 1241.7, "text": " and it's gonna become more valuable.", "tokens": [51388, 293, 309, 311, 799, 1813, 544, 8263, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 506, "seek": 121994, "start": 1241.7, "end": 1244.66, "text": " Right now it's just kind of a fascination.", "tokens": [51452, 1779, 586, 309, 311, 445, 733, 295, 257, 7184, 2486, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1266661549473668, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.0007321339217014611}, {"id": 507, "seek": 124466, "start": 1245.66, "end": 1250.66, "text": " But the day that I can point a chat GPT at my Zodacast", "tokens": [50414, 583, 264, 786, 300, 286, 393, 935, 257, 5081, 26039, 51, 412, 452, 1176, 378, 326, 525, 50664], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 508, "seek": 124466, "start": 1251.5400000000002, "end": 1254.3400000000001, "text": " and have it automatically train itself", "tokens": [50708, 293, 362, 309, 6772, 3847, 2564, 50848], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 509, "seek": 124466, "start": 1254.3400000000001, "end": 1258.14, "text": " and get 90% accuracy on when to participate in my chat", "tokens": [50848, 293, 483, 4289, 4, 14170, 322, 562, 281, 8197, 294, 452, 5081, 51038], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 510, "seek": 124466, "start": 1258.14, "end": 1261.5, "text": " and about answering questions on my behalf as an AI,", "tokens": [51038, 293, 466, 13430, 1651, 322, 452, 9490, 382, 364, 7318, 11, 51206], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 511, "seek": 124466, "start": 1261.5, "end": 1265.5400000000002, "text": " that's the time when I will become extremely interested in it.", "tokens": [51206, 300, 311, 264, 565, 562, 286, 486, 1813, 4664, 3102, 294, 309, 13, 51408], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 512, "seek": 124466, "start": 1265.5400000000002, "end": 1267.26, "text": " I will become extremely interested in it", "tokens": [51408, 286, 486, 1813, 4664, 3102, 294, 309, 51494], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 513, "seek": 124466, "start": 1267.26, "end": 1268.78, "text": " because then it's saving me time.", "tokens": [51494, 570, 550, 309, 311, 6816, 385, 565, 13, 51570], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 514, "seek": 124466, "start": 1268.78, "end": 1271.02, "text": " That's what AI potentially could do.", "tokens": [51570, 663, 311, 437, 7318, 7263, 727, 360, 13, 51682], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 515, "seek": 124466, "start": 1271.02, "end": 1274.0600000000002, "text": " And, you know, somebody mentioned the teaching thing.", "tokens": [51682, 400, 11, 291, 458, 11, 2618, 2835, 264, 4571, 551, 13, 51834], "temperature": 0.0, "avg_logprob": -0.13909774543964756, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.0071199918165802956}, {"id": 516, "seek": 127406, "start": 1274.26, "end": 1276.26, "text": " I think there's another,", "tokens": [50374, 286, 519, 456, 311, 1071, 11, 50474], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 517, "seek": 127406, "start": 1276.26, "end": 1281.26, "text": " I understand chat GPT is a subset of instructional GPT.", "tokens": [50474, 286, 1223, 5081, 26039, 51, 307, 257, 25993, 295, 35716, 26039, 51, 13, 50724], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 518, "seek": 127406, "start": 1281.3, "end": 1282.6599999999999, "text": " Did you guys read about that?", "tokens": [50726, 2589, 291, 1074, 1401, 466, 300, 30, 50794], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 519, "seek": 127406, "start": 1282.6599999999999, "end": 1283.74, "text": " So there's another GPT.", "tokens": [50794, 407, 456, 311, 1071, 26039, 51, 13, 50848], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 520, "seek": 127406, "start": 1283.74, "end": 1286.62, "text": " It's like, I think it's called instruction GPT.", "tokens": [50848, 467, 311, 411, 11, 286, 519, 309, 311, 1219, 10951, 26039, 51, 13, 50992], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 521, "seek": 127406, "start": 1286.62, "end": 1290.1799999999998, "text": " It's actually designed for training and teaching", "tokens": [50992, 467, 311, 767, 4761, 337, 3097, 293, 4571, 51170], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 522, "seek": 127406, "start": 1290.1799999999998, "end": 1292.02, "text": " and stuff like that, more than just a random chat one.", "tokens": [51170, 293, 1507, 411, 300, 11, 544, 813, 445, 257, 4974, 5081, 472, 13, 51262], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 523, "seek": 127406, "start": 1292.02, "end": 1293.74, "text": " The random chat one is to get, you know,", "tokens": [51262, 440, 4974, 5081, 472, 307, 281, 483, 11, 291, 458, 11, 51348], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 524, "seek": 127406, "start": 1293.74, "end": 1295.1799999999998, "text": " people's interest and stuff.", "tokens": [51348, 561, 311, 1179, 293, 1507, 13, 51420], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 525, "seek": 127406, "start": 1295.1799999999998, "end": 1297.74, "text": " So that actually does, does, is interesting to me.", "tokens": [51420, 407, 300, 767, 775, 11, 775, 11, 307, 1880, 281, 385, 13, 51548], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 526, "seek": 127406, "start": 1297.74, "end": 1300.06, "text": " I think teaching is fine.", "tokens": [51548, 286, 519, 4571, 307, 2489, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18830087449815539, "compression_ratio": 1.8270042194092826, "no_speech_prob": 0.0006460997392423451}, {"id": 527, "seek": 130006, "start": 1301.06, "end": 1306.06, "text": " I think that there, yeah,", "tokens": [50414, 286, 519, 300, 456, 11, 1338, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 528, "seek": 130006, "start": 1307.26, "end": 1309.06, "text": " if there was some way to have it correct.", "tokens": [50724, 498, 456, 390, 512, 636, 281, 362, 309, 3006, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 529, "seek": 130006, "start": 1309.06, "end": 1311.62, "text": " So that's kind of, I mean, the thing of it,", "tokens": [50814, 407, 300, 311, 733, 295, 11, 286, 914, 11, 264, 551, 295, 309, 11, 50942], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 530, "seek": 130006, "start": 1311.62, "end": 1312.78, "text": " mostly that would be really cool", "tokens": [50942, 5240, 300, 576, 312, 534, 1627, 51000], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 531, "seek": 130006, "start": 1312.78, "end": 1314.86, "text": " is if you had a bot that was running, right?", "tokens": [51000, 307, 498, 291, 632, 257, 10592, 300, 390, 2614, 11, 558, 30, 51104], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 532, "seek": 130006, "start": 1314.86, "end": 1316.1399999999999, "text": " So if you had a bot that was running,", "tokens": [51104, 407, 498, 291, 632, 257, 10592, 300, 390, 2614, 11, 51168], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 533, "seek": 130006, "start": 1316.1399999999999, "end": 1318.74, "text": " it was trained off of your corpus and Zodacast then,", "tokens": [51168, 309, 390, 8895, 766, 295, 428, 1181, 31624, 293, 1176, 378, 326, 525, 550, 11, 51298], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 534, "seek": 130006, "start": 1318.74, "end": 1320.5, "text": " it could chime in every once in a while", "tokens": [51298, 309, 727, 40921, 294, 633, 1564, 294, 257, 1339, 51386], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 535, "seek": 130006, "start": 1320.5, "end": 1322.22, "text": " and maybe it would get things wrong.", "tokens": [51386, 293, 1310, 309, 576, 483, 721, 2085, 13, 51472], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 536, "seek": 130006, "start": 1322.22, "end": 1324.46, "text": " It would say, well, that's not really the right answer there.", "tokens": [51472, 467, 576, 584, 11, 731, 11, 300, 311, 406, 534, 264, 558, 1867, 456, 13, 51584], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 537, "seek": 130006, "start": 1324.46, "end": 1325.74, "text": " Here's the right answer.", "tokens": [51584, 1692, 311, 264, 558, 1867, 13, 51648], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 538, "seek": 130006, "start": 1325.74, "end": 1328.8999999999999, "text": " And then it could take its correction,", "tokens": [51648, 400, 550, 309, 727, 747, 1080, 19984, 11, 51806], "temperature": 0.0, "avg_logprob": -0.1864682289019023, "compression_ratio": 1.864864864864865, "no_speech_prob": 0.0006771291955374181}, {"id": 539, "seek": 132890, "start": 1328.9, "end": 1330.98, "text": " add it to its algorithm and say,", "tokens": [50364, 909, 309, 281, 1080, 9284, 293, 584, 11, 50468], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 540, "seek": 132890, "start": 1330.98, "end": 1333.0600000000002, "text": " so that whole thing that you have to do with AI,", "tokens": [50468, 370, 300, 1379, 551, 300, 291, 362, 281, 360, 365, 7318, 11, 50572], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 541, "seek": 132890, "start": 1333.0600000000002, "end": 1334.42, "text": " where you have to constantly correct it", "tokens": [50572, 689, 291, 362, 281, 6460, 3006, 309, 50640], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 542, "seek": 132890, "start": 1334.42, "end": 1335.5800000000002, "text": " when it gets stuff wrong, right?", "tokens": [50640, 562, 309, 2170, 1507, 2085, 11, 558, 30, 50698], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 543, "seek": 132890, "start": 1335.5800000000002, "end": 1337.1000000000001, "text": " But it learns.", "tokens": [50698, 583, 309, 27152, 13, 50774], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 544, "seek": 132890, "start": 1337.1000000000001, "end": 1338.94, "text": " Every time it gets something wrong in a chat,", "tokens": [50774, 2048, 565, 309, 2170, 746, 2085, 294, 257, 5081, 11, 50866], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 545, "seek": 132890, "start": 1338.94, "end": 1340.8200000000002, "text": " we could laugh about it and I could correct it", "tokens": [50866, 321, 727, 5801, 466, 309, 293, 286, 727, 3006, 309, 50960], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 546, "seek": 132890, "start": 1340.8200000000002, "end": 1343.22, "text": " and then it would get that answer right next time.", "tokens": [50960, 293, 550, 309, 576, 483, 300, 1867, 558, 958, 565, 13, 51080], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 547, "seek": 132890, "start": 1343.22, "end": 1346.42, "text": " And then we could just keep going like that,", "tokens": [51080, 400, 550, 321, 727, 445, 1066, 516, 411, 300, 11, 51240], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 548, "seek": 132890, "start": 1346.42, "end": 1347.26, "text": " you know what I mean?", "tokens": [51240, 291, 458, 437, 286, 914, 30, 51282], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 549, "seek": 132890, "start": 1347.26, "end": 1348.8600000000001, "text": " And it could try really hard", "tokens": [51282, 400, 309, 727, 853, 534, 1152, 51362], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 550, "seek": 132890, "start": 1348.8600000000001, "end": 1351.18, "text": " and I could just kind of train it", "tokens": [51362, 293, 286, 727, 445, 733, 295, 3847, 309, 51478], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 551, "seek": 132890, "start": 1351.18, "end": 1353.8600000000001, "text": " along with everybody else while I'm not here.", "tokens": [51478, 2051, 365, 2201, 1646, 1339, 286, 478, 406, 510, 13, 51612], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 552, "seek": 132890, "start": 1353.8600000000001, "end": 1358.8600000000001, "text": " So the idea of setting up like a SkiZix,", "tokens": [51612, 407, 264, 1558, 295, 3287, 493, 411, 257, 318, 2984, 57, 970, 11, 51862], "temperature": 0.0, "avg_logprob": -0.14557871065641703, "compression_ratio": 1.7725752508361203, "no_speech_prob": 0.0027144444175064564}, {"id": 553, "seek": 135890, "start": 1358.94, "end": 1360.5400000000002, "text": " so I used to name my bot,", "tokens": [50366, 370, 286, 1143, 281, 1315, 452, 10592, 11, 50446], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 554, "seek": 135890, "start": 1360.5400000000002, "end": 1364.38, "text": " an interactive bot that dynamically learns", "tokens": [50446, 364, 15141, 10592, 300, 43492, 27152, 50638], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 555, "seek": 135890, "start": 1364.38, "end": 1366.98, "text": " by attempting to answer popular, frequent,", "tokens": [50638, 538, 22001, 281, 1867, 3743, 11, 18004, 11, 50768], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 556, "seek": 135890, "start": 1366.98, "end": 1368.22, "text": " unasked questions and getting them wrong", "tokens": [50768, 517, 3863, 292, 1651, 293, 1242, 552, 2085, 50830], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 557, "seek": 135890, "start": 1368.22, "end": 1369.3400000000001, "text": " and having it be corrected,", "tokens": [50830, 293, 1419, 309, 312, 31687, 11, 50886], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 558, "seek": 135890, "start": 1369.3400000000001, "end": 1372.66, "text": " that's like crazy, crazy compelling for me.", "tokens": [50886, 300, 311, 411, 3219, 11, 3219, 20050, 337, 385, 13, 51052], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 559, "seek": 135890, "start": 1372.66, "end": 1374.3400000000001, "text": " And that's just from a customer service perspective,", "tokens": [51052, 400, 300, 311, 445, 490, 257, 5474, 2643, 4585, 11, 51136], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 560, "seek": 135890, "start": 1374.3400000000001, "end": 1375.98, "text": " but from an educational perspective and all that.", "tokens": [51136, 457, 490, 364, 10189, 4585, 293, 439, 300, 13, 51218], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 561, "seek": 135890, "start": 1375.98, "end": 1380.0600000000002, "text": " Now, if you're gonna start asking my bot about everything", "tokens": [51218, 823, 11, 498, 291, 434, 799, 722, 3365, 452, 10592, 466, 1203, 51422], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 562, "seek": 135890, "start": 1380.0600000000002, "end": 1382.14, "text": " and putting that in your essay,", "tokens": [51422, 293, 3372, 300, 294, 428, 16238, 11, 51526], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 563, "seek": 135890, "start": 1383.7800000000002, "end": 1385.3000000000002, "text": " I don't know how I feel about that.", "tokens": [51608, 286, 500, 380, 458, 577, 286, 841, 466, 300, 13, 51684], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 564, "seek": 135890, "start": 1385.3000000000002, "end": 1387.74, "text": " Maybe it's just making searching efficient.", "tokens": [51684, 2704, 309, 311, 445, 1455, 10808, 7148, 13, 51806], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 565, "seek": 135890, "start": 1387.74, "end": 1388.88, "text": " I mean, I say that all the time.", "tokens": [51806, 286, 914, 11, 286, 584, 300, 439, 264, 565, 13, 51863], "temperature": 0.0, "avg_logprob": -0.17537384033203124, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.00033532982342876494}, {"id": 566, "seek": 138888, "start": 1388.88, "end": 1390.2, "text": " I say if you wanna be in good in tech,", "tokens": [50364, 286, 584, 498, 291, 1948, 312, 294, 665, 294, 7553, 11, 50430], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 567, "seek": 138888, "start": 1390.2, "end": 1391.48, "text": " you gotta be a really good researcher,", "tokens": [50430, 291, 3428, 312, 257, 534, 665, 21751, 11, 50494], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 568, "seek": 138888, "start": 1391.48, "end": 1392.4, "text": " be able to search fast.", "tokens": [50494, 312, 1075, 281, 3164, 2370, 13, 50540], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 569, "seek": 138888, "start": 1392.4, "end": 1395.88, "text": " Well, if you have a bot that's doing all the searching", "tokens": [50540, 1042, 11, 498, 291, 362, 257, 10592, 300, 311, 884, 439, 264, 10808, 50714], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 570, "seek": 138888, "start": 1395.88, "end": 1397.88, "text": " for you all the time and you're just asking your bot", "tokens": [50714, 337, 291, 439, 264, 565, 293, 291, 434, 445, 3365, 428, 10592, 50814], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 571, "seek": 138888, "start": 1397.88, "end": 1400.72, "text": " about that's more likely to get the right answer,", "tokens": [50814, 466, 300, 311, 544, 3700, 281, 483, 264, 558, 1867, 11, 50956], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 572, "seek": 138888, "start": 1400.72, "end": 1405.72, "text": " then, you know, as it takes four gigabytes of GP RAM", "tokens": [50956, 550, 11, 291, 458, 11, 382, 309, 2516, 1451, 42741, 295, 26039, 14561, 51206], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 573, "seek": 138888, "start": 1406.0400000000002, "end": 1408.1000000000001, "text": " to train these modern models, really.", "tokens": [51222, 281, 3847, 613, 4363, 5245, 11, 534, 13, 51325], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 574, "seek": 138888, "start": 1410.0400000000002, "end": 1412.46, "text": " Yeah, well, there's a lot of them, yeah.", "tokens": [51422, 865, 11, 731, 11, 456, 311, 257, 688, 295, 552, 11, 1338, 13, 51543], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 575, "seek": 138888, "start": 1413.8000000000002, "end": 1414.64, "text": " Yeah, I don't know.", "tokens": [51610, 865, 11, 286, 500, 380, 458, 13, 51652], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 576, "seek": 138888, "start": 1414.64, "end": 1417.44, "text": " It'd be interesting to see how much I could do.", "tokens": [51652, 467, 1116, 312, 1880, 281, 536, 577, 709, 286, 727, 360, 13, 51792], "temperature": 0.0, "avg_logprob": -0.17953192669412363, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00026118059759028256}, {"id": 577, "seek": 141744, "start": 1417.44, "end": 1419.24, "text": " I mean, I do have my thing over here.", "tokens": [50364, 286, 914, 11, 286, 360, 362, 452, 551, 670, 510, 13, 50454], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 578, "seek": 141744, "start": 1419.24, "end": 1422.24, "text": " So, I'm trying to figure out how much I could actually do", "tokens": [50454, 407, 11, 286, 478, 1382, 281, 2573, 484, 577, 709, 286, 727, 767, 360, 50604], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 579, "seek": 141744, "start": 1422.24, "end": 1425.3600000000001, "text": " that, it'd have to have a lot of data too, right?", "tokens": [50604, 300, 11, 309, 1116, 362, 281, 362, 257, 688, 295, 1412, 886, 11, 558, 30, 50760], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 580, "seek": 141744, "start": 1425.3600000000001, "end": 1426.2, "text": " So,", "tokens": [50760, 407, 11, 50802], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 581, "seek": 141744, "start": 1429.52, "end": 1434.52, "text": " oh no, no, that would not be a thing to get, yes.", "tokens": [50968, 1954, 572, 11, 572, 11, 300, 576, 406, 312, 257, 551, 281, 483, 11, 2086, 13, 51218], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 582, "seek": 141744, "start": 1436.3200000000002, "end": 1438.28, "text": " So, that's my opinion on it.", "tokens": [51308, 407, 11, 300, 311, 452, 4800, 322, 309, 13, 51406], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 583, "seek": 141744, "start": 1439.44, "end": 1441.1200000000001, "text": " Yeah, I'm kind of underwhelmed with it,", "tokens": [51464, 865, 11, 286, 478, 733, 295, 833, 8746, 1912, 365, 309, 11, 51548], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 584, "seek": 141744, "start": 1441.1200000000001, "end": 1442.76, "text": " but I know that it's going in the right direction.", "tokens": [51548, 457, 286, 458, 300, 309, 311, 516, 294, 264, 558, 3513, 13, 51630], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 585, "seek": 141744, "start": 1442.76, "end": 1443.8400000000001, "text": " I guess I'm kind of annoyed", "tokens": [51630, 286, 2041, 286, 478, 733, 295, 25921, 51684], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 586, "seek": 141744, "start": 1443.8400000000001, "end": 1446.3600000000001, "text": " because everybody's asking me about it.", "tokens": [51684, 570, 2201, 311, 3365, 385, 466, 309, 13, 51810], "temperature": 0.0, "avg_logprob": -0.15760314464569092, "compression_ratio": 1.6125, "no_speech_prob": 6.401872087735683e-05}, {"id": 587, "seek": 144636, "start": 1446.36, "end": 1448.8, "text": " And I'm like, well, what are you using it for?", "tokens": [50364, 400, 286, 478, 411, 11, 731, 11, 437, 366, 291, 1228, 309, 337, 30, 50486], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 588, "seek": 144636, "start": 1448.8, "end": 1451.52, "text": " And every time I ask what they're using it for,", "tokens": [50486, 400, 633, 565, 286, 1029, 437, 436, 434, 1228, 309, 337, 11, 50622], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 589, "seek": 144636, "start": 1452.6399999999999, "end": 1454.76, "text": " it's, well, it's making me do my homework faster.", "tokens": [50678, 309, 311, 11, 731, 11, 309, 311, 1455, 385, 360, 452, 14578, 4663, 13, 50784], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 590, "seek": 144636, "start": 1454.76, "end": 1457.84, "text": " And I'm like, oh my God, it's like,", "tokens": [50784, 400, 286, 478, 411, 11, 1954, 452, 1265, 11, 309, 311, 411, 11, 50938], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 591, "seek": 144636, "start": 1457.84, "end": 1459.1599999999999, "text": " but I don't know if that's bad.", "tokens": [50938, 457, 286, 500, 380, 458, 498, 300, 311, 1578, 13, 51004], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 592, "seek": 144636, "start": 1459.1599999999999, "end": 1460.52, "text": " I think it's bad.", "tokens": [51004, 286, 519, 309, 311, 1578, 13, 51072], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 593, "seek": 144636, "start": 1460.52, "end": 1461.76, "text": " I think it's bad because people are not doing", "tokens": [51072, 286, 519, 309, 311, 1578, 570, 561, 366, 406, 884, 51134], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 594, "seek": 144636, "start": 1461.76, "end": 1463.24, "text": " their own research.", "tokens": [51134, 641, 1065, 2132, 13, 51208], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 595, "seek": 144636, "start": 1463.24, "end": 1464.4399999999998, "text": " It's one of two things.", "tokens": [51208, 467, 311, 472, 295, 732, 721, 13, 51268], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 596, "seek": 144636, "start": 1464.4399999999998, "end": 1465.9599999999998, "text": " They're either not doing their own research", "tokens": [51268, 814, 434, 2139, 406, 884, 641, 1065, 2132, 51344], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 597, "seek": 144636, "start": 1465.9599999999998, "end": 1468.9599999999998, "text": " or it's facilitating their research, right?", "tokens": [51344, 420, 309, 311, 47558, 641, 2132, 11, 558, 30, 51494], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 598, "seek": 144636, "start": 1468.9599999999998, "end": 1473.32, "text": " If it's the second, then I'm all for that.", "tokens": [51494, 759, 309, 311, 264, 1150, 11, 550, 286, 478, 439, 337, 300, 13, 51712], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 599, "seek": 144636, "start": 1473.32, "end": 1474.9199999999998, "text": " I mean, the terminal makes you faster", "tokens": [51712, 286, 914, 11, 264, 14709, 1669, 291, 4663, 51792], "temperature": 0.0, "avg_logprob": -0.15069032326722756, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.00015842456195969135}, {"id": 600, "seek": 147492, "start": 1474.92, "end": 1477.16, "text": " during your own research, so why not an AI?", "tokens": [50364, 1830, 428, 1065, 2132, 11, 370, 983, 406, 364, 7318, 30, 50476], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 601, "seek": 147492, "start": 1478.6000000000001, "end": 1483.44, "text": " So, you know, if you shut learning, yeah.", "tokens": [50548, 407, 11, 291, 458, 11, 498, 291, 5309, 2539, 11, 1338, 13, 50790], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 602, "seek": 147492, "start": 1484.8400000000001, "end": 1487.88, "text": " So, I think that's it.", "tokens": [50860, 407, 11, 286, 519, 300, 311, 309, 13, 51012], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 603, "seek": 147492, "start": 1487.88, "end": 1492.68, "text": " I mean, I don't have any inclination to play with it.", "tokens": [51012, 286, 914, 11, 286, 500, 380, 362, 604, 37070, 2486, 281, 862, 365, 309, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 604, "seek": 147492, "start": 1492.68, "end": 1493.92, "text": " I got too many other things to make right now,", "tokens": [51252, 286, 658, 886, 867, 661, 721, 281, 652, 558, 586, 11, 51314], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 605, "seek": 147492, "start": 1493.92, "end": 1498.92, "text": " but as I said, if it were gonna make my Twitch bot", "tokens": [51314, 457, 382, 286, 848, 11, 498, 309, 645, 799, 652, 452, 22222, 10592, 51564], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 606, "seek": 147492, "start": 1499.04, "end": 1501.4, "text": " more intelligent so that it could help people", "tokens": [51570, 544, 13232, 370, 300, 309, 727, 854, 561, 51688], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 607, "seek": 147492, "start": 1501.4, "end": 1504.6000000000001, "text": " learn more quickly and save me some time,", "tokens": [51688, 1466, 544, 2661, 293, 3155, 385, 512, 565, 11, 51848], "temperature": 0.0, "avg_logprob": -0.2045421418689546, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.0007096262415871024}, {"id": 608, "seek": 150460, "start": 1504.6, "end": 1506.48, "text": " then that's a good thing.", "tokens": [50364, 550, 300, 311, 257, 665, 551, 13, 50458], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 609, "seek": 150460, "start": 1506.48, "end": 1507.32, "text": " That's a good thing.", "tokens": [50458, 663, 311, 257, 665, 551, 13, 50500], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 610, "seek": 150460, "start": 1507.32, "end": 1509.7199999999998, "text": " So, I'll try to keep my thoughts open on that,", "tokens": [50500, 407, 11, 286, 603, 853, 281, 1066, 452, 4598, 1269, 322, 300, 11, 50620], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 611, "seek": 150460, "start": 1509.7199999999998, "end": 1512.6799999999998, "text": " but Project Matters and Ceaseless are on board.", "tokens": [50620, 457, 9849, 20285, 82, 293, 8257, 296, 4272, 366, 322, 3150, 13, 50768], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 612, "seek": 150460, "start": 1512.6799999999998, "end": 1513.7199999999998, "text": " It will replace jobs.", "tokens": [50768, 467, 486, 7406, 4782, 13, 50820], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 613, "seek": 150460, "start": 1513.7199999999998, "end": 1516.32, "text": " Then I'm fine with it, use it as an education.", "tokens": [50820, 1396, 286, 478, 2489, 365, 309, 11, 764, 309, 382, 364, 3309, 13, 50950], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 614, "seek": 150460, "start": 1516.32, "end": 1518.8799999999999, "text": " They can't have it, just won't want it.", "tokens": [50950, 814, 393, 380, 362, 309, 11, 445, 1582, 380, 528, 309, 13, 51078], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 615, "seek": 150460, "start": 1518.8799999999999, "end": 1521.8799999999999, "text": " Why would they have it replace jobs?", "tokens": [51078, 1545, 576, 436, 362, 309, 7406, 4782, 30, 51228], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 616, "seek": 150460, "start": 1521.8799999999999, "end": 1523.1999999999998, "text": " I don't understand that statement at all.", "tokens": [51228, 286, 500, 380, 1223, 300, 5629, 412, 439, 13, 51294], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 617, "seek": 150460, "start": 1523.1999999999998, "end": 1524.3999999999999, "text": " I've heard that before.", "tokens": [51294, 286, 600, 2198, 300, 949, 13, 51354], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 618, "seek": 150460, "start": 1525.7199999999998, "end": 1528.62, "text": " This chat bot is no word near replacing anyone.", "tokens": [51420, 639, 5081, 10592, 307, 572, 1349, 2651, 19139, 2878, 13, 51565], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 619, "seek": 150460, "start": 1529.8799999999999, "end": 1534.3799999999999, "text": " I mean, even the people who operated the front desk", "tokens": [51628, 286, 914, 11, 754, 264, 561, 567, 20826, 264, 1868, 10026, 51853], "temperature": 0.0, "avg_logprob": -0.23763214332469995, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.00011234809790039435}, {"id": 620, "seek": 153438, "start": 1534.8600000000001, "end": 1537.38, "text": " like the place that took my piss for my drug test.", "tokens": [50388, 411, 264, 1081, 300, 1890, 452, 15171, 337, 452, 4110, 1500, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 621, "seek": 153438, "start": 1539.74, "end": 1544.74, "text": " Even they are not replaceable yet by this.", "tokens": [50632, 2754, 436, 366, 406, 7406, 712, 1939, 538, 341, 13, 50882], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 622, "seek": 153438, "start": 1545.14, "end": 1549.3400000000001, "text": " I mean, I just, I don't see it being that reliable.", "tokens": [50902, 286, 914, 11, 286, 445, 11, 286, 500, 380, 536, 309, 885, 300, 12924, 13, 51112], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 623, "seek": 153438, "start": 1549.3400000000001, "end": 1551.2, "text": " And they were pretty damn bad.", "tokens": [51112, 400, 436, 645, 1238, 8151, 1578, 13, 51205], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 624, "seek": 153438, "start": 1554.1000000000001, "end": 1556.14, "text": " I don't even want to talk about it.", "tokens": [51350, 286, 500, 380, 754, 528, 281, 751, 466, 309, 13, 51452], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 625, "seek": 153438, "start": 1556.14, "end": 1558.42, "text": " Oh, I'm sorry, as you're here at 3.58,", "tokens": [51452, 876, 11, 286, 478, 2597, 11, 382, 291, 434, 510, 412, 805, 13, 20419, 11, 51566], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 626, "seek": 153438, "start": 1558.42, "end": 1560.38, "text": " at 12.58 and not one o'clock,", "tokens": [51566, 412, 2272, 13, 20419, 293, 406, 472, 277, 6, 9023, 11, 51664], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 627, "seek": 153438, "start": 1560.38, "end": 1562.66, "text": " you need to wait until one o'clock.", "tokens": [51664, 291, 643, 281, 1699, 1826, 472, 277, 6, 9023, 13, 51778], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 628, "seek": 153438, "start": 1562.66, "end": 1563.5, "text": " Really?", "tokens": [51778, 4083, 30, 51820], "temperature": 0.0, "avg_logprob": -0.2717898743493216, "compression_ratio": 1.5046296296296295, "no_speech_prob": 0.001987632131204009}, {"id": 629, "seek": 156350, "start": 1563.62, "end": 1564.46, "text": " I just don't even want to.", "tokens": [50370, 286, 445, 500, 380, 754, 528, 281, 13, 50412], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 630, "seek": 156350, "start": 1564.46, "end": 1566.06, "text": " It's a different thing completely.", "tokens": [50412, 467, 311, 257, 819, 551, 2584, 13, 50492], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 631, "seek": 156350, "start": 1566.06, "end": 1568.22, "text": " I just had to go through.", "tokens": [50492, 286, 445, 632, 281, 352, 807, 13, 50600], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 632, "seek": 156350, "start": 1568.22, "end": 1571.14, "text": " I had to wait in line for like two hours", "tokens": [50600, 286, 632, 281, 1699, 294, 1622, 337, 411, 732, 2496, 50746], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 633, "seek": 156350, "start": 1571.14, "end": 1572.14, "text": " to get a drug test.", "tokens": [50746, 281, 483, 257, 4110, 1500, 13, 50796], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 634, "seek": 156350, "start": 1572.14, "end": 1572.98, "text": " My phone died.", "tokens": [50796, 1222, 2593, 4539, 13, 50838], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 635, "seek": 156350, "start": 1572.98, "end": 1574.1, "text": " I had to come back the next day", "tokens": [50838, 286, 632, 281, 808, 646, 264, 958, 786, 50894], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 636, "seek": 156350, "start": 1574.1, "end": 1575.86, "text": " and wait again for two hours.", "tokens": [50894, 293, 1699, 797, 337, 732, 2496, 13, 50982], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 637, "seek": 156350, "start": 1578.14, "end": 1581.02, "text": " See, any of those things that could be improved by AI,", "tokens": [51096, 3008, 11, 604, 295, 729, 721, 300, 727, 312, 9689, 538, 7318, 11, 51240], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 638, "seek": 156350, "start": 1581.02, "end": 1582.18, "text": " I'm down.", "tokens": [51240, 286, 478, 760, 13, 51298], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 639, "seek": 156350, "start": 1582.18, "end": 1583.02, "text": " I'm down.", "tokens": [51298, 286, 478, 760, 13, 51340], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 640, "seek": 156350, "start": 1584.3, "end": 1587.38, "text": " I'm down with those things being approved.", "tokens": [51404, 286, 478, 760, 365, 729, 721, 885, 10826, 13, 51558], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 641, "seek": 156350, "start": 1587.38, "end": 1588.82, "text": " Corporations are going to use it eventually", "tokens": [51558, 19665, 763, 366, 516, 281, 764, 309, 4728, 51630], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 642, "seek": 156350, "start": 1588.82, "end": 1590.54, "text": " and people should use it as well as benefit them.", "tokens": [51630, 293, 561, 820, 764, 309, 382, 731, 382, 5121, 552, 13, 51716], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 643, "seek": 156350, "start": 1590.54, "end": 1591.78, "text": " Yeah, for sure.", "tokens": [51716, 865, 11, 337, 988, 13, 51778], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 644, "seek": 156350, "start": 1591.78, "end": 1592.78, "text": " Teachers are next.", "tokens": [51778, 40596, 366, 958, 13, 51828], "temperature": 0.0, "avg_logprob": -0.22986056353594805, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.000910961301997304}, {"id": 645, "seek": 159350, "start": 1593.78, "end": 1595.74, "text": " At least the current way of teaching.", "tokens": [50378, 1711, 1935, 264, 2190, 636, 295, 4571, 13, 50476], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 646, "seek": 159350, "start": 1595.74, "end": 1597.82, "text": " Well, I think the current way of teaching is totally broken.", "tokens": [50476, 1042, 11, 286, 519, 264, 2190, 636, 295, 4571, 307, 3879, 5463, 13, 50580], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 647, "seek": 159350, "start": 1597.82, "end": 1600.58, "text": " So I am all about having...", "tokens": [50580, 407, 286, 669, 439, 466, 1419, 485, 50718], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 648, "seek": 159350, "start": 1602.62, "end": 1607.62, "text": " I am all about the education getting disrupted by AI.", "tokens": [50820, 286, 669, 439, 466, 264, 3309, 1242, 42271, 538, 7318, 13, 51070], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 649, "seek": 159350, "start": 1608.1, "end": 1611.06, "text": " And it's not completely untrue that the way", "tokens": [51094, 400, 309, 311, 406, 2584, 1701, 41729, 300, 264, 636, 51242], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 650, "seek": 159350, "start": 1611.06, "end": 1613.58, "text": " that education is happening now could be taken over", "tokens": [51242, 300, 3309, 307, 2737, 586, 727, 312, 2726, 670, 51368], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 651, "seek": 159350, "start": 1613.58, "end": 1615.7, "text": " by an AI, absolutely.", "tokens": [51368, 538, 364, 7318, 11, 3122, 13, 51474], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 652, "seek": 159350, "start": 1615.7, "end": 1616.74, "text": " Absolutely.", "tokens": [51474, 7021, 13, 51526], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 653, "seek": 159350, "start": 1616.74, "end": 1621.3, "text": " It's like, okay, I'm gonna tell you about a topic in general", "tokens": [51526, 467, 311, 411, 11, 1392, 11, 286, 478, 799, 980, 291, 466, 257, 4829, 294, 2674, 51754], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 654, "seek": 159350, "start": 1621.3, "end": 1622.98, "text": " and I'm gonna sit here and blah, blah, blah.", "tokens": [51754, 293, 286, 478, 799, 1394, 510, 293, 12288, 11, 12288, 11, 12288, 13, 51838], "temperature": 0.0, "avg_logprob": -0.1715582497099526, "compression_ratio": 1.7478991596638656, "no_speech_prob": 0.0013248086906969547}, {"id": 655, "seek": 162298, "start": 1622.98, "end": 1624.9, "text": " And you're gonna take notes and there's no ability", "tokens": [50364, 400, 291, 434, 799, 747, 5570, 293, 456, 311, 572, 3485, 50460], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 656, "seek": 162298, "start": 1624.9, "end": 1627.38, "text": " for us to interact except for off hours.", "tokens": [50460, 337, 505, 281, 4648, 3993, 337, 766, 2496, 13, 50584], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 657, "seek": 162298, "start": 1627.38, "end": 1631.3, "text": " And then you get like an hour possibly with a TA.", "tokens": [50584, 400, 550, 291, 483, 411, 364, 1773, 6264, 365, 257, 20094, 13, 50780], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 658, "seek": 162298, "start": 1631.3, "end": 1634.6200000000001, "text": " You know, the entire model for modern education", "tokens": [50780, 509, 458, 11, 264, 2302, 2316, 337, 4363, 3309, 50946], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 659, "seek": 162298, "start": 1634.6200000000001, "end": 1636.26, "text": " is totally broken.", "tokens": [50946, 307, 3879, 5463, 13, 51028], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 660, "seek": 162298, "start": 1636.26, "end": 1637.78, "text": " It's totally broken.", "tokens": [51028, 467, 311, 3879, 5463, 13, 51104], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 661, "seek": 162298, "start": 1637.78, "end": 1641.7, "text": " And it could easily be replaced by AI.", "tokens": [51104, 400, 309, 727, 3612, 312, 10772, 538, 7318, 13, 51300], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 662, "seek": 162298, "start": 1641.7, "end": 1643.38, "text": " I completely agree with that.", "tokens": [51300, 286, 2584, 3986, 365, 300, 13, 51384], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 663, "seek": 162298, "start": 1644.54, "end": 1647.34, "text": " But if you take the true learning model,", "tokens": [51442, 583, 498, 291, 747, 264, 2074, 2539, 2316, 11, 51582], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 664, "seek": 162298, "start": 1647.34, "end": 1649.42, "text": " the Art of Ex thing that we talked about,", "tokens": [51582, 264, 5735, 295, 2111, 551, 300, 321, 2825, 466, 11, 51686], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 665, "seek": 162298, "start": 1649.42, "end": 1652.42, "text": " then where you're failing faster and you're being organic", "tokens": [51686, 550, 689, 291, 434, 18223, 4663, 293, 291, 434, 885, 10220, 51836], "temperature": 0.0, "avg_logprob": -0.18936936194155396, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.002251157769933343}, {"id": 666, "seek": 165242, "start": 1652.46, "end": 1656.54, "text": " and you have a one-on-one mentor who knows you personally,", "tokens": [50366, 293, 291, 362, 257, 472, 12, 266, 12, 546, 14478, 567, 3255, 291, 5665, 11, 50570], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 667, "seek": 165242, "start": 1656.54, "end": 1657.78, "text": " I think we're a ways from that.", "tokens": [50570, 286, 519, 321, 434, 257, 2098, 490, 300, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 668, "seek": 165242, "start": 1657.78, "end": 1660.26, "text": " I do think that AI could get there.", "tokens": [50632, 286, 360, 519, 300, 7318, 727, 483, 456, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 669, "seek": 165242, "start": 1660.26, "end": 1664.8600000000001, "text": " I think that AI could have a strong chance", "tokens": [50756, 286, 519, 300, 7318, 727, 362, 257, 2068, 2931, 50986], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 670, "seek": 165242, "start": 1664.8600000000001, "end": 1668.14, "text": " at learning about you and learning about your interests", "tokens": [50986, 412, 2539, 466, 291, 293, 2539, 466, 428, 8847, 51150], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 671, "seek": 165242, "start": 1668.14, "end": 1670.22, "text": " and learning about what you struggle with and learning.", "tokens": [51150, 293, 2539, 466, 437, 291, 7799, 365, 293, 2539, 13, 51254], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 672, "seek": 165242, "start": 1670.22, "end": 1674.14, "text": " I think those things for education could be really cool.", "tokens": [51254, 286, 519, 729, 721, 337, 3309, 727, 312, 534, 1627, 13, 51450], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 673, "seek": 165242, "start": 1674.14, "end": 1675.38, "text": " I mean, think about that.", "tokens": [51450, 286, 914, 11, 519, 466, 300, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 674, "seek": 165242, "start": 1675.38, "end": 1679.54, "text": " That you could have an AI that becomes trained", "tokens": [51512, 663, 291, 727, 362, 364, 7318, 300, 3643, 8895, 51720], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 675, "seek": 165242, "start": 1679.54, "end": 1681.98, "text": " on your regular failures.", "tokens": [51720, 322, 428, 3890, 20774, 13, 51842], "temperature": 0.0, "avg_logprob": -0.11257720615552819, "compression_ratio": 1.9, "no_speech_prob": 0.0008039791136980057}, {"id": 676, "seek": 168198, "start": 1681.98, "end": 1684.78, "text": " So maybe you're learning a foreign language", "tokens": [50364, 407, 1310, 291, 434, 2539, 257, 5329, 2856, 50504], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 677, "seek": 168198, "start": 1684.78, "end": 1688.06, "text": " and you get imperative declension wrong in Russian", "tokens": [50504, 293, 291, 483, 32490, 7488, 3378, 2085, 294, 7220, 50668], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 678, "seek": 168198, "start": 1688.06, "end": 1689.22, "text": " all the time.", "tokens": [50668, 439, 264, 565, 13, 50726], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 679, "seek": 168198, "start": 1689.22, "end": 1691.8600000000001, "text": " It's like the thing, it's constantly doing the assessments", "tokens": [50726, 467, 311, 411, 264, 551, 11, 309, 311, 6460, 884, 264, 24338, 50858], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 680, "seek": 168198, "start": 1691.8600000000001, "end": 1693.9, "text": " and everything that a teacher would be doing", "tokens": [50858, 293, 1203, 300, 257, 5027, 576, 312, 884, 50960], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 681, "seek": 168198, "start": 1693.9, "end": 1696.3, "text": " and then never doing anything, just giving you an F, right?", "tokens": [50960, 293, 550, 1128, 884, 1340, 11, 445, 2902, 291, 364, 479, 11, 558, 30, 51080], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 682, "seek": 168198, "start": 1696.3, "end": 1698.06, "text": " It would be adapting and saying,", "tokens": [51080, 467, 576, 312, 34942, 293, 1566, 11, 51168], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 683, "seek": 168198, "start": 1698.06, "end": 1700.34, "text": " hey, okay, I know you have trouble with this one thing,", "tokens": [51168, 4177, 11, 1392, 11, 286, 458, 291, 362, 5253, 365, 341, 472, 551, 11, 51282], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 684, "seek": 168198, "start": 1700.34, "end": 1701.94, "text": " so I'm gonna give you more of these things.", "tokens": [51282, 370, 286, 478, 799, 976, 291, 544, 295, 613, 721, 13, 51362], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 685, "seek": 168198, "start": 1701.94, "end": 1706.14, "text": " So the potential to have AI adapt to our weaknesses", "tokens": [51362, 407, 264, 3995, 281, 362, 7318, 6231, 281, 527, 24381, 51572], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 686, "seek": 168198, "start": 1706.14, "end": 1707.18, "text": " as we're learning,", "tokens": [51572, 382, 321, 434, 2539, 11, 51624], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 687, "seek": 168198, "start": 1707.18, "end": 1708.5, "text": " maybe we don't remember things very well.", "tokens": [51624, 1310, 321, 500, 380, 1604, 721, 588, 731, 13, 51690], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 688, "seek": 168198, "start": 1708.5, "end": 1710.06, "text": " That would be me, right?", "tokens": [51690, 663, 576, 312, 385, 11, 558, 30, 51768], "temperature": 0.0, "avg_logprob": -0.1559233208225198, "compression_ratio": 1.7459807073954985, "no_speech_prob": 0.00010389573435531929}, {"id": 689, "seek": 171006, "start": 1710.06, "end": 1712.8999999999999, "text": " So it would be more about repetition.", "tokens": [50364, 407, 309, 576, 312, 544, 466, 30432, 13, 50506], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 690, "seek": 171006, "start": 1712.8999999999999, "end": 1715.1, "text": " I think that there's a tremendous potential there", "tokens": [50506, 286, 519, 300, 456, 311, 257, 10048, 3995, 456, 50616], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 691, "seek": 171006, "start": 1715.1, "end": 1716.5, "text": " for that, I really do.", "tokens": [50616, 337, 300, 11, 286, 534, 360, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 692, "seek": 171006, "start": 1717.58, "end": 1719.1799999999998, "text": " Intermediate with video graphics, not just text.", "tokens": [50740, 5751, 3130, 473, 365, 960, 11837, 11, 406, 445, 2487, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 693, "seek": 171006, "start": 1719.1799999999998, "end": 1720.1399999999999, "text": " So whole learning path,", "tokens": [50820, 407, 1379, 2539, 3100, 11, 50868], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 694, "seek": 171006, "start": 1720.1399999999999, "end": 1721.58, "text": " focus on the way of learning with custom graphics", "tokens": [50868, 1879, 322, 264, 636, 295, 2539, 365, 2375, 11837, 50940], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 695, "seek": 171006, "start": 1721.58, "end": 1722.74, "text": " to explain, yeah.", "tokens": [50940, 281, 2903, 11, 1338, 13, 50998], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 696, "seek": 171006, "start": 1722.74, "end": 1723.7, "text": " Well, and that's another thing too.", "tokens": [50998, 1042, 11, 293, 300, 311, 1071, 551, 886, 13, 51046], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 697, "seek": 171006, "start": 1723.7, "end": 1725.06, "text": " I mean, there's a book out there", "tokens": [51046, 286, 914, 11, 456, 311, 257, 1446, 484, 456, 51114], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 698, "seek": 171006, "start": 1725.06, "end": 1726.22, "text": " called Multiple Intelligences", "tokens": [51114, 1219, 40056, 18762, 328, 2667, 51172], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 699, "seek": 171006, "start": 1726.22, "end": 1729.5, "text": " and it talks about all the different ways that we learn.", "tokens": [51172, 293, 309, 6686, 466, 439, 264, 819, 2098, 300, 321, 1466, 13, 51336], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 700, "seek": 171006, "start": 1729.5, "end": 1731.98, "text": " Thomas, what's his name, Sir Ken.", "tokens": [51336, 8500, 11, 437, 311, 702, 1315, 11, 6144, 8273, 13, 51460], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 701, "seek": 171006, "start": 1731.98, "end": 1733.1399999999999, "text": " Sir Ken talks about this.", "tokens": [51460, 6144, 8273, 6686, 466, 341, 13, 51518], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 702, "seek": 171006, "start": 1733.1399999999999, "end": 1736.26, "text": " The woman who created the Juilliard Academy failed.", "tokens": [51518, 440, 3059, 567, 2942, 264, 13582, 31922, 515, 11735, 7612, 13, 51674], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 703, "seek": 171006, "start": 1736.26, "end": 1738.3799999999999, "text": " She failed out of all her classes", "tokens": [51674, 1240, 7612, 484, 295, 439, 720, 5359, 51780], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 704, "seek": 171006, "start": 1738.3799999999999, "end": 1739.62, "text": " and they took her to a specialist", "tokens": [51780, 293, 436, 1890, 720, 281, 257, 17008, 51842], "temperature": 0.0, "avg_logprob": -0.2298426511811047, "compression_ratio": 1.7366863905325445, "no_speech_prob": 0.0002377832861384377}, {"id": 705, "seek": 173962, "start": 1739.6599999999999, "end": 1741.02, "text": " and she was moving around", "tokens": [50366, 293, 750, 390, 2684, 926, 50434], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 706, "seek": 173962, "start": 1741.02, "end": 1744.34, "text": " and the specialist said to the parents, look at her.", "tokens": [50434, 293, 264, 17008, 848, 281, 264, 3152, 11, 574, 412, 720, 13, 50600], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 707, "seek": 173962, "start": 1744.34, "end": 1745.26, "text": " And she goes, what?", "tokens": [50600, 400, 750, 1709, 11, 437, 30, 50646], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 708, "seek": 173962, "start": 1745.26, "end": 1747.2199999999998, "text": " And he goes, she has to be moving.", "tokens": [50646, 400, 415, 1709, 11, 750, 575, 281, 312, 2684, 13, 50744], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 709, "seek": 173962, "start": 1747.2199999999998, "end": 1748.58, "text": " They got her in a special school", "tokens": [50744, 814, 658, 720, 294, 257, 2121, 1395, 50812], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 710, "seek": 173962, "start": 1748.58, "end": 1750.7399999999998, "text": " that was dynamic for dynamic learners", "tokens": [50812, 300, 390, 8546, 337, 8546, 23655, 50920], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 711, "seek": 173962, "start": 1750.7399999999998, "end": 1753.1799999999998, "text": " who were walking around, had to be moving to learning.", "tokens": [50920, 567, 645, 4494, 926, 11, 632, 281, 312, 2684, 281, 2539, 13, 51042], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 712, "seek": 173962, "start": 1753.1799999999998, "end": 1754.3, "text": " And she excelled.", "tokens": [51042, 400, 750, 45817, 292, 13, 51098], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 713, "seek": 173962, "start": 1754.3, "end": 1756.62, "text": " She excelled so much, she made the most,", "tokens": [51098, 1240, 45817, 292, 370, 709, 11, 750, 1027, 264, 881, 11, 51214], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 714, "seek": 173962, "start": 1756.62, "end": 1757.9799999999998, "text": " she made Juilliard Academy out of it.", "tokens": [51214, 750, 1027, 13582, 31922, 515, 11735, 484, 295, 309, 13, 51282], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 715, "seek": 173962, "start": 1757.9799999999998, "end": 1760.6999999999998, "text": " If they had written her off because of her learning style,", "tokens": [51282, 759, 436, 632, 3720, 720, 766, 570, 295, 720, 2539, 3758, 11, 51418], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 716, "seek": 173962, "start": 1760.6999999999998, "end": 1765.1, "text": " and that is one way that AI can adapt.", "tokens": [51418, 293, 300, 307, 472, 636, 300, 7318, 393, 6231, 13, 51638], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 717, "seek": 173962, "start": 1765.1, "end": 1766.3799999999999, "text": " I mean, everybody knows a teacher,", "tokens": [51638, 286, 914, 11, 2201, 3255, 257, 5027, 11, 51702], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 718, "seek": 173962, "start": 1766.3799999999999, "end": 1767.4599999999998, "text": " the best teachers in the world", "tokens": [51702, 264, 1151, 6023, 294, 264, 1002, 51756], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 719, "seek": 173962, "start": 1767.4599999999998, "end": 1769.4599999999998, "text": " are the ones who are able to adapt to the individual peak.", "tokens": [51756, 366, 264, 2306, 567, 366, 1075, 281, 6231, 281, 264, 2609, 10651, 13, 51856], "temperature": 0.0, "avg_logprob": -0.17912032387473367, "compression_ratio": 1.8498402555910542, "no_speech_prob": 0.00019106391118839383}, {"id": 720, "seek": 176946, "start": 1769.46, "end": 1771.22, "text": " Students, right?", "tokens": [50364, 17244, 11, 558, 30, 50452], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 721, "seek": 176946, "start": 1771.22, "end": 1773.74, "text": " And there's tons and tons of horrible teachers", "tokens": [50452, 400, 456, 311, 9131, 293, 9131, 295, 9263, 6023, 50578], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 722, "seek": 176946, "start": 1773.74, "end": 1775.14, "text": " who don't adapt at all.", "tokens": [50578, 567, 500, 380, 6231, 412, 439, 13, 50648], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 723, "seek": 176946, "start": 1775.14, "end": 1778.22, "text": " They stay in their methods, they do their thing.", "tokens": [50648, 814, 1754, 294, 641, 7150, 11, 436, 360, 641, 551, 13, 50802], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 724, "seek": 176946, "start": 1778.22, "end": 1781.1000000000001, "text": " It's like you adapt to them or you die and get an F", "tokens": [50802, 467, 311, 411, 291, 6231, 281, 552, 420, 291, 978, 293, 483, 364, 479, 50946], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 725, "seek": 176946, "start": 1781.1000000000001, "end": 1782.3, "text": " and you have to take it over again", "tokens": [50946, 293, 291, 362, 281, 747, 309, 670, 797, 51006], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 726, "seek": 176946, "start": 1782.3, "end": 1783.26, "text": " and spend all the money.", "tokens": [51006, 293, 3496, 439, 264, 1460, 13, 51054], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 727, "seek": 176946, "start": 1783.26, "end": 1784.8600000000001, "text": " There's plenty of that.", "tokens": [51054, 821, 311, 7140, 295, 300, 13, 51134], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 728, "seek": 176946, "start": 1784.8600000000001, "end": 1788.66, "text": " But if you, so the good teachers who adapt", "tokens": [51134, 583, 498, 291, 11, 370, 264, 665, 6023, 567, 6231, 51324], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 729, "seek": 176946, "start": 1788.66, "end": 1792.46, "text": " and make things engaging and change their methods", "tokens": [51324, 293, 652, 721, 11268, 293, 1319, 641, 7150, 51514], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 730, "seek": 176946, "start": 1792.46, "end": 1796.46, "text": " or allow God forbid one student to do one project", "tokens": [51514, 420, 2089, 1265, 34117, 472, 3107, 281, 360, 472, 1716, 51714], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 731, "seek": 176946, "start": 1796.46, "end": 1797.78, "text": " that's different than another student", "tokens": [51714, 300, 311, 819, 813, 1071, 3107, 51780], "temperature": 0.0, "avg_logprob": -0.15039752197265624, "compression_ratio": 1.7224334600760456, "no_speech_prob": 0.0019868307281285524}, {"id": 732, "seek": 179778, "start": 1797.78, "end": 1799.98, "text": " because of the way that they learn.", "tokens": [50364, 570, 295, 264, 636, 300, 436, 1466, 13, 50474], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 733, "seek": 179778, "start": 1799.98, "end": 1804.98, "text": " I mean, how do you set up a rubric for that?", "tokens": [50474, 286, 914, 11, 577, 360, 291, 992, 493, 257, 5915, 1341, 337, 300, 30, 50724], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 734, "seek": 179778, "start": 1807.94, "end": 1809.1399999999999, "text": " You can't.", "tokens": [50872, 509, 393, 380, 13, 50932], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 735, "seek": 179778, "start": 1809.1399999999999, "end": 1812.42, "text": " But if you have an AI, maybe an AI kind of thing", "tokens": [50932, 583, 498, 291, 362, 364, 7318, 11, 1310, 364, 7318, 733, 295, 551, 51096], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 736, "seek": 179778, "start": 1812.42, "end": 1816.06, "text": " is gonna get us into this closer to one-on-one education,", "tokens": [51096, 307, 799, 483, 505, 666, 341, 4966, 281, 472, 12, 266, 12, 546, 3309, 11, 51278], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 737, "seek": 179778, "start": 1816.06, "end": 1818.22, "text": " which is the holy grail.", "tokens": [51278, 597, 307, 264, 10622, 1295, 388, 13, 51386], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 738, "seek": 179778, "start": 1818.22, "end": 1820.58, "text": " One-on-one education has been the way humans", "tokens": [51386, 1485, 12, 266, 12, 546, 3309, 575, 668, 264, 636, 6255, 51504], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 739, "seek": 179778, "start": 1820.58, "end": 1823.96, "text": " have been learning best since the dawn of time.", "tokens": [51504, 362, 668, 2539, 1151, 1670, 264, 18192, 295, 565, 13, 51673], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 740, "seek": 179778, "start": 1823.96, "end": 1826.26, "text": " There's overwhelming evidence of this,", "tokens": [51673, 821, 311, 13373, 4467, 295, 341, 11, 51788], "temperature": 0.0, "avg_logprob": -0.13948731903636127, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002472236519679427}, {"id": 741, "seek": 182626, "start": 1826.26, "end": 1828.82, "text": " but nobody accepts that evidence", "tokens": [50364, 457, 5079, 33538, 300, 4467, 50492], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 742, "seek": 182626, "start": 1828.82, "end": 1832.6, "text": " because it's too impractical to do.", "tokens": [50492, 570, 309, 311, 886, 704, 1897, 804, 281, 360, 13, 50681], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 743, "seek": 182626, "start": 1832.6, "end": 1834.3, "text": " At least they say, I don't think it is.", "tokens": [50681, 1711, 1935, 436, 584, 11, 286, 500, 380, 519, 309, 307, 13, 50766], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 744, "seek": 182626, "start": 1834.3, "end": 1836.18, "text": " I think that if they were to actually economically,", "tokens": [50766, 286, 519, 300, 498, 436, 645, 281, 767, 26811, 11, 50860], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 745, "seek": 182626, "start": 1836.18, "end": 1838.58, "text": " I think they can make it work, but they don't.", "tokens": [50860, 286, 519, 436, 393, 652, 309, 589, 11, 457, 436, 500, 380, 13, 50980], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 746, "seek": 182626, "start": 1838.58, "end": 1839.7, "text": " And in order to make it work,", "tokens": [50980, 400, 294, 1668, 281, 652, 309, 589, 11, 51036], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 747, "seek": 182626, "start": 1839.7, "end": 1843.02, "text": " you'd have to have mentors adapted to a different,", "tokens": [51036, 291, 1116, 362, 281, 362, 21798, 20871, 281, 257, 819, 11, 51202], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 748, "seek": 182626, "start": 1843.02, "end": 1845.3, "text": " I mean, when you had back in the old days,", "tokens": [51202, 286, 914, 11, 562, 291, 632, 646, 294, 264, 1331, 1708, 11, 51316], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 749, "seek": 182626, "start": 1845.3, "end": 1847.58, "text": " it was like one-on-one and if that pairing didn't work,", "tokens": [51316, 309, 390, 411, 472, 12, 266, 12, 546, 293, 498, 300, 32735, 994, 380, 589, 11, 51430], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 750, "seek": 182626, "start": 1847.58, "end": 1849.54, "text": " you would find a different guru or a different master", "tokens": [51430, 291, 576, 915, 257, 819, 29949, 420, 257, 819, 4505, 51528], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 751, "seek": 182626, "start": 1849.54, "end": 1850.3799999999999, "text": " and you would go to that person.", "tokens": [51528, 293, 291, 576, 352, 281, 300, 954, 13, 51570], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 752, "seek": 182626, "start": 1850.3799999999999, "end": 1853.02, "text": " You would go to one person for their mastery in this thing", "tokens": [51570, 509, 576, 352, 281, 472, 954, 337, 641, 37951, 294, 341, 551, 51702], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 753, "seek": 182626, "start": 1853.02, "end": 1854.3, "text": " and another person in a mastery in this thing.", "tokens": [51702, 293, 1071, 954, 294, 257, 37951, 294, 341, 551, 13, 51766], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 754, "seek": 182626, "start": 1854.3, "end": 1856.18, "text": " That's true education.", "tokens": [51766, 663, 311, 2074, 3309, 13, 51860], "temperature": 0.0, "avg_logprob": -0.13751861660979514, "compression_ratio": 1.9022082018927444, "no_speech_prob": 0.0001233862858498469}, {"id": 755, "seek": 185618, "start": 1856.18, "end": 1859.78, "text": " And that's not happening in the traditional system,", "tokens": [50364, 400, 300, 311, 406, 2737, 294, 264, 5164, 1185, 11, 50544], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 756, "seek": 185618, "start": 1859.78, "end": 1861.38, "text": " but AI could potentially do it.", "tokens": [50544, 457, 7318, 727, 7263, 360, 309, 13, 50624], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 757, "seek": 185618, "start": 1861.38, "end": 1863.9, "text": " AI could potentially do it, it could.", "tokens": [50624, 7318, 727, 7263, 360, 309, 11, 309, 727, 13, 50750], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 758, "seek": 185618, "start": 1863.9, "end": 1866.3, "text": " Yeah, reviews on game writers versus 10 years ago.", "tokens": [50750, 865, 11, 10229, 322, 1216, 13491, 5717, 1266, 924, 2057, 13, 50870], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 759, "seek": 185618, "start": 1866.3, "end": 1868.9, "text": " Oh yeah, yes.", "tokens": [50870, 876, 1338, 11, 2086, 13, 51000], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 760, "seek": 185618, "start": 1868.9, "end": 1873.78, "text": " Yeah, based on consensus.", "tokens": [51000, 865, 11, 2361, 322, 19115, 13, 51244], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 761, "seek": 185618, "start": 1873.78, "end": 1875.22, "text": " Well, I think one of the things", "tokens": [51244, 1042, 11, 286, 519, 472, 295, 264, 721, 51316], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 762, "seek": 185618, "start": 1875.22, "end": 1878.5, "text": " that individual instruction like that is going to get both.", "tokens": [51316, 300, 2609, 10951, 411, 300, 307, 516, 281, 483, 1293, 13, 51480], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 763, "seek": 185618, "start": 1878.5, "end": 1883.5, "text": " This is something interesting about what I want to say here.", "tokens": [51480, 639, 307, 746, 1880, 466, 437, 286, 528, 281, 584, 510, 13, 51730], "temperature": 0.0, "avg_logprob": -0.2517533983503069, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.00015354987408500165}, {"id": 764, "seek": 188618, "start": 1886.38, "end": 1887.7, "text": " Homeschooling.", "tokens": [50374, 389, 18168, 21856, 278, 13, 50440], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 765, "seek": 188618, "start": 1887.7, "end": 1889.7, "text": " So that's, okay, so I live in the South, right?", "tokens": [50440, 407, 300, 311, 11, 1392, 11, 370, 286, 1621, 294, 264, 4242, 11, 558, 30, 50540], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 766, "seek": 188618, "start": 1889.7, "end": 1891.3400000000001, "text": " I live in North Carolina.", "tokens": [50540, 286, 1621, 294, 4067, 11480, 13, 50622], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 767, "seek": 188618, "start": 1891.3400000000001, "end": 1895.8600000000001, "text": " And ironically, there's extreme agreement", "tokens": [50622, 400, 41082, 11, 456, 311, 8084, 8106, 50848], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 768, "seek": 188618, "start": 1897.5, "end": 1901.94, "text": " between very, very right-wing conservatives", "tokens": [50930, 1296, 588, 11, 588, 558, 12, 7904, 39607, 51152], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 769, "seek": 188618, "start": 1901.94, "end": 1905.3400000000001, "text": " and very, very leftist progressives", "tokens": [51152, 293, 588, 11, 588, 1411, 468, 4205, 1539, 51322], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 770, "seek": 188618, "start": 1907.02, "end": 1909.02, "text": " on this topic of homeschooling.", "tokens": [51406, 322, 341, 4829, 295, 7388, 21856, 278, 13, 51506], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 771, "seek": 188618, "start": 1910.5, "end": 1912.22, "text": " Now, I don't know if that's a good thing or a bad thing,", "tokens": [51580, 823, 11, 286, 500, 380, 458, 498, 300, 311, 257, 665, 551, 420, 257, 1578, 551, 11, 51666], "temperature": 0.0, "avg_logprob": -0.15675787303758704, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006485998630523682}, {"id": 772, "seek": 191222, "start": 1912.26, "end": 1915.7, "text": " but they agree that the current system", "tokens": [50366, 457, 436, 3986, 300, 264, 2190, 1185, 50538], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 773, "seek": 191222, "start": 1915.7, "end": 1917.6200000000001, "text": " does not meet their needs.", "tokens": [50538, 775, 406, 1677, 641, 2203, 13, 50634], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 774, "seek": 191222, "start": 1917.6200000000001, "end": 1918.8600000000001, "text": " Now, the one people agree", "tokens": [50634, 823, 11, 264, 472, 561, 3986, 50696], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 775, "seek": 191222, "start": 1918.8600000000001, "end": 1920.54, "text": " because they don't think mathematics", "tokens": [50696, 570, 436, 500, 380, 519, 18666, 50780], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 776, "seek": 191222, "start": 1920.54, "end": 1921.74, "text": " and science are a priority", "tokens": [50780, 293, 3497, 366, 257, 9365, 50840], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 777, "seek": 191222, "start": 1921.74, "end": 1924.42, "text": " and that faith in Jesus is all that matters.", "tokens": [50840, 293, 300, 4522, 294, 2705, 307, 439, 300, 7001, 13, 50974], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 778, "seek": 191222, "start": 1924.42, "end": 1926.06, "text": " I was told that to my face", "tokens": [50974, 286, 390, 1907, 300, 281, 452, 1851, 51056], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 779, "seek": 191222, "start": 1926.06, "end": 1929.3, "text": " when my son was denied access to such a school", "tokens": [51056, 562, 452, 1872, 390, 17774, 2105, 281, 1270, 257, 1395, 51218], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 780, "seek": 191222, "start": 1929.3, "end": 1931.66, "text": " because he didn't have enough belief in Jesus", "tokens": [51218, 570, 415, 994, 380, 362, 1547, 7107, 294, 2705, 51336], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 781, "seek": 191222, "start": 1931.66, "end": 1934.22, "text": " according to their method, because we were Mormon.", "tokens": [51336, 4650, 281, 641, 3170, 11, 570, 321, 645, 39515, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 782, "seek": 191222, "start": 1934.22, "end": 1935.46, "text": " That's a true story.", "tokens": [51464, 663, 311, 257, 2074, 1657, 13, 51526], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 783, "seek": 191222, "start": 1937.82, "end": 1940.26, "text": " But they had, we thought more direct instruction", "tokens": [51644, 583, 436, 632, 11, 321, 1194, 544, 2047, 10951, 51766], "temperature": 0.0, "avg_logprob": -0.12494249425382696, "compression_ratio": 1.6768060836501901, "no_speech_prob": 0.0007553239120170474}, {"id": 784, "seek": 194026, "start": 1940.26, "end": 1942.54, "text": " would be better, but it turns out, no.", "tokens": [50364, 576, 312, 1101, 11, 457, 309, 4523, 484, 11, 572, 13, 50478], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 785, "seek": 194026, "start": 1942.54, "end": 1944.82, "text": " They literally told us math and sciences", "tokens": [50478, 814, 3736, 1907, 505, 5221, 293, 17677, 50592], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 786, "seek": 194026, "start": 1944.82, "end": 1946.82, "text": " are secondary to faith in Jesus.", "tokens": [50592, 366, 11396, 281, 4522, 294, 2705, 13, 50692], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 787, "seek": 194026, "start": 1946.82, "end": 1950.82, "text": " And we're like, okay, we'll be moving on now.", "tokens": [50692, 400, 321, 434, 411, 11, 1392, 11, 321, 603, 312, 2684, 322, 586, 13, 50892], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 788, "seek": 194026, "start": 1950.82, "end": 1952.62, "text": " And then you have the other people", "tokens": [50892, 400, 550, 291, 362, 264, 661, 561, 50982], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 789, "seek": 194026, "start": 1952.62, "end": 1955.42, "text": " who are all about the mass and the sciences", "tokens": [50982, 567, 366, 439, 466, 264, 2758, 293, 264, 17677, 51122], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 790, "seek": 194026, "start": 1955.42, "end": 1958.02, "text": " and playing in mud and stuff like that", "tokens": [51122, 293, 2433, 294, 8933, 293, 1507, 411, 300, 51252], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 791, "seek": 194026, "start": 1958.02, "end": 1959.62, "text": " in kind of the hippie education.", "tokens": [51252, 294, 733, 295, 264, 27745, 414, 3309, 13, 51332], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 792, "seek": 194026, "start": 1959.62, "end": 1961.1, "text": " And believe it or not,", "tokens": [51332, 400, 1697, 309, 420, 406, 11, 51406], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 793, "seek": 194026, "start": 1963.98, "end": 1967.26, "text": " so believe it or not, those two camps", "tokens": [51550, 370, 1697, 309, 420, 406, 11, 729, 732, 16573, 51714], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 794, "seek": 194026, "start": 1967.26, "end": 1968.66, "text": " both want the same thing.", "tokens": [51714, 1293, 528, 264, 912, 551, 13, 51784], "temperature": 0.0, "avg_logprob": -0.17775635883725924, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.004330781754106283}, {"id": 795, "seek": 196866, "start": 1968.66, "end": 1972.18, "text": " They want the government to get out of the way", "tokens": [50364, 814, 528, 264, 2463, 281, 483, 484, 295, 264, 636, 50540], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 796, "seek": 196866, "start": 1972.18, "end": 1974.18, "text": " when it comes to education", "tokens": [50540, 562, 309, 1487, 281, 3309, 50640], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 797, "seek": 196866, "start": 1974.18, "end": 1976.0600000000002, "text": " because they believe that education", "tokens": [50640, 570, 436, 1697, 300, 3309, 50734], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 798, "seek": 196866, "start": 1976.0600000000002, "end": 1977.18, "text": " can't be done properly", "tokens": [50734, 393, 380, 312, 1096, 6108, 50790], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 799, "seek": 196866, "start": 1977.18, "end": 1982.18, "text": " through any kind of singularly interested association", "tokens": [50790, 807, 604, 733, 295, 20010, 356, 3102, 14598, 51040], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 800, "seek": 196866, "start": 1982.5, "end": 1985.46, "text": " and all the problems that are coming up in education", "tokens": [51056, 293, 439, 264, 2740, 300, 366, 1348, 493, 294, 3309, 51204], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 801, "seek": 196866, "start": 1985.46, "end": 1987.42, "text": " are all related to this thing.", "tokens": [51204, 366, 439, 4077, 281, 341, 551, 13, 51302], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 802, "seek": 196866, "start": 1987.42, "end": 1990.7, "text": " I just don't know if it's a good thing or bad thing", "tokens": [51302, 286, 445, 500, 380, 458, 498, 309, 311, 257, 665, 551, 420, 1578, 551, 51466], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 803, "seek": 196866, "start": 1990.7, "end": 1994.02, "text": " to let people even get more in their sandbox.", "tokens": [51466, 281, 718, 561, 754, 483, 544, 294, 641, 42115, 13, 51632], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 804, "seek": 196866, "start": 1994.02, "end": 1996.66, "text": " I mean, I think, I don't know.", "tokens": [51632, 286, 914, 11, 286, 519, 11, 286, 500, 380, 458, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11573403795188833, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.00036824302515015006}, {"id": 805, "seek": 199666, "start": 1996.66, "end": 1998.8600000000001, "text": " I don't know, it's a really divisive topic.", "tokens": [50364, 286, 500, 380, 458, 11, 309, 311, 257, 534, 25974, 488, 4829, 13, 50474], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 806, "seek": 199666, "start": 2000.66, "end": 2003.1000000000001, "text": " Interested both South Carolina power stations", "tokens": [50564, 5751, 21885, 1293, 4242, 11480, 1347, 13390, 50686], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 807, "seek": 199666, "start": 2003.1000000000001, "end": 2003.94, "text": " have been talking this week.", "tokens": [50686, 362, 668, 1417, 341, 1243, 13, 50728], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 808, "seek": 199666, "start": 2003.94, "end": 2005.1000000000001, "text": " Oh, I know.", "tokens": [50728, 876, 11, 286, 458, 13, 50786], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 809, "seek": 199666, "start": 2005.1000000000001, "end": 2006.74, "text": " I know, I was here.", "tokens": [50786, 286, 458, 11, 286, 390, 510, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 810, "seek": 199666, "start": 2006.74, "end": 2008.3600000000001, "text": " Dude, I saw it.", "tokens": [50868, 12042, 11, 286, 1866, 309, 13, 50949], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 811, "seek": 199666, "start": 2008.3600000000001, "end": 2010.38, "text": " I don't want to talk about it right now.", "tokens": [50949, 286, 500, 380, 528, 281, 751, 466, 309, 558, 586, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 812, "seek": 199666, "start": 2010.38, "end": 2012.26, "text": " We can talk about that at a different time.", "tokens": [51050, 492, 393, 751, 466, 300, 412, 257, 819, 565, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 813, "seek": 199666, "start": 2012.26, "end": 2015.98, "text": " No, they confirmed it was an act of terrorism in our state.", "tokens": [51144, 883, 11, 436, 11341, 309, 390, 364, 605, 295, 23917, 294, 527, 1785, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 814, "seek": 199666, "start": 2015.98, "end": 2017.2, "text": " So we're Ireland now.", "tokens": [51330, 407, 321, 434, 15880, 586, 13, 51391], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 815, "seek": 199666, "start": 2018.8200000000002, "end": 2020.64, "text": " Yeah, it's in my state.", "tokens": [51472, 865, 11, 309, 311, 294, 452, 1785, 13, 51563], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 816, "seek": 199666, "start": 2020.64, "end": 2023.52, "text": " I'm seeing it on the news all the time.", "tokens": [51563, 286, 478, 2577, 309, 322, 264, 2583, 439, 264, 565, 13, 51707], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 817, "seek": 199666, "start": 2023.52, "end": 2024.96, "text": " It's not even far away.", "tokens": [51707, 467, 311, 406, 754, 1400, 1314, 13, 51779], "temperature": 0.0, "avg_logprob": -0.1612477336856101, "compression_ratio": 1.6130268199233717, "no_speech_prob": 0.0008295619045384228}, {"id": 818, "seek": 202496, "start": 2025.96, "end": 2028.2, "text": " Yeah, so we are Ireland.", "tokens": [50414, 865, 11, 370, 321, 366, 15880, 13, 50526], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}, {"id": 819, "seek": 202496, "start": 2028.2, "end": 2029.72, "text": " America is officially Ireland.", "tokens": [50526, 3374, 307, 12053, 15880, 13, 50602], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}, {"id": 820, "seek": 202496, "start": 2030.68, "end": 2035.68, "text": " We're getting attacked by domestic terrorists.", "tokens": [50650, 492, 434, 1242, 12692, 538, 10939, 28330, 13, 50900], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}, {"id": 821, "seek": 202496, "start": 2036.04, "end": 2038.24, "text": " They took out our power grid for two days.", "tokens": [50918, 814, 1890, 484, 527, 1347, 10748, 337, 732, 1708, 13, 51028], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}, {"id": 822, "seek": 202496, "start": 2039.1200000000001, "end": 2042.3600000000001, "text": " Yep, let's talk about that another time.", "tokens": [51072, 7010, 11, 718, 311, 751, 466, 300, 1071, 565, 13, 51234], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}, {"id": 823, "seek": 202496, "start": 2042.3600000000001, "end": 2044.3600000000001, "text": " I don't know if AI is gonna help with that.", "tokens": [51234, 286, 500, 380, 458, 498, 7318, 307, 799, 854, 365, 300, 13, 51334], "temperature": 0.0, "avg_logprob": -0.3270722902738131, "compression_ratio": 1.369047619047619, "no_speech_prob": 0.0006460589356720448}], "language": "en"}