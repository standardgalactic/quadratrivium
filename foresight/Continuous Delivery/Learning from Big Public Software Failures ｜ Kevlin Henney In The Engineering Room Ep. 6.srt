1
00:00:00,000 --> 00:00:03,200
Hi, my name is Dave Farley and welcome to The Engineering Room.

2
00:00:03,200 --> 00:00:07,760
If you haven't been here before, do hit subscribe and if you enjoy the content today,

3
00:00:07,760 --> 00:00:13,520
hit like as well. Do join in the conversation too and let us know your thoughts and ideas in the

4
00:00:13,520 --> 00:00:18,640
comments below. The Engineering Room is an occasional series and is meant as an addition

5
00:00:18,640 --> 00:00:23,840
to the more usual content on the Continuous Delivery channel. These are longer form conversations

6
00:00:23,840 --> 00:00:29,280
with some influential and thoughtful people from our industry. Today I'm joined by my

7
00:00:29,280 --> 00:00:35,040
friend Kevlin Henney. I first came across Kevlin at a conference in Australia many years ago,

8
00:00:35,040 --> 00:00:40,880
although we're both English. He gave several talks at that conference, including a keynote,

9
00:00:40,880 --> 00:00:47,600
which was funny, unexpected, educational and brilliantly well presented. Over the years,

10
00:00:47,600 --> 00:00:52,960
I've come to expect nothing less than that from Kevlin. That's his norm. As I started talking

11
00:00:52,960 --> 00:00:57,440
more frequently at conferences, our paths crossed more often and we became friends.

12
00:00:57,440 --> 00:01:02,160
Kevlin is an independent software development consultant, trainer, speaker and writer.

13
00:01:02,160 --> 00:01:08,320
The people who work with Kevlin always speak very highly of his services. He's witty, nerdy, sorry,

14
00:01:08,320 --> 00:01:14,560
Kevlin, and smart. He also has a Google unique name. Try it. You'll only get Kevlin.

15
00:01:15,280 --> 00:01:21,840
And rather strangely, among the cognizanty, if you ever see an obvious public software failure,

16
00:01:21,840 --> 00:01:26,640
a screen in an airport showing a command line or an advert in a stall showing the blue screen of

17
00:01:26,640 --> 00:01:33,040
death, it's called a Kevlin Henney. But no doubt we'll get to that. Welcome, Kevlin. Did I miss

18
00:01:33,040 --> 00:01:38,800
anything important? No, thank you very much, Tim. That's the perfect introduction. I'm going to copy

19
00:01:38,800 --> 00:01:46,160
and paste that. Great. Thanks. Well, I've been looking forward to this talk for a little while.

20
00:01:46,160 --> 00:01:53,600
The last time we met was in Copenhagen at a go-to conference. And my wife and family

21
00:01:54,560 --> 00:01:57,520
took the mickey out of me for the rest of the conference, because you and I, every time we

22
00:01:57,520 --> 00:02:04,000
crossed, we spent all of the time talking rapidly in great detail because we hadn't seen each other

23
00:02:04,000 --> 00:02:08,560
for a while. But the funny thing is, the way that coincidences worked out is that

24
00:02:09,280 --> 00:02:14,560
pretty much the moment I arrived in the hotel, you and family were there, and I bumped into

25
00:02:14,560 --> 00:02:20,000
everybody, including your son and daughter-in-law at the airport when I left. It's crossed quite a

26
00:02:20,000 --> 00:02:28,080
lot there. So yeah, plenty to talk about, plenty to catch up on. Cool. So let's start with that

27
00:02:28,080 --> 00:02:32,720
production failure being called a Kevlin Henney. I think I know the answer to this, but tell us how

28
00:02:32,720 --> 00:02:39,680
that happens. Yeah, well, so it's one of the things. I guess if you're in software or there's

29
00:02:39,680 --> 00:02:43,920
something that you really into, you become sensitive to things. You start spotting things.

30
00:02:43,920 --> 00:02:49,920
And I was always fascinated by the fact that, you know, see occasional failures in places,

31
00:02:49,920 --> 00:02:56,400
you occasionally see a cash machine booting up and stuff like that. You kind of notice this stuff,

32
00:02:56,400 --> 00:03:01,360
it makes you ask questions about it. But then we hit the, then we hit the kind of like,

33
00:03:02,800 --> 00:03:08,160
cameras on phones era. And at that point, suddenly, it's like, I'm walking, everywhere I'm walking,

34
00:03:08,160 --> 00:03:12,080
I have a camera. And, you know, the amount of software that we actually have everywhere

35
00:03:12,080 --> 00:03:16,480
is huge. So I'm starting to take pictures of these things. I'm also taking screenshots

36
00:03:16,480 --> 00:03:21,360
whenever something crashes, particularly if it's losing my work, I'll take a screenshot.

37
00:03:22,800 --> 00:03:27,680
Hold on to that because I think it's fascinating because it's kind of like, okay, it's often

38
00:03:27,680 --> 00:03:31,520
frustrating, but it's fascinating. It's just like, okay, I mean, this is my space. I'm in

39
00:03:31,520 --> 00:03:38,240
software that collectively we somehow created this. And I'm fond of noting that we, as in

40
00:03:38,240 --> 00:03:43,920
software development, are the largest creators of kind of gorilla installation art on the planet.

41
00:03:43,920 --> 00:03:48,720
Nobody else comes close, you know? But I used to kind of collect these. And occasionally,

42
00:03:48,720 --> 00:03:52,960
I kind of put them in talks or when running a workshop or training course, I kind of have them

43
00:03:52,960 --> 00:04:00,080
on my screen, just like as a screensaver in the breaks always causes conversation. And I always

44
00:04:00,080 --> 00:04:05,600
pointed out, oh, this is really interesting because in failure, when something fails,

45
00:04:05,680 --> 00:04:08,560
you learn about something, you learn something about how it was constructed.

46
00:04:09,360 --> 00:04:12,720
You know, it's kind of like at that moment, you lose all the encapsulation, you're presented

47
00:04:12,720 --> 00:04:17,520
with something when it works that is beautiful and pristine and pixel perfect, and it offers

48
00:04:17,520 --> 00:04:22,800
some kind of user experience. And maybe you can guess the technology, but most of the time,

49
00:04:22,800 --> 00:04:27,280
you can't. And then it's like you drop something on the floor and it fractures. And it's just like,

50
00:04:27,280 --> 00:04:32,160
oh, look, this bit's made of C sharp, or they're using that as part of their stack, or I'm pretty

51
00:04:32,160 --> 00:04:37,760
sure that's out of support now, or whatever it is, you see it loses its encapsulation, it loses

52
00:04:37,760 --> 00:04:43,200
that kind of like surface, and we see the insides. And if it doesn't tell us directly how it was built,

53
00:04:43,200 --> 00:04:48,080
it kind of invites questions, it makes you go, oh, I wonder what, how did this arise? Did they

54
00:04:48,080 --> 00:04:52,800
forget to put a tri block here? Did they forget, you know, how did this exception escape to the user?

55
00:04:54,400 --> 00:04:57,840
But, you know, I just did that kind of as a point of fun as a point of personal interest

56
00:04:57,840 --> 00:05:02,720
and point of showing people, and then people started sending me these things by email.

57
00:05:03,520 --> 00:05:09,200
And then we hit social media era, people start sharing it more directly. And then it's Twitter,

58
00:05:09,200 --> 00:05:15,760
and people are just like posting it and just adding me, then I start retweeting it. And then

59
00:05:15,760 --> 00:05:19,600
that's how that's where the that's where it acquired its name, and they actually made its way

60
00:05:19,600 --> 00:05:26,320
into urban dictionary, the register and a bunch of other things. So, so yeah, it's just one of

61
00:05:26,320 --> 00:05:31,600
those things. And the incidental side effect is it is one, it's interesting. I find it's still

62
00:05:31,600 --> 00:05:35,760
fascinating. I think there's a kind of a humor to it, as well as a serious point to be made

63
00:05:35,760 --> 00:05:40,480
in all of these things. It also ends up being an accidental service, because sometimes you're

64
00:05:40,480 --> 00:05:46,320
talking about rail services and train stations and things like that. And often people will

65
00:05:46,320 --> 00:05:51,520
at the train company as well, wherever they are in the world. And, you know, you can tell what

66
00:05:51,520 --> 00:05:55,920
the customer service is like, because often they'll go, oh, you know, instantly jump on that,

67
00:05:55,920 --> 00:05:59,760
say which station was this, I'm really sorry this happened, or there'll be just silence. And so you

68
00:05:59,760 --> 00:06:04,320
can kind of tell that you get a sense of the customer experience as well as the failure experience.

69
00:06:05,360 --> 00:06:08,640
That's brilliant. So, so kind of the archaeology of failure.

70
00:06:09,680 --> 00:06:11,280
Yeah, yeah, that's exactly it. Yeah.

71
00:06:13,040 --> 00:06:19,760
That's great. I often think that we kind of we don't, well, I don't think just think I know,

72
00:06:20,320 --> 00:06:26,480
we don't think too much about the failure failure routes so often. There's one of my

73
00:06:26,480 --> 00:06:34,400
favorite quotable bits of research was a usenix survey from a few years ago that looked into

74
00:06:34,400 --> 00:06:41,120
the cause of production failures. And something like 60% of production failures are in the error

75
00:06:41,120 --> 00:06:46,320
handling path. The most common line of code in the event of a production failure is a comment

76
00:06:46,320 --> 00:06:52,720
saying should should do some exception handling here. Yeah, yeah. That's a really interesting

77
00:06:52,720 --> 00:06:58,240
because that one, if it's the if it's the one I'm thinking of that was 2014 paper. But

78
00:06:59,360 --> 00:07:03,520
but there's probably been others. But I think I first came across that somebody did a study

79
00:07:04,160 --> 00:07:08,800
the late 90s early 2000s. I really can't I'm fortunate I can't cite it. I can't remember

80
00:07:08,800 --> 00:07:14,480
who it was. But they did an analysis of failures in the Linux kernel. And they said it's mostly

81
00:07:14,480 --> 00:07:19,680
on the error paths. Yeah, you know, the dark alleyways that just don't get explored and tested

82
00:07:19,680 --> 00:07:23,520
anywhere near as often, you know, happy day works out fine. But these edge cases,

83
00:07:24,400 --> 00:07:31,040
something goes wrong. And then either it was just like this was to do, or somebody had an idea of

84
00:07:31,040 --> 00:07:35,840
like, well, it should be something like this, but it was never really tested. And it kind of got

85
00:07:35,840 --> 00:07:41,760
marginalized in their in their memory. And now, you know, control flows wandering down this dark

86
00:07:41,760 --> 00:07:46,080
path that's been untested to deal with a really bad situation. And the situation gets worse,

87
00:07:46,080 --> 00:07:50,080
you know, it's one of those things. And that that that seems to be a recurring theme that

88
00:07:50,880 --> 00:07:55,920
these edge cases, it's kind of, you know, when you're at the edge case, it's not an edge case

89
00:07:55,920 --> 00:08:01,520
anymore. It's your world. Yeah, yeah. Yeah. It's one of the things one of the things I did some

90
00:08:01,520 --> 00:08:07,600
research for my book into the kind of history of software engineering. And of course, Margaret

91
00:08:07,600 --> 00:08:14,640
Hamilton was a huge, you know, a hero in in in that in that field in the early days of that.

92
00:08:14,640 --> 00:08:19,600
One of the things I loved that she that she went on about was talking about the importance of the

93
00:08:19,600 --> 00:08:23,760
systems that she was working on the flight control systems for for the Apollo missions,

94
00:08:24,320 --> 00:08:31,520
being man rated. And so the reason why she coined the term software engineering was to

95
00:08:31,520 --> 00:08:35,440
because they were spending all of their time worrying about how things could go wrong,

96
00:08:35,760 --> 00:08:40,400
like engineers do, you know, you don't build a bridge and just only worry about happy days,

97
00:08:40,400 --> 00:08:45,040
you worry about when there's a storm or when the load's too heavy or all of those kinds of things

98
00:08:45,040 --> 00:08:50,800
too. And we we need to be thinking the same for building, you know, serious software systems.

99
00:08:50,800 --> 00:08:54,160
Yeah, I think I think a lot of the stories around Margaret Hamilton, absolutely brilliant. I mean,

100
00:08:54,160 --> 00:08:57,440
the fact that, you know, there's one where she brought a daughter into work, you know,

101
00:08:58,320 --> 00:09:02,960
one day and daughter recreated an error or created an error condition just by messing

102
00:09:02,960 --> 00:09:06,880
about with it, put it into a state, you know, it's just like, you know, cats and children.

103
00:09:09,120 --> 00:09:14,320
And, you know, and other cases where, you know, these, you know, the kind of the classic

104
00:09:15,520 --> 00:09:20,240
certain McKismar associated with the fact that at that point, all astronauts would have been

105
00:09:20,800 --> 00:09:25,680
Air Force pilots, and the culture and image that went with that is like, oh, these highly trained

106
00:09:25,680 --> 00:09:31,680
people. And they won't make mistakes like that. And then promptly one of them does. And it's just

107
00:09:31,840 --> 00:09:36,880
they go back to her. It's like, yeah, let's do that. Let's put that failure. Because it doesn't

108
00:09:36,880 --> 00:09:40,800
matter that they're highly trained, the most the operative word in that sentence is people.

109
00:09:44,880 --> 00:09:50,480
High train gets you so far, but you're still ultimately human. And I think that that and one

110
00:09:50,480 --> 00:09:54,880
of the other points that I read that Margaret Hamilton talked about is she was trying to really

111
00:09:54,880 --> 00:10:00,960
get a seat at the table, as it were, because you put it certainly at that era. This whole idea

112
00:10:01,040 --> 00:10:07,920
that software could form a viable, meaningful first class component of a system, as opposed to just

113
00:10:07,920 --> 00:10:15,520
a secondary component was that was completely a foreign concept. And, you know, there were even

114
00:10:15,520 --> 00:10:19,600
astronauts saying, well, we don't think we're going to need software. We don't actually need

115
00:10:19,600 --> 00:10:25,920
software to land on the moon. And, you know, it's to anybody who's either studied the physics of

116
00:10:26,000 --> 00:10:30,960
it or is familiar with any of the modern stuff around this. It's just like, yeah, you can't

117
00:10:30,960 --> 00:10:35,920
just fly by the seat of your pants and that's going to work out. You need this stuff. And so

118
00:10:35,920 --> 00:10:42,400
she wanted their seat at the table. Engineering was the term that she chose. We've got to treat

119
00:10:42,400 --> 00:10:47,520
this in that sense. It's up there with all the others. Because this is not just icing on the

120
00:10:47,520 --> 00:10:52,800
cake. This is not just a glorified slide rule. There's something deeper and more fundamental

121
00:10:52,880 --> 00:10:59,680
here. We're talking about control systems and data that is genuinely life critical. You know,

122
00:10:59,680 --> 00:11:05,360
this is not just a slide rule. This is beyond that. It's the idea of it's not just a calculator,

123
00:11:05,360 --> 00:11:09,280
whereas I think many people thought of this as just extension of the calculator.

124
00:11:09,840 --> 00:11:18,240
Yes. Yeah, absolutely. Brilliant woman and a real pioneer in our field, I think.

125
00:11:18,960 --> 00:11:27,200
Yeah. Yeah, definitely. But I think that's one of the things that I found with because one of

126
00:11:27,200 --> 00:11:34,080
the other things that we had this term, engineering that kind of took off from different points.

127
00:11:34,080 --> 00:11:43,040
And I've seen it misattributed. So I've seen things where people said, oh, the NATO sponsored

128
00:11:43,040 --> 00:11:47,760
1968 software engineering conference was the beginning coined the term. No, no, no, no.

129
00:11:47,760 --> 00:11:54,080
They use the term because it was already around. Margaret Hamilton initiated that. I think I

130
00:11:54,080 --> 00:11:58,960
stumbled across a bit in communications at the ACM that it was used as a term in 1966

131
00:11:59,600 --> 00:12:04,720
in there. And in other words, there's a kind of a lineage. So by the time the conference came around,

132
00:12:06,800 --> 00:12:14,400
this term was currency. And it existed. And that was trying to try and say, well,

133
00:12:14,400 --> 00:12:23,040
what does this look like if it's for software? I know you looked at it for your book and I did

134
00:12:23,040 --> 00:12:29,200
it for, I did a whole load of talks in 2018 because it was 50 years on. So I thought I'd be in a

135
00:12:29,200 --> 00:12:33,760
series to 1968. I thought, you know what, I'm going to go and read, I'm going to actually go and read

136
00:12:33,760 --> 00:12:43,360
end to end the whole proceedings and also look at the 1969 one as well. But do that. And I did

137
00:12:43,440 --> 00:12:47,440
that a couple of years beforehand. And I found it absolutely fascinating because one, it's an

138
00:12:47,440 --> 00:12:54,320
amazing historical document capturing some really interesting insights. But also, there was a real

139
00:12:54,320 --> 00:13:00,800
sense that one of the things is, you know, some of it is incredibly dated, because, you know,

140
00:13:00,800 --> 00:13:06,000
it does date because they're talking about technical constraints and concepts from the 60s.

141
00:13:06,000 --> 00:13:10,160
But at other times, it's just like, oh, yeah, you know, it's not that you agreed on everything,

142
00:13:10,160 --> 00:13:17,520
but all of the ideas that we now debate and push forward were present. They were there,

143
00:13:17,520 --> 00:13:23,600
they were alive. Yes. And problems that those people were facing in building real systems,

144
00:13:23,600 --> 00:13:28,080
even though the computers that they were building them for are all in museums now. You know, it's

145
00:13:31,120 --> 00:13:36,320
one of the things that got me interested in kind of talking about engineering in my book and stuff

146
00:13:36,320 --> 00:13:42,000
was that, you know, I think that we discard some of those really durable ideas too readily,

147
00:13:42,000 --> 00:13:46,320
that there are things at the heart of our profession. I think the most important things

148
00:13:46,320 --> 00:13:52,000
about our profession that are that haven't changed since the 1960s. And as you said,

149
00:13:52,000 --> 00:13:57,440
you know, I had hair standing up on the back of my neck when I was reading stuff by Alan Perlis

150
00:13:58,080 --> 00:14:03,360
describing in language that sounded quite dated in many words, his choice of words sounded like

151
00:14:03,360 --> 00:14:09,920
somebody from the 1960s. But nevertheless, he was expressing ideas that would that still too many

152
00:14:09,920 --> 00:14:14,880
software development teams don't even think about doing to their detriment. Yeah. And

153
00:14:17,040 --> 00:14:23,040
crazy. Yeah. And I think there's a really interesting things in there about, you know,

154
00:14:23,040 --> 00:14:26,960
that a lot was up for discussion, but also sometimes some of the discussions were that

155
00:14:26,960 --> 00:14:31,120
they're talking like old hands, you know, they're talking about 10 years, like it's a really bad

156
00:14:31,920 --> 00:14:35,360
so that's the fascinating thing about doing this talk 50 years later is just like, well,

157
00:14:35,360 --> 00:14:40,880
they thought they were it was old hat when they did 10 years in, we're half a century on how we

158
00:14:40,880 --> 00:14:47,040
do it here, you know, and, you know, there's some really, really interesting things. So from my

159
00:14:47,040 --> 00:14:52,960
perspective, one of the things I'm very interested in is testing. And interestingly, before reading

160
00:14:52,960 --> 00:15:00,080
that, I had kind of presumed that unit testing as a term, I kind of I kind of dated that to the

161
00:15:00,080 --> 00:15:08,480
1970s. I found, you know, I hadn't tried and really pursued it back in time. But 1970s was

162
00:15:08,480 --> 00:15:12,160
what I had in my mind based on what I'd read. And I thought, you know, that would that be

163
00:15:12,160 --> 00:15:16,480
terminology. But you I look at the software engineering, look at software engineering

164
00:15:17,280 --> 00:15:21,520
proceedings. And there it is, the term unit testing is there without qualification or

165
00:15:21,520 --> 00:15:25,840
definition. In other words, it's not presented as here as a new idea. It's presented as, Oh,

166
00:15:25,840 --> 00:15:32,400
okay. I assume everybody knows it. Yeah. And it was really interesting, just looking at certain

167
00:15:32,400 --> 00:15:42,960
ideas like that. As well as some other historical kind of foreshadowings. So a number of years ago,

168
00:15:42,960 --> 00:15:49,440
I was quite heavily involved in the patents community. There are a number of elements in

169
00:15:49,440 --> 00:15:53,520
the patents community that and patents thinking, which I think have been hugely neglected for me,

170
00:15:53,520 --> 00:15:59,040
one of the most the real turn ons with the whole idea of really understanding. This is a pattern.

171
00:15:59,040 --> 00:16:05,760
It is not a it's not a principle. It is not a universal. Here is an idea. And you know what,

172
00:16:05,760 --> 00:16:11,120
sometimes this this works in some cases and not in others. And here's why. And people often miss

173
00:16:11,120 --> 00:16:17,040
that they kind of kind of latched onto the surface as it were, but not really understood the death.

174
00:16:17,040 --> 00:16:22,960
And for me, the huge, the huge influence was the trade offs, understand the trade offs. Here

175
00:16:22,960 --> 00:16:28,560
it's just like, Ah, here we go. Here is here is why this works well here, but doesn't overheard

176
00:16:28,560 --> 00:16:34,880
the context dependence of the idea was absolutely huge. So rather than talking about software from

177
00:16:34,880 --> 00:16:40,160
the perspective of mathematics in which, which is a time, which is timeless and universal and

178
00:16:40,160 --> 00:16:45,200
rest of it, here was something that was hugely dependent on, well, I can't tell you what's right.

179
00:16:45,840 --> 00:16:49,280
You know, somebody says, is this the right way? Or is this wrong? It's just like, well,

180
00:16:49,280 --> 00:16:52,560
you know, it's going to be that it depends. And that's not because I'm being a consultant. It's

181
00:16:52,560 --> 00:16:56,800
because genuinely, there are about three or four different ways of doing this. Yeah, show me the

182
00:16:56,800 --> 00:17:00,400
landscape. You know, you've got to show me the landscape that you're going to you're going to

183
00:17:00,400 --> 00:17:04,880
put this into my answer will be different if you're dealing with a legacy system, perhaps

184
00:17:04,880 --> 00:17:10,640
with a modern system, it'll vary from language to language, depending on certain elements.

185
00:17:10,640 --> 00:17:16,800
But there might be broader ideas that are still stable. But you know, there are, if you say, oh,

186
00:17:16,800 --> 00:17:20,480
this is in a multi-threaded environment, then I might retract my previous answer and go,

187
00:17:20,960 --> 00:17:25,200
actually, we're going to take a different path here. And it's the contextuality and

188
00:17:25,200 --> 00:17:31,440
understanding the trade offs. For me, that was really exciting. Now, we tend to, for a lot of

189
00:17:31,440 --> 00:17:37,840
people, they tend to credit the gang of four, Gamma, Helen, Johnson, Felicides with the pattern

190
00:17:37,840 --> 00:17:42,400
stuff. Now, certainly that initially turned me on. But even before the book was published,

191
00:17:42,400 --> 00:17:47,200
I'd heard about this stuff. But it was this other stuff that was going on inside. This comes from

192
00:17:47,200 --> 00:17:51,360
architecture. This doesn't come from software. This comes from architecture. And Christopher

193
00:17:51,360 --> 00:17:57,520
Alexander kind of originated this idea is this whole idea of he was really big on the idea of

194
00:17:57,520 --> 00:18:00,800
you've got to have an empirical design. In other words, he was trying to move,

195
00:18:02,080 --> 00:18:05,280
he was trying to move building architecture away from fashion.

196
00:18:08,000 --> 00:18:11,680
Which is something I think we get plagued with in software as well. He was trying to say, well,

197
00:18:11,680 --> 00:18:14,720
look, there's an empirical solution to this. Does it work? You know, here are the qualities

198
00:18:14,720 --> 00:18:19,920
that make something work. No, have you defined your problem? Does this solve the problem of

199
00:18:19,920 --> 00:18:24,960
living or whatever context he was looking at? And he was very clear, use the language of empiricism

200
00:18:24,960 --> 00:18:29,440
all the way through. This is not to say there were no artistic qualities to it. But I was always

201
00:18:29,440 --> 00:18:34,240
fascinated. And his writing style, again, it catches the time is 1970. So I started reading

202
00:18:34,240 --> 00:18:38,240
all the Christopher Alexander stuff. And then you eventually hear another book by Christopher

203
00:18:38,240 --> 00:18:44,880
Alexander notes on the synthesis of form, which was published in 1964. And I had a vague awareness

204
00:18:44,880 --> 00:18:50,480
that this had a big influence on a lot of disciplines at the time. But rereading reading

205
00:18:50,480 --> 00:18:55,920
the 1968 NATO software engineering proceedings was fascinating, because they kept referring to

206
00:18:55,920 --> 00:19:01,200
Christopher Alexander. But this predates his patterns work. It was all synthesis to form about

207
00:19:01,200 --> 00:19:06,800
how he thought about design in terms of balance and trade offs and, and, you know, sort of isolating

208
00:19:06,880 --> 00:19:10,560
systems of change from one another and all the rest was hugely, hugely influential.

209
00:19:12,400 --> 00:19:16,480
But kind of, kind of forgotten that kind of got buried there. So this kind of there's this

210
00:19:16,480 --> 00:19:22,160
little capsule into the kind of like, kind of the zeitgeist of the 60s, and design thinking

211
00:19:22,160 --> 00:19:27,920
of all this kind of stuff, Conway gets mentioned, Melvin Conway, and this influence on architecture

212
00:19:27,920 --> 00:19:33,040
of like, you know what, the way that your people communicate, it's going to have a huge exertive

213
00:19:33,040 --> 00:19:37,760
force on the structure that you build, how you communicate is going to is going to influence

214
00:19:37,760 --> 00:19:44,080
that because this is not maths. This is, we're creating a thing. And, and our choice of creation

215
00:19:44,080 --> 00:19:49,920
is going to be influenced by how we talk to one another. And there, again, this gets multiple

216
00:19:49,920 --> 00:19:55,600
references throughout the software engineering proceedings, which I think I think, I think,

217
00:19:55,600 --> 00:20:01,120
I think that's, I think that's, that's deeply entwined in terms, in terms embedded really in,

218
00:20:01,600 --> 00:20:12,080
what engineering really means. I must confess, I, you know, I'm, I, I love maths. I enjoy,

219
00:20:12,080 --> 00:20:17,920
I actively enjoy maths and sometimes do math, solve mathematical problems as a hobby, you know,

220
00:20:17,920 --> 00:20:24,320
but I don't think that what we do is maths. I don't, I don't, it's, it's, it appeals to

221
00:20:24,320 --> 00:20:30,080
mathematical thinkers. But one of the differences between engineering and maths is that engineering

222
00:20:30,080 --> 00:20:37,200
has that pragmatic bent, you know, so if, if you could simulate an aeroplane, the design of an

223
00:20:37,200 --> 00:20:42,000
aeroplane and wholly do that, you know, in a simulated form and just build the aeroplane and

224
00:20:42,000 --> 00:20:48,080
then take passengers, you know, people would do that, but they don't, they do that. And then

225
00:20:48,080 --> 00:20:51,920
they go flying. And certainly, if you're Boeing, I don't know whether, I don't know if they still

226
00:20:51,920 --> 00:20:56,640
do it, but certain for a very long time, the engineers that built the aeroplane were amongst

227
00:20:56,640 --> 00:21:03,040
the first passengers after the test pilot went up to go for a ride in the aeroplane that they

228
00:21:03,040 --> 00:21:08,320
designed. So there's, there's, there's this thing of, of, you know, trying stuff out. And I think

229
00:21:08,320 --> 00:21:13,520
that's one of the principles that I get a little frustrated sometimes with people talking about,

230
00:21:14,080 --> 00:21:19,360
you know, the mathematical nature of programming. It's interesting. It's fascinating. I like,

231
00:21:19,360 --> 00:21:23,440
I like thinking in those sorts of terms, but I don't think that's enough because I think it's

232
00:21:23,440 --> 00:21:28,960
usually harder to be able to write something that's, you know, a provable system than it,

233
00:21:29,600 --> 00:21:34,320
than it is to write the system in the first place. And so you more, it's almost more error prone.

234
00:21:34,320 --> 00:21:39,120
So, you know, it's, it's, it's a complex problem. I was, I was just listening to the radio

235
00:21:41,040 --> 00:21:48,240
today about, actually, I was listening to a podcast from new scientists and they were saying

236
00:21:48,880 --> 00:21:56,000
they've just rejected one of the quantum, supposedly quantum computing proof

237
00:21:57,360 --> 00:22:01,200
encryption algorithms, because somebody managed to break it on their laptop.

238
00:22:05,120 --> 00:22:11,840
And you'd think that'd be a fairly mathematical kind of area of software. So, so, so when we're

239
00:22:11,840 --> 00:22:17,920
building flight control systems or, or car control systems, or even your stock control system,

240
00:22:19,040 --> 00:22:23,680
there's still room for all those human errors and mistakes. Yeah. And, and, and, and, you know,

241
00:22:23,680 --> 00:22:29,280
Margaret Hamilton's little girl to come in and, and screw it up in new and interesting ways.

242
00:22:29,280 --> 00:22:32,480
And I think, I think that's a really important thing because it's, it's, it's,

243
00:22:32,480 --> 00:22:36,240
because this kind of whole point about kind of perspectives of when we look at things,

244
00:22:37,200 --> 00:22:44,000
that how do we reason about them? And that the, it's a distinction I made a number of years ago is

245
00:22:44,080 --> 00:22:50,800
that, you know, software, there are lots of elements of it that are mathematical, but are not

246
00:22:50,800 --> 00:22:55,440
the same as math, you know, but not mathematics. There's a distinction there. So engineering is

247
00:22:55,440 --> 00:23:00,000
not mathematics, but it is mathematical. In other words, it draws very heavily, uses it as a tool,

248
00:23:00,000 --> 00:23:04,160
and that tool can also give us further insights, but they are not an equivalence. There's not,

249
00:23:04,160 --> 00:23:09,360
you know, and that's, and that's a really important distinction. And that idea of,

250
00:23:10,080 --> 00:23:14,080
yes, but when I throw it, does it stick? You know, that kind of stuff is the real thing.

251
00:23:14,080 --> 00:23:19,920
But when, when we actually, you know, yeah, sure, this works in the simulation, but it's, you know,

252
00:23:19,920 --> 00:23:29,280
it's, it's, it's this, it's like, let's, let's take it back to the 80s. Aliens. And, you know,

253
00:23:29,280 --> 00:23:32,320
being asked, you know, how many, how many actual, how many combat drops have you done?

254
00:23:33,280 --> 00:23:37,360
And then we get one answer is like, and then the follows on simulated. It's just like,

255
00:23:38,320 --> 00:23:42,880
okay, there's a big distinction here. You know, you've actually, you know, this is your first

256
00:23:42,880 --> 00:23:48,880
time in properly in the field is a big distinction. So in other words, there's that whole kind of

257
00:23:48,880 --> 00:23:54,800
idea of like the math. And, and I think for, I think for software, the term, there's a lot of

258
00:23:54,800 --> 00:24:00,080
mathematics that is in bits, there are things that are genuine mathematics, there's a lot that

259
00:24:00,080 --> 00:24:04,560
is mathematical, but the better way of looking at it is formal. Now, I don't want to get that wrapped

260
00:24:04,560 --> 00:24:09,040
up with all methods, because that's clearly an important subset, but it's formalized. And I was,

261
00:24:09,040 --> 00:24:13,360
it's, there's, there's elements. And that's something I've always found fascinating is that

262
00:24:13,360 --> 00:24:18,560
you got the human element, which is definitely hugely informal, sloppy, we are not, we are not

263
00:24:18,560 --> 00:24:25,600
formalized creatures with very, very associative. And then what developers have to do is bridge the

264
00:24:25,600 --> 00:24:32,240
gap between this incredibly sloppy world that somehow has form and shape, but is not necessarily

265
00:24:32,240 --> 00:24:36,640
rigid and prescriptive and with well-defined boundaries. And then you kind of shift into

266
00:24:36,640 --> 00:24:42,720
the world of programs, which have exactly opposite nature. They are highly formalized, you know,

267
00:24:42,720 --> 00:24:46,400
it's, it's a programming language is a formal structure. There's no kind of like, well, maybe

268
00:24:46,400 --> 00:24:50,000
today I'll compile it, or maybe you don't. And if it looks like that, you know, you have a problem.

269
00:24:52,000 --> 00:24:57,280
You know, but it, there's kind of, there's a, and what you've got to try and do is build a system

270
00:24:57,280 --> 00:25:02,800
for the kind of the soft squishy thinking and soft squishy beings out of stuff that is really

271
00:25:02,800 --> 00:25:08,400
quite different. And the nature of these two, bringing them together, I think that for me,

272
00:25:08,400 --> 00:25:12,800
that's one of the things I find fascinating, but it's probably also for many people without them

273
00:25:12,800 --> 00:25:18,320
realizing is what's interesting about software development is there is the rewarding aspect

274
00:25:18,320 --> 00:25:23,040
of some things that are solved and elegant. And it's just like, that's done. But then there's

275
00:25:23,040 --> 00:25:27,280
the other element of like, and how does it fit with the world, which is also quite exciting.

276
00:25:28,240 --> 00:25:31,520
And also the discoveries that you make is just like, well, I thought this was a really good

277
00:25:31,520 --> 00:25:35,520
abstraction, but now I truly understand what's being built. I don't think that's the right

278
00:25:35,520 --> 00:25:38,960
abstraction. That doesn't mean it's a bad abstraction. It's just not the right abstraction

279
00:25:38,960 --> 00:25:44,240
for this system. It's just now I understand how it's evolving through time and the kind of the

280
00:25:44,240 --> 00:25:50,400
nature of changes that the client wants from it, or the things we've discovered from, from sprint

281
00:25:50,800 --> 00:25:54,800
to sprint. It's just like, oh, okay, I keep touching this, keep changing it with that

282
00:25:54,800 --> 00:26:00,000
optimism. Oh, I'll get it right this time. But actually, actually, maybe I'm learning

283
00:26:00,000 --> 00:26:05,040
something deeper, the fact that this is not the idea that I thought it was. And I need a different

284
00:26:05,040 --> 00:26:13,280
point of view. And that's, that's not a side effect to an accident. That's the nature of

285
00:26:13,840 --> 00:26:19,680
of the game. It's this exercise, it's this continual exercise in learning in which

286
00:26:20,320 --> 00:26:24,000
we enhance our understanding of the problem that we're trying to address,

287
00:26:25,120 --> 00:26:31,600
and the nature of our solution, a solution that we're trying to apply to it. And, and, and it seems

288
00:26:31,600 --> 00:26:37,200
to, that's one of the things that I very, very strongly come to believe that that's a complete

289
00:26:37,200 --> 00:26:45,200
cornerstone of our discipline. And we optimize to be able to maintain our ability to make changes

290
00:26:45,200 --> 00:26:51,200
when we learn new stuff. So, so I refer to it as this kind of one of the ways of kind of

291
00:26:51,200 --> 00:26:58,320
pragmatically, informally adopting the philosophy of science to software. So I want to, I want to

292
00:26:58,320 --> 00:27:02,160
consciously start out assuming that I'm going to make a mistake and I'm going to be wrong.

293
00:27:02,880 --> 00:27:08,160
And then I'm going to look at ways in which I can falsify my, my guesses along the way.

294
00:27:08,160 --> 00:27:13,920
And that's a much stronger way of learning than assuming that my design's perfect and it's going

295
00:27:13,920 --> 00:27:18,960
to be right. And I'm never going to have to correct it again. I've found the one true way.

296
00:27:18,960 --> 00:27:26,640
You know, I'm always reminded, you know, this, this is years ago, but I had a client where I had,

297
00:27:26,880 --> 00:27:31,840
I, I become a success of visits, I become familiar with the nature of their system and what they

298
00:27:31,840 --> 00:27:36,800
were doing. And they one day asked me, we love you to design this kind of like subsystem. And it's

299
00:27:36,800 --> 00:27:40,960
got these performance constraints and stuff like that. And we've got the suggestion for the basic

300
00:27:40,960 --> 00:27:44,880
idea of the design. And I kind of said, I don't think the memory manager is going to like that. I

301
00:27:44,880 --> 00:27:47,920
don't think that's, that's, I don't think that's going to work. I don't think it's going to meet

302
00:27:48,480 --> 00:27:52,560
the performance requirements that you need. I think it's going to be issues with it. And then I

303
00:27:52,720 --> 00:27:57,440
made a suggestion and I said, are you sure? And I said, well, I think this is going to

304
00:27:57,440 --> 00:28:01,120
work better. I think this will work better with memory allocation on this platform. I think

305
00:28:01,840 --> 00:28:05,520
that for the, you know, you're dealing with peak, they basically wanted to deal with peak demand

306
00:28:05,520 --> 00:28:08,960
in some way. You know, we can't handle the data, but all we need to do is spool it off so we can

307
00:28:08,960 --> 00:28:13,600
handle it later. And I said, I think the way I'm proposing will work this way. And then I tossed

308
00:28:13,600 --> 00:28:19,040
in another idea, because I'm not really happy until I've got three ideas. So they gave me one. I,

309
00:28:19,040 --> 00:28:23,200
I had, I had a preferred one. I didn't think there's a worker and I had a preferred one.

310
00:28:23,200 --> 00:28:27,440
And, you know, and, and then I had a third one. And I thought that one was okay. I thought it was

311
00:28:27,440 --> 00:28:31,040
better than their suggestion, but I didn't think it was great. And, you know, they gave me a couple

312
00:28:31,040 --> 00:28:35,280
of days, you know, they fed me coffee, you know, gave me a meeting room, all the rest of it. But

313
00:28:35,280 --> 00:28:40,640
my favorite thing is one, one of the guys came in one day, you know, the first or second day,

314
00:28:40,640 --> 00:28:45,040
and he came in and he saw I had an idea on my screen. I had code, there were curly brackets

315
00:28:45,040 --> 00:28:48,400
happening. I said, Oh, we didn't expect you to cut it. And it's just, I kind of looked at it.

316
00:28:48,400 --> 00:28:50,880
It was just like, well, how do you think I was going to do this sit here?

317
00:28:53,680 --> 00:28:58,080
You know, and come up with the pure design, you know, I have designed it.

318
00:28:59,200 --> 00:29:06,400
I have the architecture. Here is the solution. And it's just like, no, I'm trying each one of

319
00:29:06,400 --> 00:29:10,960
these out. I want to see what it feels like in code. And also, I'm going to do some basic,

320
00:29:10,960 --> 00:29:15,920
basic performance analysis, not too big, just to get a kind of order of magnitude feel for the

321
00:29:15,920 --> 00:29:22,080
stuff. And I wrote it up. And the funny thing is, I wrote it up. And it's only in hindsight that

322
00:29:22,080 --> 00:29:27,520
I realized I'd written it up like an experimental report. Here's the situation. Here's what we've

323
00:29:27,520 --> 00:29:31,600
got. Here's the various proposals. Here's how we've run it. Here's the results and recommendations

324
00:29:31,600 --> 00:29:37,360
for future work. But what I found is that I was right and I was wrong. I was right. Their approach

325
00:29:37,360 --> 00:29:41,840
wouldn't meet their requirements. I was also right that my preferred approach would meet their

326
00:29:41,840 --> 00:29:47,760
requirements. But I was wrong in that my kind of like third throwaway option, that was outstanding.

327
00:29:47,760 --> 00:29:52,960
It was way ahead of me. You know, and I would not have known that by meditating upon it. That had

328
00:29:52,960 --> 00:29:59,360
to be made real. It had to be brought into the world. And to actually, you also have to kind of

329
00:29:59,360 --> 00:30:03,600
mess about with it. In other words, the very active, and you mentioned kind of like

330
00:30:04,320 --> 00:30:08,960
solving mathematical problems for fun. And that's one of those interesting things is that I'm guilty

331
00:30:08,960 --> 00:30:16,560
of having done similar things in the past. And it's kind of fun. But the thing is, until you've

332
00:30:16,560 --> 00:30:21,520
done it, you don't know how you're going to do it. You've got some ideas, and you're going to crack

333
00:30:21,520 --> 00:30:26,800
away at it. And in that sense, there is a sort of a creativity. You know, mathematics is not

334
00:30:26,800 --> 00:30:30,720
necessarily empirical, but it is certainly creative. I'm going to try this. And what about

335
00:30:30,720 --> 00:30:36,960
this one? What about this? And you've got that. And software just pushes it a little bit further

336
00:30:36,960 --> 00:30:40,960
to bring it into the world and say, Well, yeah, but how does that work in the world as opposed to

337
00:30:40,960 --> 00:30:47,440
this abstract space? And that is the really important. And that idea, I think it's a really

338
00:30:47,440 --> 00:30:52,080
interesting one, because what we're doing is we're bringing together the idea of problem solving and

339
00:30:52,080 --> 00:30:58,400
creativity. But with something that somebody else is going to experience, and they're going to work

340
00:30:58,400 --> 00:31:02,640
with it, that somebody else is either going to be another developer experiencing the code,

341
00:31:02,640 --> 00:31:08,240
or it's going to be an end user experiencing what is this system like. And so there's a kind of a

342
00:31:08,240 --> 00:31:13,040
feedback, you don't necessarily get that quite the same from something that is mathematical.

343
00:31:14,880 --> 00:31:18,560
There's a kind of a sense there of, is this appropriate for the world that we want, as opposed

344
00:31:18,560 --> 00:31:25,200
to, you know, yeah, this is this is fine. It's a nice idea. But it's a case of like, what is its

345
00:31:25,200 --> 00:31:29,360
context? You know, I can give you a picture of a house. And I could ask you, is this a good house?

346
00:31:29,360 --> 00:31:32,880
And, and you could say, Yeah, that looks good. And then I say, Well, here's the hill that I got to

347
00:31:32,880 --> 00:31:40,400
put it on. You said, Well, you didn't say that. The context absolutely matters. And I think that

348
00:31:40,400 --> 00:31:46,560
sometimes we kind of, there's this kind of sort of maths envy that sometimes takes over people.

349
00:31:46,560 --> 00:31:50,880
And sometimes there's that idealism, because software does, you know, as I said, there's

350
00:31:50,880 --> 00:31:55,280
these two different spaces, that the sloppy human one that is filled with economics and

351
00:31:56,560 --> 00:32:00,560
ill form thoughts, and the fact that the realization that no matter what we do with any

352
00:32:00,560 --> 00:32:03,520
development process, people always talk about prioritizing requirements, stuff like that.

353
00:32:04,400 --> 00:32:07,520
Humans don't walk around with a list of priorities that we don't actually that's

354
00:32:07,520 --> 00:32:10,880
that's not a thing that happens in the brain. We don't have lists like that.

355
00:32:12,560 --> 00:32:20,480
And so my wife, I have very organized, but I'm going to say that when people,

356
00:32:20,560 --> 00:32:25,280
but that's a thinking tool, that a list becomes a thinking tool. Yes, when you provoke a human,

357
00:32:25,280 --> 00:32:30,800
just randomly, they don't have a, they have to create a list. And it's going to be drawn from

358
00:32:30,800 --> 00:32:38,160
whatever is available. It's an availability bias there, whatever is available at that particular

359
00:32:38,160 --> 00:32:44,000
point in time. And unless they've already really thought through, I'm going to use lists like

360
00:32:44,000 --> 00:32:47,840
this, unless they've actually structured that in there, then that's not the naturally the way

361
00:32:47,840 --> 00:32:51,920
they think. Most people don't sit there thinking like, we want a product, and I'm going to think in

362
00:32:51,920 --> 00:32:55,280
terms of these requirements. No, you're probably thinking in terms of other things that are your

363
00:32:55,280 --> 00:33:01,280
skill space. And so when we provoke humans into, oh, I need a formal structure, give me a priority

364
00:33:01,280 --> 00:33:05,680
list. That's not how they actually think, but they can learn to move towards it. But that doesn't

365
00:33:05,680 --> 00:33:10,880
mean they're thinking genuinely like that. And then we have this associative mess, which is also

366
00:33:10,880 --> 00:33:15,360
where all the creativity comes from. And then we have this kind of hard edge stuff, which is very

367
00:33:15,360 --> 00:33:18,880
uncompromising. You know, there's no negotiation with the compiler. It's not a matter of opinion

368
00:33:18,880 --> 00:33:23,680
whether or not this works or not. And then we're trying to do all of this. So we've got all these

369
00:33:23,680 --> 00:33:29,600
different strands of creativity yet bounded by a particular formalism. And so it's kind of like

370
00:33:29,600 --> 00:33:33,600
you need lots of different points of view. And so although ultimately, I believe that it is all

371
00:33:33,600 --> 00:33:37,920
underpinned by a perspective of engineering. And I think with software engineering, it's not,

372
00:33:38,880 --> 00:33:48,560
it's, I put it, I did a very long time ago at the GoTo conference. It was nearly 20 years ago,

373
00:33:48,560 --> 00:33:53,120
and it was an end note. And it was, oh, no, it was the Java conference at that time. I hadn't

374
00:33:53,120 --> 00:33:58,080
called themselves GoTo yet. And it was entitled Beyond Metaphore, where I looked at a bunch of

375
00:33:58,080 --> 00:34:04,960
metaphors that we use in software development. And the whole value of them, I sort of said,

376
00:34:04,960 --> 00:34:08,880
yeah, it gives you different points of view. But I said, one of them is actually what we do is

377
00:34:08,880 --> 00:34:13,520
engineering, but it's not engineering that has to worry mostly about physics and logistics. We

378
00:34:13,520 --> 00:34:17,440
don't really worry about logistics. It turns out that what happened? What does engineering look

379
00:34:17,440 --> 00:34:21,680
like when you take all of that away? You're still making trade-offs and you're still doing a whole

380
00:34:21,680 --> 00:34:27,760
load of things. It's just that you don't have to worry about the bridge materials. You don't have

381
00:34:27,760 --> 00:34:32,400
to worry about, you know, all the materials, you don't have to worry about it the same way.

382
00:34:32,480 --> 00:34:36,320
There's a whole load of other things that just disappear, but that doesn't stop it from being

383
00:34:37,600 --> 00:34:43,760
a discipline that is learning-based, that is in some sense pragmatic, but is also very trade-offs

384
00:34:43,760 --> 00:34:48,800
driven. That's a really, really important part. You know, mathematically, we know

385
00:34:48,800 --> 00:34:52,400
when people talk about maths, the trade-offs are not quite there in the same way. When somebody

386
00:34:52,400 --> 00:34:56,560
comes up with a proof, and they can't quite prove it, it's like, well, you know, close enough.

387
00:34:57,520 --> 00:35:05,840
No, that does not pass the mathematical test. It's like the Fermat's Last Theorem,

388
00:35:05,840 --> 00:35:09,280
which is kind of fresh in my mind because I interviewed Simon Singh a few months ago

389
00:35:10,320 --> 00:35:13,920
on some of his things, and he wrote a wonderful book on Fermat's Last Theorem, the history

390
00:35:14,640 --> 00:35:21,360
of that, and Andrew Wiles's proof. Everybody kind of suspected, no, an engineer would have said,

391
00:35:21,360 --> 00:35:25,520
yeah, you know what, Fermat's right. It's close enough. We can't find anything that's good enough.

392
00:35:25,520 --> 00:35:31,760
We can't find an N for, you know, that there is other than Pythagoras, you know, other than A

393
00:35:31,760 --> 00:35:36,880
squared plus B squared equals C squared for A, B, and C being integers. You know,

394
00:35:36,880 --> 00:35:41,040
you're not going to find any other powers. You know, there is no N that is going to fit that.

395
00:35:41,040 --> 00:35:44,640
An engineer would have given up a long time ago. They would have moved on to the next problem,

396
00:35:44,640 --> 00:35:47,200
because they said, you know, actually, we've done a plausibility analysis, and really,

397
00:35:47,200 --> 00:35:51,840
it doesn't look like there's anything there. And given the time and effort, this is good enough.

398
00:35:52,560 --> 00:35:57,680
And that's, in other words, there's a kind of a, there's a stopping point and a trade-off discussion

399
00:35:57,680 --> 00:36:04,640
that happens there. Glenn Vanderberg did a great talk about software engineering a few years ago,

400
00:36:04,640 --> 00:36:08,800
and he says engineering, in other disciplines, engineering is just the stuff that works.

401
00:36:09,440 --> 00:36:16,640
And that's it. It's that mix between adopting a scientific style of rational thinking to solve

402
00:36:16,640 --> 00:36:22,160
the problems, where that's practical. But it doesn't have to be definitive. There's also this

403
00:36:22,160 --> 00:36:30,080
empirical little add-on that, you know, you know, yeah, that's good enough. You know, it's, and that

404
00:36:30,080 --> 00:36:37,120
seems important to me as part, you know, as part of the discipline is to not expect kind of quantum

405
00:36:37,120 --> 00:36:42,800
physics levels of precision in engineering, you know, in engineering, unless you're building

406
00:36:42,800 --> 00:36:47,120
something that's using quantum physics, you know, you don't expect, you don't do that if you're

407
00:36:47,120 --> 00:36:53,440
built in a car, you know, you're more pragmatic than that. And I think, I think that's one of the,

408
00:36:54,000 --> 00:37:00,080
it's interesting that the way that you kind of couch that in talking about your talk is,

409
00:37:01,680 --> 00:37:08,480
is that it's engineering without those kind of the logistics. I talk about it in terms of,

410
00:37:08,480 --> 00:37:14,480
I think our mistake is assuming that engineering, because it's so popular in the real world,

411
00:37:14,480 --> 00:37:19,600
is production engineering that we're talking about. There are synonym and they're not.

412
00:37:19,600 --> 00:37:23,760
There's also design engineering, which I think is much, much closer to what it is that we do.

413
00:37:23,760 --> 00:37:28,720
We're much less interested in those, the logistics of production, because production's free for us.

414
00:37:29,360 --> 00:37:33,760
Yes, yes. Yeah, I think that's a, I think that is a really important distinction because it's,

415
00:37:33,760 --> 00:37:38,160
it's one of those things when you zoom in, and I think it's, it's the, as you start zooming in,

416
00:37:38,160 --> 00:37:44,800
you start realizing distinctions that are not necessarily, and that's, and I think that's,

417
00:37:44,800 --> 00:37:49,280
that's both the strength and weakness of any, of any word when we throw a word out there to say,

418
00:37:49,280 --> 00:37:55,440
this is like this, this is this. We probably have a fairly clear idea in our heads, based on

419
00:37:55,440 --> 00:37:59,680
whatever our experience is, but we've got no guarantee that the other person, the receiver,

420
00:37:59,680 --> 00:38:04,000
has the same mental model. I mean, it's, and that I think is, is a really,

421
00:38:04,880 --> 00:38:08,720
a really important one. It's sometimes when, when you kind of like push the edges of those

422
00:38:08,720 --> 00:38:12,080
definitions. So I think for me, one of the really interesting ones, actually funny enough,

423
00:38:12,640 --> 00:38:17,360
and I wonder whether, and this is tied, I know this is just like a, you know, I can't, I can't

424
00:38:17,360 --> 00:38:23,920
tell you, but basically the late 90s, I read Two Engineers Human by Henry Piotroski.

425
00:38:24,720 --> 00:38:30,560
Wonderful book. Now he's a civil engineer and historian, and really wonderful book, but,

426
00:38:30,560 --> 00:38:37,120
but the subtitle is The Role of Failure, a successful engineer. And it's that idea of

427
00:38:37,120 --> 00:38:41,120
understanding things through failure, which I wonder if that ties into me, my fascination

428
00:38:41,120 --> 00:38:45,600
with taking pictures and how other people send me pictures of failure, but that idea that actually

429
00:38:45,600 --> 00:38:54,080
we can learn a lot by nudging a system to, nudging a system beyond what we actually understood,

430
00:38:54,080 --> 00:38:58,080
nudging it beyond our preconceptions, revealing our own assumptions. It's just like, ah,

431
00:38:58,640 --> 00:39:02,960
and, and, and, and it's occasionally doing that on purpose. But one of the things I'm, I'm, I'm

432
00:39:02,960 --> 00:39:10,480
currently obsessed watching SpaceX build their Starships in, in, in Texas. And, and I've been

433
00:39:10,480 --> 00:39:16,480
following it for a, for a while now, a little while ago, they decided that they, they made

434
00:39:16,480 --> 00:39:20,880
an unusual decision of building their, their, their Spaceships out of stainless steel rather

435
00:39:20,880 --> 00:39:24,480
than aluminium, which is what Spaceships were. Originally they thought they were going to do

436
00:39:24,480 --> 00:39:28,400
carbon fiber. Then they showed, they looked at the alternatives. They came up with stainless steel

437
00:39:28,400 --> 00:39:33,280
because it got a better temperature range and for strength to weight ratio and all that kind of

438
00:39:33,280 --> 00:39:38,400
stuff. But at one point they'd built these things. They'd, they'd flown some of them.

439
00:39:38,880 --> 00:39:43,360
They decided they were going to move from four millimetre stainless steel to three millimetre

440
00:39:43,360 --> 00:39:51,040
stainless steel. Same stuff, same, same type of steel, but just a thickness change. You'd think

441
00:39:51,040 --> 00:39:56,720
that'd be the kind of thing that you could just do your slide roll in the olden days, but running

442
00:39:56,720 --> 00:40:01,360
through, running through a computer and, and understand. But no, they built, they built the

443
00:40:01,360 --> 00:40:06,880
system and then they, they, they pressure tested it to destruction to see how their welds held up,

444
00:40:06,880 --> 00:40:13,520
how their designs stood up under that real and, you know, empirical load in, you know, life-like

445
00:40:13,520 --> 00:40:19,280
circumstances. See what happens at the point when it screws up. And, you know, that, that's what real

446
00:40:19,280 --> 00:40:23,920
world engineering looks like. It seems, seems to me. But there's that idea of like, you're going to,

447
00:40:23,920 --> 00:40:29,040
we're going to do this and try this thing out and then see what happens. And there's a, for me,

448
00:40:29,040 --> 00:40:33,840
that, that's this idea that time is a really important ingredient to what we do, which I think

449
00:40:33,920 --> 00:40:41,600
is really missing from a lot of, a lot of formalisms of what is software, that it's the

450
00:40:41,600 --> 00:40:46,640
time full aspect. It's not the timeless aspect, but the time full aspect. And I was, honestly,

451
00:40:46,640 --> 00:40:50,240
I couldn't tell you the answer to this until I built it and we've seen it for a bit. I know it's

452
00:40:50,240 --> 00:40:56,640
not quite right, but it's plausibly in the right space. And, but I don't know what my assumptions

453
00:40:56,640 --> 00:41:00,880
are, you know, and as by definition, you don't know what your assumptions are. Because, and,

454
00:41:00,880 --> 00:41:04,720
you know, I always like to point out that assumptions are really weird pieces of knowledge.

455
00:41:05,360 --> 00:41:10,320
They are, they are only ever discovered, they are normally only discovered in contradiction.

456
00:41:10,880 --> 00:41:14,480
You know, somebody says something, you go, Oh, but I had assumed that at that moment,

457
00:41:14,480 --> 00:41:18,080
yeah, you discover you had an assumption, you've had it for a long time. But if anybody had asked

458
00:41:18,080 --> 00:41:22,640
you prior to that, what are your assumptions, you just said, I have none. Only when it is

459
00:41:22,640 --> 00:41:29,200
contradicted, you go, Oh, that's an assumption. So this is very curious from an epistemological

460
00:41:29,280 --> 00:41:34,800
point of view. This is really weird kind of thing. Yeah. And it's, it's the fact that you know, if

461
00:41:34,800 --> 00:41:39,840
you know, you know, it's, you know, it's kind of Lego bricks, Lego bricks in the dark, you know,

462
00:41:39,840 --> 00:41:45,120
there is a dark room, I know there are Lego bricks on the floor. The problem is, although I know that

463
00:41:45,120 --> 00:41:48,960
I have assumptions, although I know there are Lego bricks, I can't tell you where they are until

464
00:41:48,960 --> 00:41:52,800
I've stepped on them. I have assumptions, but until, but I'm not going to do that by just standing

465
00:41:52,800 --> 00:41:56,560
at the door, I can, I have to walk into the room, I have to tread through, tread through, there's

466
00:41:56,560 --> 00:41:59,600
one, there's another one, there's another one. You know, it's one of those things, you have

467
00:41:59,600 --> 00:42:04,000
to be deliberate about this, you've got to put that stuff out there. And of course, prior knowledge

468
00:42:04,000 --> 00:42:09,760
can, can give you a real kind of a real leg up, that's the standing on shoulders of giants, that's

469
00:42:09,760 --> 00:42:15,760
the cumulative experience. Now, why, why is it that we are recreating the errors that previous

470
00:42:15,760 --> 00:42:21,280
projects have done? Yeah, we got, we got all this experience. And it's, it's, we, we see this

471
00:42:21,360 --> 00:42:30,560
repeatedly at the level of individuals, companies, and discipline as a whole. It's a case of

472
00:42:32,160 --> 00:42:36,560
one of those interesting things is like, yeah, we all make mistakes. That's absolutely fine. We,

473
00:42:36,560 --> 00:42:41,120
we, we are always operating within complete knowledge by definition. We're operating within

474
00:42:41,120 --> 00:42:47,040
complete knowledge. Software, as you said, production is free. We've got that was a solved

475
00:42:47,040 --> 00:42:50,960
problem in the 1950s. We basically solved the elements of that, and we've just been getting

476
00:42:50,960 --> 00:42:59,040
better at it ever since. But that whole idea of that leaves us with the hard problem of,

477
00:42:59,040 --> 00:43:02,560
and what is it we're trying to build and why? And how do we, how do we do that? Yes. Which

478
00:43:02,560 --> 00:43:06,880
turns out to be surprisingly challenging, but it's by definition, open-ended, because we're

479
00:43:06,880 --> 00:43:12,720
not producing identical artifacts. I've got, I don't know how many of these pens lying around

480
00:43:12,800 --> 00:43:18,720
my office. And they are all equivalent to one another. They are all, except for the in-content,

481
00:43:18,720 --> 00:43:23,520
substitutable for one another. They are identical. That's because they have a production. Yeah,

482
00:43:23,520 --> 00:43:29,360
they have a production process that is designed to eliminate variation. Yeah, we, we've done that

483
00:43:29,360 --> 00:43:34,000
far. Software is never like that. Yes. Yeah. The software challenge is that if somebody comes

484
00:43:34,000 --> 00:43:38,800
along and says, I want something that, I want that system over there running over here,

485
00:43:38,800 --> 00:43:46,960
well, that's a solved problem. If I see one of my sons, if they show me an app on the phone,

486
00:43:47,520 --> 00:43:51,040
I don't have to say, oh, I need to build that. It's just like, I'm going to go to the store

487
00:43:51,040 --> 00:43:55,200
and get it for myself. It's downloadable. If somebody shows me a piece of code and say, oh,

488
00:43:55,200 --> 00:44:01,040
that's really good. We now need to write that code over here. No. Yeah. It's just a case of,

489
00:44:01,040 --> 00:44:06,160
we've solved all of these issues, but we're left with that, we're left with the challenging issue,

490
00:44:06,160 --> 00:44:10,880
which is not the production of the elimination variation, but the production of variation.

491
00:44:10,880 --> 00:44:15,840
That's our job. When somebody says, I want this system, but I want it slightly different.

492
00:44:15,840 --> 00:44:19,440
I want to, you know, I want that thing our competitor has done. Well, that's different

493
00:44:19,440 --> 00:44:24,800
because we don't have their code. That's for us. This is new. It's new to us. I want the old version.

494
00:44:24,800 --> 00:44:28,720
I want a new version of the system. And so whenever anybody asks for a feature extension,

495
00:44:28,720 --> 00:44:31,760
they're not just asking for a feature extension. They're actually asking for a new system.

496
00:44:31,840 --> 00:44:36,240
It's the old system plus the new behavior. That's a new system by definition.

497
00:44:36,880 --> 00:44:44,000
And that's one of the key facets of doing a good job is to be able to make that move

498
00:44:44,720 --> 00:44:51,680
from the previous version to the new version easy. Yes. I am increasingly of the mind that

499
00:44:51,680 --> 00:44:57,520
if you can't change your software, then the software is low quality. That is the practical,

500
00:44:57,520 --> 00:45:02,880
pragmatic realization of quality in your software. I don't care about anything else.

501
00:45:02,880 --> 00:45:05,520
You know, I don't care what language it's in. I don't care what, you know,

502
00:45:05,520 --> 00:45:12,400
if I can change it easily and safely, then it's good quality. Yeah. And and pretty much,

503
00:45:12,400 --> 00:45:15,680
and there was, and again, there were some of these sort of deep tools that, you know,

504
00:45:15,680 --> 00:45:20,560
things like modularity, cohesion, separation of concerns, encapsulation, abstraction,

505
00:45:20,560 --> 00:45:29,040
those sorts of tools that allow us the freedom to make those kinds of moves when we realize,

506
00:45:29,040 --> 00:45:32,720
oh, shit, we got it wrong. Yeah. The freedom to make the change.

507
00:45:33,360 --> 00:45:39,200
And I think that's really important because I think for me, one of those insights or,

508
00:45:39,200 --> 00:45:42,560
you know, an emerging wave of insights over the years has come from this idea,

509
00:45:42,560 --> 00:45:45,520
okay, we're always operating with incomplete knowledge. So that means that whatever I'm

510
00:45:45,520 --> 00:45:51,520
building is, is in some sense wrong, although I think wrong is sometimes there's too much,

511
00:45:52,400 --> 00:45:55,600
there's too much attached to that word. Your best guess so far.

512
00:45:56,160 --> 00:45:59,680
That's my best, yeah, based on what I knew. It's, you know, we did our best job.

513
00:45:59,680 --> 00:46:02,400
This is what we've got. But now we've learned something from it, either because the world

514
00:46:02,400 --> 00:46:08,800
told us, or because we learned as a result, our own awareness of this. But what's interesting

515
00:46:08,800 --> 00:46:15,360
is you can derive a lot of the ideas that we value, modularity, loose coupling and all the rest of it,

516
00:46:15,760 --> 00:46:18,880
from an understanding of like, well, how would you build something if you didn't know everything?

517
00:46:19,440 --> 00:46:23,440
Yes. Yes. Here's the thing I'm not sure about. Here's the thing I'm very sure about. You know,

518
00:46:23,440 --> 00:46:26,800
this thing I'm not sure about, I'm going to really ram it in there and couple tightly to it.

519
00:46:26,800 --> 00:46:31,920
No, you were loosely coupled to it because this is probably going to change. Yeah, exactly. You

520
00:46:31,920 --> 00:46:36,000
know, I'm going to isolate myself from that. This is, I'm not totally sure about it. I've kind

521
00:46:36,000 --> 00:46:41,280
of got an idea, but I want to put a little bit of distance between this and this. And that distance

522
00:46:42,080 --> 00:46:46,480
is our dependencies, that distance is our interfaces, that distance is, the idea is that

523
00:46:46,480 --> 00:46:50,560
all of this falls out naturally when you start saying, well, you can actually, and this is,

524
00:46:50,560 --> 00:46:56,400
I think, is fascinating because it runs along kind of an alternative axis. Sometimes they

525
00:46:56,400 --> 00:47:01,120
arrive at the same conclusion, but sometimes they don't, to the traditional language of abstraction

526
00:47:01,120 --> 00:47:04,640
and things like that. How would you modularise? Modularise according to abstraction? Well,

527
00:47:04,640 --> 00:47:10,240
there's multiple ways of abstract. We have different paradigms for that. But what is interesting is

528
00:47:10,240 --> 00:47:16,240
going, well, how sure are you about this? And it's just like, well, you know, we, oh, I'm pretty

529
00:47:16,240 --> 00:47:19,680
sure we've built, we've done something almost identical. It's not identical, but it's almost

530
00:47:19,680 --> 00:47:23,280
identical. Well, that gives us maybe high confidence and this worked out well. That's the

531
00:47:23,280 --> 00:47:28,000
second bit. People don't even forget that. Doing it, sometimes we get stuck in a rut. You know,

532
00:47:28,000 --> 00:47:31,440
it's just like, we did this before and how did that work out for you? Yeah, you know, not very

533
00:47:31,440 --> 00:47:35,440
well, but we're going to do it again this way. It's just that, no, no, no, there's no opportunity here.

534
00:47:36,400 --> 00:47:39,840
And that's that idea of, you know, you know, it's good to have a few ideas

535
00:47:40,400 --> 00:47:45,760
that you can trade off against one another. Yes. But then you've got that other idea of like saying,

536
00:47:45,760 --> 00:47:50,160
well, let's, let's go through this in terms of certainty. And I've done this a couple of times

537
00:47:50,160 --> 00:47:53,440
with people and they're always kind of slightly freaked out because you kind of come up with a

538
00:47:53,440 --> 00:47:57,760
rough kind of like sketch of what you're going to do. And so, well, hang on, but we haven't actually

539
00:47:57,760 --> 00:48:02,320
talked about all of the design detail that they normally talk about. It's just like, well, yeah,

540
00:48:02,320 --> 00:48:05,600
what we did is we've just drawn a bunch of boxes and lines and things

541
00:48:06,240 --> 00:48:09,520
based on your confidence. In other words, when I've asked a question,

542
00:48:10,320 --> 00:48:13,920
and you've said, oh, yeah, we're not really sure how we can do that. Right, I've drawn a line.

543
00:48:13,920 --> 00:48:17,280
There's a boundary there of knowledge, because we're sure about one side, but we're not sure about

544
00:48:17,280 --> 00:48:20,960
the other. I don't care what it is. I don't care what paradigm we're talking. It's clearly something

545
00:48:20,960 --> 00:48:25,440
we're not sure about. So maybe we shouldn't hug it too closely, a little bit of, a little bit of

546
00:48:25,440 --> 00:48:30,400
looseness. A little bit of a wall would be good. Yeah. And likewise, when somebody says, oh, yeah,

547
00:48:30,400 --> 00:48:33,200
we're going to do it this way. And a colleague says, oh, I thought we're going to do it this way.

548
00:48:33,200 --> 00:48:38,080
You know what? There's a line there as well, because it's clearly this is not settled. And it may

549
00:48:38,080 --> 00:48:42,880
turn out that one of them is right one year and the other one is right the next year. In other

550
00:48:42,880 --> 00:48:48,560
words, things may change whether it's performance characteristics or whatever, but favor one and

551
00:48:48,560 --> 00:48:53,440
then the other. And again, that's the time for rather than timeless quality. But that idea there

552
00:48:53,440 --> 00:48:58,480
that we can get a heads up just by actually almost constructively using our uncertainty

553
00:48:59,040 --> 00:49:04,240
as a positive aspect to sort of see, well, how does this work? And then we've got the empirical

554
00:49:04,240 --> 00:49:09,600
side of things, which is, okay, here's what kept changing every release. You know, what are the

555
00:49:09,600 --> 00:49:13,840
hotspots? What do we keep going back and saying, oh, no, no, this time it'll be right. We'll just

556
00:49:13,840 --> 00:49:20,000
add this here. And that kind of, I think one of the first times I ever really noticed that question

557
00:49:20,000 --> 00:49:28,720
of stability properly feeding back was a Java system. It was a company that was doing a Java

558
00:49:28,720 --> 00:49:34,160
system. And they had the debate about they were having the debate and are not yet resolved it

559
00:49:36,080 --> 00:49:46,560
about checked exceptions. And for those tuning in who are not aware of this feature in Java,

560
00:49:47,520 --> 00:49:52,720
checked exceptions basically allow, basically allow you to make exceptions part of the

561
00:49:52,720 --> 00:49:58,000
signature of a method, sort of checkable aspect of the signature. And it's one of those things

562
00:49:58,000 --> 00:50:03,200
that in theory is a good idea. But that actually turns out that in practice, if you don't know

563
00:50:03,200 --> 00:50:09,200
exactly what you're doing, in other words, you don't have perfect knowledge, and you're building

564
00:50:09,200 --> 00:50:14,960
a large system, they have a really nasty impact because they they introduce an element that is

565
00:50:16,720 --> 00:50:22,400
unstable or rather needs to be stable, but is not yet stable. And I was, how does this fail?

566
00:50:22,400 --> 00:50:26,320
I don't know yet, because we haven't fully understood this goes right back to where we

567
00:50:26,320 --> 00:50:30,560
started. What are the failure modes of this? Yeah, short of saying something trivial, like

568
00:50:30,560 --> 00:50:36,000
there is an error. And that's often what these checked exceptions tend towards, which is

569
00:50:36,800 --> 00:50:41,760
throws framework error. In other words, actually, that's almost no use to anybody whatsoever.

570
00:50:41,760 --> 00:50:48,240
Bad things may happen. Well, we knew that because bad things may happen. You end up either saying

571
00:50:48,240 --> 00:50:52,640
nothing at all, or you say it so precisely that unless you've actually had this out in the field

572
00:50:52,640 --> 00:50:56,320
for a long time and converged on that, the chances are somebody's going to come up with a new failure

573
00:50:56,320 --> 00:51:01,680
mode. And it's just like, Oh, well, so the curious thing is what you've done is that your happy day

574
00:51:01,680 --> 00:51:06,400
scenario, what you want from the method, why the reason you called it, you don't call it,

575
00:51:06,400 --> 00:51:09,920
I'm not calling this method, except perhaps in a test, I'm not calling this method in order for

576
00:51:09,920 --> 00:51:15,440
it to fail. That's not my goal here. I'm calling this because I wanted a result. I'm expecting

577
00:51:15,440 --> 00:51:20,720
that it's all going to work out. So therefore, right at the edge of my vision, and edge of my

578
00:51:20,720 --> 00:51:25,920
awareness, is all of these failures, all these possible failures, which we've not yet explored.

579
00:51:25,920 --> 00:51:30,240
And as time goes by, we get more refined understanding. Oh, this could be distributed. Oh,

580
00:51:30,240 --> 00:51:34,640
well, our distributed bit throws different exceptions to the ones that are those. So we now

581
00:51:34,640 --> 00:51:38,400
made this thing, which was local. Now it's a set. Oh, okay. So we're going to have to change the

582
00:51:38,400 --> 00:51:43,840
signature again. So we've suddenly made something we've caused churn in the in the interface. And

583
00:51:43,840 --> 00:51:48,240
this is one of those interesting things that comes out of the kind of the more empirical side

584
00:51:48,240 --> 00:51:54,080
of things. It's not that nobody who put that feature in Java did so maliciously or without

585
00:51:54,080 --> 00:51:58,960
thought. I certainly, you know, I certainly my understanding at the time, and all everything

586
00:51:58,960 --> 00:52:02,560
being out there, no, there's some good thinking, solid thinking that goes right back to the 1970s

587
00:52:03,120 --> 00:52:08,160
in exploring all of this. But it's the scale, what happens when you actually create open systems

588
00:52:08,160 --> 00:52:12,800
that are large, and with all manner of developers, it suddenly turns out that there's a fundamental

589
00:52:12,800 --> 00:52:17,280
problem here. And it's to do with rate of change and stability of knowledge, what we do and don't

590
00:52:17,280 --> 00:52:22,400
know. And that was a, that was a revelation. Anyway, for this team, it was a real revelation

591
00:52:22,400 --> 00:52:26,240
because they were split down the middle, you know, half or pro, half or anti, and I was just like,

592
00:52:27,200 --> 00:52:30,800
I can't come in and just sort of say, you know, it's going to go this way or that way.

593
00:52:30,800 --> 00:52:35,120
So actually came up with an empirical approach. And I basically said, you know, don't make anything

594
00:52:35,120 --> 00:52:39,760
checked. You know, look at, you know, before you decide to make something checked as it were,

595
00:52:39,760 --> 00:52:46,720
and seal it in, look at how it's behaved over the last few iterations, write a test to simulate

596
00:52:46,720 --> 00:52:52,080
the failures as well. Oh, well, yeah, not just, yeah, but the failures do all of those. And they

597
00:52:52,080 --> 00:52:56,960
were actually quite good, though, but your understanding of the failures. Yeah, how you

598
00:52:56,960 --> 00:53:01,040
respond to it. Absolutely. Yeah. And it turns out that some of these kept changing on a frequent

599
00:53:01,120 --> 00:53:06,080
basis. And I said, look, that idea is not yet stabilized. That idea is still young, you know,

600
00:53:06,080 --> 00:53:12,240
don't nail it in place. And which is my polite way of saying, like, actually, probably, you know,

601
00:53:12,240 --> 00:53:16,960
so don't make it checked until you're sure, which is a fancy way of saying, don't make it checked,

602
00:53:16,960 --> 00:53:21,200
because the chances are they weren't going to go back and review stuff. But what we had is at least

603
00:53:21,200 --> 00:53:26,000
a maturity model. And it's this idea of that it doesn't matter what you think today, you're going

604
00:53:26,080 --> 00:53:32,560
to overvalue your confidence. And, and so it's this idea that time will give you the answer. I

605
00:53:32,560 --> 00:53:36,960
can't tell you how this is going to evolve. I can't tell you how other, you know, this goes

606
00:53:36,960 --> 00:53:42,320
across API's, it's not just about failure loads. Yeah, this is going on. How's it going to be used?

607
00:53:42,320 --> 00:53:46,240
What are the things that are frequently going to change? And then go back to your point about

608
00:53:46,240 --> 00:53:51,440
what we want to do is align the structures of our software with what are the frequent changes we

609
00:53:51,440 --> 00:53:58,240
actually experience, as opposed to, you know, people often pad their design or add complexity,

610
00:53:58,960 --> 00:54:04,000
because they're saying, oh, well, maybe this will change. It turns out that the better your

611
00:54:04,000 --> 00:54:09,040
imagination, the worse this gets. So if you're an imagine, if you are creative and imaginative

612
00:54:09,040 --> 00:54:13,680
developer, you can imagine all kinds of possibilities and the gold plating and the extra hooks and

613
00:54:13,680 --> 00:54:18,000
bits and pieces. And so the more imagination, the less imagination you have, the quicker you'll get

614
00:54:18,000 --> 00:54:22,960
the job done. The more imagination you have, actually, in that sense, it works against you

615
00:54:22,960 --> 00:54:27,040
because you think, well, what about this? What about all of these are possible, but most of them

616
00:54:27,040 --> 00:54:31,040
are not likely. And probably what you want to do is see, well, what actually happens with this?

617
00:54:31,680 --> 00:54:37,520
And that gets you to ask the more meaningful questions like, well, you know, should we release

618
00:54:37,520 --> 00:54:42,320
this API yet? Or should we release it and put a caution on it? It's just like, okay, this is a

619
00:54:42,320 --> 00:54:47,520
beta release. No, we're not planning to support this. This is a beta release. This is for you to

620
00:54:47,520 --> 00:54:51,920
try. It makes us a little more aware. It makes us look up from the keyboard and go, how are people

621
00:54:51,920 --> 00:54:57,680
going to use this? That gets to one of the things that I think is really important is just in software

622
00:54:57,680 --> 00:55:07,680
development is always thinking in that broader context of, you know, how do people consume this?

623
00:55:07,680 --> 00:55:13,040
Whether it's other developers or whether it's end users, how do people consume it? It's that

624
00:55:13,040 --> 00:55:18,320
stuff that you were talking about earlier about the interaction between the relatively rigid

625
00:55:18,320 --> 00:55:24,320
forms of software and the relatively fuzzy forms of people. But ultimately always comes down to

626
00:55:24,320 --> 00:55:34,080
that, whether it's an API or some complex system that people interact with. It's so much about

627
00:55:34,640 --> 00:55:40,560
being pragmatic and learning that. And it's one of the things that drives me nuts, working with

628
00:55:40,560 --> 00:55:46,960
big organisations when they silo up the development process to the extent where you get development

629
00:55:46,960 --> 00:55:52,080
teams who have no idea the context in which they're pieces of software use. They have some kind of

630
00:55:52,080 --> 00:55:58,160
people giving them requirements in the form of programming by remote control, which they're

631
00:55:58,160 --> 00:56:03,840
supposed to be able to churn out these widgets and they don't have any context. And you get to use

632
00:56:03,840 --> 00:56:08,640
software that you can tell sometimes just by using the software. Nobody's ever thought about

633
00:56:08,640 --> 00:56:14,480
actually using this bloody piece of software. It's so bad. And that idea of usability, it's

634
00:56:14,480 --> 00:56:21,760
turtles all the way down. You have the end user, but then also as software developers, we are

635
00:56:21,760 --> 00:56:32,240
clients of our own products. We are clients. It's the classic consumer and supplier metaphor

636
00:56:32,240 --> 00:56:37,360
for understanding components and interfaces and so on. How is somebody going to consume this?

637
00:56:37,360 --> 00:56:42,720
But also there's that contractual idea of like, what am I going to say about how they should

638
00:56:42,720 --> 00:56:47,440
use it? Because everything has a boundary, everything has a limit. And it's that idea,

639
00:56:47,440 --> 00:56:51,920
because the over-engineering issue, I've seen that where, in fact, again, I can pick on Java,

640
00:56:52,720 --> 00:56:58,240
but I've seen it certainly in other cases. So when Java arrived, it basically said,

641
00:56:58,240 --> 00:57:01,920
hey, everything is synchronisable so you can make it thread safe. And I remember thinking at the time,

642
00:57:02,000 --> 00:57:10,800
that's a really bad idea. That's a terrible idea. That's not how you do this. Because I remember

643
00:57:10,800 --> 00:57:14,800
at the time, somebody showed me this C++ and said, oh, this isn't thread safe. And I said,

644
00:57:14,800 --> 00:57:20,880
no, it's perfectly thread safe. You can pass one thread through it. That's it. If you do anything

645
00:57:20,880 --> 00:57:24,640
else on your head, be it. But I've just told you the circumstances under which this will work.

646
00:57:24,640 --> 00:57:30,240
I have given you a context under which this will work. And that's not me being picky. It's actually

647
00:57:30,240 --> 00:57:34,240
a genuine answer. Because otherwise, people do go around and they start goal-plating everything.

648
00:57:34,240 --> 00:57:39,280
And they do so very badly. And it's just like, no, I don't actually... The question is, this is

649
00:57:39,280 --> 00:57:43,440
thread safe. Oh, yeah, but you can't share it between threads. No, I didn't say you could. It's

650
00:57:43,440 --> 00:57:49,360
perfectly thread safe. I can run it in one thread on its own. And that is its safety level. Whereas

651
00:57:49,360 --> 00:57:52,880
there are some code that has a safety level of zero. In other words, this is thread safe if you

652
00:57:52,880 --> 00:57:59,600
pass zero threads through it. It's buggy. I can give you a real-world example of that,

653
00:57:59,600 --> 00:58:03,600
the danger of synchronization blocks in Java. Martin Thompson, my friend,

654
00:58:04,640 --> 00:58:10,800
years ago worked on... At the time, we thought it was the first ever internet bank. So he was

655
00:58:10,800 --> 00:58:14,720
called in to consult on this because they had a serious performance problem with their Java

656
00:58:14,720 --> 00:58:21,280
implementations. It was one of the early big Java implementations in the sort of mid to late 90s.

657
00:58:22,400 --> 00:58:28,640
And he went in, and several people had been to look at that. And it turned out to cut a

658
00:58:28,640 --> 00:58:34,160
long story short. All of the tests ran, and it all looked fine. They put it to production,

659
00:58:34,160 --> 00:58:39,440
and the performance absolutely tanked. It turned out somebody put a synchronization

660
00:58:39,440 --> 00:58:46,080
block around some piece of code in the critical path. So this internet bank could support one

661
00:58:46,080 --> 00:58:55,200
concurrent user, and everybody else queued up. And that's the thing is that for people

662
00:58:55,840 --> 00:58:59,040
oh, yeah, but this needs to be thread safe. Well, what do you mean by that term? Yeah.

663
00:58:59,040 --> 00:59:02,640
And it's like, why are you doing it? There was, again, the context. So it's a case of like,

664
00:59:02,640 --> 00:59:06,800
not everything wants to be shared between threads. And there are other ways. And everybody was a lot

665
00:59:06,800 --> 00:59:12,400
happy in the 90s. And you finally got... It's one of the reasons I keep certain old books around

666
00:59:12,400 --> 00:59:21,200
is that you can kind of see the shifts in style and approach. But I also remember with the client,

667
00:59:21,200 --> 00:59:24,960
this was a C++ system that we went through and looked at their problem. And they just

668
00:59:25,520 --> 00:59:29,120
it wasn't they weren't highlighting a performance problem. But I remember looking through,

669
00:59:29,120 --> 00:59:35,280
they've got this huge stuff in memory, lots of data, lots of rows of data memory. And there's

670
00:59:35,280 --> 00:59:40,960
30,000 locks. And I'm sitting there going like, I'm pretty sure this is all the ways that you could

671
00:59:40,960 --> 00:59:45,680
do this. This is probably not the right way. And it was one of those kind of like, take a step back

672
00:59:45,680 --> 00:59:51,840
and look at it and go, well, actually, what you've got, you've done it as a kind of a data

673
00:59:51,840 --> 00:59:56,320
centered problem with lots of threads operating on the data. And I said, but if you understand

674
00:59:56,320 --> 01:00:00,080
what the threads do, I said, they actually follow a life cycle. And that life cycle,

675
01:00:01,200 --> 01:00:06,080
we could do that as a data flow. In other words, it worked out basically, it was a data flow. We

676
01:00:06,080 --> 01:00:10,960
basically, you know, yeah, you don't need anywhere near as many threads, you're stealing from yourself,

677
01:00:10,960 --> 01:00:14,720
it turns out. And with a lot of this, and it turns out, if you do it as a pipeline,

678
01:00:15,360 --> 01:00:19,520
then we ended up with only needing six locks. And that was in the bits that connected.

679
01:00:20,240 --> 01:00:25,760
That's in the pipes. And in other words, the point is the data, but they said, but the data

680
01:00:25,760 --> 01:00:30,160
itself is not thread safe. And I said, yes, it is because it's environment guarantees that it's

681
01:00:30,160 --> 01:00:36,800
thread safe. That data will only ever be accessed by zero or one threads at any one particular

682
01:00:36,800 --> 01:00:40,880
point in time. And that's the game. And when we start looking at this, and again, this is this

683
01:00:40,880 --> 01:00:46,400
engineering to context idea, is when we talk about when we talk about car safety and road

684
01:00:46,400 --> 01:00:50,560
safety and all the rest of it, we understand that there are conventions, rules of the road,

685
01:00:50,560 --> 01:00:56,400
and contexts in which we evaluate that. And the outside of that, we make no, there's no guarantee.

686
01:00:56,400 --> 01:01:02,000
And that's, again, for my own, for me, that light bulb moment I had when reading

687
01:01:03,120 --> 01:01:07,200
in the early days of patents, actually reading outside the kind of the software space going,

688
01:01:07,200 --> 01:01:13,280
ah, right, this is idea of context. Where does this idea apply? Beyond which we make no guarantees.

689
01:01:13,280 --> 01:01:19,760
And that doesn't mean that it's a bad solution. It just means that it is no longer appropriate or,

690
01:01:19,760 --> 01:01:23,440
you know, outside that context. It's a perfectly fine solution for the thing that it was intended

691
01:01:23,440 --> 01:01:29,760
for. And that, I think, rubs up against a different trend that sometimes we see

692
01:01:30,640 --> 01:01:35,440
developers, architects, and so on, is overgeneralization. The idea that everything must be

693
01:01:35,440 --> 01:01:44,480
general. I think that one of the traps of our disciplines, that it seems to me inherent in

694
01:01:44,480 --> 01:01:53,760
the nature of software, is that we are often inches away from some quite deeply complicated

695
01:01:53,760 --> 01:01:58,800
problems. Whatever the level of abstraction that we're working at almost, as soon as you have,

696
01:01:58,800 --> 01:02:04,640
it seems to me, fundamental, that as soon as you have two copies of information

697
01:02:04,640 --> 01:02:11,840
in separate places that are changing independently, you've got a world-class, first-class,

698
01:02:11,840 --> 01:02:16,320
quantum physics level problem. You know, this is hard stuff. However, you know, whatever the

699
01:02:16,320 --> 01:02:21,600
nature of the information, however is that you deal with it, working on high-performance systems,

700
01:02:21,600 --> 01:02:29,200
along with Martin building exchanges and trading systems and stuff. You know, we measured the costs

701
01:02:29,200 --> 01:02:37,120
of concurrency, locks, comparing swap operations in processes and all those kinds of things to

702
01:02:37,120 --> 01:02:43,440
try and optimize the performance of our systems. And one of the things that I've observed is that

703
01:02:43,440 --> 01:02:48,800
the more that people know about building concurrent systems, the more their advice is,

704
01:02:48,800 --> 01:02:58,400
don't do it unless you can possibly avoid it. This is incredibly difficult stuff. So things

705
01:02:58,400 --> 01:03:02,640
like adding synchronization blocks and saying everybody can now in Java can write threads or

706
01:03:02,640 --> 01:03:13,680
having thousands of locks in your C++ program are all, seems to me, symptoms of not realizing

707
01:03:13,680 --> 01:03:19,200
that this is a point to stop and think hard because this requires hard thinking. This is a

708
01:03:19,200 --> 01:03:25,840
difficult part. It seems to me that concurrency and coupling are the kind of the really hard parts

709
01:03:25,920 --> 01:03:33,840
of our discipline. Yeah, I think so. Because again, coupling is, and what's interesting,

710
01:03:33,840 --> 01:03:37,040
it's interesting you draw those two together because I think the interesting thing about

711
01:03:37,040 --> 01:03:43,360
coupling is that it's, concurrency is hard for us to reason about and conceptualize.

712
01:03:45,440 --> 01:03:51,120
Coupling suffers a different problem. But interesting, but both of both, which I find

713
01:03:51,120 --> 01:03:56,160
fascinating, both of them manifest themselves physically in terms of concurrency is about

714
01:03:56,160 --> 01:04:00,720
structuring things in time. But if somebody says, well, how tightly coupled is this code base,

715
01:04:00,720 --> 01:04:07,600
I'll tell you what, let me do a build. In other words, you can actually measure the energy of

716
01:04:07,600 --> 01:04:14,400
a build. And it's one of those things that I remember turning up at a particular,

717
01:04:15,200 --> 01:04:21,520
it was an engineering project, electricity company, multiple companies were subcontracting.

718
01:04:21,520 --> 01:04:28,800
It was a political nightmare. It was just pure Conway all the way through. But in the failure

719
01:04:28,800 --> 01:04:35,520
mode. And it was a political nightmare. And all kinds of fascinating things. But one of the most

720
01:04:35,520 --> 01:04:42,000
interesting things was, as a development team, the team that I was working with, what we were

721
01:04:42,000 --> 01:04:46,800
working on was very much back end stuff. It was much more towards the hardware, it was the real-time

722
01:04:46,800 --> 01:04:50,960
stuff. But it was kind of like we felt like we came out of our cave to go and speak to these

723
01:04:50,960 --> 01:04:57,600
other people. It's just, oh my goodness, this is absolute enterprise chaos. And then what was

724
01:04:57,600 --> 01:05:00,880
funny is that because we were building for multiple environments, we were building for

725
01:05:01,600 --> 01:05:08,160
32 and 64 bit environments, we were building for slow environments, as well as environments where

726
01:05:08,240 --> 01:05:12,400
we had high-powered CPUs and as we had a framework supposed to work everywhere. But the embedded

727
01:05:12,400 --> 01:05:17,360
environment, oh my goodness, the builds on that were so incredibly slow that we really, we cared

728
01:05:17,360 --> 01:05:21,760
about dependencies at such a level, so that we had fast builds, which meant when we ran out on a

729
01:05:21,760 --> 01:05:26,400
64 bit platform, it was practically instantaneous. It was a beautiful side effect. But then we

730
01:05:26,400 --> 01:05:29,600
encountered all these other people who were just doing all kinds of stuff with their code. And this

731
01:05:29,600 --> 01:05:35,200
was like, I'm going to call it C plus most of what they were writing, because it was clearly

732
01:05:35,200 --> 01:05:41,280
using a C plus plus compiler, but I don't think it got much beyond C. But the way they managed

733
01:05:41,280 --> 01:05:45,760
their dependencies or didn't, everything depended on everything else. And the build times were

734
01:05:45,760 --> 01:05:50,960
staggering and shocking. We ended up building an isolation layer between our company and the rest

735
01:05:51,680 --> 01:05:57,520
as a result, because it's just like we got so used to fast build times on these platforms. And

736
01:05:57,520 --> 01:06:02,240
it's just that idea of like, yeah, I can, you know, how good is your coupling? I can either measure

737
01:06:02,240 --> 01:06:05,920
it in joules or I can actually time it. And you see, you know, it's kind of like, you know,

738
01:06:05,920 --> 01:06:11,680
our builds take a lot less time than your builds, because we've got really, we've stripped it right

739
01:06:11,680 --> 01:06:16,320
down. What is essential? So there's a physical aspect there. But it's not, you know, and again,

740
01:06:16,320 --> 01:06:20,480
concurrency is this physical one, but concurrency would find difficult to reason about because

741
01:06:20,480 --> 01:06:24,160
having so many things in motion is not a, it's not a strength of human beings.

742
01:06:24,720 --> 01:06:29,920
But coupling is, is more a sense of scale is once we've, you know, it's that idea of like,

743
01:06:29,920 --> 01:06:34,000
there's so a large system is like really understanding what a tangle looks like,

744
01:06:34,000 --> 01:06:39,040
really understanding that this dependency means that, and they are both limits, we are limited

745
01:06:39,040 --> 01:06:43,040
by what goes on up here, but in slightly different ways with those two. But I think you're right,

746
01:06:43,040 --> 01:06:48,320
that they are fundamental. They are, they remind us, they remind us of some of the physics that

747
01:06:48,320 --> 01:06:54,880
we do encounter in the universe. And coupling certainly entropy in the build. But concurrency

748
01:06:54,880 --> 01:07:01,040
is, is that point where your idealization lands in the real world. And sometimes it reveals

749
01:07:01,040 --> 01:07:06,160
assumptions. I've certainly had that with one client there. I remember the one, one client,

750
01:07:06,160 --> 01:07:10,640
we did this kind of surgery style thing, you know, I had a couple of days there, I ran some

751
01:07:10,640 --> 01:07:14,960
training, then I had a couple of days, and people would book a morning or an afternoon and kind of,

752
01:07:14,960 --> 01:07:20,880
I'd go with the tea. And I had one, one team say, Oh, well, yeah, an hour of your time this morning

753
01:07:20,880 --> 01:07:23,760
would be great. I said, well, no, you can have the full three hours. They said, no, no, we won't

754
01:07:23,760 --> 01:07:28,480
need that. They walked in. And I remember asking a particular question. I said, you know, looking

755
01:07:28,480 --> 01:07:34,720
at the code, they were going through. And I said, Oh, so how many threads run through this piece of

756
01:07:34,720 --> 01:07:38,880
code? Because I was aware they were using threading. How many threads run through this piece of code?

757
01:07:40,000 --> 01:07:45,040
And there are a number of correct answers to this. Zero is a valid answer, which means this code is

758
01:07:45,040 --> 01:07:51,840
dead. One is also a valid answer. And many is also a valid answer. I didn't get that. What I got is

759
01:07:51,920 --> 01:07:57,520
usually one. And I said, That's interesting. What do you mean by usually one? Why would you not say

760
01:07:57,520 --> 01:08:04,000
that's many? As far as I can say, that's many. Well, what we have is we have a single threaded,

761
01:08:04,000 --> 01:08:08,640
except, you know, this is single threaded code. Except occasionally, another thread will just

762
01:08:08,640 --> 01:08:17,200
sneak into this bit here. Threads don't sneak. And they had this mental model of threading that

763
01:08:17,200 --> 01:08:21,280
was not actually how threading works. They had kind of thought that threading respected the

764
01:08:21,280 --> 01:08:26,880
natural boundaries of the language and statements and blocks and things like that. And they had,

765
01:08:26,880 --> 01:08:31,120
and they said, Well, it only happens occasionally. I said, Well, you know, you only need to fail

766
01:08:31,120 --> 01:08:34,320
occasionally. You know, there's, I said, there's a race condition waiting to happen here, because

767
01:08:34,320 --> 01:08:37,840
you see you load this and then you validate this here. What if something else sneaks in at this

768
01:08:37,840 --> 01:08:41,760
point and you've got an unvalidated, it's just like, and it's kind of like one person looks at

769
01:08:41,760 --> 01:08:44,880
another said, You know, that might explain this intermittent bug we've been having.

770
01:08:45,120 --> 01:08:51,680
And they said, What should we do? Should we add locks everywhere? And I said, No, no, no, no.

771
01:08:51,680 --> 01:08:57,040
Actually, what you need to do is take, take a step back here. Your, the problem is not to add,

772
01:08:57,040 --> 01:09:01,200
but actually to sort of say, Well, why are you doing this? What they were doing was a lazy load.

773
01:09:01,760 --> 01:09:05,440
Yeah. And, and, and it's a case of like, why are you doing the lazy load here? And they said,

774
01:09:05,440 --> 01:09:10,000
Well, we don't know the reasons are lost to time. But I said, because the problem goes away, if you

775
01:09:10,000 --> 01:09:15,280
do an eager load, if you do an eager load before it goes multi threaded, then the data you're looking

776
01:09:15,280 --> 01:09:21,840
at is actually immutable. It's reference data. It's the load that is the state change. And I said,

777
01:09:21,840 --> 01:09:27,040
let's do, let's do the opposite way rather than add locks. Let's take a step back. I mean, honestly,

778
01:09:27,040 --> 01:09:30,160
given enough time, I would have removed all the threads from this application. It was not a

779
01:09:30,160 --> 01:09:34,880
threat application. But, but it was a case of, you know, actually take the opposite view.

780
01:09:35,600 --> 01:09:39,520
This is a question of time, you're doing the load at the wrong time, you're doing, you should be

781
01:09:39,520 --> 01:09:43,520
doing the load before you go multi threaded. And if you do that, then the problem solves itself.

782
01:09:43,520 --> 01:09:48,720
But it's that shift in time and perspective. But my favorite bit, again, to do with time was when,

783
01:09:48,720 --> 01:09:52,320
when the, when the lead in the room said, you know, we might need more than that one hour,

784
01:09:52,320 --> 01:09:59,440
Kevlin now. Because when I said, do you have code like this? Again, it's because it's not,

785
01:10:00,000 --> 01:10:03,360
and it's not to criticize because that's the whole point. It goes back to say, I said earlier,

786
01:10:03,360 --> 01:10:07,920
we are always operating with incomplete knowledge, and we are built filled with assumptions.

787
01:10:08,160 --> 01:10:11,760
Until you've actually run into those, you don't realize what you're missing.

788
01:10:12,720 --> 01:10:16,640
And you, and you don't realize the magnitude of either how well you've done something or

789
01:10:16,640 --> 01:10:20,560
actually how wrong you've understood something. So, oh, actually, no, I'm using completely

790
01:10:20,560 --> 01:10:24,480
the wrong mental model for thinking about this. And that mental model

791
01:10:26,240 --> 01:10:30,320
has informed how I've structured the software, you know, the software is kind of like applied

792
01:10:30,320 --> 01:10:35,760
thought. And that mental model, it's off. And we, so that's the squishy human bit,

793
01:10:35,760 --> 01:10:39,440
that's the learning bit, but it's also the bit we need to be more, we need to sort of say,

794
01:10:39,440 --> 01:10:44,320
yeah, we need to have a bigger process that is tolerant of the fact that we are imperfect.

795
01:10:44,880 --> 01:10:48,560
And we can't know everything. And that's the whole point. This team had not really interacted

796
01:10:48,560 --> 01:10:54,720
with that and had not accommodated that idea at that level. And most teams, I don't think have,

797
01:10:54,720 --> 01:10:58,560
I think it's a very difficult thing for us to do. It's almost against the culture and the nature

798
01:10:58,560 --> 01:11:04,400
of software development in many companies. I think you're absolutely right. And to give me,

799
01:11:04,400 --> 01:11:09,920
bringing it back around to my stuff. But I think that's one of the things that

800
01:11:10,880 --> 01:11:15,440
treating this more like an engineering discipline ought to be able to give us.

801
01:11:15,440 --> 01:11:21,680
It's just those disciplines of just being able to just recognizing that we don't know the answers

802
01:11:21,680 --> 01:11:26,960
when we're starting out, recognizing that we're probably not going to be right. Therefore,

803
01:11:26,960 --> 01:11:31,680
working more experimentally, therefore, working to control, manage the complexity of the systems

804
01:11:31,680 --> 01:11:35,920
that we build and to measure things and to try stuff out. And all of those sorts of things,

805
01:11:36,960 --> 01:11:43,680
test-driven development is certainly part of that for me deeply. But I think that mindset

806
01:11:44,400 --> 01:11:49,680
is so important. One of the other kind of deep properties, it seems to me of software,

807
01:11:50,240 --> 01:11:57,040
is that unlike lots of other things, it's actually very easy to start. You can learn to

808
01:11:57,040 --> 01:12:02,960
write your first simple lines of code in a few minutes. If you've done a little bit of algebra,

809
01:12:02,960 --> 01:12:11,440
at least, it's trivial to just do your first easy, trivial bits of code. But it's deceptive because

810
01:12:13,040 --> 01:12:16,960
you don't go very far before you get into some of these more complicated things that we've been

811
01:12:16,960 --> 01:12:24,080
talking about. And as soon as you start thinking about things like concurrency, that's really hard

812
01:12:24,160 --> 01:12:30,560
for the best people in the world. It's one of those things about Martin Thompson. They're world

813
01:12:30,560 --> 01:12:35,920
class experts at some of these stuff. But they're still, they think really hard and worry about

814
01:12:37,600 --> 01:12:42,160
shared data at any point and all these kinds of things. So to be able to manage this sort of

815
01:12:42,160 --> 01:12:48,000
stuff, it's an interest. I think that's one of the beauties of it. It's a challenge of it that's

816
01:12:48,000 --> 01:12:53,600
delightful. But also, very risky. I've been talking to a few people recently about

817
01:12:55,120 --> 01:13:01,200
low code solutions. And I think that my take is that many of those sorts of systems

818
01:13:01,760 --> 01:13:06,560
suffer from that kind of failing because they assume that it's the almost, that it's the typing

819
01:13:06,560 --> 01:13:12,080
of the code that's the hard part, where it's these broader design concepts and how we organize

820
01:13:12,080 --> 01:13:16,800
the information in ways that we can make a mistake and come back to it in future and correct it.

821
01:13:17,680 --> 01:13:24,240
Identify the mistake. The identification, the recognition of how things, as you say,

822
01:13:24,240 --> 01:13:29,760
is deceptive. Things can get very messy very quickly. And we see that. So I've given a few

823
01:13:30,400 --> 01:13:34,080
partly as a result of failure screens. I've given a few talks on software failures and the

824
01:13:34,080 --> 01:13:40,480
natures of failures and what contribute to them. But one area of enduring fascination for me is

825
01:13:40,480 --> 01:13:44,320
spreadsheets, which I find absolutely fascinating because it takes a good idea and implements it

826
01:13:44,320 --> 01:13:51,280
incredibly badly. In the sense of vision, people find grid forms, it's very, very intuitive.

827
01:13:51,280 --> 01:13:56,400
There's, you know, I mean, what kid doesn't like square paper, you know, this kind of stuff. It's

828
01:13:56,400 --> 01:13:59,840
like, we like laying things out in grids and tables and all the rest of it. This is incredibly

829
01:13:59,840 --> 01:14:03,520
intuitive. And it's, it's a very, to be fair, that might just be you and me.

830
01:14:05,760 --> 01:14:09,920
Yeah, this might be a conversation. Obviously, anybody else in the comments is free to add in.

831
01:14:09,920 --> 01:14:18,160
But, you know, this whole thing is incredibly intuitive at that level. But the problem is

832
01:14:18,160 --> 01:14:25,360
there are two very fundamental issues that scupper spreadsheets and make them massively error prone.

833
01:14:25,360 --> 01:14:32,720
One is, well, three, let me raise that to three. Okay. One is the fact that you end up with a lot

834
01:14:32,720 --> 01:14:37,600
of interdependencies very, very quickly. If you're doing anything that is reasonable.

835
01:14:38,560 --> 01:14:43,840
And then the next bit, and they're all invisible. This is the one, and that this is,

836
01:14:43,840 --> 01:14:47,280
this is the one thing that as a software developer, you kind of look at spreadsheet and go, well,

837
01:14:47,280 --> 01:14:51,680
that's a nice start. But where's the button that I pressed that shows me all the dependencies

838
01:14:52,400 --> 01:14:56,720
between everything you've hidden all of the code, you've hidden a bit that actually makes it

839
01:14:56,720 --> 01:15:02,080
that shows me the structure and therefore reveals my assumptions. You've actually, and I understand.

840
01:15:02,640 --> 01:15:06,160
And there's no real mechanism for me to step back to safety when I screw it up.

841
01:15:06,880 --> 01:15:12,000
Yeah, well, yeah. But there's that idea that we've lost the bit. In other words, what we've done is

842
01:15:12,000 --> 01:15:18,160
we've presented the veneer and treated that as the whole was no software spreadsheets have a deep

843
01:15:18,160 --> 01:15:23,600
structure. But I, you know, honestly, even just using something like even a word document has

844
01:15:23,600 --> 01:15:31,360
better structure, structure tools than Excel. In Excel, I can go in and I've got the grid. That's

845
01:15:31,360 --> 01:15:36,000
it. I'm done. That is my abstraction. That's the level at which I'm invited to think.

846
01:15:36,160 --> 01:15:40,000
The code is fragmented and scattered around the relationships are thrown to the winds.

847
01:15:40,000 --> 01:15:45,680
It's a matter of detective work and archaeology to recover them. Whereas a whereas when I work with

848
01:15:45,680 --> 01:15:52,000
a document, and this is, you know, this, this is true of many different editors and word processes,

849
01:15:52,000 --> 01:15:55,760
I can get a high level structure, I can do an outline structure, I can say show me the dependencies,

850
01:15:55,760 --> 01:16:01,120
show me the cross references to this kind of stuff. In other words, it's spreadsheets are

851
01:16:01,120 --> 01:16:05,040
absolutely, you know, they are an absolute mess. And I always say this and somebody says,

852
01:16:05,040 --> 01:16:09,600
oh, but users find them intuitive. They find them intuitive to use. But they, it's like walking,

853
01:16:09,600 --> 01:16:13,600
it's like walking to a minefield. You can walk into a minefield incredibly easily.

854
01:16:13,600 --> 01:16:17,360
The problem is we have been depriving and I think this is, you know, actually, I'm going to,

855
01:16:17,360 --> 01:16:21,040
I'm going to push this one right back to the profession here. We've been depriving people

856
01:16:21,040 --> 01:16:26,880
of the things that we know. Because we know that a spreadsheet is a, it's got a terrible

857
01:16:26,880 --> 01:16:33,280
type system. It's astonishingly bad. And if anybody ever throws up the argument of backward

858
01:16:33,280 --> 01:16:40,320
compatibility, that is an absolute nonsense. We've actually seen formats for documents change

859
01:16:40,320 --> 01:16:45,760
on a five to 10 year cycle. There's no backward compatibility issue here at all with things

860
01:16:45,760 --> 01:16:50,880
like Excel. That's a myth. You know, you're looking at a five-year window at most. Explain to me why

861
01:16:50,880 --> 01:16:56,320
it is that my, my Excel looks like it was developed 30 years ago, but everything else that I'm using

862
01:16:56,320 --> 01:17:01,920
looks like it was developed in at least the last decade. Why, why is Excel failed to take on board

863
01:17:01,920 --> 01:17:06,720
all of these other tools that we know to show dependencies? And the third thing to come back

864
01:17:06,720 --> 01:17:12,000
to is that people don't realize that there are these issues. So they therefore, they, they, they

865
01:17:12,000 --> 01:17:17,280
scale up very, very, very poorly. They, they embed many mistakes. Now, the point here is what

866
01:17:17,280 --> 01:17:19,840
the reason I'm riffing on this is because you talked about the low code stuff.

867
01:17:20,720 --> 01:17:25,840
Spreadsheets are by far and away the world's most successful low code to low code solution.

868
01:17:25,840 --> 01:17:31,440
And, and anybody who hopes to rival that is just kidding themselves. I'm going to say that right

869
01:17:31,440 --> 01:17:35,600
now, you know, I'm not predicting the future. It's just like those here are very particular

870
01:17:35,600 --> 01:17:41,120
strives. They have embedded themselves in a particular way, you know, in a particular world

871
01:17:41,120 --> 01:17:47,040
and they've, and they're very current. They are ubiquitous. But if anybody wants to learn how

872
01:17:48,400 --> 01:17:52,160
to do and how not to do, learn from its successes and learn from its failures,

873
01:17:52,160 --> 01:17:56,960
and what are the things that it's good at and not good at, and then also go back through the

874
01:17:56,960 --> 01:18:02,560
history of 4GLs. And what you'll discover is that you, what there's a, there's a, there's a line

875
01:18:02,560 --> 01:18:06,880
that you're looking to draw. And you need to understand that it's not universal. There's

876
01:18:06,880 --> 01:18:11,120
a line here. You need to work out where it is. It's like, this is the bit that allows people

877
01:18:11,120 --> 01:18:15,600
the convenience they want. And then there's this other bit that's incredibly hard. If you're, if

878
01:18:15,600 --> 01:18:18,720
you're assuming that they can do, you're going to, you're, they're going to be in for a big and

879
01:18:18,720 --> 01:18:23,680
nasty shock. And we're just going to be throwing more stuff over the wall at other people for,

880
01:18:23,680 --> 01:18:28,160
oh, we need to customize this all. Oh, this is something that we knocked up. And, you know,

881
01:18:28,160 --> 01:18:32,000
but we're having a couple of problems with it. And then kind of suddenly, yes, that it, you know,

882
01:18:32,000 --> 01:18:35,840
it's just like, at this point, they suddenly discover that they are, in fact, an Olympic

883
01:18:35,840 --> 01:18:40,800
runner, because that's the only way they can get away from it faster. That we are, if we're not

884
01:18:40,800 --> 01:18:44,560
doing this one right. So I don't have any grievance with low code. It's just that when people talk

885
01:18:44,560 --> 01:18:50,560
about it as a general solution, no, what's value. It's a highly specific solution. That's its value.

886
01:18:50,640 --> 01:18:57,760
That's the value. Yeah. A narrow, narrow, narrow constrained focus. Yeah. That's really good. That

887
01:18:57,760 --> 01:19:01,760
thing. Yeah. Again, it goes back to this question, this quest for generality that we sometimes have,

888
01:19:01,760 --> 01:19:06,400
we over generalize, make things, either we end up over generalizing, make things ridiculously

889
01:19:06,400 --> 01:19:12,080
complex for ourselves, or we end up not over generalizing and forever working around taking

890
01:19:12,080 --> 01:19:17,680
something that really wasn't. It's, it's, it's, it's that, it's that really, really, you know,

891
01:19:17,680 --> 01:19:21,680
shades of gray kind of slippery slope over a snake pit,

892
01:19:24,640 --> 01:19:29,600
mixing my metaphors horribly. But, but, but you, you can't, you kind of go from, you know,

893
01:19:29,600 --> 01:19:33,600
I'm adding up a column of numbers in my spreadsheet. Cool. That's really nice. It's really good for

894
01:19:33,600 --> 01:19:38,480
that to, you know, I've built this thing. And if I change that, it goes and recalculates all of

895
01:19:38,480 --> 01:19:42,880
these other things. And there's all this, you know, which is an un-maintainable big ball of mud.

896
01:19:42,880 --> 01:19:48,880
And, you know, there's, there's no, there's no easy way to define the line between, between where

897
01:19:48,880 --> 01:19:58,800
you step over and it becomes, you know, it's just like you tread carefully, push, push your foot out

898
01:19:58,800 --> 01:20:03,040
just in front of you, just to, and I think that that is the, again, that feeds back into this

899
01:20:03,040 --> 01:20:09,600
idea that what we're looking for is, is an approach, a philosophical approach, but a practical

900
01:20:09,600 --> 01:20:15,360
approach. And, you know, I'm definitely of the school of thought that, I guess, old school

901
01:20:15,360 --> 01:20:19,280
philosophy, in the sense that philosophy was intended to be a practical thing to help you

902
01:20:19,280 --> 01:20:22,800
understand life. It was not intended to be abstract and disconnected from life. It was

903
01:20:22,800 --> 01:20:28,240
intended to be quite the opposite. So for me, this idea of actually what we want from how we

904
01:20:28,240 --> 01:20:32,400
think about software, we need, we need to understand is like, yeah, it's a bit experimental.

905
01:20:33,040 --> 01:20:37,760
There's, there's, there's things that are unknown. And actually, not only is that okay,

906
01:20:37,760 --> 01:20:44,080
but that's actually part of the job. It's not just acceptable. It is the job. It is the job.

907
01:20:44,080 --> 01:20:49,440
It is the job. So, so, so I've, I've, I've just become aware of the time we've, the amount of time

908
01:20:49,440 --> 01:20:53,440
we were talking about time and now we're aware of it. It's been so, so much fun having the

909
01:20:53,440 --> 01:20:59,520
conversation, but let's try and, let's try and run this off. So, so, so if you, if you could,

910
01:21:00,080 --> 01:21:08,240
if you could summarize this, what's, what's the advice, what do you think is the advice

911
01:21:08,240 --> 01:21:15,600
that we should give people to help walk this, walk this tightrope, explore, you know,

912
01:21:15,600 --> 01:21:19,440
walk into the, into your room of Lego with bare feet.

913
01:21:19,440 --> 01:21:22,480
Yeah. Well, I guess, I guess the simple one is runaway.

914
01:21:23,440 --> 01:21:31,520
That's the only, I think it's really to, to understand that what the challenges that you are,

915
01:21:32,960 --> 01:21:36,960
the challenge and the joy. Let's, let's, let's, I think we're all, we're always

916
01:21:36,960 --> 01:21:40,160
putting up challenges. I think we all need to accept that sometimes the challenge is the fun bit.

917
01:21:40,880 --> 01:21:45,120
You know, it has two, two aspects to it. The challenge and the fun is that you are working

918
01:21:45,120 --> 01:21:49,520
with incomplete knowledge. There is a joy to learning something. And there can also be a joy

919
01:21:49,520 --> 01:21:55,280
in discovering better solutions, alternative solutions, penny dropping moments where you go,

920
01:21:55,280 --> 01:21:59,600
you know what, I've been thinking about this wrong. And, you know, yes, I've over-abstracted.

921
01:21:59,600 --> 01:22:03,920
This really is just a string. The abstractions I wanted to do are over here.

922
01:22:04,800 --> 01:22:09,120
Those are the points that I love those run. Oh, shit. I was thinking of it wrong. And now I can

923
01:22:09,120 --> 01:22:13,360
see a new, new path. That's the thing. And it's the case of like, or I've been devoting my effort

924
01:22:13,360 --> 01:22:17,120
to this, but actually the fun is over here. If I reframe the problem, in other words,

925
01:22:17,200 --> 01:22:22,880
it's that idea of take a step back. And I think a little bit, a little bit

926
01:22:24,080 --> 01:22:28,560
something, I keep reading to do a talk called slow agile. I think I'm probably going to do it at some

927
01:22:28,560 --> 01:22:34,160
point. But it's this idea that although we often use the language of fast in connection with many

928
01:22:34,160 --> 01:22:38,320
of our practices, I think sometimes there's a different emphasis I might want to give, which is

929
01:22:40,000 --> 01:22:44,400
that some of what we're trying to do is to do things sooner, as opposed to faster, which is not

930
01:22:44,480 --> 01:22:49,200
quite the same thing. Yes, I'll use the phrase. I think that might what you might be saying is

931
01:22:49,200 --> 01:22:55,040
the phrase that I use is small steps. Yeah. And small steps are a way of achieving it.

932
01:22:56,080 --> 01:22:59,680
And I was just talking to a group today about refactoring. I was trying to

933
01:23:00,320 --> 01:23:04,240
emphasise to them, you know, in terms of all the design practices and so on. I said, there's a

934
01:23:04,240 --> 01:23:11,840
difference between running and walking. And there's a very simple idea that running is defined by

935
01:23:11,840 --> 01:23:16,320
the fact that at various points, you have zero points of contact with the ground. If you watch

936
01:23:16,320 --> 01:23:21,600
somebody running, it's 0101. If you watch somebody walking, it's 1212. There is always at least one

937
01:23:21,600 --> 01:23:28,880
point of contact with the ground. And now what does this mean? It means you move from moment to

938
01:23:28,880 --> 01:23:35,840
moment more slowly. But you are also moving with more certainty and more sureness and the ability

939
01:23:35,840 --> 01:23:40,320
to change your direction. If you try changing your direction when you are running, or when you

940
01:23:40,400 --> 01:23:45,520
stumble when you're running, and I have relatively recent personal experience of this, and I can

941
01:23:45,520 --> 01:23:51,600
say it hurt an awful lot and I was not able to walk for a few weeks. Whereas had I had that fall

942
01:23:51,600 --> 01:23:55,600
when I was walking, I would have just got up and walked off. The point there is that

943
01:23:56,480 --> 01:24:00,480
software development is not a race. Although we use the language of fast, the time scales

944
01:24:00,480 --> 01:24:05,440
we're thinking of, sometimes it encourages the wrong behaviour, I think. It's again one of those

945
01:24:05,440 --> 01:24:09,680
things when what I use a word and somebody else picks up, oh, they're talking about raw speed.

946
01:24:10,000 --> 01:24:14,720
We're not trying to optimise for speed of development. What we observe is the speed of

947
01:24:14,720 --> 01:24:19,840
development or the speed of deployment. But the thing, it's not the pedal to the metal.

948
01:24:19,840 --> 01:24:25,360
You're just going to exhaust all your developers and exhaust their capacity to think creatively.

949
01:24:25,360 --> 01:24:30,800
It's the idea that actually what we need to be doing is walking. It is the idea of stability.

950
01:24:30,800 --> 01:24:35,680
It's the idea of like, oh, that's not right. Let me just pull back a moment. It's the small steps.

951
01:24:36,480 --> 01:24:41,600
Let's roll back and take a different path. Whether that rollback is a version control rollback,

952
01:24:41,600 --> 01:24:46,240
whether that rollback is a conceptual rollback, whatever it means is the idea that we have given

953
01:24:46,240 --> 01:24:52,960
ourselves the opportunity to pay attention to what we're doing. When you are moving at high

954
01:24:52,960 --> 01:24:56,720
speed, you're not paying attention to your surroundings. All of this talk of feedback just

955
01:24:56,720 --> 01:25:03,120
disappears in the wind. The whole point is you are sensing your way and that you are adjusting

956
01:25:03,120 --> 01:25:08,560
according to that. And it's your feet on the carpet type thing. It's the sensing

957
01:25:08,560 --> 01:25:14,640
your way. How are we doing? I originally intended this, but now I see this. Why? Because I can,

958
01:25:14,640 --> 01:25:19,440
because I've taken the time to do that. I'm not individually, as a human being, remember it's

959
01:25:19,440 --> 01:25:25,520
all about people ultimately, me to appreciate which formal approach I'm going to take, which

960
01:25:25,520 --> 01:25:31,280
structure, which choices, which modules I am going to select, or my criteria for modularity,

961
01:25:31,360 --> 01:25:36,560
which ones I'm going to do here as opposed to there. That's going to take a deliberation that

962
01:25:36,560 --> 01:25:41,520
doesn't happen when you're exhausted and running at speed. It's not a productivity conversation.

963
01:25:41,520 --> 01:25:44,960
So I think for me, most of the advice I give people is just like, honestly,

964
01:25:44,960 --> 01:25:56,080
go a little bit slower because you'll go faster. That's great. I hadn't thought of it in those

965
01:25:56,080 --> 01:26:01,280
words, which is always interesting, and always an interesting thing, but still was reinforcing

966
01:26:01,280 --> 01:26:07,280
my prejudices. So good both ways around. He gave me some new things to think about

967
01:26:08,320 --> 01:26:13,840
and reinforce my prejudices, which is great. I've really enjoyed the talk today. Thank you

968
01:26:13,840 --> 01:26:21,520
so much for taking part. Thank you, Dave. It was a fun exploration. Please do check out

969
01:26:21,520 --> 01:26:30,560
Kevlin. Check his Google Unique name. You'll find his stuff, and lots of good books that Kevlin's

970
01:26:30,560 --> 01:26:37,040
written as well. So thanks, Kevlin, very much indeed. And I'll let you know when the video is

971
01:26:37,040 --> 01:26:46,960
available. Thank you. Thank you very much, Dave. That's brilliant.

