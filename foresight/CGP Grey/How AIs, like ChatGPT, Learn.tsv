start	end	text
0	2960	On the internet, the algorithms are all around you.
2960	6000	You are watching this video because an algorithm brought it to you,
6000	10080	among others, to click, which you did, and the algorithm took note.
10080	13520	When you open the Tweet Book, A, the algorithm decides what you see.
13520	16960	When you search through your photos, A, the algorithm does the finding.
16960	18880	Maybe even makes a little movie for you.
18880	21760	When you buy something, A, the algorithm sets the price,
21760	26000	and A, the algorithm is at your bank watching transactions for fraud.
26000	29680	The stock market is full of algorithms trading with algorithms.
29680	34320	Given this, you might want to know how these little algorithmic bots shaping your world work,
34320	36080	especially when they don't.
36080	38800	In ye olden days, humans built algorithmic bots
38800	42000	by giving them instructions the humans could explain.
42000	43760	If this, then that.
43760	49120	But many problems are just too big and hard for a human to write simple instructions for.
49120	51920	There's a gazillion financial transactions a second.
51920	53600	Which ones are fraudulent?
53600	56000	There's octillion videos on NetMeTube,
56000	58960	which eight should the user see as recommendations,
58960	61600	which shouldn't be allowed on the site at all.
61600	66080	For this airline seat, what is the maximum price this user will pay right now?
66080	68480	Algorithmic bots give answers to these questions,
68480	71840	not perfect answers, but much better than a human could do.
71840	75760	But how these bots work exactly more and more no one knows,
75760	79760	not even the humans who built them, or built them, as we will see.
79760	83360	Now, companies that use these bots don't want to talk about how they work,
83360	85840	because the bots are valuable employees.
85840	87200	Very, very valuable.
87200	90720	And how their brains are built is a fiercely guarded trade secret.
90720	94560	Right now, the cutting edge is most likely very, I hope you like linear algebra,
94560	97360	but what the current hotness is on any particular site,
97360	101200	and how the bots work is a bit, I don't know, and a ways will be.
101200	102800	So let's talk about one of the more quaint,
102800	108320	but understandable ways bots can be built without understanding how their brains work.
108320	111200	Say you want a bot that can recognize what is in a picture.
111200	113360	Is it a B or is it a 3?
113360	115680	It's easy for humans, even little humans,
115760	119840	but it's impossible to just tell a bot in bot language how to do it,
119840	123600	because really we just know that's a B and that's a 3.
123600	127200	We can say in words what makes them different, but bots don't understand words,
127200	131040	and it's the wiring in our brains that makes it happen anyway.
131040	133760	While an individual neuron may be understood,
133760	136800	and clusters of neurons general purpose vaguely grasped,
136800	138480	the whole is beyond.
138480	140000	Nonetheless, it works.
140000	143440	So to get a bot that can do this sorting, you don't build it yourself.
143440	147200	You build a bot that builds bots and a bot that teaches bots.
147200	151600	These bots' brains are simpler, something a smart human programmer can make.
151600	155120	The builder bot builds bots, though it's not very good at it.
155120	159440	At first it connects the wires and modules in the bot brains almost at random.
159440	164480	This leads to some very special student bots sent to teacher bot to teach.
164480	167680	Of course, teacher bot can't tell a B from a 3 either.
167680	171200	If the human could build teacher bot to do that, well then problem solved.
171200	174800	Instead, the human gives teacher bot a bunch of B photos and 3 photos,
174800	177040	and an answer key to which is what.
177040	180800	Teacher bot can't teach, but teacher bot can test.
180800	183920	The adorable student bots stick out their tongues, try very hard,
183920	185840	but they are bad at what they do.
185840	187200	Very, very bad.
187200	188960	And it's not their fault really.
188960	190080	They were built that way.
190080	193600	Grades in hand, the student bots take a march of shame back to builder bot.
193600	197280	Those that did best are put to one side, the others recycled.
197360	199760	Builder bot still isn't good at building bots,
199760	203760	but now it takes those left and makes copies with changes and new combinations.
203760	205440	Back to school they go.
205440	209040	Teacher bot teaches, or tests again, and builder bot builds again.
209040	210880	And again, and again.
210880	214240	Now, a builder that builds at random and a teacher that doesn't teach just tests,
214240	216640	and students who can't learn, they just are what they are,
216640	219680	in theory shouldn't work, but in practice it does.
219680	224960	Partly because in every iteration, builder bot slaughterhouse keeps the best and discards the rest,
224960	229440	and partly because teacher bot isn't overseeing an old-timey one-room schoolhouse
229440	234400	with a dozen students, but an infinite warehouse with thousands of students.
234400	237760	The test isn't 10 questions, but a million questions.
237760	241600	And how many times does the test build test loop repeat?
241600	243920	As many as necessary.
243920	246560	At first, students that survive are just lucky,
246560	250400	but by combining enough lucky bots and keeping only what works,
250400	253200	and randomly messing around with new copies of that,
253200	256480	eventually a student bot emerges that isn't lucky,
256480	259520	that can perhaps barely tell bees from threes.
259520	263280	As this bot is copied and changed, slowly the average test score rises,
263280	267600	and thus the grade needed to survive the next round gets higher and higher.
267600	271040	Keep this up, and eventually from the infinite warehouse slaughterhouse,
271040	274560	a student bot will emerge who can tell a bee from a tree in a photo
274560	276720	it's never seen before pretty well.
276720	279760	But how the student bot does this, neither the teacher bot,
279760	283040	nor the builder bot, nor the human overseer can understand.
283120	285440	Nor the student bot itself.
285440	288400	After keeping so many useful random changes,
288400	291360	the wiring in its head is incredibly complicated,
291360	294400	and while an individual line of code may be understood
294400	297120	and clusters of codes general purpose vaguely grasped,
297120	298960	the whole is beyond.
298960	300640	Nonetheless, it works.
300640	303280	But this is frustrating, especially as the student bot
303280	308000	is very good at exactly only the kinds of questions it's been taught to.
308000	310640	It's great with photos, but useless with videos,
310640	313440	or baffled if the photos are upside down,
313440	317120	or things that are obviously not bees, it's confident are.
317120	318560	Since teacher bot can't teach,
318560	321440	all the human overseer can do is give it more questions
321440	323120	to make the test even longer,
323120	326640	to include the kinds of questions the best bots get wrong.
326640	328560	This is important to understand.
328560	332560	It's a reason why companies are obsessed with collecting data.
332560	335840	More data equals longer tests equals better bots.
335840	338800	So when you get the are you human test on a website,
338800	341280	you are not only proving that you are human, hopefully,
341280	344720	but you are also helping to build the test to make bots that can read,
344720	347680	or count, or tell lakes from mountains or horses from humans.
347680	350080	Seeing lots of questions about driving lately,
350080	352880	hmm, what could that be building a test for?
352880	355280	Now figuring out what's in a photo, or on a sign,
355280	359200	or filtering videos requires humans to make correct enough tests,
359200	362400	but there is another kind of test that makes itself.
362400	364560	Tests on the humans.
364560	368080	For example, say entirely hypothetical NetMeTube
368080	371120	wanted users to keep watching as long as possible.
371120	374480	Well, how long a user stays on the site is easy to measure,
374480	378480	so teacher bot gives each student bot a bunch of NetMeTube users to oversee,
378480	380560	the student bots watch what their user watches,
380560	381520	looks at their files,
381520	384720	and do their best to pick the videos that keep the user on the site,
384720	387280	the longer the average, the higher their test score.
387280	389200	Build, test, repeat.
389200	390320	A million cycles later,
390320	394080	there's a student bot who's pretty good at keeping the users watching,
394080	396560	at least compared to what a human could build.
396560	400160	But when people ask how does the NetMeTube algorithm select videos,
400160	402160	once again, there isn't a great answer,
402160	406160	other than pointing to the bot and the user data it had access to,
406160	411680	and most vitally, how the human overseers direct teacher bot to score the test.
411680	414800	That's what the bot is trying to be good at to survive,
414800	419440	but what the bot is thinking, or how it thinks it, is not really knowable.
419440	423040	All that's knowable is this student bot gets to be the algorithm
423040	429120	because it's 0.1% better than the previous bot at the test the human's design.
429120	431520	So everywhere on the internet, behind the scenes,
431520	433760	there are tests to increase user interaction,
433760	437200	or set prices just right to maximize revenue,
437200	439600	or pick the posts from all your friends you'll like the most,
439600	442080	or articles people will share the most, or whatever.
442080	443760	If it's testable, it's teachable.
443760	444800	Well, teachable.
444800	447200	And a student bot will graduate from the warehouse
447200	451520	to be the algorithm of its domain, at least for a little while.
451520	453680	We're used to the idea that the tools we use,
453680	456320	even if we don't understand them, someone does.
456320	458160	But with our machines that learn,
458160	462400	we are increasingly in a position where we use tools or are used by tools
462400	465680	that no one, not even their creators, understand.
465680	469200	We can only hope to guide them with the tests we make.
469200	470960	And we need to get comfortable with that,
470960	475760	as our algorithmic bot buddies are all around and not going anywhere.
475920	479920	Okay, the bots are watching.
480720	481600	You know what's coming.
482240	488400	This is where I need to ask you to like, comment, and subscribe,
489440	492720	and bell me, and share on the tweet book.
493680	494960	The algorithm is watching.
495840	499120	It won't show people the video unless you do this.
501120	502640	Look what you've reduced me to bots.
504240	505040	What do you want?
505040	506320	Do you want watch time?
506320	507200	Is that what you want?
508080	508480	Fine.
510480	514400	Hey guys, did you know I also have podcasts you can listen to?
514400	516480	Maybe even just in the background,
516480	520640	while you're tidying up your all room for hours or whatever.
520640	523520	There's hours of audio entertainment for you
523520	527040	and watch time for the bots overseeing your actions.
527040	528800	Go ahead and take a click.
528800	533040	Entertain yourself, help me, help the bots.
