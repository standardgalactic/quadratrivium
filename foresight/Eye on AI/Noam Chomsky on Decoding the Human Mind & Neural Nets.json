{"text": " What's called AI today has departed to basically pure engineering. It's designed in such a, the large language models are designed in such a way that in principle, they can't tell you anything about language learning, cognitive processes generally, they can produce useful devices like what I'm using, but the very design ensures that you'll never understand, they'll never lead to any contribution to science. That's not a criticism anymore than I'm criticizing. Camptons this week. I talked to Noam Chomsky, one of the preeminent intellectuals of our time. Our conversation touched on the dichotomy between understanding and application in the field of artificial intelligence. Chomsky argues that AI has shifted from a science aimed at understanding cognition to a pure engineering field focused on creating useful, but not necessarily explanatory tools. He questions whether neural nets truly mirror how the brain functions and whether they exhibit any true intelligence at all. He also suggests that advanced alien life forms would likely have language structured similar to our own, allowing us to communicate. Chomsky is 94 and I reached him at home where he appeared with a clock hanging omnestly over his head. I hope you enjoy the conversation as much as I did. Well, thanks. You're in California. Actually, I'm in Arizona, which is on California time. Yeah. Yeah. Oh, wonderful. Uh, yeah. So, uh, you know, I wanted to talk to you because you have the, uh, you know, one of the few people, uh, with a deep understanding of, of, uh, linguistics and, uh, natural language processing that has the historical knowledge, uh, of, of where we are, how we got to where we are and what, uh, that might mean for the future. Uh, I, I understand the, the, uh, your criticisms of deep learning, uh, and, and what large language models are not in terms of, uh, reasoning and, and, uh, you know, understanding the, the, the underpinnings of, uh, language. But, uh, I, I thought maybe I could ask you to talk about how this developed. I mean, going back to Minsky's, uh, thesis at Princeton, when he was, you know, before he turned against the perceptron, when he was talking about, uh, nets as, uh, a possible model for, uh, biological processes in the brain. And then, you know, how did, how you see that things developed and what were the, the failures that didn't get to where presumably, uh, you would have wanted that research to go, uh, and then, and then I have some other questions. But, but, but is that enough to get started? Well, let's, let's take an analogy. Suppose you're interested in figuring out how, uh, insects navigate biological problem. So, uh, one thing you can do is say, let's try to study in detail what the desert ants are doing in my backyard, how they're using solar azimuths and so on and so forth. Something else you could do is say, look, it's easy. I'll just build an automobile which can navigate, uh, fine, does better than the desert ants. So who cares? Uh, well, those are the two forms of artificial intelligence. One is what Minsky was after. It's now kind of ridiculed as good old fashioned AI, go fi, we're past that stage. Now we just build things that do it better. Okay. Like, uh, an airplane does better than an eagle. So who cares about how eagles fly? Yeah, that's possible. But, uh, it's a difference between totally different goals. Roughly speaking, science and engineering, it's not a sharp difference, but first approximation, either you're interested in understanding something or you're just interested in building something that'll work for some purpose. So they're both fine occupations, nothing wrong with. I mean, when you say I'm criticism of the large, criticizing the large language models, that's not correct. I'm using them right now. I'm reading captions. Captions are based on deep learning, clever programming, very useful. I'm hard of hearing, so they're very helpful to me. No criticism. But if somebody comes along and says, okay, this explains language, you tell them it's kind of like saying an airplane explains how eagles fly, the wrong question. It's not intended to lead to any understanding. It's intended to be for a useful purpose. That's fine. No criticism. And what's called AI today has departed to basically pure engineering. It's designed in such a, the large language models are designed in such a way that in principle, they can't tell you anything about language, learning, cognitive processes generally, they can produce useful devices like what I'm using. But the very design ensures that you'll never understand, they'll never lead to any contribution to science. That's not a criticism anymore than I'm criticizing champions. Jeff Hinton says, you know, his goal is to understand the brain, how the brain works. And he talks about AI as we know it today, supervised learning and generative AI as useful by products, but that are not his goal or not the goal of cognitive science or computational biology. Was there a point at which you think the research lost a bead or is there research going on that people aren't paying attention to that, that is not caught up in the usefulness of these other kinds of neural nets? Well, first of all, if you're interested in how the brain works, the first question you ask is, does it work by neural nets? That's an open question. There's plenty of critical analysis that argues that neural nets are not what's involved, even in simple things like memory. Actually, these arguments that go back to Helmholtz, the neural transmission is pretty slow as compared with the ordinary memory. There's much hard for criticism by people like Randy Gallistel, cognitive neuroscientist, who's given pretty sound arguments that neural nets in principle don't have the ability to capture the core notion of a Turing machine, computational capacity, they just don't have that capacity. And he's argued that the computational capacity is in much richer computational systems in the brain, internal delves, where there's very rich computational capacity, goes wavy on neural net, some experimental evidence to support this. So if you're interested in the brain, that's the kind of thing you look at. Not just saying, can I make bigger neural nets? It's okay if you want to try it, but maybe it's the wrong place to look. So the first question is, is it even the right place to look? That's an open question in neuroscience. If you take a vote among neuroscientists, almost all of them think that neural nets are the right place to look, but you don't solve scientific questions by a vote. Yeah, one of the things that's obvious is neural nets, they may be a model, they may mimic a portion of brain activity, but there are so many other structures. There's all kind of stuff going on in the brain, way down to the cellular level, there's chemical interactions, plenty of other things. So maybe you'll learn something by studying neural nets, if you do, fine, everybody will be happy, but maybe that's not the place to look if you want to study even simple things like just memory and associations. There's now already evidence of associations internal to large cells in the hippocampus, internal to them, which means maybe something's going on at a deeper level where there's vastly more computational capacity. Those are serious questions. So there's nothing wrong with trying to construct models and learn something from them, if you can, fine. The building larger models, which is kind of the rage in the engineering side of AI right now, does produce remarkable results. I mean, what was your reaction when you saw chat GPT or GPT-4 or any of these models, that it's just a sort of clever stochastic parent or that there was something deeper? If you look at the design of the system, you can see it's like an airplane explaining flying. There's nothing to do with it. In fact, it's immediately obvious, trivially obvious, not a deep point, that it can't be teaching us anything. The reason is very simple. The large learning models work just as well for impossible languages that children can't acquire as for the languages they're trained on. So it's as if a biologist came along and said, I got a great new theory of organisms, lists a lot of organisms that possibly exist, a lot that can't possibly exist. And I can tell you nothing about the difference. I mean, that's not a contribution to biology. It doesn't meet the first minimal condition. The first minimal condition is distinguish between what's possible from what's not possible. You can't do that. It's not a contribution to science. If it was a biologist making that proposal, you'd just laugh. Why shouldn't we just laugh when an engineer from Silicon Valley says the same thing? So maybe they're fun. Maybe they're useful for something. Maybe they're harmful. Those are the kinds of questions you ask about pure technology. So take large language models. There are something they're useful. In fact, I'm using them right at this minute. Captions. It's very helpful for people like me. Are they harmful? Yeah, they can cause a lot of harm. Disinformation, defamation, brain on human gullibility. Plenty of examples. So they can cause harm. They can be of use. Those are the kinds of questions you ask about pure engineering, which can be very sophisticated and clever. I mean, the internal combustion engine is a very sophisticated device, but we don't expect it to tell us anything about how a gazelle runs. It's just the wrong question. Yeah, although I talk a lot to Jeff Hinton, and you'll be the first to concede that back propagation there's no evidence of that. And in fact, there's a lot of evidence that it wouldn't work in the brain. Reinforcement learning. You know, I spoke in a rich Sutton, that's been accepted as by a lot of people as an algorithmic model for brain activity in part of the brain, in the lower brain. So in terms of exploring the mechanisms of the brain, it seems that there is some usefulness. I mean, it says, you said there's, on the one hand, people look at the principles, and then they built through engineering, just as the analogy of a bird to an airplane, they've taken some of the principles and applied it through engineering and created something useful. But there are scientists that are looking at what's been created, like Hinton's criticism of back propagation, and are looking for other models that would fit with the principles they see in cognitive science or in the brain. And I mentioned this forward-forward algorithm, which you said you hadn't looked at. But I found it compelling in that it doesn't require signals to be passing back through the neurons. I mean, they pass back, but then stimulate other neurons as you move forward in time. But I mean, is there nothing that's been learned in the study of AI or the research of neural nets? But if you can find anything, it's great. Nothing against search, but it's just, but we have to remember what you asked about chatbots. What do we learn from them? Zero. For the simple reason that the systems work as well for impossible languages as for possible ones. So it's like the biologist with the new theory that has organisms and impossible ones and can't tell the difference. Now, maybe by the look at these systems, you'll learn something about possible organisms. Okay, great. All in favor of learning things. But there's no issues. It's just that the systems themselves, there are great claims by some of the leading figures in the field. We've solved the problem of language acquisition, namely zero contribution, because the systems work as well for impossible languages. Therefore, they can't be telling you anything about language acquisition. Period. Maybe they're useful for something else. Okay, let's take a look. Well, maybe for the audience that this is going out to, you know, I understand what you mean by impossible, impossible, but could you just give a brief synopsis of what you mean by impossible languages for people that haven't read your work? Well, I mean, there are certain general properties that every infant knows, already tested down to two years old, no evidence, couldn't have evidence. So one of the basic properties of language is that the linguistic rules apply to structures, not linear strings. So if you want to take a sentence like instinctively, birds that fly swim, it means instinctively they swim, not instinctively they fly. Well, the adverb instinctively has to find a verb to attach to. It skips the closest verb and finds the structurally closest ones. That principle turns out to be universal for all structures, all constructions, and all languages. What it means is that an infant from birth, as soon as you can test automatically, disregards linear order and disregards 100% of what it hears, notice, as all we hear is words in linear order, but you disregard that and you deal only with abstract structures in your mind, which you never hear. Take another simple example, take the friends of my brothers are in England. Who's in England? The friends of the brothers, the friends, not the brothers, the one that's adjacent, you just disregard all the linear information. It means you disregard everything you hear, everything, and you pay attention only to what your mind constructs. That's the basic, most fundamental property of language. Well, you can make up impossible languages that work with what you hear. Simple rule, take the first relevant thing, associate them. Friends of my brothers are here, brothers are the closest things, and the brothers are here. Trivial rule, much simpler than the rule we use. You can construct languages that use only those simple rules that will be based on the linear order of what we hear. Well, maybe children, people could acquire them as a puzzle somehow using non-linguistic capacities, but they're not what children, infants, reflexively construct with no evidence. Well, there's many things like this, impossible and impossible languages. Well, nobody's tried it out because it's too obvious how it's going to turn out. You take a large language model, apply it to one of these models, systems that use linear order. Of course, it's going to work fine, trivial rules. Well, that's a refutation of the system. Meaning that if you trained it on an impossible language, it would produce impossible languages. How would you mean? Well, you don't even have to train it because the rules are simple. Yeah. Rules are much simpler than the rules of language. Like taking things that are, take the example, the friends of my brother are here. The way we actually do it is we don't say, take the noun phrase that's closest. We don't do that. That would be trivial, but we don't do it. What we say is first construct the structure in your mind, friends of my brothers, then figure out that the central element in that structure is friends, not brothers. And then let's let it be talking about the head of it. It's a pretty complicated computation, but that's the one we do instantaneously and reflexively. And we ignore, and we never see it, hear it, remember? We don't hear structures. All we hear is words in linear order. What we hear is words in linear order. We never use that information. We use only the much more looks like complex. If you think about it computationally, it's actually simpler, but that's a deeper question, which is why we do it. To move to a different dimension, there's a reason for this. The reason has to do with the theory of computation. You're trying to construct an infinite array of structured expressions. Simplest way to do that, the simplest computational procedure is binary set formation. But if you use binary set formation, you're just going to get structures, not order. So what the brain is doing is the simplest computational system, which happens to be very much harder to use. Nature doesn't care about that. Nature constructs the simplest system, doesn't care about it, if it's hard to use or not. I mean, you know, nature could have saved us a lot of trouble if it had developed eight fingers instead of 10. Then we'd have a much better base for computation. But nature didn't care about that when it developed 10 fingers. If you look at evolution, it pays no attention to function. It just constructs the best system at each point. There's a lot of misleading talk about that. But if you just think about the physics of evolution, say a bacterium swallows another organism, the basis for what became complex cells, and nature doesn't get the new system, it reconstructs it in the simplest possible way. It doesn't pay any attention to how complex organisms are going to behave, not what nature can do. And that's the way evolution works all the way down the line. So not surprisingly, nature constructed language so that it's computationally elegant, but dysfunctional, hard to use in many ways. Not nature's problem, just like every other aspect of nature. You can think of a way in which you can do it better, but it didn't happen stage by stage. Two questions from that. So your view is that artificial intelligence, as it's being called, and particularly generative AI, doesn't exhibit true intelligence. Is that right? I wouldn't even say that. It's irrelevant to the question of intelligence. It's not its problem. A guy who designs a jet plane is not trying to answer the question, how do eagles fly? So to say, well, it doesn't tell us how eagles fly is the wrong question to ask. It's not the goal. Except what people are struggling with right now. You've heard the existential threat argument that these models, if they get large enough, they'll actually be more intelligent than humans. That's science fiction. I mean, there is a theoretical possibility. You can give a theoretical argument that, in principle, a complex system with vast search capacity could conceivably turn into something that would start to do things that you can't predict, maybe beyond. But that's even more remote than some distant asteroid, maybe someday hitting the earth, could happen. I mean, if you read a serious scientist on this, like Max Tagmark, his book on the three levels of intelligence, does give a sound theoretical argument as to how a massive system could, say, run through all the scientific discoveries in history, maybe find out some better way of developing them and use that better way to design something new which would destroy us all. It's, in theory, possible, but it's so remote from anything that's available that it's a waste of time to think about it. Yeah, so your view is that whatever threat exists from generative AI, it's the more mundane threat of disinformation. Disinformation, defamation, gullibility, Gary Marcus has done a lot of work on this, real cases, those are problems. I mean, you may have seen that there was a, sort of as a joke, people, somebody developed a defamation of the pope, put an image of the pope, somebody could do it for you, duplicate your face so it looks more or less like your face, pretty much duplicate your voice, develop a robot that looks kind of like you, have you say some insane thing, it would be hard only an expert could tell whether it was you or none. It's like this was done already several times, but basically is a joke. When powerful institutions get started on it, it's not going to be a joke. Another argument that's swirling around these large language models is the question of a sentence of whether if the model is large enough, and this goes a little bit back to how there's a lot more going on in the brain than the neural network or the cerebral cortex, but that there is the potential for some kind of sentence, not necessarily equivalent to human sentence. These are vacuous questions. It's like asking, does a submarine really swim? You want to call that swimming? Yeah, it swims. You don't want to call it swimming? It's not a substantive question. Well, in the sense that it supports the view that there's no separation between consciousness and the material activities of the brain. There's a separation that hasn't been believed since the 17th century. John Locke, after Newton's demonstration, said, well leaves us only with the possibility that thinking is some property of organized matter. That's the 17th century. Yeah, okay. But the belief in a soul and consciousness is something separate from a material biology. It persists. The belief in all kinds of things. But within the rational part of the human species, once Newton demonstrated that the mechanical model doesn't work, there's no material universe in the only sense that was understood. Locke took the obvious conclusion, said, well, since matter, as Mr. Newton has demonstrated, has properties that we cannot conceive of. They're not part of our intuitive picture. Since matter has those properties, organized matter can also have the property of thought. This was investigated all through the 18th century. Ended up finally with Joseph Priestley, a philosopher in the late 18th century, gave pretty extensive discussions of how material, organized material objects could have properties of thought. You can even find it in Darwin's early notebooks. It was kind of forgotten after that. Rediscovered in the late 20th century as some radical new discovery, astonishing hypothesis. Matter can think. Of course it can. In fact, we're doing it right now. But the only problem then is to find out what's involved in what we call thinking, what we call sentience, what are the properties of whatever matter is. We don't know what matter is, but whatever it turns out to be, whatever constitutes the world, what physicists don't know, but whatever it is, there's something organized. Elements of it can have various properties, like the properties that we are now using, properties that we call sentience. Then the question whether something else has sentience is as interesting as whether airplanes fly. If you're talking English, airplanes fly. If you're talking Hebrew, airplanes glide, they don't fly. It's not a substantive question. What metaphors do we like? But what you're saying then is that neural net may not be the engineering solution, but that eventually it may be possible to create a system outside of the human brain that can think whatever thinking means. And do what we call thinking. But whether it thinks or not is like asking the airplanes fly, not a substantive question. We shouldn't waste time on questions that are completely meaningless. Going back to the history then, you know, Minsky was very interested in the possibility of neural nets as a computational model. In Minsky's time, it looked as if neural nets were the right place to look. Now I think it's not so obvious, especially because of Galastal's work, which is not accepted by most neuroscientists, but seems to me pretty compelling. Can you talk a little bit about that because I haven't read that and I'm guessing our readers haven't, our listeners haven't. Galastal is not the only one. Roger Penrose is another Nobel Prize winning physicist, but a number of people have pointed out Galastal mostly that have argued, I think plausibly, that the basic component of a computational system, the basic element of essentially a Turing machine, cannot be constructed from neural nets. So you have to look somewhere else with a different form of computation. And he's also pointed out, but in fact, it's true that there's much richer computational capacity in the brain than neural nets, even internal to a cell. There's massive computational capacity intercellular. So maybe that's involved in computation. And then there's by now some experimental work, I think, giving some evidence for this, but it's a problem for neuroscientists to work on. I'm not an expert in the field. I'm looking at it from the outside, so don't take my opinion too seriously. But to me, it looks pretty compelling. But whatever it is, neural nets or something else, yes, some organization of them, of whatever is there, is giving us the capacity to do what we're doing. So if you're a scientist, what you do is approach it in two different ways. One is you try to find the properties of the system. What is the nature of the system? That's first step kind of thing I was talking about before with structure dependence. What are the properties of the system that an infant automatically develops in the mind? And there's a lot of work on that. From the other point of view, you can say, what can we learn about the brain that relates to this? Actually, there is some work. So there is neurophysiological studies which have shown that for artificial languages that violate the principle that I mentioned, this structure dependent principle, if you train people on those, the ordinary language centers don't function. You get diffuse functioning of the brain, means they're being treated as puzzles basically. So you can find some neurological correlates of some of the things that are discovered by looking at the nature of the phenotype. But it's very hard for humans for a number of reasons. We know a lot about human, the physiology of human vision. But the reason is because of invasive experiments with nonhumans, cats, monkeys and so on. Can't do that for language. There aren't any other organisms unique to humans. So there's no comparative studies. You can think of a lot of invasive experiments which teach you a lot. You can't do them for ethical reasons. So study of the neurophysiology of human cognition is a uniquely hard problem. In its basic elements like language, it's just unique to the species. And in fact, a very recent development in evolutionary history, probably the last couple of hundred thousand years, which is nothing. So you can't do the invasive experiments for ethical reasons. You can think of them, but you can't do them, fortunately. And there's no comparative evidence. So it's much harder to do. You have to do things like, you know, looking at a blood flow in the brain, MRI type things, electrical stimulation, looking from the outside. It's tough. It's not like doing the kind of experiments you can think of. So it's very hard to find out the neurophysiological basis for things like use of language. But it's one way to proceed. And the other way to proceed is learn more about the phenol. It's like chemistry for hundreds of years. You just postulated the existence of atoms. Nobody could see them. You know, why are they there? You know, because unless there are atoms with the Dalton's properties, you don't explain anything. Early genetics, early genetics work before anybody had any idea what a gene is. You just looked at the properties of the system, try to figure out what must be going on. It's the way astrophysics works. You know, most of science works like that. So this does too. When you talk about invasive exploration, there are tools that are increasingly sophisticated. I'm thinking of neural link, Elon Musk's startup that has these super fine electrodes that can be put into the brain without damaging individual neurons. There's actually, I think, much more advanced than that is work that's being done with patients under brain surgery. Under brain surgery, with the brain basically exposed, there are some noninvasive procedures that can be used to study what particular parts of the brain, even particular neurons are doing. It's very delicate work. But there is some work going on. One person is working on it is Andrea Moro, the same person who designed the experiments that I described before about impossible languages. That seems to me a promising direction. There's other kinds of work. I could mention some of it. Alec Moran, why you was doing interesting studies that shed some light on the very elementary function. How do words get stored in the brain? What's going on in the brain that tells us that blake is a possible word, but the nick isn't for an English speaker. It is for an Arabic speaker. What's going on in the brain that deals with that? Hard work. David Peppel, another very good neuroscientist, has found evidence for things like pharyngeal structure in the brain. But the kinds of invasive experiments you can dream of, you can think of, he's just not allowed to do. So you have to try it in much indirect ways. Do you think that understanding cognition has advanced in your lifetime? And are you hopeful that we'll eventually really understand how the brain thinks? Well, there's been vast improvement in understanding the phenotype that we know a great deal about that was not known even a few years ago. There's been some progress in the neuroscience of the relates to it, but it's much harder. Yeah. I'm just curious about where you are in, not physically you're in Arizona, but where you are in your thinking. Are you still pushing forward in trying to understand language in the brain or are you sort of retired, so to speak, at this point? No, very much involved. I mean, I don't work on the neurophysiology. A man I mentioned, Andrea Moro, happens to be a good friend. So I follow the work they're doing, we interact, but my work is just on the phenotype. What's the nature of the system? And there, I think we're learning a lot. I'm right in the middle of papers at the moment, looking at more subtle, complex properties. The idea is essentially to find what I said about binary set formation. How can we show that from the simplest computational procedures, we can account for the apparently complex and apparently varied properties of the language systems. There's a fair amount of progress on that, that was unheard of 20, 30 years ago. So this is all new. Understanding is one thing and then re-creating it through computation in external hardware is another. Is that a blind ally or do you think that? Well, at the moment, I don't see any particular point in it. If there is some point, okay. I mean, the kinds of things that we're learning about the nature of language, I suppose you could construct some sort of system that would duplicate them, but it doesn't seem any obvious point to it. It's like taking chemistry in 100 years ago and saying, can I construct models that will look sort of like, suppose you took, I was saying, a kick of the diagram for an organic molecule and study its properties. You could presumably construct a mechanical model that would do some of those things. Would it be useful? Apparently chemists didn't think so, but if it would, okay. If it wouldn't, then don't. Nonetheless, I mean, we are using neural nets even in this call. Do you see, I mean, setting inside the question of whether or not they help us understand anything about the brain. Are you excited at all in about the promise that these large models hold? I mean, because they do something very useful. They are. Like I said, I'm using it right now. I think it's fine for me, somebody who can't hear to be able to read what you're saying pretty accurately. It's an achievement, so great. I have nothing against technology. And who do you think is going to carry on your work from here? I mean, are there any students of yours who you think we should be paying attention to? Well, quite a lot. A lot of young people doing fine work. In fact, I work with a, closely with a small research group by now, spread all over the world. We meet virtually from Japan and Holland and other places regularly working on the kinds of problems I was talking about. But right now, I should say it's a pretty special interest. Most linguists aren't interested in these foundational questions. But I think that's happened to be my interest. I want to see if we can show the, ultimately try to show that language is essentially a natural object. I mean, there was an interesting paper written about the time that I started working on this by Albert Einstein in 1950. He had an article in Scientific American, which I read, but didn't appreciate at the time, began to appreciate later, in which he talked about what he called a miracle creed. He has an interesting history. It goes back to Galileo. Galileo had a maxim saying, nature is simple. It doesn't do things in a complicated way if it could do them in a simple way. Galileo's maxim couldn't prove it. But they said, I think that's the way it is. That's the task of the scientist to prove it. Well, over the centuries, it's been substantiated case after case. It shows up in Leibniz's principle of optimality. But by then, there was a lot of evidence for it. By now, it's just a norm for science. It's what Einstein called the miracle creed. Nature is simple. Our task is to show it. It says, improve it. Skeptic can say, I don't believe it. Okay. But that's the way science works. Well, this one's worked the same way for language. But you couldn't have proposed that 50 years ago, 20 years ago. I think now you can believe that maybe language is just basically a perfect computational system at its base. You look at the phenomena, it doesn't look like that. But the same was true of biology. Go back to the 1950s, 1960s, biologists assumed that organisms could vary so widely that each one has to be studied on its own without bias. By now, that's all forgotten. It's recognized that there, since the Cambrian explosion, there's virtually no variation in the kinds of organisms, fundamentally all the same. Deep homologies, and so on. So even been proposed that there's a universal genome, not totally accepted, but not considered ridiculous. Well, I think we're in the same direction as the study of language. Now, let me say again, there's not many linguists interested in this. Most linguists, like most biologists, are studying particular things, which is fine. You learn a lot that way. But I think it is possible now to formulate a plausible thesis that language is a natural object like others, which evolved in such a way as to have perfect design, but to be highly dysfunctional. Because that's true of natural objects, generally. It's part of the nature of evolution, which doesn't take into account possible functions. I mean, the last stage of evolution, the reproductive success that does take function into account, natural selection, that's a fringe of evolution. It's just the peripheral fringe, very important, not denigrated, but it's the basic part of evolution is constructing the optimal system that meets the physical conditions established by some disruption in the system. That's the core of evolution. That's what Turing studied. Darcy Thompson, others by now, I think it's understood. And I think maybe the study of this particular biology after a language is a biological object. So why should it be different? Let's see if we can show it. There's been a lot of talk in the news recently about extraterrestrial craft having been found by the government. I don't put much talk in it, but imagine that there is extraterrestrial life, advanced forms of life. Do you think that their language would have developed the same way if it's based on these simple principles? Or is it could there be other forms of language in other biological organisms that would be quote unquote impossible in the human context? Back around the 1960s, I guess, Minsky studied with one of his students, Daniel Belbrom, studied the simplest Turing machines, few estates, fewest symbols, and asked what happens if you just let them run free? Well, it turned out that most of them crash, either get into endless loops or just crash don't proceed. But the ones that didn't crash all produced the successor function. So he suggested what we're going to find if any kind of intelligence develops is it'll be based on the successor function. And if we want to try to communicate with some extraterrestrial intelligence, we should first see if they have the successor function and then maybe build up from there. Well, turns out the successor happens to be what you get from the simplest possible language. The language is one symbol and the simplest form of binary set formation basically gives it a successor function. Add a little bit more to it, you get something like arithmetic. Add a little bit more to it, you get something like the poor properties of language. So it's conceivable that if there is any extraterrestrial intelligence, it would have pursued the same course. Where it goes from there, we don't know enough to say. And back to the idea that there is no super natural realm, that the consciousness is an emergent property from the physical attributes of the brain. Do you believe in a higher intelligence behind the creation or continuation of the universe? I don't see any point in vacuous hypotheses. If you want to believe it okay, it has no consequences. But do you believe it? No, I don't see any point in believing things for which there's no evidence and do no work. And another thing I've always wanted to ask someone like you, clearly your intelligence surpasses most peoples. I don't think so. Well, that's a good, that's interesting that you would say that. You think it's just a matter of applying yourself to study throughout your career. I have certain talents, I know, like not believing things just cause people believe them. And keeping an open mind and looking for arguments and evidence, not anything we've been talking about when meaningless questions are proposed, like our other organism, sentient or the submarine swim, I say let's discard them and look at meaningful questions. If you just pursue common sense like that, I think you can make some progress. Same on the questions we're talking about language. If you think it through, there's every reason why the organic object language should be an object. If so, it should follow the general principles of evolution, which satisfy what Einstein called the miracle creed. So why shouldn't language, so let's pursue that CFR we can do. I think that's just common sense. Many people think it's superior intelligence. I don't think so. That's it for this episode. I want to thank Noam for his time. If you'd like a transcript of this conversation, you can find one on our website, I on AI, that's EYE-ON.AI. In the meantime, remember, the singularity may not be near, but AI is about to change your world. So pay attention.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.84, "text": " What's called AI today has departed to basically pure engineering.", "tokens": [50364, 708, 311, 1219, 7318, 965, 575, 47018, 281, 1936, 6075, 7043, 13, 50706], "temperature": 0.0, "avg_logprob": -0.2336924456167912, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.06533549726009369}, {"id": 1, "seek": 0, "start": 7.6000000000000005, "end": 14.88, "text": " It's designed in such a, the large language models are designed in such a way that in", "tokens": [50744, 467, 311, 4761, 294, 1270, 257, 11, 264, 2416, 2856, 5245, 366, 4761, 294, 1270, 257, 636, 300, 294, 51108], "temperature": 0.0, "avg_logprob": -0.2336924456167912, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.06533549726009369}, {"id": 2, "seek": 0, "start": 14.88, "end": 21.66, "text": " principle, they can't tell you anything about language learning, cognitive", "tokens": [51108, 8665, 11, 436, 393, 380, 980, 291, 1340, 466, 2856, 2539, 11, 15605, 51447], "temperature": 0.0, "avg_logprob": -0.2336924456167912, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.06533549726009369}, {"id": 3, "seek": 0, "start": 21.66, "end": 28.14, "text": " processes generally, they can produce useful devices like what I'm using, but", "tokens": [51447, 7555, 5101, 11, 436, 393, 5258, 4420, 5759, 411, 437, 286, 478, 1228, 11, 457, 51771], "temperature": 0.0, "avg_logprob": -0.2336924456167912, "compression_ratio": 1.5721649484536082, "no_speech_prob": 0.06533549726009369}, {"id": 4, "seek": 2814, "start": 28.14, "end": 33.36, "text": " the very design ensures that you'll never understand, they'll never lead", "tokens": [50364, 264, 588, 1715, 28111, 300, 291, 603, 1128, 1223, 11, 436, 603, 1128, 1477, 50625], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 5, "seek": 2814, "start": 33.36, "end": 36.68, "text": " to any contribution to science.", "tokens": [50625, 281, 604, 13150, 281, 3497, 13, 50791], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 6, "seek": 2814, "start": 37.52, "end": 41.0, "text": " That's not a criticism anymore than I'm criticizing.", "tokens": [50833, 663, 311, 406, 257, 15835, 3602, 813, 286, 478, 45474, 13, 51007], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 7, "seek": 2814, "start": 41.04, "end": 43.480000000000004, "text": " Camptons this week.", "tokens": [51009, 6886, 662, 892, 341, 1243, 13, 51131], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 8, "seek": 2814, "start": 43.480000000000004, "end": 48.06, "text": " I talked to Noam Chomsky, one of the preeminent intellectuals of our time.", "tokens": [51131, 286, 2825, 281, 883, 335, 761, 4785, 4133, 11, 472, 295, 264, 659, 443, 11058, 12576, 82, 295, 527, 565, 13, 51360], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 9, "seek": 2814, "start": 48.620000000000005, "end": 54.44, "text": " Our conversation touched on the dichotomy between understanding and application", "tokens": [51388, 2621, 3761, 9828, 322, 264, 10390, 310, 8488, 1296, 3701, 293, 3861, 51679], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 10, "seek": 2814, "start": 54.44, "end": 56.8, "text": " in the field of artificial intelligence.", "tokens": [51679, 294, 264, 2519, 295, 11677, 7599, 13, 51797], "temperature": 0.0, "avg_logprob": -0.29118634295719925, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0018668040866032243}, {"id": 11, "seek": 5680, "start": 57.339999999999996, "end": 62.739999999999995, "text": " Chomsky argues that AI has shifted from a science aimed at understanding", "tokens": [50391, 761, 4785, 4133, 38218, 300, 7318, 575, 18892, 490, 257, 3497, 20540, 412, 3701, 50661], "temperature": 0.0, "avg_logprob": -0.1788320101224459, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.004533316008746624}, {"id": 12, "seek": 5680, "start": 62.739999999999995, "end": 69.56, "text": " cognition to a pure engineering field focused on creating useful, but not", "tokens": [50661, 46905, 281, 257, 6075, 7043, 2519, 5178, 322, 4084, 4420, 11, 457, 406, 51002], "temperature": 0.0, "avg_logprob": -0.1788320101224459, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.004533316008746624}, {"id": 13, "seek": 5680, "start": 69.56, "end": 73.08, "text": " necessarily explanatory tools.", "tokens": [51002, 4725, 9045, 4745, 3873, 13, 51178], "temperature": 0.0, "avg_logprob": -0.1788320101224459, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.004533316008746624}, {"id": 14, "seek": 5680, "start": 73.6, "end": 79.4, "text": " He questions whether neural nets truly mirror how the brain functions and whether", "tokens": [51204, 634, 1651, 1968, 18161, 36170, 4908, 8013, 577, 264, 3567, 6828, 293, 1968, 51494], "temperature": 0.0, "avg_logprob": -0.1788320101224459, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.004533316008746624}, {"id": 15, "seek": 5680, "start": 79.4, "end": 82.6, "text": " they exhibit any true intelligence at all.", "tokens": [51494, 436, 20487, 604, 2074, 7599, 412, 439, 13, 51654], "temperature": 0.0, "avg_logprob": -0.1788320101224459, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.004533316008746624}, {"id": 16, "seek": 8260, "start": 83.52, "end": 89.11999999999999, "text": " He also suggests that advanced alien life forms would likely have language", "tokens": [50410, 634, 611, 13409, 300, 7339, 12319, 993, 6422, 576, 3700, 362, 2856, 50690], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 17, "seek": 8260, "start": 89.11999999999999, "end": 94.32, "text": " structured similar to our own, allowing us to communicate.", "tokens": [50690, 18519, 2531, 281, 527, 1065, 11, 8293, 505, 281, 7890, 13, 50950], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 18, "seek": 8260, "start": 95.72, "end": 102.19999999999999, "text": " Chomsky is 94 and I reached him at home where he appeared with a clock hanging", "tokens": [51020, 761, 4785, 4133, 307, 30849, 293, 286, 6488, 796, 412, 1280, 689, 415, 8516, 365, 257, 7830, 8345, 51344], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 19, "seek": 8260, "start": 102.22, "end": 104.52, "text": " omnestly over his head.", "tokens": [51345, 3406, 77, 11154, 670, 702, 1378, 13, 51460], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 20, "seek": 8260, "start": 105.39999999999999, "end": 109.28, "text": " I hope you enjoy the conversation as much as I did.", "tokens": [51504, 286, 1454, 291, 2103, 264, 3761, 382, 709, 382, 286, 630, 13, 51698], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 21, "seek": 8260, "start": 110.03999999999999, "end": 110.67999999999999, "text": " Well, thanks.", "tokens": [51736, 1042, 11, 3231, 13, 51768], "temperature": 0.0, "avg_logprob": -0.2082044161283053, "compression_ratio": 1.4312796208530805, "no_speech_prob": 0.010478755459189415}, {"id": 22, "seek": 11068, "start": 110.68, "end": 111.88000000000001, "text": " You're in California.", "tokens": [50364, 509, 434, 294, 5384, 13, 50424], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 23, "seek": 11068, "start": 112.4, "end": 115.76, "text": " Actually, I'm in Arizona, which is on California time.", "tokens": [50450, 5135, 11, 286, 478, 294, 14723, 11, 597, 307, 322, 5384, 565, 13, 50618], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 24, "seek": 11068, "start": 116.08000000000001, "end": 116.44000000000001, "text": " Yeah.", "tokens": [50634, 865, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 25, "seek": 11068, "start": 116.56, "end": 116.80000000000001, "text": " Yeah.", "tokens": [50658, 865, 13, 50670], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 26, "seek": 11068, "start": 116.80000000000001, "end": 117.60000000000001, "text": " Oh, wonderful.", "tokens": [50670, 876, 11, 3715, 13, 50710], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 27, "seek": 11068, "start": 118.12, "end": 119.12, "text": " Uh, yeah.", "tokens": [50736, 4019, 11, 1338, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 28, "seek": 11068, "start": 119.12, "end": 125.88000000000001, "text": " So, uh, you know, I wanted to talk to you because you have the, uh, you know, one", "tokens": [50786, 407, 11, 2232, 11, 291, 458, 11, 286, 1415, 281, 751, 281, 291, 570, 291, 362, 264, 11, 2232, 11, 291, 458, 11, 472, 51124], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 29, "seek": 11068, "start": 125.88000000000001, "end": 131.64000000000001, "text": " of the few people, uh, with a deep understanding of, of, uh, linguistics and,", "tokens": [51124, 295, 264, 1326, 561, 11, 2232, 11, 365, 257, 2452, 3701, 295, 11, 295, 11, 2232, 11, 21766, 6006, 293, 11, 51412], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 30, "seek": 11068, "start": 131.8, "end": 139.0, "text": " uh, natural language processing that has the historical knowledge, uh, of, of", "tokens": [51420, 2232, 11, 3303, 2856, 9007, 300, 575, 264, 8584, 3601, 11, 2232, 11, 295, 11, 295, 51780], "temperature": 0.0, "avg_logprob": -0.2632580662632848, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.002932169707491994}, {"id": 31, "seek": 13900, "start": 139.16, "end": 146.08, "text": " where we are, how we got to where we are and what, uh, that might mean for the future.", "tokens": [50372, 689, 321, 366, 11, 577, 321, 658, 281, 689, 321, 366, 293, 437, 11, 2232, 11, 300, 1062, 914, 337, 264, 2027, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1756667270455309, "compression_ratio": 1.7988505747126438, "no_speech_prob": 0.00254905316978693}, {"id": 32, "seek": 13900, "start": 146.56, "end": 155.24, "text": " Uh, I, I understand the, the, uh, your criticisms of deep learning, uh, and,", "tokens": [50742, 4019, 11, 286, 11, 286, 1223, 264, 11, 264, 11, 2232, 11, 428, 48519, 295, 2452, 2539, 11, 2232, 11, 293, 11, 51176], "temperature": 0.0, "avg_logprob": -0.1756667270455309, "compression_ratio": 1.7988505747126438, "no_speech_prob": 0.00254905316978693}, {"id": 33, "seek": 13900, "start": 155.28, "end": 163.4, "text": " and what large language models are not in terms of, uh, reasoning and, and, uh, you", "tokens": [51178, 293, 437, 2416, 2856, 5245, 366, 406, 294, 2115, 295, 11, 2232, 11, 21577, 293, 11, 293, 11, 2232, 11, 291, 51584], "temperature": 0.0, "avg_logprob": -0.1756667270455309, "compression_ratio": 1.7988505747126438, "no_speech_prob": 0.00254905316978693}, {"id": 34, "seek": 13900, "start": 163.4, "end": 167.68, "text": " know, understanding the, the, the underpinnings of, uh, language.", "tokens": [51584, 458, 11, 3701, 264, 11, 264, 11, 264, 833, 17836, 24451, 295, 11, 2232, 11, 2856, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1756667270455309, "compression_ratio": 1.7988505747126438, "no_speech_prob": 0.00254905316978693}, {"id": 35, "seek": 16768, "start": 168.28, "end": 173.92000000000002, "text": " But, uh, I, I thought maybe I could ask you to talk about how this developed.", "tokens": [50394, 583, 11, 2232, 11, 286, 11, 286, 1194, 1310, 286, 727, 1029, 291, 281, 751, 466, 577, 341, 4743, 13, 50676], "temperature": 0.0, "avg_logprob": -0.14674848797677578, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0016223735874518752}, {"id": 36, "seek": 16768, "start": 173.92000000000002, "end": 179.44, "text": " I mean, going back to Minsky's, uh, thesis at Princeton, when he was, you know,", "tokens": [50676, 286, 914, 11, 516, 646, 281, 376, 44153, 311, 11, 2232, 11, 22288, 412, 36592, 11, 562, 415, 390, 11, 291, 458, 11, 50952], "temperature": 0.0, "avg_logprob": -0.14674848797677578, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0016223735874518752}, {"id": 37, "seek": 16768, "start": 179.44, "end": 186.72, "text": " before he turned against the perceptron, when he was talking about, uh, nets as,", "tokens": [50952, 949, 415, 3574, 1970, 264, 43276, 2044, 11, 562, 415, 390, 1417, 466, 11, 2232, 11, 36170, 382, 11, 51316], "temperature": 0.0, "avg_logprob": -0.14674848797677578, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0016223735874518752}, {"id": 38, "seek": 16768, "start": 186.72, "end": 191.68, "text": " uh, a possible model for, uh, biological processes in the brain.", "tokens": [51316, 2232, 11, 257, 1944, 2316, 337, 11, 2232, 11, 13910, 7555, 294, 264, 3567, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14674848797677578, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0016223735874518752}, {"id": 39, "seek": 19168, "start": 191.68, "end": 199.36, "text": " And then, you know, how did, how you see that things developed and what were", "tokens": [50364, 400, 550, 11, 291, 458, 11, 577, 630, 11, 577, 291, 536, 300, 721, 4743, 293, 437, 645, 50748], "temperature": 0.0, "avg_logprob": -0.1399343790632955, "compression_ratio": 1.6368421052631579, "no_speech_prob": 0.001896508620120585}, {"id": 40, "seek": 19168, "start": 199.36, "end": 205.68, "text": " the, the failures that didn't get to where presumably, uh, you would have wanted", "tokens": [50748, 264, 11, 264, 20774, 300, 994, 380, 483, 281, 689, 26742, 11, 2232, 11, 291, 576, 362, 1415, 51064], "temperature": 0.0, "avg_logprob": -0.1399343790632955, "compression_ratio": 1.6368421052631579, "no_speech_prob": 0.001896508620120585}, {"id": 41, "seek": 19168, "start": 205.68, "end": 211.12, "text": " that research to go, uh, and then, and then I have some other questions.", "tokens": [51064, 300, 2132, 281, 352, 11, 2232, 11, 293, 550, 11, 293, 550, 286, 362, 512, 661, 1651, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1399343790632955, "compression_ratio": 1.6368421052631579, "no_speech_prob": 0.001896508620120585}, {"id": 42, "seek": 19168, "start": 211.12, "end": 213.72, "text": " But, but, but is that enough to get started?", "tokens": [51336, 583, 11, 457, 11, 457, 307, 300, 1547, 281, 483, 1409, 30, 51466], "temperature": 0.0, "avg_logprob": -0.1399343790632955, "compression_ratio": 1.6368421052631579, "no_speech_prob": 0.001896508620120585}, {"id": 43, "seek": 19168, "start": 215.20000000000002, "end": 218.36, "text": " Well, let's, let's take an analogy.", "tokens": [51540, 1042, 11, 718, 311, 11, 718, 311, 747, 364, 21663, 13, 51698], "temperature": 0.0, "avg_logprob": -0.1399343790632955, "compression_ratio": 1.6368421052631579, "no_speech_prob": 0.001896508620120585}, {"id": 44, "seek": 21836, "start": 219.32000000000002, "end": 230.04000000000002, "text": " Suppose you're interested in figuring out how, uh, insects navigate biological", "tokens": [50412, 21360, 291, 434, 3102, 294, 15213, 484, 577, 11, 2232, 11, 20201, 12350, 13910, 50948], "temperature": 0.0, "avg_logprob": -0.17328205393321477, "compression_ratio": 1.4378698224852071, "no_speech_prob": 0.0009108246304094791}, {"id": 45, "seek": 21836, "start": 230.04000000000002, "end": 230.72000000000003, "text": " problem.", "tokens": [50948, 1154, 13, 50982], "temperature": 0.0, "avg_logprob": -0.17328205393321477, "compression_ratio": 1.4378698224852071, "no_speech_prob": 0.0009108246304094791}, {"id": 46, "seek": 21836, "start": 231.44000000000003, "end": 240.64000000000001, "text": " So, uh, one thing you can do is say, let's try to study in detail what the", "tokens": [51018, 407, 11, 2232, 11, 472, 551, 291, 393, 360, 307, 584, 11, 718, 311, 853, 281, 2979, 294, 2607, 437, 264, 51478], "temperature": 0.0, "avg_logprob": -0.17328205393321477, "compression_ratio": 1.4378698224852071, "no_speech_prob": 0.0009108246304094791}, {"id": 47, "seek": 21836, "start": 241.32000000000002, "end": 247.88000000000002, "text": " desert ants are doing in my backyard, how they're using solar azimuths and so on", "tokens": [51512, 11029, 23355, 366, 884, 294, 452, 20036, 11, 577, 436, 434, 1228, 7936, 7883, 332, 2910, 82, 293, 370, 322, 51840], "temperature": 0.0, "avg_logprob": -0.17328205393321477, "compression_ratio": 1.4378698224852071, "no_speech_prob": 0.0009108246304094791}, {"id": 48, "seek": 24788, "start": 247.88, "end": 248.6, "text": " and so forth.", "tokens": [50364, 293, 370, 5220, 13, 50400], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 49, "seek": 24788, "start": 249.6, "end": 252.4, "text": " Something else you could do is say, look, it's easy.", "tokens": [50450, 6595, 1646, 291, 727, 360, 307, 584, 11, 574, 11, 309, 311, 1858, 13, 50590], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 50, "seek": 24788, "start": 253.48, "end": 260.12, "text": " I'll just build an automobile which can navigate, uh, fine, does better than the", "tokens": [50644, 286, 603, 445, 1322, 364, 38809, 597, 393, 12350, 11, 2232, 11, 2489, 11, 775, 1101, 813, 264, 50976], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 51, "seek": 24788, "start": 260.12, "end": 260.88, "text": " desert ants.", "tokens": [50976, 11029, 23355, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 52, "seek": 24788, "start": 261.44, "end": 262.36, "text": " So who cares?", "tokens": [51042, 407, 567, 12310, 30, 51088], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 53, "seek": 24788, "start": 263.2, "end": 267.6, "text": " Uh, well, those are the two forms of artificial intelligence.", "tokens": [51130, 4019, 11, 731, 11, 729, 366, 264, 732, 6422, 295, 11677, 7599, 13, 51350], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 54, "seek": 24788, "start": 268.64, "end": 271.36, "text": " One is what Minsky was after.", "tokens": [51402, 1485, 307, 437, 376, 44153, 390, 934, 13, 51538], "temperature": 0.0, "avg_logprob": -0.18742768764495848, "compression_ratio": 1.3926701570680629, "no_speech_prob": 0.00022337785048875958}, {"id": 55, "seek": 27136, "start": 272.36, "end": 281.48, "text": " It's now kind of ridiculed as good old fashioned AI, go fi, we're past that stage.", "tokens": [50414, 467, 311, 586, 733, 295, 9276, 45893, 382, 665, 1331, 40646, 7318, 11, 352, 15848, 11, 321, 434, 1791, 300, 3233, 13, 50870], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 56, "seek": 27136, "start": 282.16, "end": 284.72, "text": " Now we just build things that do it better.", "tokens": [50904, 823, 321, 445, 1322, 721, 300, 360, 309, 1101, 13, 51032], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 57, "seek": 27136, "start": 285.6, "end": 286.08000000000004, "text": " Okay.", "tokens": [51076, 1033, 13, 51100], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 58, "seek": 27136, "start": 286.96000000000004, "end": 291.08000000000004, "text": " Like, uh, an airplane does better than an eagle.", "tokens": [51144, 1743, 11, 2232, 11, 364, 17130, 775, 1101, 813, 364, 30745, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 59, "seek": 27136, "start": 291.12, "end": 293.2, "text": " So who cares about how eagles fly?", "tokens": [51352, 407, 567, 12310, 466, 577, 308, 33300, 3603, 30, 51456], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 60, "seek": 27136, "start": 294.56, "end": 295.64, "text": " Yeah, that's possible.", "tokens": [51524, 865, 11, 300, 311, 1944, 13, 51578], "temperature": 0.0, "avg_logprob": -0.2557306925455729, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.0061910334043204784}, {"id": 61, "seek": 29564, "start": 296.32, "end": 301.47999999999996, "text": " But, uh, it's a difference between totally different goals.", "tokens": [50398, 583, 11, 2232, 11, 309, 311, 257, 2649, 1296, 3879, 819, 5493, 13, 50656], "temperature": 0.0, "avg_logprob": -0.18381236149714544, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.003074761014431715}, {"id": 62, "seek": 29564, "start": 302.44, "end": 309.24, "text": " Roughly speaking, science and engineering, it's not a sharp difference, but first", "tokens": [50704, 42791, 356, 4124, 11, 3497, 293, 7043, 11, 309, 311, 406, 257, 8199, 2649, 11, 457, 700, 51044], "temperature": 0.0, "avg_logprob": -0.18381236149714544, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.003074761014431715}, {"id": 63, "seek": 29564, "start": 309.24, "end": 314.88, "text": " approximation, either you're interested in understanding something or you're just", "tokens": [51044, 28023, 11, 2139, 291, 434, 3102, 294, 3701, 746, 420, 291, 434, 445, 51326], "temperature": 0.0, "avg_logprob": -0.18381236149714544, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.003074761014431715}, {"id": 64, "seek": 29564, "start": 314.88, "end": 319.08, "text": " interested in building something that'll work for some purpose.", "tokens": [51326, 3102, 294, 2390, 746, 300, 603, 589, 337, 512, 4334, 13, 51536], "temperature": 0.0, "avg_logprob": -0.18381236149714544, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.003074761014431715}, {"id": 65, "seek": 29564, "start": 319.84, "end": 324.44, "text": " So they're both fine occupations, nothing wrong with.", "tokens": [51574, 407, 436, 434, 1293, 2489, 8073, 763, 11, 1825, 2085, 365, 13, 51804], "temperature": 0.0, "avg_logprob": -0.18381236149714544, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.003074761014431715}, {"id": 66, "seek": 32444, "start": 324.92, "end": 329.68, "text": " I mean, when you say I'm criticism of the large, criticizing the large language", "tokens": [50388, 286, 914, 11, 562, 291, 584, 286, 478, 15835, 295, 264, 2416, 11, 45474, 264, 2416, 2856, 50626], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 67, "seek": 32444, "start": 329.68, "end": 331.08, "text": " models, that's not correct.", "tokens": [50626, 5245, 11, 300, 311, 406, 3006, 13, 50696], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 68, "seek": 32444, "start": 331.64, "end": 333.2, "text": " I'm using them right now.", "tokens": [50724, 286, 478, 1228, 552, 558, 586, 13, 50802], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 69, "seek": 32444, "start": 333.8, "end": 335.2, "text": " I'm reading captions.", "tokens": [50832, 286, 478, 3760, 44832, 13, 50902], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 70, "seek": 32444, "start": 336.48, "end": 343.04, "text": " Captions are based on deep learning, clever programming, very useful.", "tokens": [50966, 9480, 626, 366, 2361, 322, 2452, 2539, 11, 13494, 9410, 11, 588, 4420, 13, 51294], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 71, "seek": 32444, "start": 343.52, "end": 346.04, "text": " I'm hard of hearing, so they're very helpful to me.", "tokens": [51318, 286, 478, 1152, 295, 4763, 11, 370, 436, 434, 588, 4961, 281, 385, 13, 51444], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 72, "seek": 32444, "start": 346.56, "end": 347.52, "text": " No criticism.", "tokens": [51470, 883, 15835, 13, 51518], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 73, "seek": 32444, "start": 348.2, "end": 353.72, "text": " But if somebody comes along and says, okay, this explains language, you tell them", "tokens": [51552, 583, 498, 2618, 1487, 2051, 293, 1619, 11, 1392, 11, 341, 13948, 2856, 11, 291, 980, 552, 51828], "temperature": 0.0, "avg_logprob": -0.14147593928318397, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.0010814840206876397}, {"id": 74, "seek": 35372, "start": 353.72, "end": 361.0, "text": " it's kind of like saying an airplane explains how eagles fly, the wrong question.", "tokens": [50364, 309, 311, 733, 295, 411, 1566, 364, 17130, 13948, 577, 308, 33300, 3603, 11, 264, 2085, 1168, 13, 50728], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 75, "seek": 35372, "start": 361.68, "end": 364.68, "text": " It's not intended to lead to any understanding.", "tokens": [50762, 467, 311, 406, 10226, 281, 1477, 281, 604, 3701, 13, 50912], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 76, "seek": 35372, "start": 365.24, "end": 367.48, "text": " It's intended to be for a useful purpose.", "tokens": [50940, 467, 311, 10226, 281, 312, 337, 257, 4420, 4334, 13, 51052], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 77, "seek": 35372, "start": 368.36, "end": 369.08000000000004, "text": " That's fine.", "tokens": [51096, 663, 311, 2489, 13, 51132], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 78, "seek": 35372, "start": 369.8, "end": 370.8, "text": " No criticism.", "tokens": [51168, 883, 15835, 13, 51218], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 79, "seek": 35372, "start": 371.52000000000004, "end": 378.76000000000005, "text": " And what's called AI today has departed to basically pure engineering.", "tokens": [51254, 400, 437, 311, 1219, 7318, 965, 575, 47018, 281, 1936, 6075, 7043, 13, 51616], "temperature": 0.0, "avg_logprob": -0.22569470935397679, "compression_ratio": 1.4861878453038675, "no_speech_prob": 0.0004044033121317625}, {"id": 80, "seek": 37876, "start": 379.48, "end": 386.59999999999997, "text": " It's designed in such a, the large language models are designed in such a way that", "tokens": [50400, 467, 311, 4761, 294, 1270, 257, 11, 264, 2416, 2856, 5245, 366, 4761, 294, 1270, 257, 636, 300, 50756], "temperature": 0.0, "avg_logprob": -0.1607882222042808, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.001151200500316918}, {"id": 81, "seek": 37876, "start": 386.59999999999997, "end": 393.56, "text": " in principle, they can't tell you anything about language, learning, cognitive", "tokens": [50756, 294, 8665, 11, 436, 393, 380, 980, 291, 1340, 466, 2856, 11, 2539, 11, 15605, 51104], "temperature": 0.0, "avg_logprob": -0.1607882222042808, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.001151200500316918}, {"id": 82, "seek": 37876, "start": 393.56, "end": 399.12, "text": " processes generally, they can produce useful devices like what I'm using.", "tokens": [51104, 7555, 5101, 11, 436, 393, 5258, 4420, 5759, 411, 437, 286, 478, 1228, 13, 51382], "temperature": 0.0, "avg_logprob": -0.1607882222042808, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.001151200500316918}, {"id": 83, "seek": 37876, "start": 399.76, "end": 405.0, "text": " But the very design ensures that you'll never understand, they'll never", "tokens": [51414, 583, 264, 588, 1715, 28111, 300, 291, 603, 1128, 1223, 11, 436, 603, 1128, 51676], "temperature": 0.0, "avg_logprob": -0.1607882222042808, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.001151200500316918}, {"id": 84, "seek": 37876, "start": 405.0, "end": 408.59999999999997, "text": " lead to any contribution to science.", "tokens": [51676, 1477, 281, 604, 13150, 281, 3497, 13, 51856], "temperature": 0.0, "avg_logprob": -0.1607882222042808, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.001151200500316918}, {"id": 85, "seek": 40876, "start": 409.4, "end": 413.68, "text": " That's not a criticism anymore than I'm criticizing champions.", "tokens": [50396, 663, 311, 406, 257, 15835, 3602, 813, 286, 478, 45474, 11230, 13, 50610], "temperature": 0.0, "avg_logprob": -0.23355380559371688, "compression_ratio": 1.4146341463414633, "no_speech_prob": 0.0002822810783982277}, {"id": 86, "seek": 40876, "start": 414.36, "end": 420.59999999999997, "text": " Jeff Hinton says, you know, his goal is to understand the brain, how the brain works.", "tokens": [50644, 7506, 389, 12442, 1619, 11, 291, 458, 11, 702, 3387, 307, 281, 1223, 264, 3567, 11, 577, 264, 3567, 1985, 13, 50956], "temperature": 0.0, "avg_logprob": -0.23355380559371688, "compression_ratio": 1.4146341463414633, "no_speech_prob": 0.0002822810783982277}, {"id": 87, "seek": 40876, "start": 421.52, "end": 433.12, "text": " And he talks about AI as we know it today, supervised learning and generative AI as", "tokens": [51002, 400, 415, 6686, 466, 7318, 382, 321, 458, 309, 965, 11, 46533, 2539, 293, 1337, 1166, 7318, 382, 51582], "temperature": 0.0, "avg_logprob": -0.23355380559371688, "compression_ratio": 1.4146341463414633, "no_speech_prob": 0.0002822810783982277}, {"id": 88, "seek": 43312, "start": 433.12, "end": 442.4, "text": " useful by products, but that are not his goal or not the goal of cognitive", "tokens": [50364, 4420, 538, 3383, 11, 457, 300, 366, 406, 702, 3387, 420, 406, 264, 3387, 295, 15605, 50828], "temperature": 0.0, "avg_logprob": -0.1685058655946151, "compression_ratio": 1.4580152671755726, "no_speech_prob": 0.1868329495191574}, {"id": 89, "seek": 43312, "start": 442.4, "end": 446.32, "text": " science or computational biology.", "tokens": [50828, 3497, 420, 28270, 14956, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1685058655946151, "compression_ratio": 1.4580152671755726, "no_speech_prob": 0.1868329495191574}, {"id": 90, "seek": 43312, "start": 448.36, "end": 456.44, "text": " Was there a point at which you think the research lost a bead or is there research", "tokens": [51126, 3027, 456, 257, 935, 412, 597, 291, 519, 264, 2132, 2731, 257, 24117, 420, 307, 456, 2132, 51530], "temperature": 0.0, "avg_logprob": -0.1685058655946151, "compression_ratio": 1.4580152671755726, "no_speech_prob": 0.1868329495191574}, {"id": 91, "seek": 45644, "start": 457.08, "end": 463.96, "text": " going on that people aren't paying attention to that, that is not caught up in the", "tokens": [50396, 516, 322, 300, 561, 3212, 380, 6229, 3202, 281, 300, 11, 300, 307, 406, 5415, 493, 294, 264, 50740], "temperature": 0.0, "avg_logprob": -0.13931283197904887, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003323423210531473}, {"id": 92, "seek": 45644, "start": 463.96, "end": 469.36, "text": " usefulness of these other kinds of neural nets?", "tokens": [50740, 4420, 1287, 295, 613, 661, 3685, 295, 18161, 36170, 30, 51010], "temperature": 0.0, "avg_logprob": -0.13931283197904887, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003323423210531473}, {"id": 93, "seek": 45644, "start": 471.8, "end": 476.6, "text": " Well, first of all, if you're interested in how the brain works, the first question", "tokens": [51132, 1042, 11, 700, 295, 439, 11, 498, 291, 434, 3102, 294, 577, 264, 3567, 1985, 11, 264, 700, 1168, 51372], "temperature": 0.0, "avg_logprob": -0.13931283197904887, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003323423210531473}, {"id": 94, "seek": 45644, "start": 476.6, "end": 480.36, "text": " you ask is, does it work by neural nets?", "tokens": [51372, 291, 1029, 307, 11, 775, 309, 589, 538, 18161, 36170, 30, 51560], "temperature": 0.0, "avg_logprob": -0.13931283197904887, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003323423210531473}, {"id": 95, "seek": 45644, "start": 482.04, "end": 483.32, "text": " That's an open question.", "tokens": [51644, 663, 311, 364, 1269, 1168, 13, 51708], "temperature": 0.0, "avg_logprob": -0.13931283197904887, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003323423210531473}, {"id": 96, "seek": 48332, "start": 484.12, "end": 489.71999999999997, "text": " There's plenty of critical analysis that argues that neural nets are not what's", "tokens": [50404, 821, 311, 7140, 295, 4924, 5215, 300, 38218, 300, 18161, 36170, 366, 406, 437, 311, 50684], "temperature": 0.0, "avg_logprob": -0.24947565029828978, "compression_ratio": 1.5327102803738317, "no_speech_prob": 0.0015481662703678012}, {"id": 97, "seek": 48332, "start": 489.71999999999997, "end": 492.28, "text": " involved, even in simple things like memory.", "tokens": [50684, 3288, 11, 754, 294, 2199, 721, 411, 4675, 13, 50812], "temperature": 0.0, "avg_logprob": -0.24947565029828978, "compression_ratio": 1.5327102803738317, "no_speech_prob": 0.0015481662703678012}, {"id": 98, "seek": 48332, "start": 493.48, "end": 500.84, "text": " Actually, these arguments that go back to Helmholtz, the neural transmission is pretty", "tokens": [50872, 5135, 11, 613, 12869, 300, 352, 646, 281, 6128, 76, 71, 4837, 89, 11, 264, 18161, 11574, 307, 1238, 51240], "temperature": 0.0, "avg_logprob": -0.24947565029828978, "compression_ratio": 1.5327102803738317, "no_speech_prob": 0.0015481662703678012}, {"id": 99, "seek": 48332, "start": 500.84, "end": 504.52, "text": " slow as compared with the ordinary memory.", "tokens": [51240, 2964, 382, 5347, 365, 264, 10547, 4675, 13, 51424], "temperature": 0.0, "avg_logprob": -0.24947565029828978, "compression_ratio": 1.5327102803738317, "no_speech_prob": 0.0015481662703678012}, {"id": 100, "seek": 48332, "start": 505.0, "end": 510.84, "text": " There's much hard for criticism by people like Randy Gallistel, cognitive", "tokens": [51448, 821, 311, 709, 1152, 337, 15835, 538, 561, 411, 23993, 14588, 468, 338, 11, 15605, 51740], "temperature": 0.0, "avg_logprob": -0.24947565029828978, "compression_ratio": 1.5327102803738317, "no_speech_prob": 0.0015481662703678012}, {"id": 101, "seek": 51084, "start": 510.84, "end": 517.4, "text": " neuroscientist, who's given pretty sound arguments that neural nets in principle", "tokens": [50364, 28813, 5412, 468, 11, 567, 311, 2212, 1238, 1626, 12869, 300, 18161, 36170, 294, 8665, 50692], "temperature": 0.0, "avg_logprob": -0.16426809310913085, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0007204532157629728}, {"id": 102, "seek": 51084, "start": 518.28, "end": 528.76, "text": " don't have the ability to capture the core notion of a Turing machine,", "tokens": [50736, 500, 380, 362, 264, 3485, 281, 7983, 264, 4965, 10710, 295, 257, 314, 1345, 3479, 11, 51260], "temperature": 0.0, "avg_logprob": -0.16426809310913085, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0007204532157629728}, {"id": 103, "seek": 51084, "start": 530.52, "end": 533.64, "text": " computational capacity, they just don't have that capacity.", "tokens": [51348, 28270, 6042, 11, 436, 445, 500, 380, 362, 300, 6042, 13, 51504], "temperature": 0.0, "avg_logprob": -0.16426809310913085, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0007204532157629728}, {"id": 104, "seek": 53364, "start": 534.4399999999999, "end": 542.1999999999999, "text": " And he's argued that the computational capacity is in much richer computational", "tokens": [50404, 400, 415, 311, 20219, 300, 264, 28270, 6042, 307, 294, 709, 29021, 28270, 50792], "temperature": 0.0, "avg_logprob": -0.17246826380899508, "compression_ratio": 1.6631016042780749, "no_speech_prob": 0.0035926911514252424}, {"id": 105, "seek": 53364, "start": 542.1999999999999, "end": 550.1999999999999, "text": " systems in the brain, internal delves, where there's very rich computational capacity,", "tokens": [50792, 3652, 294, 264, 3567, 11, 6920, 1103, 977, 11, 689, 456, 311, 588, 4593, 28270, 6042, 11, 51192], "temperature": 0.0, "avg_logprob": -0.17246826380899508, "compression_ratio": 1.6631016042780749, "no_speech_prob": 0.0035926911514252424}, {"id": 106, "seek": 53364, "start": 550.1999999999999, "end": 555.72, "text": " goes wavy on neural net, some experimental evidence to support this.", "tokens": [51192, 1709, 261, 15498, 322, 18161, 2533, 11, 512, 17069, 4467, 281, 1406, 341, 13, 51468], "temperature": 0.0, "avg_logprob": -0.17246826380899508, "compression_ratio": 1.6631016042780749, "no_speech_prob": 0.0035926911514252424}, {"id": 107, "seek": 53364, "start": 556.36, "end": 559.64, "text": " So if you're interested in the brain, that's the kind of thing you look at.", "tokens": [51500, 407, 498, 291, 434, 3102, 294, 264, 3567, 11, 300, 311, 264, 733, 295, 551, 291, 574, 412, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17246826380899508, "compression_ratio": 1.6631016042780749, "no_speech_prob": 0.0035926911514252424}, {"id": 108, "seek": 55964, "start": 560.6, "end": 563.64, "text": " Not just saying, can I make bigger neural nets?", "tokens": [50412, 1726, 445, 1566, 11, 393, 286, 652, 3801, 18161, 36170, 30, 50564], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 109, "seek": 55964, "start": 564.84, "end": 569.08, "text": " It's okay if you want to try it, but maybe it's the wrong place to look.", "tokens": [50624, 467, 311, 1392, 498, 291, 528, 281, 853, 309, 11, 457, 1310, 309, 311, 264, 2085, 1081, 281, 574, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 110, "seek": 55964, "start": 569.64, "end": 573.0, "text": " So the first question is, is it even the right place to look?", "tokens": [50864, 407, 264, 700, 1168, 307, 11, 307, 309, 754, 264, 558, 1081, 281, 574, 30, 51032], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 111, "seek": 55964, "start": 573.96, "end": 577.48, "text": " That's an open question in neuroscience.", "tokens": [51080, 663, 311, 364, 1269, 1168, 294, 42762, 13, 51256], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 112, "seek": 55964, "start": 578.36, "end": 583.72, "text": " If you take a vote among neuroscientists, almost all of them think that neural nets", "tokens": [51300, 759, 291, 747, 257, 4740, 3654, 28813, 5412, 1751, 11, 1920, 439, 295, 552, 519, 300, 18161, 36170, 51568], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 113, "seek": 55964, "start": 583.72, "end": 589.08, "text": " are the right place to look, but you don't solve scientific questions by a vote.", "tokens": [51568, 366, 264, 558, 1081, 281, 574, 11, 457, 291, 500, 380, 5039, 8134, 1651, 538, 257, 4740, 13, 51836], "temperature": 0.0, "avg_logprob": -0.14531014266523343, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0009543975465930998}, {"id": 114, "seek": 58964, "start": 590.36, "end": 600.1999999999999, "text": " Yeah, one of the things that's obvious is neural nets, they may be a model,", "tokens": [50400, 865, 11, 472, 295, 264, 721, 300, 311, 6322, 307, 18161, 36170, 11, 436, 815, 312, 257, 2316, 11, 50892], "temperature": 0.0, "avg_logprob": -0.14854026794433595, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.00021315374760888517}, {"id": 115, "seek": 58964, "start": 600.1999999999999, "end": 607.0, "text": " they may mimic a portion of brain activity, but there are so many other structures.", "tokens": [50892, 436, 815, 31075, 257, 8044, 295, 3567, 5191, 11, 457, 456, 366, 370, 867, 661, 9227, 13, 51232], "temperature": 0.0, "avg_logprob": -0.14854026794433595, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.00021315374760888517}, {"id": 116, "seek": 58964, "start": 608.04, "end": 613.3199999999999, "text": " There's all kind of stuff going on in the brain, way down to the cellular level,", "tokens": [51284, 821, 311, 439, 733, 295, 1507, 516, 322, 294, 264, 3567, 11, 636, 760, 281, 264, 29267, 1496, 11, 51548], "temperature": 0.0, "avg_logprob": -0.14854026794433595, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.00021315374760888517}, {"id": 117, "seek": 58964, "start": 613.3199999999999, "end": 616.04, "text": " there's chemical interactions, plenty of other things.", "tokens": [51548, 456, 311, 7313, 13280, 11, 7140, 295, 661, 721, 13, 51684], "temperature": 0.0, "avg_logprob": -0.14854026794433595, "compression_ratio": 1.560846560846561, "no_speech_prob": 0.00021315374760888517}, {"id": 118, "seek": 61604, "start": 616.92, "end": 623.4, "text": " So maybe you'll learn something by studying neural nets, if you do, fine, everybody will be happy,", "tokens": [50408, 407, 1310, 291, 603, 1466, 746, 538, 7601, 18161, 36170, 11, 498, 291, 360, 11, 2489, 11, 2201, 486, 312, 2055, 11, 50732], "temperature": 0.0, "avg_logprob": -0.11709568598499037, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00020658822904806584}, {"id": 119, "seek": 61604, "start": 624.1999999999999, "end": 629.88, "text": " but maybe that's not the place to look if you want to study even simple things like just", "tokens": [50772, 457, 1310, 300, 311, 406, 264, 1081, 281, 574, 498, 291, 528, 281, 2979, 754, 2199, 721, 411, 445, 51056], "temperature": 0.0, "avg_logprob": -0.11709568598499037, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00020658822904806584}, {"id": 120, "seek": 61604, "start": 630.52, "end": 632.1999999999999, "text": " memory and associations.", "tokens": [51088, 4675, 293, 26597, 13, 51172], "temperature": 0.0, "avg_logprob": -0.11709568598499037, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00020658822904806584}, {"id": 121, "seek": 61604, "start": 633.0799999999999, "end": 641.24, "text": " There's now already evidence of associations internal to large cells in the hippocampus,", "tokens": [51216, 821, 311, 586, 1217, 4467, 295, 26597, 6920, 281, 2416, 5438, 294, 264, 27745, 905, 1215, 301, 11, 51624], "temperature": 0.0, "avg_logprob": -0.11709568598499037, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.00020658822904806584}, {"id": 122, "seek": 64124, "start": 642.04, "end": 649.24, "text": " internal to them, which means maybe something's going on at a deeper level where there's vastly", "tokens": [50404, 6920, 281, 552, 11, 597, 1355, 1310, 746, 311, 516, 322, 412, 257, 7731, 1496, 689, 456, 311, 41426, 50764], "temperature": 0.0, "avg_logprob": -0.14071184251366592, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0006877660634927452}, {"id": 123, "seek": 64124, "start": 649.24, "end": 651.08, "text": " more computational capacity.", "tokens": [50764, 544, 28270, 6042, 13, 50856], "temperature": 0.0, "avg_logprob": -0.14071184251366592, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0006877660634927452}, {"id": 124, "seek": 64124, "start": 653.24, "end": 654.84, "text": " Those are serious questions.", "tokens": [50964, 3950, 366, 3156, 1651, 13, 51044], "temperature": 0.0, "avg_logprob": -0.14071184251366592, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0006877660634927452}, {"id": 125, "seek": 64124, "start": 655.72, "end": 661.4, "text": " So there's nothing wrong with trying to construct models and learn something from them, if you can, fine.", "tokens": [51088, 407, 456, 311, 1825, 2085, 365, 1382, 281, 7690, 5245, 293, 1466, 746, 490, 552, 11, 498, 291, 393, 11, 2489, 13, 51372], "temperature": 0.0, "avg_logprob": -0.14071184251366592, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0006877660634927452}, {"id": 126, "seek": 64124, "start": 662.04, "end": 669.48, "text": " The building larger models, which is kind of the rage in the engineering side of AI right now,", "tokens": [51404, 440, 2390, 4833, 5245, 11, 597, 307, 733, 295, 264, 20133, 294, 264, 7043, 1252, 295, 7318, 558, 586, 11, 51776], "temperature": 0.0, "avg_logprob": -0.14071184251366592, "compression_ratio": 1.5733333333333333, "no_speech_prob": 0.0006877660634927452}, {"id": 127, "seek": 66948, "start": 670.44, "end": 673.0, "text": " does produce remarkable results.", "tokens": [50412, 775, 5258, 12802, 3542, 13, 50540], "temperature": 0.0, "avg_logprob": -0.23655934169374662, "compression_ratio": 1.36, "no_speech_prob": 0.0004171468026470393}, {"id": 128, "seek": 66948, "start": 673.0, "end": 676.52, "text": " I mean, what was your reaction when you saw", "tokens": [50540, 286, 914, 11, 437, 390, 428, 5480, 562, 291, 1866, 50716], "temperature": 0.0, "avg_logprob": -0.23655934169374662, "compression_ratio": 1.36, "no_speech_prob": 0.0004171468026470393}, {"id": 129, "seek": 66948, "start": 678.6, "end": 689.0, "text": " chat GPT or GPT-4 or any of these models, that it's just a sort of clever stochastic parent", "tokens": [50820, 5081, 26039, 51, 420, 26039, 51, 12, 19, 420, 604, 295, 613, 5245, 11, 300, 309, 311, 445, 257, 1333, 295, 13494, 342, 8997, 2750, 2596, 51340], "temperature": 0.0, "avg_logprob": -0.23655934169374662, "compression_ratio": 1.36, "no_speech_prob": 0.0004171468026470393}, {"id": 130, "seek": 66948, "start": 689.0, "end": 692.12, "text": " or that there was something deeper?", "tokens": [51340, 420, 300, 456, 390, 746, 7731, 30, 51496], "temperature": 0.0, "avg_logprob": -0.23655934169374662, "compression_ratio": 1.36, "no_speech_prob": 0.0004171468026470393}, {"id": 131, "seek": 69212, "start": 692.2, "end": 701.72, "text": " If you look at the design of the system, you can see it's like an airplane explaining flying.", "tokens": [50368, 759, 291, 574, 412, 264, 1715, 295, 264, 1185, 11, 291, 393, 536, 309, 311, 411, 364, 17130, 13468, 7137, 13, 50844], "temperature": 0.0, "avg_logprob": -0.10753174085874816, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.006095482502132654}, {"id": 132, "seek": 69212, "start": 702.6, "end": 703.72, "text": " There's nothing to do with it.", "tokens": [50888, 821, 311, 1825, 281, 360, 365, 309, 13, 50944], "temperature": 0.0, "avg_logprob": -0.10753174085874816, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.006095482502132654}, {"id": 133, "seek": 69212, "start": 704.36, "end": 711.72, "text": " In fact, it's immediately obvious, trivially obvious, not a deep point, that it can't be", "tokens": [50976, 682, 1186, 11, 309, 311, 4258, 6322, 11, 1376, 85, 2270, 6322, 11, 406, 257, 2452, 935, 11, 300, 309, 393, 380, 312, 51344], "temperature": 0.0, "avg_logprob": -0.10753174085874816, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.006095482502132654}, {"id": 134, "seek": 69212, "start": 711.72, "end": 712.84, "text": " teaching us anything.", "tokens": [51344, 4571, 505, 1340, 13, 51400], "temperature": 0.0, "avg_logprob": -0.10753174085874816, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.006095482502132654}, {"id": 135, "seek": 69212, "start": 713.5600000000001, "end": 714.84, "text": " The reason is very simple.", "tokens": [51436, 440, 1778, 307, 588, 2199, 13, 51500], "temperature": 0.0, "avg_logprob": -0.10753174085874816, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.006095482502132654}, {"id": 136, "seek": 71484, "start": 715.8000000000001, "end": 724.6800000000001, "text": " The large learning models work just as well for impossible languages that children can't acquire", "tokens": [50412, 440, 2416, 2539, 5245, 589, 445, 382, 731, 337, 6243, 8650, 300, 2227, 393, 380, 20001, 50856], "temperature": 0.0, "avg_logprob": -0.10479704753772633, "compression_ratio": 1.6236559139784945, "no_speech_prob": 0.0007319721044041216}, {"id": 137, "seek": 71484, "start": 725.32, "end": 727.96, "text": " as for the languages they're trained on.", "tokens": [50888, 382, 337, 264, 8650, 436, 434, 8895, 322, 13, 51020], "temperature": 0.0, "avg_logprob": -0.10479704753772633, "compression_ratio": 1.6236559139784945, "no_speech_prob": 0.0007319721044041216}, {"id": 138, "seek": 71484, "start": 728.84, "end": 736.0400000000001, "text": " So it's as if a biologist came along and said, I got a great new theory of organisms, lists a", "tokens": [51064, 407, 309, 311, 382, 498, 257, 3228, 9201, 1361, 2051, 293, 848, 11, 286, 658, 257, 869, 777, 5261, 295, 22110, 11, 14511, 257, 51424], "temperature": 0.0, "avg_logprob": -0.10479704753772633, "compression_ratio": 1.6236559139784945, "no_speech_prob": 0.0007319721044041216}, {"id": 139, "seek": 71484, "start": 736.0400000000001, "end": 742.6800000000001, "text": " lot of organisms that possibly exist, a lot that can't possibly exist.", "tokens": [51424, 688, 295, 22110, 300, 6264, 2514, 11, 257, 688, 300, 393, 380, 6264, 2514, 13, 51756], "temperature": 0.0, "avg_logprob": -0.10479704753772633, "compression_ratio": 1.6236559139784945, "no_speech_prob": 0.0007319721044041216}, {"id": 140, "seek": 74268, "start": 742.68, "end": 744.76, "text": " And I can tell you nothing about the difference.", "tokens": [50364, 400, 286, 393, 980, 291, 1825, 466, 264, 2649, 13, 50468], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 141, "seek": 74268, "start": 746.68, "end": 750.04, "text": " I mean, that's not a contribution to biology.", "tokens": [50564, 286, 914, 11, 300, 311, 406, 257, 13150, 281, 14956, 13, 50732], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 142, "seek": 74268, "start": 750.8399999999999, "end": 753.4799999999999, "text": " It doesn't meet the first minimal condition.", "tokens": [50772, 467, 1177, 380, 1677, 264, 700, 13206, 4188, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 143, "seek": 74268, "start": 754.3599999999999, "end": 760.76, "text": " The first minimal condition is distinguish between what's possible from what's not possible.", "tokens": [50948, 440, 700, 13206, 4188, 307, 20206, 1296, 437, 311, 1944, 490, 437, 311, 406, 1944, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 144, "seek": 74268, "start": 761.4799999999999, "end": 762.4399999999999, "text": " You can't do that.", "tokens": [51304, 509, 393, 380, 360, 300, 13, 51352], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 145, "seek": 74268, "start": 763.7199999999999, "end": 765.4799999999999, "text": " It's not a contribution to science.", "tokens": [51416, 467, 311, 406, 257, 13150, 281, 3497, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1392247096912281, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0004107456770725548}, {"id": 146, "seek": 76548, "start": 766.28, "end": 771.5600000000001, "text": " If it was a biologist making that proposal, you'd just laugh.", "tokens": [50404, 759, 309, 390, 257, 3228, 9201, 1455, 300, 11494, 11, 291, 1116, 445, 5801, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 147, "seek": 76548, "start": 772.6, "end": 778.6, "text": " Why shouldn't we just laugh when an engineer from Silicon Valley says the same thing?", "tokens": [50720, 1545, 4659, 380, 321, 445, 5801, 562, 364, 11403, 490, 25351, 10666, 1619, 264, 912, 551, 30, 51020], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 148, "seek": 76548, "start": 780.2, "end": 782.2, "text": " So maybe they're fun.", "tokens": [51100, 407, 1310, 436, 434, 1019, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 149, "seek": 76548, "start": 782.2, "end": 784.2, "text": " Maybe they're useful for something.", "tokens": [51200, 2704, 436, 434, 4420, 337, 746, 13, 51300], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 150, "seek": 76548, "start": 784.2, "end": 785.32, "text": " Maybe they're harmful.", "tokens": [51300, 2704, 436, 434, 19727, 13, 51356], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 151, "seek": 76548, "start": 786.04, "end": 790.12, "text": " Those are the kinds of questions you ask about pure technology.", "tokens": [51392, 3950, 366, 264, 3685, 295, 1651, 291, 1029, 466, 6075, 2899, 13, 51596], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 152, "seek": 76548, "start": 791.08, "end": 793.0, "text": " So take large language models.", "tokens": [51644, 407, 747, 2416, 2856, 5245, 13, 51740], "temperature": 0.0, "avg_logprob": -0.1502786704472133, "compression_ratio": 1.5528846153846154, "no_speech_prob": 0.0013665588339790702}, {"id": 153, "seek": 79300, "start": 793.64, "end": 795.16, "text": " There are something they're useful.", "tokens": [50396, 821, 366, 746, 436, 434, 4420, 13, 50472], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 154, "seek": 79300, "start": 796.04, "end": 798.44, "text": " In fact, I'm using them right at this minute.", "tokens": [50516, 682, 1186, 11, 286, 478, 1228, 552, 558, 412, 341, 3456, 13, 50636], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 155, "seek": 79300, "start": 799.72, "end": 800.28, "text": " Captions.", "tokens": [50700, 9480, 626, 13, 50728], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 156, "seek": 79300, "start": 801.08, "end": 803.0, "text": " It's very helpful for people like me.", "tokens": [50768, 467, 311, 588, 4961, 337, 561, 411, 385, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 157, "seek": 79300, "start": 804.76, "end": 805.64, "text": " Are they harmful?", "tokens": [50952, 2014, 436, 19727, 30, 50996], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 158, "seek": 79300, "start": 806.28, "end": 808.04, "text": " Yeah, they can cause a lot of harm.", "tokens": [51028, 865, 11, 436, 393, 3082, 257, 688, 295, 6491, 13, 51116], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 159, "seek": 79300, "start": 808.92, "end": 814.44, "text": " Disinformation, defamation, brain on human gullibility.", "tokens": [51160, 4208, 20941, 11, 1060, 30477, 11, 3567, 322, 1952, 695, 285, 2841, 13, 51436], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 160, "seek": 79300, "start": 815.16, "end": 816.12, "text": " Plenty of examples.", "tokens": [51472, 2149, 4179, 295, 5110, 13, 51520], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 161, "seek": 79300, "start": 817.4, "end": 818.84, "text": " So they can cause harm.", "tokens": [51584, 407, 436, 393, 3082, 6491, 13, 51656], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 162, "seek": 79300, "start": 818.84, "end": 819.88, "text": " They can be of use.", "tokens": [51656, 814, 393, 312, 295, 764, 13, 51708], "temperature": 0.0, "avg_logprob": -0.18915715168431863, "compression_ratio": 1.5303030303030303, "no_speech_prob": 0.001726747490465641}, {"id": 163, "seek": 81988, "start": 820.84, "end": 825.4, "text": " Those are the kinds of questions you ask about pure engineering,", "tokens": [50412, 3950, 366, 264, 3685, 295, 1651, 291, 1029, 466, 6075, 7043, 11, 50640], "temperature": 0.0, "avg_logprob": -0.13226486980051233, "compression_ratio": 1.553072625698324, "no_speech_prob": 0.00043045575148425996}, {"id": 164, "seek": 81988, "start": 826.12, "end": 828.4399999999999, "text": " which can be very sophisticated and clever.", "tokens": [50676, 597, 393, 312, 588, 16950, 293, 13494, 13, 50792], "temperature": 0.0, "avg_logprob": -0.13226486980051233, "compression_ratio": 1.553072625698324, "no_speech_prob": 0.00043045575148425996}, {"id": 165, "seek": 81988, "start": 829.24, "end": 834.2, "text": " I mean, the internal combustion engine is a very sophisticated device,", "tokens": [50832, 286, 914, 11, 264, 6920, 28121, 2848, 307, 257, 588, 16950, 4302, 11, 51080], "temperature": 0.0, "avg_logprob": -0.13226486980051233, "compression_ratio": 1.553072625698324, "no_speech_prob": 0.00043045575148425996}, {"id": 166, "seek": 81988, "start": 835.56, "end": 841.16, "text": " but we don't expect it to tell us anything about how a gazelle runs.", "tokens": [51148, 457, 321, 500, 380, 2066, 309, 281, 980, 505, 1340, 466, 577, 257, 26232, 4434, 6676, 13, 51428], "temperature": 0.0, "avg_logprob": -0.13226486980051233, "compression_ratio": 1.553072625698324, "no_speech_prob": 0.00043045575148425996}, {"id": 167, "seek": 81988, "start": 842.84, "end": 844.12, "text": " It's just the wrong question.", "tokens": [51512, 467, 311, 445, 264, 2085, 1168, 13, 51576], "temperature": 0.0, "avg_logprob": -0.13226486980051233, "compression_ratio": 1.553072625698324, "no_speech_prob": 0.00043045575148425996}, {"id": 168, "seek": 84412, "start": 845.08, "end": 858.12, "text": " Yeah, although I talk a lot to Jeff Hinton, and you'll be the first to concede that back propagation", "tokens": [50412, 865, 11, 4878, 286, 751, 257, 688, 281, 7506, 389, 12442, 11, 293, 291, 603, 312, 264, 700, 281, 416, 29815, 300, 646, 38377, 51064], "temperature": 0.0, "avg_logprob": -0.23722194135189056, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.006093541160225868}, {"id": 169, "seek": 84412, "start": 859.5600000000001, "end": 860.92, "text": " there's no evidence of that.", "tokens": [51136, 456, 311, 572, 4467, 295, 300, 13, 51204], "temperature": 0.0, "avg_logprob": -0.23722194135189056, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.006093541160225868}, {"id": 170, "seek": 84412, "start": 860.92, "end": 866.04, "text": " And in fact, there's a lot of evidence that it wouldn't work in the brain.", "tokens": [51204, 400, 294, 1186, 11, 456, 311, 257, 688, 295, 4467, 300, 309, 2759, 380, 589, 294, 264, 3567, 13, 51460], "temperature": 0.0, "avg_logprob": -0.23722194135189056, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.006093541160225868}, {"id": 171, "seek": 84412, "start": 869.08, "end": 870.44, "text": " Reinforcement learning.", "tokens": [51612, 42116, 9382, 2539, 13, 51680], "temperature": 0.0, "avg_logprob": -0.23722194135189056, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.006093541160225868}, {"id": 172, "seek": 87044, "start": 870.44, "end": 879.0, "text": " You know, I spoke in a rich Sutton, that's been accepted as by a lot of people as", "tokens": [50364, 509, 458, 11, 286, 7179, 294, 257, 4593, 40492, 1756, 11, 300, 311, 668, 9035, 382, 538, 257, 688, 295, 561, 382, 50792], "temperature": 0.0, "avg_logprob": -0.24194437524546747, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0005791563889943063}, {"id": 173, "seek": 87044, "start": 880.2, "end": 889.1600000000001, "text": " an algorithmic model for brain activity in part of the brain, in the lower brain.", "tokens": [50852, 364, 9284, 299, 2316, 337, 3567, 5191, 294, 644, 295, 264, 3567, 11, 294, 264, 3126, 3567, 13, 51300], "temperature": 0.0, "avg_logprob": -0.24194437524546747, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.0005791563889943063}, {"id": 174, "seek": 88916, "start": 890.04, "end": 902.8399999999999, "text": " So in terms of exploring the mechanisms of the brain, it seems that there is some usefulness.", "tokens": [50408, 407, 294, 2115, 295, 12736, 264, 15902, 295, 264, 3567, 11, 309, 2544, 300, 456, 307, 512, 4420, 1287, 13, 51048], "temperature": 0.0, "avg_logprob": -0.16405739503748276, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.036754511296749115}, {"id": 175, "seek": 88916, "start": 902.8399999999999, "end": 908.92, "text": " I mean, it says, you said there's, on the one hand, people look at the principles,", "tokens": [51048, 286, 914, 11, 309, 1619, 11, 291, 848, 456, 311, 11, 322, 264, 472, 1011, 11, 561, 574, 412, 264, 9156, 11, 51352], "temperature": 0.0, "avg_logprob": -0.16405739503748276, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.036754511296749115}, {"id": 176, "seek": 88916, "start": 910.8399999999999, "end": 916.92, "text": " and then they built through engineering, just as the analogy of a bird to an airplane,", "tokens": [51448, 293, 550, 436, 3094, 807, 7043, 11, 445, 382, 264, 21663, 295, 257, 5255, 281, 364, 17130, 11, 51752], "temperature": 0.0, "avg_logprob": -0.16405739503748276, "compression_ratio": 1.5470588235294118, "no_speech_prob": 0.036754511296749115}, {"id": 177, "seek": 91692, "start": 917.56, "end": 923.8, "text": " they've taken some of the principles and applied it through engineering and created something useful.", "tokens": [50396, 436, 600, 2726, 512, 295, 264, 9156, 293, 6456, 309, 807, 7043, 293, 2942, 746, 4420, 13, 50708], "temperature": 0.0, "avg_logprob": -0.09751545014928599, "compression_ratio": 1.5792349726775956, "no_speech_prob": 0.0006261523813009262}, {"id": 178, "seek": 91692, "start": 924.36, "end": 933.0, "text": " But there are scientists that are looking at what's been created, like Hinton's criticism", "tokens": [50736, 583, 456, 366, 7708, 300, 366, 1237, 412, 437, 311, 668, 2942, 11, 411, 389, 12442, 311, 15835, 51168], "temperature": 0.0, "avg_logprob": -0.09751545014928599, "compression_ratio": 1.5792349726775956, "no_speech_prob": 0.0006261523813009262}, {"id": 179, "seek": 91692, "start": 933.0, "end": 941.8, "text": " of back propagation, and are looking for other models that would fit with the principles they see", "tokens": [51168, 295, 646, 38377, 11, 293, 366, 1237, 337, 661, 5245, 300, 576, 3318, 365, 264, 9156, 436, 536, 51608], "temperature": 0.0, "avg_logprob": -0.09751545014928599, "compression_ratio": 1.5792349726775956, "no_speech_prob": 0.0006261523813009262}, {"id": 180, "seek": 94180, "start": 941.8, "end": 946.92, "text": " in cognitive science or in the brain.", "tokens": [50364, 294, 15605, 3497, 420, 294, 264, 3567, 13, 50620], "temperature": 0.0, "avg_logprob": -0.1643832150627585, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.0014100305270403624}, {"id": 181, "seek": 94180, "start": 946.92, "end": 952.04, "text": " And I mentioned this forward-forward algorithm, which you said you hadn't looked at.", "tokens": [50620, 400, 286, 2835, 341, 2128, 12, 13305, 9284, 11, 597, 291, 848, 291, 8782, 380, 2956, 412, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1643832150627585, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.0014100305270403624}, {"id": 182, "seek": 94180, "start": 952.04, "end": 964.52, "text": " But I found it compelling in that it doesn't require signals to be passing back through", "tokens": [50876, 583, 286, 1352, 309, 20050, 294, 300, 309, 1177, 380, 3651, 12354, 281, 312, 8437, 646, 807, 51500], "temperature": 0.0, "avg_logprob": -0.1643832150627585, "compression_ratio": 1.3725490196078431, "no_speech_prob": 0.0014100305270403624}, {"id": 183, "seek": 96452, "start": 964.84, "end": 978.4399999999999, "text": " the neurons. I mean, they pass back, but then stimulate other neurons as you move forward", "tokens": [50380, 264, 22027, 13, 286, 914, 11, 436, 1320, 646, 11, 457, 550, 31269, 661, 22027, 382, 291, 1286, 2128, 51060], "temperature": 0.0, "avg_logprob": -0.17083519063097366, "compression_ratio": 1.3893129770992367, "no_speech_prob": 0.0037645187694579363}, {"id": 184, "seek": 96452, "start": 978.4399999999999, "end": 990.76, "text": " in time. But I mean, is there nothing that's been learned in the study of AI or the research", "tokens": [51060, 294, 565, 13, 583, 286, 914, 11, 307, 456, 1825, 300, 311, 668, 3264, 294, 264, 2979, 295, 7318, 420, 264, 2132, 51676], "temperature": 0.0, "avg_logprob": -0.17083519063097366, "compression_ratio": 1.3893129770992367, "no_speech_prob": 0.0037645187694579363}, {"id": 185, "seek": 99076, "start": 991.72, "end": 992.6, "text": " of neural nets?", "tokens": [50412, 295, 18161, 36170, 30, 50456], "temperature": 0.0, "avg_logprob": -0.20813239062273944, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.0024712856393307447}, {"id": 186, "seek": 99076, "start": 995.16, "end": 1002.92, "text": " But if you can find anything, it's great. Nothing against search, but it's just,", "tokens": [50584, 583, 498, 291, 393, 915, 1340, 11, 309, 311, 869, 13, 6693, 1970, 3164, 11, 457, 309, 311, 445, 11, 50972], "temperature": 0.0, "avg_logprob": -0.20813239062273944, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.0024712856393307447}, {"id": 187, "seek": 99076, "start": 1003.72, "end": 1011.16, "text": " but we have to remember what you asked about chatbots. What do we learn from them? Zero.", "tokens": [51012, 457, 321, 362, 281, 1604, 437, 291, 2351, 466, 5081, 65, 1971, 13, 708, 360, 321, 1466, 490, 552, 30, 17182, 13, 51384], "temperature": 0.0, "avg_logprob": -0.20813239062273944, "compression_ratio": 1.330935251798561, "no_speech_prob": 0.0024712856393307447}, {"id": 188, "seek": 101116, "start": 1012.04, "end": 1022.28, "text": " For the simple reason that the systems work as well for impossible languages as for possible ones.", "tokens": [50408, 1171, 264, 2199, 1778, 300, 264, 3652, 589, 382, 731, 337, 6243, 8650, 382, 337, 1944, 2306, 13, 50920], "temperature": 0.0, "avg_logprob": -0.10620225759652945, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.023316537961363792}, {"id": 189, "seek": 101116, "start": 1023.16, "end": 1030.84, "text": " So it's like the biologist with the new theory that has organisms and impossible ones and can't", "tokens": [50964, 407, 309, 311, 411, 264, 3228, 9201, 365, 264, 777, 5261, 300, 575, 22110, 293, 6243, 2306, 293, 393, 380, 51348], "temperature": 0.0, "avg_logprob": -0.10620225759652945, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.023316537961363792}, {"id": 190, "seek": 101116, "start": 1030.84, "end": 1036.52, "text": " tell the difference. Now, maybe by the look at these systems, you'll learn something about", "tokens": [51348, 980, 264, 2649, 13, 823, 11, 1310, 538, 264, 574, 412, 613, 3652, 11, 291, 603, 1466, 746, 466, 51632], "temperature": 0.0, "avg_logprob": -0.10620225759652945, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.023316537961363792}, {"id": 191, "seek": 103652, "start": 1036.52, "end": 1044.28, "text": " possible organisms. Okay, great. All in favor of learning things. But there's no issues.", "tokens": [50364, 1944, 22110, 13, 1033, 11, 869, 13, 1057, 294, 2294, 295, 2539, 721, 13, 583, 456, 311, 572, 2663, 13, 50752], "temperature": 0.0, "avg_logprob": -0.107149139046669, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0009692870080471039}, {"id": 192, "seek": 103652, "start": 1045.08, "end": 1053.48, "text": " It's just that the systems themselves, there are great claims by some of the leading figures in", "tokens": [50792, 467, 311, 445, 300, 264, 3652, 2969, 11, 456, 366, 869, 9441, 538, 512, 295, 264, 5775, 9624, 294, 51212], "temperature": 0.0, "avg_logprob": -0.107149139046669, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0009692870080471039}, {"id": 193, "seek": 103652, "start": 1053.48, "end": 1063.72, "text": " the field. We've solved the problem of language acquisition, namely zero contribution, because", "tokens": [51212, 264, 2519, 13, 492, 600, 13041, 264, 1154, 295, 2856, 21668, 11, 20926, 4018, 13150, 11, 570, 51724], "temperature": 0.0, "avg_logprob": -0.107149139046669, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0009692870080471039}, {"id": 194, "seek": 106372, "start": 1063.72, "end": 1072.28, "text": " the systems work as well for impossible languages. Therefore, they can't be telling you anything about", "tokens": [50364, 264, 3652, 589, 382, 731, 337, 6243, 8650, 13, 7504, 11, 436, 393, 380, 312, 3585, 291, 1340, 466, 50792], "temperature": 0.0, "avg_logprob": -0.09377902575901577, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0005032449844293296}, {"id": 195, "seek": 106372, "start": 1072.28, "end": 1080.04, "text": " language acquisition. Period. Maybe they're useful for something else. Okay, let's take a look.", "tokens": [50792, 2856, 21668, 13, 34976, 13, 2704, 436, 434, 4420, 337, 746, 1646, 13, 1033, 11, 718, 311, 747, 257, 574, 13, 51180], "temperature": 0.0, "avg_logprob": -0.09377902575901577, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0005032449844293296}, {"id": 196, "seek": 106372, "start": 1081.16, "end": 1089.4, "text": " Well, maybe for the audience that this is going out to, you know, I understand what you mean by", "tokens": [51236, 1042, 11, 1310, 337, 264, 4034, 300, 341, 307, 516, 484, 281, 11, 291, 458, 11, 286, 1223, 437, 291, 914, 538, 51648], "temperature": 0.0, "avg_logprob": -0.09377902575901577, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.0005032449844293296}, {"id": 197, "seek": 108940, "start": 1089.4, "end": 1097.0, "text": " impossible, impossible, but could you just give a brief synopsis of what you mean by impossible", "tokens": [50364, 6243, 11, 6243, 11, 457, 727, 291, 445, 976, 257, 5353, 5451, 3370, 271, 295, 437, 291, 914, 538, 6243, 50744], "temperature": 0.0, "avg_logprob": -0.12437199855196303, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.0016482615610584617}, {"id": 198, "seek": 108940, "start": 1097.0, "end": 1105.72, "text": " languages for people that haven't read your work? Well, I mean, there are certain general properties", "tokens": [50744, 8650, 337, 561, 300, 2378, 380, 1401, 428, 589, 30, 1042, 11, 286, 914, 11, 456, 366, 1629, 2674, 7221, 51180], "temperature": 0.0, "avg_logprob": -0.12437199855196303, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.0016482615610584617}, {"id": 199, "seek": 108940, "start": 1106.6000000000001, "end": 1117.3200000000002, "text": " that every infant knows, already tested down to two years old, no evidence, couldn't have evidence.", "tokens": [51224, 300, 633, 16757, 3255, 11, 1217, 8246, 760, 281, 732, 924, 1331, 11, 572, 4467, 11, 2809, 380, 362, 4467, 13, 51760], "temperature": 0.0, "avg_logprob": -0.12437199855196303, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.0016482615610584617}, {"id": 200, "seek": 111732, "start": 1118.28, "end": 1127.3999999999999, "text": " So one of the basic properties of language is that the linguistic rules apply to structures,", "tokens": [50412, 407, 472, 295, 264, 3875, 7221, 295, 2856, 307, 300, 264, 43002, 4474, 3079, 281, 9227, 11, 50868], "temperature": 0.0, "avg_logprob": -0.17768259843190512, "compression_ratio": 1.3482142857142858, "no_speech_prob": 0.0004305253969505429}, {"id": 201, "seek": 111732, "start": 1127.96, "end": 1134.28, "text": " not linear strings. So if you want to take a sentence like", "tokens": [50896, 406, 8213, 13985, 13, 407, 498, 291, 528, 281, 747, 257, 8174, 411, 51212], "temperature": 0.0, "avg_logprob": -0.17768259843190512, "compression_ratio": 1.3482142857142858, "no_speech_prob": 0.0004305253969505429}, {"id": 202, "seek": 113428, "start": 1134.6, "end": 1149.08, "text": " instinctively, birds that fly swim, it means instinctively they swim, not instinctively they", "tokens": [50380, 16556, 3413, 11, 9009, 300, 3603, 7110, 11, 309, 1355, 16556, 3413, 436, 7110, 11, 406, 16556, 3413, 436, 51104], "temperature": 0.0, "avg_logprob": -0.16048135562818877, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.022282226011157036}, {"id": 203, "seek": 113428, "start": 1149.08, "end": 1158.92, "text": " fly. Well, the adverb instinctively has to find a verb to attach to. It skips the closest verb", "tokens": [51104, 3603, 13, 1042, 11, 264, 614, 25809, 16556, 3413, 575, 281, 915, 257, 9595, 281, 5085, 281, 13, 467, 1110, 2600, 264, 13699, 9595, 51596], "temperature": 0.0, "avg_logprob": -0.16048135562818877, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.022282226011157036}, {"id": 204, "seek": 115892, "start": 1159.5600000000002, "end": 1165.4, "text": " and finds the structurally closest ones. That principle turns out to be universal", "tokens": [50396, 293, 10704, 264, 6594, 6512, 13699, 2306, 13, 663, 8665, 4523, 484, 281, 312, 11455, 50688], "temperature": 0.0, "avg_logprob": -0.11675635595170278, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0037054915446788073}, {"id": 205, "seek": 115892, "start": 1166.04, "end": 1173.24, "text": " for all structures, all constructions, and all languages. What it means is that an infant", "tokens": [50720, 337, 439, 9227, 11, 439, 7690, 626, 11, 293, 439, 8650, 13, 708, 309, 1355, 307, 300, 364, 16757, 51080], "temperature": 0.0, "avg_logprob": -0.11675635595170278, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0037054915446788073}, {"id": 206, "seek": 115892, "start": 1174.04, "end": 1183.5600000000002, "text": " from birth, as soon as you can test automatically, disregards linear order and disregards 100% of", "tokens": [51120, 490, 3965, 11, 382, 2321, 382, 291, 393, 1500, 6772, 11, 36405, 2287, 8213, 1668, 293, 36405, 2287, 2319, 4, 295, 51596], "temperature": 0.0, "avg_logprob": -0.11675635595170278, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0037054915446788073}, {"id": 207, "seek": 118356, "start": 1183.56, "end": 1190.84, "text": " what it hears, notice, as all we hear is words in linear order, but you disregard that and you", "tokens": [50364, 437, 309, 25688, 11, 3449, 11, 382, 439, 321, 1568, 307, 2283, 294, 8213, 1668, 11, 457, 291, 44493, 300, 293, 291, 50728], "temperature": 0.0, "avg_logprob": -0.15520914622715543, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.012617234140634537}, {"id": 208, "seek": 118356, "start": 1190.84, "end": 1199.32, "text": " deal only with abstract structures in your mind, which you never hear. Take another simple example,", "tokens": [50728, 2028, 787, 365, 12649, 9227, 294, 428, 1575, 11, 597, 291, 1128, 1568, 13, 3664, 1071, 2199, 1365, 11, 51152], "temperature": 0.0, "avg_logprob": -0.15520914622715543, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.012617234140634537}, {"id": 209, "seek": 118356, "start": 1199.32, "end": 1209.24, "text": " take the friends of my brothers are in England. Who's in England? The friends of the brothers,", "tokens": [51152, 747, 264, 1855, 295, 452, 8452, 366, 294, 8196, 13, 2102, 311, 294, 8196, 30, 440, 1855, 295, 264, 8452, 11, 51648], "temperature": 0.0, "avg_logprob": -0.15520914622715543, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.012617234140634537}, {"id": 210, "seek": 120924, "start": 1210.2, "end": 1216.28, "text": " the friends, not the brothers, the one that's adjacent, you just disregard all the linear", "tokens": [50412, 264, 1855, 11, 406, 264, 8452, 11, 264, 472, 300, 311, 24441, 11, 291, 445, 44493, 439, 264, 8213, 50716], "temperature": 0.0, "avg_logprob": -0.13330078125, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00080391630763188}, {"id": 211, "seek": 120924, "start": 1216.28, "end": 1223.64, "text": " information. It means you disregard everything you hear, everything, and you pay attention only", "tokens": [50716, 1589, 13, 467, 1355, 291, 44493, 1203, 291, 1568, 11, 1203, 11, 293, 291, 1689, 3202, 787, 51084], "temperature": 0.0, "avg_logprob": -0.13330078125, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00080391630763188}, {"id": 212, "seek": 120924, "start": 1223.64, "end": 1231.16, "text": " to what your mind constructs. That's the basic, most fundamental property of language. Well,", "tokens": [51084, 281, 437, 428, 1575, 7690, 82, 13, 663, 311, 264, 3875, 11, 881, 8088, 4707, 295, 2856, 13, 1042, 11, 51460], "temperature": 0.0, "avg_logprob": -0.13330078125, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00080391630763188}, {"id": 213, "seek": 120924, "start": 1231.16, "end": 1238.04, "text": " you can make up impossible languages that work with what you hear. Simple rule, take the first", "tokens": [51460, 291, 393, 652, 493, 6243, 8650, 300, 589, 365, 437, 291, 1568, 13, 21532, 4978, 11, 747, 264, 700, 51804], "temperature": 0.0, "avg_logprob": -0.13330078125, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.00080391630763188}, {"id": 214, "seek": 123804, "start": 1238.76, "end": 1247.0, "text": " relevant thing, associate them. Friends of my brothers are here, brothers are the closest things,", "tokens": [50400, 7340, 551, 11, 14644, 552, 13, 14042, 295, 452, 8452, 366, 510, 11, 8452, 366, 264, 13699, 721, 11, 50812], "temperature": 0.0, "avg_logprob": -0.12364400134367101, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006260851514525712}, {"id": 215, "seek": 123804, "start": 1247.0, "end": 1253.8, "text": " and the brothers are here. Trivial rule, much simpler than the rule we use. You can construct", "tokens": [50812, 293, 264, 8452, 366, 510, 13, 10931, 22640, 4978, 11, 709, 18587, 813, 264, 4978, 321, 764, 13, 509, 393, 7690, 51152], "temperature": 0.0, "avg_logprob": -0.12364400134367101, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006260851514525712}, {"id": 216, "seek": 123804, "start": 1253.8, "end": 1260.84, "text": " languages that use only those simple rules that will be based on the linear order of what we hear.", "tokens": [51152, 8650, 300, 764, 787, 729, 2199, 4474, 300, 486, 312, 2361, 322, 264, 8213, 1668, 295, 437, 321, 1568, 13, 51504], "temperature": 0.0, "avg_logprob": -0.12364400134367101, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006260851514525712}, {"id": 217, "seek": 126084, "start": 1261.8, "end": 1269.6399999999999, "text": " Well, maybe children, people could acquire them as a puzzle somehow using non-linguistic", "tokens": [50412, 1042, 11, 1310, 2227, 11, 561, 727, 20001, 552, 382, 257, 12805, 6063, 1228, 2107, 12, 1688, 84, 3142, 50804], "temperature": 0.0, "avg_logprob": -0.16206681728363037, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.010486841201782227}, {"id": 218, "seek": 126084, "start": 1269.6399999999999, "end": 1276.36, "text": " capacities, but they're not what children, infants, reflexively construct with no evidence.", "tokens": [50804, 39396, 11, 457, 436, 434, 406, 437, 2227, 11, 38829, 11, 23802, 3413, 7690, 365, 572, 4467, 13, 51140], "temperature": 0.0, "avg_logprob": -0.16206681728363037, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.010486841201782227}, {"id": 219, "seek": 126084, "start": 1277.32, "end": 1284.6, "text": " Well, there's many things like this, impossible and impossible languages. Well, nobody's tried", "tokens": [51188, 1042, 11, 456, 311, 867, 721, 411, 341, 11, 6243, 293, 6243, 8650, 13, 1042, 11, 5079, 311, 3031, 51552], "temperature": 0.0, "avg_logprob": -0.16206681728363037, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.010486841201782227}, {"id": 220, "seek": 126084, "start": 1284.6, "end": 1290.12, "text": " it out because it's too obvious how it's going to turn out. You take a large language model,", "tokens": [51552, 309, 484, 570, 309, 311, 886, 6322, 577, 309, 311, 516, 281, 1261, 484, 13, 509, 747, 257, 2416, 2856, 2316, 11, 51828], "temperature": 0.0, "avg_logprob": -0.16206681728363037, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.010486841201782227}, {"id": 221, "seek": 129012, "start": 1290.12, "end": 1297.8, "text": " apply it to one of these models, systems that use linear order. Of course, it's going to work fine,", "tokens": [50364, 3079, 309, 281, 472, 295, 613, 5245, 11, 3652, 300, 764, 8213, 1668, 13, 2720, 1164, 11, 309, 311, 516, 281, 589, 2489, 11, 50748], "temperature": 0.0, "avg_logprob": -0.13621896921202195, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0002531077479943633}, {"id": 222, "seek": 129012, "start": 1298.36, "end": 1303.56, "text": " trivial rules. Well, that's a refutation of the system.", "tokens": [50776, 26703, 4474, 13, 1042, 11, 300, 311, 257, 1895, 11380, 295, 264, 1185, 13, 51036], "temperature": 0.0, "avg_logprob": -0.13621896921202195, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0002531077479943633}, {"id": 223, "seek": 129012, "start": 1305.56, "end": 1311.0, "text": " Meaning that if you trained it on an impossible language, it would produce impossible languages.", "tokens": [51136, 19948, 300, 498, 291, 8895, 309, 322, 364, 6243, 2856, 11, 309, 576, 5258, 6243, 8650, 13, 51408], "temperature": 0.0, "avg_logprob": -0.13621896921202195, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0002531077479943633}, {"id": 224, "seek": 129012, "start": 1311.0, "end": 1316.1999999999998, "text": " How would you mean? Well, you don't even have to train it because the rules are simple.", "tokens": [51408, 1012, 576, 291, 914, 30, 1042, 11, 291, 500, 380, 754, 362, 281, 3847, 309, 570, 264, 4474, 366, 2199, 13, 51668], "temperature": 0.0, "avg_logprob": -0.13621896921202195, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0002531077479943633}, {"id": 225, "seek": 131620, "start": 1316.76, "end": 1322.8400000000001, "text": " Yeah. Rules are much simpler than the rules of language. Like taking things that are,", "tokens": [50392, 865, 13, 38897, 366, 709, 18587, 813, 264, 4474, 295, 2856, 13, 1743, 1940, 721, 300, 366, 11, 50696], "temperature": 0.0, "avg_logprob": -0.1532093750803094, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.0013454490108415484}, {"id": 226, "seek": 131620, "start": 1322.8400000000001, "end": 1331.0800000000002, "text": " take the example, the friends of my brother are here. The way we actually do it is we don't say,", "tokens": [50696, 747, 264, 1365, 11, 264, 1855, 295, 452, 3708, 366, 510, 13, 440, 636, 321, 767, 360, 309, 307, 321, 500, 380, 584, 11, 51108], "temperature": 0.0, "avg_logprob": -0.1532093750803094, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.0013454490108415484}, {"id": 227, "seek": 131620, "start": 1331.72, "end": 1339.24, "text": " take the noun phrase that's closest. We don't do that. That would be trivial, but we don't do it.", "tokens": [51140, 747, 264, 23307, 9535, 300, 311, 13699, 13, 492, 500, 380, 360, 300, 13, 663, 576, 312, 26703, 11, 457, 321, 500, 380, 360, 309, 13, 51516], "temperature": 0.0, "avg_logprob": -0.1532093750803094, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.0013454490108415484}, {"id": 228, "seek": 131620, "start": 1339.24, "end": 1344.52, "text": " What we say is first construct the structure in your mind, friends of my brothers,", "tokens": [51516, 708, 321, 584, 307, 700, 7690, 264, 3877, 294, 428, 1575, 11, 1855, 295, 452, 8452, 11, 51780], "temperature": 0.0, "avg_logprob": -0.1532093750803094, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.0013454490108415484}, {"id": 229, "seek": 134452, "start": 1345.16, "end": 1351.08, "text": " then figure out that the central element in that structure is friends, not brothers.", "tokens": [50396, 550, 2573, 484, 300, 264, 5777, 4478, 294, 300, 3877, 307, 1855, 11, 406, 8452, 13, 50692], "temperature": 0.0, "avg_logprob": -0.15265377618933237, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0008826542762108147}, {"id": 230, "seek": 134452, "start": 1351.72, "end": 1358.52, "text": " And then let's let it be talking about the head of it. It's a pretty complicated computation,", "tokens": [50724, 400, 550, 718, 311, 718, 309, 312, 1417, 466, 264, 1378, 295, 309, 13, 467, 311, 257, 1238, 6179, 24903, 11, 51064], "temperature": 0.0, "avg_logprob": -0.15265377618933237, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0008826542762108147}, {"id": 231, "seek": 134452, "start": 1359.16, "end": 1365.72, "text": " but that's the one we do instantaneously and reflexively. And we ignore, and we never see it,", "tokens": [51096, 457, 300, 311, 264, 472, 321, 360, 9836, 13131, 293, 23802, 3413, 13, 400, 321, 11200, 11, 293, 321, 1128, 536, 309, 11, 51424], "temperature": 0.0, "avg_logprob": -0.15265377618933237, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0008826542762108147}, {"id": 232, "seek": 134452, "start": 1365.72, "end": 1372.52, "text": " hear it, remember? We don't hear structures. All we hear is words in linear order. What we hear", "tokens": [51424, 1568, 309, 11, 1604, 30, 492, 500, 380, 1568, 9227, 13, 1057, 321, 1568, 307, 2283, 294, 8213, 1668, 13, 708, 321, 1568, 51764], "temperature": 0.0, "avg_logprob": -0.15265377618933237, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0008826542762108147}, {"id": 233, "seek": 137252, "start": 1372.6, "end": 1379.4, "text": " is words in linear order. We never use that information. We use only the much more looks", "tokens": [50368, 307, 2283, 294, 8213, 1668, 13, 492, 1128, 764, 300, 1589, 13, 492, 764, 787, 264, 709, 544, 1542, 50708], "temperature": 0.0, "avg_logprob": -0.0878294880470533, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.0003513601259328425}, {"id": 234, "seek": 137252, "start": 1379.4, "end": 1385.96, "text": " like complex. If you think about it computationally, it's actually simpler, but that's a deeper", "tokens": [50708, 411, 3997, 13, 759, 291, 519, 466, 309, 24903, 379, 11, 309, 311, 767, 18587, 11, 457, 300, 311, 257, 7731, 51036], "temperature": 0.0, "avg_logprob": -0.0878294880470533, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.0003513601259328425}, {"id": 235, "seek": 137252, "start": 1385.96, "end": 1392.2, "text": " question, which is why we do it. To move to a different dimension, there's a reason for this.", "tokens": [51036, 1168, 11, 597, 307, 983, 321, 360, 309, 13, 1407, 1286, 281, 257, 819, 10139, 11, 456, 311, 257, 1778, 337, 341, 13, 51348], "temperature": 0.0, "avg_logprob": -0.0878294880470533, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.0003513601259328425}, {"id": 236, "seek": 137252, "start": 1393.16, "end": 1399.8799999999999, "text": " The reason has to do with the theory of computation. You're trying to construct", "tokens": [51396, 440, 1778, 575, 281, 360, 365, 264, 5261, 295, 24903, 13, 509, 434, 1382, 281, 7690, 51732], "temperature": 0.0, "avg_logprob": -0.0878294880470533, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.0003513601259328425}, {"id": 237, "seek": 139988, "start": 1400.8400000000001, "end": 1408.68, "text": " an infinite array of structured expressions. Simplest way to do that, the simplest computational", "tokens": [50412, 364, 13785, 10225, 295, 18519, 15277, 13, 3998, 564, 377, 636, 281, 360, 300, 11, 264, 22811, 28270, 50804], "temperature": 0.0, "avg_logprob": -0.12023725963774182, "compression_ratio": 1.6927710843373494, "no_speech_prob": 0.0006360213155858219}, {"id": 238, "seek": 139988, "start": 1408.68, "end": 1415.5600000000002, "text": " procedure is binary set formation. But if you use binary set formation, you're just going to get", "tokens": [50804, 10747, 307, 17434, 992, 11723, 13, 583, 498, 291, 764, 17434, 992, 11723, 11, 291, 434, 445, 516, 281, 483, 51148], "temperature": 0.0, "avg_logprob": -0.12023725963774182, "compression_ratio": 1.6927710843373494, "no_speech_prob": 0.0006360213155858219}, {"id": 239, "seek": 139988, "start": 1415.5600000000002, "end": 1422.0400000000002, "text": " structures, not order. So what the brain is doing is the simplest computational system,", "tokens": [51148, 9227, 11, 406, 1668, 13, 407, 437, 264, 3567, 307, 884, 307, 264, 22811, 28270, 1185, 11, 51472], "temperature": 0.0, "avg_logprob": -0.12023725963774182, "compression_ratio": 1.6927710843373494, "no_speech_prob": 0.0006360213155858219}, {"id": 240, "seek": 142204, "start": 1422.92, "end": 1430.92, "text": " which happens to be very much harder to use. Nature doesn't care about that. Nature constructs", "tokens": [50408, 597, 2314, 281, 312, 588, 709, 6081, 281, 764, 13, 20159, 1177, 380, 1127, 466, 300, 13, 20159, 7690, 82, 50808], "temperature": 0.0, "avg_logprob": -0.11496403482225206, "compression_ratio": 1.5649717514124293, "no_speech_prob": 0.028428109362721443}, {"id": 241, "seek": 142204, "start": 1430.92, "end": 1439.24, "text": " the simplest system, doesn't care about it, if it's hard to use or not. I mean, you know, nature", "tokens": [50808, 264, 22811, 1185, 11, 1177, 380, 1127, 466, 309, 11, 498, 309, 311, 1152, 281, 764, 420, 406, 13, 286, 914, 11, 291, 458, 11, 3687, 51224], "temperature": 0.0, "avg_logprob": -0.11496403482225206, "compression_ratio": 1.5649717514124293, "no_speech_prob": 0.028428109362721443}, {"id": 242, "seek": 142204, "start": 1439.24, "end": 1445.8799999999999, "text": " could have saved us a lot of trouble if it had developed eight fingers instead of 10.", "tokens": [51224, 727, 362, 6624, 505, 257, 688, 295, 5253, 498, 309, 632, 4743, 3180, 7350, 2602, 295, 1266, 13, 51556], "temperature": 0.0, "avg_logprob": -0.11496403482225206, "compression_ratio": 1.5649717514124293, "no_speech_prob": 0.028428109362721443}, {"id": 243, "seek": 144588, "start": 1446.8400000000001, "end": 1454.0400000000002, "text": " Then we'd have a much better base for computation. But nature didn't care about that when it developed", "tokens": [50412, 1396, 321, 1116, 362, 257, 709, 1101, 3096, 337, 24903, 13, 583, 3687, 994, 380, 1127, 466, 300, 562, 309, 4743, 50772], "temperature": 0.0, "avg_logprob": -0.10818363915027028, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0005883332341909409}, {"id": 244, "seek": 144588, "start": 1454.0400000000002, "end": 1461.16, "text": " 10 fingers. If you look at evolution, it pays no attention to function. It just constructs the", "tokens": [50772, 1266, 7350, 13, 759, 291, 574, 412, 9303, 11, 309, 10604, 572, 3202, 281, 2445, 13, 467, 445, 7690, 82, 264, 51128], "temperature": 0.0, "avg_logprob": -0.10818363915027028, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0005883332341909409}, {"id": 245, "seek": 144588, "start": 1461.16, "end": 1467.3200000000002, "text": " best system at each point. There's a lot of misleading talk about that. But if you just think", "tokens": [51128, 1151, 1185, 412, 1184, 935, 13, 821, 311, 257, 688, 295, 36429, 751, 466, 300, 13, 583, 498, 291, 445, 519, 51436], "temperature": 0.0, "avg_logprob": -0.10818363915027028, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.0005883332341909409}, {"id": 246, "seek": 146732, "start": 1467.32, "end": 1475.1599999999999, "text": " about the physics of evolution, say a bacterium swallows another organism,", "tokens": [50364, 466, 264, 10649, 295, 9303, 11, 584, 257, 9755, 2197, 1693, 38811, 1071, 24128, 11, 50756], "temperature": 0.0, "avg_logprob": -0.10525408284417515, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.001151209231466055}, {"id": 247, "seek": 146732, "start": 1476.76, "end": 1483.8, "text": " the basis for what became complex cells, and nature doesn't get the new system,", "tokens": [50836, 264, 5143, 337, 437, 3062, 3997, 5438, 11, 293, 3687, 1177, 380, 483, 264, 777, 1185, 11, 51188], "temperature": 0.0, "avg_logprob": -0.10525408284417515, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.001151209231466055}, {"id": 248, "seek": 146732, "start": 1484.4399999999998, "end": 1490.6, "text": " it reconstructs it in the simplest possible way. It doesn't pay any attention to how", "tokens": [51220, 309, 31499, 82, 309, 294, 264, 22811, 1944, 636, 13, 467, 1177, 380, 1689, 604, 3202, 281, 577, 51528], "temperature": 0.0, "avg_logprob": -0.10525408284417515, "compression_ratio": 1.4484848484848485, "no_speech_prob": 0.001151209231466055}, {"id": 249, "seek": 149060, "start": 1490.6799999999998, "end": 1499.24, "text": " complex organisms are going to behave, not what nature can do. And that's the way evolution works", "tokens": [50368, 3997, 22110, 366, 516, 281, 15158, 11, 406, 437, 3687, 393, 360, 13, 400, 300, 311, 264, 636, 9303, 1985, 50796], "temperature": 0.0, "avg_logprob": -0.11332099365465569, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.000626273569650948}, {"id": 250, "seek": 149060, "start": 1499.24, "end": 1507.24, "text": " all the way down the line. So not surprisingly, nature constructed language so that it's", "tokens": [50796, 439, 264, 636, 760, 264, 1622, 13, 407, 406, 17600, 11, 3687, 17083, 2856, 370, 300, 309, 311, 51196], "temperature": 0.0, "avg_logprob": -0.11332099365465569, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.000626273569650948}, {"id": 251, "seek": 149060, "start": 1507.8, "end": 1516.1999999999998, "text": " computationally elegant, but dysfunctional, hard to use in many ways. Not nature's problem,", "tokens": [51224, 24903, 379, 21117, 11, 457, 32002, 304, 11, 1152, 281, 764, 294, 867, 2098, 13, 1726, 3687, 311, 1154, 11, 51644], "temperature": 0.0, "avg_logprob": -0.11332099365465569, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.000626273569650948}, {"id": 252, "seek": 151620, "start": 1516.92, "end": 1522.92, "text": " just like every other aspect of nature. You can think of a way in which you can do it better,", "tokens": [50400, 445, 411, 633, 661, 4171, 295, 3687, 13, 509, 393, 519, 295, 257, 636, 294, 597, 291, 393, 360, 309, 1101, 11, 50700], "temperature": 0.0, "avg_logprob": -0.12611158192157745, "compression_ratio": 1.408839779005525, "no_speech_prob": 0.0012063374742865562}, {"id": 253, "seek": 151620, "start": 1522.92, "end": 1532.92, "text": " but it didn't happen stage by stage. Two questions from that. So your view is that", "tokens": [50700, 457, 309, 994, 380, 1051, 3233, 538, 3233, 13, 4453, 1651, 490, 300, 13, 407, 428, 1910, 307, 300, 51200], "temperature": 0.0, "avg_logprob": -0.12611158192157745, "compression_ratio": 1.408839779005525, "no_speech_prob": 0.0012063374742865562}, {"id": 254, "seek": 151620, "start": 1533.96, "end": 1538.92, "text": " artificial intelligence, as it's being called, and particularly generative AI,", "tokens": [51252, 11677, 7599, 11, 382, 309, 311, 885, 1219, 11, 293, 4098, 1337, 1166, 7318, 11, 51500], "temperature": 0.0, "avg_logprob": -0.12611158192157745, "compression_ratio": 1.408839779005525, "no_speech_prob": 0.0012063374742865562}, {"id": 255, "seek": 153892, "start": 1539.8000000000002, "end": 1547.16, "text": " doesn't exhibit true intelligence. Is that right? I wouldn't even say that.", "tokens": [50408, 1177, 380, 20487, 2074, 7599, 13, 1119, 300, 558, 30, 286, 2759, 380, 754, 584, 300, 13, 50776], "temperature": 0.0, "avg_logprob": -0.1232305552861462, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.006095496937632561}, {"id": 256, "seek": 153892, "start": 1547.88, "end": 1556.68, "text": " It's irrelevant to the question of intelligence. It's not its problem. A guy who designs a jet plane", "tokens": [50812, 467, 311, 28682, 281, 264, 1168, 295, 7599, 13, 467, 311, 406, 1080, 1154, 13, 316, 2146, 567, 11347, 257, 14452, 5720, 51252], "temperature": 0.0, "avg_logprob": -0.1232305552861462, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.006095496937632561}, {"id": 257, "seek": 153892, "start": 1557.3200000000002, "end": 1566.92, "text": " is not trying to answer the question, how do eagles fly? So to say, well, it doesn't tell us how", "tokens": [51284, 307, 406, 1382, 281, 1867, 264, 1168, 11, 577, 360, 308, 33300, 3603, 30, 407, 281, 584, 11, 731, 11, 309, 1177, 380, 980, 505, 577, 51764], "temperature": 0.0, "avg_logprob": -0.1232305552861462, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.006095496937632561}, {"id": 258, "seek": 156692, "start": 1566.92, "end": 1576.92, "text": " eagles fly is the wrong question to ask. It's not the goal. Except what people are struggling with", "tokens": [50364, 308, 33300, 3603, 307, 264, 2085, 1168, 281, 1029, 13, 467, 311, 406, 264, 3387, 13, 16192, 437, 561, 366, 9314, 365, 50864], "temperature": 0.0, "avg_logprob": -0.11290361632162066, "compression_ratio": 1.455958549222798, "no_speech_prob": 0.00037985859671607614}, {"id": 259, "seek": 156692, "start": 1576.92, "end": 1585.88, "text": " right now. You've heard the existential threat argument that these models, if they get large", "tokens": [50864, 558, 586, 13, 509, 600, 2198, 264, 37133, 4734, 6770, 300, 613, 5245, 11, 498, 436, 483, 2416, 51312], "temperature": 0.0, "avg_logprob": -0.11290361632162066, "compression_ratio": 1.455958549222798, "no_speech_prob": 0.00037985859671607614}, {"id": 260, "seek": 156692, "start": 1585.88, "end": 1592.6000000000001, "text": " enough, they'll actually be more intelligent than humans. That's science fiction. I mean,", "tokens": [51312, 1547, 11, 436, 603, 767, 312, 544, 13232, 813, 6255, 13, 663, 311, 3497, 13266, 13, 286, 914, 11, 51648], "temperature": 0.0, "avg_logprob": -0.11290361632162066, "compression_ratio": 1.455958549222798, "no_speech_prob": 0.00037985859671607614}, {"id": 261, "seek": 159260, "start": 1592.6, "end": 1600.28, "text": " there is a theoretical possibility. You can give a theoretical argument that, in principle,", "tokens": [50364, 456, 307, 257, 20864, 7959, 13, 509, 393, 976, 257, 20864, 6770, 300, 11, 294, 8665, 11, 50748], "temperature": 0.0, "avg_logprob": -0.07929459810256959, "compression_ratio": 1.4318181818181819, "no_speech_prob": 0.0005882498226128519}, {"id": 262, "seek": 159260, "start": 1602.36, "end": 1612.52, "text": " a complex system with vast search capacity could conceivably turn into something that would start", "tokens": [50852, 257, 3997, 1185, 365, 8369, 3164, 6042, 727, 10413, 592, 1188, 1261, 666, 746, 300, 576, 722, 51360], "temperature": 0.0, "avg_logprob": -0.07929459810256959, "compression_ratio": 1.4318181818181819, "no_speech_prob": 0.0005882498226128519}, {"id": 263, "seek": 161252, "start": 1612.52, "end": 1622.2, "text": " to do things that you can't predict, maybe beyond. But that's even more remote than some", "tokens": [50364, 281, 360, 721, 300, 291, 393, 380, 6069, 11, 1310, 4399, 13, 583, 300, 311, 754, 544, 8607, 813, 512, 50848], "temperature": 0.0, "avg_logprob": -0.2014524286443537, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.03565322980284691}, {"id": 264, "seek": 161252, "start": 1623.8799999999999, "end": 1630.04, "text": " distant asteroid, maybe someday hitting the earth, could happen. I mean, if you read a", "tokens": [50932, 17275, 33833, 11, 1310, 19412, 8850, 264, 4120, 11, 727, 1051, 13, 286, 914, 11, 498, 291, 1401, 257, 51240], "temperature": 0.0, "avg_logprob": -0.2014524286443537, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.03565322980284691}, {"id": 265, "seek": 161252, "start": 1630.04, "end": 1638.12, "text": " serious scientist on this, like Max Tagmark, his book on the three levels of intelligence,", "tokens": [51240, 3156, 12662, 322, 341, 11, 411, 7402, 11204, 5638, 11, 702, 1446, 322, 264, 1045, 4358, 295, 7599, 11, 51644], "temperature": 0.0, "avg_logprob": -0.2014524286443537, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.03565322980284691}, {"id": 266, "seek": 163812, "start": 1639.08, "end": 1647.56, "text": " does give a sound theoretical argument as to how a massive system could, say,", "tokens": [50412, 775, 976, 257, 1626, 20864, 6770, 382, 281, 577, 257, 5994, 1185, 727, 11, 584, 11, 50836], "temperature": 0.0, "avg_logprob": -0.12989674952992222, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.001304113888181746}, {"id": 267, "seek": 163812, "start": 1649.32, "end": 1658.28, "text": " run through all the scientific discoveries in history, maybe find out some better way of", "tokens": [50924, 1190, 807, 439, 264, 8134, 28400, 294, 2503, 11, 1310, 915, 484, 512, 1101, 636, 295, 51372], "temperature": 0.0, "avg_logprob": -0.12989674952992222, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.001304113888181746}, {"id": 268, "seek": 163812, "start": 1660.12, "end": 1664.9199999999998, "text": " developing them and use that better way to design something new which would destroy us all.", "tokens": [51464, 6416, 552, 293, 764, 300, 1101, 636, 281, 1715, 746, 777, 597, 576, 5293, 505, 439, 13, 51704], "temperature": 0.0, "avg_logprob": -0.12989674952992222, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.001304113888181746}, {"id": 269, "seek": 166492, "start": 1665.88, "end": 1673.0800000000002, "text": " It's, in theory, possible, but it's so remote from anything that's available that it's a waste of", "tokens": [50412, 467, 311, 11, 294, 5261, 11, 1944, 11, 457, 309, 311, 370, 8607, 490, 1340, 300, 311, 2435, 300, 309, 311, 257, 5964, 295, 50772], "temperature": 0.0, "avg_logprob": -0.14663781981537308, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0007671855855733156}, {"id": 270, "seek": 166492, "start": 1673.0800000000002, "end": 1680.04, "text": " time to think about it. Yeah, so your view is that whatever threat exists from", "tokens": [50772, 565, 281, 519, 466, 309, 13, 865, 11, 370, 428, 1910, 307, 300, 2035, 4734, 8198, 490, 51120], "temperature": 0.0, "avg_logprob": -0.14663781981537308, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0007671855855733156}, {"id": 271, "seek": 166492, "start": 1681.0800000000002, "end": 1690.52, "text": " generative AI, it's the more mundane threat of disinformation. Disinformation, defamation,", "tokens": [51172, 1337, 1166, 7318, 11, 309, 311, 264, 544, 43497, 4734, 295, 717, 20941, 13, 4208, 20941, 11, 1060, 30477, 11, 51644], "temperature": 0.0, "avg_logprob": -0.14663781981537308, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0007671855855733156}, {"id": 272, "seek": 169052, "start": 1691.48, "end": 1700.76, "text": " gullibility, Gary Marcus has done a lot of work on this, real cases, those are problems. I mean,", "tokens": [50412, 695, 285, 2841, 11, 13788, 26574, 575, 1096, 257, 688, 295, 589, 322, 341, 11, 957, 3331, 11, 729, 366, 2740, 13, 286, 914, 11, 50876], "temperature": 0.0, "avg_logprob": -0.20342500860040838, "compression_ratio": 1.356164383561644, "no_speech_prob": 0.0012252865126356483}, {"id": 273, "seek": 169052, "start": 1700.76, "end": 1709.8, "text": " you may have seen that there was a, sort of as a joke, people, somebody developed a defamation of the", "tokens": [50876, 291, 815, 362, 1612, 300, 456, 390, 257, 11, 1333, 295, 382, 257, 7647, 11, 561, 11, 2618, 4743, 257, 1060, 30477, 295, 264, 51328], "temperature": 0.0, "avg_logprob": -0.20342500860040838, "compression_ratio": 1.356164383561644, "no_speech_prob": 0.0012252865126356483}, {"id": 274, "seek": 170980, "start": 1709.8799999999999, "end": 1720.84, "text": " pope, put an image of the pope, somebody could do it for you, duplicate your face so it looks more", "tokens": [50368, 42248, 11, 829, 364, 3256, 295, 264, 42248, 11, 2618, 727, 360, 309, 337, 291, 11, 23976, 428, 1851, 370, 309, 1542, 544, 50916], "temperature": 0.0, "avg_logprob": -0.12514557709565033, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.10372033715248108}, {"id": 275, "seek": 170980, "start": 1720.84, "end": 1730.12, "text": " or less like your face, pretty much duplicate your voice, develop a robot that looks kind of like you,", "tokens": [50916, 420, 1570, 411, 428, 1851, 11, 1238, 709, 23976, 428, 3177, 11, 1499, 257, 7881, 300, 1542, 733, 295, 411, 291, 11, 51380], "temperature": 0.0, "avg_logprob": -0.12514557709565033, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.10372033715248108}, {"id": 276, "seek": 170980, "start": 1730.12, "end": 1736.36, "text": " have you say some insane thing, it would be hard only an expert could tell whether it was you or", "tokens": [51380, 362, 291, 584, 512, 10838, 551, 11, 309, 576, 312, 1152, 787, 364, 5844, 727, 980, 1968, 309, 390, 291, 420, 51692], "temperature": 0.0, "avg_logprob": -0.12514557709565033, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.10372033715248108}, {"id": 277, "seek": 173636, "start": 1736.36, "end": 1743.7199999999998, "text": " none. It's like this was done already several times, but basically is a joke.", "tokens": [50364, 6022, 13, 467, 311, 411, 341, 390, 1096, 1217, 2940, 1413, 11, 457, 1936, 307, 257, 7647, 13, 50732], "temperature": 0.0, "avg_logprob": -0.19657539499217067, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0014098078245297074}, {"id": 278, "seek": 173636, "start": 1744.4399999999998, "end": 1749.7199999999998, "text": " When powerful institutions get started on it, it's not going to be a joke.", "tokens": [50768, 1133, 4005, 8142, 483, 1409, 322, 309, 11, 309, 311, 406, 516, 281, 312, 257, 7647, 13, 51032], "temperature": 0.0, "avg_logprob": -0.19657539499217067, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0014098078245297074}, {"id": 279, "seek": 173636, "start": 1754.52, "end": 1761.6399999999999, "text": " Another argument that's swirling around these large language models is the question of", "tokens": [51272, 3996, 6770, 300, 311, 30310, 278, 926, 613, 2416, 2856, 5245, 307, 264, 1168, 295, 51628], "temperature": 0.0, "avg_logprob": -0.19657539499217067, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0014098078245297074}, {"id": 280, "seek": 176164, "start": 1762.6000000000001, "end": 1770.2, "text": " a sentence of whether if the model is large enough, and this goes a little bit back to how", "tokens": [50412, 257, 8174, 295, 1968, 498, 264, 2316, 307, 2416, 1547, 11, 293, 341, 1709, 257, 707, 857, 646, 281, 577, 50792], "temperature": 0.0, "avg_logprob": -0.12717333436012268, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.005383005831390619}, {"id": 281, "seek": 176164, "start": 1770.2, "end": 1776.5200000000002, "text": " there's a lot more going on in the brain than the neural network or the cerebral cortex, but", "tokens": [50792, 456, 311, 257, 688, 544, 516, 322, 294, 264, 3567, 813, 264, 18161, 3209, 420, 264, 43561, 33312, 11, 457, 51108], "temperature": 0.0, "avg_logprob": -0.12717333436012268, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.005383005831390619}, {"id": 282, "seek": 176164, "start": 1778.5200000000002, "end": 1786.2800000000002, "text": " that there is the potential for some kind of sentence, not necessarily equivalent to human", "tokens": [51208, 300, 456, 307, 264, 3995, 337, 512, 733, 295, 8174, 11, 406, 4725, 10344, 281, 1952, 51596], "temperature": 0.0, "avg_logprob": -0.12717333436012268, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.005383005831390619}, {"id": 283, "seek": 178628, "start": 1786.28, "end": 1795.72, "text": " sentence. These are vacuous questions. It's like asking, does a submarine really swim?", "tokens": [50364, 8174, 13, 1981, 366, 2842, 12549, 1651, 13, 467, 311, 411, 3365, 11, 775, 257, 33995, 534, 7110, 30, 50836], "temperature": 0.0, "avg_logprob": -0.12345635051458655, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.003170884447172284}, {"id": 284, "seek": 178628, "start": 1797.0, "end": 1803.56, "text": " You want to call that swimming? Yeah, it swims. You don't want to call it swimming? It's not a", "tokens": [50900, 509, 528, 281, 818, 300, 11989, 30, 865, 11, 309, 42357, 13, 509, 500, 380, 528, 281, 818, 309, 11989, 30, 467, 311, 406, 257, 51228], "temperature": 0.0, "avg_logprob": -0.12345635051458655, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.003170884447172284}, {"id": 285, "seek": 178628, "start": 1803.56, "end": 1813.08, "text": " substantive question. Well, in the sense that it supports the view that there's no separation between", "tokens": [51228, 47113, 1168, 13, 1042, 11, 294, 264, 2020, 300, 309, 9346, 264, 1910, 300, 456, 311, 572, 14634, 1296, 51704], "temperature": 0.0, "avg_logprob": -0.12345635051458655, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.003170884447172284}, {"id": 286, "seek": 181308, "start": 1813.32, "end": 1822.1999999999998, "text": " consciousness and the material activities of the brain. There's a separation that hasn't", "tokens": [50376, 10081, 293, 264, 2527, 5354, 295, 264, 3567, 13, 821, 311, 257, 14634, 300, 6132, 380, 50820], "temperature": 0.0, "avg_logprob": -0.1836429089307785, "compression_ratio": 1.4365482233502538, "no_speech_prob": 0.0014100810512900352}, {"id": 287, "seek": 181308, "start": 1822.1999999999998, "end": 1830.84, "text": " been believed since the 17th century. John Locke, after Newton's demonstration, said, well leaves", "tokens": [50820, 668, 7847, 1670, 264, 3282, 392, 4901, 13, 2619, 12859, 330, 11, 934, 19541, 311, 16520, 11, 848, 11, 731, 5510, 51252], "temperature": 0.0, "avg_logprob": -0.1836429089307785, "compression_ratio": 1.4365482233502538, "no_speech_prob": 0.0014100810512900352}, {"id": 288, "seek": 181308, "start": 1830.84, "end": 1839.3999999999999, "text": " us only with the possibility that thinking is some property of organized matter. That's the 17th", "tokens": [51252, 505, 787, 365, 264, 7959, 300, 1953, 307, 512, 4707, 295, 9983, 1871, 13, 663, 311, 264, 3282, 392, 51680], "temperature": 0.0, "avg_logprob": -0.1836429089307785, "compression_ratio": 1.4365482233502538, "no_speech_prob": 0.0014100810512900352}, {"id": 289, "seek": 183940, "start": 1839.4, "end": 1851.0, "text": " century. Yeah, okay. But the belief in a soul and consciousness is something separate from a", "tokens": [50364, 4901, 13, 865, 11, 1392, 13, 583, 264, 7107, 294, 257, 5133, 293, 10081, 307, 746, 4994, 490, 257, 50944], "temperature": 0.0, "avg_logprob": -0.22833616468641493, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0003799097321461886}, {"id": 290, "seek": 183940, "start": 1851.0, "end": 1859.64, "text": " material biology. It persists. The belief in all kinds of things. But within the rational part", "tokens": [50944, 2527, 14956, 13, 467, 868, 1751, 13, 440, 7107, 294, 439, 3685, 295, 721, 13, 583, 1951, 264, 15090, 644, 51376], "temperature": 0.0, "avg_logprob": -0.22833616468641493, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0003799097321461886}, {"id": 291, "seek": 185964, "start": 1859.72, "end": 1868.2, "text": " of the human species, once Newton demonstrated that the mechanical model doesn't work,", "tokens": [50368, 295, 264, 1952, 6172, 11, 1564, 19541, 18772, 300, 264, 12070, 2316, 1177, 380, 589, 11, 50792], "temperature": 0.0, "avg_logprob": -0.09296623108878968, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.07157297432422638}, {"id": 292, "seek": 185964, "start": 1869.16, "end": 1877.5600000000002, "text": " there's no material universe in the only sense that was understood. Locke took the obvious conclusion,", "tokens": [50840, 456, 311, 572, 2527, 6445, 294, 264, 787, 2020, 300, 390, 7320, 13, 12859, 330, 1890, 264, 6322, 10063, 11, 51260], "temperature": 0.0, "avg_logprob": -0.09296623108878968, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.07157297432422638}, {"id": 293, "seek": 185964, "start": 1877.5600000000002, "end": 1885.8000000000002, "text": " said, well, since matter, as Mr. Newton has demonstrated, has properties that we cannot", "tokens": [51260, 848, 11, 731, 11, 1670, 1871, 11, 382, 2221, 13, 19541, 575, 18772, 11, 575, 7221, 300, 321, 2644, 51672], "temperature": 0.0, "avg_logprob": -0.09296623108878968, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.07157297432422638}, {"id": 294, "seek": 188580, "start": 1885.8, "end": 1892.52, "text": " conceive of. They're not part of our intuitive picture. Since matter has those properties,", "tokens": [50364, 48605, 295, 13, 814, 434, 406, 644, 295, 527, 21769, 3036, 13, 4162, 1871, 575, 729, 7221, 11, 50700], "temperature": 0.0, "avg_logprob": -0.15491223335266113, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0008557856199331582}, {"id": 295, "seek": 188580, "start": 1893.8, "end": 1899.24, "text": " organized matter can also have the property of thought. This was investigated all through the", "tokens": [50764, 9983, 1871, 393, 611, 362, 264, 4707, 295, 1194, 13, 639, 390, 30070, 439, 807, 264, 51036], "temperature": 0.0, "avg_logprob": -0.15491223335266113, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0008557856199331582}, {"id": 296, "seek": 188580, "start": 1899.24, "end": 1908.6, "text": " 18th century. Ended up finally with Joseph Priestley, a philosopher in the late 18th century,", "tokens": [51036, 2443, 392, 4901, 13, 6967, 292, 493, 2721, 365, 11170, 37052, 3420, 11, 257, 29805, 294, 264, 3469, 2443, 392, 4901, 11, 51504], "temperature": 0.0, "avg_logprob": -0.15491223335266113, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0008557856199331582}, {"id": 297, "seek": 190860, "start": 1908.6, "end": 1918.04, "text": " gave pretty extensive discussions of how material, organized material objects could have", "tokens": [50364, 2729, 1238, 13246, 11088, 295, 577, 2527, 11, 9983, 2527, 6565, 727, 362, 50836], "temperature": 0.0, "avg_logprob": -0.12834213547787424, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.0061921626329422}, {"id": 298, "seek": 190860, "start": 1918.04, "end": 1925.08, "text": " properties of thought. You can even find it in Darwin's early notebooks. It was kind of forgotten", "tokens": [50836, 7221, 295, 1194, 13, 509, 393, 754, 915, 309, 294, 30233, 311, 2440, 43782, 13, 467, 390, 733, 295, 11832, 51188], "temperature": 0.0, "avg_logprob": -0.12834213547787424, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.0061921626329422}, {"id": 299, "seek": 190860, "start": 1925.08, "end": 1932.28, "text": " after that. Rediscovered in the late 20th century as some radical new discovery,", "tokens": [51188, 934, 300, 13, 4477, 40080, 292, 294, 264, 3469, 945, 392, 4901, 382, 512, 12001, 777, 12114, 11, 51548], "temperature": 0.0, "avg_logprob": -0.12834213547787424, "compression_ratio": 1.427807486631016, "no_speech_prob": 0.0061921626329422}, {"id": 300, "seek": 193228, "start": 1932.84, "end": 1940.04, "text": " astonishing hypothesis. Matter can think. Of course it can. In fact, we're doing it right now.", "tokens": [50392, 35264, 17291, 13, 20285, 393, 519, 13, 2720, 1164, 309, 393, 13, 682, 1186, 11, 321, 434, 884, 309, 558, 586, 13, 50752], "temperature": 0.0, "avg_logprob": -0.11727665795220268, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005819185636937618}, {"id": 301, "seek": 193228, "start": 1940.92, "end": 1947.16, "text": " But the only problem then is to find out what's involved in what we call thinking,", "tokens": [50796, 583, 264, 787, 1154, 550, 307, 281, 915, 484, 437, 311, 3288, 294, 437, 321, 818, 1953, 11, 51108], "temperature": 0.0, "avg_logprob": -0.11727665795220268, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005819185636937618}, {"id": 302, "seek": 193228, "start": 1948.12, "end": 1954.44, "text": " what we call sentience, what are the properties of whatever matter is. We don't know what matter is,", "tokens": [51156, 437, 321, 818, 2279, 1182, 11, 437, 366, 264, 7221, 295, 2035, 1871, 307, 13, 492, 500, 380, 458, 437, 1871, 307, 11, 51472], "temperature": 0.0, "avg_logprob": -0.11727665795220268, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005819185636937618}, {"id": 303, "seek": 193228, "start": 1954.44, "end": 1961.56, "text": " but whatever it turns out to be, whatever constitutes the world, what physicists don't", "tokens": [51472, 457, 2035, 309, 4523, 484, 281, 312, 11, 2035, 44204, 264, 1002, 11, 437, 48716, 500, 380, 51828], "temperature": 0.0, "avg_logprob": -0.11727665795220268, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005819185636937618}, {"id": 304, "seek": 196156, "start": 1961.56, "end": 1969.8, "text": " know, but whatever it is, there's something organized. Elements of it can have various properties,", "tokens": [50364, 458, 11, 457, 2035, 309, 307, 11, 456, 311, 746, 9983, 13, 8024, 1117, 295, 309, 393, 362, 3683, 7221, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1137386835538424, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0006065912893973291}, {"id": 305, "seek": 196156, "start": 1970.44, "end": 1976.9199999999998, "text": " like the properties that we are now using, properties that we call sentience. Then the question", "tokens": [50808, 411, 264, 7221, 300, 321, 366, 586, 1228, 11, 7221, 300, 321, 818, 2279, 1182, 13, 1396, 264, 1168, 51132], "temperature": 0.0, "avg_logprob": -0.1137386835538424, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0006065912893973291}, {"id": 306, "seek": 196156, "start": 1976.9199999999998, "end": 1984.9199999999998, "text": " whether something else has sentience is as interesting as whether airplanes fly. If you're", "tokens": [51132, 1968, 746, 1646, 575, 2279, 1182, 307, 382, 1880, 382, 1968, 32947, 3603, 13, 759, 291, 434, 51532], "temperature": 0.0, "avg_logprob": -0.1137386835538424, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0006065912893973291}, {"id": 307, "seek": 198492, "start": 1984.92, "end": 1991.88, "text": " talking English, airplanes fly. If you're talking Hebrew, airplanes glide, they don't fly.", "tokens": [50364, 1417, 3669, 11, 32947, 3603, 13, 759, 291, 434, 1417, 17895, 11, 32947, 41848, 11, 436, 500, 380, 3603, 13, 50712], "temperature": 0.0, "avg_logprob": -0.12845394611358643, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0010477605974301696}, {"id": 308, "seek": 198492, "start": 1993.16, "end": 1999.5600000000002, "text": " It's not a substantive question. What metaphors do we like?", "tokens": [50776, 467, 311, 406, 257, 47113, 1168, 13, 708, 30946, 830, 360, 321, 411, 30, 51096], "temperature": 0.0, "avg_logprob": -0.12845394611358643, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0010477605974301696}, {"id": 309, "seek": 198492, "start": 2001.8000000000002, "end": 2010.8400000000001, "text": " But what you're saying then is that neural net may not be the engineering solution, but", "tokens": [51208, 583, 437, 291, 434, 1566, 550, 307, 300, 18161, 2533, 815, 406, 312, 264, 7043, 3827, 11, 457, 51660], "temperature": 0.0, "avg_logprob": -0.12845394611358643, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0010477605974301696}, {"id": 310, "seek": 201084, "start": 2011.8, "end": 2021.8799999999999, "text": " that eventually it may be possible to create a system outside of the human brain that can think", "tokens": [50412, 300, 4728, 309, 815, 312, 1944, 281, 1884, 257, 1185, 2380, 295, 264, 1952, 3567, 300, 393, 519, 50916], "temperature": 0.0, "avg_logprob": -0.1621092673270933, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00021314833429642022}, {"id": 311, "seek": 201084, "start": 2023.9599999999998, "end": 2031.6399999999999, "text": " whatever thinking means. And do what we call thinking. But whether it thinks or not is like", "tokens": [51020, 2035, 1953, 1355, 13, 400, 360, 437, 321, 818, 1953, 13, 583, 1968, 309, 7309, 420, 406, 307, 411, 51404], "temperature": 0.0, "avg_logprob": -0.1621092673270933, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00021314833429642022}, {"id": 312, "seek": 201084, "start": 2031.6399999999999, "end": 2040.52, "text": " asking the airplanes fly, not a substantive question. We shouldn't waste time on questions", "tokens": [51404, 3365, 264, 32947, 3603, 11, 406, 257, 47113, 1168, 13, 492, 4659, 380, 5964, 565, 322, 1651, 51848], "temperature": 0.0, "avg_logprob": -0.1621092673270933, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00021314833429642022}, {"id": 313, "seek": 204052, "start": 2040.52, "end": 2046.76, "text": " that are completely meaningless. Going back to the history then,", "tokens": [50364, 300, 366, 2584, 33232, 13, 10963, 646, 281, 264, 2503, 550, 11, 50676], "temperature": 0.0, "avg_logprob": -0.14864847577851395, "compression_ratio": 1.4720496894409938, "no_speech_prob": 0.0003404403105378151}, {"id": 314, "seek": 204052, "start": 2049.16, "end": 2054.12, "text": " you know, Minsky was very interested in the possibility of neural nets as a", "tokens": [50796, 291, 458, 11, 376, 44153, 390, 588, 3102, 294, 264, 7959, 295, 18161, 36170, 382, 257, 51044], "temperature": 0.0, "avg_logprob": -0.14864847577851395, "compression_ratio": 1.4720496894409938, "no_speech_prob": 0.0003404403105378151}, {"id": 315, "seek": 204052, "start": 2057.72, "end": 2064.68, "text": " computational model. In Minsky's time, it looked as if neural nets were the right place to look.", "tokens": [51224, 28270, 2316, 13, 682, 376, 44153, 311, 565, 11, 309, 2956, 382, 498, 18161, 36170, 645, 264, 558, 1081, 281, 574, 13, 51572], "temperature": 0.0, "avg_logprob": -0.14864847577851395, "compression_ratio": 1.4720496894409938, "no_speech_prob": 0.0003404403105378151}, {"id": 316, "seek": 206468, "start": 2065.48, "end": 2070.8399999999997, "text": " Now I think it's not so obvious, especially because of Galastal's work,", "tokens": [50404, 823, 286, 519, 309, 311, 406, 370, 6322, 11, 2318, 570, 295, 7336, 525, 304, 311, 589, 11, 50672], "temperature": 0.0, "avg_logprob": -0.17082600209904814, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.011866693384945393}, {"id": 317, "seek": 206468, "start": 2071.7999999999997, "end": 2077.72, "text": " which is not accepted by most neuroscientists, but seems to me pretty compelling.", "tokens": [50720, 597, 307, 406, 9035, 538, 881, 28813, 5412, 1751, 11, 457, 2544, 281, 385, 1238, 20050, 13, 51016], "temperature": 0.0, "avg_logprob": -0.17082600209904814, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.011866693384945393}, {"id": 318, "seek": 206468, "start": 2078.7599999999998, "end": 2083.7999999999997, "text": " Can you talk a little bit about that because I haven't read that and I'm guessing our readers", "tokens": [51068, 1664, 291, 751, 257, 707, 857, 466, 300, 570, 286, 2378, 380, 1401, 300, 293, 286, 478, 17939, 527, 17147, 51320], "temperature": 0.0, "avg_logprob": -0.17082600209904814, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.011866693384945393}, {"id": 319, "seek": 206468, "start": 2083.7999999999997, "end": 2092.04, "text": " haven't, our listeners haven't. Galastal is not the only one. Roger Penrose is another", "tokens": [51320, 2378, 380, 11, 527, 23274, 2378, 380, 13, 7336, 525, 304, 307, 406, 264, 787, 472, 13, 17666, 10571, 37841, 307, 1071, 51732], "temperature": 0.0, "avg_logprob": -0.17082600209904814, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.011866693384945393}, {"id": 320, "seek": 209204, "start": 2093.0, "end": 2098.92, "text": " Nobel Prize winning physicist, but a number of people have pointed out Galastal mostly that", "tokens": [50412, 24611, 22604, 8224, 42466, 11, 457, 257, 1230, 295, 561, 362, 10932, 484, 7336, 525, 304, 5240, 300, 50708], "temperature": 0.0, "avg_logprob": -0.12967284520467123, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0006559959147125483}, {"id": 321, "seek": 209204, "start": 2099.8, "end": 2107.96, "text": " have argued, I think plausibly, that the basic component of a computational system,", "tokens": [50752, 362, 20219, 11, 286, 519, 34946, 3545, 11, 300, 264, 3875, 6542, 295, 257, 28270, 1185, 11, 51160], "temperature": 0.0, "avg_logprob": -0.12967284520467123, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0006559959147125483}, {"id": 322, "seek": 209204, "start": 2109.0, "end": 2115.56, "text": " the basic element of essentially a Turing machine, cannot be constructed from neural nets.", "tokens": [51212, 264, 3875, 4478, 295, 4476, 257, 314, 1345, 3479, 11, 2644, 312, 17083, 490, 18161, 36170, 13, 51540], "temperature": 0.0, "avg_logprob": -0.12967284520467123, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0006559959147125483}, {"id": 323, "seek": 211556, "start": 2116.52, "end": 2123.64, "text": " So you have to look somewhere else with a different form of computation. And he's also", "tokens": [50412, 407, 291, 362, 281, 574, 4079, 1646, 365, 257, 819, 1254, 295, 24903, 13, 400, 415, 311, 611, 50768], "temperature": 0.0, "avg_logprob": -0.16211359618140048, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.003075001062825322}, {"id": 324, "seek": 211556, "start": 2123.64, "end": 2130.84, "text": " pointed out, but in fact, it's true that there's much richer computational capacity in the brain", "tokens": [50768, 10932, 484, 11, 457, 294, 1186, 11, 309, 311, 2074, 300, 456, 311, 709, 29021, 28270, 6042, 294, 264, 3567, 51128], "temperature": 0.0, "avg_logprob": -0.16211359618140048, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.003075001062825322}, {"id": 325, "seek": 211556, "start": 2130.84, "end": 2138.68, "text": " than neural nets, even internal to a cell. There's massive computational capacity", "tokens": [51128, 813, 18161, 36170, 11, 754, 6920, 281, 257, 2815, 13, 821, 311, 5994, 28270, 6042, 51520], "temperature": 0.0, "avg_logprob": -0.16211359618140048, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.003075001062825322}, {"id": 326, "seek": 213868, "start": 2139.64, "end": 2146.04, "text": " intercellular. So maybe that's involved in computation. And then there's by now some", "tokens": [50412, 728, 4164, 1040, 13, 407, 1310, 300, 311, 3288, 294, 24903, 13, 400, 550, 456, 311, 538, 586, 512, 50732], "temperature": 0.0, "avg_logprob": -0.1300258954366048, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.002216577297076583}, {"id": 327, "seek": 213868, "start": 2146.6, "end": 2152.9199999999996, "text": " experimental work, I think, giving some evidence for this, but it's a problem for neuroscientists", "tokens": [50760, 17069, 589, 11, 286, 519, 11, 2902, 512, 4467, 337, 341, 11, 457, 309, 311, 257, 1154, 337, 28813, 5412, 1751, 51076], "temperature": 0.0, "avg_logprob": -0.1300258954366048, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.002216577297076583}, {"id": 328, "seek": 213868, "start": 2152.9199999999996, "end": 2160.52, "text": " to work on. I'm not an expert in the field. I'm looking at it from the outside,", "tokens": [51076, 281, 589, 322, 13, 286, 478, 406, 364, 5844, 294, 264, 2519, 13, 286, 478, 1237, 412, 309, 490, 264, 2380, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1300258954366048, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.002216577297076583}, {"id": 329, "seek": 213868, "start": 2161.24, "end": 2166.04, "text": " so don't take my opinion too seriously. But to me, it looks pretty compelling.", "tokens": [51492, 370, 500, 380, 747, 452, 4800, 886, 6638, 13, 583, 281, 385, 11, 309, 1542, 1238, 20050, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1300258954366048, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.002216577297076583}, {"id": 330, "seek": 216604, "start": 2166.68, "end": 2173.32, "text": " But whatever it is, neural nets or something else, yes, some organization of them, of whatever", "tokens": [50396, 583, 2035, 309, 307, 11, 18161, 36170, 420, 746, 1646, 11, 2086, 11, 512, 4475, 295, 552, 11, 295, 2035, 50728], "temperature": 0.0, "avg_logprob": -0.11293609937032063, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.0007552917231805623}, {"id": 331, "seek": 216604, "start": 2173.32, "end": 2179.8, "text": " is there, is giving us the capacity to do what we're doing. So if you're a scientist, what you do is", "tokens": [50728, 307, 456, 11, 307, 2902, 505, 264, 6042, 281, 360, 437, 321, 434, 884, 13, 407, 498, 291, 434, 257, 12662, 11, 437, 291, 360, 307, 51052], "temperature": 0.0, "avg_logprob": -0.11293609937032063, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.0007552917231805623}, {"id": 332, "seek": 216604, "start": 2181.16, "end": 2188.2, "text": " approach it in two different ways. One is you try to find the properties of the system.", "tokens": [51120, 3109, 309, 294, 732, 819, 2098, 13, 1485, 307, 291, 853, 281, 915, 264, 7221, 295, 264, 1185, 13, 51472], "temperature": 0.0, "avg_logprob": -0.11293609937032063, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.0007552917231805623}, {"id": 333, "seek": 216604, "start": 2188.84, "end": 2195.0, "text": " What is the nature of the system? That's first step kind of thing I was talking about before with", "tokens": [51504, 708, 307, 264, 3687, 295, 264, 1185, 30, 663, 311, 700, 1823, 733, 295, 551, 286, 390, 1417, 466, 949, 365, 51812], "temperature": 0.0, "avg_logprob": -0.11293609937032063, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.0007552917231805623}, {"id": 334, "seek": 219500, "start": 2195.64, "end": 2203.48, "text": " structure dependence. What are the properties of the system that an infant automatically", "tokens": [50396, 3877, 31704, 13, 708, 366, 264, 7221, 295, 264, 1185, 300, 364, 16757, 6772, 50788], "temperature": 0.0, "avg_logprob": -0.08355568477085658, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.00030523326131515205}, {"id": 335, "seek": 219500, "start": 2203.48, "end": 2209.96, "text": " develops in the mind? And there's a lot of work on that. From the other point of view, you can say,", "tokens": [50788, 25453, 294, 264, 1575, 30, 400, 456, 311, 257, 688, 295, 589, 322, 300, 13, 3358, 264, 661, 935, 295, 1910, 11, 291, 393, 584, 11, 51112], "temperature": 0.0, "avg_logprob": -0.08355568477085658, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.00030523326131515205}, {"id": 336, "seek": 219500, "start": 2210.76, "end": 2217.08, "text": " what can we learn about the brain that relates to this? Actually, there is some work. So there is", "tokens": [51152, 437, 393, 321, 1466, 466, 264, 3567, 300, 16155, 281, 341, 30, 5135, 11, 456, 307, 512, 589, 13, 407, 456, 307, 51468], "temperature": 0.0, "avg_logprob": -0.08355568477085658, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.00030523326131515205}, {"id": 337, "seek": 221708, "start": 2217.08, "end": 2230.92, "text": " neurophysiological studies which have shown that for artificial languages that violate the principle", "tokens": [50364, 16499, 950, 749, 72, 4383, 5313, 597, 362, 4898, 300, 337, 11677, 8650, 300, 37478, 264, 8665, 51056], "temperature": 0.0, "avg_logprob": -0.14963161736203914, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.0013879328034818172}, {"id": 338, "seek": 221708, "start": 2231.64, "end": 2238.12, "text": " that I mentioned, this structure dependent principle, if you train people on those,", "tokens": [51092, 300, 286, 2835, 11, 341, 3877, 12334, 8665, 11, 498, 291, 3847, 561, 322, 729, 11, 51416], "temperature": 0.0, "avg_logprob": -0.14963161736203914, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.0013879328034818172}, {"id": 339, "seek": 221708, "start": 2239.08, "end": 2245.48, "text": " the ordinary language centers don't function. You get diffuse functioning of the brain,", "tokens": [51464, 264, 10547, 2856, 10898, 500, 380, 2445, 13, 509, 483, 42165, 18483, 295, 264, 3567, 11, 51784], "temperature": 0.0, "avg_logprob": -0.14963161736203914, "compression_ratio": 1.536723163841808, "no_speech_prob": 0.0013879328034818172}, {"id": 340, "seek": 224548, "start": 2245.48, "end": 2253.72, "text": " means they're being treated as puzzles basically. So you can find some neurological correlates of", "tokens": [50364, 1355, 436, 434, 885, 8668, 382, 24138, 1936, 13, 407, 291, 393, 915, 512, 48185, 13983, 1024, 295, 50776], "temperature": 0.0, "avg_logprob": -0.08516324116633489, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.0003624109667725861}, {"id": 341, "seek": 224548, "start": 2254.44, "end": 2260.36, "text": " some of the things that are discovered by looking at the nature of the phenotype.", "tokens": [50812, 512, 295, 264, 721, 300, 366, 6941, 538, 1237, 412, 264, 3687, 295, 264, 7279, 13108, 13, 51108], "temperature": 0.0, "avg_logprob": -0.08516324116633489, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.0003624109667725861}, {"id": 342, "seek": 224548, "start": 2261.64, "end": 2268.84, "text": " But it's very hard for humans for a number of reasons. We know a lot about human, the physiology", "tokens": [51172, 583, 309, 311, 588, 1152, 337, 6255, 337, 257, 1230, 295, 4112, 13, 492, 458, 257, 688, 466, 1952, 11, 264, 43585, 51532], "temperature": 0.0, "avg_logprob": -0.08516324116633489, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.0003624109667725861}, {"id": 343, "seek": 226884, "start": 2268.92, "end": 2277.48, "text": " of human vision. But the reason is because of invasive experiments with nonhumans, cats,", "tokens": [50368, 295, 1952, 5201, 13, 583, 264, 1778, 307, 570, 295, 30894, 12050, 365, 2107, 14645, 599, 11, 11111, 11, 50796], "temperature": 0.0, "avg_logprob": -0.13543380390514026, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.014054425992071629}, {"id": 344, "seek": 226884, "start": 2278.6800000000003, "end": 2286.2000000000003, "text": " monkeys and so on. Can't do that for language. There aren't any other organisms unique to humans.", "tokens": [50856, 29534, 293, 370, 322, 13, 1664, 380, 360, 300, 337, 2856, 13, 821, 3212, 380, 604, 661, 22110, 3845, 281, 6255, 13, 51232], "temperature": 0.0, "avg_logprob": -0.13543380390514026, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.014054425992071629}, {"id": 345, "seek": 226884, "start": 2287.0, "end": 2293.48, "text": " So there's no comparative studies. You can think of a lot of invasive experiments which", "tokens": [51272, 407, 456, 311, 572, 39292, 5313, 13, 509, 393, 519, 295, 257, 688, 295, 30894, 12050, 597, 51596], "temperature": 0.0, "avg_logprob": -0.13543380390514026, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.014054425992071629}, {"id": 346, "seek": 229348, "start": 2293.56, "end": 2301.2400000000002, "text": " teach you a lot. You can't do them for ethical reasons. So study of the neurophysiology of", "tokens": [50368, 2924, 291, 257, 688, 13, 509, 393, 380, 360, 552, 337, 18890, 4112, 13, 407, 2979, 295, 264, 16499, 950, 749, 46457, 295, 50752], "temperature": 0.0, "avg_logprob": -0.09026285373803342, "compression_ratio": 1.425531914893617, "no_speech_prob": 0.00159668386913836}, {"id": 347, "seek": 229348, "start": 2302.12, "end": 2311.2400000000002, "text": " human cognition is a uniquely hard problem. In its basic elements like language,", "tokens": [50796, 1952, 46905, 307, 257, 31474, 1152, 1154, 13, 682, 1080, 3875, 4959, 411, 2856, 11, 51252], "temperature": 0.0, "avg_logprob": -0.09026285373803342, "compression_ratio": 1.425531914893617, "no_speech_prob": 0.00159668386913836}, {"id": 348, "seek": 229348, "start": 2311.2400000000002, "end": 2318.92, "text": " it's just unique to the species. And in fact, a very recent development in evolutionary history,", "tokens": [51252, 309, 311, 445, 3845, 281, 264, 6172, 13, 400, 294, 1186, 11, 257, 588, 5162, 3250, 294, 27567, 2503, 11, 51636], "temperature": 0.0, "avg_logprob": -0.09026285373803342, "compression_ratio": 1.425531914893617, "no_speech_prob": 0.00159668386913836}, {"id": 349, "seek": 231892, "start": 2318.92, "end": 2325.88, "text": " probably the last couple of hundred thousand years, which is nothing. So you can't do the", "tokens": [50364, 1391, 264, 1036, 1916, 295, 3262, 4714, 924, 11, 597, 307, 1825, 13, 407, 291, 393, 380, 360, 264, 50712], "temperature": 0.0, "avg_logprob": -0.13207464951735276, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.0008829472353681922}, {"id": 350, "seek": 231892, "start": 2325.88, "end": 2330.76, "text": " invasive experiments for ethical reasons. You can think of them, but you can't do them,", "tokens": [50712, 30894, 12050, 337, 18890, 4112, 13, 509, 393, 519, 295, 552, 11, 457, 291, 393, 380, 360, 552, 11, 50956], "temperature": 0.0, "avg_logprob": -0.13207464951735276, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.0008829472353681922}, {"id": 351, "seek": 231892, "start": 2330.76, "end": 2338.12, "text": " fortunately. And there's no comparative evidence. So it's much harder to do. You have to do things", "tokens": [50956, 25511, 13, 400, 456, 311, 572, 39292, 4467, 13, 407, 309, 311, 709, 6081, 281, 360, 13, 509, 362, 281, 360, 721, 51324], "temperature": 0.0, "avg_logprob": -0.13207464951735276, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.0008829472353681922}, {"id": 352, "seek": 231892, "start": 2338.12, "end": 2347.16, "text": " like, you know, looking at a blood flow in the brain, MRI type things, electrical stimulation,", "tokens": [51324, 411, 11, 291, 458, 11, 1237, 412, 257, 3390, 3095, 294, 264, 3567, 11, 32812, 2010, 721, 11, 12147, 37405, 11, 51776], "temperature": 0.0, "avg_logprob": -0.13207464951735276, "compression_ratio": 1.578723404255319, "no_speech_prob": 0.0008829472353681922}, {"id": 353, "seek": 234716, "start": 2347.16, "end": 2353.56, "text": " looking from the outside. It's tough. It's not like doing the kind of experiments you can think of.", "tokens": [50364, 1237, 490, 264, 2380, 13, 467, 311, 4930, 13, 467, 311, 406, 411, 884, 264, 733, 295, 12050, 291, 393, 519, 295, 13, 50684], "temperature": 0.0, "avg_logprob": -0.092602907816569, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004440895572770387}, {"id": 354, "seek": 234716, "start": 2354.6, "end": 2362.2, "text": " So it's very hard to find out the neurophysiological basis for things like use of language. But", "tokens": [50736, 407, 309, 311, 588, 1152, 281, 915, 484, 264, 16499, 950, 749, 72, 4383, 5143, 337, 721, 411, 764, 295, 2856, 13, 583, 51116], "temperature": 0.0, "avg_logprob": -0.092602907816569, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004440895572770387}, {"id": 355, "seek": 234716, "start": 2362.92, "end": 2367.24, "text": " it's one way to proceed. And the other way to proceed is learn more about the phenol.", "tokens": [51152, 309, 311, 472, 636, 281, 8991, 13, 400, 264, 661, 636, 281, 8991, 307, 1466, 544, 466, 264, 7279, 401, 13, 51368], "temperature": 0.0, "avg_logprob": -0.092602907816569, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0004440895572770387}, {"id": 356, "seek": 236724, "start": 2367.7999999999997, "end": 2378.12, "text": " It's like chemistry for hundreds of years. You just postulated the existence of atoms.", "tokens": [50392, 467, 311, 411, 12558, 337, 6779, 295, 924, 13, 509, 445, 2183, 6987, 264, 9123, 295, 16871, 13, 50908], "temperature": 0.0, "avg_logprob": -0.20139598846435547, "compression_ratio": 1.4269662921348314, "no_speech_prob": 0.007344692945480347}, {"id": 357, "seek": 236724, "start": 2379.56, "end": 2384.12, "text": " Nobody could see them. You know, why are they there? You know, because unless", "tokens": [50980, 9297, 727, 536, 552, 13, 509, 458, 11, 983, 366, 436, 456, 30, 509, 458, 11, 570, 5969, 51208], "temperature": 0.0, "avg_logprob": -0.20139598846435547, "compression_ratio": 1.4269662921348314, "no_speech_prob": 0.007344692945480347}, {"id": 358, "seek": 236724, "start": 2384.8399999999997, "end": 2391.64, "text": " there are atoms with the Dalton's properties, you don't explain anything. Early genetics,", "tokens": [51244, 456, 366, 16871, 365, 264, 17357, 1756, 311, 7221, 11, 291, 500, 380, 2903, 1340, 13, 18344, 26516, 11, 51584], "temperature": 0.0, "avg_logprob": -0.20139598846435547, "compression_ratio": 1.4269662921348314, "no_speech_prob": 0.007344692945480347}, {"id": 359, "seek": 239164, "start": 2392.6, "end": 2398.12, "text": " early genetics work before anybody had any idea what a gene is. You just looked at the", "tokens": [50412, 2440, 26516, 589, 949, 4472, 632, 604, 1558, 437, 257, 12186, 307, 13, 509, 445, 2956, 412, 264, 50688], "temperature": 0.0, "avg_logprob": -0.15236154794692994, "compression_ratio": 1.5352112676056338, "no_speech_prob": 0.0005192736862227321}, {"id": 360, "seek": 239164, "start": 2399.7999999999997, "end": 2404.04, "text": " properties of the system, try to figure out what must be going on.", "tokens": [50772, 7221, 295, 264, 1185, 11, 853, 281, 2573, 484, 437, 1633, 312, 516, 322, 13, 50984], "temperature": 0.0, "avg_logprob": -0.15236154794692994, "compression_ratio": 1.5352112676056338, "no_speech_prob": 0.0005192736862227321}, {"id": 361, "seek": 239164, "start": 2405.4, "end": 2412.6, "text": " It's the way astrophysics works. You know, most of science works like that. So this does too.", "tokens": [51052, 467, 311, 264, 636, 5357, 11741, 41732, 1985, 13, 509, 458, 11, 881, 295, 3497, 1985, 411, 300, 13, 407, 341, 775, 886, 13, 51412], "temperature": 0.0, "avg_logprob": -0.15236154794692994, "compression_ratio": 1.5352112676056338, "no_speech_prob": 0.0005192736862227321}, {"id": 362, "seek": 239164, "start": 2413.3199999999997, "end": 2421.0, "text": " When you talk about invasive exploration, there are tools that are increasingly", "tokens": [51448, 1133, 291, 751, 466, 30894, 16197, 11, 456, 366, 3873, 300, 366, 12980, 51832], "temperature": 0.0, "avg_logprob": -0.15236154794692994, "compression_ratio": 1.5352112676056338, "no_speech_prob": 0.0005192736862227321}, {"id": 363, "seek": 242100, "start": 2421.08, "end": 2428.92, "text": " sophisticated. I'm thinking of neural link, Elon Musk's startup that has these super fine", "tokens": [50368, 16950, 13, 286, 478, 1953, 295, 18161, 2113, 11, 28498, 26019, 311, 18578, 300, 575, 613, 1687, 2489, 50760], "temperature": 0.0, "avg_logprob": -0.15209369001717404, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.0003981340560130775}, {"id": 364, "seek": 242100, "start": 2431.08, "end": 2439.08, "text": " electrodes that can be put into the brain without damaging individual neurons.", "tokens": [50868, 47824, 300, 393, 312, 829, 666, 264, 3567, 1553, 25342, 2609, 22027, 13, 51268], "temperature": 0.0, "avg_logprob": -0.15209369001717404, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.0003981340560130775}, {"id": 365, "seek": 242100, "start": 2440.52, "end": 2446.28, "text": " There's actually, I think, much more advanced than that is work that's being done with", "tokens": [51340, 821, 311, 767, 11, 286, 519, 11, 709, 544, 7339, 813, 300, 307, 589, 300, 311, 885, 1096, 365, 51628], "temperature": 0.0, "avg_logprob": -0.15209369001717404, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.0003981340560130775}, {"id": 366, "seek": 244628, "start": 2447.2400000000002, "end": 2454.36, "text": " patients under brain surgery. Under brain surgery, with the brain basically exposed,", "tokens": [50412, 4209, 833, 3567, 7930, 13, 6974, 3567, 7930, 11, 365, 264, 3567, 1936, 9495, 11, 50768], "temperature": 0.0, "avg_logprob": -0.15333926460959696, "compression_ratio": 1.525, "no_speech_prob": 0.0002304872905369848}, {"id": 367, "seek": 244628, "start": 2454.36, "end": 2463.1600000000003, "text": " there are some noninvasive procedures that can be used to study what particular", "tokens": [50768, 456, 366, 512, 2107, 259, 39211, 13846, 300, 393, 312, 1143, 281, 2979, 437, 1729, 51208], "temperature": 0.0, "avg_logprob": -0.15333926460959696, "compression_ratio": 1.525, "no_speech_prob": 0.0002304872905369848}, {"id": 368, "seek": 244628, "start": 2464.6000000000004, "end": 2469.48, "text": " parts of the brain, even particular neurons are doing. It's very delicate work.", "tokens": [51280, 3166, 295, 264, 3567, 11, 754, 1729, 22027, 366, 884, 13, 467, 311, 588, 21417, 589, 13, 51524], "temperature": 0.0, "avg_logprob": -0.15333926460959696, "compression_ratio": 1.525, "no_speech_prob": 0.0002304872905369848}, {"id": 369, "seek": 246948, "start": 2470.44, "end": 2478.28, "text": " But there is some work going on. One person is working on it is Andrea Moro,", "tokens": [50412, 583, 456, 307, 512, 589, 516, 322, 13, 1485, 954, 307, 1364, 322, 309, 307, 24215, 5146, 78, 11, 50804], "temperature": 0.0, "avg_logprob": -0.16575194895267487, "compression_ratio": 1.5, "no_speech_prob": 0.004069451708346605}, {"id": 370, "seek": 246948, "start": 2478.28, "end": 2483.56, "text": " the same person who designed the experiments that I described before about impossible languages.", "tokens": [50804, 264, 912, 954, 567, 4761, 264, 12050, 300, 286, 7619, 949, 466, 6243, 8650, 13, 51068], "temperature": 0.0, "avg_logprob": -0.16575194895267487, "compression_ratio": 1.5, "no_speech_prob": 0.004069451708346605}, {"id": 371, "seek": 246948, "start": 2484.36, "end": 2493.32, "text": " That seems to me a promising direction. There's other kinds of work. I could mention some of it.", "tokens": [51108, 663, 2544, 281, 385, 257, 20257, 3513, 13, 821, 311, 661, 3685, 295, 589, 13, 286, 727, 2152, 512, 295, 309, 13, 51556], "temperature": 0.0, "avg_logprob": -0.16575194895267487, "compression_ratio": 1.5, "no_speech_prob": 0.004069451708346605}, {"id": 372, "seek": 249332, "start": 2493.32, "end": 2503.0, "text": " Alec Moran, why you was doing interesting studies that shed some light on the very", "tokens": [50364, 9366, 66, 5146, 282, 11, 983, 291, 390, 884, 1880, 5313, 300, 14951, 512, 1442, 322, 264, 588, 50848], "temperature": 0.0, "avg_logprob": -0.23331451416015625, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003221197985112667}, {"id": 373, "seek": 249332, "start": 2503.0, "end": 2512.6000000000004, "text": " elementary function. How do words get stored in the brain? What's going on in the brain that", "tokens": [50848, 16429, 2445, 13, 1012, 360, 2283, 483, 12187, 294, 264, 3567, 30, 708, 311, 516, 322, 294, 264, 3567, 300, 51328], "temperature": 0.0, "avg_logprob": -0.23331451416015625, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003221197985112667}, {"id": 374, "seek": 249332, "start": 2514.04, "end": 2521.4, "text": " tells us that blake is a possible word, but the nick isn't for an English speaker. It is for", "tokens": [51400, 5112, 505, 300, 888, 619, 307, 257, 1944, 1349, 11, 457, 264, 15416, 1943, 380, 337, 364, 3669, 8145, 13, 467, 307, 337, 51768], "temperature": 0.0, "avg_logprob": -0.23331451416015625, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.003221197985112667}, {"id": 375, "seek": 252140, "start": 2521.48, "end": 2526.84, "text": " an Arabic speaker. What's going on in the brain that deals with that?", "tokens": [50368, 364, 19938, 8145, 13, 708, 311, 516, 322, 294, 264, 3567, 300, 11215, 365, 300, 30, 50636], "temperature": 0.0, "avg_logprob": -0.2345202128092448, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.0002958271943498403}, {"id": 376, "seek": 252140, "start": 2528.28, "end": 2538.04, "text": " Hard work. David Peppel, another very good neuroscientist, has found evidence", "tokens": [50708, 11817, 589, 13, 4389, 2396, 427, 338, 11, 1071, 588, 665, 28813, 5412, 468, 11, 575, 1352, 4467, 51196], "temperature": 0.0, "avg_logprob": -0.2345202128092448, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.0002958271943498403}, {"id": 377, "seek": 252140, "start": 2539.0, "end": 2548.92, "text": " for things like pharyngeal structure in the brain. But the kinds of invasive experiments", "tokens": [51244, 337, 721, 411, 903, 39008, 432, 304, 3877, 294, 264, 3567, 13, 583, 264, 3685, 295, 30894, 12050, 51740], "temperature": 0.0, "avg_logprob": -0.2345202128092448, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.0002958271943498403}, {"id": 378, "seek": 254892, "start": 2548.92, "end": 2556.2000000000003, "text": " you can dream of, you can think of, he's just not allowed to do. So you have to try it in much", "tokens": [50364, 291, 393, 3055, 295, 11, 291, 393, 519, 295, 11, 415, 311, 445, 406, 4350, 281, 360, 13, 407, 291, 362, 281, 853, 309, 294, 709, 50728], "temperature": 0.0, "avg_logprob": -0.11239954829216003, "compression_ratio": 1.4915254237288136, "no_speech_prob": 0.0011689477832987905}, {"id": 379, "seek": 254892, "start": 2556.2000000000003, "end": 2564.28, "text": " indirect ways. Do you think that understanding cognition has advanced in your lifetime?", "tokens": [50728, 19523, 2098, 13, 1144, 291, 519, 300, 3701, 46905, 575, 7339, 294, 428, 11364, 30, 51132], "temperature": 0.0, "avg_logprob": -0.11239954829216003, "compression_ratio": 1.4915254237288136, "no_speech_prob": 0.0011689477832987905}, {"id": 380, "seek": 254892, "start": 2565.08, "end": 2572.12, "text": " And are you hopeful that we'll eventually really understand how the brain thinks?", "tokens": [51172, 400, 366, 291, 20531, 300, 321, 603, 4728, 534, 1223, 577, 264, 3567, 7309, 30, 51524], "temperature": 0.0, "avg_logprob": -0.11239954829216003, "compression_ratio": 1.4915254237288136, "no_speech_prob": 0.0011689477832987905}, {"id": 381, "seek": 257212, "start": 2572.2, "end": 2584.3599999999997, "text": " Well, there's been vast improvement in understanding the phenotype that we know a great deal about", "tokens": [50368, 1042, 11, 456, 311, 668, 8369, 10444, 294, 3701, 264, 7279, 13108, 300, 321, 458, 257, 869, 2028, 466, 50976], "temperature": 0.0, "avg_logprob": -0.17399450865658847, "compression_ratio": 1.4104477611940298, "no_speech_prob": 0.001866517006419599}, {"id": 382, "seek": 257212, "start": 2584.3599999999997, "end": 2593.3199999999997, "text": " that was not known even a few years ago. There's been some progress in the neuroscience of", "tokens": [50976, 300, 390, 406, 2570, 754, 257, 1326, 924, 2057, 13, 821, 311, 668, 512, 4205, 294, 264, 42762, 295, 51424], "temperature": 0.0, "avg_logprob": -0.17399450865658847, "compression_ratio": 1.4104477611940298, "no_speech_prob": 0.001866517006419599}, {"id": 383, "seek": 259332, "start": 2594.1200000000003, "end": 2605.88, "text": " the relates to it, but it's much harder. Yeah. I'm just curious about where you are in,", "tokens": [50404, 264, 16155, 281, 309, 11, 457, 309, 311, 709, 6081, 13, 865, 13, 286, 478, 445, 6369, 466, 689, 291, 366, 294, 11, 50992], "temperature": 0.0, "avg_logprob": -0.17473362861795627, "compression_ratio": 1.368, "no_speech_prob": 0.01448933593928814}, {"id": 384, "seek": 259332, "start": 2606.84, "end": 2614.04, "text": " not physically you're in Arizona, but where you are in your thinking. Are you still", "tokens": [51040, 406, 9762, 291, 434, 294, 14723, 11, 457, 689, 291, 366, 294, 428, 1953, 13, 2014, 291, 920, 51400], "temperature": 0.0, "avg_logprob": -0.17473362861795627, "compression_ratio": 1.368, "no_speech_prob": 0.01448933593928814}, {"id": 385, "seek": 261404, "start": 2614.2, "end": 2629.32, "text": " pushing forward in trying to understand language in the brain or are you sort of retired, so to speak,", "tokens": [50372, 7380, 2128, 294, 1382, 281, 1223, 2856, 294, 264, 3567, 420, 366, 291, 1333, 295, 16776, 11, 370, 281, 1710, 11, 51128], "temperature": 0.0, "avg_logprob": -0.20993442161410464, "compression_ratio": 1.3098591549295775, "no_speech_prob": 0.002181568183004856}, {"id": 386, "seek": 261404, "start": 2629.32, "end": 2636.2799999999997, "text": " at this point? No, very much involved. I mean, I don't work on the neurophysiology.", "tokens": [51128, 412, 341, 935, 30, 883, 11, 588, 709, 3288, 13, 286, 914, 11, 286, 500, 380, 589, 322, 264, 16499, 950, 749, 46457, 13, 51476], "temperature": 0.0, "avg_logprob": -0.20993442161410464, "compression_ratio": 1.3098591549295775, "no_speech_prob": 0.002181568183004856}, {"id": 387, "seek": 263628, "start": 2636.6000000000004, "end": 2648.1200000000003, "text": " A man I mentioned, Andrea Moro, happens to be a good friend. So I follow the work they're doing,", "tokens": [50380, 316, 587, 286, 2835, 11, 24215, 5146, 78, 11, 2314, 281, 312, 257, 665, 1277, 13, 407, 286, 1524, 264, 589, 436, 434, 884, 11, 50956], "temperature": 0.0, "avg_logprob": -0.24581872023545304, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.007574496790766716}, {"id": 388, "seek": 263628, "start": 2648.1200000000003, "end": 2655.2400000000002, "text": " we interact, but my work is just on the phenotype. What's the nature of the system?", "tokens": [50956, 321, 4648, 11, 457, 452, 589, 307, 445, 322, 264, 7279, 13108, 13, 708, 311, 264, 3687, 295, 264, 1185, 30, 51312], "temperature": 0.0, "avg_logprob": -0.24581872023545304, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.007574496790766716}, {"id": 389, "seek": 263628, "start": 2655.88, "end": 2661.48, "text": " And there, I think we're learning a lot. I'm right in the middle of papers at the moment,", "tokens": [51344, 400, 456, 11, 286, 519, 321, 434, 2539, 257, 688, 13, 286, 478, 558, 294, 264, 2808, 295, 10577, 412, 264, 1623, 11, 51624], "temperature": 0.0, "avg_logprob": -0.24581872023545304, "compression_ratio": 1.4361702127659575, "no_speech_prob": 0.007574496790766716}, {"id": 390, "seek": 266148, "start": 2662.44, "end": 2668.84, "text": " looking at more subtle, complex properties. The idea is essentially to find", "tokens": [50412, 1237, 412, 544, 13743, 11, 3997, 7221, 13, 440, 1558, 307, 4476, 281, 915, 50732], "temperature": 0.0, "avg_logprob": -0.1714310365564683, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.001524282619357109}, {"id": 391, "seek": 266148, "start": 2670.04, "end": 2678.76, "text": " what I said about binary set formation. How can we show that from the simplest", "tokens": [50792, 437, 286, 848, 466, 17434, 992, 11723, 13, 1012, 393, 321, 855, 300, 490, 264, 22811, 51228], "temperature": 0.0, "avg_logprob": -0.1714310365564683, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.001524282619357109}, {"id": 392, "seek": 266148, "start": 2679.8, "end": 2689.08, "text": " computational procedures, we can account for the apparently complex and apparently varied", "tokens": [51280, 28270, 13846, 11, 321, 393, 2696, 337, 264, 7970, 3997, 293, 7970, 22877, 51744], "temperature": 0.0, "avg_logprob": -0.1714310365564683, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.001524282619357109}, {"id": 393, "seek": 268908, "start": 2689.88, "end": 2696.2, "text": " properties of the language systems. There's a fair amount of progress on that,", "tokens": [50404, 7221, 295, 264, 2856, 3652, 13, 821, 311, 257, 3143, 2372, 295, 4205, 322, 300, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1926964653862847, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.0006985009531490505}, {"id": 394, "seek": 268908, "start": 2697.64, "end": 2705.48, "text": " that was unheard of 20, 30 years ago. So this is all new. Understanding is one thing and then", "tokens": [50792, 300, 390, 517, 42915, 295, 945, 11, 2217, 924, 2057, 13, 407, 341, 307, 439, 777, 13, 36858, 307, 472, 551, 293, 550, 51184], "temperature": 0.0, "avg_logprob": -0.1926964653862847, "compression_ratio": 1.3129770992366412, "no_speech_prob": 0.0006985009531490505}, {"id": 395, "seek": 270548, "start": 2706.12, "end": 2718.52, "text": " re-creating it through computation in external hardware is another. Is that a blind ally or do", "tokens": [50396, 319, 12, 35546, 278, 309, 807, 24903, 294, 8320, 8837, 307, 1071, 13, 1119, 300, 257, 6865, 23356, 420, 360, 51016], "temperature": 0.0, "avg_logprob": -0.29424557319054234, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.0033238243777304888}, {"id": 396, "seek": 270548, "start": 2718.52, "end": 2727.32, "text": " you think that? Well, at the moment, I don't see any particular point in it. If there is some point,", "tokens": [51016, 291, 519, 300, 30, 1042, 11, 412, 264, 1623, 11, 286, 500, 380, 536, 604, 1729, 935, 294, 309, 13, 759, 456, 307, 512, 935, 11, 51456], "temperature": 0.0, "avg_logprob": -0.29424557319054234, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.0033238243777304888}, {"id": 397, "seek": 272732, "start": 2728.28, "end": 2737.2400000000002, "text": " okay. I mean, the kinds of things that we're learning about the nature of language,", "tokens": [50412, 1392, 13, 286, 914, 11, 264, 3685, 295, 721, 300, 321, 434, 2539, 466, 264, 3687, 295, 2856, 11, 50860], "temperature": 0.0, "avg_logprob": -0.10957219451665878, "compression_ratio": 1.45, "no_speech_prob": 0.0008038561791181564}, {"id": 398, "seek": 272732, "start": 2738.36, "end": 2743.7200000000003, "text": " I suppose you could construct some sort of system that would duplicate them,", "tokens": [50916, 286, 7297, 291, 727, 7690, 512, 1333, 295, 1185, 300, 576, 23976, 552, 11, 51184], "temperature": 0.0, "avg_logprob": -0.10957219451665878, "compression_ratio": 1.45, "no_speech_prob": 0.0008038561791181564}, {"id": 399, "seek": 272732, "start": 2745.32, "end": 2754.52, "text": " but it doesn't seem any obvious point to it. It's like taking chemistry in 100 years ago and saying,", "tokens": [51264, 457, 309, 1177, 380, 1643, 604, 6322, 935, 281, 309, 13, 467, 311, 411, 1940, 12558, 294, 2319, 924, 2057, 293, 1566, 11, 51724], "temperature": 0.0, "avg_logprob": -0.10957219451665878, "compression_ratio": 1.45, "no_speech_prob": 0.0008038561791181564}, {"id": 400, "seek": 275452, "start": 2755.4, "end": 2758.7599999999998, "text": " can I construct models that will look sort of like,", "tokens": [50408, 393, 286, 7690, 5245, 300, 486, 574, 1333, 295, 411, 11, 50576], "temperature": 0.0, "avg_logprob": -0.18583060635460746, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0010481473291292787}, {"id": 401, "seek": 275452, "start": 2759.48, "end": 2766.84, "text": " suppose you took, I was saying, a kick of the diagram for an organic molecule", "tokens": [50612, 7297, 291, 1890, 11, 286, 390, 1566, 11, 257, 4437, 295, 264, 10686, 337, 364, 10220, 15582, 50980], "temperature": 0.0, "avg_logprob": -0.18583060635460746, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0010481473291292787}, {"id": 402, "seek": 275452, "start": 2767.96, "end": 2774.68, "text": " and study its properties. You could presumably construct a mechanical model", "tokens": [51036, 293, 2979, 1080, 7221, 13, 509, 727, 26742, 7690, 257, 12070, 2316, 51372], "temperature": 0.0, "avg_logprob": -0.18583060635460746, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0010481473291292787}, {"id": 403, "seek": 275452, "start": 2775.48, "end": 2781.88, "text": " that would do some of those things. Would it be useful? Apparently chemists didn't think so, but", "tokens": [51412, 300, 576, 360, 512, 295, 729, 721, 13, 6068, 309, 312, 4420, 30, 16755, 4771, 1751, 994, 380, 519, 370, 11, 457, 51732], "temperature": 0.0, "avg_logprob": -0.18583060635460746, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.0010481473291292787}, {"id": 404, "seek": 278188, "start": 2782.52, "end": 2787.4, "text": " if it would, okay. If it wouldn't, then don't.", "tokens": [50396, 498, 309, 576, 11, 1392, 13, 759, 309, 2759, 380, 11, 550, 500, 380, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1898987211030105, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.00043718249071389437}, {"id": 405, "seek": 278188, "start": 2790.12, "end": 2795.08, "text": " Nonetheless, I mean, we are using neural nets even in this call.", "tokens": [50776, 45437, 11, 286, 914, 11, 321, 366, 1228, 18161, 36170, 754, 294, 341, 818, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1898987211030105, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.00043718249071389437}, {"id": 406, "seek": 278188, "start": 2797.08, "end": 2806.44, "text": " Do you see, I mean, setting inside the question of whether or not they help us understand anything", "tokens": [51124, 1144, 291, 536, 11, 286, 914, 11, 3287, 1854, 264, 1168, 295, 1968, 420, 406, 436, 854, 505, 1223, 1340, 51592], "temperature": 0.0, "avg_logprob": -0.1898987211030105, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.00043718249071389437}, {"id": 407, "seek": 280644, "start": 2806.44, "end": 2814.6, "text": " about the brain. Are you excited at all in about the promise that these large", "tokens": [50364, 466, 264, 3567, 13, 2014, 291, 2919, 412, 439, 294, 466, 264, 6228, 300, 613, 2416, 50772], "temperature": 0.0, "avg_logprob": -0.1185154914855957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.006690396461635828}, {"id": 408, "seek": 280644, "start": 2814.6, "end": 2818.68, "text": " models hold? I mean, because they do something very useful.", "tokens": [50772, 5245, 1797, 30, 286, 914, 11, 570, 436, 360, 746, 588, 4420, 13, 50976], "temperature": 0.0, "avg_logprob": -0.1185154914855957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.006690396461635828}, {"id": 409, "seek": 280644, "start": 2819.8, "end": 2827.96, "text": " They are. Like I said, I'm using it right now. I think it's fine for me, somebody who can't hear", "tokens": [51032, 814, 366, 13, 1743, 286, 848, 11, 286, 478, 1228, 309, 558, 586, 13, 286, 519, 309, 311, 2489, 337, 385, 11, 2618, 567, 393, 380, 1568, 51440], "temperature": 0.0, "avg_logprob": -0.1185154914855957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.006690396461635828}, {"id": 410, "seek": 282796, "start": 2828.04, "end": 2836.04, "text": " to be able to read what you're saying pretty accurately. It's an achievement, so great.", "tokens": [50368, 281, 312, 1075, 281, 1401, 437, 291, 434, 1566, 1238, 20095, 13, 467, 311, 364, 15838, 11, 370, 869, 13, 50768], "temperature": 0.0, "avg_logprob": -0.15230094061957467, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.020012211054563522}, {"id": 411, "seek": 282796, "start": 2837.4, "end": 2845.16, "text": " I have nothing against technology. And who do you think is going to carry on", "tokens": [50836, 286, 362, 1825, 1970, 2899, 13, 400, 567, 360, 291, 519, 307, 516, 281, 3985, 322, 51224], "temperature": 0.0, "avg_logprob": -0.15230094061957467, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.020012211054563522}, {"id": 412, "seek": 282796, "start": 2847.4, "end": 2854.84, "text": " your work from here? I mean, are there any students of yours who you think we should", "tokens": [51336, 428, 589, 490, 510, 30, 286, 914, 11, 366, 456, 604, 1731, 295, 6342, 567, 291, 519, 321, 820, 51708], "temperature": 0.0, "avg_logprob": -0.15230094061957467, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.020012211054563522}, {"id": 413, "seek": 285484, "start": 2854.92, "end": 2862.1200000000003, "text": " be paying attention to? Well, quite a lot. A lot of young people doing fine work.", "tokens": [50368, 312, 6229, 3202, 281, 30, 1042, 11, 1596, 257, 688, 13, 316, 688, 295, 2037, 561, 884, 2489, 589, 13, 50728], "temperature": 0.0, "avg_logprob": -0.179905219156234, "compression_ratio": 1.4096385542168675, "no_speech_prob": 0.004395177587866783}, {"id": 414, "seek": 285484, "start": 2863.0, "end": 2868.6000000000004, "text": " In fact, I work with a, closely with a small research group", "tokens": [50772, 682, 1186, 11, 286, 589, 365, 257, 11, 8185, 365, 257, 1359, 2132, 1594, 51052], "temperature": 0.0, "avg_logprob": -0.179905219156234, "compression_ratio": 1.4096385542168675, "no_speech_prob": 0.004395177587866783}, {"id": 415, "seek": 285484, "start": 2870.92, "end": 2878.52, "text": " by now, spread all over the world. We meet virtually from Japan and Holland and other places", "tokens": [51168, 538, 586, 11, 3974, 439, 670, 264, 1002, 13, 492, 1677, 14103, 490, 3367, 293, 27201, 293, 661, 3190, 51548], "temperature": 0.0, "avg_logprob": -0.179905219156234, "compression_ratio": 1.4096385542168675, "no_speech_prob": 0.004395177587866783}, {"id": 416, "seek": 287852, "start": 2878.52, "end": 2882.2, "text": " regularly working on the kinds of problems I was talking about.", "tokens": [50364, 11672, 1364, 322, 264, 3685, 295, 2740, 286, 390, 1417, 466, 13, 50548], "temperature": 0.0, "avg_logprob": -0.12661448392001065, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.009549968875944614}, {"id": 417, "seek": 287852, "start": 2883.64, "end": 2887.96, "text": " But right now, I should say it's a pretty special interest. Most linguists aren't", "tokens": [50620, 583, 558, 586, 11, 286, 820, 584, 309, 311, 257, 1238, 2121, 1179, 13, 4534, 21766, 1751, 3212, 380, 50836], "temperature": 0.0, "avg_logprob": -0.12661448392001065, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.009549968875944614}, {"id": 418, "seek": 287852, "start": 2887.96, "end": 2895.88, "text": " interested in these foundational questions. But I think that's happened to be my interest.", "tokens": [50836, 3102, 294, 613, 32195, 1651, 13, 583, 286, 519, 300, 311, 2011, 281, 312, 452, 1179, 13, 51232], "temperature": 0.0, "avg_logprob": -0.12661448392001065, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.009549968875944614}, {"id": 419, "seek": 287852, "start": 2895.88, "end": 2904.36, "text": " I want to see if we can show the, ultimately try to show that language is essentially a", "tokens": [51232, 286, 528, 281, 536, 498, 321, 393, 855, 264, 11, 6284, 853, 281, 855, 300, 2856, 307, 4476, 257, 51656], "temperature": 0.0, "avg_logprob": -0.12661448392001065, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.009549968875944614}, {"id": 420, "seek": 290436, "start": 2904.36, "end": 2913.96, "text": " natural object. I mean, there was an interesting paper written about the time that I started", "tokens": [50364, 3303, 2657, 13, 286, 914, 11, 456, 390, 364, 1880, 3035, 3720, 466, 264, 565, 300, 286, 1409, 50844], "temperature": 0.0, "avg_logprob": -0.20542563498020172, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.0030737139750272036}, {"id": 421, "seek": 290436, "start": 2913.96, "end": 2922.84, "text": " working on this by Albert Einstein in 1950. He had an article in Scientific American, which", "tokens": [50844, 1364, 322, 341, 538, 20812, 23486, 294, 18141, 13, 634, 632, 364, 7222, 294, 47437, 2665, 11, 597, 51288], "temperature": 0.0, "avg_logprob": -0.20542563498020172, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.0030737139750272036}, {"id": 422, "seek": 290436, "start": 2923.56, "end": 2929.32, "text": " I read, but didn't appreciate at the time, began to appreciate later, in which he talked", "tokens": [51324, 286, 1401, 11, 457, 994, 380, 4449, 412, 264, 565, 11, 4283, 281, 4449, 1780, 11, 294, 597, 415, 2825, 51612], "temperature": 0.0, "avg_logprob": -0.20542563498020172, "compression_ratio": 1.452127659574468, "no_speech_prob": 0.0030737139750272036}, {"id": 423, "seek": 292932, "start": 2929.32, "end": 2936.44, "text": " about what he called a miracle creed. He has an interesting history. It goes back to Galileo.", "tokens": [50364, 466, 437, 415, 1219, 257, 14660, 1197, 292, 13, 634, 575, 364, 1880, 2503, 13, 467, 1709, 646, 281, 46576, 78, 13, 50720], "temperature": 0.0, "avg_logprob": -0.11755764948857295, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.0033229365944862366}, {"id": 424, "seek": 292932, "start": 2937.32, "end": 2947.0800000000004, "text": " Galileo had a maxim saying, nature is simple. It doesn't do things in a complicated way if it", "tokens": [50764, 46576, 78, 632, 257, 5138, 1566, 11, 3687, 307, 2199, 13, 467, 1177, 380, 360, 721, 294, 257, 6179, 636, 498, 309, 51252], "temperature": 0.0, "avg_logprob": -0.11755764948857295, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.0033229365944862366}, {"id": 425, "seek": 292932, "start": 2947.0800000000004, "end": 2955.7200000000003, "text": " could do them in a simple way. Galileo's maxim couldn't prove it. But they said, I think that's", "tokens": [51252, 727, 360, 552, 294, 257, 2199, 636, 13, 46576, 78, 311, 5138, 2809, 380, 7081, 309, 13, 583, 436, 848, 11, 286, 519, 300, 311, 51684], "temperature": 0.0, "avg_logprob": -0.11755764948857295, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.0033229365944862366}, {"id": 426, "seek": 295572, "start": 2955.72, "end": 2962.8399999999997, "text": " the way it is. That's the task of the scientist to prove it. Well, over the centuries, it's been", "tokens": [50364, 264, 636, 309, 307, 13, 663, 311, 264, 5633, 295, 264, 12662, 281, 7081, 309, 13, 1042, 11, 670, 264, 13926, 11, 309, 311, 668, 50720], "temperature": 0.0, "avg_logprob": -0.08258485219564783, "compression_ratio": 1.4646464646464648, "no_speech_prob": 0.0013665665173903108}, {"id": 427, "seek": 295572, "start": 2962.8399999999997, "end": 2970.8399999999997, "text": " substantiated case after case. It shows up in Leibniz's principle of optimality. But by then,", "tokens": [50720, 4594, 11520, 770, 1389, 934, 1389, 13, 467, 3110, 493, 294, 1456, 897, 77, 590, 311, 8665, 295, 5028, 1860, 13, 583, 538, 550, 11, 51120], "temperature": 0.0, "avg_logprob": -0.08258485219564783, "compression_ratio": 1.4646464646464648, "no_speech_prob": 0.0013665665173903108}, {"id": 428, "seek": 295572, "start": 2970.8399999999997, "end": 2978.7599999999998, "text": " there was a lot of evidence for it. By now, it's just a norm for science. It's what Einstein called", "tokens": [51120, 456, 390, 257, 688, 295, 4467, 337, 309, 13, 3146, 586, 11, 309, 311, 445, 257, 2026, 337, 3497, 13, 467, 311, 437, 23486, 1219, 51516], "temperature": 0.0, "avg_logprob": -0.08258485219564783, "compression_ratio": 1.4646464646464648, "no_speech_prob": 0.0013665665173903108}, {"id": 429, "seek": 297876, "start": 2978.76, "end": 2988.6000000000004, "text": " the miracle creed. Nature is simple. Our task is to show it. It says, improve it. Skeptic can say,", "tokens": [50364, 264, 14660, 1197, 292, 13, 20159, 307, 2199, 13, 2621, 5633, 307, 281, 855, 309, 13, 467, 1619, 11, 3470, 309, 13, 32344, 32307, 393, 584, 11, 50856], "temperature": 0.0, "avg_logprob": -0.14713999736739927, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.003323607612401247}, {"id": 430, "seek": 297876, "start": 2988.6000000000004, "end": 2996.92, "text": " I don't believe it. Okay. But that's the way science works. Well, this one's worked the same way for", "tokens": [50856, 286, 500, 380, 1697, 309, 13, 1033, 13, 583, 300, 311, 264, 636, 3497, 1985, 13, 1042, 11, 341, 472, 311, 2732, 264, 912, 636, 337, 51272], "temperature": 0.0, "avg_logprob": -0.14713999736739927, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.003323607612401247}, {"id": 431, "seek": 297876, "start": 2996.92, "end": 3004.2000000000003, "text": " language. But you couldn't have proposed that 50 years ago, 20 years ago. I think now you can", "tokens": [51272, 2856, 13, 583, 291, 2809, 380, 362, 10348, 300, 2625, 924, 2057, 11, 945, 924, 2057, 13, 286, 519, 586, 291, 393, 51636], "temperature": 0.0, "avg_logprob": -0.14713999736739927, "compression_ratio": 1.4723618090452262, "no_speech_prob": 0.003323607612401247}, {"id": 432, "seek": 300420, "start": 3004.52, "end": 3013.0, "text": " believe that maybe language is just basically a perfect computational system at its base.", "tokens": [50380, 1697, 300, 1310, 2856, 307, 445, 1936, 257, 2176, 28270, 1185, 412, 1080, 3096, 13, 50804], "temperature": 0.0, "avg_logprob": -0.13586107889811197, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.0030738450586795807}, {"id": 433, "seek": 300420, "start": 3014.12, "end": 3020.68, "text": " You look at the phenomena, it doesn't look like that. But the same was true of biology. Go back to", "tokens": [50860, 509, 574, 412, 264, 22004, 11, 309, 1177, 380, 574, 411, 300, 13, 583, 264, 912, 390, 2074, 295, 14956, 13, 1037, 646, 281, 51188], "temperature": 0.0, "avg_logprob": -0.13586107889811197, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.0030738450586795807}, {"id": 434, "seek": 300420, "start": 3020.68, "end": 3032.2, "text": " the 1950s, 1960s, biologists assumed that organisms could vary so widely that each one has to be", "tokens": [51188, 264, 18141, 82, 11, 16157, 82, 11, 3228, 12256, 15895, 300, 22110, 727, 10559, 370, 13371, 300, 1184, 472, 575, 281, 312, 51764], "temperature": 0.0, "avg_logprob": -0.13586107889811197, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.0030738450586795807}, {"id": 435, "seek": 303220, "start": 3032.2, "end": 3039.3999999999996, "text": " studied on its own without bias. By now, that's all forgotten. It's recognized that there,", "tokens": [50364, 9454, 322, 1080, 1065, 1553, 12577, 13, 3146, 586, 11, 300, 311, 439, 11832, 13, 467, 311, 9823, 300, 456, 11, 50724], "temperature": 0.0, "avg_logprob": -0.13858500648947322, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0005111200152896345}, {"id": 436, "seek": 303220, "start": 3040.04, "end": 3046.3599999999997, "text": " since the Cambrian explosion, there's virtually no variation in the kinds of organisms,", "tokens": [50756, 1670, 264, 29287, 5501, 15673, 11, 456, 311, 14103, 572, 12990, 294, 264, 3685, 295, 22110, 11, 51072], "temperature": 0.0, "avg_logprob": -0.13858500648947322, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0005111200152896345}, {"id": 437, "seek": 303220, "start": 3047.16, "end": 3055.7999999999997, "text": " fundamentally all the same. Deep homologies, and so on. So even been proposed that there's a universal", "tokens": [51112, 17879, 439, 264, 912, 13, 14895, 3655, 6204, 11, 293, 370, 322, 13, 407, 754, 668, 10348, 300, 456, 311, 257, 11455, 51544], "temperature": 0.0, "avg_logprob": -0.13858500648947322, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0005111200152896345}, {"id": 438, "seek": 305580, "start": 3055.8, "end": 3063.88, "text": " genome, not totally accepted, but not considered ridiculous. Well, I think we're in the same", "tokens": [50364, 21953, 11, 406, 3879, 9035, 11, 457, 406, 4888, 11083, 13, 1042, 11, 286, 519, 321, 434, 294, 264, 912, 50768], "temperature": 0.0, "avg_logprob": -0.11051852938155053, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0014323153300210834}, {"id": 439, "seek": 305580, "start": 3063.88, "end": 3069.6400000000003, "text": " direction as the study of language. Now, let me say again, there's not many linguists interested in", "tokens": [50768, 3513, 382, 264, 2979, 295, 2856, 13, 823, 11, 718, 385, 584, 797, 11, 456, 311, 406, 867, 21766, 1751, 3102, 294, 51056], "temperature": 0.0, "avg_logprob": -0.11051852938155053, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0014323153300210834}, {"id": 440, "seek": 305580, "start": 3069.6400000000003, "end": 3077.0, "text": " this. Most linguists, like most biologists, are studying particular things, which is fine. You", "tokens": [51056, 341, 13, 4534, 21766, 1751, 11, 411, 881, 3228, 12256, 11, 366, 7601, 1729, 721, 11, 597, 307, 2489, 13, 509, 51424], "temperature": 0.0, "avg_logprob": -0.11051852938155053, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.0014323153300210834}, {"id": 441, "seek": 307700, "start": 3077.0, "end": 3087.24, "text": " learn a lot that way. But I think it is possible now to formulate a plausible thesis that language is a", "tokens": [50364, 1466, 257, 688, 300, 636, 13, 583, 286, 519, 309, 307, 1944, 586, 281, 47881, 257, 39925, 22288, 300, 2856, 307, 257, 50876], "temperature": 0.0, "avg_logprob": -0.11615488108466654, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.01242864690721035}, {"id": 442, "seek": 307700, "start": 3087.96, "end": 3094.04, "text": " natural object like others, which evolved in such a way as to have perfect design,", "tokens": [50912, 3303, 2657, 411, 2357, 11, 597, 14178, 294, 1270, 257, 636, 382, 281, 362, 2176, 1715, 11, 51216], "temperature": 0.0, "avg_logprob": -0.11615488108466654, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.01242864690721035}, {"id": 443, "seek": 307700, "start": 3094.84, "end": 3100.52, "text": " but to be highly dysfunctional. Because that's true of natural objects, generally. It's part of", "tokens": [51256, 457, 281, 312, 5405, 32002, 304, 13, 1436, 300, 311, 2074, 295, 3303, 6565, 11, 5101, 13, 467, 311, 644, 295, 51540], "temperature": 0.0, "avg_logprob": -0.11615488108466654, "compression_ratio": 1.5161290322580645, "no_speech_prob": 0.01242864690721035}, {"id": 444, "seek": 310052, "start": 3100.52, "end": 3109.4, "text": " the nature of evolution, which doesn't take into account possible functions. I mean, the last stage", "tokens": [50364, 264, 3687, 295, 9303, 11, 597, 1177, 380, 747, 666, 2696, 1944, 6828, 13, 286, 914, 11, 264, 1036, 3233, 50808], "temperature": 0.0, "avg_logprob": -0.161489876833829, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.004904346540570259}, {"id": 445, "seek": 310052, "start": 3109.4, "end": 3117.56, "text": " of evolution, the reproductive success that does take function into account, natural selection,", "tokens": [50808, 295, 9303, 11, 264, 33569, 2245, 300, 775, 747, 2445, 666, 2696, 11, 3303, 9450, 11, 51216], "temperature": 0.0, "avg_logprob": -0.161489876833829, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.004904346540570259}, {"id": 446, "seek": 310052, "start": 3118.52, "end": 3125.56, "text": " that's a fringe of evolution. It's just the peripheral fringe, very important, not denigrated,", "tokens": [51264, 300, 311, 257, 38764, 295, 9303, 13, 467, 311, 445, 264, 40235, 38764, 11, 588, 1021, 11, 406, 1441, 328, 5468, 11, 51616], "temperature": 0.0, "avg_logprob": -0.161489876833829, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.004904346540570259}, {"id": 447, "seek": 312556, "start": 3125.56, "end": 3133.72, "text": " but it's the basic part of evolution is constructing the optimal system that meets", "tokens": [50364, 457, 309, 311, 264, 3875, 644, 295, 9303, 307, 39969, 264, 16252, 1185, 300, 13961, 50772], "temperature": 0.0, "avg_logprob": -0.1252880173344766, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00024145387578755617}, {"id": 448, "seek": 312556, "start": 3133.72, "end": 3140.2799999999997, "text": " the physical conditions established by some disruption in the system. That's the core of", "tokens": [50772, 264, 4001, 4487, 7545, 538, 512, 28751, 294, 264, 1185, 13, 663, 311, 264, 4965, 295, 51100], "temperature": 0.0, "avg_logprob": -0.1252880173344766, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00024145387578755617}, {"id": 449, "seek": 312556, "start": 3140.2799999999997, "end": 3150.84, "text": " evolution. That's what Turing studied. Darcy Thompson, others by now, I think it's understood.", "tokens": [51100, 9303, 13, 663, 311, 437, 314, 1345, 9454, 13, 7803, 1344, 23460, 11, 2357, 538, 586, 11, 286, 519, 309, 311, 7320, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1252880173344766, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00024145387578755617}, {"id": 450, "seek": 315084, "start": 3150.84, "end": 3157.1600000000003, "text": " And I think maybe the study of this particular biology after a language is a biological object.", "tokens": [50364, 400, 286, 519, 1310, 264, 2979, 295, 341, 1729, 14956, 934, 257, 2856, 307, 257, 13910, 2657, 13, 50680], "temperature": 0.0, "avg_logprob": -0.14875436865765115, "compression_ratio": 1.43, "no_speech_prob": 0.00036251204437576234}, {"id": 451, "seek": 315084, "start": 3157.8, "end": 3164.44, "text": " So why should it be different? Let's see if we can show it. There's been a lot of talk in the news", "tokens": [50712, 407, 983, 820, 309, 312, 819, 30, 961, 311, 536, 498, 321, 393, 855, 309, 13, 821, 311, 668, 257, 688, 295, 751, 294, 264, 2583, 51044], "temperature": 0.0, "avg_logprob": -0.14875436865765115, "compression_ratio": 1.43, "no_speech_prob": 0.00036251204437576234}, {"id": 452, "seek": 315084, "start": 3164.44, "end": 3175.7200000000003, "text": " recently about extraterrestrial craft having been found by the government. I don't put much", "tokens": [51044, 3938, 466, 43324, 34539, 8448, 1419, 668, 1352, 538, 264, 2463, 13, 286, 500, 380, 829, 709, 51608], "temperature": 0.0, "avg_logprob": -0.14875436865765115, "compression_ratio": 1.43, "no_speech_prob": 0.00036251204437576234}, {"id": 453, "seek": 317572, "start": 3175.72, "end": 3184.9199999999996, "text": " talk in it, but imagine that there is extraterrestrial life, advanced forms of life. Do you think that", "tokens": [50364, 751, 294, 309, 11, 457, 3811, 300, 456, 307, 43324, 34539, 993, 11, 7339, 6422, 295, 993, 13, 1144, 291, 519, 300, 50824], "temperature": 0.0, "avg_logprob": -0.1093268972454649, "compression_ratio": 1.5572916666666667, "no_speech_prob": 0.012617354281246662}, {"id": 454, "seek": 317572, "start": 3184.9199999999996, "end": 3195.7999999999997, "text": " their language would have developed the same way if it's based on these simple principles? Or is it", "tokens": [50824, 641, 2856, 576, 362, 4743, 264, 912, 636, 498, 309, 311, 2361, 322, 613, 2199, 9156, 30, 1610, 307, 309, 51368], "temperature": 0.0, "avg_logprob": -0.1093268972454649, "compression_ratio": 1.5572916666666667, "no_speech_prob": 0.012617354281246662}, {"id": 455, "seek": 317572, "start": 3196.6, "end": 3204.8399999999997, "text": " could there be other forms of language in other biological organisms that would be quote unquote", "tokens": [51408, 727, 456, 312, 661, 6422, 295, 2856, 294, 661, 13910, 22110, 300, 576, 312, 6513, 37557, 51820], "temperature": 0.0, "avg_logprob": -0.1093268972454649, "compression_ratio": 1.5572916666666667, "no_speech_prob": 0.012617354281246662}, {"id": 456, "seek": 320484, "start": 3204.84, "end": 3213.7200000000003, "text": " impossible in the human context? Back around the 1960s, I guess, Minsky", "tokens": [50364, 6243, 294, 264, 1952, 4319, 30, 5833, 926, 264, 16157, 82, 11, 286, 2041, 11, 376, 44153, 50808], "temperature": 0.0, "avg_logprob": -0.21636393666267395, "compression_ratio": 1.375, "no_speech_prob": 0.0005191377131268382}, {"id": 457, "seek": 320484, "start": 3215.96, "end": 3222.6800000000003, "text": " studied with one of his students, Daniel Belbrom, studied the simplest Turing machines,", "tokens": [50920, 9454, 365, 472, 295, 702, 1731, 11, 8033, 6248, 1443, 298, 11, 9454, 264, 22811, 314, 1345, 8379, 11, 51256], "temperature": 0.0, "avg_logprob": -0.21636393666267395, "compression_ratio": 1.375, "no_speech_prob": 0.0005191377131268382}, {"id": 458, "seek": 320484, "start": 3223.56, "end": 3232.04, "text": " few estates, fewest symbols, and asked what happens if you just let them run free?", "tokens": [51300, 1326, 871, 1024, 11, 1326, 377, 16944, 11, 293, 2351, 437, 2314, 498, 291, 445, 718, 552, 1190, 1737, 30, 51724], "temperature": 0.0, "avg_logprob": -0.21636393666267395, "compression_ratio": 1.375, "no_speech_prob": 0.0005191377131268382}, {"id": 459, "seek": 323204, "start": 3233.0, "end": 3242.68, "text": " Well, it turned out that most of them crash, either get into endless loops or just crash", "tokens": [50412, 1042, 11, 309, 3574, 484, 300, 881, 295, 552, 8252, 11, 2139, 483, 666, 16144, 16121, 420, 445, 8252, 50896], "temperature": 0.0, "avg_logprob": -0.1758774439493815, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0004108079883735627}, {"id": 460, "seek": 323204, "start": 3243.48, "end": 3249.08, "text": " don't proceed. But the ones that didn't crash all produced the successor function.", "tokens": [50936, 500, 380, 8991, 13, 583, 264, 2306, 300, 994, 380, 8252, 439, 7126, 264, 31864, 2445, 13, 51216], "temperature": 0.0, "avg_logprob": -0.1758774439493815, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0004108079883735627}, {"id": 461, "seek": 323204, "start": 3250.68, "end": 3258.2799999999997, "text": " So he suggested what we're going to find if any kind of intelligence develops is", "tokens": [51296, 407, 415, 10945, 437, 321, 434, 516, 281, 915, 498, 604, 733, 295, 7599, 25453, 307, 51676], "temperature": 0.0, "avg_logprob": -0.1758774439493815, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0004108079883735627}, {"id": 462, "seek": 325828, "start": 3258.84, "end": 3265.0, "text": " it'll be based on the successor function. And if we want to try to communicate with some", "tokens": [50392, 309, 603, 312, 2361, 322, 264, 31864, 2445, 13, 400, 498, 321, 528, 281, 853, 281, 7890, 365, 512, 50700], "temperature": 0.0, "avg_logprob": -0.11080959680918101, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.001597447320818901}, {"id": 463, "seek": 325828, "start": 3265.96, "end": 3271.1600000000003, "text": " extraterrestrial intelligence, we should first see if they have the successor function", "tokens": [50748, 43324, 34539, 7599, 11, 321, 820, 700, 536, 498, 436, 362, 264, 31864, 2445, 51008], "temperature": 0.0, "avg_logprob": -0.11080959680918101, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.001597447320818901}, {"id": 464, "seek": 325828, "start": 3272.2000000000003, "end": 3276.6000000000004, "text": " and then maybe build up from there. Well, turns out the successor", "tokens": [51060, 293, 550, 1310, 1322, 493, 490, 456, 13, 1042, 11, 4523, 484, 264, 31864, 51280], "temperature": 0.0, "avg_logprob": -0.11080959680918101, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.001597447320818901}, {"id": 465, "seek": 325828, "start": 3278.2000000000003, "end": 3287.48, "text": " happens to be what you get from the simplest possible language. The language is one symbol", "tokens": [51360, 2314, 281, 312, 437, 291, 483, 490, 264, 22811, 1944, 2856, 13, 440, 2856, 307, 472, 5986, 51824], "temperature": 0.0, "avg_logprob": -0.11080959680918101, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.001597447320818901}, {"id": 466, "seek": 328748, "start": 3287.48, "end": 3293.0, "text": " and the simplest form of binary set formation basically gives it a successor function.", "tokens": [50364, 293, 264, 22811, 1254, 295, 17434, 992, 11723, 1936, 2709, 309, 257, 31864, 2445, 13, 50640], "temperature": 0.0, "avg_logprob": -0.12038050258860869, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0002652077528182417}, {"id": 467, "seek": 328748, "start": 3293.88, "end": 3299.48, "text": " Add a little bit more to it, you get something like arithmetic. Add a little bit more to it,", "tokens": [50684, 5349, 257, 707, 857, 544, 281, 309, 11, 291, 483, 746, 411, 42973, 13, 5349, 257, 707, 857, 544, 281, 309, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12038050258860869, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0002652077528182417}, {"id": 468, "seek": 328748, "start": 3299.48, "end": 3307.88, "text": " you get something like the poor properties of language. So it's conceivable that if there is any", "tokens": [50964, 291, 483, 746, 411, 264, 4716, 7221, 295, 2856, 13, 407, 309, 311, 10413, 34376, 300, 498, 456, 307, 604, 51384], "temperature": 0.0, "avg_logprob": -0.12038050258860869, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0002652077528182417}, {"id": 469, "seek": 328748, "start": 3308.52, "end": 3314.92, "text": " extraterrestrial intelligence, it would have pursued the same course. Where it goes from there,", "tokens": [51416, 43324, 34539, 7599, 11, 309, 576, 362, 34893, 264, 912, 1164, 13, 2305, 309, 1709, 490, 456, 11, 51736], "temperature": 0.0, "avg_logprob": -0.12038050258860869, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0002652077528182417}, {"id": 470, "seek": 331492, "start": 3314.92, "end": 3322.92, "text": " we don't know enough to say. And back to the idea that there is no super natural realm,", "tokens": [50364, 321, 500, 380, 458, 1547, 281, 584, 13, 400, 646, 281, 264, 1558, 300, 456, 307, 572, 1687, 3303, 15355, 11, 50764], "temperature": 0.0, "avg_logprob": -0.12717843850453694, "compression_ratio": 1.5, "no_speech_prob": 0.00048736672033555806}, {"id": 471, "seek": 331492, "start": 3322.92, "end": 3331.2400000000002, "text": " that the consciousness is an emergent property from the physical attributes of the brain.", "tokens": [50764, 300, 264, 10081, 307, 364, 4345, 6930, 4707, 490, 264, 4001, 17212, 295, 264, 3567, 13, 51180], "temperature": 0.0, "avg_logprob": -0.12717843850453694, "compression_ratio": 1.5, "no_speech_prob": 0.00048736672033555806}, {"id": 472, "seek": 331492, "start": 3333.88, "end": 3342.84, "text": " Do you believe in a higher intelligence behind the creation or continuation of the universe?", "tokens": [51312, 1144, 291, 1697, 294, 257, 2946, 7599, 2261, 264, 8016, 420, 29357, 295, 264, 6445, 30, 51760], "temperature": 0.0, "avg_logprob": -0.12717843850453694, "compression_ratio": 1.5, "no_speech_prob": 0.00048736672033555806}, {"id": 473, "seek": 334492, "start": 3345.64, "end": 3355.32, "text": " I don't see any point in vacuous hypotheses. If you want to believe it okay, it has no consequences.", "tokens": [50400, 286, 500, 380, 536, 604, 935, 294, 2842, 12549, 49969, 13, 759, 291, 528, 281, 1697, 309, 1392, 11, 309, 575, 572, 10098, 13, 50884], "temperature": 0.0, "avg_logprob": -0.15176941691965296, "compression_ratio": 1.5508982035928143, "no_speech_prob": 0.0015003711450845003}, {"id": 474, "seek": 334492, "start": 3357.88, "end": 3363.7200000000003, "text": " But do you believe it? No, I don't see any point in believing things for", "tokens": [51012, 583, 360, 291, 1697, 309, 30, 883, 11, 286, 500, 380, 536, 604, 935, 294, 16594, 721, 337, 51304], "temperature": 0.0, "avg_logprob": -0.15176941691965296, "compression_ratio": 1.5508982035928143, "no_speech_prob": 0.0015003711450845003}, {"id": 475, "seek": 334492, "start": 3365.16, "end": 3371.56, "text": " which there's no evidence and do no work. And another thing I've always wanted to ask", "tokens": [51376, 597, 456, 311, 572, 4467, 293, 360, 572, 589, 13, 400, 1071, 551, 286, 600, 1009, 1415, 281, 1029, 51696], "temperature": 0.0, "avg_logprob": -0.15176941691965296, "compression_ratio": 1.5508982035928143, "no_speech_prob": 0.0015003711450845003}, {"id": 476, "seek": 337156, "start": 3372.2, "end": 3380.84, "text": " someone like you, clearly your intelligence surpasses most peoples.", "tokens": [50396, 1580, 411, 291, 11, 4448, 428, 7599, 27650, 279, 881, 16915, 13, 50828], "temperature": 0.0, "avg_logprob": -0.15061283111572266, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00505608506500721}, {"id": 477, "seek": 337156, "start": 3381.96, "end": 3387.56, "text": " I don't think so. Well, that's a good, that's interesting that you would say that. You think", "tokens": [50884, 286, 500, 380, 519, 370, 13, 1042, 11, 300, 311, 257, 665, 11, 300, 311, 1880, 300, 291, 576, 584, 300, 13, 509, 519, 51164], "temperature": 0.0, "avg_logprob": -0.15061283111572266, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00505608506500721}, {"id": 478, "seek": 337156, "start": 3387.56, "end": 3395.16, "text": " it's just a matter of applying yourself to study throughout your career.", "tokens": [51164, 309, 311, 445, 257, 1871, 295, 9275, 1803, 281, 2979, 3710, 428, 3988, 13, 51544], "temperature": 0.0, "avg_logprob": -0.15061283111572266, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.00505608506500721}, {"id": 479, "seek": 339516, "start": 3395.16, "end": 3405.8799999999997, "text": " I have certain talents, I know, like not believing things just cause people believe them.", "tokens": [50364, 286, 362, 1629, 19933, 11, 286, 458, 11, 411, 406, 16594, 721, 445, 3082, 561, 1697, 552, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1926884100987361, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.0018099123844876885}, {"id": 480, "seek": 339516, "start": 3408.12, "end": 3415.16, "text": " And keeping an open mind and looking for arguments and evidence, not", "tokens": [51012, 400, 5145, 364, 1269, 1575, 293, 1237, 337, 12869, 293, 4467, 11, 406, 51364], "temperature": 0.0, "avg_logprob": -0.1926884100987361, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.0018099123844876885}, {"id": 481, "seek": 339516, "start": 3416.3599999999997, "end": 3421.16, "text": " anything we've been talking about when meaningless questions are proposed, like", "tokens": [51424, 1340, 321, 600, 668, 1417, 466, 562, 33232, 1651, 366, 10348, 11, 411, 51664], "temperature": 0.0, "avg_logprob": -0.1926884100987361, "compression_ratio": 1.4691358024691359, "no_speech_prob": 0.0018099123844876885}, {"id": 482, "seek": 342116, "start": 3421.16, "end": 3429.56, "text": " our other organism, sentient or the submarine swim, I say let's discard them and look at", "tokens": [50364, 527, 661, 24128, 11, 2279, 1196, 420, 264, 33995, 7110, 11, 286, 584, 718, 311, 31597, 552, 293, 574, 412, 50784], "temperature": 0.0, "avg_logprob": -0.20549396846605383, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.002755579072982073}, {"id": 483, "seek": 342116, "start": 3429.56, "end": 3439.24, "text": " meaningful questions. If you just pursue common sense like that, I think you can make some progress.", "tokens": [50784, 10995, 1651, 13, 759, 291, 445, 12392, 2689, 2020, 411, 300, 11, 286, 519, 291, 393, 652, 512, 4205, 13, 51268], "temperature": 0.0, "avg_logprob": -0.20549396846605383, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.002755579072982073}, {"id": 484, "seek": 342116, "start": 3439.24, "end": 3445.96, "text": " Same on the questions we're talking about language. If you think it through, there's every reason why", "tokens": [51268, 10635, 322, 264, 1651, 321, 434, 1417, 466, 2856, 13, 759, 291, 519, 309, 807, 11, 456, 311, 633, 1778, 983, 51604], "temperature": 0.0, "avg_logprob": -0.20549396846605383, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.002755579072982073}, {"id": 485, "seek": 344596, "start": 3446.6, "end": 3452.92, "text": " the organic object language should be an object. If so, it should follow the", "tokens": [50396, 264, 10220, 2657, 2856, 820, 312, 364, 2657, 13, 759, 370, 11, 309, 820, 1524, 264, 50712], "temperature": 0.0, "avg_logprob": -0.18043600229116585, "compression_ratio": 1.4480874316939891, "no_speech_prob": 0.014271857216954231}, {"id": 486, "seek": 344596, "start": 3453.48, "end": 3460.84, "text": " general principles of evolution, which satisfy what Einstein called the miracle creed. So why", "tokens": [50740, 2674, 9156, 295, 9303, 11, 597, 19319, 437, 23486, 1219, 264, 14660, 1197, 292, 13, 407, 983, 51108], "temperature": 0.0, "avg_logprob": -0.18043600229116585, "compression_ratio": 1.4480874316939891, "no_speech_prob": 0.014271857216954231}, {"id": 487, "seek": 344596, "start": 3460.84, "end": 3468.68, "text": " shouldn't language, so let's pursue that CFR we can do. I think that's just common sense. Many", "tokens": [51108, 4659, 380, 2856, 11, 370, 718, 311, 12392, 300, 21792, 49, 321, 393, 360, 13, 286, 519, 300, 311, 445, 2689, 2020, 13, 5126, 51500], "temperature": 0.0, "avg_logprob": -0.18043600229116585, "compression_ratio": 1.4480874316939891, "no_speech_prob": 0.014271857216954231}, {"id": 488, "seek": 346868, "start": 3468.68, "end": 3475.96, "text": " people think it's superior intelligence. I don't think so. That's it for this episode. I want to", "tokens": [50364, 561, 519, 309, 311, 13028, 7599, 13, 286, 500, 380, 519, 370, 13, 663, 311, 309, 337, 341, 3500, 13, 286, 528, 281, 50728], "temperature": 0.0, "avg_logprob": -0.14683682085519814, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.037300363183021545}, {"id": 489, "seek": 346868, "start": 3475.96, "end": 3482.52, "text": " thank Noam for his time. If you'd like a transcript of this conversation, you can find one on our", "tokens": [50728, 1309, 883, 335, 337, 702, 565, 13, 759, 291, 1116, 411, 257, 24444, 295, 341, 3761, 11, 291, 393, 915, 472, 322, 527, 51056], "temperature": 0.0, "avg_logprob": -0.14683682085519814, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.037300363183021545}, {"id": 490, "seek": 346868, "start": 3482.52, "end": 3496.04, "text": " website, I on AI, that's EYE-ON.AI. In the meantime, remember, the singularity may not be near,", "tokens": [51056, 3144, 11, 286, 322, 7318, 11, 300, 311, 462, 18881, 12, 1928, 13, 48698, 13, 682, 264, 14991, 11, 1604, 11, 264, 20010, 507, 815, 406, 312, 2651, 11, 51732], "temperature": 0.0, "avg_logprob": -0.14683682085519814, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.037300363183021545}, {"id": 491, "seek": 349604, "start": 3496.04, "end": 3506.7599999999998, "text": " but AI is about to change your world. So pay attention.", "tokens": [50396, 457, 7318, 307, 466, 281, 1319, 428, 1002, 13, 407, 1689, 3202, 13, 50900], "temperature": 0.0, "avg_logprob": -0.2793288826942444, "compression_ratio": 0.9016393442622951, "no_speech_prob": 0.04018229991197586}], "language": "en"}