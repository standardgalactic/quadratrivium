{"text": " There isn't a science around that isn't profoundly influenced by the availability of massive computing power and just greater regular computing power. It's the story of our age. It's not just the story of AI. The idea is to leverage computation to make useful things and understand the mind. These all these things need a lot of computation. It's the fact that computation has become cheaper exponentially for on the order of 100 years and can be expected to continue going It looks like doubling every two years now every 18 months and that keeps happening 18 months after 18 months after 18 months and it means you double and you double and things get qualitatively different every decade and that's happened for a long time for many decades and will happen more so in the future. So we have that to look forward to. I think it's what we really should mean when we say the singularity. The singularity is that we have this exploding it's a slow explosion of computer power and that that is fundamentally changing things. Hi I'm Craig Smith and this is I on AI. In this episode I speak with Richard Sutton the father of reinforcement learning and professor at the University of Alberta. We discussed his cooperation with John Carmack on Keen a startup that vows to reach artificial general intelligence by 2030. Richard also talked about the Alberta plan his ambitious five-year research agenda focused on building embodied agents with the capability to learn and plan through interactions with their environment. Sutton provides insights into the current state of progress new algorithmic developments and trade-offs between simulated and physical environments in training and the ultimate goal of creating AGI. I hope you find the conversation as amazing as I did. So why don't you start by introducing yourself. I assume people know who you are I've had you on the podcast before but for those new listeners tell us who you are where you are and then we'll talk about the Alberta plan which I find pretty exciting. Thank you Craig I'm Richard Sutton I'm a scientist I've been studying artificial intelligence for like 45 years a long time and I'm up in north of the University of Alberta in Canada and I'm a professor in the computer science computing science department and also I'm a researcher at Keen Technologies and I got lots of titles and sub-rolls but basically I'm just trying to figure out how the mind works and I've tried to do it in a very broad and interdisciplinary way reading all the different thinkers on the subject and addressed from the point of view of psychology and how the brain might work as well as. Yeah I've read a number of the recent papers and I can see this thread developing and I don't know whether it's just that you're writing more and so the thoughts are are more developed in print or whether they're developing in your mind but from 2019 when you wrote the bitter lesson you talked about the idea that it's really increasing computation and the striving a lot of things a lot of progress that kind of coincided with open AI's scaling of the transformer model I talked to Ilya Sutskover and I asked him whether your essay had triggered their their interest in scaling and he said no it was coincidental but I kept first can we talk about that about how scale scaling and and the availability of computational resources and Moore's law has driven a lot of what's happened in artificial intelligence research almost more than novel algorithms well I think the first thing to be aware of is it's it's been driving things that are not just artificial intelligence it's been driving all the sciences and all the engineering developments in the world there isn't a science around that isn't profoundly influenced by the availability availability of massive computing power and just greater regular computing power it's it's it's the story of our age it's not just the story of AI it's not particularly the story of AI AI has always known that it needs computation the idea is to leverage computation to make useful things and understand the mind um yeah now it's true that those of us who are interested in connection to systems or distributed networks nowadays just call neural networks not particularly good terms so I always shudder a little bit when I use it but those of us that have been doing that have have those are doing learning I think that learning is important for intelligence these all these things need a lot of computation and so they're they are limited by the computation available at the time okay so let's let's be what is this thing what is the so Moore's law what's called Moore's law it's the fact computation is becoming more plentiful and cheaper exponentially for on the order of a hundred years and can be expected to continue going that way so exponentially looks like doubling every two years now each every 18 months and that keeps happening 18 months after 18 months after 18 months and it means you double and you double and things get qualitatively different uh every decade and that's happened for a long time for many decades and will happen it's more so in the future so we have that to look forward to that will continue having a tremendous influence on everything that's done on the other hand it's just normal it's just what you would expect and that those of who worked on AI for for a long time have just you know expect and plan for and um now it's coming but it's an exponential so exponentials are self-similar so that means they look the same at every point in time every every year it's you're doubling in a year and a half and so it's it's an explosion as every exponential is an explosion it's it's sort of I think it's what we really should mean when we say the singularity the singularity is that we have this exploding it's a slow explosion of computer power and that has fundamentally changed things yeah and I had a really interesting conversation almost a year ago with Aidan Gomez who was on the team that that that designed the transformer algorithm at Google and he now has a startup co-coher he's Canadian and he said an interesting thing that that he believes it could have been almost any algorithm it didn't have to be the transformer that the community got behind the transformer poured resources into it continued to scale it and it was scalable I mean that was important that it that it's a scalable architecture but that but it didn't have to be the transformer and and that made me think of you because of so transformers they the way he described it at its core it's a stock of multi-layer perceptrons with attention you scale it feed it data and it does learns to understand language or at least seems to understand language but it's got all these obvious limitations of I've been talking a lot over the last couple of years to Yamakun about world models and that to me sounded like a much more exciting direction for general intelligence because not all intelligence is is contained in language or at least most or even less so in human text and then I see you guys come along with the Alberta plan and that that that sounded even more exciting to me so how how do you so the Alberta plan you're building the ideas to build an agent ultimately an embodied agent that that has a world model or can and create a world model through interactions with its environment how is that different from Lucune's approach at a very basic level very basic level a good is that they're a very similar idea it's uh you look at the parts of his architecture and the parts of the architecture put forth in the Alberta plan they line up one one for one yeah we're trying to do the same thing we're going about it slightly different and we could talk about that but I think to just to focus on the differences might even be to distract from the big message the big message is that you have to have a goal and you have to have a model of the world and and then everything is driven by using that model to take action and to plan action at various levels of abstraction in order to to achieve the goal okay so to me this is really what intelligence is understand the world use your understanding to get to achieve to achieve your your goals I'd like to formulate the goals as as a reward and I'm super comfortable with that other people sort of grudgingly accept rewards even though it seems kind of low level but it's a it's a natural approach I think I think it's something that almost makes more sense to people who aren't steep and deep learning and to supervise learning and one thing I found interesting in in the roadmap that you've laid out for the Alberta plan you start with supervised learning and why is that is it just because it's it's easy yeah I guess we do in a sense because we want to focus on well continual learning learning continually which is sort of an obvious thing almost what learning means it has something that goes on at all times but the first steps getting continual learning with nonlinear networks is still challenging even for supervised learning and so it's natural to start at the simplest possible case which involves the fewest other factors and that's a supervised learning case yeah yeah it's funny let me just say a few words about that because there's sort of been a fight through a struggle throughout the decades between supervised learning and reinforcement learning you know there's only so much oxygen for learning methods and all the attention that's paid to supervised learning somewhat detracts from reinforcement learning so there's a there's a there's a bit of a friendly competition and supervised learning has always won the competition because supervised learning is so much more easy to put into practice and for people to use and it's sort of it's sort of less ambitious but it's really important and really those of us who do reinforcement learning or try to make whole agent architectures we are consumers of supervised learning outcomes we will use them as components of our overall architecture so we need them and we can work on them and we need to structure them for our purposes I saw one of your talks you make a distinction between AI tools and AI agents and supervised learning falls into the tool category can you sort of start and and talk about the evolution of the Alberta plan and then present to listeners what it is in in its simplest form and that'll that'll give me a structure on which to hang questions the Alberta plan is an attempt to understand intelligence as a as a primarily a learning phenomenon assists us something that comes to understand its environment and and then drives the environment to achieve goals so the first step in the Alberta plan is the structure between the agent the environment and their interaction form the interaction there's the you're not exchanging states you're exchanging observations like sensors sensors visual touch auditory it's all abstract to those particulars but it's got to be genuine observations and not state because state we don't we don't really have access to directly so that you know the principles number one principle I'm trying to remember them as I speak but number one principle is this this agent environment interaction is sacrosanct and number two is that learning or everything is is we could say continual I think we call it we say temporally uniform temporally symmetric in in the Alberta plan which means that there are no special phases where you like training and test there's just life goes on and on you get rewards or you don't get or you don't get the reward you want and you get your observations and there there is no teacher other than rewards pains and pleasures and maybe I'm not getting the four principles right but another important point is that you are going to be forming a model and so you're going to plan both trial and error learning directly from experience and learning a model and then planning with the model both these are important part of intelligence okay so those are that's the background then we outline there are 12 steps and the 12 steps really start with let's have learning that is temporally uniform let's have metal learning and metal learning maybe I should stop and on that for a moment metal learning means learning to learn not just learning one function but once you are continually learning you're learning this and you're learning that you get many many experiences learning and you can get better at learning you can use those repeated experience with repeatedly learning to make make future learning episodes more efficient so as part of that you learn representations you learn features you learn step sizes okay so continual learning and then all the algorithms and once once we add metal learning and continual learning we have to in supervised learning then we extend that to reinforcement learning which involves its own set of issues to get more interesting temporal relationships and I think like the first six steps are crafting the basic algorithms of reinforcement working through them again to be continual and meta and then we start to bring in the the challenging issues like learning off policy and learning models of the world and then planning and the just to jump to the end the last step is about AI, AI, AI's, AI intelligence augmentation where we combine computers, AI's with our own minds to make make our own minds stronger okay now one of the key steps in there was off policy learning and learning a model of the world off policy learning means you want to be able to learn about things that you're not doing or you're not because you're not doing all the way to completion so even like to recognize an object you look at the object and you say how would you you have to define that in some objective way and the best way to just do that is as a sub problem so yeah maybe maybe I'll just sort of stop there the most interesting strategy distinctive strategy by the Alberta plan is the pose is that the mind works by posing sub problems for itself and then working on them and it's it's not it's sure it's got a main problem which is to get reward but it's also has many thousands of sub problems it's also working on simultaneously and since it's not behaving it cannot behave for all thousand problems at once it has to pick one problem like perhaps the main problem and behave according to that so all the other things have to be able to learn from data that's not exactly on what they would do and this is called off policy learning and it's a key to learning to achieve auxiliary sub problems and also it's a key to efficiently learning a model of the world yeah you you have something called the horde architecture is is that where that comes in when you you break a problem down into multiple sub tasks that that you learn I was one one paper where we we worked on that idea we developed that idea the horde is the horde of sub problems each each demon in the horde which is it could be almost viewed like a single neuron in a neural network as achieving working towards a different task trying to predict a different thing or maybe trying to attain a different thing it's the view of the of the mind as decentralized there is one goal and everything is ultimately driven towards one goal but still it's a useful structure to to have different parts driving towards towards other goals how did you get together with john cormack was that primarily because you need the funding and it gives you a vehicle to raise capital oh seriously I mean you you know Jan Lacoon's got meta behind him well it's just not it's not really comparable uh john's uh john's company is great but it's still like a 20 million dollar company and uh which is which is plenty of money for what we want to do now um john and I got together because we had similar ideas about what was needed um and and also what was not needed um to get to ai or agi um yeah so I read an art newspaper article an interview that john did down in texas and uh I just could see that he was thinking about the way thinking about things the way I was even though our backgrounds were quite different you thought of intelligence you had to there's a few principles that needed to be worked out rather than so this isn't a huge program to write it's a few principles we have to figure those out um not that many maybe uh maybe 10 000 lines instead of 10 million lines of code so it's easy to get it's relatively it's still it's still it's still hard to get basic research funding in the world it's easy to get funding towards uh applications of ai large language models particularly um anyway I'm really enjoying working at keen and being able to focus on the ideas and uh it's a it's a it's a it's a calm company we um um there's a lot of thinking involved a lot of contemplation a lot there is also experiments and we're trying to get um the engineering side of it is really important uh but for me it's been really great just to be able to regroup my thoughts and think about them very carefully and push them forward but keen is is implementing the alberta plan is that right I mean that's that's uh the project well the alberta plan is a research plan it's like a five-year research plan and so research is something you don't implement research is something you conduct and and it doesn't always end up the way you want but um yeah I wouldn't say implement is the right word not yet but but the the work you're doing at keen is is informed by the alberta yeah I'm absolutely I'm working on the alberta plan uh uh and and the end goal at keen is to create the uh the embodied intelligence described by the alberta plan you don't sound very yeah very confident well a plan is just a plan and you know I think there's a good chance that it will work out as planned but you know a five-year plan you make another one after four or three years yeah so I wouldn't I wouldn't uh presume to to know how it's gonna work out but at the same time we have to make you know we have to make our bets we have to think hard about it um just knowing um you know we we may well be right but you know you your work is primarily in reinforcement learning you're you wrote the book on reinforcement learning temporal difference learning and uh lambda and all of that is is this I mean this is this seems a much more ambitious uh project is this was it the the success of the transformer scaling that that said well you know let's do that with rl let's why why are these guys uh uh you know everyone's celebrating what they're doing but but there's much more to be done no no what what you're seeing the alberta plan is is perhaps bigger than the book but this has always been the plan we've always in AI tried to understand all of the mind and reproduce it in computers and so that's an that's that is a big enormous ambition that's what it's always been so the large language models are a bit a bit disappointing in some sense I mean it's really good that people are getting excited and people are wanting to learn about it but um but it's not it's I don't envision that it's the direction um that will be most uh productive to pursue now you know who knows what I do know is it's not the most direction that's useful for me to pursue um I I'm much more interested in actions and goals and how an agent can tell what's true and what's not true all of those things are missing from large language models so uh um no I'm not they're not really what what are they what they are doing that's important is they're showing uh what you can do with uh computation and and networks um and learning that you can get enormously complex um things and you can incorporate a lot of data it just shows the power for those who needed to be shown that and and it could be uh an interface between humans and and whatever you end up creating the agents you end up creating you still need a language interface to communicate yeah but I don't I'm I doubt that what we're doing with large language models today will contribute to that oh is that right yeah I mean in other words the models that you want to build the agents you want to build would learn language uh as as part of the learning process yeah so it's like we say language language last you know language not not language first with large language models are language first we just say large language last just as Jan McCoon says we need to do you know rat level intelligence and then cat level intelligence and we have to get those figured out before we should try to make human level intelligence uh so where are you on the plan I mean you you figured out reinforcement learning you can build agents uh you there are various architectures for creating representations from from various kinds of sensory input and and at that representation level then you can plan efficiently so where in all of that are are you in your research well it's a little hard to explain non-technically but you can say some things certainly you can say that the various steps are not done entirely sequentially you you're always looking for areas of opportunity where you can make an increment of progress and those could be you know on step 10 or they could be on step three but you also I could also try to be very rough and say that we're we're at about step four now we are still doing things where we're changing the basic underlying fundamental reinforcement learning algorithms we are not done with that we need more efficient algorithms and I'm excited about some of the changes new ideas we're developing recently about how that can be done can you talk about those new ideas at all okay well one of the big things is efficient off-policy learning and the use of important sampling important sampling is where you see how likely you're to do things under your target and your behavior policies and you adjust the returns based on those the ratios of those two and for a long time I thought that was the only way to adjust the returns but now the forward correction of the returns I think can be done by by changing your expectations so like if you're expecting a good thing to happen you're expecting a good action to be taken and then a different action was taken a more exploratory action so this is a deviation from your target policy which would be more greedy and one way to take into account the deviation from the target policy is to just say oh okay now I've done something not best so I'm just going to adjust my level now you're going to expect a little a little less and there's a way there's a systematic way of doing that that's gives us a new way to handle the off-policiness of of our returns and so this gives a whole new family of algorithms so that's exciting now exciting maybe mostly for me I think maybe the most accessible direction of of of excitement of novelty is in continual right so there's I'm going to say a bunch of things and to me they're all going to have the same solution continual learning meta learning representation learning learning to learn learning how to generalize state how to construct a state representation feature finding that whole thing is is is coming and it will be a kind of it's just a new kind of a way a new kind of way of doing the learning in deep networks and I call it dynamic learning nets see a dynamic learning nets have learning at three levels whereas usually our neural networks only learn at one level they learn the level of the weights and in addition we also want to learn at the level of step sizes so all of every place you have a weight in your network you're also going to have a step size so a step size is sometimes called a learning rate it's much better to call the step size because the learning rate will be influenced by many other things so if we imagine a whole network all these weights next to each weight is a step size that is adjusted by an adaptive process that's adapted in a meta learning way a meta gradient way towards making the system learn better rather than just perform better an instantaneous moment in time learning rates or step sizes don't affect the function they don't affect some function implemented in a particular point in time they don't affect with the network does they affect what the network learns and so if you can tune the step sizes you also get learning to learn and learning to generalize well and things like that the last three the last element that we wanted to have be adaptive weights step sizes the third one is the connection pattern so who's connected to who and so this will be done by an accretive process like let's say you start with a linear unit and it learns say a value function or a policy and it does the best it can with the features available and and then it needs to induce the creation of new features because you need to learn a nonlinear function of your original signals and so you need to create new features that have become available to that linear unit and in this way you grow in a sort of organic way a system that can learn nonlinear functions and so this is just a different way of ending up with a deep network that was all learned including all the features dynamic learning that's where is the data the input data coming from well the the input data and reinforcement just comes from life from doing things seeing things right there is no labeled data set yeah maybe I should have said this from the very beginning the whole idea of I call it experiential AI is that you know what makes you data you're you you grow up as a baby and you play with things and you see things and you do things and that's the data and the trick of reinforcement learning is how do you turn that kind of data into something you can learn from and grow a mind up from so the the beauty and the limitation of supervised learning is they say well let's not worry about that for now let's assume that somehow we have a data set with labeled things and let's let's work on this sub problem that's a great idea work on a sub problem figure it out and then move on to the next thing but really we have to move on to the next thing we have to worry about how the the data set quote data set is automatically created from the the training information there isn't ever a data set data set is is is such a misleading term it suggests that it's easy to to have this thing and store this thing and curate this thing really life is full of you do things things happen and then there's one you know everything is fleeting you you don't have a record of it and it would be enormously complex and not only valuable to have a record of it the the the feeling is totally different in reinforcement learning and supervised learning and in particularly the way the way I would adjust it you know many people do reinforcement learning by creating a buffer or a record of all the experiences that have been been retained that have been occurred at least for some period of time and I think that's that's uh an appealing but but it's it's not where the action the answer is the answer is embracing the fleeting nature of data and and making most when it happens and then letting it go well that's why you want to make an embodied system so that you have all the the five senses or or more so you need you need as you say an embodied system an interactive system that that influences its its input stream its sensory stream and that you get that interaction and for a long creative time you can do this in simulation or you can do it in robotics there's still I still know what's the best way or if the best ways do both and right or maybe first one and then the other John is interested in uh having um uh learning from video and he likes his his his view of the experience is you have massive numbers of video streams like you're viewing you know 500 channels of television and then you can switch switch to look at one look at another one um uh other people in in in keen my close colleague Joseph Modial he's uh interested in robotics and he thinks the best way to get an appropriate in data stream is to actually build robotic hardware um you know it's important that the world be large and complex because the worlds we want to address are large and complex um and so you want things like video and you want large data streams um now you can use simulations to generate even video streams simulated video but inevitably those simulated worlds are really quite simple they have an underlying simplicity uh they have objects perhaps and three-dimensional straight structure maybe they're rigid objects and the vision is is is a very particular geometric form um they they are generated and they are they are made up worlds and they are generated so they're they're really the worlds are are are less complex than the agent uh their goal would be to have to spend most of the computer power working on the mind and just a little bit to just create the simulated data and and that's that's reversed the way it really is right every person is maybe has a has a complex brain but their world is much more complex not just because the world consists of all these um physics and matter but it also consists of other minds other brains and other minds out there and and what goes on in their minds matters and so the world is inherently vastly more complex than the agent and we we've reversed that when we work on simulated worlds so which is always concerning anyway those are some of the issues in the trade-offs between working with simulations or with physical worlds nonetheless you you need to develop the architecture and the algorithms before you worry about the data data stream i would think yeah but you want to develop the right algorithms and if you're working with the world it's not representative of of your target world in an important way um it can be misleading but you're right and that's what we that's what we strive to do you know i don't know if you know but i think of my own work is almost always i want to focus on some issues so i make a really simple instance of that issue like you know a five-state world and and i study the the hell out of it but i don't like try to take advantage of its smallness you know i study algorithms that are in some sense even simpler than the simple world and i i stress those algorithms and see what their abilities are so we always you know it's always part of research is we we simplify the world understand it fully just like a a physicist might you know make a simplified world with with a ball rolling down a ramp and it's it's a really simple world and you'll try to eliminate the friction and you eliminate other weird effects and just see things in their simplest form yeah have you um paid much attention to um alex kendall's work at at wave ai do you know that company it's an autonomous driving company they have a world model called gaya one um and it's it's it's similar to what yanlacoon's doing it it you know encodes representations from from video from live video and then uh plans uh based on those representations uh and and it can control a car uh from the representation space it's actually pretty remarkable so let's talk about the world model and and what what kind of world model would be appropriate for autonomous driving um so let me say some things that are mistakes they're a natural seeming but mistakes in my opinion uh the mistake would be to make like a physics model of the world or to try to make something that could simulate the world and produce the video frames you don't you don't you don't want the video frames of the future that's not the way you think um instead you think oh i could i could go to the market and maybe there would be strawberries okay you're not creating a visual uh a video you're saying you're like jumping to the market and then your strawberries could be you know different sizes and positions and and and still uh there's not a video there's an idea that will happen if you go to the market um so uh people have realized this like yon lakun used to talk about um generating video of the future and then you realize it would be blurry and and now he realizes that you need to produce outcomes of your model that are not like not at all like video streams and not like observations at all they're like um they're like constructed states um that are the outcome of the action okay so this is this is a very different from from a partial differential equation model of the world and it's so it's very different from what self-driving car companies start with self-driving car companies start with physics and geometry and uh you know things that are calibrated by human understanding engineers understanding of the world and driving but i suspect that's going to be i mean what do i know i'm not into self-driving i don't do self-driving cars but i know that that um like tesla is and elon musk is and um so their goal is to is to make some you know they they started like everyone else with engineering models but i my understanding now is that they're building uh sort of more conceptual models um that are based on the artificial neural networks okay and so rather than starting with geometry and understood things they're just getting massive amounts of data and training it to make a model we need a model that is at the level of high level consequences not at the level of low level things like pixels and video so one way you do that is you're having state features that are at a more advanced level you say oh this is a car uh rather than this is a uh a video frame and um so and then basically it's as simple as you need abstraction in both state and time abstraction in in state is like saying there will be strawberries when i get to the market and abstraction in in time is saying oh i can go to the market and then in 20 minutes i will be there probably and other things will be the same or related in natural ways so we want to be able to think about i could go to the market you also want to think oh i could pick up the coke can i could move a finger and that will have certain consequences these these all these things that we know you think uh are vastly different scales going to the market is like 20 minutes um you know taking taking a new job you know might be a year uh deciding to study a topic also might be a period of time we think and we analyze the consequences like you wanted to meet with me today and you know we arranged it we set it up it was your your planning uh took you know place over weeks and some cases months and and and we assembled the the the event of this interview by by planning all that and exchanging mess high-level messages uh it all that you know it's silly to think that that's done at the level of of of imagining videos that we might see with our eyes or our audio is signals that we might hear yeah so we need models that are abstract in time and state and um as a reinforcement learning person um there's a particular set of technologies that i naturally turn towards to do that um the prediction is based on multi-step prediction by temporal difference learning um the planning is done by uh dynamic programming essentially value iteration but where the steps the are not low-level actions but they're called options they're high-level ways of behaving with that that terminate so they're there are things like going to the market and they'll terminate when you're at the market so you know at a certain conceptual level it's clear where we want to go to me um with abstract models in time and state built options and features i don't know you we did write one paper recently put published an AI journal on the the notion of planning using uh sub-problems on the stomp progression stomp means sub-task option model and planning put all those things together and you can do the full progression from from the data stream to abstract planning and that's that's what we're trying to put together yeah yeah and i i sort of misspoke talking about gaya one about that model i mean it they they the input is video it creates a representation and it plans and and and takes action in the representation plans actions in the representation space you can then decode that into video to see what what it's doing but but it's but you're not planning in the video space so the what what's your ambition with with this you'll figure out the refine the algorithms the reinforcement learning algorithms they need to be scalable once you have that uh then you move on and and uh start start scaling them with compute and and uh you know following your roadmap or am i simplifying it too much you know we want to understand how the mind works and then we're going to make a mind or some minds or some mind uh amount of mind uh and this will be useful in all the ways in all sorts of ways economically useful it'll also be useful um to to us to extend the capabilities of our own minds if we can understand how our minds work um we can we can augment them so that they can work better um yeah we're gonna the the key step is understanding and then there would be millions of uses um i don't think it's going to be as simple as making uh workers sort of like slaves for us to direct i don't think it'll be as simple as that um that maybe gives a lower bound on potential utility our sort of our story for etkin is we say that um well if you suppose you could make a virtual worker um this would be enormously useful um much of the work that we all do from day to day is doesn't require a physical presence it doesn't require a robot much of which we do is just shuffling information around we can do most things through through a video interface um so why can't we make workers that are extremely useful by playing the roles that people play in many cases that's that's that's sort of a lower bound and what can be done i think much more can be done and there'll be much more interesting things to be done and then this question of what should be done um yeah those are those are rich philosophical questions and practical questions for the economy yeah uh the the i've seen your third uh well and one thing on reinforcement learning and sort of supervised learning sort of took over for a while now it's transformer based generative uh ai but uh during the supervised learning phase uh the argument was that uh higher knowledge is all supervised learning and and the it's still supervised it's still supervised in general the ai had large language models they the the training information is the next token the next word and that's taken as as the correct action the analogy you gave me was uh you know because the analogy that that's always given is that you know a child sees an elephant the mother says that's an elephant and the child very quickly can generalize and and recognize other elements elephants maybe it makes a mistake and the mother corrects it and says no that's a cow and and that was always given as an example of supervised learning but maybe it's reinforcement learning maybe it's the child's reward from the mother praising him for remembering the label the point is that a child has well-developed concepts classes concepts um before and then and then when it's you know when its mother says that is an elephant uh there's already an extensive understanding on the child's and a part of you know what the space is what the objects are and and this this the the thing that that is being labeled um no the label is the least interesting part of that and the the the child has already learned all the all all the other most interesting parts of of what it means to have animals and moving things and objects in its world the label is the least interesting part well first of all you're talking about agents that that could be virtual workers already uh using reinforcement learning people are building agents and using large language models and knowledge bases to you know carry out tasks knowledge based tasks uh so what you're talking about is is more than uh linguistic tasks or knowledge based tasks you're talking about of physical planning and physical tasks is that right the key thing is having goals and a lot if you have an for example an assistant help you plan your day organize your day or do tasks for you um i'm thinking it's very important that the system is able to have goals and is able to understand your goals i think it's probably the most important part of an assistant is to understand the purposes involved and um large language models don't understand don't really understand purposes involved they will appear to a little bit um but the corner case has always come up and once you spend a bit of time they're always and you're always in a corner case and so an AI system is system that that after a bit does silly things and that don't respect the goals that you have or that have been given to it um that's not going to be a useful assistant so i mean i don't want to be critical of large language models um they're very very useful but it shouldn't be viewed as a criticism to say that they're also at the same time have rather important limitations it's not a competition in that sense are you concerned at all are you ascribed to the threat debate no i think the i don't i don't uh i i think the doomers are they're not just wrong i think i think they're blindingly biased the the bias is blinding them to what's going on basically AI is a broadly applicable technology it's not like it's not like nuclear weapons it's not like it's not like a bio weapons it can be used for all kinds of things and it's not it's not uh it's uh the way we deal with such things is we we uh we try to use them well and there will be people that use them for bad things and then you know this is just normal there's normal technology is it can be used by good people or bad people the the doomers the doomers are just saying oh somehow there's going to be it's going to be it's bad in the same way that nuclear weapons are bad that they and that's just they're just blinded by that metaphor by the thinking that that the AI will be out to kill them that's just it's just silly and i i don't i don't think well they the doomers don't actually give coherent reasons for what they what they believe and so it's hard to argue with them uh so maybe it's fair just to hold that they're they're biased and blind i don't accept i don't accept an argument this is a proper argument so so where you say you're maybe at stage four in the research car max says 2030 uh that's you know it's far enough out there that maybe people won't remember in 2030 that he said 2030 uh it's always uh you know i've 2030 has been out there for a long time and it's it's it's uh you can't it doesn't recede it's always been 2030 for the uh computer power reaching human scale um quantities yeah but anyway 2030 is is a reasonable it's a reasonable target for us understanding everything that we need in order to make uh a real mind yeah i'm good with that yeah as you you have to be ambitious i've always said that 2030 is a 25 chance of of of achieving a real intelligence a real human level intelligence 25 chance so probably not but it's it's a big enough chunk of probability that that an ambitious person should work towards it and try to make it true and it does depend upon what we do and not just the uh unfolding of the universe so we should we should try to do that that that is a big the big thing that's happening right now is the the the public is coming to grips with what it means for there to be for us to understand the mind and to have the ability to create uh minded things uh and so that that is a big uh transformation it's a big change in our worldview um and so we absolutely need all kinds of people to uh to help us help us become easy and become have an understanding of what's happening as we uh achieve human level designed intelligence that's it for this week's episode i want to thank richard for his time if you want to read a transcript of today's conversation you can find one on our website i on ai that's e y e hyphen o n dot ai in the meantime remember the singularity may be getting closer but ai is already changing your world so pay attention", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.32, "text": " There isn't a science around that isn't profoundly influenced by the availability of", "tokens": [50364, 821, 1943, 380, 257, 3497, 926, 300, 1943, 380, 39954, 15269, 538, 264, 17945, 295, 50580], "temperature": 0.0, "avg_logprob": -0.1196988577981597, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.03201102092862129}, {"id": 1, "seek": 0, "start": 4.32, "end": 8.96, "text": " massive computing power and just greater regular computing power. It's the story of our age. It's", "tokens": [50580, 5994, 15866, 1347, 293, 445, 5044, 3890, 15866, 1347, 13, 467, 311, 264, 1657, 295, 527, 3205, 13, 467, 311, 50812], "temperature": 0.0, "avg_logprob": -0.1196988577981597, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.03201102092862129}, {"id": 2, "seek": 0, "start": 8.96, "end": 15.68, "text": " not just the story of AI. The idea is to leverage computation to make useful things and understand", "tokens": [50812, 406, 445, 264, 1657, 295, 7318, 13, 440, 1558, 307, 281, 13982, 24903, 281, 652, 4420, 721, 293, 1223, 51148], "temperature": 0.0, "avg_logprob": -0.1196988577981597, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.03201102092862129}, {"id": 3, "seek": 0, "start": 15.68, "end": 20.32, "text": " the mind. These all these things need a lot of computation. It's the fact that computation has", "tokens": [51148, 264, 1575, 13, 1981, 439, 613, 721, 643, 257, 688, 295, 24903, 13, 467, 311, 264, 1186, 300, 24903, 575, 51380], "temperature": 0.0, "avg_logprob": -0.1196988577981597, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.03201102092862129}, {"id": 4, "seek": 0, "start": 20.32, "end": 27.04, "text": " become cheaper exponentially for on the order of 100 years and can be expected to continue going", "tokens": [51380, 1813, 12284, 37330, 337, 322, 264, 1668, 295, 2319, 924, 293, 393, 312, 5176, 281, 2354, 516, 51716], "temperature": 0.0, "avg_logprob": -0.1196988577981597, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.03201102092862129}, {"id": 5, "seek": 2704, "start": 27.52, "end": 33.68, "text": " It looks like doubling every two years now every 18 months and that keeps happening 18 months after", "tokens": [50388, 467, 1542, 411, 33651, 633, 732, 924, 586, 633, 2443, 2493, 293, 300, 5965, 2737, 2443, 2493, 934, 50696], "temperature": 0.0, "avg_logprob": -0.11558284415855063, "compression_ratio": 1.88715953307393, "no_speech_prob": 0.0043302117846906185}, {"id": 6, "seek": 2704, "start": 33.68, "end": 39.6, "text": " 18 months after 18 months and it means you double and you double and things get qualitatively different", "tokens": [50696, 2443, 2493, 934, 2443, 2493, 293, 309, 1355, 291, 3834, 293, 291, 3834, 293, 721, 483, 31312, 356, 819, 50992], "temperature": 0.0, "avg_logprob": -0.11558284415855063, "compression_ratio": 1.88715953307393, "no_speech_prob": 0.0043302117846906185}, {"id": 7, "seek": 2704, "start": 39.6, "end": 44.879999999999995, "text": " every decade and that's happened for a long time for many decades and will happen more so in the", "tokens": [50992, 633, 10378, 293, 300, 311, 2011, 337, 257, 938, 565, 337, 867, 7878, 293, 486, 1051, 544, 370, 294, 264, 51256], "temperature": 0.0, "avg_logprob": -0.11558284415855063, "compression_ratio": 1.88715953307393, "no_speech_prob": 0.0043302117846906185}, {"id": 8, "seek": 2704, "start": 44.879999999999995, "end": 48.879999999999995, "text": " future. So we have that to look forward to. I think it's what we really should mean when we", "tokens": [51256, 2027, 13, 407, 321, 362, 300, 281, 574, 2128, 281, 13, 286, 519, 309, 311, 437, 321, 534, 820, 914, 562, 321, 51456], "temperature": 0.0, "avg_logprob": -0.11558284415855063, "compression_ratio": 1.88715953307393, "no_speech_prob": 0.0043302117846906185}, {"id": 9, "seek": 2704, "start": 48.879999999999995, "end": 54.0, "text": " say the singularity. The singularity is that we have this exploding it's a slow explosion of", "tokens": [51456, 584, 264, 20010, 507, 13, 440, 20010, 507, 307, 300, 321, 362, 341, 35175, 309, 311, 257, 2964, 15673, 295, 51712], "temperature": 0.0, "avg_logprob": -0.11558284415855063, "compression_ratio": 1.88715953307393, "no_speech_prob": 0.0043302117846906185}, {"id": 10, "seek": 5400, "start": 54.0, "end": 59.44, "text": " computer power and that that is fundamentally changing things. Hi I'm Craig Smith and this is", "tokens": [50364, 3820, 1347, 293, 300, 300, 307, 17879, 4473, 721, 13, 2421, 286, 478, 19732, 8538, 293, 341, 307, 50636], "temperature": 0.0, "avg_logprob": -0.1126840614978178, "compression_ratio": 1.4939759036144578, "no_speech_prob": 0.016139885410666466}, {"id": 11, "seek": 5400, "start": 59.44, "end": 66.56, "text": " I on AI. In this episode I speak with Richard Sutton the father of reinforcement learning", "tokens": [50636, 286, 322, 7318, 13, 682, 341, 3500, 286, 1710, 365, 9809, 40492, 1756, 264, 3086, 295, 29280, 2539, 50992], "temperature": 0.0, "avg_logprob": -0.1126840614978178, "compression_ratio": 1.4939759036144578, "no_speech_prob": 0.016139885410666466}, {"id": 12, "seek": 5400, "start": 66.56, "end": 72.32, "text": " and professor at the University of Alberta. We discussed his cooperation with John Carmack", "tokens": [50992, 293, 8304, 412, 264, 3535, 295, 43279, 13, 492, 7152, 702, 14968, 365, 2619, 44530, 501, 51280], "temperature": 0.0, "avg_logprob": -0.1126840614978178, "compression_ratio": 1.4939759036144578, "no_speech_prob": 0.016139885410666466}, {"id": 13, "seek": 5400, "start": 72.32, "end": 79.52, "text": " on Keen a startup that vows to reach artificial general intelligence by 2030. Richard also talked", "tokens": [51280, 322, 3189, 268, 257, 18578, 300, 371, 1509, 281, 2524, 11677, 2674, 7599, 538, 28638, 13, 9809, 611, 2825, 51640], "temperature": 0.0, "avg_logprob": -0.1126840614978178, "compression_ratio": 1.4939759036144578, "no_speech_prob": 0.016139885410666466}, {"id": 14, "seek": 7952, "start": 79.52, "end": 85.92, "text": " about the Alberta plan his ambitious five-year research agenda focused on building embodied", "tokens": [50364, 466, 264, 43279, 1393, 702, 20239, 1732, 12, 5294, 2132, 9829, 5178, 322, 2390, 42046, 50684], "temperature": 0.0, "avg_logprob": -0.061826011713813335, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0378667451441288}, {"id": 15, "seek": 7952, "start": 85.92, "end": 92.56, "text": " agents with the capability to learn and plan through interactions with their environment.", "tokens": [50684, 12554, 365, 264, 13759, 281, 1466, 293, 1393, 807, 13280, 365, 641, 2823, 13, 51016], "temperature": 0.0, "avg_logprob": -0.061826011713813335, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0378667451441288}, {"id": 16, "seek": 7952, "start": 92.56, "end": 98.64, "text": " Sutton provides insights into the current state of progress new algorithmic developments", "tokens": [51016, 40492, 1756, 6417, 14310, 666, 264, 2190, 1785, 295, 4205, 777, 9284, 299, 20862, 51320], "temperature": 0.0, "avg_logprob": -0.061826011713813335, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0378667451441288}, {"id": 17, "seek": 7952, "start": 98.64, "end": 105.19999999999999, "text": " and trade-offs between simulated and physical environments in training and the ultimate goal", "tokens": [51320, 293, 4923, 12, 19231, 1296, 41713, 293, 4001, 12388, 294, 3097, 293, 264, 9705, 3387, 51648], "temperature": 0.0, "avg_logprob": -0.061826011713813335, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0378667451441288}, {"id": 18, "seek": 10520, "start": 105.2, "end": 112.64, "text": " of creating AGI. I hope you find the conversation as amazing as I did. So why don't you start by", "tokens": [50364, 295, 4084, 316, 26252, 13, 286, 1454, 291, 915, 264, 3761, 382, 2243, 382, 286, 630, 13, 407, 983, 500, 380, 291, 722, 538, 50736], "temperature": 0.0, "avg_logprob": -0.0829065416900205, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.004325014539062977}, {"id": 19, "seek": 10520, "start": 112.64, "end": 118.64, "text": " introducing yourself. I assume people know who you are I've had you on the podcast before", "tokens": [50736, 15424, 1803, 13, 286, 6552, 561, 458, 567, 291, 366, 286, 600, 632, 291, 322, 264, 7367, 949, 51036], "temperature": 0.0, "avg_logprob": -0.0829065416900205, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.004325014539062977}, {"id": 20, "seek": 10520, "start": 120.0, "end": 128.96, "text": " but for those new listeners tell us who you are where you are and then we'll talk about the Alberta", "tokens": [51104, 457, 337, 729, 777, 23274, 980, 505, 567, 291, 366, 689, 291, 366, 293, 550, 321, 603, 751, 466, 264, 43279, 51552], "temperature": 0.0, "avg_logprob": -0.0829065416900205, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.004325014539062977}, {"id": 21, "seek": 12896, "start": 128.96, "end": 138.8, "text": " plan which I find pretty exciting. Thank you Craig I'm Richard Sutton I'm a scientist I've been", "tokens": [50364, 1393, 597, 286, 915, 1238, 4670, 13, 1044, 291, 19732, 286, 478, 9809, 40492, 1756, 286, 478, 257, 12662, 286, 600, 668, 50856], "temperature": 0.0, "avg_logprob": -0.14534268012413612, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0064798821695148945}, {"id": 22, "seek": 12896, "start": 138.8, "end": 146.48000000000002, "text": " studying artificial intelligence for like 45 years a long time and I'm up in north of the", "tokens": [50856, 7601, 11677, 7599, 337, 411, 6905, 924, 257, 938, 565, 293, 286, 478, 493, 294, 6830, 295, 264, 51240], "temperature": 0.0, "avg_logprob": -0.14534268012413612, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0064798821695148945}, {"id": 23, "seek": 12896, "start": 146.48000000000002, "end": 153.28, "text": " University of Alberta in Canada and I'm a professor in the computer science computing science department", "tokens": [51240, 3535, 295, 43279, 294, 6309, 293, 286, 478, 257, 8304, 294, 264, 3820, 3497, 15866, 3497, 5882, 51580], "temperature": 0.0, "avg_logprob": -0.14534268012413612, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.0064798821695148945}, {"id": 24, "seek": 15328, "start": 153.28, "end": 161.04, "text": " and also I'm a researcher at Keen Technologies and I got lots of titles and sub-rolls but basically", "tokens": [50364, 293, 611, 286, 478, 257, 21751, 412, 3189, 268, 46993, 293, 286, 658, 3195, 295, 12992, 293, 1422, 12, 3970, 82, 457, 1936, 50752], "temperature": 0.0, "avg_logprob": -0.12051338277837281, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.04461802914738655}, {"id": 25, "seek": 15328, "start": 161.04, "end": 166.56, "text": " I'm just trying to figure out how the mind works and I've tried to do it in a very broad and", "tokens": [50752, 286, 478, 445, 1382, 281, 2573, 484, 577, 264, 1575, 1985, 293, 286, 600, 3031, 281, 360, 309, 294, 257, 588, 4152, 293, 51028], "temperature": 0.0, "avg_logprob": -0.12051338277837281, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.04461802914738655}, {"id": 26, "seek": 15328, "start": 166.56, "end": 172.88, "text": " interdisciplinary way reading all the different thinkers on the subject and addressed from the", "tokens": [51028, 38280, 636, 3760, 439, 264, 819, 37895, 322, 264, 3983, 293, 13847, 490, 264, 51344], "temperature": 0.0, "avg_logprob": -0.12051338277837281, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.04461802914738655}, {"id": 27, "seek": 15328, "start": 172.88, "end": 180.64, "text": " point of view of psychology and how the brain might work as well as. Yeah I've read a number of the", "tokens": [51344, 935, 295, 1910, 295, 15105, 293, 577, 264, 3567, 1062, 589, 382, 731, 382, 13, 865, 286, 600, 1401, 257, 1230, 295, 264, 51732], "temperature": 0.0, "avg_logprob": -0.12051338277837281, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.04461802914738655}, {"id": 28, "seek": 18064, "start": 180.64, "end": 188.23999999999998, "text": " recent papers and I can see this thread developing and I don't know whether it's just that you're", "tokens": [50364, 5162, 10577, 293, 286, 393, 536, 341, 7207, 6416, 293, 286, 500, 380, 458, 1968, 309, 311, 445, 300, 291, 434, 50744], "temperature": 0.0, "avg_logprob": -0.0685020163655281, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.004979295656085014}, {"id": 29, "seek": 18064, "start": 188.23999999999998, "end": 195.04, "text": " writing more and so the thoughts are are more developed in print or whether they're developing", "tokens": [50744, 3579, 544, 293, 370, 264, 4598, 366, 366, 544, 4743, 294, 4482, 420, 1968, 436, 434, 6416, 51084], "temperature": 0.0, "avg_logprob": -0.0685020163655281, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.004979295656085014}, {"id": 30, "seek": 18064, "start": 195.04, "end": 203.2, "text": " in your mind but from 2019 when you wrote the bitter lesson you talked about the idea that", "tokens": [51084, 294, 428, 1575, 457, 490, 6071, 562, 291, 4114, 264, 13871, 6898, 291, 2825, 466, 264, 1558, 300, 51492], "temperature": 0.0, "avg_logprob": -0.0685020163655281, "compression_ratio": 1.5898876404494382, "no_speech_prob": 0.004979295656085014}, {"id": 31, "seek": 20320, "start": 203.2, "end": 212.0, "text": " it's really increasing computation and the striving a lot of things a lot of progress", "tokens": [50364, 309, 311, 534, 5662, 24903, 293, 264, 36582, 257, 688, 295, 721, 257, 688, 295, 4205, 50804], "temperature": 0.0, "avg_logprob": -0.19909484211991474, "compression_ratio": 1.384, "no_speech_prob": 0.07686837017536163}, {"id": 32, "seek": 20320, "start": 212.72, "end": 223.6, "text": " that kind of coincided with open AI's scaling of the transformer model I talked to Ilya", "tokens": [50840, 300, 733, 295, 13001, 2112, 365, 1269, 7318, 311, 21589, 295, 264, 31782, 2316, 286, 2825, 281, 286, 45106, 51384], "temperature": 0.0, "avg_logprob": -0.19909484211991474, "compression_ratio": 1.384, "no_speech_prob": 0.07686837017536163}, {"id": 33, "seek": 22360, "start": 223.6, "end": 233.28, "text": " Sutskover and I asked him whether your essay had triggered their their interest in scaling and he", "tokens": [50364, 318, 3648, 4093, 331, 293, 286, 2351, 796, 1968, 428, 16238, 632, 21710, 641, 641, 1179, 294, 21589, 293, 415, 50848], "temperature": 0.0, "avg_logprob": -0.18866599689830432, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.11407015472650528}, {"id": 34, "seek": 22360, "start": 233.28, "end": 241.6, "text": " said no it was coincidental but I kept first can we talk about that about how scale scaling and", "tokens": [50848, 848, 572, 309, 390, 13001, 47023, 457, 286, 4305, 700, 393, 321, 751, 466, 300, 466, 577, 4373, 21589, 293, 51264], "temperature": 0.0, "avg_logprob": -0.18866599689830432, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.11407015472650528}, {"id": 35, "seek": 22360, "start": 241.6, "end": 250.48, "text": " and the availability of computational resources and Moore's law has driven a lot of what's happened", "tokens": [51264, 293, 264, 17945, 295, 28270, 3593, 293, 21644, 311, 2101, 575, 9555, 257, 688, 295, 437, 311, 2011, 51708], "temperature": 0.0, "avg_logprob": -0.18866599689830432, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.11407015472650528}, {"id": 36, "seek": 25048, "start": 250.56, "end": 258.56, "text": " in artificial intelligence research almost more than novel algorithms well I think the", "tokens": [50368, 294, 11677, 7599, 2132, 1920, 544, 813, 7613, 14642, 731, 286, 519, 264, 50768], "temperature": 0.0, "avg_logprob": -0.09803296460045709, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.0015235868049785495}, {"id": 37, "seek": 25048, "start": 258.56, "end": 263.92, "text": " first thing to be aware of is it's it's been driving things that are not just artificial", "tokens": [50768, 700, 551, 281, 312, 3650, 295, 307, 309, 311, 309, 311, 668, 4840, 721, 300, 366, 406, 445, 11677, 51036], "temperature": 0.0, "avg_logprob": -0.09803296460045709, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.0015235868049785495}, {"id": 38, "seek": 25048, "start": 263.92, "end": 270.24, "text": " intelligence it's been driving all the sciences and all the engineering developments in the world", "tokens": [51036, 7599, 309, 311, 668, 4840, 439, 264, 17677, 293, 439, 264, 7043, 20862, 294, 264, 1002, 51352], "temperature": 0.0, "avg_logprob": -0.09803296460045709, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.0015235868049785495}, {"id": 39, "seek": 25048, "start": 271.52, "end": 276.0, "text": " there isn't a science around that isn't profoundly influenced by the availability", "tokens": [51416, 456, 1943, 380, 257, 3497, 926, 300, 1943, 380, 39954, 15269, 538, 264, 17945, 51640], "temperature": 0.0, "avg_logprob": -0.09803296460045709, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.0015235868049785495}, {"id": 40, "seek": 27600, "start": 276.72, "end": 281.44, "text": " availability of massive computing power and just greater regular computing power", "tokens": [50400, 17945, 295, 5994, 15866, 1347, 293, 445, 5044, 3890, 15866, 1347, 50636], "temperature": 0.0, "avg_logprob": -0.09596107876490033, "compression_ratio": 1.8012820512820513, "no_speech_prob": 0.006093400064855814}, {"id": 41, "seek": 27600, "start": 282.48, "end": 288.48, "text": " it's it's it's the story of our age it's not just the story of AI it's not particularly the story", "tokens": [50688, 309, 311, 309, 311, 309, 311, 264, 1657, 295, 527, 3205, 309, 311, 406, 445, 264, 1657, 295, 7318, 309, 311, 406, 4098, 264, 1657, 50988], "temperature": 0.0, "avg_logprob": -0.09596107876490033, "compression_ratio": 1.8012820512820513, "no_speech_prob": 0.006093400064855814}, {"id": 42, "seek": 27600, "start": 288.48, "end": 298.08, "text": " of AI AI has always known that it needs computation the idea is to leverage computation to make useful", "tokens": [50988, 295, 7318, 7318, 575, 1009, 2570, 300, 309, 2203, 24903, 264, 1558, 307, 281, 13982, 24903, 281, 652, 4420, 51468], "temperature": 0.0, "avg_logprob": -0.09596107876490033, "compression_ratio": 1.8012820512820513, "no_speech_prob": 0.006093400064855814}, {"id": 43, "seek": 29808, "start": 298.08, "end": 306.71999999999997, "text": " things and understand the mind um yeah now it's true that those of us who are interested in", "tokens": [50364, 721, 293, 1223, 264, 1575, 1105, 1338, 586, 309, 311, 2074, 300, 729, 295, 505, 567, 366, 3102, 294, 50796], "temperature": 0.0, "avg_logprob": -0.15719025135040282, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.06843511760234833}, {"id": 44, "seek": 29808, "start": 306.71999999999997, "end": 313.2, "text": " connection to systems or distributed networks nowadays just call neural networks not particularly", "tokens": [50796, 4984, 281, 3652, 420, 12631, 9590, 13434, 445, 818, 18161, 9590, 406, 4098, 51120], "temperature": 0.0, "avg_logprob": -0.15719025135040282, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.06843511760234833}, {"id": 45, "seek": 29808, "start": 313.2, "end": 318.88, "text": " good terms so I always shudder a little bit when I use it but those of us that have been doing that", "tokens": [51120, 665, 2115, 370, 286, 1009, 402, 532, 1068, 257, 707, 857, 562, 286, 764, 309, 457, 729, 295, 505, 300, 362, 668, 884, 300, 51404], "temperature": 0.0, "avg_logprob": -0.15719025135040282, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.06843511760234833}, {"id": 46, "seek": 29808, "start": 318.88, "end": 324.32, "text": " have have those are doing learning I think that learning is important for intelligence", "tokens": [51404, 362, 362, 729, 366, 884, 2539, 286, 519, 300, 2539, 307, 1021, 337, 7599, 51676], "temperature": 0.0, "avg_logprob": -0.15719025135040282, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.06843511760234833}, {"id": 47, "seek": 32432, "start": 325.04, "end": 330.96, "text": " these all these things need a lot of computation and so they're they are limited by the computation", "tokens": [50400, 613, 439, 613, 721, 643, 257, 688, 295, 24903, 293, 370, 436, 434, 436, 366, 5567, 538, 264, 24903, 50696], "temperature": 0.0, "avg_logprob": -0.10059652435645629, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00926387868821621}, {"id": 48, "seek": 32432, "start": 330.96, "end": 337.68, "text": " available at the time okay so let's let's be what is this thing what is the so Moore's law what's", "tokens": [50696, 2435, 412, 264, 565, 1392, 370, 718, 311, 718, 311, 312, 437, 307, 341, 551, 437, 307, 264, 370, 21644, 311, 2101, 437, 311, 51032], "temperature": 0.0, "avg_logprob": -0.10059652435645629, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00926387868821621}, {"id": 49, "seek": 32432, "start": 337.68, "end": 344.32, "text": " called Moore's law it's the fact computation is becoming more plentiful and cheaper exponentially", "tokens": [51032, 1219, 21644, 311, 2101, 309, 311, 264, 1186, 24903, 307, 5617, 544, 499, 317, 2069, 293, 12284, 37330, 51364], "temperature": 0.0, "avg_logprob": -0.10059652435645629, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00926387868821621}, {"id": 50, "seek": 32432, "start": 345.03999999999996, "end": 351.28, "text": " for on the order of a hundred years and can be expected to continue going that way so", "tokens": [51400, 337, 322, 264, 1668, 295, 257, 3262, 924, 293, 393, 312, 5176, 281, 2354, 516, 300, 636, 370, 51712], "temperature": 0.0, "avg_logprob": -0.10059652435645629, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00926387868821621}, {"id": 51, "seek": 35128, "start": 351.35999999999996, "end": 356.88, "text": " exponentially looks like doubling every two years now each every 18 months and that keeps", "tokens": [50368, 37330, 1542, 411, 33651, 633, 732, 924, 586, 1184, 633, 2443, 2493, 293, 300, 5965, 50644], "temperature": 0.0, "avg_logprob": -0.07162377892470942, "compression_ratio": 1.8613861386138615, "no_speech_prob": 0.002589754993095994}, {"id": 52, "seek": 35128, "start": 356.88, "end": 362.55999999999995, "text": " happening 18 months after 18 months after 18 months and it means you double and you double", "tokens": [50644, 2737, 2443, 2493, 934, 2443, 2493, 934, 2443, 2493, 293, 309, 1355, 291, 3834, 293, 291, 3834, 50928], "temperature": 0.0, "avg_logprob": -0.07162377892470942, "compression_ratio": 1.8613861386138615, "no_speech_prob": 0.002589754993095994}, {"id": 53, "seek": 35128, "start": 362.55999999999995, "end": 370.55999999999995, "text": " and things get qualitatively different uh every decade and that's happened for a long time for", "tokens": [50928, 293, 721, 483, 31312, 356, 819, 2232, 633, 10378, 293, 300, 311, 2011, 337, 257, 938, 565, 337, 51328], "temperature": 0.0, "avg_logprob": -0.07162377892470942, "compression_ratio": 1.8613861386138615, "no_speech_prob": 0.002589754993095994}, {"id": 54, "seek": 35128, "start": 370.55999999999995, "end": 376.08, "text": " many decades and will happen it's more so in the future so we have that to look forward to that will", "tokens": [51328, 867, 7878, 293, 486, 1051, 309, 311, 544, 370, 294, 264, 2027, 370, 321, 362, 300, 281, 574, 2128, 281, 300, 486, 51604], "temperature": 0.0, "avg_logprob": -0.07162377892470942, "compression_ratio": 1.8613861386138615, "no_speech_prob": 0.002589754993095994}, {"id": 55, "seek": 37608, "start": 376.08, "end": 385.59999999999997, "text": " continue having a tremendous influence on everything that's done on the other hand it's just normal", "tokens": [50364, 2354, 1419, 257, 10048, 6503, 322, 1203, 300, 311, 1096, 322, 264, 661, 1011, 309, 311, 445, 2710, 50840], "temperature": 0.0, "avg_logprob": -0.08688787853016573, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.006485670804977417}, {"id": 56, "seek": 37608, "start": 385.59999999999997, "end": 392.88, "text": " it's just what you would expect and that those of who worked on AI for for a long time have just", "tokens": [50840, 309, 311, 445, 437, 291, 576, 2066, 293, 300, 729, 295, 567, 2732, 322, 7318, 337, 337, 257, 938, 565, 362, 445, 51204], "temperature": 0.0, "avg_logprob": -0.08688787853016573, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.006485670804977417}, {"id": 57, "seek": 37608, "start": 392.88, "end": 401.68, "text": " you know expect and plan for and um now it's coming but it's an exponential so exponentials", "tokens": [51204, 291, 458, 2066, 293, 1393, 337, 293, 1105, 586, 309, 311, 1348, 457, 309, 311, 364, 21510, 370, 21510, 82, 51644], "temperature": 0.0, "avg_logprob": -0.08688787853016573, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.006485670804977417}, {"id": 58, "seek": 40168, "start": 401.68, "end": 407.44, "text": " are self-similar so that means they look the same at every point in time every every year it's", "tokens": [50364, 366, 2698, 12, 30937, 2202, 370, 300, 1355, 436, 574, 264, 912, 412, 633, 935, 294, 565, 633, 633, 1064, 309, 311, 50652], "temperature": 0.0, "avg_logprob": -0.05993816476119192, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.023669395595788956}, {"id": 59, "seek": 40168, "start": 407.44, "end": 412.8, "text": " you're doubling in a year and a half and so it's it's an explosion as every exponential is an", "tokens": [50652, 291, 434, 33651, 294, 257, 1064, 293, 257, 1922, 293, 370, 309, 311, 309, 311, 364, 15673, 382, 633, 21510, 307, 364, 50920], "temperature": 0.0, "avg_logprob": -0.05993816476119192, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.023669395595788956}, {"id": 60, "seek": 40168, "start": 412.8, "end": 418.56, "text": " explosion it's it's sort of I think it's what we really should mean when we say the singularity", "tokens": [50920, 15673, 309, 311, 309, 311, 1333, 295, 286, 519, 309, 311, 437, 321, 534, 820, 914, 562, 321, 584, 264, 20010, 507, 51208], "temperature": 0.0, "avg_logprob": -0.05993816476119192, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.023669395595788956}, {"id": 61, "seek": 40168, "start": 418.56, "end": 425.76, "text": " the singularity is that we have this exploding it's a slow explosion of computer power and that", "tokens": [51208, 264, 20010, 507, 307, 300, 321, 362, 341, 35175, 309, 311, 257, 2964, 15673, 295, 3820, 1347, 293, 300, 51568], "temperature": 0.0, "avg_logprob": -0.05993816476119192, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.023669395595788956}, {"id": 62, "seek": 42576, "start": 426.15999999999997, "end": 432.24, "text": " has fundamentally changed things yeah and I had a really interesting conversation almost a year", "tokens": [50384, 575, 17879, 3105, 721, 1338, 293, 286, 632, 257, 534, 1880, 3761, 1920, 257, 1064, 50688], "temperature": 0.0, "avg_logprob": -0.1660263769088253, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.03205223008990288}, {"id": 63, "seek": 42576, "start": 432.24, "end": 440.4, "text": " ago with Aidan Gomez who was on the team that that that designed the transformer algorithm at", "tokens": [50688, 2057, 365, 316, 31675, 43537, 567, 390, 322, 264, 1469, 300, 300, 300, 4761, 264, 31782, 9284, 412, 51096], "temperature": 0.0, "avg_logprob": -0.1660263769088253, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.03205223008990288}, {"id": 64, "seek": 42576, "start": 440.4, "end": 449.12, "text": " Google and he now has a startup co-coher he's Canadian and he said an interesting thing that", "tokens": [51096, 3329, 293, 415, 586, 575, 257, 18578, 598, 12, 1291, 511, 415, 311, 12641, 293, 415, 848, 364, 1880, 551, 300, 51532], "temperature": 0.0, "avg_logprob": -0.1660263769088253, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.03205223008990288}, {"id": 65, "seek": 44912, "start": 449.84000000000003, "end": 456.16, "text": " that he believes it could have been almost any algorithm it didn't have to be the transformer", "tokens": [50400, 300, 415, 12307, 309, 727, 362, 668, 1920, 604, 9284, 309, 994, 380, 362, 281, 312, 264, 31782, 50716], "temperature": 0.0, "avg_logprob": -0.09864015579223633, "compression_ratio": 1.90625, "no_speech_prob": 0.02927740477025509}, {"id": 66, "seek": 44912, "start": 456.8, "end": 463.76, "text": " that the community got behind the transformer poured resources into it continued to scale it", "tokens": [50748, 300, 264, 1768, 658, 2261, 264, 31782, 23270, 3593, 666, 309, 7014, 281, 4373, 309, 51096], "temperature": 0.0, "avg_logprob": -0.09864015579223633, "compression_ratio": 1.90625, "no_speech_prob": 0.02927740477025509}, {"id": 67, "seek": 44912, "start": 464.56, "end": 470.24, "text": " and it was scalable I mean that was important that it that it's a scalable architecture but", "tokens": [51136, 293, 309, 390, 38481, 286, 914, 300, 390, 1021, 300, 309, 300, 309, 311, 257, 38481, 9482, 457, 51420], "temperature": 0.0, "avg_logprob": -0.09864015579223633, "compression_ratio": 1.90625, "no_speech_prob": 0.02927740477025509}, {"id": 68, "seek": 44912, "start": 471.44, "end": 477.2, "text": " that but it didn't have to be the transformer and and that made me think of you because", "tokens": [51480, 300, 457, 309, 994, 380, 362, 281, 312, 264, 31782, 293, 293, 300, 1027, 385, 519, 295, 291, 570, 51768], "temperature": 0.0, "avg_logprob": -0.09864015579223633, "compression_ratio": 1.90625, "no_speech_prob": 0.02927740477025509}, {"id": 69, "seek": 47720, "start": 478.0, "end": 487.84, "text": " of so transformers they the way he described it at its core it's a stock of multi-layer", "tokens": [50404, 295, 370, 4088, 433, 436, 264, 636, 415, 7619, 309, 412, 1080, 4965, 309, 311, 257, 4127, 295, 4825, 12, 8376, 260, 50896], "temperature": 0.0, "avg_logprob": -0.17251939158285817, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0009543639607727528}, {"id": 70, "seek": 47720, "start": 487.84, "end": 495.68, "text": " perceptrons with attention you scale it feed it data and it does learns to understand language", "tokens": [50896, 43276, 13270, 365, 3202, 291, 4373, 309, 3154, 309, 1412, 293, 309, 775, 27152, 281, 1223, 2856, 51288], "temperature": 0.0, "avg_logprob": -0.17251939158285817, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0009543639607727528}, {"id": 71, "seek": 47720, "start": 495.68, "end": 502.24, "text": " or at least seems to understand language but it's got all these obvious limitations", "tokens": [51288, 420, 412, 1935, 2544, 281, 1223, 2856, 457, 309, 311, 658, 439, 613, 6322, 15705, 51616], "temperature": 0.0, "avg_logprob": -0.17251939158285817, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.0009543639607727528}, {"id": 72, "seek": 50224, "start": 503.2, "end": 510.24, "text": " of I've been talking a lot over the last couple of years to Yamakun about world models and that", "tokens": [50412, 295, 286, 600, 668, 1417, 257, 688, 670, 264, 1036, 1916, 295, 924, 281, 18992, 514, 409, 466, 1002, 5245, 293, 300, 50764], "temperature": 0.0, "avg_logprob": -0.20318926081937902, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.013415983878076077}, {"id": 73, "seek": 50224, "start": 510.24, "end": 521.2, "text": " to me sounded like a much more exciting direction for general intelligence because not all intelligence", "tokens": [50764, 281, 385, 17714, 411, 257, 709, 544, 4670, 3513, 337, 2674, 7599, 570, 406, 439, 7599, 51312], "temperature": 0.0, "avg_logprob": -0.20318926081937902, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.013415983878076077}, {"id": 74, "seek": 50224, "start": 521.2, "end": 531.52, "text": " is is contained in language or at least most or even less so in human text and then I see you guys", "tokens": [51312, 307, 307, 16212, 294, 2856, 420, 412, 1935, 881, 420, 754, 1570, 370, 294, 1952, 2487, 293, 550, 286, 536, 291, 1074, 51828], "temperature": 0.0, "avg_logprob": -0.20318926081937902, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.013415983878076077}, {"id": 75, "seek": 53152, "start": 531.6, "end": 540.64, "text": " come along with the Alberta plan and that that that sounded even more exciting to me so", "tokens": [50368, 808, 2051, 365, 264, 43279, 1393, 293, 300, 300, 300, 17714, 754, 544, 4670, 281, 385, 370, 50820], "temperature": 0.0, "avg_logprob": -0.13928676534582068, "compression_ratio": 1.6312056737588652, "no_speech_prob": 0.012587080709636211}, {"id": 76, "seek": 53152, "start": 542.48, "end": 549.6, "text": " how how do you so the Alberta plan you're building the ideas to build an", "tokens": [50912, 577, 577, 360, 291, 370, 264, 43279, 1393, 291, 434, 2390, 264, 3487, 281, 1322, 364, 51268], "temperature": 0.0, "avg_logprob": -0.13928676534582068, "compression_ratio": 1.6312056737588652, "no_speech_prob": 0.012587080709636211}, {"id": 77, "seek": 53152, "start": 550.64, "end": 558.48, "text": " agent ultimately an embodied agent that that has a world model or can", "tokens": [51320, 9461, 6284, 364, 42046, 9461, 300, 300, 575, 257, 1002, 2316, 420, 393, 51712], "temperature": 0.0, "avg_logprob": -0.13928676534582068, "compression_ratio": 1.6312056737588652, "no_speech_prob": 0.012587080709636211}, {"id": 78, "seek": 55848, "start": 558.72, "end": 566.72, "text": " and create a world model through interactions with its environment how is that different from", "tokens": [50376, 293, 1884, 257, 1002, 2316, 807, 13280, 365, 1080, 2823, 577, 307, 300, 819, 490, 50776], "temperature": 0.0, "avg_logprob": -0.20117915061212355, "compression_ratio": 1.6787878787878787, "no_speech_prob": 0.001243269070982933}, {"id": 79, "seek": 55848, "start": 567.6, "end": 578.64, "text": " Lucune's approach at a very basic level very basic level a good is that they're a very similar", "tokens": [50820, 9593, 2613, 311, 3109, 412, 257, 588, 3875, 1496, 588, 3875, 1496, 257, 665, 307, 300, 436, 434, 257, 588, 2531, 51372], "temperature": 0.0, "avg_logprob": -0.20117915061212355, "compression_ratio": 1.6787878787878787, "no_speech_prob": 0.001243269070982933}, {"id": 80, "seek": 55848, "start": 578.64, "end": 584.32, "text": " idea it's uh you look at the parts of his architecture and the parts of the architecture", "tokens": [51372, 1558, 309, 311, 2232, 291, 574, 412, 264, 3166, 295, 702, 9482, 293, 264, 3166, 295, 264, 9482, 51656], "temperature": 0.0, "avg_logprob": -0.20117915061212355, "compression_ratio": 1.6787878787878787, "no_speech_prob": 0.001243269070982933}, {"id": 81, "seek": 58432, "start": 584.32, "end": 590.8000000000001, "text": " put forth in the Alberta plan they line up one one for one yeah we're trying to do the same thing", "tokens": [50364, 829, 5220, 294, 264, 43279, 1393, 436, 1622, 493, 472, 472, 337, 472, 1338, 321, 434, 1382, 281, 360, 264, 912, 551, 50688], "temperature": 0.0, "avg_logprob": -0.10539923157802848, "compression_ratio": 1.7839195979899498, "no_speech_prob": 0.012613780796527863}, {"id": 82, "seek": 58432, "start": 593.2800000000001, "end": 597.44, "text": " we're going about it slightly different and we could talk about that but I think", "tokens": [50812, 321, 434, 516, 466, 309, 4748, 819, 293, 321, 727, 751, 466, 300, 457, 286, 519, 51020], "temperature": 0.0, "avg_logprob": -0.10539923157802848, "compression_ratio": 1.7839195979899498, "no_speech_prob": 0.012613780796527863}, {"id": 83, "seek": 58432, "start": 598.08, "end": 602.1600000000001, "text": " to just to focus on the differences might even be to distract from the big message the big", "tokens": [51052, 281, 445, 281, 1879, 322, 264, 7300, 1062, 754, 312, 281, 9945, 490, 264, 955, 3636, 264, 955, 51256], "temperature": 0.0, "avg_logprob": -0.10539923157802848, "compression_ratio": 1.7839195979899498, "no_speech_prob": 0.012613780796527863}, {"id": 84, "seek": 58432, "start": 602.1600000000001, "end": 608.4000000000001, "text": " message is that you have to have a goal and you have to have a model of the world and", "tokens": [51256, 3636, 307, 300, 291, 362, 281, 362, 257, 3387, 293, 291, 362, 281, 362, 257, 2316, 295, 264, 1002, 293, 51568], "temperature": 0.0, "avg_logprob": -0.10539923157802848, "compression_ratio": 1.7839195979899498, "no_speech_prob": 0.012613780796527863}, {"id": 85, "seek": 60840, "start": 609.36, "end": 618.16, "text": " and then everything is driven by using that model to take action and to plan action at various levels", "tokens": [50412, 293, 550, 1203, 307, 9555, 538, 1228, 300, 2316, 281, 747, 3069, 293, 281, 1393, 3069, 412, 3683, 4358, 50852], "temperature": 0.0, "avg_logprob": -0.11347543216142499, "compression_ratio": 1.75, "no_speech_prob": 0.0009842254221439362}, {"id": 86, "seek": 60840, "start": 618.16, "end": 627.6, "text": " of abstraction in order to to achieve the goal okay so to me this is really what intelligence is", "tokens": [50852, 295, 37765, 294, 1668, 281, 281, 4584, 264, 3387, 1392, 370, 281, 385, 341, 307, 534, 437, 7599, 307, 51324], "temperature": 0.0, "avg_logprob": -0.11347543216142499, "compression_ratio": 1.75, "no_speech_prob": 0.0009842254221439362}, {"id": 87, "seek": 60840, "start": 627.6, "end": 632.88, "text": " understand the world use your understanding to get to achieve to achieve your your goals", "tokens": [51324, 1223, 264, 1002, 764, 428, 3701, 281, 483, 281, 4584, 281, 4584, 428, 428, 5493, 51588], "temperature": 0.0, "avg_logprob": -0.11347543216142499, "compression_ratio": 1.75, "no_speech_prob": 0.0009842254221439362}, {"id": 88, "seek": 63288, "start": 633.52, "end": 638.32, "text": " I'd like to formulate the goals as as a reward and I'm super comfortable with that other people", "tokens": [50396, 286, 1116, 411, 281, 47881, 264, 5493, 382, 382, 257, 7782, 293, 286, 478, 1687, 4619, 365, 300, 661, 561, 50636], "temperature": 0.0, "avg_logprob": -0.11932704133807488, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.021254997700452805}, {"id": 89, "seek": 63288, "start": 639.2, "end": 642.4, "text": " sort of grudgingly accept rewards even though it seems kind of low level", "tokens": [50680, 1333, 295, 677, 532, 3249, 356, 3241, 17203, 754, 1673, 309, 2544, 733, 295, 2295, 1496, 50840], "temperature": 0.0, "avg_logprob": -0.11932704133807488, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.021254997700452805}, {"id": 90, "seek": 63288, "start": 643.12, "end": 648.88, "text": " but it's a it's a natural approach I think I think it's something that almost makes more", "tokens": [50876, 457, 309, 311, 257, 309, 311, 257, 3303, 3109, 286, 519, 286, 519, 309, 311, 746, 300, 1920, 1669, 544, 51164], "temperature": 0.0, "avg_logprob": -0.11932704133807488, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.021254997700452805}, {"id": 91, "seek": 63288, "start": 648.88, "end": 653.52, "text": " sense to people who aren't steep and deep learning and to supervise learning and one thing I found", "tokens": [51164, 2020, 281, 561, 567, 3212, 380, 16841, 293, 2452, 2539, 293, 281, 37971, 908, 2539, 293, 472, 551, 286, 1352, 51396], "temperature": 0.0, "avg_logprob": -0.11932704133807488, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.021254997700452805}, {"id": 92, "seek": 63288, "start": 653.52, "end": 660.0, "text": " interesting in in the roadmap that you've laid out for the Alberta plan you start with supervised", "tokens": [51396, 1880, 294, 294, 264, 35738, 300, 291, 600, 9897, 484, 337, 264, 43279, 1393, 291, 722, 365, 46533, 51720], "temperature": 0.0, "avg_logprob": -0.11932704133807488, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.021254997700452805}, {"id": 93, "seek": 66000, "start": 660.0, "end": 667.68, "text": " learning and why is that is it just because it's it's easy yeah I guess we do in a sense", "tokens": [50364, 2539, 293, 983, 307, 300, 307, 309, 445, 570, 309, 311, 309, 311, 1858, 1338, 286, 2041, 321, 360, 294, 257, 2020, 50748], "temperature": 0.0, "avg_logprob": -0.10435478596747676, "compression_ratio": 1.785, "no_speech_prob": 0.0016472873976454139}, {"id": 94, "seek": 66000, "start": 667.68, "end": 673.12, "text": " because we want to focus on well continual learning learning continually which is sort of", "tokens": [50748, 570, 321, 528, 281, 1879, 322, 731, 1421, 901, 2539, 2539, 22277, 597, 307, 1333, 295, 51020], "temperature": 0.0, "avg_logprob": -0.10435478596747676, "compression_ratio": 1.785, "no_speech_prob": 0.0016472873976454139}, {"id": 95, "seek": 66000, "start": 673.12, "end": 678.8, "text": " an obvious thing almost what learning means it has something that goes on at all times but", "tokens": [51020, 364, 6322, 551, 1920, 437, 2539, 1355, 309, 575, 746, 300, 1709, 322, 412, 439, 1413, 457, 51304], "temperature": 0.0, "avg_logprob": -0.10435478596747676, "compression_ratio": 1.785, "no_speech_prob": 0.0016472873976454139}, {"id": 96, "seek": 66000, "start": 680.0, "end": 688.8, "text": " the first steps getting continual learning with nonlinear networks is still challenging", "tokens": [51364, 264, 700, 4439, 1242, 1421, 901, 2539, 365, 2107, 28263, 9590, 307, 920, 7595, 51804], "temperature": 0.0, "avg_logprob": -0.10435478596747676, "compression_ratio": 1.785, "no_speech_prob": 0.0016472873976454139}, {"id": 97, "seek": 68880, "start": 688.8, "end": 695.3599999999999, "text": " even for supervised learning and so it's natural to start at the simplest possible case which involves", "tokens": [50364, 754, 337, 46533, 2539, 293, 370, 309, 311, 3303, 281, 722, 412, 264, 22811, 1944, 1389, 597, 11626, 50692], "temperature": 0.0, "avg_logprob": -0.05313514500129514, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.0020479431841522455}, {"id": 98, "seek": 68880, "start": 695.3599999999999, "end": 703.28, "text": " the fewest other factors and that's a supervised learning case yeah yeah it's funny let me just", "tokens": [50692, 264, 1326, 377, 661, 6771, 293, 300, 311, 257, 46533, 2539, 1389, 1338, 1338, 309, 311, 4074, 718, 385, 445, 51088], "temperature": 0.0, "avg_logprob": -0.05313514500129514, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.0020479431841522455}, {"id": 99, "seek": 68880, "start": 703.28, "end": 708.88, "text": " say a few words about that because there's sort of been a fight through a struggle throughout the", "tokens": [51088, 584, 257, 1326, 2283, 466, 300, 570, 456, 311, 1333, 295, 668, 257, 2092, 807, 257, 7799, 3710, 264, 51368], "temperature": 0.0, "avg_logprob": -0.05313514500129514, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.0020479431841522455}, {"id": 100, "seek": 68880, "start": 708.88, "end": 715.28, "text": " decades between supervised learning and reinforcement learning you know there's only so much oxygen", "tokens": [51368, 7878, 1296, 46533, 2539, 293, 29280, 2539, 291, 458, 456, 311, 787, 370, 709, 9169, 51688], "temperature": 0.0, "avg_logprob": -0.05313514500129514, "compression_ratio": 1.81651376146789, "no_speech_prob": 0.0020479431841522455}, {"id": 101, "seek": 71528, "start": 715.28, "end": 721.12, "text": " for learning methods and all the attention that's paid to supervised learning somewhat", "tokens": [50364, 337, 2539, 7150, 293, 439, 264, 3202, 300, 311, 4835, 281, 46533, 2539, 8344, 50656], "temperature": 0.0, "avg_logprob": -0.06694363564560094, "compression_ratio": 2.067873303167421, "no_speech_prob": 0.005292609333992004}, {"id": 102, "seek": 71528, "start": 721.12, "end": 726.0799999999999, "text": " detracts from reinforcement learning so there's a there's a there's a bit of a friendly competition", "tokens": [50656, 1141, 1897, 82, 490, 29280, 2539, 370, 456, 311, 257, 456, 311, 257, 456, 311, 257, 857, 295, 257, 9208, 6211, 50904], "temperature": 0.0, "avg_logprob": -0.06694363564560094, "compression_ratio": 2.067873303167421, "no_speech_prob": 0.005292609333992004}, {"id": 103, "seek": 71528, "start": 728.16, "end": 733.1999999999999, "text": " and supervised learning has always won the competition because supervised learning is so", "tokens": [51008, 293, 46533, 2539, 575, 1009, 1582, 264, 6211, 570, 46533, 2539, 307, 370, 51260], "temperature": 0.0, "avg_logprob": -0.06694363564560094, "compression_ratio": 2.067873303167421, "no_speech_prob": 0.005292609333992004}, {"id": 104, "seek": 71528, "start": 733.1999999999999, "end": 738.9599999999999, "text": " much more easy to put into practice and for people to use and it's sort of it's sort of", "tokens": [51260, 709, 544, 1858, 281, 829, 666, 3124, 293, 337, 561, 281, 764, 293, 309, 311, 1333, 295, 309, 311, 1333, 295, 51548], "temperature": 0.0, "avg_logprob": -0.06694363564560094, "compression_ratio": 2.067873303167421, "no_speech_prob": 0.005292609333992004}, {"id": 105, "seek": 71528, "start": 738.9599999999999, "end": 743.6, "text": " less ambitious but it's really important and really those of us who do reinforcement learning", "tokens": [51548, 1570, 20239, 457, 309, 311, 534, 1021, 293, 534, 729, 295, 505, 567, 360, 29280, 2539, 51780], "temperature": 0.0, "avg_logprob": -0.06694363564560094, "compression_ratio": 2.067873303167421, "no_speech_prob": 0.005292609333992004}, {"id": 106, "seek": 74360, "start": 743.6, "end": 750.0, "text": " or try to make whole agent architectures we are consumers of supervised learning outcomes we will", "tokens": [50364, 420, 853, 281, 652, 1379, 9461, 6331, 1303, 321, 366, 11883, 295, 46533, 2539, 10070, 321, 486, 50684], "temperature": 0.0, "avg_logprob": -0.12126613041711232, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.006282706744968891}, {"id": 107, "seek": 74360, "start": 750.0, "end": 755.12, "text": " use them as components of our overall architecture so we need them and we can work on them and we", "tokens": [50684, 764, 552, 382, 6677, 295, 527, 4787, 9482, 370, 321, 643, 552, 293, 321, 393, 589, 322, 552, 293, 321, 50940], "temperature": 0.0, "avg_logprob": -0.12126613041711232, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.006282706744968891}, {"id": 108, "seek": 74360, "start": 755.12, "end": 763.44, "text": " need to structure them for our purposes I saw one of your talks you make a distinction between", "tokens": [50940, 643, 281, 3877, 552, 337, 527, 9932, 286, 1866, 472, 295, 428, 6686, 291, 652, 257, 16844, 1296, 51356], "temperature": 0.0, "avg_logprob": -0.12126613041711232, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.006282706744968891}, {"id": 109, "seek": 76344, "start": 764.4000000000001, "end": 773.84, "text": " AI tools and AI agents and supervised learning falls into the tool category can you sort of", "tokens": [50412, 7318, 3873, 293, 7318, 12554, 293, 46533, 2539, 8804, 666, 264, 2290, 7719, 393, 291, 1333, 295, 50884], "temperature": 0.0, "avg_logprob": -0.11122346693469633, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.09521152079105377}, {"id": 110, "seek": 76344, "start": 773.84, "end": 780.32, "text": " start and and talk about the evolution of the Alberta plan and then present to listeners", "tokens": [50884, 722, 293, 293, 751, 466, 264, 9303, 295, 264, 43279, 1393, 293, 550, 1974, 281, 23274, 51208], "temperature": 0.0, "avg_logprob": -0.11122346693469633, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.09521152079105377}, {"id": 111, "seek": 76344, "start": 780.96, "end": 788.48, "text": " what it is in in its simplest form and that'll that'll give me a structure on which to hang", "tokens": [51240, 437, 309, 307, 294, 294, 1080, 22811, 1254, 293, 300, 603, 300, 603, 976, 385, 257, 3877, 322, 597, 281, 3967, 51616], "temperature": 0.0, "avg_logprob": -0.11122346693469633, "compression_ratio": 1.5632183908045978, "no_speech_prob": 0.09521152079105377}, {"id": 112, "seek": 78848, "start": 788.5600000000001, "end": 796.8000000000001, "text": " questions the Alberta plan is an attempt to understand intelligence as a as a primarily", "tokens": [50368, 1651, 264, 43279, 1393, 307, 364, 5217, 281, 1223, 7599, 382, 257, 382, 257, 10029, 50780], "temperature": 0.0, "avg_logprob": -0.16197588745976838, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.006475925445556641}, {"id": 113, "seek": 78848, "start": 796.8000000000001, "end": 804.48, "text": " a learning phenomenon assists us something that comes to understand its environment and and then", "tokens": [50780, 257, 2539, 14029, 49416, 505, 746, 300, 1487, 281, 1223, 1080, 2823, 293, 293, 550, 51164], "temperature": 0.0, "avg_logprob": -0.16197588745976838, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.006475925445556641}, {"id": 114, "seek": 78848, "start": 806.0, "end": 812.64, "text": " drives the environment to achieve goals so the first step in the Alberta plan is the structure", "tokens": [51240, 11754, 264, 2823, 281, 4584, 5493, 370, 264, 700, 1823, 294, 264, 43279, 1393, 307, 264, 3877, 51572], "temperature": 0.0, "avg_logprob": -0.16197588745976838, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.006475925445556641}, {"id": 115, "seek": 78848, "start": 812.64, "end": 817.28, "text": " between the agent the environment and their interaction form the interaction there's the", "tokens": [51572, 1296, 264, 9461, 264, 2823, 293, 641, 9285, 1254, 264, 9285, 456, 311, 264, 51804], "temperature": 0.0, "avg_logprob": -0.16197588745976838, "compression_ratio": 1.8969072164948453, "no_speech_prob": 0.006475925445556641}, {"id": 116, "seek": 81728, "start": 817.28, "end": 823.1999999999999, "text": " you're not exchanging states you're exchanging observations like sensors sensors visual touch", "tokens": [50364, 291, 434, 406, 6210, 9741, 4368, 291, 434, 6210, 9741, 18163, 411, 14840, 14840, 5056, 2557, 50660], "temperature": 0.0, "avg_logprob": -0.11308618871177115, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.0014747517416253686}, {"id": 117, "seek": 81728, "start": 823.1999999999999, "end": 831.76, "text": " auditory it's all abstract to those particulars but it's got to be genuine observations and not", "tokens": [50660, 17748, 827, 309, 311, 439, 12649, 281, 729, 21861, 685, 457, 309, 311, 658, 281, 312, 16699, 18163, 293, 406, 51088], "temperature": 0.0, "avg_logprob": -0.11308618871177115, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.0014747517416253686}, {"id": 118, "seek": 81728, "start": 831.76, "end": 839.52, "text": " state because state we don't we don't really have access to directly so that you know the", "tokens": [51088, 1785, 570, 1785, 321, 500, 380, 321, 500, 380, 534, 362, 2105, 281, 3838, 370, 300, 291, 458, 264, 51476], "temperature": 0.0, "avg_logprob": -0.11308618871177115, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.0014747517416253686}, {"id": 119, "seek": 81728, "start": 839.52, "end": 844.16, "text": " principles number one principle I'm trying to remember them as I speak but number one principle", "tokens": [51476, 9156, 1230, 472, 8665, 286, 478, 1382, 281, 1604, 552, 382, 286, 1710, 457, 1230, 472, 8665, 51708], "temperature": 0.0, "avg_logprob": -0.11308618871177115, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.0014747517416253686}, {"id": 120, "seek": 84416, "start": 844.16, "end": 852.0799999999999, "text": " is this this agent environment interaction is sacrosanct and number two is that learning or", "tokens": [50364, 307, 341, 341, 9461, 2823, 9285, 307, 4899, 2635, 282, 349, 293, 1230, 732, 307, 300, 2539, 420, 50760], "temperature": 0.0, "avg_logprob": -0.09672687167213076, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.002081017242744565}, {"id": 121, "seek": 84416, "start": 852.0799999999999, "end": 858.4, "text": " everything is is we could say continual I think we call it we say temporally uniform", "tokens": [50760, 1203, 307, 307, 321, 727, 584, 1421, 901, 286, 519, 321, 818, 309, 321, 584, 8219, 379, 9452, 51076], "temperature": 0.0, "avg_logprob": -0.09672687167213076, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.002081017242744565}, {"id": 122, "seek": 84416, "start": 859.52, "end": 864.56, "text": " temporally symmetric in in the Alberta plan which means that there are no special phases", "tokens": [51132, 8219, 379, 32330, 294, 294, 264, 43279, 1393, 597, 1355, 300, 456, 366, 572, 2121, 18764, 51384], "temperature": 0.0, "avg_logprob": -0.09672687167213076, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.002081017242744565}, {"id": 123, "seek": 84416, "start": 864.56, "end": 871.28, "text": " where you like training and test there's just life goes on and on you get rewards or you don't get", "tokens": [51384, 689, 291, 411, 3097, 293, 1500, 456, 311, 445, 993, 1709, 322, 293, 322, 291, 483, 17203, 420, 291, 500, 380, 483, 51720], "temperature": 0.0, "avg_logprob": -0.09672687167213076, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.002081017242744565}, {"id": 124, "seek": 87128, "start": 872.24, "end": 878.9599999999999, "text": " or you don't get the reward you want and you get your observations and there there is no teacher", "tokens": [50412, 420, 291, 500, 380, 483, 264, 7782, 291, 528, 293, 291, 483, 428, 18163, 293, 456, 456, 307, 572, 5027, 50748], "temperature": 0.0, "avg_logprob": -0.10729974599984976, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.0014543627621605992}, {"id": 125, "seek": 87128, "start": 878.9599999999999, "end": 890.16, "text": " other than rewards pains and pleasures and maybe I'm not getting the four principles right but", "tokens": [50748, 661, 813, 17203, 29774, 293, 48627, 293, 1310, 286, 478, 406, 1242, 264, 1451, 9156, 558, 457, 51308], "temperature": 0.0, "avg_logprob": -0.10729974599984976, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.0014543627621605992}, {"id": 126, "seek": 87128, "start": 890.16, "end": 896.0, "text": " another important point is that you are going to be forming a model and so you're going to plan", "tokens": [51308, 1071, 1021, 935, 307, 300, 291, 366, 516, 281, 312, 15745, 257, 2316, 293, 370, 291, 434, 516, 281, 1393, 51600], "temperature": 0.0, "avg_logprob": -0.10729974599984976, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.0014543627621605992}, {"id": 127, "seek": 89600, "start": 896.64, "end": 903.12, "text": " both trial and error learning directly from experience and learning a model and then planning", "tokens": [50396, 1293, 7308, 293, 6713, 2539, 3838, 490, 1752, 293, 2539, 257, 2316, 293, 550, 5038, 50720], "temperature": 0.0, "avg_logprob": -0.09290311862896015, "compression_ratio": 1.845771144278607, "no_speech_prob": 0.008572716265916824}, {"id": 128, "seek": 89600, "start": 903.12, "end": 909.44, "text": " with the model both these are important part of intelligence okay so those are that's the", "tokens": [50720, 365, 264, 2316, 1293, 613, 366, 1021, 644, 295, 7599, 1392, 370, 729, 366, 300, 311, 264, 51036], "temperature": 0.0, "avg_logprob": -0.09290311862896015, "compression_ratio": 1.845771144278607, "no_speech_prob": 0.008572716265916824}, {"id": 129, "seek": 89600, "start": 909.44, "end": 915.44, "text": " background then we outline there are 12 steps and the 12 steps really start with let's have", "tokens": [51036, 3678, 550, 321, 16387, 456, 366, 2272, 4439, 293, 264, 2272, 4439, 534, 722, 365, 718, 311, 362, 51336], "temperature": 0.0, "avg_logprob": -0.09290311862896015, "compression_ratio": 1.845771144278607, "no_speech_prob": 0.008572716265916824}, {"id": 130, "seek": 89600, "start": 915.44, "end": 921.52, "text": " learning that is temporally uniform let's have metal learning and metal learning maybe I should", "tokens": [51336, 2539, 300, 307, 8219, 379, 9452, 718, 311, 362, 5760, 2539, 293, 5760, 2539, 1310, 286, 820, 51640], "temperature": 0.0, "avg_logprob": -0.09290311862896015, "compression_ratio": 1.845771144278607, "no_speech_prob": 0.008572716265916824}, {"id": 131, "seek": 92152, "start": 921.52, "end": 928.24, "text": " stop and on that for a moment metal learning means learning to learn not just learning one function", "tokens": [50364, 1590, 293, 322, 300, 337, 257, 1623, 5760, 2539, 1355, 2539, 281, 1466, 406, 445, 2539, 472, 2445, 50700], "temperature": 0.0, "avg_logprob": -0.045936873084620425, "compression_ratio": 2.0210526315789474, "no_speech_prob": 0.016644082963466644}, {"id": 132, "seek": 92152, "start": 928.24, "end": 932.8, "text": " but once you are continually learning you're learning this and you're learning that you get", "tokens": [50700, 457, 1564, 291, 366, 22277, 2539, 291, 434, 2539, 341, 293, 291, 434, 2539, 300, 291, 483, 50928], "temperature": 0.0, "avg_logprob": -0.045936873084620425, "compression_ratio": 2.0210526315789474, "no_speech_prob": 0.016644082963466644}, {"id": 133, "seek": 92152, "start": 932.8, "end": 938.0799999999999, "text": " many many experiences learning and you can get better at learning you can use those repeated", "tokens": [50928, 867, 867, 5235, 2539, 293, 291, 393, 483, 1101, 412, 2539, 291, 393, 764, 729, 10477, 51192], "temperature": 0.0, "avg_logprob": -0.045936873084620425, "compression_ratio": 2.0210526315789474, "no_speech_prob": 0.016644082963466644}, {"id": 134, "seek": 92152, "start": 938.0799999999999, "end": 946.16, "text": " experience with repeatedly learning to make make future learning episodes more efficient so as part", "tokens": [51192, 1752, 365, 18227, 2539, 281, 652, 652, 2027, 2539, 9313, 544, 7148, 370, 382, 644, 51596], "temperature": 0.0, "avg_logprob": -0.045936873084620425, "compression_ratio": 2.0210526315789474, "no_speech_prob": 0.016644082963466644}, {"id": 135, "seek": 94616, "start": 946.24, "end": 953.4399999999999, "text": " of that you learn representations you learn features you learn step sizes", "tokens": [50368, 295, 300, 291, 1466, 33358, 291, 1466, 4122, 291, 1466, 1823, 11602, 50728], "temperature": 0.0, "avg_logprob": -0.09737218828762279, "compression_ratio": 1.8415300546448088, "no_speech_prob": 0.006092769093811512}, {"id": 136, "seek": 94616, "start": 955.68, "end": 960.8, "text": " okay so continual learning and then all the algorithms and once once we add", "tokens": [50840, 1392, 370, 1421, 901, 2539, 293, 550, 439, 264, 14642, 293, 1564, 1564, 321, 909, 51096], "temperature": 0.0, "avg_logprob": -0.09737218828762279, "compression_ratio": 1.8415300546448088, "no_speech_prob": 0.006092769093811512}, {"id": 137, "seek": 94616, "start": 960.8, "end": 965.8399999999999, "text": " metal learning and continual learning we have to in supervised learning then we extend that to", "tokens": [51096, 5760, 2539, 293, 1421, 901, 2539, 321, 362, 281, 294, 46533, 2539, 550, 321, 10101, 300, 281, 51348], "temperature": 0.0, "avg_logprob": -0.09737218828762279, "compression_ratio": 1.8415300546448088, "no_speech_prob": 0.006092769093811512}, {"id": 138, "seek": 94616, "start": 967.52, "end": 972.72, "text": " reinforcement learning which involves its own set of issues to get more interesting temporal", "tokens": [51432, 29280, 2539, 597, 11626, 1080, 1065, 992, 295, 2663, 281, 483, 544, 1880, 30881, 51692], "temperature": 0.0, "avg_logprob": -0.09737218828762279, "compression_ratio": 1.8415300546448088, "no_speech_prob": 0.006092769093811512}, {"id": 139, "seek": 97272, "start": 972.72, "end": 982.08, "text": " relationships and I think like the first six steps are crafting the basic algorithms of reinforcement", "tokens": [50364, 6159, 293, 286, 519, 411, 264, 700, 2309, 4439, 366, 29048, 264, 3875, 14642, 295, 29280, 50832], "temperature": 0.0, "avg_logprob": -0.11026316483815511, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.001206052373163402}, {"id": 140, "seek": 97272, "start": 982.08, "end": 990.08, "text": " working through them again to be continual and meta and then we start to bring in the the challenging", "tokens": [50832, 1364, 807, 552, 797, 281, 312, 1421, 901, 293, 19616, 293, 550, 321, 722, 281, 1565, 294, 264, 264, 7595, 51232], "temperature": 0.0, "avg_logprob": -0.11026316483815511, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.001206052373163402}, {"id": 141, "seek": 97272, "start": 990.08, "end": 997.0400000000001, "text": " issues like learning off policy and learning models of the world and then planning and the", "tokens": [51232, 2663, 411, 2539, 766, 3897, 293, 2539, 5245, 295, 264, 1002, 293, 550, 5038, 293, 264, 51580], "temperature": 0.0, "avg_logprob": -0.11026316483815511, "compression_ratio": 1.699421965317919, "no_speech_prob": 0.001206052373163402}, {"id": 142, "seek": 99704, "start": 997.8399999999999, "end": 1000.3199999999999, "text": " just to jump to the end the last step is about", "tokens": [50404, 445, 281, 3012, 281, 264, 917, 264, 1036, 1823, 307, 466, 50528], "temperature": 0.0, "avg_logprob": -0.16359062471251556, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0037054915446788073}, {"id": 143, "seek": 99704, "start": 1004.3199999999999, "end": 1009.52, "text": " AI, AI, AI's, AI intelligence augmentation", "tokens": [50728, 7318, 11, 7318, 11, 7318, 311, 11, 7318, 7599, 14501, 19631, 50988], "temperature": 0.0, "avg_logprob": -0.16359062471251556, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0037054915446788073}, {"id": 144, "seek": 99704, "start": 1011.76, "end": 1019.52, "text": " where we combine computers, AI's with our own minds to make make our own minds stronger", "tokens": [51100, 689, 321, 10432, 10807, 11, 7318, 311, 365, 527, 1065, 9634, 281, 652, 652, 527, 1065, 9634, 7249, 51488], "temperature": 0.0, "avg_logprob": -0.16359062471251556, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0037054915446788073}, {"id": 145, "seek": 99704, "start": 1020.9599999999999, "end": 1026.6399999999999, "text": " okay now one of the key steps in there was off policy learning and learning a model of the world", "tokens": [51560, 1392, 586, 472, 295, 264, 2141, 4439, 294, 456, 390, 766, 3897, 2539, 293, 2539, 257, 2316, 295, 264, 1002, 51844], "temperature": 0.0, "avg_logprob": -0.16359062471251556, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0037054915446788073}, {"id": 146, "seek": 102704, "start": 1027.84, "end": 1033.44, "text": " off policy learning means you want to be able to learn about things that you're not doing or you're", "tokens": [50404, 766, 3897, 2539, 1355, 291, 528, 281, 312, 1075, 281, 1466, 466, 721, 300, 291, 434, 406, 884, 420, 291, 434, 50684], "temperature": 0.0, "avg_logprob": -0.09655356051316902, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0004726909101009369}, {"id": 147, "seek": 102704, "start": 1033.44, "end": 1040.6399999999999, "text": " not because you're not doing all the way to completion so even like to recognize an object", "tokens": [50684, 406, 570, 291, 434, 406, 884, 439, 264, 636, 281, 19372, 370, 754, 411, 281, 5521, 364, 2657, 51044], "temperature": 0.0, "avg_logprob": -0.09655356051316902, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0004726909101009369}, {"id": 148, "seek": 102704, "start": 1040.6399999999999, "end": 1047.76, "text": " you look at the object and you say how would you you have to define that in some objective way", "tokens": [51044, 291, 574, 412, 264, 2657, 293, 291, 584, 577, 576, 291, 291, 362, 281, 6964, 300, 294, 512, 10024, 636, 51400], "temperature": 0.0, "avg_logprob": -0.09655356051316902, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0004726909101009369}, {"id": 149, "seek": 104776, "start": 1048.4, "end": 1053.28, "text": " and the best way to just do that is as a sub problem so", "tokens": [50396, 293, 264, 1151, 636, 281, 445, 360, 300, 307, 382, 257, 1422, 1154, 370, 50640], "temperature": 0.0, "avg_logprob": -0.14568697941767705, "compression_ratio": 1.7318435754189945, "no_speech_prob": 0.10657636821269989}, {"id": 150, "seek": 104776, "start": 1055.52, "end": 1063.44, "text": " yeah maybe maybe I'll just sort of stop there the most interesting strategy", "tokens": [50752, 1338, 1310, 1310, 286, 603, 445, 1333, 295, 1590, 456, 264, 881, 1880, 5206, 51148], "temperature": 0.0, "avg_logprob": -0.14568697941767705, "compression_ratio": 1.7318435754189945, "no_speech_prob": 0.10657636821269989}, {"id": 151, "seek": 104776, "start": 1065.28, "end": 1070.16, "text": " distinctive strategy by the Alberta plan is the pose is that the mind works by posing sub", "tokens": [51240, 27766, 5206, 538, 264, 43279, 1393, 307, 264, 10774, 307, 300, 264, 1575, 1985, 538, 40378, 1422, 51484], "temperature": 0.0, "avg_logprob": -0.14568697941767705, "compression_ratio": 1.7318435754189945, "no_speech_prob": 0.10657636821269989}, {"id": 152, "seek": 104776, "start": 1070.16, "end": 1075.2, "text": " problems for itself and then working on them and it's it's not it's sure it's got a main", "tokens": [51484, 2740, 337, 2564, 293, 550, 1364, 322, 552, 293, 309, 311, 309, 311, 406, 309, 311, 988, 309, 311, 658, 257, 2135, 51736], "temperature": 0.0, "avg_logprob": -0.14568697941767705, "compression_ratio": 1.7318435754189945, "no_speech_prob": 0.10657636821269989}, {"id": 153, "seek": 107520, "start": 1075.28, "end": 1080.48, "text": " problem which is to get reward but it's also has many thousands of sub problems it's also", "tokens": [50368, 1154, 597, 307, 281, 483, 7782, 457, 309, 311, 611, 575, 867, 5383, 295, 1422, 2740, 309, 311, 611, 50628], "temperature": 0.0, "avg_logprob": -0.07279391013658963, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.014052608981728554}, {"id": 154, "seek": 107520, "start": 1080.48, "end": 1085.8400000000001, "text": " working on simultaneously and since it's not behaving it cannot behave for all thousand", "tokens": [50628, 1364, 322, 16561, 293, 1670, 309, 311, 406, 35263, 309, 2644, 15158, 337, 439, 4714, 50896], "temperature": 0.0, "avg_logprob": -0.07279391013658963, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.014052608981728554}, {"id": 155, "seek": 107520, "start": 1085.8400000000001, "end": 1090.0800000000002, "text": " problems at once it has to pick one problem like perhaps the main problem and behave according to", "tokens": [50896, 2740, 412, 1564, 309, 575, 281, 1888, 472, 1154, 411, 4317, 264, 2135, 1154, 293, 15158, 4650, 281, 51108], "temperature": 0.0, "avg_logprob": -0.07279391013658963, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.014052608981728554}, {"id": 156, "seek": 107520, "start": 1090.0800000000002, "end": 1094.88, "text": " that so all the other things have to be able to learn from data that's not exactly on what they", "tokens": [51108, 300, 370, 439, 264, 661, 721, 362, 281, 312, 1075, 281, 1466, 490, 1412, 300, 311, 406, 2293, 322, 437, 436, 51348], "temperature": 0.0, "avg_logprob": -0.07279391013658963, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.014052608981728554}, {"id": 157, "seek": 107520, "start": 1094.88, "end": 1102.72, "text": " would do and this is called off policy learning and it's a key to learning to achieve auxiliary", "tokens": [51348, 576, 360, 293, 341, 307, 1219, 766, 3897, 2539, 293, 309, 311, 257, 2141, 281, 2539, 281, 4584, 43741, 51740], "temperature": 0.0, "avg_logprob": -0.07279391013658963, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.014052608981728554}, {"id": 158, "seek": 110272, "start": 1102.72, "end": 1108.72, "text": " sub problems and also it's a key to efficiently learning a model of the world yeah you you have", "tokens": [50364, 1422, 2740, 293, 611, 309, 311, 257, 2141, 281, 19621, 2539, 257, 2316, 295, 264, 1002, 1338, 291, 291, 362, 50664], "temperature": 0.0, "avg_logprob": -0.10002999078659784, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.0013872868148609996}, {"id": 159, "seek": 110272, "start": 1109.76, "end": 1117.3600000000001, "text": " something called the horde architecture is is that where that comes in when you you break", "tokens": [50716, 746, 1219, 264, 276, 15127, 9482, 307, 307, 300, 689, 300, 1487, 294, 562, 291, 291, 1821, 51096], "temperature": 0.0, "avg_logprob": -0.10002999078659784, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.0013872868148609996}, {"id": 160, "seek": 110272, "start": 1117.3600000000001, "end": 1125.3600000000001, "text": " a problem down into multiple sub tasks that that you learn I was one one paper where we", "tokens": [51096, 257, 1154, 760, 666, 3866, 1422, 9608, 300, 300, 291, 1466, 286, 390, 472, 472, 3035, 689, 321, 51496], "temperature": 0.0, "avg_logprob": -0.10002999078659784, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.0013872868148609996}, {"id": 161, "seek": 110272, "start": 1126.48, "end": 1129.92, "text": " we worked on that idea we developed that idea the horde is the horde of sub problems", "tokens": [51552, 321, 2732, 322, 300, 1558, 321, 4743, 300, 1558, 264, 276, 15127, 307, 264, 276, 15127, 295, 1422, 2740, 51724], "temperature": 0.0, "avg_logprob": -0.10002999078659784, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.0013872868148609996}, {"id": 162, "seek": 112992, "start": 1130.5600000000002, "end": 1138.24, "text": " each each demon in the horde which is it could be almost viewed like a single neuron in a neural", "tokens": [50396, 1184, 1184, 14283, 294, 264, 276, 15127, 597, 307, 309, 727, 312, 1920, 19174, 411, 257, 2167, 34090, 294, 257, 18161, 50780], "temperature": 0.0, "avg_logprob": -0.10473922320774623, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.0018081804737448692}, {"id": 163, "seek": 112992, "start": 1138.24, "end": 1144.64, "text": " network as achieving working towards a different task trying to predict a different thing or maybe", "tokens": [50780, 3209, 382, 19626, 1364, 3030, 257, 819, 5633, 1382, 281, 6069, 257, 819, 551, 420, 1310, 51100], "temperature": 0.0, "avg_logprob": -0.10473922320774623, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.0018081804737448692}, {"id": 164, "seek": 112992, "start": 1144.64, "end": 1151.8400000000001, "text": " trying to attain a different thing it's the view of the of the mind as decentralized there is one", "tokens": [51100, 1382, 281, 23766, 257, 819, 551, 309, 311, 264, 1910, 295, 264, 295, 264, 1575, 382, 32870, 456, 307, 472, 51460], "temperature": 0.0, "avg_logprob": -0.10473922320774623, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.0018081804737448692}, {"id": 165, "seek": 112992, "start": 1151.8400000000001, "end": 1157.52, "text": " goal and everything is ultimately driven towards one goal but still it's a useful structure to", "tokens": [51460, 3387, 293, 1203, 307, 6284, 9555, 3030, 472, 3387, 457, 920, 309, 311, 257, 4420, 3877, 281, 51744], "temperature": 0.0, "avg_logprob": -0.10473922320774623, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.0018081804737448692}, {"id": 166, "seek": 115752, "start": 1157.84, "end": 1165.92, "text": " to have different parts driving towards towards other goals how did you get together with john", "tokens": [50380, 281, 362, 819, 3166, 4840, 3030, 3030, 661, 5493, 577, 630, 291, 483, 1214, 365, 35097, 50784], "temperature": 0.0, "avg_logprob": -0.23913689815636838, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0058147842064499855}, {"id": 167, "seek": 115752, "start": 1165.92, "end": 1174.0, "text": " cormack was that primarily because you need the funding and it gives you a vehicle to raise", "tokens": [50784, 269, 687, 501, 390, 300, 10029, 570, 291, 643, 264, 6137, 293, 309, 2709, 291, 257, 5864, 281, 5300, 51188], "temperature": 0.0, "avg_logprob": -0.23913689815636838, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0058147842064499855}, {"id": 168, "seek": 115752, "start": 1174.0, "end": 1180.56, "text": " capital oh seriously I mean you you know Jan Lacoon's got meta behind him well it's just not it's", "tokens": [51188, 4238, 1954, 6638, 286, 914, 291, 291, 458, 4956, 40113, 4106, 311, 658, 19616, 2261, 796, 731, 309, 311, 445, 406, 309, 311, 51516], "temperature": 0.0, "avg_logprob": -0.23913689815636838, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0058147842064499855}, {"id": 169, "seek": 118056, "start": 1180.56, "end": 1187.2, "text": " not really comparable uh john's uh john's company is great but it's still like a 20 million dollar", "tokens": [50364, 406, 534, 25323, 2232, 35097, 311, 2232, 35097, 311, 2237, 307, 869, 457, 309, 311, 920, 411, 257, 945, 2459, 7241, 50696], "temperature": 0.0, "avg_logprob": -0.1161514641582102, "compression_ratio": 1.6647398843930636, "no_speech_prob": 0.04882058873772621}, {"id": 170, "seek": 118056, "start": 1187.2, "end": 1195.84, "text": " company and uh which is which is plenty of money for what we want to do now um john and I got together", "tokens": [50696, 2237, 293, 2232, 597, 307, 597, 307, 7140, 295, 1460, 337, 437, 321, 528, 281, 360, 586, 1105, 35097, 293, 286, 658, 1214, 51128], "temperature": 0.0, "avg_logprob": -0.1161514641582102, "compression_ratio": 1.6647398843930636, "no_speech_prob": 0.04882058873772621}, {"id": 171, "seek": 118056, "start": 1195.84, "end": 1202.8, "text": " because we had similar ideas about what was needed um and and also what was not needed", "tokens": [51128, 570, 321, 632, 2531, 3487, 466, 437, 390, 2978, 1105, 293, 293, 611, 437, 390, 406, 2978, 51476], "temperature": 0.0, "avg_logprob": -0.1161514641582102, "compression_ratio": 1.6647398843930636, "no_speech_prob": 0.04882058873772621}, {"id": 172, "seek": 120280, "start": 1203.52, "end": 1213.2, "text": " um to get to ai or agi um yeah so I read an art newspaper article an interview that john did", "tokens": [50400, 1105, 281, 483, 281, 9783, 420, 623, 72, 1105, 1338, 370, 286, 1401, 364, 1523, 13669, 7222, 364, 4049, 300, 35097, 630, 50884], "temperature": 0.0, "avg_logprob": -0.10301858811151414, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.023674961179494858}, {"id": 173, "seek": 120280, "start": 1214.32, "end": 1217.9199999999998, "text": " down in texas and uh I just could see that he was thinking about the way", "tokens": [50940, 760, 294, 535, 87, 296, 293, 2232, 286, 445, 727, 536, 300, 415, 390, 1953, 466, 264, 636, 51120], "temperature": 0.0, "avg_logprob": -0.10301858811151414, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.023674961179494858}, {"id": 174, "seek": 120280, "start": 1218.6399999999999, "end": 1221.44, "text": " thinking about things the way I was even though our backgrounds were quite different", "tokens": [51156, 1953, 466, 721, 264, 636, 286, 390, 754, 1673, 527, 17336, 645, 1596, 819, 51296], "temperature": 0.0, "avg_logprob": -0.10301858811151414, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.023674961179494858}, {"id": 175, "seek": 120280, "start": 1222.0, "end": 1227.28, "text": " you thought of intelligence you had to there's a few principles that needed to be worked out", "tokens": [51324, 291, 1194, 295, 7599, 291, 632, 281, 456, 311, 257, 1326, 9156, 300, 2978, 281, 312, 2732, 484, 51588], "temperature": 0.0, "avg_logprob": -0.10301858811151414, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.023674961179494858}, {"id": 176, "seek": 120280, "start": 1227.28, "end": 1232.32, "text": " rather than so this isn't a huge program to write it's a few principles we have to figure those out", "tokens": [51588, 2831, 813, 370, 341, 1943, 380, 257, 2603, 1461, 281, 2464, 309, 311, 257, 1326, 9156, 321, 362, 281, 2573, 729, 484, 51840], "temperature": 0.0, "avg_logprob": -0.10301858811151414, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.023674961179494858}, {"id": 177, "seek": 123280, "start": 1233.04, "end": 1239.84, "text": " um not that many maybe uh maybe 10 000 lines instead of 10 million lines of code", "tokens": [50376, 1105, 406, 300, 867, 1310, 2232, 1310, 1266, 13711, 3876, 2602, 295, 1266, 2459, 3876, 295, 3089, 50716], "temperature": 0.0, "avg_logprob": -0.08126552714857944, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0006561665795743465}, {"id": 178, "seek": 123280, "start": 1240.72, "end": 1248.24, "text": " so it's easy to get it's relatively it's still it's still it's still hard to get basic research", "tokens": [50760, 370, 309, 311, 1858, 281, 483, 309, 311, 7226, 309, 311, 920, 309, 311, 920, 309, 311, 920, 1152, 281, 483, 3875, 2132, 51136], "temperature": 0.0, "avg_logprob": -0.08126552714857944, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0006561665795743465}, {"id": 179, "seek": 123280, "start": 1248.24, "end": 1254.3999999999999, "text": " funding in the world it's easy to get funding towards uh applications of ai large language models", "tokens": [51136, 6137, 294, 264, 1002, 309, 311, 1858, 281, 483, 6137, 3030, 2232, 5821, 295, 9783, 2416, 2856, 5245, 51444], "temperature": 0.0, "avg_logprob": -0.08126552714857944, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0006561665795743465}, {"id": 180, "seek": 123280, "start": 1254.3999999999999, "end": 1261.76, "text": " particularly um anyway I'm really enjoying working at keen and being able to focus on the ideas", "tokens": [51444, 4098, 1105, 4033, 286, 478, 534, 9929, 1364, 412, 20297, 293, 885, 1075, 281, 1879, 322, 264, 3487, 51812], "temperature": 0.0, "avg_logprob": -0.08126552714857944, "compression_ratio": 1.7452830188679245, "no_speech_prob": 0.0006561665795743465}, {"id": 181, "seek": 126176, "start": 1262.56, "end": 1271.2, "text": " and uh it's a it's a it's a it's a calm company we um um", "tokens": [50404, 293, 2232, 309, 311, 257, 309, 311, 257, 309, 311, 257, 309, 311, 257, 7151, 2237, 321, 1105, 1105, 50836], "temperature": 0.0, "avg_logprob": -0.09050614806427353, "compression_ratio": 1.7409326424870466, "no_speech_prob": 0.002047983231022954}, {"id": 182, "seek": 126176, "start": 1272.96, "end": 1277.76, "text": " there's a lot of thinking involved a lot of contemplation a lot there is also experiments", "tokens": [50924, 456, 311, 257, 688, 295, 1953, 3288, 257, 688, 295, 19935, 399, 257, 688, 456, 307, 611, 12050, 51164], "temperature": 0.0, "avg_logprob": -0.09050614806427353, "compression_ratio": 1.7409326424870466, "no_speech_prob": 0.002047983231022954}, {"id": 183, "seek": 126176, "start": 1277.76, "end": 1283.2, "text": " and we're trying to get um the engineering side of it is really important uh but for me it's", "tokens": [51164, 293, 321, 434, 1382, 281, 483, 1105, 264, 7043, 1252, 295, 309, 307, 534, 1021, 2232, 457, 337, 385, 309, 311, 51436], "temperature": 0.0, "avg_logprob": -0.09050614806427353, "compression_ratio": 1.7409326424870466, "no_speech_prob": 0.002047983231022954}, {"id": 184, "seek": 126176, "start": 1283.2, "end": 1288.72, "text": " been really great just to be able to regroup my thoughts and think about them very carefully and", "tokens": [51436, 668, 534, 869, 445, 281, 312, 1075, 281, 319, 17377, 452, 4598, 293, 519, 466, 552, 588, 7500, 293, 51712], "temperature": 0.0, "avg_logprob": -0.09050614806427353, "compression_ratio": 1.7409326424870466, "no_speech_prob": 0.002047983231022954}, {"id": 185, "seek": 128872, "start": 1289.28, "end": 1295.92, "text": " push them forward but keen is is implementing the alberta plan is that right I mean that's", "tokens": [50392, 2944, 552, 2128, 457, 20297, 307, 307, 18114, 264, 419, 607, 1328, 1393, 307, 300, 558, 286, 914, 300, 311, 50724], "temperature": 0.0, "avg_logprob": -0.07789019398067308, "compression_ratio": 1.9234693877551021, "no_speech_prob": 0.007454214617609978}, {"id": 186, "seek": 128872, "start": 1295.92, "end": 1301.52, "text": " that's uh the project well the alberta plan is a research plan it's like a five-year research plan", "tokens": [50724, 300, 311, 2232, 264, 1716, 731, 264, 419, 607, 1328, 1393, 307, 257, 2132, 1393, 309, 311, 411, 257, 1732, 12, 5294, 2132, 1393, 51004], "temperature": 0.0, "avg_logprob": -0.07789019398067308, "compression_ratio": 1.9234693877551021, "no_speech_prob": 0.007454214617609978}, {"id": 187, "seek": 128872, "start": 1302.08, "end": 1308.88, "text": " and so research is something you don't implement research is something you conduct and and it", "tokens": [51032, 293, 370, 2132, 307, 746, 291, 500, 380, 4445, 2132, 307, 746, 291, 6018, 293, 293, 309, 51372], "temperature": 0.0, "avg_logprob": -0.07789019398067308, "compression_ratio": 1.9234693877551021, "no_speech_prob": 0.007454214617609978}, {"id": 188, "seek": 128872, "start": 1308.88, "end": 1316.48, "text": " doesn't always end up the way you want but um yeah I wouldn't say implement is the right word", "tokens": [51372, 1177, 380, 1009, 917, 493, 264, 636, 291, 528, 457, 1105, 1338, 286, 2759, 380, 584, 4445, 307, 264, 558, 1349, 51752], "temperature": 0.0, "avg_logprob": -0.07789019398067308, "compression_ratio": 1.9234693877551021, "no_speech_prob": 0.007454214617609978}, {"id": 189, "seek": 131648, "start": 1316.48, "end": 1323.3600000000001, "text": " not yet but but the the work you're doing at keen is is informed by the alberta", "tokens": [50364, 406, 1939, 457, 457, 264, 264, 589, 291, 434, 884, 412, 20297, 307, 307, 11740, 538, 264, 419, 607, 1328, 50708], "temperature": 0.0, "avg_logprob": -0.10940203768141726, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.003762968350201845}, {"id": 190, "seek": 131648, "start": 1324.08, "end": 1330.24, "text": " yeah I'm absolutely I'm working on the alberta plan uh uh and and the end goal at keen is to", "tokens": [50744, 1338, 286, 478, 3122, 286, 478, 1364, 322, 264, 419, 607, 1328, 1393, 2232, 2232, 293, 293, 264, 917, 3387, 412, 20297, 307, 281, 51052], "temperature": 0.0, "avg_logprob": -0.10940203768141726, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.003762968350201845}, {"id": 191, "seek": 131648, "start": 1330.24, "end": 1339.6, "text": " create the uh the embodied intelligence described by the alberta plan you don't sound very yeah", "tokens": [51052, 1884, 264, 2232, 264, 42046, 7599, 7619, 538, 264, 419, 607, 1328, 1393, 291, 500, 380, 1626, 588, 1338, 51520], "temperature": 0.0, "avg_logprob": -0.10940203768141726, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.003762968350201845}, {"id": 192, "seek": 131648, "start": 1339.6, "end": 1345.44, "text": " very confident well a plan is just a plan and you know I think there's a good chance that it", "tokens": [51520, 588, 6679, 731, 257, 1393, 307, 445, 257, 1393, 293, 291, 458, 286, 519, 456, 311, 257, 665, 2931, 300, 309, 51812], "temperature": 0.0, "avg_logprob": -0.10940203768141726, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.003762968350201845}, {"id": 193, "seek": 134544, "start": 1345.44, "end": 1351.68, "text": " will work out as planned but you know a five-year plan you make another one after four or three years", "tokens": [50364, 486, 589, 484, 382, 8589, 457, 291, 458, 257, 1732, 12, 5294, 1393, 291, 652, 1071, 472, 934, 1451, 420, 1045, 924, 50676], "temperature": 0.0, "avg_logprob": -0.08759383412150594, "compression_ratio": 1.7633136094674555, "no_speech_prob": 0.0006260189693421125}, {"id": 194, "seek": 134544, "start": 1353.76, "end": 1361.52, "text": " yeah so I wouldn't I wouldn't uh presume to to know how it's gonna work out but at the same time", "tokens": [50780, 1338, 370, 286, 2759, 380, 286, 2759, 380, 2232, 43283, 281, 281, 458, 577, 309, 311, 799, 589, 484, 457, 412, 264, 912, 565, 51168], "temperature": 0.0, "avg_logprob": -0.08759383412150594, "compression_ratio": 1.7633136094674555, "no_speech_prob": 0.0006260189693421125}, {"id": 195, "seek": 134544, "start": 1361.52, "end": 1368.8, "text": " we have to make you know we have to make our bets we have to think hard about it um just knowing um", "tokens": [51168, 321, 362, 281, 652, 291, 458, 321, 362, 281, 652, 527, 39922, 321, 362, 281, 519, 1152, 466, 309, 1105, 445, 5276, 1105, 51532], "temperature": 0.0, "avg_logprob": -0.08759383412150594, "compression_ratio": 1.7633136094674555, "no_speech_prob": 0.0006260189693421125}, {"id": 196, "seek": 136880, "start": 1369.76, "end": 1376.8, "text": " you know we we may well be right but you know you your work is primarily in reinforcement", "tokens": [50412, 291, 458, 321, 321, 815, 731, 312, 558, 457, 291, 458, 291, 428, 589, 307, 10029, 294, 29280, 50764], "temperature": 0.0, "avg_logprob": -0.20888543533066573, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.013605819083750248}, {"id": 197, "seek": 136880, "start": 1376.8, "end": 1382.3999999999999, "text": " learning you're you wrote the book on reinforcement learning temporal difference learning and", "tokens": [50764, 2539, 291, 434, 291, 4114, 264, 1446, 322, 29280, 2539, 30881, 2649, 2539, 293, 51044], "temperature": 0.0, "avg_logprob": -0.20888543533066573, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.013605819083750248}, {"id": 198, "seek": 136880, "start": 1383.9199999999998, "end": 1392.6399999999999, "text": " uh lambda and all of that is is this I mean this is this seems a much more ambitious", "tokens": [51120, 2232, 13607, 293, 439, 295, 300, 307, 307, 341, 286, 914, 341, 307, 341, 2544, 257, 709, 544, 20239, 51556], "temperature": 0.0, "avg_logprob": -0.20888543533066573, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.013605819083750248}, {"id": 199, "seek": 139264, "start": 1393.6000000000001, "end": 1403.76, "text": " uh project is this was it the the success of the transformer scaling that that said well you know", "tokens": [50412, 2232, 1716, 307, 341, 390, 309, 264, 264, 2245, 295, 264, 31782, 21589, 300, 300, 848, 731, 291, 458, 50920], "temperature": 0.0, "avg_logprob": -0.12366758633966315, "compression_ratio": 1.7305389221556886, "no_speech_prob": 0.018537089228630066}, {"id": 200, "seek": 139264, "start": 1404.5600000000002, "end": 1411.2800000000002, "text": " let's do that with rl let's why why are these guys uh uh you know everyone's celebrating what", "tokens": [50960, 718, 311, 360, 300, 365, 367, 75, 718, 311, 983, 983, 366, 613, 1074, 2232, 2232, 291, 458, 1518, 311, 15252, 437, 51296], "temperature": 0.0, "avg_logprob": -0.12366758633966315, "compression_ratio": 1.7305389221556886, "no_speech_prob": 0.018537089228630066}, {"id": 201, "seek": 139264, "start": 1411.2800000000002, "end": 1416.96, "text": " they're doing but but there's much more to be done no no what what you're seeing the alberta plan", "tokens": [51296, 436, 434, 884, 457, 457, 456, 311, 709, 544, 281, 312, 1096, 572, 572, 437, 437, 291, 434, 2577, 264, 419, 607, 1328, 1393, 51580], "temperature": 0.0, "avg_logprob": -0.12366758633966315, "compression_ratio": 1.7305389221556886, "no_speech_prob": 0.018537089228630066}, {"id": 202, "seek": 141696, "start": 1416.96, "end": 1423.1200000000001, "text": " is is perhaps bigger than the book but this has always been the plan we've always in AI", "tokens": [50364, 307, 307, 4317, 3801, 813, 264, 1446, 457, 341, 575, 1009, 668, 264, 1393, 321, 600, 1009, 294, 7318, 50672], "temperature": 0.0, "avg_logprob": -0.08660024820372116, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.011325014755129814}, {"id": 203, "seek": 141696, "start": 1423.1200000000001, "end": 1429.52, "text": " tried to understand all of the mind and reproduce it in computers and so that's an that's that is a", "tokens": [50672, 3031, 281, 1223, 439, 295, 264, 1575, 293, 29501, 309, 294, 10807, 293, 370, 300, 311, 364, 300, 311, 300, 307, 257, 50992], "temperature": 0.0, "avg_logprob": -0.08660024820372116, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.011325014755129814}, {"id": 204, "seek": 141696, "start": 1429.52, "end": 1438.24, "text": " big enormous ambition that's what it's always been so the large language models are a bit", "tokens": [50992, 955, 11322, 22814, 300, 311, 437, 309, 311, 1009, 668, 370, 264, 2416, 2856, 5245, 366, 257, 857, 51428], "temperature": 0.0, "avg_logprob": -0.08660024820372116, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.011325014755129814}, {"id": 205, "seek": 141696, "start": 1440.08, "end": 1444.16, "text": " a bit disappointing in some sense I mean it's really good that people are getting excited", "tokens": [51520, 257, 857, 25054, 294, 512, 2020, 286, 914, 309, 311, 534, 665, 300, 561, 366, 1242, 2919, 51724], "temperature": 0.0, "avg_logprob": -0.08660024820372116, "compression_ratio": 1.7476190476190476, "no_speech_prob": 0.011325014755129814}, {"id": 206, "seek": 144416, "start": 1444.24, "end": 1452.0800000000002, "text": " and people are wanting to learn about it but um but it's not it's I don't envision that it's the", "tokens": [50368, 293, 561, 366, 7935, 281, 1466, 466, 309, 457, 1105, 457, 309, 311, 406, 309, 311, 286, 500, 380, 24739, 300, 309, 311, 264, 50760], "temperature": 0.0, "avg_logprob": -0.08565994061921772, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.003943319898098707}, {"id": 207, "seek": 144416, "start": 1452.72, "end": 1462.24, "text": " direction um that will be most uh productive to pursue now you know who knows what I do know", "tokens": [50792, 3513, 1105, 300, 486, 312, 881, 2232, 13304, 281, 12392, 586, 291, 458, 567, 3255, 437, 286, 360, 458, 51268], "temperature": 0.0, "avg_logprob": -0.08565994061921772, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.003943319898098707}, {"id": 208, "seek": 144416, "start": 1462.24, "end": 1467.92, "text": " is it's not the most direction that's useful for me to pursue um I I'm much more interested in", "tokens": [51268, 307, 309, 311, 406, 264, 881, 3513, 300, 311, 4420, 337, 385, 281, 12392, 1105, 286, 286, 478, 709, 544, 3102, 294, 51552], "temperature": 0.0, "avg_logprob": -0.08565994061921772, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.003943319898098707}, {"id": 209, "seek": 144416, "start": 1467.92, "end": 1473.3600000000001, "text": " actions and goals and how an agent can tell what's true and what's not true all of those", "tokens": [51552, 5909, 293, 5493, 293, 577, 364, 9461, 393, 980, 437, 311, 2074, 293, 437, 311, 406, 2074, 439, 295, 729, 51824], "temperature": 0.0, "avg_logprob": -0.08565994061921772, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.003943319898098707}, {"id": 210, "seek": 147336, "start": 1473.36, "end": 1482.4799999999998, "text": " things are missing from large language models so uh um no I'm not they're not really what what are", "tokens": [50364, 721, 366, 5361, 490, 2416, 2856, 5245, 370, 2232, 1105, 572, 286, 478, 406, 436, 434, 406, 534, 437, 437, 366, 50820], "temperature": 0.0, "avg_logprob": -0.12131926507660837, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.0034276950173079967}, {"id": 211, "seek": 147336, "start": 1482.4799999999998, "end": 1488.7199999999998, "text": " they what they are doing that's important is they're showing uh what you can do with uh computation", "tokens": [50820, 436, 437, 436, 366, 884, 300, 311, 1021, 307, 436, 434, 4099, 2232, 437, 291, 393, 360, 365, 2232, 24903, 51132], "temperature": 0.0, "avg_logprob": -0.12131926507660837, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.0034276950173079967}, {"id": 212, "seek": 147336, "start": 1488.7199999999998, "end": 1497.52, "text": " and and networks um and learning that you can get enormously complex um things and you can", "tokens": [51132, 293, 293, 9590, 1105, 293, 2539, 300, 291, 393, 483, 39669, 3997, 1105, 721, 293, 291, 393, 51572], "temperature": 0.0, "avg_logprob": -0.12131926507660837, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.0034276950173079967}, {"id": 213, "seek": 149752, "start": 1497.6, "end": 1503.44, "text": " incorporate a lot of data it just shows the power for those who needed to be shown that", "tokens": [50368, 16091, 257, 688, 295, 1412, 309, 445, 3110, 264, 1347, 337, 729, 567, 2978, 281, 312, 4898, 300, 50660], "temperature": 0.0, "avg_logprob": -0.1096511963875063, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.013214933685958385}, {"id": 214, "seek": 149752, "start": 1505.36, "end": 1515.28, "text": " and and it could be uh an interface between humans and and whatever you end up creating", "tokens": [50756, 293, 293, 309, 727, 312, 2232, 364, 9226, 1296, 6255, 293, 293, 2035, 291, 917, 493, 4084, 51252], "temperature": 0.0, "avg_logprob": -0.1096511963875063, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.013214933685958385}, {"id": 215, "seek": 149752, "start": 1515.28, "end": 1523.84, "text": " the agents you end up creating you still need a language interface to communicate yeah but I don't", "tokens": [51252, 264, 12554, 291, 917, 493, 4084, 291, 920, 643, 257, 2856, 9226, 281, 7890, 1338, 457, 286, 500, 380, 51680], "temperature": 0.0, "avg_logprob": -0.1096511963875063, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.013214933685958385}, {"id": 216, "seek": 152384, "start": 1524.8, "end": 1529.84, "text": " I'm I doubt that what we're doing with large language models today will contribute to that", "tokens": [50412, 286, 478, 286, 6385, 300, 437, 321, 434, 884, 365, 2416, 2856, 5245, 965, 486, 10586, 281, 300, 50664], "temperature": 0.0, "avg_logprob": -0.13191536822950983, "compression_ratio": 1.9476439790575917, "no_speech_prob": 0.004064044915139675}, {"id": 217, "seek": 152384, "start": 1529.84, "end": 1535.52, "text": " oh is that right yeah I mean in other words the models that you want to build the agents you want", "tokens": [50664, 1954, 307, 300, 558, 1338, 286, 914, 294, 661, 2283, 264, 5245, 300, 291, 528, 281, 1322, 264, 12554, 291, 528, 50948], "temperature": 0.0, "avg_logprob": -0.13191536822950983, "compression_ratio": 1.9476439790575917, "no_speech_prob": 0.004064044915139675}, {"id": 218, "seek": 152384, "start": 1535.52, "end": 1542.3999999999999, "text": " to build would learn language uh as as part of the learning process yeah so it's like we say", "tokens": [50948, 281, 1322, 576, 1466, 2856, 2232, 382, 382, 644, 295, 264, 2539, 1399, 1338, 370, 309, 311, 411, 321, 584, 51292], "temperature": 0.0, "avg_logprob": -0.13191536822950983, "compression_ratio": 1.9476439790575917, "no_speech_prob": 0.004064044915139675}, {"id": 219, "seek": 152384, "start": 1543.12, "end": 1548.56, "text": " language language last you know language not not language first with large language models", "tokens": [51328, 2856, 2856, 1036, 291, 458, 2856, 406, 406, 2856, 700, 365, 2416, 2856, 5245, 51600], "temperature": 0.0, "avg_logprob": -0.13191536822950983, "compression_ratio": 1.9476439790575917, "no_speech_prob": 0.004064044915139675}, {"id": 220, "seek": 154856, "start": 1548.56, "end": 1554.32, "text": " are language first we just say large language last just as Jan McCoon says we need to do you", "tokens": [50364, 366, 2856, 700, 321, 445, 584, 2416, 2856, 1036, 445, 382, 4956, 12061, 4106, 1619, 321, 643, 281, 360, 291, 50652], "temperature": 0.0, "avg_logprob": -0.11305382810992959, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.0052980477921664715}, {"id": 221, "seek": 154856, "start": 1554.32, "end": 1559.28, "text": " know rat level intelligence and then cat level intelligence and we have to get those figured", "tokens": [50652, 458, 5937, 1496, 7599, 293, 550, 3857, 1496, 7599, 293, 321, 362, 281, 483, 729, 8932, 50900], "temperature": 0.0, "avg_logprob": -0.11305382810992959, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.0052980477921664715}, {"id": 222, "seek": 154856, "start": 1559.28, "end": 1565.44, "text": " out before we should try to make human level intelligence uh so where are you on the plan I", "tokens": [50900, 484, 949, 321, 820, 853, 281, 652, 1952, 1496, 7599, 2232, 370, 689, 366, 291, 322, 264, 1393, 286, 51208], "temperature": 0.0, "avg_logprob": -0.11305382810992959, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.0052980477921664715}, {"id": 223, "seek": 154856, "start": 1565.44, "end": 1574.48, "text": " mean you you figured out reinforcement learning you can build agents uh you there are various", "tokens": [51208, 914, 291, 291, 8932, 484, 29280, 2539, 291, 393, 1322, 12554, 2232, 291, 456, 366, 3683, 51660], "temperature": 0.0, "avg_logprob": -0.11305382810992959, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.0052980477921664715}, {"id": 224, "seek": 157448, "start": 1574.48, "end": 1582.24, "text": " architectures for creating representations from from various kinds of sensory input", "tokens": [50364, 6331, 1303, 337, 4084, 33358, 490, 490, 3683, 3685, 295, 27233, 4846, 50752], "temperature": 0.0, "avg_logprob": -0.11017341613769531, "compression_ratio": 1.5875, "no_speech_prob": 0.004067341331392527}, {"id": 225, "seek": 157448, "start": 1584.16, "end": 1592.8, "text": " and and at that representation level then you can plan efficiently so where in all of that", "tokens": [50848, 293, 293, 412, 300, 10290, 1496, 550, 291, 393, 1393, 19621, 370, 689, 294, 439, 295, 300, 51280], "temperature": 0.0, "avg_logprob": -0.11017341613769531, "compression_ratio": 1.5875, "no_speech_prob": 0.004067341331392527}, {"id": 226, "seek": 157448, "start": 1593.92, "end": 1598.72, "text": " are are you in your research well it's a little hard to explain non-technically", "tokens": [51336, 366, 366, 291, 294, 428, 2132, 731, 309, 311, 257, 707, 1152, 281, 2903, 2107, 12, 29113, 984, 51576], "temperature": 0.0, "avg_logprob": -0.11017341613769531, "compression_ratio": 1.5875, "no_speech_prob": 0.004067341331392527}, {"id": 227, "seek": 159872, "start": 1598.8, "end": 1605.3600000000001, "text": " but you can say some things certainly you can say that the various steps", "tokens": [50368, 457, 291, 393, 584, 512, 721, 3297, 291, 393, 584, 300, 264, 3683, 4439, 50696], "temperature": 0.0, "avg_logprob": -0.09491430010114398, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.03960171341896057}, {"id": 228, "seek": 159872, "start": 1606.96, "end": 1612.48, "text": " are not done entirely sequentially you you're always looking for areas of opportunity where", "tokens": [50776, 366, 406, 1096, 7696, 5123, 3137, 291, 291, 434, 1009, 1237, 337, 3179, 295, 2650, 689, 51052], "temperature": 0.0, "avg_logprob": -0.09491430010114398, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.03960171341896057}, {"id": 229, "seek": 159872, "start": 1612.48, "end": 1618.4, "text": " you can make an increment of progress and those could be you know on step 10 or they could be on", "tokens": [51052, 291, 393, 652, 364, 26200, 295, 4205, 293, 729, 727, 312, 291, 458, 322, 1823, 1266, 420, 436, 727, 312, 322, 51348], "temperature": 0.0, "avg_logprob": -0.09491430010114398, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.03960171341896057}, {"id": 230, "seek": 159872, "start": 1618.4, "end": 1625.28, "text": " step three but you also I could also try to be very rough and say that we're we're at about step", "tokens": [51348, 1823, 1045, 457, 291, 611, 286, 727, 611, 853, 281, 312, 588, 5903, 293, 584, 300, 321, 434, 321, 434, 412, 466, 1823, 51692], "temperature": 0.0, "avg_logprob": -0.09491430010114398, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.03960171341896057}, {"id": 231, "seek": 162528, "start": 1625.36, "end": 1632.48, "text": " four now we are still doing things where we're changing the basic underlying", "tokens": [50368, 1451, 586, 321, 366, 920, 884, 721, 689, 321, 434, 4473, 264, 3875, 14217, 50724], "temperature": 0.0, "avg_logprob": -0.06751767476399739, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.01047769095748663}, {"id": 232, "seek": 162528, "start": 1633.2, "end": 1640.6399999999999, "text": " fundamental reinforcement learning algorithms we are not done with that we need more efficient", "tokens": [50760, 8088, 29280, 2539, 14642, 321, 366, 406, 1096, 365, 300, 321, 643, 544, 7148, 51132], "temperature": 0.0, "avg_logprob": -0.06751767476399739, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.01047769095748663}, {"id": 233, "seek": 162528, "start": 1640.6399999999999, "end": 1648.0, "text": " algorithms and I'm excited about some of the changes new ideas we're developing recently", "tokens": [51132, 14642, 293, 286, 478, 2919, 466, 512, 295, 264, 2962, 777, 3487, 321, 434, 6416, 3938, 51500], "temperature": 0.0, "avg_logprob": -0.06751767476399739, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.01047769095748663}, {"id": 234, "seek": 162528, "start": 1648.0, "end": 1653.76, "text": " about how that can be done can you talk about those new ideas at all okay well one of the big", "tokens": [51500, 466, 577, 300, 393, 312, 1096, 393, 291, 751, 466, 729, 777, 3487, 412, 439, 1392, 731, 472, 295, 264, 955, 51788], "temperature": 0.0, "avg_logprob": -0.06751767476399739, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.01047769095748663}, {"id": 235, "seek": 165376, "start": 1653.76, "end": 1660.96, "text": " things is efficient off-policy learning and the use of important sampling important sampling is", "tokens": [50364, 721, 307, 7148, 766, 12, 12892, 2632, 2539, 293, 264, 764, 295, 1021, 21179, 1021, 21179, 307, 50724], "temperature": 0.0, "avg_logprob": -0.060403111469314756, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.0027990052476525307}, {"id": 236, "seek": 165376, "start": 1660.96, "end": 1665.76, "text": " where you see how likely you're to do things under your target and your behavior policies", "tokens": [50724, 689, 291, 536, 577, 3700, 291, 434, 281, 360, 721, 833, 428, 3779, 293, 428, 5223, 7657, 50964], "temperature": 0.0, "avg_logprob": -0.060403111469314756, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.0027990052476525307}, {"id": 237, "seek": 165376, "start": 1665.76, "end": 1673.92, "text": " and you adjust the returns based on those the ratios of those two and for a long time I thought", "tokens": [50964, 293, 291, 4369, 264, 11247, 2361, 322, 729, 264, 32435, 295, 729, 732, 293, 337, 257, 938, 565, 286, 1194, 51372], "temperature": 0.0, "avg_logprob": -0.060403111469314756, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.0027990052476525307}, {"id": 238, "seek": 165376, "start": 1673.92, "end": 1681.76, "text": " that was the only way to adjust the returns but now the forward correction of the returns I think", "tokens": [51372, 300, 390, 264, 787, 636, 281, 4369, 264, 11247, 457, 586, 264, 2128, 19984, 295, 264, 11247, 286, 519, 51764], "temperature": 0.0, "avg_logprob": -0.060403111469314756, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.0027990052476525307}, {"id": 239, "seek": 168176, "start": 1681.76, "end": 1692.8, "text": " can be done by by changing your expectations so like if you're expecting a good thing to happen", "tokens": [50364, 393, 312, 1096, 538, 538, 4473, 428, 9843, 370, 411, 498, 291, 434, 9650, 257, 665, 551, 281, 1051, 50916], "temperature": 0.0, "avg_logprob": -0.07648057829249989, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0011333407601341605}, {"id": 240, "seek": 168176, "start": 1692.8, "end": 1698.32, "text": " you're expecting a good action to be taken and then a different action was taken a more exploratory", "tokens": [50916, 291, 434, 9650, 257, 665, 3069, 281, 312, 2726, 293, 550, 257, 819, 3069, 390, 2726, 257, 544, 24765, 4745, 51192], "temperature": 0.0, "avg_logprob": -0.07648057829249989, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0011333407601341605}, {"id": 241, "seek": 168176, "start": 1698.32, "end": 1706.32, "text": " action so this is a deviation from your target policy which would be more greedy and one way to", "tokens": [51192, 3069, 370, 341, 307, 257, 25163, 490, 428, 3779, 3897, 597, 576, 312, 544, 28228, 293, 472, 636, 281, 51592], "temperature": 0.0, "avg_logprob": -0.07648057829249989, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0011333407601341605}, {"id": 242, "seek": 168176, "start": 1706.32, "end": 1710.8, "text": " take into account the deviation from the target policy is to just say oh okay now I've done something", "tokens": [51592, 747, 666, 2696, 264, 25163, 490, 264, 3779, 3897, 307, 281, 445, 584, 1954, 1392, 586, 286, 600, 1096, 746, 51816], "temperature": 0.0, "avg_logprob": -0.07648057829249989, "compression_ratio": 1.8537735849056605, "no_speech_prob": 0.0011333407601341605}, {"id": 243, "seek": 171080, "start": 1711.44, "end": 1715.36, "text": " not best so I'm just going to adjust my level now you're going to expect a little a little less", "tokens": [50396, 406, 1151, 370, 286, 478, 445, 516, 281, 4369, 452, 1496, 586, 291, 434, 516, 281, 2066, 257, 707, 257, 707, 1570, 50592], "temperature": 0.0, "avg_logprob": -0.10427992856955226, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.002979564480483532}, {"id": 244, "seek": 171080, "start": 1716.08, "end": 1718.96, "text": " and there's a way there's a systematic way of doing that", "tokens": [50628, 293, 456, 311, 257, 636, 456, 311, 257, 27249, 636, 295, 884, 300, 50772], "temperature": 0.0, "avg_logprob": -0.10427992856955226, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.002979564480483532}, {"id": 245, "seek": 171080, "start": 1721.28, "end": 1727.12, "text": " that's gives us a new way to handle the off-policiness of of our returns", "tokens": [50888, 300, 311, 2709, 505, 257, 777, 636, 281, 4813, 264, 766, 12, 12892, 299, 1324, 295, 295, 527, 11247, 51180], "temperature": 0.0, "avg_logprob": -0.10427992856955226, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.002979564480483532}, {"id": 246, "seek": 171080, "start": 1727.84, "end": 1733.52, "text": " and so this gives a whole new family of algorithms so that's exciting now", "tokens": [51216, 293, 370, 341, 2709, 257, 1379, 777, 1605, 295, 14642, 370, 300, 311, 4670, 586, 51500], "temperature": 0.0, "avg_logprob": -0.10427992856955226, "compression_ratio": 1.670391061452514, "no_speech_prob": 0.002979564480483532}, {"id": 247, "seek": 173352, "start": 1734.32, "end": 1742.24, "text": " exciting maybe mostly for me I think maybe the most accessible direction of of of excitement", "tokens": [50404, 4670, 1310, 5240, 337, 385, 286, 519, 1310, 264, 881, 9515, 3513, 295, 295, 295, 14755, 50800], "temperature": 0.0, "avg_logprob": -0.13634528869237655, "compression_ratio": 1.8172588832487309, "no_speech_prob": 0.0007671292987652123}, {"id": 248, "seek": 173352, "start": 1742.8, "end": 1748.08, "text": " of novelty is in continual right so there's I'm going to say a bunch of things and to me", "tokens": [50828, 295, 44805, 307, 294, 1421, 901, 558, 370, 456, 311, 286, 478, 516, 281, 584, 257, 3840, 295, 721, 293, 281, 385, 51092], "temperature": 0.0, "avg_logprob": -0.13634528869237655, "compression_ratio": 1.8172588832487309, "no_speech_prob": 0.0007671292987652123}, {"id": 249, "seek": 173352, "start": 1748.08, "end": 1753.36, "text": " they're all going to have the same solution continual learning meta learning representation", "tokens": [51092, 436, 434, 439, 516, 281, 362, 264, 912, 3827, 1421, 901, 2539, 19616, 2539, 10290, 51356], "temperature": 0.0, "avg_logprob": -0.13634528869237655, "compression_ratio": 1.8172588832487309, "no_speech_prob": 0.0007671292987652123}, {"id": 250, "seek": 173352, "start": 1753.36, "end": 1759.76, "text": " learning learning to learn learning how to generalize state how to construct a state", "tokens": [51356, 2539, 2539, 281, 1466, 2539, 577, 281, 2674, 1125, 1785, 577, 281, 7690, 257, 1785, 51676], "temperature": 0.0, "avg_logprob": -0.13634528869237655, "compression_ratio": 1.8172588832487309, "no_speech_prob": 0.0007671292987652123}, {"id": 251, "seek": 175976, "start": 1759.76, "end": 1767.04, "text": " representation feature finding that whole thing is is is coming and it will be a kind of", "tokens": [50364, 10290, 4111, 5006, 300, 1379, 551, 307, 307, 307, 1348, 293, 309, 486, 312, 257, 733, 295, 50728], "temperature": 0.0, "avg_logprob": -0.08124714944420791, "compression_ratio": 1.8911917098445596, "no_speech_prob": 0.007934195920825005}, {"id": 252, "seek": 175976, "start": 1768.4, "end": 1773.6, "text": " it's just a new kind of a way a new kind of way of doing the learning in deep networks", "tokens": [50796, 309, 311, 445, 257, 777, 733, 295, 257, 636, 257, 777, 733, 295, 636, 295, 884, 264, 2539, 294, 2452, 9590, 51056], "temperature": 0.0, "avg_logprob": -0.08124714944420791, "compression_ratio": 1.8911917098445596, "no_speech_prob": 0.007934195920825005}, {"id": 253, "seek": 175976, "start": 1775.68, "end": 1782.08, "text": " and I call it dynamic learning nets see a dynamic learning nets have learning at three levels", "tokens": [51160, 293, 286, 818, 309, 8546, 2539, 36170, 536, 257, 8546, 2539, 36170, 362, 2539, 412, 1045, 4358, 51480], "temperature": 0.0, "avg_logprob": -0.08124714944420791, "compression_ratio": 1.8911917098445596, "no_speech_prob": 0.007934195920825005}, {"id": 254, "seek": 175976, "start": 1782.08, "end": 1787.36, "text": " whereas usually our neural networks only learn at one level they learn the level of the weights", "tokens": [51480, 9735, 2673, 527, 18161, 9590, 787, 1466, 412, 472, 1496, 436, 1466, 264, 1496, 295, 264, 17443, 51744], "temperature": 0.0, "avg_logprob": -0.08124714944420791, "compression_ratio": 1.8911917098445596, "no_speech_prob": 0.007934195920825005}, {"id": 255, "seek": 178736, "start": 1788.0, "end": 1793.12, "text": " and in addition we also want to learn at the level of step sizes so all of every place you", "tokens": [50396, 293, 294, 4500, 321, 611, 528, 281, 1466, 412, 264, 1496, 295, 1823, 11602, 370, 439, 295, 633, 1081, 291, 50652], "temperature": 0.0, "avg_logprob": -0.08829884962602096, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0005031631444580853}, {"id": 256, "seek": 178736, "start": 1793.12, "end": 1798.0, "text": " have a weight in your network you're also going to have a step size so a step size is sometimes", "tokens": [50652, 362, 257, 3364, 294, 428, 3209, 291, 434, 611, 516, 281, 362, 257, 1823, 2744, 370, 257, 1823, 2744, 307, 2171, 50896], "temperature": 0.0, "avg_logprob": -0.08829884962602096, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0005031631444580853}, {"id": 257, "seek": 178736, "start": 1798.0, "end": 1801.4399999999998, "text": " called a learning rate it's much better to call the step size because the learning rate will be", "tokens": [50896, 1219, 257, 2539, 3314, 309, 311, 709, 1101, 281, 818, 264, 1823, 2744, 570, 264, 2539, 3314, 486, 312, 51068], "temperature": 0.0, "avg_logprob": -0.08829884962602096, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0005031631444580853}, {"id": 258, "seek": 178736, "start": 1801.4399999999998, "end": 1807.6, "text": " influenced by many other things so if we imagine a whole network all these weights next to each", "tokens": [51068, 15269, 538, 867, 661, 721, 370, 498, 321, 3811, 257, 1379, 3209, 439, 613, 17443, 958, 281, 1184, 51376], "temperature": 0.0, "avg_logprob": -0.08829884962602096, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0005031631444580853}, {"id": 259, "seek": 178736, "start": 1807.6, "end": 1814.24, "text": " weight is a step size that is adjusted by an adaptive process that's adapted in a meta learning way", "tokens": [51376, 3364, 307, 257, 1823, 2744, 300, 307, 19871, 538, 364, 27912, 1399, 300, 311, 20871, 294, 257, 19616, 2539, 636, 51708], "temperature": 0.0, "avg_logprob": -0.08829884962602096, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0005031631444580853}, {"id": 260, "seek": 181424, "start": 1814.24, "end": 1820.0, "text": " a meta gradient way towards making the system learn better rather than just perform better", "tokens": [50364, 257, 19616, 16235, 636, 3030, 1455, 264, 1185, 1466, 1101, 2831, 813, 445, 2042, 1101, 50652], "temperature": 0.0, "avg_logprob": -0.12468869758374763, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.0015006153844296932}, {"id": 261, "seek": 181424, "start": 1820.0, "end": 1825.76, "text": " an instantaneous moment in time learning rates or step sizes don't affect the function they don't", "tokens": [50652, 364, 45596, 1623, 294, 565, 2539, 6846, 420, 1823, 11602, 500, 380, 3345, 264, 2445, 436, 500, 380, 50940], "temperature": 0.0, "avg_logprob": -0.12468869758374763, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.0015006153844296932}, {"id": 262, "seek": 181424, "start": 1825.76, "end": 1829.1200000000001, "text": " affect some function implemented in a particular point in time they don't affect with the network", "tokens": [50940, 3345, 512, 2445, 12270, 294, 257, 1729, 935, 294, 565, 436, 500, 380, 3345, 365, 264, 3209, 51108], "temperature": 0.0, "avg_logprob": -0.12468869758374763, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.0015006153844296932}, {"id": 263, "seek": 181424, "start": 1829.1200000000001, "end": 1834.8, "text": " does they affect what the network learns and so if you can tune the step sizes you also get", "tokens": [51108, 775, 436, 3345, 437, 264, 3209, 27152, 293, 370, 498, 291, 393, 10864, 264, 1823, 11602, 291, 611, 483, 51392], "temperature": 0.0, "avg_logprob": -0.12468869758374763, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.0015006153844296932}, {"id": 264, "seek": 181424, "start": 1834.8, "end": 1841.84, "text": " learning to learn and learning to generalize well and things like that the last three the last", "tokens": [51392, 2539, 281, 1466, 293, 2539, 281, 2674, 1125, 731, 293, 721, 411, 300, 264, 1036, 1045, 264, 1036, 51744], "temperature": 0.0, "avg_logprob": -0.12468869758374763, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.0015006153844296932}, {"id": 265, "seek": 184184, "start": 1841.84, "end": 1848.8, "text": " element that we wanted to have be adaptive weights step sizes the third one is the connection pattern", "tokens": [50364, 4478, 300, 321, 1415, 281, 362, 312, 27912, 17443, 1823, 11602, 264, 2636, 472, 307, 264, 4984, 5102, 50712], "temperature": 0.0, "avg_logprob": -0.07921409606933594, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0037053648848086596}, {"id": 266, "seek": 184184, "start": 1849.6, "end": 1856.24, "text": " so who's connected to who and so this will be done by an accretive process", "tokens": [50752, 370, 567, 311, 4582, 281, 567, 293, 370, 341, 486, 312, 1096, 538, 364, 1317, 1505, 488, 1399, 51084], "temperature": 0.0, "avg_logprob": -0.07921409606933594, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0037053648848086596}, {"id": 267, "seek": 184184, "start": 1858.48, "end": 1864.1599999999999, "text": " like let's say you start with a linear unit and it learns say a value function or a policy", "tokens": [51196, 411, 718, 311, 584, 291, 722, 365, 257, 8213, 4985, 293, 309, 27152, 584, 257, 2158, 2445, 420, 257, 3897, 51480], "temperature": 0.0, "avg_logprob": -0.07921409606933594, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0037053648848086596}, {"id": 268, "seek": 184184, "start": 1864.1599999999999, "end": 1870.1599999999999, "text": " and it does the best it can with the features available and and then it needs to induce the", "tokens": [51480, 293, 309, 775, 264, 1151, 309, 393, 365, 264, 4122, 2435, 293, 293, 550, 309, 2203, 281, 41263, 264, 51780], "temperature": 0.0, "avg_logprob": -0.07921409606933594, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0037053648848086596}, {"id": 269, "seek": 187016, "start": 1870.16, "end": 1875.28, "text": " creation of new features because you need to learn a nonlinear function of your original", "tokens": [50364, 8016, 295, 777, 4122, 570, 291, 643, 281, 1466, 257, 2107, 28263, 2445, 295, 428, 3380, 50620], "temperature": 0.0, "avg_logprob": -0.06098273323803413, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.00012727313151117414}, {"id": 270, "seek": 187016, "start": 1875.28, "end": 1882.48, "text": " signals and so you need to create new features that have become available to that linear unit", "tokens": [50620, 12354, 293, 370, 291, 643, 281, 1884, 777, 4122, 300, 362, 1813, 2435, 281, 300, 8213, 4985, 50980], "temperature": 0.0, "avg_logprob": -0.06098273323803413, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.00012727313151117414}, {"id": 271, "seek": 187016, "start": 1882.48, "end": 1888.72, "text": " and in this way you grow in a sort of organic way a system that can learn nonlinear functions", "tokens": [50980, 293, 294, 341, 636, 291, 1852, 294, 257, 1333, 295, 10220, 636, 257, 1185, 300, 393, 1466, 2107, 28263, 6828, 51292], "temperature": 0.0, "avg_logprob": -0.06098273323803413, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.00012727313151117414}, {"id": 272, "seek": 187016, "start": 1890.96, "end": 1898.4, "text": " and so this is just a different way of ending up with a deep network that was all learned", "tokens": [51404, 293, 370, 341, 307, 445, 257, 819, 636, 295, 8121, 493, 365, 257, 2452, 3209, 300, 390, 439, 3264, 51776], "temperature": 0.0, "avg_logprob": -0.06098273323803413, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.00012727313151117414}, {"id": 273, "seek": 189840, "start": 1898.4, "end": 1904.5600000000002, "text": " including all the features dynamic learning that's where is the data the input data coming from", "tokens": [50364, 3009, 439, 264, 4122, 8546, 2539, 300, 311, 689, 307, 264, 1412, 264, 4846, 1412, 1348, 490, 50672], "temperature": 0.0, "avg_logprob": -0.12105892751818505, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.00521807512268424}, {"id": 274, "seek": 189840, "start": 1904.5600000000002, "end": 1909.68, "text": " well the the input data and reinforcement just comes from life from doing things seeing things", "tokens": [50672, 731, 264, 264, 4846, 1412, 293, 29280, 445, 1487, 490, 993, 490, 884, 721, 2577, 721, 50928], "temperature": 0.0, "avg_logprob": -0.12105892751818505, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.00521807512268424}, {"id": 275, "seek": 189840, "start": 1909.68, "end": 1914.0800000000002, "text": " right there is no labeled data set yeah maybe I should have said this from the very beginning", "tokens": [50928, 558, 456, 307, 572, 21335, 1412, 992, 1338, 1310, 286, 820, 362, 848, 341, 490, 264, 588, 2863, 51148], "temperature": 0.0, "avg_logprob": -0.12105892751818505, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.00521807512268424}, {"id": 276, "seek": 189840, "start": 1914.0800000000002, "end": 1921.3600000000001, "text": " the whole idea of I call it experiential AI is that you know what makes you data you're you you", "tokens": [51148, 264, 1379, 1558, 295, 286, 818, 309, 49611, 831, 7318, 307, 300, 291, 458, 437, 1669, 291, 1412, 291, 434, 291, 291, 51512], "temperature": 0.0, "avg_logprob": -0.12105892751818505, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.00521807512268424}, {"id": 277, "seek": 189840, "start": 1921.3600000000001, "end": 1927.92, "text": " grow up as a baby and you play with things and you see things and you do things and that's the", "tokens": [51512, 1852, 493, 382, 257, 3186, 293, 291, 862, 365, 721, 293, 291, 536, 721, 293, 291, 360, 721, 293, 300, 311, 264, 51840], "temperature": 0.0, "avg_logprob": -0.12105892751818505, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.00521807512268424}, {"id": 278, "seek": 192792, "start": 1927.92, "end": 1933.68, "text": " data and the trick of reinforcement learning is how do you turn that kind of data into something", "tokens": [50364, 1412, 293, 264, 4282, 295, 29280, 2539, 307, 577, 360, 291, 1261, 300, 733, 295, 1412, 666, 746, 50652], "temperature": 0.0, "avg_logprob": -0.08082061343722874, "compression_ratio": 1.9450980392156862, "no_speech_prob": 0.00034588915877975523}, {"id": 279, "seek": 192792, "start": 1933.68, "end": 1939.28, "text": " you can learn from and grow a mind up from so the the beauty and the limitation of supervised learning", "tokens": [50652, 291, 393, 1466, 490, 293, 1852, 257, 1575, 493, 490, 370, 264, 264, 6643, 293, 264, 27432, 295, 46533, 2539, 50932], "temperature": 0.0, "avg_logprob": -0.08082061343722874, "compression_ratio": 1.9450980392156862, "no_speech_prob": 0.00034588915877975523}, {"id": 280, "seek": 192792, "start": 1939.28, "end": 1944.4, "text": " is they say well let's not worry about that for now let's assume that somehow we have a data set", "tokens": [50932, 307, 436, 584, 731, 718, 311, 406, 3292, 466, 300, 337, 586, 718, 311, 6552, 300, 6063, 321, 362, 257, 1412, 992, 51188], "temperature": 0.0, "avg_logprob": -0.08082061343722874, "compression_ratio": 1.9450980392156862, "no_speech_prob": 0.00034588915877975523}, {"id": 281, "seek": 192792, "start": 1944.4, "end": 1949.92, "text": " with labeled things and let's let's work on this sub problem that's a great idea work on a sub problem", "tokens": [51188, 365, 21335, 721, 293, 718, 311, 718, 311, 589, 322, 341, 1422, 1154, 300, 311, 257, 869, 1558, 589, 322, 257, 1422, 1154, 51464], "temperature": 0.0, "avg_logprob": -0.08082061343722874, "compression_ratio": 1.9450980392156862, "no_speech_prob": 0.00034588915877975523}, {"id": 282, "seek": 192792, "start": 1949.92, "end": 1955.76, "text": " figure it out and then move on to the next thing but really we have to move on to the next thing", "tokens": [51464, 2573, 309, 484, 293, 550, 1286, 322, 281, 264, 958, 551, 457, 534, 321, 362, 281, 1286, 322, 281, 264, 958, 551, 51756], "temperature": 0.0, "avg_logprob": -0.08082061343722874, "compression_ratio": 1.9450980392156862, "no_speech_prob": 0.00034588915877975523}, {"id": 283, "seek": 195576, "start": 1955.76, "end": 1961.36, "text": " we have to worry about how the the data set quote data set is automatically created from", "tokens": [50364, 321, 362, 281, 3292, 466, 577, 264, 264, 1412, 992, 6513, 1412, 992, 307, 6772, 2942, 490, 50644], "temperature": 0.0, "avg_logprob": -0.08349448387775946, "compression_ratio": 1.8995983935742973, "no_speech_prob": 0.001926271477714181}, {"id": 284, "seek": 195576, "start": 1961.36, "end": 1967.12, "text": " the the training information there isn't ever a data set data set is is is such a misleading term", "tokens": [50644, 264, 264, 3097, 1589, 456, 1943, 380, 1562, 257, 1412, 992, 1412, 992, 307, 307, 307, 1270, 257, 36429, 1433, 50932], "temperature": 0.0, "avg_logprob": -0.08349448387775946, "compression_ratio": 1.8995983935742973, "no_speech_prob": 0.001926271477714181}, {"id": 285, "seek": 195576, "start": 1967.12, "end": 1972.08, "text": " it suggests that it's easy to to have this thing and store this thing and curate this thing", "tokens": [50932, 309, 13409, 300, 309, 311, 1858, 281, 281, 362, 341, 551, 293, 3531, 341, 551, 293, 1262, 473, 341, 551, 51180], "temperature": 0.0, "avg_logprob": -0.08349448387775946, "compression_ratio": 1.8995983935742973, "no_speech_prob": 0.001926271477714181}, {"id": 286, "seek": 195576, "start": 1972.08, "end": 1978.0, "text": " really life is full of you do things things happen and then there's one you know everything is", "tokens": [51180, 534, 993, 307, 1577, 295, 291, 360, 721, 721, 1051, 293, 550, 456, 311, 472, 291, 458, 1203, 307, 51476], "temperature": 0.0, "avg_logprob": -0.08349448387775946, "compression_ratio": 1.8995983935742973, "no_speech_prob": 0.001926271477714181}, {"id": 287, "seek": 195576, "start": 1978.0, "end": 1984.8799999999999, "text": " fleeting you you don't have a record of it and it would be enormously complex and not only valuable", "tokens": [51476, 7025, 9880, 291, 291, 500, 380, 362, 257, 2136, 295, 309, 293, 309, 576, 312, 39669, 3997, 293, 406, 787, 8263, 51820], "temperature": 0.0, "avg_logprob": -0.08349448387775946, "compression_ratio": 1.8995983935742973, "no_speech_prob": 0.001926271477714181}, {"id": 288, "seek": 198488, "start": 1984.88, "end": 1990.88, "text": " to have a record of it the the the feeling is totally different in reinforcement learning and", "tokens": [50364, 281, 362, 257, 2136, 295, 309, 264, 264, 264, 2633, 307, 3879, 819, 294, 29280, 2539, 293, 50664], "temperature": 0.0, "avg_logprob": -0.10814378291000555, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.001205930719152093}, {"id": 289, "seek": 198488, "start": 1990.88, "end": 1996.88, "text": " supervised learning and in particularly the way the way I would adjust it you know many people", "tokens": [50664, 46533, 2539, 293, 294, 4098, 264, 636, 264, 636, 286, 576, 4369, 309, 291, 458, 867, 561, 50964], "temperature": 0.0, "avg_logprob": -0.10814378291000555, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.001205930719152093}, {"id": 290, "seek": 198488, "start": 1997.68, "end": 2003.1200000000001, "text": " do reinforcement learning by creating a buffer or a record of all the experiences that have been", "tokens": [51004, 360, 29280, 2539, 538, 4084, 257, 21762, 420, 257, 2136, 295, 439, 264, 5235, 300, 362, 668, 51276], "temperature": 0.0, "avg_logprob": -0.10814378291000555, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.001205930719152093}, {"id": 291, "seek": 198488, "start": 2003.1200000000001, "end": 2010.88, "text": " been retained that have been occurred at least for some period of time and I think that's that's", "tokens": [51276, 668, 33438, 300, 362, 668, 11068, 412, 1935, 337, 512, 2896, 295, 565, 293, 286, 519, 300, 311, 300, 311, 51664], "temperature": 0.0, "avg_logprob": -0.10814378291000555, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.001205930719152093}, {"id": 292, "seek": 201088, "start": 2011.5200000000002, "end": 2017.8400000000001, "text": " uh an appealing but but it's it's not where the action the answer is the answer is", "tokens": [50396, 2232, 364, 23842, 457, 457, 309, 311, 309, 311, 406, 689, 264, 3069, 264, 1867, 307, 264, 1867, 307, 50712], "temperature": 0.0, "avg_logprob": -0.11713066320309694, "compression_ratio": 1.9162303664921465, "no_speech_prob": 0.0005273664137348533}, {"id": 293, "seek": 201088, "start": 2019.0400000000002, "end": 2026.0, "text": " embracing the fleeting nature of data and and making most when it happens and then letting it go", "tokens": [50772, 31596, 264, 7025, 9880, 3687, 295, 1412, 293, 293, 1455, 881, 562, 309, 2314, 293, 550, 8295, 309, 352, 51120], "temperature": 0.0, "avg_logprob": -0.11713066320309694, "compression_ratio": 1.9162303664921465, "no_speech_prob": 0.0005273664137348533}, {"id": 294, "seek": 201088, "start": 2026.5600000000002, "end": 2032.5600000000002, "text": " well that's why you want to make an embodied system so that you have all the the five senses or", "tokens": [51148, 731, 300, 311, 983, 291, 528, 281, 652, 364, 42046, 1185, 370, 300, 291, 362, 439, 264, 264, 1732, 17057, 420, 51448], "temperature": 0.0, "avg_logprob": -0.11713066320309694, "compression_ratio": 1.9162303664921465, "no_speech_prob": 0.0005273664137348533}, {"id": 295, "seek": 201088, "start": 2033.3600000000001, "end": 2039.6000000000001, "text": " or more so you need you need as you say an embodied system an interactive system that that", "tokens": [51488, 420, 544, 370, 291, 643, 291, 643, 382, 291, 584, 364, 42046, 1185, 364, 15141, 1185, 300, 300, 51800], "temperature": 0.0, "avg_logprob": -0.11713066320309694, "compression_ratio": 1.9162303664921465, "no_speech_prob": 0.0005273664137348533}, {"id": 296, "seek": 203960, "start": 2039.9199999999998, "end": 2047.36, "text": " influences its its input stream its sensory stream and that you get that interaction and for a long", "tokens": [50380, 21222, 1080, 1080, 4846, 4309, 1080, 27233, 4309, 293, 300, 291, 483, 300, 9285, 293, 337, 257, 938, 50752], "temperature": 0.0, "avg_logprob": -0.12313005198603091, "compression_ratio": 1.7251461988304093, "no_speech_prob": 0.0007789910887368023}, {"id": 297, "seek": 203960, "start": 2047.36, "end": 2054.96, "text": " creative time you can do this in simulation or you can do it in robotics there's still I still", "tokens": [50752, 5880, 565, 291, 393, 360, 341, 294, 16575, 420, 291, 393, 360, 309, 294, 34145, 456, 311, 920, 286, 920, 51132], "temperature": 0.0, "avg_logprob": -0.12313005198603091, "compression_ratio": 1.7251461988304093, "no_speech_prob": 0.0007789910887368023}, {"id": 298, "seek": 203960, "start": 2054.96, "end": 2060.3199999999997, "text": " know what's the best way or if the best ways do both and right or maybe first one and then the other", "tokens": [51132, 458, 437, 311, 264, 1151, 636, 420, 498, 264, 1151, 2098, 360, 1293, 293, 558, 420, 1310, 700, 472, 293, 550, 264, 661, 51400], "temperature": 0.0, "avg_logprob": -0.12313005198603091, "compression_ratio": 1.7251461988304093, "no_speech_prob": 0.0007789910887368023}, {"id": 299, "seek": 206032, "start": 2061.1200000000003, "end": 2070.8, "text": " John is interested in uh having um uh learning from video and he likes his his his view of the", "tokens": [50404, 2619, 307, 3102, 294, 2232, 1419, 1105, 2232, 2539, 490, 960, 293, 415, 5902, 702, 702, 702, 1910, 295, 264, 50888], "temperature": 0.0, "avg_logprob": -0.12464071420522836, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.10219559073448181}, {"id": 300, "seek": 206032, "start": 2070.8, "end": 2076.88, "text": " experience is you have massive numbers of video streams like you're viewing you know 500 channels", "tokens": [50888, 1752, 307, 291, 362, 5994, 3547, 295, 960, 15842, 411, 291, 434, 17480, 291, 458, 5923, 9235, 51192], "temperature": 0.0, "avg_logprob": -0.12464071420522836, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.10219559073448181}, {"id": 301, "seek": 206032, "start": 2076.88, "end": 2084.4, "text": " of television and then you can switch switch to look at one look at another one um uh other people", "tokens": [51192, 295, 8815, 293, 550, 291, 393, 3679, 3679, 281, 574, 412, 472, 574, 412, 1071, 472, 1105, 2232, 661, 561, 51568], "temperature": 0.0, "avg_logprob": -0.12464071420522836, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.10219559073448181}, {"id": 302, "seek": 208440, "start": 2084.4, "end": 2092.32, "text": " in in in keen my close colleague Joseph Modial he's uh interested in robotics and he thinks the", "tokens": [50364, 294, 294, 294, 20297, 452, 1998, 13532, 11170, 6583, 831, 415, 311, 2232, 3102, 294, 34145, 293, 415, 7309, 264, 50760], "temperature": 0.0, "avg_logprob": -0.1194133873445442, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0018962827743962407}, {"id": 303, "seek": 208440, "start": 2092.32, "end": 2098.8, "text": " best way to get an appropriate in data stream is to actually build robotic hardware um", "tokens": [50760, 1151, 636, 281, 483, 364, 6854, 294, 1412, 4309, 307, 281, 767, 1322, 30468, 8837, 1105, 51084], "temperature": 0.0, "avg_logprob": -0.1194133873445442, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0018962827743962407}, {"id": 304, "seek": 208440, "start": 2100.8, "end": 2105.52, "text": " you know it's important that the world be large and complex because the worlds we want to address", "tokens": [51184, 291, 458, 309, 311, 1021, 300, 264, 1002, 312, 2416, 293, 3997, 570, 264, 13401, 321, 528, 281, 2985, 51420], "temperature": 0.0, "avg_logprob": -0.1194133873445442, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0018962827743962407}, {"id": 305, "seek": 208440, "start": 2105.52, "end": 2112.64, "text": " are large and complex um and so you want things like video and you want large data streams um", "tokens": [51420, 366, 2416, 293, 3997, 1105, 293, 370, 291, 528, 721, 411, 960, 293, 291, 528, 2416, 1412, 15842, 1105, 51776], "temperature": 0.0, "avg_logprob": -0.1194133873445442, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0018962827743962407}, {"id": 306, "seek": 211440, "start": 2114.4, "end": 2121.76, "text": " now you can use simulations to generate even video streams simulated video but inevitably", "tokens": [50364, 586, 291, 393, 764, 35138, 281, 8460, 754, 960, 15842, 41713, 960, 457, 28171, 50732], "temperature": 0.0, "avg_logprob": -0.11977117833956866, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00020024008699692786}, {"id": 307, "seek": 211440, "start": 2121.76, "end": 2127.6800000000003, "text": " those simulated worlds are really quite simple they have an underlying simplicity uh they have", "tokens": [50732, 729, 41713, 13401, 366, 534, 1596, 2199, 436, 362, 364, 14217, 25632, 2232, 436, 362, 51028], "temperature": 0.0, "avg_logprob": -0.11977117833956866, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00020024008699692786}, {"id": 308, "seek": 211440, "start": 2127.6800000000003, "end": 2133.92, "text": " objects perhaps and three-dimensional straight structure maybe they're rigid objects and the", "tokens": [51028, 6565, 4317, 293, 1045, 12, 18759, 2997, 3877, 1310, 436, 434, 22195, 6565, 293, 264, 51340], "temperature": 0.0, "avg_logprob": -0.11977117833956866, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00020024008699692786}, {"id": 309, "seek": 211440, "start": 2133.92, "end": 2140.2400000000002, "text": " vision is is is a very particular geometric form um they they are generated and they are", "tokens": [51340, 5201, 307, 307, 307, 257, 588, 1729, 33246, 1254, 1105, 436, 436, 366, 10833, 293, 436, 366, 51656], "temperature": 0.0, "avg_logprob": -0.11977117833956866, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00020024008699692786}, {"id": 310, "seek": 214024, "start": 2140.24, "end": 2144.8799999999997, "text": " they are made up worlds and they are generated so they're they're really the worlds are are are", "tokens": [50364, 436, 366, 1027, 493, 13401, 293, 436, 366, 10833, 370, 436, 434, 436, 434, 534, 264, 13401, 366, 366, 366, 50596], "temperature": 0.0, "avg_logprob": -0.08338530328538683, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.0019264179281890392}, {"id": 311, "seek": 214024, "start": 2144.8799999999997, "end": 2150.3999999999996, "text": " less complex than the agent uh their goal would be to have to spend most of the computer power", "tokens": [50596, 1570, 3997, 813, 264, 9461, 2232, 641, 3387, 576, 312, 281, 362, 281, 3496, 881, 295, 264, 3820, 1347, 50872], "temperature": 0.0, "avg_logprob": -0.08338530328538683, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.0019264179281890392}, {"id": 312, "seek": 214024, "start": 2150.3999999999996, "end": 2156.8799999999997, "text": " working on the mind and just a little bit to just create the simulated data and and that's that's", "tokens": [50872, 1364, 322, 264, 1575, 293, 445, 257, 707, 857, 281, 445, 1884, 264, 41713, 1412, 293, 293, 300, 311, 300, 311, 51196], "temperature": 0.0, "avg_logprob": -0.08338530328538683, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.0019264179281890392}, {"id": 313, "seek": 214024, "start": 2156.8799999999997, "end": 2166.0, "text": " reversed the way it really is right every person is maybe has a has a complex brain but their world", "tokens": [51196, 30563, 264, 636, 309, 534, 307, 558, 633, 954, 307, 1310, 575, 257, 575, 257, 3997, 3567, 457, 641, 1002, 51652], "temperature": 0.0, "avg_logprob": -0.08338530328538683, "compression_ratio": 1.8476190476190477, "no_speech_prob": 0.0019264179281890392}, {"id": 314, "seek": 216600, "start": 2166.0, "end": 2171.84, "text": " is much more complex not just because the world consists of all these um physics and matter", "tokens": [50364, 307, 709, 544, 3997, 406, 445, 570, 264, 1002, 14689, 295, 439, 613, 1105, 10649, 293, 1871, 50656], "temperature": 0.0, "avg_logprob": -0.07801138270984996, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.09795313328504562}, {"id": 315, "seek": 216600, "start": 2171.84, "end": 2176.4, "text": " but it also consists of other minds other brains and other minds out there and and what goes on", "tokens": [50656, 457, 309, 611, 14689, 295, 661, 9634, 661, 15442, 293, 661, 9634, 484, 456, 293, 293, 437, 1709, 322, 50884], "temperature": 0.0, "avg_logprob": -0.07801138270984996, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.09795313328504562}, {"id": 316, "seek": 216600, "start": 2176.4, "end": 2180.88, "text": " in their minds matters and so the world is inherently vastly more complex than the agent", "tokens": [50884, 294, 641, 9634, 7001, 293, 370, 264, 1002, 307, 27993, 41426, 544, 3997, 813, 264, 9461, 51108], "temperature": 0.0, "avg_logprob": -0.07801138270984996, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.09795313328504562}, {"id": 317, "seek": 216600, "start": 2182.16, "end": 2186.64, "text": " and we we've reversed that when we work on simulated worlds so which is always concerning", "tokens": [51172, 293, 321, 321, 600, 30563, 300, 562, 321, 589, 322, 41713, 13401, 370, 597, 307, 1009, 18087, 51396], "temperature": 0.0, "avg_logprob": -0.07801138270984996, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.09795313328504562}, {"id": 318, "seek": 216600, "start": 2187.6, "end": 2192.88, "text": " anyway those are some of the issues in the trade-offs between working with simulations or with", "tokens": [51444, 4033, 729, 366, 512, 295, 264, 2663, 294, 264, 4923, 12, 19231, 1296, 1364, 365, 35138, 420, 365, 51708], "temperature": 0.0, "avg_logprob": -0.07801138270984996, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.09795313328504562}, {"id": 319, "seek": 219288, "start": 2193.6, "end": 2198.48, "text": " physical worlds nonetheless you you need to develop the architecture and the algorithms", "tokens": [50400, 4001, 13401, 26756, 291, 291, 643, 281, 1499, 264, 9482, 293, 264, 14642, 50644], "temperature": 0.0, "avg_logprob": -0.11516142480167342, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.003026170888915658}, {"id": 320, "seek": 219288, "start": 2199.44, "end": 2206.08, "text": " before you worry about the data data stream i would think yeah but you want to develop the", "tokens": [50692, 949, 291, 3292, 466, 264, 1412, 1412, 4309, 741, 576, 519, 1338, 457, 291, 528, 281, 1499, 264, 51024], "temperature": 0.0, "avg_logprob": -0.11516142480167342, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.003026170888915658}, {"id": 321, "seek": 219288, "start": 2206.08, "end": 2211.36, "text": " right algorithms and if you're working with the world it's not representative of of your target", "tokens": [51024, 558, 14642, 293, 498, 291, 434, 1364, 365, 264, 1002, 309, 311, 406, 12424, 295, 295, 428, 3779, 51288], "temperature": 0.0, "avg_logprob": -0.11516142480167342, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.003026170888915658}, {"id": 322, "seek": 219288, "start": 2211.36, "end": 2218.88, "text": " world in an important way um it can be misleading but you're right and that's what we that's what", "tokens": [51288, 1002, 294, 364, 1021, 636, 1105, 309, 393, 312, 36429, 457, 291, 434, 558, 293, 300, 311, 437, 321, 300, 311, 437, 51664], "temperature": 0.0, "avg_logprob": -0.11516142480167342, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.003026170888915658}, {"id": 323, "seek": 221888, "start": 2218.88, "end": 2223.12, "text": " we strive to do you know i don't know if you know but i think of my own work is almost always", "tokens": [50364, 321, 23829, 281, 360, 291, 458, 741, 500, 380, 458, 498, 291, 458, 457, 741, 519, 295, 452, 1065, 589, 307, 1920, 1009, 50576], "temperature": 0.0, "avg_logprob": -0.06776502753506188, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.013212235644459724}, {"id": 324, "seek": 221888, "start": 2223.6800000000003, "end": 2228.48, "text": " i want to focus on some issues so i make a really simple instance of that issue like you know a", "tokens": [50604, 741, 528, 281, 1879, 322, 512, 2663, 370, 741, 652, 257, 534, 2199, 5197, 295, 300, 2734, 411, 291, 458, 257, 50844], "temperature": 0.0, "avg_logprob": -0.06776502753506188, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.013212235644459724}, {"id": 325, "seek": 221888, "start": 2228.48, "end": 2236.32, "text": " five-state world and and i study the the hell out of it but i don't like try to take advantage of", "tokens": [50844, 1732, 12, 15406, 1002, 293, 293, 741, 2979, 264, 264, 4921, 484, 295, 309, 457, 741, 500, 380, 411, 853, 281, 747, 5002, 295, 51236], "temperature": 0.0, "avg_logprob": -0.06776502753506188, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.013212235644459724}, {"id": 326, "seek": 221888, "start": 2236.32, "end": 2242.32, "text": " its smallness you know i study algorithms that are in some sense even simpler than the simple world", "tokens": [51236, 1080, 1359, 1287, 291, 458, 741, 2979, 14642, 300, 366, 294, 512, 2020, 754, 18587, 813, 264, 2199, 1002, 51536], "temperature": 0.0, "avg_logprob": -0.06776502753506188, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.013212235644459724}, {"id": 327, "seek": 221888, "start": 2242.32, "end": 2247.52, "text": " and i i stress those algorithms and see what their abilities are so we always you know it's always", "tokens": [51536, 293, 741, 741, 4244, 729, 14642, 293, 536, 437, 641, 11582, 366, 370, 321, 1009, 291, 458, 309, 311, 1009, 51796], "temperature": 0.0, "avg_logprob": -0.06776502753506188, "compression_ratio": 1.9362549800796813, "no_speech_prob": 0.013212235644459724}, {"id": 328, "seek": 224752, "start": 2247.52, "end": 2253.52, "text": " part of research is we we simplify the world understand it fully just like a a physicist might", "tokens": [50364, 644, 295, 2132, 307, 321, 321, 20460, 264, 1002, 1223, 309, 4498, 445, 411, 257, 257, 42466, 1062, 50664], "temperature": 0.0, "avg_logprob": -0.09863162622219179, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.0051368772983551025}, {"id": 329, "seek": 224752, "start": 2253.52, "end": 2258.24, "text": " you know make a simplified world with with a ball rolling down a ramp and it's it's a really", "tokens": [50664, 291, 458, 652, 257, 26335, 1002, 365, 365, 257, 2594, 9439, 760, 257, 12428, 293, 309, 311, 309, 311, 257, 534, 50900], "temperature": 0.0, "avg_logprob": -0.09863162622219179, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.0051368772983551025}, {"id": 330, "seek": 224752, "start": 2258.24, "end": 2264.48, "text": " simple world and you'll try to eliminate the friction and you eliminate other weird effects", "tokens": [50900, 2199, 1002, 293, 291, 603, 853, 281, 13819, 264, 17710, 293, 291, 13819, 661, 3657, 5065, 51212], "temperature": 0.0, "avg_logprob": -0.09863162622219179, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.0051368772983551025}, {"id": 331, "seek": 224752, "start": 2264.48, "end": 2270.88, "text": " and just see things in their simplest form yeah have you um paid much attention to um", "tokens": [51212, 293, 445, 536, 721, 294, 641, 22811, 1254, 1338, 362, 291, 1105, 4835, 709, 3202, 281, 1105, 51532], "temperature": 0.0, "avg_logprob": -0.09863162622219179, "compression_ratio": 1.7464114832535884, "no_speech_prob": 0.0051368772983551025}, {"id": 332, "seek": 227088, "start": 2271.84, "end": 2278.1600000000003, "text": " alex kendall's work at at wave ai do you know that company it's an autonomous driving company", "tokens": [50412, 257, 2021, 17016, 336, 311, 589, 412, 412, 5772, 9783, 360, 291, 458, 300, 2237, 309, 311, 364, 23797, 4840, 2237, 50728], "temperature": 0.0, "avg_logprob": -0.19187025229136148, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.018820716068148613}, {"id": 333, "seek": 227088, "start": 2278.1600000000003, "end": 2287.44, "text": " they have a world model called gaya one um and it's it's it's similar to what yanlacoon's doing", "tokens": [50728, 436, 362, 257, 1002, 2316, 1219, 290, 4427, 472, 1105, 293, 309, 311, 309, 311, 309, 311, 2531, 281, 437, 17700, 75, 326, 4106, 311, 884, 51192], "temperature": 0.0, "avg_logprob": -0.19187025229136148, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.018820716068148613}, {"id": 334, "seek": 227088, "start": 2287.44, "end": 2297.52, "text": " it it you know encodes representations from from video from live video and then uh plans", "tokens": [51192, 309, 309, 291, 458, 2058, 4789, 33358, 490, 490, 960, 490, 1621, 960, 293, 550, 2232, 5482, 51696], "temperature": 0.0, "avg_logprob": -0.19187025229136148, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.018820716068148613}, {"id": 335, "seek": 229752, "start": 2298.48, "end": 2309.44, "text": " uh based on those representations uh and and it can control a car uh from the representation space", "tokens": [50412, 2232, 2361, 322, 729, 33358, 2232, 293, 293, 309, 393, 1969, 257, 1032, 2232, 490, 264, 10290, 1901, 50960], "temperature": 0.0, "avg_logprob": -0.08965197547537382, "compression_ratio": 1.672514619883041, "no_speech_prob": 0.0010985794942826033}, {"id": 336, "seek": 229752, "start": 2309.44, "end": 2317.6, "text": " it's actually pretty remarkable so let's talk about the world model and and what what kind of", "tokens": [50960, 309, 311, 767, 1238, 12802, 370, 718, 311, 751, 466, 264, 1002, 2316, 293, 293, 437, 437, 733, 295, 51368], "temperature": 0.0, "avg_logprob": -0.08965197547537382, "compression_ratio": 1.672514619883041, "no_speech_prob": 0.0010985794942826033}, {"id": 337, "seek": 229752, "start": 2317.6, "end": 2326.56, "text": " world model would be appropriate for autonomous driving um so let me say some things that are", "tokens": [51368, 1002, 2316, 576, 312, 6854, 337, 23797, 4840, 1105, 370, 718, 385, 584, 512, 721, 300, 366, 51816], "temperature": 0.0, "avg_logprob": -0.08965197547537382, "compression_ratio": 1.672514619883041, "no_speech_prob": 0.0010985794942826033}, {"id": 338, "seek": 232752, "start": 2327.92, "end": 2333.92, "text": " mistakes they're a natural seeming but mistakes in my opinion uh the mistake would be to make", "tokens": [50384, 8038, 436, 434, 257, 3303, 1643, 278, 457, 8038, 294, 452, 4800, 2232, 264, 6146, 576, 312, 281, 652, 50684], "temperature": 0.0, "avg_logprob": -0.05520883303010062, "compression_ratio": 1.9170984455958548, "no_speech_prob": 0.004066692665219307}, {"id": 339, "seek": 232752, "start": 2333.92, "end": 2340.48, "text": " like a physics model of the world or to try to make something that could simulate the world and", "tokens": [50684, 411, 257, 10649, 2316, 295, 264, 1002, 420, 281, 853, 281, 652, 746, 300, 727, 27817, 264, 1002, 293, 51012], "temperature": 0.0, "avg_logprob": -0.05520883303010062, "compression_ratio": 1.9170984455958548, "no_speech_prob": 0.004066692665219307}, {"id": 340, "seek": 232752, "start": 2340.48, "end": 2346.48, "text": " produce the video frames you don't you don't you don't want the video frames of the future", "tokens": [51012, 5258, 264, 960, 12083, 291, 500, 380, 291, 500, 380, 291, 500, 380, 528, 264, 960, 12083, 295, 264, 2027, 51312], "temperature": 0.0, "avg_logprob": -0.05520883303010062, "compression_ratio": 1.9170984455958548, "no_speech_prob": 0.004066692665219307}, {"id": 341, "seek": 232752, "start": 2346.48, "end": 2353.7599999999998, "text": " that's not the way you think um instead you think oh i could i could go to the market and", "tokens": [51312, 300, 311, 406, 264, 636, 291, 519, 1105, 2602, 291, 519, 1954, 741, 727, 741, 727, 352, 281, 264, 2142, 293, 51676], "temperature": 0.0, "avg_logprob": -0.05520883303010062, "compression_ratio": 1.9170984455958548, "no_speech_prob": 0.004066692665219307}, {"id": 342, "seek": 235376, "start": 2353.76, "end": 2360.5600000000004, "text": " maybe there would be strawberries okay you're not creating a visual uh a video you're saying", "tokens": [50364, 1310, 456, 576, 312, 26873, 1392, 291, 434, 406, 4084, 257, 5056, 2232, 257, 960, 291, 434, 1566, 50704], "temperature": 0.0, "avg_logprob": -0.08377367166372446, "compression_ratio": 1.7484662576687116, "no_speech_prob": 0.015409877523779869}, {"id": 343, "seek": 235376, "start": 2360.5600000000004, "end": 2367.1200000000003, "text": " you're like jumping to the market and then your strawberries could be you know different sizes", "tokens": [50704, 291, 434, 411, 11233, 281, 264, 2142, 293, 550, 428, 26873, 727, 312, 291, 458, 819, 11602, 51032], "temperature": 0.0, "avg_logprob": -0.08377367166372446, "compression_ratio": 1.7484662576687116, "no_speech_prob": 0.015409877523779869}, {"id": 344, "seek": 235376, "start": 2367.1200000000003, "end": 2374.0800000000004, "text": " and positions and and and still uh there's not a video there's an idea that will happen if you go", "tokens": [51032, 293, 8432, 293, 293, 293, 920, 2232, 456, 311, 406, 257, 960, 456, 311, 364, 1558, 300, 486, 1051, 498, 291, 352, 51380], "temperature": 0.0, "avg_logprob": -0.08377367166372446, "compression_ratio": 1.7484662576687116, "no_speech_prob": 0.015409877523779869}, {"id": 345, "seek": 237408, "start": 2374.08, "end": 2386.16, "text": " to the market um so uh people have realized this like yon lakun used to talk about um generating", "tokens": [50364, 281, 264, 2142, 1105, 370, 2232, 561, 362, 5334, 341, 411, 288, 266, 287, 514, 409, 1143, 281, 751, 466, 1105, 17746, 50968], "temperature": 0.0, "avg_logprob": -0.15197965373163638, "compression_ratio": 1.7, "no_speech_prob": 0.029743598774075508}, {"id": 346, "seek": 237408, "start": 2386.16, "end": 2393.84, "text": " video of the future and then you realize it would be blurry and and now he realizes that you need", "tokens": [50968, 960, 295, 264, 2027, 293, 550, 291, 4325, 309, 576, 312, 37644, 293, 293, 586, 415, 29316, 300, 291, 643, 51352], "temperature": 0.0, "avg_logprob": -0.15197965373163638, "compression_ratio": 1.7, "no_speech_prob": 0.029743598774075508}, {"id": 347, "seek": 237408, "start": 2393.84, "end": 2399.36, "text": " to produce outcomes of your model that are not like not at all like video streams and not like", "tokens": [51352, 281, 5258, 10070, 295, 428, 2316, 300, 366, 406, 411, 406, 412, 439, 411, 960, 15842, 293, 406, 411, 51628], "temperature": 0.0, "avg_logprob": -0.15197965373163638, "compression_ratio": 1.7, "no_speech_prob": 0.029743598774075508}, {"id": 348, "seek": 239936, "start": 2399.36, "end": 2407.6800000000003, "text": " observations at all they're like um they're like constructed states um that are the outcome of the", "tokens": [50364, 18163, 412, 439, 436, 434, 411, 1105, 436, 434, 411, 17083, 4368, 1105, 300, 366, 264, 9700, 295, 264, 50780], "temperature": 0.0, "avg_logprob": -0.08608285490288792, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.0028004085179418325}, {"id": 349, "seek": 239936, "start": 2407.6800000000003, "end": 2415.52, "text": " action okay so this is this is a very different from from a partial differential equation model", "tokens": [50780, 3069, 1392, 370, 341, 307, 341, 307, 257, 588, 819, 490, 490, 257, 14641, 15756, 5367, 2316, 51172], "temperature": 0.0, "avg_logprob": -0.08608285490288792, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.0028004085179418325}, {"id": 350, "seek": 239936, "start": 2415.52, "end": 2422.4, "text": " of the world and it's so it's very different from what self-driving car companies start with", "tokens": [51172, 295, 264, 1002, 293, 309, 311, 370, 309, 311, 588, 819, 490, 437, 2698, 12, 47094, 1032, 3431, 722, 365, 51516], "temperature": 0.0, "avg_logprob": -0.08608285490288792, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.0028004085179418325}, {"id": 351, "seek": 239936, "start": 2422.4, "end": 2428.0, "text": " self-driving car companies start with physics and geometry and uh you know things that are", "tokens": [51516, 2698, 12, 47094, 1032, 3431, 722, 365, 10649, 293, 18426, 293, 2232, 291, 458, 721, 300, 366, 51796], "temperature": 0.0, "avg_logprob": -0.08608285490288792, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.0028004085179418325}, {"id": 352, "seek": 242800, "start": 2428.0, "end": 2433.44, "text": " calibrated by human understanding engineers understanding of the world and driving but", "tokens": [50364, 21583, 5468, 538, 1952, 3701, 11955, 3701, 295, 264, 1002, 293, 4840, 457, 50636], "temperature": 0.0, "avg_logprob": -0.09608245681930375, "compression_ratio": 1.811881188118812, "no_speech_prob": 0.0035370958503335714}, {"id": 353, "seek": 242800, "start": 2434.48, "end": 2439.84, "text": " i suspect that's going to be i mean what do i know i'm not into self-driving i don't do", "tokens": [50688, 741, 9091, 300, 311, 516, 281, 312, 741, 914, 437, 360, 741, 458, 741, 478, 406, 666, 2698, 12, 47094, 741, 500, 380, 360, 50956], "temperature": 0.0, "avg_logprob": -0.09608245681930375, "compression_ratio": 1.811881188118812, "no_speech_prob": 0.0035370958503335714}, {"id": 354, "seek": 242800, "start": 2439.84, "end": 2448.24, "text": " self-driving cars but i know that that um like tesla is and elon musk is and um so their goal", "tokens": [50956, 2698, 12, 47094, 5163, 457, 741, 458, 300, 300, 1105, 411, 20018, 875, 307, 293, 806, 266, 1038, 74, 307, 293, 1105, 370, 641, 3387, 51376], "temperature": 0.0, "avg_logprob": -0.09608245681930375, "compression_ratio": 1.811881188118812, "no_speech_prob": 0.0035370958503335714}, {"id": 355, "seek": 242800, "start": 2448.24, "end": 2453.12, "text": " is to is to make some you know they they started like everyone else with engineering models but i", "tokens": [51376, 307, 281, 307, 281, 652, 512, 291, 458, 436, 436, 1409, 411, 1518, 1646, 365, 7043, 5245, 457, 741, 51620], "temperature": 0.0, "avg_logprob": -0.09608245681930375, "compression_ratio": 1.811881188118812, "no_speech_prob": 0.0035370958503335714}, {"id": 356, "seek": 245312, "start": 2453.7599999999998, "end": 2459.52, "text": " my understanding now is that they're building uh sort of more conceptual models um that are", "tokens": [50396, 452, 3701, 586, 307, 300, 436, 434, 2390, 2232, 1333, 295, 544, 24106, 5245, 1105, 300, 366, 50684], "temperature": 0.0, "avg_logprob": -0.0927651596069336, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.1309962272644043}, {"id": 357, "seek": 245312, "start": 2459.52, "end": 2465.6, "text": " based on the artificial neural networks okay and so rather than starting with geometry and", "tokens": [50684, 2361, 322, 264, 11677, 18161, 9590, 1392, 293, 370, 2831, 813, 2891, 365, 18426, 293, 50988], "temperature": 0.0, "avg_logprob": -0.0927651596069336, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.1309962272644043}, {"id": 358, "seek": 245312, "start": 2465.6, "end": 2470.48, "text": " understood things they're just getting massive amounts of data and training it to make a model", "tokens": [50988, 7320, 721, 436, 434, 445, 1242, 5994, 11663, 295, 1412, 293, 3097, 309, 281, 652, 257, 2316, 51232], "temperature": 0.0, "avg_logprob": -0.0927651596069336, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.1309962272644043}, {"id": 359, "seek": 245312, "start": 2470.48, "end": 2476.08, "text": " we need a model that is at the level of high level consequences not at the level of low level", "tokens": [51232, 321, 643, 257, 2316, 300, 307, 412, 264, 1496, 295, 1090, 1496, 10098, 406, 412, 264, 1496, 295, 2295, 1496, 51512], "temperature": 0.0, "avg_logprob": -0.0927651596069336, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.1309962272644043}, {"id": 360, "seek": 245312, "start": 2476.08, "end": 2481.12, "text": " things like pixels and video so one way you do that is you're having state features that are", "tokens": [51512, 721, 411, 18668, 293, 960, 370, 472, 636, 291, 360, 300, 307, 291, 434, 1419, 1785, 4122, 300, 366, 51764], "temperature": 0.0, "avg_logprob": -0.0927651596069336, "compression_ratio": 1.848605577689243, "no_speech_prob": 0.1309962272644043}, {"id": 361, "seek": 248112, "start": 2481.12, "end": 2487.44, "text": " at a more advanced level you say oh this is a car uh rather than this is a uh a video frame", "tokens": [50364, 412, 257, 544, 7339, 1496, 291, 584, 1954, 341, 307, 257, 1032, 2232, 2831, 813, 341, 307, 257, 2232, 257, 960, 3920, 50680], "temperature": 0.0, "avg_logprob": -0.08787153008278836, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.010324499569833279}, {"id": 362, "seek": 248112, "start": 2489.2799999999997, "end": 2498.48, "text": " and um so and then basically it's as simple as you need abstraction in both state and time", "tokens": [50772, 293, 1105, 370, 293, 550, 1936, 309, 311, 382, 2199, 382, 291, 643, 37765, 294, 1293, 1785, 293, 565, 51232], "temperature": 0.0, "avg_logprob": -0.08787153008278836, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.010324499569833279}, {"id": 363, "seek": 248112, "start": 2499.12, "end": 2504.88, "text": " abstraction in in state is like saying there will be strawberries when i get to the market", "tokens": [51264, 37765, 294, 294, 1785, 307, 411, 1566, 456, 486, 312, 26873, 562, 741, 483, 281, 264, 2142, 51552], "temperature": 0.0, "avg_logprob": -0.08787153008278836, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.010324499569833279}, {"id": 364, "seek": 248112, "start": 2504.88, "end": 2511.04, "text": " and abstraction in in time is saying oh i can go to the market and then in 20 minutes i will", "tokens": [51552, 293, 37765, 294, 294, 565, 307, 1566, 1954, 741, 393, 352, 281, 264, 2142, 293, 550, 294, 945, 2077, 741, 486, 51860], "temperature": 0.0, "avg_logprob": -0.08787153008278836, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.010324499569833279}, {"id": 365, "seek": 251104, "start": 2511.04, "end": 2518.64, "text": " be there probably and other things will be the same or related in natural ways", "tokens": [50364, 312, 456, 1391, 293, 661, 721, 486, 312, 264, 912, 420, 4077, 294, 3303, 2098, 50744], "temperature": 0.0, "avg_logprob": -0.06533103830674115, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0006261671660467982}, {"id": 366, "seek": 251104, "start": 2521.44, "end": 2525.36, "text": " so we want to be able to think about i could go to the market you also want to think oh i could", "tokens": [50884, 370, 321, 528, 281, 312, 1075, 281, 519, 466, 741, 727, 352, 281, 264, 2142, 291, 611, 528, 281, 519, 1954, 741, 727, 51080], "temperature": 0.0, "avg_logprob": -0.06533103830674115, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0006261671660467982}, {"id": 367, "seek": 251104, "start": 2525.36, "end": 2530.24, "text": " pick up the coke can i could move a finger and that will have certain consequences these these", "tokens": [51080, 1888, 493, 264, 33659, 393, 741, 727, 1286, 257, 5984, 293, 300, 486, 362, 1629, 10098, 613, 613, 51324], "temperature": 0.0, "avg_logprob": -0.06533103830674115, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0006261671660467982}, {"id": 368, "seek": 251104, "start": 2530.24, "end": 2534.96, "text": " all these things that we know you think uh are vastly different scales going to the market is like", "tokens": [51324, 439, 613, 721, 300, 321, 458, 291, 519, 2232, 366, 41426, 819, 17408, 516, 281, 264, 2142, 307, 411, 51560], "temperature": 0.0, "avg_logprob": -0.06533103830674115, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0006261671660467982}, {"id": 369, "seek": 253496, "start": 2534.96, "end": 2542.7200000000003, "text": " 20 minutes um you know taking taking a new job you know might be a year uh deciding to study a", "tokens": [50364, 945, 2077, 1105, 291, 458, 1940, 1940, 257, 777, 1691, 291, 458, 1062, 312, 257, 1064, 2232, 17990, 281, 2979, 257, 50752], "temperature": 0.0, "avg_logprob": -0.09271472295125326, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.10220718383789062}, {"id": 370, "seek": 253496, "start": 2542.7200000000003, "end": 2548.8, "text": " topic also might be a period of time we think and we analyze the consequences like you wanted to", "tokens": [50752, 4829, 611, 1062, 312, 257, 2896, 295, 565, 321, 519, 293, 321, 12477, 264, 10098, 411, 291, 1415, 281, 51056], "temperature": 0.0, "avg_logprob": -0.09271472295125326, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.10220718383789062}, {"id": 371, "seek": 253496, "start": 2548.8, "end": 2555.36, "text": " meet with me today and you know we arranged it we set it up it was your your planning uh took", "tokens": [51056, 1677, 365, 385, 965, 293, 291, 458, 321, 18721, 309, 321, 992, 309, 493, 309, 390, 428, 428, 5038, 2232, 1890, 51384], "temperature": 0.0, "avg_logprob": -0.09271472295125326, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.10220718383789062}, {"id": 372, "seek": 253496, "start": 2555.36, "end": 2562.16, "text": " you know place over weeks and some cases months and and and we assembled the the the event of", "tokens": [51384, 291, 458, 1081, 670, 3259, 293, 512, 3331, 2493, 293, 293, 293, 321, 24204, 264, 264, 264, 2280, 295, 51724], "temperature": 0.0, "avg_logprob": -0.09271472295125326, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.10220718383789062}, {"id": 373, "seek": 256216, "start": 2562.16, "end": 2568.64, "text": " this interview by by planning all that and exchanging mess high-level messages uh it all that", "tokens": [50364, 341, 4049, 538, 538, 5038, 439, 300, 293, 6210, 9741, 2082, 1090, 12, 12418, 7897, 2232, 309, 439, 300, 50688], "temperature": 0.0, "avg_logprob": -0.09668865203857421, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.0009394660010002553}, {"id": 374, "seek": 256216, "start": 2568.64, "end": 2573.68, "text": " you know it's silly to think that that's done at the level of of of imagining videos that we might", "tokens": [50688, 291, 458, 309, 311, 11774, 281, 519, 300, 300, 311, 1096, 412, 264, 1496, 295, 295, 295, 27798, 2145, 300, 321, 1062, 50940], "temperature": 0.0, "avg_logprob": -0.09668865203857421, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.0009394660010002553}, {"id": 375, "seek": 256216, "start": 2573.68, "end": 2580.64, "text": " see with our eyes or our audio is signals that we might hear yeah so we need models that are", "tokens": [50940, 536, 365, 527, 2575, 420, 527, 6278, 307, 12354, 300, 321, 1062, 1568, 1338, 370, 321, 643, 5245, 300, 366, 51288], "temperature": 0.0, "avg_logprob": -0.09668865203857421, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.0009394660010002553}, {"id": 376, "seek": 256216, "start": 2580.64, "end": 2589.2, "text": " abstract in time and state and um as a reinforcement learning person um there's a particular set of", "tokens": [51288, 12649, 294, 565, 293, 1785, 293, 1105, 382, 257, 29280, 2539, 954, 1105, 456, 311, 257, 1729, 992, 295, 51716], "temperature": 0.0, "avg_logprob": -0.09668865203857421, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.0009394660010002553}, {"id": 377, "seek": 258920, "start": 2589.2, "end": 2596.64, "text": " technologies that i naturally turn towards to do that um the prediction is based on multi-step", "tokens": [50364, 7943, 300, 741, 8195, 1261, 3030, 281, 360, 300, 1105, 264, 17630, 307, 2361, 322, 4825, 12, 16792, 50736], "temperature": 0.0, "avg_logprob": -0.1137006402015686, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.0024719645734876394}, {"id": 378, "seek": 258920, "start": 2596.64, "end": 2605.52, "text": " prediction by temporal difference learning um the planning is done by uh dynamic programming", "tokens": [50736, 17630, 538, 30881, 2649, 2539, 1105, 264, 5038, 307, 1096, 538, 2232, 8546, 9410, 51180], "temperature": 0.0, "avg_logprob": -0.1137006402015686, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.0024719645734876394}, {"id": 379, "seek": 258920, "start": 2605.52, "end": 2612.48, "text": " essentially value iteration but where the steps the are not low-level actions but they're called", "tokens": [51180, 4476, 2158, 24784, 457, 689, 264, 4439, 264, 366, 406, 2295, 12, 12418, 5909, 457, 436, 434, 1219, 51528], "temperature": 0.0, "avg_logprob": -0.1137006402015686, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.0024719645734876394}, {"id": 380, "seek": 258920, "start": 2612.48, "end": 2616.96, "text": " options they're high-level ways of behaving with that that terminate so they're there are things", "tokens": [51528, 3956, 436, 434, 1090, 12, 12418, 2098, 295, 35263, 365, 300, 300, 10761, 473, 370, 436, 434, 456, 366, 721, 51752], "temperature": 0.0, "avg_logprob": -0.1137006402015686, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.0024719645734876394}, {"id": 381, "seek": 261696, "start": 2616.96, "end": 2622.96, "text": " like going to the market and they'll terminate when you're at the market so you know at a certain", "tokens": [50364, 411, 516, 281, 264, 2142, 293, 436, 603, 10761, 473, 562, 291, 434, 412, 264, 2142, 370, 291, 458, 412, 257, 1629, 50664], "temperature": 0.0, "avg_logprob": -0.12317719397606788, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.00388354086317122}, {"id": 382, "seek": 261696, "start": 2622.96, "end": 2632.4, "text": " conceptual level it's clear where we want to go to me um with abstract models in time and state", "tokens": [50664, 24106, 1496, 309, 311, 1850, 689, 321, 528, 281, 352, 281, 385, 1105, 365, 12649, 5245, 294, 565, 293, 1785, 51136], "temperature": 0.0, "avg_logprob": -0.12317719397606788, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.00388354086317122}, {"id": 383, "seek": 261696, "start": 2633.2, "end": 2634.64, "text": " built options and features", "tokens": [51176, 3094, 3956, 293, 4122, 51248], "temperature": 0.0, "avg_logprob": -0.12317719397606788, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.00388354086317122}, {"id": 384, "seek": 261696, "start": 2638.2400000000002, "end": 2645.92, "text": " i don't know you we did write one paper recently put published an AI journal on the the notion of", "tokens": [51428, 741, 500, 380, 458, 291, 321, 630, 2464, 472, 3035, 3938, 829, 6572, 364, 7318, 6708, 322, 264, 264, 10710, 295, 51812], "temperature": 0.0, "avg_logprob": -0.12317719397606788, "compression_ratio": 1.5820895522388059, "no_speech_prob": 0.00388354086317122}, {"id": 385, "seek": 264592, "start": 2645.92, "end": 2656.0, "text": " planning using uh sub-problems on the stomp progression stomp means sub-task option model", "tokens": [50364, 5038, 1228, 2232, 1422, 12, 47419, 82, 322, 264, 342, 8586, 18733, 342, 8586, 1355, 1422, 12, 83, 3863, 3614, 2316, 50868], "temperature": 0.0, "avg_logprob": -0.11697595510909807, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.0007434325525537133}, {"id": 386, "seek": 264592, "start": 2656.0, "end": 2661.2000000000003, "text": " and planning put all those things together and you can do the full progression from from the", "tokens": [50868, 293, 5038, 829, 439, 729, 721, 1214, 293, 291, 393, 360, 264, 1577, 18733, 490, 490, 264, 51128], "temperature": 0.0, "avg_logprob": -0.11697595510909807, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.0007434325525537133}, {"id": 387, "seek": 264592, "start": 2661.2000000000003, "end": 2668.56, "text": " data stream to abstract planning and that's that's what we're trying to put together yeah yeah and i", "tokens": [51128, 1412, 4309, 281, 12649, 5038, 293, 300, 311, 300, 311, 437, 321, 434, 1382, 281, 829, 1214, 1338, 1338, 293, 741, 51496], "temperature": 0.0, "avg_logprob": -0.11697595510909807, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.0007434325525537133}, {"id": 388, "seek": 266856, "start": 2668.56, "end": 2675.68, "text": " i sort of misspoke talking about gaya one about that model i mean it they they the input is video", "tokens": [50364, 741, 1333, 295, 1713, 48776, 1417, 466, 290, 4427, 472, 466, 300, 2316, 741, 914, 309, 436, 436, 264, 4846, 307, 960, 50720], "temperature": 0.0, "avg_logprob": -0.11417812685812673, "compression_ratio": 1.870748299319728, "no_speech_prob": 0.05911707878112793}, {"id": 389, "seek": 266856, "start": 2677.2, "end": 2685.6, "text": " it creates a representation and it plans and and and takes action in the representation", "tokens": [50796, 309, 7829, 257, 10290, 293, 309, 5482, 293, 293, 293, 2516, 3069, 294, 264, 10290, 51216], "temperature": 0.0, "avg_logprob": -0.11417812685812673, "compression_ratio": 1.870748299319728, "no_speech_prob": 0.05911707878112793}, {"id": 390, "seek": 266856, "start": 2686.64, "end": 2694.48, "text": " plans actions in the representation space you can then decode that into video to see what", "tokens": [51268, 5482, 5909, 294, 264, 10290, 1901, 291, 393, 550, 979, 1429, 300, 666, 960, 281, 536, 437, 51660], "temperature": 0.0, "avg_logprob": -0.11417812685812673, "compression_ratio": 1.870748299319728, "no_speech_prob": 0.05911707878112793}, {"id": 391, "seek": 269448, "start": 2695.2, "end": 2702.48, "text": " what it's doing but but it's but you're not planning in the video space so the what what's", "tokens": [50400, 437, 309, 311, 884, 457, 457, 309, 311, 457, 291, 434, 406, 5038, 294, 264, 960, 1901, 370, 264, 437, 437, 311, 50764], "temperature": 0.0, "avg_logprob": -0.08597660787177808, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.00844007171690464}, {"id": 392, "seek": 269448, "start": 2702.48, "end": 2709.44, "text": " your ambition with with this you'll figure out the refine the algorithms the reinforcement learning", "tokens": [50764, 428, 22814, 365, 365, 341, 291, 603, 2573, 484, 264, 33906, 264, 14642, 264, 29280, 2539, 51112], "temperature": 0.0, "avg_logprob": -0.08597660787177808, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.00844007171690464}, {"id": 393, "seek": 269448, "start": 2709.44, "end": 2719.36, "text": " algorithms they need to be scalable once you have that uh then you move on and and uh start start", "tokens": [51112, 14642, 436, 643, 281, 312, 38481, 1564, 291, 362, 300, 2232, 550, 291, 1286, 322, 293, 293, 2232, 722, 722, 51608], "temperature": 0.0, "avg_logprob": -0.08597660787177808, "compression_ratio": 1.7245508982035929, "no_speech_prob": 0.00844007171690464}, {"id": 394, "seek": 271936, "start": 2719.36, "end": 2727.6800000000003, "text": " scaling them with compute and and uh you know following your roadmap or am i simplifying it too", "tokens": [50364, 21589, 552, 365, 14722, 293, 293, 2232, 291, 458, 3480, 428, 35738, 420, 669, 741, 6883, 5489, 309, 886, 50780], "temperature": 0.0, "avg_logprob": -0.07947052700418822, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.009853232651948929}, {"id": 395, "seek": 271936, "start": 2727.6800000000003, "end": 2732.7200000000003, "text": " much you know we want to understand how the mind works and then we're going to make a mind or some", "tokens": [50780, 709, 291, 458, 321, 528, 281, 1223, 577, 264, 1575, 1985, 293, 550, 321, 434, 516, 281, 652, 257, 1575, 420, 512, 51032], "temperature": 0.0, "avg_logprob": -0.07947052700418822, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.009853232651948929}, {"id": 396, "seek": 271936, "start": 2732.7200000000003, "end": 2742.4, "text": " minds or some mind uh amount of mind uh and this will be useful in all the ways in all sorts of", "tokens": [51032, 9634, 420, 512, 1575, 2232, 2372, 295, 1575, 2232, 293, 341, 486, 312, 4420, 294, 439, 264, 2098, 294, 439, 7527, 295, 51516], "temperature": 0.0, "avg_logprob": -0.07947052700418822, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.009853232651948929}, {"id": 397, "seek": 274240, "start": 2742.4, "end": 2750.96, "text": " ways economically useful it'll also be useful um to to us to extend the capabilities of our own", "tokens": [50364, 2098, 26811, 4420, 309, 603, 611, 312, 4420, 1105, 281, 281, 505, 281, 10101, 264, 10862, 295, 527, 1065, 50792], "temperature": 0.0, "avg_logprob": -0.0732225649284594, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.05414680019021034}, {"id": 398, "seek": 274240, "start": 2750.96, "end": 2758.56, "text": " minds if we can understand how our minds work um we can we can augment them so that they can work", "tokens": [50792, 9634, 498, 321, 393, 1223, 577, 527, 9634, 589, 1105, 321, 393, 321, 393, 29919, 552, 370, 300, 436, 393, 589, 51172], "temperature": 0.0, "avg_logprob": -0.0732225649284594, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.05414680019021034}, {"id": 399, "seek": 274240, "start": 2758.56, "end": 2766.88, "text": " better um yeah we're gonna the the key step is understanding and then there would be millions", "tokens": [51172, 1101, 1105, 1338, 321, 434, 799, 264, 264, 2141, 1823, 307, 3701, 293, 550, 456, 576, 312, 6803, 51588], "temperature": 0.0, "avg_logprob": -0.0732225649284594, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.05414680019021034}, {"id": 400, "seek": 276688, "start": 2766.88, "end": 2776.2400000000002, "text": " of uses um i don't think it's going to be as simple as making uh workers sort of like slaves for us", "tokens": [50364, 295, 4960, 1105, 741, 500, 380, 519, 309, 311, 516, 281, 312, 382, 2199, 382, 1455, 2232, 5600, 1333, 295, 411, 18394, 337, 505, 50832], "temperature": 0.0, "avg_logprob": -0.07206428867496856, "compression_ratio": 1.7329192546583851, "no_speech_prob": 0.028841614723205566}, {"id": 401, "seek": 276688, "start": 2776.96, "end": 2783.76, "text": " to direct i don't think it'll be as simple as that um that maybe gives a lower bound on", "tokens": [50868, 281, 2047, 741, 500, 380, 519, 309, 603, 312, 382, 2199, 382, 300, 1105, 300, 1310, 2709, 257, 3126, 5472, 322, 51208], "temperature": 0.0, "avg_logprob": -0.07206428867496856, "compression_ratio": 1.7329192546583851, "no_speech_prob": 0.028841614723205566}, {"id": 402, "seek": 276688, "start": 2783.76, "end": 2791.44, "text": " potential utility our sort of our story for etkin is we say that um well if you suppose you", "tokens": [51208, 3995, 14877, 527, 1333, 295, 527, 1657, 337, 1030, 5843, 307, 321, 584, 300, 1105, 731, 498, 291, 7297, 291, 51592], "temperature": 0.0, "avg_logprob": -0.07206428867496856, "compression_ratio": 1.7329192546583851, "no_speech_prob": 0.028841614723205566}, {"id": 403, "seek": 279144, "start": 2791.44, "end": 2798.08, "text": " could make a virtual worker um this would be enormously useful um much of the work that we", "tokens": [50364, 727, 652, 257, 6374, 11346, 1105, 341, 576, 312, 39669, 4420, 1105, 709, 295, 264, 589, 300, 321, 50696], "temperature": 0.0, "avg_logprob": -0.08445034470669059, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010160678066313267}, {"id": 404, "seek": 279144, "start": 2798.08, "end": 2803.68, "text": " all do from day to day is doesn't require a physical presence it doesn't require a robot", "tokens": [50696, 439, 360, 490, 786, 281, 786, 307, 1177, 380, 3651, 257, 4001, 6814, 309, 1177, 380, 3651, 257, 7881, 50976], "temperature": 0.0, "avg_logprob": -0.08445034470669059, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010160678066313267}, {"id": 405, "seek": 279144, "start": 2803.68, "end": 2810.48, "text": " much of which we do is just shuffling information around we can do most things through through a", "tokens": [50976, 709, 295, 597, 321, 360, 307, 445, 402, 1245, 1688, 1589, 926, 321, 393, 360, 881, 721, 807, 807, 257, 51316], "temperature": 0.0, "avg_logprob": -0.08445034470669059, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010160678066313267}, {"id": 406, "seek": 279144, "start": 2810.48, "end": 2819.84, "text": " video interface um so why can't we make workers that are extremely useful by playing the roles that", "tokens": [51316, 960, 9226, 1105, 370, 983, 393, 380, 321, 652, 5600, 300, 366, 4664, 4420, 538, 2433, 264, 9604, 300, 51784], "temperature": 0.0, "avg_logprob": -0.08445034470669059, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010160678066313267}, {"id": 407, "seek": 281984, "start": 2820.08, "end": 2825.44, "text": " people play in many cases that's that's that's sort of a lower bound and what can be done", "tokens": [50376, 561, 862, 294, 867, 3331, 300, 311, 300, 311, 300, 311, 1333, 295, 257, 3126, 5472, 293, 437, 393, 312, 1096, 50644], "temperature": 0.0, "avg_logprob": -0.11830273380985966, "compression_ratio": 1.9606741573033708, "no_speech_prob": 0.003426465904340148}, {"id": 408, "seek": 281984, "start": 2825.44, "end": 2828.8, "text": " i think much more can be done and there'll be much more interesting things to be done", "tokens": [50644, 741, 519, 709, 544, 393, 312, 1096, 293, 456, 603, 312, 709, 544, 1880, 721, 281, 312, 1096, 50812], "temperature": 0.0, "avg_logprob": -0.11830273380985966, "compression_ratio": 1.9606741573033708, "no_speech_prob": 0.003426465904340148}, {"id": 409, "seek": 281984, "start": 2832.0, "end": 2838.96, "text": " and then this question of what should be done um yeah those are those are rich", "tokens": [50972, 293, 550, 341, 1168, 295, 437, 820, 312, 1096, 1105, 1338, 729, 366, 729, 366, 4593, 51320], "temperature": 0.0, "avg_logprob": -0.11830273380985966, "compression_ratio": 1.9606741573033708, "no_speech_prob": 0.003426465904340148}, {"id": 410, "seek": 281984, "start": 2838.96, "end": 2845.76, "text": " philosophical questions and practical questions for the economy yeah uh the the i've seen your", "tokens": [51320, 25066, 1651, 293, 8496, 1651, 337, 264, 5010, 1338, 2232, 264, 264, 741, 600, 1612, 428, 51660], "temperature": 0.0, "avg_logprob": -0.11830273380985966, "compression_ratio": 1.9606741573033708, "no_speech_prob": 0.003426465904340148}, {"id": 411, "seek": 284576, "start": 2845.76, "end": 2850.8, "text": " third uh well and one thing on reinforcement learning and sort of supervised learning sort", "tokens": [50364, 2636, 2232, 731, 293, 472, 551, 322, 29280, 2539, 293, 1333, 295, 46533, 2539, 1333, 50616], "temperature": 0.0, "avg_logprob": -0.14108659075452135, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.014929368160665035}, {"id": 412, "seek": 284576, "start": 2850.8, "end": 2858.2400000000002, "text": " of took over for a while now it's transformer based generative uh ai but uh during the supervised", "tokens": [50616, 295, 1890, 670, 337, 257, 1339, 586, 309, 311, 31782, 2361, 1337, 1166, 2232, 9783, 457, 2232, 1830, 264, 46533, 50988], "temperature": 0.0, "avg_logprob": -0.14108659075452135, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.014929368160665035}, {"id": 413, "seek": 284576, "start": 2858.2400000000002, "end": 2867.92, "text": " learning phase uh the argument was that uh higher knowledge is all supervised learning", "tokens": [50988, 2539, 5574, 2232, 264, 6770, 390, 300, 2232, 2946, 3601, 307, 439, 46533, 2539, 51472], "temperature": 0.0, "avg_logprob": -0.14108659075452135, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.014929368160665035}, {"id": 414, "seek": 284576, "start": 2867.92, "end": 2874.88, "text": " and and the it's still supervised it's still supervised in general the ai had large language", "tokens": [51472, 293, 293, 264, 309, 311, 920, 46533, 309, 311, 920, 46533, 294, 2674, 264, 9783, 632, 2416, 2856, 51820], "temperature": 0.0, "avg_logprob": -0.14108659075452135, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.014929368160665035}, {"id": 415, "seek": 287488, "start": 2874.88, "end": 2882.0, "text": " models they the the training information is the next token the next word and that's taken as", "tokens": [50364, 5245, 436, 264, 264, 3097, 1589, 307, 264, 958, 14862, 264, 958, 1349, 293, 300, 311, 2726, 382, 50720], "temperature": 0.0, "avg_logprob": -0.058561979778229245, "compression_ratio": 1.7806451612903227, "no_speech_prob": 0.0016214515781030059}, {"id": 416, "seek": 287488, "start": 2882.96, "end": 2890.88, "text": " as the correct action the analogy you gave me was uh you know because the analogy that that's", "tokens": [50768, 382, 264, 3006, 3069, 264, 21663, 291, 2729, 385, 390, 2232, 291, 458, 570, 264, 21663, 300, 300, 311, 51164], "temperature": 0.0, "avg_logprob": -0.058561979778229245, "compression_ratio": 1.7806451612903227, "no_speech_prob": 0.0016214515781030059}, {"id": 417, "seek": 287488, "start": 2890.88, "end": 2897.84, "text": " always given is that you know a child sees an elephant the mother says that's an elephant", "tokens": [51164, 1009, 2212, 307, 300, 291, 458, 257, 1440, 8194, 364, 19791, 264, 2895, 1619, 300, 311, 364, 19791, 51512], "temperature": 0.0, "avg_logprob": -0.058561979778229245, "compression_ratio": 1.7806451612903227, "no_speech_prob": 0.0016214515781030059}, {"id": 418, "seek": 289784, "start": 2898.4, "end": 2905.44, "text": " and the child very quickly can generalize and and recognize other elements elephants maybe it", "tokens": [50392, 293, 264, 1440, 588, 2661, 393, 2674, 1125, 293, 293, 5521, 661, 4959, 33015, 1310, 309, 50744], "temperature": 0.0, "avg_logprob": -0.07348282162736101, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.05494663864374161}, {"id": 419, "seek": 289784, "start": 2905.44, "end": 2912.0, "text": " makes a mistake and the mother corrects it and says no that's a cow and and that was always given", "tokens": [50744, 1669, 257, 6146, 293, 264, 2895, 3006, 82, 309, 293, 1619, 572, 300, 311, 257, 8408, 293, 293, 300, 390, 1009, 2212, 51072], "temperature": 0.0, "avg_logprob": -0.07348282162736101, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.05494663864374161}, {"id": 420, "seek": 289784, "start": 2912.0, "end": 2916.8, "text": " as an example of supervised learning but maybe it's reinforcement learning maybe it's the child's", "tokens": [51072, 382, 364, 1365, 295, 46533, 2539, 457, 1310, 309, 311, 29280, 2539, 1310, 309, 311, 264, 1440, 311, 51312], "temperature": 0.0, "avg_logprob": -0.07348282162736101, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.05494663864374161}, {"id": 421, "seek": 289784, "start": 2917.52, "end": 2926.0, "text": " reward from the mother praising him for remembering the label the point is that a child has", "tokens": [51348, 7782, 490, 264, 2895, 42941, 796, 337, 20719, 264, 7645, 264, 935, 307, 300, 257, 1440, 575, 51772], "temperature": 0.0, "avg_logprob": -0.07348282162736101, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.05494663864374161}, {"id": 422, "seek": 292784, "start": 2928.4, "end": 2936.48, "text": " well-developed concepts classes concepts um before and then and then when it's you know when", "tokens": [50392, 731, 12, 35464, 292, 10392, 5359, 10392, 1105, 949, 293, 550, 293, 550, 562, 309, 311, 291, 458, 562, 50796], "temperature": 0.0, "avg_logprob": -0.10874376874981505, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.0014093981590121984}, {"id": 423, "seek": 292784, "start": 2936.48, "end": 2943.04, "text": " its mother says that is an elephant uh there's already an extensive understanding on the child's", "tokens": [50796, 1080, 2895, 1619, 300, 307, 364, 19791, 2232, 456, 311, 1217, 364, 13246, 3701, 322, 264, 1440, 311, 51124], "temperature": 0.0, "avg_logprob": -0.10874376874981505, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.0014093981590121984}, {"id": 424, "seek": 292784, "start": 2943.6800000000003, "end": 2951.52, "text": " and a part of you know what the space is what the objects are and and this this the the thing", "tokens": [51156, 293, 257, 644, 295, 291, 458, 437, 264, 1901, 307, 437, 264, 6565, 366, 293, 293, 341, 341, 264, 264, 551, 51548], "temperature": 0.0, "avg_logprob": -0.10874376874981505, "compression_ratio": 1.7048192771084338, "no_speech_prob": 0.0014093981590121984}, {"id": 425, "seek": 295152, "start": 2952.08, "end": 2959.52, "text": " that that is being labeled um no the label is the least interesting part of that and the the", "tokens": [50392, 300, 300, 307, 885, 21335, 1105, 572, 264, 7645, 307, 264, 1935, 1880, 644, 295, 300, 293, 264, 264, 50764], "temperature": 0.0, "avg_logprob": -0.13496066302787968, "compression_ratio": 1.9739583333333333, "no_speech_prob": 0.02714274451136589}, {"id": 426, "seek": 295152, "start": 2959.52, "end": 2966.4, "text": " the child has already learned all the all all the other most interesting parts of of what it means", "tokens": [50764, 264, 1440, 575, 1217, 3264, 439, 264, 439, 439, 264, 661, 881, 1880, 3166, 295, 295, 437, 309, 1355, 51108], "temperature": 0.0, "avg_logprob": -0.13496066302787968, "compression_ratio": 1.9739583333333333, "no_speech_prob": 0.02714274451136589}, {"id": 427, "seek": 295152, "start": 2966.96, "end": 2971.68, "text": " to have animals and moving things and objects in its world the label is the least interesting", "tokens": [51136, 281, 362, 4882, 293, 2684, 721, 293, 6565, 294, 1080, 1002, 264, 7645, 307, 264, 1935, 1880, 51372], "temperature": 0.0, "avg_logprob": -0.13496066302787968, "compression_ratio": 1.9739583333333333, "no_speech_prob": 0.02714274451136589}, {"id": 428, "seek": 295152, "start": 2971.68, "end": 2977.7599999999998, "text": " part well first of all you're talking about agents that that could be virtual workers already", "tokens": [51372, 644, 731, 700, 295, 439, 291, 434, 1417, 466, 12554, 300, 300, 727, 312, 6374, 5600, 1217, 51676], "temperature": 0.0, "avg_logprob": -0.13496066302787968, "compression_ratio": 1.9739583333333333, "no_speech_prob": 0.02714274451136589}, {"id": 429, "seek": 297776, "start": 2978.32, "end": 2988.1600000000003, "text": " uh using reinforcement learning people are building agents and using large language models", "tokens": [50392, 2232, 1228, 29280, 2539, 561, 366, 2390, 12554, 293, 1228, 2416, 2856, 5245, 50884], "temperature": 0.0, "avg_logprob": -0.1772289276123047, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.007335500326007605}, {"id": 430, "seek": 297776, "start": 2988.1600000000003, "end": 3000.7200000000003, "text": " and knowledge bases to you know carry out tasks knowledge based tasks uh so what you're talking", "tokens": [50884, 293, 3601, 17949, 281, 291, 458, 3985, 484, 9608, 3601, 2361, 9608, 2232, 370, 437, 291, 434, 1417, 51512], "temperature": 0.0, "avg_logprob": -0.1772289276123047, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.007335500326007605}, {"id": 431, "seek": 300072, "start": 3000.72, "end": 3008.3999999999996, "text": " about is is more than uh linguistic tasks or knowledge based tasks you're talking about", "tokens": [50364, 466, 307, 307, 544, 813, 2232, 43002, 9608, 420, 3601, 2361, 9608, 291, 434, 1417, 466, 50748], "temperature": 0.0, "avg_logprob": -0.1002568583334646, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.0426921509206295}, {"id": 432, "seek": 300072, "start": 3009.2, "end": 3018.08, "text": " of physical planning and physical tasks is that right the key thing is having goals and a lot", "tokens": [50788, 295, 4001, 5038, 293, 4001, 9608, 307, 300, 558, 264, 2141, 551, 307, 1419, 5493, 293, 257, 688, 51232], "temperature": 0.0, "avg_logprob": -0.1002568583334646, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.0426921509206295}, {"id": 433, "seek": 300072, "start": 3019.2799999999997, "end": 3025.2, "text": " if you have an for example an assistant help you plan your day organize your day or do tasks for", "tokens": [51292, 498, 291, 362, 364, 337, 1365, 364, 10994, 854, 291, 1393, 428, 786, 13859, 428, 786, 420, 360, 9608, 337, 51588], "temperature": 0.0, "avg_logprob": -0.1002568583334646, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.0426921509206295}, {"id": 434, "seek": 302520, "start": 3025.2, "end": 3033.2799999999997, "text": " you um i'm thinking it's very important that the system is able to have goals and is able to", "tokens": [50364, 291, 1105, 741, 478, 1953, 309, 311, 588, 1021, 300, 264, 1185, 307, 1075, 281, 362, 5493, 293, 307, 1075, 281, 50768], "temperature": 0.0, "avg_logprob": -0.07615406282486455, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.024034082889556885}, {"id": 435, "seek": 302520, "start": 3033.2799999999997, "end": 3040.24, "text": " understand your goals i think it's probably the most important part of an assistant is to understand", "tokens": [50768, 1223, 428, 5493, 741, 519, 309, 311, 1391, 264, 881, 1021, 644, 295, 364, 10994, 307, 281, 1223, 51116], "temperature": 0.0, "avg_logprob": -0.07615406282486455, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.024034082889556885}, {"id": 436, "seek": 302520, "start": 3040.24, "end": 3047.68, "text": " the purposes involved and um large language models don't understand don't really understand", "tokens": [51116, 264, 9932, 3288, 293, 1105, 2416, 2856, 5245, 500, 380, 1223, 500, 380, 534, 1223, 51488], "temperature": 0.0, "avg_logprob": -0.07615406282486455, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.024034082889556885}, {"id": 437, "seek": 304768, "start": 3047.68, "end": 3055.9199999999996, "text": " purposes involved they will appear to a little bit um but the corner case has always come up and", "tokens": [50364, 9932, 3288, 436, 486, 4204, 281, 257, 707, 857, 1105, 457, 264, 4538, 1389, 575, 1009, 808, 493, 293, 50776], "temperature": 0.0, "avg_logprob": -0.11064587807168766, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.2306293249130249}, {"id": 438, "seek": 304768, "start": 3055.9199999999996, "end": 3062.24, "text": " once you spend a bit of time they're always and you're always in a corner case and so an AI system", "tokens": [50776, 1564, 291, 3496, 257, 857, 295, 565, 436, 434, 1009, 293, 291, 434, 1009, 294, 257, 4538, 1389, 293, 370, 364, 7318, 1185, 51092], "temperature": 0.0, "avg_logprob": -0.11064587807168766, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.2306293249130249}, {"id": 439, "seek": 304768, "start": 3062.24, "end": 3068.64, "text": " is system that that after a bit does silly things and that don't respect the goals that you have or", "tokens": [51092, 307, 1185, 300, 300, 934, 257, 857, 775, 11774, 721, 293, 300, 500, 380, 3104, 264, 5493, 300, 291, 362, 420, 51412], "temperature": 0.0, "avg_logprob": -0.11064587807168766, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.2306293249130249}, {"id": 440, "seek": 304768, "start": 3068.64, "end": 3074.56, "text": " that have been given to it um that's not going to be a useful assistant so i mean i don't want to be", "tokens": [51412, 300, 362, 668, 2212, 281, 309, 1105, 300, 311, 406, 516, 281, 312, 257, 4420, 10994, 370, 741, 914, 741, 500, 380, 528, 281, 312, 51708], "temperature": 0.0, "avg_logprob": -0.11064587807168766, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.2306293249130249}, {"id": 441, "seek": 307456, "start": 3074.56, "end": 3081.2, "text": " critical of large language models um they're very very useful but it shouldn't be viewed as a criticism", "tokens": [50364, 4924, 295, 2416, 2856, 5245, 1105, 436, 434, 588, 588, 4420, 457, 309, 4659, 380, 312, 19174, 382, 257, 15835, 50696], "temperature": 0.0, "avg_logprob": -0.10401451053904064, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02972075156867504}, {"id": 442, "seek": 307456, "start": 3081.2, "end": 3086.56, "text": " to say that they're also at the same time have rather important limitations it's not a competition", "tokens": [50696, 281, 584, 300, 436, 434, 611, 412, 264, 912, 565, 362, 2831, 1021, 15705, 309, 311, 406, 257, 6211, 50964], "temperature": 0.0, "avg_logprob": -0.10401451053904064, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02972075156867504}, {"id": 443, "seek": 307456, "start": 3086.56, "end": 3096.0, "text": " in that sense are you concerned at all are you ascribed to the threat debate no i think the", "tokens": [50964, 294, 300, 2020, 366, 291, 5922, 412, 439, 366, 291, 382, 18732, 281, 264, 4734, 7958, 572, 741, 519, 264, 51436], "temperature": 0.0, "avg_logprob": -0.10401451053904064, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02972075156867504}, {"id": 444, "seek": 309600, "start": 3096.56, "end": 3104.4, "text": " i don't i don't uh i i think the doomers are they're not just wrong i think i think they're", "tokens": [50392, 741, 500, 380, 741, 500, 380, 2232, 741, 741, 519, 264, 360, 298, 433, 366, 436, 434, 406, 445, 2085, 741, 519, 741, 519, 436, 434, 50784], "temperature": 0.0, "avg_logprob": -0.08535556422853932, "compression_ratio": 1.9095477386934674, "no_speech_prob": 0.06087788939476013}, {"id": 445, "seek": 309600, "start": 3104.4, "end": 3111.28, "text": " blindingly biased the the bias is blinding them to what's going on basically AI is a broadly", "tokens": [50784, 6865, 12163, 28035, 264, 264, 12577, 307, 6865, 278, 552, 281, 437, 311, 516, 322, 1936, 7318, 307, 257, 19511, 51128], "temperature": 0.0, "avg_logprob": -0.08535556422853932, "compression_ratio": 1.9095477386934674, "no_speech_prob": 0.06087788939476013}, {"id": 446, "seek": 309600, "start": 3111.28, "end": 3116.88, "text": " applicable technology it's not like it's not like nuclear weapons it's not like it's not like a", "tokens": [51128, 21142, 2899, 309, 311, 406, 411, 309, 311, 406, 411, 8179, 7278, 309, 311, 406, 411, 309, 311, 406, 411, 257, 51408], "temperature": 0.0, "avg_logprob": -0.08535556422853932, "compression_ratio": 1.9095477386934674, "no_speech_prob": 0.06087788939476013}, {"id": 447, "seek": 309600, "start": 3116.88, "end": 3124.64, "text": " bio weapons it can be used for all kinds of things and it's not it's not uh it's uh the way we deal", "tokens": [51408, 12198, 7278, 309, 393, 312, 1143, 337, 439, 3685, 295, 721, 293, 309, 311, 406, 309, 311, 406, 2232, 309, 311, 2232, 264, 636, 321, 2028, 51796], "temperature": 0.0, "avg_logprob": -0.08535556422853932, "compression_ratio": 1.9095477386934674, "no_speech_prob": 0.06087788939476013}, {"id": 448, "seek": 312464, "start": 3124.64, "end": 3132.0, "text": " with such things is we we uh we try to use them well and there will be people that use them", "tokens": [50364, 365, 1270, 721, 307, 321, 321, 2232, 321, 853, 281, 764, 552, 731, 293, 456, 486, 312, 561, 300, 764, 552, 50732], "temperature": 0.0, "avg_logprob": -0.08160572154547578, "compression_ratio": 1.9206349206349207, "no_speech_prob": 0.005815650336444378}, {"id": 449, "seek": 312464, "start": 3132.72, "end": 3137.2799999999997, "text": " for bad things and then you know this is just normal there's normal technology", "tokens": [50768, 337, 1578, 721, 293, 550, 291, 458, 341, 307, 445, 2710, 456, 311, 2710, 2899, 50996], "temperature": 0.0, "avg_logprob": -0.08160572154547578, "compression_ratio": 1.9206349206349207, "no_speech_prob": 0.005815650336444378}, {"id": 450, "seek": 312464, "start": 3137.2799999999997, "end": 3143.12, "text": " is it can be used by good people or bad people the the doomers the doomers are just saying oh", "tokens": [50996, 307, 309, 393, 312, 1143, 538, 665, 561, 420, 1578, 561, 264, 264, 360, 298, 433, 264, 360, 298, 433, 366, 445, 1566, 1954, 51288], "temperature": 0.0, "avg_logprob": -0.08160572154547578, "compression_ratio": 1.9206349206349207, "no_speech_prob": 0.005815650336444378}, {"id": 451, "seek": 312464, "start": 3143.12, "end": 3149.7599999999998, "text": " somehow there's going to be it's going to be it's bad in the same way that nuclear weapons are bad", "tokens": [51288, 6063, 456, 311, 516, 281, 312, 309, 311, 516, 281, 312, 309, 311, 1578, 294, 264, 912, 636, 300, 8179, 7278, 366, 1578, 51620], "temperature": 0.0, "avg_logprob": -0.08160572154547578, "compression_ratio": 1.9206349206349207, "no_speech_prob": 0.005815650336444378}, {"id": 452, "seek": 314976, "start": 3149.76, "end": 3157.28, "text": " that they and that's just they're just blinded by that metaphor by the thinking that that the AI", "tokens": [50364, 300, 436, 293, 300, 311, 445, 436, 434, 445, 6865, 292, 538, 300, 19157, 538, 264, 1953, 300, 300, 264, 7318, 50740], "temperature": 0.0, "avg_logprob": -0.0989979871114095, "compression_ratio": 1.7888198757763976, "no_speech_prob": 0.010322820395231247}, {"id": 453, "seek": 314976, "start": 3157.28, "end": 3164.88, "text": " will be out to kill them that's just it's just silly and i i don't i don't think well they the", "tokens": [50740, 486, 312, 484, 281, 1961, 552, 300, 311, 445, 309, 311, 445, 11774, 293, 741, 741, 500, 380, 741, 500, 380, 519, 731, 436, 264, 51120], "temperature": 0.0, "avg_logprob": -0.0989979871114095, "compression_ratio": 1.7888198757763976, "no_speech_prob": 0.010322820395231247}, {"id": 454, "seek": 314976, "start": 3164.88, "end": 3172.5600000000004, "text": " doomers don't actually give coherent reasons for what they what they believe and so it's hard to", "tokens": [51120, 360, 298, 433, 500, 380, 767, 976, 36239, 4112, 337, 437, 436, 437, 436, 1697, 293, 370, 309, 311, 1152, 281, 51504], "temperature": 0.0, "avg_logprob": -0.0989979871114095, "compression_ratio": 1.7888198757763976, "no_speech_prob": 0.010322820395231247}, {"id": 455, "seek": 317256, "start": 3172.56, "end": 3179.6, "text": " argue with them uh so maybe it's fair just to hold that they're they're biased and blind", "tokens": [50364, 9695, 365, 552, 2232, 370, 1310, 309, 311, 3143, 445, 281, 1797, 300, 436, 434, 436, 434, 28035, 293, 6865, 50716], "temperature": 0.0, "avg_logprob": -0.10847605599297418, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.10080602020025253}, {"id": 456, "seek": 317256, "start": 3179.6, "end": 3185.6, "text": " i don't accept i don't accept an argument this is a proper argument so so where you say you're", "tokens": [50716, 741, 500, 380, 3241, 741, 500, 380, 3241, 364, 6770, 341, 307, 257, 2296, 6770, 370, 370, 689, 291, 584, 291, 434, 51016], "temperature": 0.0, "avg_logprob": -0.10847605599297418, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.10080602020025253}, {"id": 457, "seek": 317256, "start": 3185.6, "end": 3196.96, "text": " maybe at stage four in the research car max says 2030 uh that's you know it's far enough out there", "tokens": [51016, 1310, 412, 3233, 1451, 294, 264, 2132, 1032, 11469, 1619, 28638, 2232, 300, 311, 291, 458, 309, 311, 1400, 1547, 484, 456, 51584], "temperature": 0.0, "avg_logprob": -0.10847605599297418, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.10080602020025253}, {"id": 458, "seek": 319696, "start": 3196.96, "end": 3205.68, "text": " that maybe people won't remember in 2030 that he said 2030 uh it's always uh you know i've 2030", "tokens": [50364, 300, 1310, 561, 1582, 380, 1604, 294, 28638, 300, 415, 848, 28638, 2232, 309, 311, 1009, 2232, 291, 458, 741, 600, 28638, 50800], "temperature": 0.0, "avg_logprob": -0.08761128626371685, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.01882622390985489}, {"id": 459, "seek": 319696, "start": 3205.68, "end": 3212.7200000000003, "text": " has been out there for a long time and it's it's it's uh you can't it doesn't recede it's always", "tokens": [50800, 575, 668, 484, 456, 337, 257, 938, 565, 293, 309, 311, 309, 311, 309, 311, 2232, 291, 393, 380, 309, 1177, 380, 850, 4858, 309, 311, 1009, 51152], "temperature": 0.0, "avg_logprob": -0.08761128626371685, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.01882622390985489}, {"id": 460, "seek": 319696, "start": 3212.7200000000003, "end": 3224.2400000000002, "text": " been 2030 for the uh computer power reaching human scale um quantities yeah but anyway 2030 is is a", "tokens": [51152, 668, 28638, 337, 264, 2232, 3820, 1347, 9906, 1952, 4373, 1105, 22927, 1338, 457, 4033, 28638, 307, 307, 257, 51728], "temperature": 0.0, "avg_logprob": -0.08761128626371685, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.01882622390985489}, {"id": 461, "seek": 322424, "start": 3224.24, "end": 3230.16, "text": " reasonable it's a reasonable target for us understanding everything that we need in order", "tokens": [50364, 10585, 309, 311, 257, 10585, 3779, 337, 505, 3701, 1203, 300, 321, 643, 294, 1668, 50660], "temperature": 0.0, "avg_logprob": -0.09941045821659149, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.006091336254030466}, {"id": 462, "seek": 322424, "start": 3230.16, "end": 3236.72, "text": " to make uh a real mind yeah i'm good with that yeah as you you have to be ambitious", "tokens": [50660, 281, 652, 2232, 257, 957, 1575, 1338, 741, 478, 665, 365, 300, 1338, 382, 291, 291, 362, 281, 312, 20239, 50988], "temperature": 0.0, "avg_logprob": -0.09941045821659149, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.006091336254030466}, {"id": 463, "seek": 322424, "start": 3238.56, "end": 3249.2, "text": " i've always said that 2030 is a 25 chance of of of achieving a real intelligence a real human", "tokens": [51080, 741, 600, 1009, 848, 300, 28638, 307, 257, 3552, 2931, 295, 295, 295, 19626, 257, 957, 7599, 257, 957, 1952, 51612], "temperature": 0.0, "avg_logprob": -0.09941045821659149, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.006091336254030466}, {"id": 464, "seek": 324920, "start": 3249.2, "end": 3255.6, "text": " level intelligence 25 chance so probably not but it's it's a big enough chunk of probability that", "tokens": [50364, 1496, 7599, 3552, 2931, 370, 1391, 406, 457, 309, 311, 309, 311, 257, 955, 1547, 16635, 295, 8482, 300, 50684], "temperature": 0.0, "avg_logprob": -0.06093546060415415, "compression_ratio": 1.7844036697247707, "no_speech_prob": 0.08262438327074051}, {"id": 465, "seek": 324920, "start": 3256.16, "end": 3260.7999999999997, "text": " that an ambitious person should work towards it and try to make it true and it does depend upon", "tokens": [50712, 300, 364, 20239, 954, 820, 589, 3030, 309, 293, 853, 281, 652, 309, 2074, 293, 309, 775, 5672, 3564, 50944], "temperature": 0.0, "avg_logprob": -0.06093546060415415, "compression_ratio": 1.7844036697247707, "no_speech_prob": 0.08262438327074051}, {"id": 466, "seek": 324920, "start": 3260.7999999999997, "end": 3267.7599999999998, "text": " what we do and not just the uh unfolding of the universe so we should we should try to do that", "tokens": [50944, 437, 321, 360, 293, 406, 445, 264, 2232, 44586, 295, 264, 6445, 370, 321, 820, 321, 820, 853, 281, 360, 300, 51292], "temperature": 0.0, "avg_logprob": -0.06093546060415415, "compression_ratio": 1.7844036697247707, "no_speech_prob": 0.08262438327074051}, {"id": 467, "seek": 324920, "start": 3267.7599999999998, "end": 3274.08, "text": " that that is a big the big thing that's happening right now is the the the public is coming to grips", "tokens": [51292, 300, 300, 307, 257, 955, 264, 955, 551, 300, 311, 2737, 558, 586, 307, 264, 264, 264, 1908, 307, 1348, 281, 38037, 51608], "temperature": 0.0, "avg_logprob": -0.06093546060415415, "compression_ratio": 1.7844036697247707, "no_speech_prob": 0.08262438327074051}, {"id": 468, "seek": 327408, "start": 3274.08, "end": 3279.12, "text": " with what it means for there to be for us to understand the mind and to have the ability to", "tokens": [50364, 365, 437, 309, 1355, 337, 456, 281, 312, 337, 505, 281, 1223, 264, 1575, 293, 281, 362, 264, 3485, 281, 50616], "temperature": 0.0, "avg_logprob": -0.06242462517558665, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.09373725205659866}, {"id": 469, "seek": 327408, "start": 3279.12, "end": 3287.68, "text": " create uh minded things uh and so that that is a big uh transformation it's a big change in our", "tokens": [50616, 1884, 2232, 36707, 721, 2232, 293, 370, 300, 300, 307, 257, 955, 2232, 9887, 309, 311, 257, 955, 1319, 294, 527, 51044], "temperature": 0.0, "avg_logprob": -0.06242462517558665, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.09373725205659866}, {"id": 470, "seek": 327408, "start": 3287.68, "end": 3297.2799999999997, "text": " worldview um and so we absolutely need all kinds of people to uh to help us help us become easy", "tokens": [51044, 41141, 1105, 293, 370, 321, 3122, 643, 439, 3685, 295, 561, 281, 2232, 281, 854, 505, 854, 505, 1813, 1858, 51524], "temperature": 0.0, "avg_logprob": -0.06242462517558665, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.09373725205659866}, {"id": 471, "seek": 329728, "start": 3297.28, "end": 3304.88, "text": " and become have an understanding of what's happening as we uh achieve human level", "tokens": [50364, 293, 1813, 362, 364, 3701, 295, 437, 311, 2737, 382, 321, 2232, 4584, 1952, 1496, 50744], "temperature": 0.0, "avg_logprob": -0.09162200291951497, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.024785298854112625}, {"id": 472, "seek": 329728, "start": 3305.92, "end": 3311.76, "text": " designed intelligence that's it for this week's episode i want to thank richard for his time", "tokens": [50796, 4761, 7599, 300, 311, 309, 337, 341, 1243, 311, 3500, 741, 528, 281, 1309, 4593, 515, 337, 702, 565, 51088], "temperature": 0.0, "avg_logprob": -0.09162200291951497, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.024785298854112625}, {"id": 473, "seek": 329728, "start": 3311.76, "end": 3318.0800000000004, "text": " if you want to read a transcript of today's conversation you can find one on our website", "tokens": [51088, 498, 291, 528, 281, 1401, 257, 24444, 295, 965, 311, 3761, 291, 393, 915, 472, 322, 527, 3144, 51404], "temperature": 0.0, "avg_logprob": -0.09162200291951497, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.024785298854112625}, {"id": 474, "seek": 331808, "start": 3318.16, "end": 3326.3199999999997, "text": " i on ai that's e y e hyphen o n dot ai in the meantime remember the singularity may be getting", "tokens": [50368, 741, 322, 9783, 300, 311, 308, 288, 308, 2477, 47059, 277, 297, 5893, 9783, 294, 264, 14991, 1604, 264, 20010, 507, 815, 312, 1242, 50776], "temperature": 0.0, "avg_logprob": -0.22069010734558106, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.5259827971458435}, {"id": 475, "seek": 331808, "start": 3326.3199999999997, "end": 3334.88, "text": " closer but ai is already changing your world so pay attention", "tokens": [50776, 4966, 457, 9783, 307, 1217, 4473, 428, 1002, 370, 1689, 3202, 51204], "temperature": 0.0, "avg_logprob": -0.22069010734558106, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.5259827971458435}], "language": "en"}