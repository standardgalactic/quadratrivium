{"text": " Even if you train a system to have a world model that can predict what's going to happen next, the world is really complicated and there's probably all kinds of situations that the system hasn't been trained on and need to, you know, fine-tune itself as it goes. The question of how we organize AI research going forward which is somewhat determined by how afraid people are of the consequences of AI. So if you have a rather positive view of the impact of AI on society and you trust humanity and society and democracies to use it in good ways, then the best way to make progress is to open research. AI might be the most important new computer technology ever. It's storming every industry and literally billions of dollars are being invested. So buckle up. The problem is that AI needs a lot of speed and processing power. So how do you compete without cost spiraling out of control? It's time to upgrade to the next generation of the cloud, Oracle Cloud Infrastructure or OCI. OCI is a single platform for your infrastructure, database, application, development, and AI needs. OCI has four to eight times the bandwidth of other clouds, offers one consistent price instead of variable regional pricing, and of course nobody does data better than Oracle. So now you can train your AI models at twice the speed and less than half the cost of other clouds. If you want to do more and spend less like Uber, eight by eight, and Databricks Mosaic, take a free test drive of OCI at oracle.com slash ion AI. That's E-Y-E-O-N-A-I all run together oracle.com slash ion AI. Hi, I'm Craig Smith and this is ION AI. In this episode, I speak again with Yan Lacoon, one of the founders of deep learning and someone who followers of AI should need no introduction to. Yan talks about his work on developing world models on why he does not believe AI research poses a threat to humanity and why he thinks open source AI models are the future. In the course of the conversation, we talk about a new model, Gaia 1, developed by a company called Wave AI. I'll have an episode with Wave's founder to further explore that world model which has produced some startling results. I hope you find the conversation with Yan as enlightening as I did. First, the notion of world model is the idea that the system would get some idea of the state of the world and be able to predict sort of following states of the world resulting from just the natural evolution of the world or resulting from an action that the agent might take. If you have an idea of the state of the world and you imagine an action that you're going to take and you can predict the resulting state of the world, that means you can predict what's going to happen as a consequence of a sequence of actions and that means you can plan a sequence of actions to arrive at a particular goal. That's really what a world model is. At least that's what the Wave people have understood the word in other contexts, like in the context of optimal control and robotics and things like that. That's what a world model is. Now, there's several levels of complexity of those world models, whether they model yourself, the agent, or whether they model the external world, which is much more complicated. Training a world model basically consists in just observing the world go by and then learning to predict what's going to happen next, or observing the world taking an action and then observing the resulting effect, an action that you take as an agent or an action that you see other agents taking. That establishes causality essentially. You could think of this as a causal model. Those models don't need to predict all the details about the world. They don't need to be generative. They don't need to predict exactly every pixel in a video, for example, because what you need to be able to predict is enough details, some sort of abstract representation to allow you to plan. You're assembling something out of wood and you're going to put two planks together and attach them with screws. It doesn't matter the details of which type of screwdriver you're using or the size of the screw within some limits and things like that. There are details that in the end don't matter as to what the end result will be or the precise grain of the wood and things of that type. You need to have some abstract level of representation within which you can make the prediction without having to predict every detail. That's why those JPA architectures I've been advocating are useful. Models like the Gaia 1 model from Wave actually makes prediction in an abstract representation space. There's been a lot of work in that area for years also at FAIR, but generally the abstract representation were pre-trained. The encoders that would take images from videos and then encode them into some representation were trained in some other way. The progress we've made over the last six months in self-improvised learning for images and video is that now we can train the entire system to make those predictions simultaneously. We have systems now that can learn good representations of images and the basic idea is very simple. You take an image, you run it through an encoder, then you corrupt that image, you mask parts of it, for example, or you transform it in various ways, you blur it, you change the colors, you change the framing a little bit, and you run that corrupted image through the same encoder or something very similar. And then you train the encoder to predict the features of the complete image from the features of the corrupted one. You're not trying to reconstruct the perfect image, you're just trying to predict the representation of it. And this is different, this is not generative in the sense that it does not produce pixels. And that's the secret to getting self-supervisual into work in the context of images and video. You don't want to be predicting pixels, it doesn't work. You can't predict pixels as an afterthought, which is what the Gaia system is doing by sticking a decoder on it and with some diffusion model that will produce a nice image, but that's kind of a second step. If you train the system by predicting pixels, you just don't get good representations, you don't get good predictions, you get blurry predictions most of the time. So that's what makes learning from images and video fundamentally different from learning from text because in text you don't have that problem. It's easy to predict words, even if you cannot do a perfect prediction because language is discrete. So language is simple compared to the real world. And there's a lot written right now about the energy required in the computational resources GPUs required to train language models. Is it less in training a world model like using iJAPA architecture? Well, it's hard to tell because there is no equivalent training procedure, self-supervised training procedure for video, for example, that does not use JAPA. The ones that are generative don't really work. Yeah. Well, but this architecture could also be applied to language, couldn't it? Oh yeah, absolutely. Yeah, so you could very well use a JAPA architecture that makes prediction in representation space and apply to language. Yeah, definitely. And in that case, would it be less computationally intense than training a large language model? It's possible. It's not entirely clear either. I mean, there is some advantage regardless of what technique you're using to making those models really big. They just seem to work better if you make them big. So if you make them bigger. So scaling is useful. Contrary to some claims, I do not believe that scaling is sufficient. So in other words, we're not going to get anywhere close to human level AI. In fact, not even any more level AI by simply scaling up language models. Even multimodal language models that we applied to video, we're going to have to find new concepts, new architectures. And I've written a vision paper about this a while back of a different type of architecture that would be necessary for this. So scaling is necessary, but not sufficient. And we're missing some basic ingredients to get to human level AI. We're fooled by the fact that LLMs are fluent. And so we think that they have human level intelligence because they can manipulate language. But that's false. And in fact, there's a very good symptom for this, which is that we have systems that can pass the bar exam, but answering questions from text by basically regurgitating what they've learned, more or less by road. But we don't have completely autonomous level five cell driving cars, or at least no system that can learn to do this in about 20 hours of practice, just like any 17-year-old. And we certainly don't have any domestic robot that can clear up the dinner table and fill up the dishwasher attest that any 10-year-old can learn in one shot. So clearly, we're missing something big. And that something is an ability to learn how the world works and the world is much more complicated than language. And also being able to plan and reason, basically having a mental world model that allows to plan and predict consequences of actions. That's what we're missing. It takes a while before we figure this out. You were on another paper that talked about augmented language models. And in the embodied touring test, was that the same paper, the embodied touring test? Can you talk about that? First of all, what is the embodied touring test? I didn't quite understand that. Well, okay, it's a different concept. But it's basically the idea that you do, it's based on the Moravec paradox, right? So Moravec many years ago noticed that things that appeared difficult for humans turned out to sometimes be very easy for computers to do, like playing chess, much better than humans. Or I don't know, computing integrals or whatever, certainly doing arithmetic. But then there are things that we take for granted as humans that we don't even consider them intelligent tasks that we are incapable of reproducing with computers. And so that's where the embodied touring test comes in. Observe what a cat can do or how fast a cat can learn new tricks or how a cat can plan to jump on a bunch of different furniture to get to the top of wherever it wants to go. That's an amazing feat that we can't reproduce with robots today. So that's kind of the embodied touring test, if you want. Like, can you make a robot that can behave, have behaviors that are easily wishable from those of animals, first of all, and can acquire new ones with the same efficiency as animals? Then the augmented LLM paper is different. It's about how do you sort of minimally change large language models so that they can use tools so they can, to some extent, plan actions. Like, you know, you need to compute the product of two numbers, right? You just call a calculator and you know you're going to get the product of those two numbers. And LLMs are notoriously bad for arithmetic, so they need to do this kind of stuff or do a search, you know, using a search engine or database lookup or something like that. So there's a lot of work on this right now and it's somewhat incremental. Like, you know, how can you sort of minimally change LLM and take advantage of their current capabilities but still augment them with the ability to use tools? Yeah. And I don't want to get into the too much into the threat debate. But, you know, you're on one side, your colleagues, Jeff and Yashor on the other. I recently saw a picture of the three of you. I think you put that up on social media, saying how, you know, you can disagree but still be friends. This idea of augmenting language models with stronger reasoning capabilities and the ability, and agency, the ability to use tools is precisely what Jeff and Yashor are worried about. Can you just, why are you not worried about that? Okay. So first of all, what you're describing is not necessarily what they are afraid of. They are alerting people and various governments and others about various dangers that they perceive. Okay. So one danger, one set of dangers are relatively short-term. There are things like, you know, bad people will use technology for bad things. What can bad people use powerful AI systems for? And one concern that, you know, governments have been worried about and intelligence agencies encounter intelligence and stuff like that is, you know, could value-intentioned organizations or countries use LLM to help them, I don't know, design pathogens or chemical weapons or other things or cyber attacks, you know, things like that, right? Now, those problems are not new. Those problems have been with us for a long time. And the question is, what incremental help would AI systems bring to the table? So my opinion is that as of today, AI systems are not sophisticated enough to provide any significant help for such value-intentioned people because those systems are trained with public data that is publicly available on the internet. And they can't really invent anything. They're going to regurgitate with a little bit of interpolation if you want. But they cannot produce anything that you can't get from a search engine in a few minutes. So that claim is being tested at the moment. There are people who are actually kind of trying to figure out, like, is it the case that you can actually do something, you're unable to do something more dangerous with sort of current AI technology that you can do with a search engine results are not out yet. But my hunch is that, you know, it's not going to enable a lot of people to do significantly bad things. Then there is the issue of things like code generation for cyber attacks and things like this. And those problems have been with us for years. And the interesting thing that most people should know, like, you know, also for like disinformation or attempts to corrupt the electoral process and things like this. And what's very important for everyone to know is that the best countermeasures that we have against all of those attacks currently use AI massively. Okay. So AI is used as a defense mechanism against those attacks. It's not actually used to do the attacks yet. And so now it becomes the question of, you know, who has the better system, like other countermeasures? Is the AI countermeasures significantly better than the AI is used by the attackers so that, you know, the problem is satisfactorily mitigated. And that's what we are. Now, the good news is that there are many more good guys and bad guys. They're usually much more competent. They're usually much more sophisticated. They're usually much more better funded. And they have a strong incentive to take down the attackers. So it's a game of cat and mouse, just like every security that's ever existed. There's nothing new there. Okay. Nothing quite entirely new. Yeah. But then there is the question of existential risk, right? And this is something that both Jeff and Yosha have been thinking of fairly recently. So for Jeff, it's only sort of just before last summer that he became, he started thinking about this because before he thought he was convinced that the kind of algorithms that we had were significantly inferior to the kind of learning algorithm that the brain used. And the epiphany he had was that, in fact, no, because looking at the capabilities of large English models, they can do pretty amazing things with a relatively small number of neurons and synapses. He said, maybe they're more efficient than the brain. And maybe the learning algorithm that we use, back propagation, is actually better than whatever it is that the brain uses. So he started thinking about like, you know, what are the consequences? And but that's very recent. And in my opinion, he hasn't thought about this enough. Yosha went to a similar epiphany last winter, where he started thinking about the long-term consequences. And came to the conclusion also that there was a potential danger. They're both convinced that AI has enormous potential benefits. They're just worried about the dangers. And they're both worried about the dangers because they have some doubts about the ability of our institutions to do the best with technology. You know, whether they are political, economic, geopolitical, financial institutions, or industrial, to do the right thing, to be motivated by the right thing. So you know, if you trust the system, if you trust humanity and democracy, you might be entitled to believe that society is going to make the best use of future technology. If you don't believe in the solidity of those institutions, then you might be scared. Okay. I think I'm more confident in humanity and democracy than they are. And, and, you know, whatever current systems and they are, I've been thinking about this problem for much longer, actually, since at least 2014. So when I started fair at Facebook at the time, it became pretty clear, pretty early on that, you know, deploying AI systems was going to have big consequences on people in society. And we got confronted to this very early. And so I started thinking about those problems very early on. Things like, you know, counter measures against like bias in AI systems, systematic bias, counter measures against attacks, or, you know, detection of hate speech in every language, things like that. These are things that people at fair worked on and then were eventually deployed. To just to give you an example, the proportion of hate speech that was taken down automatically by AI systems five years ago, you know, in 2017, was about 20 to 25%. Last year, it was 95%. And the difference is entirely due to progress in natural language understanding, entirely grew to transformers that are pretrained self-supervised and can essentially detect hate speech in any language. Not perfectly. Nothing is perfect. It's ever perfect. But AI is massively there. And that's the solution. So I started thinking about those issues, including existential risk, very early on. In fact, in 2015, early 2016, actually, I organized a conference hosted at NYU on the future of AI, where a lot of those questions were discussed. I invited people like, you know, Eric Schmidt and Mark Schreffer, who was the CTO of Facebook at the time. A lot of people, both from the academic and AI research side and from the industry side. And there were two days, a public day and kind of a more private day. What came out of this is the creation of an institution called a partnership on AI. So this is a discussion I had with Mr. Sabis, which was, you know, would it be useful to have a forum where we can discuss before they happen, sort of bad things that could happen as a consequence of deploying AI? Pretty soon, we brought on board Eric Horvitz and a bunch of other people, and we co-founded this thing called a partnership on AI, which basically has been funding studies about AI ethics and consequences of AI and publishing guidelines about, you know, how you do it right to me and my time. So this is not a new thing for me. Like, I've been thinking about this for 10 years, essentially. Whereas for Yosha and Jeff, it's much more recent. Yeah. But nonetheless, this augmented AI or augmented language models that have stronger reasoning and agency raises the threat, regardless of whether or not it can be countered to a higher level. Right. Okay. So I guess the question there becomes, what is the blueprint of future AI systems that will be capable of reasoning and planning, will understand how the world works, will be able to, you know, use tools and have agency and things like that. Right. And I tell you, they will not be autoregressive LLMs. So the problems that we see at the moment of autoregressive LLM, the fact that they hallucinate, they sometimes say really stupid things. They don't really have a good understanding of the world. People claim that they have some simple word model, but it's very implicit and it's really not good at all. Like, for example, you know, you can tell an LLM that A is the same as B. And then you ask if B is the same as A, and it will say, I don't know, or no. Right. I mean, those things don't really understand logic or anything like that. Right. So the type of system that we're talking about that might be, that might approach any more level intelligence and let alone human level intelligence have not been designed. They don't exist. And so discussing their danger and their potential harm is a bit like, you know, discussing the sex of angels at the moment, or to be a little more accurate, perhaps, it would be kind of like discussing how we're going to make transatlantic flight at near the speed of sound safe when we haven't yet invented the turbojet in 1925. Yeah. Yeah. Like, you know, we can speculate, but you know, how do we, how did we make turbojet safe? It required decades of really careful engineering to make them incredibly reliable. And, you know, now we can, you know, run like halfway around the world with the two-engine turbojet aircraft. I mean, that's an incredible feat. And it's not like people were discussing sort of philosophical questions about how you make turbojet safe. It's just really careful and complicated engineering that no one, none of us would understand. So, you know, how could we ask the AI community now to explain how AI systems are going to be safe? We haven't invented them yet. No. Okay. That said, I have some idea about how we can design them so that they have these capabilities. And as a consequence, how they will be safe, I call this objective driven AI. So what that means is essentially systems that produce their answer by planning their answer so as to satisfy an objective or a set of objectives. So this is very different from current LLNs. Current LLNs produce one word after the other or one token, which is, which has a board unit, doesn't matter, right? They don't really think and plan ahead as we, as we said before. They just produce one word after the other. That's not controllable. The only thing we can do is see if what they've produced, like check if what they've produced satisfies some criterion or set of criteria and then not produce an answer or produce a non-answer if the answer that was produced isn't appropriate. But we can't really force them to produce an answer that satisfies a set of objectives. So objective driven AI is the other way, is the opposite. The only thing that the system can produce are answers that satisfy a certain number of objectives. So what objective would be? Did you answer the question? Another objective could be, is your answer understandable by a 13 year old because you're talking to a 13 year old? Another would be, is this, I don't know, terrorist propaganda or something? You know, you can have a number of criteria like this, guardrails that would guarantee that the answer that's produced is satisfy certain criteria, whatever they are. Okay. Same for a robot, you could guarantee that the sequence of actions that is produced will not hurt anyone. Like you can have very low level, you know, guardrails of this type that say, okay, you have, you know, humans nearby and you're cooking, so you have a big knife in your hand, don't flare your arms. Okay, that would be a very simple guardrails to impose. And you can imagine having a whole bunch of guardrails like this that will guarantee that the behavior of those systems would be safe and that their primary goal would be to be basically subservient to us, right? So I do not believe that we'll have AI systems that can work that will not be subservient to us, will define their own goals, they will define their own sub goals, but those sub goals would be sub goals or goals that we set them and will not have all kinds of guardrails that will guarantee the safety. And we're not going to, it's not like we're going to invent a system and make a gigantic one that we know will have human level AI and just turning on and then from the next minute is going to take over the world. That's completely preposterous. What we're going to do is try with small ones, you know, maybe as smart as a mouse or something, maybe a dog, maybe a cat, maybe a dog, maybe and work our way up and then, you know, put some more guardrails. Basically, like we've engineered, you know, more and more powerful and more reliable turbojets. It's an engineering problem. Yeah, yeah. You were also on a paper, maybe this is the one that talked about the embodied Turing test on neuro AI. Can you explain what the neuro AI is? Okay. Well, it's the idea that we should get some inspiration from neuroscience to build AI systems and that there is something to be learned from neuroscience and from cognitive science to drive the design of AI systems, some inspiration. Okay. Something to be learned as well as the other way around. So what's interesting right now is that the best models that we have of how, for example, the visual cortex works is convolutional neural networks, which are also the models that we use to recognize images primarily in artificial systems. So there is kind of information kind of being exchanged both ways. There's one, you know, one way to make progress in AI is to kind of ignore nature and just, you know, kind of try to solve problems in a sort of engineering fashion, if you want. I found interaction with neuroscience always thought provoking. So you don't want to be copying nature very too closely because there are details in nature that are irrelevant. And there are principles on which, you know, natural intelligence is based that we haven't discovered. So, but there is some inspiration to have certainly in your convolutional net for inspired by the architecture of the visual cortex. The whole idea of neural net and deep learning came out of the idea that, you know, intelligence can emerge from a large collection of simple elements that are connected with each other and change the nature of their interactions. That's the whole idea, right? So, so inspiration from neuroscience certainly has been extremely beneficial so far. And the idea of neural AI is that you should keep going. You don't want to go too far. So going too far, for example, is trying to reproduce the some aspect of the functioning of neurons with electronics. I'm not sure that's a good idea. I'm skeptical about this, for example. So your research right now, are you, your main focus is on furthering the JEPA architecture into other modalities or where are you headed? Yeah. So, I mean, the long term goal is, you know, to get machines to be as intelligent and learn as efficiently as animals and humans. Okay. And the reason for this is that we need this because we need to amplify human intelligence. And so intelligence is the most needed commodity that we want in the world, right? And so we could, you know, possibly bring a new renaissance to humanity if we could amplify human intelligence using machines, which we are doing already with computers, right? I mean, that's pretty much what they've been designed to do. But even more, you know, imagine a future where every one of us has an intelligent assistant with us at all times. They can be smarter than us. You shouldn't feel threatened by that. We should feel like we are like, you know, a director of a big lab or a CEO of a company that has a staff working for them of people who are smarter than themselves. I mean, we're used to this already. I'm used to this certainly working with people who are smarter than me. So we shouldn't feel threatened by this, but it's going to empower a lot of us, right, and humanity as a whole. So I think that's a good thing. That's the overall practical goal, if you want, right? Then there's a scientific question that's behind this, which is really what is intelligence and how you build it. And then which is, you know, how can system learn the way animals and humans seem to be learning so efficiently? And the next thing is, how do we learn how the world works by observation, by watching the world go by through vision and all the other senses? And animals can do this without language, right? So it has nothing to do with language, has to do with learning from sensory perceives and learning mostly without acting, because any action you take can kill you. So it's better to be able to learn as much as you can without actually acting at all, just observing, which is what babies do in the first few months of life. They can't hardly do anything, right? So they mostly observe and learn how the world works by observation. So what kind of learning takes place there? So that's obviously kind of self-supervised, right? It's learning by prediction. That's an whole idea from cognitive science. And the thing is, you know, we can learn to predict videos, but then we notice that predicting videos, predicting pixels in video, is so initially complicated that it doesn't work. And so then came this idea of JEPA, right? Learn representations so that you can make predictions in representation space. And that turned out to work really well for learning image features. And now we're working on getting this to work for video. And eventually, we'll be able to use this to learn to learn world models, where you show a piece of video, and then you say, I'm going to take this action, predict what's going to happen next in the world. And, you know, which is a bit where the Gaia system from Wave is doing at a high level, but we need this at sort of various levels of abstraction, so that we can build, you know, systems that are more general than autonomous driving. Okay. That's the... Yeah. And it's my fault, so I won't go over the hour. But is it conceivable that someday there'll be a model that you may be embodied in a robot that is ingesting video from its environment and learning as it's just continuously learning and getting smarter and smarter and smarter? Yeah. I mean, that's kind of a bit of a necessity. The reason being that, you know, even if you train a system to have a world model that can predict what's going to happen next, the world is really complicated. And there's probably all kinds of situations that you, you know, the system hasn't been trained on and need to, you know, fine tune itself as it goes. So, you know, animals and humans do this early in life by playing. So play is a way of learning your world model in situations that basically you won't hurt you. And, but then during life, of course, you know, when we don't drive, there's all kinds of these mistakes that we do initially that we don't do after having some experience. And that's because we're fine tuning our world model to some extent. We're learning a new task. We're basically just learning a new version of our world model. Right. So, so yeah, I mean, this type of continuous, continual learning is going to have to be present. But the overall power and the intelligence of the system will be limited by, you know, how much a co-governor on that is using and various other constraints, you know, computational constraints, basically. And, you know, you're still young. And, and this not sure about that. Well, you're younger than Jeff. Let me put it that way. But this, the progress you've made on world models is, is fairly rapid from my point of view, watching it. Are you, are you hopeful that within your career, you'll have embodied robots that are, are building world models through their interaction in reality, and, and then being able to, well, I guess the other question on world models, do you then combine it with a language model to do reasoning or, or is the world model able to, to do reasoning on its own? But are you hopeful that in your career, you'll, you'll get to the point where you'll have this continuous learning in a world model? Yeah, I sure hope so. I might have another, you know, 10, 10 useful years or something like this in research before my brain, you know, turns into dish and male sauce, but, or something like that, you know, 15 years if I'm lucky. So, or perhaps less. But yeah, I hope that there's going to be breakthroughs in that direction during that time. Now, whether that will result in the kind of artifact that you're describing, you know, robots that can, like, you know, domestic robots, for example, or, or sort of in cars that are, they can run fairly quickly by themselves. I don't know, because there might be all kinds of obstacles that we have not envisaged that may appear on the way. You know, that's, it's a constant in the history of AI that you have some new idea and a breakthrough, and you think that's going to solve all the world's problems. And then you're going to hit limitation, and you have to go beyond that limitation. So it's like, you know, you're climbing a mountain, you find a way to climb the mountain that you're seeing. And you know that once you get to the top, you will have the problem solved because now it's, you know, the gentle slope down. And once you get to the top, you realize that there is another mountain behind it that you hadn't seen. So that's, that's, that's been the history of AI, right, where people have come up with sort of new concepts, new ideas, new way to approach AI reasoning, whatever, perception, and then realize that their idea basically was very limited. And so, so, you know, this, inevitably, we're trying to figure out what's the next revolution in AI. That's what I'm trying to figure out. So, you know, learning how the world works from video, having systems that have world model allows systems to reason and plan. And there's something I want to be very clear about, which is an answer to your question, which is that you can have systems that reason and plan without manipulating language. Animals are capable of amazing feats of planning and also to some extent reasoning. They don't have language, at least most of them don't. And so, many of them don't have culture because they are mostly solitary animals. So, you know, it's only the animals that have some level of culture. So, so the idea that a system can plan and reason is not connected with the idea that you can manipulate language. Those are two different things. It needs to be able to manipulate abstract notions. But those notions do not necessarily correspond to linguistic entities like words or things like that. We can have mental images if you want to things. Like you do ask a physicist or a mathematician, you know, how they reason is very much in terms of sort of mental models. I have nothing to do with language. Then you can turn things into language. But that's a different story. That's the second step. So, so, you know, we're going to have to figure out how to do this reasoning, hierarchical planning in machines, reproduce this first. And then, of course, you know, sticking language on top of it will help. Like, we'll make those systems smarter and be able, you know, we will allow us to communicate with them and teach them things. And they're going to be able to teach us things and stuff like that. But this is a different question, really. The question of how we organize AI research going forward, which is somewhat determined by how afraid people are of the consequences of AI. So, if you have a rather positive view of the impact of AI on society, and you trust humanity and society and democracies to use it in good ways, then the best way to make progress is to open research. And for the people who are afraid of the consequences, whether they are societal or geopolitical, they're putting pressure on governments around the world to regulate AI in ways that basically limit access, particularly of open source code and things like that. And it's a big debate at the moment. I'm very much on the side. So, he's met up very much on the side of open research. Yeah, actually, that was something I was going to ask you. And now that you've brought it up. Because there, I've been talking to people about this. And there is a view that aside from the risks of open source, you know, again, Jeff Hinton saying, you know, would you open source thermonuclear weapons? Aside from that is the question of as to whether open source can marshal the resources to compete with proprietary models. And because of the tremendous resources required for when you're scaling these models. And there's a question as to whether or not Meta will continue to open source future versions of Lama or not continue to open source, but whether it'll continue to invest the resources needed to push the open source models. So what do you think about that? Okay, there's a lot to say about this. Okay, so first thing is, there's no question that Meta will continue to invest the resources to build better and better AI systems, because it needs it for its own products. So the resources will be invested. Now, the next question is, do you, you know, will we continue to open source the base models? And the answer is, you know, probably yes, because that creates an ecosystem on top of which an entire industry can be built. And there is no point, you know, having 50 different companies building proprietary close systems when you can have, you know, one good base open source base model that everybody can use. It's wasteful. And it's not a good idea. And another reason for having open source models is that it, it nobody has no entity as powerful as it thinks it is, as a monopoly on good ideas. And so if you want people who can have good new innovative ideas to contribute, you need an open source platform. If you want the academic world to contribute, you need open source platforms. If you want the startup world to be able to build customized products, you need open source base models, because they don't have the resources to build to train large models, right? Okay, and then there is the history that shows that for, for foundational technology, for infrastructure type technology, open source always wins, right? It's true of the software infrastructure of the internet. In the early 90s and mid 90s, there was a big battle between sun macro systems and Microsoft to produce the, deliver the software infrastructure of the internet, you know, operating systems, web servers, web browsers, and, and, you know, various servers aside and client-side frameworks, right? They're both lost. Nobody is talking about them anymore. The entire world is, of the web is using Linux and Apache and MySQL and JavaScript and, and, you know, and even the, the basic core code for, for web browser is open source. So, open source won by a huge margin. Why? Because it's safer, gathers more people to contribute. All the features are unnecessary. It's more reliable. Venerabilities are fixed faster. And, and it's customizable. So anybody can customize Linux to run on whatever hardware they want, right? So open source wins. And the same, same for AI. It's going to be the same thing. It's inevitable. The, the people now who are climbing up, like open AI, their, their system is based on publications from all of us. Sure. And from open platforms like, like PyTorch. Yeah. Judgeability is built using PyTorch. PyTorch was produced originally by Meta. Now it's owned by the Linux Foundation. It's open source. They've contributed to it, by the way. You know, their LLM is based on transformer architectures invented at Google. Yeah. All the tricks to kind of train all those things came out of like various papers from all kinds of different institutions, including academia, all the fine-tuning techniques, same. So nobody works in a vacuum. The thing is, nobody can keep their advance and their advantage for very long if they are secretive. Yeah. Except that with these models, because they're so compute intensive and they cost so much money to train, you need somebody like Meta that who's, who's going to be willing to build them and open source them. And that's why I was, when I was asking whether they'll continue, obviously Meta will continue building, you know, resource-intensive models. But the question is whether they'll continue to open source. I mean, if- I'm telling you, I'm telling you the only reason why Meta could stop open sourcing models are legal. So if there is a law that adds laws, open source AI systems above a certain level of sophistication, then of course we can do it. If there are laws that in the US or across the world makes it illegal to use public content to train AI systems, then it's the end of AI for everybody, not just for the open source. Okay. So, or at least the end of the type of AI that we are talking about today might have, you know, new AI in the future, but that don't require as much data. So, and then there is, you know, liability. If you, if you, if you, if you believe in the kind of that someone doing something bad with an AI system that was open sourced by by Meta, then Meta is liable, then Meta will have a big incentive not to release it, obviously. So it's the entire question about this is around legal reasons and political decisions. But on the idea of open source winning, don't you need more people or more companies like Meta building the foundation models and open sourcing them? Or could it be, could an open source ecosystem win based on a single company building the models? No, I mean, you need two or three. And there are two or three, right? I mean, there is this hugging face. There is Mistral in France, who's also embracing sort of an open source LLM. They're very good LLM. It's a small one, but it's very good. There is, you know, academic efforts like Lyon. They don't have all the resources they need, but they, you know, they collect the data that is used by everyone. So everybody can contribute. One thing that I think is really important to understand also is that there is a future in which I described earlier in which every one of us, every one of our interactions with the digital world will be mediated by an AI assistant. And this is going to be for true for everyone around the world, right? Everyone who has any kind of smart device. Eventually it's going to be in our, you know, augmented reality glasses, but, you know, for the time being in our smartphones, right? And so imagine that future where, you know, you are, I don't know, from Indonesia or Senegal or France. And your entire digital diet is done through the mediation of an AI system. Your government is not going to be happy about it. Your government is going to want the local culture to be present in that system. It doesn't want that system to be closed sourced and controlled by a company on the west coast of the US. So just for reasons of preserving the diversity of culture across the world and not having or entire information diet being biased by whatever it is that some company on the west coast of the US states, there's going to need to be open source platforms. And they're going to be predominant in at least outside the US for that reason. Including China, right? There is all those talks about, oh, what if China puts their hands on our open source code? I mean, China wants control over its own LLM because they don't want their citizen to, you know, have access to certain type of information. So they're not going to use our LLMs. They're going to trend theirs that they already have. And nobody is, you know, particularly ahead of anybody else by more than about a year. Yeah. And China is pushing open source. I mean, they're very pro open source within their ecosystems. Some of them, you know, it's there's no like unified opinion there. But I mean, it's the same in in the West, right? There are some some governments that are too afraid of the risks. And then or are thinking about it and some others that are all for open source because they see this as the only way for them to have any influence on the type of information and culture that would be mediated by those systems. So it's going to have to be like Wikipedia, right? Wikipedia, you know, is built by millions of people who contribute to or from all around the world in all kinds of languages. Okay. And it has a system for sort of vetting the information. The way AI systems of the future will be taught and we'll be fine tuned will have to be the same way will have to be quite sourced. Because something that matters to a farmer in southern India is probably not going to be taken into account by the fine tuning done by, you know, some some company on the west coast of the US. AI might be the most important new computer technology ever. It's storming every industry and literally billions of dollars are being invested. So buckle up. The problem is that AI needs a lot of speed and processing power. So how do you compete without cost spiraling out of control? It's time to upgrade to the next generation of the cloud oracle cloud infrastructure or OCI. OCI is a single platform for your infrastructure, database, application, development and AI needs. OCI has four to eight times the bandwidth of other clouds, offers one consistent price instead of variable regional pricing. And of course, nobody does data better than oracle. So now you can train your AI models at twice the speed and less than half the cost of other clouds. If you want to do more and spend less like Uber, eight by eight and Databricks Mosaic, take a free test drive of OCI at oracle.com slash I on AI. That's E Y E O N A I all run together oracle.com slash I on AI. That's it for this episode. I want to thank Yen for his time. If you want to read a transcript of this conversation, you can find one on our website I on AI. That's E Y E hyphen O N dot AI. And remember the singularity may not be near, but AI is changing your world. So best pay attention.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.2, "text": " Even if you train a system to have a world model that can predict what's going to happen next,", "tokens": [50364, 2754, 498, 291, 3847, 257, 1185, 281, 362, 257, 1002, 2316, 300, 393, 6069, 437, 311, 516, 281, 1051, 958, 11, 50524], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 1, "seek": 0, "start": 3.2, "end": 7.5200000000000005, "text": " the world is really complicated and there's probably all kinds of situations that the system", "tokens": [50524, 264, 1002, 307, 534, 6179, 293, 456, 311, 1391, 439, 3685, 295, 6851, 300, 264, 1185, 50740], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 2, "seek": 0, "start": 7.5200000000000005, "end": 13.44, "text": " hasn't been trained on and need to, you know, fine-tune itself as it goes. The question of how", "tokens": [50740, 6132, 380, 668, 8895, 322, 293, 643, 281, 11, 291, 458, 11, 2489, 12, 83, 2613, 2564, 382, 309, 1709, 13, 440, 1168, 295, 577, 51036], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 3, "seek": 0, "start": 13.44, "end": 18.72, "text": " we organize AI research going forward which is somewhat determined by how afraid people are", "tokens": [51036, 321, 13859, 7318, 2132, 516, 2128, 597, 307, 8344, 9540, 538, 577, 4638, 561, 366, 51300], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 4, "seek": 0, "start": 18.72, "end": 24.32, "text": " of the consequences of AI. So if you have a rather positive view of the impact of AI on society and", "tokens": [51300, 295, 264, 10098, 295, 7318, 13, 407, 498, 291, 362, 257, 2831, 3353, 1910, 295, 264, 2712, 295, 7318, 322, 4086, 293, 51580], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 5, "seek": 0, "start": 24.32, "end": 28.88, "text": " you trust humanity and society and democracies to use it in good ways, then the best way to", "tokens": [51580, 291, 3361, 10243, 293, 4086, 293, 6366, 20330, 281, 764, 309, 294, 665, 2098, 11, 550, 264, 1151, 636, 281, 51808], "temperature": 0.0, "avg_logprob": -0.10418575688412315, "compression_ratio": 1.7099697885196374, "no_speech_prob": 0.005165860988199711}, {"id": 6, "seek": 2888, "start": 28.88, "end": 35.68, "text": " make progress is to open research. AI might be the most important new computer technology ever.", "tokens": [50364, 652, 4205, 307, 281, 1269, 2132, 13, 7318, 1062, 312, 264, 881, 1021, 777, 3820, 2899, 1562, 13, 50704], "temperature": 0.0, "avg_logprob": -0.08339549755227976, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.009551489725708961}, {"id": 7, "seek": 2888, "start": 35.68, "end": 41.76, "text": " It's storming every industry and literally billions of dollars are being invested. So buckle up.", "tokens": [50704, 467, 311, 7679, 278, 633, 3518, 293, 3736, 17375, 295, 3808, 366, 885, 13104, 13, 407, 37686, 493, 13, 51008], "temperature": 0.0, "avg_logprob": -0.08339549755227976, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.009551489725708961}, {"id": 8, "seek": 2888, "start": 42.4, "end": 48.239999999999995, "text": " The problem is that AI needs a lot of speed and processing power. So how do you compete", "tokens": [51040, 440, 1154, 307, 300, 7318, 2203, 257, 688, 295, 3073, 293, 9007, 1347, 13, 407, 577, 360, 291, 11831, 51332], "temperature": 0.0, "avg_logprob": -0.08339549755227976, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.009551489725708961}, {"id": 9, "seek": 2888, "start": 48.239999999999995, "end": 54.879999999999995, "text": " without cost spiraling out of control? It's time to upgrade to the next generation of the cloud,", "tokens": [51332, 1553, 2063, 10733, 4270, 484, 295, 1969, 30, 467, 311, 565, 281, 11484, 281, 264, 958, 5125, 295, 264, 4588, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08339549755227976, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.009551489725708961}, {"id": 10, "seek": 5488, "start": 55.52, "end": 63.120000000000005, "text": " Oracle Cloud Infrastructure or OCI. OCI is a single platform for your infrastructure,", "tokens": [50396, 25654, 8061, 38425, 2885, 420, 422, 25240, 13, 422, 25240, 307, 257, 2167, 3663, 337, 428, 6896, 11, 50776], "temperature": 0.0, "avg_logprob": -0.091355528150286, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.06368158757686615}, {"id": 11, "seek": 5488, "start": 63.120000000000005, "end": 71.12, "text": " database, application, development, and AI needs. OCI has four to eight times the bandwidth of other", "tokens": [50776, 8149, 11, 3861, 11, 3250, 11, 293, 7318, 2203, 13, 422, 25240, 575, 1451, 281, 3180, 1413, 264, 23647, 295, 661, 51176], "temperature": 0.0, "avg_logprob": -0.091355528150286, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.06368158757686615}, {"id": 12, "seek": 5488, "start": 71.12, "end": 78.72, "text": " clouds, offers one consistent price instead of variable regional pricing, and of course nobody", "tokens": [51176, 12193, 11, 7736, 472, 8398, 3218, 2602, 295, 7006, 10964, 17621, 11, 293, 295, 1164, 5079, 51556], "temperature": 0.0, "avg_logprob": -0.091355528150286, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.06368158757686615}, {"id": 13, "seek": 7872, "start": 78.72, "end": 85.92, "text": " does data better than Oracle. So now you can train your AI models at twice the speed and less than", "tokens": [50364, 775, 1412, 1101, 813, 25654, 13, 407, 586, 291, 393, 3847, 428, 7318, 5245, 412, 6091, 264, 3073, 293, 1570, 813, 50724], "temperature": 0.0, "avg_logprob": -0.12451596312470488, "compression_ratio": 1.429951690821256, "no_speech_prob": 0.2876330316066742}, {"id": 14, "seek": 7872, "start": 85.92, "end": 93.36, "text": " half the cost of other clouds. If you want to do more and spend less like Uber, eight by eight,", "tokens": [50724, 1922, 264, 2063, 295, 661, 12193, 13, 759, 291, 528, 281, 360, 544, 293, 3496, 1570, 411, 21839, 11, 3180, 538, 3180, 11, 51096], "temperature": 0.0, "avg_logprob": -0.12451596312470488, "compression_ratio": 1.429951690821256, "no_speech_prob": 0.2876330316066742}, {"id": 15, "seek": 7872, "start": 93.92, "end": 106.0, "text": " and Databricks Mosaic, take a free test drive of OCI at oracle.com slash ion AI. That's E-Y-E-O-N-A-I", "tokens": [51124, 293, 40461, 81, 7663, 376, 42261, 11, 747, 257, 1737, 1500, 3332, 295, 422, 25240, 412, 420, 7041, 13, 1112, 17330, 17437, 7318, 13, 663, 311, 462, 12, 56, 12, 36, 12, 46, 12, 45, 12, 32, 12, 40, 51728], "temperature": 0.0, "avg_logprob": -0.12451596312470488, "compression_ratio": 1.429951690821256, "no_speech_prob": 0.2876330316066742}, {"id": 16, "seek": 10600, "start": 106.0, "end": 117.04, "text": " all run together oracle.com slash ion AI. Hi, I'm Craig Smith and this is ION AI. In this episode,", "tokens": [50364, 439, 1190, 1214, 420, 7041, 13, 1112, 17330, 17437, 7318, 13, 2421, 11, 286, 478, 19732, 8538, 293, 341, 307, 286, 1928, 7318, 13, 682, 341, 3500, 11, 50916], "temperature": 0.0, "avg_logprob": -0.13993755340576172, "compression_ratio": 1.438423645320197, "no_speech_prob": 0.08383267372846603}, {"id": 17, "seek": 10600, "start": 117.04, "end": 124.48, "text": " I speak again with Yan Lacoon, one of the founders of deep learning and someone who followers of AI", "tokens": [50916, 286, 1710, 797, 365, 13633, 40113, 4106, 11, 472, 295, 264, 25608, 295, 2452, 2539, 293, 1580, 567, 13071, 295, 7318, 51288], "temperature": 0.0, "avg_logprob": -0.13993755340576172, "compression_ratio": 1.438423645320197, "no_speech_prob": 0.08383267372846603}, {"id": 18, "seek": 10600, "start": 124.48, "end": 131.68, "text": " should need no introduction to. Yan talks about his work on developing world models on why he", "tokens": [51288, 820, 643, 572, 9339, 281, 13, 13633, 6686, 466, 702, 589, 322, 6416, 1002, 5245, 322, 983, 415, 51648], "temperature": 0.0, "avg_logprob": -0.13993755340576172, "compression_ratio": 1.438423645320197, "no_speech_prob": 0.08383267372846603}, {"id": 19, "seek": 13168, "start": 131.68, "end": 139.28, "text": " does not believe AI research poses a threat to humanity and why he thinks open source AI models", "tokens": [50364, 775, 406, 1697, 7318, 2132, 26059, 257, 4734, 281, 10243, 293, 983, 415, 7309, 1269, 4009, 7318, 5245, 50744], "temperature": 0.0, "avg_logprob": -0.08142726522096445, "compression_ratio": 1.5076142131979695, "no_speech_prob": 0.024029890075325966}, {"id": 20, "seek": 13168, "start": 139.28, "end": 146.72, "text": " are the future. In the course of the conversation, we talk about a new model, Gaia 1, developed by a", "tokens": [50744, 366, 264, 2027, 13, 682, 264, 1164, 295, 264, 3761, 11, 321, 751, 466, 257, 777, 2316, 11, 10384, 654, 502, 11, 4743, 538, 257, 51116], "temperature": 0.0, "avg_logprob": -0.08142726522096445, "compression_ratio": 1.5076142131979695, "no_speech_prob": 0.024029890075325966}, {"id": 21, "seek": 13168, "start": 146.72, "end": 155.04000000000002, "text": " company called Wave AI. I'll have an episode with Wave's founder to further explore that world model", "tokens": [51116, 2237, 1219, 28530, 7318, 13, 286, 603, 362, 364, 3500, 365, 28530, 311, 14917, 281, 3052, 6839, 300, 1002, 2316, 51532], "temperature": 0.0, "avg_logprob": -0.08142726522096445, "compression_ratio": 1.5076142131979695, "no_speech_prob": 0.024029890075325966}, {"id": 22, "seek": 15504, "start": 155.04, "end": 160.95999999999998, "text": " which has produced some startling results. I hope you find the conversation with Yan", "tokens": [50364, 597, 575, 7126, 512, 722, 1688, 3542, 13, 286, 1454, 291, 915, 264, 3761, 365, 13633, 50660], "temperature": 0.0, "avg_logprob": -0.08298273881276448, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.014707704074680805}, {"id": 23, "seek": 15504, "start": 160.95999999999998, "end": 168.48, "text": " as enlightening as I did. First, the notion of world model is the idea that the system would get", "tokens": [50660, 382, 18690, 4559, 382, 286, 630, 13, 2386, 11, 264, 10710, 295, 1002, 2316, 307, 264, 1558, 300, 264, 1185, 576, 483, 51036], "temperature": 0.0, "avg_logprob": -0.08298273881276448, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.014707704074680805}, {"id": 24, "seek": 15504, "start": 168.48, "end": 174.95999999999998, "text": " some idea of the state of the world and be able to predict sort of following states of the world", "tokens": [51036, 512, 1558, 295, 264, 1785, 295, 264, 1002, 293, 312, 1075, 281, 6069, 1333, 295, 3480, 4368, 295, 264, 1002, 51360], "temperature": 0.0, "avg_logprob": -0.08298273881276448, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.014707704074680805}, {"id": 25, "seek": 15504, "start": 174.95999999999998, "end": 178.95999999999998, "text": " resulting from just the natural evolution of the world or resulting from an action that the", "tokens": [51360, 16505, 490, 445, 264, 3303, 9303, 295, 264, 1002, 420, 16505, 490, 364, 3069, 300, 264, 51560], "temperature": 0.0, "avg_logprob": -0.08298273881276448, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.014707704074680805}, {"id": 26, "seek": 17896, "start": 178.96, "end": 185.44, "text": " agent might take. If you have an idea of the state of the world and you imagine an action that", "tokens": [50364, 9461, 1062, 747, 13, 759, 291, 362, 364, 1558, 295, 264, 1785, 295, 264, 1002, 293, 291, 3811, 364, 3069, 300, 50688], "temperature": 0.0, "avg_logprob": -0.07820881449657938, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.006894323974847794}, {"id": 27, "seek": 17896, "start": 185.44, "end": 191.92000000000002, "text": " you're going to take and you can predict the resulting state of the world, that means you", "tokens": [50688, 291, 434, 516, 281, 747, 293, 291, 393, 6069, 264, 16505, 1785, 295, 264, 1002, 11, 300, 1355, 291, 51012], "temperature": 0.0, "avg_logprob": -0.07820881449657938, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.006894323974847794}, {"id": 28, "seek": 17896, "start": 191.92000000000002, "end": 195.44, "text": " can predict what's going to happen as a consequence of a sequence of actions and that means you can", "tokens": [51012, 393, 6069, 437, 311, 516, 281, 1051, 382, 257, 18326, 295, 257, 8310, 295, 5909, 293, 300, 1355, 291, 393, 51188], "temperature": 0.0, "avg_logprob": -0.07820881449657938, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.006894323974847794}, {"id": 29, "seek": 17896, "start": 195.44, "end": 201.76000000000002, "text": " plan a sequence of actions to arrive at a particular goal. That's really what a world model is. At", "tokens": [51188, 1393, 257, 8310, 295, 5909, 281, 8881, 412, 257, 1729, 3387, 13, 663, 311, 534, 437, 257, 1002, 2316, 307, 13, 1711, 51504], "temperature": 0.0, "avg_logprob": -0.07820881449657938, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.006894323974847794}, {"id": 30, "seek": 20176, "start": 201.76, "end": 209.67999999999998, "text": " least that's what the Wave people have understood the word in other contexts, like in the context of", "tokens": [50364, 1935, 300, 311, 437, 264, 28530, 561, 362, 7320, 264, 1349, 294, 661, 30628, 11, 411, 294, 264, 4319, 295, 50760], "temperature": 0.0, "avg_logprob": -0.16962598717730978, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00021973754337523133}, {"id": 31, "seek": 20176, "start": 209.67999999999998, "end": 216.07999999999998, "text": " optimal control and robotics and things like that. That's what a world model is. Now, there's several", "tokens": [50760, 16252, 1969, 293, 34145, 293, 721, 411, 300, 13, 663, 311, 437, 257, 1002, 2316, 307, 13, 823, 11, 456, 311, 2940, 51080], "temperature": 0.0, "avg_logprob": -0.16962598717730978, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00021973754337523133}, {"id": 32, "seek": 20176, "start": 216.07999999999998, "end": 223.51999999999998, "text": " levels of complexity of those world models, whether they model yourself, the agent, or whether they", "tokens": [51080, 4358, 295, 14024, 295, 729, 1002, 5245, 11, 1968, 436, 2316, 1803, 11, 264, 9461, 11, 420, 1968, 436, 51452], "temperature": 0.0, "avg_logprob": -0.16962598717730978, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00021973754337523133}, {"id": 33, "seek": 22352, "start": 223.52, "end": 232.88, "text": " model the external world, which is much more complicated. Training a world model basically", "tokens": [50364, 2316, 264, 8320, 1002, 11, 597, 307, 709, 544, 6179, 13, 20620, 257, 1002, 2316, 1936, 50832], "temperature": 0.0, "avg_logprob": -0.10170314930103443, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.0007670203922316432}, {"id": 34, "seek": 22352, "start": 232.88, "end": 238.24, "text": " consists in just observing the world go by and then learning to predict what's going to happen next,", "tokens": [50832, 14689, 294, 445, 22107, 264, 1002, 352, 538, 293, 550, 2539, 281, 6069, 437, 311, 516, 281, 1051, 958, 11, 51100], "temperature": 0.0, "avg_logprob": -0.10170314930103443, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.0007670203922316432}, {"id": 35, "seek": 22352, "start": 238.96, "end": 245.12, "text": " or observing the world taking an action and then observing the resulting effect, an action that", "tokens": [51136, 420, 22107, 264, 1002, 1940, 364, 3069, 293, 550, 22107, 264, 16505, 1802, 11, 364, 3069, 300, 51444], "temperature": 0.0, "avg_logprob": -0.10170314930103443, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.0007670203922316432}, {"id": 36, "seek": 22352, "start": 245.12, "end": 251.92000000000002, "text": " you take as an agent or an action that you see other agents taking. That establishes", "tokens": [51444, 291, 747, 382, 364, 9461, 420, 364, 3069, 300, 291, 536, 661, 12554, 1940, 13, 663, 8327, 279, 51784], "temperature": 0.0, "avg_logprob": -0.10170314930103443, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.0007670203922316432}, {"id": 37, "seek": 25192, "start": 252.16, "end": 261.91999999999996, "text": " causality essentially. You could think of this as a causal model. Those models don't need to predict", "tokens": [50376, 3302, 1860, 4476, 13, 509, 727, 519, 295, 341, 382, 257, 38755, 2316, 13, 3950, 5245, 500, 380, 643, 281, 6069, 50864], "temperature": 0.0, "avg_logprob": -0.16954280234671928, "compression_ratio": 1.687150837988827, "no_speech_prob": 0.0007191406330093741}, {"id": 38, "seek": 25192, "start": 261.91999999999996, "end": 267.12, "text": " all the details about the world. They don't need to be generative. They don't need to predict exactly", "tokens": [50864, 439, 264, 4365, 466, 264, 1002, 13, 814, 500, 380, 643, 281, 312, 1337, 1166, 13, 814, 500, 380, 643, 281, 6069, 2293, 51124], "temperature": 0.0, "avg_logprob": -0.16954280234671928, "compression_ratio": 1.687150837988827, "no_speech_prob": 0.0007191406330093741}, {"id": 39, "seek": 25192, "start": 267.12, "end": 274.4, "text": " every pixel in a video, for example, because what you need to be able to predict is enough details,", "tokens": [51124, 633, 19261, 294, 257, 960, 11, 337, 1365, 11, 570, 437, 291, 643, 281, 312, 1075, 281, 6069, 307, 1547, 4365, 11, 51488], "temperature": 0.0, "avg_logprob": -0.16954280234671928, "compression_ratio": 1.687150837988827, "no_speech_prob": 0.0007191406330093741}, {"id": 40, "seek": 27440, "start": 275.28, "end": 287.2, "text": " some sort of abstract representation to allow you to plan. You're assembling something out of wood", "tokens": [50408, 512, 1333, 295, 12649, 10290, 281, 2089, 291, 281, 1393, 13, 509, 434, 43867, 746, 484, 295, 4576, 51004], "temperature": 0.0, "avg_logprob": -0.10381507873535156, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007007467094808817}, {"id": 41, "seek": 27440, "start": 287.2, "end": 294.32, "text": " and you're going to put two planks together and attach them with screws. It doesn't matter the", "tokens": [51004, 293, 291, 434, 516, 281, 829, 732, 499, 14592, 1214, 293, 5085, 552, 365, 13050, 13, 467, 1177, 380, 1871, 264, 51360], "temperature": 0.0, "avg_logprob": -0.10381507873535156, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007007467094808817}, {"id": 42, "seek": 27440, "start": 294.32, "end": 300.47999999999996, "text": " details of which type of screwdriver you're using or the size of the screw within some limits and", "tokens": [51360, 4365, 295, 597, 2010, 295, 27282, 291, 434, 1228, 420, 264, 2744, 295, 264, 5630, 1951, 512, 10406, 293, 51668], "temperature": 0.0, "avg_logprob": -0.10381507873535156, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007007467094808817}, {"id": 43, "seek": 30048, "start": 300.48, "end": 305.44, "text": " things like that. There are details that in the end don't matter as to what the end result", "tokens": [50364, 721, 411, 300, 13, 821, 366, 4365, 300, 294, 264, 917, 500, 380, 1871, 382, 281, 437, 264, 917, 1874, 50612], "temperature": 0.0, "avg_logprob": -0.12251079914181731, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0011507263407111168}, {"id": 44, "seek": 30048, "start": 305.44, "end": 312.40000000000003, "text": " will be or the precise grain of the wood and things of that type. You need to have some", "tokens": [50612, 486, 312, 420, 264, 13600, 12837, 295, 264, 4576, 293, 721, 295, 300, 2010, 13, 509, 643, 281, 362, 512, 50960], "temperature": 0.0, "avg_logprob": -0.12251079914181731, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0011507263407111168}, {"id": 45, "seek": 30048, "start": 312.40000000000003, "end": 316.8, "text": " abstract level of representation within which you can make the prediction without having to", "tokens": [50960, 12649, 1496, 295, 10290, 1951, 597, 291, 393, 652, 264, 17630, 1553, 1419, 281, 51180], "temperature": 0.0, "avg_logprob": -0.12251079914181731, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0011507263407111168}, {"id": 46, "seek": 30048, "start": 316.8, "end": 324.8, "text": " predict every detail. That's why those JPA architectures I've been advocating are useful. Models like", "tokens": [51180, 6069, 633, 2607, 13, 663, 311, 983, 729, 508, 10297, 6331, 1303, 286, 600, 668, 32050, 366, 4420, 13, 6583, 1625, 411, 51580], "temperature": 0.0, "avg_logprob": -0.12251079914181731, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0011507263407111168}, {"id": 47, "seek": 32480, "start": 325.76, "end": 331.84000000000003, "text": " the Gaia 1 model from Wave actually makes prediction in an abstract representation space.", "tokens": [50412, 264, 10384, 654, 502, 2316, 490, 28530, 767, 1669, 17630, 294, 364, 12649, 10290, 1901, 13, 50716], "temperature": 0.0, "avg_logprob": -0.17804012658461085, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.0014998923288658261}, {"id": 48, "seek": 32480, "start": 331.84000000000003, "end": 337.28000000000003, "text": " There's been a lot of work in that area for years also at FAIR, but generally the", "tokens": [50716, 821, 311, 668, 257, 688, 295, 589, 294, 300, 1859, 337, 924, 611, 412, 19894, 7740, 11, 457, 5101, 264, 50988], "temperature": 0.0, "avg_logprob": -0.17804012658461085, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.0014998923288658261}, {"id": 49, "seek": 32480, "start": 337.92, "end": 343.2, "text": " abstract representation were pre-trained. The encoders that would take images from videos and", "tokens": [51020, 12649, 10290, 645, 659, 12, 17227, 2001, 13, 440, 2058, 378, 433, 300, 576, 747, 5267, 490, 2145, 293, 51284], "temperature": 0.0, "avg_logprob": -0.17804012658461085, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.0014998923288658261}, {"id": 50, "seek": 32480, "start": 343.2, "end": 348.0, "text": " then encode them into some representation were trained in some other way. The progress we've", "tokens": [51284, 550, 2058, 1429, 552, 666, 512, 10290, 645, 8895, 294, 512, 661, 636, 13, 440, 4205, 321, 600, 51524], "temperature": 0.0, "avg_logprob": -0.17804012658461085, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.0014998923288658261}, {"id": 51, "seek": 32480, "start": 348.0, "end": 353.84000000000003, "text": " made over the last six months in self-improvised learning for images and video is that now we", "tokens": [51524, 1027, 670, 264, 1036, 2309, 2493, 294, 2698, 12, 332, 4318, 24420, 2539, 337, 5267, 293, 960, 307, 300, 586, 321, 51816], "temperature": 0.0, "avg_logprob": -0.17804012658461085, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.0014998923288658261}, {"id": 52, "seek": 35384, "start": 353.84, "end": 361.11999999999995, "text": " can train the entire system to make those predictions simultaneously. We have systems now that can", "tokens": [50364, 393, 3847, 264, 2302, 1185, 281, 652, 729, 21264, 16561, 13, 492, 362, 3652, 586, 300, 393, 50728], "temperature": 0.0, "avg_logprob": -0.11441128181688713, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.0004952476592734456}, {"id": 53, "seek": 35384, "start": 362.4, "end": 369.28, "text": " learn good representations of images and the basic idea is very simple. You take an image,", "tokens": [50792, 1466, 665, 33358, 295, 5267, 293, 264, 3875, 1558, 307, 588, 2199, 13, 509, 747, 364, 3256, 11, 51136], "temperature": 0.0, "avg_logprob": -0.11441128181688713, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.0004952476592734456}, {"id": 54, "seek": 35384, "start": 370.55999999999995, "end": 377.52, "text": " you run it through an encoder, then you corrupt that image, you mask parts of it, for example,", "tokens": [51200, 291, 1190, 309, 807, 364, 2058, 19866, 11, 550, 291, 17366, 300, 3256, 11, 291, 6094, 3166, 295, 309, 11, 337, 1365, 11, 51548], "temperature": 0.0, "avg_logprob": -0.11441128181688713, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.0004952476592734456}, {"id": 55, "seek": 37752, "start": 378.08, "end": 385.2, "text": " or you transform it in various ways, you blur it, you change the colors, you change the framing a", "tokens": [50392, 420, 291, 4088, 309, 294, 3683, 2098, 11, 291, 14257, 309, 11, 291, 1319, 264, 4577, 11, 291, 1319, 264, 28971, 257, 50748], "temperature": 0.0, "avg_logprob": -0.12967842728344361, "compression_ratio": 1.7100591715976332, "no_speech_prob": 0.0008289995021186769}, {"id": 56, "seek": 37752, "start": 385.2, "end": 390.0, "text": " little bit, and you run that corrupted image through the same encoder or something very similar.", "tokens": [50748, 707, 857, 11, 293, 291, 1190, 300, 39480, 3256, 807, 264, 912, 2058, 19866, 420, 746, 588, 2531, 13, 50988], "temperature": 0.0, "avg_logprob": -0.12967842728344361, "compression_ratio": 1.7100591715976332, "no_speech_prob": 0.0008289995021186769}, {"id": 57, "seek": 37752, "start": 391.59999999999997, "end": 397.12, "text": " And then you train the encoder to predict the features of the complete image from the features", "tokens": [51068, 400, 550, 291, 3847, 264, 2058, 19866, 281, 6069, 264, 4122, 295, 264, 3566, 3256, 490, 264, 4122, 51344], "temperature": 0.0, "avg_logprob": -0.12967842728344361, "compression_ratio": 1.7100591715976332, "no_speech_prob": 0.0008289995021186769}, {"id": 58, "seek": 39712, "start": 397.92, "end": 405.52, "text": " of the corrupted one. You're not trying to reconstruct the perfect image,", "tokens": [50404, 295, 264, 39480, 472, 13, 509, 434, 406, 1382, 281, 31499, 264, 2176, 3256, 11, 50784], "temperature": 0.0, "avg_logprob": -0.11959774192722364, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.0037054673302918673}, {"id": 59, "seek": 39712, "start": 406.4, "end": 411.52, "text": " you're just trying to predict the representation of it. And this is different,", "tokens": [50828, 291, 434, 445, 1382, 281, 6069, 264, 10290, 295, 309, 13, 400, 341, 307, 819, 11, 51084], "temperature": 0.0, "avg_logprob": -0.11959774192722364, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.0037054673302918673}, {"id": 60, "seek": 39712, "start": 411.52, "end": 416.8, "text": " this is not generative in the sense that it does not produce pixels. And that's the secret to getting", "tokens": [51084, 341, 307, 406, 1337, 1166, 294, 264, 2020, 300, 309, 775, 406, 5258, 18668, 13, 400, 300, 311, 264, 4054, 281, 1242, 51348], "temperature": 0.0, "avg_logprob": -0.11959774192722364, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.0037054673302918673}, {"id": 61, "seek": 39712, "start": 416.8, "end": 422.08, "text": " self-supervisual into work in the context of images and video. You don't want to be predicting pixels,", "tokens": [51348, 2698, 12, 48172, 4938, 901, 666, 589, 294, 264, 4319, 295, 5267, 293, 960, 13, 509, 500, 380, 528, 281, 312, 32884, 18668, 11, 51612], "temperature": 0.0, "avg_logprob": -0.11959774192722364, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.0037054673302918673}, {"id": 62, "seek": 42208, "start": 422.08, "end": 427.03999999999996, "text": " it doesn't work. You can't predict pixels as an afterthought, which is what the Gaia system is", "tokens": [50364, 309, 1177, 380, 589, 13, 509, 393, 380, 6069, 18668, 382, 364, 934, 43135, 11, 597, 307, 437, 264, 10384, 654, 1185, 307, 50612], "temperature": 0.0, "avg_logprob": -0.08464302840056243, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0019546400289982557}, {"id": 63, "seek": 42208, "start": 427.03999999999996, "end": 432.08, "text": " doing by sticking a decoder on it and with some diffusion model that will produce a nice image,", "tokens": [50612, 884, 538, 13465, 257, 979, 19866, 322, 309, 293, 365, 512, 25242, 2316, 300, 486, 5258, 257, 1481, 3256, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08464302840056243, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0019546400289982557}, {"id": 64, "seek": 42208, "start": 432.08, "end": 437.28, "text": " but that's kind of a second step. If you train the system by predicting pixels,", "tokens": [50864, 457, 300, 311, 733, 295, 257, 1150, 1823, 13, 759, 291, 3847, 264, 1185, 538, 32884, 18668, 11, 51124], "temperature": 0.0, "avg_logprob": -0.08464302840056243, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0019546400289982557}, {"id": 65, "seek": 42208, "start": 438.0, "end": 442.0, "text": " you just don't get good representations, you don't get good predictions, you get blurry", "tokens": [51160, 291, 445, 500, 380, 483, 665, 33358, 11, 291, 500, 380, 483, 665, 21264, 11, 291, 483, 37644, 51360], "temperature": 0.0, "avg_logprob": -0.08464302840056243, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0019546400289982557}, {"id": 66, "seek": 42208, "start": 442.0, "end": 448.47999999999996, "text": " predictions most of the time. So that's what makes learning from images and video fundamentally", "tokens": [51360, 21264, 881, 295, 264, 565, 13, 407, 300, 311, 437, 1669, 2539, 490, 5267, 293, 960, 17879, 51684], "temperature": 0.0, "avg_logprob": -0.08464302840056243, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0019546400289982557}, {"id": 67, "seek": 44848, "start": 448.48, "end": 454.40000000000003, "text": " different from learning from text because in text you don't have that problem. It's easy to predict", "tokens": [50364, 819, 490, 2539, 490, 2487, 570, 294, 2487, 291, 500, 380, 362, 300, 1154, 13, 467, 311, 1858, 281, 6069, 50660], "temperature": 0.0, "avg_logprob": -0.1299597373375526, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.00552756804972887}, {"id": 68, "seek": 44848, "start": 454.40000000000003, "end": 461.04, "text": " words, even if you cannot do a perfect prediction because language is discrete. So language is", "tokens": [50660, 2283, 11, 754, 498, 291, 2644, 360, 257, 2176, 17630, 570, 2856, 307, 27706, 13, 407, 2856, 307, 50992], "temperature": 0.0, "avg_logprob": -0.1299597373375526, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.00552756804972887}, {"id": 69, "seek": 44848, "start": 461.04, "end": 472.64000000000004, "text": " simple compared to the real world. And there's a lot written right now about the energy required", "tokens": [50992, 2199, 5347, 281, 264, 957, 1002, 13, 400, 456, 311, 257, 688, 3720, 558, 586, 466, 264, 2281, 4739, 51572], "temperature": 0.0, "avg_logprob": -0.1299597373375526, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.00552756804972887}, {"id": 70, "seek": 47264, "start": 472.71999999999997, "end": 480.96, "text": " in the computational resources GPUs required to train language models. Is it less", "tokens": [50368, 294, 264, 28270, 3593, 18407, 82, 4739, 281, 3847, 2856, 5245, 13, 1119, 309, 1570, 50780], "temperature": 0.0, "avg_logprob": -0.11664772033691406, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.009543593041598797}, {"id": 71, "seek": 47264, "start": 482.08, "end": 488.47999999999996, "text": " in training a world model like using iJAPA architecture? Well, it's hard to tell because", "tokens": [50836, 294, 3097, 257, 1002, 2316, 411, 1228, 741, 41, 4715, 32, 9482, 30, 1042, 11, 309, 311, 1152, 281, 980, 570, 51156], "temperature": 0.0, "avg_logprob": -0.11664772033691406, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.009543593041598797}, {"id": 72, "seek": 47264, "start": 488.47999999999996, "end": 495.76, "text": " there is no equivalent training procedure, self-supervised training procedure for video,", "tokens": [51156, 456, 307, 572, 10344, 3097, 10747, 11, 2698, 12, 48172, 24420, 3097, 10747, 337, 960, 11, 51520], "temperature": 0.0, "avg_logprob": -0.11664772033691406, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.009543593041598797}, {"id": 73, "seek": 47264, "start": 495.76, "end": 501.76, "text": " for example, that does not use JAPA. The ones that are generative don't really work.", "tokens": [51520, 337, 1365, 11, 300, 775, 406, 764, 508, 4715, 32, 13, 440, 2306, 300, 366, 1337, 1166, 500, 380, 534, 589, 13, 51820], "temperature": 0.0, "avg_logprob": -0.11664772033691406, "compression_ratio": 1.528888888888889, "no_speech_prob": 0.009543593041598797}, {"id": 74, "seek": 50264, "start": 502.88, "end": 509.84, "text": " Yeah. Well, but this architecture could also be applied to language, couldn't it?", "tokens": [50376, 865, 13, 1042, 11, 457, 341, 9482, 727, 611, 312, 6456, 281, 2856, 11, 2809, 380, 309, 30, 50724], "temperature": 0.0, "avg_logprob": -0.1727562804720295, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019553559832274914}, {"id": 75, "seek": 50264, "start": 510.71999999999997, "end": 517.52, "text": " Oh yeah, absolutely. Yeah, so you could very well use a JAPA architecture that makes prediction", "tokens": [50768, 876, 1338, 11, 3122, 13, 865, 11, 370, 291, 727, 588, 731, 764, 257, 508, 4715, 32, 9482, 300, 1669, 17630, 51108], "temperature": 0.0, "avg_logprob": -0.1727562804720295, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019553559832274914}, {"id": 76, "seek": 50264, "start": 517.52, "end": 524.4, "text": " in representation space and apply to language. Yeah, definitely. And in that case, would it be", "tokens": [51108, 294, 10290, 1901, 293, 3079, 281, 2856, 13, 865, 11, 2138, 13, 400, 294, 300, 1389, 11, 576, 309, 312, 51452], "temperature": 0.0, "avg_logprob": -0.1727562804720295, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0019553559832274914}, {"id": 77, "seek": 52440, "start": 524.48, "end": 532.0, "text": " less computationally intense than training a large language model?", "tokens": [50368, 1570, 24903, 379, 9447, 813, 3097, 257, 2416, 2856, 2316, 30, 50744], "temperature": 0.0, "avg_logprob": -0.09413079083976099, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0028000178281217813}, {"id": 78, "seek": 52440, "start": 532.0, "end": 539.76, "text": " It's possible. It's not entirely clear either. I mean, there is some advantage regardless of what", "tokens": [50744, 467, 311, 1944, 13, 467, 311, 406, 7696, 1850, 2139, 13, 286, 914, 11, 456, 307, 512, 5002, 10060, 295, 437, 51132], "temperature": 0.0, "avg_logprob": -0.09413079083976099, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0028000178281217813}, {"id": 79, "seek": 52440, "start": 539.76, "end": 545.4399999999999, "text": " technique you're using to making those models really big. They just seem to work better if you", "tokens": [51132, 6532, 291, 434, 1228, 281, 1455, 729, 5245, 534, 955, 13, 814, 445, 1643, 281, 589, 1101, 498, 291, 51416], "temperature": 0.0, "avg_logprob": -0.09413079083976099, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0028000178281217813}, {"id": 80, "seek": 54544, "start": 545.44, "end": 554.48, "text": " make them big. So if you make them bigger. So scaling is useful. Contrary to some claims,", "tokens": [50364, 652, 552, 955, 13, 407, 498, 291, 652, 552, 3801, 13, 407, 21589, 307, 4420, 13, 4839, 81, 822, 281, 512, 9441, 11, 50816], "temperature": 0.0, "avg_logprob": -0.11897352579477671, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.006484581623226404}, {"id": 81, "seek": 54544, "start": 554.48, "end": 559.6800000000001, "text": " I do not believe that scaling is sufficient. So in other words, we're not going to get anywhere", "tokens": [50816, 286, 360, 406, 1697, 300, 21589, 307, 11563, 13, 407, 294, 661, 2283, 11, 321, 434, 406, 516, 281, 483, 4992, 51076], "temperature": 0.0, "avg_logprob": -0.11897352579477671, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.006484581623226404}, {"id": 82, "seek": 54544, "start": 559.6800000000001, "end": 570.32, "text": " close to human level AI. In fact, not even any more level AI by simply scaling up language models.", "tokens": [51076, 1998, 281, 1952, 1496, 7318, 13, 682, 1186, 11, 406, 754, 604, 544, 1496, 7318, 538, 2935, 21589, 493, 2856, 5245, 13, 51608], "temperature": 0.0, "avg_logprob": -0.11897352579477671, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.006484581623226404}, {"id": 83, "seek": 57032, "start": 571.12, "end": 576.32, "text": " Even multimodal language models that we applied to video, we're going to have to find new concepts,", "tokens": [50404, 2754, 32972, 378, 304, 2856, 5245, 300, 321, 6456, 281, 960, 11, 321, 434, 516, 281, 362, 281, 915, 777, 10392, 11, 50664], "temperature": 0.0, "avg_logprob": -0.15784339343800263, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0020184048917144537}, {"id": 84, "seek": 57032, "start": 576.32, "end": 584.0, "text": " new architectures. And I've written a vision paper about this a while back of a different", "tokens": [50664, 777, 6331, 1303, 13, 400, 286, 600, 3720, 257, 5201, 3035, 466, 341, 257, 1339, 646, 295, 257, 819, 51048], "temperature": 0.0, "avg_logprob": -0.15784339343800263, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0020184048917144537}, {"id": 85, "seek": 57032, "start": 584.0, "end": 590.72, "text": " type of architecture that would be necessary for this. So scaling is necessary, but not sufficient.", "tokens": [51048, 2010, 295, 9482, 300, 576, 312, 4818, 337, 341, 13, 407, 21589, 307, 4818, 11, 457, 406, 11563, 13, 51384], "temperature": 0.0, "avg_logprob": -0.15784339343800263, "compression_ratio": 1.4896907216494846, "no_speech_prob": 0.0020184048917144537}, {"id": 86, "seek": 59072, "start": 591.6800000000001, "end": 601.12, "text": " And we're missing some basic ingredients to get to human level AI. We're fooled by the fact that", "tokens": [50412, 400, 321, 434, 5361, 512, 3875, 6952, 281, 483, 281, 1952, 1496, 7318, 13, 492, 434, 33372, 538, 264, 1186, 300, 50884], "temperature": 0.0, "avg_logprob": -0.11723458766937256, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.003169573377817869}, {"id": 87, "seek": 59072, "start": 601.12, "end": 606.4, "text": " LLMs are fluent. And so we think that they have human level intelligence because they can manipulate", "tokens": [50884, 441, 43, 26386, 366, 40799, 13, 400, 370, 321, 519, 300, 436, 362, 1952, 1496, 7599, 570, 436, 393, 20459, 51148], "temperature": 0.0, "avg_logprob": -0.11723458766937256, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.003169573377817869}, {"id": 88, "seek": 59072, "start": 606.4, "end": 616.32, "text": " language. But that's false. And in fact, there's a very good symptom for this, which is that", "tokens": [51148, 2856, 13, 583, 300, 311, 7908, 13, 400, 294, 1186, 11, 456, 311, 257, 588, 665, 29370, 337, 341, 11, 597, 307, 300, 51644], "temperature": 0.0, "avg_logprob": -0.11723458766937256, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.003169573377817869}, {"id": 89, "seek": 61632, "start": 617.2800000000001, "end": 624.96, "text": " we have systems that can pass the bar exam, but answering questions from text by basically", "tokens": [50412, 321, 362, 3652, 300, 393, 1320, 264, 2159, 1139, 11, 457, 13430, 1651, 490, 2487, 538, 1936, 50796], "temperature": 0.0, "avg_logprob": -0.1681893476799353, "compression_ratio": 1.4947368421052631, "no_speech_prob": 0.002277880208566785}, {"id": 90, "seek": 61632, "start": 624.96, "end": 632.88, "text": " regurgitating what they've learned, more or less by road. But we don't have completely autonomous", "tokens": [50796, 1121, 5476, 16350, 437, 436, 600, 3264, 11, 544, 420, 1570, 538, 3060, 13, 583, 321, 500, 380, 362, 2584, 23797, 51192], "temperature": 0.0, "avg_logprob": -0.1681893476799353, "compression_ratio": 1.4947368421052631, "no_speech_prob": 0.002277880208566785}, {"id": 91, "seek": 61632, "start": 632.88, "end": 639.36, "text": " level five cell driving cars, or at least no system that can learn to do this in about 20 hours", "tokens": [51192, 1496, 1732, 2815, 4840, 5163, 11, 420, 412, 1935, 572, 1185, 300, 393, 1466, 281, 360, 341, 294, 466, 945, 2496, 51516], "temperature": 0.0, "avg_logprob": -0.1681893476799353, "compression_ratio": 1.4947368421052631, "no_speech_prob": 0.002277880208566785}, {"id": 92, "seek": 63936, "start": 639.52, "end": 646.4, "text": " of practice, just like any 17-year-old. And we certainly don't have any domestic robot that can", "tokens": [50372, 295, 3124, 11, 445, 411, 604, 3282, 12, 5294, 12, 2641, 13, 400, 321, 3297, 500, 380, 362, 604, 10939, 7881, 300, 393, 50716], "temperature": 0.0, "avg_logprob": -0.12268429417763987, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.09052357077598572}, {"id": 93, "seek": 63936, "start": 647.44, "end": 651.2, "text": " clear up the dinner table and fill up the dishwasher attest that any 10-year-old can learn", "tokens": [50768, 1850, 493, 264, 6148, 3199, 293, 2836, 493, 264, 38009, 951, 377, 300, 604, 1266, 12, 5294, 12, 2641, 393, 1466, 50956], "temperature": 0.0, "avg_logprob": -0.12268429417763987, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.09052357077598572}, {"id": 94, "seek": 63936, "start": 651.2, "end": 658.8000000000001, "text": " in one shot. So clearly, we're missing something big. And that something is an ability to learn", "tokens": [50956, 294, 472, 3347, 13, 407, 4448, 11, 321, 434, 5361, 746, 955, 13, 400, 300, 746, 307, 364, 3485, 281, 1466, 51336], "temperature": 0.0, "avg_logprob": -0.12268429417763987, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.09052357077598572}, {"id": 95, "seek": 63936, "start": 658.8000000000001, "end": 663.36, "text": " how the world works and the world is much more complicated than language. And also being able", "tokens": [51336, 577, 264, 1002, 1985, 293, 264, 1002, 307, 709, 544, 6179, 813, 2856, 13, 400, 611, 885, 1075, 51564], "temperature": 0.0, "avg_logprob": -0.12268429417763987, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.09052357077598572}, {"id": 96, "seek": 66336, "start": 663.36, "end": 670.72, "text": " to plan and reason, basically having a mental world model that allows to plan and predict", "tokens": [50364, 281, 1393, 293, 1778, 11, 1936, 1419, 257, 4973, 1002, 2316, 300, 4045, 281, 1393, 293, 6069, 50732], "temperature": 0.0, "avg_logprob": -0.1799285371424788, "compression_ratio": 1.4364640883977902, "no_speech_prob": 0.011668792925775051}, {"id": 97, "seek": 66336, "start": 671.36, "end": 677.12, "text": " consequences of actions. That's what we're missing. It takes a while before we figure this out.", "tokens": [50764, 10098, 295, 5909, 13, 663, 311, 437, 321, 434, 5361, 13, 467, 2516, 257, 1339, 949, 321, 2573, 341, 484, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1799285371424788, "compression_ratio": 1.4364640883977902, "no_speech_prob": 0.011668792925775051}, {"id": 98, "seek": 66336, "start": 678.16, "end": 687.84, "text": " You were on another paper that talked about augmented language models. And", "tokens": [51104, 509, 645, 322, 1071, 3035, 300, 2825, 466, 36155, 2856, 5245, 13, 400, 51588], "temperature": 0.0, "avg_logprob": -0.1799285371424788, "compression_ratio": 1.4364640883977902, "no_speech_prob": 0.011668792925775051}, {"id": 99, "seek": 68784, "start": 687.84, "end": 693.6800000000001, "text": " in the embodied touring test, was that the same paper, the embodied touring test?", "tokens": [50364, 294, 264, 42046, 32487, 1500, 11, 390, 300, 264, 912, 3035, 11, 264, 42046, 32487, 1500, 30, 50656], "temperature": 0.0, "avg_logprob": -0.18884775531825734, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.004751485772430897}, {"id": 100, "seek": 68784, "start": 696.1600000000001, "end": 701.76, "text": " Can you talk about that? First of all, what is the embodied touring test? I didn't quite", "tokens": [50780, 1664, 291, 751, 466, 300, 30, 2386, 295, 439, 11, 437, 307, 264, 42046, 32487, 1500, 30, 286, 994, 380, 1596, 51060], "temperature": 0.0, "avg_logprob": -0.18884775531825734, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.004751485772430897}, {"id": 101, "seek": 68784, "start": 701.76, "end": 710.8000000000001, "text": " understand that. Well, okay, it's a different concept. But it's basically the idea that you", "tokens": [51060, 1223, 300, 13, 1042, 11, 1392, 11, 309, 311, 257, 819, 3410, 13, 583, 309, 311, 1936, 264, 1558, 300, 291, 51512], "temperature": 0.0, "avg_logprob": -0.18884775531825734, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.004751485772430897}, {"id": 102, "seek": 71080, "start": 711.76, "end": 721.28, "text": " do, it's based on the Moravec paradox, right? So Moravec many years ago noticed that things that", "tokens": [50412, 360, 11, 309, 311, 2361, 322, 264, 5146, 946, 66, 26221, 11, 558, 30, 407, 5146, 946, 66, 867, 924, 2057, 5694, 300, 721, 300, 50888], "temperature": 0.0, "avg_logprob": -0.1837521456600575, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.007917538285255432}, {"id": 103, "seek": 71080, "start": 721.28, "end": 727.3599999999999, "text": " appeared difficult for humans turned out to sometimes be very easy for computers to do,", "tokens": [50888, 8516, 2252, 337, 6255, 3574, 484, 281, 2171, 312, 588, 1858, 337, 10807, 281, 360, 11, 51192], "temperature": 0.0, "avg_logprob": -0.1837521456600575, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.007917538285255432}, {"id": 104, "seek": 71080, "start": 727.3599999999999, "end": 733.5999999999999, "text": " like playing chess, much better than humans. Or I don't know, computing integrals or whatever,", "tokens": [51192, 411, 2433, 24122, 11, 709, 1101, 813, 6255, 13, 1610, 286, 500, 380, 458, 11, 15866, 3572, 1124, 420, 2035, 11, 51504], "temperature": 0.0, "avg_logprob": -0.1837521456600575, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.007917538285255432}, {"id": 105, "seek": 71080, "start": 733.5999999999999, "end": 739.5999999999999, "text": " certainly doing arithmetic. But then there are things that we take for granted as humans that", "tokens": [51504, 3297, 884, 42973, 13, 583, 550, 456, 366, 721, 300, 321, 747, 337, 12344, 382, 6255, 300, 51804], "temperature": 0.0, "avg_logprob": -0.1837521456600575, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.007917538285255432}, {"id": 106, "seek": 73960, "start": 739.6, "end": 743.84, "text": " we don't even consider them intelligent tasks that we are incapable of reproducing with computers.", "tokens": [50364, 321, 500, 380, 754, 1949, 552, 13232, 9608, 300, 321, 366, 44174, 295, 11408, 2175, 365, 10807, 13, 50576], "temperature": 0.0, "avg_logprob": -0.08417742451032002, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.0005878221127204597}, {"id": 107, "seek": 73960, "start": 745.12, "end": 751.84, "text": " And so that's where the embodied touring test comes in. Observe what a cat can do or how fast a cat", "tokens": [50640, 400, 370, 300, 311, 689, 264, 42046, 32487, 1500, 1487, 294, 13, 20707, 3768, 437, 257, 3857, 393, 360, 420, 577, 2370, 257, 3857, 50976], "temperature": 0.0, "avg_logprob": -0.08417742451032002, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.0005878221127204597}, {"id": 108, "seek": 73960, "start": 751.84, "end": 761.36, "text": " can learn new tricks or how a cat can plan to jump on a bunch of different furniture to get to the", "tokens": [50976, 393, 1466, 777, 11733, 420, 577, 257, 3857, 393, 1393, 281, 3012, 322, 257, 3840, 295, 819, 15671, 281, 483, 281, 264, 51452], "temperature": 0.0, "avg_logprob": -0.08417742451032002, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.0005878221127204597}, {"id": 109, "seek": 73960, "start": 761.36, "end": 767.6800000000001, "text": " top of wherever it wants to go. That's an amazing feat that we can't reproduce with robots today.", "tokens": [51452, 1192, 295, 8660, 309, 2738, 281, 352, 13, 663, 311, 364, 2243, 15425, 300, 321, 393, 380, 29501, 365, 14733, 965, 13, 51768], "temperature": 0.0, "avg_logprob": -0.08417742451032002, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.0005878221127204597}, {"id": 110, "seek": 76768, "start": 768.64, "end": 776.3199999999999, "text": " So that's kind of the embodied touring test, if you want. Like, can you make a robot that", "tokens": [50412, 407, 300, 311, 733, 295, 264, 42046, 32487, 1500, 11, 498, 291, 528, 13, 1743, 11, 393, 291, 652, 257, 7881, 300, 50796], "temperature": 0.0, "avg_logprob": -0.1920722872018814, "compression_ratio": 1.48, "no_speech_prob": 0.000543880567420274}, {"id": 111, "seek": 76768, "start": 777.04, "end": 783.3599999999999, "text": " can behave, have behaviors that are easily wishable from those of animals, first of all,", "tokens": [50832, 393, 15158, 11, 362, 15501, 300, 366, 3612, 3172, 712, 490, 729, 295, 4882, 11, 700, 295, 439, 11, 51148], "temperature": 0.0, "avg_logprob": -0.1920722872018814, "compression_ratio": 1.48, "no_speech_prob": 0.000543880567420274}, {"id": 112, "seek": 76768, "start": 783.3599999999999, "end": 791.4399999999999, "text": " and can acquire new ones with the same efficiency as animals? Then the augmented", "tokens": [51148, 293, 393, 20001, 777, 2306, 365, 264, 912, 10493, 382, 4882, 30, 1396, 264, 36155, 51552], "temperature": 0.0, "avg_logprob": -0.1920722872018814, "compression_ratio": 1.48, "no_speech_prob": 0.000543880567420274}, {"id": 113, "seek": 79144, "start": 791.44, "end": 798.4000000000001, "text": " LLM paper is different. It's about how do you sort of minimally change large language models so", "tokens": [50364, 441, 43, 44, 3035, 307, 819, 13, 467, 311, 466, 577, 360, 291, 1333, 295, 4464, 379, 1319, 2416, 2856, 5245, 370, 50712], "temperature": 0.0, "avg_logprob": -0.14800625462685862, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.011857611127197742}, {"id": 114, "seek": 79144, "start": 798.4000000000001, "end": 804.8800000000001, "text": " that they can use tools so they can, to some extent, plan actions. Like, you know, you need to compute", "tokens": [50712, 300, 436, 393, 764, 3873, 370, 436, 393, 11, 281, 512, 8396, 11, 1393, 5909, 13, 1743, 11, 291, 458, 11, 291, 643, 281, 14722, 51036], "temperature": 0.0, "avg_logprob": -0.14800625462685862, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.011857611127197742}, {"id": 115, "seek": 79144, "start": 804.8800000000001, "end": 809.2800000000001, "text": " the product of two numbers, right? You just call a calculator and you know you're going to get the", "tokens": [51036, 264, 1674, 295, 732, 3547, 11, 558, 30, 509, 445, 818, 257, 24993, 293, 291, 458, 291, 434, 516, 281, 483, 264, 51256], "temperature": 0.0, "avg_logprob": -0.14800625462685862, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.011857611127197742}, {"id": 116, "seek": 79144, "start": 809.2800000000001, "end": 814.4000000000001, "text": " product of those two numbers. And LLMs are notoriously bad for arithmetic, so they need to do", "tokens": [51256, 1674, 295, 729, 732, 3547, 13, 400, 441, 43, 26386, 366, 46772, 8994, 1578, 337, 42973, 11, 370, 436, 643, 281, 360, 51512], "temperature": 0.0, "avg_logprob": -0.14800625462685862, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.011857611127197742}, {"id": 117, "seek": 79144, "start": 814.4000000000001, "end": 819.6800000000001, "text": " this kind of stuff or do a search, you know, using a search engine or database lookup or", "tokens": [51512, 341, 733, 295, 1507, 420, 360, 257, 3164, 11, 291, 458, 11, 1228, 257, 3164, 2848, 420, 8149, 574, 1010, 420, 51776], "temperature": 0.0, "avg_logprob": -0.14800625462685862, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.011857611127197742}, {"id": 118, "seek": 81968, "start": 819.68, "end": 824.2399999999999, "text": " something like that. So there's a lot of work on this right now and it's somewhat incremental. Like,", "tokens": [50364, 746, 411, 300, 13, 407, 456, 311, 257, 688, 295, 589, 322, 341, 558, 586, 293, 309, 311, 8344, 35759, 13, 1743, 11, 50592], "temperature": 0.0, "avg_logprob": -0.10882868226041499, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.0016738876001909375}, {"id": 119, "seek": 81968, "start": 824.2399999999999, "end": 829.8399999999999, "text": " you know, how can you sort of minimally change LLM and take advantage of their current capabilities", "tokens": [50592, 291, 458, 11, 577, 393, 291, 1333, 295, 4464, 379, 1319, 441, 43, 44, 293, 747, 5002, 295, 641, 2190, 10862, 50872], "temperature": 0.0, "avg_logprob": -0.10882868226041499, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.0016738876001909375}, {"id": 120, "seek": 81968, "start": 829.8399999999999, "end": 837.5999999999999, "text": " but still augment them with the ability to use tools? Yeah. And I don't want to get into the", "tokens": [50872, 457, 920, 29919, 552, 365, 264, 3485, 281, 764, 3873, 30, 865, 13, 400, 286, 500, 380, 528, 281, 483, 666, 264, 51260], "temperature": 0.0, "avg_logprob": -0.10882868226041499, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.0016738876001909375}, {"id": 121, "seek": 81968, "start": 838.2399999999999, "end": 844.16, "text": " too much into the threat debate. But, you know, you're on one side, your colleagues,", "tokens": [51292, 886, 709, 666, 264, 4734, 7958, 13, 583, 11, 291, 458, 11, 291, 434, 322, 472, 1252, 11, 428, 7734, 11, 51588], "temperature": 0.0, "avg_logprob": -0.10882868226041499, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.0016738876001909375}, {"id": 122, "seek": 84416, "start": 845.04, "end": 851.28, "text": " Jeff and Yashor on the other. I recently saw a picture of the three of you. I think you put that", "tokens": [50408, 7506, 293, 398, 1299, 284, 322, 264, 661, 13, 286, 3938, 1866, 257, 3036, 295, 264, 1045, 295, 291, 13, 286, 519, 291, 829, 300, 50720], "temperature": 0.0, "avg_logprob": -0.16600614519261603, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.013633018359541893}, {"id": 123, "seek": 84416, "start": 851.28, "end": 861.4399999999999, "text": " up on social media, saying how, you know, you can disagree but still be friends. This idea of", "tokens": [50720, 493, 322, 2093, 3021, 11, 1566, 577, 11, 291, 458, 11, 291, 393, 14091, 457, 920, 312, 1855, 13, 639, 1558, 295, 51228], "temperature": 0.0, "avg_logprob": -0.16600614519261603, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.013633018359541893}, {"id": 124, "seek": 84416, "start": 861.4399999999999, "end": 868.9599999999999, "text": " augmenting language models with stronger reasoning capabilities and the ability,", "tokens": [51228, 29919, 278, 2856, 5245, 365, 7249, 21577, 10862, 293, 264, 3485, 11, 51604], "temperature": 0.0, "avg_logprob": -0.16600614519261603, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.013633018359541893}, {"id": 125, "seek": 86896, "start": 868.96, "end": 876.72, "text": " and agency, the ability to use tools is precisely what Jeff and Yashor are worried about.", "tokens": [50364, 293, 7934, 11, 264, 3485, 281, 764, 3873, 307, 13402, 437, 7506, 293, 398, 1299, 284, 366, 5804, 466, 13, 50752], "temperature": 0.0, "avg_logprob": -0.13976514512214108, "compression_ratio": 1.5, "no_speech_prob": 0.003171969437971711}, {"id": 126, "seek": 86896, "start": 878.24, "end": 889.52, "text": " Can you just, why are you not worried about that? Okay. So first of all, what you're describing", "tokens": [50828, 1664, 291, 445, 11, 983, 366, 291, 406, 5804, 466, 300, 30, 1033, 13, 407, 700, 295, 439, 11, 437, 291, 434, 16141, 51392], "temperature": 0.0, "avg_logprob": -0.13976514512214108, "compression_ratio": 1.5, "no_speech_prob": 0.003171969437971711}, {"id": 127, "seek": 86896, "start": 889.52, "end": 898.24, "text": " is not necessarily what they are afraid of. They are alerting people and various governments and", "tokens": [51392, 307, 406, 4725, 437, 436, 366, 4638, 295, 13, 814, 366, 419, 27187, 561, 293, 3683, 11280, 293, 51828], "temperature": 0.0, "avg_logprob": -0.13976514512214108, "compression_ratio": 1.5, "no_speech_prob": 0.003171969437971711}, {"id": 128, "seek": 89824, "start": 898.24, "end": 904.88, "text": " others about various dangers that they perceive. Okay. So one danger, one set of dangers are", "tokens": [50364, 2357, 466, 3683, 27701, 300, 436, 20281, 13, 1033, 13, 407, 472, 4330, 11, 472, 992, 295, 27701, 366, 50696], "temperature": 0.0, "avg_logprob": -0.10737530778094036, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.0011872353497892618}, {"id": 129, "seek": 89824, "start": 905.44, "end": 910.48, "text": " relatively short-term. There are things like, you know, bad people will use technology for bad", "tokens": [50724, 7226, 2099, 12, 7039, 13, 821, 366, 721, 411, 11, 291, 458, 11, 1578, 561, 486, 764, 2899, 337, 1578, 50976], "temperature": 0.0, "avg_logprob": -0.10737530778094036, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.0011872353497892618}, {"id": 130, "seek": 89824, "start": 910.48, "end": 916.88, "text": " things. What can bad people use powerful AI systems for? And one concern that, you know,", "tokens": [50976, 721, 13, 708, 393, 1578, 561, 764, 4005, 7318, 3652, 337, 30, 400, 472, 3136, 300, 11, 291, 458, 11, 51296], "temperature": 0.0, "avg_logprob": -0.10737530778094036, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.0011872353497892618}, {"id": 131, "seek": 89824, "start": 916.88, "end": 924.64, "text": " governments have been worried about and intelligence agencies encounter intelligence and stuff like", "tokens": [51296, 11280, 362, 668, 5804, 466, 293, 7599, 9504, 8593, 7599, 293, 1507, 411, 51684], "temperature": 0.0, "avg_logprob": -0.10737530778094036, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.0011872353497892618}, {"id": 132, "seek": 92464, "start": 924.64, "end": 932.72, "text": " that is, you know, could value-intentioned organizations or countries use LLM to help them,", "tokens": [50364, 300, 307, 11, 291, 458, 11, 727, 2158, 12, 686, 1251, 292, 6150, 420, 3517, 764, 441, 43, 44, 281, 854, 552, 11, 50768], "temperature": 0.0, "avg_logprob": -0.1346299648284912, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.004750450607389212}, {"id": 133, "seek": 92464, "start": 932.72, "end": 939.84, "text": " I don't know, design pathogens or chemical weapons or other things or cyber attacks,", "tokens": [50768, 286, 500, 380, 458, 11, 1715, 44760, 420, 7313, 7278, 420, 661, 721, 420, 13411, 8122, 11, 51124], "temperature": 0.0, "avg_logprob": -0.1346299648284912, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.004750450607389212}, {"id": 134, "seek": 92464, "start": 939.84, "end": 943.84, "text": " you know, things like that, right? Now, those problems are not new. Those problems have been", "tokens": [51124, 291, 458, 11, 721, 411, 300, 11, 558, 30, 823, 11, 729, 2740, 366, 406, 777, 13, 3950, 2740, 362, 668, 51324], "temperature": 0.0, "avg_logprob": -0.1346299648284912, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.004750450607389212}, {"id": 135, "seek": 92464, "start": 943.84, "end": 951.2, "text": " with us for a long time. And the question is, what incremental help would AI systems bring to the", "tokens": [51324, 365, 505, 337, 257, 938, 565, 13, 400, 264, 1168, 307, 11, 437, 35759, 854, 576, 7318, 3652, 1565, 281, 264, 51692], "temperature": 0.0, "avg_logprob": -0.1346299648284912, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.004750450607389212}, {"id": 136, "seek": 95120, "start": 951.2, "end": 960.1600000000001, "text": " table? So my opinion is that as of today, AI systems are not sophisticated enough to provide", "tokens": [50364, 3199, 30, 407, 452, 4800, 307, 300, 382, 295, 965, 11, 7318, 3652, 366, 406, 16950, 1547, 281, 2893, 50812], "temperature": 0.0, "avg_logprob": -0.09385440435754247, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0009847101755440235}, {"id": 137, "seek": 95120, "start": 960.1600000000001, "end": 967.2, "text": " any significant help for such value-intentioned people because those systems are trained with", "tokens": [50812, 604, 4776, 854, 337, 1270, 2158, 12, 686, 1251, 292, 561, 570, 729, 3652, 366, 8895, 365, 51164], "temperature": 0.0, "avg_logprob": -0.09385440435754247, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0009847101755440235}, {"id": 138, "seek": 95120, "start": 967.2, "end": 971.5200000000001, "text": " public data that is publicly available on the internet. And they can't really invent anything.", "tokens": [51164, 1908, 1412, 300, 307, 14843, 2435, 322, 264, 4705, 13, 400, 436, 393, 380, 534, 7962, 1340, 13, 51380], "temperature": 0.0, "avg_logprob": -0.09385440435754247, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0009847101755440235}, {"id": 139, "seek": 95120, "start": 971.5200000000001, "end": 976.32, "text": " They're going to regurgitate with a little bit of interpolation if you want. But", "tokens": [51380, 814, 434, 516, 281, 1121, 5476, 8086, 365, 257, 707, 857, 295, 44902, 399, 498, 291, 528, 13, 583, 51620], "temperature": 0.0, "avg_logprob": -0.09385440435754247, "compression_ratio": 1.547008547008547, "no_speech_prob": 0.0009847101755440235}, {"id": 140, "seek": 97632, "start": 977.12, "end": 984.8000000000001, "text": " they cannot produce anything that you can't get from a search engine in a few minutes.", "tokens": [50404, 436, 2644, 5258, 1340, 300, 291, 393, 380, 483, 490, 257, 3164, 2848, 294, 257, 1326, 2077, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13475025267828078, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0005972928483970463}, {"id": 141, "seek": 97632, "start": 986.1600000000001, "end": 990.0, "text": " So that claim is being tested at the moment. There are people who are actually kind of", "tokens": [50856, 407, 300, 3932, 307, 885, 8246, 412, 264, 1623, 13, 821, 366, 561, 567, 366, 767, 733, 295, 51048], "temperature": 0.0, "avg_logprob": -0.13475025267828078, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0005972928483970463}, {"id": 142, "seek": 97632, "start": 990.5600000000001, "end": 995.2800000000001, "text": " trying to figure out, like, is it the case that you can actually do something, you're", "tokens": [51076, 1382, 281, 2573, 484, 11, 411, 11, 307, 309, 264, 1389, 300, 291, 393, 767, 360, 746, 11, 291, 434, 51312], "temperature": 0.0, "avg_logprob": -0.13475025267828078, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0005972928483970463}, {"id": 143, "seek": 97632, "start": 995.2800000000001, "end": 999.84, "text": " unable to do something more dangerous with sort of current AI technology that you can do with a", "tokens": [51312, 11299, 281, 360, 746, 544, 5795, 365, 1333, 295, 2190, 7318, 2899, 300, 291, 393, 360, 365, 257, 51540], "temperature": 0.0, "avg_logprob": -0.13475025267828078, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.0005972928483970463}, {"id": 144, "seek": 99984, "start": 999.84, "end": 1007.76, "text": " search engine results are not out yet. But my hunch is that, you know, it's not going to enable", "tokens": [50364, 3164, 2848, 3542, 366, 406, 484, 1939, 13, 583, 452, 47630, 307, 300, 11, 291, 458, 11, 309, 311, 406, 516, 281, 9528, 50760], "temperature": 0.0, "avg_logprob": -0.10045830408732097, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0019255364313721657}, {"id": 145, "seek": 99984, "start": 1007.76, "end": 1014.1600000000001, "text": " a lot of people to do significantly bad things. Then there is the issue of things like code", "tokens": [50760, 257, 688, 295, 561, 281, 360, 10591, 1578, 721, 13, 1396, 456, 307, 264, 2734, 295, 721, 411, 3089, 51080], "temperature": 0.0, "avg_logprob": -0.10045830408732097, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0019255364313721657}, {"id": 146, "seek": 99984, "start": 1014.1600000000001, "end": 1018.8000000000001, "text": " generation for cyber attacks and things like this. And those problems have been with us for years.", "tokens": [51080, 5125, 337, 13411, 8122, 293, 721, 411, 341, 13, 400, 729, 2740, 362, 668, 365, 505, 337, 924, 13, 51312], "temperature": 0.0, "avg_logprob": -0.10045830408732097, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0019255364313721657}, {"id": 147, "seek": 99984, "start": 1019.76, "end": 1024.08, "text": " And the interesting thing that most people should know, like, you know, also for like", "tokens": [51360, 400, 264, 1880, 551, 300, 881, 561, 820, 458, 11, 411, 11, 291, 458, 11, 611, 337, 411, 51576], "temperature": 0.0, "avg_logprob": -0.10045830408732097, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0019255364313721657}, {"id": 148, "seek": 99984, "start": 1024.08, "end": 1028.88, "text": " disinformation or attempts to corrupt the electoral process and things like this. And what's", "tokens": [51576, 717, 20941, 420, 15257, 281, 17366, 264, 28633, 1399, 293, 721, 411, 341, 13, 400, 437, 311, 51816], "temperature": 0.0, "avg_logprob": -0.10045830408732097, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0019255364313721657}, {"id": 149, "seek": 102888, "start": 1029.6000000000001, "end": 1034.48, "text": " very important for everyone to know is that the best countermeasures that we have", "tokens": [50400, 588, 1021, 337, 1518, 281, 458, 307, 300, 264, 1151, 5682, 1398, 20044, 300, 321, 362, 50644], "temperature": 0.0, "avg_logprob": -0.09116866371848366, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0004372239636722952}, {"id": 150, "seek": 102888, "start": 1034.48, "end": 1041.0400000000002, "text": " against all of those attacks currently use AI massively. Okay. So AI is used as a defense", "tokens": [50644, 1970, 439, 295, 729, 8122, 4362, 764, 7318, 29379, 13, 1033, 13, 407, 7318, 307, 1143, 382, 257, 7654, 50972], "temperature": 0.0, "avg_logprob": -0.09116866371848366, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0004372239636722952}, {"id": 151, "seek": 102888, "start": 1041.0400000000002, "end": 1049.2800000000002, "text": " mechanism against those attacks. It's not actually used to do the attacks yet. And so now it becomes", "tokens": [50972, 7513, 1970, 729, 8122, 13, 467, 311, 406, 767, 1143, 281, 360, 264, 8122, 1939, 13, 400, 370, 586, 309, 3643, 51384], "temperature": 0.0, "avg_logprob": -0.09116866371848366, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0004372239636722952}, {"id": 152, "seek": 102888, "start": 1049.2800000000002, "end": 1056.5600000000002, "text": " the question of, you know, who has the better system, like other countermeasures? Is the AI", "tokens": [51384, 264, 1168, 295, 11, 291, 458, 11, 567, 575, 264, 1101, 1185, 11, 411, 661, 5682, 1398, 20044, 30, 1119, 264, 7318, 51748], "temperature": 0.0, "avg_logprob": -0.09116866371848366, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0004372239636722952}, {"id": 153, "seek": 105656, "start": 1057.52, "end": 1063.84, "text": " countermeasures significantly better than the AI is used by the attackers so that, you know,", "tokens": [50412, 5682, 1398, 20044, 10591, 1101, 813, 264, 7318, 307, 1143, 538, 264, 45129, 370, 300, 11, 291, 458, 11, 50728], "temperature": 0.0, "avg_logprob": -0.11727386972178584, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002433112356811762}, {"id": 154, "seek": 105656, "start": 1063.84, "end": 1070.56, "text": " the problem is satisfactorily mitigated. And that's what we are. Now, the good news is that there are", "tokens": [50728, 264, 1154, 307, 5519, 15104, 953, 15699, 770, 13, 400, 300, 311, 437, 321, 366, 13, 823, 11, 264, 665, 2583, 307, 300, 456, 366, 51064], "temperature": 0.0, "avg_logprob": -0.11727386972178584, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002433112356811762}, {"id": 155, "seek": 105656, "start": 1070.56, "end": 1076.72, "text": " many more good guys and bad guys. They're usually much more competent. They're usually much more", "tokens": [51064, 867, 544, 665, 1074, 293, 1578, 1074, 13, 814, 434, 2673, 709, 544, 29998, 13, 814, 434, 2673, 709, 544, 51372], "temperature": 0.0, "avg_logprob": -0.11727386972178584, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002433112356811762}, {"id": 156, "seek": 105656, "start": 1076.72, "end": 1082.96, "text": " sophisticated. They're usually much more better funded. And they have a strong incentive to take", "tokens": [51372, 16950, 13, 814, 434, 2673, 709, 544, 1101, 14385, 13, 400, 436, 362, 257, 2068, 22346, 281, 747, 51684], "temperature": 0.0, "avg_logprob": -0.11727386972178584, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002433112356811762}, {"id": 157, "seek": 108296, "start": 1082.96, "end": 1091.68, "text": " down the attackers. So it's a game of cat and mouse, just like every security that's ever existed.", "tokens": [50364, 760, 264, 45129, 13, 407, 309, 311, 257, 1216, 295, 3857, 293, 9719, 11, 445, 411, 633, 3825, 300, 311, 1562, 13135, 13, 50800], "temperature": 0.0, "avg_logprob": -0.16570548488669198, "compression_ratio": 1.465, "no_speech_prob": 0.011663711629807949}, {"id": 158, "seek": 108296, "start": 1092.48, "end": 1100.08, "text": " There's nothing new there. Okay. Nothing quite entirely new. Yeah. But then there is the question", "tokens": [50840, 821, 311, 1825, 777, 456, 13, 1033, 13, 6693, 1596, 7696, 777, 13, 865, 13, 583, 550, 456, 307, 264, 1168, 51220], "temperature": 0.0, "avg_logprob": -0.16570548488669198, "compression_ratio": 1.465, "no_speech_prob": 0.011663711629807949}, {"id": 159, "seek": 108296, "start": 1100.08, "end": 1108.4, "text": " of existential risk, right? And this is something that both Jeff and Yosha have been thinking of", "tokens": [51220, 295, 37133, 3148, 11, 558, 30, 400, 341, 307, 746, 300, 1293, 7506, 293, 398, 329, 1641, 362, 668, 1953, 295, 51636], "temperature": 0.0, "avg_logprob": -0.16570548488669198, "compression_ratio": 1.465, "no_speech_prob": 0.011663711629807949}, {"id": 160, "seek": 110840, "start": 1109.2, "end": 1114.0, "text": " fairly recently. So for Jeff, it's only sort of just before last summer that he became,", "tokens": [50404, 6457, 3938, 13, 407, 337, 7506, 11, 309, 311, 787, 1333, 295, 445, 949, 1036, 4266, 300, 415, 3062, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1262915667365579, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.0017801878275349736}, {"id": 161, "seek": 110840, "start": 1115.2, "end": 1119.52, "text": " he started thinking about this because before he thought he was convinced that the kind of", "tokens": [50704, 415, 1409, 1953, 466, 341, 570, 949, 415, 1194, 415, 390, 12561, 300, 264, 733, 295, 50920], "temperature": 0.0, "avg_logprob": -0.1262915667365579, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.0017801878275349736}, {"id": 162, "seek": 110840, "start": 1119.52, "end": 1125.1200000000001, "text": " algorithms that we had were significantly inferior to the kind of learning algorithm that the brain", "tokens": [50920, 14642, 300, 321, 632, 645, 10591, 24249, 281, 264, 733, 295, 2539, 9284, 300, 264, 3567, 51200], "temperature": 0.0, "avg_logprob": -0.1262915667365579, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.0017801878275349736}, {"id": 163, "seek": 110840, "start": 1125.1200000000001, "end": 1132.4, "text": " used. And the epiphany he had was that, in fact, no, because looking at the capabilities of", "tokens": [51200, 1143, 13, 400, 264, 2388, 24595, 1325, 415, 632, 390, 300, 11, 294, 1186, 11, 572, 11, 570, 1237, 412, 264, 10862, 295, 51564], "temperature": 0.0, "avg_logprob": -0.1262915667365579, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.0017801878275349736}, {"id": 164, "seek": 113240, "start": 1133.2, "end": 1138.0800000000002, "text": " large English models, they can do pretty amazing things with a relatively small number of neurons", "tokens": [50404, 2416, 3669, 5245, 11, 436, 393, 360, 1238, 2243, 721, 365, 257, 7226, 1359, 1230, 295, 22027, 50648], "temperature": 0.0, "avg_logprob": -0.12384819757370721, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0008292372804135084}, {"id": 165, "seek": 113240, "start": 1138.0800000000002, "end": 1141.8400000000001, "text": " and synapses. He said, maybe they're more efficient than the brain. And maybe the learning algorithm", "tokens": [50648, 293, 5451, 2382, 279, 13, 634, 848, 11, 1310, 436, 434, 544, 7148, 813, 264, 3567, 13, 400, 1310, 264, 2539, 9284, 50836], "temperature": 0.0, "avg_logprob": -0.12384819757370721, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0008292372804135084}, {"id": 166, "seek": 113240, "start": 1141.8400000000001, "end": 1145.6000000000001, "text": " that we use, back propagation, is actually better than whatever it is that the brain uses.", "tokens": [50836, 300, 321, 764, 11, 646, 38377, 11, 307, 767, 1101, 813, 2035, 309, 307, 300, 264, 3567, 4960, 13, 51024], "temperature": 0.0, "avg_logprob": -0.12384819757370721, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0008292372804135084}, {"id": 167, "seek": 113240, "start": 1146.24, "end": 1149.2800000000002, "text": " So he started thinking about like, you know, what are the consequences? And", "tokens": [51056, 407, 415, 1409, 1953, 466, 411, 11, 291, 458, 11, 437, 366, 264, 10098, 30, 400, 51208], "temperature": 0.0, "avg_logprob": -0.12384819757370721, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0008292372804135084}, {"id": 168, "seek": 113240, "start": 1150.3200000000002, "end": 1153.68, "text": " but that's very recent. And in my opinion, he hasn't thought about this enough.", "tokens": [51260, 457, 300, 311, 588, 5162, 13, 400, 294, 452, 4800, 11, 415, 6132, 380, 1194, 466, 341, 1547, 13, 51428], "temperature": 0.0, "avg_logprob": -0.12384819757370721, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.0008292372804135084}, {"id": 169, "seek": 115368, "start": 1154.0, "end": 1163.28, "text": " Yosha went to a similar epiphany last winter, where he started thinking about the long-term", "tokens": [50380, 398, 329, 1641, 1437, 281, 257, 2531, 2388, 24595, 1325, 1036, 6355, 11, 689, 415, 1409, 1953, 466, 264, 938, 12, 7039, 50844], "temperature": 0.0, "avg_logprob": -0.14004364496544947, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.0006162602221593261}, {"id": 170, "seek": 115368, "start": 1163.28, "end": 1169.52, "text": " consequences. And came to the conclusion also that there was a potential danger.", "tokens": [50844, 10098, 13, 400, 1361, 281, 264, 10063, 611, 300, 456, 390, 257, 3995, 4330, 13, 51156], "temperature": 0.0, "avg_logprob": -0.14004364496544947, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.0006162602221593261}, {"id": 171, "seek": 115368, "start": 1170.88, "end": 1175.3600000000001, "text": " They're both convinced that AI has enormous potential benefits. They're just worried", "tokens": [51224, 814, 434, 1293, 12561, 300, 7318, 575, 11322, 3995, 5311, 13, 814, 434, 445, 5804, 51448], "temperature": 0.0, "avg_logprob": -0.14004364496544947, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.0006162602221593261}, {"id": 172, "seek": 115368, "start": 1176.5600000000002, "end": 1180.88, "text": " about the dangers. And they're both worried about the dangers because they have some doubts", "tokens": [51508, 466, 264, 27701, 13, 400, 436, 434, 1293, 5804, 466, 264, 27701, 570, 436, 362, 512, 22618, 51724], "temperature": 0.0, "avg_logprob": -0.14004364496544947, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.0006162602221593261}, {"id": 173, "seek": 118088, "start": 1181.68, "end": 1187.6000000000001, "text": " about the ability of our institutions to do the best with technology.", "tokens": [50404, 466, 264, 3485, 295, 527, 8142, 281, 360, 264, 1151, 365, 2899, 13, 50700], "temperature": 0.0, "avg_logprob": -0.14353037747469816, "compression_ratio": 1.6, "no_speech_prob": 0.0015951477689668536}, {"id": 174, "seek": 118088, "start": 1189.3600000000001, "end": 1196.64, "text": " You know, whether they are political, economic, geopolitical, financial institutions,", "tokens": [50788, 509, 458, 11, 1968, 436, 366, 3905, 11, 4836, 11, 46615, 804, 11, 4669, 8142, 11, 51152], "temperature": 0.0, "avg_logprob": -0.14353037747469816, "compression_ratio": 1.6, "no_speech_prob": 0.0015951477689668536}, {"id": 175, "seek": 118088, "start": 1196.64, "end": 1203.92, "text": " or industrial, to do the right thing, to be motivated by the right thing. So", "tokens": [51152, 420, 9987, 11, 281, 360, 264, 558, 551, 11, 281, 312, 14515, 538, 264, 558, 551, 13, 407, 51516], "temperature": 0.0, "avg_logprob": -0.14353037747469816, "compression_ratio": 1.6, "no_speech_prob": 0.0015951477689668536}, {"id": 176, "seek": 120392, "start": 1204.48, "end": 1212.88, "text": " you know, if you trust the system, if you trust humanity and democracy,", "tokens": [50392, 291, 458, 11, 498, 291, 3361, 264, 1185, 11, 498, 291, 3361, 10243, 293, 10528, 11, 50812], "temperature": 0.0, "avg_logprob": -0.16120668819972447, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.0005517818499356508}, {"id": 177, "seek": 120392, "start": 1214.96, "end": 1223.2, "text": " you might be entitled to believe that society is going to make the best use of", "tokens": [50916, 291, 1062, 312, 17838, 281, 1697, 300, 4086, 307, 516, 281, 652, 264, 1151, 764, 295, 51328], "temperature": 0.0, "avg_logprob": -0.16120668819972447, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.0005517818499356508}, {"id": 178, "seek": 120392, "start": 1223.2, "end": 1228.64, "text": " future technology. If you don't believe in the solidity of those institutions,", "tokens": [51328, 2027, 2899, 13, 759, 291, 500, 380, 1697, 294, 264, 5100, 507, 295, 729, 8142, 11, 51600], "temperature": 0.0, "avg_logprob": -0.16120668819972447, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.0005517818499356508}, {"id": 179, "seek": 122864, "start": 1228.64, "end": 1234.64, "text": " then you might be scared. Okay. I think I'm more confident in humanity and democracy than they are.", "tokens": [50364, 550, 291, 1062, 312, 5338, 13, 1033, 13, 286, 519, 286, 478, 544, 6679, 294, 10243, 293, 10528, 813, 436, 366, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15921126917788858, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.004601812455803156}, {"id": 180, "seek": 122864, "start": 1235.2800000000002, "end": 1239.0400000000002, "text": " And, and, you know, whatever current systems and they are, I've been thinking about this", "tokens": [50696, 400, 11, 293, 11, 291, 458, 11, 2035, 2190, 3652, 293, 436, 366, 11, 286, 600, 668, 1953, 466, 341, 50884], "temperature": 0.0, "avg_logprob": -0.15921126917788858, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.004601812455803156}, {"id": 181, "seek": 122864, "start": 1239.0400000000002, "end": 1247.44, "text": " problem for much longer, actually, since at least 2014. So when I started fair at Facebook at the", "tokens": [50884, 1154, 337, 709, 2854, 11, 767, 11, 1670, 412, 1935, 8227, 13, 407, 562, 286, 1409, 3143, 412, 4384, 412, 264, 51304], "temperature": 0.0, "avg_logprob": -0.15921126917788858, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.004601812455803156}, {"id": 182, "seek": 122864, "start": 1247.44, "end": 1253.1200000000001, "text": " time, it became pretty clear, pretty early on that, you know, deploying AI systems was going to have", "tokens": [51304, 565, 11, 309, 3062, 1238, 1850, 11, 1238, 2440, 322, 300, 11, 291, 458, 11, 34198, 7318, 3652, 390, 516, 281, 362, 51588], "temperature": 0.0, "avg_logprob": -0.15921126917788858, "compression_ratio": 1.5296442687747036, "no_speech_prob": 0.004601812455803156}, {"id": 183, "seek": 125312, "start": 1253.84, "end": 1259.84, "text": " big consequences on people in society. And we got confronted to this very early.", "tokens": [50400, 955, 10098, 322, 561, 294, 4086, 13, 400, 321, 658, 31257, 281, 341, 588, 2440, 13, 50700], "temperature": 0.0, "avg_logprob": -0.14753488215004526, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0023558272514492273}, {"id": 184, "seek": 125312, "start": 1260.56, "end": 1265.36, "text": " And so I started thinking about those problems very early on. Things like, you know, counter", "tokens": [50736, 400, 370, 286, 1409, 1953, 466, 729, 2740, 588, 2440, 322, 13, 9514, 411, 11, 291, 458, 11, 5682, 50976], "temperature": 0.0, "avg_logprob": -0.14753488215004526, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0023558272514492273}, {"id": 185, "seek": 125312, "start": 1265.36, "end": 1272.32, "text": " measures against like bias in AI systems, systematic bias, counter measures against attacks,", "tokens": [50976, 8000, 1970, 411, 12577, 294, 7318, 3652, 11, 27249, 12577, 11, 5682, 8000, 1970, 8122, 11, 51324], "temperature": 0.0, "avg_logprob": -0.14753488215004526, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0023558272514492273}, {"id": 186, "seek": 125312, "start": 1274.08, "end": 1278.56, "text": " or, you know, detection of hate speech in every language, things like that. These are things that", "tokens": [51412, 420, 11, 291, 458, 11, 17784, 295, 4700, 6218, 294, 633, 2856, 11, 721, 411, 300, 13, 1981, 366, 721, 300, 51636], "temperature": 0.0, "avg_logprob": -0.14753488215004526, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0023558272514492273}, {"id": 187, "seek": 127856, "start": 1278.56, "end": 1283.76, "text": " people at fair worked on and then were eventually deployed. To just to give you an example, the", "tokens": [50364, 561, 412, 3143, 2732, 322, 293, 550, 645, 4728, 17826, 13, 1407, 445, 281, 976, 291, 364, 1365, 11, 264, 50624], "temperature": 0.0, "avg_logprob": -0.14683065743281923, "compression_ratio": 1.52, "no_speech_prob": 0.0035843595396727324}, {"id": 188, "seek": 127856, "start": 1284.56, "end": 1289.12, "text": " proportion of hate speech that was taken down automatically by AI systems five years ago,", "tokens": [50664, 16068, 295, 4700, 6218, 300, 390, 2726, 760, 6772, 538, 7318, 3652, 1732, 924, 2057, 11, 50892], "temperature": 0.0, "avg_logprob": -0.14683065743281923, "compression_ratio": 1.52, "no_speech_prob": 0.0035843595396727324}, {"id": 189, "seek": 127856, "start": 1289.12, "end": 1297.9199999999998, "text": " you know, in 2017, was about 20 to 25%. Last year, it was 95%. And the difference is entirely due to", "tokens": [50892, 291, 458, 11, 294, 6591, 11, 390, 466, 945, 281, 3552, 6856, 5264, 1064, 11, 309, 390, 13420, 6856, 400, 264, 2649, 307, 7696, 3462, 281, 51332], "temperature": 0.0, "avg_logprob": -0.14683065743281923, "compression_ratio": 1.52, "no_speech_prob": 0.0035843595396727324}, {"id": 190, "seek": 127856, "start": 1297.9199999999998, "end": 1303.52, "text": " progress in natural language understanding, entirely grew to transformers that are pretrained", "tokens": [51332, 4205, 294, 3303, 2856, 3701, 11, 7696, 6109, 281, 4088, 433, 300, 366, 1162, 31774, 51612], "temperature": 0.0, "avg_logprob": -0.14683065743281923, "compression_ratio": 1.52, "no_speech_prob": 0.0035843595396727324}, {"id": 191, "seek": 130352, "start": 1303.6, "end": 1308.6399999999999, "text": " self-supervised and can essentially detect hate speech in any language. Not perfectly. Nothing", "tokens": [50368, 2698, 12, 48172, 24420, 293, 393, 4476, 5531, 4700, 6218, 294, 604, 2856, 13, 1726, 6239, 13, 6693, 50620], "temperature": 0.0, "avg_logprob": -0.13756845330679288, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.019689543172717094}, {"id": 192, "seek": 130352, "start": 1308.6399999999999, "end": 1314.56, "text": " is perfect. It's ever perfect. But AI is massively there. And that's the solution. So I started", "tokens": [50620, 307, 2176, 13, 467, 311, 1562, 2176, 13, 583, 7318, 307, 29379, 456, 13, 400, 300, 311, 264, 3827, 13, 407, 286, 1409, 50916], "temperature": 0.0, "avg_logprob": -0.13756845330679288, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.019689543172717094}, {"id": 193, "seek": 130352, "start": 1314.56, "end": 1322.0, "text": " thinking about those issues, including existential risk, very early on. In fact, in 2015, early 2016,", "tokens": [50916, 1953, 466, 729, 2663, 11, 3009, 37133, 3148, 11, 588, 2440, 322, 13, 682, 1186, 11, 294, 7546, 11, 2440, 6549, 11, 51288], "temperature": 0.0, "avg_logprob": -0.13756845330679288, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.019689543172717094}, {"id": 194, "seek": 130352, "start": 1322.0, "end": 1328.16, "text": " actually, I organized a conference hosted at NYU on the future of AI, where a lot of those", "tokens": [51288, 767, 11, 286, 9983, 257, 7586, 19204, 412, 42682, 322, 264, 2027, 295, 7318, 11, 689, 257, 688, 295, 729, 51596], "temperature": 0.0, "avg_logprob": -0.13756845330679288, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.019689543172717094}, {"id": 195, "seek": 132816, "start": 1328.16, "end": 1337.6000000000001, "text": " questions were discussed. I invited people like, you know, Eric Schmidt and Mark Schreffer, who", "tokens": [50364, 1651, 645, 7152, 13, 286, 9185, 561, 411, 11, 291, 458, 11, 9336, 42621, 293, 3934, 2065, 265, 38145, 11, 567, 50836], "temperature": 0.0, "avg_logprob": -0.23020086897180436, "compression_ratio": 1.5432098765432098, "no_speech_prob": 0.00666752178221941}, {"id": 196, "seek": 132816, "start": 1337.6000000000001, "end": 1346.0, "text": " was the CTO of Facebook at the time. A lot of people, both from the academic and AI research", "tokens": [50836, 390, 264, 383, 15427, 295, 4384, 412, 264, 565, 13, 316, 688, 295, 561, 11, 1293, 490, 264, 7778, 293, 7318, 2132, 51256], "temperature": 0.0, "avg_logprob": -0.23020086897180436, "compression_ratio": 1.5432098765432098, "no_speech_prob": 0.00666752178221941}, {"id": 197, "seek": 132816, "start": 1346.0, "end": 1350.88, "text": " side and from the industry side. And there were two days, a public day and kind of a more private", "tokens": [51256, 1252, 293, 490, 264, 3518, 1252, 13, 400, 456, 645, 732, 1708, 11, 257, 1908, 786, 293, 733, 295, 257, 544, 4551, 51500], "temperature": 0.0, "avg_logprob": -0.23020086897180436, "compression_ratio": 1.5432098765432098, "no_speech_prob": 0.00666752178221941}, {"id": 198, "seek": 132816, "start": 1350.88, "end": 1355.92, "text": " day. What came out of this is the creation of an institution called a partnership on AI.", "tokens": [51500, 786, 13, 708, 1361, 484, 295, 341, 307, 264, 8016, 295, 364, 7818, 1219, 257, 9982, 322, 7318, 13, 51752], "temperature": 0.0, "avg_logprob": -0.23020086897180436, "compression_ratio": 1.5432098765432098, "no_speech_prob": 0.00666752178221941}, {"id": 199, "seek": 135592, "start": 1355.92, "end": 1362.4, "text": " So this is a discussion I had with Mr. Sabis, which was, you know, would it be useful to have a", "tokens": [50364, 407, 341, 307, 257, 5017, 286, 632, 365, 2221, 13, 13915, 271, 11, 597, 390, 11, 291, 458, 11, 576, 309, 312, 4420, 281, 362, 257, 50688], "temperature": 0.0, "avg_logprob": -0.17110887486883936, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.0025831833481788635}, {"id": 200, "seek": 135592, "start": 1362.4, "end": 1367.8400000000001, "text": " forum where we can discuss before they happen, sort of bad things that could happen as a consequence", "tokens": [50688, 17542, 689, 321, 393, 2248, 949, 436, 1051, 11, 1333, 295, 1578, 721, 300, 727, 1051, 382, 257, 18326, 50960], "temperature": 0.0, "avg_logprob": -0.17110887486883936, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.0025831833481788635}, {"id": 201, "seek": 135592, "start": 1367.8400000000001, "end": 1375.8400000000001, "text": " of deploying AI? Pretty soon, we brought on board Eric Horvitz and a bunch of other people,", "tokens": [50960, 295, 34198, 7318, 30, 10693, 2321, 11, 321, 3038, 322, 3150, 9336, 10691, 85, 6862, 293, 257, 3840, 295, 661, 561, 11, 51360], "temperature": 0.0, "avg_logprob": -0.17110887486883936, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.0025831833481788635}, {"id": 202, "seek": 135592, "start": 1375.8400000000001, "end": 1379.2, "text": " and we co-founded this thing called a partnership on AI, which basically has been", "tokens": [51360, 293, 321, 598, 12, 49547, 341, 551, 1219, 257, 9982, 322, 7318, 11, 597, 1936, 575, 668, 51528], "temperature": 0.0, "avg_logprob": -0.17110887486883936, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.0025831833481788635}, {"id": 203, "seek": 137920, "start": 1380.16, "end": 1389.52, "text": " funding studies about AI ethics and consequences of AI and publishing guidelines about, you know,", "tokens": [50412, 6137, 5313, 466, 7318, 19769, 293, 10098, 295, 7318, 293, 17832, 12470, 466, 11, 291, 458, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1659034522804054, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.025149909779429436}, {"id": 204, "seek": 137920, "start": 1389.52, "end": 1394.4, "text": " how you do it right to me and my time. So this is not a new thing for me. Like, I've been thinking", "tokens": [50880, 577, 291, 360, 309, 558, 281, 385, 293, 452, 565, 13, 407, 341, 307, 406, 257, 777, 551, 337, 385, 13, 1743, 11, 286, 600, 668, 1953, 51124], "temperature": 0.0, "avg_logprob": -0.1659034522804054, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.025149909779429436}, {"id": 205, "seek": 137920, "start": 1394.4, "end": 1399.3600000000001, "text": " about this for 10 years, essentially. Whereas for Yosha and Jeff, it's much more recent.", "tokens": [51124, 466, 341, 337, 1266, 924, 11, 4476, 13, 13813, 337, 398, 329, 1641, 293, 7506, 11, 309, 311, 709, 544, 5162, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1659034522804054, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.025149909779429436}, {"id": 206, "seek": 139936, "start": 1400.1599999999999, "end": 1409.36, "text": " Yeah. But nonetheless, this augmented AI or augmented language models that have stronger", "tokens": [50404, 865, 13, 583, 26756, 11, 341, 36155, 7318, 420, 36155, 2856, 5245, 300, 362, 7249, 50864], "temperature": 0.0, "avg_logprob": -0.14163392489073706, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.048088811337947845}, {"id": 207, "seek": 139936, "start": 1409.36, "end": 1419.1999999999998, "text": " reasoning and agency raises the threat, regardless of whether or not it can be countered", "tokens": [50864, 21577, 293, 7934, 19658, 264, 4734, 11, 10060, 295, 1968, 420, 406, 309, 393, 312, 5682, 292, 51356], "temperature": 0.0, "avg_logprob": -0.14163392489073706, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.048088811337947845}, {"id": 208, "seek": 139936, "start": 1419.9199999999998, "end": 1427.6, "text": " to a higher level. Right. Okay. So I guess the question there becomes, what is the blueprint", "tokens": [51392, 281, 257, 2946, 1496, 13, 1779, 13, 1033, 13, 407, 286, 2041, 264, 1168, 456, 3643, 11, 437, 307, 264, 35868, 51776], "temperature": 0.0, "avg_logprob": -0.14163392489073706, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.048088811337947845}, {"id": 209, "seek": 142760, "start": 1428.24, "end": 1434.6399999999999, "text": " of future AI systems that will be capable of reasoning and planning, will understand how the", "tokens": [50396, 295, 2027, 7318, 3652, 300, 486, 312, 8189, 295, 21577, 293, 5038, 11, 486, 1223, 577, 264, 50716], "temperature": 0.0, "avg_logprob": -0.0983911887886598, "compression_ratio": 1.65625, "no_speech_prob": 0.002214709296822548}, {"id": 210, "seek": 142760, "start": 1434.6399999999999, "end": 1440.8, "text": " world works, will be able to, you know, use tools and have agency and things like that. Right.", "tokens": [50716, 1002, 1985, 11, 486, 312, 1075, 281, 11, 291, 458, 11, 764, 3873, 293, 362, 7934, 293, 721, 411, 300, 13, 1779, 13, 51024], "temperature": 0.0, "avg_logprob": -0.0983911887886598, "compression_ratio": 1.65625, "no_speech_prob": 0.002214709296822548}, {"id": 211, "seek": 142760, "start": 1442.32, "end": 1449.04, "text": " And I tell you, they will not be autoregressive LLMs. So the problems that we see at the moment", "tokens": [51100, 400, 286, 980, 291, 11, 436, 486, 406, 312, 1476, 418, 3091, 488, 441, 43, 26386, 13, 407, 264, 2740, 300, 321, 536, 412, 264, 1623, 51436], "temperature": 0.0, "avg_logprob": -0.0983911887886598, "compression_ratio": 1.65625, "no_speech_prob": 0.002214709296822548}, {"id": 212, "seek": 142760, "start": 1449.9199999999998, "end": 1455.84, "text": " of autoregressive LLM, the fact that they hallucinate, they sometimes say really stupid", "tokens": [51480, 295, 1476, 418, 3091, 488, 441, 43, 44, 11, 264, 1186, 300, 436, 35212, 13923, 11, 436, 2171, 584, 534, 6631, 51776], "temperature": 0.0, "avg_logprob": -0.0983911887886598, "compression_ratio": 1.65625, "no_speech_prob": 0.002214709296822548}, {"id": 213, "seek": 145584, "start": 1455.84, "end": 1460.6399999999999, "text": " things. They don't really have a good understanding of the world. People claim that they have some", "tokens": [50364, 721, 13, 814, 500, 380, 534, 362, 257, 665, 3701, 295, 264, 1002, 13, 3432, 3932, 300, 436, 362, 512, 50604], "temperature": 0.0, "avg_logprob": -0.12818371246908314, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0009998447494581342}, {"id": 214, "seek": 145584, "start": 1460.6399999999999, "end": 1465.4399999999998, "text": " simple word model, but it's very implicit and it's really not good at all. Like, for example,", "tokens": [50604, 2199, 1349, 2316, 11, 457, 309, 311, 588, 26947, 293, 309, 311, 534, 406, 665, 412, 439, 13, 1743, 11, 337, 1365, 11, 50844], "temperature": 0.0, "avg_logprob": -0.12818371246908314, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0009998447494581342}, {"id": 215, "seek": 145584, "start": 1466.6399999999999, "end": 1472.6399999999999, "text": " you know, you can tell an LLM that A is the same as B. And then you ask if B is the same as A,", "tokens": [50904, 291, 458, 11, 291, 393, 980, 364, 441, 43, 44, 300, 316, 307, 264, 912, 382, 363, 13, 400, 550, 291, 1029, 498, 363, 307, 264, 912, 382, 316, 11, 51204], "temperature": 0.0, "avg_logprob": -0.12818371246908314, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0009998447494581342}, {"id": 216, "seek": 145584, "start": 1472.6399999999999, "end": 1478.0, "text": " and it will say, I don't know, or no. Right. I mean, those things don't really understand", "tokens": [51204, 293, 309, 486, 584, 11, 286, 500, 380, 458, 11, 420, 572, 13, 1779, 13, 286, 914, 11, 729, 721, 500, 380, 534, 1223, 51472], "temperature": 0.0, "avg_logprob": -0.12818371246908314, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0009998447494581342}, {"id": 217, "seek": 147800, "start": 1478.0, "end": 1486.16, "text": " logic or anything like that. Right. So the type of system that we're talking about that might be,", "tokens": [50364, 9952, 420, 1340, 411, 300, 13, 1779, 13, 407, 264, 2010, 295, 1185, 300, 321, 434, 1417, 466, 300, 1062, 312, 11, 50772], "temperature": 0.0, "avg_logprob": -0.15238228063473755, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0051370966248214245}, {"id": 218, "seek": 147800, "start": 1487.04, "end": 1492.88, "text": " that might approach any more level intelligence and let alone human level intelligence have not", "tokens": [50816, 300, 1062, 3109, 604, 544, 1496, 7599, 293, 718, 3312, 1952, 1496, 7599, 362, 406, 51108], "temperature": 0.0, "avg_logprob": -0.15238228063473755, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0051370966248214245}, {"id": 219, "seek": 147800, "start": 1492.88, "end": 1500.88, "text": " been designed. They don't exist. And so discussing their danger and their potential harm is a bit", "tokens": [51108, 668, 4761, 13, 814, 500, 380, 2514, 13, 400, 370, 10850, 641, 4330, 293, 641, 3995, 6491, 307, 257, 857, 51508], "temperature": 0.0, "avg_logprob": -0.15238228063473755, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0051370966248214245}, {"id": 220, "seek": 147800, "start": 1500.88, "end": 1506.24, "text": " like, you know, discussing the sex of angels at the moment, or to be a little more", "tokens": [51508, 411, 11, 291, 458, 11, 10850, 264, 3260, 295, 18175, 412, 264, 1623, 11, 420, 281, 312, 257, 707, 544, 51776], "temperature": 0.0, "avg_logprob": -0.15238228063473755, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0051370966248214245}, {"id": 221, "seek": 150624, "start": 1506.64, "end": 1512.96, "text": " accurate, perhaps, it would be kind of like discussing how we're going to make transatlantic", "tokens": [50384, 8559, 11, 4317, 11, 309, 576, 312, 733, 295, 411, 10850, 577, 321, 434, 516, 281, 652, 1145, 48630, 7128, 50700], "temperature": 0.0, "avg_logprob": -0.1700189446890226, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002180557930842042}, {"id": 222, "seek": 150624, "start": 1512.96, "end": 1520.64, "text": " flight at near the speed of sound safe when we haven't yet invented the turbojet in 1925.", "tokens": [50700, 7018, 412, 2651, 264, 3073, 295, 1626, 3273, 562, 321, 2378, 380, 1939, 14479, 264, 20902, 7108, 294, 1294, 6074, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1700189446890226, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002180557930842042}, {"id": 223, "seek": 150624, "start": 1521.2, "end": 1528.4, "text": " Yeah. Yeah. Like, you know, we can speculate, but you know, how do we, how did we make turbojet", "tokens": [51112, 865, 13, 865, 13, 1743, 11, 291, 458, 11, 321, 393, 40775, 11, 457, 291, 458, 11, 577, 360, 321, 11, 577, 630, 321, 652, 20902, 7108, 51472], "temperature": 0.0, "avg_logprob": -0.1700189446890226, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002180557930842042}, {"id": 224, "seek": 150624, "start": 1528.4, "end": 1534.64, "text": " safe? It required decades of really careful engineering to make them incredibly reliable.", "tokens": [51472, 3273, 30, 467, 4739, 7878, 295, 534, 5026, 7043, 281, 652, 552, 6252, 12924, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1700189446890226, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.002180557930842042}, {"id": 225, "seek": 153464, "start": 1534.64, "end": 1541.1200000000001, "text": " And, you know, now we can, you know, run like halfway around the world with the two-engine", "tokens": [50364, 400, 11, 291, 458, 11, 586, 321, 393, 11, 291, 458, 11, 1190, 411, 15461, 926, 264, 1002, 365, 264, 732, 12, 25609, 50688], "temperature": 0.0, "avg_logprob": -0.10158304150184888, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0005526301101781428}, {"id": 226, "seek": 153464, "start": 1543.3600000000001, "end": 1550.96, "text": " turbojet aircraft. I mean, that's an incredible feat. And it's not like people were discussing", "tokens": [50800, 20902, 7108, 9465, 13, 286, 914, 11, 300, 311, 364, 4651, 15425, 13, 400, 309, 311, 406, 411, 561, 645, 10850, 51180], "temperature": 0.0, "avg_logprob": -0.10158304150184888, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0005526301101781428}, {"id": 227, "seek": 153464, "start": 1550.96, "end": 1555.2, "text": " sort of philosophical questions about how you make turbojet safe. It's just really careful and", "tokens": [51180, 1333, 295, 25066, 1651, 466, 577, 291, 652, 20902, 7108, 3273, 13, 467, 311, 445, 534, 5026, 293, 51392], "temperature": 0.0, "avg_logprob": -0.10158304150184888, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0005526301101781428}, {"id": 228, "seek": 153464, "start": 1555.2, "end": 1564.0800000000002, "text": " complicated engineering that no one, none of us would understand. So, you know,", "tokens": [51392, 6179, 7043, 300, 572, 472, 11, 6022, 295, 505, 576, 1223, 13, 407, 11, 291, 458, 11, 51836], "temperature": 0.0, "avg_logprob": -0.10158304150184888, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0005526301101781428}, {"id": 229, "seek": 156408, "start": 1564.32, "end": 1571.04, "text": " how could we ask the AI community now to explain how AI systems are going to be safe? We haven't", "tokens": [50376, 577, 727, 321, 1029, 264, 7318, 1768, 586, 281, 2903, 577, 7318, 3652, 366, 516, 281, 312, 3273, 30, 492, 2378, 380, 50712], "temperature": 0.0, "avg_logprob": -0.1095883160421293, "compression_ratio": 1.4568527918781726, "no_speech_prob": 0.0015445953467860818}, {"id": 230, "seek": 156408, "start": 1571.04, "end": 1579.04, "text": " invented them yet. No. Okay. That said, I have some idea about how we can design them so that", "tokens": [50712, 14479, 552, 1939, 13, 883, 13, 1033, 13, 663, 848, 11, 286, 362, 512, 1558, 466, 577, 321, 393, 1715, 552, 370, 300, 51112], "temperature": 0.0, "avg_logprob": -0.1095883160421293, "compression_ratio": 1.4568527918781726, "no_speech_prob": 0.0015445953467860818}, {"id": 231, "seek": 156408, "start": 1579.04, "end": 1584.8, "text": " they have these capabilities. And as a consequence, how they will be safe, I call this objective", "tokens": [51112, 436, 362, 613, 10862, 13, 400, 382, 257, 18326, 11, 577, 436, 486, 312, 3273, 11, 286, 818, 341, 10024, 51400], "temperature": 0.0, "avg_logprob": -0.1095883160421293, "compression_ratio": 1.4568527918781726, "no_speech_prob": 0.0015445953467860818}, {"id": 232, "seek": 158480, "start": 1584.8, "end": 1595.36, "text": " driven AI. So what that means is essentially systems that produce their answer by planning", "tokens": [50364, 9555, 7318, 13, 407, 437, 300, 1355, 307, 4476, 3652, 300, 5258, 641, 1867, 538, 5038, 50892], "temperature": 0.0, "avg_logprob": -0.1604490997970745, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.009554330259561539}, {"id": 233, "seek": 158480, "start": 1595.36, "end": 1601.12, "text": " their answer so as to satisfy an objective or a set of objectives. So this is very different", "tokens": [50892, 641, 1867, 370, 382, 281, 19319, 364, 10024, 420, 257, 992, 295, 15961, 13, 407, 341, 307, 588, 819, 51180], "temperature": 0.0, "avg_logprob": -0.1604490997970745, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.009554330259561539}, {"id": 234, "seek": 158480, "start": 1601.12, "end": 1605.76, "text": " from current LLNs. Current LLNs produce one word after the other or one token, which is,", "tokens": [51180, 490, 2190, 441, 43, 45, 82, 13, 15629, 441, 43, 45, 82, 5258, 472, 1349, 934, 264, 661, 420, 472, 14862, 11, 597, 307, 11, 51412], "temperature": 0.0, "avg_logprob": -0.1604490997970745, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.009554330259561539}, {"id": 235, "seek": 158480, "start": 1605.76, "end": 1610.8, "text": " which has a board unit, doesn't matter, right? They don't really think and plan ahead as we,", "tokens": [51412, 597, 575, 257, 3150, 4985, 11, 1177, 380, 1871, 11, 558, 30, 814, 500, 380, 534, 519, 293, 1393, 2286, 382, 321, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1604490997970745, "compression_ratio": 1.6079295154185023, "no_speech_prob": 0.009554330259561539}, {"id": 236, "seek": 161080, "start": 1610.8, "end": 1614.48, "text": " as we said before. They just produce one word after the other. That's not controllable.", "tokens": [50364, 382, 321, 848, 949, 13, 814, 445, 5258, 472, 1349, 934, 264, 661, 13, 663, 311, 406, 45159, 712, 13, 50548], "temperature": 0.0, "avg_logprob": -0.12333636934107, "compression_ratio": 1.7718446601941749, "no_speech_prob": 0.001263712765648961}, {"id": 237, "seek": 161080, "start": 1615.84, "end": 1620.6399999999999, "text": " The only thing we can do is see if what they've produced, like check if what they've produced", "tokens": [50616, 440, 787, 551, 321, 393, 360, 307, 536, 498, 437, 436, 600, 7126, 11, 411, 1520, 498, 437, 436, 600, 7126, 50856], "temperature": 0.0, "avg_logprob": -0.12333636934107, "compression_ratio": 1.7718446601941749, "no_speech_prob": 0.001263712765648961}, {"id": 238, "seek": 161080, "start": 1621.52, "end": 1627.2, "text": " satisfies some criterion or set of criteria and then not produce an answer or produce a", "tokens": [50900, 44271, 512, 46691, 420, 992, 295, 11101, 293, 550, 406, 5258, 364, 1867, 420, 5258, 257, 51184], "temperature": 0.0, "avg_logprob": -0.12333636934107, "compression_ratio": 1.7718446601941749, "no_speech_prob": 0.001263712765648961}, {"id": 239, "seek": 161080, "start": 1627.2, "end": 1634.6399999999999, "text": " non-answer if the answer that was produced isn't appropriate. But we can't really force them to", "tokens": [51184, 2107, 12, 43904, 498, 264, 1867, 300, 390, 7126, 1943, 380, 6854, 13, 583, 321, 393, 380, 534, 3464, 552, 281, 51556], "temperature": 0.0, "avg_logprob": -0.12333636934107, "compression_ratio": 1.7718446601941749, "no_speech_prob": 0.001263712765648961}, {"id": 240, "seek": 163464, "start": 1635.3600000000001, "end": 1642.8000000000002, "text": " produce an answer that satisfies a set of objectives. So objective driven AI is the other way,", "tokens": [50400, 5258, 364, 1867, 300, 44271, 257, 992, 295, 15961, 13, 407, 10024, 9555, 7318, 307, 264, 661, 636, 11, 50772], "temperature": 0.0, "avg_logprob": -0.13976562982318044, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.000720507581718266}, {"id": 241, "seek": 163464, "start": 1642.8000000000002, "end": 1649.92, "text": " is the opposite. The only thing that the system can produce are answers that satisfy a certain", "tokens": [50772, 307, 264, 6182, 13, 440, 787, 551, 300, 264, 1185, 393, 5258, 366, 6338, 300, 19319, 257, 1629, 51128], "temperature": 0.0, "avg_logprob": -0.13976562982318044, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.000720507581718266}, {"id": 242, "seek": 163464, "start": 1649.92, "end": 1655.5200000000002, "text": " number of objectives. So what objective would be? Did you answer the question? Another objective could", "tokens": [51128, 1230, 295, 15961, 13, 407, 437, 10024, 576, 312, 30, 2589, 291, 1867, 264, 1168, 30, 3996, 10024, 727, 51408], "temperature": 0.0, "avg_logprob": -0.13976562982318044, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.000720507581718266}, {"id": 243, "seek": 163464, "start": 1655.5200000000002, "end": 1660.8000000000002, "text": " be, is your answer understandable by a 13 year old because you're talking to a 13 year old?", "tokens": [51408, 312, 11, 307, 428, 1867, 25648, 538, 257, 3705, 1064, 1331, 570, 291, 434, 1417, 281, 257, 3705, 1064, 1331, 30, 51672], "temperature": 0.0, "avg_logprob": -0.13976562982318044, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.000720507581718266}, {"id": 244, "seek": 166080, "start": 1661.44, "end": 1668.72, "text": " Another would be, is this, I don't know, terrorist propaganda or something? You know,", "tokens": [50396, 3996, 576, 312, 11, 307, 341, 11, 286, 500, 380, 458, 11, 20342, 22968, 420, 746, 30, 509, 458, 11, 50760], "temperature": 0.0, "avg_logprob": -0.15174853126957732, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0014998926781117916}, {"id": 245, "seek": 166080, "start": 1668.72, "end": 1673.36, "text": " you can have a number of criteria like this, guardrails that would guarantee that the answer", "tokens": [50760, 291, 393, 362, 257, 1230, 295, 11101, 411, 341, 11, 6290, 424, 4174, 300, 576, 10815, 300, 264, 1867, 50992], "temperature": 0.0, "avg_logprob": -0.15174853126957732, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0014998926781117916}, {"id": 246, "seek": 166080, "start": 1673.36, "end": 1679.68, "text": " that's produced is satisfy certain criteria, whatever they are. Okay. Same for a robot,", "tokens": [50992, 300, 311, 7126, 307, 19319, 1629, 11101, 11, 2035, 436, 366, 13, 1033, 13, 10635, 337, 257, 7881, 11, 51308], "temperature": 0.0, "avg_logprob": -0.15174853126957732, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0014998926781117916}, {"id": 247, "seek": 166080, "start": 1679.68, "end": 1683.52, "text": " you could guarantee that the sequence of actions that is produced will not hurt anyone.", "tokens": [51308, 291, 727, 10815, 300, 264, 8310, 295, 5909, 300, 307, 7126, 486, 406, 4607, 2878, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15174853126957732, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0014998926781117916}, {"id": 248, "seek": 166080, "start": 1684.08, "end": 1687.6, "text": " Like you can have very low level, you know, guardrails of this type that say,", "tokens": [51528, 1743, 291, 393, 362, 588, 2295, 1496, 11, 291, 458, 11, 6290, 424, 4174, 295, 341, 2010, 300, 584, 11, 51704], "temperature": 0.0, "avg_logprob": -0.15174853126957732, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0014998926781117916}, {"id": 249, "seek": 168760, "start": 1687.9199999999998, "end": 1693.4399999999998, "text": " okay, you have, you know, humans nearby and you're cooking, so you have a big knife in your hand,", "tokens": [50380, 1392, 11, 291, 362, 11, 291, 458, 11, 6255, 11184, 293, 291, 434, 6361, 11, 370, 291, 362, 257, 955, 7976, 294, 428, 1011, 11, 50656], "temperature": 0.0, "avg_logprob": -0.14706648458348642, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.002080923644825816}, {"id": 250, "seek": 168760, "start": 1693.4399999999998, "end": 1699.4399999999998, "text": " don't flare your arms. Okay, that would be a very simple guardrails to impose. And you can imagine", "tokens": [50656, 500, 380, 32446, 428, 5812, 13, 1033, 11, 300, 576, 312, 257, 588, 2199, 6290, 424, 4174, 281, 26952, 13, 400, 291, 393, 3811, 50956], "temperature": 0.0, "avg_logprob": -0.14706648458348642, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.002080923644825816}, {"id": 251, "seek": 168760, "start": 1699.4399999999998, "end": 1703.52, "text": " having a whole bunch of guardrails like this that will guarantee that the behavior of those systems", "tokens": [50956, 1419, 257, 1379, 3840, 295, 6290, 424, 4174, 411, 341, 300, 486, 10815, 300, 264, 5223, 295, 729, 3652, 51160], "temperature": 0.0, "avg_logprob": -0.14706648458348642, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.002080923644825816}, {"id": 252, "seek": 168760, "start": 1704.1599999999999, "end": 1712.8799999999999, "text": " would be safe and that their primary goal would be to be basically subservient to us, right? So I", "tokens": [51192, 576, 312, 3273, 293, 300, 641, 6194, 3387, 576, 312, 281, 312, 1936, 2090, 1978, 1196, 281, 505, 11, 558, 30, 407, 286, 51628], "temperature": 0.0, "avg_logprob": -0.14706648458348642, "compression_ratio": 1.6485355648535565, "no_speech_prob": 0.002080923644825816}, {"id": 253, "seek": 171288, "start": 1712.88, "end": 1720.3200000000002, "text": " do not believe that we'll have AI systems that can work that will not be subservient to us,", "tokens": [50364, 360, 406, 1697, 300, 321, 603, 362, 7318, 3652, 300, 393, 589, 300, 486, 406, 312, 2090, 1978, 1196, 281, 505, 11, 50736], "temperature": 0.0, "avg_logprob": -0.09915292674097521, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.00035681904410012066}, {"id": 254, "seek": 171288, "start": 1721.0400000000002, "end": 1724.64, "text": " will define their own goals, they will define their own sub goals, but those sub goals would", "tokens": [50772, 486, 6964, 641, 1065, 5493, 11, 436, 486, 6964, 641, 1065, 1422, 5493, 11, 457, 729, 1422, 5493, 576, 50952], "temperature": 0.0, "avg_logprob": -0.09915292674097521, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.00035681904410012066}, {"id": 255, "seek": 171288, "start": 1724.64, "end": 1730.96, "text": " be sub goals or goals that we set them and will not have all kinds of guardrails that will", "tokens": [50952, 312, 1422, 5493, 420, 5493, 300, 321, 992, 552, 293, 486, 406, 362, 439, 3685, 295, 6290, 424, 4174, 300, 486, 51268], "temperature": 0.0, "avg_logprob": -0.09915292674097521, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.00035681904410012066}, {"id": 256, "seek": 171288, "start": 1730.96, "end": 1735.6000000000001, "text": " guarantee the safety. And we're not going to, it's not like we're going to invent a system", "tokens": [51268, 10815, 264, 4514, 13, 400, 321, 434, 406, 516, 281, 11, 309, 311, 406, 411, 321, 434, 516, 281, 7962, 257, 1185, 51500], "temperature": 0.0, "avg_logprob": -0.09915292674097521, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.00035681904410012066}, {"id": 257, "seek": 171288, "start": 1735.6000000000001, "end": 1740.0800000000002, "text": " and make a gigantic one that we know will have human level AI and just turning on and then from", "tokens": [51500, 293, 652, 257, 26800, 472, 300, 321, 458, 486, 362, 1952, 1496, 7318, 293, 445, 6246, 322, 293, 550, 490, 51724], "temperature": 0.0, "avg_logprob": -0.09915292674097521, "compression_ratio": 1.9170124481327802, "no_speech_prob": 0.00035681904410012066}, {"id": 258, "seek": 174008, "start": 1740.6399999999999, "end": 1743.4399999999998, "text": " the next minute is going to take over the world. That's completely preposterous.", "tokens": [50392, 264, 958, 3456, 307, 516, 281, 747, 670, 264, 1002, 13, 663, 311, 2584, 2666, 7096, 563, 13, 50532], "temperature": 0.0, "avg_logprob": -0.1222418878899246, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.004680694080889225}, {"id": 259, "seek": 174008, "start": 1743.9199999999998, "end": 1748.96, "text": " What we're going to do is try with small ones, you know, maybe as smart as a mouse or something,", "tokens": [50556, 708, 321, 434, 516, 281, 360, 307, 853, 365, 1359, 2306, 11, 291, 458, 11, 1310, 382, 4069, 382, 257, 9719, 420, 746, 11, 50808], "temperature": 0.0, "avg_logprob": -0.1222418878899246, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.004680694080889225}, {"id": 260, "seek": 174008, "start": 1748.96, "end": 1753.1999999999998, "text": " maybe a dog, maybe a cat, maybe a dog, maybe and work our way up and then, you know,", "tokens": [50808, 1310, 257, 3000, 11, 1310, 257, 3857, 11, 1310, 257, 3000, 11, 1310, 293, 589, 527, 636, 493, 293, 550, 11, 291, 458, 11, 51020], "temperature": 0.0, "avg_logprob": -0.1222418878899246, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.004680694080889225}, {"id": 261, "seek": 174008, "start": 1753.1999999999998, "end": 1759.12, "text": " put some more guardrails. Basically, like we've engineered, you know, more and more powerful", "tokens": [51020, 829, 512, 544, 6290, 424, 4174, 13, 8537, 11, 411, 321, 600, 38648, 11, 291, 458, 11, 544, 293, 544, 4005, 51316], "temperature": 0.0, "avg_logprob": -0.1222418878899246, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.004680694080889225}, {"id": 262, "seek": 174008, "start": 1759.12, "end": 1767.36, "text": " and more reliable turbojets. It's an engineering problem. Yeah, yeah. You were also on a paper,", "tokens": [51316, 293, 544, 12924, 20902, 25349, 13, 467, 311, 364, 7043, 1154, 13, 865, 11, 1338, 13, 509, 645, 611, 322, 257, 3035, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1222418878899246, "compression_ratio": 1.748062015503876, "no_speech_prob": 0.004680694080889225}, {"id": 263, "seek": 176736, "start": 1767.36, "end": 1772.6399999999999, "text": " maybe this is the one that talked about the embodied Turing test on neuro AI.", "tokens": [50364, 1310, 341, 307, 264, 472, 300, 2825, 466, 264, 42046, 314, 1345, 1500, 322, 16499, 7318, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1347190614730593, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.0014529147883877158}, {"id": 264, "seek": 176736, "start": 1774.8, "end": 1785.4399999999998, "text": " Can you explain what the neuro AI is? Okay. Well, it's the idea that we should get some", "tokens": [50736, 1664, 291, 2903, 437, 264, 16499, 7318, 307, 30, 1033, 13, 1042, 11, 309, 311, 264, 1558, 300, 321, 820, 483, 512, 51268], "temperature": 0.0, "avg_logprob": -0.1347190614730593, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.0014529147883877158}, {"id": 265, "seek": 176736, "start": 1785.4399999999998, "end": 1793.28, "text": " inspiration from neuroscience to build AI systems and that there is something to be learned from", "tokens": [51268, 10249, 490, 42762, 281, 1322, 7318, 3652, 293, 300, 456, 307, 746, 281, 312, 3264, 490, 51660], "temperature": 0.0, "avg_logprob": -0.1347190614730593, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.0014529147883877158}, {"id": 266, "seek": 179328, "start": 1793.28, "end": 1802.32, "text": " neuroscience and from cognitive science to drive the design of AI systems, some inspiration.", "tokens": [50364, 42762, 293, 490, 15605, 3497, 281, 3332, 264, 1715, 295, 7318, 3652, 11, 512, 10249, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11748948911341225, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0005608546198345721}, {"id": 267, "seek": 179328, "start": 1802.96, "end": 1808.8799999999999, "text": " Okay. Something to be learned as well as the other way around. So what's interesting right now is", "tokens": [50848, 1033, 13, 6595, 281, 312, 3264, 382, 731, 382, 264, 661, 636, 926, 13, 407, 437, 311, 1880, 558, 586, 307, 51144], "temperature": 0.0, "avg_logprob": -0.11748948911341225, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0005608546198345721}, {"id": 268, "seek": 179328, "start": 1808.8799999999999, "end": 1815.84, "text": " that the best models that we have of how, for example, the visual cortex works is convolutional", "tokens": [51144, 300, 264, 1151, 5245, 300, 321, 362, 295, 577, 11, 337, 1365, 11, 264, 5056, 33312, 1985, 307, 45216, 304, 51492], "temperature": 0.0, "avg_logprob": -0.11748948911341225, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0005608546198345721}, {"id": 269, "seek": 179328, "start": 1815.84, "end": 1820.8, "text": " neural networks, which are also the models that we use to recognize images primarily", "tokens": [51492, 18161, 9590, 11, 597, 366, 611, 264, 5245, 300, 321, 764, 281, 5521, 5267, 10029, 51740], "temperature": 0.0, "avg_logprob": -0.11748948911341225, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0005608546198345721}, {"id": 270, "seek": 182080, "start": 1820.8, "end": 1826.8, "text": " in artificial systems. So there is kind of information kind of being exchanged both ways.", "tokens": [50364, 294, 11677, 3652, 13, 407, 456, 307, 733, 295, 1589, 733, 295, 885, 38378, 1293, 2098, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12984490668636628, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.0018370614852756262}, {"id": 271, "seek": 182080, "start": 1827.52, "end": 1835.76, "text": " There's one, you know, one way to make progress in AI is to kind of ignore nature and just,", "tokens": [50700, 821, 311, 472, 11, 291, 458, 11, 472, 636, 281, 652, 4205, 294, 7318, 307, 281, 733, 295, 11200, 3687, 293, 445, 11, 51112], "temperature": 0.0, "avg_logprob": -0.12984490668636628, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.0018370614852756262}, {"id": 272, "seek": 182080, "start": 1835.76, "end": 1842.24, "text": " you know, kind of try to solve problems in a sort of engineering fashion, if you want.", "tokens": [51112, 291, 458, 11, 733, 295, 853, 281, 5039, 2740, 294, 257, 1333, 295, 7043, 6700, 11, 498, 291, 528, 13, 51436], "temperature": 0.0, "avg_logprob": -0.12984490668636628, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.0018370614852756262}, {"id": 273, "seek": 182080, "start": 1843.84, "end": 1850.56, "text": " I found interaction with neuroscience always thought provoking. So you don't want to be", "tokens": [51516, 286, 1352, 9285, 365, 42762, 1009, 1194, 1439, 5953, 13, 407, 291, 500, 380, 528, 281, 312, 51852], "temperature": 0.0, "avg_logprob": -0.12984490668636628, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.0018370614852756262}, {"id": 274, "seek": 185056, "start": 1850.6399999999999, "end": 1854.96, "text": " copying nature very too closely because there are details in nature that are irrelevant.", "tokens": [50368, 27976, 3687, 588, 886, 8185, 570, 456, 366, 4365, 294, 3687, 300, 366, 28682, 13, 50584], "temperature": 0.0, "avg_logprob": -0.09986424446105957, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0003857201663777232}, {"id": 275, "seek": 185056, "start": 1855.84, "end": 1860.72, "text": " And there are principles on which, you know, natural intelligence is based that we haven't", "tokens": [50628, 400, 456, 366, 9156, 322, 597, 11, 291, 458, 11, 3303, 7599, 307, 2361, 300, 321, 2378, 380, 50872], "temperature": 0.0, "avg_logprob": -0.09986424446105957, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0003857201663777232}, {"id": 276, "seek": 185056, "start": 1860.72, "end": 1866.3999999999999, "text": " discovered. So, but there is some inspiration to have certainly in your convolutional net for", "tokens": [50872, 6941, 13, 407, 11, 457, 456, 307, 512, 10249, 281, 362, 3297, 294, 428, 45216, 304, 2533, 337, 51156], "temperature": 0.0, "avg_logprob": -0.09986424446105957, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0003857201663777232}, {"id": 277, "seek": 185056, "start": 1866.3999999999999, "end": 1871.6, "text": " inspired by the architecture of the visual cortex. The whole idea of neural net and deep learning", "tokens": [51156, 7547, 538, 264, 9482, 295, 264, 5056, 33312, 13, 440, 1379, 1558, 295, 18161, 2533, 293, 2452, 2539, 51416], "temperature": 0.0, "avg_logprob": -0.09986424446105957, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0003857201663777232}, {"id": 278, "seek": 185056, "start": 1871.6, "end": 1877.2, "text": " came out of the idea that, you know, intelligence can emerge from a large collection of simple", "tokens": [51416, 1361, 484, 295, 264, 1558, 300, 11, 291, 458, 11, 7599, 393, 21511, 490, 257, 2416, 5765, 295, 2199, 51696], "temperature": 0.0, "avg_logprob": -0.09986424446105957, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.0003857201663777232}, {"id": 279, "seek": 187720, "start": 1877.2, "end": 1882.0800000000002, "text": " elements that are connected with each other and change the nature of their interactions.", "tokens": [50364, 4959, 300, 366, 4582, 365, 1184, 661, 293, 1319, 264, 3687, 295, 641, 13280, 13, 50608], "temperature": 0.0, "avg_logprob": -0.10746400109652815, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.000939429912250489}, {"id": 280, "seek": 187720, "start": 1882.0800000000002, "end": 1888.8, "text": " That's the whole idea, right? So, so inspiration from neuroscience certainly has been extremely", "tokens": [50608, 663, 311, 264, 1379, 1558, 11, 558, 30, 407, 11, 370, 10249, 490, 42762, 3297, 575, 668, 4664, 50944], "temperature": 0.0, "avg_logprob": -0.10746400109652815, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.000939429912250489}, {"id": 281, "seek": 187720, "start": 1889.68, "end": 1894.8, "text": " beneficial so far. And the idea of neural AI is that you should keep going. You don't want to go", "tokens": [50988, 14072, 370, 1400, 13, 400, 264, 1558, 295, 18161, 7318, 307, 300, 291, 820, 1066, 516, 13, 509, 500, 380, 528, 281, 352, 51244], "temperature": 0.0, "avg_logprob": -0.10746400109652815, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.000939429912250489}, {"id": 282, "seek": 187720, "start": 1894.8, "end": 1902.24, "text": " too far. So going too far, for example, is trying to reproduce the some aspect of the functioning", "tokens": [51244, 886, 1400, 13, 407, 516, 886, 1400, 11, 337, 1365, 11, 307, 1382, 281, 29501, 264, 512, 4171, 295, 264, 18483, 51616], "temperature": 0.0, "avg_logprob": -0.10746400109652815, "compression_ratio": 1.5857740585774058, "no_speech_prob": 0.000939429912250489}, {"id": 283, "seek": 190224, "start": 1902.24, "end": 1909.76, "text": " of neurons with electronics. I'm not sure that's a good idea. I'm skeptical about this, for example.", "tokens": [50364, 295, 22027, 365, 20611, 13, 286, 478, 406, 988, 300, 311, 257, 665, 1558, 13, 286, 478, 28601, 466, 341, 11, 337, 1365, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1170908080206977, "compression_ratio": 1.3895348837209303, "no_speech_prob": 0.002931164810433984}, {"id": 284, "seek": 190224, "start": 1911.84, "end": 1917.76, "text": " So your research right now, are you, your main focus is on", "tokens": [50844, 407, 428, 2132, 558, 586, 11, 366, 291, 11, 428, 2135, 1879, 307, 322, 51140], "temperature": 0.0, "avg_logprob": -0.1170908080206977, "compression_ratio": 1.3895348837209303, "no_speech_prob": 0.002931164810433984}, {"id": 285, "seek": 190224, "start": 1919.1200000000001, "end": 1925.44, "text": " furthering the JEPA architecture into other modalities or where are you headed?", "tokens": [51208, 3052, 278, 264, 508, 8929, 32, 9482, 666, 661, 1072, 16110, 420, 689, 366, 291, 12798, 30, 51524], "temperature": 0.0, "avg_logprob": -0.1170908080206977, "compression_ratio": 1.3895348837209303, "no_speech_prob": 0.002931164810433984}, {"id": 286, "seek": 192544, "start": 1926.4, "end": 1934.0, "text": " Yeah. So, I mean, the long term goal is, you know, to get machines to be as intelligent and learn", "tokens": [50412, 865, 13, 407, 11, 286, 914, 11, 264, 938, 1433, 3387, 307, 11, 291, 458, 11, 281, 483, 8379, 281, 312, 382, 13232, 293, 1466, 50792], "temperature": 0.0, "avg_logprob": -0.13689058025678, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.009627653285861015}, {"id": 287, "seek": 192544, "start": 1934.0, "end": 1939.52, "text": " as efficiently as animals and humans. Okay. And the reason for this is that we need this because", "tokens": [50792, 382, 19621, 382, 4882, 293, 6255, 13, 1033, 13, 400, 264, 1778, 337, 341, 307, 300, 321, 643, 341, 570, 51068], "temperature": 0.0, "avg_logprob": -0.13689058025678, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.009627653285861015}, {"id": 288, "seek": 192544, "start": 1939.52, "end": 1945.76, "text": " we need to amplify human intelligence. And so intelligence is the most needed commodity that", "tokens": [51068, 321, 643, 281, 41174, 1952, 7599, 13, 400, 370, 7599, 307, 264, 881, 2978, 29125, 300, 51380], "temperature": 0.0, "avg_logprob": -0.13689058025678, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.009627653285861015}, {"id": 289, "seek": 192544, "start": 1945.76, "end": 1953.1200000000001, "text": " we want in the world, right? And so we could, you know, possibly bring a new renaissance to humanity", "tokens": [51380, 321, 528, 294, 264, 1002, 11, 558, 30, 400, 370, 321, 727, 11, 291, 458, 11, 6264, 1565, 257, 777, 319, 629, 14431, 281, 10243, 51748], "temperature": 0.0, "avg_logprob": -0.13689058025678, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.009627653285861015}, {"id": 290, "seek": 195312, "start": 1953.12, "end": 1958.4799999999998, "text": " if we could amplify human intelligence using machines, which we are doing already with computers,", "tokens": [50364, 498, 321, 727, 41174, 1952, 7599, 1228, 8379, 11, 597, 321, 366, 884, 1217, 365, 10807, 11, 50632], "temperature": 0.0, "avg_logprob": -0.10209227156365054, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.0008418864454142749}, {"id": 291, "seek": 195312, "start": 1958.4799999999998, "end": 1963.1999999999998, "text": " right? I mean, that's pretty much what they've been designed to do. But even more, you know,", "tokens": [50632, 558, 30, 286, 914, 11, 300, 311, 1238, 709, 437, 436, 600, 668, 4761, 281, 360, 13, 583, 754, 544, 11, 291, 458, 11, 50868], "temperature": 0.0, "avg_logprob": -0.10209227156365054, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.0008418864454142749}, {"id": 292, "seek": 195312, "start": 1963.1999999999998, "end": 1972.8799999999999, "text": " imagine a future where every one of us has an intelligent assistant with us at all times.", "tokens": [50868, 3811, 257, 2027, 689, 633, 472, 295, 505, 575, 364, 13232, 10994, 365, 505, 412, 439, 1413, 13, 51352], "temperature": 0.0, "avg_logprob": -0.10209227156365054, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.0008418864454142749}, {"id": 293, "seek": 195312, "start": 1973.52, "end": 1977.6, "text": " They can be smarter than us. You shouldn't feel threatened by that. We should feel", "tokens": [51384, 814, 393, 312, 20294, 813, 505, 13, 509, 4659, 380, 841, 18268, 538, 300, 13, 492, 820, 841, 51588], "temperature": 0.0, "avg_logprob": -0.10209227156365054, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.0008418864454142749}, {"id": 294, "seek": 197760, "start": 1978.56, "end": 1985.84, "text": " like we are like, you know, a director of a big lab or a CEO of a company that has a staff working", "tokens": [50412, 411, 321, 366, 411, 11, 291, 458, 11, 257, 5391, 295, 257, 955, 2715, 420, 257, 9282, 295, 257, 2237, 300, 575, 257, 3525, 1364, 50776], "temperature": 0.0, "avg_logprob": -0.12503436860584077, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004004696384072304}, {"id": 295, "seek": 197760, "start": 1985.84, "end": 1990.24, "text": " for them of people who are smarter than themselves. I mean, we're used to this already. I'm used to", "tokens": [50776, 337, 552, 295, 561, 567, 366, 20294, 813, 2969, 13, 286, 914, 11, 321, 434, 1143, 281, 341, 1217, 13, 286, 478, 1143, 281, 50996], "temperature": 0.0, "avg_logprob": -0.12503436860584077, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004004696384072304}, {"id": 296, "seek": 197760, "start": 1990.24, "end": 1995.36, "text": " this certainly working with people who are smarter than me. So we shouldn't feel threatened by this,", "tokens": [50996, 341, 3297, 1364, 365, 561, 567, 366, 20294, 813, 385, 13, 407, 321, 4659, 380, 841, 18268, 538, 341, 11, 51252], "temperature": 0.0, "avg_logprob": -0.12503436860584077, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004004696384072304}, {"id": 297, "seek": 197760, "start": 1995.36, "end": 2003.52, "text": " but it's going to empower a lot of us, right, and humanity as a whole. So I think that's a good", "tokens": [51252, 457, 309, 311, 516, 281, 11071, 257, 688, 295, 505, 11, 558, 11, 293, 10243, 382, 257, 1379, 13, 407, 286, 519, 300, 311, 257, 665, 51660], "temperature": 0.0, "avg_logprob": -0.12503436860584077, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004004696384072304}, {"id": 298, "seek": 200352, "start": 2003.6, "end": 2007.92, "text": " thing. That's the overall practical goal, if you want, right? Then there's a scientific", "tokens": [50368, 551, 13, 663, 311, 264, 4787, 8496, 3387, 11, 498, 291, 528, 11, 558, 30, 1396, 456, 311, 257, 8134, 50584], "temperature": 0.0, "avg_logprob": -0.1024833852594549, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008431418798863888}, {"id": 299, "seek": 200352, "start": 2007.92, "end": 2011.84, "text": " question that's behind this, which is really what is intelligence and how you build it.", "tokens": [50584, 1168, 300, 311, 2261, 341, 11, 597, 307, 534, 437, 307, 7599, 293, 577, 291, 1322, 309, 13, 50780], "temperature": 0.0, "avg_logprob": -0.1024833852594549, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008431418798863888}, {"id": 300, "seek": 200352, "start": 2012.96, "end": 2018.24, "text": " And then which is, you know, how can system learn the way animals and humans seem to be", "tokens": [50836, 400, 550, 597, 307, 11, 291, 458, 11, 577, 393, 1185, 1466, 264, 636, 4882, 293, 6255, 1643, 281, 312, 51100], "temperature": 0.0, "avg_logprob": -0.1024833852594549, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008431418798863888}, {"id": 301, "seek": 200352, "start": 2018.24, "end": 2025.44, "text": " learning so efficiently? And the next thing is, how do we learn how the world works by observation,", "tokens": [51100, 2539, 370, 19621, 30, 400, 264, 958, 551, 307, 11, 577, 360, 321, 1466, 577, 264, 1002, 1985, 538, 14816, 11, 51460], "temperature": 0.0, "avg_logprob": -0.1024833852594549, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008431418798863888}, {"id": 302, "seek": 200352, "start": 2025.44, "end": 2032.08, "text": " by watching the world go by through vision and all the other senses? And animals can do this", "tokens": [51460, 538, 1976, 264, 1002, 352, 538, 807, 5201, 293, 439, 264, 661, 17057, 30, 400, 4882, 393, 360, 341, 51792], "temperature": 0.0, "avg_logprob": -0.1024833852594549, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008431418798863888}, {"id": 303, "seek": 203208, "start": 2032.08, "end": 2039.36, "text": " without language, right? So it has nothing to do with language, has to do with learning from sensory", "tokens": [50364, 1553, 2856, 11, 558, 30, 407, 309, 575, 1825, 281, 360, 365, 2856, 11, 575, 281, 360, 365, 2539, 490, 27233, 50728], "temperature": 0.0, "avg_logprob": -0.10299506103783324, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.004745472222566605}, {"id": 304, "seek": 203208, "start": 2039.36, "end": 2044.96, "text": " perceives and learning mostly without acting, because any action you take can kill you. So", "tokens": [50728, 9016, 1539, 293, 2539, 5240, 1553, 6577, 11, 570, 604, 3069, 291, 747, 393, 1961, 291, 13, 407, 51008], "temperature": 0.0, "avg_logprob": -0.10299506103783324, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.004745472222566605}, {"id": 305, "seek": 203208, "start": 2044.96, "end": 2049.2, "text": " it's better to be able to learn as much as you can without actually acting at all, just observing,", "tokens": [51008, 309, 311, 1101, 281, 312, 1075, 281, 1466, 382, 709, 382, 291, 393, 1553, 767, 6577, 412, 439, 11, 445, 22107, 11, 51220], "temperature": 0.0, "avg_logprob": -0.10299506103783324, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.004745472222566605}, {"id": 306, "seek": 203208, "start": 2050.0, "end": 2054.4, "text": " which is what babies do in the first few months of life. They can't hardly do anything, right? So", "tokens": [51260, 597, 307, 437, 10917, 360, 294, 264, 700, 1326, 2493, 295, 993, 13, 814, 393, 380, 13572, 360, 1340, 11, 558, 30, 407, 51480], "temperature": 0.0, "avg_logprob": -0.10299506103783324, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.004745472222566605}, {"id": 307, "seek": 203208, "start": 2054.4, "end": 2059.6, "text": " they mostly observe and learn how the world works by observation. So what kind of learning takes", "tokens": [51480, 436, 5240, 11441, 293, 1466, 577, 264, 1002, 1985, 538, 14816, 13, 407, 437, 733, 295, 2539, 2516, 51740], "temperature": 0.0, "avg_logprob": -0.10299506103783324, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.004745472222566605}, {"id": 308, "seek": 205960, "start": 2059.68, "end": 2064.88, "text": " place there? So that's obviously kind of self-supervised, right? It's learning by prediction. That's an", "tokens": [50368, 1081, 456, 30, 407, 300, 311, 2745, 733, 295, 2698, 12, 48172, 24420, 11, 558, 30, 467, 311, 2539, 538, 17630, 13, 663, 311, 364, 50628], "temperature": 0.0, "avg_logprob": -0.12843858986570125, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006085042841732502}, {"id": 309, "seek": 205960, "start": 2064.88, "end": 2072.08, "text": " whole idea from cognitive science. And the thing is, you know, we can learn to predict videos,", "tokens": [50628, 1379, 1558, 490, 15605, 3497, 13, 400, 264, 551, 307, 11, 291, 458, 11, 321, 393, 1466, 281, 6069, 2145, 11, 50988], "temperature": 0.0, "avg_logprob": -0.12843858986570125, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006085042841732502}, {"id": 310, "seek": 205960, "start": 2072.08, "end": 2076.72, "text": " but then we notice that predicting videos, predicting pixels in video, is so initially", "tokens": [50988, 457, 550, 321, 3449, 300, 32884, 2145, 11, 32884, 18668, 294, 960, 11, 307, 370, 9105, 51220], "temperature": 0.0, "avg_logprob": -0.12843858986570125, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006085042841732502}, {"id": 311, "seek": 205960, "start": 2076.72, "end": 2083.36, "text": " complicated that it doesn't work. And so then came this idea of JEPA, right? Learn representations", "tokens": [51220, 6179, 300, 309, 1177, 380, 589, 13, 400, 370, 550, 1361, 341, 1558, 295, 508, 8929, 32, 11, 558, 30, 17216, 33358, 51552], "temperature": 0.0, "avg_logprob": -0.12843858986570125, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006085042841732502}, {"id": 312, "seek": 205960, "start": 2083.36, "end": 2088.08, "text": " so that you can make predictions in representation space. And that turned out to work really well", "tokens": [51552, 370, 300, 291, 393, 652, 21264, 294, 10290, 1901, 13, 400, 300, 3574, 484, 281, 589, 534, 731, 51788], "temperature": 0.0, "avg_logprob": -0.12843858986570125, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006085042841732502}, {"id": 313, "seek": 208808, "start": 2088.08, "end": 2093.6, "text": " for learning image features. And now we're working on getting this to work for video. And", "tokens": [50364, 337, 2539, 3256, 4122, 13, 400, 586, 321, 434, 1364, 322, 1242, 341, 281, 589, 337, 960, 13, 400, 50640], "temperature": 0.0, "avg_logprob": -0.10721265792846679, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.0005881258402951062}, {"id": 314, "seek": 208808, "start": 2093.6, "end": 2100.0, "text": " eventually, we'll be able to use this to learn to learn world models, where you show a piece of", "tokens": [50640, 4728, 11, 321, 603, 312, 1075, 281, 764, 341, 281, 1466, 281, 1466, 1002, 5245, 11, 689, 291, 855, 257, 2522, 295, 50960], "temperature": 0.0, "avg_logprob": -0.10721265792846679, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.0005881258402951062}, {"id": 315, "seek": 208808, "start": 2100.0, "end": 2104.96, "text": " video, and then you say, I'm going to take this action, predict what's going to happen next in the", "tokens": [50960, 960, 11, 293, 550, 291, 584, 11, 286, 478, 516, 281, 747, 341, 3069, 11, 6069, 437, 311, 516, 281, 1051, 958, 294, 264, 51208], "temperature": 0.0, "avg_logprob": -0.10721265792846679, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.0005881258402951062}, {"id": 316, "seek": 208808, "start": 2104.96, "end": 2113.52, "text": " world. And, you know, which is a bit where the Gaia system from Wave is doing at a high level,", "tokens": [51208, 1002, 13, 400, 11, 291, 458, 11, 597, 307, 257, 857, 689, 264, 10384, 654, 1185, 490, 28530, 307, 884, 412, 257, 1090, 1496, 11, 51636], "temperature": 0.0, "avg_logprob": -0.10721265792846679, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.0005881258402951062}, {"id": 317, "seek": 211352, "start": 2113.52, "end": 2117.44, "text": " but we need this at sort of various levels of abstraction, so that we can build,", "tokens": [50364, 457, 321, 643, 341, 412, 1333, 295, 3683, 4358, 295, 37765, 11, 370, 300, 321, 393, 1322, 11, 50560], "temperature": 0.0, "avg_logprob": -0.19353094235272475, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.004675665870308876}, {"id": 318, "seek": 211352, "start": 2119.2, "end": 2124.64, "text": " you know, systems that are more general than autonomous driving. Okay. That's the...", "tokens": [50648, 291, 458, 11, 3652, 300, 366, 544, 2674, 813, 23797, 4840, 13, 1033, 13, 663, 311, 264, 485, 50920], "temperature": 0.0, "avg_logprob": -0.19353094235272475, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.004675665870308876}, {"id": 319, "seek": 211352, "start": 2124.64, "end": 2139.36, "text": " Yeah. And it's my fault, so I won't go over the hour. But is it conceivable that someday there'll be", "tokens": [50920, 865, 13, 400, 309, 311, 452, 7441, 11, 370, 286, 1582, 380, 352, 670, 264, 1773, 13, 583, 307, 309, 10413, 34376, 300, 19412, 456, 603, 312, 51656], "temperature": 0.0, "avg_logprob": -0.19353094235272475, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.004675665870308876}, {"id": 320, "seek": 213936, "start": 2140.2400000000002, "end": 2153.28, "text": " a model that you may be embodied in a robot that is ingesting video from its environment", "tokens": [50408, 257, 2316, 300, 291, 815, 312, 42046, 294, 257, 7881, 300, 307, 3957, 8714, 960, 490, 1080, 2823, 51060], "temperature": 0.0, "avg_logprob": -0.17139008045196533, "compression_ratio": 1.5210084033613445, "no_speech_prob": 0.008702697232365608}, {"id": 321, "seek": 213936, "start": 2153.28, "end": 2160.88, "text": " and learning as it's just continuously learning and getting smarter and smarter and smarter?", "tokens": [51060, 293, 2539, 382, 309, 311, 445, 15684, 2539, 293, 1242, 20294, 293, 20294, 293, 20294, 30, 51440], "temperature": 0.0, "avg_logprob": -0.17139008045196533, "compression_ratio": 1.5210084033613445, "no_speech_prob": 0.008702697232365608}, {"id": 322, "seek": 216088, "start": 2161.6, "end": 2169.28, "text": " Yeah. I mean, that's kind of a bit of a necessity. The reason being that, you know,", "tokens": [50400, 865, 13, 286, 914, 11, 300, 311, 733, 295, 257, 857, 295, 257, 24217, 13, 440, 1778, 885, 300, 11, 291, 458, 11, 50784], "temperature": 0.0, "avg_logprob": -0.08625518397281044, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0017522141570225358}, {"id": 323, "seek": 216088, "start": 2169.28, "end": 2172.56, "text": " even if you train a system to have a world model that can predict what's going to happen next,", "tokens": [50784, 754, 498, 291, 3847, 257, 1185, 281, 362, 257, 1002, 2316, 300, 393, 6069, 437, 311, 516, 281, 1051, 958, 11, 50948], "temperature": 0.0, "avg_logprob": -0.08625518397281044, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0017522141570225358}, {"id": 324, "seek": 216088, "start": 2173.44, "end": 2177.84, "text": " the world is really complicated. And there's probably all kinds of situations that you,", "tokens": [50992, 264, 1002, 307, 534, 6179, 13, 400, 456, 311, 1391, 439, 3685, 295, 6851, 300, 291, 11, 51212], "temperature": 0.0, "avg_logprob": -0.08625518397281044, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0017522141570225358}, {"id": 325, "seek": 216088, "start": 2177.84, "end": 2183.28, "text": " you know, the system hasn't been trained on and need to, you know, fine tune itself as it goes.", "tokens": [51212, 291, 458, 11, 264, 1185, 6132, 380, 668, 8895, 322, 293, 643, 281, 11, 291, 458, 11, 2489, 10864, 2564, 382, 309, 1709, 13, 51484], "temperature": 0.0, "avg_logprob": -0.08625518397281044, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0017522141570225358}, {"id": 326, "seek": 218328, "start": 2184.1600000000003, "end": 2193.6800000000003, "text": " So, you know, animals and humans do this early in life by playing. So play is a way of", "tokens": [50408, 407, 11, 291, 458, 11, 4882, 293, 6255, 360, 341, 2440, 294, 993, 538, 2433, 13, 407, 862, 307, 257, 636, 295, 50884], "temperature": 0.0, "avg_logprob": -0.1595023579067654, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.004121765494346619}, {"id": 327, "seek": 218328, "start": 2194.7200000000003, "end": 2200.0, "text": " learning your world model in situations that basically you won't hurt you.", "tokens": [50936, 2539, 428, 1002, 2316, 294, 6851, 300, 1936, 291, 1582, 380, 4607, 291, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1595023579067654, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.004121765494346619}, {"id": 328, "seek": 218328, "start": 2201.92, "end": 2207.52, "text": " And, but then during life, of course, you know, when we don't drive, there's all kinds of these", "tokens": [51296, 400, 11, 457, 550, 1830, 993, 11, 295, 1164, 11, 291, 458, 11, 562, 321, 500, 380, 3332, 11, 456, 311, 439, 3685, 295, 613, 51576], "temperature": 0.0, "avg_logprob": -0.1595023579067654, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.004121765494346619}, {"id": 329, "seek": 218328, "start": 2207.52, "end": 2213.0400000000004, "text": " mistakes that we do initially that we don't do after having some experience. And that's because", "tokens": [51576, 8038, 300, 321, 360, 9105, 300, 321, 500, 380, 360, 934, 1419, 512, 1752, 13, 400, 300, 311, 570, 51852], "temperature": 0.0, "avg_logprob": -0.1595023579067654, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.004121765494346619}, {"id": 330, "seek": 221304, "start": 2213.04, "end": 2219.2799999999997, "text": " we're fine tuning our world model to some extent. We're learning a new task. We're basically just", "tokens": [50364, 321, 434, 2489, 15164, 527, 1002, 2316, 281, 512, 8396, 13, 492, 434, 2539, 257, 777, 5633, 13, 492, 434, 1936, 445, 50676], "temperature": 0.0, "avg_logprob": -0.2093168207117029, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.0021432957146316767}, {"id": 331, "seek": 221304, "start": 2219.2799999999997, "end": 2225.68, "text": " learning a new version of our world model. Right. So, so yeah, I mean, this type of continuous,", "tokens": [50676, 2539, 257, 777, 3037, 295, 527, 1002, 2316, 13, 1779, 13, 407, 11, 370, 1338, 11, 286, 914, 11, 341, 2010, 295, 10957, 11, 50996], "temperature": 0.0, "avg_logprob": -0.2093168207117029, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.0021432957146316767}, {"id": 332, "seek": 221304, "start": 2225.68, "end": 2230.96, "text": " continual learning is going to have to be present. But the overall power and the", "tokens": [50996, 1421, 901, 2539, 307, 516, 281, 362, 281, 312, 1974, 13, 583, 264, 4787, 1347, 293, 264, 51260], "temperature": 0.0, "avg_logprob": -0.2093168207117029, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.0021432957146316767}, {"id": 333, "seek": 221304, "start": 2230.96, "end": 2235.52, "text": " intelligence of the system will be limited by, you know, how much a co-governor on that is using", "tokens": [51260, 7599, 295, 264, 1185, 486, 312, 5567, 538, 11, 291, 458, 11, 577, 709, 257, 598, 12, 35329, 284, 322, 300, 307, 1228, 51488], "temperature": 0.0, "avg_logprob": -0.2093168207117029, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.0021432957146316767}, {"id": 334, "seek": 221304, "start": 2235.52, "end": 2239.2799999999997, "text": " and various other constraints, you know, computational constraints, basically.", "tokens": [51488, 293, 3683, 661, 18491, 11, 291, 458, 11, 28270, 18491, 11, 1936, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2093168207117029, "compression_ratio": 1.7509727626459144, "no_speech_prob": 0.0021432957146316767}, {"id": 335, "seek": 223928, "start": 2239.6000000000004, "end": 2246.0, "text": " And, you know, you're still young. And, and this not sure about that.", "tokens": [50380, 400, 11, 291, 458, 11, 291, 434, 920, 2037, 13, 400, 11, 293, 341, 406, 988, 466, 300, 13, 50700], "temperature": 0.0, "avg_logprob": -0.30070670958488216, "compression_ratio": 1.4105960264900663, "no_speech_prob": 0.004067456349730492}, {"id": 336, "seek": 223928, "start": 2246.6400000000003, "end": 2250.4, "text": " Well, you're younger than Jeff. Let me put it that way.", "tokens": [50732, 1042, 11, 291, 434, 7037, 813, 7506, 13, 961, 385, 829, 309, 300, 636, 13, 50920], "temperature": 0.0, "avg_logprob": -0.30070670958488216, "compression_ratio": 1.4105960264900663, "no_speech_prob": 0.004067456349730492}, {"id": 337, "seek": 223928, "start": 2255.0400000000004, "end": 2262.0800000000004, "text": " But this, the progress you've made on world models is, is fairly rapid from my point of", "tokens": [51152, 583, 341, 11, 264, 4205, 291, 600, 1027, 322, 1002, 5245, 307, 11, 307, 6457, 7558, 490, 452, 935, 295, 51504], "temperature": 0.0, "avg_logprob": -0.30070670958488216, "compression_ratio": 1.4105960264900663, "no_speech_prob": 0.004067456349730492}, {"id": 338, "seek": 226208, "start": 2262.16, "end": 2271.36, "text": " view, watching it. Are you, are you hopeful that within your career, you'll have", "tokens": [50368, 1910, 11, 1976, 309, 13, 2014, 291, 11, 366, 291, 20531, 300, 1951, 428, 3988, 11, 291, 603, 362, 50828], "temperature": 0.0, "avg_logprob": -0.14778093431816727, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.4144802987575531}, {"id": 339, "seek": 226208, "start": 2272.72, "end": 2279.04, "text": " embodied robots that are, are building world models through their interaction in reality,", "tokens": [50896, 42046, 14733, 300, 366, 11, 366, 2390, 1002, 5245, 807, 641, 9285, 294, 4103, 11, 51212], "temperature": 0.0, "avg_logprob": -0.14778093431816727, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.4144802987575531}, {"id": 340, "seek": 226208, "start": 2279.04, "end": 2283.12, "text": " and, and then being able to, well, I guess the other question on world models,", "tokens": [51212, 293, 11, 293, 550, 885, 1075, 281, 11, 731, 11, 286, 2041, 264, 661, 1168, 322, 1002, 5245, 11, 51416], "temperature": 0.0, "avg_logprob": -0.14778093431816727, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.4144802987575531}, {"id": 341, "seek": 228312, "start": 2284.08, "end": 2293.44, "text": " do you then combine it with a language model to do reasoning or, or is the world model able to,", "tokens": [50412, 360, 291, 550, 10432, 309, 365, 257, 2856, 2316, 281, 360, 21577, 420, 11, 420, 307, 264, 1002, 2316, 1075, 281, 11, 50880], "temperature": 0.0, "avg_logprob": -0.10708817313699161, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.04600968956947327}, {"id": 342, "seek": 228312, "start": 2293.44, "end": 2298.64, "text": " to do reasoning on its own? But are you hopeful that in your career, you'll, you'll get to the", "tokens": [50880, 281, 360, 21577, 322, 1080, 1065, 30, 583, 366, 291, 20531, 300, 294, 428, 3988, 11, 291, 603, 11, 291, 603, 483, 281, 264, 51140], "temperature": 0.0, "avg_logprob": -0.10708817313699161, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.04600968956947327}, {"id": 343, "seek": 228312, "start": 2298.64, "end": 2305.12, "text": " point where you'll have this continuous learning in a world model? Yeah, I sure hope so. I might have", "tokens": [51140, 935, 689, 291, 603, 362, 341, 10957, 2539, 294, 257, 1002, 2316, 30, 865, 11, 286, 988, 1454, 370, 13, 286, 1062, 362, 51464], "temperature": 0.0, "avg_logprob": -0.10708817313699161, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.04600968956947327}, {"id": 344, "seek": 228312, "start": 2305.12, "end": 2311.44, "text": " another, you know, 10, 10 useful years or something like this in research before my brain, you know,", "tokens": [51464, 1071, 11, 291, 458, 11, 1266, 11, 1266, 4420, 924, 420, 746, 411, 341, 294, 2132, 949, 452, 3567, 11, 291, 458, 11, 51780], "temperature": 0.0, "avg_logprob": -0.10708817313699161, "compression_ratio": 1.6866952789699572, "no_speech_prob": 0.04600968956947327}, {"id": 345, "seek": 231144, "start": 2311.44, "end": 2318.56, "text": " turns into dish and male sauce, but, or something like that, you know, 15 years if I'm lucky.", "tokens": [50364, 4523, 666, 5025, 293, 7133, 4880, 11, 457, 11, 420, 746, 411, 300, 11, 291, 458, 11, 2119, 924, 498, 286, 478, 6356, 13, 50720], "temperature": 0.0, "avg_logprob": -0.15253750483194986, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0014531607739627361}, {"id": 346, "seek": 231144, "start": 2320.0, "end": 2326.16, "text": " So, or perhaps less. But yeah, I hope that there's going to be breakthroughs in that direction", "tokens": [50792, 407, 11, 420, 4317, 1570, 13, 583, 1338, 11, 286, 1454, 300, 456, 311, 516, 281, 312, 22397, 82, 294, 300, 3513, 51100], "temperature": 0.0, "avg_logprob": -0.15253750483194986, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0014531607739627361}, {"id": 347, "seek": 231144, "start": 2326.16, "end": 2333.6, "text": " during that time. Now, whether that will result in the kind of artifact that you're describing,", "tokens": [51100, 1830, 300, 565, 13, 823, 11, 1968, 300, 486, 1874, 294, 264, 733, 295, 34806, 300, 291, 434, 16141, 11, 51472], "temperature": 0.0, "avg_logprob": -0.15253750483194986, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0014531607739627361}, {"id": 348, "seek": 231144, "start": 2333.6, "end": 2337.76, "text": " you know, robots that can, like, you know, domestic robots, for example, or,", "tokens": [51472, 291, 458, 11, 14733, 300, 393, 11, 411, 11, 291, 458, 11, 10939, 14733, 11, 337, 1365, 11, 420, 11, 51680], "temperature": 0.0, "avg_logprob": -0.15253750483194986, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0014531607739627361}, {"id": 349, "seek": 233776, "start": 2337.76, "end": 2341.5200000000004, "text": " or sort of in cars that are, they can run fairly quickly by themselves.", "tokens": [50364, 420, 1333, 295, 294, 5163, 300, 366, 11, 436, 393, 1190, 6457, 2661, 538, 2969, 13, 50552], "temperature": 0.0, "avg_logprob": -0.14538466624724558, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.0009689383441582322}, {"id": 350, "seek": 233776, "start": 2342.88, "end": 2349.84, "text": " I don't know, because there might be all kinds of obstacles that we have not envisaged that may", "tokens": [50620, 286, 500, 380, 458, 11, 570, 456, 1062, 312, 439, 3685, 295, 17735, 300, 321, 362, 406, 2267, 271, 2980, 300, 815, 50968], "temperature": 0.0, "avg_logprob": -0.14538466624724558, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.0009689383441582322}, {"id": 351, "seek": 233776, "start": 2350.48, "end": 2357.44, "text": " appear on the way. You know, that's, it's a constant in the history of AI that you have some new idea", "tokens": [51000, 4204, 322, 264, 636, 13, 509, 458, 11, 300, 311, 11, 309, 311, 257, 5754, 294, 264, 2503, 295, 7318, 300, 291, 362, 512, 777, 1558, 51348], "temperature": 0.0, "avg_logprob": -0.14538466624724558, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.0009689383441582322}, {"id": 352, "seek": 233776, "start": 2358.1600000000003, "end": 2361.44, "text": " and a breakthrough, and you think that's going to solve all the world's problems.", "tokens": [51384, 293, 257, 22397, 11, 293, 291, 519, 300, 311, 516, 281, 5039, 439, 264, 1002, 311, 2740, 13, 51548], "temperature": 0.0, "avg_logprob": -0.14538466624724558, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.0009689383441582322}, {"id": 353, "seek": 233776, "start": 2362.2400000000002, "end": 2367.2000000000003, "text": " And then you're going to hit limitation, and you have to go beyond that limitation. So it's like,", "tokens": [51588, 400, 550, 291, 434, 516, 281, 2045, 27432, 11, 293, 291, 362, 281, 352, 4399, 300, 27432, 13, 407, 309, 311, 411, 11, 51836], "temperature": 0.0, "avg_logprob": -0.14538466624724558, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.0009689383441582322}, {"id": 354, "seek": 236720, "start": 2367.2799999999997, "end": 2371.7599999999998, "text": " you know, you're climbing a mountain, you find a way to climb the mountain that you're seeing.", "tokens": [50368, 291, 458, 11, 291, 434, 14780, 257, 6937, 11, 291, 915, 257, 636, 281, 10724, 264, 6937, 300, 291, 434, 2577, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10285045686832145, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0008958049584180117}, {"id": 355, "seek": 236720, "start": 2372.56, "end": 2378.48, "text": " And you know that once you get to the top, you will have the problem solved because now it's,", "tokens": [50632, 400, 291, 458, 300, 1564, 291, 483, 281, 264, 1192, 11, 291, 486, 362, 264, 1154, 13041, 570, 586, 309, 311, 11, 50928], "temperature": 0.0, "avg_logprob": -0.10285045686832145, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0008958049584180117}, {"id": 356, "seek": 236720, "start": 2378.48, "end": 2383.7599999999998, "text": " you know, the gentle slope down. And once you get to the top, you realize that there is", "tokens": [50928, 291, 458, 11, 264, 6424, 13525, 760, 13, 400, 1564, 291, 483, 281, 264, 1192, 11, 291, 4325, 300, 456, 307, 51192], "temperature": 0.0, "avg_logprob": -0.10285045686832145, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0008958049584180117}, {"id": 357, "seek": 236720, "start": 2383.7599999999998, "end": 2390.08, "text": " another mountain behind it that you hadn't seen. So that's, that's, that's been the history of AI,", "tokens": [51192, 1071, 6937, 2261, 309, 300, 291, 8782, 380, 1612, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 668, 264, 2503, 295, 7318, 11, 51508], "temperature": 0.0, "avg_logprob": -0.10285045686832145, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0008958049584180117}, {"id": 358, "seek": 236720, "start": 2390.08, "end": 2395.7599999999998, "text": " right, where people have come up with sort of new concepts, new ideas, new way to approach", "tokens": [51508, 558, 11, 689, 561, 362, 808, 493, 365, 1333, 295, 777, 10392, 11, 777, 3487, 11, 777, 636, 281, 3109, 51792], "temperature": 0.0, "avg_logprob": -0.10285045686832145, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0008958049584180117}, {"id": 359, "seek": 239720, "start": 2397.68, "end": 2404.64, "text": " AI reasoning, whatever, perception, and then realize that their idea basically was very limited.", "tokens": [50388, 7318, 21577, 11, 2035, 11, 12860, 11, 293, 550, 4325, 300, 641, 1558, 1936, 390, 588, 5567, 13, 50736], "temperature": 0.0, "avg_logprob": -0.18477324644724527, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0006357196834869683}, {"id": 360, "seek": 239720, "start": 2406.3999999999996, "end": 2414.96, "text": " And so, so, you know, this, inevitably, we're trying to figure out what's the next", "tokens": [50824, 400, 370, 11, 370, 11, 291, 458, 11, 341, 11, 28171, 11, 321, 434, 1382, 281, 2573, 484, 437, 311, 264, 958, 51252], "temperature": 0.0, "avg_logprob": -0.18477324644724527, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0006357196834869683}, {"id": 361, "seek": 239720, "start": 2416.16, "end": 2420.96, "text": " revolution in AI. That's what I'm trying to figure out. So, you know, learning how the world works", "tokens": [51312, 8894, 294, 7318, 13, 663, 311, 437, 286, 478, 1382, 281, 2573, 484, 13, 407, 11, 291, 458, 11, 2539, 577, 264, 1002, 1985, 51552], "temperature": 0.0, "avg_logprob": -0.18477324644724527, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0006357196834869683}, {"id": 362, "seek": 242096, "start": 2420.96, "end": 2425.2, "text": " from video, having systems that have world model allows systems to reason and plan.", "tokens": [50364, 490, 960, 11, 1419, 3652, 300, 362, 1002, 2316, 4045, 3652, 281, 1778, 293, 1393, 13, 50576], "temperature": 0.0, "avg_logprob": -0.13053140295557228, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.02327415533363819}, {"id": 363, "seek": 242096, "start": 2427.52, "end": 2434.96, "text": " And there's something I want to be very clear about, which is an answer to your question,", "tokens": [50692, 400, 456, 311, 746, 286, 528, 281, 312, 588, 1850, 466, 11, 597, 307, 364, 1867, 281, 428, 1168, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13053140295557228, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.02327415533363819}, {"id": 364, "seek": 242096, "start": 2436.4, "end": 2441.84, "text": " which is that you can have systems that reason and plan without manipulating language. Animals are", "tokens": [51136, 597, 307, 300, 291, 393, 362, 3652, 300, 1778, 293, 1393, 1553, 40805, 2856, 13, 47164, 366, 51408], "temperature": 0.0, "avg_logprob": -0.13053140295557228, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.02327415533363819}, {"id": 365, "seek": 242096, "start": 2441.84, "end": 2449.28, "text": " capable of amazing feats of planning and also to some extent reasoning. They don't have language,", "tokens": [51408, 8189, 295, 2243, 579, 1720, 295, 5038, 293, 611, 281, 512, 8396, 21577, 13, 814, 500, 380, 362, 2856, 11, 51780], "temperature": 0.0, "avg_logprob": -0.13053140295557228, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.02327415533363819}, {"id": 366, "seek": 244928, "start": 2449.36, "end": 2456.96, "text": " at least most of them don't. And so, many of them don't have culture because they are mostly", "tokens": [50368, 412, 1935, 881, 295, 552, 500, 380, 13, 400, 370, 11, 867, 295, 552, 500, 380, 362, 3713, 570, 436, 366, 5240, 50748], "temperature": 0.0, "avg_logprob": -0.10412659443600077, "compression_ratio": 1.625, "no_speech_prob": 0.0006548983510583639}, {"id": 367, "seek": 244928, "start": 2456.96, "end": 2465.52, "text": " solitary animals. So, you know, it's only the animals that have some level of culture. So,", "tokens": [50748, 44155, 4882, 13, 407, 11, 291, 458, 11, 309, 311, 787, 264, 4882, 300, 362, 512, 1496, 295, 3713, 13, 407, 11, 51176], "temperature": 0.0, "avg_logprob": -0.10412659443600077, "compression_ratio": 1.625, "no_speech_prob": 0.0006548983510583639}, {"id": 368, "seek": 244928, "start": 2468.0, "end": 2474.48, "text": " so the idea that a system can plan and reason is not connected with the idea that you can", "tokens": [51300, 370, 264, 1558, 300, 257, 1185, 393, 1393, 293, 1778, 307, 406, 4582, 365, 264, 1558, 300, 291, 393, 51624], "temperature": 0.0, "avg_logprob": -0.10412659443600077, "compression_ratio": 1.625, "no_speech_prob": 0.0006548983510583639}, {"id": 369, "seek": 247448, "start": 2474.48, "end": 2479.84, "text": " manipulate language. Those are two different things. It needs to be able to manipulate abstract", "tokens": [50364, 20459, 2856, 13, 3950, 366, 732, 819, 721, 13, 467, 2203, 281, 312, 1075, 281, 20459, 12649, 50632], "temperature": 0.0, "avg_logprob": -0.14916040420532226, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.011828065849840641}, {"id": 370, "seek": 247448, "start": 2480.64, "end": 2485.84, "text": " notions. But those notions do not necessarily correspond to linguistic entities like words", "tokens": [50672, 35799, 13, 583, 729, 35799, 360, 406, 4725, 6805, 281, 43002, 16667, 411, 2283, 50932], "temperature": 0.0, "avg_logprob": -0.14916040420532226, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.011828065849840641}, {"id": 371, "seek": 247448, "start": 2485.84, "end": 2491.04, "text": " or things like that. We can have mental images if you want to things. Like you do", "tokens": [50932, 420, 721, 411, 300, 13, 492, 393, 362, 4973, 5267, 498, 291, 528, 281, 721, 13, 1743, 291, 360, 51192], "temperature": 0.0, "avg_logprob": -0.14916040420532226, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.011828065849840641}, {"id": 372, "seek": 247448, "start": 2492.08, "end": 2496.2400000000002, "text": " ask a physicist or a mathematician, you know, how they reason is very much in terms of sort of", "tokens": [51244, 1029, 257, 42466, 420, 257, 48281, 11, 291, 458, 11, 577, 436, 1778, 307, 588, 709, 294, 2115, 295, 1333, 295, 51452], "temperature": 0.0, "avg_logprob": -0.14916040420532226, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.011828065849840641}, {"id": 373, "seek": 247448, "start": 2496.2400000000002, "end": 2499.92, "text": " mental models. I have nothing to do with language. Then you can turn things into", "tokens": [51452, 4973, 5245, 13, 286, 362, 1825, 281, 360, 365, 2856, 13, 1396, 291, 393, 1261, 721, 666, 51636], "temperature": 0.0, "avg_logprob": -0.14916040420532226, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.011828065849840641}, {"id": 374, "seek": 249992, "start": 2500.2400000000002, "end": 2504.88, "text": " language. But that's a different story. That's the second step. So,", "tokens": [50380, 2856, 13, 583, 300, 311, 257, 819, 1657, 13, 663, 311, 264, 1150, 1823, 13, 407, 11, 50612], "temperature": 0.0, "avg_logprob": -0.19287991305010035, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.0025074228178709745}, {"id": 375, "seek": 249992, "start": 2508.64, "end": 2512.96, "text": " so, you know, we're going to have to figure out how to do this reasoning,", "tokens": [50800, 370, 11, 291, 458, 11, 321, 434, 516, 281, 362, 281, 2573, 484, 577, 281, 360, 341, 21577, 11, 51016], "temperature": 0.0, "avg_logprob": -0.19287991305010035, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.0025074228178709745}, {"id": 376, "seek": 249992, "start": 2512.96, "end": 2519.76, "text": " hierarchical planning in machines, reproduce this first. And then, of course, you know,", "tokens": [51016, 35250, 804, 5038, 294, 8379, 11, 29501, 341, 700, 13, 400, 550, 11, 295, 1164, 11, 291, 458, 11, 51356], "temperature": 0.0, "avg_logprob": -0.19287991305010035, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.0025074228178709745}, {"id": 377, "seek": 249992, "start": 2519.76, "end": 2524.0, "text": " sticking language on top of it will help. Like, we'll make those systems smarter and be able,", "tokens": [51356, 13465, 2856, 322, 1192, 295, 309, 486, 854, 13, 1743, 11, 321, 603, 652, 729, 3652, 20294, 293, 312, 1075, 11, 51568], "temperature": 0.0, "avg_logprob": -0.19287991305010035, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.0025074228178709745}, {"id": 378, "seek": 249992, "start": 2524.0, "end": 2527.6, "text": " you know, we will allow us to communicate with them and teach them things. And they're going to", "tokens": [51568, 291, 458, 11, 321, 486, 2089, 505, 281, 7890, 365, 552, 293, 2924, 552, 721, 13, 400, 436, 434, 516, 281, 51748], "temperature": 0.0, "avg_logprob": -0.19287991305010035, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.0025074228178709745}, {"id": 379, "seek": 252760, "start": 2527.6, "end": 2532.56, "text": " be able to teach us things and stuff like that. But this is a different question, really.", "tokens": [50364, 312, 1075, 281, 2924, 505, 721, 293, 1507, 411, 300, 13, 583, 341, 307, 257, 819, 1168, 11, 534, 13, 50612], "temperature": 0.0, "avg_logprob": -0.10040693604544307, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0043202051892876625}, {"id": 380, "seek": 252760, "start": 2533.12, "end": 2538.56, "text": " The question of how we organize AI research going forward, which is somewhat determined by how", "tokens": [50640, 440, 1168, 295, 577, 321, 13859, 7318, 2132, 516, 2128, 11, 597, 307, 8344, 9540, 538, 577, 50912], "temperature": 0.0, "avg_logprob": -0.10040693604544307, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0043202051892876625}, {"id": 381, "seek": 252760, "start": 2538.56, "end": 2545.44, "text": " afraid people are of the consequences of AI. So, if you have a rather positive view of the impact", "tokens": [50912, 4638, 561, 366, 295, 264, 10098, 295, 7318, 13, 407, 11, 498, 291, 362, 257, 2831, 3353, 1910, 295, 264, 2712, 51256], "temperature": 0.0, "avg_logprob": -0.10040693604544307, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0043202051892876625}, {"id": 382, "seek": 252760, "start": 2545.44, "end": 2550.16, "text": " of AI on society, and you trust humanity and society and democracies to use it in good ways,", "tokens": [51256, 295, 7318, 322, 4086, 11, 293, 291, 3361, 10243, 293, 4086, 293, 6366, 20330, 281, 764, 309, 294, 665, 2098, 11, 51492], "temperature": 0.0, "avg_logprob": -0.10040693604544307, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.0043202051892876625}, {"id": 383, "seek": 255016, "start": 2550.96, "end": 2558.08, "text": " then the best way to make progress is to open research. And for the people who are", "tokens": [50404, 550, 264, 1151, 636, 281, 652, 4205, 307, 281, 1269, 2132, 13, 400, 337, 264, 561, 567, 366, 50760], "temperature": 0.0, "avg_logprob": -0.09974143443963467, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.007927315309643745}, {"id": 384, "seek": 255016, "start": 2558.08, "end": 2562.3199999999997, "text": " afraid of the consequences, whether they are societal or geopolitical,", "tokens": [50760, 4638, 295, 264, 10098, 11, 1968, 436, 366, 33472, 420, 46615, 804, 11, 50972], "temperature": 0.0, "avg_logprob": -0.09974143443963467, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.007927315309643745}, {"id": 385, "seek": 255016, "start": 2564.0, "end": 2570.24, "text": " they're putting pressure on governments around the world to regulate AI in ways that basically limit", "tokens": [51056, 436, 434, 3372, 3321, 322, 11280, 926, 264, 1002, 281, 24475, 7318, 294, 2098, 300, 1936, 4948, 51368], "temperature": 0.0, "avg_logprob": -0.09974143443963467, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.007927315309643745}, {"id": 386, "seek": 255016, "start": 2571.92, "end": 2577.6, "text": " access, particularly of open source code and things like that. And it's a big debate at the", "tokens": [51452, 2105, 11, 4098, 295, 1269, 4009, 3089, 293, 721, 411, 300, 13, 400, 309, 311, 257, 955, 7958, 412, 264, 51736], "temperature": 0.0, "avg_logprob": -0.09974143443963467, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.007927315309643745}, {"id": 387, "seek": 257760, "start": 2577.6, "end": 2582.3199999999997, "text": " moment. I'm very much on the side. So, he's met up very much on the side of open research.", "tokens": [50364, 1623, 13, 286, 478, 588, 709, 322, 264, 1252, 13, 407, 11, 415, 311, 1131, 493, 588, 709, 322, 264, 1252, 295, 1269, 2132, 13, 50600], "temperature": 0.0, "avg_logprob": -0.12794364324890742, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.02185829170048237}, {"id": 388, "seek": 257760, "start": 2582.96, "end": 2588.56, "text": " Yeah, actually, that was something I was going to ask you. And now that you've brought it up.", "tokens": [50632, 865, 11, 767, 11, 300, 390, 746, 286, 390, 516, 281, 1029, 291, 13, 400, 586, 300, 291, 600, 3038, 309, 493, 13, 50912], "temperature": 0.0, "avg_logprob": -0.12794364324890742, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.02185829170048237}, {"id": 389, "seek": 257760, "start": 2589.44, "end": 2597.12, "text": " Because there, I've been talking to people about this. And there is a view that aside from the", "tokens": [50956, 1436, 456, 11, 286, 600, 668, 1417, 281, 561, 466, 341, 13, 400, 456, 307, 257, 1910, 300, 7359, 490, 264, 51340], "temperature": 0.0, "avg_logprob": -0.12794364324890742, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.02185829170048237}, {"id": 390, "seek": 257760, "start": 2597.12, "end": 2604.16, "text": " risks of open source, you know, again, Jeff Hinton saying, you know, would you open source", "tokens": [51340, 10888, 295, 1269, 4009, 11, 291, 458, 11, 797, 11, 7506, 389, 12442, 1566, 11, 291, 458, 11, 576, 291, 1269, 4009, 51692], "temperature": 0.0, "avg_logprob": -0.12794364324890742, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.02185829170048237}, {"id": 391, "seek": 260416, "start": 2604.16, "end": 2613.8399999999997, "text": " thermonuclear weapons? Aside from that is the question of as to whether open source can marshal", "tokens": [50364, 8810, 266, 30335, 7278, 30, 33726, 490, 300, 307, 264, 1168, 295, 382, 281, 1968, 1269, 4009, 393, 30517, 4947, 50848], "temperature": 0.0, "avg_logprob": -0.1209917459331575, "compression_ratio": 1.6331360946745561, "no_speech_prob": 0.006001239642500877}, {"id": 392, "seek": 260416, "start": 2613.8399999999997, "end": 2625.12, "text": " the resources to compete with proprietary models. And because of the tremendous resources required", "tokens": [50848, 264, 3593, 281, 11831, 365, 38992, 5245, 13, 400, 570, 295, 264, 10048, 3593, 4739, 51412], "temperature": 0.0, "avg_logprob": -0.1209917459331575, "compression_ratio": 1.6331360946745561, "no_speech_prob": 0.006001239642500877}, {"id": 393, "seek": 260416, "start": 2625.12, "end": 2631.3599999999997, "text": " for when you're scaling these models. And there's a question as to whether or not", "tokens": [51412, 337, 562, 291, 434, 21589, 613, 5245, 13, 400, 456, 311, 257, 1168, 382, 281, 1968, 420, 406, 51724], "temperature": 0.0, "avg_logprob": -0.1209917459331575, "compression_ratio": 1.6331360946745561, "no_speech_prob": 0.006001239642500877}, {"id": 394, "seek": 263136, "start": 2631.36, "end": 2640.1600000000003, "text": " Meta will continue to open source future versions of Lama or not continue to open source, but whether", "tokens": [50364, 6377, 64, 486, 2354, 281, 1269, 4009, 2027, 9606, 295, 441, 2404, 420, 406, 2354, 281, 1269, 4009, 11, 457, 1968, 50804], "temperature": 0.0, "avg_logprob": -0.15809742061571144, "compression_ratio": 1.8578947368421053, "no_speech_prob": 0.007006736006587744}, {"id": 395, "seek": 263136, "start": 2640.1600000000003, "end": 2648.1600000000003, "text": " it'll continue to invest the resources needed to push the open source models.", "tokens": [50804, 309, 603, 2354, 281, 1963, 264, 3593, 2978, 281, 2944, 264, 1269, 4009, 5245, 13, 51204], "temperature": 0.0, "avg_logprob": -0.15809742061571144, "compression_ratio": 1.8578947368421053, "no_speech_prob": 0.007006736006587744}, {"id": 396, "seek": 263136, "start": 2649.1200000000003, "end": 2653.84, "text": " So what do you think about that? Okay, there's a lot to say about this. Okay, so first thing is,", "tokens": [51252, 407, 437, 360, 291, 519, 466, 300, 30, 1033, 11, 456, 311, 257, 688, 281, 584, 466, 341, 13, 1033, 11, 370, 700, 551, 307, 11, 51488], "temperature": 0.0, "avg_logprob": -0.15809742061571144, "compression_ratio": 1.8578947368421053, "no_speech_prob": 0.007006736006587744}, {"id": 397, "seek": 263136, "start": 2654.7200000000003, "end": 2658.7200000000003, "text": " there's no question that Meta will continue to invest the resources to build", "tokens": [51532, 456, 311, 572, 1168, 300, 6377, 64, 486, 2354, 281, 1963, 264, 3593, 281, 1322, 51732], "temperature": 0.0, "avg_logprob": -0.15809742061571144, "compression_ratio": 1.8578947368421053, "no_speech_prob": 0.007006736006587744}, {"id": 398, "seek": 265872, "start": 2659.52, "end": 2664.7999999999997, "text": " better and better AI systems, because it needs it for its own products. So the resources will", "tokens": [50404, 1101, 293, 1101, 7318, 3652, 11, 570, 309, 2203, 309, 337, 1080, 1065, 3383, 13, 407, 264, 3593, 486, 50668], "temperature": 0.0, "avg_logprob": -0.07745315150210733, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0011690218234434724}, {"id": 399, "seek": 265872, "start": 2664.7999999999997, "end": 2671.12, "text": " be invested. Now, the next question is, do you, you know, will we continue to open source the", "tokens": [50668, 312, 13104, 13, 823, 11, 264, 958, 1168, 307, 11, 360, 291, 11, 291, 458, 11, 486, 321, 2354, 281, 1269, 4009, 264, 50984], "temperature": 0.0, "avg_logprob": -0.07745315150210733, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0011690218234434724}, {"id": 400, "seek": 265872, "start": 2671.12, "end": 2677.7599999999998, "text": " base models? And the answer is, you know, probably yes, because that creates an ecosystem on top of", "tokens": [50984, 3096, 5245, 30, 400, 264, 1867, 307, 11, 291, 458, 11, 1391, 2086, 11, 570, 300, 7829, 364, 11311, 322, 1192, 295, 51316], "temperature": 0.0, "avg_logprob": -0.07745315150210733, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0011690218234434724}, {"id": 401, "seek": 265872, "start": 2677.7599999999998, "end": 2683.12, "text": " which an entire industry can be built. And there is no point, you know, having 50 different companies", "tokens": [51316, 597, 364, 2302, 3518, 393, 312, 3094, 13, 400, 456, 307, 572, 935, 11, 291, 458, 11, 1419, 2625, 819, 3431, 51584], "temperature": 0.0, "avg_logprob": -0.07745315150210733, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0011690218234434724}, {"id": 402, "seek": 268312, "start": 2683.44, "end": 2691.8399999999997, "text": " building proprietary close systems when you can have, you know, one good base open source base", "tokens": [50380, 2390, 38992, 1998, 3652, 562, 291, 393, 362, 11, 291, 458, 11, 472, 665, 3096, 1269, 4009, 3096, 50800], "temperature": 0.0, "avg_logprob": -0.12848427636282786, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.001366325537674129}, {"id": 403, "seek": 268312, "start": 2691.8399999999997, "end": 2699.68, "text": " model that everybody can use. It's wasteful. And it's not a good idea. And another reason for", "tokens": [50800, 2316, 300, 2201, 393, 764, 13, 467, 311, 5964, 906, 13, 400, 309, 311, 406, 257, 665, 1558, 13, 400, 1071, 1778, 337, 51192], "temperature": 0.0, "avg_logprob": -0.12848427636282786, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.001366325537674129}, {"id": 404, "seek": 268312, "start": 2699.68, "end": 2708.16, "text": " having open source models is that it, it nobody has no entity as powerful as it thinks it is,", "tokens": [51192, 1419, 1269, 4009, 5245, 307, 300, 309, 11, 309, 5079, 575, 572, 13977, 382, 4005, 382, 309, 7309, 309, 307, 11, 51616], "temperature": 0.0, "avg_logprob": -0.12848427636282786, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.001366325537674129}, {"id": 405, "seek": 270816, "start": 2708.24, "end": 2714.08, "text": " as a monopoly on good ideas. And so if you want people who can have good new innovative ideas", "tokens": [50368, 382, 257, 37061, 322, 665, 3487, 13, 400, 370, 498, 291, 528, 561, 567, 393, 362, 665, 777, 12999, 3487, 50660], "temperature": 0.0, "avg_logprob": -0.1115565077166691, "compression_ratio": 1.904564315352697, "no_speech_prob": 0.008977342396974564}, {"id": 406, "seek": 270816, "start": 2714.08, "end": 2718.96, "text": " to contribute, you need an open source platform. If you want the academic world to contribute,", "tokens": [50660, 281, 10586, 11, 291, 643, 364, 1269, 4009, 3663, 13, 759, 291, 528, 264, 7778, 1002, 281, 10586, 11, 50904], "temperature": 0.0, "avg_logprob": -0.1115565077166691, "compression_ratio": 1.904564315352697, "no_speech_prob": 0.008977342396974564}, {"id": 407, "seek": 270816, "start": 2718.96, "end": 2722.56, "text": " you need open source platforms. If you want the startup world to be able to build", "tokens": [50904, 291, 643, 1269, 4009, 9473, 13, 759, 291, 528, 264, 18578, 1002, 281, 312, 1075, 281, 1322, 51084], "temperature": 0.0, "avg_logprob": -0.1115565077166691, "compression_ratio": 1.904564315352697, "no_speech_prob": 0.008977342396974564}, {"id": 408, "seek": 270816, "start": 2722.56, "end": 2727.68, "text": " customized products, you need open source base models, because they don't have the resources to", "tokens": [51084, 30581, 3383, 11, 291, 643, 1269, 4009, 3096, 5245, 11, 570, 436, 500, 380, 362, 264, 3593, 281, 51340], "temperature": 0.0, "avg_logprob": -0.1115565077166691, "compression_ratio": 1.904564315352697, "no_speech_prob": 0.008977342396974564}, {"id": 409, "seek": 270816, "start": 2727.68, "end": 2734.48, "text": " build to train large models, right? Okay, and then there is the history that shows that for,", "tokens": [51340, 1322, 281, 3847, 2416, 5245, 11, 558, 30, 1033, 11, 293, 550, 456, 307, 264, 2503, 300, 3110, 300, 337, 11, 51680], "temperature": 0.0, "avg_logprob": -0.1115565077166691, "compression_ratio": 1.904564315352697, "no_speech_prob": 0.008977342396974564}, {"id": 410, "seek": 273448, "start": 2735.04, "end": 2743.76, "text": " for foundational technology, for infrastructure type technology, open source always wins,", "tokens": [50392, 337, 32195, 2899, 11, 337, 6896, 2010, 2899, 11, 1269, 4009, 1009, 10641, 11, 50828], "temperature": 0.0, "avg_logprob": -0.20762222043929562, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.0005974019295535982}, {"id": 411, "seek": 273448, "start": 2746.64, "end": 2753.44, "text": " right? It's true of the software infrastructure of the internet. In the early 90s and mid 90s,", "tokens": [50972, 558, 30, 467, 311, 2074, 295, 264, 4722, 6896, 295, 264, 4705, 13, 682, 264, 2440, 4289, 82, 293, 2062, 4289, 82, 11, 51312], "temperature": 0.0, "avg_logprob": -0.20762222043929562, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.0005974019295535982}, {"id": 412, "seek": 273448, "start": 2753.44, "end": 2758.56, "text": " there was a big battle between sun macro systems and Microsoft to produce the, deliver the", "tokens": [51312, 456, 390, 257, 955, 4635, 1296, 3295, 18887, 3652, 293, 8116, 281, 5258, 264, 11, 4239, 264, 51568], "temperature": 0.0, "avg_logprob": -0.20762222043929562, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.0005974019295535982}, {"id": 413, "seek": 275856, "start": 2759.52, "end": 2763.92, "text": " software infrastructure of the internet, you know, operating systems, web servers,", "tokens": [50412, 4722, 6896, 295, 264, 4705, 11, 291, 458, 11, 7447, 3652, 11, 3670, 15909, 11, 50632], "temperature": 0.0, "avg_logprob": -0.18980214787625718, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003220748156309128}, {"id": 414, "seek": 275856, "start": 2765.36, "end": 2770.0, "text": " web browsers, and, and, you know, various servers aside and client-side frameworks, right?", "tokens": [50704, 3670, 36069, 11, 293, 11, 293, 11, 291, 458, 11, 3683, 15909, 7359, 293, 6423, 12, 1812, 29834, 11, 558, 30, 50936], "temperature": 0.0, "avg_logprob": -0.18980214787625718, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003220748156309128}, {"id": 415, "seek": 275856, "start": 2770.0, "end": 2775.2, "text": " They're both lost. Nobody is talking about them anymore. The entire world is,", "tokens": [50936, 814, 434, 1293, 2731, 13, 9297, 307, 1417, 466, 552, 3602, 13, 440, 2302, 1002, 307, 11, 51196], "temperature": 0.0, "avg_logprob": -0.18980214787625718, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003220748156309128}, {"id": 416, "seek": 275856, "start": 2776.96, "end": 2786.56, "text": " of the web is using Linux and Apache and MySQL and JavaScript and, and, you know, and even the,", "tokens": [51284, 295, 264, 3670, 307, 1228, 18734, 293, 46597, 293, 1222, 39934, 293, 15778, 293, 11, 293, 11, 291, 458, 11, 293, 754, 264, 11, 51764], "temperature": 0.0, "avg_logprob": -0.18980214787625718, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003220748156309128}, {"id": 417, "seek": 278656, "start": 2786.7999999999997, "end": 2791.6, "text": " the basic core code for, for web browser is open source. So,", "tokens": [50376, 264, 3875, 4965, 3089, 337, 11, 337, 3670, 11185, 307, 1269, 4009, 13, 407, 11, 50616], "temperature": 0.0, "avg_logprob": -0.1904192590094232, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.000552575453184545}, {"id": 418, "seek": 278656, "start": 2793.44, "end": 2800.32, "text": " open source won by a huge margin. Why? Because it's safer, gathers more people to contribute.", "tokens": [50708, 1269, 4009, 1582, 538, 257, 2603, 10270, 13, 1545, 30, 1436, 309, 311, 15856, 11, 290, 11850, 544, 561, 281, 10586, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1904192590094232, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.000552575453184545}, {"id": 419, "seek": 278656, "start": 2800.32, "end": 2803.36, "text": " All the features are unnecessary. It's more reliable.", "tokens": [51052, 1057, 264, 4122, 366, 19350, 13, 467, 311, 544, 12924, 13, 51204], "temperature": 0.0, "avg_logprob": -0.1904192590094232, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.000552575453184545}, {"id": 420, "seek": 278656, "start": 2805.7599999999998, "end": 2812.96, "text": " Venerabilities are fixed faster. And, and it's customizable. So anybody can customize Linux", "tokens": [51324, 691, 7971, 6167, 366, 6806, 4663, 13, 400, 11, 293, 309, 311, 47922, 13, 407, 4472, 393, 19734, 18734, 51684], "temperature": 0.0, "avg_logprob": -0.1904192590094232, "compression_ratio": 1.477832512315271, "no_speech_prob": 0.000552575453184545}, {"id": 421, "seek": 281296, "start": 2812.96, "end": 2820.4, "text": " to run on whatever hardware they want, right? So open source wins. And the same, same for AI.", "tokens": [50364, 281, 1190, 322, 2035, 8837, 436, 528, 11, 558, 30, 407, 1269, 4009, 10641, 13, 400, 264, 912, 11, 912, 337, 7318, 13, 50736], "temperature": 0.0, "avg_logprob": -0.20164757632137684, "compression_ratio": 1.5144230769230769, "no_speech_prob": 0.014696015976369381}, {"id": 422, "seek": 281296, "start": 2820.4, "end": 2825.28, "text": " It's going to be the same thing. It's inevitable. The, the people now who are climbing up,", "tokens": [50736, 467, 311, 516, 281, 312, 264, 912, 551, 13, 467, 311, 21451, 13, 440, 11, 264, 561, 586, 567, 366, 14780, 493, 11, 50980], "temperature": 0.0, "avg_logprob": -0.20164757632137684, "compression_ratio": 1.5144230769230769, "no_speech_prob": 0.014696015976369381}, {"id": 423, "seek": 281296, "start": 2826.32, "end": 2835.2, "text": " like open AI, their, their system is based on publications from all of us. Sure. And from", "tokens": [51032, 411, 1269, 7318, 11, 641, 11, 641, 1185, 307, 2361, 322, 25618, 490, 439, 295, 505, 13, 4894, 13, 400, 490, 51476], "temperature": 0.0, "avg_logprob": -0.20164757632137684, "compression_ratio": 1.5144230769230769, "no_speech_prob": 0.014696015976369381}, {"id": 424, "seek": 281296, "start": 2836.16, "end": 2838.8, "text": " open platforms like, like PyTorch. Yeah.", "tokens": [51524, 1269, 9473, 411, 11, 411, 9953, 51, 284, 339, 13, 865, 13, 51656], "temperature": 0.0, "avg_logprob": -0.20164757632137684, "compression_ratio": 1.5144230769230769, "no_speech_prob": 0.014696015976369381}, {"id": 425, "seek": 283880, "start": 2838.8, "end": 2843.28, "text": " Judgeability is built using PyTorch. PyTorch was produced originally by Meta. Now it's owned by", "tokens": [50364, 19476, 2310, 307, 3094, 1228, 9953, 51, 284, 339, 13, 9953, 51, 284, 339, 390, 7126, 7993, 538, 6377, 64, 13, 823, 309, 311, 11684, 538, 50588], "temperature": 0.0, "avg_logprob": -0.15943280388327205, "compression_ratio": 1.5344262295081967, "no_speech_prob": 0.0052033280953764915}, {"id": 426, "seek": 283880, "start": 2843.28, "end": 2849.52, "text": " the Linux Foundation. It's open source. They've contributed to it, by the way. You know, their", "tokens": [50588, 264, 18734, 10335, 13, 467, 311, 1269, 4009, 13, 814, 600, 18434, 281, 309, 11, 538, 264, 636, 13, 509, 458, 11, 641, 50900], "temperature": 0.0, "avg_logprob": -0.15943280388327205, "compression_ratio": 1.5344262295081967, "no_speech_prob": 0.0052033280953764915}, {"id": 427, "seek": 283880, "start": 2849.52, "end": 2856.1600000000003, "text": " LLM is based on transformer architectures invented at Google. Yeah. All the tricks to kind of train", "tokens": [50900, 441, 43, 44, 307, 2361, 322, 31782, 6331, 1303, 14479, 412, 3329, 13, 865, 13, 1057, 264, 11733, 281, 733, 295, 3847, 51232], "temperature": 0.0, "avg_logprob": -0.15943280388327205, "compression_ratio": 1.5344262295081967, "no_speech_prob": 0.0052033280953764915}, {"id": 428, "seek": 283880, "start": 2856.1600000000003, "end": 2861.28, "text": " all those things came out of like various papers from all kinds of different institutions,", "tokens": [51232, 439, 729, 721, 1361, 484, 295, 411, 3683, 10577, 490, 439, 3685, 295, 819, 8142, 11, 51488], "temperature": 0.0, "avg_logprob": -0.15943280388327205, "compression_ratio": 1.5344262295081967, "no_speech_prob": 0.0052033280953764915}, {"id": 429, "seek": 283880, "start": 2861.28, "end": 2867.76, "text": " including academia, all the fine-tuning techniques, same. So nobody works in a vacuum.", "tokens": [51488, 3009, 28937, 11, 439, 264, 2489, 12, 83, 37726, 7512, 11, 912, 13, 407, 5079, 1985, 294, 257, 14224, 13, 51812], "temperature": 0.0, "avg_logprob": -0.15943280388327205, "compression_ratio": 1.5344262295081967, "no_speech_prob": 0.0052033280953764915}, {"id": 430, "seek": 286776, "start": 2867.76, "end": 2872.5600000000004, "text": " The thing is, nobody can keep their advance and their advantage", "tokens": [50364, 440, 551, 307, 11, 5079, 393, 1066, 641, 7295, 293, 641, 5002, 50604], "temperature": 0.0, "avg_logprob": -0.12019025195728648, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.0005440210225060582}, {"id": 431, "seek": 286776, "start": 2874.1600000000003, "end": 2880.32, "text": " for very long if they are secretive. Yeah. Except that with these models, because they're", "tokens": [50684, 337, 588, 938, 498, 436, 366, 4054, 488, 13, 865, 13, 16192, 300, 365, 613, 5245, 11, 570, 436, 434, 50992], "temperature": 0.0, "avg_logprob": -0.12019025195728648, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.0005440210225060582}, {"id": 432, "seek": 286776, "start": 2880.32, "end": 2887.2000000000003, "text": " so compute intensive and they cost so much money to train, you need somebody like Meta that who's,", "tokens": [50992, 370, 14722, 18957, 293, 436, 2063, 370, 709, 1460, 281, 3847, 11, 291, 643, 2618, 411, 6377, 64, 300, 567, 311, 11, 51336], "temperature": 0.0, "avg_logprob": -0.12019025195728648, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.0005440210225060582}, {"id": 433, "seek": 286776, "start": 2887.2000000000003, "end": 2893.44, "text": " who's going to be willing to build them and open source them. And that's why I was, when I was", "tokens": [51336, 567, 311, 516, 281, 312, 4950, 281, 1322, 552, 293, 1269, 4009, 552, 13, 400, 300, 311, 983, 286, 390, 11, 562, 286, 390, 51648], "temperature": 0.0, "avg_logprob": -0.12019025195728648, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.0005440210225060582}, {"id": 434, "seek": 289344, "start": 2893.44, "end": 2903.52, "text": " asking whether they'll continue, obviously Meta will continue building, you know, resource-intensive", "tokens": [50364, 3365, 1968, 436, 603, 2354, 11, 2745, 6377, 64, 486, 2354, 2390, 11, 291, 458, 11, 7684, 12, 686, 2953, 50868], "temperature": 0.0, "avg_logprob": -0.16956344120939013, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0025501262862235308}, {"id": 435, "seek": 289344, "start": 2903.52, "end": 2910.0, "text": " models. But the question is whether they'll continue to open source. I mean, if- I'm telling you,", "tokens": [50868, 5245, 13, 583, 264, 1168, 307, 1968, 436, 603, 2354, 281, 1269, 4009, 13, 286, 914, 11, 498, 12, 286, 478, 3585, 291, 11, 51192], "temperature": 0.0, "avg_logprob": -0.16956344120939013, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0025501262862235308}, {"id": 436, "seek": 289344, "start": 2910.0, "end": 2917.04, "text": " I'm telling you the only reason why Meta could stop open sourcing models are legal.", "tokens": [51192, 286, 478, 3585, 291, 264, 787, 1778, 983, 6377, 64, 727, 1590, 1269, 11006, 2175, 5245, 366, 5089, 13, 51544], "temperature": 0.0, "avg_logprob": -0.16956344120939013, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0025501262862235308}, {"id": 437, "seek": 291704, "start": 2918.0, "end": 2923.52, "text": " So if there is a law that adds laws, open source AI systems above a certain level of", "tokens": [50412, 407, 498, 456, 307, 257, 2101, 300, 10860, 6064, 11, 1269, 4009, 7318, 3652, 3673, 257, 1629, 1496, 295, 50688], "temperature": 0.0, "avg_logprob": -0.15838305155436197, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.0025093278381973505}, {"id": 438, "seek": 291704, "start": 2924.8, "end": 2933.2, "text": " sophistication, then of course we can do it. If there are laws that in the US or across the world", "tokens": [50752, 15572, 399, 11, 550, 295, 1164, 321, 393, 360, 309, 13, 759, 456, 366, 6064, 300, 294, 264, 2546, 420, 2108, 264, 1002, 51172], "temperature": 0.0, "avg_logprob": -0.15838305155436197, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.0025093278381973505}, {"id": 439, "seek": 291704, "start": 2935.52, "end": 2942.4, "text": " makes it illegal to use public content to train AI systems, then it's the end of AI", "tokens": [51288, 1669, 309, 11905, 281, 764, 1908, 2701, 281, 3847, 7318, 3652, 11, 550, 309, 311, 264, 917, 295, 7318, 51632], "temperature": 0.0, "avg_logprob": -0.15838305155436197, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.0025093278381973505}, {"id": 440, "seek": 294240, "start": 2942.48, "end": 2948.56, "text": " for everybody, not just for the open source. Okay. So, or at least the end of the type of AI", "tokens": [50368, 337, 2201, 11, 406, 445, 337, 264, 1269, 4009, 13, 1033, 13, 407, 11, 420, 412, 1935, 264, 917, 295, 264, 2010, 295, 7318, 50672], "temperature": 0.0, "avg_logprob": -0.1487287007845365, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.007774882018566132}, {"id": 441, "seek": 294240, "start": 2948.56, "end": 2952.4, "text": " that we are talking about today might have, you know, new AI in the future, but that don't", "tokens": [50672, 300, 321, 366, 1417, 466, 965, 1062, 362, 11, 291, 458, 11, 777, 7318, 294, 264, 2027, 11, 457, 300, 500, 380, 50864], "temperature": 0.0, "avg_logprob": -0.1487287007845365, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.007774882018566132}, {"id": 442, "seek": 294240, "start": 2952.4, "end": 2961.36, "text": " require as much data. So, and then there is, you know, liability. If you, if you, if you, if you", "tokens": [50864, 3651, 382, 709, 1412, 13, 407, 11, 293, 550, 456, 307, 11, 291, 458, 11, 25196, 13, 759, 291, 11, 498, 291, 11, 498, 291, 11, 498, 291, 51312], "temperature": 0.0, "avg_logprob": -0.1487287007845365, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.007774882018566132}, {"id": 443, "seek": 294240, "start": 2961.36, "end": 2968.96, "text": " believe in the kind of that someone doing something bad with an AI system that was open sourced by", "tokens": [51312, 1697, 294, 264, 733, 295, 300, 1580, 884, 746, 1578, 365, 364, 7318, 1185, 300, 390, 1269, 11006, 1232, 538, 51692], "temperature": 0.0, "avg_logprob": -0.1487287007845365, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.007774882018566132}, {"id": 444, "seek": 296896, "start": 2969.68, "end": 2975.92, "text": " by Meta, then Meta is liable, then Meta will have a big incentive not to release it, obviously.", "tokens": [50400, 538, 6377, 64, 11, 550, 6377, 64, 307, 375, 712, 11, 550, 6377, 64, 486, 362, 257, 955, 22346, 406, 281, 4374, 309, 11, 2745, 13, 50712], "temperature": 0.0, "avg_logprob": -0.13769159109696097, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.005135668441653252}, {"id": 445, "seek": 296896, "start": 2976.7200000000003, "end": 2981.84, "text": " So it's the entire question about this is around legal reasons and political decisions.", "tokens": [50752, 407, 309, 311, 264, 2302, 1168, 466, 341, 307, 926, 5089, 4112, 293, 3905, 5327, 13, 51008], "temperature": 0.0, "avg_logprob": -0.13769159109696097, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.005135668441653252}, {"id": 446, "seek": 296896, "start": 2981.84, "end": 2988.32, "text": " But on the idea of open source winning, don't you need more people or more companies like Meta", "tokens": [51008, 583, 322, 264, 1558, 295, 1269, 4009, 8224, 11, 500, 380, 291, 643, 544, 561, 420, 544, 3431, 411, 6377, 64, 51332], "temperature": 0.0, "avg_logprob": -0.13769159109696097, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.005135668441653252}, {"id": 447, "seek": 296896, "start": 2988.32, "end": 2994.4, "text": " building the foundation models and open sourcing them? Or could it be, could an open source", "tokens": [51332, 2390, 264, 7030, 5245, 293, 1269, 11006, 2175, 552, 30, 1610, 727, 309, 312, 11, 727, 364, 1269, 4009, 51636], "temperature": 0.0, "avg_logprob": -0.13769159109696097, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.005135668441653252}, {"id": 448, "seek": 299440, "start": 2994.96, "end": 3001.28, "text": " ecosystem win based on a single company building the models? No, I mean, you need two or three.", "tokens": [50392, 11311, 1942, 2361, 322, 257, 2167, 2237, 2390, 264, 5245, 30, 883, 11, 286, 914, 11, 291, 643, 732, 420, 1045, 13, 50708], "temperature": 0.0, "avg_logprob": -0.15575050007213245, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.007340573705732822}, {"id": 449, "seek": 299440, "start": 3002.0, "end": 3006.96, "text": " And there are two or three, right? I mean, there is this hugging face. There is Mistral in France,", "tokens": [50744, 400, 456, 366, 732, 420, 1045, 11, 558, 30, 286, 914, 11, 456, 307, 341, 41706, 1851, 13, 821, 307, 20166, 2155, 294, 6190, 11, 50992], "temperature": 0.0, "avg_logprob": -0.15575050007213245, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.007340573705732822}, {"id": 450, "seek": 299440, "start": 3006.96, "end": 3013.04, "text": " who's also embracing sort of an open source LLM. They're very good LLM. It's a small one, but it's", "tokens": [50992, 567, 311, 611, 31596, 1333, 295, 364, 1269, 4009, 441, 43, 44, 13, 814, 434, 588, 665, 441, 43, 44, 13, 467, 311, 257, 1359, 472, 11, 457, 309, 311, 51296], "temperature": 0.0, "avg_logprob": -0.15575050007213245, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.007340573705732822}, {"id": 451, "seek": 299440, "start": 3013.04, "end": 3021.6800000000003, "text": " very good. There is, you know, academic efforts like Lyon. They don't have all the resources they", "tokens": [51296, 588, 665, 13, 821, 307, 11, 291, 458, 11, 7778, 6484, 411, 12687, 266, 13, 814, 500, 380, 362, 439, 264, 3593, 436, 51728], "temperature": 0.0, "avg_logprob": -0.15575050007213245, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.007340573705732822}, {"id": 452, "seek": 302168, "start": 3021.68, "end": 3026.64, "text": " need, but they, you know, they collect the data that is used by everyone. So everybody can contribute.", "tokens": [50364, 643, 11, 457, 436, 11, 291, 458, 11, 436, 2500, 264, 1412, 300, 307, 1143, 538, 1518, 13, 407, 2201, 393, 10586, 13, 50612], "temperature": 0.0, "avg_logprob": -0.10311130819649532, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.0035305197816342115}, {"id": 453, "seek": 302168, "start": 3026.64, "end": 3031.44, "text": " One thing that I think is really important to understand also is that there is a future in", "tokens": [50612, 1485, 551, 300, 286, 519, 307, 534, 1021, 281, 1223, 611, 307, 300, 456, 307, 257, 2027, 294, 50852], "temperature": 0.0, "avg_logprob": -0.10311130819649532, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.0035305197816342115}, {"id": 454, "seek": 302168, "start": 3031.44, "end": 3037.52, "text": " which I described earlier in which every one of us, every one of our interactions with the digital", "tokens": [50852, 597, 286, 7619, 3071, 294, 597, 633, 472, 295, 505, 11, 633, 472, 295, 527, 13280, 365, 264, 4562, 51156], "temperature": 0.0, "avg_logprob": -0.10311130819649532, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.0035305197816342115}, {"id": 455, "seek": 302168, "start": 3037.52, "end": 3044.0, "text": " world will be mediated by an AI assistant. And this is going to be for true for everyone around", "tokens": [51156, 1002, 486, 312, 17269, 770, 538, 364, 7318, 10994, 13, 400, 341, 307, 516, 281, 312, 337, 2074, 337, 1518, 926, 51480], "temperature": 0.0, "avg_logprob": -0.10311130819649532, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.0035305197816342115}, {"id": 456, "seek": 302168, "start": 3044.0, "end": 3049.2799999999997, "text": " the world, right? Everyone who has any kind of smart device. Eventually it's going to be in our,", "tokens": [51480, 264, 1002, 11, 558, 30, 5198, 567, 575, 604, 733, 295, 4069, 4302, 13, 17586, 309, 311, 516, 281, 312, 294, 527, 11, 51744], "temperature": 0.0, "avg_logprob": -0.10311130819649532, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.0035305197816342115}, {"id": 457, "seek": 304928, "start": 3049.28, "end": 3053.44, "text": " you know, augmented reality glasses, but, you know, for the time being in our smartphones, right?", "tokens": [50364, 291, 458, 11, 36155, 4103, 10812, 11, 457, 11, 291, 458, 11, 337, 264, 565, 885, 294, 527, 26782, 11, 558, 30, 50572], "temperature": 0.0, "avg_logprob": -0.13803787231445314, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0024696416221559048}, {"id": 458, "seek": 304928, "start": 3055.2000000000003, "end": 3062.2400000000002, "text": " And so imagine that future where, you know, you are, I don't know, from", "tokens": [50660, 400, 370, 3811, 300, 2027, 689, 11, 291, 458, 11, 291, 366, 11, 286, 500, 380, 458, 11, 490, 51012], "temperature": 0.0, "avg_logprob": -0.13803787231445314, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0024696416221559048}, {"id": 459, "seek": 304928, "start": 3064.4, "end": 3073.84, "text": " Indonesia or Senegal or France. And your entire digital diet is done through the", "tokens": [51120, 16879, 420, 3862, 38221, 420, 6190, 13, 400, 428, 2302, 4562, 6339, 307, 1096, 807, 264, 51592], "temperature": 0.0, "avg_logprob": -0.13803787231445314, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0024696416221559048}, {"id": 460, "seek": 307384, "start": 3074.56, "end": 3081.84, "text": " mediation of an AI system. Your government is not going to be happy about it. Your government", "tokens": [50400, 1205, 6642, 295, 364, 7318, 1185, 13, 2260, 2463, 307, 406, 516, 281, 312, 2055, 466, 309, 13, 2260, 2463, 50764], "temperature": 0.0, "avg_logprob": -0.19487953186035156, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.01112782396376133}, {"id": 461, "seek": 307384, "start": 3082.6400000000003, "end": 3087.44, "text": " is going to want the local culture to be present in that system. It doesn't want that system to be", "tokens": [50804, 307, 516, 281, 528, 264, 2654, 3713, 281, 312, 1974, 294, 300, 1185, 13, 467, 1177, 380, 528, 300, 1185, 281, 312, 51044], "temperature": 0.0, "avg_logprob": -0.19487953186035156, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.01112782396376133}, {"id": 462, "seek": 307384, "start": 3087.44, "end": 3096.88, "text": " closed sourced and controlled by a company on the west coast of the US. So just for reasons of", "tokens": [51044, 5395, 11006, 1232, 293, 10164, 538, 257, 2237, 322, 264, 7009, 8684, 295, 264, 2546, 13, 407, 445, 337, 4112, 295, 51516], "temperature": 0.0, "avg_logprob": -0.19487953186035156, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.01112782396376133}, {"id": 463, "seek": 309688, "start": 3097.2000000000003, "end": 3105.36, "text": " preserving the diversity of culture across the world and not having or entire information", "tokens": [50380, 33173, 264, 8811, 295, 3713, 2108, 264, 1002, 293, 406, 1419, 420, 2302, 1589, 50788], "temperature": 0.0, "avg_logprob": -0.16019684591411074, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.013000046834349632}, {"id": 464, "seek": 309688, "start": 3105.36, "end": 3109.84, "text": " diet being biased by whatever it is that some company on the west coast of the US states,", "tokens": [50788, 6339, 885, 28035, 538, 2035, 309, 307, 300, 512, 2237, 322, 264, 7009, 8684, 295, 264, 2546, 4368, 11, 51012], "temperature": 0.0, "avg_logprob": -0.16019684591411074, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.013000046834349632}, {"id": 465, "seek": 309688, "start": 3111.36, "end": 3117.36, "text": " there's going to need to be open source platforms. And they're going to be predominant", "tokens": [51088, 456, 311, 516, 281, 643, 281, 312, 1269, 4009, 9473, 13, 400, 436, 434, 516, 281, 312, 21456, 394, 51388], "temperature": 0.0, "avg_logprob": -0.16019684591411074, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.013000046834349632}, {"id": 466, "seek": 309688, "start": 3118.2400000000002, "end": 3124.4, "text": " in at least outside the US for that reason. Including China, right? There is all those", "tokens": [51432, 294, 412, 1935, 2380, 264, 2546, 337, 300, 1778, 13, 27137, 3533, 11, 558, 30, 821, 307, 439, 729, 51740], "temperature": 0.0, "avg_logprob": -0.16019684591411074, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.013000046834349632}, {"id": 467, "seek": 312440, "start": 3124.4, "end": 3129.12, "text": " talks about, oh, what if China puts their hands on our open source code? I mean, China wants control", "tokens": [50364, 6686, 466, 11, 1954, 11, 437, 498, 3533, 8137, 641, 2377, 322, 527, 1269, 4009, 3089, 30, 286, 914, 11, 3533, 2738, 1969, 50600], "temperature": 0.0, "avg_logprob": -0.14678844602981417, "compression_ratio": 1.6, "no_speech_prob": 0.017151283100247383}, {"id": 468, "seek": 312440, "start": 3129.12, "end": 3135.76, "text": " over its own LLM because they don't want their citizen to, you know, have access to certain type", "tokens": [50600, 670, 1080, 1065, 441, 43, 44, 570, 436, 500, 380, 528, 641, 13326, 281, 11, 291, 458, 11, 362, 2105, 281, 1629, 2010, 50932], "temperature": 0.0, "avg_logprob": -0.14678844602981417, "compression_ratio": 1.6, "no_speech_prob": 0.017151283100247383}, {"id": 469, "seek": 312440, "start": 3135.76, "end": 3140.48, "text": " of information. So they're not going to use our LLMs. They're going to trend theirs that they already", "tokens": [50932, 295, 1589, 13, 407, 436, 434, 406, 516, 281, 764, 527, 441, 43, 26386, 13, 814, 434, 516, 281, 6028, 22760, 300, 436, 1217, 51168], "temperature": 0.0, "avg_logprob": -0.14678844602981417, "compression_ratio": 1.6, "no_speech_prob": 0.017151283100247383}, {"id": 470, "seek": 312440, "start": 3140.48, "end": 3146.64, "text": " have. And nobody is, you know, particularly ahead of anybody else by more than about a year.", "tokens": [51168, 362, 13, 400, 5079, 307, 11, 291, 458, 11, 4098, 2286, 295, 4472, 1646, 538, 544, 813, 466, 257, 1064, 13, 51476], "temperature": 0.0, "avg_logprob": -0.14678844602981417, "compression_ratio": 1.6, "no_speech_prob": 0.017151283100247383}, {"id": 471, "seek": 314664, "start": 3147.52, "end": 3155.12, "text": " Yeah. And China is pushing open source. I mean, they're very pro open source within their", "tokens": [50408, 865, 13, 400, 3533, 307, 7380, 1269, 4009, 13, 286, 914, 11, 436, 434, 588, 447, 1269, 4009, 1951, 641, 50788], "temperature": 0.0, "avg_logprob": -0.15284936324409817, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.02514231763780117}, {"id": 472, "seek": 314664, "start": 3155.12, "end": 3160.96, "text": " ecosystems. Some of them, you know, it's there's no like unified opinion there. But", "tokens": [50788, 32647, 13, 2188, 295, 552, 11, 291, 458, 11, 309, 311, 456, 311, 572, 411, 26787, 4800, 456, 13, 583, 51080], "temperature": 0.0, "avg_logprob": -0.15284936324409817, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.02514231763780117}, {"id": 473, "seek": 314664, "start": 3163.04, "end": 3166.8799999999997, "text": " I mean, it's the same in in the West, right? There are some some governments that are too", "tokens": [51184, 286, 914, 11, 309, 311, 264, 912, 294, 294, 264, 4055, 11, 558, 30, 821, 366, 512, 512, 11280, 300, 366, 886, 51376], "temperature": 0.0, "avg_logprob": -0.15284936324409817, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.02514231763780117}, {"id": 474, "seek": 314664, "start": 3166.8799999999997, "end": 3173.52, "text": " afraid of the risks. And then or are thinking about it and some others that are all for open", "tokens": [51376, 4638, 295, 264, 10888, 13, 400, 550, 420, 366, 1953, 466, 309, 293, 512, 2357, 300, 366, 439, 337, 1269, 51708], "temperature": 0.0, "avg_logprob": -0.15284936324409817, "compression_ratio": 1.6255707762557077, "no_speech_prob": 0.02514231763780117}, {"id": 475, "seek": 317352, "start": 3173.52, "end": 3179.44, "text": " source because they see this as the only way for them to have any influence on the", "tokens": [50364, 4009, 570, 436, 536, 341, 382, 264, 787, 636, 337, 552, 281, 362, 604, 6503, 322, 264, 50660], "temperature": 0.0, "avg_logprob": -0.14380213919650303, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.011602883227169514}, {"id": 476, "seek": 317352, "start": 3182.16, "end": 3188.24, "text": " type of information and culture that would be mediated by those systems. So it's going to have", "tokens": [50796, 2010, 295, 1589, 293, 3713, 300, 576, 312, 17269, 770, 538, 729, 3652, 13, 407, 309, 311, 516, 281, 362, 51100], "temperature": 0.0, "avg_logprob": -0.14380213919650303, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.011602883227169514}, {"id": 477, "seek": 317352, "start": 3188.24, "end": 3197.12, "text": " to be like Wikipedia, right? Wikipedia, you know, is built by millions of people who contribute to", "tokens": [51100, 281, 312, 411, 28999, 11, 558, 30, 28999, 11, 291, 458, 11, 307, 3094, 538, 6803, 295, 561, 567, 10586, 281, 51544], "temperature": 0.0, "avg_logprob": -0.14380213919650303, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.011602883227169514}, {"id": 478, "seek": 317352, "start": 3197.12, "end": 3201.28, "text": " or from all around the world in all kinds of languages. Okay. And it has a system for sort", "tokens": [51544, 420, 490, 439, 926, 264, 1002, 294, 439, 3685, 295, 8650, 13, 1033, 13, 400, 309, 575, 257, 1185, 337, 1333, 51752], "temperature": 0.0, "avg_logprob": -0.14380213919650303, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.011602883227169514}, {"id": 479, "seek": 320128, "start": 3201.36, "end": 3206.7200000000003, "text": " of vetting the information. The way AI systems of the future will be taught and we'll be fine", "tokens": [50368, 295, 12423, 783, 264, 1589, 13, 440, 636, 7318, 3652, 295, 264, 2027, 486, 312, 5928, 293, 321, 603, 312, 2489, 50636], "temperature": 0.0, "avg_logprob": -0.14733622385107953, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.01132447924464941}, {"id": 480, "seek": 320128, "start": 3206.7200000000003, "end": 3213.36, "text": " tuned will have to be the same way will have to be quite sourced. Because something that matters to", "tokens": [50636, 10870, 486, 362, 281, 312, 264, 912, 636, 486, 362, 281, 312, 1596, 11006, 1232, 13, 1436, 746, 300, 7001, 281, 50968], "temperature": 0.0, "avg_logprob": -0.14733622385107953, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.01132447924464941}, {"id": 481, "seek": 320128, "start": 3214.7200000000003, "end": 3221.6000000000004, "text": " a farmer in southern India is probably not going to be taken into account by the fine", "tokens": [51036, 257, 17891, 294, 13456, 5282, 307, 1391, 406, 516, 281, 312, 2726, 666, 2696, 538, 264, 2489, 51380], "temperature": 0.0, "avg_logprob": -0.14733622385107953, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.01132447924464941}, {"id": 482, "seek": 320128, "start": 3221.6000000000004, "end": 3227.36, "text": " tuning done by, you know, some some company on the west coast of the US. AI might be the most", "tokens": [51380, 15164, 1096, 538, 11, 291, 458, 11, 512, 512, 2237, 322, 264, 7009, 8684, 295, 264, 2546, 13, 7318, 1062, 312, 264, 881, 51668], "temperature": 0.0, "avg_logprob": -0.14733622385107953, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.01132447924464941}, {"id": 483, "seek": 322736, "start": 3227.36, "end": 3233.44, "text": " important new computer technology ever. It's storming every industry and literally billions", "tokens": [50364, 1021, 777, 3820, 2899, 1562, 13, 467, 311, 7679, 278, 633, 3518, 293, 3736, 17375, 50668], "temperature": 0.0, "avg_logprob": -0.07412414117292924, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.34491413831710815}, {"id": 484, "seek": 322736, "start": 3233.44, "end": 3239.92, "text": " of dollars are being invested. So buckle up. The problem is that AI needs a lot of speed and", "tokens": [50668, 295, 3808, 366, 885, 13104, 13, 407, 37686, 493, 13, 440, 1154, 307, 300, 7318, 2203, 257, 688, 295, 3073, 293, 50992], "temperature": 0.0, "avg_logprob": -0.07412414117292924, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.34491413831710815}, {"id": 485, "seek": 322736, "start": 3239.92, "end": 3247.28, "text": " processing power. So how do you compete without cost spiraling out of control? It's time to upgrade", "tokens": [50992, 9007, 1347, 13, 407, 577, 360, 291, 11831, 1553, 2063, 10733, 4270, 484, 295, 1969, 30, 467, 311, 565, 281, 11484, 51360], "temperature": 0.0, "avg_logprob": -0.07412414117292924, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.34491413831710815}, {"id": 486, "seek": 322736, "start": 3247.28, "end": 3256.08, "text": " to the next generation of the cloud oracle cloud infrastructure or OCI. OCI is a single platform", "tokens": [51360, 281, 264, 958, 5125, 295, 264, 4588, 420, 7041, 4588, 6896, 420, 422, 25240, 13, 422, 25240, 307, 257, 2167, 3663, 51800], "temperature": 0.0, "avg_logprob": -0.07412414117292924, "compression_ratio": 1.548780487804878, "no_speech_prob": 0.34491413831710815}, {"id": 487, "seek": 325608, "start": 3256.08, "end": 3263.92, "text": " for your infrastructure, database, application, development and AI needs. OCI has four to eight", "tokens": [50364, 337, 428, 6896, 11, 8149, 11, 3861, 11, 3250, 293, 7318, 2203, 13, 422, 25240, 575, 1451, 281, 3180, 50756], "temperature": 0.0, "avg_logprob": -0.07156170498241078, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.008443474769592285}, {"id": 488, "seek": 325608, "start": 3263.92, "end": 3270.96, "text": " times the bandwidth of other clouds, offers one consistent price instead of variable regional", "tokens": [50756, 1413, 264, 23647, 295, 661, 12193, 11, 7736, 472, 8398, 3218, 2602, 295, 7006, 10964, 51108], "temperature": 0.0, "avg_logprob": -0.07156170498241078, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.008443474769592285}, {"id": 489, "seek": 325608, "start": 3270.96, "end": 3278.24, "text": " pricing. And of course, nobody does data better than oracle. So now you can train your AI models", "tokens": [51108, 17621, 13, 400, 295, 1164, 11, 5079, 775, 1412, 1101, 813, 420, 7041, 13, 407, 586, 291, 393, 3847, 428, 7318, 5245, 51472], "temperature": 0.0, "avg_logprob": -0.07156170498241078, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.008443474769592285}, {"id": 490, "seek": 325608, "start": 3278.24, "end": 3284.96, "text": " at twice the speed and less than half the cost of other clouds. If you want to do more and spend", "tokens": [51472, 412, 6091, 264, 3073, 293, 1570, 813, 1922, 264, 2063, 295, 661, 12193, 13, 759, 291, 528, 281, 360, 544, 293, 3496, 51808], "temperature": 0.0, "avg_logprob": -0.07156170498241078, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.008443474769592285}, {"id": 491, "seek": 328496, "start": 3284.96, "end": 3294.64, "text": " less like Uber, eight by eight and Databricks Mosaic, take a free test drive of OCI at oracle.com", "tokens": [50364, 1570, 411, 21839, 11, 3180, 538, 3180, 293, 40461, 81, 7663, 376, 42261, 11, 747, 257, 1737, 1500, 3332, 295, 422, 25240, 412, 420, 7041, 13, 1112, 50848], "temperature": 0.0, "avg_logprob": -0.14119550083460433, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.06652924418449402}, {"id": 492, "seek": 328496, "start": 3295.2, "end": 3307.04, "text": " slash I on AI. That's E Y E O N A I all run together oracle.com slash I on AI. That's it for this", "tokens": [50876, 17330, 286, 322, 7318, 13, 663, 311, 462, 398, 462, 422, 426, 316, 286, 439, 1190, 1214, 420, 7041, 13, 1112, 17330, 286, 322, 7318, 13, 663, 311, 309, 337, 341, 51468], "temperature": 0.0, "avg_logprob": -0.14119550083460433, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.06652924418449402}, {"id": 493, "seek": 328496, "start": 3307.04, "end": 3313.92, "text": " episode. I want to thank Yen for his time. If you want to read a transcript of this conversation,", "tokens": [51468, 3500, 13, 286, 528, 281, 1309, 398, 268, 337, 702, 565, 13, 759, 291, 528, 281, 1401, 257, 24444, 295, 341, 3761, 11, 51812], "temperature": 0.0, "avg_logprob": -0.14119550083460433, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.06652924418449402}, {"id": 494, "seek": 331392, "start": 3313.92, "end": 3323.52, "text": " you can find one on our website I on AI. That's E Y E hyphen O N dot AI. And remember the singularity", "tokens": [50364, 291, 393, 915, 472, 322, 527, 3144, 286, 322, 7318, 13, 663, 311, 462, 398, 462, 2477, 47059, 422, 426, 5893, 7318, 13, 400, 1604, 264, 20010, 507, 50844], "temperature": 0.0, "avg_logprob": -0.23519275665283204, "compression_ratio": 1.2647058823529411, "no_speech_prob": 0.0063872565515339375}, {"id": 495, "seek": 331392, "start": 3324.32, "end": 3336.48, "text": " may not be near, but AI is changing your world. So best pay attention.", "tokens": [50884, 815, 406, 312, 2651, 11, 457, 7318, 307, 4473, 428, 1002, 13, 407, 1151, 1689, 3202, 13, 51492], "temperature": 0.0, "avg_logprob": -0.23519275665283204, "compression_ratio": 1.2647058823529411, "no_speech_prob": 0.0063872565515339375}], "language": "en"}