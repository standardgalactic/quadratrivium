start	end	text
0	6840	What's called AI today has departed to basically pure engineering.
7600	14880	It's designed in such a, the large language models are designed in such a way that in
14880	21660	principle, they can't tell you anything about language learning, cognitive
21660	28140	processes generally, they can produce useful devices like what I'm using, but
28140	33360	the very design ensures that you'll never understand, they'll never lead
33360	36680	to any contribution to science.
37520	41000	That's not a criticism anymore than I'm criticizing.
41040	43480	Camptons this week.
43480	48060	I talked to Noam Chomsky, one of the preeminent intellectuals of our time.
48620	54440	Our conversation touched on the dichotomy between understanding and application
54440	56800	in the field of artificial intelligence.
57340	62740	Chomsky argues that AI has shifted from a science aimed at understanding
62740	69560	cognition to a pure engineering field focused on creating useful, but not
69560	73080	necessarily explanatory tools.
73600	79400	He questions whether neural nets truly mirror how the brain functions and whether
79400	82600	they exhibit any true intelligence at all.
83520	89120	He also suggests that advanced alien life forms would likely have language
89120	94320	structured similar to our own, allowing us to communicate.
95720	102200	Chomsky is 94 and I reached him at home where he appeared with a clock hanging
102220	104520	omnestly over his head.
105400	109280	I hope you enjoy the conversation as much as I did.
110040	110680	Well, thanks.
110680	111880	You're in California.
112400	115760	Actually, I'm in Arizona, which is on California time.
116080	116440	Yeah.
116560	116800	Yeah.
116800	117600	Oh, wonderful.
118120	119120	Uh, yeah.
119120	125880	So, uh, you know, I wanted to talk to you because you have the, uh, you know, one
125880	131640	of the few people, uh, with a deep understanding of, of, uh, linguistics and,
131800	139000	uh, natural language processing that has the historical knowledge, uh, of, of
139160	146080	where we are, how we got to where we are and what, uh, that might mean for the future.
146560	155240	Uh, I, I understand the, the, uh, your criticisms of deep learning, uh, and,
155280	163400	and what large language models are not in terms of, uh, reasoning and, and, uh, you
163400	167680	know, understanding the, the, the underpinnings of, uh, language.
168280	173920	But, uh, I, I thought maybe I could ask you to talk about how this developed.
173920	179440	I mean, going back to Minsky's, uh, thesis at Princeton, when he was, you know,
179440	186720	before he turned against the perceptron, when he was talking about, uh, nets as,
186720	191680	uh, a possible model for, uh, biological processes in the brain.
191680	199360	And then, you know, how did, how you see that things developed and what were
199360	205680	the, the failures that didn't get to where presumably, uh, you would have wanted
205680	211120	that research to go, uh, and then, and then I have some other questions.
211120	213720	But, but, but is that enough to get started?
215200	218360	Well, let's, let's take an analogy.
219320	230040	Suppose you're interested in figuring out how, uh, insects navigate biological
230040	230720	problem.
231440	240640	So, uh, one thing you can do is say, let's try to study in detail what the
241320	247880	desert ants are doing in my backyard, how they're using solar azimuths and so on
247880	248600	and so forth.
249600	252400	Something else you could do is say, look, it's easy.
253480	260120	I'll just build an automobile which can navigate, uh, fine, does better than the
260120	260880	desert ants.
261440	262360	So who cares?
263200	267600	Uh, well, those are the two forms of artificial intelligence.
268640	271360	One is what Minsky was after.
272360	281480	It's now kind of ridiculed as good old fashioned AI, go fi, we're past that stage.
282160	284720	Now we just build things that do it better.
285600	286080	Okay.
286960	291080	Like, uh, an airplane does better than an eagle.
291120	293200	So who cares about how eagles fly?
294560	295640	Yeah, that's possible.
296320	301480	But, uh, it's a difference between totally different goals.
302440	309240	Roughly speaking, science and engineering, it's not a sharp difference, but first
309240	314880	approximation, either you're interested in understanding something or you're just
314880	319080	interested in building something that'll work for some purpose.
319840	324440	So they're both fine occupations, nothing wrong with.
324920	329680	I mean, when you say I'm criticism of the large, criticizing the large language
329680	331080	models, that's not correct.
331640	333200	I'm using them right now.
333800	335200	I'm reading captions.
336480	343040	Captions are based on deep learning, clever programming, very useful.
343520	346040	I'm hard of hearing, so they're very helpful to me.
346560	347520	No criticism.
348200	353720	But if somebody comes along and says, okay, this explains language, you tell them
353720	361000	it's kind of like saying an airplane explains how eagles fly, the wrong question.
361680	364680	It's not intended to lead to any understanding.
365240	367480	It's intended to be for a useful purpose.
368360	369080	That's fine.
369800	370800	No criticism.
371520	378760	And what's called AI today has departed to basically pure engineering.
379480	386600	It's designed in such a, the large language models are designed in such a way that
386600	393560	in principle, they can't tell you anything about language, learning, cognitive
393560	399120	processes generally, they can produce useful devices like what I'm using.
399760	405000	But the very design ensures that you'll never understand, they'll never
405000	408600	lead to any contribution to science.
409400	413680	That's not a criticism anymore than I'm criticizing champions.
414360	420600	Jeff Hinton says, you know, his goal is to understand the brain, how the brain works.
421520	433120	And he talks about AI as we know it today, supervised learning and generative AI as
433120	442400	useful by products, but that are not his goal or not the goal of cognitive
442400	446320	science or computational biology.
448360	456440	Was there a point at which you think the research lost a bead or is there research
457080	463960	going on that people aren't paying attention to that, that is not caught up in the
463960	469360	usefulness of these other kinds of neural nets?
471800	476600	Well, first of all, if you're interested in how the brain works, the first question
476600	480360	you ask is, does it work by neural nets?
482040	483320	That's an open question.
484120	489720	There's plenty of critical analysis that argues that neural nets are not what's
489720	492280	involved, even in simple things like memory.
493480	500840	Actually, these arguments that go back to Helmholtz, the neural transmission is pretty
500840	504520	slow as compared with the ordinary memory.
505000	510840	There's much hard for criticism by people like Randy Gallistel, cognitive
510840	517400	neuroscientist, who's given pretty sound arguments that neural nets in principle
518280	528760	don't have the ability to capture the core notion of a Turing machine,
530520	533640	computational capacity, they just don't have that capacity.
534440	542200	And he's argued that the computational capacity is in much richer computational
542200	550200	systems in the brain, internal delves, where there's very rich computational capacity,
550200	555720	goes wavy on neural net, some experimental evidence to support this.
556360	559640	So if you're interested in the brain, that's the kind of thing you look at.
560600	563640	Not just saying, can I make bigger neural nets?
564840	569080	It's okay if you want to try it, but maybe it's the wrong place to look.
569640	573000	So the first question is, is it even the right place to look?
573960	577480	That's an open question in neuroscience.
578360	583720	If you take a vote among neuroscientists, almost all of them think that neural nets
583720	589080	are the right place to look, but you don't solve scientific questions by a vote.
590360	600200	Yeah, one of the things that's obvious is neural nets, they may be a model,
600200	607000	they may mimic a portion of brain activity, but there are so many other structures.
608040	613320	There's all kind of stuff going on in the brain, way down to the cellular level,
613320	616040	there's chemical interactions, plenty of other things.
616920	623400	So maybe you'll learn something by studying neural nets, if you do, fine, everybody will be happy,
624200	629880	but maybe that's not the place to look if you want to study even simple things like just
630520	632200	memory and associations.
633080	641240	There's now already evidence of associations internal to large cells in the hippocampus,
642040	649240	internal to them, which means maybe something's going on at a deeper level where there's vastly
649240	651080	more computational capacity.
653240	654840	Those are serious questions.
655720	661400	So there's nothing wrong with trying to construct models and learn something from them, if you can, fine.
662040	669480	The building larger models, which is kind of the rage in the engineering side of AI right now,
670440	673000	does produce remarkable results.
673000	676520	I mean, what was your reaction when you saw
678600	689000	chat GPT or GPT-4 or any of these models, that it's just a sort of clever stochastic parent
689000	692120	or that there was something deeper?
692200	701720	If you look at the design of the system, you can see it's like an airplane explaining flying.
702600	703720	There's nothing to do with it.
704360	711720	In fact, it's immediately obvious, trivially obvious, not a deep point, that it can't be
711720	712840	teaching us anything.
713560	714840	The reason is very simple.
715800	724680	The large learning models work just as well for impossible languages that children can't acquire
725320	727960	as for the languages they're trained on.
728840	736040	So it's as if a biologist came along and said, I got a great new theory of organisms, lists a
736040	742680	lot of organisms that possibly exist, a lot that can't possibly exist.
742680	744760	And I can tell you nothing about the difference.
746680	750040	I mean, that's not a contribution to biology.
750840	753480	It doesn't meet the first minimal condition.
754360	760760	The first minimal condition is distinguish between what's possible from what's not possible.
761480	762440	You can't do that.
763720	765480	It's not a contribution to science.
766280	771560	If it was a biologist making that proposal, you'd just laugh.
772600	778600	Why shouldn't we just laugh when an engineer from Silicon Valley says the same thing?
780200	782200	So maybe they're fun.
782200	784200	Maybe they're useful for something.
784200	785320	Maybe they're harmful.
786040	790120	Those are the kinds of questions you ask about pure technology.
791080	793000	So take large language models.
793640	795160	There are something they're useful.
796040	798440	In fact, I'm using them right at this minute.
799720	800280	Captions.
801080	803000	It's very helpful for people like me.
804760	805640	Are they harmful?
806280	808040	Yeah, they can cause a lot of harm.
808920	814440	Disinformation, defamation, brain on human gullibility.
815160	816120	Plenty of examples.
817400	818840	So they can cause harm.
818840	819880	They can be of use.
820840	825400	Those are the kinds of questions you ask about pure engineering,
826120	828440	which can be very sophisticated and clever.
829240	834200	I mean, the internal combustion engine is a very sophisticated device,
835560	841160	but we don't expect it to tell us anything about how a gazelle runs.
842840	844120	It's just the wrong question.
845080	858120	Yeah, although I talk a lot to Jeff Hinton, and you'll be the first to concede that back propagation
859560	860920	there's no evidence of that.
860920	866040	And in fact, there's a lot of evidence that it wouldn't work in the brain.
869080	870440	Reinforcement learning.
870440	879000	You know, I spoke in a rich Sutton, that's been accepted as by a lot of people as
880200	889160	an algorithmic model for brain activity in part of the brain, in the lower brain.
890040	902840	So in terms of exploring the mechanisms of the brain, it seems that there is some usefulness.
902840	908920	I mean, it says, you said there's, on the one hand, people look at the principles,
910840	916920	and then they built through engineering, just as the analogy of a bird to an airplane,
917560	923800	they've taken some of the principles and applied it through engineering and created something useful.
924360	933000	But there are scientists that are looking at what's been created, like Hinton's criticism
933000	941800	of back propagation, and are looking for other models that would fit with the principles they see
941800	946920	in cognitive science or in the brain.
946920	952040	And I mentioned this forward-forward algorithm, which you said you hadn't looked at.
952040	964520	But I found it compelling in that it doesn't require signals to be passing back through
964840	978440	the neurons. I mean, they pass back, but then stimulate other neurons as you move forward
978440	990760	in time. But I mean, is there nothing that's been learned in the study of AI or the research
991720	992600	of neural nets?
995160	1002920	But if you can find anything, it's great. Nothing against search, but it's just,
1003720	1011160	but we have to remember what you asked about chatbots. What do we learn from them? Zero.
1012040	1022280	For the simple reason that the systems work as well for impossible languages as for possible ones.
1023160	1030840	So it's like the biologist with the new theory that has organisms and impossible ones and can't
1030840	1036520	tell the difference. Now, maybe by the look at these systems, you'll learn something about
1036520	1044280	possible organisms. Okay, great. All in favor of learning things. But there's no issues.
1045080	1053480	It's just that the systems themselves, there are great claims by some of the leading figures in
1053480	1063720	the field. We've solved the problem of language acquisition, namely zero contribution, because
1063720	1072280	the systems work as well for impossible languages. Therefore, they can't be telling you anything about
1072280	1080040	language acquisition. Period. Maybe they're useful for something else. Okay, let's take a look.
1081160	1089400	Well, maybe for the audience that this is going out to, you know, I understand what you mean by
1089400	1097000	impossible, impossible, but could you just give a brief synopsis of what you mean by impossible
1097000	1105720	languages for people that haven't read your work? Well, I mean, there are certain general properties
1106600	1117320	that every infant knows, already tested down to two years old, no evidence, couldn't have evidence.
1118280	1127400	So one of the basic properties of language is that the linguistic rules apply to structures,
1127960	1134280	not linear strings. So if you want to take a sentence like
1134600	1149080	instinctively, birds that fly swim, it means instinctively they swim, not instinctively they
1149080	1158920	fly. Well, the adverb instinctively has to find a verb to attach to. It skips the closest verb
1159560	1165400	and finds the structurally closest ones. That principle turns out to be universal
1166040	1173240	for all structures, all constructions, and all languages. What it means is that an infant
1174040	1183560	from birth, as soon as you can test automatically, disregards linear order and disregards 100% of
1183560	1190840	what it hears, notice, as all we hear is words in linear order, but you disregard that and you
1190840	1199320	deal only with abstract structures in your mind, which you never hear. Take another simple example,
1199320	1209240	take the friends of my brothers are in England. Who's in England? The friends of the brothers,
1210200	1216280	the friends, not the brothers, the one that's adjacent, you just disregard all the linear
1216280	1223640	information. It means you disregard everything you hear, everything, and you pay attention only
1223640	1231160	to what your mind constructs. That's the basic, most fundamental property of language. Well,
1231160	1238040	you can make up impossible languages that work with what you hear. Simple rule, take the first
1238760	1247000	relevant thing, associate them. Friends of my brothers are here, brothers are the closest things,
1247000	1253800	and the brothers are here. Trivial rule, much simpler than the rule we use. You can construct
1253800	1260840	languages that use only those simple rules that will be based on the linear order of what we hear.
1261800	1269640	Well, maybe children, people could acquire them as a puzzle somehow using non-linguistic
1269640	1276360	capacities, but they're not what children, infants, reflexively construct with no evidence.
1277320	1284600	Well, there's many things like this, impossible and impossible languages. Well, nobody's tried
1284600	1290120	it out because it's too obvious how it's going to turn out. You take a large language model,
1290120	1297800	apply it to one of these models, systems that use linear order. Of course, it's going to work fine,
1298360	1303560	trivial rules. Well, that's a refutation of the system.
1305560	1311000	Meaning that if you trained it on an impossible language, it would produce impossible languages.
1311000	1316200	How would you mean? Well, you don't even have to train it because the rules are simple.
1316760	1322840	Yeah. Rules are much simpler than the rules of language. Like taking things that are,
1322840	1331080	take the example, the friends of my brother are here. The way we actually do it is we don't say,
1331720	1339240	take the noun phrase that's closest. We don't do that. That would be trivial, but we don't do it.
1339240	1344520	What we say is first construct the structure in your mind, friends of my brothers,
1345160	1351080	then figure out that the central element in that structure is friends, not brothers.
1351720	1358520	And then let's let it be talking about the head of it. It's a pretty complicated computation,
1359160	1365720	but that's the one we do instantaneously and reflexively. And we ignore, and we never see it,
1365720	1372520	hear it, remember? We don't hear structures. All we hear is words in linear order. What we hear
1372600	1379400	is words in linear order. We never use that information. We use only the much more looks
1379400	1385960	like complex. If you think about it computationally, it's actually simpler, but that's a deeper
1385960	1392200	question, which is why we do it. To move to a different dimension, there's a reason for this.
1393160	1399880	The reason has to do with the theory of computation. You're trying to construct
1400840	1408680	an infinite array of structured expressions. Simplest way to do that, the simplest computational
1408680	1415560	procedure is binary set formation. But if you use binary set formation, you're just going to get
1415560	1422040	structures, not order. So what the brain is doing is the simplest computational system,
1422920	1430920	which happens to be very much harder to use. Nature doesn't care about that. Nature constructs
1430920	1439240	the simplest system, doesn't care about it, if it's hard to use or not. I mean, you know, nature
1439240	1445880	could have saved us a lot of trouble if it had developed eight fingers instead of 10.
1446840	1454040	Then we'd have a much better base for computation. But nature didn't care about that when it developed
1454040	1461160	10 fingers. If you look at evolution, it pays no attention to function. It just constructs the
1461160	1467320	best system at each point. There's a lot of misleading talk about that. But if you just think
1467320	1475160	about the physics of evolution, say a bacterium swallows another organism,
1476760	1483800	the basis for what became complex cells, and nature doesn't get the new system,
1484440	1490600	it reconstructs it in the simplest possible way. It doesn't pay any attention to how
1490680	1499240	complex organisms are going to behave, not what nature can do. And that's the way evolution works
1499240	1507240	all the way down the line. So not surprisingly, nature constructed language so that it's
1507800	1516200	computationally elegant, but dysfunctional, hard to use in many ways. Not nature's problem,
1516920	1522920	just like every other aspect of nature. You can think of a way in which you can do it better,
1522920	1532920	but it didn't happen stage by stage. Two questions from that. So your view is that
1533960	1538920	artificial intelligence, as it's being called, and particularly generative AI,
1539800	1547160	doesn't exhibit true intelligence. Is that right? I wouldn't even say that.
1547880	1556680	It's irrelevant to the question of intelligence. It's not its problem. A guy who designs a jet plane
1557320	1566920	is not trying to answer the question, how do eagles fly? So to say, well, it doesn't tell us how
1566920	1576920	eagles fly is the wrong question to ask. It's not the goal. Except what people are struggling with
1576920	1585880	right now. You've heard the existential threat argument that these models, if they get large
1585880	1592600	enough, they'll actually be more intelligent than humans. That's science fiction. I mean,
1592600	1600280	there is a theoretical possibility. You can give a theoretical argument that, in principle,
1602360	1612520	a complex system with vast search capacity could conceivably turn into something that would start
1612520	1622200	to do things that you can't predict, maybe beyond. But that's even more remote than some
1623880	1630040	distant asteroid, maybe someday hitting the earth, could happen. I mean, if you read a
1630040	1638120	serious scientist on this, like Max Tagmark, his book on the three levels of intelligence,
1639080	1647560	does give a sound theoretical argument as to how a massive system could, say,
1649320	1658280	run through all the scientific discoveries in history, maybe find out some better way of
1660120	1664920	developing them and use that better way to design something new which would destroy us all.
1665880	1673080	It's, in theory, possible, but it's so remote from anything that's available that it's a waste of
1673080	1680040	time to think about it. Yeah, so your view is that whatever threat exists from
1681080	1690520	generative AI, it's the more mundane threat of disinformation. Disinformation, defamation,
1691480	1700760	gullibility, Gary Marcus has done a lot of work on this, real cases, those are problems. I mean,
1700760	1709800	you may have seen that there was a, sort of as a joke, people, somebody developed a defamation of the
1709880	1720840	pope, put an image of the pope, somebody could do it for you, duplicate your face so it looks more
1720840	1730120	or less like your face, pretty much duplicate your voice, develop a robot that looks kind of like you,
1730120	1736360	have you say some insane thing, it would be hard only an expert could tell whether it was you or
1736360	1743720	none. It's like this was done already several times, but basically is a joke.
1744440	1749720	When powerful institutions get started on it, it's not going to be a joke.
1754520	1761640	Another argument that's swirling around these large language models is the question of
1762600	1770200	a sentence of whether if the model is large enough, and this goes a little bit back to how
1770200	1776520	there's a lot more going on in the brain than the neural network or the cerebral cortex, but
1778520	1786280	that there is the potential for some kind of sentence, not necessarily equivalent to human
1786280	1795720	sentence. These are vacuous questions. It's like asking, does a submarine really swim?
1797000	1803560	You want to call that swimming? Yeah, it swims. You don't want to call it swimming? It's not a
1803560	1813080	substantive question. Well, in the sense that it supports the view that there's no separation between
1813320	1822200	consciousness and the material activities of the brain. There's a separation that hasn't
1822200	1830840	been believed since the 17th century. John Locke, after Newton's demonstration, said, well leaves
1830840	1839400	us only with the possibility that thinking is some property of organized matter. That's the 17th
1839400	1851000	century. Yeah, okay. But the belief in a soul and consciousness is something separate from a
1851000	1859640	material biology. It persists. The belief in all kinds of things. But within the rational part
1859720	1868200	of the human species, once Newton demonstrated that the mechanical model doesn't work,
1869160	1877560	there's no material universe in the only sense that was understood. Locke took the obvious conclusion,
1877560	1885800	said, well, since matter, as Mr. Newton has demonstrated, has properties that we cannot
1885800	1892520	conceive of. They're not part of our intuitive picture. Since matter has those properties,
1893800	1899240	organized matter can also have the property of thought. This was investigated all through the
1899240	1908600	18th century. Ended up finally with Joseph Priestley, a philosopher in the late 18th century,
1908600	1918040	gave pretty extensive discussions of how material, organized material objects could have
1918040	1925080	properties of thought. You can even find it in Darwin's early notebooks. It was kind of forgotten
1925080	1932280	after that. Rediscovered in the late 20th century as some radical new discovery,
1932840	1940040	astonishing hypothesis. Matter can think. Of course it can. In fact, we're doing it right now.
1940920	1947160	But the only problem then is to find out what's involved in what we call thinking,
1948120	1954440	what we call sentience, what are the properties of whatever matter is. We don't know what matter is,
1954440	1961560	but whatever it turns out to be, whatever constitutes the world, what physicists don't
1961560	1969800	know, but whatever it is, there's something organized. Elements of it can have various properties,
1970440	1976920	like the properties that we are now using, properties that we call sentience. Then the question
1976920	1984920	whether something else has sentience is as interesting as whether airplanes fly. If you're
1984920	1991880	talking English, airplanes fly. If you're talking Hebrew, airplanes glide, they don't fly.
1993160	1999560	It's not a substantive question. What metaphors do we like?
2001800	2010840	But what you're saying then is that neural net may not be the engineering solution, but
2011800	2021880	that eventually it may be possible to create a system outside of the human brain that can think
2023960	2031640	whatever thinking means. And do what we call thinking. But whether it thinks or not is like
2031640	2040520	asking the airplanes fly, not a substantive question. We shouldn't waste time on questions
2040520	2046760	that are completely meaningless. Going back to the history then,
2049160	2054120	you know, Minsky was very interested in the possibility of neural nets as a
2057720	2064680	computational model. In Minsky's time, it looked as if neural nets were the right place to look.
2065480	2070840	Now I think it's not so obvious, especially because of Galastal's work,
2071800	2077720	which is not accepted by most neuroscientists, but seems to me pretty compelling.
2078760	2083800	Can you talk a little bit about that because I haven't read that and I'm guessing our readers
2083800	2092040	haven't, our listeners haven't. Galastal is not the only one. Roger Penrose is another
2093000	2098920	Nobel Prize winning physicist, but a number of people have pointed out Galastal mostly that
2099800	2107960	have argued, I think plausibly, that the basic component of a computational system,
2109000	2115560	the basic element of essentially a Turing machine, cannot be constructed from neural nets.
2116520	2123640	So you have to look somewhere else with a different form of computation. And he's also
2123640	2130840	pointed out, but in fact, it's true that there's much richer computational capacity in the brain
2130840	2138680	than neural nets, even internal to a cell. There's massive computational capacity
2139640	2146040	intercellular. So maybe that's involved in computation. And then there's by now some
2146600	2152920	experimental work, I think, giving some evidence for this, but it's a problem for neuroscientists
2152920	2160520	to work on. I'm not an expert in the field. I'm looking at it from the outside,
2161240	2166040	so don't take my opinion too seriously. But to me, it looks pretty compelling.
2166680	2173320	But whatever it is, neural nets or something else, yes, some organization of them, of whatever
2173320	2179800	is there, is giving us the capacity to do what we're doing. So if you're a scientist, what you do is
2181160	2188200	approach it in two different ways. One is you try to find the properties of the system.
2188840	2195000	What is the nature of the system? That's first step kind of thing I was talking about before with
2195640	2203480	structure dependence. What are the properties of the system that an infant automatically
2203480	2209960	develops in the mind? And there's a lot of work on that. From the other point of view, you can say,
2210760	2217080	what can we learn about the brain that relates to this? Actually, there is some work. So there is
2217080	2230920	neurophysiological studies which have shown that for artificial languages that violate the principle
2231640	2238120	that I mentioned, this structure dependent principle, if you train people on those,
2239080	2245480	the ordinary language centers don't function. You get diffuse functioning of the brain,
2245480	2253720	means they're being treated as puzzles basically. So you can find some neurological correlates of
2254440	2260360	some of the things that are discovered by looking at the nature of the phenotype.
2261640	2268840	But it's very hard for humans for a number of reasons. We know a lot about human, the physiology
2268920	2277480	of human vision. But the reason is because of invasive experiments with nonhumans, cats,
2278680	2286200	monkeys and so on. Can't do that for language. There aren't any other organisms unique to humans.
2287000	2293480	So there's no comparative studies. You can think of a lot of invasive experiments which
2293560	2301240	teach you a lot. You can't do them for ethical reasons. So study of the neurophysiology of
2302120	2311240	human cognition is a uniquely hard problem. In its basic elements like language,
2311240	2318920	it's just unique to the species. And in fact, a very recent development in evolutionary history,
2318920	2325880	probably the last couple of hundred thousand years, which is nothing. So you can't do the
2325880	2330760	invasive experiments for ethical reasons. You can think of them, but you can't do them,
2330760	2338120	fortunately. And there's no comparative evidence. So it's much harder to do. You have to do things
2338120	2347160	like, you know, looking at a blood flow in the brain, MRI type things, electrical stimulation,
2347160	2353560	looking from the outside. It's tough. It's not like doing the kind of experiments you can think of.
2354600	2362200	So it's very hard to find out the neurophysiological basis for things like use of language. But
2362920	2367240	it's one way to proceed. And the other way to proceed is learn more about the phenol.
2367800	2378120	It's like chemistry for hundreds of years. You just postulated the existence of atoms.
2379560	2384120	Nobody could see them. You know, why are they there? You know, because unless
2384840	2391640	there are atoms with the Dalton's properties, you don't explain anything. Early genetics,
2392600	2398120	early genetics work before anybody had any idea what a gene is. You just looked at the
2399800	2404040	properties of the system, try to figure out what must be going on.
2405400	2412600	It's the way astrophysics works. You know, most of science works like that. So this does too.
2413320	2421000	When you talk about invasive exploration, there are tools that are increasingly
2421080	2428920	sophisticated. I'm thinking of neural link, Elon Musk's startup that has these super fine
2431080	2439080	electrodes that can be put into the brain without damaging individual neurons.
2440520	2446280	There's actually, I think, much more advanced than that is work that's being done with
2447240	2454360	patients under brain surgery. Under brain surgery, with the brain basically exposed,
2454360	2463160	there are some noninvasive procedures that can be used to study what particular
2464600	2469480	parts of the brain, even particular neurons are doing. It's very delicate work.
2470440	2478280	But there is some work going on. One person is working on it is Andrea Moro,
2478280	2483560	the same person who designed the experiments that I described before about impossible languages.
2484360	2493320	That seems to me a promising direction. There's other kinds of work. I could mention some of it.
2493320	2503000	Alec Moran, why you was doing interesting studies that shed some light on the very
2503000	2512600	elementary function. How do words get stored in the brain? What's going on in the brain that
2514040	2521400	tells us that blake is a possible word, but the nick isn't for an English speaker. It is for
2521480	2526840	an Arabic speaker. What's going on in the brain that deals with that?
2528280	2538040	Hard work. David Peppel, another very good neuroscientist, has found evidence
2539000	2548920	for things like pharyngeal structure in the brain. But the kinds of invasive experiments
2548920	2556200	you can dream of, you can think of, he's just not allowed to do. So you have to try it in much
2556200	2564280	indirect ways. Do you think that understanding cognition has advanced in your lifetime?
2565080	2572120	And are you hopeful that we'll eventually really understand how the brain thinks?
2572200	2584360	Well, there's been vast improvement in understanding the phenotype that we know a great deal about
2584360	2593320	that was not known even a few years ago. There's been some progress in the neuroscience of
2594120	2605880	the relates to it, but it's much harder. Yeah. I'm just curious about where you are in,
2606840	2614040	not physically you're in Arizona, but where you are in your thinking. Are you still
2614200	2629320	pushing forward in trying to understand language in the brain or are you sort of retired, so to speak,
2629320	2636280	at this point? No, very much involved. I mean, I don't work on the neurophysiology.
2636600	2648120	A man I mentioned, Andrea Moro, happens to be a good friend. So I follow the work they're doing,
2648120	2655240	we interact, but my work is just on the phenotype. What's the nature of the system?
2655880	2661480	And there, I think we're learning a lot. I'm right in the middle of papers at the moment,
2662440	2668840	looking at more subtle, complex properties. The idea is essentially to find
2670040	2678760	what I said about binary set formation. How can we show that from the simplest
2679800	2689080	computational procedures, we can account for the apparently complex and apparently varied
2689880	2696200	properties of the language systems. There's a fair amount of progress on that,
2697640	2705480	that was unheard of 20, 30 years ago. So this is all new. Understanding is one thing and then
2706120	2718520	re-creating it through computation in external hardware is another. Is that a blind ally or do
2718520	2727320	you think that? Well, at the moment, I don't see any particular point in it. If there is some point,
2728280	2737240	okay. I mean, the kinds of things that we're learning about the nature of language,
2738360	2743720	I suppose you could construct some sort of system that would duplicate them,
2745320	2754520	but it doesn't seem any obvious point to it. It's like taking chemistry in 100 years ago and saying,
2755400	2758760	can I construct models that will look sort of like,
2759480	2766840	suppose you took, I was saying, a kick of the diagram for an organic molecule
2767960	2774680	and study its properties. You could presumably construct a mechanical model
2775480	2781880	that would do some of those things. Would it be useful? Apparently chemists didn't think so, but
2782520	2787400	if it would, okay. If it wouldn't, then don't.
2790120	2795080	Nonetheless, I mean, we are using neural nets even in this call.
2797080	2806440	Do you see, I mean, setting inside the question of whether or not they help us understand anything
2806440	2814600	about the brain. Are you excited at all in about the promise that these large
2814600	2818680	models hold? I mean, because they do something very useful.
2819800	2827960	They are. Like I said, I'm using it right now. I think it's fine for me, somebody who can't hear
2828040	2836040	to be able to read what you're saying pretty accurately. It's an achievement, so great.
2837400	2845160	I have nothing against technology. And who do you think is going to carry on
2847400	2854840	your work from here? I mean, are there any students of yours who you think we should
2854920	2862120	be paying attention to? Well, quite a lot. A lot of young people doing fine work.
2863000	2868600	In fact, I work with a, closely with a small research group
2870920	2878520	by now, spread all over the world. We meet virtually from Japan and Holland and other places
2878520	2882200	regularly working on the kinds of problems I was talking about.
2883640	2887960	But right now, I should say it's a pretty special interest. Most linguists aren't
2887960	2895880	interested in these foundational questions. But I think that's happened to be my interest.
2895880	2904360	I want to see if we can show the, ultimately try to show that language is essentially a
2904360	2913960	natural object. I mean, there was an interesting paper written about the time that I started
2913960	2922840	working on this by Albert Einstein in 1950. He had an article in Scientific American, which
2923560	2929320	I read, but didn't appreciate at the time, began to appreciate later, in which he talked
2929320	2936440	about what he called a miracle creed. He has an interesting history. It goes back to Galileo.
2937320	2947080	Galileo had a maxim saying, nature is simple. It doesn't do things in a complicated way if it
2947080	2955720	could do them in a simple way. Galileo's maxim couldn't prove it. But they said, I think that's
2955720	2962840	the way it is. That's the task of the scientist to prove it. Well, over the centuries, it's been
2962840	2970840	substantiated case after case. It shows up in Leibniz's principle of optimality. But by then,
2970840	2978760	there was a lot of evidence for it. By now, it's just a norm for science. It's what Einstein called
2978760	2988600	the miracle creed. Nature is simple. Our task is to show it. It says, improve it. Skeptic can say,
2988600	2996920	I don't believe it. Okay. But that's the way science works. Well, this one's worked the same way for
2996920	3004200	language. But you couldn't have proposed that 50 years ago, 20 years ago. I think now you can
3004520	3013000	believe that maybe language is just basically a perfect computational system at its base.
3014120	3020680	You look at the phenomena, it doesn't look like that. But the same was true of biology. Go back to
3020680	3032200	the 1950s, 1960s, biologists assumed that organisms could vary so widely that each one has to be
3032200	3039400	studied on its own without bias. By now, that's all forgotten. It's recognized that there,
3040040	3046360	since the Cambrian explosion, there's virtually no variation in the kinds of organisms,
3047160	3055800	fundamentally all the same. Deep homologies, and so on. So even been proposed that there's a universal
3055800	3063880	genome, not totally accepted, but not considered ridiculous. Well, I think we're in the same
3063880	3069640	direction as the study of language. Now, let me say again, there's not many linguists interested in
3069640	3077000	this. Most linguists, like most biologists, are studying particular things, which is fine. You
3077000	3087240	learn a lot that way. But I think it is possible now to formulate a plausible thesis that language is a
3087960	3094040	natural object like others, which evolved in such a way as to have perfect design,
3094840	3100520	but to be highly dysfunctional. Because that's true of natural objects, generally. It's part of
3100520	3109400	the nature of evolution, which doesn't take into account possible functions. I mean, the last stage
3109400	3117560	of evolution, the reproductive success that does take function into account, natural selection,
3118520	3125560	that's a fringe of evolution. It's just the peripheral fringe, very important, not denigrated,
3125560	3133720	but it's the basic part of evolution is constructing the optimal system that meets
3133720	3140280	the physical conditions established by some disruption in the system. That's the core of
3140280	3150840	evolution. That's what Turing studied. Darcy Thompson, others by now, I think it's understood.
3150840	3157160	And I think maybe the study of this particular biology after a language is a biological object.
3157800	3164440	So why should it be different? Let's see if we can show it. There's been a lot of talk in the news
3164440	3175720	recently about extraterrestrial craft having been found by the government. I don't put much
3175720	3184920	talk in it, but imagine that there is extraterrestrial life, advanced forms of life. Do you think that
3184920	3195800	their language would have developed the same way if it's based on these simple principles? Or is it
3196600	3204840	could there be other forms of language in other biological organisms that would be quote unquote
3204840	3213720	impossible in the human context? Back around the 1960s, I guess, Minsky
3215960	3222680	studied with one of his students, Daniel Belbrom, studied the simplest Turing machines,
3223560	3232040	few estates, fewest symbols, and asked what happens if you just let them run free?
3233000	3242680	Well, it turned out that most of them crash, either get into endless loops or just crash
3243480	3249080	don't proceed. But the ones that didn't crash all produced the successor function.
3250680	3258280	So he suggested what we're going to find if any kind of intelligence develops is
3258840	3265000	it'll be based on the successor function. And if we want to try to communicate with some
3265960	3271160	extraterrestrial intelligence, we should first see if they have the successor function
3272200	3276600	and then maybe build up from there. Well, turns out the successor
3278200	3287480	happens to be what you get from the simplest possible language. The language is one symbol
3287480	3293000	and the simplest form of binary set formation basically gives it a successor function.
3293880	3299480	Add a little bit more to it, you get something like arithmetic. Add a little bit more to it,
3299480	3307880	you get something like the poor properties of language. So it's conceivable that if there is any
3308520	3314920	extraterrestrial intelligence, it would have pursued the same course. Where it goes from there,
3314920	3322920	we don't know enough to say. And back to the idea that there is no super natural realm,
3322920	3331240	that the consciousness is an emergent property from the physical attributes of the brain.
3333880	3342840	Do you believe in a higher intelligence behind the creation or continuation of the universe?
3345640	3355320	I don't see any point in vacuous hypotheses. If you want to believe it okay, it has no consequences.
3357880	3363720	But do you believe it? No, I don't see any point in believing things for
3365160	3371560	which there's no evidence and do no work. And another thing I've always wanted to ask
3372200	3380840	someone like you, clearly your intelligence surpasses most peoples.
3381960	3387560	I don't think so. Well, that's a good, that's interesting that you would say that. You think
3387560	3395160	it's just a matter of applying yourself to study throughout your career.
3395160	3405880	I have certain talents, I know, like not believing things just cause people believe them.
3408120	3415160	And keeping an open mind and looking for arguments and evidence, not
3416360	3421160	anything we've been talking about when meaningless questions are proposed, like
3421160	3429560	our other organism, sentient or the submarine swim, I say let's discard them and look at
3429560	3439240	meaningful questions. If you just pursue common sense like that, I think you can make some progress.
3439240	3445960	Same on the questions we're talking about language. If you think it through, there's every reason why
3446600	3452920	the organic object language should be an object. If so, it should follow the
3453480	3460840	general principles of evolution, which satisfy what Einstein called the miracle creed. So why
3460840	3468680	shouldn't language, so let's pursue that CFR we can do. I think that's just common sense. Many
3468680	3475960	people think it's superior intelligence. I don't think so. That's it for this episode. I want to
3475960	3482520	thank Noam for his time. If you'd like a transcript of this conversation, you can find one on our
3482520	3496040	website, I on AI, that's EYE-ON.AI. In the meantime, remember, the singularity may not be near,
3496040	3506760	but AI is about to change your world. So pay attention.
