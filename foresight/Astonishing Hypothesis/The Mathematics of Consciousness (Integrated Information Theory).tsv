start	end	text
0	16040	On June 11th, 2022, a Washington Post published breaking news.
16040	20600	A Google programmer thought that an AI he interacted with was conscious.
20600	24960	Soon after, several news audits published statements from other AI researchers.
24960	30280	They all said that just because it is acting like a conscious being, does not mean an AI
30280	32040	is conscious.
32040	34120	But one question remained unanswered.
34120	40240	How do we know if an AI, or let's say a human being, is conscious?
40240	45040	This is a serious problem, and there are many ethical implications.
45040	50880	For example, we do not know for sure whether animals are conscious, and we do not know
50880	54580	when consciousness arises to a human development.
54580	61180	We can also never be entirely sure whether someone who seems unconscious really has no
61180	62340	consciousness.
62340	67100	Some patients have been shown to remain conscious during anesthesia.
67100	73780	Other patients were found to be conscious after being diagnosed as comatose.
73780	77940	And the problem is not just that we cannot rely on behavior.
77940	84020	We also do not know for sure if someone is conscious by measuring their brain activity.
84020	88860	We have not yet found a reliable biomarker of consciousness.
88860	93200	What we lack is a rigorous scientific theory.
93200	98260	The mathematical equations of such a scientific theory of consciousness should allow us to
98260	102660	determine if someone or something is conscious.
102660	108180	That is, a mathematical theory of consciousness should tell us if an artificial intelligence
108180	109980	is conscious.
109980	114980	Using this math, we should also be able to compute if someone is comatose anesthetized
114980	118500	when dreamless sleep using their brain activity.
118500	123700	More than that, such a theory should allow us to tell what someone is conscious of.
123700	128160	In other words, we should be able to peek into someone's consciousness by applying this
128160	132940	math to neural data measured from their brain.
132940	135580	Does this sound too fantastical?
135580	138740	Well it turns out that such a theory already exists.
138740	144180	This theory is called Integrated Information Theory or IIT for short.
144180	149820	IIT has originally been put forward by neuroscientist Giulia Tornoni in 2008.
149820	155100	IIT has since gained wide support by other leading neuroscientists such as the director
155100	159020	of the Allen Institute, Christoph Koch and many others.
159020	165220	IIT can be expressed as equations, such as these, but IIT is much simpler than it may
165220	166220	seem.
166220	169740	If you are watching, at the end of this video, you will fully understand the mathematics
169740	172700	of IIT and what we can do with it.
172700	176740	IIT starts with a small set of axioms.
176740	181060	Axioms are statements that seem reasonable to accept without proof.
181060	184020	The first axiom is intrinsic existence.
184020	187940	This simply means that we accept that our consciousness exists.
187940	193340	Moreover, our consciousness exists independently of external observers.
193340	196700	If this sounds too philosophical to you, do not worry.
196700	200060	We just need a solid starting point for the theory.
200060	206500	As you will see in a moment, this axiom nicely translates into mathematical equations.
206500	210300	The second axiom of IIT is about information.
210300	213620	Information here just means that consciousness differentiates.
213620	219300	For example, whenever we do not see an elephant, we gain the information that we are not looking
219300	220880	at an elephant.
220880	226120	This definition of information is very different from classic information theory.
226120	231720	As you will see in a moment, IIT does not measure information in bytes or bits.
231720	234280	The third axiom is about integration.
234280	238220	This just means that we have only one consciousness.
238220	242280	We do not have many different fragments of consciousness at the same time.
242280	246700	Our consciousness is unified into a cohesive whole.
246700	250400	The fourth axiom of IIT is composition.
250440	252320	This is as trivial as it sounds.
252320	255040	It means that our consciousness is structured.
255040	258320	We experience different things across space and time.
258320	260620	There is one more axiom.
260620	262920	This axiom is exclusion.
262920	266320	This means that there are boundaries to a conscious experience.
266320	271720	For example, we are only visually conscious of the world in front of us.
271720	274560	If you question one or more of these axioms, do not worry.
274560	279160	There are many axioms in mathematics that are contentious yet useful.
279520	282480	How do we get from these axioms to the rest of the math?
282480	288000	IIT builds on its axioms using hypotheses called postulates.
288000	293200	Postulates translate from the axiomatic properties of consciousness to mathematical characteristics
293200	295200	of a physical system.
295200	301480	In other words, IIT tells us what a system must be like to produce consciousness.
301480	309000	Now, what mathematical descriptions of a system might account for the properties of consciousness?
309000	312520	Then let us first define what IIT means by system.
312520	318760	Well, a system is just a set of things that interact.
318760	320280	Interaction is key.
320280	325080	Remember that the first axiom said that consciousness exists.
325080	329720	Science can only assume the existence of things that interact with other things.
329720	334040	Thus, interaction is the basis of existence.
334040	335120	See how this works?
335120	340440	If we accept that consciousness exists, we can assume that a physical system that produces
340440	344400	consciousness must contain interacting elements.
344400	352760	This is the kind of logic that IIT uses to translate from its axioms to its postulates.
352760	356920	Now let us mathematically formalize what we just said.
356920	361480	Each system consists of two or more elements.
361480	367520	Typically an element can be represented as a discrete variable x sub i.
367520	369560	Elements are defined by three properties.
369560	372560	First, they can have at least two states.
372560	377280	Second, they receive inputs from other elements that can change these states.
377280	381600	And third, they have outputs that depend on these states.
381600	387920	The interacting elements x sub i to sub n form system sub t, where t denotes the present
387920	389440	moment in time.
389440	395280	To keep things easy, let's assume that our four elements here are brain cells or neurons.
395280	399760	As you might know, neurons can either be in an on or off state.
399760	403400	We will indicate these states as unfilled or filled disks.
403400	410320	As all disks are unfilled, all four neurons are off at the current time point t.
410320	415960	Now we said that in order for consciousness to exist, there need to be causal interactions.
415960	418760	These are visualized here by white lines.
418760	421480	How do we define a causal interaction?
421480	428120	Well, remember that each element must have an output that depends on its current state.
428120	431920	These outputs become inputs to other elements.
431920	437160	These inputs define whether or not elements change in state.
437160	444000	So using outputs, single elements, or a combination of elements acting in concert can change the
444000	446320	state of other elements.
446320	449600	That is a causal interaction.
449600	455560	If a subgroup of the system, such as a single element, or a combination thereof, influences
455560	461000	the overall system state, we call that a causal mechanism.
461000	464120	Let us denote mechanisms with y.
464120	471880	And to keep things simple again, let us assume that each element of our model is also a mechanism.
471880	476840	Of course, if we consider the brain, we can think of neurons as elements that are also
476840	477840	mechanisms.
477840	483160	But the mathematics of IIT is more general, as the same concept applies to other brain
483160	487480	structures or even AI.
487480	494000	Now IIT's general idea is to determine whether a system integrates information.
494000	499600	Integrated information is quantified as how much a mechanism in a particular state makes
499600	502720	a difference to the system as a whole.
502720	508200	One way this can be done is by cutting a mechanism out of a system.
508200	513840	If such a cut makes a difference, we can quantify how big that difference is.
513840	515840	How is that done in practice?
515840	520880	Remember, each element has a state, receives inputs, and produces an output.
520880	525000	In our little system, each neuron receives three inputs.
525000	530960	The inputs each neuron receives depend on the state of the other neurons that send their
530960	532640	output to this neuron.
532640	539560	So in our case, each neuron receives a zero or a one from three other neurons depending
539560	542360	on their off or on state.
542360	547560	Real-life neurons perform simple computations, such as summing up their inputs.
547560	552720	If the sum is larger than a certain threshold, neurons change their state from off to on.
552720	558040	So depending on its inputs, a neuron may or may not change its state.
558040	560640	And this state becomes its output.
560640	565840	In our model system, the output is split, so that each of the other neurons receives
565840	567440	an input.
567440	571200	But these are all just copies of the same output.
571200	576960	This means we can describe all possible interactions of this neuron by creating a table.
576960	583400	This table lists all possible combinations of three binary inputs and resulting states.
583400	588040	The resulting state equals that neuron's output.
588040	591600	As we said, real-life neurons sum up inputs.
591600	594720	If the sum is large enough, they turn on.
594720	599040	We can replicate this process in our system by assuming the neuron's threshold to be
599040	600600	three.
600600	606680	In other words, we define a neuron's state to be on, or one, if, and only if, all three
606680	608680	of its inputs are one.
608680	613720	But differently, our model neuron's output is always zero, except when all three of its
613720	615840	inputs are one.
615840	620880	An input-output relationship, such as this, is called an AND gate.
620880	622600	You can probably see why.
622600	631200	The output of this gate is only one if its input 1, and 2, and 3 are all one.
631200	637320	Now let us assume our neuron is much more sensitive and has a much lower threshold for
637320	638320	its summed inputs.
638320	640400	Let's say it's set to one.
640400	643440	In this case, we end up with a very different table.
643440	647520	This kind of table resembles a different logic gate, called OR.
647520	648680	You can see why.
648680	655840	This gate is one if input 1, OR 2, OR 3, OR 1.
655840	658840	Such logic gates are at the heart of computers.
658840	664320	However, keep in mind that actual neurons are much more complicated than that.
664320	666600	So here's our model system again.
666600	671960	Except now we mark for each neuron what kind of input-output table or matrix we have defined
671960	672960	for them.
672960	678840	Now, looking at a single moment in time is not very helpful, since nothing is changing.
678840	684440	And since we're after causal interactions, it is change that we're interested in.
684440	689360	So instead of freezing the system at a single moment, let us look at how the system evolves
689360	690360	over time.
690360	699520	T0 is the current moment, minus 1 is the immediate past, and T plus 1 is one step in the future.
699520	706480	The connections between neurons will be shown between one slice of time and the next one.
706480	710720	In order to calculate the amount of integrated information of a system, we first need to
710720	715200	evaluate the information generated by each single mechanism.
715200	721800	This is done by computing how much each mechanism affects the system as a whole.
721800	728280	This influence is quantifiable, since the current state of a mechanism constrains which
728280	730920	system states can occur.
730920	733280	And IIT goes a step further.
733280	738640	By knowing that a mechanism is in its current state, we also obtain information about the
738640	745560	past, since only a subset of all possible system states can lead up to the mechanism
745560	747600	being in its current state.
747600	752480	This means that a mechanism does not just constrain future possibilities, but in some
752480	756360	sense also constrains the past.
756360	757920	Let's start with the latter.
757920	762680	Suppose we don't know anything about current or past system states.
762680	767040	What would the probability of each possible past state be?
767440	772760	IIT calls this the unconstrained probability or PUC.
772760	776920	For our four neurons, there are 16 possible past states.
776920	782040	We can symbolize these states using zeros and ones, for often on-states of these neurons
782040	783040	respectively.
783040	789400	If we do that, we get a table where each row represents a possible past state.
789400	795080	Since each state is equally likely, our distribution PUC is uniform.
795080	800200	All possible past states might have happened with a probability of 1 over 16.
800200	805600	But remember, this unconstrained probability is due to the fact that we lack information
805600	809520	about mechanism and system states in the present.
809520	814400	Now let's suppose that we know that mechanism X1 is currently in an on state.
814400	819800	Since mechanism X1 only turns on when all of its inputs were on, we can derive a very
819800	823280	different probability distribution of past states.
823280	827400	We now know that there can only have been two past states.
827400	829120	Both states were equally likely.
829120	834720	This means that the conditional probability of each of these states was 0.5.
834720	840000	The resulting distribution is called the cos repertoire of mechanism X1.
840000	847360	This example shows how one can gain information about a system's past by knowing the present.
847360	850080	But how do we quantify that information?
850080	855520	IIT does that by calculating the distance between the unconstrained and the conditional
855520	857400	probability distributions.
857400	861720	The result is called the cos information.
861720	867400	Now that we have seen how we can quantify information about the past that is gained by considering
867400	872440	a given mechanism in its current state, we can apply the same principle to future states.
872440	877040	In other words, we can derive an unconstrained probability of future states as well as the
877040	882200	conditional probabilities of future states given the current state of mechanism X1.
882200	885760	The latter distribution is called the effect repertoire.
885760	890040	Then we calculate the distance between these two distributions.
890040	895840	The resulting number is the effect information of mechanism X1.
895840	896840	Let's recap.
896840	902040	We have seen how IIT quantifies information within a cos system that is contingent upon
902040	905760	or constrained by a mechanism in its current state.
905760	911960	The result of this process are two numbers, the cos information and the effect information.
911960	917280	Of course, both these numbers were specific to a single mechanism in a specific state.
917280	921520	In this case, we looked at mechanism X1, presently being on.
921520	927920	If it were off, both the cos information and the effect information would change accordingly.
927920	929880	And what about the other mechanisms?
929880	934040	Well, if we know the present state of the system, we can simply repeat everything we
934040	936280	have done so far for each of them.
936280	941480	Each time, we obtain the cos information and effect information given that mechanism's
941480	943280	current state.
943280	948120	The final step is to decide whether the cos information or the effect information are
948120	950680	more important to the system.
950680	957000	Since IIT claims to characterize the capacity of a system, it sees the minimum of the two
957000	958460	as a bottleneck.
958460	961920	This bottleneck can be thought of as the weakest link that breaks the chain.
962200	967160	Thus, whatever is the minimum between the cos information and the effect information
967160	973440	is carried forward as the cos effect information of the mechanism being in its current state.
973440	980680	Okay, this explains how IIT quantifies information, but how do we quantify integration?
980680	986040	As it turns out, we can use the same algorithm of comparing probability distributions for
986040	988440	this quantification as well.
988440	994700	Specifically, we eliminate each connection between a mechanism and the rest of the system
994700	996960	and see if that makes any difference.
996960	1001680	If the system's probability distributions do not change after we eliminate a connection,
1001680	1007480	we can deduce that the connection was reducible and there was no integration.
1007480	1012540	In practice, this is done by a process called statistical noising or marginalizing.
1012540	1018980	This just means replacing the inputs provided by our connection with a random noise distribution.
1018980	1026420	Then we compute the distance between the partitioned and unpartitioned probability distributions.
1026420	1031100	Once we have done that, for all connections, we determine which elimination resulted in
1031100	1033580	the smallest change.
1033580	1038740	The partition that yielded the smallest distance is called the minimum information partition
1038740	1044980	or MIP, and the result of that computation is the amount of integrated information, or
1044980	1049980	small phi, that is generated by the mechanism.
1049980	1055260	Now we can compute both the past integrated information as well as the future integrated
1055260	1056420	information.
1056420	1061700	As long as both are larger than zero, we can take the minimum to derive the cos effect
1061700	1065380	integrated information for a mechanism.
1065380	1069620	Of course, this computation only provided the integrated information on the level of
1069620	1073100	mechanisms, such as individual neurons.
1073100	1076260	How do we get from here to the whole brain and consciousness?
1076260	1081380	Well, we can use the same algorithm of replacing connections with noise, not just for seeing
1081380	1085780	on mechanisms, but also whole subsystems of a system.
1085780	1086780	So there you are.
1086780	1090340	There's a lot more to say of course, but this is the gist of it.
1090340	1094940	You now understand that IIT provides a simple piece of math that links brain and mind.
1094980	1099900	By computing the integrated information of a neural system, we can finally start to work
1099900	1102380	on finding out more about consciousness.
