1
00:00:00,000 --> 00:00:16,040
On June 11th, 2022, a Washington Post published breaking news.

2
00:00:16,040 --> 00:00:20,600
A Google programmer thought that an AI he interacted with was conscious.

3
00:00:20,600 --> 00:00:24,960
Soon after, several news audits published statements from other AI researchers.

4
00:00:24,960 --> 00:00:30,280
They all said that just because it is acting like a conscious being, does not mean an AI

5
00:00:30,280 --> 00:00:32,040
is conscious.

6
00:00:32,040 --> 00:00:34,120
But one question remained unanswered.

7
00:00:34,120 --> 00:00:40,240
How do we know if an AI, or let's say a human being, is conscious?

8
00:00:40,240 --> 00:00:45,040
This is a serious problem, and there are many ethical implications.

9
00:00:45,040 --> 00:00:50,880
For example, we do not know for sure whether animals are conscious, and we do not know

10
00:00:50,880 --> 00:00:54,580
when consciousness arises to a human development.

11
00:00:54,580 --> 00:01:01,180
We can also never be entirely sure whether someone who seems unconscious really has no

12
00:01:01,180 --> 00:01:02,340
consciousness.

13
00:01:02,340 --> 00:01:07,100
Some patients have been shown to remain conscious during anesthesia.

14
00:01:07,100 --> 00:01:13,780
Other patients were found to be conscious after being diagnosed as comatose.

15
00:01:13,780 --> 00:01:17,940
And the problem is not just that we cannot rely on behavior.

16
00:01:17,940 --> 00:01:24,020
We also do not know for sure if someone is conscious by measuring their brain activity.

17
00:01:24,020 --> 00:01:28,860
We have not yet found a reliable biomarker of consciousness.

18
00:01:28,860 --> 00:01:33,200
What we lack is a rigorous scientific theory.

19
00:01:33,200 --> 00:01:38,260
The mathematical equations of such a scientific theory of consciousness should allow us to

20
00:01:38,260 --> 00:01:42,660
determine if someone or something is conscious.

21
00:01:42,660 --> 00:01:48,180
That is, a mathematical theory of consciousness should tell us if an artificial intelligence

22
00:01:48,180 --> 00:01:49,980
is conscious.

23
00:01:49,980 --> 00:01:54,980
Using this math, we should also be able to compute if someone is comatose anesthetized

24
00:01:54,980 --> 00:01:58,500
when dreamless sleep using their brain activity.

25
00:01:58,500 --> 00:02:03,700
More than that, such a theory should allow us to tell what someone is conscious of.

26
00:02:03,700 --> 00:02:08,160
In other words, we should be able to peek into someone's consciousness by applying this

27
00:02:08,160 --> 00:02:12,940
math to neural data measured from their brain.

28
00:02:12,940 --> 00:02:15,580
Does this sound too fantastical?

29
00:02:15,580 --> 00:02:18,740
Well it turns out that such a theory already exists.

30
00:02:18,740 --> 00:02:24,180
This theory is called Integrated Information Theory or IIT for short.

31
00:02:24,180 --> 00:02:29,820
IIT has originally been put forward by neuroscientist Giulia Tornoni in 2008.

32
00:02:29,820 --> 00:02:35,100
IIT has since gained wide support by other leading neuroscientists such as the director

33
00:02:35,100 --> 00:02:39,020
of the Allen Institute, Christoph Koch and many others.

34
00:02:39,020 --> 00:02:45,220
IIT can be expressed as equations, such as these, but IIT is much simpler than it may

35
00:02:45,220 --> 00:02:46,220
seem.

36
00:02:46,220 --> 00:02:49,740
If you are watching, at the end of this video, you will fully understand the mathematics

37
00:02:49,740 --> 00:02:52,700
of IIT and what we can do with it.

38
00:02:52,700 --> 00:02:56,740
IIT starts with a small set of axioms.

39
00:02:56,740 --> 00:03:01,060
Axioms are statements that seem reasonable to accept without proof.

40
00:03:01,060 --> 00:03:04,020
The first axiom is intrinsic existence.

41
00:03:04,020 --> 00:03:07,940
This simply means that we accept that our consciousness exists.

42
00:03:07,940 --> 00:03:13,340
Moreover, our consciousness exists independently of external observers.

43
00:03:13,340 --> 00:03:16,700
If this sounds too philosophical to you, do not worry.

44
00:03:16,700 --> 00:03:20,060
We just need a solid starting point for the theory.

45
00:03:20,060 --> 00:03:26,500
As you will see in a moment, this axiom nicely translates into mathematical equations.

46
00:03:26,500 --> 00:03:30,300
The second axiom of IIT is about information.

47
00:03:30,300 --> 00:03:33,620
Information here just means that consciousness differentiates.

48
00:03:33,620 --> 00:03:39,300
For example, whenever we do not see an elephant, we gain the information that we are not looking

49
00:03:39,300 --> 00:03:40,880
at an elephant.

50
00:03:40,880 --> 00:03:46,120
This definition of information is very different from classic information theory.

51
00:03:46,120 --> 00:03:51,720
As you will see in a moment, IIT does not measure information in bytes or bits.

52
00:03:51,720 --> 00:03:54,280
The third axiom is about integration.

53
00:03:54,280 --> 00:03:58,220
This just means that we have only one consciousness.

54
00:03:58,220 --> 00:04:02,280
We do not have many different fragments of consciousness at the same time.

55
00:04:02,280 --> 00:04:06,700
Our consciousness is unified into a cohesive whole.

56
00:04:06,700 --> 00:04:10,400
The fourth axiom of IIT is composition.

57
00:04:10,440 --> 00:04:12,320
This is as trivial as it sounds.

58
00:04:12,320 --> 00:04:15,040
It means that our consciousness is structured.

59
00:04:15,040 --> 00:04:18,320
We experience different things across space and time.

60
00:04:18,320 --> 00:04:20,620
There is one more axiom.

61
00:04:20,620 --> 00:04:22,920
This axiom is exclusion.

62
00:04:22,920 --> 00:04:26,320
This means that there are boundaries to a conscious experience.

63
00:04:26,320 --> 00:04:31,720
For example, we are only visually conscious of the world in front of us.

64
00:04:31,720 --> 00:04:34,560
If you question one or more of these axioms, do not worry.

65
00:04:34,560 --> 00:04:39,160
There are many axioms in mathematics that are contentious yet useful.

66
00:04:39,520 --> 00:04:42,480
How do we get from these axioms to the rest of the math?

67
00:04:42,480 --> 00:04:48,000
IIT builds on its axioms using hypotheses called postulates.

68
00:04:48,000 --> 00:04:53,200
Postulates translate from the axiomatic properties of consciousness to mathematical characteristics

69
00:04:53,200 --> 00:04:55,200
of a physical system.

70
00:04:55,200 --> 00:05:01,480
In other words, IIT tells us what a system must be like to produce consciousness.

71
00:05:01,480 --> 00:05:09,000
Now, what mathematical descriptions of a system might account for the properties of consciousness?

72
00:05:09,000 --> 00:05:12,520
Then let us first define what IIT means by system.

73
00:05:12,520 --> 00:05:18,760
Well, a system is just a set of things that interact.

74
00:05:18,760 --> 00:05:20,280
Interaction is key.

75
00:05:20,280 --> 00:05:25,080
Remember that the first axiom said that consciousness exists.

76
00:05:25,080 --> 00:05:29,720
Science can only assume the existence of things that interact with other things.

77
00:05:29,720 --> 00:05:34,040
Thus, interaction is the basis of existence.

78
00:05:34,040 --> 00:05:35,120
See how this works?

79
00:05:35,120 --> 00:05:40,440
If we accept that consciousness exists, we can assume that a physical system that produces

80
00:05:40,440 --> 00:05:44,400
consciousness must contain interacting elements.

81
00:05:44,400 --> 00:05:52,760
This is the kind of logic that IIT uses to translate from its axioms to its postulates.

82
00:05:52,760 --> 00:05:56,920
Now let us mathematically formalize what we just said.

83
00:05:56,920 --> 00:06:01,480
Each system consists of two or more elements.

84
00:06:01,480 --> 00:06:07,520
Typically an element can be represented as a discrete variable x sub i.

85
00:06:07,520 --> 00:06:09,560
Elements are defined by three properties.

86
00:06:09,560 --> 00:06:12,560
First, they can have at least two states.

87
00:06:12,560 --> 00:06:17,280
Second, they receive inputs from other elements that can change these states.

88
00:06:17,280 --> 00:06:21,600
And third, they have outputs that depend on these states.

89
00:06:21,600 --> 00:06:27,920
The interacting elements x sub i to sub n form system sub t, where t denotes the present

90
00:06:27,920 --> 00:06:29,440
moment in time.

91
00:06:29,440 --> 00:06:35,280
To keep things easy, let's assume that our four elements here are brain cells or neurons.

92
00:06:35,280 --> 00:06:39,760
As you might know, neurons can either be in an on or off state.

93
00:06:39,760 --> 00:06:43,400
We will indicate these states as unfilled or filled disks.

94
00:06:43,400 --> 00:06:50,320
As all disks are unfilled, all four neurons are off at the current time point t.

95
00:06:50,320 --> 00:06:55,960
Now we said that in order for consciousness to exist, there need to be causal interactions.

96
00:06:55,960 --> 00:06:58,760
These are visualized here by white lines.

97
00:06:58,760 --> 00:07:01,480
How do we define a causal interaction?

98
00:07:01,480 --> 00:07:08,120
Well, remember that each element must have an output that depends on its current state.

99
00:07:08,120 --> 00:07:11,920
These outputs become inputs to other elements.

100
00:07:11,920 --> 00:07:17,160
These inputs define whether or not elements change in state.

101
00:07:17,160 --> 00:07:24,000
So using outputs, single elements, or a combination of elements acting in concert can change the

102
00:07:24,000 --> 00:07:26,320
state of other elements.

103
00:07:26,320 --> 00:07:29,600
That is a causal interaction.

104
00:07:29,600 --> 00:07:35,560
If a subgroup of the system, such as a single element, or a combination thereof, influences

105
00:07:35,560 --> 00:07:41,000
the overall system state, we call that a causal mechanism.

106
00:07:41,000 --> 00:07:44,120
Let us denote mechanisms with y.

107
00:07:44,120 --> 00:07:51,880
And to keep things simple again, let us assume that each element of our model is also a mechanism.

108
00:07:51,880 --> 00:07:56,840
Of course, if we consider the brain, we can think of neurons as elements that are also

109
00:07:56,840 --> 00:07:57,840
mechanisms.

110
00:07:57,840 --> 00:08:03,160
But the mathematics of IIT is more general, as the same concept applies to other brain

111
00:08:03,160 --> 00:08:07,480
structures or even AI.

112
00:08:07,480 --> 00:08:14,000
Now IIT's general idea is to determine whether a system integrates information.

113
00:08:14,000 --> 00:08:19,600
Integrated information is quantified as how much a mechanism in a particular state makes

114
00:08:19,600 --> 00:08:22,720
a difference to the system as a whole.

115
00:08:22,720 --> 00:08:28,200
One way this can be done is by cutting a mechanism out of a system.

116
00:08:28,200 --> 00:08:33,840
If such a cut makes a difference, we can quantify how big that difference is.

117
00:08:33,840 --> 00:08:35,840
How is that done in practice?

118
00:08:35,840 --> 00:08:40,880
Remember, each element has a state, receives inputs, and produces an output.

119
00:08:40,880 --> 00:08:45,000
In our little system, each neuron receives three inputs.

120
00:08:45,000 --> 00:08:50,960
The inputs each neuron receives depend on the state of the other neurons that send their

121
00:08:50,960 --> 00:08:52,640
output to this neuron.

122
00:08:52,640 --> 00:08:59,560
So in our case, each neuron receives a zero or a one from three other neurons depending

123
00:08:59,560 --> 00:09:02,360
on their off or on state.

124
00:09:02,360 --> 00:09:07,560
Real-life neurons perform simple computations, such as summing up their inputs.

125
00:09:07,560 --> 00:09:12,720
If the sum is larger than a certain threshold, neurons change their state from off to on.

126
00:09:12,720 --> 00:09:18,040
So depending on its inputs, a neuron may or may not change its state.

127
00:09:18,040 --> 00:09:20,640
And this state becomes its output.

128
00:09:20,640 --> 00:09:25,840
In our model system, the output is split, so that each of the other neurons receives

129
00:09:25,840 --> 00:09:27,440
an input.

130
00:09:27,440 --> 00:09:31,200
But these are all just copies of the same output.

131
00:09:31,200 --> 00:09:36,960
This means we can describe all possible interactions of this neuron by creating a table.

132
00:09:36,960 --> 00:09:43,400
This table lists all possible combinations of three binary inputs and resulting states.

133
00:09:43,400 --> 00:09:48,040
The resulting state equals that neuron's output.

134
00:09:48,040 --> 00:09:51,600
As we said, real-life neurons sum up inputs.

135
00:09:51,600 --> 00:09:54,720
If the sum is large enough, they turn on.

136
00:09:54,720 --> 00:09:59,040
We can replicate this process in our system by assuming the neuron's threshold to be

137
00:09:59,040 --> 00:10:00,600
three.

138
00:10:00,600 --> 00:10:06,680
In other words, we define a neuron's state to be on, or one, if, and only if, all three

139
00:10:06,680 --> 00:10:08,680
of its inputs are one.

140
00:10:08,680 --> 00:10:13,720
But differently, our model neuron's output is always zero, except when all three of its

141
00:10:13,720 --> 00:10:15,840
inputs are one.

142
00:10:15,840 --> 00:10:20,880
An input-output relationship, such as this, is called an AND gate.

143
00:10:20,880 --> 00:10:22,600
You can probably see why.

144
00:10:22,600 --> 00:10:31,200
The output of this gate is only one if its input 1, and 2, and 3 are all one.

145
00:10:31,200 --> 00:10:37,320
Now let us assume our neuron is much more sensitive and has a much lower threshold for

146
00:10:37,320 --> 00:10:38,320
its summed inputs.

147
00:10:38,320 --> 00:10:40,400
Let's say it's set to one.

148
00:10:40,400 --> 00:10:43,440
In this case, we end up with a very different table.

149
00:10:43,440 --> 00:10:47,520
This kind of table resembles a different logic gate, called OR.

150
00:10:47,520 --> 00:10:48,680
You can see why.

151
00:10:48,680 --> 00:10:55,840
This gate is one if input 1, OR 2, OR 3, OR 1.

152
00:10:55,840 --> 00:10:58,840
Such logic gates are at the heart of computers.

153
00:10:58,840 --> 00:11:04,320
However, keep in mind that actual neurons are much more complicated than that.

154
00:11:04,320 --> 00:11:06,600
So here's our model system again.

155
00:11:06,600 --> 00:11:11,960
Except now we mark for each neuron what kind of input-output table or matrix we have defined

156
00:11:11,960 --> 00:11:12,960
for them.

157
00:11:12,960 --> 00:11:18,840
Now, looking at a single moment in time is not very helpful, since nothing is changing.

158
00:11:18,840 --> 00:11:24,440
And since we're after causal interactions, it is change that we're interested in.

159
00:11:24,440 --> 00:11:29,360
So instead of freezing the system at a single moment, let us look at how the system evolves

160
00:11:29,360 --> 00:11:30,360
over time.

161
00:11:30,360 --> 00:11:39,520
T0 is the current moment, minus 1 is the immediate past, and T plus 1 is one step in the future.

162
00:11:39,520 --> 00:11:46,480
The connections between neurons will be shown between one slice of time and the next one.

163
00:11:46,480 --> 00:11:50,720
In order to calculate the amount of integrated information of a system, we first need to

164
00:11:50,720 --> 00:11:55,200
evaluate the information generated by each single mechanism.

165
00:11:55,200 --> 00:12:01,800
This is done by computing how much each mechanism affects the system as a whole.

166
00:12:01,800 --> 00:12:08,280
This influence is quantifiable, since the current state of a mechanism constrains which

167
00:12:08,280 --> 00:12:10,920
system states can occur.

168
00:12:10,920 --> 00:12:13,280
And IIT goes a step further.

169
00:12:13,280 --> 00:12:18,640
By knowing that a mechanism is in its current state, we also obtain information about the

170
00:12:18,640 --> 00:12:25,560
past, since only a subset of all possible system states can lead up to the mechanism

171
00:12:25,560 --> 00:12:27,600
being in its current state.

172
00:12:27,600 --> 00:12:32,480
This means that a mechanism does not just constrain future possibilities, but in some

173
00:12:32,480 --> 00:12:36,360
sense also constrains the past.

174
00:12:36,360 --> 00:12:37,920
Let's start with the latter.

175
00:12:37,920 --> 00:12:42,680
Suppose we don't know anything about current or past system states.

176
00:12:42,680 --> 00:12:47,040
What would the probability of each possible past state be?

177
00:12:47,440 --> 00:12:52,760
IIT calls this the unconstrained probability or PUC.

178
00:12:52,760 --> 00:12:56,920
For our four neurons, there are 16 possible past states.

179
00:12:56,920 --> 00:13:02,040
We can symbolize these states using zeros and ones, for often on-states of these neurons

180
00:13:02,040 --> 00:13:03,040
respectively.

181
00:13:03,040 --> 00:13:09,400
If we do that, we get a table where each row represents a possible past state.

182
00:13:09,400 --> 00:13:15,080
Since each state is equally likely, our distribution PUC is uniform.

183
00:13:15,080 --> 00:13:20,200
All possible past states might have happened with a probability of 1 over 16.

184
00:13:20,200 --> 00:13:25,600
But remember, this unconstrained probability is due to the fact that we lack information

185
00:13:25,600 --> 00:13:29,520
about mechanism and system states in the present.

186
00:13:29,520 --> 00:13:34,400
Now let's suppose that we know that mechanism X1 is currently in an on state.

187
00:13:34,400 --> 00:13:39,800
Since mechanism X1 only turns on when all of its inputs were on, we can derive a very

188
00:13:39,800 --> 00:13:43,280
different probability distribution of past states.

189
00:13:43,280 --> 00:13:47,400
We now know that there can only have been two past states.

190
00:13:47,400 --> 00:13:49,120
Both states were equally likely.

191
00:13:49,120 --> 00:13:54,720
This means that the conditional probability of each of these states was 0.5.

192
00:13:54,720 --> 00:14:00,000
The resulting distribution is called the cos repertoire of mechanism X1.

193
00:14:00,000 --> 00:14:07,360
This example shows how one can gain information about a system's past by knowing the present.

194
00:14:07,360 --> 00:14:10,080
But how do we quantify that information?

195
00:14:10,080 --> 00:14:15,520
IIT does that by calculating the distance between the unconstrained and the conditional

196
00:14:15,520 --> 00:14:17,400
probability distributions.

197
00:14:17,400 --> 00:14:21,720
The result is called the cos information.

198
00:14:21,720 --> 00:14:27,400
Now that we have seen how we can quantify information about the past that is gained by considering

199
00:14:27,400 --> 00:14:32,440
a given mechanism in its current state, we can apply the same principle to future states.

200
00:14:32,440 --> 00:14:37,040
In other words, we can derive an unconstrained probability of future states as well as the

201
00:14:37,040 --> 00:14:42,200
conditional probabilities of future states given the current state of mechanism X1.

202
00:14:42,200 --> 00:14:45,760
The latter distribution is called the effect repertoire.

203
00:14:45,760 --> 00:14:50,040
Then we calculate the distance between these two distributions.

204
00:14:50,040 --> 00:14:55,840
The resulting number is the effect information of mechanism X1.

205
00:14:55,840 --> 00:14:56,840
Let's recap.

206
00:14:56,840 --> 00:15:02,040
We have seen how IIT quantifies information within a cos system that is contingent upon

207
00:15:02,040 --> 00:15:05,760
or constrained by a mechanism in its current state.

208
00:15:05,760 --> 00:15:11,960
The result of this process are two numbers, the cos information and the effect information.

209
00:15:11,960 --> 00:15:17,280
Of course, both these numbers were specific to a single mechanism in a specific state.

210
00:15:17,280 --> 00:15:21,520
In this case, we looked at mechanism X1, presently being on.

211
00:15:21,520 --> 00:15:27,920
If it were off, both the cos information and the effect information would change accordingly.

212
00:15:27,920 --> 00:15:29,880
And what about the other mechanisms?

213
00:15:29,880 --> 00:15:34,040
Well, if we know the present state of the system, we can simply repeat everything we

214
00:15:34,040 --> 00:15:36,280
have done so far for each of them.

215
00:15:36,280 --> 00:15:41,480
Each time, we obtain the cos information and effect information given that mechanism's

216
00:15:41,480 --> 00:15:43,280
current state.

217
00:15:43,280 --> 00:15:48,120
The final step is to decide whether the cos information or the effect information are

218
00:15:48,120 --> 00:15:50,680
more important to the system.

219
00:15:50,680 --> 00:15:57,000
Since IIT claims to characterize the capacity of a system, it sees the minimum of the two

220
00:15:57,000 --> 00:15:58,460
as a bottleneck.

221
00:15:58,460 --> 00:16:01,920
This bottleneck can be thought of as the weakest link that breaks the chain.

222
00:16:02,200 --> 00:16:07,160
Thus, whatever is the minimum between the cos information and the effect information

223
00:16:07,160 --> 00:16:13,440
is carried forward as the cos effect information of the mechanism being in its current state.

224
00:16:13,440 --> 00:16:20,680
Okay, this explains how IIT quantifies information, but how do we quantify integration?

225
00:16:20,680 --> 00:16:26,040
As it turns out, we can use the same algorithm of comparing probability distributions for

226
00:16:26,040 --> 00:16:28,440
this quantification as well.

227
00:16:28,440 --> 00:16:34,700
Specifically, we eliminate each connection between a mechanism and the rest of the system

228
00:16:34,700 --> 00:16:36,960
and see if that makes any difference.

229
00:16:36,960 --> 00:16:41,680
If the system's probability distributions do not change after we eliminate a connection,

230
00:16:41,680 --> 00:16:47,480
we can deduce that the connection was reducible and there was no integration.

231
00:16:47,480 --> 00:16:52,540
In practice, this is done by a process called statistical noising or marginalizing.

232
00:16:52,540 --> 00:16:58,980
This just means replacing the inputs provided by our connection with a random noise distribution.

233
00:16:58,980 --> 00:17:06,420
Then we compute the distance between the partitioned and unpartitioned probability distributions.

234
00:17:06,420 --> 00:17:11,100
Once we have done that, for all connections, we determine which elimination resulted in

235
00:17:11,100 --> 00:17:13,580
the smallest change.

236
00:17:13,580 --> 00:17:18,740
The partition that yielded the smallest distance is called the minimum information partition

237
00:17:18,740 --> 00:17:24,980
or MIP, and the result of that computation is the amount of integrated information, or

238
00:17:24,980 --> 00:17:29,980
small phi, that is generated by the mechanism.

239
00:17:29,980 --> 00:17:35,260
Now we can compute both the past integrated information as well as the future integrated

240
00:17:35,260 --> 00:17:36,420
information.

241
00:17:36,420 --> 00:17:41,700
As long as both are larger than zero, we can take the minimum to derive the cos effect

242
00:17:41,700 --> 00:17:45,380
integrated information for a mechanism.

243
00:17:45,380 --> 00:17:49,620
Of course, this computation only provided the integrated information on the level of

244
00:17:49,620 --> 00:17:53,100
mechanisms, such as individual neurons.

245
00:17:53,100 --> 00:17:56,260
How do we get from here to the whole brain and consciousness?

246
00:17:56,260 --> 00:18:01,380
Well, we can use the same algorithm of replacing connections with noise, not just for seeing

247
00:18:01,380 --> 00:18:05,780
on mechanisms, but also whole subsystems of a system.

248
00:18:05,780 --> 00:18:06,780
So there you are.

249
00:18:06,780 --> 00:18:10,340
There's a lot more to say of course, but this is the gist of it.

250
00:18:10,340 --> 00:18:14,940
You now understand that IIT provides a simple piece of math that links brain and mind.

251
00:18:14,980 --> 00:18:19,900
By computing the integrated information of a neural system, we can finally start to work

252
00:18:19,900 --> 00:18:22,380
on finding out more about consciousness.

