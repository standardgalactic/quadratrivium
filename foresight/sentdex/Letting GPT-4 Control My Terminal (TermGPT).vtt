WEBVTT

00:00.000 --> 00:03.440
Giving GPT-4 full access to my terminal.

00:03.440 --> 00:07.040
For some of you, you're way too excited about the prospects of such a thing,

00:07.040 --> 00:09.680
and this probably scares the heck out of many others of you.

00:10.240 --> 00:12.880
The idea is actually pretty simple and safe.

00:12.880 --> 00:20.560
We're really just trying to make prototyping and R&D with GPT-4 and models like it much more fluid.

00:20.560 --> 00:25.120
As it stands right now, you might go to the chat GPT UI or some other chat UI

00:25.680 --> 00:29.520
and ask it for something like a matplotlib graphing example.

00:30.000 --> 00:33.520
You'll wait for the generation, then you'll copy and paste it into an editor,

00:33.520 --> 00:36.160
and then run it, and then maybe then you'll ask for some changes,

00:36.160 --> 00:39.600
more weight, more copy and pasta, and so on.

00:39.600 --> 00:43.840
What I want to do instead is eliminate a lot of the sort of waiting

00:43.840 --> 00:49.600
and going from prompt to result, and I really want to just make this as quickly

00:50.320 --> 00:55.920
happen as quickly as possible, as well as require as little effort as possible.

00:55.920 --> 00:59.280
While still reviewing, what the model actually wishes to do

00:59.280 --> 01:01.600
before allowing it to do that.

01:01.600 --> 01:05.120
We can even do the edit to dark theme too in this way.

01:05.120 --> 01:08.400
For something so simple as just a matplotlib example,

01:08.400 --> 01:14.160
these are fairly minimal time savings, although I think the effort is still pretty low comparatively.

01:14.160 --> 01:18.960
But you can also quickly see that we issued one prompt and then we waited for GPT-4

01:18.960 --> 01:23.520
to generate all the commands at once, each of which would have been a separate kind of

01:23.520 --> 01:26.880
manual back and forth for us, especially if we hit some sort of error,

01:26.880 --> 01:29.120
or we're just waiting for something to happen.

01:29.120 --> 01:34.400
But instead we can review and run all of the commands in one go.

01:34.400 --> 01:39.280
As we continue to ask for more complicated things or even projects that might require

01:39.280 --> 01:43.760
multiple files or even installations of packages in setting up an environment,

01:43.760 --> 01:48.000
or even as we want maybe to modify those files,

01:48.000 --> 01:52.480
this sort of structure can wind up saving us a dawn of time and energy.

01:52.480 --> 01:55.280
So let's see some more fancy examples.

01:55.280 --> 01:58.240
Imagine that you found some sort of model on HuggingFace,

01:58.240 --> 02:01.840
like this code completion language model from Replit.

02:01.840 --> 02:06.080
That's very lightweight, and you'd like to make a demo with it by implementing

02:06.080 --> 02:09.680
the model into some sort of locally hosted web page

02:09.680 --> 02:15.680
with a text form input for the prompt and then some logic to display the output,

02:15.680 --> 02:16.880
you know, the continued text.

02:16.880 --> 02:21.440
Some very common use case for this particular model.

02:22.240 --> 02:27.840
So probably GPT-4 really first needs to know what model do we want to use,

02:27.840 --> 02:32.640
and then maybe do some light reading on the model's page to understand a bit about,

02:32.640 --> 02:35.280
you know, how to actually work with this model.

02:35.920 --> 02:40.560
Temp GPT doesn't have any web parsing ability built in,

02:40.560 --> 02:45.040
but it can program for us, and we can certainly parse with a program.

02:45.040 --> 02:49.600
So we can start off by asking Temp GPT to do just that for us.

02:49.600 --> 02:52.800
And it does this first by installing beautiful soup for Python,

02:53.440 --> 02:58.720
making the directory we asked for, and then writing some web scraping code to get the text

02:58.720 --> 03:02.720
from that page, and then saving it to the text file that we requested.

03:02.720 --> 03:08.640
We can then use Temp GPT to read that content.text file and create a web app for us that demos

03:08.640 --> 03:10.000
its abilities.

03:10.000 --> 03:15.040
We did hit an error along the way, which I just copy and paste to Temp GPT both times,

03:15.040 --> 03:16.400
and it is fixed.

03:16.880 --> 03:21.040
This is one thing I'm considering fully automating, and I'm trying to do that

03:21.600 --> 03:28.560
by allowing Temp GPT to read the terminal outputs to determine if more commands or changes

03:28.560 --> 03:31.280
need to be made, if an error is at least detected.

03:31.840 --> 03:37.120
The error and suggestion in the error text here could have been ingested by Temp GPT

03:37.120 --> 03:42.400
to easily implement and fix not really much different than us copying and pasting the error

03:42.400 --> 03:42.960
ourselves.

03:43.600 --> 03:49.440
Anyway, after reading the error, Temp GPT finds a way to remedy the problem and our program

03:49.440 --> 03:50.000
works.

03:50.000 --> 03:55.120
This has been extremely minimal with effort compared to what I would have done,

03:55.120 --> 04:00.320
even if I was either traditionally doing this by hand or even via the chat UI for chat GPT.

04:00.880 --> 04:05.440
And we can definitely do this in an even more like less clunky way.

04:05.440 --> 04:07.760
Speaking of which, how about a web parser idea?

04:07.760 --> 04:12.800
Can we use Temp GPT to modify a pre-existing project?

04:12.800 --> 04:13.760
Absolutely.

04:13.760 --> 04:19.520
Might we actually use Temp GPT to modify itself to add something like a web parser?

04:20.160 --> 04:26.080
Here, I ask Temp GPT to implement a web parsing feature similar to my file reading feature,

04:26.080 --> 04:31.440
and it modifies multiple areas of the Temp GPT script to do this.

04:32.000 --> 04:36.000
Testing this feature, we can ask Temp GPT to parse some web page and then save a summary

04:36.000 --> 04:37.120
of that text to file.

04:37.120 --> 04:42.000
For example, let's parse the readme page from GitHub for TensorFlow and see if GPT-4

04:42.000 --> 04:45.600
can summarize it for us into one sentence about what TensorFlow is.

04:46.320 --> 04:52.000
In this case, though, it is plausible that GPT-4 could also just have used its own underlying

04:52.000 --> 04:53.440
knowledge of TensorFlow.

04:53.440 --> 04:59.280
For example, we could just outright ask GPT-4 about TensorFlow without any other context,

04:59.280 --> 05:02.240
and it could summarize into one sentence.

05:02.240 --> 05:08.000
Instead, let's ask about something newer, so we could ask about stable studio from Stability AI.

05:08.000 --> 05:13.600
Asking GPT-4 via the chat UI, and it looks like this time GPT-4 doesn't actually know,

05:13.600 --> 05:14.320
which makes sense.

05:14.320 --> 05:20.320
This is relatively new, and GPT-4's knowledge stops in late March or something like that.

05:20.320 --> 05:23.840
So then we can go back to our example, parse that readme, and get a good summary of it.

05:23.840 --> 05:28.720
Okay, so those are just some really quick examples of what's possible, and to be honest,

05:28.720 --> 05:34.000
this has all just been kind of my first attempts as I'm trying to kind of make this happen, as

05:34.000 --> 05:38.720
this is a common, at least personally workflow for me, and I really just wanted to stop,

05:38.720 --> 05:44.080
you know, highlighting or clicking copy code, paste, run, copy some error, go back, like all

05:44.080 --> 05:48.960
this like back and forth was getting very old, and I really just wanted to come up with a solution

05:48.960 --> 05:53.040
that would just automatically kind of do these things for me, execute the commands for me,

05:53.040 --> 05:53.600
all of that.

05:54.320 --> 05:59.680
So this is really my first run through, and there are for sure going to be better ways to do

06:00.400 --> 06:05.120
the things that I'm doing here, and I definitely there's lots of things that we could build on,

06:05.120 --> 06:06.720
and I'm going to be hosting this code.

06:06.720 --> 06:10.960
So if you have ideas or things you want to try, feel free to fork or submit a poll request or

06:10.960 --> 06:11.680
anything like that.

06:11.680 --> 06:15.280
So with that, let's go ahead and dive into the code and see how everything is working under

06:15.280 --> 06:15.760
the hood.

06:15.760 --> 06:19.360
All right, so here with the code, let's go ahead and run through how everything works.

06:19.360 --> 06:21.680
So first, we've just got a bunch of imports.

06:21.680 --> 06:26.480
Open AI for the API, of course, Colorama to make things pretty, time for a sleep

06:27.120 --> 06:27.760
context.

06:27.760 --> 06:30.160
This is how I'm setting the pre prompt.

06:30.160 --> 06:34.240
We will come to that in a moment, but for now, that's just that's it's the pre prompt

06:35.200 --> 06:36.160
sub process.

06:36.160 --> 06:40.240
This is for attempting to execute commands and get their output.

06:40.240 --> 06:41.520
I'm still struggling with this.

06:41.520 --> 06:44.720
Maybe someone can help me figure out what the heck why this doesn't work.

06:44.720 --> 06:47.360
I'm sure it's probably some super simple logic problem.

06:47.360 --> 06:53.920
But anyway, read for regular expressions, requests and beautiful soup for the web parsing

06:53.920 --> 06:56.960
capability that term GPT actually added for itself.

06:58.320 --> 07:05.520
Again, and this actually isn't really all that required since we term GPT can already

07:05.520 --> 07:06.800
write a web parser.

07:06.800 --> 07:11.120
But the real kicker here is, you know, it could also write code to open up a file.

07:11.120 --> 07:15.600
But what you want to be able to do is read that information into context.

07:15.600 --> 07:20.480
So doing that, I think still kind of requires these features, but I want to kind of clean

07:20.480 --> 07:24.480
this up and quite possibly make it a little more dynamic.

07:24.480 --> 07:30.400
So for example, like pulling from a website, do you really just want the paragraph text?

07:30.400 --> 07:34.880
Do we want to also handle for JavaScript that happens to populate things?

07:34.880 --> 07:38.640
You know, so like this is a really basic example, but this won't get you very far.

07:38.640 --> 07:41.840
So anyway, I'm still kind of thinking about how I really want to do that.

07:41.840 --> 07:44.480
But anyway, moving along, the open AI key,

07:45.280 --> 07:47.600
really all the open AI stuff, I've got a video on that.

07:47.600 --> 07:50.720
I'll try to remember to put a link in the description for the basics of working with

07:50.720 --> 07:51.440
that API.

07:52.400 --> 07:54.800
But anyway, that's where our key is debug.

07:54.800 --> 08:02.160
This is just for a few extra print statements, just to mostly for outputting the full context

08:02.160 --> 08:06.960
every time I query GPT for just because that'll tell you for sure what exactly you're sending

08:06.960 --> 08:08.000
and getting back.

08:08.000 --> 08:11.680
I find that to be the biggest amount of information that you don't always want to see.

08:11.680 --> 08:14.080
But if you're having a problem, you probably want to see that whole thing.

08:14.080 --> 08:17.520
So anyway, moving along, message history is that terminal commands.

08:17.520 --> 08:20.560
That's just like the from the context that initial stuff that comes in.

08:22.400 --> 08:27.760
Then we have the regular expression pattern for the sort of functionality of reading a file

08:27.760 --> 08:29.200
or reading a website.

08:29.200 --> 08:30.480
So this is just read a file.

08:30.480 --> 08:31.920
This is W for website.

08:33.200 --> 08:34.320
It's just going to follow that.

08:34.320 --> 08:40.480
Again, we really could use large language models to also parse this out and it wouldn't

08:40.480 --> 08:42.800
even need to be like super structured in any way.

08:42.800 --> 08:47.760
It could just read some text and then determine is there a file that should be read?

08:47.760 --> 08:49.920
If yes, read that file, add that in.

08:49.920 --> 08:52.400
So you don't necessarily have to do it this way.

08:52.400 --> 08:57.440
Again, more on that and the context and all that stuff in a little bit because eventually

08:57.440 --> 08:59.600
I would like to do this without using open AI.

08:59.600 --> 09:00.960
I'd like to use an open source model.

09:00.960 --> 09:07.200
So I just don't want to get too deep into prompt engineering with GPT for when I'd like to

09:07.200 --> 09:13.520
I'm kind of like holding out for a really solid open source model with a solid license.

09:13.520 --> 09:14.240
So no llama.

09:15.360 --> 09:16.960
Anyway, moving on GPT query.

09:16.960 --> 09:22.880
So this is pretty much nothing new since the GPT for tutorial.

09:22.880 --> 09:26.560
So again, if any of this is confusing to you other than maybe the color Rama stuff,

09:26.560 --> 09:32.560
this just sets a color sets a styling basically does the text whatever and then resets it back

09:32.560 --> 09:32.960
to normal.

09:32.960 --> 09:35.680
So that's just that's just typical color Rama stuff.

09:36.400 --> 09:41.360
But anyway, if the debug is true, we are sending the entire message history,

09:41.360 --> 09:44.800
which is the full context that we're sending off to GPT for.

09:44.800 --> 09:48.160
So if anything's not working the way we're expecting, that's the first thing that we're

09:48.160 --> 09:48.560
going to do.

09:48.560 --> 09:54.400
So for example, reading the console outputs like trying to get the return on in the console.

09:55.840 --> 09:59.920
It doesn't give the most recent command no matter how hard I try.

09:59.920 --> 10:01.520
So I don't know.

10:01.520 --> 10:05.360
At first I thought it was while I'm hitting errors and I was thinking the error is causing

10:05.440 --> 10:06.320
my problem.

10:06.320 --> 10:09.760
But I'm pretty sure I'm handling it such that you would still you should still capture the

10:09.760 --> 10:10.000
error.

10:10.000 --> 10:11.360
But for some reason I'm just not.

10:11.360 --> 10:14.400
So anyway, moving along.

10:14.400 --> 10:18.880
So this is just a query GPT for API extract paragraphs.

10:18.880 --> 10:24.240
This is the code that GPT for slash term GPT wrote and modified into our script for us.

10:25.120 --> 10:27.760
Just simply reads a website grabs all the paragraph text.

10:27.760 --> 10:28.960
So really, really basic.

10:28.960 --> 10:31.600
Again, I think this should be a little better.

10:33.040 --> 10:34.240
But moving along.

10:34.240 --> 10:36.160
So then we've just got some pretty colorama stuff.

10:36.160 --> 10:37.440
Welcome to term GPT.

10:38.240 --> 10:43.200
It just tells you kind of the point of term GPT is just to make prototyping faster.

10:43.200 --> 10:44.720
Not a whole bunch of other fancy stuff.

10:44.720 --> 10:47.200
It's just make prototyping and R&D really quick.

10:47.200 --> 10:51.040
But don't run commands without still being able to review them.

10:51.040 --> 10:53.840
So continuing along.

10:53.840 --> 10:55.760
So there's just some more color color stuff.

10:55.760 --> 10:57.120
You've seen what it outputs already.

10:58.080 --> 11:02.160
So then we get the input whatever the user wants to, you know, put in the command.

11:02.160 --> 11:04.480
And then we have these very simple ones like clear.

11:04.480 --> 11:09.520
This just clears out that whole contextual history and just resets us back to terminal commands.

11:09.520 --> 11:13.440
We'll talk about we'll show those momentarily output.

11:13.440 --> 11:17.680
This reads theoretically the output from the system basically in the terminal.

11:17.680 --> 11:20.080
What, you know, what was the response back to that terminal?

11:20.080 --> 11:22.000
What was printed out in that terminal?

11:22.000 --> 11:25.840
So if you did hit an error, it would be nice to be able to say output or, you know,

11:25.840 --> 11:26.880
call this command.

11:26.880 --> 11:30.000
And then it would read that rather than you needing to copy and paste in the error.

11:30.000 --> 11:31.680
But again, it's not really working.

11:31.680 --> 11:33.680
So I'm going to copy and paste the error still.

11:34.800 --> 11:39.840
Otherwise, what it's going to do is it's going to look for any matches for do we want to read

11:39.840 --> 11:42.160
any files and it can do any number of files.

11:42.160 --> 11:47.440
And then essentially what it's going to do is either for files or websites that text that it

11:47.440 --> 11:51.040
parses, it's just going to shove it in and just it's going to build that context.

11:51.040 --> 11:55.280
And so it's just going to populate that context with the actual text.

11:55.280 --> 11:56.960
So it just adds it in.

11:56.960 --> 12:00.640
So you'll say I have this file here and then you'll say you'll have like the read command

12:00.640 --> 12:04.400
and it will quite literally say the file name and then the content of the file.

12:04.400 --> 12:06.880
So again, no different than what you would say.

12:06.880 --> 12:08.080
Hey, I've got this Python file.

12:08.080 --> 12:10.640
Here's the code copy, paste you paste in the code.

12:10.640 --> 12:12.000
This is the same exact thing.

12:12.000 --> 12:14.320
It just builds that context for me.

12:14.320 --> 12:17.680
So once we have that user input, which is going to be, you know,

12:17.680 --> 12:22.000
please help me make a flash website or please help me do, you know, whatever it is,

12:22.000 --> 12:25.040
we have that user input, we're going to send that off to GPT.

12:25.600 --> 12:28.720
And we're essentially going to wait until GPT is done.

12:28.720 --> 12:30.160
So what does that mean?

12:30.160 --> 12:32.240
So now it's time to go to our context.

12:32.240 --> 12:39.360
So this is the pre-prompt that I'm using to force GPT-4 to behave in the way that I want.

12:39.920 --> 12:46.160
So essentially, this is all sent off and this is how the program begins.

12:46.160 --> 12:49.920
So we're starting off by just telling GPT-4.

12:49.920 --> 12:52.800
Let me add word wrap real quick, make this a little easier on us.

12:53.360 --> 12:56.000
We're saying, as if I had told it, you know,

12:56.000 --> 12:58.480
give in text input from a user looking to do programming,

12:58.480 --> 13:02.720
help me build a series of console commands that will achieve the goals of the prompt.

13:02.720 --> 13:09.040
Your responses will come one command at a time where each response is just the command

13:09.040 --> 13:10.000
and nothing else.

13:10.000 --> 13:14.080
When ready for the next command, the user will say next, all camps next.

13:15.040 --> 13:17.360
And you will respond with the next command.

13:17.360 --> 13:21.360
When we have reached the end of console commands, respond with done.

13:21.920 --> 13:25.840
And then you will do it again with some new input from the user.

13:25.840 --> 13:27.840
If you understand, say okay.

13:27.840 --> 13:31.120
And again, we're just forcing the assistant here, you know,

13:31.120 --> 13:33.280
to think in historically it said, okay.

13:33.920 --> 13:36.720
And then what I'm doing is a one shot kind of example.

13:37.440 --> 13:42.080
I did find GPT-4 to be pretty good at following this command,

13:42.080 --> 13:45.680
but very often it's still added commentary to the commands and all that.

13:45.680 --> 13:49.680
And yes, we could use literally a large language model to parse out the command still.

13:50.320 --> 13:51.120
I don't like that.

13:51.120 --> 13:53.040
So I wanted to do at least a one shot.

13:53.040 --> 13:56.080
I thought maybe it might take more, but a one shot gives us an opportunity

13:56.880 --> 13:58.960
to show it even more basic stuff.

13:58.960 --> 14:02.640
So like for example, in this case, we're using cat to write to these files.

14:02.640 --> 14:05.200
But there's lots of ways that this could have been done.

14:05.200 --> 14:11.200
But given all of the huge variability of stuff that can happen inside of a script,

14:11.200 --> 14:16.960
it would likely break many of the methods that might be used to populate a file.

14:16.960 --> 14:18.800
So this one is just the one that works.

14:18.800 --> 14:23.200
So it allows us to kind of still kind of show really what we're looking for.

14:23.200 --> 14:29.120
So for example, with such a basic thing as show me a basic flask web dev example with templates,

14:29.120 --> 14:34.880
right? And the first command, in this case, we're making this up.

14:34.880 --> 14:38.480
We're showing GPT-4 how we want it to behave.

14:38.480 --> 14:44.000
So we're saying if someone asked this, here's an example of the sequence of events that should occur.

14:44.000 --> 14:45.840
First, you're going to need to pip install flask.

14:46.480 --> 14:48.640
And then the user is going to say, next.

14:48.640 --> 14:53.440
And then GPT-4 is going to respond with, you're going to want to make a directory basic flask app.

14:54.080 --> 15:02.720
Next, so already we're trying to get it to kind of put this into specific project folders.

15:03.440 --> 15:08.720
Then what it's going to do is actually write and then into that directory and then app.py.

15:09.680 --> 15:14.640
It's going to add just a very basic app.py with some template examples.

15:14.640 --> 15:18.720
Thank you. And then, okay, that's what it says.

15:18.720 --> 15:20.160
And then the user, next.

15:20.160 --> 15:24.480
And then it wants to make a template stir, add that index.html.

15:24.480 --> 15:25.280
Next, blah, blah, blah.

15:25.280 --> 15:30.160
You get the idea all the way down to actually running that app.py.

15:30.160 --> 15:31.120
The user says, next.

15:31.120 --> 15:33.360
And actually we're done because we've run the app.

15:33.360 --> 15:37.440
So it's just a really simple example that we're showing GPT-4.

15:38.000 --> 15:40.160
This is how I want you to respond every time.

15:40.160 --> 15:44.880
And then if that way, if the user did happen to say clear or whatever,

15:44.880 --> 15:47.920
we just reset right back to this context and continue on.

15:47.920 --> 15:52.800
But I found that you can generally keep going pretty far and be totally fine.

15:52.800 --> 15:55.840
But if you are experiencing weird things, you would just clear it and start over.

15:56.400 --> 16:00.960
But anyway, coming over here, while not GPT-done.

16:01.520 --> 16:06.080
So GPT-done starts as, where the heck are you here?

16:06.080 --> 16:07.600
Because we haven't started a new input.

16:07.600 --> 16:09.920
So we're going to start as GPT-done equals false.

16:10.560 --> 16:12.880
So then what's going to happen is, as long as that's true,

16:12.880 --> 16:16.080
what we're going to do is we're going to wait for the next command from the user.

16:17.040 --> 16:19.840
And essentially, it's going to just inject that.

16:20.560 --> 16:23.120
So we don't need to say next.

16:23.120 --> 16:28.080
We're just going to automatically tell GPT-4 next in the script.

16:28.080 --> 16:33.120
And we're just waiting until we literally see reply-content.lower.

16:33.120 --> 16:36.320
The only reason I'm doing this, GPT-4 always did an all caps done.

16:36.320 --> 16:37.120
It was good.

16:38.240 --> 16:42.640
But chat GPT, for example, I was just trying between the two of them to see if we save some money.

16:44.320 --> 16:46.560
It would sometimes lowercase, sometimes add a period.

16:46.560 --> 16:47.840
So I was trying to handle for that.

16:47.840 --> 16:52.000
But again, GPT-4 really follows this very well.

16:52.000 --> 17:00.080
I'm sure I could come up with ways to structure things such that chat GPT or GPT-3.5 works.

17:00.080 --> 17:03.680
There's no reason in my head that this couldn't be done with chat GPT.

17:03.680 --> 17:06.400
But GPT-4 is just way better than chat GPT.

17:06.400 --> 17:08.480
So anyway, moving on.

17:10.400 --> 17:13.200
So if it has reached a done, then we set done to true.

17:13.200 --> 17:14.880
Cool. And we break out.

17:14.880 --> 17:19.040
And then essentially, all the way up to this point, we've been, every time we get a command,

17:19.040 --> 17:23.360
we've been adding that command to a list of commands right here.

17:24.080 --> 17:27.760
Once we have that list of commands, you could have been theoretically running them,

17:27.760 --> 17:34.080
getting the return, and plausibly adding this to the context or something just to see,

17:34.080 --> 17:35.360
did you hit an arrow along the way?

17:36.080 --> 17:39.360
I think that's a mistake because either you're going to have to sit there and keep clicking

17:39.360 --> 17:41.200
like next or saying next or whatever.

17:41.920 --> 17:44.160
Or you're going to be blindly running commands.

17:44.160 --> 17:47.280
And you're probably more likely to just kind of blindly just hit go, go, go.

17:48.080 --> 17:49.280
And I don't think that's a good idea.

17:49.280 --> 17:51.600
So we're going to build that whole list.

17:51.600 --> 17:56.800
And then we're essentially going to iterate through that whole list, printing it out in bold red,

17:57.520 --> 18:00.640
making it clear what the commands are that are going to be run.

18:01.520 --> 18:07.360
And then if we want to actually run those commands, then we are going to go ahead and

18:07.360 --> 18:08.800
iterate through all of them and run them.

18:08.800 --> 18:11.920
And this is where I'm attempting to get the actual output.

18:11.920 --> 18:14.960
This does work all the way up to, I believe, the last output.

18:14.960 --> 18:20.000
I need to look a little deeper into that and see if there's got to be something wrong with

18:20.000 --> 18:20.720
my logic or something.

18:20.720 --> 18:24.160
Like I feel like this should work, but for whatever reason, it's just not working.

18:24.880 --> 18:31.600
Anyway, if the user puts in anything other than Y here, it just doesn't run the commands.

18:31.600 --> 18:32.080
And that's fine.

18:32.960 --> 18:38.560
Sometimes still, it does suggest to you, it might still give you some text,

18:38.560 --> 18:41.600
especially I found that to be true with the console output.

18:41.600 --> 18:44.240
It'll just say, oh, I didn't find any errors or something like that.

18:44.240 --> 18:46.080
So it doesn't say done, like it should.

18:46.080 --> 18:49.200
But anyway, that's all there is to it.

18:49.200 --> 18:53.280
All of the power of this, this is all just a bunch of stupid logic,

18:54.000 --> 18:56.400
really around what is the pre-prompt.

18:56.400 --> 19:02.320
And what we can do with a pre-prompt is, I mean, there's essentially infinite pre-prompts

19:02.320 --> 19:03.840
that we could theoretically use.

19:04.720 --> 19:08.240
There are better examples plausibly that we could show it.

19:08.800 --> 19:15.280
And there's more capabilities that we could show it or teach it or even just kind of that might

19:15.280 --> 19:16.160
show up.

19:16.160 --> 19:22.880
So even given this really basic example, I have found term GPT using GPT-4 to be

19:24.560 --> 19:25.360
really impressive.

19:25.360 --> 19:28.480
It really hasn't let me down on any task yet.

19:29.440 --> 19:34.960
Certainly, there's really nothing that GPT-4 could do for me via the chat UI that I haven't

19:34.960 --> 19:37.200
been able to just do via term GPT.

19:38.000 --> 19:40.080
And it's just been so much easier.

19:40.080 --> 19:43.360
And again, I made this really for myself and I'm just sharing it with people.

19:44.320 --> 19:46.480
And it's for sure a work in progress.

19:47.200 --> 19:53.280
There are some relatively new open source large language models that I'd really like to see

19:53.280 --> 19:54.960
can they fill in this gap.

19:54.960 --> 19:59.440
Because like I said, even chat GPT is weak-ish at this.

19:59.440 --> 20:06.160
Again, I think I could come up with prompts that chat GPT or GPT-3.5 rather could be successful with.

20:07.120 --> 20:10.720
So I just, I don't want to put in a bunch of time making chat GPT work.

20:10.800 --> 20:15.280
I'd rather it be some sort of open source model with a permissive license.

20:15.280 --> 20:17.600
So anyway, stay tuned for that.

20:17.600 --> 20:19.680
And again, I will put everything up on GitHub.

20:20.400 --> 20:26.000
Feel free to make a fork or whatever or make pull requests and just kind of tinker with this.

20:26.000 --> 20:27.120
I think this is kind of cool.

20:27.120 --> 20:29.440
I like the idea of going back and forth like this.

20:29.440 --> 20:36.160
And just doing the R&D with GPT-4 but just removing all of that extra effort.

20:36.160 --> 20:38.080
It's been, it's been really fun using it.

20:38.080 --> 20:40.560
So anyway, hopefully you guys will enjoy it.

20:40.560 --> 20:44.880
If you've got questions, comments, concerns, whatever suggestions, feel free to leave them below.

20:44.880 --> 20:48.080
Otherwise, I will see you all in another video.

20:48.080 --> 20:52.640
If you've ever wondered and wanted to know more about how neural networks actually work,

20:52.640 --> 20:57.600
including the optimization and fitment, rather than just simply calling some method,

20:57.600 --> 21:01.440
then you might be interested in checking out the neural networks from scratch book

21:01.440 --> 21:03.280
by myself and Daniel Kukiawa.

21:03.280 --> 21:07.680
The book can be had in the form of an ebook PDF, softcover or hardcover.

21:07.680 --> 21:10.000
And we ship for free worldwide.

21:10.560 --> 21:13.840
Also, the physical books just come with an ebook copy.

21:13.840 --> 21:18.560
All copies are in full color, which helps because there's a lot of code syntax highlighting

21:18.560 --> 21:21.520
and lots of charts and diagrams to help convey the principles.

21:22.080 --> 21:26.640
Also, almost all of those charts and diagrams have QR codes and links that take you to

21:26.640 --> 21:29.200
animations to help further illustrate the concepts.

21:30.080 --> 21:34.400
This is truly a real neural networks from scratch,

21:34.400 --> 21:39.120
teaching everything from the forward pass calculation of laws, back propagation and

21:39.120 --> 21:39.840
optimization.

21:39.840 --> 21:43.680
The only math that you're expected to know coming in is basic algebra.

21:43.680 --> 21:46.880
The rest is taught by us in the book, step by step.

21:46.880 --> 21:50.800
Everything is shown and explained in the book first logically, then mathematically,

21:50.800 --> 21:54.400
then via raw Python code, no third party libraries.

21:54.400 --> 21:56.880
And then finally optimized via NumPy.

21:56.880 --> 22:00.960
And this is for every step of the way, building and training actual neural networks

22:00.960 --> 22:06.400
for a fully fundamental understanding of neural networks and how they work from scratch.

22:06.400 --> 22:11.360
If at any point you're lost or confused, all copies of the book also grant access to a Google

22:11.360 --> 22:17.600
Docs version of the book, where you can ask your questions in line with the actual text itself.

22:17.600 --> 22:21.200
This is an incredible project that I'm extremely proud of to share with you all.

22:21.200 --> 22:25.120
We've sold over 13,000 copies to students all over the world.

22:25.120 --> 22:27.680
If you're looking to take your knowledge of deep learning to the next level,

22:27.680 --> 22:32.400
or if you're just looking to start that journey, I can't imagine a better way.

22:32.400 --> 22:38.720
So to learn more and buy yourself a copy, you can head to nnfs.io.

