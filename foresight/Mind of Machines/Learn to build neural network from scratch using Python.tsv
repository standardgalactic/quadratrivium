start	end	text
0	19000	Welcome to Minds of Machine. Today we are diving into fascinating world of neural networks where we will construct a basic structure of neural networks using Python and then we will go to a even complex structures of with three layers of neural network using NumPy.
19000	29000	So by laying the foundation for deeper learnings we are focusing on the core architectures. So let's get started.
29000	38000	So first part we will build a single structure of neural network in order to understand the basic of neural network.
38000	49000	First we define the input for the neural network. In our case we define the number format. It can be anything like an image or a long text.
49000	57000	As you can see we have defined an input in which it is in the form of array 1, 2, 3 and 2.5.
57000	61000	There are four values which we are passing to a neural network.
61000	76000	Then we are defining the weight for each neurons. In a computation sense weights are numerical parameters that define how much influence one neuron has on another.
76000	85000	Each connection between neurons in the network is assigned a weight. A primary use of the weight is in the learning process.
85000	98000	When a neural network is trained on a data set it will gradually adjust these based on the input data it receives and the error in the prediction.
98000	109000	This process often done through algorithms like back propagation or using optimization technique like gradient descent is how the network learns.
110000	116000	So in our case we will define three weights.
116000	128000	Weight 1 which has like four nodes, weight 2 which has four values because the shape of the input and the weight should be equal otherwise we will get an error.
128000	132000	And then weight 3. So there are three weights.
133000	141000	Next we are going to define the bases for each neuron.
141000	150000	So bases are additional parameters in neural network model alongside weights in a mathematical sense.
150000	158000	If you consider new neurons output as a function of its input the base is additional added constant.
158000	163000	On an offset to the output of the neurons activation function.
163000	169000	For example if the dish tastes too bland the chef might add a pinch of salt.
169000	181000	Similarly if neural networks prediction are constantly off in certain direction adding or adjusting the bias can help shift its prediction closer to the accurate value.
181000	188000	So as we have defined three weights here in similar case we will define three biases.
188000	209000	Bias 1 as 2 bias 2 as 3 and bias 3 as 0.5.
210000	214000	Now we will define the core function of each neuron.
214000	221000	For that we will loop each input and multiply with each weight and sum with bias.
221000	232000	So as you can see this is a basic one node how of a neural network which works which helps us to give the prediction.
232000	241000	So we are defining a function called as calculate output in which we are passing three input parameters as inputs weight and biases.
241000	253000	And then we are declaring the output as 0 which will be the actual result of how whenever an input is given how the neuron will predict the answer.
253000	268000	Since there are like four inputs which we have given so we are looping it through the length of the input and then now output is equals to input multiplied by weight.
268000	277000	And then once we get the output against each weight it will finally add it with the bias.
277000	283000	So this is the actual output you get from one node of the neuron.
288000	297000	And this way we loop it for all the inputs so that will give you a single value.
297000	303000	Now we have to calculate the output for each neuron as I mentioned before.
307000	319000	So we will call the calculate output function which is first output against weight one.
319000	335000	Then the input output two against weight two which is the second node of the neuron and weight output three is the output of the third node of the neural network.
335000	344000	So in this way this is just we are creating a single layer or coding a single layer of the neural network.
344000	362000	And here aggregating the output is basically putting all three outputs in one singular array and then we see the result of by printing it by printing the output.
363000	369000	As print layer output and declaring the output variable.
369000	385000	Now we will run our code as python3neuralnetwork.py which is my file name and you can see the layer output as 4.8, 1.21 and 2.3.85.
385000	399000	Now in this image you can see the input you can consider as the numbers which we have given and this layer at those nodes like the weight one, weight two, weight three.
399000	414000	In this image there are four weights but in code I have defined only three weights so this input is multiplied against every weight and then it is actually summed by the buyers and then it finally gives you the way.
415000	438000	So this outputs are basically in the form of numbers because computers usually understand the numbers but the input can be an image or a text or any form of data and this neurons will apply those formulas on those data and give us the prediction that it can be hard dog or this kind of dog or that kind of dog.
438000	448000	So here the input is the dog which we are passing through the neural network and it gives us two prediction based on the formula or the core function which we have used in our code.
449000	458000	Now let's create in the second part to build a structure of neural networks using numpy.
458000	481000	So in that we just did by a single layer. In the next one we might will create multiple layers of neural networks using numpy because it gives you faster performance when you use for follow the performance fault so that is basically used for understanding but using numpy gives you better results.
482000	491000	So first we are importing the numpy a library if it is not there then try to download in your terminal otherwise it will throw an error.
494000	497000	Then we define the classes neural networks layer.
497000	512000	Then we define an initialization function in which we define the weights and biases for each layer.
513000	524000	Self dot weight is equals to weight in this way we define the weight.
525000	546000	Next one is initializing the biases for the layer which is the same way as weight is declared as these two are the important parameters of the neural network.
547000	556000	Now we will define the forward function which is basically the actual calculation which each node does.
557000	574000	Inside this function we just take the inputs so here we are basically using the compute dot product of weight and input which means and then adding the bias so which is the main function of each node which neuron does.
575000	598000	So and the dot product is one of the function which numpy gives which makes our performance faster so instead of using the basic functionality which is given we are using numpy np dot dot which automatically does is the multiplies the weight and input and then adds the biases finally and will return the output.
599000	605000	So here we have declared the main function of our neural network.
606000	610000	Next we will define the inputs to our neural network layer.
611000	618000	First we are defining the same input where example which we have used in the previous one 1, 2, 3, 2.5.
622000	625000	Then we define the weights and biases for the layer.
628000	655000	We declare the weight for the first neuron as 0.2, 0.8, 0.5, 1.0.
655000	662000	And then we declare the same for second neuron as I showed in the previous one how we did.
667000	675000	But here we will declare it in the form of matrix which might be called as vectors.
675000	697000	Now we define the basis for each neuron so as we have 3 neurons we will have 3 bases as 2, 3 and 0.5.
705000	711000	Since we have declared the class so now we will create instances of the neural network.
715000	722000	So in this we will instantiate the layer with specified weights and biases.
723000	734000	So we will just pass the weights and biases and call the neural network with the values basically initializing the values.
735000	746000	Now we will pass the inputs to the forward function.
747000	751000	It will use the weights and biases which we have passed through the layer function.
753000	758000	Now we will calculate the output of the layers for the given input.
759000	774000	And now we will print the output as layer output and you can see by finally running python3neuralnetwork.py we can see the output.
775000	783000	So in this way NumPy gives you a better performance and is better for performance and faster execution of calculation.
784000	792000	For loops are usually not considered while creating a complex neural network because it will hamper the performance.
793000	798000	And if you compare the time taken by NumPy is way lesser than compared to For Loops.
799000	809000	So in this tutorial I have shown you how you can create a single layer of neural network using just basic For Loops or NumPy.
810000	815000	Usually NumPy is suggested to use for larger layers.
816000	823000	With single layers it won't affect the performance but with multi layers it's better to use NumPy.
824000	827000	So this is the end of the tutorial.
828000	833000	Thanks for watching. Stay curious and keep exploring with Minds of Machine.
