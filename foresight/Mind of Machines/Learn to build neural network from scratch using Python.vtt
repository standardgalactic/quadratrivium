WEBVTT

00:00.000 --> 00:19.000
Welcome to Minds of Machine. Today we are diving into fascinating world of neural networks where we will construct a basic structure of neural networks using Python and then we will go to a even complex structures of with three layers of neural network using NumPy.

00:19.000 --> 00:29.000
So by laying the foundation for deeper learnings we are focusing on the core architectures. So let's get started.

00:29.000 --> 00:38.000
So first part we will build a single structure of neural network in order to understand the basic of neural network.

00:38.000 --> 00:49.000
First we define the input for the neural network. In our case we define the number format. It can be anything like an image or a long text.

00:49.000 --> 00:57.000
As you can see we have defined an input in which it is in the form of array 1, 2, 3 and 2.5.

00:57.000 --> 01:01.000
There are four values which we are passing to a neural network.

01:01.000 --> 01:16.000
Then we are defining the weight for each neurons. In a computation sense weights are numerical parameters that define how much influence one neuron has on another.

01:16.000 --> 01:25.000
Each connection between neurons in the network is assigned a weight. A primary use of the weight is in the learning process.

01:25.000 --> 01:38.000
When a neural network is trained on a data set it will gradually adjust these based on the input data it receives and the error in the prediction.

01:38.000 --> 01:49.000
This process often done through algorithms like back propagation or using optimization technique like gradient descent is how the network learns.

01:50.000 --> 01:56.000
So in our case we will define three weights.

01:56.000 --> 02:08.000
Weight 1 which has like four nodes, weight 2 which has four values because the shape of the input and the weight should be equal otherwise we will get an error.

02:08.000 --> 02:12.000
And then weight 3. So there are three weights.

02:13.000 --> 02:21.000
Next we are going to define the bases for each neuron.

02:21.000 --> 02:30.000
So bases are additional parameters in neural network model alongside weights in a mathematical sense.

02:30.000 --> 02:38.000
If you consider new neurons output as a function of its input the base is additional added constant.

02:38.000 --> 02:43.000
On an offset to the output of the neurons activation function.

02:43.000 --> 02:49.000
For example if the dish tastes too bland the chef might add a pinch of salt.

02:49.000 --> 03:01.000
Similarly if neural networks prediction are constantly off in certain direction adding or adjusting the bias can help shift its prediction closer to the accurate value.

03:01.000 --> 03:08.000
So as we have defined three weights here in similar case we will define three biases.

03:08.000 --> 03:29.000
Bias 1 as 2 bias 2 as 3 and bias 3 as 0.5.

03:30.000 --> 03:34.000
Now we will define the core function of each neuron.

03:34.000 --> 03:41.000
For that we will loop each input and multiply with each weight and sum with bias.

03:41.000 --> 03:52.000
So as you can see this is a basic one node how of a neural network which works which helps us to give the prediction.

03:52.000 --> 04:01.000
So we are defining a function called as calculate output in which we are passing three input parameters as inputs weight and biases.

04:01.000 --> 04:13.000
And then we are declaring the output as 0 which will be the actual result of how whenever an input is given how the neuron will predict the answer.

04:13.000 --> 04:28.000
Since there are like four inputs which we have given so we are looping it through the length of the input and then now output is equals to input multiplied by weight.

04:28.000 --> 04:37.000
And then once we get the output against each weight it will finally add it with the bias.

04:37.000 --> 04:43.000
So this is the actual output you get from one node of the neuron.

04:48.000 --> 04:57.000
And this way we loop it for all the inputs so that will give you a single value.

04:57.000 --> 05:03.000
Now we have to calculate the output for each neuron as I mentioned before.

05:07.000 --> 05:19.000
So we will call the calculate output function which is first output against weight one.

05:19.000 --> 05:35.000
Then the input output two against weight two which is the second node of the neuron and weight output three is the output of the third node of the neural network.

05:35.000 --> 05:44.000
So in this way this is just we are creating a single layer or coding a single layer of the neural network.

05:44.000 --> 06:02.000
And here aggregating the output is basically putting all three outputs in one singular array and then we see the result of by printing it by printing the output.

06:03.000 --> 06:09.000
As print layer output and declaring the output variable.

06:09.000 --> 06:25.000
Now we will run our code as python3neuralnetwork.py which is my file name and you can see the layer output as 4.8, 1.21 and 2.3.85.

06:25.000 --> 06:39.000
Now in this image you can see the input you can consider as the numbers which we have given and this layer at those nodes like the weight one, weight two, weight three.

06:39.000 --> 06:54.000
In this image there are four weights but in code I have defined only three weights so this input is multiplied against every weight and then it is actually summed by the buyers and then it finally gives you the way.

06:55.000 --> 07:18.000
So this outputs are basically in the form of numbers because computers usually understand the numbers but the input can be an image or a text or any form of data and this neurons will apply those formulas on those data and give us the prediction that it can be hard dog or this kind of dog or that kind of dog.

07:18.000 --> 07:28.000
So here the input is the dog which we are passing through the neural network and it gives us two prediction based on the formula or the core function which we have used in our code.

07:29.000 --> 07:38.000
Now let's create in the second part to build a structure of neural networks using numpy.

07:38.000 --> 08:01.000
So in that we just did by a single layer. In the next one we might will create multiple layers of neural networks using numpy because it gives you faster performance when you use for follow the performance fault so that is basically used for understanding but using numpy gives you better results.

08:02.000 --> 08:11.000
So first we are importing the numpy a library if it is not there then try to download in your terminal otherwise it will throw an error.

08:14.000 --> 08:17.000
Then we define the classes neural networks layer.

08:17.000 --> 08:32.000
Then we define an initialization function in which we define the weights and biases for each layer.

08:33.000 --> 08:44.000
Self dot weight is equals to weight in this way we define the weight.

08:45.000 --> 09:06.000
Next one is initializing the biases for the layer which is the same way as weight is declared as these two are the important parameters of the neural network.

09:07.000 --> 09:16.000
Now we will define the forward function which is basically the actual calculation which each node does.

09:17.000 --> 09:34.000
Inside this function we just take the inputs so here we are basically using the compute dot product of weight and input which means and then adding the bias so which is the main function of each node which neuron does.

09:35.000 --> 09:58.000
So and the dot product is one of the function which numpy gives which makes our performance faster so instead of using the basic functionality which is given we are using numpy np dot dot which automatically does is the multiplies the weight and input and then adds the biases finally and will return the output.

09:59.000 --> 10:05.000
So here we have declared the main function of our neural network.

10:06.000 --> 10:10.000
Next we will define the inputs to our neural network layer.

10:11.000 --> 10:18.000
First we are defining the same input where example which we have used in the previous one 1, 2, 3, 2.5.

10:22.000 --> 10:25.000
Then we define the weights and biases for the layer.

10:28.000 --> 10:55.000
We declare the weight for the first neuron as 0.2, 0.8, 0.5, 1.0.

10:55.000 --> 11:02.000
And then we declare the same for second neuron as I showed in the previous one how we did.

11:07.000 --> 11:15.000
But here we will declare it in the form of matrix which might be called as vectors.

11:15.000 --> 11:37.000
Now we define the basis for each neuron so as we have 3 neurons we will have 3 bases as 2, 3 and 0.5.

11:45.000 --> 11:51.000
Since we have declared the class so now we will create instances of the neural network.

11:55.000 --> 12:02.000
So in this we will instantiate the layer with specified weights and biases.

12:03.000 --> 12:14.000
So we will just pass the weights and biases and call the neural network with the values basically initializing the values.

12:15.000 --> 12:26.000
Now we will pass the inputs to the forward function.

12:27.000 --> 12:31.000
It will use the weights and biases which we have passed through the layer function.

12:33.000 --> 12:38.000
Now we will calculate the output of the layers for the given input.

12:39.000 --> 12:54.000
And now we will print the output as layer output and you can see by finally running python3neuralnetwork.py we can see the output.

12:55.000 --> 13:03.000
So in this way NumPy gives you a better performance and is better for performance and faster execution of calculation.

13:04.000 --> 13:12.000
For loops are usually not considered while creating a complex neural network because it will hamper the performance.

13:13.000 --> 13:18.000
And if you compare the time taken by NumPy is way lesser than compared to For Loops.

13:19.000 --> 13:29.000
So in this tutorial I have shown you how you can create a single layer of neural network using just basic For Loops or NumPy.

13:30.000 --> 13:35.000
Usually NumPy is suggested to use for larger layers.

13:36.000 --> 13:43.000
With single layers it won't affect the performance but with multi layers it's better to use NumPy.

13:44.000 --> 13:47.000
So this is the end of the tutorial.

13:48.000 --> 13:53.000
Thanks for watching. Stay curious and keep exploring with Minds of Machine.

