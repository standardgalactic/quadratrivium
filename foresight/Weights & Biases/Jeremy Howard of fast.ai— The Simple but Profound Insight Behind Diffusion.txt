I've been telling everybody who will listen that I feel like we're in the middle of a
significant spike in technological capability right now.
And so if you're not doing that, you're missing out on being at the forefront of something
that's substantially changing what humans are able to do.
You're listening to Gradient Descent, a show about machine learning in the real world,
and I'm your host, Lucas Biewald.
Jeremy Howard is the founding researcher at Fast.ai, which is a research institute dedicated
to making deep learning more accessible.
They make an incredible Python repository that people use for lots and lots of deep learning
projects, and they make an incredible set of classes that many people I know have taken
and is almost universally loved.
He was also the CEO and founder of Aenlytic, the president of Kaggle, and has done a whole
bunch of diverse, amazing things in his career.
It's always super inspiring to talk to Jeremy, and this interview is no different.
I really hope you enjoy it.
You are the first person to be on this podcast two times, and I think you are the most popular
guest that we've had based on our YouTube metrics, so it's great to have you.
And I guess I wanted to start with, actually, the most memorable part of our interview for
me personally was the amount of time that you set aside every day to work on just learning
and just said like undirected sort of learning new things, which I really thought was an
amazing thing that I always aspire to do more of.
But I was curious lately, what have you been learning?
I'm spending all my spare time at the moment on generative modeling around the kind of
global diffusion or diffusion modeling space.
Hence the new course, I guess.
Is that part of the learning process?
It's a bit of a chicken-and-the-egg thing.
It's partly the new courses because of the learning and partly the learnings because
of the new course.
I've been telling everybody who will listen that I feel like we're in the middle of a
significant spike in technological capability right now.
And so if you're not doing that, you're missing out on being at the forefront of something
that's substantially changing what humans are able to do.
And so when there's such a technological shift, it creates all kinds of opportunities for startups
and for scientific progress and also opportunities to screw up society, which hopefully you
can figure out how to avoid and stuff like that.
So I'm very keen to do what I can to be on the forefront of that and to help others who
are interested in doing the same thing.
And when you say spike, do you mean diffusion models specifically or do you mean machine
learning more broadly?
Do you mean like this?
I mean diffusion models specifically.
Interesting.
Yeah, it's a simple but profound insight, which is that it's very difficult for a model
to generate something creative and aesthetic and correct from nothing or from nothing but
a prompt or a question or whatever.
And the profound insight is to say, well, given that that's hard, why don't we not ask
a model to do that directly?
But why don't we train a model to do something a little bit better than nothing?
And then to make a model that if we run it multiple times takes a thing that's a little
bit better than nothing and makes that a little bit better still and a little bit better still.
And so if you run the model multiple times, as long as it's capable of improving the previous
output each time, and it's just a case of running it lots of times.
And that's the insight behind diffusion models.
As you'd be well aware, Lucas, it's not a new insight.
It's the same basic insight that all that belongs to this class of models called boosted
models.
So boosted models are when you train a model to fix a previous model, to find its errors
and reduce them.
And so we use lots of boosted models, gradient boosting machines in particular are particularly
popular, but any model can be turned into a boosted model by training it to fix the
previous model's errors.
But yeah, we haven't really done that in generative models before.
And we now have a whole infrastructure for how to do it well.
And the interesting thing is that having started to get deep into the area of realized we're
not close at all to doing that in an optimal way.
So the fantastic results you're seeing at the moment are based on what in a year's time
or two will be considered extremely primitive approaches.
Could you say a little more about that?
Sure.
So broadly speaking, we're looking to create a function that if we apply it to an input
it returns a better version of that input.
So for example, if we're trying to create a picture that represents a cute photo of
a teddy bear, then we want a function that takes anything that's not yet a really great
cute photo of a teddy bear and makes it something a little bit more like a cute photo of a teddy
bear than what it started with.
And furthermore that can take the output of a previous version of running this model and
run it again to create something that's even more like a cute version of a teddy bear.
It's a little harder than it first sounds because of this problem of out of distribution
inputs.
The thing is if the result of running the model once is something that does look a
little bit more like a teddy bear, that output needs to be valid as input to running the
model again.
If it's not something the model has been trained to recognize, it's not going to do a good
job.
So the tricky way that current approaches generally do that is that they basically do the same
thing that we taught in our 2018-2019 course, which is what we call crappification, which
is to take a perfectly good image and make it crappy.
In the course what we did was we added JPEG noise to it and reduced its resolution and
scrolled text over the top of it.
The approach that's used today is actually much more rigorous but in some ways less flexible.
It's to sprinkle Gaussian noise all over it.
So basically add or subtract random numbers for every pixel.
And the key thing is then that one step of inference, so making it slightly more like
a cute teddy bear, is basically to do your best to create a cute teddy bear and then
sprinkle a whole bunch of noise back onto the pixels, but a bit less noise than you
had before.
And so that's by definition at least going to be pretty close to being in distribution
in the sense that you train a model that learns to take pictures which have varying
amounts of noise sprinkled over them and to remove that noise.
So yeah, so you can just add a bit less noise and then you run the model again and add a
bit of noise back, a bit of less noise and then run the model again and add a bit of
noise back, a bit less noise and so forth.
So it's really neat, but a lot of it's done this way because of theoretical convenience
I guess and it's worked really well because we can use that theory in a call convenience
to figure out what good hyperparameters are and it'll get a lot of the details working
pretty well.
But there's totally different ways you can do things and you can see like even in the
last week there's been two very significant papers that have dramatically improved the
state of the art, both of which don't run the same model each time during this boosting
phase, during this diffusion phase, but they have different models for different amounts
of noise or there are some which will have like super resolution stages.
So you're basically creating something smaller than making it bigger and you have different
models for those.
Basically what I think, yeah, what we're starting to see is like that gradual move away from
the stuff that's theoretically convenient to stuff that like is more flexible, has more
fatally hyperparameters to tune, but then people spend more time tuning those hyperparameters,
creating more complex mixture of experts or ensembles.
And I think, yeah, there's going to be a lot more of that happening.
And also the biggest piece I think will be this whole question of like, well, how do
we use them with humans in the loop most effectively because like, you know, the purpose of these
is to create stuff.
And currently it's like, it's almost an accident that we can ask for a photo of a particular
kind of thing, you know, like a cute teddy bear.
The models are trained with what's called conditioning, where they're conditioned on
these captions, but like, the captions are known to be wrong because they come from the
alt tags in HTML web pages, those alt tags are very rarely accurate descriptions of pictures.
So the whole thing, you know, and then the way the conditioning is done is kind of really
got nothing to do with actually trying to create something that will respond to prompts.
So the prompts themselves are a bit of an accident and the conditioning is kind of a
bit of an accident.
So the fact that we can use prompts at all, it's a bit of an accident.
And as a result, it's a huge art right now to figure out like how, you know, trending
on ArtStation, 8K, ultra realistic, you know, portrait of Lucas B. Wilde looking thoughtful.
Whatever.
There's whole books, you know, of like, here's lots of prompts we tried and here's what
the outputs looked like and then how do you like customize that because actually, you
know, you're trying to create a storybook about, you know, Lucas B.
Wilde's progress in creating a new startup and you want, you know, you want it to fit
into this particular box here and you want a picture of a red button in the background
there and, you know, like, how do you get, you know, the same style, the same character
content, the particular composition, you know, it's all about this interaction between
human and machine.
There's so many things, you know, which we're just starting to understand how to do.
And so in the coming years, I think it will turn into a powerful tool for, you know, computer
assisted human creativity rather than what it is now, which is more of a hands-something
off to the machine and hope that it's useful.
Do you think the same approach applies across domains or is there something about images,
the way it's sort of obvious how to add noise and maybe the data set that we have?
I mean, certainly the way you described diffusion, you could, there's a natural application that's
almost any domain, but I guess Gaussian noise on text, it's a little unclear to me like
what that, what that really means.
So last week, a paper showing diffusion for text came out.
There's already diffusion models for like proteins.
There's already diffusion models for audio.
The audio ones are used, or some of them use a fairly hacky, obvious, but neat approach
of using diffusion to generate spectrograms, which are images, and then having something
like a super resolution model, but it's not doing super resolution, it's doing spectrogram
to sound.
So yeah, these things are already starting to exist.
They haven't had as much resources put into them yet, so they're still not that great.
Yeah, that's the thing, Lucas, this is not just images at all.
It'll be used in medicine, it'll be used in copywriting.
I mean, the way we currently do generative text models, again, it's kind of a happy accident.
So when I did ULM fit, the whole reason I created a language model was for the purpose
of fine-tuning it to create a classifier, and GPT then that took that idea and scaled
it up with Transformers, what Alec Radford was trying to do there was not generate text,
but trying to solve other problems by fine-tuning it.
There was this kind of discovery almost with GPT-3 that when you take this and you scale
it far enough, it actually starts generating reasonable sounding text, but the text is not
necessarily correct, in fact, it's very often wildly incorrect.
And so yeah, intentionally working on text generation approaches, which is specifically
designed for generating text is something that there's a lot of room to improve.
And generally speaking, the way I see it is this, you've got a generative model that's
trying to do something difficult, and it's pretty good at it, or at least better than nothing.
It'll be better at it if you can do it in a way that it runs multiple times during inference,
because you're giving it more opportunities to do its thing.
So I think that means that these multi-step inference models, which may or may not be diffusion
models, but kind of boosted generative models are here to stay, because no matter how good
your model, generative model is, you can always make it better if you can find a way to write it
multiple times. I guess that is a good segue to another question I had, which is,
I think one of the really fun things about deep learning in the early days was it was so
tangible. And you have this fantastic class where you can just kind of build these models and see
how they work and play with them. And so I think we both have a very similar learning approach.
But one thing I've personally been struggling with, honestly, with these bigger models is just
actually engaging with them in a meaningful way. It's fun to run the various image-generating
models, but it feels kind of daunting. I'm not sure I have the money myself to buy the compute
to make one that really works. We actually had one person on this podcast who did it for fun,
Boris, which is a super fun episode. And I felt really jealous of how much fun he had building
it. But I'm curious how you turn that problem into something like tractable that you can actually
engage with. Yeah, well, you know, I mean, remember, Boris is one of our alumni. He's part of our
fast AI community. And he showed what is possible for a single tenacious person to do.
Although I think Google donated like $100,000 a computer, so it wasn't totally...
Yeah, absolutely. If you can show that you're doing useful work, then there's plenty of compute
out there, which you can get donated to. But having said that, what he was largely trying to do at
least at the outset was to replicate what open an AI had done. I take a very different approach,
which is I always assume that the best thing out there right now is far short of what the
best thing could be, that in five to 10 years time, there'll be something better. And I always look
for improving that. So yeah, so you should take our new course, Lucas. I was loaded on,
which we're in the middle of, because what I've been working on is exactly what you describe,
which is how to train and play with the state of the art, the image generative model in a
notebook or kind of single GPU. And as with all of these things, the trick is to start with an
easier but equivalent problem. So I'm doing all my work just about on the fashion MNIST dataset,
which rather than being 512 by 512 pixel images of literally anything in the world,
including artworks, they're 20, they're three channel. Fashion MNIST is 28 by 28 single channel
images of one of 10 types of clothing. Now, I always tell people like whether you're doing
a cackle competition or a project at work or whatever are the most important.
Two steps are to create a rapid feedback loop where you can iterate and test fast
and to have a test which is highly correlated with the final thing you're going to be doing.
So that if you have those two things, you can quickly try lots of ideas and see if they're
probably going to work, you know, on the bigger dataset or the big harder problem or whatever.
So it turns out fashion MNIST basically, yeah, I've kind of like replicated a bunch of different
approaches from the literature on fashion MNIST, the relative effectiveness of those different
approaches on fashion MNIST mirrors basically exactly their relative effectiveness on Koko
or ImageNet or Lyon or whatever. But I can train a model on a single GPU to a point where I can
see relative differences in about two minutes. And that means I can, yeah, like very rapidly
try things. And so I've started, yeah, building notebooks where I show every single little step.
And also it helps a lot to use notebooks, which almost nobody working in the
generative modeling field seems to be doing at the moment. So what they do is they have,
you know, the normal approach is to, you know, do ImageNet 64 pixel or, you know,
SciFar 32 pixel, which is still better than doing 512 by 512 Lyon. But it still takes,
you know, ImageNet 64 pixel takes many hours on an 8 GPU machine.
You can't do a fast iteration loop, you know. So, yeah, in a notebook, you know, I can like
run a single iteration of diffusion. I can see what the outputs look like because the pictures
are all there in front of me. You know, if you're not using this kind of approach, instead you're
switching back and forth between a terminal and then you need some way of actually viewing the
images. And given that you're probably not sitting directly on that 8 GPU box, you're
probably SSHing into it. So now you've got to find a way to show you those pictures.
There are ways, by the way, of showing pictures in the terminal. For example, if you use Item2,
there's something called ImageCat. If you use other terminals, they probably support something
called Sixall, Sixall Graphics. But there's, you know, they're not going to be as
a good exploration environment for this kind of stuff than a notebook is. So, yeah, I think
there's lots of opportunities for, you know, people like you and me to play in this field.
I mean, I know there is because I've, you know, started spending time talking to
some of the folks who were the primary researchers responsible for their key components of stable
diffusion. And I'm already telling them things that they hadn't thought of before by virtue of
weird little experiments I've done with Fashioned MNIST on my
single GPU triple notebook. Yeah, that makes sense. I mean, a fast feedback loop is so important.
I mean, that's very cool. I was curious, broadly, if you have thoughts on stable diffusion in
general, I feel like, you know, we're sitting here in November, you know, 2022, and I think
they've done an amazing job of bringing awareness to generative models. I don't know, what do you
think of a stable diffusion? I mean, it's been great for progress in the field,
really. Yeah, I mean, generally speaking, I'm all about democratization and accessibility,
as you know. I don't love the fact that before a stable diffusion was released,
you know, a small number of people in the world had access to
the full generative models, and then other people could like pay for cut down versions of them,
use them in small quantities. The thing is, accessing these things through a
web based API is extremely limiting, you know, when you've actually got the weights,
you can really play with both the engineering and the artistic side of
doing things that no one's done before. So yeah, I think that's great. I think it's important.
I think, you know, as with any of these things, you release a new powerful technology out there,
and a whole bunch of people are going to be using it for, you know, not necessarily the
things that you would have chosen to use it for. So for example, for stable diffusion,
it seems like a very large percentage of people who are using it to generate lots and lots of
images are doing it to generate anime, and specifically nearly entirely, you know,
very young women with very few clothes on anime pictures. And I'm sure there are people out there
who are taking the clothes off entirely, you know. So that's, I mean, that happens, I guess, with any
technology, and I don't necessarily have, I mean, you can't, I guess you can't stop that
happening. But we certainly need appropriate laws around at least, you know, making illegal
things, make sure the things that we don't want to be legal are in fact illegal.
But yeah, I mean, there are obviously huge benefits, and you're not going to get stuff like,
you know, protein diffusion models or, you know, pharmaceutical diffusion models or, you know,
none of those are going to develop if the technologies in the hands of like two or three big
organizations. So it's certainly a very valuable step on the whole for society to have this stuff
as open as possible. And to be clear, it was, it was all trained at universities, you know. So the
main one, most of the stuff we're using now for stable diffusion is trained in Germany,
at German academic institutions, using donated hardware.
I guess it's interesting, though, that it was, I think, primarily ethics and AI considerations that,
you know, made folks like OpenAI kind of restrict access to their models, or at least that's what
they said. Do you think that you would know our priori that that was like the wrong thing to do,
were you, would you have pushed against that? So actually, I actually read a blog post about
that back in when GPT-3 was announced and not released. And nearly universally, the
feedback at least from the AI community was, oh, this is lame, they're just doing it for profits.
And in my blog post, I said, like, well, not necessarily, you know, like,
there are genuine things to be thinking about here,
which is not to say that that means that the motivation wasn't at least partially profit-driven,
it might well have been. Like it's certainly convenient that the ethical considerations read
in this way entirely align with profit-driven motives as well. But like I say, it doesn't
necessarily mean they're not true. And I'm pretty sure it's of both reasons. And if you look at the
way OpenAI has behaved since then, they've behaved in a way that is very increasingly,
apparently profit-driven. So I'm less generous in my interpretation now than I was then,
based on their continuing patterns of behavior. And I think also with the benefit of hindsight,
it feels a lot more like, you know, in the last couple of years,
companies keeping models to themselves, the main impact that sense of being is to create
a bigger bifurcation between haves and have-nots in terms of capability,
requiring more researchers to pay for API access to do things, a decreased amount of openness that
in fact even, you know, what could be argued as being kind of deceitful behavior. So like,
for example, we now know that the OpenAI models that you can pay to access are actually not the
same as what's been described in their research papers. And we've now had dozens of people write
research papers comparing various work to the OpenAI models. And now we've learned that actually
we're not comparing to what we thought we were comparing at all. And, you know, thousands of
hours of research at time being wasted and papers being published with what turns out now to actually
be totally wrong information in. So yeah, I'm definitely, you know, more enthusiastic about
the idea of being open than perhaps more confident about that than I was a couple of years ago.
And I guess, do you have thoughts on the language side of things like large language models? Like,
do you think that, for example, do you think that prompt engineering is headed to be like an
important way of doing machine learning? Like, you know, you do see these models doing incredibly
well and like a wide variety of NLP tasks, like better than models, you know, trained specifically
on these specific tasks sometimes. Yeah, I think generative text models have both more
opportunities and more threats than generative image models, for sure. Like I say, they're kind
of the fact that they work at all is in some ways a bit of an accident. They're far, far, far from
being optimized for for purpose at the moment. But they're already amazingly good, particularly if you
do this kind of stuff where I mean, literally, there are now dozens of papers,
just look at like what kind of prompts happen to work on these models that we kind of accidentally
made generative models, who's, you know, let's think step by step and whatever else.
We're starting to find ways to actually get them to do a little bit more of what we actually want
them to do. But so far, using really, really basic things like, you know, this instruction
tuning. So, you know, rather than just feeding at the entire internet, let's actually fine tune it
with some examples of things that are actually correct. That actually represent outputs that
we would want for these inputs rather than just whatever somebody Rando wrote on the internet
25 years ago. Yeah, so my worry is I'm much more worried about misuse of text models and image models,
because it wouldn't be at all hard to create a million Twitter or Facebook or whatever
accounts and program them to work together to impact the kind of worlds discourse
in very substantial ways over time. And nobody would know, you know, so we could have like,
you know, like on Twitter, for example, some, you know, fairly small number of accounts,
often where nobody actually knows the human who's behind it can have very substantive effects on
like what people are talking about and how do people talk about that thing. And so imagine,
yeah, a million of those accounts, which were actually bots that had been trained to be more
compelling than humans, which, which already for years, we've had bots which humans rank as more
compelling than actual humans. And that they've been trained to work together, you know, take
alternate points of view in exactly the right way. And this bot gradually gets convinced by that bot
and whatever else like, yeah, it could cause a very small number of people in the world to
programmably decide how they want humanity to think about a topic and pay to make that happen.
Although if I, if I remember right, it seemed like all of fast AI is like sort of broad mandate
was to basically make a no code interface into machine learning so anyone could access it.
And it does sort of seem like prompt engineering to the extent that it works is like a huge step
in that direction. Right. Yeah, that's what I'm saying. It's like, that's why I say it's like
both got more opportunities and more threats. So yeah, the opportunities are vast to, you know,
so take for example, the recent thing that was released like last week or so, explainpaper.com
where our students are already, you know, so with our course, we do, you know, look at a paper or
two each week. And so, and so last week, I had told told the classes homework to
reimplement the diff edit paper. And so students are saying like, oh, I didn't understand this
paragraph. So I highlighted it and explainpaper.com and here's the summary it gave. And that's a lot
more clear now that I tried to understand that bit. So I asked for more information.
You know, this is very, very valuable. And, you know, I saw somebody on Twitter a couple of days
ago saying they don't really use Stack Overflow anymore because they created this tiny little
simple little script called ask where they type ask and then something at a prompt, sorry, at a,
in the bash, you know, shell repel and it would feed that off to open AI GPT three and return
that the result and they basically use that instead of searching the internet nowadays.
So yeah, people are definitely using this stuff and it's going to get much, much better.
Do you have a clever way like with fashion, emnist and image generation to play with large
language models on kind of a bite sized scale?
Not yet. No, I, some, you know, I'll get to that maybe, you know, another part of the course,
I guess it's definitely a great question and something to think about.
Interesting. Okay. A question that I need to revisit because this is unexpectedly, I think,
one of the reasons that so many people listened to my interview with you last time,
you sort of made an interesting comment that you felt like Python wasn't the future of ML
and you sort of said maybe Julia is the, is the future of ML and that really seemed to like strike
a chord with the internet everywhere. I think it's kind of the most discussed part of great
incentive of all time. So I'm just curious, do you have any more thoughts on that? Like I,
do you, do you sort of still believe that like Julia is the future? You're sort of on the fence
about that. I mean, I was on the fence about that last time we spoke and I would say I'm a little
less bullish than I was then because I just, I feel like the Julia ecosystem and culture,
you know, it's so focused on these like HPC kind of like huge compute running things on national
labs, machines and it's all stuff that's very appealing to engineers. It feels good, but it's
such a tiny audience, you know, and it's not like, I don't care about whether I can run something on
5000 nodes. I just want to run it on my laptop and it's still not great for running on my laptop
really and it's not great for creating software that I can send you. I can't, you know, if I
created a little CLI tool or whatever, well, it's not great for creating little CLI tools because
it's so slow to start up and then how the hell am I going to send it to you to try out? It'd be like,
okay, Lucas, well, install the entirety of Julia and then run the REPL and then type this to go
into package management mode and then, okay, now you've got this thing and now you can run it and
it's like, okay, that's not going to happen or, you know, even just deploying a website, you know,
and it's a lot of fast and bother and uses more resources than it should. It's still got that
potential but, you know, I guess the other thing that's become more clear though in the last couple
of years is their grand experiment on type dispatch. It is more challenging to get that all working
properly than perhaps I had realized because it's still not really quite all working properly
and I think good on them for trying to make it work properly. It's a vast research project.
But, you know, there's a lot of weird little edge cases and trying to make that all run smoothly
is incredibly challenging. So I suspect, yeah, something needs to replace Python but maybe
it's something that doesn't exist yet. Partly though, I mean, so what we're seeing instead,
everybody knows we have to replace Python. So what instead's been happening is we're using Python to
create non-Python artifacts. So most obviously, Jax, you know, Jax uses Python or a subset of Python
with a kind of embedded DSL written as a library which only lets you create things that can be
expressible as XLA programs and then XLA compiles that to run fast on a GPU. And that works pretty
well. It's very challenging though for research or hacking or learning or whatever because it's
actually not Python that's running at all. So it's extremely difficult to like profile and
debug and so forth that code. Very hard to kind of run it in a really nicely in notebooks.
So like in our little team working on diffusion models, we kind of all want to use Jax. But every
time we try, it's always like, because like everything I write, it's always wrong the first
14 times. And with Python, you know, I have 14 goals at making it better by like finding all the
stupid things I did by running one line at a time and checking things and looking at pictures.
With Jax, I wouldn't know how to fix my broken code, really. It's difficult.
But you don't think that that flexibility is like fundamentally in conflict with making
a language performant? It is for Python, I think. Yeah. So for Python, like
that flexibility is to be able to actually run it as Python code. So like if you look at where
PyTorch is going now, they've got this TorchDynamo stuff where they're working, you know, they're
basically, you know, can interface with NVFuser and you can interface with Triton, the OpenAI
compiler-ish thing, I'm not exactly sure what you'd call it. And so clearly PyTorch is heading
the same direction as Jax, which is if you want it to run fast, you'll use TorchDynamo or whatever
it ends up being called. That's actually now, you know, integrated into the PyTorch tree.
That's clearly where we're heading. And again, you end up with, you know, probably you'll be
using Triton. So you end up, Triton's amazing. Super cool, super fantastic. But you know,
you still end up with this thing that's running compiled code. It's not the same code you wrote,
but a version of it. Again, difficult, more difficult to hack on. Yes. I think, you know,
if you look at how this works, you know, there's a whole world of software that's written in languages
which are explicitly designed to work this way. They're compiled languages, you know,
languages like C++ and Swift and Rust. And they have something very nice, which is they have
flags, you can pass the compiler. So you can pass the D flag to run it in the debugger,
or you can pass the O flag to run it, you know, in the optimized version. And so basically,
you get to choose how close the code that's actually running is to the actual lines of code
that you wrote. So that for debugging, you can actually, you know, it'll run slower, but it's
actually running the lines of code that you wrote. And I think we want something like that,
something that, yeah, it looks like Python, it's pretty compatible with Python, but, you know,
you can still run it as Python, but you can also run it in an optimized way. You know,
maybe something that actually takes better advantage of these kind of type hints that we can
provide. Yeah, that's my guess is what's going to happen is we'll see Python-esque languages,
you know, we'll continue to see these Python-esque languages appear that may begin to look less
and less like pure Python. And, you know, are designed to work better and better with these
back-end linear algebra accelerators and compilers.
Is there some language out there right now that has that feel for you?
No, they're all basically these embedded DSLs, you know, like TVM or like Halide.
You know, we have the MLIR project, which is kind of providing the back-end needed for these kinds
of things. And, you know, Chris Latner has a new company, which, you know, presumably going to be
placed better than any other to create what we need for this kind of thing. And so he's the guy
behind MLIR. Yeah, but it feels like a big open area to me at the moment.
Interesting. Okay, on a totally different topic that I kind of can't believe we didn't cover
last time. I feel like we must have been right in the middle of it. You know, I think Guy,
along with many other people in the world, sort of watched you kind of advocate for wearing masks
in the early days of COVID. And, you know, I think you had one of the most, I mean, some of the most
like, you know, high-profile like articles on this, like the second most popular article on like
free print. And I'm just kind of curious if you could sort of tell that story from your perspective
and maybe, you know, like what you were seeing that other people were missing and how you're
kind of approaching that problem differently. I mean, it's hard for me, Loicos, because like,
I don't understand why, and I still don't understand why it's not reasonably obvious to
everybody, like, what's everybody else missing and why? Because like, to my point of view,
well, okay, so like, let me go back. So February 2020, you know, mid-ish February 2020, like,
February 2020, I had a course coming up at the University of San Francisco that I was going
to be teaching. And I had heard, you know, increasing chatter about this, whatever, Chinese
virus thing. And I guess, you know, what then happened was it hit Italy. And there was a lot
more information in English about what was happening in Italy than there was what was happening in
China. So suddenly it was much more accessible to see what was going on, you know, particularly
because a lot of the Italian doctors and whatever were actually on Twitter and stuff, so I could
read what was happening. And that, you know, a whole bunch of people were saying like, you know,
this is a disaster, you know, the president of the Italian medical body just died of COVID and,
you know, there's not enough hospital beds. And then I knew it kind of just, I think,
starting to get detected in New York. And I thought, oh, well, it seems like it might be quite
likely to come here. What does that mean for our course? You know, it's very, like, not at all
altruistic, just like, are we still going to do our course? So my wife and I kind of started
reading about it to try to figure out what should happen with the course. And as we did it, we were,
yeah, it's like very obvious that it was going to be a global pandemic. And it was going to sweep
through San Francisco within weeks. And so like, within two days, I guess, I wrote an email
to everybody who had registered, you know, I think, registered for course and put, you know,
put out a blog post and said, we're not doing the course live, we're going to do it virtually.
This is well before, you know, our university or I think any university had decided to do that,
which again, I already thought was weird. Like, I thought, like, okay, it's not
yet here, but obviously it's going to be. So why are people acting as if it's not going to be?
And so, yeah, Rachel and I ended up writing a long blog post, you know, because we were kind of like,
okay, it's not just our course. It's like, we know we've got all these friends in San Francisco who
are doing things that we're pretty sure they're going to look back on in hindsight and think
that was a terrible idea. Because I put myself in my community at risk. And so we said, like, okay,
we didn't know much about it. So we just said, look, as data scientists, here's
what we can see so far in the data. You know, it does seem to grow exponentially,
at least at first. And you know, this is the impact it's been having in one body. And
here's the early impact in New York. And here's like how the math of these kinds of, you know,
things work. And so here's like, not just a prediction, but an almost certainty as to what's
going to happen here. And that got a lot of attention. And we had no idea how to avoid it
ourselves. But we were worried that like, historically, you know, when there is global
pandemics, it can lead to, it can lead to violence, it can lead to societal disharmony,
whatever. So we, we decided to get out of San Francisco for a while. We also it's clear that
it was going to be there's going to be a lockdown at some point, because it's, you know, I mean,
why wouldn't there be, again, none of our friends seem to believe any of this is going to happen.
It's really, I thought it was weird, you know, like it just seemed very obvious. And then, yeah,
there was a lockdown like a week or two later, we had told our daughter's school, she's like,
oh, that's probably going to be a lockdown. You know, sent back this rather annoyed email about
interrupting learning or something. Yeah. And so the schools were closed for a year in the end in
San Francisco. So then we were like, oh, well, how do we, yeah, how do we like,
not get COVID? Because we probably don't want to get COVID because it seems like getting COVID can
be bad. We started to hear from people who would like, you know, saying maybe there could be longer
term implications of some of these kinds of SARS viruses. So I started looking into like how it
was spread. And I discovered that there's all these countries around China that had avoided
getting hit by COVID. And particularly Hong Kong, there's like literally a train line away from
Wuhan. And that just seems amazing, you know. And that's what I discovered that like Mongolia,
Taiwan, and Hong Kong all had this kind of, you know, either universal mask policy or universal
mask usage, kind of culturally. And I thought, oh, that's weird. Because I thought masks are
this kind of like weird thing that, I don't know, for some reason, you go to Chinatown,
you see people wearing masks. And I was like, oh, that's weird. You know, I didn't have much
notice of it. But then as I, yeah, started learning it was this respiratory, you know,
infection and it's kind of seemed to make sense. And so I read something in the Washington Post
talking about how in the Czech Republic, particularly the populace had independently
decided to wear masks, you know, heavily driven by a kind of a popular science YouTuber.
And basically, yeah, within like three or four days, you know,
the whole country had made enough masks for everybody. And their president was like talking
about how proud he was. And there, again, their like infection was going right was going the
opposite direction to other countries. I thought that was interesting. So yeah, I kind of read
an article about that. And then I talked to a guy who used to be very, you know, high up in the
government on the science policy side, and I asked him what's going on with masks. And he said, like,
well, you know, nobody thinks there's very convincing science about it. So he said, if you
want to convince people to wear masks, then you'd need, you know, find some better science.
So I contacted basically the 18 smartest scientific researchers I knew.
You know, everybody from from Max Friedman to saying it to Fecci and said, you know,
not just scientific researchers in the case of sociological researcher that said like,
you want to help me, but together the evidence. So that's where our paper came from.
Basically, everybody said yes, they all agreed. So suddenly we had this huge author group. So we
kind of set up a slack channel. And yeah, none of us like had a really strong opinion going in.
I had one of the world's best aerosol scientists, he was probably the strongest
opinion going in because this is his job. And he was like, well, let me explain aerosols to you.
And then what happened was there was this amazing couple of papers that actually used this laser
scattering light chamber thing to actually literally take videos of, you know, respiratory
particles suspended in the air, not suspended, but just they just float in the air. It showed
that they float in the air for up to an hour. And it showed that when somebody wears a mask,
they don't appear. And that was the point where I went from like curious and interested to a
hundred percent convinced. Because it'd be like as somebody said, like, I promise you, Lucas,
if you throw this ball at that wall, it won't bounce off, it will go through. And then you'd
be like, well, Jeremy, I'm not sure, but I'll give it a go. And you throw the ball at the wall,
and it bounces off. And you go like, Jeremy, I am very sure you're wrong about your theorem.
And that's how it was with masks. There are people who said like, our masks don't
provide respiratory protection from from these airborne particles. And here's a video of them
not going through the mask. So I was like, okay, that's, I don't need any RCTs. I don't like,
it's like, there's a video, it's a picture of it working. So yeah, so then I kind of went all in
on just trying to say to people, oh, no, there's actually a thing that stops the thing that infects
us. So we should wear them. And I found it extraordinarily bizarre that everybody didn't
just go, oh, look at that video of it working. Therefore, it works. So it's like a super
frustrating experience. Like, I don't, there's nothing I enjoy about researching masks. And
there's nothing I enjoy about political advocacy, you know, the former is boring, and the latter is
stressful. But when there's something that's so obviously can like save millions of lives and
also like avoid who knows what long-term harm, it just seems absolutely ethically required
to act on that. And so I, you know, spoke with all kinds of like world leaders and
politicians and celebrities and whatever. And at every jurisdiction, it was like this, like a whole
new conversation, you know, it's like talking to people in South Africa. And so I go, oh, we don't
believe in masks. It's like, talk to people in London, we don't believe in masks, talk to people
in Australia, we don't believe in masks, talk to people in Florida, we don't believe in masks. And
like each one, I discovered this horrible thing, which is everybody decided they didn't believe
in masks until their personal jurisdiction got hit hard by COVID, until the hospital started
filling up. And then they would get back to me and say, like, oh, tell me more about this masks
thing, Jeremy. And that was like infuriating, because of course the answer is, well, if you had
of put in mask mandates two months ago, then this wouldn't have happened. And now it's too late
because masks can reduce R by a bit, but not enough to reverse a full on pandemic once it's
there. So honestly, it, you know, I got really burned out by the process, like it was like in
some ways it was successful, but in the end, the pandemic still happened. And in the end, I'm still
yeah, flabbergasted, particularly now that like, high quality medical masks are like widely available.
Demand is so low that factories have been shutting down, you know. So yeah, I've never had COVID,
like literally nobody I know, who has worn a high quality mask at all times indoors.
No, none of them have got COVID, you know, and everybody I know who doesn't have all had COVID.
And there's a point at which is kind of say like, okay, I, I've done what I can, you know,
you do you. Do you, so you continue to wear a mask indoors at all times? Of course, yeah.
And I guess what would change, when would you stop wearing a mask indoors? I mean,
I suspect like the same as the answer question, when would I stop drinking clean water? I'd rather
keep drinking clean water, you know, like we decided, I mean, remember it took decades
even after the John Snow experiment to, you know, big cities to decide to invest in clean water
infrastructure. So presumably after some number of years, we will invest in clear air infrastructure.
So China's already done it. They now have, I believe, HIPAA filters in pretty much all their
public building buildings, and they're putting in UV sterilization in pretty much all their public
buildings. So hopefully at some point, the West will do the same thing. And then it'll be like,
okay, I'm in an environment with clean air. So I don't have to like, self-clean the air.
So that'd be one option. Another would be again, China's ahead of us on this, they have nasal
vaccines, which, you know, probably much more effective. So if we eventually get those, and
you know, I think they can actually make a significant dent on transmission,
which the injected vaccines don't make much of a big impact on transmission. So yeah,
there are technologies that should allow us to be able to be, I think, pretty safe in indoor spaces.
But you don't wear masks in outdoor space? That is that the...
No, I mean, it's not exactly a hard and fast rule. We went to a birthday party recently,
for example, where it was like a karaoke thing, and it was outdoors, but all the kids were singing,
and they were tightly packed and whatever. So our family wore a mask because there's
a high amount of aerosolizing activities going on with a high density of people. But yeah,
broadly speaking, I'm not too concerned about outdoors because the airborne particles disperse
much more quickly. I see. So I guess the interesting thing about that story maybe is that
there maybe was a fairly broad scientific consensus, but no one was really ready to advocate
for it. Is that a better summary of what was happening? If you got all these scientists
together and they actually all agreed with what you were saying? They didn't, unfortunately.
What happened was it was highly polarized by areas. So the people that actually understood
this are the aerosol scientists, and the aerosol science community was basically 100%
all on the same page of talking, breathing. These are aerosolizing activities. We have
loads of evidence that this is transmitted through aerosols. We have loads of evidence that
in the droplet nuclei that are suspended in the air, masks block those from getting to your lungs.
Like all those were pretty much understood in that community.
But then the challenge is, Lucas, that we haven't had a major respiratory pandemic in the west
really since the Spanish flu. So none of our infectious disease community has any background
in that. So I spent a lot of time advocating, including speaking directly to the WHO's
infection control groups or the folks that ran the response at the WHO. And they were overwhelmingly
people who had a background in infectious diseases that were spread through contact,
the kind of stuff that hand washing helps with. So they were just coming from a totally different
direction and had decades of experience on treating different kinds of diseases in a different way.
And they were doing their best to learn and understand. But for some, that was a very difficult
experience. And one in particular, John Connolly, his financial stake was very high in this
foamy transfer. Transmission is not through the air, but by contact because he has financial
interests in that being the case. So very difficult for him to come to terms with the idea that
this is a respiratory infection through respiratory particles requiring respiratory protection.
So yeah, that was a big challenge is this world view difference between different scientific
groups. And the aerosol scientists, there were actually none of them on the WHO's infection
protection committee or infection control, whatever it was. So I noticed when I was talking
to WHO, it was a total lack of diversity. Every single one had the same kind of academic background
and the same way of thinking about things. And they all knew each other very well. And they were
also, they also all saw being on being involved in the WHO as being a very strong status signal
in their career. So everybody wants to be invited to those kinds of things. And so you really want
to like have all the other people on the committee think you're a good, nice person. And so it creates
this real monoculture. So that was another big part of the problem. And it was all like, it definitely
made me a lot more cynical than I was before to see like how the WHO works. And even like our
big paper, like how to get it published, it took a year from being written to being published.
So by the time it was published, it was basically too late. And the process of getting it published
was much more about politics than about science, you know. And it was disappointing for me to discover
that systems that I had thought of as being like very much focused on rationality and data and
correctness and rigor. Yeah, so much of it turned out to be about politics and networks and stuff.
So I guess I was probably pretty naive before all that happened.
I mean, I guess my sense is that people broadly believe that masks reduce the spread of COVID at
this point. I mean, I'm not sure that I know exactly to what degree it sounds like you're
saying to like a really massive degree, but I think you had a part in that, or maybe just
I read this probably on Twitter and we're just watching you talk about it. But it doesn't seem
like it means too much. I was leading the mask serial group globally, like and we were the most
substantive group doing that. Absolutely. It feels like it was successful though. I mean, I just
it was successful-ish. Like I think it's, I mean, if you're in San Francisco, it'll look more
than successful than if you're in Australia, for example. In Australia, from time to time,
we've had mask mandates and everybody wears them when they're told to. The rest of the time,
it's strongly recommended, but nobody does. But like at San Francisco, I'm told like, I don't know,
maybe 30% of kicks at schools or some schools are wearing them. Like it's definitely like it's
it's, it's, it's disappearing. And also like people on a lot of people, maybe most people,
I see wearing masks, at least in Australia, are wearing masks that don't work very well,
even though the good masks are really easy to get. And a lot of people don't realize like, oh,
if you get a high quality and 95 respirator, you can wear that as many times as you like until
the straps wear out, you know, a lot of people think are anywhere at once. A lot of people think
it has to be fit tested. Like there's a lot of people think it's like donning and doffing is
some complicated thing. Yeah, there's all this like wrong information out there. And so the
number of people actually wearing high quality masks is, to me, it's surprisingly low. Like if
everybody wore one whenever they were indoors, you know, particularly if we also had HIPAA filters
in indoor spaces, I suspect we would be done with a virus that would go away, because how would a
respiratory virus continue to transmit when you break the flow of respiratory particles?
Yeah, I mean, even in China, like every other pictures I see, everybody's wearing surgical
masks, just like weird to me. Interesting. Well, look, we're almost out of time. And we always
end with two questions, but you're a little bit of an unusual guess. I don't know exactly how
well these will fit your worldview. But we like to, I like to ask people if you had some extra time
to research something completely different, what might it be? And I feel like you are just like a
unending font of this stuff. So what are some things that you're interested in that you haven't
had time to look into? Well, I'll answer a slightly different question, because like anytime I'm
interested in researching something, I just do. Fair enough. So the most recent thing I spent a lot
of time researching is children's education. So our daughter missed the first year of school
because of COVID in San Francisco, they were closed. That would have been her kind of
transitional kindergarten year, as they call it in California. And then we came to Australia,
and so she went to regular school for the first year here. And she was straight into grade one.
And she enjoyed it. She was always happy to go and happy to stay there. But
it felt like she had blossomed a lot more during her previous year when she was doing stuff over
Zerium and on apps and stuff than the year that she was in person in the classroom, which
really surprised me. And instead she had become much more of a perfectionist and was becoming
like much less resilient after her year at physical school. And that all seemed really weird to me,
because I thought that environment would be much more healthy than the previous one. So I started,
yeah, I started investigating it really carefully and studying a lot of academic papers about
education. And I was just stunned to discover that, yeah, there's kind of like pretty broad
consensus in parts of the academic community or some very strong data that suggests like schools
are not a particularly great place for most kids to really blossom or at least entirely focus on
school learning. And in fact, tutoring kids that do tutoring get tutoring are
like in the very top highest academic performers, regardless of their previous background,
like it seems like all kids can be really successful given the right tutoring. And that like
because our daughter was doing all this stuff with like apps and on zoom and stuff during her first
year, none of that is limited by the speed at which a teacher thinks a kid should go,
but instead the computer is dynamically adjusting difficulty over time. So weirdly enough,
our daughter did, you know, was basically at grade four or grade five of math after a few months of
doing these apps, you know, they're so much more effective than normal teaching. So we're also trying
to figure out like, well, how do you how do you avoid her getting really bored and stuff? So yeah,
so I did this really deep dive into education and discovered there's all these like
fascinating different ways of teaching and learning, which are entirely different to what's
done at normal schools. So eventually, yeah, we decided to take her out of school and
you know, instead switched to using these kind of more academically driven approaches in a
homeschooling environment, which also seemed to generally lead to better social outcomes,
you know, better mental outcomes, mental health outcomes, and better learning outcomes.
And so again, that's kind of been interesting to me to discover this like
whole world of research that seems really important, you know, for humanity,
how kids should learn and yeah, it feels like again, it's being largely ignored by
the institutions that we send our kids to.
And so wait, let me just summarize, see if I got the summary of this, basically that
tutors are much more effective than schools at actually teaching kids things. Is that
what you're saying?
That would be part of it. I mean, and then specific then, but I mean, there's lots of
so yeah, that's kind of one starting point. It's like, yes, even kids that would otherwise
have been doing pretty badly at school can be in the very top performers.
So like that kind of is an existence proof that pretty much all kids can be extremely successful.
But then there's also this kind of, yeah, interesting data point for us, which is when we
kind of gave our daughter an iPad and some, you know, math and reading apps and
somebody on the other end of a zoom to supervise them, she had a huge amount of fun and learnt
dramatically more quickly than I thought was possible. And then when she actually went to
school, she basically learned nothing for the whole year and ended up becoming much less resilient.
And then that yeah, that there are specific ways of learning that are not particularly
compatible with the normal ways we teach at school. So for example,
we might have talked before about like Anki and repetitive spaced learning, you know,
so my daughter does Anki every day. So like literally everything she learns,
she will remember forever if she put, you know, she creates a card for it, if she decides she
wants to know it. So yeah, so like it's, and that's kind of quite difficult to do at a normal
school because you did all of your grade levels to be doing Anki so that in grade five, you're still
got cards from grade one or grade two coming back. But what happens at school is like each year.
So for example, in Australia, the year seven and year eight math curriculums and nearly entirely
are a refresh of the primary school curriculum, because they kind of assume the kids are going
to need to see it again, because they've probably forgotten a lot of it. Things like how would you
incorporate spaced repetitive learning. Some schools in England have tried to do something
like that using something they call retrieval practice. And so I know there's a school called
the Makayla School, which I believe had the highest results academically in the whole country.
They do something like this. So there's a few, there's a handful of schools here and there which
are trying to use these kind of research results. But they're, yeah, they're kind of the odd ones
out. All right. And I guess like finally, I don't know if this one really applies to you. We usually
ask because you know that my company in this interview is all about sort of like making machine
learning really work in the real world. We usually ask like kind of what's the hard part that you
encountered in sort of like taking something from research to actually working for some purpose.
And that may not exactly apply to you, but you seem very good at sort of interpreting my questions
in a useful way. So I pose it in its most abstract form. I mean, I've, yeah, I've had
lots of projects that I've tried to bring into the real world. Of course. That's right. Yeah. So
and it's difficult, you know. Yeah. I mean, I've been doing machine learning projects for over 25
years now, believe it or not. And in the early days, you know, it was such a challenge because
managers didn't believe in the power of data at all. And when I would try to tell them that it
could be really valuable, they would always say like, can you point to a role model of a company
that's been successful because of their use of data? And there were none, you know, and that was
tough. Yeah. And then Google came along, which was great, you know, because then I could point
out this one company that was like really working hard to use data and they've become very valuable
because of it. Nowadays, that bit's a lot easier. But actually, unfortunately, my answer is going to
be that I've kind of, for a lot of companies I've given up on even trying, because I tried to get,
particularly when I was at Singularity University, where all of our students were basically execs
from giant companies. And we were trying to convince them to be more data focused. And some
of them really took that on board. And then they would like, invite me to come and talk to their
VP groups and exec groups. And I saw lots of big companies try to get more data driven, try to use
machine learning. I didn't see any being successful. And that the issue seemed to be
that their entire management teams were people who, that was not their area of expertise.
They were not promoted because they were good at that. They would have very smart,
data driven people down in their business analyst levels. But they would have no idea
which ones knew what they were talking about and have no way to curate what they were being told.
All of the promotion systems were based on experience and credentialing and
things other than analytical capabilities. So yeah, in those kinds of companies, I eventually
decided like, okay, maybe it's not possible for a legacy company to become a data driven company.
And so nowadays, I focused all of my attention on startups created by founders that are already
data driven and have a good understanding of analysis. And what we're seeing is increasingly
the most valuable companies, or particularly the most valuable companies in America, they're basically
all now tech startups. I mean, they're not startups anymore, but they're all companies
that are created by kind of engineers and data driven people. So I'd kind of, yeah, I think for
data scientists interested in making an impact, the best thing to do would be to try and make
sure you're at a company where that kind of work is appreciated and understood by the executive team.
Interesting. Well, great to talk to you. That was super fun. Thanks for answering my wide range
of questions. Yeah, it's always so inspiring to talk to you. I really appreciate it. Oh, thank you.
If you're enjoying these interviews and you want to learn more, please click on the link to the
show notes in the description where you can find links to all the papers that are mentioned,
supplemental material, and a transcription that we worked really hard to produce. So check it out.
And how is everything going at Weights and Biases? I always hear nothing but good things
about it. Everybody loves it. I got to admit, actually, the other day I was talking to my
friend, I think it was Tanishk, about like, oh, what's going on with this learning rate here?
I wonder if it's working properly. And then he's like, oh, well, here's a graph of the learning
rate. I was like, oh, that was quick and great. Where did that come from? And he's like,
Weights and Biases. He blocks it. Oh, he's still recording. Put that on there. I probably should
have looked at the Weights and Biases team. Here I was with like, plot dot plot x equals,
he's already got it pasted into the discord chat. All right, well, that'd be a great day. Thanks.
Cheers, mate.
