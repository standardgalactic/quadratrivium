WEBVTT

00:00.000 --> 00:05.000
Okay, welcome everybody.

00:05.000 --> 00:07.000
Very glad you could make it for this talk.

00:07.000 --> 00:09.000
I've been working on this for a while.

00:09.000 --> 00:10.000
I'm really excited about it.

00:10.000 --> 00:14.000
If you don't know me, I am Gabriel,

00:14.000 --> 00:17.000
and I'm an instructor here at Fullstack Academy of Code.

00:17.000 --> 00:20.000
My social media presence is G. Lebec everywhere,

00:20.000 --> 00:23.000
except, unfortunately, and somewhat ironically,

00:23.000 --> 00:25.000
given the subject of this talk at Twitter,

00:25.000 --> 00:27.000
where I was forced to use an underscore.

00:27.000 --> 00:30.000
There's going to be resources available on my GitHub

00:30.000 --> 00:32.000
at slash G. Lebec slash Lambda Talk,

00:32.000 --> 00:35.000
so you can go find additional stuff after this.

00:35.000 --> 00:38.000
All right, so let's just dive in and get started.

00:38.000 --> 00:41.000
I want to start by pointing out a minute node ripple here.

00:41.000 --> 00:44.000
I can do kind of typical JavaScript-y stuff,

00:44.000 --> 00:47.000
but we're going to avoid JavaScript in the sort of classical sense

00:47.000 --> 00:50.000
as much as possible, and start off with this function

00:50.000 --> 00:53.000
called I or identity.

00:53.000 --> 00:55.000
Now, just looking at the function,

00:55.000 --> 00:57.000
if I invoke it with some value,

00:57.000 --> 00:59.000
what am I going to get back here?

00:59.000 --> 01:04.000
Yeah, identity of one is one, identity of two is two.

01:04.000 --> 01:08.000
What about the identity of identity?

01:08.000 --> 01:11.000
Yeah, it's the identity function.

01:11.000 --> 01:14.000
So, very simply, the identity combinator

01:14.000 --> 01:19.000
is a function that takes in an input A

01:19.000 --> 01:21.000
and it returns an output A.

01:21.000 --> 01:24.000
Basically, it just reflects back a value.

01:24.000 --> 01:26.000
So, the identity of any X is X,

01:26.000 --> 01:28.000
and we saw that in this particular paradigm,

01:28.000 --> 01:31.000
we're allowed to use functions as arguments.

01:31.000 --> 01:33.000
Verbs are nouns and nouns are verbs,

01:33.000 --> 01:37.000
so the identity of identity is itself.

01:37.000 --> 01:40.000
In Haskell, this is actually built into the Prelude module,

01:40.000 --> 01:43.000
which is the base standard module for the language,

01:43.000 --> 01:45.000
as the ID function.

01:45.000 --> 01:47.000
As you can see, it takes an argument five

01:47.000 --> 01:49.000
and gives you back five.

01:49.000 --> 01:52.000
So, looking at this, I just flashed a bunch of stuff on the screen.

01:52.000 --> 01:54.000
You might be thinking, what's this lambda stuff

01:54.000 --> 01:56.000
that's sitting up here?

01:56.000 --> 01:58.000
So, lambda is a signifier.

01:58.000 --> 02:00.000
It's a notation that we're going to use

02:00.000 --> 02:03.000
to indicate that we're starting the definition of a function.

02:03.000 --> 02:07.000
So, we can read this as we're starting to define a function,

02:07.000 --> 02:10.000
which takes a single input or parameter,

02:10.000 --> 02:13.000
and it returns some expression, some body.

02:13.000 --> 02:16.000
And this whole thing is called a lambda abstraction

02:16.000 --> 02:17.000
in the lambda calculus,

02:17.000 --> 02:21.000
but it basically just means it's a unary anonymous function.

02:21.000 --> 02:24.000
Unary meaning it takes a single input.

02:24.000 --> 02:29.000
The lambda calculus is a really tiny symbol manipulation framework.

02:29.000 --> 02:33.000
A calculus is just a way of moving around symbols on a page.

02:33.000 --> 02:37.000
The subject that you may have learned in school called calculus

02:37.000 --> 02:40.000
is a specific calculus for things like differentials

02:40.000 --> 02:44.000
and integrals and stuff like that, derivatives.

02:44.000 --> 02:47.000
And so, this calculus is about something else.

02:47.000 --> 02:52.000
This calculus is about evaluating and defining functions.

02:52.000 --> 02:55.000
So, in the lambda calculus, we have variables,

02:55.000 --> 02:57.000
which are pretty boring.

02:57.000 --> 02:58.000
Please come in.

02:58.000 --> 03:00.000
We've got expressions,

03:00.000 --> 03:05.000
which are the application of some function to its argument.

03:05.000 --> 03:09.000
We've got an expression that is itself a function definition,

03:09.000 --> 03:13.000
an abstraction instead of a concrete thing like 1 plus 5,

03:13.000 --> 03:15.000
1 plus 6, 1 plus 7.

03:15.000 --> 03:18.000
We have something like 1 plus A.

03:18.000 --> 03:20.000
And A can be anything.

03:20.000 --> 03:22.000
It's become abstracted.

03:22.000 --> 03:25.000
And we have groupings to disambiguate the order

03:25.000 --> 03:28.000
in which we should be doing certain operations.

03:28.000 --> 03:30.000
This is the entire lambda calculus.

03:30.000 --> 03:31.000
All right.

03:31.000 --> 03:32.000
So, talk's over.

03:32.000 --> 03:33.000
I can go home now.

03:33.000 --> 03:35.000
No, we're going to see some examples of this.

03:35.000 --> 03:39.000
So, let's start with just a couple of cross comparisons here.

03:39.000 --> 03:43.000
Variables in the lambda calculus, as I mentioned, are extremely boring.

03:43.000 --> 03:47.000
One thing to note here is that these variables are immutable.

03:47.000 --> 03:49.000
They cannot be changed after the fact.

03:49.000 --> 03:53.000
There's no concept of assignment, per se, in the lambda calculus.

03:53.000 --> 03:55.000
There is binding, which we'll see shortly.

03:55.000 --> 03:58.000
But if this variable is bound to a value,

03:58.000 --> 04:02.000
that's its value for now and forevermore.

04:02.000 --> 04:05.000
So, no, let all const.

04:05.000 --> 04:07.000
Applications are slightly more interesting.

04:07.000 --> 04:09.000
This is applying a function to its arguments.

04:09.000 --> 04:12.000
And in the lambda calculus, that's just juxtaposition.

04:12.000 --> 04:14.000
It's just a space.

04:14.000 --> 04:16.000
There's no parens for invocation,

04:16.000 --> 04:19.000
which at first, if you're used to something like JavaScript,

04:19.000 --> 04:21.000
it's a little disconcerting.

04:21.000 --> 04:25.000
But in reality, it ends up removing a lot of noise from our expressions.

04:25.000 --> 04:26.000
And as this talk goes on,

04:26.000 --> 04:30.000
you're probably going to see it's becoming easier and easier to read the lambda calculus

04:30.000 --> 04:33.000
rather than trying to parse the JavaScript.

04:33.000 --> 04:36.000
So, here we apply a function f to its argument a.

04:36.000 --> 04:38.000
We can apply multiple arguments,

04:38.000 --> 04:41.000
but in the lambda calculus, all functions are unary.

04:41.000 --> 04:43.000
So, this is really a curried function.

04:43.000 --> 04:45.000
This is an f that takes an a,

04:45.000 --> 04:47.000
and that returns a new function,

04:47.000 --> 04:50.000
which is not written down, which takes a b.

04:50.000 --> 04:52.000
Let's try this out.

04:52.000 --> 04:56.000
Let's do kind of a classic example of a curried addition function.

04:56.000 --> 04:58.000
We'll say that add takes an a,

04:58.000 --> 05:03.000
and it takes a b, and it returns a plus b.

05:03.000 --> 05:08.000
So, if we call add with just some single argument,

05:08.000 --> 05:10.000
we get back some function.

05:10.000 --> 05:13.000
If we call that function with an additional argument,

05:13.000 --> 05:16.000
now we get the final result.

05:16.000 --> 05:19.000
Pretty familiar stuff, I think, for this crowd.

05:19.000 --> 05:23.000
So, f a b, you can read that as first it takes an a,

05:23.000 --> 05:25.000
and then a b, and if there are more arguments,

05:25.000 --> 05:27.000
they get fed in one by one,

05:27.000 --> 05:31.000
going from the leftmost argument onwards,

05:31.000 --> 05:33.000
marching kind of toward the right.

05:33.000 --> 05:36.000
We can make this clear with parentheses.

05:36.000 --> 05:39.000
We can say, first apply f to a,

05:39.000 --> 05:41.000
and then apply the result of that to b,

05:41.000 --> 05:43.000
but this isn't necessary because we say

05:43.000 --> 05:45.000
that function application is left associative.

05:45.000 --> 05:47.000
So, these are really useless parentheses,

05:47.000 --> 05:51.000
and we'll omit them in most of our examples.

05:51.000 --> 05:54.000
Finally, we can use parentheses to force evaluations

05:54.000 --> 05:56.000
to occur in a different order.

05:56.000 --> 05:58.000
So, here this is actually a different expression.

05:58.000 --> 06:01.000
This means something else in the lambda calculus.

06:01.000 --> 06:03.000
It means we're going to first apply a to b,

06:03.000 --> 06:07.000
and the result of that will be the argument to f.

06:07.000 --> 06:09.000
Hi, hello.

06:09.000 --> 06:11.000
Welcome.

06:11.000 --> 06:16.000
So, just to summarize for everybody who's just arrived,

06:16.000 --> 06:18.000
we're starting to define the syntax

06:18.000 --> 06:22.000
of a very small language called the lambda calculus.

06:22.000 --> 06:25.000
And this is just something that takes functions,

06:25.000 --> 06:27.000
applications of functions to arguments,

06:27.000 --> 06:29.000
and parentheses for grouping.

06:29.000 --> 06:31.000
That's really it.

06:31.000 --> 06:34.000
So, really high level review of just this last slide.

06:34.000 --> 06:37.000
F a means invoke f with a,

06:37.000 --> 06:40.000
and you'll get more as we go.

06:40.000 --> 06:43.000
So, let's talk about function definition in the lambda calculus.

06:43.000 --> 06:45.000
As I said before, we use a lambda to indicate

06:45.000 --> 06:47.000
that we're defining a new function.

06:47.000 --> 06:49.000
So, we got lambda calculus on the left,

06:49.000 --> 06:50.000
JavaScript on the right.

06:50.000 --> 06:53.000
This is a function that takes an a and returns whatever b is.

06:53.000 --> 06:55.000
Sort of throws away a,

06:55.000 --> 06:58.000
a b becomes irrelevant in this expression.

06:58.000 --> 07:01.000
The function abstraction like this is greedy.

07:01.000 --> 07:05.000
The body swallows up as much stuff to the right as it can,

07:05.000 --> 07:08.000
and that's all included in the body of this lambda abstraction.

07:08.000 --> 07:11.000
So, up into the point where it would stop making sense,

07:11.000 --> 07:16.000
like if you're using parens to force things to be evaluated differently.

07:16.000 --> 07:19.000
So, this indicates a function that takes an a,

07:19.000 --> 07:23.000
and it invokes b with x as its argument.

07:23.000 --> 07:25.000
We can disambiguate this with parentheses,

07:25.000 --> 07:28.000
but as I said, since lambda abstractions

07:28.000 --> 07:30.000
greedily swallow up everything to the right,

07:30.000 --> 07:32.000
these are actually useless parentheses,

07:32.000 --> 07:37.000
and we'll not really show them in most of the upcoming examples.

07:37.000 --> 07:39.000
On the other hand, if we use parentheses

07:39.000 --> 07:42.000
to force the thing on the left to be a function with a body

07:42.000 --> 07:45.000
that's just the b variable,

07:45.000 --> 07:48.000
now this is a different expression.

07:48.000 --> 07:51.000
Now we're saying take a function that goes from a to b

07:51.000 --> 07:56.000
and apply it to the argument x.

07:56.000 --> 07:59.000
As we saw a second ago in a demonstration

07:59.000 --> 08:02.000
in the lambda calculus we're allowed to nest functions.

08:02.000 --> 08:05.000
So, this is a function that takes an a

08:05.000 --> 08:09.000
and returns a new function that new function takes a b

08:09.000 --> 08:12.000
and that function returns an a.

08:12.000 --> 08:16.000
So, just to reprise our curried addition function from a second ago,

08:16.000 --> 08:19.000
we have this function that takes an a,

08:19.000 --> 08:21.000
returns a function that takes a b,

08:21.000 --> 08:23.000
and that returns a plus b.

08:23.000 --> 08:28.000
So, we have to feed out the arguments not like this all at once,

08:28.000 --> 08:32.000
but rather each argument one at a time

08:32.000 --> 08:36.000
in a successive invocations,

08:36.000 --> 08:41.000
and we get the result we want, known as currying.

08:41.000 --> 08:44.000
Again, we can clarify this using parentheses.

08:44.000 --> 08:47.000
The lambda on the left returns the inner lambda,

08:47.000 --> 08:49.000
and then we can use that.

08:49.000 --> 08:51.000
But since these are useless parentheses,

08:51.000 --> 08:55.000
we'll omit them in most of the examples.

08:55.000 --> 08:56.000
How are we doing so far?

08:56.000 --> 09:00.000
Questions about the bare syntax of the lambda calculus?

09:00.000 --> 09:03.000
As you can see, it's very similar to JavaScript,

09:03.000 --> 09:06.000
except you don't have parentheses around function invocation.

09:06.000 --> 09:08.000
You just put things next to each other,

09:08.000 --> 09:10.000
and that indicates apply a function on the left

09:10.000 --> 09:14.000
to the argument on the right.

09:14.000 --> 09:16.000
Cool.

09:16.000 --> 09:17.000
All right.

09:17.000 --> 09:19.000
So, I swear this is going to be the most complicated bit

09:19.000 --> 09:21.000
of lambda calculus syntax we have to deal with.

09:21.000 --> 09:23.000
It's called beta reduction.

09:23.000 --> 09:26.000
It's got a scary name, but it really just means

09:26.000 --> 09:30.000
tracing the logic, evaluating the function invocations,

09:30.000 --> 09:32.000
seeing what we end up with.

09:32.000 --> 09:36.000
So beta reduction is just the act of taking a function

09:36.000 --> 09:39.000
and applying it to its argument.

09:39.000 --> 09:41.000
So here we've got this function in red

09:41.000 --> 09:43.000
applied to the argument underlined.

09:43.000 --> 09:45.000
What we do is we take the argument,

09:45.000 --> 09:48.000
and it comes in as the parameter of the function.

09:48.000 --> 09:51.000
This is a function that takes an A and returns an A.

09:52.000 --> 09:55.000
So this argument, the BCB function,

09:55.000 --> 09:59.000
is going to replace in the body of the function every A.

09:59.000 --> 10:01.000
We go look in the body, find all the As,

10:01.000 --> 10:04.000
and we substitute in this other expression.

10:04.000 --> 10:09.000
And that gives us this first simplification.

10:09.000 --> 10:11.000
Well, we continue doing this.

10:11.000 --> 10:13.000
We've got a new function, the BCB function,

10:13.000 --> 10:16.000
being applied to another argument, the X argument.

10:16.000 --> 10:18.000
So we're going to take the X argument

10:18.000 --> 10:22.000
and substitute it in as the parameter to the function.

10:22.000 --> 10:24.000
So we go look inside the function body,

10:24.000 --> 10:27.000
find all the B's, and replace them all with X's.

10:27.000 --> 10:31.000
And we get this new function as a result.

10:31.000 --> 10:33.000
Once again, we've got a function

10:33.000 --> 10:35.000
that we're going to apply to an argument.

10:35.000 --> 10:39.000
We take the argument, we pass it into the function's parameter.

10:39.000 --> 10:41.000
We go look in the body for all the C's.

10:41.000 --> 10:43.000
There are no C's in this body.

10:43.000 --> 10:45.000
We replace all the C's with that argument,

10:45.000 --> 10:48.000
and that gives us this simplification.

10:48.000 --> 10:50.000
At this point, we've got nothing left to do.

10:50.000 --> 10:52.000
There are no more reducible expressions.

10:52.000 --> 10:54.000
So we say this is in beta normal form,

10:54.000 --> 10:56.000
which is just a hilarious way of saying

10:56.000 --> 11:01.000
we've fully evaluated the function in a terminal way.

11:01.000 --> 11:04.000
So it looks a little dense

11:04.000 --> 11:06.000
compared to what you're used to with JavaScript,

11:06.000 --> 11:11.000
but it's really nothing that we haven't done many times in JavaScript.

11:11.000 --> 11:14.000
Taking a function, passing in arguments as the parameters,

11:14.000 --> 11:17.000
and then in the body, everywhere that parameter exists,

11:17.000 --> 11:20.000
it's been replaced by a value.

11:20.000 --> 11:22.000
There's some caveats here.

11:22.000 --> 11:24.000
I'm not going to cover in this presentation.

11:24.000 --> 11:26.000
If you could do multiple reductions

11:26.000 --> 11:29.000
in different places in the expression simultaneously,

11:29.000 --> 11:33.000
there are caveats and strategies to which ones you should do first.

11:33.000 --> 11:37.000
And there's also possible ways that two separate functions

11:37.000 --> 11:39.000
that coincidentally share the same variable names,

11:39.000 --> 11:42.000
you want to avoid conflating those two variables,

11:42.000 --> 11:43.000
which mean different things.

11:43.000 --> 11:45.000
So there are some gotchas,

11:45.000 --> 11:49.000
but they're kind of outside the scope of this talk.

11:49.000 --> 11:52.000
Let's see another combinator here, the mockingbird.

11:52.000 --> 11:54.000
This is a fun function.

11:54.000 --> 11:56.000
It takes a function as input,

11:56.000 --> 12:01.000
and it invokes that function passing in itself.

12:01.000 --> 12:05.000
This is the self-application combinator.

12:05.000 --> 12:06.000
Whoa, what's happening here?

12:06.000 --> 12:07.000
This is craziness.

12:07.000 --> 12:08.000
Let's try it out.

12:08.000 --> 12:11.000
The mockingbird is a function that takes a function,

12:11.000 --> 12:14.000
calls the function on itself.

12:14.000 --> 12:17.000
What might the mockingbird of identity be?

12:17.000 --> 12:23.000
Somebody walked me through the logic here.

12:23.000 --> 12:26.000
What's f in this function?

12:26.000 --> 12:28.000
It's the identity.

12:28.000 --> 12:30.000
What are we doing with it?

12:30.000 --> 12:35.000
Identity of identity.

12:35.000 --> 12:37.000
We already solved that before, right?

12:37.000 --> 12:38.000
What is the answer?

12:38.000 --> 12:40.000
It's the identity.

12:40.000 --> 12:42.000
The self-application of identity is identity.

12:42.000 --> 12:45.000
We saw that earlier.

12:45.000 --> 12:48.000
This one's going to be a little bit more disconcerting.

12:48.000 --> 12:53.000
What is the self-application of self-application?

12:53.000 --> 12:56.000
Feel free to yell it out if you think you got it.

12:56.000 --> 13:05.000
It may be hinted at by the fact that I'm putting this in a try-catch block.

13:05.000 --> 13:10.000
Any takers?

13:10.000 --> 13:12.000
Call stack size exceeded.

13:12.000 --> 13:14.000
What just happened?

13:14.000 --> 13:19.000
Well, mockingbird of identity is identity of identity, self-application.

13:19.000 --> 13:23.000
We already know that that is identity, so that made sense.

13:23.000 --> 13:26.000
That does reduce to a better normal form.

13:26.000 --> 13:31.000
But the mockingbird of the mockingbird is the self-application of self-application.

13:31.000 --> 13:35.000
So we take self-application and we apply it to itself.

13:35.000 --> 13:39.000
But if we're going to evaluate that, that's the self-application of self-application.

13:39.000 --> 13:45.000
So we take the self-application and uh-oh, it just goes on forever.

13:45.000 --> 13:47.000
This is a problem.

13:47.000 --> 13:53.000
The problem is we don't always know if some lambda term is going to have a beta normal form.

13:53.000 --> 13:56.000
We don't know if this process ends or not.

13:56.000 --> 13:58.000
Sometimes it doesn't end.

13:58.000 --> 14:02.000
Sometimes it diverges, which means it goes on forever.

14:02.000 --> 14:07.000
And in fact, there's no way to know in a general way if a given expression,

14:07.000 --> 14:12.000
there's no single algorithm that can tell you whether or not one of these expressions will stop.

14:12.000 --> 14:15.000
That's known as the halting problem and Alan Turing figured it out.

14:15.000 --> 14:21.000
Now for an individual one, you can prove through ad hoc means that, yeah,

14:21.000 --> 14:23.000
for instance, this one is going to go on forever.

14:23.000 --> 14:28.000
So it's not that it's always unanswerable, just that there's no one set of steps that you can take

14:28.000 --> 14:34.000
that will cause that, that you will know whether or not it halts.

14:34.000 --> 14:39.000
This particular divergent term, by the way, is called the omega combinator.

14:39.000 --> 14:44.000
Omega because it's like the end, alpha and the omega.

14:44.000 --> 14:48.000
And sometimes the mockingbird as a result is called little omega.

14:48.000 --> 14:52.000
One of the problems you'll find if you start going out and reading about all this stuff

14:52.000 --> 14:56.000
is that a lot of different mathematicians and programmers and people have worked on it over time

14:56.000 --> 14:59.000
and they've all given their own pet names to these things.

14:59.000 --> 15:05.000
So there's a lot of synonyms and sometimes even intersection.

15:05.000 --> 15:10.000
Okay, we're almost done with lambda calculus syntax, but I lied before and I said it was the end.

15:10.000 --> 15:13.000
There's one more thing I want to show you about syntax here.

15:13.000 --> 15:17.000
We can do, as I said before, these nested lambdas.

15:17.000 --> 15:22.000
We could say there's a function that takes an A and that returns a function that takes a B,

15:22.000 --> 15:26.000
which returns a function that takes a C, which finally returns a B.

15:26.000 --> 15:31.000
But the way we're using these functions, we just kind of think of, well,

15:31.000 --> 15:35.000
we're going to call it with both arguments at once in quotes,

15:35.000 --> 15:38.000
really meaning we feed it the first argument then the second argument.

15:38.000 --> 15:42.000
But we think of it as taking two arguments just in a curried way.

15:42.000 --> 15:47.000
So in order to kind of make it easier to write this stuff down and parse it,

15:47.000 --> 15:51.000
there's a little bit of a shorthand where we just condense all the nested lambdas

15:51.000 --> 15:53.000
and say, here's a ternary function.

15:53.000 --> 15:56.000
Here's a function that takes three inputs and returns something.

15:56.000 --> 15:58.000
But don't get fooled.

15:58.000 --> 16:01.000
These don't come in all simultaneously.

16:01.000 --> 16:05.000
We feed them into the function one after the other.

16:05.000 --> 16:09.000
So this still means nested lambda expressions.

16:09.000 --> 16:14.000
It's just a convenient shorthand for indicating that they're curried.

16:14.000 --> 16:17.000
I'm not going to go through all of the logic of this again.

16:17.000 --> 16:22.000
It's the exact same example we saw before of feeding an argument into its parameter

16:22.000 --> 16:26.000
and replacing the parameter in the body, feeding an argument into its parameter

16:26.000 --> 16:29.000
and replacing the parameter in the body.

16:29.000 --> 16:35.000
But this time I've used the syntax shorthand to show those nested lambdas.

16:35.000 --> 16:40.000
So the body of this one is another lambda and then we proceed as normal

16:40.000 --> 16:44.000
and the rest of this is exactly identical to what we saw before.

16:44.000 --> 16:46.000
So just a shorthand.

16:46.000 --> 16:49.000
Don't get too tripped up over it, but it's going to be convenient for us

16:49.000 --> 16:53.000
to be able to think conceptually of functions that take multiple arguments

16:53.000 --> 16:58.000
even though we know, we'll just keep that as a footnote, that they're all curried functions.

16:58.000 --> 17:01.000
Are you ready for the next combinator?

17:01.000 --> 17:04.000
Let's talk about the kestrel.

17:04.000 --> 17:10.000
The kestrel takes an A and a B and it returns A.

17:10.000 --> 17:15.000
Let's try that out.

17:15.000 --> 17:19.000
Takes an A, takes a B, returns A.

17:19.000 --> 17:23.000
What is the kestrel of the identity in the mockingbird?

17:23.000 --> 17:26.000
Yeah.

17:26.000 --> 17:31.000
What about the kestrel of the kestrel in the mockingbird?

17:31.000 --> 17:34.000
Right.

17:34.000 --> 17:38.000
It doesn't matter what the second thing is, it's irrelevant.

17:38.000 --> 17:48.000
The kestrel just takes two things and returns the first one.

17:48.000 --> 17:52.000
So we just saw that here.

17:52.000 --> 17:57.000
In Haskell, this is built into the base language as the const function.

17:57.000 --> 17:59.000
Why is it called const in Haskell?

17:59.000 --> 18:01.000
Let's try something interesting here.

18:01.000 --> 18:09.000
I'm going to say k5 is the function you get when you call k with only one of its arguments.

18:09.000 --> 18:12.000
So normally the kestrel takes two arguments and gives you back the first one,

18:12.000 --> 18:15.000
but I'm only going to give it one of its arguments.

18:15.000 --> 18:21.000
Well, that's interesting, but these are curried functions, so I can give it another argument.

18:21.000 --> 18:23.000
It gives me back the first thing.

18:23.000 --> 18:25.000
I can also give it back some other argument.

18:25.000 --> 18:27.000
It gives me back the first thing.

18:27.000 --> 18:30.000
This is a function that's fixated on a particular value.

18:30.000 --> 18:32.000
It's the constant five function.

18:32.000 --> 18:38.000
No matter how I invoke this function, it always gives me back five.

18:38.000 --> 18:41.000
That's why it's called const in Haskell.

18:41.000 --> 18:44.000
But it's the k-combinator.

18:44.000 --> 18:46.000
Here's a fun one.

18:46.000 --> 18:48.000
I really like this one.

18:48.000 --> 18:52.000
The kestrel of identity and some x is?

18:52.000 --> 18:53.000
Identity.

18:53.000 --> 18:55.000
Identity, makes sense.

18:55.000 --> 18:57.000
This is an algebraic equality.

18:57.000 --> 19:01.000
The thing on the left is the thing on the right and vice versa.

19:01.000 --> 19:04.000
Well, the thing on the right is a function.

19:04.000 --> 19:09.000
And I know in the lambda calculus I'm allowed to apply functions to values.

19:09.000 --> 19:11.000
So I apply this to y.

19:11.000 --> 19:14.000
What do I get?

19:14.000 --> 19:15.000
Yy.

19:15.000 --> 19:17.000
Y, that makes sense.

19:17.000 --> 19:21.000
On the left side equals the middle side equals the right side.

19:21.000 --> 19:23.000
That means I can ignore the thing in the middle,

19:23.000 --> 19:25.000
and the thing on the left equals the thing on the right.

19:25.000 --> 19:28.000
Does anybody see where I'm going with this?

19:28.000 --> 19:34.000
I've got ki of x and y returns y.

19:34.000 --> 19:40.000
Ki of a first argument and a second argument returns the second argument.

19:40.000 --> 19:45.000
I just derived the kite.

19:46.000 --> 19:51.000
The kite combinator takes two arguments.

19:51.000 --> 19:53.000
One and two.

19:53.000 --> 19:56.000
And it gives you back the second one.

19:56.000 --> 19:58.000
Now, I could have done this manually.

19:58.000 --> 20:04.000
I could have said the kite is a function that takes an a,

20:04.000 --> 20:08.000
and it takes a b, and it returns b.

20:08.000 --> 20:12.000
And then I would call the kite on something like four and nine,

20:12.000 --> 20:14.000
and it gives me back nine.

20:14.000 --> 20:20.000
But it's cool to see that from these atomic combinators combined together,

20:20.000 --> 20:23.000
I get these new molecules, which are other combinators.

20:23.000 --> 20:26.000
So some of my combinators can mix and match

20:26.000 --> 20:31.000
and start producing other functions that are useful and interesting in different ways.

20:31.000 --> 20:38.000
So ki of m and ki is?

20:38.000 --> 20:42.000
Yes.

20:42.000 --> 20:45.000
So kite of the mockingbird in the Kestrel's castle.

20:45.000 --> 20:46.000
Flip them around.

20:46.000 --> 20:47.000
You get the other one.

20:47.000 --> 20:49.000
So far, so good.

20:49.000 --> 20:52.000
At this point, probably some of you are wondering,

20:52.000 --> 20:54.000
what's with all the bird names?

20:54.000 --> 20:57.000
Got mockingbird, Kestrel, kite, et cetera.

20:57.000 --> 20:58.000
All right.

20:58.000 --> 21:01.000
So we're going to take a little mental break for a moment and talk about history.

21:01.000 --> 21:04.000
Moses Eliachchenfinkel.

21:04.000 --> 21:07.000
And I can't pronounce German, so please forgive me.

21:07.000 --> 21:10.000
Name these things, long German names.

21:10.000 --> 21:15.000
Like Zussim et Setsum function.

21:15.000 --> 21:18.000
Haskell B. Curry, who came a little bit later,

21:18.000 --> 21:22.000
used some of the same letters, but also some of his own letters,

21:22.000 --> 21:24.000
just to add to the confusion.

21:24.000 --> 21:29.000
And in the 1980s, a logician and puzzle author named Raymond Smullyan

21:29.000 --> 21:32.000
wrote this absolutely wonderful book to mock a mockingbird.

21:32.000 --> 21:37.000
The whole back two thirds of which is about combinatorial logic.

21:37.000 --> 21:42.000
And Smullyan took Curry's combinator names and turned them into birds.

21:42.000 --> 21:47.000
And the reason is because the book doesn't lay a lot of emphasis

21:47.000 --> 21:50.000
on the math from a formal perspective.

21:50.000 --> 21:54.000
Instead, it uses this metaphor of birds in a forest

21:54.000 --> 21:59.000
who hear the songs of other birds and sing back the names of other birds.

21:59.000 --> 22:03.000
So birds creating birds and singing birds and all this kind of stuff.

22:04.000 --> 22:08.000
Now, unfortunately, Smullyan called the identity combinator the idiot bird.

22:08.000 --> 22:10.000
I wish that he had used the ibis.

22:10.000 --> 22:14.000
I used the ibis in my first slide, but we'll forgive him

22:14.000 --> 22:17.000
because the rest of the book is just so wonderful.

22:17.000 --> 22:20.000
Now, he didn't do this totally for no reason.

22:20.000 --> 22:25.000
He actually did it to honor Curry because Curry was himself an avid bird watcher.

22:25.000 --> 22:30.000
And at this point, some of you are thinking, Haskell Curry, who's this guy?

22:30.000 --> 22:32.000
Why do we care about him?

22:32.000 --> 22:35.000
I'm not Sean Finkel or vice versa.

22:35.000 --> 22:40.000
So the next slide is the anti-diversity slide.

22:40.000 --> 22:44.000
This is just the historical nature of mathematics in the 20s and 30s.

22:44.000 --> 22:46.000
It was filled with a lot of white men.

22:46.000 --> 22:49.000
So we'll acknowledge that and move on.

22:49.000 --> 22:52.000
But I'm going to give you a really fast crash course

22:52.000 --> 22:54.000
in the formalization of mathematical logic.

22:54.000 --> 22:58.000
Around the late 19th century, early 20th century,

22:58.000 --> 23:02.000
people were realizing that math, which had seemed on the face of it

23:02.000 --> 23:07.000
so cut and dried and straightforward, was hiding some really nasty paradoxes.

23:07.000 --> 23:10.000
And so people were trying to unify mathematics and figure out

23:10.000 --> 23:15.000
the sufficient axioms that would define all of mathematics in one big tone.

23:15.000 --> 23:18.000
So what was like the real, true system of math?

23:18.000 --> 23:20.000
Bless you.

23:20.000 --> 23:22.000
So I'm going to race through this.

23:22.000 --> 23:23.000
I could do an entire presentation.

23:23.000 --> 23:25.000
That would be two hours on just this.

23:25.000 --> 23:29.000
I'm going to try and keep it to less than five minutes.

23:29.000 --> 23:34.000
In 89, Giuseppe Piano invents his own formal notation for function abstraction.

23:34.000 --> 23:39.000
He also defines arithmetic as the sequence of natural numbers starting from zero,

23:39.000 --> 23:43.000
and then the successor of zero, and then the successor of successor of zero,

23:43.000 --> 23:46.000
and the successor of successor of successor of zero, and so on and so forth.

23:46.000 --> 23:49.000
These are Piano numbers.

23:49.000 --> 23:55.000
The logician Gottlob Frege develops his own function notation,

23:55.000 --> 23:57.000
which uses this really unique graph format.

23:57.000 --> 23:59.000
It's actually really cool to say.

23:59.000 --> 24:01.000
Impossible to read.

24:01.000 --> 24:06.000
But a good idea, a good idea which has better versions that come later.

24:06.000 --> 24:11.000
And most famously, he basically invents quantified axiomatic logic.

24:11.000 --> 24:15.000
So this is the kind of sentence like, for all x in the reals,

24:15.000 --> 24:19.000
there exists a y in the reals such that y is greater than x.

24:19.000 --> 24:22.000
For all, and there exists.

24:22.000 --> 24:26.000
That's the quantification and quantified axiomatic logic.

24:26.000 --> 24:31.000
By the way, Frege, even in 1891, was using curried functions.

24:31.000 --> 24:36.000
In the 1910s, Bertrand Russell, along with Whitehead,

24:36.000 --> 24:38.000
very famously published Principia Mathematica,

24:38.000 --> 24:41.000
an attempt at formalizing all math,

24:41.000 --> 24:45.000
but he also discovered earlier than that, actually, Russell's paradox,

24:45.000 --> 24:49.000
the thing of all sets that do not contain themselves.

24:49.000 --> 24:52.000
Well, is that set in itself or not?

24:52.000 --> 24:55.000
It's a paradox. It's impossible to figure out.

24:55.000 --> 25:00.000
So that made a lot of people really disconcerted,

25:00.000 --> 25:07.000
and they realized that math wasn't quite so perfect in its foundations as first thought.

25:07.000 --> 25:11.000
Schoen Finkl, we talked about, he was an early pioneer in combinatorial logic.

25:11.000 --> 25:16.000
He also used currying and published one paper, and then it was really sad, actually.

25:16.000 --> 25:19.000
The rest of his life really spiraled downhill.

25:19.000 --> 25:24.000
He ended up in a mental asylum, which don't worry,

25:24.000 --> 25:29.000
it's not because of combinatorial logic, I don't think.

25:29.000 --> 25:33.000
Van Neumann, famous mathematician, also later in life,

25:33.000 --> 25:36.000
helped build the first real electric computers.

25:36.000 --> 25:41.000
He also kind of did something that, if you reinterpret it, it's combinatorial logic,

25:41.000 --> 25:45.000
but that was almost by accident, like that wasn't his goal in life.

25:45.000 --> 25:49.000
And then in 26, Haskell Curry starts reinventing combinatorial logic.

25:49.000 --> 25:52.000
He wasn't aware of Schoen Finkl or Frege, well, he was aware of Frege,

25:52.000 --> 25:55.000
but not any kind of link to combinatorics.

25:55.000 --> 25:58.000
And so he does a whole bunch of contributions.

25:58.000 --> 26:05.000
He's a really smart guy at Princeton, and in 1927, he discovers that Schoen Finkl beat him to the punch.

26:05.000 --> 26:09.000
So he forges on nonetheless, which is good for us,

26:09.000 --> 26:12.000
because he develops many, many new theorems.

26:12.000 --> 26:18.000
In 1931, Cort Godot, very famous mathematician,

26:18.000 --> 26:22.000
who kind of plunged a dagger into the very heart of math,

26:22.000 --> 26:29.000
discovers that this race in search for the perfect set of foundations for math is fundamentally flawed.

26:29.000 --> 26:33.000
It's a fool's errand, it's impossible, it's literally impossible,

26:33.000 --> 26:39.000
because every complicated enough system to be interesting by a certain definition of interesting,

26:39.000 --> 26:45.000
such as piano numbers, is either inconsistent or incomplete.

26:45.000 --> 26:49.000
That means there's either logical inconsistencies which make it make no sense,

26:49.000 --> 26:54.000
or there are systems and things inside that language which you can talk about,

26:54.000 --> 26:56.000
but you can't prove or disprove.

26:56.000 --> 26:58.000
There's no way to get to the proof or disprove.

26:58.000 --> 27:01.000
That totally upends math as we know it.

27:02.000 --> 27:08.000
In the 30s, Alonzo Church is trying to figure out a system that's at least good enough

27:08.000 --> 27:12.000
to compute things that are computable in some definition of computable,

27:12.000 --> 27:16.000
and he develops this thing that we've been talking about the whole time, lambda calculus,

27:16.000 --> 27:19.000
this notation system for writing down functions.

27:19.000 --> 27:27.000
Now, it's this tiny, tiny language, and at first, his grad students such as Stephen Klaney and Rosser,

27:28.000 --> 27:32.000
they think that it's not going to really lead too much, like it's just a notation system,

27:32.000 --> 27:35.000
but then they start to realize like it's ballooning outwards,

27:35.000 --> 27:40.000
and it's from this very tiny bit of logic is coming all sorts of interesting results.

27:40.000 --> 27:46.000
They also prove different versions of it are consistent or inconsistent.

27:46.000 --> 27:53.000
Stephen Klaney, by the way, goes on later in life to invent this thing that we use all the time called regular expressions,

27:53.000 --> 27:56.000
so that's fun.

27:56.000 --> 28:04.000
In 1936, Alonzo Church solves a famous unsolved problem, David Hilbert's decision problem.

28:04.000 --> 28:09.000
This is an algorithm problem that says like, well, actually, I can't remember the specifics,

28:09.000 --> 28:11.000
but it's, let me see.

28:11.000 --> 28:15.000
Oh, is there a way to figure out if any given problem does have a solution,

28:15.000 --> 28:18.000
very closely related to, but distinct from the halting problem?

28:18.000 --> 28:22.000
And Church is like, no, there isn't.

28:22.000 --> 28:29.000
But he uses the lambda calculus to solve it, which was hilarious because it started out as three or four lines of notation,

28:29.000 --> 28:35.000
and it turned into a system complicated enough to solve this famous unsolved problem.

28:35.000 --> 28:37.000
Guess what also happens in 1936?

28:37.000 --> 28:41.000
Two months later, Alon Turing solves the problem using something called a Turing machine,

28:41.000 --> 28:46.000
and he publishes his own paper, and then he finds out that Church beat him to the punch by two months,

28:46.000 --> 28:48.000
and he gets really annoyed by that.

28:48.000 --> 28:52.000
He was actually quite disappointed to find out that someone else had raced him

28:52.000 --> 28:55.000
and beat him to solving the decision problem.

28:55.000 --> 28:59.000
But he looks at the paper, he looks at Church's lambda calculus and says, you know what?

28:59.000 --> 29:01.000
These are actually identical.

29:01.000 --> 29:08.000
My Turing machines and Church's lambda calculus are the exact same thing just expressed different ways.

29:08.000 --> 29:15.000
So then he decides, you know what, I'll bury the hatchet, come to Princeton, get a PhD under Church with Church as his advisor.

29:15.000 --> 29:21.000
And in 1937, he publishes the first fixed point combinator.

29:21.000 --> 29:24.000
Okay, that's the history.

29:24.000 --> 29:29.000
In the tiniest nutshell I could manage, or at least bear to part with.

29:29.000 --> 29:32.000
So, combinator.

29:32.000 --> 29:34.000
You keep using that word.

29:34.000 --> 29:36.000
I don't think it means what you think it means.

29:36.000 --> 29:38.000
What is a combinator?

29:38.000 --> 29:41.000
We've said this thing many times, combinator logic and combinator's lambda calculus.

29:41.000 --> 29:43.000
Where's the dividing line?

29:43.000 --> 29:47.000
In reality, they're almost entirely the same thing.

29:47.000 --> 29:51.000
A combinator is a function with no free variables.

29:51.000 --> 29:57.000
A free variable is a variable in a function body that's not bound to some parameter.

29:57.000 --> 30:03.000
So this is a combinator because the B in the body is bound to the B parameter.

30:03.000 --> 30:06.000
Whereas that's not a combinator because A comes from nowhere.

30:06.000 --> 30:10.000
What is A? Who knows? We could make it up. It doesn't matter.

30:10.000 --> 30:15.000
It doesn't matter that we're not using the B. The B is irrelevant. It's a parameter.

30:15.000 --> 30:20.000
Not a combinator because where does the B come from? Don't know.

30:20.000 --> 30:22.000
And even more complicated stuff like this.

30:22.000 --> 30:25.000
Don't get distracted by the E. That's a parameter. It's not a variable.

30:25.000 --> 30:29.000
So everything that appears in the body, C and B, those are bound to parameters.

30:29.000 --> 30:34.000
That's a combinator. You now know what a combinator is.

30:34.000 --> 30:42.000
We've seen a bunch of combinators. Identity, self-application, first or const, second.

30:42.000 --> 30:49.000
And the cool thing is, as I mentioned before, using some of the primitive combinators mixed together,

30:49.000 --> 30:54.000
we start generating some of the more complicated combinators, or at least other combinators,

30:54.000 --> 30:58.000
which is surprising but cool.

30:58.000 --> 31:01.000
Are you ready for the next one?

31:01.000 --> 31:06.000
Let's look at the cardinal. Let's just look at it for a second.

31:06.000 --> 31:11.000
Not the beautiful photo, which I stole from somewhere. I can't remember where.

31:11.000 --> 31:18.000
But the combinator itself, anybody looking at this, can you think conceptually what this actually does

31:18.000 --> 31:24.000
in sort of a use case way?

31:24.000 --> 31:27.000
I'm really pushing you here because we're talking about abstract math,

31:27.000 --> 31:32.000
but we're just keeping you in a land with no JavaScript.

31:32.000 --> 31:40.000
Exactly. It just flips around arguments. It takes a function f that takes two parameters,

31:40.000 --> 31:46.000
and then it calls the function f with both of those parameters, but in the opposite order.

31:46.000 --> 31:53.000
So here's the C combinator, and what if we apply this to a function in two arguments,

31:53.000 --> 31:56.000
which is the kestrel and these other two things that we don't care what they are,

31:56.000 --> 31:58.000
but they're i and m in this case.

31:58.000 --> 32:04.000
The cardinal of the kestrel and the idiot and the mockingbird.

32:04.000 --> 32:09.000
Well, walking through it, it takes three things, the function and two arguments,

32:09.000 --> 32:13.000
and it calls the function. Which is the function here?

32:13.000 --> 32:18.000
k. And it calls them with two arguments. Which are the arguments?

32:18.000 --> 32:24.000
And it calls them in the opposite order. So it's k of m and i, which is?

32:24.000 --> 32:27.000
Yeah.

32:27.000 --> 32:33.000
So we start with the kestrel, and then we put two things into it, but backwards.

32:33.000 --> 32:35.000
That's interesting because look at what we have here.

32:35.000 --> 32:38.000
The cardinal of the kestrel takes two things and returns the second.

32:38.000 --> 32:42.000
Does that sound familiar?

32:42.000 --> 32:44.000
It's the kite.

32:44.000 --> 32:47.000
The cardinal of the kestrel is the kestrel of identity.

32:47.000 --> 32:51.000
The kite is this other thing. They're all the same.

32:51.000 --> 32:53.000
And we can just do this to prove it.

32:53.000 --> 32:56.000
Let's do the cardinal takes a function.

32:56.000 --> 32:59.000
This monitor went away. There we go.

32:59.000 --> 33:03.000
It takes a function, takes an argument, another argument,

33:03.000 --> 33:09.000
calls the argument with the arguments backwards.

33:09.000 --> 33:13.000
Let's get the cardinal of the kestrel.

33:13.000 --> 33:16.000
Apply it to two variables.

33:16.000 --> 33:18.000
The kestrel normally gives you back the first thing,

33:18.000 --> 33:21.000
but the cardinal of the kestrel gives you the second thing.

33:21.000 --> 33:28.000
It works. This isn't pure math. It's also applicable.

33:28.000 --> 33:31.000
So that's kind of fun. Cardinal, if you've got a cardinal,

33:31.000 --> 33:33.000
you can apply it in different ways.

33:33.000 --> 33:36.000
You can flip the kite around to get the kestrel or the kestrel to get the kite.

33:36.000 --> 33:39.000
And in fact, in Haskell, this is built into the base language,

33:39.000 --> 33:41.000
and it's called flip.

33:41.000 --> 33:47.000
And it actually ends up being useful from time to time.

33:47.000 --> 33:49.000
So why? Why are we learning this?

33:49.000 --> 33:51.000
What's actually going on here?

33:51.000 --> 33:54.000
How is this useful? Do we care?

33:54.000 --> 33:57.000
Remember, lambda cacos and Turing machines are equivalent.

33:57.000 --> 34:00.000
Anything one can calculate, the other can calculate.

34:00.000 --> 34:03.000
But Turing machines are exciting because they're these hypothetical devices

34:03.000 --> 34:07.000
that use state information that exists over here, here, here,

34:07.000 --> 34:12.000
and things that change over time to do computations.

34:12.000 --> 34:14.000
And from these hypothetical devices, people said,

34:14.000 --> 34:17.000
wait a second, we could build real machines that do this.

34:17.000 --> 34:19.000
And they use memory and state,

34:19.000 --> 34:21.000
and they do a little bit more complicated stuff

34:21.000 --> 34:24.000
just to make it more performant and easier to work with.

34:24.000 --> 34:27.000
But at their heart, they're really Turing machines.

34:27.000 --> 34:29.000
So they work with machine code,

34:29.000 --> 34:31.000
which means let's flip a whole bunch of physical switches

34:31.000 --> 34:34.000
and then see what electricity and bits come out the other end.

34:34.000 --> 34:38.000
And we abstract that away in a language, a text format called assembly language,

34:38.000 --> 34:43.000
that says things like, move the data in register B to the accumulator register.

34:43.000 --> 34:48.000
Add one to whatever value is in the accumulator register of my memory.

34:48.000 --> 34:52.000
Very stateful, very machine-based, very hard for humans to reason about.

34:52.000 --> 34:56.000
It's not conceptual. It's all about machines.

34:56.000 --> 35:00.000
Well, we build higher-level languages like C that compile into assembly.

35:00.000 --> 35:03.000
But those higher-level languages are still machine-centric.

35:03.000 --> 35:08.000
They still say things like, hey, see, go allocate seven bits of memory over here

35:08.000 --> 35:12.000
and give me back a reference to the pointer of that memory address and so on and so forth.

35:12.000 --> 35:14.000
So then somebody says, well, this is stupid.

35:14.000 --> 35:16.000
We'll make the programming languages do that for us,

35:16.000 --> 35:18.000
and we'll just focus more on concepts.

35:18.000 --> 35:20.000
Like, hey, give me a var x,

35:20.000 --> 35:22.000
and I don't care how you figure out the memory for that,

35:22.000 --> 35:24.000
just go do it yourself.

35:24.000 --> 35:27.000
And then somebody says, why are we even bothering with memory?

35:27.000 --> 35:32.000
Why don't we just have these pure functions that operate on each other?

35:32.000 --> 35:33.000
And wait a second.

35:33.000 --> 35:37.000
This whole time this machine march through abstraction

35:37.000 --> 35:41.000
has been leading us to something that existed before Turing machines existed,

35:41.000 --> 35:43.000
which is the lambda calculus.

35:43.000 --> 35:47.000
Functional programming languages are based on,

35:47.000 --> 35:51.000
slash their backbone is, the lambda calculus.

35:51.000 --> 35:54.000
So if we decide, wait, we're not going to organically evolve

35:54.000 --> 35:57.000
towards this kind of conceptual abstraction,

35:57.000 --> 36:01.000
but let's just start straight from the lambda calculus and go the other direction.

36:01.000 --> 36:04.000
We can start designing purely functional languages

36:04.000 --> 36:09.000
and using all the decades of mathematical research that have gone into LC

36:09.000 --> 36:11.000
to design our language and see what comes out of that

36:11.000 --> 36:13.000
and see if there's anything useful that we could do there.

36:13.000 --> 36:15.000
And then we'll take that pure functional language,

36:15.000 --> 36:22.000
just compile it down to machine code so it runs on our physical Turing machines.

36:22.000 --> 36:25.000
Lambda calculus and Turing machines are equivalent.

36:25.000 --> 36:30.000
Therefore, here's the big theme of the entire talk coming in the next slide.

36:30.000 --> 36:33.000
Everything can be functions.

36:33.000 --> 36:37.000
When I say everything, I mean everything.

36:37.000 --> 36:40.000
Like Booleans.

36:40.000 --> 36:41.000
Whoa.

36:41.000 --> 36:44.000
Here's a JavaScript Boolean expression.

36:44.000 --> 36:50.000
Not X is equal to, that's the double equals, not the assignment equals.

36:50.000 --> 36:55.000
Y or the result of the expression A and Z.

36:55.000 --> 36:57.000
How are we going to do this in lambda calculus?

36:57.000 --> 37:01.000
Well, it's a problem because we don't have negation.

37:01.000 --> 37:04.000
We don't have ors and and operators.

37:04.000 --> 37:07.000
I mean, we don't even have a quality checks in the lambda calculus, right?

37:07.000 --> 37:09.000
That wasn't in the language.

37:09.000 --> 37:11.000
We don't have Booleans.

37:11.000 --> 37:13.000
We do have parentheses.

37:13.000 --> 37:16.000
That's what we got.

37:16.000 --> 37:18.000
We got parens.

37:18.000 --> 37:21.000
All right, so how on earth are we going to do this?

37:21.000 --> 37:25.000
Let's start with the primitive building blocks, the Booleans.

37:25.000 --> 37:27.000
A bool.

37:27.000 --> 37:30.000
What is that used for in JavaScript?

37:30.000 --> 37:33.000
Well, what about selection?

37:33.000 --> 37:36.000
Some result is check a Boolean condition.

37:36.000 --> 37:39.000
If it's true, we'll get the first expression.

37:39.000 --> 37:42.000
If it's false, we'll get the second expression.

37:42.000 --> 37:45.000
Let's start translating this over to lambda calculus.

37:45.000 --> 37:49.000
Well, we got this ternary except, oops, this question mark and colon.

37:49.000 --> 37:51.000
That's not in the lambda calculus syntax.

37:51.000 --> 37:53.000
It's got to go. Bye-bye.

37:53.000 --> 37:55.000
What are we left with?

37:55.000 --> 37:57.000
This is a function application, right?

37:57.000 --> 37:59.000
So bool must be.

37:59.000 --> 38:01.000
What's the theme of the talk?

38:01.000 --> 38:03.000
A function.

38:03.000 --> 38:05.000
And, oh, well, what do we need here?

38:05.000 --> 38:08.000
We need a function that if it's the quote unquote true function,

38:08.000 --> 38:10.000
it selects the first expression.

38:10.000 --> 38:13.000
And if it's the false function, it selects the second expression.

38:13.000 --> 38:16.000
Wait a second. This sounds really familiar to me.

38:16.000 --> 38:20.000
Where have we seen a pair of functions that select either the first or second things?

38:20.000 --> 38:22.000
Yeah.

38:22.000 --> 38:24.000
We already have Booleans.

38:24.000 --> 38:26.000
We didn't even have to reinvent them.

38:26.000 --> 38:29.000
They're already in the language that we've developed so far in this talk.

38:29.000 --> 38:35.000
We'll just encode, in other words, represent Booleans as functions.

38:35.000 --> 38:38.000
We'll say that the kestrel function, the constant function,

38:38.000 --> 38:42.000
the first function is true, quote unquote, and the kite is false.

38:43.000 --> 38:45.000
That's kind of neat.

38:45.000 --> 38:49.000
Let's do that while we're looking at this slide and admiring it.

38:49.000 --> 38:53.000
True is equal to the kestrel.

38:53.000 --> 38:57.000
And false is equal to the kite.

38:57.000 --> 38:59.000
Now, there's a little node trick that I'll use here,

38:59.000 --> 39:03.000
because if I go console log out true, it tells me it's the kestrel,

39:03.000 --> 39:08.000
which is true, but in both senses.

39:08.000 --> 39:12.000
But it's also slightly annoying, like if I'm going to start doing Booleans.

39:12.000 --> 39:13.000
So I'm going to do a little trick here.

39:13.000 --> 39:24.000
I'm going to say t.inspect is a function that returns the string true slash kestrel.

39:24.000 --> 39:33.000
And false.inspect is a function that returns false or the kite.

39:34.000 --> 39:36.000
Now, if I log out t, I get t slash k.

39:36.000 --> 39:40.000
And if I log out false, I get false slash kite.

39:40.000 --> 39:46.000
So that'll be useful going forward in some of these demos.

39:46.000 --> 39:47.000
That wasn't lambda calculus.

39:47.000 --> 39:51.000
The other stuff was, but not the dot.inspect.

39:51.000 --> 39:53.000
OK, so we have true and false.

39:53.000 --> 39:55.000
But true and false on their own are kind of boring, right?

39:55.000 --> 39:57.000
Yeah, so we can select between two things.

39:57.000 --> 39:58.000
What about Boolean logic?

39:58.000 --> 40:01.000
What about vacation?

40:01.000 --> 40:03.000
Let's translate it.

40:03.000 --> 40:05.000
Well, what doesn't belong?

40:05.000 --> 40:08.000
One of these things is not like the others.

40:08.000 --> 40:13.000
The negation, the exclamation mark isn't in the lambda calculus syntax.

40:13.000 --> 40:15.000
What does it got to be instead?

40:15.000 --> 40:17.000
What's the theme of the talk?

40:17.000 --> 40:19.000
A function.

40:19.000 --> 40:20.000
The not function.

40:20.000 --> 40:26.000
The not function will take in a Boolean and it will select between two other Booleans.

40:26.000 --> 40:30.000
If we give it not true, it selects false.

40:30.000 --> 40:34.000
If we give it false, it selects true.

40:34.000 --> 40:36.000
How can we implement the not function?

40:36.000 --> 40:37.000
Well, wait a second.

40:37.000 --> 40:40.000
We just talked about selecting between two things.

40:40.000 --> 40:48.000
What kind of thing selects between two possibilities?

40:48.000 --> 40:49.000
We have a function.

40:49.000 --> 40:50.000
Yes, a function.

40:50.000 --> 40:52.000
That's true.

40:52.000 --> 40:58.000
But specifically, these Booleans that we're using, the kite and the kestrel,

40:58.000 --> 41:02.000
themselves functions that choose between two possibilities.

41:02.000 --> 41:04.000
Look at what I have here, this expression.

41:04.000 --> 41:05.000
An unknown Boolean p.

41:05.000 --> 41:06.000
It might be the kite.

41:06.000 --> 41:07.000
It might be the kestrel.

41:07.000 --> 41:09.000
I don't know which one.

41:09.000 --> 41:16.000
If it's the kestrel or true, which one of those does it select?

41:16.000 --> 41:20.000
The first one, false.

41:20.000 --> 41:27.000
And if my unknown Boolean is the kite, which does it select?

41:27.000 --> 41:29.000
The second one, true.

41:29.000 --> 41:34.000
My unknown Boolean selects its own opposite in this expression.

41:34.000 --> 41:38.000
So we'll turn this into a function and we'll call it not.

41:38.000 --> 41:39.000
That's it.

41:39.000 --> 41:46.000
Not just takes a Boolean and then tells the Boolean select your opposite.

41:46.000 --> 41:49.000
I promise it works.

41:50.000 --> 41:57.000
So not takes, let's say it takes a Boolean and then it calls the Boolean passing in false and true.

41:57.000 --> 42:00.000
So if we say not true, that's false.

42:00.000 --> 42:02.000
And not false is true.

42:02.000 --> 42:05.000
I've not put a single JavaScript Boolean into any of this.

42:05.000 --> 42:06.000
I'm doing negation.

42:06.000 --> 42:13.000
This is like, this should be exciting.

42:13.000 --> 42:14.000
All right.

42:14.000 --> 42:18.000
So our church encodings, which is what these things are called for Booleans now includes

42:18.000 --> 42:19.000
negation.

42:19.000 --> 42:22.000
We saw how we got true and false.

42:22.000 --> 42:24.000
But there's a more exciting way of doing this.

42:24.000 --> 42:26.000
There's an even better way, in my opinion.

42:26.000 --> 42:28.000
A cooler way.

42:28.000 --> 42:31.000
Not true is false and not false is true.

42:31.000 --> 42:35.000
But we said true and false, we're encoding those as the kestrel and the kite.

42:35.000 --> 42:40.000
But if the kestrel and the kite, there's no named functions in lambda calculus.

42:40.000 --> 42:45.000
This is just us writing down a shorthand so that we don't have to remember and read out all the lambdas.

42:45.000 --> 42:50.000
But if we did replace them with their equivalent lambda expressions, that's what we're really looking at.

42:50.000 --> 42:58.000
Now, we're saying the Not function will take at the top there a lambda that takes two arguments and gives you back the first,

42:58.000 --> 43:03.000
and it gives you back a lambda that takes two arguments and gives you back the second.

43:03.000 --> 43:04.000
OK?

43:04.000 --> 43:08.000
And at the bottom, we're saying it takes, you know, two arguments and gives you back the second,

43:08.000 --> 43:14.000
and the Not function will give you back a lambda that takes two arguments and gives you back the first.

43:14.000 --> 43:14.880
Interesting.

43:17.240 --> 43:21.120
So does anyone see, instead of not,

43:21.120 --> 43:22.800
is there a function that we've already

43:22.800 --> 43:26.000
seen that will result in this?

43:26.000 --> 43:30.000
A function that accepts a binary function, a function that

43:30.000 --> 43:36.200
takes two arguments, and it moves the arguments around?

43:36.200 --> 43:38.080
It's the cardinal.

43:38.080 --> 43:41.200
Yeah, the only other one we've seen.

43:41.200 --> 43:43.560
The cardinal already does this behavior.

43:43.560 --> 43:47.680
The cardinal is boolean not.

43:47.680 --> 43:53.240
The flip of true is false, and the flip of false is true.

43:53.240 --> 43:55.000
This monitor is really going to bug me.

43:55.000 --> 43:55.560
There we go.

43:55.560 --> 43:56.440
Stay there.

43:56.440 --> 43:58.400
Don't move.

43:58.400 --> 43:58.960
Let's try it.

43:58.960 --> 44:03.200
Cardinal of true.

44:03.200 --> 44:06.440
Now, unfortunately, look what I'm about to get here.

44:06.440 --> 44:09.440
This isn't quite what I want, just this function.

44:09.440 --> 44:10.600
Well, that's weird.

44:10.600 --> 44:12.280
What if I use this function?

44:12.280 --> 44:15.720
I'll apply it to two things, one and two.

44:15.720 --> 44:17.840
I get back the second thing, which is what I want.

44:17.840 --> 44:21.320
The flip of true is false, so I should get the second thing.

44:21.320 --> 44:25.720
And the flip of false is true, so I should get back

44:25.720 --> 44:27.680
the first thing, which I do.

44:27.680 --> 44:31.520
The problem is, the problem is, and it's not really a problem,

44:31.520 --> 44:35.520
the problem is that the cardinal generates a new function,

44:35.520 --> 44:39.840
unlike my previous implementation of not, which

44:39.840 --> 44:42.960
selects between existing false and true functions,

44:42.960 --> 44:46.800
the cardinal generates a new function that behaves identically

44:46.800 --> 44:48.960
to the kestrel or kite.

44:48.960 --> 44:52.560
This kind of identity crisis is known

44:52.560 --> 44:56.680
as intentional equality versus extensional equality.

44:56.680 --> 44:58.640
Extensional equality, which is the kind of equality

44:58.640 --> 45:02.240
I'll use throughout this talk, means the functions are the same.

45:02.240 --> 45:05.600
If for every input, they generate the same output.

45:05.600 --> 45:07.560
So the cardinal of the kestrel is

45:07.600 --> 45:10.480
extensionally equal to the kite.

45:10.480 --> 45:11.920
They both behave identically.

45:11.920 --> 45:15.160
There's no way to tell them apart from the outside, quote unquote.

45:15.160 --> 45:18.160
Intentional equality is more like, well, where did it come from

45:18.160 --> 45:18.920
and what's inside it?

45:18.920 --> 45:20.760
What are its guts?

45:20.760 --> 45:27.880
I'm not going to focus on that during this talk, but it works.

45:27.880 --> 45:30.920
That's the important thing.

45:30.920 --> 45:36.880
Let's design and together, Boolean and, Boolean conjunction.

45:36.880 --> 45:37.800
We know it's a function, right?

45:37.800 --> 45:39.520
That's the theme of the talk.

45:39.520 --> 45:42.200
How many arguments does it take?

45:42.200 --> 45:43.920
What are these arguments?

45:43.920 --> 45:45.800
What kind of thing are they?

45:45.800 --> 45:47.800
They're Booleans, so they're the kestrel of the kite

45:47.800 --> 45:50.960
or kite and kestrel or kestrel or kestrel or kite and kite,

45:50.960 --> 45:53.240
just to finish it out.

45:53.240 --> 45:55.640
Well, to take in a parameter, you're

45:55.640 --> 45:57.480
probably going to use that parameter somewhere

45:57.480 --> 45:59.040
in the body of your function, right?

45:59.040 --> 46:01.680
So even if we're not quite sure where to go with this,

46:01.680 --> 46:04.600
let's try just using one of these Booleans.

46:04.600 --> 46:08.760
P is a Boolean, so what does it do?

46:08.760 --> 46:11.360
What do these Boolean functions do when I use them?

46:14.560 --> 46:17.400
Yeah, they select between two possibilities,

46:17.400 --> 46:19.000
such as the Spanish question mark.

46:21.600 --> 46:27.520
What if our first argument to and is false?

46:27.520 --> 46:30.560
Which of the two possibilities will P select?

46:30.560 --> 46:31.680
The second one.

46:31.680 --> 46:32.480
But wait a second.

46:32.480 --> 46:34.640
If one of the arguments to and is false,

46:34.640 --> 46:36.960
what should that result of this entire function be?

46:39.800 --> 46:43.160
Yeah, so I'll just put false there.

46:43.160 --> 46:46.560
If P is false, short circuit, don't bother looking at Q.

46:46.560 --> 46:49.160
There's no point where you can know we just select the second

46:49.160 --> 46:51.520
thing, and it's already going to be false.

46:51.520 --> 46:57.520
So we don't even bother checking Q. Well, what if P is true?

46:57.520 --> 47:00.400
It's going to select the first thing, right?

47:00.400 --> 47:01.640
But what is that first thing?

47:01.640 --> 47:03.320
What should it be?

47:03.320 --> 47:04.760
Based on Q?

47:04.760 --> 47:07.440
Yeah, it's got to be Q.

47:07.440 --> 47:11.880
Because if P is true, the and is true only when Q is true,

47:11.880 --> 47:14.040
and the and is false if Q is false.

47:14.040 --> 47:16.960
So once P is true, we have to go look at Q and use Q as our

47:16.960 --> 47:19.520
result.

47:19.520 --> 47:21.960
There's one more small simplification we can actually

47:21.960 --> 47:23.520
make to this that's kind of nice.

47:23.520 --> 47:27.840
I like it in any rate, which is we said that, by the way, P is

47:27.840 --> 47:30.320
a Boolean, so it selects between two possibilities.

47:30.360 --> 47:33.840
If P is false, it should select false.

47:33.840 --> 47:36.480
But I've hard-coded in a false.

47:36.480 --> 47:39.120
There was a way I could do this even more directly or

47:39.120 --> 47:41.640
indirectly, it depends on your perspective.

47:41.640 --> 47:44.600
If P is false and it should select false, P can just

47:44.600 --> 47:47.080
select itself.

47:47.080 --> 47:50.680
If P is false, then return P, which is false.

47:50.680 --> 47:52.760
So I end up with this thing, which is very much a

47:52.760 --> 47:56.560
combinator, PQ, PQP.

47:56.560 --> 47:58.000
That is my and function.

48:00.400 --> 48:04.360
I forget where we're at in our demonstrations of JavaScript.

48:04.360 --> 48:05.840
Do we have not?

48:05.840 --> 48:07.160
We do have not.

48:07.160 --> 48:07.920
What about and?

48:07.920 --> 48:08.440
No, we don't.

48:08.440 --> 48:09.800
OK, let's do that.

48:09.800 --> 48:16.240
And takes a Boolean and another Boolean, and it applies P

48:16.240 --> 48:19.760
to Q to P. PQ, PQP.

48:19.760 --> 48:21.120
That makes sense.

48:21.120 --> 48:26.400
So and of false and true is false.

48:26.400 --> 48:29.120
And of true and true is true.

48:29.320 --> 48:30.960
And false is false.

48:30.960 --> 48:34.040
And false and false is false.

48:34.040 --> 48:36.560
All the things we love and expect from the and function.

48:39.280 --> 48:40.280
That's neat.

48:40.280 --> 48:41.520
Let's do or.

48:41.520 --> 48:44.120
What is or?

48:44.120 --> 48:47.720
Hey, someone's got the theme down.

48:47.720 --> 48:48.520
I cheated ahead.

48:48.520 --> 48:51.000
I jumped ahead and gave you two of the arguments.

48:51.000 --> 48:51.720
Oh, no.

48:51.720 --> 48:52.600
What are we going to do?

48:52.600 --> 48:54.720
P is a Boolean, it selects between two things.

48:54.720 --> 48:56.560
All right, here's where it differs from and.

48:56.560 --> 48:58.160
What if P is true?

48:58.160 --> 49:00.120
Oops, I jumped ahead too much.

49:00.120 --> 49:01.120
P is true.

49:01.120 --> 49:03.520
It selects the first thing, which has got to be true.

49:03.520 --> 49:05.760
If P is true, we don't have to bother looking at Q, because

49:05.760 --> 49:09.640
in or, if one of them is true, then we just result in true.

49:09.640 --> 49:14.560
If P is false, what's the second argument got to be?

49:14.560 --> 49:18.280
Q. It's just the opposite of the thing before.

49:18.280 --> 49:22.840
So we can also simplify our kind of glossed over that, but

49:22.840 --> 49:24.280
it doesn't have to be a hard-coded true.

49:24.280 --> 49:26.360
It can just be P, because we reuse it.

49:26.440 --> 49:30.320
If P is true, just return P.

49:30.320 --> 49:34.040
That fact is actually really fun, because there's another

49:34.040 --> 49:37.400
little thing we can do here that's a trick.

49:37.400 --> 49:42.640
Somebody tell me, if I apply this PQ double PQ function to

49:42.640 --> 49:46.040
X and Y as arguments, what is the resulting

49:46.040 --> 49:47.000
better reduction?

49:47.000 --> 49:50.320
In other words, what is the evaluation of this function?

49:50.320 --> 49:53.920
What do I get as a result?

49:53.920 --> 49:58.040
Remember, X replaces every P in the body, and Y replaces every

49:58.040 --> 49:58.920
Q in the body.

50:01.440 --> 50:03.840
Yep, X, X, Y.

50:03.840 --> 50:06.440
But there's another function we've already seen that does

50:06.440 --> 50:09.120
this.

50:09.120 --> 50:10.160
I'll give you a hint.

50:10.160 --> 50:12.200
What if we ignore the Ys for a second?

50:15.360 --> 50:16.840
Yeah, it's the mockingverd.

50:16.840 --> 50:19.040
It's the self-applicationverd.

50:19.040 --> 50:21.160
The self-application of X is double X.

50:21.160 --> 50:23.600
It's the self-application of X.

50:23.600 --> 50:25.920
But if the thing on the left is equal to the thing on the

50:25.920 --> 50:29.160
right, they're both functions I could apply them to some Y.

50:29.160 --> 50:31.440
And now we see, wait a second, the thing on the top and the

50:31.440 --> 50:32.880
thing on the bottom are actually the same.

50:32.880 --> 50:36.920
The mockingverd works just like this other function.

50:36.920 --> 50:39.000
It looks almost exactly like that, except the other

50:39.000 --> 50:42.120
function is this additional Q on the end, which is useless.

50:42.120 --> 50:44.200
It takes a Q and applies a Q.

50:44.200 --> 50:47.720
This is known as the mockingverd once removed.

50:47.720 --> 50:50.200
So that's what the star means.

50:50.200 --> 50:52.320
It's been given an extra argument.

50:52.320 --> 50:55.160
The mockingverd once removed is extensionally equal to the

50:55.160 --> 50:55.720
mockingverd.

50:55.720 --> 50:58.480
It behaves identically to it.

50:58.480 --> 51:00.560
So have we defined or?

51:00.560 --> 51:01.120
No, we haven't.

51:01.120 --> 51:02.440
Let's do that really quickly.

51:02.440 --> 51:04.680
Or it takes a P and a Q.

51:04.680 --> 51:10.320
And it does P of P and Q.

51:10.320 --> 51:15.840
We can demonstrate that or TF is true, or F is false, or

51:15.840 --> 51:19.560
FT is true, and of course, or TT is true.

51:19.560 --> 51:21.360
But we can also use the mockingverd for that, because

51:21.360 --> 51:23.960
we just proved that the mockingverd outflurrates the

51:23.960 --> 51:25.400
same way here.

51:25.400 --> 51:29.920
So mockingverd of true and false is true.

51:29.920 --> 51:32.200
False and false is false.

51:32.200 --> 51:35.440
False and true is an or statement as well.

51:35.440 --> 51:37.680
And that's also an or statement.

51:37.680 --> 51:39.120
Wow.

51:39.120 --> 51:42.960
Mockingverd, you're multi-talented.

51:42.960 --> 51:45.560
Anybody have an idea what this might be?

51:52.160 --> 51:55.040
Well, it's definitely a function that takes two

51:55.040 --> 51:57.120
arguments.

51:57.120 --> 51:59.360
And I'm going to tell you P and Q are Booleans, just to make

51:59.360 --> 52:01.040
it slightly easier.

52:01.040 --> 52:03.640
But if P and Q are Booleans, what does P do?

52:07.400 --> 52:10.360
It selects between two possibilities.

52:10.360 --> 52:13.160
And if Q is a Boolean, what does it do?

52:13.160 --> 52:15.800
It selects between two possibilities.

52:15.800 --> 52:18.160
Does this make it easier to see what this function does?

52:18.600 --> 52:22.240
Sorry?

52:22.240 --> 52:24.760
You were sure.

52:24.760 --> 52:28.520
Well, if P and Q are the same Boolean, they select true.

52:28.520 --> 52:31.640
If they're the same that way, they also select true.

52:31.640 --> 52:35.440
But if they're different, they select false.

52:35.440 --> 52:38.120
Which function is this?

52:38.120 --> 52:40.400
Sorry?

52:40.400 --> 52:42.040
Oh, is Zor something like that?

52:42.040 --> 52:43.560
Not quite.

52:43.560 --> 52:44.480
Maybe.

52:44.480 --> 52:45.720
I'd have to think about it.

52:45.720 --> 52:46.520
It might be Zor.

52:46.520 --> 52:48.080
Yeah, I'd have to think about it.

52:49.000 --> 52:51.240
Yeah.

52:51.240 --> 52:52.040
That's true.

52:52.040 --> 52:53.240
That's cool.

52:53.240 --> 52:55.480
Yeah, nice work.

52:55.480 --> 52:57.080
I didn't think about that.

52:57.080 --> 52:59.480
There's a simpler thing that we use this with.

52:59.480 --> 53:01.320
If P and Q are the same, we get true.

53:01.320 --> 53:02.520
If they're different, we get false.

53:02.520 --> 53:05.200
That's called equality.

53:05.200 --> 53:11.280
This test, if P and Q are the same Boolean, well, there's a

53:11.280 --> 53:13.480
nice little simplification we can make here.

53:13.480 --> 53:15.160
Q is a Boolean true or false.

53:15.160 --> 53:16.240
If it's true, it selects true.

53:16.280 --> 53:18.280
If it's false, it selects false.

53:18.280 --> 53:19.200
That's redundant.

53:19.200 --> 53:20.640
We could just use Q as it is.

53:20.640 --> 53:22.840
It's already true or false.

53:22.840 --> 53:25.720
And at the bottom, if Q is true, it selects false.

53:25.720 --> 53:28.000
And if it's false, it selects true.

53:28.000 --> 53:29.960
We already have a function that does that.

53:29.960 --> 53:32.000
It's called the not function.

53:32.000 --> 53:36.840
So we can simplify this to P, Q, not Q. And that is our

53:36.840 --> 53:38.840
Boolean equality function.

53:38.840 --> 53:42.960
I'll do that as long as it sets P to Q to P, Q, not Q.

53:43.000 --> 53:47.480
So Boolean equality takes a P and a Q.

53:47.480 --> 53:53.520
And it does P of Q and not Q.

53:53.520 --> 53:54.200
Try it out.

53:54.200 --> 53:58.840
Boolean equality of true and true is, of course, true.

53:58.840 --> 54:00.480
True and false, nope.

54:00.480 --> 54:02.240
False and false, yes.

54:02.240 --> 54:04.360
False and true, nope.

54:04.360 --> 54:06.640
Nice.

54:06.640 --> 54:08.320
It's always fun to see it actually work.

54:08.320 --> 54:10.520
Like, you kind of believe it, and then you see it, and

54:10.520 --> 54:12.600
you're like, oh, I guess it really is true.

54:15.600 --> 54:17.400
All right, we got church encodings from Booleons.

54:21.560 --> 54:23.880
I'm not going to do this one out.

54:23.880 --> 54:26.480
But if you are familiar with Boolean logic, you have heard

54:26.480 --> 54:28.000
of De Morgan's laws.

54:28.000 --> 54:30.600
De Morgan's laws are a pair of laws.

54:30.600 --> 54:31.760
This is only one of them.

54:31.760 --> 54:38.920
But it says that not P and Q is equal to not P or not Q.

54:39.000 --> 54:42.320
And we've just expressed that using nothing but functions.

54:42.320 --> 54:45.200
No Booleans, no ands, no ors.

54:45.200 --> 54:46.040
I could prove that.

54:46.040 --> 54:48.520
We'll just take our shorthand and replace it with the

54:48.520 --> 54:50.320
actual lambda calculus.

54:50.320 --> 54:56.280
So there's our Boolean equality of not and PQ or not P or

54:56.280 --> 54:59.000
not Q.

54:59.000 --> 55:02.480
All right, it's pretty cool.

55:02.480 --> 55:05.960
Now, I rehearsed this talk last night.

55:05.960 --> 55:06.880
My fiance made me.

55:06.880 --> 55:10.040
She said, this talk is way longer than an hour.

55:10.040 --> 55:11.800
I was like, ah, we'll see how long it is.

55:11.800 --> 55:13.800
She said, no, no, no, you're going to rehearse.

55:13.800 --> 55:18.520
And I rehearsed, and it's way longer than an hour.

55:18.520 --> 55:21.760
But this is a really good stopping point.

55:21.760 --> 55:23.640
So what I'm going to do is I'm going to give you the

55:23.640 --> 55:27.320
conclusion of this talk, which works perfectly after this

55:27.320 --> 55:27.720
slide.

55:27.720 --> 55:28.440
It fits.

55:28.440 --> 55:29.680
It makes sense.

55:29.680 --> 55:33.880
And anyone who would like to is welcome to stay another

55:33.880 --> 55:35.080
30-ish minutes.

55:35.080 --> 55:37.200
I'm going to go into another room, because Mark has to

55:37.200 --> 55:40.960
come in here and get this room ready for demo day.

55:40.960 --> 55:45.440
And I'll show them numbers in the lambda calculus.

55:45.440 --> 55:47.800
But before we do that, I'm going to conclude this talk.

55:47.800 --> 55:51.280
So let me skip way down to the bottom of my deck here.

55:51.280 --> 55:53.200
If I can find my mouse, there it is.

55:57.920 --> 56:00.680
Nope, further.

56:00.680 --> 56:04.600
Nope, more than that.

56:04.640 --> 56:07.000
Keep going.

56:07.000 --> 56:10.440
Try to remember where this slide starts.

56:10.440 --> 56:11.800
Almost there.

56:20.520 --> 56:22.360
So a small preview.

56:28.400 --> 56:31.400
This isn't even the only table in this talk.

56:31.400 --> 56:33.560
These are just the combinators, let alone the

56:33.560 --> 56:36.760
Boolean equality, the arithmetic, the numerals, and

56:36.760 --> 56:41.000
the arithmetic operations that yield Booleans.

56:41.000 --> 56:43.760
So lots of stuff that I am cutting out in the

56:43.760 --> 56:45.000
interest of time.

56:45.000 --> 56:48.680
But yeah, I know.

56:48.680 --> 56:51.040
Here's where I want to conclude, and I want to give you a

56:51.040 --> 56:52.880
couple little small addendums.

56:52.880 --> 56:56.320
The first is I emphasized early on that from primitive

56:56.320 --> 56:59.400
combinators come other combinators.

56:59.400 --> 57:02.760
And this is a really cool sort of atom to molecule sort of

57:02.760 --> 57:03.840
situation.

57:03.840 --> 57:07.280
And it begs the question, how many combinators do we need

57:07.280 --> 57:11.560
and which ones to generate all the other ones?

57:11.560 --> 57:12.880
Is it even possible to do that?

57:12.880 --> 57:15.840
Do we need an infinite number of them?

57:15.840 --> 57:19.720
20, 10, 5?

57:19.720 --> 57:21.320
Just two.

57:21.320 --> 57:22.160
Not even identity.

57:22.160 --> 57:23.400
Identity isn't on the board.

57:23.400 --> 57:24.520
These are the only two you need.

57:24.520 --> 57:26.520
You can make identity out of this, the

57:26.520 --> 57:28.520
Starling and the Kestrel.

57:28.520 --> 57:30.080
The Starling is a weird one.

57:30.200 --> 57:32.880
I actually don't really like the SK

57:32.880 --> 57:37.000
Combinator Calculus, which is what it is called.

57:37.000 --> 57:42.520
I really like the BCKIM Combinator Calculus.

57:42.520 --> 57:44.880
If I just added m to this, this would actually suffice

57:44.880 --> 57:45.680
five of them.

57:45.680 --> 57:47.480
And that was the one that Curry used.

57:47.480 --> 57:49.760
I find this far easier to use than the SK

57:49.760 --> 57:52.040
Combinator Calculus.

57:52.040 --> 57:53.960
For instance, the identity in the SK

57:53.960 --> 57:56.160
Combinator Calculus is S of KK.

57:56.160 --> 57:58.320
It's also SKS.

57:58.320 --> 58:01.000
Those are extensionally equal.

58:01.000 --> 58:03.480
You didn't get a chance to see the Vario, but the Vario

58:03.480 --> 58:05.320
is the world's smallest data structure.

58:05.320 --> 58:05.760
That's right.

58:05.760 --> 58:08.200
I'm putting data structures in lambda calculus.

58:08.200 --> 58:11.120
Here it is in the SK Combinator Calculus.

58:11.120 --> 58:15.960
And this is not even close to how complicated it can get.

58:15.960 --> 58:17.520
So really, why?

58:17.520 --> 58:18.640
What is what?

58:18.640 --> 58:20.600
What?

58:20.600 --> 58:21.520
All right.

58:21.520 --> 58:24.880
To begin with, in my opinion, I was searching for the

58:24.880 --> 58:26.360
answer to this why question.

58:26.360 --> 58:30.520
I was trying to think, am I trying to evangelize like

58:30.520 --> 58:33.120
learning abstract math or this and that?

58:33.120 --> 58:34.000
Then I realized, you know what?

58:34.000 --> 58:37.560
The honest answer for myself is, it's just fun.

58:37.560 --> 58:38.720
I enjoy this.

58:38.720 --> 58:41.800
I hope that you might enjoy it too.

58:41.800 --> 58:45.760
That's the entire basis of the book to Maka Making Bird.

58:45.760 --> 58:48.880
It's a book of logic puzzles and games.

58:48.880 --> 58:54.160
It was written to act as a series of fun challenges.

58:54.200 --> 58:56.760
It's a great mental workout.

58:56.760 --> 58:59.800
Thinking along these patterns, let's you think about, oh

58:59.800 --> 59:01.720
my gosh, I have to think of where nouns are verbs and

59:01.720 --> 59:03.040
verbs are nouns.

59:03.040 --> 59:05.920
And I've got to be able to think about partially applied

59:05.920 --> 59:08.760
functions, curried functions, higher order functions.

59:08.760 --> 59:10.760
There's a lot of spaghetti.

59:10.760 --> 59:15.360
So it's really laying down the neurological groundwork for

59:15.360 --> 59:18.440
understanding functional programming in general.

59:18.440 --> 59:21.440
The lambda calculus, as I said before, being the basis of

59:21.440 --> 59:26.360
languages like Miranda and Lisp and Haskell, means that

59:26.360 --> 59:29.360
those languages, if you know this kind of

59:29.360 --> 59:34.160
combinatorial logic, it sets you up for success in those

59:34.160 --> 59:35.440
kinds of languages.

59:35.440 --> 59:38.640
Because even though you're not required to think entirely

59:38.640 --> 59:41.800
that way, there's a large portion of those languages

59:41.800 --> 59:46.240
that assumes you are comfortable with that.

59:46.240 --> 59:49.320
And from that, we get all sorts of real world practical

59:49.320 --> 59:50.240
benefits.

59:50.320 --> 59:52.120
So I started writing them down.

59:52.120 --> 59:54.320
A lot of them are intersections with just functional

59:54.320 --> 59:55.200
programming in general.

59:55.200 --> 59:58.480
But many of these come directly from the lambda calculus.

59:58.480 --> 01:00:02.880
Closures, higher order functions, laziness,

01:00:02.880 --> 01:00:06.120
infinite data structures, garbage collection, function

01:00:06.120 --> 01:00:10.360
graph reduction, type theory, provable programming code,

01:00:10.360 --> 01:00:13.440
parallel processing for free, parametric polymorphism.

01:00:13.440 --> 01:00:15.600
I mean, it just keeps going on and on and on.

01:00:15.640 --> 01:00:19.800
And this all derives straight out of purely mathematical

01:00:19.800 --> 01:00:24.000
fields that existed even before computers did.

01:00:24.000 --> 01:00:26.000
But at the end of the day, I really just think that there's

01:00:26.000 --> 01:00:28.440
a lot of elegant mathematical beauty to it.

01:00:28.440 --> 01:00:30.520
And it's kind of art for art's sake.

01:00:30.520 --> 01:00:33.680
I hope that this has inspired you to become interested in

01:00:33.680 --> 01:00:38.080
this topic and maybe to go read some more about it.

01:00:38.080 --> 01:00:41.200
Find a little bit of slides.

01:00:41.200 --> 01:00:42.520
Here are all the combinators.

01:00:42.520 --> 01:00:43.960
Here are all the booleans.

01:00:44.000 --> 01:00:47.400
The numerals, church arithmetic, boolean ops in the

01:00:47.400 --> 01:00:49.960
church arithmetic, data structures.

01:00:49.960 --> 01:00:52.280
All of this is in the deck.

01:00:52.280 --> 01:00:54.800
It's not an hour-long talk, is it?

01:00:54.800 --> 01:00:57.480
And you've probably all been wondering, wait a second.

01:00:57.480 --> 01:01:00.120
Where's the most famous combinator of all, the Y

01:01:00.120 --> 01:01:01.120
combinator?

01:01:01.120 --> 01:01:03.120
Well, there's the Y combinator.

01:01:03.120 --> 01:01:04.400
What does it do?

01:01:04.400 --> 01:01:06.800
I'll just leave you with this as a brain teaser.

01:01:06.800 --> 01:01:10.440
The lambda calculus has neither loops nor recursion.

01:01:10.440 --> 01:01:12.600
So how does it do either of those things?

01:01:12.600 --> 01:01:15.120
Because it can calculate anything calculable.

01:01:15.120 --> 01:01:16.040
This is the answer.

01:01:16.040 --> 01:01:20.440
The Y combinator allows for recursion in a language that

01:01:20.440 --> 01:01:23.120
doesn't have recursion built into it.

01:01:23.120 --> 01:01:26.280
Unfortunately, I cannot demonstrate this in JavaScript

01:01:26.280 --> 01:01:29.480
because it goes on forever.

01:01:29.480 --> 01:01:30.920
This is a fixed point combinator.

01:01:30.920 --> 01:01:34.080
It infinitely just keeps evaluating itself, which works

01:01:34.080 --> 01:01:36.680
in a lazy language like Haskell or the lambda calculus

01:01:36.680 --> 01:01:37.680
itself.

01:01:37.680 --> 01:01:41.360
So unfortunately, because JavaScript is like the thing

01:01:41.360 --> 01:01:43.720
on the right and not like the thing on the left,

01:01:43.720 --> 01:01:46.080
we need a slight variation on the Y combinator

01:01:46.080 --> 01:01:49.240
called the Z combinator, which is the exact same as the Y

01:01:49.240 --> 01:01:51.000
combinator except the middle of it

01:01:51.000 --> 01:01:55.440
has a funk, which defers calculation until required.

01:01:55.440 --> 01:01:58.080
So the Z combinator I could demo if I wanted to,

01:01:58.080 --> 01:02:02.200
but I haven't set that up in my code so I won't today.

01:02:02.200 --> 01:02:03.840
All right, that is the talk.

01:02:03.840 --> 01:02:04.640
Thank you very much.

01:02:04.640 --> 01:02:05.440
Any questions?

