start	end	text
0	2000	Alex O'Connor, welcome to the show.
2000	4000	How splendidly we progress.
4000	6000	The first time on a Skype call,
6000	9000	the second time was in person in Austin,
9000	13000	and now it's something of a sort of cinematic production.
13000	15000	I fear that next time we'll be in 3D or something.
15000	17000	It's good to see you again.
17000	18000	Good to see you as well, mate.
18000	22000	How are you feeling in the aftermath of Peter Hitchens?
22000	25000	Validated, vindicated.
25000	28000	I must say that I was a little bit...
28000	31000	I was in two minds about uploading that interview.
31000	35000	There was a bit of a mixture of opinion coming from him.
35000	37000	He wasn't speaking entirely clearly.
37000	39000	It must have been something on his mind.
39000	43000	He said, as he's getting up to walk out,
43000	45000	I don't think you should run this.
45000	47000	And I'm thinking, look, if my guest tells me
47000	49000	that they don't want me to run an interview for any reason,
49000	51000	it could be because they've had a bad hair day,
51000	53000	then I'll respect that.
53000	56000	And so I thought, damn, am I really going to have to be the bigger man here
56000	58000	and just not post this at all?
58000	61000	But then he kept saying, oh, run it if you like.
61000	63000	I can't stop you from running it.
63000	65000	I just don't think you have any moral right to run it.
65000	67000	And I asked him why.
67000	70000	And he said it was because I am a propagandist for drug decriminalization,
70000	72000	a subject which prior to that, by the way,
72000	75000	I'd spoken about once ever.
75000	80000	And that I'd intentionally tricked him to appear on my podcast
80000	83000	in order that I might fool him into a conversation about drugs.
84000	87000	Now, before the podcast started, I said, Mr. Hitchens,
87000	91000	you have about three subject areas that we both talk about
91000	93000	where I think there's a bit of crossover
93000	96000	that you've either spoken about or indeed written books about.
96000	99000	And those are the decriminalization of drugs.
99000	101000	I also mentioned this in my email.
101000	103000	The existence of God or religion, I should say,
103000	105000	God and religion is the topic.
105000	107000	And the third was monarchy.
107000	110000	At this point, he says, you know, monarchy is a bit boring.
110000	115000	Okay, notice listener that he did not take this opportunity
115000	118000	to tell me that he thought that drugs were a bit boring
118000	121000	or would rather not really talk about drugs at all or for too long.
121000	122000	Okay, fine.
122000	124000	So I'm thinking, I agree with you, the monarchy is incredibly boring.
124000	126000	In fact, that's the entirety of my point about the monarchy
126000	129000	is that it's essentially just boring more than anything else.
129000	131000	So let's just do the other two.
131000	134000	So I say we'll run for about an hour ideally.
134000	136000	He says, that's good, you know, and I say, but you know,
136000	138000	if the conversation flows, it can be an hour and a half.
138000	139000	It could be two hours.
139000	143000	And okay, he says, well, look, you know,
143000	145000	I say sometimes they can be three hours long.
145000	148000	He says, well, three hours might be a bit long, but we'll see how we do.
148000	149000	So I'm thinking about an hour and a half.
149000	152000	An hour and a half on what was now, in my view, two subjects.
152000	156000	So at about 40 minutes into this potentially 90 minute podcast
156000	159000	on the same topic when he told me that we've been going around
159000	164000	for too long on that topic, I was a little bit bemused.
164000	167000	But I did think to myself, maybe I've done something wrong here.
167000	171000	Maybe I have upset him in a way that obviously was not intentional.
171000	173000	You know, I wasn't trying to bring this out of him,
173000	175000	although, you know, it does do quite well for the channel.
175000	177000	It's not like it's something I would do intentionally.
177000	179000	So I did think to myself, well, maybe I've done something.
179000	181000	So I listened back and I sent it to some friends, including you.
181000	184000	And thank you for listening to it and saying that like,
184000	186000	most people just said, you have to run this.
186000	188000	He's been completely unreasonable.
188000	190000	And so there have been criticisms.
190000	193000	People have said, well, you know what, it was a bit boring.
193000	195000	Or yeah, it was going around in circles.
195000	197000	I submit that that was his fault, by the way,
197000	200000	because he does this thing which I've noticed
200000	203000	in a lot of philosophical and political discussion,
203000	205000	which is the sort of, I know this one attitude.
205000	208000	When you do a lot of interviews, I find that you have a sort of,
208000	209000	I know this one.
209000	210000	And so...
210000	212000	They answered the question that they heard,
212000	213000	not the answer that was asked.
213000	214000	Exactly.
214000	219000	And it happens, especially when it's easy enough
219000	221000	to make that mistake if you're not listening carefully.
221000	224000	So he was talking about the...
224000	228000	Well, I asked him about the decriminalization of cannabis.
228000	231000	And he says that, well, this will essentially mean
231000	233000	that a lot of more children will be smoking it.
233000	236000	He had this contention that children would end up smoking cannabis.
236000	238000	And I thought to myself, well, okay,
238000	240000	I can understand that concern, of course,
240000	243000	but I think the tobacco industry has suffered quite a blow
243000	246000	in still being perfectly legal to buy as an adult,
246000	248000	but kids just aren't smoking cigarettes anymore.
248000	250000	It's just not a thing that's really done.
250000	251000	Why is that?
251000	254000	In other words, we've had quite a successful education campaign
254000	257000	whereby it's not popular for kids to smoke anymore,
257000	259000	and yet it's still perfectly legal.
259000	261000	Can't we have a similar approach to cannabis?
261000	263000	Potentially, by the way, not a good view.
263000	265000	Potentially a perfectly rebuttable view.
265000	267000	I'm not sure, but I wouldn't know
267000	269000	because they didn't get a rebuttal to that view.
269000	272000	Instead, I just heard, you know, all you can do is do the whole,
272000	275000	which by the way is a genuinely quite tired line in this debate,
275000	277000	the whole, oh, what about smoking?
277000	279000	Or indeed another point where I brought up alcohol.
279000	281000	All you can say is what about alcohol?
281000	282000	What about smoking?
282000	284000	And that's not what I was doing.
284000	286000	At least I contend that's not what I was doing.
286000	287000	Because that's what he heard.
287000	288000	He goes, oh, I know this one.
288000	289000	I've heard this before.
289000	290000	Yeah, and you haven't read my book.
290000	292000	It didn't seem to occur to him
292000	295000	that it is possible, Mr. Hitchens,
295000	297000	to read your book and yet still,
297000	300000	after having done so, disagree with you.
300000	303000	Yeah, it's sometimes when you hear people speak,
303000	305000	especially guys that are a little bit older,
305000	310000	I think there is kind of like reverse ageism that goes on,
310000	313000	which is who is this sort of young whippersnapper person
313000	316000	who I maybe have heard of or haven't heard of much.
316000	322000	And almost like a blas√© kind of discrediting of the thing.
322000	325000	It's like, this is your show, but it's my show, so to speak.
325000	330000	And yeah, it was like, I thought his attitude was pompous
330000	331000	and unlikable.
332000	335000	And my favorite part was when he threw the pillow
335000	336000	at the microphone.
336000	337000	Throwing the pillow down.
337000	339000	And he kept sort of walking back over.
339000	341000	He says, you know, I don't want you to post this.
341000	343000	And yet walked back over to the microphone.
343000	344000	I've never told you about you before.
344000	346000	I've decided that I absolutely do not like you.
346000	348000	It was quite something.
348000	350000	And a lot of people messaged me saying,
350000	352000	hey, like, I'm so sorry that happened.
352000	354000	Like, you know, you're doing all right.
354000	357000	And I'm thinking, sorry, sorry.
357000	359000	I thought there's no way that this is happening.
359000	362000	I mean, when it looked like he was about to get up,
362000	364000	I thought, surely not.
364000	366000	But then internally, I'm thinking, like, go on then, do it.
366000	367000	Go on then, yeah.
367000	369000	Do it, because I don't think I've done anything wrong here.
369000	371000	It was the podcasting equivalent of, come on mate, have a go.
371000	374000	Yeah, but you know, the weirdest thing was
374000	379000	because he sort of gets up to go and he walks out
379000	381000	and he stands at the door.
381000	384000	And I wish you kind of could have seen his body language.
384000	386000	It was very much, there's one point where you can see it
386000	388000	when he walks back into shot and he says something.
388000	390000	And then after he said it, he just sort of stands there
390000	392000	looking at me as if to say, like, what have you got?
392000	393000	Have a go.
393000	395000	And so he'd keep going, like, I'm going to go now.
395000	396000	I'm going.
396000	397000	Right.
397000	399000	I'm going to, I'm going and waiting.
399000	401000	It's just the podcast playing hard to get equivalent.
401000	402000	It must have been something like that.
402000	405000	Yeah, it was like, it was like the person who wants the fight
405000	407000	but wants to look like they didn't initiate the fight.
407000	408000	Right.
408000	410000	And I don't think it's my fault.
410000	412000	I'll leave it up to the, to the judgment of the listener
412000	413000	or the viewer.
413000	415000	I don't think it's my fault that he spent 17 minutes,
415000	420000	17 count them, 17 entire minutes stood at the door
420000	422000	telling me how much he personally dislikes me,
422000	424000	telling me how much he doesn't want to see me again.
424000	427000	I've wanted to do that for as long as I've known you.
427000	428000	So.
428000	429000	Well, we'll see how we did.
429000	430000	Yeah, today.
430000	433000	You're going to try and convince me of the existence of God today.
433000	435000	You managed to convince chat GPT.
435000	436000	That's right.
436000	438000	Which means, does it mean that I'm smarter than chat GPT
438000	442000	if you convince me more quickly or more slowly or not at all?
442000	443000	I don't know.
443000	447000	I do know that it, it means that, well, well chat GPT
447000	449000	if it's going to inherit eternal life,
449000	452000	I sort of wonder how that's going to work in heaven.
452000	453000	I don't know.
453000	454000	I mean, I don't know if I've made it.
454000	456000	Just this recursive nightmare for everyone as they walk around
456000	459000	and they've got the chat GPT logo floating about.
459000	460000	Yeah.
460000	462000	The interesting thing about chat GPT is that you sort of,
462000	464000	you can, you can essentially convince it of anything.
464000	467000	And so I wasn't quite sure if it was even a very good video idea
467000	469000	because I'm sure I could just as easily convince it
469000	470000	that God doesn't exist.
470000	472000	Well, at least you can be thankful that it wasn't able
472000	474000	to say it had no opinion of you before,
474000	476000	but it absolutely does not like you and then get up and walk out.
476000	477000	Quite right.
477000	479000	Some people in the comments did say that at least, you know,
479000	481000	chat GPT stuck around until the end.
481000	482000	That would be a task.
482000	483000	In fact, that's another video idea.
483000	486000	I got chat GPT to storm out of an interview.
488000	490000	Even I probably couldn't do that.
491000	492000	Didn't this get brought up?
492000	494000	You debated Ben Shapiro yesterday.
494000	495000	How did that go?
495000	496000	I haven't even seen you.
496000	497000	It went well.
497000	500000	I think it will probably be out around the time of this,
500000	503000	this interview maybe slightly before or slightly afterwards.
503000	505000	It was, it was a good conversation.
505000	508000	We were discussing whether or not religion is good for society.
509000	511000	It stands for young Benjamin to take at the moment.
511000	512000	I suppose so.
512000	516000	I mean, it was a very much sort of don't mention the war type,
516000	517000	type scenario.
517000	519000	I mean, the producers had said that we want this to be
519000	520000	an evergreen conversation.
520000	523000	We want this to be something that people can listen to at any point.
523000	527000	And also Ben had just the night before been to the Oxford Union.
527000	529000	And I haven't seen that yet either.
529000	530000	I saw that.
530000	534000	He went had at it with a bunch of people on the other side of the fence.
534000	535000	Yeah.
535000	536000	He didn't have a very good time.
536000	539000	He said to me that it was the most tense thing that he's ever done.
540000	542000	The most tense thing he's ever, ever been a part of.
542000	546000	Well, I saw something that was kind of interesting was the video
546000	548000	was only shot on what appeared to be iPhone.
548000	549000	Yes.
549000	553000	So there was no, maybe they just wanted to get it early as opposed
553000	556000	to waiting for the Oxford Union's official video to come through.
556000	557000	Seems to be the case.
557000	559000	They do seem to be planning to upload it.
559000	561000	In fact, when I was recording with Ben,
561000	563000	I think his team were in the green room,
563000	566000	sort of furiously subtitling to try and get it out
566000	568000	potentially before the Oxford Union.
568000	569000	I'm not entirely sure.
569000	573000	But I mean, it sounded like a hell of an evening.
573000	578000	And so the next day he was saying that it sort of felt like a nice break from that.
578000	580000	What to sit opposite you.
580000	584000	Well, you are the comfortable leather pair of shoes that he can put on.
584000	587000	I think Ben relaxes in argumentation.
587000	589000	I think he genuinely enjoys it.
589000	592000	I think there's no contradiction to say that he was having some time off
592000	595000	by sitting there and having a spack.
595000	597000	But he was having a break from the politics.
597000	600000	In other words, he was able to just argue about something a bit more perennial
600000	604000	and a little less fiery, I suppose.
604000	605000	What have you learned?
605000	610000	So you are, I've been a massive fan of you since before you came on the podcast
610000	613000	and since then we've become friends and you've come out to see me in Austin.
613000	614000	We've spent a ton of time together.
614000	617000	You're probably my favorite person to watch debate people
617000	622000	because it's kind of a little bit like watching Batman versus Spider-Man or something.
622000	624000	Because I know you well and we've argued a lot.
624000	629000	And I know maybe Ben Shapiro, but I don't know what will happen when these two people come together.
629000	632000	You were president of Socks Ock?
632000	634000	The Socratic Society, yes.
634000	638000	You were part of Debate Sock and all of this other stuff at Oxford.
638000	645000	Given that you've got a relatively illustrious heritage of both formal and informal debates,
645000	652000	what is your assessment of Ben Shapiro's debating style, his ethical consistency,
652000	655000	his ability to deploy logic, et cetera, et cetera.
655000	658000	Now that you've gone mano a mano in the ring.
658000	661000	Well, he has obviously an incredibly high verbal IQ.
661000	665000	He constructs a sentence out of nowhere and do it very quickly.
665000	667000	And he's also very difficult to interrupt.
667000	669000	Not that I particularly wanted to.
669000	672000	I mean, he would throw sort of maybe two or three points out at once.
672000	675000	And you want to butt in and do them one by one.
675000	676000	You don't want to be rude, of course.
676000	681000	So I let him finish, but it was amazing how they just glued together into one wall of text.
681000	687000	I've seen comments on some of the videos that I was watching of him in preparation to talk to him
687000	692000	where people were not being funny in saying that they play the video on 0.75 feet.
692000	694000	Because it makes him sound normal.
694000	699000	There was sort of an episode with Constantine and Francis Trigonometry
699000	703000	and he's talking about religion and its relation to the fentanyl crisis.
703000	704000	And people were saying that if you...
704000	705000	And it was very fast.
705000	709000	And if you play it on 0.75, you forget that you've done that
709000	712000	and you're just hearing somebody talk at a normal volume at a normal speed
712000	715000	and then Constantine comes in sounding like a blue whale or something.
715000	717000	So he's very quick.
717000	720000	But also I thought very charitable.
720000	721000	This is the thing.
721000	722000	I think people get Ben Shapiro wrong.
722000	728000	I went to his Cambridge Union event after this discussion slash debate
728000	730000	because it was in Cambridge.
730000	732000	That's why we were out there.
732000	735000	So I went to this event and I was talking to a lot of the students afterwards
735000	738000	and you hear a lot of people saying about Ben Shapiro that he's a bit of a grifter
738000	741000	or, well, I'm not really a fan, or you have the sort of secret fans
741000	743000	who are sat in the chamber going like,
743000	747000	well, I think it's important if you're going to disagree with someone.
747000	751000	You sort of have to hear the thing that you're going to disagree with in the flesh.
751000	753000	You can say that you like Ben Shapiro.
753000	754000	It's okay.
754000	761000	But people see this side of him of the sort of slightly sneering, smarmy,
761000	764000	owning the college student kind of thing.
764000	769000	But I think in many ways he matches the energy that he's given.
769000	773000	And so taking him seriously and listening to what he's saying
773000	777000	and being willing to concede a point to him, he will do the same thing.
777000	779000	And I think that happened in this conversation.
779000	780000	It's steadfast.
780000	782000	We're saying what we think to each other.
782000	785000	At one point, we both accuse each other simultaneously of being delusional.
785000	789000	But in such a manner that if you say something, you get a sort of like,
789000	792000	yeah, no, that's a fair point, actually, maybe we should put it this way instead.
792000	793000	Or, yeah, you know, actually, I see what you're saying.
793000	794000	No, you're right.
794000	796000	I should have said this instead, that kind of attitude,
796000	800000	which is the kind of thing that people think Ben Shapiro is incapable of for some reason.
800000	801000	Humility.
801000	802000	You know what I mean?
802000	803000	Yeah.
803000	806000	And it's a kind of, it's a hidden humility because it comes out not in the attitude,
806000	810000	not in the, not in a sort of, he's not going to like give way to you emotion.
810000	812000	He's not going to be like, oh, you're right.
812000	815000	It would just be if you pay attention to the way he's constructing an argument
815000	818000	and changing it subtly based on your responses, you know, that he really is listening
818000	821000	and really is trying to engage with what you're actually saying.
821000	824000	And that's the kind of humility that I don't think can really be faked.
824000	825000	Yeah.
825000	830000	I am friends with a bunch of guys that have worked with him over the years.
831000	836000	I know for a fine fact that part of his debate prep involves a number of break glass
836000	841000	in case of mass offense, sort of escape hatches,
841000	846000	and that there's layers of how deep and how aggressive he can go.
846000	851000	So I would love to know, actually, I might email him and find out what he's got on you,
851000	854000	just in case I ever need to actually pull that pin.
854000	858000	Well, he said to me when he walked in, I saw the Peter Hitchens thing,
858000	860000	because everybody's been saying to me recently.
860000	861000	So he'd at least seen that.
861000	862000	So he knows how I behave.
862000	865000	And he knows, in other words, that if he did start sort of screaming at me,
865000	868000	that I would probably just sit there and take it.
868000	869000	Right.
869000	870000	Okay.
870000	872000	Like the philosophical cuck that you are.
872000	873000	Yeah.
873000	874000	You're kind of a little...
874000	877000	There's another quote for the footer bio, I think.
877000	878000	Yeah.
878000	879000	Have you updated it too?
879000	880000	I absolutely do not.
880000	882000	I've decided I do not like you, Peter Hitchens.
882000	884000	It's in there somewhere.
884000	887000	I think it's I actively dislike you is the quote that's now on my bio.
888000	889000	Yeah.
889000	890000	I don't think I'll ever get rid of unusually penetrating...
890000	891000	What was it that you were doing,
891000	894000	what was it that you did for a while making theists question their beliefs
894000	896000	and lesbians question their sexuality since...
896000	898000	I don't know what you're talking about.
898000	899000	I remember that in your bio.
899000	900000	I have no idea what you're talking about.
900000	902000	We really haven't had each other a long time, haven't we?
902000	903000	Yeah.
903000	904000	You know what I found yesterday?
904000	907000	I was, I sort of stumbled across it while looking for an email trying to find out
907000	908000	where we were filming today.
908000	912000	And I found the original email that you sent me in,
912000	915000	must have been 2019, when we first met.
915000	916000	And it was amazing.
916000	918000	It was this sort of, hi, Alex.
918000	920000	Been watching your stuff for a while.
920000	922000	Like it was sort of three, four paragraphs of texts.
922000	925000	I'd love to sit down and have a conversation with you.
925000	927000	I think that your views will be of big interest to my view.
927000	930000	And then I've already spoken to these people.
930000	932000	And it was a bunch of people that I hadn't heard of.
932000	933000	Wasn't really in my sphere.
933000	938000	And it signed off Chris Williamson Voodoo events.
938000	939000	Fantastic.
939000	940000	Yeah.
940000	941000	Wow.
941000	942000	My previous life.
942000	943000	Yeah.
943000	945000	I had a filling nightclubs in my signature until only six months ago.
945000	947000	I realized that I needed to get rid of it.
947000	949000	But no, it's, it's cool, man.
949000	952000	I think, you know, if I could invest money in people,
952000	956000	you, George Mack, Zach, my housemate,
956000	959000	Gwinda Bogle, Rob Henderson, you know, even Rory Sutherland,
959000	962000	I don't think that the market has priced in his talent.
962000	967000	And it's so funny because like what I did for almost all of my career in
967000	971000	nightlife was find different kind of talent, right?
971000	973000	It was like degenerate party talent,
973000	977000	things that had good work ethic and some skill and then bring them in
977000	979000	and sort of train them up.
979000	982000	So keeping your finger on the pulse of what's happening with regards to
982000	984000	trends, if who is appropriate and blah, blah, blah.
984000	986000	But yeah, man, I'm, you know, there is a point,
986000	989000	I will happily say it now, there is a point that's going to occur
989000	993000	within the next few years where something happens with you being
993000	997000	involved that just catapults you into like superstardom.
997000	1001000	Like I would absolutely bet a shit ton of money that this is going to happen.
1001000	1003000	What's that big thing you're doing soon?
1003000	1006000	Can we announce the big thing that you're doing soon, that even bigger debate?
1006000	1007000	I think not.
1007000	1008000	Right.
1008000	1010000	Only because it's still very much up in the air.
1010000	1011000	Okay.
1011000	1012000	However.
1012000	1013000	If and when that happens.
1013000	1014000	If and when that happens.
1014000	1015000	It's going to break the internet.
1015000	1016000	That could be it.
1016000	1017000	Yeah.
1017000	1018000	Unless this does it for me.
1018000	1019000	Very well might do.
1019000	1020000	This is the biggest platform you've been on.
1020000	1024000	So when was the last time that you're aware of in your world of philosophy
1024000	1029000	that something like a step change, like the equivalent of the discovery
1029000	1031000	of the Higgs boson happened?
1031000	1032000	In philosophy?
1032000	1033000	Yeah.
1033000	1036000	Every now and again something does come along that's a bit revolutionary.
1036000	1040000	And a recent example and by recent, consider we're talking about the history
1040000	1045000	of philosophy here, 20th century, the theory of knowledge is completely
1045000	1048000	exploded by a man called Edmund Gettier.
1048000	1051000	And this is actually, I think quite fascinating.
1051000	1053000	I'll be interested to hear what you think about this.
1053000	1057000	So knowledge is really difficult to define.
1057000	1059000	People didn't used to have as much of a problem with it.
1059000	1063000	Like if you had to give a definition of knowledge, what does it mean to know something?
1063000	1064000	This isn't like a trick question.
1064000	1065000	I'm just interested.
1065000	1066000	What do you think?
1066000	1071000	To know something, to be able to accurately predict what happens in the world.
1071000	1072000	Okay.
1072000	1077000	So it's got something to do with it being true in the world and your ability to predict.
1077000	1079000	But you can also think about things in the past, right?
1079000	1083000	Like you can know that Napoleon existed or something.
1084000	1086000	And the ability to infer.
1086000	1091000	Yeah, to infer, to sort of have some kind of belief about the world.
1091000	1092000	Which is accurate.
1092000	1094000	Which is accurate, which is true.
1096000	1097000	Sure.
1097000	1102000	But then imagine, for example, you're in like a locked concrete box with no windows.
1102000	1109000	And I don't know, like some voodoo mystic tells you that it's raining outside.
1109000	1111000	And they're just like insane.
1111000	1112000	They're on drugs or something.
1112000	1114000	And they just tell you that it's raining, they're convinced of it.
1114000	1117000	And for some reason, you believe them totally irrationally.
1117000	1121000	And it just so happens that it is, by coincidence, raining outside.
1121000	1122000	Did you know?
1122000	1123000	Right.
1123000	1127000	So you have a belief about the world, which is true, but it would seem very strange to
1127000	1130000	say that you know there's raining outside, right?
1130000	1135000	And so since Plato and the ancients, we've sort of had a consensus on the idea that knowledge
1135000	1138000	is justified true belief, JTB.
1139000	1142000	So you need to have a belief that's true.
1142000	1146000	You need to, of course, believe it to be true, but you have to also be justified in that
1146000	1147000	belief.
1147000	1148000	And that's what makes it knowledge.
1148000	1152000	So if you see that it's raining outside through the window and you believe that it's raining
1152000	1155000	outside and then it's true that it's raining outside, now you can say you know that it's
1155000	1156000	raining outside.
1156000	1161000	And this is just essentially consensus for potentially thousands of years of talking
1161000	1162000	about here.
1162000	1166000	And then Edmund Getty, and at least one account, this may be apocryphal, but it's said that
1166000	1171000	he sort of hadn't really published anything and was being compelled to get something in
1171000	1175000	a journal and he just sort of reaches into his papers of random things he's been writing,
1175000	1179000	pulls up the one on the top and hands it off for submission.
1179000	1181000	This is about two or three pages long.
1181000	1185000	And it just upends the whole thing with essentially a counter example, which you're now known as
1185000	1186000	Getty air cases.
1186000	1194000	So his example was to say, okay, imagine that you're in a job interview and your interview
1195000	1201000	goes really quite well and the person says to you, you know, I shouldn't really be saying
1201000	1203000	this, but I think you've got it.
1203000	1205000	And so you go back outside and you're feeling pretty good.
1205000	1209000	There are other candidates, but you've got a pretty justified reason to think that you're
1209000	1210000	going to get the job.
1210000	1214000	Then the other guy goes in and while you're waiting for him, you know, you're just fiddling
1214000	1217000	around in your pocket and you take out whatever you've got in your pocket and you've got 10
1217000	1219000	coins and you're just fiddling with the 10 coins.
1219000	1224000	So you develop a justified belief that the person who's going to get the job has 10 coins
1224000	1229000	in his pocket because you're pretty sure you're going to get the job and you've just by chance,
1229000	1231000	you just had a look and you've got 10 coins.
1231000	1235000	So you got a justified belief that the person who's going to get the job has 10 coins in
1235000	1236000	their pocket.
1236000	1239000	There's been some kind of like freak mistake or something.
1239000	1242000	Maybe they've read your name wrong on the form or the person who told you they thought you
1242000	1245000	got it meant speaks the other person, but it turns out the other guy actually gets the
1245000	1246000	job.
1246000	1251000	But just by sheer coincidence, he also has 10 coins in his pocket.
1251000	1257000	The question is, did you know that the person who would get the job would have 10 coins
1257000	1258000	in his pocket?
1258000	1264000	You have a justified, true belief that the person who gets the job would have 10 coins
1264000	1268000	in his pocket, but it seems in this circumstance, you didn't know that.
1268000	1269000	That just seems wrong.
1269000	1270000	Seems like a wrong account.
1270000	1274000	It's a bit of a sort of clunky example and he gives another one which is also maybe a
1274000	1281000	little bit clunky, but this sort of sparks this type of affair called a Gettier case.
1281000	1287000	Well, you told me, I think over dinner, the best Gettier case, which was the person behind
1287000	1288000	the hedge.
1288000	1289000	Yes.
1289000	1290000	So this is better.
1290000	1291000	I think so.
1291000	1292000	So I think it's actually better.
1292000	1294000	Firstly, it's better to experience them for yourself and there are simpler explanations
1294000	1295000	as well.
1295000	1301000	So I was in a car driving around a bend and over the hedge, I see this small child sort
1302000	1306000	of bouncing up and down behind the hedge and I thought to myself, oh, cool.
1306000	1307000	I'm about to see a horse.
1307000	1310000	I mean, it looked like the kid was riding a horse and I was like, yeah, cool.
1310000	1316000	We're going to see a horse and we ride around this bend and the kid was actually on his
1316000	1321000	or her like dad's back and that's why she was high up and bouncing up and down.
1321000	1327000	But just by sheer coincidence in the field behind them was a horse and I couldn't believe
1327000	1328000	it.
1328000	1329000	I thought I've just experienced a Gettier case.
1329000	1332000	I had a justified true belief that I was about to see a horse.
1332000	1336000	The difficulty with that one is that it's probably not justified to believe that I was
1336000	1338000	about to see a horse because I probably should have thought that it could have been a father.
1338000	1341000	But a much more simple example and this actually happened to me once.
1341000	1346000	I was in the US Capitol building in the crypt and they had the clock that used to be in
1346000	1351000	the house of representatives and they said that the reason they replaced it and brought
1351000	1353000	it down here was because they were fed up of winding it up.
1353000	1355000	They didn't want to wind it anymore.
1355000	1358000	And I looked at it and I asked the tour guide lady.
1358000	1360000	I said, well, do they still wind it while it's down here?
1360000	1361000	And she said, no.
1361000	1365000	And I thought, but it's the real, it's the time.
1365000	1367000	It says the time right now.
1367000	1370000	And she was like, oh, yeah, it must be a coincidence.
1370000	1373000	And I was like the only one looking around like, hey, that's, that's pretty, that's pretty extraordinary.
1373000	1375000	I mean, I guess it happens twice a day, right?
1375000	1376000	But this is a Gettier case.
1376000	1380000	If you, if your watch breaks, but you don't know that it's broken, you've got a reliable
1380000	1387000	watch, but today it's broken and you look at the time and it stopped on half past three.
1387000	1389000	And so you look at it and you think, oh, it must be half past three.
1389000	1391000	And it does actually just so happen to be half past three.
1391000	1393000	Did you know it was half past three?
1393000	1395000	That's a Gettier case.
1395000	1397000	Justified true belief.
1397000	1400000	And yet it seems weird to say that you, that you know it.
1400000	1405000	So Gettier's revelation here was something like what you're talking about.
1405000	1408000	A sort of genuine novelty in the history of philosophy.
1408000	1410000	And they come about quite rarely, but they, they do occur.
1410000	1413000	This episode is brought to you by Element.
1413000	1417000	Element is a tasty electrolyte drink mix with everything that you need and nothing that
1417000	1418000	you don't.
1418000	1420000	It's a healthy alternative to sugary electrolyte drinks.
1420000	1424000	It's got a science-backed electrolyte ratio of sodium, potassium and magnesium.
1424000	1427000	You might ask, what do I want with an electrolyte drink?
1427000	1429000	Well, it'll regulate your appetite.
1429000	1430000	It'll curb cravings.
1430000	1431000	It'll help improve your brain function.
1431000	1433000	And best of all, it tastes phenomenal.
1433000	1438000	First thing in the morning, this orange element salt in water is outstanding.
1438000	1442000	Your adenosine system that caffeine acts on isn't even active for the first 90 minutes
1442000	1443000	of the day.
1443000	1444000	So it's pointless having a morning coffee.
1444000	1447000	Your adrenal system, which is what salt acts on, is active.
1447000	1450000	So this will make you feel more alert, more awake and improve your hydration.
1450000	1454000	Best of all, they've got a no BS, no questions asked refund policy.
1454000	1455000	So you can buy it.
1455000	1458000	And if you do not like it for any reason, they will give you your money back.
1458000	1459000	That's how confident they are that you love it.
1459000	1465000	Head to drinklmnt.com slash modern wisdom to get a free sample pack of all eight flavors
1465000	1466000	with your first box.
1466000	1471000	That's drinklmnt.com slash modern wisdom.
1471000	1475000	What happens downstream from that in the world of philosophy?
1475000	1477000	Just a massive migraine, basically.
1477000	1482000	People start coming up with arguments, responses, you know, so people start saying,
1482000	1483000	Oh, maybe it's not justified to believe.
1483000	1489000	Maybe it's like causally related justification to the cause of the
1489000	1495000	But presumably kind of in the same way that I guess a new scientific discovery is made
1495000	1499000	about the way that we metabolize glucose or about what happens if you take this amount
1499000	1504000	of nicotine or the role of metformin in preventing high blood pressure or something.
1504000	1509000	They're stacked on top of that one assumption, a number of other assumptions.
1509000	1513000	But with philosophy, especially something I imagine like the philosophy of knowledge,
1513000	1521000	it's so foundational that having this entire universe built on this particular foundation
1521000	1526000	then means that the entire house of cards collapses down and people then need to rebuild
1526000	1528000	all of this nightmare on top of it.
1528000	1529000	Yeah.
1529000	1532000	Well, most of philosophy is just a consistency test as it is in something like mathematics.
1532000	1536000	It's just that we accept that there are certain axioms that even even mathematical axioms,
1536000	1539000	you know, you can you can you can question them.
1539000	1549000	I mean, Veritasium just made a quite good video about Euclidean geometry and how it sort of
1549000	1555000	just accepted for a very long time that for example, you know, if you have a right angle,
1556000	1561000	then if you sort of join up the two lines coming off that right angle, you'll create a triangle
1561000	1564000	whose interior angles add up to 180 degrees.
1564000	1571000	And then people start thinking about what about like curved geometric spaces?
1571000	1572000	What if you do this on a globe?
1572000	1576000	If you put a triangle on a globe, the angles aren't going to add up in that way.
1576000	1583000	And these these are sort of like axioms of mathematics that essentially they don't necessarily get proved wrong
1583000	1586000	or thrown out, but people realize that you can think about things differently.
1586000	1589000	And so most of what we're doing is actually just testing for consistency.
1589000	1595000	And so it's actually quite difficult to prove an axiom wrong because you kind of need an axiom just to get off the ground.
1595000	1598000	And the rest of everything you're doing is just consistency tests with that axiom.
1598000	1602000	This is one of the most interesting things I learned from you, maybe in the first ever episode that we did,
1602000	1609000	as you were teaching me about the difference between ethics and matter ethics as someone that isn't formally trained in either.
1610000	1612000	And you I use this all the time.
1612000	1618000	It's such an interesting mental model to think that in order for me and you to have a discussion about ethics,
1618000	1625000	our meta ethical foundation, we need to agree on that because out of that, if we don't,
1625000	1631000	the entire ethical discussion on top will just continue to fall back to definitional problems
1631000	1636000	and what you're presuming that so you can't discuss the stuff that happens on top
1636000	1638000	unless you discuss the stuff that's underneath.
1638000	1641000	And this is it's the entirety of the trans debate, right?
1641000	1650000	It's the entirety of lexical overwhelm that if you can't agree on the definition of words,
1650000	1657000	the argument about the words and what they then refer to just collapses in on itself
1657000	1661000	and continuously just falls back to an argument about the definition of words.
1661000	1665000	Yes, this happens with, for example, freedom.
1665000	1671000	There are lots of different ways of conceiving of freedom, famously freedom from and freedom to, right?
1671000	1677000	Is freedom just being left alone or is freedom being empowered to do things that you should be able to do?
1677000	1680000	And then when you have people arguing about nationalised healthcare, for example,
1680000	1684000	one person says to be free, you need to be healthy.
1684000	1688000	And one person says to be free, you need to spend your own money as you please
1688000	1690000	and not be forced to fund other people's healthcare now.
1690000	1693000	Both of these people can be right, they're just defining freedom differently.
1693000	1695000	So you're quite right.
1695000	1697000	And that's why metaethics is quite important.
1697000	1703000	I mean, AJA I pointed out in Language, Truth and Logic that the vast majority of ethical debate is not ethical debate.
1703000	1705000	It's descriptive debate, it's factual debate.
1705000	1709000	If you look at the so-called ethical debate around gun laws in America, for example,
1709000	1711000	people are talking about statistics.
1711000	1713000	They're saying X many people die per year.
1713000	1716000	Oh, well, don't you know that more children are killed by swimming pools?
1717000	1723000	Don't you know that if we ban certain types of weapons or blah, blah, blah,
1723000	1729000	that this many less people will die, all these kind of things are just descriptive factual statements
1729000	1731000	that people like to dispute with each other.
1731000	1733000	And that's why they like to say we have the facts on our side.
1733000	1740000	But the actual ethical question that undergirds it all is hardly ever even reached.
1740000	1743000	And so most of the time people are actually arguing about that.
1743000	1745000	I mean, the same thing with an abortion debate, for example.
1745000	1748000	You know, questions about biology, when does consciousness emerge?
1748000	1752000	Can it survive on its own outside of the womb this week or this week?
1752000	1753000	You know, this kind of stuff.
1753000	1757000	Will it increase the number of women who die or decrease the number of women who die?
1757000	1759000	But none of these are ethical questions.
1759000	1763000	And people think they're having an ethical debate when they're actually just having a debate about facts
1763000	1766000	that can be resolved in principle by scientific empirical inquiry.
1766000	1770000	The ethical question is the more interesting one that's often assumed.
1770000	1773000	And if people think that they agree with each other
1773000	1776000	or understand each other in the same way on that ethical first point,
1776000	1779000	then you're in for a disaster.
1779000	1781000	If they don't, I mean.
1781000	1785000	Yeah, what do you wish that more people could realize
1785000	1790000	when it comes to understanding ethics and consistency in their own lives?
1790000	1795000	Is there something that a little red pill or a particular insight that you wish you could deposit
1795000	1798000	into the mind of the populace that you think would make their lives a little bit more easy
1798000	1800000	or the sense making a bit more simple?
1800000	1805000	I didn't know about making lives easier, but I do think that people should recognize
1805000	1809000	the extent to which emotions dominate our ethical thinking.
1809000	1812000	I mean, I take a...
1812000	1816000	I think it's seen as a relatively eccentric view that ethics just is the expression of emotion.
1816000	1821000	This was something popularized by that same AJ Ayer in a book that was so troubling
1821000	1824000	to the philosophical consensus at the time that there's a story of,
1824000	1826000	I think it was like a...
1826000	1829000	maybe a dean of Balliol College or something who when a student came in,
1829000	1832000	everybody wanted to talk about this book and they were so scared of the implications of it
1832000	1836000	that he literally throws it out of the window because he just doesn't want to talk about it.
1836000	1841000	Ayer is talking about how the only things that can be meaningful are those which are
1841000	1844000	analytically true or empirically verifiable.
1844000	1848000	If the statement you're making isn't something you can, at least in principle,
1848000	1852000	test empirically or something that's just a tautology, two and two is four,
1852000	1854000	then what you're saying is literally meaningless.
1854000	1856000	And people came to him and said, well, what about ethical statements?
1856000	1859000	You can't prove these in principle and they're not tautological.
1859000	1865000	And he said, well, the way that they're meaningful is that they are expressions of emotion.
1865000	1868000	And it gives birth to this view called emotivism,
1868000	1871000	which is really a philosophy of language more than a philosophy of ethics.
1871000	1876000	It tries to describe what people mean when they say good or bad.
1876000	1880000	And famously, he comes up with this analogy that saying murder is wrong.
1880000	1882000	It's like saying boo murder.
1882000	1886000	And saying murder is giving to charity as good as like saying yay charity.
1886000	1888000	It's just an expression of emotion.
1888000	1891000	It's not even the same thing as saying I like charity or I don't like murder
1891000	1893000	because those things can be true or false.
1893000	1894000	They have truth value.
1894000	1898000	It could be true that it is just a psychological fact that I don't like murder.
1898000	1899000	He means murder is wrong that statement.
1899000	1903000	It's just the expression of the emotion, boo murder.
1903000	1908000	And I think even if you don't agree with him to that extent, as I more or less do,
1908000	1913000	if you begin to recognize the extent to which emotions are dominating your ethical conduct,
1913000	1918000	pay attention to what it feels like when you analyze something as wrong.
1918000	1921000	I think it belongs in the same category as-
1921000	1922000	Because you've got this sort of-
1922000	1923000	Emotion.
1923000	1928000	Sweet of a soup of stimulus going on inside of you.
1928000	1931000	What is it like to feel like something is wrong?
1931000	1937000	And we know that people seem to change what they rationally do based on how they're feeling.
1937000	1939000	I mean, I don't know if you've come across terror management theory before.
1939000	1940000	It surprised me if you hadn't.
1940000	1945000	The idea that all human beings are doing is trying to manage their fear of death.
1945000	1948000	And that's what motivates all human activity.
1948000	1951000	And there have been some interesting studies and some of them are harder to replicate than others.
1951000	1958000	But I mean, the first one, the most famous was some, I think, Arizona state judges.
1958000	1964000	And they were being asked to recommend a bond for the solicitation of prostitution.
1965000	1970000	And what the researchers did was they asked them to fill out just a form first.
1970000	1975000	And on half of the forms, they just mentioned death.
1975000	1977000	They just put in a few questions about death.
1977000	1979000	What do you think happens after death?
1979000	1980000	Who would you put in your will?
1980000	1981000	That kind of stuff.
1981000	1983000	Nothing too extreme.
1983000	1988000	And they found that the bond that was set by the judges-
1988000	1992000	I mean, I think the average bond for the control group was less than $100.
1992000	1996000	And for the ones who were reminded of their death was my $200 or $300 on average.
1996000	1998000	What does that imply?
1998000	2004000	So the interpretation of terror management theory was that when we're reminded of our deaths,
2004000	2011000	we need to temporarily, more heavily reaffirm the sort of death-denying aspects of our culture.
2011000	2015000	The reason that we do things, the reason we create art, the reason that we get out of bed,
2015000	2021000	the reason that we have conversations like this is because in some way it's traceable back to trying to essentially deny our own death.
2021000	2023000	Ernest Bakker wrote a book called The Denial of Death.
2023000	2026000	And this is essentially the idea.
2026000	2029000	And so for judges, it might be something like by participating in the legal system,
2029000	2035000	they're participating in something that's a bit beyond them and therefore it exists outside of their own mortality.
2035000	2042000	And so the thesis, this mortality salience hypothesis as it's known, is that for a judge,
2042000	2050000	if they're reminded of their own death, what they will temporarily be compelled to do is more harshly reaffirm that thing
2050000	2055000	that is the death-denying aspects of their daily life, which is participation in the legal system,
2055000	2057000	so more harsh penalties.
2057000	2060000	Now, the explanation seems a little bit tenuous.
2060000	2065000	I'm not sure about that, but it does seem strange that when you remind people of their own death,
2065000	2072000	they will, like Muslims will become more derogatory towards Jews.
2072000	2076000	People of different nationalities will sit further away from each other.
2077000	2082000	When asked to draw pictures of currency, it will draw physically larger pictures of currency.
2082000	2089000	People's opinion on whether they prefer a picture of a forest or a picture of suburban neighborhood will change on average.
2089000	2093000	These things are extraordinary, just from being reminded of your own death.
2093000	2099000	Of course, the biggest manifestation of the denial of death would be religion.
2099000	2108000	That would also explain why religion deals a lot with death and why if you remind people of their own death,
2108000	2112000	they also become religious, which by the way is true of atheists as well.
2112000	2115000	People who don't believe in God will still become more religious,
2115000	2120000	even if they don't ultimately believe in God when reminded of their own death.
2121000	2128000	I've been thinking a good bit recently about how people do an awful lot,
2128000	2132000	especially in the modern world, that is death denialism masquerading as something else.
2132000	2135000	I think the productivity movement very much is that.
2135000	2138000	Trying to fit more into less time.
2138000	2144000	If only I could get more life, more work, more output out of my one unit of days or whatever.
2144000	2150000	I think that a good chunk of the health and fitness world, the longevity movement, the biohacking movement,
2150000	2153000	all of that is absolutely death denialism.
2153000	2159000	And you can see as well, nutrition, all of the arguments about is it better for me to be carnivore or vegan?
2159000	2161000	Should I go high carb or low carb?
2161000	2162000	Can I do intermittent fasting?
2162000	2165000	Should I be using ketones exogenously?
2166000	2174000	Ultimately, the reason that I think these arguments are so vehement and passionate,
2174000	2178000	especially when you think it's diet, guys, right?
2178000	2179000	It's diet.
2179000	2185000	It's like, I want to have aspartame, you want to have sugar.
2185000	2190000	How does my aspartame consumption impact your sugar consumption?
2190000	2199000	But what it hits at for a lot of people is a certainty about I can predict and project out into the future
2199000	2203000	how long I'm going to be able to live or die and I'm going to be able to compare myself to this other person.
2203000	2213000	And their conviction in their particular approach, which derogates my approach implicitly,
2213000	2217000	suggests to me, you're going to die sooner.
2217000	2219000	And that causes me to be fucking terrified.
2219000	2223000	And it's the same reason why people are so, how long do you need to do?
2223000	2225000	It's not VO2 max that's most important.
2225000	2226000	It's HRV.
2226000	2227000	It's resting heart rate.
2227000	2228000	It's not its galvanic skin temperature.
2228000	2229000	We're not looking at that.
2229000	2230000	We're looking at telomere length.
2230000	2231000	We're not looking at that.
2231000	2232000	It's whatever.
2232000	2235000	All of the things, you know, the entire field of health and fitness, which I'm a big part of,
2235000	2241000	I think is a good chunk of it is death denialism, just masquerading as getting big biceps.
2241000	2242000	Yes.
2242000	2245000	So sometimes it is more obvious.
2245000	2250000	I think we need more nihilist health influences who will sort of say, you know,
2250000	2255000	when the question is asked, you know, should you eat white bread or brown bread or whatever it is,
2255000	2257000	you know, that they'll sort of begin with the question.
2257000	2261000	It sort of depends on your views on the intrinsic value of life.
2261000	2267000	Also, if you're a bit of a utilitarian, I mean, people often say that being unhealthy might be unethical
2267000	2272000	because in a country with nationalised healthcare, you're a burden.
2272000	2274000	But are you?
2274000	2280000	I mean, who costs the taxpayer more, the person who eats a bunch of burgers
2280000	2283000	and has a heart attack and dies instantly, or the person who lives into old age
2283000	2286000	and therefore has some kind of long-term health problem like Alzheimer's.
2286000	2288000	I need to, I need to interject here.
2288000	2294000	So you ring me probably three years ago, four years ago, you ring me and I'm in the gym.
2294000	2297000	And you say something like, what are you doing?
2297000	2298000	So I come in the gym.
2298000	2299000	What are you doing?
2299000	2300000	Oh, just whatever.
2300000	2301000	Whatever.
2301000	2302000	Catch up a little bit.
2302000	2303000	I was like, what's going on?
2303000	2307000	And you said, I'm trying nihilism.
2307000	2310000	And I said, what do you mean?
2310000	2314000	And you went, as a life philosophy, I'm trying nihilism.
2314000	2316000	And I still don't know what you mean.
2316000	2323000	So how is your experiment to make nihilism great again going?
2323000	2329000	Well, I was getting a bit fed up of people saying, oh, you're a nihilist.
2329000	2330000	Oh, you're an atheist.
2330000	2331000	They wouldn't say it in the terms of nihilism.
2331000	2333000	They'd say, oh, you're an atheist.
2333000	2334000	Yeah, right.
2334000	2335000	Yeah.
2335000	2341000	I mean, there was a cliff of Jordan Peterson on the Lex Friedman podcast.
2341000	2346000	And he says, oh, you're secular and you go to art galleries.
2346000	2347000	Yeah.
2347000	2349000	Well, what makes you think you're secular?
2349000	2350000	And the head turn is real.
2350000	2351000	He does that.
2351000	2356000	I thought to myself, what on earth are you talking about, man?
2356000	2358000	Do you think you can't be an atheist and enjoy art?
2358000	2360000	Now, I tried my best to understand what he was getting at.
2360000	2365000	And I think he was trying to basically say that in order to enjoy art,
2365000	2367000	you need to have some kind of value.
2367000	2370000	And in order to have any kind of surface level value,
2370000	2372000	you can always ask the why that question.
2372000	2374000	Why do you value this?
2374000	2378000	The classic sort of why do you go to school to get a good grade?
2378000	2379000	Well, you don't just want the grade.
2379000	2380000	Why do you get the grade?
2380000	2382000	You do it to get a good job and so on and so forth.
2382000	2383000	Happens with value.
2383000	2385000	And so why do you value art?
2385000	2387000	Because maybe you value beauty or something.
2387000	2390000	And Peterson's whole thing is that whatever's at the top of this value hierarchy
2390000	2392000	is in his definition divine.
2392000	2394000	He just defines it as such.
2394000	2399000	And so he essentially said that people claim that they are nihilists,
2399000	2401000	but they don't live like that.
2401000	2403000	I thought, well, what would it mean to really live like a nihilist?
2403000	2406000	And I guess I tried it on for size,
2406000	2412000	but he's right into the extent that I think most people don't live like they're nihilists.
2412000	2415000	What would the definition of living like a nihilist be?
2415000	2422000	I think it would just mean the rejection of any such thing as a non-contingent reason for acting.
2422000	2424000	Be more accessible.
2424000	2431000	You would need to really think that there's no reason to do anything
2431000	2435000	outside of essentially your crude preferences in biological drives.
2435000	2436000	Right.
2436000	2442000	And I think the reason why people think that nihilism is unlivable
2442000	2447000	is because they have this image of somebody just immediately becoming a Raskolnikov type figure
2447000	2449000	and just committing a murder or something.
2449000	2452000	But they forget that these people still have their memory.
2452000	2455000	They're going to be embedded in a culture and an upbringing
2455000	2458000	that their preferences are essentially still going to be aligned.
2458000	2461000	I mean, Pendulet was once asked, if you're an atheist,
2461000	2466000	why don't you kill and assault every person you want to?
2466000	2470000	And he says, I do, I do kill and assault everybody I want to,
2470000	2472000	which is precisely nobody.
2472000	2475000	And very clever, gets a bit of an applause.
2475000	2479000	But I mean, the difficult question ethically is what happens when somebody doesn't have that view?
2479000	2481000	What happens when somebody does just disagree with you?
2481000	2483000	But I don't know, it was kind of boring.
2483000	2490000	Just to interject that, so you could see the meaning-making machine of society and cultural norms
2490000	2495000	as being useful to constrain the behavior of those outlier people,
2495000	2499000	the ones who would go out and commit the litany of mass murders.
2499000	2504000	But mum told me that I'm not supposed to squash bugs when I was five years old
2504000	2506000	and this is now carried on through.
2506000	2511000	But yeah, I think for most people, we are the descendants of the people who avoided,
2511000	2514000	at least for the most part, killing people that were close to us.
2514000	2517000	And we feel a lot of the time like we're now close to each other.
2517000	2520000	Yes, yes.
2520000	2522000	I think that's probably true.
2522000	2528000	The issue is that the more that we try to explain away these mechanisms,
2529000	2536000	we try to understand why in our evolutionary history we might have evolved certain moral taboos,
2536000	2538000	this kind of stuff.
2538000	2541000	It begins to essentially take the complete ethical force out of it
2541000	2544000	and that's what people think leads to leads to nihilism.
2544000	2549000	Once you have fully explained why something would be considered immoral,
2549000	2554000	just on evolutionary grounds, you've essentially taken out the moral factor altogether
2554000	2557000	and you're explaining it in terms of genetic preference.
2557000	2559000	Yeah, there's no more meaning.
2559000	2563000	There's no additional fluff or feeling of anything.
2563000	2566000	But this is, you know, I've spent a lot of time over the last few years
2566000	2569000	talking to evolutionary psychologists, evolutionary biologists,
2569000	2574000	people that have looked at the evolution of culture as well from a mimetic standpoint too.
2574000	2586000	And it does seem to me that culture is just like exclusively an adaptive response to coordination at large scale
2586000	2593000	and that all of the things that are encoded in that are effective ways for your tribe to not blow itself up.
2593000	2595000	Would you say the same thing about morality in general?
2595000	2596000	Yes.
2596000	2602000	So then how do you escape this nihilist conundrum that you think all it is,
2602000	2607000	you know, the reason why you're not killing people is just because you sort of evolved that way.
2607000	2609000	Doesn't that kind of take out some of the meaning?
2609000	2618000	So I think if you are permanently self-assessing why you do the things you do and the inputs that you feel,
2618000	2623000	but what that doesn't account for is the fact that we are self-deceptive.
2623000	2624000	Quite right, yeah.
2624000	2628000	And the sense of being a human is one that is imbued with meaning.
2628000	2634000	I often use this term about how you are not personally cursed as a reassurance.
2634000	2636000	And it was something that was reassuring to me.
2636000	2640000	If I was spending a bit of time where I was feeling sad or down or whatever,
2640000	2643000	it would feel like whatever emotion I was going through,
2643000	2646000	whatever unpleasant emotion I was going through was like a personal curse.
2646000	2651000	And this makes sense when you look back at how the gods were personified as different sorts of emotions, right?
2651000	2658000	That, you know, keep it had an arrow that hit you or that, you know, you had gods of war, you had gods of wrath,
2658000	2660000	you had gods of envy, you had gods of narcissism.
2660000	2670000	Because the experience of a thing, of a thought, of an emotion, of a state is not just the confused chemical signals of your body.
2670000	2672000	And now I can just reverse engineer this.
2672000	2679000	Even the interest, the interaction of you and whatever's going on in the social group around you isn't just that.
2679000	2684000	It's imbued with meaning because you interpret things in this soup of experience,
2684000	2688000	which scales things up from just what's happening to,
2688000	2692000	and it feels like there's something, it feels like there's some there, there, right?
2692000	2696000	Yes. Yeah, yeah, you can't escape that illusion if it is an illusion.
2696000	2702000	This is another thing that I spoke to Ben about first name, first name basis it seems now.
2702000	2703000	Mr. Shapiro.
2703000	2704000	I did try that.
2704000	2708000	And, you know, when I was emailing back and forth about setting up that event,
2708000	2714000	I went to type out sort of like, well, it would be great to talk to Mr. Shapiro about, it just didn't feel right.
2714000	2716000	I just couldn't bring myself to do it.
2716000	2719000	At least not behind his back, not say that I'm rude behind his back,
2719000	2722000	but it felt even weirder that he wasn't there to sort of appreciate the courtesy.
2722000	2728000	Anyway, he said, like, you know, that I don't believe in free will.
2728000	2730000	I don't know if you believe in free will, perhaps we can talk about that.
2730000	2735000	He's like, look, you don't believe in free will, but you act as if free will does exist all the time.
2735000	2739000	And I remember thinking, what do you mean?
2739000	2744000	What does it look like to act as though free will doesn't exist?
2744000	2752000	The very argument or one of the arguments against free will is that you are essentially driven by your biology,
2752000	2757000	your genes, your will, you know, the Arthur Schopenhauer line that you can do what you will.
2757000	2759000	You just can't will what you will.
2759000	2760000	In fact, you have to do what you will.
2760000	2763000	That's what drives behavior.
2763000	2770000	If that's the case, then why do you have this vision in your head that if you lack a belief in free will,
2770000	2772000	you're like not going to get out of bed in the morning.
2772000	2776000	The very argument is that you will get out of bed in the morning because you desire to go and get some breakfast.
2776000	2778000	That's like the whole point.
2778000	2782000	And so any argument of that form of people say, well, you don't live like that's the case.
2782000	2786000	I was like to think, well, what would it look like to you then?
2786000	2792000	You know, if I could ask Jordan Peterson when he says the way you don't live like an atheist, what would that look like to you?
2792000	2800000	I don't know if he might say something like, well, you'd probably be this morally depraved, you know, self-interested, blah, blah, blah.
2800000	2802000	Like maybe, but is that really what you think?
2802000	2803000	I mean, I don't know.
2803000	2811000	Yeah, I think it forgets the fact that you are a product of your time, regardless of your beliefs from that time.
2811000	2812000	Right?
2812000	2818000	I understand the Judeo-Christian values that everything is based on, you know, it's like a common talking point from those guys.
2818000	2828000	But okay, how am I supposed to extricate me from that completely shake the etch-a-sketch of my value set and then take it from the beginning?
2828000	2834000	And let's not forget, like a lot of those values have grown out of what would have been an adaptive response in any case.
2834000	2835000	Yeah.
2835000	2837000	So the illusion is there.
2837000	2838000	The illusion is unshakable.
2838000	2843000	And so it sort of is a bit senseless to me to us, particularly on the free will thing.
2843000	2846000	Like, oh, why don't you act like free will doesn't exist?
2846000	2848000	What do you mean?
2848000	2850000	I literally, it's unintelligible to me.
2850000	2852000	Did you listen to my Sapolsky episode yet?
2852000	2853000	No, I didn't think so.
2853000	2857000	So his new book determined the science of life without free will.
2858000	2861000	Every time that I talk about free will, people get upset.
2861000	2862000	Why is that?
2862000	2864000	That's the question for you.
2864000	2865000	I think the reason-
2865000	2867000	Insert joke about how it's not their fault.
2867000	2868000	Yeah, yeah.
2868000	2873000	It's like my least favorite genre of joke that's done in philosophy.
2873000	2874000	Every single time.
2874000	2875000	Every single time.
2875000	2876000	Without fail.
2877000	2878000	I don't know.
2878000	2879000	I don't know.
2879000	2886000	And it's something that the conversation about free will is such a turn off for people that I actively push it further into episodes.
2886000	2890000	I actively don't title episodes that have got that in it.
2890000	2896000	I can surreptitiously coax people into thinking about it.
2896000	2903000	But the response is very, it's a high amount of dissatisfaction.
2903000	2905000	People don't like to think about that.
2905000	2909000	Now, it may be because it's dry.
2909000	2911000	I'm open to that.
2911000	2912000	That's true.
2912000	2917000	It may be because it threatens their sense of agency and sovereignty,
2917000	2920000	which is something I've kind of built this channel off the back of,
2920000	2925000	like you can enact change within your own life, internalize your locus of control,
2925000	2927000	stop being such a bitch, etc.
2927000	2936000	And so maybe I'm a victim of my own foundation in that regard that I've selected for a particular group of people.
2936000	2938000	But it's happened a few times.
2938000	2941000	A few different conversations about it, tangential.
2942000	2946000	One guy was a compatibility like quasi-compatibilist.
2946000	2949000	Why are you shaking your head?
2951000	2955000	That it's just the most ludicrous compromise to me.
2955000	2956000	Compatibilism.
2956000	2960000	Am I right in saying that compatibilism just kicks the can down the road
2960000	2962000	and plays lexical overload with things?
2962000	2963000	I think more or less.
2963000	2964000	Right.
2964000	2967000	A lot of the time you're just also dealing with essentially a redefinition of free will.
2967000	2968000	It's water.
2968000	2969000	I don't mean that.
2969000	2970000	I mean this thing.
2970000	2974000	Yeah, Sam Harris has called it the Atlantis fallacy.
2974000	2978000	He had an extended argument with Daniel Dennett, a compatibilist about free will.
2978000	2983000	And Daniel Dennett would talk about how this exists and this exists.
2983000	2986000	And it sounds like, yeah, that's true.
2986000	2989000	But you're just not talking about what people care about in free will.
2989000	2992000	What you're doing is we're trying to ask if Atlantis exists.
2992000	2995000	And you're pointing to Venice and you're saying, look, here's the city.
2995000	2999000	It's got a lot of water and it's kind of old.
2999000	3003000	And these are all true, but it's just not Atlantis.
3003000	3008000	And what most people are talking about when they try to bring free will back into the discussion is just not free will.
3008000	3010000	It's as straightforward as it gets in my view.
3010000	3015000	I mean, there are versions of freedom that can be sensibly believed in.
3015000	3019000	It kind of depends on what your conception of freedom means.
3019000	3021000	But if you mean something like authorship over your actions,
3021000	3024000	if you mean that we could have rewound the clock and I could have done something differently,
3024000	3026000	but I could have won a different shirt.
3026000	3029000	I don't think that the answer is yes.
3029000	3030000	Logically, yes.
3030000	3031000	You know, the possible worlds discussion earlier.
3031000	3033000	There's a possible world where I'm in a different shirt,
3033000	3038000	but I guess like physically, possibly metaphysically,
3038000	3039000	I couldn't have made a different choice.
3039000	3045000	Well, regardless of what you believe or don't believe about free will,
3045000	3048000	the response, people's response to it is fascinating.
3048000	3050000	Absolutely fascinating.
3050000	3055000	And maybe, yeah, maybe it is that degree of control, almost like the denial of death.
3055000	3061000	Like I wonder, have they done experiments on when people are reminded that they do
3061000	3063000	or do not have free will that their behavior adjusts?
3063000	3066000	Not that I know of, but I would love to see that because if it is,
3066000	3069000	and maybe it is true, but I think if it is true,
3069000	3072000	I can understand why it might be quite like fatalistic.
3072000	3076000	I mean, it literally is quite fatalistic really to say that there's no freedom.
3076000	3079000	And I can understand why that might make someone sad
3079000	3082000	and that sadness might motivate their behaviors slightly differently.
3082000	3086000	But I think that intrinsically, if there are a way to control for people
3086000	3088000	who are sort of happy or sad about it,
3088000	3090000	because you can believe in there's no free will and be like,
3090000	3092000	thank goodness, it's all out of my hands.
3092000	3097000	If you can control for that and show that people do, they are like less productive
3097000	3099000	or they don't get out of bed as much,
3099000	3101000	then I think that would be meaningful
3101000	3104000	and it might be a sort of second order reason not to have this conversation.
3104000	3109000	I don't know if there's been such a investigation as there has to death,
3109000	3113000	which by the way, I think a good example of the death denial thing
3113000	3118000	is to think about your magnum opus
3118000	3123000	if you were sort of working on the great life work or something
3123000	3128000	and you're about to die and then you're just about to sort of to finish it off.
3128000	3132000	Suppose you found out that after you publish this and you die,
3132000	3136000	a week later you found out that a meteor was going to come and destroy the earth.
3136000	3138000	Everybody dies.
3138000	3142000	Does that make you more or less enthusiastic about finishing your project?
3142000	3147000	Now, for most people, I think, it's going to make them less enthusiastic.
3147000	3149000	It would certainly make me less enthusiastic.
3149000	3151000	But why? What's the difference to you?
3151000	3152000	It doesn't make a difference.
3152000	3155000	You're going to be dead beforehand anyway, nothing's going to change.
3155000	3160000	Seems to suggest that maybe the desire to get this done
3160000	3163000	before you die in the first place isn't just as people like to claim
3163000	3166000	for the love of the art and it's all in the process.
3166000	3168000	No, it's because here's a work that's going to outlive you.
3168000	3170000	Here's something that's going to help you to escape your own death.
3170000	3174000	And when faced with the inevitability of the destruction of even that,
3174000	3175000	the motivation goes down.
3175000	3179000	I wouldn't be surprised if simply reminding somebody who's writing a play or something
3179000	3185000	that one day, heat death, everything evaporates including your new book
3185000	3188000	if that would make them less motivated to finish the book.
3188000	3192000	Which to me implies that the reverse corollary
3192000	3195000	is that the reason you are making the book is in some way indebted
3195000	3198000	to the fact that you think it will outlive you and therefore is an exercise
3198000	3199000	in the denial of death.
3199000	3202000	Didn't Ernest Becker die at an unfortunate time?
3202000	3204000	I don't know much about his personal life.
3204000	3205000	I think he did.
3205000	3210000	But there are interesting coincidences like that dotted across a lot of...
3210000	3215000	The thing about coincidences is that so many things happen all the time
3215000	3219000	that the only extraordinary thing would be if there weren't some extraordinary things like that.
3219000	3222000	Like Al Becker Mew was killed in a car crash
3222000	3225000	and he was killed in a car crash with a train ticket in his pocket.
3225000	3228000	So it seemed like he decided at the last minute to go in the car and said,
3228000	3233000	and he had previously said that the most absurd way to die would be in an automobile accident.
3233000	3235000	And that's how he dies.
3235000	3239000	Sigmund Freud was terrified of...
3239000	3242000	I think it was the number 63.
3242000	3243000	It was like 63.
3243000	3245000	Or maybe it was like 48.
3245000	3246000	I can't remember.
3246000	3247000	A number around that.
3247000	3248000	He was just terrified of it.
3248000	3252000	Had a real sort of foreboding about it for some reason.
3252000	3257000	He got a phone number that ended in that number and it freaked him out.
3257000	3263000	He got a hotel room that had that number and he just became convinced that he was going to die at that age.
3263000	3265000	Guess when he died?
3265000	3266000	48.
3266000	3267000	No, when he was like 80.
3267000	3269000	Sometimes it goes wrong.
3269000	3270000	You're a dick.
3270000	3272000	You are a dick.
3272000	3273000	The rest of that was true though.
3273000	3274000	All right.
3274000	3276000	What's your sexy paradox that you wanted to show me?
3276000	3277000	Yes.
3277000	3278000	Get your paradox out of the land.
3278000	3280000	Think about this, right?
3280000	3286000	Now, I can't remember what the source is and I want to attribute the person who does it.
3286000	3287000	Maybe I can find it.
3287000	3288000	Yeah, get it.
3288000	3291000	Let me find it because I want to make sure that they get the credit for it.
3291000	3302000	I was told about it by a friend and you have to give me a minute because I don't want to pass this off as my own.
3302000	3305000	What do you do with everything else?
3305000	3307000	I think it's called the anthropic.
3307000	3315000	So it's a website called risingentropy.com is seemingly the origin of this paradox,
3315000	3321000	but I was told about it by a friend and it's, I guess, okay, so imagine that,
3321000	3328000	and what this does is it shows us that different ways of thinking give us wildly different answers to the same problem,
3328000	3330000	different ways of looking at a problem.
3330000	3340000	So imagine that there's a maniac who, and it's called the anthropic dice killer if you want to look it up.
3340000	3344000	There's a maniac who is kidnapping people and murdering them.
3344000	3350000	And what he does is he kidnaps one person and he blindfolds them and he rolls a dice.
3350000	3355000	And if that dice is a six, then he'll kill you.
3355000	3357000	If not, he'll let you go free.
3357000	3363000	And what he'll do if he lets you go free is he'll go and pick up two people, kidnap them, blindfold them,
3363000	3364000	roll the dice.
3364000	3365000	If it's a six, kills you.
3365000	3367000	If it's anything else, go free.
3367000	3368000	Then it's four people.
3368000	3371000	Then it's eight people and it doubles.
3371000	3372000	So it's an exponential.
3372000	3373000	Until he hits a six.
3373000	3374000	Until he hits a six.
3374000	3381000	Now, you wake up knowing all this information, you wake up blindfolded and you know these facts
3381000	3385000	and you know that a dice is about to be rolled, but you're blindfolded.
3385000	3387000	You don't know how many people are there with you.
3387000	3396000	You're given a button that you can press that will make the chances that you're killed half, one and two.
3396000	3400000	So if you want to, you can press this button and a 50% of the time it will just kill you immediately
3400000	3402000	and 50% of the time you'll get to go free.
3402000	3404000	Or you can let him roll the dice.
3404000	3405000	What do you do?
3405000	3407000	Do you press the button or not?
3407000	3414000	So at least on the surface, this is to do with the probability of one in six versus one in two.
3414000	3418000	There is this escalating thing that's happening in the background.
3418000	3428000	So I would presume that you would say, don't hit the button because that has increased the chance of you being killed from one in six to one in two.
3428000	3429000	Right.
3429000	3430000	And this seems true.
3430000	3434000	And it is true that, yeah, I mean, like you've got a one in six chance of dying.
3434000	3436000	And if you press the button, you've got a one in two.
3436000	3438000	So you're better at rolling the dice.
3438000	3449000	But if you think about it as one big block, then something very strange happens because if you consider all of the people involved,
3449000	3458000	if all you know is that you've woken up and you're somewhere in this process, then interestingly,
3458000	3466000	say it gets to number two, it gets to round two, then there have been three people involved, three victims involved.
3467000	3472000	And two of them end up dying and one of them goes free.
3472000	3480000	So if you find yourself in this situation as a victim, you've got a more than half probability that you're in the second group that ends up dying.
3480000	3484000	I suppose that actually it ends in the third group.
3484000	3485000	Right.
3485000	3486000	Now there are how many people involved?
3486000	3488000	You've got one than two.
3488000	3489000	Then four.
3489000	3490000	Then four.
3490000	3493000	So we've now got seven people involved.
3493000	3494000	Right.
3494000	3496000	Four people end up dying.
3496000	3504000	And so if you sort of wake up in this scenario, you've got a four in seven chance that you're going to die,
3504000	3507000	that you're going to be one of the people who dies, which is more than half.
3507000	3513000	And this continues such that if you consider the fact that it doesn't matter where it ends,
3513000	3521000	you're always going to have a slightly higher than half chance that you're in the group that ends up getting killed.
3522000	3530000	But is it more than half given that each round of the dice roll is only one in six?
3530000	3536000	Yeah, because it's about like if in fact it gets to number three.
3536000	3537000	Right.
3537000	3544000	Like you know that you're going to be in the group that dies.
3544000	3549000	If it in fact gets to number two, then there's a more than half chance that you're going to die.
3550000	3551000	So I'm going to hit the button.
3551000	3552000	Is that right?
3552000	3553000	Well, maybe.
3553000	3555000	I mean, it seems ludicrous to hit the button, but thinking about it this way,
3555000	3556000	it seems like that's what you should actually do.
3556000	3560000	It's simultaneously the case that you have got a one in six chance of dying
3560000	3563000	because you're doing it on the roll of a dice.
3563000	3568000	But at the same time, if you think about the fact that one of these groups is going to end up dying
3568000	3575000	and it doesn't matter where it ends, the chances of you being in that group are always going to be slightly higher than half.
3575000	3576000	Right.
3576000	3578000	From a population level.
3578000	3582000	The anthropic dice killer because it is the anthropic principle is thinking about.
3582000	3583000	Yeah.
3583000	3584000	What's that?
3585000	3591000	I once read a sci-fi book that was there was a threat of the end of the world.
3591000	3594000	They were looking to get humanity off the planet.
3594000	3606000	And there is a theory that uses almost this exact same idea which says that if you take the entirety of human history
3606000	3613000	and you were to pick a time at which you were to live and you have this rapid increase toward humanity,
3613000	3621000	it works out that it's more likely that you are within some percent of the end of humanity.
3621000	3622000	Right.
3622000	3623000	Yeah.
3623000	3625000	Because of the exponential growth.
3625000	3626000	Precisely.
3626000	3627000	Exactly.
3627000	3628000	Are you familiar with this idea?
3628000	3629000	I don't think so.
3629000	3630000	Right.
3630000	3631000	But it's fascinating.
3631000	3632000	It works the exact same.
3632000	3636000	If that graph is going up at the requisite speed, then yeah.
3636000	3637000	Right.
3637000	3638000	And this is the exact same thing.
3638000	3641000	I mean, the version on the website actually involves snake eyes.
3641000	3642000	So it's two dice.
3642000	3647000	And instead of it being one, then two, then four, it's one, then ten, then a hundred, then a thousand.
3647000	3648000	Right.
3648000	3649000	So it ramps up more quickly.
3649000	3650000	And now you're rolling snake eyes.
3650000	3652000	So it's a one in 36 chance.
3652000	3658000	And it turns out that if you add up the probability of like N number of cases,
3658000	3663000	it's something like 90% chance versus the half that you get to press,
3663000	3664000	which just seems ludicrous.
3664000	3666000	And it seems that two things are true at once,
3666000	3668000	depending on just how you look at the problem.
3668000	3670000	So sometimes problems like this are just to do with the way you word them.
3670000	3672000	I mean, there are tons of like these sort of interesting math paradoxes,
3672000	3674000	which aren't paradoxes at all.
3674000	3676000	You must be familiar with the man who walks into the hotel,
3676000	3678000	pays 30 pounds, goes up to his room,
3678000	3683000	and the guy behind the bar says,
3683000	3685000	the manager says,
3685000	3687000	oh, no, he should have only paid 25.
3687000	3688000	We've got a deal on.
3688000	3689000	So he calls the bell boy and says,
3689000	3692000	can you go and give him five pounds back to the man in the room?
3692000	3694000	And the bell boy thinks to himself on the way up,
3694000	3695000	like this guy doesn't know any better.
3695000	3696000	He doesn't know how much he owed.
3696000	3698000	I'm going to pocket three pounds for myself.
3698000	3700000	I'm only going to give him two pounds.
3700000	3701000	So he goes back to the room.
3701000	3702000	He says, excuse me, sir.
3702000	3704000	Sorry, you paid, you know, you paid 30 pounds.
3704000	3705000	You paid too much.
3705000	3706000	Here's two pounds change.
3706000	3709000	So how much has the man now paid?
3709000	3711000	25 pounds.
3711000	3712000	No, 28 pounds.
3712000	3713000	28 pounds.
3713000	3715000	And how much has the bell boy got in his pocket?
3715000	3716000	Two.
3716000	3719000	He gave the guy two pounds back.
3719000	3720000	Right.
3720000	3722000	Where's that money come from?
3722000	3723000	Yeah, he's got three.
3723000	3726000	So the bell boy, so the man's now only paid 28 pounds.
3726000	3727000	He's paid 30 pounds.
3727000	3728000	He gets two pounds back from the bell boy.
3728000	3729000	Yeah.
3729000	3730000	He's got, he's paid 28 pounds.
3730000	3733000	The bell boy's got three pounds in his pocket,
3733000	3735000	which makes 31.
3735000	3737000	So where's the extra pound come from?
3737000	3738000	Actually, no, he hasn't.
3738000	3742000	The guy paid 25 plus now he's got two back.
3742000	3743000	That's right.
3743000	3745000	So it's the way you word it, right?
3745000	3747000	So this like stumps people.
3747000	3749000	And you can do it the other way around as well.
3749000	3752000	You can say that the guy goes up and he gives,
3752000	3754000	the bell boy gives three pounds back to the guy.
3754000	3756000	So he's only paid 27 pounds,
3756000	3758000	but the bell boy's got two pounds.
3758000	3759000	And it's only 29.
3759000	3761000	And this, you know, it sort of goes viral on social media
3761000	3763000	because people are like, how the hell does it work?
3763000	3767000	It's the blue and black or green and gold dress.
3767000	3769000	It's like, I mean, for those that, yeah, I guess there is,
3769000	3771000	it's like those in that there is a real answer
3771000	3773000	to what the actual war is actually going on there.
3773000	3776000	It leads people based on how you word it.
3776000	3778000	It's how people, you know, shortchange it
3778000	3781000	when they scan people at a bar or something.
3781000	3784000	I mean, the easiest way to visualise that particular problem
3784000	3787000	is to imagine that the man was only supposed to pay two pounds.
3787000	3789000	You know, so the bell boy goes up and gives him 28.
3789000	3791000	He's supposed to give him 28 pounds
3791000	3793000	and decides to pocket two pounds for himself.
3793000	3796000	So he gives him, you know, gives him 26 pounds back.
3796000	3798000	So how much is the man paid, like four pounds
3798000	3802000	and how much the bell boy got, like 26 pounds,
3802000	3803000	which is ludicrous.
3803000	3807000	But you'd be amazed at how easily people can be
3807000	3809000	completely nicely stumped by it.
3809000	3811000	And it's all in the, it's all in the wording.
3811000	3813000	So a problem like the anthropic dice killer,
3813000	3816000	I wonder how much it's just sort of to do with the way
3816000	3818000	that you describe it, you know.
3818000	3821000	Have there been any paradoxes
3821000	3825000	that sent you into a fugue state for a little while?
3825000	3828000	Was there anything that captured a particularly long amount of time
3828000	3831000	that you sort of couldn't stop considering?
3836000	3838000	Most of the famous ones since,
3838000	3840000	since I first started learning about paradoxes,
3840000	3842000	like the famous Monty Hall problem,
3842000	3845000	that obsessed me for, well, I wouldn't say obsessed me,
3845000	3847000	but I was sort of blown away by it.
3847000	3849000	There's also, you know the Monty Hall problem.
3849000	3851000	You'll definitely have heard of this before.
3851000	3856000	This, it's the game show and the three doors.
3856000	3857000	Right. Yeah.
3857000	3859000	You know what I'm talking about.
3859000	3861000	There are interesting paradoxes that aren't actually paradoxes.
3861000	3864000	There's a book by Jim Alcalely called Paradox,
3864000	3868000	which is a description of so-called paradoxes.
3868000	3873000	So like, I think, I think all this paradox is,
3873000	3877000	when people used to think that the universe was infinite,
3877000	3879000	infinitely large, I mean,
3879000	3883000	there was this problem that if empty space is filled up
3883000	3885000	fairly randomly with stars,
3885000	3887000	I mean, we know there's a lot of stars in the sky
3887000	3890000	and galaxies and objects that emit light,
3890000	3895000	then there should essentially be no darkness in the sky.
3895000	3898000	The sky should look kind of like an overcast day
3898000	3903000	because like the gaps in the sky, you know,
3903000	3905000	are all eventually going to be filled up
3905000	3907000	and any amount, any small gap,
3907000	3909000	you might think the stars are really far away.
3909000	3911000	They'll also be like closer together,
3911000	3913000	therefore emitting more light visually and they'll be bigger.
3913000	3915000	And so if the universe is infinite,
3915000	3917000	you should just see a sort of overcast day.
3917000	3918000	And it was a paradox.
3918000	3921000	It was like, how does this happen?
3921000	3923000	And it basically became an interesting proof
3923000	3925000	that the universe has a beginning,
3925000	3927000	that the universe is not in fact infinite,
3927000	3929000	just the fact that it gets dark at night
3929000	3931000	because if it were actually infinite,
3931000	3935000	there should be a sort of overcast view,
3935000	3937000	Alba's paradox.
3937000	3938000	And like I say, it's sort of a paradox,
3938000	3940000	but not really a paradox.
3940000	3942000	Are you familiar with the Buete's Void?
3942000	3943000	Do you know this? I think so.
3943000	3945000	This is like my favorite part of the universe.
3945000	3946000	I'd say like I'm mapping it,
3946000	3950000	like my favorite barbecue restaurants in Austin.
3950000	3954000	And it's a huge, what's referred to as a super void,
3954000	3956000	which is a period of the universe,
3956000	3960000	an area of the universe which has way fewer galaxies
3960000	3962000	than you would anticipate.
3962000	3965000	And given what's the principle of like,
3965000	3968000	homogeneity across the universe that it should be,
3968000	3970000	it should be relatively similar, right?
3970000	3971000	Like thermodynamics.
3971000	3972000	Yes.
3972000	3974000	Entropy and...
3974000	3977000	Now you're just saying the space words at me.
3977000	3980000	Well, you know, like when you spray in aerosol can,
3980000	3981000	it will eventually spread at the room.
3981000	3982000	Dispaces equally.
3982000	3987000	So the point is that there shouldn't be
3987000	3991000	huge fluctuations in the way that we see the universe.
3991000	3993000	Everything should be spread relatively evenly.
3993000	3997000	Now, I found out that supposedly at the point of the Big Bang,
3997000	4002000	there were one million particles of antimatter
4002000	4005000	and one million and one particles of matter.
4005000	4009000	And it is that one to one million and one ratio
4009000	4012000	that is exactly where everything that we see comes from.
4012000	4014000	And this minor imbalance is actually
4014000	4016000	what's permitted everything to exist.
4016000	4021000	But this particular Buete's B-O-O one with an umlaut T-E-S,
4021000	4023000	Buete's super void.
4023000	4025000	It's just super fucking interesting.
4025000	4028000	It's this gap where there's way fewer galaxies
4028000	4029000	than there should be.
4029000	4031000	Why should this exist?
4031000	4034000	Given that we've got this sort of principle of homogeneity
4034000	4035000	across the universe.
4035000	4038000	And that's one of my favorite things to like learn about.
4038000	4039000	Yeah.
4039000	4043000	But is it that we know about this void
4043000	4045000	because of the disbalance?
4045000	4047000	Or is it that we hypothesize the disbalance
4047000	4049000	because of the knowledge of the void?
4049000	4053000	We know based on mapping of, I think,
4053000	4056000	I'm not sure if it's telescopic or if it's microwave background stuff,
4056000	4057000	but we know that it's there.
4057000	4058000	Right.
4058000	4060000	And the question is, what the fuck is this thing doing there?
4060000	4061000	Yeah.
4061000	4063000	Well, that's a bit like sort of dark energy when we discover
4063000	4066000	that galaxies are spinning a little bit too quickly on the outside.
4066000	4068000	There seems to be something like pushing them along.
4068000	4072000	What do you make of the fine-tune universe idea?
4073000	4078000	A lot of people describe it as the most powerful argument for God's existence.
4078000	4081000	Christopher Hitchens in the back of a car once said
4081000	4083000	that that was really what gave him pause.
4083000	4086000	I don't find that it moves me very much.
4086000	4091000	I mean, it does seem quite extraordinary that had any of the constants
4091000	4094000	of the universe, the force of gravity, for example,
4094000	4099000	if it was stronger or weaker by the most unimaginably small amount,
4099000	4102000	then it would either be strong enough that the universe would collapse in on itself
4102000	4107000	or it would be so weak that atoms couldn't even form
4107000	4109000	or at least objects couldn't form
4109000	4112000	and everything just gets blown apart at the big bang.
4114000	4115000	Three explanations for this.
4115000	4119000	It's chance, it's necessity or it's design
4119000	4122000	and chances seems like a ludicrous suggestion.
4122000	4124000	I mean, there are lots of different constants
4124000	4127000	and it may be the case that we discover this sort of theory of everything
4127000	4128000	that reduces it down to one.
4128000	4133000	Still a huge mystery as to why it has the constant that it does
4133000	4138000	but would mean that we're not talking about lots of different constants in harmony.
4138000	4140000	Somehow happens to be unified in one way.
4140000	4143000	But the idea that it's necessarily being that way
4143000	4145000	doesn't seem that out of the question for me.
4147000	4150000	People put it in the language of saying that
4150000	4153000	had the constants been different by this amount,
4153000	4154000	the universe couldn't exist.
4154000	4160000	And what people often hear is the chances of the constant being as it was
4160000	4163000	was the same number, but I don't think that's the same thing.
4163000	4166000	It might just be not possible that it could have had a different value.
4166000	4171000	What's the observer selection effect of this?
4171000	4174000	This doesn't work for the fine-tuning argument, I think.
4174000	4178000	So the so-called like anthropic principle,
4178000	4181000	the universe seems designed for human life.
4182000	4184000	People might point to, for example,
4184000	4188000	the Earth's perfect distance from the Sun in the so-called Goldilocks zone
4188000	4191000	had it been a little bit further out or a little bit closer, humans couldn't exist.
4191000	4193000	And the easy answer to that is to say,
4193000	4194000	well, yeah, but if you didn't exist,
4194000	4197000	then you wouldn't be there to observe that it didn't exist, right?
4197000	4200000	And so you say, given the size of the universe,
4200000	4204000	life might develop somewhere, possibly in multiple places,
4204000	4208000	and the places where it's going to be observed coming about
4208000	4210000	is where it comes about, so no surprise.
4210000	4214000	That works there, but the fine-tuning concepts of the universe,
4214000	4218000	we're not talking about like,
4218000	4223000	we're not talking about like a potential billions of Earths
4223000	4225000	that could all give rise to human beings.
4225000	4227000	We're talking about if one of these constants was different,
4227000	4230000	by the tiniest amount, nothing exists.
4230000	4234000	And sure, it is still true that didn't not happen.
4234000	4236000	We wouldn't be here to observe it.
4236000	4239000	My friend Josh Perique has given me an example in the past of like,
4239000	4246000	I don't know, you can imagine like a series of highly trained knife throwers
4246000	4251000	just lobbed like 100,000 knives at you in an attempt to kill you,
4251000	4256000	and they all miss perfectly cutting out the silhouette of your body behind you,
4256000	4260000	absolutely perfectly, just like uncanny.
4260000	4262000	And someone says, well, they must have done that on purpose.
4262000	4263000	It's like a trick, right?
4263000	4265000	And you say, no, no, I think it's just happened by chance.
4265000	4266000	You say, well, that's ludicrous.
4266000	4267000	Oh, what if it didn't?
4267000	4270000	And I wouldn't be here to observe that it did, would I?
4270000	4274000	It still just wouldn't do it for you, even though that is true.
4274000	4276000	Had you been killed, you wouldn't be there to observe it.
4276000	4280000	It just seems such an unlikely coincidence that that just doesn't work
4280000	4284000	when we're talking about the actual fundamental stuff of the universe,
4284000	4285000	which is why people are so troubled by it.
4285000	4288000	But I do think, generally speaking, with all of these kinds of things,
4288000	4291000	fine-tuning, consciousness is another example
4291000	4294000	that's broadly in the scientific realm that people think,
4294000	4296000	like this just can't be explained to that reference to a God.
4296000	4297000	Maybe they're right.
4297000	4298000	I don't know.
4298000	4300000	But if you intuitively were to step into a time machine
4300000	4302000	and look at some people having this conversation,
4302000	4308000	and you said like, imagine them looking back and saying,
4308000	4309000	gosh, can you believe it?
4309000	4311000	They hadn't worked out fine-tuning yet.
4311000	4313000	They hadn't figured out the constants.
4313000	4316000	Oh, they hadn't figured out the science of consciousness yet.
4316000	4318000	I can conceive of that.
4318000	4321000	Just intuitively, I can see someone doing that.
4321000	4323000	But when I think about my arguments for atheism,
4323000	4326000	the problem of evil, divine hidden, this kind of stuff,
4326000	4329000	I can't imagine somebody looking through a time machine similarly
4329000	4331000	at a conversation that I have and going,
4331000	4332000	gosh, can you believe it?
4332000	4334000	They hadn't worked out the problem of evil yet.
4334000	4336000	They hadn't worked out divine hiddenness yet.
4336000	4337000	I think these are perennial problems.
4337000	4341000	So where you have these scientific arguments for the existence of God,
4341000	4344000	I guess I just have more of a trust that they will one day be explained
4344000	4349000	in a way that won't require recourse to a divine author
4349000	4355000	in a way that my criticisms of religion will probably not be similarly resolved.
4355000	4358000	We had a great conversation in Austin
4358000	4362000	as you explained to me about the potential historical accuracy
4362000	4366000	or inaccuracy of Jesus' resurrection.
4366000	4368000	Can you go through that a little bit?
4368000	4369000	Yeah.
4369000	4371000	I mean, this sometimes is used as an argument for the existence of God,
4371000	4373000	but I think more successfully is used
4373000	4375000	once you've already established the existence of God
4375000	4377000	to try to establish the truth of Christianity.
4377000	4384000	And that is a bunch of historical facts surrounding Jesus' alleged resurrection
4384000	4387000	that you sort of have to ask what the best explanation is for.
4387000	4389000	Now, you can't historically prove a resurrection,
4389000	4392000	but you can historically prove events
4392000	4396000	and then ask what the best explanation of those facts is.
4396000	4400000	So people will often point to the fact that there was a man called Jesus
4400000	4406000	walking around morally teaching people who was crucified by the Romans
4406000	4411000	and that a few days after his death was seen,
4411000	4416000	people made claims that they'd seen him after he'd died.
4416000	4418000	And the question is how do you explain these facts?
4418000	4422000	The gospel reliability is an interesting question in general
4422000	4424000	and people will often on the surface level say,
4424000	4426000	look, the Bible contradicts itself.
4426000	4428000	It's full of contradictions.
4428000	4432000	And there are some seeming contradictions in the gospel story,
4432000	4436000	but of course, what a lot of people neglect to consider
4436000	4439000	is that when we're talking about a text as a historical document,
4439000	4448000	contradictions shouldn't make us think that it's less accurate but more accurate.
4448000	4450000	If historical sources contradict each other,
4450000	4453000	that's evidence of their accuracy rather than evidence of the opposite.
4453000	4460000	Because if this is a mythical story that somebody's making up,
4460000	4465000	you would expect the details to concur.
4465000	4471000	That is, if you're questioning two suspects in some kind of murder trial or something
4471000	4477000	and their stories match up perfectly, like to the tea, the timings, everything,
4477000	4479000	it arouses suspicion.
4479000	4481000	It seems like somebody's inventing something.
4481000	4484000	Someone's coming up with a story here and trying to perfect it.
4484000	4486000	Now, people have this idea that a bunch of people got together
4486000	4492000	and tried to fool the world into this mythical story of this man rising from the dead.
4492000	4497000	Do you think they would have made the mistake of just including these blatant contradictions?
4497000	4498000	I don't know.
4498000	4500000	In other words, I think if somebody was making it up,
4500000	4502000	they probably would have taken more care.
4502000	4504000	Is there a term for this?
4504000	4505000	I'm sure there is.
4505000	4506000	I'm not a historian.
4506000	4508000	I couldn't tell you what it is.
4508000	4514000	But we do see contradictions on the minor points.
4514000	4517000	We don't really see much disagreement about the major points.
4517000	4519000	There is some enough disagreement, I think, to arouse suspicion.
4519000	4522000	I'm saying this as if I'm some kind of Christian or theist.
4522000	4528000	I put on that hat when I'm asked to have a conversation of this kind.
4528000	4533000	It does seem to me suspicious, for example, that the Gospel of Mark, which is the earliest Gospel,
4533000	4536000	contains no post-resurrection appearances.
4536000	4541000	Then the Gospel of Matthew does include post-resurrection appearances.
4541000	4543000	The Gospel of Luke includes even more.
4543000	4546000	It's only in the Gospel of John that we get, for instance, doubting Thomas,
4546000	4551000	which is the latest canonical Gospel, I should say.
4551000	4552000	That's where that arises.
4552000	4557000	In fact, the story of doubting Thomas famously, he doesn't believe that it's the risen Christ.
4557000	4559000	Jesus says, come and touch my wounds.
4559000	4564000	He touches his wounds and he says, my Lord and my God.
4564000	4569000	Jesus says, you believe because you've seen.
4569000	4572000	Blessed are those who believe without seeing.
4572000	4579000	In my view, what we have is this so-called mythological development of no post-resurrection appearances.
4579000	4585000	As the time goes on, as we get further away from the source, the stories get more fantastical,
4585000	4592000	ending in a moral lesson to believe without seeing.
4592000	4595000	This to me does seem a little bit suspicious.
4595000	4597000	It is a fascinating mystery.
4597000	4600000	Something very strange happened on Easter morning.
4601000	4606000	How do we explain the fact that this man gets crucified by the Romans
4606000	4611000	and then people claim to see him after he died and were willing to be put to death for that belief?
4611000	4613000	Maybe he didn't die.
4613000	4619000	Unlikely, as they say, the Romans knew how to kill people and supposedly they check
4619000	4629000	and they go to break the legs of the other prisoners as they're taking them down from their crosses.
4629000	4634000	They were taking them down temporarily and they hadn't died yet,
4634000	4637000	but when they go to break Jesus' legs, they realize he's already dead,
4637000	4643000	which is why his legs don't get broken and they stab him in the side with a stick to make sure that he's dead.
4643000	4646000	This was a very effective method of killing people and they knew how to do it,
4646000	4650000	so it's unlikely that he somehow survived this.
4650000	4654000	Is that the guy that stabbed him with the spear and supposedly this blood on the spear?
4654000	4658000	Yeah, someone stabbed him with the spear after he's on the cross.
4658000	4661000	And it's essentially to check he's dead.
4661000	4669000	Okay, so the likely hit is that he was actually crucified and then a few days later people are claiming to see him.
4669000	4675000	Maybe they're lying, but then you don't tend to go to death for something you know to be a lie.
4675000	4679000	You're willing to be put to death for things that you think are true that are false,
4679000	4683000	but very rarely are people willing to die for beliefs that they don't actually believe themselves.
4683000	4686000	That doesn't really happen, so they probably weren't lying.
4687000	4690000	Maybe they were mistaken, fooled.
4690000	4694000	Yeah, now I've known you since about 2019,
4694000	4701000	which is probably, it will have been slightly longer than Jesus was with his disciples,
4701000	4708000	but imagine spending every single day with this person, living with this person, eating with this person.
4708000	4711000	And then you've only seen him a few days ago.
4711000	4716000	And somehow, imagine somebody managed to convince you that they were me.
4716000	4720000	Even if I had a twin brother, they probably wouldn't be able to convince you that it was me.
4720000	4724000	Or maybe they were hallucinating in groups.
4724000	4732000	One of the earliest New Testament sources is the letters of Paul, the earliest.
4732000	4737000	And in one of those letters, Paul refers to Jesus having appeared to 500 people at once.
4737000	4741000	And in some of the Gospels, you get at least some group appearances, at least more than one person.
4741000	4746000	And sometimes groups of disciples, the 12, all seeing Jesus all at once.
4746000	4748000	You don't get group hallucinations like that.
4748000	4752000	And so it doesn't seem like they were mistaken either.
4752000	4755000	And so if they're not mistaken, they're not making it up.
4755000	4761000	What explains the fact that these people claim to see him after he had died?
4761000	4769000	And the Christian apologists will say that the only real plausible explanation is that he really did rise from the dead.
4769000	4773000	Now, it's an interesting argument and it's quite powerful.
4773000	4780000	However, my response has always been that this sort of process of elimination is very clever.
4780000	4782000	And that's how it's usually run.
4782000	4783000	But it can go the other way.
4783000	4787000	I mean, imagine I were trying to prove that there was such thing as a group hallucination.
4787000	4790000	I know it's extraordinary, but there was a group hallucination.
4790000	4793000	And I tried to prove it by saying, well, what are the other explanations?
4793000	4794000	Or maybe they lied.
4794000	4796000	Well, they wouldn't do that because they wouldn't go to death.
4796000	4799000	Or maybe a man rose from the dead, but come on, that doesn't happen.
4799000	4800000	That breaks all the laws of physics.
4800000	4802000	So the only remaining option is this.
4802000	4803000	Kind of depends where you start.
4803000	4804000	But it is weird.
4804000	4807000	Something very strange seems to have happened on that morning.
4807000	4812000	I can see why philosophers go mad.
4812000	4818000	Because you were able to simultaneously convince yourself of something and then convince yourself of the opposite
4818000	4820000	and convince yourself of everything that you've believed.
4820000	4823000	Yeah, but that's...
4823000	4828000	I think one of those famous quotes of Socrates is that the sign of wisdom in a man
4828000	4832000	or something is the ability to entertain a belief without holding it
4832000	4834000	or without becoming convinced by it or something like that.
4834000	4839000	And I think it's something anybody can do if they want to.
4839000	4841000	And it's why philosophers are so...
4841000	4843000	We think that philosophers are better at doing this.
4843000	4844000	I don't think that's true.
4844000	4849000	I think they're just talking about stuff that's far less political, far less real.
4849000	4851000	And so they're less likely to get...
4851000	4856000	They're less likely to be offended at the prospect of considering the falsehood of their beliefs.
4856000	4857000	Maybe.
4857000	4858000	Until you get into religion, I suppose.
4858000	4868000	You definitely seem to be able to have an ability to drop into and out of arguments on both sides of the same fence
4868000	4873000	and play with ideas in a way that I think is rare
4873000	4877000	and presumably a bit of a disposition but also largely trained
4877000	4883000	because you can sit and convince chat GPT that God exists
4883000	4886000	or try and turn me into a theist
4886000	4890000	and then stand on stage and do the exact opposite.
4890000	4892000	And just...
4892000	4897000	I think that there's probably quite a lot to learn from how people who have spent a good bit of time
4898000	4901000	playing with ideas in philosophy
4901000	4907000	dispassionately have that separation between themselves
4907000	4911000	and the idea and the belief and what it means to them and the emotion
4911000	4914000	and kind of that whole ambient mess.
4914000	4915000	Yeah.
4915000	4918000	It's playing is a good word because it's fun.
4918000	4919000	It's enjoyable.
4919000	4922000	That's why it's fun to talk about theory of knowledge
4922000	4924000	because who really cares?
4924000	4927000	It doesn't grow corn as they say
4927000	4930000	or make corn, however you are supposed to say it.
4930000	4935000	And that's fine because if it did, then it would certainly all get a bit serious
4935000	4938000	and it kind of really matters whether you get it right or wrong
4938000	4942000	whereas here we're just sort of having fun
4942000	4943000	but you can...
4943000	4944000	I don't know.
4944000	4947000	I can kind of see why heretics would get burnt at the stake
4947000	4949000	when religion had social power
4949000	4954000	because you become convinced that this is the source of meaning
4954000	4956000	this is the source of truth without it we are nothing.
4956000	4957000	It's now being threatened.
4957000	4960000	And then it turns out that maybe there are actually some holes to poke here
4960000	4961000	or what are you going to do?
4961000	4963000	I mean, you can't let them do that
4963000	4968000	because this is literally societally calamitous
4968000	4970000	and so they end up getting burnt at the stake.
4970000	4971000	That's what also annoys me.
4971000	4973000	I mean, you mentioned earlier this recent resurgence in the idea
4973000	4976000	that we're all sort of balancing on Judeo-Christian values
4977000	4979000	may be kind of true in a sense
4979000	4981000	but it does kind of get on my nerves
4981000	4982000	that after...
4982000	4984000	I said this to Ben yesterday
4984000	4988000	that the history of religious persecution
4988000	4990000	against the very developments
4990000	4993000	that those religious groups now like to claim as their own
4993000	4997000	I think the religion has shown to be wrong on a number of things
4997000	4999000	I listed them yesterday
4999000	5001000	the position of women in society
5001000	5003000	the fate of homosexuals
5003000	5005000	at least practicing homosexuals
5005000	5007000	the position of the earth in relation to the sun
5007000	5011000	the age of both of those celestial bodies
5011000	5015000	wrong about the common evolutionary ancestry of all animals
5015000	5017000	including the human animal
5017000	5020000	wrong about the ownership of other human beings as private property
5020000	5022000	as it's explicitly condoned not only in the Old Testament
5022000	5024000	but also in the new
5024000	5028000	and now not only does religion sort of...
5028000	5031000	I mean, religion fails to come to us with an apology
5031000	5033000	and contrition and say maybe we were wrong
5033000	5036000	it says, no, no, no, those things are ours all along
5036000	5038000	it says, yes
5038000	5042000	we may have shown the instruments of torture to Galileo
5042000	5044000	because he suggested that the earth might orbit the sun
5044000	5046000	rather than the other way around
5046000	5050000	but hey, didn't you know that the scientific revolution
5050000	5053000	is essentially Judeo-Christian in origin?
5053000	5057000	Yes, the Old Testament gives you explicit instructions
5057000	5060000	about exactly how to either buy or steal other human beings
5060000	5063000	and keep them sometimes as your sexual property
5063000	5066000	but don't you know that the abolitionist movement
5066000	5069000	is essentially Judeo-Christian in origin?
5069000	5072000	Yes, I know that St. Paul says that
5072000	5074000	man is the glory of God
5074000	5076000	but woman is the glory of man
5076000	5077000	and that I suffer not a woman to teach
5077000	5078000	nor to assert authority over a man
5078000	5080000	rather she should remain silent
5080000	5082000	for Adam was formed first then Eve
5082000	5084000	but don't you know that social justice movements
5084000	5087000	are essentially Judeo-Christian in origin?
5087000	5090000	Yes, we know about the stoning of homosexuals
5090000	5093000	and the fact that even St. Paul says
5093000	5094000	that they're not getting into heaven
5094000	5096000	but don't you know that the LGBT movement
5096000	5099000	is essentially sort of riding on Judeo-Christian principles?
5099000	5101000	It seems to me relatively offensive
5101000	5103000	to the people who've managed to secure these developments
5103000	5104000	against the very religious traditions
5104000	5106000	that now like to claim them as their own.
5106000	5109000	Yeah, both cause and effect
5109000	5112000	it's like being punched in the face by somebody
5112000	5115000	who then comes over and gives you a bandage for it.
5115000	5117000	I mean people like to refer to
5117000	5119000	and this is, I'm sort of rehashing some of the stuff
5119000	5121000	that I said yesterday here
5125000	5129000	people like to point out that the people
5129000	5133000	who really got the scientific revolution going
5133000	5135000	or often believe as in God,
5135000	5137000	Galileo believed in God, Newton believed in God
5137000	5139000	in fact Newton spent, but people were fascinated
5139000	5141000	to discover his diaries to find that he spent more time
5141000	5144000	writing about theology than science.
5144000	5146000	A mad man for the last 30 years doing alchemy, right?
5146000	5148000	Right, but here's the thing, right?
5148000	5152000	Like if, and as I said yesterday
5152000	5154000	I don't claim that this is the case
5154000	5158000	but if it were true that science had like undermined
5158000	5161000	religion and Christianity, if it were the case that
5161000	5163000	actually these things aren't compatible with each other
5163000	5165000	then when somebody says, well that can't be the case
5165000	5167000	because don't you know that the people who sort of founded
5167000	5168000	the scientific revolution were religious?
5168000	5169000	Well what else would they have been
5169000	5171000	if they hadn't yet invented the mechanism
5171000	5173000	by which their beliefs would come to be undermined?
5173000	5175000	It's like saying that it's amazing that the person
5175000	5179000	who invented the motor car didn't own a motor car beforehand.
5179000	5180000	You see what I'm saying?
5180000	5182000	It's sort of, I don't know, it seems very strange to me
5182000	5185000	and it's very recently that the popularity of this
5185000	5186000	has increased as you say.
5186000	5188000	I mean you go back to the mid-naughties
5188000	5190000	at the height of new atheism and it was very popular
5190000	5192000	to talk about how religions sort of always getting
5192000	5194000	in the way of science and maybe that was a bit crude
5194000	5198000	but I think we're seeing an equally crude annexation
5198000	5202000	of all of the beneficial social developments
5202000	5206000	of the past 100 years as somehow necessarily standing
5206000	5208000	upon the Judeo-Christian tradition
5208000	5210000	as if it couldn't have happened without them.
5210000	5215000	Is this a scrabbling for something to hold on to
5215000	5217000	given that the collapse of grand narratives
5217000	5220000	has had some poor externalities over the last couple of years?
5220000	5221000	Is it just mass cope?
5221000	5222000	I think so.
5222000	5225000	I think that nihilism as it were carries with it
5225000	5228000	the feeling of being naked.
5228000	5231000	You sort of thrown off what were essentially
5231000	5234000	optional clothes to reveal what was there all along
5234000	5239000	but when you actually face it to nature
5239000	5241000	it's embarrassing, it's scary
5241000	5243000	and you will do anything you can
5243000	5245000	if you find yourself naked in public
5245000	5248000	to find any clothes to put on, not just your old ones.
5248000	5249000	It doesn't matter what clothes.
5249000	5251000	Any clothes are better than no clothes
5251000	5253000	and this is what people are beginning to realize
5253000	5256000	and so they're scrambling for their old clothes again.
5256000	5258000	Trying to legitimate.
5258000	5263000	Yes, and trying to put them on
5263000	5265000	and that's why it's easy as well
5265000	5267000	for people to go around poking holes in other people's clothes.
5267000	5269000	It's very easy to do
5269000	5272000	but that's what the success of a movement like New Atheism
5272000	5274000	consists in the fact that all they had to do
5274000	5276000	was just tell other people why they're wrong.
5276000	5278000	You only need to poke holes in other people's clothes
5278000	5280000	but if you need to sew your own shirt
5280000	5282000	that gets a little more difficult.
5282000	5284000	Yes, Lewis said that the purpose of philosophy
5284000	5287000	is not the cutting down of forests
5287000	5289000	but the irrigation of deserts.
5290000	5291000	That's very interesting.
5291000	5293000	Yeah, I've thought about this for a good while.
5296000	5300000	The seductiveness of being critic
5300000	5303000	as opposed to being somebody that makes suggestions
5303000	5306000	and the lack of preparedness of anybody
5306000	5308000	to put forward any proposals for anything.
5308000	5310000	And it's easy for both sides
5310000	5312000	to accuse each other of being reactionary.
5312000	5314000	The reactionary right, the reactionary left.
5318000	5321000	For instance, a perfect example of this
5321000	5324000	is in the world of dating
5324000	5326000	and mate selection in the mating market
5326000	5329000	everybody can provide criticisms
5329000	5331000	about what's going wrong
5331000	5334000	and almost nobody provides any actionable steps to improve it
5334000	5337000	beyond something that is
5337000	5339000	illimitative rather than additive.
5339000	5342000	If we could just stop doing this
5342000	5344000	then this would be fixed.
5344000	5346000	I don't think that's quite the way that it works.
5346000	5349000	And there's another very unique protection mechanism
5349000	5351000	that's given which is
5351000	5354000	it's very hard to criticize someone's criticism
5354000	5358000	or at least being a critic
5358000	5360000	leaves you open to criticism
5360000	5363000	way less than being a proposer.
5363000	5365000	If I put something forward
5365000	5367000	if I posit a potential solution
5367000	5369000	for you to be able to come back and say
5369000	5371000	this is shit and this is shit and this is shit
5371000	5373000	it's very easy to do.
5373000	5375000	Whereas for you to say
5375000	5377000	for me to critic what you did
5377000	5379000	and then for you to come back and go
5379000	5381000	actually this and this and this
5381000	5383000	it gets all a little bit abstract
5383000	5385000	and it's a few degrees removed from anything that feels real.
5385000	5387000	Simon Cowell can't write a song.
5387000	5390000	If the world was full of Simon Cowell
5390000	5392000	we'd end up with no music.
5392000	5394000	Somebody's got to do the building here.
5394000	5396000	You can't just be a critic.
5396000	5398000	And this is what I think
5398000	5401000	has been the reason for the success
5401000	5403000	of the sort of anti-New Atheist stuff
5403000	5405000	that we've been seeing recently.
5405000	5406000	You'll have seen this.
5406000	5407000	Even the New Atheist themselves
5407000	5409000	sort of treat it like it's a dead animal
5409000	5410000	and in many ways it is
5410000	5412000	and I think it's got to do with the fact that
5412000	5414000	they've done a very good job
5414000	5417000	of cutting down the central pillar
5417000	5421000	of what has traditionally been
5421000	5423000	the reason for people getting out of bed
5423000	5424000	in the morning.
5424000	5426000	And then when people are there saying
5426000	5428000	well, what do we put in its place?
5428000	5430000	They're like, see ya.
5430000	5431000	You know, I'm out.
5431000	5433000	And they go off and do different things.
5433000	5435000	And what are people to do?
5435000	5436000	And that's why...
5436000	5437000	Was it the job of the New Atheists
5437000	5439000	to provide something to...
5439000	5441000	Well, maybe not.
5441000	5443000	Some people are just good at diagnosing problems.
5443000	5445000	Karl Marx is a good example.
5447000	5449000	Karl Marx's diagnoses
5449000	5452000	of the way the world works
5452000	5453000	are fascinating to read
5453000	5454000	and incredibly useful
5454000	5455000	even if you disagree with them.
5455000	5459000	But obviously attempts to
5459000	5462000	sort of build societies
5462000	5465000	on those ideas alone have failed.
5465000	5468000	Seems like you need something a little bit more.
5468000	5471000	I just don't think it's true
5471000	5473000	the religion stuff, I mean.
5473000	5475000	And so that's why I think
5475000	5476000	we're seeing this
5476000	5477000	because people are beginning to realize
5477000	5479000	that it probably isn't true.
5479000	5481000	They can't quite get behind
5481000	5483000	the truth claims.
5483000	5485000	But they recognize that there's some utility
5485000	5487000	in having other people believe
5487000	5489000	that it is true.
5489000	5492000	And I don't know where that leaves us
5492000	5494000	because in this discussion
5494000	5496000	about whether religion is good or bad for society,
5496000	5497000	I said yesterday,
5497000	5500000	look, I will accept your premise wholesale
5500000	5502000	that religion is good,
5502000	5504000	maybe even necessary for society.
5504000	5505000	What do you want me to do
5505000	5506000	if I just don't think it's true?
5506000	5508000	Am I just lying to my children,
5508000	5509000	raising and believing something
5509000	5511000	that I don't believe is the case
5511000	5514000	because I think it will somehow be beneficial to society?
5514000	5515000	I don't think it works like that.
5515000	5517000	I don't think people can actually fool themselves.
5517000	5518000	Sure, you can act as if God exists,
5518000	5519000	and that's what someone like Peterson says
5519000	5521000	that people do already,
5521000	5523000	but ultimately if you just say,
5523000	5524000	well, I think that, you know,
5524000	5526000	it should just act like a Christian
5526000	5527000	because it's good for me.
5527000	5528000	Then when push comes to shove
5528000	5530000	and you really have to make a moral sacrifice,
5530000	5532000	if you're not actually a Christian,
5532000	5533000	you're probably not going to do
5533000	5534000	the actually Christian thing.
5534000	5536000	Well, I wonder whether this is afforded to people
5536000	5539000	because of the convenience and comfort of modern life.
5539000	5541000	The fact that having to really,
5541000	5542000	really put something on the line,
5542000	5545000	it's mostly lapping as belief systems
5545000	5547000	and I'll pick up that piece of trash
5547000	5551000	and I will give money to this person on the street.
5551000	5553000	Yeah, people have sort of forgotten.
5553000	5555000	It's like bourgeois religious belief.
5555000	5557000	It's so irregularly that we have to make
5557000	5559000	genuine moral sacrifices of the kind
5559000	5560000	that used to be commonplace
5560000	5561000	throughout the history of humanity
5561000	5564000	that we've sort of forgotten our ability to do so.
5564000	5565000	And I think that if you push people now,
5566000	5567000	they recognize that they probably wouldn't
5567000	5568000	make those sacrifices.
5568000	5570000	Did you see the Mr. Beast poll where he asked,
5570000	5571000	would you rather have like a million dollars
5571000	5573000	or like a random person on Earth dies
5573000	5575000	or something like that if you press this button?
5575000	5576000	No.
5576000	5577000	And like, I think it might have been
5577000	5579000	a majority of people that's slim majority
5579000	5581000	said they'd press that button.
5581000	5582000	Yeah, kill someone random.
5582000	5584000	I'll take a million bucks.
5584000	5587000	And I actually kind of believe them.
5587000	5589000	I think they actually would.
5589000	5594000	And people want to say that that's because
5594000	5598000	we've lost our belief in God.
5598000	5599000	I don't know.
5599000	5601000	Maybe I think a better explanation is just that,
5601000	5603000	like you say, we've become too comfortable.
5603000	5605000	And so when somebody says in other words like,
5605000	5609000	oh, well, this must be due to decline in religion
5609000	5610000	and the fact that we've forgotten
5610000	5611000	our Judeo-Christian heritage.
5611000	5612000	I mean, you'll probably hear that a lot
5612000	5614000	from people that you might talk to on this podcast.
5614000	5615000	They'll say something like that.
5615000	5616000	Just think to yourself like,
5616000	5618000	is that really the best explanation?
5618000	5619000	Is that the only explanation?
5619000	5621000	Could it be something to do with the growth of technology?
5621000	5623000	Could it be to do with something
5624000	5625000	to do with the growth of comfort?
5625000	5626000	Yeah.
5626000	5627000	And is it more likely to do with that?
5627000	5629000	And maybe it's not the lack of religion
5629000	5631000	that's causing the other stuff,
5631000	5634000	but this other source that's causing both of those things.
5634000	5635000	Yeah.
5635000	5637000	I've been thinking a lot recently about stuff
5637000	5640000	that is literally true, but figuratively false
5640000	5643000	and figuratively true, but literally false.
5643000	5648000	And it kind of seems a little bit like the beliefs
5648000	5650000	that you're talking about here.
5650000	5653000	It may be comforting, increasing in happiness,
5653000	5656000	adaptive to kind of act as if these things exist.
5656000	5659000	The belief in free will, actually.
5659000	5661000	Believing in free will or sorry.
5661000	5664000	Yeah, determinism generally is something
5664000	5668000	that may be literally true, but figuratively false.
5668000	5669000	Yes.
5669000	5671000	And that's kind of where I've come to
5671000	5672000	as an opinion with this,
5672000	5675000	that largely it's through designed ignorance
5675000	5677000	that I just don't think about it that much.
5677000	5679000	Precisely the reason it evolves.
5679000	5681000	That that's why it exists as an illusion
5681000	5683000	because it does something for us.
5683000	5684000	And that's fine.
5684000	5686000	I've never had a problem saying that,
5686000	5689000	but when the sort of auspices under which
5689000	5691000	I'm having a conversation with Ben Shapiro
5691000	5694000	is that he made a video called The Atheist Illusion.
5694000	5696000	And in that video, he says like,
5696000	5699000	look, you can't have free will without God.
5699000	5700000	I say, yeah, I agree.
5700000	5702000	You can't have free will without God.
5702000	5704000	You just also can't have it with God.
5704000	5706000	And he essentially says like,
5706000	5708000	well, you know, there's sort of a,
5708000	5709000	I don't know how free will works,
5709000	5711000	but it's sort of a mystery that I'm willing
5711000	5712000	to accept wholesale.
5712000	5714000	And I'm like, well, this is fine,
5714000	5717000	but who's the delusory one here?
5717000	5718000	You know what I mean?
5718000	5720000	Like I've got no problem with you saying like,
5720000	5722000	well, I see that this is more Ben Shapiro, by the way,
5722000	5724000	but I have no problem with somebody saying, well,
5724000	5726000	yeah, I mean, maybe free will doesn't exist,
5726000	5728000	but it's better to act as though it does.
5728000	5729000	It's like, okay, fine.
5729000	5731000	But then don't say that I'm the one acting under a delusion.
5731000	5732000	I mean, delusions can be good.
5732000	5733000	They might evolve for a good reason,
5733000	5735000	but I don't know.
5735000	5737000	I guess I find it difficult to treat something as true.
5737000	5740000	That isn't, it's a bit like the gun has always loaded.
5740000	5744000	That's one of Brett Weinstein's example examples.
5744000	5746000	It's, it's not true that the gun has always loaded,
5746000	5748000	but we're just going to pretend that it is.
5748000	5749000	And that's much better.
5749000	5750000	At least we're good society.
5750000	5751000	If we always act like that.
5751000	5752000	They're truly false, but figuratively true.
5752000	5757000	But like, you can't actually act like it's true.
5757000	5759000	Like if you ask me to put money on,
5759000	5761000	like opening the gun and seeing if there's a bullet in that.
5761000	5763000	You can behave in a way that functions as if it were.
5763000	5764000	Yeah.
5764000	5765000	But then when push comes to shove
5765000	5767000	and you really need to make a decision,
5767000	5768000	you're not going to be able to do it
5768000	5769000	unless you really believe it's true.
5769000	5770000	Right.
5770000	5771000	So this only works in low stakes situations.
5771000	5772000	Exactly.
5772000	5773000	Yeah.
5773000	5775000	So if, so, you know, it's all too easy to say, oh, you know, we,
5775000	5777000	we'll just, we'll just sort of act as though it's true.
5777000	5778000	Good example here.
5778000	5781000	Using the, using the act as if the gun is loaded thing.
5781000	5783000	You do not point it at anybody.
5783000	5785000	You do not leave it around the children.
5785000	5786000	You do not do the rest of it.
5786000	5789000	If a robber breaks into your house,
5789000	5792000	you don't go downstairs with said gun acting as if it's loaded.
5792000	5793000	Exactly.
5793000	5794000	Exactly right.
5794000	5796000	And so the moment that it actually really matters,
5796000	5800000	like in the prior case, it only matters when it goes wrong, right?
5800000	5803000	But when it begins to matter when it goes right
5803000	5807000	and that it goes right, this principle just doesn't work.
5807000	5810000	And so I'm, I'm suspicious of its efficacy in other words.
5810000	5813000	I think we might need to actually start acting in accordance with what's true,
5813000	5815000	which by the way is what people have been saying for a long time.
5815000	5817000	Oh, why don't we all just act in accordance with what's true?
5817000	5821000	And then suddenly when you begin to realize that maybe free will doesn't exist,
5821000	5824000	maybe morality is just a social adaptation.
5824000	5827000	Suddenly this idea of acting in accordance with what's true
5827000	5830000	is a point of principle goes out the window.
5830000	5835000	And it's amazing how I sort of see deontologists,
5835000	5840000	virtue ethicists transform for my very eyes into utilitarians.
5840000	5843000	Out goes the principle of live in accordance with the truth,
5843000	5846000	out go the principles of honesty
5846000	5849000	and sort of lack of intentional self-deception.
5849000	5851000	Because, well, we want the greatest good for the greatest number.
5851000	5853000	A better, more functional society comes about
5853000	5855000	if we just pretend as though this is the case.
5855000	5858000	What happened to the virtue? What happened to the principle?
5858000	5861000	What happened to the deontological ethics?
5861000	5863000	It's just out the window all of a sudden.
5863000	5866000	I think sometimes people like to have their cake and eat it too in that respect.
5866000	5869000	I like to act in accordance with what I think is true.
5869000	5870000	And when somebody challenges me and says,
5870000	5873000	well, you don't act as though you don't have free will,
5873000	5875000	I just don't know what that means.
5875000	5877000	I don't know what that looks like.
5877000	5879000	It probably looks something like this.
5879000	5881000	Alex O'Connor, ladies and gentlemen.
5881000	5883000	Alex, it's been a while since I've had you on.
5883000	5886000	I think I'm going to be joining you on your show at some point soon.
5886000	5887000	I hope so.
5887000	5890000	What can people expect of you over the next couple of months?
5890000	5891000	What's coming up?
5891000	5893000	Hopefully that conversation with Ben Shapiro,
5893000	5897000	which I'll mention for a 16 billionth time,
5897000	5898000	will be out.
5898000	5900000	I've got a few debates coming up.
5900000	5902000	Oxford Union, Durham Union,
5902000	5905000	something at Cambridge on the monarchy.
5905000	5907000	You're being known for that.
5907000	5912000	Piers Morgan's catapulted you to the forefront of the anti-monarchists.
5912000	5916000	I'm becoming something of a royal correspondent for that news channel.
5916000	5917000	An anti-royal correspondent.
5917000	5921000	Hey, my Twitter bio is growing by the minute on this forecast.
5921000	5924000	Where should people go if they want to keep up to date with the stuff you do?
5924000	5926000	Just type in my name, Alex O'Connor.
5926000	5928000	I am technically still Cosmic Skeptic.
5928000	5930000	That's my old handle.
5930000	5932000	I tend to go by my Christian name now,
5932000	5935000	but the handles are still there, so you'll still find me that way too.
5935000	5936000	Alex, I appreciate you.
5936000	5937000	Thank you, mate.
5937000	5939000	Thank you very much for tuning in.
5939000	5940000	If you enjoyed that episode,
5940000	5945000	you will love my full-length, two-hour-long podcast with Douglas Murray.
5945000	5946000	Go on.
5947000	5948000	Press it.
