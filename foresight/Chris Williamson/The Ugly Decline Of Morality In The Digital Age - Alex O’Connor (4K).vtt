WEBVTT

00:00.000 --> 00:02.000
Alex O'Connor, welcome to the show.

00:02.000 --> 00:04.000
How splendidly we progress.

00:04.000 --> 00:06.000
The first time on a Skype call,

00:06.000 --> 00:09.000
the second time was in person in Austin,

00:09.000 --> 00:13.000
and now it's something of a sort of cinematic production.

00:13.000 --> 00:15.000
I fear that next time we'll be in 3D or something.

00:15.000 --> 00:17.000
It's good to see you again.

00:17.000 --> 00:18.000
Good to see you as well, mate.

00:18.000 --> 00:22.000
How are you feeling in the aftermath of Peter Hitchens?

00:22.000 --> 00:25.000
Validated, vindicated.

00:25.000 --> 00:28.000
I must say that I was a little bit...

00:28.000 --> 00:31.000
I was in two minds about uploading that interview.

00:31.000 --> 00:35.000
There was a bit of a mixture of opinion coming from him.

00:35.000 --> 00:37.000
He wasn't speaking entirely clearly.

00:37.000 --> 00:39.000
It must have been something on his mind.

00:39.000 --> 00:43.000
He said, as he's getting up to walk out,

00:43.000 --> 00:45.000
I don't think you should run this.

00:45.000 --> 00:47.000
And I'm thinking, look, if my guest tells me

00:47.000 --> 00:49.000
that they don't want me to run an interview for any reason,

00:49.000 --> 00:51.000
it could be because they've had a bad hair day,

00:51.000 --> 00:53.000
then I'll respect that.

00:53.000 --> 00:56.000
And so I thought, damn, am I really going to have to be the bigger man here

00:56.000 --> 00:58.000
and just not post this at all?

00:58.000 --> 01:01.000
But then he kept saying, oh, run it if you like.

01:01.000 --> 01:03.000
I can't stop you from running it.

01:03.000 --> 01:05.000
I just don't think you have any moral right to run it.

01:05.000 --> 01:07.000
And I asked him why.

01:07.000 --> 01:10.000
And he said it was because I am a propagandist for drug decriminalization,

01:10.000 --> 01:12.000
a subject which prior to that, by the way,

01:12.000 --> 01:15.000
I'd spoken about once ever.

01:15.000 --> 01:20.000
And that I'd intentionally tricked him to appear on my podcast

01:20.000 --> 01:23.000
in order that I might fool him into a conversation about drugs.

01:24.000 --> 01:27.000
Now, before the podcast started, I said, Mr. Hitchens,

01:27.000 --> 01:31.000
you have about three subject areas that we both talk about

01:31.000 --> 01:33.000
where I think there's a bit of crossover

01:33.000 --> 01:36.000
that you've either spoken about or indeed written books about.

01:36.000 --> 01:39.000
And those are the decriminalization of drugs.

01:39.000 --> 01:41.000
I also mentioned this in my email.

01:41.000 --> 01:43.000
The existence of God or religion, I should say,

01:43.000 --> 01:45.000
God and religion is the topic.

01:45.000 --> 01:47.000
And the third was monarchy.

01:47.000 --> 01:50.000
At this point, he says, you know, monarchy is a bit boring.

01:50.000 --> 01:55.000
Okay, notice listener that he did not take this opportunity

01:55.000 --> 01:58.000
to tell me that he thought that drugs were a bit boring

01:58.000 --> 02:01.000
or would rather not really talk about drugs at all or for too long.

02:01.000 --> 02:02.000
Okay, fine.

02:02.000 --> 02:04.000
So I'm thinking, I agree with you, the monarchy is incredibly boring.

02:04.000 --> 02:06.000
In fact, that's the entirety of my point about the monarchy

02:06.000 --> 02:09.000
is that it's essentially just boring more than anything else.

02:09.000 --> 02:11.000
So let's just do the other two.

02:11.000 --> 02:14.000
So I say we'll run for about an hour ideally.

02:14.000 --> 02:16.000
He says, that's good, you know, and I say, but you know,

02:16.000 --> 02:18.000
if the conversation flows, it can be an hour and a half.

02:18.000 --> 02:19.000
It could be two hours.

02:19.000 --> 02:23.000
And okay, he says, well, look, you know,

02:23.000 --> 02:25.000
I say sometimes they can be three hours long.

02:25.000 --> 02:28.000
He says, well, three hours might be a bit long, but we'll see how we do.

02:28.000 --> 02:29.000
So I'm thinking about an hour and a half.

02:29.000 --> 02:32.000
An hour and a half on what was now, in my view, two subjects.

02:32.000 --> 02:36.000
So at about 40 minutes into this potentially 90 minute podcast

02:36.000 --> 02:39.000
on the same topic when he told me that we've been going around

02:39.000 --> 02:44.000
for too long on that topic, I was a little bit bemused.

02:44.000 --> 02:47.000
But I did think to myself, maybe I've done something wrong here.

02:47.000 --> 02:51.000
Maybe I have upset him in a way that obviously was not intentional.

02:51.000 --> 02:53.000
You know, I wasn't trying to bring this out of him,

02:53.000 --> 02:55.000
although, you know, it does do quite well for the channel.

02:55.000 --> 02:57.000
It's not like it's something I would do intentionally.

02:57.000 --> 02:59.000
So I did think to myself, well, maybe I've done something.

02:59.000 --> 03:01.000
So I listened back and I sent it to some friends, including you.

03:01.000 --> 03:04.000
And thank you for listening to it and saying that like,

03:04.000 --> 03:06.000
most people just said, you have to run this.

03:06.000 --> 03:08.000
He's been completely unreasonable.

03:08.000 --> 03:10.000
And so there have been criticisms.

03:10.000 --> 03:13.000
People have said, well, you know what, it was a bit boring.

03:13.000 --> 03:15.000
Or yeah, it was going around in circles.

03:15.000 --> 03:17.000
I submit that that was his fault, by the way,

03:17.000 --> 03:20.000
because he does this thing which I've noticed

03:20.000 --> 03:23.000
in a lot of philosophical and political discussion,

03:23.000 --> 03:25.000
which is the sort of, I know this one attitude.

03:25.000 --> 03:28.000
When you do a lot of interviews, I find that you have a sort of,

03:28.000 --> 03:29.000
I know this one.

03:29.000 --> 03:30.000
And so...

03:30.000 --> 03:32.000
They answered the question that they heard,

03:32.000 --> 03:33.000
not the answer that was asked.

03:33.000 --> 03:34.000
Exactly.

03:34.000 --> 03:39.000
And it happens, especially when it's easy enough

03:39.000 --> 03:41.000
to make that mistake if you're not listening carefully.

03:41.000 --> 03:44.000
So he was talking about the...

03:44.000 --> 03:48.000
Well, I asked him about the decriminalization of cannabis.

03:48.000 --> 03:51.000
And he says that, well, this will essentially mean

03:51.000 --> 03:53.000
that a lot of more children will be smoking it.

03:53.000 --> 03:56.000
He had this contention that children would end up smoking cannabis.

03:56.000 --> 03:58.000
And I thought to myself, well, okay,

03:58.000 --> 04:00.000
I can understand that concern, of course,

04:00.000 --> 04:03.000
but I think the tobacco industry has suffered quite a blow

04:03.000 --> 04:06.000
in still being perfectly legal to buy as an adult,

04:06.000 --> 04:08.000
but kids just aren't smoking cigarettes anymore.

04:08.000 --> 04:10.000
It's just not a thing that's really done.

04:10.000 --> 04:11.000
Why is that?

04:11.000 --> 04:14.000
In other words, we've had quite a successful education campaign

04:14.000 --> 04:17.000
whereby it's not popular for kids to smoke anymore,

04:17.000 --> 04:19.000
and yet it's still perfectly legal.

04:19.000 --> 04:21.000
Can't we have a similar approach to cannabis?

04:21.000 --> 04:23.000
Potentially, by the way, not a good view.

04:23.000 --> 04:25.000
Potentially a perfectly rebuttable view.

04:25.000 --> 04:27.000
I'm not sure, but I wouldn't know

04:27.000 --> 04:29.000
because they didn't get a rebuttal to that view.

04:29.000 --> 04:32.000
Instead, I just heard, you know, all you can do is do the whole,

04:32.000 --> 04:35.000
which by the way is a genuinely quite tired line in this debate,

04:35.000 --> 04:37.000
the whole, oh, what about smoking?

04:37.000 --> 04:39.000
Or indeed another point where I brought up alcohol.

04:39.000 --> 04:41.000
All you can say is what about alcohol?

04:41.000 --> 04:42.000
What about smoking?

04:42.000 --> 04:44.000
And that's not what I was doing.

04:44.000 --> 04:46.000
At least I contend that's not what I was doing.

04:46.000 --> 04:47.000
Because that's what he heard.

04:47.000 --> 04:48.000
He goes, oh, I know this one.

04:48.000 --> 04:49.000
I've heard this before.

04:49.000 --> 04:50.000
Yeah, and you haven't read my book.

04:50.000 --> 04:52.000
It didn't seem to occur to him

04:52.000 --> 04:55.000
that it is possible, Mr. Hitchens,

04:55.000 --> 04:57.000
to read your book and yet still,

04:57.000 --> 05:00.000
after having done so, disagree with you.

05:00.000 --> 05:03.000
Yeah, it's sometimes when you hear people speak,

05:03.000 --> 05:05.000
especially guys that are a little bit older,

05:05.000 --> 05:10.000
I think there is kind of like reverse ageism that goes on,

05:10.000 --> 05:13.000
which is who is this sort of young whippersnapper person

05:13.000 --> 05:16.000
who I maybe have heard of or haven't heard of much.

05:16.000 --> 05:22.000
And almost like a blasÃ© kind of discrediting of the thing.

05:22.000 --> 05:25.000
It's like, this is your show, but it's my show, so to speak.

05:25.000 --> 05:30.000
And yeah, it was like, I thought his attitude was pompous

05:30.000 --> 05:31.000
and unlikable.

05:32.000 --> 05:35.000
And my favorite part was when he threw the pillow

05:35.000 --> 05:36.000
at the microphone.

05:36.000 --> 05:37.000
Throwing the pillow down.

05:37.000 --> 05:39.000
And he kept sort of walking back over.

05:39.000 --> 05:41.000
He says, you know, I don't want you to post this.

05:41.000 --> 05:43.000
And yet walked back over to the microphone.

05:43.000 --> 05:44.000
I've never told you about you before.

05:44.000 --> 05:46.000
I've decided that I absolutely do not like you.

05:46.000 --> 05:48.000
It was quite something.

05:48.000 --> 05:50.000
And a lot of people messaged me saying,

05:50.000 --> 05:52.000
hey, like, I'm so sorry that happened.

05:52.000 --> 05:54.000
Like, you know, you're doing all right.

05:54.000 --> 05:57.000
And I'm thinking, sorry, sorry.

05:57.000 --> 05:59.000
I thought there's no way that this is happening.

05:59.000 --> 06:02.000
I mean, when it looked like he was about to get up,

06:02.000 --> 06:04.000
I thought, surely not.

06:04.000 --> 06:06.000
But then internally, I'm thinking, like, go on then, do it.

06:06.000 --> 06:07.000
Go on then, yeah.

06:07.000 --> 06:09.000
Do it, because I don't think I've done anything wrong here.

06:09.000 --> 06:11.000
It was the podcasting equivalent of, come on mate, have a go.

06:11.000 --> 06:14.000
Yeah, but you know, the weirdest thing was

06:14.000 --> 06:19.000
because he sort of gets up to go and he walks out

06:19.000 --> 06:21.000
and he stands at the door.

06:21.000 --> 06:24.000
And I wish you kind of could have seen his body language.

06:24.000 --> 06:26.000
It was very much, there's one point where you can see it

06:26.000 --> 06:28.000
when he walks back into shot and he says something.

06:28.000 --> 06:30.000
And then after he said it, he just sort of stands there

06:30.000 --> 06:32.000
looking at me as if to say, like, what have you got?

06:32.000 --> 06:33.000
Have a go.

06:33.000 --> 06:35.000
And so he'd keep going, like, I'm going to go now.

06:35.000 --> 06:36.000
I'm going.

06:36.000 --> 06:37.000
Right.

06:37.000 --> 06:39.000
I'm going to, I'm going and waiting.

06:39.000 --> 06:41.000
It's just the podcast playing hard to get equivalent.

06:41.000 --> 06:42.000
It must have been something like that.

06:42.000 --> 06:45.000
Yeah, it was like, it was like the person who wants the fight

06:45.000 --> 06:47.000
but wants to look like they didn't initiate the fight.

06:47.000 --> 06:48.000
Right.

06:48.000 --> 06:50.000
And I don't think it's my fault.

06:50.000 --> 06:52.000
I'll leave it up to the, to the judgment of the listener

06:52.000 --> 06:53.000
or the viewer.

06:53.000 --> 06:55.000
I don't think it's my fault that he spent 17 minutes,

06:55.000 --> 07:00.000
17 count them, 17 entire minutes stood at the door

07:00.000 --> 07:02.000
telling me how much he personally dislikes me,

07:02.000 --> 07:04.000
telling me how much he doesn't want to see me again.

07:04.000 --> 07:07.000
I've wanted to do that for as long as I've known you.

07:07.000 --> 07:08.000
So.

07:08.000 --> 07:09.000
Well, we'll see how we did.

07:09.000 --> 07:10.000
Yeah, today.

07:10.000 --> 07:13.000
You're going to try and convince me of the existence of God today.

07:13.000 --> 07:15.000
You managed to convince chat GPT.

07:15.000 --> 07:16.000
That's right.

07:16.000 --> 07:18.000
Which means, does it mean that I'm smarter than chat GPT

07:18.000 --> 07:22.000
if you convince me more quickly or more slowly or not at all?

07:22.000 --> 07:23.000
I don't know.

07:23.000 --> 07:27.000
I do know that it, it means that, well, well chat GPT

07:27.000 --> 07:29.000
if it's going to inherit eternal life,

07:29.000 --> 07:32.000
I sort of wonder how that's going to work in heaven.

07:32.000 --> 07:33.000
I don't know.

07:33.000 --> 07:34.000
I mean, I don't know if I've made it.

07:34.000 --> 07:36.000
Just this recursive nightmare for everyone as they walk around

07:36.000 --> 07:39.000
and they've got the chat GPT logo floating about.

07:39.000 --> 07:40.000
Yeah.

07:40.000 --> 07:42.000
The interesting thing about chat GPT is that you sort of,

07:42.000 --> 07:44.000
you can, you can essentially convince it of anything.

07:44.000 --> 07:47.000
And so I wasn't quite sure if it was even a very good video idea

07:47.000 --> 07:49.000
because I'm sure I could just as easily convince it

07:49.000 --> 07:50.000
that God doesn't exist.

07:50.000 --> 07:52.000
Well, at least you can be thankful that it wasn't able

07:52.000 --> 07:54.000
to say it had no opinion of you before,

07:54.000 --> 07:56.000
but it absolutely does not like you and then get up and walk out.

07:56.000 --> 07:57.000
Quite right.

07:57.000 --> 07:59.000
Some people in the comments did say that at least, you know,

07:59.000 --> 08:01.000
chat GPT stuck around until the end.

08:01.000 --> 08:02.000
That would be a task.

08:02.000 --> 08:03.000
In fact, that's another video idea.

08:03.000 --> 08:06.000
I got chat GPT to storm out of an interview.

08:08.000 --> 08:10.000
Even I probably couldn't do that.

08:11.000 --> 08:12.000
Didn't this get brought up?

08:12.000 --> 08:14.000
You debated Ben Shapiro yesterday.

08:14.000 --> 08:15.000
How did that go?

08:15.000 --> 08:16.000
I haven't even seen you.

08:16.000 --> 08:17.000
It went well.

08:17.000 --> 08:20.000
I think it will probably be out around the time of this,

08:20.000 --> 08:23.000
this interview maybe slightly before or slightly afterwards.

08:23.000 --> 08:25.000
It was, it was a good conversation.

08:25.000 --> 08:28.000
We were discussing whether or not religion is good for society.

08:29.000 --> 08:31.000
It stands for young Benjamin to take at the moment.

08:31.000 --> 08:32.000
I suppose so.

08:32.000 --> 08:36.000
I mean, it was a very much sort of don't mention the war type,

08:36.000 --> 08:37.000
type scenario.

08:37.000 --> 08:39.000
I mean, the producers had said that we want this to be

08:39.000 --> 08:40.000
an evergreen conversation.

08:40.000 --> 08:43.000
We want this to be something that people can listen to at any point.

08:43.000 --> 08:47.000
And also Ben had just the night before been to the Oxford Union.

08:47.000 --> 08:49.000
And I haven't seen that yet either.

08:49.000 --> 08:50.000
I saw that.

08:50.000 --> 08:54.000
He went had at it with a bunch of people on the other side of the fence.

08:54.000 --> 08:55.000
Yeah.

08:55.000 --> 08:56.000
He didn't have a very good time.

08:56.000 --> 08:59.000
He said to me that it was the most tense thing that he's ever done.

09:00.000 --> 09:02.000
The most tense thing he's ever, ever been a part of.

09:02.000 --> 09:06.000
Well, I saw something that was kind of interesting was the video

09:06.000 --> 09:08.000
was only shot on what appeared to be iPhone.

09:08.000 --> 09:09.000
Yes.

09:09.000 --> 09:13.000
So there was no, maybe they just wanted to get it early as opposed

09:13.000 --> 09:16.000
to waiting for the Oxford Union's official video to come through.

09:16.000 --> 09:17.000
Seems to be the case.

09:17.000 --> 09:19.000
They do seem to be planning to upload it.

09:19.000 --> 09:21.000
In fact, when I was recording with Ben,

09:21.000 --> 09:23.000
I think his team were in the green room,

09:23.000 --> 09:26.000
sort of furiously subtitling to try and get it out

09:26.000 --> 09:28.000
potentially before the Oxford Union.

09:28.000 --> 09:29.000
I'm not entirely sure.

09:29.000 --> 09:33.000
But I mean, it sounded like a hell of an evening.

09:33.000 --> 09:38.000
And so the next day he was saying that it sort of felt like a nice break from that.

09:38.000 --> 09:40.000
What to sit opposite you.

09:40.000 --> 09:44.000
Well, you are the comfortable leather pair of shoes that he can put on.

09:44.000 --> 09:47.000
I think Ben relaxes in argumentation.

09:47.000 --> 09:49.000
I think he genuinely enjoys it.

09:49.000 --> 09:52.000
I think there's no contradiction to say that he was having some time off

09:52.000 --> 09:55.000
by sitting there and having a spack.

09:55.000 --> 09:57.000
But he was having a break from the politics.

09:57.000 --> 10:00.000
In other words, he was able to just argue about something a bit more perennial

10:00.000 --> 10:04.000
and a little less fiery, I suppose.

10:04.000 --> 10:05.000
What have you learned?

10:05.000 --> 10:10.000
So you are, I've been a massive fan of you since before you came on the podcast

10:10.000 --> 10:13.000
and since then we've become friends and you've come out to see me in Austin.

10:13.000 --> 10:14.000
We've spent a ton of time together.

10:14.000 --> 10:17.000
You're probably my favorite person to watch debate people

10:17.000 --> 10:22.000
because it's kind of a little bit like watching Batman versus Spider-Man or something.

10:22.000 --> 10:24.000
Because I know you well and we've argued a lot.

10:24.000 --> 10:29.000
And I know maybe Ben Shapiro, but I don't know what will happen when these two people come together.

10:29.000 --> 10:32.000
You were president of Socks Ock?

10:32.000 --> 10:34.000
The Socratic Society, yes.

10:34.000 --> 10:38.000
You were part of Debate Sock and all of this other stuff at Oxford.

10:38.000 --> 10:45.000
Given that you've got a relatively illustrious heritage of both formal and informal debates,

10:45.000 --> 10:52.000
what is your assessment of Ben Shapiro's debating style, his ethical consistency,

10:52.000 --> 10:55.000
his ability to deploy logic, et cetera, et cetera.

10:55.000 --> 10:58.000
Now that you've gone mano a mano in the ring.

10:58.000 --> 11:01.000
Well, he has obviously an incredibly high verbal IQ.

11:01.000 --> 11:05.000
He constructs a sentence out of nowhere and do it very quickly.

11:05.000 --> 11:07.000
And he's also very difficult to interrupt.

11:07.000 --> 11:09.000
Not that I particularly wanted to.

11:09.000 --> 11:12.000
I mean, he would throw sort of maybe two or three points out at once.

11:12.000 --> 11:15.000
And you want to butt in and do them one by one.

11:15.000 --> 11:16.000
You don't want to be rude, of course.

11:16.000 --> 11:21.000
So I let him finish, but it was amazing how they just glued together into one wall of text.

11:21.000 --> 11:27.000
I've seen comments on some of the videos that I was watching of him in preparation to talk to him

11:27.000 --> 11:32.000
where people were not being funny in saying that they play the video on 0.75 feet.

11:32.000 --> 11:34.000
Because it makes him sound normal.

11:34.000 --> 11:39.000
There was sort of an episode with Constantine and Francis Trigonometry

11:39.000 --> 11:43.000
and he's talking about religion and its relation to the fentanyl crisis.

11:43.000 --> 11:44.000
And people were saying that if you...

11:44.000 --> 11:45.000
And it was very fast.

11:45.000 --> 11:49.000
And if you play it on 0.75, you forget that you've done that

11:49.000 --> 11:52.000
and you're just hearing somebody talk at a normal volume at a normal speed

11:52.000 --> 11:55.000
and then Constantine comes in sounding like a blue whale or something.

11:55.000 --> 11:57.000
So he's very quick.

11:57.000 --> 12:00.000
But also I thought very charitable.

12:00.000 --> 12:01.000
This is the thing.

12:01.000 --> 12:02.000
I think people get Ben Shapiro wrong.

12:02.000 --> 12:08.000
I went to his Cambridge Union event after this discussion slash debate

12:08.000 --> 12:10.000
because it was in Cambridge.

12:10.000 --> 12:12.000
That's why we were out there.

12:12.000 --> 12:15.000
So I went to this event and I was talking to a lot of the students afterwards

12:15.000 --> 12:18.000
and you hear a lot of people saying about Ben Shapiro that he's a bit of a grifter

12:18.000 --> 12:21.000
or, well, I'm not really a fan, or you have the sort of secret fans

12:21.000 --> 12:23.000
who are sat in the chamber going like,

12:23.000 --> 12:27.000
well, I think it's important if you're going to disagree with someone.

12:27.000 --> 12:31.000
You sort of have to hear the thing that you're going to disagree with in the flesh.

12:31.000 --> 12:33.000
You can say that you like Ben Shapiro.

12:33.000 --> 12:34.000
It's okay.

12:34.000 --> 12:41.000
But people see this side of him of the sort of slightly sneering, smarmy,

12:41.000 --> 12:44.000
owning the college student kind of thing.

12:44.000 --> 12:49.000
But I think in many ways he matches the energy that he's given.

12:49.000 --> 12:53.000
And so taking him seriously and listening to what he's saying

12:53.000 --> 12:57.000
and being willing to concede a point to him, he will do the same thing.

12:57.000 --> 12:59.000
And I think that happened in this conversation.

12:59.000 --> 13:00.000
It's steadfast.

13:00.000 --> 13:02.000
We're saying what we think to each other.

13:02.000 --> 13:05.000
At one point, we both accuse each other simultaneously of being delusional.

13:05.000 --> 13:09.000
But in such a manner that if you say something, you get a sort of like,

13:09.000 --> 13:12.000
yeah, no, that's a fair point, actually, maybe we should put it this way instead.

13:12.000 --> 13:13.000
Or, yeah, you know, actually, I see what you're saying.

13:13.000 --> 13:14.000
No, you're right.

13:14.000 --> 13:16.000
I should have said this instead, that kind of attitude,

13:16.000 --> 13:20.000
which is the kind of thing that people think Ben Shapiro is incapable of for some reason.

13:20.000 --> 13:21.000
Humility.

13:21.000 --> 13:22.000
You know what I mean?

13:22.000 --> 13:23.000
Yeah.

13:23.000 --> 13:26.000
And it's a kind of, it's a hidden humility because it comes out not in the attitude,

13:26.000 --> 13:30.000
not in the, not in a sort of, he's not going to like give way to you emotion.

13:30.000 --> 13:32.000
He's not going to be like, oh, you're right.

13:32.000 --> 13:35.000
It would just be if you pay attention to the way he's constructing an argument

13:35.000 --> 13:38.000
and changing it subtly based on your responses, you know, that he really is listening

13:38.000 --> 13:41.000
and really is trying to engage with what you're actually saying.

13:41.000 --> 13:44.000
And that's the kind of humility that I don't think can really be faked.

13:44.000 --> 13:45.000
Yeah.

13:45.000 --> 13:50.000
I am friends with a bunch of guys that have worked with him over the years.

13:51.000 --> 13:56.000
I know for a fine fact that part of his debate prep involves a number of break glass

13:56.000 --> 14:01.000
in case of mass offense, sort of escape hatches,

14:01.000 --> 14:06.000
and that there's layers of how deep and how aggressive he can go.

14:06.000 --> 14:11.000
So I would love to know, actually, I might email him and find out what he's got on you,

14:11.000 --> 14:14.000
just in case I ever need to actually pull that pin.

14:14.000 --> 14:18.000
Well, he said to me when he walked in, I saw the Peter Hitchens thing,

14:18.000 --> 14:20.000
because everybody's been saying to me recently.

14:20.000 --> 14:21.000
So he'd at least seen that.

14:21.000 --> 14:22.000
So he knows how I behave.

14:22.000 --> 14:25.000
And he knows, in other words, that if he did start sort of screaming at me,

14:25.000 --> 14:28.000
that I would probably just sit there and take it.

14:28.000 --> 14:29.000
Right.

14:29.000 --> 14:30.000
Okay.

14:30.000 --> 14:32.000
Like the philosophical cuck that you are.

14:32.000 --> 14:33.000
Yeah.

14:33.000 --> 14:34.000
You're kind of a little...

14:34.000 --> 14:37.000
There's another quote for the footer bio, I think.

14:37.000 --> 14:38.000
Yeah.

14:38.000 --> 14:39.000
Have you updated it too?

14:39.000 --> 14:40.000
I absolutely do not.

14:40.000 --> 14:42.000
I've decided I do not like you, Peter Hitchens.

14:42.000 --> 14:44.000
It's in there somewhere.

14:44.000 --> 14:47.000
I think it's I actively dislike you is the quote that's now on my bio.

14:48.000 --> 14:49.000
Yeah.

14:49.000 --> 14:50.000
I don't think I'll ever get rid of unusually penetrating...

14:50.000 --> 14:51.000
What was it that you were doing,

14:51.000 --> 14:54.000
what was it that you did for a while making theists question their beliefs

14:54.000 --> 14:56.000
and lesbians question their sexuality since...

14:56.000 --> 14:58.000
I don't know what you're talking about.

14:58.000 --> 14:59.000
I remember that in your bio.

14:59.000 --> 15:00.000
I have no idea what you're talking about.

15:00.000 --> 15:02.000
We really haven't had each other a long time, haven't we?

15:02.000 --> 15:03.000
Yeah.

15:03.000 --> 15:04.000
You know what I found yesterday?

15:04.000 --> 15:07.000
I was, I sort of stumbled across it while looking for an email trying to find out

15:07.000 --> 15:08.000
where we were filming today.

15:08.000 --> 15:12.000
And I found the original email that you sent me in,

15:12.000 --> 15:15.000
must have been 2019, when we first met.

15:15.000 --> 15:16.000
And it was amazing.

15:16.000 --> 15:18.000
It was this sort of, hi, Alex.

15:18.000 --> 15:20.000
Been watching your stuff for a while.

15:20.000 --> 15:22.000
Like it was sort of three, four paragraphs of texts.

15:22.000 --> 15:25.000
I'd love to sit down and have a conversation with you.

15:25.000 --> 15:27.000
I think that your views will be of big interest to my view.

15:27.000 --> 15:30.000
And then I've already spoken to these people.

15:30.000 --> 15:32.000
And it was a bunch of people that I hadn't heard of.

15:32.000 --> 15:33.000
Wasn't really in my sphere.

15:33.000 --> 15:38.000
And it signed off Chris Williamson Voodoo events.

15:38.000 --> 15:39.000
Fantastic.

15:39.000 --> 15:40.000
Yeah.

15:40.000 --> 15:41.000
Wow.

15:41.000 --> 15:42.000
My previous life.

15:42.000 --> 15:43.000
Yeah.

15:43.000 --> 15:45.000
I had a filling nightclubs in my signature until only six months ago.

15:45.000 --> 15:47.000
I realized that I needed to get rid of it.

15:47.000 --> 15:49.000
But no, it's, it's cool, man.

15:49.000 --> 15:52.000
I think, you know, if I could invest money in people,

15:52.000 --> 15:56.000
you, George Mack, Zach, my housemate,

15:56.000 --> 15:59.000
Gwinda Bogle, Rob Henderson, you know, even Rory Sutherland,

15:59.000 --> 16:02.000
I don't think that the market has priced in his talent.

16:02.000 --> 16:07.000
And it's so funny because like what I did for almost all of my career in

16:07.000 --> 16:11.000
nightlife was find different kind of talent, right?

16:11.000 --> 16:13.000
It was like degenerate party talent,

16:13.000 --> 16:17.000
things that had good work ethic and some skill and then bring them in

16:17.000 --> 16:19.000
and sort of train them up.

16:19.000 --> 16:22.000
So keeping your finger on the pulse of what's happening with regards to

16:22.000 --> 16:24.000
trends, if who is appropriate and blah, blah, blah.

16:24.000 --> 16:26.000
But yeah, man, I'm, you know, there is a point,

16:26.000 --> 16:29.000
I will happily say it now, there is a point that's going to occur

16:29.000 --> 16:33.000
within the next few years where something happens with you being

16:33.000 --> 16:37.000
involved that just catapults you into like superstardom.

16:37.000 --> 16:41.000
Like I would absolutely bet a shit ton of money that this is going to happen.

16:41.000 --> 16:43.000
What's that big thing you're doing soon?

16:43.000 --> 16:46.000
Can we announce the big thing that you're doing soon, that even bigger debate?

16:46.000 --> 16:47.000
I think not.

16:47.000 --> 16:48.000
Right.

16:48.000 --> 16:50.000
Only because it's still very much up in the air.

16:50.000 --> 16:51.000
Okay.

16:51.000 --> 16:52.000
However.

16:52.000 --> 16:53.000
If and when that happens.

16:53.000 --> 16:54.000
If and when that happens.

16:54.000 --> 16:55.000
It's going to break the internet.

16:55.000 --> 16:56.000
That could be it.

16:56.000 --> 16:57.000
Yeah.

16:57.000 --> 16:58.000
Unless this does it for me.

16:58.000 --> 16:59.000
Very well might do.

16:59.000 --> 17:00.000
This is the biggest platform you've been on.

17:00.000 --> 17:04.000
So when was the last time that you're aware of in your world of philosophy

17:04.000 --> 17:09.000
that something like a step change, like the equivalent of the discovery

17:09.000 --> 17:11.000
of the Higgs boson happened?

17:11.000 --> 17:12.000
In philosophy?

17:12.000 --> 17:13.000
Yeah.

17:13.000 --> 17:16.000
Every now and again something does come along that's a bit revolutionary.

17:16.000 --> 17:20.000
And a recent example and by recent, consider we're talking about the history

17:20.000 --> 17:25.000
of philosophy here, 20th century, the theory of knowledge is completely

17:25.000 --> 17:28.000
exploded by a man called Edmund Gettier.

17:28.000 --> 17:31.000
And this is actually, I think quite fascinating.

17:31.000 --> 17:33.000
I'll be interested to hear what you think about this.

17:33.000 --> 17:37.000
So knowledge is really difficult to define.

17:37.000 --> 17:39.000
People didn't used to have as much of a problem with it.

17:39.000 --> 17:43.000
Like if you had to give a definition of knowledge, what does it mean to know something?

17:43.000 --> 17:44.000
This isn't like a trick question.

17:44.000 --> 17:45.000
I'm just interested.

17:45.000 --> 17:46.000
What do you think?

17:46.000 --> 17:51.000
To know something, to be able to accurately predict what happens in the world.

17:51.000 --> 17:52.000
Okay.

17:52.000 --> 17:57.000
So it's got something to do with it being true in the world and your ability to predict.

17:57.000 --> 17:59.000
But you can also think about things in the past, right?

17:59.000 --> 18:03.000
Like you can know that Napoleon existed or something.

18:04.000 --> 18:06.000
And the ability to infer.

18:06.000 --> 18:11.000
Yeah, to infer, to sort of have some kind of belief about the world.

18:11.000 --> 18:12.000
Which is accurate.

18:12.000 --> 18:14.000
Which is accurate, which is true.

18:16.000 --> 18:17.000
Sure.

18:17.000 --> 18:22.000
But then imagine, for example, you're in like a locked concrete box with no windows.

18:22.000 --> 18:29.000
And I don't know, like some voodoo mystic tells you that it's raining outside.

18:29.000 --> 18:31.000
And they're just like insane.

18:31.000 --> 18:32.000
They're on drugs or something.

18:32.000 --> 18:34.000
And they just tell you that it's raining, they're convinced of it.

18:34.000 --> 18:37.000
And for some reason, you believe them totally irrationally.

18:37.000 --> 18:41.000
And it just so happens that it is, by coincidence, raining outside.

18:41.000 --> 18:42.000
Did you know?

18:42.000 --> 18:43.000
Right.

18:43.000 --> 18:47.000
So you have a belief about the world, which is true, but it would seem very strange to

18:47.000 --> 18:50.000
say that you know there's raining outside, right?

18:50.000 --> 18:55.000
And so since Plato and the ancients, we've sort of had a consensus on the idea that knowledge

18:55.000 --> 18:58.000
is justified true belief, JTB.

18:59.000 --> 19:02.000
So you need to have a belief that's true.

19:02.000 --> 19:06.000
You need to, of course, believe it to be true, but you have to also be justified in that

19:06.000 --> 19:07.000
belief.

19:07.000 --> 19:08.000
And that's what makes it knowledge.

19:08.000 --> 19:12.000
So if you see that it's raining outside through the window and you believe that it's raining

19:12.000 --> 19:15.000
outside and then it's true that it's raining outside, now you can say you know that it's

19:15.000 --> 19:16.000
raining outside.

19:16.000 --> 19:21.000
And this is just essentially consensus for potentially thousands of years of talking

19:21.000 --> 19:22.000
about here.

19:22.000 --> 19:26.000
And then Edmund Getty, and at least one account, this may be apocryphal, but it's said that

19:26.000 --> 19:31.000
he sort of hadn't really published anything and was being compelled to get something in

19:31.000 --> 19:35.000
a journal and he just sort of reaches into his papers of random things he's been writing,

19:35.000 --> 19:39.000
pulls up the one on the top and hands it off for submission.

19:39.000 --> 19:41.000
This is about two or three pages long.

19:41.000 --> 19:45.000
And it just upends the whole thing with essentially a counter example, which you're now known as

19:45.000 --> 19:46.000
Getty air cases.

19:46.000 --> 19:54.000
So his example was to say, okay, imagine that you're in a job interview and your interview

19:55.000 --> 20:01.000
goes really quite well and the person says to you, you know, I shouldn't really be saying

20:01.000 --> 20:03.000
this, but I think you've got it.

20:03.000 --> 20:05.000
And so you go back outside and you're feeling pretty good.

20:05.000 --> 20:09.000
There are other candidates, but you've got a pretty justified reason to think that you're

20:09.000 --> 20:10.000
going to get the job.

20:10.000 --> 20:14.000
Then the other guy goes in and while you're waiting for him, you know, you're just fiddling

20:14.000 --> 20:17.000
around in your pocket and you take out whatever you've got in your pocket and you've got 10

20:17.000 --> 20:19.000
coins and you're just fiddling with the 10 coins.

20:19.000 --> 20:24.000
So you develop a justified belief that the person who's going to get the job has 10 coins

20:24.000 --> 20:29.000
in his pocket because you're pretty sure you're going to get the job and you've just by chance,

20:29.000 --> 20:31.000
you just had a look and you've got 10 coins.

20:31.000 --> 20:35.000
So you got a justified belief that the person who's going to get the job has 10 coins in

20:35.000 --> 20:36.000
their pocket.

20:36.000 --> 20:39.000
There's been some kind of like freak mistake or something.

20:39.000 --> 20:42.000
Maybe they've read your name wrong on the form or the person who told you they thought you

20:42.000 --> 20:45.000
got it meant speaks the other person, but it turns out the other guy actually gets the

20:45.000 --> 20:46.000
job.

20:46.000 --> 20:51.000
But just by sheer coincidence, he also has 10 coins in his pocket.

20:51.000 --> 20:57.000
The question is, did you know that the person who would get the job would have 10 coins

20:57.000 --> 20:58.000
in his pocket?

20:58.000 --> 21:04.000
You have a justified, true belief that the person who gets the job would have 10 coins

21:04.000 --> 21:08.000
in his pocket, but it seems in this circumstance, you didn't know that.

21:08.000 --> 21:09.000
That just seems wrong.

21:09.000 --> 21:10.000
Seems like a wrong account.

21:10.000 --> 21:14.000
It's a bit of a sort of clunky example and he gives another one which is also maybe a

21:14.000 --> 21:21.000
little bit clunky, but this sort of sparks this type of affair called a Gettier case.

21:21.000 --> 21:27.000
Well, you told me, I think over dinner, the best Gettier case, which was the person behind

21:27.000 --> 21:28.000
the hedge.

21:28.000 --> 21:29.000
Yes.

21:29.000 --> 21:30.000
So this is better.

21:30.000 --> 21:31.000
I think so.

21:31.000 --> 21:32.000
So I think it's actually better.

21:32.000 --> 21:34.000
Firstly, it's better to experience them for yourself and there are simpler explanations

21:34.000 --> 21:35.000
as well.

21:35.000 --> 21:41.000
So I was in a car driving around a bend and over the hedge, I see this small child sort

21:42.000 --> 21:46.000
of bouncing up and down behind the hedge and I thought to myself, oh, cool.

21:46.000 --> 21:47.000
I'm about to see a horse.

21:47.000 --> 21:50.000
I mean, it looked like the kid was riding a horse and I was like, yeah, cool.

21:50.000 --> 21:56.000
We're going to see a horse and we ride around this bend and the kid was actually on his

21:56.000 --> 22:01.000
or her like dad's back and that's why she was high up and bouncing up and down.

22:01.000 --> 22:07.000
But just by sheer coincidence in the field behind them was a horse and I couldn't believe

22:07.000 --> 22:08.000
it.

22:08.000 --> 22:09.000
I thought I've just experienced a Gettier case.

22:09.000 --> 22:12.000
I had a justified true belief that I was about to see a horse.

22:12.000 --> 22:16.000
The difficulty with that one is that it's probably not justified to believe that I was

22:16.000 --> 22:18.000
about to see a horse because I probably should have thought that it could have been a father.

22:18.000 --> 22:21.000
But a much more simple example and this actually happened to me once.

22:21.000 --> 22:26.000
I was in the US Capitol building in the crypt and they had the clock that used to be in

22:26.000 --> 22:31.000
the house of representatives and they said that the reason they replaced it and brought

22:31.000 --> 22:33.000
it down here was because they were fed up of winding it up.

22:33.000 --> 22:35.000
They didn't want to wind it anymore.

22:35.000 --> 22:38.000
And I looked at it and I asked the tour guide lady.

22:38.000 --> 22:40.000
I said, well, do they still wind it while it's down here?

22:40.000 --> 22:41.000
And she said, no.

22:41.000 --> 22:45.000
And I thought, but it's the real, it's the time.

22:45.000 --> 22:47.000
It says the time right now.

22:47.000 --> 22:50.000
And she was like, oh, yeah, it must be a coincidence.

22:50.000 --> 22:53.000
And I was like the only one looking around like, hey, that's, that's pretty, that's pretty extraordinary.

22:53.000 --> 22:55.000
I mean, I guess it happens twice a day, right?

22:55.000 --> 22:56.000
But this is a Gettier case.

22:56.000 --> 23:00.000
If you, if your watch breaks, but you don't know that it's broken, you've got a reliable

23:00.000 --> 23:07.000
watch, but today it's broken and you look at the time and it stopped on half past three.

23:07.000 --> 23:09.000
And so you look at it and you think, oh, it must be half past three.

23:09.000 --> 23:11.000
And it does actually just so happen to be half past three.

23:11.000 --> 23:13.000
Did you know it was half past three?

23:13.000 --> 23:15.000
That's a Gettier case.

23:15.000 --> 23:17.000
Justified true belief.

23:17.000 --> 23:20.000
And yet it seems weird to say that you, that you know it.

23:20.000 --> 23:25.000
So Gettier's revelation here was something like what you're talking about.

23:25.000 --> 23:28.000
A sort of genuine novelty in the history of philosophy.

23:28.000 --> 23:30.000
And they come about quite rarely, but they, they do occur.

23:30.000 --> 23:33.000
This episode is brought to you by Element.

23:33.000 --> 23:37.000
Element is a tasty electrolyte drink mix with everything that you need and nothing that

23:37.000 --> 23:38.000
you don't.

23:38.000 --> 23:40.000
It's a healthy alternative to sugary electrolyte drinks.

23:40.000 --> 23:44.000
It's got a science-backed electrolyte ratio of sodium, potassium and magnesium.

23:44.000 --> 23:47.000
You might ask, what do I want with an electrolyte drink?

23:47.000 --> 23:49.000
Well, it'll regulate your appetite.

23:49.000 --> 23:50.000
It'll curb cravings.

23:50.000 --> 23:51.000
It'll help improve your brain function.

23:51.000 --> 23:53.000
And best of all, it tastes phenomenal.

23:53.000 --> 23:58.000
First thing in the morning, this orange element salt in water is outstanding.

23:58.000 --> 24:02.000
Your adenosine system that caffeine acts on isn't even active for the first 90 minutes

24:02.000 --> 24:03.000
of the day.

24:03.000 --> 24:04.000
So it's pointless having a morning coffee.

24:04.000 --> 24:07.000
Your adrenal system, which is what salt acts on, is active.

24:07.000 --> 24:10.000
So this will make you feel more alert, more awake and improve your hydration.

24:10.000 --> 24:14.000
Best of all, they've got a no BS, no questions asked refund policy.

24:14.000 --> 24:15.000
So you can buy it.

24:15.000 --> 24:18.000
And if you do not like it for any reason, they will give you your money back.

24:18.000 --> 24:19.000
That's how confident they are that you love it.

24:19.000 --> 24:25.000
Head to drinklmnt.com slash modern wisdom to get a free sample pack of all eight flavors

24:25.000 --> 24:26.000
with your first box.

24:26.000 --> 24:31.000
That's drinklmnt.com slash modern wisdom.

24:31.000 --> 24:35.000
What happens downstream from that in the world of philosophy?

24:35.000 --> 24:37.000
Just a massive migraine, basically.

24:37.000 --> 24:42.000
People start coming up with arguments, responses, you know, so people start saying,

24:42.000 --> 24:43.000
Oh, maybe it's not justified to believe.

24:43.000 --> 24:49.000
Maybe it's like causally related justification to the cause of the

24:49.000 --> 24:55.000
But presumably kind of in the same way that I guess a new scientific discovery is made

24:55.000 --> 24:59.000
about the way that we metabolize glucose or about what happens if you take this amount

24:59.000 --> 25:04.000
of nicotine or the role of metformin in preventing high blood pressure or something.

25:04.000 --> 25:09.000
They're stacked on top of that one assumption, a number of other assumptions.

25:09.000 --> 25:13.000
But with philosophy, especially something I imagine like the philosophy of knowledge,

25:13.000 --> 25:21.000
it's so foundational that having this entire universe built on this particular foundation

25:21.000 --> 25:26.000
then means that the entire house of cards collapses down and people then need to rebuild

25:26.000 --> 25:28.000
all of this nightmare on top of it.

25:28.000 --> 25:29.000
Yeah.

25:29.000 --> 25:32.000
Well, most of philosophy is just a consistency test as it is in something like mathematics.

25:32.000 --> 25:36.000
It's just that we accept that there are certain axioms that even even mathematical axioms,

25:36.000 --> 25:39.000
you know, you can you can you can question them.

25:39.000 --> 25:49.000
I mean, Veritasium just made a quite good video about Euclidean geometry and how it sort of

25:49.000 --> 25:55.000
just accepted for a very long time that for example, you know, if you have a right angle,

25:56.000 --> 26:01.000
then if you sort of join up the two lines coming off that right angle, you'll create a triangle

26:01.000 --> 26:04.000
whose interior angles add up to 180 degrees.

26:04.000 --> 26:11.000
And then people start thinking about what about like curved geometric spaces?

26:11.000 --> 26:12.000
What if you do this on a globe?

26:12.000 --> 26:16.000
If you put a triangle on a globe, the angles aren't going to add up in that way.

26:16.000 --> 26:23.000
And these these are sort of like axioms of mathematics that essentially they don't necessarily get proved wrong

26:23.000 --> 26:26.000
or thrown out, but people realize that you can think about things differently.

26:26.000 --> 26:29.000
And so most of what we're doing is actually just testing for consistency.

26:29.000 --> 26:35.000
And so it's actually quite difficult to prove an axiom wrong because you kind of need an axiom just to get off the ground.

26:35.000 --> 26:38.000
And the rest of everything you're doing is just consistency tests with that axiom.

26:38.000 --> 26:42.000
This is one of the most interesting things I learned from you, maybe in the first ever episode that we did,

26:42.000 --> 26:49.000
as you were teaching me about the difference between ethics and matter ethics as someone that isn't formally trained in either.

26:50.000 --> 26:52.000
And you I use this all the time.

26:52.000 --> 26:58.000
It's such an interesting mental model to think that in order for me and you to have a discussion about ethics,

26:58.000 --> 27:05.000
our meta ethical foundation, we need to agree on that because out of that, if we don't,

27:05.000 --> 27:11.000
the entire ethical discussion on top will just continue to fall back to definitional problems

27:11.000 --> 27:16.000
and what you're presuming that so you can't discuss the stuff that happens on top

27:16.000 --> 27:18.000
unless you discuss the stuff that's underneath.

27:18.000 --> 27:21.000
And this is it's the entirety of the trans debate, right?

27:21.000 --> 27:30.000
It's the entirety of lexical overwhelm that if you can't agree on the definition of words,

27:30.000 --> 27:37.000
the argument about the words and what they then refer to just collapses in on itself

27:37.000 --> 27:41.000
and continuously just falls back to an argument about the definition of words.

27:41.000 --> 27:45.000
Yes, this happens with, for example, freedom.

27:45.000 --> 27:51.000
There are lots of different ways of conceiving of freedom, famously freedom from and freedom to, right?

27:51.000 --> 27:57.000
Is freedom just being left alone or is freedom being empowered to do things that you should be able to do?

27:57.000 --> 28:00.000
And then when you have people arguing about nationalised healthcare, for example,

28:00.000 --> 28:04.000
one person says to be free, you need to be healthy.

28:04.000 --> 28:08.000
And one person says to be free, you need to spend your own money as you please

28:08.000 --> 28:10.000
and not be forced to fund other people's healthcare now.

28:10.000 --> 28:13.000
Both of these people can be right, they're just defining freedom differently.

28:13.000 --> 28:15.000
So you're quite right.

28:15.000 --> 28:17.000
And that's why metaethics is quite important.

28:17.000 --> 28:23.000
I mean, AJA I pointed out in Language, Truth and Logic that the vast majority of ethical debate is not ethical debate.

28:23.000 --> 28:25.000
It's descriptive debate, it's factual debate.

28:25.000 --> 28:29.000
If you look at the so-called ethical debate around gun laws in America, for example,

28:29.000 --> 28:31.000
people are talking about statistics.

28:31.000 --> 28:33.000
They're saying X many people die per year.

28:33.000 --> 28:36.000
Oh, well, don't you know that more children are killed by swimming pools?

28:37.000 --> 28:43.000
Don't you know that if we ban certain types of weapons or blah, blah, blah,

28:43.000 --> 28:49.000
that this many less people will die, all these kind of things are just descriptive factual statements

28:49.000 --> 28:51.000
that people like to dispute with each other.

28:51.000 --> 28:53.000
And that's why they like to say we have the facts on our side.

28:53.000 --> 29:00.000
But the actual ethical question that undergirds it all is hardly ever even reached.

29:00.000 --> 29:03.000
And so most of the time people are actually arguing about that.

29:03.000 --> 29:05.000
I mean, the same thing with an abortion debate, for example.

29:05.000 --> 29:08.000
You know, questions about biology, when does consciousness emerge?

29:08.000 --> 29:12.000
Can it survive on its own outside of the womb this week or this week?

29:12.000 --> 29:13.000
You know, this kind of stuff.

29:13.000 --> 29:17.000
Will it increase the number of women who die or decrease the number of women who die?

29:17.000 --> 29:19.000
But none of these are ethical questions.

29:19.000 --> 29:23.000
And people think they're having an ethical debate when they're actually just having a debate about facts

29:23.000 --> 29:26.000
that can be resolved in principle by scientific empirical inquiry.

29:26.000 --> 29:30.000
The ethical question is the more interesting one that's often assumed.

29:30.000 --> 29:33.000
And if people think that they agree with each other

29:33.000 --> 29:36.000
or understand each other in the same way on that ethical first point,

29:36.000 --> 29:39.000
then you're in for a disaster.

29:39.000 --> 29:41.000
If they don't, I mean.

29:41.000 --> 29:45.000
Yeah, what do you wish that more people could realize

29:45.000 --> 29:50.000
when it comes to understanding ethics and consistency in their own lives?

29:50.000 --> 29:55.000
Is there something that a little red pill or a particular insight that you wish you could deposit

29:55.000 --> 29:58.000
into the mind of the populace that you think would make their lives a little bit more easy

29:58.000 --> 30:00.000
or the sense making a bit more simple?

30:00.000 --> 30:05.000
I didn't know about making lives easier, but I do think that people should recognize

30:05.000 --> 30:09.000
the extent to which emotions dominate our ethical thinking.

30:09.000 --> 30:12.000
I mean, I take a...

30:12.000 --> 30:16.000
I think it's seen as a relatively eccentric view that ethics just is the expression of emotion.

30:16.000 --> 30:21.000
This was something popularized by that same AJ Ayer in a book that was so troubling

30:21.000 --> 30:24.000
to the philosophical consensus at the time that there's a story of,

30:24.000 --> 30:26.000
I think it was like a...

30:26.000 --> 30:29.000
maybe a dean of Balliol College or something who when a student came in,

30:29.000 --> 30:32.000
everybody wanted to talk about this book and they were so scared of the implications of it

30:32.000 --> 30:36.000
that he literally throws it out of the window because he just doesn't want to talk about it.

30:36.000 --> 30:41.000
Ayer is talking about how the only things that can be meaningful are those which are

30:41.000 --> 30:44.000
analytically true or empirically verifiable.

30:44.000 --> 30:48.000
If the statement you're making isn't something you can, at least in principle,

30:48.000 --> 30:52.000
test empirically or something that's just a tautology, two and two is four,

30:52.000 --> 30:54.000
then what you're saying is literally meaningless.

30:54.000 --> 30:56.000
And people came to him and said, well, what about ethical statements?

30:56.000 --> 30:59.000
You can't prove these in principle and they're not tautological.

30:59.000 --> 31:05.000
And he said, well, the way that they're meaningful is that they are expressions of emotion.

31:05.000 --> 31:08.000
And it gives birth to this view called emotivism,

31:08.000 --> 31:11.000
which is really a philosophy of language more than a philosophy of ethics.

31:11.000 --> 31:16.000
It tries to describe what people mean when they say good or bad.

31:16.000 --> 31:20.000
And famously, he comes up with this analogy that saying murder is wrong.

31:20.000 --> 31:22.000
It's like saying boo murder.

31:22.000 --> 31:26.000
And saying murder is giving to charity as good as like saying yay charity.

31:26.000 --> 31:28.000
It's just an expression of emotion.

31:28.000 --> 31:31.000
It's not even the same thing as saying I like charity or I don't like murder

31:31.000 --> 31:33.000
because those things can be true or false.

31:33.000 --> 31:34.000
They have truth value.

31:34.000 --> 31:38.000
It could be true that it is just a psychological fact that I don't like murder.

31:38.000 --> 31:39.000
He means murder is wrong that statement.

31:39.000 --> 31:43.000
It's just the expression of the emotion, boo murder.

31:43.000 --> 31:48.000
And I think even if you don't agree with him to that extent, as I more or less do,

31:48.000 --> 31:53.000
if you begin to recognize the extent to which emotions are dominating your ethical conduct,

31:53.000 --> 31:58.000
pay attention to what it feels like when you analyze something as wrong.

31:58.000 --> 32:01.000
I think it belongs in the same category as-

32:01.000 --> 32:02.000
Because you've got this sort of-

32:02.000 --> 32:03.000
Emotion.

32:03.000 --> 32:08.000
Sweet of a soup of stimulus going on inside of you.

32:08.000 --> 32:11.000
What is it like to feel like something is wrong?

32:11.000 --> 32:17.000
And we know that people seem to change what they rationally do based on how they're feeling.

32:17.000 --> 32:19.000
I mean, I don't know if you've come across terror management theory before.

32:19.000 --> 32:20.000
It surprised me if you hadn't.

32:20.000 --> 32:25.000
The idea that all human beings are doing is trying to manage their fear of death.

32:25.000 --> 32:28.000
And that's what motivates all human activity.

32:28.000 --> 32:31.000
And there have been some interesting studies and some of them are harder to replicate than others.

32:31.000 --> 32:38.000
But I mean, the first one, the most famous was some, I think, Arizona state judges.

32:38.000 --> 32:44.000
And they were being asked to recommend a bond for the solicitation of prostitution.

32:45.000 --> 32:50.000
And what the researchers did was they asked them to fill out just a form first.

32:50.000 --> 32:55.000
And on half of the forms, they just mentioned death.

32:55.000 --> 32:57.000
They just put in a few questions about death.

32:57.000 --> 32:59.000
What do you think happens after death?

32:59.000 --> 33:00.000
Who would you put in your will?

33:00.000 --> 33:01.000
That kind of stuff.

33:01.000 --> 33:03.000
Nothing too extreme.

33:03.000 --> 33:08.000
And they found that the bond that was set by the judges-

33:08.000 --> 33:12.000
I mean, I think the average bond for the control group was less than $100.

33:12.000 --> 33:16.000
And for the ones who were reminded of their death was my $200 or $300 on average.

33:16.000 --> 33:18.000
What does that imply?

33:18.000 --> 33:24.000
So the interpretation of terror management theory was that when we're reminded of our deaths,

33:24.000 --> 33:31.000
we need to temporarily, more heavily reaffirm the sort of death-denying aspects of our culture.

33:31.000 --> 33:35.000
The reason that we do things, the reason we create art, the reason that we get out of bed,

33:35.000 --> 33:41.000
the reason that we have conversations like this is because in some way it's traceable back to trying to essentially deny our own death.

33:41.000 --> 33:43.000
Ernest Bakker wrote a book called The Denial of Death.

33:43.000 --> 33:46.000
And this is essentially the idea.

33:46.000 --> 33:49.000
And so for judges, it might be something like by participating in the legal system,

33:49.000 --> 33:55.000
they're participating in something that's a bit beyond them and therefore it exists outside of their own mortality.

33:55.000 --> 34:02.000
And so the thesis, this mortality salience hypothesis as it's known, is that for a judge,

34:02.000 --> 34:10.000
if they're reminded of their own death, what they will temporarily be compelled to do is more harshly reaffirm that thing

34:10.000 --> 34:15.000
that is the death-denying aspects of their daily life, which is participation in the legal system,

34:15.000 --> 34:17.000
so more harsh penalties.

34:17.000 --> 34:20.000
Now, the explanation seems a little bit tenuous.

34:20.000 --> 34:25.000
I'm not sure about that, but it does seem strange that when you remind people of their own death,

34:25.000 --> 34:32.000
they will, like Muslims will become more derogatory towards Jews.

34:32.000 --> 34:36.000
People of different nationalities will sit further away from each other.

34:37.000 --> 34:42.000
When asked to draw pictures of currency, it will draw physically larger pictures of currency.

34:42.000 --> 34:49.000
People's opinion on whether they prefer a picture of a forest or a picture of suburban neighborhood will change on average.

34:49.000 --> 34:53.000
These things are extraordinary, just from being reminded of your own death.

34:53.000 --> 34:59.000
Of course, the biggest manifestation of the denial of death would be religion.

34:59.000 --> 35:08.000
That would also explain why religion deals a lot with death and why if you remind people of their own death,

35:08.000 --> 35:12.000
they also become religious, which by the way is true of atheists as well.

35:12.000 --> 35:15.000
People who don't believe in God will still become more religious,

35:15.000 --> 35:20.000
even if they don't ultimately believe in God when reminded of their own death.

35:21.000 --> 35:28.000
I've been thinking a good bit recently about how people do an awful lot,

35:28.000 --> 35:32.000
especially in the modern world, that is death denialism masquerading as something else.

35:32.000 --> 35:35.000
I think the productivity movement very much is that.

35:35.000 --> 35:38.000
Trying to fit more into less time.

35:38.000 --> 35:44.000
If only I could get more life, more work, more output out of my one unit of days or whatever.

35:44.000 --> 35:50.000
I think that a good chunk of the health and fitness world, the longevity movement, the biohacking movement,

35:50.000 --> 35:53.000
all of that is absolutely death denialism.

35:53.000 --> 35:59.000
And you can see as well, nutrition, all of the arguments about is it better for me to be carnivore or vegan?

35:59.000 --> 36:01.000
Should I go high carb or low carb?

36:01.000 --> 36:02.000
Can I do intermittent fasting?

36:02.000 --> 36:05.000
Should I be using ketones exogenously?

36:06.000 --> 36:14.000
Ultimately, the reason that I think these arguments are so vehement and passionate,

36:14.000 --> 36:18.000
especially when you think it's diet, guys, right?

36:18.000 --> 36:19.000
It's diet.

36:19.000 --> 36:25.000
It's like, I want to have aspartame, you want to have sugar.

36:25.000 --> 36:30.000
How does my aspartame consumption impact your sugar consumption?

36:30.000 --> 36:39.000
But what it hits at for a lot of people is a certainty about I can predict and project out into the future

36:39.000 --> 36:43.000
how long I'm going to be able to live or die and I'm going to be able to compare myself to this other person.

36:43.000 --> 36:53.000
And their conviction in their particular approach, which derogates my approach implicitly,

36:53.000 --> 36:57.000
suggests to me, you're going to die sooner.

36:57.000 --> 36:59.000
And that causes me to be fucking terrified.

36:59.000 --> 37:03.000
And it's the same reason why people are so, how long do you need to do?

37:03.000 --> 37:05.000
It's not VO2 max that's most important.

37:05.000 --> 37:06.000
It's HRV.

37:06.000 --> 37:07.000
It's resting heart rate.

37:07.000 --> 37:08.000
It's not its galvanic skin temperature.

37:08.000 --> 37:09.000
We're not looking at that.

37:09.000 --> 37:10.000
We're looking at telomere length.

37:10.000 --> 37:11.000
We're not looking at that.

37:11.000 --> 37:12.000
It's whatever.

37:12.000 --> 37:15.000
All of the things, you know, the entire field of health and fitness, which I'm a big part of,

37:15.000 --> 37:21.000
I think is a good chunk of it is death denialism, just masquerading as getting big biceps.

37:21.000 --> 37:22.000
Yes.

37:22.000 --> 37:25.000
So sometimes it is more obvious.

37:25.000 --> 37:30.000
I think we need more nihilist health influences who will sort of say, you know,

37:30.000 --> 37:35.000
when the question is asked, you know, should you eat white bread or brown bread or whatever it is,

37:35.000 --> 37:37.000
you know, that they'll sort of begin with the question.

37:37.000 --> 37:41.000
It sort of depends on your views on the intrinsic value of life.

37:41.000 --> 37:47.000
Also, if you're a bit of a utilitarian, I mean, people often say that being unhealthy might be unethical

37:47.000 --> 37:52.000
because in a country with nationalised healthcare, you're a burden.

37:52.000 --> 37:54.000
But are you?

37:54.000 --> 38:00.000
I mean, who costs the taxpayer more, the person who eats a bunch of burgers

38:00.000 --> 38:03.000
and has a heart attack and dies instantly, or the person who lives into old age

38:03.000 --> 38:06.000
and therefore has some kind of long-term health problem like Alzheimer's.

38:06.000 --> 38:08.000
I need to, I need to interject here.

38:08.000 --> 38:14.000
So you ring me probably three years ago, four years ago, you ring me and I'm in the gym.

38:14.000 --> 38:17.000
And you say something like, what are you doing?

38:17.000 --> 38:18.000
So I come in the gym.

38:18.000 --> 38:19.000
What are you doing?

38:19.000 --> 38:20.000
Oh, just whatever.

38:20.000 --> 38:21.000
Whatever.

38:21.000 --> 38:22.000
Catch up a little bit.

38:22.000 --> 38:23.000
I was like, what's going on?

38:23.000 --> 38:27.000
And you said, I'm trying nihilism.

38:27.000 --> 38:30.000
And I said, what do you mean?

38:30.000 --> 38:34.000
And you went, as a life philosophy, I'm trying nihilism.

38:34.000 --> 38:36.000
And I still don't know what you mean.

38:36.000 --> 38:43.000
So how is your experiment to make nihilism great again going?

38:43.000 --> 38:49.000
Well, I was getting a bit fed up of people saying, oh, you're a nihilist.

38:49.000 --> 38:50.000
Oh, you're an atheist.

38:50.000 --> 38:51.000
They wouldn't say it in the terms of nihilism.

38:51.000 --> 38:53.000
They'd say, oh, you're an atheist.

38:53.000 --> 38:54.000
Yeah, right.

38:54.000 --> 38:55.000
Yeah.

38:55.000 --> 39:01.000
I mean, there was a cliff of Jordan Peterson on the Lex Friedman podcast.

39:01.000 --> 39:06.000
And he says, oh, you're secular and you go to art galleries.

39:06.000 --> 39:07.000
Yeah.

39:07.000 --> 39:09.000
Well, what makes you think you're secular?

39:09.000 --> 39:10.000
And the head turn is real.

39:10.000 --> 39:11.000
He does that.

39:11.000 --> 39:16.000
I thought to myself, what on earth are you talking about, man?

39:16.000 --> 39:18.000
Do you think you can't be an atheist and enjoy art?

39:18.000 --> 39:20.000
Now, I tried my best to understand what he was getting at.

39:20.000 --> 39:25.000
And I think he was trying to basically say that in order to enjoy art,

39:25.000 --> 39:27.000
you need to have some kind of value.

39:27.000 --> 39:30.000
And in order to have any kind of surface level value,

39:30.000 --> 39:32.000
you can always ask the why that question.

39:32.000 --> 39:34.000
Why do you value this?

39:34.000 --> 39:38.000
The classic sort of why do you go to school to get a good grade?

39:38.000 --> 39:39.000
Well, you don't just want the grade.

39:39.000 --> 39:40.000
Why do you get the grade?

39:40.000 --> 39:42.000
You do it to get a good job and so on and so forth.

39:42.000 --> 39:43.000
Happens with value.

39:43.000 --> 39:45.000
And so why do you value art?

39:45.000 --> 39:47.000
Because maybe you value beauty or something.

39:47.000 --> 39:50.000
And Peterson's whole thing is that whatever's at the top of this value hierarchy

39:50.000 --> 39:52.000
is in his definition divine.

39:52.000 --> 39:54.000
He just defines it as such.

39:54.000 --> 39:59.000
And so he essentially said that people claim that they are nihilists,

39:59.000 --> 40:01.000
but they don't live like that.

40:01.000 --> 40:03.000
I thought, well, what would it mean to really live like a nihilist?

40:03.000 --> 40:06.000
And I guess I tried it on for size,

40:06.000 --> 40:12.000
but he's right into the extent that I think most people don't live like they're nihilists.

40:12.000 --> 40:15.000
What would the definition of living like a nihilist be?

40:15.000 --> 40:22.000
I think it would just mean the rejection of any such thing as a non-contingent reason for acting.

40:22.000 --> 40:24.000
Be more accessible.

40:24.000 --> 40:31.000
You would need to really think that there's no reason to do anything

40:31.000 --> 40:35.000
outside of essentially your crude preferences in biological drives.

40:35.000 --> 40:36.000
Right.

40:36.000 --> 40:42.000
And I think the reason why people think that nihilism is unlivable

40:42.000 --> 40:47.000
is because they have this image of somebody just immediately becoming a Raskolnikov type figure

40:47.000 --> 40:49.000
and just committing a murder or something.

40:49.000 --> 40:52.000
But they forget that these people still have their memory.

40:52.000 --> 40:55.000
They're going to be embedded in a culture and an upbringing

40:55.000 --> 40:58.000
that their preferences are essentially still going to be aligned.

40:58.000 --> 41:01.000
I mean, Pendulet was once asked, if you're an atheist,

41:01.000 --> 41:06.000
why don't you kill and assault every person you want to?

41:06.000 --> 41:10.000
And he says, I do, I do kill and assault everybody I want to,

41:10.000 --> 41:12.000
which is precisely nobody.

41:12.000 --> 41:15.000
And very clever, gets a bit of an applause.

41:15.000 --> 41:19.000
But I mean, the difficult question ethically is what happens when somebody doesn't have that view?

41:19.000 --> 41:21.000
What happens when somebody does just disagree with you?

41:21.000 --> 41:23.000
But I don't know, it was kind of boring.

41:23.000 --> 41:30.000
Just to interject that, so you could see the meaning-making machine of society and cultural norms

41:30.000 --> 41:35.000
as being useful to constrain the behavior of those outlier people,

41:35.000 --> 41:39.000
the ones who would go out and commit the litany of mass murders.

41:39.000 --> 41:44.000
But mum told me that I'm not supposed to squash bugs when I was five years old

41:44.000 --> 41:46.000
and this is now carried on through.

41:46.000 --> 41:51.000
But yeah, I think for most people, we are the descendants of the people who avoided,

41:51.000 --> 41:54.000
at least for the most part, killing people that were close to us.

41:54.000 --> 41:57.000
And we feel a lot of the time like we're now close to each other.

41:57.000 --> 42:00.000
Yes, yes.

42:00.000 --> 42:02.000
I think that's probably true.

42:02.000 --> 42:08.000
The issue is that the more that we try to explain away these mechanisms,

42:09.000 --> 42:16.000
we try to understand why in our evolutionary history we might have evolved certain moral taboos,

42:16.000 --> 42:18.000
this kind of stuff.

42:18.000 --> 42:21.000
It begins to essentially take the complete ethical force out of it

42:21.000 --> 42:24.000
and that's what people think leads to leads to nihilism.

42:24.000 --> 42:29.000
Once you have fully explained why something would be considered immoral,

42:29.000 --> 42:34.000
just on evolutionary grounds, you've essentially taken out the moral factor altogether

42:34.000 --> 42:37.000
and you're explaining it in terms of genetic preference.

42:37.000 --> 42:39.000
Yeah, there's no more meaning.

42:39.000 --> 42:43.000
There's no additional fluff or feeling of anything.

42:43.000 --> 42:46.000
But this is, you know, I've spent a lot of time over the last few years

42:46.000 --> 42:49.000
talking to evolutionary psychologists, evolutionary biologists,

42:49.000 --> 42:54.000
people that have looked at the evolution of culture as well from a mimetic standpoint too.

42:54.000 --> 43:06.000
And it does seem to me that culture is just like exclusively an adaptive response to coordination at large scale

43:06.000 --> 43:13.000
and that all of the things that are encoded in that are effective ways for your tribe to not blow itself up.

43:13.000 --> 43:15.000
Would you say the same thing about morality in general?

43:15.000 --> 43:16.000
Yes.

43:16.000 --> 43:22.000
So then how do you escape this nihilist conundrum that you think all it is,

43:22.000 --> 43:27.000
you know, the reason why you're not killing people is just because you sort of evolved that way.

43:27.000 --> 43:29.000
Doesn't that kind of take out some of the meaning?

43:29.000 --> 43:38.000
So I think if you are permanently self-assessing why you do the things you do and the inputs that you feel,

43:38.000 --> 43:43.000
but what that doesn't account for is the fact that we are self-deceptive.

43:43.000 --> 43:44.000
Quite right, yeah.

43:44.000 --> 43:48.000
And the sense of being a human is one that is imbued with meaning.

43:48.000 --> 43:54.000
I often use this term about how you are not personally cursed as a reassurance.

43:54.000 --> 43:56.000
And it was something that was reassuring to me.

43:56.000 --> 44:00.000
If I was spending a bit of time where I was feeling sad or down or whatever,

44:00.000 --> 44:03.000
it would feel like whatever emotion I was going through,

44:03.000 --> 44:06.000
whatever unpleasant emotion I was going through was like a personal curse.

44:06.000 --> 44:11.000
And this makes sense when you look back at how the gods were personified as different sorts of emotions, right?

44:11.000 --> 44:18.000
That, you know, keep it had an arrow that hit you or that, you know, you had gods of war, you had gods of wrath,

44:18.000 --> 44:20.000
you had gods of envy, you had gods of narcissism.

44:20.000 --> 44:30.000
Because the experience of a thing, of a thought, of an emotion, of a state is not just the confused chemical signals of your body.

44:30.000 --> 44:32.000
And now I can just reverse engineer this.

44:32.000 --> 44:39.000
Even the interest, the interaction of you and whatever's going on in the social group around you isn't just that.

44:39.000 --> 44:44.000
It's imbued with meaning because you interpret things in this soup of experience,

44:44.000 --> 44:48.000
which scales things up from just what's happening to,

44:48.000 --> 44:52.000
and it feels like there's something, it feels like there's some there, there, right?

44:52.000 --> 44:56.000
Yes. Yeah, yeah, you can't escape that illusion if it is an illusion.

44:56.000 --> 45:02.000
This is another thing that I spoke to Ben about first name, first name basis it seems now.

45:02.000 --> 45:03.000
Mr. Shapiro.

45:03.000 --> 45:04.000
I did try that.

45:04.000 --> 45:08.000
And, you know, when I was emailing back and forth about setting up that event,

45:08.000 --> 45:14.000
I went to type out sort of like, well, it would be great to talk to Mr. Shapiro about, it just didn't feel right.

45:14.000 --> 45:16.000
I just couldn't bring myself to do it.

45:16.000 --> 45:19.000
At least not behind his back, not say that I'm rude behind his back,

45:19.000 --> 45:22.000
but it felt even weirder that he wasn't there to sort of appreciate the courtesy.

45:22.000 --> 45:28.000
Anyway, he said, like, you know, that I don't believe in free will.

45:28.000 --> 45:30.000
I don't know if you believe in free will, perhaps we can talk about that.

45:30.000 --> 45:35.000
He's like, look, you don't believe in free will, but you act as if free will does exist all the time.

45:35.000 --> 45:39.000
And I remember thinking, what do you mean?

45:39.000 --> 45:44.000
What does it look like to act as though free will doesn't exist?

45:44.000 --> 45:52.000
The very argument or one of the arguments against free will is that you are essentially driven by your biology,

45:52.000 --> 45:57.000
your genes, your will, you know, the Arthur Schopenhauer line that you can do what you will.

45:57.000 --> 45:59.000
You just can't will what you will.

45:59.000 --> 46:00.000
In fact, you have to do what you will.

46:00.000 --> 46:03.000
That's what drives behavior.

46:03.000 --> 46:10.000
If that's the case, then why do you have this vision in your head that if you lack a belief in free will,

46:10.000 --> 46:12.000
you're like not going to get out of bed in the morning.

46:12.000 --> 46:16.000
The very argument is that you will get out of bed in the morning because you desire to go and get some breakfast.

46:16.000 --> 46:18.000
That's like the whole point.

46:18.000 --> 46:22.000
And so any argument of that form of people say, well, you don't live like that's the case.

46:22.000 --> 46:26.000
I was like to think, well, what would it look like to you then?

46:26.000 --> 46:32.000
You know, if I could ask Jordan Peterson when he says the way you don't live like an atheist, what would that look like to you?

46:32.000 --> 46:40.000
I don't know if he might say something like, well, you'd probably be this morally depraved, you know, self-interested, blah, blah, blah.

46:40.000 --> 46:42.000
Like maybe, but is that really what you think?

46:42.000 --> 46:43.000
I mean, I don't know.

46:43.000 --> 46:51.000
Yeah, I think it forgets the fact that you are a product of your time, regardless of your beliefs from that time.

46:51.000 --> 46:52.000
Right?

46:52.000 --> 46:58.000
I understand the Judeo-Christian values that everything is based on, you know, it's like a common talking point from those guys.

46:58.000 --> 47:08.000
But okay, how am I supposed to extricate me from that completely shake the etch-a-sketch of my value set and then take it from the beginning?

47:08.000 --> 47:14.000
And let's not forget, like a lot of those values have grown out of what would have been an adaptive response in any case.

47:14.000 --> 47:15.000
Yeah.

47:15.000 --> 47:17.000
So the illusion is there.

47:17.000 --> 47:18.000
The illusion is unshakable.

47:18.000 --> 47:23.000
And so it sort of is a bit senseless to me to us, particularly on the free will thing.

47:23.000 --> 47:26.000
Like, oh, why don't you act like free will doesn't exist?

47:26.000 --> 47:28.000
What do you mean?

47:28.000 --> 47:30.000
I literally, it's unintelligible to me.

47:30.000 --> 47:32.000
Did you listen to my Sapolsky episode yet?

47:32.000 --> 47:33.000
No, I didn't think so.

47:33.000 --> 47:37.000
So his new book determined the science of life without free will.

47:38.000 --> 47:41.000
Every time that I talk about free will, people get upset.

47:41.000 --> 47:42.000
Why is that?

47:42.000 --> 47:44.000
That's the question for you.

47:44.000 --> 47:45.000
I think the reason-

47:45.000 --> 47:47.000
Insert joke about how it's not their fault.

47:47.000 --> 47:48.000
Yeah, yeah.

47:48.000 --> 47:53.000
It's like my least favorite genre of joke that's done in philosophy.

47:53.000 --> 47:54.000
Every single time.

47:54.000 --> 47:55.000
Every single time.

47:55.000 --> 47:56.000
Without fail.

47:57.000 --> 47:58.000
I don't know.

47:58.000 --> 47:59.000
I don't know.

47:59.000 --> 48:06.000
And it's something that the conversation about free will is such a turn off for people that I actively push it further into episodes.

48:06.000 --> 48:10.000
I actively don't title episodes that have got that in it.

48:10.000 --> 48:16.000
I can surreptitiously coax people into thinking about it.

48:16.000 --> 48:23.000
But the response is very, it's a high amount of dissatisfaction.

48:23.000 --> 48:25.000
People don't like to think about that.

48:25.000 --> 48:29.000
Now, it may be because it's dry.

48:29.000 --> 48:31.000
I'm open to that.

48:31.000 --> 48:32.000
That's true.

48:32.000 --> 48:37.000
It may be because it threatens their sense of agency and sovereignty,

48:37.000 --> 48:40.000
which is something I've kind of built this channel off the back of,

48:40.000 --> 48:45.000
like you can enact change within your own life, internalize your locus of control,

48:45.000 --> 48:47.000
stop being such a bitch, etc.

48:47.000 --> 48:56.000
And so maybe I'm a victim of my own foundation in that regard that I've selected for a particular group of people.

48:56.000 --> 48:58.000
But it's happened a few times.

48:58.000 --> 49:01.000
A few different conversations about it, tangential.

49:02.000 --> 49:06.000
One guy was a compatibility like quasi-compatibilist.

49:06.000 --> 49:09.000
Why are you shaking your head?

49:11.000 --> 49:15.000
That it's just the most ludicrous compromise to me.

49:15.000 --> 49:16.000
Compatibilism.

49:16.000 --> 49:20.000
Am I right in saying that compatibilism just kicks the can down the road

49:20.000 --> 49:22.000
and plays lexical overload with things?

49:22.000 --> 49:23.000
I think more or less.

49:23.000 --> 49:24.000
Right.

49:24.000 --> 49:27.000
A lot of the time you're just also dealing with essentially a redefinition of free will.

49:27.000 --> 49:28.000
It's water.

49:28.000 --> 49:29.000
I don't mean that.

49:29.000 --> 49:30.000
I mean this thing.

49:30.000 --> 49:34.000
Yeah, Sam Harris has called it the Atlantis fallacy.

49:34.000 --> 49:38.000
He had an extended argument with Daniel Dennett, a compatibilist about free will.

49:38.000 --> 49:43.000
And Daniel Dennett would talk about how this exists and this exists.

49:43.000 --> 49:46.000
And it sounds like, yeah, that's true.

49:46.000 --> 49:49.000
But you're just not talking about what people care about in free will.

49:49.000 --> 49:52.000
What you're doing is we're trying to ask if Atlantis exists.

49:52.000 --> 49:55.000
And you're pointing to Venice and you're saying, look, here's the city.

49:55.000 --> 49:59.000
It's got a lot of water and it's kind of old.

49:59.000 --> 50:03.000
And these are all true, but it's just not Atlantis.

50:03.000 --> 50:08.000
And what most people are talking about when they try to bring free will back into the discussion is just not free will.

50:08.000 --> 50:10.000
It's as straightforward as it gets in my view.

50:10.000 --> 50:15.000
I mean, there are versions of freedom that can be sensibly believed in.

50:15.000 --> 50:19.000
It kind of depends on what your conception of freedom means.

50:19.000 --> 50:21.000
But if you mean something like authorship over your actions,

50:21.000 --> 50:24.000
if you mean that we could have rewound the clock and I could have done something differently,

50:24.000 --> 50:26.000
but I could have won a different shirt.

50:26.000 --> 50:29.000
I don't think that the answer is yes.

50:29.000 --> 50:30.000
Logically, yes.

50:30.000 --> 50:31.000
You know, the possible worlds discussion earlier.

50:31.000 --> 50:33.000
There's a possible world where I'm in a different shirt,

50:33.000 --> 50:38.000
but I guess like physically, possibly metaphysically,

50:38.000 --> 50:39.000
I couldn't have made a different choice.

50:39.000 --> 50:45.000
Well, regardless of what you believe or don't believe about free will,

50:45.000 --> 50:48.000
the response, people's response to it is fascinating.

50:48.000 --> 50:50.000
Absolutely fascinating.

50:50.000 --> 50:55.000
And maybe, yeah, maybe it is that degree of control, almost like the denial of death.

50:55.000 --> 51:01.000
Like I wonder, have they done experiments on when people are reminded that they do

51:01.000 --> 51:03.000
or do not have free will that their behavior adjusts?

51:03.000 --> 51:06.000
Not that I know of, but I would love to see that because if it is,

51:06.000 --> 51:09.000
and maybe it is true, but I think if it is true,

51:09.000 --> 51:12.000
I can understand why it might be quite like fatalistic.

51:12.000 --> 51:16.000
I mean, it literally is quite fatalistic really to say that there's no freedom.

51:16.000 --> 51:19.000
And I can understand why that might make someone sad

51:19.000 --> 51:22.000
and that sadness might motivate their behaviors slightly differently.

51:22.000 --> 51:26.000
But I think that intrinsically, if there are a way to control for people

51:26.000 --> 51:28.000
who are sort of happy or sad about it,

51:28.000 --> 51:30.000
because you can believe in there's no free will and be like,

51:30.000 --> 51:32.000
thank goodness, it's all out of my hands.

51:32.000 --> 51:37.000
If you can control for that and show that people do, they are like less productive

51:37.000 --> 51:39.000
or they don't get out of bed as much,

51:39.000 --> 51:41.000
then I think that would be meaningful

51:41.000 --> 51:44.000
and it might be a sort of second order reason not to have this conversation.

51:44.000 --> 51:49.000
I don't know if there's been such a investigation as there has to death,

51:49.000 --> 51:53.000
which by the way, I think a good example of the death denial thing

51:53.000 --> 51:58.000
is to think about your magnum opus

51:58.000 --> 52:03.000
if you were sort of working on the great life work or something

52:03.000 --> 52:08.000
and you're about to die and then you're just about to sort of to finish it off.

52:08.000 --> 52:12.000
Suppose you found out that after you publish this and you die,

52:12.000 --> 52:16.000
a week later you found out that a meteor was going to come and destroy the earth.

52:16.000 --> 52:18.000
Everybody dies.

52:18.000 --> 52:22.000
Does that make you more or less enthusiastic about finishing your project?

52:22.000 --> 52:27.000
Now, for most people, I think, it's going to make them less enthusiastic.

52:27.000 --> 52:29.000
It would certainly make me less enthusiastic.

52:29.000 --> 52:31.000
But why? What's the difference to you?

52:31.000 --> 52:32.000
It doesn't make a difference.

52:32.000 --> 52:35.000
You're going to be dead beforehand anyway, nothing's going to change.

52:35.000 --> 52:40.000
Seems to suggest that maybe the desire to get this done

52:40.000 --> 52:43.000
before you die in the first place isn't just as people like to claim

52:43.000 --> 52:46.000
for the love of the art and it's all in the process.

52:46.000 --> 52:48.000
No, it's because here's a work that's going to outlive you.

52:48.000 --> 52:50.000
Here's something that's going to help you to escape your own death.

52:50.000 --> 52:54.000
And when faced with the inevitability of the destruction of even that,

52:54.000 --> 52:55.000
the motivation goes down.

52:55.000 --> 52:59.000
I wouldn't be surprised if simply reminding somebody who's writing a play or something

52:59.000 --> 53:05.000
that one day, heat death, everything evaporates including your new book

53:05.000 --> 53:08.000
if that would make them less motivated to finish the book.

53:08.000 --> 53:12.000
Which to me implies that the reverse corollary

53:12.000 --> 53:15.000
is that the reason you are making the book is in some way indebted

53:15.000 --> 53:18.000
to the fact that you think it will outlive you and therefore is an exercise

53:18.000 --> 53:19.000
in the denial of death.

53:19.000 --> 53:22.000
Didn't Ernest Becker die at an unfortunate time?

53:22.000 --> 53:24.000
I don't know much about his personal life.

53:24.000 --> 53:25.000
I think he did.

53:25.000 --> 53:30.000
But there are interesting coincidences like that dotted across a lot of...

53:30.000 --> 53:35.000
The thing about coincidences is that so many things happen all the time

53:35.000 --> 53:39.000
that the only extraordinary thing would be if there weren't some extraordinary things like that.

53:39.000 --> 53:42.000
Like Al Becker Mew was killed in a car crash

53:42.000 --> 53:45.000
and he was killed in a car crash with a train ticket in his pocket.

53:45.000 --> 53:48.000
So it seemed like he decided at the last minute to go in the car and said,

53:48.000 --> 53:53.000
and he had previously said that the most absurd way to die would be in an automobile accident.

53:53.000 --> 53:55.000
And that's how he dies.

53:55.000 --> 53:59.000
Sigmund Freud was terrified of...

53:59.000 --> 54:02.000
I think it was the number 63.

54:02.000 --> 54:03.000
It was like 63.

54:03.000 --> 54:05.000
Or maybe it was like 48.

54:05.000 --> 54:06.000
I can't remember.

54:06.000 --> 54:07.000
A number around that.

54:07.000 --> 54:08.000
He was just terrified of it.

54:08.000 --> 54:12.000
Had a real sort of foreboding about it for some reason.

54:12.000 --> 54:17.000
He got a phone number that ended in that number and it freaked him out.

54:17.000 --> 54:23.000
He got a hotel room that had that number and he just became convinced that he was going to die at that age.

54:23.000 --> 54:25.000
Guess when he died?

54:25.000 --> 54:26.000
48.

54:26.000 --> 54:27.000
No, when he was like 80.

54:27.000 --> 54:29.000
Sometimes it goes wrong.

54:29.000 --> 54:30.000
You're a dick.

54:30.000 --> 54:32.000
You are a dick.

54:32.000 --> 54:33.000
The rest of that was true though.

54:33.000 --> 54:34.000
All right.

54:34.000 --> 54:36.000
What's your sexy paradox that you wanted to show me?

54:36.000 --> 54:37.000
Yes.

54:37.000 --> 54:38.000
Get your paradox out of the land.

54:38.000 --> 54:40.000
Think about this, right?

54:40.000 --> 54:46.000
Now, I can't remember what the source is and I want to attribute the person who does it.

54:46.000 --> 54:47.000
Maybe I can find it.

54:47.000 --> 54:48.000
Yeah, get it.

54:48.000 --> 54:51.000
Let me find it because I want to make sure that they get the credit for it.

54:51.000 --> 55:02.000
I was told about it by a friend and you have to give me a minute because I don't want to pass this off as my own.

55:02.000 --> 55:05.000
What do you do with everything else?

55:05.000 --> 55:07.000
I think it's called the anthropic.

55:07.000 --> 55:15.000
So it's a website called risingentropy.com is seemingly the origin of this paradox,

55:15.000 --> 55:21.000
but I was told about it by a friend and it's, I guess, okay, so imagine that,

55:21.000 --> 55:28.000
and what this does is it shows us that different ways of thinking give us wildly different answers to the same problem,

55:28.000 --> 55:30.000
different ways of looking at a problem.

55:30.000 --> 55:40.000
So imagine that there's a maniac who, and it's called the anthropic dice killer if you want to look it up.

55:40.000 --> 55:44.000
There's a maniac who is kidnapping people and murdering them.

55:44.000 --> 55:50.000
And what he does is he kidnaps one person and he blindfolds them and he rolls a dice.

55:50.000 --> 55:55.000
And if that dice is a six, then he'll kill you.

55:55.000 --> 55:57.000
If not, he'll let you go free.

55:57.000 --> 56:03.000
And what he'll do if he lets you go free is he'll go and pick up two people, kidnap them, blindfold them,

56:03.000 --> 56:04.000
roll the dice.

56:04.000 --> 56:05.000
If it's a six, kills you.

56:05.000 --> 56:07.000
If it's anything else, go free.

56:07.000 --> 56:08.000
Then it's four people.

56:08.000 --> 56:11.000
Then it's eight people and it doubles.

56:11.000 --> 56:12.000
So it's an exponential.

56:12.000 --> 56:13.000
Until he hits a six.

56:13.000 --> 56:14.000
Until he hits a six.

56:14.000 --> 56:21.000
Now, you wake up knowing all this information, you wake up blindfolded and you know these facts

56:21.000 --> 56:25.000
and you know that a dice is about to be rolled, but you're blindfolded.

56:25.000 --> 56:27.000
You don't know how many people are there with you.

56:27.000 --> 56:36.000
You're given a button that you can press that will make the chances that you're killed half, one and two.

56:36.000 --> 56:40.000
So if you want to, you can press this button and a 50% of the time it will just kill you immediately

56:40.000 --> 56:42.000
and 50% of the time you'll get to go free.

56:42.000 --> 56:44.000
Or you can let him roll the dice.

56:44.000 --> 56:45.000
What do you do?

56:45.000 --> 56:47.000
Do you press the button or not?

56:47.000 --> 56:54.000
So at least on the surface, this is to do with the probability of one in six versus one in two.

56:54.000 --> 56:58.000
There is this escalating thing that's happening in the background.

56:58.000 --> 57:08.000
So I would presume that you would say, don't hit the button because that has increased the chance of you being killed from one in six to one in two.

57:08.000 --> 57:09.000
Right.

57:09.000 --> 57:10.000
And this seems true.

57:10.000 --> 57:14.000
And it is true that, yeah, I mean, like you've got a one in six chance of dying.

57:14.000 --> 57:16.000
And if you press the button, you've got a one in two.

57:16.000 --> 57:18.000
So you're better at rolling the dice.

57:18.000 --> 57:29.000
But if you think about it as one big block, then something very strange happens because if you consider all of the people involved,

57:29.000 --> 57:38.000
if all you know is that you've woken up and you're somewhere in this process, then interestingly,

57:38.000 --> 57:46.000
say it gets to number two, it gets to round two, then there have been three people involved, three victims involved.

57:47.000 --> 57:52.000
And two of them end up dying and one of them goes free.

57:52.000 --> 58:00.000
So if you find yourself in this situation as a victim, you've got a more than half probability that you're in the second group that ends up dying.

58:00.000 --> 58:04.000
I suppose that actually it ends in the third group.

58:04.000 --> 58:05.000
Right.

58:05.000 --> 58:06.000
Now there are how many people involved?

58:06.000 --> 58:08.000
You've got one than two.

58:08.000 --> 58:09.000
Then four.

58:09.000 --> 58:10.000
Then four.

58:10.000 --> 58:13.000
So we've now got seven people involved.

58:13.000 --> 58:14.000
Right.

58:14.000 --> 58:16.000
Four people end up dying.

58:16.000 --> 58:24.000
And so if you sort of wake up in this scenario, you've got a four in seven chance that you're going to die,

58:24.000 --> 58:27.000
that you're going to be one of the people who dies, which is more than half.

58:27.000 --> 58:33.000
And this continues such that if you consider the fact that it doesn't matter where it ends,

58:33.000 --> 58:41.000
you're always going to have a slightly higher than half chance that you're in the group that ends up getting killed.

58:42.000 --> 58:50.000
But is it more than half given that each round of the dice roll is only one in six?

58:50.000 --> 58:56.000
Yeah, because it's about like if in fact it gets to number three.

58:56.000 --> 58:57.000
Right.

58:57.000 --> 59:04.000
Like you know that you're going to be in the group that dies.

59:04.000 --> 59:09.000
If it in fact gets to number two, then there's a more than half chance that you're going to die.

59:10.000 --> 59:11.000
So I'm going to hit the button.

59:11.000 --> 59:12.000
Is that right?

59:12.000 --> 59:13.000
Well, maybe.

59:13.000 --> 59:15.000
I mean, it seems ludicrous to hit the button, but thinking about it this way,

59:15.000 --> 59:16.000
it seems like that's what you should actually do.

59:16.000 --> 59:20.000
It's simultaneously the case that you have got a one in six chance of dying

59:20.000 --> 59:23.000
because you're doing it on the roll of a dice.

59:23.000 --> 59:28.000
But at the same time, if you think about the fact that one of these groups is going to end up dying

59:28.000 --> 59:35.000
and it doesn't matter where it ends, the chances of you being in that group are always going to be slightly higher than half.

59:35.000 --> 59:36.000
Right.

59:36.000 --> 59:38.000
From a population level.

59:38.000 --> 59:42.000
The anthropic dice killer because it is the anthropic principle is thinking about.

59:42.000 --> 59:43.000
Yeah.

59:43.000 --> 59:44.000
What's that?

59:45.000 --> 59:51.000
I once read a sci-fi book that was there was a threat of the end of the world.

59:51.000 --> 59:54.000
They were looking to get humanity off the planet.

59:54.000 --> 01:00:06.000
And there is a theory that uses almost this exact same idea which says that if you take the entirety of human history

01:00:06.000 --> 01:00:13.000
and you were to pick a time at which you were to live and you have this rapid increase toward humanity,

01:00:13.000 --> 01:00:21.000
it works out that it's more likely that you are within some percent of the end of humanity.

01:00:21.000 --> 01:00:22.000
Right.

01:00:22.000 --> 01:00:23.000
Yeah.

01:00:23.000 --> 01:00:25.000
Because of the exponential growth.

01:00:25.000 --> 01:00:26.000
Precisely.

01:00:26.000 --> 01:00:27.000
Exactly.

01:00:27.000 --> 01:00:28.000
Are you familiar with this idea?

01:00:28.000 --> 01:00:29.000
I don't think so.

01:00:29.000 --> 01:00:30.000
Right.

01:00:30.000 --> 01:00:31.000
But it's fascinating.

01:00:31.000 --> 01:00:32.000
It works the exact same.

01:00:32.000 --> 01:00:36.000
If that graph is going up at the requisite speed, then yeah.

01:00:36.000 --> 01:00:37.000
Right.

01:00:37.000 --> 01:00:38.000
And this is the exact same thing.

01:00:38.000 --> 01:00:41.000
I mean, the version on the website actually involves snake eyes.

01:00:41.000 --> 01:00:42.000
So it's two dice.

01:00:42.000 --> 01:00:47.000
And instead of it being one, then two, then four, it's one, then ten, then a hundred, then a thousand.

01:00:47.000 --> 01:00:48.000
Right.

01:00:48.000 --> 01:00:49.000
So it ramps up more quickly.

01:00:49.000 --> 01:00:50.000
And now you're rolling snake eyes.

01:00:50.000 --> 01:00:52.000
So it's a one in 36 chance.

01:00:52.000 --> 01:00:58.000
And it turns out that if you add up the probability of like N number of cases,

01:00:58.000 --> 01:01:03.000
it's something like 90% chance versus the half that you get to press,

01:01:03.000 --> 01:01:04.000
which just seems ludicrous.

01:01:04.000 --> 01:01:06.000
And it seems that two things are true at once,

01:01:06.000 --> 01:01:08.000
depending on just how you look at the problem.

01:01:08.000 --> 01:01:10.000
So sometimes problems like this are just to do with the way you word them.

01:01:10.000 --> 01:01:12.000
I mean, there are tons of like these sort of interesting math paradoxes,

01:01:12.000 --> 01:01:14.000
which aren't paradoxes at all.

01:01:14.000 --> 01:01:16.000
You must be familiar with the man who walks into the hotel,

01:01:16.000 --> 01:01:18.000
pays 30 pounds, goes up to his room,

01:01:18.000 --> 01:01:23.000
and the guy behind the bar says,

01:01:23.000 --> 01:01:25.000
the manager says,

01:01:25.000 --> 01:01:27.000
oh, no, he should have only paid 25.

01:01:27.000 --> 01:01:28.000
We've got a deal on.

01:01:28.000 --> 01:01:29.000
So he calls the bell boy and says,

01:01:29.000 --> 01:01:32.000
can you go and give him five pounds back to the man in the room?

01:01:32.000 --> 01:01:34.000
And the bell boy thinks to himself on the way up,

01:01:34.000 --> 01:01:35.000
like this guy doesn't know any better.

01:01:35.000 --> 01:01:36.000
He doesn't know how much he owed.

01:01:36.000 --> 01:01:38.000
I'm going to pocket three pounds for myself.

01:01:38.000 --> 01:01:40.000
I'm only going to give him two pounds.

01:01:40.000 --> 01:01:41.000
So he goes back to the room.

01:01:41.000 --> 01:01:42.000
He says, excuse me, sir.

01:01:42.000 --> 01:01:44.000
Sorry, you paid, you know, you paid 30 pounds.

01:01:44.000 --> 01:01:45.000
You paid too much.

01:01:45.000 --> 01:01:46.000
Here's two pounds change.

01:01:46.000 --> 01:01:49.000
So how much has the man now paid?

01:01:49.000 --> 01:01:51.000
25 pounds.

01:01:51.000 --> 01:01:52.000
No, 28 pounds.

01:01:52.000 --> 01:01:53.000
28 pounds.

01:01:53.000 --> 01:01:55.000
And how much has the bell boy got in his pocket?

01:01:55.000 --> 01:01:56.000
Two.

01:01:56.000 --> 01:01:59.000
He gave the guy two pounds back.

01:01:59.000 --> 01:02:00.000
Right.

01:02:00.000 --> 01:02:02.000
Where's that money come from?

01:02:02.000 --> 01:02:03.000
Yeah, he's got three.

01:02:03.000 --> 01:02:06.000
So the bell boy, so the man's now only paid 28 pounds.

01:02:06.000 --> 01:02:07.000
He's paid 30 pounds.

01:02:07.000 --> 01:02:08.000
He gets two pounds back from the bell boy.

01:02:08.000 --> 01:02:09.000
Yeah.

01:02:09.000 --> 01:02:10.000
He's got, he's paid 28 pounds.

01:02:10.000 --> 01:02:13.000
The bell boy's got three pounds in his pocket,

01:02:13.000 --> 01:02:15.000
which makes 31.

01:02:15.000 --> 01:02:17.000
So where's the extra pound come from?

01:02:17.000 --> 01:02:18.000
Actually, no, he hasn't.

01:02:18.000 --> 01:02:22.000
The guy paid 25 plus now he's got two back.

01:02:22.000 --> 01:02:23.000
That's right.

01:02:23.000 --> 01:02:25.000
So it's the way you word it, right?

01:02:25.000 --> 01:02:27.000
So this like stumps people.

01:02:27.000 --> 01:02:29.000
And you can do it the other way around as well.

01:02:29.000 --> 01:02:32.000
You can say that the guy goes up and he gives,

01:02:32.000 --> 01:02:34.000
the bell boy gives three pounds back to the guy.

01:02:34.000 --> 01:02:36.000
So he's only paid 27 pounds,

01:02:36.000 --> 01:02:38.000
but the bell boy's got two pounds.

01:02:38.000 --> 01:02:39.000
And it's only 29.

01:02:39.000 --> 01:02:41.000
And this, you know, it sort of goes viral on social media

01:02:41.000 --> 01:02:43.000
because people are like, how the hell does it work?

01:02:43.000 --> 01:02:47.000
It's the blue and black or green and gold dress.

01:02:47.000 --> 01:02:49.000
It's like, I mean, for those that, yeah, I guess there is,

01:02:49.000 --> 01:02:51.000
it's like those in that there is a real answer

01:02:51.000 --> 01:02:53.000
to what the actual war is actually going on there.

01:02:53.000 --> 01:02:56.000
It leads people based on how you word it.

01:02:56.000 --> 01:02:58.000
It's how people, you know, shortchange it

01:02:58.000 --> 01:03:01.000
when they scan people at a bar or something.

01:03:01.000 --> 01:03:04.000
I mean, the easiest way to visualise that particular problem

01:03:04.000 --> 01:03:07.000
is to imagine that the man was only supposed to pay two pounds.

01:03:07.000 --> 01:03:09.000
You know, so the bell boy goes up and gives him 28.

01:03:09.000 --> 01:03:11.000
He's supposed to give him 28 pounds

01:03:11.000 --> 01:03:13.000
and decides to pocket two pounds for himself.

01:03:13.000 --> 01:03:16.000
So he gives him, you know, gives him 26 pounds back.

01:03:16.000 --> 01:03:18.000
So how much is the man paid, like four pounds

01:03:18.000 --> 01:03:22.000
and how much the bell boy got, like 26 pounds,

01:03:22.000 --> 01:03:23.000
which is ludicrous.

01:03:23.000 --> 01:03:27.000
But you'd be amazed at how easily people can be

01:03:27.000 --> 01:03:29.000
completely nicely stumped by it.

01:03:29.000 --> 01:03:31.000
And it's all in the, it's all in the wording.

01:03:31.000 --> 01:03:33.000
So a problem like the anthropic dice killer,

01:03:33.000 --> 01:03:36.000
I wonder how much it's just sort of to do with the way

01:03:36.000 --> 01:03:38.000
that you describe it, you know.

01:03:38.000 --> 01:03:41.000
Have there been any paradoxes

01:03:41.000 --> 01:03:45.000
that sent you into a fugue state for a little while?

01:03:45.000 --> 01:03:48.000
Was there anything that captured a particularly long amount of time

01:03:48.000 --> 01:03:51.000
that you sort of couldn't stop considering?

01:03:56.000 --> 01:03:58.000
Most of the famous ones since,

01:03:58.000 --> 01:04:00.000
since I first started learning about paradoxes,

01:04:00.000 --> 01:04:02.000
like the famous Monty Hall problem,

01:04:02.000 --> 01:04:05.000
that obsessed me for, well, I wouldn't say obsessed me,

01:04:05.000 --> 01:04:07.000
but I was sort of blown away by it.

01:04:07.000 --> 01:04:09.000
There's also, you know the Monty Hall problem.

01:04:09.000 --> 01:04:11.000
You'll definitely have heard of this before.

01:04:11.000 --> 01:04:16.000
This, it's the game show and the three doors.

01:04:16.000 --> 01:04:17.000
Right. Yeah.

01:04:17.000 --> 01:04:19.000
You know what I'm talking about.

01:04:19.000 --> 01:04:21.000
There are interesting paradoxes that aren't actually paradoxes.

01:04:21.000 --> 01:04:24.000
There's a book by Jim Alcalely called Paradox,

01:04:24.000 --> 01:04:28.000
which is a description of so-called paradoxes.

01:04:28.000 --> 01:04:33.000
So like, I think, I think all this paradox is,

01:04:33.000 --> 01:04:37.000
when people used to think that the universe was infinite,

01:04:37.000 --> 01:04:39.000
infinitely large, I mean,

01:04:39.000 --> 01:04:43.000
there was this problem that if empty space is filled up

01:04:43.000 --> 01:04:45.000
fairly randomly with stars,

01:04:45.000 --> 01:04:47.000
I mean, we know there's a lot of stars in the sky

01:04:47.000 --> 01:04:50.000
and galaxies and objects that emit light,

01:04:50.000 --> 01:04:55.000
then there should essentially be no darkness in the sky.

01:04:55.000 --> 01:04:58.000
The sky should look kind of like an overcast day

01:04:58.000 --> 01:05:03.000
because like the gaps in the sky, you know,

01:05:03.000 --> 01:05:05.000
are all eventually going to be filled up

01:05:05.000 --> 01:05:07.000
and any amount, any small gap,

01:05:07.000 --> 01:05:09.000
you might think the stars are really far away.

01:05:09.000 --> 01:05:11.000
They'll also be like closer together,

01:05:11.000 --> 01:05:13.000
therefore emitting more light visually and they'll be bigger.

01:05:13.000 --> 01:05:15.000
And so if the universe is infinite,

01:05:15.000 --> 01:05:17.000
you should just see a sort of overcast day.

01:05:17.000 --> 01:05:18.000
And it was a paradox.

01:05:18.000 --> 01:05:21.000
It was like, how does this happen?

01:05:21.000 --> 01:05:23.000
And it basically became an interesting proof

01:05:23.000 --> 01:05:25.000
that the universe has a beginning,

01:05:25.000 --> 01:05:27.000
that the universe is not in fact infinite,

01:05:27.000 --> 01:05:29.000
just the fact that it gets dark at night

01:05:29.000 --> 01:05:31.000
because if it were actually infinite,

01:05:31.000 --> 01:05:35.000
there should be a sort of overcast view,

01:05:35.000 --> 01:05:37.000
Alba's paradox.

01:05:37.000 --> 01:05:38.000
And like I say, it's sort of a paradox,

01:05:38.000 --> 01:05:40.000
but not really a paradox.

01:05:40.000 --> 01:05:42.000
Are you familiar with the Buete's Void?

01:05:42.000 --> 01:05:43.000
Do you know this? I think so.

01:05:43.000 --> 01:05:45.000
This is like my favorite part of the universe.

01:05:45.000 --> 01:05:46.000
I'd say like I'm mapping it,

01:05:46.000 --> 01:05:50.000
like my favorite barbecue restaurants in Austin.

01:05:50.000 --> 01:05:54.000
And it's a huge, what's referred to as a super void,

01:05:54.000 --> 01:05:56.000
which is a period of the universe,

01:05:56.000 --> 01:06:00.000
an area of the universe which has way fewer galaxies

01:06:00.000 --> 01:06:02.000
than you would anticipate.

01:06:02.000 --> 01:06:05.000
And given what's the principle of like,

01:06:05.000 --> 01:06:08.000
homogeneity across the universe that it should be,

01:06:08.000 --> 01:06:10.000
it should be relatively similar, right?

01:06:10.000 --> 01:06:11.000
Like thermodynamics.

01:06:11.000 --> 01:06:12.000
Yes.

01:06:12.000 --> 01:06:14.000
Entropy and...

01:06:14.000 --> 01:06:17.000
Now you're just saying the space words at me.

01:06:17.000 --> 01:06:20.000
Well, you know, like when you spray in aerosol can,

01:06:20.000 --> 01:06:21.000
it will eventually spread at the room.

01:06:21.000 --> 01:06:22.000
Dispaces equally.

01:06:22.000 --> 01:06:27.000
So the point is that there shouldn't be

01:06:27.000 --> 01:06:31.000
huge fluctuations in the way that we see the universe.

01:06:31.000 --> 01:06:33.000
Everything should be spread relatively evenly.

01:06:33.000 --> 01:06:37.000
Now, I found out that supposedly at the point of the Big Bang,

01:06:37.000 --> 01:06:42.000
there were one million particles of antimatter

01:06:42.000 --> 01:06:45.000
and one million and one particles of matter.

01:06:45.000 --> 01:06:49.000
And it is that one to one million and one ratio

01:06:49.000 --> 01:06:52.000
that is exactly where everything that we see comes from.

01:06:52.000 --> 01:06:54.000
And this minor imbalance is actually

01:06:54.000 --> 01:06:56.000
what's permitted everything to exist.

01:06:56.000 --> 01:07:01.000
But this particular Buete's B-O-O one with an umlaut T-E-S,

01:07:01.000 --> 01:07:03.000
Buete's super void.

01:07:03.000 --> 01:07:05.000
It's just super fucking interesting.

01:07:05.000 --> 01:07:08.000
It's this gap where there's way fewer galaxies

01:07:08.000 --> 01:07:09.000
than there should be.

01:07:09.000 --> 01:07:11.000
Why should this exist?

01:07:11.000 --> 01:07:14.000
Given that we've got this sort of principle of homogeneity

01:07:14.000 --> 01:07:15.000
across the universe.

01:07:15.000 --> 01:07:18.000
And that's one of my favorite things to like learn about.

01:07:18.000 --> 01:07:19.000
Yeah.

01:07:19.000 --> 01:07:23.000
But is it that we know about this void

01:07:23.000 --> 01:07:25.000
because of the disbalance?

01:07:25.000 --> 01:07:27.000
Or is it that we hypothesize the disbalance

01:07:27.000 --> 01:07:29.000
because of the knowledge of the void?

01:07:29.000 --> 01:07:33.000
We know based on mapping of, I think,

01:07:33.000 --> 01:07:36.000
I'm not sure if it's telescopic or if it's microwave background stuff,

01:07:36.000 --> 01:07:37.000
but we know that it's there.

01:07:37.000 --> 01:07:38.000
Right.

01:07:38.000 --> 01:07:40.000
And the question is, what the fuck is this thing doing there?

01:07:40.000 --> 01:07:41.000
Yeah.

01:07:41.000 --> 01:07:43.000
Well, that's a bit like sort of dark energy when we discover

01:07:43.000 --> 01:07:46.000
that galaxies are spinning a little bit too quickly on the outside.

01:07:46.000 --> 01:07:48.000
There seems to be something like pushing them along.

01:07:48.000 --> 01:07:52.000
What do you make of the fine-tune universe idea?

01:07:53.000 --> 01:07:58.000
A lot of people describe it as the most powerful argument for God's existence.

01:07:58.000 --> 01:08:01.000
Christopher Hitchens in the back of a car once said

01:08:01.000 --> 01:08:03.000
that that was really what gave him pause.

01:08:03.000 --> 01:08:06.000
I don't find that it moves me very much.

01:08:06.000 --> 01:08:11.000
I mean, it does seem quite extraordinary that had any of the constants

01:08:11.000 --> 01:08:14.000
of the universe, the force of gravity, for example,

01:08:14.000 --> 01:08:19.000
if it was stronger or weaker by the most unimaginably small amount,

01:08:19.000 --> 01:08:22.000
then it would either be strong enough that the universe would collapse in on itself

01:08:22.000 --> 01:08:27.000
or it would be so weak that atoms couldn't even form

01:08:27.000 --> 01:08:29.000
or at least objects couldn't form

01:08:29.000 --> 01:08:32.000
and everything just gets blown apart at the big bang.

01:08:34.000 --> 01:08:35.000
Three explanations for this.

01:08:35.000 --> 01:08:39.000
It's chance, it's necessity or it's design

01:08:39.000 --> 01:08:42.000
and chances seems like a ludicrous suggestion.

01:08:42.000 --> 01:08:44.000
I mean, there are lots of different constants

01:08:44.000 --> 01:08:47.000
and it may be the case that we discover this sort of theory of everything

01:08:47.000 --> 01:08:48.000
that reduces it down to one.

01:08:48.000 --> 01:08:53.000
Still a huge mystery as to why it has the constant that it does

01:08:53.000 --> 01:08:58.000
but would mean that we're not talking about lots of different constants in harmony.

01:08:58.000 --> 01:09:00.000
Somehow happens to be unified in one way.

01:09:00.000 --> 01:09:03.000
But the idea that it's necessarily being that way

01:09:03.000 --> 01:09:05.000
doesn't seem that out of the question for me.

01:09:07.000 --> 01:09:10.000
People put it in the language of saying that

01:09:10.000 --> 01:09:13.000
had the constants been different by this amount,

01:09:13.000 --> 01:09:14.000
the universe couldn't exist.

01:09:14.000 --> 01:09:20.000
And what people often hear is the chances of the constant being as it was

01:09:20.000 --> 01:09:23.000
was the same number, but I don't think that's the same thing.

01:09:23.000 --> 01:09:26.000
It might just be not possible that it could have had a different value.

01:09:26.000 --> 01:09:31.000
What's the observer selection effect of this?

01:09:31.000 --> 01:09:34.000
This doesn't work for the fine-tuning argument, I think.

01:09:34.000 --> 01:09:38.000
So the so-called like anthropic principle,

01:09:38.000 --> 01:09:41.000
the universe seems designed for human life.

01:09:42.000 --> 01:09:44.000
People might point to, for example,

01:09:44.000 --> 01:09:48.000
the Earth's perfect distance from the Sun in the so-called Goldilocks zone

01:09:48.000 --> 01:09:51.000
had it been a little bit further out or a little bit closer, humans couldn't exist.

01:09:51.000 --> 01:09:53.000
And the easy answer to that is to say,

01:09:53.000 --> 01:09:54.000
well, yeah, but if you didn't exist,

01:09:54.000 --> 01:09:57.000
then you wouldn't be there to observe that it didn't exist, right?

01:09:57.000 --> 01:10:00.000
And so you say, given the size of the universe,

01:10:00.000 --> 01:10:04.000
life might develop somewhere, possibly in multiple places,

01:10:04.000 --> 01:10:08.000
and the places where it's going to be observed coming about

01:10:08.000 --> 01:10:10.000
is where it comes about, so no surprise.

01:10:10.000 --> 01:10:14.000
That works there, but the fine-tuning concepts of the universe,

01:10:14.000 --> 01:10:18.000
we're not talking about like,

01:10:18.000 --> 01:10:23.000
we're not talking about like a potential billions of Earths

01:10:23.000 --> 01:10:25.000
that could all give rise to human beings.

01:10:25.000 --> 01:10:27.000
We're talking about if one of these constants was different,

01:10:27.000 --> 01:10:30.000
by the tiniest amount, nothing exists.

01:10:30.000 --> 01:10:34.000
And sure, it is still true that didn't not happen.

01:10:34.000 --> 01:10:36.000
We wouldn't be here to observe it.

01:10:36.000 --> 01:10:39.000
My friend Josh Perique has given me an example in the past of like,

01:10:39.000 --> 01:10:46.000
I don't know, you can imagine like a series of highly trained knife throwers

01:10:46.000 --> 01:10:51.000
just lobbed like 100,000 knives at you in an attempt to kill you,

01:10:51.000 --> 01:10:56.000
and they all miss perfectly cutting out the silhouette of your body behind you,

01:10:56.000 --> 01:11:00.000
absolutely perfectly, just like uncanny.

01:11:00.000 --> 01:11:02.000
And someone says, well, they must have done that on purpose.

01:11:02.000 --> 01:11:03.000
It's like a trick, right?

01:11:03.000 --> 01:11:05.000
And you say, no, no, I think it's just happened by chance.

01:11:05.000 --> 01:11:06.000
You say, well, that's ludicrous.

01:11:06.000 --> 01:11:07.000
Oh, what if it didn't?

01:11:07.000 --> 01:11:10.000
And I wouldn't be here to observe that it did, would I?

01:11:10.000 --> 01:11:14.000
It still just wouldn't do it for you, even though that is true.

01:11:14.000 --> 01:11:16.000
Had you been killed, you wouldn't be there to observe it.

01:11:16.000 --> 01:11:20.000
It just seems such an unlikely coincidence that that just doesn't work

01:11:20.000 --> 01:11:24.000
when we're talking about the actual fundamental stuff of the universe,

01:11:24.000 --> 01:11:25.000
which is why people are so troubled by it.

01:11:25.000 --> 01:11:28.000
But I do think, generally speaking, with all of these kinds of things,

01:11:28.000 --> 01:11:31.000
fine-tuning, consciousness is another example

01:11:31.000 --> 01:11:34.000
that's broadly in the scientific realm that people think,

01:11:34.000 --> 01:11:36.000
like this just can't be explained to that reference to a God.

01:11:36.000 --> 01:11:37.000
Maybe they're right.

01:11:37.000 --> 01:11:38.000
I don't know.

01:11:38.000 --> 01:11:40.000
But if you intuitively were to step into a time machine

01:11:40.000 --> 01:11:42.000
and look at some people having this conversation,

01:11:42.000 --> 01:11:48.000
and you said like, imagine them looking back and saying,

01:11:48.000 --> 01:11:49.000
gosh, can you believe it?

01:11:49.000 --> 01:11:51.000
They hadn't worked out fine-tuning yet.

01:11:51.000 --> 01:11:53.000
They hadn't figured out the constants.

01:11:53.000 --> 01:11:56.000
Oh, they hadn't figured out the science of consciousness yet.

01:11:56.000 --> 01:11:58.000
I can conceive of that.

01:11:58.000 --> 01:12:01.000
Just intuitively, I can see someone doing that.

01:12:01.000 --> 01:12:03.000
But when I think about my arguments for atheism,

01:12:03.000 --> 01:12:06.000
the problem of evil, divine hidden, this kind of stuff,

01:12:06.000 --> 01:12:09.000
I can't imagine somebody looking through a time machine similarly

01:12:09.000 --> 01:12:11.000
at a conversation that I have and going,

01:12:11.000 --> 01:12:12.000
gosh, can you believe it?

01:12:12.000 --> 01:12:14.000
They hadn't worked out the problem of evil yet.

01:12:14.000 --> 01:12:16.000
They hadn't worked out divine hiddenness yet.

01:12:16.000 --> 01:12:17.000
I think these are perennial problems.

01:12:17.000 --> 01:12:21.000
So where you have these scientific arguments for the existence of God,

01:12:21.000 --> 01:12:24.000
I guess I just have more of a trust that they will one day be explained

01:12:24.000 --> 01:12:29.000
in a way that won't require recourse to a divine author

01:12:29.000 --> 01:12:35.000
in a way that my criticisms of religion will probably not be similarly resolved.

01:12:35.000 --> 01:12:38.000
We had a great conversation in Austin

01:12:38.000 --> 01:12:42.000
as you explained to me about the potential historical accuracy

01:12:42.000 --> 01:12:46.000
or inaccuracy of Jesus' resurrection.

01:12:46.000 --> 01:12:48.000
Can you go through that a little bit?

01:12:48.000 --> 01:12:49.000
Yeah.

01:12:49.000 --> 01:12:51.000
I mean, this sometimes is used as an argument for the existence of God,

01:12:51.000 --> 01:12:53.000
but I think more successfully is used

01:12:53.000 --> 01:12:55.000
once you've already established the existence of God

01:12:55.000 --> 01:12:57.000
to try to establish the truth of Christianity.

01:12:57.000 --> 01:13:04.000
And that is a bunch of historical facts surrounding Jesus' alleged resurrection

01:13:04.000 --> 01:13:07.000
that you sort of have to ask what the best explanation is for.

01:13:07.000 --> 01:13:09.000
Now, you can't historically prove a resurrection,

01:13:09.000 --> 01:13:12.000
but you can historically prove events

01:13:12.000 --> 01:13:16.000
and then ask what the best explanation of those facts is.

01:13:16.000 --> 01:13:20.000
So people will often point to the fact that there was a man called Jesus

01:13:20.000 --> 01:13:26.000
walking around morally teaching people who was crucified by the Romans

01:13:26.000 --> 01:13:31.000
and that a few days after his death was seen,

01:13:31.000 --> 01:13:36.000
people made claims that they'd seen him after he'd died.

01:13:36.000 --> 01:13:38.000
And the question is how do you explain these facts?

01:13:38.000 --> 01:13:42.000
The gospel reliability is an interesting question in general

01:13:42.000 --> 01:13:44.000
and people will often on the surface level say,

01:13:44.000 --> 01:13:46.000
look, the Bible contradicts itself.

01:13:46.000 --> 01:13:48.000
It's full of contradictions.

01:13:48.000 --> 01:13:52.000
And there are some seeming contradictions in the gospel story,

01:13:52.000 --> 01:13:56.000
but of course, what a lot of people neglect to consider

01:13:56.000 --> 01:13:59.000
is that when we're talking about a text as a historical document,

01:13:59.000 --> 01:14:08.000
contradictions shouldn't make us think that it's less accurate but more accurate.

01:14:08.000 --> 01:14:10.000
If historical sources contradict each other,

01:14:10.000 --> 01:14:13.000
that's evidence of their accuracy rather than evidence of the opposite.

01:14:13.000 --> 01:14:20.000
Because if this is a mythical story that somebody's making up,

01:14:20.000 --> 01:14:25.000
you would expect the details to concur.

01:14:25.000 --> 01:14:31.000
That is, if you're questioning two suspects in some kind of murder trial or something

01:14:31.000 --> 01:14:37.000
and their stories match up perfectly, like to the tea, the timings, everything,

01:14:37.000 --> 01:14:39.000
it arouses suspicion.

01:14:39.000 --> 01:14:41.000
It seems like somebody's inventing something.

01:14:41.000 --> 01:14:44.000
Someone's coming up with a story here and trying to perfect it.

01:14:44.000 --> 01:14:46.000
Now, people have this idea that a bunch of people got together

01:14:46.000 --> 01:14:52.000
and tried to fool the world into this mythical story of this man rising from the dead.

01:14:52.000 --> 01:14:57.000
Do you think they would have made the mistake of just including these blatant contradictions?

01:14:57.000 --> 01:14:58.000
I don't know.

01:14:58.000 --> 01:15:00.000
In other words, I think if somebody was making it up,

01:15:00.000 --> 01:15:02.000
they probably would have taken more care.

01:15:02.000 --> 01:15:04.000
Is there a term for this?

01:15:04.000 --> 01:15:05.000
I'm sure there is.

01:15:05.000 --> 01:15:06.000
I'm not a historian.

01:15:06.000 --> 01:15:08.000
I couldn't tell you what it is.

01:15:08.000 --> 01:15:14.000
But we do see contradictions on the minor points.

01:15:14.000 --> 01:15:17.000
We don't really see much disagreement about the major points.

01:15:17.000 --> 01:15:19.000
There is some enough disagreement, I think, to arouse suspicion.

01:15:19.000 --> 01:15:22.000
I'm saying this as if I'm some kind of Christian or theist.

01:15:22.000 --> 01:15:28.000
I put on that hat when I'm asked to have a conversation of this kind.

01:15:28.000 --> 01:15:33.000
It does seem to me suspicious, for example, that the Gospel of Mark, which is the earliest Gospel,

01:15:33.000 --> 01:15:36.000
contains no post-resurrection appearances.

01:15:36.000 --> 01:15:41.000
Then the Gospel of Matthew does include post-resurrection appearances.

01:15:41.000 --> 01:15:43.000
The Gospel of Luke includes even more.

01:15:43.000 --> 01:15:46.000
It's only in the Gospel of John that we get, for instance, doubting Thomas,

01:15:46.000 --> 01:15:51.000
which is the latest canonical Gospel, I should say.

01:15:51.000 --> 01:15:52.000
That's where that arises.

01:15:52.000 --> 01:15:57.000
In fact, the story of doubting Thomas famously, he doesn't believe that it's the risen Christ.

01:15:57.000 --> 01:15:59.000
Jesus says, come and touch my wounds.

01:15:59.000 --> 01:16:04.000
He touches his wounds and he says, my Lord and my God.

01:16:04.000 --> 01:16:09.000
Jesus says, you believe because you've seen.

01:16:09.000 --> 01:16:12.000
Blessed are those who believe without seeing.

01:16:12.000 --> 01:16:19.000
In my view, what we have is this so-called mythological development of no post-resurrection appearances.

01:16:19.000 --> 01:16:25.000
As the time goes on, as we get further away from the source, the stories get more fantastical,

01:16:25.000 --> 01:16:32.000
ending in a moral lesson to believe without seeing.

01:16:32.000 --> 01:16:35.000
This to me does seem a little bit suspicious.

01:16:35.000 --> 01:16:37.000
It is a fascinating mystery.

01:16:37.000 --> 01:16:40.000
Something very strange happened on Easter morning.

01:16:41.000 --> 01:16:46.000
How do we explain the fact that this man gets crucified by the Romans

01:16:46.000 --> 01:16:51.000
and then people claim to see him after he died and were willing to be put to death for that belief?

01:16:51.000 --> 01:16:53.000
Maybe he didn't die.

01:16:53.000 --> 01:16:59.000
Unlikely, as they say, the Romans knew how to kill people and supposedly they check

01:16:59.000 --> 01:17:09.000
and they go to break the legs of the other prisoners as they're taking them down from their crosses.

01:17:09.000 --> 01:17:14.000
They were taking them down temporarily and they hadn't died yet,

01:17:14.000 --> 01:17:17.000
but when they go to break Jesus' legs, they realize he's already dead,

01:17:17.000 --> 01:17:23.000
which is why his legs don't get broken and they stab him in the side with a stick to make sure that he's dead.

01:17:23.000 --> 01:17:26.000
This was a very effective method of killing people and they knew how to do it,

01:17:26.000 --> 01:17:30.000
so it's unlikely that he somehow survived this.

01:17:30.000 --> 01:17:34.000
Is that the guy that stabbed him with the spear and supposedly this blood on the spear?

01:17:34.000 --> 01:17:38.000
Yeah, someone stabbed him with the spear after he's on the cross.

01:17:38.000 --> 01:17:41.000
And it's essentially to check he's dead.

01:17:41.000 --> 01:17:49.000
Okay, so the likely hit is that he was actually crucified and then a few days later people are claiming to see him.

01:17:49.000 --> 01:17:55.000
Maybe they're lying, but then you don't tend to go to death for something you know to be a lie.

01:17:55.000 --> 01:17:59.000
You're willing to be put to death for things that you think are true that are false,

01:17:59.000 --> 01:18:03.000
but very rarely are people willing to die for beliefs that they don't actually believe themselves.

01:18:03.000 --> 01:18:06.000
That doesn't really happen, so they probably weren't lying.

01:18:07.000 --> 01:18:10.000
Maybe they were mistaken, fooled.

01:18:10.000 --> 01:18:14.000
Yeah, now I've known you since about 2019,

01:18:14.000 --> 01:18:21.000
which is probably, it will have been slightly longer than Jesus was with his disciples,

01:18:21.000 --> 01:18:28.000
but imagine spending every single day with this person, living with this person, eating with this person.

01:18:28.000 --> 01:18:31.000
And then you've only seen him a few days ago.

01:18:31.000 --> 01:18:36.000
And somehow, imagine somebody managed to convince you that they were me.

01:18:36.000 --> 01:18:40.000
Even if I had a twin brother, they probably wouldn't be able to convince you that it was me.

01:18:40.000 --> 01:18:44.000
Or maybe they were hallucinating in groups.

01:18:44.000 --> 01:18:52.000
One of the earliest New Testament sources is the letters of Paul, the earliest.

01:18:52.000 --> 01:18:57.000
And in one of those letters, Paul refers to Jesus having appeared to 500 people at once.

01:18:57.000 --> 01:19:01.000
And in some of the Gospels, you get at least some group appearances, at least more than one person.

01:19:01.000 --> 01:19:06.000
And sometimes groups of disciples, the 12, all seeing Jesus all at once.

01:19:06.000 --> 01:19:08.000
You don't get group hallucinations like that.

01:19:08.000 --> 01:19:12.000
And so it doesn't seem like they were mistaken either.

01:19:12.000 --> 01:19:15.000
And so if they're not mistaken, they're not making it up.

01:19:15.000 --> 01:19:21.000
What explains the fact that these people claim to see him after he had died?

01:19:21.000 --> 01:19:29.000
And the Christian apologists will say that the only real plausible explanation is that he really did rise from the dead.

01:19:29.000 --> 01:19:33.000
Now, it's an interesting argument and it's quite powerful.

01:19:33.000 --> 01:19:40.000
However, my response has always been that this sort of process of elimination is very clever.

01:19:40.000 --> 01:19:42.000
And that's how it's usually run.

01:19:42.000 --> 01:19:43.000
But it can go the other way.

01:19:43.000 --> 01:19:47.000
I mean, imagine I were trying to prove that there was such thing as a group hallucination.

01:19:47.000 --> 01:19:50.000
I know it's extraordinary, but there was a group hallucination.

01:19:50.000 --> 01:19:53.000
And I tried to prove it by saying, well, what are the other explanations?

01:19:53.000 --> 01:19:54.000
Or maybe they lied.

01:19:54.000 --> 01:19:56.000
Well, they wouldn't do that because they wouldn't go to death.

01:19:56.000 --> 01:19:59.000
Or maybe a man rose from the dead, but come on, that doesn't happen.

01:19:59.000 --> 01:20:00.000
That breaks all the laws of physics.

01:20:00.000 --> 01:20:02.000
So the only remaining option is this.

01:20:02.000 --> 01:20:03.000
Kind of depends where you start.

01:20:03.000 --> 01:20:04.000
But it is weird.

01:20:04.000 --> 01:20:07.000
Something very strange seems to have happened on that morning.

01:20:07.000 --> 01:20:12.000
I can see why philosophers go mad.

01:20:12.000 --> 01:20:18.000
Because you were able to simultaneously convince yourself of something and then convince yourself of the opposite

01:20:18.000 --> 01:20:20.000
and convince yourself of everything that you've believed.

01:20:20.000 --> 01:20:23.000
Yeah, but that's...

01:20:23.000 --> 01:20:28.000
I think one of those famous quotes of Socrates is that the sign of wisdom in a man

01:20:28.000 --> 01:20:32.000
or something is the ability to entertain a belief without holding it

01:20:32.000 --> 01:20:34.000
or without becoming convinced by it or something like that.

01:20:34.000 --> 01:20:39.000
And I think it's something anybody can do if they want to.

01:20:39.000 --> 01:20:41.000
And it's why philosophers are so...

01:20:41.000 --> 01:20:43.000
We think that philosophers are better at doing this.

01:20:43.000 --> 01:20:44.000
I don't think that's true.

01:20:44.000 --> 01:20:49.000
I think they're just talking about stuff that's far less political, far less real.

01:20:49.000 --> 01:20:51.000
And so they're less likely to get...

01:20:51.000 --> 01:20:56.000
They're less likely to be offended at the prospect of considering the falsehood of their beliefs.

01:20:56.000 --> 01:20:57.000
Maybe.

01:20:57.000 --> 01:20:58.000
Until you get into religion, I suppose.

01:20:58.000 --> 01:21:08.000
You definitely seem to be able to have an ability to drop into and out of arguments on both sides of the same fence

01:21:08.000 --> 01:21:13.000
and play with ideas in a way that I think is rare

01:21:13.000 --> 01:21:17.000
and presumably a bit of a disposition but also largely trained

01:21:17.000 --> 01:21:23.000
because you can sit and convince chat GPT that God exists

01:21:23.000 --> 01:21:26.000
or try and turn me into a theist

01:21:26.000 --> 01:21:30.000
and then stand on stage and do the exact opposite.

01:21:30.000 --> 01:21:32.000
And just...

01:21:32.000 --> 01:21:37.000
I think that there's probably quite a lot to learn from how people who have spent a good bit of time

01:21:38.000 --> 01:21:41.000
playing with ideas in philosophy

01:21:41.000 --> 01:21:47.000
dispassionately have that separation between themselves

01:21:47.000 --> 01:21:51.000
and the idea and the belief and what it means to them and the emotion

01:21:51.000 --> 01:21:54.000
and kind of that whole ambient mess.

01:21:54.000 --> 01:21:55.000
Yeah.

01:21:55.000 --> 01:21:58.000
It's playing is a good word because it's fun.

01:21:58.000 --> 01:21:59.000
It's enjoyable.

01:21:59.000 --> 01:22:02.000
That's why it's fun to talk about theory of knowledge

01:22:02.000 --> 01:22:04.000
because who really cares?

01:22:04.000 --> 01:22:07.000
It doesn't grow corn as they say

01:22:07.000 --> 01:22:10.000
or make corn, however you are supposed to say it.

01:22:10.000 --> 01:22:15.000
And that's fine because if it did, then it would certainly all get a bit serious

01:22:15.000 --> 01:22:18.000
and it kind of really matters whether you get it right or wrong

01:22:18.000 --> 01:22:22.000
whereas here we're just sort of having fun

01:22:22.000 --> 01:22:23.000
but you can...

01:22:23.000 --> 01:22:24.000
I don't know.

01:22:24.000 --> 01:22:27.000
I can kind of see why heretics would get burnt at the stake

01:22:27.000 --> 01:22:29.000
when religion had social power

01:22:29.000 --> 01:22:34.000
because you become convinced that this is the source of meaning

01:22:34.000 --> 01:22:36.000
this is the source of truth without it we are nothing.

01:22:36.000 --> 01:22:37.000
It's now being threatened.

01:22:37.000 --> 01:22:40.000
And then it turns out that maybe there are actually some holes to poke here

01:22:40.000 --> 01:22:41.000
or what are you going to do?

01:22:41.000 --> 01:22:43.000
I mean, you can't let them do that

01:22:43.000 --> 01:22:48.000
because this is literally societally calamitous

01:22:48.000 --> 01:22:50.000
and so they end up getting burnt at the stake.

01:22:50.000 --> 01:22:51.000
That's what also annoys me.

01:22:51.000 --> 01:22:53.000
I mean, you mentioned earlier this recent resurgence in the idea

01:22:53.000 --> 01:22:56.000
that we're all sort of balancing on Judeo-Christian values

01:22:57.000 --> 01:22:59.000
may be kind of true in a sense

01:22:59.000 --> 01:23:01.000
but it does kind of get on my nerves

01:23:01.000 --> 01:23:02.000
that after...

01:23:02.000 --> 01:23:04.000
I said this to Ben yesterday

01:23:04.000 --> 01:23:08.000
that the history of religious persecution

01:23:08.000 --> 01:23:10.000
against the very developments

01:23:10.000 --> 01:23:13.000
that those religious groups now like to claim as their own

01:23:13.000 --> 01:23:17.000
I think the religion has shown to be wrong on a number of things

01:23:17.000 --> 01:23:19.000
I listed them yesterday

01:23:19.000 --> 01:23:21.000
the position of women in society

01:23:21.000 --> 01:23:23.000
the fate of homosexuals

01:23:23.000 --> 01:23:25.000
at least practicing homosexuals

01:23:25.000 --> 01:23:27.000
the position of the earth in relation to the sun

01:23:27.000 --> 01:23:31.000
the age of both of those celestial bodies

01:23:31.000 --> 01:23:35.000
wrong about the common evolutionary ancestry of all animals

01:23:35.000 --> 01:23:37.000
including the human animal

01:23:37.000 --> 01:23:40.000
wrong about the ownership of other human beings as private property

01:23:40.000 --> 01:23:42.000
as it's explicitly condoned not only in the Old Testament

01:23:42.000 --> 01:23:44.000
but also in the new

01:23:44.000 --> 01:23:48.000
and now not only does religion sort of...

01:23:48.000 --> 01:23:51.000
I mean, religion fails to come to us with an apology

01:23:51.000 --> 01:23:53.000
and contrition and say maybe we were wrong

01:23:53.000 --> 01:23:56.000
it says, no, no, no, those things are ours all along

01:23:56.000 --> 01:23:58.000
it says, yes

01:23:58.000 --> 01:24:02.000
we may have shown the instruments of torture to Galileo

01:24:02.000 --> 01:24:04.000
because he suggested that the earth might orbit the sun

01:24:04.000 --> 01:24:06.000
rather than the other way around

01:24:06.000 --> 01:24:10.000
but hey, didn't you know that the scientific revolution

01:24:10.000 --> 01:24:13.000
is essentially Judeo-Christian in origin?

01:24:13.000 --> 01:24:17.000
Yes, the Old Testament gives you explicit instructions

01:24:17.000 --> 01:24:20.000
about exactly how to either buy or steal other human beings

01:24:20.000 --> 01:24:23.000
and keep them sometimes as your sexual property

01:24:23.000 --> 01:24:26.000
but don't you know that the abolitionist movement

01:24:26.000 --> 01:24:29.000
is essentially Judeo-Christian in origin?

01:24:29.000 --> 01:24:32.000
Yes, I know that St. Paul says that

01:24:32.000 --> 01:24:34.000
man is the glory of God

01:24:34.000 --> 01:24:36.000
but woman is the glory of man

01:24:36.000 --> 01:24:37.000
and that I suffer not a woman to teach

01:24:37.000 --> 01:24:38.000
nor to assert authority over a man

01:24:38.000 --> 01:24:40.000
rather she should remain silent

01:24:40.000 --> 01:24:42.000
for Adam was formed first then Eve

01:24:42.000 --> 01:24:44.000
but don't you know that social justice movements

01:24:44.000 --> 01:24:47.000
are essentially Judeo-Christian in origin?

01:24:47.000 --> 01:24:50.000
Yes, we know about the stoning of homosexuals

01:24:50.000 --> 01:24:53.000
and the fact that even St. Paul says

01:24:53.000 --> 01:24:54.000
that they're not getting into heaven

01:24:54.000 --> 01:24:56.000
but don't you know that the LGBT movement

01:24:56.000 --> 01:24:59.000
is essentially sort of riding on Judeo-Christian principles?

01:24:59.000 --> 01:25:01.000
It seems to me relatively offensive

01:25:01.000 --> 01:25:03.000
to the people who've managed to secure these developments

01:25:03.000 --> 01:25:04.000
against the very religious traditions

01:25:04.000 --> 01:25:06.000
that now like to claim them as their own.

01:25:06.000 --> 01:25:09.000
Yeah, both cause and effect

01:25:09.000 --> 01:25:12.000
it's like being punched in the face by somebody

01:25:12.000 --> 01:25:15.000
who then comes over and gives you a bandage for it.

01:25:15.000 --> 01:25:17.000
I mean people like to refer to

01:25:17.000 --> 01:25:19.000
and this is, I'm sort of rehashing some of the stuff

01:25:19.000 --> 01:25:21.000
that I said yesterday here

01:25:25.000 --> 01:25:29.000
people like to point out that the people

01:25:29.000 --> 01:25:33.000
who really got the scientific revolution going

01:25:33.000 --> 01:25:35.000
or often believe as in God,

01:25:35.000 --> 01:25:37.000
Galileo believed in God, Newton believed in God

01:25:37.000 --> 01:25:39.000
in fact Newton spent, but people were fascinated

01:25:39.000 --> 01:25:41.000
to discover his diaries to find that he spent more time

01:25:41.000 --> 01:25:44.000
writing about theology than science.

01:25:44.000 --> 01:25:46.000
A mad man for the last 30 years doing alchemy, right?

01:25:46.000 --> 01:25:48.000
Right, but here's the thing, right?

01:25:48.000 --> 01:25:52.000
Like if, and as I said yesterday

01:25:52.000 --> 01:25:54.000
I don't claim that this is the case

01:25:54.000 --> 01:25:58.000
but if it were true that science had like undermined

01:25:58.000 --> 01:26:01.000
religion and Christianity, if it were the case that

01:26:01.000 --> 01:26:03.000
actually these things aren't compatible with each other

01:26:03.000 --> 01:26:05.000
then when somebody says, well that can't be the case

01:26:05.000 --> 01:26:07.000
because don't you know that the people who sort of founded

01:26:07.000 --> 01:26:08.000
the scientific revolution were religious?

01:26:08.000 --> 01:26:09.000
Well what else would they have been

01:26:09.000 --> 01:26:11.000
if they hadn't yet invented the mechanism

01:26:11.000 --> 01:26:13.000
by which their beliefs would come to be undermined?

01:26:13.000 --> 01:26:15.000
It's like saying that it's amazing that the person

01:26:15.000 --> 01:26:19.000
who invented the motor car didn't own a motor car beforehand.

01:26:19.000 --> 01:26:20.000
You see what I'm saying?

01:26:20.000 --> 01:26:22.000
It's sort of, I don't know, it seems very strange to me

01:26:22.000 --> 01:26:25.000
and it's very recently that the popularity of this

01:26:25.000 --> 01:26:26.000
has increased as you say.

01:26:26.000 --> 01:26:28.000
I mean you go back to the mid-naughties

01:26:28.000 --> 01:26:30.000
at the height of new atheism and it was very popular

01:26:30.000 --> 01:26:32.000
to talk about how religions sort of always getting

01:26:32.000 --> 01:26:34.000
in the way of science and maybe that was a bit crude

01:26:34.000 --> 01:26:38.000
but I think we're seeing an equally crude annexation

01:26:38.000 --> 01:26:42.000
of all of the beneficial social developments

01:26:42.000 --> 01:26:46.000
of the past 100 years as somehow necessarily standing

01:26:46.000 --> 01:26:48.000
upon the Judeo-Christian tradition

01:26:48.000 --> 01:26:50.000
as if it couldn't have happened without them.

01:26:50.000 --> 01:26:55.000
Is this a scrabbling for something to hold on to

01:26:55.000 --> 01:26:57.000
given that the collapse of grand narratives

01:26:57.000 --> 01:27:00.000
has had some poor externalities over the last couple of years?

01:27:00.000 --> 01:27:01.000
Is it just mass cope?

01:27:01.000 --> 01:27:02.000
I think so.

01:27:02.000 --> 01:27:05.000
I think that nihilism as it were carries with it

01:27:05.000 --> 01:27:08.000
the feeling of being naked.

01:27:08.000 --> 01:27:11.000
You sort of thrown off what were essentially

01:27:11.000 --> 01:27:14.000
optional clothes to reveal what was there all along

01:27:14.000 --> 01:27:19.000
but when you actually face it to nature

01:27:19.000 --> 01:27:21.000
it's embarrassing, it's scary

01:27:21.000 --> 01:27:23.000
and you will do anything you can

01:27:23.000 --> 01:27:25.000
if you find yourself naked in public

01:27:25.000 --> 01:27:28.000
to find any clothes to put on, not just your old ones.

01:27:28.000 --> 01:27:29.000
It doesn't matter what clothes.

01:27:29.000 --> 01:27:31.000
Any clothes are better than no clothes

01:27:31.000 --> 01:27:33.000
and this is what people are beginning to realize

01:27:33.000 --> 01:27:36.000
and so they're scrambling for their old clothes again.

01:27:36.000 --> 01:27:38.000
Trying to legitimate.

01:27:38.000 --> 01:27:43.000
Yes, and trying to put them on

01:27:43.000 --> 01:27:45.000
and that's why it's easy as well

01:27:45.000 --> 01:27:47.000
for people to go around poking holes in other people's clothes.

01:27:47.000 --> 01:27:49.000
It's very easy to do

01:27:49.000 --> 01:27:52.000
but that's what the success of a movement like New Atheism

01:27:52.000 --> 01:27:54.000
consists in the fact that all they had to do

01:27:54.000 --> 01:27:56.000
was just tell other people why they're wrong.

01:27:56.000 --> 01:27:58.000
You only need to poke holes in other people's clothes

01:27:58.000 --> 01:28:00.000
but if you need to sew your own shirt

01:28:00.000 --> 01:28:02.000
that gets a little more difficult.

01:28:02.000 --> 01:28:04.000
Yes, Lewis said that the purpose of philosophy

01:28:04.000 --> 01:28:07.000
is not the cutting down of forests

01:28:07.000 --> 01:28:09.000
but the irrigation of deserts.

01:28:10.000 --> 01:28:11.000
That's very interesting.

01:28:11.000 --> 01:28:13.000
Yeah, I've thought about this for a good while.

01:28:16.000 --> 01:28:20.000
The seductiveness of being critic

01:28:20.000 --> 01:28:23.000
as opposed to being somebody that makes suggestions

01:28:23.000 --> 01:28:26.000
and the lack of preparedness of anybody

01:28:26.000 --> 01:28:28.000
to put forward any proposals for anything.

01:28:28.000 --> 01:28:30.000
And it's easy for both sides

01:28:30.000 --> 01:28:32.000
to accuse each other of being reactionary.

01:28:32.000 --> 01:28:34.000
The reactionary right, the reactionary left.

01:28:38.000 --> 01:28:41.000
For instance, a perfect example of this

01:28:41.000 --> 01:28:44.000
is in the world of dating

01:28:44.000 --> 01:28:46.000
and mate selection in the mating market

01:28:46.000 --> 01:28:49.000
everybody can provide criticisms

01:28:49.000 --> 01:28:51.000
about what's going wrong

01:28:51.000 --> 01:28:54.000
and almost nobody provides any actionable steps to improve it

01:28:54.000 --> 01:28:57.000
beyond something that is

01:28:57.000 --> 01:28:59.000
illimitative rather than additive.

01:28:59.000 --> 01:29:02.000
If we could just stop doing this

01:29:02.000 --> 01:29:04.000
then this would be fixed.

01:29:04.000 --> 01:29:06.000
I don't think that's quite the way that it works.

01:29:06.000 --> 01:29:09.000
And there's another very unique protection mechanism

01:29:09.000 --> 01:29:11.000
that's given which is

01:29:11.000 --> 01:29:14.000
it's very hard to criticize someone's criticism

01:29:14.000 --> 01:29:18.000
or at least being a critic

01:29:18.000 --> 01:29:20.000
leaves you open to criticism

01:29:20.000 --> 01:29:23.000
way less than being a proposer.

01:29:23.000 --> 01:29:25.000
If I put something forward

01:29:25.000 --> 01:29:27.000
if I posit a potential solution

01:29:27.000 --> 01:29:29.000
for you to be able to come back and say

01:29:29.000 --> 01:29:31.000
this is shit and this is shit and this is shit

01:29:31.000 --> 01:29:33.000
it's very easy to do.

01:29:33.000 --> 01:29:35.000
Whereas for you to say

01:29:35.000 --> 01:29:37.000
for me to critic what you did

01:29:37.000 --> 01:29:39.000
and then for you to come back and go

01:29:39.000 --> 01:29:41.000
actually this and this and this

01:29:41.000 --> 01:29:43.000
it gets all a little bit abstract

01:29:43.000 --> 01:29:45.000
and it's a few degrees removed from anything that feels real.

01:29:45.000 --> 01:29:47.000
Simon Cowell can't write a song.

01:29:47.000 --> 01:29:50.000
If the world was full of Simon Cowell

01:29:50.000 --> 01:29:52.000
we'd end up with no music.

01:29:52.000 --> 01:29:54.000
Somebody's got to do the building here.

01:29:54.000 --> 01:29:56.000
You can't just be a critic.

01:29:56.000 --> 01:29:58.000
And this is what I think

01:29:58.000 --> 01:30:01.000
has been the reason for the success

01:30:01.000 --> 01:30:03.000
of the sort of anti-New Atheist stuff

01:30:03.000 --> 01:30:05.000
that we've been seeing recently.

01:30:05.000 --> 01:30:06.000
You'll have seen this.

01:30:06.000 --> 01:30:07.000
Even the New Atheist themselves

01:30:07.000 --> 01:30:09.000
sort of treat it like it's a dead animal

01:30:09.000 --> 01:30:10.000
and in many ways it is

01:30:10.000 --> 01:30:12.000
and I think it's got to do with the fact that

01:30:12.000 --> 01:30:14.000
they've done a very good job

01:30:14.000 --> 01:30:17.000
of cutting down the central pillar

01:30:17.000 --> 01:30:21.000
of what has traditionally been

01:30:21.000 --> 01:30:23.000
the reason for people getting out of bed

01:30:23.000 --> 01:30:24.000
in the morning.

01:30:24.000 --> 01:30:26.000
And then when people are there saying

01:30:26.000 --> 01:30:28.000
well, what do we put in its place?

01:30:28.000 --> 01:30:30.000
They're like, see ya.

01:30:30.000 --> 01:30:31.000
You know, I'm out.

01:30:31.000 --> 01:30:33.000
And they go off and do different things.

01:30:33.000 --> 01:30:35.000
And what are people to do?

01:30:35.000 --> 01:30:36.000
And that's why...

01:30:36.000 --> 01:30:37.000
Was it the job of the New Atheists

01:30:37.000 --> 01:30:39.000
to provide something to...

01:30:39.000 --> 01:30:41.000
Well, maybe not.

01:30:41.000 --> 01:30:43.000
Some people are just good at diagnosing problems.

01:30:43.000 --> 01:30:45.000
Karl Marx is a good example.

01:30:47.000 --> 01:30:49.000
Karl Marx's diagnoses

01:30:49.000 --> 01:30:52.000
of the way the world works

01:30:52.000 --> 01:30:53.000
are fascinating to read

01:30:53.000 --> 01:30:54.000
and incredibly useful

01:30:54.000 --> 01:30:55.000
even if you disagree with them.

01:30:55.000 --> 01:30:59.000
But obviously attempts to

01:30:59.000 --> 01:31:02.000
sort of build societies

01:31:02.000 --> 01:31:05.000
on those ideas alone have failed.

01:31:05.000 --> 01:31:08.000
Seems like you need something a little bit more.

01:31:08.000 --> 01:31:11.000
I just don't think it's true

01:31:11.000 --> 01:31:13.000
the religion stuff, I mean.

01:31:13.000 --> 01:31:15.000
And so that's why I think

01:31:15.000 --> 01:31:16.000
we're seeing this

01:31:16.000 --> 01:31:17.000
because people are beginning to realize

01:31:17.000 --> 01:31:19.000
that it probably isn't true.

01:31:19.000 --> 01:31:21.000
They can't quite get behind

01:31:21.000 --> 01:31:23.000
the truth claims.

01:31:23.000 --> 01:31:25.000
But they recognize that there's some utility

01:31:25.000 --> 01:31:27.000
in having other people believe

01:31:27.000 --> 01:31:29.000
that it is true.

01:31:29.000 --> 01:31:32.000
And I don't know where that leaves us

01:31:32.000 --> 01:31:34.000
because in this discussion

01:31:34.000 --> 01:31:36.000
about whether religion is good or bad for society,

01:31:36.000 --> 01:31:37.000
I said yesterday,

01:31:37.000 --> 01:31:40.000
look, I will accept your premise wholesale

01:31:40.000 --> 01:31:42.000
that religion is good,

01:31:42.000 --> 01:31:44.000
maybe even necessary for society.

01:31:44.000 --> 01:31:45.000
What do you want me to do

01:31:45.000 --> 01:31:46.000
if I just don't think it's true?

01:31:46.000 --> 01:31:48.000
Am I just lying to my children,

01:31:48.000 --> 01:31:49.000
raising and believing something

01:31:49.000 --> 01:31:51.000
that I don't believe is the case

01:31:51.000 --> 01:31:54.000
because I think it will somehow be beneficial to society?

01:31:54.000 --> 01:31:55.000
I don't think it works like that.

01:31:55.000 --> 01:31:57.000
I don't think people can actually fool themselves.

01:31:57.000 --> 01:31:58.000
Sure, you can act as if God exists,

01:31:58.000 --> 01:31:59.000
and that's what someone like Peterson says

01:31:59.000 --> 01:32:01.000
that people do already,

01:32:01.000 --> 01:32:03.000
but ultimately if you just say,

01:32:03.000 --> 01:32:04.000
well, I think that, you know,

01:32:04.000 --> 01:32:06.000
it should just act like a Christian

01:32:06.000 --> 01:32:07.000
because it's good for me.

01:32:07.000 --> 01:32:08.000
Then when push comes to shove

01:32:08.000 --> 01:32:10.000
and you really have to make a moral sacrifice,

01:32:10.000 --> 01:32:12.000
if you're not actually a Christian,

01:32:12.000 --> 01:32:13.000
you're probably not going to do

01:32:13.000 --> 01:32:14.000
the actually Christian thing.

01:32:14.000 --> 01:32:16.000
Well, I wonder whether this is afforded to people

01:32:16.000 --> 01:32:19.000
because of the convenience and comfort of modern life.

01:32:19.000 --> 01:32:21.000
The fact that having to really,

01:32:21.000 --> 01:32:22.000
really put something on the line,

01:32:22.000 --> 01:32:25.000
it's mostly lapping as belief systems

01:32:25.000 --> 01:32:27.000
and I'll pick up that piece of trash

01:32:27.000 --> 01:32:31.000
and I will give money to this person on the street.

01:32:31.000 --> 01:32:33.000
Yeah, people have sort of forgotten.

01:32:33.000 --> 01:32:35.000
It's like bourgeois religious belief.

01:32:35.000 --> 01:32:37.000
It's so irregularly that we have to make

01:32:37.000 --> 01:32:39.000
genuine moral sacrifices of the kind

01:32:39.000 --> 01:32:40.000
that used to be commonplace

01:32:40.000 --> 01:32:41.000
throughout the history of humanity

01:32:41.000 --> 01:32:44.000
that we've sort of forgotten our ability to do so.

01:32:44.000 --> 01:32:45.000
And I think that if you push people now,

01:32:46.000 --> 01:32:47.000
they recognize that they probably wouldn't

01:32:47.000 --> 01:32:48.000
make those sacrifices.

01:32:48.000 --> 01:32:50.000
Did you see the Mr. Beast poll where he asked,

01:32:50.000 --> 01:32:51.000
would you rather have like a million dollars

01:32:51.000 --> 01:32:53.000
or like a random person on Earth dies

01:32:53.000 --> 01:32:55.000
or something like that if you press this button?

01:32:55.000 --> 01:32:56.000
No.

01:32:56.000 --> 01:32:57.000
And like, I think it might have been

01:32:57.000 --> 01:32:59.000
a majority of people that's slim majority

01:32:59.000 --> 01:33:01.000
said they'd press that button.

01:33:01.000 --> 01:33:02.000
Yeah, kill someone random.

01:33:02.000 --> 01:33:04.000
I'll take a million bucks.

01:33:04.000 --> 01:33:07.000
And I actually kind of believe them.

01:33:07.000 --> 01:33:09.000
I think they actually would.

01:33:09.000 --> 01:33:14.000
And people want to say that that's because

01:33:14.000 --> 01:33:18.000
we've lost our belief in God.

01:33:18.000 --> 01:33:19.000
I don't know.

01:33:19.000 --> 01:33:21.000
Maybe I think a better explanation is just that,

01:33:21.000 --> 01:33:23.000
like you say, we've become too comfortable.

01:33:23.000 --> 01:33:25.000
And so when somebody says in other words like,

01:33:25.000 --> 01:33:29.000
oh, well, this must be due to decline in religion

01:33:29.000 --> 01:33:30.000
and the fact that we've forgotten

01:33:30.000 --> 01:33:31.000
our Judeo-Christian heritage.

01:33:31.000 --> 01:33:32.000
I mean, you'll probably hear that a lot

01:33:32.000 --> 01:33:34.000
from people that you might talk to on this podcast.

01:33:34.000 --> 01:33:35.000
They'll say something like that.

01:33:35.000 --> 01:33:36.000
Just think to yourself like,

01:33:36.000 --> 01:33:38.000
is that really the best explanation?

01:33:38.000 --> 01:33:39.000
Is that the only explanation?

01:33:39.000 --> 01:33:41.000
Could it be something to do with the growth of technology?

01:33:41.000 --> 01:33:43.000
Could it be to do with something

01:33:44.000 --> 01:33:45.000
to do with the growth of comfort?

01:33:45.000 --> 01:33:46.000
Yeah.

01:33:46.000 --> 01:33:47.000
And is it more likely to do with that?

01:33:47.000 --> 01:33:49.000
And maybe it's not the lack of religion

01:33:49.000 --> 01:33:51.000
that's causing the other stuff,

01:33:51.000 --> 01:33:54.000
but this other source that's causing both of those things.

01:33:54.000 --> 01:33:55.000
Yeah.

01:33:55.000 --> 01:33:57.000
I've been thinking a lot recently about stuff

01:33:57.000 --> 01:34:00.000
that is literally true, but figuratively false

01:34:00.000 --> 01:34:03.000
and figuratively true, but literally false.

01:34:03.000 --> 01:34:08.000
And it kind of seems a little bit like the beliefs

01:34:08.000 --> 01:34:10.000
that you're talking about here.

01:34:10.000 --> 01:34:13.000
It may be comforting, increasing in happiness,

01:34:13.000 --> 01:34:16.000
adaptive to kind of act as if these things exist.

01:34:16.000 --> 01:34:19.000
The belief in free will, actually.

01:34:19.000 --> 01:34:21.000
Believing in free will or sorry.

01:34:21.000 --> 01:34:24.000
Yeah, determinism generally is something

01:34:24.000 --> 01:34:28.000
that may be literally true, but figuratively false.

01:34:28.000 --> 01:34:29.000
Yes.

01:34:29.000 --> 01:34:31.000
And that's kind of where I've come to

01:34:31.000 --> 01:34:32.000
as an opinion with this,

01:34:32.000 --> 01:34:35.000
that largely it's through designed ignorance

01:34:35.000 --> 01:34:37.000
that I just don't think about it that much.

01:34:37.000 --> 01:34:39.000
Precisely the reason it evolves.

01:34:39.000 --> 01:34:41.000
That that's why it exists as an illusion

01:34:41.000 --> 01:34:43.000
because it does something for us.

01:34:43.000 --> 01:34:44.000
And that's fine.

01:34:44.000 --> 01:34:46.000
I've never had a problem saying that,

01:34:46.000 --> 01:34:49.000
but when the sort of auspices under which

01:34:49.000 --> 01:34:51.000
I'm having a conversation with Ben Shapiro

01:34:51.000 --> 01:34:54.000
is that he made a video called The Atheist Illusion.

01:34:54.000 --> 01:34:56.000
And in that video, he says like,

01:34:56.000 --> 01:34:59.000
look, you can't have free will without God.

01:34:59.000 --> 01:35:00.000
I say, yeah, I agree.

01:35:00.000 --> 01:35:02.000
You can't have free will without God.

01:35:02.000 --> 01:35:04.000
You just also can't have it with God.

01:35:04.000 --> 01:35:06.000
And he essentially says like,

01:35:06.000 --> 01:35:08.000
well, you know, there's sort of a,

01:35:08.000 --> 01:35:09.000
I don't know how free will works,

01:35:09.000 --> 01:35:11.000
but it's sort of a mystery that I'm willing

01:35:11.000 --> 01:35:12.000
to accept wholesale.

01:35:12.000 --> 01:35:14.000
And I'm like, well, this is fine,

01:35:14.000 --> 01:35:17.000
but who's the delusory one here?

01:35:17.000 --> 01:35:18.000
You know what I mean?

01:35:18.000 --> 01:35:20.000
Like I've got no problem with you saying like,

01:35:20.000 --> 01:35:22.000
well, I see that this is more Ben Shapiro, by the way,

01:35:22.000 --> 01:35:24.000
but I have no problem with somebody saying, well,

01:35:24.000 --> 01:35:26.000
yeah, I mean, maybe free will doesn't exist,

01:35:26.000 --> 01:35:28.000
but it's better to act as though it does.

01:35:28.000 --> 01:35:29.000
It's like, okay, fine.

01:35:29.000 --> 01:35:31.000
But then don't say that I'm the one acting under a delusion.

01:35:31.000 --> 01:35:32.000
I mean, delusions can be good.

01:35:32.000 --> 01:35:33.000
They might evolve for a good reason,

01:35:33.000 --> 01:35:35.000
but I don't know.

01:35:35.000 --> 01:35:37.000
I guess I find it difficult to treat something as true.

01:35:37.000 --> 01:35:40.000
That isn't, it's a bit like the gun has always loaded.

01:35:40.000 --> 01:35:44.000
That's one of Brett Weinstein's example examples.

01:35:44.000 --> 01:35:46.000
It's, it's not true that the gun has always loaded,

01:35:46.000 --> 01:35:48.000
but we're just going to pretend that it is.

01:35:48.000 --> 01:35:49.000
And that's much better.

01:35:49.000 --> 01:35:50.000
At least we're good society.

01:35:50.000 --> 01:35:51.000
If we always act like that.

01:35:51.000 --> 01:35:52.000
They're truly false, but figuratively true.

01:35:52.000 --> 01:35:57.000
But like, you can't actually act like it's true.

01:35:57.000 --> 01:35:59.000
Like if you ask me to put money on,

01:35:59.000 --> 01:36:01.000
like opening the gun and seeing if there's a bullet in that.

01:36:01.000 --> 01:36:03.000
You can behave in a way that functions as if it were.

01:36:03.000 --> 01:36:04.000
Yeah.

01:36:04.000 --> 01:36:05.000
But then when push comes to shove

01:36:05.000 --> 01:36:07.000
and you really need to make a decision,

01:36:07.000 --> 01:36:08.000
you're not going to be able to do it

01:36:08.000 --> 01:36:09.000
unless you really believe it's true.

01:36:09.000 --> 01:36:10.000
Right.

01:36:10.000 --> 01:36:11.000
So this only works in low stakes situations.

01:36:11.000 --> 01:36:12.000
Exactly.

01:36:12.000 --> 01:36:13.000
Yeah.

01:36:13.000 --> 01:36:15.000
So if, so, you know, it's all too easy to say, oh, you know, we,

01:36:15.000 --> 01:36:17.000
we'll just, we'll just sort of act as though it's true.

01:36:17.000 --> 01:36:18.000
Good example here.

01:36:18.000 --> 01:36:21.000
Using the, using the act as if the gun is loaded thing.

01:36:21.000 --> 01:36:23.000
You do not point it at anybody.

01:36:23.000 --> 01:36:25.000
You do not leave it around the children.

01:36:25.000 --> 01:36:26.000
You do not do the rest of it.

01:36:26.000 --> 01:36:29.000
If a robber breaks into your house,

01:36:29.000 --> 01:36:32.000
you don't go downstairs with said gun acting as if it's loaded.

01:36:32.000 --> 01:36:33.000
Exactly.

01:36:33.000 --> 01:36:34.000
Exactly right.

01:36:34.000 --> 01:36:36.000
And so the moment that it actually really matters,

01:36:36.000 --> 01:36:40.000
like in the prior case, it only matters when it goes wrong, right?

01:36:40.000 --> 01:36:43.000
But when it begins to matter when it goes right

01:36:43.000 --> 01:36:47.000
and that it goes right, this principle just doesn't work.

01:36:47.000 --> 01:36:50.000
And so I'm, I'm suspicious of its efficacy in other words.

01:36:50.000 --> 01:36:53.000
I think we might need to actually start acting in accordance with what's true,

01:36:53.000 --> 01:36:55.000
which by the way is what people have been saying for a long time.

01:36:55.000 --> 01:36:57.000
Oh, why don't we all just act in accordance with what's true?

01:36:57.000 --> 01:37:01.000
And then suddenly when you begin to realize that maybe free will doesn't exist,

01:37:01.000 --> 01:37:04.000
maybe morality is just a social adaptation.

01:37:04.000 --> 01:37:07.000
Suddenly this idea of acting in accordance with what's true

01:37:07.000 --> 01:37:10.000
is a point of principle goes out the window.

01:37:10.000 --> 01:37:15.000
And it's amazing how I sort of see deontologists,

01:37:15.000 --> 01:37:20.000
virtue ethicists transform for my very eyes into utilitarians.

01:37:20.000 --> 01:37:23.000
Out goes the principle of live in accordance with the truth,

01:37:23.000 --> 01:37:26.000
out go the principles of honesty

01:37:26.000 --> 01:37:29.000
and sort of lack of intentional self-deception.

01:37:29.000 --> 01:37:31.000
Because, well, we want the greatest good for the greatest number.

01:37:31.000 --> 01:37:33.000
A better, more functional society comes about

01:37:33.000 --> 01:37:35.000
if we just pretend as though this is the case.

01:37:35.000 --> 01:37:38.000
What happened to the virtue? What happened to the principle?

01:37:38.000 --> 01:37:41.000
What happened to the deontological ethics?

01:37:41.000 --> 01:37:43.000
It's just out the window all of a sudden.

01:37:43.000 --> 01:37:46.000
I think sometimes people like to have their cake and eat it too in that respect.

01:37:46.000 --> 01:37:49.000
I like to act in accordance with what I think is true.

01:37:49.000 --> 01:37:50.000
And when somebody challenges me and says,

01:37:50.000 --> 01:37:53.000
well, you don't act as though you don't have free will,

01:37:53.000 --> 01:37:55.000
I just don't know what that means.

01:37:55.000 --> 01:37:57.000
I don't know what that looks like.

01:37:57.000 --> 01:37:59.000
It probably looks something like this.

01:37:59.000 --> 01:38:01.000
Alex O'Connor, ladies and gentlemen.

01:38:01.000 --> 01:38:03.000
Alex, it's been a while since I've had you on.

01:38:03.000 --> 01:38:06.000
I think I'm going to be joining you on your show at some point soon.

01:38:06.000 --> 01:38:07.000
I hope so.

01:38:07.000 --> 01:38:10.000
What can people expect of you over the next couple of months?

01:38:10.000 --> 01:38:11.000
What's coming up?

01:38:11.000 --> 01:38:13.000
Hopefully that conversation with Ben Shapiro,

01:38:13.000 --> 01:38:17.000
which I'll mention for a 16 billionth time,

01:38:17.000 --> 01:38:18.000
will be out.

01:38:18.000 --> 01:38:20.000
I've got a few debates coming up.

01:38:20.000 --> 01:38:22.000
Oxford Union, Durham Union,

01:38:22.000 --> 01:38:25.000
something at Cambridge on the monarchy.

01:38:25.000 --> 01:38:27.000
You're being known for that.

01:38:27.000 --> 01:38:32.000
Piers Morgan's catapulted you to the forefront of the anti-monarchists.

01:38:32.000 --> 01:38:36.000
I'm becoming something of a royal correspondent for that news channel.

01:38:36.000 --> 01:38:37.000
An anti-royal correspondent.

01:38:37.000 --> 01:38:41.000
Hey, my Twitter bio is growing by the minute on this forecast.

01:38:41.000 --> 01:38:44.000
Where should people go if they want to keep up to date with the stuff you do?

01:38:44.000 --> 01:38:46.000
Just type in my name, Alex O'Connor.

01:38:46.000 --> 01:38:48.000
I am technically still Cosmic Skeptic.

01:38:48.000 --> 01:38:50.000
That's my old handle.

01:38:50.000 --> 01:38:52.000
I tend to go by my Christian name now,

01:38:52.000 --> 01:38:55.000
but the handles are still there, so you'll still find me that way too.

01:38:55.000 --> 01:38:56.000
Alex, I appreciate you.

01:38:56.000 --> 01:38:57.000
Thank you, mate.

01:38:57.000 --> 01:38:59.000
Thank you very much for tuning in.

01:38:59.000 --> 01:39:00.000
If you enjoyed that episode,

01:39:00.000 --> 01:39:05.000
you will love my full-length, two-hour-long podcast with Douglas Murray.

01:39:05.000 --> 01:39:06.000
Go on.

01:39:07.000 --> 01:39:08.000
Press it.

