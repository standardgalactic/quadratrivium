1
00:00:00,000 --> 00:00:19,560
Hi everybody, I'm Peter Morgan, so I represent a company called Deep Learning Partnership

2
00:00:19,560 --> 00:00:26,480
which is an AI consulting company, so it's plain old deep learning for my bread and butter.

3
00:00:26,480 --> 00:00:34,800
But today I'm going to talk outside of that into what I see as the future.

4
00:00:34,800 --> 00:00:43,320
So here's a little book that I wrote for O'Reilly, it's free to download, so go ahead, machine

5
00:00:43,320 --> 00:00:48,040
learning is changing the rules, there's my company website, there's my Twitter handle.

6
00:00:48,040 --> 00:00:53,960
I tweet on sort of what I'm going to be talking about today a lot, so you can sort of keep

7
00:00:53,960 --> 00:00:57,680
up to date if you so desire.

8
00:00:57,680 --> 00:01:00,240
So what am I going to talk about?

9
00:01:00,240 --> 00:01:05,760
So what is intelligence, a good place to start, if we're trying to solve it, we need to ask

10
00:01:05,760 --> 00:01:10,400
what it is, figure out exactly what it is we're trying to solve.

11
00:01:10,400 --> 00:01:17,960
So I'll start by outlining what I think intelligence is, I'll answer that question today.

12
00:01:17,960 --> 00:01:23,000
And then we'll look at physical systems, biological, non-biological, so the non-biological ones

13
00:01:23,000 --> 00:01:34,400
being computers, silicon, that type of thing, biological systems being us, we are what we

14
00:01:34,400 --> 00:01:40,040
are trying to model, this is it, we're trying to model the human brain.

15
00:01:40,040 --> 00:01:46,600
And not only the human brain, but how biology does intelligence, how biology does intelligence.

16
00:01:46,720 --> 00:01:53,920
The aim of my talk is to describe that and a system that might actually build it.

17
00:01:53,920 --> 00:01:59,760
And then we'll do a quick recap, a very quick recap on deep learning, because I've just

18
00:01:59,760 --> 00:02:05,520
tried to convey that, you know, biology isn't actually deep learning at all, and a lot of

19
00:02:05,520 --> 00:02:10,600
the talks today, particularly the neuroscience talk I saw earlier before lunch, made that

20
00:02:10,600 --> 00:02:17,160
very clear, we're not deep learning won't get us to intelligence, right?

21
00:02:17,160 --> 00:02:21,520
And I'll explain exactly why, well basically it's statistical in what we want as a physical

22
00:02:21,520 --> 00:02:23,040
theory of intelligence, right?

23
00:02:23,040 --> 00:02:27,280
So I'll go more into the physics and the neuroscience.

24
00:02:27,280 --> 00:02:34,360
Finally we'll have a look at a theory of AGI, and I'll talk about that, so that's the very

25
00:02:34,360 --> 00:02:35,760
end of the talk.

26
00:02:35,760 --> 00:02:45,200
Okay, so without further ado, if, yeah, so why do we, okay, hopefully the clicker will

27
00:02:45,200 --> 00:02:46,200
work.

28
00:02:46,200 --> 00:02:50,640
So why do we want to build AGI, well we want to solve intelligence, we want to understand

29
00:02:50,640 --> 00:02:56,840
intelligence, so we want to build systems that we can use to do all these tasks and

30
00:02:56,840 --> 00:03:03,800
then make money from that, or just do all the automate all the boring stuff, and ultimately

31
00:03:03,800 --> 00:03:06,800
if it's general intelligence, we can automate everything.

32
00:03:06,800 --> 00:03:13,240
So then we got to ask, you know, philosophically what do we do, right, if we build these systems,

33
00:03:13,240 --> 00:03:17,240
and my answer to that is we'll just get back to being more human, right?

34
00:03:17,240 --> 00:03:23,360
We won't have to work in factories and production lines, and you know, even though we, a lot

35
00:03:23,360 --> 00:03:26,920
of people have convinced themselves, you know, this is what the true meaning of life is,

36
00:03:26,920 --> 00:03:31,240
I don't buy it, so once we build it, it'll become more obvious what we'll have to do

37
00:03:31,240 --> 00:03:32,240
with ourselves.

38
00:03:32,240 --> 00:03:36,280
Okay, nothing to get too worried about, okay.

39
00:03:36,280 --> 00:03:40,840
I'm not a doomsayer, I'm not here to say, oh my God, you know, the world's ending.

40
00:03:40,840 --> 00:03:44,720
But you know, the conversation at some point always goes there, so I thought I'd just get

41
00:03:44,720 --> 00:03:46,920
that out of the way at the beginning.

42
00:03:46,920 --> 00:03:51,360
So let's focus on trying to build it for the rest of the talk.

43
00:03:51,360 --> 00:03:53,880
So what is general intelligence?

44
00:03:53,880 --> 00:03:59,800
Are any of these, general intelligence, AlphaGo, AlphaStar, playing StarCraft from DeepMind,

45
00:03:59,800 --> 00:04:04,000
you know, I've come over from London where DeepMind are based, the Google company, DeepBlue

46
00:04:04,000 --> 00:04:12,280
from IBM, back in the late 90s, IBM Watson, winning at Jeopardy, natural language processing,

47
00:04:12,280 --> 00:04:15,800
none of those are even close to general intelligence.

48
00:04:15,800 --> 00:04:19,600
They do very specific things, they're completely dumb, they're completely stupid, they use

49
00:04:19,600 --> 00:04:24,040
statistical methods, so no, they're super clever, it's like they can totally outperform

50
00:04:24,040 --> 00:04:28,360
us just like a calculator outperforms us with multiplication, right?

51
00:04:28,360 --> 00:04:33,240
So not dismissing it entirely, but it's not general intelligence, that's not what I'm

52
00:04:33,240 --> 00:04:35,000
here to talk about.

53
00:04:35,000 --> 00:04:39,680
That's what DeepMind does, it's not what I'm trying to do, although ultimately they do

54
00:04:39,680 --> 00:04:43,800
want to do that, and they've said that very, very, very clearly.

55
00:04:43,800 --> 00:04:46,400
But right now they're not doing it.

56
00:04:46,400 --> 00:04:47,400
So what is intelligence?

57
00:04:47,400 --> 00:04:50,680
Well here's the answer, it's not one thing, it's many things.

58
00:04:50,680 --> 00:04:56,720
So it's basically we are agents in our environment, so it's our adaptation to our environment.

59
00:04:56,720 --> 00:05:00,720
If we were living in a different universe with different laws of physics, gravity goes

60
00:05:00,720 --> 00:05:05,000
up instead of down, we would be adapted to that, and so that would be, our intelligence

61
00:05:05,000 --> 00:05:08,880
would be adapted to that environment, okay?

62
00:05:08,880 --> 00:05:13,600
So it's simply adapting to our environment, exploiting our environment, modeling our

63
00:05:13,600 --> 00:05:18,440
environment and predicting, successfully predicting what's going to happen next in our environment.

64
00:05:18,440 --> 00:05:22,160
If you think about it, it just kind of boils down, it's, you know, deflate everything

65
00:05:22,160 --> 00:05:25,400
right now, it just kind of boils down to that, whether we're trying to win the lottery or

66
00:05:25,400 --> 00:05:30,040
build a rocket to the moon, or even build journal intelligence, we're just trying to

67
00:05:30,040 --> 00:05:31,320
model our environment.

68
00:05:31,320 --> 00:05:34,960
It just so happens that we're trying to model our brain, okay, with journal intelligence.

69
00:05:34,960 --> 00:05:38,520
So we've done a pretty good job, you know, we've done, you know, the laws of physics,

70
00:05:38,520 --> 00:05:44,280
we've had Newton, we've had Einstein, we've had Feynman, we've had some super clever computer

71
00:05:44,280 --> 00:05:48,480
scientists, biologists, neuroscientists, but it's all the same thing, we're just trying

72
00:05:48,480 --> 00:05:53,040
to model, just trying to model our environment, okay?

73
00:05:53,040 --> 00:05:57,680
So it's not just Einstein, that's not the only thing that has to do with intelligence,

74
00:05:57,680 --> 00:06:03,720
it's spatially, you know, we have athletes, you know, that are way better than Einstein

75
00:06:03,720 --> 00:06:05,240
at doing the high jump, right?

76
00:06:05,240 --> 00:06:09,560
So he was crap at that, but very good at modeling general relativity.

77
00:06:09,560 --> 00:06:14,080
But when it came to hurling himself over a high bar at seven feet, you know, he would

78
00:06:14,080 --> 00:06:15,600
just fail miserably.

79
00:06:15,600 --> 00:06:20,120
When the high jumper goes to solve, you know, to understand the universe right down mathematically,

80
00:06:20,120 --> 00:06:21,120
he would fail.

81
00:06:21,400 --> 00:06:24,880
There's not one type of intelligence, okay, there's many.

82
00:06:24,880 --> 00:06:28,560
And that's what the G and AGI stands for, it's general, okay?

83
00:06:28,560 --> 00:06:33,880
So we're trying to build things that are spatially intelligent, aware of the environment, we're

84
00:06:33,880 --> 00:06:39,120
not doing a very good job there, are we, with climate change and everything like that, Donald

85
00:06:39,120 --> 00:06:41,240
Trump, blah, blah, blah, right?

86
00:06:41,240 --> 00:06:45,520
So, you know, that's, for me, is a big part of intelligence is to understanding our environment,

87
00:06:45,520 --> 00:06:48,800
not destroying our environment, but, you know, kind of living in harmony, that might be a

88
00:06:48,880 --> 00:06:54,520
definition in naturalist intelligence, not getting too political, but, you know, that's

89
00:06:54,520 --> 00:06:55,520
what I believe.

90
00:06:55,520 --> 00:07:04,080
Musical, you know, Mozart, Beethoven, the Beatles, whatever type of music you like, and

91
00:07:04,080 --> 00:07:08,680
I've managed to turn that off, that is a type of musical intelligence.

92
00:07:08,680 --> 00:07:13,480
Not everyone can create, write a beautiful melody or a symphony, but some people can,

93
00:07:13,480 --> 00:07:14,480
right?

94
00:07:15,000 --> 00:07:19,680
These are all the different types of intelligence, linguistic, you know, Shakespeare, or, you

95
00:07:19,680 --> 00:07:26,160
know, who can write a great poem, et cetera, et cetera, interpersonal people relationships,

96
00:07:26,160 --> 00:07:33,160
how we relate to one another, social intelligence, emotional intelligence, introspection, how

97
00:07:33,160 --> 00:07:39,200
we understand ourselves, you know, how we react in society, how we go about, you know,

98
00:07:39,440 --> 00:07:45,760
place in the world, and then you build it up hierarchically into nations, you know,

99
00:07:45,760 --> 00:07:49,640
do we go to war, do we not, I mean, how do we keep peace internationally?

100
00:07:49,640 --> 00:07:53,880
These are all different types of intelligence that these machines will have to do if they're

101
00:07:53,880 --> 00:07:56,080
truly general intelligence, okay?

102
00:07:56,080 --> 00:07:59,360
So it's not just the building the Einstein, you can see that now, it's everything.

103
00:07:59,360 --> 00:08:03,920
It's physical, it's political, it's social, it's emotional, okay?

104
00:08:03,920 --> 00:08:08,400
A big ask, a big ask, but we do that in three pounds in our skull, right?

105
00:08:08,440 --> 00:08:13,120
So biology has done it, using 100 billion neurons, roughly, somebody said 86 billion,

106
00:08:13,120 --> 00:08:19,760
but it's of that order of magnitude, and perhaps it's the connections, 1,000 to 10,000 synapses

107
00:08:19,760 --> 00:08:23,000
per neuron, so it's a very complex system.

108
00:08:23,000 --> 00:08:27,200
So it's no wonder, you know, we can't give ourselves too hard a time that we haven't

109
00:08:27,200 --> 00:08:32,400
built it yet, because, you know, it's complex, and also, you know, the earth's 4 billion

110
00:08:32,400 --> 00:08:38,120
years old, we've had a few years, okay, we didn't just come up with this stuff yesterday,

111
00:08:38,120 --> 00:08:42,800
you know, we can go back 10,000 years, 20,000 years, we were pretty much living in caves,

112
00:08:42,800 --> 00:08:43,800
right?

113
00:08:43,800 --> 00:08:47,840
It's only the last 100 or so years that we've kind of, you know, hit this exponential where

114
00:08:47,840 --> 00:08:51,400
we're taking off, and the singularity is there, and all that kind of stuff, right?

115
00:08:51,400 --> 00:08:56,040
So we're living in very interesting times, but this is where intelligence has brought

116
00:08:56,040 --> 00:09:00,080
us, and this is where we are, we're sitting in this conference talking about it, right?

117
00:09:00,080 --> 00:09:03,880
We wouldn't have been doing this maybe even 10 years ago, okay?

118
00:09:03,880 --> 00:09:05,200
So we're ready to build it.

119
00:09:05,200 --> 00:09:06,720
How far have we come?

120
00:09:06,720 --> 00:09:09,280
I would argue not very far.

121
00:09:09,280 --> 00:09:14,080
All these talks we've seen today have all been about deep learning and statistical methods.

122
00:09:14,080 --> 00:09:20,560
The best we've done, I think, is around 50% for logical, mathematical, linguistic.

123
00:09:20,560 --> 00:09:23,720
The last talk was on BERT, it's super impressive stuff.

124
00:09:23,720 --> 00:09:29,480
There's GPT2 with open AI, there's BERT with Google, you know, Facebook, Microsoft, everyone,

125
00:09:29,480 --> 00:09:34,560
all the big tech companies are plowing ahead with these statistical methods, but there's

126
00:09:34,600 --> 00:09:38,880
nothing to do with general intelligence, so, you know, statistics will only get us so far,

127
00:09:38,880 --> 00:09:39,880
right?

128
00:09:39,880 --> 00:09:43,680
And in fact, when it comes to introspection, thinking about the universe, they're actually

129
00:09:43,680 --> 00:09:45,800
zero, they're not even off the ground, okay?

130
00:09:45,800 --> 00:09:49,880
They haven't even started, haven't even begun, and they never will do because it's, statistics

131
00:09:49,880 --> 00:09:51,640
won't do it.

132
00:09:51,640 --> 00:09:53,160
Physics will, statistics won't.

133
00:09:53,160 --> 00:09:58,640
I'm not trying to discredit anyone here, I'm just trying to focus on general intelligence,

134
00:09:58,640 --> 00:09:59,640
okay?

135
00:09:59,640 --> 00:10:01,400
Okay, so how will we get there?

136
00:10:01,440 --> 00:10:06,160
Well, it takes a village to create an AGI, just as it takes a village to raise a child,

137
00:10:06,160 --> 00:10:07,160
right?

138
00:10:07,160 --> 00:10:10,560
It's going to take a village to build these things, so it's not just physicists, it's

139
00:10:10,560 --> 00:10:15,680
not just computer scientists, it's not just, you know, psychologists, it's all of us together,

140
00:10:15,680 --> 00:10:21,680
so it's neuroscientists, psychologists, physicists, computer scientists, everybody, politicians,

141
00:10:21,680 --> 00:10:26,320
because this is general intelligence, we need everybody in the room together.

142
00:10:27,320 --> 00:10:34,560
Okay, so, you know, so physically, you know, biology, biologically and non-biologically,

143
00:10:34,560 --> 00:10:41,680
let's have a, take a look at, you know, how, how physically intelligence manifests, okay?

144
00:10:41,680 --> 00:10:50,960
So, biology, very clever, we start with bacteria, no, no central nervous system, no neurons,

145
00:10:50,960 --> 00:10:55,400
nothing, and yet they survive, they reproduce, they're intelligent, okay?

146
00:10:55,400 --> 00:10:58,640
They're much more intelligent than us, maybe they'll survive longer than us, the rate we're

147
00:10:58,640 --> 00:11:04,200
going, I'm not putting my bets right now, so, you know, that is intelligence without

148
00:11:04,200 --> 00:11:09,360
even a single neuron anywhere to be seen, so they're using chemical gradients, they're

149
00:11:09,360 --> 00:11:14,160
just using the laws of physics to wiggle and wobble about, but they've learned how to reproduce,

150
00:11:14,160 --> 00:11:15,560
create DNA and reproduce.

151
00:11:15,560 --> 00:11:21,880
They haven't learned anything, right, that's a, that's an anthropomorphism, you know, this

152
00:11:21,880 --> 00:11:29,480
is, this is what the laws of physics can do and has done, you know, in terms of biology.

153
00:11:29,480 --> 00:11:35,360
The first thing with the central nervous system is the C. elegans, I think it has 130 odd

154
00:11:35,360 --> 00:11:42,520
neurons, so arguably this is the dumbest thing with the central nervous system, so, but yet

155
00:11:42,520 --> 00:11:47,880
it can, you know, understand, it can survive, it eats, it reproduces, the bumblebee has

156
00:11:47,880 --> 00:11:53,160
about a million neurons, this is how biology does things, it can navigate, it does its

157
00:11:53,160 --> 00:11:59,400
wiggle dance, it's societal, it lives in a society, and right up to us, the brain, the

158
00:11:59,400 --> 00:12:05,200
human brain in fact, you know, you've got all the mammal elephants, fish, chimpanzees,

159
00:12:05,200 --> 00:12:12,240
us, right, so there's a whole spectrum here of intelligence, you know, assuming, assuming

160
00:12:12,600 --> 00:12:18,480
we'll start with the, you know, the simplest systems and build up, but is there something

161
00:12:18,480 --> 00:12:25,360
here that unites these, all of these systems here, you know, because I'm interested in

162
00:12:25,360 --> 00:12:30,240
understanding theoretically what intelligence is, in other words, you know, writing down

163
00:12:30,240 --> 00:12:35,400
the mathematical equations that we will use to guide us when we build these things, okay,

164
00:12:35,400 --> 00:12:40,120
not just sort of trying, does this work, does this work, I'll add another neuron, another

165
00:12:40,120 --> 00:12:44,360
layer to my deep neural network, I want to understand the basic physical, the physics

166
00:12:44,360 --> 00:12:50,840
of intelligence, or, you know, we do as a community, the AGI community, okay, so the

167
00:12:50,840 --> 00:12:57,680
first thing we notice is that biology is hierarchical, we start off with atoms, they're certainly

168
00:12:57,680 --> 00:13:03,680
not intelligent, molecules, neurons, they're not intelligent unto themselves, but when

169
00:13:03,680 --> 00:13:08,920
you start connecting these things together, they connect home, then intelligence emerges

170
00:13:08,920 --> 00:13:15,360
from there, and then we have us, you know, agents, and then we have societies and nations

171
00:13:15,360 --> 00:13:22,800
and finally the world, so, you know, the whole thing is hierarchical from atoms up to nations,

172
00:13:22,800 --> 00:13:28,320
so this general theory will have to explain the whole lot, okay, so it's a big ask, right,

173
00:13:28,320 --> 00:13:32,320
we're actually trying to describe the whole thing and not just bits of it, okay, so just

174
00:13:32,320 --> 00:13:37,080
to kind of sort of expand your mind, put it all in perspective.

175
00:13:37,080 --> 00:13:41,420
So we're coming up with a truly general theory of intelligence, and that's what a neuron

176
00:13:41,420 --> 00:13:45,760
looks like, it's super complex, do we need to go to this level, you know, there's a lot

177
00:13:45,760 --> 00:13:52,800
of open questions, we don't know, we'll see, okay, we'll just see, nature does, clearly,

178
00:13:52,800 --> 00:13:58,080
because that's what a neuron looks like, but when we build these systems will we have to,

179
00:13:58,080 --> 00:14:03,160
it's a very, very, very interesting and open question right now, okay, but it won't stop

180
00:14:03,160 --> 00:14:06,680
us perhaps coming up with the underlying theory.

181
00:14:06,680 --> 00:14:10,920
So this is what a brain looks like, this is what intelligence looks like, it's organized

182
00:14:10,920 --> 00:14:17,320
into structures, repeating structures of about two million neurons in these so-called cortical

183
00:14:17,320 --> 00:14:24,320
columns, again and over and over and over again, so if somebody goes blind, God forbid,

184
00:14:24,320 --> 00:14:30,360
some of those neurons that we use to process visual information are quickly repurposed

185
00:14:30,400 --> 00:14:37,240
into processing sound, okay, so the kind of general, there's a generality there, these

186
00:14:37,240 --> 00:14:43,120
are just information, these are information processing systems that seem to have some

187
00:14:43,120 --> 00:14:48,880
sort of generality, so we do know that, that's something we do know so far, and I'm going

188
00:14:48,880 --> 00:14:54,680
up the hierarchy here, here's the connectome, so it's all connected, besides these tens

189
00:14:54,680 --> 00:14:59,960
of tens of thousands of synapses between each neuron, these things are organized into

190
00:14:59,960 --> 00:15:04,520
some larger, if you go up one level in this hierarchy, then you start to see this connectome

191
00:15:04,520 --> 00:15:09,720
forming, whether that's in humans or even bees, you know, there's this layer above

192
00:15:09,720 --> 00:15:15,480
the neuron set, maybe that's the right layer to start with, okay, and then above that then

193
00:15:15,480 --> 00:15:22,160
that's attached to a central nervous system and all living beings, a fish, a bee, a human,

194
00:15:22,160 --> 00:15:27,480
so it's not just a brain and a jar, although some might argue Stephen Hawking was kind

195
00:15:27,480 --> 00:15:31,440
of that because he had that terrible disease and there are people, so we can function like

196
00:15:31,440 --> 00:15:36,520
that, but we're really interested in building the whole physical as well, but the brain

197
00:15:36,520 --> 00:15:40,600
is the main thing, once we've cracked that, we've cracked intelligence, I'm just saying

198
00:15:40,600 --> 00:15:47,200
we connect it to the rest of our system, do we need kidneys? I doubt it, I doubt we'll

199
00:15:47,200 --> 00:15:53,520
have this thing, a system with kidneys and lungs and everything else, right, but that's

200
00:15:53,520 --> 00:15:59,800
how biology has done it in every single thing, so there's this other part, 90%, you know,

201
00:15:59,800 --> 00:16:04,400
which I think we need to worry about the brain more than the rest of it, but the rest of

202
00:16:04,400 --> 00:16:09,920
it's super clever, but kind of clunky, it's just, nature's put us together like that,

203
00:16:09,920 --> 00:16:15,440
we may not need to go down to that, consider that so much, but if we're building robotics

204
00:16:15,560 --> 00:16:23,120
we will, but a robot might not have kidneys, but it needs to be able to move around fluidly,

205
00:16:23,120 --> 00:16:27,600
and we haven't quite got that yet, even though Atlas does nice backflips and super, I mean

206
00:16:27,600 --> 00:16:32,880
it's getting pretty good, isn't it, every month Boston Dynamics comes out with a new

207
00:16:32,880 --> 00:16:39,160
video, it's like, oh my God, it's like so human, and then they beat themselves, but

208
00:16:39,160 --> 00:16:45,400
it's not intelligent, it can't play chess, it can't ponder the universe, its own existence,

209
00:16:45,600 --> 00:16:48,880
it doesn't even know it's alive, that's how dumb it is, but it's very good with the

210
00:16:48,880 --> 00:16:54,920
physical part, okay, that's all part of intelligence, and then the social systems, we talk about

211
00:16:54,920 --> 00:17:05,000
cloud robotics, form robotics, social intelligence, that's the final layer, okay, so here's where

212
00:17:05,000 --> 00:17:10,280
we are with the non-biological, you know, we've started off with CPUs of von Neumann

213
00:17:10,320 --> 00:17:16,560
architecture we've heard about today, separating the processing from the memory, and then we've

214
00:17:16,560 --> 00:17:20,600
also heard that biology doesn't do that, it does the processing in the memory on the

215
00:17:20,600 --> 00:17:26,240
same thing, Neuron is both a memory and a processor, so none of these, there's this

216
00:17:26,240 --> 00:17:31,520
little von Neumann architecture, okay, so that's what it looks like, it's beautiful,

217
00:17:31,520 --> 00:17:36,720
we saw a picture of a TPU version 3 in the last slide, it's like a supercomputer, it

218
00:17:36,720 --> 00:17:44,840
does like a petaflop or something or more, graph core, there's 100 petaflops in like

219
00:17:44,840 --> 00:17:49,680
eight racks, you know, that's the world's most powerful supercomputer, almost, not quite,

220
00:17:49,680 --> 00:17:55,360
but it's getting up there, so these are ASICs, they're specifically designed to multiply

221
00:17:55,360 --> 00:18:00,600
huge matrix, billion by billion matrices together, which the brain isn't doing clearly, and you

222
00:18:00,600 --> 00:18:04,240
know, that's how many times bigger than the brain is that, right, it's got nothing to

223
00:18:04,280 --> 00:18:08,520
do with general intelligence, but it's super good at multiplying, it's good at linear algebra,

224
00:18:08,520 --> 00:18:15,680
it'll statistically, you know, calculate things, that's why BERT will get statistically brilliant,

225
00:18:15,680 --> 00:18:20,560
but it'll never understand Shakespeare, because it can't, because it's linear algebra, right,

226
00:18:20,560 --> 00:18:26,560
linear algebra doesn't do that, okay, and there is the world's biggest, it's 3x a flop,

227
00:18:26,560 --> 00:18:34,240
it's summit, chock full of GPUs and I think AMD processors, super impressive, but it's

228
00:18:34,240 --> 00:18:40,160
as dumb as a brick, right, doesn't do anything, it's a big calculator, so what are we missing,

229
00:18:40,160 --> 00:18:48,320
so we do all that in three pound, right, we don't need three football fields or 10 megawatts,

230
00:18:49,600 --> 00:18:55,840
we need a couple of sandwiches and apple and a drink, you know, and we can discover the laws

231
00:18:55,840 --> 00:19:04,400
of the universe, okay, so clearly we're not even close by any of those other approaches,

232
00:19:04,400 --> 00:19:11,600
maybe one approach in hardware is neuromorphic computing, which stated aim is to replicate

233
00:19:11,600 --> 00:19:16,320
the brain, okay, in hardware, and so there's a project called Spinnaker, part of the human

234
00:19:16,320 --> 00:19:21,120
brain project, which is doing that, Steve Furber, who was part of ARM, based at University of

235
00:19:21,120 --> 00:19:27,200
Manchester, been working for the last 20 years, he's built, their team there have built, now under

236
00:19:27,200 --> 00:19:32,720
the wing of the human brain project, have built, I think, a billion artificial neurons, so they're

237
00:19:32,720 --> 00:19:41,280
analog, they process the information using analog, not digital, and it's more, it's not the von Neumann,

238
00:19:41,280 --> 00:19:47,280
it's kind of combined, so they call that memristors, where the memory and the processing is combined in

239
00:19:47,280 --> 00:19:52,480
the same place, and the architecture looks completely different, there it is, that's a

240
00:19:52,480 --> 00:19:57,920
billion neurons right there, so immediately we see, you know, it's a little bit smaller than

241
00:19:57,920 --> 00:20:06,480
the others, that's all analog computing, and that's what it looks like, so yeah, we start off with

242
00:20:06,480 --> 00:20:11,680
a thousand neurons per core, and then we put them into chips, and it's hierarchical, then we put 48

243
00:20:11,680 --> 00:20:17,120
chips on a board, 24 boards in a rack, we have 10 racks, right, and that's sitting in a data center

244
00:20:17,120 --> 00:20:22,640
in Manchester today, and you can log in now if you want to, set up an account, log in and start

245
00:20:22,640 --> 00:20:29,040
processing stuff using neuromorphic computing, and you can put in the MNIST data set, you can

246
00:20:29,040 --> 00:20:34,480
place a doku, you can play chess, and it doesn't do deep learning at all, it's processing it with

247
00:20:34,480 --> 00:20:40,000
neuromorphic algorithms and hardware, okay, so for me this is definitely a step in the right

248
00:20:40,000 --> 00:20:45,120
direction, so hardware is important, it's not everything, obviously the algorithms need to be

249
00:20:45,120 --> 00:20:50,400
there as well, but I think we need to be running it on the right hardware, otherwise it's a simulation,

250
00:20:50,400 --> 00:20:55,040
you can always simulate anything on a chip, but you need, you know, they've done that in the human

251
00:20:55,040 --> 00:21:01,600
brain project using, you know, the von Neumann architecture, I think they processed a second

252
00:21:01,600 --> 00:21:07,200
of what the brain can do, it took them like a week in the whole data center, so you know,

253
00:21:07,200 --> 00:21:11,520
you can always simulate things, but it's not efficient, so you can actually simulate in real

254
00:21:11,520 --> 00:21:16,160
time using this neuromorphic architecture, because it runs efficiently like the brain,

255
00:21:16,160 --> 00:21:22,960
I think it's about a thousand times less efficient than biology, whereas the CPUs and

256
00:21:22,960 --> 00:21:28,640
everything else that we saw, digital is about a million times less efficient, so it's definitely

257
00:21:28,640 --> 00:21:33,360
a step, and this is the first generation, so we're going to iterate just like we did with the CPU

258
00:21:33,360 --> 00:21:38,640
processing and the digital, we've had 50 years, we've got 10 billion transistors on a thing,

259
00:21:38,640 --> 00:21:43,760
a centimeter big, right, so we'll do the same with neuromorphic, we'll have generation upon

260
00:21:43,760 --> 00:21:48,640
generation, and soon we'll have 100 billion neurons, because it's Moore's law, it's exponential,

261
00:21:49,200 --> 00:21:55,760
and we will see, you know, sort of human level intelligence, whether it will be sentient and

262
00:21:56,880 --> 00:22:02,000
is down to the algorithms, actually, so I think we have the hardware, we're at the very beginning

263
00:22:02,000 --> 00:22:06,560
of this journey with the hardware, but we need algorithms, so let's look at the algorithms, so

264
00:22:07,120 --> 00:22:10,880
that's another one, the brain scales, that's the University of Heidelberg here in Germany,

265
00:22:10,880 --> 00:22:15,920
that's part of the human brain project as a spinnaker versus the Google TPUs, I would argue

266
00:22:15,920 --> 00:22:21,280
the one on the left with neuromorphic is the right hardware to be working on for general

267
00:22:21,280 --> 00:22:26,160
intelligence, okay, and it's quantum computing, nothing to do with how the brain works, but,

268
00:22:26,160 --> 00:22:31,520
you know, sexy pictures, so I put it up there, and it is, it is like the last form of computing,

269
00:22:31,600 --> 00:22:36,320
right, you cannot forget it, it's a big deal, it's going to come online, but I don't think it will be,

270
00:22:37,120 --> 00:22:42,480
you know, used to, you know, understand nature too well, I think biology doesn't use it, so I

271
00:22:42,480 --> 00:22:46,800
doubt we might have to go to the quantum level, but the quantum will be very important in other

272
00:22:46,800 --> 00:22:52,560
aspects, perhaps not general intelligence, okay, so there's the four summary of everything I've

273
00:22:52,560 --> 00:22:57,360
talked about, the four different types of hardware, the digital, the neuromorphic, quantum, and then

274
00:22:57,360 --> 00:23:05,920
biology, right, so we want to try to build the thing in the lower right hand corner here,

275
00:23:05,920 --> 00:23:12,160
and I think neuromorphic is getting, that's the way we'll do it, and that's what they look like,

276
00:23:12,160 --> 00:23:16,800
okay, so the brain, you see the similarity a little bit, the neurons in the brain, the digital,

277
00:23:16,800 --> 00:23:21,520
the neuromorphic, and quantum looks a bit out on its own weird, but ultimately it's these little

278
00:23:21,520 --> 00:23:28,400
units of information processing, okay, and then the data center of the future won't just be classical

279
00:23:28,400 --> 00:23:36,880
computing, it'll be a mix of quantum, neuromorphic, and classical, so deep learning, quick recap,

280
00:23:36,880 --> 00:23:42,000
that's what it looks like, this is what general intelligence isn't, so it's not that, it's not

281
00:23:42,000 --> 00:23:49,280
that, and that's, you know, deep learning is not AGI, so AGI is linear algebra, so you know,

282
00:23:49,280 --> 00:23:53,680
you're just summing up the weights times these vectors, and billion by billion matrices,

283
00:23:53,680 --> 00:23:59,680
it does not give us a neuron, absolutely, not even close, but never will do, and it was never,

284
00:23:59,680 --> 00:24:04,000
it was never meant to, to be honest, if you talk to the researchers like Jan Lacoon and Jeff Hinton,

285
00:24:04,000 --> 00:24:09,360
they, we're not trying to imitate the brain at all, we just found the stuff that works really well,

286
00:24:09,360 --> 00:24:14,880
but, and then Jeff Hinton, he's in my last slide, says that, you know, if we think really hard about

287
00:24:14,880 --> 00:24:19,280
how nature does it, biology will, that's how we're going to do it, and he's recently said,

288
00:24:19,280 --> 00:24:22,720
everything I've ever done on deep learning is sort of, I'm going to have to put that to one

289
00:24:22,720 --> 00:24:26,960
side now, because to get to the next level, and I saw a slide in some other presentation today,

290
00:24:28,080 --> 00:24:31,840
you know, it's starting to get a bit mainstream now, you know, deep learning is running out of

291
00:24:31,840 --> 00:24:36,480
steam, you know, we can maybe tweak the knobs and get another two or three percent of accuracy,

292
00:24:36,480 --> 00:24:40,320
but yeah, where do we go, it's not general, it's very specific, it's not going to give us those

293
00:24:40,320 --> 00:24:45,360
nine types of intelligence, and I think that's what people are trying to say, even though they

294
00:24:45,360 --> 00:24:50,400
don't quite realize perhaps what they're saying, but that thing on the left is what we're trying to

295
00:24:50,400 --> 00:24:55,920
build, not that little bit of linear algebra on the right. Okay, so what is the theory, okay,

296
00:24:56,800 --> 00:25:01,040
you know, I'd be, I could just walk off the stage now and say, ah, you know, we don't,

297
00:25:01,040 --> 00:25:07,280
I don't know, thanks for coming, you know, spending all your money, but I'll try, I'll try, I'll give

298
00:25:07,840 --> 00:25:16,160
you something, a bit more than that, so let's see, so I mentioned earlier that it's not statistical,

299
00:25:16,160 --> 00:25:21,040
right, so what is it, it's physics, right, everything is built using the laws of physics,

300
00:25:21,040 --> 00:25:26,480
so why not the brain, right, why not, let's start there, it's nice and simple, so what do we know

301
00:25:26,480 --> 00:25:31,760
about physics, right, well we know Newton's laws, we know relativity, we know general relativity,

302
00:25:31,760 --> 00:25:37,440
we have Maxwell's equations from last century, we're standing on shoulders of so many giants

303
00:25:37,440 --> 00:25:43,040
here, Maxwell, Newton, you know, all the greats, Helmholtz, Boltzmann, Gibbs, you know, we got the

304
00:25:43,040 --> 00:25:49,280
laws of thermodynamics, we got quantum mechanics, we don't think we'll need that, but we still have

305
00:25:49,280 --> 00:25:52,800
it, we have relevance at quantum mechanics, we have dark energy, we have stuff we don't know,

306
00:25:52,800 --> 00:25:57,600
dark energy, dark matter, we're probably not involved with intelligence, the thing is that

307
00:25:57,600 --> 00:26:02,160
all of that can be encapsulated in something called the principle of least action,

308
00:26:03,280 --> 00:26:09,920
which says that nature behaves to minimize the free energy of any system, you know,

309
00:26:10,640 --> 00:26:15,440
whether that's microscopic or macroscopic, whether it's a millisecond, a nanosecond,

310
00:26:15,440 --> 00:26:20,240
or the age of the universe, there's this fundamental underlying principle of physics,

311
00:26:20,240 --> 00:26:25,520
if you did a PhD in physics, who did a PhD in physics, yes, so a couple of people here

312
00:26:25,520 --> 00:26:29,920
will have seen this principle of least action, and you write it down, it's a nice beautiful

313
00:26:29,920 --> 00:26:35,040
formulation, you can write it down in Lagrangian or Hamiltonian form, but it's, you know, one line

314
00:26:35,040 --> 00:26:43,440
and you can use it in principle to describe any system, okay, I say in principle because, you

315
00:26:43,440 --> 00:26:47,600
know, nature is complicated, you know, the brain's complicated, as soon as you get more than a few

316
00:26:47,600 --> 00:26:53,360
atoms, you know, or a few molecules, it's hard, right, so, but in principle, this is the underlying

317
00:26:53,360 --> 00:26:57,200
principle, so that's where I'm going to start, right, with the theory of intelligent, I'm going

318
00:26:57,200 --> 00:27:02,000
to say if we can use it for everything else, then let's apply it to the brain, see how far we get,

319
00:27:02,560 --> 00:27:07,040
that's what it looks like, there's a beautiful book just written, I think, yeah, last year at Cambridge

320
00:27:07,040 --> 00:27:11,440
University Press, surprisingly, there's nothing else before this, because it's been around about

321
00:27:11,440 --> 00:27:16,000
100 years, it's called the principle of least action, it's got all the different examples in the world

322
00:27:16,000 --> 00:27:22,720
of thermodynamics, classical mechanics, steam trains, computers, digital, quantum, everything,

323
00:27:22,720 --> 00:27:26,800
chapter on each, how it's applied, how it's applied, how it's applied, how it's applied,

324
00:27:27,600 --> 00:27:32,080
so they need an extra chapter on how it's applied to the brain, I think, but that's what it looks

325
00:27:32,080 --> 00:27:39,920
like, you know, that s is the action, the q is momentum, t is time, and q dots, you know, the

326
00:27:39,920 --> 00:27:46,800
dv dt, the change of momentum with change in time, and delta s equals zero is all the physics,

327
00:27:47,360 --> 00:27:52,880
it's the change in action, nature acts so that delta s, where s is the action,

328
00:27:54,320 --> 00:27:59,280
is, it tries to minimize that quantity where s is that in terms of Lagrangian, okay, don't

329
00:27:59,280 --> 00:28:04,080
worry about the math or the physics, we're not going to go there, but so let's apply that to the

330
00:28:04,080 --> 00:28:10,720
intelligence and see how far we get, because it works for everything else, okay, so again, it's not

331
00:28:10,720 --> 00:28:15,760
just about pattern recognition, it's about modeling the world, okay, we model stuff, we can imagine,

332
00:28:15,840 --> 00:28:21,040
we problem solve, we can build new models, we can understand, right, we don't just do statistical

333
00:28:21,040 --> 00:28:26,720
analysis, otherwise it'd be zombies, right, or we'd be a silicon chip, we'd be built into our

334
00:28:26,720 --> 00:28:34,640
factory and we're not, so here are some theoretical approaches, I'm going to choose the Friston

335
00:28:34,640 --> 00:28:40,560
active inference one, which uses the delta s equals zero, the others don't, but these are, these are

336
00:28:40,560 --> 00:28:49,040
very, very, very, you know, credible attempts at general intelligence and all of these people

337
00:28:49,040 --> 00:28:53,200
have been working at least 30 years on these theories, so they're certainly not to be dismissed,

338
00:28:53,200 --> 00:28:57,760
and let's pick this one and just do all the others are wrong, there's going to be bits of each that

339
00:28:57,760 --> 00:29:04,640
it kind of have, have some, there's going to be overlap, so you know, we've, Helmholtz started

340
00:29:04,640 --> 00:29:11,600
with statistical physics, right, it's, the brain is 100 billion neurons, it's a big messy, warm,

341
00:29:11,600 --> 00:29:15,360
complex system, so statistical physics is over 100 years old.

342
00:29:22,960 --> 00:29:31,280
Okay, so I will wind it up, yeah, let me wind it up, so yeah, 30 years for all of these, right,

343
00:29:31,280 --> 00:29:39,120
I'm going to pick Friston in the last two minutes, okay, now active inference, we can look this up,

344
00:29:40,400 --> 00:29:45,200
again it uses the free energy, it's minimizing the free energy, let me just flick through and then I'll

345
00:29:45,200 --> 00:29:51,360
sum it up, there's Professor Friston there and we, we don't have time to hear, so this is what it

346
00:29:51,360 --> 00:29:55,760
looks like, we can draw diagrams and pretty pictures, we can write down equations, we can have

347
00:29:55,760 --> 00:30:00,720
me, us in the environment, the environment acting back on the agent, the agent acting back on the

348
00:30:00,720 --> 00:30:05,920
environment, all the physics is in place, we can write down the equations for it, we can do it for

349
00:30:05,920 --> 00:30:11,200
bacteria or the brain, so it works on all systems, there's the math that's super, super ugly, but

350
00:30:11,200 --> 00:30:17,520
it's, you know, it's, that's theoretical neuroscience and this is, that's the equation of, that's like

351
00:30:17,520 --> 00:30:22,480
the general theory of relativity for, for the brain, right, so there you saw it, he's got loads of

352
00:30:22,480 --> 00:30:28,960
papers, can we build it, I say yes, we have the data, we have the theory, we have the algorithms

353
00:30:28,960 --> 00:30:35,600
and we have the hardware, okay, and there's some AGI project, there's Merrick's here, Ben's here,

354
00:30:35,600 --> 00:30:40,400
there's a, Jürgen Schmidt-Huber's not here, these are all super clever people doing super clever

355
00:30:40,400 --> 00:30:47,120
things and I picked our active inference as one because I feel it's the one most based on physics

356
00:30:47,120 --> 00:30:51,680
and I'd say we're at the beginning of our journey, it might take us five or ten years to sort of

357
00:30:51,680 --> 00:30:56,320
build us as we wait for the hardware especially to mature, I believe we have the algorithms,

358
00:30:56,400 --> 00:31:01,680
it's a super bold statement to be saying, but I encourage you to read some of the papers

359
00:31:01,680 --> 00:31:06,000
and there's Jeff Hinton saying at the very end, you know, this is three years ago,

360
00:31:06,000 --> 00:31:10,080
the conceptual breakthroughs will take us, we need new conceptual breakthroughs,

361
00:31:10,080 --> 00:31:14,240
I believe the breakthroughs are going to come when we understand the brain, thank you very much.

362
00:31:16,960 --> 00:31:21,360
I'm, I'm so sorry for being so rushed, I also would like to know more,

363
00:31:21,840 --> 00:31:26,640
can I steal five minutes of the Q&A, so like for just one question, I know that he overtake,

364
00:31:26,640 --> 00:31:30,480
he's going to make it up to you. Okay, one question. He owes you five minutes of lifetime,

365
00:31:30,480 --> 00:31:35,760
yeah, I'll make sure you get that. I do, I do. Five minutes of your lifetime to him. Thank you so

366
00:31:35,760 --> 00:31:43,120
much. Thank you so much for the question, sorry for your time, just in taking one question,

367
00:31:43,120 --> 00:31:48,640
so I'm just going to be very quick to keep on schedule, so I'm going to just speak in very

368
00:31:48,640 --> 00:31:54,640
short words, so Richard Feynman, you know, you've been a music producer, besides all your other

369
00:31:54,640 --> 00:31:59,200
work in the academia, and you've shown us a great slide where you said for AGI we need

370
00:31:59,200 --> 00:32:06,240
computer sciences, physics, neurosciences, and psychology, so bringing these four things together,

371
00:32:06,240 --> 00:32:11,200
I mean, the question is, and you've been in academia, in our society every, every incentive

372
00:32:11,200 --> 00:32:16,240
is to be very specialized and to really focus on one subject and then people don't talk and connect

373
00:32:16,320 --> 00:32:21,440
enough with each other, and I think we need that for AGI. What are you doing or what can we do as

374
00:32:21,440 --> 00:32:25,440
a society to bring these four groups together? Is there conferences to exchange with those four

375
00:32:25,440 --> 00:32:29,440
groups? I mean, how do you get these different people, these different tribes talking with each

376
00:32:29,440 --> 00:32:33,440
other? Is that the short question? Is that the short question? Well, it was a long question, I hope he

377
00:32:33,440 --> 00:32:38,560
has a short answer, but yeah, okay, yeah, so Professor Friston's group's a neuroscience group,

378
00:32:38,560 --> 00:32:43,200
it's a theoretical neuroscience group, they have very strong mathematicians, very strong computer

379
00:32:43,200 --> 00:32:47,920
scientists, DeepMind's a bit of a, you know, case study in this, they get neuroscientists,

380
00:32:47,920 --> 00:32:51,840
computer science, sitting in the same room, so it's the very beginning, but I think you need

381
00:32:51,840 --> 00:32:59,520
more, I think you need psychologists, yeah, so we need a little bit more input from other science

382
00:32:59,520 --> 00:33:06,800
sectors to begin with, and yeah, I mean, it's, yeah, I mean, ultimately you have to build these

383
00:33:06,800 --> 00:33:14,320
things, the theory is going to come from a very, very strong scientific, mathematically competent

384
00:33:14,320 --> 00:33:19,760
person, okay, you can get all the psychologists talking in a room and everybody else, but ultimately

385
00:33:19,760 --> 00:33:24,320
someone or a couple of people have to write down a scientific theory, just like Einstein wrote down

386
00:33:24,320 --> 00:33:28,960
the theory of relativity, so maybe I was a little bit generous, you know, we need everybody, we need

387
00:33:28,960 --> 00:33:33,920
the ideas from everywhere, but the actual person himself or herself is going to be, have to be

388
00:33:34,000 --> 00:33:39,120
super strong a math, we saw some of the math, it's not simple, it takes a while, right, it's a huge,

389
00:33:39,120 --> 00:33:43,920
just like the theory of general relativity, and I'll end here, you know, we can understand the

390
00:33:43,920 --> 00:33:48,400
concepts, but the actual math is really, really, really hard, right, I don't know if you've ever

391
00:33:48,400 --> 00:33:54,320
tried it to solve the, no, the field equations, I have, they're not easy, right, yeah, so don't

392
00:33:54,320 --> 00:34:00,720
expect this to be easy, it's going to be simple, but the math is still going to be, you know, hard,

393
00:34:00,720 --> 00:34:06,400
okay, yeah, okay, thank you. Okay, Peter, one more question, where can we find your slides,

394
00:34:06,400 --> 00:34:11,760
are you going to upload them somewhere? Yeah, I thought the conference was going to upload them,

395
00:34:11,760 --> 00:34:18,640
if not, then my slide share is, they're available on my slide share, so if you go to

396
00:34:18,640 --> 00:34:23,600
slide share and just Google Peter Morgan, I guess, you'll find you, you'll find him, okay,

397
00:34:24,560 --> 00:34:28,800
I think that's the best way, and the other thing is just to look at Carl Friston, he has a great

398
00:34:28,800 --> 00:34:33,840
website with all his papers, which is super heavy going, but if you're really, really,

399
00:34:34,560 --> 00:34:38,000
I don't know, you know, if you really believe you want to try and solve intelligence,

400
00:34:38,000 --> 00:34:44,720
that's the best place to start.

