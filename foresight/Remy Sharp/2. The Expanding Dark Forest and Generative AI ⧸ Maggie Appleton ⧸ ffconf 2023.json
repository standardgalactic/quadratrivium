{"text": " Hi, thank you. Thank you so much for having me. I'm very excited to not tell you how AI is going to save us all. This talk is called The Expanding Dark Forest in Generative AI. It's going to be about writing on the web, trust, and human relationships, so like small fish. And also AI, unfortunately, I'm sorry. There always has to be one AI talk at every conference at this point, but at least you get me and not someone telling you how it's going to take all your jobs. So I only give a footnote with this talk where I say, well, this talk is up to date as of about a week ago, as of about Monday. So anything that's happened since Monday, I can't take accountability for. It's probably all out of date by now, but this is the state of the AI industry. So first some context. This is me. I look like this on the internet. My name is Maggie. I am a designer at an AI research lab called ELICIT. We do use language models to help scientists and researchers do literature review, which is a long, boring task, creating many thousands of PDFs, and this is something that language models are actually quite good at helping with. I also am very online. I'm very on Twitter, X, whatever you want to call it. I write a lot online, and this has led to lots of really positive relationships, a lot of really good career success, and this will become relevant later as to why I care so much about people in the future being able to do that, to be able to write online and connect with others by writing online. I'm also a cultural anthropologist. I originally trained in this for my undergraduate degree before becoming a designer because you can't get paid much to be a cultural anthropologist, but a lot of theory I learned there plays back into my thoughts on design and development and how we build things on the web. If you want to take notes on things, you can also just scan this QR code, and this whole talk is transcribed with slides and everything on this link, so don't worry about taking pictures of slides you like or trying to remember what I said. You can reference it later. I might have to update it a bit because the talk evolves, but one version that's mostly the same is on that QR code. Here's what I'm going to talk about. First, we're going to talk about the dark forest theory of the web. What is that? Next, I'm going to talk about the state of generative AI as of a week ago. I'm third going to present some problems, and then we can kind of talk about whether they actually are problems. We can question whether we think they're legitimate or not. Lastly, I'm going to talk about possible futures, so how to deal with all these hypothetical problems that I present. First, to explain the dark forest theory of the web, I'm first going to have to explain the dark forest theory of the universe. This is a theory that tries to explain why we haven't found intelligent life in the universe. Here we are in the universe, the pale blue dot, and as far as we know, we are the only intelligent life around. We've been beaming out messages for like 60 years now with like SETI, trying to find other intelligent life, trying to see if there are aliens or some other kind of being that could respond to us. We haven't heard anything back. The big question here is why. Dark forest theory says it's because the universe is like a dark forest at night. It's a place that seems quiet and lifeless because if you make noise, the predators come eat you. If you draw attention to yourself, you're going to be attacked and destroyed. It stands to reason that all the other intelligent civilizations that may or may not exist have either died or learned to shut up. And we don't know which one we are yet. So the web version of this builds off this concept. It's a theory that was proposed by Nancy Strickler, who's a really good thinker and writer back in 2019. And Nancy wrote this article describing what it feels like to be in public spaces on the web around this time. And Nancy pointed out these two main vibes, let's say. And the first is that being on the web often feels like a very lifeless, automated place that's devoid of humans. It's got all this ads and click bait and predatory behaviors and none of it feels like real humans are trying to connect with us on the web. It just feels commercial. The second vibe, actually, here, so here we are on the web, right? And we are naively writing a bunch of very sincere, authentic accounts of our lives and thoughts and experiences and trying to make connections to the other intelligent humans. We're sending out messages, trying to beam out life. But then what we hear in response is content that seems very inauthentic and human. It sounds like a bunch of robots and automations doing marketing automations and growth hacking, kind of pumping out generic click bait. So we've seen all this stuff, right? This is like low-quality listicles, right? Productivity rubbish, growth hacking advice, you know, banal motivational quotes, dramatic click bait. Like, a lot of this may as well be automated, even if a human didn't make it in some sense, right? They're rarely trying to communicate some sincere original of thought to other humans. They're trying to get you to click, right, and rack up some views. And this flood of really low-quality content has made us retreat away from the public spaces of the web. It's very costly for us to spend time and energy wading through all this craft. So the second vibe of the dark web is that there's a lot of unnecessarily antagonistic behavior at a large scale. So when we are putting out all these signals, right, trying to authentically connect to other humans, we could become a target, right? We risk the Twitter mob coming to eat us is what can happen. So there's a term on Twitter called getting main character. I don't know if people have heard of this. And I don't know if people remember, this is one year ago, Garden Lady. This was a very famous tweet, if everyone saw this one, where this really lovely woman got on Twitter one morning and she said, my husband and I wake up every morning and we bring our coffee out to the garden and we sit and talk for hours and it never gets old and we never run out of things to talk about and I love him so much. And everyone's like, that's such a nice tweet. That's so wonderful. And then this went viral. They got picked up and the Twitter reply started rolling in. So someone said, that's cool. I wake up every morning and fight my wavy traffic for an hour in Miami to get to work. That must be nice. Someone else, I wake up at 6am, right? This is an unattainable goal for most people. Not that she said it was a goal, but interpret it as you will. Another one, again, complaining about the morning routine and then goes, it must be nice being a trust fund baby with not a care in the world. So I thought this tech talk summed it up nicely. I don't care if something good happened to you. It should have happened to me instead. So this seems like a dumb example, but it was a really good moment on Twitter that shows kind of the energy flows that happen on these really large-scale social media platforms, right? Someone can publish something that's very kind and nice and it gets interpreted the wrong way. People take it in bad faith. They take it out of context. They try to amplify it to unintended audiences. We will take every opportunity to misinterpret things and be ungenerous to each other. And this is how we get cancelling some pylons and we've all seen so many examples of this happening in what seems like a very unfair way. John Ronson wrote an entire book about this called You've Been Publicly Shamed. The catalog is quite a few of these. It's a little out of date now, but it's a lot of kind of classic original examples of people getting cancels. And then the real material consequences they fix, right? They lose jobs. They lose friends. They are alienated from their community. It is not just internet drama. They really do have to face repercussions for these pylons. And so this makes the web a very sincerely dangerous place to sincerely publish your thoughts, to publish honest things on. And this makes it hard to find people, right? It's very difficult to find people who are being sincere, who are seeking coherence and who are trying to build collective knowledge in public. I know this is not what everyone wants to do with the web, right? Like some people just want to dance on TikTok and that's completely fine. We have to let them do that. But I'm interested in at least some of the web enabling this kind of productive discourse and having spaces of community building and I'm hoping some people here feel the same, right? Rather than it being like this threatening inhuman place where you can't actually say what you think. So how do we cope with this, right? We're all wandering around this dark forest of like Facebook and LinkedIn and Twitter and we realize we need to go somewhere safer. So what we end up doing is we retreat primarily to what's being called the cozy web. So this was a term coined by Venkatesh Rao in direct response to the dark web theory. And Venkat pointed out that we've all started going underground. We move into semi-private spaces like newsletters or personal websites where you're less at risk of attack. You're not on these big platforms. You're on your own separate domain or you're on your own separate newsletter. So this gives us some safety. We can at least decide a little bit who reads it and understand our audience. But we often retreat even further into gate kept spaces like slacks, WhatsApps, Discord, Signal groups, right? This is where we end up spending the most of our time and having real human relationships where we can express our ideas safely, right? So things that we say we know will be taken in good faith in these smaller groups. We can engage in real discussions. But there's some problems here, right? Like none of this is indexable or searchable. It's very hard to include people who aren't already in the group. And it hides collective knowledge in these private databases that are even hard for the users themselves to access. And also like good luck finding anything on Discord. Like you'll never be able to use the search functionality in these apps. So my current theory, sadly, is that the dark forest is about to expand because we now have this thing called generative AI. So I'm sure everyone has mostly heard of this, but what I'm talking about specifically here is machine learning models and neural networks that can create content that before this point in history only humans could make, right? This is text, images, audio and video that mimics human creations in a very compelling and believable way. Here are kind of some of the major foundational models that you might have heard of for different media types, right? We have GPT4 and clod for text, mid-journey and stable diffusion for images. There's now video ones like runway ML. And you might have heard some of the news that a lot of these models are now becoming multimodal so they can do text to image, image to text, audio to text. Like you can kind of go anywhere you want with media here. And this is, of course, chat GPT. I'm sure we've all seen a thousand screenshots of this at this point. We understand what it is. But to recap, it's right, we know it can generate huge volumes of high-quality text in seconds. The outputs are indistinguishable from human-made text when we try to get people to guess what's chat GPT and what's human. They often can't. It's trained on a huge volume of text scraped primarily from the English-speaking web. And this all sounds very simple, right? But it leads to many kind of complex and potentially useful behaviors, but it's very emergent. We don't really understand what's possible because of this capability yet. We can also now, of course, generate images, right? This is mid-journey, which usually makes pretty beautiful impressive stuff. But so we found that these, like, generative AI models are now very easy to use and very widely accessible, right? They don't require technical skills. They're incredibly cheap. And they're increasingly becoming a feature in existing software you already have access to, like Adobe or Photoshop or Notion. They're just becoming pervasive. But the product category that I'm most nervous about, not just, like, Notion generating a plan for you, is what's being called content generators, mostly for content marketers. So I'm going to pick on one product, but there are many. This one's called Blaze. And it creates articles and social media content for you, right? In half the time, who wouldn't want that? Who doesn't want more content on the internet? And so I want to show you how this works. So you decide what kind of content you want to make, right? You can say a blog post or a newsletter or a bunch of Twitter posts. And I'm going to say I want to write a blog post. And you type in what you want to write about, and your target audience, and SEO keywords. So I've decided I want to write about why plant-based meat is morally wrong, which I don't believe, but that sounds like a good clickbait to me. Like, someone's going to be like, yeah, I want to find out why that's bad. You know, maybe I'm a company that has some financial interest in plant-based meats going badly. So I'm going to go ahead and have this model write a little article for me. It lets me pick a title, which is a nice customization. And then it chans out 700 words, right? And this is now ready for me to hit publish, right? Or at least gives me some base to work off. And if I'm blobbing against plant-based meats, I can just generate 100 of these, right? And, like, optimize them for Google SEO and publish them all at once. And, like, hard days out of Cassie Dunn. Right? The quality and truthfulness of what's written in here is very questionable. We'll get to problems with that later. But the point is, this is super easy to do at scale very cheaply. And it essentially murders Google such, right? Like, this just does away with SEO optimized content. Because anyone can publish this immediately. It gets even better at the end. Like, it prompts me to generate more content. So it's like, oh, you have this blog post. Why not generate LinkedIn posts and tweets and YouTube scripts and everything. We're not just getting crappy Google articles. This is across every publishing platform. Right? So there's tons of things to do this. There's, like, AI-linked post-generators, generate your next tweet, right? YouTube content and autopilot, just thousands of these tools are pouring out. So most of the examples I showed actually have a very simple architecture, right? You have a single input, like, write me an article on plant-based meat. And you feed it into this big, black mystery box of a language model, right? And we don't really understand totally what happens inside, but it gives you an output, right? Rates you an essay. But you can't really tweak what happened in the middle. You can edit the output, but you can't kind of pull the knobs on the actual language model itself. Which isn't very sophisticated. We don't have a lot of control or transparency in what's happening. But the industry has realized this is a problem, and we started building architectures that are much more flexible and powerful. So we now have a language model architecture where we take that same black box of the language model, but we give it access to external tools, right? We say, okay, now we're going to tell it it can search the web through an API. We give it access to a calculator. We give it access to a code REPL and APIs. It's now getting a lot more capable, right? It can now look up, can do maths, you know? It can look up information that things might not be right. It can double check its answers. Also language models are usually quite forgetful. You might have found this, chat GPT after a long string. We'll forget what you said earlier on. We can now hook them up to long-term memory databases and have them reference things like many weeks or months in the past, which makes them a lot more capable. And we've also found that they perform much better if you give them these cognitive prompts. Like you tell it to do something, but then you say, you know, think about your answer, critique it, and then answer me again. And that actually improves the quality of the answer quite a lot. That's often called chain of thought prompting, self critique. It can observe what it knows and plan the next step. And it's getting these more cognitive capacities by adding on these kind of extra techniques. So this is being called the agent architecture, right? You tell the language model to act like an agent. It ends up as being like the centralized brain and you give it, you can say you can use any of these tools and then it composes which tools it wants to use to achieve your goals. So it ends up being a chain like this where you give it your goal, it'll like observe, it'll plan, it'll call a different tool, it'll observe, it'll plan. And we can actually do really complex, kind of scarily impressive things when we level up to these more sophisticated architectures. And actually on Monday, OpenAI did this big dev day talk, I don't know if people saw this, and they announced a new API called the assistance API that makes all that stuff that I showed that used to require quite a lot of Python code and kind of insider knowledge, and they're just making it super easy for everyone to now do this architecture, where you're able to kind of run any function, call any API, all hooked up to their really powerful models. So we're about to enter this phase where this very capable agent architecture is becoming pervasive and widespread and might be the foundation of a lot of new tools being built. So we're sort of on the precipice of really unnerving moment, let's say. Because agent architectures, I think, means we're about to enter a stage of sharing the web with non-human agents, right? These agents are very different to what we've currently noticed bots in the past, like a completely different architecture and set of capabilities. They're going to have a lot more data on how realistic humans behave, and they're rapidly going to get more and more capable as time goes on. And soon, probably already now, we're not going to be able to tell difference between these agents and real humans. If anyone else spends a lot of time on Twitter slash X, you'll already have noticed there's a lot of accounts you stumble across that have a weird vibe to them, and you definitely realize this is just chat GPT hooked up to a Twitter account, but otherwise is trying to look real, but like every tweet is very optimized and comes back in like a second. It's just replying to things, you know, three seconds later. So it's happening. And sharing the web, I want to say with agents, I don't want to jump to saying this is like inherently bad. I think they could have lots of good use cases, right? We could have automated moderators in communities. We could have search assistants, but I think it's mostly that it's going to get complicated, and this is going to be a huge product and cultural problem we're going to need to think about carefully and deal with. So we should get into why is this a problem for the web, right? I'm only going to focus on how this will affect human relationships and information quality on the web. Anything else, like how we might all end up unemployed or dead soon is like well beyond my pay grade, so I'm just limiting the space to just like how do we make meaningful human connections and find a good quality content on the web. Because, yeah, the cost of creating and publishing content just dropped to almost zero at this point, right? Like humans are quite expensive and slow at making content, right? We need time to research and think, and we like clumsily string words together, and then we want to take breaks, and we want to be able to nap and eat and sleep, and then we demand people pay us like extraordinary rates, right, to do this research. And generative models don't need time off, and they don't get bored, and they cost like a couple fractions of a cent to write a few thousand words. So given the dynamics here, it's very likely that models are going to become the main generators of content online. So I think we're about to drown in a sea of informational garbage, right? I think we're just going to be absolutely swamped in masses of mediocre content. Like every marketer and SEO strategist and optimizer bro is just going to have a field day here, you know, just filling the whole internet with all of their keyword stuff, optimized crap. And this explosion of noise is going to make it really difficult to find both good quality people, real people, and good quality content, and hear any signal through the noise. And we can tell this is happening because scammers and scammers are currently quite lazy, and we're kind of in the baby phases of this. So there's a phrase that you might have seen chat GPT reply with. It sometimes says, as an AI language model, I do not have political beliefs, or as an AI language model, I cannot answer that question. And this phrase, if you search and direct quotes for it around the web, shows up everywhere, just like Amazon, Google, Yelp reviews, tweets, LinkedIn posts, it's full of this phrase, because people can't be bothered to like control F and like delete the one phrase that gives them away. All right. So I did a quick search for this on LinkedIn, it got 16,000 hits, and they're like really boring attempts to like write engaging content, but they all begin with the phrase as an AI language model. Look in the first sentence. And these are real people too. I did look at their profiles. They genuinely have jobs, and they're trying to optimize their presence or something. But yeah, this is starting to happen. The motivation for doing this rate isn't hard to understand. So let's like think of the hypothetical scenario. So this is Nigel. He's written a book about why nepotism is great, right? And he wants to be a book fluencer. He's like, it's his first book, he's self-published on Amazon, he wants to like, you know, become a big book guy. So he spends up an agent, right? Not unlike an actual publishing agent. He might have hired in the past. And he says, hey, like, help me promote my book, you know? And so the agent thinks for a while, and it goes off, and it strategizes, and it generates a steady stream of tweets, right, based about on the content of the book, like real insights from the book, and it starts tweeting those out from Nigel's account, and he's given it access, you know? And it goes and it does the same thing for LinkedIn and Facebook, you know, pretty easy. And then it writes and schedules a newsletter to go out over the course of six months so that his followers will always kind of get updates on new things he's researching. It sets up a medium account, it reposts those as articles, right? Makes a set of addictive TikTok videos based on that content, generates a bunch of podcast episodes, use Nigel's voice. We can totally do that now. It's pretty easy. And then it finds a bunch of other people who like are talking about nepotism and starts replying to them on LinkedIn and Twitter and making friends, and maybe they're actually agents interacting with it, and like, it's a whole bunch of just agents interacting with agents. And none of this is different to what Nigel could do on his own. So we don't know that content moderation or spam filters are actually going to pick this stuff up, because maybe it's tweeting it slow enough that a human could have done it, and it really is in Nigel's voice. It's used his writing to write this content. We don't necessarily have automated ways to filter any of this out. And the thing is, without an agent, 99% of Nigel-type people wouldn't have gone to all this effort. They don't have the time and energy to have made all this content. But with the agent, suddenly, we have people like Nigel, but times 99 of them, able to create this amount of content all the time. And this is how we kind of get the flood of just tons of content more than we can really cope with. So the scale and the quality of the content is actually what's different here. Strangely enough, it might have written better stuff than Nigel ever would. We might have way better quality content about nepotism all over the internet. But you can imagine how this would play out at another 100x scale, right, with political lobbying groups who have very vested interests in certain ideas or beliefs or truths getting out into the world. Specific agendas, large companies that want you to believe certain things about their product or certain things about scientific claims. They all have access to these assistants and agents, too. So I do have some good news. Like, this has all been a bit dark, a bit of a downer. The good news is that this might not be a problem. Maybe this is all just fine, right? This is only a problem if we want to use the web for very particular purposes, such as facilitating genuine human relationships or pursuing collective sense-making and knowledge building or grounding our knowledge of the world in reality. So we don't care about any of these things. This is all fine. We're going to have amazing content on TikTok. We're going to be very entertained. The thing is, I'm quite keen on a lot of these outcomes. I write on the web a lot. I've had overwhelmingly positive experiences writing on the web and meeting people for doing that. I have this whole thing called digital gardening I bang on about, about making everyone publish their unfinished notes to the web and improve them over time and use that as a way to meet people interested in what you're interested in. But, yeah, the goal of that stuff is to make the web a space where that's possible for collective understanding and knowledge building. And I'm really worried that generative agents like meaningfully threaten this in the very near term, like the six to 12 month kind of time range. I can't even think beyond that. So when I talk to people about my worries, I talk to a lot of people in the AI safety and research world. They kind of go, why does it matter? My AI agent is going to make much better content than you ever would. Why do you care that an agent made it and not a human? I'm like, okay, let's engage with that question properly. I'm sympathetic to that point. So here's the reasons that generated content is a little bit different, right? The first is its connection to reality. The second is the social context they live within. And the third is its potential for human relationships. And I'm going to go into these in detail. So first, generated content, you probably have heard of this, is different because it has a different relationship to reality than we do, right? We are embodied humans, right? And we are sharing a physical reality. And we have all this rich embodied information, like we all understand we're in this kind of beautiful theater and we're in Brighton and we have a lot of physical embodied context about what we know about each other. And often what we're doing on the web is we're reading other people's accounts of this reality and we compare it against our own and we're like, do I agree with that? Is that really true? This is like the cycle of all of art and science and literature, you know, reading and comparing and writing your own version of things. And what we've done now is we've fed that huge trove of information into a neural network or a large language model. And it's created a sort of representation of that text, right? It's created a model of the things that we've already known about the world and have published to the web. And the thing is that model can now generate text that's predictably similar to what it was before, but it's totally unhinged from the physical reality that it once came from, right? It has some big connection. It did come from there. There's like a chain here, but it fully like cannot access that reality, right? Even if we put in robots, right, with like arms and eyes and ears, it can't sense the world the way we sense the world until we make like a fully synthetic like mimicry human that like is hooked up to a language model. But I think like 10 years away, I don't know, I think we have some time. Right, it can't validate its claims. It's the big thing. We politely call this hallucination, right? This is when language models say things that aren't true about the world. We say it's hallucinating, right? Like it's some side kind of very smart person on some like mild drugs who's confused about like who they are or where they are, but they're saying very intelligent things. You're sort of holding them lightly, you know? Language models are also different because they have a very different social context, right? They have a very strange relationship to our social world. So hopefully you know this, but everything you and I say is situated in a social context, right? We understand what we share in common. And if you met someone who spoke a different language from a different culture, you would not assume they thought the same things about the world that you would if you met someone from your own neighborhood, right? If one of us met someone from like the Kenzie in England, we would have very different understandings of like hygiene and science and like how the world works. We would know some things in common. We technically speak the same language, but we would know that we didn't have a shared social context in the same way. But a language model is not a person and it does not have a fixed reality, right? They know nothing about the cultural context of who they're talking to and they take on different characters depending on what you tell them to do. You can say, you know, pretend to be a professor, pretend to be an athlete, pretend to be a young child and it will take on that character. So it doesn't even have a fixed place it's talking to you from in the way that a human does. But they do represent a very particular way of seeing the world because we trained them primarily on text on the web that was generated by a majority English-speaking, like 95% of the training data is English-speaking, a primarily English-speaking westernized population, people who have mostly written a lot on Reddit and lived between about 1900 and 2023, which like in the grand scheme of history and geography is a very narrow slice of humanity, right? Of all possible cultures we've had in the past, all possible cultures we could have in the future and all possible languages. This is just such a small representation of reality and yet we're now making it the source of truth, right? The Oracle. You go to chat, GBT to ask everything. So it's taking this already dominant way of seeing the world and reinforcing that dominance, which is problematic and is like a whole different talk that I don't even think I'm qualified to do but someone should. And we hope that this will improve over time but it's really hard to do without lots of data and most cultures don't have the vast kind of written record that an English-speaking westernized online population does. So lastly, generated content lacks the potential for human relationships that human-made content does, right? If you write something online and I read it and I find it compelling, I can DM you on Twitter or I can find you on Blue Sky or I could find you somehow, ideally hopefully not on LinkedIn, but somehow and message you and be like, I love this. This was such good ideas. Like I want to write a piece in response to you and like we start having a little dialogue that I've had so many relationships blossom this way. But if you have a language model, it's not going to be able to do that. So this is a still from the film, Her, right? This has become kind of a cultural touch point of like parasocial relationships with AI. Hopefully people have seen it but if not, so Joaquin Phoenix, our lovely main character, he has this great relationship with his personal AI, he talks to her in his ear, it falls in love with her. But then the AI of course grows bored of him because he's a very kind of basic human and leaves and he's destroyed. And like some people were supposed to get this like film is supposed to be a warning, right? And some people took it as a suggestion. So there's a company called replica who make AI companions for you that you can make friends with, possibly date and fall in love with. There's a lot of suggestions of sort of lonely young men engaging with this and their marketing copy. And I mean, maybe I do need to explicitly point this out. An AI replica or any other kind of like generative agent person cannot fulfill all our human needs, right? They cannot give you a hug, they cannot come to your birthday party, they cannot kind of engage with you in a meaningful, full human way. And so any kind of language model agent on the internet has no capacity for that back and forth relationship. Even if it faked it, it's very unclear that it would actually satisfy what we need when we have an actual friend that we can go out to coffee with. So that all sounds quite bad again. Like deep breaths, the whole talk is really just digging you in a ditch, I'm sorry. But I'm now going to talk about possible futures. And again, these futures I think are not mutually exclusive, I think they all might unfold in different ways over the next five to 10 years. And like I can't speculate beyond that, God knows where we are. But yeah, I'm hoping they all kind of happen in parallel. So the first is I think we're about to spend a lot of time thinking about how we pass the reverse Turing test. So how do we prove we're human on a web filled with agents? So the original Turing test, you have a human talk to a computer and another human through like a wall so they can't see the typing messages of each other. And then the original test, the computer had to prove that it was the human. It had to prove it was competent. And on the new web, we are now the ones under scrutiny. We have to prove we're real. So we're going to end up like we will assume everyone is an agent until proven otherwise. So I kind of wrote this post where I was thinking about some short term tactics. Like we could use funny terminology. We could all try to become teenagers who like have this insider jargon that the language models don't know about, but they'll pick up on it pretty quick, you know, and then you'll have to abandon it, get a new jargon. We could write in non-dominant languages. If you speak something like Catalan or Welsh, you're probably in a pretty good position, you know, you'll be able to write in a way that's more native than a language model ever could. And ideally, we just do higher quality writing, we do more research, we do more critical thinking. We really reference events and people that could we could only know about from the real world, from being embodied humans in space. I don't know how long those kind of defenses will last, but that's in the short term something we can at least pull on. This next one, I apologize for the phrase, but it too perfectly, it catches the point. I'm not going to explain it. You can Google that later. But the point is that the content from models might end up becoming our source of truth, and that how we know things simply was like, well, a language model once said it, you know, and then it's forever captured in our circular flow of information. So right in this current model, right, the training data is at least based on real world experiences. It's kind of going in a single loop. But we're now going to use that generated text to train new models. And so we enter this loop where like there's this very tenuous link to the real world that was once a long time ago, the source of this data. This is already starting to happen. AI researchers are worried we're kind of going to run out of data to train models on within five years. And so there's a lot of talk of how do we generate information that we can feed the models, feed back into the models. This one was a really funny example of this happening. I don't know if people saw this. So someone noticed that if you ask Google if you can melt an egg, it's like smart AI summary said yes. And they were like, why would it say that? They weren't investigating. And it turned out that fact was pulled from Quora that was generated from chat GPT. And because Quora is considered a reputable website with good SEO standing, it got pulled up into the Google like smart answer. And it's not hard to imagine how all kinds of hallucinated answers are going to become part of this loop if all these major websites are using chat GPT or their own agent to generate answers and then they just feed it to each other. It's like at one point, can you melt an egg? This phenomenon is very worrying for the scientific community and they have good reason to be. We're already seeing a lot of evidence that scientific researchers are using language models to help them write papers. So again, this is a paper that was published in a genuine fairly legitimate journal, Environmental Science and Pollution Research. And it included the phrase regenerate response at the end of a paragraph, which is the button above chat GPT's input box. There's another one in August that was published on fossil fuel allocation that included the phrase as an AI language model. Now, there's a lot of debate in the community where they were like, well, this doesn't mean the science in these papers is totally false, right? They could have done real research on real experiments and they were just trying to get this paper out and at the end they went, you know what, chat GPT summarizes paragraph for me. That totally could have happened. But the problem is we don't know. There's no protocol for the transparency of how you say what you didn't, didn't use chat GPT or whatever kind of model for. So now people are trying to make it more legitimate. Some people are listing chat GPT as an author on papers. And there's a real risk that people with much worse intentions will kind of take this and run with it and just make scientific paper mills. There's a lot of companies that have a lot of vested interests in publishing science that agree with the thing that they would like to be true. Usually you find this out when you get to the funding source section of the paper where you're like, oh, yeah, funded by the people who make this drug. Interesting. But you can tell that if they're going to be able to use generative models to kind of pump out lots of research papers, maybe based on dubious science, it becomes very hard for us to tell what is actually real, what is vetted. I mean, it just takes the whole, the replication crisis to a whole new level. So this one seems the most obvious, right? One possible future is we will just retreat further into the cozy web, right? The dark frost will grow larger and we will just go, okay, I'm only interacting with Discord and WhatsApp, right? LinkedIn is dead, Twitter is dead. We've had to abandon it. We have to maybe make new privatized gate kept spaces, which I think has a lot of downsides, but this just might be the best way to deal with it. I think authors are going to increasingly put content behind blocks and paywalls. I think this is already happening with things like sub-stack and medium, where you're constantly having to log in or prove that you are part of this community to access the content. You understand why authors do this, right? Because actually you're having your content scraped and then fed into generative models puts you in a disadvantage. Like your ideas could be taken out of context, maybe it's taken something that you wanted to actually charge for and given out for free. Someone could train a model on your work and have it start writing in your voice. There's a lot of ways this can go really badly for someone whose full-time job is being a researcher or a content creator. We'll also see more websites that have a large amount of content blocking scraping for language models, or one way to do it is to just charge a huge amount for your API. Reddit did this recently. We're going to put the price so high that no company in their right mind would really pay it, or it would just cost them so much. Twitter kind of did the same. It's hard to tell if this was actually strategic or on purpose, but raising the price to whatever it was, like 42,000 per month, means that very few people can access Twitter's really high-quality content in an age where content to train models is the new goals. It's kind of leading us to a place where the web is not open by default. You can't just query any API for any content you want. Everything is locked down and gatecapped and kind of cordoned off. Next, I think we're going to have what I'm calling the Meet Space Premium. We are in the Meet Space Premium. It's when we begin to prefer and preference offline first interactions. So we will start to doubt all people online. And the only way to confirm someone's humanity is to meet them in person, right, to go for coffee or beer. And once you do that, you can kind of set up a little trust network, right? You can say, oh, I've already met Sarah over there, and she's a real human, and you've already met Tom, and he's a real human, and we can kind of like coordinate our networks to vet who's real on the web. And then when you read their writing, you kind of know it's from an actual person, or you'd hope so. You may be of some trust network of people who aren't writing generated stuff under their own name. I think this has knock-on effects. Like, people might move back to cities or higher population and places. In-person events are going to be preferable. I think there's obvious disadvantages to this, right? The web was this huge democratization thing to enable people who are maybe disabled or have young children or who are caregivers who can't get out of the house for a whole bunch of reasons aren't going to have the same access to the trust network that someone can who could physically show up in space a lot. Yeah. So, a natural follow-on from this also. So, a lot of people have been like, well, why don't we just put it on the blockchain, you know? Why don't we just get a third party to verify our humanity with a cryptographic key, and then you can sign all your published content with it, and it'll link back to your identity, and this is how we'll have decentralized trust networks. And I'm like, okay, I don't know the details of this. This sounds weird. So, there's a project called Worldcoin that, funnily enough, is also funded by OpenAI's leader, Sam Altman. He partially helped found it, which shows he kind of knows the problem he's helped contribute to. So, this scary orb scans your eyeball to confirm your identity, and then it creates a unique human credential for you to use online to sign all your stuff with. It's really not taking off as a project, but it's around. And people are still trying to do this. There's a whole community thinking this is the future that I don't have sophisticated thoughts on yet, and I'm still like, oh, cryptocurrency. But maybe this is some way to get around it. I'm also expecting any day that Elon's going to announce the purple check, where you pay $30 a month, and you don't actually have to. You just take a box that's like, I'm human, and then you get this little check and solve it. So, those are all a bit negative. I do think there is some hope in this future. We can certainly fight fire with fire. So, I think it's reasonable to assume that we're all going to have a set of personal language models to kind of help defend us and serve our needs on the web. They can filter information, they can manage information. And I expect these to be baked into browsers, or maybe even the operating system, right? And they're going to do things like identify generated content, they're going to debunk claims, they're going to flag misinformation, they're going to go help hunt down real scientific sources for you, maybe vet scientific papers, curate and suggest things to you. So, I think this actually could work in both directions. It's not just all like the bad actors get this power. We also get a lot of capacity and capability from these models. We might find it absurd that anyone would browse like the raw web without one of these kind of in tow. It's the same way you wouldn't like go onto the dark web, like you know what's there, but you know you don't want to see it. It might be kind of like that. Okay, so I'm almost done wrapping this up. But the question I want to leave everyone with is which of these possible futures would you like to make happen, right? Generative AI is not necessarily a destructive force, you know, as with all technology, it depends how you wield it. Oh, I went back to the wrong slide, sorry. There we go. The way that we choose to deploy this in the world is really what matters, right? The product decisions we make as individuals and companies, if you are working in the space or you're trying to get into it. Because obviously if you are working on a tool that like turns out tons of human-like content from marketing and influence purposes, like you can stop, like that's really like we don't need that. You can just stop doing that. But what should you be building instead? It's maybe a more helpful question. So I tried to come up with a few principles for building products language models that are probably going to evolve over time, but this is like a first pass. And the first is to protect human agency. The second is to treat models as reasoning engines and not sources of truth. And lastly that we should be augmenting our cognitive abilities and not replacing them. So protecting human agency, this is like usually at the moment you have a human prompter and it hands something off to an autonomous agent and the agent goes and does stuff, right? This is like the open AI assistance model or any of the architectures I showed before. And this is like the path to self-destruction. This is what most AI safety researchers are very afraid of is that the locus of agency sits within the agent. But the ideal form of this is that the locus of agent stays within the human and it has a collaborative agent on hand and there's this very short continuous feedback loop that is constantly going between them. Where the human is the one checking, should I do that? Do I want that? Is that true? Like they're able to actually fact check things and then the agent is much more of a helper. Short feedback loops, close supervision, limited power, it's slower but it's safer. That ties into the second principle that we should treat models as tiny reasoning engines and not sources of truth. So one way to use these models is to like ask it for every answer and ask it every question and trust what it says. Another one is you can train them to do specific things like just summarize this text, just extract data from this paper, just find contradictions in this statement and then you can bring your own data which could be legitimate scientific papers, it could be your own notes, it could be Wikipedia and then you use these models to just do these very small scoped things where you can observe every single output and check that it's actually legitimate and you're not handing off this big complex task to this big black box model. And lastly, we should augment our cognitive abilities and not replace them, right? Language models are very good at things that humans are not good at like searching and discovering things in large datasets, role playing as identities and characters, they're actually really good at doing that, rapidly organizing data, turning fuzzy inputs into structured outputs, there's a lot that they're good at that we're bad at and we should use them for those things. There's tons that like we're good at they're not that we're still trying to like make them do like checking claims against physical reality, long-term memory, having embodied knowledge, understanding social context, having emotional intelligence, I think combining the two of these so that we're doing things models can't do and they're doing things we're not very good at actually leverages the best of both worlds. Because a lot of AI researchers in the moment, they use this metaphor of aliens, this is from the 1970s alien film or frightening, it just it makes me think this is like not the most appealing collaborative partner this metaphor, this like big scary unknown consciousness that like might kill you, but there's another metaphor that I like more that Kate Darling is a robotics researcher at MIT and she wrote this book called The New Breed, arguing we should think about robots as animals, we have a long cultural legal history with animals and working collaboratively with them, oxen, dogs, pigs, right in this very like mutually beneficial relationship most of the time and this is actually a pretty good metaphor to expand to AI where we have to kind of treat them a little bit like some form of intelligent species but one that we are in community with and are part of our systems and are not this like big scary alien who might come kill us all is like usually what it gets talked about as. So yeah there's this big push for this philosophical approach, some people call it cyber-organism, there's a very long article there was a written on less wrong which is not my favorite website but it's a good article that kind of goes in depth into this if you do want to read more about it. So that's all I have, I want to thank you so much for listening, again slide the notes on this QR code if you like missed anything, I'm on Twitter X at mappleton still until that really does fall apart and you can DM me there, you can message me again I love meeting people through writing on the web if you have blogs that like relate to these kind of topics send them to me but yeah thank you so much for listening, I appreciate it.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.48, "text": " Hi, thank you. Thank you so much for having me. I'm very excited to not tell you how AI", "tokens": [50364, 2421, 11, 1309, 291, 13, 1044, 291, 370, 709, 337, 1419, 385, 13, 286, 478, 588, 2919, 281, 406, 980, 291, 577, 7318, 51188], "temperature": 0.0, "avg_logprob": -0.2876456578572591, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.026028433814644814}, {"id": 1, "seek": 0, "start": 16.48, "end": 22.32, "text": " is going to save us all. This talk is called The Expanding Dark Forest in Generative AI.", "tokens": [51188, 307, 516, 281, 3155, 505, 439, 13, 639, 751, 307, 1219, 440, 21391, 42389, 9563, 18124, 294, 15409, 1166, 7318, 13, 51480], "temperature": 0.0, "avg_logprob": -0.2876456578572591, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.026028433814644814}, {"id": 2, "seek": 0, "start": 22.32, "end": 27.36, "text": " It's going to be about writing on the web, trust, and human relationships, so like small", "tokens": [51480, 467, 311, 516, 281, 312, 466, 3579, 322, 264, 3670, 11, 3361, 11, 293, 1952, 6159, 11, 370, 411, 1359, 51732], "temperature": 0.0, "avg_logprob": -0.2876456578572591, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.026028433814644814}, {"id": 3, "seek": 2736, "start": 27.36, "end": 33.519999999999996, "text": " fish. And also AI, unfortunately, I'm sorry. There always has to be one AI talk at every", "tokens": [50364, 3506, 13, 400, 611, 7318, 11, 7015, 11, 286, 478, 2597, 13, 821, 1009, 575, 281, 312, 472, 7318, 751, 412, 633, 50672], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 4, "seek": 2736, "start": 33.519999999999996, "end": 36.76, "text": " conference at this point, but at least you get me and not someone telling you how it's", "tokens": [50672, 7586, 412, 341, 935, 11, 457, 412, 1935, 291, 483, 385, 293, 406, 1580, 3585, 291, 577, 309, 311, 50834], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 5, "seek": 2736, "start": 36.76, "end": 41.92, "text": " going to take all your jobs. So I only give a footnote with this talk where I say, well,", "tokens": [50834, 516, 281, 747, 439, 428, 4782, 13, 407, 286, 787, 976, 257, 2671, 22178, 365, 341, 751, 689, 286, 584, 11, 731, 11, 51092], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 6, "seek": 2736, "start": 41.92, "end": 45.56, "text": " this talk is up to date as of about a week ago, as of about Monday. So anything that's", "tokens": [51092, 341, 751, 307, 493, 281, 4002, 382, 295, 466, 257, 1243, 2057, 11, 382, 295, 466, 8138, 13, 407, 1340, 300, 311, 51274], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 7, "seek": 2736, "start": 45.56, "end": 50.16, "text": " happened since Monday, I can't take accountability for. It's probably all out of date by now,", "tokens": [51274, 2011, 1670, 8138, 11, 286, 393, 380, 747, 19380, 337, 13, 467, 311, 1391, 439, 484, 295, 4002, 538, 586, 11, 51504], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 8, "seek": 2736, "start": 50.16, "end": 55.68, "text": " but this is the state of the AI industry. So first some context. This is me. I look", "tokens": [51504, 457, 341, 307, 264, 1785, 295, 264, 7318, 3518, 13, 407, 700, 512, 4319, 13, 639, 307, 385, 13, 286, 574, 51780], "temperature": 0.0, "avg_logprob": -0.17810362157687334, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.0845012292265892}, {"id": 9, "seek": 5568, "start": 55.76, "end": 60.96, "text": " like this on the internet. My name is Maggie. I am a designer at an AI research lab called", "tokens": [50368, 411, 341, 322, 264, 4705, 13, 1222, 1315, 307, 29107, 13, 286, 669, 257, 11795, 412, 364, 7318, 2132, 2715, 1219, 50628], "temperature": 0.0, "avg_logprob": -0.183383652142116, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.004925514571368694}, {"id": 10, "seek": 5568, "start": 60.96, "end": 66.84, "text": " ELICIT. We do use language models to help scientists and researchers do literature review,", "tokens": [50628, 14426, 2532, 3927, 13, 492, 360, 764, 2856, 5245, 281, 854, 7708, 293, 10309, 360, 10394, 3131, 11, 50922], "temperature": 0.0, "avg_logprob": -0.183383652142116, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.004925514571368694}, {"id": 11, "seek": 5568, "start": 66.84, "end": 71.08, "text": " which is a long, boring task, creating many thousands of PDFs, and this is something that", "tokens": [50922, 597, 307, 257, 938, 11, 9989, 5633, 11, 4084, 867, 5383, 295, 17752, 82, 11, 293, 341, 307, 746, 300, 51134], "temperature": 0.0, "avg_logprob": -0.183383652142116, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.004925514571368694}, {"id": 12, "seek": 5568, "start": 71.08, "end": 76.56, "text": " language models are actually quite good at helping with. I also am very online. I'm", "tokens": [51134, 2856, 5245, 366, 767, 1596, 665, 412, 4315, 365, 13, 286, 611, 669, 588, 2950, 13, 286, 478, 51408], "temperature": 0.0, "avg_logprob": -0.183383652142116, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.004925514571368694}, {"id": 13, "seek": 5568, "start": 76.56, "end": 82.12, "text": " very on Twitter, X, whatever you want to call it. I write a lot online, and this has led", "tokens": [51408, 588, 322, 5794, 11, 1783, 11, 2035, 291, 528, 281, 818, 309, 13, 286, 2464, 257, 688, 2950, 11, 293, 341, 575, 4684, 51686], "temperature": 0.0, "avg_logprob": -0.183383652142116, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.004925514571368694}, {"id": 14, "seek": 8212, "start": 82.16000000000001, "end": 86.52000000000001, "text": " to lots of really positive relationships, a lot of really good career success, and this", "tokens": [50366, 281, 3195, 295, 534, 3353, 6159, 11, 257, 688, 295, 534, 665, 3988, 2245, 11, 293, 341, 50584], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 15, "seek": 8212, "start": 86.52000000000001, "end": 90.52000000000001, "text": " will become relevant later as to why I care so much about people in the future being able", "tokens": [50584, 486, 1813, 7340, 1780, 382, 281, 983, 286, 1127, 370, 709, 466, 561, 294, 264, 2027, 885, 1075, 50784], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 16, "seek": 8212, "start": 90.52000000000001, "end": 96.68, "text": " to do that, to be able to write online and connect with others by writing online.", "tokens": [50784, 281, 360, 300, 11, 281, 312, 1075, 281, 2464, 2950, 293, 1745, 365, 2357, 538, 3579, 2950, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 17, "seek": 8212, "start": 96.68, "end": 100.88000000000001, "text": " I'm also a cultural anthropologist. I originally trained in this for my undergraduate degree", "tokens": [51092, 286, 478, 611, 257, 6988, 22727, 9201, 13, 286, 7993, 8895, 294, 341, 337, 452, 19113, 4314, 51302], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 18, "seek": 8212, "start": 100.88000000000001, "end": 105.36000000000001, "text": " before becoming a designer because you can't get paid much to be a cultural anthropologist,", "tokens": [51302, 949, 5617, 257, 11795, 570, 291, 393, 380, 483, 4835, 709, 281, 312, 257, 6988, 22727, 9201, 11, 51526], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 19, "seek": 8212, "start": 105.36000000000001, "end": 110.16, "text": " but a lot of theory I learned there plays back into my thoughts on design and development", "tokens": [51526, 457, 257, 688, 295, 5261, 286, 3264, 456, 5749, 646, 666, 452, 4598, 322, 1715, 293, 3250, 51766], "temperature": 0.0, "avg_logprob": -0.12754832195634602, "compression_ratio": 1.7740863787375416, "no_speech_prob": 0.0003622292715590447}, {"id": 20, "seek": 11016, "start": 110.36, "end": 116.96, "text": " and how we build things on the web. If you want to take notes on things, you can also", "tokens": [50374, 293, 577, 321, 1322, 721, 322, 264, 3670, 13, 759, 291, 528, 281, 747, 5570, 322, 721, 11, 291, 393, 611, 50704], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 21, "seek": 11016, "start": 116.96, "end": 121.03999999999999, "text": " just scan this QR code, and this whole talk is transcribed with slides and everything", "tokens": [50704, 445, 11049, 341, 32784, 3089, 11, 293, 341, 1379, 751, 307, 1145, 18732, 365, 9788, 293, 1203, 50908], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 22, "seek": 11016, "start": 121.03999999999999, "end": 125.52, "text": " on this link, so don't worry about taking pictures of slides you like or trying to remember", "tokens": [50908, 322, 341, 2113, 11, 370, 500, 380, 3292, 466, 1940, 5242, 295, 9788, 291, 411, 420, 1382, 281, 1604, 51132], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 23, "seek": 11016, "start": 125.52, "end": 128.8, "text": " what I said. You can reference it later. I might have to update it a bit because the", "tokens": [51132, 437, 286, 848, 13, 509, 393, 6408, 309, 1780, 13, 286, 1062, 362, 281, 5623, 309, 257, 857, 570, 264, 51296], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 24, "seek": 11016, "start": 128.8, "end": 134.68, "text": " talk evolves, but one version that's mostly the same is on that QR code.", "tokens": [51296, 751, 43737, 11, 457, 472, 3037, 300, 311, 5240, 264, 912, 307, 322, 300, 32784, 3089, 13, 51590], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 25, "seek": 11016, "start": 134.68, "end": 139.44, "text": " Here's what I'm going to talk about. First, we're going to talk about the dark forest", "tokens": [51590, 1692, 311, 437, 286, 478, 516, 281, 751, 466, 13, 2386, 11, 321, 434, 516, 281, 751, 466, 264, 2877, 6719, 51828], "temperature": 0.0, "avg_logprob": -0.16811545320259508, "compression_ratio": 1.7303754266211604, "no_speech_prob": 0.0058328877203166485}, {"id": 26, "seek": 13944, "start": 139.48, "end": 144.52, "text": " theory of the web. What is that? Next, I'm going to talk about the state of generative", "tokens": [50366, 5261, 295, 264, 3670, 13, 708, 307, 300, 30, 3087, 11, 286, 478, 516, 281, 751, 466, 264, 1785, 295, 1337, 1166, 50618], "temperature": 0.0, "avg_logprob": -0.14507990298063858, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0011528793256729841}, {"id": 27, "seek": 13944, "start": 144.52, "end": 151.64, "text": " AI as of a week ago. I'm third going to present some problems, and then we can kind of talk", "tokens": [50618, 7318, 382, 295, 257, 1243, 2057, 13, 286, 478, 2636, 516, 281, 1974, 512, 2740, 11, 293, 550, 321, 393, 733, 295, 751, 50974], "temperature": 0.0, "avg_logprob": -0.14507990298063858, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0011528793256729841}, {"id": 28, "seek": 13944, "start": 151.64, "end": 154.32, "text": " about whether they actually are problems. We can question whether we think they're legitimate", "tokens": [50974, 466, 1968, 436, 767, 366, 2740, 13, 492, 393, 1168, 1968, 321, 519, 436, 434, 17956, 51108], "temperature": 0.0, "avg_logprob": -0.14507990298063858, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0011528793256729841}, {"id": 29, "seek": 13944, "start": 154.32, "end": 159.76, "text": " or not. Lastly, I'm going to talk about possible futures, so how to deal with all these hypothetical", "tokens": [51108, 420, 406, 13, 18072, 11, 286, 478, 516, 281, 751, 466, 1944, 26071, 11, 370, 577, 281, 2028, 365, 439, 613, 33053, 51380], "temperature": 0.0, "avg_logprob": -0.14507990298063858, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0011528793256729841}, {"id": 30, "seek": 13944, "start": 159.76, "end": 166.48, "text": " problems that I present. First, to explain the dark forest theory of the web, I'm first", "tokens": [51380, 2740, 300, 286, 1974, 13, 2386, 11, 281, 2903, 264, 2877, 6719, 5261, 295, 264, 3670, 11, 286, 478, 700, 51716], "temperature": 0.0, "avg_logprob": -0.14507990298063858, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0011528793256729841}, {"id": 31, "seek": 16648, "start": 166.51999999999998, "end": 172.35999999999999, "text": " going to have to explain the dark forest theory of the universe. This is a theory that tries", "tokens": [50366, 516, 281, 362, 281, 2903, 264, 2877, 6719, 5261, 295, 264, 6445, 13, 639, 307, 257, 5261, 300, 9898, 50658], "temperature": 0.0, "avg_logprob": -0.13398383344922746, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.001491821138188243}, {"id": 32, "seek": 16648, "start": 172.35999999999999, "end": 178.04, "text": " to explain why we haven't found intelligent life in the universe. Here we are in the universe,", "tokens": [50658, 281, 2903, 983, 321, 2378, 380, 1352, 13232, 993, 294, 264, 6445, 13, 1692, 321, 366, 294, 264, 6445, 11, 50942], "temperature": 0.0, "avg_logprob": -0.13398383344922746, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.001491821138188243}, {"id": 33, "seek": 16648, "start": 178.04, "end": 183.51999999999998, "text": " the pale blue dot, and as far as we know, we are the only intelligent life around. We've", "tokens": [50942, 264, 19546, 3344, 5893, 11, 293, 382, 1400, 382, 321, 458, 11, 321, 366, 264, 787, 13232, 993, 926, 13, 492, 600, 51216], "temperature": 0.0, "avg_logprob": -0.13398383344922746, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.001491821138188243}, {"id": 34, "seek": 16648, "start": 183.51999999999998, "end": 188.72, "text": " been beaming out messages for like 60 years now with like SETI, trying to find other intelligent", "tokens": [51216, 668, 312, 5184, 484, 7897, 337, 411, 4060, 924, 586, 365, 411, 318, 4850, 40, 11, 1382, 281, 915, 661, 13232, 51476], "temperature": 0.0, "avg_logprob": -0.13398383344922746, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.001491821138188243}, {"id": 35, "seek": 16648, "start": 188.72, "end": 192.56, "text": " life, trying to see if there are aliens or some other kind of being that could respond", "tokens": [51476, 993, 11, 1382, 281, 536, 498, 456, 366, 21594, 420, 512, 661, 733, 295, 885, 300, 727, 4196, 51668], "temperature": 0.0, "avg_logprob": -0.13398383344922746, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.001491821138188243}, {"id": 36, "seek": 19256, "start": 192.6, "end": 199.6, "text": " to us. We haven't heard anything back. The big question here is why. Dark forest theory", "tokens": [50366, 281, 505, 13, 492, 2378, 380, 2198, 1340, 646, 13, 440, 955, 1168, 510, 307, 983, 13, 9563, 6719, 5261, 50716], "temperature": 0.0, "avg_logprob": -0.13998489379882811, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0014158356934785843}, {"id": 37, "seek": 19256, "start": 199.84, "end": 205.32, "text": " says it's because the universe is like a dark forest at night. It's a place that seems", "tokens": [50728, 1619, 309, 311, 570, 264, 6445, 307, 411, 257, 2877, 6719, 412, 1818, 13, 467, 311, 257, 1081, 300, 2544, 51002], "temperature": 0.0, "avg_logprob": -0.13998489379882811, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0014158356934785843}, {"id": 38, "seek": 19256, "start": 205.32, "end": 212.32, "text": " quiet and lifeless because if you make noise, the predators come eat you. If you draw attention", "tokens": [51002, 5677, 293, 4545, 4272, 570, 498, 291, 652, 5658, 11, 264, 29194, 808, 1862, 291, 13, 759, 291, 2642, 3202, 51352], "temperature": 0.0, "avg_logprob": -0.13998489379882811, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0014158356934785843}, {"id": 39, "seek": 19256, "start": 212.32, "end": 217.04, "text": " to yourself, you're going to be attacked and destroyed. It stands to reason that all the", "tokens": [51352, 281, 1803, 11, 291, 434, 516, 281, 312, 12692, 293, 8937, 13, 467, 7382, 281, 1778, 300, 439, 264, 51588], "temperature": 0.0, "avg_logprob": -0.13998489379882811, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0014158356934785843}, {"id": 40, "seek": 19256, "start": 217.04, "end": 221.8, "text": " other intelligent civilizations that may or may not exist have either died or learned", "tokens": [51588, 661, 13232, 40749, 300, 815, 420, 815, 406, 2514, 362, 2139, 4539, 420, 3264, 51826], "temperature": 0.0, "avg_logprob": -0.13998489379882811, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0014158356934785843}, {"id": 41, "seek": 22180, "start": 221.84, "end": 228.52, "text": " to shut up. And we don't know which one we are yet. So the web version of this builds", "tokens": [50366, 281, 5309, 493, 13, 400, 321, 500, 380, 458, 597, 472, 321, 366, 1939, 13, 407, 264, 3670, 3037, 295, 341, 15182, 50700], "temperature": 0.0, "avg_logprob": -0.15757614526993188, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.0008355362806469202}, {"id": 42, "seek": 22180, "start": 228.52, "end": 233.8, "text": " off this concept. It's a theory that was proposed by Nancy Strickler, who's a really good thinker", "tokens": [50700, 766, 341, 3410, 13, 467, 311, 257, 5261, 300, 390, 10348, 538, 18154, 8251, 618, 1918, 11, 567, 311, 257, 534, 665, 519, 260, 50964], "temperature": 0.0, "avg_logprob": -0.15757614526993188, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.0008355362806469202}, {"id": 43, "seek": 22180, "start": 233.8, "end": 239.28, "text": " and writer back in 2019. And Nancy wrote this article describing what it feels like to be", "tokens": [50964, 293, 9936, 646, 294, 6071, 13, 400, 18154, 4114, 341, 7222, 16141, 437, 309, 3417, 411, 281, 312, 51238], "temperature": 0.0, "avg_logprob": -0.15757614526993188, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.0008355362806469202}, {"id": 44, "seek": 22180, "start": 239.28, "end": 244.76000000000002, "text": " in public spaces on the web around this time. And Nancy pointed out these two main vibes,", "tokens": [51238, 294, 1908, 7673, 322, 264, 3670, 926, 341, 565, 13, 400, 18154, 10932, 484, 613, 732, 2135, 27636, 11, 51512], "temperature": 0.0, "avg_logprob": -0.15757614526993188, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.0008355362806469202}, {"id": 45, "seek": 22180, "start": 244.76000000000002, "end": 250.4, "text": " let's say. And the first is that being on the web often feels like a very lifeless, automated", "tokens": [51512, 718, 311, 584, 13, 400, 264, 700, 307, 300, 885, 322, 264, 3670, 2049, 3417, 411, 257, 588, 4545, 4272, 11, 18473, 51794], "temperature": 0.0, "avg_logprob": -0.15757614526993188, "compression_ratio": 1.6618181818181819, "no_speech_prob": 0.0008355362806469202}, {"id": 46, "seek": 25040, "start": 250.48000000000002, "end": 256.32, "text": " place that's devoid of humans. It's got all this ads and click bait and predatory behaviors", "tokens": [50368, 1081, 300, 311, 1905, 17079, 295, 6255, 13, 467, 311, 658, 439, 341, 10342, 293, 2052, 16865, 293, 3852, 4745, 15501, 50660], "temperature": 0.0, "avg_logprob": -0.22116307599828877, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.0005131543148308992}, {"id": 47, "seek": 25040, "start": 256.32, "end": 259.64, "text": " and none of it feels like real humans are trying to connect with us on the web. It just", "tokens": [50660, 293, 6022, 295, 309, 3417, 411, 957, 6255, 366, 1382, 281, 1745, 365, 505, 322, 264, 3670, 13, 467, 445, 50826], "temperature": 0.0, "avg_logprob": -0.22116307599828877, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.0005131543148308992}, {"id": 48, "seek": 25040, "start": 259.64, "end": 265.52, "text": " feels commercial. The second vibe, actually, here, so here we are on the web, right? And", "tokens": [50826, 3417, 6841, 13, 440, 1150, 14606, 11, 767, 11, 510, 11, 370, 510, 321, 366, 322, 264, 3670, 11, 558, 30, 400, 51120], "temperature": 0.0, "avg_logprob": -0.22116307599828877, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.0005131543148308992}, {"id": 49, "seek": 25040, "start": 265.52, "end": 271.32, "text": " we are naively writing a bunch of very sincere, authentic accounts of our lives and thoughts", "tokens": [51120, 321, 366, 1667, 3413, 3579, 257, 3840, 295, 588, 16941, 11, 12466, 9402, 295, 527, 2909, 293, 4598, 51410], "temperature": 0.0, "avg_logprob": -0.22116307599828877, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.0005131543148308992}, {"id": 50, "seek": 25040, "start": 271.32, "end": 276.04, "text": " and experiences and trying to make connections to the other intelligent humans. We're sending", "tokens": [51410, 293, 5235, 293, 1382, 281, 652, 9271, 281, 264, 661, 13232, 6255, 13, 492, 434, 7750, 51646], "temperature": 0.0, "avg_logprob": -0.22116307599828877, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.0005131543148308992}, {"id": 51, "seek": 27604, "start": 276.08000000000004, "end": 281.56, "text": " out messages, trying to beam out life. But then what we hear in response is content that", "tokens": [50366, 484, 7897, 11, 1382, 281, 14269, 484, 993, 13, 583, 550, 437, 321, 1568, 294, 4134, 307, 2701, 300, 50640], "temperature": 0.0, "avg_logprob": -0.1557783739907401, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.0033099197316914797}, {"id": 52, "seek": 27604, "start": 281.56, "end": 287.40000000000003, "text": " seems very inauthentic and human. It sounds like a bunch of robots and automations doing", "tokens": [50640, 2544, 588, 294, 40198, 317, 299, 293, 1952, 13, 467, 3263, 411, 257, 3840, 295, 14733, 293, 3553, 763, 884, 50932], "temperature": 0.0, "avg_logprob": -0.1557783739907401, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.0033099197316914797}, {"id": 53, "seek": 27604, "start": 287.40000000000003, "end": 292.52000000000004, "text": " marketing automations and growth hacking, kind of pumping out generic click bait. So we've", "tokens": [50932, 6370, 3553, 763, 293, 4599, 31422, 11, 733, 295, 27131, 484, 19577, 2052, 16865, 13, 407, 321, 600, 51188], "temperature": 0.0, "avg_logprob": -0.1557783739907401, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.0033099197316914797}, {"id": 54, "seek": 27604, "start": 292.52000000000004, "end": 297.8, "text": " seen all this stuff, right? This is like low-quality listicles, right? Productivity rubbish, growth", "tokens": [51188, 1612, 439, 341, 1507, 11, 558, 30, 639, 307, 411, 2295, 12, 11286, 1329, 5350, 11, 558, 30, 22005, 4253, 29978, 11, 4599, 51452], "temperature": 0.0, "avg_logprob": -0.1557783739907401, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.0033099197316914797}, {"id": 55, "seek": 27604, "start": 297.8, "end": 303.56, "text": " hacking advice, you know, banal motivational quotes, dramatic click bait. Like, a lot of", "tokens": [51452, 31422, 5192, 11, 291, 458, 11, 5643, 304, 48186, 19963, 11, 12023, 2052, 16865, 13, 1743, 11, 257, 688, 295, 51740], "temperature": 0.0, "avg_logprob": -0.1557783739907401, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.0033099197316914797}, {"id": 56, "seek": 30356, "start": 303.6, "end": 308.08, "text": " this may as well be automated, even if a human didn't make it in some sense, right? They're", "tokens": [50366, 341, 815, 382, 731, 312, 18473, 11, 754, 498, 257, 1952, 994, 380, 652, 309, 294, 512, 2020, 11, 558, 30, 814, 434, 50590], "temperature": 0.0, "avg_logprob": -0.12042121719895747, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.0009565204964019358}, {"id": 57, "seek": 30356, "start": 308.08, "end": 312.84, "text": " rarely trying to communicate some sincere original of thought to other humans. They're", "tokens": [50590, 13752, 1382, 281, 7890, 512, 16941, 3380, 295, 1194, 281, 661, 6255, 13, 814, 434, 50828], "temperature": 0.0, "avg_logprob": -0.12042121719895747, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.0009565204964019358}, {"id": 58, "seek": 30356, "start": 312.84, "end": 317.68, "text": " trying to get you to click, right, and rack up some views. And this flood of really low-quality", "tokens": [50828, 1382, 281, 483, 291, 281, 2052, 11, 558, 11, 293, 14788, 493, 512, 6809, 13, 400, 341, 10481, 295, 534, 2295, 12, 11286, 51070], "temperature": 0.0, "avg_logprob": -0.12042121719895747, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.0009565204964019358}, {"id": 59, "seek": 30356, "start": 317.68, "end": 323.16, "text": " content has made us retreat away from the public spaces of the web. It's very costly for us", "tokens": [51070, 2701, 575, 1027, 505, 15505, 1314, 490, 264, 1908, 7673, 295, 264, 3670, 13, 467, 311, 588, 28328, 337, 505, 51344], "temperature": 0.0, "avg_logprob": -0.12042121719895747, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.0009565204964019358}, {"id": 60, "seek": 30356, "start": 323.16, "end": 329.2, "text": " to spend time and energy wading through all this craft. So the second vibe of the dark web is", "tokens": [51344, 281, 3496, 565, 293, 2281, 261, 8166, 807, 439, 341, 8448, 13, 407, 264, 1150, 14606, 295, 264, 2877, 3670, 307, 51646], "temperature": 0.0, "avg_logprob": -0.12042121719895747, "compression_ratio": 1.6370106761565837, "no_speech_prob": 0.0009565204964019358}, {"id": 61, "seek": 32920, "start": 329.28, "end": 336.0, "text": " that there's a lot of unnecessarily antagonistic behavior at a large scale. So when we are putting", "tokens": [50368, 300, 456, 311, 257, 688, 295, 16799, 3289, 32590, 3142, 5223, 412, 257, 2416, 4373, 13, 407, 562, 321, 366, 3372, 50704], "temperature": 0.0, "avg_logprob": -0.13655203183492023, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0015825426671653986}, {"id": 62, "seek": 32920, "start": 336.0, "end": 340.8, "text": " out all these signals, right, trying to authentically connect to other humans, we could become a", "tokens": [50704, 484, 439, 613, 12354, 11, 558, 11, 1382, 281, 9214, 984, 1745, 281, 661, 6255, 11, 321, 727, 1813, 257, 50944], "temperature": 0.0, "avg_logprob": -0.13655203183492023, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0015825426671653986}, {"id": 63, "seek": 32920, "start": 340.8, "end": 347.84, "text": " target, right? We risk the Twitter mob coming to eat us is what can happen. So there's a term on", "tokens": [50944, 3779, 11, 558, 30, 492, 3148, 264, 5794, 4298, 1348, 281, 1862, 505, 307, 437, 393, 1051, 13, 407, 456, 311, 257, 1433, 322, 51296], "temperature": 0.0, "avg_logprob": -0.13655203183492023, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0015825426671653986}, {"id": 64, "seek": 32920, "start": 347.84, "end": 352.0, "text": " Twitter called getting main character. I don't know if people have heard of this. And I don't", "tokens": [51296, 5794, 1219, 1242, 2135, 2517, 13, 286, 500, 380, 458, 498, 561, 362, 2198, 295, 341, 13, 400, 286, 500, 380, 51504], "temperature": 0.0, "avg_logprob": -0.13655203183492023, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0015825426671653986}, {"id": 65, "seek": 32920, "start": 352.0, "end": 356.24, "text": " know if people remember, this is one year ago, Garden Lady. This was a very famous tweet, if", "tokens": [51504, 458, 498, 561, 1604, 11, 341, 307, 472, 1064, 2057, 11, 19429, 11256, 13, 639, 390, 257, 588, 4618, 15258, 11, 498, 51716], "temperature": 0.0, "avg_logprob": -0.13655203183492023, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0015825426671653986}, {"id": 66, "seek": 35624, "start": 356.32, "end": 361.36, "text": " everyone saw this one, where this really lovely woman got on Twitter one morning and she said,", "tokens": [50368, 1518, 1866, 341, 472, 11, 689, 341, 534, 7496, 3059, 658, 322, 5794, 472, 2446, 293, 750, 848, 11, 50620], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 67, "seek": 35624, "start": 361.36, "end": 365.52, "text": " my husband and I wake up every morning and we bring our coffee out to the garden and we sit and", "tokens": [50620, 452, 5213, 293, 286, 6634, 493, 633, 2446, 293, 321, 1565, 527, 4982, 484, 281, 264, 7431, 293, 321, 1394, 293, 50828], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 68, "seek": 35624, "start": 365.52, "end": 369.28000000000003, "text": " talk for hours and it never gets old and we never run out of things to talk about and I love him", "tokens": [50828, 751, 337, 2496, 293, 309, 1128, 2170, 1331, 293, 321, 1128, 1190, 484, 295, 721, 281, 751, 466, 293, 286, 959, 796, 51016], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 69, "seek": 35624, "start": 369.28000000000003, "end": 374.32, "text": " so much. And everyone's like, that's such a nice tweet. That's so wonderful. And then this went", "tokens": [51016, 370, 709, 13, 400, 1518, 311, 411, 11, 300, 311, 1270, 257, 1481, 15258, 13, 663, 311, 370, 3715, 13, 400, 550, 341, 1437, 51268], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 70, "seek": 35624, "start": 374.32, "end": 380.16, "text": " viral. They got picked up and the Twitter reply started rolling in. So someone said, that's cool.", "tokens": [51268, 16132, 13, 814, 658, 6183, 493, 293, 264, 5794, 16972, 1409, 9439, 294, 13, 407, 1580, 848, 11, 300, 311, 1627, 13, 51560], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 71, "seek": 35624, "start": 380.16, "end": 384.32, "text": " I wake up every morning and fight my wavy traffic for an hour in Miami to get to work. That must be", "tokens": [51560, 286, 6634, 493, 633, 2446, 293, 2092, 452, 261, 15498, 6419, 337, 364, 1773, 294, 18367, 281, 483, 281, 589, 13, 663, 1633, 312, 51768], "temperature": 0.0, "avg_logprob": -0.1292021633827523, "compression_ratio": 1.8270440251572326, "no_speech_prob": 0.00693920161575079}, {"id": 72, "seek": 38432, "start": 384.32, "end": 390.32, "text": " nice. Someone else, I wake up at 6am, right? This is an unattainable goal for most people. Not", "tokens": [50364, 1481, 13, 8734, 1646, 11, 286, 6634, 493, 412, 1386, 335, 11, 558, 30, 639, 307, 364, 47316, 491, 712, 3387, 337, 881, 561, 13, 1726, 50664], "temperature": 0.0, "avg_logprob": -0.11133507856233853, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.003153348108753562}, {"id": 73, "seek": 38432, "start": 390.32, "end": 395.68, "text": " that she said it was a goal, but interpret it as you will. Another one, again, complaining about", "tokens": [50664, 300, 750, 848, 309, 390, 257, 3387, 11, 457, 7302, 309, 382, 291, 486, 13, 3996, 472, 11, 797, 11, 20740, 466, 50932], "temperature": 0.0, "avg_logprob": -0.11133507856233853, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.003153348108753562}, {"id": 74, "seek": 38432, "start": 395.68, "end": 399.44, "text": " the morning routine and then goes, it must be nice being a trust fund baby with not a care in the", "tokens": [50932, 264, 2446, 9927, 293, 550, 1709, 11, 309, 1633, 312, 1481, 885, 257, 3361, 2374, 3186, 365, 406, 257, 1127, 294, 264, 51120], "temperature": 0.0, "avg_logprob": -0.11133507856233853, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.003153348108753562}, {"id": 75, "seek": 38432, "start": 399.44, "end": 406.0, "text": " world. So I thought this tech talk summed it up nicely. I don't care if something good happened", "tokens": [51120, 1002, 13, 407, 286, 1194, 341, 7553, 751, 2408, 1912, 309, 493, 9594, 13, 286, 500, 380, 1127, 498, 746, 665, 2011, 51448], "temperature": 0.0, "avg_logprob": -0.11133507856233853, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.003153348108753562}, {"id": 76, "seek": 38432, "start": 406.0, "end": 412.08, "text": " to you. It should have happened to me instead. So this seems like a dumb example, but it was a", "tokens": [51448, 281, 291, 13, 467, 820, 362, 2011, 281, 385, 2602, 13, 407, 341, 2544, 411, 257, 10316, 1365, 11, 457, 309, 390, 257, 51752], "temperature": 0.0, "avg_logprob": -0.11133507856233853, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.003153348108753562}, {"id": 77, "seek": 41208, "start": 412.08, "end": 416.32, "text": " really good moment on Twitter that shows kind of the energy flows that happen on these really", "tokens": [50364, 534, 665, 1623, 322, 5794, 300, 3110, 733, 295, 264, 2281, 12867, 300, 1051, 322, 613, 534, 50576], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 78, "seek": 41208, "start": 416.32, "end": 421.35999999999996, "text": " large-scale social media platforms, right? Someone can publish something that's very kind and nice", "tokens": [50576, 2416, 12, 20033, 2093, 3021, 9473, 11, 558, 30, 8734, 393, 11374, 746, 300, 311, 588, 733, 293, 1481, 50828], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 79, "seek": 41208, "start": 421.35999999999996, "end": 426.15999999999997, "text": " and it gets interpreted the wrong way. People take it in bad faith. They take it out of context.", "tokens": [50828, 293, 309, 2170, 26749, 264, 2085, 636, 13, 3432, 747, 309, 294, 1578, 4522, 13, 814, 747, 309, 484, 295, 4319, 13, 51068], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 80, "seek": 41208, "start": 426.15999999999997, "end": 430.88, "text": " They try to amplify it to unintended audiences. We will take every opportunity to misinterpret", "tokens": [51068, 814, 853, 281, 41174, 309, 281, 49902, 15479, 13, 492, 486, 747, 633, 2650, 281, 3346, 41935, 51304], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 81, "seek": 41208, "start": 430.88, "end": 435.44, "text": " things and be ungenerous to each other. And this is how we get cancelling some pylons and we've", "tokens": [51304, 721, 293, 312, 517, 21848, 563, 281, 1184, 661, 13, 400, 341, 307, 577, 321, 483, 393, 384, 2669, 512, 280, 5088, 892, 293, 321, 600, 51532], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 82, "seek": 41208, "start": 435.44, "end": 441.59999999999997, "text": " all seen so many examples of this happening in what seems like a very unfair way. John Ronson", "tokens": [51532, 439, 1612, 370, 867, 5110, 295, 341, 2737, 294, 437, 2544, 411, 257, 588, 17019, 636, 13, 2619, 497, 892, 266, 51840], "temperature": 0.0, "avg_logprob": -0.0821618683197919, "compression_ratio": 1.688235294117647, "no_speech_prob": 0.004146096762269735}, {"id": 83, "seek": 44160, "start": 441.6, "end": 444.96000000000004, "text": " wrote an entire book about this called You've Been Publicly Shamed. The catalog is quite a", "tokens": [50364, 4114, 364, 2302, 1446, 466, 341, 1219, 509, 600, 32839, 9489, 356, 1160, 3475, 13, 440, 19746, 307, 1596, 257, 50532], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 84, "seek": 44160, "start": 444.96000000000004, "end": 449.52000000000004, "text": " few of these. It's a little out of date now, but it's a lot of kind of classic original examples", "tokens": [50532, 1326, 295, 613, 13, 467, 311, 257, 707, 484, 295, 4002, 586, 11, 457, 309, 311, 257, 688, 295, 733, 295, 7230, 3380, 5110, 50760], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 85, "seek": 44160, "start": 449.52000000000004, "end": 454.40000000000003, "text": " of people getting cancels. And then the real material consequences they fix, right? They lose", "tokens": [50760, 295, 561, 1242, 393, 66, 1625, 13, 400, 550, 264, 957, 2527, 10098, 436, 3191, 11, 558, 30, 814, 3624, 51004], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 86, "seek": 44160, "start": 454.40000000000003, "end": 459.20000000000005, "text": " jobs. They lose friends. They are alienated from their community. It is not just internet drama.", "tokens": [51004, 4782, 13, 814, 3624, 1855, 13, 814, 366, 12319, 770, 490, 641, 1768, 13, 467, 307, 406, 445, 4705, 9412, 13, 51244], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 87, "seek": 44160, "start": 459.20000000000005, "end": 464.96000000000004, "text": " They really do have to face repercussions for these pylons. And so this makes the web a very", "tokens": [51244, 814, 534, 360, 362, 281, 1851, 28946, 38899, 337, 613, 280, 5088, 892, 13, 400, 370, 341, 1669, 264, 3670, 257, 588, 51532], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 88, "seek": 44160, "start": 464.96000000000004, "end": 469.20000000000005, "text": " sincerely dangerous place to sincerely publish your thoughts, to publish honest things on.", "tokens": [51532, 30694, 5795, 1081, 281, 30694, 11374, 428, 4598, 11, 281, 11374, 3245, 721, 322, 13, 51744], "temperature": 0.0, "avg_logprob": -0.10620701401321976, "compression_ratio": 1.6578171091445428, "no_speech_prob": 0.0022312679793685675}, {"id": 89, "seek": 47160, "start": 471.6, "end": 475.52000000000004, "text": " And this makes it hard to find people, right? It's very difficult to find people who are being", "tokens": [50364, 400, 341, 1669, 309, 1152, 281, 915, 561, 11, 558, 30, 467, 311, 588, 2252, 281, 915, 561, 567, 366, 885, 50560], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 90, "seek": 47160, "start": 475.52000000000004, "end": 480.40000000000003, "text": " sincere, who are seeking coherence and who are trying to build collective knowledge in public.", "tokens": [50560, 16941, 11, 567, 366, 11670, 26528, 655, 293, 567, 366, 1382, 281, 1322, 12590, 3601, 294, 1908, 13, 50804], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 91, "seek": 47160, "start": 481.36, "end": 485.52000000000004, "text": " I know this is not what everyone wants to do with the web, right? Like some people just want to", "tokens": [50852, 286, 458, 341, 307, 406, 437, 1518, 2738, 281, 360, 365, 264, 3670, 11, 558, 30, 1743, 512, 561, 445, 528, 281, 51060], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 92, "seek": 47160, "start": 485.52000000000004, "end": 490.24, "text": " dance on TikTok and that's completely fine. We have to let them do that. But I'm interested in", "tokens": [51060, 4489, 322, 20211, 293, 300, 311, 2584, 2489, 13, 492, 362, 281, 718, 552, 360, 300, 13, 583, 286, 478, 3102, 294, 51296], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 93, "seek": 47160, "start": 490.24, "end": 496.0, "text": " at least some of the web enabling this kind of productive discourse and having spaces of community", "tokens": [51296, 412, 1935, 512, 295, 264, 3670, 23148, 341, 733, 295, 13304, 23938, 293, 1419, 7673, 295, 1768, 51584], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 94, "seek": 47160, "start": 496.0, "end": 500.8, "text": " building and I'm hoping some people here feel the same, right? Rather than it being like this", "tokens": [51584, 2390, 293, 286, 478, 7159, 512, 561, 510, 841, 264, 912, 11, 558, 30, 16571, 813, 309, 885, 411, 341, 51824], "temperature": 0.0, "avg_logprob": -0.09048945868193213, "compression_ratio": 1.7739938080495357, "no_speech_prob": 0.0014316141605377197}, {"id": 95, "seek": 50080, "start": 500.8, "end": 506.0, "text": " threatening inhuman place where you can't actually say what you think. So how do we cope with this,", "tokens": [50364, 20768, 294, 18796, 1081, 689, 291, 393, 380, 767, 584, 437, 291, 519, 13, 407, 577, 360, 321, 22598, 365, 341, 11, 50624], "temperature": 0.0, "avg_logprob": -0.11756781227568276, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0007479653577320278}, {"id": 96, "seek": 50080, "start": 506.0, "end": 511.44, "text": " right? We're all wandering around this dark forest of like Facebook and LinkedIn and Twitter", "tokens": [50624, 558, 30, 492, 434, 439, 26396, 926, 341, 2877, 6719, 295, 411, 4384, 293, 20657, 293, 5794, 50896], "temperature": 0.0, "avg_logprob": -0.11756781227568276, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0007479653577320278}, {"id": 97, "seek": 50080, "start": 511.44, "end": 516.64, "text": " and we realize we need to go somewhere safer. So what we end up doing is we retreat primarily to", "tokens": [50896, 293, 321, 4325, 321, 643, 281, 352, 4079, 15856, 13, 407, 437, 321, 917, 493, 884, 307, 321, 15505, 10029, 281, 51156], "temperature": 0.0, "avg_logprob": -0.11756781227568276, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0007479653577320278}, {"id": 98, "seek": 50080, "start": 516.64, "end": 523.12, "text": " what's being called the cozy web. So this was a term coined by Venkatesh Rao in direct response", "tokens": [51156, 437, 311, 885, 1219, 264, 29414, 3670, 13, 407, 341, 390, 257, 1433, 45222, 538, 11182, 74, 1024, 71, 7591, 78, 294, 2047, 4134, 51480], "temperature": 0.0, "avg_logprob": -0.11756781227568276, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0007479653577320278}, {"id": 99, "seek": 50080, "start": 523.12, "end": 529.04, "text": " to the dark web theory. And Venkat pointed out that we've all started going underground. We move", "tokens": [51480, 281, 264, 2877, 3670, 5261, 13, 400, 11182, 20876, 10932, 484, 300, 321, 600, 439, 1409, 516, 14977, 13, 492, 1286, 51776], "temperature": 0.0, "avg_logprob": -0.11756781227568276, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0007479653577320278}, {"id": 100, "seek": 52904, "start": 529.04, "end": 534.24, "text": " into semi-private spaces like newsletters or personal websites where you're less at risk of", "tokens": [50364, 666, 12909, 12, 36391, 19083, 7673, 411, 2583, 2631, 1559, 420, 2973, 12891, 689, 291, 434, 1570, 412, 3148, 295, 50624], "temperature": 0.0, "avg_logprob": -0.09569671826484875, "compression_ratio": 1.6782006920415224, "no_speech_prob": 0.0008634977275505662}, {"id": 101, "seek": 52904, "start": 534.24, "end": 539.52, "text": " attack. You're not on these big platforms. You're on your own separate domain or you're on your own", "tokens": [50624, 2690, 13, 509, 434, 406, 322, 613, 955, 9473, 13, 509, 434, 322, 428, 1065, 4994, 9274, 420, 291, 434, 322, 428, 1065, 50888], "temperature": 0.0, "avg_logprob": -0.09569671826484875, "compression_ratio": 1.6782006920415224, "no_speech_prob": 0.0008634977275505662}, {"id": 102, "seek": 52904, "start": 539.52, "end": 544.7199999999999, "text": " separate newsletter. So this gives us some safety. We can at least decide a little bit who reads it", "tokens": [50888, 4994, 26469, 13, 407, 341, 2709, 505, 512, 4514, 13, 492, 393, 412, 1935, 4536, 257, 707, 857, 567, 15700, 309, 51148], "temperature": 0.0, "avg_logprob": -0.09569671826484875, "compression_ratio": 1.6782006920415224, "no_speech_prob": 0.0008634977275505662}, {"id": 103, "seek": 52904, "start": 544.7199999999999, "end": 550.8, "text": " and understand our audience. But we often retreat even further into gate kept spaces like slacks,", "tokens": [51148, 293, 1223, 527, 4034, 13, 583, 321, 2049, 15505, 754, 3052, 666, 8539, 4305, 7673, 411, 1061, 7424, 11, 51452], "temperature": 0.0, "avg_logprob": -0.09569671826484875, "compression_ratio": 1.6782006920415224, "no_speech_prob": 0.0008634977275505662}, {"id": 104, "seek": 52904, "start": 550.8, "end": 556.0799999999999, "text": " WhatsApps, Discord, Signal groups, right? This is where we end up spending the most of our time", "tokens": [51452, 30513, 82, 11, 32623, 11, 43414, 3935, 11, 558, 30, 639, 307, 689, 321, 917, 493, 6434, 264, 881, 295, 527, 565, 51716], "temperature": 0.0, "avg_logprob": -0.09569671826484875, "compression_ratio": 1.6782006920415224, "no_speech_prob": 0.0008634977275505662}, {"id": 105, "seek": 55608, "start": 556.08, "end": 561.2800000000001, "text": " and having real human relationships where we can express our ideas safely, right? So things", "tokens": [50364, 293, 1419, 957, 1952, 6159, 689, 321, 393, 5109, 527, 3487, 11750, 11, 558, 30, 407, 721, 50624], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 106, "seek": 55608, "start": 561.2800000000001, "end": 566.08, "text": " that we say we know will be taken in good faith in these smaller groups. We can engage in real", "tokens": [50624, 300, 321, 584, 321, 458, 486, 312, 2726, 294, 665, 4522, 294, 613, 4356, 3935, 13, 492, 393, 4683, 294, 957, 50864], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 107, "seek": 55608, "start": 566.08, "end": 571.2, "text": " discussions. But there's some problems here, right? Like none of this is indexable or searchable.", "tokens": [50864, 11088, 13, 583, 456, 311, 512, 2740, 510, 11, 558, 30, 1743, 6022, 295, 341, 307, 8186, 712, 420, 3164, 712, 13, 51120], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 108, "seek": 55608, "start": 571.2, "end": 577.0400000000001, "text": " It's very hard to include people who aren't already in the group. And it hides collective", "tokens": [51120, 467, 311, 588, 1152, 281, 4090, 561, 567, 3212, 380, 1217, 294, 264, 1594, 13, 400, 309, 35953, 12590, 51412], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 109, "seek": 55608, "start": 577.0400000000001, "end": 580.72, "text": " knowledge in these private databases that are even hard for the users themselves to access.", "tokens": [51412, 3601, 294, 613, 4551, 22380, 300, 366, 754, 1152, 337, 264, 5022, 2969, 281, 2105, 13, 51596], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 110, "seek": 55608, "start": 581.44, "end": 585.12, "text": " And also like good luck finding anything on Discord. Like you'll never be able to use the", "tokens": [51632, 400, 611, 411, 665, 3668, 5006, 1340, 322, 32623, 13, 1743, 291, 603, 1128, 312, 1075, 281, 764, 264, 51816], "temperature": 0.0, "avg_logprob": -0.06947778165340424, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.0005008341977372766}, {"id": 111, "seek": 58512, "start": 585.12, "end": 592.08, "text": " search functionality in these apps. So my current theory, sadly, is that the dark forest is about", "tokens": [50364, 3164, 14980, 294, 613, 7733, 13, 407, 452, 2190, 5261, 11, 22023, 11, 307, 300, 264, 2877, 6719, 307, 466, 50712], "temperature": 0.0, "avg_logprob": -0.07594502312796457, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0003858476411551237}, {"id": 112, "seek": 58512, "start": 592.08, "end": 599.28, "text": " to expand because we now have this thing called generative AI. So I'm sure everyone has mostly", "tokens": [50712, 281, 5268, 570, 321, 586, 362, 341, 551, 1219, 1337, 1166, 7318, 13, 407, 286, 478, 988, 1518, 575, 5240, 51072], "temperature": 0.0, "avg_logprob": -0.07594502312796457, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0003858476411551237}, {"id": 113, "seek": 58512, "start": 599.28, "end": 603.12, "text": " heard of this, but what I'm talking about specifically here is machine learning models", "tokens": [51072, 2198, 295, 341, 11, 457, 437, 286, 478, 1417, 466, 4682, 510, 307, 3479, 2539, 5245, 51264], "temperature": 0.0, "avg_logprob": -0.07594502312796457, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0003858476411551237}, {"id": 114, "seek": 58512, "start": 603.12, "end": 608.08, "text": " and neural networks that can create content that before this point in history only humans could", "tokens": [51264, 293, 18161, 9590, 300, 393, 1884, 2701, 300, 949, 341, 935, 294, 2503, 787, 6255, 727, 51512], "temperature": 0.0, "avg_logprob": -0.07594502312796457, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0003858476411551237}, {"id": 115, "seek": 58512, "start": 608.08, "end": 614.32, "text": " make, right? This is text, images, audio and video that mimics human creations in a very", "tokens": [51512, 652, 11, 558, 30, 639, 307, 2487, 11, 5267, 11, 6278, 293, 960, 300, 12247, 1167, 1952, 37836, 294, 257, 588, 51824], "temperature": 0.0, "avg_logprob": -0.07594502312796457, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0003858476411551237}, {"id": 116, "seek": 61432, "start": 614.32, "end": 620.0, "text": " compelling and believable way. Here are kind of some of the major foundational models that you", "tokens": [50364, 20050, 293, 1351, 17915, 636, 13, 1692, 366, 733, 295, 512, 295, 264, 2563, 32195, 5245, 300, 291, 50648], "temperature": 0.0, "avg_logprob": -0.14012581060740573, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0004252590879332274}, {"id": 117, "seek": 61432, "start": 620.0, "end": 625.36, "text": " might have heard of for different media types, right? We have GPT4 and clod for text, mid-journey", "tokens": [50648, 1062, 362, 2198, 295, 337, 819, 3021, 3467, 11, 558, 30, 492, 362, 26039, 51, 19, 293, 596, 378, 337, 2487, 11, 2062, 12, 8696, 2397, 50916], "temperature": 0.0, "avg_logprob": -0.14012581060740573, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0004252590879332274}, {"id": 118, "seek": 61432, "start": 625.36, "end": 630.08, "text": " and stable diffusion for images. There's now video ones like runway ML. And you might have", "tokens": [50916, 293, 8351, 25242, 337, 5267, 13, 821, 311, 586, 960, 2306, 411, 26642, 21601, 13, 400, 291, 1062, 362, 51152], "temperature": 0.0, "avg_logprob": -0.14012581060740573, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0004252590879332274}, {"id": 119, "seek": 61432, "start": 630.08, "end": 634.5600000000001, "text": " heard some of the news that a lot of these models are now becoming multimodal so they can do text", "tokens": [51152, 2198, 512, 295, 264, 2583, 300, 257, 688, 295, 613, 5245, 366, 586, 5617, 32972, 378, 304, 370, 436, 393, 360, 2487, 51376], "temperature": 0.0, "avg_logprob": -0.14012581060740573, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0004252590879332274}, {"id": 120, "seek": 61432, "start": 634.5600000000001, "end": 639.6, "text": " to image, image to text, audio to text. Like you can kind of go anywhere you want with media here.", "tokens": [51376, 281, 3256, 11, 3256, 281, 2487, 11, 6278, 281, 2487, 13, 1743, 291, 393, 733, 295, 352, 4992, 291, 528, 365, 3021, 510, 13, 51628], "temperature": 0.0, "avg_logprob": -0.14012581060740573, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0004252590879332274}, {"id": 121, "seek": 63960, "start": 640.5600000000001, "end": 645.36, "text": " And this is, of course, chat GPT. I'm sure we've all seen a thousand screenshots of this at this", "tokens": [50412, 400, 341, 307, 11, 295, 1164, 11, 5081, 26039, 51, 13, 286, 478, 988, 321, 600, 439, 1612, 257, 4714, 40661, 295, 341, 412, 341, 50652], "temperature": 0.0, "avg_logprob": -0.11786837875843048, "compression_ratio": 1.5913621262458473, "no_speech_prob": 0.0005764479865320027}, {"id": 122, "seek": 63960, "start": 645.36, "end": 651.0400000000001, "text": " point. We understand what it is. But to recap, it's right, we know it can generate huge volumes", "tokens": [50652, 935, 13, 492, 1223, 437, 309, 307, 13, 583, 281, 20928, 11, 309, 311, 558, 11, 321, 458, 309, 393, 8460, 2603, 22219, 50936], "temperature": 0.0, "avg_logprob": -0.11786837875843048, "compression_ratio": 1.5913621262458473, "no_speech_prob": 0.0005764479865320027}, {"id": 123, "seek": 63960, "start": 651.0400000000001, "end": 656.48, "text": " of high-quality text in seconds. The outputs are indistinguishable from human-made text when we", "tokens": [50936, 295, 1090, 12, 11286, 2487, 294, 3949, 13, 440, 23930, 366, 1016, 468, 7050, 742, 712, 490, 1952, 12, 10341, 2487, 562, 321, 51208], "temperature": 0.0, "avg_logprob": -0.11786837875843048, "compression_ratio": 1.5913621262458473, "no_speech_prob": 0.0005764479865320027}, {"id": 124, "seek": 63960, "start": 656.48, "end": 661.6800000000001, "text": " try to get people to guess what's chat GPT and what's human. They often can't. It's trained on a", "tokens": [51208, 853, 281, 483, 561, 281, 2041, 437, 311, 5081, 26039, 51, 293, 437, 311, 1952, 13, 814, 2049, 393, 380, 13, 467, 311, 8895, 322, 257, 51468], "temperature": 0.0, "avg_logprob": -0.11786837875843048, "compression_ratio": 1.5913621262458473, "no_speech_prob": 0.0005764479865320027}, {"id": 125, "seek": 63960, "start": 661.6800000000001, "end": 667.2, "text": " huge volume of text scraped primarily from the English-speaking web. And this all sounds very", "tokens": [51468, 2603, 5523, 295, 2487, 13943, 3452, 10029, 490, 264, 3669, 12, 14579, 3670, 13, 400, 341, 439, 3263, 588, 51744], "temperature": 0.0, "avg_logprob": -0.11786837875843048, "compression_ratio": 1.5913621262458473, "no_speech_prob": 0.0005764479865320027}, {"id": 126, "seek": 66720, "start": 667.2, "end": 671.6800000000001, "text": " simple, right? But it leads to many kind of complex and potentially useful behaviors, but it's", "tokens": [50364, 2199, 11, 558, 30, 583, 309, 6689, 281, 867, 733, 295, 3997, 293, 7263, 4420, 15501, 11, 457, 309, 311, 50588], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 127, "seek": 66720, "start": 671.6800000000001, "end": 677.2800000000001, "text": " very emergent. We don't really understand what's possible because of this capability yet. We can", "tokens": [50588, 588, 4345, 6930, 13, 492, 500, 380, 534, 1223, 437, 311, 1944, 570, 295, 341, 13759, 1939, 13, 492, 393, 50868], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 128, "seek": 66720, "start": 677.2800000000001, "end": 681.36, "text": " also now, of course, generate images, right? This is mid-journey, which usually makes pretty", "tokens": [50868, 611, 586, 11, 295, 1164, 11, 8460, 5267, 11, 558, 30, 639, 307, 2062, 12, 8696, 2397, 11, 597, 2673, 1669, 1238, 51072], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 129, "seek": 66720, "start": 681.36, "end": 687.44, "text": " beautiful impressive stuff. But so we found that these, like, generative AI models are now very", "tokens": [51072, 2238, 8992, 1507, 13, 583, 370, 321, 1352, 300, 613, 11, 411, 11, 1337, 1166, 7318, 5245, 366, 586, 588, 51376], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 130, "seek": 66720, "start": 687.44, "end": 691.12, "text": " easy to use and very widely accessible, right? They don't require technical skills. They're", "tokens": [51376, 1858, 281, 764, 293, 588, 13371, 9515, 11, 558, 30, 814, 500, 380, 3651, 6191, 3942, 13, 814, 434, 51560], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 131, "seek": 66720, "start": 691.12, "end": 695.5200000000001, "text": " incredibly cheap. And they're increasingly becoming a feature in existing software you already have", "tokens": [51560, 6252, 7084, 13, 400, 436, 434, 12980, 5617, 257, 4111, 294, 6741, 4722, 291, 1217, 362, 51780], "temperature": 0.0, "avg_logprob": -0.11104165142729082, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.00022078465553931892}, {"id": 132, "seek": 69552, "start": 695.52, "end": 698.96, "text": " access to, like Adobe or Photoshop or Notion. They're just becoming pervasive.", "tokens": [50364, 2105, 281, 11, 411, 24862, 420, 20821, 420, 1726, 313, 13, 814, 434, 445, 5617, 680, 39211, 13, 50536], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 133, "seek": 69552, "start": 701.1999999999999, "end": 705.36, "text": " But the product category that I'm most nervous about, not just, like, Notion generating a plan", "tokens": [50648, 583, 264, 1674, 7719, 300, 286, 478, 881, 6296, 466, 11, 406, 445, 11, 411, 11, 1726, 313, 17746, 257, 1393, 50856], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 134, "seek": 69552, "start": 705.36, "end": 709.68, "text": " for you, is what's being called content generators, mostly for content marketers. So I'm going to pick", "tokens": [50856, 337, 291, 11, 307, 437, 311, 885, 1219, 2701, 38662, 11, 5240, 337, 2701, 48003, 13, 407, 286, 478, 516, 281, 1888, 51072], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 135, "seek": 69552, "start": 709.68, "end": 714.72, "text": " on one product, but there are many. This one's called Blaze. And it creates articles and social", "tokens": [51072, 322, 472, 1674, 11, 457, 456, 366, 867, 13, 639, 472, 311, 1219, 49894, 13, 400, 309, 7829, 11290, 293, 2093, 51324], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 136, "seek": 69552, "start": 714.72, "end": 718.16, "text": " media content for you, right? In half the time, who wouldn't want that? Who doesn't want more", "tokens": [51324, 3021, 2701, 337, 291, 11, 558, 30, 682, 1922, 264, 565, 11, 567, 2759, 380, 528, 300, 30, 2102, 1177, 380, 528, 544, 51496], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 137, "seek": 69552, "start": 718.16, "end": 723.52, "text": " content on the internet? And so I want to show you how this works. So you decide what kind of", "tokens": [51496, 2701, 322, 264, 4705, 30, 400, 370, 286, 528, 281, 855, 291, 577, 341, 1985, 13, 407, 291, 4536, 437, 733, 295, 51764], "temperature": 0.0, "avg_logprob": -0.0784157083389607, "compression_ratio": 1.7125382262996942, "no_speech_prob": 0.0008689388050697744}, {"id": 138, "seek": 72352, "start": 723.52, "end": 728.64, "text": " content you want to make, right? You can say a blog post or a newsletter or a bunch of Twitter posts.", "tokens": [50364, 2701, 291, 528, 281, 652, 11, 558, 30, 509, 393, 584, 257, 6968, 2183, 420, 257, 26469, 420, 257, 3840, 295, 5794, 12300, 13, 50620], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 139, "seek": 72352, "start": 728.64, "end": 732.96, "text": " And I'm going to say I want to write a blog post. And you type in what you want to write about,", "tokens": [50620, 400, 286, 478, 516, 281, 584, 286, 528, 281, 2464, 257, 6968, 2183, 13, 400, 291, 2010, 294, 437, 291, 528, 281, 2464, 466, 11, 50836], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 140, "seek": 72352, "start": 732.96, "end": 737.04, "text": " and your target audience, and SEO keywords. So I've decided I want to write about why", "tokens": [50836, 293, 428, 3779, 4034, 11, 293, 22964, 21009, 13, 407, 286, 600, 3047, 286, 528, 281, 2464, 466, 983, 51040], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 141, "seek": 72352, "start": 737.6, "end": 740.96, "text": " plant-based meat is morally wrong, which I don't believe, but that sounds like a good clickbait", "tokens": [51068, 3709, 12, 6032, 4615, 307, 38622, 2085, 11, 597, 286, 500, 380, 1697, 11, 457, 300, 3263, 411, 257, 665, 2052, 41274, 51236], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 142, "seek": 72352, "start": 740.96, "end": 743.4399999999999, "text": " to me. Like, someone's going to be like, yeah, I want to find out why that's bad.", "tokens": [51236, 281, 385, 13, 1743, 11, 1580, 311, 516, 281, 312, 411, 11, 1338, 11, 286, 528, 281, 915, 484, 983, 300, 311, 1578, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 143, "seek": 72352, "start": 744.48, "end": 748.56, "text": " You know, maybe I'm a company that has some financial interest in plant-based meats going", "tokens": [51412, 509, 458, 11, 1310, 286, 478, 257, 2237, 300, 575, 512, 4669, 1179, 294, 3709, 12, 6032, 38106, 516, 51616], "temperature": 0.0, "avg_logprob": -0.10611231797406463, "compression_ratio": 1.7831715210355987, "no_speech_prob": 0.0013105451362207532}, {"id": 144, "seek": 74856, "start": 748.56, "end": 753.8399999999999, "text": " badly. So I'm going to go ahead and have this model write a little article for me. It lets", "tokens": [50364, 13425, 13, 407, 286, 478, 516, 281, 352, 2286, 293, 362, 341, 2316, 2464, 257, 707, 7222, 337, 385, 13, 467, 6653, 50628], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 145, "seek": 74856, "start": 753.8399999999999, "end": 758.64, "text": " me pick a title, which is a nice customization. And then it chans out 700 words, right? And this", "tokens": [50628, 385, 1888, 257, 4876, 11, 597, 307, 257, 1481, 39387, 13, 400, 550, 309, 417, 599, 484, 15204, 2283, 11, 558, 30, 400, 341, 50868], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 146, "seek": 74856, "start": 758.64, "end": 761.8399999999999, "text": " is now ready for me to hit publish, right? Or at least gives me some base to work off.", "tokens": [50868, 307, 586, 1919, 337, 385, 281, 2045, 11374, 11, 558, 30, 1610, 412, 1935, 2709, 385, 512, 3096, 281, 589, 766, 13, 51028], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 147, "seek": 74856, "start": 762.64, "end": 766.0799999999999, "text": " And if I'm blobbing against plant-based meats, I can just generate 100 of these, right? And,", "tokens": [51068, 400, 498, 286, 478, 46115, 4324, 1970, 3709, 12, 6032, 38106, 11, 286, 393, 445, 8460, 2319, 295, 613, 11, 558, 30, 400, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 148, "seek": 74856, "start": 766.0799999999999, "end": 770.3199999999999, "text": " like, optimize them for Google SEO and publish them all at once. And, like, hard days out of", "tokens": [51240, 411, 11, 19719, 552, 337, 3329, 22964, 293, 11374, 552, 439, 412, 1564, 13, 400, 11, 411, 11, 1152, 1708, 484, 295, 51452], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 149, "seek": 74856, "start": 770.3199999999999, "end": 774.8, "text": " Cassie Dunn. Right? The quality and truthfulness of what's written in here is very questionable.", "tokens": [51452, 18208, 414, 11959, 77, 13, 1779, 30, 440, 3125, 293, 3494, 26872, 295, 437, 311, 3720, 294, 510, 307, 588, 37158, 13, 51676], "temperature": 0.0, "avg_logprob": -0.1467811711629232, "compression_ratio": 1.6239067055393586, "no_speech_prob": 0.005055286921560764}, {"id": 150, "seek": 77480, "start": 774.8, "end": 779.92, "text": " We'll get to problems with that later. But the point is, this is super easy to do at scale", "tokens": [50364, 492, 603, 483, 281, 2740, 365, 300, 1780, 13, 583, 264, 935, 307, 11, 341, 307, 1687, 1858, 281, 360, 412, 4373, 50620], "temperature": 0.0, "avg_logprob": -0.10618950191297029, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.002387093845754862}, {"id": 151, "seek": 77480, "start": 779.92, "end": 784.8, "text": " very cheaply. And it essentially murders Google such, right? Like, this just does away with SEO", "tokens": [50620, 588, 7084, 356, 13, 400, 309, 4476, 30479, 3329, 1270, 11, 558, 30, 1743, 11, 341, 445, 775, 1314, 365, 22964, 50864], "temperature": 0.0, "avg_logprob": -0.10618950191297029, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.002387093845754862}, {"id": 152, "seek": 77480, "start": 784.8, "end": 790.88, "text": " optimized content. Because anyone can publish this immediately. It gets even better at the end.", "tokens": [50864, 26941, 2701, 13, 1436, 2878, 393, 11374, 341, 4258, 13, 467, 2170, 754, 1101, 412, 264, 917, 13, 51168], "temperature": 0.0, "avg_logprob": -0.10618950191297029, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.002387093845754862}, {"id": 153, "seek": 77480, "start": 790.88, "end": 794.8, "text": " Like, it prompts me to generate more content. So it's like, oh, you have this blog post. Why not", "tokens": [51168, 1743, 11, 309, 41095, 385, 281, 8460, 544, 2701, 13, 407, 309, 311, 411, 11, 1954, 11, 291, 362, 341, 6968, 2183, 13, 1545, 406, 51364], "temperature": 0.0, "avg_logprob": -0.10618950191297029, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.002387093845754862}, {"id": 154, "seek": 77480, "start": 794.8, "end": 798.8, "text": " generate LinkedIn posts and tweets and YouTube scripts and everything. We're not just getting", "tokens": [51364, 8460, 20657, 12300, 293, 25671, 293, 3088, 23294, 293, 1203, 13, 492, 434, 406, 445, 1242, 51564], "temperature": 0.0, "avg_logprob": -0.10618950191297029, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.002387093845754862}, {"id": 155, "seek": 79880, "start": 798.8, "end": 805.4399999999999, "text": " crappy Google articles. This is across every publishing platform. Right? So there's tons of", "tokens": [50364, 36531, 3329, 11290, 13, 639, 307, 2108, 633, 17832, 3663, 13, 1779, 30, 407, 456, 311, 9131, 295, 50696], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 156, "seek": 79880, "start": 805.4399999999999, "end": 808.9599999999999, "text": " things to do this. There's, like, AI-linked post-generators, generate your next tweet,", "tokens": [50696, 721, 281, 360, 341, 13, 821, 311, 11, 411, 11, 7318, 12, 22473, 292, 2183, 12, 21848, 3391, 11, 8460, 428, 958, 15258, 11, 50872], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 157, "seek": 79880, "start": 808.9599999999999, "end": 812.24, "text": " right? YouTube content and autopilot, just thousands of these tools are pouring out.", "tokens": [50872, 558, 30, 3088, 2701, 293, 31090, 31516, 11, 445, 5383, 295, 613, 3873, 366, 20450, 484, 13, 51036], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 158, "seek": 79880, "start": 814.0799999999999, "end": 818.24, "text": " So most of the examples I showed actually have a very simple architecture, right? You have a", "tokens": [51128, 407, 881, 295, 264, 5110, 286, 4712, 767, 362, 257, 588, 2199, 9482, 11, 558, 30, 509, 362, 257, 51336], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 159, "seek": 79880, "start": 818.24, "end": 822.88, "text": " single input, like, write me an article on plant-based meat. And you feed it into this big,", "tokens": [51336, 2167, 4846, 11, 411, 11, 2464, 385, 364, 7222, 322, 3709, 12, 6032, 4615, 13, 400, 291, 3154, 309, 666, 341, 955, 11, 51568], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 160, "seek": 79880, "start": 822.88, "end": 826.9599999999999, "text": " black mystery box of a language model, right? And we don't really understand totally what", "tokens": [51568, 2211, 11422, 2424, 295, 257, 2856, 2316, 11, 558, 30, 400, 321, 500, 380, 534, 1223, 3879, 437, 51772], "temperature": 0.0, "avg_logprob": -0.14301251289539768, "compression_ratio": 1.6604938271604939, "no_speech_prob": 0.00473807891830802}, {"id": 161, "seek": 82696, "start": 827.0400000000001, "end": 831.12, "text": " happens inside, but it gives you an output, right? Rates you an essay. But you can't really tweak", "tokens": [50368, 2314, 1854, 11, 457, 309, 2709, 291, 364, 5598, 11, 558, 30, 497, 1024, 291, 364, 16238, 13, 583, 291, 393, 380, 534, 29879, 50572], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 162, "seek": 82696, "start": 831.12, "end": 835.2800000000001, "text": " what happened in the middle. You can edit the output, but you can't kind of pull the knobs", "tokens": [50572, 437, 2011, 294, 264, 2808, 13, 509, 393, 8129, 264, 5598, 11, 457, 291, 393, 380, 733, 295, 2235, 264, 46999, 50780], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 163, "seek": 82696, "start": 835.2800000000001, "end": 840.0, "text": " on the actual language model itself. Which isn't very sophisticated. We don't have a lot of control", "tokens": [50780, 322, 264, 3539, 2856, 2316, 2564, 13, 3013, 1943, 380, 588, 16950, 13, 492, 500, 380, 362, 257, 688, 295, 1969, 51016], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 164, "seek": 82696, "start": 840.0, "end": 844.96, "text": " or transparency in what's happening. But the industry has realized this is a problem, and we", "tokens": [51016, 420, 17131, 294, 437, 311, 2737, 13, 583, 264, 3518, 575, 5334, 341, 307, 257, 1154, 11, 293, 321, 51264], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 165, "seek": 82696, "start": 844.96, "end": 851.0400000000001, "text": " started building architectures that are much more flexible and powerful. So we now have a language", "tokens": [51264, 1409, 2390, 6331, 1303, 300, 366, 709, 544, 11358, 293, 4005, 13, 407, 321, 586, 362, 257, 2856, 51568], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 166, "seek": 82696, "start": 851.0400000000001, "end": 855.44, "text": " model architecture where we take that same black box of the language model, but we give it access", "tokens": [51568, 2316, 9482, 689, 321, 747, 300, 912, 2211, 2424, 295, 264, 2856, 2316, 11, 457, 321, 976, 309, 2105, 51788], "temperature": 0.0, "avg_logprob": -0.08717677873723648, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.000310584349790588}, {"id": 167, "seek": 85544, "start": 855.44, "end": 858.8000000000001, "text": " to external tools, right? We say, okay, now we're going to tell it it can search the web through", "tokens": [50364, 281, 8320, 3873, 11, 558, 30, 492, 584, 11, 1392, 11, 586, 321, 434, 516, 281, 980, 309, 309, 393, 3164, 264, 3670, 807, 50532], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 168, "seek": 85544, "start": 858.8000000000001, "end": 864.72, "text": " an API. We give it access to a calculator. We give it access to a code REPL and APIs. It's now", "tokens": [50532, 364, 9362, 13, 492, 976, 309, 2105, 281, 257, 24993, 13, 492, 976, 309, 2105, 281, 257, 3089, 31511, 43, 293, 21445, 13, 467, 311, 586, 50828], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 169, "seek": 85544, "start": 864.72, "end": 870.1600000000001, "text": " getting a lot more capable, right? It can now look up, can do maths, you know? It can look up", "tokens": [50828, 1242, 257, 688, 544, 8189, 11, 558, 30, 467, 393, 586, 574, 493, 11, 393, 360, 36287, 11, 291, 458, 30, 467, 393, 574, 493, 51100], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 170, "seek": 85544, "start": 870.1600000000001, "end": 875.44, "text": " information that things might not be right. It can double check its answers. Also language models", "tokens": [51100, 1589, 300, 721, 1062, 406, 312, 558, 13, 467, 393, 3834, 1520, 1080, 6338, 13, 2743, 2856, 5245, 51364], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 171, "seek": 85544, "start": 875.44, "end": 878.8000000000001, "text": " are usually quite forgetful. You might have found this, chat GPT after a long string. We'll forget", "tokens": [51364, 366, 2673, 1596, 2870, 906, 13, 509, 1062, 362, 1352, 341, 11, 5081, 26039, 51, 934, 257, 938, 6798, 13, 492, 603, 2870, 51532], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 172, "seek": 85544, "start": 878.8000000000001, "end": 882.8800000000001, "text": " what you said earlier on. We can now hook them up to long-term memory databases and have them", "tokens": [51532, 437, 291, 848, 3071, 322, 13, 492, 393, 586, 6328, 552, 493, 281, 938, 12, 7039, 4675, 22380, 293, 362, 552, 51736], "temperature": 0.0, "avg_logprob": -0.12354924031440785, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.0015695298789069057}, {"id": 173, "seek": 88288, "start": 882.88, "end": 886.56, "text": " reference things like many weeks or months in the past, which makes them a lot more capable.", "tokens": [50364, 6408, 721, 411, 867, 3259, 420, 2493, 294, 264, 1791, 11, 597, 1669, 552, 257, 688, 544, 8189, 13, 50548], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 174, "seek": 88288, "start": 887.68, "end": 892.16, "text": " And we've also found that they perform much better if you give them these cognitive prompts.", "tokens": [50604, 400, 321, 600, 611, 1352, 300, 436, 2042, 709, 1101, 498, 291, 976, 552, 613, 15605, 41095, 13, 50828], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 175, "seek": 88288, "start": 892.16, "end": 896.0, "text": " Like you tell it to do something, but then you say, you know, think about your answer, critique it,", "tokens": [50828, 1743, 291, 980, 309, 281, 360, 746, 11, 457, 550, 291, 584, 11, 291, 458, 11, 519, 466, 428, 1867, 11, 25673, 309, 11, 51020], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 176, "seek": 88288, "start": 896.0, "end": 899.4399999999999, "text": " and then answer me again. And that actually improves the quality of the answer quite a lot.", "tokens": [51020, 293, 550, 1867, 385, 797, 13, 400, 300, 767, 24771, 264, 3125, 295, 264, 1867, 1596, 257, 688, 13, 51192], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 177, "seek": 88288, "start": 900.08, "end": 904.96, "text": " That's often called chain of thought prompting, self critique. It can observe what it knows and", "tokens": [51224, 663, 311, 2049, 1219, 5021, 295, 1194, 12391, 278, 11, 2698, 25673, 13, 467, 393, 11441, 437, 309, 3255, 293, 51468], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 178, "seek": 88288, "start": 904.96, "end": 910.24, "text": " plan the next step. And it's getting these more cognitive capacities by adding on these kind of", "tokens": [51468, 1393, 264, 958, 1823, 13, 400, 309, 311, 1242, 613, 544, 15605, 39396, 538, 5127, 322, 613, 733, 295, 51732], "temperature": 0.0, "avg_logprob": -0.09230298207218486, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.001506303553469479}, {"id": 179, "seek": 91024, "start": 911.12, "end": 916.24, "text": " extra techniques. So this is being called the agent architecture, right? You tell the language", "tokens": [50408, 2857, 7512, 13, 407, 341, 307, 885, 1219, 264, 9461, 9482, 11, 558, 30, 509, 980, 264, 2856, 50664], "temperature": 0.0, "avg_logprob": -0.09874146934447249, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.00023927765141706914}, {"id": 180, "seek": 91024, "start": 916.24, "end": 921.6800000000001, "text": " model to act like an agent. It ends up as being like the centralized brain and you give it, you", "tokens": [50664, 2316, 281, 605, 411, 364, 9461, 13, 467, 5314, 493, 382, 885, 411, 264, 32395, 3567, 293, 291, 976, 309, 11, 291, 50936], "temperature": 0.0, "avg_logprob": -0.09874146934447249, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.00023927765141706914}, {"id": 181, "seek": 91024, "start": 921.6800000000001, "end": 927.2, "text": " can say you can use any of these tools and then it composes which tools it wants to use to achieve", "tokens": [50936, 393, 584, 291, 393, 764, 604, 295, 613, 3873, 293, 550, 309, 715, 4201, 597, 3873, 309, 2738, 281, 764, 281, 4584, 51212], "temperature": 0.0, "avg_logprob": -0.09874146934447249, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.00023927765141706914}, {"id": 182, "seek": 91024, "start": 927.2, "end": 931.52, "text": " your goals. So it ends up being a chain like this where you give it your goal, it'll like observe,", "tokens": [51212, 428, 5493, 13, 407, 309, 5314, 493, 885, 257, 5021, 411, 341, 689, 291, 976, 309, 428, 3387, 11, 309, 603, 411, 11441, 11, 51428], "temperature": 0.0, "avg_logprob": -0.09874146934447249, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.00023927765141706914}, {"id": 183, "seek": 91024, "start": 931.52, "end": 936.72, "text": " it'll plan, it'll call a different tool, it'll observe, it'll plan. And we can actually do really", "tokens": [51428, 309, 603, 1393, 11, 309, 603, 818, 257, 819, 2290, 11, 309, 603, 11441, 11, 309, 603, 1393, 13, 400, 321, 393, 767, 360, 534, 51688], "temperature": 0.0, "avg_logprob": -0.09874146934447249, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.00023927765141706914}, {"id": 184, "seek": 93672, "start": 936.8000000000001, "end": 942.24, "text": " complex, kind of scarily impressive things when we level up to these more sophisticated architectures.", "tokens": [50368, 3997, 11, 733, 295, 795, 3289, 8992, 721, 562, 321, 1496, 493, 281, 613, 544, 16950, 6331, 1303, 13, 50640], "temperature": 0.0, "avg_logprob": -0.12109968683741114, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0009127094526775181}, {"id": 185, "seek": 93672, "start": 943.36, "end": 949.6800000000001, "text": " And actually on Monday, OpenAI did this big dev day talk, I don't know if people saw this,", "tokens": [50696, 400, 767, 322, 8138, 11, 7238, 48698, 630, 341, 955, 1905, 786, 751, 11, 286, 500, 380, 458, 498, 561, 1866, 341, 11, 51012], "temperature": 0.0, "avg_logprob": -0.12109968683741114, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0009127094526775181}, {"id": 186, "seek": 93672, "start": 949.6800000000001, "end": 954.48, "text": " and they announced a new API called the assistance API that makes all that stuff that I showed that", "tokens": [51012, 293, 436, 7548, 257, 777, 9362, 1219, 264, 9683, 9362, 300, 1669, 439, 300, 1507, 300, 286, 4712, 300, 51252], "temperature": 0.0, "avg_logprob": -0.12109968683741114, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0009127094526775181}, {"id": 187, "seek": 93672, "start": 954.48, "end": 959.0400000000001, "text": " used to require quite a lot of Python code and kind of insider knowledge, and they're just making", "tokens": [51252, 1143, 281, 3651, 1596, 257, 688, 295, 15329, 3089, 293, 733, 295, 40990, 3601, 11, 293, 436, 434, 445, 1455, 51480], "temperature": 0.0, "avg_logprob": -0.12109968683741114, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0009127094526775181}, {"id": 188, "seek": 93672, "start": 959.0400000000001, "end": 963.0400000000001, "text": " it super easy for everyone to now do this architecture, where you're able to kind of", "tokens": [51480, 309, 1687, 1858, 337, 1518, 281, 586, 360, 341, 9482, 11, 689, 291, 434, 1075, 281, 733, 295, 51680], "temperature": 0.0, "avg_logprob": -0.12109968683741114, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0009127094526775181}, {"id": 189, "seek": 96304, "start": 963.12, "end": 966.9599999999999, "text": " run any function, call any API, all hooked up to their really powerful models.", "tokens": [50368, 1190, 604, 2445, 11, 818, 604, 9362, 11, 439, 20410, 493, 281, 641, 534, 4005, 5245, 13, 50560], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 190, "seek": 96304, "start": 967.76, "end": 971.92, "text": " So we're about to enter this phase where this very capable agent architecture is becoming", "tokens": [50600, 407, 321, 434, 466, 281, 3242, 341, 5574, 689, 341, 588, 8189, 9461, 9482, 307, 5617, 50808], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 191, "seek": 96304, "start": 971.92, "end": 976.0799999999999, "text": " pervasive and widespread and might be the foundation of a lot of new tools being built.", "tokens": [50808, 680, 39211, 293, 22679, 293, 1062, 312, 264, 7030, 295, 257, 688, 295, 777, 3873, 885, 3094, 13, 51016], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 192, "seek": 96304, "start": 976.0799999999999, "end": 979.68, "text": " So we're sort of on the precipice of really unnerving moment, let's say.", "tokens": [51016, 407, 321, 434, 1333, 295, 322, 264, 23354, 573, 295, 534, 517, 1193, 798, 1623, 11, 718, 311, 584, 13, 51196], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 193, "seek": 96304, "start": 981.12, "end": 986.16, "text": " Because agent architectures, I think, means we're about to enter a stage of sharing the web with", "tokens": [51268, 1436, 9461, 6331, 1303, 11, 286, 519, 11, 1355, 321, 434, 466, 281, 3242, 257, 3233, 295, 5414, 264, 3670, 365, 51520], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 194, "seek": 96304, "start": 986.16, "end": 991.52, "text": " non-human agents, right? These agents are very different to what we've currently noticed bots", "tokens": [51520, 2107, 12, 18796, 12554, 11, 558, 30, 1981, 12554, 366, 588, 819, 281, 437, 321, 600, 4362, 5694, 35410, 51788], "temperature": 0.0, "avg_logprob": -0.096786865234375, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00040545538649894297}, {"id": 195, "seek": 99152, "start": 991.52, "end": 994.64, "text": " in the past, like a completely different architecture and set of capabilities.", "tokens": [50364, 294, 264, 1791, 11, 411, 257, 2584, 819, 9482, 293, 992, 295, 10862, 13, 50520], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 196, "seek": 99152, "start": 995.52, "end": 999.04, "text": " They're going to have a lot more data on how realistic humans behave,", "tokens": [50564, 814, 434, 516, 281, 362, 257, 688, 544, 1412, 322, 577, 12465, 6255, 15158, 11, 50740], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 197, "seek": 99152, "start": 999.04, "end": 1001.68, "text": " and they're rapidly going to get more and more capable as time goes on.", "tokens": [50740, 293, 436, 434, 12910, 516, 281, 483, 544, 293, 544, 8189, 382, 565, 1709, 322, 13, 50872], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 198, "seek": 99152, "start": 1002.48, "end": 1006.88, "text": " And soon, probably already now, we're not going to be able to tell difference between", "tokens": [50912, 400, 2321, 11, 1391, 1217, 586, 11, 321, 434, 406, 516, 281, 312, 1075, 281, 980, 2649, 1296, 51132], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 199, "seek": 99152, "start": 1006.88, "end": 1012.0799999999999, "text": " these agents and real humans. If anyone else spends a lot of time on Twitter slash X,", "tokens": [51132, 613, 12554, 293, 957, 6255, 13, 759, 2878, 1646, 25620, 257, 688, 295, 565, 322, 5794, 17330, 1783, 11, 51392], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 200, "seek": 99152, "start": 1012.0799999999999, "end": 1015.92, "text": " you'll already have noticed there's a lot of accounts you stumble across that have a weird", "tokens": [51392, 291, 603, 1217, 362, 5694, 456, 311, 257, 688, 295, 9402, 291, 41302, 2108, 300, 362, 257, 3657, 51584], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 201, "seek": 99152, "start": 1015.92, "end": 1020.4, "text": " vibe to them, and you definitely realize this is just chat GPT hooked up to a Twitter account,", "tokens": [51584, 14606, 281, 552, 11, 293, 291, 2138, 4325, 341, 307, 445, 5081, 26039, 51, 20410, 493, 281, 257, 5794, 2696, 11, 51808], "temperature": 0.0, "avg_logprob": -0.08595432504250185, "compression_ratio": 1.756838905775076, "no_speech_prob": 0.000972776033449918}, {"id": 202, "seek": 102040, "start": 1020.4, "end": 1025.44, "text": " but otherwise is trying to look real, but like every tweet is very optimized and comes back in", "tokens": [50364, 457, 5911, 307, 1382, 281, 574, 957, 11, 457, 411, 633, 15258, 307, 588, 26941, 293, 1487, 646, 294, 50616], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 203, "seek": 102040, "start": 1025.44, "end": 1029.92, "text": " like a second. It's just replying to things, you know, three seconds later. So it's happening.", "tokens": [50616, 411, 257, 1150, 13, 467, 311, 445, 1085, 7310, 281, 721, 11, 291, 458, 11, 1045, 3949, 1780, 13, 407, 309, 311, 2737, 13, 50840], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 204, "seek": 102040, "start": 1031.12, "end": 1034.4, "text": " And sharing the web, I want to say with agents, I don't want to jump to saying this is like", "tokens": [50900, 400, 5414, 264, 3670, 11, 286, 528, 281, 584, 365, 12554, 11, 286, 500, 380, 528, 281, 3012, 281, 1566, 341, 307, 411, 51064], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 205, "seek": 102040, "start": 1034.4, "end": 1038.32, "text": " inherently bad. I think they could have lots of good use cases, right? We could have", "tokens": [51064, 27993, 1578, 13, 286, 519, 436, 727, 362, 3195, 295, 665, 764, 3331, 11, 558, 30, 492, 727, 362, 51260], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 206, "seek": 102040, "start": 1038.32, "end": 1043.12, "text": " automated moderators in communities. We could have search assistants, but I think it's mostly", "tokens": [51260, 18473, 10494, 3391, 294, 4456, 13, 492, 727, 362, 3164, 34949, 11, 457, 286, 519, 309, 311, 5240, 51500], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 207, "seek": 102040, "start": 1043.12, "end": 1046.96, "text": " that it's going to get complicated, and this is going to be a huge product and cultural problem", "tokens": [51500, 300, 309, 311, 516, 281, 483, 6179, 11, 293, 341, 307, 516, 281, 312, 257, 2603, 1674, 293, 6988, 1154, 51692], "temperature": 0.0, "avg_logprob": -0.09241649182173457, "compression_ratio": 1.7429467084639498, "no_speech_prob": 0.00022998455096967518}, {"id": 208, "seek": 104696, "start": 1046.96, "end": 1052.48, "text": " we're going to need to think about carefully and deal with. So we should get into why is this", "tokens": [50364, 321, 434, 516, 281, 643, 281, 519, 466, 7500, 293, 2028, 365, 13, 407, 321, 820, 483, 666, 983, 307, 341, 50640], "temperature": 0.0, "avg_logprob": -0.09979072917591442, "compression_ratio": 1.6763636363636363, "no_speech_prob": 0.0007280389545485377}, {"id": 209, "seek": 104696, "start": 1052.48, "end": 1057.8400000000001, "text": " a problem for the web, right? I'm only going to focus on how this will affect human relationships", "tokens": [50640, 257, 1154, 337, 264, 3670, 11, 558, 30, 286, 478, 787, 516, 281, 1879, 322, 577, 341, 486, 3345, 1952, 6159, 50908], "temperature": 0.0, "avg_logprob": -0.09979072917591442, "compression_ratio": 1.6763636363636363, "no_speech_prob": 0.0007280389545485377}, {"id": 210, "seek": 104696, "start": 1057.8400000000001, "end": 1063.3600000000001, "text": " and information quality on the web. Anything else, like how we might all end up unemployed or dead", "tokens": [50908, 293, 1589, 3125, 322, 264, 3670, 13, 11998, 1646, 11, 411, 577, 321, 1062, 439, 917, 493, 34411, 420, 3116, 51184], "temperature": 0.0, "avg_logprob": -0.09979072917591442, "compression_ratio": 1.6763636363636363, "no_speech_prob": 0.0007280389545485377}, {"id": 211, "seek": 104696, "start": 1063.3600000000001, "end": 1068.32, "text": " soon is like well beyond my pay grade, so I'm just limiting the space to just like how do we", "tokens": [51184, 2321, 307, 411, 731, 4399, 452, 1689, 7204, 11, 370, 286, 478, 445, 22083, 264, 1901, 281, 445, 411, 577, 360, 321, 51432], "temperature": 0.0, "avg_logprob": -0.09979072917591442, "compression_ratio": 1.6763636363636363, "no_speech_prob": 0.0007280389545485377}, {"id": 212, "seek": 104696, "start": 1068.88, "end": 1072.64, "text": " make meaningful human connections and find a good quality content on the web.", "tokens": [51460, 652, 10995, 1952, 9271, 293, 915, 257, 665, 3125, 2701, 322, 264, 3670, 13, 51648], "temperature": 0.0, "avg_logprob": -0.09979072917591442, "compression_ratio": 1.6763636363636363, "no_speech_prob": 0.0007280389545485377}, {"id": 213, "seek": 107264, "start": 1073.6000000000001, "end": 1079.44, "text": " Because, yeah, the cost of creating and publishing content just dropped to almost zero at this point,", "tokens": [50412, 1436, 11, 1338, 11, 264, 2063, 295, 4084, 293, 17832, 2701, 445, 8119, 281, 1920, 4018, 412, 341, 935, 11, 50704], "temperature": 0.0, "avg_logprob": -0.12718301906920315, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00038323362241499126}, {"id": 214, "seek": 107264, "start": 1080.0800000000002, "end": 1085.76, "text": " right? Like humans are quite expensive and slow at making content, right? We need time to research", "tokens": [50736, 558, 30, 1743, 6255, 366, 1596, 5124, 293, 2964, 412, 1455, 2701, 11, 558, 30, 492, 643, 565, 281, 2132, 51020], "temperature": 0.0, "avg_logprob": -0.12718301906920315, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00038323362241499126}, {"id": 215, "seek": 107264, "start": 1085.76, "end": 1090.3200000000002, "text": " and think, and we like clumsily string words together, and then we want to take breaks,", "tokens": [51020, 293, 519, 11, 293, 321, 411, 596, 8099, 953, 6798, 2283, 1214, 11, 293, 550, 321, 528, 281, 747, 9857, 11, 51248], "temperature": 0.0, "avg_logprob": -0.12718301906920315, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00038323362241499126}, {"id": 216, "seek": 107264, "start": 1090.3200000000002, "end": 1095.2, "text": " and we want to be able to nap and eat and sleep, and then we demand people pay us like", "tokens": [51248, 293, 321, 528, 281, 312, 1075, 281, 9296, 293, 1862, 293, 2817, 11, 293, 550, 321, 4733, 561, 1689, 505, 411, 51492], "temperature": 0.0, "avg_logprob": -0.12718301906920315, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00038323362241499126}, {"id": 217, "seek": 107264, "start": 1095.2, "end": 1100.88, "text": " extraordinary rates, right, to do this research. And generative models don't need time off,", "tokens": [51492, 10581, 6846, 11, 558, 11, 281, 360, 341, 2132, 13, 400, 1337, 1166, 5245, 500, 380, 643, 565, 766, 11, 51776], "temperature": 0.0, "avg_logprob": -0.12718301906920315, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00038323362241499126}, {"id": 218, "seek": 110088, "start": 1100.88, "end": 1104.24, "text": " and they don't get bored, and they cost like a couple fractions of a cent to write a few thousand", "tokens": [50364, 293, 436, 500, 380, 483, 13521, 11, 293, 436, 2063, 411, 257, 1916, 36058, 295, 257, 1489, 281, 2464, 257, 1326, 4714, 50532], "temperature": 0.0, "avg_logprob": -0.08815396034111411, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.00022839017037767917}, {"id": 219, "seek": 110088, "start": 1104.24, "end": 1110.48, "text": " words. So given the dynamics here, it's very likely that models are going to become the main", "tokens": [50532, 2283, 13, 407, 2212, 264, 15679, 510, 11, 309, 311, 588, 3700, 300, 5245, 366, 516, 281, 1813, 264, 2135, 50844], "temperature": 0.0, "avg_logprob": -0.08815396034111411, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.00022839017037767917}, {"id": 220, "seek": 110088, "start": 1110.48, "end": 1117.44, "text": " generators of content online. So I think we're about to drown in a sea of informational garbage,", "tokens": [50844, 38662, 295, 2701, 2950, 13, 407, 286, 519, 321, 434, 466, 281, 20337, 294, 257, 4158, 295, 49391, 14150, 11, 51192], "temperature": 0.0, "avg_logprob": -0.08815396034111411, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.00022839017037767917}, {"id": 221, "seek": 110088, "start": 1117.44, "end": 1122.3200000000002, "text": " right? I think we're just going to be absolutely swamped in masses of mediocre content. Like every", "tokens": [51192, 558, 30, 286, 519, 321, 434, 445, 516, 281, 312, 3122, 31724, 292, 294, 23935, 295, 45415, 2701, 13, 1743, 633, 51436], "temperature": 0.0, "avg_logprob": -0.08815396034111411, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.00022839017037767917}, {"id": 222, "seek": 110088, "start": 1122.3200000000002, "end": 1126.24, "text": " marketer and SEO strategist and optimizer bro is just going to have a field day here, you know,", "tokens": [51436, 2142, 260, 293, 22964, 5464, 468, 293, 5028, 6545, 2006, 307, 445, 516, 281, 362, 257, 2519, 786, 510, 11, 291, 458, 11, 51632], "temperature": 0.0, "avg_logprob": -0.08815396034111411, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.00022839017037767917}, {"id": 223, "seek": 112624, "start": 1126.24, "end": 1131.76, "text": " just filling the whole internet with all of their keyword stuff, optimized crap. And this explosion", "tokens": [50364, 445, 10623, 264, 1379, 4705, 365, 439, 295, 641, 20428, 1507, 11, 26941, 12426, 13, 400, 341, 15673, 50640], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 224, "seek": 112624, "start": 1131.76, "end": 1136.32, "text": " of noise is going to make it really difficult to find both good quality people, real people,", "tokens": [50640, 295, 5658, 307, 516, 281, 652, 309, 534, 2252, 281, 915, 1293, 665, 3125, 561, 11, 957, 561, 11, 50868], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 225, "seek": 112624, "start": 1136.32, "end": 1141.68, "text": " and good quality content, and hear any signal through the noise. And we can tell this is", "tokens": [50868, 293, 665, 3125, 2701, 11, 293, 1568, 604, 6358, 807, 264, 5658, 13, 400, 321, 393, 980, 341, 307, 51136], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 226, "seek": 112624, "start": 1141.68, "end": 1145.52, "text": " happening because scammers and scammers are currently quite lazy, and we're kind of in the", "tokens": [51136, 2737, 570, 795, 48414, 293, 795, 48414, 366, 4362, 1596, 14847, 11, 293, 321, 434, 733, 295, 294, 264, 51328], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 227, "seek": 112624, "start": 1145.52, "end": 1150.88, "text": " baby phases of this. So there's a phrase that you might have seen chat GPT reply with. It sometimes", "tokens": [51328, 3186, 18764, 295, 341, 13, 407, 456, 311, 257, 9535, 300, 291, 1062, 362, 1612, 5081, 26039, 51, 16972, 365, 13, 467, 2171, 51596], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 228, "seek": 112624, "start": 1150.88, "end": 1155.04, "text": " says, as an AI language model, I do not have political beliefs, or as an AI language model,", "tokens": [51596, 1619, 11, 382, 364, 7318, 2856, 2316, 11, 286, 360, 406, 362, 3905, 13585, 11, 420, 382, 364, 7318, 2856, 2316, 11, 51804], "temperature": 0.0, "avg_logprob": -0.09213863913692645, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0028222398832440376}, {"id": 229, "seek": 115504, "start": 1155.12, "end": 1159.6, "text": " I cannot answer that question. And this phrase, if you search and direct quotes for it around the", "tokens": [50368, 286, 2644, 1867, 300, 1168, 13, 400, 341, 9535, 11, 498, 291, 3164, 293, 2047, 19963, 337, 309, 926, 264, 50592], "temperature": 0.0, "avg_logprob": -0.12460926251533704, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.0014734627911821008}, {"id": 230, "seek": 115504, "start": 1159.6, "end": 1165.36, "text": " web, shows up everywhere, just like Amazon, Google, Yelp reviews, tweets, LinkedIn posts,", "tokens": [50592, 3670, 11, 3110, 493, 5315, 11, 445, 411, 6795, 11, 3329, 11, 398, 28591, 10229, 11, 25671, 11, 20657, 12300, 11, 50880], "temperature": 0.0, "avg_logprob": -0.12460926251533704, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.0014734627911821008}, {"id": 231, "seek": 115504, "start": 1165.36, "end": 1169.2, "text": " it's full of this phrase, because people can't be bothered to like control F and like delete the", "tokens": [50880, 309, 311, 1577, 295, 341, 9535, 11, 570, 561, 393, 380, 312, 22996, 281, 411, 1969, 479, 293, 411, 12097, 264, 51072], "temperature": 0.0, "avg_logprob": -0.12460926251533704, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.0014734627911821008}, {"id": 232, "seek": 115504, "start": 1169.2, "end": 1174.72, "text": " one phrase that gives them away. All right. So I did a quick search for this on LinkedIn, it got", "tokens": [51072, 472, 9535, 300, 2709, 552, 1314, 13, 1057, 558, 13, 407, 286, 630, 257, 1702, 3164, 337, 341, 322, 20657, 11, 309, 658, 51348], "temperature": 0.0, "avg_logprob": -0.12460926251533704, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.0014734627911821008}, {"id": 233, "seek": 115504, "start": 1174.72, "end": 1180.72, "text": " 16,000 hits, and they're like really boring attempts to like write engaging content, but they", "tokens": [51348, 3165, 11, 1360, 8664, 11, 293, 436, 434, 411, 534, 9989, 15257, 281, 411, 2464, 11268, 2701, 11, 457, 436, 51648], "temperature": 0.0, "avg_logprob": -0.12460926251533704, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.0014734627911821008}, {"id": 234, "seek": 118072, "start": 1180.72, "end": 1185.44, "text": " all begin with the phrase as an AI language model. Look in the first sentence. And these are real", "tokens": [50364, 439, 1841, 365, 264, 9535, 382, 364, 7318, 2856, 2316, 13, 2053, 294, 264, 700, 8174, 13, 400, 613, 366, 957, 50600], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 235, "seek": 118072, "start": 1185.44, "end": 1188.88, "text": " people too. I did look at their profiles. They genuinely have jobs, and they're trying to optimize", "tokens": [50600, 561, 886, 13, 286, 630, 574, 412, 641, 23693, 13, 814, 17839, 362, 4782, 11, 293, 436, 434, 1382, 281, 19719, 50772], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 236, "seek": 118072, "start": 1188.88, "end": 1195.68, "text": " their presence or something. But yeah, this is starting to happen. The motivation for doing", "tokens": [50772, 641, 6814, 420, 746, 13, 583, 1338, 11, 341, 307, 2891, 281, 1051, 13, 440, 12335, 337, 884, 51112], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 237, "seek": 118072, "start": 1195.68, "end": 1199.84, "text": " this rate isn't hard to understand. So let's like think of the hypothetical scenario. So this is", "tokens": [51112, 341, 3314, 1943, 380, 1152, 281, 1223, 13, 407, 718, 311, 411, 519, 295, 264, 33053, 9005, 13, 407, 341, 307, 51320], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 238, "seek": 118072, "start": 1199.84, "end": 1205.3600000000001, "text": " Nigel. He's written a book about why nepotism is great, right? And he wants to be a book fluencer.", "tokens": [51320, 39554, 338, 13, 634, 311, 3720, 257, 1446, 466, 983, 408, 17698, 1434, 307, 869, 11, 558, 30, 400, 415, 2738, 281, 312, 257, 1446, 5029, 16542, 13, 51596], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 239, "seek": 118072, "start": 1205.3600000000001, "end": 1209.28, "text": " He's like, it's his first book, he's self-published on Amazon, he wants to like, you know, become a", "tokens": [51596, 634, 311, 411, 11, 309, 311, 702, 700, 1446, 11, 415, 311, 2698, 12, 79, 836, 4173, 322, 6795, 11, 415, 2738, 281, 411, 11, 291, 458, 11, 1813, 257, 51792], "temperature": 0.0, "avg_logprob": -0.12343078812742544, "compression_ratio": 1.6543909348441925, "no_speech_prob": 0.0021714246831834316}, {"id": 240, "seek": 120928, "start": 1209.28, "end": 1214.08, "text": " big book guy. So he spends up an agent, right? Not unlike an actual publishing agent. He might have", "tokens": [50364, 955, 1446, 2146, 13, 407, 415, 25620, 493, 364, 9461, 11, 558, 30, 1726, 8343, 364, 3539, 17832, 9461, 13, 634, 1062, 362, 50604], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 241, "seek": 120928, "start": 1214.08, "end": 1220.3999999999999, "text": " hired in the past. And he says, hey, like, help me promote my book, you know? And so the agent", "tokens": [50604, 13144, 294, 264, 1791, 13, 400, 415, 1619, 11, 4177, 11, 411, 11, 854, 385, 9773, 452, 1446, 11, 291, 458, 30, 400, 370, 264, 9461, 50920], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 242, "seek": 120928, "start": 1220.3999999999999, "end": 1225.52, "text": " thinks for a while, and it goes off, and it strategizes, and it generates a steady stream", "tokens": [50920, 7309, 337, 257, 1339, 11, 293, 309, 1709, 766, 11, 293, 309, 5464, 5660, 11, 293, 309, 23815, 257, 13211, 4309, 51176], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 243, "seek": 120928, "start": 1225.52, "end": 1228.8799999999999, "text": " of tweets, right, based about on the content of the book, like real insights from the book,", "tokens": [51176, 295, 25671, 11, 558, 11, 2361, 466, 322, 264, 2701, 295, 264, 1446, 11, 411, 957, 14310, 490, 264, 1446, 11, 51344], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 244, "seek": 120928, "start": 1228.8799999999999, "end": 1232.0, "text": " and it starts tweeting those out from Nigel's account, and he's given it access, you know?", "tokens": [51344, 293, 309, 3719, 40090, 729, 484, 490, 39554, 338, 311, 2696, 11, 293, 415, 311, 2212, 309, 2105, 11, 291, 458, 30, 51500], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 245, "seek": 120928, "start": 1233.12, "end": 1236.56, "text": " And it goes and it does the same thing for LinkedIn and Facebook, you know, pretty easy.", "tokens": [51556, 400, 309, 1709, 293, 309, 775, 264, 912, 551, 337, 20657, 293, 4384, 11, 291, 458, 11, 1238, 1858, 13, 51728], "temperature": 0.0, "avg_logprob": -0.13122065537640837, "compression_ratio": 1.7993527508090614, "no_speech_prob": 0.00039221812039613724}, {"id": 246, "seek": 123656, "start": 1237.52, "end": 1241.6799999999998, "text": " And then it writes and schedules a newsletter to go out over the course of six months so that", "tokens": [50412, 400, 550, 309, 13657, 293, 28078, 257, 26469, 281, 352, 484, 670, 264, 1164, 295, 2309, 2493, 370, 300, 50620], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 247, "seek": 123656, "start": 1241.6799999999998, "end": 1245.9199999999998, "text": " his followers will always kind of get updates on new things he's researching. It sets up a", "tokens": [50620, 702, 13071, 486, 1009, 733, 295, 483, 9205, 322, 777, 721, 415, 311, 24176, 13, 467, 6352, 493, 257, 50832], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 248, "seek": 123656, "start": 1245.9199999999998, "end": 1250.48, "text": " medium account, it reposts those as articles, right? Makes a set of addictive TikTok videos", "tokens": [50832, 6399, 2696, 11, 309, 1085, 555, 82, 729, 382, 11290, 11, 558, 30, 25245, 257, 992, 295, 36486, 20211, 2145, 51060], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 249, "seek": 123656, "start": 1250.48, "end": 1255.12, "text": " based on that content, generates a bunch of podcast episodes, use Nigel's voice. We can", "tokens": [51060, 2361, 322, 300, 2701, 11, 23815, 257, 3840, 295, 7367, 9313, 11, 764, 39554, 338, 311, 3177, 13, 492, 393, 51292], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 250, "seek": 123656, "start": 1255.12, "end": 1260.48, "text": " totally do that now. It's pretty easy. And then it finds a bunch of other people who like are", "tokens": [51292, 3879, 360, 300, 586, 13, 467, 311, 1238, 1858, 13, 400, 550, 309, 10704, 257, 3840, 295, 661, 561, 567, 411, 366, 51560], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 251, "seek": 123656, "start": 1260.48, "end": 1264.72, "text": " talking about nepotism and starts replying to them on LinkedIn and Twitter and making friends,", "tokens": [51560, 1417, 466, 408, 17698, 1434, 293, 3719, 1085, 7310, 281, 552, 322, 20657, 293, 5794, 293, 1455, 1855, 11, 51772], "temperature": 0.0, "avg_logprob": -0.09877447974412962, "compression_ratio": 1.6264705882352941, "no_speech_prob": 0.0037785330787301064}, {"id": 252, "seek": 126472, "start": 1264.72, "end": 1268.32, "text": " and maybe they're actually agents interacting with it, and like, it's a whole bunch of just", "tokens": [50364, 293, 1310, 436, 434, 767, 12554, 18017, 365, 309, 11, 293, 411, 11, 309, 311, 257, 1379, 3840, 295, 445, 50544], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 253, "seek": 126472, "start": 1269.44, "end": 1274.24, "text": " agents interacting with agents. And none of this is different to what Nigel could do on his own.", "tokens": [50600, 12554, 18017, 365, 12554, 13, 400, 6022, 295, 341, 307, 819, 281, 437, 39554, 338, 727, 360, 322, 702, 1065, 13, 50840], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 254, "seek": 126472, "start": 1274.24, "end": 1280.24, "text": " So we don't know that content moderation or spam filters are actually going to pick this", "tokens": [50840, 407, 321, 500, 380, 458, 300, 2701, 49471, 420, 24028, 15995, 366, 767, 516, 281, 1888, 341, 51140], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 255, "seek": 126472, "start": 1280.24, "end": 1284.96, "text": " stuff up, because maybe it's tweeting it slow enough that a human could have done it,", "tokens": [51140, 1507, 493, 11, 570, 1310, 309, 311, 40090, 309, 2964, 1547, 300, 257, 1952, 727, 362, 1096, 309, 11, 51376], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 256, "seek": 126472, "start": 1284.96, "end": 1288.08, "text": " and it really is in Nigel's voice. It's used his writing to write this content.", "tokens": [51376, 293, 309, 534, 307, 294, 39554, 338, 311, 3177, 13, 467, 311, 1143, 702, 3579, 281, 2464, 341, 2701, 13, 51532], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 257, "seek": 126472, "start": 1288.64, "end": 1291.84, "text": " We don't necessarily have automated ways to filter any of this out.", "tokens": [51560, 492, 500, 380, 4725, 362, 18473, 2098, 281, 6608, 604, 295, 341, 484, 13, 51720], "temperature": 0.0, "avg_logprob": -0.09595677947998046, "compression_ratio": 1.7867132867132867, "no_speech_prob": 0.0005713605787605047}, {"id": 258, "seek": 129184, "start": 1292.6399999999999, "end": 1297.84, "text": " And the thing is, without an agent, 99% of Nigel-type people wouldn't have gone to all", "tokens": [50404, 400, 264, 551, 307, 11, 1553, 364, 9461, 11, 11803, 4, 295, 39554, 338, 12, 20467, 561, 2759, 380, 362, 2780, 281, 439, 50664], "temperature": 0.0, "avg_logprob": -0.1133220641593623, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.0008685183129273355}, {"id": 259, "seek": 129184, "start": 1297.84, "end": 1302.1599999999999, "text": " this effort. They don't have the time and energy to have made all this content. But with the agent,", "tokens": [50664, 341, 4630, 13, 814, 500, 380, 362, 264, 565, 293, 2281, 281, 362, 1027, 439, 341, 2701, 13, 583, 365, 264, 9461, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1133220641593623, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.0008685183129273355}, {"id": 260, "seek": 129184, "start": 1302.72, "end": 1309.04, "text": " suddenly, we have people like Nigel, but times 99 of them, able to create this amount of content", "tokens": [50908, 5800, 11, 321, 362, 561, 411, 39554, 338, 11, 457, 1413, 11803, 295, 552, 11, 1075, 281, 1884, 341, 2372, 295, 2701, 51224], "temperature": 0.0, "avg_logprob": -0.1133220641593623, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.0008685183129273355}, {"id": 261, "seek": 129184, "start": 1309.04, "end": 1313.12, "text": " all the time. And this is how we kind of get the flood of just tons of content more than we can", "tokens": [51224, 439, 264, 565, 13, 400, 341, 307, 577, 321, 733, 295, 483, 264, 10481, 295, 445, 9131, 295, 2701, 544, 813, 321, 393, 51428], "temperature": 0.0, "avg_logprob": -0.1133220641593623, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.0008685183129273355}, {"id": 262, "seek": 129184, "start": 1313.12, "end": 1319.12, "text": " really cope with. So the scale and the quality of the content is actually what's different here.", "tokens": [51428, 534, 22598, 365, 13, 407, 264, 4373, 293, 264, 3125, 295, 264, 2701, 307, 767, 437, 311, 819, 510, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1133220641593623, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.0008685183129273355}, {"id": 263, "seek": 131912, "start": 1319.36, "end": 1323.12, "text": " Strangely enough, it might have written better stuff than Nigel ever would. We might have way", "tokens": [50376, 8251, 656, 736, 1547, 11, 309, 1062, 362, 3720, 1101, 1507, 813, 39554, 338, 1562, 576, 13, 492, 1062, 362, 636, 50564], "temperature": 0.0, "avg_logprob": -0.1251559440906231, "compression_ratio": 1.683453237410072, "no_speech_prob": 0.0016345980111509562}, {"id": 264, "seek": 131912, "start": 1323.12, "end": 1328.2399999999998, "text": " better quality content about nepotism all over the internet. But you can imagine how this would", "tokens": [50564, 1101, 3125, 2701, 466, 408, 17698, 1434, 439, 670, 264, 4705, 13, 583, 291, 393, 3811, 577, 341, 576, 50820], "temperature": 0.0, "avg_logprob": -0.1251559440906231, "compression_ratio": 1.683453237410072, "no_speech_prob": 0.0016345980111509562}, {"id": 265, "seek": 131912, "start": 1328.2399999999998, "end": 1334.08, "text": " play out at another 100x scale, right, with political lobbying groups who have very vested", "tokens": [50820, 862, 484, 412, 1071, 2319, 87, 4373, 11, 558, 11, 365, 3905, 47142, 3935, 567, 362, 588, 49317, 51112], "temperature": 0.0, "avg_logprob": -0.1251559440906231, "compression_ratio": 1.683453237410072, "no_speech_prob": 0.0016345980111509562}, {"id": 266, "seek": 131912, "start": 1334.08, "end": 1339.84, "text": " interests in certain ideas or beliefs or truths getting out into the world. Specific agendas,", "tokens": [51112, 8847, 294, 1629, 3487, 420, 13585, 420, 30079, 1242, 484, 666, 264, 1002, 13, 20484, 1089, 623, 45252, 11, 51400], "temperature": 0.0, "avg_logprob": -0.1251559440906231, "compression_ratio": 1.683453237410072, "no_speech_prob": 0.0016345980111509562}, {"id": 267, "seek": 131912, "start": 1340.56, "end": 1344.6399999999999, "text": " large companies that want you to believe certain things about their product or certain things", "tokens": [51436, 2416, 3431, 300, 528, 291, 281, 1697, 1629, 721, 466, 641, 1674, 420, 1629, 721, 51640], "temperature": 0.0, "avg_logprob": -0.1251559440906231, "compression_ratio": 1.683453237410072, "no_speech_prob": 0.0016345980111509562}, {"id": 268, "seek": 134464, "start": 1344.64, "end": 1349.2800000000002, "text": " about scientific claims. They all have access to these assistants and agents, too.", "tokens": [50364, 466, 8134, 9441, 13, 814, 439, 362, 2105, 281, 613, 34949, 293, 12554, 11, 886, 13, 50596], "temperature": 0.0, "avg_logprob": -0.12286089942568824, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0005867101717740297}, {"id": 269, "seek": 134464, "start": 1350.72, "end": 1353.6000000000001, "text": " So I do have some good news. Like, this has all been a bit dark, a bit of a downer.", "tokens": [50668, 407, 286, 360, 362, 512, 665, 2583, 13, 1743, 11, 341, 575, 439, 668, 257, 857, 2877, 11, 257, 857, 295, 257, 760, 260, 13, 50812], "temperature": 0.0, "avg_logprob": -0.12286089942568824, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0005867101717740297}, {"id": 270, "seek": 134464, "start": 1354.5600000000002, "end": 1359.2, "text": " The good news is that this might not be a problem. Maybe this is all just fine, right?", "tokens": [50860, 440, 665, 2583, 307, 300, 341, 1062, 406, 312, 257, 1154, 13, 2704, 341, 307, 439, 445, 2489, 11, 558, 30, 51092], "temperature": 0.0, "avg_logprob": -0.12286089942568824, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0005867101717740297}, {"id": 271, "seek": 134464, "start": 1359.92, "end": 1363.8400000000001, "text": " This is only a problem if we want to use the web for very particular purposes,", "tokens": [51128, 639, 307, 787, 257, 1154, 498, 321, 528, 281, 764, 264, 3670, 337, 588, 1729, 9932, 11, 51324], "temperature": 0.0, "avg_logprob": -0.12286089942568824, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0005867101717740297}, {"id": 272, "seek": 134464, "start": 1364.64, "end": 1371.1200000000001, "text": " such as facilitating genuine human relationships or pursuing collective sense-making and knowledge", "tokens": [51364, 1270, 382, 47558, 16699, 1952, 6159, 420, 20222, 12590, 2020, 12, 12402, 293, 3601, 51688], "temperature": 0.0, "avg_logprob": -0.12286089942568824, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0005867101717740297}, {"id": 273, "seek": 137112, "start": 1371.12, "end": 1378.1599999999999, "text": " building or grounding our knowledge of the world in reality. So we don't care about any of these", "tokens": [50364, 2390, 420, 46727, 527, 3601, 295, 264, 1002, 294, 4103, 13, 407, 321, 500, 380, 1127, 466, 604, 295, 613, 50716], "temperature": 0.0, "avg_logprob": -0.100064784024669, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.001619416056200862}, {"id": 274, "seek": 137112, "start": 1378.1599999999999, "end": 1382.56, "text": " things. This is all fine. We're going to have amazing content on TikTok. We're going to be", "tokens": [50716, 721, 13, 639, 307, 439, 2489, 13, 492, 434, 516, 281, 362, 2243, 2701, 322, 20211, 13, 492, 434, 516, 281, 312, 50936], "temperature": 0.0, "avg_logprob": -0.100064784024669, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.001619416056200862}, {"id": 275, "seek": 137112, "start": 1382.56, "end": 1388.7199999999998, "text": " very entertained. The thing is, I'm quite keen on a lot of these outcomes. I write on the web a", "tokens": [50936, 588, 44783, 13, 440, 551, 307, 11, 286, 478, 1596, 20297, 322, 257, 688, 295, 613, 10070, 13, 286, 2464, 322, 264, 3670, 257, 51244], "temperature": 0.0, "avg_logprob": -0.100064784024669, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.001619416056200862}, {"id": 276, "seek": 137112, "start": 1388.7199999999998, "end": 1393.36, "text": " lot. I've had overwhelmingly positive experiences writing on the web and meeting people for doing", "tokens": [51244, 688, 13, 286, 600, 632, 42926, 3353, 5235, 3579, 322, 264, 3670, 293, 3440, 561, 337, 884, 51476], "temperature": 0.0, "avg_logprob": -0.100064784024669, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.001619416056200862}, {"id": 277, "seek": 137112, "start": 1393.36, "end": 1398.8, "text": " that. I have this whole thing called digital gardening I bang on about, about making everyone", "tokens": [51476, 300, 13, 286, 362, 341, 1379, 551, 1219, 4562, 31799, 286, 8550, 322, 466, 11, 466, 1455, 1518, 51748], "temperature": 0.0, "avg_logprob": -0.100064784024669, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.001619416056200862}, {"id": 278, "seek": 139880, "start": 1398.8, "end": 1403.44, "text": " publish their unfinished notes to the web and improve them over time and use that as a way", "tokens": [50364, 11374, 641, 41037, 5570, 281, 264, 3670, 293, 3470, 552, 670, 565, 293, 764, 300, 382, 257, 636, 50596], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 279, "seek": 139880, "start": 1403.44, "end": 1408.8799999999999, "text": " to meet people interested in what you're interested in. But, yeah, the goal of that stuff is to make", "tokens": [50596, 281, 1677, 561, 3102, 294, 437, 291, 434, 3102, 294, 13, 583, 11, 1338, 11, 264, 3387, 295, 300, 1507, 307, 281, 652, 50868], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 280, "seek": 139880, "start": 1409.68, "end": 1413.12, "text": " the web a space where that's possible for collective understanding and knowledge building.", "tokens": [50908, 264, 3670, 257, 1901, 689, 300, 311, 1944, 337, 12590, 3701, 293, 3601, 2390, 13, 51080], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 281, "seek": 139880, "start": 1413.76, "end": 1417.52, "text": " And I'm really worried that generative agents like meaningfully threaten this in the very near", "tokens": [51112, 400, 286, 478, 534, 5804, 300, 1337, 1166, 12554, 411, 3620, 2277, 29864, 341, 294, 264, 588, 2651, 51300], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 282, "seek": 139880, "start": 1417.52, "end": 1421.12, "text": " term, like the six to 12 month kind of time range. I can't even think beyond that.", "tokens": [51300, 1433, 11, 411, 264, 2309, 281, 2272, 1618, 733, 295, 565, 3613, 13, 286, 393, 380, 754, 519, 4399, 300, 13, 51480], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 283, "seek": 139880, "start": 1423.12, "end": 1426.56, "text": " So when I talk to people about my worries, I talk to a lot of people in the AI safety and", "tokens": [51580, 407, 562, 286, 751, 281, 561, 466, 452, 16340, 11, 286, 751, 281, 257, 688, 295, 561, 294, 264, 7318, 4514, 293, 51752], "temperature": 0.0, "avg_logprob": -0.12722194467792075, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0004291955556254834}, {"id": 284, "seek": 142656, "start": 1426.6399999999999, "end": 1431.6799999999998, "text": " research world. They kind of go, why does it matter? My AI agent is going to make much better", "tokens": [50368, 2132, 1002, 13, 814, 733, 295, 352, 11, 983, 775, 309, 1871, 30, 1222, 7318, 9461, 307, 516, 281, 652, 709, 1101, 50620], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 285, "seek": 142656, "start": 1431.6799999999998, "end": 1435.84, "text": " content than you ever would. Why do you care that an agent made it and not a human? I'm like,", "tokens": [50620, 2701, 813, 291, 1562, 576, 13, 1545, 360, 291, 1127, 300, 364, 9461, 1027, 309, 293, 406, 257, 1952, 30, 286, 478, 411, 11, 50828], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 286, "seek": 142656, "start": 1435.84, "end": 1439.76, "text": " okay, let's engage with that question properly. I'm sympathetic to that point.", "tokens": [50828, 1392, 11, 718, 311, 4683, 365, 300, 1168, 6108, 13, 286, 478, 36032, 281, 300, 935, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 287, "seek": 142656, "start": 1441.6799999999998, "end": 1444.1599999999999, "text": " So here's the reasons that generated content is a little bit different, right?", "tokens": [51120, 407, 510, 311, 264, 4112, 300, 10833, 2701, 307, 257, 707, 857, 819, 11, 558, 30, 51244], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 288, "seek": 142656, "start": 1444.8, "end": 1449.36, "text": " The first is its connection to reality. The second is the social context they live within.", "tokens": [51276, 440, 700, 307, 1080, 4984, 281, 4103, 13, 440, 1150, 307, 264, 2093, 4319, 436, 1621, 1951, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 289, "seek": 142656, "start": 1450.08, "end": 1453.84, "text": " And the third is its potential for human relationships. And I'm going to go into", "tokens": [51540, 400, 264, 2636, 307, 1080, 3995, 337, 1952, 6159, 13, 400, 286, 478, 516, 281, 352, 666, 51728], "temperature": 0.0, "avg_logprob": -0.1377052366733551, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.0005493838689289987}, {"id": 290, "seek": 145384, "start": 1453.84, "end": 1459.6799999999998, "text": " these in detail. So first, generated content, you probably have heard of this, is different", "tokens": [50364, 613, 294, 2607, 13, 407, 700, 11, 10833, 2701, 11, 291, 1391, 362, 2198, 295, 341, 11, 307, 819, 50656], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 291, "seek": 145384, "start": 1459.6799999999998, "end": 1464.32, "text": " because it has a different relationship to reality than we do, right? We are embodied humans,", "tokens": [50656, 570, 309, 575, 257, 819, 2480, 281, 4103, 813, 321, 360, 11, 558, 30, 492, 366, 42046, 6255, 11, 50888], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 292, "seek": 145384, "start": 1464.32, "end": 1468.48, "text": " right? And we are sharing a physical reality. And we have all this rich embodied information,", "tokens": [50888, 558, 30, 400, 321, 366, 5414, 257, 4001, 4103, 13, 400, 321, 362, 439, 341, 4593, 42046, 1589, 11, 51096], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 293, "seek": 145384, "start": 1468.48, "end": 1471.76, "text": " like we all understand we're in this kind of beautiful theater and we're in Brighton and we", "tokens": [51096, 411, 321, 439, 1223, 321, 434, 294, 341, 733, 295, 2238, 10612, 293, 321, 434, 294, 24271, 266, 293, 321, 51260], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 294, "seek": 145384, "start": 1471.76, "end": 1477.6799999999998, "text": " have a lot of physical embodied context about what we know about each other. And often what we're", "tokens": [51260, 362, 257, 688, 295, 4001, 42046, 4319, 466, 437, 321, 458, 466, 1184, 661, 13, 400, 2049, 437, 321, 434, 51556], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 295, "seek": 145384, "start": 1477.6799999999998, "end": 1481.1999999999998, "text": " doing on the web is we're reading other people's accounts of this reality and we compare it against", "tokens": [51556, 884, 322, 264, 3670, 307, 321, 434, 3760, 661, 561, 311, 9402, 295, 341, 4103, 293, 321, 6794, 309, 1970, 51732], "temperature": 0.0, "avg_logprob": -0.0923895945075814, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0009896955452859402}, {"id": 296, "seek": 148120, "start": 1481.2, "end": 1485.2, "text": " our own and we're like, do I agree with that? Is that really true? This is like the cycle of all", "tokens": [50364, 527, 1065, 293, 321, 434, 411, 11, 360, 286, 3986, 365, 300, 30, 1119, 300, 534, 2074, 30, 639, 307, 411, 264, 6586, 295, 439, 50564], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 297, "seek": 148120, "start": 1485.2, "end": 1489.6000000000001, "text": " of art and science and literature, you know, reading and comparing and writing your own version of", "tokens": [50564, 295, 1523, 293, 3497, 293, 10394, 11, 291, 458, 11, 3760, 293, 15763, 293, 3579, 428, 1065, 3037, 295, 50784], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 298, "seek": 148120, "start": 1489.6000000000001, "end": 1496.16, "text": " things. And what we've done now is we've fed that huge trove of information into a neural network", "tokens": [50784, 721, 13, 400, 437, 321, 600, 1096, 586, 307, 321, 600, 4636, 300, 2603, 4495, 303, 295, 1589, 666, 257, 18161, 3209, 51112], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 299, "seek": 148120, "start": 1496.16, "end": 1500.88, "text": " or a large language model. And it's created a sort of representation of that text, right? It's", "tokens": [51112, 420, 257, 2416, 2856, 2316, 13, 400, 309, 311, 2942, 257, 1333, 295, 10290, 295, 300, 2487, 11, 558, 30, 467, 311, 51348], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 300, "seek": 148120, "start": 1500.88, "end": 1504.56, "text": " created a model of the things that we've already known about the world and have published to the", "tokens": [51348, 2942, 257, 2316, 295, 264, 721, 300, 321, 600, 1217, 2570, 466, 264, 1002, 293, 362, 6572, 281, 264, 51532], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 301, "seek": 148120, "start": 1504.56, "end": 1509.3600000000001, "text": " web. And the thing is that model can now generate text that's predictably similar to what it was", "tokens": [51532, 3670, 13, 400, 264, 551, 307, 300, 2316, 393, 586, 8460, 2487, 300, 311, 6069, 1188, 2531, 281, 437, 309, 390, 51772], "temperature": 0.0, "avg_logprob": -0.09975991450564962, "compression_ratio": 1.81875, "no_speech_prob": 0.000660235935356468}, {"id": 302, "seek": 150936, "start": 1509.36, "end": 1515.04, "text": " before, but it's totally unhinged from the physical reality that it once came from, right? It has", "tokens": [50364, 949, 11, 457, 309, 311, 3879, 517, 571, 292, 490, 264, 4001, 4103, 300, 309, 1564, 1361, 490, 11, 558, 30, 467, 575, 50648], "temperature": 0.0, "avg_logprob": -0.1223977558196537, "compression_ratio": 1.7269503546099292, "no_speech_prob": 0.003411108162254095}, {"id": 303, "seek": 150936, "start": 1515.04, "end": 1519.4399999999998, "text": " some big connection. It did come from there. There's like a chain here, but it fully like cannot", "tokens": [50648, 512, 955, 4984, 13, 467, 630, 808, 490, 456, 13, 821, 311, 411, 257, 5021, 510, 11, 457, 309, 4498, 411, 2644, 50868], "temperature": 0.0, "avg_logprob": -0.1223977558196537, "compression_ratio": 1.7269503546099292, "no_speech_prob": 0.003411108162254095}, {"id": 304, "seek": 150936, "start": 1519.4399999999998, "end": 1524.3999999999999, "text": " access that reality, right? Even if we put in robots, right, with like arms and eyes and ears,", "tokens": [50868, 2105, 300, 4103, 11, 558, 30, 2754, 498, 321, 829, 294, 14733, 11, 558, 11, 365, 411, 5812, 293, 2575, 293, 8798, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1223977558196537, "compression_ratio": 1.7269503546099292, "no_speech_prob": 0.003411108162254095}, {"id": 305, "seek": 150936, "start": 1524.3999999999999, "end": 1529.6799999999998, "text": " it can't sense the world the way we sense the world until we make like a fully synthetic like", "tokens": [51116, 309, 393, 380, 2020, 264, 1002, 264, 636, 321, 2020, 264, 1002, 1826, 321, 652, 411, 257, 4498, 23420, 411, 51380], "temperature": 0.0, "avg_logprob": -0.1223977558196537, "compression_ratio": 1.7269503546099292, "no_speech_prob": 0.003411108162254095}, {"id": 306, "seek": 150936, "start": 1529.6799999999998, "end": 1533.76, "text": " mimicry human that like is hooked up to a language model. But I think like 10 years away, I don't know,", "tokens": [51380, 31075, 627, 1952, 300, 411, 307, 20410, 493, 281, 257, 2856, 2316, 13, 583, 286, 519, 411, 1266, 924, 1314, 11, 286, 500, 380, 458, 11, 51584], "temperature": 0.0, "avg_logprob": -0.1223977558196537, "compression_ratio": 1.7269503546099292, "no_speech_prob": 0.003411108162254095}, {"id": 307, "seek": 153376, "start": 1533.76, "end": 1538.24, "text": " I think we have some time. Right, it can't validate its claims. It's the big thing.", "tokens": [50364, 286, 519, 321, 362, 512, 565, 13, 1779, 11, 309, 393, 380, 29562, 1080, 9441, 13, 467, 311, 264, 955, 551, 13, 50588], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 308, "seek": 153376, "start": 1540.0, "end": 1543.44, "text": " We politely call this hallucination, right? This is when language models say things that aren't", "tokens": [50676, 492, 1180, 1959, 818, 341, 35212, 2486, 11, 558, 30, 639, 307, 562, 2856, 5245, 584, 721, 300, 3212, 380, 50848], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 309, "seek": 153376, "start": 1543.44, "end": 1547.92, "text": " true about the world. We say it's hallucinating, right? Like it's some side kind of very smart", "tokens": [50848, 2074, 466, 264, 1002, 13, 492, 584, 309, 311, 35212, 8205, 11, 558, 30, 1743, 309, 311, 512, 1252, 733, 295, 588, 4069, 51072], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 310, "seek": 153376, "start": 1547.92, "end": 1551.76, "text": " person on some like mild drugs who's confused about like who they are or where they are,", "tokens": [51072, 954, 322, 512, 411, 15154, 7766, 567, 311, 9019, 466, 411, 567, 436, 366, 420, 689, 436, 366, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 311, "seek": 153376, "start": 1551.76, "end": 1555.36, "text": " but they're saying very intelligent things. You're sort of holding them lightly, you know?", "tokens": [51264, 457, 436, 434, 1566, 588, 13232, 721, 13, 509, 434, 1333, 295, 5061, 552, 16695, 11, 291, 458, 30, 51444], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 312, "seek": 153376, "start": 1557.2, "end": 1561.12, "text": " Language models are also different because they have a very different social context, right?", "tokens": [51536, 24445, 5245, 366, 611, 819, 570, 436, 362, 257, 588, 819, 2093, 4319, 11, 558, 30, 51732], "temperature": 0.0, "avg_logprob": -0.11746274618277873, "compression_ratio": 1.7588424437299035, "no_speech_prob": 0.0011636365670710802}, {"id": 313, "seek": 156112, "start": 1561.12, "end": 1565.36, "text": " They have a very strange relationship to our social world. So hopefully you know this, but", "tokens": [50364, 814, 362, 257, 588, 5861, 2480, 281, 527, 2093, 1002, 13, 407, 4696, 291, 458, 341, 11, 457, 50576], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 314, "seek": 156112, "start": 1565.36, "end": 1570.3999999999999, "text": " everything you and I say is situated in a social context, right? We understand what we share in", "tokens": [50576, 1203, 291, 293, 286, 584, 307, 30143, 294, 257, 2093, 4319, 11, 558, 30, 492, 1223, 437, 321, 2073, 294, 50828], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 315, "seek": 156112, "start": 1570.3999999999999, "end": 1573.9199999999998, "text": " common. And if you met someone who spoke a different language from a different culture,", "tokens": [50828, 2689, 13, 400, 498, 291, 1131, 1580, 567, 7179, 257, 819, 2856, 490, 257, 819, 3713, 11, 51004], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 316, "seek": 156112, "start": 1573.9199999999998, "end": 1577.6799999999998, "text": " you would not assume they thought the same things about the world that you would if you met someone", "tokens": [51004, 291, 576, 406, 6552, 436, 1194, 264, 912, 721, 466, 264, 1002, 300, 291, 576, 498, 291, 1131, 1580, 51192], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 317, "seek": 156112, "start": 1577.6799999999998, "end": 1582.8799999999999, "text": " from your own neighborhood, right? If one of us met someone from like the Kenzie in England,", "tokens": [51192, 490, 428, 1065, 7630, 11, 558, 30, 759, 472, 295, 505, 1131, 1580, 490, 411, 264, 8273, 3283, 294, 8196, 11, 51452], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 318, "seek": 156112, "start": 1582.8799999999999, "end": 1587.36, "text": " we would have very different understandings of like hygiene and science and like how the world", "tokens": [51452, 321, 576, 362, 588, 819, 1223, 1109, 295, 411, 29541, 293, 3497, 293, 411, 577, 264, 1002, 51676], "temperature": 0.0, "avg_logprob": -0.08021249468364412, "compression_ratio": 1.8187702265372168, "no_speech_prob": 0.00039653340354561806}, {"id": 319, "seek": 158736, "start": 1587.36, "end": 1590.8, "text": " works. We would know some things in common. We technically speak the same language,", "tokens": [50364, 1985, 13, 492, 576, 458, 512, 721, 294, 2689, 13, 492, 12120, 1710, 264, 912, 2856, 11, 50536], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 320, "seek": 158736, "start": 1590.8, "end": 1594.24, "text": " but we would know that we didn't have a shared social context in the same way.", "tokens": [50536, 457, 321, 576, 458, 300, 321, 994, 380, 362, 257, 5507, 2093, 4319, 294, 264, 912, 636, 13, 50708], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 321, "seek": 158736, "start": 1596.08, "end": 1601.28, "text": " But a language model is not a person and it does not have a fixed reality, right? They know nothing", "tokens": [50800, 583, 257, 2856, 2316, 307, 406, 257, 954, 293, 309, 775, 406, 362, 257, 6806, 4103, 11, 558, 30, 814, 458, 1825, 51060], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 322, "seek": 158736, "start": 1601.28, "end": 1605.76, "text": " about the cultural context of who they're talking to and they take on different characters depending", "tokens": [51060, 466, 264, 6988, 4319, 295, 567, 436, 434, 1417, 281, 293, 436, 747, 322, 819, 4342, 5413, 51284], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 323, "seek": 158736, "start": 1605.76, "end": 1610.32, "text": " on what you tell them to do. You can say, you know, pretend to be a professor, pretend to be an", "tokens": [51284, 322, 437, 291, 980, 552, 281, 360, 13, 509, 393, 584, 11, 291, 458, 11, 11865, 281, 312, 257, 8304, 11, 11865, 281, 312, 364, 51512], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 324, "seek": 158736, "start": 1610.32, "end": 1614.8799999999999, "text": " athlete, pretend to be a young child and it will take on that character. So it doesn't even have", "tokens": [51512, 18002, 11, 11865, 281, 312, 257, 2037, 1440, 293, 309, 486, 747, 322, 300, 2517, 13, 407, 309, 1177, 380, 754, 362, 51740], "temperature": 0.0, "avg_logprob": -0.07980240009449147, "compression_ratio": 1.8229508196721311, "no_speech_prob": 0.0006079868180677295}, {"id": 325, "seek": 161488, "start": 1614.88, "end": 1621.0400000000002, "text": " a fixed place it's talking to you from in the way that a human does. But they do represent a very", "tokens": [50364, 257, 6806, 1081, 309, 311, 1417, 281, 291, 490, 294, 264, 636, 300, 257, 1952, 775, 13, 583, 436, 360, 2906, 257, 588, 50672], "temperature": 0.0, "avg_logprob": -0.11627400198648143, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.0011064315913245082}, {"id": 326, "seek": 161488, "start": 1621.0400000000002, "end": 1626.88, "text": " particular way of seeing the world because we trained them primarily on text on the web that", "tokens": [50672, 1729, 636, 295, 2577, 264, 1002, 570, 321, 8895, 552, 10029, 322, 2487, 322, 264, 3670, 300, 50964], "temperature": 0.0, "avg_logprob": -0.11627400198648143, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.0011064315913245082}, {"id": 327, "seek": 161488, "start": 1626.88, "end": 1633.5200000000002, "text": " was generated by a majority English-speaking, like 95% of the training data is English-speaking,", "tokens": [50964, 390, 10833, 538, 257, 6286, 3669, 12, 14579, 11, 411, 13420, 4, 295, 264, 3097, 1412, 307, 3669, 12, 14579, 11, 51296], "temperature": 0.0, "avg_logprob": -0.11627400198648143, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.0011064315913245082}, {"id": 328, "seek": 161488, "start": 1634.5600000000002, "end": 1639.2, "text": " a primarily English-speaking westernized population, people who have mostly written a", "tokens": [51348, 257, 10029, 3669, 12, 14579, 13231, 1602, 4415, 11, 561, 567, 362, 5240, 3720, 257, 51580], "temperature": 0.0, "avg_logprob": -0.11627400198648143, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.0011064315913245082}, {"id": 329, "seek": 163920, "start": 1639.2, "end": 1645.3600000000001, "text": " lot on Reddit and lived between about 1900 and 2023, which like in the grand scheme of history", "tokens": [50364, 688, 322, 32210, 293, 5152, 1296, 466, 28898, 293, 44377, 11, 597, 411, 294, 264, 2697, 12232, 295, 2503, 50672], "temperature": 0.0, "avg_logprob": -0.12045751538193017, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.00680707348510623}, {"id": 330, "seek": 163920, "start": 1645.3600000000001, "end": 1651.68, "text": " and geography is a very narrow slice of humanity, right? Of all possible cultures we've had in the", "tokens": [50672, 293, 26695, 307, 257, 588, 9432, 13153, 295, 10243, 11, 558, 30, 2720, 439, 1944, 12951, 321, 600, 632, 294, 264, 50988], "temperature": 0.0, "avg_logprob": -0.12045751538193017, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.00680707348510623}, {"id": 331, "seek": 163920, "start": 1651.68, "end": 1656.8, "text": " past, all possible cultures we could have in the future and all possible languages. This is just", "tokens": [50988, 1791, 11, 439, 1944, 12951, 321, 727, 362, 294, 264, 2027, 293, 439, 1944, 8650, 13, 639, 307, 445, 51244], "temperature": 0.0, "avg_logprob": -0.12045751538193017, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.00680707348510623}, {"id": 332, "seek": 163920, "start": 1656.8, "end": 1662.0, "text": " such a small representation of reality and yet we're now making it the source of truth, right?", "tokens": [51244, 1270, 257, 1359, 10290, 295, 4103, 293, 1939, 321, 434, 586, 1455, 309, 264, 4009, 295, 3494, 11, 558, 30, 51504], "temperature": 0.0, "avg_logprob": -0.12045751538193017, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.00680707348510623}, {"id": 333, "seek": 163920, "start": 1662.0, "end": 1668.48, "text": " The Oracle. You go to chat, GBT to ask everything. So it's taking this already dominant way of", "tokens": [51504, 440, 25654, 13, 509, 352, 281, 5081, 11, 26809, 51, 281, 1029, 1203, 13, 407, 309, 311, 1940, 341, 1217, 15657, 636, 295, 51828], "temperature": 0.0, "avg_logprob": -0.12045751538193017, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.00680707348510623}, {"id": 334, "seek": 166848, "start": 1668.48, "end": 1672.32, "text": " seeing the world and reinforcing that dominance, which is problematic and is like a whole different", "tokens": [50364, 2577, 264, 1002, 293, 48262, 300, 34987, 11, 597, 307, 19011, 293, 307, 411, 257, 1379, 819, 50556], "temperature": 0.0, "avg_logprob": -0.0916347323723559, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.0004300956497900188}, {"id": 335, "seek": 166848, "start": 1672.32, "end": 1677.6, "text": " talk that I don't even think I'm qualified to do but someone should. And we hope that this will", "tokens": [50556, 751, 300, 286, 500, 380, 754, 519, 286, 478, 15904, 281, 360, 457, 1580, 820, 13, 400, 321, 1454, 300, 341, 486, 50820], "temperature": 0.0, "avg_logprob": -0.0916347323723559, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.0004300956497900188}, {"id": 336, "seek": 166848, "start": 1677.6, "end": 1682.4, "text": " improve over time but it's really hard to do without lots of data and most cultures don't have the", "tokens": [50820, 3470, 670, 565, 457, 309, 311, 534, 1152, 281, 360, 1553, 3195, 295, 1412, 293, 881, 12951, 500, 380, 362, 264, 51060], "temperature": 0.0, "avg_logprob": -0.0916347323723559, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.0004300956497900188}, {"id": 337, "seek": 166848, "start": 1682.4, "end": 1689.52, "text": " vast kind of written record that an English-speaking westernized online population does. So lastly,", "tokens": [51060, 8369, 733, 295, 3720, 2136, 300, 364, 3669, 12, 14579, 13231, 1602, 2950, 4415, 775, 13, 407, 16386, 11, 51416], "temperature": 0.0, "avg_logprob": -0.0916347323723559, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.0004300956497900188}, {"id": 338, "seek": 166848, "start": 1690.32, "end": 1694.56, "text": " generated content lacks the potential for human relationships that human-made content does,", "tokens": [51456, 10833, 2701, 31132, 264, 3995, 337, 1952, 6159, 300, 1952, 12, 10341, 2701, 775, 11, 51668], "temperature": 0.0, "avg_logprob": -0.0916347323723559, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.0004300956497900188}, {"id": 339, "seek": 169456, "start": 1694.56, "end": 1700.3999999999999, "text": " right? If you write something online and I read it and I find it compelling, I can DM you on Twitter", "tokens": [50364, 558, 30, 759, 291, 2464, 746, 2950, 293, 286, 1401, 309, 293, 286, 915, 309, 20050, 11, 286, 393, 15322, 291, 322, 5794, 50656], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 340, "seek": 169456, "start": 1700.3999999999999, "end": 1704.24, "text": " or I can find you on Blue Sky or I could find you somehow, ideally hopefully not on LinkedIn,", "tokens": [50656, 420, 286, 393, 915, 291, 322, 8510, 9879, 420, 286, 727, 915, 291, 6063, 11, 22915, 4696, 406, 322, 20657, 11, 50848], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 341, "seek": 169456, "start": 1704.24, "end": 1708.1599999999999, "text": " but somehow and message you and be like, I love this. This was such good ideas. Like I want to", "tokens": [50848, 457, 6063, 293, 3636, 291, 293, 312, 411, 11, 286, 959, 341, 13, 639, 390, 1270, 665, 3487, 13, 1743, 286, 528, 281, 51044], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 342, "seek": 169456, "start": 1708.1599999999999, "end": 1712.56, "text": " write a piece in response to you and like we start having a little dialogue that I've had so many", "tokens": [51044, 2464, 257, 2522, 294, 4134, 281, 291, 293, 411, 321, 722, 1419, 257, 707, 10221, 300, 286, 600, 632, 370, 867, 51264], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 343, "seek": 169456, "start": 1712.56, "end": 1718.08, "text": " relationships blossom this way. But if you have a language model, it's not going to be able to do", "tokens": [51264, 6159, 38524, 341, 636, 13, 583, 498, 291, 362, 257, 2856, 2316, 11, 309, 311, 406, 516, 281, 312, 1075, 281, 360, 51540], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 344, "seek": 169456, "start": 1718.08, "end": 1723.04, "text": " that. So this is a still from the film, Her, right? This has become kind of a cultural touch", "tokens": [51540, 300, 13, 407, 341, 307, 257, 920, 490, 264, 2007, 11, 3204, 11, 558, 30, 639, 575, 1813, 733, 295, 257, 6988, 2557, 51788], "temperature": 0.0, "avg_logprob": -0.10395986206677495, "compression_ratio": 1.685131195335277, "no_speech_prob": 0.003084122436121106}, {"id": 345, "seek": 172304, "start": 1723.04, "end": 1729.04, "text": " point of like parasocial relationships with AI. Hopefully people have seen it but if not,", "tokens": [50364, 935, 295, 411, 21012, 78, 1013, 6159, 365, 7318, 13, 10429, 561, 362, 1612, 309, 457, 498, 406, 11, 50664], "temperature": 0.0, "avg_logprob": -0.13374004364013672, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0072692143730819225}, {"id": 346, "seek": 172304, "start": 1729.04, "end": 1733.92, "text": " so Joaquin Phoenix, our lovely main character, he has this great relationship with his personal AI,", "tokens": [50664, 370, 3139, 23761, 259, 18383, 11, 527, 7496, 2135, 2517, 11, 415, 575, 341, 869, 2480, 365, 702, 2973, 7318, 11, 50908], "temperature": 0.0, "avg_logprob": -0.13374004364013672, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0072692143730819225}, {"id": 347, "seek": 172304, "start": 1733.92, "end": 1739.76, "text": " he talks to her in his ear, it falls in love with her. But then the AI of course grows bored of him", "tokens": [50908, 415, 6686, 281, 720, 294, 702, 1273, 11, 309, 8804, 294, 959, 365, 720, 13, 583, 550, 264, 7318, 295, 1164, 13156, 13521, 295, 796, 51200], "temperature": 0.0, "avg_logprob": -0.13374004364013672, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0072692143730819225}, {"id": 348, "seek": 172304, "start": 1739.76, "end": 1746.0, "text": " because he's a very kind of basic human and leaves and he's destroyed. And like some people were", "tokens": [51200, 570, 415, 311, 257, 588, 733, 295, 3875, 1952, 293, 5510, 293, 415, 311, 8937, 13, 400, 411, 512, 561, 645, 51512], "temperature": 0.0, "avg_logprob": -0.13374004364013672, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0072692143730819225}, {"id": 349, "seek": 172304, "start": 1746.0, "end": 1749.6, "text": " supposed to get this like film is supposed to be a warning, right? And some people took it as a", "tokens": [51512, 3442, 281, 483, 341, 411, 2007, 307, 3442, 281, 312, 257, 9164, 11, 558, 30, 400, 512, 561, 1890, 309, 382, 257, 51692], "temperature": 0.0, "avg_logprob": -0.13374004364013672, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0072692143730819225}, {"id": 350, "seek": 174960, "start": 1749.6, "end": 1758.7199999999998, "text": " suggestion. So there's a company called replica who make AI companions for you that you can", "tokens": [50364, 16541, 13, 407, 456, 311, 257, 2237, 1219, 35456, 567, 652, 7318, 28009, 337, 291, 300, 291, 393, 50820], "temperature": 0.0, "avg_logprob": -0.09984338283538818, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006676425691694021}, {"id": 351, "seek": 174960, "start": 1760.0, "end": 1764.3999999999999, "text": " make friends with, possibly date and fall in love with. There's a lot of suggestions of sort of", "tokens": [50884, 652, 1855, 365, 11, 6264, 4002, 293, 2100, 294, 959, 365, 13, 821, 311, 257, 688, 295, 13396, 295, 1333, 295, 51104], "temperature": 0.0, "avg_logprob": -0.09984338283538818, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006676425691694021}, {"id": 352, "seek": 174960, "start": 1764.3999999999999, "end": 1770.1599999999999, "text": " lonely young men engaging with this and their marketing copy. And I mean, maybe I do need to", "tokens": [51104, 14236, 2037, 1706, 11268, 365, 341, 293, 641, 6370, 5055, 13, 400, 286, 914, 11, 1310, 286, 360, 643, 281, 51392], "temperature": 0.0, "avg_logprob": -0.09984338283538818, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006676425691694021}, {"id": 353, "seek": 174960, "start": 1770.1599999999999, "end": 1776.48, "text": " explicitly point this out. An AI replica or any other kind of like generative agent person cannot", "tokens": [51392, 20803, 935, 341, 484, 13, 1107, 7318, 35456, 420, 604, 661, 733, 295, 411, 1337, 1166, 9461, 954, 2644, 51708], "temperature": 0.0, "avg_logprob": -0.09984338283538818, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006676425691694021}, {"id": 354, "seek": 177648, "start": 1776.48, "end": 1780.8, "text": " fulfill all our human needs, right? They cannot give you a hug, they cannot come to your birthday", "tokens": [50364, 13875, 439, 527, 1952, 2203, 11, 558, 30, 814, 2644, 976, 291, 257, 8777, 11, 436, 2644, 808, 281, 428, 6154, 50580], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 355, "seek": 177648, "start": 1780.8, "end": 1787.44, "text": " party, they cannot kind of engage with you in a meaningful, full human way. And so any kind of", "tokens": [50580, 3595, 11, 436, 2644, 733, 295, 4683, 365, 291, 294, 257, 10995, 11, 1577, 1952, 636, 13, 400, 370, 604, 733, 295, 50912], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 356, "seek": 177648, "start": 1787.44, "end": 1791.68, "text": " language model agent on the internet has no capacity for that back and forth relationship.", "tokens": [50912, 2856, 2316, 9461, 322, 264, 4705, 575, 572, 6042, 337, 300, 646, 293, 5220, 2480, 13, 51124], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 357, "seek": 177648, "start": 1791.68, "end": 1795.84, "text": " Even if it faked it, it's very unclear that it would actually satisfy what we need when we have", "tokens": [51124, 2754, 498, 309, 283, 7301, 309, 11, 309, 311, 588, 25636, 300, 309, 576, 767, 19319, 437, 321, 643, 562, 321, 362, 51332], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 358, "seek": 177648, "start": 1795.84, "end": 1800.64, "text": " an actual friend that we can go out to coffee with. So that all sounds quite bad again. Like", "tokens": [51332, 364, 3539, 1277, 300, 321, 393, 352, 484, 281, 4982, 365, 13, 407, 300, 439, 3263, 1596, 1578, 797, 13, 1743, 51572], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 359, "seek": 177648, "start": 1800.64, "end": 1805.76, "text": " deep breaths, the whole talk is really just digging you in a ditch, I'm sorry. But I'm now", "tokens": [51572, 2452, 33769, 11, 264, 1379, 751, 307, 534, 445, 17343, 291, 294, 257, 25325, 11, 286, 478, 2597, 13, 583, 286, 478, 586, 51828], "temperature": 0.0, "avg_logprob": -0.08190165320746333, "compression_ratio": 1.6607669616519174, "no_speech_prob": 0.00314656225964427}, {"id": 360, "seek": 180576, "start": 1805.76, "end": 1811.92, "text": " going to talk about possible futures. And again, these futures I think are not mutually exclusive,", "tokens": [50364, 516, 281, 751, 466, 1944, 26071, 13, 400, 797, 11, 613, 26071, 286, 519, 366, 406, 39144, 13005, 11, 50672], "temperature": 0.0, "avg_logprob": -0.10635507901509603, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0006530261598527431}, {"id": 361, "seek": 180576, "start": 1811.92, "end": 1815.76, "text": " I think they all might unfold in different ways over the next five to 10 years. And like I can't", "tokens": [50672, 286, 519, 436, 439, 1062, 17980, 294, 819, 2098, 670, 264, 958, 1732, 281, 1266, 924, 13, 400, 411, 286, 393, 380, 50864], "temperature": 0.0, "avg_logprob": -0.10635507901509603, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0006530261598527431}, {"id": 362, "seek": 180576, "start": 1815.76, "end": 1820.16, "text": " speculate beyond that, God knows where we are. But yeah, I'm hoping they all kind of happen", "tokens": [50864, 40775, 4399, 300, 11, 1265, 3255, 689, 321, 366, 13, 583, 1338, 11, 286, 478, 7159, 436, 439, 733, 295, 1051, 51084], "temperature": 0.0, "avg_logprob": -0.10635507901509603, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0006530261598527431}, {"id": 363, "seek": 180576, "start": 1820.16, "end": 1825.44, "text": " in parallel. So the first is I think we're about to spend a lot of time thinking about how we", "tokens": [51084, 294, 8952, 13, 407, 264, 700, 307, 286, 519, 321, 434, 466, 281, 3496, 257, 688, 295, 565, 1953, 466, 577, 321, 51348], "temperature": 0.0, "avg_logprob": -0.10635507901509603, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0006530261598527431}, {"id": 364, "seek": 180576, "start": 1825.44, "end": 1831.6, "text": " pass the reverse Turing test. So how do we prove we're human on a web filled with agents? So the", "tokens": [51348, 1320, 264, 9943, 314, 1345, 1500, 13, 407, 577, 360, 321, 7081, 321, 434, 1952, 322, 257, 3670, 6412, 365, 12554, 30, 407, 264, 51656], "temperature": 0.0, "avg_logprob": -0.10635507901509603, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0006530261598527431}, {"id": 365, "seek": 183160, "start": 1831.6, "end": 1836.48, "text": " original Turing test, you have a human talk to a computer and another human through like a wall", "tokens": [50364, 3380, 314, 1345, 1500, 11, 291, 362, 257, 1952, 751, 281, 257, 3820, 293, 1071, 1952, 807, 411, 257, 2929, 50608], "temperature": 0.0, "avg_logprob": -0.08085316816965739, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.000665626663248986}, {"id": 366, "seek": 183160, "start": 1836.48, "end": 1841.1999999999998, "text": " so they can't see the typing messages of each other. And then the original test, the computer had", "tokens": [50608, 370, 436, 393, 380, 536, 264, 18444, 7897, 295, 1184, 661, 13, 400, 550, 264, 3380, 1500, 11, 264, 3820, 632, 50844], "temperature": 0.0, "avg_logprob": -0.08085316816965739, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.000665626663248986}, {"id": 367, "seek": 183160, "start": 1841.1999999999998, "end": 1846.8799999999999, "text": " to prove that it was the human. It had to prove it was competent. And on the new web, we are now the", "tokens": [50844, 281, 7081, 300, 309, 390, 264, 1952, 13, 467, 632, 281, 7081, 309, 390, 29998, 13, 400, 322, 264, 777, 3670, 11, 321, 366, 586, 264, 51128], "temperature": 0.0, "avg_logprob": -0.08085316816965739, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.000665626663248986}, {"id": 368, "seek": 183160, "start": 1846.8799999999999, "end": 1854.0, "text": " ones under scrutiny. We have to prove we're real. So we're going to end up like we will assume", "tokens": [51128, 2306, 833, 38615, 13, 492, 362, 281, 7081, 321, 434, 957, 13, 407, 321, 434, 516, 281, 917, 493, 411, 321, 486, 6552, 51484], "temperature": 0.0, "avg_logprob": -0.08085316816965739, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.000665626663248986}, {"id": 369, "seek": 183160, "start": 1854.0, "end": 1858.48, "text": " everyone is an agent until proven otherwise. So I kind of wrote this post where I was", "tokens": [51484, 1518, 307, 364, 9461, 1826, 12785, 5911, 13, 407, 286, 733, 295, 4114, 341, 2183, 689, 286, 390, 51708], "temperature": 0.0, "avg_logprob": -0.08085316816965739, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.000665626663248986}, {"id": 370, "seek": 185848, "start": 1859.2, "end": 1863.04, "text": " thinking about some short term tactics. Like we could use funny terminology. We could all try to", "tokens": [50400, 1953, 466, 512, 2099, 1433, 19454, 13, 1743, 321, 727, 764, 4074, 27575, 13, 492, 727, 439, 853, 281, 50592], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 371, "seek": 185848, "start": 1863.04, "end": 1867.1200000000001, "text": " become teenagers who like have this insider jargon that the language models don't know about, but", "tokens": [50592, 1813, 23618, 567, 411, 362, 341, 40990, 15181, 10660, 300, 264, 2856, 5245, 500, 380, 458, 466, 11, 457, 50796], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 372, "seek": 185848, "start": 1867.1200000000001, "end": 1870.32, "text": " they'll pick up on it pretty quick, you know, and then you'll have to abandon it, get a new jargon.", "tokens": [50796, 436, 603, 1888, 493, 322, 309, 1238, 1702, 11, 291, 458, 11, 293, 550, 291, 603, 362, 281, 9072, 309, 11, 483, 257, 777, 15181, 10660, 13, 50956], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 373, "seek": 185848, "start": 1871.1200000000001, "end": 1874.8, "text": " We could write in non-dominant languages. If you speak something like Catalan or Welsh,", "tokens": [50996, 492, 727, 2464, 294, 2107, 12, 4121, 259, 394, 8650, 13, 759, 291, 1710, 746, 411, 9565, 14163, 420, 27129, 11, 51180], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 374, "seek": 185848, "start": 1874.8, "end": 1878.4, "text": " you're probably in a pretty good position, you know, you'll be able to write in a way that's", "tokens": [51180, 291, 434, 1391, 294, 257, 1238, 665, 2535, 11, 291, 458, 11, 291, 603, 312, 1075, 281, 2464, 294, 257, 636, 300, 311, 51360], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 375, "seek": 185848, "start": 1878.4, "end": 1883.52, "text": " more native than a language model ever could. And ideally, we just do higher quality writing,", "tokens": [51360, 544, 8470, 813, 257, 2856, 2316, 1562, 727, 13, 400, 22915, 11, 321, 445, 360, 2946, 3125, 3579, 11, 51616], "temperature": 0.0, "avg_logprob": -0.11796392521388094, "compression_ratio": 1.761609907120743, "no_speech_prob": 0.0016811653040349483}, {"id": 376, "seek": 188352, "start": 1883.52, "end": 1889.12, "text": " we do more research, we do more critical thinking. We really reference events and people that could", "tokens": [50364, 321, 360, 544, 2132, 11, 321, 360, 544, 4924, 1953, 13, 492, 534, 6408, 3931, 293, 561, 300, 727, 50644], "temperature": 0.0, "avg_logprob": -0.12090987518054097, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.0014862801181152463}, {"id": 377, "seek": 188352, "start": 1889.12, "end": 1893.76, "text": " we could only know about from the real world, from being embodied humans in space. I don't know how", "tokens": [50644, 321, 727, 787, 458, 466, 490, 264, 957, 1002, 11, 490, 885, 42046, 6255, 294, 1901, 13, 286, 500, 380, 458, 577, 50876], "temperature": 0.0, "avg_logprob": -0.12090987518054097, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.0014862801181152463}, {"id": 378, "seek": 188352, "start": 1893.76, "end": 1898.0, "text": " long those kind of defenses will last, but that's in the short term something we can at least pull", "tokens": [50876, 938, 729, 733, 295, 35989, 486, 1036, 11, 457, 300, 311, 294, 264, 2099, 1433, 746, 321, 393, 412, 1935, 2235, 51088], "temperature": 0.0, "avg_logprob": -0.12090987518054097, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.0014862801181152463}, {"id": 379, "seek": 188352, "start": 1898.0, "end": 1903.84, "text": " on. This next one, I apologize for the phrase, but it too perfectly, it catches the point. I'm", "tokens": [51088, 322, 13, 639, 958, 472, 11, 286, 12328, 337, 264, 9535, 11, 457, 309, 886, 6239, 11, 309, 25496, 264, 935, 13, 286, 478, 51380], "temperature": 0.0, "avg_logprob": -0.12090987518054097, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.0014862801181152463}, {"id": 380, "seek": 188352, "start": 1903.84, "end": 1910.56, "text": " not going to explain it. You can Google that later. But the point is that the content from models", "tokens": [51380, 406, 516, 281, 2903, 309, 13, 509, 393, 3329, 300, 1780, 13, 583, 264, 935, 307, 300, 264, 2701, 490, 5245, 51716], "temperature": 0.0, "avg_logprob": -0.12090987518054097, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.0014862801181152463}, {"id": 381, "seek": 191056, "start": 1910.56, "end": 1914.8799999999999, "text": " might end up becoming our source of truth, and that how we know things simply was like,", "tokens": [50364, 1062, 917, 493, 5617, 527, 4009, 295, 3494, 11, 293, 300, 577, 321, 458, 721, 2935, 390, 411, 11, 50580], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 382, "seek": 191056, "start": 1914.8799999999999, "end": 1919.28, "text": " well, a language model once said it, you know, and then it's forever captured in our circular flow", "tokens": [50580, 731, 11, 257, 2856, 2316, 1564, 848, 309, 11, 291, 458, 11, 293, 550, 309, 311, 5680, 11828, 294, 527, 16476, 3095, 50800], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 383, "seek": 191056, "start": 1919.28, "end": 1922.96, "text": " of information. So right in this current model, right, the training data is at least based on", "tokens": [50800, 295, 1589, 13, 407, 558, 294, 341, 2190, 2316, 11, 558, 11, 264, 3097, 1412, 307, 412, 1935, 2361, 322, 50984], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 384, "seek": 191056, "start": 1922.96, "end": 1927.76, "text": " real world experiences. It's kind of going in a single loop. But we're now going to use that", "tokens": [50984, 957, 1002, 5235, 13, 467, 311, 733, 295, 516, 294, 257, 2167, 6367, 13, 583, 321, 434, 586, 516, 281, 764, 300, 51224], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 385, "seek": 191056, "start": 1927.76, "end": 1934.08, "text": " generated text to train new models. And so we enter this loop where like there's this very", "tokens": [51224, 10833, 2487, 281, 3847, 777, 5245, 13, 400, 370, 321, 3242, 341, 6367, 689, 411, 456, 311, 341, 588, 51540], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 386, "seek": 191056, "start": 1934.08, "end": 1938.96, "text": " tenuous link to the real world that was once a long time ago, the source of this data. This is", "tokens": [51540, 2064, 12549, 2113, 281, 264, 957, 1002, 300, 390, 1564, 257, 938, 565, 2057, 11, 264, 4009, 295, 341, 1412, 13, 639, 307, 51784], "temperature": 0.0, "avg_logprob": -0.10788789927530631, "compression_ratio": 1.7306501547987616, "no_speech_prob": 0.0007445826195180416}, {"id": 387, "seek": 193896, "start": 1938.96, "end": 1943.2, "text": " already starting to happen. AI researchers are worried we're kind of going to run out of data to", "tokens": [50364, 1217, 2891, 281, 1051, 13, 7318, 10309, 366, 5804, 321, 434, 733, 295, 516, 281, 1190, 484, 295, 1412, 281, 50576], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 388, "seek": 193896, "start": 1943.2, "end": 1947.6000000000001, "text": " train models on within five years. And so there's a lot of talk of how do we generate information", "tokens": [50576, 3847, 5245, 322, 1951, 1732, 924, 13, 400, 370, 456, 311, 257, 688, 295, 751, 295, 577, 360, 321, 8460, 1589, 50796], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 389, "seek": 193896, "start": 1947.6000000000001, "end": 1953.44, "text": " that we can feed the models, feed back into the models. This one was a really funny example of", "tokens": [50796, 300, 321, 393, 3154, 264, 5245, 11, 3154, 646, 666, 264, 5245, 13, 639, 472, 390, 257, 534, 4074, 1365, 295, 51088], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 390, "seek": 193896, "start": 1953.44, "end": 1957.68, "text": " this happening. I don't know if people saw this. So someone noticed that if you ask Google if you", "tokens": [51088, 341, 2737, 13, 286, 500, 380, 458, 498, 561, 1866, 341, 13, 407, 1580, 5694, 300, 498, 291, 1029, 3329, 498, 291, 51300], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 391, "seek": 193896, "start": 1957.68, "end": 1962.24, "text": " can melt an egg, it's like smart AI summary said yes. And they were like, why would it say that?", "tokens": [51300, 393, 10083, 364, 3777, 11, 309, 311, 411, 4069, 7318, 12691, 848, 2086, 13, 400, 436, 645, 411, 11, 983, 576, 309, 584, 300, 30, 51528], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 392, "seek": 193896, "start": 1962.24, "end": 1966.56, "text": " They weren't investigating. And it turned out that fact was pulled from Quora that was generated", "tokens": [51528, 814, 4999, 380, 22858, 13, 400, 309, 3574, 484, 300, 1186, 390, 7373, 490, 2326, 3252, 300, 390, 10833, 51744], "temperature": 0.0, "avg_logprob": -0.10881648265140158, "compression_ratio": 1.7138643067846608, "no_speech_prob": 0.00053532695164904}, {"id": 393, "seek": 196656, "start": 1966.56, "end": 1972.32, "text": " from chat GPT. And because Quora is considered a reputable website with good SEO standing,", "tokens": [50364, 490, 5081, 26039, 51, 13, 400, 570, 2326, 3252, 307, 4888, 257, 1085, 32148, 3144, 365, 665, 22964, 4877, 11, 50652], "temperature": 0.0, "avg_logprob": -0.07924926386470288, "compression_ratio": 1.6, "no_speech_prob": 0.001470334129408002}, {"id": 394, "seek": 196656, "start": 1972.32, "end": 1976.96, "text": " it got pulled up into the Google like smart answer. And it's not hard to imagine how all", "tokens": [50652, 309, 658, 7373, 493, 666, 264, 3329, 411, 4069, 1867, 13, 400, 309, 311, 406, 1152, 281, 3811, 577, 439, 50884], "temperature": 0.0, "avg_logprob": -0.07924926386470288, "compression_ratio": 1.6, "no_speech_prob": 0.001470334129408002}, {"id": 395, "seek": 196656, "start": 1976.96, "end": 1981.36, "text": " kinds of hallucinated answers are going to become part of this loop if all these major websites are", "tokens": [50884, 3685, 295, 35212, 5410, 6338, 366, 516, 281, 1813, 644, 295, 341, 6367, 498, 439, 613, 2563, 12891, 366, 51104], "temperature": 0.0, "avg_logprob": -0.07924926386470288, "compression_ratio": 1.6, "no_speech_prob": 0.001470334129408002}, {"id": 396, "seek": 196656, "start": 1981.36, "end": 1986.3999999999999, "text": " using chat GPT or their own agent to generate answers and then they just feed it to each other.", "tokens": [51104, 1228, 5081, 26039, 51, 420, 641, 1065, 9461, 281, 8460, 6338, 293, 550, 436, 445, 3154, 309, 281, 1184, 661, 13, 51356], "temperature": 0.0, "avg_logprob": -0.07924926386470288, "compression_ratio": 1.6, "no_speech_prob": 0.001470334129408002}, {"id": 397, "seek": 196656, "start": 1986.3999999999999, "end": 1993.2, "text": " It's like at one point, can you melt an egg? This phenomenon is very worrying for the scientific", "tokens": [51356, 467, 311, 411, 412, 472, 935, 11, 393, 291, 10083, 364, 3777, 30, 639, 14029, 307, 588, 18788, 337, 264, 8134, 51696], "temperature": 0.0, "avg_logprob": -0.07924926386470288, "compression_ratio": 1.6, "no_speech_prob": 0.001470334129408002}, {"id": 398, "seek": 199320, "start": 1993.28, "end": 1997.52, "text": " community and they have good reason to be. We're already seeing a lot of evidence that scientific", "tokens": [50368, 1768, 293, 436, 362, 665, 1778, 281, 312, 13, 492, 434, 1217, 2577, 257, 688, 295, 4467, 300, 8134, 50580], "temperature": 0.0, "avg_logprob": -0.09853258410703788, "compression_ratio": 1.604810996563574, "no_speech_prob": 0.001600652583874762}, {"id": 399, "seek": 199320, "start": 1997.52, "end": 2004.72, "text": " researchers are using language models to help them write papers. So again, this is a paper", "tokens": [50580, 10309, 366, 1228, 2856, 5245, 281, 854, 552, 2464, 10577, 13, 407, 797, 11, 341, 307, 257, 3035, 50940], "temperature": 0.0, "avg_logprob": -0.09853258410703788, "compression_ratio": 1.604810996563574, "no_speech_prob": 0.001600652583874762}, {"id": 400, "seek": 199320, "start": 2004.72, "end": 2009.8400000000001, "text": " that was published in a genuine fairly legitimate journal, Environmental Science and Pollution", "tokens": [50940, 300, 390, 6572, 294, 257, 16699, 6457, 17956, 6708, 11, 27813, 8976, 293, 31304, 1448, 51196], "temperature": 0.0, "avg_logprob": -0.09853258410703788, "compression_ratio": 1.604810996563574, "no_speech_prob": 0.001600652583874762}, {"id": 401, "seek": 199320, "start": 2009.8400000000001, "end": 2015.28, "text": " Research. And it included the phrase regenerate response at the end of a paragraph, which is the", "tokens": [51196, 10303, 13, 400, 309, 5556, 264, 9535, 26358, 473, 4134, 412, 264, 917, 295, 257, 18865, 11, 597, 307, 264, 51468], "temperature": 0.0, "avg_logprob": -0.09853258410703788, "compression_ratio": 1.604810996563574, "no_speech_prob": 0.001600652583874762}, {"id": 402, "seek": 199320, "start": 2015.28, "end": 2021.8400000000001, "text": " button above chat GPT's input box. There's another one in August that was published on", "tokens": [51468, 2960, 3673, 5081, 26039, 51, 311, 4846, 2424, 13, 821, 311, 1071, 472, 294, 6897, 300, 390, 6572, 322, 51796], "temperature": 0.0, "avg_logprob": -0.09853258410703788, "compression_ratio": 1.604810996563574, "no_speech_prob": 0.001600652583874762}, {"id": 403, "seek": 202184, "start": 2021.9199999999998, "end": 2028.3999999999999, "text": " fossil fuel allocation that included the phrase as an AI language model. Now, there's a lot of", "tokens": [50368, 18737, 6616, 27599, 300, 5556, 264, 9535, 382, 364, 7318, 2856, 2316, 13, 823, 11, 456, 311, 257, 688, 295, 50692], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 404, "seek": 202184, "start": 2028.3999999999999, "end": 2031.6, "text": " debate in the community where they were like, well, this doesn't mean the science in these papers is", "tokens": [50692, 7958, 294, 264, 1768, 689, 436, 645, 411, 11, 731, 11, 341, 1177, 380, 914, 264, 3497, 294, 613, 10577, 307, 50852], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 405, "seek": 202184, "start": 2031.6, "end": 2035.1999999999998, "text": " totally false, right? They could have done real research on real experiments and they were just", "tokens": [50852, 3879, 7908, 11, 558, 30, 814, 727, 362, 1096, 957, 2132, 322, 957, 12050, 293, 436, 645, 445, 51032], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 406, "seek": 202184, "start": 2035.1999999999998, "end": 2039.12, "text": " trying to get this paper out and at the end they went, you know what, chat GPT summarizes paragraph", "tokens": [51032, 1382, 281, 483, 341, 3035, 484, 293, 412, 264, 917, 436, 1437, 11, 291, 458, 437, 11, 5081, 26039, 51, 14611, 5660, 18865, 51228], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 407, "seek": 202184, "start": 2039.12, "end": 2043.84, "text": " for me. That totally could have happened. But the problem is we don't know. There's no protocol for", "tokens": [51228, 337, 385, 13, 663, 3879, 727, 362, 2011, 13, 583, 264, 1154, 307, 321, 500, 380, 458, 13, 821, 311, 572, 10336, 337, 51464], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 408, "seek": 202184, "start": 2043.84, "end": 2048.72, "text": " the transparency of how you say what you didn't, didn't use chat GPT or whatever kind of model for.", "tokens": [51464, 264, 17131, 295, 577, 291, 584, 437, 291, 994, 380, 11, 994, 380, 764, 5081, 26039, 51, 420, 2035, 733, 295, 2316, 337, 13, 51708], "temperature": 0.0, "avg_logprob": -0.09879050221476522, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0007538708159700036}, {"id": 409, "seek": 204872, "start": 2049.12, "end": 2054.9599999999996, "text": " So now people are trying to make it more legitimate. Some people are listing chat GPT as an author on", "tokens": [50384, 407, 586, 561, 366, 1382, 281, 652, 309, 544, 17956, 13, 2188, 561, 366, 22161, 5081, 26039, 51, 382, 364, 3793, 322, 50676], "temperature": 0.0, "avg_logprob": -0.1283114948103913, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.00024081714218482375}, {"id": 410, "seek": 204872, "start": 2054.9599999999996, "end": 2060.8799999999997, "text": " papers. And there's a real risk that people with much worse intentions will kind of take this and", "tokens": [50676, 10577, 13, 400, 456, 311, 257, 957, 3148, 300, 561, 365, 709, 5324, 19354, 486, 733, 295, 747, 341, 293, 50972], "temperature": 0.0, "avg_logprob": -0.1283114948103913, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.00024081714218482375}, {"id": 411, "seek": 204872, "start": 2060.8799999999997, "end": 2065.4399999999996, "text": " run with it and just make scientific paper mills. There's a lot of companies that have a lot of", "tokens": [50972, 1190, 365, 309, 293, 445, 652, 8134, 3035, 1728, 82, 13, 821, 311, 257, 688, 295, 3431, 300, 362, 257, 688, 295, 51200], "temperature": 0.0, "avg_logprob": -0.1283114948103913, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.00024081714218482375}, {"id": 412, "seek": 204872, "start": 2065.4399999999996, "end": 2070.64, "text": " vested interests in publishing science that agree with the thing that they would like to be true.", "tokens": [51200, 49317, 8847, 294, 17832, 3497, 300, 3986, 365, 264, 551, 300, 436, 576, 411, 281, 312, 2074, 13, 51460], "temperature": 0.0, "avg_logprob": -0.1283114948103913, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.00024081714218482375}, {"id": 413, "seek": 204872, "start": 2070.64, "end": 2074.3999999999996, "text": " Usually you find this out when you get to the funding source section of the paper where you're", "tokens": [51460, 11419, 291, 915, 341, 484, 562, 291, 483, 281, 264, 6137, 4009, 3541, 295, 264, 3035, 689, 291, 434, 51648], "temperature": 0.0, "avg_logprob": -0.1283114948103913, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.00024081714218482375}, {"id": 414, "seek": 207440, "start": 2074.4, "end": 2079.36, "text": " like, oh, yeah, funded by the people who make this drug. Interesting. But you can tell that if", "tokens": [50364, 411, 11, 1954, 11, 1338, 11, 14385, 538, 264, 561, 567, 652, 341, 4110, 13, 14711, 13, 583, 291, 393, 980, 300, 498, 50612], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 415, "seek": 207440, "start": 2079.36, "end": 2083.28, "text": " they're going to be able to use generative models to kind of pump out lots of research papers, maybe", "tokens": [50612, 436, 434, 516, 281, 312, 1075, 281, 764, 1337, 1166, 5245, 281, 733, 295, 5889, 484, 3195, 295, 2132, 10577, 11, 1310, 50808], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 416, "seek": 207440, "start": 2083.28, "end": 2088.64, "text": " based on dubious science, it becomes very hard for us to tell what is actually real, what is vetted.", "tokens": [50808, 2361, 322, 18540, 851, 3497, 11, 309, 3643, 588, 1152, 337, 505, 281, 980, 437, 307, 767, 957, 11, 437, 307, 371, 46508, 13, 51076], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 417, "seek": 207440, "start": 2088.64, "end": 2094.32, "text": " I mean, it just takes the whole, the replication crisis to a whole new level. So this one seems", "tokens": [51076, 286, 914, 11, 309, 445, 2516, 264, 1379, 11, 264, 39911, 5869, 281, 257, 1379, 777, 1496, 13, 407, 341, 472, 2544, 51360], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 418, "seek": 207440, "start": 2094.32, "end": 2098.88, "text": " the most obvious, right? One possible future is we will just retreat further into the cozy web,", "tokens": [51360, 264, 881, 6322, 11, 558, 30, 1485, 1944, 2027, 307, 321, 486, 445, 15505, 3052, 666, 264, 29414, 3670, 11, 51588], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 419, "seek": 207440, "start": 2098.88, "end": 2104.08, "text": " right? The dark frost will grow larger and we will just go, okay, I'm only interacting with", "tokens": [51588, 558, 30, 440, 2877, 19623, 486, 1852, 4833, 293, 321, 486, 445, 352, 11, 1392, 11, 286, 478, 787, 18017, 365, 51848], "temperature": 0.0, "avg_logprob": -0.0839143060658076, "compression_ratio": 1.6430594900849858, "no_speech_prob": 0.0007222194690257311}, {"id": 420, "seek": 210408, "start": 2104.08, "end": 2109.12, "text": " Discord and WhatsApp, right? LinkedIn is dead, Twitter is dead. We've had to abandon it. We have", "tokens": [50364, 32623, 293, 30513, 11, 558, 30, 20657, 307, 3116, 11, 5794, 307, 3116, 13, 492, 600, 632, 281, 9072, 309, 13, 492, 362, 50616], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 421, "seek": 210408, "start": 2109.12, "end": 2113.7599999999998, "text": " to maybe make new privatized gate kept spaces, which I think has a lot of downsides, but this", "tokens": [50616, 281, 1310, 652, 777, 31856, 1602, 8539, 4305, 7673, 11, 597, 286, 519, 575, 257, 688, 295, 21554, 1875, 11, 457, 341, 50848], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 422, "seek": 210408, "start": 2113.7599999999998, "end": 2118.56, "text": " just might be the best way to deal with it. I think authors are going to increasingly put", "tokens": [50848, 445, 1062, 312, 264, 1151, 636, 281, 2028, 365, 309, 13, 286, 519, 16552, 366, 516, 281, 12980, 829, 51088], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 423, "seek": 210408, "start": 2118.56, "end": 2122.0, "text": " content behind blocks and paywalls. I think this is already happening with things like", "tokens": [51088, 2701, 2261, 8474, 293, 1689, 16256, 82, 13, 286, 519, 341, 307, 1217, 2737, 365, 721, 411, 51260], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 424, "seek": 210408, "start": 2122.0, "end": 2127.68, "text": " sub-stack and medium, where you're constantly having to log in or prove that you are part of", "tokens": [51260, 1422, 12, 372, 501, 293, 6399, 11, 689, 291, 434, 6460, 1419, 281, 3565, 294, 420, 7081, 300, 291, 366, 644, 295, 51544], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 425, "seek": 210408, "start": 2127.68, "end": 2133.2, "text": " this community to access the content. You understand why authors do this, right? Because", "tokens": [51544, 341, 1768, 281, 2105, 264, 2701, 13, 509, 1223, 983, 16552, 360, 341, 11, 558, 30, 1436, 51820], "temperature": 0.0, "avg_logprob": -0.124754507150223, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.0008216018322855234}, {"id": 426, "seek": 213320, "start": 2133.2, "end": 2137.68, "text": " actually you're having your content scraped and then fed into generative models puts you in a", "tokens": [50364, 767, 291, 434, 1419, 428, 2701, 13943, 3452, 293, 550, 4636, 666, 1337, 1166, 5245, 8137, 291, 294, 257, 50588], "temperature": 0.0, "avg_logprob": -0.12588802543846336, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.001419108477421105}, {"id": 427, "seek": 213320, "start": 2137.68, "end": 2143.4399999999996, "text": " disadvantage. Like your ideas could be taken out of context, maybe it's taken something that you", "tokens": [50588, 24292, 13, 1743, 428, 3487, 727, 312, 2726, 484, 295, 4319, 11, 1310, 309, 311, 2726, 746, 300, 291, 50876], "temperature": 0.0, "avg_logprob": -0.12588802543846336, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.001419108477421105}, {"id": 428, "seek": 213320, "start": 2143.4399999999996, "end": 2148.24, "text": " wanted to actually charge for and given out for free. Someone could train a model on your work", "tokens": [50876, 1415, 281, 767, 4602, 337, 293, 2212, 484, 337, 1737, 13, 8734, 727, 3847, 257, 2316, 322, 428, 589, 51116], "temperature": 0.0, "avg_logprob": -0.12588802543846336, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.001419108477421105}, {"id": 429, "seek": 213320, "start": 2148.24, "end": 2152.0, "text": " and have it start writing in your voice. There's a lot of ways this can go really badly for someone", "tokens": [51116, 293, 362, 309, 722, 3579, 294, 428, 3177, 13, 821, 311, 257, 688, 295, 2098, 341, 393, 352, 534, 13425, 337, 1580, 51304], "temperature": 0.0, "avg_logprob": -0.12588802543846336, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.001419108477421105}, {"id": 430, "seek": 213320, "start": 2152.0, "end": 2158.72, "text": " whose full-time job is being a researcher or a content creator. We'll also see more websites", "tokens": [51304, 6104, 1577, 12, 3766, 1691, 307, 885, 257, 21751, 420, 257, 2701, 14181, 13, 492, 603, 611, 536, 544, 12891, 51640], "temperature": 0.0, "avg_logprob": -0.12588802543846336, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.001419108477421105}, {"id": 431, "seek": 215872, "start": 2158.7999999999997, "end": 2164.16, "text": " that have a large amount of content blocking scraping for language models, or one way to do", "tokens": [50368, 300, 362, 257, 2416, 2372, 295, 2701, 17776, 43738, 337, 2856, 5245, 11, 420, 472, 636, 281, 360, 50636], "temperature": 0.0, "avg_logprob": -0.11886800237062599, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.05080721154808998}, {"id": 432, "seek": 215872, "start": 2164.16, "end": 2169.3599999999997, "text": " it is to just charge a huge amount for your API. Reddit did this recently. We're going to put the", "tokens": [50636, 309, 307, 281, 445, 4602, 257, 2603, 2372, 337, 428, 9362, 13, 32210, 630, 341, 3938, 13, 492, 434, 516, 281, 829, 264, 50896], "temperature": 0.0, "avg_logprob": -0.11886800237062599, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.05080721154808998}, {"id": 433, "seek": 215872, "start": 2169.3599999999997, "end": 2173.3599999999997, "text": " price so high that no company in their right mind would really pay it, or it would just cost them", "tokens": [50896, 3218, 370, 1090, 300, 572, 2237, 294, 641, 558, 1575, 576, 534, 1689, 309, 11, 420, 309, 576, 445, 2063, 552, 51096], "temperature": 0.0, "avg_logprob": -0.11886800237062599, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.05080721154808998}, {"id": 434, "seek": 215872, "start": 2173.3599999999997, "end": 2179.3599999999997, "text": " so much. Twitter kind of did the same. It's hard to tell if this was actually strategic or on purpose,", "tokens": [51096, 370, 709, 13, 5794, 733, 295, 630, 264, 912, 13, 467, 311, 1152, 281, 980, 498, 341, 390, 767, 10924, 420, 322, 4334, 11, 51396], "temperature": 0.0, "avg_logprob": -0.11886800237062599, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.05080721154808998}, {"id": 435, "seek": 215872, "start": 2179.3599999999997, "end": 2185.2799999999997, "text": " but raising the price to whatever it was, like 42,000 per month, means that very few people", "tokens": [51396, 457, 11225, 264, 3218, 281, 2035, 309, 390, 11, 411, 14034, 11, 1360, 680, 1618, 11, 1355, 300, 588, 1326, 561, 51692], "temperature": 0.0, "avg_logprob": -0.11886800237062599, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.05080721154808998}, {"id": 436, "seek": 218528, "start": 2185.28, "end": 2191.2000000000003, "text": " can access Twitter's really high-quality content in an age where content to train models is the", "tokens": [50364, 393, 2105, 5794, 311, 534, 1090, 12, 11286, 2701, 294, 364, 3205, 689, 2701, 281, 3847, 5245, 307, 264, 50660], "temperature": 0.0, "avg_logprob": -0.12653338603484324, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0008092130301520228}, {"id": 437, "seek": 218528, "start": 2191.2000000000003, "end": 2196.2400000000002, "text": " new goals. It's kind of leading us to a place where the web is not open by default. You can't", "tokens": [50660, 777, 5493, 13, 467, 311, 733, 295, 5775, 505, 281, 257, 1081, 689, 264, 3670, 307, 406, 1269, 538, 7576, 13, 509, 393, 380, 50912], "temperature": 0.0, "avg_logprob": -0.12653338603484324, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0008092130301520228}, {"id": 438, "seek": 218528, "start": 2196.2400000000002, "end": 2200.88, "text": " just query any API for any content you want. Everything is locked down and gatecapped and", "tokens": [50912, 445, 14581, 604, 9362, 337, 604, 2701, 291, 528, 13, 5471, 307, 9376, 760, 293, 8539, 496, 3320, 293, 51144], "temperature": 0.0, "avg_logprob": -0.12653338603484324, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0008092130301520228}, {"id": 439, "seek": 218528, "start": 2200.88, "end": 2205.92, "text": " kind of cordoned off. Next, I think we're going to have what I'm calling the Meet Space Premium.", "tokens": [51144, 733, 295, 12250, 19009, 766, 13, 3087, 11, 286, 519, 321, 434, 516, 281, 362, 437, 286, 478, 5141, 264, 22963, 8705, 34881, 13, 51396], "temperature": 0.0, "avg_logprob": -0.12653338603484324, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0008092130301520228}, {"id": 440, "seek": 218528, "start": 2207.84, "end": 2212.32, "text": " We are in the Meet Space Premium. It's when we begin to prefer and preference offline first", "tokens": [51492, 492, 366, 294, 264, 22963, 8705, 34881, 13, 467, 311, 562, 321, 1841, 281, 4382, 293, 17502, 21857, 700, 51716], "temperature": 0.0, "avg_logprob": -0.12653338603484324, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0008092130301520228}, {"id": 441, "seek": 221232, "start": 2212.32, "end": 2218.32, "text": " interactions. So we will start to doubt all people online. And the only way to confirm someone's", "tokens": [50364, 13280, 13, 407, 321, 486, 722, 281, 6385, 439, 561, 2950, 13, 400, 264, 787, 636, 281, 9064, 1580, 311, 50664], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 442, "seek": 221232, "start": 2218.32, "end": 2222.1600000000003, "text": " humanity is to meet them in person, right, to go for coffee or beer. And once you do that,", "tokens": [50664, 10243, 307, 281, 1677, 552, 294, 954, 11, 558, 11, 281, 352, 337, 4982, 420, 8795, 13, 400, 1564, 291, 360, 300, 11, 50856], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 443, "seek": 221232, "start": 2222.1600000000003, "end": 2226.2400000000002, "text": " you can kind of set up a little trust network, right? You can say, oh, I've already met Sarah", "tokens": [50856, 291, 393, 733, 295, 992, 493, 257, 707, 3361, 3209, 11, 558, 30, 509, 393, 584, 11, 1954, 11, 286, 600, 1217, 1131, 9519, 51060], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 444, "seek": 221232, "start": 2226.2400000000002, "end": 2229.92, "text": " over there, and she's a real human, and you've already met Tom, and he's a real human, and we can", "tokens": [51060, 670, 456, 11, 293, 750, 311, 257, 957, 1952, 11, 293, 291, 600, 1217, 1131, 5041, 11, 293, 415, 311, 257, 957, 1952, 11, 293, 321, 393, 51244], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 445, "seek": 221232, "start": 2229.92, "end": 2234.48, "text": " kind of like coordinate our networks to vet who's real on the web. And then when you read their", "tokens": [51244, 733, 295, 411, 15670, 527, 9590, 281, 12423, 567, 311, 957, 322, 264, 3670, 13, 400, 550, 562, 291, 1401, 641, 51472], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 446, "seek": 221232, "start": 2234.48, "end": 2238.88, "text": " writing, you kind of know it's from an actual person, or you'd hope so. You may be of some", "tokens": [51472, 3579, 11, 291, 733, 295, 458, 309, 311, 490, 364, 3539, 954, 11, 420, 291, 1116, 1454, 370, 13, 509, 815, 312, 295, 512, 51692], "temperature": 0.0, "avg_logprob": -0.09945668737872754, "compression_ratio": 1.802547770700637, "no_speech_prob": 0.00206102360971272}, {"id": 447, "seek": 223888, "start": 2238.88, "end": 2241.92, "text": " trust network of people who aren't writing generated stuff under their own name.", "tokens": [50364, 3361, 3209, 295, 561, 567, 3212, 380, 3579, 10833, 1507, 833, 641, 1065, 1315, 13, 50516], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 448, "seek": 223888, "start": 2243.04, "end": 2246.1600000000003, "text": " I think this has knock-on effects. Like, people might move back to cities or", "tokens": [50572, 286, 519, 341, 575, 6728, 12, 266, 5065, 13, 1743, 11, 561, 1062, 1286, 646, 281, 6486, 420, 50728], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 449, "seek": 223888, "start": 2246.1600000000003, "end": 2250.96, "text": " higher population and places. In-person events are going to be preferable. I think there's", "tokens": [50728, 2946, 4415, 293, 3190, 13, 682, 12, 10813, 3931, 366, 516, 281, 312, 4382, 712, 13, 286, 519, 456, 311, 50968], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 450, "seek": 223888, "start": 2250.96, "end": 2255.04, "text": " obvious disadvantages to this, right? The web was this huge democratization thing to enable", "tokens": [50968, 6322, 37431, 281, 341, 11, 558, 30, 440, 3670, 390, 341, 2603, 37221, 2144, 551, 281, 9528, 51172], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 451, "seek": 223888, "start": 2255.04, "end": 2259.12, "text": " people who are maybe disabled or have young children or who are caregivers who can't get", "tokens": [51172, 561, 567, 366, 1310, 15191, 420, 362, 2037, 2227, 420, 567, 366, 35440, 567, 393, 380, 483, 51376], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 452, "seek": 223888, "start": 2259.12, "end": 2262.96, "text": " out of the house for a whole bunch of reasons aren't going to have the same access to the trust", "tokens": [51376, 484, 295, 264, 1782, 337, 257, 1379, 3840, 295, 4112, 3212, 380, 516, 281, 362, 264, 912, 2105, 281, 264, 3361, 51568], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 453, "seek": 223888, "start": 2262.96, "end": 2266.4, "text": " network that someone can who could physically show up in space a lot.", "tokens": [51568, 3209, 300, 1580, 393, 567, 727, 9762, 855, 493, 294, 1901, 257, 688, 13, 51740], "temperature": 0.0, "avg_logprob": -0.13136491984346488, "compression_ratio": 1.739766081871345, "no_speech_prob": 0.00047647664905525744}, {"id": 454, "seek": 226888, "start": 2269.2000000000003, "end": 2273.04, "text": " Yeah. So, a natural follow-on from this also. So, a lot of people have been like,", "tokens": [50380, 865, 13, 407, 11, 257, 3303, 1524, 12, 266, 490, 341, 611, 13, 407, 11, 257, 688, 295, 561, 362, 668, 411, 11, 50572], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 455, "seek": 226888, "start": 2273.04, "end": 2277.6800000000003, "text": " well, why don't we just put it on the blockchain, you know? Why don't we just get a third party", "tokens": [50572, 731, 11, 983, 500, 380, 321, 445, 829, 309, 322, 264, 17176, 11, 291, 458, 30, 1545, 500, 380, 321, 445, 483, 257, 2636, 3595, 50804], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 456, "seek": 226888, "start": 2277.6800000000003, "end": 2282.4, "text": " to verify our humanity with a cryptographic key, and then you can sign all your published", "tokens": [50804, 281, 16888, 527, 10243, 365, 257, 9844, 12295, 2141, 11, 293, 550, 291, 393, 1465, 439, 428, 6572, 51040], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 457, "seek": 226888, "start": 2282.4, "end": 2286.48, "text": " content with it, and it'll link back to your identity, and this is how we'll have decentralized", "tokens": [51040, 2701, 365, 309, 11, 293, 309, 603, 2113, 646, 281, 428, 6575, 11, 293, 341, 307, 577, 321, 603, 362, 32870, 51244], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 458, "seek": 226888, "start": 2286.48, "end": 2290.6400000000003, "text": " trust networks. And I'm like, okay, I don't know the details of this. This sounds weird.", "tokens": [51244, 3361, 9590, 13, 400, 286, 478, 411, 11, 1392, 11, 286, 500, 380, 458, 264, 4365, 295, 341, 13, 639, 3263, 3657, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 459, "seek": 226888, "start": 2290.6400000000003, "end": 2296.2400000000002, "text": " So, there's a project called Worldcoin that, funnily enough, is also funded by OpenAI's", "tokens": [51452, 407, 11, 456, 311, 257, 1716, 1219, 3937, 8562, 300, 11, 1019, 77, 953, 1547, 11, 307, 611, 14385, 538, 7238, 48698, 311, 51732], "temperature": 0.0, "avg_logprob": -0.1306484637617254, "compression_ratio": 1.6265060240963856, "no_speech_prob": 0.00045009321183897555}, {"id": 460, "seek": 229624, "start": 2296.3199999999997, "end": 2300.56, "text": " leader, Sam Altman. He partially helped found it, which shows he kind of knows the problem he's", "tokens": [50368, 5263, 11, 4832, 15992, 1601, 13, 634, 18886, 4254, 1352, 309, 11, 597, 3110, 415, 733, 295, 3255, 264, 1154, 415, 311, 50580], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 461, "seek": 229624, "start": 2300.56, "end": 2305.9199999999996, "text": " helped contribute to. So, this scary orb scans your eyeball to confirm your identity,", "tokens": [50580, 4254, 10586, 281, 13, 407, 11, 341, 6958, 14715, 35116, 428, 38868, 281, 9064, 428, 6575, 11, 50848], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 462, "seek": 229624, "start": 2305.9199999999996, "end": 2310.56, "text": " and then it creates a unique human credential for you to use online to sign all your stuff with.", "tokens": [50848, 293, 550, 309, 7829, 257, 3845, 1952, 22034, 337, 291, 281, 764, 2950, 281, 1465, 439, 428, 1507, 365, 13, 51080], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 463, "seek": 229624, "start": 2310.56, "end": 2314.08, "text": " It's really not taking off as a project, but it's around. And people are still trying to do this.", "tokens": [51080, 467, 311, 534, 406, 1940, 766, 382, 257, 1716, 11, 457, 309, 311, 926, 13, 400, 561, 366, 920, 1382, 281, 360, 341, 13, 51256], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 464, "seek": 229624, "start": 2314.08, "end": 2319.04, "text": " There's a whole community thinking this is the future that I don't have sophisticated thoughts", "tokens": [51256, 821, 311, 257, 1379, 1768, 1953, 341, 307, 264, 2027, 300, 286, 500, 380, 362, 16950, 4598, 51504], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 465, "seek": 229624, "start": 2319.04, "end": 2324.0, "text": " on yet, and I'm still like, oh, cryptocurrency. But maybe this is some way to get around it.", "tokens": [51504, 322, 1939, 11, 293, 286, 478, 920, 411, 11, 1954, 11, 28809, 13, 583, 1310, 341, 307, 512, 636, 281, 483, 926, 309, 13, 51752], "temperature": 0.0, "avg_logprob": -0.11552975143211475, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.011322150938212872}, {"id": 466, "seek": 232400, "start": 2324.96, "end": 2328.56, "text": " I'm also expecting any day that Elon's going to announce the purple check,", "tokens": [50412, 286, 478, 611, 9650, 604, 786, 300, 28498, 311, 516, 281, 7478, 264, 9656, 1520, 11, 50592], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 467, "seek": 232400, "start": 2328.56, "end": 2332.16, "text": " where you pay $30 a month, and you don't actually have to. You just take a box that's like,", "tokens": [50592, 689, 291, 1689, 1848, 3446, 257, 1618, 11, 293, 291, 500, 380, 767, 362, 281, 13, 509, 445, 747, 257, 2424, 300, 311, 411, 11, 50772], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 468, "seek": 232400, "start": 2332.16, "end": 2337.92, "text": " I'm human, and then you get this little check and solve it. So, those are all a bit negative.", "tokens": [50772, 286, 478, 1952, 11, 293, 550, 291, 483, 341, 707, 1520, 293, 5039, 309, 13, 407, 11, 729, 366, 439, 257, 857, 3671, 13, 51060], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 469, "seek": 232400, "start": 2337.92, "end": 2342.4, "text": " I do think there is some hope in this future. We can certainly fight fire with fire.", "tokens": [51060, 286, 360, 519, 456, 307, 512, 1454, 294, 341, 2027, 13, 492, 393, 3297, 2092, 2610, 365, 2610, 13, 51284], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 470, "seek": 232400, "start": 2342.4, "end": 2346.32, "text": " So, I think it's reasonable to assume that we're all going to have a set of personal language", "tokens": [51284, 407, 11, 286, 519, 309, 311, 10585, 281, 6552, 300, 321, 434, 439, 516, 281, 362, 257, 992, 295, 2973, 2856, 51480], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 471, "seek": 232400, "start": 2346.32, "end": 2351.28, "text": " models to kind of help defend us and serve our needs on the web. They can filter information,", "tokens": [51480, 5245, 281, 733, 295, 854, 8602, 505, 293, 4596, 527, 2203, 322, 264, 3670, 13, 814, 393, 6608, 1589, 11, 51728], "temperature": 0.0, "avg_logprob": -0.10558786323602251, "compression_ratio": 1.64, "no_speech_prob": 0.0004547088756226003}, {"id": 472, "seek": 235128, "start": 2351.28, "end": 2356.0800000000004, "text": " they can manage information. And I expect these to be baked into browsers, or maybe even the", "tokens": [50364, 436, 393, 3067, 1589, 13, 400, 286, 2066, 613, 281, 312, 19453, 666, 36069, 11, 420, 1310, 754, 264, 50604], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 473, "seek": 235128, "start": 2356.0800000000004, "end": 2360.0800000000004, "text": " operating system, right? And they're going to do things like identify generated content,", "tokens": [50604, 7447, 1185, 11, 558, 30, 400, 436, 434, 516, 281, 360, 721, 411, 5876, 10833, 2701, 11, 50804], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 474, "seek": 235128, "start": 2360.0800000000004, "end": 2364.0, "text": " they're going to debunk claims, they're going to flag misinformation, they're going to go", "tokens": [50804, 436, 434, 516, 281, 3001, 3197, 9441, 11, 436, 434, 516, 281, 7166, 34238, 11, 436, 434, 516, 281, 352, 51000], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 475, "seek": 235128, "start": 2364.0, "end": 2369.0400000000004, "text": " help hunt down real scientific sources for you, maybe vet scientific papers, curate and suggest", "tokens": [51000, 854, 12454, 760, 957, 8134, 7139, 337, 291, 11, 1310, 12423, 8134, 10577, 11, 1262, 473, 293, 3402, 51252], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 476, "seek": 235128, "start": 2369.0400000000004, "end": 2372.8, "text": " things to you. So, I think this actually could work in both directions. It's not just all like", "tokens": [51252, 721, 281, 291, 13, 407, 11, 286, 519, 341, 767, 727, 589, 294, 1293, 11095, 13, 467, 311, 406, 445, 439, 411, 51440], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 477, "seek": 235128, "start": 2372.8, "end": 2377.36, "text": " the bad actors get this power. We also get a lot of capacity and capability from these models.", "tokens": [51440, 264, 1578, 10037, 483, 341, 1347, 13, 492, 611, 483, 257, 688, 295, 6042, 293, 13759, 490, 613, 5245, 13, 51668], "temperature": 0.0, "avg_logprob": -0.08102601124690129, "compression_ratio": 1.779552715654952, "no_speech_prob": 0.0011027653235942125}, {"id": 478, "seek": 237736, "start": 2378.32, "end": 2382.8, "text": " We might find it absurd that anyone would browse like the raw web without one of these", "tokens": [50412, 492, 1062, 915, 309, 19774, 300, 2878, 576, 31442, 411, 264, 8936, 3670, 1553, 472, 295, 613, 50636], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 479, "seek": 237736, "start": 2382.8, "end": 2386.1600000000003, "text": " kind of in tow. It's the same way you wouldn't like go onto the dark web, like you know what's", "tokens": [50636, 733, 295, 294, 10966, 13, 467, 311, 264, 912, 636, 291, 2759, 380, 411, 352, 3911, 264, 2877, 3670, 11, 411, 291, 458, 437, 311, 50804], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 480, "seek": 237736, "start": 2386.1600000000003, "end": 2391.52, "text": " there, but you know you don't want to see it. It might be kind of like that. Okay, so I'm almost", "tokens": [50804, 456, 11, 457, 291, 458, 291, 500, 380, 528, 281, 536, 309, 13, 467, 1062, 312, 733, 295, 411, 300, 13, 1033, 11, 370, 286, 478, 1920, 51072], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 481, "seek": 237736, "start": 2391.52, "end": 2395.84, "text": " done wrapping this up. But the question I want to leave everyone with is which of these possible", "tokens": [51072, 1096, 21993, 341, 493, 13, 583, 264, 1168, 286, 528, 281, 1856, 1518, 365, 307, 597, 295, 613, 1944, 51288], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 482, "seek": 237736, "start": 2395.84, "end": 2401.2000000000003, "text": " futures would you like to make happen, right? Generative AI is not necessarily a destructive", "tokens": [51288, 26071, 576, 291, 411, 281, 652, 1051, 11, 558, 30, 15409, 1166, 7318, 307, 406, 4725, 257, 26960, 51556], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 483, "seek": 237736, "start": 2401.2000000000003, "end": 2405.04, "text": " force, you know, as with all technology, it depends how you wield it. Oh, I went back to the", "tokens": [51556, 3464, 11, 291, 458, 11, 382, 365, 439, 2899, 11, 309, 5946, 577, 291, 35982, 309, 13, 876, 11, 286, 1437, 646, 281, 264, 51748], "temperature": 0.0, "avg_logprob": -0.12318948904673259, "compression_ratio": 1.753125, "no_speech_prob": 0.001029909122735262}, {"id": 484, "seek": 240504, "start": 2405.04, "end": 2412.08, "text": " wrong slide, sorry. There we go. The way that we choose to deploy this in the world is really", "tokens": [50364, 2085, 4137, 11, 2597, 13, 821, 321, 352, 13, 440, 636, 300, 321, 2826, 281, 7274, 341, 294, 264, 1002, 307, 534, 50716], "temperature": 0.0, "avg_logprob": -0.1325345744257388, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.00040060808532871306}, {"id": 485, "seek": 240504, "start": 2412.08, "end": 2415.52, "text": " what matters, right? The product decisions we make as individuals and companies, if you are", "tokens": [50716, 437, 7001, 11, 558, 30, 440, 1674, 5327, 321, 652, 382, 5346, 293, 3431, 11, 498, 291, 366, 50888], "temperature": 0.0, "avg_logprob": -0.1325345744257388, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.00040060808532871306}, {"id": 486, "seek": 240504, "start": 2415.52, "end": 2420.88, "text": " working in the space or you're trying to get into it. Because obviously if you are working on a tool", "tokens": [50888, 1364, 294, 264, 1901, 420, 291, 434, 1382, 281, 483, 666, 309, 13, 1436, 2745, 498, 291, 366, 1364, 322, 257, 2290, 51156], "temperature": 0.0, "avg_logprob": -0.1325345744257388, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.00040060808532871306}, {"id": 487, "seek": 240504, "start": 2420.88, "end": 2427.84, "text": " that like turns out tons of human-like content from marketing and influence purposes, like", "tokens": [51156, 300, 411, 4523, 484, 9131, 295, 1952, 12, 4092, 2701, 490, 6370, 293, 6503, 9932, 11, 411, 51504], "temperature": 0.0, "avg_logprob": -0.1325345744257388, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.00040060808532871306}, {"id": 488, "seek": 240504, "start": 2427.84, "end": 2433.04, "text": " you can stop, like that's really like we don't need that. You can just stop doing that. But what", "tokens": [51504, 291, 393, 1590, 11, 411, 300, 311, 534, 411, 321, 500, 380, 643, 300, 13, 509, 393, 445, 1590, 884, 300, 13, 583, 437, 51764], "temperature": 0.0, "avg_logprob": -0.1325345744257388, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.00040060808532871306}, {"id": 489, "seek": 243304, "start": 2433.04, "end": 2437.2, "text": " should you be building instead? It's maybe a more helpful question. So I tried to come up with a few", "tokens": [50364, 820, 291, 312, 2390, 2602, 30, 467, 311, 1310, 257, 544, 4961, 1168, 13, 407, 286, 3031, 281, 808, 493, 365, 257, 1326, 50572], "temperature": 0.0, "avg_logprob": -0.0756914103142569, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.0001979985972866416}, {"id": 490, "seek": 243304, "start": 2437.2, "end": 2441.2, "text": " principles for building products language models that are probably going to evolve over time, but", "tokens": [50572, 9156, 337, 2390, 3383, 2856, 5245, 300, 366, 1391, 516, 281, 16693, 670, 565, 11, 457, 50772], "temperature": 0.0, "avg_logprob": -0.0756914103142569, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.0001979985972866416}, {"id": 491, "seek": 243304, "start": 2441.2, "end": 2447.44, "text": " this is like a first pass. And the first is to protect human agency. The second is to treat models", "tokens": [50772, 341, 307, 411, 257, 700, 1320, 13, 400, 264, 700, 307, 281, 2371, 1952, 7934, 13, 440, 1150, 307, 281, 2387, 5245, 51084], "temperature": 0.0, "avg_logprob": -0.0756914103142569, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.0001979985972866416}, {"id": 492, "seek": 243304, "start": 2447.44, "end": 2452.8, "text": " as reasoning engines and not sources of truth. And lastly that we should be augmenting our", "tokens": [51084, 382, 21577, 12982, 293, 406, 7139, 295, 3494, 13, 400, 16386, 300, 321, 820, 312, 29919, 278, 527, 51352], "temperature": 0.0, "avg_logprob": -0.0756914103142569, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.0001979985972866416}, {"id": 493, "seek": 243304, "start": 2452.8, "end": 2458.96, "text": " cognitive abilities and not replacing them. So protecting human agency, this is like usually", "tokens": [51352, 15605, 11582, 293, 406, 19139, 552, 13, 407, 12316, 1952, 7934, 11, 341, 307, 411, 2673, 51660], "temperature": 0.0, "avg_logprob": -0.0756914103142569, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.0001979985972866416}, {"id": 494, "seek": 245896, "start": 2459.04, "end": 2463.12, "text": " at the moment you have a human prompter and it hands something off to an autonomous agent", "tokens": [50368, 412, 264, 1623, 291, 362, 257, 1952, 2234, 79, 391, 293, 309, 2377, 746, 766, 281, 364, 23797, 9461, 50572], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 495, "seek": 245896, "start": 2463.12, "end": 2467.36, "text": " and the agent goes and does stuff, right? This is like the open AI assistance model or any of", "tokens": [50572, 293, 264, 9461, 1709, 293, 775, 1507, 11, 558, 30, 639, 307, 411, 264, 1269, 7318, 9683, 2316, 420, 604, 295, 50784], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 496, "seek": 245896, "start": 2467.36, "end": 2470.8, "text": " the architectures I showed before. And this is like the path to self-destruction. This is what", "tokens": [50784, 264, 6331, 1303, 286, 4712, 949, 13, 400, 341, 307, 411, 264, 3100, 281, 2698, 12, 23748, 3826, 13, 639, 307, 437, 50956], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 497, "seek": 245896, "start": 2470.8, "end": 2475.12, "text": " most AI safety researchers are very afraid of is that the locus of agency sits within the agent.", "tokens": [50956, 881, 7318, 4514, 10309, 366, 588, 4638, 295, 307, 300, 264, 450, 1149, 295, 7934, 12696, 1951, 264, 9461, 13, 51172], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 498, "seek": 245896, "start": 2476.4, "end": 2480.2400000000002, "text": " But the ideal form of this is that the locus of agent stays within the human", "tokens": [51236, 583, 264, 7157, 1254, 295, 341, 307, 300, 264, 450, 1149, 295, 9461, 10834, 1951, 264, 1952, 51428], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 499, "seek": 245896, "start": 2480.2400000000002, "end": 2484.08, "text": " and it has a collaborative agent on hand and there's this very short continuous feedback loop", "tokens": [51428, 293, 309, 575, 257, 16555, 9461, 322, 1011, 293, 456, 311, 341, 588, 2099, 10957, 5824, 6367, 51620], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 500, "seek": 245896, "start": 2484.08, "end": 2488.32, "text": " that is constantly going between them. Where the human is the one checking, should I do that? Do", "tokens": [51620, 300, 307, 6460, 516, 1296, 552, 13, 2305, 264, 1952, 307, 264, 472, 8568, 11, 820, 286, 360, 300, 30, 1144, 51832], "temperature": 0.0, "avg_logprob": -0.11072827008814594, "compression_ratio": 1.8371428571428572, "no_speech_prob": 0.001343949930742383}, {"id": 501, "seek": 248832, "start": 2488.32, "end": 2493.84, "text": " I want that? Is that true? Like they're able to actually fact check things and then the agent is", "tokens": [50364, 286, 528, 300, 30, 1119, 300, 2074, 30, 1743, 436, 434, 1075, 281, 767, 1186, 1520, 721, 293, 550, 264, 9461, 307, 50640], "temperature": 0.0, "avg_logprob": -0.08789881830630095, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0001959965011337772}, {"id": 502, "seek": 248832, "start": 2493.84, "end": 2500.96, "text": " much more of a helper. Short feedback loops, close supervision, limited power, it's slower but it's", "tokens": [50640, 709, 544, 295, 257, 36133, 13, 16881, 5824, 16121, 11, 1998, 32675, 11, 5567, 1347, 11, 309, 311, 14009, 457, 309, 311, 50996], "temperature": 0.0, "avg_logprob": -0.08789881830630095, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0001959965011337772}, {"id": 503, "seek": 248832, "start": 2500.96, "end": 2507.36, "text": " safer. That ties into the second principle that we should treat models as tiny reasoning engines", "tokens": [50996, 15856, 13, 663, 14039, 666, 264, 1150, 8665, 300, 321, 820, 2387, 5245, 382, 5870, 21577, 12982, 51316], "temperature": 0.0, "avg_logprob": -0.08789881830630095, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0001959965011337772}, {"id": 504, "seek": 248832, "start": 2507.36, "end": 2512.1600000000003, "text": " and not sources of truth. So one way to use these models is to like ask it for every answer and", "tokens": [51316, 293, 406, 7139, 295, 3494, 13, 407, 472, 636, 281, 764, 613, 5245, 307, 281, 411, 1029, 309, 337, 633, 1867, 293, 51556], "temperature": 0.0, "avg_logprob": -0.08789881830630095, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0001959965011337772}, {"id": 505, "seek": 248832, "start": 2512.1600000000003, "end": 2517.52, "text": " ask it every question and trust what it says. Another one is you can train them to do specific", "tokens": [51556, 1029, 309, 633, 1168, 293, 3361, 437, 309, 1619, 13, 3996, 472, 307, 291, 393, 3847, 552, 281, 360, 2685, 51824], "temperature": 0.0, "avg_logprob": -0.08789881830630095, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0001959965011337772}, {"id": 506, "seek": 251752, "start": 2517.52, "end": 2523.36, "text": " things like just summarize this text, just extract data from this paper, just find contradictions in", "tokens": [50364, 721, 411, 445, 20858, 341, 2487, 11, 445, 8947, 1412, 490, 341, 3035, 11, 445, 915, 15858, 15607, 294, 50656], "temperature": 0.0, "avg_logprob": -0.0829516365414574, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0003385866293683648}, {"id": 507, "seek": 251752, "start": 2523.36, "end": 2528.4, "text": " this statement and then you can bring your own data which could be legitimate scientific papers,", "tokens": [50656, 341, 5629, 293, 550, 291, 393, 1565, 428, 1065, 1412, 597, 727, 312, 17956, 8134, 10577, 11, 50908], "temperature": 0.0, "avg_logprob": -0.0829516365414574, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0003385866293683648}, {"id": 508, "seek": 251752, "start": 2528.4, "end": 2532.48, "text": " it could be your own notes, it could be Wikipedia and then you use these models to just do these", "tokens": [50908, 309, 727, 312, 428, 1065, 5570, 11, 309, 727, 312, 28999, 293, 550, 291, 764, 613, 5245, 281, 445, 360, 613, 51112], "temperature": 0.0, "avg_logprob": -0.0829516365414574, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0003385866293683648}, {"id": 509, "seek": 251752, "start": 2532.48, "end": 2536.88, "text": " very small scoped things where you can observe every single output and check that it's actually", "tokens": [51112, 588, 1359, 795, 27277, 721, 689, 291, 393, 11441, 633, 2167, 5598, 293, 1520, 300, 309, 311, 767, 51332], "temperature": 0.0, "avg_logprob": -0.0829516365414574, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0003385866293683648}, {"id": 510, "seek": 251752, "start": 2536.88, "end": 2541.36, "text": " legitimate and you're not handing off this big complex task to this big black box model.", "tokens": [51332, 17956, 293, 291, 434, 406, 34774, 766, 341, 955, 3997, 5633, 281, 341, 955, 2211, 2424, 2316, 13, 51556], "temperature": 0.0, "avg_logprob": -0.0829516365414574, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0003385866293683648}, {"id": 511, "seek": 254136, "start": 2542.2400000000002, "end": 2548.48, "text": " And lastly, we should augment our cognitive abilities and not replace them, right? Language models", "tokens": [50408, 400, 16386, 11, 321, 820, 29919, 527, 15605, 11582, 293, 406, 7406, 552, 11, 558, 30, 24445, 5245, 50720], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 512, "seek": 254136, "start": 2548.48, "end": 2553.28, "text": " are very good at things that humans are not good at like searching and discovering things in large", "tokens": [50720, 366, 588, 665, 412, 721, 300, 6255, 366, 406, 665, 412, 411, 10808, 293, 24773, 721, 294, 2416, 50960], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 513, "seek": 254136, "start": 2553.28, "end": 2557.84, "text": " datasets, role playing as identities and characters, they're actually really good at doing that,", "tokens": [50960, 42856, 11, 3090, 2433, 382, 24239, 293, 4342, 11, 436, 434, 767, 534, 665, 412, 884, 300, 11, 51188], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 514, "seek": 254136, "start": 2558.4, "end": 2563.04, "text": " rapidly organizing data, turning fuzzy inputs into structured outputs, there's a lot that they're", "tokens": [51216, 12910, 17608, 1412, 11, 6246, 34710, 15743, 666, 18519, 23930, 11, 456, 311, 257, 688, 300, 436, 434, 51448], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 515, "seek": 254136, "start": 2563.04, "end": 2567.04, "text": " good at that we're bad at and we should use them for those things. There's tons that like we're", "tokens": [51448, 665, 412, 300, 321, 434, 1578, 412, 293, 321, 820, 764, 552, 337, 729, 721, 13, 821, 311, 9131, 300, 411, 321, 434, 51648], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 516, "seek": 254136, "start": 2567.04, "end": 2570.96, "text": " good at they're not that we're still trying to like make them do like checking claims against", "tokens": [51648, 665, 412, 436, 434, 406, 300, 321, 434, 920, 1382, 281, 411, 652, 552, 360, 411, 8568, 9441, 1970, 51844], "temperature": 0.0, "avg_logprob": -0.12879948318004608, "compression_ratio": 1.8713826366559485, "no_speech_prob": 0.0005816280608996749}, {"id": 517, "seek": 257096, "start": 2570.96, "end": 2576.48, "text": " physical reality, long-term memory, having embodied knowledge, understanding social context,", "tokens": [50364, 4001, 4103, 11, 938, 12, 7039, 4675, 11, 1419, 42046, 3601, 11, 3701, 2093, 4319, 11, 50640], "temperature": 0.0, "avg_logprob": -0.11659796454689719, "compression_ratio": 1.6758620689655173, "no_speech_prob": 0.0005725689115934074}, {"id": 518, "seek": 257096, "start": 2576.48, "end": 2581.44, "text": " having emotional intelligence, I think combining the two of these so that we're doing things models", "tokens": [50640, 1419, 6863, 7599, 11, 286, 519, 21928, 264, 732, 295, 613, 370, 300, 321, 434, 884, 721, 5245, 50888], "temperature": 0.0, "avg_logprob": -0.11659796454689719, "compression_ratio": 1.6758620689655173, "no_speech_prob": 0.0005725689115934074}, {"id": 519, "seek": 257096, "start": 2581.44, "end": 2586.32, "text": " can't do and they're doing things we're not very good at actually leverages the best of both worlds.", "tokens": [50888, 393, 380, 360, 293, 436, 434, 884, 721, 321, 434, 406, 588, 665, 412, 767, 12451, 1660, 264, 1151, 295, 1293, 13401, 13, 51132], "temperature": 0.0, "avg_logprob": -0.11659796454689719, "compression_ratio": 1.6758620689655173, "no_speech_prob": 0.0005725689115934074}, {"id": 520, "seek": 257096, "start": 2587.36, "end": 2591.28, "text": " Because a lot of AI researchers in the moment, they use this metaphor of aliens, this is from", "tokens": [51184, 1436, 257, 688, 295, 7318, 10309, 294, 264, 1623, 11, 436, 764, 341, 19157, 295, 21594, 11, 341, 307, 490, 51380], "temperature": 0.0, "avg_logprob": -0.11659796454689719, "compression_ratio": 1.6758620689655173, "no_speech_prob": 0.0005725689115934074}, {"id": 521, "seek": 257096, "start": 2591.28, "end": 2597.76, "text": " the 1970s alien film or frightening, it just it makes me think this is like not the most appealing", "tokens": [51380, 264, 14577, 82, 12319, 2007, 420, 31043, 11, 309, 445, 309, 1669, 385, 519, 341, 307, 411, 406, 264, 881, 23842, 51704], "temperature": 0.0, "avg_logprob": -0.11659796454689719, "compression_ratio": 1.6758620689655173, "no_speech_prob": 0.0005725689115934074}, {"id": 522, "seek": 259776, "start": 2597.76, "end": 2602.96, "text": " collaborative partner this metaphor, this like big scary unknown consciousness that like might", "tokens": [50364, 16555, 4975, 341, 19157, 11, 341, 411, 955, 6958, 9841, 10081, 300, 411, 1062, 50624], "temperature": 0.0, "avg_logprob": -0.11224511953500602, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.005225527100265026}, {"id": 523, "seek": 259776, "start": 2602.96, "end": 2608.88, "text": " kill you, but there's another metaphor that I like more that Kate Darling is a robotics researcher", "tokens": [50624, 1961, 291, 11, 457, 456, 311, 1071, 19157, 300, 286, 411, 544, 300, 16251, 38697, 307, 257, 34145, 21751, 50920], "temperature": 0.0, "avg_logprob": -0.11224511953500602, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.005225527100265026}, {"id": 524, "seek": 259776, "start": 2608.88, "end": 2613.36, "text": " at MIT and she wrote this book called The New Breed, arguing we should think about robots as", "tokens": [50920, 412, 13100, 293, 750, 4114, 341, 1446, 1219, 440, 1873, 7090, 292, 11, 19697, 321, 820, 519, 466, 14733, 382, 51144], "temperature": 0.0, "avg_logprob": -0.11224511953500602, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.005225527100265026}, {"id": 525, "seek": 259776, "start": 2613.36, "end": 2618.48, "text": " animals, we have a long cultural legal history with animals and working collaboratively with them,", "tokens": [51144, 4882, 11, 321, 362, 257, 938, 6988, 5089, 2503, 365, 4882, 293, 1364, 16555, 356, 365, 552, 11, 51400], "temperature": 0.0, "avg_logprob": -0.11224511953500602, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.005225527100265026}, {"id": 526, "seek": 259776, "start": 2618.48, "end": 2624.2400000000002, "text": " oxen, dogs, pigs, right in this very like mutually beneficial relationship most of the time and this", "tokens": [51400, 5976, 268, 11, 7197, 11, 24380, 11, 558, 294, 341, 588, 411, 39144, 14072, 2480, 881, 295, 264, 565, 293, 341, 51688], "temperature": 0.0, "avg_logprob": -0.11224511953500602, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.005225527100265026}, {"id": 527, "seek": 262424, "start": 2624.24, "end": 2628.4799999999996, "text": " is actually a pretty good metaphor to expand to AI where we have to kind of treat them a little bit", "tokens": [50364, 307, 767, 257, 1238, 665, 19157, 281, 5268, 281, 7318, 689, 321, 362, 281, 733, 295, 2387, 552, 257, 707, 857, 50576], "temperature": 0.0, "avg_logprob": -0.1224489128380491, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00014702156477142125}, {"id": 528, "seek": 262424, "start": 2628.4799999999996, "end": 2634.24, "text": " like some form of intelligent species but one that we are in community with and are part of our", "tokens": [50576, 411, 512, 1254, 295, 13232, 6172, 457, 472, 300, 321, 366, 294, 1768, 365, 293, 366, 644, 295, 527, 50864], "temperature": 0.0, "avg_logprob": -0.1224489128380491, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00014702156477142125}, {"id": 529, "seek": 262424, "start": 2634.24, "end": 2639.6, "text": " systems and are not this like big scary alien who might come kill us all is like usually what it", "tokens": [50864, 3652, 293, 366, 406, 341, 411, 955, 6958, 12319, 567, 1062, 808, 1961, 505, 439, 307, 411, 2673, 437, 309, 51132], "temperature": 0.0, "avg_logprob": -0.1224489128380491, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00014702156477142125}, {"id": 530, "seek": 262424, "start": 2639.6, "end": 2646.72, "text": " gets talked about as. So yeah there's this big push for this philosophical approach, some people", "tokens": [51132, 2170, 2825, 466, 382, 13, 407, 1338, 456, 311, 341, 955, 2944, 337, 341, 25066, 3109, 11, 512, 561, 51488], "temperature": 0.0, "avg_logprob": -0.1224489128380491, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00014702156477142125}, {"id": 531, "seek": 262424, "start": 2646.72, "end": 2650.72, "text": " call it cyber-organism, there's a very long article there was a written on less wrong which is not", "tokens": [51488, 818, 309, 13411, 12, 12372, 1434, 11, 456, 311, 257, 588, 938, 7222, 456, 390, 257, 3720, 322, 1570, 2085, 597, 307, 406, 51688], "temperature": 0.0, "avg_logprob": -0.1224489128380491, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00014702156477142125}, {"id": 532, "seek": 265072, "start": 2650.72, "end": 2655.4399999999996, "text": " my favorite website but it's a good article that kind of goes in depth into this if you do want", "tokens": [50364, 452, 2954, 3144, 457, 309, 311, 257, 665, 7222, 300, 733, 295, 1709, 294, 7161, 666, 341, 498, 291, 360, 528, 50600], "temperature": 0.0, "avg_logprob": -0.12533829793208787, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.003281228942796588}, {"id": 533, "seek": 265072, "start": 2655.4399999999996, "end": 2661.68, "text": " to read more about it. So that's all I have, I want to thank you so much for listening, again", "tokens": [50600, 281, 1401, 544, 466, 309, 13, 407, 300, 311, 439, 286, 362, 11, 286, 528, 281, 1309, 291, 370, 709, 337, 4764, 11, 797, 50912], "temperature": 0.0, "avg_logprob": -0.12533829793208787, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.003281228942796588}, {"id": 534, "seek": 265072, "start": 2661.68, "end": 2668.64, "text": " slide the notes on this QR code if you like missed anything, I'm on Twitter X at mappleton still", "tokens": [50912, 4137, 264, 5570, 322, 341, 32784, 3089, 498, 291, 411, 6721, 1340, 11, 286, 478, 322, 5794, 1783, 412, 463, 427, 14806, 920, 51260], "temperature": 0.0, "avg_logprob": -0.12533829793208787, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.003281228942796588}, {"id": 535, "seek": 265072, "start": 2668.64, "end": 2673.9199999999996, "text": " until that really does fall apart and you can DM me there, you can message me again I love meeting", "tokens": [51260, 1826, 300, 534, 775, 2100, 4936, 293, 291, 393, 15322, 385, 456, 11, 291, 393, 3636, 385, 797, 286, 959, 3440, 51524], "temperature": 0.0, "avg_logprob": -0.12533829793208787, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.003281228942796588}, {"id": 536, "seek": 265072, "start": 2673.9199999999996, "end": 2678.8799999999997, "text": " people through writing on the web if you have blogs that like relate to these kind of topics", "tokens": [51524, 561, 807, 3579, 322, 264, 3670, 498, 291, 362, 31038, 300, 411, 10961, 281, 613, 733, 295, 8378, 51772], "temperature": 0.0, "avg_logprob": -0.12533829793208787, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.003281228942796588}, {"id": 537, "seek": 267888, "start": 2678.88, "end": 2690.88, "text": " send them to me but yeah thank you so much for listening, I appreciate it.", "tokens": [50364, 2845, 552, 281, 385, 457, 1338, 1309, 291, 370, 709, 337, 4764, 11, 286, 4449, 309, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3613626003265381, "compression_ratio": 1.0136986301369864, "no_speech_prob": 0.024979835376143456}], "language": "en"}