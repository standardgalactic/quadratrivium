WEBVTT

00:00.000 --> 00:16.480
Hi, thank you. Thank you so much for having me. I'm very excited to not tell you how AI

00:16.480 --> 00:22.320
is going to save us all. This talk is called The Expanding Dark Forest in Generative AI.

00:22.320 --> 00:27.360
It's going to be about writing on the web, trust, and human relationships, so like small

00:27.360 --> 00:33.520
fish. And also AI, unfortunately, I'm sorry. There always has to be one AI talk at every

00:33.520 --> 00:36.760
conference at this point, but at least you get me and not someone telling you how it's

00:36.760 --> 00:41.920
going to take all your jobs. So I only give a footnote with this talk where I say, well,

00:41.920 --> 00:45.560
this talk is up to date as of about a week ago, as of about Monday. So anything that's

00:45.560 --> 00:50.160
happened since Monday, I can't take accountability for. It's probably all out of date by now,

00:50.160 --> 00:55.680
but this is the state of the AI industry. So first some context. This is me. I look

00:55.760 --> 01:00.960
like this on the internet. My name is Maggie. I am a designer at an AI research lab called

01:00.960 --> 01:06.840
ELICIT. We do use language models to help scientists and researchers do literature review,

01:06.840 --> 01:11.080
which is a long, boring task, creating many thousands of PDFs, and this is something that

01:11.080 --> 01:16.560
language models are actually quite good at helping with. I also am very online. I'm

01:16.560 --> 01:22.120
very on Twitter, X, whatever you want to call it. I write a lot online, and this has led

01:22.160 --> 01:26.520
to lots of really positive relationships, a lot of really good career success, and this

01:26.520 --> 01:30.520
will become relevant later as to why I care so much about people in the future being able

01:30.520 --> 01:36.680
to do that, to be able to write online and connect with others by writing online.

01:36.680 --> 01:40.880
I'm also a cultural anthropologist. I originally trained in this for my undergraduate degree

01:40.880 --> 01:45.360
before becoming a designer because you can't get paid much to be a cultural anthropologist,

01:45.360 --> 01:50.160
but a lot of theory I learned there plays back into my thoughts on design and development

01:50.360 --> 01:56.960
and how we build things on the web. If you want to take notes on things, you can also

01:56.960 --> 02:01.040
just scan this QR code, and this whole talk is transcribed with slides and everything

02:01.040 --> 02:05.520
on this link, so don't worry about taking pictures of slides you like or trying to remember

02:05.520 --> 02:08.800
what I said. You can reference it later. I might have to update it a bit because the

02:08.800 --> 02:14.680
talk evolves, but one version that's mostly the same is on that QR code.

02:14.680 --> 02:19.440
Here's what I'm going to talk about. First, we're going to talk about the dark forest

02:19.480 --> 02:24.520
theory of the web. What is that? Next, I'm going to talk about the state of generative

02:24.520 --> 02:31.640
AI as of a week ago. I'm third going to present some problems, and then we can kind of talk

02:31.640 --> 02:34.320
about whether they actually are problems. We can question whether we think they're legitimate

02:34.320 --> 02:39.760
or not. Lastly, I'm going to talk about possible futures, so how to deal with all these hypothetical

02:39.760 --> 02:46.480
problems that I present. First, to explain the dark forest theory of the web, I'm first

02:46.520 --> 02:52.360
going to have to explain the dark forest theory of the universe. This is a theory that tries

02:52.360 --> 02:58.040
to explain why we haven't found intelligent life in the universe. Here we are in the universe,

02:58.040 --> 03:03.520
the pale blue dot, and as far as we know, we are the only intelligent life around. We've

03:03.520 --> 03:08.720
been beaming out messages for like 60 years now with like SETI, trying to find other intelligent

03:08.720 --> 03:12.560
life, trying to see if there are aliens or some other kind of being that could respond

03:12.600 --> 03:19.600
to us. We haven't heard anything back. The big question here is why. Dark forest theory

03:19.840 --> 03:25.320
says it's because the universe is like a dark forest at night. It's a place that seems

03:25.320 --> 03:32.320
quiet and lifeless because if you make noise, the predators come eat you. If you draw attention

03:32.320 --> 03:37.040
to yourself, you're going to be attacked and destroyed. It stands to reason that all the

03:37.040 --> 03:41.800
other intelligent civilizations that may or may not exist have either died or learned

03:41.840 --> 03:48.520
to shut up. And we don't know which one we are yet. So the web version of this builds

03:48.520 --> 03:53.800
off this concept. It's a theory that was proposed by Nancy Strickler, who's a really good thinker

03:53.800 --> 03:59.280
and writer back in 2019. And Nancy wrote this article describing what it feels like to be

03:59.280 --> 04:04.760
in public spaces on the web around this time. And Nancy pointed out these two main vibes,

04:04.760 --> 04:10.400
let's say. And the first is that being on the web often feels like a very lifeless, automated

04:10.480 --> 04:16.320
place that's devoid of humans. It's got all this ads and click bait and predatory behaviors

04:16.320 --> 04:19.640
and none of it feels like real humans are trying to connect with us on the web. It just

04:19.640 --> 04:25.520
feels commercial. The second vibe, actually, here, so here we are on the web, right? And

04:25.520 --> 04:31.320
we are naively writing a bunch of very sincere, authentic accounts of our lives and thoughts

04:31.320 --> 04:36.040
and experiences and trying to make connections to the other intelligent humans. We're sending

04:36.080 --> 04:41.560
out messages, trying to beam out life. But then what we hear in response is content that

04:41.560 --> 04:47.400
seems very inauthentic and human. It sounds like a bunch of robots and automations doing

04:47.400 --> 04:52.520
marketing automations and growth hacking, kind of pumping out generic click bait. So we've

04:52.520 --> 04:57.800
seen all this stuff, right? This is like low-quality listicles, right? Productivity rubbish, growth

04:57.800 --> 05:03.560
hacking advice, you know, banal motivational quotes, dramatic click bait. Like, a lot of

05:03.600 --> 05:08.080
this may as well be automated, even if a human didn't make it in some sense, right? They're

05:08.080 --> 05:12.840
rarely trying to communicate some sincere original of thought to other humans. They're

05:12.840 --> 05:17.680
trying to get you to click, right, and rack up some views. And this flood of really low-quality

05:17.680 --> 05:23.160
content has made us retreat away from the public spaces of the web. It's very costly for us

05:23.160 --> 05:29.200
to spend time and energy wading through all this craft. So the second vibe of the dark web is

05:29.280 --> 05:36.000
that there's a lot of unnecessarily antagonistic behavior at a large scale. So when we are putting

05:36.000 --> 05:40.800
out all these signals, right, trying to authentically connect to other humans, we could become a

05:40.800 --> 05:47.840
target, right? We risk the Twitter mob coming to eat us is what can happen. So there's a term on

05:47.840 --> 05:52.000
Twitter called getting main character. I don't know if people have heard of this. And I don't

05:52.000 --> 05:56.240
know if people remember, this is one year ago, Garden Lady. This was a very famous tweet, if

05:56.320 --> 06:01.360
everyone saw this one, where this really lovely woman got on Twitter one morning and she said,

06:01.360 --> 06:05.520
my husband and I wake up every morning and we bring our coffee out to the garden and we sit and

06:05.520 --> 06:09.280
talk for hours and it never gets old and we never run out of things to talk about and I love him

06:09.280 --> 06:14.320
so much. And everyone's like, that's such a nice tweet. That's so wonderful. And then this went

06:14.320 --> 06:20.160
viral. They got picked up and the Twitter reply started rolling in. So someone said, that's cool.

06:20.160 --> 06:24.320
I wake up every morning and fight my wavy traffic for an hour in Miami to get to work. That must be

06:24.320 --> 06:30.320
nice. Someone else, I wake up at 6am, right? This is an unattainable goal for most people. Not

06:30.320 --> 06:35.680
that she said it was a goal, but interpret it as you will. Another one, again, complaining about

06:35.680 --> 06:39.440
the morning routine and then goes, it must be nice being a trust fund baby with not a care in the

06:39.440 --> 06:46.000
world. So I thought this tech talk summed it up nicely. I don't care if something good happened

06:46.000 --> 06:52.080
to you. It should have happened to me instead. So this seems like a dumb example, but it was a

06:52.080 --> 06:56.320
really good moment on Twitter that shows kind of the energy flows that happen on these really

06:56.320 --> 07:01.360
large-scale social media platforms, right? Someone can publish something that's very kind and nice

07:01.360 --> 07:06.160
and it gets interpreted the wrong way. People take it in bad faith. They take it out of context.

07:06.160 --> 07:10.880
They try to amplify it to unintended audiences. We will take every opportunity to misinterpret

07:10.880 --> 07:15.440
things and be ungenerous to each other. And this is how we get cancelling some pylons and we've

07:15.440 --> 07:21.600
all seen so many examples of this happening in what seems like a very unfair way. John Ronson

07:21.600 --> 07:24.960
wrote an entire book about this called You've Been Publicly Shamed. The catalog is quite a

07:24.960 --> 07:29.520
few of these. It's a little out of date now, but it's a lot of kind of classic original examples

07:29.520 --> 07:34.400
of people getting cancels. And then the real material consequences they fix, right? They lose

07:34.400 --> 07:39.200
jobs. They lose friends. They are alienated from their community. It is not just internet drama.

07:39.200 --> 07:44.960
They really do have to face repercussions for these pylons. And so this makes the web a very

07:44.960 --> 07:49.200
sincerely dangerous place to sincerely publish your thoughts, to publish honest things on.

07:51.600 --> 07:55.520
And this makes it hard to find people, right? It's very difficult to find people who are being

07:55.520 --> 08:00.400
sincere, who are seeking coherence and who are trying to build collective knowledge in public.

08:01.360 --> 08:05.520
I know this is not what everyone wants to do with the web, right? Like some people just want to

08:05.520 --> 08:10.240
dance on TikTok and that's completely fine. We have to let them do that. But I'm interested in

08:10.240 --> 08:16.000
at least some of the web enabling this kind of productive discourse and having spaces of community

08:16.000 --> 08:20.800
building and I'm hoping some people here feel the same, right? Rather than it being like this

08:20.800 --> 08:26.000
threatening inhuman place where you can't actually say what you think. So how do we cope with this,

08:26.000 --> 08:31.440
right? We're all wandering around this dark forest of like Facebook and LinkedIn and Twitter

08:31.440 --> 08:36.640
and we realize we need to go somewhere safer. So what we end up doing is we retreat primarily to

08:36.640 --> 08:43.120
what's being called the cozy web. So this was a term coined by Venkatesh Rao in direct response

08:43.120 --> 08:49.040
to the dark web theory. And Venkat pointed out that we've all started going underground. We move

08:49.040 --> 08:54.240
into semi-private spaces like newsletters or personal websites where you're less at risk of

08:54.240 --> 08:59.520
attack. You're not on these big platforms. You're on your own separate domain or you're on your own

08:59.520 --> 09:04.720
separate newsletter. So this gives us some safety. We can at least decide a little bit who reads it

09:04.720 --> 09:10.800
and understand our audience. But we often retreat even further into gate kept spaces like slacks,

09:10.800 --> 09:16.080
WhatsApps, Discord, Signal groups, right? This is where we end up spending the most of our time

09:16.080 --> 09:21.280
and having real human relationships where we can express our ideas safely, right? So things

09:21.280 --> 09:26.080
that we say we know will be taken in good faith in these smaller groups. We can engage in real

09:26.080 --> 09:31.200
discussions. But there's some problems here, right? Like none of this is indexable or searchable.

09:31.200 --> 09:37.040
It's very hard to include people who aren't already in the group. And it hides collective

09:37.040 --> 09:40.720
knowledge in these private databases that are even hard for the users themselves to access.

09:41.440 --> 09:45.120
And also like good luck finding anything on Discord. Like you'll never be able to use the

09:45.120 --> 09:52.080
search functionality in these apps. So my current theory, sadly, is that the dark forest is about

09:52.080 --> 09:59.280
to expand because we now have this thing called generative AI. So I'm sure everyone has mostly

09:59.280 --> 10:03.120
heard of this, but what I'm talking about specifically here is machine learning models

10:03.120 --> 10:08.080
and neural networks that can create content that before this point in history only humans could

10:08.080 --> 10:14.320
make, right? This is text, images, audio and video that mimics human creations in a very

10:14.320 --> 10:20.000
compelling and believable way. Here are kind of some of the major foundational models that you

10:20.000 --> 10:25.360
might have heard of for different media types, right? We have GPT4 and clod for text, mid-journey

10:25.360 --> 10:30.080
and stable diffusion for images. There's now video ones like runway ML. And you might have

10:30.080 --> 10:34.560
heard some of the news that a lot of these models are now becoming multimodal so they can do text

10:34.560 --> 10:39.600
to image, image to text, audio to text. Like you can kind of go anywhere you want with media here.

10:40.560 --> 10:45.360
And this is, of course, chat GPT. I'm sure we've all seen a thousand screenshots of this at this

10:45.360 --> 10:51.040
point. We understand what it is. But to recap, it's right, we know it can generate huge volumes

10:51.040 --> 10:56.480
of high-quality text in seconds. The outputs are indistinguishable from human-made text when we

10:56.480 --> 11:01.680
try to get people to guess what's chat GPT and what's human. They often can't. It's trained on a

11:01.680 --> 11:07.200
huge volume of text scraped primarily from the English-speaking web. And this all sounds very

11:07.200 --> 11:11.680
simple, right? But it leads to many kind of complex and potentially useful behaviors, but it's

11:11.680 --> 11:17.280
very emergent. We don't really understand what's possible because of this capability yet. We can

11:17.280 --> 11:21.360
also now, of course, generate images, right? This is mid-journey, which usually makes pretty

11:21.360 --> 11:27.440
beautiful impressive stuff. But so we found that these, like, generative AI models are now very

11:27.440 --> 11:31.120
easy to use and very widely accessible, right? They don't require technical skills. They're

11:31.120 --> 11:35.520
incredibly cheap. And they're increasingly becoming a feature in existing software you already have

11:35.520 --> 11:38.960
access to, like Adobe or Photoshop or Notion. They're just becoming pervasive.

11:41.200 --> 11:45.360
But the product category that I'm most nervous about, not just, like, Notion generating a plan

11:45.360 --> 11:49.680
for you, is what's being called content generators, mostly for content marketers. So I'm going to pick

11:49.680 --> 11:54.720
on one product, but there are many. This one's called Blaze. And it creates articles and social

11:54.720 --> 11:58.160
media content for you, right? In half the time, who wouldn't want that? Who doesn't want more

11:58.160 --> 12:03.520
content on the internet? And so I want to show you how this works. So you decide what kind of

12:03.520 --> 12:08.640
content you want to make, right? You can say a blog post or a newsletter or a bunch of Twitter posts.

12:08.640 --> 12:12.960
And I'm going to say I want to write a blog post. And you type in what you want to write about,

12:12.960 --> 12:17.040
and your target audience, and SEO keywords. So I've decided I want to write about why

12:17.600 --> 12:20.960
plant-based meat is morally wrong, which I don't believe, but that sounds like a good clickbait

12:20.960 --> 12:23.440
to me. Like, someone's going to be like, yeah, I want to find out why that's bad.

12:24.480 --> 12:28.560
You know, maybe I'm a company that has some financial interest in plant-based meats going

12:28.560 --> 12:33.840
badly. So I'm going to go ahead and have this model write a little article for me. It lets

12:33.840 --> 12:38.640
me pick a title, which is a nice customization. And then it chans out 700 words, right? And this

12:38.640 --> 12:41.840
is now ready for me to hit publish, right? Or at least gives me some base to work off.

12:42.640 --> 12:46.080
And if I'm blobbing against plant-based meats, I can just generate 100 of these, right? And,

12:46.080 --> 12:50.320
like, optimize them for Google SEO and publish them all at once. And, like, hard days out of

12:50.320 --> 12:54.800
Cassie Dunn. Right? The quality and truthfulness of what's written in here is very questionable.

12:54.800 --> 12:59.920
We'll get to problems with that later. But the point is, this is super easy to do at scale

12:59.920 --> 13:04.800
very cheaply. And it essentially murders Google such, right? Like, this just does away with SEO

13:04.800 --> 13:10.880
optimized content. Because anyone can publish this immediately. It gets even better at the end.

13:10.880 --> 13:14.800
Like, it prompts me to generate more content. So it's like, oh, you have this blog post. Why not

13:14.800 --> 13:18.800
generate LinkedIn posts and tweets and YouTube scripts and everything. We're not just getting

13:18.800 --> 13:25.440
crappy Google articles. This is across every publishing platform. Right? So there's tons of

13:25.440 --> 13:28.960
things to do this. There's, like, AI-linked post-generators, generate your next tweet,

13:28.960 --> 13:32.240
right? YouTube content and autopilot, just thousands of these tools are pouring out.

13:34.080 --> 13:38.240
So most of the examples I showed actually have a very simple architecture, right? You have a

13:38.240 --> 13:42.880
single input, like, write me an article on plant-based meat. And you feed it into this big,

13:42.880 --> 13:46.960
black mystery box of a language model, right? And we don't really understand totally what

13:47.040 --> 13:51.120
happens inside, but it gives you an output, right? Rates you an essay. But you can't really tweak

13:51.120 --> 13:55.280
what happened in the middle. You can edit the output, but you can't kind of pull the knobs

13:55.280 --> 14:00.000
on the actual language model itself. Which isn't very sophisticated. We don't have a lot of control

14:00.000 --> 14:04.960
or transparency in what's happening. But the industry has realized this is a problem, and we

14:04.960 --> 14:11.040
started building architectures that are much more flexible and powerful. So we now have a language

14:11.040 --> 14:15.440
model architecture where we take that same black box of the language model, but we give it access

14:15.440 --> 14:18.800
to external tools, right? We say, okay, now we're going to tell it it can search the web through

14:18.800 --> 14:24.720
an API. We give it access to a calculator. We give it access to a code REPL and APIs. It's now

14:24.720 --> 14:30.160
getting a lot more capable, right? It can now look up, can do maths, you know? It can look up

14:30.160 --> 14:35.440
information that things might not be right. It can double check its answers. Also language models

14:35.440 --> 14:38.800
are usually quite forgetful. You might have found this, chat GPT after a long string. We'll forget

14:38.800 --> 14:42.880
what you said earlier on. We can now hook them up to long-term memory databases and have them

14:42.880 --> 14:46.560
reference things like many weeks or months in the past, which makes them a lot more capable.

14:47.680 --> 14:52.160
And we've also found that they perform much better if you give them these cognitive prompts.

14:52.160 --> 14:56.000
Like you tell it to do something, but then you say, you know, think about your answer, critique it,

14:56.000 --> 14:59.440
and then answer me again. And that actually improves the quality of the answer quite a lot.

15:00.080 --> 15:04.960
That's often called chain of thought prompting, self critique. It can observe what it knows and

15:04.960 --> 15:10.240
plan the next step. And it's getting these more cognitive capacities by adding on these kind of

15:11.120 --> 15:16.240
extra techniques. So this is being called the agent architecture, right? You tell the language

15:16.240 --> 15:21.680
model to act like an agent. It ends up as being like the centralized brain and you give it, you

15:21.680 --> 15:27.200
can say you can use any of these tools and then it composes which tools it wants to use to achieve

15:27.200 --> 15:31.520
your goals. So it ends up being a chain like this where you give it your goal, it'll like observe,

15:31.520 --> 15:36.720
it'll plan, it'll call a different tool, it'll observe, it'll plan. And we can actually do really

15:36.800 --> 15:42.240
complex, kind of scarily impressive things when we level up to these more sophisticated architectures.

15:43.360 --> 15:49.680
And actually on Monday, OpenAI did this big dev day talk, I don't know if people saw this,

15:49.680 --> 15:54.480
and they announced a new API called the assistance API that makes all that stuff that I showed that

15:54.480 --> 15:59.040
used to require quite a lot of Python code and kind of insider knowledge, and they're just making

15:59.040 --> 16:03.040
it super easy for everyone to now do this architecture, where you're able to kind of

16:03.120 --> 16:06.960
run any function, call any API, all hooked up to their really powerful models.

16:07.760 --> 16:11.920
So we're about to enter this phase where this very capable agent architecture is becoming

16:11.920 --> 16:16.080
pervasive and widespread and might be the foundation of a lot of new tools being built.

16:16.080 --> 16:19.680
So we're sort of on the precipice of really unnerving moment, let's say.

16:21.120 --> 16:26.160
Because agent architectures, I think, means we're about to enter a stage of sharing the web with

16:26.160 --> 16:31.520
non-human agents, right? These agents are very different to what we've currently noticed bots

16:31.520 --> 16:34.640
in the past, like a completely different architecture and set of capabilities.

16:35.520 --> 16:39.040
They're going to have a lot more data on how realistic humans behave,

16:39.040 --> 16:41.680
and they're rapidly going to get more and more capable as time goes on.

16:42.480 --> 16:46.880
And soon, probably already now, we're not going to be able to tell difference between

16:46.880 --> 16:52.080
these agents and real humans. If anyone else spends a lot of time on Twitter slash X,

16:52.080 --> 16:55.920
you'll already have noticed there's a lot of accounts you stumble across that have a weird

16:55.920 --> 17:00.400
vibe to them, and you definitely realize this is just chat GPT hooked up to a Twitter account,

17:00.400 --> 17:05.440
but otherwise is trying to look real, but like every tweet is very optimized and comes back in

17:05.440 --> 17:09.920
like a second. It's just replying to things, you know, three seconds later. So it's happening.

17:11.120 --> 17:14.400
And sharing the web, I want to say with agents, I don't want to jump to saying this is like

17:14.400 --> 17:18.320
inherently bad. I think they could have lots of good use cases, right? We could have

17:18.320 --> 17:23.120
automated moderators in communities. We could have search assistants, but I think it's mostly

17:23.120 --> 17:26.960
that it's going to get complicated, and this is going to be a huge product and cultural problem

17:26.960 --> 17:32.480
we're going to need to think about carefully and deal with. So we should get into why is this

17:32.480 --> 17:37.840
a problem for the web, right? I'm only going to focus on how this will affect human relationships

17:37.840 --> 17:43.360
and information quality on the web. Anything else, like how we might all end up unemployed or dead

17:43.360 --> 17:48.320
soon is like well beyond my pay grade, so I'm just limiting the space to just like how do we

17:48.880 --> 17:52.640
make meaningful human connections and find a good quality content on the web.

17:53.600 --> 17:59.440
Because, yeah, the cost of creating and publishing content just dropped to almost zero at this point,

18:00.080 --> 18:05.760
right? Like humans are quite expensive and slow at making content, right? We need time to research

18:05.760 --> 18:10.320
and think, and we like clumsily string words together, and then we want to take breaks,

18:10.320 --> 18:15.200
and we want to be able to nap and eat and sleep, and then we demand people pay us like

18:15.200 --> 18:20.880
extraordinary rates, right, to do this research. And generative models don't need time off,

18:20.880 --> 18:24.240
and they don't get bored, and they cost like a couple fractions of a cent to write a few thousand

18:24.240 --> 18:30.480
words. So given the dynamics here, it's very likely that models are going to become the main

18:30.480 --> 18:37.440
generators of content online. So I think we're about to drown in a sea of informational garbage,

18:37.440 --> 18:42.320
right? I think we're just going to be absolutely swamped in masses of mediocre content. Like every

18:42.320 --> 18:46.240
marketer and SEO strategist and optimizer bro is just going to have a field day here, you know,

18:46.240 --> 18:51.760
just filling the whole internet with all of their keyword stuff, optimized crap. And this explosion

18:51.760 --> 18:56.320
of noise is going to make it really difficult to find both good quality people, real people,

18:56.320 --> 19:01.680
and good quality content, and hear any signal through the noise. And we can tell this is

19:01.680 --> 19:05.520
happening because scammers and scammers are currently quite lazy, and we're kind of in the

19:05.520 --> 19:10.880
baby phases of this. So there's a phrase that you might have seen chat GPT reply with. It sometimes

19:10.880 --> 19:15.040
says, as an AI language model, I do not have political beliefs, or as an AI language model,

19:15.120 --> 19:19.600
I cannot answer that question. And this phrase, if you search and direct quotes for it around the

19:19.600 --> 19:25.360
web, shows up everywhere, just like Amazon, Google, Yelp reviews, tweets, LinkedIn posts,

19:25.360 --> 19:29.200
it's full of this phrase, because people can't be bothered to like control F and like delete the

19:29.200 --> 19:34.720
one phrase that gives them away. All right. So I did a quick search for this on LinkedIn, it got

19:34.720 --> 19:40.720
16,000 hits, and they're like really boring attempts to like write engaging content, but they

19:40.720 --> 19:45.440
all begin with the phrase as an AI language model. Look in the first sentence. And these are real

19:45.440 --> 19:48.880
people too. I did look at their profiles. They genuinely have jobs, and they're trying to optimize

19:48.880 --> 19:55.680
their presence or something. But yeah, this is starting to happen. The motivation for doing

19:55.680 --> 19:59.840
this rate isn't hard to understand. So let's like think of the hypothetical scenario. So this is

19:59.840 --> 20:05.360
Nigel. He's written a book about why nepotism is great, right? And he wants to be a book fluencer.

20:05.360 --> 20:09.280
He's like, it's his first book, he's self-published on Amazon, he wants to like, you know, become a

20:09.280 --> 20:14.080
big book guy. So he spends up an agent, right? Not unlike an actual publishing agent. He might have

20:14.080 --> 20:20.400
hired in the past. And he says, hey, like, help me promote my book, you know? And so the agent

20:20.400 --> 20:25.520
thinks for a while, and it goes off, and it strategizes, and it generates a steady stream

20:25.520 --> 20:28.880
of tweets, right, based about on the content of the book, like real insights from the book,

20:28.880 --> 20:32.000
and it starts tweeting those out from Nigel's account, and he's given it access, you know?

20:33.120 --> 20:36.560
And it goes and it does the same thing for LinkedIn and Facebook, you know, pretty easy.

20:37.520 --> 20:41.680
And then it writes and schedules a newsletter to go out over the course of six months so that

20:41.680 --> 20:45.920
his followers will always kind of get updates on new things he's researching. It sets up a

20:45.920 --> 20:50.480
medium account, it reposts those as articles, right? Makes a set of addictive TikTok videos

20:50.480 --> 20:55.120
based on that content, generates a bunch of podcast episodes, use Nigel's voice. We can

20:55.120 --> 21:00.480
totally do that now. It's pretty easy. And then it finds a bunch of other people who like are

21:00.480 --> 21:04.720
talking about nepotism and starts replying to them on LinkedIn and Twitter and making friends,

21:04.720 --> 21:08.320
and maybe they're actually agents interacting with it, and like, it's a whole bunch of just

21:09.440 --> 21:14.240
agents interacting with agents. And none of this is different to what Nigel could do on his own.

21:14.240 --> 21:20.240
So we don't know that content moderation or spam filters are actually going to pick this

21:20.240 --> 21:24.960
stuff up, because maybe it's tweeting it slow enough that a human could have done it,

21:24.960 --> 21:28.080
and it really is in Nigel's voice. It's used his writing to write this content.

21:28.640 --> 21:31.840
We don't necessarily have automated ways to filter any of this out.

21:32.640 --> 21:37.840
And the thing is, without an agent, 99% of Nigel-type people wouldn't have gone to all

21:37.840 --> 21:42.160
this effort. They don't have the time and energy to have made all this content. But with the agent,

21:42.720 --> 21:49.040
suddenly, we have people like Nigel, but times 99 of them, able to create this amount of content

21:49.040 --> 21:53.120
all the time. And this is how we kind of get the flood of just tons of content more than we can

21:53.120 --> 21:59.120
really cope with. So the scale and the quality of the content is actually what's different here.

21:59.360 --> 22:03.120
Strangely enough, it might have written better stuff than Nigel ever would. We might have way

22:03.120 --> 22:08.240
better quality content about nepotism all over the internet. But you can imagine how this would

22:08.240 --> 22:14.080
play out at another 100x scale, right, with political lobbying groups who have very vested

22:14.080 --> 22:19.840
interests in certain ideas or beliefs or truths getting out into the world. Specific agendas,

22:20.560 --> 22:24.640
large companies that want you to believe certain things about their product or certain things

22:24.640 --> 22:29.280
about scientific claims. They all have access to these assistants and agents, too.

22:30.720 --> 22:33.600
So I do have some good news. Like, this has all been a bit dark, a bit of a downer.

22:34.560 --> 22:39.200
The good news is that this might not be a problem. Maybe this is all just fine, right?

22:39.920 --> 22:43.840
This is only a problem if we want to use the web for very particular purposes,

22:44.640 --> 22:51.120
such as facilitating genuine human relationships or pursuing collective sense-making and knowledge

22:51.120 --> 22:58.160
building or grounding our knowledge of the world in reality. So we don't care about any of these

22:58.160 --> 23:02.560
things. This is all fine. We're going to have amazing content on TikTok. We're going to be

23:02.560 --> 23:08.720
very entertained. The thing is, I'm quite keen on a lot of these outcomes. I write on the web a

23:08.720 --> 23:13.360
lot. I've had overwhelmingly positive experiences writing on the web and meeting people for doing

23:13.360 --> 23:18.800
that. I have this whole thing called digital gardening I bang on about, about making everyone

23:18.800 --> 23:23.440
publish their unfinished notes to the web and improve them over time and use that as a way

23:23.440 --> 23:28.880
to meet people interested in what you're interested in. But, yeah, the goal of that stuff is to make

23:29.680 --> 23:33.120
the web a space where that's possible for collective understanding and knowledge building.

23:33.760 --> 23:37.520
And I'm really worried that generative agents like meaningfully threaten this in the very near

23:37.520 --> 23:41.120
term, like the six to 12 month kind of time range. I can't even think beyond that.

23:43.120 --> 23:46.560
So when I talk to people about my worries, I talk to a lot of people in the AI safety and

23:46.640 --> 23:51.680
research world. They kind of go, why does it matter? My AI agent is going to make much better

23:51.680 --> 23:55.840
content than you ever would. Why do you care that an agent made it and not a human? I'm like,

23:55.840 --> 23:59.760
okay, let's engage with that question properly. I'm sympathetic to that point.

24:01.680 --> 24:04.160
So here's the reasons that generated content is a little bit different, right?

24:04.800 --> 24:09.360
The first is its connection to reality. The second is the social context they live within.

24:10.080 --> 24:13.840
And the third is its potential for human relationships. And I'm going to go into

24:13.840 --> 24:19.680
these in detail. So first, generated content, you probably have heard of this, is different

24:19.680 --> 24:24.320
because it has a different relationship to reality than we do, right? We are embodied humans,

24:24.320 --> 24:28.480
right? And we are sharing a physical reality. And we have all this rich embodied information,

24:28.480 --> 24:31.760
like we all understand we're in this kind of beautiful theater and we're in Brighton and we

24:31.760 --> 24:37.680
have a lot of physical embodied context about what we know about each other. And often what we're

24:37.680 --> 24:41.200
doing on the web is we're reading other people's accounts of this reality and we compare it against

24:41.200 --> 24:45.200
our own and we're like, do I agree with that? Is that really true? This is like the cycle of all

24:45.200 --> 24:49.600
of art and science and literature, you know, reading and comparing and writing your own version of

24:49.600 --> 24:56.160
things. And what we've done now is we've fed that huge trove of information into a neural network

24:56.160 --> 25:00.880
or a large language model. And it's created a sort of representation of that text, right? It's

25:00.880 --> 25:04.560
created a model of the things that we've already known about the world and have published to the

25:04.560 --> 25:09.360
web. And the thing is that model can now generate text that's predictably similar to what it was

25:09.360 --> 25:15.040
before, but it's totally unhinged from the physical reality that it once came from, right? It has

25:15.040 --> 25:19.440
some big connection. It did come from there. There's like a chain here, but it fully like cannot

25:19.440 --> 25:24.400
access that reality, right? Even if we put in robots, right, with like arms and eyes and ears,

25:24.400 --> 25:29.680
it can't sense the world the way we sense the world until we make like a fully synthetic like

25:29.680 --> 25:33.760
mimicry human that like is hooked up to a language model. But I think like 10 years away, I don't know,

25:33.760 --> 25:38.240
I think we have some time. Right, it can't validate its claims. It's the big thing.

25:40.000 --> 25:43.440
We politely call this hallucination, right? This is when language models say things that aren't

25:43.440 --> 25:47.920
true about the world. We say it's hallucinating, right? Like it's some side kind of very smart

25:47.920 --> 25:51.760
person on some like mild drugs who's confused about like who they are or where they are,

25:51.760 --> 25:55.360
but they're saying very intelligent things. You're sort of holding them lightly, you know?

25:57.200 --> 26:01.120
Language models are also different because they have a very different social context, right?

26:01.120 --> 26:05.360
They have a very strange relationship to our social world. So hopefully you know this, but

26:05.360 --> 26:10.400
everything you and I say is situated in a social context, right? We understand what we share in

26:10.400 --> 26:13.920
common. And if you met someone who spoke a different language from a different culture,

26:13.920 --> 26:17.680
you would not assume they thought the same things about the world that you would if you met someone

26:17.680 --> 26:22.880
from your own neighborhood, right? If one of us met someone from like the Kenzie in England,

26:22.880 --> 26:27.360
we would have very different understandings of like hygiene and science and like how the world

26:27.360 --> 26:30.800
works. We would know some things in common. We technically speak the same language,

26:30.800 --> 26:34.240
but we would know that we didn't have a shared social context in the same way.

26:36.080 --> 26:41.280
But a language model is not a person and it does not have a fixed reality, right? They know nothing

26:41.280 --> 26:45.760
about the cultural context of who they're talking to and they take on different characters depending

26:45.760 --> 26:50.320
on what you tell them to do. You can say, you know, pretend to be a professor, pretend to be an

26:50.320 --> 26:54.880
athlete, pretend to be a young child and it will take on that character. So it doesn't even have

26:54.880 --> 27:01.040
a fixed place it's talking to you from in the way that a human does. But they do represent a very

27:01.040 --> 27:06.880
particular way of seeing the world because we trained them primarily on text on the web that

27:06.880 --> 27:13.520
was generated by a majority English-speaking, like 95% of the training data is English-speaking,

27:14.560 --> 27:19.200
a primarily English-speaking westernized population, people who have mostly written a

27:19.200 --> 27:25.360
lot on Reddit and lived between about 1900 and 2023, which like in the grand scheme of history

27:25.360 --> 27:31.680
and geography is a very narrow slice of humanity, right? Of all possible cultures we've had in the

27:31.680 --> 27:36.800
past, all possible cultures we could have in the future and all possible languages. This is just

27:36.800 --> 27:42.000
such a small representation of reality and yet we're now making it the source of truth, right?

27:42.000 --> 27:48.480
The Oracle. You go to chat, GBT to ask everything. So it's taking this already dominant way of

27:48.480 --> 27:52.320
seeing the world and reinforcing that dominance, which is problematic and is like a whole different

27:52.320 --> 27:57.600
talk that I don't even think I'm qualified to do but someone should. And we hope that this will

27:57.600 --> 28:02.400
improve over time but it's really hard to do without lots of data and most cultures don't have the

28:02.400 --> 28:09.520
vast kind of written record that an English-speaking westernized online population does. So lastly,

28:10.320 --> 28:14.560
generated content lacks the potential for human relationships that human-made content does,

28:14.560 --> 28:20.400
right? If you write something online and I read it and I find it compelling, I can DM you on Twitter

28:20.400 --> 28:24.240
or I can find you on Blue Sky or I could find you somehow, ideally hopefully not on LinkedIn,

28:24.240 --> 28:28.160
but somehow and message you and be like, I love this. This was such good ideas. Like I want to

28:28.160 --> 28:32.560
write a piece in response to you and like we start having a little dialogue that I've had so many

28:32.560 --> 28:38.080
relationships blossom this way. But if you have a language model, it's not going to be able to do

28:38.080 --> 28:43.040
that. So this is a still from the film, Her, right? This has become kind of a cultural touch

28:43.040 --> 28:49.040
point of like parasocial relationships with AI. Hopefully people have seen it but if not,

28:49.040 --> 28:53.920
so Joaquin Phoenix, our lovely main character, he has this great relationship with his personal AI,

28:53.920 --> 28:59.760
he talks to her in his ear, it falls in love with her. But then the AI of course grows bored of him

28:59.760 --> 29:06.000
because he's a very kind of basic human and leaves and he's destroyed. And like some people were

29:06.000 --> 29:09.600
supposed to get this like film is supposed to be a warning, right? And some people took it as a

29:09.600 --> 29:18.720
suggestion. So there's a company called replica who make AI companions for you that you can

29:20.000 --> 29:24.400
make friends with, possibly date and fall in love with. There's a lot of suggestions of sort of

29:24.400 --> 29:30.160
lonely young men engaging with this and their marketing copy. And I mean, maybe I do need to

29:30.160 --> 29:36.480
explicitly point this out. An AI replica or any other kind of like generative agent person cannot

29:36.480 --> 29:40.800
fulfill all our human needs, right? They cannot give you a hug, they cannot come to your birthday

29:40.800 --> 29:47.440
party, they cannot kind of engage with you in a meaningful, full human way. And so any kind of

29:47.440 --> 29:51.680
language model agent on the internet has no capacity for that back and forth relationship.

29:51.680 --> 29:55.840
Even if it faked it, it's very unclear that it would actually satisfy what we need when we have

29:55.840 --> 30:00.640
an actual friend that we can go out to coffee with. So that all sounds quite bad again. Like

30:00.640 --> 30:05.760
deep breaths, the whole talk is really just digging you in a ditch, I'm sorry. But I'm now

30:05.760 --> 30:11.920
going to talk about possible futures. And again, these futures I think are not mutually exclusive,

30:11.920 --> 30:15.760
I think they all might unfold in different ways over the next five to 10 years. And like I can't

30:15.760 --> 30:20.160
speculate beyond that, God knows where we are. But yeah, I'm hoping they all kind of happen

30:20.160 --> 30:25.440
in parallel. So the first is I think we're about to spend a lot of time thinking about how we

30:25.440 --> 30:31.600
pass the reverse Turing test. So how do we prove we're human on a web filled with agents? So the

30:31.600 --> 30:36.480
original Turing test, you have a human talk to a computer and another human through like a wall

30:36.480 --> 30:41.200
so they can't see the typing messages of each other. And then the original test, the computer had

30:41.200 --> 30:46.880
to prove that it was the human. It had to prove it was competent. And on the new web, we are now the

30:46.880 --> 30:54.000
ones under scrutiny. We have to prove we're real. So we're going to end up like we will assume

30:54.000 --> 30:58.480
everyone is an agent until proven otherwise. So I kind of wrote this post where I was

30:59.200 --> 31:03.040
thinking about some short term tactics. Like we could use funny terminology. We could all try to

31:03.040 --> 31:07.120
become teenagers who like have this insider jargon that the language models don't know about, but

31:07.120 --> 31:10.320
they'll pick up on it pretty quick, you know, and then you'll have to abandon it, get a new jargon.

31:11.120 --> 31:14.800
We could write in non-dominant languages. If you speak something like Catalan or Welsh,

31:14.800 --> 31:18.400
you're probably in a pretty good position, you know, you'll be able to write in a way that's

31:18.400 --> 31:23.520
more native than a language model ever could. And ideally, we just do higher quality writing,

31:23.520 --> 31:29.120
we do more research, we do more critical thinking. We really reference events and people that could

31:29.120 --> 31:33.760
we could only know about from the real world, from being embodied humans in space. I don't know how

31:33.760 --> 31:38.000
long those kind of defenses will last, but that's in the short term something we can at least pull

31:38.000 --> 31:43.840
on. This next one, I apologize for the phrase, but it too perfectly, it catches the point. I'm

31:43.840 --> 31:50.560
not going to explain it. You can Google that later. But the point is that the content from models

31:50.560 --> 31:54.880
might end up becoming our source of truth, and that how we know things simply was like,

31:54.880 --> 31:59.280
well, a language model once said it, you know, and then it's forever captured in our circular flow

31:59.280 --> 32:02.960
of information. So right in this current model, right, the training data is at least based on

32:02.960 --> 32:07.760
real world experiences. It's kind of going in a single loop. But we're now going to use that

32:07.760 --> 32:14.080
generated text to train new models. And so we enter this loop where like there's this very

32:14.080 --> 32:18.960
tenuous link to the real world that was once a long time ago, the source of this data. This is

32:18.960 --> 32:23.200
already starting to happen. AI researchers are worried we're kind of going to run out of data to

32:23.200 --> 32:27.600
train models on within five years. And so there's a lot of talk of how do we generate information

32:27.600 --> 32:33.440
that we can feed the models, feed back into the models. This one was a really funny example of

32:33.440 --> 32:37.680
this happening. I don't know if people saw this. So someone noticed that if you ask Google if you

32:37.680 --> 32:42.240
can melt an egg, it's like smart AI summary said yes. And they were like, why would it say that?

32:42.240 --> 32:46.560
They weren't investigating. And it turned out that fact was pulled from Quora that was generated

32:46.560 --> 32:52.320
from chat GPT. And because Quora is considered a reputable website with good SEO standing,

32:52.320 --> 32:56.960
it got pulled up into the Google like smart answer. And it's not hard to imagine how all

32:56.960 --> 33:01.360
kinds of hallucinated answers are going to become part of this loop if all these major websites are

33:01.360 --> 33:06.400
using chat GPT or their own agent to generate answers and then they just feed it to each other.

33:06.400 --> 33:13.200
It's like at one point, can you melt an egg? This phenomenon is very worrying for the scientific

33:13.280 --> 33:17.520
community and they have good reason to be. We're already seeing a lot of evidence that scientific

33:17.520 --> 33:24.720
researchers are using language models to help them write papers. So again, this is a paper

33:24.720 --> 33:29.840
that was published in a genuine fairly legitimate journal, Environmental Science and Pollution

33:29.840 --> 33:35.280
Research. And it included the phrase regenerate response at the end of a paragraph, which is the

33:35.280 --> 33:41.840
button above chat GPT's input box. There's another one in August that was published on

33:41.920 --> 33:48.400
fossil fuel allocation that included the phrase as an AI language model. Now, there's a lot of

33:48.400 --> 33:51.600
debate in the community where they were like, well, this doesn't mean the science in these papers is

33:51.600 --> 33:55.200
totally false, right? They could have done real research on real experiments and they were just

33:55.200 --> 33:59.120
trying to get this paper out and at the end they went, you know what, chat GPT summarizes paragraph

33:59.120 --> 34:03.840
for me. That totally could have happened. But the problem is we don't know. There's no protocol for

34:03.840 --> 34:08.720
the transparency of how you say what you didn't, didn't use chat GPT or whatever kind of model for.

34:09.120 --> 34:14.960
So now people are trying to make it more legitimate. Some people are listing chat GPT as an author on

34:14.960 --> 34:20.880
papers. And there's a real risk that people with much worse intentions will kind of take this and

34:20.880 --> 34:25.440
run with it and just make scientific paper mills. There's a lot of companies that have a lot of

34:25.440 --> 34:30.640
vested interests in publishing science that agree with the thing that they would like to be true.

34:30.640 --> 34:34.400
Usually you find this out when you get to the funding source section of the paper where you're

34:34.400 --> 34:39.360
like, oh, yeah, funded by the people who make this drug. Interesting. But you can tell that if

34:39.360 --> 34:43.280
they're going to be able to use generative models to kind of pump out lots of research papers, maybe

34:43.280 --> 34:48.640
based on dubious science, it becomes very hard for us to tell what is actually real, what is vetted.

34:48.640 --> 34:54.320
I mean, it just takes the whole, the replication crisis to a whole new level. So this one seems

34:54.320 --> 34:58.880
the most obvious, right? One possible future is we will just retreat further into the cozy web,

34:58.880 --> 35:04.080
right? The dark frost will grow larger and we will just go, okay, I'm only interacting with

35:04.080 --> 35:09.120
Discord and WhatsApp, right? LinkedIn is dead, Twitter is dead. We've had to abandon it. We have

35:09.120 --> 35:13.760
to maybe make new privatized gate kept spaces, which I think has a lot of downsides, but this

35:13.760 --> 35:18.560
just might be the best way to deal with it. I think authors are going to increasingly put

35:18.560 --> 35:22.000
content behind blocks and paywalls. I think this is already happening with things like

35:22.000 --> 35:27.680
sub-stack and medium, where you're constantly having to log in or prove that you are part of

35:27.680 --> 35:33.200
this community to access the content. You understand why authors do this, right? Because

35:33.200 --> 35:37.680
actually you're having your content scraped and then fed into generative models puts you in a

35:37.680 --> 35:43.440
disadvantage. Like your ideas could be taken out of context, maybe it's taken something that you

35:43.440 --> 35:48.240
wanted to actually charge for and given out for free. Someone could train a model on your work

35:48.240 --> 35:52.000
and have it start writing in your voice. There's a lot of ways this can go really badly for someone

35:52.000 --> 35:58.720
whose full-time job is being a researcher or a content creator. We'll also see more websites

35:58.800 --> 36:04.160
that have a large amount of content blocking scraping for language models, or one way to do

36:04.160 --> 36:09.360
it is to just charge a huge amount for your API. Reddit did this recently. We're going to put the

36:09.360 --> 36:13.360
price so high that no company in their right mind would really pay it, or it would just cost them

36:13.360 --> 36:19.360
so much. Twitter kind of did the same. It's hard to tell if this was actually strategic or on purpose,

36:19.360 --> 36:25.280
but raising the price to whatever it was, like 42,000 per month, means that very few people

36:25.280 --> 36:31.200
can access Twitter's really high-quality content in an age where content to train models is the

36:31.200 --> 36:36.240
new goals. It's kind of leading us to a place where the web is not open by default. You can't

36:36.240 --> 36:40.880
just query any API for any content you want. Everything is locked down and gatecapped and

36:40.880 --> 36:45.920
kind of cordoned off. Next, I think we're going to have what I'm calling the Meet Space Premium.

36:47.840 --> 36:52.320
We are in the Meet Space Premium. It's when we begin to prefer and preference offline first

36:52.320 --> 36:58.320
interactions. So we will start to doubt all people online. And the only way to confirm someone's

36:58.320 --> 37:02.160
humanity is to meet them in person, right, to go for coffee or beer. And once you do that,

37:02.160 --> 37:06.240
you can kind of set up a little trust network, right? You can say, oh, I've already met Sarah

37:06.240 --> 37:09.920
over there, and she's a real human, and you've already met Tom, and he's a real human, and we can

37:09.920 --> 37:14.480
kind of like coordinate our networks to vet who's real on the web. And then when you read their

37:14.480 --> 37:18.880
writing, you kind of know it's from an actual person, or you'd hope so. You may be of some

37:18.880 --> 37:21.920
trust network of people who aren't writing generated stuff under their own name.

37:23.040 --> 37:26.160
I think this has knock-on effects. Like, people might move back to cities or

37:26.160 --> 37:30.960
higher population and places. In-person events are going to be preferable. I think there's

37:30.960 --> 37:35.040
obvious disadvantages to this, right? The web was this huge democratization thing to enable

37:35.040 --> 37:39.120
people who are maybe disabled or have young children or who are caregivers who can't get

37:39.120 --> 37:42.960
out of the house for a whole bunch of reasons aren't going to have the same access to the trust

37:42.960 --> 37:46.400
network that someone can who could physically show up in space a lot.

37:49.200 --> 37:53.040
Yeah. So, a natural follow-on from this also. So, a lot of people have been like,

37:53.040 --> 37:57.680
well, why don't we just put it on the blockchain, you know? Why don't we just get a third party

37:57.680 --> 38:02.400
to verify our humanity with a cryptographic key, and then you can sign all your published

38:02.400 --> 38:06.480
content with it, and it'll link back to your identity, and this is how we'll have decentralized

38:06.480 --> 38:10.640
trust networks. And I'm like, okay, I don't know the details of this. This sounds weird.

38:10.640 --> 38:16.240
So, there's a project called Worldcoin that, funnily enough, is also funded by OpenAI's

38:16.320 --> 38:20.560
leader, Sam Altman. He partially helped found it, which shows he kind of knows the problem he's

38:20.560 --> 38:25.920
helped contribute to. So, this scary orb scans your eyeball to confirm your identity,

38:25.920 --> 38:30.560
and then it creates a unique human credential for you to use online to sign all your stuff with.

38:30.560 --> 38:34.080
It's really not taking off as a project, but it's around. And people are still trying to do this.

38:34.080 --> 38:39.040
There's a whole community thinking this is the future that I don't have sophisticated thoughts

38:39.040 --> 38:44.000
on yet, and I'm still like, oh, cryptocurrency. But maybe this is some way to get around it.

38:44.960 --> 38:48.560
I'm also expecting any day that Elon's going to announce the purple check,

38:48.560 --> 38:52.160
where you pay $30 a month, and you don't actually have to. You just take a box that's like,

38:52.160 --> 38:57.920
I'm human, and then you get this little check and solve it. So, those are all a bit negative.

38:57.920 --> 39:02.400
I do think there is some hope in this future. We can certainly fight fire with fire.

39:02.400 --> 39:06.320
So, I think it's reasonable to assume that we're all going to have a set of personal language

39:06.320 --> 39:11.280
models to kind of help defend us and serve our needs on the web. They can filter information,

39:11.280 --> 39:16.080
they can manage information. And I expect these to be baked into browsers, or maybe even the

39:16.080 --> 39:20.080
operating system, right? And they're going to do things like identify generated content,

39:20.080 --> 39:24.000
they're going to debunk claims, they're going to flag misinformation, they're going to go

39:24.000 --> 39:29.040
help hunt down real scientific sources for you, maybe vet scientific papers, curate and suggest

39:29.040 --> 39:32.800
things to you. So, I think this actually could work in both directions. It's not just all like

39:32.800 --> 39:37.360
the bad actors get this power. We also get a lot of capacity and capability from these models.

39:38.320 --> 39:42.800
We might find it absurd that anyone would browse like the raw web without one of these

39:42.800 --> 39:46.160
kind of in tow. It's the same way you wouldn't like go onto the dark web, like you know what's

39:46.160 --> 39:51.520
there, but you know you don't want to see it. It might be kind of like that. Okay, so I'm almost

39:51.520 --> 39:55.840
done wrapping this up. But the question I want to leave everyone with is which of these possible

39:55.840 --> 40:01.200
futures would you like to make happen, right? Generative AI is not necessarily a destructive

40:01.200 --> 40:05.040
force, you know, as with all technology, it depends how you wield it. Oh, I went back to the

40:05.040 --> 40:12.080
wrong slide, sorry. There we go. The way that we choose to deploy this in the world is really

40:12.080 --> 40:15.520
what matters, right? The product decisions we make as individuals and companies, if you are

40:15.520 --> 40:20.880
working in the space or you're trying to get into it. Because obviously if you are working on a tool

40:20.880 --> 40:27.840
that like turns out tons of human-like content from marketing and influence purposes, like

40:27.840 --> 40:33.040
you can stop, like that's really like we don't need that. You can just stop doing that. But what

40:33.040 --> 40:37.200
should you be building instead? It's maybe a more helpful question. So I tried to come up with a few

40:37.200 --> 40:41.200
principles for building products language models that are probably going to evolve over time, but

40:41.200 --> 40:47.440
this is like a first pass. And the first is to protect human agency. The second is to treat models

40:47.440 --> 40:52.800
as reasoning engines and not sources of truth. And lastly that we should be augmenting our

40:52.800 --> 40:58.960
cognitive abilities and not replacing them. So protecting human agency, this is like usually

40:59.040 --> 41:03.120
at the moment you have a human prompter and it hands something off to an autonomous agent

41:03.120 --> 41:07.360
and the agent goes and does stuff, right? This is like the open AI assistance model or any of

41:07.360 --> 41:10.800
the architectures I showed before. And this is like the path to self-destruction. This is what

41:10.800 --> 41:15.120
most AI safety researchers are very afraid of is that the locus of agency sits within the agent.

41:16.400 --> 41:20.240
But the ideal form of this is that the locus of agent stays within the human

41:20.240 --> 41:24.080
and it has a collaborative agent on hand and there's this very short continuous feedback loop

41:24.080 --> 41:28.320
that is constantly going between them. Where the human is the one checking, should I do that? Do

41:28.320 --> 41:33.840
I want that? Is that true? Like they're able to actually fact check things and then the agent is

41:33.840 --> 41:40.960
much more of a helper. Short feedback loops, close supervision, limited power, it's slower but it's

41:40.960 --> 41:47.360
safer. That ties into the second principle that we should treat models as tiny reasoning engines

41:47.360 --> 41:52.160
and not sources of truth. So one way to use these models is to like ask it for every answer and

41:52.160 --> 41:57.520
ask it every question and trust what it says. Another one is you can train them to do specific

41:57.520 --> 42:03.360
things like just summarize this text, just extract data from this paper, just find contradictions in

42:03.360 --> 42:08.400
this statement and then you can bring your own data which could be legitimate scientific papers,

42:08.400 --> 42:12.480
it could be your own notes, it could be Wikipedia and then you use these models to just do these

42:12.480 --> 42:16.880
very small scoped things where you can observe every single output and check that it's actually

42:16.880 --> 42:21.360
legitimate and you're not handing off this big complex task to this big black box model.

42:22.240 --> 42:28.480
And lastly, we should augment our cognitive abilities and not replace them, right? Language models

42:28.480 --> 42:33.280
are very good at things that humans are not good at like searching and discovering things in large

42:33.280 --> 42:37.840
datasets, role playing as identities and characters, they're actually really good at doing that,

42:38.400 --> 42:43.040
rapidly organizing data, turning fuzzy inputs into structured outputs, there's a lot that they're

42:43.040 --> 42:47.040
good at that we're bad at and we should use them for those things. There's tons that like we're

42:47.040 --> 42:50.960
good at they're not that we're still trying to like make them do like checking claims against

42:50.960 --> 42:56.480
physical reality, long-term memory, having embodied knowledge, understanding social context,

42:56.480 --> 43:01.440
having emotional intelligence, I think combining the two of these so that we're doing things models

43:01.440 --> 43:06.320
can't do and they're doing things we're not very good at actually leverages the best of both worlds.

43:07.360 --> 43:11.280
Because a lot of AI researchers in the moment, they use this metaphor of aliens, this is from

43:11.280 --> 43:17.760
the 1970s alien film or frightening, it just it makes me think this is like not the most appealing

43:17.760 --> 43:22.960
collaborative partner this metaphor, this like big scary unknown consciousness that like might

43:22.960 --> 43:28.880
kill you, but there's another metaphor that I like more that Kate Darling is a robotics researcher

43:28.880 --> 43:33.360
at MIT and she wrote this book called The New Breed, arguing we should think about robots as

43:33.360 --> 43:38.480
animals, we have a long cultural legal history with animals and working collaboratively with them,

43:38.480 --> 43:44.240
oxen, dogs, pigs, right in this very like mutually beneficial relationship most of the time and this

43:44.240 --> 43:48.480
is actually a pretty good metaphor to expand to AI where we have to kind of treat them a little bit

43:48.480 --> 43:54.240
like some form of intelligent species but one that we are in community with and are part of our

43:54.240 --> 43:59.600
systems and are not this like big scary alien who might come kill us all is like usually what it

43:59.600 --> 44:06.720
gets talked about as. So yeah there's this big push for this philosophical approach, some people

44:06.720 --> 44:10.720
call it cyber-organism, there's a very long article there was a written on less wrong which is not

44:10.720 --> 44:15.440
my favorite website but it's a good article that kind of goes in depth into this if you do want

44:15.440 --> 44:21.680
to read more about it. So that's all I have, I want to thank you so much for listening, again

44:21.680 --> 44:28.640
slide the notes on this QR code if you like missed anything, I'm on Twitter X at mappleton still

44:28.640 --> 44:33.920
until that really does fall apart and you can DM me there, you can message me again I love meeting

44:33.920 --> 44:38.880
people through writing on the web if you have blogs that like relate to these kind of topics

44:38.880 --> 44:50.880
send them to me but yeah thank you so much for listening, I appreciate it.

