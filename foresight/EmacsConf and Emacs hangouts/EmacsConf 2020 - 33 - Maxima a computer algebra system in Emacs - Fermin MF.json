{"text": " You are now unmuted. Okay, can you guys hear me? Yeah, can you guys hear me too? Yep, I can, and you're live, so take it away. Okay, so hello everyone, my name is Fermin. I'm a programmer math student from Spain. I've been using Emacs for two years now, more or less, and today I'm going to talk about Maxima Computer Algebra System into Emacs. So, let's talk about what is Maxima? Well, Maxima is a system for manipulation of symbolic and numerical expression. It's similar in some regard to Octave, and it's also free software. It's derived from the Maxima from the M-A-T from the M-A-T, and it's written in common Lisp, which is a language that I really like and enjoy writing. So for me, it's a plus. So, let's talk about the initial support for Maxima. When I first started using it, I looked for support into Emacs, and I found that there's two major modes in the main repository of Maxima. For Emacs, the first one is iMaxima, which I don't know too much about it, and the second one is Maxima.L, which is the one I took first, and it was pretty nice. It has like a major mode, a minor mode, a nice ripple, but it also has some disadvantages. The first one is that it's quite outdated. I think it was from the 2007. So it's not tested with the Korean Emacs version, and the second one is that it doesn't use modern Emacs capability. I'm talking, for example, about the last or more latex preview from the last iMax 27.1, I think. And the last one is that it's not integrated with common third-party extension. I'm talking about company, for example, well, third-party. Yeah, you know, the Elpa Milpa packages. So this stock is going to be divided into parts. First one is going to be how much Maxima I made today in Max exercise. Don't worry, it's going to be quite easy. And the second one is going to be why for the package and the least improvement that I did, and a couple of things more, maybe the future and where's the package right now, if you can use it. So let's talk about the workflow. Right out of the box, it has like an almost super. I didn't write this. It was already in Emacs. So that's pretty nice. Let's go with a simple example. Okay, so this is an array of three equations and three variables. So it's a system that can be solved and the solution is unique. So we're going to solve it, right? Let's go. Solutions. Okay, here's how you define a variable in, let's call solve. Okay, let's call implicit. Oh, no, sorry. Okay, and now an array of variables. Okay, so first of all, we have to send this variable to the Maxima. We can do that with Ctrl C, Ctrl C, or with the Maxima. And then line. Okay, so let's put the Maxima buffer right here. Okay, so right now we can get the solution like this. So we call this line right now, Ctrl C, Ctrl C. As you can see, we get like an array inside an array, because let's see why we get this. So we can call Maxima help point. So open a doc buffer with all information about the solve function. So we can see that there's a list of solution equations. You can see it. Okay. So, but we know that the system only have one solution. So we're only interested in the first one. We can do this like pretty easily just to take the first one. We can send it to the buffer. So this is quite an easy example that you can see there to completion of the help facilities that we have. We can also get information about the symbol. For example, Maxima symbol doc. And we get in the, I don't know if you can see it correctly, in the mini buffer all the possible parameters of the function. So let's continue. Okay. So let's go to a more, well, complicated example, so to say. Oops. Okay. So we have this equation and we want to go from minus one to five. I want to show in a nice graph. Right. First of all, we begin sending this line to the Maxima repo. Put it in the bottom again. Okay. So this is not ideal if you want to write down this equation because it's quite messy. Where is when? So what's thing are where? I'm called the function Maxima. Let's say insert form. Okay. And this is more easy. This basically put text behind and led or more to render it. And this is why easy to write down. You can use it like in every expression. So first we have to call a library. Let's load the library. Library draw. So completion for local variable and local libraries. Sorry. Let me try to finish the draw. Okay. We send the line. So right now we have a leverage and we should even have auto completion for the library function. Okay. We have this called draw 2d. And now we can call implicit. We should have. Okay. And we can have input the variable of equations. We put the first variable. The minus five, the five. Five. The V variable, the minus five and the five. Okay. It should be all. All good. So let me try to send it. Okay. You cannot see it right now. Because I'm just sharing the maximum screen. Let me try to change that. Okay. Okay. Can you plot? Hello. Okay. So this is basically the graph that can you plot generates. Right now it's not integrated into. Into the maximum package, but it's a work in progress. So let's go back to e-max. Where are you? Okay. Okay. Okay. So, um, let's continue. So, uh, this is some of the things that you can use for you day to day programming in maxima. Um, let's go now with the. Okay. As you can see, this is just text that is rendered. Okay. Let's go with the next slide. This is how I use maxima a simple example. We don't want to talk too much about it because everyone used the package in a different way. So we're now going to talk about the original package and the way I change it. Right. So the documentation, uh, of the original was great, but for me, it wasn't embedded in the code. It wasn't something sometimes hard to read. Like it was like a big chunk of comment. Give me all the information. Like, um, for me, that's too much. I prefer a cohesive, small, um, comment and then a big read me with ordered all the links and information. So that's one of the first thing I change. Um, then also completion. I'm a big fan. I'm used to slime. So, um, I love beta to completion. So, um, the first thing that I noticed that, well, it uses an absolute function. I don't know if you can see correctly. Okay. Um, coming dynamic is deprecated and it also have like this, uh, variable, which is maxima symbol, which is basically a big, uh, list of all the possible completion. So, uh, if I load the library, it's not aware of the new symbols, or even if I create a variable, it's not loaded. So it's not dynamic. So I want the first thing I want is dynamic completion. Right. So I improve it, which it wasn't that hard. I first of all create maximum gets completion, which we're going to see in a moment. And then I change is complete in the region. So this is the improved version, but the good thing is like I decoupled the completion function. So I make that again, using all your own. So you get a prefix, which is, um, like the thing that you're going to auto complete, you get the inferior process, which I'm going to talk about later, but basically it's a maximum process you can work with. And you get an optional argument, which is fuzzy finding. Okay. So you can easily send a block here with, uh, with the approach, which is a maximum command that gets you all the auto completion. And then you process the, the output and you return, uh, a list of possible completion. This function can be easily put into company. As you can see, just get maximum cellular inferior process. It's a process that just, uh, uses. Sorry. I have all the approach and the get that symbol. It's like a, like I say, axillary lights. Help me, uh, for all that dirty stuff. So, and process manipulation. Let's talk about how the maximum process was in the beginning. So at first it was just one process and you send all of the things there and you move the process here and there. And there was a global state, right? So all the function depends on variable variables. Um, I don't like that approach. I prefer more like a short to say functional, like you sense one things and you return something. So it's not like avoid functions or to say. So I change it drastically. Uh, well, this is the maximum start function now. It just create, uh, start a process with this function, which is maximum making failure. So this function just, uh, uh, gets a name and it returned a process of maximum and you can then manipulate it the way you want. Let's see a better version. So this is the opposite, right? This remove an inferior process and delete the process and kill the buffer. Right? So let's give it an example. Cause this, you can see it pretty easily in this example. So, uh, I want to go to the scratch buffer, which I think you can see better. Okay. So, uh, this is the way you can get a process with your name and save it into a variable. Right? Let's execute this. So as you can see, well, I don't know if you can see big, you get a process. Let's go to it. The process called my maxima as the buffer. Right? And if we can, you can send the stuff to the process. Right? We can call maxima send block, get a blog of pallid maxima code and just pass the variable the process and we send code to the process. Right? We can, uh, this is youthful. You have some expensive computation that you want to process as synchrony. So to say, so the process can manage it. And when you get the results correctly, you can also get the results from the process. I mean, I don't put it here, but it's quite easy. And then you remove the inferior, which is the way to get rid of the process and the buffer. So if we call this function, we should get rid of the process and it works. The person is no longer. I'm happy to continue. So, um, other things that improve the package. I'm doing time. Okay. Another thing that I did to the package was to add a continue integration and continue delivery. Right? So the package didn't have any tests and the code was a little bit messy. So I, um, add integration at test and test with the test simple framework from Rocky bursting, the maintainer of real good, which is a great package by the way. Um, yeah, this is one example of the process. So right now, cause, um, the infrastructure of the process management is the couple. So I can test it pretty easily. This is the test function of the inferior running. So I can check if an inferior is running right now. And I can just delete it after and get the results. And I also did some integration with the party packages. The first one company, of course, I love auto completion. The second one was our mold that was already there. And Lattec with the, um, or Latin Lattec insert form. And with poly mode, cause, um, let me evaluate this. Maxima can understand list code. Well, more or less, he has to like a function, so to say, that you can send a list command to the Maxima rebel. And you can understand it in some way. So we can go to the Maxima, Paulie, Paulie, Maxima, right? You enable Paulie Maxima and it creates a poly mode, which this is list code. And this is Maxima code. So we can send this to the Maxima rebel. We come to C control art, which it send the, um, the Kurem, um, area, region. Sorry. And we define a variable with, which is called test. And as we can see, we have the variable test right here. So you can, uh, program in list, uh, and you can send it to Maxima. So this is pretty good. Pretty nice. Um, working integration with this line mode and with shrunk. So you can actually have a sort of completion of, uh, function inside the Maxima list package. But this is going to take quite a while. That's not trivial. So, um, what are the features of Maxima right now? Well, we have phones highlighting smart indentation. Uh, it was already in the package, but now it's quite better. Uh, great help functions right now. Uh, you can find the documentation quite fast and currently they menu integration. This is quite basic. It needs to be a little bit improved, uh, latex support, auto completion, local company, and maximum process integration and mini buffer. I didn't show you, but basically if you call global Maxima minor mode, you have the minor mode and you call Maxima mini buffer. How are you? Okay. Maybe for you can basically use a right simple Maxima command and it will give you the results. This is like a program version of, um, calc. So you can, okay. Yeah. You write the command and you get the output way more to come. I have like a list of, um, issues that I put enhancements and new features that I'm going to develop. So, uh, the future and the present of the package. Well, the package is right now Melpa, uh, Melpa stable. Um, Melpa stable is in the zero point seven point six version. And I'm planning to include into the non-genu Elpa. This is the URL of the package by the way. So you can, if you go to Melpa, you put Maxima and you can download it. Uh, it doesn't have too much dependencies. You're aware of that. Um, and thank you very much. Uh, this is going to be my talk. These are my, uh, information. This is my kid lab. This is my page, which I don't love too much. And this is my email. So, um, thank you very much. And I will be answering some questions right now and happy hacking. Thank you very much for the great talk. Um, yeah, let's see if we have any questions. Yeah. I'm reading like this. Um, so I'm a body of each other user right now. Okay. Maximum of each other. Yep. There are a couple of questions. Wow. Maximum of October. I don't want to, I don't know Octave that much. Um, like I use it like a couple of time, but I'm not happy. And I found the, um, Octave package to be quite a little bit harder to understand. Um, also that, um, it didn't have too much features. Like I prefer the maximum used to maybe Octave is better. I don't, I'm not a hundred percent sure. I know that you can use it for similar stuff, but that's it. So, sorry. Oh, okay. I mean, a little bit of a rush. Sorry. Let me drink a little blue. Okay. Okay. Okay. Okay. How does Maxima compare to Sage math in Emacs? I mean, I don't know what is Sage math. I'm sorry. Um, so I cannot answer your squinch with your question. I think. Sorry. But I mean, Maxima is ready in Como List. That's just a preference for me because I like, uh, a list dialect and Camel is interesting. Um, yeah. Uh, do you plan to have a maximum for session for Maxima code block? Yes. I want to improve the, um, of Maxima package, but I didn't have enough time and I want to clear a little bit of the code because still right now, um, uh, the code is quite messy in some areas because I pretty much implement first the basic function. I want to build in top off. So right now it's quite usable, but it's still have some things that I want to improve. So when I finish that, I will, um, improve the normal version. I think it maximized it to get into, into your video. Yes. Uh, I think that the creator of Maxima like have this list, uh, mine and probably, uh, um, that they, if you go to a symbol, you get all the information and that reflect that you can actually write your program of Maxima into, um, into list literally cause they have a command. So I think that is quite easy to get into. So many versions they use it for, um, first, um, years. So it is quite easy. And I think with my package, you can use it like pretty, pretty easily. Just create a file and you can start typing and Maxima quite easy to install also. So I think, yeah, it is quite easy. And the page, the page should restart. I don't know why. Sorry. Okay. Uh, Maxima seems to have strict infix listener. Hmm. Uh, infix strict infix. Infix list syntax. Um, you're talking about the Maxima itself syntax or I don't understand the question. Well, I going to go to the next question. Is there a support for images in Maxima mode? Not right now. Uh, the way I want to implement some IMAX, um, things. Uh, is there a support for, but right now it doesn't have like, uh, if you want to have a new plot, um, inside your buffer right now, it's not possible. So that's the thing that I Maxima does that Maxima.l still doesn't do which university you start to use Maxima. Um, in the Saragossa university from Spain, they use Maxima in the, um, thing in the engineer and in the math also. So not 100% sure right now, but when I started, are you planning to open your package into Maxima? Um, I don't know about that because, um, maybe can be a little bit messy. Um, because the Maxima repel is more built around like Maxima itself and they don't update the interfaces that much. I have no problem. Like it's okay. It just, um, you just have to, um, if you want to push, you can push in other repository. I mean, it's just changed the file in other way, but also the test, um, it's going to be a little bit harder because I think they're using, uh, search for, um, I'm using, uh, kid lab, uh, continue integration with you in delivery. So yeah, I don't think that, but it will, yeah, it will be nice. Okay. Um, it's possible to include maximizing or files, similar to Jupyter notebooks. Um, I mean, you can, uh, use Maxima in your, or, uh, files and you have Maxima.l mode integrated. And you can like create, uh, put that code in a buffer and then, uh, um, uh, edit it correctly, but it is now not, it doesn't have like all the features like all the languages because right now, uh, as my understanding is quite basic. So I still have some, still need some, some stuff, some workaround. Okay. I think that's it. Yep. So that's it. Uh, thank you very much for your live talk and for, you know, the live Q&A. Thank you. Thank you all. Amazing. Cheers. Thank you. It's thanks to all you guys. It's awesome. Okay. Thank you. Cheers. Bye. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.0, "text": " You are now unmuted.", "tokens": [50364, 509, 366, 586, 19334, 4866, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 1, "seek": 0, "start": 3.0, "end": 6.0, "text": " Okay, can you guys hear me?", "tokens": [50514, 1033, 11, 393, 291, 1074, 1568, 385, 30, 50664], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 2, "seek": 0, "start": 6.0, "end": 9.0, "text": " Yeah, can you guys hear me too?", "tokens": [50664, 865, 11, 393, 291, 1074, 1568, 385, 886, 30, 50814], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 3, "seek": 0, "start": 9.0, "end": 13.0, "text": " Yep, I can, and you're live, so take it away.", "tokens": [50814, 7010, 11, 286, 393, 11, 293, 291, 434, 1621, 11, 370, 747, 309, 1314, 13, 51014], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 4, "seek": 0, "start": 13.0, "end": 17.0, "text": " Okay, so hello everyone, my name is Fermin.", "tokens": [51014, 1033, 11, 370, 7751, 1518, 11, 452, 1315, 307, 43261, 259, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 5, "seek": 0, "start": 17.0, "end": 20.0, "text": " I'm a programmer math student from Spain.", "tokens": [51214, 286, 478, 257, 32116, 5221, 3107, 490, 12838, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 6, "seek": 0, "start": 20.0, "end": 24.0, "text": " I've been using Emacs for two years now, more or less,", "tokens": [51364, 286, 600, 668, 1228, 3968, 44937, 337, 732, 924, 586, 11, 544, 420, 1570, 11, 51564], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 7, "seek": 0, "start": 24.0, "end": 29.0, "text": " and today I'm going to talk about Maxima Computer Algebra System into Emacs.", "tokens": [51564, 293, 965, 286, 478, 516, 281, 751, 466, 7402, 4775, 22289, 967, 19983, 8910, 666, 3968, 44937, 13, 51814], "temperature": 0.0, "avg_logprob": -0.23494170795787464, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.43647798895835876}, {"id": 8, "seek": 2900, "start": 29.0, "end": 32.0, "text": " So, let's talk about what is Maxima?", "tokens": [50364, 407, 11, 718, 311, 751, 466, 437, 307, 7402, 4775, 30, 50514], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 9, "seek": 2900, "start": 32.0, "end": 36.0, "text": " Well, Maxima is a system for manipulation of symbolic and numerical expression.", "tokens": [50514, 1042, 11, 7402, 4775, 307, 257, 1185, 337, 26475, 295, 25755, 293, 29054, 6114, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 10, "seek": 2900, "start": 36.0, "end": 41.0, "text": " It's similar in some regard to Octave, and it's also free software.", "tokens": [50714, 467, 311, 2531, 294, 512, 3843, 281, 6788, 946, 11, 293, 309, 311, 611, 1737, 4722, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 11, "seek": 2900, "start": 41.0, "end": 45.0, "text": " It's derived from the Maxima from the M-A-T from the M-A-T,", "tokens": [50964, 467, 311, 18949, 490, 264, 7402, 4775, 490, 264, 376, 12, 32, 12, 51, 490, 264, 376, 12, 32, 12, 51, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 12, "seek": 2900, "start": 45.0, "end": 50.0, "text": " and it's written in common Lisp, which is a language that I really like and enjoy writing.", "tokens": [51164, 293, 309, 311, 3720, 294, 2689, 441, 7631, 11, 597, 307, 257, 2856, 300, 286, 534, 411, 293, 2103, 3579, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 13, "seek": 2900, "start": 50.0, "end": 52.0, "text": " So for me, it's a plus.", "tokens": [51414, 407, 337, 385, 11, 309, 311, 257, 1804, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 14, "seek": 2900, "start": 52.0, "end": 56.0, "text": " So, let's talk about the initial support for Maxima.", "tokens": [51514, 407, 11, 718, 311, 751, 466, 264, 5883, 1406, 337, 7402, 4775, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1750328463892783, "compression_ratio": 1.6680161943319838, "no_speech_prob": 0.008838299661874771}, {"id": 15, "seek": 5600, "start": 56.0, "end": 59.0, "text": " When I first started using it, I looked for support into Emacs,", "tokens": [50364, 1133, 286, 700, 1409, 1228, 309, 11, 286, 2956, 337, 1406, 666, 3968, 44937, 11, 50514], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 16, "seek": 5600, "start": 59.0, "end": 64.0, "text": " and I found that there's two major modes in the main repository of Maxima.", "tokens": [50514, 293, 286, 1352, 300, 456, 311, 732, 2563, 14068, 294, 264, 2135, 25841, 295, 7402, 4775, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 17, "seek": 5600, "start": 64.0, "end": 69.0, "text": " For Emacs, the first one is iMaxima, which I don't know too much about it,", "tokens": [50764, 1171, 3968, 44937, 11, 264, 700, 472, 307, 741, 36025, 4775, 11, 597, 286, 500, 380, 458, 886, 709, 466, 309, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 18, "seek": 5600, "start": 69.0, "end": 73.0, "text": " and the second one is Maxima.L, which is the one I took first,", "tokens": [51014, 293, 264, 1150, 472, 307, 7402, 4775, 13, 43, 11, 597, 307, 264, 472, 286, 1890, 700, 11, 51214], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 19, "seek": 5600, "start": 73.0, "end": 75.0, "text": " and it was pretty nice.", "tokens": [51214, 293, 309, 390, 1238, 1481, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 20, "seek": 5600, "start": 75.0, "end": 79.0, "text": " It has like a major mode, a minor mode, a nice ripple,", "tokens": [51314, 467, 575, 411, 257, 2563, 4391, 11, 257, 6696, 4391, 11, 257, 1481, 40688, 11, 51514], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 21, "seek": 5600, "start": 79.0, "end": 83.0, "text": " but it also has some disadvantages.", "tokens": [51514, 457, 309, 611, 575, 512, 37431, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09974144245016164, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.07387448102235794}, {"id": 22, "seek": 8300, "start": 83.0, "end": 86.0, "text": " The first one is that it's quite outdated.", "tokens": [50364, 440, 700, 472, 307, 300, 309, 311, 1596, 36313, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 23, "seek": 8300, "start": 86.0, "end": 89.0, "text": " I think it was from the 2007.", "tokens": [50514, 286, 519, 309, 390, 490, 264, 12656, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 24, "seek": 8300, "start": 89.0, "end": 92.0, "text": " So it's not tested with the Korean Emacs version,", "tokens": [50664, 407, 309, 311, 406, 8246, 365, 264, 6933, 3968, 44937, 3037, 11, 50814], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 25, "seek": 8300, "start": 92.0, "end": 96.0, "text": " and the second one is that it doesn't use modern Emacs capability.", "tokens": [50814, 293, 264, 1150, 472, 307, 300, 309, 1177, 380, 764, 4363, 3968, 44937, 13759, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 26, "seek": 8300, "start": 96.0, "end": 100.0, "text": " I'm talking, for example, about the last or more latex preview", "tokens": [51014, 286, 478, 1417, 11, 337, 1365, 11, 466, 264, 1036, 420, 544, 3469, 87, 14281, 51214], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 27, "seek": 8300, "start": 100.0, "end": 104.0, "text": " from the last iMax 27.1, I think.", "tokens": [51214, 490, 264, 1036, 741, 36025, 7634, 13, 16, 11, 286, 519, 13, 51414], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 28, "seek": 8300, "start": 104.0, "end": 108.0, "text": " And the last one is that it's not integrated with common third-party extension.", "tokens": [51414, 400, 264, 1036, 472, 307, 300, 309, 311, 406, 10919, 365, 2689, 2636, 12, 23409, 10320, 13, 51614], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 29, "seek": 8300, "start": 108.0, "end": 111.0, "text": " I'm talking about company, for example, well, third-party.", "tokens": [51614, 286, 478, 1417, 466, 2237, 11, 337, 1365, 11, 731, 11, 2636, 12, 23409, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15584881579289672, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.001775710959918797}, {"id": 30, "seek": 11100, "start": 111.0, "end": 115.0, "text": " Yeah, you know, the Elpa Milpa packages.", "tokens": [50364, 865, 11, 291, 458, 11, 264, 2699, 4306, 7036, 4306, 17401, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 31, "seek": 11100, "start": 115.0, "end": 118.0, "text": " So this stock is going to be divided into parts.", "tokens": [50564, 407, 341, 4127, 307, 516, 281, 312, 6666, 666, 3166, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 32, "seek": 11100, "start": 118.0, "end": 122.0, "text": " First one is going to be how much Maxima I made today in Max exercise.", "tokens": [50714, 2386, 472, 307, 516, 281, 312, 577, 709, 7402, 4775, 286, 1027, 965, 294, 7402, 5380, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 33, "seek": 11100, "start": 122.0, "end": 125.0, "text": " Don't worry, it's going to be quite easy.", "tokens": [50914, 1468, 380, 3292, 11, 309, 311, 516, 281, 312, 1596, 1858, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 34, "seek": 11100, "start": 125.0, "end": 128.0, "text": " And the second one is going to be why for the package", "tokens": [51064, 400, 264, 1150, 472, 307, 516, 281, 312, 983, 337, 264, 7372, 51214], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 35, "seek": 11100, "start": 128.0, "end": 132.0, "text": " and the least improvement that I did, and a couple of things more,", "tokens": [51214, 293, 264, 1935, 10444, 300, 286, 630, 11, 293, 257, 1916, 295, 721, 544, 11, 51414], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 36, "seek": 11100, "start": 132.0, "end": 136.0, "text": " maybe the future and where's the package right now, if you can use it.", "tokens": [51414, 1310, 264, 2027, 293, 689, 311, 264, 7372, 558, 586, 11, 498, 291, 393, 764, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 37, "seek": 11100, "start": 136.0, "end": 139.0, "text": " So let's talk about the workflow.", "tokens": [51614, 407, 718, 311, 751, 466, 264, 20993, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16522945341516715, "compression_ratio": 1.6653696498054475, "no_speech_prob": 0.0025282723363488913}, {"id": 38, "seek": 13900, "start": 139.0, "end": 142.0, "text": " Right out of the box, it has like an almost super.", "tokens": [50364, 1779, 484, 295, 264, 2424, 11, 309, 575, 411, 364, 1920, 1687, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 39, "seek": 13900, "start": 142.0, "end": 147.0, "text": " I didn't write this. It was already in Emacs.", "tokens": [50514, 286, 994, 380, 2464, 341, 13, 467, 390, 1217, 294, 3968, 44937, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 40, "seek": 13900, "start": 147.0, "end": 152.0, "text": " So that's pretty nice. Let's go with a simple example.", "tokens": [50764, 407, 300, 311, 1238, 1481, 13, 961, 311, 352, 365, 257, 2199, 1365, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 41, "seek": 13900, "start": 152.0, "end": 156.0, "text": " Okay, so this is an array of three equations and three variables.", "tokens": [51014, 1033, 11, 370, 341, 307, 364, 10225, 295, 1045, 11787, 293, 1045, 9102, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 42, "seek": 13900, "start": 156.0, "end": 160.0, "text": " So it's a system that can be solved and the solution is unique.", "tokens": [51214, 407, 309, 311, 257, 1185, 300, 393, 312, 13041, 293, 264, 3827, 307, 3845, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 43, "seek": 13900, "start": 160.0, "end": 162.0, "text": " So we're going to solve it, right?", "tokens": [51414, 407, 321, 434, 516, 281, 5039, 309, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 44, "seek": 13900, "start": 162.0, "end": 166.0, "text": " Let's go. Solutions.", "tokens": [51514, 961, 311, 352, 13, 36295, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13006410504331684, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.001971454592421651}, {"id": 45, "seek": 16600, "start": 166.0, "end": 170.0, "text": " Okay, here's how you define a variable in, let's call solve.", "tokens": [50364, 1033, 11, 510, 311, 577, 291, 6964, 257, 7006, 294, 11, 718, 311, 818, 5039, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 46, "seek": 16600, "start": 170.0, "end": 175.0, "text": " Okay, let's call implicit.", "tokens": [50564, 1033, 11, 718, 311, 818, 26947, 13, 50814], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 47, "seek": 16600, "start": 175.0, "end": 178.0, "text": " Oh, no, sorry.", "tokens": [50814, 876, 11, 572, 11, 2597, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 48, "seek": 16600, "start": 178.0, "end": 182.0, "text": " Okay, and now an array of variables.", "tokens": [50964, 1033, 11, 293, 586, 364, 10225, 295, 9102, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 49, "seek": 16600, "start": 182.0, "end": 188.0, "text": " Okay, so first of all, we have to send this variable to the Maxima.", "tokens": [51164, 1033, 11, 370, 700, 295, 439, 11, 321, 362, 281, 2845, 341, 7006, 281, 264, 7402, 4775, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 50, "seek": 16600, "start": 188.0, "end": 194.0, "text": " We can do that with Ctrl C, Ctrl C, or with the Maxima.", "tokens": [51464, 492, 393, 360, 300, 365, 35233, 383, 11, 35233, 383, 11, 420, 365, 264, 7402, 4775, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23810018342116784, "compression_ratio": 1.6335403726708075, "no_speech_prob": 0.0035635600797832012}, {"id": 51, "seek": 19400, "start": 194.0, "end": 201.0, "text": " And then line. Okay, so let's put the Maxima buffer right here.", "tokens": [50364, 400, 550, 1622, 13, 1033, 11, 370, 718, 311, 829, 264, 7402, 4775, 21762, 558, 510, 13, 50714], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 52, "seek": 19400, "start": 201.0, "end": 206.0, "text": " Okay, so right now we can get the solution like this.", "tokens": [50714, 1033, 11, 370, 558, 586, 321, 393, 483, 264, 3827, 411, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 53, "seek": 19400, "start": 206.0, "end": 210.0, "text": " So we call this line right now, Ctrl C, Ctrl C.", "tokens": [50964, 407, 321, 818, 341, 1622, 558, 586, 11, 35233, 383, 11, 35233, 383, 13, 51164], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 54, "seek": 19400, "start": 210.0, "end": 213.0, "text": " As you can see, we get like an array inside an array,", "tokens": [51164, 1018, 291, 393, 536, 11, 321, 483, 411, 364, 10225, 1854, 364, 10225, 11, 51314], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 55, "seek": 19400, "start": 213.0, "end": 216.0, "text": " because let's see why we get this.", "tokens": [51314, 570, 718, 311, 536, 983, 321, 483, 341, 13, 51464], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 56, "seek": 19400, "start": 216.0, "end": 221.0, "text": " So we can call Maxima help point.", "tokens": [51464, 407, 321, 393, 818, 7402, 4775, 854, 935, 13, 51714], "temperature": 0.0, "avg_logprob": -0.197232543097602, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0065720295533537865}, {"id": 57, "seek": 22100, "start": 221.0, "end": 227.0, "text": " So open a doc buffer with all information about the solve function.", "tokens": [50364, 407, 1269, 257, 3211, 21762, 365, 439, 1589, 466, 264, 5039, 2445, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 58, "seek": 22100, "start": 227.0, "end": 231.0, "text": " So we can see that there's a list of solution equations.", "tokens": [50664, 407, 321, 393, 536, 300, 456, 311, 257, 1329, 295, 3827, 11787, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 59, "seek": 22100, "start": 231.0, "end": 233.0, "text": " You can see it. Okay.", "tokens": [50864, 509, 393, 536, 309, 13, 1033, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 60, "seek": 22100, "start": 233.0, "end": 237.0, "text": " So, but we know that the system only have one solution.", "tokens": [50964, 407, 11, 457, 321, 458, 300, 264, 1185, 787, 362, 472, 3827, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 61, "seek": 22100, "start": 237.0, "end": 239.0, "text": " So we're only interested in the first one.", "tokens": [51164, 407, 321, 434, 787, 3102, 294, 264, 700, 472, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 62, "seek": 22100, "start": 239.0, "end": 242.0, "text": " We can do this like pretty easily just to take the first one.", "tokens": [51264, 492, 393, 360, 341, 411, 1238, 3612, 445, 281, 747, 264, 700, 472, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 63, "seek": 22100, "start": 242.0, "end": 245.0, "text": " We can send it to the buffer.", "tokens": [51414, 492, 393, 2845, 309, 281, 264, 21762, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 64, "seek": 22100, "start": 245.0, "end": 248.0, "text": " So this is quite an easy example that you can see there to completion", "tokens": [51564, 407, 341, 307, 1596, 364, 1858, 1365, 300, 291, 393, 536, 456, 281, 19372, 51714], "temperature": 0.0, "avg_logprob": -0.20828866091641512, "compression_ratio": 1.7850877192982457, "no_speech_prob": 0.005202125757932663}, {"id": 65, "seek": 24800, "start": 248.0, "end": 251.0, "text": " of the help facilities that we have.", "tokens": [50364, 295, 264, 854, 9406, 300, 321, 362, 13, 50514], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 66, "seek": 24800, "start": 251.0, "end": 253.0, "text": " We can also get information about the symbol.", "tokens": [50514, 492, 393, 611, 483, 1589, 466, 264, 5986, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 67, "seek": 24800, "start": 253.0, "end": 256.0, "text": " For example, Maxima symbol doc.", "tokens": [50614, 1171, 1365, 11, 7402, 4775, 5986, 3211, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 68, "seek": 24800, "start": 256.0, "end": 259.0, "text": " And we get in the, I don't know if you can see it correctly,", "tokens": [50764, 400, 321, 483, 294, 264, 11, 286, 500, 380, 458, 498, 291, 393, 536, 309, 8944, 11, 50914], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 69, "seek": 24800, "start": 259.0, "end": 265.0, "text": " in the mini buffer all the possible parameters of the function.", "tokens": [50914, 294, 264, 8382, 21762, 439, 264, 1944, 9834, 295, 264, 2445, 13, 51214], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 70, "seek": 24800, "start": 265.0, "end": 268.0, "text": " So let's continue.", "tokens": [51214, 407, 718, 311, 2354, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 71, "seek": 24800, "start": 268.0, "end": 270.0, "text": " Okay.", "tokens": [51364, 1033, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 72, "seek": 24800, "start": 270.0, "end": 274.0, "text": " So let's go to a more, well, complicated example, so to say.", "tokens": [51464, 407, 718, 311, 352, 281, 257, 544, 11, 731, 11, 6179, 1365, 11, 370, 281, 584, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 73, "seek": 24800, "start": 274.0, "end": 277.0, "text": " Oops. Okay.", "tokens": [51664, 21726, 13, 1033, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17370180990181716, "compression_ratio": 1.5458715596330275, "no_speech_prob": 0.014454364776611328}, {"id": 74, "seek": 27700, "start": 277.0, "end": 283.0, "text": " So we have this equation and we want to go from minus one to five.", "tokens": [50364, 407, 321, 362, 341, 5367, 293, 321, 528, 281, 352, 490, 3175, 472, 281, 1732, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 75, "seek": 27700, "start": 283.0, "end": 285.0, "text": " I want to show in a nice graph.", "tokens": [50664, 286, 528, 281, 855, 294, 257, 1481, 4295, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 76, "seek": 27700, "start": 285.0, "end": 286.0, "text": " Right.", "tokens": [50764, 1779, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 77, "seek": 27700, "start": 286.0, "end": 290.0, "text": " First of all, we begin sending this line to the Maxima repo.", "tokens": [50814, 2386, 295, 439, 11, 321, 1841, 7750, 341, 1622, 281, 264, 7402, 4775, 49040, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 78, "seek": 27700, "start": 290.0, "end": 292.0, "text": " Put it in the bottom again.", "tokens": [51014, 4935, 309, 294, 264, 2767, 797, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 79, "seek": 27700, "start": 292.0, "end": 294.0, "text": " Okay.", "tokens": [51114, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 80, "seek": 27700, "start": 294.0, "end": 297.0, "text": " So this is not ideal if you want to write down this equation", "tokens": [51214, 407, 341, 307, 406, 7157, 498, 291, 528, 281, 2464, 760, 341, 5367, 51364], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 81, "seek": 27700, "start": 297.0, "end": 299.0, "text": " because it's quite messy.", "tokens": [51364, 570, 309, 311, 1596, 16191, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 82, "seek": 27700, "start": 299.0, "end": 301.0, "text": " Where is when?", "tokens": [51464, 2305, 307, 562, 30, 51564], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 83, "seek": 27700, "start": 301.0, "end": 303.0, "text": " So what's thing are where?", "tokens": [51564, 407, 437, 311, 551, 366, 689, 30, 51664], "temperature": 0.0, "avg_logprob": -0.19692872797401206, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.001426692120730877}, {"id": 84, "seek": 30300, "start": 303.0, "end": 305.0, "text": " I'm called the function Maxima.", "tokens": [50364, 286, 478, 1219, 264, 2445, 7402, 4775, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 85, "seek": 30300, "start": 305.0, "end": 307.0, "text": " Let's say insert form.", "tokens": [50464, 961, 311, 584, 8969, 1254, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 86, "seek": 30300, "start": 307.0, "end": 308.0, "text": " Okay.", "tokens": [50564, 1033, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 87, "seek": 30300, "start": 308.0, "end": 309.0, "text": " And this is more easy.", "tokens": [50614, 400, 341, 307, 544, 1858, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 88, "seek": 30300, "start": 309.0, "end": 314.0, "text": " This basically put text behind and led or more to render it.", "tokens": [50664, 639, 1936, 829, 2487, 2261, 293, 4684, 420, 544, 281, 15529, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 89, "seek": 30300, "start": 314.0, "end": 316.0, "text": " And this is why easy to write down.", "tokens": [50914, 400, 341, 307, 983, 1858, 281, 2464, 760, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 90, "seek": 30300, "start": 316.0, "end": 320.0, "text": " You can use it like in every expression.", "tokens": [51014, 509, 393, 764, 309, 411, 294, 633, 6114, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 91, "seek": 30300, "start": 320.0, "end": 323.0, "text": " So first we have to call a library.", "tokens": [51214, 407, 700, 321, 362, 281, 818, 257, 6405, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 92, "seek": 30300, "start": 323.0, "end": 326.0, "text": " Let's load the library.", "tokens": [51364, 961, 311, 3677, 264, 6405, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 93, "seek": 30300, "start": 326.0, "end": 328.0, "text": " Library draw.", "tokens": [51514, 12806, 2642, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1920926493983115, "compression_ratio": 1.5206185567010309, "no_speech_prob": 0.007287499960511923}, {"id": 94, "seek": 32800, "start": 328.0, "end": 332.0, "text": " So completion for local variable and local libraries.", "tokens": [50364, 407, 19372, 337, 2654, 7006, 293, 2654, 15148, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 95, "seek": 32800, "start": 332.0, "end": 334.0, "text": " Sorry.", "tokens": [50564, 4919, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 96, "seek": 32800, "start": 334.0, "end": 336.0, "text": " Let me try to finish the draw.", "tokens": [50664, 961, 385, 853, 281, 2413, 264, 2642, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 97, "seek": 32800, "start": 336.0, "end": 337.0, "text": " Okay.", "tokens": [50764, 1033, 13, 50814], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 98, "seek": 32800, "start": 337.0, "end": 339.0, "text": " We send the line.", "tokens": [50814, 492, 2845, 264, 1622, 13, 50914], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 99, "seek": 32800, "start": 339.0, "end": 342.0, "text": " So right now we have a leverage and we should even have auto completion", "tokens": [50914, 407, 558, 586, 321, 362, 257, 13982, 293, 321, 820, 754, 362, 8399, 19372, 51064], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 100, "seek": 32800, "start": 342.0, "end": 344.0, "text": " for the library function.", "tokens": [51064, 337, 264, 6405, 2445, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 101, "seek": 32800, "start": 344.0, "end": 345.0, "text": " Okay.", "tokens": [51164, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 102, "seek": 32800, "start": 345.0, "end": 347.0, "text": " We have this called draw 2d.", "tokens": [51214, 492, 362, 341, 1219, 2642, 568, 67, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 103, "seek": 32800, "start": 347.0, "end": 350.0, "text": " And now we can call implicit.", "tokens": [51314, 400, 586, 321, 393, 818, 26947, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 104, "seek": 32800, "start": 350.0, "end": 351.0, "text": " We should have.", "tokens": [51464, 492, 820, 362, 13, 51514], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 105, "seek": 32800, "start": 351.0, "end": 352.0, "text": " Okay.", "tokens": [51514, 1033, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 106, "seek": 32800, "start": 352.0, "end": 355.0, "text": " And we can have input the variable of equations.", "tokens": [51564, 400, 321, 393, 362, 4846, 264, 7006, 295, 11787, 13, 51714], "temperature": 0.0, "avg_logprob": -0.25625865864303876, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.00438345642760396}, {"id": 107, "seek": 35500, "start": 355.0, "end": 357.0, "text": " We put the first variable.", "tokens": [50364, 492, 829, 264, 700, 7006, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 108, "seek": 35500, "start": 357.0, "end": 361.0, "text": " The minus five, the five.", "tokens": [50464, 440, 3175, 1732, 11, 264, 1732, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 109, "seek": 35500, "start": 361.0, "end": 362.0, "text": " Five.", "tokens": [50664, 9436, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 110, "seek": 35500, "start": 362.0, "end": 366.0, "text": " The V variable, the minus five and the five.", "tokens": [50714, 440, 691, 7006, 11, 264, 3175, 1732, 293, 264, 1732, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 111, "seek": 35500, "start": 366.0, "end": 367.0, "text": " Okay.", "tokens": [50914, 1033, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 112, "seek": 35500, "start": 367.0, "end": 368.0, "text": " It should be all.", "tokens": [50964, 467, 820, 312, 439, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 113, "seek": 35500, "start": 368.0, "end": 369.0, "text": " All good.", "tokens": [51014, 1057, 665, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 114, "seek": 35500, "start": 369.0, "end": 371.0, "text": " So let me try to send it.", "tokens": [51064, 407, 718, 385, 853, 281, 2845, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 115, "seek": 35500, "start": 371.0, "end": 372.0, "text": " Okay.", "tokens": [51164, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 116, "seek": 35500, "start": 372.0, "end": 374.0, "text": " You cannot see it right now.", "tokens": [51214, 509, 2644, 536, 309, 558, 586, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 117, "seek": 35500, "start": 374.0, "end": 376.0, "text": " Because I'm just sharing the maximum screen.", "tokens": [51314, 1436, 286, 478, 445, 5414, 264, 6674, 2568, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 118, "seek": 35500, "start": 376.0, "end": 379.0, "text": " Let me try to change that.", "tokens": [51414, 961, 385, 853, 281, 1319, 300, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 119, "seek": 35500, "start": 379.0, "end": 383.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1806515780362216, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.014419891871511936}, {"id": 120, "seek": 38300, "start": 383.0, "end": 384.0, "text": " Okay.", "tokens": [50364, 1033, 13, 50414], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 121, "seek": 38300, "start": 384.0, "end": 385.0, "text": " Can you plot?", "tokens": [50414, 1664, 291, 7542, 30, 50464], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 122, "seek": 38300, "start": 385.0, "end": 386.0, "text": " Hello.", "tokens": [50464, 2425, 13, 50514], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 123, "seek": 38300, "start": 391.0, "end": 392.0, "text": " Okay.", "tokens": [50764, 1033, 13, 50814], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 124, "seek": 38300, "start": 392.0, "end": 395.0, "text": " So this is basically the graph that can you plot generates.", "tokens": [50814, 407, 341, 307, 1936, 264, 4295, 300, 393, 291, 7542, 23815, 13, 50964], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 125, "seek": 38300, "start": 395.0, "end": 398.0, "text": " Right now it's not integrated into.", "tokens": [50964, 1779, 586, 309, 311, 406, 10919, 666, 13, 51114], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 126, "seek": 38300, "start": 398.0, "end": 402.0, "text": " Into the maximum package, but it's a work in progress.", "tokens": [51114, 23373, 264, 6674, 7372, 11, 457, 309, 311, 257, 589, 294, 4205, 13, 51314], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 127, "seek": 38300, "start": 402.0, "end": 405.0, "text": " So let's go back to e-max.", "tokens": [51314, 407, 718, 311, 352, 646, 281, 308, 12, 41167, 13, 51464], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 128, "seek": 38300, "start": 405.0, "end": 407.0, "text": " Where are you?", "tokens": [51464, 2305, 366, 291, 30, 51564], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 129, "seek": 38300, "start": 407.0, "end": 408.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51614], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 130, "seek": 38300, "start": 408.0, "end": 410.0, "text": " Okay.", "tokens": [51614, 1033, 13, 51714], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 131, "seek": 38300, "start": 410.0, "end": 411.0, "text": " Okay.", "tokens": [51714, 1033, 13, 51764], "temperature": 0.0, "avg_logprob": -0.29573468411906384, "compression_ratio": 1.4550898203592815, "no_speech_prob": 0.0027806884609162807}, {"id": 132, "seek": 41100, "start": 411.0, "end": 415.0, "text": " So, um, let's continue.", "tokens": [50364, 407, 11, 1105, 11, 718, 311, 2354, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 133, "seek": 41100, "start": 415.0, "end": 420.0, "text": " So, uh, this is some of the things that you can use for you day to day programming in", "tokens": [50564, 407, 11, 2232, 11, 341, 307, 512, 295, 264, 721, 300, 291, 393, 764, 337, 291, 786, 281, 786, 9410, 294, 50814], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 134, "seek": 41100, "start": 420.0, "end": 421.0, "text": " maxima.", "tokens": [50814, 5138, 64, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 135, "seek": 41100, "start": 421.0, "end": 425.0, "text": " Um, let's go now with the.", "tokens": [50864, 3301, 11, 718, 311, 352, 586, 365, 264, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 136, "seek": 41100, "start": 425.0, "end": 426.0, "text": " Okay.", "tokens": [51064, 1033, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 137, "seek": 41100, "start": 426.0, "end": 429.0, "text": " As you can see, this is just text that is rendered.", "tokens": [51114, 1018, 291, 393, 536, 11, 341, 307, 445, 2487, 300, 307, 28748, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 138, "seek": 41100, "start": 429.0, "end": 430.0, "text": " Okay.", "tokens": [51264, 1033, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 139, "seek": 41100, "start": 430.0, "end": 431.0, "text": " Let's go with the next slide.", "tokens": [51314, 961, 311, 352, 365, 264, 958, 4137, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 140, "seek": 41100, "start": 431.0, "end": 433.0, "text": " This is how I use maxima a simple example.", "tokens": [51364, 639, 307, 577, 286, 764, 5138, 64, 257, 2199, 1365, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 141, "seek": 41100, "start": 433.0, "end": 438.0, "text": " We don't want to talk too much about it because everyone used the package in a different way.", "tokens": [51464, 492, 500, 380, 528, 281, 751, 886, 709, 466, 309, 570, 1518, 1143, 264, 7372, 294, 257, 819, 636, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13607403410582983, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0011089704930782318}, {"id": 142, "seek": 43800, "start": 438.0, "end": 442.0, "text": " So we're now going to talk about the original package and the way I change it.", "tokens": [50364, 407, 321, 434, 586, 516, 281, 751, 466, 264, 3380, 7372, 293, 264, 636, 286, 1319, 309, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 143, "seek": 43800, "start": 442.0, "end": 443.0, "text": " Right.", "tokens": [50564, 1779, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 144, "seek": 43800, "start": 443.0, "end": 449.0, "text": " So the documentation, uh, of the original was great, but for me, it wasn't embedded in", "tokens": [50614, 407, 264, 14333, 11, 2232, 11, 295, 264, 3380, 390, 869, 11, 457, 337, 385, 11, 309, 2067, 380, 16741, 294, 50914], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 145, "seek": 43800, "start": 449.0, "end": 450.0, "text": " the code.", "tokens": [50914, 264, 3089, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 146, "seek": 43800, "start": 450.0, "end": 452.0, "text": " It wasn't something sometimes hard to read.", "tokens": [50964, 467, 2067, 380, 746, 2171, 1152, 281, 1401, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 147, "seek": 43800, "start": 452.0, "end": 455.0, "text": " Like it was like a big chunk of comment.", "tokens": [51064, 1743, 309, 390, 411, 257, 955, 16635, 295, 2871, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 148, "seek": 43800, "start": 455.0, "end": 457.0, "text": " Give me all the information.", "tokens": [51214, 5303, 385, 439, 264, 1589, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 149, "seek": 43800, "start": 457.0, "end": 460.0, "text": " Like, um, for me, that's too much.", "tokens": [51314, 1743, 11, 1105, 11, 337, 385, 11, 300, 311, 886, 709, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 150, "seek": 43800, "start": 460.0, "end": 466.0, "text": " I prefer a cohesive, small, um, comment and then a big read me with ordered all the links", "tokens": [51464, 286, 4382, 257, 43025, 11, 1359, 11, 1105, 11, 2871, 293, 550, 257, 955, 1401, 385, 365, 8866, 439, 264, 6123, 51764], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 151, "seek": 43800, "start": 466.0, "end": 467.0, "text": " and information.", "tokens": [51764, 293, 1589, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1443490005853608, "compression_ratio": 1.7244094488188977, "no_speech_prob": 0.00688049104064703}, {"id": 152, "seek": 46700, "start": 467.0, "end": 470.0, "text": " So that's one of the first thing I change.", "tokens": [50364, 407, 300, 311, 472, 295, 264, 700, 551, 286, 1319, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 153, "seek": 46700, "start": 470.0, "end": 471.0, "text": " Um, then also completion.", "tokens": [50514, 3301, 11, 550, 611, 19372, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 154, "seek": 46700, "start": 471.0, "end": 472.0, "text": " I'm a big fan.", "tokens": [50564, 286, 478, 257, 955, 3429, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 155, "seek": 46700, "start": 472.0, "end": 474.0, "text": " I'm used to slime.", "tokens": [50614, 286, 478, 1143, 281, 20650, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 156, "seek": 46700, "start": 474.0, "end": 477.0, "text": " So, um, I love beta to completion.", "tokens": [50714, 407, 11, 1105, 11, 286, 959, 9861, 281, 19372, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 157, "seek": 46700, "start": 477.0, "end": 481.0, "text": " So, um, the first thing that I noticed that, well, it uses an absolute function.", "tokens": [50864, 407, 11, 1105, 11, 264, 700, 551, 300, 286, 5694, 300, 11, 731, 11, 309, 4960, 364, 8236, 2445, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 158, "seek": 46700, "start": 481.0, "end": 483.0, "text": " I don't know if you can see correctly.", "tokens": [51064, 286, 500, 380, 458, 498, 291, 393, 536, 8944, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 159, "seek": 46700, "start": 483.0, "end": 484.0, "text": " Okay.", "tokens": [51164, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 160, "seek": 46700, "start": 484.0, "end": 490.0, "text": " Um, coming dynamic is deprecated and it also have like this, uh, variable, which is maxima", "tokens": [51214, 3301, 11, 1348, 8546, 307, 1367, 13867, 770, 293, 309, 611, 362, 411, 341, 11, 2232, 11, 7006, 11, 597, 307, 5138, 64, 51514], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 161, "seek": 46700, "start": 490.0, "end": 495.0, "text": " symbol, which is basically a big, uh, list of all the possible completion.", "tokens": [51514, 5986, 11, 597, 307, 1936, 257, 955, 11, 2232, 11, 1329, 295, 439, 264, 1944, 19372, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1469497107025376, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.009615778923034668}, {"id": 162, "seek": 49500, "start": 495.0, "end": 501.0, "text": " So, uh, if I load the library, it's not aware of the new symbols, or even if I create a", "tokens": [50364, 407, 11, 2232, 11, 498, 286, 3677, 264, 6405, 11, 309, 311, 406, 3650, 295, 264, 777, 16944, 11, 420, 754, 498, 286, 1884, 257, 50664], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 163, "seek": 49500, "start": 501.0, "end": 503.0, "text": " variable, it's not loaded.", "tokens": [50664, 7006, 11, 309, 311, 406, 13210, 13, 50764], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 164, "seek": 49500, "start": 503.0, "end": 504.0, "text": " So it's not dynamic.", "tokens": [50764, 407, 309, 311, 406, 8546, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 165, "seek": 49500, "start": 504.0, "end": 507.0, "text": " So I want the first thing I want is dynamic completion.", "tokens": [50814, 407, 286, 528, 264, 700, 551, 286, 528, 307, 8546, 19372, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 166, "seek": 49500, "start": 507.0, "end": 508.0, "text": " Right.", "tokens": [50964, 1779, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 167, "seek": 49500, "start": 508.0, "end": 511.0, "text": " So I improve it, which it wasn't that hard.", "tokens": [51014, 407, 286, 3470, 309, 11, 597, 309, 2067, 380, 300, 1152, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 168, "seek": 49500, "start": 511.0, "end": 516.0, "text": " I first of all create maximum gets completion, which we're going to see in a moment.", "tokens": [51164, 286, 700, 295, 439, 1884, 6674, 2170, 19372, 11, 597, 321, 434, 516, 281, 536, 294, 257, 1623, 13, 51414], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 169, "seek": 49500, "start": 516.0, "end": 518.0, "text": " And then I change is complete in the region.", "tokens": [51414, 400, 550, 286, 1319, 307, 3566, 294, 264, 4458, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 170, "seek": 49500, "start": 518.0, "end": 523.0, "text": " So this is the improved version, but the good thing is like I decoupled the completion", "tokens": [51514, 407, 341, 307, 264, 9689, 3037, 11, 457, 264, 665, 551, 307, 411, 286, 979, 263, 15551, 264, 19372, 51764], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 171, "seek": 49500, "start": 523.0, "end": 524.0, "text": " function.", "tokens": [51764, 2445, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15576773531296673, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.023624097928404808}, {"id": 172, "seek": 52400, "start": 524.0, "end": 526.0, "text": " So I make that again, using all your own.", "tokens": [50364, 407, 286, 652, 300, 797, 11, 1228, 439, 428, 1065, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 173, "seek": 52400, "start": 526.0, "end": 533.0, "text": " So you get a prefix, which is, um, like the thing that you're going to auto complete,", "tokens": [50464, 407, 291, 483, 257, 46969, 11, 597, 307, 11, 1105, 11, 411, 264, 551, 300, 291, 434, 516, 281, 8399, 3566, 11, 50814], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 174, "seek": 52400, "start": 533.0, "end": 538.0, "text": " you get the inferior process, which I'm going to talk about later, but basically it's a", "tokens": [50814, 291, 483, 264, 24249, 1399, 11, 597, 286, 478, 516, 281, 751, 466, 1780, 11, 457, 1936, 309, 311, 257, 51064], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 175, "seek": 52400, "start": 538.0, "end": 540.0, "text": " maximum process you can work with.", "tokens": [51064, 6674, 1399, 291, 393, 589, 365, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 176, "seek": 52400, "start": 540.0, "end": 543.0, "text": " And you get an optional argument, which is fuzzy finding.", "tokens": [51164, 400, 291, 483, 364, 17312, 6770, 11, 597, 307, 34710, 5006, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 177, "seek": 52400, "start": 543.0, "end": 544.0, "text": " Okay.", "tokens": [51314, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 178, "seek": 52400, "start": 544.0, "end": 551.0, "text": " So you can easily send a block here with, uh, with the approach, which is a maximum command", "tokens": [51364, 407, 291, 393, 3612, 2845, 257, 3461, 510, 365, 11, 2232, 11, 365, 264, 3109, 11, 597, 307, 257, 6674, 5622, 51714], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 179, "seek": 52400, "start": 551.0, "end": 553.0, "text": " that gets you all the auto completion.", "tokens": [51714, 300, 2170, 291, 439, 264, 8399, 19372, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1507768867429623, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002348529640585184}, {"id": 180, "seek": 55300, "start": 553.0, "end": 560.0, "text": " And then you process the, the output and you return, uh, a list of possible completion.", "tokens": [50364, 400, 550, 291, 1399, 264, 11, 264, 5598, 293, 291, 2736, 11, 2232, 11, 257, 1329, 295, 1944, 19372, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 181, "seek": 55300, "start": 560.0, "end": 563.0, "text": " This function can be easily put into company.", "tokens": [50714, 639, 2445, 393, 312, 3612, 829, 666, 2237, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 182, "seek": 55300, "start": 563.0, "end": 567.0, "text": " As you can see, just get maximum cellular inferior process.", "tokens": [50864, 1018, 291, 393, 536, 11, 445, 483, 6674, 29267, 24249, 1399, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 183, "seek": 55300, "start": 567.0, "end": 570.0, "text": " It's a process that just, uh, uses.", "tokens": [51064, 467, 311, 257, 1399, 300, 445, 11, 2232, 11, 4960, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 184, "seek": 55300, "start": 570.0, "end": 571.0, "text": " Sorry.", "tokens": [51214, 4919, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 185, "seek": 55300, "start": 571.0, "end": 575.0, "text": " I have all the approach and the get that symbol.", "tokens": [51264, 286, 362, 439, 264, 3109, 293, 264, 483, 300, 5986, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 186, "seek": 55300, "start": 575.0, "end": 578.0, "text": " It's like a, like I say, axillary lights.", "tokens": [51464, 467, 311, 411, 257, 11, 411, 286, 584, 11, 6360, 46367, 5811, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 187, "seek": 55300, "start": 578.0, "end": 581.0, "text": " Help me, uh, for all that dirty stuff.", "tokens": [51614, 10773, 385, 11, 2232, 11, 337, 439, 300, 9360, 1507, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2789091306312062, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0017379634082317352}, {"id": 188, "seek": 58100, "start": 581.0, "end": 583.0, "text": " So, and process manipulation.", "tokens": [50364, 407, 11, 293, 1399, 26475, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 189, "seek": 58100, "start": 583.0, "end": 588.0, "text": " Let's talk about how the maximum process was in the beginning.", "tokens": [50464, 961, 311, 751, 466, 577, 264, 6674, 1399, 390, 294, 264, 2863, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 190, "seek": 58100, "start": 588.0, "end": 593.0, "text": " So at first it was just one process and you send all of the things there and you move", "tokens": [50714, 407, 412, 700, 309, 390, 445, 472, 1399, 293, 291, 2845, 439, 295, 264, 721, 456, 293, 291, 1286, 50964], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 191, "seek": 58100, "start": 593.0, "end": 595.0, "text": " the process here and there.", "tokens": [50964, 264, 1399, 510, 293, 456, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 192, "seek": 58100, "start": 595.0, "end": 598.0, "text": " And there was a global state, right?", "tokens": [51064, 400, 456, 390, 257, 4338, 1785, 11, 558, 30, 51214], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 193, "seek": 58100, "start": 598.0, "end": 601.0, "text": " So all the function depends on variable variables.", "tokens": [51214, 407, 439, 264, 2445, 5946, 322, 7006, 9102, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 194, "seek": 58100, "start": 601.0, "end": 603.0, "text": " Um, I don't like that approach.", "tokens": [51364, 3301, 11, 286, 500, 380, 411, 300, 3109, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 195, "seek": 58100, "start": 603.0, "end": 610.0, "text": " I prefer more like a short to say functional, like you sense one things and you return something.", "tokens": [51464, 286, 4382, 544, 411, 257, 2099, 281, 584, 11745, 11, 411, 291, 2020, 472, 721, 293, 291, 2736, 746, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1733252674067786, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0021740905940532684}, {"id": 196, "seek": 61000, "start": 610.0, "end": 613.0, "text": " So it's not like avoid functions or to say.", "tokens": [50364, 407, 309, 311, 406, 411, 5042, 6828, 420, 281, 584, 13, 50514], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 197, "seek": 61000, "start": 613.0, "end": 615.0, "text": " So I change it drastically.", "tokens": [50514, 407, 286, 1319, 309, 29673, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 198, "seek": 61000, "start": 615.0, "end": 618.0, "text": " Uh, well, this is the maximum start function now.", "tokens": [50614, 4019, 11, 731, 11, 341, 307, 264, 6674, 722, 2445, 586, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 199, "seek": 61000, "start": 618.0, "end": 623.0, "text": " It just create, uh, start a process with this function, which is maximum making failure.", "tokens": [50764, 467, 445, 1884, 11, 2232, 11, 722, 257, 1399, 365, 341, 2445, 11, 597, 307, 6674, 1455, 7763, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 200, "seek": 61000, "start": 623.0, "end": 630.0, "text": " So this function just, uh, uh, gets a name and it returned a process of maximum and you", "tokens": [51014, 407, 341, 2445, 445, 11, 2232, 11, 2232, 11, 2170, 257, 1315, 293, 309, 8752, 257, 1399, 295, 6674, 293, 291, 51364], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 201, "seek": 61000, "start": 630.0, "end": 632.0, "text": " can then manipulate it the way you want.", "tokens": [51364, 393, 550, 20459, 309, 264, 636, 291, 528, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 202, "seek": 61000, "start": 632.0, "end": 634.0, "text": " Let's see a better version.", "tokens": [51464, 961, 311, 536, 257, 1101, 3037, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 203, "seek": 61000, "start": 634.0, "end": 636.0, "text": " So this is the opposite, right?", "tokens": [51564, 407, 341, 307, 264, 6182, 11, 558, 30, 51664], "temperature": 0.0, "avg_logprob": -0.17454784840076892, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.0035773934796452522}, {"id": 204, "seek": 63600, "start": 636.0, "end": 641.0, "text": " This remove an inferior process and delete the process and kill the buffer.", "tokens": [50364, 639, 4159, 364, 24249, 1399, 293, 12097, 264, 1399, 293, 1961, 264, 21762, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 205, "seek": 63600, "start": 641.0, "end": 642.0, "text": " Right?", "tokens": [50614, 1779, 30, 50664], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 206, "seek": 63600, "start": 642.0, "end": 643.0, "text": " So let's give it an example.", "tokens": [50664, 407, 718, 311, 976, 309, 364, 1365, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 207, "seek": 63600, "start": 643.0, "end": 646.0, "text": " Cause this, you can see it pretty easily in this example.", "tokens": [50714, 10865, 341, 11, 291, 393, 536, 309, 1238, 3612, 294, 341, 1365, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 208, "seek": 63600, "start": 646.0, "end": 651.0, "text": " So, uh, I want to go to the scratch buffer, which I think you can see better.", "tokens": [50864, 407, 11, 2232, 11, 286, 528, 281, 352, 281, 264, 8459, 21762, 11, 597, 286, 519, 291, 393, 536, 1101, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 209, "seek": 63600, "start": 651.0, "end": 652.0, "text": " Okay.", "tokens": [51114, 1033, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 210, "seek": 63600, "start": 652.0, "end": 657.0, "text": " So, uh, this is the way you can get a process with your name and save it into a variable.", "tokens": [51164, 407, 11, 2232, 11, 341, 307, 264, 636, 291, 393, 483, 257, 1399, 365, 428, 1315, 293, 3155, 309, 666, 257, 7006, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 211, "seek": 63600, "start": 657.0, "end": 658.0, "text": " Right?", "tokens": [51414, 1779, 30, 51464], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 212, "seek": 63600, "start": 658.0, "end": 659.0, "text": " Let's execute this.", "tokens": [51464, 961, 311, 14483, 341, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 213, "seek": 63600, "start": 659.0, "end": 663.0, "text": " So as you can see, well, I don't know if you can see big, you get a process.", "tokens": [51514, 407, 382, 291, 393, 536, 11, 731, 11, 286, 500, 380, 458, 498, 291, 393, 536, 955, 11, 291, 483, 257, 1399, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 214, "seek": 63600, "start": 663.0, "end": 665.0, "text": " Let's go to it.", "tokens": [51714, 961, 311, 352, 281, 309, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13840790061683922, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.007098943926393986}, {"id": 215, "seek": 66500, "start": 665.0, "end": 668.0, "text": " The process called my maxima as the buffer.", "tokens": [50364, 440, 1399, 1219, 452, 5138, 64, 382, 264, 21762, 13, 50514], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 216, "seek": 66500, "start": 668.0, "end": 669.0, "text": " Right?", "tokens": [50514, 1779, 30, 50564], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 217, "seek": 66500, "start": 669.0, "end": 671.0, "text": " And if we can, you can send the stuff to the process.", "tokens": [50564, 400, 498, 321, 393, 11, 291, 393, 2845, 264, 1507, 281, 264, 1399, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 218, "seek": 66500, "start": 671.0, "end": 672.0, "text": " Right?", "tokens": [50664, 1779, 30, 50714], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 219, "seek": 66500, "start": 672.0, "end": 677.0, "text": " We can call maxima send block, get a blog of pallid maxima code and just pass the variable", "tokens": [50714, 492, 393, 818, 5138, 64, 2845, 3461, 11, 483, 257, 6968, 295, 24075, 327, 5138, 64, 3089, 293, 445, 1320, 264, 7006, 50964], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 220, "seek": 66500, "start": 677.0, "end": 680.0, "text": " the process and we send code to the process.", "tokens": [50964, 264, 1399, 293, 321, 2845, 3089, 281, 264, 1399, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 221, "seek": 66500, "start": 680.0, "end": 681.0, "text": " Right?", "tokens": [51114, 1779, 30, 51164], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 222, "seek": 66500, "start": 681.0, "end": 682.0, "text": " We can, uh, this is youthful.", "tokens": [51164, 492, 393, 11, 2232, 11, 341, 307, 7503, 906, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 223, "seek": 66500, "start": 682.0, "end": 687.0, "text": " You have some expensive computation that you want to process as synchrony.", "tokens": [51214, 509, 362, 512, 5124, 24903, 300, 291, 528, 281, 1399, 382, 19331, 88, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 224, "seek": 66500, "start": 687.0, "end": 690.0, "text": " So to say, so the process can manage it.", "tokens": [51464, 407, 281, 584, 11, 370, 264, 1399, 393, 3067, 309, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 225, "seek": 66500, "start": 690.0, "end": 694.0, "text": " And when you get the results correctly, you can also get the results from the process.", "tokens": [51614, 400, 562, 291, 483, 264, 3542, 8944, 11, 291, 393, 611, 483, 264, 3542, 490, 264, 1399, 13, 51814], "temperature": 0.0, "avg_logprob": -0.19251710905445565, "compression_ratio": 1.90234375, "no_speech_prob": 0.0059448229148983955}, {"id": 226, "seek": 69400, "start": 694.0, "end": 697.0, "text": " I mean, I don't put it here, but it's quite easy.", "tokens": [50364, 286, 914, 11, 286, 500, 380, 829, 309, 510, 11, 457, 309, 311, 1596, 1858, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 227, "seek": 69400, "start": 697.0, "end": 703.0, "text": " And then you remove the inferior, which is the way to get rid of the process and the", "tokens": [50514, 400, 550, 291, 4159, 264, 24249, 11, 597, 307, 264, 636, 281, 483, 3973, 295, 264, 1399, 293, 264, 50814], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 228, "seek": 69400, "start": 703.0, "end": 704.0, "text": " buffer.", "tokens": [50814, 21762, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 229, "seek": 69400, "start": 704.0, "end": 708.0, "text": " So if we call this function, we should get rid of the process and it works.", "tokens": [50864, 407, 498, 321, 818, 341, 2445, 11, 321, 820, 483, 3973, 295, 264, 1399, 293, 309, 1985, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 230, "seek": 69400, "start": 708.0, "end": 710.0, "text": " The person is no longer.", "tokens": [51064, 440, 954, 307, 572, 2854, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 231, "seek": 69400, "start": 710.0, "end": 712.0, "text": " I'm happy to continue.", "tokens": [51164, 286, 478, 2055, 281, 2354, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 232, "seek": 69400, "start": 712.0, "end": 716.0, "text": " So, um, other things that improve the package.", "tokens": [51264, 407, 11, 1105, 11, 661, 721, 300, 3470, 264, 7372, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 233, "seek": 69400, "start": 716.0, "end": 718.0, "text": " I'm doing time.", "tokens": [51464, 286, 478, 884, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 234, "seek": 69400, "start": 718.0, "end": 719.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18673731486002604, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0068435040302574635}, {"id": 235, "seek": 71900, "start": 719.0, "end": 723.0, "text": " Another thing that I did to the package was to add a continue integration and continue", "tokens": [50364, 3996, 551, 300, 286, 630, 281, 264, 7372, 390, 281, 909, 257, 2354, 10980, 293, 2354, 50564], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 236, "seek": 71900, "start": 723.0, "end": 724.0, "text": " delivery.", "tokens": [50564, 8982, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 237, "seek": 71900, "start": 724.0, "end": 725.0, "text": " Right?", "tokens": [50614, 1779, 30, 50664], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 238, "seek": 71900, "start": 725.0, "end": 729.0, "text": " So the package didn't have any tests and the code was a little bit messy.", "tokens": [50664, 407, 264, 7372, 994, 380, 362, 604, 6921, 293, 264, 3089, 390, 257, 707, 857, 16191, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 239, "seek": 71900, "start": 729.0, "end": 738.0, "text": " So I, um, add integration at test and test with the test simple framework from Rocky", "tokens": [50864, 407, 286, 11, 1105, 11, 909, 10980, 412, 1500, 293, 1500, 365, 264, 1500, 2199, 8388, 490, 26916, 51314], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 240, "seek": 71900, "start": 738.0, "end": 743.0, "text": " bursting, the maintainer of real good, which is a great package by the way.", "tokens": [51314, 45713, 11, 264, 6909, 260, 295, 957, 665, 11, 597, 307, 257, 869, 7372, 538, 264, 636, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 241, "seek": 71900, "start": 743.0, "end": 746.0, "text": " Um, yeah, this is one example of the process.", "tokens": [51564, 3301, 11, 1338, 11, 341, 307, 472, 1365, 295, 264, 1399, 13, 51714], "temperature": 0.0, "avg_logprob": -0.15153910381959215, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.00836949422955513}, {"id": 242, "seek": 74600, "start": 746.0, "end": 751.0, "text": " So right now, cause, um, the infrastructure of the process management is the couple.", "tokens": [50364, 407, 558, 586, 11, 3082, 11, 1105, 11, 264, 6896, 295, 264, 1399, 4592, 307, 264, 1916, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 243, "seek": 74600, "start": 751.0, "end": 753.0, "text": " So I can test it pretty easily.", "tokens": [50614, 407, 286, 393, 1500, 309, 1238, 3612, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 244, "seek": 74600, "start": 753.0, "end": 756.0, "text": " This is the test function of the inferior running.", "tokens": [50714, 639, 307, 264, 1500, 2445, 295, 264, 24249, 2614, 13, 50864], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 245, "seek": 74600, "start": 756.0, "end": 759.0, "text": " So I can check if an inferior is running right now.", "tokens": [50864, 407, 286, 393, 1520, 498, 364, 24249, 307, 2614, 558, 586, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 246, "seek": 74600, "start": 759.0, "end": 763.0, "text": " And I can just delete it after and get the results.", "tokens": [51014, 400, 286, 393, 445, 12097, 309, 934, 293, 483, 264, 3542, 13, 51214], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 247, "seek": 74600, "start": 763.0, "end": 766.0, "text": " And I also did some integration with the party packages.", "tokens": [51214, 400, 286, 611, 630, 512, 10980, 365, 264, 3595, 17401, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 248, "seek": 74600, "start": 766.0, "end": 768.0, "text": " The first one company, of course, I love auto completion.", "tokens": [51364, 440, 700, 472, 2237, 11, 295, 1164, 11, 286, 959, 8399, 19372, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 249, "seek": 74600, "start": 768.0, "end": 771.0, "text": " The second one was our mold that was already there.", "tokens": [51464, 440, 1150, 472, 390, 527, 11102, 300, 390, 1217, 456, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14119923853241237, "compression_ratio": 1.7109375, "no_speech_prob": 0.0027485049795359373}, {"id": 250, "seek": 77100, "start": 771.0, "end": 776.0, "text": " And Lattec with the, um, or Latin Lattec insert form.", "tokens": [50364, 400, 7354, 975, 66, 365, 264, 11, 1105, 11, 420, 10803, 7354, 975, 66, 8969, 1254, 13, 50614], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 251, "seek": 77100, "start": 776.0, "end": 781.0, "text": " And with poly mode, cause, um, let me evaluate this.", "tokens": [50614, 400, 365, 6754, 4391, 11, 3082, 11, 1105, 11, 718, 385, 13059, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 252, "seek": 77100, "start": 781.0, "end": 783.0, "text": " Maxima can understand list code.", "tokens": [50864, 7402, 4775, 393, 1223, 1329, 3089, 13, 50964], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 253, "seek": 77100, "start": 783.0, "end": 790.0, "text": " Well, more or less, he has to like a function, so to say, that you can send a list command", "tokens": [50964, 1042, 11, 544, 420, 1570, 11, 415, 575, 281, 411, 257, 2445, 11, 370, 281, 584, 11, 300, 291, 393, 2845, 257, 1329, 5622, 51314], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 254, "seek": 77100, "start": 790.0, "end": 792.0, "text": " to the Maxima rebel.", "tokens": [51314, 281, 264, 7402, 4775, 28293, 13, 51414], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 255, "seek": 77100, "start": 792.0, "end": 794.0, "text": " And you can understand it in some way.", "tokens": [51414, 400, 291, 393, 1223, 309, 294, 512, 636, 13, 51514], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 256, "seek": 77100, "start": 794.0, "end": 799.0, "text": " So we can go to the Maxima, Paulie, Paulie, Maxima, right?", "tokens": [51514, 407, 321, 393, 352, 281, 264, 7402, 4775, 11, 4552, 414, 11, 4552, 414, 11, 7402, 4775, 11, 558, 30, 51764], "temperature": 0.0, "avg_logprob": -0.34054811865882534, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.08129934966564178}, {"id": 257, "seek": 79900, "start": 799.0, "end": 804.0, "text": " You enable Paulie Maxima and it creates a poly mode, which this is list code.", "tokens": [50364, 509, 9528, 4552, 414, 7402, 4775, 293, 309, 7829, 257, 6754, 4391, 11, 597, 341, 307, 1329, 3089, 13, 50614], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 258, "seek": 79900, "start": 804.0, "end": 806.0, "text": " And this is Maxima code.", "tokens": [50614, 400, 341, 307, 7402, 4775, 3089, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 259, "seek": 79900, "start": 806.0, "end": 808.0, "text": " So we can send this to the Maxima rebel.", "tokens": [50714, 407, 321, 393, 2845, 341, 281, 264, 7402, 4775, 28293, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 260, "seek": 79900, "start": 808.0, "end": 816.0, "text": " We come to C control art, which it send the, um, the Kurem, um, area, region.", "tokens": [50814, 492, 808, 281, 383, 1969, 1523, 11, 597, 309, 2845, 264, 11, 1105, 11, 264, 591, 540, 76, 11, 1105, 11, 1859, 11, 4458, 13, 51214], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 261, "seek": 79900, "start": 816.0, "end": 817.0, "text": " Sorry.", "tokens": [51214, 4919, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 262, "seek": 79900, "start": 817.0, "end": 820.0, "text": " And we define a variable with, which is called test.", "tokens": [51264, 400, 321, 6964, 257, 7006, 365, 11, 597, 307, 1219, 1500, 13, 51414], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 263, "seek": 79900, "start": 820.0, "end": 822.0, "text": " And as we can see, we have the variable test right here.", "tokens": [51414, 400, 382, 321, 393, 536, 11, 321, 362, 264, 7006, 1500, 558, 510, 13, 51514], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 264, "seek": 79900, "start": 822.0, "end": 827.0, "text": " So you can, uh, program in list, uh, and you can send it to Maxima.", "tokens": [51514, 407, 291, 393, 11, 2232, 11, 1461, 294, 1329, 11, 2232, 11, 293, 291, 393, 2845, 309, 281, 7402, 4775, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22756348839101864, "compression_ratio": 1.7652173913043478, "no_speech_prob": 0.01101128663867712}, {"id": 265, "seek": 82700, "start": 828.0, "end": 829.0, "text": " So this is pretty good.", "tokens": [50414, 407, 341, 307, 1238, 665, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 266, "seek": 82700, "start": 829.0, "end": 830.0, "text": " Pretty nice.", "tokens": [50464, 10693, 1481, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 267, "seek": 82700, "start": 830.0, "end": 834.0, "text": " Um, working integration with this line mode and with shrunk.", "tokens": [50514, 3301, 11, 1364, 10980, 365, 341, 1622, 4391, 293, 365, 9884, 3197, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 268, "seek": 82700, "start": 834.0, "end": 840.0, "text": " So you can actually have a sort of completion of, uh, function inside the Maxima list package.", "tokens": [50714, 407, 291, 393, 767, 362, 257, 1333, 295, 19372, 295, 11, 2232, 11, 2445, 1854, 264, 7402, 4775, 1329, 7372, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 269, "seek": 82700, "start": 840.0, "end": 843.0, "text": " But this is going to take quite a while.", "tokens": [51014, 583, 341, 307, 516, 281, 747, 1596, 257, 1339, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 270, "seek": 82700, "start": 843.0, "end": 844.0, "text": " That's not trivial.", "tokens": [51164, 663, 311, 406, 26703, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 271, "seek": 82700, "start": 844.0, "end": 848.0, "text": " So, um, what are the features of Maxima right now?", "tokens": [51214, 407, 11, 1105, 11, 437, 366, 264, 4122, 295, 7402, 4775, 558, 586, 30, 51414], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 272, "seek": 82700, "start": 848.0, "end": 851.0, "text": " Well, we have phones highlighting smart indentation.", "tokens": [51414, 1042, 11, 321, 362, 10216, 26551, 4069, 44494, 399, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 273, "seek": 82700, "start": 851.0, "end": 854.0, "text": " Uh, it was already in the package, but now it's quite better.", "tokens": [51564, 4019, 11, 309, 390, 1217, 294, 264, 7372, 11, 457, 586, 309, 311, 1596, 1101, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 274, "seek": 82700, "start": 854.0, "end": 856.0, "text": " Uh, great help functions right now.", "tokens": [51714, 4019, 11, 869, 854, 6828, 558, 586, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2139544039964676, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.007238014601171017}, {"id": 275, "seek": 85600, "start": 856.0, "end": 860.0, "text": " Uh, you can find the documentation quite fast and currently they menu integration.", "tokens": [50364, 4019, 11, 291, 393, 915, 264, 14333, 1596, 2370, 293, 4362, 436, 6510, 10980, 13, 50564], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 276, "seek": 85600, "start": 860.0, "end": 861.0, "text": " This is quite basic.", "tokens": [50564, 639, 307, 1596, 3875, 13, 50614], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 277, "seek": 85600, "start": 861.0, "end": 865.0, "text": " It needs to be a little bit improved, uh, latex support, auto completion, local company,", "tokens": [50614, 467, 2203, 281, 312, 257, 707, 857, 9689, 11, 2232, 11, 3469, 87, 1406, 11, 8399, 19372, 11, 2654, 2237, 11, 50814], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 278, "seek": 85600, "start": 865.0, "end": 868.0, "text": " and maximum process integration and mini buffer.", "tokens": [50814, 293, 6674, 1399, 10980, 293, 8382, 21762, 13, 50964], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 279, "seek": 85600, "start": 868.0, "end": 874.0, "text": " I didn't show you, but basically if you call global Maxima minor mode, you have the minor", "tokens": [50964, 286, 994, 380, 855, 291, 11, 457, 1936, 498, 291, 818, 4338, 7402, 4775, 6696, 4391, 11, 291, 362, 264, 6696, 51264], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 280, "seek": 85600, "start": 874.0, "end": 876.0, "text": " mode and you call Maxima mini buffer.", "tokens": [51264, 4391, 293, 291, 818, 7402, 4775, 8382, 21762, 13, 51364], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 281, "seek": 85600, "start": 876.0, "end": 877.0, "text": " How are you?", "tokens": [51364, 1012, 366, 291, 30, 51414], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 282, "seek": 85600, "start": 877.0, "end": 878.0, "text": " Okay.", "tokens": [51414, 1033, 13, 51464], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 283, "seek": 85600, "start": 878.0, "end": 882.0, "text": " Maybe for you can basically use a right simple Maxima command and it will give you the", "tokens": [51464, 2704, 337, 291, 393, 1936, 764, 257, 558, 2199, 7402, 4775, 5622, 293, 309, 486, 976, 291, 264, 51664], "temperature": 0.0, "avg_logprob": -0.27433832680306786, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0051167625933885574}, {"id": 284, "seek": 88200, "start": 882.0, "end": 883.0, "text": " results.", "tokens": [50364, 3542, 13, 50414], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 285, "seek": 88200, "start": 883.0, "end": 886.0, "text": " This is like a program version of, um, calc.", "tokens": [50414, 639, 307, 411, 257, 1461, 3037, 295, 11, 1105, 11, 2104, 66, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 286, "seek": 88200, "start": 886.0, "end": 888.0, "text": " So you can, okay.", "tokens": [50564, 407, 291, 393, 11, 1392, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 287, "seek": 88200, "start": 888.0, "end": 889.0, "text": " Yeah.", "tokens": [50664, 865, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 288, "seek": 88200, "start": 889.0, "end": 891.0, "text": " You write the command and you get the output way more to come.", "tokens": [50714, 509, 2464, 264, 5622, 293, 291, 483, 264, 5598, 636, 544, 281, 808, 13, 50814], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 289, "seek": 88200, "start": 891.0, "end": 897.0, "text": " I have like a list of, um, issues that I put enhancements and new features that I'm going", "tokens": [50814, 286, 362, 411, 257, 1329, 295, 11, 1105, 11, 2663, 300, 286, 829, 11985, 1117, 293, 777, 4122, 300, 286, 478, 516, 51114], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 290, "seek": 88200, "start": 897.0, "end": 899.0, "text": " to develop.", "tokens": [51114, 281, 1499, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 291, "seek": 88200, "start": 899.0, "end": 902.0, "text": " So, uh, the future and the present of the package.", "tokens": [51214, 407, 11, 2232, 11, 264, 2027, 293, 264, 1974, 295, 264, 7372, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 292, "seek": 88200, "start": 902.0, "end": 905.0, "text": " Well, the package is right now Melpa, uh, Melpa stable.", "tokens": [51364, 1042, 11, 264, 7372, 307, 558, 586, 7375, 4306, 11, 2232, 11, 7375, 4306, 8351, 13, 51514], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 293, "seek": 88200, "start": 905.0, "end": 910.0, "text": " Um, Melpa stable is in the zero point seven point six version.", "tokens": [51514, 3301, 11, 7375, 4306, 8351, 307, 294, 264, 4018, 935, 3407, 935, 2309, 3037, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23081301152706146, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.016273483633995056}, {"id": 294, "seek": 91000, "start": 910.0, "end": 915.0, "text": " And I'm planning to include into the non-genu Elpa.", "tokens": [50364, 400, 286, 478, 5038, 281, 4090, 666, 264, 2107, 12, 1766, 84, 2699, 4306, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 295, "seek": 91000, "start": 915.0, "end": 917.0, "text": " This is the URL of the package by the way.", "tokens": [50614, 639, 307, 264, 12905, 295, 264, 7372, 538, 264, 636, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 296, "seek": 91000, "start": 917.0, "end": 921.0, "text": " So you can, if you go to Melpa, you put Maxima and you can download it.", "tokens": [50714, 407, 291, 393, 11, 498, 291, 352, 281, 7375, 4306, 11, 291, 829, 7402, 4775, 293, 291, 393, 5484, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 297, "seek": 91000, "start": 921.0, "end": 923.0, "text": " Uh, it doesn't have too much dependencies.", "tokens": [50914, 4019, 11, 309, 1177, 380, 362, 886, 709, 36606, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 298, "seek": 91000, "start": 923.0, "end": 925.0, "text": " You're aware of that.", "tokens": [51014, 509, 434, 3650, 295, 300, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 299, "seek": 91000, "start": 925.0, "end": 927.0, "text": " Um, and thank you very much.", "tokens": [51114, 3301, 11, 293, 1309, 291, 588, 709, 13, 51214], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 300, "seek": 91000, "start": 927.0, "end": 928.0, "text": " Uh, this is going to be my talk.", "tokens": [51214, 4019, 11, 341, 307, 516, 281, 312, 452, 751, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 301, "seek": 91000, "start": 928.0, "end": 930.0, "text": " These are my, uh, information.", "tokens": [51264, 1981, 366, 452, 11, 2232, 11, 1589, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 302, "seek": 91000, "start": 930.0, "end": 932.0, "text": " This is my kid lab.", "tokens": [51364, 639, 307, 452, 1636, 2715, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 303, "seek": 91000, "start": 932.0, "end": 934.0, "text": " This is my page, which I don't love too much.", "tokens": [51464, 639, 307, 452, 3028, 11, 597, 286, 500, 380, 959, 886, 709, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 304, "seek": 91000, "start": 934.0, "end": 936.0, "text": " And this is my email.", "tokens": [51564, 400, 341, 307, 452, 3796, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 305, "seek": 91000, "start": 936.0, "end": 939.0, "text": " So, um, thank you very much.", "tokens": [51664, 407, 11, 1105, 11, 1309, 291, 588, 709, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14596242712648122, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.023973271250724792}, {"id": 306, "seek": 93900, "start": 939.0, "end": 943.0, "text": " And I will be answering some questions right now and happy hacking.", "tokens": [50364, 400, 286, 486, 312, 13430, 512, 1651, 558, 586, 293, 2055, 31422, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 307, "seek": 93900, "start": 948.0, "end": 951.0, "text": " Thank you very much for the great talk.", "tokens": [50814, 1044, 291, 588, 709, 337, 264, 869, 751, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 308, "seek": 93900, "start": 951.0, "end": 955.0, "text": " Um, yeah, let's see if we have any questions.", "tokens": [50964, 3301, 11, 1338, 11, 718, 311, 536, 498, 321, 362, 604, 1651, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 309, "seek": 93900, "start": 955.0, "end": 956.0, "text": " Yeah.", "tokens": [51164, 865, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 310, "seek": 93900, "start": 956.0, "end": 958.0, "text": " I'm reading like this.", "tokens": [51214, 286, 478, 3760, 411, 341, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 311, "seek": 93900, "start": 958.0, "end": 961.0, "text": " Um, so I'm a body of each other user right now.", "tokens": [51314, 3301, 11, 370, 286, 478, 257, 1772, 295, 1184, 661, 4195, 558, 586, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 312, "seek": 93900, "start": 961.0, "end": 963.0, "text": " Okay.", "tokens": [51464, 1033, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 313, "seek": 93900, "start": 964.0, "end": 966.0, "text": " Maximum of each other.", "tokens": [51614, 29076, 449, 295, 1184, 661, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 314, "seek": 93900, "start": 966.0, "end": 967.0, "text": " Yep.", "tokens": [51714, 7010, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 315, "seek": 93900, "start": 967.0, "end": 968.0, "text": " There are a couple of questions.", "tokens": [51764, 821, 366, 257, 1916, 295, 1651, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2616702119509379, "compression_ratio": 1.5153061224489797, "no_speech_prob": 0.014454309828579426}, {"id": 316, "seek": 96800, "start": 969.0, "end": 970.0, "text": " Wow.", "tokens": [50414, 3153, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 317, "seek": 96800, "start": 970.0, "end": 971.0, "text": " Maximum of October.", "tokens": [50464, 29076, 449, 295, 7617, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 318, "seek": 96800, "start": 971.0, "end": 974.0, "text": " I don't want to, I don't know Octave that much.", "tokens": [50514, 286, 500, 380, 528, 281, 11, 286, 500, 380, 458, 6788, 946, 300, 709, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 319, "seek": 96800, "start": 974.0, "end": 979.0, "text": " Um, like I use it like a couple of time, but I'm not happy.", "tokens": [50664, 3301, 11, 411, 286, 764, 309, 411, 257, 1916, 295, 565, 11, 457, 286, 478, 406, 2055, 13, 50914], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 320, "seek": 96800, "start": 979.0, "end": 986.0, "text": " And I found the, um, Octave package to be quite a little bit harder to", "tokens": [50914, 400, 286, 1352, 264, 11, 1105, 11, 6788, 946, 7372, 281, 312, 1596, 257, 707, 857, 6081, 281, 51264], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 321, "seek": 96800, "start": 986.0, "end": 987.0, "text": " understand.", "tokens": [51264, 1223, 13, 51314], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 322, "seek": 96800, "start": 987.0, "end": 994.0, "text": " Um, also that, um, it didn't have too much features.", "tokens": [51314, 3301, 11, 611, 300, 11, 1105, 11, 309, 994, 380, 362, 886, 709, 4122, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 323, "seek": 96800, "start": 994.0, "end": 997.0, "text": " Like I prefer the maximum used to maybe Octave is better.", "tokens": [51664, 1743, 286, 4382, 264, 6674, 1143, 281, 1310, 6788, 946, 307, 1101, 13, 51814], "temperature": 0.0, "avg_logprob": -0.23795284415191076, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0030609851237386465}, {"id": 324, "seek": 99700, "start": 997.0, "end": 999.0, "text": " I don't, I'm not a hundred percent sure.", "tokens": [50364, 286, 500, 380, 11, 286, 478, 406, 257, 3262, 3043, 988, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 325, "seek": 99700, "start": 999.0, "end": 1003.0, "text": " I know that you can use it for similar stuff, but that's it.", "tokens": [50464, 286, 458, 300, 291, 393, 764, 309, 337, 2531, 1507, 11, 457, 300, 311, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 326, "seek": 99700, "start": 1003.0, "end": 1004.0, "text": " So, sorry.", "tokens": [50664, 407, 11, 2597, 13, 50714], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 327, "seek": 99700, "start": 1007.0, "end": 1008.0, "text": " Oh, okay.", "tokens": [50864, 876, 11, 1392, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 328, "seek": 99700, "start": 1008.0, "end": 1010.0, "text": " I mean, a little bit of a rush.", "tokens": [50914, 286, 914, 11, 257, 707, 857, 295, 257, 9300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 329, "seek": 99700, "start": 1010.0, "end": 1011.0, "text": " Sorry.", "tokens": [51014, 4919, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 330, "seek": 99700, "start": 1011.0, "end": 1013.0, "text": " Let me drink a little blue.", "tokens": [51064, 961, 385, 2822, 257, 707, 3344, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 331, "seek": 99700, "start": 1013.0, "end": 1014.0, "text": " Okay.", "tokens": [51164, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 332, "seek": 99700, "start": 1014.0, "end": 1015.0, "text": " Okay.", "tokens": [51214, 1033, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 333, "seek": 99700, "start": 1015.0, "end": 1016.0, "text": " Okay.", "tokens": [51264, 1033, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 334, "seek": 99700, "start": 1021.0, "end": 1022.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16975049862916441, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.007553722243756056}, {"id": 335, "seek": 102200, "start": 1023.0, "end": 1026.0, "text": " How does Maxima compare to Sage math in Emacs?", "tokens": [50414, 1012, 775, 7402, 4775, 6794, 281, 33812, 5221, 294, 3968, 44937, 30, 50564], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 336, "seek": 102200, "start": 1029.0, "end": 1034.0, "text": " I mean, I don't know what is Sage math.", "tokens": [50714, 286, 914, 11, 286, 500, 380, 458, 437, 307, 33812, 5221, 13, 50964], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 337, "seek": 102200, "start": 1034.0, "end": 1035.0, "text": " I'm sorry.", "tokens": [50964, 286, 478, 2597, 13, 51014], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 338, "seek": 102200, "start": 1035.0, "end": 1039.0, "text": " Um, so I cannot answer your squinch with your question.", "tokens": [51014, 3301, 11, 370, 286, 2644, 1867, 428, 2339, 12415, 365, 428, 1168, 13, 51214], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 339, "seek": 102200, "start": 1039.0, "end": 1040.0, "text": " I think.", "tokens": [51214, 286, 519, 13, 51264], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 340, "seek": 102200, "start": 1042.0, "end": 1043.0, "text": " Sorry.", "tokens": [51364, 4919, 13, 51414], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 341, "seek": 102200, "start": 1043.0, "end": 1046.0, "text": " But I mean, Maxima is ready in Como List.", "tokens": [51414, 583, 286, 914, 11, 7402, 4775, 307, 1919, 294, 11913, 17668, 13, 51564], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 342, "seek": 102200, "start": 1046.0, "end": 1048.0, "text": " That's just a preference for me because I like, uh,", "tokens": [51564, 663, 311, 445, 257, 17502, 337, 385, 570, 286, 411, 11, 2232, 11, 51664], "temperature": 0.0, "avg_logprob": -0.28313943241419415, "compression_ratio": 1.3842105263157896, "no_speech_prob": 0.0031502617057412863}, {"id": 343, "seek": 104800, "start": 1048.0, "end": 1052.0, "text": " a list dialect and Camel is interesting.", "tokens": [50364, 257, 1329, 24652, 293, 6886, 338, 307, 1880, 13, 50564], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 344, "seek": 104800, "start": 1052.0, "end": 1057.0, "text": " Um, yeah.", "tokens": [50564, 3301, 11, 1338, 13, 50814], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 345, "seek": 104800, "start": 1057.0, "end": 1063.0, "text": " Uh, do you plan to have a maximum for session for Maxima code", "tokens": [50814, 4019, 11, 360, 291, 1393, 281, 362, 257, 6674, 337, 5481, 337, 7402, 4775, 3089, 51114], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 346, "seek": 104800, "start": 1063.0, "end": 1064.0, "text": " block?", "tokens": [51114, 3461, 30, 51164], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 347, "seek": 104800, "start": 1064.0, "end": 1065.0, "text": " Yes.", "tokens": [51164, 1079, 13, 51214], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 348, "seek": 104800, "start": 1065.0, "end": 1070.0, "text": " I want to improve the, um, of Maxima package,", "tokens": [51214, 286, 528, 281, 3470, 264, 11, 1105, 11, 295, 7402, 4775, 7372, 11, 51464], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 349, "seek": 104800, "start": 1070.0, "end": 1073.0, "text": " but I didn't have enough time and I want to clear a little bit of", "tokens": [51464, 457, 286, 994, 380, 362, 1547, 565, 293, 286, 528, 281, 1850, 257, 707, 857, 295, 51614], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 350, "seek": 104800, "start": 1073.0, "end": 1077.0, "text": " the code because still right now, um,", "tokens": [51614, 264, 3089, 570, 920, 558, 586, 11, 1105, 11, 51814], "temperature": 0.0, "avg_logprob": -0.29862176288257947, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.007391692139208317}, {"id": 351, "seek": 107700, "start": 1078.0, "end": 1081.0, "text": " uh, the code is quite messy in some areas because I pretty much", "tokens": [50414, 2232, 11, 264, 3089, 307, 1596, 16191, 294, 512, 3179, 570, 286, 1238, 709, 50564], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 352, "seek": 107700, "start": 1081.0, "end": 1083.0, "text": " implement first the basic function.", "tokens": [50564, 4445, 700, 264, 3875, 2445, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 353, "seek": 107700, "start": 1083.0, "end": 1085.0, "text": " I want to build in top off.", "tokens": [50664, 286, 528, 281, 1322, 294, 1192, 766, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 354, "seek": 107700, "start": 1085.0, "end": 1086.0, "text": " So right now it's quite usable,", "tokens": [50764, 407, 558, 586, 309, 311, 1596, 29975, 11, 50814], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 355, "seek": 107700, "start": 1086.0, "end": 1088.0, "text": " but it's still have some things that I want to improve.", "tokens": [50814, 457, 309, 311, 920, 362, 512, 721, 300, 286, 528, 281, 3470, 13, 50914], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 356, "seek": 107700, "start": 1088.0, "end": 1091.0, "text": " So when I finish that, I will, um,", "tokens": [50914, 407, 562, 286, 2413, 300, 11, 286, 486, 11, 1105, 11, 51064], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 357, "seek": 107700, "start": 1091.0, "end": 1093.0, "text": " improve the normal version.", "tokens": [51064, 3470, 264, 2710, 3037, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 358, "seek": 107700, "start": 1093.0, "end": 1097.0, "text": " I think it maximized it to get into, into your video.", "tokens": [51164, 286, 519, 309, 5138, 1602, 309, 281, 483, 666, 11, 666, 428, 960, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 359, "seek": 107700, "start": 1097.0, "end": 1098.0, "text": " Yes.", "tokens": [51364, 1079, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 360, "seek": 107700, "start": 1098.0, "end": 1103.0, "text": " Uh, I think that the creator of Maxima like have this list, uh,", "tokens": [51414, 4019, 11, 286, 519, 300, 264, 14181, 295, 7402, 4775, 411, 362, 341, 1329, 11, 2232, 11, 51664], "temperature": 0.0, "avg_logprob": -0.20035123825073242, "compression_ratio": 1.6169354838709677, "no_speech_prob": 0.0013223558198660612}, {"id": 361, "seek": 110300, "start": 1103.0, "end": 1108.0, "text": " mine and probably, uh, um, that they,", "tokens": [50364, 3892, 293, 1391, 11, 2232, 11, 1105, 11, 300, 436, 11, 50614], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 362, "seek": 110300, "start": 1108.0, "end": 1112.0, "text": " if you go to a symbol, you get all the information and that reflect", "tokens": [50614, 498, 291, 352, 281, 257, 5986, 11, 291, 483, 439, 264, 1589, 293, 300, 5031, 50814], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 363, "seek": 110300, "start": 1112.0, "end": 1116.0, "text": " that you can actually write your program of Maxima into,", "tokens": [50814, 300, 291, 393, 767, 2464, 428, 1461, 295, 7402, 4775, 666, 11, 51014], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 364, "seek": 110300, "start": 1116.0, "end": 1121.0, "text": " um, into list literally cause they have a command.", "tokens": [51014, 1105, 11, 666, 1329, 3736, 3082, 436, 362, 257, 5622, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 365, "seek": 110300, "start": 1121.0, "end": 1123.0, "text": " So I think that is quite easy to get into.", "tokens": [51264, 407, 286, 519, 300, 307, 1596, 1858, 281, 483, 666, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 366, "seek": 110300, "start": 1123.0, "end": 1129.0, "text": " So many versions they use it for, um, first, um, years.", "tokens": [51364, 407, 867, 9606, 436, 764, 309, 337, 11, 1105, 11, 700, 11, 1105, 11, 924, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 367, "seek": 110300, "start": 1129.0, "end": 1130.0, "text": " So it is quite easy.", "tokens": [51664, 407, 309, 307, 1596, 1858, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19411484076052296, "compression_ratio": 1.6989795918367347, "no_speech_prob": 0.006565683521330357}, {"id": 368, "seek": 113000, "start": 1130.0, "end": 1134.0, "text": " And I think with my package, you can use it like pretty,", "tokens": [50364, 400, 286, 519, 365, 452, 7372, 11, 291, 393, 764, 309, 411, 1238, 11, 50564], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 369, "seek": 113000, "start": 1134.0, "end": 1135.0, "text": " pretty easily.", "tokens": [50564, 1238, 3612, 13, 50614], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 370, "seek": 113000, "start": 1135.0, "end": 1139.0, "text": " Just create a file and you can start typing and Maxima quite easy", "tokens": [50614, 1449, 1884, 257, 3991, 293, 291, 393, 722, 18444, 293, 7402, 4775, 1596, 1858, 50814], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 371, "seek": 113000, "start": 1139.0, "end": 1140.0, "text": " to install also.", "tokens": [50814, 281, 3625, 611, 13, 50864], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 372, "seek": 113000, "start": 1140.0, "end": 1143.0, "text": " So I think, yeah, it is quite easy.", "tokens": [50864, 407, 286, 519, 11, 1338, 11, 309, 307, 1596, 1858, 13, 51014], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 373, "seek": 113000, "start": 1143.0, "end": 1145.0, "text": " And the page, the page should restart.", "tokens": [51014, 400, 264, 3028, 11, 264, 3028, 820, 21022, 13, 51114], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 374, "seek": 113000, "start": 1145.0, "end": 1147.0, "text": " I don't know why.", "tokens": [51114, 286, 500, 380, 458, 983, 13, 51214], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 375, "seek": 113000, "start": 1147.0, "end": 1148.0, "text": " Sorry.", "tokens": [51214, 4919, 13, 51264], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 376, "seek": 113000, "start": 1149.0, "end": 1150.0, "text": " Okay.", "tokens": [51314, 1033, 13, 51364], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 377, "seek": 113000, "start": 1150.0, "end": 1153.0, "text": " Uh, Maxima seems to have strict infix listener.", "tokens": [51364, 4019, 11, 7402, 4775, 2544, 281, 362, 10910, 1536, 970, 31569, 13, 51514], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 378, "seek": 113000, "start": 1153.0, "end": 1154.0, "text": " Hmm.", "tokens": [51514, 8239, 13, 51564], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 379, "seek": 113000, "start": 1154.0, "end": 1159.0, "text": " Uh, infix strict infix.", "tokens": [51564, 4019, 11, 1536, 970, 10910, 1536, 970, 13, 51814], "temperature": 0.0, "avg_logprob": -0.30752793033566095, "compression_ratio": 1.5971563981042654, "no_speech_prob": 0.008441813290119171}, {"id": 380, "seek": 115900, "start": 1159.0, "end": 1161.0, "text": " Infix list syntax.", "tokens": [50364, 11537, 970, 1329, 28431, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 381, "seek": 115900, "start": 1161.0, "end": 1167.0, "text": " Um, you're talking about the Maxima itself syntax or I don't", "tokens": [50464, 3301, 11, 291, 434, 1417, 466, 264, 7402, 4775, 2564, 28431, 420, 286, 500, 380, 50764], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 382, "seek": 115900, "start": 1167.0, "end": 1168.0, "text": " understand the question.", "tokens": [50764, 1223, 264, 1168, 13, 50814], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 383, "seek": 115900, "start": 1168.0, "end": 1174.0, "text": " Well, I going to go to the next question.", "tokens": [50814, 1042, 11, 286, 516, 281, 352, 281, 264, 958, 1168, 13, 51114], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 384, "seek": 115900, "start": 1174.0, "end": 1177.0, "text": " Is there a support for images in Maxima mode?", "tokens": [51114, 1119, 456, 257, 1406, 337, 5267, 294, 7402, 4775, 4391, 30, 51264], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 385, "seek": 115900, "start": 1177.0, "end": 1178.0, "text": " Not right now.", "tokens": [51264, 1726, 558, 586, 13, 51314], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 386, "seek": 115900, "start": 1178.0, "end": 1186.0, "text": " Uh, the way I want to implement some IMAX, um, things.", "tokens": [51314, 4019, 11, 264, 636, 286, 528, 281, 4445, 512, 286, 9998, 55, 11, 1105, 11, 721, 13, 51714], "temperature": 0.0, "avg_logprob": -0.23336373754294523, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.002411187393590808}, {"id": 387, "seek": 118600, "start": 1187.0, "end": 1191.0, "text": " Uh, is there a support for, but right now it doesn't have like,", "tokens": [50414, 4019, 11, 307, 456, 257, 1406, 337, 11, 457, 558, 586, 309, 1177, 380, 362, 411, 11, 50614], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 388, "seek": 118600, "start": 1191.0, "end": 1195.0, "text": " uh, if you want to have a new plot, um, inside your buffer right now,", "tokens": [50614, 2232, 11, 498, 291, 528, 281, 362, 257, 777, 7542, 11, 1105, 11, 1854, 428, 21762, 558, 586, 11, 50814], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 389, "seek": 118600, "start": 1195.0, "end": 1196.0, "text": " it's not possible.", "tokens": [50814, 309, 311, 406, 1944, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 390, "seek": 118600, "start": 1196.0, "end": 1201.0, "text": " So that's the thing that I Maxima does that Maxima.l still doesn't", "tokens": [50864, 407, 300, 311, 264, 551, 300, 286, 7402, 4775, 775, 300, 7402, 4775, 13, 75, 920, 1177, 380, 51114], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 391, "seek": 118600, "start": 1201.0, "end": 1204.0, "text": " do which university you start to use Maxima.", "tokens": [51114, 360, 597, 5454, 291, 722, 281, 764, 7402, 4775, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 392, "seek": 118600, "start": 1204.0, "end": 1210.0, "text": " Um, in the Saragossa university from Spain, they use Maxima in", "tokens": [51264, 3301, 11, 294, 264, 6894, 559, 9978, 5454, 490, 12838, 11, 436, 764, 7402, 4775, 294, 51564], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 393, "seek": 118600, "start": 1210.0, "end": 1215.0, "text": " the, um, thing in the engineer and in the math also.", "tokens": [51564, 264, 11, 1105, 11, 551, 294, 264, 11403, 293, 294, 264, 5221, 611, 13, 51814], "temperature": 0.0, "avg_logprob": -0.24519601904827615, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.008617247454822063}, {"id": 394, "seek": 121500, "start": 1215.0, "end": 1219.0, "text": " So not 100% sure right now, but when I started, are you planning", "tokens": [50364, 407, 406, 2319, 4, 988, 558, 586, 11, 457, 562, 286, 1409, 11, 366, 291, 5038, 50564], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 395, "seek": 121500, "start": 1219.0, "end": 1221.0, "text": " to open your package into Maxima?", "tokens": [50564, 281, 1269, 428, 7372, 666, 7402, 4775, 30, 50664], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 396, "seek": 121500, "start": 1221.0, "end": 1226.0, "text": " Um, I don't know about that because, um, maybe can be a little bit messy.", "tokens": [50664, 3301, 11, 286, 500, 380, 458, 466, 300, 570, 11, 1105, 11, 1310, 393, 312, 257, 707, 857, 16191, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 397, "seek": 121500, "start": 1226.0, "end": 1232.0, "text": " Um, because the Maxima repel is more built around like Maxima", "tokens": [50914, 3301, 11, 570, 264, 7402, 4775, 1085, 338, 307, 544, 3094, 926, 411, 7402, 4775, 51214], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 398, "seek": 121500, "start": 1232.0, "end": 1237.0, "text": " itself and they don't update the interfaces that much.", "tokens": [51214, 2564, 293, 436, 500, 380, 5623, 264, 28416, 300, 709, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 399, "seek": 121500, "start": 1237.0, "end": 1238.0, "text": " I have no problem.", "tokens": [51464, 286, 362, 572, 1154, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 400, "seek": 121500, "start": 1238.0, "end": 1240.0, "text": " Like it's okay.", "tokens": [51514, 1743, 309, 311, 1392, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1656130055586497, "compression_ratio": 1.4930875576036866, "no_speech_prob": 0.006354056764394045}, {"id": 401, "seek": 124000, "start": 1240.0, "end": 1245.0, "text": " It just, um, you just have to, um, if you want to push,", "tokens": [50364, 467, 445, 11, 1105, 11, 291, 445, 362, 281, 11, 1105, 11, 498, 291, 528, 281, 2944, 11, 50614], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 402, "seek": 124000, "start": 1245.0, "end": 1247.0, "text": " you can push in other repository.", "tokens": [50614, 291, 393, 2944, 294, 661, 25841, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 403, "seek": 124000, "start": 1247.0, "end": 1251.0, "text": " I mean, it's just changed the file in other way, but also the", "tokens": [50714, 286, 914, 11, 309, 311, 445, 3105, 264, 3991, 294, 661, 636, 11, 457, 611, 264, 50914], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 404, "seek": 124000, "start": 1251.0, "end": 1254.0, "text": " test, um, it's going to be a little bit harder because I think", "tokens": [50914, 1500, 11, 1105, 11, 309, 311, 516, 281, 312, 257, 707, 857, 6081, 570, 286, 519, 51064], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 405, "seek": 124000, "start": 1254.0, "end": 1260.0, "text": " they're using, uh, search for, um, I'm using, uh, kid lab, uh,", "tokens": [51064, 436, 434, 1228, 11, 2232, 11, 3164, 337, 11, 1105, 11, 286, 478, 1228, 11, 2232, 11, 1636, 2715, 11, 2232, 11, 51364], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 406, "seek": 124000, "start": 1260.0, "end": 1262.0, "text": " continue integration with you in delivery.", "tokens": [51364, 2354, 10980, 365, 291, 294, 8982, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 407, "seek": 124000, "start": 1262.0, "end": 1268.0, "text": " So yeah, I don't think that, but it will, yeah, it will be nice.", "tokens": [51464, 407, 1338, 11, 286, 500, 380, 519, 300, 11, 457, 309, 486, 11, 1338, 11, 309, 486, 312, 1481, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23285607267017208, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.006462903693318367}, {"id": 408, "seek": 127000, "start": 1271.0, "end": 1272.0, "text": " Okay.", "tokens": [50414, 1033, 13, 50464], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 409, "seek": 127000, "start": 1272.0, "end": 1274.0, "text": " Um, it's possible to include maximizing or files,", "tokens": [50464, 3301, 11, 309, 311, 1944, 281, 4090, 5138, 3319, 420, 7098, 11, 50564], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 410, "seek": 127000, "start": 1274.0, "end": 1276.0, "text": " similar to Jupyter notebooks.", "tokens": [50564, 2531, 281, 22125, 88, 391, 43782, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 411, "seek": 127000, "start": 1276.0, "end": 1280.0, "text": " Um, I mean, you can, uh, use Maxima in your,", "tokens": [50664, 3301, 11, 286, 914, 11, 291, 393, 11, 2232, 11, 764, 7402, 4775, 294, 428, 11, 50864], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 412, "seek": 127000, "start": 1280.0, "end": 1284.0, "text": " or, uh, files and you have Maxima.l mode integrated.", "tokens": [50864, 420, 11, 2232, 11, 7098, 293, 291, 362, 7402, 4775, 13, 75, 4391, 10919, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 413, "seek": 127000, "start": 1284.0, "end": 1288.0, "text": " And you can like create, uh, put that code in a buffer and then,", "tokens": [51064, 400, 291, 393, 411, 1884, 11, 2232, 11, 829, 300, 3089, 294, 257, 21762, 293, 550, 11, 51264], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 414, "seek": 127000, "start": 1288.0, "end": 1294.0, "text": " uh, um, uh, edit it correctly, but it is now not,", "tokens": [51264, 2232, 11, 1105, 11, 2232, 11, 8129, 309, 8944, 11, 457, 309, 307, 586, 406, 11, 51564], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 415, "seek": 127000, "start": 1294.0, "end": 1297.0, "text": " it doesn't have like all the features like all the languages", "tokens": [51564, 309, 1177, 380, 362, 411, 439, 264, 4122, 411, 439, 264, 8650, 51714], "temperature": 0.0, "avg_logprob": -0.25520623248556384, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.005940655246376991}, {"id": 416, "seek": 129700, "start": 1297.0, "end": 1301.0, "text": " because right now, uh, as my understanding is quite basic.", "tokens": [50364, 570, 558, 586, 11, 2232, 11, 382, 452, 3701, 307, 1596, 3875, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 417, "seek": 129700, "start": 1301.0, "end": 1306.0, "text": " So I still have some, still need some, some stuff, some workaround.", "tokens": [50564, 407, 286, 920, 362, 512, 11, 920, 643, 512, 11, 512, 1507, 11, 512, 589, 25762, 13, 50814], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 418, "seek": 129700, "start": 1308.0, "end": 1309.0, "text": " Okay.", "tokens": [50914, 1033, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 419, "seek": 129700, "start": 1309.0, "end": 1310.0, "text": " I think that's it.", "tokens": [50964, 286, 519, 300, 311, 309, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 420, "seek": 129700, "start": 1316.0, "end": 1317.0, "text": " Yep.", "tokens": [51314, 7010, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 421, "seek": 129700, "start": 1317.0, "end": 1318.0, "text": " So that's it.", "tokens": [51364, 407, 300, 311, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 422, "seek": 129700, "start": 1318.0, "end": 1322.0, "text": " Uh, thank you very much for your live talk and for,", "tokens": [51414, 4019, 11, 1309, 291, 588, 709, 337, 428, 1621, 751, 293, 337, 11, 51614], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 423, "seek": 129700, "start": 1322.0, "end": 1323.0, "text": " you know, the live Q&A.", "tokens": [51614, 291, 458, 11, 264, 1621, 1249, 5, 32, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 424, "seek": 129700, "start": 1324.0, "end": 1325.0, "text": " Thank you.", "tokens": [51714, 1044, 291, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18255509270562065, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.016600394621491432}, {"id": 425, "seek": 132500, "start": 1325.0, "end": 1326.0, "text": " Thank you all.", "tokens": [50364, 1044, 291, 439, 13, 50414], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 426, "seek": 132500, "start": 1326.0, "end": 1327.0, "text": " Amazing.", "tokens": [50414, 14165, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 427, "seek": 132500, "start": 1328.0, "end": 1329.0, "text": " Cheers.", "tokens": [50514, 13006, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 428, "seek": 132500, "start": 1329.0, "end": 1330.0, "text": " Thank you.", "tokens": [50564, 1044, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 429, "seek": 132500, "start": 1330.0, "end": 1331.0, "text": " It's thanks to all you guys.", "tokens": [50614, 467, 311, 3231, 281, 439, 291, 1074, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 430, "seek": 132500, "start": 1331.0, "end": 1332.0, "text": " It's awesome.", "tokens": [50664, 467, 311, 3476, 13, 50714], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 431, "seek": 132500, "start": 1332.0, "end": 1333.0, "text": " Okay.", "tokens": [50714, 1033, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 432, "seek": 132500, "start": 1333.0, "end": 1334.0, "text": " Thank you.", "tokens": [50764, 1044, 291, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 433, "seek": 132500, "start": 1334.0, "end": 1335.0, "text": " Cheers.", "tokens": [50814, 13006, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 434, "seek": 132500, "start": 1335.0, "end": 1336.0, "text": " Bye.", "tokens": [50864, 4621, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}, {"id": 435, "seek": 132500, "start": 1336.0, "end": 1337.0, "text": " Bye.", "tokens": [50914, 4621, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19023381618031285, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.040191397070884705}], "language": "en"}