1
00:00:00,000 --> 00:00:02,060
you

2
00:00:30,000 --> 00:00:32,060
you

3
00:01:00,000 --> 00:01:02,060
you

4
00:01:30,000 --> 00:01:32,060
you

5
00:02:00,000 --> 00:02:02,360
you

6
00:09:00,000 --> 00:09:29,480
good afternoon I still have to wait for a sign since we

7
00:09:29,480 --> 00:09:38,400
the livestream determines the program are we ready I guess we are ready good

8
00:09:38,400 --> 00:09:43,720
afternoon dear ladies and gentlemen the president of the Bavarian Academy of

9
00:09:43,720 --> 00:09:48,840
Science I would like to welcome you all to our talk focusing on current

10
00:09:48,840 --> 00:09:54,920
developments of advanced computing technologies we are very proud to host

11
00:09:54,920 --> 00:10:01,820
this event in the rural residents in the center of Munich which houses the main

12
00:10:01,820 --> 00:10:09,200
office of the Bavarian Academy of Science founded in 1759 the Academy

13
00:10:09,200 --> 00:10:15,080
functions today as a community of scholars a non-university research

14
00:10:15,080 --> 00:10:19,680
institution and a communication interface between the Bavarian

15
00:10:19,680 --> 00:10:26,240
scientific community society and policymakers with the scholars the

16
00:10:26,240 --> 00:10:31,240
Academy provides a powerful internet disciplinary network of very

17
00:10:31,240 --> 00:10:37,880
established scientists this network of excellence interacts very closely with

18
00:10:37,880 --> 00:10:43,720
all Bavarian research institutions and political decision makers and represents

19
00:10:43,720 --> 00:10:49,920
an important part of the science communication with the public research

20
00:10:49,920 --> 00:10:55,560
activities range from the composer Richard Strauss to the study of climate

21
00:10:55,560 --> 00:11:01,600
change in their alps from baroque ceiling paintings to quantum physics the

22
00:11:01,600 --> 00:11:06,520
longer-term basic research spans from natural science to technology to

23
00:11:06,520 --> 00:11:12,120
humanities and social studies the Academy research project actively

24
00:11:12,160 --> 00:11:18,200
leverage the latest digital technologies the Leibniz supercomputer center also

25
00:11:18,200 --> 00:11:23,880
part of our Academy serves as an important infrastructural support for

26
00:11:23,880 --> 00:11:29,120
digital activities at Bavarian universities today we will hear an

27
00:11:29,120 --> 00:11:33,440
important contribution to the rapidly growing discussions about artificial

28
00:11:33,440 --> 00:11:39,280
intelligence from Jan Lecun who is according to the Time magazine one of

29
00:11:39,280 --> 00:11:45,280
the hundred worldwide leading AI pioneers his professor of NYU on chief

30
00:11:45,280 --> 00:11:53,000
I scientists at Metta not in California in New York I just learned the title of

31
00:11:53,000 --> 00:11:57,960
his talk from machine learning to autonomous intelligence artificial

32
00:11:57,960 --> 00:12:02,120
intelligence as you all know is the key topic of our time not only in research

33
00:12:02,120 --> 00:12:08,000
and industry but also in the broader society this becomes evident as a large

34
00:12:08,120 --> 00:12:13,760
interest and thank you for all coming to this meeting on sharing this

35
00:12:13,760 --> 00:12:20,840
experience we're very pleased as Bavarian Academy to gather with the AI agency to

36
00:12:20,840 --> 00:12:26,840
be part of biosphere biosphere is the official network of all AI activities

37
00:12:26,840 --> 00:12:33,560
in Bavaria we partner in this important task to advance AI science in Bavaria in

38
00:12:33,640 --> 00:12:39,000
close cooperation with the Center for Advanced Studies at LMU the Bavarian

39
00:12:39,000 --> 00:12:43,040
Research Institute for Digital Transformation the Munich Center for

40
00:12:43,040 --> 00:12:50,680
Machine Learning and the Konrad Susie School of Excellence in Reliable AI the

41
00:12:50,680 --> 00:12:55,080
event today is part of this successful cooperation and we're looking very

42
00:12:55,080 --> 00:13:00,480
broadly forward to learn more about recent progress from advanced computing to

43
00:13:00,480 --> 00:13:07,520
autonomous intelligence I hereby hand over to professor Thomas Seidel member

44
00:13:07,520 --> 00:13:13,440
of the Bavarian AI Council chair of database systems and data mining

45
00:13:13,440 --> 00:13:20,280
director of Munich Center for Machine Learning to all of you I wish a very

46
00:13:20,440 --> 00:13:25,760
insightful and informative afternoon the Seidel

47
00:13:33,760 --> 00:13:39,720
yeah thank you President Schweiger for this nice introduction and very warm

48
00:13:39,720 --> 00:13:45,600
welcome also from my side to all of you particularly to Jan Leckardt to be here

49
00:13:45,600 --> 00:13:52,040
today I wear two hats today one is I'm a member of the Bavarian AI Council we

50
00:13:52,040 --> 00:13:56,560
are 20 members appointed by the Bavarian state government as part of their high

51
00:13:56,560 --> 00:14:01,600
tech agenda from universities research institutions and also companies in the

52
00:14:01,600 --> 00:14:07,000
field to advise the government on AI strategies and actions particularly in

53
00:14:07,000 --> 00:14:13,440
steering the Bavarian AI agency so the representative is also Dr. Klimke which

54
00:14:13,480 --> 00:14:18,560
promotes the Bavarian network which we call biosphere so the logo is there as

55
00:14:18,560 --> 00:14:23,120
well so the biosphere comprises a variety of strong AI players in Bavaria

56
00:14:23,120 --> 00:14:27,400
also universities research institutes from all over Bavaria as well as a lot

57
00:14:27,400 --> 00:14:32,000
of the global companies we have here including Google, Microsoft, IBM but

58
00:14:32,000 --> 00:14:38,800
also the locally sitting global players Siemens, BMWs, every insurances Munich

59
00:14:38,800 --> 00:14:43,520
three Alliance and so on but also many original small and medium enterprises

60
00:14:43,520 --> 00:14:50,800
and startups in the field of AI so the second hat I am aware today's I'm one

61
00:14:50,800 --> 00:14:53,920
of the four directors of the Munich Center for Machine Learning one of the

62
00:14:53,920 --> 00:15:00,120
co-directors Daniel Gremmels also here and we this is a consortium of LMU and

63
00:15:00,120 --> 00:15:05,160
Tom funded by the BNBF in the Bavarian high-tech agenda with around 50 PIs in

64
00:15:05,160 --> 00:15:08,800
machine learning in the I3 junior research groups recently established

65
00:15:08,800 --> 00:15:14,480
around 200 doctoral students and our focus is on foundations of machine

66
00:15:14,480 --> 00:15:19,120
learning where we have several players including Gitta Kottiniok from the

67
00:15:19,120 --> 00:15:23,040
mathematical part and statistics and computer science is there then perception

68
00:15:23,040 --> 00:15:28,360
we are particularly strong in computer vision here and in Munich and in natural

69
00:15:28,360 --> 00:15:34,560
language processing the two big things where humans and computers interact

70
00:15:34,600 --> 00:15:41,280
and a lot of domain specific things it's not on research but also on transfer

71
00:15:41,280 --> 00:15:46,120
activities fostering the collaboration network together with the biosphere

72
00:15:46,120 --> 00:15:50,560
outreach to the general public things like that if you're interested also

73
00:15:50,560 --> 00:15:55,200
openings of course so this is that part so I'm sure we get fully inspired by

74
00:15:55,200 --> 00:16:00,240
your presentation and between your presentation is now the next is Dr. Mayer

75
00:16:00,240 --> 00:16:13,360
from TASS, you're on stage, thank you ladies and gentlemen may I also welcome

76
00:16:13,360 --> 00:16:17,920
you warmly on behalf of the Center for Advanced Studies at LMU and let me

77
00:16:17,920 --> 00:16:22,440
briefly say a few words about this institution and how it comes into play

78
00:16:22,440 --> 00:16:27,840
the Center for Advanced Studies at LMU was founded 15 years ago to provide a

79
00:16:27,960 --> 00:16:33,600
forum for precisely those research questions that cannot be tackled by

80
00:16:33,600 --> 00:16:39,200
only one discipline this was intended to take account of an increasingly

81
00:16:39,200 --> 00:16:45,200
diversifying but also specializing body of research that is becoming more and

82
00:16:45,200 --> 00:16:50,640
more disparate not only in terms of content but also in terms of space in

83
00:16:50,640 --> 00:16:56,640
Munich you can just think of the campus in Ober-Schleishheim, Ober-Guy-Ching,

84
00:16:56,640 --> 00:17:02,600
Nordeid in the far south so the Center for Advanced Studies offers the place

85
00:17:02,600 --> 00:17:09,120
where these centrifugal forces can be bundled and for what topic does this

86
00:17:09,120 --> 00:17:14,200
task play a more important role than for artificial intelligence which is

87
00:17:14,200 --> 00:17:21,080
spread across most faculties of LMU and other universities it was therefore a

88
00:17:21,080 --> 00:17:25,600
great pleasure for us when Gitta Kutinyok freshly appointed at our

89
00:17:25,640 --> 00:17:30,680
university approached us and asked whether a form it could be found that

90
00:17:30,680 --> 00:17:36,920
would network research on AI at LMU and unable to discuss overarching issues

91
00:17:36,920 --> 00:17:42,280
together it wasn't long before a so-called interdisciplinary CAS

92
00:17:42,280 --> 00:17:47,880
research focused entitled next generation AI was born bringing together

93
00:17:47,880 --> 00:17:53,960
researchers from 14 faculties working on the topic of artificial intelligence

94
00:17:53,960 --> 00:17:59,960
over the course of two years a wide variety of lectures workshops and

95
00:17:59,960 --> 00:18:05,680
conferences was organized and held and we were thrilled by the spirit that

96
00:18:05,680 --> 00:18:11,120
emerged of that group that's why we look forward to Professor LeCun's lecture

97
00:18:11,120 --> 00:18:16,760
today with both a smile and a tear as it marks the formal conclusion of the

98
00:18:16,760 --> 00:18:22,040
research focus we are honored and grateful that Professor LeCun is going

99
00:18:22,080 --> 00:18:39,320
to give the lecture in this framework today yeah also a warm welcome from my

100
00:18:39,320 --> 00:18:44,320
side to everyone here on site and also to everyone who participates via

101
00:18:44,320 --> 00:18:49,240
live stream it is wonderful to have so many people with us here this afternoon

102
00:18:49,920 --> 00:18:52,760
and a great thanks to all of our cooperation partners for actually

103
00:18:52,760 --> 00:18:56,720
making this lecture possible and here I would like to particularly thank Dr

104
00:18:56,720 --> 00:19:00,640
Anette Meyer and the Center for Advanced Studies of the Ludwig Maximilians

105
00:19:00,640 --> 00:19:05,400
University München Professor Dr. Markus Schweiger and the Bavarian Academy of

106
00:19:05,400 --> 00:19:10,120
Sciences and Humanities that this event can take place here in the academy in

107
00:19:10,120 --> 00:19:14,640
these really beautiful rooms Professor Dr. Thomas Seidel and Dr. Michael

108
00:19:14,680 --> 00:19:19,320
Klimker from the biosphere the Bavarian Eye Network which made the live stream

109
00:19:19,320 --> 00:19:24,520
for the event possible and also Dr. Christoph Egle from the Bavarian

110
00:19:24,520 --> 00:19:29,360
Research Institute for Digital Transformation and now it's my great

111
00:19:29,360 --> 00:19:34,400
pleasure and honor to welcome Professor Jan LeCun thank you very much for

112
00:19:34,400 --> 00:19:39,080
accepting our invitation and for coming to Munich for this lecture today

113
00:19:39,680 --> 00:19:44,520
Professor LeCun is chief AI scientist at Meta and the silver professor of

114
00:19:44,520 --> 00:19:49,680
computer science at New York University he started his career with a PhD in

115
00:19:49,680 --> 00:19:55,400
computer science at Sorbonne University in Paris and then moved to the US where

116
00:19:55,400 --> 00:20:00,360
he became the head of the image processing research department at the

117
00:20:00,360 --> 00:20:08,120
famous Bell Labs the AT&T Bell Laboratories then after intermediate

118
00:20:08,160 --> 00:20:14,320
stations he joined New York University in 2003 and he also became there the

119
00:20:14,320 --> 00:20:22,000
founding director of the NYU Center for Data Science in 2012. His groundbreaking

120
00:20:22,000 --> 00:20:26,320
work includes among many others the development of convolutional neural

121
00:20:26,320 --> 00:20:30,480
networks which are the state-of-the-art for basically any problem in particular

122
00:20:30,480 --> 00:20:35,360
imaging sciences and computer vision and a particularly particular convolutional

123
00:20:35,560 --> 00:20:41,240
network architecture is also named by him the so-called LeNet which in

124
00:20:41,240 --> 00:20:45,440
sense also promoted the impressive development of deep learning and AI as

125
00:20:45,440 --> 00:20:52,520
we experience it today. His contributions are honored by numerous awards many more

126
00:20:52,520 --> 00:20:57,120
than I could name here let me just mention that he's a member of the US

127
00:20:57,120 --> 00:21:01,640
National Academy of Sciences and the National Academy of Engineering he

128
00:21:01,640 --> 00:21:07,480
received various honorary degrees for instance from EPFL, received the IEEE

129
00:21:07,480 --> 00:21:15,800
neural network pioneer award and in 2019 the Turing Award which is typically

130
00:21:15,800 --> 00:21:20,880
referred to as the Nobel Prize of Computing and just a few weeks ago we

131
00:21:20,880 --> 00:21:25,720
already heard at the Time Magazine and congratulations to that has selected him

132
00:21:25,720 --> 00:21:32,280
as one of the 100 most influential people in AI worldwide and he also

133
00:21:32,280 --> 00:21:36,840
repeatedly contributes to the public debate about AI with also controversial

134
00:21:36,840 --> 00:21:43,680
proclamations for example on the current craze around large language models. How

135
00:21:43,680 --> 00:21:49,600
could machines to learn as efficiently as humans and animals? How could machines

136
00:21:49,720 --> 00:21:56,360
learn to reason and plan? In his lecture Professor Jan LeKang will now talk about

137
00:21:56,360 --> 00:22:02,760
a possible path towards an autonomous intelligent agents based on a new

138
00:22:02,760 --> 00:22:07,440
modular cognitive architecture. Where come Jan? The floor is yours.

139
00:22:19,600 --> 00:22:33,760
Thank you very much for the introduction and thank you very much for

140
00:22:33,760 --> 00:22:38,960
inviting me for coming here so so numerous. I have to correct one thing

141
00:22:38,960 --> 00:22:46,960
though I did not call convolutional net solonet this was my lab director at Bell

142
00:22:46,960 --> 00:22:58,640
Labs who gave it that name I would never done this but it's a good name okay it's

143
00:22:58,640 --> 00:23:02,880
a long title and a long subtitle objective-driven AI this is what I call

144
00:23:02,880 --> 00:23:08,360
this I used to give this talk with the title autonomous machine intelligence

145
00:23:08,360 --> 00:23:15,040
and and it scares people you know they say do you mean machines that will be

146
00:23:15,040 --> 00:23:17,880
autonomous we're not going to be able to control them so I changed the name to

147
00:23:17,880 --> 00:23:22,840
objective-driven AI because that's really more accurate and they're really kind

148
00:23:22,840 --> 00:23:26,640
of systems it's an aspiration it's not something that we've done it's something

149
00:23:26,640 --> 00:23:31,480
that we should do and there are systems that could of course learn remember

150
00:23:31,480 --> 00:23:39,080
reason plan have common sense be steerable controllable safe and have the

151
00:23:39,080 --> 00:23:42,880
same kind of learning abilities and intelligence that we observe in animals

152
00:23:42,920 --> 00:23:50,120
and humans so let me start by a little bit of the state of the art okay because

153
00:23:50,120 --> 00:23:54,640
there's a lot of debates today about about AI and a lot of people are afraid

154
00:23:54,640 --> 00:24:00,280
of AI it's understandable whenever there is technological revolution people are

155
00:24:00,280 --> 00:24:05,280
afraid of the unknown and AI is promising to be a big revolution so people

156
00:24:05,280 --> 00:24:10,080
are afraid so let's first talk about the benefits before we talk about the risks

157
00:24:10,760 --> 00:24:17,680
and the benefits are of AI are numerous already today and there is you know even

158
00:24:17,680 --> 00:24:23,400
more coming in medicine particularly in imaging diagnosis assistant treatment

159
00:24:23,400 --> 00:24:27,480
protocol drug design things like this very promising research transportation

160
00:24:27,480 --> 00:24:32,480
every car sold in the European Union today has to come with what's called a

161
00:24:32,480 --> 00:24:36,920
automatic emergency braking system a system that will automatically stop the

162
00:24:36,920 --> 00:24:42,480
car there is an obstacle in front of it and the driver does not react this

163
00:24:42,480 --> 00:24:47,960
saves lives it reduces frontal collision by 40% so AI saves lives and that uses

164
00:24:47,960 --> 00:24:56,120
convolutional nets by the way and in all the systems that I know in fact Germany

165
00:24:56,120 --> 00:25:03,920
was kind of a and and a very in particular was a pioneer in this some of

166
00:25:03,920 --> 00:25:09,000
the early systems of this type was the word developed by them events so driving

167
00:25:09,000 --> 00:25:12,520
assistance autonomous driving energy storage and management things like that

168
00:25:12,520 --> 00:25:16,160
environmental environmental monitoring and protection I'm going to say a few

169
00:25:16,160 --> 00:25:20,040
words about this content information and management this is probably the biggest

170
00:25:20,040 --> 00:25:25,280
use of AI today and of course in industry manufacturing information systems

171
00:25:25,280 --> 00:25:29,720
quality control etc a lot of applications are expected also in things like

172
00:25:29,720 --> 00:25:35,080
education for personalized education connecting people with each other with

173
00:25:35,080 --> 00:25:40,320
translation today presence augmented reality virtual reality and then

174
00:25:40,320 --> 00:25:45,160
enormous applications in science biology and genomics neuroscience physics

175
00:25:45,160 --> 00:25:49,600
particularly physics of disordered systems complex systems very large-scale

176
00:25:49,600 --> 00:25:56,440
simulations chemistry material science very promising area for AI so this well

177
00:25:56,480 --> 00:25:59,800
really and of course you know we've been talking a lot about creation like

178
00:25:59,800 --> 00:26:06,480
creating art AI is essentially enabling a lot more people to be creative people

179
00:26:06,480 --> 00:26:10,440
who don't necessarily have the technique the underlying technique for

180
00:26:10,440 --> 00:26:15,960
producing art so I will affect every aspect of human activity and let me give

181
00:26:15,960 --> 00:26:21,120
you a couple examples so this is a video that was put together by my colleagues

182
00:26:21,120 --> 00:26:25,840
at meta a couple years ago this is already sort of aging if you want and we

183
00:26:25,840 --> 00:26:32,360
chose the capability of computer vision system as of about two years ago so we

184
00:26:32,360 --> 00:26:36,800
can have systems that detect objects and put frames around them give them a name

185
00:26:36,800 --> 00:26:41,600
they can track human bodies and figure out in what what pose they are densely

186
00:26:41,600 --> 00:26:46,400
actually so that's actually very useful for all kinds of applications and more

187
00:26:46,400 --> 00:26:50,520
interestingly we can have systems that perform what's called semantic

188
00:26:50,520 --> 00:26:55,360
segmentation which means isolating every object marking them with kind of a mask

189
00:26:55,480 --> 00:27:00,040
and then giving them a name for a category and this works for a very

190
00:27:00,040 --> 00:27:04,880
fine-grained category for example the species of a bird or or plant or

191
00:27:04,880 --> 00:27:09,160
something of that type so it's pretty amazing it's not like computer vision is

192
00:27:09,160 --> 00:27:14,080
completely solved in fact if it was solved we wouldn't have the large

193
00:27:14,080 --> 00:27:19,760
conference that takes place in Paris next week called ICCV so there's still a

194
00:27:19,800 --> 00:27:28,400
lot of work to do but but there's been a huge amount of advances there and a lot

195
00:27:28,400 --> 00:27:36,920
of advances in AI but no advances in my slides for some reason okay my

196
00:27:36,920 --> 00:27:42,920
presentation refuses to advance hang on just one minute one second

197
00:27:50,760 --> 00:27:57,600
okay I mentioned medicine so certainly medical imaging is an area where a lot

198
00:27:57,600 --> 00:28:01,800
of work is going on there's too many to cite really this is some work by some of

199
00:28:01,800 --> 00:28:09,240
my colleagues at NYU that use 3d image recognition not just 2d in some cases

200
00:28:09,240 --> 00:28:14,560
this is actually 2d but that use various techniques to detect for example tumors

201
00:28:14,640 --> 00:28:22,000
in mammograms or particular things in MRI and other types of images and

202
00:28:22,000 --> 00:28:27,360
almost a lot of progress there some product project that took place a few

203
00:28:27,360 --> 00:28:31,240
years ago which was a collaboration between the NYU radiology department and

204
00:28:31,240 --> 00:28:37,080
people at fair Meta's fundamental research lab which essentially allows to

205
00:28:37,080 --> 00:28:41,280
accelerate the data collection for an MRI by a factor of 4 without degrading the

206
00:28:41,280 --> 00:28:46,080
image quality so instead of having to lie down in a MRI machine for 40 minutes

207
00:28:46,080 --> 00:28:49,320
or something you can reduce this to 10 minutes and have the same quality of

208
00:28:49,320 --> 00:28:54,640
images and that's thanks to deep learning essentially a lot of applications in

209
00:28:54,640 --> 00:29:01,520
science what's interesting today is that the favorite model that neuroscientists

210
00:29:01,520 --> 00:29:06,480
use to explain how the brain works use artificial neural nets so the best

211
00:29:06,480 --> 00:29:10,640
explanation for what we observe using functional MRI data in the visual

212
00:29:10,720 --> 00:29:15,280
cortex of humans and animals are actually models that are essentially

213
00:29:15,280 --> 00:29:22,600
convolutional net models and that's kind of a closing the circle because the

214
00:29:22,600 --> 00:29:26,560
architectural convolutional net is actually inspired by the architecture of

215
00:29:26,560 --> 00:29:31,800
the visual cortex classic work in neuroscience from the 1960s the similar

216
00:29:31,800 --> 00:29:40,280
work also in language understanding this is a recent paper in science by some

217
00:29:40,280 --> 00:29:45,360
colleagues from from from it actually and they try to figure out if the

218
00:29:45,360 --> 00:29:49,480
current large language models that everybody is playing with explain the

219
00:29:49,480 --> 00:29:54,240
what we observe in the brain when people are asked to kind of remember or

220
00:29:54,240 --> 00:29:59,360
understand a story and the answer is sort of but not really it doesn't work nearly

221
00:29:59,360 --> 00:30:03,680
as well as a convolutional net models for vision so what that means is that

222
00:30:03,680 --> 00:30:08,680
we're missing something that those models probably are not sufficient to

223
00:30:08,680 --> 00:30:14,040
explain what the brain does when when we understand language I mentioned some

224
00:30:14,040 --> 00:30:18,480
applications in science in particle physics in particular high energy physics

225
00:30:18,480 --> 00:30:24,520
to kind of make models of particle collisions and things of that type image

226
00:30:24,520 --> 00:30:30,280
processing to discover exoplanets some estimate says that about 12 percent of

227
00:30:30,280 --> 00:30:36,000
all physics papers today actually mention AI as a tool that he used which is

228
00:30:36,040 --> 00:30:42,560
astonishing in just a relatively short time and in the large-scale simulation

229
00:30:42,560 --> 00:30:46,080
sort of universe scale simulation that could sort of validate or invalidate

230
00:30:46,080 --> 00:30:51,760
certain theories about dark matter and things I guess so very fascinating work

231
00:30:51,760 --> 00:30:57,520
and applications this is a very interesting project that was started by

232
00:30:57,520 --> 00:31:03,280
some of my colleagues at fair by Larry Zittnick in particular called the open

233
00:31:03,280 --> 00:31:08,360
catalyst project and you can actually participate if you want the website is

234
00:31:08,360 --> 00:31:18,840
open-catalyst.org and and that project the idea of that project is that we

235
00:31:18,840 --> 00:31:23,800
could solve climate change if we had a good efficient scalable way of storing

236
00:31:23,800 --> 00:31:30,400
energy if we had a good way of storing energy we could cover a small desert

237
00:31:30,680 --> 00:31:36,880
with solar panels and produce enough energy to power Europe or the entire

238
00:31:36,880 --> 00:31:43,700
planet the problem is you have to have a way of storing energy which is why

239
00:31:43,700 --> 00:31:50,760
renewables today despite the decisions of the German government to go all out on

240
00:31:50,760 --> 00:31:57,840
it renewables are not drivable you can't control whenever there is wind or sun

241
00:31:58,120 --> 00:32:03,960
and so you need another source of energy when there is no no sun or or no no

242
00:32:03,960 --> 00:32:08,800
wind and and for that you need to be able to store energy and ship it wherever

243
00:32:08,800 --> 00:32:12,120
it's needed the best way to store energy is in the form of hydrogen or maybe

244
00:32:12,120 --> 00:32:17,080
methane and the best way to do this is by separating hydrogen from oxygen from

245
00:32:17,080 --> 00:32:20,960
water right so take some water put two electrodes and then separate hydrogen

246
00:32:20,960 --> 00:32:28,840
from oxygen problem with this is that it's either scalable if you use catalyst

247
00:32:28,840 --> 00:32:36,360
to do this like platinum sorry it's either efficient if you use catalyst like

248
00:32:36,360 --> 00:32:40,800
platinum or it's scalable but not efficient and so the big question is

249
00:32:40,800 --> 00:32:46,640
could we design compounds new catalyst that would facilitate this reaction so

250
00:32:46,640 --> 00:32:51,440
that is efficient but does not require exotic materials like like platinum so

251
00:32:51,440 --> 00:32:56,240
that is scalable and the idea there is that you do a lot of chemical

252
00:32:56,240 --> 00:33:02,080
simulation that's called DFT simulation of various of water on two various

253
00:33:02,080 --> 00:33:06,520
compounds and then you generate that data using simulation and also using

254
00:33:06,520 --> 00:33:10,320
experiments you put that data you make it available and then you ask people can

255
00:33:10,320 --> 00:33:14,240
you train machine learning system to figure out what the underlying rule is

256
00:33:14,240 --> 00:33:19,960
so that we can use it to design new materials that might have the same

257
00:33:19,960 --> 00:33:26,520
effect but be cheap so fascinating program it may not work but it's worth

258
00:33:26,520 --> 00:33:33,160
a shot okay now what's important to realize is that the progress we've seen

259
00:33:33,160 --> 00:33:36,720
over the last few years in AI and machine learning are due to a set of

260
00:33:36,720 --> 00:33:40,720
techniques that we call self-supervised running which I'm sure many of you here

261
00:33:40,720 --> 00:33:47,160
in the room have heard about and essentially self-supervised running

262
00:33:47,160 --> 00:33:52,880
would be a set of techniques that allows a system to be trained to represent the

263
00:33:52,880 --> 00:34:01,280
data the world without requiring labeled data okay without requiring sort of

264
00:34:01,280 --> 00:34:09,960
manual human intervention to produce the data so perhaps the best success of

265
00:34:09,960 --> 00:34:15,680
this idea which I've been advocating for a long time is in the context of natural

266
00:34:15,680 --> 00:34:21,960
language understanding so the way all NLP systems are trained today whether

267
00:34:21,960 --> 00:34:26,800
there are LLMs of the types that we play with or others is the following you

268
00:34:26,800 --> 00:34:32,360
take a piece of text a sequence of words and you remove some of the words you

269
00:34:32,360 --> 00:34:37,040
you mask you mask them you blank them out you replace them by a blank marker okay

270
00:34:37,080 --> 00:34:41,720
you corrupt essentially the input and you put it at the input of a large neural

271
00:34:41,720 --> 00:34:45,320
net you train this very large neural net usually usually a transformer

272
00:34:45,320 --> 00:34:51,240
architecture to predict the words that are missing in the process of doing so

273
00:34:51,240 --> 00:34:56,920
the system has to extract representations of the text that contain the

274
00:34:56,920 --> 00:35:03,320
semantics the syntax the you know grammar everything I sort of lied slightly

275
00:35:03,480 --> 00:35:08,120
here these are not words that are input they are what's called tokens which are

276
00:35:08,120 --> 00:35:13,720
essentially subword units so in most languages words have a prefix and a

277
00:35:13,720 --> 00:35:18,400
root and a suffix and you need to kind of separate those for those systems to

278
00:35:18,400 --> 00:35:22,200
work properly otherwise your dictionary of words would be gigantic and then in

279
00:35:22,200 --> 00:35:25,160
German you have to do it because you can have words that are long like this

280
00:35:25,160 --> 00:35:30,600
they are you know by so so there is no choice you have to break up words into

281
00:35:30,600 --> 00:35:37,000
subword units you know in tokens and so you train that you train the system and

282
00:35:37,000 --> 00:35:43,320
and this is the so-called BERT model if you want or idea and that's me

283
00:35:43,320 --> 00:35:46,800
incredibly successful it's completely self-supervised you don't need any other

284
00:35:46,800 --> 00:35:51,760
data than the text and once you've pre-trained that system you can use the

285
00:35:51,760 --> 00:35:57,680
internal representation produced by the system as input to a subsequent task a

286
00:35:57,680 --> 00:36:02,400
downstream task like let's say translation hate speech detection you

287
00:36:02,400 --> 00:36:06,200
know summarization whatever so that's the general idea of self-supervised

288
00:36:06,200 --> 00:36:10,880
running fill in the blanks have a big piece of data corrupt it in some way

289
00:36:10,880 --> 00:36:16,120
and then train some big neural net to fill in the blanks or or recover the

290
00:36:16,120 --> 00:36:21,200
original data a particularly stunning example of this which I'm not going to

291
00:36:21,200 --> 00:36:27,200
go into the technical details of but I will later is a system they came out of

292
00:36:27,240 --> 00:36:32,360
my colleagues that in Paris that fair Paris called Dino v2 you can think of it

293
00:36:32,360 --> 00:36:36,160
as a foundation model for vision so it's a system that is trained to extract

294
00:36:36,160 --> 00:36:39,960
features from images such that those features can be used for anything you

295
00:36:39,960 --> 00:36:43,960
want whether it's classification fine-grained classification depth

296
00:36:43,960 --> 00:36:48,200
estimation semantic segmentation instance retrieval so the same kind of

297
00:36:48,200 --> 00:36:52,120
application that I showed in the video but basically with very little

298
00:36:52,160 --> 00:36:56,880
supervision this is then it's pre-trained and it basically because it's

299
00:36:56,880 --> 00:37:03,640
pre-trained on enormous amounts of data just training a very shadow head to

300
00:37:03,640 --> 00:37:08,360
solve any particular one of those problems actually beats the state of the

301
00:37:08,360 --> 00:37:12,600
art for that's estimation or classification or whatever you can

302
00:37:12,600 --> 00:37:17,160
actually play with it interactively that's the URL that you see here and

303
00:37:17,160 --> 00:37:21,240
these are some examples of visualization of what the features that are

304
00:37:21,280 --> 00:37:26,640
extracted are it's kind of a you know colorful representation of the like

305
00:37:26,640 --> 00:37:30,840
different feature vectors are represented by different colors this is

306
00:37:30,840 --> 00:37:33,600
actually kind of each color is like a principal component if you know what

307
00:37:33,600 --> 00:37:39,080
that is so those are you know examples on sort of typical typical images and

308
00:37:39,080 --> 00:37:42,600
people I've started to use this for all kinds of stuff for biological image

309
00:37:42,600 --> 00:37:49,120
analysis for astronomy for for environmental protection so that's the

310
00:37:49,120 --> 00:37:53,240
next example I'm going to show you so this is a project by someone on the team

311
00:37:53,240 --> 00:37:58,480
Camille Coupri and a large collection collection of collaborators and what she

312
00:37:58,480 --> 00:38:06,800
did was use the Dino V2 features and trained relatively small system on top

313
00:38:06,800 --> 00:38:13,600
of it to tell what the height of the trees are from a satellite image so we

314
00:38:13,600 --> 00:38:17,400
have lots of satellite images on the entire world at half meter resolution

315
00:38:17,400 --> 00:38:22,560
you can get this from a satellite imaging companies and for some areas

316
00:38:22,560 --> 00:38:27,960
there is LiDAR data which tells you how tall the trees are so you use that to

317
00:38:27,960 --> 00:38:31,040
train the system and then you can apply it to the entire world and what it tells

318
00:38:31,040 --> 00:38:37,840
you is how much how much carbon is captured by the trees if you know

319
00:38:37,840 --> 00:38:41,160
roughly what the height of the tree is you know roughly how much carbon is

320
00:38:41,600 --> 00:38:47,600
captured in the tree that's super important to know like you know should

321
00:38:47,600 --> 00:38:53,200
we protect forests of course we should should we plant more trees where things

322
00:38:53,200 --> 00:38:57,960
like that so very interesting this publications on this where you know

323
00:38:57,960 --> 00:39:03,240
everything is detailed and everything another success of self supervised

324
00:39:03,240 --> 00:39:07,120
running of the type that I showed for natural language processing where you

325
00:39:07,400 --> 00:39:15,720
remove some other words is in biology proteomics particularly so you can the

326
00:39:15,720 --> 00:39:21,120
protein is a sequence of amino acids and we know hundreds of millions of them so

327
00:39:21,120 --> 00:39:24,080
you take a sequence of amino acids you remove some of the amino acids and you

328
00:39:24,080 --> 00:39:27,480
train some gigantic neural net to predict the amino acids that are missing

329
00:39:27,480 --> 00:39:32,640
the system kind of learns to represent sequences of amino acids that

330
00:39:32,640 --> 00:39:36,840
constitute proteins and then you use that representation as input to a system

331
00:39:36,880 --> 00:39:40,720
that predicts the conformation of that protein how it folds well they can stick

332
00:39:40,720 --> 00:39:44,840
to another protein a particular location so there's a famous work by our

333
00:39:44,840 --> 00:39:50,280
colleagues at DeepMind at Fairfold but the this idea of using pre-trained

334
00:39:50,280 --> 00:39:56,440
transformers for protein was actually first published by my colleagues at fair

335
00:39:56,440 --> 00:40:00,400
they're actually no longer at fair now they have left Fairf to create a startup

336
00:40:00,440 --> 00:40:07,840
around this around this idea but it's incredibly successful thousands of

337
00:40:07,840 --> 00:40:11,840
research groups around the world are using this kind of data is actually a

338
00:40:11,840 --> 00:40:17,920
atlas of folded protein contains 600 million proteins or something like that

339
00:40:17,920 --> 00:40:26,680
with the structure that is predicted it's called the ESM metagenomic atlas and

340
00:40:27,440 --> 00:40:34,480
ESM atlas.com a very big tool for biologists that really may change

341
00:40:34,480 --> 00:40:38,920
completely the way we do drug design and understand the mechanisms of life

342
00:40:38,920 --> 00:40:46,320
another very impressive project here that required a lot of effort is a project

343
00:40:46,320 --> 00:40:51,480
called no language left behind again from fair collection of people from the

344
00:40:51,480 --> 00:40:55,240
various sites of fair and this is a system that can translate 200 languages

345
00:40:55,880 --> 00:41:01,920
from in any direction and when you look at what those languages are it's a lot

346
00:41:01,920 --> 00:41:07,200
of languages most of them we never heard of in you know square corners of the

347
00:41:07,200 --> 00:41:12,480
world but it's important for people to be able to preserve that culture that you

348
00:41:12,480 --> 00:41:16,360
know they can speak their language and basically be understood using automatic

349
00:41:16,360 --> 00:41:21,360
translation so what's interesting about this is that there are four thousand

350
00:41:21,800 --> 00:41:29,120
directions for translation but the data only covers 2400 of those pairs

351
00:41:29,120 --> 00:41:37,960
among the 40,000 despite that because we train a giant transformer to represent

352
00:41:37,960 --> 00:41:43,200
language regardless of the language the system takes advantage of the

353
00:41:43,200 --> 00:41:47,080
similarities between between the language families to actually kind of

354
00:41:47,080 --> 00:41:51,160
extract a multilingual language independent representation of language

355
00:41:51,160 --> 00:41:54,920
which allows the system to do translation in any direction including

356
00:41:54,920 --> 00:41:59,960
four directions has never been trained on that's pretty amazing pretty small

357
00:41:59,960 --> 00:42:09,680
model but today standard only 54 billion parameters I mean sizable the same team

358
00:42:09,680 --> 00:42:14,480
now as another project called seamless which was was announced a few weeks ago

359
00:42:14,480 --> 00:42:21,840
they can do speech to speech speech to text text to speech and text to text

360
00:42:21,840 --> 00:42:27,760
translation as well as speech recognition speech synthesis etc speech to

361
00:42:27,760 --> 00:42:33,680
speech is interesting because it can do translation for languages that are not

362
00:42:33,680 --> 00:42:37,360
written directly from speech to speech that system can handle a thousand

363
00:42:37,360 --> 00:42:43,320
languages which is really impressive okay so applications of deep learning that

364
00:42:43,320 --> 00:42:49,160
are less visible perhaps is that deep learning or AI connects people to

365
00:42:49,160 --> 00:42:53,920
knowledge and they connect people to each other the biggest deployment of

366
00:42:53,920 --> 00:42:58,320
machine learning today is probably in social networks and online services like

367
00:42:58,320 --> 00:43:03,560
like search engines and if you take deep learning out of Google or Meta or

368
00:43:03,560 --> 00:43:10,640
Microsoft companies crumble they literally are built around it so deep

369
00:43:10,640 --> 00:43:13,040
learning helps us deal with the information deluge for doing things

370
00:43:13,040 --> 00:43:16,720
like search and retrieval ranking question answering things like this but

371
00:43:16,720 --> 00:43:20,600
and that requires machine to understand content of course for

372
00:43:20,600 --> 00:43:25,160
translation which is very useful for people who are not literate for example

373
00:43:25,160 --> 00:43:30,080
or people are blind or visually impaired so there's three billion people in the

374
00:43:30,080 --> 00:43:34,800
world today who can't use technology because they basically can't read more

375
00:43:34,800 --> 00:43:39,800
or less so here's the biggest use of AI today filtering out illegal and

376
00:43:39,800 --> 00:43:44,480
dangerous content and this is something that's very hard to do it's impossible to

377
00:43:44,480 --> 00:43:51,440
do perfectly but to tell you to give you an idea of how much progress AI has made

378
00:43:51,440 --> 00:43:55,520
those idea of pre-training transformers and stuff like that the

379
00:43:55,520 --> 00:44:02,920
proportion of hate speech that Facebook was able to take down automatically five

380
00:44:02,920 --> 00:44:09,560
years ago was about 20 to 25 percent okay it was using sort of fairly simple

381
00:44:09,560 --> 00:44:16,000
machine learning techniques NLP methods of the types that were common five years

382
00:44:16,000 --> 00:44:26,520
ago and then self-supervised pre-trained transformers happened and that number

383
00:44:26,520 --> 00:44:33,400
went to 95% last year and it's just progress in AI so a lot of people that

384
00:44:33,400 --> 00:44:37,600
we hear talk about AI who generally don't know much about AI actually tell you

385
00:44:37,600 --> 00:44:41,640
about all the dangers of AI that then you know AI is going to destroy I don't

386
00:44:41,640 --> 00:44:45,400
know democracy because of disinformation and things like that what they

387
00:44:45,400 --> 00:44:48,760
don't understand is that AI is actually the solution to those problems it's not

388
00:44:48,760 --> 00:44:52,360
actually the problem it's the solution to those problems and it's already the

389
00:44:52,360 --> 00:44:57,560
case that doing content moderation on social networks makes massive use of the

390
00:44:57,560 --> 00:45:03,080
latest advancements in AI and the people who try to corrupt that system are not

391
00:45:03,240 --> 00:45:11,200
sophisticated in terms of their AI so something that needs to be known okay

392
00:45:11,200 --> 00:45:15,760
but everybody is excited about generative AI and autoregressive large

393
00:45:15,760 --> 00:45:22,000
language models and things of that type right so many of you certainly I'm sure

394
00:45:22,000 --> 00:45:25,200
have played with those image generation things where you type a text and

395
00:45:25,200 --> 00:45:30,240
outcomes image and this is the state of the art about a year and a half ago from

396
00:45:30,280 --> 00:45:34,920
either a meta and make a scene system or a penny I dali to or Google's image and

397
00:45:34,920 --> 00:45:45,800
as of yesterday this is what you get out of meta so this is actually from a

398
00:45:45,800 --> 00:45:50,440
paper and you can get the paper from archive it's there but there's a product

399
00:45:50,440 --> 00:45:56,600
attached to that paper called emu it's an acronym but actually don't remember

400
00:45:56,640 --> 00:46:05,000
what it means and what the system can do is in it can generate images from a

401
00:46:05,000 --> 00:46:10,840
text prompt and it was rolled out as a product yesterday as well as the paper

402
00:46:10,840 --> 00:46:14,000
right so it's one of the things where like the science the research the

403
00:46:14,000 --> 00:46:20,080
technology and the product come out to the same day pretty crazy and this is

404
00:46:20,080 --> 00:46:23,680
available in Facebook Messenger if you use Facebook Messenger you can you can

405
00:46:23,680 --> 00:46:30,840
ask to talk to meta AI that is the name of the intelligent virtual assistant

406
00:46:30,840 --> 00:46:38,800
at meta the generic ones and then if in a font you type backslash sorry forward

407
00:46:38,800 --> 00:46:45,640
slash imaging and type a text then the system will produce an image in five

408
00:46:45,640 --> 00:46:52,480
seconds this used to take minutes the results are pretty amazing the same team

409
00:46:52,520 --> 00:46:58,120
is is working on synthesizing video this is actually some work from about a year

410
00:46:58,120 --> 00:47:02,840
ago they're making progress on sort of practical things of this type okay but

411
00:47:02,840 --> 00:47:07,680
how do those LLMs those large language models you know that you can talk to how

412
00:47:07,680 --> 00:47:13,840
do they work they are autoregressive right so what that means is they are of

413
00:47:13,840 --> 00:47:17,040
the type that I talked about before you take a text and you remove some other

414
00:47:17,040 --> 00:47:21,960
words and then you turn train assistant to predict the words except it's a

415
00:47:21,960 --> 00:47:26,360
special case where you only train the system to predict the last word okay to

416
00:47:26,360 --> 00:47:31,520
take a long piece of text remove the last word and train this gigantic neural

417
00:47:31,520 --> 00:47:37,680
net to predict that last word and if you train the system this way you can do

418
00:47:37,680 --> 00:47:42,480
what's called autoregressive prediction which means give a text predict the last

419
00:47:42,480 --> 00:47:47,120
word or the next word then inject that into the input and then predict the next

420
00:47:47,120 --> 00:47:51,720
next word and then shift that into an input produce the third word etc.

421
00:47:51,880 --> 00:47:58,320
Autoregressive prediction and it's amazing how it works there's a whole

422
00:47:58,320 --> 00:48:03,840
bunch of those models around actually I typed that list a few a couple months

423
00:48:03,840 --> 00:48:07,960
ago and now there's a whole bunch more but Blunderbot Galactica Lama Lama 2

424
00:48:07,960 --> 00:48:14,280
from from meta which is actually a open source code Lama that came out in July

425
00:48:14,280 --> 00:48:20,320
which is basically Lama specialized for generating code Alpaca Lambda Chinchilla

426
00:48:20,360 --> 00:48:24,760
chai GPT the various incarnations of chai GPT and then there is one that came

427
00:48:24,760 --> 00:48:30,040
out just a few days ago called mistral via a French startup in Paris formed by

428
00:48:30,040 --> 00:48:34,960
people who used to be at fair and deep end actually that's interesting so

429
00:48:34,960 --> 00:48:39,760
performance is amazing for those systems right we've all been surprised by it but

430
00:48:39,760 --> 00:48:42,880
they do make really really stupid mistakes they don't really understand the

431
00:48:42,880 --> 00:48:48,720
world they they're trained to produce the most likely sequence of words that

432
00:48:48,760 --> 00:48:51,760
follow a particular prompt and then they're kind of fine-tuned to sort of

433
00:48:51,760 --> 00:48:55,280
work well for particular types of questions but they make factual errors

434
00:48:55,280 --> 00:49:00,680
logical errors they are inconsistent they don't really have reasoning abilities

435
00:49:00,680 --> 00:49:07,880
it's very easy to kind of chorus them into producing toxic content they really

436
00:49:07,880 --> 00:49:11,040
do have a limited knowledge of the underlying reality because they're

437
00:49:11,040 --> 00:49:15,760
purely trained from text they don't have common sense like a cat can have common

438
00:49:15,760 --> 00:49:21,680
sense and they can't plan their answer so you can you can play with Lama so

439
00:49:21,680 --> 00:49:27,280
basically the chatbot I just mentioned meta AI is sort of a productized

440
00:49:27,280 --> 00:49:32,040
version of Lama too if you want and it has various incarnations actually various

441
00:49:32,040 --> 00:49:36,400
personas that you can call and there's three models the production model is a

442
00:49:36,400 --> 00:49:40,760
different one but it's open source you can download it if you're a big enough GPU

443
00:49:40,760 --> 00:49:45,080
you can read it on your GPU there's a lot of people working towards running those

444
00:49:45,080 --> 00:49:49,400
models on mobile devices and laptops and things like that and they they can

445
00:49:49,400 --> 00:49:53,880
generate text this is a funny one so in the early days of Lama my colleagues

446
00:49:53,880 --> 00:49:59,080
kind of interrogated that so they typed into Lama did you know that Yanlok

447
00:49:59,080 --> 00:50:02,720
dropped a rap album last year we listened to it and here is what we thought

448
00:50:02,720 --> 00:50:10,040
and this and the system writes a critique of my alleged rap album so they

449
00:50:10,040 --> 00:50:14,480
showed this to me and they say is it okay if we put this in the paper and say

450
00:50:14,480 --> 00:50:19,360
yeah sure no problem but I said like could you do this with jazz because you

451
00:50:19,360 --> 00:50:26,520
know I'm like I'm rap is okay but like I prefer jazz really and they told me yeah

452
00:50:26,520 --> 00:50:32,480
yeah we tried and it didn't work because there's not enough training data for

453
00:50:32,480 --> 00:50:43,960
jazz so I cried so as I was saying you can fine-tune the system to sort of play

454
00:50:44,000 --> 00:50:49,960
different roles and what Mita announced yesterday is that is 28 different

455
00:50:49,960 --> 00:50:52,680
chatbots that are specialized for different applications so think for

456
00:50:52,680 --> 00:50:58,120
example you can have Snoop Dogg a rapper be a dungeon master if you are into

457
00:50:58,120 --> 00:51:04,240
dungeon and dragon or text adventure games others that are like advisors for

458
00:51:04,240 --> 00:51:10,560
traveling others that are cooks or or sous chefs or whatever so different

459
00:51:10,760 --> 00:51:17,600
but those things really suck I mean they really not that great because they

460
00:51:17,600 --> 00:51:21,080
don't understand the world they just manipulate language because they

461
00:51:21,080 --> 00:51:24,600
manipulate language fluently we're fooled into thinking that they are

462
00:51:24,600 --> 00:51:29,360
intelligent but they're not intelligent in certain ways but they're not

463
00:51:29,360 --> 00:51:35,920
intelligent in sort of what we think as as human intelligence so you will see if

464
00:51:35,920 --> 00:51:41,040
you go to X from a Twitter or any kind of social networks people who make

465
00:51:41,040 --> 00:51:47,000
posts say oh there is a latest LLM from so-and-so company and you type this and

466
00:51:47,000 --> 00:51:51,280
it's mind-blowing you know we are this far away from human level intelligence

467
00:51:51,280 --> 00:51:56,560
what I call a GI I hate the term and you know it's for tomorrow like you know all

468
00:51:56,560 --> 00:52:00,640
the naysayers are wrong blah blah blah it's just happening tomorrow they are

469
00:52:00,640 --> 00:52:04,880
wrong okay this those things do not have anything close to human intelligence

470
00:52:05,160 --> 00:52:09,040
they appear to do to have to have it because they're trained on so much data

471
00:52:09,040 --> 00:52:13,120
that they've accumulated an enormous amount of background knowledge

472
00:52:13,120 --> 00:52:17,840
approximately that they can regurgitate approximately so whenever they seem

473
00:52:17,840 --> 00:52:22,120
intelligent it's usually because they can do information retrieval in an

474
00:52:22,120 --> 00:52:26,400
approximate way that sort of looks reasonable but they cannot possibly

475
00:52:26,400 --> 00:52:30,240
understand how the world works because their only training data is text and

476
00:52:30,240 --> 00:52:34,400
most of human knowledge this may surprise you but most of human knowledge has

477
00:52:34,440 --> 00:52:39,440
nothing to do with language it has to do with our experience with the world

478
00:52:39,440 --> 00:52:47,960
every day physics another limitation that people have been pointing out

479
00:52:47,960 --> 00:52:52,920
increasingly with various papers is the inability of those LLMs to plan so an

480
00:52:52,920 --> 00:52:58,840
LLM produces those tokens autoregressively as I explained earlier right they

481
00:52:58,840 --> 00:53:02,640
don't plan their answer they just produce one token after the other and

482
00:53:03,040 --> 00:53:06,360
whatever token they produce will determine which token they produce next

483
00:53:06,360 --> 00:53:12,960
because it's autoregressive there is a process by which the system is basically

484
00:53:12,960 --> 00:53:17,320
an exponentially divergent process the system makes one mistake that takes it

485
00:53:17,320 --> 00:53:25,520
out of the kind of correct set of answers it cannot recover and so this

486
00:53:25,520 --> 00:53:30,720
entire architecture of autoregressive prediction in my opinion is is inherently

487
00:53:30,720 --> 00:53:35,280
flawed and my prediction is that within a few years nobody in their right mind

488
00:53:35,280 --> 00:53:40,320
would use autoregressive LLMs okay everybody is working towards something

489
00:53:40,320 --> 00:53:47,480
better because those things are major flaws now what's the issue though is

490
00:53:47,480 --> 00:53:51,960
that there's a lot of people who are scared about future AI systems that may

491
00:53:51,960 --> 00:53:56,680
have the may attain attain human intelligence or or be more intelligent

492
00:53:56,680 --> 00:54:01,720
than humans and if you extrapolate from what LLMs currently do you might think

493
00:54:01,720 --> 00:54:04,840
well it's gonna be very dangerous because those systems cannot really be

494
00:54:04,840 --> 00:54:09,560
controlled they can spew complete nonsense they can be jail broken blah

495
00:54:09,560 --> 00:54:13,600
blah if they are smart they might be dangerous that's a big mistake future

496
00:54:13,600 --> 00:54:17,720
AI systems will not be using this particular blueprint they're not going

497
00:54:17,720 --> 00:54:22,640
to be autoregressive LLMs okay and I'm going to tell you what I think it will

498
00:54:22,640 --> 00:54:33,200
be okay so autoregressive LLMs suck I just said all that no reasoning no

499
00:54:33,200 --> 00:54:39,240
planning essentially right the amount of computation devoted to producing a

500
00:54:39,240 --> 00:54:44,480
single token by an LLM autoregressive LLM is constant there's a constant amount

501
00:54:44,480 --> 00:54:48,800
of computation per token produced so there's no possibility for the system

502
00:54:48,840 --> 00:54:53,840
to for example think about something for a long time before saying something it's

503
00:54:53,840 --> 00:55:03,560
cannot do that by construction so machines do not of this type do not

504
00:55:03,560 --> 00:55:09,200
learn how the world works unlike animal and animals and humans they will not be

505
00:55:09,200 --> 00:55:16,280
able to approach human intelligence okay so whatever I don't know the CEO of some

506
00:55:16,320 --> 00:55:20,480
company that thinks they have the best LLM in the world tells you a GI is just

507
00:55:20,480 --> 00:55:27,080
around the corner don't believe that we're still missing some major advances

508
00:55:27,080 --> 00:55:35,840
but there is absolutely no question that eventually machines will surpass human

509
00:55:35,840 --> 00:55:42,160
intelligence in all domains okay it's basically no doubt about that and it's

510
00:55:42,200 --> 00:55:50,440
going to happen during the lifetime of most people here maybe not me you know I

511
00:55:50,440 --> 00:55:57,240
might take a few decades there's no question it's going to happen so these

512
00:55:57,240 --> 00:56:02,680
are I think the biggest challenges for AI going forward learning representations

513
00:56:02,680 --> 00:56:08,000
and predictive models of the world and I'll tell you why in a minute and that's

514
00:56:08,000 --> 00:56:11,160
what's addressed by self-supervised learning so we have good handle on this

515
00:56:11,200 --> 00:56:17,560
at least for text not so much for video learning to reason so if some of you know

516
00:56:17,560 --> 00:56:21,680
about Daniel Kahneman's theory of system one system two sort of subconscious

517
00:56:21,680 --> 00:56:24,920
things that we do without thinking and then conscious things that we have to

518
00:56:24,920 --> 00:56:31,040
focus our attention on LLMs currently can do system one but not system two we

519
00:56:31,040 --> 00:56:35,640
need to build AI systems that are capable of reasoning of the type that Daniel

520
00:56:35,800 --> 00:56:41,400
Kahneman calls system two is a Nobel Prize winning well he won the Nobel Prize

521
00:56:41,400 --> 00:56:49,680
in economics but is a psychologist and one possible path towards a solution

522
00:56:49,680 --> 00:56:53,320
that I've been proposing for about a year now you're gonna have is what I call

523
00:56:53,320 --> 00:56:57,600
this objective driven AI so this paper I put on open review it's not on archive

524
00:56:57,600 --> 00:57:01,240
it's an open review because on open review you can make comments and and this

525
00:57:01,240 --> 00:57:04,800
is a working document more than a kind of finished paper if you want it's long

526
00:57:04,840 --> 00:57:08,360
though you can also listen to technical talks I've given about this are a

527
00:57:08,360 --> 00:57:13,360
little more technical than the current one and it's based on this idea of a

528
00:57:13,360 --> 00:57:18,640
modular cognitive architecture where you have a system composed of multiple

529
00:57:18,640 --> 00:57:25,000
modules first module be the perception so it's represented overlaid over the

530
00:57:25,000 --> 00:57:28,800
back of the brain because in the human brain perception is in the back so

531
00:57:28,800 --> 00:57:34,280
perception basically perceives the world and then constructs an estimate of the

532
00:57:34,280 --> 00:57:38,360
state of the world right so it produces an estimate of the state of the world

533
00:57:38,360 --> 00:57:43,520
perhaps it needs to combine this with the content of a memory that contains you

534
00:57:43,520 --> 00:57:47,480
know other information about the state of the world that is not currently

535
00:57:47,480 --> 00:57:52,480
perceptible and then that goes into a world model and the role of the world

536
00:57:52,480 --> 00:57:59,880
model is to imagine the outcome of a sequence of actions okay so the system

537
00:57:59,920 --> 00:58:04,160
can imagine a sequence of actions that's the role of the actor the yellow

538
00:58:04,160 --> 00:58:08,960
module so the actor imagines a sequence of actions fits that to the world model

539
00:58:08,960 --> 00:58:12,600
the world model knows the current state of the world and what the world model

540
00:58:12,600 --> 00:58:16,880
predicts is the future state of the world that will result from that sequence

541
00:58:16,880 --> 00:58:22,120
of actions now that cannot be a perfectly exact prediction because the

542
00:58:22,120 --> 00:58:29,200
world is not entirely predictable but that's the the the role of the world

543
00:58:29,240 --> 00:58:33,760
model and then the entire purpose of the system is to figure out a particular

544
00:58:33,760 --> 00:58:38,960
sequence of actions that will predict a state of the world that satisfies a

545
00:58:38,960 --> 00:58:44,120
certain number of constraints that are implemented by the cost module so the

546
00:58:44,120 --> 00:58:49,680
red module that you see this cost module that that's the drive of the system

547
00:58:49,680 --> 00:58:54,440
that's the the current goal of the system if you want and the entire purpose of

548
00:58:54,440 --> 00:58:58,360
the system so imagine this module as getting the predictions from the world

549
00:58:58,360 --> 00:59:04,760
model and then computing a cost for it right so basically it computes the degree

550
00:59:04,760 --> 00:59:12,000
of in comfort of the system discomfort and what the system does is that it

551
00:59:12,000 --> 00:59:15,720
figures out internally a sequence of actions so the actor does that it figures

552
00:59:15,720 --> 00:59:18,720
out a sequence of actions that will minimize its cost according to the

553
00:59:18,720 --> 00:59:26,040
predictions of the world model okay and this is very much system 2 type it's

554
00:59:26,040 --> 00:59:29,960
very similar to what you know people do classically in optimal control it's

555
00:59:29,960 --> 00:59:34,720
called model predictive control and it's really like this right observe the state

556
00:59:34,720 --> 00:59:38,400
of the world get an initial world state representation combine that with what

557
00:59:38,400 --> 00:59:41,760
you think about the state of the world from your memory feed a sequence of

558
00:59:41,760 --> 00:59:44,920
actions to your world model and ask the world model to predict where the final

559
00:59:44,920 --> 00:59:48,560
state will be then feed that to your objectives the objectives might

560
00:59:48,560 --> 00:59:53,720
implement the goal that the system has set for itself or that you set it for

561
00:59:53,760 --> 00:59:58,840
it but also you can have a number of guardrails so might be a guardrails if

562
00:59:58,840 --> 01:00:05,920
we have a domestic robot that is cooking has a knife in its hand because it's

563
01:00:05,920 --> 01:00:11,520
cutting onions or whatever you might have a cost that says if you have a knife

564
01:00:11,520 --> 01:00:16,840
in your hand and there are people around you don't move your hand too fast okay

565
01:00:16,840 --> 01:00:21,960
don't flail your arms right so maybe dangerous so you can imagine all kinds

566
01:00:22,000 --> 01:00:28,080
of guardrails of this type to basically ensure the safety of the of the system and

567
01:00:28,080 --> 01:00:31,360
the system has no choice but satisfy those because they are satisfied at

568
01:00:31,360 --> 01:00:37,680
inference time they're not it's not like RLHF for LLMs reinforcement learning

569
01:00:37,680 --> 01:00:43,320
through human feedback where it's a it's a training time fine-tuning to make

570
01:00:43,320 --> 01:00:49,440
sure the system produces only safe behavior the system can always produce

571
01:00:49,600 --> 01:00:54,200
unsafe behavior by you know being prompted something that the the people

572
01:00:54,200 --> 01:00:57,960
training it didn't think of it didn't think about here that's impossible the

573
01:00:57,960 --> 01:01:01,080
system cannot produce a sequence of actions that will not satisfy the

574
01:01:01,080 --> 01:01:06,040
guardrails according to the world model so those systems would be intrinsically

575
01:01:06,040 --> 01:01:13,160
safe provided two things provided that the guardrail objectives guarantee the

576
01:01:13,160 --> 01:01:17,720
safety and that's complicated also provided that the world model is accurate

577
01:01:17,760 --> 01:01:22,280
and that's also complicated so you can imagine something like this that works

578
01:01:22,280 --> 01:01:27,400
over time so that you know you can have a sequence for example in this case

579
01:01:27,400 --> 01:01:32,520
sequence of two actions you can have and again this is very similar to what

580
01:01:32,520 --> 01:01:36,720
control theory is called model predictive control except here we're

581
01:01:36,720 --> 01:01:42,120
learning the world model and possibly learning the cost as well you might want

582
01:01:42,120 --> 01:01:45,960
to imagine the system like this that does hierarchical planning humans animals

583
01:01:46,000 --> 01:01:49,680
do hierarchical planning all the time it's a essential characteristic of what

584
01:01:49,680 --> 01:01:54,320
we can do and we don't know how to do this at the moment we have some ideas

585
01:01:54,320 --> 01:01:57,760
working on it but it really doesn't work like if there is like a really good

586
01:01:57,760 --> 01:02:02,640
opportunity for young scientists or aspiring scientists to really solve a

587
01:02:02,640 --> 01:02:06,880
problem like try to see if you can do something about hierarchical planning

588
01:02:06,880 --> 01:02:15,280
because it's really hard but the payoff if you can do it I think is enormous so

589
01:02:15,280 --> 01:02:21,440
a good example of this is let's say I'm at NYU in my office at NYU and I want to

590
01:02:21,440 --> 01:02:25,440
go to Paris okay so my objective is my distance to Paris I want to minimize my

591
01:02:25,440 --> 01:02:30,280
distance to Paris at a high level I can say well first thing I need to do is go

592
01:02:30,280 --> 01:02:33,960
to the airport and then catch a plane and there is a latent variable that may

593
01:02:33,960 --> 01:02:37,960
indicate like which airport I'm choosing depending on traffic or whatever or what

594
01:02:37,960 --> 01:02:44,240
airline flights at what time okay now how do I go to the airport well I have

595
01:02:44,240 --> 01:02:48,800
to go down in the street and catch a taxi you can do this in New York you can

596
01:02:48,800 --> 01:02:53,400
just tell the taxi in the street how do I go down in the street I need to stand up

597
01:02:53,400 --> 01:02:58,200
for my chair open the door go to the stair staircase of the elevator how do I

598
01:02:58,200 --> 01:03:03,880
get out from my chair I need to kind of push with my arms or something or or

599
01:03:03,880 --> 01:03:07,640
turn my chair and then you know you imagine you can imagine decomposing this

600
01:03:07,640 --> 01:03:11,480
all the way down to millisecond by millisecond muscle control I'm not going

601
01:03:11,480 --> 01:03:17,520
to plan my entire trajectory from my NYU office to Paris in terms of millisecond

602
01:03:17,520 --> 01:03:21,240
by millisecond muscle control that would be classical planning it has to be

603
01:03:21,240 --> 01:03:27,440
hierarchical and people can do this today I mean engineers do this in control

604
01:03:27,440 --> 01:03:33,480
but those various levels in a hierarchy are designed by hand the question is can

605
01:03:33,480 --> 01:03:36,800
we train a machine to automatically learn what the proper hierarchical

606
01:03:36,840 --> 01:03:42,320
representation of the action plan is and that's the answer problem yeah you're

607
01:03:42,320 --> 01:03:49,000
looking to do a phd or something or two or three that's a good problem

608
01:03:51,360 --> 01:03:56,680
we could use techniques like this for LLMs so LLMs that would be non-auto

609
01:03:56,680 --> 01:04:00,920
aggressive instead of producing one token after the other they would basically

610
01:04:00,920 --> 01:04:06,360
infer a sequence of tokens that would satisfy a number of objectives on a

611
01:04:06,360 --> 01:04:09,560
guardrail an objective that measures to what extent you're answering the

612
01:04:09,560 --> 01:04:15,600
question and an objective that measures to what extent the answer is non-toxic

613
01:04:15,600 --> 01:04:23,120
or toxic or whatever right that would make LLMs controllable nothing like

614
01:04:23,120 --> 01:04:27,520
this works today right again if you are looking for a good topic for a phd that's

615
01:04:27,520 --> 01:04:35,920
a good one ultimately we need machine to learn to understand the world that's the

616
01:04:35,960 --> 01:04:40,960
purpose of that world model the essential central piece of that architecture

617
01:04:40,960 --> 01:04:45,480
I just talked about is this world model given the state of the world at time t

618
01:04:45,480 --> 01:04:48,200
given an action I might take or a sequence of actions what is going to be

619
01:04:48,200 --> 01:04:55,360
the state of the world at time t plus one or t plus whatever and humans and

620
01:04:55,360 --> 01:05:01,000
animals are amazingly good at this babies learn how the world works in the first

621
01:05:01,080 --> 01:05:06,400
few months of life at an amazing speed and they learn an incredible amount of

622
01:05:06,400 --> 01:05:09,360
background knowledge about the world first thing you learn is that the world

623
01:05:09,360 --> 01:05:14,400
is three-dimensional then you learn that something like object permanence the

624
01:05:14,400 --> 01:05:19,840
fact that when an object is hidden behind another one it still exists okay

625
01:05:20,200 --> 01:05:22,200
five

626
01:05:26,200 --> 01:05:32,000
and babies learn things like basic notions like gravity in the around the age of

627
01:05:32,000 --> 01:05:35,720
nine months takes a long time to learn intuitive physics like like inertia

628
01:05:35,720 --> 01:05:39,600
gravity things like that okay but it's mostly just by observation a little bit

629
01:05:39,600 --> 01:05:46,000
by experimentation and we don't know how to reproduce this kind of learning with

630
01:05:46,040 --> 01:05:51,120
machines and that's why although we have fluid systems that can pass the bar

631
01:05:51,120 --> 01:06:00,800
exam or medical exams we don't have robots that can clear up the dinner table

632
01:06:00,800 --> 01:06:05,600
and fill up the dishwasher something that any 10 year old can learn in one

633
01:06:05,600 --> 01:06:11,040
shot in a few minutes we don't even have completely autonomous level five cell

634
01:06:11,040 --> 01:06:16,960
driving cars even though any 17 year old can learn to do this within 20 hours

635
01:06:16,960 --> 01:06:26,120
and then drive at 300 kilometers an hour on the Autobahn you know obviously we're

636
01:06:26,120 --> 01:06:30,840
missing something really big with machines that humans and animals can can do

637
01:06:30,840 --> 01:06:35,600
in terms of learning that learning efficiency that we don't we don't know

638
01:06:35,600 --> 01:06:39,840
how to reproduce so we need this ability to learn world models to get machines to

639
01:06:39,840 --> 01:06:44,400
learn world models from video essentially from natural signals and so

640
01:06:44,400 --> 01:06:47,480
this is idea of self-supervised learning but now apply to video not text and it

641
01:06:47,480 --> 01:06:53,640
turns out text is easy text is easy because text is discrete and finite it's

642
01:06:53,640 --> 01:06:57,520
only a finite number of possible tokens in every language on the order of 30

643
01:06:57,520 --> 01:07:02,960
thousand or something and so it's easy to predict a distribution a probability

644
01:07:02,960 --> 01:07:06,760
distribution over the next token you can represent it by a long list of numbers

645
01:07:06,760 --> 01:07:11,920
between 0 and 1 that's on to 1 but if you want to predict video you can't do

646
01:07:11,920 --> 01:07:15,200
that because we don't know how to represent probability distributions over

647
01:07:15,200 --> 01:07:19,080
all possible videos at least not in a good way so if you train a neural net to

648
01:07:19,080 --> 01:07:23,520
predict what happens in a very simple video this is over overhead video from a

649
01:07:23,520 --> 01:07:30,000
highway you get this kind of prediction very very blurry prediction because the

650
01:07:30,000 --> 01:07:33,240
system can only predict the average of all the possible things that can happen

651
01:07:33,240 --> 01:07:38,160
and it can't make make up its mind so the solution I'm proposing to this is

652
01:07:38,160 --> 01:07:46,160
something I call joint embedded joint embedding architecture okay or joint

653
01:07:46,160 --> 01:07:52,440
embedding predictive architecture JEPA and this is a non generative

654
01:07:52,440 --> 01:07:55,120
architecture so everybody is talking about generative AI what I'm telling you

655
01:07:55,120 --> 01:08:03,480
here is abandoned generative models okay so not only am I telling you AI is not

656
01:08:03,480 --> 01:08:08,960
gonna kill us but LLM suck machine learning sucks and generative models

657
01:08:08,960 --> 01:08:14,200
suck right all the popular things at the moment okay so a generative model

658
01:08:14,200 --> 01:08:18,200
predicts you know if you have an observation x you're trying to predict

659
01:08:18,200 --> 01:08:22,600
y just predict y from x using an encoder and some predictor right but what

660
01:08:22,600 --> 01:08:27,720
problem with this is that you have to predict every single details of y and in

661
01:08:27,720 --> 01:08:30,920
video that's just too much in text it's okay it's just like you know what word

662
01:08:30,920 --> 01:08:34,440
okay you don't know exactly what word but it's okay in video it's just not

663
01:08:34,440 --> 01:08:38,680
possible so what you should do instead is what's on the right here the joint

664
01:08:38,680 --> 01:08:43,320
embedding architecture where you run both x and y through encoders the

665
01:08:43,320 --> 01:08:46,920
encoders eliminate all the irrelevant details about the input and the

666
01:08:46,920 --> 01:08:51,440
prediction takes place in representation space okay so joint

667
01:08:51,440 --> 01:08:55,160
embedding predictive architecture JPA there's several incarnations of this

668
01:08:55,160 --> 01:09:00,600
I'm not gonna go to the details because I don't have time and you can read the

669
01:09:00,600 --> 01:09:10,880
details in this long paper I can't read what's on it but I can imagine and that's

670
01:09:10,880 --> 01:09:16,320
kind of the basic JPA architecture so let me skip ahead a little bit there's

671
01:09:16,400 --> 01:09:23,880
two ways to train those JPAs basically two major techniques to train

672
01:09:23,880 --> 01:09:26,680
those JPAs that cannot be understood within the context of probabilistic

673
01:09:26,680 --> 01:09:30,480
methods but only within the context of what I called energy based models and I

674
01:09:30,480 --> 01:09:34,480
was going to explain what this was but I skipped that section but you don't need

675
01:09:34,480 --> 01:09:37,760
to know about energy based model to understand what I'm gonna say so there's

676
01:09:37,760 --> 01:09:42,560
several methods to train those JPAs and this is a particularly interesting one

677
01:09:42,600 --> 01:09:50,520
this is a paper that was published at CVPR just a few months ago it's called

678
01:09:50,520 --> 01:09:58,960
image JPA and it's using this masking idea so you take an image you mask

679
01:09:58,960 --> 01:10:04,320
regions of that image okay and you feed that partially masked image to an

680
01:10:04,320 --> 01:10:09,000
encoder the encoder produces a representation and with that representation

681
01:10:09,040 --> 01:10:13,160
you try to predict using another neural net predictor you try to predict the

682
01:10:13,160 --> 01:10:16,680
representation for use from the full image okay and they both they run

683
01:10:16,680 --> 01:10:20,520
through essentially identical encoders so not identical one of them uses

684
01:10:20,520 --> 01:10:25,320
something called exponential moving average weights but but but they're

685
01:10:25,320 --> 01:10:31,160
almost identical and and that works amazingly well so you you train the

686
01:10:31,160 --> 01:10:35,840
system this way pre-train it with images that you corrupt by masking them

687
01:10:35,840 --> 01:10:40,080
partially and you get amazing result on using the features that are produced by

688
01:10:40,080 --> 01:10:44,040
that system you get amazing results for classification for segmentation for all

689
01:10:44,040 --> 01:10:49,600
kinds of stuff and the Dino method I told you about before is very similar to

690
01:10:49,600 --> 01:10:54,440
this it uses kind of a slightly different way of encoding the outputs but

691
01:10:54,440 --> 01:11:00,800
it's it's in spirit it's very much the same idea and it gives really good

692
01:11:00,800 --> 01:11:06,880
performance on image recognition on transfer tasks on all kinds of stuff

693
01:11:06,880 --> 01:11:11,120
that I don't have time to tell you about okay but things we're working on today

694
01:11:11,120 --> 01:11:14,520
that we need to work on because we don't know how to do it perfectly is self

695
01:11:14,520 --> 01:11:18,080
supervised running from video so basically a version of this image JEPA

696
01:11:18,080 --> 01:11:22,520
that would work for video and learn good representations of videos by

697
01:11:22,520 --> 01:11:26,640
observing the world basically the same thing that babies can do right so we

698
01:11:26,640 --> 01:11:32,720
have a project along those lines V JEPA and we have a paper that we're just

699
01:11:32,720 --> 01:11:36,960
submitting to a conference that some of you probably know what it is because the

700
01:11:36,960 --> 01:11:42,400
deadline is today well actually if you know what it is you're probably not here

701
01:11:42,400 --> 01:11:48,520
you're working on your paper I think the deadline is passed by two hours so maybe

702
01:11:48,520 --> 01:11:54,960
maybe you're here so then you would be able to use those JEPA as world models

703
01:11:54,960 --> 01:12:00,840
right because you know you have an input and you can feed it maybe a set of

704
01:12:00,840 --> 01:12:05,800
actions that an agent might take and it will predict a representation abstract

705
01:12:05,800 --> 01:12:09,200
representation of the state of the world at the next time step and so this could

706
01:12:09,200 --> 01:12:12,080
be used perhaps as a world model as one of the components of the big

707
01:12:12,080 --> 01:12:21,000
architecture I introduced earlier okay okay I said that already all right so

708
01:12:21,040 --> 01:12:26,200
there's quite a question that we need to answer with AI and this is my second

709
01:12:26,200 --> 01:12:31,320
last slide how long is it going to be before we reach human level AI years to

710
01:12:31,320 --> 01:12:35,920
decades probably decades it's probably harder than we think it's certainly much

711
01:12:35,920 --> 01:12:42,760
harder than what the most boasting people believe there's many problems to solve

712
01:12:42,760 --> 01:12:47,240
along the way and before we get to human level AI we're going to get to

713
01:12:47,240 --> 01:12:50,800
something like cat level AI okay so people who are scared that you know

714
01:12:50,800 --> 01:12:54,720
one day someone is going to discover the secret of human level AI is going to

715
01:12:54,720 --> 01:12:58,240
turn on this gigantic computer and that gigantic computer is going to take over

716
01:12:58,240 --> 01:13:03,640
the world and kill everyone that's just ridiculously stupid just cannot possibly

717
01:13:03,640 --> 01:13:06,920
happen we're gonna start small we're gonna you know start with something that

718
01:13:06,920 --> 01:13:10,360
has all the right components but it's small it's not gonna be very smart it's

719
01:13:10,360 --> 01:13:16,360
gonna be like a rat or a cat right and then we're gonna work our way up and you

720
01:13:16,360 --> 01:13:20,440
know change the objectives to make sure it's safe and test it in all kinds of

721
01:13:20,480 --> 01:13:25,640
sandboxes and blah blah blah so this idea somehow that you know the discovery of

722
01:13:25,640 --> 01:13:30,400
AI is going to be an event and that machines are going to escape for control

723
01:13:30,400 --> 01:13:37,360
that's Hollywood movies it's not the real world there is no such thing as a

724
01:13:37,360 --> 01:13:42,840
GI anyway because intelligence is really a multi-dimensional thing humans are

725
01:13:42,840 --> 01:13:48,760
only good at certain things and terrible at many things in fact our minds are

726
01:13:48,760 --> 01:13:53,480
extremely specialized we don't realize this but we're incredibly specialized and

727
01:13:53,480 --> 01:13:58,760
we know this because computers are much better than us at many tasks for example

728
01:13:58,760 --> 01:14:06,600
chess go poker pretty much every video game I mean not today but eventually

729
01:14:06,600 --> 01:14:12,760
recognizing a species of a bird by just listening to the song recognizing an

730
01:14:12,760 --> 01:14:17,560
individual whale or marine mammal by the shape of the tail like AI systems can do

731
01:14:17,560 --> 01:14:24,080
this a very small number of humans can do all of this I mean we just we totally

732
01:14:24,080 --> 01:14:28,920
suck at chess as humans machines are much better than we are and so we don't

733
01:14:28,920 --> 01:14:35,120
have general intelligence ourselves so this word a GI makes no sense human

734
01:14:35,120 --> 01:14:40,400
level yes a GI no there's no question as I said before that machines will

735
01:14:40,400 --> 01:14:46,000
eventually surpass human intelligence and so people are scared by this but

736
01:14:46,040 --> 01:14:53,840
really is a interesting question to ask ourselves imagine a future maybe 20 years

737
01:14:53,840 --> 01:15:00,720
from now or maybe longer where every single one of our interactions with the

738
01:15:00,720 --> 01:15:04,440
digital world is mediated by an AI system okay and it might happen faster

739
01:15:04,440 --> 01:15:09,400
actually okay if some of the startups are being created today and some of the

740
01:15:09,400 --> 01:15:14,040
big company plans product plans actually fulfilled this may happen fairly

741
01:15:14,040 --> 01:15:18,880
quickly that essentially every time that we want to connect to the digital

742
01:15:18,880 --> 01:15:24,720
world that will be through the intermediary of an AI system then those

743
01:15:24,720 --> 01:15:33,120
systems will become the repository of all human knowledge right and it's very

744
01:15:33,120 --> 01:15:39,800
important for that at least the base for a foundation of this to be open source

745
01:15:40,160 --> 01:15:44,400
every infrastructure the internet is open source runs on open source software

746
01:15:44,400 --> 01:15:49,880
and the reason is because it's too important for one company to control it

747
01:15:49,880 --> 01:15:56,000
right so it's the same for AI systems they will have to be open source because

748
01:15:56,000 --> 01:16:00,000
it's too important for any single company or small number of Californian

749
01:16:00,000 --> 01:16:06,520
company to control AI systems if all of our information of all the citizens are

750
01:16:06,560 --> 01:16:12,000
basically filtered through those AI systems the way those systems will be

751
01:16:12,000 --> 01:16:16,240
trained will need to be quite sourced kind of like Wikipedia to collect

752
01:16:16,240 --> 01:16:20,640
culture and information and knowledge from the entire world not just from the

753
01:16:20,640 --> 01:16:27,840
view of the world in parallel to us in place right so that's why I'm a huge

754
01:16:27,840 --> 01:16:34,480
advocate of open source base models for AI and a number of my colleagues at

755
01:16:35,200 --> 01:16:39,240
Meta and his company policy at Meta to open source those base models because it

756
01:16:39,240 --> 01:16:45,960
makes them safer more powerful they progress faster they're more culturally

757
01:16:45,960 --> 01:16:50,200
diverse if more people can train them and it creates an entire ecosystem of

758
01:16:50,200 --> 01:16:55,800
startups and research projects that can build on top of it so it's a very

759
01:16:55,800 --> 01:17:00,280
important political questions at the moment because a lot of companies are

760
01:17:00,280 --> 01:17:04,240
pressuring governments around the world including the German government to

761
01:17:04,240 --> 01:17:09,400
basically keep AI under lock and key to say AI is too dangerous it needs to be

762
01:17:09,400 --> 01:17:19,120
controlled and licensed and and not put into the hands of everyone I think it's

763
01:17:19,120 --> 01:17:22,280
the exact opposite I think it's too dangerous to actually keep in the hands

764
01:17:22,280 --> 01:17:27,720
of just a few a few people okay so I became a little philosophical political

765
01:17:27,720 --> 01:17:34,040
here those people have convinced the UK government the Prime Minister that

766
01:17:34,040 --> 01:17:40,160
AI should be regulated under lock and key apparently the EU Commission also is

767
01:17:40,160 --> 01:17:49,800
convinced this is very bad and I think if we do it right AI will make everybody

768
01:17:49,800 --> 01:17:54,120
smarter it's like we all have those intelligent assistant with us all the

769
01:17:54,120 --> 01:17:57,800
time it's like having a staff of intelligent people working for you okay

770
01:17:57,800 --> 01:18:03,120
every person who is leading anything including me only works with people who

771
01:18:03,160 --> 01:18:06,880
are smarter than them right I only hire people who are smarter than me because

772
01:18:06,880 --> 01:18:10,080
that's the way to be successful so that everybody is gonna be like that we'll

773
01:18:10,080 --> 01:18:13,960
have AI assistant that are smarter than us we shouldn't feel threatened by them

774
01:18:13,960 --> 01:18:17,680
because we'll be controlling them they will be designed to be subservient to us

775
01:18:17,680 --> 01:18:23,560
so this may have an effect on society similar to what the printing press had

776
01:18:23,560 --> 01:18:30,480
probably 500 years ago not too far from here of basically causing a new

777
01:18:30,520 --> 01:18:34,240
renaissance because intelligence is really the commodity that we lack the

778
01:18:34,240 --> 01:18:40,480
most this will make humanity smarter thank you very much

779
01:19:00,480 --> 01:19:11,360
yeah thank you so very much Jan for an amazing lecture we have about 10 minutes

780
01:19:11,360 --> 01:19:22,200
for questions and I'm sure there are several so much for the great talk

781
01:19:22,200 --> 01:19:26,360
customer from a minute you alluded to the fact that we should keep code open

782
01:19:26,360 --> 01:19:30,320
which is great however as you know right many of the recent developments not

783
01:19:30,320 --> 01:19:33,360
just rely on the code but also on the hardware so many of the things are

784
01:19:33,360 --> 01:19:37,960
developed at companies because they have access to a large GPU resources now not

785
01:19:37,960 --> 01:19:41,800
only Germany I guess we are limited by that so and what's your take on that

786
01:19:41,800 --> 01:19:46,600
also being in an academic and an meta environment right how do you deal

787
01:19:46,600 --> 01:19:49,920
yourself with it do you do some things only at universities and others only at

788
01:19:49,920 --> 01:19:56,320
meta or how I mean how do you see that in the future okay should have used an

789
01:19:56,320 --> 01:19:59,920
automatic speech recognizer because there is an awful echo and it's very hard to

790
01:19:59,920 --> 01:20:07,680
understand it's not your fault but anyway I mean hardware is a big limitation so

791
01:20:07,680 --> 01:20:11,880
currently the only entities they can train large language models that are

792
01:20:11,880 --> 01:20:17,480
good are people who have access to large amounts of computation either in-house

793
01:20:17,480 --> 01:20:24,240
which is the case for Google and meta and Microsoft or through cloud services

794
01:20:24,240 --> 01:20:28,000
which is the case for open AI and entropy can others they have access to

795
01:20:28,000 --> 01:20:32,240
Microsoft Azure and you know some of them use AWS some of them use other

796
01:20:32,240 --> 01:20:37,640
other tools so but that costs a huge amount of money so training a sort of

797
01:20:37,640 --> 01:20:41,880
top-of-the-line language model today you know costs tens of millions of euros

798
01:20:41,880 --> 01:20:50,000
right it depends how many tens depends on how you do it possibly more if you

799
01:20:50,000 --> 01:20:55,840
want to buy an infrastructure that is sufficient power today you have to buy

800
01:20:55,840 --> 01:21:04,720
basically stuff from Nvidia and is going to cost you a number with with 10

801
01:21:04,720 --> 01:21:12,040
digits it's in the billions it's insane so what that tells you is that it's like

802
01:21:12,040 --> 01:21:17,440
it's like an autobahn you don't want 10 parallel autobahn going from one city to

803
01:21:17,440 --> 01:21:23,040
another city you just want one and that has to be sort of accessible to everyone

804
01:21:23,040 --> 01:21:27,840
so that's the idea behind open source base model foundation model they need to

805
01:21:27,840 --> 01:21:31,320
be open source because it's a common infrastructure they can be customized

806
01:21:31,320 --> 01:21:36,440
and there's no point having 50 of them because they cost so much to train that's

807
01:21:36,440 --> 01:21:39,760
another argument for open source

808
01:21:53,080 --> 01:21:59,520
hello yes hi thank you for the great lecture there was a slide that had

809
01:21:59,520 --> 01:22:04,120
challenges of AI and machine learning and there were three points in there it

810
01:22:04,120 --> 01:22:11,600
went by really fast and I couldn't catch if ethical fairness responsible AI was a

811
01:22:11,600 --> 01:22:17,720
challenge that you're facing with and if so what are you doing about it okay so I

812
01:22:17,760 --> 01:22:23,520
think that point was wrapped into the the second point but sort of not

813
01:22:23,520 --> 01:22:28,360
mentioned directly it was more can I mention in the other thing so this idea

814
01:22:28,360 --> 01:22:32,800
of objective driven AI the fact that a system can only produce answers that

815
01:22:32,800 --> 01:22:37,480
satisfy a number of objectives including some guardrails the answer to your

816
01:22:37,480 --> 01:22:40,960
question is how do you design those guardrails essentially we don't have an

817
01:22:40,960 --> 01:22:45,480
answer to this and the reason we don't have an answer to this is because we

818
01:22:45,520 --> 01:22:51,920
haven't really began to build systems of this type and so it's as if someone in

819
01:22:51,920 --> 01:22:58,560
1925 asked aviators how are you going to make sure that transatlantic

820
01:22:58,560 --> 01:23:03,760
transatlantic flight at near the speed of sound will be safe nobody could be

821
01:23:03,760 --> 01:23:09,280
possibly answering this nobody across the Atlantic on a plane in 1925 at least

822
01:23:09,280 --> 01:23:16,120
not in there not without any stuff nobody knew what a turbojet was like the

823
01:23:16,120 --> 01:23:19,200
idea of you know speaking at near the speed of sound was completely

824
01:23:19,200 --> 01:23:24,000
unthinkable so we're a bit in the same situation we don't know how exactly how

825
01:23:24,000 --> 01:23:28,880
to make those things safe because we haven't built them yet but I think it's

826
01:23:28,880 --> 01:23:32,720
an engineering problem like any other problem and there is a there's a fallacy

827
01:23:32,720 --> 01:23:37,240
also which is that to design those objectives a lot of people say oh we've

828
01:23:37,280 --> 01:23:40,760
never done this before so we're not going to know how to do it but in fact we are

829
01:23:40,760 --> 01:23:45,360
doing this all the time we've been doing it for millenia designing objectives so

830
01:23:45,360 --> 01:23:52,000
that intelligent entities behave properly that's called laws lawmaking is

831
01:23:52,000 --> 01:23:56,920
designing objectives for humans to behave properly and it's even designing

832
01:23:56,920 --> 01:24:02,080
objectives for superhuman entities to behave properly superhuman entities

833
01:24:02,080 --> 01:24:05,800
like corporations for example right corporate law basically is a way to make

834
01:24:05,800 --> 01:24:10,600
sure that whatever a corporation does is aligned more or less with the common

835
01:24:10,600 --> 01:24:14,040
good of society right of course you know they can be corruption and everything

836
01:24:14,040 --> 01:24:18,040
but that's the that's a big idea so we're very familiar with this with this

837
01:24:18,040 --> 01:24:22,640
this concept it's not it's not new

838
01:24:29,040 --> 01:24:33,640
and thank you Jan for the really great talk I want to follow up on the question

839
01:24:33,640 --> 01:24:39,440
we had earlier about GPU resources what I see is that in machine learning and AI

840
01:24:39,440 --> 01:24:44,480
the biggest breakthroughs in the last years were achieved with huge amount of

841
01:24:44,480 --> 01:24:52,040
GPU resources the amount that academic institutions typically do not have do

842
01:24:52,040 --> 01:24:57,560
you see a future for academic research in the field of AI so I'm gonna can make

843
01:24:57,600 --> 01:25:04,600
myself I have two hats okay let me tell you something many of the best ideas come

844
01:25:04,600 --> 01:25:10,120
from academia okay the whole idea of generating images from text and things

845
01:25:10,120 --> 01:25:15,260
like this those actually came out of a German university right and then you

846
01:25:15,260 --> 01:25:20,320
know people picked it up and made products out of it but originally this

847
01:25:20,320 --> 01:25:24,520
was done not too far from here in the university the whole idea of using

848
01:25:24,560 --> 01:25:29,280
attention mechanisms which is the basis of transformers they came out of

849
01:25:29,280 --> 01:25:35,940
university Montreal so that was an interesting story they this was Dimitri

850
01:25:35,940 --> 01:25:41,280
Bada now Kim Jong-chul who is now a colleague at NYU and Joshua Benjo and

851
01:25:41,280 --> 01:25:44,880
they came up with this idea that when you build a translation system the system

852
01:25:44,880 --> 01:25:50,600
should be able to decide which word to look at to translate you know English

853
01:25:50,600 --> 01:25:54,500
into let's say German in fact German was the main issue because you know the

854
01:25:54,500 --> 01:25:59,780
verb is at the end so it screws up all the translation system so so that was

855
01:25:59,780 --> 01:26:05,180
actually the solution to that problem and and they came up with this idea of

856
01:26:05,180 --> 01:26:11,260
this kind of learn attention mechanism and then there was a paper that that by

857
01:26:11,260 --> 01:26:15,060
Chris Manning at Stanford that sort of picked up this architecture and made it

858
01:26:15,060 --> 01:26:20,460
work at scale so they won the WNT competition a few months later and then

859
01:26:20,460 --> 01:26:23,780
the entire industry jumped on it right and then you know as much people at

860
01:26:23,780 --> 01:26:26,980
Google said oh you can build an entire neural net based on just this idea and

861
01:26:26,980 --> 01:26:30,460
the title of the paper was attention is all you need and that was the

862
01:26:30,460 --> 01:26:36,260
transformer and you know so the root of some of those good ideas are very often

863
01:26:36,260 --> 01:26:39,500
in academia then the problems that I talked about you know how you do

864
01:26:39,500 --> 01:26:42,420
hierarchical planning how you're done world models from video that kind of

865
01:26:42,420 --> 01:26:45,980
stuff these are things you don't need enormous amounts of computation to

866
01:26:45,980 --> 01:26:50,940
demonstrate the principle you may not be able to you know beat some benchmark

867
01:26:50,940 --> 01:26:55,260
results or whatever but it doesn't matter if you show that a principle can

868
01:26:55,260 --> 01:26:59,060
work and it's convincing enough then there'll be other people who pick it up

869
01:26:59,060 --> 01:27:02,380
and actually build something real out of it it's okay that's the way you have

870
01:27:02,380 --> 01:27:13,740
intellectual impact so if you think about your career and what drove you would

871
01:27:13,740 --> 01:27:18,260
you say that more the dreams you had about what could be possible or you're

872
01:27:18,300 --> 01:27:25,180
so interested in the topic let yeah just all the work you contributed to and how

873
01:27:25,180 --> 01:27:31,500
that maybe change also over time yeah so interesting question I think at the

874
01:27:31,500 --> 01:27:36,820
root of it is really a scientific question what is intelligence how does

875
01:27:36,820 --> 01:27:42,500
the brain work you know it's a very sort of front and center big big scientific

876
01:27:42,500 --> 01:27:47,540
question over time so right there's three big scientific questions is what you

877
01:27:47,540 --> 01:27:50,900
know what's the universe made of what's life all about and how does the brain

878
01:27:50,900 --> 01:27:58,100
work right three questions but then I'm kind of an engineer as well so for a

879
01:27:58,100 --> 01:28:01,620
complex system like the brain the only way to really understand how it works is

880
01:28:01,620 --> 01:28:05,740
that you build one yourself and you verify that like all the hypothesis that

881
01:28:05,740 --> 01:28:09,660
you built into your system actually kind of correspond to what happened and it's

882
01:28:09,660 --> 01:28:14,740
really the inspiration behind convolutional nets and multilayer learning

883
01:28:14,980 --> 01:28:19,540
and the whole idea of neural nets in the first place right getting inspiration

884
01:28:19,540 --> 01:28:22,940
from the brain but not copying it because you copied blindly you're not

885
01:28:22,940 --> 01:28:26,540
gonna get anywhere you need to understand the underlying principles so

886
01:28:26,540 --> 01:28:29,940
underlying the understanding the underlying principles of intelligence is

887
01:28:29,940 --> 01:28:34,060
really what kind of drives me and then it's great if you have like multiple

888
01:28:34,060 --> 01:28:39,420
applications whether they are useful or entertaining I mostly don't do this

889
01:28:39,420 --> 01:28:44,660
myself but but I'm really happy with people do it

890
01:28:47,340 --> 01:28:54,020
hello LeCun I want to ask you a question what's your opinion on the field of

891
01:28:54,020 --> 01:28:58,780
embodied AI and robot learning I think it's very interesting because it's

892
01:28:58,780 --> 01:29:04,100
deployed artificial intelligence techniques to change the real world yes

893
01:29:04,380 --> 01:29:12,860
I completely agree so in fact in fact that's kind of one of the point that I

894
01:29:12,860 --> 01:29:18,620
perhaps didn't make clear enough that this idea of world model as I said is

895
01:29:18,620 --> 01:29:22,100
easy to do in the context of language which is why we have language models

896
01:29:22,100 --> 01:29:28,300
that are so impressive but it's very hard to do in the context of the real

897
01:29:28,300 --> 01:29:32,740
world data video things like that property of sensitive data from a robot

898
01:29:33,020 --> 01:29:38,700
and so the good news about the good thing the good aspect of embodied AI of

899
01:29:38,700 --> 01:29:42,420
like working with with robots whether they are real or simulated is that you

900
01:29:42,420 --> 01:29:48,780
can't cheat you can't take shortcuts like representing everything as a word or

901
01:29:48,780 --> 01:29:55,660
something although some people are trying to do that but so I think

902
01:29:56,020 --> 01:30:03,820
focusing on this kind of type of problem I think makes people honest so I

903
01:30:03,820 --> 01:30:09,100
think the most interesting advances in in AI over the last several years are

904
01:30:09,100 --> 01:30:13,980
not in LLMs they are in people who do robotics and try to do control and sort

905
01:30:13,980 --> 01:30:19,860
of make robots basically learn efficiently without having to be trained

906
01:30:19,860 --> 01:30:25,740
by you know for hours in simulation this teams there's a colleague at NYU

907
01:30:25,740 --> 01:30:30,660
Lera Alpinto who's working on this there is I mean I've grouped a colleague

908
01:30:30,660 --> 01:30:35,140
Emelon and his colleagues and then probably the biggest group working on

909
01:30:35,140 --> 01:30:40,100
this is at Berkeley Peter Abiel, Segelle Yvine and Chelsea Finn who is a former

910
01:30:40,100 --> 01:30:43,980
student of theirs at Stanford those are really kind of interesting approaches

911
01:30:43,980 --> 01:30:51,180
there this whole idea of planning objective-driven kind of planning you

912
01:30:51,180 --> 01:30:55,820
have to do that in the context of robots so in that sense is very interesting

913
01:30:55,820 --> 01:30:59,820
there's a whole division at fair that actually is called embodied AI for that

914
01:30:59,820 --> 01:31:08,740
reason thank you yeah thank you so much Jan I mean this amazing lecture and I

915
01:31:08,740 --> 01:31:12,060
think you're all very grateful that you shared your thoughts and perspectives on

916
01:31:12,060 --> 01:31:16,380
future AI with us and I think we all got a lot of impulses from this today so we

917
01:31:16,380 --> 01:31:19,780
have a small gift for you as well

918
01:31:43,060 --> 01:31:47,060
thank you

919
01:31:50,060 --> 01:31:55,580
yeah so let me also again I mean thank all cooperation partners who contributed

920
01:31:55,580 --> 01:32:01,380
to this event so the Center for Advanced Studies biosphere the Varian Academy of

921
01:32:01,380 --> 01:32:06,260
Sciences Humanities Munich Center for Machine Learning the Varian Research

922
01:32:06,260 --> 01:32:10,780
Institute for Digital Transformation and the Konrad Susi School of Excellence in

923
01:32:10,780 --> 01:32:16,100
Reliable AI and sorry I would like to have a special thanks to Dr. Ursula

924
01:32:16,100 --> 01:32:20,420
Olinger who is science manager at my chair and who headed actually the

925
01:32:20,420 --> 01:32:26,820
organization of the entire event so I think she deserves a small applause

926
01:32:34,540 --> 01:32:38,980
yeah thanks also everyone for coming here and also for those who joined us

927
01:32:38,980 --> 01:32:43,860
via live stream we now have we I would now like to invite you to a little

928
01:32:43,860 --> 01:32:49,580
reception in this Sitzung Sal 1 and 2 which is here right around the corner

929
01:32:49,580 --> 01:32:53,580
so thank you so much

930
01:33:08,980 --> 01:33:11,040
you

