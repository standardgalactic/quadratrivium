{"text": " you you you you you good afternoon I still have to wait for a sign since we the livestream determines the program are we ready I guess we are ready good afternoon dear ladies and gentlemen the president of the Bavarian Academy of Science I would like to welcome you all to our talk focusing on current developments of advanced computing technologies we are very proud to host this event in the rural residents in the center of Munich which houses the main office of the Bavarian Academy of Science founded in 1759 the Academy functions today as a community of scholars a non-university research institution and a communication interface between the Bavarian scientific community society and policymakers with the scholars the Academy provides a powerful internet disciplinary network of very established scientists this network of excellence interacts very closely with all Bavarian research institutions and political decision makers and represents an important part of the science communication with the public research activities range from the composer Richard Strauss to the study of climate change in their alps from baroque ceiling paintings to quantum physics the longer-term basic research spans from natural science to technology to humanities and social studies the Academy research project actively leverage the latest digital technologies the Leibniz supercomputer center also part of our Academy serves as an important infrastructural support for digital activities at Bavarian universities today we will hear an important contribution to the rapidly growing discussions about artificial intelligence from Jan Lecun who is according to the Time magazine one of the hundred worldwide leading AI pioneers his professor of NYU on chief I scientists at Metta not in California in New York I just learned the title of his talk from machine learning to autonomous intelligence artificial intelligence as you all know is the key topic of our time not only in research and industry but also in the broader society this becomes evident as a large interest and thank you for all coming to this meeting on sharing this experience we're very pleased as Bavarian Academy to gather with the AI agency to be part of biosphere biosphere is the official network of all AI activities in Bavaria we partner in this important task to advance AI science in Bavaria in close cooperation with the Center for Advanced Studies at LMU the Bavarian Research Institute for Digital Transformation the Munich Center for Machine Learning and the Konrad Susie School of Excellence in Reliable AI the event today is part of this successful cooperation and we're looking very broadly forward to learn more about recent progress from advanced computing to autonomous intelligence I hereby hand over to professor Thomas Seidel member of the Bavarian AI Council chair of database systems and data mining director of Munich Center for Machine Learning to all of you I wish a very insightful and informative afternoon the Seidel yeah thank you President Schweiger for this nice introduction and very warm welcome also from my side to all of you particularly to Jan Leckardt to be here today I wear two hats today one is I'm a member of the Bavarian AI Council we are 20 members appointed by the Bavarian state government as part of their high tech agenda from universities research institutions and also companies in the field to advise the government on AI strategies and actions particularly in steering the Bavarian AI agency so the representative is also Dr. Klimke which promotes the Bavarian network which we call biosphere so the logo is there as well so the biosphere comprises a variety of strong AI players in Bavaria also universities research institutes from all over Bavaria as well as a lot of the global companies we have here including Google, Microsoft, IBM but also the locally sitting global players Siemens, BMWs, every insurances Munich three Alliance and so on but also many original small and medium enterprises and startups in the field of AI so the second hat I am aware today's I'm one of the four directors of the Munich Center for Machine Learning one of the co-directors Daniel Gremmels also here and we this is a consortium of LMU and Tom funded by the BNBF in the Bavarian high-tech agenda with around 50 PIs in machine learning in the I3 junior research groups recently established around 200 doctoral students and our focus is on foundations of machine learning where we have several players including Gitta Kottiniok from the mathematical part and statistics and computer science is there then perception we are particularly strong in computer vision here and in Munich and in natural language processing the two big things where humans and computers interact and a lot of domain specific things it's not on research but also on transfer activities fostering the collaboration network together with the biosphere outreach to the general public things like that if you're interested also openings of course so this is that part so I'm sure we get fully inspired by your presentation and between your presentation is now the next is Dr. Mayer from TASS, you're on stage, thank you ladies and gentlemen may I also welcome you warmly on behalf of the Center for Advanced Studies at LMU and let me briefly say a few words about this institution and how it comes into play the Center for Advanced Studies at LMU was founded 15 years ago to provide a forum for precisely those research questions that cannot be tackled by only one discipline this was intended to take account of an increasingly diversifying but also specializing body of research that is becoming more and more disparate not only in terms of content but also in terms of space in Munich you can just think of the campus in Ober-Schleishheim, Ober-Guy-Ching, Nordeid in the far south so the Center for Advanced Studies offers the place where these centrifugal forces can be bundled and for what topic does this task play a more important role than for artificial intelligence which is spread across most faculties of LMU and other universities it was therefore a great pleasure for us when Gitta Kutinyok freshly appointed at our university approached us and asked whether a form it could be found that would network research on AI at LMU and unable to discuss overarching issues together it wasn't long before a so-called interdisciplinary CAS research focused entitled next generation AI was born bringing together researchers from 14 faculties working on the topic of artificial intelligence over the course of two years a wide variety of lectures workshops and conferences was organized and held and we were thrilled by the spirit that emerged of that group that's why we look forward to Professor LeCun's lecture today with both a smile and a tear as it marks the formal conclusion of the research focus we are honored and grateful that Professor LeCun is going to give the lecture in this framework today yeah also a warm welcome from my side to everyone here on site and also to everyone who participates via live stream it is wonderful to have so many people with us here this afternoon and a great thanks to all of our cooperation partners for actually making this lecture possible and here I would like to particularly thank Dr Anette Meyer and the Center for Advanced Studies of the Ludwig Maximilians University M\u00fcnchen Professor Dr. Markus Schweiger and the Bavarian Academy of Sciences and Humanities that this event can take place here in the academy in these really beautiful rooms Professor Dr. Thomas Seidel and Dr. Michael Klimker from the biosphere the Bavarian Eye Network which made the live stream for the event possible and also Dr. Christoph Egle from the Bavarian Research Institute for Digital Transformation and now it's my great pleasure and honor to welcome Professor Jan LeCun thank you very much for accepting our invitation and for coming to Munich for this lecture today Professor LeCun is chief AI scientist at Meta and the silver professor of computer science at New York University he started his career with a PhD in computer science at Sorbonne University in Paris and then moved to the US where he became the head of the image processing research department at the famous Bell Labs the AT&T Bell Laboratories then after intermediate stations he joined New York University in 2003 and he also became there the founding director of the NYU Center for Data Science in 2012. His groundbreaking work includes among many others the development of convolutional neural networks which are the state-of-the-art for basically any problem in particular imaging sciences and computer vision and a particularly particular convolutional network architecture is also named by him the so-called LeNet which in sense also promoted the impressive development of deep learning and AI as we experience it today. His contributions are honored by numerous awards many more than I could name here let me just mention that he's a member of the US National Academy of Sciences and the National Academy of Engineering he received various honorary degrees for instance from EPFL, received the IEEE neural network pioneer award and in 2019 the Turing Award which is typically referred to as the Nobel Prize of Computing and just a few weeks ago we already heard at the Time Magazine and congratulations to that has selected him as one of the 100 most influential people in AI worldwide and he also repeatedly contributes to the public debate about AI with also controversial proclamations for example on the current craze around large language models. How could machines to learn as efficiently as humans and animals? How could machines learn to reason and plan? In his lecture Professor Jan LeKang will now talk about a possible path towards an autonomous intelligent agents based on a new modular cognitive architecture. Where come Jan? The floor is yours. Thank you very much for the introduction and thank you very much for inviting me for coming here so so numerous. I have to correct one thing though I did not call convolutional net solonet this was my lab director at Bell Labs who gave it that name I would never done this but it's a good name okay it's a long title and a long subtitle objective-driven AI this is what I call this I used to give this talk with the title autonomous machine intelligence and and it scares people you know they say do you mean machines that will be autonomous we're not going to be able to control them so I changed the name to objective-driven AI because that's really more accurate and they're really kind of systems it's an aspiration it's not something that we've done it's something that we should do and there are systems that could of course learn remember reason plan have common sense be steerable controllable safe and have the same kind of learning abilities and intelligence that we observe in animals and humans so let me start by a little bit of the state of the art okay because there's a lot of debates today about about AI and a lot of people are afraid of AI it's understandable whenever there is technological revolution people are afraid of the unknown and AI is promising to be a big revolution so people are afraid so let's first talk about the benefits before we talk about the risks and the benefits are of AI are numerous already today and there is you know even more coming in medicine particularly in imaging diagnosis assistant treatment protocol drug design things like this very promising research transportation every car sold in the European Union today has to come with what's called a automatic emergency braking system a system that will automatically stop the car there is an obstacle in front of it and the driver does not react this saves lives it reduces frontal collision by 40% so AI saves lives and that uses convolutional nets by the way and in all the systems that I know in fact Germany was kind of a and and a very in particular was a pioneer in this some of the early systems of this type was the word developed by them events so driving assistance autonomous driving energy storage and management things like that environmental environmental monitoring and protection I'm going to say a few words about this content information and management this is probably the biggest use of AI today and of course in industry manufacturing information systems quality control etc a lot of applications are expected also in things like education for personalized education connecting people with each other with translation today presence augmented reality virtual reality and then enormous applications in science biology and genomics neuroscience physics particularly physics of disordered systems complex systems very large-scale simulations chemistry material science very promising area for AI so this well really and of course you know we've been talking a lot about creation like creating art AI is essentially enabling a lot more people to be creative people who don't necessarily have the technique the underlying technique for producing art so I will affect every aspect of human activity and let me give you a couple examples so this is a video that was put together by my colleagues at meta a couple years ago this is already sort of aging if you want and we chose the capability of computer vision system as of about two years ago so we can have systems that detect objects and put frames around them give them a name they can track human bodies and figure out in what what pose they are densely actually so that's actually very useful for all kinds of applications and more interestingly we can have systems that perform what's called semantic segmentation which means isolating every object marking them with kind of a mask and then giving them a name for a category and this works for a very fine-grained category for example the species of a bird or or plant or something of that type so it's pretty amazing it's not like computer vision is completely solved in fact if it was solved we wouldn't have the large conference that takes place in Paris next week called ICCV so there's still a lot of work to do but but there's been a huge amount of advances there and a lot of advances in AI but no advances in my slides for some reason okay my presentation refuses to advance hang on just one minute one second okay I mentioned medicine so certainly medical imaging is an area where a lot of work is going on there's too many to cite really this is some work by some of my colleagues at NYU that use 3d image recognition not just 2d in some cases this is actually 2d but that use various techniques to detect for example tumors in mammograms or particular things in MRI and other types of images and almost a lot of progress there some product project that took place a few years ago which was a collaboration between the NYU radiology department and people at fair Meta's fundamental research lab which essentially allows to accelerate the data collection for an MRI by a factor of 4 without degrading the image quality so instead of having to lie down in a MRI machine for 40 minutes or something you can reduce this to 10 minutes and have the same quality of images and that's thanks to deep learning essentially a lot of applications in science what's interesting today is that the favorite model that neuroscientists use to explain how the brain works use artificial neural nets so the best explanation for what we observe using functional MRI data in the visual cortex of humans and animals are actually models that are essentially convolutional net models and that's kind of a closing the circle because the architectural convolutional net is actually inspired by the architecture of the visual cortex classic work in neuroscience from the 1960s the similar work also in language understanding this is a recent paper in science by some colleagues from from from it actually and they try to figure out if the current large language models that everybody is playing with explain the what we observe in the brain when people are asked to kind of remember or understand a story and the answer is sort of but not really it doesn't work nearly as well as a convolutional net models for vision so what that means is that we're missing something that those models probably are not sufficient to explain what the brain does when when we understand language I mentioned some applications in science in particle physics in particular high energy physics to kind of make models of particle collisions and things of that type image processing to discover exoplanets some estimate says that about 12 percent of all physics papers today actually mention AI as a tool that he used which is astonishing in just a relatively short time and in the large-scale simulation sort of universe scale simulation that could sort of validate or invalidate certain theories about dark matter and things I guess so very fascinating work and applications this is a very interesting project that was started by some of my colleagues at fair by Larry Zittnick in particular called the open catalyst project and you can actually participate if you want the website is open-catalyst.org and and that project the idea of that project is that we could solve climate change if we had a good efficient scalable way of storing energy if we had a good way of storing energy we could cover a small desert with solar panels and produce enough energy to power Europe or the entire planet the problem is you have to have a way of storing energy which is why renewables today despite the decisions of the German government to go all out on it renewables are not drivable you can't control whenever there is wind or sun and so you need another source of energy when there is no no sun or or no no wind and and for that you need to be able to store energy and ship it wherever it's needed the best way to store energy is in the form of hydrogen or maybe methane and the best way to do this is by separating hydrogen from oxygen from water right so take some water put two electrodes and then separate hydrogen from oxygen problem with this is that it's either scalable if you use catalyst to do this like platinum sorry it's either efficient if you use catalyst like platinum or it's scalable but not efficient and so the big question is could we design compounds new catalyst that would facilitate this reaction so that is efficient but does not require exotic materials like like platinum so that is scalable and the idea there is that you do a lot of chemical simulation that's called DFT simulation of various of water on two various compounds and then you generate that data using simulation and also using experiments you put that data you make it available and then you ask people can you train machine learning system to figure out what the underlying rule is so that we can use it to design new materials that might have the same effect but be cheap so fascinating program it may not work but it's worth a shot okay now what's important to realize is that the progress we've seen over the last few years in AI and machine learning are due to a set of techniques that we call self-supervised running which I'm sure many of you here in the room have heard about and essentially self-supervised running would be a set of techniques that allows a system to be trained to represent the data the world without requiring labeled data okay without requiring sort of manual human intervention to produce the data so perhaps the best success of this idea which I've been advocating for a long time is in the context of natural language understanding so the way all NLP systems are trained today whether there are LLMs of the types that we play with or others is the following you take a piece of text a sequence of words and you remove some of the words you you mask you mask them you blank them out you replace them by a blank marker okay you corrupt essentially the input and you put it at the input of a large neural net you train this very large neural net usually usually a transformer architecture to predict the words that are missing in the process of doing so the system has to extract representations of the text that contain the semantics the syntax the you know grammar everything I sort of lied slightly here these are not words that are input they are what's called tokens which are essentially subword units so in most languages words have a prefix and a root and a suffix and you need to kind of separate those for those systems to work properly otherwise your dictionary of words would be gigantic and then in German you have to do it because you can have words that are long like this they are you know by so so there is no choice you have to break up words into subword units you know in tokens and so you train that you train the system and and this is the so-called BERT model if you want or idea and that's me incredibly successful it's completely self-supervised you don't need any other data than the text and once you've pre-trained that system you can use the internal representation produced by the system as input to a subsequent task a downstream task like let's say translation hate speech detection you know summarization whatever so that's the general idea of self-supervised running fill in the blanks have a big piece of data corrupt it in some way and then train some big neural net to fill in the blanks or or recover the original data a particularly stunning example of this which I'm not going to go into the technical details of but I will later is a system they came out of my colleagues that in Paris that fair Paris called Dino v2 you can think of it as a foundation model for vision so it's a system that is trained to extract features from images such that those features can be used for anything you want whether it's classification fine-grained classification depth estimation semantic segmentation instance retrieval so the same kind of application that I showed in the video but basically with very little supervision this is then it's pre-trained and it basically because it's pre-trained on enormous amounts of data just training a very shadow head to solve any particular one of those problems actually beats the state of the art for that's estimation or classification or whatever you can actually play with it interactively that's the URL that you see here and these are some examples of visualization of what the features that are extracted are it's kind of a you know colorful representation of the like different feature vectors are represented by different colors this is actually kind of each color is like a principal component if you know what that is so those are you know examples on sort of typical typical images and people I've started to use this for all kinds of stuff for biological image analysis for astronomy for for environmental protection so that's the next example I'm going to show you so this is a project by someone on the team Camille Coupri and a large collection collection of collaborators and what she did was use the Dino V2 features and trained relatively small system on top of it to tell what the height of the trees are from a satellite image so we have lots of satellite images on the entire world at half meter resolution you can get this from a satellite imaging companies and for some areas there is LiDAR data which tells you how tall the trees are so you use that to train the system and then you can apply it to the entire world and what it tells you is how much how much carbon is captured by the trees if you know roughly what the height of the tree is you know roughly how much carbon is captured in the tree that's super important to know like you know should we protect forests of course we should should we plant more trees where things like that so very interesting this publications on this where you know everything is detailed and everything another success of self supervised running of the type that I showed for natural language processing where you remove some other words is in biology proteomics particularly so you can the protein is a sequence of amino acids and we know hundreds of millions of them so you take a sequence of amino acids you remove some of the amino acids and you train some gigantic neural net to predict the amino acids that are missing the system kind of learns to represent sequences of amino acids that constitute proteins and then you use that representation as input to a system that predicts the conformation of that protein how it folds well they can stick to another protein a particular location so there's a famous work by our colleagues at DeepMind at Fairfold but the this idea of using pre-trained transformers for protein was actually first published by my colleagues at fair they're actually no longer at fair now they have left Fairf to create a startup around this around this idea but it's incredibly successful thousands of research groups around the world are using this kind of data is actually a atlas of folded protein contains 600 million proteins or something like that with the structure that is predicted it's called the ESM metagenomic atlas and ESM atlas.com a very big tool for biologists that really may change completely the way we do drug design and understand the mechanisms of life another very impressive project here that required a lot of effort is a project called no language left behind again from fair collection of people from the various sites of fair and this is a system that can translate 200 languages from in any direction and when you look at what those languages are it's a lot of languages most of them we never heard of in you know square corners of the world but it's important for people to be able to preserve that culture that you know they can speak their language and basically be understood using automatic translation so what's interesting about this is that there are four thousand directions for translation but the data only covers 2400 of those pairs among the 40,000 despite that because we train a giant transformer to represent language regardless of the language the system takes advantage of the similarities between between the language families to actually kind of extract a multilingual language independent representation of language which allows the system to do translation in any direction including four directions has never been trained on that's pretty amazing pretty small model but today standard only 54 billion parameters I mean sizable the same team now as another project called seamless which was was announced a few weeks ago they can do speech to speech speech to text text to speech and text to text translation as well as speech recognition speech synthesis etc speech to speech is interesting because it can do translation for languages that are not written directly from speech to speech that system can handle a thousand languages which is really impressive okay so applications of deep learning that are less visible perhaps is that deep learning or AI connects people to knowledge and they connect people to each other the biggest deployment of machine learning today is probably in social networks and online services like like search engines and if you take deep learning out of Google or Meta or Microsoft companies crumble they literally are built around it so deep learning helps us deal with the information deluge for doing things like search and retrieval ranking question answering things like this but and that requires machine to understand content of course for translation which is very useful for people who are not literate for example or people are blind or visually impaired so there's three billion people in the world today who can't use technology because they basically can't read more or less so here's the biggest use of AI today filtering out illegal and dangerous content and this is something that's very hard to do it's impossible to do perfectly but to tell you to give you an idea of how much progress AI has made those idea of pre-training transformers and stuff like that the proportion of hate speech that Facebook was able to take down automatically five years ago was about 20 to 25 percent okay it was using sort of fairly simple machine learning techniques NLP methods of the types that were common five years ago and then self-supervised pre-trained transformers happened and that number went to 95% last year and it's just progress in AI so a lot of people that we hear talk about AI who generally don't know much about AI actually tell you about all the dangers of AI that then you know AI is going to destroy I don't know democracy because of disinformation and things like that what they don't understand is that AI is actually the solution to those problems it's not actually the problem it's the solution to those problems and it's already the case that doing content moderation on social networks makes massive use of the latest advancements in AI and the people who try to corrupt that system are not sophisticated in terms of their AI so something that needs to be known okay but everybody is excited about generative AI and autoregressive large language models and things of that type right so many of you certainly I'm sure have played with those image generation things where you type a text and outcomes image and this is the state of the art about a year and a half ago from either a meta and make a scene system or a penny I dali to or Google's image and as of yesterday this is what you get out of meta so this is actually from a paper and you can get the paper from archive it's there but there's a product attached to that paper called emu it's an acronym but actually don't remember what it means and what the system can do is in it can generate images from a text prompt and it was rolled out as a product yesterday as well as the paper right so it's one of the things where like the science the research the technology and the product come out to the same day pretty crazy and this is available in Facebook Messenger if you use Facebook Messenger you can you can ask to talk to meta AI that is the name of the intelligent virtual assistant at meta the generic ones and then if in a font you type backslash sorry forward slash imaging and type a text then the system will produce an image in five seconds this used to take minutes the results are pretty amazing the same team is is working on synthesizing video this is actually some work from about a year ago they're making progress on sort of practical things of this type okay but how do those LLMs those large language models you know that you can talk to how do they work they are autoregressive right so what that means is they are of the type that I talked about before you take a text and you remove some other words and then you turn train assistant to predict the words except it's a special case where you only train the system to predict the last word okay to take a long piece of text remove the last word and train this gigantic neural net to predict that last word and if you train the system this way you can do what's called autoregressive prediction which means give a text predict the last word or the next word then inject that into the input and then predict the next next word and then shift that into an input produce the third word etc. Autoregressive prediction and it's amazing how it works there's a whole bunch of those models around actually I typed that list a few a couple months ago and now there's a whole bunch more but Blunderbot Galactica Lama Lama 2 from from meta which is actually a open source code Lama that came out in July which is basically Lama specialized for generating code Alpaca Lambda Chinchilla chai GPT the various incarnations of chai GPT and then there is one that came out just a few days ago called mistral via a French startup in Paris formed by people who used to be at fair and deep end actually that's interesting so performance is amazing for those systems right we've all been surprised by it but they do make really really stupid mistakes they don't really understand the world they they're trained to produce the most likely sequence of words that follow a particular prompt and then they're kind of fine-tuned to sort of work well for particular types of questions but they make factual errors logical errors they are inconsistent they don't really have reasoning abilities it's very easy to kind of chorus them into producing toxic content they really do have a limited knowledge of the underlying reality because they're purely trained from text they don't have common sense like a cat can have common sense and they can't plan their answer so you can you can play with Lama so basically the chatbot I just mentioned meta AI is sort of a productized version of Lama too if you want and it has various incarnations actually various personas that you can call and there's three models the production model is a different one but it's open source you can download it if you're a big enough GPU you can read it on your GPU there's a lot of people working towards running those models on mobile devices and laptops and things like that and they they can generate text this is a funny one so in the early days of Lama my colleagues kind of interrogated that so they typed into Lama did you know that Yanlok dropped a rap album last year we listened to it and here is what we thought and this and the system writes a critique of my alleged rap album so they showed this to me and they say is it okay if we put this in the paper and say yeah sure no problem but I said like could you do this with jazz because you know I'm like I'm rap is okay but like I prefer jazz really and they told me yeah yeah we tried and it didn't work because there's not enough training data for jazz so I cried so as I was saying you can fine-tune the system to sort of play different roles and what Mita announced yesterday is that is 28 different chatbots that are specialized for different applications so think for example you can have Snoop Dogg a rapper be a dungeon master if you are into dungeon and dragon or text adventure games others that are like advisors for traveling others that are cooks or or sous chefs or whatever so different but those things really suck I mean they really not that great because they don't understand the world they just manipulate language because they manipulate language fluently we're fooled into thinking that they are intelligent but they're not intelligent in certain ways but they're not intelligent in sort of what we think as as human intelligence so you will see if you go to X from a Twitter or any kind of social networks people who make posts say oh there is a latest LLM from so-and-so company and you type this and it's mind-blowing you know we are this far away from human level intelligence what I call a GI I hate the term and you know it's for tomorrow like you know all the naysayers are wrong blah blah blah it's just happening tomorrow they are wrong okay this those things do not have anything close to human intelligence they appear to do to have to have it because they're trained on so much data that they've accumulated an enormous amount of background knowledge approximately that they can regurgitate approximately so whenever they seem intelligent it's usually because they can do information retrieval in an approximate way that sort of looks reasonable but they cannot possibly understand how the world works because their only training data is text and most of human knowledge this may surprise you but most of human knowledge has nothing to do with language it has to do with our experience with the world every day physics another limitation that people have been pointing out increasingly with various papers is the inability of those LLMs to plan so an LLM produces those tokens autoregressively as I explained earlier right they don't plan their answer they just produce one token after the other and whatever token they produce will determine which token they produce next because it's autoregressive there is a process by which the system is basically an exponentially divergent process the system makes one mistake that takes it out of the kind of correct set of answers it cannot recover and so this entire architecture of autoregressive prediction in my opinion is is inherently flawed and my prediction is that within a few years nobody in their right mind would use autoregressive LLMs okay everybody is working towards something better because those things are major flaws now what's the issue though is that there's a lot of people who are scared about future AI systems that may have the may attain attain human intelligence or or be more intelligent than humans and if you extrapolate from what LLMs currently do you might think well it's gonna be very dangerous because those systems cannot really be controlled they can spew complete nonsense they can be jail broken blah blah if they are smart they might be dangerous that's a big mistake future AI systems will not be using this particular blueprint they're not going to be autoregressive LLMs okay and I'm going to tell you what I think it will be okay so autoregressive LLMs suck I just said all that no reasoning no planning essentially right the amount of computation devoted to producing a single token by an LLM autoregressive LLM is constant there's a constant amount of computation per token produced so there's no possibility for the system to for example think about something for a long time before saying something it's cannot do that by construction so machines do not of this type do not learn how the world works unlike animal and animals and humans they will not be able to approach human intelligence okay so whatever I don't know the CEO of some company that thinks they have the best LLM in the world tells you a GI is just around the corner don't believe that we're still missing some major advances but there is absolutely no question that eventually machines will surpass human intelligence in all domains okay it's basically no doubt about that and it's going to happen during the lifetime of most people here maybe not me you know I might take a few decades there's no question it's going to happen so these are I think the biggest challenges for AI going forward learning representations and predictive models of the world and I'll tell you why in a minute and that's what's addressed by self-supervised learning so we have good handle on this at least for text not so much for video learning to reason so if some of you know about Daniel Kahneman's theory of system one system two sort of subconscious things that we do without thinking and then conscious things that we have to focus our attention on LLMs currently can do system one but not system two we need to build AI systems that are capable of reasoning of the type that Daniel Kahneman calls system two is a Nobel Prize winning well he won the Nobel Prize in economics but is a psychologist and one possible path towards a solution that I've been proposing for about a year now you're gonna have is what I call this objective driven AI so this paper I put on open review it's not on archive it's an open review because on open review you can make comments and and this is a working document more than a kind of finished paper if you want it's long though you can also listen to technical talks I've given about this are a little more technical than the current one and it's based on this idea of a modular cognitive architecture where you have a system composed of multiple modules first module be the perception so it's represented overlaid over the back of the brain because in the human brain perception is in the back so perception basically perceives the world and then constructs an estimate of the state of the world right so it produces an estimate of the state of the world perhaps it needs to combine this with the content of a memory that contains you know other information about the state of the world that is not currently perceptible and then that goes into a world model and the role of the world model is to imagine the outcome of a sequence of actions okay so the system can imagine a sequence of actions that's the role of the actor the yellow module so the actor imagines a sequence of actions fits that to the world model the world model knows the current state of the world and what the world model predicts is the future state of the world that will result from that sequence of actions now that cannot be a perfectly exact prediction because the world is not entirely predictable but that's the the the role of the world model and then the entire purpose of the system is to figure out a particular sequence of actions that will predict a state of the world that satisfies a certain number of constraints that are implemented by the cost module so the red module that you see this cost module that that's the drive of the system that's the the current goal of the system if you want and the entire purpose of the system so imagine this module as getting the predictions from the world model and then computing a cost for it right so basically it computes the degree of in comfort of the system discomfort and what the system does is that it figures out internally a sequence of actions so the actor does that it figures out a sequence of actions that will minimize its cost according to the predictions of the world model okay and this is very much system 2 type it's very similar to what you know people do classically in optimal control it's called model predictive control and it's really like this right observe the state of the world get an initial world state representation combine that with what you think about the state of the world from your memory feed a sequence of actions to your world model and ask the world model to predict where the final state will be then feed that to your objectives the objectives might implement the goal that the system has set for itself or that you set it for it but also you can have a number of guardrails so might be a guardrails if we have a domestic robot that is cooking has a knife in its hand because it's cutting onions or whatever you might have a cost that says if you have a knife in your hand and there are people around you don't move your hand too fast okay don't flail your arms right so maybe dangerous so you can imagine all kinds of guardrails of this type to basically ensure the safety of the of the system and the system has no choice but satisfy those because they are satisfied at inference time they're not it's not like RLHF for LLMs reinforcement learning through human feedback where it's a it's a training time fine-tuning to make sure the system produces only safe behavior the system can always produce unsafe behavior by you know being prompted something that the the people training it didn't think of it didn't think about here that's impossible the system cannot produce a sequence of actions that will not satisfy the guardrails according to the world model so those systems would be intrinsically safe provided two things provided that the guardrail objectives guarantee the safety and that's complicated also provided that the world model is accurate and that's also complicated so you can imagine something like this that works over time so that you know you can have a sequence for example in this case sequence of two actions you can have and again this is very similar to what control theory is called model predictive control except here we're learning the world model and possibly learning the cost as well you might want to imagine the system like this that does hierarchical planning humans animals do hierarchical planning all the time it's a essential characteristic of what we can do and we don't know how to do this at the moment we have some ideas working on it but it really doesn't work like if there is like a really good opportunity for young scientists or aspiring scientists to really solve a problem like try to see if you can do something about hierarchical planning because it's really hard but the payoff if you can do it I think is enormous so a good example of this is let's say I'm at NYU in my office at NYU and I want to go to Paris okay so my objective is my distance to Paris I want to minimize my distance to Paris at a high level I can say well first thing I need to do is go to the airport and then catch a plane and there is a latent variable that may indicate like which airport I'm choosing depending on traffic or whatever or what airline flights at what time okay now how do I go to the airport well I have to go down in the street and catch a taxi you can do this in New York you can just tell the taxi in the street how do I go down in the street I need to stand up for my chair open the door go to the stair staircase of the elevator how do I get out from my chair I need to kind of push with my arms or something or or turn my chair and then you know you imagine you can imagine decomposing this all the way down to millisecond by millisecond muscle control I'm not going to plan my entire trajectory from my NYU office to Paris in terms of millisecond by millisecond muscle control that would be classical planning it has to be hierarchical and people can do this today I mean engineers do this in control but those various levels in a hierarchy are designed by hand the question is can we train a machine to automatically learn what the proper hierarchical representation of the action plan is and that's the answer problem yeah you're looking to do a phd or something or two or three that's a good problem we could use techniques like this for LLMs so LLMs that would be non-auto aggressive instead of producing one token after the other they would basically infer a sequence of tokens that would satisfy a number of objectives on a guardrail an objective that measures to what extent you're answering the question and an objective that measures to what extent the answer is non-toxic or toxic or whatever right that would make LLMs controllable nothing like this works today right again if you are looking for a good topic for a phd that's a good one ultimately we need machine to learn to understand the world that's the purpose of that world model the essential central piece of that architecture I just talked about is this world model given the state of the world at time t given an action I might take or a sequence of actions what is going to be the state of the world at time t plus one or t plus whatever and humans and animals are amazingly good at this babies learn how the world works in the first few months of life at an amazing speed and they learn an incredible amount of background knowledge about the world first thing you learn is that the world is three-dimensional then you learn that something like object permanence the fact that when an object is hidden behind another one it still exists okay five and babies learn things like basic notions like gravity in the around the age of nine months takes a long time to learn intuitive physics like like inertia gravity things like that okay but it's mostly just by observation a little bit by experimentation and we don't know how to reproduce this kind of learning with machines and that's why although we have fluid systems that can pass the bar exam or medical exams we don't have robots that can clear up the dinner table and fill up the dishwasher something that any 10 year old can learn in one shot in a few minutes we don't even have completely autonomous level five cell driving cars even though any 17 year old can learn to do this within 20 hours and then drive at 300 kilometers an hour on the Autobahn you know obviously we're missing something really big with machines that humans and animals can can do in terms of learning that learning efficiency that we don't we don't know how to reproduce so we need this ability to learn world models to get machines to learn world models from video essentially from natural signals and so this is idea of self-supervised learning but now apply to video not text and it turns out text is easy text is easy because text is discrete and finite it's only a finite number of possible tokens in every language on the order of 30 thousand or something and so it's easy to predict a distribution a probability distribution over the next token you can represent it by a long list of numbers between 0 and 1 that's on to 1 but if you want to predict video you can't do that because we don't know how to represent probability distributions over all possible videos at least not in a good way so if you train a neural net to predict what happens in a very simple video this is over overhead video from a highway you get this kind of prediction very very blurry prediction because the system can only predict the average of all the possible things that can happen and it can't make make up its mind so the solution I'm proposing to this is something I call joint embedded joint embedding architecture okay or joint embedding predictive architecture JEPA and this is a non generative architecture so everybody is talking about generative AI what I'm telling you here is abandoned generative models okay so not only am I telling you AI is not gonna kill us but LLM suck machine learning sucks and generative models suck right all the popular things at the moment okay so a generative model predicts you know if you have an observation x you're trying to predict y just predict y from x using an encoder and some predictor right but what problem with this is that you have to predict every single details of y and in video that's just too much in text it's okay it's just like you know what word okay you don't know exactly what word but it's okay in video it's just not possible so what you should do instead is what's on the right here the joint embedding architecture where you run both x and y through encoders the encoders eliminate all the irrelevant details about the input and the prediction takes place in representation space okay so joint embedding predictive architecture JPA there's several incarnations of this I'm not gonna go to the details because I don't have time and you can read the details in this long paper I can't read what's on it but I can imagine and that's kind of the basic JPA architecture so let me skip ahead a little bit there's two ways to train those JPAs basically two major techniques to train those JPAs that cannot be understood within the context of probabilistic methods but only within the context of what I called energy based models and I was going to explain what this was but I skipped that section but you don't need to know about energy based model to understand what I'm gonna say so there's several methods to train those JPAs and this is a particularly interesting one this is a paper that was published at CVPR just a few months ago it's called image JPA and it's using this masking idea so you take an image you mask regions of that image okay and you feed that partially masked image to an encoder the encoder produces a representation and with that representation you try to predict using another neural net predictor you try to predict the representation for use from the full image okay and they both they run through essentially identical encoders so not identical one of them uses something called exponential moving average weights but but but they're almost identical and and that works amazingly well so you you train the system this way pre-train it with images that you corrupt by masking them partially and you get amazing result on using the features that are produced by that system you get amazing results for classification for segmentation for all kinds of stuff and the Dino method I told you about before is very similar to this it uses kind of a slightly different way of encoding the outputs but it's it's in spirit it's very much the same idea and it gives really good performance on image recognition on transfer tasks on all kinds of stuff that I don't have time to tell you about okay but things we're working on today that we need to work on because we don't know how to do it perfectly is self supervised running from video so basically a version of this image JEPA that would work for video and learn good representations of videos by observing the world basically the same thing that babies can do right so we have a project along those lines V JEPA and we have a paper that we're just submitting to a conference that some of you probably know what it is because the deadline is today well actually if you know what it is you're probably not here you're working on your paper I think the deadline is passed by two hours so maybe maybe you're here so then you would be able to use those JEPA as world models right because you know you have an input and you can feed it maybe a set of actions that an agent might take and it will predict a representation abstract representation of the state of the world at the next time step and so this could be used perhaps as a world model as one of the components of the big architecture I introduced earlier okay okay I said that already all right so there's quite a question that we need to answer with AI and this is my second last slide how long is it going to be before we reach human level AI years to decades probably decades it's probably harder than we think it's certainly much harder than what the most boasting people believe there's many problems to solve along the way and before we get to human level AI we're going to get to something like cat level AI okay so people who are scared that you know one day someone is going to discover the secret of human level AI is going to turn on this gigantic computer and that gigantic computer is going to take over the world and kill everyone that's just ridiculously stupid just cannot possibly happen we're gonna start small we're gonna you know start with something that has all the right components but it's small it's not gonna be very smart it's gonna be like a rat or a cat right and then we're gonna work our way up and you know change the objectives to make sure it's safe and test it in all kinds of sandboxes and blah blah blah so this idea somehow that you know the discovery of AI is going to be an event and that machines are going to escape for control that's Hollywood movies it's not the real world there is no such thing as a GI anyway because intelligence is really a multi-dimensional thing humans are only good at certain things and terrible at many things in fact our minds are extremely specialized we don't realize this but we're incredibly specialized and we know this because computers are much better than us at many tasks for example chess go poker pretty much every video game I mean not today but eventually recognizing a species of a bird by just listening to the song recognizing an individual whale or marine mammal by the shape of the tail like AI systems can do this a very small number of humans can do all of this I mean we just we totally suck at chess as humans machines are much better than we are and so we don't have general intelligence ourselves so this word a GI makes no sense human level yes a GI no there's no question as I said before that machines will eventually surpass human intelligence and so people are scared by this but really is a interesting question to ask ourselves imagine a future maybe 20 years from now or maybe longer where every single one of our interactions with the digital world is mediated by an AI system okay and it might happen faster actually okay if some of the startups are being created today and some of the big company plans product plans actually fulfilled this may happen fairly quickly that essentially every time that we want to connect to the digital world that will be through the intermediary of an AI system then those systems will become the repository of all human knowledge right and it's very important for that at least the base for a foundation of this to be open source every infrastructure the internet is open source runs on open source software and the reason is because it's too important for one company to control it right so it's the same for AI systems they will have to be open source because it's too important for any single company or small number of Californian company to control AI systems if all of our information of all the citizens are basically filtered through those AI systems the way those systems will be trained will need to be quite sourced kind of like Wikipedia to collect culture and information and knowledge from the entire world not just from the view of the world in parallel to us in place right so that's why I'm a huge advocate of open source base models for AI and a number of my colleagues at Meta and his company policy at Meta to open source those base models because it makes them safer more powerful they progress faster they're more culturally diverse if more people can train them and it creates an entire ecosystem of startups and research projects that can build on top of it so it's a very important political questions at the moment because a lot of companies are pressuring governments around the world including the German government to basically keep AI under lock and key to say AI is too dangerous it needs to be controlled and licensed and and not put into the hands of everyone I think it's the exact opposite I think it's too dangerous to actually keep in the hands of just a few a few people okay so I became a little philosophical political here those people have convinced the UK government the Prime Minister that AI should be regulated under lock and key apparently the EU Commission also is convinced this is very bad and I think if we do it right AI will make everybody smarter it's like we all have those intelligent assistant with us all the time it's like having a staff of intelligent people working for you okay every person who is leading anything including me only works with people who are smarter than them right I only hire people who are smarter than me because that's the way to be successful so that everybody is gonna be like that we'll have AI assistant that are smarter than us we shouldn't feel threatened by them because we'll be controlling them they will be designed to be subservient to us so this may have an effect on society similar to what the printing press had probably 500 years ago not too far from here of basically causing a new renaissance because intelligence is really the commodity that we lack the most this will make humanity smarter thank you very much yeah thank you so very much Jan for an amazing lecture we have about 10 minutes for questions and I'm sure there are several so much for the great talk customer from a minute you alluded to the fact that we should keep code open which is great however as you know right many of the recent developments not just rely on the code but also on the hardware so many of the things are developed at companies because they have access to a large GPU resources now not only Germany I guess we are limited by that so and what's your take on that also being in an academic and an meta environment right how do you deal yourself with it do you do some things only at universities and others only at meta or how I mean how do you see that in the future okay should have used an automatic speech recognizer because there is an awful echo and it's very hard to understand it's not your fault but anyway I mean hardware is a big limitation so currently the only entities they can train large language models that are good are people who have access to large amounts of computation either in-house which is the case for Google and meta and Microsoft or through cloud services which is the case for open AI and entropy can others they have access to Microsoft Azure and you know some of them use AWS some of them use other other tools so but that costs a huge amount of money so training a sort of top-of-the-line language model today you know costs tens of millions of euros right it depends how many tens depends on how you do it possibly more if you want to buy an infrastructure that is sufficient power today you have to buy basically stuff from Nvidia and is going to cost you a number with with 10 digits it's in the billions it's insane so what that tells you is that it's like it's like an autobahn you don't want 10 parallel autobahn going from one city to another city you just want one and that has to be sort of accessible to everyone so that's the idea behind open source base model foundation model they need to be open source because it's a common infrastructure they can be customized and there's no point having 50 of them because they cost so much to train that's another argument for open source hello yes hi thank you for the great lecture there was a slide that had challenges of AI and machine learning and there were three points in there it went by really fast and I couldn't catch if ethical fairness responsible AI was a challenge that you're facing with and if so what are you doing about it okay so I think that point was wrapped into the the second point but sort of not mentioned directly it was more can I mention in the other thing so this idea of objective driven AI the fact that a system can only produce answers that satisfy a number of objectives including some guardrails the answer to your question is how do you design those guardrails essentially we don't have an answer to this and the reason we don't have an answer to this is because we haven't really began to build systems of this type and so it's as if someone in 1925 asked aviators how are you going to make sure that transatlantic transatlantic flight at near the speed of sound will be safe nobody could be possibly answering this nobody across the Atlantic on a plane in 1925 at least not in there not without any stuff nobody knew what a turbojet was like the idea of you know speaking at near the speed of sound was completely unthinkable so we're a bit in the same situation we don't know how exactly how to make those things safe because we haven't built them yet but I think it's an engineering problem like any other problem and there is a there's a fallacy also which is that to design those objectives a lot of people say oh we've never done this before so we're not going to know how to do it but in fact we are doing this all the time we've been doing it for millenia designing objectives so that intelligent entities behave properly that's called laws lawmaking is designing objectives for humans to behave properly and it's even designing objectives for superhuman entities to behave properly superhuman entities like corporations for example right corporate law basically is a way to make sure that whatever a corporation does is aligned more or less with the common good of society right of course you know they can be corruption and everything but that's the that's a big idea so we're very familiar with this with this this concept it's not it's not new and thank you Jan for the really great talk I want to follow up on the question we had earlier about GPU resources what I see is that in machine learning and AI the biggest breakthroughs in the last years were achieved with huge amount of GPU resources the amount that academic institutions typically do not have do you see a future for academic research in the field of AI so I'm gonna can make myself I have two hats okay let me tell you something many of the best ideas come from academia okay the whole idea of generating images from text and things like this those actually came out of a German university right and then you know people picked it up and made products out of it but originally this was done not too far from here in the university the whole idea of using attention mechanisms which is the basis of transformers they came out of university Montreal so that was an interesting story they this was Dimitri Bada now Kim Jong-chul who is now a colleague at NYU and Joshua Benjo and they came up with this idea that when you build a translation system the system should be able to decide which word to look at to translate you know English into let's say German in fact German was the main issue because you know the verb is at the end so it screws up all the translation system so so that was actually the solution to that problem and and they came up with this idea of this kind of learn attention mechanism and then there was a paper that that by Chris Manning at Stanford that sort of picked up this architecture and made it work at scale so they won the WNT competition a few months later and then the entire industry jumped on it right and then you know as much people at Google said oh you can build an entire neural net based on just this idea and the title of the paper was attention is all you need and that was the transformer and you know so the root of some of those good ideas are very often in academia then the problems that I talked about you know how you do hierarchical planning how you're done world models from video that kind of stuff these are things you don't need enormous amounts of computation to demonstrate the principle you may not be able to you know beat some benchmark results or whatever but it doesn't matter if you show that a principle can work and it's convincing enough then there'll be other people who pick it up and actually build something real out of it it's okay that's the way you have intellectual impact so if you think about your career and what drove you would you say that more the dreams you had about what could be possible or you're so interested in the topic let yeah just all the work you contributed to and how that maybe change also over time yeah so interesting question I think at the root of it is really a scientific question what is intelligence how does the brain work you know it's a very sort of front and center big big scientific question over time so right there's three big scientific questions is what you know what's the universe made of what's life all about and how does the brain work right three questions but then I'm kind of an engineer as well so for a complex system like the brain the only way to really understand how it works is that you build one yourself and you verify that like all the hypothesis that you built into your system actually kind of correspond to what happened and it's really the inspiration behind convolutional nets and multilayer learning and the whole idea of neural nets in the first place right getting inspiration from the brain but not copying it because you copied blindly you're not gonna get anywhere you need to understand the underlying principles so underlying the understanding the underlying principles of intelligence is really what kind of drives me and then it's great if you have like multiple applications whether they are useful or entertaining I mostly don't do this myself but but I'm really happy with people do it hello LeCun I want to ask you a question what's your opinion on the field of embodied AI and robot learning I think it's very interesting because it's deployed artificial intelligence techniques to change the real world yes I completely agree so in fact in fact that's kind of one of the point that I perhaps didn't make clear enough that this idea of world model as I said is easy to do in the context of language which is why we have language models that are so impressive but it's very hard to do in the context of the real world data video things like that property of sensitive data from a robot and so the good news about the good thing the good aspect of embodied AI of like working with with robots whether they are real or simulated is that you can't cheat you can't take shortcuts like representing everything as a word or something although some people are trying to do that but so I think focusing on this kind of type of problem I think makes people honest so I think the most interesting advances in in AI over the last several years are not in LLMs they are in people who do robotics and try to do control and sort of make robots basically learn efficiently without having to be trained by you know for hours in simulation this teams there's a colleague at NYU Lera Alpinto who's working on this there is I mean I've grouped a colleague Emelon and his colleagues and then probably the biggest group working on this is at Berkeley Peter Abiel, Segelle Yvine and Chelsea Finn who is a former student of theirs at Stanford those are really kind of interesting approaches there this whole idea of planning objective-driven kind of planning you have to do that in the context of robots so in that sense is very interesting there's a whole division at fair that actually is called embodied AI for that reason thank you yeah thank you so much Jan I mean this amazing lecture and I think you're all very grateful that you shared your thoughts and perspectives on future AI with us and I think we all got a lot of impulses from this today so we have a small gift for you as well thank you yeah so let me also again I mean thank all cooperation partners who contributed to this event so the Center for Advanced Studies biosphere the Varian Academy of Sciences Humanities Munich Center for Machine Learning the Varian Research Institute for Digital Transformation and the Konrad Susi School of Excellence in Reliable AI and sorry I would like to have a special thanks to Dr. Ursula Olinger who is science manager at my chair and who headed actually the organization of the entire event so I think she deserves a small applause yeah thanks also everyone for coming here and also for those who joined us via live stream we now have we I would now like to invite you to a little reception in this Sitzung Sal 1 and 2 which is here right around the corner so thank you so much you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.06, "text": " you", "tokens": [50364, 291, 50467], "temperature": 0.0, "avg_logprob": -0.5840091109275818, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.9433673024177551}, {"id": 1, "seek": 3000, "start": 30.0, "end": 32.06, "text": " you", "tokens": [50364, 291, 50467], "temperature": 0.0, "avg_logprob": -0.8104591965675354, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.8407076001167297}, {"id": 2, "seek": 6000, "start": 60.0, "end": 62.06, "text": " you", "tokens": [50364, 291, 50467], "temperature": 0.0, "avg_logprob": -0.8522099256515503, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.7867293357849121}, {"id": 3, "seek": 9000, "start": 90.0, "end": 92.06, "text": " you", "tokens": [50364, 291, 50467], "temperature": 0.0, "avg_logprob": -0.9181030988693237, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.7435857653617859}, {"id": 4, "seek": 12000, "start": 120.0, "end": 122.36, "text": " you", "tokens": [50379, 291, 50482], "temperature": 1.0, "avg_logprob": -1.6530992984771729, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.47245678305625916}, {"id": 5, "seek": 54000, "start": 540.0, "end": 569.48, "text": " good afternoon I still have to wait for a sign since we", "tokens": [50364, 665, 6499, 286, 920, 362, 281, 1699, 337, 257, 1465, 1670, 321, 51838], "temperature": 0.0, "avg_logprob": -0.524676501750946, "compression_ratio": 0.9322033898305084, "no_speech_prob": 0.40591511130332947}, {"id": 6, "seek": 56948, "start": 569.48, "end": 578.4, "text": " the livestream determines the program are we ready I guess we are ready good", "tokens": [50364, 264, 29782, 24799, 264, 1461, 366, 321, 1919, 286, 2041, 321, 366, 1919, 665, 50810], "temperature": 0.0, "avg_logprob": -0.243978152199397, "compression_ratio": 1.5736842105263158, "no_speech_prob": 0.42701229453086853}, {"id": 7, "seek": 56948, "start": 578.4, "end": 583.72, "text": " afternoon dear ladies and gentlemen the president of the Bavarian Academy of", "tokens": [50810, 6499, 6875, 9974, 293, 11669, 264, 3868, 295, 264, 363, 706, 10652, 11735, 295, 51076], "temperature": 0.0, "avg_logprob": -0.243978152199397, "compression_ratio": 1.5736842105263158, "no_speech_prob": 0.42701229453086853}, {"id": 8, "seek": 56948, "start": 583.72, "end": 588.84, "text": " Science I would like to welcome you all to our talk focusing on current", "tokens": [51076, 8976, 286, 576, 411, 281, 2928, 291, 439, 281, 527, 751, 8416, 322, 2190, 51332], "temperature": 0.0, "avg_logprob": -0.243978152199397, "compression_ratio": 1.5736842105263158, "no_speech_prob": 0.42701229453086853}, {"id": 9, "seek": 56948, "start": 588.84, "end": 594.9200000000001, "text": " developments of advanced computing technologies we are very proud to host", "tokens": [51332, 20862, 295, 7339, 15866, 7943, 321, 366, 588, 4570, 281, 3975, 51636], "temperature": 0.0, "avg_logprob": -0.243978152199397, "compression_ratio": 1.5736842105263158, "no_speech_prob": 0.42701229453086853}, {"id": 10, "seek": 59492, "start": 594.92, "end": 601.8199999999999, "text": " this event in the rural residents in the center of Munich which houses the main", "tokens": [50364, 341, 2280, 294, 264, 11165, 9630, 294, 264, 3056, 295, 40601, 597, 8078, 264, 2135, 50709], "temperature": 0.0, "avg_logprob": -0.1686812960912311, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.12358518689870834}, {"id": 11, "seek": 59492, "start": 601.8199999999999, "end": 609.1999999999999, "text": " office of the Bavarian Academy of Science founded in 1759 the Academy", "tokens": [50709, 3398, 295, 264, 363, 706, 10652, 11735, 295, 8976, 13234, 294, 3282, 19600, 264, 11735, 51078], "temperature": 0.0, "avg_logprob": -0.1686812960912311, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.12358518689870834}, {"id": 12, "seek": 59492, "start": 609.1999999999999, "end": 615.0799999999999, "text": " functions today as a community of scholars a non-university research", "tokens": [51078, 6828, 965, 382, 257, 1768, 295, 8553, 257, 2107, 12, 409, 2550, 2132, 51372], "temperature": 0.0, "avg_logprob": -0.1686812960912311, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.12358518689870834}, {"id": 13, "seek": 59492, "start": 615.0799999999999, "end": 619.68, "text": " institution and a communication interface between the Bavarian", "tokens": [51372, 7818, 293, 257, 6101, 9226, 1296, 264, 363, 706, 10652, 51602], "temperature": 0.0, "avg_logprob": -0.1686812960912311, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.12358518689870834}, {"id": 14, "seek": 61968, "start": 619.68, "end": 626.2399999999999, "text": " scientific community society and policymakers with the scholars the", "tokens": [50364, 8134, 1768, 4086, 293, 47325, 365, 264, 8553, 264, 50692], "temperature": 0.0, "avg_logprob": -0.2016013089348288, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.13038742542266846}, {"id": 15, "seek": 61968, "start": 626.2399999999999, "end": 631.2399999999999, "text": " Academy provides a powerful internet disciplinary network of very", "tokens": [50692, 11735, 6417, 257, 4005, 4705, 8644, 4066, 3209, 295, 588, 50942], "temperature": 0.0, "avg_logprob": -0.2016013089348288, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.13038742542266846}, {"id": 16, "seek": 61968, "start": 631.2399999999999, "end": 637.88, "text": " established scientists this network of excellence interacts very closely with", "tokens": [50942, 7545, 7708, 341, 3209, 295, 21268, 43582, 588, 8185, 365, 51274], "temperature": 0.0, "avg_logprob": -0.2016013089348288, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.13038742542266846}, {"id": 17, "seek": 61968, "start": 637.88, "end": 643.7199999999999, "text": " all Bavarian research institutions and political decision makers and represents", "tokens": [51274, 439, 363, 706, 10652, 2132, 8142, 293, 3905, 3537, 19323, 293, 8855, 51566], "temperature": 0.0, "avg_logprob": -0.2016013089348288, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.13038742542266846}, {"id": 18, "seek": 64372, "start": 643.72, "end": 649.9200000000001, "text": " an important part of the science communication with the public research", "tokens": [50364, 364, 1021, 644, 295, 264, 3497, 6101, 365, 264, 1908, 2132, 50674], "temperature": 0.0, "avg_logprob": -0.17410591286672672, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.026716986671090126}, {"id": 19, "seek": 64372, "start": 649.9200000000001, "end": 655.5600000000001, "text": " activities range from the composer Richard Strauss to the study of climate", "tokens": [50674, 5354, 3613, 490, 264, 26003, 9809, 12875, 2023, 281, 264, 2979, 295, 5659, 50956], "temperature": 0.0, "avg_logprob": -0.17410591286672672, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.026716986671090126}, {"id": 20, "seek": 64372, "start": 655.5600000000001, "end": 661.6, "text": " change in their alps from baroque ceiling paintings to quantum physics the", "tokens": [50956, 1319, 294, 641, 419, 1878, 490, 2159, 29743, 13655, 14880, 281, 13018, 10649, 264, 51258], "temperature": 0.0, "avg_logprob": -0.17410591286672672, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.026716986671090126}, {"id": 21, "seek": 64372, "start": 661.6, "end": 666.52, "text": " longer-term basic research spans from natural science to technology to", "tokens": [51258, 2854, 12, 7039, 3875, 2132, 44086, 490, 3303, 3497, 281, 2899, 281, 51504], "temperature": 0.0, "avg_logprob": -0.17410591286672672, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.026716986671090126}, {"id": 22, "seek": 64372, "start": 666.52, "end": 672.12, "text": " humanities and social studies the Academy research project actively", "tokens": [51504, 36140, 293, 2093, 5313, 264, 11735, 2132, 1716, 13022, 51784], "temperature": 0.0, "avg_logprob": -0.17410591286672672, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.026716986671090126}, {"id": 23, "seek": 67212, "start": 672.16, "end": 678.2, "text": " leverage the latest digital technologies the Leibniz supercomputer center also", "tokens": [50366, 13982, 264, 6792, 4562, 7943, 264, 1456, 897, 77, 590, 36708, 3056, 611, 50668], "temperature": 0.0, "avg_logprob": -0.2458910555452914, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.009997245855629444}, {"id": 24, "seek": 67212, "start": 678.2, "end": 683.88, "text": " part of our Academy serves as an important infrastructural support for", "tokens": [50668, 644, 295, 527, 11735, 13451, 382, 364, 1021, 6534, 1757, 1807, 1406, 337, 50952], "temperature": 0.0, "avg_logprob": -0.2458910555452914, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.009997245855629444}, {"id": 25, "seek": 67212, "start": 683.88, "end": 689.12, "text": " digital activities at Bavarian universities today we will hear an", "tokens": [50952, 4562, 5354, 412, 363, 706, 10652, 11779, 965, 321, 486, 1568, 364, 51214], "temperature": 0.0, "avg_logprob": -0.2458910555452914, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.009997245855629444}, {"id": 26, "seek": 67212, "start": 689.12, "end": 693.44, "text": " important contribution to the rapidly growing discussions about artificial", "tokens": [51214, 1021, 13150, 281, 264, 12910, 4194, 11088, 466, 11677, 51430], "temperature": 0.0, "avg_logprob": -0.2458910555452914, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.009997245855629444}, {"id": 27, "seek": 67212, "start": 693.44, "end": 699.28, "text": " intelligence from Jan Lecun who is according to the Time magazine one of", "tokens": [51430, 7599, 490, 4956, 1456, 66, 409, 567, 307, 4650, 281, 264, 6161, 11332, 472, 295, 51722], "temperature": 0.0, "avg_logprob": -0.2458910555452914, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.009997245855629444}, {"id": 28, "seek": 69928, "start": 699.28, "end": 705.28, "text": " the hundred worldwide leading AI pioneers his professor of NYU on chief", "tokens": [50364, 264, 3262, 13485, 5775, 7318, 47381, 702, 8304, 295, 42682, 322, 9588, 50664], "temperature": 0.0, "avg_logprob": -0.19354993104934692, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.024224860593676567}, {"id": 29, "seek": 69928, "start": 705.28, "end": 713.0, "text": " I scientists at Metta not in California in New York I just learned the title of", "tokens": [50664, 286, 7708, 412, 6377, 1328, 406, 294, 5384, 294, 1873, 3609, 286, 445, 3264, 264, 4876, 295, 51050], "temperature": 0.0, "avg_logprob": -0.19354993104934692, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.024224860593676567}, {"id": 30, "seek": 69928, "start": 713.0, "end": 717.9599999999999, "text": " his talk from machine learning to autonomous intelligence artificial", "tokens": [51050, 702, 751, 490, 3479, 2539, 281, 23797, 7599, 11677, 51298], "temperature": 0.0, "avg_logprob": -0.19354993104934692, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.024224860593676567}, {"id": 31, "seek": 69928, "start": 717.9599999999999, "end": 722.12, "text": " intelligence as you all know is the key topic of our time not only in research", "tokens": [51298, 7599, 382, 291, 439, 458, 307, 264, 2141, 4829, 295, 527, 565, 406, 787, 294, 2132, 51506], "temperature": 0.0, "avg_logprob": -0.19354993104934692, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.024224860593676567}, {"id": 32, "seek": 69928, "start": 722.12, "end": 728.0, "text": " and industry but also in the broader society this becomes evident as a large", "tokens": [51506, 293, 3518, 457, 611, 294, 264, 13227, 4086, 341, 3643, 16371, 382, 257, 2416, 51800], "temperature": 0.0, "avg_logprob": -0.19354993104934692, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.024224860593676567}, {"id": 33, "seek": 72800, "start": 728.12, "end": 733.76, "text": " interest and thank you for all coming to this meeting on sharing this", "tokens": [50370, 1179, 293, 1309, 291, 337, 439, 1348, 281, 341, 3440, 322, 5414, 341, 50652], "temperature": 0.0, "avg_logprob": -0.1667411520674422, "compression_ratio": 1.6210526315789473, "no_speech_prob": 0.02831183560192585}, {"id": 34, "seek": 72800, "start": 733.76, "end": 740.84, "text": " experience we're very pleased as Bavarian Academy to gather with the AI agency to", "tokens": [50652, 1752, 321, 434, 588, 10587, 382, 363, 706, 10652, 11735, 281, 5448, 365, 264, 7318, 7934, 281, 51006], "temperature": 0.0, "avg_logprob": -0.1667411520674422, "compression_ratio": 1.6210526315789473, "no_speech_prob": 0.02831183560192585}, {"id": 35, "seek": 72800, "start": 740.84, "end": 746.84, "text": " be part of biosphere biosphere is the official network of all AI activities", "tokens": [51006, 312, 644, 295, 36997, 6605, 36997, 6605, 307, 264, 4783, 3209, 295, 439, 7318, 5354, 51306], "temperature": 0.0, "avg_logprob": -0.1667411520674422, "compression_ratio": 1.6210526315789473, "no_speech_prob": 0.02831183560192585}, {"id": 36, "seek": 72800, "start": 746.84, "end": 753.56, "text": " in Bavaria we partner in this important task to advance AI science in Bavaria in", "tokens": [51306, 294, 363, 706, 9831, 321, 4975, 294, 341, 1021, 5633, 281, 7295, 7318, 3497, 294, 363, 706, 9831, 294, 51642], "temperature": 0.0, "avg_logprob": -0.1667411520674422, "compression_ratio": 1.6210526315789473, "no_speech_prob": 0.02831183560192585}, {"id": 37, "seek": 75356, "start": 753.64, "end": 759.0, "text": " close cooperation with the Center for Advanced Studies at LMU the Bavarian", "tokens": [50368, 1998, 14968, 365, 264, 5169, 337, 26951, 17515, 412, 46529, 52, 264, 363, 706, 10652, 50636], "temperature": 0.0, "avg_logprob": -0.17732980923774916, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.006647230591624975}, {"id": 38, "seek": 75356, "start": 759.0, "end": 763.04, "text": " Research Institute for Digital Transformation the Munich Center for", "tokens": [50636, 10303, 9446, 337, 15522, 6531, 8663, 264, 40601, 5169, 337, 50838], "temperature": 0.0, "avg_logprob": -0.17732980923774916, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.006647230591624975}, {"id": 39, "seek": 75356, "start": 763.04, "end": 770.68, "text": " Machine Learning and the Konrad Susie School of Excellence in Reliable AI the", "tokens": [50838, 22155, 15205, 293, 264, 12718, 6206, 9545, 414, 5070, 295, 44684, 294, 8738, 9364, 7318, 264, 51220], "temperature": 0.0, "avg_logprob": -0.17732980923774916, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.006647230591624975}, {"id": 40, "seek": 75356, "start": 770.68, "end": 775.0799999999999, "text": " event today is part of this successful cooperation and we're looking very", "tokens": [51220, 2280, 965, 307, 644, 295, 341, 4406, 14968, 293, 321, 434, 1237, 588, 51440], "temperature": 0.0, "avg_logprob": -0.17732980923774916, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.006647230591624975}, {"id": 41, "seek": 75356, "start": 775.0799999999999, "end": 780.4799999999999, "text": " broadly forward to learn more about recent progress from advanced computing to", "tokens": [51440, 19511, 2128, 281, 1466, 544, 466, 5162, 4205, 490, 7339, 15866, 281, 51710], "temperature": 0.0, "avg_logprob": -0.17732980923774916, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.006647230591624975}, {"id": 42, "seek": 78048, "start": 780.48, "end": 787.52, "text": " autonomous intelligence I hereby hand over to professor Thomas Seidel member", "tokens": [50364, 23797, 7599, 286, 510, 2322, 1011, 670, 281, 8304, 8500, 1100, 16189, 4006, 50716], "temperature": 0.0, "avg_logprob": -0.29468523025512694, "compression_ratio": 1.3924050632911393, "no_speech_prob": 0.003880898468196392}, {"id": 43, "seek": 78048, "start": 787.52, "end": 793.44, "text": " of the Bavarian AI Council chair of database systems and data mining", "tokens": [50716, 295, 264, 363, 706, 10652, 7318, 7076, 6090, 295, 8149, 3652, 293, 1412, 15512, 51012], "temperature": 0.0, "avg_logprob": -0.29468523025512694, "compression_ratio": 1.3924050632911393, "no_speech_prob": 0.003880898468196392}, {"id": 44, "seek": 78048, "start": 793.44, "end": 800.28, "text": " director of Munich Center for Machine Learning to all of you I wish a very", "tokens": [51012, 5391, 295, 40601, 5169, 337, 22155, 15205, 281, 439, 295, 291, 286, 3172, 257, 588, 51354], "temperature": 0.0, "avg_logprob": -0.29468523025512694, "compression_ratio": 1.3924050632911393, "no_speech_prob": 0.003880898468196392}, {"id": 45, "seek": 80028, "start": 800.4399999999999, "end": 805.76, "text": " insightful and informative afternoon the Seidel", "tokens": [50372, 46401, 293, 27759, 6499, 264, 1100, 16189, 50638], "temperature": 0.0, "avg_logprob": -0.39825731642702794, "compression_ratio": 1.4, "no_speech_prob": 0.024443667382001877}, {"id": 46, "seek": 80028, "start": 813.76, "end": 819.72, "text": " yeah thank you President Schweiger for this nice introduction and very warm", "tokens": [51038, 1338, 1309, 291, 3117, 24343, 4810, 337, 341, 1481, 9339, 293, 588, 4561, 51336], "temperature": 0.0, "avg_logprob": -0.39825731642702794, "compression_ratio": 1.4, "no_speech_prob": 0.024443667382001877}, {"id": 47, "seek": 80028, "start": 819.72, "end": 825.6, "text": " welcome also from my side to all of you particularly to Jan Leckardt to be here", "tokens": [51336, 2928, 611, 490, 452, 1252, 281, 439, 295, 291, 4098, 281, 4956, 1456, 547, 515, 83, 281, 312, 510, 51630], "temperature": 0.0, "avg_logprob": -0.39825731642702794, "compression_ratio": 1.4, "no_speech_prob": 0.024443667382001877}, {"id": 48, "seek": 82560, "start": 825.6, "end": 832.0400000000001, "text": " today I wear two hats today one is I'm a member of the Bavarian AI Council we", "tokens": [50364, 965, 286, 3728, 732, 20549, 965, 472, 307, 286, 478, 257, 4006, 295, 264, 363, 706, 10652, 7318, 7076, 321, 50686], "temperature": 0.0, "avg_logprob": -0.16576224023645575, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.025663480162620544}, {"id": 49, "seek": 82560, "start": 832.0400000000001, "end": 836.5600000000001, "text": " are 20 members appointed by the Bavarian state government as part of their high", "tokens": [50686, 366, 945, 2679, 17653, 538, 264, 363, 706, 10652, 1785, 2463, 382, 644, 295, 641, 1090, 50912], "temperature": 0.0, "avg_logprob": -0.16576224023645575, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.025663480162620544}, {"id": 50, "seek": 82560, "start": 836.5600000000001, "end": 841.6, "text": " tech agenda from universities research institutions and also companies in the", "tokens": [50912, 7553, 9829, 490, 11779, 2132, 8142, 293, 611, 3431, 294, 264, 51164], "temperature": 0.0, "avg_logprob": -0.16576224023645575, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.025663480162620544}, {"id": 51, "seek": 82560, "start": 841.6, "end": 847.0, "text": " field to advise the government on AI strategies and actions particularly in", "tokens": [51164, 2519, 281, 18312, 264, 2463, 322, 7318, 9029, 293, 5909, 4098, 294, 51434], "temperature": 0.0, "avg_logprob": -0.16576224023645575, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.025663480162620544}, {"id": 52, "seek": 82560, "start": 847.0, "end": 853.44, "text": " steering the Bavarian AI agency so the representative is also Dr. Klimke which", "tokens": [51434, 14823, 264, 363, 706, 10652, 7318, 7934, 370, 264, 12424, 307, 611, 2491, 13, 25136, 330, 597, 51756], "temperature": 0.0, "avg_logprob": -0.16576224023645575, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.025663480162620544}, {"id": 53, "seek": 85344, "start": 853.48, "end": 858.5600000000001, "text": " promotes the Bavarian network which we call biosphere so the logo is there as", "tokens": [50366, 36015, 264, 363, 706, 10652, 3209, 597, 321, 818, 36997, 6605, 370, 264, 9699, 307, 456, 382, 50620], "temperature": 0.0, "avg_logprob": -0.2389167047316028, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.012407691217958927}, {"id": 54, "seek": 85344, "start": 858.5600000000001, "end": 863.12, "text": " well so the biosphere comprises a variety of strong AI players in Bavaria", "tokens": [50620, 731, 370, 264, 36997, 6605, 16802, 3598, 257, 5673, 295, 2068, 7318, 4150, 294, 363, 706, 9831, 50848], "temperature": 0.0, "avg_logprob": -0.2389167047316028, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.012407691217958927}, {"id": 55, "seek": 85344, "start": 863.12, "end": 867.4000000000001, "text": " also universities research institutes from all over Bavaria as well as a lot", "tokens": [50848, 611, 11779, 2132, 4348, 1819, 490, 439, 670, 363, 706, 9831, 382, 731, 382, 257, 688, 51062], "temperature": 0.0, "avg_logprob": -0.2389167047316028, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.012407691217958927}, {"id": 56, "seek": 85344, "start": 867.4000000000001, "end": 872.0, "text": " of the global companies we have here including Google, Microsoft, IBM but", "tokens": [51062, 295, 264, 4338, 3431, 321, 362, 510, 3009, 3329, 11, 8116, 11, 23487, 457, 51292], "temperature": 0.0, "avg_logprob": -0.2389167047316028, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.012407691217958927}, {"id": 57, "seek": 85344, "start": 872.0, "end": 878.8000000000001, "text": " also the locally sitting global players Siemens, BMWs, every insurances Munich", "tokens": [51292, 611, 264, 16143, 3798, 4338, 4150, 3559, 45743, 11, 21355, 82, 11, 633, 1028, 374, 2676, 40601, 51632], "temperature": 0.0, "avg_logprob": -0.2389167047316028, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.012407691217958927}, {"id": 58, "seek": 87880, "start": 878.8, "end": 883.52, "text": " three Alliance and so on but also many original small and medium enterprises", "tokens": [50364, 1045, 21859, 293, 370, 322, 457, 611, 867, 3380, 1359, 293, 6399, 29034, 50600], "temperature": 0.0, "avg_logprob": -0.2613649555281097, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.017165660858154297}, {"id": 59, "seek": 87880, "start": 883.52, "end": 890.8, "text": " and startups in the field of AI so the second hat I am aware today's I'm one", "tokens": [50600, 293, 28041, 294, 264, 2519, 295, 7318, 370, 264, 1150, 2385, 286, 669, 3650, 965, 311, 286, 478, 472, 50964], "temperature": 0.0, "avg_logprob": -0.2613649555281097, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.017165660858154297}, {"id": 60, "seek": 87880, "start": 890.8, "end": 893.92, "text": " of the four directors of the Munich Center for Machine Learning one of the", "tokens": [50964, 295, 264, 1451, 17307, 295, 264, 40601, 5169, 337, 22155, 15205, 472, 295, 264, 51120], "temperature": 0.0, "avg_logprob": -0.2613649555281097, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.017165660858154297}, {"id": 61, "seek": 87880, "start": 893.92, "end": 900.12, "text": " co-directors Daniel Gremmels also here and we this is a consortium of LMU and", "tokens": [51120, 598, 12, 18267, 5547, 8033, 14986, 2174, 1625, 611, 510, 293, 321, 341, 307, 257, 38343, 2197, 295, 46529, 52, 293, 51430], "temperature": 0.0, "avg_logprob": -0.2613649555281097, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.017165660858154297}, {"id": 62, "seek": 87880, "start": 900.12, "end": 905.16, "text": " Tom funded by the BNBF in the Bavarian high-tech agenda with around 50 PIs in", "tokens": [51430, 5041, 14385, 538, 264, 363, 45, 33, 37, 294, 264, 363, 706, 10652, 1090, 12, 25970, 9829, 365, 926, 2625, 430, 6802, 294, 51682], "temperature": 0.0, "avg_logprob": -0.2613649555281097, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.017165660858154297}, {"id": 63, "seek": 90516, "start": 905.16, "end": 908.8, "text": " machine learning in the I3 junior research groups recently established", "tokens": [50364, 3479, 2539, 294, 264, 286, 18, 16195, 2132, 3935, 3938, 7545, 50546], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 64, "seek": 90516, "start": 908.8, "end": 914.48, "text": " around 200 doctoral students and our focus is on foundations of machine", "tokens": [50546, 926, 2331, 41419, 1731, 293, 527, 1879, 307, 322, 22467, 295, 3479, 50830], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 65, "seek": 90516, "start": 914.48, "end": 919.12, "text": " learning where we have several players including Gitta Kottiniok from the", "tokens": [50830, 2539, 689, 321, 362, 2940, 4150, 3009, 460, 21870, 591, 1521, 3812, 453, 490, 264, 51062], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 66, "seek": 90516, "start": 919.12, "end": 923.04, "text": " mathematical part and statistics and computer science is there then perception", "tokens": [51062, 18894, 644, 293, 12523, 293, 3820, 3497, 307, 456, 550, 12860, 51258], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 67, "seek": 90516, "start": 923.04, "end": 928.36, "text": " we are particularly strong in computer vision here and in Munich and in natural", "tokens": [51258, 321, 366, 4098, 2068, 294, 3820, 5201, 510, 293, 294, 40601, 293, 294, 3303, 51524], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 68, "seek": 90516, "start": 928.36, "end": 934.56, "text": " language processing the two big things where humans and computers interact", "tokens": [51524, 2856, 9007, 264, 732, 955, 721, 689, 6255, 293, 10807, 4648, 51834], "temperature": 0.0, "avg_logprob": -0.306464975530451, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.007534058764576912}, {"id": 69, "seek": 93456, "start": 934.5999999999999, "end": 941.28, "text": " and a lot of domain specific things it's not on research but also on transfer", "tokens": [50366, 293, 257, 688, 295, 9274, 2685, 721, 309, 311, 406, 322, 2132, 457, 611, 322, 5003, 50700], "temperature": 0.0, "avg_logprob": -0.20926243918282644, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.002700367011129856}, {"id": 70, "seek": 93456, "start": 941.28, "end": 946.1199999999999, "text": " activities fostering the collaboration network together with the biosphere", "tokens": [50700, 5354, 17114, 278, 264, 9363, 3209, 1214, 365, 264, 36997, 6605, 50942], "temperature": 0.0, "avg_logprob": -0.20926243918282644, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.002700367011129856}, {"id": 71, "seek": 93456, "start": 946.1199999999999, "end": 950.56, "text": " outreach to the general public things like that if you're interested also", "tokens": [50942, 19638, 281, 264, 2674, 1908, 721, 411, 300, 498, 291, 434, 3102, 611, 51164], "temperature": 0.0, "avg_logprob": -0.20926243918282644, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.002700367011129856}, {"id": 72, "seek": 93456, "start": 950.56, "end": 955.1999999999999, "text": " openings of course so this is that part so I'm sure we get fully inspired by", "tokens": [51164, 35941, 295, 1164, 370, 341, 307, 300, 644, 370, 286, 478, 988, 321, 483, 4498, 7547, 538, 51396], "temperature": 0.0, "avg_logprob": -0.20926243918282644, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.002700367011129856}, {"id": 73, "seek": 93456, "start": 955.1999999999999, "end": 960.2399999999999, "text": " your presentation and between your presentation is now the next is Dr. Mayer", "tokens": [51396, 428, 5860, 293, 1296, 428, 5860, 307, 586, 264, 958, 307, 2491, 13, 1891, 260, 51648], "temperature": 0.0, "avg_logprob": -0.20926243918282644, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.002700367011129856}, {"id": 74, "seek": 96024, "start": 960.24, "end": 973.36, "text": " from TASS, you're on stage, thank you ladies and gentlemen may I also welcome", "tokens": [50364, 490, 314, 19678, 11, 291, 434, 322, 3233, 11, 1309, 291, 9974, 293, 11669, 815, 286, 611, 2928, 51020], "temperature": 0.0, "avg_logprob": -0.27498756408691405, "compression_ratio": 1.5729166666666667, "no_speech_prob": 0.0026668391656130552}, {"id": 75, "seek": 96024, "start": 973.36, "end": 977.92, "text": " you warmly on behalf of the Center for Advanced Studies at LMU and let me", "tokens": [51020, 291, 4561, 356, 322, 9490, 295, 264, 5169, 337, 26951, 17515, 412, 46529, 52, 293, 718, 385, 51248], "temperature": 0.0, "avg_logprob": -0.27498756408691405, "compression_ratio": 1.5729166666666667, "no_speech_prob": 0.0026668391656130552}, {"id": 76, "seek": 96024, "start": 977.92, "end": 982.44, "text": " briefly say a few words about this institution and how it comes into play", "tokens": [51248, 10515, 584, 257, 1326, 2283, 466, 341, 7818, 293, 577, 309, 1487, 666, 862, 51474], "temperature": 0.0, "avg_logprob": -0.27498756408691405, "compression_ratio": 1.5729166666666667, "no_speech_prob": 0.0026668391656130552}, {"id": 77, "seek": 96024, "start": 982.44, "end": 987.84, "text": " the Center for Advanced Studies at LMU was founded 15 years ago to provide a", "tokens": [51474, 264, 5169, 337, 26951, 17515, 412, 46529, 52, 390, 13234, 2119, 924, 2057, 281, 2893, 257, 51744], "temperature": 0.0, "avg_logprob": -0.27498756408691405, "compression_ratio": 1.5729166666666667, "no_speech_prob": 0.0026668391656130552}, {"id": 78, "seek": 98784, "start": 987.96, "end": 993.6, "text": " forum for precisely those research questions that cannot be tackled by", "tokens": [50370, 17542, 337, 13402, 729, 2132, 1651, 300, 2644, 312, 9426, 1493, 538, 50652], "temperature": 0.0, "avg_logprob": -0.24858339097764756, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.008568408899009228}, {"id": 79, "seek": 98784, "start": 993.6, "end": 999.2, "text": " only one discipline this was intended to take account of an increasingly", "tokens": [50652, 787, 472, 13635, 341, 390, 10226, 281, 747, 2696, 295, 364, 12980, 50932], "temperature": 0.0, "avg_logprob": -0.24858339097764756, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.008568408899009228}, {"id": 80, "seek": 98784, "start": 999.2, "end": 1005.2, "text": " diversifying but also specializing body of research that is becoming more and", "tokens": [50932, 6111, 5489, 457, 611, 2121, 3319, 1772, 295, 2132, 300, 307, 5617, 544, 293, 51232], "temperature": 0.0, "avg_logprob": -0.24858339097764756, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.008568408899009228}, {"id": 81, "seek": 98784, "start": 1005.2, "end": 1010.64, "text": " more disparate not only in terms of content but also in terms of space in", "tokens": [51232, 544, 14548, 473, 406, 787, 294, 2115, 295, 2701, 457, 611, 294, 2115, 295, 1901, 294, 51504], "temperature": 0.0, "avg_logprob": -0.24858339097764756, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.008568408899009228}, {"id": 82, "seek": 98784, "start": 1010.64, "end": 1016.64, "text": " Munich you can just think of the campus in Ober-Schleishheim, Ober-Guy-Ching,", "tokens": [51504, 40601, 291, 393, 445, 519, 295, 264, 4828, 294, 27664, 12, 31560, 306, 742, 18673, 11, 27664, 12, 38, 7493, 12, 6546, 278, 11, 51804], "temperature": 0.0, "avg_logprob": -0.24858339097764756, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.008568408899009228}, {"id": 83, "seek": 101664, "start": 1016.64, "end": 1022.6, "text": " Nordeid in the far south so the Center for Advanced Studies offers the place", "tokens": [50364, 426, 15127, 327, 294, 264, 1400, 7377, 370, 264, 5169, 337, 26951, 17515, 7736, 264, 1081, 50662], "temperature": 0.0, "avg_logprob": -0.2491892421946806, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0026829850394278765}, {"id": 84, "seek": 101664, "start": 1022.6, "end": 1029.12, "text": " where these centrifugal forces can be bundled and for what topic does this", "tokens": [50662, 689, 613, 44828, 17812, 5874, 393, 312, 13882, 1493, 293, 337, 437, 4829, 775, 341, 50988], "temperature": 0.0, "avg_logprob": -0.2491892421946806, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0026829850394278765}, {"id": 85, "seek": 101664, "start": 1029.12, "end": 1034.2, "text": " task play a more important role than for artificial intelligence which is", "tokens": [50988, 5633, 862, 257, 544, 1021, 3090, 813, 337, 11677, 7599, 597, 307, 51242], "temperature": 0.0, "avg_logprob": -0.2491892421946806, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0026829850394278765}, {"id": 86, "seek": 101664, "start": 1034.2, "end": 1041.08, "text": " spread across most faculties of LMU and other universities it was therefore a", "tokens": [51242, 3974, 2108, 881, 44137, 530, 295, 46529, 52, 293, 661, 11779, 309, 390, 4412, 257, 51586], "temperature": 0.0, "avg_logprob": -0.2491892421946806, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0026829850394278765}, {"id": 87, "seek": 101664, "start": 1041.08, "end": 1045.6, "text": " great pleasure for us when Gitta Kutinyok freshly appointed at our", "tokens": [51586, 869, 6834, 337, 505, 562, 460, 21870, 591, 325, 3519, 453, 34412, 17653, 412, 527, 51812], "temperature": 0.0, "avg_logprob": -0.2491892421946806, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0026829850394278765}, {"id": 88, "seek": 104560, "start": 1045.6399999999999, "end": 1050.6799999999998, "text": " university approached us and asked whether a form it could be found that", "tokens": [50366, 5454, 17247, 505, 293, 2351, 1968, 257, 1254, 309, 727, 312, 1352, 300, 50618], "temperature": 0.0, "avg_logprob": -0.20315549145006154, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0023523864801973104}, {"id": 89, "seek": 104560, "start": 1050.6799999999998, "end": 1056.9199999999998, "text": " would network research on AI at LMU and unable to discuss overarching issues", "tokens": [50618, 576, 3209, 2132, 322, 7318, 412, 46529, 52, 293, 11299, 281, 2248, 45501, 2663, 50930], "temperature": 0.0, "avg_logprob": -0.20315549145006154, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0023523864801973104}, {"id": 90, "seek": 104560, "start": 1056.9199999999998, "end": 1062.28, "text": " together it wasn't long before a so-called interdisciplinary CAS", "tokens": [50930, 1214, 309, 2067, 380, 938, 949, 257, 370, 12, 11880, 38280, 43268, 51198], "temperature": 0.0, "avg_logprob": -0.20315549145006154, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0023523864801973104}, {"id": 91, "seek": 104560, "start": 1062.28, "end": 1067.8799999999999, "text": " research focused entitled next generation AI was born bringing together", "tokens": [51198, 2132, 5178, 17838, 958, 5125, 7318, 390, 4232, 5062, 1214, 51478], "temperature": 0.0, "avg_logprob": -0.20315549145006154, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0023523864801973104}, {"id": 92, "seek": 104560, "start": 1067.8799999999999, "end": 1073.9599999999998, "text": " researchers from 14 faculties working on the topic of artificial intelligence", "tokens": [51478, 10309, 490, 3499, 44137, 530, 1364, 322, 264, 4829, 295, 11677, 7599, 51782], "temperature": 0.0, "avg_logprob": -0.20315549145006154, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0023523864801973104}, {"id": 93, "seek": 107396, "start": 1073.96, "end": 1079.96, "text": " over the course of two years a wide variety of lectures workshops and", "tokens": [50364, 670, 264, 1164, 295, 732, 924, 257, 4874, 5673, 295, 16564, 19162, 293, 50664], "temperature": 0.0, "avg_logprob": -0.15380931181066176, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.0009546393412165344}, {"id": 94, "seek": 107396, "start": 1079.96, "end": 1085.68, "text": " conferences was organized and held and we were thrilled by the spirit that", "tokens": [50664, 22032, 390, 9983, 293, 5167, 293, 321, 645, 18744, 538, 264, 3797, 300, 50950], "temperature": 0.0, "avg_logprob": -0.15380931181066176, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.0009546393412165344}, {"id": 95, "seek": 107396, "start": 1085.68, "end": 1091.1200000000001, "text": " emerged of that group that's why we look forward to Professor LeCun's lecture", "tokens": [50950, 20178, 295, 300, 1594, 300, 311, 983, 321, 574, 2128, 281, 8419, 1456, 34, 409, 311, 7991, 51222], "temperature": 0.0, "avg_logprob": -0.15380931181066176, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.0009546393412165344}, {"id": 96, "seek": 107396, "start": 1091.1200000000001, "end": 1096.76, "text": " today with both a smile and a tear as it marks the formal conclusion of the", "tokens": [51222, 965, 365, 1293, 257, 7563, 293, 257, 12556, 382, 309, 10640, 264, 9860, 10063, 295, 264, 51504], "temperature": 0.0, "avg_logprob": -0.15380931181066176, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.0009546393412165344}, {"id": 97, "seek": 107396, "start": 1096.76, "end": 1102.04, "text": " research focus we are honored and grateful that Professor LeCun is going", "tokens": [51504, 2132, 1879, 321, 366, 14556, 293, 7941, 300, 8419, 1456, 34, 409, 307, 516, 51768], "temperature": 0.0, "avg_logprob": -0.15380931181066176, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.0009546393412165344}, {"id": 98, "seek": 110204, "start": 1102.08, "end": 1119.32, "text": " to give the lecture in this framework today yeah also a warm welcome from my", "tokens": [50366, 281, 976, 264, 7991, 294, 341, 8388, 965, 1338, 611, 257, 4561, 2928, 490, 452, 51228], "temperature": 0.0, "avg_logprob": -0.18831883943997896, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0021262660156935453}, {"id": 99, "seek": 110204, "start": 1119.32, "end": 1124.32, "text": " side to everyone here on site and also to everyone who participates via", "tokens": [51228, 1252, 281, 1518, 510, 322, 3621, 293, 611, 281, 1518, 567, 3421, 1024, 5766, 51478], "temperature": 0.0, "avg_logprob": -0.18831883943997896, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0021262660156935453}, {"id": 100, "seek": 110204, "start": 1124.32, "end": 1129.24, "text": " live stream it is wonderful to have so many people with us here this afternoon", "tokens": [51478, 1621, 4309, 309, 307, 3715, 281, 362, 370, 867, 561, 365, 505, 510, 341, 6499, 51724], "temperature": 0.0, "avg_logprob": -0.18831883943997896, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0021262660156935453}, {"id": 101, "seek": 112924, "start": 1129.92, "end": 1132.76, "text": " and a great thanks to all of our cooperation partners for actually", "tokens": [50398, 293, 257, 869, 3231, 281, 439, 295, 527, 14968, 4462, 337, 767, 50540], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 102, "seek": 112924, "start": 1132.76, "end": 1136.72, "text": " making this lecture possible and here I would like to particularly thank Dr", "tokens": [50540, 1455, 341, 7991, 1944, 293, 510, 286, 576, 411, 281, 4098, 1309, 2491, 50738], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 103, "seek": 112924, "start": 1136.72, "end": 1140.64, "text": " Anette Meyer and the Center for Advanced Studies of the Ludwig Maximilians", "tokens": [50738, 1107, 3007, 47207, 293, 264, 5169, 337, 26951, 17515, 295, 264, 30550, 33313, 29076, 21738, 50934], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 104, "seek": 112924, "start": 1140.64, "end": 1145.4, "text": " University M\u00fcnchen Professor Dr. Markus Schweiger and the Bavarian Academy of", "tokens": [50934, 3535, 35840, 2470, 8419, 2491, 13, 45041, 24343, 4810, 293, 264, 363, 706, 10652, 11735, 295, 51172], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 105, "seek": 112924, "start": 1145.4, "end": 1150.1200000000001, "text": " Sciences and Humanities that this event can take place here in the academy in", "tokens": [51172, 21108, 293, 10294, 1088, 300, 341, 2280, 393, 747, 1081, 510, 294, 264, 25525, 294, 51408], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 106, "seek": 112924, "start": 1150.1200000000001, "end": 1154.64, "text": " these really beautiful rooms Professor Dr. Thomas Seidel and Dr. Michael", "tokens": [51408, 613, 534, 2238, 9396, 8419, 2491, 13, 8500, 1100, 16189, 293, 2491, 13, 5116, 51634], "temperature": 0.0, "avg_logprob": -0.24016014253250276, "compression_ratio": 1.5795053003533568, "no_speech_prob": 0.008228608407080173}, {"id": 107, "seek": 115464, "start": 1154.68, "end": 1159.3200000000002, "text": " Klimker from the biosphere the Bavarian Eye Network which made the live stream", "tokens": [50366, 25136, 5767, 490, 264, 36997, 6605, 264, 363, 706, 10652, 21603, 12640, 597, 1027, 264, 1621, 4309, 50598], "temperature": 0.0, "avg_logprob": -0.2098300485049977, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.004119068384170532}, {"id": 108, "seek": 115464, "start": 1159.3200000000002, "end": 1164.5200000000002, "text": " for the event possible and also Dr. Christoph Egle from the Bavarian", "tokens": [50598, 337, 264, 2280, 1944, 293, 611, 2491, 13, 2040, 5317, 462, 22631, 490, 264, 363, 706, 10652, 50858], "temperature": 0.0, "avg_logprob": -0.2098300485049977, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.004119068384170532}, {"id": 109, "seek": 115464, "start": 1164.5200000000002, "end": 1169.3600000000001, "text": " Research Institute for Digital Transformation and now it's my great", "tokens": [50858, 10303, 9446, 337, 15522, 6531, 8663, 293, 586, 309, 311, 452, 869, 51100], "temperature": 0.0, "avg_logprob": -0.2098300485049977, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.004119068384170532}, {"id": 110, "seek": 115464, "start": 1169.3600000000001, "end": 1174.4, "text": " pleasure and honor to welcome Professor Jan LeCun thank you very much for", "tokens": [51100, 6834, 293, 5968, 281, 2928, 8419, 4956, 1456, 34, 409, 1309, 291, 588, 709, 337, 51352], "temperature": 0.0, "avg_logprob": -0.2098300485049977, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.004119068384170532}, {"id": 111, "seek": 115464, "start": 1174.4, "end": 1179.0800000000002, "text": " accepting our invitation and for coming to Munich for this lecture today", "tokens": [51352, 17391, 527, 17890, 293, 337, 1348, 281, 40601, 337, 341, 7991, 965, 51586], "temperature": 0.0, "avg_logprob": -0.2098300485049977, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.004119068384170532}, {"id": 112, "seek": 117908, "start": 1179.6799999999998, "end": 1184.52, "text": " Professor LeCun is chief AI scientist at Meta and the silver professor of", "tokens": [50394, 8419, 1456, 34, 409, 307, 9588, 7318, 12662, 412, 6377, 64, 293, 264, 8753, 8304, 295, 50636], "temperature": 0.0, "avg_logprob": -0.21580252589949642, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004812939092516899}, {"id": 113, "seek": 117908, "start": 1184.52, "end": 1189.6799999999998, "text": " computer science at New York University he started his career with a PhD in", "tokens": [50636, 3820, 3497, 412, 1873, 3609, 3535, 415, 1409, 702, 3988, 365, 257, 14476, 294, 50894], "temperature": 0.0, "avg_logprob": -0.21580252589949642, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004812939092516899}, {"id": 114, "seek": 117908, "start": 1189.6799999999998, "end": 1195.3999999999999, "text": " computer science at Sorbonne University in Paris and then moved to the US where", "tokens": [50894, 3820, 3497, 412, 21421, 4351, 716, 3535, 294, 8380, 293, 550, 4259, 281, 264, 2546, 689, 51180], "temperature": 0.0, "avg_logprob": -0.21580252589949642, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004812939092516899}, {"id": 115, "seek": 117908, "start": 1195.3999999999999, "end": 1200.36, "text": " he became the head of the image processing research department at the", "tokens": [51180, 415, 3062, 264, 1378, 295, 264, 3256, 9007, 2132, 5882, 412, 264, 51428], "temperature": 0.0, "avg_logprob": -0.21580252589949642, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004812939092516899}, {"id": 116, "seek": 117908, "start": 1200.36, "end": 1208.12, "text": " famous Bell Labs the AT&T Bell Laboratories then after intermediate", "tokens": [51428, 4618, 11485, 40047, 264, 8872, 5, 51, 11485, 17250, 30077, 550, 934, 19376, 51816], "temperature": 0.0, "avg_logprob": -0.21580252589949642, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004812939092516899}, {"id": 117, "seek": 120812, "start": 1208.1599999999999, "end": 1214.32, "text": " stations he joined New York University in 2003 and he also became there the", "tokens": [50366, 13390, 415, 6869, 1873, 3609, 3535, 294, 16416, 293, 415, 611, 3062, 456, 264, 50674], "temperature": 0.0, "avg_logprob": -0.1566389180436919, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0004716352850664407}, {"id": 118, "seek": 120812, "start": 1214.32, "end": 1222.0, "text": " founding director of the NYU Center for Data Science in 2012. His groundbreaking", "tokens": [50674, 22223, 5391, 295, 264, 42682, 5169, 337, 11888, 8976, 294, 9125, 13, 2812, 42491, 51058], "temperature": 0.0, "avg_logprob": -0.1566389180436919, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0004716352850664407}, {"id": 119, "seek": 120812, "start": 1222.0, "end": 1226.32, "text": " work includes among many others the development of convolutional neural", "tokens": [51058, 589, 5974, 3654, 867, 2357, 264, 3250, 295, 45216, 304, 18161, 51274], "temperature": 0.0, "avg_logprob": -0.1566389180436919, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0004716352850664407}, {"id": 120, "seek": 120812, "start": 1226.32, "end": 1230.4799999999998, "text": " networks which are the state-of-the-art for basically any problem in particular", "tokens": [51274, 9590, 597, 366, 264, 1785, 12, 2670, 12, 3322, 12, 446, 337, 1936, 604, 1154, 294, 1729, 51482], "temperature": 0.0, "avg_logprob": -0.1566389180436919, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0004716352850664407}, {"id": 121, "seek": 120812, "start": 1230.4799999999998, "end": 1235.36, "text": " imaging sciences and computer vision and a particularly particular convolutional", "tokens": [51482, 25036, 17677, 293, 3820, 5201, 293, 257, 4098, 1729, 45216, 304, 51726], "temperature": 0.0, "avg_logprob": -0.1566389180436919, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0004716352850664407}, {"id": 122, "seek": 123536, "start": 1235.56, "end": 1241.24, "text": " network architecture is also named by him the so-called LeNet which in", "tokens": [50374, 3209, 9482, 307, 611, 4926, 538, 796, 264, 370, 12, 11880, 1456, 31890, 597, 294, 50658], "temperature": 0.0, "avg_logprob": -0.13125719847502532, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0021086041815578938}, {"id": 123, "seek": 123536, "start": 1241.24, "end": 1245.4399999999998, "text": " sense also promoted the impressive development of deep learning and AI as", "tokens": [50658, 2020, 611, 21162, 264, 8992, 3250, 295, 2452, 2539, 293, 7318, 382, 50868], "temperature": 0.0, "avg_logprob": -0.13125719847502532, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0021086041815578938}, {"id": 124, "seek": 123536, "start": 1245.4399999999998, "end": 1252.52, "text": " we experience it today. His contributions are honored by numerous awards many more", "tokens": [50868, 321, 1752, 309, 965, 13, 2812, 15725, 366, 14556, 538, 12546, 15193, 867, 544, 51222], "temperature": 0.0, "avg_logprob": -0.13125719847502532, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0021086041815578938}, {"id": 125, "seek": 123536, "start": 1252.52, "end": 1257.12, "text": " than I could name here let me just mention that he's a member of the US", "tokens": [51222, 813, 286, 727, 1315, 510, 718, 385, 445, 2152, 300, 415, 311, 257, 4006, 295, 264, 2546, 51452], "temperature": 0.0, "avg_logprob": -0.13125719847502532, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0021086041815578938}, {"id": 126, "seek": 123536, "start": 1257.12, "end": 1261.6399999999999, "text": " National Academy of Sciences and the National Academy of Engineering he", "tokens": [51452, 4862, 11735, 295, 21108, 293, 264, 4862, 11735, 295, 16215, 415, 51678], "temperature": 0.0, "avg_logprob": -0.13125719847502532, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0021086041815578938}, {"id": 127, "seek": 126164, "start": 1261.64, "end": 1267.48, "text": " received various honorary degrees for instance from EPFL, received the IEEE", "tokens": [50364, 4613, 3683, 49365, 5310, 337, 5197, 490, 25330, 31455, 11, 4613, 264, 286, 7258, 36, 50656], "temperature": 0.0, "avg_logprob": -0.21407097928664265, "compression_ratio": 1.4205607476635513, "no_speech_prob": 0.0006552266422659159}, {"id": 128, "seek": 126164, "start": 1267.48, "end": 1275.8000000000002, "text": " neural network pioneer award and in 2019 the Turing Award which is typically", "tokens": [50656, 18161, 3209, 37668, 7130, 293, 294, 6071, 264, 314, 1345, 13894, 597, 307, 5850, 51072], "temperature": 0.0, "avg_logprob": -0.21407097928664265, "compression_ratio": 1.4205607476635513, "no_speech_prob": 0.0006552266422659159}, {"id": 129, "seek": 126164, "start": 1275.8000000000002, "end": 1280.88, "text": " referred to as the Nobel Prize of Computing and just a few weeks ago we", "tokens": [51072, 10839, 281, 382, 264, 24611, 22604, 295, 37804, 278, 293, 445, 257, 1326, 3259, 2057, 321, 51326], "temperature": 0.0, "avg_logprob": -0.21407097928664265, "compression_ratio": 1.4205607476635513, "no_speech_prob": 0.0006552266422659159}, {"id": 130, "seek": 126164, "start": 1280.88, "end": 1285.72, "text": " already heard at the Time Magazine and congratulations to that has selected him", "tokens": [51326, 1217, 2198, 412, 264, 6161, 27618, 293, 13568, 281, 300, 575, 8209, 796, 51568], "temperature": 0.0, "avg_logprob": -0.21407097928664265, "compression_ratio": 1.4205607476635513, "no_speech_prob": 0.0006552266422659159}, {"id": 131, "seek": 128572, "start": 1285.72, "end": 1292.28, "text": " as one of the 100 most influential people in AI worldwide and he also", "tokens": [50364, 382, 472, 295, 264, 2319, 881, 22215, 561, 294, 7318, 13485, 293, 415, 611, 50692], "temperature": 0.0, "avg_logprob": -0.1764951041250518, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.0029279033187776804}, {"id": 132, "seek": 128572, "start": 1292.28, "end": 1296.84, "text": " repeatedly contributes to the public debate about AI with also controversial", "tokens": [50692, 18227, 32035, 281, 264, 1908, 7958, 466, 7318, 365, 611, 17323, 50920], "temperature": 0.0, "avg_logprob": -0.1764951041250518, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.0029279033187776804}, {"id": 133, "seek": 128572, "start": 1296.84, "end": 1303.68, "text": " proclamations for example on the current craze around large language models. How", "tokens": [50920, 447, 3474, 335, 763, 337, 1365, 322, 264, 2190, 2094, 1381, 926, 2416, 2856, 5245, 13, 1012, 51262], "temperature": 0.0, "avg_logprob": -0.1764951041250518, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.0029279033187776804}, {"id": 134, "seek": 128572, "start": 1303.68, "end": 1309.6000000000001, "text": " could machines to learn as efficiently as humans and animals? How could machines", "tokens": [51262, 727, 8379, 281, 1466, 382, 19621, 382, 6255, 293, 4882, 30, 1012, 727, 8379, 51558], "temperature": 0.0, "avg_logprob": -0.1764951041250518, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.0029279033187776804}, {"id": 135, "seek": 130960, "start": 1309.7199999999998, "end": 1316.36, "text": " learn to reason and plan? In his lecture Professor Jan LeKang will now talk about", "tokens": [50370, 1466, 281, 1778, 293, 1393, 30, 682, 702, 7991, 8419, 4956, 1456, 42, 656, 486, 586, 751, 466, 50702], "temperature": 0.0, "avg_logprob": -0.32728336334228514, "compression_ratio": 1.3641975308641976, "no_speech_prob": 0.003016041126102209}, {"id": 136, "seek": 130960, "start": 1316.36, "end": 1322.76, "text": " a possible path towards an autonomous intelligent agents based on a new", "tokens": [50702, 257, 1944, 3100, 3030, 364, 23797, 13232, 12554, 2361, 322, 257, 777, 51022], "temperature": 0.0, "avg_logprob": -0.32728336334228514, "compression_ratio": 1.3641975308641976, "no_speech_prob": 0.003016041126102209}, {"id": 137, "seek": 130960, "start": 1322.76, "end": 1327.4399999999998, "text": " modular cognitive architecture. Where come Jan? The floor is yours.", "tokens": [51022, 31111, 15605, 9482, 13, 2305, 808, 4956, 30, 440, 4123, 307, 6342, 13, 51256], "temperature": 0.0, "avg_logprob": -0.32728336334228514, "compression_ratio": 1.3641975308641976, "no_speech_prob": 0.003016041126102209}, {"id": 138, "seek": 133960, "start": 1339.6, "end": 1353.76, "text": " Thank you very much for the introduction and thank you very much for", "tokens": [50364, 1044, 291, 588, 709, 337, 264, 9339, 293, 1309, 291, 588, 709, 337, 51072], "temperature": 0.0, "avg_logprob": -0.26514176969174985, "compression_ratio": 1.5241379310344827, "no_speech_prob": 0.0031696956139057875}, {"id": 139, "seek": 133960, "start": 1353.76, "end": 1358.9599999999998, "text": " inviting me for coming here so so numerous. I have to correct one thing", "tokens": [51072, 18202, 385, 337, 1348, 510, 370, 370, 12546, 13, 286, 362, 281, 3006, 472, 551, 51332], "temperature": 0.0, "avg_logprob": -0.26514176969174985, "compression_ratio": 1.5241379310344827, "no_speech_prob": 0.0031696956139057875}, {"id": 140, "seek": 133960, "start": 1358.9599999999998, "end": 1366.9599999999998, "text": " though I did not call convolutional net solonet this was my lab director at Bell", "tokens": [51332, 1673, 286, 630, 406, 818, 45216, 304, 2533, 1404, 266, 302, 341, 390, 452, 2715, 5391, 412, 11485, 51732], "temperature": 0.0, "avg_logprob": -0.26514176969174985, "compression_ratio": 1.5241379310344827, "no_speech_prob": 0.0031696956139057875}, {"id": 141, "seek": 136696, "start": 1366.96, "end": 1378.64, "text": " Labs who gave it that name I would never done this but it's a good name okay it's", "tokens": [50364, 40047, 567, 2729, 309, 300, 1315, 286, 576, 1128, 1096, 341, 457, 309, 311, 257, 665, 1315, 1392, 309, 311, 50948], "temperature": 0.0, "avg_logprob": -0.19372527222884328, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.002313450910151005}, {"id": 142, "seek": 136696, "start": 1378.64, "end": 1382.88, "text": " a long title and a long subtitle objective-driven AI this is what I call", "tokens": [50948, 257, 938, 4876, 293, 257, 938, 30706, 306, 10024, 12, 25456, 7318, 341, 307, 437, 286, 818, 51160], "temperature": 0.0, "avg_logprob": -0.19372527222884328, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.002313450910151005}, {"id": 143, "seek": 136696, "start": 1382.88, "end": 1388.3600000000001, "text": " this I used to give this talk with the title autonomous machine intelligence", "tokens": [51160, 341, 286, 1143, 281, 976, 341, 751, 365, 264, 4876, 23797, 3479, 7599, 51434], "temperature": 0.0, "avg_logprob": -0.19372527222884328, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.002313450910151005}, {"id": 144, "seek": 136696, "start": 1388.3600000000001, "end": 1395.04, "text": " and and it scares people you know they say do you mean machines that will be", "tokens": [51434, 293, 293, 309, 35721, 561, 291, 458, 436, 584, 360, 291, 914, 8379, 300, 486, 312, 51768], "temperature": 0.0, "avg_logprob": -0.19372527222884328, "compression_ratio": 1.612565445026178, "no_speech_prob": 0.002313450910151005}, {"id": 145, "seek": 139504, "start": 1395.04, "end": 1397.8799999999999, "text": " autonomous we're not going to be able to control them so I changed the name to", "tokens": [50364, 23797, 321, 434, 406, 516, 281, 312, 1075, 281, 1969, 552, 370, 286, 3105, 264, 1315, 281, 50506], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 146, "seek": 139504, "start": 1397.8799999999999, "end": 1402.84, "text": " objective-driven AI because that's really more accurate and they're really kind", "tokens": [50506, 10024, 12, 25456, 7318, 570, 300, 311, 534, 544, 8559, 293, 436, 434, 534, 733, 50754], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 147, "seek": 139504, "start": 1402.84, "end": 1406.6399999999999, "text": " of systems it's an aspiration it's not something that we've done it's something", "tokens": [50754, 295, 3652, 309, 311, 364, 44565, 309, 311, 406, 746, 300, 321, 600, 1096, 309, 311, 746, 50944], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 148, "seek": 139504, "start": 1406.6399999999999, "end": 1411.48, "text": " that we should do and there are systems that could of course learn remember", "tokens": [50944, 300, 321, 820, 360, 293, 456, 366, 3652, 300, 727, 295, 1164, 1466, 1604, 51186], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 149, "seek": 139504, "start": 1411.48, "end": 1419.08, "text": " reason plan have common sense be steerable controllable safe and have the", "tokens": [51186, 1778, 1393, 362, 2689, 2020, 312, 30814, 712, 45159, 712, 3273, 293, 362, 264, 51566], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 150, "seek": 139504, "start": 1419.08, "end": 1422.8799999999999, "text": " same kind of learning abilities and intelligence that we observe in animals", "tokens": [51566, 912, 733, 295, 2539, 11582, 293, 7599, 300, 321, 11441, 294, 4882, 51756], "temperature": 0.0, "avg_logprob": -0.11884768032333226, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.012451362796127796}, {"id": 151, "seek": 142288, "start": 1422.92, "end": 1430.1200000000001, "text": " and humans so let me start by a little bit of the state of the art okay because", "tokens": [50366, 293, 6255, 370, 718, 385, 722, 538, 257, 707, 857, 295, 264, 1785, 295, 264, 1523, 1392, 570, 50726], "temperature": 0.0, "avg_logprob": -0.11953118642171225, "compression_ratio": 1.84037558685446, "no_speech_prob": 0.004918219055980444}, {"id": 152, "seek": 142288, "start": 1430.1200000000001, "end": 1434.64, "text": " there's a lot of debates today about about AI and a lot of people are afraid", "tokens": [50726, 456, 311, 257, 688, 295, 24203, 965, 466, 466, 7318, 293, 257, 688, 295, 561, 366, 4638, 50952], "temperature": 0.0, "avg_logprob": -0.11953118642171225, "compression_ratio": 1.84037558685446, "no_speech_prob": 0.004918219055980444}, {"id": 153, "seek": 142288, "start": 1434.64, "end": 1440.2800000000002, "text": " of AI it's understandable whenever there is technological revolution people are", "tokens": [50952, 295, 7318, 309, 311, 25648, 5699, 456, 307, 18439, 8894, 561, 366, 51234], "temperature": 0.0, "avg_logprob": -0.11953118642171225, "compression_ratio": 1.84037558685446, "no_speech_prob": 0.004918219055980444}, {"id": 154, "seek": 142288, "start": 1440.2800000000002, "end": 1445.2800000000002, "text": " afraid of the unknown and AI is promising to be a big revolution so people", "tokens": [51234, 4638, 295, 264, 9841, 293, 7318, 307, 20257, 281, 312, 257, 955, 8894, 370, 561, 51484], "temperature": 0.0, "avg_logprob": -0.11953118642171225, "compression_ratio": 1.84037558685446, "no_speech_prob": 0.004918219055980444}, {"id": 155, "seek": 142288, "start": 1445.2800000000002, "end": 1450.0800000000002, "text": " are afraid so let's first talk about the benefits before we talk about the risks", "tokens": [51484, 366, 4638, 370, 718, 311, 700, 751, 466, 264, 5311, 949, 321, 751, 466, 264, 10888, 51724], "temperature": 0.0, "avg_logprob": -0.11953118642171225, "compression_ratio": 1.84037558685446, "no_speech_prob": 0.004918219055980444}, {"id": 156, "seek": 145008, "start": 1450.76, "end": 1457.6799999999998, "text": " and the benefits are of AI are numerous already today and there is you know even", "tokens": [50398, 293, 264, 5311, 366, 295, 7318, 366, 12546, 1217, 965, 293, 456, 307, 291, 458, 754, 50744], "temperature": 0.0, "avg_logprob": -0.17244004567464194, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006235672626644373}, {"id": 157, "seek": 145008, "start": 1457.6799999999998, "end": 1463.3999999999999, "text": " more coming in medicine particularly in imaging diagnosis assistant treatment", "tokens": [50744, 544, 1348, 294, 7195, 4098, 294, 25036, 15217, 10994, 5032, 51030], "temperature": 0.0, "avg_logprob": -0.17244004567464194, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006235672626644373}, {"id": 158, "seek": 145008, "start": 1463.3999999999999, "end": 1467.48, "text": " protocol drug design things like this very promising research transportation", "tokens": [51030, 10336, 4110, 1715, 721, 411, 341, 588, 20257, 2132, 11328, 51234], "temperature": 0.0, "avg_logprob": -0.17244004567464194, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006235672626644373}, {"id": 159, "seek": 145008, "start": 1467.48, "end": 1472.48, "text": " every car sold in the European Union today has to come with what's called a", "tokens": [51234, 633, 1032, 3718, 294, 264, 6473, 8133, 965, 575, 281, 808, 365, 437, 311, 1219, 257, 51484], "temperature": 0.0, "avg_logprob": -0.17244004567464194, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006235672626644373}, {"id": 160, "seek": 145008, "start": 1472.48, "end": 1476.9199999999998, "text": " automatic emergency braking system a system that will automatically stop the", "tokens": [51484, 12509, 7473, 32140, 1185, 257, 1185, 300, 486, 6772, 1590, 264, 51706], "temperature": 0.0, "avg_logprob": -0.17244004567464194, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.006235672626644373}, {"id": 161, "seek": 147692, "start": 1476.92, "end": 1482.48, "text": " car there is an obstacle in front of it and the driver does not react this", "tokens": [50364, 1032, 456, 307, 364, 23112, 294, 1868, 295, 309, 293, 264, 6787, 775, 406, 4515, 341, 50642], "temperature": 0.0, "avg_logprob": -0.20864520574870862, "compression_ratio": 1.5958549222797926, "no_speech_prob": 0.021564532071352005}, {"id": 162, "seek": 147692, "start": 1482.48, "end": 1487.96, "text": " saves lives it reduces frontal collision by 40% so AI saves lives and that uses", "tokens": [50642, 19155, 2909, 309, 18081, 34647, 24644, 538, 3356, 4, 370, 7318, 19155, 2909, 293, 300, 4960, 50916], "temperature": 0.0, "avg_logprob": -0.20864520574870862, "compression_ratio": 1.5958549222797926, "no_speech_prob": 0.021564532071352005}, {"id": 163, "seek": 147692, "start": 1487.96, "end": 1496.1200000000001, "text": " convolutional nets by the way and in all the systems that I know in fact Germany", "tokens": [50916, 45216, 304, 36170, 538, 264, 636, 293, 294, 439, 264, 3652, 300, 286, 458, 294, 1186, 7244, 51324], "temperature": 0.0, "avg_logprob": -0.20864520574870862, "compression_ratio": 1.5958549222797926, "no_speech_prob": 0.021564532071352005}, {"id": 164, "seek": 147692, "start": 1496.1200000000001, "end": 1503.92, "text": " was kind of a and and a very in particular was a pioneer in this some of", "tokens": [51324, 390, 733, 295, 257, 293, 293, 257, 588, 294, 1729, 390, 257, 37668, 294, 341, 512, 295, 51714], "temperature": 0.0, "avg_logprob": -0.20864520574870862, "compression_ratio": 1.5958549222797926, "no_speech_prob": 0.021564532071352005}, {"id": 165, "seek": 150392, "start": 1503.92, "end": 1509.0, "text": " the early systems of this type was the word developed by them events so driving", "tokens": [50364, 264, 2440, 3652, 295, 341, 2010, 390, 264, 1349, 4743, 538, 552, 3931, 370, 4840, 50618], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 166, "seek": 150392, "start": 1509.0, "end": 1512.52, "text": " assistance autonomous driving energy storage and management things like that", "tokens": [50618, 9683, 23797, 4840, 2281, 6725, 293, 4592, 721, 411, 300, 50794], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 167, "seek": 150392, "start": 1512.52, "end": 1516.16, "text": " environmental environmental monitoring and protection I'm going to say a few", "tokens": [50794, 8303, 8303, 11028, 293, 6334, 286, 478, 516, 281, 584, 257, 1326, 50976], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 168, "seek": 150392, "start": 1516.16, "end": 1520.04, "text": " words about this content information and management this is probably the biggest", "tokens": [50976, 2283, 466, 341, 2701, 1589, 293, 4592, 341, 307, 1391, 264, 3880, 51170], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 169, "seek": 150392, "start": 1520.04, "end": 1525.28, "text": " use of AI today and of course in industry manufacturing information systems", "tokens": [51170, 764, 295, 7318, 965, 293, 295, 1164, 294, 3518, 11096, 1589, 3652, 51432], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 170, "seek": 150392, "start": 1525.28, "end": 1529.72, "text": " quality control etc a lot of applications are expected also in things like", "tokens": [51432, 3125, 1969, 5183, 257, 688, 295, 5821, 366, 5176, 611, 294, 721, 411, 51654], "temperature": 0.0, "avg_logprob": -0.20573741739446466, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.027674442157149315}, {"id": 171, "seek": 152972, "start": 1529.72, "end": 1535.08, "text": " education for personalized education connecting people with each other with", "tokens": [50364, 3309, 337, 28415, 3309, 11015, 561, 365, 1184, 661, 365, 50632], "temperature": 0.0, "avg_logprob": -0.16217179731889206, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.009641836397349834}, {"id": 172, "seek": 152972, "start": 1535.08, "end": 1540.32, "text": " translation today presence augmented reality virtual reality and then", "tokens": [50632, 12853, 965, 6814, 36155, 4103, 6374, 4103, 293, 550, 50894], "temperature": 0.0, "avg_logprob": -0.16217179731889206, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.009641836397349834}, {"id": 173, "seek": 152972, "start": 1540.32, "end": 1545.16, "text": " enormous applications in science biology and genomics neuroscience physics", "tokens": [50894, 11322, 5821, 294, 3497, 14956, 293, 1049, 29884, 42762, 10649, 51136], "temperature": 0.0, "avg_logprob": -0.16217179731889206, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.009641836397349834}, {"id": 174, "seek": 152972, "start": 1545.16, "end": 1549.6000000000001, "text": " particularly physics of disordered systems complex systems very large-scale", "tokens": [51136, 4098, 10649, 295, 717, 765, 4073, 3652, 3997, 3652, 588, 2416, 12, 20033, 51358], "temperature": 0.0, "avg_logprob": -0.16217179731889206, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.009641836397349834}, {"id": 175, "seek": 152972, "start": 1549.6000000000001, "end": 1556.44, "text": " simulations chemistry material science very promising area for AI so this well", "tokens": [51358, 35138, 12558, 2527, 3497, 588, 20257, 1859, 337, 7318, 370, 341, 731, 51700], "temperature": 0.0, "avg_logprob": -0.16217179731889206, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.009641836397349834}, {"id": 176, "seek": 155644, "start": 1556.48, "end": 1559.8, "text": " really and of course you know we've been talking a lot about creation like", "tokens": [50366, 534, 293, 295, 1164, 291, 458, 321, 600, 668, 1417, 257, 688, 466, 8016, 411, 50532], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 177, "seek": 155644, "start": 1559.8, "end": 1566.48, "text": " creating art AI is essentially enabling a lot more people to be creative people", "tokens": [50532, 4084, 1523, 7318, 307, 4476, 23148, 257, 688, 544, 561, 281, 312, 5880, 561, 50866], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 178, "seek": 155644, "start": 1566.48, "end": 1570.44, "text": " who don't necessarily have the technique the underlying technique for", "tokens": [50866, 567, 500, 380, 4725, 362, 264, 6532, 264, 14217, 6532, 337, 51064], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 179, "seek": 155644, "start": 1570.44, "end": 1575.96, "text": " producing art so I will affect every aspect of human activity and let me give", "tokens": [51064, 10501, 1523, 370, 286, 486, 3345, 633, 4171, 295, 1952, 5191, 293, 718, 385, 976, 51340], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 180, "seek": 155644, "start": 1575.96, "end": 1581.1200000000001, "text": " you a couple examples so this is a video that was put together by my colleagues", "tokens": [51340, 291, 257, 1916, 5110, 370, 341, 307, 257, 960, 300, 390, 829, 1214, 538, 452, 7734, 51598], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 181, "seek": 155644, "start": 1581.1200000000001, "end": 1585.8400000000001, "text": " at meta a couple years ago this is already sort of aging if you want and we", "tokens": [51598, 412, 19616, 257, 1916, 924, 2057, 341, 307, 1217, 1333, 295, 19090, 498, 291, 528, 293, 321, 51834], "temperature": 0.0, "avg_logprob": -0.14254972981471642, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.007484835106879473}, {"id": 182, "seek": 158584, "start": 1585.84, "end": 1592.36, "text": " chose the capability of computer vision system as of about two years ago so we", "tokens": [50364, 5111, 264, 13759, 295, 3820, 5201, 1185, 382, 295, 466, 732, 924, 2057, 370, 321, 50690], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 183, "seek": 158584, "start": 1592.36, "end": 1596.8, "text": " can have systems that detect objects and put frames around them give them a name", "tokens": [50690, 393, 362, 3652, 300, 5531, 6565, 293, 829, 12083, 926, 552, 976, 552, 257, 1315, 50912], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 184, "seek": 158584, "start": 1596.8, "end": 1601.6, "text": " they can track human bodies and figure out in what what pose they are densely", "tokens": [50912, 436, 393, 2837, 1952, 7510, 293, 2573, 484, 294, 437, 437, 10774, 436, 366, 24505, 736, 51152], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 185, "seek": 158584, "start": 1601.6, "end": 1606.3999999999999, "text": " actually so that's actually very useful for all kinds of applications and more", "tokens": [51152, 767, 370, 300, 311, 767, 588, 4420, 337, 439, 3685, 295, 5821, 293, 544, 51392], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 186, "seek": 158584, "start": 1606.3999999999999, "end": 1610.52, "text": " interestingly we can have systems that perform what's called semantic", "tokens": [51392, 25873, 321, 393, 362, 3652, 300, 2042, 437, 311, 1219, 47982, 51598], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 187, "seek": 158584, "start": 1610.52, "end": 1615.36, "text": " segmentation which means isolating every object marking them with kind of a mask", "tokens": [51598, 9469, 399, 597, 1355, 48912, 633, 2657, 25482, 552, 365, 733, 295, 257, 6094, 51840], "temperature": 0.0, "avg_logprob": -0.11385462019178602, "compression_ratio": 1.82421875, "no_speech_prob": 0.0009969818638637662}, {"id": 188, "seek": 161536, "start": 1615.4799999999998, "end": 1620.04, "text": " and then giving them a name for a category and this works for a very", "tokens": [50370, 293, 550, 2902, 552, 257, 1315, 337, 257, 7719, 293, 341, 1985, 337, 257, 588, 50598], "temperature": 0.0, "avg_logprob": -0.1279440032111274, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.001542482408694923}, {"id": 189, "seek": 161536, "start": 1620.04, "end": 1624.8799999999999, "text": " fine-grained category for example the species of a bird or or plant or", "tokens": [50598, 2489, 12, 20735, 2001, 7719, 337, 1365, 264, 6172, 295, 257, 5255, 420, 420, 3709, 420, 50840], "temperature": 0.0, "avg_logprob": -0.1279440032111274, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.001542482408694923}, {"id": 190, "seek": 161536, "start": 1624.8799999999999, "end": 1629.1599999999999, "text": " something of that type so it's pretty amazing it's not like computer vision is", "tokens": [50840, 746, 295, 300, 2010, 370, 309, 311, 1238, 2243, 309, 311, 406, 411, 3820, 5201, 307, 51054], "temperature": 0.0, "avg_logprob": -0.1279440032111274, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.001542482408694923}, {"id": 191, "seek": 161536, "start": 1629.1599999999999, "end": 1634.08, "text": " completely solved in fact if it was solved we wouldn't have the large", "tokens": [51054, 2584, 13041, 294, 1186, 498, 309, 390, 13041, 321, 2759, 380, 362, 264, 2416, 51300], "temperature": 0.0, "avg_logprob": -0.1279440032111274, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.001542482408694923}, {"id": 192, "seek": 161536, "start": 1634.08, "end": 1639.76, "text": " conference that takes place in Paris next week called ICCV so there's still a", "tokens": [51300, 7586, 300, 2516, 1081, 294, 8380, 958, 1243, 1219, 286, 11717, 53, 370, 456, 311, 920, 257, 51584], "temperature": 0.0, "avg_logprob": -0.1279440032111274, "compression_ratio": 1.5844155844155845, "no_speech_prob": 0.001542482408694923}, {"id": 193, "seek": 163976, "start": 1639.8, "end": 1648.4, "text": " lot of work to do but but there's been a huge amount of advances there and a lot", "tokens": [50366, 688, 295, 589, 281, 360, 457, 457, 456, 311, 668, 257, 2603, 2372, 295, 25297, 456, 293, 257, 688, 50796], "temperature": 0.0, "avg_logprob": -0.16788950333228478, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.00616853591054678}, {"id": 194, "seek": 163976, "start": 1648.4, "end": 1656.92, "text": " of advances in AI but no advances in my slides for some reason okay my", "tokens": [50796, 295, 25297, 294, 7318, 457, 572, 25297, 294, 452, 9788, 337, 512, 1778, 1392, 452, 51222], "temperature": 0.0, "avg_logprob": -0.16788950333228478, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.00616853591054678}, {"id": 195, "seek": 163976, "start": 1656.92, "end": 1662.92, "text": " presentation refuses to advance hang on just one minute one second", "tokens": [51222, 5860, 33222, 281, 7295, 3967, 322, 445, 472, 3456, 472, 1150, 51522], "temperature": 0.0, "avg_logprob": -0.16788950333228478, "compression_ratio": 1.5797101449275361, "no_speech_prob": 0.00616853591054678}, {"id": 196, "seek": 166976, "start": 1670.76, "end": 1677.6, "text": " okay I mentioned medicine so certainly medical imaging is an area where a lot", "tokens": [50414, 1392, 286, 2835, 7195, 370, 3297, 4625, 25036, 307, 364, 1859, 689, 257, 688, 50756], "temperature": 0.0, "avg_logprob": -0.1538116709391276, "compression_ratio": 1.58, "no_speech_prob": 0.0014024265110492706}, {"id": 197, "seek": 166976, "start": 1677.6, "end": 1681.8, "text": " of work is going on there's too many to cite really this is some work by some of", "tokens": [50756, 295, 589, 307, 516, 322, 456, 311, 886, 867, 281, 37771, 534, 341, 307, 512, 589, 538, 512, 295, 50966], "temperature": 0.0, "avg_logprob": -0.1538116709391276, "compression_ratio": 1.58, "no_speech_prob": 0.0014024265110492706}, {"id": 198, "seek": 166976, "start": 1681.8, "end": 1689.24, "text": " my colleagues at NYU that use 3d image recognition not just 2d in some cases", "tokens": [50966, 452, 7734, 412, 42682, 300, 764, 805, 67, 3256, 11150, 406, 445, 568, 67, 294, 512, 3331, 51338], "temperature": 0.0, "avg_logprob": -0.1538116709391276, "compression_ratio": 1.58, "no_speech_prob": 0.0014024265110492706}, {"id": 199, "seek": 166976, "start": 1689.24, "end": 1694.56, "text": " this is actually 2d but that use various techniques to detect for example tumors", "tokens": [51338, 341, 307, 767, 568, 67, 457, 300, 764, 3683, 7512, 281, 5531, 337, 1365, 38466, 51604], "temperature": 0.0, "avg_logprob": -0.1538116709391276, "compression_ratio": 1.58, "no_speech_prob": 0.0014024265110492706}, {"id": 200, "seek": 169456, "start": 1694.6399999999999, "end": 1702.0, "text": " in mammograms or particular things in MRI and other types of images and", "tokens": [50368, 294, 19033, 12820, 82, 420, 1729, 721, 294, 32812, 293, 661, 3467, 295, 5267, 293, 50736], "temperature": 0.0, "avg_logprob": -0.23294090362916509, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00771754514425993}, {"id": 201, "seek": 169456, "start": 1702.0, "end": 1707.36, "text": " almost a lot of progress there some product project that took place a few", "tokens": [50736, 1920, 257, 688, 295, 4205, 456, 512, 1674, 1716, 300, 1890, 1081, 257, 1326, 51004], "temperature": 0.0, "avg_logprob": -0.23294090362916509, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00771754514425993}, {"id": 202, "seek": 169456, "start": 1707.36, "end": 1711.24, "text": " years ago which was a collaboration between the NYU radiology department and", "tokens": [51004, 924, 2057, 597, 390, 257, 9363, 1296, 264, 42682, 16335, 1793, 5882, 293, 51198], "temperature": 0.0, "avg_logprob": -0.23294090362916509, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00771754514425993}, {"id": 203, "seek": 169456, "start": 1711.24, "end": 1717.08, "text": " people at fair Meta's fundamental research lab which essentially allows to", "tokens": [51198, 561, 412, 3143, 6377, 64, 311, 8088, 2132, 2715, 597, 4476, 4045, 281, 51490], "temperature": 0.0, "avg_logprob": -0.23294090362916509, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00771754514425993}, {"id": 204, "seek": 169456, "start": 1717.08, "end": 1721.28, "text": " accelerate the data collection for an MRI by a factor of 4 without degrading the", "tokens": [51490, 21341, 264, 1412, 5765, 337, 364, 32812, 538, 257, 5952, 295, 1017, 1553, 24740, 278, 264, 51700], "temperature": 0.0, "avg_logprob": -0.23294090362916509, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00771754514425993}, {"id": 205, "seek": 172128, "start": 1721.28, "end": 1726.08, "text": " image quality so instead of having to lie down in a MRI machine for 40 minutes", "tokens": [50364, 3256, 3125, 370, 2602, 295, 1419, 281, 4544, 760, 294, 257, 32812, 3479, 337, 3356, 2077, 50604], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 206, "seek": 172128, "start": 1726.08, "end": 1729.32, "text": " or something you can reduce this to 10 minutes and have the same quality of", "tokens": [50604, 420, 746, 291, 393, 5407, 341, 281, 1266, 2077, 293, 362, 264, 912, 3125, 295, 50766], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 207, "seek": 172128, "start": 1729.32, "end": 1734.6399999999999, "text": " images and that's thanks to deep learning essentially a lot of applications in", "tokens": [50766, 5267, 293, 300, 311, 3231, 281, 2452, 2539, 4476, 257, 688, 295, 5821, 294, 51032], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 208, "seek": 172128, "start": 1734.6399999999999, "end": 1741.52, "text": " science what's interesting today is that the favorite model that neuroscientists", "tokens": [51032, 3497, 437, 311, 1880, 965, 307, 300, 264, 2954, 2316, 300, 28813, 5412, 1751, 51376], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 209, "seek": 172128, "start": 1741.52, "end": 1746.48, "text": " use to explain how the brain works use artificial neural nets so the best", "tokens": [51376, 764, 281, 2903, 577, 264, 3567, 1985, 764, 11677, 18161, 36170, 370, 264, 1151, 51624], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 210, "seek": 172128, "start": 1746.48, "end": 1750.6399999999999, "text": " explanation for what we observe using functional MRI data in the visual", "tokens": [51624, 10835, 337, 437, 321, 11441, 1228, 11745, 32812, 1412, 294, 264, 5056, 51832], "temperature": 0.0, "avg_logprob": -0.12143762183911873, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.002915934193879366}, {"id": 211, "seek": 175064, "start": 1750.72, "end": 1755.2800000000002, "text": " cortex of humans and animals are actually models that are essentially", "tokens": [50368, 33312, 295, 6255, 293, 4882, 366, 767, 5245, 300, 366, 4476, 50596], "temperature": 0.0, "avg_logprob": -0.200448613417776, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.006421028636395931}, {"id": 212, "seek": 175064, "start": 1755.2800000000002, "end": 1762.6000000000001, "text": " convolutional net models and that's kind of a closing the circle because the", "tokens": [50596, 45216, 304, 2533, 5245, 293, 300, 311, 733, 295, 257, 10377, 264, 6329, 570, 264, 50962], "temperature": 0.0, "avg_logprob": -0.200448613417776, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.006421028636395931}, {"id": 213, "seek": 175064, "start": 1762.6000000000001, "end": 1766.5600000000002, "text": " architectural convolutional net is actually inspired by the architecture of", "tokens": [50962, 26621, 45216, 304, 2533, 307, 767, 7547, 538, 264, 9482, 295, 51160], "temperature": 0.0, "avg_logprob": -0.200448613417776, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.006421028636395931}, {"id": 214, "seek": 175064, "start": 1766.5600000000002, "end": 1771.8000000000002, "text": " the visual cortex classic work in neuroscience from the 1960s the similar", "tokens": [51160, 264, 5056, 33312, 7230, 589, 294, 42762, 490, 264, 16157, 82, 264, 2531, 51422], "temperature": 0.0, "avg_logprob": -0.200448613417776, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.006421028636395931}, {"id": 215, "seek": 175064, "start": 1771.8000000000002, "end": 1780.2800000000002, "text": " work also in language understanding this is a recent paper in science by some", "tokens": [51422, 589, 611, 294, 2856, 3701, 341, 307, 257, 5162, 3035, 294, 3497, 538, 512, 51846], "temperature": 0.0, "avg_logprob": -0.200448613417776, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.006421028636395931}, {"id": 216, "seek": 178028, "start": 1780.28, "end": 1785.36, "text": " colleagues from from from it actually and they try to figure out if the", "tokens": [50364, 7734, 490, 490, 490, 309, 767, 293, 436, 853, 281, 2573, 484, 498, 264, 50618], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 217, "seek": 178028, "start": 1785.36, "end": 1789.48, "text": " current large language models that everybody is playing with explain the", "tokens": [50618, 2190, 2416, 2856, 5245, 300, 2201, 307, 2433, 365, 2903, 264, 50824], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 218, "seek": 178028, "start": 1789.48, "end": 1794.24, "text": " what we observe in the brain when people are asked to kind of remember or", "tokens": [50824, 437, 321, 11441, 294, 264, 3567, 562, 561, 366, 2351, 281, 733, 295, 1604, 420, 51062], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 219, "seek": 178028, "start": 1794.24, "end": 1799.36, "text": " understand a story and the answer is sort of but not really it doesn't work nearly", "tokens": [51062, 1223, 257, 1657, 293, 264, 1867, 307, 1333, 295, 457, 406, 534, 309, 1177, 380, 589, 6217, 51318], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 220, "seek": 178028, "start": 1799.36, "end": 1803.68, "text": " as well as a convolutional net models for vision so what that means is that", "tokens": [51318, 382, 731, 382, 257, 45216, 304, 2533, 5245, 337, 5201, 370, 437, 300, 1355, 307, 300, 51534], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 221, "seek": 178028, "start": 1803.68, "end": 1808.68, "text": " we're missing something that those models probably are not sufficient to", "tokens": [51534, 321, 434, 5361, 746, 300, 729, 5245, 1391, 366, 406, 11563, 281, 51784], "temperature": 0.0, "avg_logprob": -0.1656484700212575, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0038091326132416725}, {"id": 222, "seek": 180868, "start": 1808.68, "end": 1814.04, "text": " explain what the brain does when when we understand language I mentioned some", "tokens": [50364, 2903, 437, 264, 3567, 775, 562, 562, 321, 1223, 2856, 286, 2835, 512, 50632], "temperature": 0.0, "avg_logprob": -0.16522725020782858, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.00550652714446187}, {"id": 223, "seek": 180868, "start": 1814.04, "end": 1818.48, "text": " applications in science in particle physics in particular high energy physics", "tokens": [50632, 5821, 294, 3497, 294, 12359, 10649, 294, 1729, 1090, 2281, 10649, 50854], "temperature": 0.0, "avg_logprob": -0.16522725020782858, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.00550652714446187}, {"id": 224, "seek": 180868, "start": 1818.48, "end": 1824.52, "text": " to kind of make models of particle collisions and things of that type image", "tokens": [50854, 281, 733, 295, 652, 5245, 295, 12359, 46537, 293, 721, 295, 300, 2010, 3256, 51156], "temperature": 0.0, "avg_logprob": -0.16522725020782858, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.00550652714446187}, {"id": 225, "seek": 180868, "start": 1824.52, "end": 1830.28, "text": " processing to discover exoplanets some estimate says that about 12 percent of", "tokens": [51156, 9007, 281, 4411, 454, 49768, 1385, 512, 12539, 1619, 300, 466, 2272, 3043, 295, 51444], "temperature": 0.0, "avg_logprob": -0.16522725020782858, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.00550652714446187}, {"id": 226, "seek": 180868, "start": 1830.28, "end": 1836.0, "text": " all physics papers today actually mention AI as a tool that he used which is", "tokens": [51444, 439, 10649, 10577, 965, 767, 2152, 7318, 382, 257, 2290, 300, 415, 1143, 597, 307, 51730], "temperature": 0.0, "avg_logprob": -0.16522725020782858, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.00550652714446187}, {"id": 227, "seek": 183600, "start": 1836.04, "end": 1842.56, "text": " astonishing in just a relatively short time and in the large-scale simulation", "tokens": [50366, 35264, 294, 445, 257, 7226, 2099, 565, 293, 294, 264, 2416, 12, 20033, 16575, 50692], "temperature": 0.0, "avg_logprob": -0.1748309076568227, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.001719420775771141}, {"id": 228, "seek": 183600, "start": 1842.56, "end": 1846.08, "text": " sort of universe scale simulation that could sort of validate or invalidate", "tokens": [50692, 1333, 295, 6445, 4373, 16575, 300, 727, 1333, 295, 29562, 420, 34702, 473, 50868], "temperature": 0.0, "avg_logprob": -0.1748309076568227, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.001719420775771141}, {"id": 229, "seek": 183600, "start": 1846.08, "end": 1851.76, "text": " certain theories about dark matter and things I guess so very fascinating work", "tokens": [50868, 1629, 13667, 466, 2877, 1871, 293, 721, 286, 2041, 370, 588, 10343, 589, 51152], "temperature": 0.0, "avg_logprob": -0.1748309076568227, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.001719420775771141}, {"id": 230, "seek": 183600, "start": 1851.76, "end": 1857.52, "text": " and applications this is a very interesting project that was started by", "tokens": [51152, 293, 5821, 341, 307, 257, 588, 1880, 1716, 300, 390, 1409, 538, 51440], "temperature": 0.0, "avg_logprob": -0.1748309076568227, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.001719420775771141}, {"id": 231, "seek": 183600, "start": 1857.52, "end": 1863.28, "text": " some of my colleagues at fair by Larry Zittnick in particular called the open", "tokens": [51440, 512, 295, 452, 7734, 412, 3143, 538, 18145, 1176, 593, 77, 618, 294, 1729, 1219, 264, 1269, 51728], "temperature": 0.0, "avg_logprob": -0.1748309076568227, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.001719420775771141}, {"id": 232, "seek": 186328, "start": 1863.28, "end": 1868.36, "text": " catalyst project and you can actually participate if you want the website is", "tokens": [50364, 23868, 1716, 293, 291, 393, 767, 8197, 498, 291, 528, 264, 3144, 307, 50618], "temperature": 0.0, "avg_logprob": -0.1419649258465834, "compression_ratio": 1.7836257309941521, "no_speech_prob": 0.0032637636177241802}, {"id": 233, "seek": 186328, "start": 1868.36, "end": 1878.84, "text": " open-catalyst.org and and that project the idea of that project is that we", "tokens": [50618, 1269, 12, 18035, 19530, 13, 4646, 293, 293, 300, 1716, 264, 1558, 295, 300, 1716, 307, 300, 321, 51142], "temperature": 0.0, "avg_logprob": -0.1419649258465834, "compression_ratio": 1.7836257309941521, "no_speech_prob": 0.0032637636177241802}, {"id": 234, "seek": 186328, "start": 1878.84, "end": 1883.8, "text": " could solve climate change if we had a good efficient scalable way of storing", "tokens": [51142, 727, 5039, 5659, 1319, 498, 321, 632, 257, 665, 7148, 38481, 636, 295, 26085, 51390], "temperature": 0.0, "avg_logprob": -0.1419649258465834, "compression_ratio": 1.7836257309941521, "no_speech_prob": 0.0032637636177241802}, {"id": 235, "seek": 186328, "start": 1883.8, "end": 1890.3999999999999, "text": " energy if we had a good way of storing energy we could cover a small desert", "tokens": [51390, 2281, 498, 321, 632, 257, 665, 636, 295, 26085, 2281, 321, 727, 2060, 257, 1359, 11029, 51720], "temperature": 0.0, "avg_logprob": -0.1419649258465834, "compression_ratio": 1.7836257309941521, "no_speech_prob": 0.0032637636177241802}, {"id": 236, "seek": 189040, "start": 1890.68, "end": 1896.88, "text": " with solar panels and produce enough energy to power Europe or the entire", "tokens": [50378, 365, 7936, 13419, 293, 5258, 1547, 2281, 281, 1347, 3315, 420, 264, 2302, 50688], "temperature": 0.0, "avg_logprob": -0.14792161592295472, "compression_ratio": 1.609375, "no_speech_prob": 0.007405387237668037}, {"id": 237, "seek": 189040, "start": 1896.88, "end": 1903.7, "text": " planet the problem is you have to have a way of storing energy which is why", "tokens": [50688, 5054, 264, 1154, 307, 291, 362, 281, 362, 257, 636, 295, 26085, 2281, 597, 307, 983, 51029], "temperature": 0.0, "avg_logprob": -0.14792161592295472, "compression_ratio": 1.609375, "no_speech_prob": 0.007405387237668037}, {"id": 238, "seek": 189040, "start": 1903.7, "end": 1910.76, "text": " renewables today despite the decisions of the German government to go all out on", "tokens": [51029, 10162, 2965, 965, 7228, 264, 5327, 295, 264, 6521, 2463, 281, 352, 439, 484, 322, 51382], "temperature": 0.0, "avg_logprob": -0.14792161592295472, "compression_ratio": 1.609375, "no_speech_prob": 0.007405387237668037}, {"id": 239, "seek": 189040, "start": 1910.76, "end": 1917.8400000000001, "text": " it renewables are not drivable you can't control whenever there is wind or sun", "tokens": [51382, 309, 10162, 2965, 366, 406, 1630, 17915, 291, 393, 380, 1969, 5699, 456, 307, 2468, 420, 3295, 51736], "temperature": 0.0, "avg_logprob": -0.14792161592295472, "compression_ratio": 1.609375, "no_speech_prob": 0.007405387237668037}, {"id": 240, "seek": 191784, "start": 1918.12, "end": 1923.9599999999998, "text": " and so you need another source of energy when there is no no sun or or no no", "tokens": [50378, 293, 370, 291, 643, 1071, 4009, 295, 2281, 562, 456, 307, 572, 572, 3295, 420, 420, 572, 572, 50670], "temperature": 0.0, "avg_logprob": -0.15116669820702594, "compression_ratio": 1.9303482587064678, "no_speech_prob": 0.005437956657260656}, {"id": 241, "seek": 191784, "start": 1923.9599999999998, "end": 1928.8, "text": " wind and and for that you need to be able to store energy and ship it wherever", "tokens": [50670, 2468, 293, 293, 337, 300, 291, 643, 281, 312, 1075, 281, 3531, 2281, 293, 5374, 309, 8660, 50912], "temperature": 0.0, "avg_logprob": -0.15116669820702594, "compression_ratio": 1.9303482587064678, "no_speech_prob": 0.005437956657260656}, {"id": 242, "seek": 191784, "start": 1928.8, "end": 1932.12, "text": " it's needed the best way to store energy is in the form of hydrogen or maybe", "tokens": [50912, 309, 311, 2978, 264, 1151, 636, 281, 3531, 2281, 307, 294, 264, 1254, 295, 12697, 420, 1310, 51078], "temperature": 0.0, "avg_logprob": -0.15116669820702594, "compression_ratio": 1.9303482587064678, "no_speech_prob": 0.005437956657260656}, {"id": 243, "seek": 191784, "start": 1932.12, "end": 1937.08, "text": " methane and the best way to do this is by separating hydrogen from oxygen from", "tokens": [51078, 32521, 293, 264, 1151, 636, 281, 360, 341, 307, 538, 29279, 12697, 490, 9169, 490, 51326], "temperature": 0.0, "avg_logprob": -0.15116669820702594, "compression_ratio": 1.9303482587064678, "no_speech_prob": 0.005437956657260656}, {"id": 244, "seek": 191784, "start": 1937.08, "end": 1940.9599999999998, "text": " water right so take some water put two electrodes and then separate hydrogen", "tokens": [51326, 1281, 558, 370, 747, 512, 1281, 829, 732, 47824, 293, 550, 4994, 12697, 51520], "temperature": 0.0, "avg_logprob": -0.15116669820702594, "compression_ratio": 1.9303482587064678, "no_speech_prob": 0.005437956657260656}, {"id": 245, "seek": 194096, "start": 1940.96, "end": 1948.8400000000001, "text": " from oxygen problem with this is that it's either scalable if you use catalyst", "tokens": [50364, 490, 9169, 1154, 365, 341, 307, 300, 309, 311, 2139, 38481, 498, 291, 764, 23868, 50758], "temperature": 0.0, "avg_logprob": -0.1992162068684896, "compression_ratio": 1.8047337278106508, "no_speech_prob": 0.005963439121842384}, {"id": 246, "seek": 194096, "start": 1948.8400000000001, "end": 1956.3600000000001, "text": " to do this like platinum sorry it's either efficient if you use catalyst like", "tokens": [50758, 281, 360, 341, 411, 37475, 2597, 309, 311, 2139, 7148, 498, 291, 764, 23868, 411, 51134], "temperature": 0.0, "avg_logprob": -0.1992162068684896, "compression_ratio": 1.8047337278106508, "no_speech_prob": 0.005963439121842384}, {"id": 247, "seek": 194096, "start": 1956.3600000000001, "end": 1960.8, "text": " platinum or it's scalable but not efficient and so the big question is", "tokens": [51134, 37475, 420, 309, 311, 38481, 457, 406, 7148, 293, 370, 264, 955, 1168, 307, 51356], "temperature": 0.0, "avg_logprob": -0.1992162068684896, "compression_ratio": 1.8047337278106508, "no_speech_prob": 0.005963439121842384}, {"id": 248, "seek": 194096, "start": 1960.8, "end": 1966.64, "text": " could we design compounds new catalyst that would facilitate this reaction so", "tokens": [51356, 727, 321, 1715, 21810, 777, 23868, 300, 576, 20207, 341, 5480, 370, 51648], "temperature": 0.0, "avg_logprob": -0.1992162068684896, "compression_ratio": 1.8047337278106508, "no_speech_prob": 0.005963439121842384}, {"id": 249, "seek": 196664, "start": 1966.64, "end": 1971.44, "text": " that is efficient but does not require exotic materials like like platinum so", "tokens": [50364, 300, 307, 7148, 457, 775, 406, 3651, 27063, 5319, 411, 411, 37475, 370, 50604], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 250, "seek": 196664, "start": 1971.44, "end": 1976.24, "text": " that is scalable and the idea there is that you do a lot of chemical", "tokens": [50604, 300, 307, 38481, 293, 264, 1558, 456, 307, 300, 291, 360, 257, 688, 295, 7313, 50844], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 251, "seek": 196664, "start": 1976.24, "end": 1982.0800000000002, "text": " simulation that's called DFT simulation of various of water on two various", "tokens": [50844, 16575, 300, 311, 1219, 413, 25469, 16575, 295, 3683, 295, 1281, 322, 732, 3683, 51136], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 252, "seek": 196664, "start": 1982.0800000000002, "end": 1986.5200000000002, "text": " compounds and then you generate that data using simulation and also using", "tokens": [51136, 21810, 293, 550, 291, 8460, 300, 1412, 1228, 16575, 293, 611, 1228, 51358], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 253, "seek": 196664, "start": 1986.5200000000002, "end": 1990.3200000000002, "text": " experiments you put that data you make it available and then you ask people can", "tokens": [51358, 12050, 291, 829, 300, 1412, 291, 652, 309, 2435, 293, 550, 291, 1029, 561, 393, 51548], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 254, "seek": 196664, "start": 1990.3200000000002, "end": 1994.24, "text": " you train machine learning system to figure out what the underlying rule is", "tokens": [51548, 291, 3847, 3479, 2539, 1185, 281, 2573, 484, 437, 264, 14217, 4978, 307, 51744], "temperature": 0.0, "avg_logprob": -0.15488192439079285, "compression_ratio": 1.804, "no_speech_prob": 0.0017167950281873345}, {"id": 255, "seek": 199424, "start": 1994.24, "end": 1999.96, "text": " so that we can use it to design new materials that might have the same", "tokens": [50364, 370, 300, 321, 393, 764, 309, 281, 1715, 777, 5319, 300, 1062, 362, 264, 912, 50650], "temperature": 0.0, "avg_logprob": -0.1423999451018952, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.00305462209507823}, {"id": 256, "seek": 199424, "start": 1999.96, "end": 2006.52, "text": " effect but be cheap so fascinating program it may not work but it's worth", "tokens": [50650, 1802, 457, 312, 7084, 370, 10343, 1461, 309, 815, 406, 589, 457, 309, 311, 3163, 50978], "temperature": 0.0, "avg_logprob": -0.1423999451018952, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.00305462209507823}, {"id": 257, "seek": 199424, "start": 2006.52, "end": 2013.16, "text": " a shot okay now what's important to realize is that the progress we've seen", "tokens": [50978, 257, 3347, 1392, 586, 437, 311, 1021, 281, 4325, 307, 300, 264, 4205, 321, 600, 1612, 51310], "temperature": 0.0, "avg_logprob": -0.1423999451018952, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.00305462209507823}, {"id": 258, "seek": 199424, "start": 2013.16, "end": 2016.72, "text": " over the last few years in AI and machine learning are due to a set of", "tokens": [51310, 670, 264, 1036, 1326, 924, 294, 7318, 293, 3479, 2539, 366, 3462, 281, 257, 992, 295, 51488], "temperature": 0.0, "avg_logprob": -0.1423999451018952, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.00305462209507823}, {"id": 259, "seek": 199424, "start": 2016.72, "end": 2020.72, "text": " techniques that we call self-supervised running which I'm sure many of you here", "tokens": [51488, 7512, 300, 321, 818, 2698, 12, 48172, 24420, 2614, 597, 286, 478, 988, 867, 295, 291, 510, 51688], "temperature": 0.0, "avg_logprob": -0.1423999451018952, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.00305462209507823}, {"id": 260, "seek": 202072, "start": 2020.72, "end": 2027.16, "text": " in the room have heard about and essentially self-supervised running", "tokens": [50364, 294, 264, 1808, 362, 2198, 466, 293, 4476, 2698, 12, 48172, 24420, 2614, 50686], "temperature": 0.0, "avg_logprob": -0.17647050321102142, "compression_ratio": 1.6378378378378378, "no_speech_prob": 0.0029820178169757128}, {"id": 261, "seek": 202072, "start": 2027.16, "end": 2032.88, "text": " would be a set of techniques that allows a system to be trained to represent the", "tokens": [50686, 576, 312, 257, 992, 295, 7512, 300, 4045, 257, 1185, 281, 312, 8895, 281, 2906, 264, 50972], "temperature": 0.0, "avg_logprob": -0.17647050321102142, "compression_ratio": 1.6378378378378378, "no_speech_prob": 0.0029820178169757128}, {"id": 262, "seek": 202072, "start": 2032.88, "end": 2041.28, "text": " data the world without requiring labeled data okay without requiring sort of", "tokens": [50972, 1412, 264, 1002, 1553, 24165, 21335, 1412, 1392, 1553, 24165, 1333, 295, 51392], "temperature": 0.0, "avg_logprob": -0.17647050321102142, "compression_ratio": 1.6378378378378378, "no_speech_prob": 0.0029820178169757128}, {"id": 263, "seek": 202072, "start": 2041.28, "end": 2049.96, "text": " manual human intervention to produce the data so perhaps the best success of", "tokens": [51392, 9688, 1952, 13176, 281, 5258, 264, 1412, 370, 4317, 264, 1151, 2245, 295, 51826], "temperature": 0.0, "avg_logprob": -0.17647050321102142, "compression_ratio": 1.6378378378378378, "no_speech_prob": 0.0029820178169757128}, {"id": 264, "seek": 204996, "start": 2049.96, "end": 2055.68, "text": " this idea which I've been advocating for a long time is in the context of natural", "tokens": [50364, 341, 1558, 597, 286, 600, 668, 32050, 337, 257, 938, 565, 307, 294, 264, 4319, 295, 3303, 50650], "temperature": 0.0, "avg_logprob": -0.15222546394835126, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.004320337902754545}, {"id": 265, "seek": 204996, "start": 2055.68, "end": 2061.96, "text": " language understanding so the way all NLP systems are trained today whether", "tokens": [50650, 2856, 3701, 370, 264, 636, 439, 426, 45196, 3652, 366, 8895, 965, 1968, 50964], "temperature": 0.0, "avg_logprob": -0.15222546394835126, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.004320337902754545}, {"id": 266, "seek": 204996, "start": 2061.96, "end": 2066.8, "text": " there are LLMs of the types that we play with or others is the following you", "tokens": [50964, 456, 366, 441, 43, 26386, 295, 264, 3467, 300, 321, 862, 365, 420, 2357, 307, 264, 3480, 291, 51206], "temperature": 0.0, "avg_logprob": -0.15222546394835126, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.004320337902754545}, {"id": 267, "seek": 204996, "start": 2066.8, "end": 2072.36, "text": " take a piece of text a sequence of words and you remove some of the words you", "tokens": [51206, 747, 257, 2522, 295, 2487, 257, 8310, 295, 2283, 293, 291, 4159, 512, 295, 264, 2283, 291, 51484], "temperature": 0.0, "avg_logprob": -0.15222546394835126, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.004320337902754545}, {"id": 268, "seek": 204996, "start": 2072.36, "end": 2077.04, "text": " you mask you mask them you blank them out you replace them by a blank marker okay", "tokens": [51484, 291, 6094, 291, 6094, 552, 291, 8247, 552, 484, 291, 7406, 552, 538, 257, 8247, 15247, 1392, 51718], "temperature": 0.0, "avg_logprob": -0.15222546394835126, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.004320337902754545}, {"id": 269, "seek": 207704, "start": 2077.08, "end": 2081.72, "text": " you corrupt essentially the input and you put it at the input of a large neural", "tokens": [50366, 291, 17366, 4476, 264, 4846, 293, 291, 829, 309, 412, 264, 4846, 295, 257, 2416, 18161, 50598], "temperature": 0.0, "avg_logprob": -0.1624296188354492, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.003743313020095229}, {"id": 270, "seek": 207704, "start": 2081.72, "end": 2085.32, "text": " net you train this very large neural net usually usually a transformer", "tokens": [50598, 2533, 291, 3847, 341, 588, 2416, 18161, 2533, 2673, 2673, 257, 31782, 50778], "temperature": 0.0, "avg_logprob": -0.1624296188354492, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.003743313020095229}, {"id": 271, "seek": 207704, "start": 2085.32, "end": 2091.24, "text": " architecture to predict the words that are missing in the process of doing so", "tokens": [50778, 9482, 281, 6069, 264, 2283, 300, 366, 5361, 294, 264, 1399, 295, 884, 370, 51074], "temperature": 0.0, "avg_logprob": -0.1624296188354492, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.003743313020095229}, {"id": 272, "seek": 207704, "start": 2091.24, "end": 2096.92, "text": " the system has to extract representations of the text that contain the", "tokens": [51074, 264, 1185, 575, 281, 8947, 33358, 295, 264, 2487, 300, 5304, 264, 51358], "temperature": 0.0, "avg_logprob": -0.1624296188354492, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.003743313020095229}, {"id": 273, "seek": 207704, "start": 2096.92, "end": 2103.32, "text": " semantics the syntax the you know grammar everything I sort of lied slightly", "tokens": [51358, 4361, 45298, 264, 28431, 264, 291, 458, 22317, 1203, 286, 1333, 295, 20101, 4748, 51678], "temperature": 0.0, "avg_logprob": -0.1624296188354492, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.003743313020095229}, {"id": 274, "seek": 210332, "start": 2103.48, "end": 2108.1200000000003, "text": " here these are not words that are input they are what's called tokens which are", "tokens": [50372, 510, 613, 366, 406, 2283, 300, 366, 4846, 436, 366, 437, 311, 1219, 22667, 597, 366, 50604], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 275, "seek": 210332, "start": 2108.1200000000003, "end": 2113.7200000000003, "text": " essentially subword units so in most languages words have a prefix and a", "tokens": [50604, 4476, 1422, 7462, 6815, 370, 294, 881, 8650, 2283, 362, 257, 46969, 293, 257, 50884], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 276, "seek": 210332, "start": 2113.7200000000003, "end": 2118.4, "text": " root and a suffix and you need to kind of separate those for those systems to", "tokens": [50884, 5593, 293, 257, 3889, 970, 293, 291, 643, 281, 733, 295, 4994, 729, 337, 729, 3652, 281, 51118], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 277, "seek": 210332, "start": 2118.4, "end": 2122.2000000000003, "text": " work properly otherwise your dictionary of words would be gigantic and then in", "tokens": [51118, 589, 6108, 5911, 428, 25890, 295, 2283, 576, 312, 26800, 293, 550, 294, 51308], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 278, "seek": 210332, "start": 2122.2000000000003, "end": 2125.1600000000003, "text": " German you have to do it because you can have words that are long like this", "tokens": [51308, 6521, 291, 362, 281, 360, 309, 570, 291, 393, 362, 2283, 300, 366, 938, 411, 341, 51456], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 279, "seek": 210332, "start": 2125.1600000000003, "end": 2130.6000000000004, "text": " they are you know by so so there is no choice you have to break up words into", "tokens": [51456, 436, 366, 291, 458, 538, 370, 370, 456, 307, 572, 3922, 291, 362, 281, 1821, 493, 2283, 666, 51728], "temperature": 0.0, "avg_logprob": -0.1368724858319318, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.012679475359618664}, {"id": 280, "seek": 213060, "start": 2130.6, "end": 2137.0, "text": " subword units you know in tokens and so you train that you train the system and", "tokens": [50364, 1422, 7462, 6815, 291, 458, 294, 22667, 293, 370, 291, 3847, 300, 291, 3847, 264, 1185, 293, 50684], "temperature": 0.0, "avg_logprob": -0.16411202004615297, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.004451905842870474}, {"id": 281, "seek": 213060, "start": 2137.0, "end": 2143.3199999999997, "text": " and this is the so-called BERT model if you want or idea and that's me", "tokens": [50684, 293, 341, 307, 264, 370, 12, 11880, 363, 31479, 2316, 498, 291, 528, 420, 1558, 293, 300, 311, 385, 51000], "temperature": 0.0, "avg_logprob": -0.16411202004615297, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.004451905842870474}, {"id": 282, "seek": 213060, "start": 2143.3199999999997, "end": 2146.7999999999997, "text": " incredibly successful it's completely self-supervised you don't need any other", "tokens": [51000, 6252, 4406, 309, 311, 2584, 2698, 12, 48172, 24420, 291, 500, 380, 643, 604, 661, 51174], "temperature": 0.0, "avg_logprob": -0.16411202004615297, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.004451905842870474}, {"id": 283, "seek": 213060, "start": 2146.7999999999997, "end": 2151.7599999999998, "text": " data than the text and once you've pre-trained that system you can use the", "tokens": [51174, 1412, 813, 264, 2487, 293, 1564, 291, 600, 659, 12, 17227, 2001, 300, 1185, 291, 393, 764, 264, 51422], "temperature": 0.0, "avg_logprob": -0.16411202004615297, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.004451905842870474}, {"id": 284, "seek": 213060, "start": 2151.7599999999998, "end": 2157.68, "text": " internal representation produced by the system as input to a subsequent task a", "tokens": [51422, 6920, 10290, 7126, 538, 264, 1185, 382, 4846, 281, 257, 19962, 5633, 257, 51718], "temperature": 0.0, "avg_logprob": -0.16411202004615297, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.004451905842870474}, {"id": 285, "seek": 215768, "start": 2157.68, "end": 2162.3999999999996, "text": " downstream task like let's say translation hate speech detection you", "tokens": [50364, 30621, 5633, 411, 718, 311, 584, 12853, 4700, 6218, 17784, 291, 50600], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 286, "seek": 215768, "start": 2162.3999999999996, "end": 2166.2, "text": " know summarization whatever so that's the general idea of self-supervised", "tokens": [50600, 458, 14611, 2144, 2035, 370, 300, 311, 264, 2674, 1558, 295, 2698, 12, 48172, 24420, 50790], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 287, "seek": 215768, "start": 2166.2, "end": 2170.8799999999997, "text": " running fill in the blanks have a big piece of data corrupt it in some way", "tokens": [50790, 2614, 2836, 294, 264, 8247, 82, 362, 257, 955, 2522, 295, 1412, 17366, 309, 294, 512, 636, 51024], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 288, "seek": 215768, "start": 2170.8799999999997, "end": 2176.12, "text": " and then train some big neural net to fill in the blanks or or recover the", "tokens": [51024, 293, 550, 3847, 512, 955, 18161, 2533, 281, 2836, 294, 264, 8247, 82, 420, 420, 8114, 264, 51286], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 289, "seek": 215768, "start": 2176.12, "end": 2181.2, "text": " original data a particularly stunning example of this which I'm not going to", "tokens": [51286, 3380, 1412, 257, 4098, 18550, 1365, 295, 341, 597, 286, 478, 406, 516, 281, 51540], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 290, "seek": 215768, "start": 2181.2, "end": 2187.2, "text": " go into the technical details of but I will later is a system they came out of", "tokens": [51540, 352, 666, 264, 6191, 4365, 295, 457, 286, 486, 1780, 307, 257, 1185, 436, 1361, 484, 295, 51840], "temperature": 0.0, "avg_logprob": -0.15685975211007255, "compression_ratio": 1.6905660377358491, "no_speech_prob": 0.004387554246932268}, {"id": 291, "seek": 218720, "start": 2187.24, "end": 2192.3599999999997, "text": " my colleagues that in Paris that fair Paris called Dino v2 you can think of it", "tokens": [50366, 452, 7734, 300, 294, 8380, 300, 3143, 8380, 1219, 413, 2982, 371, 17, 291, 393, 519, 295, 309, 50622], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 292, "seek": 218720, "start": 2192.3599999999997, "end": 2196.16, "text": " as a foundation model for vision so it's a system that is trained to extract", "tokens": [50622, 382, 257, 7030, 2316, 337, 5201, 370, 309, 311, 257, 1185, 300, 307, 8895, 281, 8947, 50812], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 293, "seek": 218720, "start": 2196.16, "end": 2199.96, "text": " features from images such that those features can be used for anything you", "tokens": [50812, 4122, 490, 5267, 1270, 300, 729, 4122, 393, 312, 1143, 337, 1340, 291, 51002], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 294, "seek": 218720, "start": 2199.96, "end": 2203.96, "text": " want whether it's classification fine-grained classification depth", "tokens": [51002, 528, 1968, 309, 311, 21538, 2489, 12, 20735, 2001, 21538, 7161, 51202], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 295, "seek": 218720, "start": 2203.96, "end": 2208.2, "text": " estimation semantic segmentation instance retrieval so the same kind of", "tokens": [51202, 35701, 47982, 9469, 399, 5197, 19817, 3337, 370, 264, 912, 733, 295, 51414], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 296, "seek": 218720, "start": 2208.2, "end": 2212.12, "text": " application that I showed in the video but basically with very little", "tokens": [51414, 3861, 300, 286, 4712, 294, 264, 960, 457, 1936, 365, 588, 707, 51610], "temperature": 0.0, "avg_logprob": -0.18046667178471884, "compression_ratio": 1.71484375, "no_speech_prob": 0.002232452156022191}, {"id": 297, "seek": 221212, "start": 2212.16, "end": 2216.88, "text": " supervision this is then it's pre-trained and it basically because it's", "tokens": [50366, 32675, 341, 307, 550, 309, 311, 659, 12, 17227, 2001, 293, 309, 1936, 570, 309, 311, 50602], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 298, "seek": 221212, "start": 2216.88, "end": 2223.64, "text": " pre-trained on enormous amounts of data just training a very shadow head to", "tokens": [50602, 659, 12, 17227, 2001, 322, 11322, 11663, 295, 1412, 445, 3097, 257, 588, 8576, 1378, 281, 50940], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 299, "seek": 221212, "start": 2223.64, "end": 2228.3599999999997, "text": " solve any particular one of those problems actually beats the state of the", "tokens": [50940, 5039, 604, 1729, 472, 295, 729, 2740, 767, 16447, 264, 1785, 295, 264, 51176], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 300, "seek": 221212, "start": 2228.3599999999997, "end": 2232.6, "text": " art for that's estimation or classification or whatever you can", "tokens": [51176, 1523, 337, 300, 311, 35701, 420, 21538, 420, 2035, 291, 393, 51388], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 301, "seek": 221212, "start": 2232.6, "end": 2237.16, "text": " actually play with it interactively that's the URL that you see here and", "tokens": [51388, 767, 862, 365, 309, 4648, 3413, 300, 311, 264, 12905, 300, 291, 536, 510, 293, 51616], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 302, "seek": 221212, "start": 2237.16, "end": 2241.24, "text": " these are some examples of visualization of what the features that are", "tokens": [51616, 613, 366, 512, 5110, 295, 25801, 295, 437, 264, 4122, 300, 366, 51820], "temperature": 0.0, "avg_logprob": -0.15613918697711118, "compression_ratio": 1.72, "no_speech_prob": 0.0027969442307949066}, {"id": 303, "seek": 224124, "start": 2241.2799999999997, "end": 2246.64, "text": " extracted are it's kind of a you know colorful representation of the like", "tokens": [50366, 34086, 366, 309, 311, 733, 295, 257, 291, 458, 18506, 10290, 295, 264, 411, 50634], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 304, "seek": 224124, "start": 2246.64, "end": 2250.8399999999997, "text": " different feature vectors are represented by different colors this is", "tokens": [50634, 819, 4111, 18875, 366, 10379, 538, 819, 4577, 341, 307, 50844], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 305, "seek": 224124, "start": 2250.8399999999997, "end": 2253.6, "text": " actually kind of each color is like a principal component if you know what", "tokens": [50844, 767, 733, 295, 1184, 2017, 307, 411, 257, 9716, 6542, 498, 291, 458, 437, 50982], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 306, "seek": 224124, "start": 2253.6, "end": 2259.08, "text": " that is so those are you know examples on sort of typical typical images and", "tokens": [50982, 300, 307, 370, 729, 366, 291, 458, 5110, 322, 1333, 295, 7476, 7476, 5267, 293, 51256], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 307, "seek": 224124, "start": 2259.08, "end": 2262.6, "text": " people I've started to use this for all kinds of stuff for biological image", "tokens": [51256, 561, 286, 600, 1409, 281, 764, 341, 337, 439, 3685, 295, 1507, 337, 13910, 3256, 51432], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 308, "seek": 224124, "start": 2262.6, "end": 2269.12, "text": " analysis for astronomy for for environmental protection so that's the", "tokens": [51432, 5215, 337, 37844, 337, 337, 8303, 6334, 370, 300, 311, 264, 51758], "temperature": 0.0, "avg_logprob": -0.12826050994216756, "compression_ratio": 1.822314049586777, "no_speech_prob": 0.0036931277718394995}, {"id": 309, "seek": 226912, "start": 2269.12, "end": 2273.24, "text": " next example I'm going to show you so this is a project by someone on the team", "tokens": [50364, 958, 1365, 286, 478, 516, 281, 855, 291, 370, 341, 307, 257, 1716, 538, 1580, 322, 264, 1469, 50570], "temperature": 0.0, "avg_logprob": -0.19856228671231113, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.008170634508132935}, {"id": 310, "seek": 226912, "start": 2273.24, "end": 2278.48, "text": " Camille Coupri and a large collection collection of collaborators and what she", "tokens": [50570, 6886, 3409, 383, 1250, 470, 293, 257, 2416, 5765, 5765, 295, 39789, 293, 437, 750, 50832], "temperature": 0.0, "avg_logprob": -0.19856228671231113, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.008170634508132935}, {"id": 311, "seek": 226912, "start": 2278.48, "end": 2286.7999999999997, "text": " did was use the Dino V2 features and trained relatively small system on top", "tokens": [50832, 630, 390, 764, 264, 413, 2982, 691, 17, 4122, 293, 8895, 7226, 1359, 1185, 322, 1192, 51248], "temperature": 0.0, "avg_logprob": -0.19856228671231113, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.008170634508132935}, {"id": 312, "seek": 226912, "start": 2286.7999999999997, "end": 2293.6, "text": " of it to tell what the height of the trees are from a satellite image so we", "tokens": [51248, 295, 309, 281, 980, 437, 264, 6681, 295, 264, 5852, 366, 490, 257, 16016, 3256, 370, 321, 51588], "temperature": 0.0, "avg_logprob": -0.19856228671231113, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.008170634508132935}, {"id": 313, "seek": 226912, "start": 2293.6, "end": 2297.4, "text": " have lots of satellite images on the entire world at half meter resolution", "tokens": [51588, 362, 3195, 295, 16016, 5267, 322, 264, 2302, 1002, 412, 1922, 9255, 8669, 51778], "temperature": 0.0, "avg_logprob": -0.19856228671231113, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.008170634508132935}, {"id": 314, "seek": 229740, "start": 2297.4, "end": 2302.56, "text": " you can get this from a satellite imaging companies and for some areas", "tokens": [50364, 291, 393, 483, 341, 490, 257, 16016, 25036, 3431, 293, 337, 512, 3179, 50622], "temperature": 0.0, "avg_logprob": -0.14975519494695977, "compression_ratio": 1.8284313725490196, "no_speech_prob": 0.0017480954993516207}, {"id": 315, "seek": 229740, "start": 2302.56, "end": 2307.96, "text": " there is LiDAR data which tells you how tall the trees are so you use that to", "tokens": [50622, 456, 307, 8349, 35, 1899, 1412, 597, 5112, 291, 577, 6764, 264, 5852, 366, 370, 291, 764, 300, 281, 50892], "temperature": 0.0, "avg_logprob": -0.14975519494695977, "compression_ratio": 1.8284313725490196, "no_speech_prob": 0.0017480954993516207}, {"id": 316, "seek": 229740, "start": 2307.96, "end": 2311.04, "text": " train the system and then you can apply it to the entire world and what it tells", "tokens": [50892, 3847, 264, 1185, 293, 550, 291, 393, 3079, 309, 281, 264, 2302, 1002, 293, 437, 309, 5112, 51046], "temperature": 0.0, "avg_logprob": -0.14975519494695977, "compression_ratio": 1.8284313725490196, "no_speech_prob": 0.0017480954993516207}, {"id": 317, "seek": 229740, "start": 2311.04, "end": 2317.84, "text": " you is how much how much carbon is captured by the trees if you know", "tokens": [51046, 291, 307, 577, 709, 577, 709, 5954, 307, 11828, 538, 264, 5852, 498, 291, 458, 51386], "temperature": 0.0, "avg_logprob": -0.14975519494695977, "compression_ratio": 1.8284313725490196, "no_speech_prob": 0.0017480954993516207}, {"id": 318, "seek": 229740, "start": 2317.84, "end": 2321.1600000000003, "text": " roughly what the height of the tree is you know roughly how much carbon is", "tokens": [51386, 9810, 437, 264, 6681, 295, 264, 4230, 307, 291, 458, 9810, 577, 709, 5954, 307, 51552], "temperature": 0.0, "avg_logprob": -0.14975519494695977, "compression_ratio": 1.8284313725490196, "no_speech_prob": 0.0017480954993516207}, {"id": 319, "seek": 232116, "start": 2321.6, "end": 2327.6, "text": " captured in the tree that's super important to know like you know should", "tokens": [50386, 11828, 294, 264, 4230, 300, 311, 1687, 1021, 281, 458, 411, 291, 458, 820, 50686], "temperature": 0.0, "avg_logprob": -0.17105284372965496, "compression_ratio": 1.7922705314009661, "no_speech_prob": 0.019679198041558266}, {"id": 320, "seek": 232116, "start": 2327.6, "end": 2333.2, "text": " we protect forests of course we should should we plant more trees where things", "tokens": [50686, 321, 2371, 21700, 295, 1164, 321, 820, 820, 321, 3709, 544, 5852, 689, 721, 50966], "temperature": 0.0, "avg_logprob": -0.17105284372965496, "compression_ratio": 1.7922705314009661, "no_speech_prob": 0.019679198041558266}, {"id": 321, "seek": 232116, "start": 2333.2, "end": 2337.96, "text": " like that so very interesting this publications on this where you know", "tokens": [50966, 411, 300, 370, 588, 1880, 341, 25618, 322, 341, 689, 291, 458, 51204], "temperature": 0.0, "avg_logprob": -0.17105284372965496, "compression_ratio": 1.7922705314009661, "no_speech_prob": 0.019679198041558266}, {"id": 322, "seek": 232116, "start": 2337.96, "end": 2343.24, "text": " everything is detailed and everything another success of self supervised", "tokens": [51204, 1203, 307, 9942, 293, 1203, 1071, 2245, 295, 2698, 46533, 51468], "temperature": 0.0, "avg_logprob": -0.17105284372965496, "compression_ratio": 1.7922705314009661, "no_speech_prob": 0.019679198041558266}, {"id": 323, "seek": 232116, "start": 2343.24, "end": 2347.12, "text": " running of the type that I showed for natural language processing where you", "tokens": [51468, 2614, 295, 264, 2010, 300, 286, 4712, 337, 3303, 2856, 9007, 689, 291, 51662], "temperature": 0.0, "avg_logprob": -0.17105284372965496, "compression_ratio": 1.7922705314009661, "no_speech_prob": 0.019679198041558266}, {"id": 324, "seek": 234712, "start": 2347.4, "end": 2355.72, "text": " remove some other words is in biology proteomics particularly so you can the", "tokens": [50378, 4159, 512, 661, 2283, 307, 294, 14956, 5631, 29884, 4098, 370, 291, 393, 264, 50794], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 325, "seek": 234712, "start": 2355.72, "end": 2361.12, "text": " protein is a sequence of amino acids and we know hundreds of millions of them so", "tokens": [50794, 7944, 307, 257, 8310, 295, 24674, 21667, 293, 321, 458, 6779, 295, 6803, 295, 552, 370, 51064], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 326, "seek": 234712, "start": 2361.12, "end": 2364.08, "text": " you take a sequence of amino acids you remove some of the amino acids and you", "tokens": [51064, 291, 747, 257, 8310, 295, 24674, 21667, 291, 4159, 512, 295, 264, 24674, 21667, 293, 291, 51212], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 327, "seek": 234712, "start": 2364.08, "end": 2367.48, "text": " train some gigantic neural net to predict the amino acids that are missing", "tokens": [51212, 3847, 512, 26800, 18161, 2533, 281, 6069, 264, 24674, 21667, 300, 366, 5361, 51382], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 328, "seek": 234712, "start": 2367.48, "end": 2372.64, "text": " the system kind of learns to represent sequences of amino acids that", "tokens": [51382, 264, 1185, 733, 295, 27152, 281, 2906, 22978, 295, 24674, 21667, 300, 51640], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 329, "seek": 234712, "start": 2372.64, "end": 2376.8399999999997, "text": " constitute proteins and then you use that representation as input to a system", "tokens": [51640, 41658, 15577, 293, 550, 291, 764, 300, 10290, 382, 4846, 281, 257, 1185, 51850], "temperature": 0.0, "avg_logprob": -0.14315025173887916, "compression_ratio": 2.0493273542600896, "no_speech_prob": 0.017001377418637276}, {"id": 330, "seek": 237684, "start": 2376.88, "end": 2380.7200000000003, "text": " that predicts the conformation of that protein how it folds well they can stick", "tokens": [50366, 300, 6069, 82, 264, 416, 8663, 295, 300, 7944, 577, 309, 31341, 731, 436, 393, 2897, 50558], "temperature": 0.0, "avg_logprob": -0.24073653750949436, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.008343327790498734}, {"id": 331, "seek": 237684, "start": 2380.7200000000003, "end": 2384.84, "text": " to another protein a particular location so there's a famous work by our", "tokens": [50558, 281, 1071, 7944, 257, 1729, 4914, 370, 456, 311, 257, 4618, 589, 538, 527, 50764], "temperature": 0.0, "avg_logprob": -0.24073653750949436, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.008343327790498734}, {"id": 332, "seek": 237684, "start": 2384.84, "end": 2390.28, "text": " colleagues at DeepMind at Fairfold but the this idea of using pre-trained", "tokens": [50764, 7734, 412, 14895, 44, 471, 412, 12157, 18353, 457, 264, 341, 1558, 295, 1228, 659, 12, 17227, 2001, 51036], "temperature": 0.0, "avg_logprob": -0.24073653750949436, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.008343327790498734}, {"id": 333, "seek": 237684, "start": 2390.28, "end": 2396.44, "text": " transformers for protein was actually first published by my colleagues at fair", "tokens": [51036, 4088, 433, 337, 7944, 390, 767, 700, 6572, 538, 452, 7734, 412, 3143, 51344], "temperature": 0.0, "avg_logprob": -0.24073653750949436, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.008343327790498734}, {"id": 334, "seek": 237684, "start": 2396.44, "end": 2400.4, "text": " they're actually no longer at fair now they have left Fairf to create a startup", "tokens": [51344, 436, 434, 767, 572, 2854, 412, 3143, 586, 436, 362, 1411, 12157, 69, 281, 1884, 257, 18578, 51542], "temperature": 0.0, "avg_logprob": -0.24073653750949436, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.008343327790498734}, {"id": 335, "seek": 240040, "start": 2400.44, "end": 2407.84, "text": " around this around this idea but it's incredibly successful thousands of", "tokens": [50366, 926, 341, 926, 341, 1558, 457, 309, 311, 6252, 4406, 5383, 295, 50736], "temperature": 0.0, "avg_logprob": -0.304151079547939, "compression_ratio": 1.5947368421052632, "no_speech_prob": 0.008910087868571281}, {"id": 336, "seek": 240040, "start": 2407.84, "end": 2411.84, "text": " research groups around the world are using this kind of data is actually a", "tokens": [50736, 2132, 3935, 926, 264, 1002, 366, 1228, 341, 733, 295, 1412, 307, 767, 257, 50936], "temperature": 0.0, "avg_logprob": -0.304151079547939, "compression_ratio": 1.5947368421052632, "no_speech_prob": 0.008910087868571281}, {"id": 337, "seek": 240040, "start": 2411.84, "end": 2417.92, "text": " atlas of folded protein contains 600 million proteins or something like that", "tokens": [50936, 412, 7743, 295, 23940, 7944, 8306, 11849, 2459, 15577, 420, 746, 411, 300, 51240], "temperature": 0.0, "avg_logprob": -0.304151079547939, "compression_ratio": 1.5947368421052632, "no_speech_prob": 0.008910087868571281}, {"id": 338, "seek": 240040, "start": 2417.92, "end": 2426.6800000000003, "text": " with the structure that is predicted it's called the ESM metagenomic atlas and", "tokens": [51240, 365, 264, 3877, 300, 307, 19147, 309, 311, 1219, 264, 12564, 44, 1131, 4698, 21401, 412, 7743, 293, 51678], "temperature": 0.0, "avg_logprob": -0.304151079547939, "compression_ratio": 1.5947368421052632, "no_speech_prob": 0.008910087868571281}, {"id": 339, "seek": 242668, "start": 2427.44, "end": 2434.48, "text": " ESM atlas.com a very big tool for biologists that really may change", "tokens": [50402, 12564, 44, 412, 7743, 13, 1112, 257, 588, 955, 2290, 337, 3228, 12256, 300, 534, 815, 1319, 50754], "temperature": 0.0, "avg_logprob": -0.24373629006994776, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.006456492003053427}, {"id": 340, "seek": 242668, "start": 2434.48, "end": 2438.9199999999996, "text": " completely the way we do drug design and understand the mechanisms of life", "tokens": [50754, 2584, 264, 636, 321, 360, 4110, 1715, 293, 1223, 264, 15902, 295, 993, 50976], "temperature": 0.0, "avg_logprob": -0.24373629006994776, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.006456492003053427}, {"id": 341, "seek": 242668, "start": 2438.9199999999996, "end": 2446.3199999999997, "text": " another very impressive project here that required a lot of effort is a project", "tokens": [50976, 1071, 588, 8992, 1716, 510, 300, 4739, 257, 688, 295, 4630, 307, 257, 1716, 51346], "temperature": 0.0, "avg_logprob": -0.24373629006994776, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.006456492003053427}, {"id": 342, "seek": 242668, "start": 2446.3199999999997, "end": 2451.48, "text": " called no language left behind again from fair collection of people from the", "tokens": [51346, 1219, 572, 2856, 1411, 2261, 797, 490, 3143, 5765, 295, 561, 490, 264, 51604], "temperature": 0.0, "avg_logprob": -0.24373629006994776, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.006456492003053427}, {"id": 343, "seek": 242668, "start": 2451.48, "end": 2455.24, "text": " various sites of fair and this is a system that can translate 200 languages", "tokens": [51604, 3683, 7533, 295, 3143, 293, 341, 307, 257, 1185, 300, 393, 13799, 2331, 8650, 51792], "temperature": 0.0, "avg_logprob": -0.24373629006994776, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.006456492003053427}, {"id": 344, "seek": 245524, "start": 2455.8799999999997, "end": 2461.9199999999996, "text": " from in any direction and when you look at what those languages are it's a lot", "tokens": [50396, 490, 294, 604, 3513, 293, 562, 291, 574, 412, 437, 729, 8650, 366, 309, 311, 257, 688, 50698], "temperature": 0.0, "avg_logprob": -0.16017511279083962, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.002733950037509203}, {"id": 345, "seek": 245524, "start": 2461.9199999999996, "end": 2467.2, "text": " of languages most of them we never heard of in you know square corners of the", "tokens": [50698, 295, 8650, 881, 295, 552, 321, 1128, 2198, 295, 294, 291, 458, 3732, 12413, 295, 264, 50962], "temperature": 0.0, "avg_logprob": -0.16017511279083962, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.002733950037509203}, {"id": 346, "seek": 245524, "start": 2467.2, "end": 2472.4799999999996, "text": " world but it's important for people to be able to preserve that culture that you", "tokens": [50962, 1002, 457, 309, 311, 1021, 337, 561, 281, 312, 1075, 281, 15665, 300, 3713, 300, 291, 51226], "temperature": 0.0, "avg_logprob": -0.16017511279083962, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.002733950037509203}, {"id": 347, "seek": 245524, "start": 2472.4799999999996, "end": 2476.3599999999997, "text": " know they can speak their language and basically be understood using automatic", "tokens": [51226, 458, 436, 393, 1710, 641, 2856, 293, 1936, 312, 7320, 1228, 12509, 51420], "temperature": 0.0, "avg_logprob": -0.16017511279083962, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.002733950037509203}, {"id": 348, "seek": 245524, "start": 2476.3599999999997, "end": 2481.3599999999997, "text": " translation so what's interesting about this is that there are four thousand", "tokens": [51420, 12853, 370, 437, 311, 1880, 466, 341, 307, 300, 456, 366, 1451, 4714, 51670], "temperature": 0.0, "avg_logprob": -0.16017511279083962, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.002733950037509203}, {"id": 349, "seek": 248136, "start": 2481.8, "end": 2489.1200000000003, "text": " directions for translation but the data only covers 2400 of those pairs", "tokens": [50386, 11095, 337, 12853, 457, 264, 1412, 787, 10538, 4022, 628, 295, 729, 15494, 50752], "temperature": 0.0, "avg_logprob": -0.20227800789525954, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.005647008307278156}, {"id": 350, "seek": 248136, "start": 2489.1200000000003, "end": 2497.96, "text": " among the 40,000 despite that because we train a giant transformer to represent", "tokens": [50752, 3654, 264, 3356, 11, 1360, 7228, 300, 570, 321, 3847, 257, 7410, 31782, 281, 2906, 51194], "temperature": 0.0, "avg_logprob": -0.20227800789525954, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.005647008307278156}, {"id": 351, "seek": 248136, "start": 2497.96, "end": 2503.2000000000003, "text": " language regardless of the language the system takes advantage of the", "tokens": [51194, 2856, 10060, 295, 264, 2856, 264, 1185, 2516, 5002, 295, 264, 51456], "temperature": 0.0, "avg_logprob": -0.20227800789525954, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.005647008307278156}, {"id": 352, "seek": 248136, "start": 2503.2000000000003, "end": 2507.08, "text": " similarities between between the language families to actually kind of", "tokens": [51456, 24197, 1296, 1296, 264, 2856, 4466, 281, 767, 733, 295, 51650], "temperature": 0.0, "avg_logprob": -0.20227800789525954, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.005647008307278156}, {"id": 353, "seek": 250708, "start": 2507.08, "end": 2511.16, "text": " extract a multilingual language independent representation of language", "tokens": [50364, 8947, 257, 2120, 38219, 2856, 6695, 10290, 295, 2856, 50568], "temperature": 0.0, "avg_logprob": -0.17239733000059385, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0025031957775354385}, {"id": 354, "seek": 250708, "start": 2511.16, "end": 2514.92, "text": " which allows the system to do translation in any direction including", "tokens": [50568, 597, 4045, 264, 1185, 281, 360, 12853, 294, 604, 3513, 3009, 50756], "temperature": 0.0, "avg_logprob": -0.17239733000059385, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0025031957775354385}, {"id": 355, "seek": 250708, "start": 2514.92, "end": 2519.96, "text": " four directions has never been trained on that's pretty amazing pretty small", "tokens": [50756, 1451, 11095, 575, 1128, 668, 8895, 322, 300, 311, 1238, 2243, 1238, 1359, 51008], "temperature": 0.0, "avg_logprob": -0.17239733000059385, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0025031957775354385}, {"id": 356, "seek": 250708, "start": 2519.96, "end": 2529.68, "text": " model but today standard only 54 billion parameters I mean sizable the same team", "tokens": [51008, 2316, 457, 965, 3832, 787, 20793, 5218, 9834, 286, 914, 13723, 712, 264, 912, 1469, 51494], "temperature": 0.0, "avg_logprob": -0.17239733000059385, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0025031957775354385}, {"id": 357, "seek": 250708, "start": 2529.68, "end": 2534.48, "text": " now as another project called seamless which was was announced a few weeks ago", "tokens": [51494, 586, 382, 1071, 1716, 1219, 28677, 597, 390, 390, 7548, 257, 1326, 3259, 2057, 51734], "temperature": 0.0, "avg_logprob": -0.17239733000059385, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0025031957775354385}, {"id": 358, "seek": 253448, "start": 2534.48, "end": 2541.84, "text": " they can do speech to speech speech to text text to speech and text to text", "tokens": [50364, 436, 393, 360, 6218, 281, 6218, 6218, 281, 2487, 2487, 281, 6218, 293, 2487, 281, 2487, 50732], "temperature": 0.0, "avg_logprob": -0.20785538773787648, "compression_ratio": 2.0, "no_speech_prob": 0.002775467000901699}, {"id": 359, "seek": 253448, "start": 2541.84, "end": 2547.76, "text": " translation as well as speech recognition speech synthesis etc speech to", "tokens": [50732, 12853, 382, 731, 382, 6218, 11150, 6218, 30252, 5183, 6218, 281, 51028], "temperature": 0.0, "avg_logprob": -0.20785538773787648, "compression_ratio": 2.0, "no_speech_prob": 0.002775467000901699}, {"id": 360, "seek": 253448, "start": 2547.76, "end": 2553.68, "text": " speech is interesting because it can do translation for languages that are not", "tokens": [51028, 6218, 307, 1880, 570, 309, 393, 360, 12853, 337, 8650, 300, 366, 406, 51324], "temperature": 0.0, "avg_logprob": -0.20785538773787648, "compression_ratio": 2.0, "no_speech_prob": 0.002775467000901699}, {"id": 361, "seek": 253448, "start": 2553.68, "end": 2557.36, "text": " written directly from speech to speech that system can handle a thousand", "tokens": [51324, 3720, 3838, 490, 6218, 281, 6218, 300, 1185, 393, 4813, 257, 4714, 51508], "temperature": 0.0, "avg_logprob": -0.20785538773787648, "compression_ratio": 2.0, "no_speech_prob": 0.002775467000901699}, {"id": 362, "seek": 253448, "start": 2557.36, "end": 2563.32, "text": " languages which is really impressive okay so applications of deep learning that", "tokens": [51508, 8650, 597, 307, 534, 8992, 1392, 370, 5821, 295, 2452, 2539, 300, 51806], "temperature": 0.0, "avg_logprob": -0.20785538773787648, "compression_ratio": 2.0, "no_speech_prob": 0.002775467000901699}, {"id": 363, "seek": 256332, "start": 2563.32, "end": 2569.1600000000003, "text": " are less visible perhaps is that deep learning or AI connects people to", "tokens": [50364, 366, 1570, 8974, 4317, 307, 300, 2452, 2539, 420, 7318, 16967, 561, 281, 50656], "temperature": 0.0, "avg_logprob": -0.16399629492508738, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.005991416517645121}, {"id": 364, "seek": 256332, "start": 2569.1600000000003, "end": 2573.92, "text": " knowledge and they connect people to each other the biggest deployment of", "tokens": [50656, 3601, 293, 436, 1745, 561, 281, 1184, 661, 264, 3880, 19317, 295, 50894], "temperature": 0.0, "avg_logprob": -0.16399629492508738, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.005991416517645121}, {"id": 365, "seek": 256332, "start": 2573.92, "end": 2578.32, "text": " machine learning today is probably in social networks and online services like", "tokens": [50894, 3479, 2539, 965, 307, 1391, 294, 2093, 9590, 293, 2950, 3328, 411, 51114], "temperature": 0.0, "avg_logprob": -0.16399629492508738, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.005991416517645121}, {"id": 366, "seek": 256332, "start": 2578.32, "end": 2583.56, "text": " like search engines and if you take deep learning out of Google or Meta or", "tokens": [51114, 411, 3164, 12982, 293, 498, 291, 747, 2452, 2539, 484, 295, 3329, 420, 6377, 64, 420, 51376], "temperature": 0.0, "avg_logprob": -0.16399629492508738, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.005991416517645121}, {"id": 367, "seek": 256332, "start": 2583.56, "end": 2590.6400000000003, "text": " Microsoft companies crumble they literally are built around it so deep", "tokens": [51376, 8116, 3431, 47478, 436, 3736, 366, 3094, 926, 309, 370, 2452, 51730], "temperature": 0.0, "avg_logprob": -0.16399629492508738, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.005991416517645121}, {"id": 368, "seek": 259064, "start": 2590.64, "end": 2593.04, "text": " learning helps us deal with the information deluge for doing things", "tokens": [50364, 2539, 3665, 505, 2028, 365, 264, 1589, 1103, 7181, 337, 884, 721, 50484], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 369, "seek": 259064, "start": 2593.04, "end": 2596.72, "text": " like search and retrieval ranking question answering things like this but", "tokens": [50484, 411, 3164, 293, 19817, 3337, 17833, 1168, 13430, 721, 411, 341, 457, 50668], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 370, "seek": 259064, "start": 2596.72, "end": 2600.6, "text": " and that requires machine to understand content of course for", "tokens": [50668, 293, 300, 7029, 3479, 281, 1223, 2701, 295, 1164, 337, 50862], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 371, "seek": 259064, "start": 2600.6, "end": 2605.16, "text": " translation which is very useful for people who are not literate for example", "tokens": [50862, 12853, 597, 307, 588, 4420, 337, 561, 567, 366, 406, 2733, 473, 337, 1365, 51090], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 372, "seek": 259064, "start": 2605.16, "end": 2610.08, "text": " or people are blind or visually impaired so there's three billion people in the", "tokens": [51090, 420, 561, 366, 6865, 420, 19622, 36762, 370, 456, 311, 1045, 5218, 561, 294, 264, 51336], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 373, "seek": 259064, "start": 2610.08, "end": 2614.7999999999997, "text": " world today who can't use technology because they basically can't read more", "tokens": [51336, 1002, 965, 567, 393, 380, 764, 2899, 570, 436, 1936, 393, 380, 1401, 544, 51572], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 374, "seek": 259064, "start": 2614.7999999999997, "end": 2619.7999999999997, "text": " or less so here's the biggest use of AI today filtering out illegal and", "tokens": [51572, 420, 1570, 370, 510, 311, 264, 3880, 764, 295, 7318, 965, 30822, 484, 11905, 293, 51822], "temperature": 0.0, "avg_logprob": -0.15105120340983072, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.019539497792720795}, {"id": 375, "seek": 261980, "start": 2619.8, "end": 2624.48, "text": " dangerous content and this is something that's very hard to do it's impossible to", "tokens": [50364, 5795, 2701, 293, 341, 307, 746, 300, 311, 588, 1152, 281, 360, 309, 311, 6243, 281, 50598], "temperature": 0.0, "avg_logprob": -0.14050486918245808, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.016253149136900902}, {"id": 376, "seek": 261980, "start": 2624.48, "end": 2631.44, "text": " do perfectly but to tell you to give you an idea of how much progress AI has made", "tokens": [50598, 360, 6239, 457, 281, 980, 291, 281, 976, 291, 364, 1558, 295, 577, 709, 4205, 7318, 575, 1027, 50946], "temperature": 0.0, "avg_logprob": -0.14050486918245808, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.016253149136900902}, {"id": 377, "seek": 261980, "start": 2631.44, "end": 2635.52, "text": " those idea of pre-training transformers and stuff like that the", "tokens": [50946, 729, 1558, 295, 659, 12, 17227, 1760, 4088, 433, 293, 1507, 411, 300, 264, 51150], "temperature": 0.0, "avg_logprob": -0.14050486918245808, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.016253149136900902}, {"id": 378, "seek": 261980, "start": 2635.52, "end": 2642.92, "text": " proportion of hate speech that Facebook was able to take down automatically five", "tokens": [51150, 16068, 295, 4700, 6218, 300, 4384, 390, 1075, 281, 747, 760, 6772, 1732, 51520], "temperature": 0.0, "avg_logprob": -0.14050486918245808, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.016253149136900902}, {"id": 379, "seek": 261980, "start": 2642.92, "end": 2649.5600000000004, "text": " years ago was about 20 to 25 percent okay it was using sort of fairly simple", "tokens": [51520, 924, 2057, 390, 466, 945, 281, 3552, 3043, 1392, 309, 390, 1228, 1333, 295, 6457, 2199, 51852], "temperature": 0.0, "avg_logprob": -0.14050486918245808, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.016253149136900902}, {"id": 380, "seek": 264956, "start": 2649.56, "end": 2656.0, "text": " machine learning techniques NLP methods of the types that were common five years", "tokens": [50364, 3479, 2539, 7512, 426, 45196, 7150, 295, 264, 3467, 300, 645, 2689, 1732, 924, 50686], "temperature": 0.0, "avg_logprob": -0.18200852996424624, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0022973630111664534}, {"id": 381, "seek": 264956, "start": 2656.0, "end": 2666.52, "text": " ago and then self-supervised pre-trained transformers happened and that number", "tokens": [50686, 2057, 293, 550, 2698, 12, 48172, 24420, 659, 12, 17227, 2001, 4088, 433, 2011, 293, 300, 1230, 51212], "temperature": 0.0, "avg_logprob": -0.18200852996424624, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0022973630111664534}, {"id": 382, "seek": 264956, "start": 2666.52, "end": 2673.4, "text": " went to 95% last year and it's just progress in AI so a lot of people that", "tokens": [51212, 1437, 281, 13420, 4, 1036, 1064, 293, 309, 311, 445, 4205, 294, 7318, 370, 257, 688, 295, 561, 300, 51556], "temperature": 0.0, "avg_logprob": -0.18200852996424624, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0022973630111664534}, {"id": 383, "seek": 264956, "start": 2673.4, "end": 2677.6, "text": " we hear talk about AI who generally don't know much about AI actually tell you", "tokens": [51556, 321, 1568, 751, 466, 7318, 567, 5101, 500, 380, 458, 709, 466, 7318, 767, 980, 291, 51766], "temperature": 0.0, "avg_logprob": -0.18200852996424624, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0022973630111664534}, {"id": 384, "seek": 267760, "start": 2677.6, "end": 2681.64, "text": " about all the dangers of AI that then you know AI is going to destroy I don't", "tokens": [50364, 466, 439, 264, 27701, 295, 7318, 300, 550, 291, 458, 7318, 307, 516, 281, 5293, 286, 500, 380, 50566], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 385, "seek": 267760, "start": 2681.64, "end": 2685.4, "text": " know democracy because of disinformation and things like that what they", "tokens": [50566, 458, 10528, 570, 295, 717, 20941, 293, 721, 411, 300, 437, 436, 50754], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 386, "seek": 267760, "start": 2685.4, "end": 2688.7599999999998, "text": " don't understand is that AI is actually the solution to those problems it's not", "tokens": [50754, 500, 380, 1223, 307, 300, 7318, 307, 767, 264, 3827, 281, 729, 2740, 309, 311, 406, 50922], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 387, "seek": 267760, "start": 2688.7599999999998, "end": 2692.36, "text": " actually the problem it's the solution to those problems and it's already the", "tokens": [50922, 767, 264, 1154, 309, 311, 264, 3827, 281, 729, 2740, 293, 309, 311, 1217, 264, 51102], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 388, "seek": 267760, "start": 2692.36, "end": 2697.56, "text": " case that doing content moderation on social networks makes massive use of the", "tokens": [51102, 1389, 300, 884, 2701, 49471, 322, 2093, 9590, 1669, 5994, 764, 295, 264, 51362], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 389, "seek": 267760, "start": 2697.56, "end": 2703.08, "text": " latest advancements in AI and the people who try to corrupt that system are not", "tokens": [51362, 6792, 7295, 1117, 294, 7318, 293, 264, 561, 567, 853, 281, 17366, 300, 1185, 366, 406, 51638], "temperature": 0.0, "avg_logprob": -0.11605342534872201, "compression_ratio": 1.8714859437751004, "no_speech_prob": 0.006959756836295128}, {"id": 390, "seek": 270308, "start": 2703.24, "end": 2711.2, "text": " sophisticated in terms of their AI so something that needs to be known okay", "tokens": [50372, 16950, 294, 2115, 295, 641, 7318, 370, 746, 300, 2203, 281, 312, 2570, 1392, 50770], "temperature": 0.0, "avg_logprob": -0.1678175213693202, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.01270576473325491}, {"id": 391, "seek": 270308, "start": 2711.2, "end": 2715.7599999999998, "text": " but everybody is excited about generative AI and autoregressive large", "tokens": [50770, 457, 2201, 307, 2919, 466, 1337, 1166, 7318, 293, 1476, 418, 3091, 488, 2416, 50998], "temperature": 0.0, "avg_logprob": -0.1678175213693202, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.01270576473325491}, {"id": 392, "seek": 270308, "start": 2715.7599999999998, "end": 2722.0, "text": " language models and things of that type right so many of you certainly I'm sure", "tokens": [50998, 2856, 5245, 293, 721, 295, 300, 2010, 558, 370, 867, 295, 291, 3297, 286, 478, 988, 51310], "temperature": 0.0, "avg_logprob": -0.1678175213693202, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.01270576473325491}, {"id": 393, "seek": 270308, "start": 2722.0, "end": 2725.2, "text": " have played with those image generation things where you type a text and", "tokens": [51310, 362, 3737, 365, 729, 3256, 5125, 721, 689, 291, 2010, 257, 2487, 293, 51470], "temperature": 0.0, "avg_logprob": -0.1678175213693202, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.01270576473325491}, {"id": 394, "seek": 270308, "start": 2725.2, "end": 2730.24, "text": " outcomes image and this is the state of the art about a year and a half ago from", "tokens": [51470, 10070, 3256, 293, 341, 307, 264, 1785, 295, 264, 1523, 466, 257, 1064, 293, 257, 1922, 2057, 490, 51722], "temperature": 0.0, "avg_logprob": -0.1678175213693202, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.01270576473325491}, {"id": 395, "seek": 273024, "start": 2730.2799999999997, "end": 2734.9199999999996, "text": " either a meta and make a scene system or a penny I dali to or Google's image and", "tokens": [50366, 2139, 257, 19616, 293, 652, 257, 4145, 1185, 420, 257, 24178, 286, 274, 5103, 281, 420, 3329, 311, 3256, 293, 50598], "temperature": 0.0, "avg_logprob": -0.30508835315704347, "compression_ratio": 1.6864864864864866, "no_speech_prob": 0.008019187487661839}, {"id": 396, "seek": 273024, "start": 2734.9199999999996, "end": 2745.7999999999997, "text": " as of yesterday this is what you get out of meta so this is actually from a", "tokens": [50598, 382, 295, 5186, 341, 307, 437, 291, 483, 484, 295, 19616, 370, 341, 307, 767, 490, 257, 51142], "temperature": 0.0, "avg_logprob": -0.30508835315704347, "compression_ratio": 1.6864864864864866, "no_speech_prob": 0.008019187487661839}, {"id": 397, "seek": 273024, "start": 2745.7999999999997, "end": 2750.4399999999996, "text": " paper and you can get the paper from archive it's there but there's a product", "tokens": [51142, 3035, 293, 291, 393, 483, 264, 3035, 490, 23507, 309, 311, 456, 457, 456, 311, 257, 1674, 51374], "temperature": 0.0, "avg_logprob": -0.30508835315704347, "compression_ratio": 1.6864864864864866, "no_speech_prob": 0.008019187487661839}, {"id": 398, "seek": 273024, "start": 2750.4399999999996, "end": 2756.6, "text": " attached to that paper called emu it's an acronym but actually don't remember", "tokens": [51374, 8570, 281, 300, 3035, 1219, 846, 84, 309, 311, 364, 39195, 457, 767, 500, 380, 1604, 51682], "temperature": 0.0, "avg_logprob": -0.30508835315704347, "compression_ratio": 1.6864864864864866, "no_speech_prob": 0.008019187487661839}, {"id": 399, "seek": 275660, "start": 2756.64, "end": 2765.0, "text": " what it means and what the system can do is in it can generate images from a", "tokens": [50366, 437, 309, 1355, 293, 437, 264, 1185, 393, 360, 307, 294, 309, 393, 8460, 5267, 490, 257, 50784], "temperature": 0.0, "avg_logprob": -0.14466288956728848, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.005431793164461851}, {"id": 400, "seek": 275660, "start": 2765.0, "end": 2770.8399999999997, "text": " text prompt and it was rolled out as a product yesterday as well as the paper", "tokens": [50784, 2487, 12391, 293, 309, 390, 14306, 484, 382, 257, 1674, 5186, 382, 731, 382, 264, 3035, 51076], "temperature": 0.0, "avg_logprob": -0.14466288956728848, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.005431793164461851}, {"id": 401, "seek": 275660, "start": 2770.8399999999997, "end": 2774.0, "text": " right so it's one of the things where like the science the research the", "tokens": [51076, 558, 370, 309, 311, 472, 295, 264, 721, 689, 411, 264, 3497, 264, 2132, 264, 51234], "temperature": 0.0, "avg_logprob": -0.14466288956728848, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.005431793164461851}, {"id": 402, "seek": 275660, "start": 2774.0, "end": 2780.08, "text": " technology and the product come out to the same day pretty crazy and this is", "tokens": [51234, 2899, 293, 264, 1674, 808, 484, 281, 264, 912, 786, 1238, 3219, 293, 341, 307, 51538], "temperature": 0.0, "avg_logprob": -0.14466288956728848, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.005431793164461851}, {"id": 403, "seek": 275660, "start": 2780.08, "end": 2783.68, "text": " available in Facebook Messenger if you use Facebook Messenger you can you can", "tokens": [51538, 2435, 294, 4384, 34226, 498, 291, 764, 4384, 34226, 291, 393, 291, 393, 51718], "temperature": 0.0, "avg_logprob": -0.14466288956728848, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.005431793164461851}, {"id": 404, "seek": 278368, "start": 2783.68, "end": 2790.8399999999997, "text": " ask to talk to meta AI that is the name of the intelligent virtual assistant", "tokens": [50364, 1029, 281, 751, 281, 19616, 7318, 300, 307, 264, 1315, 295, 264, 13232, 6374, 10994, 50722], "temperature": 0.0, "avg_logprob": -0.1964384979671902, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.008620492182672024}, {"id": 405, "seek": 278368, "start": 2790.8399999999997, "end": 2798.7999999999997, "text": " at meta the generic ones and then if in a font you type backslash sorry forward", "tokens": [50722, 412, 19616, 264, 19577, 2306, 293, 550, 498, 294, 257, 10703, 291, 2010, 646, 10418, 1299, 2597, 2128, 51120], "temperature": 0.0, "avg_logprob": -0.1964384979671902, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.008620492182672024}, {"id": 406, "seek": 278368, "start": 2798.7999999999997, "end": 2805.64, "text": " slash imaging and type a text then the system will produce an image in five", "tokens": [51120, 17330, 25036, 293, 2010, 257, 2487, 550, 264, 1185, 486, 5258, 364, 3256, 294, 1732, 51462], "temperature": 0.0, "avg_logprob": -0.1964384979671902, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.008620492182672024}, {"id": 407, "seek": 278368, "start": 2805.64, "end": 2812.48, "text": " seconds this used to take minutes the results are pretty amazing the same team", "tokens": [51462, 3949, 341, 1143, 281, 747, 2077, 264, 3542, 366, 1238, 2243, 264, 912, 1469, 51804], "temperature": 0.0, "avg_logprob": -0.1964384979671902, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.008620492182672024}, {"id": 408, "seek": 281248, "start": 2812.52, "end": 2818.12, "text": " is is working on synthesizing video this is actually some work from about a year", "tokens": [50366, 307, 307, 1364, 322, 26617, 3319, 960, 341, 307, 767, 512, 589, 490, 466, 257, 1064, 50646], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 409, "seek": 281248, "start": 2818.12, "end": 2822.84, "text": " ago they're making progress on sort of practical things of this type okay but", "tokens": [50646, 2057, 436, 434, 1455, 4205, 322, 1333, 295, 8496, 721, 295, 341, 2010, 1392, 457, 50882], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 410, "seek": 281248, "start": 2822.84, "end": 2827.68, "text": " how do those LLMs those large language models you know that you can talk to how", "tokens": [50882, 577, 360, 729, 441, 43, 26386, 729, 2416, 2856, 5245, 291, 458, 300, 291, 393, 751, 281, 577, 51124], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 411, "seek": 281248, "start": 2827.68, "end": 2833.84, "text": " do they work they are autoregressive right so what that means is they are of", "tokens": [51124, 360, 436, 589, 436, 366, 1476, 418, 3091, 488, 558, 370, 437, 300, 1355, 307, 436, 366, 295, 51432], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 412, "seek": 281248, "start": 2833.84, "end": 2837.04, "text": " the type that I talked about before you take a text and you remove some other", "tokens": [51432, 264, 2010, 300, 286, 2825, 466, 949, 291, 747, 257, 2487, 293, 291, 4159, 512, 661, 51592], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 413, "seek": 281248, "start": 2837.04, "end": 2841.96, "text": " words and then you turn train assistant to predict the words except it's a", "tokens": [51592, 2283, 293, 550, 291, 1261, 3847, 10994, 281, 6069, 264, 2283, 3993, 309, 311, 257, 51838], "temperature": 0.0, "avg_logprob": -0.16200401101793563, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.009773132391273975}, {"id": 414, "seek": 284196, "start": 2841.96, "end": 2846.36, "text": " special case where you only train the system to predict the last word okay to", "tokens": [50364, 2121, 1389, 689, 291, 787, 3847, 264, 1185, 281, 6069, 264, 1036, 1349, 1392, 281, 50584], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 415, "seek": 284196, "start": 2846.36, "end": 2851.52, "text": " take a long piece of text remove the last word and train this gigantic neural", "tokens": [50584, 747, 257, 938, 2522, 295, 2487, 4159, 264, 1036, 1349, 293, 3847, 341, 26800, 18161, 50842], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 416, "seek": 284196, "start": 2851.52, "end": 2857.68, "text": " net to predict that last word and if you train the system this way you can do", "tokens": [50842, 2533, 281, 6069, 300, 1036, 1349, 293, 498, 291, 3847, 264, 1185, 341, 636, 291, 393, 360, 51150], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 417, "seek": 284196, "start": 2857.68, "end": 2862.48, "text": " what's called autoregressive prediction which means give a text predict the last", "tokens": [51150, 437, 311, 1219, 1476, 418, 3091, 488, 17630, 597, 1355, 976, 257, 2487, 6069, 264, 1036, 51390], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 418, "seek": 284196, "start": 2862.48, "end": 2867.12, "text": " word or the next word then inject that into the input and then predict the next", "tokens": [51390, 1349, 420, 264, 958, 1349, 550, 10711, 300, 666, 264, 4846, 293, 550, 6069, 264, 958, 51622], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 419, "seek": 284196, "start": 2867.12, "end": 2871.7200000000003, "text": " next word and then shift that into an input produce the third word etc.", "tokens": [51622, 958, 1349, 293, 550, 5513, 300, 666, 364, 4846, 5258, 264, 2636, 1349, 5183, 13, 51852], "temperature": 0.0, "avg_logprob": -0.1392764338740596, "compression_ratio": 2.0896860986547083, "no_speech_prob": 0.0017053233459591866}, {"id": 420, "seek": 287172, "start": 2871.8799999999997, "end": 2878.3199999999997, "text": " Autoregressive prediction and it's amazing how it works there's a whole", "tokens": [50372, 6049, 418, 3091, 488, 17630, 293, 309, 311, 2243, 577, 309, 1985, 456, 311, 257, 1379, 50694], "temperature": 0.0, "avg_logprob": -0.28839355154135793, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.003915078472346067}, {"id": 421, "seek": 287172, "start": 2878.3199999999997, "end": 2883.8399999999997, "text": " bunch of those models around actually I typed that list a few a couple months", "tokens": [50694, 3840, 295, 729, 5245, 926, 767, 286, 33941, 300, 1329, 257, 1326, 257, 1916, 2493, 50970], "temperature": 0.0, "avg_logprob": -0.28839355154135793, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.003915078472346067}, {"id": 422, "seek": 287172, "start": 2883.8399999999997, "end": 2887.9599999999996, "text": " ago and now there's a whole bunch more but Blunderbot Galactica Lama Lama 2", "tokens": [50970, 2057, 293, 586, 456, 311, 257, 1379, 3840, 544, 457, 2177, 6617, 18870, 7336, 578, 2262, 441, 2404, 441, 2404, 568, 51176], "temperature": 0.0, "avg_logprob": -0.28839355154135793, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.003915078472346067}, {"id": 423, "seek": 287172, "start": 2887.9599999999996, "end": 2894.2799999999997, "text": " from from meta which is actually a open source code Lama that came out in July", "tokens": [51176, 490, 490, 19616, 597, 307, 767, 257, 1269, 4009, 3089, 441, 2404, 300, 1361, 484, 294, 7370, 51492], "temperature": 0.0, "avg_logprob": -0.28839355154135793, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.003915078472346067}, {"id": 424, "seek": 287172, "start": 2894.2799999999997, "end": 2900.3199999999997, "text": " which is basically Lama specialized for generating code Alpaca Lambda Chinchilla", "tokens": [51492, 597, 307, 1936, 441, 2404, 19813, 337, 17746, 3089, 967, 79, 6628, 45691, 4430, 339, 5291, 51794], "temperature": 0.0, "avg_logprob": -0.28839355154135793, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.003915078472346067}, {"id": 425, "seek": 290032, "start": 2900.36, "end": 2904.76, "text": " chai GPT the various incarnations of chai GPT and then there is one that came", "tokens": [50366, 417, 1301, 26039, 51, 264, 3683, 30938, 763, 295, 417, 1301, 26039, 51, 293, 550, 456, 307, 472, 300, 1361, 50586], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 426, "seek": 290032, "start": 2904.76, "end": 2910.04, "text": " out just a few days ago called mistral via a French startup in Paris formed by", "tokens": [50586, 484, 445, 257, 1326, 1708, 2057, 1219, 3544, 2155, 5766, 257, 5522, 18578, 294, 8380, 8693, 538, 50850], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 427, "seek": 290032, "start": 2910.04, "end": 2914.96, "text": " people who used to be at fair and deep end actually that's interesting so", "tokens": [50850, 561, 567, 1143, 281, 312, 412, 3143, 293, 2452, 917, 767, 300, 311, 1880, 370, 51096], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 428, "seek": 290032, "start": 2914.96, "end": 2919.76, "text": " performance is amazing for those systems right we've all been surprised by it but", "tokens": [51096, 3389, 307, 2243, 337, 729, 3652, 558, 321, 600, 439, 668, 6100, 538, 309, 457, 51336], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 429, "seek": 290032, "start": 2919.76, "end": 2922.88, "text": " they do make really really stupid mistakes they don't really understand the", "tokens": [51336, 436, 360, 652, 534, 534, 6631, 8038, 436, 500, 380, 534, 1223, 264, 51492], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 430, "seek": 290032, "start": 2922.88, "end": 2928.7200000000003, "text": " world they they're trained to produce the most likely sequence of words that", "tokens": [51492, 1002, 436, 436, 434, 8895, 281, 5258, 264, 881, 3700, 8310, 295, 2283, 300, 51784], "temperature": 0.0, "avg_logprob": -0.20120294005782516, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0057866135612130165}, {"id": 431, "seek": 292872, "start": 2928.7599999999998, "end": 2931.7599999999998, "text": " follow a particular prompt and then they're kind of fine-tuned to sort of", "tokens": [50366, 1524, 257, 1729, 12391, 293, 550, 436, 434, 733, 295, 2489, 12, 83, 43703, 281, 1333, 295, 50516], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 432, "seek": 292872, "start": 2931.7599999999998, "end": 2935.2799999999997, "text": " work well for particular types of questions but they make factual errors", "tokens": [50516, 589, 731, 337, 1729, 3467, 295, 1651, 457, 436, 652, 48029, 13603, 50692], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 433, "seek": 292872, "start": 2935.2799999999997, "end": 2940.68, "text": " logical errors they are inconsistent they don't really have reasoning abilities", "tokens": [50692, 14978, 13603, 436, 366, 36891, 436, 500, 380, 534, 362, 21577, 11582, 50962], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 434, "seek": 292872, "start": 2940.68, "end": 2947.8799999999997, "text": " it's very easy to kind of chorus them into producing toxic content they really", "tokens": [50962, 309, 311, 588, 1858, 281, 733, 295, 22632, 552, 666, 10501, 12786, 2701, 436, 534, 51322], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 435, "seek": 292872, "start": 2947.8799999999997, "end": 2951.04, "text": " do have a limited knowledge of the underlying reality because they're", "tokens": [51322, 360, 362, 257, 5567, 3601, 295, 264, 14217, 4103, 570, 436, 434, 51480], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 436, "seek": 292872, "start": 2951.04, "end": 2955.7599999999998, "text": " purely trained from text they don't have common sense like a cat can have common", "tokens": [51480, 17491, 8895, 490, 2487, 436, 500, 380, 362, 2689, 2020, 411, 257, 3857, 393, 362, 2689, 51716], "temperature": 0.0, "avg_logprob": -0.1359025507557149, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.0023915593046694994}, {"id": 437, "seek": 295576, "start": 2955.76, "end": 2961.6800000000003, "text": " sense and they can't plan their answer so you can you can play with Lama so", "tokens": [50364, 2020, 293, 436, 393, 380, 1393, 641, 1867, 370, 291, 393, 291, 393, 862, 365, 441, 2404, 370, 50660], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 438, "seek": 295576, "start": 2961.6800000000003, "end": 2967.28, "text": " basically the chatbot I just mentioned meta AI is sort of a productized", "tokens": [50660, 1936, 264, 5081, 18870, 286, 445, 2835, 19616, 7318, 307, 1333, 295, 257, 1674, 1602, 50940], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 439, "seek": 295576, "start": 2967.28, "end": 2972.0400000000004, "text": " version of Lama too if you want and it has various incarnations actually various", "tokens": [50940, 3037, 295, 441, 2404, 886, 498, 291, 528, 293, 309, 575, 3683, 30938, 763, 767, 3683, 51178], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 440, "seek": 295576, "start": 2972.0400000000004, "end": 2976.4, "text": " personas that you can call and there's three models the production model is a", "tokens": [51178, 12019, 300, 291, 393, 818, 293, 456, 311, 1045, 5245, 264, 4265, 2316, 307, 257, 51396], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 441, "seek": 295576, "start": 2976.4, "end": 2980.76, "text": " different one but it's open source you can download it if you're a big enough GPU", "tokens": [51396, 819, 472, 457, 309, 311, 1269, 4009, 291, 393, 5484, 309, 498, 291, 434, 257, 955, 1547, 18407, 51614], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 442, "seek": 295576, "start": 2980.76, "end": 2985.0800000000004, "text": " you can read it on your GPU there's a lot of people working towards running those", "tokens": [51614, 291, 393, 1401, 309, 322, 428, 18407, 456, 311, 257, 688, 295, 561, 1364, 3030, 2614, 729, 51830], "temperature": 0.0, "avg_logprob": -0.18203753918673085, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.006368810776621103}, {"id": 443, "seek": 298508, "start": 2985.08, "end": 2989.4, "text": " models on mobile devices and laptops and things like that and they they can", "tokens": [50364, 5245, 322, 6013, 5759, 293, 27642, 293, 721, 411, 300, 293, 436, 436, 393, 50580], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 444, "seek": 298508, "start": 2989.4, "end": 2993.88, "text": " generate text this is a funny one so in the early days of Lama my colleagues", "tokens": [50580, 8460, 2487, 341, 307, 257, 4074, 472, 370, 294, 264, 2440, 1708, 295, 441, 2404, 452, 7734, 50804], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 445, "seek": 298508, "start": 2993.88, "end": 2999.08, "text": " kind of interrogated that so they typed into Lama did you know that Yanlok", "tokens": [50804, 733, 295, 24871, 770, 300, 370, 436, 33941, 666, 441, 2404, 630, 291, 458, 300, 13633, 75, 453, 51064], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 446, "seek": 298508, "start": 2999.08, "end": 3002.72, "text": " dropped a rap album last year we listened to it and here is what we thought", "tokens": [51064, 8119, 257, 5099, 6030, 1036, 1064, 321, 13207, 281, 309, 293, 510, 307, 437, 321, 1194, 51246], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 447, "seek": 298508, "start": 3002.72, "end": 3010.04, "text": " and this and the system writes a critique of my alleged rap album so they", "tokens": [51246, 293, 341, 293, 264, 1185, 13657, 257, 25673, 295, 452, 26317, 5099, 6030, 370, 436, 51612], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 448, "seek": 298508, "start": 3010.04, "end": 3014.48, "text": " showed this to me and they say is it okay if we put this in the paper and say", "tokens": [51612, 4712, 341, 281, 385, 293, 436, 584, 307, 309, 1392, 498, 321, 829, 341, 294, 264, 3035, 293, 584, 51834], "temperature": 0.0, "avg_logprob": -0.1715393403990079, "compression_ratio": 1.82, "no_speech_prob": 0.0019504096126183867}, {"id": 449, "seek": 301448, "start": 3014.48, "end": 3019.36, "text": " yeah sure no problem but I said like could you do this with jazz because you", "tokens": [50364, 1338, 988, 572, 1154, 457, 286, 848, 411, 727, 291, 360, 341, 365, 15066, 570, 291, 50608], "temperature": 0.0, "avg_logprob": -0.15717955669724798, "compression_ratio": 1.5879396984924623, "no_speech_prob": 0.0011473573977127671}, {"id": 450, "seek": 301448, "start": 3019.36, "end": 3026.52, "text": " know I'm like I'm rap is okay but like I prefer jazz really and they told me yeah", "tokens": [50608, 458, 286, 478, 411, 286, 478, 5099, 307, 1392, 457, 411, 286, 4382, 15066, 534, 293, 436, 1907, 385, 1338, 50966], "temperature": 0.0, "avg_logprob": -0.15717955669724798, "compression_ratio": 1.5879396984924623, "no_speech_prob": 0.0011473573977127671}, {"id": 451, "seek": 301448, "start": 3026.52, "end": 3032.48, "text": " yeah we tried and it didn't work because there's not enough training data for", "tokens": [50966, 1338, 321, 3031, 293, 309, 994, 380, 589, 570, 456, 311, 406, 1547, 3097, 1412, 337, 51264], "temperature": 0.0, "avg_logprob": -0.15717955669724798, "compression_ratio": 1.5879396984924623, "no_speech_prob": 0.0011473573977127671}, {"id": 452, "seek": 301448, "start": 3032.48, "end": 3043.96, "text": " jazz so I cried so as I was saying you can fine-tune the system to sort of play", "tokens": [51264, 15066, 370, 286, 16266, 370, 382, 286, 390, 1566, 291, 393, 2489, 12, 83, 2613, 264, 1185, 281, 1333, 295, 862, 51838], "temperature": 0.0, "avg_logprob": -0.15717955669724798, "compression_ratio": 1.5879396984924623, "no_speech_prob": 0.0011473573977127671}, {"id": 453, "seek": 304396, "start": 3044.0, "end": 3049.96, "text": " different roles and what Mita announced yesterday is that is 28 different", "tokens": [50366, 819, 9604, 293, 437, 376, 2786, 7548, 5186, 307, 300, 307, 7562, 819, 50664], "temperature": 0.0, "avg_logprob": -0.21006607714994455, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.014011240564286709}, {"id": 454, "seek": 304396, "start": 3049.96, "end": 3052.68, "text": " chatbots that are specialized for different applications so think for", "tokens": [50664, 5081, 65, 1971, 300, 366, 19813, 337, 819, 5821, 370, 519, 337, 50800], "temperature": 0.0, "avg_logprob": -0.21006607714994455, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.014011240564286709}, {"id": 455, "seek": 304396, "start": 3052.68, "end": 3058.12, "text": " example you can have Snoop Dogg a rapper be a dungeon master if you are into", "tokens": [50800, 1365, 291, 393, 362, 42902, 404, 13472, 70, 257, 26457, 312, 257, 27919, 4505, 498, 291, 366, 666, 51072], "temperature": 0.0, "avg_logprob": -0.21006607714994455, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.014011240564286709}, {"id": 456, "seek": 304396, "start": 3058.12, "end": 3064.2400000000002, "text": " dungeon and dragon or text adventure games others that are like advisors for", "tokens": [51072, 27919, 293, 12165, 420, 2487, 9868, 2813, 2357, 300, 366, 411, 29136, 337, 51378], "temperature": 0.0, "avg_logprob": -0.21006607714994455, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.014011240564286709}, {"id": 457, "seek": 304396, "start": 3064.2400000000002, "end": 3070.56, "text": " traveling others that are cooks or or sous chefs or whatever so different", "tokens": [51378, 9712, 2357, 300, 366, 30709, 420, 420, 16686, 30191, 420, 2035, 370, 819, 51694], "temperature": 0.0, "avg_logprob": -0.21006607714994455, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.014011240564286709}, {"id": 458, "seek": 307056, "start": 3070.7599999999998, "end": 3077.6, "text": " but those things really suck I mean they really not that great because they", "tokens": [50374, 457, 729, 721, 534, 9967, 286, 914, 436, 534, 406, 300, 869, 570, 436, 50716], "temperature": 0.0, "avg_logprob": -0.16423979783669496, "compression_ratio": 1.9267015706806283, "no_speech_prob": 0.028321368619799614}, {"id": 459, "seek": 307056, "start": 3077.6, "end": 3081.08, "text": " don't understand the world they just manipulate language because they", "tokens": [50716, 500, 380, 1223, 264, 1002, 436, 445, 20459, 2856, 570, 436, 50890], "temperature": 0.0, "avg_logprob": -0.16423979783669496, "compression_ratio": 1.9267015706806283, "no_speech_prob": 0.028321368619799614}, {"id": 460, "seek": 307056, "start": 3081.08, "end": 3084.6, "text": " manipulate language fluently we're fooled into thinking that they are", "tokens": [50890, 20459, 2856, 5029, 2276, 321, 434, 33372, 666, 1953, 300, 436, 366, 51066], "temperature": 0.0, "avg_logprob": -0.16423979783669496, "compression_ratio": 1.9267015706806283, "no_speech_prob": 0.028321368619799614}, {"id": 461, "seek": 307056, "start": 3084.6, "end": 3089.36, "text": " intelligent but they're not intelligent in certain ways but they're not", "tokens": [51066, 13232, 457, 436, 434, 406, 13232, 294, 1629, 2098, 457, 436, 434, 406, 51304], "temperature": 0.0, "avg_logprob": -0.16423979783669496, "compression_ratio": 1.9267015706806283, "no_speech_prob": 0.028321368619799614}, {"id": 462, "seek": 307056, "start": 3089.36, "end": 3095.92, "text": " intelligent in sort of what we think as as human intelligence so you will see if", "tokens": [51304, 13232, 294, 1333, 295, 437, 321, 519, 382, 382, 1952, 7599, 370, 291, 486, 536, 498, 51632], "temperature": 0.0, "avg_logprob": -0.16423979783669496, "compression_ratio": 1.9267015706806283, "no_speech_prob": 0.028321368619799614}, {"id": 463, "seek": 309592, "start": 3095.92, "end": 3101.04, "text": " you go to X from a Twitter or any kind of social networks people who make", "tokens": [50364, 291, 352, 281, 1783, 490, 257, 5794, 420, 604, 733, 295, 2093, 9590, 561, 567, 652, 50620], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 464, "seek": 309592, "start": 3101.04, "end": 3107.0, "text": " posts say oh there is a latest LLM from so-and-so company and you type this and", "tokens": [50620, 12300, 584, 1954, 456, 307, 257, 6792, 441, 43, 44, 490, 370, 12, 474, 12, 539, 2237, 293, 291, 2010, 341, 293, 50918], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 465, "seek": 309592, "start": 3107.0, "end": 3111.28, "text": " it's mind-blowing you know we are this far away from human level intelligence", "tokens": [50918, 309, 311, 1575, 12, 43788, 291, 458, 321, 366, 341, 1400, 1314, 490, 1952, 1496, 7599, 51132], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 466, "seek": 309592, "start": 3111.28, "end": 3116.56, "text": " what I call a GI I hate the term and you know it's for tomorrow like you know all", "tokens": [51132, 437, 286, 818, 257, 26634, 286, 4700, 264, 1433, 293, 291, 458, 309, 311, 337, 4153, 411, 291, 458, 439, 51396], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 467, "seek": 309592, "start": 3116.56, "end": 3120.64, "text": " the naysayers are wrong blah blah blah it's just happening tomorrow they are", "tokens": [51396, 264, 297, 3772, 320, 433, 366, 2085, 12288, 12288, 12288, 309, 311, 445, 2737, 4153, 436, 366, 51600], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 468, "seek": 309592, "start": 3120.64, "end": 3124.88, "text": " wrong okay this those things do not have anything close to human intelligence", "tokens": [51600, 2085, 1392, 341, 729, 721, 360, 406, 362, 1340, 1998, 281, 1952, 7599, 51812], "temperature": 0.0, "avg_logprob": -0.15629524295612918, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.014669169671833515}, {"id": 469, "seek": 312488, "start": 3125.1600000000003, "end": 3129.04, "text": " they appear to do to have to have it because they're trained on so much data", "tokens": [50378, 436, 4204, 281, 360, 281, 362, 281, 362, 309, 570, 436, 434, 8895, 322, 370, 709, 1412, 50572], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 470, "seek": 312488, "start": 3129.04, "end": 3133.12, "text": " that they've accumulated an enormous amount of background knowledge", "tokens": [50572, 300, 436, 600, 31346, 364, 11322, 2372, 295, 3678, 3601, 50776], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 471, "seek": 312488, "start": 3133.12, "end": 3137.84, "text": " approximately that they can regurgitate approximately so whenever they seem", "tokens": [50776, 10447, 300, 436, 393, 1121, 5476, 8086, 10447, 370, 5699, 436, 1643, 51012], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 472, "seek": 312488, "start": 3137.84, "end": 3142.12, "text": " intelligent it's usually because they can do information retrieval in an", "tokens": [51012, 13232, 309, 311, 2673, 570, 436, 393, 360, 1589, 19817, 3337, 294, 364, 51226], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 473, "seek": 312488, "start": 3142.12, "end": 3146.4, "text": " approximate way that sort of looks reasonable but they cannot possibly", "tokens": [51226, 30874, 636, 300, 1333, 295, 1542, 10585, 457, 436, 2644, 6264, 51440], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 474, "seek": 312488, "start": 3146.4, "end": 3150.2400000000002, "text": " understand how the world works because their only training data is text and", "tokens": [51440, 1223, 577, 264, 1002, 1985, 570, 641, 787, 3097, 1412, 307, 2487, 293, 51632], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 475, "seek": 312488, "start": 3150.2400000000002, "end": 3154.4, "text": " most of human knowledge this may surprise you but most of human knowledge has", "tokens": [51632, 881, 295, 1952, 3601, 341, 815, 6365, 291, 457, 881, 295, 1952, 3601, 575, 51840], "temperature": 0.0, "avg_logprob": -0.16224449085739423, "compression_ratio": 1.9328358208955223, "no_speech_prob": 0.00906461663544178}, {"id": 476, "seek": 315440, "start": 3154.44, "end": 3159.44, "text": " nothing to do with language it has to do with our experience with the world", "tokens": [50366, 1825, 281, 360, 365, 2856, 309, 575, 281, 360, 365, 527, 1752, 365, 264, 1002, 50616], "temperature": 0.0, "avg_logprob": -0.17400452068873815, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.002472052350640297}, {"id": 477, "seek": 315440, "start": 3159.44, "end": 3167.96, "text": " every day physics another limitation that people have been pointing out", "tokens": [50616, 633, 786, 10649, 1071, 27432, 300, 561, 362, 668, 12166, 484, 51042], "temperature": 0.0, "avg_logprob": -0.17400452068873815, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.002472052350640297}, {"id": 478, "seek": 315440, "start": 3167.96, "end": 3172.92, "text": " increasingly with various papers is the inability of those LLMs to plan so an", "tokens": [51042, 12980, 365, 3683, 10577, 307, 264, 33162, 295, 729, 441, 43, 26386, 281, 1393, 370, 364, 51290], "temperature": 0.0, "avg_logprob": -0.17400452068873815, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.002472052350640297}, {"id": 479, "seek": 315440, "start": 3172.92, "end": 3178.84, "text": " LLM produces those tokens autoregressively as I explained earlier right they", "tokens": [51290, 441, 43, 44, 14725, 729, 22667, 1476, 418, 3091, 3413, 382, 286, 8825, 3071, 558, 436, 51586], "temperature": 0.0, "avg_logprob": -0.17400452068873815, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.002472052350640297}, {"id": 480, "seek": 315440, "start": 3178.84, "end": 3182.64, "text": " don't plan their answer they just produce one token after the other and", "tokens": [51586, 500, 380, 1393, 641, 1867, 436, 445, 5258, 472, 14862, 934, 264, 661, 293, 51776], "temperature": 0.0, "avg_logprob": -0.17400452068873815, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.002472052350640297}, {"id": 481, "seek": 318264, "start": 3183.04, "end": 3186.3599999999997, "text": " whatever token they produce will determine which token they produce next", "tokens": [50384, 2035, 14862, 436, 5258, 486, 6997, 597, 14862, 436, 5258, 958, 50550], "temperature": 0.0, "avg_logprob": -0.19516440135676685, "compression_ratio": 1.819047619047619, "no_speech_prob": 0.0008145596948452294}, {"id": 482, "seek": 318264, "start": 3186.3599999999997, "end": 3192.96, "text": " because it's autoregressive there is a process by which the system is basically", "tokens": [50550, 570, 309, 311, 1476, 418, 3091, 488, 456, 307, 257, 1399, 538, 597, 264, 1185, 307, 1936, 50880], "temperature": 0.0, "avg_logprob": -0.19516440135676685, "compression_ratio": 1.819047619047619, "no_speech_prob": 0.0008145596948452294}, {"id": 483, "seek": 318264, "start": 3192.96, "end": 3197.3199999999997, "text": " an exponentially divergent process the system makes one mistake that takes it", "tokens": [50880, 364, 37330, 18558, 6930, 1399, 264, 1185, 1669, 472, 6146, 300, 2516, 309, 51098], "temperature": 0.0, "avg_logprob": -0.19516440135676685, "compression_ratio": 1.819047619047619, "no_speech_prob": 0.0008145596948452294}, {"id": 484, "seek": 318264, "start": 3197.3199999999997, "end": 3205.52, "text": " out of the kind of correct set of answers it cannot recover and so this", "tokens": [51098, 484, 295, 264, 733, 295, 3006, 992, 295, 6338, 309, 2644, 8114, 293, 370, 341, 51508], "temperature": 0.0, "avg_logprob": -0.19516440135676685, "compression_ratio": 1.819047619047619, "no_speech_prob": 0.0008145596948452294}, {"id": 485, "seek": 318264, "start": 3205.52, "end": 3210.72, "text": " entire architecture of autoregressive prediction in my opinion is is inherently", "tokens": [51508, 2302, 9482, 295, 1476, 418, 3091, 488, 17630, 294, 452, 4800, 307, 307, 27993, 51768], "temperature": 0.0, "avg_logprob": -0.19516440135676685, "compression_ratio": 1.819047619047619, "no_speech_prob": 0.0008145596948452294}, {"id": 486, "seek": 321072, "start": 3210.72, "end": 3215.2799999999997, "text": " flawed and my prediction is that within a few years nobody in their right mind", "tokens": [50364, 38823, 293, 452, 17630, 307, 300, 1951, 257, 1326, 924, 5079, 294, 641, 558, 1575, 50592], "temperature": 0.0, "avg_logprob": -0.17850528444562638, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0027371051255613565}, {"id": 487, "seek": 321072, "start": 3215.2799999999997, "end": 3220.3199999999997, "text": " would use autoregressive LLMs okay everybody is working towards something", "tokens": [50592, 576, 764, 1476, 418, 3091, 488, 441, 43, 26386, 1392, 2201, 307, 1364, 3030, 746, 50844], "temperature": 0.0, "avg_logprob": -0.17850528444562638, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0027371051255613565}, {"id": 488, "seek": 321072, "start": 3220.3199999999997, "end": 3227.48, "text": " better because those things are major flaws now what's the issue though is", "tokens": [50844, 1101, 570, 729, 721, 366, 2563, 27108, 586, 437, 311, 264, 2734, 1673, 307, 51202], "temperature": 0.0, "avg_logprob": -0.17850528444562638, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0027371051255613565}, {"id": 489, "seek": 321072, "start": 3227.48, "end": 3231.9599999999996, "text": " that there's a lot of people who are scared about future AI systems that may", "tokens": [51202, 300, 456, 311, 257, 688, 295, 561, 567, 366, 5338, 466, 2027, 7318, 3652, 300, 815, 51426], "temperature": 0.0, "avg_logprob": -0.17850528444562638, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0027371051255613565}, {"id": 490, "seek": 321072, "start": 3231.9599999999996, "end": 3236.68, "text": " have the may attain attain human intelligence or or be more intelligent", "tokens": [51426, 362, 264, 815, 23766, 23766, 1952, 7599, 420, 420, 312, 544, 13232, 51662], "temperature": 0.0, "avg_logprob": -0.17850528444562638, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0027371051255613565}, {"id": 491, "seek": 323668, "start": 3236.68, "end": 3241.72, "text": " than humans and if you extrapolate from what LLMs currently do you might think", "tokens": [50364, 813, 6255, 293, 498, 291, 48224, 473, 490, 437, 441, 43, 26386, 4362, 360, 291, 1062, 519, 50616], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 492, "seek": 323668, "start": 3241.72, "end": 3244.8399999999997, "text": " well it's gonna be very dangerous because those systems cannot really be", "tokens": [50616, 731, 309, 311, 799, 312, 588, 5795, 570, 729, 3652, 2644, 534, 312, 50772], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 493, "seek": 323668, "start": 3244.8399999999997, "end": 3249.56, "text": " controlled they can spew complete nonsense they can be jail broken blah", "tokens": [50772, 10164, 436, 393, 768, 86, 3566, 14925, 436, 393, 312, 10511, 5463, 12288, 51008], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 494, "seek": 323668, "start": 3249.56, "end": 3253.6, "text": " blah if they are smart they might be dangerous that's a big mistake future", "tokens": [51008, 12288, 498, 436, 366, 4069, 436, 1062, 312, 5795, 300, 311, 257, 955, 6146, 2027, 51210], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 495, "seek": 323668, "start": 3253.6, "end": 3257.72, "text": " AI systems will not be using this particular blueprint they're not going", "tokens": [51210, 7318, 3652, 486, 406, 312, 1228, 341, 1729, 35868, 436, 434, 406, 516, 51416], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 496, "seek": 323668, "start": 3257.72, "end": 3262.64, "text": " to be autoregressive LLMs okay and I'm going to tell you what I think it will", "tokens": [51416, 281, 312, 1476, 418, 3091, 488, 441, 43, 26386, 1392, 293, 286, 478, 516, 281, 980, 291, 437, 286, 519, 309, 486, 51662], "temperature": 0.0, "avg_logprob": -0.15903834761860214, "compression_ratio": 1.7072243346007605, "no_speech_prob": 0.008678236044943333}, {"id": 497, "seek": 326264, "start": 3262.64, "end": 3273.2, "text": " be okay so autoregressive LLMs suck I just said all that no reasoning no", "tokens": [50364, 312, 1392, 370, 1476, 418, 3091, 488, 441, 43, 26386, 9967, 286, 445, 848, 439, 300, 572, 21577, 572, 50892], "temperature": 0.0, "avg_logprob": -0.16754808941402952, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.003921477124094963}, {"id": 498, "seek": 326264, "start": 3273.2, "end": 3279.24, "text": " planning essentially right the amount of computation devoted to producing a", "tokens": [50892, 5038, 4476, 558, 264, 2372, 295, 24903, 21815, 281, 10501, 257, 51194], "temperature": 0.0, "avg_logprob": -0.16754808941402952, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.003921477124094963}, {"id": 499, "seek": 326264, "start": 3279.24, "end": 3284.48, "text": " single token by an LLM autoregressive LLM is constant there's a constant amount", "tokens": [51194, 2167, 14862, 538, 364, 441, 43, 44, 1476, 418, 3091, 488, 441, 43, 44, 307, 5754, 456, 311, 257, 5754, 2372, 51456], "temperature": 0.0, "avg_logprob": -0.16754808941402952, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.003921477124094963}, {"id": 500, "seek": 326264, "start": 3284.48, "end": 3288.7999999999997, "text": " of computation per token produced so there's no possibility for the system", "tokens": [51456, 295, 24903, 680, 14862, 7126, 370, 456, 311, 572, 7959, 337, 264, 1185, 51672], "temperature": 0.0, "avg_logprob": -0.16754808941402952, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.003921477124094963}, {"id": 501, "seek": 328880, "start": 3288.84, "end": 3293.84, "text": " to for example think about something for a long time before saying something it's", "tokens": [50366, 281, 337, 1365, 519, 466, 746, 337, 257, 938, 565, 949, 1566, 746, 309, 311, 50616], "temperature": 0.0, "avg_logprob": -0.16301168714250838, "compression_ratio": 1.596938775510204, "no_speech_prob": 0.006846604403108358}, {"id": 502, "seek": 328880, "start": 3293.84, "end": 3303.5600000000004, "text": " cannot do that by construction so machines do not of this type do not", "tokens": [50616, 2644, 360, 300, 538, 6435, 370, 8379, 360, 406, 295, 341, 2010, 360, 406, 51102], "temperature": 0.0, "avg_logprob": -0.16301168714250838, "compression_ratio": 1.596938775510204, "no_speech_prob": 0.006846604403108358}, {"id": 503, "seek": 328880, "start": 3303.5600000000004, "end": 3309.2000000000003, "text": " learn how the world works unlike animal and animals and humans they will not be", "tokens": [51102, 1466, 577, 264, 1002, 1985, 8343, 5496, 293, 4882, 293, 6255, 436, 486, 406, 312, 51384], "temperature": 0.0, "avg_logprob": -0.16301168714250838, "compression_ratio": 1.596938775510204, "no_speech_prob": 0.006846604403108358}, {"id": 504, "seek": 328880, "start": 3309.2000000000003, "end": 3316.28, "text": " able to approach human intelligence okay so whatever I don't know the CEO of some", "tokens": [51384, 1075, 281, 3109, 1952, 7599, 1392, 370, 2035, 286, 500, 380, 458, 264, 9282, 295, 512, 51738], "temperature": 0.0, "avg_logprob": -0.16301168714250838, "compression_ratio": 1.596938775510204, "no_speech_prob": 0.006846604403108358}, {"id": 505, "seek": 331628, "start": 3316.32, "end": 3320.48, "text": " company that thinks they have the best LLM in the world tells you a GI is just", "tokens": [50366, 2237, 300, 7309, 436, 362, 264, 1151, 441, 43, 44, 294, 264, 1002, 5112, 291, 257, 26634, 307, 445, 50574], "temperature": 0.0, "avg_logprob": -0.17388996396745954, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.002849611919373274}, {"id": 506, "seek": 331628, "start": 3320.48, "end": 3327.0800000000004, "text": " around the corner don't believe that we're still missing some major advances", "tokens": [50574, 926, 264, 4538, 500, 380, 1697, 300, 321, 434, 920, 5361, 512, 2563, 25297, 50904], "temperature": 0.0, "avg_logprob": -0.17388996396745954, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.002849611919373274}, {"id": 507, "seek": 331628, "start": 3327.0800000000004, "end": 3335.84, "text": " but there is absolutely no question that eventually machines will surpass human", "tokens": [50904, 457, 456, 307, 3122, 572, 1168, 300, 4728, 8379, 486, 27650, 1952, 51342], "temperature": 0.0, "avg_logprob": -0.17388996396745954, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.002849611919373274}, {"id": 508, "seek": 331628, "start": 3335.84, "end": 3342.1600000000003, "text": " intelligence in all domains okay it's basically no doubt about that and it's", "tokens": [51342, 7599, 294, 439, 25514, 1392, 309, 311, 1936, 572, 6385, 466, 300, 293, 309, 311, 51658], "temperature": 0.0, "avg_logprob": -0.17388996396745954, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.002849611919373274}, {"id": 509, "seek": 334216, "start": 3342.2, "end": 3350.44, "text": " going to happen during the lifetime of most people here maybe not me you know I", "tokens": [50366, 516, 281, 1051, 1830, 264, 11364, 295, 881, 561, 510, 1310, 406, 385, 291, 458, 286, 50778], "temperature": 0.0, "avg_logprob": -0.15313036176893446, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.0018920513102784753}, {"id": 510, "seek": 334216, "start": 3350.44, "end": 3357.24, "text": " might take a few decades there's no question it's going to happen so these", "tokens": [50778, 1062, 747, 257, 1326, 7878, 456, 311, 572, 1168, 309, 311, 516, 281, 1051, 370, 613, 51118], "temperature": 0.0, "avg_logprob": -0.15313036176893446, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.0018920513102784753}, {"id": 511, "seek": 334216, "start": 3357.24, "end": 3362.68, "text": " are I think the biggest challenges for AI going forward learning representations", "tokens": [51118, 366, 286, 519, 264, 3880, 4759, 337, 7318, 516, 2128, 2539, 33358, 51390], "temperature": 0.0, "avg_logprob": -0.15313036176893446, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.0018920513102784753}, {"id": 512, "seek": 334216, "start": 3362.68, "end": 3368.0, "text": " and predictive models of the world and I'll tell you why in a minute and that's", "tokens": [51390, 293, 35521, 5245, 295, 264, 1002, 293, 286, 603, 980, 291, 983, 294, 257, 3456, 293, 300, 311, 51656], "temperature": 0.0, "avg_logprob": -0.15313036176893446, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.0018920513102784753}, {"id": 513, "seek": 334216, "start": 3368.0, "end": 3371.16, "text": " what's addressed by self-supervised learning so we have good handle on this", "tokens": [51656, 437, 311, 13847, 538, 2698, 12, 48172, 24420, 2539, 370, 321, 362, 665, 4813, 322, 341, 51814], "temperature": 0.0, "avg_logprob": -0.15313036176893446, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.0018920513102784753}, {"id": 514, "seek": 337116, "start": 3371.2, "end": 3377.56, "text": " at least for text not so much for video learning to reason so if some of you know", "tokens": [50366, 412, 1935, 337, 2487, 406, 370, 709, 337, 960, 2539, 281, 1778, 370, 498, 512, 295, 291, 458, 50684], "temperature": 0.0, "avg_logprob": -0.1966306875040243, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.00541973952203989}, {"id": 515, "seek": 337116, "start": 3377.56, "end": 3381.68, "text": " about Daniel Kahneman's theory of system one system two sort of subconscious", "tokens": [50684, 466, 8033, 591, 12140, 15023, 311, 5261, 295, 1185, 472, 1185, 732, 1333, 295, 27389, 50890], "temperature": 0.0, "avg_logprob": -0.1966306875040243, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.00541973952203989}, {"id": 516, "seek": 337116, "start": 3381.68, "end": 3384.92, "text": " things that we do without thinking and then conscious things that we have to", "tokens": [50890, 721, 300, 321, 360, 1553, 1953, 293, 550, 6648, 721, 300, 321, 362, 281, 51052], "temperature": 0.0, "avg_logprob": -0.1966306875040243, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.00541973952203989}, {"id": 517, "seek": 337116, "start": 3384.92, "end": 3391.04, "text": " focus our attention on LLMs currently can do system one but not system two we", "tokens": [51052, 1879, 527, 3202, 322, 441, 43, 26386, 4362, 393, 360, 1185, 472, 457, 406, 1185, 732, 321, 51358], "temperature": 0.0, "avg_logprob": -0.1966306875040243, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.00541973952203989}, {"id": 518, "seek": 337116, "start": 3391.04, "end": 3395.64, "text": " need to build AI systems that are capable of reasoning of the type that Daniel", "tokens": [51358, 643, 281, 1322, 7318, 3652, 300, 366, 8189, 295, 21577, 295, 264, 2010, 300, 8033, 51588], "temperature": 0.0, "avg_logprob": -0.1966306875040243, "compression_ratio": 1.757847533632287, "no_speech_prob": 0.00541973952203989}, {"id": 519, "seek": 339564, "start": 3395.7999999999997, "end": 3401.4, "text": " Kahneman calls system two is a Nobel Prize winning well he won the Nobel Prize", "tokens": [50372, 591, 12140, 15023, 5498, 1185, 732, 307, 257, 24611, 22604, 8224, 731, 415, 1582, 264, 24611, 22604, 50652], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 520, "seek": 339564, "start": 3401.4, "end": 3409.68, "text": " in economics but is a psychologist and one possible path towards a solution", "tokens": [50652, 294, 14564, 457, 307, 257, 29514, 293, 472, 1944, 3100, 3030, 257, 3827, 51066], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 521, "seek": 339564, "start": 3409.68, "end": 3413.3199999999997, "text": " that I've been proposing for about a year now you're gonna have is what I call", "tokens": [51066, 300, 286, 600, 668, 29939, 337, 466, 257, 1064, 586, 291, 434, 799, 362, 307, 437, 286, 818, 51248], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 522, "seek": 339564, "start": 3413.3199999999997, "end": 3417.6, "text": " this objective driven AI so this paper I put on open review it's not on archive", "tokens": [51248, 341, 10024, 9555, 7318, 370, 341, 3035, 286, 829, 322, 1269, 3131, 309, 311, 406, 322, 23507, 51462], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 523, "seek": 339564, "start": 3417.6, "end": 3421.24, "text": " it's an open review because on open review you can make comments and and this", "tokens": [51462, 309, 311, 364, 1269, 3131, 570, 322, 1269, 3131, 291, 393, 652, 3053, 293, 293, 341, 51644], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 524, "seek": 339564, "start": 3421.24, "end": 3424.7999999999997, "text": " is a working document more than a kind of finished paper if you want it's long", "tokens": [51644, 307, 257, 1364, 4166, 544, 813, 257, 733, 295, 4335, 3035, 498, 291, 528, 309, 311, 938, 51822], "temperature": 0.0, "avg_logprob": -0.19138448578970774, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.005176224745810032}, {"id": 525, "seek": 342480, "start": 3424.84, "end": 3428.36, "text": " though you can also listen to technical talks I've given about this are a", "tokens": [50366, 1673, 291, 393, 611, 2140, 281, 6191, 6686, 286, 600, 2212, 466, 341, 366, 257, 50542], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 526, "seek": 342480, "start": 3428.36, "end": 3433.36, "text": " little more technical than the current one and it's based on this idea of a", "tokens": [50542, 707, 544, 6191, 813, 264, 2190, 472, 293, 309, 311, 2361, 322, 341, 1558, 295, 257, 50792], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 527, "seek": 342480, "start": 3433.36, "end": 3438.6400000000003, "text": " modular cognitive architecture where you have a system composed of multiple", "tokens": [50792, 31111, 15605, 9482, 689, 291, 362, 257, 1185, 18204, 295, 3866, 51056], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 528, "seek": 342480, "start": 3438.6400000000003, "end": 3445.0, "text": " modules first module be the perception so it's represented overlaid over the", "tokens": [51056, 16679, 700, 10088, 312, 264, 12860, 370, 309, 311, 10379, 670, 875, 327, 670, 264, 51374], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 529, "seek": 342480, "start": 3445.0, "end": 3448.8, "text": " back of the brain because in the human brain perception is in the back so", "tokens": [51374, 646, 295, 264, 3567, 570, 294, 264, 1952, 3567, 12860, 307, 294, 264, 646, 370, 51564], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 530, "seek": 342480, "start": 3448.8, "end": 3454.28, "text": " perception basically perceives the world and then constructs an estimate of the", "tokens": [51564, 12860, 1936, 9016, 1539, 264, 1002, 293, 550, 7690, 82, 364, 12539, 295, 264, 51838], "temperature": 0.0, "avg_logprob": -0.1316869354248047, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.004363649059087038}, {"id": 531, "seek": 345428, "start": 3454.28, "end": 3458.36, "text": " state of the world right so it produces an estimate of the state of the world", "tokens": [50364, 1785, 295, 264, 1002, 558, 370, 309, 14725, 364, 12539, 295, 264, 1785, 295, 264, 1002, 50568], "temperature": 0.0, "avg_logprob": -0.17319157479823322, "compression_ratio": 1.915, "no_speech_prob": 0.002195937093347311}, {"id": 532, "seek": 345428, "start": 3458.36, "end": 3463.52, "text": " perhaps it needs to combine this with the content of a memory that contains you", "tokens": [50568, 4317, 309, 2203, 281, 10432, 341, 365, 264, 2701, 295, 257, 4675, 300, 8306, 291, 50826], "temperature": 0.0, "avg_logprob": -0.17319157479823322, "compression_ratio": 1.915, "no_speech_prob": 0.002195937093347311}, {"id": 533, "seek": 345428, "start": 3463.52, "end": 3467.48, "text": " know other information about the state of the world that is not currently", "tokens": [50826, 458, 661, 1589, 466, 264, 1785, 295, 264, 1002, 300, 307, 406, 4362, 51024], "temperature": 0.0, "avg_logprob": -0.17319157479823322, "compression_ratio": 1.915, "no_speech_prob": 0.002195937093347311}, {"id": 534, "seek": 345428, "start": 3467.48, "end": 3472.48, "text": " perceptible and then that goes into a world model and the role of the world", "tokens": [51024, 43276, 964, 293, 550, 300, 1709, 666, 257, 1002, 2316, 293, 264, 3090, 295, 264, 1002, 51274], "temperature": 0.0, "avg_logprob": -0.17319157479823322, "compression_ratio": 1.915, "no_speech_prob": 0.002195937093347311}, {"id": 535, "seek": 345428, "start": 3472.48, "end": 3479.88, "text": " model is to imagine the outcome of a sequence of actions okay so the system", "tokens": [51274, 2316, 307, 281, 3811, 264, 9700, 295, 257, 8310, 295, 5909, 1392, 370, 264, 1185, 51644], "temperature": 0.0, "avg_logprob": -0.17319157479823322, "compression_ratio": 1.915, "no_speech_prob": 0.002195937093347311}, {"id": 536, "seek": 347988, "start": 3479.92, "end": 3484.1600000000003, "text": " can imagine a sequence of actions that's the role of the actor the yellow", "tokens": [50366, 393, 3811, 257, 8310, 295, 5909, 300, 311, 264, 3090, 295, 264, 8747, 264, 5566, 50578], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 537, "seek": 347988, "start": 3484.1600000000003, "end": 3488.96, "text": " module so the actor imagines a sequence of actions fits that to the world model", "tokens": [50578, 10088, 370, 264, 8747, 2576, 1652, 257, 8310, 295, 5909, 9001, 300, 281, 264, 1002, 2316, 50818], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 538, "seek": 347988, "start": 3488.96, "end": 3492.6, "text": " the world model knows the current state of the world and what the world model", "tokens": [50818, 264, 1002, 2316, 3255, 264, 2190, 1785, 295, 264, 1002, 293, 437, 264, 1002, 2316, 51000], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 539, "seek": 347988, "start": 3492.6, "end": 3496.88, "text": " predicts is the future state of the world that will result from that sequence", "tokens": [51000, 6069, 82, 307, 264, 2027, 1785, 295, 264, 1002, 300, 486, 1874, 490, 300, 8310, 51214], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 540, "seek": 347988, "start": 3496.88, "end": 3502.12, "text": " of actions now that cannot be a perfectly exact prediction because the", "tokens": [51214, 295, 5909, 586, 300, 2644, 312, 257, 6239, 1900, 17630, 570, 264, 51476], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 541, "seek": 347988, "start": 3502.12, "end": 3509.2000000000003, "text": " world is not entirely predictable but that's the the the role of the world", "tokens": [51476, 1002, 307, 406, 7696, 27737, 457, 300, 311, 264, 264, 264, 3090, 295, 264, 1002, 51830], "temperature": 0.0, "avg_logprob": -0.15871947419409657, "compression_ratio": 2.2524752475247523, "no_speech_prob": 0.0016712989890947938}, {"id": 542, "seek": 350920, "start": 3509.24, "end": 3513.7599999999998, "text": " model and then the entire purpose of the system is to figure out a particular", "tokens": [50366, 2316, 293, 550, 264, 2302, 4334, 295, 264, 1185, 307, 281, 2573, 484, 257, 1729, 50592], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 543, "seek": 350920, "start": 3513.7599999999998, "end": 3518.96, "text": " sequence of actions that will predict a state of the world that satisfies a", "tokens": [50592, 8310, 295, 5909, 300, 486, 6069, 257, 1785, 295, 264, 1002, 300, 44271, 257, 50852], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 544, "seek": 350920, "start": 3518.96, "end": 3524.12, "text": " certain number of constraints that are implemented by the cost module so the", "tokens": [50852, 1629, 1230, 295, 18491, 300, 366, 12270, 538, 264, 2063, 10088, 370, 264, 51110], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 545, "seek": 350920, "start": 3524.12, "end": 3529.68, "text": " red module that you see this cost module that that's the drive of the system", "tokens": [51110, 2182, 10088, 300, 291, 536, 341, 2063, 10088, 300, 300, 311, 264, 3332, 295, 264, 1185, 51388], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 546, "seek": 350920, "start": 3529.68, "end": 3534.4399999999996, "text": " that's the the current goal of the system if you want and the entire purpose of", "tokens": [51388, 300, 311, 264, 264, 2190, 3387, 295, 264, 1185, 498, 291, 528, 293, 264, 2302, 4334, 295, 51626], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 547, "seek": 350920, "start": 3534.4399999999996, "end": 3538.3599999999997, "text": " the system so imagine this module as getting the predictions from the world", "tokens": [51626, 264, 1185, 370, 3811, 341, 10088, 382, 1242, 264, 21264, 490, 264, 1002, 51822], "temperature": 0.0, "avg_logprob": -0.13907263325709923, "compression_ratio": 2.0669642857142856, "no_speech_prob": 0.001406082883477211}, {"id": 548, "seek": 353836, "start": 3538.36, "end": 3544.76, "text": " model and then computing a cost for it right so basically it computes the degree", "tokens": [50364, 2316, 293, 550, 15866, 257, 2063, 337, 309, 558, 370, 1936, 309, 715, 1819, 264, 4314, 50684], "temperature": 0.0, "avg_logprob": -0.1435565837593966, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.0010799112496897578}, {"id": 549, "seek": 353836, "start": 3544.76, "end": 3552.0, "text": " of in comfort of the system discomfort and what the system does is that it", "tokens": [50684, 295, 294, 3400, 295, 264, 1185, 28552, 293, 437, 264, 1185, 775, 307, 300, 309, 51046], "temperature": 0.0, "avg_logprob": -0.1435565837593966, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.0010799112496897578}, {"id": 550, "seek": 353836, "start": 3552.0, "end": 3555.7200000000003, "text": " figures out internally a sequence of actions so the actor does that it figures", "tokens": [51046, 9624, 484, 19501, 257, 8310, 295, 5909, 370, 264, 8747, 775, 300, 309, 9624, 51232], "temperature": 0.0, "avg_logprob": -0.1435565837593966, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.0010799112496897578}, {"id": 551, "seek": 353836, "start": 3555.7200000000003, "end": 3558.7200000000003, "text": " out a sequence of actions that will minimize its cost according to the", "tokens": [51232, 484, 257, 8310, 295, 5909, 300, 486, 17522, 1080, 2063, 4650, 281, 264, 51382], "temperature": 0.0, "avg_logprob": -0.1435565837593966, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.0010799112496897578}, {"id": 552, "seek": 353836, "start": 3558.7200000000003, "end": 3566.04, "text": " predictions of the world model okay and this is very much system 2 type it's", "tokens": [51382, 21264, 295, 264, 1002, 2316, 1392, 293, 341, 307, 588, 709, 1185, 568, 2010, 309, 311, 51748], "temperature": 0.0, "avg_logprob": -0.1435565837593966, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.0010799112496897578}, {"id": 553, "seek": 356604, "start": 3566.04, "end": 3569.96, "text": " very similar to what you know people do classically in optimal control it's", "tokens": [50364, 588, 2531, 281, 437, 291, 458, 561, 360, 1508, 984, 294, 16252, 1969, 309, 311, 50560], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 554, "seek": 356604, "start": 3569.96, "end": 3574.72, "text": " called model predictive control and it's really like this right observe the state", "tokens": [50560, 1219, 2316, 35521, 1969, 293, 309, 311, 534, 411, 341, 558, 11441, 264, 1785, 50798], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 555, "seek": 356604, "start": 3574.72, "end": 3578.4, "text": " of the world get an initial world state representation combine that with what", "tokens": [50798, 295, 264, 1002, 483, 364, 5883, 1002, 1785, 10290, 10432, 300, 365, 437, 50982], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 556, "seek": 356604, "start": 3578.4, "end": 3581.7599999999998, "text": " you think about the state of the world from your memory feed a sequence of", "tokens": [50982, 291, 519, 466, 264, 1785, 295, 264, 1002, 490, 428, 4675, 3154, 257, 8310, 295, 51150], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 557, "seek": 356604, "start": 3581.7599999999998, "end": 3584.92, "text": " actions to your world model and ask the world model to predict where the final", "tokens": [51150, 5909, 281, 428, 1002, 2316, 293, 1029, 264, 1002, 2316, 281, 6069, 689, 264, 2572, 51308], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 558, "seek": 356604, "start": 3584.92, "end": 3588.56, "text": " state will be then feed that to your objectives the objectives might", "tokens": [51308, 1785, 486, 312, 550, 3154, 300, 281, 428, 15961, 264, 15961, 1062, 51490], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 559, "seek": 356604, "start": 3588.56, "end": 3593.72, "text": " implement the goal that the system has set for itself or that you set it for", "tokens": [51490, 4445, 264, 3387, 300, 264, 1185, 575, 992, 337, 2564, 420, 300, 291, 992, 309, 337, 51748], "temperature": 0.0, "avg_logprob": -0.14301425013048896, "compression_ratio": 1.9669117647058822, "no_speech_prob": 0.009537378326058388}, {"id": 560, "seek": 359372, "start": 3593.7599999999998, "end": 3598.8399999999997, "text": " it but also you can have a number of guardrails so might be a guardrails if", "tokens": [50366, 309, 457, 611, 291, 393, 362, 257, 1230, 295, 6290, 424, 4174, 370, 1062, 312, 257, 6290, 424, 4174, 498, 50620], "temperature": 0.0, "avg_logprob": -0.1609950844122439, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00911098811775446}, {"id": 561, "seek": 359372, "start": 3598.8399999999997, "end": 3605.9199999999996, "text": " we have a domestic robot that is cooking has a knife in its hand because it's", "tokens": [50620, 321, 362, 257, 10939, 7881, 300, 307, 6361, 575, 257, 7976, 294, 1080, 1011, 570, 309, 311, 50974], "temperature": 0.0, "avg_logprob": -0.1609950844122439, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00911098811775446}, {"id": 562, "seek": 359372, "start": 3605.9199999999996, "end": 3611.52, "text": " cutting onions or whatever you might have a cost that says if you have a knife", "tokens": [50974, 6492, 13146, 420, 2035, 291, 1062, 362, 257, 2063, 300, 1619, 498, 291, 362, 257, 7976, 51254], "temperature": 0.0, "avg_logprob": -0.1609950844122439, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00911098811775446}, {"id": 563, "seek": 359372, "start": 3611.52, "end": 3616.8399999999997, "text": " in your hand and there are people around you don't move your hand too fast okay", "tokens": [51254, 294, 428, 1011, 293, 456, 366, 561, 926, 291, 500, 380, 1286, 428, 1011, 886, 2370, 1392, 51520], "temperature": 0.0, "avg_logprob": -0.1609950844122439, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00911098811775446}, {"id": 564, "seek": 359372, "start": 3616.8399999999997, "end": 3621.9599999999996, "text": " don't flail your arms right so maybe dangerous so you can imagine all kinds", "tokens": [51520, 500, 380, 932, 864, 428, 5812, 558, 370, 1310, 5795, 370, 291, 393, 3811, 439, 3685, 51776], "temperature": 0.0, "avg_logprob": -0.1609950844122439, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00911098811775446}, {"id": 565, "seek": 362196, "start": 3622.0, "end": 3628.08, "text": " of guardrails of this type to basically ensure the safety of the of the system and", "tokens": [50366, 295, 6290, 424, 4174, 295, 341, 2010, 281, 1936, 5586, 264, 4514, 295, 264, 295, 264, 1185, 293, 50670], "temperature": 0.0, "avg_logprob": -0.19176545350447946, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009056968614459038}, {"id": 566, "seek": 362196, "start": 3628.08, "end": 3631.36, "text": " the system has no choice but satisfy those because they are satisfied at", "tokens": [50670, 264, 1185, 575, 572, 3922, 457, 19319, 729, 570, 436, 366, 11239, 412, 50834], "temperature": 0.0, "avg_logprob": -0.19176545350447946, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009056968614459038}, {"id": 567, "seek": 362196, "start": 3631.36, "end": 3637.68, "text": " inference time they're not it's not like RLHF for LLMs reinforcement learning", "tokens": [50834, 38253, 565, 436, 434, 406, 309, 311, 406, 411, 497, 43, 39, 37, 337, 441, 43, 26386, 29280, 2539, 51150], "temperature": 0.0, "avg_logprob": -0.19176545350447946, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009056968614459038}, {"id": 568, "seek": 362196, "start": 3637.68, "end": 3643.32, "text": " through human feedback where it's a it's a training time fine-tuning to make", "tokens": [51150, 807, 1952, 5824, 689, 309, 311, 257, 309, 311, 257, 3097, 565, 2489, 12, 83, 37726, 281, 652, 51432], "temperature": 0.0, "avg_logprob": -0.19176545350447946, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009056968614459038}, {"id": 569, "seek": 362196, "start": 3643.32, "end": 3649.44, "text": " sure the system produces only safe behavior the system can always produce", "tokens": [51432, 988, 264, 1185, 14725, 787, 3273, 5223, 264, 1185, 393, 1009, 5258, 51738], "temperature": 0.0, "avg_logprob": -0.19176545350447946, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009056968614459038}, {"id": 570, "seek": 364944, "start": 3649.6, "end": 3654.2000000000003, "text": " unsafe behavior by you know being prompted something that the the people", "tokens": [50372, 35948, 5223, 538, 291, 458, 885, 31042, 746, 300, 264, 264, 561, 50602], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 571, "seek": 364944, "start": 3654.2000000000003, "end": 3657.96, "text": " training it didn't think of it didn't think about here that's impossible the", "tokens": [50602, 3097, 309, 994, 380, 519, 295, 309, 994, 380, 519, 466, 510, 300, 311, 6243, 264, 50790], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 572, "seek": 364944, "start": 3657.96, "end": 3661.08, "text": " system cannot produce a sequence of actions that will not satisfy the", "tokens": [50790, 1185, 2644, 5258, 257, 8310, 295, 5909, 300, 486, 406, 19319, 264, 50946], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 573, "seek": 364944, "start": 3661.08, "end": 3666.04, "text": " guardrails according to the world model so those systems would be intrinsically", "tokens": [50946, 6290, 424, 4174, 4650, 281, 264, 1002, 2316, 370, 729, 3652, 576, 312, 28621, 984, 51194], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 574, "seek": 364944, "start": 3666.04, "end": 3673.16, "text": " safe provided two things provided that the guardrail objectives guarantee the", "tokens": [51194, 3273, 5649, 732, 721, 5649, 300, 264, 6290, 44765, 15961, 10815, 264, 51550], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 575, "seek": 364944, "start": 3673.16, "end": 3677.7200000000003, "text": " safety and that's complicated also provided that the world model is accurate", "tokens": [51550, 4514, 293, 300, 311, 6179, 611, 5649, 300, 264, 1002, 2316, 307, 8559, 51778], "temperature": 0.0, "avg_logprob": -0.14094890432154877, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0025749464984983206}, {"id": 576, "seek": 367772, "start": 3677.7599999999998, "end": 3682.2799999999997, "text": " and that's also complicated so you can imagine something like this that works", "tokens": [50366, 293, 300, 311, 611, 6179, 370, 291, 393, 3811, 746, 411, 341, 300, 1985, 50592], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 577, "seek": 367772, "start": 3682.2799999999997, "end": 3687.3999999999996, "text": " over time so that you know you can have a sequence for example in this case", "tokens": [50592, 670, 565, 370, 300, 291, 458, 291, 393, 362, 257, 8310, 337, 1365, 294, 341, 1389, 50848], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 578, "seek": 367772, "start": 3687.3999999999996, "end": 3692.52, "text": " sequence of two actions you can have and again this is very similar to what", "tokens": [50848, 8310, 295, 732, 5909, 291, 393, 362, 293, 797, 341, 307, 588, 2531, 281, 437, 51104], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 579, "seek": 367772, "start": 3692.52, "end": 3696.72, "text": " control theory is called model predictive control except here we're", "tokens": [51104, 1969, 5261, 307, 1219, 2316, 35521, 1969, 3993, 510, 321, 434, 51314], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 580, "seek": 367772, "start": 3696.72, "end": 3702.12, "text": " learning the world model and possibly learning the cost as well you might want", "tokens": [51314, 2539, 264, 1002, 2316, 293, 6264, 2539, 264, 2063, 382, 731, 291, 1062, 528, 51584], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 581, "seek": 367772, "start": 3702.12, "end": 3705.9599999999996, "text": " to imagine the system like this that does hierarchical planning humans animals", "tokens": [51584, 281, 3811, 264, 1185, 411, 341, 300, 775, 35250, 804, 5038, 6255, 4882, 51776], "temperature": 0.0, "avg_logprob": -0.15092817286855167, "compression_ratio": 1.8495934959349594, "no_speech_prob": 0.0024264873936772346}, {"id": 582, "seek": 370596, "start": 3706.0, "end": 3709.68, "text": " do hierarchical planning all the time it's a essential characteristic of what", "tokens": [50366, 360, 35250, 804, 5038, 439, 264, 565, 309, 311, 257, 7115, 16282, 295, 437, 50550], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 583, "seek": 370596, "start": 3709.68, "end": 3714.32, "text": " we can do and we don't know how to do this at the moment we have some ideas", "tokens": [50550, 321, 393, 360, 293, 321, 500, 380, 458, 577, 281, 360, 341, 412, 264, 1623, 321, 362, 512, 3487, 50782], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 584, "seek": 370596, "start": 3714.32, "end": 3717.76, "text": " working on it but it really doesn't work like if there is like a really good", "tokens": [50782, 1364, 322, 309, 457, 309, 534, 1177, 380, 589, 411, 498, 456, 307, 411, 257, 534, 665, 50954], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 585, "seek": 370596, "start": 3717.76, "end": 3722.64, "text": " opportunity for young scientists or aspiring scientists to really solve a", "tokens": [50954, 2650, 337, 2037, 7708, 420, 45405, 7708, 281, 534, 5039, 257, 51198], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 586, "seek": 370596, "start": 3722.64, "end": 3726.88, "text": " problem like try to see if you can do something about hierarchical planning", "tokens": [51198, 1154, 411, 853, 281, 536, 498, 291, 393, 360, 746, 466, 35250, 804, 5038, 51410], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 587, "seek": 370596, "start": 3726.88, "end": 3735.28, "text": " because it's really hard but the payoff if you can do it I think is enormous so", "tokens": [51410, 570, 309, 311, 534, 1152, 457, 264, 46547, 498, 291, 393, 360, 309, 286, 519, 307, 11322, 370, 51830], "temperature": 0.0, "avg_logprob": -0.10062089367447613, "compression_ratio": 1.84, "no_speech_prob": 0.004049987066537142}, {"id": 588, "seek": 373528, "start": 3735.28, "end": 3741.44, "text": " a good example of this is let's say I'm at NYU in my office at NYU and I want to", "tokens": [50364, 257, 665, 1365, 295, 341, 307, 718, 311, 584, 286, 478, 412, 42682, 294, 452, 3398, 412, 42682, 293, 286, 528, 281, 50672], "temperature": 0.0, "avg_logprob": -0.13621147155761718, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0016334865940734744}, {"id": 589, "seek": 373528, "start": 3741.44, "end": 3745.44, "text": " go to Paris okay so my objective is my distance to Paris I want to minimize my", "tokens": [50672, 352, 281, 8380, 1392, 370, 452, 10024, 307, 452, 4560, 281, 8380, 286, 528, 281, 17522, 452, 50872], "temperature": 0.0, "avg_logprob": -0.13621147155761718, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0016334865940734744}, {"id": 590, "seek": 373528, "start": 3745.44, "end": 3750.28, "text": " distance to Paris at a high level I can say well first thing I need to do is go", "tokens": [50872, 4560, 281, 8380, 412, 257, 1090, 1496, 286, 393, 584, 731, 700, 551, 286, 643, 281, 360, 307, 352, 51114], "temperature": 0.0, "avg_logprob": -0.13621147155761718, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0016334865940734744}, {"id": 591, "seek": 373528, "start": 3750.28, "end": 3753.96, "text": " to the airport and then catch a plane and there is a latent variable that may", "tokens": [51114, 281, 264, 10155, 293, 550, 3745, 257, 5720, 293, 456, 307, 257, 48994, 7006, 300, 815, 51298], "temperature": 0.0, "avg_logprob": -0.13621147155761718, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0016334865940734744}, {"id": 592, "seek": 373528, "start": 3753.96, "end": 3757.96, "text": " indicate like which airport I'm choosing depending on traffic or whatever or what", "tokens": [51298, 13330, 411, 597, 10155, 286, 478, 10875, 5413, 322, 6419, 420, 2035, 420, 437, 51498], "temperature": 0.0, "avg_logprob": -0.13621147155761718, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0016334865940734744}, {"id": 593, "seek": 375796, "start": 3757.96, "end": 3764.2400000000002, "text": " airline flights at what time okay now how do I go to the airport well I have", "tokens": [50364, 29528, 21089, 412, 437, 565, 1392, 586, 577, 360, 286, 352, 281, 264, 10155, 731, 286, 362, 50678], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 594, "seek": 375796, "start": 3764.2400000000002, "end": 3768.8, "text": " to go down in the street and catch a taxi you can do this in New York you can", "tokens": [50678, 281, 352, 760, 294, 264, 4838, 293, 3745, 257, 18984, 291, 393, 360, 341, 294, 1873, 3609, 291, 393, 50906], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 595, "seek": 375796, "start": 3768.8, "end": 3773.4, "text": " just tell the taxi in the street how do I go down in the street I need to stand up", "tokens": [50906, 445, 980, 264, 18984, 294, 264, 4838, 577, 360, 286, 352, 760, 294, 264, 4838, 286, 643, 281, 1463, 493, 51136], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 596, "seek": 375796, "start": 3773.4, "end": 3778.2, "text": " for my chair open the door go to the stair staircase of the elevator how do I", "tokens": [51136, 337, 452, 6090, 1269, 264, 2853, 352, 281, 264, 22273, 35359, 295, 264, 18782, 577, 360, 286, 51376], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 597, "seek": 375796, "start": 3778.2, "end": 3783.88, "text": " get out from my chair I need to kind of push with my arms or something or or", "tokens": [51376, 483, 484, 490, 452, 6090, 286, 643, 281, 733, 295, 2944, 365, 452, 5812, 420, 746, 420, 420, 51660], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 598, "seek": 375796, "start": 3783.88, "end": 3787.64, "text": " turn my chair and then you know you imagine you can imagine decomposing this", "tokens": [51660, 1261, 452, 6090, 293, 550, 291, 458, 291, 3811, 291, 393, 3811, 22867, 6110, 341, 51848], "temperature": 0.0, "avg_logprob": -0.15769537289937338, "compression_ratio": 1.9300411522633745, "no_speech_prob": 0.054104503244161606}, {"id": 599, "seek": 378764, "start": 3787.64, "end": 3791.48, "text": " all the way down to millisecond by millisecond muscle control I'm not going", "tokens": [50364, 439, 264, 636, 760, 281, 27940, 18882, 538, 27940, 18882, 8679, 1969, 286, 478, 406, 516, 50556], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 600, "seek": 378764, "start": 3791.48, "end": 3797.52, "text": " to plan my entire trajectory from my NYU office to Paris in terms of millisecond", "tokens": [50556, 281, 1393, 452, 2302, 21512, 490, 452, 42682, 3398, 281, 8380, 294, 2115, 295, 27940, 18882, 50858], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 601, "seek": 378764, "start": 3797.52, "end": 3801.24, "text": " by millisecond muscle control that would be classical planning it has to be", "tokens": [50858, 538, 27940, 18882, 8679, 1969, 300, 576, 312, 13735, 5038, 309, 575, 281, 312, 51044], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 602, "seek": 378764, "start": 3801.24, "end": 3807.44, "text": " hierarchical and people can do this today I mean engineers do this in control", "tokens": [51044, 35250, 804, 293, 561, 393, 360, 341, 965, 286, 914, 11955, 360, 341, 294, 1969, 51354], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 603, "seek": 378764, "start": 3807.44, "end": 3813.48, "text": " but those various levels in a hierarchy are designed by hand the question is can", "tokens": [51354, 457, 729, 3683, 4358, 294, 257, 22333, 366, 4761, 538, 1011, 264, 1168, 307, 393, 51656], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 604, "seek": 378764, "start": 3813.48, "end": 3816.7999999999997, "text": " we train a machine to automatically learn what the proper hierarchical", "tokens": [51656, 321, 3847, 257, 3479, 281, 6772, 1466, 437, 264, 2296, 35250, 804, 51822], "temperature": 0.0, "avg_logprob": -0.12902314055199718, "compression_ratio": 1.855421686746988, "no_speech_prob": 0.004306306131184101}, {"id": 605, "seek": 381680, "start": 3816.84, "end": 3822.32, "text": " representation of the action plan is and that's the answer problem yeah you're", "tokens": [50366, 10290, 295, 264, 3069, 1393, 307, 293, 300, 311, 264, 1867, 1154, 1338, 291, 434, 50640], "temperature": 0.0, "avg_logprob": -0.21870683034261068, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.002293797442689538}, {"id": 606, "seek": 381680, "start": 3822.32, "end": 3829.0, "text": " looking to do a phd or something or two or three that's a good problem", "tokens": [50640, 1237, 281, 360, 257, 903, 67, 420, 746, 420, 732, 420, 1045, 300, 311, 257, 665, 1154, 50974], "temperature": 0.0, "avg_logprob": -0.21870683034261068, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.002293797442689538}, {"id": 607, "seek": 381680, "start": 3831.36, "end": 3836.6800000000003, "text": " we could use techniques like this for LLMs so LLMs that would be non-auto", "tokens": [51092, 321, 727, 764, 7512, 411, 341, 337, 441, 43, 26386, 370, 441, 43, 26386, 300, 576, 312, 2107, 12, 41988, 51358], "temperature": 0.0, "avg_logprob": -0.21870683034261068, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.002293797442689538}, {"id": 608, "seek": 381680, "start": 3836.6800000000003, "end": 3840.92, "text": " aggressive instead of producing one token after the other they would basically", "tokens": [51358, 10762, 2602, 295, 10501, 472, 14862, 934, 264, 661, 436, 576, 1936, 51570], "temperature": 0.0, "avg_logprob": -0.21870683034261068, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.002293797442689538}, {"id": 609, "seek": 381680, "start": 3840.92, "end": 3846.36, "text": " infer a sequence of tokens that would satisfy a number of objectives on a", "tokens": [51570, 13596, 257, 8310, 295, 22667, 300, 576, 19319, 257, 1230, 295, 15961, 322, 257, 51842], "temperature": 0.0, "avg_logprob": -0.21870683034261068, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.002293797442689538}, {"id": 610, "seek": 384636, "start": 3846.36, "end": 3849.56, "text": " guardrail an objective that measures to what extent you're answering the", "tokens": [50364, 6290, 44765, 364, 10024, 300, 8000, 281, 437, 8396, 291, 434, 13430, 264, 50524], "temperature": 0.0, "avg_logprob": -0.14900942163153008, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.0008660400053486228}, {"id": 611, "seek": 384636, "start": 3849.56, "end": 3855.6, "text": " question and an objective that measures to what extent the answer is non-toxic", "tokens": [50524, 1168, 293, 364, 10024, 300, 8000, 281, 437, 8396, 264, 1867, 307, 2107, 12, 1353, 47228, 50826], "temperature": 0.0, "avg_logprob": -0.14900942163153008, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.0008660400053486228}, {"id": 612, "seek": 384636, "start": 3855.6, "end": 3863.1200000000003, "text": " or toxic or whatever right that would make LLMs controllable nothing like", "tokens": [50826, 420, 12786, 420, 2035, 558, 300, 576, 652, 441, 43, 26386, 45159, 712, 1825, 411, 51202], "temperature": 0.0, "avg_logprob": -0.14900942163153008, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.0008660400053486228}, {"id": 613, "seek": 384636, "start": 3863.1200000000003, "end": 3867.52, "text": " this works today right again if you are looking for a good topic for a phd that's", "tokens": [51202, 341, 1985, 965, 558, 797, 498, 291, 366, 1237, 337, 257, 665, 4829, 337, 257, 903, 67, 300, 311, 51422], "temperature": 0.0, "avg_logprob": -0.14900942163153008, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.0008660400053486228}, {"id": 614, "seek": 384636, "start": 3867.52, "end": 3875.92, "text": " a good one ultimately we need machine to learn to understand the world that's the", "tokens": [51422, 257, 665, 472, 6284, 321, 643, 3479, 281, 1466, 281, 1223, 264, 1002, 300, 311, 264, 51842], "temperature": 0.0, "avg_logprob": -0.14900942163153008, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.0008660400053486228}, {"id": 615, "seek": 387592, "start": 3875.96, "end": 3880.96, "text": " purpose of that world model the essential central piece of that architecture", "tokens": [50366, 4334, 295, 300, 1002, 2316, 264, 7115, 5777, 2522, 295, 300, 9482, 50616], "temperature": 0.0, "avg_logprob": -0.16010852342241266, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.002126601291820407}, {"id": 616, "seek": 387592, "start": 3880.96, "end": 3885.48, "text": " I just talked about is this world model given the state of the world at time t", "tokens": [50616, 286, 445, 2825, 466, 307, 341, 1002, 2316, 2212, 264, 1785, 295, 264, 1002, 412, 565, 256, 50842], "temperature": 0.0, "avg_logprob": -0.16010852342241266, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.002126601291820407}, {"id": 617, "seek": 387592, "start": 3885.48, "end": 3888.2000000000003, "text": " given an action I might take or a sequence of actions what is going to be", "tokens": [50842, 2212, 364, 3069, 286, 1062, 747, 420, 257, 8310, 295, 5909, 437, 307, 516, 281, 312, 50978], "temperature": 0.0, "avg_logprob": -0.16010852342241266, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.002126601291820407}, {"id": 618, "seek": 387592, "start": 3888.2000000000003, "end": 3895.36, "text": " the state of the world at time t plus one or t plus whatever and humans and", "tokens": [50978, 264, 1785, 295, 264, 1002, 412, 565, 256, 1804, 472, 420, 256, 1804, 2035, 293, 6255, 293, 51336], "temperature": 0.0, "avg_logprob": -0.16010852342241266, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.002126601291820407}, {"id": 619, "seek": 387592, "start": 3895.36, "end": 3901.0, "text": " animals are amazingly good at this babies learn how the world works in the first", "tokens": [51336, 4882, 366, 31762, 665, 412, 341, 10917, 1466, 577, 264, 1002, 1985, 294, 264, 700, 51618], "temperature": 0.0, "avg_logprob": -0.16010852342241266, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.002126601291820407}, {"id": 620, "seek": 390100, "start": 3901.08, "end": 3906.4, "text": " few months of life at an amazing speed and they learn an incredible amount of", "tokens": [50368, 1326, 2493, 295, 993, 412, 364, 2243, 3073, 293, 436, 1466, 364, 4651, 2372, 295, 50634], "temperature": 0.0, "avg_logprob": -0.15561512744787967, "compression_ratio": 1.6775956284153006, "no_speech_prob": 0.005041694734245539}, {"id": 621, "seek": 390100, "start": 3906.4, "end": 3909.36, "text": " background knowledge about the world first thing you learn is that the world", "tokens": [50634, 3678, 3601, 466, 264, 1002, 700, 551, 291, 1466, 307, 300, 264, 1002, 50782], "temperature": 0.0, "avg_logprob": -0.15561512744787967, "compression_ratio": 1.6775956284153006, "no_speech_prob": 0.005041694734245539}, {"id": 622, "seek": 390100, "start": 3909.36, "end": 3914.4, "text": " is three-dimensional then you learn that something like object permanence the", "tokens": [50782, 307, 1045, 12, 18759, 550, 291, 1466, 300, 746, 411, 2657, 8105, 655, 264, 51034], "temperature": 0.0, "avg_logprob": -0.15561512744787967, "compression_ratio": 1.6775956284153006, "no_speech_prob": 0.005041694734245539}, {"id": 623, "seek": 390100, "start": 3914.4, "end": 3919.84, "text": " fact that when an object is hidden behind another one it still exists okay", "tokens": [51034, 1186, 300, 562, 364, 2657, 307, 7633, 2261, 1071, 472, 309, 920, 8198, 1392, 51306], "temperature": 0.0, "avg_logprob": -0.15561512744787967, "compression_ratio": 1.6775956284153006, "no_speech_prob": 0.005041694734245539}, {"id": 624, "seek": 391984, "start": 3920.2000000000003, "end": 3922.2000000000003, "text": " five", "tokens": [50382, 1732, 50482], "temperature": 0.0, "avg_logprob": -0.2055147735165878, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.005781204905360937}, {"id": 625, "seek": 391984, "start": 3926.2000000000003, "end": 3932.0, "text": " and babies learn things like basic notions like gravity in the around the age of", "tokens": [50682, 293, 10917, 1466, 721, 411, 3875, 35799, 411, 12110, 294, 264, 926, 264, 3205, 295, 50972], "temperature": 0.0, "avg_logprob": -0.2055147735165878, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.005781204905360937}, {"id": 626, "seek": 391984, "start": 3932.0, "end": 3935.7200000000003, "text": " nine months takes a long time to learn intuitive physics like like inertia", "tokens": [50972, 4949, 2493, 2516, 257, 938, 565, 281, 1466, 21769, 10649, 411, 411, 37234, 51158], "temperature": 0.0, "avg_logprob": -0.2055147735165878, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.005781204905360937}, {"id": 627, "seek": 391984, "start": 3935.7200000000003, "end": 3939.6000000000004, "text": " gravity things like that okay but it's mostly just by observation a little bit", "tokens": [51158, 12110, 721, 411, 300, 1392, 457, 309, 311, 5240, 445, 538, 14816, 257, 707, 857, 51352], "temperature": 0.0, "avg_logprob": -0.2055147735165878, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.005781204905360937}, {"id": 628, "seek": 391984, "start": 3939.6000000000004, "end": 3946.0, "text": " by experimentation and we don't know how to reproduce this kind of learning with", "tokens": [51352, 538, 37142, 293, 321, 500, 380, 458, 577, 281, 29501, 341, 733, 295, 2539, 365, 51672], "temperature": 0.0, "avg_logprob": -0.2055147735165878, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.005781204905360937}, {"id": 629, "seek": 394600, "start": 3946.04, "end": 3951.12, "text": " machines and that's why although we have fluid systems that can pass the bar", "tokens": [50366, 8379, 293, 300, 311, 983, 4878, 321, 362, 9113, 3652, 300, 393, 1320, 264, 2159, 50620], "temperature": 0.0, "avg_logprob": -0.1354021690261196, "compression_ratio": 1.664864864864865, "no_speech_prob": 0.003013935638591647}, {"id": 630, "seek": 394600, "start": 3951.12, "end": 3960.8, "text": " exam or medical exams we don't have robots that can clear up the dinner table", "tokens": [50620, 1139, 420, 4625, 20514, 321, 500, 380, 362, 14733, 300, 393, 1850, 493, 264, 6148, 3199, 51104], "temperature": 0.0, "avg_logprob": -0.1354021690261196, "compression_ratio": 1.664864864864865, "no_speech_prob": 0.003013935638591647}, {"id": 631, "seek": 394600, "start": 3960.8, "end": 3965.6, "text": " and fill up the dishwasher something that any 10 year old can learn in one", "tokens": [51104, 293, 2836, 493, 264, 38009, 746, 300, 604, 1266, 1064, 1331, 393, 1466, 294, 472, 51344], "temperature": 0.0, "avg_logprob": -0.1354021690261196, "compression_ratio": 1.664864864864865, "no_speech_prob": 0.003013935638591647}, {"id": 632, "seek": 394600, "start": 3965.6, "end": 3971.04, "text": " shot in a few minutes we don't even have completely autonomous level five cell", "tokens": [51344, 3347, 294, 257, 1326, 2077, 321, 500, 380, 754, 362, 2584, 23797, 1496, 1732, 2815, 51616], "temperature": 0.0, "avg_logprob": -0.1354021690261196, "compression_ratio": 1.664864864864865, "no_speech_prob": 0.003013935638591647}, {"id": 633, "seek": 397104, "start": 3971.04, "end": 3976.96, "text": " driving cars even though any 17 year old can learn to do this within 20 hours", "tokens": [50364, 4840, 5163, 754, 1673, 604, 3282, 1064, 1331, 393, 1466, 281, 360, 341, 1951, 945, 2496, 50660], "temperature": 0.0, "avg_logprob": -0.13039570711971668, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.002501284470781684}, {"id": 634, "seek": 397104, "start": 3976.96, "end": 3986.12, "text": " and then drive at 300 kilometers an hour on the Autobahn you know obviously we're", "tokens": [50660, 293, 550, 3332, 412, 6641, 13904, 364, 1773, 322, 264, 49909, 12140, 291, 458, 2745, 321, 434, 51118], "temperature": 0.0, "avg_logprob": -0.13039570711971668, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.002501284470781684}, {"id": 635, "seek": 397104, "start": 3986.12, "end": 3990.84, "text": " missing something really big with machines that humans and animals can can do", "tokens": [51118, 5361, 746, 534, 955, 365, 8379, 300, 6255, 293, 4882, 393, 393, 360, 51354], "temperature": 0.0, "avg_logprob": -0.13039570711971668, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.002501284470781684}, {"id": 636, "seek": 397104, "start": 3990.84, "end": 3995.6, "text": " in terms of learning that learning efficiency that we don't we don't know", "tokens": [51354, 294, 2115, 295, 2539, 300, 2539, 10493, 300, 321, 500, 380, 321, 500, 380, 458, 51592], "temperature": 0.0, "avg_logprob": -0.13039570711971668, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.002501284470781684}, {"id": 637, "seek": 397104, "start": 3995.6, "end": 3999.84, "text": " how to reproduce so we need this ability to learn world models to get machines to", "tokens": [51592, 577, 281, 29501, 370, 321, 643, 341, 3485, 281, 1466, 1002, 5245, 281, 483, 8379, 281, 51804], "temperature": 0.0, "avg_logprob": -0.13039570711971668, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.002501284470781684}, {"id": 638, "seek": 399984, "start": 3999.84, "end": 4004.4, "text": " learn world models from video essentially from natural signals and so", "tokens": [50364, 1466, 1002, 5245, 490, 960, 4476, 490, 3303, 12354, 293, 370, 50592], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 639, "seek": 399984, "start": 4004.4, "end": 4007.48, "text": " this is idea of self-supervised learning but now apply to video not text and it", "tokens": [50592, 341, 307, 1558, 295, 2698, 12, 48172, 24420, 2539, 457, 586, 3079, 281, 960, 406, 2487, 293, 309, 50746], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 640, "seek": 399984, "start": 4007.48, "end": 4013.6400000000003, "text": " turns out text is easy text is easy because text is discrete and finite it's", "tokens": [50746, 4523, 484, 2487, 307, 1858, 2487, 307, 1858, 570, 2487, 307, 27706, 293, 19362, 309, 311, 51054], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 641, "seek": 399984, "start": 4013.6400000000003, "end": 4017.52, "text": " only a finite number of possible tokens in every language on the order of 30", "tokens": [51054, 787, 257, 19362, 1230, 295, 1944, 22667, 294, 633, 2856, 322, 264, 1668, 295, 2217, 51248], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 642, "seek": 399984, "start": 4017.52, "end": 4022.96, "text": " thousand or something and so it's easy to predict a distribution a probability", "tokens": [51248, 4714, 420, 746, 293, 370, 309, 311, 1858, 281, 6069, 257, 7316, 257, 8482, 51520], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 643, "seek": 399984, "start": 4022.96, "end": 4026.76, "text": " distribution over the next token you can represent it by a long list of numbers", "tokens": [51520, 7316, 670, 264, 958, 14862, 291, 393, 2906, 309, 538, 257, 938, 1329, 295, 3547, 51710], "temperature": 0.0, "avg_logprob": -0.1629028135133021, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.014073236845433712}, {"id": 644, "seek": 402676, "start": 4026.76, "end": 4031.92, "text": " between 0 and 1 that's on to 1 but if you want to predict video you can't do", "tokens": [50364, 1296, 1958, 293, 502, 300, 311, 322, 281, 502, 457, 498, 291, 528, 281, 6069, 960, 291, 393, 380, 360, 50622], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 645, "seek": 402676, "start": 4031.92, "end": 4035.2000000000003, "text": " that because we don't know how to represent probability distributions over", "tokens": [50622, 300, 570, 321, 500, 380, 458, 577, 281, 2906, 8482, 37870, 670, 50786], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 646, "seek": 402676, "start": 4035.2000000000003, "end": 4039.0800000000004, "text": " all possible videos at least not in a good way so if you train a neural net to", "tokens": [50786, 439, 1944, 2145, 412, 1935, 406, 294, 257, 665, 636, 370, 498, 291, 3847, 257, 18161, 2533, 281, 50980], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 647, "seek": 402676, "start": 4039.0800000000004, "end": 4043.5200000000004, "text": " predict what happens in a very simple video this is over overhead video from a", "tokens": [50980, 6069, 437, 2314, 294, 257, 588, 2199, 960, 341, 307, 670, 19922, 960, 490, 257, 51202], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 648, "seek": 402676, "start": 4043.5200000000004, "end": 4050.0, "text": " highway you get this kind of prediction very very blurry prediction because the", "tokens": [51202, 17205, 291, 483, 341, 733, 295, 17630, 588, 588, 37644, 17630, 570, 264, 51526], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 649, "seek": 402676, "start": 4050.0, "end": 4053.2400000000002, "text": " system can only predict the average of all the possible things that can happen", "tokens": [51526, 1185, 393, 787, 6069, 264, 4274, 295, 439, 264, 1944, 721, 300, 393, 1051, 51688], "temperature": 0.0, "avg_logprob": -0.17278311387547907, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.008131719194352627}, {"id": 650, "seek": 405324, "start": 4053.24, "end": 4058.16, "text": " and it can't make make up its mind so the solution I'm proposing to this is", "tokens": [50364, 293, 309, 393, 380, 652, 652, 493, 1080, 1575, 370, 264, 3827, 286, 478, 29939, 281, 341, 307, 50610], "temperature": 0.0, "avg_logprob": -0.22904324531555176, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.003988838754594326}, {"id": 651, "seek": 405324, "start": 4058.16, "end": 4066.16, "text": " something I call joint embedded joint embedding architecture okay or joint", "tokens": [50610, 746, 286, 818, 7225, 16741, 7225, 12240, 3584, 9482, 1392, 420, 7225, 51010], "temperature": 0.0, "avg_logprob": -0.22904324531555176, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.003988838754594326}, {"id": 652, "seek": 405324, "start": 4066.16, "end": 4072.4399999999996, "text": " embedding predictive architecture JEPA and this is a non generative", "tokens": [51010, 12240, 3584, 35521, 9482, 508, 8929, 32, 293, 341, 307, 257, 2107, 1337, 1166, 51324], "temperature": 0.0, "avg_logprob": -0.22904324531555176, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.003988838754594326}, {"id": 653, "seek": 405324, "start": 4072.4399999999996, "end": 4075.12, "text": " architecture so everybody is talking about generative AI what I'm telling you", "tokens": [51324, 9482, 370, 2201, 307, 1417, 466, 1337, 1166, 7318, 437, 286, 478, 3585, 291, 51458], "temperature": 0.0, "avg_logprob": -0.22904324531555176, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.003988838754594326}, {"id": 654, "seek": 407512, "start": 4075.12, "end": 4083.48, "text": " here is abandoned generative models okay so not only am I telling you AI is not", "tokens": [50364, 510, 307, 13732, 1337, 1166, 5245, 1392, 370, 406, 787, 669, 286, 3585, 291, 7318, 307, 406, 50782], "temperature": 0.0, "avg_logprob": -0.16011411017113988, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.03501405566930771}, {"id": 655, "seek": 407512, "start": 4083.48, "end": 4088.96, "text": " gonna kill us but LLM suck machine learning sucks and generative models", "tokens": [50782, 799, 1961, 505, 457, 441, 43, 44, 9967, 3479, 2539, 15846, 293, 1337, 1166, 5245, 51056], "temperature": 0.0, "avg_logprob": -0.16011411017113988, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.03501405566930771}, {"id": 656, "seek": 407512, "start": 4088.96, "end": 4094.2, "text": " suck right all the popular things at the moment okay so a generative model", "tokens": [51056, 9967, 558, 439, 264, 3743, 721, 412, 264, 1623, 1392, 370, 257, 1337, 1166, 2316, 51318], "temperature": 0.0, "avg_logprob": -0.16011411017113988, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.03501405566930771}, {"id": 657, "seek": 407512, "start": 4094.2, "end": 4098.2, "text": " predicts you know if you have an observation x you're trying to predict", "tokens": [51318, 6069, 82, 291, 458, 498, 291, 362, 364, 14816, 2031, 291, 434, 1382, 281, 6069, 51518], "temperature": 0.0, "avg_logprob": -0.16011411017113988, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.03501405566930771}, {"id": 658, "seek": 407512, "start": 4098.2, "end": 4102.599999999999, "text": " y just predict y from x using an encoder and some predictor right but what", "tokens": [51518, 288, 445, 6069, 288, 490, 2031, 1228, 364, 2058, 19866, 293, 512, 6069, 284, 558, 457, 437, 51738], "temperature": 0.0, "avg_logprob": -0.16011411017113988, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.03501405566930771}, {"id": 659, "seek": 410260, "start": 4102.6, "end": 4107.72, "text": " problem with this is that you have to predict every single details of y and in", "tokens": [50364, 1154, 365, 341, 307, 300, 291, 362, 281, 6069, 633, 2167, 4365, 295, 288, 293, 294, 50620], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 660, "seek": 410260, "start": 4107.72, "end": 4110.92, "text": " video that's just too much in text it's okay it's just like you know what word", "tokens": [50620, 960, 300, 311, 445, 886, 709, 294, 2487, 309, 311, 1392, 309, 311, 445, 411, 291, 458, 437, 1349, 50780], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 661, "seek": 410260, "start": 4110.92, "end": 4114.4400000000005, "text": " okay you don't know exactly what word but it's okay in video it's just not", "tokens": [50780, 1392, 291, 500, 380, 458, 2293, 437, 1349, 457, 309, 311, 1392, 294, 960, 309, 311, 445, 406, 50956], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 662, "seek": 410260, "start": 4114.4400000000005, "end": 4118.68, "text": " possible so what you should do instead is what's on the right here the joint", "tokens": [50956, 1944, 370, 437, 291, 820, 360, 2602, 307, 437, 311, 322, 264, 558, 510, 264, 7225, 51168], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 663, "seek": 410260, "start": 4118.68, "end": 4123.320000000001, "text": " embedding architecture where you run both x and y through encoders the", "tokens": [51168, 12240, 3584, 9482, 689, 291, 1190, 1293, 2031, 293, 288, 807, 2058, 378, 433, 264, 51400], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 664, "seek": 410260, "start": 4123.320000000001, "end": 4126.92, "text": " encoders eliminate all the irrelevant details about the input and the", "tokens": [51400, 2058, 378, 433, 13819, 439, 264, 28682, 4365, 466, 264, 4846, 293, 264, 51580], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 665, "seek": 410260, "start": 4126.92, "end": 4131.4400000000005, "text": " prediction takes place in representation space okay so joint", "tokens": [51580, 17630, 2516, 1081, 294, 10290, 1901, 1392, 370, 7225, 51806], "temperature": 0.0, "avg_logprob": -0.1030572594189253, "compression_ratio": 1.8581818181818182, "no_speech_prob": 0.0005270126275718212}, {"id": 666, "seek": 413144, "start": 4131.44, "end": 4135.16, "text": " embedding predictive architecture JPA there's several incarnations of this", "tokens": [50364, 12240, 3584, 35521, 9482, 508, 10297, 456, 311, 2940, 30938, 763, 295, 341, 50550], "temperature": 0.0, "avg_logprob": -0.1749960621701011, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004418755881488323}, {"id": 667, "seek": 413144, "start": 4135.16, "end": 4140.599999999999, "text": " I'm not gonna go to the details because I don't have time and you can read the", "tokens": [50550, 286, 478, 406, 799, 352, 281, 264, 4365, 570, 286, 500, 380, 362, 565, 293, 291, 393, 1401, 264, 50822], "temperature": 0.0, "avg_logprob": -0.1749960621701011, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004418755881488323}, {"id": 668, "seek": 413144, "start": 4140.599999999999, "end": 4150.879999999999, "text": " details in this long paper I can't read what's on it but I can imagine and that's", "tokens": [50822, 4365, 294, 341, 938, 3035, 286, 393, 380, 1401, 437, 311, 322, 309, 457, 286, 393, 3811, 293, 300, 311, 51336], "temperature": 0.0, "avg_logprob": -0.1749960621701011, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004418755881488323}, {"id": 669, "seek": 413144, "start": 4150.879999999999, "end": 4156.32, "text": " kind of the basic JPA architecture so let me skip ahead a little bit there's", "tokens": [51336, 733, 295, 264, 3875, 508, 10297, 9482, 370, 718, 385, 10023, 2286, 257, 707, 857, 456, 311, 51608], "temperature": 0.0, "avg_logprob": -0.1749960621701011, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004418755881488323}, {"id": 670, "seek": 415632, "start": 4156.4, "end": 4163.88, "text": " two ways to train those JPAs basically two major techniques to train", "tokens": [50368, 732, 2098, 281, 3847, 729, 508, 10297, 82, 1936, 732, 2563, 7512, 281, 3847, 50742], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 671, "seek": 415632, "start": 4163.88, "end": 4166.679999999999, "text": " those JPAs that cannot be understood within the context of probabilistic", "tokens": [50742, 729, 508, 10297, 82, 300, 2644, 312, 7320, 1951, 264, 4319, 295, 31959, 3142, 50882], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 672, "seek": 415632, "start": 4166.679999999999, "end": 4170.48, "text": " methods but only within the context of what I called energy based models and I", "tokens": [50882, 7150, 457, 787, 1951, 264, 4319, 295, 437, 286, 1219, 2281, 2361, 5245, 293, 286, 51072], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 673, "seek": 415632, "start": 4170.48, "end": 4174.48, "text": " was going to explain what this was but I skipped that section but you don't need", "tokens": [51072, 390, 516, 281, 2903, 437, 341, 390, 457, 286, 30193, 300, 3541, 457, 291, 500, 380, 643, 51272], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 674, "seek": 415632, "start": 4174.48, "end": 4177.759999999999, "text": " to know about energy based model to understand what I'm gonna say so there's", "tokens": [51272, 281, 458, 466, 2281, 2361, 2316, 281, 1223, 437, 286, 478, 799, 584, 370, 456, 311, 51436], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 675, "seek": 415632, "start": 4177.759999999999, "end": 4182.5599999999995, "text": " several methods to train those JPAs and this is a particularly interesting one", "tokens": [51436, 2940, 7150, 281, 3847, 729, 508, 10297, 82, 293, 341, 307, 257, 4098, 1880, 472, 51676], "temperature": 0.0, "avg_logprob": -0.15826510474795386, "compression_ratio": 1.8653061224489795, "no_speech_prob": 0.0156155526638031}, {"id": 676, "seek": 418256, "start": 4182.6, "end": 4190.52, "text": " this is a paper that was published at CVPR just a few months ago it's called", "tokens": [50366, 341, 307, 257, 3035, 300, 390, 6572, 412, 22995, 15958, 445, 257, 1326, 2493, 2057, 309, 311, 1219, 50762], "temperature": 0.0, "avg_logprob": -0.17405368912387903, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.005947415251284838}, {"id": 677, "seek": 418256, "start": 4190.52, "end": 4198.96, "text": " image JPA and it's using this masking idea so you take an image you mask", "tokens": [50762, 3256, 508, 10297, 293, 309, 311, 1228, 341, 31226, 1558, 370, 291, 747, 364, 3256, 291, 6094, 51184], "temperature": 0.0, "avg_logprob": -0.17405368912387903, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.005947415251284838}, {"id": 678, "seek": 418256, "start": 4198.96, "end": 4204.320000000001, "text": " regions of that image okay and you feed that partially masked image to an", "tokens": [51184, 10682, 295, 300, 3256, 1392, 293, 291, 3154, 300, 18886, 45249, 3256, 281, 364, 51452], "temperature": 0.0, "avg_logprob": -0.17405368912387903, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.005947415251284838}, {"id": 679, "seek": 418256, "start": 4204.320000000001, "end": 4209.0, "text": " encoder the encoder produces a representation and with that representation", "tokens": [51452, 2058, 19866, 264, 2058, 19866, 14725, 257, 10290, 293, 365, 300, 10290, 51686], "temperature": 0.0, "avg_logprob": -0.17405368912387903, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.005947415251284838}, {"id": 680, "seek": 420900, "start": 4209.04, "end": 4213.16, "text": " you try to predict using another neural net predictor you try to predict the", "tokens": [50366, 291, 853, 281, 6069, 1228, 1071, 18161, 2533, 6069, 284, 291, 853, 281, 6069, 264, 50572], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 681, "seek": 420900, "start": 4213.16, "end": 4216.68, "text": " representation for use from the full image okay and they both they run", "tokens": [50572, 10290, 337, 764, 490, 264, 1577, 3256, 1392, 293, 436, 1293, 436, 1190, 50748], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 682, "seek": 420900, "start": 4216.68, "end": 4220.52, "text": " through essentially identical encoders so not identical one of them uses", "tokens": [50748, 807, 4476, 14800, 2058, 378, 433, 370, 406, 14800, 472, 295, 552, 4960, 50940], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 683, "seek": 420900, "start": 4220.52, "end": 4225.32, "text": " something called exponential moving average weights but but but they're", "tokens": [50940, 746, 1219, 21510, 2684, 4274, 17443, 457, 457, 457, 436, 434, 51180], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 684, "seek": 420900, "start": 4225.32, "end": 4231.16, "text": " almost identical and and that works amazingly well so you you train the", "tokens": [51180, 1920, 14800, 293, 293, 300, 1985, 31762, 731, 370, 291, 291, 3847, 264, 51472], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 685, "seek": 420900, "start": 4231.16, "end": 4235.84, "text": " system this way pre-train it with images that you corrupt by masking them", "tokens": [51472, 1185, 341, 636, 659, 12, 83, 7146, 309, 365, 5267, 300, 291, 17366, 538, 31226, 552, 51706], "temperature": 0.0, "avg_logprob": -0.15283816488165605, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.0023159030824899673}, {"id": 686, "seek": 423584, "start": 4235.84, "end": 4240.08, "text": " partially and you get amazing result on using the features that are produced by", "tokens": [50364, 18886, 293, 291, 483, 2243, 1874, 322, 1228, 264, 4122, 300, 366, 7126, 538, 50576], "temperature": 0.0, "avg_logprob": -0.14361016316847366, "compression_ratio": 1.71875, "no_speech_prob": 0.0049443976022303104}, {"id": 687, "seek": 423584, "start": 4240.08, "end": 4244.04, "text": " that system you get amazing results for classification for segmentation for all", "tokens": [50576, 300, 1185, 291, 483, 2243, 3542, 337, 21538, 337, 9469, 399, 337, 439, 50774], "temperature": 0.0, "avg_logprob": -0.14361016316847366, "compression_ratio": 1.71875, "no_speech_prob": 0.0049443976022303104}, {"id": 688, "seek": 423584, "start": 4244.04, "end": 4249.6, "text": " kinds of stuff and the Dino method I told you about before is very similar to", "tokens": [50774, 3685, 295, 1507, 293, 264, 413, 2982, 3170, 286, 1907, 291, 466, 949, 307, 588, 2531, 281, 51052], "temperature": 0.0, "avg_logprob": -0.14361016316847366, "compression_ratio": 1.71875, "no_speech_prob": 0.0049443976022303104}, {"id": 689, "seek": 423584, "start": 4249.6, "end": 4254.4400000000005, "text": " this it uses kind of a slightly different way of encoding the outputs but", "tokens": [51052, 341, 309, 4960, 733, 295, 257, 4748, 819, 636, 295, 43430, 264, 23930, 457, 51294], "temperature": 0.0, "avg_logprob": -0.14361016316847366, "compression_ratio": 1.71875, "no_speech_prob": 0.0049443976022303104}, {"id": 690, "seek": 423584, "start": 4254.4400000000005, "end": 4260.8, "text": " it's it's in spirit it's very much the same idea and it gives really good", "tokens": [51294, 309, 311, 309, 311, 294, 3797, 309, 311, 588, 709, 264, 912, 1558, 293, 309, 2709, 534, 665, 51612], "temperature": 0.0, "avg_logprob": -0.14361016316847366, "compression_ratio": 1.71875, "no_speech_prob": 0.0049443976022303104}, {"id": 691, "seek": 426080, "start": 4260.8, "end": 4266.88, "text": " performance on image recognition on transfer tasks on all kinds of stuff", "tokens": [50364, 3389, 322, 3256, 11150, 322, 5003, 9608, 322, 439, 3685, 295, 1507, 50668], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 692, "seek": 426080, "start": 4266.88, "end": 4271.12, "text": " that I don't have time to tell you about okay but things we're working on today", "tokens": [50668, 300, 286, 500, 380, 362, 565, 281, 980, 291, 466, 1392, 457, 721, 321, 434, 1364, 322, 965, 50880], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 693, "seek": 426080, "start": 4271.12, "end": 4274.52, "text": " that we need to work on because we don't know how to do it perfectly is self", "tokens": [50880, 300, 321, 643, 281, 589, 322, 570, 321, 500, 380, 458, 577, 281, 360, 309, 6239, 307, 2698, 51050], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 694, "seek": 426080, "start": 4274.52, "end": 4278.08, "text": " supervised running from video so basically a version of this image JEPA", "tokens": [51050, 46533, 2614, 490, 960, 370, 1936, 257, 3037, 295, 341, 3256, 508, 8929, 32, 51228], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 695, "seek": 426080, "start": 4278.08, "end": 4282.52, "text": " that would work for video and learn good representations of videos by", "tokens": [51228, 300, 576, 589, 337, 960, 293, 1466, 665, 33358, 295, 2145, 538, 51450], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 696, "seek": 426080, "start": 4282.52, "end": 4286.64, "text": " observing the world basically the same thing that babies can do right so we", "tokens": [51450, 22107, 264, 1002, 1936, 264, 912, 551, 300, 10917, 393, 360, 558, 370, 321, 51656], "temperature": 0.0, "avg_logprob": -0.1503437547122731, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.02088080905377865}, {"id": 697, "seek": 428664, "start": 4286.64, "end": 4292.72, "text": " have a project along those lines V JEPA and we have a paper that we're just", "tokens": [50364, 362, 257, 1716, 2051, 729, 3876, 691, 508, 8929, 32, 293, 321, 362, 257, 3035, 300, 321, 434, 445, 50668], "temperature": 0.0, "avg_logprob": -0.1473317730183504, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.0032617428805679083}, {"id": 698, "seek": 428664, "start": 4292.72, "end": 4296.96, "text": " submitting to a conference that some of you probably know what it is because the", "tokens": [50668, 31836, 281, 257, 7586, 300, 512, 295, 291, 1391, 458, 437, 309, 307, 570, 264, 50880], "temperature": 0.0, "avg_logprob": -0.1473317730183504, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.0032617428805679083}, {"id": 699, "seek": 428664, "start": 4296.96, "end": 4302.400000000001, "text": " deadline is today well actually if you know what it is you're probably not here", "tokens": [50880, 20615, 307, 965, 731, 767, 498, 291, 458, 437, 309, 307, 291, 434, 1391, 406, 510, 51152], "temperature": 0.0, "avg_logprob": -0.1473317730183504, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.0032617428805679083}, {"id": 700, "seek": 428664, "start": 4302.400000000001, "end": 4308.52, "text": " you're working on your paper I think the deadline is passed by two hours so maybe", "tokens": [51152, 291, 434, 1364, 322, 428, 3035, 286, 519, 264, 20615, 307, 4678, 538, 732, 2496, 370, 1310, 51458], "temperature": 0.0, "avg_logprob": -0.1473317730183504, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.0032617428805679083}, {"id": 701, "seek": 428664, "start": 4308.52, "end": 4314.96, "text": " maybe you're here so then you would be able to use those JEPA as world models", "tokens": [51458, 1310, 291, 434, 510, 370, 550, 291, 576, 312, 1075, 281, 764, 729, 508, 8929, 32, 382, 1002, 5245, 51780], "temperature": 0.0, "avg_logprob": -0.1473317730183504, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.0032617428805679083}, {"id": 702, "seek": 431496, "start": 4314.96, "end": 4320.84, "text": " right because you know you have an input and you can feed it maybe a set of", "tokens": [50364, 558, 570, 291, 458, 291, 362, 364, 4846, 293, 291, 393, 3154, 309, 1310, 257, 992, 295, 50658], "temperature": 0.0, "avg_logprob": -0.1441308620364167, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.004384088795632124}, {"id": 703, "seek": 431496, "start": 4320.84, "end": 4325.8, "text": " actions that an agent might take and it will predict a representation abstract", "tokens": [50658, 5909, 300, 364, 9461, 1062, 747, 293, 309, 486, 6069, 257, 10290, 12649, 50906], "temperature": 0.0, "avg_logprob": -0.1441308620364167, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.004384088795632124}, {"id": 704, "seek": 431496, "start": 4325.8, "end": 4329.2, "text": " representation of the state of the world at the next time step and so this could", "tokens": [50906, 10290, 295, 264, 1785, 295, 264, 1002, 412, 264, 958, 565, 1823, 293, 370, 341, 727, 51076], "temperature": 0.0, "avg_logprob": -0.1441308620364167, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.004384088795632124}, {"id": 705, "seek": 431496, "start": 4329.2, "end": 4332.08, "text": " be used perhaps as a world model as one of the components of the big", "tokens": [51076, 312, 1143, 4317, 382, 257, 1002, 2316, 382, 472, 295, 264, 6677, 295, 264, 955, 51220], "temperature": 0.0, "avg_logprob": -0.1441308620364167, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.004384088795632124}, {"id": 706, "seek": 431496, "start": 4332.08, "end": 4341.0, "text": " architecture I introduced earlier okay okay I said that already all right so", "tokens": [51220, 9482, 286, 7268, 3071, 1392, 1392, 286, 848, 300, 1217, 439, 558, 370, 51666], "temperature": 0.0, "avg_logprob": -0.1441308620364167, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.004384088795632124}, {"id": 707, "seek": 434100, "start": 4341.04, "end": 4346.2, "text": " there's quite a question that we need to answer with AI and this is my second", "tokens": [50366, 456, 311, 1596, 257, 1168, 300, 321, 643, 281, 1867, 365, 7318, 293, 341, 307, 452, 1150, 50624], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 708, "seek": 434100, "start": 4346.2, "end": 4351.32, "text": " last slide how long is it going to be before we reach human level AI years to", "tokens": [50624, 1036, 4137, 577, 938, 307, 309, 516, 281, 312, 949, 321, 2524, 1952, 1496, 7318, 924, 281, 50880], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 709, "seek": 434100, "start": 4351.32, "end": 4355.92, "text": " decades probably decades it's probably harder than we think it's certainly much", "tokens": [50880, 7878, 1391, 7878, 309, 311, 1391, 6081, 813, 321, 519, 309, 311, 3297, 709, 51110], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 710, "seek": 434100, "start": 4355.92, "end": 4362.76, "text": " harder than what the most boasting people believe there's many problems to solve", "tokens": [51110, 6081, 813, 437, 264, 881, 748, 30587, 561, 1697, 456, 311, 867, 2740, 281, 5039, 51452], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 711, "seek": 434100, "start": 4362.76, "end": 4367.24, "text": " along the way and before we get to human level AI we're going to get to", "tokens": [51452, 2051, 264, 636, 293, 949, 321, 483, 281, 1952, 1496, 7318, 321, 434, 516, 281, 483, 281, 51676], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 712, "seek": 434100, "start": 4367.24, "end": 4370.8, "text": " something like cat level AI okay so people who are scared that you know", "tokens": [51676, 746, 411, 3857, 1496, 7318, 1392, 370, 561, 567, 366, 5338, 300, 291, 458, 51854], "temperature": 0.0, "avg_logprob": -0.17186097745542173, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.004730690736323595}, {"id": 713, "seek": 437080, "start": 4370.8, "end": 4374.72, "text": " one day someone is going to discover the secret of human level AI is going to", "tokens": [50364, 472, 786, 1580, 307, 516, 281, 4411, 264, 4054, 295, 1952, 1496, 7318, 307, 516, 281, 50560], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 714, "seek": 437080, "start": 4374.72, "end": 4378.24, "text": " turn on this gigantic computer and that gigantic computer is going to take over", "tokens": [50560, 1261, 322, 341, 26800, 3820, 293, 300, 26800, 3820, 307, 516, 281, 747, 670, 50736], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 715, "seek": 437080, "start": 4378.24, "end": 4383.64, "text": " the world and kill everyone that's just ridiculously stupid just cannot possibly", "tokens": [50736, 264, 1002, 293, 1961, 1518, 300, 311, 445, 41358, 6631, 445, 2644, 6264, 51006], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 716, "seek": 437080, "start": 4383.64, "end": 4386.92, "text": " happen we're gonna start small we're gonna you know start with something that", "tokens": [51006, 1051, 321, 434, 799, 722, 1359, 321, 434, 799, 291, 458, 722, 365, 746, 300, 51170], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 717, "seek": 437080, "start": 4386.92, "end": 4390.360000000001, "text": " has all the right components but it's small it's not gonna be very smart it's", "tokens": [51170, 575, 439, 264, 558, 6677, 457, 309, 311, 1359, 309, 311, 406, 799, 312, 588, 4069, 309, 311, 51342], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 718, "seek": 437080, "start": 4390.360000000001, "end": 4396.360000000001, "text": " gonna be like a rat or a cat right and then we're gonna work our way up and you", "tokens": [51342, 799, 312, 411, 257, 5937, 420, 257, 3857, 558, 293, 550, 321, 434, 799, 589, 527, 636, 493, 293, 291, 51642], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 719, "seek": 437080, "start": 4396.360000000001, "end": 4400.4400000000005, "text": " know change the objectives to make sure it's safe and test it in all kinds of", "tokens": [51642, 458, 1319, 264, 15961, 281, 652, 988, 309, 311, 3273, 293, 1500, 309, 294, 439, 3685, 295, 51846], "temperature": 0.0, "avg_logprob": -0.11561013746631238, "compression_ratio": 1.936842105263158, "no_speech_prob": 0.00198527448810637}, {"id": 720, "seek": 440044, "start": 4400.48, "end": 4405.639999999999, "text": " sandboxes and blah blah blah so this idea somehow that you know the discovery of", "tokens": [50366, 42115, 279, 293, 12288, 12288, 12288, 370, 341, 1558, 6063, 300, 291, 458, 264, 12114, 295, 50624], "temperature": 0.0, "avg_logprob": -0.17066250490338614, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0009381641866639256}, {"id": 721, "seek": 440044, "start": 4405.639999999999, "end": 4410.4, "text": " AI is going to be an event and that machines are going to escape for control", "tokens": [50624, 7318, 307, 516, 281, 312, 364, 2280, 293, 300, 8379, 366, 516, 281, 7615, 337, 1969, 50862], "temperature": 0.0, "avg_logprob": -0.17066250490338614, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0009381641866639256}, {"id": 722, "seek": 440044, "start": 4410.4, "end": 4417.36, "text": " that's Hollywood movies it's not the real world there is no such thing as a", "tokens": [50862, 300, 311, 11628, 6233, 309, 311, 406, 264, 957, 1002, 456, 307, 572, 1270, 551, 382, 257, 51210], "temperature": 0.0, "avg_logprob": -0.17066250490338614, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0009381641866639256}, {"id": 723, "seek": 440044, "start": 4417.36, "end": 4422.839999999999, "text": " GI anyway because intelligence is really a multi-dimensional thing humans are", "tokens": [51210, 26634, 4033, 570, 7599, 307, 534, 257, 4825, 12, 18759, 551, 6255, 366, 51484], "temperature": 0.0, "avg_logprob": -0.17066250490338614, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0009381641866639256}, {"id": 724, "seek": 440044, "start": 4422.839999999999, "end": 4428.759999999999, "text": " only good at certain things and terrible at many things in fact our minds are", "tokens": [51484, 787, 665, 412, 1629, 721, 293, 6237, 412, 867, 721, 294, 1186, 527, 9634, 366, 51780], "temperature": 0.0, "avg_logprob": -0.17066250490338614, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0009381641866639256}, {"id": 725, "seek": 442876, "start": 4428.76, "end": 4433.4800000000005, "text": " extremely specialized we don't realize this but we're incredibly specialized and", "tokens": [50364, 4664, 19813, 321, 500, 380, 4325, 341, 457, 321, 434, 6252, 19813, 293, 50600], "temperature": 0.0, "avg_logprob": -0.16476706096104213, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.002919652033597231}, {"id": 726, "seek": 442876, "start": 4433.4800000000005, "end": 4438.76, "text": " we know this because computers are much better than us at many tasks for example", "tokens": [50600, 321, 458, 341, 570, 10807, 366, 709, 1101, 813, 505, 412, 867, 9608, 337, 1365, 50864], "temperature": 0.0, "avg_logprob": -0.16476706096104213, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.002919652033597231}, {"id": 727, "seek": 442876, "start": 4438.76, "end": 4446.6, "text": " chess go poker pretty much every video game I mean not today but eventually", "tokens": [50864, 24122, 352, 36863, 1238, 709, 633, 960, 1216, 286, 914, 406, 965, 457, 4728, 51256], "temperature": 0.0, "avg_logprob": -0.16476706096104213, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.002919652033597231}, {"id": 728, "seek": 442876, "start": 4446.6, "end": 4452.76, "text": " recognizing a species of a bird by just listening to the song recognizing an", "tokens": [51256, 18538, 257, 6172, 295, 257, 5255, 538, 445, 4764, 281, 264, 2153, 18538, 364, 51564], "temperature": 0.0, "avg_logprob": -0.16476706096104213, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.002919652033597231}, {"id": 729, "seek": 442876, "start": 4452.76, "end": 4457.56, "text": " individual whale or marine mammal by the shape of the tail like AI systems can do", "tokens": [51564, 2609, 25370, 420, 20246, 49312, 538, 264, 3909, 295, 264, 6838, 411, 7318, 3652, 393, 360, 51804], "temperature": 0.0, "avg_logprob": -0.16476706096104213, "compression_ratio": 1.6569037656903767, "no_speech_prob": 0.002919652033597231}, {"id": 730, "seek": 445756, "start": 4457.56, "end": 4464.080000000001, "text": " this a very small number of humans can do all of this I mean we just we totally", "tokens": [50364, 341, 257, 588, 1359, 1230, 295, 6255, 393, 360, 439, 295, 341, 286, 914, 321, 445, 321, 3879, 50690], "temperature": 0.0, "avg_logprob": -0.15197521989995783, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0009097261354327202}, {"id": 731, "seek": 445756, "start": 4464.080000000001, "end": 4468.92, "text": " suck at chess as humans machines are much better than we are and so we don't", "tokens": [50690, 9967, 412, 24122, 382, 6255, 8379, 366, 709, 1101, 813, 321, 366, 293, 370, 321, 500, 380, 50932], "temperature": 0.0, "avg_logprob": -0.15197521989995783, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0009097261354327202}, {"id": 732, "seek": 445756, "start": 4468.92, "end": 4475.120000000001, "text": " have general intelligence ourselves so this word a GI makes no sense human", "tokens": [50932, 362, 2674, 7599, 4175, 370, 341, 1349, 257, 26634, 1669, 572, 2020, 1952, 51242], "temperature": 0.0, "avg_logprob": -0.15197521989995783, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0009097261354327202}, {"id": 733, "seek": 445756, "start": 4475.120000000001, "end": 4480.400000000001, "text": " level yes a GI no there's no question as I said before that machines will", "tokens": [51242, 1496, 2086, 257, 26634, 572, 456, 311, 572, 1168, 382, 286, 848, 949, 300, 8379, 486, 51506], "temperature": 0.0, "avg_logprob": -0.15197521989995783, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0009097261354327202}, {"id": 734, "seek": 445756, "start": 4480.400000000001, "end": 4486.0, "text": " eventually surpass human intelligence and so people are scared by this but", "tokens": [51506, 4728, 27650, 1952, 7599, 293, 370, 561, 366, 5338, 538, 341, 457, 51786], "temperature": 0.0, "avg_logprob": -0.15197521989995783, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0009097261354327202}, {"id": 735, "seek": 448600, "start": 4486.04, "end": 4493.84, "text": " really is a interesting question to ask ourselves imagine a future maybe 20 years", "tokens": [50366, 534, 307, 257, 1880, 1168, 281, 1029, 4175, 3811, 257, 2027, 1310, 945, 924, 50756], "temperature": 0.0, "avg_logprob": -0.17780524124333888, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001770852948538959}, {"id": 736, "seek": 448600, "start": 4493.84, "end": 4500.72, "text": " from now or maybe longer where every single one of our interactions with the", "tokens": [50756, 490, 586, 420, 1310, 2854, 689, 633, 2167, 472, 295, 527, 13280, 365, 264, 51100], "temperature": 0.0, "avg_logprob": -0.17780524124333888, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001770852948538959}, {"id": 737, "seek": 448600, "start": 4500.72, "end": 4504.44, "text": " digital world is mediated by an AI system okay and it might happen faster", "tokens": [51100, 4562, 1002, 307, 17269, 770, 538, 364, 7318, 1185, 1392, 293, 309, 1062, 1051, 4663, 51286], "temperature": 0.0, "avg_logprob": -0.17780524124333888, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001770852948538959}, {"id": 738, "seek": 448600, "start": 4504.44, "end": 4509.4, "text": " actually okay if some of the startups are being created today and some of the", "tokens": [51286, 767, 1392, 498, 512, 295, 264, 28041, 366, 885, 2942, 965, 293, 512, 295, 264, 51534], "temperature": 0.0, "avg_logprob": -0.17780524124333888, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001770852948538959}, {"id": 739, "seek": 448600, "start": 4509.4, "end": 4514.04, "text": " big company plans product plans actually fulfilled this may happen fairly", "tokens": [51534, 955, 2237, 5482, 1674, 5482, 767, 21380, 341, 815, 1051, 6457, 51766], "temperature": 0.0, "avg_logprob": -0.17780524124333888, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001770852948538959}, {"id": 740, "seek": 451404, "start": 4514.04, "end": 4518.88, "text": " quickly that essentially every time that we want to connect to the digital", "tokens": [50364, 2661, 300, 4476, 633, 565, 300, 321, 528, 281, 1745, 281, 264, 4562, 50606], "temperature": 0.0, "avg_logprob": -0.19089488129117596, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.004292772617191076}, {"id": 741, "seek": 451404, "start": 4518.88, "end": 4524.72, "text": " world that will be through the intermediary of an AI system then those", "tokens": [50606, 1002, 300, 486, 312, 807, 264, 15184, 822, 295, 364, 7318, 1185, 550, 729, 50898], "temperature": 0.0, "avg_logprob": -0.19089488129117596, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.004292772617191076}, {"id": 742, "seek": 451404, "start": 4524.72, "end": 4533.12, "text": " systems will become the repository of all human knowledge right and it's very", "tokens": [50898, 3652, 486, 1813, 264, 25841, 295, 439, 1952, 3601, 558, 293, 309, 311, 588, 51318], "temperature": 0.0, "avg_logprob": -0.19089488129117596, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.004292772617191076}, {"id": 743, "seek": 451404, "start": 4533.12, "end": 4539.8, "text": " important for that at least the base for a foundation of this to be open source", "tokens": [51318, 1021, 337, 300, 412, 1935, 264, 3096, 337, 257, 7030, 295, 341, 281, 312, 1269, 4009, 51652], "temperature": 0.0, "avg_logprob": -0.19089488129117596, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.004292772617191076}, {"id": 744, "seek": 453980, "start": 4540.16, "end": 4544.400000000001, "text": " every infrastructure the internet is open source runs on open source software", "tokens": [50382, 633, 6896, 264, 4705, 307, 1269, 4009, 6676, 322, 1269, 4009, 4722, 50594], "temperature": 0.0, "avg_logprob": -0.17385104684268726, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.0038671395741403103}, {"id": 745, "seek": 453980, "start": 4544.400000000001, "end": 4549.88, "text": " and the reason is because it's too important for one company to control it", "tokens": [50594, 293, 264, 1778, 307, 570, 309, 311, 886, 1021, 337, 472, 2237, 281, 1969, 309, 50868], "temperature": 0.0, "avg_logprob": -0.17385104684268726, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.0038671395741403103}, {"id": 746, "seek": 453980, "start": 4549.88, "end": 4556.0, "text": " right so it's the same for AI systems they will have to be open source because", "tokens": [50868, 558, 370, 309, 311, 264, 912, 337, 7318, 3652, 436, 486, 362, 281, 312, 1269, 4009, 570, 51174], "temperature": 0.0, "avg_logprob": -0.17385104684268726, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.0038671395741403103}, {"id": 747, "seek": 453980, "start": 4556.0, "end": 4560.0, "text": " it's too important for any single company or small number of Californian", "tokens": [51174, 309, 311, 886, 1021, 337, 604, 2167, 2237, 420, 1359, 1230, 295, 5284, 952, 51374], "temperature": 0.0, "avg_logprob": -0.17385104684268726, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.0038671395741403103}, {"id": 748, "seek": 453980, "start": 4560.0, "end": 4566.52, "text": " company to control AI systems if all of our information of all the citizens are", "tokens": [51374, 2237, 281, 1969, 7318, 3652, 498, 439, 295, 527, 1589, 295, 439, 264, 7180, 366, 51700], "temperature": 0.0, "avg_logprob": -0.17385104684268726, "compression_ratio": 1.8731707317073172, "no_speech_prob": 0.0038671395741403103}, {"id": 749, "seek": 456652, "start": 4566.56, "end": 4572.0, "text": " basically filtered through those AI systems the way those systems will be", "tokens": [50366, 1936, 37111, 807, 729, 7318, 3652, 264, 636, 729, 3652, 486, 312, 50638], "temperature": 0.0, "avg_logprob": -0.15443086063160616, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.007165984250605106}, {"id": 750, "seek": 456652, "start": 4572.0, "end": 4576.240000000001, "text": " trained will need to be quite sourced kind of like Wikipedia to collect", "tokens": [50638, 8895, 486, 643, 281, 312, 1596, 11006, 1232, 733, 295, 411, 28999, 281, 2500, 50850], "temperature": 0.0, "avg_logprob": -0.15443086063160616, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.007165984250605106}, {"id": 751, "seek": 456652, "start": 4576.240000000001, "end": 4580.64, "text": " culture and information and knowledge from the entire world not just from the", "tokens": [50850, 3713, 293, 1589, 293, 3601, 490, 264, 2302, 1002, 406, 445, 490, 264, 51070], "temperature": 0.0, "avg_logprob": -0.15443086063160616, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.007165984250605106}, {"id": 752, "seek": 456652, "start": 4580.64, "end": 4587.84, "text": " view of the world in parallel to us in place right so that's why I'm a huge", "tokens": [51070, 1910, 295, 264, 1002, 294, 8952, 281, 505, 294, 1081, 558, 370, 300, 311, 983, 286, 478, 257, 2603, 51430], "temperature": 0.0, "avg_logprob": -0.15443086063160616, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.007165984250605106}, {"id": 753, "seek": 456652, "start": 4587.84, "end": 4594.4800000000005, "text": " advocate of open source base models for AI and a number of my colleagues at", "tokens": [51430, 14608, 295, 1269, 4009, 3096, 5245, 337, 7318, 293, 257, 1230, 295, 452, 7734, 412, 51762], "temperature": 0.0, "avg_logprob": -0.15443086063160616, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.007165984250605106}, {"id": 754, "seek": 459448, "start": 4595.2, "end": 4599.24, "text": " Meta and his company policy at Meta to open source those base models because it", "tokens": [50400, 6377, 64, 293, 702, 2237, 3897, 412, 6377, 64, 281, 1269, 4009, 729, 3096, 5245, 570, 309, 50602], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 755, "seek": 459448, "start": 4599.24, "end": 4605.959999999999, "text": " makes them safer more powerful they progress faster they're more culturally", "tokens": [50602, 1669, 552, 15856, 544, 4005, 436, 4205, 4663, 436, 434, 544, 28879, 50938], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 756, "seek": 459448, "start": 4605.959999999999, "end": 4610.2, "text": " diverse if more people can train them and it creates an entire ecosystem of", "tokens": [50938, 9521, 498, 544, 561, 393, 3847, 552, 293, 309, 7829, 364, 2302, 11311, 295, 51150], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 757, "seek": 459448, "start": 4610.2, "end": 4615.799999999999, "text": " startups and research projects that can build on top of it so it's a very", "tokens": [51150, 28041, 293, 2132, 4455, 300, 393, 1322, 322, 1192, 295, 309, 370, 309, 311, 257, 588, 51430], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 758, "seek": 459448, "start": 4615.799999999999, "end": 4620.28, "text": " important political questions at the moment because a lot of companies are", "tokens": [51430, 1021, 3905, 1651, 412, 264, 1623, 570, 257, 688, 295, 3431, 366, 51654], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 759, "seek": 459448, "start": 4620.28, "end": 4624.24, "text": " pressuring governments around the world including the German government to", "tokens": [51654, 1886, 1345, 11280, 926, 264, 1002, 3009, 264, 6521, 2463, 281, 51852], "temperature": 0.0, "avg_logprob": -0.16231716672579447, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.011897441931068897}, {"id": 760, "seek": 462424, "start": 4624.24, "end": 4629.4, "text": " basically keep AI under lock and key to say AI is too dangerous it needs to be", "tokens": [50364, 1936, 1066, 7318, 833, 4017, 293, 2141, 281, 584, 7318, 307, 886, 5795, 309, 2203, 281, 312, 50622], "temperature": 0.0, "avg_logprob": -0.12609959744859014, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0032905780244618654}, {"id": 761, "seek": 462424, "start": 4629.4, "end": 4639.12, "text": " controlled and licensed and and not put into the hands of everyone I think it's", "tokens": [50622, 10164, 293, 25225, 293, 293, 406, 829, 666, 264, 2377, 295, 1518, 286, 519, 309, 311, 51108], "temperature": 0.0, "avg_logprob": -0.12609959744859014, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0032905780244618654}, {"id": 762, "seek": 462424, "start": 4639.12, "end": 4642.28, "text": " the exact opposite I think it's too dangerous to actually keep in the hands", "tokens": [51108, 264, 1900, 6182, 286, 519, 309, 311, 886, 5795, 281, 767, 1066, 294, 264, 2377, 51266], "temperature": 0.0, "avg_logprob": -0.12609959744859014, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0032905780244618654}, {"id": 763, "seek": 462424, "start": 4642.28, "end": 4647.719999999999, "text": " of just a few a few people okay so I became a little philosophical political", "tokens": [51266, 295, 445, 257, 1326, 257, 1326, 561, 1392, 370, 286, 3062, 257, 707, 25066, 3905, 51538], "temperature": 0.0, "avg_logprob": -0.12609959744859014, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0032905780244618654}, {"id": 764, "seek": 462424, "start": 4647.719999999999, "end": 4654.04, "text": " here those people have convinced the UK government the Prime Minister that", "tokens": [51538, 510, 729, 561, 362, 12561, 264, 7051, 2463, 264, 9655, 6506, 300, 51854], "temperature": 0.0, "avg_logprob": -0.12609959744859014, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0032905780244618654}, {"id": 765, "seek": 465404, "start": 4654.04, "end": 4660.16, "text": " AI should be regulated under lock and key apparently the EU Commission also is", "tokens": [50364, 7318, 820, 312, 26243, 833, 4017, 293, 2141, 7970, 264, 10887, 10766, 611, 307, 50670], "temperature": 0.0, "avg_logprob": -0.16273001262119838, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0016595273045822978}, {"id": 766, "seek": 465404, "start": 4660.16, "end": 4669.8, "text": " convinced this is very bad and I think if we do it right AI will make everybody", "tokens": [50670, 12561, 341, 307, 588, 1578, 293, 286, 519, 498, 321, 360, 309, 558, 7318, 486, 652, 2201, 51152], "temperature": 0.0, "avg_logprob": -0.16273001262119838, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0016595273045822978}, {"id": 767, "seek": 465404, "start": 4669.8, "end": 4674.12, "text": " smarter it's like we all have those intelligent assistant with us all the", "tokens": [51152, 20294, 309, 311, 411, 321, 439, 362, 729, 13232, 10994, 365, 505, 439, 264, 51368], "temperature": 0.0, "avg_logprob": -0.16273001262119838, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0016595273045822978}, {"id": 768, "seek": 465404, "start": 4674.12, "end": 4677.8, "text": " time it's like having a staff of intelligent people working for you okay", "tokens": [51368, 565, 309, 311, 411, 1419, 257, 3525, 295, 13232, 561, 1364, 337, 291, 1392, 51552], "temperature": 0.0, "avg_logprob": -0.16273001262119838, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0016595273045822978}, {"id": 769, "seek": 465404, "start": 4677.8, "end": 4683.12, "text": " every person who is leading anything including me only works with people who", "tokens": [51552, 633, 954, 567, 307, 5775, 1340, 3009, 385, 787, 1985, 365, 561, 567, 51818], "temperature": 0.0, "avg_logprob": -0.16273001262119838, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0016595273045822978}, {"id": 770, "seek": 468312, "start": 4683.16, "end": 4686.88, "text": " are smarter than them right I only hire people who are smarter than me because", "tokens": [50366, 366, 20294, 813, 552, 558, 286, 787, 11158, 561, 567, 366, 20294, 813, 385, 570, 50552], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 771, "seek": 468312, "start": 4686.88, "end": 4690.08, "text": " that's the way to be successful so that everybody is gonna be like that we'll", "tokens": [50552, 300, 311, 264, 636, 281, 312, 4406, 370, 300, 2201, 307, 799, 312, 411, 300, 321, 603, 50712], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 772, "seek": 468312, "start": 4690.08, "end": 4693.96, "text": " have AI assistant that are smarter than us we shouldn't feel threatened by them", "tokens": [50712, 362, 7318, 10994, 300, 366, 20294, 813, 505, 321, 4659, 380, 841, 18268, 538, 552, 50906], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 773, "seek": 468312, "start": 4693.96, "end": 4697.68, "text": " because we'll be controlling them they will be designed to be subservient to us", "tokens": [50906, 570, 321, 603, 312, 14905, 552, 436, 486, 312, 4761, 281, 312, 2090, 1978, 1196, 281, 505, 51092], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 774, "seek": 468312, "start": 4697.68, "end": 4703.5599999999995, "text": " so this may have an effect on society similar to what the printing press had", "tokens": [51092, 370, 341, 815, 362, 364, 1802, 322, 4086, 2531, 281, 437, 264, 14699, 1886, 632, 51386], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 775, "seek": 468312, "start": 4703.5599999999995, "end": 4710.48, "text": " probably 500 years ago not too far from here of basically causing a new", "tokens": [51386, 1391, 5923, 924, 2057, 406, 886, 1400, 490, 510, 295, 1936, 9853, 257, 777, 51732], "temperature": 0.0, "avg_logprob": -0.15614233284353096, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006496048532426357}, {"id": 776, "seek": 471048, "start": 4710.5199999999995, "end": 4714.24, "text": " renaissance because intelligence is really the commodity that we lack the", "tokens": [50366, 319, 629, 14431, 570, 7599, 307, 534, 264, 29125, 300, 321, 5011, 264, 50552], "temperature": 0.0, "avg_logprob": -0.2065416063581194, "compression_ratio": 1.3265306122448979, "no_speech_prob": 0.021990660578012466}, {"id": 777, "seek": 471048, "start": 4714.24, "end": 4720.48, "text": " most this will make humanity smarter thank you very much", "tokens": [50552, 881, 341, 486, 652, 10243, 20294, 1309, 291, 588, 709, 50864], "temperature": 0.0, "avg_logprob": -0.2065416063581194, "compression_ratio": 1.3265306122448979, "no_speech_prob": 0.021990660578012466}, {"id": 778, "seek": 474048, "start": 4740.48, "end": 4751.36, "text": " yeah thank you so very much Jan for an amazing lecture we have about 10 minutes", "tokens": [50364, 1338, 1309, 291, 370, 588, 709, 4956, 337, 364, 2243, 7991, 321, 362, 466, 1266, 2077, 50908], "temperature": 0.0, "avg_logprob": -0.33703509739467075, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.010859043337404728}, {"id": 779, "seek": 474048, "start": 4751.36, "end": 4762.2, "text": " for questions and I'm sure there are several so much for the great talk", "tokens": [50908, 337, 1651, 293, 286, 478, 988, 456, 366, 2940, 370, 709, 337, 264, 869, 751, 51450], "temperature": 0.0, "avg_logprob": -0.33703509739467075, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.010859043337404728}, {"id": 780, "seek": 474048, "start": 4762.2, "end": 4766.36, "text": " customer from a minute you alluded to the fact that we should keep code open", "tokens": [51450, 5474, 490, 257, 3456, 291, 33919, 281, 264, 1186, 300, 321, 820, 1066, 3089, 1269, 51658], "temperature": 0.0, "avg_logprob": -0.33703509739467075, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.010859043337404728}, {"id": 781, "seek": 474048, "start": 4766.36, "end": 4770.32, "text": " which is great however as you know right many of the recent developments not", "tokens": [51658, 597, 307, 869, 4461, 382, 291, 458, 558, 867, 295, 264, 5162, 20862, 406, 51856], "temperature": 0.0, "avg_logprob": -0.33703509739467075, "compression_ratio": 1.5482233502538072, "no_speech_prob": 0.010859043337404728}, {"id": 782, "seek": 477032, "start": 4770.32, "end": 4773.36, "text": " just rely on the code but also on the hardware so many of the things are", "tokens": [50364, 445, 10687, 322, 264, 3089, 457, 611, 322, 264, 8837, 370, 867, 295, 264, 721, 366, 50516], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 783, "seek": 477032, "start": 4773.36, "end": 4777.96, "text": " developed at companies because they have access to a large GPU resources now not", "tokens": [50516, 4743, 412, 3431, 570, 436, 362, 2105, 281, 257, 2416, 18407, 3593, 586, 406, 50746], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 784, "seek": 477032, "start": 4777.96, "end": 4781.799999999999, "text": " only Germany I guess we are limited by that so and what's your take on that", "tokens": [50746, 787, 7244, 286, 2041, 321, 366, 5567, 538, 300, 370, 293, 437, 311, 428, 747, 322, 300, 50938], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 785, "seek": 477032, "start": 4781.799999999999, "end": 4786.599999999999, "text": " also being in an academic and an meta environment right how do you deal", "tokens": [50938, 611, 885, 294, 364, 7778, 293, 364, 19616, 2823, 558, 577, 360, 291, 2028, 51178], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 786, "seek": 477032, "start": 4786.599999999999, "end": 4789.92, "text": " yourself with it do you do some things only at universities and others only at", "tokens": [51178, 1803, 365, 309, 360, 291, 360, 512, 721, 787, 412, 11779, 293, 2357, 787, 412, 51344], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 787, "seek": 477032, "start": 4789.92, "end": 4796.32, "text": " meta or how I mean how do you see that in the future okay should have used an", "tokens": [51344, 19616, 420, 577, 286, 914, 577, 360, 291, 536, 300, 294, 264, 2027, 1392, 820, 362, 1143, 364, 51664], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 788, "seek": 477032, "start": 4796.32, "end": 4799.92, "text": " automatic speech recognizer because there is an awful echo and it's very hard to", "tokens": [51664, 12509, 6218, 3068, 6545, 570, 456, 307, 364, 11232, 14300, 293, 309, 311, 588, 1152, 281, 51844], "temperature": 0.0, "avg_logprob": -0.18030519334096756, "compression_ratio": 1.7672131147540984, "no_speech_prob": 0.011672601103782654}, {"id": 789, "seek": 479992, "start": 4799.92, "end": 4807.68, "text": " understand it's not your fault but anyway I mean hardware is a big limitation so", "tokens": [50364, 1223, 309, 311, 406, 428, 7441, 457, 4033, 286, 914, 8837, 307, 257, 955, 27432, 370, 50752], "temperature": 0.0, "avg_logprob": -0.19279722940354121, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.0024203092325478792}, {"id": 790, "seek": 479992, "start": 4807.68, "end": 4811.88, "text": " currently the only entities they can train large language models that are", "tokens": [50752, 4362, 264, 787, 16667, 436, 393, 3847, 2416, 2856, 5245, 300, 366, 50962], "temperature": 0.0, "avg_logprob": -0.19279722940354121, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.0024203092325478792}, {"id": 791, "seek": 479992, "start": 4811.88, "end": 4817.4800000000005, "text": " good are people who have access to large amounts of computation either in-house", "tokens": [50962, 665, 366, 561, 567, 362, 2105, 281, 2416, 11663, 295, 24903, 2139, 294, 12, 6410, 51242], "temperature": 0.0, "avg_logprob": -0.19279722940354121, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.0024203092325478792}, {"id": 792, "seek": 479992, "start": 4817.4800000000005, "end": 4824.24, "text": " which is the case for Google and meta and Microsoft or through cloud services", "tokens": [51242, 597, 307, 264, 1389, 337, 3329, 293, 19616, 293, 8116, 420, 807, 4588, 3328, 51580], "temperature": 0.0, "avg_logprob": -0.19279722940354121, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.0024203092325478792}, {"id": 793, "seek": 479992, "start": 4824.24, "end": 4828.0, "text": " which is the case for open AI and entropy can others they have access to", "tokens": [51580, 597, 307, 264, 1389, 337, 1269, 7318, 293, 30867, 393, 2357, 436, 362, 2105, 281, 51768], "temperature": 0.0, "avg_logprob": -0.19279722940354121, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.0024203092325478792}, {"id": 794, "seek": 482800, "start": 4828.0, "end": 4832.24, "text": " Microsoft Azure and you know some of them use AWS some of them use other", "tokens": [50364, 8116, 11969, 293, 291, 458, 512, 295, 552, 764, 17650, 512, 295, 552, 764, 661, 50576], "temperature": 0.0, "avg_logprob": -0.1543224146077921, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.003521307371556759}, {"id": 795, "seek": 482800, "start": 4832.24, "end": 4837.64, "text": " other tools so but that costs a huge amount of money so training a sort of", "tokens": [50576, 661, 3873, 370, 457, 300, 5497, 257, 2603, 2372, 295, 1460, 370, 3097, 257, 1333, 295, 50846], "temperature": 0.0, "avg_logprob": -0.1543224146077921, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.003521307371556759}, {"id": 796, "seek": 482800, "start": 4837.64, "end": 4841.88, "text": " top-of-the-line language model today you know costs tens of millions of euros", "tokens": [50846, 1192, 12, 2670, 12, 3322, 12, 1889, 2856, 2316, 965, 291, 458, 5497, 10688, 295, 6803, 295, 14160, 51058], "temperature": 0.0, "avg_logprob": -0.1543224146077921, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.003521307371556759}, {"id": 797, "seek": 482800, "start": 4841.88, "end": 4850.0, "text": " right it depends how many tens depends on how you do it possibly more if you", "tokens": [51058, 558, 309, 5946, 577, 867, 10688, 5946, 322, 577, 291, 360, 309, 6264, 544, 498, 291, 51464], "temperature": 0.0, "avg_logprob": -0.1543224146077921, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.003521307371556759}, {"id": 798, "seek": 482800, "start": 4850.0, "end": 4855.84, "text": " want to buy an infrastructure that is sufficient power today you have to buy", "tokens": [51464, 528, 281, 2256, 364, 6896, 300, 307, 11563, 1347, 965, 291, 362, 281, 2256, 51756], "temperature": 0.0, "avg_logprob": -0.1543224146077921, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.003521307371556759}, {"id": 799, "seek": 485584, "start": 4855.84, "end": 4864.72, "text": " basically stuff from Nvidia and is going to cost you a number with with 10", "tokens": [50364, 1936, 1507, 490, 46284, 293, 307, 516, 281, 2063, 291, 257, 1230, 365, 365, 1266, 50808], "temperature": 0.0, "avg_logprob": -0.16216829087999132, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.004044439643621445}, {"id": 800, "seek": 485584, "start": 4864.72, "end": 4872.04, "text": " digits it's in the billions it's insane so what that tells you is that it's like", "tokens": [50808, 27011, 309, 311, 294, 264, 17375, 309, 311, 10838, 370, 437, 300, 5112, 291, 307, 300, 309, 311, 411, 51174], "temperature": 0.0, "avg_logprob": -0.16216829087999132, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.004044439643621445}, {"id": 801, "seek": 485584, "start": 4872.04, "end": 4877.4400000000005, "text": " it's like an autobahn you don't want 10 parallel autobahn going from one city to", "tokens": [51174, 309, 311, 411, 364, 1476, 996, 12140, 291, 500, 380, 528, 1266, 8952, 1476, 996, 12140, 516, 490, 472, 2307, 281, 51444], "temperature": 0.0, "avg_logprob": -0.16216829087999132, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.004044439643621445}, {"id": 802, "seek": 485584, "start": 4877.4400000000005, "end": 4883.04, "text": " another city you just want one and that has to be sort of accessible to everyone", "tokens": [51444, 1071, 2307, 291, 445, 528, 472, 293, 300, 575, 281, 312, 1333, 295, 9515, 281, 1518, 51724], "temperature": 0.0, "avg_logprob": -0.16216829087999132, "compression_ratio": 1.6772486772486772, "no_speech_prob": 0.004044439643621445}, {"id": 803, "seek": 488304, "start": 4883.04, "end": 4887.84, "text": " so that's the idea behind open source base model foundation model they need to", "tokens": [50364, 370, 300, 311, 264, 1558, 2261, 1269, 4009, 3096, 2316, 7030, 2316, 436, 643, 281, 50604], "temperature": 0.0, "avg_logprob": -0.193215274810791, "compression_ratio": 1.6583850931677018, "no_speech_prob": 0.006330658216029406}, {"id": 804, "seek": 488304, "start": 4887.84, "end": 4891.32, "text": " be open source because it's a common infrastructure they can be customized", "tokens": [50604, 312, 1269, 4009, 570, 309, 311, 257, 2689, 6896, 436, 393, 312, 30581, 50778], "temperature": 0.0, "avg_logprob": -0.193215274810791, "compression_ratio": 1.6583850931677018, "no_speech_prob": 0.006330658216029406}, {"id": 805, "seek": 488304, "start": 4891.32, "end": 4896.44, "text": " and there's no point having 50 of them because they cost so much to train that's", "tokens": [50778, 293, 456, 311, 572, 935, 1419, 2625, 295, 552, 570, 436, 2063, 370, 709, 281, 3847, 300, 311, 51034], "temperature": 0.0, "avg_logprob": -0.193215274810791, "compression_ratio": 1.6583850931677018, "no_speech_prob": 0.006330658216029406}, {"id": 806, "seek": 488304, "start": 4896.44, "end": 4899.76, "text": " another argument for open source", "tokens": [51034, 1071, 6770, 337, 1269, 4009, 51200], "temperature": 0.0, "avg_logprob": -0.193215274810791, "compression_ratio": 1.6583850931677018, "no_speech_prob": 0.006330658216029406}, {"id": 807, "seek": 491304, "start": 4913.08, "end": 4919.5199999999995, "text": " hello yes hi thank you for the great lecture there was a slide that had", "tokens": [50366, 7751, 2086, 4879, 1309, 291, 337, 264, 869, 7991, 456, 390, 257, 4137, 300, 632, 50688], "temperature": 0.0, "avg_logprob": -0.17712288686673935, "compression_ratio": 1.6134020618556701, "no_speech_prob": 0.007171968463808298}, {"id": 808, "seek": 491304, "start": 4919.5199999999995, "end": 4924.12, "text": " challenges of AI and machine learning and there were three points in there it", "tokens": [50688, 4759, 295, 7318, 293, 3479, 2539, 293, 456, 645, 1045, 2793, 294, 456, 309, 50918], "temperature": 0.0, "avg_logprob": -0.17712288686673935, "compression_ratio": 1.6134020618556701, "no_speech_prob": 0.007171968463808298}, {"id": 809, "seek": 491304, "start": 4924.12, "end": 4931.6, "text": " went by really fast and I couldn't catch if ethical fairness responsible AI was a", "tokens": [50918, 1437, 538, 534, 2370, 293, 286, 2809, 380, 3745, 498, 18890, 29765, 6250, 7318, 390, 257, 51292], "temperature": 0.0, "avg_logprob": -0.17712288686673935, "compression_ratio": 1.6134020618556701, "no_speech_prob": 0.007171968463808298}, {"id": 810, "seek": 491304, "start": 4931.6, "end": 4937.72, "text": " challenge that you're facing with and if so what are you doing about it okay so I", "tokens": [51292, 3430, 300, 291, 434, 7170, 365, 293, 498, 370, 437, 366, 291, 884, 466, 309, 1392, 370, 286, 51598], "temperature": 0.0, "avg_logprob": -0.17712288686673935, "compression_ratio": 1.6134020618556701, "no_speech_prob": 0.007171968463808298}, {"id": 811, "seek": 493772, "start": 4937.76, "end": 4943.52, "text": " think that point was wrapped into the the second point but sort of not", "tokens": [50366, 519, 300, 935, 390, 14226, 666, 264, 264, 1150, 935, 457, 1333, 295, 406, 50654], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 812, "seek": 493772, "start": 4943.52, "end": 4948.360000000001, "text": " mentioned directly it was more can I mention in the other thing so this idea", "tokens": [50654, 2835, 3838, 309, 390, 544, 393, 286, 2152, 294, 264, 661, 551, 370, 341, 1558, 50896], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 813, "seek": 493772, "start": 4948.360000000001, "end": 4952.8, "text": " of objective driven AI the fact that a system can only produce answers that", "tokens": [50896, 295, 10024, 9555, 7318, 264, 1186, 300, 257, 1185, 393, 787, 5258, 6338, 300, 51118], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 814, "seek": 493772, "start": 4952.8, "end": 4957.4800000000005, "text": " satisfy a number of objectives including some guardrails the answer to your", "tokens": [51118, 19319, 257, 1230, 295, 15961, 3009, 512, 6290, 424, 4174, 264, 1867, 281, 428, 51352], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 815, "seek": 493772, "start": 4957.4800000000005, "end": 4960.96, "text": " question is how do you design those guardrails essentially we don't have an", "tokens": [51352, 1168, 307, 577, 360, 291, 1715, 729, 6290, 424, 4174, 4476, 321, 500, 380, 362, 364, 51526], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 816, "seek": 493772, "start": 4960.96, "end": 4965.4800000000005, "text": " answer to this and the reason we don't have an answer to this is because we", "tokens": [51526, 1867, 281, 341, 293, 264, 1778, 321, 500, 380, 362, 364, 1867, 281, 341, 307, 570, 321, 51752], "temperature": 0.0, "avg_logprob": -0.12505528560051551, "compression_ratio": 1.8713692946058091, "no_speech_prob": 0.007522994186729193}, {"id": 817, "seek": 496548, "start": 4965.5199999999995, "end": 4971.919999999999, "text": " haven't really began to build systems of this type and so it's as if someone in", "tokens": [50366, 2378, 380, 534, 4283, 281, 1322, 3652, 295, 341, 2010, 293, 370, 309, 311, 382, 498, 1580, 294, 50686], "temperature": 0.0, "avg_logprob": -0.14183556406121506, "compression_ratio": 1.5803108808290156, "no_speech_prob": 0.0013809725642204285}, {"id": 818, "seek": 496548, "start": 4971.919999999999, "end": 4978.5599999999995, "text": " 1925 asked aviators how are you going to make sure that transatlantic", "tokens": [50686, 1294, 6074, 2351, 1305, 72, 3391, 577, 366, 291, 516, 281, 652, 988, 300, 1145, 48630, 7128, 51018], "temperature": 0.0, "avg_logprob": -0.14183556406121506, "compression_ratio": 1.5803108808290156, "no_speech_prob": 0.0013809725642204285}, {"id": 819, "seek": 496548, "start": 4978.5599999999995, "end": 4983.759999999999, "text": " transatlantic flight at near the speed of sound will be safe nobody could be", "tokens": [51018, 1145, 48630, 7128, 7018, 412, 2651, 264, 3073, 295, 1626, 486, 312, 3273, 5079, 727, 312, 51278], "temperature": 0.0, "avg_logprob": -0.14183556406121506, "compression_ratio": 1.5803108808290156, "no_speech_prob": 0.0013809725642204285}, {"id": 820, "seek": 496548, "start": 4983.759999999999, "end": 4989.28, "text": " possibly answering this nobody across the Atlantic on a plane in 1925 at least", "tokens": [51278, 6264, 13430, 341, 5079, 2108, 264, 20233, 322, 257, 5720, 294, 1294, 6074, 412, 1935, 51554], "temperature": 0.0, "avg_logprob": -0.14183556406121506, "compression_ratio": 1.5803108808290156, "no_speech_prob": 0.0013809725642204285}, {"id": 821, "seek": 498928, "start": 4989.28, "end": 4996.12, "text": " not in there not without any stuff nobody knew what a turbojet was like the", "tokens": [50364, 406, 294, 456, 406, 1553, 604, 1507, 5079, 2586, 437, 257, 20902, 7108, 390, 411, 264, 50706], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 822, "seek": 498928, "start": 4996.12, "end": 4999.2, "text": " idea of you know speaking at near the speed of sound was completely", "tokens": [50706, 1558, 295, 291, 458, 4124, 412, 2651, 264, 3073, 295, 1626, 390, 2584, 50860], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 823, "seek": 498928, "start": 4999.2, "end": 5004.0, "text": " unthinkable so we're a bit in the same situation we don't know how exactly how", "tokens": [50860, 517, 21074, 712, 370, 321, 434, 257, 857, 294, 264, 912, 2590, 321, 500, 380, 458, 577, 2293, 577, 51100], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 824, "seek": 498928, "start": 5004.0, "end": 5008.88, "text": " to make those things safe because we haven't built them yet but I think it's", "tokens": [51100, 281, 652, 729, 721, 3273, 570, 321, 2378, 380, 3094, 552, 1939, 457, 286, 519, 309, 311, 51344], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 825, "seek": 498928, "start": 5008.88, "end": 5012.719999999999, "text": " an engineering problem like any other problem and there is a there's a fallacy", "tokens": [51344, 364, 7043, 1154, 411, 604, 661, 1154, 293, 456, 307, 257, 456, 311, 257, 2100, 2551, 51536], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 826, "seek": 498928, "start": 5012.719999999999, "end": 5017.24, "text": " also which is that to design those objectives a lot of people say oh we've", "tokens": [51536, 611, 597, 307, 300, 281, 1715, 729, 15961, 257, 688, 295, 561, 584, 1954, 321, 600, 51762], "temperature": 0.0, "avg_logprob": -0.13829286248834283, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0031630913726985455}, {"id": 827, "seek": 501724, "start": 5017.28, "end": 5020.76, "text": " never done this before so we're not going to know how to do it but in fact we are", "tokens": [50366, 1128, 1096, 341, 949, 370, 321, 434, 406, 516, 281, 458, 577, 281, 360, 309, 457, 294, 1186, 321, 366, 50540], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 828, "seek": 501724, "start": 5020.76, "end": 5025.36, "text": " doing this all the time we've been doing it for millenia designing objectives so", "tokens": [50540, 884, 341, 439, 264, 565, 321, 600, 668, 884, 309, 337, 1728, 268, 654, 14685, 15961, 370, 50770], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 829, "seek": 501724, "start": 5025.36, "end": 5032.0, "text": " that intelligent entities behave properly that's called laws lawmaking is", "tokens": [50770, 300, 13232, 16667, 15158, 6108, 300, 311, 1219, 6064, 2101, 12402, 307, 51102], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 830, "seek": 501724, "start": 5032.0, "end": 5036.92, "text": " designing objectives for humans to behave properly and it's even designing", "tokens": [51102, 14685, 15961, 337, 6255, 281, 15158, 6108, 293, 309, 311, 754, 14685, 51348], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 831, "seek": 501724, "start": 5036.92, "end": 5042.08, "text": " objectives for superhuman entities to behave properly superhuman entities", "tokens": [51348, 15961, 337, 1687, 18796, 16667, 281, 15158, 6108, 1687, 18796, 16667, 51606], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 832, "seek": 501724, "start": 5042.08, "end": 5045.8, "text": " like corporations for example right corporate law basically is a way to make", "tokens": [51606, 411, 17676, 337, 1365, 558, 10896, 2101, 1936, 307, 257, 636, 281, 652, 51792], "temperature": 0.0, "avg_logprob": -0.14232869581742721, "compression_ratio": 2.026315789473684, "no_speech_prob": 0.012177083641290665}, {"id": 833, "seek": 504580, "start": 5045.8, "end": 5050.6, "text": " sure that whatever a corporation does is aligned more or less with the common", "tokens": [50364, 988, 300, 2035, 257, 22197, 775, 307, 17962, 544, 420, 1570, 365, 264, 2689, 50604], "temperature": 0.0, "avg_logprob": -0.20427751541137695, "compression_ratio": 1.6682692307692308, "no_speech_prob": 0.004127426538616419}, {"id": 834, "seek": 504580, "start": 5050.6, "end": 5054.04, "text": " good of society right of course you know they can be corruption and everything", "tokens": [50604, 665, 295, 4086, 558, 295, 1164, 291, 458, 436, 393, 312, 17959, 293, 1203, 50776], "temperature": 0.0, "avg_logprob": -0.20427751541137695, "compression_ratio": 1.6682692307692308, "no_speech_prob": 0.004127426538616419}, {"id": 835, "seek": 504580, "start": 5054.04, "end": 5058.04, "text": " but that's the that's a big idea so we're very familiar with this with this", "tokens": [50776, 457, 300, 311, 264, 300, 311, 257, 955, 1558, 370, 321, 434, 588, 4963, 365, 341, 365, 341, 50976], "temperature": 0.0, "avg_logprob": -0.20427751541137695, "compression_ratio": 1.6682692307692308, "no_speech_prob": 0.004127426538616419}, {"id": 836, "seek": 504580, "start": 5058.04, "end": 5062.64, "text": " this concept it's not it's not new", "tokens": [50976, 341, 3410, 309, 311, 406, 309, 311, 406, 777, 51206], "temperature": 0.0, "avg_logprob": -0.20427751541137695, "compression_ratio": 1.6682692307692308, "no_speech_prob": 0.004127426538616419}, {"id": 837, "seek": 504580, "start": 5069.04, "end": 5073.64, "text": " and thank you Jan for the really great talk I want to follow up on the question", "tokens": [51526, 293, 1309, 291, 4956, 337, 264, 534, 869, 751, 286, 528, 281, 1524, 493, 322, 264, 1168, 51756], "temperature": 0.0, "avg_logprob": -0.20427751541137695, "compression_ratio": 1.6682692307692308, "no_speech_prob": 0.004127426538616419}, {"id": 838, "seek": 507364, "start": 5073.64, "end": 5079.4400000000005, "text": " we had earlier about GPU resources what I see is that in machine learning and AI", "tokens": [50364, 321, 632, 3071, 466, 18407, 3593, 437, 286, 536, 307, 300, 294, 3479, 2539, 293, 7318, 50654], "temperature": 0.0, "avg_logprob": -0.18148656572614397, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012785753235220909}, {"id": 839, "seek": 507364, "start": 5079.4400000000005, "end": 5084.4800000000005, "text": " the biggest breakthroughs in the last years were achieved with huge amount of", "tokens": [50654, 264, 3880, 22397, 82, 294, 264, 1036, 924, 645, 11042, 365, 2603, 2372, 295, 50906], "temperature": 0.0, "avg_logprob": -0.18148656572614397, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012785753235220909}, {"id": 840, "seek": 507364, "start": 5084.4800000000005, "end": 5092.04, "text": " GPU resources the amount that academic institutions typically do not have do", "tokens": [50906, 18407, 3593, 264, 2372, 300, 7778, 8142, 5850, 360, 406, 362, 360, 51284], "temperature": 0.0, "avg_logprob": -0.18148656572614397, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012785753235220909}, {"id": 841, "seek": 507364, "start": 5092.04, "end": 5097.56, "text": " you see a future for academic research in the field of AI so I'm gonna can make", "tokens": [51284, 291, 536, 257, 2027, 337, 7778, 2132, 294, 264, 2519, 295, 7318, 370, 286, 478, 799, 393, 652, 51560], "temperature": 0.0, "avg_logprob": -0.18148656572614397, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.012785753235220909}, {"id": 842, "seek": 509756, "start": 5097.6, "end": 5104.6, "text": " myself I have two hats okay let me tell you something many of the best ideas come", "tokens": [50366, 2059, 286, 362, 732, 20549, 1392, 718, 385, 980, 291, 746, 867, 295, 264, 1151, 3487, 808, 50716], "temperature": 0.0, "avg_logprob": -0.1569787530338063, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.010099953040480614}, {"id": 843, "seek": 509756, "start": 5104.6, "end": 5110.120000000001, "text": " from academia okay the whole idea of generating images from text and things", "tokens": [50716, 490, 28937, 1392, 264, 1379, 1558, 295, 17746, 5267, 490, 2487, 293, 721, 50992], "temperature": 0.0, "avg_logprob": -0.1569787530338063, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.010099953040480614}, {"id": 844, "seek": 509756, "start": 5110.120000000001, "end": 5115.26, "text": " like this those actually came out of a German university right and then you", "tokens": [50992, 411, 341, 729, 767, 1361, 484, 295, 257, 6521, 5454, 558, 293, 550, 291, 51249], "temperature": 0.0, "avg_logprob": -0.1569787530338063, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.010099953040480614}, {"id": 845, "seek": 509756, "start": 5115.26, "end": 5120.320000000001, "text": " know people picked it up and made products out of it but originally this", "tokens": [51249, 458, 561, 6183, 309, 493, 293, 1027, 3383, 484, 295, 309, 457, 7993, 341, 51502], "temperature": 0.0, "avg_logprob": -0.1569787530338063, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.010099953040480614}, {"id": 846, "seek": 509756, "start": 5120.320000000001, "end": 5124.52, "text": " was done not too far from here in the university the whole idea of using", "tokens": [51502, 390, 1096, 406, 886, 1400, 490, 510, 294, 264, 5454, 264, 1379, 1558, 295, 1228, 51712], "temperature": 0.0, "avg_logprob": -0.1569787530338063, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.010099953040480614}, {"id": 847, "seek": 512452, "start": 5124.56, "end": 5129.280000000001, "text": " attention mechanisms which is the basis of transformers they came out of", "tokens": [50366, 3202, 15902, 597, 307, 264, 5143, 295, 4088, 433, 436, 1361, 484, 295, 50602], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 848, "seek": 512452, "start": 5129.280000000001, "end": 5135.9400000000005, "text": " university Montreal so that was an interesting story they this was Dimitri", "tokens": [50602, 5454, 34180, 370, 300, 390, 364, 1880, 1657, 436, 341, 390, 20975, 270, 470, 50935], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 849, "seek": 512452, "start": 5135.9400000000005, "end": 5141.280000000001, "text": " Bada now Kim Jong-chul who is now a colleague at NYU and Joshua Benjo and", "tokens": [50935, 363, 1538, 586, 5652, 19589, 12, 339, 425, 567, 307, 586, 257, 13532, 412, 42682, 293, 24005, 3964, 5134, 293, 51202], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 850, "seek": 512452, "start": 5141.280000000001, "end": 5144.88, "text": " they came up with this idea that when you build a translation system the system", "tokens": [51202, 436, 1361, 493, 365, 341, 1558, 300, 562, 291, 1322, 257, 12853, 1185, 264, 1185, 51382], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 851, "seek": 512452, "start": 5144.88, "end": 5150.6, "text": " should be able to decide which word to look at to translate you know English", "tokens": [51382, 820, 312, 1075, 281, 4536, 597, 1349, 281, 574, 412, 281, 13799, 291, 458, 3669, 51668], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 852, "seek": 512452, "start": 5150.6, "end": 5154.5, "text": " into let's say German in fact German was the main issue because you know the", "tokens": [51668, 666, 718, 311, 584, 6521, 294, 1186, 6521, 390, 264, 2135, 2734, 570, 291, 458, 264, 51863], "temperature": 0.0, "avg_logprob": -0.21231364312573014, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.009378939867019653}, {"id": 853, "seek": 515450, "start": 5154.5, "end": 5159.78, "text": " verb is at the end so it screws up all the translation system so so that was", "tokens": [50364, 9595, 307, 412, 264, 917, 370, 309, 13050, 493, 439, 264, 12853, 1185, 370, 370, 300, 390, 50628], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 854, "seek": 515450, "start": 5159.78, "end": 5165.18, "text": " actually the solution to that problem and and they came up with this idea of", "tokens": [50628, 767, 264, 3827, 281, 300, 1154, 293, 293, 436, 1361, 493, 365, 341, 1558, 295, 50898], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 855, "seek": 515450, "start": 5165.18, "end": 5171.26, "text": " this kind of learn attention mechanism and then there was a paper that that by", "tokens": [50898, 341, 733, 295, 1466, 3202, 7513, 293, 550, 456, 390, 257, 3035, 300, 300, 538, 51202], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 856, "seek": 515450, "start": 5171.26, "end": 5175.06, "text": " Chris Manning at Stanford that sort of picked up this architecture and made it", "tokens": [51202, 6688, 2458, 773, 412, 20374, 300, 1333, 295, 6183, 493, 341, 9482, 293, 1027, 309, 51392], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 857, "seek": 515450, "start": 5175.06, "end": 5180.46, "text": " work at scale so they won the WNT competition a few months later and then", "tokens": [51392, 589, 412, 4373, 370, 436, 1582, 264, 343, 30817, 6211, 257, 1326, 2493, 1780, 293, 550, 51662], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 858, "seek": 515450, "start": 5180.46, "end": 5183.78, "text": " the entire industry jumped on it right and then you know as much people at", "tokens": [51662, 264, 2302, 3518, 13864, 322, 309, 558, 293, 550, 291, 458, 382, 709, 561, 412, 51828], "temperature": 0.0, "avg_logprob": -0.1679288382842162, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.003800388425588608}, {"id": 859, "seek": 518378, "start": 5183.78, "end": 5186.98, "text": " Google said oh you can build an entire neural net based on just this idea and", "tokens": [50364, 3329, 848, 1954, 291, 393, 1322, 364, 2302, 18161, 2533, 2361, 322, 445, 341, 1558, 293, 50524], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 860, "seek": 518378, "start": 5186.98, "end": 5190.46, "text": " the title of the paper was attention is all you need and that was the", "tokens": [50524, 264, 4876, 295, 264, 3035, 390, 3202, 307, 439, 291, 643, 293, 300, 390, 264, 50698], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 861, "seek": 518378, "start": 5190.46, "end": 5196.259999999999, "text": " transformer and you know so the root of some of those good ideas are very often", "tokens": [50698, 31782, 293, 291, 458, 370, 264, 5593, 295, 512, 295, 729, 665, 3487, 366, 588, 2049, 50988], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 862, "seek": 518378, "start": 5196.259999999999, "end": 5199.5, "text": " in academia then the problems that I talked about you know how you do", "tokens": [50988, 294, 28937, 550, 264, 2740, 300, 286, 2825, 466, 291, 458, 577, 291, 360, 51150], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 863, "seek": 518378, "start": 5199.5, "end": 5202.42, "text": " hierarchical planning how you're done world models from video that kind of", "tokens": [51150, 35250, 804, 5038, 577, 291, 434, 1096, 1002, 5245, 490, 960, 300, 733, 295, 51296], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 864, "seek": 518378, "start": 5202.42, "end": 5205.98, "text": " stuff these are things you don't need enormous amounts of computation to", "tokens": [51296, 1507, 613, 366, 721, 291, 500, 380, 643, 11322, 11663, 295, 24903, 281, 51474], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 865, "seek": 518378, "start": 5205.98, "end": 5210.94, "text": " demonstrate the principle you may not be able to you know beat some benchmark", "tokens": [51474, 11698, 264, 8665, 291, 815, 406, 312, 1075, 281, 291, 458, 4224, 512, 18927, 51722], "temperature": 0.0, "avg_logprob": -0.12569577006970423, "compression_ratio": 1.7972508591065293, "no_speech_prob": 0.004589503165334463}, {"id": 866, "seek": 521094, "start": 5210.94, "end": 5215.259999999999, "text": " results or whatever but it doesn't matter if you show that a principle can", "tokens": [50364, 3542, 420, 2035, 457, 309, 1177, 380, 1871, 498, 291, 855, 300, 257, 8665, 393, 50580], "temperature": 0.0, "avg_logprob": -0.16440718968709309, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0020083682611584663}, {"id": 867, "seek": 521094, "start": 5215.259999999999, "end": 5219.0599999999995, "text": " work and it's convincing enough then there'll be other people who pick it up", "tokens": [50580, 589, 293, 309, 311, 24823, 1547, 550, 456, 603, 312, 661, 561, 567, 1888, 309, 493, 50770], "temperature": 0.0, "avg_logprob": -0.16440718968709309, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0020083682611584663}, {"id": 868, "seek": 521094, "start": 5219.0599999999995, "end": 5222.379999999999, "text": " and actually build something real out of it it's okay that's the way you have", "tokens": [50770, 293, 767, 1322, 746, 957, 484, 295, 309, 309, 311, 1392, 300, 311, 264, 636, 291, 362, 50936], "temperature": 0.0, "avg_logprob": -0.16440718968709309, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0020083682611584663}, {"id": 869, "seek": 521094, "start": 5222.379999999999, "end": 5233.74, "text": " intellectual impact so if you think about your career and what drove you would", "tokens": [50936, 12576, 2712, 370, 498, 291, 519, 466, 428, 3988, 293, 437, 13226, 291, 576, 51504], "temperature": 0.0, "avg_logprob": -0.16440718968709309, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0020083682611584663}, {"id": 870, "seek": 521094, "start": 5233.74, "end": 5238.259999999999, "text": " you say that more the dreams you had about what could be possible or you're", "tokens": [51504, 291, 584, 300, 544, 264, 7505, 291, 632, 466, 437, 727, 312, 1944, 420, 291, 434, 51730], "temperature": 0.0, "avg_logprob": -0.16440718968709309, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0020083682611584663}, {"id": 871, "seek": 523826, "start": 5238.3, "end": 5245.18, "text": " so interested in the topic let yeah just all the work you contributed to and how", "tokens": [50366, 370, 3102, 294, 264, 4829, 718, 1338, 445, 439, 264, 589, 291, 18434, 281, 293, 577, 50710], "temperature": 0.0, "avg_logprob": -0.1727260434350302, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.006668413057923317}, {"id": 872, "seek": 523826, "start": 5245.18, "end": 5251.5, "text": " that maybe change also over time yeah so interesting question I think at the", "tokens": [50710, 300, 1310, 1319, 611, 670, 565, 1338, 370, 1880, 1168, 286, 519, 412, 264, 51026], "temperature": 0.0, "avg_logprob": -0.1727260434350302, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.006668413057923317}, {"id": 873, "seek": 523826, "start": 5251.5, "end": 5256.820000000001, "text": " root of it is really a scientific question what is intelligence how does", "tokens": [51026, 5593, 295, 309, 307, 534, 257, 8134, 1168, 437, 307, 7599, 577, 775, 51292], "temperature": 0.0, "avg_logprob": -0.1727260434350302, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.006668413057923317}, {"id": 874, "seek": 523826, "start": 5256.820000000001, "end": 5262.5, "text": " the brain work you know it's a very sort of front and center big big scientific", "tokens": [51292, 264, 3567, 589, 291, 458, 309, 311, 257, 588, 1333, 295, 1868, 293, 3056, 955, 955, 8134, 51576], "temperature": 0.0, "avg_logprob": -0.1727260434350302, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.006668413057923317}, {"id": 875, "seek": 523826, "start": 5262.5, "end": 5267.54, "text": " question over time so right there's three big scientific questions is what you", "tokens": [51576, 1168, 670, 565, 370, 558, 456, 311, 1045, 955, 8134, 1651, 307, 437, 291, 51828], "temperature": 0.0, "avg_logprob": -0.1727260434350302, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.006668413057923317}, {"id": 876, "seek": 526754, "start": 5267.54, "end": 5270.9, "text": " know what's the universe made of what's life all about and how does the brain", "tokens": [50364, 458, 437, 311, 264, 6445, 1027, 295, 437, 311, 993, 439, 466, 293, 577, 775, 264, 3567, 50532], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 877, "seek": 526754, "start": 5270.9, "end": 5278.1, "text": " work right three questions but then I'm kind of an engineer as well so for a", "tokens": [50532, 589, 558, 1045, 1651, 457, 550, 286, 478, 733, 295, 364, 11403, 382, 731, 370, 337, 257, 50892], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 878, "seek": 526754, "start": 5278.1, "end": 5281.62, "text": " complex system like the brain the only way to really understand how it works is", "tokens": [50892, 3997, 1185, 411, 264, 3567, 264, 787, 636, 281, 534, 1223, 577, 309, 1985, 307, 51068], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 879, "seek": 526754, "start": 5281.62, "end": 5285.74, "text": " that you build one yourself and you verify that like all the hypothesis that", "tokens": [51068, 300, 291, 1322, 472, 1803, 293, 291, 16888, 300, 411, 439, 264, 17291, 300, 51274], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 880, "seek": 526754, "start": 5285.74, "end": 5289.66, "text": " you built into your system actually kind of correspond to what happened and it's", "tokens": [51274, 291, 3094, 666, 428, 1185, 767, 733, 295, 6805, 281, 437, 2011, 293, 309, 311, 51470], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 881, "seek": 526754, "start": 5289.66, "end": 5294.74, "text": " really the inspiration behind convolutional nets and multilayer learning", "tokens": [51470, 534, 264, 10249, 2261, 45216, 304, 36170, 293, 2120, 388, 11167, 2539, 51724], "temperature": 0.0, "avg_logprob": -0.14422555153186506, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.004160214215517044}, {"id": 882, "seek": 529474, "start": 5294.98, "end": 5299.54, "text": " and the whole idea of neural nets in the first place right getting inspiration", "tokens": [50376, 293, 264, 1379, 1558, 295, 18161, 36170, 294, 264, 700, 1081, 558, 1242, 10249, 50604], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 883, "seek": 529474, "start": 5299.54, "end": 5302.94, "text": " from the brain but not copying it because you copied blindly you're not", "tokens": [50604, 490, 264, 3567, 457, 406, 27976, 309, 570, 291, 25365, 47744, 291, 434, 406, 50774], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 884, "seek": 529474, "start": 5302.94, "end": 5306.54, "text": " gonna get anywhere you need to understand the underlying principles so", "tokens": [50774, 799, 483, 4992, 291, 643, 281, 1223, 264, 14217, 9156, 370, 50954], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 885, "seek": 529474, "start": 5306.54, "end": 5309.94, "text": " underlying the understanding the underlying principles of intelligence is", "tokens": [50954, 14217, 264, 3701, 264, 14217, 9156, 295, 7599, 307, 51124], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 886, "seek": 529474, "start": 5309.94, "end": 5314.0599999999995, "text": " really what kind of drives me and then it's great if you have like multiple", "tokens": [51124, 534, 437, 733, 295, 11754, 385, 293, 550, 309, 311, 869, 498, 291, 362, 411, 3866, 51330], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 887, "seek": 529474, "start": 5314.0599999999995, "end": 5319.42, "text": " applications whether they are useful or entertaining I mostly don't do this", "tokens": [51330, 5821, 1968, 436, 366, 4420, 420, 20402, 286, 5240, 500, 380, 360, 341, 51598], "temperature": 0.0, "avg_logprob": -0.16902192084343878, "compression_ratio": 1.788, "no_speech_prob": 0.005672556813806295}, {"id": 888, "seek": 531942, "start": 5319.42, "end": 5324.66, "text": " myself but but I'm really happy with people do it", "tokens": [50364, 2059, 457, 457, 286, 478, 534, 2055, 365, 561, 360, 309, 50626], "temperature": 0.0, "avg_logprob": -0.3435341417789459, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.007569408509880304}, {"id": 889, "seek": 531942, "start": 5327.34, "end": 5334.02, "text": " hello LeCun I want to ask you a question what's your opinion on the field of", "tokens": [50760, 7751, 1456, 34, 409, 286, 528, 281, 1029, 291, 257, 1168, 437, 311, 428, 4800, 322, 264, 2519, 295, 51094], "temperature": 0.0, "avg_logprob": -0.3435341417789459, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.007569408509880304}, {"id": 890, "seek": 531942, "start": 5334.02, "end": 5338.78, "text": " embodied AI and robot learning I think it's very interesting because it's", "tokens": [51094, 42046, 7318, 293, 7881, 2539, 286, 519, 309, 311, 588, 1880, 570, 309, 311, 51332], "temperature": 0.0, "avg_logprob": -0.3435341417789459, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.007569408509880304}, {"id": 891, "seek": 531942, "start": 5338.78, "end": 5344.1, "text": " deployed artificial intelligence techniques to change the real world yes", "tokens": [51332, 17826, 11677, 7599, 7512, 281, 1319, 264, 957, 1002, 2086, 51598], "temperature": 0.0, "avg_logprob": -0.3435341417789459, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.007569408509880304}, {"id": 892, "seek": 534410, "start": 5344.38, "end": 5352.860000000001, "text": " I completely agree so in fact in fact that's kind of one of the point that I", "tokens": [50378, 286, 2584, 3986, 370, 294, 1186, 294, 1186, 300, 311, 733, 295, 472, 295, 264, 935, 300, 286, 50802], "temperature": 0.0, "avg_logprob": -0.18904792869484033, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.005477859638631344}, {"id": 893, "seek": 534410, "start": 5352.860000000001, "end": 5358.620000000001, "text": " perhaps didn't make clear enough that this idea of world model as I said is", "tokens": [50802, 4317, 994, 380, 652, 1850, 1547, 300, 341, 1558, 295, 1002, 2316, 382, 286, 848, 307, 51090], "temperature": 0.0, "avg_logprob": -0.18904792869484033, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.005477859638631344}, {"id": 894, "seek": 534410, "start": 5358.620000000001, "end": 5362.1, "text": " easy to do in the context of language which is why we have language models", "tokens": [51090, 1858, 281, 360, 294, 264, 4319, 295, 2856, 597, 307, 983, 321, 362, 2856, 5245, 51264], "temperature": 0.0, "avg_logprob": -0.18904792869484033, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.005477859638631344}, {"id": 895, "seek": 534410, "start": 5362.1, "end": 5368.3, "text": " that are so impressive but it's very hard to do in the context of the real", "tokens": [51264, 300, 366, 370, 8992, 457, 309, 311, 588, 1152, 281, 360, 294, 264, 4319, 295, 264, 957, 51574], "temperature": 0.0, "avg_logprob": -0.18904792869484033, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.005477859638631344}, {"id": 896, "seek": 534410, "start": 5368.3, "end": 5372.740000000001, "text": " world data video things like that property of sensitive data from a robot", "tokens": [51574, 1002, 1412, 960, 721, 411, 300, 4707, 295, 9477, 1412, 490, 257, 7881, 51796], "temperature": 0.0, "avg_logprob": -0.18904792869484033, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.005477859638631344}, {"id": 897, "seek": 537274, "start": 5373.0199999999995, "end": 5378.7, "text": " and so the good news about the good thing the good aspect of embodied AI of", "tokens": [50378, 293, 370, 264, 665, 2583, 466, 264, 665, 551, 264, 665, 4171, 295, 42046, 7318, 295, 50662], "temperature": 0.0, "avg_logprob": -0.18173020026263068, "compression_ratio": 1.6611111111111112, "no_speech_prob": 0.0019120899960398674}, {"id": 898, "seek": 537274, "start": 5378.7, "end": 5382.42, "text": " like working with with robots whether they are real or simulated is that you", "tokens": [50662, 411, 1364, 365, 365, 14733, 1968, 436, 366, 957, 420, 41713, 307, 300, 291, 50848], "temperature": 0.0, "avg_logprob": -0.18173020026263068, "compression_ratio": 1.6611111111111112, "no_speech_prob": 0.0019120899960398674}, {"id": 899, "seek": 537274, "start": 5382.42, "end": 5388.78, "text": " can't cheat you can't take shortcuts like representing everything as a word or", "tokens": [50848, 393, 380, 17470, 291, 393, 380, 747, 34620, 411, 13460, 1203, 382, 257, 1349, 420, 51166], "temperature": 0.0, "avg_logprob": -0.18173020026263068, "compression_ratio": 1.6611111111111112, "no_speech_prob": 0.0019120899960398674}, {"id": 900, "seek": 537274, "start": 5388.78, "end": 5395.66, "text": " something although some people are trying to do that but so I think", "tokens": [51166, 746, 4878, 512, 561, 366, 1382, 281, 360, 300, 457, 370, 286, 519, 51510], "temperature": 0.0, "avg_logprob": -0.18173020026263068, "compression_ratio": 1.6611111111111112, "no_speech_prob": 0.0019120899960398674}, {"id": 901, "seek": 539566, "start": 5396.0199999999995, "end": 5403.82, "text": " focusing on this kind of type of problem I think makes people honest so I", "tokens": [50382, 8416, 322, 341, 733, 295, 2010, 295, 1154, 286, 519, 1669, 561, 3245, 370, 286, 50772], "temperature": 0.0, "avg_logprob": -0.14539279108462128, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004778715781867504}, {"id": 902, "seek": 539566, "start": 5403.82, "end": 5409.099999999999, "text": " think the most interesting advances in in AI over the last several years are", "tokens": [50772, 519, 264, 881, 1880, 25297, 294, 294, 7318, 670, 264, 1036, 2940, 924, 366, 51036], "temperature": 0.0, "avg_logprob": -0.14539279108462128, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004778715781867504}, {"id": 903, "seek": 539566, "start": 5409.099999999999, "end": 5413.98, "text": " not in LLMs they are in people who do robotics and try to do control and sort", "tokens": [51036, 406, 294, 441, 43, 26386, 436, 366, 294, 561, 567, 360, 34145, 293, 853, 281, 360, 1969, 293, 1333, 51280], "temperature": 0.0, "avg_logprob": -0.14539279108462128, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004778715781867504}, {"id": 904, "seek": 539566, "start": 5413.98, "end": 5419.86, "text": " of make robots basically learn efficiently without having to be trained", "tokens": [51280, 295, 652, 14733, 1936, 1466, 19621, 1553, 1419, 281, 312, 8895, 51574], "temperature": 0.0, "avg_logprob": -0.14539279108462128, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004778715781867504}, {"id": 905, "seek": 541986, "start": 5419.86, "end": 5425.74, "text": " by you know for hours in simulation this teams there's a colleague at NYU", "tokens": [50364, 538, 291, 458, 337, 2496, 294, 16575, 341, 5491, 456, 311, 257, 13532, 412, 42682, 50658], "temperature": 0.0, "avg_logprob": -0.3589784765756258, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.03163328021764755}, {"id": 906, "seek": 541986, "start": 5425.74, "end": 5430.66, "text": " Lera Alpinto who's working on this there is I mean I've grouped a colleague", "tokens": [50658, 441, 1663, 967, 79, 17246, 567, 311, 1364, 322, 341, 456, 307, 286, 914, 286, 600, 41877, 257, 13532, 50904], "temperature": 0.0, "avg_logprob": -0.3589784765756258, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.03163328021764755}, {"id": 907, "seek": 541986, "start": 5430.66, "end": 5435.139999999999, "text": " Emelon and his colleagues and then probably the biggest group working on", "tokens": [50904, 3968, 338, 266, 293, 702, 7734, 293, 550, 1391, 264, 3880, 1594, 1364, 322, 51128], "temperature": 0.0, "avg_logprob": -0.3589784765756258, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.03163328021764755}, {"id": 908, "seek": 541986, "start": 5435.139999999999, "end": 5440.099999999999, "text": " this is at Berkeley Peter Abiel, Segelle Yvine and Chelsea Finn who is a former", "tokens": [51128, 341, 307, 412, 23684, 6508, 2847, 1187, 11, 1100, 432, 2447, 398, 85, 533, 293, 26527, 21066, 567, 307, 257, 5819, 51376], "temperature": 0.0, "avg_logprob": -0.3589784765756258, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.03163328021764755}, {"id": 909, "seek": 541986, "start": 5440.099999999999, "end": 5443.98, "text": " student of theirs at Stanford those are really kind of interesting approaches", "tokens": [51376, 3107, 295, 22760, 412, 20374, 729, 366, 534, 733, 295, 1880, 11587, 51570], "temperature": 0.0, "avg_logprob": -0.3589784765756258, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.03163328021764755}, {"id": 910, "seek": 544398, "start": 5443.98, "end": 5451.179999999999, "text": " there this whole idea of planning objective-driven kind of planning you", "tokens": [50364, 456, 341, 1379, 1558, 295, 5038, 10024, 12, 25456, 733, 295, 5038, 291, 50724], "temperature": 0.0, "avg_logprob": -0.21577054400776707, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.008669978938996792}, {"id": 911, "seek": 544398, "start": 5451.179999999999, "end": 5455.82, "text": " have to do that in the context of robots so in that sense is very interesting", "tokens": [50724, 362, 281, 360, 300, 294, 264, 4319, 295, 14733, 370, 294, 300, 2020, 307, 588, 1880, 50956], "temperature": 0.0, "avg_logprob": -0.21577054400776707, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.008669978938996792}, {"id": 912, "seek": 544398, "start": 5455.82, "end": 5459.82, "text": " there's a whole division at fair that actually is called embodied AI for that", "tokens": [50956, 456, 311, 257, 1379, 10044, 412, 3143, 300, 767, 307, 1219, 42046, 7318, 337, 300, 51156], "temperature": 0.0, "avg_logprob": -0.21577054400776707, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.008669978938996792}, {"id": 913, "seek": 544398, "start": 5459.82, "end": 5468.74, "text": " reason thank you yeah thank you so much Jan I mean this amazing lecture and I", "tokens": [51156, 1778, 1309, 291, 1338, 1309, 291, 370, 709, 4956, 286, 914, 341, 2243, 7991, 293, 286, 51602], "temperature": 0.0, "avg_logprob": -0.21577054400776707, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.008669978938996792}, {"id": 914, "seek": 544398, "start": 5468.74, "end": 5472.0599999999995, "text": " think you're all very grateful that you shared your thoughts and perspectives on", "tokens": [51602, 519, 291, 434, 439, 588, 7941, 300, 291, 5507, 428, 4598, 293, 16766, 322, 51768], "temperature": 0.0, "avg_logprob": -0.21577054400776707, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.008669978938996792}, {"id": 915, "seek": 547206, "start": 5472.06, "end": 5476.38, "text": " future AI with us and I think we all got a lot of impulses from this today so we", "tokens": [50364, 2027, 7318, 365, 505, 293, 286, 519, 321, 439, 658, 257, 688, 295, 41767, 6196, 490, 341, 965, 370, 321, 50580], "temperature": 0.0, "avg_logprob": -0.19952697464914032, "compression_ratio": 1.2258064516129032, "no_speech_prob": 0.040693894028663635}, {"id": 916, "seek": 547206, "start": 5476.38, "end": 5479.780000000001, "text": " have a small gift for you as well", "tokens": [50580, 362, 257, 1359, 5306, 337, 291, 382, 731, 50750], "temperature": 0.0, "avg_logprob": -0.19952697464914032, "compression_ratio": 1.2258064516129032, "no_speech_prob": 0.040693894028663635}, {"id": 917, "seek": 550206, "start": 5503.06, "end": 5507.06, "text": " thank you", "tokens": [50414, 1309, 291, 50614], "temperature": 0.0, "avg_logprob": -0.38740077488858937, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.007070092484354973}, {"id": 918, "seek": 550206, "start": 5510.06, "end": 5515.580000000001, "text": " yeah so let me also again I mean thank all cooperation partners who contributed", "tokens": [50764, 1338, 370, 718, 385, 611, 797, 286, 914, 1309, 439, 14968, 4462, 567, 18434, 51040], "temperature": 0.0, "avg_logprob": -0.38740077488858937, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.007070092484354973}, {"id": 919, "seek": 550206, "start": 5515.580000000001, "end": 5521.38, "text": " to this event so the Center for Advanced Studies biosphere the Varian Academy of", "tokens": [51040, 281, 341, 2280, 370, 264, 5169, 337, 26951, 17515, 36997, 6605, 264, 691, 10652, 11735, 295, 51330], "temperature": 0.0, "avg_logprob": -0.38740077488858937, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.007070092484354973}, {"id": 920, "seek": 550206, "start": 5521.38, "end": 5526.26, "text": " Sciences Humanities Munich Center for Machine Learning the Varian Research", "tokens": [51330, 21108, 10294, 1088, 40601, 5169, 337, 22155, 15205, 264, 691, 10652, 10303, 51574], "temperature": 0.0, "avg_logprob": -0.38740077488858937, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.007070092484354973}, {"id": 921, "seek": 550206, "start": 5526.26, "end": 5530.780000000001, "text": " Institute for Digital Transformation and the Konrad Susi School of Excellence in", "tokens": [51574, 9446, 337, 15522, 6531, 8663, 293, 264, 12718, 6206, 9545, 72, 5070, 295, 44684, 294, 51800], "temperature": 0.0, "avg_logprob": -0.38740077488858937, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.007070092484354973}, {"id": 922, "seek": 553078, "start": 5530.78, "end": 5536.099999999999, "text": " Reliable AI and sorry I would like to have a special thanks to Dr. Ursula", "tokens": [50364, 8738, 9364, 7318, 293, 2597, 286, 576, 411, 281, 362, 257, 2121, 3231, 281, 2491, 13, 41303, 3780, 50630], "temperature": 0.0, "avg_logprob": -0.20650576182774136, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.004232487641274929}, {"id": 923, "seek": 553078, "start": 5536.099999999999, "end": 5540.42, "text": " Olinger who is science manager at my chair and who headed actually the", "tokens": [50630, 422, 1688, 260, 567, 307, 3497, 6598, 412, 452, 6090, 293, 567, 12798, 767, 264, 50846], "temperature": 0.0, "avg_logprob": -0.20650576182774136, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.004232487641274929}, {"id": 924, "seek": 553078, "start": 5540.42, "end": 5546.82, "text": " organization of the entire event so I think she deserves a small applause", "tokens": [50846, 4475, 295, 264, 2302, 2280, 370, 286, 519, 750, 17037, 257, 1359, 9969, 51166], "temperature": 0.0, "avg_logprob": -0.20650576182774136, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.004232487641274929}, {"id": 925, "seek": 553078, "start": 5554.54, "end": 5558.98, "text": " yeah thanks also everyone for coming here and also for those who joined us", "tokens": [51552, 1338, 3231, 611, 1518, 337, 1348, 510, 293, 611, 337, 729, 567, 6869, 505, 51774], "temperature": 0.0, "avg_logprob": -0.20650576182774136, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.004232487641274929}, {"id": 926, "seek": 555898, "start": 5558.98, "end": 5563.86, "text": " via live stream we now have we I would now like to invite you to a little", "tokens": [50364, 5766, 1621, 4309, 321, 586, 362, 321, 286, 576, 586, 411, 281, 7980, 291, 281, 257, 707, 50608], "temperature": 0.0, "avg_logprob": -0.30526965597401495, "compression_ratio": 1.36, "no_speech_prob": 0.0064356084913015366}, {"id": 927, "seek": 555898, "start": 5563.86, "end": 5569.58, "text": " reception in this Sitzung Sal 1 and 2 which is here right around the corner", "tokens": [50608, 21682, 294, 341, 318, 6862, 1063, 5996, 502, 293, 568, 597, 307, 510, 558, 926, 264, 4538, 50894], "temperature": 0.0, "avg_logprob": -0.30526965597401495, "compression_ratio": 1.36, "no_speech_prob": 0.0064356084913015366}, {"id": 928, "seek": 555898, "start": 5569.58, "end": 5573.58, "text": " so thank you so much", "tokens": [50894, 370, 1309, 291, 370, 709, 51094], "temperature": 0.0, "avg_logprob": -0.30526965597401495, "compression_ratio": 1.36, "no_speech_prob": 0.0064356084913015366}, {"id": 929, "seek": 558898, "start": 5588.98, "end": 5591.04, "text": " you", "tokens": [50364, 291, 50467], "temperature": 0.0, "avg_logprob": -0.7250720858573914, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.5954941511154175}], "language": "en"}