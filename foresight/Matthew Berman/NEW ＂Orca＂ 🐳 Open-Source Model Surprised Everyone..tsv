start	end	text
0	3440	There's a battle being waged right now
3440	5440	in the world of artificial intelligence
5440	7960	between large foundational models
7960	10160	and smaller open source models.
10160	13400	And just this week, a new research paper was dropped
13400	16680	that promises to append the conversation completely.
16680	18200	Now, if you remember a few weeks ago,
18200	21160	I made a video about the letter called We Have No Mote,
21160	23880	which was a leaked internal memo from Google
23880	26640	that really highlighted how open source models,
26640	30280	smaller ones specifically, are iterating so quickly
30280	32000	that these large foundational models
32000	36000	that Google and OpenAI have are truly at risk.
36000	38720	And I found that to be a very compelling paper.
38720	40760	And then just two weeks ago,
40760	42800	another research paper was released
42800	45200	that claimed to disprove a lot of the value
45200	47520	that these open source smaller models have.
47520	49920	Today, we're gonna take a look at all of this
49920	51680	and we're gonna figure out what's the truth.
51680	53520	We're gonna take a look at the new Orca paper
53520	55000	that was just dropped this week.
55040	57880	We're gonna look at the We Have No Mote document again
57880	59480	and we're gonna take a look at the research paper
59480	60600	that came out a couple of weeks ago
60600	62040	talking about the false promise
62040	65880	of imitating proprietary large language models like GPT-4.
65880	66720	Let's go.
66720	68800	So this is Orca, progressive learning
68800	72040	from complex explanation traces of GPT-4.
72040	73240	This is a new research paper
73240	76080	dropped by Microsoft Research of all companies.
76080	79160	Of course, they made a substantial investment in OpenAI
79160	82160	and own a significant portion of that company.
82160	84360	So for them to release a new research paper
84400	85680	illustrating a new technique
85680	87760	to make open source smaller models
87760	90600	extremely powerful is really fascinating.
90600	93680	Microsoft as a company has embraced open source
93680	96320	in the years since Satya Nadella took over
96320	97480	and I'm all for it.
97480	100240	This paper is absolutely fascinating
100240	102080	and it makes a ton of sense.
102080	104080	But before we get into this paper,
104080	105960	let's take a look at those previous documents
105960	106800	that I mentioned.
106800	108280	Now a little over a month ago,
108280	110760	this internal memo from Google was released
110760	111920	called We Have No Mote.
111920	113120	And the main point of this memo
113120	115320	is that open source models are proliferating
115320	119280	and iterating so quickly that the gap between models
119280	124080	like GPT-4 and Palm 2 are shrinking very quickly.
124080	126480	The fact that any developer can get their hands
126480	129040	on these models and new techniques to train
129040	131080	and fine tune these models are coming out every day.
131080	133880	And we're seeing that from Laura to Q Laura
133880	136080	to now having a ton of different options
136080	138560	of how to train and fine tune these models
138560	139800	in really efficient ways
139800	142320	and run them on any consumer grade hardware.
142320	144640	And I agreed with a lot that was in this paper.
144640	146200	Of course, a business mode
146200	148600	is not just the technical limitations.
148600	150160	There's much more to it than that.
150160	152760	But a lot of the points made in this paper are very valid.
152760	155280	And I've seen more innovation in the open source community
155280	156320	over these last few weeks
156320	158920	than I've seen on these proprietary large models.
158920	161040	But then a research paper out of UC Berkeley
161040	162400	was dropped a couple of weeks ago
162400	164080	that really challenged the assertions
164080	165960	of the We Have No Mote leak document.
165960	167360	In this research paper,
167360	170680	the false promise of imitating proprietary LLMs,
170680	172400	they spell out that these open source models
172400	176440	are simply just imitating the outputs of these larger models
176440	178760	without actually understanding the logic
178760	180560	to reach certain outputs.
180560	181960	The gist of this paper
181960	184080	and what Orca looks to correct
184080	186200	is that these open source models
186200	189320	are simply being trained on prompts and responses
189320	191440	which is good for pattern matching.
191440	193880	So for example, if you're a student in college
193880	195200	and you're taking a class,
195200	198040	you could probably do pretty well on a lot of tests
198040	200920	simply by pattern matching the question to an answer.
200920	203480	But that student is gonna have a lot of limitations.
203480	205040	If one of the questions varies
205040	206920	from their pattern matching ability,
206920	208520	by even just a little bit,
208520	210680	their ability to reason and figure out
210680	213320	what the answer might be becomes highly limited.
213320	216000	Whereas the student who fundamentally
216000	217960	and deeply understands a topic
217960	221200	won't be thrown off by any variation of the question.
221200	225120	They'll be able to reason and step by step get to the answer
225120	227320	because they do truly understand the topic.
227320	228760	And that's really the difference
228760	231360	between these large foundational models
231360	234160	and the open source imitations of them
234160	235360	as per this paper.
235360	237120	And that brings us to Orca.
237120	239800	Orca challenges the idea that open source models
239800	242280	can only really imitate answers
242280	244520	and will get thrown off by any variation
244520	246040	in the prompts themselves.
246040	248960	And the way they do it seems very obvious in hindsight.
248960	250800	Before we get into the details,
250800	255040	Orca outperforms every other open source model
255040	259280	and even outperforms ChatGPT, which is GPT 3.5,
259280	261200	in a lot of different benchmarks.
261200	264360	Now, of course, it still lags behind GPT4,
264360	266480	but the gap continues to close.
266480	268080	So let's take a look at this paper now.
268080	269520	They start off the abstract
269520	272340	by addressing this imitation concept.
272340	275320	Recent research has focused on enhancing the capability
275320	277520	of smaller models through imitation learning,
277520	279280	drawing on the outputs generated
279280	280920	by large foundational models.
280920	285000	Again, LFMs are referring to ChatGPT and GPT4.
285000	286880	And they start to outline the limitations
286880	288680	of these imitation techniques.
288680	291640	Some that they point out are limited imitation signals
291640	293880	from shallow LFM outputs,
293880	296280	small scale homogenous training data,
296280	300360	and most notably a lack of rigorous evaluation
300360	303280	resulting in overestimating the small models capability
303280	305800	as they tend to learn to imitate the style
305800	308760	but not the reasoning process of LFMs.
308760	311640	That is really the crux of this paper.
311640	314520	How do we start getting these open source models
314520	317600	to not just mimic the question answer pairs,
317600	320040	but actually understand how they get
320040	322420	from a question to an answer.
322420	325560	And only with that is true intelligence created.
325560	328000	To address these challenges, we develop ORCA,
328000	329680	a 13 billion parameter model
329680	332800	that learns to imitate the reasoning process of LFMs.
332800	334560	Let's pause there for a second.
334560	339080	This model, the ORCA model is only 13 billion parameters,
339080	343120	which means it can run on pretty much any modern hardware.
343120	344520	Whereas some of the other models
344520	345840	that I've been reviewing recently,
345840	347080	like the Guinaco model,
347080	349600	require me to rent out a cloud GPU,
349600	353080	like an A6000 that has 48 gigabytes of VRAM,
353080	355820	because it's so large, 65 billion parameters.
355820	357560	And this performs better than that.
357560	359060	Now here's the key to the paper.
359060	360360	Here's the key technique.
360360	363720	ORCA learns from rich signals from GPT-4,
363720	365560	including explanation traces,
365560	367680	step-by-step thought processes,
367680	369640	and other complex instructions
369640	372800	guided by teacher assistance from chat GPT.
372800	374720	Now I'll explain what teacher assistance is
374720	377040	in a little bit, but looking at this sentence,
377040	378520	what it's really saying is,
378520	381120	rather than learning from the prompt and response pairs,
381120	383800	we're going to ask these large foundational models
383800	387160	to explain their reasoning step-by-step,
387160	389280	and the smaller open source models
389280	390560	will learn from that.
390560	392280	Truly fascinating.
392280	394160	Now I wanna briefly touch on this guided
394160	396840	by teacher assistance from chat GPT.
396840	400000	They have a two-tier teaching process.
400000	403680	One, they take chat GPT, which is GPT-3.5,
403680	405480	and they have a large number of examples
405480	406880	to learn from, five million.
406880	408680	Then they take those five million,
408680	412260	boil it down to the most important one million examples,
412260	415760	and then use GPT-4 to continue to train
415760	417520	on more complex examples.
417520	419160	So how does it actually perform?
419160	421480	ORCA surpasses conventional state-of-the-art
421480	424640	instruction-tuned models, such as Vecunia 13B
424640	429000	by more than 100% in complex zero-shot reasoning benchmarks
429000	433040	like Big Bench Hard and 42% on AGI Eval.
433040	436140	Big Bench Hard and AGI Eval are just sets of tests
436140	437920	that they give to these large language models
437920	439360	to test their performance.
439360	443800	ORCA reaches parity with chat GPT on the BBH benchmark
443800	445560	and shows competitive performance
445560	448120	in professional and academic examinations
448120	450400	like SAT, LSAT, GRE, and GMAT,
450400	453360	both in zero-shot setting without chain of thought
453360	455100	while trailing behind GPT-4.
455100	458080	And again, this last sentence is everything.
458080	460200	Our research indicates that learning
460200	462400	from step-by-step explanations,
462400	464160	whether these are generated by humans
464160	465560	or more advanced AI models,
465560	468440	is a promising direction to improve model capabilities
468440	469280	and skills.
469280	470720	And just like humans,
470720	473840	large language models understanding how something works
473840	475760	is much more effective
475760	479000	than just being able to pattern match questions and answers.
479000	481640	So large language models are typically tuned
481640	483660	by something called instruction tuning.
483660	486600	You have a set of prompts and you have a set of responses
486600	489600	and those pairs are passed to the open source model
489600	490680	and it learns from that.
490680	493960	This technique is called explanation tuning
493960	496160	where it's not just the prompt and the answer
496160	498920	but an explanation of the reasoning and the logic
498920	502120	for how chat GPT and GPT-4 arrived at an answer.
502120	505880	And so we can see here when evaluated by GPT-4
505880	507600	and that's called auto-evaluation,
507600	510820	ORCA 13B actually beats chat GPT.
510820	513140	It beats Bard and it certainly beats
513140	515200	the open source models based on Lama.
515200	518640	And then for zero shot problems on academic exams,
518640	521400	chat GPT definitely performs better
521400	525600	but ORCA 13B is really closing the gap in performance
525600	528840	and performs much better than Virginia 13B.
528840	531480	And for complex zero shot reasoning tasks
531480	535120	and big bench hard, ORCA achieves parity with chat GPT.
535120	536080	And here again,
536080	538760	they specifically call out that imitation paper.
538760	541800	Authors assert that model imitation is a false promise
541800	544960	since broadly matching chat GPT using purely imitation
544960	547320	would require one, a concerted effort
547320	549720	to collect enormous imitation data sets
549720	552720	and far more diverse and higher quality imitation data
552720	554140	than is currently available.
554140	556800	So one of the biggest problems is these open source models
556800	559680	can't get enough data to use the imitation technique
559680	560840	and perform at the same rate
560840	562800	as these large foundational models.
562800	564280	Contrary to this assertion,
564280	567000	we demonstrate that both conditions one and two
567000	569320	are attainable and that it is possible
569320	571560	to reduce the gap with proprietary LLMs
571560	573560	on multiple zero shot benchmarks
573560	575280	that require sophisticated reasoning.
575280	578120	And here they touch on what the existing open source models
578120	580040	are doing currently to train themselves.
580040	583200	Both Alpaca and Wizard LM employ a variant
583200	584160	of self-instructs.
584160	585440	So that's what we've been talking about.
585440	588960	Wizard LM introduces the concept of Eval Instruct
588960	591800	which gradually rewrites the initial set of instructions
591800	593400	into more complex versions
593400	595000	attempting to overcome some of the methods
595000	596240	inherent shortcomings.
596240	597920	But with Vakunya and Kuala,
597920	600160	they demonstrate remarkable performance
600160	601960	due to the more human-like conversations
601960	603120	and natural instructions
603120	605080	in the community contributed conversations
605080	606680	like those in shared GPT.
606680	608400	So basically what they're saying is
608400	610720	as more people are using these open source models
610720	611680	and sharing their data,
611680	613280	sharing their instructions,
613280	614760	their prompts and the output,
614760	616400	they'll continue to train on those pairs
616400	617560	and get better and better.
617560	619440	But there's a limitation with that as well.
619440	621920	And it's the same thing that we keep coming back to.
621920	624600	Models trained on such natural conversations
624600	626080	may capture the style
626080	629320	but not the reasoning process of the LLFM.
629320	631880	So again, they'll be able to pattern match
631880	634720	but they're not gonna truly understand the logic
634720	637560	and the reasoning behind arriving at the solutions.
637560	641680	Now the Orca Paper puts forth three key contributions.
641680	644080	Number one is explanation tuning.
644080	646840	And again, this is fine tuning models
646840	649880	based on the step-by-step explanation
649880	651240	of the reasoning and the logic
651240	652760	of how to arrive at a solution.
652760	653920	Let's read this a little bit.
653920	656400	We augment the query response pairs
656400	658760	with detailed responses from GPT-4
658760	661320	that explain the reasoning process of the teacher
661320	663000	as it generates the response.
663000	664720	And to get the step-by-step reasoning,
664720	667240	they're using some of these more modern prompting techniques
667240	668600	that we've been learning about,
668600	670720	such as explain like I'm five,
670720	673440	think step-by-step and justify your response.
673440	677520	This forces GPT-4 to put forth its reasoning
677520	679720	and its logic in the response itself
679720	681680	and that is used to train.
681680	683480	And that's what explanation tuning is.
683480	686280	Another issue is scaling the amount of tasks and instructions.
686280	688960	As you'll see in a graph that I'll show in a second,
688960	690440	a lot of these open source models
690440	692480	are using a highly limited data set,
692480	695080	but that's where Orca really excels.
695080	697600	We utilize the Flaan 2020 collection
697600	699760	and that's a data set of tasks and instructions
699760	700880	put forth by Google
700880	703760	that has tens of millions of instructions.
703760	706020	So let's quickly take a look at the data sizes
706020	707360	for these open source models.
707360	709720	All of them have in the thousands.
709720	713280	So you can see here that Alpaca has 52,000,
713280	716280	Vakunya has 70,000 and WizardLM with the most
716280	719280	has 250,000 based on the teacher of chat GPT.
719280	720680	And some of these other ones like Dolly
720680	721760	are human instructed.
721760	723280	So they're even more limited
723280	724920	because of the limitations of humans.
724920	726720	However, as you could see here,
726720	730200	Orca has five million, many times more
730200	732600	than all of the other open source models.
732600	735160	And it's based on chat GPT initially,
735160	737160	so that's the initial five million pass
737160	740280	and then GPT-4 with a second pass
740280	743120	of much more complex tasks and instructions.
743120	745420	So not only are they getting full explanations
745420	746920	of query and responses
746920	749160	and how they actually reach those responses,
749160	751040	but they're getting so many more of them
751040	752960	and they're solving the data scaling issue.
752960	754400	Last is evaluation.
754400	757720	There are a lot of issues with current evaluation techniques
757720	758920	for open source models,
758920	761320	but Orca claims to solve these in a few ways.
761320	763800	They use auto evaluation with GPT-4.
763800	767640	So basically asking GPT-4 between two potential responses,
767640	768720	which one is best.
768720	771560	They also use academic benchmarks like Big Bench Hard
771560	774560	and Truthful QA and professional and academic exams
774560	776480	like the SAT, LSAT, et cetera.
776480	778580	And last, they use safety evaluation
778580	781140	from ToxicGen, basically do these responses
781140	782700	contain toxic language.
782700	784220	So in figure four,
784220	786660	they illustrate what the previous techniques do
786660	788580	with queries and responses.
788580	790180	So here's a user instruction.
790180	792260	Use the data to calculate the median.
792260	794340	Here it says, first, we need to arrange the data
794340	795620	in ascending order.
795620	796700	Since there are five numbers,
796700	799060	the median is in the middle, which is seven.
799060	800220	And so this is very basic.
800220	802700	It's a prompt, a query, and then the response.
802700	804060	Whereas with their new method,
804060	806380	they ask GPT-4 to explain.
806380	807540	So the system instruction
807540	809420	seems to be the main tool that they use
809420	813060	to get chat GPT and GPT-4 to explain their reasoning.
813060	814580	You are an AI assistant.
814580	816060	User will give you a task.
816060	818460	Your goal is to complete the task as faithfully
818460	819980	as you can while performing the task.
819980	822420	Think step by step and justify your steps.
822420	825820	So again, use the given data to calculate the median.
825820	826780	Same prompt.
826780	828980	To calculate the median, I will follow these steps.
828980	831700	And GPT-4 actually outlines step by step
831700	833820	how it will figure out what the median is.
833820	836420	That data is then used to train the open source model.
836420	838020	I find it so fascinating
838020	840420	that we're using some of these modern prompting techniques
840420	843300	like chain of thought, like explain like on five,
843300	845700	that people have been figuring out over the last few months
845700	849260	to get better answers from chat GPT and GPT-4.
849260	851260	And we're using those to get better data
851260	853700	to train the open source models with.
853700	856880	And as I mentioned, system messages seem to be the main tool
856880	859020	to get chat GPT and GPT-4
859020	862060	to provide the step by step explanations.
862060	865060	And if you play around with the chat GPT playground
865060	867760	or even the API, you'll know that the system messages
867760	870940	are a requirement for using either of these tools.
870940	872140	So here are a few examples.
872140	873180	You will be given a task,
873180	875340	you must generate a detailed and long answer.
875340	877540	Think like you are answering to a five year old,
877540	878660	help as much as you can.
878660	880500	So it's really just coaxing chat GPT-4
880500	883380	to explain its reasoning and to be as verbose as possible.
883380	884980	So let's actually take a look at the difference
884980	886740	between these two prompting techniques.
886740	888060	So for the system message,
888060	891380	you are an AI assistant that helps people find information.
891380	892620	User will give you a question.
892620	894620	Your task is to answer as faithfully as you can
894660	896980	while answering things step by step and justify your answer.
896980	900880	So the prompt is pick which sentence is not logical.
900880	904060	Sentence A, people in the desert often look forward to flood.
904060	907140	Sentence B, people in the desert often look forward to rain.
907140	908860	Now it might seem obvious to us
908860	910580	why these sentences are different,
910580	913300	but there's really just a subtle difference between them.
913300	915020	So here a typical response might be,
915020	916740	there is no reason to look forward to a flood
916740	917980	because floods cause damage.
917980	919260	The answer is sentence A.
919260	921700	Chat GPT says, okay, let's break it down.
921700	923100	Read the sentences carefully.
923100	924140	So it's talking about what steps
924140	925580	am I going to take to answer this?
925580	927380	Identify the differences between them
927380	929500	and determine which sentence is not logical.
929500	932020	Then they say, sentence A, people in the desert
932020	933100	often look forward to the flood.
933100	935620	This sentence suggests that people in the desert
935620	937500	are eagerly anticipating a flood.
937500	940060	However, floods are typically destructive and dangerous.
940060	942940	So it seems unlikely that people would look forward to them.
942940	945260	Sentence B, they're looking forward to the rain.
945260	948500	And it says this sentence suggests that people in the desert
948500	950300	are eagerly anticipating rain
950300	951860	while the desert is a dry environment.
951860	953620	Rain can be beneficial in providing water
953620	954580	for plants and animals.
954580	957100	Then it finishes with, based on the above analysis,
957100	959580	it can be concluded that sentence A is not logical.
959580	961340	Then we look at GPT-4's answer.
961340	963500	And as you can see, I won't read all of it.
963500	966860	It's a much more detailed and verbose answer.
966860	968660	Now in this section, they talk about
968660	971340	why Chat GPT as a teaching assistant,
971340	974660	assistant to GPT-4, is such a powerful method.
974660	976740	And there's really two reasons for it.
976740	979840	One is a capacity gap because there's such a large gap
979840	982480	between the ORCA model and GPT-4.
982480	984240	Being able to take data from GPT-4
984240	986080	and passing it directly into ORCA,
986080	987760	it's gonna struggle with imitation.
987760	989520	Whereas if they progressively teach it
989520	991480	to get to the GPT-4 level
991480	994080	by the intermediate step of Chat GPT,
994080	995840	it really performs much better.
995840	998600	This can be viewed as a form of progressive learning
998600	1000240	or curriculum learning,
1000240	1002520	where the student first learns from easier examples
1002520	1003920	followed by harder ones.
1003920	1007400	Again, more and more human-like behavior.
1007440	1010080	Human doesn't go from learning the basics of addition
1010080	1011920	all the way to calculus in one step.
1011920	1014400	They learn many incrementally more difficult steps
1014400	1017880	of mathematics between addition and calculus.
1017880	1021440	Next is a simple pragmatic reason, cost and time.
1021440	1025200	Chat GPT, specifically GPT-3.5 turbo,
1025200	1029200	is much faster and much less expensive than GPT-4.
1029200	1031120	So that's why they use five million examples
1031120	1034920	with Chat GPT and one million examples for GPT-4.
1034920	1036560	So this graphic shows the performance
1036600	1038360	of these large foundational models,
1038360	1040440	Vecunia and ORCA.
1040440	1042520	And as we can clearly see from questions
1042520	1044280	from the LSAT and the SAT,
1044280	1047600	ORCA performs significantly better than Vecunia.
1047600	1049440	And if we look at the ORCA column,
1049440	1051240	compared to the Chat GPT column,
1051240	1053720	overall it performs quite similarly,
1053720	1056480	but it still does lag behind GPT-4.
1056480	1057600	And they've actually shown
1057600	1060240	that this progressive learning technique really works.
1060240	1063200	As we can see here, using only GPT-4,
1063240	1066840	they were able to achieve a score of 37.18,
1066840	1070400	whereas if they used that intermediate step of Chat GPT,
1070400	1073160	they were able to achieve 41.7.
1073160	1074720	That might seem small,
1074720	1076320	but that is a significant improvement.
1076320	1078120	And for the big bench hard results,
1078120	1081560	ORCA performs marginally better than Chat GPT on aggregate
1081560	1085440	across all tasks, significantly lags GPT-4
1085440	1089120	and outperforms Vecunia by 113%.
1089120	1092160	And here they give a graphic of the zero-shot performance
1092200	1094160	against all of these different tasks.
1094160	1097280	And you can see that ORCA performs substantially
1097280	1098440	better than Vecunia.
1098440	1101240	And even across all of them, like it said,
1101240	1103680	it performs better than Chat GPT.
1103680	1105240	So what does all this mean?
1105240	1107800	I find it fascinating for two reasons.
1107800	1110360	One, open-source models continue to get better
1110360	1112040	at a rapid clip.
1112040	1114560	New techniques for fine-tuning, training
1114560	1116880	are coming out every single day.
1116880	1119440	So I think back to that we have no mode paper
1119440	1121240	and it makes a lot of sense still.
1121240	1123520	I also find it fascinating that GPT-4
1123520	1125920	still seems to have some secret sauce
1125920	1129080	and performs much better than any other model.
1129080	1131840	So OpenAI seems to have plenty of mode.
1131840	1135080	This mode seems to be incrementally getting decreased,
1135080	1136400	but they still do have it.
1136400	1138160	The last thing that I find fascinating
1138160	1141360	is that this paper is by Microsoft Research.
1141360	1145680	Microsoft Research owns a significant portion of OpenAI.
1145680	1147640	So the fact that they're making research gains
1147640	1149620	in open-source is awesome.
1149620	1151860	And OpenAI really must feel
1151860	1153940	that they have a significant mode to work with.
1153940	1156940	And OpenAI also mentioned a week ago
1156940	1159100	that they're releasing their own open-source model.
1159100	1160940	So I think what all of this means
1160940	1162780	is that these large language models
1162780	1165440	will continue to get better and cheaper over time.
1165440	1168100	Now Orca's code and dataset are not yet released,
1168100	1170180	but as soon as it is, we're gonna review it.
1170180	1171660	I'm gonna show you how to use it
1171660	1173260	and we'll see how it performs.
1173260	1174500	If you liked this video,
1174500	1176420	please consider giving me a like and subscribe
1176420	1178020	and I'll see you in the next one.
