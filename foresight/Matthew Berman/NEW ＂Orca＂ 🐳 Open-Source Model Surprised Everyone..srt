1
00:00:00,000 --> 00:00:03,440
There's a battle being waged right now

2
00:00:03,440 --> 00:00:05,440
in the world of artificial intelligence

3
00:00:05,440 --> 00:00:07,960
between large foundational models

4
00:00:07,960 --> 00:00:10,160
and smaller open source models.

5
00:00:10,160 --> 00:00:13,400
And just this week, a new research paper was dropped

6
00:00:13,400 --> 00:00:16,680
that promises to append the conversation completely.

7
00:00:16,680 --> 00:00:18,200
Now, if you remember a few weeks ago,

8
00:00:18,200 --> 00:00:21,160
I made a video about the letter called We Have No Mote,

9
00:00:21,160 --> 00:00:23,880
which was a leaked internal memo from Google

10
00:00:23,880 --> 00:00:26,640
that really highlighted how open source models,

11
00:00:26,640 --> 00:00:30,280
smaller ones specifically, are iterating so quickly

12
00:00:30,280 --> 00:00:32,000
that these large foundational models

13
00:00:32,000 --> 00:00:36,000
that Google and OpenAI have are truly at risk.

14
00:00:36,000 --> 00:00:38,720
And I found that to be a very compelling paper.

15
00:00:38,720 --> 00:00:40,760
And then just two weeks ago,

16
00:00:40,760 --> 00:00:42,800
another research paper was released

17
00:00:42,800 --> 00:00:45,200
that claimed to disprove a lot of the value

18
00:00:45,200 --> 00:00:47,520
that these open source smaller models have.

19
00:00:47,520 --> 00:00:49,920
Today, we're gonna take a look at all of this

20
00:00:49,920 --> 00:00:51,680
and we're gonna figure out what's the truth.

21
00:00:51,680 --> 00:00:53,520
We're gonna take a look at the new Orca paper

22
00:00:53,520 --> 00:00:55,000
that was just dropped this week.

23
00:00:55,040 --> 00:00:57,880
We're gonna look at the We Have No Mote document again

24
00:00:57,880 --> 00:00:59,480
and we're gonna take a look at the research paper

25
00:00:59,480 --> 00:01:00,600
that came out a couple of weeks ago

26
00:01:00,600 --> 00:01:02,040
talking about the false promise

27
00:01:02,040 --> 00:01:05,880
of imitating proprietary large language models like GPT-4.

28
00:01:05,880 --> 00:01:06,720
Let's go.

29
00:01:06,720 --> 00:01:08,800
So this is Orca, progressive learning

30
00:01:08,800 --> 00:01:12,040
from complex explanation traces of GPT-4.

31
00:01:12,040 --> 00:01:13,240
This is a new research paper

32
00:01:13,240 --> 00:01:16,080
dropped by Microsoft Research of all companies.

33
00:01:16,080 --> 00:01:19,160
Of course, they made a substantial investment in OpenAI

34
00:01:19,160 --> 00:01:22,160
and own a significant portion of that company.

35
00:01:22,160 --> 00:01:24,360
So for them to release a new research paper

36
00:01:24,400 --> 00:01:25,680
illustrating a new technique

37
00:01:25,680 --> 00:01:27,760
to make open source smaller models

38
00:01:27,760 --> 00:01:30,600
extremely powerful is really fascinating.

39
00:01:30,600 --> 00:01:33,680
Microsoft as a company has embraced open source

40
00:01:33,680 --> 00:01:36,320
in the years since Satya Nadella took over

41
00:01:36,320 --> 00:01:37,480
and I'm all for it.

42
00:01:37,480 --> 00:01:40,240
This paper is absolutely fascinating

43
00:01:40,240 --> 00:01:42,080
and it makes a ton of sense.

44
00:01:42,080 --> 00:01:44,080
But before we get into this paper,

45
00:01:44,080 --> 00:01:45,960
let's take a look at those previous documents

46
00:01:45,960 --> 00:01:46,800
that I mentioned.

47
00:01:46,800 --> 00:01:48,280
Now a little over a month ago,

48
00:01:48,280 --> 00:01:50,760
this internal memo from Google was released

49
00:01:50,760 --> 00:01:51,920
called We Have No Mote.

50
00:01:51,920 --> 00:01:53,120
And the main point of this memo

51
00:01:53,120 --> 00:01:55,320
is that open source models are proliferating

52
00:01:55,320 --> 00:01:59,280
and iterating so quickly that the gap between models

53
00:01:59,280 --> 00:02:04,080
like GPT-4 and Palm 2 are shrinking very quickly.

54
00:02:04,080 --> 00:02:06,480
The fact that any developer can get their hands

55
00:02:06,480 --> 00:02:09,040
on these models and new techniques to train

56
00:02:09,040 --> 00:02:11,080
and fine tune these models are coming out every day.

57
00:02:11,080 --> 00:02:13,880
And we're seeing that from Laura to Q Laura

58
00:02:13,880 --> 00:02:16,080
to now having a ton of different options

59
00:02:16,080 --> 00:02:18,560
of how to train and fine tune these models

60
00:02:18,560 --> 00:02:19,800
in really efficient ways

61
00:02:19,800 --> 00:02:22,320
and run them on any consumer grade hardware.

62
00:02:22,320 --> 00:02:24,640
And I agreed with a lot that was in this paper.

63
00:02:24,640 --> 00:02:26,200
Of course, a business mode

64
00:02:26,200 --> 00:02:28,600
is not just the technical limitations.

65
00:02:28,600 --> 00:02:30,160
There's much more to it than that.

66
00:02:30,160 --> 00:02:32,760
But a lot of the points made in this paper are very valid.

67
00:02:32,760 --> 00:02:35,280
And I've seen more innovation in the open source community

68
00:02:35,280 --> 00:02:36,320
over these last few weeks

69
00:02:36,320 --> 00:02:38,920
than I've seen on these proprietary large models.

70
00:02:38,920 --> 00:02:41,040
But then a research paper out of UC Berkeley

71
00:02:41,040 --> 00:02:42,400
was dropped a couple of weeks ago

72
00:02:42,400 --> 00:02:44,080
that really challenged the assertions

73
00:02:44,080 --> 00:02:45,960
of the We Have No Mote leak document.

74
00:02:45,960 --> 00:02:47,360
In this research paper,

75
00:02:47,360 --> 00:02:50,680
the false promise of imitating proprietary LLMs,

76
00:02:50,680 --> 00:02:52,400
they spell out that these open source models

77
00:02:52,400 --> 00:02:56,440
are simply just imitating the outputs of these larger models

78
00:02:56,440 --> 00:02:58,760
without actually understanding the logic

79
00:02:58,760 --> 00:03:00,560
to reach certain outputs.

80
00:03:00,560 --> 00:03:01,960
The gist of this paper

81
00:03:01,960 --> 00:03:04,080
and what Orca looks to correct

82
00:03:04,080 --> 00:03:06,200
is that these open source models

83
00:03:06,200 --> 00:03:09,320
are simply being trained on prompts and responses

84
00:03:09,320 --> 00:03:11,440
which is good for pattern matching.

85
00:03:11,440 --> 00:03:13,880
So for example, if you're a student in college

86
00:03:13,880 --> 00:03:15,200
and you're taking a class,

87
00:03:15,200 --> 00:03:18,040
you could probably do pretty well on a lot of tests

88
00:03:18,040 --> 00:03:20,920
simply by pattern matching the question to an answer.

89
00:03:20,920 --> 00:03:23,480
But that student is gonna have a lot of limitations.

90
00:03:23,480 --> 00:03:25,040
If one of the questions varies

91
00:03:25,040 --> 00:03:26,920
from their pattern matching ability,

92
00:03:26,920 --> 00:03:28,520
by even just a little bit,

93
00:03:28,520 --> 00:03:30,680
their ability to reason and figure out

94
00:03:30,680 --> 00:03:33,320
what the answer might be becomes highly limited.

95
00:03:33,320 --> 00:03:36,000
Whereas the student who fundamentally

96
00:03:36,000 --> 00:03:37,960
and deeply understands a topic

97
00:03:37,960 --> 00:03:41,200
won't be thrown off by any variation of the question.

98
00:03:41,200 --> 00:03:45,120
They'll be able to reason and step by step get to the answer

99
00:03:45,120 --> 00:03:47,320
because they do truly understand the topic.

100
00:03:47,320 --> 00:03:48,760
And that's really the difference

101
00:03:48,760 --> 00:03:51,360
between these large foundational models

102
00:03:51,360 --> 00:03:54,160
and the open source imitations of them

103
00:03:54,160 --> 00:03:55,360
as per this paper.

104
00:03:55,360 --> 00:03:57,120
And that brings us to Orca.

105
00:03:57,120 --> 00:03:59,800
Orca challenges the idea that open source models

106
00:03:59,800 --> 00:04:02,280
can only really imitate answers

107
00:04:02,280 --> 00:04:04,520
and will get thrown off by any variation

108
00:04:04,520 --> 00:04:06,040
in the prompts themselves.

109
00:04:06,040 --> 00:04:08,960
And the way they do it seems very obvious in hindsight.

110
00:04:08,960 --> 00:04:10,800
Before we get into the details,

111
00:04:10,800 --> 00:04:15,040
Orca outperforms every other open source model

112
00:04:15,040 --> 00:04:19,280
and even outperforms ChatGPT, which is GPT 3.5,

113
00:04:19,280 --> 00:04:21,200
in a lot of different benchmarks.

114
00:04:21,200 --> 00:04:24,360
Now, of course, it still lags behind GPT4,

115
00:04:24,360 --> 00:04:26,480
but the gap continues to close.

116
00:04:26,480 --> 00:04:28,080
So let's take a look at this paper now.

117
00:04:28,080 --> 00:04:29,520
They start off the abstract

118
00:04:29,520 --> 00:04:32,340
by addressing this imitation concept.

119
00:04:32,340 --> 00:04:35,320
Recent research has focused on enhancing the capability

120
00:04:35,320 --> 00:04:37,520
of smaller models through imitation learning,

121
00:04:37,520 --> 00:04:39,280
drawing on the outputs generated

122
00:04:39,280 --> 00:04:40,920
by large foundational models.

123
00:04:40,920 --> 00:04:45,000
Again, LFMs are referring to ChatGPT and GPT4.

124
00:04:45,000 --> 00:04:46,880
And they start to outline the limitations

125
00:04:46,880 --> 00:04:48,680
of these imitation techniques.

126
00:04:48,680 --> 00:04:51,640
Some that they point out are limited imitation signals

127
00:04:51,640 --> 00:04:53,880
from shallow LFM outputs,

128
00:04:53,880 --> 00:04:56,280
small scale homogenous training data,

129
00:04:56,280 --> 00:05:00,360
and most notably a lack of rigorous evaluation

130
00:05:00,360 --> 00:05:03,280
resulting in overestimating the small models capability

131
00:05:03,280 --> 00:05:05,800
as they tend to learn to imitate the style

132
00:05:05,800 --> 00:05:08,760
but not the reasoning process of LFMs.

133
00:05:08,760 --> 00:05:11,640
That is really the crux of this paper.

134
00:05:11,640 --> 00:05:14,520
How do we start getting these open source models

135
00:05:14,520 --> 00:05:17,600
to not just mimic the question answer pairs,

136
00:05:17,600 --> 00:05:20,040
but actually understand how they get

137
00:05:20,040 --> 00:05:22,420
from a question to an answer.

138
00:05:22,420 --> 00:05:25,560
And only with that is true intelligence created.

139
00:05:25,560 --> 00:05:28,000
To address these challenges, we develop ORCA,

140
00:05:28,000 --> 00:05:29,680
a 13 billion parameter model

141
00:05:29,680 --> 00:05:32,800
that learns to imitate the reasoning process of LFMs.

142
00:05:32,800 --> 00:05:34,560
Let's pause there for a second.

143
00:05:34,560 --> 00:05:39,080
This model, the ORCA model is only 13 billion parameters,

144
00:05:39,080 --> 00:05:43,120
which means it can run on pretty much any modern hardware.

145
00:05:43,120 --> 00:05:44,520
Whereas some of the other models

146
00:05:44,520 --> 00:05:45,840
that I've been reviewing recently,

147
00:05:45,840 --> 00:05:47,080
like the Guinaco model,

148
00:05:47,080 --> 00:05:49,600
require me to rent out a cloud GPU,

149
00:05:49,600 --> 00:05:53,080
like an A6000 that has 48 gigabytes of VRAM,

150
00:05:53,080 --> 00:05:55,820
because it's so large, 65 billion parameters.

151
00:05:55,820 --> 00:05:57,560
And this performs better than that.

152
00:05:57,560 --> 00:05:59,060
Now here's the key to the paper.

153
00:05:59,060 --> 00:06:00,360
Here's the key technique.

154
00:06:00,360 --> 00:06:03,720
ORCA learns from rich signals from GPT-4,

155
00:06:03,720 --> 00:06:05,560
including explanation traces,

156
00:06:05,560 --> 00:06:07,680
step-by-step thought processes,

157
00:06:07,680 --> 00:06:09,640
and other complex instructions

158
00:06:09,640 --> 00:06:12,800
guided by teacher assistance from chat GPT.

159
00:06:12,800 --> 00:06:14,720
Now I'll explain what teacher assistance is

160
00:06:14,720 --> 00:06:17,040
in a little bit, but looking at this sentence,

161
00:06:17,040 --> 00:06:18,520
what it's really saying is,

162
00:06:18,520 --> 00:06:21,120
rather than learning from the prompt and response pairs,

163
00:06:21,120 --> 00:06:23,800
we're going to ask these large foundational models

164
00:06:23,800 --> 00:06:27,160
to explain their reasoning step-by-step,

165
00:06:27,160 --> 00:06:29,280
and the smaller open source models

166
00:06:29,280 --> 00:06:30,560
will learn from that.

167
00:06:30,560 --> 00:06:32,280
Truly fascinating.

168
00:06:32,280 --> 00:06:34,160
Now I wanna briefly touch on this guided

169
00:06:34,160 --> 00:06:36,840
by teacher assistance from chat GPT.

170
00:06:36,840 --> 00:06:40,000
They have a two-tier teaching process.

171
00:06:40,000 --> 00:06:43,680
One, they take chat GPT, which is GPT-3.5,

172
00:06:43,680 --> 00:06:45,480
and they have a large number of examples

173
00:06:45,480 --> 00:06:46,880
to learn from, five million.

174
00:06:46,880 --> 00:06:48,680
Then they take those five million,

175
00:06:48,680 --> 00:06:52,260
boil it down to the most important one million examples,

176
00:06:52,260 --> 00:06:55,760
and then use GPT-4 to continue to train

177
00:06:55,760 --> 00:06:57,520
on more complex examples.

178
00:06:57,520 --> 00:06:59,160
So how does it actually perform?

179
00:06:59,160 --> 00:07:01,480
ORCA surpasses conventional state-of-the-art

180
00:07:01,480 --> 00:07:04,640
instruction-tuned models, such as Vecunia 13B

181
00:07:04,640 --> 00:07:09,000
by more than 100% in complex zero-shot reasoning benchmarks

182
00:07:09,000 --> 00:07:13,040
like Big Bench Hard and 42% on AGI Eval.

183
00:07:13,040 --> 00:07:16,140
Big Bench Hard and AGI Eval are just sets of tests

184
00:07:16,140 --> 00:07:17,920
that they give to these large language models

185
00:07:17,920 --> 00:07:19,360
to test their performance.

186
00:07:19,360 --> 00:07:23,800
ORCA reaches parity with chat GPT on the BBH benchmark

187
00:07:23,800 --> 00:07:25,560
and shows competitive performance

188
00:07:25,560 --> 00:07:28,120
in professional and academic examinations

189
00:07:28,120 --> 00:07:30,400
like SAT, LSAT, GRE, and GMAT,

190
00:07:30,400 --> 00:07:33,360
both in zero-shot setting without chain of thought

191
00:07:33,360 --> 00:07:35,100
while trailing behind GPT-4.

192
00:07:35,100 --> 00:07:38,080
And again, this last sentence is everything.

193
00:07:38,080 --> 00:07:40,200
Our research indicates that learning

194
00:07:40,200 --> 00:07:42,400
from step-by-step explanations,

195
00:07:42,400 --> 00:07:44,160
whether these are generated by humans

196
00:07:44,160 --> 00:07:45,560
or more advanced AI models,

197
00:07:45,560 --> 00:07:48,440
is a promising direction to improve model capabilities

198
00:07:48,440 --> 00:07:49,280
and skills.

199
00:07:49,280 --> 00:07:50,720
And just like humans,

200
00:07:50,720 --> 00:07:53,840
large language models understanding how something works

201
00:07:53,840 --> 00:07:55,760
is much more effective

202
00:07:55,760 --> 00:07:59,000
than just being able to pattern match questions and answers.

203
00:07:59,000 --> 00:08:01,640
So large language models are typically tuned

204
00:08:01,640 --> 00:08:03,660
by something called instruction tuning.

205
00:08:03,660 --> 00:08:06,600
You have a set of prompts and you have a set of responses

206
00:08:06,600 --> 00:08:09,600
and those pairs are passed to the open source model

207
00:08:09,600 --> 00:08:10,680
and it learns from that.

208
00:08:10,680 --> 00:08:13,960
This technique is called explanation tuning

209
00:08:13,960 --> 00:08:16,160
where it's not just the prompt and the answer

210
00:08:16,160 --> 00:08:18,920
but an explanation of the reasoning and the logic

211
00:08:18,920 --> 00:08:22,120
for how chat GPT and GPT-4 arrived at an answer.

212
00:08:22,120 --> 00:08:25,880
And so we can see here when evaluated by GPT-4

213
00:08:25,880 --> 00:08:27,600
and that's called auto-evaluation,

214
00:08:27,600 --> 00:08:30,820
ORCA 13B actually beats chat GPT.

215
00:08:30,820 --> 00:08:33,140
It beats Bard and it certainly beats

216
00:08:33,140 --> 00:08:35,200
the open source models based on Lama.

217
00:08:35,200 --> 00:08:38,640
And then for zero shot problems on academic exams,

218
00:08:38,640 --> 00:08:41,400
chat GPT definitely performs better

219
00:08:41,400 --> 00:08:45,600
but ORCA 13B is really closing the gap in performance

220
00:08:45,600 --> 00:08:48,840
and performs much better than Virginia 13B.

221
00:08:48,840 --> 00:08:51,480
And for complex zero shot reasoning tasks

222
00:08:51,480 --> 00:08:55,120
and big bench hard, ORCA achieves parity with chat GPT.

223
00:08:55,120 --> 00:08:56,080
And here again,

224
00:08:56,080 --> 00:08:58,760
they specifically call out that imitation paper.

225
00:08:58,760 --> 00:09:01,800
Authors assert that model imitation is a false promise

226
00:09:01,800 --> 00:09:04,960
since broadly matching chat GPT using purely imitation

227
00:09:04,960 --> 00:09:07,320
would require one, a concerted effort

228
00:09:07,320 --> 00:09:09,720
to collect enormous imitation data sets

229
00:09:09,720 --> 00:09:12,720
and far more diverse and higher quality imitation data

230
00:09:12,720 --> 00:09:14,140
than is currently available.

231
00:09:14,140 --> 00:09:16,800
So one of the biggest problems is these open source models

232
00:09:16,800 --> 00:09:19,680
can't get enough data to use the imitation technique

233
00:09:19,680 --> 00:09:20,840
and perform at the same rate

234
00:09:20,840 --> 00:09:22,800
as these large foundational models.

235
00:09:22,800 --> 00:09:24,280
Contrary to this assertion,

236
00:09:24,280 --> 00:09:27,000
we demonstrate that both conditions one and two

237
00:09:27,000 --> 00:09:29,320
are attainable and that it is possible

238
00:09:29,320 --> 00:09:31,560
to reduce the gap with proprietary LLMs

239
00:09:31,560 --> 00:09:33,560
on multiple zero shot benchmarks

240
00:09:33,560 --> 00:09:35,280
that require sophisticated reasoning.

241
00:09:35,280 --> 00:09:38,120
And here they touch on what the existing open source models

242
00:09:38,120 --> 00:09:40,040
are doing currently to train themselves.

243
00:09:40,040 --> 00:09:43,200
Both Alpaca and Wizard LM employ a variant

244
00:09:43,200 --> 00:09:44,160
of self-instructs.

245
00:09:44,160 --> 00:09:45,440
So that's what we've been talking about.

246
00:09:45,440 --> 00:09:48,960
Wizard LM introduces the concept of Eval Instruct

247
00:09:48,960 --> 00:09:51,800
which gradually rewrites the initial set of instructions

248
00:09:51,800 --> 00:09:53,400
into more complex versions

249
00:09:53,400 --> 00:09:55,000
attempting to overcome some of the methods

250
00:09:55,000 --> 00:09:56,240
inherent shortcomings.

251
00:09:56,240 --> 00:09:57,920
But with Vakunya and Kuala,

252
00:09:57,920 --> 00:10:00,160
they demonstrate remarkable performance

253
00:10:00,160 --> 00:10:01,960
due to the more human-like conversations

254
00:10:01,960 --> 00:10:03,120
and natural instructions

255
00:10:03,120 --> 00:10:05,080
in the community contributed conversations

256
00:10:05,080 --> 00:10:06,680
like those in shared GPT.

257
00:10:06,680 --> 00:10:08,400
So basically what they're saying is

258
00:10:08,400 --> 00:10:10,720
as more people are using these open source models

259
00:10:10,720 --> 00:10:11,680
and sharing their data,

260
00:10:11,680 --> 00:10:13,280
sharing their instructions,

261
00:10:13,280 --> 00:10:14,760
their prompts and the output,

262
00:10:14,760 --> 00:10:16,400
they'll continue to train on those pairs

263
00:10:16,400 --> 00:10:17,560
and get better and better.

264
00:10:17,560 --> 00:10:19,440
But there's a limitation with that as well.

265
00:10:19,440 --> 00:10:21,920
And it's the same thing that we keep coming back to.

266
00:10:21,920 --> 00:10:24,600
Models trained on such natural conversations

267
00:10:24,600 --> 00:10:26,080
may capture the style

268
00:10:26,080 --> 00:10:29,320
but not the reasoning process of the LLFM.

269
00:10:29,320 --> 00:10:31,880
So again, they'll be able to pattern match

270
00:10:31,880 --> 00:10:34,720
but they're not gonna truly understand the logic

271
00:10:34,720 --> 00:10:37,560
and the reasoning behind arriving at the solutions.

272
00:10:37,560 --> 00:10:41,680
Now the Orca Paper puts forth three key contributions.

273
00:10:41,680 --> 00:10:44,080
Number one is explanation tuning.

274
00:10:44,080 --> 00:10:46,840
And again, this is fine tuning models

275
00:10:46,840 --> 00:10:49,880
based on the step-by-step explanation

276
00:10:49,880 --> 00:10:51,240
of the reasoning and the logic

277
00:10:51,240 --> 00:10:52,760
of how to arrive at a solution.

278
00:10:52,760 --> 00:10:53,920
Let's read this a little bit.

279
00:10:53,920 --> 00:10:56,400
We augment the query response pairs

280
00:10:56,400 --> 00:10:58,760
with detailed responses from GPT-4

281
00:10:58,760 --> 00:11:01,320
that explain the reasoning process of the teacher

282
00:11:01,320 --> 00:11:03,000
as it generates the response.

283
00:11:03,000 --> 00:11:04,720
And to get the step-by-step reasoning,

284
00:11:04,720 --> 00:11:07,240
they're using some of these more modern prompting techniques

285
00:11:07,240 --> 00:11:08,600
that we've been learning about,

286
00:11:08,600 --> 00:11:10,720
such as explain like I'm five,

287
00:11:10,720 --> 00:11:13,440
think step-by-step and justify your response.

288
00:11:13,440 --> 00:11:17,520
This forces GPT-4 to put forth its reasoning

289
00:11:17,520 --> 00:11:19,720
and its logic in the response itself

290
00:11:19,720 --> 00:11:21,680
and that is used to train.

291
00:11:21,680 --> 00:11:23,480
And that's what explanation tuning is.

292
00:11:23,480 --> 00:11:26,280
Another issue is scaling the amount of tasks and instructions.

293
00:11:26,280 --> 00:11:28,960
As you'll see in a graph that I'll show in a second,

294
00:11:28,960 --> 00:11:30,440
a lot of these open source models

295
00:11:30,440 --> 00:11:32,480
are using a highly limited data set,

296
00:11:32,480 --> 00:11:35,080
but that's where Orca really excels.

297
00:11:35,080 --> 00:11:37,600
We utilize the Flaan 2020 collection

298
00:11:37,600 --> 00:11:39,760
and that's a data set of tasks and instructions

299
00:11:39,760 --> 00:11:40,880
put forth by Google

300
00:11:40,880 --> 00:11:43,760
that has tens of millions of instructions.

301
00:11:43,760 --> 00:11:46,020
So let's quickly take a look at the data sizes

302
00:11:46,020 --> 00:11:47,360
for these open source models.

303
00:11:47,360 --> 00:11:49,720
All of them have in the thousands.

304
00:11:49,720 --> 00:11:53,280
So you can see here that Alpaca has 52,000,

305
00:11:53,280 --> 00:11:56,280
Vakunya has 70,000 and WizardLM with the most

306
00:11:56,280 --> 00:11:59,280
has 250,000 based on the teacher of chat GPT.

307
00:11:59,280 --> 00:12:00,680
And some of these other ones like Dolly

308
00:12:00,680 --> 00:12:01,760
are human instructed.

309
00:12:01,760 --> 00:12:03,280
So they're even more limited

310
00:12:03,280 --> 00:12:04,920
because of the limitations of humans.

311
00:12:04,920 --> 00:12:06,720
However, as you could see here,

312
00:12:06,720 --> 00:12:10,200
Orca has five million, many times more

313
00:12:10,200 --> 00:12:12,600
than all of the other open source models.

314
00:12:12,600 --> 00:12:15,160
And it's based on chat GPT initially,

315
00:12:15,160 --> 00:12:17,160
so that's the initial five million pass

316
00:12:17,160 --> 00:12:20,280
and then GPT-4 with a second pass

317
00:12:20,280 --> 00:12:23,120
of much more complex tasks and instructions.

318
00:12:23,120 --> 00:12:25,420
So not only are they getting full explanations

319
00:12:25,420 --> 00:12:26,920
of query and responses

320
00:12:26,920 --> 00:12:29,160
and how they actually reach those responses,

321
00:12:29,160 --> 00:12:31,040
but they're getting so many more of them

322
00:12:31,040 --> 00:12:32,960
and they're solving the data scaling issue.

323
00:12:32,960 --> 00:12:34,400
Last is evaluation.

324
00:12:34,400 --> 00:12:37,720
There are a lot of issues with current evaluation techniques

325
00:12:37,720 --> 00:12:38,920
for open source models,

326
00:12:38,920 --> 00:12:41,320
but Orca claims to solve these in a few ways.

327
00:12:41,320 --> 00:12:43,800
They use auto evaluation with GPT-4.

328
00:12:43,800 --> 00:12:47,640
So basically asking GPT-4 between two potential responses,

329
00:12:47,640 --> 00:12:48,720
which one is best.

330
00:12:48,720 --> 00:12:51,560
They also use academic benchmarks like Big Bench Hard

331
00:12:51,560 --> 00:12:54,560
and Truthful QA and professional and academic exams

332
00:12:54,560 --> 00:12:56,480
like the SAT, LSAT, et cetera.

333
00:12:56,480 --> 00:12:58,580
And last, they use safety evaluation

334
00:12:58,580 --> 00:13:01,140
from ToxicGen, basically do these responses

335
00:13:01,140 --> 00:13:02,700
contain toxic language.

336
00:13:02,700 --> 00:13:04,220
So in figure four,

337
00:13:04,220 --> 00:13:06,660
they illustrate what the previous techniques do

338
00:13:06,660 --> 00:13:08,580
with queries and responses.

339
00:13:08,580 --> 00:13:10,180
So here's a user instruction.

340
00:13:10,180 --> 00:13:12,260
Use the data to calculate the median.

341
00:13:12,260 --> 00:13:14,340
Here it says, first, we need to arrange the data

342
00:13:14,340 --> 00:13:15,620
in ascending order.

343
00:13:15,620 --> 00:13:16,700
Since there are five numbers,

344
00:13:16,700 --> 00:13:19,060
the median is in the middle, which is seven.

345
00:13:19,060 --> 00:13:20,220
And so this is very basic.

346
00:13:20,220 --> 00:13:22,700
It's a prompt, a query, and then the response.

347
00:13:22,700 --> 00:13:24,060
Whereas with their new method,

348
00:13:24,060 --> 00:13:26,380
they ask GPT-4 to explain.

349
00:13:26,380 --> 00:13:27,540
So the system instruction

350
00:13:27,540 --> 00:13:29,420
seems to be the main tool that they use

351
00:13:29,420 --> 00:13:33,060
to get chat GPT and GPT-4 to explain their reasoning.

352
00:13:33,060 --> 00:13:34,580
You are an AI assistant.

353
00:13:34,580 --> 00:13:36,060
User will give you a task.

354
00:13:36,060 --> 00:13:38,460
Your goal is to complete the task as faithfully

355
00:13:38,460 --> 00:13:39,980
as you can while performing the task.

356
00:13:39,980 --> 00:13:42,420
Think step by step and justify your steps.

357
00:13:42,420 --> 00:13:45,820
So again, use the given data to calculate the median.

358
00:13:45,820 --> 00:13:46,780
Same prompt.

359
00:13:46,780 --> 00:13:48,980
To calculate the median, I will follow these steps.

360
00:13:48,980 --> 00:13:51,700
And GPT-4 actually outlines step by step

361
00:13:51,700 --> 00:13:53,820
how it will figure out what the median is.

362
00:13:53,820 --> 00:13:56,420
That data is then used to train the open source model.

363
00:13:56,420 --> 00:13:58,020
I find it so fascinating

364
00:13:58,020 --> 00:14:00,420
that we're using some of these modern prompting techniques

365
00:14:00,420 --> 00:14:03,300
like chain of thought, like explain like on five,

366
00:14:03,300 --> 00:14:05,700
that people have been figuring out over the last few months

367
00:14:05,700 --> 00:14:09,260
to get better answers from chat GPT and GPT-4.

368
00:14:09,260 --> 00:14:11,260
And we're using those to get better data

369
00:14:11,260 --> 00:14:13,700
to train the open source models with.

370
00:14:13,700 --> 00:14:16,880
And as I mentioned, system messages seem to be the main tool

371
00:14:16,880 --> 00:14:19,020
to get chat GPT and GPT-4

372
00:14:19,020 --> 00:14:22,060
to provide the step by step explanations.

373
00:14:22,060 --> 00:14:25,060
And if you play around with the chat GPT playground

374
00:14:25,060 --> 00:14:27,760
or even the API, you'll know that the system messages

375
00:14:27,760 --> 00:14:30,940
are a requirement for using either of these tools.

376
00:14:30,940 --> 00:14:32,140
So here are a few examples.

377
00:14:32,140 --> 00:14:33,180
You will be given a task,

378
00:14:33,180 --> 00:14:35,340
you must generate a detailed and long answer.

379
00:14:35,340 --> 00:14:37,540
Think like you are answering to a five year old,

380
00:14:37,540 --> 00:14:38,660
help as much as you can.

381
00:14:38,660 --> 00:14:40,500
So it's really just coaxing chat GPT-4

382
00:14:40,500 --> 00:14:43,380
to explain its reasoning and to be as verbose as possible.

383
00:14:43,380 --> 00:14:44,980
So let's actually take a look at the difference

384
00:14:44,980 --> 00:14:46,740
between these two prompting techniques.

385
00:14:46,740 --> 00:14:48,060
So for the system message,

386
00:14:48,060 --> 00:14:51,380
you are an AI assistant that helps people find information.

387
00:14:51,380 --> 00:14:52,620
User will give you a question.

388
00:14:52,620 --> 00:14:54,620
Your task is to answer as faithfully as you can

389
00:14:54,660 --> 00:14:56,980
while answering things step by step and justify your answer.

390
00:14:56,980 --> 00:15:00,880
So the prompt is pick which sentence is not logical.

391
00:15:00,880 --> 00:15:04,060
Sentence A, people in the desert often look forward to flood.

392
00:15:04,060 --> 00:15:07,140
Sentence B, people in the desert often look forward to rain.

393
00:15:07,140 --> 00:15:08,860
Now it might seem obvious to us

394
00:15:08,860 --> 00:15:10,580
why these sentences are different,

395
00:15:10,580 --> 00:15:13,300
but there's really just a subtle difference between them.

396
00:15:13,300 --> 00:15:15,020
So here a typical response might be,

397
00:15:15,020 --> 00:15:16,740
there is no reason to look forward to a flood

398
00:15:16,740 --> 00:15:17,980
because floods cause damage.

399
00:15:17,980 --> 00:15:19,260
The answer is sentence A.

400
00:15:19,260 --> 00:15:21,700
Chat GPT says, okay, let's break it down.

401
00:15:21,700 --> 00:15:23,100
Read the sentences carefully.

402
00:15:23,100 --> 00:15:24,140
So it's talking about what steps

403
00:15:24,140 --> 00:15:25,580
am I going to take to answer this?

404
00:15:25,580 --> 00:15:27,380
Identify the differences between them

405
00:15:27,380 --> 00:15:29,500
and determine which sentence is not logical.

406
00:15:29,500 --> 00:15:32,020
Then they say, sentence A, people in the desert

407
00:15:32,020 --> 00:15:33,100
often look forward to the flood.

408
00:15:33,100 --> 00:15:35,620
This sentence suggests that people in the desert

409
00:15:35,620 --> 00:15:37,500
are eagerly anticipating a flood.

410
00:15:37,500 --> 00:15:40,060
However, floods are typically destructive and dangerous.

411
00:15:40,060 --> 00:15:42,940
So it seems unlikely that people would look forward to them.

412
00:15:42,940 --> 00:15:45,260
Sentence B, they're looking forward to the rain.

413
00:15:45,260 --> 00:15:48,500
And it says this sentence suggests that people in the desert

414
00:15:48,500 --> 00:15:50,300
are eagerly anticipating rain

415
00:15:50,300 --> 00:15:51,860
while the desert is a dry environment.

416
00:15:51,860 --> 00:15:53,620
Rain can be beneficial in providing water

417
00:15:53,620 --> 00:15:54,580
for plants and animals.

418
00:15:54,580 --> 00:15:57,100
Then it finishes with, based on the above analysis,

419
00:15:57,100 --> 00:15:59,580
it can be concluded that sentence A is not logical.

420
00:15:59,580 --> 00:16:01,340
Then we look at GPT-4's answer.

421
00:16:01,340 --> 00:16:03,500
And as you can see, I won't read all of it.

422
00:16:03,500 --> 00:16:06,860
It's a much more detailed and verbose answer.

423
00:16:06,860 --> 00:16:08,660
Now in this section, they talk about

424
00:16:08,660 --> 00:16:11,340
why Chat GPT as a teaching assistant,

425
00:16:11,340 --> 00:16:14,660
assistant to GPT-4, is such a powerful method.

426
00:16:14,660 --> 00:16:16,740
And there's really two reasons for it.

427
00:16:16,740 --> 00:16:19,840
One is a capacity gap because there's such a large gap

428
00:16:19,840 --> 00:16:22,480
between the ORCA model and GPT-4.

429
00:16:22,480 --> 00:16:24,240
Being able to take data from GPT-4

430
00:16:24,240 --> 00:16:26,080
and passing it directly into ORCA,

431
00:16:26,080 --> 00:16:27,760
it's gonna struggle with imitation.

432
00:16:27,760 --> 00:16:29,520
Whereas if they progressively teach it

433
00:16:29,520 --> 00:16:31,480
to get to the GPT-4 level

434
00:16:31,480 --> 00:16:34,080
by the intermediate step of Chat GPT,

435
00:16:34,080 --> 00:16:35,840
it really performs much better.

436
00:16:35,840 --> 00:16:38,600
This can be viewed as a form of progressive learning

437
00:16:38,600 --> 00:16:40,240
or curriculum learning,

438
00:16:40,240 --> 00:16:42,520
where the student first learns from easier examples

439
00:16:42,520 --> 00:16:43,920
followed by harder ones.

440
00:16:43,920 --> 00:16:47,400
Again, more and more human-like behavior.

441
00:16:47,440 --> 00:16:50,080
Human doesn't go from learning the basics of addition

442
00:16:50,080 --> 00:16:51,920
all the way to calculus in one step.

443
00:16:51,920 --> 00:16:54,400
They learn many incrementally more difficult steps

444
00:16:54,400 --> 00:16:57,880
of mathematics between addition and calculus.

445
00:16:57,880 --> 00:17:01,440
Next is a simple pragmatic reason, cost and time.

446
00:17:01,440 --> 00:17:05,200
Chat GPT, specifically GPT-3.5 turbo,

447
00:17:05,200 --> 00:17:09,200
is much faster and much less expensive than GPT-4.

448
00:17:09,200 --> 00:17:11,120
So that's why they use five million examples

449
00:17:11,120 --> 00:17:14,920
with Chat GPT and one million examples for GPT-4.

450
00:17:14,920 --> 00:17:16,560
So this graphic shows the performance

451
00:17:16,600 --> 00:17:18,360
of these large foundational models,

452
00:17:18,360 --> 00:17:20,440
Vecunia and ORCA.

453
00:17:20,440 --> 00:17:22,520
And as we can clearly see from questions

454
00:17:22,520 --> 00:17:24,280
from the LSAT and the SAT,

455
00:17:24,280 --> 00:17:27,600
ORCA performs significantly better than Vecunia.

456
00:17:27,600 --> 00:17:29,440
And if we look at the ORCA column,

457
00:17:29,440 --> 00:17:31,240
compared to the Chat GPT column,

458
00:17:31,240 --> 00:17:33,720
overall it performs quite similarly,

459
00:17:33,720 --> 00:17:36,480
but it still does lag behind GPT-4.

460
00:17:36,480 --> 00:17:37,600
And they've actually shown

461
00:17:37,600 --> 00:17:40,240
that this progressive learning technique really works.

462
00:17:40,240 --> 00:17:43,200
As we can see here, using only GPT-4,

463
00:17:43,240 --> 00:17:46,840
they were able to achieve a score of 37.18,

464
00:17:46,840 --> 00:17:50,400
whereas if they used that intermediate step of Chat GPT,

465
00:17:50,400 --> 00:17:53,160
they were able to achieve 41.7.

466
00:17:53,160 --> 00:17:54,720
That might seem small,

467
00:17:54,720 --> 00:17:56,320
but that is a significant improvement.

468
00:17:56,320 --> 00:17:58,120
And for the big bench hard results,

469
00:17:58,120 --> 00:18:01,560
ORCA performs marginally better than Chat GPT on aggregate

470
00:18:01,560 --> 00:18:05,440
across all tasks, significantly lags GPT-4

471
00:18:05,440 --> 00:18:09,120
and outperforms Vecunia by 113%.

472
00:18:09,120 --> 00:18:12,160
And here they give a graphic of the zero-shot performance

473
00:18:12,200 --> 00:18:14,160
against all of these different tasks.

474
00:18:14,160 --> 00:18:17,280
And you can see that ORCA performs substantially

475
00:18:17,280 --> 00:18:18,440
better than Vecunia.

476
00:18:18,440 --> 00:18:21,240
And even across all of them, like it said,

477
00:18:21,240 --> 00:18:23,680
it performs better than Chat GPT.

478
00:18:23,680 --> 00:18:25,240
So what does all this mean?

479
00:18:25,240 --> 00:18:27,800
I find it fascinating for two reasons.

480
00:18:27,800 --> 00:18:30,360
One, open-source models continue to get better

481
00:18:30,360 --> 00:18:32,040
at a rapid clip.

482
00:18:32,040 --> 00:18:34,560
New techniques for fine-tuning, training

483
00:18:34,560 --> 00:18:36,880
are coming out every single day.

484
00:18:36,880 --> 00:18:39,440
So I think back to that we have no mode paper

485
00:18:39,440 --> 00:18:41,240
and it makes a lot of sense still.

486
00:18:41,240 --> 00:18:43,520
I also find it fascinating that GPT-4

487
00:18:43,520 --> 00:18:45,920
still seems to have some secret sauce

488
00:18:45,920 --> 00:18:49,080
and performs much better than any other model.

489
00:18:49,080 --> 00:18:51,840
So OpenAI seems to have plenty of mode.

490
00:18:51,840 --> 00:18:55,080
This mode seems to be incrementally getting decreased,

491
00:18:55,080 --> 00:18:56,400
but they still do have it.

492
00:18:56,400 --> 00:18:58,160
The last thing that I find fascinating

493
00:18:58,160 --> 00:19:01,360
is that this paper is by Microsoft Research.

494
00:19:01,360 --> 00:19:05,680
Microsoft Research owns a significant portion of OpenAI.

495
00:19:05,680 --> 00:19:07,640
So the fact that they're making research gains

496
00:19:07,640 --> 00:19:09,620
in open-source is awesome.

497
00:19:09,620 --> 00:19:11,860
And OpenAI really must feel

498
00:19:11,860 --> 00:19:13,940
that they have a significant mode to work with.

499
00:19:13,940 --> 00:19:16,940
And OpenAI also mentioned a week ago

500
00:19:16,940 --> 00:19:19,100
that they're releasing their own open-source model.

501
00:19:19,100 --> 00:19:20,940
So I think what all of this means

502
00:19:20,940 --> 00:19:22,780
is that these large language models

503
00:19:22,780 --> 00:19:25,440
will continue to get better and cheaper over time.

504
00:19:25,440 --> 00:19:28,100
Now Orca's code and dataset are not yet released,

505
00:19:28,100 --> 00:19:30,180
but as soon as it is, we're gonna review it.

506
00:19:30,180 --> 00:19:31,660
I'm gonna show you how to use it

507
00:19:31,660 --> 00:19:33,260
and we'll see how it performs.

508
00:19:33,260 --> 00:19:34,500
If you liked this video,

509
00:19:34,500 --> 00:19:36,420
please consider giving me a like and subscribe

510
00:19:36,420 --> 00:19:38,020
and I'll see you in the next one.

