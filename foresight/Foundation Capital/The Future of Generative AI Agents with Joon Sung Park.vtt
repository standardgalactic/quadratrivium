WEBVTT

00:00.000 --> 00:04.280
The number of users who use ChatGPT, that's incredible.

00:04.280 --> 00:07.920
But I think it's sort of worth asking ourselves,

00:07.920 --> 00:11.080
is that sort of quote unquote the killer applications

00:11.080 --> 00:12.520
that we were waiting for?

00:12.520 --> 00:16.280
ChatGPT does feel like a fairly simple wrapper

00:16.280 --> 00:19.320
around our sling model, because that's what it is.

00:19.320 --> 00:22.160
OpenAI has done fantastic things to make it safer

00:22.160 --> 00:23.880
and make it more useful by tuning,

00:23.880 --> 00:25.560
I think, what's really great.

00:25.560 --> 00:28.200
But I think it's worth asking if that is actually

00:28.200 --> 00:32.480
the killer application, why is it a killer application?

00:32.480 --> 00:33.960
And the answer might actually come out

00:33.960 --> 00:36.960
that maybe it actually isn't the killer application

00:36.960 --> 00:39.880
that we were waiting for, in which case,

00:39.880 --> 00:42.160
what is going to be the killer application?

00:42.160 --> 00:44.080
That's really going to add value

00:44.080 --> 00:45.800
in a much more generalizable way.

00:48.360 --> 00:50.720
Welcome to AI in the real world.

00:50.720 --> 00:51.920
I'm your host.

00:51.920 --> 00:53.280
My name is Joanne Chen,

00:53.280 --> 00:55.760
and I am a general partner at Foundation Capital.

00:55.760 --> 00:56.920
I work closely with startups

00:56.920 --> 00:59.160
that are reshaping business with AI.

00:59.160 --> 01:02.000
In this series, I'll be holding in-depth discussions

01:02.000 --> 01:03.800
with leading AI researchers.

01:03.800 --> 01:05.680
We'll explore how state-of-the-art AI models

01:05.680 --> 01:08.960
are being applied in real enterprises today.

01:08.960 --> 01:12.200
To kick things off, I'm excited to speak with June Zempark,

01:12.200 --> 01:15.120
a PhD student in computer science at Stanford.

01:15.120 --> 01:18.280
June works at the intersection of human-computer interaction

01:18.280 --> 01:20.080
and natural language processing.

01:20.080 --> 01:23.800
He is best known for his research on AI agents.

01:23.800 --> 01:27.040
We break down how AI is transforming agent design,

01:27.040 --> 01:29.520
share advice for builders working with these models,

01:29.520 --> 01:31.000
and unpack why we haven't yet found

01:31.000 --> 01:34.440
the perfect killer app for AI agents.

01:34.440 --> 01:35.800
Here's our conversation.

01:35.800 --> 01:37.280
How are you?

01:37.280 --> 01:38.120
Good, what about you?

01:38.120 --> 01:38.960
Great seeing you again.

01:38.960 --> 01:39.800
Good to see you again.

01:39.800 --> 01:40.720
It's been a while.

01:40.720 --> 01:43.040
Because the on-conference was last,

01:43.040 --> 01:44.640
I want to say, June.

01:44.640 --> 01:45.960
June?

01:45.960 --> 01:46.800
May or June?

01:46.800 --> 01:47.800
Yeah.

01:47.800 --> 01:50.120
Last June, May or June.

01:50.120 --> 01:51.640
Wow, time-wise.

01:51.640 --> 01:53.200
And the world has changed.

01:53.240 --> 01:57.240
I think that agents have finally made its way

01:57.240 --> 02:01.080
into real enterprises with real use cases.

02:01.080 --> 02:04.760
And it was not, back then, it was a lot of,

02:04.760 --> 02:07.920
like, what could this be, right?

02:07.920 --> 02:09.680
Thanks to you as some of your work,

02:09.680 --> 02:11.240
which is why I'm super excited

02:11.240 --> 02:14.320
to have this conversation together.

02:15.240 --> 02:16.240
Especially right now,

02:16.240 --> 02:21.240
since enterprises are sinking in a real way

02:22.240 --> 02:24.400
to adopt.

02:24.400 --> 02:28.040
So I thought, who can we chat with

02:28.040 --> 02:30.200
that would have a really interesting perspective?

02:30.200 --> 02:32.160
And that's why we reached out back to you.

02:32.160 --> 02:34.760
So I really appreciate the time.

02:34.760 --> 02:35.600
Of course.

02:35.600 --> 02:37.360
Thanks for having me.

02:37.360 --> 02:39.200
Do you mind maybe just to start

02:39.200 --> 02:43.520
giving us a quick rundown of what's happened,

02:43.520 --> 02:46.040
maybe some of the background that you have

02:46.040 --> 02:47.280
building this technology?

02:48.440 --> 02:49.640
Yeah.

02:49.640 --> 02:51.600
So let's see.

02:51.600 --> 02:54.360
So do you want me to just sort of speak about

02:54.360 --> 02:56.120
sort of what has happened in the past six months,

02:56.120 --> 02:59.080
or sort of what would be interesting for you?

02:59.080 --> 03:01.560
Just a brief overview of what you worked on

03:01.560 --> 03:04.440
and also what's happened in the last six months

03:04.440 --> 03:06.880
to a year in terms of evolution.

03:06.880 --> 03:07.720
Yeah.

03:07.720 --> 03:08.840
All right, that sounds good.

03:08.840 --> 03:09.680
Right.

03:09.680 --> 03:12.200
So I guess I'll do a quick intro.

03:12.200 --> 03:15.200
So I'm sort of, I'm a PhD student here,

03:15.200 --> 03:18.480
sort of working in the area of HCI and NLP.

03:18.520 --> 03:21.560
So as you know, sort of the work that we've done,

03:21.560 --> 03:23.560
I think the one that I'm sort of mainly known for

03:23.560 --> 03:25.520
is this paper called Generative Agents.

03:26.480 --> 03:29.440
And Generative Agents in particular was a project

03:29.440 --> 03:31.000
that I tried to ask,

03:31.000 --> 03:34.680
can we use our language models to create general agents

03:34.680 --> 03:37.040
that can populate a simulation world?

03:37.040 --> 03:37.880
Right?

03:37.880 --> 03:40.480
So if you play something like SimCity or Sims,

03:40.480 --> 03:42.760
can we actually create these NPC-like characters

03:42.760 --> 03:44.720
that would actually flood into the city

03:44.720 --> 03:46.800
and actually live like humans?

03:46.800 --> 03:49.080
And by definition, it is sort of everything

03:49.080 --> 03:52.200
from how they would wake up in the morning,

03:52.200 --> 03:55.360
talk to each other, form routines and relationships,

03:55.360 --> 03:58.320
all the way to creating basically communities

03:58.320 --> 04:00.280
and emerging social dynamics.

04:01.440 --> 04:03.480
And sort of my interest in this area

04:03.480 --> 04:05.400
really stems from this idea.

04:05.400 --> 04:07.600
So this is sort of what people at the intersection

04:07.600 --> 04:09.840
of human-computer interaction and natural language processing

04:09.840 --> 04:11.600
in which learning like to ask,

04:11.600 --> 04:14.640
which is we now have these really amazing models

04:14.680 --> 04:17.160
like our language models and foundation models,

04:17.160 --> 04:18.840
the question really becomes,

04:18.840 --> 04:20.400
what are you going to do with them?

04:20.400 --> 04:21.240
Right?

04:21.240 --> 04:22.960
These models are new and they're great

04:22.960 --> 04:25.200
and we think they have great capacity,

04:25.200 --> 04:27.840
but are they really going to enable us

04:27.840 --> 04:31.360
to do something that's quite new and unique?

04:31.360 --> 04:33.120
And that has been sort of the focal point

04:33.120 --> 04:35.320
for a lot of the research that I do.

04:35.320 --> 04:37.600
And ultimately the conversation that we got down

04:37.600 --> 04:39.640
towards this idea of,

04:39.640 --> 04:41.760
well, these models are trained and brought data

04:41.760 --> 04:45.680
like the web, Wikipedia and so forth.

04:45.680 --> 04:47.600
So they can actually be used to generate

04:47.600 --> 04:49.760
a lot of believable human behavior

04:49.760 --> 04:52.000
when you're given a very micro context.

04:52.000 --> 04:53.600
So can we actually piece this together

04:53.600 --> 04:55.200
to create human-like agents,

04:55.200 --> 04:58.000
which is something that AI more broadly

04:58.000 --> 05:00.120
has envisioned since its founding days.

05:01.160 --> 05:03.600
And we decided that this is the time to do that.

05:03.600 --> 05:06.800
And so that's how we got to where we are.

05:06.800 --> 05:08.800
So that's the generative agents.

05:08.800 --> 05:12.160
And this is the paper that was published in April last year.

05:12.160 --> 05:14.000
We put it on archive in April

05:14.000 --> 05:16.640
and was officially published November.

05:16.640 --> 05:21.640
Which is crazy how much the world has developed.

05:22.240 --> 05:26.520
I'm curious what initially motivated this topic for you?

05:26.520 --> 05:28.440
I'm sure you had lots of different options

05:28.440 --> 05:30.840
in terms of what to research and study.

05:30.840 --> 05:33.080
Why did you decide to focus on this?

05:34.640 --> 05:35.480
Yeah.

05:35.480 --> 05:39.160
So ultimately, it really was the question of

05:39.160 --> 05:41.120
what will large language models,

05:41.120 --> 05:44.280
these new models that are being trained,

05:44.280 --> 05:45.800
really going to enable us to do.

05:45.800 --> 05:48.840
And when I started my PhD was around like 2020.

05:48.840 --> 05:51.680
And that was when GPT-3 was just about to come out.

05:51.680 --> 05:54.200
During my first year, we wrote a paper called

05:54.200 --> 05:57.880
Foundation Models, which sort of made this observation

05:57.880 --> 06:00.280
that there's going to be this new wave of models

06:00.280 --> 06:01.480
that's going to come out,

06:01.480 --> 06:04.000
where we're not going to be training these models

06:04.000 --> 06:05.600
for a specific task,

06:05.600 --> 06:08.000
but rather we'll be training for a modality.

06:08.000 --> 06:10.280
We're going to be training this language model

06:10.280 --> 06:12.560
that can process language and so forth.

06:13.520 --> 06:17.600
And we thought that was going to be a big opportunity there

06:17.600 --> 06:19.320
in terms of what we can do with them.

06:19.320 --> 06:21.120
But the question of what are we going to do with them

06:21.120 --> 06:22.720
was incredibly unclear.

06:22.720 --> 06:26.640
So really our first instinct as sort of researchers

06:26.640 --> 06:29.600
and more machine learning in the NLP community,

06:29.600 --> 06:32.000
where we sort of were drawn to was this idea

06:32.000 --> 06:33.440
of can we do classifications?

06:33.440 --> 06:35.480
Or generations with these models?

06:35.480 --> 06:38.400
And seeing that these models could do that was really exciting

06:38.400 --> 06:40.120
because we didn't train these models to do that,

06:40.120 --> 06:41.640
but they could.

06:41.640 --> 06:44.240
But more from the interaction perspective,

06:44.240 --> 06:46.720
doing classification and simple generation

06:46.720 --> 06:48.600
was something that we already knew how to do.

06:48.600 --> 06:51.600
So that did them feel fundamentally new.

06:51.600 --> 06:53.920
So really the question again became

06:53.920 --> 06:56.840
what are we going to do that's going to be truly new

06:56.840 --> 06:59.880
and transformative in the sense of interaction?

07:00.880 --> 07:05.960
So that's what really drew us to look for these kind of ideas.

07:05.960 --> 07:07.880
And again, that's we thought

07:07.880 --> 07:11.880
simulating human behavior in general computational agents,

07:11.880 --> 07:14.200
that felt like a big problem because in part

07:14.200 --> 07:16.280
because it's something that, again,

07:16.280 --> 07:19.440
our community had wanted for many decades.

07:19.440 --> 07:22.480
It was sort of the idea that people in more

07:22.480 --> 07:25.560
the cognitive science field that really inspired

07:25.560 --> 07:29.040
the early AI research, like Alan Newell and Albert Sass.

07:29.200 --> 07:31.520
Simon, these folks were asking.

07:31.520 --> 07:35.720
And we were certainly inspired by those ideas.

07:35.720 --> 07:37.520
And of course, we thought it would be a lot of fun

07:37.520 --> 07:40.080
because we sort of grew up with sims, Pokemon

07:40.080 --> 07:44.400
and these kinds of games in the 90s and early 2000s.

07:44.400 --> 07:46.760
And we were certainly inspired by those games as well.

07:46.760 --> 07:48.520
I love those games as well.

07:48.520 --> 07:53.480
And it's nice to see some of that play out in the real world.

07:53.480 --> 07:56.440
I agree. I think games are fun in the sense that,

07:56.440 --> 07:58.760
you know, I think they are inspirational in many ways

07:58.760 --> 08:02.240
because they are very forward-looking in many ways, right?

08:02.240 --> 08:04.400
Because you can be a little bit more playful.

08:04.400 --> 08:07.080
And I think research can be in many ways playful,

08:07.080 --> 08:10.240
especially when you're trying to do really forward-looking research.

08:10.240 --> 08:12.680
So it certainly is a big inspiration.

08:12.680 --> 08:16.280
And I was just going to sort of end that comment by saying

08:16.280 --> 08:19.960
that I think it's worth asking for us as a community

08:19.960 --> 08:23.160
what's going to be the new sort of quote unquote

08:23.160 --> 08:26.880
care application of these models.

08:26.920 --> 08:29.480
In the sense that when we had personal computers

08:29.480 --> 08:32.960
in the early 80s and so forth,

08:32.960 --> 08:35.600
the computers were very cool.

08:35.600 --> 08:40.320
But what really made them into household applications

08:40.320 --> 08:41.840
were the existence of this,

08:41.840 --> 08:46.280
what we would now consider as killer application of PCs,

08:46.280 --> 08:47.680
like Microsoft Excel,

08:47.680 --> 08:52.400
that really made tabular information usable and scalable.

08:52.400 --> 08:54.400
I think we, Luris Language Model Community,

08:54.400 --> 08:57.280
or should also be looking for those kind of ideas as well,

08:57.280 --> 08:58.960
because that's going to be ultimately

08:58.960 --> 09:01.680
what's going to really transform the user experience

09:01.680 --> 09:02.760
around these models.

09:02.760 --> 09:06.920
And I think we're seeing some great usage of these models,

09:06.920 --> 09:10.200
but I think there's a lot more to do going forward.

09:10.200 --> 09:11.680
Makes a lot of sense.

09:11.680 --> 09:15.480
When you look at what's happened since April, right,

09:15.480 --> 09:17.160
a lot of things have changed.

09:17.160 --> 09:20.120
We have new LLM capabilities.

09:20.120 --> 09:24.760
We have a whole flurry of startups building in this space.

09:24.760 --> 09:28.400
Could you maybe summarize what you've seen?

09:28.400 --> 09:30.080
Right.

09:30.080 --> 09:31.200
So, right.

09:31.200 --> 09:33.640
So, Agent Sotini has been a big thing,

09:33.640 --> 09:38.200
especially first the latter half of 2023.

09:38.200 --> 09:40.480
This is how I'm seeing it.

09:40.480 --> 09:43.600
Agent Community, it's sort of the way I view it,

09:43.600 --> 09:47.200
has split into two communities, I would argue now.

09:47.200 --> 09:50.840
So, maybe it might actually make a little more sense

09:50.840 --> 09:53.280
to really talk about the history of agents,

09:53.280 --> 09:55.200
because agent became a big thing last year,

09:55.200 --> 09:58.640
but this is not a new idea in and out of itself.

09:58.640 --> 10:01.480
Right, even in the commercial space,

10:01.480 --> 10:04.200
we actually had agents like Microsoft Clippy,

10:04.200 --> 10:06.560
I'm not sure how many of us will actually remember that,

10:06.560 --> 10:10.960
but there used to be these agents in sort of our industry

10:10.960 --> 10:12.520
and in research.

10:12.520 --> 10:15.440
So, this is certainly not a new idea.

10:15.520 --> 10:18.360
So, if you go all the way back,

10:18.360 --> 10:21.080
so we had agents like Clippy,

10:21.080 --> 10:23.360
and in many ways these agents,

10:23.360 --> 10:24.920
especially in the reinforcement learning

10:24.920 --> 10:26.000
and machine learning community,

10:26.000 --> 10:29.720
agents were these elements that basically

10:29.720 --> 10:31.040
could simulate human behavior.

10:31.040 --> 10:34.240
I think that is ultimately sort of underlying thesis,

10:34.240 --> 10:37.320
but many of the agents were given tools

10:37.320 --> 10:39.360
to automate certain tasks.

10:39.360 --> 10:41.720
And the task it were meant to automate

10:41.720 --> 10:44.000
were tasks that are not simple, right?

10:44.000 --> 10:46.440
It's not something like you're running a for loop

10:46.440 --> 10:47.520
with your Python code,

10:47.520 --> 10:49.200
but it's a little bit more complex than that, right?

10:49.200 --> 10:52.520
It operates in much more embodied spaces

10:52.520 --> 10:56.080
or in spaces that we often operate in, right?

10:56.080 --> 10:58.520
The web, right?

10:58.520 --> 11:00.480
Can it, the simplest example

11:00.480 --> 11:02.280
with these kind of tool-based agents

11:02.280 --> 11:04.200
are can it order me pizza?

11:04.200 --> 11:06.520
Can it buy plane tickets?

11:06.520 --> 11:08.200
And those might sound simple,

11:08.200 --> 11:10.480
but we know from our experiences

11:10.480 --> 11:11.920
that even ordering pizza actually

11:11.920 --> 11:14.240
does require multiple steps, right?

11:14.240 --> 11:15.880
We need to travel to certain websites,

11:15.880 --> 11:17.520
we need to look through the menus,

11:17.520 --> 11:19.200
actually make the payment,

11:19.200 --> 11:22.800
and deal with sort of entering your address and so forth.

11:22.800 --> 11:24.920
So that was one genre of agents

11:24.920 --> 11:27.400
that already sort of existed for a long time,

11:27.400 --> 11:30.120
or I would say all genres of agents sort of existed,

11:30.120 --> 11:33.560
but that was one genre that was highlighted in the past.

11:33.560 --> 11:37.080
So you see things like Clippy is also in that genre as well.

11:37.080 --> 11:39.520
You're a Microsoft Office user,

11:39.520 --> 11:41.440
Clippy would try to automate some tasks for you

11:41.440 --> 11:44.720
based on your prior interaction with the software.

11:44.720 --> 11:49.720
Another set of agents was this idea of simulation agents,

11:50.880 --> 11:52.320
or agents that were created-

11:52.320 --> 11:54.080
To clarify on that point,

11:54.080 --> 11:57.720
those agents are single agents, correct?

11:57.720 --> 11:58.840
They can be single agents,

11:58.840 --> 12:03.400
they were often implemented as single agents, that's right.

12:03.400 --> 12:04.600
I don't think by definition

12:04.600 --> 12:06.280
they actually had to be single agents.

12:06.280 --> 12:08.600
So you'd actually try, you're now seeing,

12:08.600 --> 12:10.600
at least in the research,

12:10.600 --> 12:12.640
you're starting to see glimpse of people

12:12.640 --> 12:15.480
is trying to imagine what would it look like

12:15.480 --> 12:18.240
for these agents to be in a multi-agent setting.

12:18.240 --> 12:20.640
So research paper that I remember coming out

12:20.640 --> 12:23.920
after Generative Agents was basically,

12:23.920 --> 12:27.560
what if you have a company of agents, right?

12:27.560 --> 12:28.920
There's going to be a CEO,

12:28.920 --> 12:30.920
but there's also going to be a designer agent

12:30.920 --> 12:33.560
who works in some other aspects,

12:33.560 --> 12:36.560
there is going to be editor in this company,

12:36.560 --> 12:39.720
and those are still much within the literature

12:39.720 --> 12:42.680
of what I would call tool-based agents, right?

12:42.680 --> 12:47.360
They're trying to automate some complex tasks for the users.

12:47.360 --> 12:48.520
And I think there's going to be a lot of

12:48.520 --> 12:50.640
sort of really big opportunities in this space,

12:50.640 --> 12:52.080
that's something that people have been working on

12:52.080 --> 12:55.400
for a long time, for all the right reasons.

12:55.400 --> 13:00.400
Now, another community that has formed,

13:00.600 --> 13:04.520
but to some extent actually has a slightly different route,

13:04.520 --> 13:07.960
is agents that were created for simulations.

13:09.960 --> 13:12.920
And these agents were certainly a part of games, right?

13:12.920 --> 13:14.760
In the past we had Sims,

13:14.760 --> 13:17.440
but we also had these NPC characters

13:17.440 --> 13:19.200
that we could interact with.

13:19.200 --> 13:23.000
Now, those NPCs and agents back then were very much,

13:23.000 --> 13:26.400
it was simpler agents that were either rule-based,

13:26.400 --> 13:28.080
there were some reinforcement learning agents

13:28.080 --> 13:29.680
back then as well in that space.

13:31.040 --> 13:33.480
But another one that we could usually think about

13:33.480 --> 13:37.680
were agents that were used basically in social science,

13:37.720 --> 13:40.440
economic agents, or agents that would simulate

13:40.440 --> 13:42.760
our policy decision-making and so forth.

13:43.760 --> 13:46.960
And those agents were also a part of this literature.

13:48.040 --> 13:50.520
And what we're seeing today is,

13:50.520 --> 13:53.080
we're one recognizing that Lawrence Lynch model

13:53.080 --> 13:54.840
is simulating human behavior.

13:54.840 --> 13:56.520
So it touches on all these agents,

13:56.520 --> 13:59.800
that it can be a foundational sort of architectural layer

13:59.800 --> 14:02.240
for creating all these different sorts of agents.

14:02.240 --> 14:05.080
But in terms of our initial application spaces,

14:05.080 --> 14:06.280
we're seeing this split,

14:06.280 --> 14:07.360
where there's one community

14:07.360 --> 14:10.680
who's now deeply interested in agents using tools,

14:10.680 --> 14:13.280
but another community that is deeply interested

14:13.280 --> 14:15.800
in this idea of can we simulate?

14:15.800 --> 14:19.120
And this is where I would say like multi-agents

14:19.120 --> 14:20.600
and as well as personalization

14:20.600 --> 14:24.080
is really starting to be highlighted in the simulation space

14:24.080 --> 14:26.960
because it's a little bit more directly incorporated

14:26.960 --> 14:28.880
to the idea of simulations.

14:28.880 --> 14:30.280
Who are we simulating for?

14:30.280 --> 14:31.560
What are we simulating?

14:31.560 --> 14:33.200
Who are we simulating?

14:33.200 --> 14:35.360
And by definition, simulations often happen

14:35.440 --> 14:36.920
in this multi-agent space.

14:36.920 --> 14:40.560
So those are the two communities that you're starting to see.

14:40.560 --> 14:43.520
So generative agent certainly stands on the far end

14:43.520 --> 14:45.480
of the simulation-based agents,

14:45.480 --> 14:46.680
whereas some other projects

14:46.680 --> 14:48.520
that were also really cool last year,

14:48.520 --> 14:51.800
I think a lot of sort of open AI, GPTs, I would say,

14:51.800 --> 14:53.840
are another end of the simulation agents

14:53.840 --> 14:56.440
or another end of tool-based agents.

14:56.440 --> 14:59.760
So those are the axes that you're sort of seeing right now.

14:59.760 --> 15:00.840
And sort of end by saying,

15:00.840 --> 15:02.560
my hunch actually is again,

15:02.560 --> 15:05.760
because they all start from the same technical thesis

15:05.760 --> 15:07.720
that we can simulate human behavior,

15:07.720 --> 15:08.880
they will merge in the end.

15:08.880 --> 15:11.720
I don't think they will be completely separate thesis

15:11.720 --> 15:13.960
like five to 10 years down the line.

15:13.960 --> 15:15.680
It's more going to be the question of

15:15.680 --> 15:18.920
where are we going to make our short-term bets

15:18.920 --> 15:20.840
and what's going to be an interesting

15:20.840 --> 15:24.720
and meaningful application space in the next two to five years.

15:24.720 --> 15:26.120
So that's the field that I'm seeing

15:26.120 --> 15:28.680
and how it's developing right now.

15:28.680 --> 15:30.040
Before we maybe go into that,

15:30.040 --> 15:34.520
could you maybe describe how LLM specifically

15:34.520 --> 15:39.520
has affected the, especially the latter cohort, right?

15:39.520 --> 15:41.800
What is the before and what is the after?

15:41.800 --> 15:44.600
And what is the magnitude of improvement

15:44.600 --> 15:49.600
because of this technology that's now cheap enough to use?

15:49.600 --> 15:50.480
Right.

15:50.480 --> 15:54.480
So Lawrence-Lenge Motor is really what made this possible.

15:54.480 --> 15:58.080
That is really the fundamental fact that we needed.

15:58.080 --> 16:00.480
In the past, when you wanted to create,

16:00.480 --> 16:02.720
and this goes for both types of agents,

16:02.720 --> 16:04.520
tool-based and simulations,

16:04.520 --> 16:06.680
what you really needed was,

16:08.080 --> 16:10.080
you basically needed rule-based agents.

16:10.080 --> 16:11.520
That was the most common.

16:11.520 --> 16:14.320
And rule-based agents are sort of a more sophisticated way

16:14.320 --> 16:17.360
of saying we're scripting all the behaviors.

16:17.360 --> 16:21.280
So imagine you're building an NPC for a game.

16:21.280 --> 16:24.760
A human author would actually write every sentence

16:24.760 --> 16:27.640
that the agent would say to the user, for instance.

16:28.480 --> 16:32.960
Human author would actually describe in either code or language,

16:32.960 --> 16:34.920
if this happens, you do this.

16:34.920 --> 16:37.800
So you basically design all the possible behaviors.

16:38.880 --> 16:41.800
Now, that is expensive and not scalable, right?

16:41.800 --> 16:45.840
And that was the fundamental block that we had.

16:45.840 --> 16:48.360
Now, tool-based agents had similar issues

16:48.360 --> 16:51.720
that in many of the contexts it had to operate,

16:51.720 --> 16:53.800
it's not a very generalizable tool.

16:53.800 --> 16:56.920
So if you sort of see how clippy

16:56.920 --> 17:00.240
or even some of the agents that we're using today,

17:00.240 --> 17:01.920
very simple types of agents actually

17:01.920 --> 17:04.480
are already embedded into our daily usage.

17:04.480 --> 17:07.600
So you may have used Google spreadsheet or Google doc.

17:07.600 --> 17:11.960
It would auto-complete in some very rudimentary way

17:11.960 --> 17:13.880
that actually could be considered in some ways

17:13.880 --> 17:17.200
an agent in this direction of tool-based agents.

17:17.200 --> 17:20.280
And the rules they were using so far were very simple.

17:20.280 --> 17:21.800
It's not exactly rule-based,

17:21.800 --> 17:24.080
but it is something that was very much hard-coded

17:24.080 --> 17:25.680
into the agent's behavior.

17:25.680 --> 17:28.120
And there was some learning going on,

17:28.120 --> 17:32.640
but there were very strict or simple statistics

17:32.640 --> 17:34.200
that we were using.

17:34.200 --> 17:36.760
What large language model changes

17:36.760 --> 17:39.200
is large language model gives us a single ingredient,

17:39.200 --> 17:43.520
which is given a micro-context, micromoment,

17:43.520 --> 17:48.520
let's say I'm sitting in this room talking to Joanne

17:48.840 --> 17:51.200
and about let's say generative agents

17:51.200 --> 17:53.120
or simulations and so forth.

17:53.120 --> 17:56.320
Given that micromoment description,

17:56.320 --> 17:58.480
a language model is extremely good

17:58.480 --> 18:01.880
at predicting the next moment, right?

18:01.880 --> 18:05.240
So what are the reasonable set of things

18:05.240 --> 18:09.120
that June might say in this particular conversation

18:09.120 --> 18:10.840
given what he knows?

18:10.840 --> 18:12.240
It's very good at doing that.

18:13.840 --> 18:17.680
That on its own is not a perfect agent

18:17.680 --> 18:19.560
or it's not the complete ingredient

18:19.560 --> 18:22.080
that you need to create these agents

18:22.080 --> 18:25.400
that are meant to live for many, many years or decades.

18:25.400 --> 18:28.320
But they are the right ingredient

18:28.320 --> 18:30.000
or building block that we need it

18:30.000 --> 18:32.080
because that can be used to replace

18:32.080 --> 18:35.240
what was in the past, manual authoring.

18:36.240 --> 18:38.120
In the past, we had to manually author

18:38.120 --> 18:42.320
all the possible sequences given any micromoment,

18:42.320 --> 18:44.360
but large language model can come in.

18:45.360 --> 18:49.400
So given that ingredient, what we really could do

18:49.400 --> 18:53.160
is bake in long-term memory and some reflection module

18:53.160 --> 18:55.400
on top of it and planning module.

18:55.400 --> 18:57.840
So given the micro-ingredient

18:58.760 --> 19:02.800
plus an agent architecture that we give it on top of it,

19:02.800 --> 19:05.400
these agents can basically now start to function

19:05.400 --> 19:07.960
as something that can operate in that

19:07.960 --> 19:10.720
in a world that's much like ours

19:10.760 --> 19:14.720
with a fairly decent degree of long-term coherence.

19:14.720 --> 19:15.800
So that's where we are

19:15.800 --> 19:17.640
and that's really the difference it made.

19:17.640 --> 19:20.480
And I'd say this is sort of a zero to one difference,

19:20.480 --> 19:21.520
not a degree difference

19:21.520 --> 19:24.480
because before large language model, this was not possible.

19:25.840 --> 19:30.600
What else is, so we, large language models gave memory,

19:30.600 --> 19:34.840
gave context, gave interactions to these agents.

19:34.840 --> 19:39.240
What else in a perfect world would these agents have

19:39.240 --> 19:41.120
in order to better mimic the real world?

19:41.120 --> 19:44.040
Like what's maybe in the next stop, just out of curiosity?

19:45.160 --> 19:47.080
Right, so to clarify, large language model

19:47.080 --> 19:48.360
doesn't actually have,

19:48.360 --> 19:50.880
so large language model provides one element.

19:50.880 --> 19:53.320
It's the micro sort of a module

19:53.320 --> 19:55.440
for predicting the next sequence.

19:57.080 --> 19:58.560
It is the agent architecture

19:58.560 --> 20:02.600
that actually ends up giving the memory and planning ability,

20:02.600 --> 20:05.560
but those two pair becomes a fantastic combination.

20:06.320 --> 20:09.040
Now, going forward,

20:09.040 --> 20:12.120
what I do think is going to be interesting are,

20:12.120 --> 20:13.960
so right now we're using large language model,

20:13.960 --> 20:17.600
but we may have all noticed that things like chatGPT

20:17.600 --> 20:21.600
can now not only do it just language,

20:21.600 --> 20:24.480
but also other modality like image.

20:25.800 --> 20:29.000
I think that's going to be really interesting, right?

20:29.000 --> 20:32.160
So right now, let's say if you,

20:32.160 --> 20:34.240
and this is sort of based on my prior work

20:34.280 --> 20:35.480
called Generative Agents,

20:35.480 --> 20:37.520
and we had this game world like sim ad

20:37.520 --> 20:39.240
that we call a smallville,

20:39.240 --> 20:44.240
the way these agents perceived and operated in their world

20:44.400 --> 20:47.760
was basically by translating,

20:47.760 --> 20:49.760
and like our system translating

20:49.760 --> 20:52.440
the visual world into natural language.

20:52.440 --> 20:54.360
So we would tell the agent,

20:54.360 --> 20:56.120
you are in your apartment,

20:56.120 --> 21:00.400
or you are in the kitchen talking to someone.

21:00.400 --> 21:02.720
So we would actually take the visual world

21:03.720 --> 21:07.000
and use our system to translate the visual world

21:07.000 --> 21:08.440
into natural language,

21:08.440 --> 21:10.880
and then feeding it to the agent architecture

21:10.880 --> 21:13.760
that would use our language model to process this.

21:13.760 --> 21:17.200
But now with these models being able to deal

21:17.200 --> 21:20.360
with multi-modal aspect,

21:20.360 --> 21:23.480
we might actually be able to bypass that phase

21:23.480 --> 21:26.000
and go straight from here is the visual world

21:26.000 --> 21:28.720
or space that you're seeing right now.

21:28.720 --> 21:31.200
That is your memory, now act on it.

21:32.160 --> 21:34.760
I think that's going to be potentially very powerful

21:34.760 --> 21:39.480
because in part, image is much richer to some,

21:39.480 --> 21:40.600
it conveys a lot more.

21:40.600 --> 21:44.480
I do come from natural language processing background,

21:44.480 --> 21:48.560
at least that's my other half of my sort of academic background.

21:48.560 --> 21:51.200
So I have bias towards believing

21:51.200 --> 21:52.840
the natural language is profound,

21:52.840 --> 21:54.760
and I think that we're going to be,

21:54.760 --> 21:57.080
that will be the case going forward as well.

21:57.080 --> 21:59.000
But image does offer something

21:59.000 --> 22:01.920
that just language alone does not.

22:01.920 --> 22:04.000
So image is going to be a big thing.

22:04.000 --> 22:07.640
Now imagine the future video is going to be a big thing as well,

22:07.640 --> 22:10.680
then gradually the more these agents

22:10.680 --> 22:12.840
will basically increasingly get more powerful

22:12.840 --> 22:15.400
as this new modality gets piled on.

22:15.400 --> 22:18.320
So that's something that we should be looking forward to.

22:18.320 --> 22:19.560
That's great.

22:19.560 --> 22:21.000
What are some on the downside,

22:21.000 --> 22:22.920
what are some of the limitations

22:23.880 --> 22:27.560
that you're seeing in terms of these agents,

22:27.560 --> 22:29.080
especially generative agents?

22:30.240 --> 22:31.640
Right.

22:31.640 --> 22:36.640
So there are limitations that I can mention

22:36.640 --> 22:40.200
just about sort of in the context of our work.

22:40.200 --> 22:43.120
And then I think there are going to be interesting limitations

22:43.120 --> 22:46.280
that are much more application specific.

22:46.280 --> 22:48.520
So for generative agents today,

22:48.520 --> 22:50.960
certainly the technical limitation right now

22:50.960 --> 22:53.320
might have to do with things like,

22:53.320 --> 22:55.560
so you're using whether it's an open source.

22:55.560 --> 22:58.480
So right now we use OpenAI's model.

22:58.480 --> 23:01.120
OpenAI has actually done a lot of work

23:01.120 --> 23:03.040
to make the model safer.

23:03.040 --> 23:06.400
And I think OpenAI, I think that was the right approach

23:06.400 --> 23:08.400
in the sense that what they really wanted to create

23:08.400 --> 23:12.560
was these chatbots or agents or chatGPT

23:12.560 --> 23:16.080
that are a safe tool to use for most people.

23:17.000 --> 23:19.120
Now, if you want to run a simulation

23:19.120 --> 23:22.080
or create truly accurate and believable agents

23:22.080 --> 23:24.480
with something like chatGPT, however,

23:24.480 --> 23:26.920
that could become a limitation

23:26.920 --> 23:32.040
because what we really experience as humans

23:32.040 --> 23:34.280
is we fight, we sometimes have conflicts,

23:34.280 --> 23:36.320
we disagree with each other.

23:36.320 --> 23:38.320
And that might not be something that's something

23:38.320 --> 23:40.640
like chatGPT that's been fine-tuned

23:40.640 --> 23:43.280
to not behave that way to remain safe.

23:43.280 --> 23:45.160
It's something, it might not be something

23:45.160 --> 23:47.760
that these models would try to surface.

23:47.760 --> 23:51.800
And that could be a potential block

23:51.800 --> 23:55.600
in creating more accurate, more believable simulations

23:55.600 --> 23:57.760
or agents for that matter.

23:57.760 --> 23:59.880
So that's something that is one limitation

23:59.880 --> 24:01.360
right now that we're seeing.

24:02.880 --> 24:06.040
An interesting way to tackle this, I think, going forward

24:06.040 --> 24:08.840
is to use open source models or other models

24:08.840 --> 24:11.520
that have less of these fine-tuned nature.

24:13.240 --> 24:15.360
But it's going to be highly dependent

24:15.360 --> 24:17.600
on the models that we'll be using for this.

24:17.600 --> 24:20.480
So I think that's one thing to look forward to.

24:20.480 --> 24:24.120
Got it, got it, that's super helpful.

24:24.120 --> 24:27.480
And maybe one last question on the research side.

24:28.720 --> 24:31.120
When you think about future areas to explore

24:31.120 --> 24:35.320
for you specifically, what are some of the

24:38.160 --> 24:42.360
more narrow topics that you're hoping to dive deeper in?

24:43.440 --> 24:44.320
Given the world.

24:45.320 --> 24:50.160
So ultimately, I think making the agents more accurate

24:52.040 --> 24:55.320
for these agents to be more accurate reflection of who we are,

24:55.320 --> 24:57.640
I think it's going to be a really interesting research

24:57.640 --> 25:01.760
and I think it's going to, that's going to be an area

25:01.760 --> 25:04.600
that's going to have more of a research and broader impact.

25:05.960 --> 25:10.400
So right now, you may have seen the sort of simulation demo,

25:10.640 --> 25:14.640
the agents that live in that simulation are fictional,

25:14.640 --> 25:18.560
that we just, for instance, we have an agent named Isabella,

25:18.560 --> 25:21.480
we told Isabella that she is a cafe owner

25:21.480 --> 25:24.680
and large language model basically makes up

25:24.680 --> 25:29.320
what a persona that is reasonable given that description.

25:29.320 --> 25:31.720
But I think it's going to be far more interesting

25:31.720 --> 25:36.280
if we can make these simulations actually closely model

25:36.280 --> 25:38.840
our actual human communities.

25:38.840 --> 25:41.960
So it's not just fictional, but actually has groundings.

25:41.960 --> 25:44.640
That's going to open up from our perspective

25:44.640 --> 25:47.560
an entirely new set of application spaces

25:47.560 --> 25:49.120
as well as research impact.

25:50.320 --> 25:51.800
This can be used, for instance,

25:51.800 --> 25:54.760
to actually model or predict markets

25:54.760 --> 25:59.760
or it's going to be able to use two more closely personalized

26:00.200 --> 26:03.120
many of these agents for individual use cases.

26:03.120 --> 26:04.600
So that's something that we're looking forward to

26:04.600 --> 26:06.120
in terms of sort of a particular topic

26:06.120 --> 26:08.240
that we're diving into.

26:08.240 --> 26:10.320
That plug, of course, scaling up the agents.

26:10.320 --> 26:13.160
I think that's another big one, but those two.

26:13.160 --> 26:14.480
That makes sense.

26:14.480 --> 26:16.480
Now, one of the things that's missing

26:16.480 --> 26:21.480
in most AI technologies is like really the

26:22.440 --> 26:25.520
emotional part of how humans feel, right?

26:25.520 --> 26:29.240
Like all of that data is largely not captured

26:29.240 --> 26:32.640
and therefore not part of any kind of models today.

26:33.560 --> 26:36.720
Language is one small output of what we have.

26:36.720 --> 26:39.840
It's a very important output for sure,

26:39.840 --> 26:41.040
but it's still one small output.

26:41.040 --> 26:44.720
So I wonder how we might be able to incorporate

26:44.720 --> 26:47.220
some of the data around our emotions.

26:48.280 --> 26:49.200
I agree.

26:49.200 --> 26:50.580
Some thoughts in the future.

26:52.200 --> 26:54.720
Maybe let's move on to the applications today

26:54.720 --> 26:58.140
since you talked about some of the challenges for agents.

26:59.120 --> 27:02.480
Many organizations are thinking about

27:02.480 --> 27:04.200
how to use large language models today, right?

27:04.200 --> 27:06.960
There's a huge amount of aspirations.

27:06.960 --> 27:09.520
A subset of them are also thinking about

27:09.520 --> 27:12.360
what are some of the agent technology applications

27:12.360 --> 27:15.880
that are viable within an enterprise,

27:15.880 --> 27:18.520
which has limitations around infrastructure,

27:18.520 --> 27:22.240
around data silos, security, and all that stuff.

27:23.200 --> 27:25.640
Any particular areas where you've seen

27:26.920 --> 27:29.880
companies be successful at using these technologies

27:29.880 --> 27:30.860
in production?

27:31.800 --> 27:32.960
Right.

27:32.960 --> 27:34.560
So I think this is going to be incredibly

27:34.560 --> 27:38.360
like case-by-case answer.

27:38.360 --> 27:40.440
So let me think.

27:42.320 --> 27:45.040
Or if not, like any hypothesis as to

27:46.240 --> 27:48.600
where you might see the first

27:48.600 --> 27:50.680
commercial deployments at scale.

27:51.720 --> 27:52.560
Right.

27:55.240 --> 27:59.080
So there is something that I have.

27:59.080 --> 28:01.600
This is, there's a message that I have

28:01.600 --> 28:04.320
in trying to communicate, I think, in different settings.

28:04.320 --> 28:06.440
So this is not something I'm sort of

28:06.440 --> 28:07.840
conveying for the first time.

28:08.960 --> 28:12.280
And my opinion has been getting updated,

28:12.280 --> 28:14.400
but I think fundamentally I think this is right.

28:14.400 --> 28:17.040
So the way I've been describing it is

28:17.040 --> 28:22.040
in human computer interaction or in most task settings,

28:22.640 --> 28:24.200
there are two types of problems

28:24.200 --> 28:27.140
that we deploy our machines or agents in.

28:27.140 --> 28:30.480
One has very hard-edge problem spaces.

28:30.520 --> 28:33.000
These are things like, hey, order me pizza

28:33.000 --> 28:34.720
or buy me a plane ticket.

28:34.720 --> 28:38.360
These are tasks where there's a very concrete outcome

28:38.360 --> 28:41.160
and there often is a right or wrong answer

28:41.160 --> 28:43.640
that the agent has to achieve.

28:43.640 --> 28:45.680
At least from the user's perspective,

28:45.680 --> 28:48.960
there is something that would absolutely be yes or no.

28:50.240 --> 28:51.880
And then there are problem spaces

28:51.880 --> 28:54.800
where we have soft-edge problems.

28:54.800 --> 28:57.840
These are problems where we can increasingly

28:57.840 --> 29:00.520
co-climb towards sort of being better,

29:00.520 --> 29:03.800
but at certain level it starts to actually become useful.

29:03.800 --> 29:05.760
So to make this intuition a little bit,

29:05.760 --> 29:08.080
to make this a little bit more intuitive here,

29:08.080 --> 29:11.680
for instance, if I guess the worst possible case scenario

29:11.680 --> 29:13.920
is I asked the agent to buy me a plane ticket

29:13.920 --> 29:15.880
and it bought me the wrong ticket

29:15.880 --> 29:17.760
that just goes to a different place,

29:17.760 --> 29:19.600
then that's like a heavy no.

29:21.200 --> 29:25.280
Whereas let's say I asked the agent to sort of

29:26.280 --> 29:29.080
simulate a behavior that is sort of fun

29:29.080 --> 29:30.600
so that when I'm in a game,

29:30.600 --> 29:33.080
this is sort of entertaining and interesting.

29:33.080 --> 29:35.080
That might be something that the agent

29:35.080 --> 29:36.720
doesn't need to be quite perfect in,

29:36.720 --> 29:39.120
but it can still get there quite quickly.

29:39.120 --> 29:41.240
And then we can gradually improve.

29:41.240 --> 29:45.000
Those two are the spaces that we can sort of,

29:45.000 --> 29:47.520
in terms of when we consider where to deploy

29:47.520 --> 29:50.080
or how these will actually make its first impact,

29:50.080 --> 29:53.080
we might actually be looking at those problem spaces first.

29:53.080 --> 29:55.240
And these are the classes that I'm seeing.

29:55.240 --> 29:57.240
If I were to make my bet,

29:57.240 --> 30:00.200
agents will likely succeed first

30:00.200 --> 30:02.800
in the soft-edge problem spaces

30:02.800 --> 30:05.400
and will gradually inch into making it work

30:05.400 --> 30:07.480
in the hardest problem space.

30:07.480 --> 30:09.560
This has been sort of an intuition

30:09.560 --> 30:13.040
with agent research community for some time.

30:13.040 --> 30:15.440
So when Clippy, for instance, failed.

30:16.520 --> 30:19.680
Our intuition there, at least from research perspective,

30:19.680 --> 30:22.120
wasn't that these agents failed

30:22.120 --> 30:25.080
because we didn't have the technology there.

30:25.080 --> 30:26.320
Certainly these were deployed

30:26.320 --> 30:28.840
and there were some confidence around the technology.

30:28.840 --> 30:32.400
But the problem there actually was with interaction,

30:32.400 --> 30:36.520
that when agents are deployed in hard-edge problem spaces,

30:36.520 --> 30:39.040
it's often deployed in states where

30:39.960 --> 30:43.280
it actually has to have a fairly long chain of steps

30:43.280 --> 30:47.200
and fairly high, the risk were fairly high.

30:47.200 --> 30:49.920
When it fails, the cost of correcting its error

30:49.920 --> 30:50.840
is actually quite high,

30:50.840 --> 30:53.440
cost of auditing its error is actually quite high.

30:54.440 --> 30:56.040
So when these agents are deployed

30:56.040 --> 30:57.680
in hardest problem spaces,

30:57.680 --> 30:59.160
it has to reckon with the fact

30:59.160 --> 31:02.280
that it will undoubtedly make mistakes.

31:02.280 --> 31:04.000
And when it does make a mistake,

31:04.000 --> 31:05.920
it has to be increasingly auditable

31:05.920 --> 31:08.520
and controllable by the users

31:08.520 --> 31:11.600
so that the cost of correcting its error

31:11.600 --> 31:15.160
is not high enough that from the user's perspective,

31:15.160 --> 31:18.960
the cost-benefit analysis basically has to make sense.

31:18.960 --> 31:22.120
And that's been a fundamental challenge with agents.

31:22.240 --> 31:24.560
That's why in every era,

31:24.560 --> 31:28.240
we see the interest around agents spike for a while

31:28.240 --> 31:29.600
and then it quickly subsides

31:29.600 --> 31:32.320
after like maybe a half a year or two a year.

31:32.320 --> 31:35.440
Now there's a real issue now though,

31:35.440 --> 31:37.720
that given the large language model in the progress we saw

31:37.720 --> 31:39.720
that this might not be the case this time

31:39.720 --> 31:42.560
or at some point we might be able to make this work.

31:42.560 --> 31:46.240
But for now, so I'm closely monitoring this

31:46.240 --> 31:47.920
as well and I think we all should.

31:47.920 --> 31:49.400
I don't think we should just go and say,

31:49.400 --> 31:50.560
because it didn't work before,

31:50.560 --> 31:52.680
it's not going to work this time.

31:52.680 --> 31:57.360
But my hunch is that we will likely see

31:57.360 --> 31:59.640
very similar pattern arise,

31:59.640 --> 32:01.800
at least for the first of the future.

32:01.800 --> 32:05.000
And we haven't quite dealt with the interaction problems

32:05.000 --> 32:07.160
with those types of agents.

32:07.160 --> 32:10.280
So I think it's much safer to assume

32:10.280 --> 32:12.840
that it is going to be in the soft edge problems basis.

32:12.840 --> 32:15.920
And that's why in some areas, in many of the aspects,

32:15.920 --> 32:18.040
that's why our team was also interested

32:18.040 --> 32:19.640
in this idea of simulation.

32:19.640 --> 32:22.800
Because simulation is sort of the prime example

32:22.800 --> 32:24.800
of soft edge problem spaces,

32:24.800 --> 32:27.000
where the simulation has to be good enough

32:27.000 --> 32:29.040
for it to start being useful.

32:29.040 --> 32:32.480
That's also why I think a lot of really early promising AI

32:32.480 --> 32:35.360
startups that's going to go in the agent space

32:35.360 --> 32:39.080
are places that does NPCs for games.

32:39.080 --> 32:42.080
Because those are very safe soft edge problem spaces

32:42.080 --> 32:44.360
where the agents can fail, but that's okay.

32:45.320 --> 32:47.620
And gradually we'll sort of go to the other area as well.

32:47.620 --> 32:50.260
But I think that's where the impact is going to start

32:50.260 --> 32:51.660
in the next couple of years.

32:53.100 --> 32:58.100
I also think just seeing the startups in this space,

32:58.740 --> 33:03.740
in sectors and functions that allow for failure,

33:04.380 --> 33:08.420
like you said, include things like marketing.

33:09.260 --> 33:12.500
Where if you market incorrectly,

33:12.500 --> 33:14.780
it's not that big of a deal.

33:14.780 --> 33:19.260
If you write the wrong code,

33:19.260 --> 33:21.580
that's probably going to be a bigger deal.

33:21.580 --> 33:26.300
If you pick the wrong security features, that's a huge deal.

33:26.300 --> 33:28.260
If you pick the wrong things for healthcare,

33:28.260 --> 33:29.900
that's an even bigger deal.

33:29.900 --> 33:33.900
So there are degrees of fault tolerance

33:33.900 --> 33:35.940
within the enterprise.

33:35.940 --> 33:36.940
That's one thing.

33:36.940 --> 33:39.460
And the second on the consumer side,

33:39.460 --> 33:43.340
especially if the agents are just assisting consumers

33:43.340 --> 33:46.400
by not executing on anything.

33:47.660 --> 33:49.460
That could probably also work.

33:49.460 --> 33:52.140
For example, there's a company called Rewind,

33:52.140 --> 33:55.740
which is using some of the agent technologies, I believe.

33:55.740 --> 33:58.780
And they're getting a bunch of consumer demand,

33:58.780 --> 34:02.980
but what consumers are doing is just searching

34:02.980 --> 34:06.160
for a behavior that they have had before.

34:07.380 --> 34:11.420
And this product is helping them do that

34:11.460 --> 34:15.780
versus do anything real world, really.

34:15.780 --> 34:16.620
Interesting.

34:18.260 --> 34:19.420
But that's super.

34:19.420 --> 34:23.660
The way that you frame it is very useful.

34:24.500 --> 34:29.060
What about just from an architecture standpoint,

34:29.060 --> 34:33.740
large language models enabled by transformer architectures?

34:34.740 --> 34:36.740
This is a whole different direction.

34:36.740 --> 34:39.540
We're already seeing companies that are saying,

34:39.540 --> 34:42.180
hey, transformers are not the most efficient.

34:43.300 --> 34:44.900
Inference costs are very high.

34:46.020 --> 34:48.540
Let's look at the next thing.

34:48.540 --> 34:51.660
Have you spent much time thinking about that?

34:51.660 --> 34:55.260
And if so, any impact to the work that you're doing?

34:56.460 --> 34:57.300
Right.

34:57.300 --> 35:01.220
So certainly a next sort of model

35:01.220 --> 35:02.580
that we're going to be banking on,

35:02.580 --> 35:05.180
I think that always is an important topic.

35:05.180 --> 35:07.500
And that's something that I think we as a community

35:07.500 --> 35:09.100
always has to sort of monitor,

35:09.100 --> 35:10.700
because I think you're right,

35:10.700 --> 35:13.140
that transformer is not going to be the end model

35:13.140 --> 35:16.380
that will be hopefully, I mean, not on what.

35:16.380 --> 35:18.620
The hope here is that we wouldn't be using transformer

35:18.620 --> 35:19.700
10 years down the line.

35:21.180 --> 35:24.500
But one way that we do view this is,

35:24.500 --> 35:27.220
this is very much like a programmer's way

35:27.220 --> 35:28.060
of looking at this.

35:28.060 --> 35:30.380
We view this in abstractions, right?

35:30.380 --> 35:33.500
So what transformer has gotten us right now

35:33.500 --> 35:36.300
is this amazing capacity for reasoning

35:36.300 --> 35:39.540
and processing information and generating information.

35:40.380 --> 35:43.620
So it might be the case that in the future,

35:43.620 --> 35:46.580
that task will be done by even better models.

35:46.580 --> 35:48.940
And hopefully that's going to be the case.

35:48.940 --> 35:51.820
But for the sake of building applications,

35:51.820 --> 35:53.780
it is true that we can sort of view this

35:53.780 --> 35:55.620
as a layer of abstraction.

35:55.620 --> 35:57.820
That there might be some other technology

35:57.820 --> 36:00.620
that's going to be powering it in the future,

36:00.620 --> 36:02.140
but really what we're focusing on

36:02.140 --> 36:04.820
is the capacity and the modality.

36:04.820 --> 36:07.700
What kind of reasoning, using what modality,

36:07.700 --> 36:10.300
can these technologies that exist today do?

36:10.300 --> 36:12.460
And we're going to be building on top of it.

36:12.460 --> 36:16.100
So I think that's sort of our way of looking at it

36:16.100 --> 36:20.780
in sort of a medium term, again, the next three to five years.

36:20.780 --> 36:23.700
Now, if you're looking, because right now,

36:23.700 --> 36:25.540
there are some promising architectures

36:25.540 --> 36:29.620
that's sort of been created at the forefront of,

36:29.620 --> 36:31.340
I would say more in the machine learning

36:31.340 --> 36:33.660
and natural language processing communities

36:33.660 --> 36:37.580
that I'm personally getting a little bit excited about.

36:37.580 --> 36:40.340
But at the moment, those are still

36:40.340 --> 36:43.300
in the very much in the research phase.

36:43.300 --> 36:45.820
And can you share some examples of that?

36:45.820 --> 36:48.860
Yeah, so I think there's one model that recently came out,

36:48.860 --> 36:50.940
like Mamba by some folks.

36:50.940 --> 36:53.260
Those are from Stanford folks.

36:53.260 --> 36:57.020
So I think the authors now at CMU and Princeton

36:57.020 --> 36:59.900
sort of all within sort of this community.

36:59.900 --> 37:02.260
So that's one example of sort of a potentially promising

37:02.260 --> 37:03.180
or interesting model.

37:03.180 --> 37:04.940
And that's the one that I recently heard about

37:04.940 --> 37:08.940
that I think is interesting to be looking at.

37:08.940 --> 37:12.860
But these models, for them to be deployed at scale

37:12.860 --> 37:17.100
in a commercial way, if we decide to basically go

37:17.100 --> 37:19.820
with certain model that's getting created today,

37:19.820 --> 37:24.740
it will give us maybe two to five year timeline

37:24.740 --> 37:26.580
before they can really take off.

37:26.580 --> 37:32.660
Because Transformer is not, it is a relatively modern model,

37:32.660 --> 37:35.300
but it really is how you look at sort of the timeline.

37:35.300 --> 37:36.100
There's Transformer.

37:36.100 --> 37:37.220
Seven-ish years?

37:37.220 --> 37:39.140
Seven-ish years.

37:39.140 --> 37:42.020
So I think hopefully if we find something like this time,

37:42.020 --> 37:43.500
maybe it's going to go much faster.

37:43.500 --> 37:46.500
But it still took about seven-ish years for Chatchapiti

37:46.500 --> 37:47.740
to really come out.

37:47.740 --> 37:49.580
So it's not immediate.

37:49.580 --> 37:51.700
Whereas a lot of interactions that we can build,

37:51.700 --> 37:53.780
I think there's a lot that we can do like today

37:53.780 --> 37:55.940
to create really cool experiences.

37:55.940 --> 37:57.500
So I think that's how we're looking at this.

37:57.500 --> 37:58.780
There is a medium term.

37:58.780 --> 38:01.620
This is where we are focused on the level of extraction,

38:01.620 --> 38:04.020
that this is the capacity that we'll have.

38:04.020 --> 38:07.100
And then maybe in the down the line five to 10 year term,

38:07.100 --> 38:09.420
we can really be looking forward to some new models that's

38:09.420 --> 38:11.500
going to make an impact.

38:11.500 --> 38:12.020
That's great.

38:12.020 --> 38:13.980
That's great.

38:13.980 --> 38:14.460
Cool.

38:14.460 --> 38:16.140
Very cool.

38:16.140 --> 38:20.980
Maybe more generally, if you just zoom out for a moment,

38:20.980 --> 38:24.700
when you look at the ecosystem today,

38:24.700 --> 38:27.180
what are some of the problems that you want to see solve?

38:27.180 --> 38:28.860
We talked about multimodal a little bit.

38:28.860 --> 38:33.020
We talked about new models right after Transformers

38:33.020 --> 38:34.060
that might come out.

38:34.060 --> 38:37.420
What are some of the problems that you are most excited

38:37.420 --> 38:39.260
about someone solving?

38:39.260 --> 38:43.540
Not necessarily you personally, but someone solving.

38:43.540 --> 38:46.100
I sort of have two in mind.

38:46.100 --> 38:50.380
And it's a little bit less of a, this is a specific problem

38:50.380 --> 38:52.180
that I want to solve.

38:52.180 --> 38:54.980
But it's more sort of questions that I have

38:54.980 --> 38:58.740
that I think more of us should be thinking about.

38:58.740 --> 39:02.020
And to some extent, and this happens a lot with sort of the way

39:02.020 --> 39:04.900
I do my research as well, where I get

39:04.900 --> 39:08.820
inspired by big problems or foundational problems

39:08.820 --> 39:11.380
that we had in previous decades.

39:11.380 --> 39:14.020
Because oftentimes, there's a lot of insights

39:14.020 --> 39:18.700
that we can learn from the past as we build on the future.

39:18.700 --> 39:25.180
One, certainly I'm embedded into this agent space.

39:25.180 --> 39:31.540
One is, in the past, agents had its hype cycles, basically.

39:31.540 --> 39:34.260
But it failed.

39:34.260 --> 39:36.780
That the hype cycle lasted for a couple of years,

39:36.780 --> 39:39.100
and then people very quickly lost interest.

39:39.100 --> 39:41.340
Basically because it didn't quite deliver

39:41.340 --> 39:44.860
on the promises that it had.

39:44.860 --> 39:49.540
I think it's worth asking ourselves why that was the case.

39:49.540 --> 39:52.820
I think the opportunity this time is real.

39:52.820 --> 39:54.820
But I also think the opportunity in the past

39:54.860 --> 39:57.900
was also real to some aspect as well.

39:57.900 --> 40:00.100
So just because the opportunity is real

40:00.100 --> 40:02.340
and language model is really cool doesn't necessarily

40:02.340 --> 40:04.500
guarantee us, at least from my perspective,

40:04.500 --> 40:06.820
that we're going to, that agent will finally

40:06.820 --> 40:10.140
be a thing that everyone will use.

40:10.140 --> 40:13.580
I think there is a future where that will happen at some point.

40:13.580 --> 40:16.180
I think it might even happen this cycle.

40:16.180 --> 40:19.940
But I think it's really worth asking, as a community,

40:19.940 --> 40:23.220
why did it fail in the past so that we don't repeat those mistakes?

40:23.220 --> 40:25.660
One sort of main thing I'm sort of curious about

40:25.660 --> 40:27.980
that I don't think a lot of us are thinking about

40:27.980 --> 40:32.300
is actually not the technology part, but the interaction.

40:32.300 --> 40:36.020
How are these agents going to be used in what way?

40:36.020 --> 40:38.900
Because ultimately that's where it really delivers value

40:38.900 --> 40:40.660
to the end users.

40:40.660 --> 40:43.940
And that's where agents in the past have failed.

40:43.940 --> 40:45.300
That it was really cool technology,

40:45.300 --> 40:47.660
but we didn't seriously ask ourselves,

40:47.660 --> 40:49.620
is this something that people really need?

40:49.620 --> 40:51.580
And does the cost-benefit analysis

40:51.580 --> 40:54.620
of using these agents and learning how to use them well

40:54.620 --> 40:57.620
really make sense for the broader user base?

40:57.620 --> 40:59.340
So that's one.

40:59.340 --> 41:04.500
And other one is sort of my, it's a little bit of a hot take,

41:04.500 --> 41:06.380
but it's also a shorter take, which

41:06.380 --> 41:08.300
is we have large language models,

41:08.300 --> 41:12.020
and I think these have made a huge impact already.

41:12.020 --> 41:16.260
The number of users who use chat.gbt, that's incredible.

41:16.260 --> 41:19.940
But I think it's sort of worth asking ourselves,

41:19.940 --> 41:23.060
is that sort of quote unquote the killer applications

41:23.060 --> 41:25.140
that we were waiting for?

41:25.140 --> 41:29.980
Because in many ways, chat.gbt, or maybe it is.

41:29.980 --> 41:34.140
And I think if it is, I think somebody should articulate this.

41:34.140 --> 41:37.980
But chat.gbt does feel like a fairly simple wrapper

41:37.980 --> 41:41.020
around our language model, because that's what it is.

41:41.020 --> 41:44.700
And OpenAI has done fantastic things to make it safer

41:44.700 --> 41:46.700
and make it more useful by tuning, I think,

41:46.700 --> 41:48.140
what's really great.

41:48.180 --> 41:50.780
But I think it's worth asking, if that is actually

41:50.780 --> 41:55.020
the killer application, why is it a killer application?

41:55.020 --> 41:56.500
And the answer might actually come out

41:56.500 --> 41:59.540
that maybe it actually isn't the killer application

41:59.540 --> 42:02.780
that we were waiting for, in which case, what

42:02.780 --> 42:04.740
is going to be the killer application?

42:04.740 --> 42:07.140
That's really going to add value in a much more

42:07.140 --> 42:10.340
generalizable way.

42:10.340 --> 42:12.820
That's a very abstract question.

42:12.820 --> 42:14.900
For now, it's for me, it's just a hunch

42:14.900 --> 42:17.860
that I think there's something to be asked about there.

42:17.900 --> 42:20.140
And if I'm wrong, I would also love to hear again

42:20.140 --> 42:23.580
somebody really say, we already have this killer application,

42:23.580 --> 42:26.820
maybe it's co-pilot, chat.gbt, and here's why.

42:26.820 --> 42:31.820
But for now, this is a question that I'm still asking myself.

42:31.820 --> 42:33.060
That makes sense.

42:33.060 --> 42:35.060
And thank you for sharing that.

42:35.060 --> 42:40.660
What are some of your favorite AI apps today that you use?

42:40.660 --> 42:41.900
I love chat.gbt.

42:41.900 --> 42:43.300
I use it every day.

42:43.300 --> 42:46.700
Chat.gbt did make a difference in my workflow.

42:47.580 --> 42:51.220
So as a researcher, one of the main things I do

42:51.220 --> 42:54.220
is I program every day, or at least most days,

42:54.220 --> 42:56.340
or I write or write papers.

42:56.340 --> 42:58.300
So I do one of those two things.

42:58.300 --> 43:00.740
Chat.gbt is fantastic at both.

43:00.740 --> 43:05.580
So as all programmers sort of know,

43:05.580 --> 43:07.180
we sometimes don't bother remembering

43:07.180 --> 43:10.860
all the different functions or documentation.

43:10.860 --> 43:12.820
It's very good at generating a lot of the code

43:12.820 --> 43:14.500
when I have an idea.

43:14.500 --> 43:16.060
Really impressive.

43:16.060 --> 43:17.780
It's also quite a good editor.

43:17.780 --> 43:21.460
So if I make grammar error in my sort of sentences,

43:21.460 --> 43:24.140
chat.gbt will usually catch them for me.

43:24.140 --> 43:27.140
It's simple and easy thing, but it's good enough now

43:27.140 --> 43:30.980
that it's actually making a difference in the workflow.

43:30.980 --> 43:34.300
So as a chat.gbt, for sure, by extension, I think co-pilot

43:34.300 --> 43:36.980
will make a difference.

43:36.980 --> 43:38.860
So it's sort of worth asking, maybe going back

43:38.860 --> 43:41.180
to the question around killer application.

43:41.180 --> 43:43.180
What is the definition of killer application?

43:43.180 --> 43:45.780
I think it does some people define it

43:45.780 --> 43:48.340
as application that has more users.

43:48.340 --> 43:50.700
And the fact of that, I think, always has to be the case,

43:50.700 --> 43:52.940
that no killer application has no user.

43:52.940 --> 43:56.180
Killer application, by default, means the application

43:56.180 --> 43:59.740
that will have the most number of users.

43:59.740 --> 44:02.460
But I think there is more theoretical definition

44:02.460 --> 44:04.780
to what a killer application is.

44:04.780 --> 44:07.980
That implies a lot of users who are the most number of users.

44:07.980 --> 44:12.100
But for instance, if we look back to the prior era of PC,

44:12.100 --> 44:13.780
my killer application that I mentioned

44:13.780 --> 44:18.060
was something like Microsoft's Excel or this tabular data

44:18.060 --> 44:21.580
format, the thing that would let us manipulate the tabular

44:21.580 --> 44:22.900
data.

44:22.900 --> 44:25.740
So really, the definition, in a more theoretical sense

44:25.740 --> 44:27.820
of killer application here, is there

44:27.820 --> 44:30.140
is new technology stack that is being developed.

44:30.140 --> 44:33.060
There is a new file type that is getting generated.

44:33.060 --> 44:36.460
Then the killer application is the one that would let us

44:36.460 --> 44:39.100
manipulate the file application, file type.

44:39.100 --> 44:40.700
That's one theoretical definition

44:40.700 --> 44:43.020
that one could give, at least that's

44:43.020 --> 44:44.980
sort of the definition that I've been towing with.

44:44.980 --> 44:46.380
I think it's an interesting one.

44:46.380 --> 44:47.900
I don't think it's the only one.

44:47.900 --> 44:50.700
But those are sort of ways that I'm looking at this.

44:50.700 --> 44:52.060
That makes a lot of sense.

44:52.060 --> 44:54.620
I also use chatGPT every single day.

44:54.620 --> 44:56.580
It's been very helpful.

44:56.580 --> 44:59.500
Everything from coming up with menu names

44:59.500 --> 45:05.740
to rewriting emails that don't sound as nice.

45:05.740 --> 45:09.660
And I've tried a little bit to give it files and images.

45:09.660 --> 45:12.460
So I actually helped my mother create a background.

45:12.460 --> 45:14.260
She's a dancer, so she was performing

45:14.260 --> 45:16.380
on one of the very specific background for her dance.

45:16.380 --> 45:19.140
And I created that for her using chatGPT.

45:19.140 --> 45:21.420
So all sorts of utility there.

45:21.420 --> 45:24.220
But I love the way that you framed

45:24.220 --> 45:26.140
the last potential application.

45:26.140 --> 45:29.140
Maybe just one last question from my end.

45:29.140 --> 45:39.300
Any resources or books that you love that is on this topic?

45:40.300 --> 45:41.300
Right.

45:45.300 --> 45:48.580
I do think, and this is often the case

45:48.580 --> 45:51.100
with many of the cutting edge spaces.

45:51.100 --> 45:53.340
I think a lot of the papers that are coming out

45:53.340 --> 45:55.140
that are gaining a lot of attention,

45:55.140 --> 45:56.740
I think those are sort of worth checking out

45:56.740 --> 45:57.940
as sort of the resources.

45:57.940 --> 46:01.540
It's not exactly like here's one book that we can all look at.

46:01.540 --> 46:04.940
But things are moving fast enough that I think

46:04.940 --> 46:07.140
those are sort of interesting resources

46:07.140 --> 46:09.740
or just things that are getting created today

46:09.740 --> 46:11.540
and their documentations.

46:11.540 --> 46:15.140
So those are sort of mentioned as sort of a generic answer.

46:15.140 --> 46:18.540
I do think, I think this has been a sort of running thing

46:18.540 --> 46:20.540
in some of the things I mentioned today,

46:20.540 --> 46:28.540
I get inspired by insights that basically had an impact

46:28.540 --> 46:31.140
that stood the test of time.

46:31.140 --> 46:33.540
And the reason why that is the case

46:33.540 --> 46:36.540
is because I personally think all the great ideas

46:36.540 --> 46:38.540
are sort of timeless.

46:38.540 --> 46:41.540
It's because current time cycle is over,

46:41.540 --> 46:43.540
it doesn't mean they're less interesting or less meaningful.

46:43.540 --> 46:44.540
For sure.

46:44.540 --> 46:48.540
That foundational ideas that will continue to have impact.

46:48.540 --> 46:50.540
So when I look for resources,

46:50.540 --> 46:55.540
I actually look back to books from truly the prior generations.

46:55.540 --> 46:58.540
So some of the works that I often go back to

46:58.540 --> 47:01.540
are works by Herbert Simon, Alan G.

47:01.540 --> 47:04.540
Those are founders of AI and many of these fields

47:04.540 --> 47:06.540
who would later go into a turning award

47:06.540 --> 47:08.540
and Nobel Prize and so forth.

47:08.540 --> 47:11.540
And those works, early cognitive psychologists

47:11.540 --> 47:16.540
and scientists inspired my work a lot and their textbook.

47:16.540 --> 47:18.540
Those people actually have written books

47:18.540 --> 47:20.540
because they were much more established

47:20.540 --> 47:22.540
than sort of the cutting edge spaces today.

47:22.540 --> 47:26.540
So I go back to those as sort of my personal resources

47:26.540 --> 47:28.540
for getting ideas.

47:28.540 --> 47:29.540
That's great.

47:29.540 --> 47:30.540
Thank you so much.

47:30.540 --> 47:32.540
This was super, super helpful to me personally

47:32.540 --> 47:34.540
because what we do as investors

47:34.540 --> 47:39.540
is we try to understand the impacts of technology

47:39.540 --> 47:44.540
and start to invest in companies when it becomes,

47:44.540 --> 47:47.540
at the beginning of when it becomes commercially viable.

47:47.540 --> 47:50.540
So to your point around what are the problem spaces,

47:50.540 --> 47:53.540
what are the applications in which this can be applied

47:53.540 --> 47:56.540
in a cost-effective and secure way

47:56.540 --> 48:01.540
that where the end user is willing to interact

48:01.540 --> 48:03.540
and get value,

48:03.540 --> 48:07.540
that's when we start to come in and invest in these companies

48:07.540 --> 48:11.540
which will hopefully be much bigger companies in the future.

48:11.540 --> 48:13.540
So really appreciate this chat.

48:13.540 --> 48:15.540
Yeah, it was fun.

