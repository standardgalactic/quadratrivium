{"text": " The number of users who use ChatGPT, that's incredible. But I think it's sort of worth asking ourselves, is that sort of quote unquote the killer applications that we were waiting for? ChatGPT does feel like a fairly simple wrapper around our sling model, because that's what it is. OpenAI has done fantastic things to make it safer and make it more useful by tuning, I think, what's really great. But I think it's worth asking if that is actually the killer application, why is it a killer application? And the answer might actually come out that maybe it actually isn't the killer application that we were waiting for, in which case, what is going to be the killer application? That's really going to add value in a much more generalizable way. Welcome to AI in the real world. I'm your host. My name is Joanne Chen, and I am a general partner at Foundation Capital. I work closely with startups that are reshaping business with AI. In this series, I'll be holding in-depth discussions with leading AI researchers. We'll explore how state-of-the-art AI models are being applied in real enterprises today. To kick things off, I'm excited to speak with June Zempark, a PhD student in computer science at Stanford. June works at the intersection of human-computer interaction and natural language processing. He is best known for his research on AI agents. We break down how AI is transforming agent design, share advice for builders working with these models, and unpack why we haven't yet found the perfect killer app for AI agents. Here's our conversation. How are you? Good, what about you? Great seeing you again. Good to see you again. It's been a while. Because the on-conference was last, I want to say, June. June? May or June? Yeah. Last June, May or June. Wow, time-wise. And the world has changed. I think that agents have finally made its way into real enterprises with real use cases. And it was not, back then, it was a lot of, like, what could this be, right? Thanks to you as some of your work, which is why I'm super excited to have this conversation together. Especially right now, since enterprises are sinking in a real way to adopt. So I thought, who can we chat with that would have a really interesting perspective? And that's why we reached out back to you. So I really appreciate the time. Of course. Thanks for having me. Do you mind maybe just to start giving us a quick rundown of what's happened, maybe some of the background that you have building this technology? Yeah. So let's see. So do you want me to just sort of speak about sort of what has happened in the past six months, or sort of what would be interesting for you? Just a brief overview of what you worked on and also what's happened in the last six months to a year in terms of evolution. Yeah. All right, that sounds good. Right. So I guess I'll do a quick intro. So I'm sort of, I'm a PhD student here, sort of working in the area of HCI and NLP. So as you know, sort of the work that we've done, I think the one that I'm sort of mainly known for is this paper called Generative Agents. And Generative Agents in particular was a project that I tried to ask, can we use our language models to create general agents that can populate a simulation world? Right? So if you play something like SimCity or Sims, can we actually create these NPC-like characters that would actually flood into the city and actually live like humans? And by definition, it is sort of everything from how they would wake up in the morning, talk to each other, form routines and relationships, all the way to creating basically communities and emerging social dynamics. And sort of my interest in this area really stems from this idea. So this is sort of what people at the intersection of human-computer interaction and natural language processing in which learning like to ask, which is we now have these really amazing models like our language models and foundation models, the question really becomes, what are you going to do with them? Right? These models are new and they're great and we think they have great capacity, but are they really going to enable us to do something that's quite new and unique? And that has been sort of the focal point for a lot of the research that I do. And ultimately the conversation that we got down towards this idea of, well, these models are trained and brought data like the web, Wikipedia and so forth. So they can actually be used to generate a lot of believable human behavior when you're given a very micro context. So can we actually piece this together to create human-like agents, which is something that AI more broadly has envisioned since its founding days. And we decided that this is the time to do that. And so that's how we got to where we are. So that's the generative agents. And this is the paper that was published in April last year. We put it on archive in April and was officially published November. Which is crazy how much the world has developed. I'm curious what initially motivated this topic for you? I'm sure you had lots of different options in terms of what to research and study. Why did you decide to focus on this? Yeah. So ultimately, it really was the question of what will large language models, these new models that are being trained, really going to enable us to do. And when I started my PhD was around like 2020. And that was when GPT-3 was just about to come out. During my first year, we wrote a paper called Foundation Models, which sort of made this observation that there's going to be this new wave of models that's going to come out, where we're not going to be training these models for a specific task, but rather we'll be training for a modality. We're going to be training this language model that can process language and so forth. And we thought that was going to be a big opportunity there in terms of what we can do with them. But the question of what are we going to do with them was incredibly unclear. So really our first instinct as sort of researchers and more machine learning in the NLP community, where we sort of were drawn to was this idea of can we do classifications? Or generations with these models? And seeing that these models could do that was really exciting because we didn't train these models to do that, but they could. But more from the interaction perspective, doing classification and simple generation was something that we already knew how to do. So that did them feel fundamentally new. So really the question again became what are we going to do that's going to be truly new and transformative in the sense of interaction? So that's what really drew us to look for these kind of ideas. And again, that's we thought simulating human behavior in general computational agents, that felt like a big problem because in part because it's something that, again, our community had wanted for many decades. It was sort of the idea that people in more the cognitive science field that really inspired the early AI research, like Alan Newell and Albert Sass. Simon, these folks were asking. And we were certainly inspired by those ideas. And of course, we thought it would be a lot of fun because we sort of grew up with sims, Pokemon and these kinds of games in the 90s and early 2000s. And we were certainly inspired by those games as well. I love those games as well. And it's nice to see some of that play out in the real world. I agree. I think games are fun in the sense that, you know, I think they are inspirational in many ways because they are very forward-looking in many ways, right? Because you can be a little bit more playful. And I think research can be in many ways playful, especially when you're trying to do really forward-looking research. So it certainly is a big inspiration. And I was just going to sort of end that comment by saying that I think it's worth asking for us as a community what's going to be the new sort of quote unquote care application of these models. In the sense that when we had personal computers in the early 80s and so forth, the computers were very cool. But what really made them into household applications were the existence of this, what we would now consider as killer application of PCs, like Microsoft Excel, that really made tabular information usable and scalable. I think we, Luris Language Model Community, or should also be looking for those kind of ideas as well, because that's going to be ultimately what's going to really transform the user experience around these models. And I think we're seeing some great usage of these models, but I think there's a lot more to do going forward. Makes a lot of sense. When you look at what's happened since April, right, a lot of things have changed. We have new LLM capabilities. We have a whole flurry of startups building in this space. Could you maybe summarize what you've seen? Right. So, right. So, Agent Sotini has been a big thing, especially first the latter half of 2023. This is how I'm seeing it. Agent Community, it's sort of the way I view it, has split into two communities, I would argue now. So, maybe it might actually make a little more sense to really talk about the history of agents, because agent became a big thing last year, but this is not a new idea in and out of itself. Right, even in the commercial space, we actually had agents like Microsoft Clippy, I'm not sure how many of us will actually remember that, but there used to be these agents in sort of our industry and in research. So, this is certainly not a new idea. So, if you go all the way back, so we had agents like Clippy, and in many ways these agents, especially in the reinforcement learning and machine learning community, agents were these elements that basically could simulate human behavior. I think that is ultimately sort of underlying thesis, but many of the agents were given tools to automate certain tasks. And the task it were meant to automate were tasks that are not simple, right? It's not something like you're running a for loop with your Python code, but it's a little bit more complex than that, right? It operates in much more embodied spaces or in spaces that we often operate in, right? The web, right? Can it, the simplest example with these kind of tool-based agents are can it order me pizza? Can it buy plane tickets? And those might sound simple, but we know from our experiences that even ordering pizza actually does require multiple steps, right? We need to travel to certain websites, we need to look through the menus, actually make the payment, and deal with sort of entering your address and so forth. So that was one genre of agents that already sort of existed for a long time, or I would say all genres of agents sort of existed, but that was one genre that was highlighted in the past. So you see things like Clippy is also in that genre as well. You're a Microsoft Office user, Clippy would try to automate some tasks for you based on your prior interaction with the software. Another set of agents was this idea of simulation agents, or agents that were created- To clarify on that point, those agents are single agents, correct? They can be single agents, they were often implemented as single agents, that's right. I don't think by definition they actually had to be single agents. So you'd actually try, you're now seeing, at least in the research, you're starting to see glimpse of people is trying to imagine what would it look like for these agents to be in a multi-agent setting. So research paper that I remember coming out after Generative Agents was basically, what if you have a company of agents, right? There's going to be a CEO, but there's also going to be a designer agent who works in some other aspects, there is going to be editor in this company, and those are still much within the literature of what I would call tool-based agents, right? They're trying to automate some complex tasks for the users. And I think there's going to be a lot of sort of really big opportunities in this space, that's something that people have been working on for a long time, for all the right reasons. Now, another community that has formed, but to some extent actually has a slightly different route, is agents that were created for simulations. And these agents were certainly a part of games, right? In the past we had Sims, but we also had these NPC characters that we could interact with. Now, those NPCs and agents back then were very much, it was simpler agents that were either rule-based, there were some reinforcement learning agents back then as well in that space. But another one that we could usually think about were agents that were used basically in social science, economic agents, or agents that would simulate our policy decision-making and so forth. And those agents were also a part of this literature. And what we're seeing today is, we're one recognizing that Lawrence Lynch model is simulating human behavior. So it touches on all these agents, that it can be a foundational sort of architectural layer for creating all these different sorts of agents. But in terms of our initial application spaces, we're seeing this split, where there's one community who's now deeply interested in agents using tools, but another community that is deeply interested in this idea of can we simulate? And this is where I would say like multi-agents and as well as personalization is really starting to be highlighted in the simulation space because it's a little bit more directly incorporated to the idea of simulations. Who are we simulating for? What are we simulating? Who are we simulating? And by definition, simulations often happen in this multi-agent space. So those are the two communities that you're starting to see. So generative agent certainly stands on the far end of the simulation-based agents, whereas some other projects that were also really cool last year, I think a lot of sort of open AI, GPTs, I would say, are another end of the simulation agents or another end of tool-based agents. So those are the axes that you're sort of seeing right now. And sort of end by saying, my hunch actually is again, because they all start from the same technical thesis that we can simulate human behavior, they will merge in the end. I don't think they will be completely separate thesis like five to 10 years down the line. It's more going to be the question of where are we going to make our short-term bets and what's going to be an interesting and meaningful application space in the next two to five years. So that's the field that I'm seeing and how it's developing right now. Before we maybe go into that, could you maybe describe how LLM specifically has affected the, especially the latter cohort, right? What is the before and what is the after? And what is the magnitude of improvement because of this technology that's now cheap enough to use? Right. So Lawrence-Lenge Motor is really what made this possible. That is really the fundamental fact that we needed. In the past, when you wanted to create, and this goes for both types of agents, tool-based and simulations, what you really needed was, you basically needed rule-based agents. That was the most common. And rule-based agents are sort of a more sophisticated way of saying we're scripting all the behaviors. So imagine you're building an NPC for a game. A human author would actually write every sentence that the agent would say to the user, for instance. Human author would actually describe in either code or language, if this happens, you do this. So you basically design all the possible behaviors. Now, that is expensive and not scalable, right? And that was the fundamental block that we had. Now, tool-based agents had similar issues that in many of the contexts it had to operate, it's not a very generalizable tool. So if you sort of see how clippy or even some of the agents that we're using today, very simple types of agents actually are already embedded into our daily usage. So you may have used Google spreadsheet or Google doc. It would auto-complete in some very rudimentary way that actually could be considered in some ways an agent in this direction of tool-based agents. And the rules they were using so far were very simple. It's not exactly rule-based, but it is something that was very much hard-coded into the agent's behavior. And there was some learning going on, but there were very strict or simple statistics that we were using. What large language model changes is large language model gives us a single ingredient, which is given a micro-context, micromoment, let's say I'm sitting in this room talking to Joanne and about let's say generative agents or simulations and so forth. Given that micromoment description, a language model is extremely good at predicting the next moment, right? So what are the reasonable set of things that June might say in this particular conversation given what he knows? It's very good at doing that. That on its own is not a perfect agent or it's not the complete ingredient that you need to create these agents that are meant to live for many, many years or decades. But they are the right ingredient or building block that we need it because that can be used to replace what was in the past, manual authoring. In the past, we had to manually author all the possible sequences given any micromoment, but large language model can come in. So given that ingredient, what we really could do is bake in long-term memory and some reflection module on top of it and planning module. So given the micro-ingredient plus an agent architecture that we give it on top of it, these agents can basically now start to function as something that can operate in that in a world that's much like ours with a fairly decent degree of long-term coherence. So that's where we are and that's really the difference it made. And I'd say this is sort of a zero to one difference, not a degree difference because before large language model, this was not possible. What else is, so we, large language models gave memory, gave context, gave interactions to these agents. What else in a perfect world would these agents have in order to better mimic the real world? Like what's maybe in the next stop, just out of curiosity? Right, so to clarify, large language model doesn't actually have, so large language model provides one element. It's the micro sort of a module for predicting the next sequence. It is the agent architecture that actually ends up giving the memory and planning ability, but those two pair becomes a fantastic combination. Now, going forward, what I do think is going to be interesting are, so right now we're using large language model, but we may have all noticed that things like chatGPT can now not only do it just language, but also other modality like image. I think that's going to be really interesting, right? So right now, let's say if you, and this is sort of based on my prior work called Generative Agents, and we had this game world like sim ad that we call a smallville, the way these agents perceived and operated in their world was basically by translating, and like our system translating the visual world into natural language. So we would tell the agent, you are in your apartment, or you are in the kitchen talking to someone. So we would actually take the visual world and use our system to translate the visual world into natural language, and then feeding it to the agent architecture that would use our language model to process this. But now with these models being able to deal with multi-modal aspect, we might actually be able to bypass that phase and go straight from here is the visual world or space that you're seeing right now. That is your memory, now act on it. I think that's going to be potentially very powerful because in part, image is much richer to some, it conveys a lot more. I do come from natural language processing background, at least that's my other half of my sort of academic background. So I have bias towards believing the natural language is profound, and I think that we're going to be, that will be the case going forward as well. But image does offer something that just language alone does not. So image is going to be a big thing. Now imagine the future video is going to be a big thing as well, then gradually the more these agents will basically increasingly get more powerful as this new modality gets piled on. So that's something that we should be looking forward to. That's great. What are some on the downside, what are some of the limitations that you're seeing in terms of these agents, especially generative agents? Right. So there are limitations that I can mention just about sort of in the context of our work. And then I think there are going to be interesting limitations that are much more application specific. So for generative agents today, certainly the technical limitation right now might have to do with things like, so you're using whether it's an open source. So right now we use OpenAI's model. OpenAI has actually done a lot of work to make the model safer. And I think OpenAI, I think that was the right approach in the sense that what they really wanted to create was these chatbots or agents or chatGPT that are a safe tool to use for most people. Now, if you want to run a simulation or create truly accurate and believable agents with something like chatGPT, however, that could become a limitation because what we really experience as humans is we fight, we sometimes have conflicts, we disagree with each other. And that might not be something that's something like chatGPT that's been fine-tuned to not behave that way to remain safe. It's something, it might not be something that these models would try to surface. And that could be a potential block in creating more accurate, more believable simulations or agents for that matter. So that's something that is one limitation right now that we're seeing. An interesting way to tackle this, I think, going forward is to use open source models or other models that have less of these fine-tuned nature. But it's going to be highly dependent on the models that we'll be using for this. So I think that's one thing to look forward to. Got it, got it, that's super helpful. And maybe one last question on the research side. When you think about future areas to explore for you specifically, what are some of the more narrow topics that you're hoping to dive deeper in? Given the world. So ultimately, I think making the agents more accurate for these agents to be more accurate reflection of who we are, I think it's going to be a really interesting research and I think it's going to, that's going to be an area that's going to have more of a research and broader impact. So right now, you may have seen the sort of simulation demo, the agents that live in that simulation are fictional, that we just, for instance, we have an agent named Isabella, we told Isabella that she is a cafe owner and large language model basically makes up what a persona that is reasonable given that description. But I think it's going to be far more interesting if we can make these simulations actually closely model our actual human communities. So it's not just fictional, but actually has groundings. That's going to open up from our perspective an entirely new set of application spaces as well as research impact. This can be used, for instance, to actually model or predict markets or it's going to be able to use two more closely personalized many of these agents for individual use cases. So that's something that we're looking forward to in terms of sort of a particular topic that we're diving into. That plug, of course, scaling up the agents. I think that's another big one, but those two. That makes sense. Now, one of the things that's missing in most AI technologies is like really the emotional part of how humans feel, right? Like all of that data is largely not captured and therefore not part of any kind of models today. Language is one small output of what we have. It's a very important output for sure, but it's still one small output. So I wonder how we might be able to incorporate some of the data around our emotions. I agree. Some thoughts in the future. Maybe let's move on to the applications today since you talked about some of the challenges for agents. Many organizations are thinking about how to use large language models today, right? There's a huge amount of aspirations. A subset of them are also thinking about what are some of the agent technology applications that are viable within an enterprise, which has limitations around infrastructure, around data silos, security, and all that stuff. Any particular areas where you've seen companies be successful at using these technologies in production? Right. So I think this is going to be incredibly like case-by-case answer. So let me think. Or if not, like any hypothesis as to where you might see the first commercial deployments at scale. Right. So there is something that I have. This is, there's a message that I have in trying to communicate, I think, in different settings. So this is not something I'm sort of conveying for the first time. And my opinion has been getting updated, but I think fundamentally I think this is right. So the way I've been describing it is in human computer interaction or in most task settings, there are two types of problems that we deploy our machines or agents in. One has very hard-edge problem spaces. These are things like, hey, order me pizza or buy me a plane ticket. These are tasks where there's a very concrete outcome and there often is a right or wrong answer that the agent has to achieve. At least from the user's perspective, there is something that would absolutely be yes or no. And then there are problem spaces where we have soft-edge problems. These are problems where we can increasingly co-climb towards sort of being better, but at certain level it starts to actually become useful. So to make this intuition a little bit, to make this a little bit more intuitive here, for instance, if I guess the worst possible case scenario is I asked the agent to buy me a plane ticket and it bought me the wrong ticket that just goes to a different place, then that's like a heavy no. Whereas let's say I asked the agent to sort of simulate a behavior that is sort of fun so that when I'm in a game, this is sort of entertaining and interesting. That might be something that the agent doesn't need to be quite perfect in, but it can still get there quite quickly. And then we can gradually improve. Those two are the spaces that we can sort of, in terms of when we consider where to deploy or how these will actually make its first impact, we might actually be looking at those problem spaces first. And these are the classes that I'm seeing. If I were to make my bet, agents will likely succeed first in the soft-edge problem spaces and will gradually inch into making it work in the hardest problem space. This has been sort of an intuition with agent research community for some time. So when Clippy, for instance, failed. Our intuition there, at least from research perspective, wasn't that these agents failed because we didn't have the technology there. Certainly these were deployed and there were some confidence around the technology. But the problem there actually was with interaction, that when agents are deployed in hard-edge problem spaces, it's often deployed in states where it actually has to have a fairly long chain of steps and fairly high, the risk were fairly high. When it fails, the cost of correcting its error is actually quite high, cost of auditing its error is actually quite high. So when these agents are deployed in hardest problem spaces, it has to reckon with the fact that it will undoubtedly make mistakes. And when it does make a mistake, it has to be increasingly auditable and controllable by the users so that the cost of correcting its error is not high enough that from the user's perspective, the cost-benefit analysis basically has to make sense. And that's been a fundamental challenge with agents. That's why in every era, we see the interest around agents spike for a while and then it quickly subsides after like maybe a half a year or two a year. Now there's a real issue now though, that given the large language model in the progress we saw that this might not be the case this time or at some point we might be able to make this work. But for now, so I'm closely monitoring this as well and I think we all should. I don't think we should just go and say, because it didn't work before, it's not going to work this time. But my hunch is that we will likely see very similar pattern arise, at least for the first of the future. And we haven't quite dealt with the interaction problems with those types of agents. So I think it's much safer to assume that it is going to be in the soft edge problems basis. And that's why in some areas, in many of the aspects, that's why our team was also interested in this idea of simulation. Because simulation is sort of the prime example of soft edge problem spaces, where the simulation has to be good enough for it to start being useful. That's also why I think a lot of really early promising AI startups that's going to go in the agent space are places that does NPCs for games. Because those are very safe soft edge problem spaces where the agents can fail, but that's okay. And gradually we'll sort of go to the other area as well. But I think that's where the impact is going to start in the next couple of years. I also think just seeing the startups in this space, in sectors and functions that allow for failure, like you said, include things like marketing. Where if you market incorrectly, it's not that big of a deal. If you write the wrong code, that's probably going to be a bigger deal. If you pick the wrong security features, that's a huge deal. If you pick the wrong things for healthcare, that's an even bigger deal. So there are degrees of fault tolerance within the enterprise. That's one thing. And the second on the consumer side, especially if the agents are just assisting consumers by not executing on anything. That could probably also work. For example, there's a company called Rewind, which is using some of the agent technologies, I believe. And they're getting a bunch of consumer demand, but what consumers are doing is just searching for a behavior that they have had before. And this product is helping them do that versus do anything real world, really. Interesting. But that's super. The way that you frame it is very useful. What about just from an architecture standpoint, large language models enabled by transformer architectures? This is a whole different direction. We're already seeing companies that are saying, hey, transformers are not the most efficient. Inference costs are very high. Let's look at the next thing. Have you spent much time thinking about that? And if so, any impact to the work that you're doing? Right. So certainly a next sort of model that we're going to be banking on, I think that always is an important topic. And that's something that I think we as a community always has to sort of monitor, because I think you're right, that transformer is not going to be the end model that will be hopefully, I mean, not on what. The hope here is that we wouldn't be using transformer 10 years down the line. But one way that we do view this is, this is very much like a programmer's way of looking at this. We view this in abstractions, right? So what transformer has gotten us right now is this amazing capacity for reasoning and processing information and generating information. So it might be the case that in the future, that task will be done by even better models. And hopefully that's going to be the case. But for the sake of building applications, it is true that we can sort of view this as a layer of abstraction. That there might be some other technology that's going to be powering it in the future, but really what we're focusing on is the capacity and the modality. What kind of reasoning, using what modality, can these technologies that exist today do? And we're going to be building on top of it. So I think that's sort of our way of looking at it in sort of a medium term, again, the next three to five years. Now, if you're looking, because right now, there are some promising architectures that's sort of been created at the forefront of, I would say more in the machine learning and natural language processing communities that I'm personally getting a little bit excited about. But at the moment, those are still in the very much in the research phase. And can you share some examples of that? Yeah, so I think there's one model that recently came out, like Mamba by some folks. Those are from Stanford folks. So I think the authors now at CMU and Princeton sort of all within sort of this community. So that's one example of sort of a potentially promising or interesting model. And that's the one that I recently heard about that I think is interesting to be looking at. But these models, for them to be deployed at scale in a commercial way, if we decide to basically go with certain model that's getting created today, it will give us maybe two to five year timeline before they can really take off. Because Transformer is not, it is a relatively modern model, but it really is how you look at sort of the timeline. There's Transformer. Seven-ish years? Seven-ish years. So I think hopefully if we find something like this time, maybe it's going to go much faster. But it still took about seven-ish years for Chatchapiti to really come out. So it's not immediate. Whereas a lot of interactions that we can build, I think there's a lot that we can do like today to create really cool experiences. So I think that's how we're looking at this. There is a medium term. This is where we are focused on the level of extraction, that this is the capacity that we'll have. And then maybe in the down the line five to 10 year term, we can really be looking forward to some new models that's going to make an impact. That's great. That's great. Cool. Very cool. Maybe more generally, if you just zoom out for a moment, when you look at the ecosystem today, what are some of the problems that you want to see solve? We talked about multimodal a little bit. We talked about new models right after Transformers that might come out. What are some of the problems that you are most excited about someone solving? Not necessarily you personally, but someone solving. I sort of have two in mind. And it's a little bit less of a, this is a specific problem that I want to solve. But it's more sort of questions that I have that I think more of us should be thinking about. And to some extent, and this happens a lot with sort of the way I do my research as well, where I get inspired by big problems or foundational problems that we had in previous decades. Because oftentimes, there's a lot of insights that we can learn from the past as we build on the future. One, certainly I'm embedded into this agent space. One is, in the past, agents had its hype cycles, basically. But it failed. That the hype cycle lasted for a couple of years, and then people very quickly lost interest. Basically because it didn't quite deliver on the promises that it had. I think it's worth asking ourselves why that was the case. I think the opportunity this time is real. But I also think the opportunity in the past was also real to some aspect as well. So just because the opportunity is real and language model is really cool doesn't necessarily guarantee us, at least from my perspective, that we're going to, that agent will finally be a thing that everyone will use. I think there is a future where that will happen at some point. I think it might even happen this cycle. But I think it's really worth asking, as a community, why did it fail in the past so that we don't repeat those mistakes? One sort of main thing I'm sort of curious about that I don't think a lot of us are thinking about is actually not the technology part, but the interaction. How are these agents going to be used in what way? Because ultimately that's where it really delivers value to the end users. And that's where agents in the past have failed. That it was really cool technology, but we didn't seriously ask ourselves, is this something that people really need? And does the cost-benefit analysis of using these agents and learning how to use them well really make sense for the broader user base? So that's one. And other one is sort of my, it's a little bit of a hot take, but it's also a shorter take, which is we have large language models, and I think these have made a huge impact already. The number of users who use chat.gbt, that's incredible. But I think it's sort of worth asking ourselves, is that sort of quote unquote the killer applications that we were waiting for? Because in many ways, chat.gbt, or maybe it is. And I think if it is, I think somebody should articulate this. But chat.gbt does feel like a fairly simple wrapper around our language model, because that's what it is. And OpenAI has done fantastic things to make it safer and make it more useful by tuning, I think, what's really great. But I think it's worth asking, if that is actually the killer application, why is it a killer application? And the answer might actually come out that maybe it actually isn't the killer application that we were waiting for, in which case, what is going to be the killer application? That's really going to add value in a much more generalizable way. That's a very abstract question. For now, it's for me, it's just a hunch that I think there's something to be asked about there. And if I'm wrong, I would also love to hear again somebody really say, we already have this killer application, maybe it's co-pilot, chat.gbt, and here's why. But for now, this is a question that I'm still asking myself. That makes sense. And thank you for sharing that. What are some of your favorite AI apps today that you use? I love chat.gbt. I use it every day. Chat.gbt did make a difference in my workflow. So as a researcher, one of the main things I do is I program every day, or at least most days, or I write or write papers. So I do one of those two things. Chat.gbt is fantastic at both. So as all programmers sort of know, we sometimes don't bother remembering all the different functions or documentation. It's very good at generating a lot of the code when I have an idea. Really impressive. It's also quite a good editor. So if I make grammar error in my sort of sentences, chat.gbt will usually catch them for me. It's simple and easy thing, but it's good enough now that it's actually making a difference in the workflow. So as a chat.gbt, for sure, by extension, I think co-pilot will make a difference. So it's sort of worth asking, maybe going back to the question around killer application. What is the definition of killer application? I think it does some people define it as application that has more users. And the fact of that, I think, always has to be the case, that no killer application has no user. Killer application, by default, means the application that will have the most number of users. But I think there is more theoretical definition to what a killer application is. That implies a lot of users who are the most number of users. But for instance, if we look back to the prior era of PC, my killer application that I mentioned was something like Microsoft's Excel or this tabular data format, the thing that would let us manipulate the tabular data. So really, the definition, in a more theoretical sense of killer application here, is there is new technology stack that is being developed. There is a new file type that is getting generated. Then the killer application is the one that would let us manipulate the file application, file type. That's one theoretical definition that one could give, at least that's sort of the definition that I've been towing with. I think it's an interesting one. I don't think it's the only one. But those are sort of ways that I'm looking at this. That makes a lot of sense. I also use chatGPT every single day. It's been very helpful. Everything from coming up with menu names to rewriting emails that don't sound as nice. And I've tried a little bit to give it files and images. So I actually helped my mother create a background. She's a dancer, so she was performing on one of the very specific background for her dance. And I created that for her using chatGPT. So all sorts of utility there. But I love the way that you framed the last potential application. Maybe just one last question from my end. Any resources or books that you love that is on this topic? Right. I do think, and this is often the case with many of the cutting edge spaces. I think a lot of the papers that are coming out that are gaining a lot of attention, I think those are sort of worth checking out as sort of the resources. It's not exactly like here's one book that we can all look at. But things are moving fast enough that I think those are sort of interesting resources or just things that are getting created today and their documentations. So those are sort of mentioned as sort of a generic answer. I do think, I think this has been a sort of running thing in some of the things I mentioned today, I get inspired by insights that basically had an impact that stood the test of time. And the reason why that is the case is because I personally think all the great ideas are sort of timeless. It's because current time cycle is over, it doesn't mean they're less interesting or less meaningful. For sure. That foundational ideas that will continue to have impact. So when I look for resources, I actually look back to books from truly the prior generations. So some of the works that I often go back to are works by Herbert Simon, Alan G. Those are founders of AI and many of these fields who would later go into a turning award and Nobel Prize and so forth. And those works, early cognitive psychologists and scientists inspired my work a lot and their textbook. Those people actually have written books because they were much more established than sort of the cutting edge spaces today. So I go back to those as sort of my personal resources for getting ideas. That's great. Thank you so much. This was super, super helpful to me personally because what we do as investors is we try to understand the impacts of technology and start to invest in companies when it becomes, at the beginning of when it becomes commercially viable. So to your point around what are the problem spaces, what are the applications in which this can be applied in a cost-effective and secure way that where the end user is willing to interact and get value, that's when we start to come in and invest in these companies which will hopefully be much bigger companies in the future. So really appreciate this chat. Yeah, it was fun.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.28, "text": " The number of users who use ChatGPT, that's incredible.", "tokens": [50364, 440, 1230, 295, 5022, 567, 764, 27503, 38, 47, 51, 11, 300, 311, 4651, 13, 50578], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 1, "seek": 0, "start": 4.28, "end": 7.92, "text": " But I think it's sort of worth asking ourselves,", "tokens": [50578, 583, 286, 519, 309, 311, 1333, 295, 3163, 3365, 4175, 11, 50760], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 2, "seek": 0, "start": 7.92, "end": 11.08, "text": " is that sort of quote unquote the killer applications", "tokens": [50760, 307, 300, 1333, 295, 6513, 37557, 264, 13364, 5821, 50918], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 3, "seek": 0, "start": 11.08, "end": 12.52, "text": " that we were waiting for?", "tokens": [50918, 300, 321, 645, 3806, 337, 30, 50990], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 4, "seek": 0, "start": 12.52, "end": 16.28, "text": " ChatGPT does feel like a fairly simple wrapper", "tokens": [50990, 27503, 38, 47, 51, 775, 841, 411, 257, 6457, 2199, 46906, 51178], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 5, "seek": 0, "start": 16.28, "end": 19.32, "text": " around our sling model, because that's what it is.", "tokens": [51178, 926, 527, 1061, 278, 2316, 11, 570, 300, 311, 437, 309, 307, 13, 51330], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 6, "seek": 0, "start": 19.32, "end": 22.16, "text": " OpenAI has done fantastic things to make it safer", "tokens": [51330, 7238, 48698, 575, 1096, 5456, 721, 281, 652, 309, 15856, 51472], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 7, "seek": 0, "start": 22.16, "end": 23.88, "text": " and make it more useful by tuning,", "tokens": [51472, 293, 652, 309, 544, 4420, 538, 15164, 11, 51558], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 8, "seek": 0, "start": 23.88, "end": 25.560000000000002, "text": " I think, what's really great.", "tokens": [51558, 286, 519, 11, 437, 311, 534, 869, 13, 51642], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 9, "seek": 0, "start": 25.560000000000002, "end": 28.2, "text": " But I think it's worth asking if that is actually", "tokens": [51642, 583, 286, 519, 309, 311, 3163, 3365, 498, 300, 307, 767, 51774], "temperature": 0.0, "avg_logprob": -0.23639112903225806, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.013395547866821289}, {"id": 10, "seek": 2820, "start": 28.2, "end": 32.48, "text": " the killer application, why is it a killer application?", "tokens": [50364, 264, 13364, 3861, 11, 983, 307, 309, 257, 13364, 3861, 30, 50578], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 11, "seek": 2820, "start": 32.48, "end": 33.96, "text": " And the answer might actually come out", "tokens": [50578, 400, 264, 1867, 1062, 767, 808, 484, 50652], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 12, "seek": 2820, "start": 33.96, "end": 36.96, "text": " that maybe it actually isn't the killer application", "tokens": [50652, 300, 1310, 309, 767, 1943, 380, 264, 13364, 3861, 50802], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 13, "seek": 2820, "start": 36.96, "end": 39.879999999999995, "text": " that we were waiting for, in which case,", "tokens": [50802, 300, 321, 645, 3806, 337, 11, 294, 597, 1389, 11, 50948], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 14, "seek": 2820, "start": 39.879999999999995, "end": 42.16, "text": " what is going to be the killer application?", "tokens": [50948, 437, 307, 516, 281, 312, 264, 13364, 3861, 30, 51062], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 15, "seek": 2820, "start": 42.16, "end": 44.08, "text": " That's really going to add value", "tokens": [51062, 663, 311, 534, 516, 281, 909, 2158, 51158], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 16, "seek": 2820, "start": 44.08, "end": 45.8, "text": " in a much more generalizable way.", "tokens": [51158, 294, 257, 709, 544, 2674, 22395, 636, 13, 51244], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 17, "seek": 2820, "start": 48.36, "end": 50.72, "text": " Welcome to AI in the real world.", "tokens": [51372, 4027, 281, 7318, 294, 264, 957, 1002, 13, 51490], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 18, "seek": 2820, "start": 50.72, "end": 51.92, "text": " I'm your host.", "tokens": [51490, 286, 478, 428, 3975, 13, 51550], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 19, "seek": 2820, "start": 51.92, "end": 53.28, "text": " My name is Joanne Chen,", "tokens": [51550, 1222, 1315, 307, 3139, 12674, 13682, 11, 51618], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 20, "seek": 2820, "start": 53.28, "end": 55.760000000000005, "text": " and I am a general partner at Foundation Capital.", "tokens": [51618, 293, 286, 669, 257, 2674, 4975, 412, 10335, 21502, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16529988827912703, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0007912297151051462}, {"id": 21, "seek": 5576, "start": 55.76, "end": 56.919999999999995, "text": " I work closely with startups", "tokens": [50364, 286, 589, 8185, 365, 28041, 50422], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 22, "seek": 5576, "start": 56.919999999999995, "end": 59.16, "text": " that are reshaping business with AI.", "tokens": [50422, 300, 366, 725, 71, 569, 278, 1606, 365, 7318, 13, 50534], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 23, "seek": 5576, "start": 59.16, "end": 62.0, "text": " In this series, I'll be holding in-depth discussions", "tokens": [50534, 682, 341, 2638, 11, 286, 603, 312, 5061, 294, 12, 25478, 11088, 50676], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 24, "seek": 5576, "start": 62.0, "end": 63.8, "text": " with leading AI researchers.", "tokens": [50676, 365, 5775, 7318, 10309, 13, 50766], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 25, "seek": 5576, "start": 63.8, "end": 65.67999999999999, "text": " We'll explore how state-of-the-art AI models", "tokens": [50766, 492, 603, 6839, 577, 1785, 12, 2670, 12, 3322, 12, 446, 7318, 5245, 50860], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 26, "seek": 5576, "start": 65.67999999999999, "end": 68.96, "text": " are being applied in real enterprises today.", "tokens": [50860, 366, 885, 6456, 294, 957, 29034, 965, 13, 51024], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 27, "seek": 5576, "start": 68.96, "end": 72.2, "text": " To kick things off, I'm excited to speak with June Zempark,", "tokens": [51024, 1407, 4437, 721, 766, 11, 286, 478, 2919, 281, 1710, 365, 6928, 1176, 15970, 809, 11, 51186], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 28, "seek": 5576, "start": 72.2, "end": 75.12, "text": " a PhD student in computer science at Stanford.", "tokens": [51186, 257, 14476, 3107, 294, 3820, 3497, 412, 20374, 13, 51332], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 29, "seek": 5576, "start": 75.12, "end": 78.28, "text": " June works at the intersection of human-computer interaction", "tokens": [51332, 6928, 1985, 412, 264, 15236, 295, 1952, 12, 1112, 13849, 9285, 51490], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 30, "seek": 5576, "start": 78.28, "end": 80.08, "text": " and natural language processing.", "tokens": [51490, 293, 3303, 2856, 9007, 13, 51580], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 31, "seek": 5576, "start": 80.08, "end": 83.8, "text": " He is best known for his research on AI agents.", "tokens": [51580, 634, 307, 1151, 2570, 337, 702, 2132, 322, 7318, 12554, 13, 51766], "temperature": 0.0, "avg_logprob": -0.11055238856825718, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.005383210722357035}, {"id": 32, "seek": 8380, "start": 83.8, "end": 87.03999999999999, "text": " We break down how AI is transforming agent design,", "tokens": [50364, 492, 1821, 760, 577, 7318, 307, 27210, 9461, 1715, 11, 50526], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 33, "seek": 8380, "start": 87.03999999999999, "end": 89.52, "text": " share advice for builders working with these models,", "tokens": [50526, 2073, 5192, 337, 36281, 1364, 365, 613, 5245, 11, 50650], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 34, "seek": 8380, "start": 89.52, "end": 91.0, "text": " and unpack why we haven't yet found", "tokens": [50650, 293, 26699, 983, 321, 2378, 380, 1939, 1352, 50724], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 35, "seek": 8380, "start": 91.0, "end": 94.44, "text": " the perfect killer app for AI agents.", "tokens": [50724, 264, 2176, 13364, 724, 337, 7318, 12554, 13, 50896], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 36, "seek": 8380, "start": 94.44, "end": 95.8, "text": " Here's our conversation.", "tokens": [50896, 1692, 311, 527, 3761, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 37, "seek": 8380, "start": 95.8, "end": 97.28, "text": " How are you?", "tokens": [50964, 1012, 366, 291, 30, 51038], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 38, "seek": 8380, "start": 97.28, "end": 98.12, "text": " Good, what about you?", "tokens": [51038, 2205, 11, 437, 466, 291, 30, 51080], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 39, "seek": 8380, "start": 98.12, "end": 98.96, "text": " Great seeing you again.", "tokens": [51080, 3769, 2577, 291, 797, 13, 51122], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 40, "seek": 8380, "start": 98.96, "end": 99.8, "text": " Good to see you again.", "tokens": [51122, 2205, 281, 536, 291, 797, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 41, "seek": 8380, "start": 99.8, "end": 100.72, "text": " It's been a while.", "tokens": [51164, 467, 311, 668, 257, 1339, 13, 51210], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 42, "seek": 8380, "start": 100.72, "end": 103.03999999999999, "text": " Because the on-conference was last,", "tokens": [51210, 1436, 264, 322, 12, 1671, 5158, 390, 1036, 11, 51326], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 43, "seek": 8380, "start": 103.03999999999999, "end": 104.64, "text": " I want to say, June.", "tokens": [51326, 286, 528, 281, 584, 11, 6928, 13, 51406], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 44, "seek": 8380, "start": 104.64, "end": 105.96, "text": " June?", "tokens": [51406, 6928, 30, 51472], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 45, "seek": 8380, "start": 105.96, "end": 106.8, "text": " May or June?", "tokens": [51472, 1891, 420, 6928, 30, 51514], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 46, "seek": 8380, "start": 106.8, "end": 107.8, "text": " Yeah.", "tokens": [51514, 865, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 47, "seek": 8380, "start": 107.8, "end": 110.12, "text": " Last June, May or June.", "tokens": [51564, 5264, 6928, 11, 1891, 420, 6928, 13, 51680], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 48, "seek": 8380, "start": 110.12, "end": 111.64, "text": " Wow, time-wise.", "tokens": [51680, 3153, 11, 565, 12, 3711, 13, 51756], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 49, "seek": 8380, "start": 111.64, "end": 113.2, "text": " And the world has changed.", "tokens": [51756, 400, 264, 1002, 575, 3105, 13, 51834], "temperature": 0.0, "avg_logprob": -0.17199008529250687, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.056498438119888306}, {"id": 50, "seek": 11320, "start": 113.24000000000001, "end": 117.24000000000001, "text": " I think that agents have finally made its way", "tokens": [50366, 286, 519, 300, 12554, 362, 2721, 1027, 1080, 636, 50566], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 51, "seek": 11320, "start": 117.24000000000001, "end": 121.08, "text": " into real enterprises with real use cases.", "tokens": [50566, 666, 957, 29034, 365, 957, 764, 3331, 13, 50758], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 52, "seek": 11320, "start": 121.08, "end": 124.76, "text": " And it was not, back then, it was a lot of,", "tokens": [50758, 400, 309, 390, 406, 11, 646, 550, 11, 309, 390, 257, 688, 295, 11, 50942], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 53, "seek": 11320, "start": 124.76, "end": 127.92, "text": " like, what could this be, right?", "tokens": [50942, 411, 11, 437, 727, 341, 312, 11, 558, 30, 51100], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 54, "seek": 11320, "start": 127.92, "end": 129.68, "text": " Thanks to you as some of your work,", "tokens": [51100, 2561, 281, 291, 382, 512, 295, 428, 589, 11, 51188], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 55, "seek": 11320, "start": 129.68, "end": 131.24, "text": " which is why I'm super excited", "tokens": [51188, 597, 307, 983, 286, 478, 1687, 2919, 51266], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 56, "seek": 11320, "start": 131.24, "end": 134.32, "text": " to have this conversation together.", "tokens": [51266, 281, 362, 341, 3761, 1214, 13, 51420], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 57, "seek": 11320, "start": 135.24, "end": 136.24, "text": " Especially right now,", "tokens": [51466, 8545, 558, 586, 11, 51516], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 58, "seek": 11320, "start": 136.24, "end": 141.24, "text": " since enterprises are sinking in a real way", "tokens": [51516, 1670, 29034, 366, 28148, 294, 257, 957, 636, 51766], "temperature": 0.0, "avg_logprob": -0.2001808653486536, "compression_ratio": 1.5391705069124424, "no_speech_prob": 0.00043008505599573255}, {"id": 59, "seek": 14124, "start": 142.24, "end": 144.4, "text": " to adopt.", "tokens": [50414, 281, 6878, 13, 50522], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 60, "seek": 14124, "start": 144.4, "end": 148.04000000000002, "text": " So I thought, who can we chat with", "tokens": [50522, 407, 286, 1194, 11, 567, 393, 321, 5081, 365, 50704], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 61, "seek": 14124, "start": 148.04000000000002, "end": 150.20000000000002, "text": " that would have a really interesting perspective?", "tokens": [50704, 300, 576, 362, 257, 534, 1880, 4585, 30, 50812], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 62, "seek": 14124, "start": 150.20000000000002, "end": 152.16, "text": " And that's why we reached out back to you.", "tokens": [50812, 400, 300, 311, 983, 321, 6488, 484, 646, 281, 291, 13, 50910], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 63, "seek": 14124, "start": 152.16, "end": 154.76000000000002, "text": " So I really appreciate the time.", "tokens": [50910, 407, 286, 534, 4449, 264, 565, 13, 51040], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 64, "seek": 14124, "start": 154.76000000000002, "end": 155.60000000000002, "text": " Of course.", "tokens": [51040, 2720, 1164, 13, 51082], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 65, "seek": 14124, "start": 155.60000000000002, "end": 157.36, "text": " Thanks for having me.", "tokens": [51082, 2561, 337, 1419, 385, 13, 51170], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 66, "seek": 14124, "start": 157.36, "end": 159.20000000000002, "text": " Do you mind maybe just to start", "tokens": [51170, 1144, 291, 1575, 1310, 445, 281, 722, 51262], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 67, "seek": 14124, "start": 159.20000000000002, "end": 163.52, "text": " giving us a quick rundown of what's happened,", "tokens": [51262, 2902, 505, 257, 1702, 23096, 648, 295, 437, 311, 2011, 11, 51478], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 68, "seek": 14124, "start": 163.52, "end": 166.04000000000002, "text": " maybe some of the background that you have", "tokens": [51478, 1310, 512, 295, 264, 3678, 300, 291, 362, 51604], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 69, "seek": 14124, "start": 166.04000000000002, "end": 167.28, "text": " building this technology?", "tokens": [51604, 2390, 341, 2899, 30, 51666], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 70, "seek": 14124, "start": 168.44, "end": 169.64000000000001, "text": " Yeah.", "tokens": [51724, 865, 13, 51784], "temperature": 0.0, "avg_logprob": -0.21736539327181303, "compression_ratio": 1.5278969957081545, "no_speech_prob": 0.0008681334438733757}, {"id": 71, "seek": 16964, "start": 169.64, "end": 171.6, "text": " So let's see.", "tokens": [50364, 407, 718, 311, 536, 13, 50462], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 72, "seek": 16964, "start": 171.6, "end": 174.35999999999999, "text": " So do you want me to just sort of speak about", "tokens": [50462, 407, 360, 291, 528, 385, 281, 445, 1333, 295, 1710, 466, 50600], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 73, "seek": 16964, "start": 174.35999999999999, "end": 176.11999999999998, "text": " sort of what has happened in the past six months,", "tokens": [50600, 1333, 295, 437, 575, 2011, 294, 264, 1791, 2309, 2493, 11, 50688], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 74, "seek": 16964, "start": 176.11999999999998, "end": 179.07999999999998, "text": " or sort of what would be interesting for you?", "tokens": [50688, 420, 1333, 295, 437, 576, 312, 1880, 337, 291, 30, 50836], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 75, "seek": 16964, "start": 179.07999999999998, "end": 181.55999999999997, "text": " Just a brief overview of what you worked on", "tokens": [50836, 1449, 257, 5353, 12492, 295, 437, 291, 2732, 322, 50960], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 76, "seek": 16964, "start": 181.55999999999997, "end": 184.44, "text": " and also what's happened in the last six months", "tokens": [50960, 293, 611, 437, 311, 2011, 294, 264, 1036, 2309, 2493, 51104], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 77, "seek": 16964, "start": 184.44, "end": 186.88, "text": " to a year in terms of evolution.", "tokens": [51104, 281, 257, 1064, 294, 2115, 295, 9303, 13, 51226], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 78, "seek": 16964, "start": 186.88, "end": 187.72, "text": " Yeah.", "tokens": [51226, 865, 13, 51268], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 79, "seek": 16964, "start": 187.72, "end": 188.83999999999997, "text": " All right, that sounds good.", "tokens": [51268, 1057, 558, 11, 300, 3263, 665, 13, 51324], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 80, "seek": 16964, "start": 188.83999999999997, "end": 189.67999999999998, "text": " Right.", "tokens": [51324, 1779, 13, 51366], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 81, "seek": 16964, "start": 189.67999999999998, "end": 192.2, "text": " So I guess I'll do a quick intro.", "tokens": [51366, 407, 286, 2041, 286, 603, 360, 257, 1702, 12897, 13, 51492], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 82, "seek": 16964, "start": 192.2, "end": 195.2, "text": " So I'm sort of, I'm a PhD student here,", "tokens": [51492, 407, 286, 478, 1333, 295, 11, 286, 478, 257, 14476, 3107, 510, 11, 51642], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 83, "seek": 16964, "start": 195.2, "end": 198.48, "text": " sort of working in the area of HCI and NLP.", "tokens": [51642, 1333, 295, 1364, 294, 264, 1859, 295, 389, 25240, 293, 426, 45196, 13, 51806], "temperature": 0.0, "avg_logprob": -0.17857535108387898, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0008677819278091192}, {"id": 84, "seek": 19848, "start": 198.51999999999998, "end": 201.56, "text": " So as you know, sort of the work that we've done,", "tokens": [50366, 407, 382, 291, 458, 11, 1333, 295, 264, 589, 300, 321, 600, 1096, 11, 50518], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 85, "seek": 19848, "start": 201.56, "end": 203.56, "text": " I think the one that I'm sort of mainly known for", "tokens": [50518, 286, 519, 264, 472, 300, 286, 478, 1333, 295, 8704, 2570, 337, 50618], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 86, "seek": 19848, "start": 203.56, "end": 205.51999999999998, "text": " is this paper called Generative Agents.", "tokens": [50618, 307, 341, 3035, 1219, 15409, 1166, 2725, 791, 13, 50716], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 87, "seek": 19848, "start": 206.48, "end": 209.44, "text": " And Generative Agents in particular was a project", "tokens": [50764, 400, 15409, 1166, 2725, 791, 294, 1729, 390, 257, 1716, 50912], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 88, "seek": 19848, "start": 209.44, "end": 211.0, "text": " that I tried to ask,", "tokens": [50912, 300, 286, 3031, 281, 1029, 11, 50990], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 89, "seek": 19848, "start": 211.0, "end": 214.67999999999998, "text": " can we use our language models to create general agents", "tokens": [50990, 393, 321, 764, 527, 2856, 5245, 281, 1884, 2674, 12554, 51174], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 90, "seek": 19848, "start": 214.67999999999998, "end": 217.04, "text": " that can populate a simulation world?", "tokens": [51174, 300, 393, 1665, 5256, 257, 16575, 1002, 30, 51292], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 91, "seek": 19848, "start": 217.04, "end": 217.88, "text": " Right?", "tokens": [51292, 1779, 30, 51334], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 92, "seek": 19848, "start": 217.88, "end": 220.48, "text": " So if you play something like SimCity or Sims,", "tokens": [51334, 407, 498, 291, 862, 746, 411, 3998, 34, 507, 420, 33289, 11, 51464], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 93, "seek": 19848, "start": 220.48, "end": 222.76, "text": " can we actually create these NPC-like characters", "tokens": [51464, 393, 321, 767, 1884, 613, 28787, 12, 4092, 4342, 51578], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 94, "seek": 19848, "start": 222.76, "end": 224.72, "text": " that would actually flood into the city", "tokens": [51578, 300, 576, 767, 10481, 666, 264, 2307, 51676], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 95, "seek": 19848, "start": 224.72, "end": 226.79999999999998, "text": " and actually live like humans?", "tokens": [51676, 293, 767, 1621, 411, 6255, 30, 51780], "temperature": 0.0, "avg_logprob": -0.13331142454656936, "compression_ratio": 1.7132616487455197, "no_speech_prob": 0.00017945047875400633}, {"id": 96, "seek": 22680, "start": 226.8, "end": 229.08, "text": " And by definition, it is sort of everything", "tokens": [50364, 400, 538, 7123, 11, 309, 307, 1333, 295, 1203, 50478], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 97, "seek": 22680, "start": 229.08, "end": 232.20000000000002, "text": " from how they would wake up in the morning,", "tokens": [50478, 490, 577, 436, 576, 6634, 493, 294, 264, 2446, 11, 50634], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 98, "seek": 22680, "start": 232.20000000000002, "end": 235.36, "text": " talk to each other, form routines and relationships,", "tokens": [50634, 751, 281, 1184, 661, 11, 1254, 33827, 293, 6159, 11, 50792], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 99, "seek": 22680, "start": 235.36, "end": 238.32000000000002, "text": " all the way to creating basically communities", "tokens": [50792, 439, 264, 636, 281, 4084, 1936, 4456, 50940], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 100, "seek": 22680, "start": 238.32000000000002, "end": 240.28, "text": " and emerging social dynamics.", "tokens": [50940, 293, 14989, 2093, 15679, 13, 51038], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 101, "seek": 22680, "start": 241.44, "end": 243.48000000000002, "text": " And sort of my interest in this area", "tokens": [51096, 400, 1333, 295, 452, 1179, 294, 341, 1859, 51198], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 102, "seek": 22680, "start": 243.48000000000002, "end": 245.4, "text": " really stems from this idea.", "tokens": [51198, 534, 27600, 490, 341, 1558, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 103, "seek": 22680, "start": 245.4, "end": 247.60000000000002, "text": " So this is sort of what people at the intersection", "tokens": [51294, 407, 341, 307, 1333, 295, 437, 561, 412, 264, 15236, 51404], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 104, "seek": 22680, "start": 247.60000000000002, "end": 249.84, "text": " of human-computer interaction and natural language processing", "tokens": [51404, 295, 1952, 12, 1112, 13849, 9285, 293, 3303, 2856, 9007, 51516], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 105, "seek": 22680, "start": 249.84, "end": 251.60000000000002, "text": " in which learning like to ask,", "tokens": [51516, 294, 597, 2539, 411, 281, 1029, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 106, "seek": 22680, "start": 251.60000000000002, "end": 254.64000000000001, "text": " which is we now have these really amazing models", "tokens": [51604, 597, 307, 321, 586, 362, 613, 534, 2243, 5245, 51756], "temperature": 0.0, "avg_logprob": -0.1218730760657269, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.5460016331635416e-05}, {"id": 107, "seek": 25464, "start": 254.67999999999998, "end": 257.15999999999997, "text": " like our language models and foundation models,", "tokens": [50366, 411, 527, 2856, 5245, 293, 7030, 5245, 11, 50490], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 108, "seek": 25464, "start": 257.15999999999997, "end": 258.84, "text": " the question really becomes,", "tokens": [50490, 264, 1168, 534, 3643, 11, 50574], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 109, "seek": 25464, "start": 258.84, "end": 260.4, "text": " what are you going to do with them?", "tokens": [50574, 437, 366, 291, 516, 281, 360, 365, 552, 30, 50652], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 110, "seek": 25464, "start": 260.4, "end": 261.24, "text": " Right?", "tokens": [50652, 1779, 30, 50694], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 111, "seek": 25464, "start": 261.24, "end": 262.96, "text": " These models are new and they're great", "tokens": [50694, 1981, 5245, 366, 777, 293, 436, 434, 869, 50780], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 112, "seek": 25464, "start": 262.96, "end": 265.2, "text": " and we think they have great capacity,", "tokens": [50780, 293, 321, 519, 436, 362, 869, 6042, 11, 50892], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 113, "seek": 25464, "start": 265.2, "end": 267.84, "text": " but are they really going to enable us", "tokens": [50892, 457, 366, 436, 534, 516, 281, 9528, 505, 51024], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 114, "seek": 25464, "start": 267.84, "end": 271.36, "text": " to do something that's quite new and unique?", "tokens": [51024, 281, 360, 746, 300, 311, 1596, 777, 293, 3845, 30, 51200], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 115, "seek": 25464, "start": 271.36, "end": 273.12, "text": " And that has been sort of the focal point", "tokens": [51200, 400, 300, 575, 668, 1333, 295, 264, 26592, 935, 51288], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 116, "seek": 25464, "start": 273.12, "end": 275.32, "text": " for a lot of the research that I do.", "tokens": [51288, 337, 257, 688, 295, 264, 2132, 300, 286, 360, 13, 51398], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 117, "seek": 25464, "start": 275.32, "end": 277.59999999999997, "text": " And ultimately the conversation that we got down", "tokens": [51398, 400, 6284, 264, 3761, 300, 321, 658, 760, 51512], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 118, "seek": 25464, "start": 277.59999999999997, "end": 279.64, "text": " towards this idea of,", "tokens": [51512, 3030, 341, 1558, 295, 11, 51614], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 119, "seek": 25464, "start": 279.64, "end": 281.76, "text": " well, these models are trained and brought data", "tokens": [51614, 731, 11, 613, 5245, 366, 8895, 293, 3038, 1412, 51720], "temperature": 0.0, "avg_logprob": -0.16264792314664586, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0017811863217502832}, {"id": 120, "seek": 28176, "start": 281.76, "end": 285.68, "text": " like the web, Wikipedia and so forth.", "tokens": [50364, 411, 264, 3670, 11, 28999, 293, 370, 5220, 13, 50560], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 121, "seek": 28176, "start": 285.68, "end": 287.59999999999997, "text": " So they can actually be used to generate", "tokens": [50560, 407, 436, 393, 767, 312, 1143, 281, 8460, 50656], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 122, "seek": 28176, "start": 287.59999999999997, "end": 289.76, "text": " a lot of believable human behavior", "tokens": [50656, 257, 688, 295, 1351, 17915, 1952, 5223, 50764], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 123, "seek": 28176, "start": 289.76, "end": 292.0, "text": " when you're given a very micro context.", "tokens": [50764, 562, 291, 434, 2212, 257, 588, 4532, 4319, 13, 50876], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 124, "seek": 28176, "start": 292.0, "end": 293.59999999999997, "text": " So can we actually piece this together", "tokens": [50876, 407, 393, 321, 767, 2522, 341, 1214, 50956], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 125, "seek": 28176, "start": 293.59999999999997, "end": 295.2, "text": " to create human-like agents,", "tokens": [50956, 281, 1884, 1952, 12, 4092, 12554, 11, 51036], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 126, "seek": 28176, "start": 295.2, "end": 298.0, "text": " which is something that AI more broadly", "tokens": [51036, 597, 307, 746, 300, 7318, 544, 19511, 51176], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 127, "seek": 28176, "start": 298.0, "end": 300.12, "text": " has envisioned since its founding days.", "tokens": [51176, 575, 47733, 1670, 1080, 22223, 1708, 13, 51282], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 128, "seek": 28176, "start": 301.15999999999997, "end": 303.59999999999997, "text": " And we decided that this is the time to do that.", "tokens": [51334, 400, 321, 3047, 300, 341, 307, 264, 565, 281, 360, 300, 13, 51456], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 129, "seek": 28176, "start": 303.59999999999997, "end": 306.8, "text": " And so that's how we got to where we are.", "tokens": [51456, 400, 370, 300, 311, 577, 321, 658, 281, 689, 321, 366, 13, 51616], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 130, "seek": 28176, "start": 306.8, "end": 308.8, "text": " So that's the generative agents.", "tokens": [51616, 407, 300, 311, 264, 1337, 1166, 12554, 13, 51716], "temperature": 0.0, "avg_logprob": -0.12455284901154347, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.0034811091609299183}, {"id": 131, "seek": 30880, "start": 308.8, "end": 312.16, "text": " And this is the paper that was published in April last year.", "tokens": [50364, 400, 341, 307, 264, 3035, 300, 390, 6572, 294, 6929, 1036, 1064, 13, 50532], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 132, "seek": 30880, "start": 312.16, "end": 314.0, "text": " We put it on archive in April", "tokens": [50532, 492, 829, 309, 322, 23507, 294, 6929, 50624], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 133, "seek": 30880, "start": 314.0, "end": 316.64, "text": " and was officially published November.", "tokens": [50624, 293, 390, 12053, 6572, 7674, 13, 50756], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 134, "seek": 30880, "start": 316.64, "end": 321.64, "text": " Which is crazy how much the world has developed.", "tokens": [50756, 3013, 307, 3219, 577, 709, 264, 1002, 575, 4743, 13, 51006], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 135, "seek": 30880, "start": 322.24, "end": 326.52, "text": " I'm curious what initially motivated this topic for you?", "tokens": [51036, 286, 478, 6369, 437, 9105, 14515, 341, 4829, 337, 291, 30, 51250], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 136, "seek": 30880, "start": 326.52, "end": 328.44, "text": " I'm sure you had lots of different options", "tokens": [51250, 286, 478, 988, 291, 632, 3195, 295, 819, 3956, 51346], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 137, "seek": 30880, "start": 328.44, "end": 330.84000000000003, "text": " in terms of what to research and study.", "tokens": [51346, 294, 2115, 295, 437, 281, 2132, 293, 2979, 13, 51466], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 138, "seek": 30880, "start": 330.84000000000003, "end": 333.08000000000004, "text": " Why did you decide to focus on this?", "tokens": [51466, 1545, 630, 291, 4536, 281, 1879, 322, 341, 30, 51578], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 139, "seek": 30880, "start": 334.64, "end": 335.48, "text": " Yeah.", "tokens": [51656, 865, 13, 51698], "temperature": 0.0, "avg_logprob": -0.15148232380549112, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.0007204308058135211}, {"id": 140, "seek": 33548, "start": 335.48, "end": 339.16, "text": " So ultimately, it really was the question of", "tokens": [50364, 407, 6284, 11, 309, 534, 390, 264, 1168, 295, 50548], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 141, "seek": 33548, "start": 339.16, "end": 341.12, "text": " what will large language models,", "tokens": [50548, 437, 486, 2416, 2856, 5245, 11, 50646], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 142, "seek": 33548, "start": 341.12, "end": 344.28000000000003, "text": " these new models that are being trained,", "tokens": [50646, 613, 777, 5245, 300, 366, 885, 8895, 11, 50804], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 143, "seek": 33548, "start": 344.28000000000003, "end": 345.8, "text": " really going to enable us to do.", "tokens": [50804, 534, 516, 281, 9528, 505, 281, 360, 13, 50880], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 144, "seek": 33548, "start": 345.8, "end": 348.84000000000003, "text": " And when I started my PhD was around like 2020.", "tokens": [50880, 400, 562, 286, 1409, 452, 14476, 390, 926, 411, 4808, 13, 51032], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 145, "seek": 33548, "start": 348.84000000000003, "end": 351.68, "text": " And that was when GPT-3 was just about to come out.", "tokens": [51032, 400, 300, 390, 562, 26039, 51, 12, 18, 390, 445, 466, 281, 808, 484, 13, 51174], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 146, "seek": 33548, "start": 351.68, "end": 354.20000000000005, "text": " During my first year, we wrote a paper called", "tokens": [51174, 6842, 452, 700, 1064, 11, 321, 4114, 257, 3035, 1219, 51300], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 147, "seek": 33548, "start": 354.20000000000005, "end": 357.88, "text": " Foundation Models, which sort of made this observation", "tokens": [51300, 10335, 6583, 1625, 11, 597, 1333, 295, 1027, 341, 14816, 51484], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 148, "seek": 33548, "start": 357.88, "end": 360.28000000000003, "text": " that there's going to be this new wave of models", "tokens": [51484, 300, 456, 311, 516, 281, 312, 341, 777, 5772, 295, 5245, 51604], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 149, "seek": 33548, "start": 360.28000000000003, "end": 361.48, "text": " that's going to come out,", "tokens": [51604, 300, 311, 516, 281, 808, 484, 11, 51664], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 150, "seek": 33548, "start": 361.48, "end": 364.0, "text": " where we're not going to be training these models", "tokens": [51664, 689, 321, 434, 406, 516, 281, 312, 3097, 613, 5245, 51790], "temperature": 0.0, "avg_logprob": -0.15610023616820343, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0002734254812821746}, {"id": 151, "seek": 36400, "start": 364.0, "end": 365.6, "text": " for a specific task,", "tokens": [50364, 337, 257, 2685, 5633, 11, 50444], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 152, "seek": 36400, "start": 365.6, "end": 368.0, "text": " but rather we'll be training for a modality.", "tokens": [50444, 457, 2831, 321, 603, 312, 3097, 337, 257, 1072, 1860, 13, 50564], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 153, "seek": 36400, "start": 368.0, "end": 370.28, "text": " We're going to be training this language model", "tokens": [50564, 492, 434, 516, 281, 312, 3097, 341, 2856, 2316, 50678], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 154, "seek": 36400, "start": 370.28, "end": 372.56, "text": " that can process language and so forth.", "tokens": [50678, 300, 393, 1399, 2856, 293, 370, 5220, 13, 50792], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 155, "seek": 36400, "start": 373.52, "end": 377.6, "text": " And we thought that was going to be a big opportunity there", "tokens": [50840, 400, 321, 1194, 300, 390, 516, 281, 312, 257, 955, 2650, 456, 51044], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 156, "seek": 36400, "start": 377.6, "end": 379.32, "text": " in terms of what we can do with them.", "tokens": [51044, 294, 2115, 295, 437, 321, 393, 360, 365, 552, 13, 51130], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 157, "seek": 36400, "start": 379.32, "end": 381.12, "text": " But the question of what are we going to do with them", "tokens": [51130, 583, 264, 1168, 295, 437, 366, 321, 516, 281, 360, 365, 552, 51220], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 158, "seek": 36400, "start": 381.12, "end": 382.72, "text": " was incredibly unclear.", "tokens": [51220, 390, 6252, 25636, 13, 51300], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 159, "seek": 36400, "start": 382.72, "end": 386.64, "text": " So really our first instinct as sort of researchers", "tokens": [51300, 407, 534, 527, 700, 16556, 382, 1333, 295, 10309, 51496], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 160, "seek": 36400, "start": 386.64, "end": 389.6, "text": " and more machine learning in the NLP community,", "tokens": [51496, 293, 544, 3479, 2539, 294, 264, 426, 45196, 1768, 11, 51644], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 161, "seek": 36400, "start": 389.6, "end": 392.0, "text": " where we sort of were drawn to was this idea", "tokens": [51644, 689, 321, 1333, 295, 645, 10117, 281, 390, 341, 1558, 51764], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 162, "seek": 36400, "start": 392.0, "end": 393.44, "text": " of can we do classifications?", "tokens": [51764, 295, 393, 321, 360, 1508, 7833, 30, 51836], "temperature": 0.0, "avg_logprob": -0.136603936216885, "compression_ratio": 1.7587412587412588, "no_speech_prob": 0.001080433838069439}, {"id": 163, "seek": 39344, "start": 393.44, "end": 395.48, "text": " Or generations with these models?", "tokens": [50364, 1610, 10593, 365, 613, 5245, 30, 50466], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 164, "seek": 39344, "start": 395.48, "end": 398.4, "text": " And seeing that these models could do that was really exciting", "tokens": [50466, 400, 2577, 300, 613, 5245, 727, 360, 300, 390, 534, 4670, 50612], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 165, "seek": 39344, "start": 398.4, "end": 400.12, "text": " because we didn't train these models to do that,", "tokens": [50612, 570, 321, 994, 380, 3847, 613, 5245, 281, 360, 300, 11, 50698], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 166, "seek": 39344, "start": 400.12, "end": 401.64, "text": " but they could.", "tokens": [50698, 457, 436, 727, 13, 50774], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 167, "seek": 39344, "start": 401.64, "end": 404.24, "text": " But more from the interaction perspective,", "tokens": [50774, 583, 544, 490, 264, 9285, 4585, 11, 50904], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 168, "seek": 39344, "start": 404.24, "end": 406.72, "text": " doing classification and simple generation", "tokens": [50904, 884, 21538, 293, 2199, 5125, 51028], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 169, "seek": 39344, "start": 406.72, "end": 408.6, "text": " was something that we already knew how to do.", "tokens": [51028, 390, 746, 300, 321, 1217, 2586, 577, 281, 360, 13, 51122], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 170, "seek": 39344, "start": 408.6, "end": 411.6, "text": " So that did them feel fundamentally new.", "tokens": [51122, 407, 300, 630, 552, 841, 17879, 777, 13, 51272], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 171, "seek": 39344, "start": 411.6, "end": 413.92, "text": " So really the question again became", "tokens": [51272, 407, 534, 264, 1168, 797, 3062, 51388], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 172, "seek": 39344, "start": 413.92, "end": 416.84, "text": " what are we going to do that's going to be truly new", "tokens": [51388, 437, 366, 321, 516, 281, 360, 300, 311, 516, 281, 312, 4908, 777, 51534], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 173, "seek": 39344, "start": 416.84, "end": 419.88, "text": " and transformative in the sense of interaction?", "tokens": [51534, 293, 36070, 294, 264, 2020, 295, 9285, 30, 51686], "temperature": 0.0, "avg_logprob": -0.14211413290648334, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0005699794855900109}, {"id": 174, "seek": 41988, "start": 420.88, "end": 425.96, "text": " So that's what really drew us to look for these kind of ideas.", "tokens": [50414, 407, 300, 311, 437, 534, 12804, 505, 281, 574, 337, 613, 733, 295, 3487, 13, 50668], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 175, "seek": 41988, "start": 425.96, "end": 427.88, "text": " And again, that's we thought", "tokens": [50668, 400, 797, 11, 300, 311, 321, 1194, 50764], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 176, "seek": 41988, "start": 427.88, "end": 431.88, "text": " simulating human behavior in general computational agents,", "tokens": [50764, 1034, 12162, 1952, 5223, 294, 2674, 28270, 12554, 11, 50964], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 177, "seek": 41988, "start": 431.88, "end": 434.2, "text": " that felt like a big problem because in part", "tokens": [50964, 300, 2762, 411, 257, 955, 1154, 570, 294, 644, 51080], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 178, "seek": 41988, "start": 434.2, "end": 436.28, "text": " because it's something that, again,", "tokens": [51080, 570, 309, 311, 746, 300, 11, 797, 11, 51184], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 179, "seek": 41988, "start": 436.28, "end": 439.44, "text": " our community had wanted for many decades.", "tokens": [51184, 527, 1768, 632, 1415, 337, 867, 7878, 13, 51342], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 180, "seek": 41988, "start": 439.44, "end": 442.48, "text": " It was sort of the idea that people in more", "tokens": [51342, 467, 390, 1333, 295, 264, 1558, 300, 561, 294, 544, 51494], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 181, "seek": 41988, "start": 442.48, "end": 445.56, "text": " the cognitive science field that really inspired", "tokens": [51494, 264, 15605, 3497, 2519, 300, 534, 7547, 51648], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 182, "seek": 41988, "start": 445.56, "end": 449.04, "text": " the early AI research, like Alan Newell and Albert Sass.", "tokens": [51648, 264, 2440, 7318, 2132, 11, 411, 16442, 1734, 6326, 293, 20812, 318, 640, 13, 51822], "temperature": 0.0, "avg_logprob": -0.2519100937887887, "compression_ratio": 1.6245210727969348, "no_speech_prob": 0.0002820909721776843}, {"id": 183, "seek": 44904, "start": 449.20000000000005, "end": 451.52000000000004, "text": " Simon, these folks were asking.", "tokens": [50372, 13193, 11, 613, 4024, 645, 3365, 13, 50488], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 184, "seek": 44904, "start": 451.52000000000004, "end": 455.72, "text": " And we were certainly inspired by those ideas.", "tokens": [50488, 400, 321, 645, 3297, 7547, 538, 729, 3487, 13, 50698], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 185, "seek": 44904, "start": 455.72, "end": 457.52000000000004, "text": " And of course, we thought it would be a lot of fun", "tokens": [50698, 400, 295, 1164, 11, 321, 1194, 309, 576, 312, 257, 688, 295, 1019, 50788], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 186, "seek": 44904, "start": 457.52000000000004, "end": 460.08000000000004, "text": " because we sort of grew up with sims, Pokemon", "tokens": [50788, 570, 321, 1333, 295, 6109, 493, 365, 1034, 82, 11, 13796, 50916], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 187, "seek": 44904, "start": 460.08000000000004, "end": 464.40000000000003, "text": " and these kinds of games in the 90s and early 2000s.", "tokens": [50916, 293, 613, 3685, 295, 2813, 294, 264, 4289, 82, 293, 2440, 8132, 82, 13, 51132], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 188, "seek": 44904, "start": 464.40000000000003, "end": 466.76, "text": " And we were certainly inspired by those games as well.", "tokens": [51132, 400, 321, 645, 3297, 7547, 538, 729, 2813, 382, 731, 13, 51250], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 189, "seek": 44904, "start": 466.76, "end": 468.52000000000004, "text": " I love those games as well.", "tokens": [51250, 286, 959, 729, 2813, 382, 731, 13, 51338], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 190, "seek": 44904, "start": 468.52000000000004, "end": 473.48, "text": " And it's nice to see some of that play out in the real world.", "tokens": [51338, 400, 309, 311, 1481, 281, 536, 512, 295, 300, 862, 484, 294, 264, 957, 1002, 13, 51586], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 191, "seek": 44904, "start": 473.48, "end": 476.44, "text": " I agree. I think games are fun in the sense that,", "tokens": [51586, 286, 3986, 13, 286, 519, 2813, 366, 1019, 294, 264, 2020, 300, 11, 51734], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 192, "seek": 44904, "start": 476.44, "end": 478.76, "text": " you know, I think they are inspirational in many ways", "tokens": [51734, 291, 458, 11, 286, 519, 436, 366, 33554, 294, 867, 2098, 51850], "temperature": 0.0, "avg_logprob": -0.16520920084483587, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.00326991337351501}, {"id": 193, "seek": 47876, "start": 478.76, "end": 482.24, "text": " because they are very forward-looking in many ways, right?", "tokens": [50364, 570, 436, 366, 588, 2128, 12, 16129, 294, 867, 2098, 11, 558, 30, 50538], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 194, "seek": 47876, "start": 482.24, "end": 484.4, "text": " Because you can be a little bit more playful.", "tokens": [50538, 1436, 291, 393, 312, 257, 707, 857, 544, 30730, 13, 50646], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 195, "seek": 47876, "start": 484.4, "end": 487.08, "text": " And I think research can be in many ways playful,", "tokens": [50646, 400, 286, 519, 2132, 393, 312, 294, 867, 2098, 30730, 11, 50780], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 196, "seek": 47876, "start": 487.08, "end": 490.24, "text": " especially when you're trying to do really forward-looking research.", "tokens": [50780, 2318, 562, 291, 434, 1382, 281, 360, 534, 2128, 12, 16129, 2132, 13, 50938], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 197, "seek": 47876, "start": 490.24, "end": 492.68, "text": " So it certainly is a big inspiration.", "tokens": [50938, 407, 309, 3297, 307, 257, 955, 10249, 13, 51060], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 198, "seek": 47876, "start": 492.68, "end": 496.28, "text": " And I was just going to sort of end that comment by saying", "tokens": [51060, 400, 286, 390, 445, 516, 281, 1333, 295, 917, 300, 2871, 538, 1566, 51240], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 199, "seek": 47876, "start": 496.28, "end": 499.96, "text": " that I think it's worth asking for us as a community", "tokens": [51240, 300, 286, 519, 309, 311, 3163, 3365, 337, 505, 382, 257, 1768, 51424], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 200, "seek": 47876, "start": 499.96, "end": 503.15999999999997, "text": " what's going to be the new sort of quote unquote", "tokens": [51424, 437, 311, 516, 281, 312, 264, 777, 1333, 295, 6513, 37557, 51584], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 201, "seek": 47876, "start": 503.15999999999997, "end": 506.88, "text": " care application of these models.", "tokens": [51584, 1127, 3861, 295, 613, 5245, 13, 51770], "temperature": 0.0, "avg_logprob": -0.16008135803744325, "compression_ratio": 1.7471264367816093, "no_speech_prob": 0.0012430464848876}, {"id": 202, "seek": 50688, "start": 506.92, "end": 509.48, "text": " In the sense that when we had personal computers", "tokens": [50366, 682, 264, 2020, 300, 562, 321, 632, 2973, 10807, 50494], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 203, "seek": 50688, "start": 509.48, "end": 512.96, "text": " in the early 80s and so forth,", "tokens": [50494, 294, 264, 2440, 4688, 82, 293, 370, 5220, 11, 50668], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 204, "seek": 50688, "start": 512.96, "end": 515.6, "text": " the computers were very cool.", "tokens": [50668, 264, 10807, 645, 588, 1627, 13, 50800], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 205, "seek": 50688, "start": 515.6, "end": 520.32, "text": " But what really made them into household applications", "tokens": [50800, 583, 437, 534, 1027, 552, 666, 9888, 5821, 51036], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 206, "seek": 50688, "start": 520.32, "end": 521.84, "text": " were the existence of this,", "tokens": [51036, 645, 264, 9123, 295, 341, 11, 51112], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 207, "seek": 50688, "start": 521.84, "end": 526.28, "text": " what we would now consider as killer application of PCs,", "tokens": [51112, 437, 321, 576, 586, 1949, 382, 13364, 3861, 295, 46913, 11, 51334], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 208, "seek": 50688, "start": 526.28, "end": 527.68, "text": " like Microsoft Excel,", "tokens": [51334, 411, 8116, 19060, 11, 51404], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 209, "seek": 50688, "start": 527.68, "end": 532.4, "text": " that really made tabular information usable and scalable.", "tokens": [51404, 300, 534, 1027, 4421, 1040, 1589, 29975, 293, 38481, 13, 51640], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 210, "seek": 50688, "start": 532.4, "end": 534.4, "text": " I think we, Luris Language Model Community,", "tokens": [51640, 286, 519, 321, 11, 441, 374, 271, 24445, 17105, 10421, 11, 51740], "temperature": 0.0, "avg_logprob": -0.20439095192767204, "compression_ratio": 1.5829787234042554, "no_speech_prob": 0.003119704080745578}, {"id": 211, "seek": 53440, "start": 534.4, "end": 537.28, "text": " or should also be looking for those kind of ideas as well,", "tokens": [50364, 420, 820, 611, 312, 1237, 337, 729, 733, 295, 3487, 382, 731, 11, 50508], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 212, "seek": 53440, "start": 537.28, "end": 538.9599999999999, "text": " because that's going to be ultimately", "tokens": [50508, 570, 300, 311, 516, 281, 312, 6284, 50592], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 213, "seek": 53440, "start": 538.9599999999999, "end": 541.68, "text": " what's going to really transform the user experience", "tokens": [50592, 437, 311, 516, 281, 534, 4088, 264, 4195, 1752, 50728], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 214, "seek": 53440, "start": 541.68, "end": 542.76, "text": " around these models.", "tokens": [50728, 926, 613, 5245, 13, 50782], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 215, "seek": 53440, "start": 542.76, "end": 546.92, "text": " And I think we're seeing some great usage of these models,", "tokens": [50782, 400, 286, 519, 321, 434, 2577, 512, 869, 14924, 295, 613, 5245, 11, 50990], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 216, "seek": 53440, "start": 546.92, "end": 550.1999999999999, "text": " but I think there's a lot more to do going forward.", "tokens": [50990, 457, 286, 519, 456, 311, 257, 688, 544, 281, 360, 516, 2128, 13, 51154], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 217, "seek": 53440, "start": 550.1999999999999, "end": 551.68, "text": " Makes a lot of sense.", "tokens": [51154, 25245, 257, 688, 295, 2020, 13, 51228], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 218, "seek": 53440, "start": 551.68, "end": 555.48, "text": " When you look at what's happened since April, right,", "tokens": [51228, 1133, 291, 574, 412, 437, 311, 2011, 1670, 6929, 11, 558, 11, 51418], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 219, "seek": 53440, "start": 555.48, "end": 557.16, "text": " a lot of things have changed.", "tokens": [51418, 257, 688, 295, 721, 362, 3105, 13, 51502], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 220, "seek": 53440, "start": 557.16, "end": 560.12, "text": " We have new LLM capabilities.", "tokens": [51502, 492, 362, 777, 441, 43, 44, 10862, 13, 51650], "temperature": 0.0, "avg_logprob": -0.12810537271332323, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0005109602934680879}, {"id": 221, "seek": 56012, "start": 560.12, "end": 564.76, "text": " We have a whole flurry of startups building in this space.", "tokens": [50364, 492, 362, 257, 1379, 932, 30614, 295, 28041, 2390, 294, 341, 1901, 13, 50596], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 222, "seek": 56012, "start": 564.76, "end": 568.4, "text": " Could you maybe summarize what you've seen?", "tokens": [50596, 7497, 291, 1310, 20858, 437, 291, 600, 1612, 30, 50778], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 223, "seek": 56012, "start": 568.4, "end": 570.08, "text": " Right.", "tokens": [50778, 1779, 13, 50862], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 224, "seek": 56012, "start": 570.08, "end": 571.2, "text": " So, right.", "tokens": [50862, 407, 11, 558, 13, 50918], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 225, "seek": 56012, "start": 571.2, "end": 573.64, "text": " So, Agent Sotini has been a big thing,", "tokens": [50918, 407, 11, 27174, 318, 310, 3812, 575, 668, 257, 955, 551, 11, 51040], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 226, "seek": 56012, "start": 573.64, "end": 578.2, "text": " especially first the latter half of 2023.", "tokens": [51040, 2318, 700, 264, 18481, 1922, 295, 44377, 13, 51268], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 227, "seek": 56012, "start": 578.2, "end": 580.48, "text": " This is how I'm seeing it.", "tokens": [51268, 639, 307, 577, 286, 478, 2577, 309, 13, 51382], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 228, "seek": 56012, "start": 580.48, "end": 583.6, "text": " Agent Community, it's sort of the way I view it,", "tokens": [51382, 27174, 10421, 11, 309, 311, 1333, 295, 264, 636, 286, 1910, 309, 11, 51538], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 229, "seek": 56012, "start": 583.6, "end": 587.2, "text": " has split into two communities, I would argue now.", "tokens": [51538, 575, 7472, 666, 732, 4456, 11, 286, 576, 9695, 586, 13, 51718], "temperature": 0.0, "avg_logprob": -0.30135101318359375, "compression_ratio": 1.4449339207048457, "no_speech_prob": 0.0041944244876503944}, {"id": 230, "seek": 58720, "start": 587.2, "end": 590.84, "text": " So, maybe it might actually make a little more sense", "tokens": [50364, 407, 11, 1310, 309, 1062, 767, 652, 257, 707, 544, 2020, 50546], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 231, "seek": 58720, "start": 590.84, "end": 593.2800000000001, "text": " to really talk about the history of agents,", "tokens": [50546, 281, 534, 751, 466, 264, 2503, 295, 12554, 11, 50668], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 232, "seek": 58720, "start": 593.2800000000001, "end": 595.2, "text": " because agent became a big thing last year,", "tokens": [50668, 570, 9461, 3062, 257, 955, 551, 1036, 1064, 11, 50764], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 233, "seek": 58720, "start": 595.2, "end": 598.6400000000001, "text": " but this is not a new idea in and out of itself.", "tokens": [50764, 457, 341, 307, 406, 257, 777, 1558, 294, 293, 484, 295, 2564, 13, 50936], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 234, "seek": 58720, "start": 598.6400000000001, "end": 601.48, "text": " Right, even in the commercial space,", "tokens": [50936, 1779, 11, 754, 294, 264, 6841, 1901, 11, 51078], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 235, "seek": 58720, "start": 601.48, "end": 604.2, "text": " we actually had agents like Microsoft Clippy,", "tokens": [51078, 321, 767, 632, 12554, 411, 8116, 2033, 48363, 11, 51214], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 236, "seek": 58720, "start": 604.2, "end": 606.5600000000001, "text": " I'm not sure how many of us will actually remember that,", "tokens": [51214, 286, 478, 406, 988, 577, 867, 295, 505, 486, 767, 1604, 300, 11, 51332], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 237, "seek": 58720, "start": 606.5600000000001, "end": 610.96, "text": " but there used to be these agents in sort of our industry", "tokens": [51332, 457, 456, 1143, 281, 312, 613, 12554, 294, 1333, 295, 527, 3518, 51552], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 238, "seek": 58720, "start": 610.96, "end": 612.5200000000001, "text": " and in research.", "tokens": [51552, 293, 294, 2132, 13, 51630], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 239, "seek": 58720, "start": 612.5200000000001, "end": 615.44, "text": " So, this is certainly not a new idea.", "tokens": [51630, 407, 11, 341, 307, 3297, 406, 257, 777, 1558, 13, 51776], "temperature": 0.0, "avg_logprob": -0.15761650403340657, "compression_ratio": 1.6679245283018869, "no_speech_prob": 6.498147558886558e-05}, {"id": 240, "seek": 61544, "start": 615.5200000000001, "end": 618.36, "text": " So, if you go all the way back,", "tokens": [50368, 407, 11, 498, 291, 352, 439, 264, 636, 646, 11, 50510], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 241, "seek": 61544, "start": 618.36, "end": 621.08, "text": " so we had agents like Clippy,", "tokens": [50510, 370, 321, 632, 12554, 411, 2033, 48363, 11, 50646], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 242, "seek": 61544, "start": 621.08, "end": 623.36, "text": " and in many ways these agents,", "tokens": [50646, 293, 294, 867, 2098, 613, 12554, 11, 50760], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 243, "seek": 61544, "start": 623.36, "end": 624.9200000000001, "text": " especially in the reinforcement learning", "tokens": [50760, 2318, 294, 264, 29280, 2539, 50838], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 244, "seek": 61544, "start": 624.9200000000001, "end": 626.0, "text": " and machine learning community,", "tokens": [50838, 293, 3479, 2539, 1768, 11, 50892], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 245, "seek": 61544, "start": 626.0, "end": 629.72, "text": " agents were these elements that basically", "tokens": [50892, 12554, 645, 613, 4959, 300, 1936, 51078], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 246, "seek": 61544, "start": 629.72, "end": 631.0400000000001, "text": " could simulate human behavior.", "tokens": [51078, 727, 27817, 1952, 5223, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 247, "seek": 61544, "start": 631.0400000000001, "end": 634.24, "text": " I think that is ultimately sort of underlying thesis,", "tokens": [51144, 286, 519, 300, 307, 6284, 1333, 295, 14217, 22288, 11, 51304], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 248, "seek": 61544, "start": 634.24, "end": 637.32, "text": " but many of the agents were given tools", "tokens": [51304, 457, 867, 295, 264, 12554, 645, 2212, 3873, 51458], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 249, "seek": 61544, "start": 637.32, "end": 639.36, "text": " to automate certain tasks.", "tokens": [51458, 281, 31605, 1629, 9608, 13, 51560], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 250, "seek": 61544, "start": 639.36, "end": 641.72, "text": " And the task it were meant to automate", "tokens": [51560, 400, 264, 5633, 309, 645, 4140, 281, 31605, 51678], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 251, "seek": 61544, "start": 641.72, "end": 644.0, "text": " were tasks that are not simple, right?", "tokens": [51678, 645, 9608, 300, 366, 406, 2199, 11, 558, 30, 51792], "temperature": 0.0, "avg_logprob": -0.1628326518195016, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.0008424243424087763}, {"id": 252, "seek": 64400, "start": 644.0, "end": 646.44, "text": " It's not something like you're running a for loop", "tokens": [50364, 467, 311, 406, 746, 411, 291, 434, 2614, 257, 337, 6367, 50486], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 253, "seek": 64400, "start": 646.44, "end": 647.52, "text": " with your Python code,", "tokens": [50486, 365, 428, 15329, 3089, 11, 50540], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 254, "seek": 64400, "start": 647.52, "end": 649.2, "text": " but it's a little bit more complex than that, right?", "tokens": [50540, 457, 309, 311, 257, 707, 857, 544, 3997, 813, 300, 11, 558, 30, 50624], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 255, "seek": 64400, "start": 649.2, "end": 652.52, "text": " It operates in much more embodied spaces", "tokens": [50624, 467, 22577, 294, 709, 544, 42046, 7673, 50790], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 256, "seek": 64400, "start": 652.52, "end": 656.08, "text": " or in spaces that we often operate in, right?", "tokens": [50790, 420, 294, 7673, 300, 321, 2049, 9651, 294, 11, 558, 30, 50968], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 257, "seek": 64400, "start": 656.08, "end": 658.52, "text": " The web, right?", "tokens": [50968, 440, 3670, 11, 558, 30, 51090], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 258, "seek": 64400, "start": 658.52, "end": 660.48, "text": " Can it, the simplest example", "tokens": [51090, 1664, 309, 11, 264, 22811, 1365, 51188], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 259, "seek": 64400, "start": 660.48, "end": 662.28, "text": " with these kind of tool-based agents", "tokens": [51188, 365, 613, 733, 295, 2290, 12, 6032, 12554, 51278], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 260, "seek": 64400, "start": 662.28, "end": 664.2, "text": " are can it order me pizza?", "tokens": [51278, 366, 393, 309, 1668, 385, 8298, 30, 51374], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 261, "seek": 64400, "start": 664.2, "end": 666.52, "text": " Can it buy plane tickets?", "tokens": [51374, 1664, 309, 2256, 5720, 12628, 30, 51490], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 262, "seek": 64400, "start": 666.52, "end": 668.2, "text": " And those might sound simple,", "tokens": [51490, 400, 729, 1062, 1626, 2199, 11, 51574], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 263, "seek": 64400, "start": 668.2, "end": 670.48, "text": " but we know from our experiences", "tokens": [51574, 457, 321, 458, 490, 527, 5235, 51688], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 264, "seek": 64400, "start": 670.48, "end": 671.92, "text": " that even ordering pizza actually", "tokens": [51688, 300, 754, 21739, 8298, 767, 51760], "temperature": 0.0, "avg_logprob": -0.1349345484087544, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0006358982645906508}, {"id": 265, "seek": 67192, "start": 671.92, "end": 674.24, "text": " does require multiple steps, right?", "tokens": [50364, 775, 3651, 3866, 4439, 11, 558, 30, 50480], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 266, "seek": 67192, "start": 674.24, "end": 675.88, "text": " We need to travel to certain websites,", "tokens": [50480, 492, 643, 281, 3147, 281, 1629, 12891, 11, 50562], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 267, "seek": 67192, "start": 675.88, "end": 677.52, "text": " we need to look through the menus,", "tokens": [50562, 321, 643, 281, 574, 807, 264, 30347, 11, 50644], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 268, "seek": 67192, "start": 677.52, "end": 679.1999999999999, "text": " actually make the payment,", "tokens": [50644, 767, 652, 264, 10224, 11, 50728], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 269, "seek": 67192, "start": 679.1999999999999, "end": 682.8, "text": " and deal with sort of entering your address and so forth.", "tokens": [50728, 293, 2028, 365, 1333, 295, 11104, 428, 2985, 293, 370, 5220, 13, 50908], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 270, "seek": 67192, "start": 682.8, "end": 684.92, "text": " So that was one genre of agents", "tokens": [50908, 407, 300, 390, 472, 11022, 295, 12554, 51014], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 271, "seek": 67192, "start": 684.92, "end": 687.4, "text": " that already sort of existed for a long time,", "tokens": [51014, 300, 1217, 1333, 295, 13135, 337, 257, 938, 565, 11, 51138], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 272, "seek": 67192, "start": 687.4, "end": 690.12, "text": " or I would say all genres of agents sort of existed,", "tokens": [51138, 420, 286, 576, 584, 439, 30057, 295, 12554, 1333, 295, 13135, 11, 51274], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 273, "seek": 67192, "start": 690.12, "end": 693.56, "text": " but that was one genre that was highlighted in the past.", "tokens": [51274, 457, 300, 390, 472, 11022, 300, 390, 17173, 294, 264, 1791, 13, 51446], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 274, "seek": 67192, "start": 693.56, "end": 697.0799999999999, "text": " So you see things like Clippy is also in that genre as well.", "tokens": [51446, 407, 291, 536, 721, 411, 2033, 48363, 307, 611, 294, 300, 11022, 382, 731, 13, 51622], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 275, "seek": 67192, "start": 697.0799999999999, "end": 699.52, "text": " You're a Microsoft Office user,", "tokens": [51622, 509, 434, 257, 8116, 8935, 4195, 11, 51744], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 276, "seek": 67192, "start": 699.52, "end": 701.4399999999999, "text": " Clippy would try to automate some tasks for you", "tokens": [51744, 2033, 48363, 576, 853, 281, 31605, 512, 9608, 337, 291, 51840], "temperature": 0.0, "avg_logprob": -0.09304478185639965, "compression_ratio": 1.75503355704698, "no_speech_prob": 0.0019874288700520992}, {"id": 277, "seek": 70144, "start": 701.44, "end": 704.72, "text": " based on your prior interaction with the software.", "tokens": [50364, 2361, 322, 428, 4059, 9285, 365, 264, 4722, 13, 50528], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 278, "seek": 70144, "start": 704.72, "end": 709.72, "text": " Another set of agents was this idea of simulation agents,", "tokens": [50528, 3996, 992, 295, 12554, 390, 341, 1558, 295, 16575, 12554, 11, 50778], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 279, "seek": 70144, "start": 710.8800000000001, "end": 712.32, "text": " or agents that were created-", "tokens": [50836, 420, 12554, 300, 645, 2942, 12, 50908], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 280, "seek": 70144, "start": 712.32, "end": 714.08, "text": " To clarify on that point,", "tokens": [50908, 1407, 17594, 322, 300, 935, 11, 50996], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 281, "seek": 70144, "start": 714.08, "end": 717.72, "text": " those agents are single agents, correct?", "tokens": [50996, 729, 12554, 366, 2167, 12554, 11, 3006, 30, 51178], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 282, "seek": 70144, "start": 717.72, "end": 718.84, "text": " They can be single agents,", "tokens": [51178, 814, 393, 312, 2167, 12554, 11, 51234], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 283, "seek": 70144, "start": 718.84, "end": 723.4000000000001, "text": " they were often implemented as single agents, that's right.", "tokens": [51234, 436, 645, 2049, 12270, 382, 2167, 12554, 11, 300, 311, 558, 13, 51462], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 284, "seek": 70144, "start": 723.4000000000001, "end": 724.6, "text": " I don't think by definition", "tokens": [51462, 286, 500, 380, 519, 538, 7123, 51522], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 285, "seek": 70144, "start": 724.6, "end": 726.2800000000001, "text": " they actually had to be single agents.", "tokens": [51522, 436, 767, 632, 281, 312, 2167, 12554, 13, 51606], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 286, "seek": 70144, "start": 726.2800000000001, "end": 728.6, "text": " So you'd actually try, you're now seeing,", "tokens": [51606, 407, 291, 1116, 767, 853, 11, 291, 434, 586, 2577, 11, 51722], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 287, "seek": 70144, "start": 728.6, "end": 730.6, "text": " at least in the research,", "tokens": [51722, 412, 1935, 294, 264, 2132, 11, 51822], "temperature": 0.0, "avg_logprob": -0.16069081399293073, "compression_ratio": 1.7676348547717842, "no_speech_prob": 0.00037964447983540595}, {"id": 288, "seek": 73060, "start": 730.6, "end": 732.64, "text": " you're starting to see glimpse of people", "tokens": [50364, 291, 434, 2891, 281, 536, 25838, 295, 561, 50466], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 289, "seek": 73060, "start": 732.64, "end": 735.48, "text": " is trying to imagine what would it look like", "tokens": [50466, 307, 1382, 281, 3811, 437, 576, 309, 574, 411, 50608], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 290, "seek": 73060, "start": 735.48, "end": 738.24, "text": " for these agents to be in a multi-agent setting.", "tokens": [50608, 337, 613, 12554, 281, 312, 294, 257, 4825, 12, 559, 317, 3287, 13, 50746], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 291, "seek": 73060, "start": 738.24, "end": 740.64, "text": " So research paper that I remember coming out", "tokens": [50746, 407, 2132, 3035, 300, 286, 1604, 1348, 484, 50866], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 292, "seek": 73060, "start": 740.64, "end": 743.9200000000001, "text": " after Generative Agents was basically,", "tokens": [50866, 934, 15409, 1166, 2725, 791, 390, 1936, 11, 51030], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 293, "seek": 73060, "start": 743.9200000000001, "end": 747.5600000000001, "text": " what if you have a company of agents, right?", "tokens": [51030, 437, 498, 291, 362, 257, 2237, 295, 12554, 11, 558, 30, 51212], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 294, "seek": 73060, "start": 747.5600000000001, "end": 748.9200000000001, "text": " There's going to be a CEO,", "tokens": [51212, 821, 311, 516, 281, 312, 257, 9282, 11, 51280], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 295, "seek": 73060, "start": 748.9200000000001, "end": 750.9200000000001, "text": " but there's also going to be a designer agent", "tokens": [51280, 457, 456, 311, 611, 516, 281, 312, 257, 11795, 9461, 51380], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 296, "seek": 73060, "start": 750.9200000000001, "end": 753.5600000000001, "text": " who works in some other aspects,", "tokens": [51380, 567, 1985, 294, 512, 661, 7270, 11, 51512], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 297, "seek": 73060, "start": 753.5600000000001, "end": 756.5600000000001, "text": " there is going to be editor in this company,", "tokens": [51512, 456, 307, 516, 281, 312, 9839, 294, 341, 2237, 11, 51662], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 298, "seek": 73060, "start": 756.5600000000001, "end": 759.72, "text": " and those are still much within the literature", "tokens": [51662, 293, 729, 366, 920, 709, 1951, 264, 10394, 51820], "temperature": 0.0, "avg_logprob": -0.18380874203097436, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.0006255785119719803}, {"id": 299, "seek": 75972, "start": 759.72, "end": 762.6800000000001, "text": " of what I would call tool-based agents, right?", "tokens": [50364, 295, 437, 286, 576, 818, 2290, 12, 6032, 12554, 11, 558, 30, 50512], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 300, "seek": 75972, "start": 762.6800000000001, "end": 767.36, "text": " They're trying to automate some complex tasks for the users.", "tokens": [50512, 814, 434, 1382, 281, 31605, 512, 3997, 9608, 337, 264, 5022, 13, 50746], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 301, "seek": 75972, "start": 767.36, "end": 768.52, "text": " And I think there's going to be a lot of", "tokens": [50746, 400, 286, 519, 456, 311, 516, 281, 312, 257, 688, 295, 50804], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 302, "seek": 75972, "start": 768.52, "end": 770.64, "text": " sort of really big opportunities in this space,", "tokens": [50804, 1333, 295, 534, 955, 4786, 294, 341, 1901, 11, 50910], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 303, "seek": 75972, "start": 770.64, "end": 772.08, "text": " that's something that people have been working on", "tokens": [50910, 300, 311, 746, 300, 561, 362, 668, 1364, 322, 50982], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 304, "seek": 75972, "start": 772.08, "end": 775.4, "text": " for a long time, for all the right reasons.", "tokens": [50982, 337, 257, 938, 565, 11, 337, 439, 264, 558, 4112, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 305, "seek": 75972, "start": 775.4, "end": 780.4, "text": " Now, another community that has formed,", "tokens": [51148, 823, 11, 1071, 1768, 300, 575, 8693, 11, 51398], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 306, "seek": 75972, "start": 780.6, "end": 784.52, "text": " but to some extent actually has a slightly different route,", "tokens": [51408, 457, 281, 512, 8396, 767, 575, 257, 4748, 819, 7955, 11, 51604], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 307, "seek": 75972, "start": 784.52, "end": 787.96, "text": " is agents that were created for simulations.", "tokens": [51604, 307, 12554, 300, 645, 2942, 337, 35138, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13843832882967863, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.0009693122701719403}, {"id": 308, "seek": 78972, "start": 789.96, "end": 792.9200000000001, "text": " And these agents were certainly a part of games, right?", "tokens": [50376, 400, 613, 12554, 645, 3297, 257, 644, 295, 2813, 11, 558, 30, 50524], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 309, "seek": 78972, "start": 792.9200000000001, "end": 794.76, "text": " In the past we had Sims,", "tokens": [50524, 682, 264, 1791, 321, 632, 33289, 11, 50616], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 310, "seek": 78972, "start": 794.76, "end": 797.44, "text": " but we also had these NPC characters", "tokens": [50616, 457, 321, 611, 632, 613, 28787, 4342, 50750], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 311, "seek": 78972, "start": 797.44, "end": 799.2, "text": " that we could interact with.", "tokens": [50750, 300, 321, 727, 4648, 365, 13, 50838], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 312, "seek": 78972, "start": 799.2, "end": 803.0, "text": " Now, those NPCs and agents back then were very much,", "tokens": [50838, 823, 11, 729, 28787, 82, 293, 12554, 646, 550, 645, 588, 709, 11, 51028], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 313, "seek": 78972, "start": 803.0, "end": 806.4, "text": " it was simpler agents that were either rule-based,", "tokens": [51028, 309, 390, 18587, 12554, 300, 645, 2139, 4978, 12, 6032, 11, 51198], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 314, "seek": 78972, "start": 806.4, "end": 808.08, "text": " there were some reinforcement learning agents", "tokens": [51198, 456, 645, 512, 29280, 2539, 12554, 51282], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 315, "seek": 78972, "start": 808.08, "end": 809.6800000000001, "text": " back then as well in that space.", "tokens": [51282, 646, 550, 382, 731, 294, 300, 1901, 13, 51362], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 316, "seek": 78972, "start": 811.0400000000001, "end": 813.48, "text": " But another one that we could usually think about", "tokens": [51430, 583, 1071, 472, 300, 321, 727, 2673, 519, 466, 51552], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 317, "seek": 78972, "start": 813.48, "end": 817.6800000000001, "text": " were agents that were used basically in social science,", "tokens": [51552, 645, 12554, 300, 645, 1143, 1936, 294, 2093, 3497, 11, 51762], "temperature": 0.0, "avg_logprob": -0.1499799951776728, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0008825895492918789}, {"id": 318, "seek": 81768, "start": 817.7199999999999, "end": 820.4399999999999, "text": " economic agents, or agents that would simulate", "tokens": [50366, 4836, 12554, 11, 420, 12554, 300, 576, 27817, 50502], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 319, "seek": 81768, "start": 820.4399999999999, "end": 822.76, "text": " our policy decision-making and so forth.", "tokens": [50502, 527, 3897, 3537, 12, 12402, 293, 370, 5220, 13, 50618], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 320, "seek": 81768, "start": 823.76, "end": 826.9599999999999, "text": " And those agents were also a part of this literature.", "tokens": [50668, 400, 729, 12554, 645, 611, 257, 644, 295, 341, 10394, 13, 50828], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 321, "seek": 81768, "start": 828.04, "end": 830.52, "text": " And what we're seeing today is,", "tokens": [50882, 400, 437, 321, 434, 2577, 965, 307, 11, 51006], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 322, "seek": 81768, "start": 830.52, "end": 833.0799999999999, "text": " we're one recognizing that Lawrence Lynch model", "tokens": [51006, 321, 434, 472, 18538, 300, 22787, 32345, 2316, 51134], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 323, "seek": 81768, "start": 833.0799999999999, "end": 834.8399999999999, "text": " is simulating human behavior.", "tokens": [51134, 307, 1034, 12162, 1952, 5223, 13, 51222], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 324, "seek": 81768, "start": 834.8399999999999, "end": 836.52, "text": " So it touches on all these agents,", "tokens": [51222, 407, 309, 17431, 322, 439, 613, 12554, 11, 51306], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 325, "seek": 81768, "start": 836.52, "end": 839.8, "text": " that it can be a foundational sort of architectural layer", "tokens": [51306, 300, 309, 393, 312, 257, 32195, 1333, 295, 26621, 4583, 51470], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 326, "seek": 81768, "start": 839.8, "end": 842.24, "text": " for creating all these different sorts of agents.", "tokens": [51470, 337, 4084, 439, 613, 819, 7527, 295, 12554, 13, 51592], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 327, "seek": 81768, "start": 842.24, "end": 845.0799999999999, "text": " But in terms of our initial application spaces,", "tokens": [51592, 583, 294, 2115, 295, 527, 5883, 3861, 7673, 11, 51734], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 328, "seek": 81768, "start": 845.0799999999999, "end": 846.28, "text": " we're seeing this split,", "tokens": [51734, 321, 434, 2577, 341, 7472, 11, 51794], "temperature": 0.0, "avg_logprob": -0.17932007230561356, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.0028421233873814344}, {"id": 329, "seek": 84628, "start": 846.28, "end": 847.36, "text": " where there's one community", "tokens": [50364, 689, 456, 311, 472, 1768, 50418], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 330, "seek": 84628, "start": 847.36, "end": 850.68, "text": " who's now deeply interested in agents using tools,", "tokens": [50418, 567, 311, 586, 8760, 3102, 294, 12554, 1228, 3873, 11, 50584], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 331, "seek": 84628, "start": 850.68, "end": 853.28, "text": " but another community that is deeply interested", "tokens": [50584, 457, 1071, 1768, 300, 307, 8760, 3102, 50714], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 332, "seek": 84628, "start": 853.28, "end": 855.8, "text": " in this idea of can we simulate?", "tokens": [50714, 294, 341, 1558, 295, 393, 321, 27817, 30, 50840], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 333, "seek": 84628, "start": 855.8, "end": 859.12, "text": " And this is where I would say like multi-agents", "tokens": [50840, 400, 341, 307, 689, 286, 576, 584, 411, 4825, 12, 559, 791, 51006], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 334, "seek": 84628, "start": 859.12, "end": 860.6, "text": " and as well as personalization", "tokens": [51006, 293, 382, 731, 382, 2973, 2144, 51080], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 335, "seek": 84628, "start": 860.6, "end": 864.0799999999999, "text": " is really starting to be highlighted in the simulation space", "tokens": [51080, 307, 534, 2891, 281, 312, 17173, 294, 264, 16575, 1901, 51254], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 336, "seek": 84628, "start": 864.0799999999999, "end": 866.9599999999999, "text": " because it's a little bit more directly incorporated", "tokens": [51254, 570, 309, 311, 257, 707, 857, 544, 3838, 21654, 51398], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 337, "seek": 84628, "start": 866.9599999999999, "end": 868.88, "text": " to the idea of simulations.", "tokens": [51398, 281, 264, 1558, 295, 35138, 13, 51494], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 338, "seek": 84628, "start": 868.88, "end": 870.28, "text": " Who are we simulating for?", "tokens": [51494, 2102, 366, 321, 1034, 12162, 337, 30, 51564], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 339, "seek": 84628, "start": 870.28, "end": 871.56, "text": " What are we simulating?", "tokens": [51564, 708, 366, 321, 1034, 12162, 30, 51628], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 340, "seek": 84628, "start": 871.56, "end": 873.1999999999999, "text": " Who are we simulating?", "tokens": [51628, 2102, 366, 321, 1034, 12162, 30, 51710], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 341, "seek": 84628, "start": 873.1999999999999, "end": 875.36, "text": " And by definition, simulations often happen", "tokens": [51710, 400, 538, 7123, 11, 35138, 2049, 1051, 51818], "temperature": 0.0, "avg_logprob": -0.11245123795636995, "compression_ratio": 1.8935361216730038, "no_speech_prob": 0.004607343580573797}, {"id": 342, "seek": 87536, "start": 875.44, "end": 876.92, "text": " in this multi-agent space.", "tokens": [50368, 294, 341, 4825, 12, 559, 317, 1901, 13, 50442], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 343, "seek": 87536, "start": 876.92, "end": 880.5600000000001, "text": " So those are the two communities that you're starting to see.", "tokens": [50442, 407, 729, 366, 264, 732, 4456, 300, 291, 434, 2891, 281, 536, 13, 50624], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 344, "seek": 87536, "start": 880.5600000000001, "end": 883.52, "text": " So generative agent certainly stands on the far end", "tokens": [50624, 407, 1337, 1166, 9461, 3297, 7382, 322, 264, 1400, 917, 50772], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 345, "seek": 87536, "start": 883.52, "end": 885.48, "text": " of the simulation-based agents,", "tokens": [50772, 295, 264, 16575, 12, 6032, 12554, 11, 50870], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 346, "seek": 87536, "start": 885.48, "end": 886.6800000000001, "text": " whereas some other projects", "tokens": [50870, 9735, 512, 661, 4455, 50930], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 347, "seek": 87536, "start": 886.6800000000001, "end": 888.52, "text": " that were also really cool last year,", "tokens": [50930, 300, 645, 611, 534, 1627, 1036, 1064, 11, 51022], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 348, "seek": 87536, "start": 888.52, "end": 891.8000000000001, "text": " I think a lot of sort of open AI, GPTs, I would say,", "tokens": [51022, 286, 519, 257, 688, 295, 1333, 295, 1269, 7318, 11, 26039, 33424, 11, 286, 576, 584, 11, 51186], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 349, "seek": 87536, "start": 891.8000000000001, "end": 893.84, "text": " are another end of the simulation agents", "tokens": [51186, 366, 1071, 917, 295, 264, 16575, 12554, 51288], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 350, "seek": 87536, "start": 893.84, "end": 896.44, "text": " or another end of tool-based agents.", "tokens": [51288, 420, 1071, 917, 295, 2290, 12, 6032, 12554, 13, 51418], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 351, "seek": 87536, "start": 896.44, "end": 899.76, "text": " So those are the axes that you're sort of seeing right now.", "tokens": [51418, 407, 729, 366, 264, 35387, 300, 291, 434, 1333, 295, 2577, 558, 586, 13, 51584], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 352, "seek": 87536, "start": 899.76, "end": 900.84, "text": " And sort of end by saying,", "tokens": [51584, 400, 1333, 295, 917, 538, 1566, 11, 51638], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 353, "seek": 87536, "start": 900.84, "end": 902.5600000000001, "text": " my hunch actually is again,", "tokens": [51638, 452, 47630, 767, 307, 797, 11, 51724], "temperature": 0.0, "avg_logprob": -0.16289748865015366, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0019850237295031548}, {"id": 354, "seek": 90256, "start": 902.56, "end": 905.76, "text": " because they all start from the same technical thesis", "tokens": [50364, 570, 436, 439, 722, 490, 264, 912, 6191, 22288, 50524], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 355, "seek": 90256, "start": 905.76, "end": 907.7199999999999, "text": " that we can simulate human behavior,", "tokens": [50524, 300, 321, 393, 27817, 1952, 5223, 11, 50622], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 356, "seek": 90256, "start": 907.7199999999999, "end": 908.88, "text": " they will merge in the end.", "tokens": [50622, 436, 486, 22183, 294, 264, 917, 13, 50680], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 357, "seek": 90256, "start": 908.88, "end": 911.7199999999999, "text": " I don't think they will be completely separate thesis", "tokens": [50680, 286, 500, 380, 519, 436, 486, 312, 2584, 4994, 22288, 50822], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 358, "seek": 90256, "start": 911.7199999999999, "end": 913.9599999999999, "text": " like five to 10 years down the line.", "tokens": [50822, 411, 1732, 281, 1266, 924, 760, 264, 1622, 13, 50934], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 359, "seek": 90256, "start": 913.9599999999999, "end": 915.68, "text": " It's more going to be the question of", "tokens": [50934, 467, 311, 544, 516, 281, 312, 264, 1168, 295, 51020], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 360, "seek": 90256, "start": 915.68, "end": 918.92, "text": " where are we going to make our short-term bets", "tokens": [51020, 689, 366, 321, 516, 281, 652, 527, 2099, 12, 7039, 39922, 51182], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 361, "seek": 90256, "start": 918.92, "end": 920.8399999999999, "text": " and what's going to be an interesting", "tokens": [51182, 293, 437, 311, 516, 281, 312, 364, 1880, 51278], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 362, "seek": 90256, "start": 920.8399999999999, "end": 924.7199999999999, "text": " and meaningful application space in the next two to five years.", "tokens": [51278, 293, 10995, 3861, 1901, 294, 264, 958, 732, 281, 1732, 924, 13, 51472], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 363, "seek": 90256, "start": 924.7199999999999, "end": 926.1199999999999, "text": " So that's the field that I'm seeing", "tokens": [51472, 407, 300, 311, 264, 2519, 300, 286, 478, 2577, 51542], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 364, "seek": 90256, "start": 926.1199999999999, "end": 928.68, "text": " and how it's developing right now.", "tokens": [51542, 293, 577, 309, 311, 6416, 558, 586, 13, 51670], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 365, "seek": 90256, "start": 928.68, "end": 930.04, "text": " Before we maybe go into that,", "tokens": [51670, 4546, 321, 1310, 352, 666, 300, 11, 51738], "temperature": 0.0, "avg_logprob": -0.09280904856595126, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.0023954748176038265}, {"id": 366, "seek": 93004, "start": 930.04, "end": 934.52, "text": " could you maybe describe how LLM specifically", "tokens": [50364, 727, 291, 1310, 6786, 577, 441, 43, 44, 4682, 50588], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 367, "seek": 93004, "start": 934.52, "end": 939.52, "text": " has affected the, especially the latter cohort, right?", "tokens": [50588, 575, 8028, 264, 11, 2318, 264, 18481, 28902, 11, 558, 30, 50838], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 368, "seek": 93004, "start": 939.52, "end": 941.8, "text": " What is the before and what is the after?", "tokens": [50838, 708, 307, 264, 949, 293, 437, 307, 264, 934, 30, 50952], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 369, "seek": 93004, "start": 941.8, "end": 944.5999999999999, "text": " And what is the magnitude of improvement", "tokens": [50952, 400, 437, 307, 264, 15668, 295, 10444, 51092], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 370, "seek": 93004, "start": 944.5999999999999, "end": 949.5999999999999, "text": " because of this technology that's now cheap enough to use?", "tokens": [51092, 570, 295, 341, 2899, 300, 311, 586, 7084, 1547, 281, 764, 30, 51342], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 371, "seek": 93004, "start": 949.5999999999999, "end": 950.48, "text": " Right.", "tokens": [51342, 1779, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 372, "seek": 93004, "start": 950.48, "end": 954.48, "text": " So Lawrence-Lenge Motor is really what made this possible.", "tokens": [51386, 407, 22787, 12, 43, 3032, 18495, 307, 534, 437, 1027, 341, 1944, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 373, "seek": 93004, "start": 954.48, "end": 958.0799999999999, "text": " That is really the fundamental fact that we needed.", "tokens": [51586, 663, 307, 534, 264, 8088, 1186, 300, 321, 2978, 13, 51766], "temperature": 0.0, "avg_logprob": -0.1685373472130817, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0004300648288335651}, {"id": 374, "seek": 95808, "start": 958.08, "end": 960.48, "text": " In the past, when you wanted to create,", "tokens": [50364, 682, 264, 1791, 11, 562, 291, 1415, 281, 1884, 11, 50484], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 375, "seek": 95808, "start": 960.48, "end": 962.72, "text": " and this goes for both types of agents,", "tokens": [50484, 293, 341, 1709, 337, 1293, 3467, 295, 12554, 11, 50596], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 376, "seek": 95808, "start": 962.72, "end": 964.5200000000001, "text": " tool-based and simulations,", "tokens": [50596, 2290, 12, 6032, 293, 35138, 11, 50686], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 377, "seek": 95808, "start": 964.5200000000001, "end": 966.6800000000001, "text": " what you really needed was,", "tokens": [50686, 437, 291, 534, 2978, 390, 11, 50794], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 378, "seek": 95808, "start": 968.08, "end": 970.08, "text": " you basically needed rule-based agents.", "tokens": [50864, 291, 1936, 2978, 4978, 12, 6032, 12554, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 379, "seek": 95808, "start": 970.08, "end": 971.5200000000001, "text": " That was the most common.", "tokens": [50964, 663, 390, 264, 881, 2689, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 380, "seek": 95808, "start": 971.5200000000001, "end": 974.32, "text": " And rule-based agents are sort of a more sophisticated way", "tokens": [51036, 400, 4978, 12, 6032, 12554, 366, 1333, 295, 257, 544, 16950, 636, 51176], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 381, "seek": 95808, "start": 974.32, "end": 977.36, "text": " of saying we're scripting all the behaviors.", "tokens": [51176, 295, 1566, 321, 434, 5755, 278, 439, 264, 15501, 13, 51328], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 382, "seek": 95808, "start": 977.36, "end": 981.2800000000001, "text": " So imagine you're building an NPC for a game.", "tokens": [51328, 407, 3811, 291, 434, 2390, 364, 28787, 337, 257, 1216, 13, 51524], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 383, "seek": 95808, "start": 981.2800000000001, "end": 984.76, "text": " A human author would actually write every sentence", "tokens": [51524, 316, 1952, 3793, 576, 767, 2464, 633, 8174, 51698], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 384, "seek": 95808, "start": 984.76, "end": 987.6400000000001, "text": " that the agent would say to the user, for instance.", "tokens": [51698, 300, 264, 9461, 576, 584, 281, 264, 4195, 11, 337, 5197, 13, 51842], "temperature": 0.0, "avg_logprob": -0.10232614298335842, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.001284020021557808}, {"id": 385, "seek": 98764, "start": 988.48, "end": 992.96, "text": " Human author would actually describe in either code or language,", "tokens": [50406, 10294, 3793, 576, 767, 6786, 294, 2139, 3089, 420, 2856, 11, 50630], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 386, "seek": 98764, "start": 992.96, "end": 994.92, "text": " if this happens, you do this.", "tokens": [50630, 498, 341, 2314, 11, 291, 360, 341, 13, 50728], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 387, "seek": 98764, "start": 994.92, "end": 997.8, "text": " So you basically design all the possible behaviors.", "tokens": [50728, 407, 291, 1936, 1715, 439, 264, 1944, 15501, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 388, "seek": 98764, "start": 998.88, "end": 1001.8, "text": " Now, that is expensive and not scalable, right?", "tokens": [50926, 823, 11, 300, 307, 5124, 293, 406, 38481, 11, 558, 30, 51072], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 389, "seek": 98764, "start": 1001.8, "end": 1005.84, "text": " And that was the fundamental block that we had.", "tokens": [51072, 400, 300, 390, 264, 8088, 3461, 300, 321, 632, 13, 51274], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 390, "seek": 98764, "start": 1005.84, "end": 1008.36, "text": " Now, tool-based agents had similar issues", "tokens": [51274, 823, 11, 2290, 12, 6032, 12554, 632, 2531, 2663, 51400], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 391, "seek": 98764, "start": 1008.36, "end": 1011.72, "text": " that in many of the contexts it had to operate,", "tokens": [51400, 300, 294, 867, 295, 264, 30628, 309, 632, 281, 9651, 11, 51568], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 392, "seek": 98764, "start": 1011.72, "end": 1013.8, "text": " it's not a very generalizable tool.", "tokens": [51568, 309, 311, 406, 257, 588, 2674, 22395, 2290, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1389891505241394, "compression_ratio": 1.5659574468085107, "no_speech_prob": 0.00012329980381764472}, {"id": 393, "seek": 101380, "start": 1013.8, "end": 1016.92, "text": " So if you sort of see how clippy", "tokens": [50364, 407, 498, 291, 1333, 295, 536, 577, 596, 48363, 50520], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 394, "seek": 101380, "start": 1016.92, "end": 1020.24, "text": " or even some of the agents that we're using today,", "tokens": [50520, 420, 754, 512, 295, 264, 12554, 300, 321, 434, 1228, 965, 11, 50686], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 395, "seek": 101380, "start": 1020.24, "end": 1021.92, "text": " very simple types of agents actually", "tokens": [50686, 588, 2199, 3467, 295, 12554, 767, 50770], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 396, "seek": 101380, "start": 1021.92, "end": 1024.48, "text": " are already embedded into our daily usage.", "tokens": [50770, 366, 1217, 16741, 666, 527, 5212, 14924, 13, 50898], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 397, "seek": 101380, "start": 1024.48, "end": 1027.6, "text": " So you may have used Google spreadsheet or Google doc.", "tokens": [50898, 407, 291, 815, 362, 1143, 3329, 27733, 420, 3329, 3211, 13, 51054], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 398, "seek": 101380, "start": 1027.6, "end": 1031.96, "text": " It would auto-complete in some very rudimentary way", "tokens": [51054, 467, 576, 8399, 12, 1112, 17220, 294, 512, 588, 32109, 2328, 822, 636, 51272], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 399, "seek": 101380, "start": 1031.96, "end": 1033.8799999999999, "text": " that actually could be considered in some ways", "tokens": [51272, 300, 767, 727, 312, 4888, 294, 512, 2098, 51368], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 400, "seek": 101380, "start": 1033.8799999999999, "end": 1037.2, "text": " an agent in this direction of tool-based agents.", "tokens": [51368, 364, 9461, 294, 341, 3513, 295, 2290, 12, 6032, 12554, 13, 51534], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 401, "seek": 101380, "start": 1037.2, "end": 1040.28, "text": " And the rules they were using so far were very simple.", "tokens": [51534, 400, 264, 4474, 436, 645, 1228, 370, 1400, 645, 588, 2199, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 402, "seek": 101380, "start": 1040.28, "end": 1041.8, "text": " It's not exactly rule-based,", "tokens": [51688, 467, 311, 406, 2293, 4978, 12, 6032, 11, 51764], "temperature": 0.0, "avg_logprob": -0.11747193336486816, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00024144133203662932}, {"id": 403, "seek": 104180, "start": 1041.8, "end": 1044.08, "text": " but it is something that was very much hard-coded", "tokens": [50364, 457, 309, 307, 746, 300, 390, 588, 709, 1152, 12, 66, 12340, 50478], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 404, "seek": 104180, "start": 1044.08, "end": 1045.68, "text": " into the agent's behavior.", "tokens": [50478, 666, 264, 9461, 311, 5223, 13, 50558], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 405, "seek": 104180, "start": 1045.68, "end": 1048.12, "text": " And there was some learning going on,", "tokens": [50558, 400, 456, 390, 512, 2539, 516, 322, 11, 50680], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 406, "seek": 104180, "start": 1048.12, "end": 1052.6399999999999, "text": " but there were very strict or simple statistics", "tokens": [50680, 457, 456, 645, 588, 10910, 420, 2199, 12523, 50906], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 407, "seek": 104180, "start": 1052.6399999999999, "end": 1054.2, "text": " that we were using.", "tokens": [50906, 300, 321, 645, 1228, 13, 50984], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 408, "seek": 104180, "start": 1054.2, "end": 1056.76, "text": " What large language model changes", "tokens": [50984, 708, 2416, 2856, 2316, 2962, 51112], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 409, "seek": 104180, "start": 1056.76, "end": 1059.2, "text": " is large language model gives us a single ingredient,", "tokens": [51112, 307, 2416, 2856, 2316, 2709, 505, 257, 2167, 14751, 11, 51234], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 410, "seek": 104180, "start": 1059.2, "end": 1063.52, "text": " which is given a micro-context, micromoment,", "tokens": [51234, 597, 307, 2212, 257, 4532, 12, 9000, 3828, 11, 3123, 4397, 298, 317, 11, 51450], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 411, "seek": 104180, "start": 1063.52, "end": 1068.52, "text": " let's say I'm sitting in this room talking to Joanne", "tokens": [51450, 718, 311, 584, 286, 478, 3798, 294, 341, 1808, 1417, 281, 3139, 12674, 51700], "temperature": 0.0, "avg_logprob": -0.18166362649143333, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.00011231801909161732}, {"id": 412, "seek": 106852, "start": 1068.84, "end": 1071.2, "text": " and about let's say generative agents", "tokens": [50380, 293, 466, 718, 311, 584, 1337, 1166, 12554, 50498], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 413, "seek": 106852, "start": 1071.2, "end": 1073.12, "text": " or simulations and so forth.", "tokens": [50498, 420, 35138, 293, 370, 5220, 13, 50594], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 414, "seek": 106852, "start": 1073.12, "end": 1076.32, "text": " Given that micromoment description,", "tokens": [50594, 18600, 300, 3123, 4397, 298, 317, 3855, 11, 50754], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 415, "seek": 106852, "start": 1076.32, "end": 1078.48, "text": " a language model is extremely good", "tokens": [50754, 257, 2856, 2316, 307, 4664, 665, 50862], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 416, "seek": 106852, "start": 1078.48, "end": 1081.8799999999999, "text": " at predicting the next moment, right?", "tokens": [50862, 412, 32884, 264, 958, 1623, 11, 558, 30, 51032], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 417, "seek": 106852, "start": 1081.8799999999999, "end": 1085.24, "text": " So what are the reasonable set of things", "tokens": [51032, 407, 437, 366, 264, 10585, 992, 295, 721, 51200], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 418, "seek": 106852, "start": 1085.24, "end": 1089.12, "text": " that June might say in this particular conversation", "tokens": [51200, 300, 6928, 1062, 584, 294, 341, 1729, 3761, 51394], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 419, "seek": 106852, "start": 1089.12, "end": 1090.84, "text": " given what he knows?", "tokens": [51394, 2212, 437, 415, 3255, 30, 51480], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 420, "seek": 106852, "start": 1090.84, "end": 1092.24, "text": " It's very good at doing that.", "tokens": [51480, 467, 311, 588, 665, 412, 884, 300, 13, 51550], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 421, "seek": 106852, "start": 1093.84, "end": 1097.68, "text": " That on its own is not a perfect agent", "tokens": [51630, 663, 322, 1080, 1065, 307, 406, 257, 2176, 9461, 51822], "temperature": 0.0, "avg_logprob": -0.11693307757377625, "compression_ratio": 1.5982142857142858, "no_speech_prob": 0.0015982277691364288}, {"id": 422, "seek": 109768, "start": 1097.68, "end": 1099.5600000000002, "text": " or it's not the complete ingredient", "tokens": [50364, 420, 309, 311, 406, 264, 3566, 14751, 50458], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 423, "seek": 109768, "start": 1099.5600000000002, "end": 1102.0800000000002, "text": " that you need to create these agents", "tokens": [50458, 300, 291, 643, 281, 1884, 613, 12554, 50584], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 424, "seek": 109768, "start": 1102.0800000000002, "end": 1105.4, "text": " that are meant to live for many, many years or decades.", "tokens": [50584, 300, 366, 4140, 281, 1621, 337, 867, 11, 867, 924, 420, 7878, 13, 50750], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 425, "seek": 109768, "start": 1105.4, "end": 1108.3200000000002, "text": " But they are the right ingredient", "tokens": [50750, 583, 436, 366, 264, 558, 14751, 50896], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 426, "seek": 109768, "start": 1108.3200000000002, "end": 1110.0, "text": " or building block that we need it", "tokens": [50896, 420, 2390, 3461, 300, 321, 643, 309, 50980], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 427, "seek": 109768, "start": 1110.0, "end": 1112.0800000000002, "text": " because that can be used to replace", "tokens": [50980, 570, 300, 393, 312, 1143, 281, 7406, 51084], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 428, "seek": 109768, "start": 1112.0800000000002, "end": 1115.24, "text": " what was in the past, manual authoring.", "tokens": [51084, 437, 390, 294, 264, 1791, 11, 9688, 3793, 278, 13, 51242], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 429, "seek": 109768, "start": 1116.24, "end": 1118.1200000000001, "text": " In the past, we had to manually author", "tokens": [51292, 682, 264, 1791, 11, 321, 632, 281, 16945, 3793, 51386], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 430, "seek": 109768, "start": 1118.1200000000001, "end": 1122.3200000000002, "text": " all the possible sequences given any micromoment,", "tokens": [51386, 439, 264, 1944, 22978, 2212, 604, 3123, 4397, 298, 317, 11, 51596], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 431, "seek": 109768, "start": 1122.3200000000002, "end": 1124.3600000000001, "text": " but large language model can come in.", "tokens": [51596, 457, 2416, 2856, 2316, 393, 808, 294, 13, 51698], "temperature": 0.0, "avg_logprob": -0.11011218133373796, "compression_ratio": 1.7198275862068966, "no_speech_prob": 0.0005188575596548617}, {"id": 432, "seek": 112436, "start": 1125.36, "end": 1129.3999999999999, "text": " So given that ingredient, what we really could do", "tokens": [50414, 407, 2212, 300, 14751, 11, 437, 321, 534, 727, 360, 50616], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 433, "seek": 112436, "start": 1129.3999999999999, "end": 1133.1599999999999, "text": " is bake in long-term memory and some reflection module", "tokens": [50616, 307, 16562, 294, 938, 12, 7039, 4675, 293, 512, 12914, 10088, 50804], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 434, "seek": 112436, "start": 1133.1599999999999, "end": 1135.3999999999999, "text": " on top of it and planning module.", "tokens": [50804, 322, 1192, 295, 309, 293, 5038, 10088, 13, 50916], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 435, "seek": 112436, "start": 1135.3999999999999, "end": 1137.84, "text": " So given the micro-ingredient", "tokens": [50916, 407, 2212, 264, 4532, 12, 278, 986, 1196, 51038], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 436, "seek": 112436, "start": 1138.76, "end": 1142.8, "text": " plus an agent architecture that we give it on top of it,", "tokens": [51084, 1804, 364, 9461, 9482, 300, 321, 976, 309, 322, 1192, 295, 309, 11, 51286], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 437, "seek": 112436, "start": 1142.8, "end": 1145.3999999999999, "text": " these agents can basically now start to function", "tokens": [51286, 613, 12554, 393, 1936, 586, 722, 281, 2445, 51416], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 438, "seek": 112436, "start": 1145.3999999999999, "end": 1147.9599999999998, "text": " as something that can operate in that", "tokens": [51416, 382, 746, 300, 393, 9651, 294, 300, 51544], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 439, "seek": 112436, "start": 1147.9599999999998, "end": 1150.7199999999998, "text": " in a world that's much like ours", "tokens": [51544, 294, 257, 1002, 300, 311, 709, 411, 11896, 51682], "temperature": 0.0, "avg_logprob": -0.17913441081623455, "compression_ratio": 1.6995073891625616, "no_speech_prob": 0.0002230506797786802}, {"id": 440, "seek": 115072, "start": 1150.76, "end": 1154.72, "text": " with a fairly decent degree of long-term coherence.", "tokens": [50366, 365, 257, 6457, 8681, 4314, 295, 938, 12, 7039, 26528, 655, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 441, "seek": 115072, "start": 1154.72, "end": 1155.8, "text": " So that's where we are", "tokens": [50564, 407, 300, 311, 689, 321, 366, 50618], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 442, "seek": 115072, "start": 1155.8, "end": 1157.64, "text": " and that's really the difference it made.", "tokens": [50618, 293, 300, 311, 534, 264, 2649, 309, 1027, 13, 50710], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 443, "seek": 115072, "start": 1157.64, "end": 1160.48, "text": " And I'd say this is sort of a zero to one difference,", "tokens": [50710, 400, 286, 1116, 584, 341, 307, 1333, 295, 257, 4018, 281, 472, 2649, 11, 50852], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 444, "seek": 115072, "start": 1160.48, "end": 1161.52, "text": " not a degree difference", "tokens": [50852, 406, 257, 4314, 2649, 50904], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 445, "seek": 115072, "start": 1161.52, "end": 1164.48, "text": " because before large language model, this was not possible.", "tokens": [50904, 570, 949, 2416, 2856, 2316, 11, 341, 390, 406, 1944, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 446, "seek": 115072, "start": 1165.84, "end": 1170.6000000000001, "text": " What else is, so we, large language models gave memory,", "tokens": [51120, 708, 1646, 307, 11, 370, 321, 11, 2416, 2856, 5245, 2729, 4675, 11, 51358], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 447, "seek": 115072, "start": 1170.6000000000001, "end": 1174.84, "text": " gave context, gave interactions to these agents.", "tokens": [51358, 2729, 4319, 11, 2729, 13280, 281, 613, 12554, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 448, "seek": 115072, "start": 1174.84, "end": 1179.24, "text": " What else in a perfect world would these agents have", "tokens": [51570, 708, 1646, 294, 257, 2176, 1002, 576, 613, 12554, 362, 51790], "temperature": 0.0, "avg_logprob": -0.1175704973715323, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.00039791123708710074}, {"id": 449, "seek": 117924, "start": 1179.24, "end": 1181.1200000000001, "text": " in order to better mimic the real world?", "tokens": [50364, 294, 1668, 281, 1101, 31075, 264, 957, 1002, 30, 50458], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 450, "seek": 117924, "start": 1181.1200000000001, "end": 1184.04, "text": " Like what's maybe in the next stop, just out of curiosity?", "tokens": [50458, 1743, 437, 311, 1310, 294, 264, 958, 1590, 11, 445, 484, 295, 18769, 30, 50604], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 451, "seek": 117924, "start": 1185.16, "end": 1187.08, "text": " Right, so to clarify, large language model", "tokens": [50660, 1779, 11, 370, 281, 17594, 11, 2416, 2856, 2316, 50756], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 452, "seek": 117924, "start": 1187.08, "end": 1188.36, "text": " doesn't actually have,", "tokens": [50756, 1177, 380, 767, 362, 11, 50820], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 453, "seek": 117924, "start": 1188.36, "end": 1190.88, "text": " so large language model provides one element.", "tokens": [50820, 370, 2416, 2856, 2316, 6417, 472, 4478, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 454, "seek": 117924, "start": 1190.88, "end": 1193.32, "text": " It's the micro sort of a module", "tokens": [50946, 467, 311, 264, 4532, 1333, 295, 257, 10088, 51068], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 455, "seek": 117924, "start": 1193.32, "end": 1195.44, "text": " for predicting the next sequence.", "tokens": [51068, 337, 32884, 264, 958, 8310, 13, 51174], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 456, "seek": 117924, "start": 1197.08, "end": 1198.56, "text": " It is the agent architecture", "tokens": [51256, 467, 307, 264, 9461, 9482, 51330], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 457, "seek": 117924, "start": 1198.56, "end": 1202.6, "text": " that actually ends up giving the memory and planning ability,", "tokens": [51330, 300, 767, 5314, 493, 2902, 264, 4675, 293, 5038, 3485, 11, 51532], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 458, "seek": 117924, "start": 1202.6, "end": 1205.56, "text": " but those two pair becomes a fantastic combination.", "tokens": [51532, 457, 729, 732, 6119, 3643, 257, 5456, 6562, 13, 51680], "temperature": 0.0, "avg_logprob": -0.1700741749889446, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.0012421563733369112}, {"id": 459, "seek": 120556, "start": 1206.32, "end": 1209.04, "text": " Now, going forward,", "tokens": [50402, 823, 11, 516, 2128, 11, 50538], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 460, "seek": 120556, "start": 1209.04, "end": 1212.12, "text": " what I do think is going to be interesting are,", "tokens": [50538, 437, 286, 360, 519, 307, 516, 281, 312, 1880, 366, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 461, "seek": 120556, "start": 1212.12, "end": 1213.96, "text": " so right now we're using large language model,", "tokens": [50692, 370, 558, 586, 321, 434, 1228, 2416, 2856, 2316, 11, 50784], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 462, "seek": 120556, "start": 1213.96, "end": 1217.6, "text": " but we may have all noticed that things like chatGPT", "tokens": [50784, 457, 321, 815, 362, 439, 5694, 300, 721, 411, 5081, 38, 47, 51, 50966], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 463, "seek": 120556, "start": 1217.6, "end": 1221.6, "text": " can now not only do it just language,", "tokens": [50966, 393, 586, 406, 787, 360, 309, 445, 2856, 11, 51166], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 464, "seek": 120556, "start": 1221.6, "end": 1224.48, "text": " but also other modality like image.", "tokens": [51166, 457, 611, 661, 1072, 1860, 411, 3256, 13, 51310], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 465, "seek": 120556, "start": 1225.8, "end": 1229.0, "text": " I think that's going to be really interesting, right?", "tokens": [51376, 286, 519, 300, 311, 516, 281, 312, 534, 1880, 11, 558, 30, 51536], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 466, "seek": 120556, "start": 1229.0, "end": 1232.1599999999999, "text": " So right now, let's say if you,", "tokens": [51536, 407, 558, 586, 11, 718, 311, 584, 498, 291, 11, 51694], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 467, "seek": 120556, "start": 1232.1599999999999, "end": 1234.24, "text": " and this is sort of based on my prior work", "tokens": [51694, 293, 341, 307, 1333, 295, 2361, 322, 452, 4059, 589, 51798], "temperature": 0.0, "avg_logprob": -0.1800262133280436, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.0005695066647604108}, {"id": 468, "seek": 123424, "start": 1234.28, "end": 1235.48, "text": " called Generative Agents,", "tokens": [50366, 1219, 15409, 1166, 2725, 791, 11, 50426], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 469, "seek": 123424, "start": 1235.48, "end": 1237.52, "text": " and we had this game world like sim ad", "tokens": [50426, 293, 321, 632, 341, 1216, 1002, 411, 1034, 614, 50528], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 470, "seek": 123424, "start": 1237.52, "end": 1239.24, "text": " that we call a smallville,", "tokens": [50528, 300, 321, 818, 257, 1359, 8386, 11, 50614], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 471, "seek": 123424, "start": 1239.24, "end": 1244.24, "text": " the way these agents perceived and operated in their world", "tokens": [50614, 264, 636, 613, 12554, 19049, 293, 20826, 294, 641, 1002, 50864], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 472, "seek": 123424, "start": 1244.4, "end": 1247.76, "text": " was basically by translating,", "tokens": [50872, 390, 1936, 538, 35030, 11, 51040], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 473, "seek": 123424, "start": 1247.76, "end": 1249.76, "text": " and like our system translating", "tokens": [51040, 293, 411, 527, 1185, 35030, 51140], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 474, "seek": 123424, "start": 1249.76, "end": 1252.44, "text": " the visual world into natural language.", "tokens": [51140, 264, 5056, 1002, 666, 3303, 2856, 13, 51274], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 475, "seek": 123424, "start": 1252.44, "end": 1254.36, "text": " So we would tell the agent,", "tokens": [51274, 407, 321, 576, 980, 264, 9461, 11, 51370], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 476, "seek": 123424, "start": 1254.36, "end": 1256.1200000000001, "text": " you are in your apartment,", "tokens": [51370, 291, 366, 294, 428, 9587, 11, 51458], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 477, "seek": 123424, "start": 1256.1200000000001, "end": 1260.4, "text": " or you are in the kitchen talking to someone.", "tokens": [51458, 420, 291, 366, 294, 264, 6525, 1417, 281, 1580, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 478, "seek": 123424, "start": 1260.4, "end": 1262.72, "text": " So we would actually take the visual world", "tokens": [51672, 407, 321, 576, 767, 747, 264, 5056, 1002, 51788], "temperature": 0.0, "avg_logprob": -0.2155632239121657, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0037028936203569174}, {"id": 479, "seek": 126272, "start": 1263.72, "end": 1267.0, "text": " and use our system to translate the visual world", "tokens": [50414, 293, 764, 527, 1185, 281, 13799, 264, 5056, 1002, 50578], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 480, "seek": 126272, "start": 1267.0, "end": 1268.44, "text": " into natural language,", "tokens": [50578, 666, 3303, 2856, 11, 50650], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 481, "seek": 126272, "start": 1268.44, "end": 1270.88, "text": " and then feeding it to the agent architecture", "tokens": [50650, 293, 550, 12919, 309, 281, 264, 9461, 9482, 50772], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 482, "seek": 126272, "start": 1270.88, "end": 1273.76, "text": " that would use our language model to process this.", "tokens": [50772, 300, 576, 764, 527, 2856, 2316, 281, 1399, 341, 13, 50916], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 483, "seek": 126272, "start": 1273.76, "end": 1277.2, "text": " But now with these models being able to deal", "tokens": [50916, 583, 586, 365, 613, 5245, 885, 1075, 281, 2028, 51088], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 484, "seek": 126272, "start": 1277.2, "end": 1280.3600000000001, "text": " with multi-modal aspect,", "tokens": [51088, 365, 4825, 12, 8014, 304, 4171, 11, 51246], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 485, "seek": 126272, "start": 1280.3600000000001, "end": 1283.48, "text": " we might actually be able to bypass that phase", "tokens": [51246, 321, 1062, 767, 312, 1075, 281, 24996, 300, 5574, 51402], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 486, "seek": 126272, "start": 1283.48, "end": 1286.0, "text": " and go straight from here is the visual world", "tokens": [51402, 293, 352, 2997, 490, 510, 307, 264, 5056, 1002, 51528], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 487, "seek": 126272, "start": 1286.0, "end": 1288.72, "text": " or space that you're seeing right now.", "tokens": [51528, 420, 1901, 300, 291, 434, 2577, 558, 586, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 488, "seek": 126272, "start": 1288.72, "end": 1291.2, "text": " That is your memory, now act on it.", "tokens": [51664, 663, 307, 428, 4675, 11, 586, 605, 322, 309, 13, 51788], "temperature": 0.0, "avg_logprob": -0.11638867180302458, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00026110548060387373}, {"id": 489, "seek": 129120, "start": 1292.16, "end": 1294.76, "text": " I think that's going to be potentially very powerful", "tokens": [50412, 286, 519, 300, 311, 516, 281, 312, 7263, 588, 4005, 50542], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 490, "seek": 129120, "start": 1294.76, "end": 1299.48, "text": " because in part, image is much richer to some,", "tokens": [50542, 570, 294, 644, 11, 3256, 307, 709, 29021, 281, 512, 11, 50778], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 491, "seek": 129120, "start": 1299.48, "end": 1300.6000000000001, "text": " it conveys a lot more.", "tokens": [50778, 309, 18053, 749, 257, 688, 544, 13, 50834], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 492, "seek": 129120, "start": 1300.6000000000001, "end": 1304.48, "text": " I do come from natural language processing background,", "tokens": [50834, 286, 360, 808, 490, 3303, 2856, 9007, 3678, 11, 51028], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 493, "seek": 129120, "start": 1304.48, "end": 1308.56, "text": " at least that's my other half of my sort of academic background.", "tokens": [51028, 412, 1935, 300, 311, 452, 661, 1922, 295, 452, 1333, 295, 7778, 3678, 13, 51232], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 494, "seek": 129120, "start": 1308.56, "end": 1311.2, "text": " So I have bias towards believing", "tokens": [51232, 407, 286, 362, 12577, 3030, 16594, 51364], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 495, "seek": 129120, "start": 1311.2, "end": 1312.8400000000001, "text": " the natural language is profound,", "tokens": [51364, 264, 3303, 2856, 307, 14382, 11, 51446], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 496, "seek": 129120, "start": 1312.8400000000001, "end": 1314.76, "text": " and I think that we're going to be,", "tokens": [51446, 293, 286, 519, 300, 321, 434, 516, 281, 312, 11, 51542], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 497, "seek": 129120, "start": 1314.76, "end": 1317.0800000000002, "text": " that will be the case going forward as well.", "tokens": [51542, 300, 486, 312, 264, 1389, 516, 2128, 382, 731, 13, 51658], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 498, "seek": 129120, "start": 1317.0800000000002, "end": 1319.0, "text": " But image does offer something", "tokens": [51658, 583, 3256, 775, 2626, 746, 51754], "temperature": 0.0, "avg_logprob": -0.14335004633123224, "compression_ratio": 1.6975806451612903, "no_speech_prob": 0.0003680215450003743}, {"id": 499, "seek": 131900, "start": 1319.0, "end": 1321.92, "text": " that just language alone does not.", "tokens": [50364, 300, 445, 2856, 3312, 775, 406, 13, 50510], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 500, "seek": 131900, "start": 1321.92, "end": 1324.0, "text": " So image is going to be a big thing.", "tokens": [50510, 407, 3256, 307, 516, 281, 312, 257, 955, 551, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 501, "seek": 131900, "start": 1324.0, "end": 1327.64, "text": " Now imagine the future video is going to be a big thing as well,", "tokens": [50614, 823, 3811, 264, 2027, 960, 307, 516, 281, 312, 257, 955, 551, 382, 731, 11, 50796], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 502, "seek": 131900, "start": 1327.64, "end": 1330.68, "text": " then gradually the more these agents", "tokens": [50796, 550, 13145, 264, 544, 613, 12554, 50948], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 503, "seek": 131900, "start": 1330.68, "end": 1332.84, "text": " will basically increasingly get more powerful", "tokens": [50948, 486, 1936, 12980, 483, 544, 4005, 51056], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 504, "seek": 131900, "start": 1332.84, "end": 1335.4, "text": " as this new modality gets piled on.", "tokens": [51056, 382, 341, 777, 1072, 1860, 2170, 6429, 292, 322, 13, 51184], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 505, "seek": 131900, "start": 1335.4, "end": 1338.32, "text": " So that's something that we should be looking forward to.", "tokens": [51184, 407, 300, 311, 746, 300, 321, 820, 312, 1237, 2128, 281, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 506, "seek": 131900, "start": 1338.32, "end": 1339.56, "text": " That's great.", "tokens": [51330, 663, 311, 869, 13, 51392], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 507, "seek": 131900, "start": 1339.56, "end": 1341.0, "text": " What are some on the downside,", "tokens": [51392, 708, 366, 512, 322, 264, 25060, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 508, "seek": 131900, "start": 1341.0, "end": 1342.92, "text": " what are some of the limitations", "tokens": [51464, 437, 366, 512, 295, 264, 15705, 51560], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 509, "seek": 131900, "start": 1343.88, "end": 1347.56, "text": " that you're seeing in terms of these agents,", "tokens": [51608, 300, 291, 434, 2577, 294, 2115, 295, 613, 12554, 11, 51792], "temperature": 0.0, "avg_logprob": -0.1428729978382078, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.000561301305424422}, {"id": 510, "seek": 134756, "start": 1347.56, "end": 1349.08, "text": " especially generative agents?", "tokens": [50364, 2318, 1337, 1166, 12554, 30, 50440], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 511, "seek": 134756, "start": 1350.24, "end": 1351.6399999999999, "text": " Right.", "tokens": [50498, 1779, 13, 50568], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 512, "seek": 134756, "start": 1351.6399999999999, "end": 1356.6399999999999, "text": " So there are limitations that I can mention", "tokens": [50568, 407, 456, 366, 15705, 300, 286, 393, 2152, 50818], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 513, "seek": 134756, "start": 1356.6399999999999, "end": 1360.2, "text": " just about sort of in the context of our work.", "tokens": [50818, 445, 466, 1333, 295, 294, 264, 4319, 295, 527, 589, 13, 50996], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 514, "seek": 134756, "start": 1360.2, "end": 1363.12, "text": " And then I think there are going to be interesting limitations", "tokens": [50996, 400, 550, 286, 519, 456, 366, 516, 281, 312, 1880, 15705, 51142], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 515, "seek": 134756, "start": 1363.12, "end": 1366.28, "text": " that are much more application specific.", "tokens": [51142, 300, 366, 709, 544, 3861, 2685, 13, 51300], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 516, "seek": 134756, "start": 1366.28, "end": 1368.52, "text": " So for generative agents today,", "tokens": [51300, 407, 337, 1337, 1166, 12554, 965, 11, 51412], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 517, "seek": 134756, "start": 1368.52, "end": 1370.96, "text": " certainly the technical limitation right now", "tokens": [51412, 3297, 264, 6191, 27432, 558, 586, 51534], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 518, "seek": 134756, "start": 1370.96, "end": 1373.32, "text": " might have to do with things like,", "tokens": [51534, 1062, 362, 281, 360, 365, 721, 411, 11, 51652], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 519, "seek": 134756, "start": 1373.32, "end": 1375.56, "text": " so you're using whether it's an open source.", "tokens": [51652, 370, 291, 434, 1228, 1968, 309, 311, 364, 1269, 4009, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20750119734783562, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.0013031905982643366}, {"id": 520, "seek": 137556, "start": 1375.56, "end": 1378.48, "text": " So right now we use OpenAI's model.", "tokens": [50364, 407, 558, 586, 321, 764, 7238, 48698, 311, 2316, 13, 50510], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 521, "seek": 137556, "start": 1378.48, "end": 1381.12, "text": " OpenAI has actually done a lot of work", "tokens": [50510, 7238, 48698, 575, 767, 1096, 257, 688, 295, 589, 50642], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 522, "seek": 137556, "start": 1381.12, "end": 1383.04, "text": " to make the model safer.", "tokens": [50642, 281, 652, 264, 2316, 15856, 13, 50738], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 523, "seek": 137556, "start": 1383.04, "end": 1386.3999999999999, "text": " And I think OpenAI, I think that was the right approach", "tokens": [50738, 400, 286, 519, 7238, 48698, 11, 286, 519, 300, 390, 264, 558, 3109, 50906], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 524, "seek": 137556, "start": 1386.3999999999999, "end": 1388.3999999999999, "text": " in the sense that what they really wanted to create", "tokens": [50906, 294, 264, 2020, 300, 437, 436, 534, 1415, 281, 1884, 51006], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 525, "seek": 137556, "start": 1388.3999999999999, "end": 1392.56, "text": " was these chatbots or agents or chatGPT", "tokens": [51006, 390, 613, 5081, 65, 1971, 420, 12554, 420, 5081, 38, 47, 51, 51214], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 526, "seek": 137556, "start": 1392.56, "end": 1396.08, "text": " that are a safe tool to use for most people.", "tokens": [51214, 300, 366, 257, 3273, 2290, 281, 764, 337, 881, 561, 13, 51390], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 527, "seek": 137556, "start": 1397.0, "end": 1399.12, "text": " Now, if you want to run a simulation", "tokens": [51436, 823, 11, 498, 291, 528, 281, 1190, 257, 16575, 51542], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 528, "seek": 137556, "start": 1399.12, "end": 1402.08, "text": " or create truly accurate and believable agents", "tokens": [51542, 420, 1884, 4908, 8559, 293, 1351, 17915, 12554, 51690], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 529, "seek": 137556, "start": 1402.08, "end": 1404.48, "text": " with something like chatGPT, however,", "tokens": [51690, 365, 746, 411, 5081, 38, 47, 51, 11, 4461, 11, 51810], "temperature": 0.0, "avg_logprob": -0.13278003533681235, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.00040395263931714}, {"id": 530, "seek": 140448, "start": 1404.48, "end": 1406.92, "text": " that could become a limitation", "tokens": [50364, 300, 727, 1813, 257, 27432, 50486], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 531, "seek": 140448, "start": 1406.92, "end": 1412.04, "text": " because what we really experience as humans", "tokens": [50486, 570, 437, 321, 534, 1752, 382, 6255, 50742], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 532, "seek": 140448, "start": 1412.04, "end": 1414.28, "text": " is we fight, we sometimes have conflicts,", "tokens": [50742, 307, 321, 2092, 11, 321, 2171, 362, 19807, 11, 50854], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 533, "seek": 140448, "start": 1414.28, "end": 1416.32, "text": " we disagree with each other.", "tokens": [50854, 321, 14091, 365, 1184, 661, 13, 50956], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 534, "seek": 140448, "start": 1416.32, "end": 1418.32, "text": " And that might not be something that's something", "tokens": [50956, 400, 300, 1062, 406, 312, 746, 300, 311, 746, 51056], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 535, "seek": 140448, "start": 1418.32, "end": 1420.64, "text": " like chatGPT that's been fine-tuned", "tokens": [51056, 411, 5081, 38, 47, 51, 300, 311, 668, 2489, 12, 83, 43703, 51172], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 536, "seek": 140448, "start": 1420.64, "end": 1423.28, "text": " to not behave that way to remain safe.", "tokens": [51172, 281, 406, 15158, 300, 636, 281, 6222, 3273, 13, 51304], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 537, "seek": 140448, "start": 1423.28, "end": 1425.16, "text": " It's something, it might not be something", "tokens": [51304, 467, 311, 746, 11, 309, 1062, 406, 312, 746, 51398], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 538, "seek": 140448, "start": 1425.16, "end": 1427.76, "text": " that these models would try to surface.", "tokens": [51398, 300, 613, 5245, 576, 853, 281, 3753, 13, 51528], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 539, "seek": 140448, "start": 1427.76, "end": 1431.8, "text": " And that could be a potential block", "tokens": [51528, 400, 300, 727, 312, 257, 3995, 3461, 51730], "temperature": 0.0, "avg_logprob": -0.14907097122044238, "compression_ratio": 1.7432432432432432, "no_speech_prob": 5.556912219617516e-05}, {"id": 540, "seek": 143180, "start": 1431.8, "end": 1435.6, "text": " in creating more accurate, more believable simulations", "tokens": [50364, 294, 4084, 544, 8559, 11, 544, 1351, 17915, 35138, 50554], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 541, "seek": 143180, "start": 1435.6, "end": 1437.76, "text": " or agents for that matter.", "tokens": [50554, 420, 12554, 337, 300, 1871, 13, 50662], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 542, "seek": 143180, "start": 1437.76, "end": 1439.8799999999999, "text": " So that's something that is one limitation", "tokens": [50662, 407, 300, 311, 746, 300, 307, 472, 27432, 50768], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 543, "seek": 143180, "start": 1439.8799999999999, "end": 1441.36, "text": " right now that we're seeing.", "tokens": [50768, 558, 586, 300, 321, 434, 2577, 13, 50842], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 544, "seek": 143180, "start": 1442.8799999999999, "end": 1446.04, "text": " An interesting way to tackle this, I think, going forward", "tokens": [50918, 1107, 1880, 636, 281, 14896, 341, 11, 286, 519, 11, 516, 2128, 51076], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 545, "seek": 143180, "start": 1446.04, "end": 1448.84, "text": " is to use open source models or other models", "tokens": [51076, 307, 281, 764, 1269, 4009, 5245, 420, 661, 5245, 51216], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 546, "seek": 143180, "start": 1448.84, "end": 1451.52, "text": " that have less of these fine-tuned nature.", "tokens": [51216, 300, 362, 1570, 295, 613, 2489, 12, 83, 43703, 3687, 13, 51350], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 547, "seek": 143180, "start": 1453.24, "end": 1455.36, "text": " But it's going to be highly dependent", "tokens": [51436, 583, 309, 311, 516, 281, 312, 5405, 12334, 51542], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 548, "seek": 143180, "start": 1455.36, "end": 1457.6, "text": " on the models that we'll be using for this.", "tokens": [51542, 322, 264, 5245, 300, 321, 603, 312, 1228, 337, 341, 13, 51654], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 549, "seek": 143180, "start": 1457.6, "end": 1460.48, "text": " So I think that's one thing to look forward to.", "tokens": [51654, 407, 286, 519, 300, 311, 472, 551, 281, 574, 2128, 281, 13, 51798], "temperature": 0.0, "avg_logprob": -0.10832886073900305, "compression_ratio": 1.716, "no_speech_prob": 0.0011327990796416998}, {"id": 550, "seek": 146048, "start": 1460.48, "end": 1464.1200000000001, "text": " Got it, got it, that's super helpful.", "tokens": [50364, 5803, 309, 11, 658, 309, 11, 300, 311, 1687, 4961, 13, 50546], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 551, "seek": 146048, "start": 1464.1200000000001, "end": 1467.48, "text": " And maybe one last question on the research side.", "tokens": [50546, 400, 1310, 472, 1036, 1168, 322, 264, 2132, 1252, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 552, "seek": 146048, "start": 1468.72, "end": 1471.1200000000001, "text": " When you think about future areas to explore", "tokens": [50776, 1133, 291, 519, 466, 2027, 3179, 281, 6839, 50896], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 553, "seek": 146048, "start": 1471.1200000000001, "end": 1475.32, "text": " for you specifically, what are some of the", "tokens": [50896, 337, 291, 4682, 11, 437, 366, 512, 295, 264, 51106], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 554, "seek": 146048, "start": 1478.16, "end": 1482.3600000000001, "text": " more narrow topics that you're hoping to dive deeper in?", "tokens": [51248, 544, 9432, 8378, 300, 291, 434, 7159, 281, 9192, 7731, 294, 30, 51458], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 555, "seek": 146048, "start": 1483.44, "end": 1484.32, "text": " Given the world.", "tokens": [51512, 18600, 264, 1002, 13, 51556], "temperature": 0.0, "avg_logprob": -0.23953723907470703, "compression_ratio": 1.4147727272727273, "no_speech_prob": 0.0027561825700104237}, {"id": 556, "seek": 148432, "start": 1485.32, "end": 1490.1599999999999, "text": " So ultimately, I think making the agents more accurate", "tokens": [50414, 407, 6284, 11, 286, 519, 1455, 264, 12554, 544, 8559, 50656], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 557, "seek": 148432, "start": 1492.04, "end": 1495.32, "text": " for these agents to be more accurate reflection of who we are,", "tokens": [50750, 337, 613, 12554, 281, 312, 544, 8559, 12914, 295, 567, 321, 366, 11, 50914], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 558, "seek": 148432, "start": 1495.32, "end": 1497.6399999999999, "text": " I think it's going to be a really interesting research", "tokens": [50914, 286, 519, 309, 311, 516, 281, 312, 257, 534, 1880, 2132, 51030], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 559, "seek": 148432, "start": 1497.6399999999999, "end": 1501.76, "text": " and I think it's going to, that's going to be an area", "tokens": [51030, 293, 286, 519, 309, 311, 516, 281, 11, 300, 311, 516, 281, 312, 364, 1859, 51236], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 560, "seek": 148432, "start": 1501.76, "end": 1504.6, "text": " that's going to have more of a research and broader impact.", "tokens": [51236, 300, 311, 516, 281, 362, 544, 295, 257, 2132, 293, 13227, 2712, 13, 51378], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 561, "seek": 148432, "start": 1505.96, "end": 1510.3999999999999, "text": " So right now, you may have seen the sort of simulation demo,", "tokens": [51446, 407, 558, 586, 11, 291, 815, 362, 1612, 264, 1333, 295, 16575, 10723, 11, 51668], "temperature": 0.0, "avg_logprob": -0.19638555314805772, "compression_ratio": 1.8556149732620322, "no_speech_prob": 0.00022337849077302963}, {"id": 562, "seek": 151040, "start": 1510.64, "end": 1514.64, "text": " the agents that live in that simulation are fictional,", "tokens": [50376, 264, 12554, 300, 1621, 294, 300, 16575, 366, 28911, 11, 50576], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 563, "seek": 151040, "start": 1514.64, "end": 1518.5600000000002, "text": " that we just, for instance, we have an agent named Isabella,", "tokens": [50576, 300, 321, 445, 11, 337, 5197, 11, 321, 362, 364, 9461, 4926, 35686, 9885, 11, 50772], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 564, "seek": 151040, "start": 1518.5600000000002, "end": 1521.48, "text": " we told Isabella that she is a cafe owner", "tokens": [50772, 321, 1907, 35686, 9885, 300, 750, 307, 257, 17773, 7289, 50918], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 565, "seek": 151040, "start": 1521.48, "end": 1524.68, "text": " and large language model basically makes up", "tokens": [50918, 293, 2416, 2856, 2316, 1936, 1669, 493, 51078], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 566, "seek": 151040, "start": 1524.68, "end": 1529.3200000000002, "text": " what a persona that is reasonable given that description.", "tokens": [51078, 437, 257, 12184, 300, 307, 10585, 2212, 300, 3855, 13, 51310], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 567, "seek": 151040, "start": 1529.3200000000002, "end": 1531.72, "text": " But I think it's going to be far more interesting", "tokens": [51310, 583, 286, 519, 309, 311, 516, 281, 312, 1400, 544, 1880, 51430], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 568, "seek": 151040, "start": 1531.72, "end": 1536.2800000000002, "text": " if we can make these simulations actually closely model", "tokens": [51430, 498, 321, 393, 652, 613, 35138, 767, 8185, 2316, 51658], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 569, "seek": 151040, "start": 1536.2800000000002, "end": 1538.8400000000001, "text": " our actual human communities.", "tokens": [51658, 527, 3539, 1952, 4456, 13, 51786], "temperature": 0.0, "avg_logprob": -0.13858125586258738, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006567732430994511}, {"id": 570, "seek": 153884, "start": 1538.84, "end": 1541.9599999999998, "text": " So it's not just fictional, but actually has groundings.", "tokens": [50364, 407, 309, 311, 406, 445, 28911, 11, 457, 767, 575, 2727, 1109, 13, 50520], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 571, "seek": 153884, "start": 1541.9599999999998, "end": 1544.6399999999999, "text": " That's going to open up from our perspective", "tokens": [50520, 663, 311, 516, 281, 1269, 493, 490, 527, 4585, 50654], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 572, "seek": 153884, "start": 1544.6399999999999, "end": 1547.56, "text": " an entirely new set of application spaces", "tokens": [50654, 364, 7696, 777, 992, 295, 3861, 7673, 50800], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 573, "seek": 153884, "start": 1547.56, "end": 1549.12, "text": " as well as research impact.", "tokens": [50800, 382, 731, 382, 2132, 2712, 13, 50878], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 574, "seek": 153884, "start": 1550.32, "end": 1551.8, "text": " This can be used, for instance,", "tokens": [50938, 639, 393, 312, 1143, 11, 337, 5197, 11, 51012], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 575, "seek": 153884, "start": 1551.8, "end": 1554.76, "text": " to actually model or predict markets", "tokens": [51012, 281, 767, 2316, 420, 6069, 8383, 51160], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 576, "seek": 153884, "start": 1554.76, "end": 1559.76, "text": " or it's going to be able to use two more closely personalized", "tokens": [51160, 420, 309, 311, 516, 281, 312, 1075, 281, 764, 732, 544, 8185, 28415, 51410], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 577, "seek": 153884, "start": 1560.1999999999998, "end": 1563.12, "text": " many of these agents for individual use cases.", "tokens": [51432, 867, 295, 613, 12554, 337, 2609, 764, 3331, 13, 51578], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 578, "seek": 153884, "start": 1563.12, "end": 1564.6, "text": " So that's something that we're looking forward to", "tokens": [51578, 407, 300, 311, 746, 300, 321, 434, 1237, 2128, 281, 51652], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 579, "seek": 153884, "start": 1564.6, "end": 1566.12, "text": " in terms of sort of a particular topic", "tokens": [51652, 294, 2115, 295, 1333, 295, 257, 1729, 4829, 51728], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 580, "seek": 153884, "start": 1566.12, "end": 1568.24, "text": " that we're diving into.", "tokens": [51728, 300, 321, 434, 20241, 666, 13, 51834], "temperature": 0.0, "avg_logprob": -0.10631560477889887, "compression_ratio": 1.68, "no_speech_prob": 0.00031496057636104524}, {"id": 581, "seek": 156824, "start": 1568.24, "end": 1570.32, "text": " That plug, of course, scaling up the agents.", "tokens": [50364, 663, 5452, 11, 295, 1164, 11, 21589, 493, 264, 12554, 13, 50468], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 582, "seek": 156824, "start": 1570.32, "end": 1573.16, "text": " I think that's another big one, but those two.", "tokens": [50468, 286, 519, 300, 311, 1071, 955, 472, 11, 457, 729, 732, 13, 50610], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 583, "seek": 156824, "start": 1573.16, "end": 1574.48, "text": " That makes sense.", "tokens": [50610, 663, 1669, 2020, 13, 50676], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 584, "seek": 156824, "start": 1574.48, "end": 1576.48, "text": " Now, one of the things that's missing", "tokens": [50676, 823, 11, 472, 295, 264, 721, 300, 311, 5361, 50776], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 585, "seek": 156824, "start": 1576.48, "end": 1581.48, "text": " in most AI technologies is like really the", "tokens": [50776, 294, 881, 7318, 7943, 307, 411, 534, 264, 51026], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 586, "seek": 156824, "start": 1582.44, "end": 1585.52, "text": " emotional part of how humans feel, right?", "tokens": [51074, 6863, 644, 295, 577, 6255, 841, 11, 558, 30, 51228], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 587, "seek": 156824, "start": 1585.52, "end": 1589.24, "text": " Like all of that data is largely not captured", "tokens": [51228, 1743, 439, 295, 300, 1412, 307, 11611, 406, 11828, 51414], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 588, "seek": 156824, "start": 1589.24, "end": 1592.64, "text": " and therefore not part of any kind of models today.", "tokens": [51414, 293, 4412, 406, 644, 295, 604, 733, 295, 5245, 965, 13, 51584], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 589, "seek": 156824, "start": 1593.56, "end": 1596.72, "text": " Language is one small output of what we have.", "tokens": [51630, 24445, 307, 472, 1359, 5598, 295, 437, 321, 362, 13, 51788], "temperature": 0.0, "avg_logprob": -0.18557187422965338, "compression_ratio": 1.5601659751037344, "no_speech_prob": 0.000141960583277978}, {"id": 590, "seek": 159672, "start": 1596.72, "end": 1599.84, "text": " It's a very important output for sure,", "tokens": [50364, 467, 311, 257, 588, 1021, 5598, 337, 988, 11, 50520], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 591, "seek": 159672, "start": 1599.84, "end": 1601.04, "text": " but it's still one small output.", "tokens": [50520, 457, 309, 311, 920, 472, 1359, 5598, 13, 50580], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 592, "seek": 159672, "start": 1601.04, "end": 1604.72, "text": " So I wonder how we might be able to incorporate", "tokens": [50580, 407, 286, 2441, 577, 321, 1062, 312, 1075, 281, 16091, 50764], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 593, "seek": 159672, "start": 1604.72, "end": 1607.22, "text": " some of the data around our emotions.", "tokens": [50764, 512, 295, 264, 1412, 926, 527, 8462, 13, 50889], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 594, "seek": 159672, "start": 1608.28, "end": 1609.2, "text": " I agree.", "tokens": [50942, 286, 3986, 13, 50988], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 595, "seek": 159672, "start": 1609.2, "end": 1610.58, "text": " Some thoughts in the future.", "tokens": [50988, 2188, 4598, 294, 264, 2027, 13, 51057], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 596, "seek": 159672, "start": 1612.2, "end": 1614.72, "text": " Maybe let's move on to the applications today", "tokens": [51138, 2704, 718, 311, 1286, 322, 281, 264, 5821, 965, 51264], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 597, "seek": 159672, "start": 1614.72, "end": 1618.14, "text": " since you talked about some of the challenges for agents.", "tokens": [51264, 1670, 291, 2825, 466, 512, 295, 264, 4759, 337, 12554, 13, 51435], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 598, "seek": 159672, "start": 1619.1200000000001, "end": 1622.48, "text": " Many organizations are thinking about", "tokens": [51484, 5126, 6150, 366, 1953, 466, 51652], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 599, "seek": 159672, "start": 1622.48, "end": 1624.2, "text": " how to use large language models today, right?", "tokens": [51652, 577, 281, 764, 2416, 2856, 5245, 965, 11, 558, 30, 51738], "temperature": 0.0, "avg_logprob": -0.13177666805758334, "compression_ratio": 1.6, "no_speech_prob": 8.885988791007549e-05}, {"id": 600, "seek": 162420, "start": 1624.2, "end": 1626.96, "text": " There's a huge amount of aspirations.", "tokens": [50364, 821, 311, 257, 2603, 2372, 295, 32458, 13, 50502], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 601, "seek": 162420, "start": 1626.96, "end": 1629.52, "text": " A subset of them are also thinking about", "tokens": [50502, 316, 25993, 295, 552, 366, 611, 1953, 466, 50630], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 602, "seek": 162420, "start": 1629.52, "end": 1632.3600000000001, "text": " what are some of the agent technology applications", "tokens": [50630, 437, 366, 512, 295, 264, 9461, 2899, 5821, 50772], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 603, "seek": 162420, "start": 1632.3600000000001, "end": 1635.88, "text": " that are viable within an enterprise,", "tokens": [50772, 300, 366, 22024, 1951, 364, 14132, 11, 50948], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 604, "seek": 162420, "start": 1635.88, "end": 1638.52, "text": " which has limitations around infrastructure,", "tokens": [50948, 597, 575, 15705, 926, 6896, 11, 51080], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 605, "seek": 162420, "start": 1638.52, "end": 1642.24, "text": " around data silos, security, and all that stuff.", "tokens": [51080, 926, 1412, 48893, 11, 3825, 11, 293, 439, 300, 1507, 13, 51266], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 606, "seek": 162420, "start": 1643.2, "end": 1645.64, "text": " Any particular areas where you've seen", "tokens": [51314, 2639, 1729, 3179, 689, 291, 600, 1612, 51436], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 607, "seek": 162420, "start": 1646.92, "end": 1649.88, "text": " companies be successful at using these technologies", "tokens": [51500, 3431, 312, 4406, 412, 1228, 613, 7943, 51648], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 608, "seek": 162420, "start": 1649.88, "end": 1650.8600000000001, "text": " in production?", "tokens": [51648, 294, 4265, 30, 51697], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 609, "seek": 162420, "start": 1651.8, "end": 1652.96, "text": " Right.", "tokens": [51744, 1779, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1854684165354525, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.0007787815411575139}, {"id": 610, "seek": 165296, "start": 1652.96, "end": 1654.56, "text": " So I think this is going to be incredibly", "tokens": [50364, 407, 286, 519, 341, 307, 516, 281, 312, 6252, 50444], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 611, "seek": 165296, "start": 1654.56, "end": 1658.3600000000001, "text": " like case-by-case answer.", "tokens": [50444, 411, 1389, 12, 2322, 12, 9765, 1867, 13, 50634], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 612, "seek": 165296, "start": 1658.3600000000001, "end": 1660.44, "text": " So let me think.", "tokens": [50634, 407, 718, 385, 519, 13, 50738], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 613, "seek": 165296, "start": 1662.32, "end": 1665.04, "text": " Or if not, like any hypothesis as to", "tokens": [50832, 1610, 498, 406, 11, 411, 604, 17291, 382, 281, 50968], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 614, "seek": 165296, "start": 1666.24, "end": 1668.6000000000001, "text": " where you might see the first", "tokens": [51028, 689, 291, 1062, 536, 264, 700, 51146], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 615, "seek": 165296, "start": 1668.6000000000001, "end": 1670.68, "text": " commercial deployments at scale.", "tokens": [51146, 6841, 7274, 1117, 412, 4373, 13, 51250], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 616, "seek": 165296, "start": 1671.72, "end": 1672.56, "text": " Right.", "tokens": [51302, 1779, 13, 51344], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 617, "seek": 165296, "start": 1675.24, "end": 1679.08, "text": " So there is something that I have.", "tokens": [51478, 407, 456, 307, 746, 300, 286, 362, 13, 51670], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 618, "seek": 165296, "start": 1679.08, "end": 1681.6000000000001, "text": " This is, there's a message that I have", "tokens": [51670, 639, 307, 11, 456, 311, 257, 3636, 300, 286, 362, 51796], "temperature": 0.0, "avg_logprob": -0.23771329672939806, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.00013737376139033586}, {"id": 619, "seek": 168160, "start": 1681.6, "end": 1684.32, "text": " in trying to communicate, I think, in different settings.", "tokens": [50364, 294, 1382, 281, 7890, 11, 286, 519, 11, 294, 819, 6257, 13, 50500], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 620, "seek": 168160, "start": 1684.32, "end": 1686.4399999999998, "text": " So this is not something I'm sort of", "tokens": [50500, 407, 341, 307, 406, 746, 286, 478, 1333, 295, 50606], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 621, "seek": 168160, "start": 1686.4399999999998, "end": 1687.84, "text": " conveying for the first time.", "tokens": [50606, 18053, 1840, 337, 264, 700, 565, 13, 50676], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 622, "seek": 168160, "start": 1688.9599999999998, "end": 1692.28, "text": " And my opinion has been getting updated,", "tokens": [50732, 400, 452, 4800, 575, 668, 1242, 10588, 11, 50898], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 623, "seek": 168160, "start": 1692.28, "end": 1694.3999999999999, "text": " but I think fundamentally I think this is right.", "tokens": [50898, 457, 286, 519, 17879, 286, 519, 341, 307, 558, 13, 51004], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 624, "seek": 168160, "start": 1694.3999999999999, "end": 1697.04, "text": " So the way I've been describing it is", "tokens": [51004, 407, 264, 636, 286, 600, 668, 16141, 309, 307, 51136], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 625, "seek": 168160, "start": 1697.04, "end": 1702.04, "text": " in human computer interaction or in most task settings,", "tokens": [51136, 294, 1952, 3820, 9285, 420, 294, 881, 5633, 6257, 11, 51386], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 626, "seek": 168160, "start": 1702.6399999999999, "end": 1704.1999999999998, "text": " there are two types of problems", "tokens": [51416, 456, 366, 732, 3467, 295, 2740, 51494], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 627, "seek": 168160, "start": 1704.1999999999998, "end": 1707.1399999999999, "text": " that we deploy our machines or agents in.", "tokens": [51494, 300, 321, 7274, 527, 8379, 420, 12554, 294, 13, 51641], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 628, "seek": 168160, "start": 1707.1399999999999, "end": 1710.48, "text": " One has very hard-edge problem spaces.", "tokens": [51641, 1485, 575, 588, 1152, 12, 12203, 1154, 7673, 13, 51808], "temperature": 0.0, "avg_logprob": -0.20781721510328688, "compression_ratio": 1.6381322957198443, "no_speech_prob": 0.0023546142037957907}, {"id": 629, "seek": 171048, "start": 1710.52, "end": 1713.0, "text": " These are things like, hey, order me pizza", "tokens": [50366, 1981, 366, 721, 411, 11, 4177, 11, 1668, 385, 8298, 50490], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 630, "seek": 171048, "start": 1713.0, "end": 1714.72, "text": " or buy me a plane ticket.", "tokens": [50490, 420, 2256, 385, 257, 5720, 10550, 13, 50576], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 631, "seek": 171048, "start": 1714.72, "end": 1718.3600000000001, "text": " These are tasks where there's a very concrete outcome", "tokens": [50576, 1981, 366, 9608, 689, 456, 311, 257, 588, 9859, 9700, 50758], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 632, "seek": 171048, "start": 1718.3600000000001, "end": 1721.16, "text": " and there often is a right or wrong answer", "tokens": [50758, 293, 456, 2049, 307, 257, 558, 420, 2085, 1867, 50898], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 633, "seek": 171048, "start": 1721.16, "end": 1723.64, "text": " that the agent has to achieve.", "tokens": [50898, 300, 264, 9461, 575, 281, 4584, 13, 51022], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 634, "seek": 171048, "start": 1723.64, "end": 1725.68, "text": " At least from the user's perspective,", "tokens": [51022, 1711, 1935, 490, 264, 4195, 311, 4585, 11, 51124], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 635, "seek": 171048, "start": 1725.68, "end": 1728.96, "text": " there is something that would absolutely be yes or no.", "tokens": [51124, 456, 307, 746, 300, 576, 3122, 312, 2086, 420, 572, 13, 51288], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 636, "seek": 171048, "start": 1730.24, "end": 1731.88, "text": " And then there are problem spaces", "tokens": [51352, 400, 550, 456, 366, 1154, 7673, 51434], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 637, "seek": 171048, "start": 1731.88, "end": 1734.8, "text": " where we have soft-edge problems.", "tokens": [51434, 689, 321, 362, 2787, 12, 12203, 2740, 13, 51580], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 638, "seek": 171048, "start": 1734.8, "end": 1737.84, "text": " These are problems where we can increasingly", "tokens": [51580, 1981, 366, 2740, 689, 321, 393, 12980, 51732], "temperature": 0.0, "avg_logprob": -0.135003544035412, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.0004954460891894996}, {"id": 639, "seek": 173784, "start": 1737.84, "end": 1740.52, "text": " co-climb towards sort of being better,", "tokens": [50364, 598, 12, 3474, 17306, 3030, 1333, 295, 885, 1101, 11, 50498], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 640, "seek": 173784, "start": 1740.52, "end": 1743.8, "text": " but at certain level it starts to actually become useful.", "tokens": [50498, 457, 412, 1629, 1496, 309, 3719, 281, 767, 1813, 4420, 13, 50662], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 641, "seek": 173784, "start": 1743.8, "end": 1745.76, "text": " So to make this intuition a little bit,", "tokens": [50662, 407, 281, 652, 341, 24002, 257, 707, 857, 11, 50760], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 642, "seek": 173784, "start": 1745.76, "end": 1748.08, "text": " to make this a little bit more intuitive here,", "tokens": [50760, 281, 652, 341, 257, 707, 857, 544, 21769, 510, 11, 50876], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 643, "seek": 173784, "start": 1748.08, "end": 1751.6799999999998, "text": " for instance, if I guess the worst possible case scenario", "tokens": [50876, 337, 5197, 11, 498, 286, 2041, 264, 5855, 1944, 1389, 9005, 51056], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 644, "seek": 173784, "start": 1751.6799999999998, "end": 1753.9199999999998, "text": " is I asked the agent to buy me a plane ticket", "tokens": [51056, 307, 286, 2351, 264, 9461, 281, 2256, 385, 257, 5720, 10550, 51168], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 645, "seek": 173784, "start": 1753.9199999999998, "end": 1755.8799999999999, "text": " and it bought me the wrong ticket", "tokens": [51168, 293, 309, 4243, 385, 264, 2085, 10550, 51266], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 646, "seek": 173784, "start": 1755.8799999999999, "end": 1757.76, "text": " that just goes to a different place,", "tokens": [51266, 300, 445, 1709, 281, 257, 819, 1081, 11, 51360], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 647, "seek": 173784, "start": 1757.76, "end": 1759.6, "text": " then that's like a heavy no.", "tokens": [51360, 550, 300, 311, 411, 257, 4676, 572, 13, 51452], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 648, "seek": 173784, "start": 1761.1999999999998, "end": 1765.28, "text": " Whereas let's say I asked the agent to sort of", "tokens": [51532, 13813, 718, 311, 584, 286, 2351, 264, 9461, 281, 1333, 295, 51736], "temperature": 0.0, "avg_logprob": -0.15997731483588784, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.0035370357800275087}, {"id": 649, "seek": 176528, "start": 1766.28, "end": 1769.08, "text": " simulate a behavior that is sort of fun", "tokens": [50414, 27817, 257, 5223, 300, 307, 1333, 295, 1019, 50554], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 650, "seek": 176528, "start": 1769.08, "end": 1770.6, "text": " so that when I'm in a game,", "tokens": [50554, 370, 300, 562, 286, 478, 294, 257, 1216, 11, 50630], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 651, "seek": 176528, "start": 1770.6, "end": 1773.08, "text": " this is sort of entertaining and interesting.", "tokens": [50630, 341, 307, 1333, 295, 20402, 293, 1880, 13, 50754], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 652, "seek": 176528, "start": 1773.08, "end": 1775.08, "text": " That might be something that the agent", "tokens": [50754, 663, 1062, 312, 746, 300, 264, 9461, 50854], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 653, "seek": 176528, "start": 1775.08, "end": 1776.72, "text": " doesn't need to be quite perfect in,", "tokens": [50854, 1177, 380, 643, 281, 312, 1596, 2176, 294, 11, 50936], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 654, "seek": 176528, "start": 1776.72, "end": 1779.12, "text": " but it can still get there quite quickly.", "tokens": [50936, 457, 309, 393, 920, 483, 456, 1596, 2661, 13, 51056], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 655, "seek": 176528, "start": 1779.12, "end": 1781.24, "text": " And then we can gradually improve.", "tokens": [51056, 400, 550, 321, 393, 13145, 3470, 13, 51162], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 656, "seek": 176528, "start": 1781.24, "end": 1785.0, "text": " Those two are the spaces that we can sort of,", "tokens": [51162, 3950, 732, 366, 264, 7673, 300, 321, 393, 1333, 295, 11, 51350], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 657, "seek": 176528, "start": 1785.0, "end": 1787.52, "text": " in terms of when we consider where to deploy", "tokens": [51350, 294, 2115, 295, 562, 321, 1949, 689, 281, 7274, 51476], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 658, "seek": 176528, "start": 1787.52, "end": 1790.08, "text": " or how these will actually make its first impact,", "tokens": [51476, 420, 577, 613, 486, 767, 652, 1080, 700, 2712, 11, 51604], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 659, "seek": 176528, "start": 1790.08, "end": 1793.08, "text": " we might actually be looking at those problem spaces first.", "tokens": [51604, 321, 1062, 767, 312, 1237, 412, 729, 1154, 7673, 700, 13, 51754], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 660, "seek": 176528, "start": 1793.08, "end": 1795.24, "text": " And these are the classes that I'm seeing.", "tokens": [51754, 400, 613, 366, 264, 5359, 300, 286, 478, 2577, 13, 51862], "temperature": 0.0, "avg_logprob": -0.08311796900051743, "compression_ratio": 1.7832167832167831, "no_speech_prob": 0.0008826850680634379}, {"id": 661, "seek": 179524, "start": 1795.24, "end": 1797.24, "text": " If I were to make my bet,", "tokens": [50364, 759, 286, 645, 281, 652, 452, 778, 11, 50464], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 662, "seek": 179524, "start": 1797.24, "end": 1800.2, "text": " agents will likely succeed first", "tokens": [50464, 12554, 486, 3700, 7754, 700, 50612], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 663, "seek": 179524, "start": 1800.2, "end": 1802.8, "text": " in the soft-edge problem spaces", "tokens": [50612, 294, 264, 2787, 12, 12203, 1154, 7673, 50742], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 664, "seek": 179524, "start": 1802.8, "end": 1805.4, "text": " and will gradually inch into making it work", "tokens": [50742, 293, 486, 13145, 7227, 666, 1455, 309, 589, 50872], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 665, "seek": 179524, "start": 1805.4, "end": 1807.48, "text": " in the hardest problem space.", "tokens": [50872, 294, 264, 13158, 1154, 1901, 13, 50976], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 666, "seek": 179524, "start": 1807.48, "end": 1809.56, "text": " This has been sort of an intuition", "tokens": [50976, 639, 575, 668, 1333, 295, 364, 24002, 51080], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 667, "seek": 179524, "start": 1809.56, "end": 1813.04, "text": " with agent research community for some time.", "tokens": [51080, 365, 9461, 2132, 1768, 337, 512, 565, 13, 51254], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 668, "seek": 179524, "start": 1813.04, "end": 1815.44, "text": " So when Clippy, for instance, failed.", "tokens": [51254, 407, 562, 2033, 48363, 11, 337, 5197, 11, 7612, 13, 51374], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 669, "seek": 179524, "start": 1816.52, "end": 1819.68, "text": " Our intuition there, at least from research perspective,", "tokens": [51428, 2621, 24002, 456, 11, 412, 1935, 490, 2132, 4585, 11, 51586], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 670, "seek": 179524, "start": 1819.68, "end": 1822.1200000000001, "text": " wasn't that these agents failed", "tokens": [51586, 2067, 380, 300, 613, 12554, 7612, 51708], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 671, "seek": 179524, "start": 1822.1200000000001, "end": 1825.08, "text": " because we didn't have the technology there.", "tokens": [51708, 570, 321, 994, 380, 362, 264, 2899, 456, 13, 51856], "temperature": 0.0, "avg_logprob": -0.12022706314369484, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.00015842480934225023}, {"id": 672, "seek": 182508, "start": 1825.08, "end": 1826.32, "text": " Certainly these were deployed", "tokens": [50364, 16628, 613, 645, 17826, 50426], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 673, "seek": 182508, "start": 1826.32, "end": 1828.84, "text": " and there were some confidence around the technology.", "tokens": [50426, 293, 456, 645, 512, 6687, 926, 264, 2899, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 674, "seek": 182508, "start": 1828.84, "end": 1832.3999999999999, "text": " But the problem there actually was with interaction,", "tokens": [50552, 583, 264, 1154, 456, 767, 390, 365, 9285, 11, 50730], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 675, "seek": 182508, "start": 1832.3999999999999, "end": 1836.52, "text": " that when agents are deployed in hard-edge problem spaces,", "tokens": [50730, 300, 562, 12554, 366, 17826, 294, 1152, 12, 12203, 1154, 7673, 11, 50936], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 676, "seek": 182508, "start": 1836.52, "end": 1839.04, "text": " it's often deployed in states where", "tokens": [50936, 309, 311, 2049, 17826, 294, 4368, 689, 51062], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 677, "seek": 182508, "start": 1839.96, "end": 1843.28, "text": " it actually has to have a fairly long chain of steps", "tokens": [51108, 309, 767, 575, 281, 362, 257, 6457, 938, 5021, 295, 4439, 51274], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 678, "seek": 182508, "start": 1843.28, "end": 1847.1999999999998, "text": " and fairly high, the risk were fairly high.", "tokens": [51274, 293, 6457, 1090, 11, 264, 3148, 645, 6457, 1090, 13, 51470], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 679, "seek": 182508, "start": 1847.1999999999998, "end": 1849.9199999999998, "text": " When it fails, the cost of correcting its error", "tokens": [51470, 1133, 309, 18199, 11, 264, 2063, 295, 47032, 1080, 6713, 51606], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 680, "seek": 182508, "start": 1849.9199999999998, "end": 1850.84, "text": " is actually quite high,", "tokens": [51606, 307, 767, 1596, 1090, 11, 51652], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 681, "seek": 182508, "start": 1850.84, "end": 1853.4399999999998, "text": " cost of auditing its error is actually quite high.", "tokens": [51652, 2063, 295, 2379, 1748, 1080, 6713, 307, 767, 1596, 1090, 13, 51782], "temperature": 0.0, "avg_logprob": -0.13207205859097568, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.00012532535765785724}, {"id": 682, "seek": 185344, "start": 1854.44, "end": 1856.04, "text": " So when these agents are deployed", "tokens": [50414, 407, 562, 613, 12554, 366, 17826, 50494], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 683, "seek": 185344, "start": 1856.04, "end": 1857.68, "text": " in hardest problem spaces,", "tokens": [50494, 294, 13158, 1154, 7673, 11, 50576], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 684, "seek": 185344, "start": 1857.68, "end": 1859.16, "text": " it has to reckon with the fact", "tokens": [50576, 309, 575, 281, 29548, 365, 264, 1186, 50650], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 685, "seek": 185344, "start": 1859.16, "end": 1862.28, "text": " that it will undoubtedly make mistakes.", "tokens": [50650, 300, 309, 486, 35211, 652, 8038, 13, 50806], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 686, "seek": 185344, "start": 1862.28, "end": 1864.0, "text": " And when it does make a mistake,", "tokens": [50806, 400, 562, 309, 775, 652, 257, 6146, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 687, "seek": 185344, "start": 1864.0, "end": 1865.92, "text": " it has to be increasingly auditable", "tokens": [50892, 309, 575, 281, 312, 12980, 2379, 16772, 50988], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 688, "seek": 185344, "start": 1865.92, "end": 1868.52, "text": " and controllable by the users", "tokens": [50988, 293, 45159, 712, 538, 264, 5022, 51118], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 689, "seek": 185344, "start": 1868.52, "end": 1871.6000000000001, "text": " so that the cost of correcting its error", "tokens": [51118, 370, 300, 264, 2063, 295, 47032, 1080, 6713, 51272], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 690, "seek": 185344, "start": 1871.6000000000001, "end": 1875.16, "text": " is not high enough that from the user's perspective,", "tokens": [51272, 307, 406, 1090, 1547, 300, 490, 264, 4195, 311, 4585, 11, 51450], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 691, "seek": 185344, "start": 1875.16, "end": 1878.96, "text": " the cost-benefit analysis basically has to make sense.", "tokens": [51450, 264, 2063, 12, 41605, 6845, 5215, 1936, 575, 281, 652, 2020, 13, 51640], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 692, "seek": 185344, "start": 1878.96, "end": 1882.1200000000001, "text": " And that's been a fundamental challenge with agents.", "tokens": [51640, 400, 300, 311, 668, 257, 8088, 3430, 365, 12554, 13, 51798], "temperature": 0.0, "avg_logprob": -0.11636127437557187, "compression_ratio": 1.6941176470588235, "no_speech_prob": 5.3903750085737556e-05}, {"id": 693, "seek": 188212, "start": 1882.2399999999998, "end": 1884.56, "text": " That's why in every era,", "tokens": [50370, 663, 311, 983, 294, 633, 4249, 11, 50486], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 694, "seek": 188212, "start": 1884.56, "end": 1888.2399999999998, "text": " we see the interest around agents spike for a while", "tokens": [50486, 321, 536, 264, 1179, 926, 12554, 21053, 337, 257, 1339, 50670], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 695, "seek": 188212, "start": 1888.2399999999998, "end": 1889.6, "text": " and then it quickly subsides", "tokens": [50670, 293, 550, 309, 2661, 2090, 1875, 50738], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 696, "seek": 188212, "start": 1889.6, "end": 1892.32, "text": " after like maybe a half a year or two a year.", "tokens": [50738, 934, 411, 1310, 257, 1922, 257, 1064, 420, 732, 257, 1064, 13, 50874], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 697, "seek": 188212, "start": 1892.32, "end": 1895.4399999999998, "text": " Now there's a real issue now though,", "tokens": [50874, 823, 456, 311, 257, 957, 2734, 586, 1673, 11, 51030], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 698, "seek": 188212, "start": 1895.4399999999998, "end": 1897.7199999999998, "text": " that given the large language model in the progress we saw", "tokens": [51030, 300, 2212, 264, 2416, 2856, 2316, 294, 264, 4205, 321, 1866, 51144], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 699, "seek": 188212, "start": 1897.7199999999998, "end": 1899.7199999999998, "text": " that this might not be the case this time", "tokens": [51144, 300, 341, 1062, 406, 312, 264, 1389, 341, 565, 51244], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 700, "seek": 188212, "start": 1899.7199999999998, "end": 1902.56, "text": " or at some point we might be able to make this work.", "tokens": [51244, 420, 412, 512, 935, 321, 1062, 312, 1075, 281, 652, 341, 589, 13, 51386], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 701, "seek": 188212, "start": 1902.56, "end": 1906.2399999999998, "text": " But for now, so I'm closely monitoring this", "tokens": [51386, 583, 337, 586, 11, 370, 286, 478, 8185, 11028, 341, 51570], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 702, "seek": 188212, "start": 1906.2399999999998, "end": 1907.9199999999998, "text": " as well and I think we all should.", "tokens": [51570, 382, 731, 293, 286, 519, 321, 439, 820, 13, 51654], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 703, "seek": 188212, "start": 1907.9199999999998, "end": 1909.3999999999999, "text": " I don't think we should just go and say,", "tokens": [51654, 286, 500, 380, 519, 321, 820, 445, 352, 293, 584, 11, 51728], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 704, "seek": 188212, "start": 1909.3999999999999, "end": 1910.56, "text": " because it didn't work before,", "tokens": [51728, 570, 309, 994, 380, 589, 949, 11, 51786], "temperature": 0.0, "avg_logprob": -0.16126371111188617, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.0010474961018189788}, {"id": 705, "seek": 191056, "start": 1910.56, "end": 1912.6799999999998, "text": " it's not going to work this time.", "tokens": [50364, 309, 311, 406, 516, 281, 589, 341, 565, 13, 50470], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 706, "seek": 191056, "start": 1912.6799999999998, "end": 1917.36, "text": " But my hunch is that we will likely see", "tokens": [50470, 583, 452, 47630, 307, 300, 321, 486, 3700, 536, 50704], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 707, "seek": 191056, "start": 1917.36, "end": 1919.6399999999999, "text": " very similar pattern arise,", "tokens": [50704, 588, 2531, 5102, 20288, 11, 50818], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 708, "seek": 191056, "start": 1919.6399999999999, "end": 1921.8, "text": " at least for the first of the future.", "tokens": [50818, 412, 1935, 337, 264, 700, 295, 264, 2027, 13, 50926], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 709, "seek": 191056, "start": 1921.8, "end": 1925.0, "text": " And we haven't quite dealt with the interaction problems", "tokens": [50926, 400, 321, 2378, 380, 1596, 15991, 365, 264, 9285, 2740, 51086], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 710, "seek": 191056, "start": 1925.0, "end": 1927.1599999999999, "text": " with those types of agents.", "tokens": [51086, 365, 729, 3467, 295, 12554, 13, 51194], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 711, "seek": 191056, "start": 1927.1599999999999, "end": 1930.28, "text": " So I think it's much safer to assume", "tokens": [51194, 407, 286, 519, 309, 311, 709, 15856, 281, 6552, 51350], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 712, "seek": 191056, "start": 1930.28, "end": 1932.84, "text": " that it is going to be in the soft edge problems basis.", "tokens": [51350, 300, 309, 307, 516, 281, 312, 294, 264, 2787, 4691, 2740, 5143, 13, 51478], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 713, "seek": 191056, "start": 1932.84, "end": 1935.9199999999998, "text": " And that's why in some areas, in many of the aspects,", "tokens": [51478, 400, 300, 311, 983, 294, 512, 3179, 11, 294, 867, 295, 264, 7270, 11, 51632], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 714, "seek": 191056, "start": 1935.9199999999998, "end": 1938.04, "text": " that's why our team was also interested", "tokens": [51632, 300, 311, 983, 527, 1469, 390, 611, 3102, 51738], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 715, "seek": 191056, "start": 1938.04, "end": 1939.6399999999999, "text": " in this idea of simulation.", "tokens": [51738, 294, 341, 1558, 295, 16575, 13, 51818], "temperature": 0.0, "avg_logprob": -0.12941005581715068, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.001324753277003765}, {"id": 716, "seek": 193964, "start": 1939.64, "end": 1942.8000000000002, "text": " Because simulation is sort of the prime example", "tokens": [50364, 1436, 16575, 307, 1333, 295, 264, 5835, 1365, 50522], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 717, "seek": 193964, "start": 1942.8000000000002, "end": 1944.8000000000002, "text": " of soft edge problem spaces,", "tokens": [50522, 295, 2787, 4691, 1154, 7673, 11, 50622], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 718, "seek": 193964, "start": 1944.8000000000002, "end": 1947.0, "text": " where the simulation has to be good enough", "tokens": [50622, 689, 264, 16575, 575, 281, 312, 665, 1547, 50732], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 719, "seek": 193964, "start": 1947.0, "end": 1949.0400000000002, "text": " for it to start being useful.", "tokens": [50732, 337, 309, 281, 722, 885, 4420, 13, 50834], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 720, "seek": 193964, "start": 1949.0400000000002, "end": 1952.48, "text": " That's also why I think a lot of really early promising AI", "tokens": [50834, 663, 311, 611, 983, 286, 519, 257, 688, 295, 534, 2440, 20257, 7318, 51006], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 721, "seek": 193964, "start": 1952.48, "end": 1955.3600000000001, "text": " startups that's going to go in the agent space", "tokens": [51006, 28041, 300, 311, 516, 281, 352, 294, 264, 9461, 1901, 51150], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 722, "seek": 193964, "start": 1955.3600000000001, "end": 1959.0800000000002, "text": " are places that does NPCs for games.", "tokens": [51150, 366, 3190, 300, 775, 28787, 82, 337, 2813, 13, 51336], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 723, "seek": 193964, "start": 1959.0800000000002, "end": 1962.0800000000002, "text": " Because those are very safe soft edge problem spaces", "tokens": [51336, 1436, 729, 366, 588, 3273, 2787, 4691, 1154, 7673, 51486], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 724, "seek": 193964, "start": 1962.0800000000002, "end": 1964.3600000000001, "text": " where the agents can fail, but that's okay.", "tokens": [51486, 689, 264, 12554, 393, 3061, 11, 457, 300, 311, 1392, 13, 51600], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 725, "seek": 193964, "start": 1965.3200000000002, "end": 1967.6200000000001, "text": " And gradually we'll sort of go to the other area as well.", "tokens": [51648, 400, 13145, 321, 603, 1333, 295, 352, 281, 264, 661, 1859, 382, 731, 13, 51763], "temperature": 0.0, "avg_logprob": -0.12593190282837957, "compression_ratio": 1.7192307692307693, "no_speech_prob": 9.609342669136822e-05}, {"id": 726, "seek": 196762, "start": 1967.62, "end": 1970.26, "text": " But I think that's where the impact is going to start", "tokens": [50364, 583, 286, 519, 300, 311, 689, 264, 2712, 307, 516, 281, 722, 50496], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 727, "seek": 196762, "start": 1970.26, "end": 1971.6599999999999, "text": " in the next couple of years.", "tokens": [50496, 294, 264, 958, 1916, 295, 924, 13, 50566], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 728, "seek": 196762, "start": 1973.1, "end": 1978.1, "text": " I also think just seeing the startups in this space,", "tokens": [50638, 286, 611, 519, 445, 2577, 264, 28041, 294, 341, 1901, 11, 50888], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 729, "seek": 196762, "start": 1978.7399999999998, "end": 1983.7399999999998, "text": " in sectors and functions that allow for failure,", "tokens": [50920, 294, 18373, 293, 6828, 300, 2089, 337, 7763, 11, 51170], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 730, "seek": 196762, "start": 1984.3799999999999, "end": 1988.4199999999998, "text": " like you said, include things like marketing.", "tokens": [51202, 411, 291, 848, 11, 4090, 721, 411, 6370, 13, 51404], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 731, "seek": 196762, "start": 1989.26, "end": 1992.5, "text": " Where if you market incorrectly,", "tokens": [51446, 2305, 498, 291, 2142, 42892, 11, 51608], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 732, "seek": 196762, "start": 1992.5, "end": 1994.78, "text": " it's not that big of a deal.", "tokens": [51608, 309, 311, 406, 300, 955, 295, 257, 2028, 13, 51722], "temperature": 0.0, "avg_logprob": -0.17505992213381996, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0003511049144435674}, {"id": 733, "seek": 199478, "start": 1994.78, "end": 1999.26, "text": " If you write the wrong code,", "tokens": [50364, 759, 291, 2464, 264, 2085, 3089, 11, 50588], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 734, "seek": 199478, "start": 1999.26, "end": 2001.58, "text": " that's probably going to be a bigger deal.", "tokens": [50588, 300, 311, 1391, 516, 281, 312, 257, 3801, 2028, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 735, "seek": 199478, "start": 2001.58, "end": 2006.3, "text": " If you pick the wrong security features, that's a huge deal.", "tokens": [50704, 759, 291, 1888, 264, 2085, 3825, 4122, 11, 300, 311, 257, 2603, 2028, 13, 50940], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 736, "seek": 199478, "start": 2006.3, "end": 2008.26, "text": " If you pick the wrong things for healthcare,", "tokens": [50940, 759, 291, 1888, 264, 2085, 721, 337, 8884, 11, 51038], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 737, "seek": 199478, "start": 2008.26, "end": 2009.8999999999999, "text": " that's an even bigger deal.", "tokens": [51038, 300, 311, 364, 754, 3801, 2028, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 738, "seek": 199478, "start": 2009.8999999999999, "end": 2013.8999999999999, "text": " So there are degrees of fault tolerance", "tokens": [51120, 407, 456, 366, 5310, 295, 7441, 23368, 51320], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 739, "seek": 199478, "start": 2013.8999999999999, "end": 2015.94, "text": " within the enterprise.", "tokens": [51320, 1951, 264, 14132, 13, 51422], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 740, "seek": 199478, "start": 2015.94, "end": 2016.94, "text": " That's one thing.", "tokens": [51422, 663, 311, 472, 551, 13, 51472], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 741, "seek": 199478, "start": 2016.94, "end": 2019.46, "text": " And the second on the consumer side,", "tokens": [51472, 400, 264, 1150, 322, 264, 9711, 1252, 11, 51598], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 742, "seek": 199478, "start": 2019.46, "end": 2023.34, "text": " especially if the agents are just assisting consumers", "tokens": [51598, 2318, 498, 264, 12554, 366, 445, 40368, 11883, 51792], "temperature": 0.0, "avg_logprob": -0.1376453437427483, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00022676779190078378}, {"id": 743, "seek": 202334, "start": 2023.34, "end": 2026.3999999999999, "text": " by not executing on anything.", "tokens": [50364, 538, 406, 32368, 322, 1340, 13, 50517], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 744, "seek": 202334, "start": 2027.6599999999999, "end": 2029.4599999999998, "text": " That could probably also work.", "tokens": [50580, 663, 727, 1391, 611, 589, 13, 50670], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 745, "seek": 202334, "start": 2029.4599999999998, "end": 2032.1399999999999, "text": " For example, there's a company called Rewind,", "tokens": [50670, 1171, 1365, 11, 456, 311, 257, 2237, 1219, 497, 1023, 471, 11, 50804], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 746, "seek": 202334, "start": 2032.1399999999999, "end": 2035.74, "text": " which is using some of the agent technologies, I believe.", "tokens": [50804, 597, 307, 1228, 512, 295, 264, 9461, 7943, 11, 286, 1697, 13, 50984], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 747, "seek": 202334, "start": 2035.74, "end": 2038.78, "text": " And they're getting a bunch of consumer demand,", "tokens": [50984, 400, 436, 434, 1242, 257, 3840, 295, 9711, 4733, 11, 51136], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 748, "seek": 202334, "start": 2038.78, "end": 2042.98, "text": " but what consumers are doing is just searching", "tokens": [51136, 457, 437, 11883, 366, 884, 307, 445, 10808, 51346], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 749, "seek": 202334, "start": 2042.98, "end": 2046.1599999999999, "text": " for a behavior that they have had before.", "tokens": [51346, 337, 257, 5223, 300, 436, 362, 632, 949, 13, 51505], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 750, "seek": 202334, "start": 2047.3799999999999, "end": 2051.42, "text": " And this product is helping them do that", "tokens": [51566, 400, 341, 1674, 307, 4315, 552, 360, 300, 51768], "temperature": 0.0, "avg_logprob": -0.1662094137641821, "compression_ratio": 1.5132743362831858, "no_speech_prob": 0.00041703740134835243}, {"id": 751, "seek": 205142, "start": 2051.46, "end": 2055.78, "text": " versus do anything real world, really.", "tokens": [50366, 5717, 360, 1340, 957, 1002, 11, 534, 13, 50582], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 752, "seek": 205142, "start": 2055.78, "end": 2056.62, "text": " Interesting.", "tokens": [50582, 14711, 13, 50624], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 753, "seek": 205142, "start": 2058.26, "end": 2059.42, "text": " But that's super.", "tokens": [50706, 583, 300, 311, 1687, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 754, "seek": 205142, "start": 2059.42, "end": 2063.66, "text": " The way that you frame it is very useful.", "tokens": [50764, 440, 636, 300, 291, 3920, 309, 307, 588, 4420, 13, 50976], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 755, "seek": 205142, "start": 2064.5, "end": 2069.06, "text": " What about just from an architecture standpoint,", "tokens": [51018, 708, 466, 445, 490, 364, 9482, 15827, 11, 51246], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 756, "seek": 205142, "start": 2069.06, "end": 2073.7400000000002, "text": " large language models enabled by transformer architectures?", "tokens": [51246, 2416, 2856, 5245, 15172, 538, 31782, 6331, 1303, 30, 51480], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 757, "seek": 205142, "start": 2074.7400000000002, "end": 2076.7400000000002, "text": " This is a whole different direction.", "tokens": [51530, 639, 307, 257, 1379, 819, 3513, 13, 51630], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 758, "seek": 205142, "start": 2076.7400000000002, "end": 2079.54, "text": " We're already seeing companies that are saying,", "tokens": [51630, 492, 434, 1217, 2577, 3431, 300, 366, 1566, 11, 51770], "temperature": 0.0, "avg_logprob": -0.2235407327350817, "compression_ratio": 1.4734299516908214, "no_speech_prob": 0.001430693781003356}, {"id": 759, "seek": 207954, "start": 2079.54, "end": 2082.18, "text": " hey, transformers are not the most efficient.", "tokens": [50364, 4177, 11, 4088, 433, 366, 406, 264, 881, 7148, 13, 50496], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 760, "seek": 207954, "start": 2083.3, "end": 2084.9, "text": " Inference costs are very high.", "tokens": [50552, 682, 5158, 5497, 366, 588, 1090, 13, 50632], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 761, "seek": 207954, "start": 2086.02, "end": 2088.54, "text": " Let's look at the next thing.", "tokens": [50688, 961, 311, 574, 412, 264, 958, 551, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 762, "seek": 207954, "start": 2088.54, "end": 2091.66, "text": " Have you spent much time thinking about that?", "tokens": [50814, 3560, 291, 4418, 709, 565, 1953, 466, 300, 30, 50970], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 763, "seek": 207954, "start": 2091.66, "end": 2095.2599999999998, "text": " And if so, any impact to the work that you're doing?", "tokens": [50970, 400, 498, 370, 11, 604, 2712, 281, 264, 589, 300, 291, 434, 884, 30, 51150], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 764, "seek": 207954, "start": 2096.46, "end": 2097.3, "text": " Right.", "tokens": [51210, 1779, 13, 51252], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 765, "seek": 207954, "start": 2097.3, "end": 2101.22, "text": " So certainly a next sort of model", "tokens": [51252, 407, 3297, 257, 958, 1333, 295, 2316, 51448], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 766, "seek": 207954, "start": 2101.22, "end": 2102.58, "text": " that we're going to be banking on,", "tokens": [51448, 300, 321, 434, 516, 281, 312, 18261, 322, 11, 51516], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 767, "seek": 207954, "start": 2102.58, "end": 2105.18, "text": " I think that always is an important topic.", "tokens": [51516, 286, 519, 300, 1009, 307, 364, 1021, 4829, 13, 51646], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 768, "seek": 207954, "start": 2105.18, "end": 2107.5, "text": " And that's something that I think we as a community", "tokens": [51646, 400, 300, 311, 746, 300, 286, 519, 321, 382, 257, 1768, 51762], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 769, "seek": 207954, "start": 2107.5, "end": 2109.1, "text": " always has to sort of monitor,", "tokens": [51762, 1009, 575, 281, 1333, 295, 6002, 11, 51842], "temperature": 0.0, "avg_logprob": -0.14761326455662394, "compression_ratio": 1.6544715447154472, "no_speech_prob": 0.0002063382271444425}, {"id": 770, "seek": 210910, "start": 2109.1, "end": 2110.7, "text": " because I think you're right,", "tokens": [50364, 570, 286, 519, 291, 434, 558, 11, 50444], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 771, "seek": 210910, "start": 2110.7, "end": 2113.14, "text": " that transformer is not going to be the end model", "tokens": [50444, 300, 31782, 307, 406, 516, 281, 312, 264, 917, 2316, 50566], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 772, "seek": 210910, "start": 2113.14, "end": 2116.38, "text": " that will be hopefully, I mean, not on what.", "tokens": [50566, 300, 486, 312, 4696, 11, 286, 914, 11, 406, 322, 437, 13, 50728], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 773, "seek": 210910, "start": 2116.38, "end": 2118.62, "text": " The hope here is that we wouldn't be using transformer", "tokens": [50728, 440, 1454, 510, 307, 300, 321, 2759, 380, 312, 1228, 31782, 50840], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 774, "seek": 210910, "start": 2118.62, "end": 2119.7, "text": " 10 years down the line.", "tokens": [50840, 1266, 924, 760, 264, 1622, 13, 50894], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 775, "seek": 210910, "start": 2121.18, "end": 2124.5, "text": " But one way that we do view this is,", "tokens": [50968, 583, 472, 636, 300, 321, 360, 1910, 341, 307, 11, 51134], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 776, "seek": 210910, "start": 2124.5, "end": 2127.22, "text": " this is very much like a programmer's way", "tokens": [51134, 341, 307, 588, 709, 411, 257, 32116, 311, 636, 51270], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 777, "seek": 210910, "start": 2127.22, "end": 2128.06, "text": " of looking at this.", "tokens": [51270, 295, 1237, 412, 341, 13, 51312], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 778, "seek": 210910, "start": 2128.06, "end": 2130.38, "text": " We view this in abstractions, right?", "tokens": [51312, 492, 1910, 341, 294, 12649, 626, 11, 558, 30, 51428], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 779, "seek": 210910, "start": 2130.38, "end": 2133.5, "text": " So what transformer has gotten us right now", "tokens": [51428, 407, 437, 31782, 575, 5768, 505, 558, 586, 51584], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 780, "seek": 210910, "start": 2133.5, "end": 2136.2999999999997, "text": " is this amazing capacity for reasoning", "tokens": [51584, 307, 341, 2243, 6042, 337, 21577, 51724], "temperature": 0.0, "avg_logprob": -0.16265370295597956, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.00038562389090657234}, {"id": 781, "seek": 213630, "start": 2136.3, "end": 2139.54, "text": " and processing information and generating information.", "tokens": [50364, 293, 9007, 1589, 293, 17746, 1589, 13, 50526], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 782, "seek": 213630, "start": 2140.38, "end": 2143.6200000000003, "text": " So it might be the case that in the future,", "tokens": [50568, 407, 309, 1062, 312, 264, 1389, 300, 294, 264, 2027, 11, 50730], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 783, "seek": 213630, "start": 2143.6200000000003, "end": 2146.5800000000004, "text": " that task will be done by even better models.", "tokens": [50730, 300, 5633, 486, 312, 1096, 538, 754, 1101, 5245, 13, 50878], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 784, "seek": 213630, "start": 2146.5800000000004, "end": 2148.94, "text": " And hopefully that's going to be the case.", "tokens": [50878, 400, 4696, 300, 311, 516, 281, 312, 264, 1389, 13, 50996], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 785, "seek": 213630, "start": 2148.94, "end": 2151.82, "text": " But for the sake of building applications,", "tokens": [50996, 583, 337, 264, 9717, 295, 2390, 5821, 11, 51140], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 786, "seek": 213630, "start": 2151.82, "end": 2153.78, "text": " it is true that we can sort of view this", "tokens": [51140, 309, 307, 2074, 300, 321, 393, 1333, 295, 1910, 341, 51238], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 787, "seek": 213630, "start": 2153.78, "end": 2155.6200000000003, "text": " as a layer of abstraction.", "tokens": [51238, 382, 257, 4583, 295, 37765, 13, 51330], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 788, "seek": 213630, "start": 2155.6200000000003, "end": 2157.82, "text": " That there might be some other technology", "tokens": [51330, 663, 456, 1062, 312, 512, 661, 2899, 51440], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 789, "seek": 213630, "start": 2157.82, "end": 2160.6200000000003, "text": " that's going to be powering it in the future,", "tokens": [51440, 300, 311, 516, 281, 312, 1347, 278, 309, 294, 264, 2027, 11, 51580], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 790, "seek": 213630, "start": 2160.6200000000003, "end": 2162.1400000000003, "text": " but really what we're focusing on", "tokens": [51580, 457, 534, 437, 321, 434, 8416, 322, 51656], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 791, "seek": 213630, "start": 2162.1400000000003, "end": 2164.82, "text": " is the capacity and the modality.", "tokens": [51656, 307, 264, 6042, 293, 264, 1072, 1860, 13, 51790], "temperature": 0.0, "avg_logprob": -0.09112116495768229, "compression_ratio": 1.7874015748031495, "no_speech_prob": 0.0008553622174076736}, {"id": 792, "seek": 216482, "start": 2164.82, "end": 2167.7000000000003, "text": " What kind of reasoning, using what modality,", "tokens": [50364, 708, 733, 295, 21577, 11, 1228, 437, 1072, 1860, 11, 50508], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 793, "seek": 216482, "start": 2167.7000000000003, "end": 2170.3, "text": " can these technologies that exist today do?", "tokens": [50508, 393, 613, 7943, 300, 2514, 965, 360, 30, 50638], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 794, "seek": 216482, "start": 2170.3, "end": 2172.46, "text": " And we're going to be building on top of it.", "tokens": [50638, 400, 321, 434, 516, 281, 312, 2390, 322, 1192, 295, 309, 13, 50746], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 795, "seek": 216482, "start": 2172.46, "end": 2176.1000000000004, "text": " So I think that's sort of our way of looking at it", "tokens": [50746, 407, 286, 519, 300, 311, 1333, 295, 527, 636, 295, 1237, 412, 309, 50928], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 796, "seek": 216482, "start": 2176.1000000000004, "end": 2180.78, "text": " in sort of a medium term, again, the next three to five years.", "tokens": [50928, 294, 1333, 295, 257, 6399, 1433, 11, 797, 11, 264, 958, 1045, 281, 1732, 924, 13, 51162], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 797, "seek": 216482, "start": 2180.78, "end": 2183.7000000000003, "text": " Now, if you're looking, because right now,", "tokens": [51162, 823, 11, 498, 291, 434, 1237, 11, 570, 558, 586, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 798, "seek": 216482, "start": 2183.7000000000003, "end": 2185.54, "text": " there are some promising architectures", "tokens": [51308, 456, 366, 512, 20257, 6331, 1303, 51400], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 799, "seek": 216482, "start": 2185.54, "end": 2189.6200000000003, "text": " that's sort of been created at the forefront of,", "tokens": [51400, 300, 311, 1333, 295, 668, 2942, 412, 264, 27287, 295, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 800, "seek": 216482, "start": 2189.6200000000003, "end": 2191.34, "text": " I would say more in the machine learning", "tokens": [51604, 286, 576, 584, 544, 294, 264, 3479, 2539, 51690], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 801, "seek": 216482, "start": 2191.34, "end": 2193.6600000000003, "text": " and natural language processing communities", "tokens": [51690, 293, 3303, 2856, 9007, 4456, 51806], "temperature": 0.0, "avg_logprob": -0.1629695423313829, "compression_ratio": 1.613240418118467, "no_speech_prob": 0.000518510234542191}, {"id": 802, "seek": 219366, "start": 2193.66, "end": 2197.58, "text": " that I'm personally getting a little bit excited about.", "tokens": [50364, 300, 286, 478, 5665, 1242, 257, 707, 857, 2919, 466, 13, 50560], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 803, "seek": 219366, "start": 2197.58, "end": 2200.3399999999997, "text": " But at the moment, those are still", "tokens": [50560, 583, 412, 264, 1623, 11, 729, 366, 920, 50698], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 804, "seek": 219366, "start": 2200.3399999999997, "end": 2203.2999999999997, "text": " in the very much in the research phase.", "tokens": [50698, 294, 264, 588, 709, 294, 264, 2132, 5574, 13, 50846], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 805, "seek": 219366, "start": 2203.2999999999997, "end": 2205.8199999999997, "text": " And can you share some examples of that?", "tokens": [50846, 400, 393, 291, 2073, 512, 5110, 295, 300, 30, 50972], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 806, "seek": 219366, "start": 2205.8199999999997, "end": 2208.8599999999997, "text": " Yeah, so I think there's one model that recently came out,", "tokens": [50972, 865, 11, 370, 286, 519, 456, 311, 472, 2316, 300, 3938, 1361, 484, 11, 51124], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 807, "seek": 219366, "start": 2208.8599999999997, "end": 2210.94, "text": " like Mamba by some folks.", "tokens": [51124, 411, 376, 23337, 538, 512, 4024, 13, 51228], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 808, "seek": 219366, "start": 2210.94, "end": 2213.2599999999998, "text": " Those are from Stanford folks.", "tokens": [51228, 3950, 366, 490, 20374, 4024, 13, 51344], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 809, "seek": 219366, "start": 2213.2599999999998, "end": 2217.02, "text": " So I think the authors now at CMU and Princeton", "tokens": [51344, 407, 286, 519, 264, 16552, 586, 412, 20424, 52, 293, 36592, 51532], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 810, "seek": 219366, "start": 2217.02, "end": 2219.8999999999996, "text": " sort of all within sort of this community.", "tokens": [51532, 1333, 295, 439, 1951, 1333, 295, 341, 1768, 13, 51676], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 811, "seek": 219366, "start": 2219.8999999999996, "end": 2222.2599999999998, "text": " So that's one example of sort of a potentially promising", "tokens": [51676, 407, 300, 311, 472, 1365, 295, 1333, 295, 257, 7263, 20257, 51794], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 812, "seek": 219366, "start": 2222.2599999999998, "end": 2223.18, "text": " or interesting model.", "tokens": [51794, 420, 1880, 2316, 13, 51840], "temperature": 0.0, "avg_logprob": -0.17922857331066597, "compression_ratio": 1.643884892086331, "no_speech_prob": 0.000535155413672328}, {"id": 813, "seek": 222318, "start": 2223.18, "end": 2224.94, "text": " And that's the one that I recently heard about", "tokens": [50364, 400, 300, 311, 264, 472, 300, 286, 3938, 2198, 466, 50452], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 814, "seek": 222318, "start": 2224.94, "end": 2228.94, "text": " that I think is interesting to be looking at.", "tokens": [50452, 300, 286, 519, 307, 1880, 281, 312, 1237, 412, 13, 50652], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 815, "seek": 222318, "start": 2228.94, "end": 2232.8599999999997, "text": " But these models, for them to be deployed at scale", "tokens": [50652, 583, 613, 5245, 11, 337, 552, 281, 312, 17826, 412, 4373, 50848], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 816, "seek": 222318, "start": 2232.8599999999997, "end": 2237.1, "text": " in a commercial way, if we decide to basically go", "tokens": [50848, 294, 257, 6841, 636, 11, 498, 321, 4536, 281, 1936, 352, 51060], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 817, "seek": 222318, "start": 2237.1, "end": 2239.8199999999997, "text": " with certain model that's getting created today,", "tokens": [51060, 365, 1629, 2316, 300, 311, 1242, 2942, 965, 11, 51196], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 818, "seek": 222318, "start": 2239.8199999999997, "end": 2244.74, "text": " it will give us maybe two to five year timeline", "tokens": [51196, 309, 486, 976, 505, 1310, 732, 281, 1732, 1064, 12933, 51442], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 819, "seek": 222318, "start": 2244.74, "end": 2246.58, "text": " before they can really take off.", "tokens": [51442, 949, 436, 393, 534, 747, 766, 13, 51534], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 820, "seek": 222318, "start": 2246.58, "end": 2252.66, "text": " Because Transformer is not, it is a relatively modern model,", "tokens": [51534, 1436, 27938, 260, 307, 406, 11, 309, 307, 257, 7226, 4363, 2316, 11, 51838], "temperature": 0.0, "avg_logprob": -0.14307657877604166, "compression_ratio": 1.641025641025641, "no_speech_prob": 8.214369154302403e-05}, {"id": 821, "seek": 225266, "start": 2252.66, "end": 2255.2999999999997, "text": " but it really is how you look at sort of the timeline.", "tokens": [50364, 457, 309, 534, 307, 577, 291, 574, 412, 1333, 295, 264, 12933, 13, 50496], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 822, "seek": 225266, "start": 2255.2999999999997, "end": 2256.1, "text": " There's Transformer.", "tokens": [50496, 821, 311, 27938, 260, 13, 50536], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 823, "seek": 225266, "start": 2256.1, "end": 2257.22, "text": " Seven-ish years?", "tokens": [50536, 14868, 12, 742, 924, 30, 50592], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 824, "seek": 225266, "start": 2257.22, "end": 2259.14, "text": " Seven-ish years.", "tokens": [50592, 14868, 12, 742, 924, 13, 50688], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 825, "seek": 225266, "start": 2259.14, "end": 2262.02, "text": " So I think hopefully if we find something like this time,", "tokens": [50688, 407, 286, 519, 4696, 498, 321, 915, 746, 411, 341, 565, 11, 50832], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 826, "seek": 225266, "start": 2262.02, "end": 2263.5, "text": " maybe it's going to go much faster.", "tokens": [50832, 1310, 309, 311, 516, 281, 352, 709, 4663, 13, 50906], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 827, "seek": 225266, "start": 2263.5, "end": 2266.5, "text": " But it still took about seven-ish years for Chatchapiti", "tokens": [50906, 583, 309, 920, 1890, 466, 3407, 12, 742, 924, 337, 761, 852, 569, 8707, 51056], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 828, "seek": 225266, "start": 2266.5, "end": 2267.74, "text": " to really come out.", "tokens": [51056, 281, 534, 808, 484, 13, 51118], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 829, "seek": 225266, "start": 2267.74, "end": 2269.58, "text": " So it's not immediate.", "tokens": [51118, 407, 309, 311, 406, 11629, 13, 51210], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 830, "seek": 225266, "start": 2269.58, "end": 2271.7, "text": " Whereas a lot of interactions that we can build,", "tokens": [51210, 13813, 257, 688, 295, 13280, 300, 321, 393, 1322, 11, 51316], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 831, "seek": 225266, "start": 2271.7, "end": 2273.7799999999997, "text": " I think there's a lot that we can do like today", "tokens": [51316, 286, 519, 456, 311, 257, 688, 300, 321, 393, 360, 411, 965, 51420], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 832, "seek": 225266, "start": 2273.7799999999997, "end": 2275.94, "text": " to create really cool experiences.", "tokens": [51420, 281, 1884, 534, 1627, 5235, 13, 51528], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 833, "seek": 225266, "start": 2275.94, "end": 2277.5, "text": " So I think that's how we're looking at this.", "tokens": [51528, 407, 286, 519, 300, 311, 577, 321, 434, 1237, 412, 341, 13, 51606], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 834, "seek": 225266, "start": 2277.5, "end": 2278.7799999999997, "text": " There is a medium term.", "tokens": [51606, 821, 307, 257, 6399, 1433, 13, 51670], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 835, "seek": 225266, "start": 2278.7799999999997, "end": 2281.62, "text": " This is where we are focused on the level of extraction,", "tokens": [51670, 639, 307, 689, 321, 366, 5178, 322, 264, 1496, 295, 30197, 11, 51812], "temperature": 0.0, "avg_logprob": -0.20545236075796733, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0009105202043429017}, {"id": 836, "seek": 228162, "start": 2281.62, "end": 2284.02, "text": " that this is the capacity that we'll have.", "tokens": [50364, 300, 341, 307, 264, 6042, 300, 321, 603, 362, 13, 50484], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 837, "seek": 228162, "start": 2284.02, "end": 2287.1, "text": " And then maybe in the down the line five to 10 year term,", "tokens": [50484, 400, 550, 1310, 294, 264, 760, 264, 1622, 1732, 281, 1266, 1064, 1433, 11, 50638], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 838, "seek": 228162, "start": 2287.1, "end": 2289.42, "text": " we can really be looking forward to some new models that's", "tokens": [50638, 321, 393, 534, 312, 1237, 2128, 281, 512, 777, 5245, 300, 311, 50754], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 839, "seek": 228162, "start": 2289.42, "end": 2291.5, "text": " going to make an impact.", "tokens": [50754, 516, 281, 652, 364, 2712, 13, 50858], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 840, "seek": 228162, "start": 2291.5, "end": 2292.02, "text": " That's great.", "tokens": [50858, 663, 311, 869, 13, 50884], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 841, "seek": 228162, "start": 2292.02, "end": 2293.98, "text": " That's great.", "tokens": [50884, 663, 311, 869, 13, 50982], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 842, "seek": 228162, "start": 2293.98, "end": 2294.46, "text": " Cool.", "tokens": [50982, 8561, 13, 51006], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 843, "seek": 228162, "start": 2294.46, "end": 2296.14, "text": " Very cool.", "tokens": [51006, 4372, 1627, 13, 51090], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 844, "seek": 228162, "start": 2296.14, "end": 2300.98, "text": " Maybe more generally, if you just zoom out for a moment,", "tokens": [51090, 2704, 544, 5101, 11, 498, 291, 445, 8863, 484, 337, 257, 1623, 11, 51332], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 845, "seek": 228162, "start": 2300.98, "end": 2304.7, "text": " when you look at the ecosystem today,", "tokens": [51332, 562, 291, 574, 412, 264, 11311, 965, 11, 51518], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 846, "seek": 228162, "start": 2304.7, "end": 2307.18, "text": " what are some of the problems that you want to see solve?", "tokens": [51518, 437, 366, 512, 295, 264, 2740, 300, 291, 528, 281, 536, 5039, 30, 51642], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 847, "seek": 228162, "start": 2307.18, "end": 2308.8599999999997, "text": " We talked about multimodal a little bit.", "tokens": [51642, 492, 2825, 466, 32972, 378, 304, 257, 707, 857, 13, 51726], "temperature": 0.0, "avg_logprob": -0.16059768676757813, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00044379965402185917}, {"id": 848, "seek": 230886, "start": 2308.86, "end": 2313.02, "text": " We talked about new models right after Transformers", "tokens": [50364, 492, 2825, 466, 777, 5245, 558, 934, 27938, 433, 50572], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 849, "seek": 230886, "start": 2313.02, "end": 2314.06, "text": " that might come out.", "tokens": [50572, 300, 1062, 808, 484, 13, 50624], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 850, "seek": 230886, "start": 2314.06, "end": 2317.42, "text": " What are some of the problems that you are most excited", "tokens": [50624, 708, 366, 512, 295, 264, 2740, 300, 291, 366, 881, 2919, 50792], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 851, "seek": 230886, "start": 2317.42, "end": 2319.26, "text": " about someone solving?", "tokens": [50792, 466, 1580, 12606, 30, 50884], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 852, "seek": 230886, "start": 2319.26, "end": 2323.54, "text": " Not necessarily you personally, but someone solving.", "tokens": [50884, 1726, 4725, 291, 5665, 11, 457, 1580, 12606, 13, 51098], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 853, "seek": 230886, "start": 2323.54, "end": 2326.1, "text": " I sort of have two in mind.", "tokens": [51098, 286, 1333, 295, 362, 732, 294, 1575, 13, 51226], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 854, "seek": 230886, "start": 2326.1, "end": 2330.38, "text": " And it's a little bit less of a, this is a specific problem", "tokens": [51226, 400, 309, 311, 257, 707, 857, 1570, 295, 257, 11, 341, 307, 257, 2685, 1154, 51440], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 855, "seek": 230886, "start": 2330.38, "end": 2332.1800000000003, "text": " that I want to solve.", "tokens": [51440, 300, 286, 528, 281, 5039, 13, 51530], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 856, "seek": 230886, "start": 2332.1800000000003, "end": 2334.98, "text": " But it's more sort of questions that I have", "tokens": [51530, 583, 309, 311, 544, 1333, 295, 1651, 300, 286, 362, 51670], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 857, "seek": 230886, "start": 2334.98, "end": 2338.7400000000002, "text": " that I think more of us should be thinking about.", "tokens": [51670, 300, 286, 519, 544, 295, 505, 820, 312, 1953, 466, 13, 51858], "temperature": 0.0, "avg_logprob": -0.17866125973788174, "compression_ratio": 1.7, "no_speech_prob": 0.0001487855624873191}, {"id": 858, "seek": 233874, "start": 2338.74, "end": 2342.02, "text": " And to some extent, and this happens a lot with sort of the way", "tokens": [50364, 400, 281, 512, 8396, 11, 293, 341, 2314, 257, 688, 365, 1333, 295, 264, 636, 50528], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 859, "seek": 233874, "start": 2342.02, "end": 2344.8999999999996, "text": " I do my research as well, where I get", "tokens": [50528, 286, 360, 452, 2132, 382, 731, 11, 689, 286, 483, 50672], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 860, "seek": 233874, "start": 2344.8999999999996, "end": 2348.8199999999997, "text": " inspired by big problems or foundational problems", "tokens": [50672, 7547, 538, 955, 2740, 420, 32195, 2740, 50868], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 861, "seek": 233874, "start": 2348.8199999999997, "end": 2351.3799999999997, "text": " that we had in previous decades.", "tokens": [50868, 300, 321, 632, 294, 3894, 7878, 13, 50996], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 862, "seek": 233874, "start": 2351.3799999999997, "end": 2354.02, "text": " Because oftentimes, there's a lot of insights", "tokens": [50996, 1436, 18349, 11, 456, 311, 257, 688, 295, 14310, 51128], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 863, "seek": 233874, "start": 2354.02, "end": 2358.7, "text": " that we can learn from the past as we build on the future.", "tokens": [51128, 300, 321, 393, 1466, 490, 264, 1791, 382, 321, 1322, 322, 264, 2027, 13, 51362], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 864, "seek": 233874, "start": 2358.7, "end": 2365.18, "text": " One, certainly I'm embedded into this agent space.", "tokens": [51362, 1485, 11, 3297, 286, 478, 16741, 666, 341, 9461, 1901, 13, 51686], "temperature": 0.0, "avg_logprob": -0.1333910802776894, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.00031490795663557947}, {"id": 865, "seek": 236518, "start": 2365.18, "end": 2371.54, "text": " One is, in the past, agents had its hype cycles, basically.", "tokens": [50364, 1485, 307, 11, 294, 264, 1791, 11, 12554, 632, 1080, 24144, 17796, 11, 1936, 13, 50682], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 866, "seek": 236518, "start": 2371.54, "end": 2374.2599999999998, "text": " But it failed.", "tokens": [50682, 583, 309, 7612, 13, 50818], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 867, "seek": 236518, "start": 2374.2599999999998, "end": 2376.7799999999997, "text": " That the hype cycle lasted for a couple of years,", "tokens": [50818, 663, 264, 24144, 6586, 21116, 337, 257, 1916, 295, 924, 11, 50944], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 868, "seek": 236518, "start": 2376.7799999999997, "end": 2379.1, "text": " and then people very quickly lost interest.", "tokens": [50944, 293, 550, 561, 588, 2661, 2731, 1179, 13, 51060], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 869, "seek": 236518, "start": 2379.1, "end": 2381.3399999999997, "text": " Basically because it didn't quite deliver", "tokens": [51060, 8537, 570, 309, 994, 380, 1596, 4239, 51172], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 870, "seek": 236518, "start": 2381.3399999999997, "end": 2384.8599999999997, "text": " on the promises that it had.", "tokens": [51172, 322, 264, 16403, 300, 309, 632, 13, 51348], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 871, "seek": 236518, "start": 2384.8599999999997, "end": 2389.54, "text": " I think it's worth asking ourselves why that was the case.", "tokens": [51348, 286, 519, 309, 311, 3163, 3365, 4175, 983, 300, 390, 264, 1389, 13, 51582], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 872, "seek": 236518, "start": 2389.54, "end": 2392.8199999999997, "text": " I think the opportunity this time is real.", "tokens": [51582, 286, 519, 264, 2650, 341, 565, 307, 957, 13, 51746], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 873, "seek": 236518, "start": 2392.8199999999997, "end": 2394.8199999999997, "text": " But I also think the opportunity in the past", "tokens": [51746, 583, 286, 611, 519, 264, 2650, 294, 264, 1791, 51846], "temperature": 0.0, "avg_logprob": -0.15239115594660194, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0010648379102349281}, {"id": 874, "seek": 239482, "start": 2394.86, "end": 2397.9, "text": " was also real to some aspect as well.", "tokens": [50366, 390, 611, 957, 281, 512, 4171, 382, 731, 13, 50518], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 875, "seek": 239482, "start": 2397.9, "end": 2400.1000000000004, "text": " So just because the opportunity is real", "tokens": [50518, 407, 445, 570, 264, 2650, 307, 957, 50628], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 876, "seek": 239482, "start": 2400.1000000000004, "end": 2402.34, "text": " and language model is really cool doesn't necessarily", "tokens": [50628, 293, 2856, 2316, 307, 534, 1627, 1177, 380, 4725, 50740], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 877, "seek": 239482, "start": 2402.34, "end": 2404.5, "text": " guarantee us, at least from my perspective,", "tokens": [50740, 10815, 505, 11, 412, 1935, 490, 452, 4585, 11, 50848], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 878, "seek": 239482, "start": 2404.5, "end": 2406.82, "text": " that we're going to, that agent will finally", "tokens": [50848, 300, 321, 434, 516, 281, 11, 300, 9461, 486, 2721, 50964], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 879, "seek": 239482, "start": 2406.82, "end": 2410.1400000000003, "text": " be a thing that everyone will use.", "tokens": [50964, 312, 257, 551, 300, 1518, 486, 764, 13, 51130], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 880, "seek": 239482, "start": 2410.1400000000003, "end": 2413.5800000000004, "text": " I think there is a future where that will happen at some point.", "tokens": [51130, 286, 519, 456, 307, 257, 2027, 689, 300, 486, 1051, 412, 512, 935, 13, 51302], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 881, "seek": 239482, "start": 2413.5800000000004, "end": 2416.1800000000003, "text": " I think it might even happen this cycle.", "tokens": [51302, 286, 519, 309, 1062, 754, 1051, 341, 6586, 13, 51432], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 882, "seek": 239482, "start": 2416.1800000000003, "end": 2419.94, "text": " But I think it's really worth asking, as a community,", "tokens": [51432, 583, 286, 519, 309, 311, 534, 3163, 3365, 11, 382, 257, 1768, 11, 51620], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 883, "seek": 239482, "start": 2419.94, "end": 2423.2200000000003, "text": " why did it fail in the past so that we don't repeat those mistakes?", "tokens": [51620, 983, 630, 309, 3061, 294, 264, 1791, 370, 300, 321, 500, 380, 7149, 729, 8038, 30, 51784], "temperature": 0.0, "avg_logprob": -0.14902169363839285, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.0014992950018495321}, {"id": 884, "seek": 242322, "start": 2423.22, "end": 2425.66, "text": " One sort of main thing I'm sort of curious about", "tokens": [50364, 1485, 1333, 295, 2135, 551, 286, 478, 1333, 295, 6369, 466, 50486], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 885, "seek": 242322, "start": 2425.66, "end": 2427.98, "text": " that I don't think a lot of us are thinking about", "tokens": [50486, 300, 286, 500, 380, 519, 257, 688, 295, 505, 366, 1953, 466, 50602], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 886, "seek": 242322, "start": 2427.98, "end": 2432.2999999999997, "text": " is actually not the technology part, but the interaction.", "tokens": [50602, 307, 767, 406, 264, 2899, 644, 11, 457, 264, 9285, 13, 50818], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 887, "seek": 242322, "start": 2432.2999999999997, "end": 2436.02, "text": " How are these agents going to be used in what way?", "tokens": [50818, 1012, 366, 613, 12554, 516, 281, 312, 1143, 294, 437, 636, 30, 51004], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 888, "seek": 242322, "start": 2436.02, "end": 2438.8999999999996, "text": " Because ultimately that's where it really delivers value", "tokens": [51004, 1436, 6284, 300, 311, 689, 309, 534, 24860, 2158, 51148], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 889, "seek": 242322, "start": 2438.8999999999996, "end": 2440.66, "text": " to the end users.", "tokens": [51148, 281, 264, 917, 5022, 13, 51236], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 890, "seek": 242322, "start": 2440.66, "end": 2443.9399999999996, "text": " And that's where agents in the past have failed.", "tokens": [51236, 400, 300, 311, 689, 12554, 294, 264, 1791, 362, 7612, 13, 51400], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 891, "seek": 242322, "start": 2443.9399999999996, "end": 2445.2999999999997, "text": " That it was really cool technology,", "tokens": [51400, 663, 309, 390, 534, 1627, 2899, 11, 51468], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 892, "seek": 242322, "start": 2445.2999999999997, "end": 2447.66, "text": " but we didn't seriously ask ourselves,", "tokens": [51468, 457, 321, 994, 380, 6638, 1029, 4175, 11, 51586], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 893, "seek": 242322, "start": 2447.66, "end": 2449.62, "text": " is this something that people really need?", "tokens": [51586, 307, 341, 746, 300, 561, 534, 643, 30, 51684], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 894, "seek": 242322, "start": 2449.62, "end": 2451.58, "text": " And does the cost-benefit analysis", "tokens": [51684, 400, 775, 264, 2063, 12, 41605, 6845, 5215, 51782], "temperature": 0.0, "avg_logprob": -0.12639551314096603, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.0023958245292305946}, {"id": 895, "seek": 245158, "start": 2451.58, "end": 2454.62, "text": " of using these agents and learning how to use them well", "tokens": [50364, 295, 1228, 613, 12554, 293, 2539, 577, 281, 764, 552, 731, 50516], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 896, "seek": 245158, "start": 2454.62, "end": 2457.62, "text": " really make sense for the broader user base?", "tokens": [50516, 534, 652, 2020, 337, 264, 13227, 4195, 3096, 30, 50666], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 897, "seek": 245158, "start": 2457.62, "end": 2459.34, "text": " So that's one.", "tokens": [50666, 407, 300, 311, 472, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 898, "seek": 245158, "start": 2459.34, "end": 2464.5, "text": " And other one is sort of my, it's a little bit of a hot take,", "tokens": [50752, 400, 661, 472, 307, 1333, 295, 452, 11, 309, 311, 257, 707, 857, 295, 257, 2368, 747, 11, 51010], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 899, "seek": 245158, "start": 2464.5, "end": 2466.38, "text": " but it's also a shorter take, which", "tokens": [51010, 457, 309, 311, 611, 257, 11639, 747, 11, 597, 51104], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 900, "seek": 245158, "start": 2466.38, "end": 2468.2999999999997, "text": " is we have large language models,", "tokens": [51104, 307, 321, 362, 2416, 2856, 5245, 11, 51200], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 901, "seek": 245158, "start": 2468.2999999999997, "end": 2472.02, "text": " and I think these have made a huge impact already.", "tokens": [51200, 293, 286, 519, 613, 362, 1027, 257, 2603, 2712, 1217, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 902, "seek": 245158, "start": 2472.02, "end": 2476.2599999999998, "text": " The number of users who use chat.gbt, that's incredible.", "tokens": [51386, 440, 1230, 295, 5022, 567, 764, 5081, 13, 70, 4517, 11, 300, 311, 4651, 13, 51598], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 903, "seek": 245158, "start": 2476.2599999999998, "end": 2479.94, "text": " But I think it's sort of worth asking ourselves,", "tokens": [51598, 583, 286, 519, 309, 311, 1333, 295, 3163, 3365, 4175, 11, 51782], "temperature": 0.0, "avg_logprob": -0.1629873144215551, "compression_ratio": 1.6290322580645162, "no_speech_prob": 0.0006259631481952965}, {"id": 904, "seek": 247994, "start": 2479.94, "end": 2483.06, "text": " is that sort of quote unquote the killer applications", "tokens": [50364, 307, 300, 1333, 295, 6513, 37557, 264, 13364, 5821, 50520], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 905, "seek": 247994, "start": 2483.06, "end": 2485.14, "text": " that we were waiting for?", "tokens": [50520, 300, 321, 645, 3806, 337, 30, 50624], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 906, "seek": 247994, "start": 2485.14, "end": 2489.98, "text": " Because in many ways, chat.gbt, or maybe it is.", "tokens": [50624, 1436, 294, 867, 2098, 11, 5081, 13, 70, 4517, 11, 420, 1310, 309, 307, 13, 50866], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 907, "seek": 247994, "start": 2489.98, "end": 2494.14, "text": " And I think if it is, I think somebody should articulate this.", "tokens": [50866, 400, 286, 519, 498, 309, 307, 11, 286, 519, 2618, 820, 30305, 341, 13, 51074], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 908, "seek": 247994, "start": 2494.14, "end": 2497.98, "text": " But chat.gbt does feel like a fairly simple wrapper", "tokens": [51074, 583, 5081, 13, 70, 4517, 775, 841, 411, 257, 6457, 2199, 46906, 51266], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 909, "seek": 247994, "start": 2497.98, "end": 2501.02, "text": " around our language model, because that's what it is.", "tokens": [51266, 926, 527, 2856, 2316, 11, 570, 300, 311, 437, 309, 307, 13, 51418], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 910, "seek": 247994, "start": 2501.02, "end": 2504.7000000000003, "text": " And OpenAI has done fantastic things to make it safer", "tokens": [51418, 400, 7238, 48698, 575, 1096, 5456, 721, 281, 652, 309, 15856, 51602], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 911, "seek": 247994, "start": 2504.7000000000003, "end": 2506.7000000000003, "text": " and make it more useful by tuning, I think,", "tokens": [51602, 293, 652, 309, 544, 4420, 538, 15164, 11, 286, 519, 11, 51702], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 912, "seek": 247994, "start": 2506.7000000000003, "end": 2508.14, "text": " what's really great.", "tokens": [51702, 437, 311, 534, 869, 13, 51774], "temperature": 0.0, "avg_logprob": -0.16374709087869396, "compression_ratio": 1.6468253968253967, "no_speech_prob": 0.0010810436215251684}, {"id": 913, "seek": 250814, "start": 2508.18, "end": 2510.7799999999997, "text": " But I think it's worth asking, if that is actually", "tokens": [50366, 583, 286, 519, 309, 311, 3163, 3365, 11, 498, 300, 307, 767, 50496], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 914, "seek": 250814, "start": 2510.7799999999997, "end": 2515.02, "text": " the killer application, why is it a killer application?", "tokens": [50496, 264, 13364, 3861, 11, 983, 307, 309, 257, 13364, 3861, 30, 50708], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 915, "seek": 250814, "start": 2515.02, "end": 2516.5, "text": " And the answer might actually come out", "tokens": [50708, 400, 264, 1867, 1062, 767, 808, 484, 50782], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 916, "seek": 250814, "start": 2516.5, "end": 2519.54, "text": " that maybe it actually isn't the killer application", "tokens": [50782, 300, 1310, 309, 767, 1943, 380, 264, 13364, 3861, 50934], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 917, "seek": 250814, "start": 2519.54, "end": 2522.7799999999997, "text": " that we were waiting for, in which case, what", "tokens": [50934, 300, 321, 645, 3806, 337, 11, 294, 597, 1389, 11, 437, 51096], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 918, "seek": 250814, "start": 2522.7799999999997, "end": 2524.74, "text": " is going to be the killer application?", "tokens": [51096, 307, 516, 281, 312, 264, 13364, 3861, 30, 51194], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 919, "seek": 250814, "start": 2524.74, "end": 2527.14, "text": " That's really going to add value in a much more", "tokens": [51194, 663, 311, 534, 516, 281, 909, 2158, 294, 257, 709, 544, 51314], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 920, "seek": 250814, "start": 2527.14, "end": 2530.3399999999997, "text": " generalizable way.", "tokens": [51314, 2674, 22395, 636, 13, 51474], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 921, "seek": 250814, "start": 2530.3399999999997, "end": 2532.8199999999997, "text": " That's a very abstract question.", "tokens": [51474, 663, 311, 257, 588, 12649, 1168, 13, 51598], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 922, "seek": 250814, "start": 2532.8199999999997, "end": 2534.9, "text": " For now, it's for me, it's just a hunch", "tokens": [51598, 1171, 586, 11, 309, 311, 337, 385, 11, 309, 311, 445, 257, 47630, 51702], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 923, "seek": 250814, "start": 2534.9, "end": 2537.8599999999997, "text": " that I think there's something to be asked about there.", "tokens": [51702, 300, 286, 519, 456, 311, 746, 281, 312, 2351, 466, 456, 13, 51850], "temperature": 0.0, "avg_logprob": -0.14328739254973655, "compression_ratio": 1.8455598455598456, "no_speech_prob": 0.0001354882842861116}, {"id": 924, "seek": 253786, "start": 2537.9, "end": 2540.1400000000003, "text": " And if I'm wrong, I would also love to hear again", "tokens": [50366, 400, 498, 286, 478, 2085, 11, 286, 576, 611, 959, 281, 1568, 797, 50478], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 925, "seek": 253786, "start": 2540.1400000000003, "end": 2543.58, "text": " somebody really say, we already have this killer application,", "tokens": [50478, 2618, 534, 584, 11, 321, 1217, 362, 341, 13364, 3861, 11, 50650], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 926, "seek": 253786, "start": 2543.58, "end": 2546.82, "text": " maybe it's co-pilot, chat.gbt, and here's why.", "tokens": [50650, 1310, 309, 311, 598, 12, 79, 31516, 11, 5081, 13, 70, 4517, 11, 293, 510, 311, 983, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 927, "seek": 253786, "start": 2546.82, "end": 2551.82, "text": " But for now, this is a question that I'm still asking myself.", "tokens": [50812, 583, 337, 586, 11, 341, 307, 257, 1168, 300, 286, 478, 920, 3365, 2059, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 928, "seek": 253786, "start": 2551.82, "end": 2553.06, "text": " That makes sense.", "tokens": [51062, 663, 1669, 2020, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 929, "seek": 253786, "start": 2553.06, "end": 2555.06, "text": " And thank you for sharing that.", "tokens": [51124, 400, 1309, 291, 337, 5414, 300, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 930, "seek": 253786, "start": 2555.06, "end": 2560.6600000000003, "text": " What are some of your favorite AI apps today that you use?", "tokens": [51224, 708, 366, 512, 295, 428, 2954, 7318, 7733, 965, 300, 291, 764, 30, 51504], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 931, "seek": 253786, "start": 2560.6600000000003, "end": 2561.9, "text": " I love chat.gbt.", "tokens": [51504, 286, 959, 5081, 13, 70, 4517, 13, 51566], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 932, "seek": 253786, "start": 2561.9, "end": 2563.3, "text": " I use it every day.", "tokens": [51566, 286, 764, 309, 633, 786, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 933, "seek": 253786, "start": 2563.3, "end": 2566.7000000000003, "text": " Chat.gbt did make a difference in my workflow.", "tokens": [51636, 27503, 13, 70, 4517, 630, 652, 257, 2649, 294, 452, 20993, 13, 51806], "temperature": 0.0, "avg_logprob": -0.1344279944896698, "compression_ratio": 1.558490566037736, "no_speech_prob": 0.0001463022199459374}, {"id": 934, "seek": 256670, "start": 2567.58, "end": 2571.22, "text": " So as a researcher, one of the main things I do", "tokens": [50408, 407, 382, 257, 21751, 11, 472, 295, 264, 2135, 721, 286, 360, 50590], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 935, "seek": 256670, "start": 2571.22, "end": 2574.22, "text": " is I program every day, or at least most days,", "tokens": [50590, 307, 286, 1461, 633, 786, 11, 420, 412, 1935, 881, 1708, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 936, "seek": 256670, "start": 2574.22, "end": 2576.3399999999997, "text": " or I write or write papers.", "tokens": [50740, 420, 286, 2464, 420, 2464, 10577, 13, 50846], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 937, "seek": 256670, "start": 2576.3399999999997, "end": 2578.2999999999997, "text": " So I do one of those two things.", "tokens": [50846, 407, 286, 360, 472, 295, 729, 732, 721, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 938, "seek": 256670, "start": 2578.2999999999997, "end": 2580.74, "text": " Chat.gbt is fantastic at both.", "tokens": [50944, 27503, 13, 70, 4517, 307, 5456, 412, 1293, 13, 51066], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 939, "seek": 256670, "start": 2580.74, "end": 2585.58, "text": " So as all programmers sort of know,", "tokens": [51066, 407, 382, 439, 41504, 1333, 295, 458, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 940, "seek": 256670, "start": 2585.58, "end": 2587.18, "text": " we sometimes don't bother remembering", "tokens": [51308, 321, 2171, 500, 380, 8677, 20719, 51388], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 941, "seek": 256670, "start": 2587.18, "end": 2590.8599999999997, "text": " all the different functions or documentation.", "tokens": [51388, 439, 264, 819, 6828, 420, 14333, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 942, "seek": 256670, "start": 2590.8599999999997, "end": 2592.8199999999997, "text": " It's very good at generating a lot of the code", "tokens": [51572, 467, 311, 588, 665, 412, 17746, 257, 688, 295, 264, 3089, 51670], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 943, "seek": 256670, "start": 2592.8199999999997, "end": 2594.5, "text": " when I have an idea.", "tokens": [51670, 562, 286, 362, 364, 1558, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 944, "seek": 256670, "start": 2594.5, "end": 2596.06, "text": " Really impressive.", "tokens": [51754, 4083, 8992, 13, 51832], "temperature": 0.0, "avg_logprob": -0.1714404256720292, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.00017389425192959607}, {"id": 945, "seek": 259606, "start": 2596.06, "end": 2597.7799999999997, "text": " It's also quite a good editor.", "tokens": [50364, 467, 311, 611, 1596, 257, 665, 9839, 13, 50450], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 946, "seek": 259606, "start": 2597.7799999999997, "end": 2601.46, "text": " So if I make grammar error in my sort of sentences,", "tokens": [50450, 407, 498, 286, 652, 22317, 6713, 294, 452, 1333, 295, 16579, 11, 50634], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 947, "seek": 259606, "start": 2601.46, "end": 2604.14, "text": " chat.gbt will usually catch them for me.", "tokens": [50634, 5081, 13, 70, 4517, 486, 2673, 3745, 552, 337, 385, 13, 50768], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 948, "seek": 259606, "start": 2604.14, "end": 2607.14, "text": " It's simple and easy thing, but it's good enough now", "tokens": [50768, 467, 311, 2199, 293, 1858, 551, 11, 457, 309, 311, 665, 1547, 586, 50918], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 949, "seek": 259606, "start": 2607.14, "end": 2610.98, "text": " that it's actually making a difference in the workflow.", "tokens": [50918, 300, 309, 311, 767, 1455, 257, 2649, 294, 264, 20993, 13, 51110], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 950, "seek": 259606, "start": 2610.98, "end": 2614.2999999999997, "text": " So as a chat.gbt, for sure, by extension, I think co-pilot", "tokens": [51110, 407, 382, 257, 5081, 13, 70, 4517, 11, 337, 988, 11, 538, 10320, 11, 286, 519, 598, 12, 79, 31516, 51276], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 951, "seek": 259606, "start": 2614.2999999999997, "end": 2616.98, "text": " will make a difference.", "tokens": [51276, 486, 652, 257, 2649, 13, 51410], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 952, "seek": 259606, "start": 2616.98, "end": 2618.86, "text": " So it's sort of worth asking, maybe going back", "tokens": [51410, 407, 309, 311, 1333, 295, 3163, 3365, 11, 1310, 516, 646, 51504], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 953, "seek": 259606, "start": 2618.86, "end": 2621.18, "text": " to the question around killer application.", "tokens": [51504, 281, 264, 1168, 926, 13364, 3861, 13, 51620], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 954, "seek": 259606, "start": 2621.18, "end": 2623.18, "text": " What is the definition of killer application?", "tokens": [51620, 708, 307, 264, 7123, 295, 13364, 3861, 30, 51720], "temperature": 0.0, "avg_logprob": -0.16104355454444885, "compression_ratio": 1.7083333333333333, "no_speech_prob": 8.216130663640797e-05}, {"id": 955, "seek": 262318, "start": 2623.18, "end": 2625.7799999999997, "text": " I think it does some people define it", "tokens": [50364, 286, 519, 309, 775, 512, 561, 6964, 309, 50494], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 956, "seek": 262318, "start": 2625.7799999999997, "end": 2628.3399999999997, "text": " as application that has more users.", "tokens": [50494, 382, 3861, 300, 575, 544, 5022, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 957, "seek": 262318, "start": 2628.3399999999997, "end": 2630.7, "text": " And the fact of that, I think, always has to be the case,", "tokens": [50622, 400, 264, 1186, 295, 300, 11, 286, 519, 11, 1009, 575, 281, 312, 264, 1389, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 958, "seek": 262318, "start": 2630.7, "end": 2632.94, "text": " that no killer application has no user.", "tokens": [50740, 300, 572, 13364, 3861, 575, 572, 4195, 13, 50852], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 959, "seek": 262318, "start": 2632.94, "end": 2636.18, "text": " Killer application, by default, means the application", "tokens": [50852, 39846, 3861, 11, 538, 7576, 11, 1355, 264, 3861, 51014], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 960, "seek": 262318, "start": 2636.18, "end": 2639.74, "text": " that will have the most number of users.", "tokens": [51014, 300, 486, 362, 264, 881, 1230, 295, 5022, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 961, "seek": 262318, "start": 2639.74, "end": 2642.46, "text": " But I think there is more theoretical definition", "tokens": [51192, 583, 286, 519, 456, 307, 544, 20864, 7123, 51328], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 962, "seek": 262318, "start": 2642.46, "end": 2644.7799999999997, "text": " to what a killer application is.", "tokens": [51328, 281, 437, 257, 13364, 3861, 307, 13, 51444], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 963, "seek": 262318, "start": 2644.7799999999997, "end": 2647.98, "text": " That implies a lot of users who are the most number of users.", "tokens": [51444, 663, 18779, 257, 688, 295, 5022, 567, 366, 264, 881, 1230, 295, 5022, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 964, "seek": 262318, "start": 2647.98, "end": 2652.1, "text": " But for instance, if we look back to the prior era of PC,", "tokens": [51604, 583, 337, 5197, 11, 498, 321, 574, 646, 281, 264, 4059, 4249, 295, 6465, 11, 51810], "temperature": 0.0, "avg_logprob": -0.1585273432537792, "compression_ratio": 1.9338842975206612, "no_speech_prob": 0.0036481700371950865}, {"id": 965, "seek": 265210, "start": 2652.1, "end": 2653.7799999999997, "text": " my killer application that I mentioned", "tokens": [50364, 452, 13364, 3861, 300, 286, 2835, 50448], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 966, "seek": 265210, "start": 2653.7799999999997, "end": 2658.06, "text": " was something like Microsoft's Excel or this tabular data", "tokens": [50448, 390, 746, 411, 8116, 311, 19060, 420, 341, 4421, 1040, 1412, 50662], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 967, "seek": 265210, "start": 2658.06, "end": 2661.58, "text": " format, the thing that would let us manipulate the tabular", "tokens": [50662, 7877, 11, 264, 551, 300, 576, 718, 505, 20459, 264, 4421, 1040, 50838], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 968, "seek": 265210, "start": 2661.58, "end": 2662.9, "text": " data.", "tokens": [50838, 1412, 13, 50904], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 969, "seek": 265210, "start": 2662.9, "end": 2665.74, "text": " So really, the definition, in a more theoretical sense", "tokens": [50904, 407, 534, 11, 264, 7123, 11, 294, 257, 544, 20864, 2020, 51046], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 970, "seek": 265210, "start": 2665.74, "end": 2667.8199999999997, "text": " of killer application here, is there", "tokens": [51046, 295, 13364, 3861, 510, 11, 307, 456, 51150], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 971, "seek": 265210, "start": 2667.8199999999997, "end": 2670.14, "text": " is new technology stack that is being developed.", "tokens": [51150, 307, 777, 2899, 8630, 300, 307, 885, 4743, 13, 51266], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 972, "seek": 265210, "start": 2670.14, "end": 2673.06, "text": " There is a new file type that is getting generated.", "tokens": [51266, 821, 307, 257, 777, 3991, 2010, 300, 307, 1242, 10833, 13, 51412], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 973, "seek": 265210, "start": 2673.06, "end": 2676.46, "text": " Then the killer application is the one that would let us", "tokens": [51412, 1396, 264, 13364, 3861, 307, 264, 472, 300, 576, 718, 505, 51582], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 974, "seek": 265210, "start": 2676.46, "end": 2679.1, "text": " manipulate the file application, file type.", "tokens": [51582, 20459, 264, 3991, 3861, 11, 3991, 2010, 13, 51714], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 975, "seek": 265210, "start": 2679.1, "end": 2680.7, "text": " That's one theoretical definition", "tokens": [51714, 663, 311, 472, 20864, 7123, 51794], "temperature": 0.0, "avg_logprob": -0.16328245961767995, "compression_ratio": 1.9878048780487805, "no_speech_prob": 0.00013975967885926366}, {"id": 976, "seek": 268070, "start": 2680.7, "end": 2683.02, "text": " that one could give, at least that's", "tokens": [50364, 300, 472, 727, 976, 11, 412, 1935, 300, 311, 50480], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 977, "seek": 268070, "start": 2683.02, "end": 2684.98, "text": " sort of the definition that I've been towing with.", "tokens": [50480, 1333, 295, 264, 7123, 300, 286, 600, 668, 281, 7904, 365, 13, 50578], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 978, "seek": 268070, "start": 2684.98, "end": 2686.3799999999997, "text": " I think it's an interesting one.", "tokens": [50578, 286, 519, 309, 311, 364, 1880, 472, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 979, "seek": 268070, "start": 2686.3799999999997, "end": 2687.8999999999996, "text": " I don't think it's the only one.", "tokens": [50648, 286, 500, 380, 519, 309, 311, 264, 787, 472, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 980, "seek": 268070, "start": 2687.8999999999996, "end": 2690.7, "text": " But those are sort of ways that I'm looking at this.", "tokens": [50724, 583, 729, 366, 1333, 295, 2098, 300, 286, 478, 1237, 412, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 981, "seek": 268070, "start": 2690.7, "end": 2692.06, "text": " That makes a lot of sense.", "tokens": [50864, 663, 1669, 257, 688, 295, 2020, 13, 50932], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 982, "seek": 268070, "start": 2692.06, "end": 2694.62, "text": " I also use chatGPT every single day.", "tokens": [50932, 286, 611, 764, 5081, 38, 47, 51, 633, 2167, 786, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 983, "seek": 268070, "start": 2694.62, "end": 2696.58, "text": " It's been very helpful.", "tokens": [51060, 467, 311, 668, 588, 4961, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 984, "seek": 268070, "start": 2696.58, "end": 2699.5, "text": " Everything from coming up with menu names", "tokens": [51158, 5471, 490, 1348, 493, 365, 6510, 5288, 51304], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 985, "seek": 268070, "start": 2699.5, "end": 2705.74, "text": " to rewriting emails that don't sound as nice.", "tokens": [51304, 281, 319, 19868, 12524, 300, 500, 380, 1626, 382, 1481, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 986, "seek": 268070, "start": 2705.74, "end": 2709.66, "text": " And I've tried a little bit to give it files and images.", "tokens": [51616, 400, 286, 600, 3031, 257, 707, 857, 281, 976, 309, 7098, 293, 5267, 13, 51812], "temperature": 0.0, "avg_logprob": -0.1958884470390551, "compression_ratio": 1.6755725190839694, "no_speech_prob": 0.0016432099509984255}, {"id": 987, "seek": 270966, "start": 2709.66, "end": 2712.46, "text": " So I actually helped my mother create a background.", "tokens": [50364, 407, 286, 767, 4254, 452, 2895, 1884, 257, 3678, 13, 50504], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 988, "seek": 270966, "start": 2712.46, "end": 2714.2599999999998, "text": " She's a dancer, so she was performing", "tokens": [50504, 1240, 311, 257, 21621, 11, 370, 750, 390, 10205, 50594], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 989, "seek": 270966, "start": 2714.2599999999998, "end": 2716.3799999999997, "text": " on one of the very specific background for her dance.", "tokens": [50594, 322, 472, 295, 264, 588, 2685, 3678, 337, 720, 4489, 13, 50700], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 990, "seek": 270966, "start": 2716.3799999999997, "end": 2719.14, "text": " And I created that for her using chatGPT.", "tokens": [50700, 400, 286, 2942, 300, 337, 720, 1228, 5081, 38, 47, 51, 13, 50838], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 991, "seek": 270966, "start": 2719.14, "end": 2721.42, "text": " So all sorts of utility there.", "tokens": [50838, 407, 439, 7527, 295, 14877, 456, 13, 50952], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 992, "seek": 270966, "start": 2721.42, "end": 2724.22, "text": " But I love the way that you framed", "tokens": [50952, 583, 286, 959, 264, 636, 300, 291, 30420, 51092], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 993, "seek": 270966, "start": 2724.22, "end": 2726.14, "text": " the last potential application.", "tokens": [51092, 264, 1036, 3995, 3861, 13, 51188], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 994, "seek": 270966, "start": 2726.14, "end": 2729.14, "text": " Maybe just one last question from my end.", "tokens": [51188, 2704, 445, 472, 1036, 1168, 490, 452, 917, 13, 51338], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 995, "seek": 270966, "start": 2729.14, "end": 2739.2999999999997, "text": " Any resources or books that you love that is on this topic?", "tokens": [51338, 2639, 3593, 420, 3642, 300, 291, 959, 300, 307, 322, 341, 4829, 30, 51846], "temperature": 0.0, "avg_logprob": -0.16650575857896072, "compression_ratio": 1.565040650406504, "no_speech_prob": 0.0030728434212505817}, {"id": 996, "seek": 273930, "start": 2740.3, "end": 2741.3, "text": " Right.", "tokens": [50414, 1779, 13, 50464], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 997, "seek": 273930, "start": 2745.3, "end": 2748.5800000000004, "text": " I do think, and this is often the case", "tokens": [50664, 286, 360, 519, 11, 293, 341, 307, 2049, 264, 1389, 50828], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 998, "seek": 273930, "start": 2748.5800000000004, "end": 2751.1000000000004, "text": " with many of the cutting edge spaces.", "tokens": [50828, 365, 867, 295, 264, 6492, 4691, 7673, 13, 50954], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 999, "seek": 273930, "start": 2751.1000000000004, "end": 2753.34, "text": " I think a lot of the papers that are coming out", "tokens": [50954, 286, 519, 257, 688, 295, 264, 10577, 300, 366, 1348, 484, 51066], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1000, "seek": 273930, "start": 2753.34, "end": 2755.1400000000003, "text": " that are gaining a lot of attention,", "tokens": [51066, 300, 366, 19752, 257, 688, 295, 3202, 11, 51156], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1001, "seek": 273930, "start": 2755.1400000000003, "end": 2756.7400000000002, "text": " I think those are sort of worth checking out", "tokens": [51156, 286, 519, 729, 366, 1333, 295, 3163, 8568, 484, 51236], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1002, "seek": 273930, "start": 2756.7400000000002, "end": 2757.94, "text": " as sort of the resources.", "tokens": [51236, 382, 1333, 295, 264, 3593, 13, 51296], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1003, "seek": 273930, "start": 2757.94, "end": 2761.54, "text": " It's not exactly like here's one book that we can all look at.", "tokens": [51296, 467, 311, 406, 2293, 411, 510, 311, 472, 1446, 300, 321, 393, 439, 574, 412, 13, 51476], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1004, "seek": 273930, "start": 2761.54, "end": 2764.94, "text": " But things are moving fast enough that I think", "tokens": [51476, 583, 721, 366, 2684, 2370, 1547, 300, 286, 519, 51646], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1005, "seek": 273930, "start": 2764.94, "end": 2767.1400000000003, "text": " those are sort of interesting resources", "tokens": [51646, 729, 366, 1333, 295, 1880, 3593, 51756], "temperature": 0.0, "avg_logprob": -0.31612317807206486, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.016302917152643204}, {"id": 1006, "seek": 276714, "start": 2767.14, "end": 2769.74, "text": " or just things that are getting created today", "tokens": [50364, 420, 445, 721, 300, 366, 1242, 2942, 965, 50494], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1007, "seek": 276714, "start": 2769.74, "end": 2771.54, "text": " and their documentations.", "tokens": [50494, 293, 641, 4166, 763, 13, 50584], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1008, "seek": 276714, "start": 2771.54, "end": 2775.14, "text": " So those are sort of mentioned as sort of a generic answer.", "tokens": [50584, 407, 729, 366, 1333, 295, 2835, 382, 1333, 295, 257, 19577, 1867, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1009, "seek": 276714, "start": 2775.14, "end": 2778.54, "text": " I do think, I think this has been a sort of running thing", "tokens": [50764, 286, 360, 519, 11, 286, 519, 341, 575, 668, 257, 1333, 295, 2614, 551, 50934], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1010, "seek": 276714, "start": 2778.54, "end": 2780.54, "text": " in some of the things I mentioned today,", "tokens": [50934, 294, 512, 295, 264, 721, 286, 2835, 965, 11, 51034], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1011, "seek": 276714, "start": 2780.54, "end": 2788.54, "text": " I get inspired by insights that basically had an impact", "tokens": [51034, 286, 483, 7547, 538, 14310, 300, 1936, 632, 364, 2712, 51434], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1012, "seek": 276714, "start": 2788.54, "end": 2791.14, "text": " that stood the test of time.", "tokens": [51434, 300, 9371, 264, 1500, 295, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1013, "seek": 276714, "start": 2791.14, "end": 2793.54, "text": " And the reason why that is the case", "tokens": [51564, 400, 264, 1778, 983, 300, 307, 264, 1389, 51684], "temperature": 0.0, "avg_logprob": -0.3291590317435887, "compression_ratio": 1.7121951219512195, "no_speech_prob": 0.0009812555508688092}, {"id": 1014, "seek": 279354, "start": 2793.54, "end": 2796.54, "text": " is because I personally think all the great ideas", "tokens": [50364, 307, 570, 286, 5665, 519, 439, 264, 869, 3487, 50514], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1015, "seek": 279354, "start": 2796.54, "end": 2798.54, "text": " are sort of timeless.", "tokens": [50514, 366, 1333, 295, 41200, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1016, "seek": 279354, "start": 2798.54, "end": 2801.54, "text": " It's because current time cycle is over,", "tokens": [50614, 467, 311, 570, 2190, 565, 6586, 307, 670, 11, 50764], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1017, "seek": 279354, "start": 2801.54, "end": 2803.54, "text": " it doesn't mean they're less interesting or less meaningful.", "tokens": [50764, 309, 1177, 380, 914, 436, 434, 1570, 1880, 420, 1570, 10995, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1018, "seek": 279354, "start": 2803.54, "end": 2804.54, "text": " For sure.", "tokens": [50864, 1171, 988, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1019, "seek": 279354, "start": 2804.54, "end": 2808.54, "text": " That foundational ideas that will continue to have impact.", "tokens": [50914, 663, 32195, 3487, 300, 486, 2354, 281, 362, 2712, 13, 51114], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1020, "seek": 279354, "start": 2808.54, "end": 2810.54, "text": " So when I look for resources,", "tokens": [51114, 407, 562, 286, 574, 337, 3593, 11, 51214], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1021, "seek": 279354, "start": 2810.54, "end": 2815.54, "text": " I actually look back to books from truly the prior generations.", "tokens": [51214, 286, 767, 574, 646, 281, 3642, 490, 4908, 264, 4059, 10593, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1022, "seek": 279354, "start": 2815.54, "end": 2818.54, "text": " So some of the works that I often go back to", "tokens": [51464, 407, 512, 295, 264, 1985, 300, 286, 2049, 352, 646, 281, 51614], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1023, "seek": 279354, "start": 2818.54, "end": 2821.54, "text": " are works by Herbert Simon, Alan G.", "tokens": [51614, 366, 1985, 538, 41942, 13193, 11, 16442, 460, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3089541863957676, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.0013439826434478164}, {"id": 1024, "seek": 282154, "start": 2821.54, "end": 2824.54, "text": " Those are founders of AI and many of these fields", "tokens": [50364, 3950, 366, 25608, 295, 7318, 293, 867, 295, 613, 7909, 50514], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1025, "seek": 282154, "start": 2824.54, "end": 2826.54, "text": " who would later go into a turning award", "tokens": [50514, 567, 576, 1780, 352, 666, 257, 6246, 7130, 50614], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1026, "seek": 282154, "start": 2826.54, "end": 2828.54, "text": " and Nobel Prize and so forth.", "tokens": [50614, 293, 24611, 22604, 293, 370, 5220, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1027, "seek": 282154, "start": 2828.54, "end": 2831.54, "text": " And those works, early cognitive psychologists", "tokens": [50714, 400, 729, 1985, 11, 2440, 15605, 41562, 50864], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1028, "seek": 282154, "start": 2831.54, "end": 2836.54, "text": " and scientists inspired my work a lot and their textbook.", "tokens": [50864, 293, 7708, 7547, 452, 589, 257, 688, 293, 641, 25591, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1029, "seek": 282154, "start": 2836.54, "end": 2838.54, "text": " Those people actually have written books", "tokens": [51114, 3950, 561, 767, 362, 3720, 3642, 51214], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1030, "seek": 282154, "start": 2838.54, "end": 2840.54, "text": " because they were much more established", "tokens": [51214, 570, 436, 645, 709, 544, 7545, 51314], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1031, "seek": 282154, "start": 2840.54, "end": 2842.54, "text": " than sort of the cutting edge spaces today.", "tokens": [51314, 813, 1333, 295, 264, 6492, 4691, 7673, 965, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1032, "seek": 282154, "start": 2842.54, "end": 2846.54, "text": " So I go back to those as sort of my personal resources", "tokens": [51414, 407, 286, 352, 646, 281, 729, 382, 1333, 295, 452, 2973, 3593, 51614], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1033, "seek": 282154, "start": 2846.54, "end": 2848.54, "text": " for getting ideas.", "tokens": [51614, 337, 1242, 3487, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1034, "seek": 282154, "start": 2848.54, "end": 2849.54, "text": " That's great.", "tokens": [51714, 663, 311, 869, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1457239168661612, "compression_ratio": 1.6007326007326008, "no_speech_prob": 0.004748735576868057}, {"id": 1035, "seek": 284954, "start": 2849.54, "end": 2850.54, "text": " Thank you so much.", "tokens": [50364, 1044, 291, 370, 709, 13, 50414], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1036, "seek": 284954, "start": 2850.54, "end": 2852.54, "text": " This was super, super helpful to me personally", "tokens": [50414, 639, 390, 1687, 11, 1687, 4961, 281, 385, 5665, 50514], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1037, "seek": 284954, "start": 2852.54, "end": 2854.54, "text": " because what we do as investors", "tokens": [50514, 570, 437, 321, 360, 382, 11519, 50614], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1038, "seek": 284954, "start": 2854.54, "end": 2859.54, "text": " is we try to understand the impacts of technology", "tokens": [50614, 307, 321, 853, 281, 1223, 264, 11606, 295, 2899, 50864], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1039, "seek": 284954, "start": 2859.54, "end": 2864.54, "text": " and start to invest in companies when it becomes,", "tokens": [50864, 293, 722, 281, 1963, 294, 3431, 562, 309, 3643, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1040, "seek": 284954, "start": 2864.54, "end": 2867.54, "text": " at the beginning of when it becomes commercially viable.", "tokens": [51114, 412, 264, 2863, 295, 562, 309, 3643, 41751, 22024, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1041, "seek": 284954, "start": 2867.54, "end": 2870.54, "text": " So to your point around what are the problem spaces,", "tokens": [51264, 407, 281, 428, 935, 926, 437, 366, 264, 1154, 7673, 11, 51414], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1042, "seek": 284954, "start": 2870.54, "end": 2873.54, "text": " what are the applications in which this can be applied", "tokens": [51414, 437, 366, 264, 5821, 294, 597, 341, 393, 312, 6456, 51564], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1043, "seek": 284954, "start": 2873.54, "end": 2876.54, "text": " in a cost-effective and secure way", "tokens": [51564, 294, 257, 2063, 12, 45122, 293, 7144, 636, 51714], "temperature": 0.0, "avg_logprob": -0.10265760032498107, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.00080357666593045}, {"id": 1044, "seek": 287654, "start": 2876.54, "end": 2881.54, "text": " that where the end user is willing to interact", "tokens": [50364, 300, 689, 264, 917, 4195, 307, 4950, 281, 4648, 50614], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}, {"id": 1045, "seek": 287654, "start": 2881.54, "end": 2883.54, "text": " and get value,", "tokens": [50614, 293, 483, 2158, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}, {"id": 1046, "seek": 287654, "start": 2883.54, "end": 2887.54, "text": " that's when we start to come in and invest in these companies", "tokens": [50714, 300, 311, 562, 321, 722, 281, 808, 294, 293, 1963, 294, 613, 3431, 50914], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}, {"id": 1047, "seek": 287654, "start": 2887.54, "end": 2891.54, "text": " which will hopefully be much bigger companies in the future.", "tokens": [50914, 597, 486, 4696, 312, 709, 3801, 3431, 294, 264, 2027, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}, {"id": 1048, "seek": 287654, "start": 2891.54, "end": 2893.54, "text": " So really appreciate this chat.", "tokens": [51114, 407, 534, 4449, 341, 5081, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}, {"id": 1049, "seek": 287654, "start": 2893.54, "end": 2895.54, "text": " Yeah, it was fun.", "tokens": [51214, 865, 11, 309, 390, 1019, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09521209039995747, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.0035917945206165314}], "language": "en"}