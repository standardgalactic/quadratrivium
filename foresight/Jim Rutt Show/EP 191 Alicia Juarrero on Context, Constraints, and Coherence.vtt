WEBVTT

00:00.000 --> 00:04.000
Howdy, this is Jim Rutt, and this is The Jim Rutt Show.

00:04.000 --> 00:11.000
Music

00:11.000 --> 00:16.000
Listeners have asked us to provide pointers to some of the resources we talk about on the show.

00:16.000 --> 00:22.000
We now have links to books and articles referenced in recent podcasts that are available on our website.

00:22.000 --> 00:24.000
We also offer full transcripts.

00:24.000 --> 00:29.000
Go to JimRuttShow.com. That's JimRuttShow.com.

00:29.000 --> 00:32.000
Music

00:32.000 --> 00:35.000
Today's guest is Alicia Herrero.

00:35.000 --> 00:41.000
She's a professor of philosophy emerita at Prince George's Community College in Maryland.

00:41.000 --> 00:43.000
This is kind of old home week.

00:43.000 --> 00:48.000
I actually grew up in PG County as we used to call it in the day.

00:48.000 --> 00:53.000
They tell me you're not supposed to say PG anymore, but that's what we always call it.

00:54.000 --> 01:00.000
I lived there from the time I was two to the time I was 22, and my wife is from PG also.

01:00.000 --> 01:06.000
My brother is a distinguished alum of Prince George's Community College,

01:06.000 --> 01:11.000
and probably half my friends went there, so it's great to connect with Alicia.

01:11.000 --> 01:13.000
She is a complexity person.

01:13.000 --> 01:16.000
She is the author of Dynamics in Action.

01:16.000 --> 01:20.000
I have not read that book, but I ordered it and look forward to reading it.

01:20.000 --> 01:26.000
It's very interesting, and she's co-editor of Reframing Complexity, Perspectives of North and South,

01:26.000 --> 01:31.000
and Emergence, Self-Organization, and Complexity, Precursors, and Prototypes.

01:31.000 --> 01:36.000
And she's written lots of publications and refereed philosophy journals.

01:36.000 --> 01:41.000
She's also written a couple of things that I read while I was doing my research for this episode

01:41.000 --> 01:43.000
that I think the audience might find interesting.

01:43.000 --> 01:47.000
One's called Downward Causation, Poliani, and Progosian,

01:47.000 --> 01:50.000
and another one called Western Science and Philosophy.

01:50.000 --> 01:54.000
Can't deal with the relations between parts and holes.

01:54.000 --> 01:57.000
You know, they're pretty serious, but they're not quite scholarly papers, right?

01:57.000 --> 02:02.000
And so I think our audience could deal with them, and as always, links to those papers

02:02.000 --> 02:06.000
and the books will be on our website at JimRucho.com.

02:06.000 --> 02:08.000
So, welcome, Alicia!

02:08.000 --> 02:12.000
Thank you for having me. It's a pleasure to meet you.

02:12.000 --> 02:16.000
Yeah, it's a very good conversation. I really enjoyed reading the book.

02:16.000 --> 02:21.000
It's quite short, 235 pages, but it is chock-full of stuff.

02:21.000 --> 02:25.000
I mean, there's lots of ideas in this book, but we probably aren't going to get to them all.

02:25.000 --> 02:30.000
My topic list is, I try to keep it to seven pages, but it looks like I got more like 11,

02:30.000 --> 02:32.000
so we'll see how far we can get into it.

02:32.000 --> 02:35.000
But I'd also like your writing styles very clear.

02:35.000 --> 02:37.000
Oh, no, it is not.

02:37.000 --> 02:41.000
You must have not read much of it because it is horrendously...

02:41.000 --> 02:45.000
No, no, for philosophy book, it's damn readable.

02:45.000 --> 02:48.000
No, no, no, it's awful. I wish I were here.

02:48.000 --> 02:51.000
Well, no, no, I would disagree. I would disagree.

02:51.000 --> 02:55.000
But today we're going to talk about her newest book just published called

02:55.000 --> 03:01.000
Context Changes Everything, How Constraints Create Coherence.

03:01.000 --> 03:04.000
So, the book was just published a couple of weeks ago, right?

03:04.000 --> 03:06.000
A couple of weeks ago, yes.

03:06.000 --> 03:09.000
Well, again, we'll have a link to the book on the episode page.

03:09.000 --> 03:11.000
So, let's actually start with something.

03:11.000 --> 03:13.000
We talk about a fair bit.

03:13.000 --> 03:16.000
A number of our guests, for some reason, have found this framing useful.

03:16.000 --> 03:19.000
And that is Aristotle's Four Causes.

03:19.000 --> 03:22.000
This is a theme that runs throughout the book.

03:22.000 --> 03:27.000
Why don't you remind the audience what the Four Causes are and what they are?

03:27.000 --> 03:31.000
Well, I think Aristotle probably got it from the potter's wheel.

03:31.000 --> 03:38.000
You know, he started thinking about causes and effects using the example of the potter's wheel.

03:38.000 --> 03:45.000
Four Causes are material cause, the clay, the stuff from which the pot will be made.

03:45.000 --> 03:54.000
Then final cause or purpose or teleology, which is the goal to which the thing that you're making will be put,

03:54.000 --> 03:56.000
which is pouring water.

03:56.000 --> 03:59.000
So, the final cause of the picture would be water.

03:59.000 --> 04:02.000
The formal cause, it's not quite shape.

04:02.000 --> 04:06.000
It's sort of the what makes a picture a picture.

04:06.000 --> 04:12.000
So, it is the essence, the basic fundamental identity of the thing.

04:12.000 --> 04:24.000
And then finally, efficient cause, which is the actual force exerted by the hands and the on the on the clay to turn it into the picture.

04:24.000 --> 04:25.000
So, it's energetic.

04:25.000 --> 04:28.000
Efficient cause is energetic exchange.

04:28.000 --> 04:34.000
One of the things, the points you make is that prior to maybe the late 16th century,

04:34.000 --> 04:40.000
people tended to consider all those causes when they were thinking about nature and the pre-scientific era.

04:40.000 --> 04:51.000
But one of the moves that probably came off accidentally more or less from the invention of modern science was a very heavy focus on the efficient cause.

04:51.000 --> 04:52.000
Correct, correct.

04:52.000 --> 04:57.000
In a sense, material cause, people figured, well, science will take care of that.

04:57.000 --> 05:01.000
And formal cause and final cause were sort of discarded.

05:01.000 --> 05:02.000
They went out with a bustle.

05:02.000 --> 05:05.000
You know, this is something we don't have to worry about anymore.

05:05.000 --> 05:10.000
So, we can explain everything in terms of forceful causes.

05:11.000 --> 05:25.000
It seems to me that when you're talking about complex dynamical systems, somehow final cause and formal cause kind of gets snuck in indirectly, not the way Aristotle thought.

05:25.000 --> 05:43.000
People were born with an act or organisms or all natural phenomena had an inherent internal and teleki internal kind of like an acorn has the form of an oak built into it.

05:43.000 --> 05:48.000
And all it has to do is unroll and unfold into the final form.

05:48.000 --> 06:02.000
But I think what we have now with complex dynamical systems is that interactions with the environment and in my view constraints are the contemporary version of formal and final cause.

06:02.000 --> 06:10.000
Yeah, and the over focus on efficient cause, matter and motion bumping into each other.

06:10.000 --> 06:18.000
I often refer to that as naive Newtonianism and you know, most nerdy smart kids go through that period, right?

06:18.000 --> 06:30.000
And they make the error of thinking the famous Laplacian area where he says, yeah, give me the position and velocity of everything in the universe and I can predict the future in the past with total precision.

06:30.000 --> 06:36.000
But fortunately, once you get exposed to ideas of complexity, you realize it's completely crazy.

06:36.000 --> 06:45.000
And that has actually caused for those people who've gotten the complexity lens to realize there's much more to our universe than naive Newtonism.

06:45.000 --> 06:49.000
But, but it's amazing how it's persisted and you can't blame people.

06:49.000 --> 06:56.000
I mean, it seems to do a hell of a job predicting eclipses, but even Newton knew the three body problem would mess things up.

06:56.000 --> 06:57.000
Right.

06:57.000 --> 07:05.000
But that was a warning Newton gave us that went on heated for many centuries.

07:05.000 --> 07:12.000
My first paper was about Kant and Prigogene and exactly about that subject matter.

07:12.000 --> 07:13.000
Yeah.

07:13.000 --> 07:19.000
And then as you talk about in your book, one of the current manifestations of it, though, I will say it depends where you are in the sciences.

07:19.000 --> 07:23.000
Now, I've had the good fortune to be around complexity people for the last 20 years.

07:23.000 --> 07:26.000
And so there's much, much, much less of that there.

07:26.000 --> 07:33.000
But I suppose out in the wilds of solid state physics and places like that, there's still a lot about what you call nothing but ism.

07:33.000 --> 07:34.000
Right.

07:34.000 --> 07:37.000
Explain what nothing but ism is.

07:37.000 --> 07:49.000
Well, the idea that the whole is nothing but the sum of its parts and therefore anything that appears to be an emergent property is really an epiphenomenon.

07:49.000 --> 07:55.000
It is, it is, it is sort of froth that's thrown up, but it really has no causal power.

07:55.000 --> 08:07.000
Well, of course, not because if causal power is only thought of as efficient causality, then clearly the synchronization of the photon streams in a laser beam.

08:07.000 --> 08:13.000
Don't align their component laser beams as another efficient cause.

08:13.000 --> 08:14.000
So that's the problem.

08:14.000 --> 08:18.000
Yeah, that's it leads very quickly to absurd conclusions.

08:18.000 --> 08:21.000
What makes me wonder why did it hang in there so long?

08:21.000 --> 08:23.000
Well, and you know where it hung in.

08:23.000 --> 08:31.000
I came at this because I wrote a dissertation on the difference between explaining and justifying behavior.

08:31.000 --> 08:34.000
Well, justification has to do with moral reasons so on.

08:34.000 --> 08:42.000
But explaining behavior, the first sense of that first book that you quoted is what is the difference between a wink and a blink?

08:42.000 --> 08:46.000
Presumably, it's the cause, right?

08:46.000 --> 08:55.000
Meaning that an intention causes a wink, but a, my throwing some sand in your face would cause you to blink.

08:55.000 --> 09:04.000
Well, but then the next question is what the hell's an intention and how can an intention cause the action in an efficient cause way?

09:04.000 --> 09:05.000
Correct?

09:05.000 --> 09:10.000
And my answer was obviously, well, there can't be just one neuron pushing another neuron pushing.

09:10.000 --> 09:11.000
I mean, forget it.

09:11.000 --> 09:12.000
That doesn't work that way.

09:12.000 --> 09:21.000
And at the time I was living in Berkeley and I was hanging around people who were into network theory and systems analysis and so on.

09:21.000 --> 09:22.000
I'm going, you know what?

09:22.000 --> 09:24.000
There's got to be a network property.

09:24.000 --> 09:26.000
We're talking the 70s gym.

09:26.000 --> 09:41.000
There's got to be a network property that somehow produces emergent properties, which in turn can loop back down and cause the neurons that are responsible for motor control to move the arm in a way that it satisfies the intention that I started out with.

09:41.000 --> 09:42.000
All right.

09:42.000 --> 09:43.000
So how is this going to work?

09:43.000 --> 09:45.000
You were talking about PG community college.

09:45.000 --> 09:49.000
The nice thing about teaching a community college is nobody gives it them to publish anything or not.

09:49.000 --> 09:52.000
You're going to be judged by how well you teach.

09:52.000 --> 09:54.000
So nobody cares about whether you publish.

09:54.000 --> 10:01.000
On the other hand, nobody's forcing you to write papers on the fifth decimal point of the existing theory.

10:01.000 --> 10:10.000
So I could play around and in this area in DC, I could hang around NIH and start listening to people come talk.

10:10.000 --> 10:15.000
And so you start understanding how patterns in neural systems work and so on.

10:15.000 --> 10:16.000
So it's got to be something.

10:16.000 --> 10:18.000
It's got to be something like that.

10:18.000 --> 10:21.000
So that's when I decided, all right, you know what?

10:21.000 --> 10:24.000
I'm going to give the term cause to the Newtonians.

10:24.000 --> 10:25.000
I'm not going to fight that battle.

10:25.000 --> 10:27.000
It's going to take me forever to fight that battle.

10:27.000 --> 10:39.000
So instead, what I want to do is look at the notion of constraint because as soon as the hard scientists get into trouble with that Newtonian silly understanding of efficient causes.

10:39.000 --> 10:44.000
You mentioned they retreat and hide behind the notion of constraint.

10:44.000 --> 10:46.000
And I thought, you know what?

10:46.000 --> 10:47.000
That's going to work.

10:47.000 --> 11:00.000
So that's that's how the whole that's how my, my, my trajectory towards reconceptualizing causality and specially formal and final cause in terms of constraints developed.

11:00.000 --> 11:01.000
It's interesting.

11:01.000 --> 11:05.000
And actually it worked well with the little analogy I use.

11:05.000 --> 11:16.000
When I'm trying to explain complexity to just random people at a party or something, I will say you can think of reductionism, you know, classic science as the study of the dancer.

11:16.000 --> 11:19.000
While complexity is the study of the dance, right?

11:19.000 --> 11:22.000
And a dance is not random motion.

11:22.000 --> 11:24.000
It has constraints, right?

11:24.000 --> 11:26.000
If it's going to be, it's going to be a jitterbug.

11:26.000 --> 11:28.000
It has one form of constraints.

11:28.000 --> 11:30.000
If it's going to be a waltz, it has another.

11:30.000 --> 11:35.000
And so when I read that and saw the movie you were making, I say, works perfectly with my good old.

11:35.000 --> 11:36.000
Absolutely.

11:36.000 --> 11:38.000
My good old analogy.

11:38.000 --> 11:39.000
Absolutely.

11:39.000 --> 11:42.000
And it held held together quite well.

11:42.000 --> 11:48.000
So now let's move on to your next topic, which is a term that most non philosophers will have never heard of.

11:48.000 --> 11:51.000
I've heard of it a few times, but it's not term we use very often.

11:51.000 --> 11:52.000
Santa Fe Institute.

11:52.000 --> 11:53.000
Myriology.

11:53.000 --> 11:55.000
Is that how you pronounce that?

11:55.000 --> 11:56.000
Myriology.

11:56.000 --> 11:59.000
And that's, again, the whole parts, parts whole.

11:59.000 --> 12:04.000
Because let's use an example from Brian Arthur's note that I love.

12:04.000 --> 12:10.000
That's a Santa Fe book on complexity of economics, economics and complexity.

12:10.000 --> 12:25.000
What, what a, an economy is, are a bunch of individual elements that interact in a constrained way to result in an

12:25.000 --> 12:33.000
emergent phenomenon that has certain properties that the components don't have.

12:33.000 --> 12:39.000
An economy has certain characteristics that the individual trader and seller don't.

12:39.000 --> 12:50.000
But once that whole WHLE, which is a coherent whole, and I really want to emphasize the fact that a coherent whole is different from a

12:51.000 --> 12:55.000
mass clump of stuff because it's organized.

12:55.000 --> 12:59.000
And what organizes it are the constraints.

12:59.000 --> 13:12.000
But once it's organized, then all of a sudden the components also acquire different properties because suddenly they are now traders and regulators and so on and so forth.

13:12.000 --> 13:13.000
Correct.

13:13.000 --> 13:16.000
So there you have the whole part.

13:16.000 --> 13:23.000
The parts of the components, correct, and, and the interact the constrained interactions among the components.

13:23.000 --> 13:29.000
The whole is what I'm calling in this new book a constraint regime.

13:29.000 --> 13:42.000
Because one of the problems we've also had, I don't know if it's Newtonianism or what, but we tend to reify things, things, no pun intended, we tend to reify things.

13:42.000 --> 13:59.000
But an economy is nothing other than all these constraints all held together by an overarching set of constraint regimes once the constraints close into it into a coherent whole.

13:59.000 --> 14:08.000
But they can then loop back down and affect their components and they acquire, they acquire, now they have a role, right?

14:08.000 --> 14:19.000
In a society, once a society is a socially organized structure, people can be citizens, they can be senators, they can be teachers.

14:19.000 --> 14:24.000
Those roles don't exist except within an organized society.

14:24.000 --> 14:34.000
So then the next question is, well, on a more general level, what is the relationship between the parts and the holes and the holes and the parts?

14:34.000 --> 14:42.000
If you really buy the whole Newtonian idea, ain't no difference between the parts and the holes, the holes are nothing but the sum of the parts.

14:42.000 --> 14:54.000
But that means you cannot explain how it is that my behavior is constrained top down by my living in a particular culture.

14:54.000 --> 15:05.000
The fact that I was born and raised in Cuba, the fact that all of these affect my behavior, but they don't do that as an efficient cause.

15:05.000 --> 15:17.000
A culture, an economic system doesn't cause my behavior to differ in any kind of efficient cause.

15:18.000 --> 15:25.000
But since the Newtonian Revolution, pretty much myriology got thrown out of the picture.

15:25.000 --> 15:31.000
So that messes up philosophy of mind because you cannot explain mental events.

15:31.000 --> 15:40.000
If you think of mental events as emergent properties because they should be reducible to a bunch of neurons pushing each other around.

15:40.000 --> 15:44.000
But where does the emergent property go when you have that?

15:44.000 --> 15:50.000
I'll tell you a little example. I've got my little homey examples that I love to use on this as people who doubt.

15:50.000 --> 15:53.000
We'll get this later, the idea of top down causality.

15:53.000 --> 15:59.000
I say, let's imagine me dead and run through a blender and poured into a bathtub, right?

15:59.000 --> 16:05.000
What's the chances that those chemicals are going to hop out of the bathtub, walk down the hill and go to the ice cream store?

16:05.000 --> 16:07.000
Essentially zero, right?

16:07.000 --> 16:14.000
And on the other hand, if it's me and I'm operating up in cognitive space and it's after dinner and we just had a nice dinner

16:14.000 --> 16:21.000
and I feel like a walk with my wife to go down and get something nice, then we may decide to haul all these atoms and molecules

16:21.000 --> 16:27.000
and they have nothing to say about it because this top down idea, well, let's go get some ice cream, causes the,

16:27.000 --> 16:33.000
and by the way, Newtonian physics is never, or let's say physics is never violated, right?

16:33.000 --> 16:37.000
The atoms are dragged along and they are dragged along through efficient causes.

16:37.000 --> 16:45.000
You know, they're all stuck together and bound by various forces, but the decision to go get the ice cream came at a higher level in the stack.

16:45.000 --> 16:51.000
And, you know, and again, some of the attempts to deny that that happens is just bizarre, right?

16:51.000 --> 16:54.000
Well, it is to me and you, but it isn't to an awful lot of people.

16:54.000 --> 17:00.000
And even folks, and I may, I hope there hasn't been a change in the last couple of years,

17:00.000 --> 17:17.000
but even somebody like Brian Rockland, who recognizes the reality of the emergent properties nonetheless gets very weary about ascribing causal properties,

17:17.000 --> 17:23.000
causal powers, let's use that for causal powers to those emergent properties.

17:23.000 --> 17:27.000
In a sense, the notion of supervenience is continuous.

17:27.000 --> 17:37.000
So they're very few of us, people like Carl Gillette, people like Robert Bishop, they're very few of us who are willing to go the next step and say,

17:37.000 --> 17:50.000
not only are emergent properties real, they have causal powers with respect to their own components and that's what homeostasis is for God's sake.

17:51.000 --> 17:59.000
Homeostasis readjusts the metabolism, the neural system and so on in order to maintain the integrity of the whole.

17:59.000 --> 18:11.000
But the idea that nonetheless that should be explicable in a reductionist fashion, the power aspect of it is still not quite,

18:11.000 --> 18:13.000
the physicists haven't bought it.

18:13.000 --> 18:17.000
Philosophers, I hate to say this, I have, I never read philosophy anymore.

18:17.000 --> 18:25.000
I, because all the, I grew up, I was trained as an analytic philosophy for in the United States, all they're worried about is the meaning of words.

18:25.000 --> 18:27.000
I mean, they're very few people.

18:27.000 --> 18:40.000
And you can tell why, how this is when you have people like Chalmers and Christoph Koch, who Chalmers has sort of thrown in the towel and he's really saying,

18:40.000 --> 18:48.000
the only way you're going to have mental properties is if you build them in from the get go from the, from the bot, you know, so therefore electrons have mental quality.

18:48.000 --> 18:51.000
Oh, come on, give me a break.

18:51.000 --> 18:52.000
Yeah.

18:52.000 --> 18:58.000
We had Christoph Koch on the show sometime back and he actually is a panpsychic.

18:59.000 --> 19:01.000
But you, but do you understand why?

19:01.000 --> 19:15.000
Because if all of reality comes from innate internal fundamental properties that only interact with efficient causes, there's no way you can get a coherent whole.

19:15.000 --> 19:24.000
And that's the key word coherently organized that then and from which emergent causal powers come.

19:24.000 --> 19:31.000
And it's interesting that they, another extremely bright guy named Ben Gertzel has been on my show many times, good friend of mine.

19:31.000 --> 19:37.000
I think he's a panpsychic for exactly that reason, because otherwise he's wedded to his model of the universe.

19:37.000 --> 19:39.000
And where does consciousness come from?

19:39.000 --> 19:45.000
If it doesn't, if it isn't innate, while a complexitarian would say, well, it's obviously emerged just another level on the stack, right?

19:45.000 --> 19:46.000
And that's not that hard.

19:46.000 --> 19:47.000
Correct.

19:48.000 --> 20:08.000
But it's this notion that my nature, you know, oh, it's in my nature is somehow given as an essence in the fundamental tiny, tiny bits that make up the rest of it.

20:08.000 --> 20:13.000
That's still much more widespread than one would think.

20:13.000 --> 20:14.000
Yeah.

20:14.000 --> 20:16.000
We'll get to supervenience later.

20:16.000 --> 20:20.000
And I think we have a somewhat different point of view, but not entirely different.

20:20.000 --> 20:21.000
We'll get to that later.

20:21.000 --> 20:32.000
But I think we're on the same page that, hey, this need to smuggle in something like consciousness or cognition as a fundamental property of matter seems to be a big overreach.

20:32.000 --> 20:36.000
I mean, do we try to smuggle in the fundamental nature of digestion?

20:36.000 --> 20:37.000
I don't think so, right?

20:37.000 --> 20:41.000
But we get overly confused when it comes to cognitive processes.

20:41.000 --> 20:42.000
But digestion is a good example.

20:42.000 --> 20:44.000
And that's the one John Searle has always used.

20:44.000 --> 20:45.000
That's why I always use it.

20:45.000 --> 20:46.000
Yeah, exactly.

20:46.000 --> 20:47.000
And I used to fight him.

20:47.000 --> 20:51.000
We were on the NEH board together.

20:51.000 --> 20:58.000
But the thing about digestion is digestion really doesn't do much.

20:58.000 --> 21:00.000
I mean, it is an effect.

21:00.000 --> 21:03.000
Digestion is an effect of all these other processes.

21:04.000 --> 21:11.000
The reason I like homeostasis is because the metastability of homeostasis is causally effective.

21:11.000 --> 21:21.000
It does, if I have the fudge brownie, it's going to switch all my glucose and all everything else around to keep the integrity of the whole.

21:21.000 --> 21:32.000
So it has caused what I would want to call causal powers, but I've given up that term because people will say, oh, but it is an efficient causation.

21:32.000 --> 21:33.000
No, that's right.

21:33.000 --> 21:34.000
It isn't.

21:34.000 --> 21:40.000
But it is DS Lewis's notion of cause meaning without which not.

21:40.000 --> 21:42.000
If that weren't the case, it wouldn't be.

21:42.000 --> 21:46.000
So that's the causal notion I would espouse.

21:46.000 --> 21:56.000
Okay, let's now make the next step, which is why don't you start to define what you mean by constraints and lay out a taxonomy of different kinds of constraints.

21:56.000 --> 21:59.000
This is where the book really started to get into new territory for me.

21:59.000 --> 22:01.000
I've had it very interesting.

22:01.000 --> 22:04.000
And that's what the new one is all about.

22:04.000 --> 22:08.000
That's what the new one is all about.

22:08.000 --> 22:19.000
I think in the first book, I made a distinction barring from Lila Gatlin's book called information in the living system, which was from 1960, something or other.

22:19.000 --> 22:27.000
A distinction between I use the term at the time, context free and context sensitive or context dependent.

22:27.000 --> 22:32.000
There's a lot of grief from people saying ain't nothing that's context independent.

22:32.000 --> 22:33.000
All right.

22:33.000 --> 22:35.000
So in this one, I call it context.

22:35.000 --> 22:37.000
I mean, nothing's context free.

22:37.000 --> 22:53.000
So in this book, I call it context independent and context dependent context independent according to Lila Gatlin are conditions that take a system far from equi probability.

22:53.000 --> 22:59.000
Now, whatever takes conditions away from random from white noise from random noise.

22:59.000 --> 23:08.000
So if you institute a gradient, you have you have instituted a context independent constraint.

23:08.000 --> 23:22.000
If you institute if you institute polarity or charge, we were talking the early universe here probably that were those were probably the earliest constraints.

23:23.000 --> 23:38.000
And I call them context independent because in a sense what they do is they set the context in a sense they set the boundaries of possibility space and inhomogeneities within that possibility space.

23:38.000 --> 23:42.000
So it's no longer white noise.

23:42.000 --> 23:51.000
Lila Gatlin calls context dependent constraints, those that take a system away from independence.

23:51.000 --> 23:58.000
So one of the things that's that I find interesting also is that we might put Newtonian is now.

23:58.000 --> 24:06.000
But when you look at the second law of thermodynamics and I'm petrified because I kind of talk about the second law of thermodynamics in this new book.

24:06.000 --> 24:17.000
But according to the Boltzmannian everybody's interpretation of the second law of thermodynamics, the the events in the particles are independent of one another.

24:17.000 --> 24:22.000
And I think you're never going to get complexity if you have independent particles.

24:22.000 --> 24:37.000
That's the beauty of Stuart Kaussman's button example button mesh example, you know, you tie one button to another tower, and all of a sudden, the thing turns into a mesh, right you have a phase transition, and you have a mesh.

24:37.000 --> 24:46.000
So what would I consider context dependent constraints that take a system far from independence.

24:46.000 --> 24:50.000
I would consider catalysts.

24:50.000 --> 24:56.000
Context dependent constraints. I would consider feedback loops.

24:56.000 --> 25:15.000
Context dependent constraints. And I think since that first book was published 20 some years ago, what's nice to me is the burgeoning of epigenetics nowadays, because if epigenetics isn't an example of context dependent constraints with a vengeance.

25:15.000 --> 25:31.000
I don't know what is so once you have all these context dependent constraints, acting inside a context independent possibility space set possibility space.

25:31.000 --> 25:43.000
Then I think the possibility of complexity appears you don't have a possibility of complexity just with emergent, just with efficient causes.

25:43.000 --> 25:58.000
These forms of constraints do. I also make a distinction between temporal and spatial constraints. I give two examples from from playground devices.

25:58.000 --> 26:17.000
In the playground swing. The child learns very quickly that when they kick is as important as how strong they kick. And the timing of the kick does not impart more energy to the kick.

26:17.000 --> 26:27.000
So that's an example of where Newton alone efficient causes alone won't work. Does that make sense. I mean you have to otherwise it won't kick.

26:27.000 --> 26:42.000
So that's another example is another example of a spatial context dependent constraint, because depending on the length of that plank on the top and the plinth on the bottom the base on the bottom.

26:42.000 --> 26:53.000
Then when where the child sits will be determined by those context dependent constraints in order for them to be able to do your daughter.

26:53.000 --> 26:59.000
Another example that I like a lot which I know you know Dave Snowden and he likes to use a lot.

26:59.000 --> 27:22.000
I think I used it first but that's okay is is the roundabout the the traffic circles. Right. The architecture of the roundabout is a context dependent constraint that affects the behavior of pedestrians and drivers in a system.

27:22.000 --> 27:38.000
So that's another example of a context. I think sequencing is a beautiful example of temporal constraints. A has to be done before B which has to be done before C which has to be done before E and it's done in a different order.

27:38.000 --> 27:42.000
The order of the make a huge difference in the outcome.

27:42.000 --> 28:06.000
So all of these I consider context sensitive constraints. I lump a lot of those into enabling constraints because I think of enabling constraints as particularly those context dependent constraints that together achieve closure such that this coherent whole emerges.

28:06.000 --> 28:20.000
Interesting. And you also I think that was interesting about your your use of the word constraint is you use it very broadly. Yes, you include it. I mean for instance one of my mentors in the complexity space was Harold Morowitz.

28:20.000 --> 28:30.000
Oh, sure. He was here nearby at George Mason for a long time. Yeah, I used to live out in Loudoun County and see him quite once a week.

28:30.000 --> 28:48.000
He has this idea that you know the 27 emergencies or whatever it is and then each one is defined by a set of pruning rules which you know tilt things one way or the other and that those faith those changes are fundamental inflection points in the evolution of the universe and some of them may have been

28:48.000 --> 29:02.000
some of them probably are contingent and some of them aren't and the ones that aren't maybe maybe correspond to your non contextual constraints. For instance, one of his steps is defined by the poly exclusion principle for instance.

29:02.000 --> 29:20.000
Absolutely. I mentioned that in the second book. I think notions of symmetry and conservation prints. You know, it's funny. Physicists all use word causality and so on and use half of the time they're talking about Newtonian cause then when they figure it can't fit and all of a sudden they move to principles.

29:20.000 --> 29:31.000
Right. To to consider that sort of thing and I absolutely agree. I think rules regulations are examples of constraints.

29:32.000 --> 29:40.000
They set the possibility space and they determine what is more likely within it than otherwise.

29:40.000 --> 29:49.000
And I did like the point and this is Harold makes the same point that especially higher up in the stack. We're talking more probabilities than we are blacks and whites.

29:49.000 --> 30:06.000
Absolutely. And perhaps what I speculate on in this new book is that whenever you have the emergence of a coherent dynamic, you have a phase transition to a continuous function.

30:07.000 --> 30:25.000
If you have that if I'm right on that, then it seems to me that top down control is analog. It's a it's a change in the setting of the system to an analog notion so you're going from your old fashioned toggle switch to a dimmer switch.

30:25.000 --> 30:40.000
And that's why homeostasis can keep the timeliness because that's very important for homeostasis in most ecosystems and it also can keep the sensitivity to local conditions.

30:40.000 --> 30:53.000
I think only analog them do that. I the Dyson's have been were poo pooed a lot, but there's something that tells me that their emphasis on analog control somehow might be might be on to something.

30:53.000 --> 30:57.000
I had to make it clear for the audience talk about Freeman and George.

30:57.000 --> 30:59.000
All deceased now. Yeah.

30:59.000 --> 31:03.000
Did George die recently about the last six months or a year.

31:03.000 --> 31:05.000
I used to come by the Santa Fe Institute.

31:05.000 --> 31:22.000
Freeman, I don't believe ever did at least I never met him there, but very interesting family also knew very interesting family also knew Esther Dyson who was George's brother who was a very, very extremely influential thinker in the early days of the computer industry and then later has become a

31:22.000 --> 31:26.000
brilliant venture capitalist, particularly in the Eastern Eastern Europe.

31:26.000 --> 31:27.000
That was her area.

31:27.000 --> 31:28.000
I didn't know.

31:28.000 --> 31:30.000
Yeah, quite amazing woman really.

31:30.000 --> 31:32.000
Yeah, she really was really quite.

31:32.000 --> 31:39.000
Okay, let's I haven't way later in my topic list, but let's talk about it now, which is analog versus digital.

31:39.000 --> 31:41.000
I actually have a fair bit of background in this.

31:41.000 --> 31:43.000
I had two of my companies back in my business career.

31:43.000 --> 31:44.000
They weren't mine.

31:44.000 --> 31:46.000
I was on the I was a chairman of one.

31:46.000 --> 31:51.000
I was a investor and director or another were both involved in software for designing computer chips.

31:51.000 --> 31:54.000
And in particular for designing analog computer chips.

31:54.000 --> 31:58.000
And so I learned quite a bit about analog versus digital.

31:58.000 --> 32:04.000
And for instance, I learned I probably should have known it that digital actually is analog below some level, right?

32:04.000 --> 32:10.000
And then there's there's a whole series of clever things they do to go from analog to digital.

32:10.000 --> 32:21.000
But then the other point, what you allude to is that on comparable computational tasks, analogs, literally six orders of magnitude more efficient.

32:21.000 --> 32:22.000
That's it.

32:22.000 --> 32:26.000
And that's not to be the reason why the brain doesn't overload.

32:26.000 --> 32:27.000
Correct.

32:27.000 --> 32:29.000
That has to be the reason why the brain.

32:29.000 --> 32:31.000
So the brain is a good example of that.

32:31.000 --> 32:38.000
Why the why the mind, why the mind when you transit, when you do the face transition to a mental event.

32:38.000 --> 32:51.000
What you're doing is you're transitioning from neuronal electrical exchanges to control on the basis of some kind of typology, a facial recognition.

32:51.000 --> 32:57.000
So now you're talking on the basis of how close is that pattern to this exemplar face.

32:57.000 --> 33:02.000
Though, again, to keep in mind, the brain is a good example because the brain is both digital and analog.

33:02.000 --> 33:03.000
Exactly.

33:03.000 --> 33:04.000
Exactly.

33:04.000 --> 33:05.000
Exactly.

33:05.000 --> 33:06.000
Correct.

33:06.000 --> 33:07.000
And it switches back and forth.

33:07.000 --> 33:08.000
Yeah.

33:08.000 --> 33:22.000
And so, you know, the domain of ideas or concepts or objects, you know, the, you know, the very important object ontology that at least mammals and above develop probably Burge to is continuously variable.

33:22.000 --> 33:23.000
And it's not perfect.

33:23.000 --> 33:26.000
It's classic analog classification.

33:26.000 --> 33:29.000
And yet it's actually implemented on digital circuitry.

33:29.000 --> 33:30.000
Correct.

33:30.000 --> 33:31.000
Correct.

33:31.000 --> 33:35.000
It's not digital, but the command top down is cut is analog.

33:35.000 --> 33:37.000
That makes perfect sense to me.

33:37.000 --> 33:38.000
Yeah.

33:38.000 --> 33:52.000
Though I would also just add that the continuously variable while true of analog versus digital is maybe less important than people think is one of the principles of computation is you can simulate analog at any level of detail you want.

33:52.000 --> 34:01.000
On the other hand, to simulate analog at extremely fine detail is very expensive computationally while you get it for free with analog.

34:01.000 --> 34:03.000
So that's the, that's the cool thing about analog.

34:03.000 --> 34:14.000
So that George Dyson used to use as an example, you know, even though the internet and all the computers that we use now are digital.

34:14.000 --> 34:20.000
When you look at social media and that stuff, it's what's connected to what.

34:20.000 --> 34:22.000
So we're back to the dance, right?

34:22.000 --> 34:23.000
Yeah.

34:23.000 --> 34:25.000
And that's the people who are analog, right?

34:25.000 --> 34:37.000
And it's the dance of the people and the people in a sense are the condensated nodes of the intersections of all these constraints.

34:37.000 --> 34:38.000
Right.

34:38.000 --> 34:48.000
So that's what I argue in this new book that everybody's all bent out of shape about identity because they all think of identity of something internal essential.

34:48.000 --> 34:58.000
The same thing as coach and and and Chalmers were concerned in, but we need to transition to identity as a set of interdependent constraints.

34:58.000 --> 35:00.000
That's what makes me me.

35:00.000 --> 35:01.000
Right.

35:01.000 --> 35:06.000
I am a set of interdependent constraints and high dimensional.

35:06.000 --> 35:08.000
Very high dimension.

35:08.000 --> 35:17.000
The other thing that's so annoying about the stupid identity politics of both the left and the right is both sides want to condense down to just one or two dimensions.

35:17.000 --> 35:20.000
And there's hundreds of dimensions, right?

35:20.000 --> 35:27.000
You know, I'm a cat, you know, someone's a dog fancier who loves mountain laurel, but not Rotodendrons.

35:27.000 --> 35:29.000
There's so many dimensions.

35:29.000 --> 35:34.000
And I say that these two are the ultimate ones, just like just kind of dumb, right?

35:34.000 --> 35:43.000
You know what did it for me that I finally decided I can finish that first book where was worked by Hinton, Jerry Hinton, who's now a big shot.

35:43.000 --> 35:50.000
Clout and Chalmers and they were doing early work in artificial networks that read words.

35:50.000 --> 35:54.000
It was one of the early text reading networks.

35:54.000 --> 35:59.000
And they were working on simulating.

35:59.000 --> 36:01.000
I had never heard it at the time.

36:01.000 --> 36:06.000
Have you ever heard the difference between surface and deep dyslexia?

36:06.000 --> 36:08.000
No, I was very interesting.

36:08.000 --> 36:10.000
I thought that was in your book.

36:10.000 --> 36:12.000
You gave a great example in your book.

36:12.000 --> 36:13.000
Oh, God.

36:13.000 --> 36:14.000
And I use it in a sense.

36:14.000 --> 36:16.000
No, well, it was their example.

36:16.000 --> 36:17.000
Okay.

36:17.000 --> 36:18.000
It was their example.

36:18.000 --> 36:21.000
They, you know, do you want me to repeat it here?

36:21.000 --> 36:22.000
Sure.

36:22.000 --> 36:23.000
I want you to tell the story.

36:23.000 --> 36:24.000
It's very interesting.

36:24.000 --> 36:25.000
I'll tell the story.

36:25.000 --> 36:28.000
Surface dyslexia is what most dyslexic human beings have.

36:28.000 --> 36:30.000
They transpose letters.

36:30.000 --> 36:35.000
So they read caught for cat or they read tag for cat.

36:35.000 --> 36:40.000
They just transpose letters or four gets read as a seven, that kind of thing.

36:40.000 --> 36:44.000
There was the point being, there's no semantics involved.

36:44.000 --> 36:48.000
It's purely the appearance of the input.

36:48.000 --> 36:50.000
Okay.

36:50.000 --> 36:53.000
Apparently deep dyslexia is very different.

36:53.000 --> 36:56.000
Now what I'll give you the example first.

36:56.000 --> 37:00.000
What Hinton Plout and Chalice, and the reason I plunked them all together is because Hinton

37:00.000 --> 37:03.000
and Plout would write Hinton and Chalice Plout and Chalice.

37:03.000 --> 37:07.000
So there's zillions of papers that came out about 25 years ago about this.

37:07.000 --> 37:14.000
And they trained these early reading neural networks.

37:14.000 --> 37:19.000
And when they had, when they train them with feedback loops, so they were current, recurrent

37:19.000 --> 37:30.000
networks, and they lesioned the networks above the feedback loops.

37:30.000 --> 37:34.000
The network would be shown cat and it would say tack.

37:34.000 --> 37:36.000
So it would do surface dyslexia.

37:36.000 --> 37:40.000
It would produce surface dyslexia kind of errors.

37:40.000 --> 37:48.000
But then if they lesioned the artificial neural network below the feedback loops, they might

37:48.000 --> 37:51.000
show the network again.

37:51.000 --> 37:54.000
These are, these are silicone networks.

37:54.000 --> 37:56.000
They're not organic.

37:56.000 --> 38:01.000
They would show them B, A, N, D band.

38:01.000 --> 38:09.000
And the thing output would say it had read orchestra or they would show it B, E, D.

38:09.000 --> 38:12.000
And the thing would say it had read cut.

38:12.000 --> 38:15.000
That is.

38:15.000 --> 38:21.000
And so somebody, not me, asked one of them, Hinton, Blauser, Chalice, how do you explain this?

38:21.000 --> 38:27.000
And their answer was the only way I can explain this is to postulate that the system, because of the

38:27.000 --> 38:30.000
middle layers that we don't quite know what's going on.

38:30.000 --> 38:33.000
And that has got to be what's going on with Chalice BD, by the way.

38:33.000 --> 38:37.000
The middle layer has created semantic attractors, period.

38:37.000 --> 38:38.000
Case closed.

38:38.000 --> 38:42.000
And the output is just showing from the semantic attractor.

38:42.000 --> 38:44.000
That makes perfect sense.

38:44.000 --> 38:47.000
But there's your emergent property being causally powerful.

38:47.000 --> 38:48.000
Interesting.

38:48.000 --> 38:54.000
By the way, for all my computer people who listen, and there's a lot, the GE Hinton she's talking about is the

38:54.000 --> 38:55.000
Jeffrey Hinton.

38:55.000 --> 38:57.000
He's the Jerry Hinton.

38:57.000 --> 39:00.000
I want, I shouldn't say this on, on the air, but I will.

39:00.000 --> 39:06.000
I said to John Sterle at one of these NEH meetings, John, I think Hinton's work is so very good.

39:06.000 --> 39:08.000
I don't understand why everybody's so interested in Hinton.

39:08.000 --> 39:10.000
I thought, he's very good.

39:10.000 --> 39:12.000
Trust me, he's very good.

39:12.000 --> 39:15.000
It is, it is the Jerry Hinton.

39:15.000 --> 39:16.000
Right.

39:16.000 --> 39:21.000
He's the guy that broke through the breakthroughs that drove all the stuff that we're doing today.

39:21.000 --> 39:22.000
Absolutely.

39:22.000 --> 39:28.000
And everybody was paying attention to these reading networks a long time ago, or at least not as many people should have been.

39:28.000 --> 39:31.000
Yeah, I was actually doing neural nets back in 2001, 2002.

39:31.000 --> 39:34.000
In fact, that's how I got invited out to the Santa Fe Institute.

39:34.000 --> 39:36.000
It was my work on evolutionary neural nets.

39:36.000 --> 39:41.000
Well, my book was published by MIT 1999, and this has been published before.

39:41.000 --> 39:45.000
So I think that stuff was published in 1995, 1998, thereabouts.

39:45.000 --> 39:46.000
Yep, that was.

39:46.000 --> 39:47.000
They did it for me.

39:47.000 --> 40:01.000
I thought, now I can write this book because I have some kind of evidence that the semantic attractor in the brain, in a culture, whatever you want to call it, has causal effects.

40:01.000 --> 40:04.000
Now, when I was reading the book, I write a lot of notes I always do.

40:04.000 --> 40:09.000
One I wanted to ask you about, because how does it fit into your concept of constraints?

40:09.000 --> 40:11.000
It certainly is one of Harold's pruning rules.

40:11.000 --> 40:16.000
And that's the idea of the species competitive exclusion principle.

40:16.000 --> 40:20.000
And which actually, my core field is evolutionary computing.

40:20.000 --> 40:26.000
And so I understand a lot of how speciation works from a mathematical perspective.

40:26.000 --> 40:31.000
And it's more or less a thing that is just true, right?

40:31.000 --> 40:41.000
If a competitive dynamic has these attributes, there will be, and a fitness landscape has a certain shape, there will be competitive exclusion principle around species.

40:41.000 --> 40:45.000
Does that fit into your idea of constraint?

40:45.000 --> 40:58.000
Well, if what I speculate about there existing a constraint regime, correct, then that is the constraint regime for that possibility space, right?

40:58.000 --> 41:06.000
Yeah, it basically says that if anything is competitive, if you get too far away from the center of what's efficient in that part of the fitness landscape,

41:06.000 --> 41:14.000
inevitably you'll be less, not inevitably, most of the time you will be, you know, less fit than the ones right at the near the peak.

41:14.000 --> 41:16.000
And therefore your numbers will go down.

41:16.000 --> 41:21.000
So it's very hard to move away from the peak of the species definition.

41:21.000 --> 41:25.000
The phenotypical collection, of course, as you point out, they're not all the same.

41:25.000 --> 41:30.000
They're an ensemble, but they nonetheless cluster around a species type.

41:30.000 --> 41:31.000
Correct.

41:31.000 --> 41:32.000
Correct.

41:32.000 --> 41:36.000
I don't know if this is an attempt to answer your question or attempt to evade it.

41:36.000 --> 41:38.000
I'm not sure.

41:38.000 --> 41:43.000
Tim Allen, T.H. Allen and Starr who have that book, they've got two editions of it.

41:43.000 --> 41:47.000
I like the first one, the first edition better called Hierarchy Theory.

41:48.000 --> 42:02.000
And they use as an example prairie grassland ecosystems in the Midwest, where apparently the prairie grassland competes against flowering plants.

42:02.000 --> 42:07.000
It also competes of obviously against forbs, horses that eat the grasses.

42:07.000 --> 42:08.000
Correct.

42:08.000 --> 42:16.000
Apparently, if you look at the, if you look at that whole ecosystem, and you look at it from the point of view of the grass.

42:16.000 --> 42:18.000
Right.

42:18.000 --> 42:25.000
Competition with the flowers is a lot harder than competition with the horses.

42:25.000 --> 42:29.000
Apparently, flowers will really do a number of flowering plants.

42:29.000 --> 42:30.000
I don't know.

42:30.000 --> 42:32.000
Dicotillodons or whatever the other things are called.

42:32.000 --> 42:33.000
All right.

42:33.000 --> 42:40.000
So over history, over a period of time, the prairie grasses send out have sent out.

42:40.000 --> 42:42.000
And of course, this is all selection.

42:42.000 --> 42:44.000
I'm not at all disputing, obviously.

42:44.000 --> 42:45.000
They are winning.

42:45.000 --> 42:54.000
They have sent out Mary stems, Mary stems or these shoots right below the surface, but that stick out enough that the horses can eat them.

42:54.000 --> 43:08.000
And so in a sense, Jim, they, the grass invites the horse to come in to feed and incorporates it into what is now an enlarged ecosystem.

43:08.000 --> 43:21.000
So instead of having two competing species, what you having is the enlargement of the niche or the constraint regime.

43:21.000 --> 43:32.000
And Tim Allen says it's kind of like a Shanghai where was a predator and to incorporate it into a an enlarged constraint regime.

43:32.000 --> 43:37.000
Now the, now the horse is part of the grasslands ecosystem.

43:37.000 --> 43:41.000
And that's how they keep the flowers at bay.

43:41.000 --> 43:52.000
I think that way of looking at it as a dynamical, mutual adjustment system is an awful lot better than two species competing.

43:52.000 --> 43:55.000
Yeah, two species are competing, but this other stuff.

43:55.000 --> 44:13.000
And then I get from the fact that I didn't realize until fairly recently that the understanding of the term fit during Darwin's era meant more like you go to a tailor to get a fitting for a new suit of clothes.

44:13.000 --> 44:18.000
So when you think of fit in that sense, it's what is it?

44:18.000 --> 44:21.000
It's a mutual adjustment, correct?

44:21.000 --> 44:33.000
Which means that when I talk about constraint, the form of bottom up and top down relationships has to be one of mutual constraint adjustment.

44:33.000 --> 44:42.000
That's what it basically is. You're adjusting all the constraints to see how you can best satisfy the overarching dynamic.

44:42.000 --> 44:48.000
Yeah, then to your example of the grasses and the horses, etc. It's always in a co-evolutionary context.

44:48.000 --> 44:52.000
Exactly. And that's your idea of context, right?

44:52.000 --> 44:57.000
It's temporal too. It's temporal too. You've got to include temporality. Absolutely.

44:57.000 --> 45:01.000
All right, so let's move on here. That was good, actually.

45:01.000 --> 45:09.000
In the interest of time, I'm going to skip over the COVID example and let's talk more about time temporal constraints.

45:09.000 --> 45:16.000
I think you did a really nice job of talking about cardinality, ordinality, and indexiality.

45:16.000 --> 45:17.000
Inexicality.

45:17.000 --> 45:25.000
Inexicality, okay. I want you to distinguish those, particularly the distinguished cardinality from ordinality.

45:25.000 --> 45:29.000
Well, cardinality is just a mount, correct?

45:29.000 --> 45:31.000
So a pile of sand has a cardinality.

45:31.000 --> 45:35.000
A pile of sand is bigger or smaller, correct.

45:35.000 --> 45:39.000
Ordinality is first, second, third.

45:39.000 --> 45:47.000
I don't see where you can get first, second, thirds much out of Newtonian mechanics.

45:47.000 --> 45:59.000
Whereas once you have temporal constraints instituted, this has to occur and this sets the stage for then the next thing to occur.

45:59.000 --> 46:11.000
Once that sets the stage for the third thing to occur, then you have ordinality, which is first, second, third, orders, right?

46:11.000 --> 46:15.000
Indexicality takes it a bit further.

46:15.000 --> 46:26.000
It's like perspective or the position you are in in a complex dynamical structure means there are certain properties that are indexical.

46:26.000 --> 46:29.000
This is to the left of this. This is to the right of this.

46:29.000 --> 46:32.000
That's what I mean by indexicality.

46:32.000 --> 46:43.000
It really has wreaked havoc in philosophy of mind because intentional causation again is eminently indexical.

46:43.000 --> 46:50.000
So one example I use in this new book is that philosophers use all the time.

46:50.000 --> 47:00.000
Mary told John's wife that he was cheating on her, but Mary doesn't know that John's wife's name is Alice.

47:00.000 --> 47:09.000
So did Mary tell John's wife that it was Alice?

47:09.000 --> 47:16.000
You see what I mean? It has to be interpreted, I think, in terms of the emergent dynamics and emergent properties.

47:16.000 --> 47:22.000
So it has to be treated in terms of indexicals, inside and out.

47:22.000 --> 47:33.000
So I think once you have emergent constraints in place, that's what, and I wish there were a verb that makes...

47:33.000 --> 47:36.000
How could you make a verb out of the word rugged?

47:36.000 --> 47:38.000
Ruggedify.

47:38.000 --> 47:42.000
It ruggedifies the possibility space, right?

47:42.000 --> 47:50.000
And each one of those valleys and attractor basins or attractor separate tricks is right.

47:50.000 --> 47:55.000
They are the ruggedness of a possibility space.

47:55.000 --> 48:07.000
And that explains why the view from inside an attractor looks real different from the view from the hill overlooking the next basin of attractor, correct?

48:07.000 --> 48:14.000
And when we talk about causality, we have to take that kind of indexicality into account.

48:14.000 --> 48:19.000
Yeah, then with respect to ordinality, many things are inherently ordered.

48:19.000 --> 48:27.000
In fact, I just published last night a very interesting podcast, Currents Number 100, with Sarah Walker and Lee Cronin.

48:27.000 --> 48:33.000
Ooh, I've got a note to her. Sarah and Mary Walker. Her stuff's really interesting.

48:33.000 --> 48:36.000
Yeah, and on time, it's an object.

48:36.000 --> 48:47.000
And their hypothesis is that evolution and other expanding complexity is essentially a series of steps that get taken, right?

48:47.000 --> 48:58.000
They point out that the most complex chemicals created by abiotic processes never have more than 13 or 14 steps.

48:58.000 --> 49:06.000
But abiotic processes can go much higher than that, and then man-made processes can go a bit further than that.

49:06.000 --> 49:10.000
And so I thought it was a very interesting juxtaposition with your idea of ordinality.

49:10.000 --> 49:17.000
One of the examples you gave was the social evolution of the processing of cassava.

49:17.000 --> 49:19.000
I believe it was in South America.

49:19.000 --> 49:24.000
That's from Heinrich's book on the secrets to our success or something.

49:24.000 --> 49:29.000
Heinrich is what, head of sociology or something at Harvard.

49:29.000 --> 49:36.000
It's apparently something that's poisonous, but yet nutritious if it weren't poisonous.

49:36.000 --> 49:48.000
The indigenous community in South America has figured out a way of leaching out that poison, but the preparation for that root vegetable has to be done in a particular sequence,

49:48.000 --> 49:52.000
because if you don't, you're going to kill out the entire population.

49:52.000 --> 49:59.000
Going back to Sarah Walker, somebody told me day before yesterday that apparently there's something I'm not on Twitter,

49:59.000 --> 50:02.000
which I probably should be neither on Twitter nor on Facebook.

50:02.000 --> 50:12.000
Somebody told me that somebody wrote a Twitter comment saying that Sarah Walker's driving forces are my constraints,

50:12.000 --> 50:16.000
which is flattering, I think, for me.

50:17.000 --> 50:18.000
She's very good.

50:18.000 --> 50:19.000
She's very good.

50:19.000 --> 50:25.000
And Lee too, the two of them were one of the better science, hard science episodes I've had in a while.

50:25.000 --> 50:28.000
Lee probably is very good. Yeah, I like his stuff.

50:28.000 --> 50:29.000
Interesting.

50:29.000 --> 50:30.000
Okay.

50:30.000 --> 50:36.000
Now you mentioned, why not hit on these, because they're classic rich examples.

50:36.000 --> 50:40.000
Kaufman's Buttons, Huygens Pendulums, and Benard Cells.

50:40.000 --> 50:42.000
Benard Cells.

50:42.000 --> 50:45.000
And paint those in with your ideas around.

50:45.000 --> 50:52.000
Well, the Benard Cells was the source of all my interest in complexity theory.

50:52.000 --> 50:55.000
It was the early 1980s, Jim.

50:55.000 --> 50:57.000
Could you tell us, folks, what it is, not everybody knows.

50:57.000 --> 51:00.000
Okay, a Benard Cells is you take a pan of water.

51:00.000 --> 51:07.000
They're called Ray Lee Benard Cells, and they were discovered at the beginning of the 20th century by Ray Lee and Benard.

51:07.000 --> 51:14.000
Take a pan of water, any kind of viscous fluid, and you heated the uniformity from below.

51:14.000 --> 51:17.000
All right, you still have conduction.

51:17.000 --> 51:26.000
After a certain gradient, after a certain threshold of instability, that's my context independent constraint, Jim.

51:26.000 --> 51:43.000
After you pass a threshold of that gradient, the system cannot handle any kind of fluctuation, and the context will amplify any minor bubble or perturbation.

51:43.000 --> 51:54.000
And all of a sudden, you will get convection cells, those rolling hexagonal cells made of billions of molecules of water that all align in a self-organized way.

51:54.000 --> 52:05.000
And that the cell itself constraints top down the individual molecules of water cell they behave as if they knew what was the one next to them was doing.

52:05.000 --> 52:06.000
All right.

52:06.000 --> 52:18.000
So, it was the 1980s, and I had to go to jury duty here in Montgomery County, and so I took a bag full of stuff that I had to read, and I figured, and I was reading,

52:18.000 --> 52:22.000
Kant's critique of practical reason.

52:22.000 --> 52:33.000
Kant's critique of practical reason says the problem with T, and by the way, at the time that Kant wrote, teleology was synonymous with self-organization.

52:33.000 --> 52:36.000
Go figure, 1804.

52:36.000 --> 52:47.000
Kant said, in order to understand this kind of phenomena, he said, we need an understanding of circular causality that is unknown to us.

52:47.000 --> 52:56.000
Because remember, Kant had bought the Newtonian-Humian collade that was all effective, efficient causality.

52:56.000 --> 53:00.000
So, he said, but look at how nature works.

53:00.000 --> 53:06.000
A tree produces the leaves and then is produced in turn by the leaves.

53:06.000 --> 53:16.000
So, the whole tree is produced by the component parts and in turn loops back down and produces the components that created in the first place.

53:16.000 --> 53:23.000
And so, I'm reading this, going all right, yeah, but how do we fit this into modern science?

53:23.000 --> 53:34.000
And then the Prigogene and Stenger's order out of chaos had just come out of print, come in print, and he's looking at dissipated structures which all have that process.

53:34.000 --> 53:40.000
You get individually constrained interactions that after a threshold of instability,

53:40.000 --> 53:48.000
cross a phase transition and self-organize to produce a whole which then loops back down and constrains the component parts.

53:48.000 --> 53:57.000
So, that to me was, whoa, I found a scientifically respectable way of explaining teleology and formal cause.

53:57.000 --> 54:00.000
That's what did it for me in the 80s.

54:00.000 --> 54:03.000
You were at the right place and right time because Prigogene certainly-

54:03.000 --> 54:08.000
Well, and just seeing again, not having to publish so that you-

54:08.000 --> 54:11.000
Go where you want to go, right?

54:11.000 --> 54:21.000
Decimal point of whatever you already exist allowed me to be a dilettante and play around with ideas just because they were interesting.

54:21.000 --> 54:34.000
And one of the things that Prigogene predicts is that these, especially these abiotic complex systems will actually be more efficient at burning energy than their predecessors.

54:34.000 --> 54:36.000
And that's the Bernard cells for sure.

54:36.000 --> 54:39.000
They actually move more heat through by convection.

54:39.000 --> 54:46.000
And one of my favorites is the whirlpool in the toilet actually allows the water to go down faster.

54:46.000 --> 54:53.000
So it actually is dissipating the potential energy of the water in the tank more quickly than if it didn't form the whirlpool.

54:53.000 --> 54:57.000
You know what I used in class when I taught courses about mines, rains, and machines?

54:57.000 --> 55:01.000
I actually taught a seminar on mines, rains, and machines at PG.

55:01.000 --> 55:05.000
But I take the two, you know, the standard two large gallons.

55:05.000 --> 55:06.000
Oh, yeah.

55:06.000 --> 55:07.000
Put them together.

55:07.000 --> 55:09.000
And then watch the tornadoes.

55:09.000 --> 55:12.000
And the students would, ooh.

55:12.000 --> 55:16.000
Yeah, we made one of those for my daughter when she was like a middle school student.

55:16.000 --> 55:17.000
Yeah, that was a cool thing.

55:17.000 --> 55:18.000
It's pretty cool.

55:18.000 --> 55:20.000
They can really appreciate it intuitively.

55:20.000 --> 55:32.000
Yeah, so the idea of Prigogene and the idea of dissipative systems, even though they have more structure and more interesting things going on, are also, generally speaking, more efficient at burning energy.

55:32.000 --> 55:36.000
And so the good old second law never actually gets violated.

55:36.000 --> 55:38.000
It's just in a different form.

55:38.000 --> 55:40.000
So this, then, you've set me up perfectly.

55:41.000 --> 55:53.000
But thermal equilibrium gets retarded a bit because you have a structure that gets created in the process that persists a bit longer than the component parts.

55:53.000 --> 55:56.000
But that's the explanation for social systems.

55:56.000 --> 56:00.000
That's an explanation for its cities, right?

56:00.000 --> 56:04.000
Cities are more energy efficient than they were organized, right?

56:04.000 --> 56:11.000
Though they burn a lot at per unit square foot, they burn a lot, but per person, they're less, which actually now it sets up to my next time.

56:11.000 --> 56:14.000
You're not going to fool the second law.

56:14.000 --> 56:15.000
No, exactly.

56:15.000 --> 56:16.000
That's the one law.

56:16.000 --> 56:22.000
If anyone ever comes to you and tells you they beat the second law, tell them to go pound sad, right?

56:22.000 --> 56:24.000
And so now we get to where it gets more interesting.

56:24.000 --> 56:31.000
And this, of course, is the secret of life is catalyst loops, autocatalytic networks, et cetera.

56:31.000 --> 56:39.000
This is where we go from whirlpools, which have a self-forming part, but they're not fully closed loops, right?

56:39.000 --> 56:48.000
Well, I really liked a book that came out about seven years ago by two...

56:48.000 --> 56:54.000
Well, a lot of them worked out of the University of the Basque country in Spain.

56:54.000 --> 56:59.000
And the good thing about those folks is they published in English, otherwise they would go into black hole.

56:59.000 --> 57:00.000
But they published in there.

57:00.000 --> 57:04.000
Unfortunately, this book is Springer, and Springer's so damn expensive, nobody buys the book.

57:04.000 --> 57:05.000
But I think they're very good.

57:05.000 --> 57:08.000
And the book is called Biological Autonomy.

57:08.000 --> 57:18.000
And their argument is that, well, things like the Krebs cycle and so on, these are closures of process.

57:18.000 --> 57:27.000
But once you start having autocatalytic and hypercycles, a la eigen and so on, what do you have that...

57:27.000 --> 57:35.000
The constraint loop that closes is a loop of constraints themselves.

57:35.000 --> 57:42.000
And so the constraints create the constraining conditions that make them possible to begin with.

57:42.000 --> 57:50.000
And that is what enables their self-reinforcing, but their self-perpetuating.

57:50.000 --> 58:04.000
And so these Matteo Moreno and Mocio argue that is what makes living things different from, say, even the BZ reaction,

58:04.000 --> 58:11.000
where the boundary conditions, the constraints are, in a sense, self-set from without.

58:11.000 --> 58:17.000
You set the conditions of the pan of water or the chemicals.

58:17.000 --> 58:25.000
But once you get a situation where the constraints themselves become self-perpetuating,

58:25.000 --> 58:30.000
then you have the possibility of reproduction of species and that sort of thing.

58:30.000 --> 58:33.000
Now, you didn't really hit on it as hard as I thought you might.

58:33.000 --> 58:41.000
But the perfect example of that is that the autocatalytic reactions within a cell are also responsible

58:41.000 --> 58:45.000
for building and maintaining the membrane that allows the concentration.

58:45.000 --> 58:47.000
And that's hugely important to my mind.

58:47.000 --> 58:49.000
Absolutely, absolutely.

58:49.000 --> 58:55.000
I think that's what they mean because, from memory, we've always thought of it as boundary conditions.

58:55.000 --> 59:04.000
And that was my beef with Polani, because Polani says, Polani was ultimately religious.

59:04.000 --> 59:09.000
And so Michael Polani, the philosopher at the beginning of the 20th century, I guess it was,

59:09.000 --> 59:14.000
he believed that God sets the original boundary conditions.

59:14.000 --> 59:18.000
And then once you've got that, then everything else self-organizes within it.

59:18.000 --> 59:27.000
But the whole point of, I think, the closure of constraints is that it creates the boundary conditions

59:27.000 --> 59:30.000
within which it self-organizes as well.

59:30.000 --> 59:32.000
So yes, you're absolutely right.

59:32.000 --> 59:34.000
Yeah, I think that's hugely important.

59:34.000 --> 59:39.000
And of course, as we've learned, the nature of these membranes changed over time,

59:39.000 --> 59:41.000
and it's continually changing.

59:41.000 --> 59:46.000
And the fact that they're semi-permeable with different rules for what goes from the inside out

59:46.000 --> 59:54.000
and what comes from the outside in are hugely important to maintain the reactions that are going inside.

59:54.000 --> 01:00:00.000
I think we finally understood that because of the role of interfaces in computers.

01:00:00.000 --> 01:00:02.000
Yeah, I think that helps.

01:00:03.000 --> 01:00:11.000
And what, therefore, what that also means, I think, is once you have a phase transition to a new dynamic,

01:00:11.000 --> 01:00:14.000
you have a new code.

01:00:14.000 --> 01:00:20.000
And a new code means simply the settings and the rules that govern that membrane,

01:00:20.000 --> 01:00:28.000
that boundary conditions, what it allows in and what it produces as waste and as action.

01:00:28.000 --> 01:00:29.000
Absolutely.

01:00:29.000 --> 01:00:33.000
And then the other interesting example you gave, which I had thought of before,

01:00:33.000 --> 01:00:37.000
is you talked about the architecture of the circulatory system as another...

01:00:37.000 --> 01:00:40.000
That's more anointing, which is a really nice example,

01:00:40.000 --> 01:00:48.000
because the vasculature of the body, the lymph node and the blood circulating system,

01:00:48.000 --> 01:00:54.000
really prevents the seeping out, right?

01:00:54.000 --> 01:00:56.000
But it is not an energetic force.

01:00:56.000 --> 01:00:58.000
That's what the heart does.

01:00:59.000 --> 01:01:11.000
But the vasculature is more like the timing of the playground swing in that it controls the settings.

01:01:11.000 --> 01:01:12.000
You know what?

01:01:12.000 --> 01:01:17.000
After I submitted this MIT, which was, geez, it was almost a year and a half, two years ago,

01:01:17.000 --> 01:01:19.000
but it took so long.

01:01:19.000 --> 01:01:28.000
I am fascinated recently by the inflammatory system and the immune system connection,

01:01:28.000 --> 01:01:32.000
because they are now talking about three levels.

01:01:32.000 --> 01:01:38.000
They're talking about structure, function, and then regulation.

01:01:38.000 --> 01:01:44.000
And that, you know, if my arm gets cut off,

01:01:44.000 --> 01:01:49.000
then the inflammation hits it immediately to try to repair the wound.

01:01:49.000 --> 01:01:51.000
All right?

01:01:51.000 --> 01:01:55.000
If all of a sudden the interactions in the body are out of kilter,

01:01:55.000 --> 01:01:58.000
then the function of homeostasis may not work as well.

01:01:58.000 --> 01:02:01.000
That you get diabetes and so on and so forth.

01:02:01.000 --> 01:02:07.000
But the idea recently is that perhaps there is a third level,

01:02:07.000 --> 01:02:11.000
which is the setting of the functional system.

01:02:11.000 --> 01:02:15.000
I'll call it the set points or the settings,

01:02:15.000 --> 01:02:22.000
and that perhaps things like PTSD, chronic inflammatory disease syndrome,

01:02:22.000 --> 01:02:29.000
that kind of thing is that on and off switch, for example,

01:02:29.000 --> 01:02:33.000
the dimmer switch, the analog is screwy.

01:02:33.000 --> 01:02:41.000
So it's the set point, it's the regulatory control of that function.

01:02:41.000 --> 01:02:45.000
That's often that maybe that's the way to attack PTSD, for example.

01:02:45.000 --> 01:02:48.000
There's nothing wrong with the function of PTSD.

01:02:48.000 --> 01:02:51.000
We're supposed to freak out if we think someone's attacking us at night.

01:02:51.000 --> 01:02:57.000
What's wrong is the fact that we are now reacting in a different context

01:02:57.000 --> 01:02:59.000
the way it should have been before.

01:02:59.000 --> 01:03:02.000
Then that means there's something wrong with the toggle switch.

01:03:02.000 --> 01:03:07.000
There's nothing wrong with the switch, which I find really interesting,

01:03:07.000 --> 01:03:14.000
because I think that has a lot to say with two for social systems.

01:03:14.000 --> 01:03:20.000
It has a lot to say, not just for the inflammatory system.

01:03:20.000 --> 01:03:24.000
Perhaps all of complex dynamical systems have those three layers,

01:03:24.000 --> 01:03:28.000
structure, function, and then regulation.

01:03:28.000 --> 01:03:32.000
And then, of course, the question is, how do these three levels interact?

01:03:32.000 --> 01:03:37.000
And they do not interact by efficient causes, they interact by constraints.

01:03:37.000 --> 01:03:45.000
That everybody who's done hierarchy theory in biology is comfortable with that.

01:03:45.000 --> 01:03:51.000
Okay, let's move on to another topic here, which is that you described them as constraints,

01:03:51.000 --> 01:03:56.000
though I would not normally think of them that way, but I think in your lens they work.

01:03:56.000 --> 01:04:01.000
And that's the idea of scaffolds and scaffolding of affordances, etc.

01:04:01.000 --> 01:04:07.000
Talk about your thoughts on scaffolding and how you can use the language of constraints around that.

01:04:07.000 --> 01:04:17.000
I think you have the old-fashioned architectural scaffolds that are external artifacts

01:04:17.000 --> 01:04:23.000
that are temporary and that guide the construction of new buildings, correct?

01:04:23.000 --> 01:04:31.000
But if you think of constraints, of context-sensitive constraints as conditions and factors

01:04:31.000 --> 01:04:37.000
that take a system away from independence, they link things together.

01:04:37.000 --> 01:04:48.000
What scaffolds do, and I love the work of Bishop and especially the word of WimSat,

01:04:49.000 --> 01:04:54.000
they've done work on scaffolding long before they got fashionable recently.

01:04:54.000 --> 01:05:03.000
They provide a temporary equilibrium point from which to take the next step,

01:05:03.000 --> 01:05:07.000
and it's not only, it's like a ratchet.

01:05:07.000 --> 01:05:10.000
I think of scaffolds almost like ratchets.

01:05:10.000 --> 01:05:20.000
They provide a temporary, metastable position from which the next step,

01:05:20.000 --> 01:05:28.000
whose direction the scaffold itself also suggests, can be more easily taken.

01:05:28.000 --> 01:05:32.000
But that chapter you're thinking about from the new book,

01:05:32.000 --> 01:05:37.000
there's so many other different types of constraints, of that kind of constraints.

01:05:37.000 --> 01:05:39.000
There's entrenchment.

01:05:39.000 --> 01:05:46.000
That's a hell of a constraint that we use a lot, especially in social systems, correct?

01:05:46.000 --> 01:05:52.000
To retard any innovation or buffers.

01:05:52.000 --> 01:05:59.000
I think probably the difference between a buffer and an entrenchment might be how long it lasts, right?

01:05:59.000 --> 01:06:07.000
But it's a way to control the relationships between the inside and the outside,

01:06:07.000 --> 01:06:12.000
and the next step, that's why I think of it as a form of constraint.

01:06:12.000 --> 01:06:18.000
Because the scaffold, again, is not, my bent noir is always efficient cause.

01:06:18.000 --> 01:06:23.000
I'm always thinking, well, this is something that has effects, but it's not as an efficient cause.

01:06:23.000 --> 01:06:27.000
So I have buffers, I have entrenchment, I have scaffolding.

01:06:27.000 --> 01:06:32.000
I have that kind of process that we use a lot.

01:06:32.000 --> 01:06:35.000
And now you could throw those in with catalysts.

01:06:35.000 --> 01:06:36.000
Absolutely.

01:06:36.000 --> 01:06:39.000
And certainly, let's say scaffolds and catalysts both have the effect,

01:06:39.000 --> 01:06:42.000
while they don't necessarily provide energy themselves,

01:06:42.000 --> 01:06:46.000
they lower the activation energy for something to occur.

01:06:46.000 --> 01:06:47.000
Correct, correct.

01:06:47.000 --> 01:06:54.000
And even those scaffolds that are not temporary like the flying buttresses of Gothic cathedrals

01:06:54.000 --> 01:06:56.000
that end up being part of the structure,

01:06:56.000 --> 01:06:59.000
and that is also true of these lattices.

01:06:59.000 --> 01:07:09.000
They implant that are embedded with nutrients that promote bone growth, right?

01:07:09.000 --> 01:07:22.000
The point being that the location and the direction of the holes in that lattice are what pattern the bone growth.

01:07:22.000 --> 01:07:28.000
But then they end up getting absorbed and becoming part of the bone itself.

01:07:28.000 --> 01:07:38.000
So these are all forms of affecting consequences that are not, or that are in addition to.

01:07:38.000 --> 01:07:42.000
I don't want to discount efficient causes, obviously.

01:07:42.000 --> 01:07:47.000
I just don't believe they're the full story.

01:07:47.000 --> 01:07:52.000
And this, in some sense, the basic laws of physics continue to be true,

01:07:52.000 --> 01:07:57.000
but there's much more interesting structure being built that's in addition.

01:07:57.000 --> 01:08:01.000
And that's what the naive reductionism misses.

01:08:01.000 --> 01:08:02.000
Correct.

01:08:02.000 --> 01:08:03.000
And now, go ahead.

01:08:03.000 --> 01:08:04.000
I'm sorry.

01:08:04.000 --> 01:08:05.000
I interrupt.

01:08:05.000 --> 01:08:06.000
I'm Cuban.

01:08:06.000 --> 01:08:07.000
I'm sorry.

01:08:07.000 --> 01:08:08.000
You talk with your hands.

01:08:08.000 --> 01:08:09.000
That's right.

01:08:09.000 --> 01:08:10.000
That's right.

01:08:10.000 --> 01:08:13.000
And that's, again, I think that it's kind of this myopia of over-reductionism.

01:08:13.000 --> 01:08:14.000
Nothing wrong with reductionism.

01:08:14.000 --> 01:08:16.000
No, no, there's nothing wrong with that.

01:08:16.000 --> 01:08:18.000
You need to know both the dance and the dancer.

01:08:18.000 --> 01:08:23.000
But there's a sense that somehow the relational and the dynamical are not real.

01:08:23.000 --> 01:08:28.000
Every bit is real as the primary properties.

01:08:28.000 --> 01:08:33.000
And that's my problem with myriology and nothing but is so on.

01:08:33.000 --> 01:08:38.000
The problem that everybody complained about top-down causation is not possible

01:08:38.000 --> 01:08:45.000
is because it would violate physical closure and it would violate the conservation of energy.

01:08:45.000 --> 01:08:49.000
Sure, if you think of it as efficient causes, of course, it's going to do those two things.

01:08:49.000 --> 01:08:56.000
But if it operates as constraining dynamics, you're not violating physical closure

01:08:56.000 --> 01:09:00.000
or constraint or conservation.

01:09:00.000 --> 01:09:03.000
So that's why it works very nicely.

01:09:03.000 --> 01:09:08.000
It's not violating any basic physics tenets.

01:09:08.000 --> 01:09:10.000
Why don't you do a little riff on that?

01:09:10.000 --> 01:09:14.000
Because that is one of the questions in complexity.

01:09:14.000 --> 01:09:16.000
And it befuddles the laymen in particular.

01:09:16.000 --> 01:09:17.000
What?

01:09:17.000 --> 01:09:19.000
Top-down causality.

01:09:19.000 --> 01:09:24.000
And how you can have top-down causality and no magic needs occur.

01:09:24.000 --> 01:09:29.000
Well, in the very same way that homoestasis changes my glucose production

01:09:29.000 --> 01:09:32.000
or how does a culture affect me?

01:09:32.000 --> 01:09:34.000
That is top-down causality.

01:09:34.000 --> 01:09:37.000
That is causality from the hole in which I am embedded.

01:09:37.000 --> 01:09:41.000
If I were not part of that culture, it would not affect me.

01:09:41.000 --> 01:09:42.000
Correct?

01:09:42.000 --> 01:09:43.000
Right.

01:09:43.000 --> 01:09:49.000
And that means that the constraint dynamic of the culture in which I am embedded

01:09:49.000 --> 01:09:55.000
be the college at which I taught, the society in which I live, the family to which I belong,

01:09:55.000 --> 01:09:59.000
the constraint structure of each of those organizations

01:09:59.000 --> 01:10:08.000
changes the likelihood of different behaviors that might otherwise have been open to me that are not.

01:10:08.000 --> 01:10:15.000
In the very same way that once entrained into a Benard cell, the molecule of water

01:10:15.000 --> 01:10:21.000
has different probabilities of where it is going to go

01:10:21.000 --> 01:10:25.000
because the constraint structure of the Benard cell affects it.

01:10:25.000 --> 01:10:27.000
And that is what I mean by top-down causation.

01:10:27.000 --> 01:10:31.000
So there is nothing magical about it, but it is not efficient causality.

01:10:31.000 --> 01:10:34.000
If you think of it as efficient causality, then of course it is magical.

01:10:34.000 --> 01:10:35.000
Gotcha.

01:10:35.000 --> 01:10:40.000
And there has been many, many pointless conversation on this as you no doubt have experienced it.

01:10:40.000 --> 01:10:41.000
Absolutely.

01:10:41.000 --> 01:10:44.000
Well, my centuries of this going on.

01:10:44.000 --> 01:10:45.000
Indeed.

01:10:45.000 --> 01:10:46.000
Let's move on.

01:10:46.000 --> 01:10:47.000
We are getting kind of late on time here.

01:10:47.000 --> 01:10:49.000
We have got about another 13 minutes.

01:10:49.000 --> 01:10:51.000
And this was something new to me.

01:10:51.000 --> 01:10:54.000
Very interesting to always run across something new.

01:10:54.000 --> 01:10:57.000
And that is the idea of many to one transitions.

01:10:57.000 --> 01:10:59.000
Maybe you can dig into this in some depth.

01:10:59.000 --> 01:11:00.000
Okay.

01:11:00.000 --> 01:11:07.000
And that was, all right, when at the beginning, once behaviorism got put to bed,

01:11:07.000 --> 01:11:11.000
then functionalism came into play or the identity theory.

01:11:11.000 --> 01:11:17.000
So the idea was that mind is to brain as a computer software is to its hardware.

01:11:17.000 --> 01:11:22.000
So then people said, all right, just like a lot of different,

01:11:22.000 --> 01:11:29.000
Microsoft Office can be run on different, on Apple and the different hardware devices,

01:11:29.000 --> 01:11:34.000
that's the explanation that gives some legitimacy to the notion of a mind.

01:11:34.000 --> 01:11:36.000
These are the notion of the brain.

01:11:36.000 --> 01:11:39.000
The brain is the hardware, the mind is the software fight.

01:11:39.000 --> 01:11:46.000
But there was also always the idea that the notion of supervenience and Donald Davidson's

01:11:46.000 --> 01:11:54.000
term is there will be no change in the supervenient properties without any corresponding changes

01:11:54.000 --> 01:11:58.000
in the subvening in the hardware.

01:11:58.000 --> 01:12:04.000
So there was always implicit in the notion of supervenience, a one to one relationship.

01:12:04.000 --> 01:12:08.000
And the reason I think that was true was because I don't think they ever got away from the

01:12:08.000 --> 01:12:09.000
physicals out.

01:12:09.000 --> 01:12:11.000
So there was always that one to one relationship.

01:12:11.000 --> 01:12:18.000
So the idea was, all right, so a mental event, my thinking of my grandmother,

01:12:18.000 --> 01:12:25.000
my pain in my leg will always be correlated one to one with this particular neuro pattern

01:12:25.000 --> 01:12:28.000
in the brain, which indicates pain in my leg.

01:12:28.000 --> 01:12:32.000
This one about indicates that's my, my grandmother.

01:12:32.000 --> 01:12:40.000
But very quickly, multiple realizability, many to one relationships, all sudden came about.

01:12:40.000 --> 01:12:46.000
And that was that, well, though, and behold, if this part of the brain is excised,

01:12:46.000 --> 01:12:52.000
the hearing function might be taken over by the other part of the brain.

01:12:52.000 --> 01:12:57.000
Another part of the brain that was supposedly not at all dedicated to hearing, but all of

01:12:57.000 --> 01:12:58.000
a sudden it was.

01:12:58.000 --> 01:13:05.000
So the notion, and I almost wanted to name this title, this new book, Imprasive Degeneracy.

01:13:05.000 --> 01:13:11.000
Don't get so, don't get cutesy here, because biologists have always been very comfortable

01:13:11.000 --> 01:13:12.000
with degeneracy.

01:13:12.000 --> 01:13:19.000
That is, there are many ways for the same amino acids to produce different amino acids to produce

01:13:19.000 --> 01:13:20.000
the same protein.

01:13:21.000 --> 01:13:31.000
That's what I mean by many to one, many different lower level paths to realize the same emergent

01:13:31.000 --> 01:13:32.000
property.

01:13:34.000 --> 01:13:37.000
That's what I mean by many to one.

01:13:37.000 --> 01:13:45.000
And that seems to be true in general for the higher level properties of complex dynamical

01:13:45.000 --> 01:13:46.000
systems.

01:13:46.000 --> 01:13:57.000
An economy can stay itself despite many different varieties or many different configurations,

01:13:57.000 --> 01:14:04.000
as long as that overarching constraint structure remains within a certain range.

01:14:04.000 --> 01:14:07.000
Does that, have I made sense here?

01:14:07.000 --> 01:14:08.000
Yes, ish.

01:14:08.000 --> 01:14:10.000
Let me drill it a little further.

01:14:10.000 --> 01:14:11.000
All right.

01:14:11.000 --> 01:14:16.000
You also talk about many to one, because, you know, we do have multiple realizable domains,

01:14:16.000 --> 01:14:18.000
and the idea of degeneracy is very important.

01:14:18.000 --> 01:14:24.000
And for the audience, degeneracy basically means that things with different forms can

01:14:24.000 --> 01:14:26.000
have the same function, right?

01:14:26.000 --> 01:14:27.000
Correct.

01:14:27.000 --> 01:14:29.000
Different lower levels, same higher levels.

01:14:29.000 --> 01:14:30.000
Same higher level.

01:14:30.000 --> 01:14:34.000
And there's a bunch of famous examples in biochemistry where it's more famous, but you also talked

01:14:34.000 --> 01:14:40.000
about many to one as something analogous to dimensional reduction in systems.

01:14:40.000 --> 01:14:44.000
And think about the fact that, you know, with the example I gave before, Jim gets up out

01:14:44.000 --> 01:14:48.000
of his chair and goes down the hill to the ice cream store.

01:14:48.000 --> 01:14:53.000
There's lots and lots and lots of predicate signals that probably led to that, right?

01:14:53.000 --> 01:14:58.000
And they eventually got concentrated down to a single decision.

01:14:58.000 --> 01:15:03.000
Should I get up, go down the hill, get an ice cream cone, or should I go to the refrigerator,

01:15:03.000 --> 01:15:07.000
freezer and pull out a frozen yogurt bar, right?

01:15:07.000 --> 01:15:12.000
And the fact that there's many, many, many inputs, but there's a single decision around

01:15:12.000 --> 01:15:16.000
the affordance was also the way you described many to one.

01:15:16.000 --> 01:15:25.000
The reverse of it is pluripotentiality, which is one lower level that has the potential

01:15:25.000 --> 01:15:29.000
for becoming much more different functionality.

01:15:29.000 --> 01:15:32.000
And of course, stem cells are the example of that, right?

01:15:32.000 --> 01:15:37.000
They are pluripotents.

01:15:37.000 --> 01:15:42.000
They are not totipotents, which people thought might, they might be for a while,

01:15:42.000 --> 01:15:44.000
that they could become any other.

01:15:44.000 --> 01:15:48.000
They're not quite their totipotentiality.

01:15:48.000 --> 01:15:51.000
But that was the problem with supervenience.

01:15:51.000 --> 01:15:59.000
Because then the question was, how can the same neural processes in the brain produce

01:15:59.000 --> 01:16:08.000
such very different, differently property functions, higher level properties?

01:16:08.000 --> 01:16:15.000
And Davidson said, if you can't identify a causal relationship between the two,

01:16:15.000 --> 01:16:18.000
then you might as well go back to behaviorism.

01:16:18.000 --> 01:16:28.000
And at that point, J-Wan Kim at Brown, who had been a big advocate of supervenience at the time,

01:16:28.000 --> 01:16:30.000
decided supervenience won't work.

01:16:30.000 --> 01:16:34.000
It either is one to one or it's not.

01:16:34.000 --> 01:16:36.000
And that's why he titled that.

01:16:36.000 --> 01:16:39.000
Was it a paper or was it a book called Descartes' Revenge?

01:16:39.000 --> 01:16:48.000
Because then again, the problem was, how do you get top down causality in that once you decide to go to the fridge, Jim,

01:16:48.000 --> 01:16:51.000
you could decide to walk directly to the fridge.

01:16:51.000 --> 01:16:57.000
You could decide to go outside because somebody is going to watch you take something from the fridge

01:16:57.000 --> 01:16:59.000
and you go outside, you go all the way around.

01:16:59.000 --> 01:17:05.000
So there are a lot of different ways to implement that top down decision, correct?

01:17:05.000 --> 01:17:16.000
And the problem with again, efficient causality is that it only worked for instantaneous relationships.

01:17:16.000 --> 01:17:21.000
Efficient causality cannot handle what used to be called in philosophy standing causes.

01:17:21.000 --> 01:17:26.000
In other words, I decided I'm going to write a book and it took me two damn years to do so.

01:17:26.000 --> 01:17:38.000
So how on earth does that intention continue in force and continue exerting an influence all throughout those two years?

01:17:38.000 --> 01:17:45.000
That's what I meant in that sense by multiple realizability top down.

01:17:45.000 --> 01:17:52.000
Yeah, and then of course that goes back to the very classic Greek philosophical question of the ship of Theseus, right?

01:17:52.000 --> 01:17:58.000
Our audience goes, okay, the supposed ship that Theseus took to Crete, I guess it was,

01:17:58.000 --> 01:18:04.000
then it was preserved in Athenian harbor and then over the years, the boards rotted and they replaced one by one.

01:18:04.000 --> 01:18:07.000
Eventually every plank on the ship had been replaced.

01:18:07.000 --> 01:18:11.000
There was nothing original, but it was the same ship or was it, right?

01:18:11.000 --> 01:18:12.000
Correct.

01:18:12.000 --> 01:18:18.000
And we can say the same thing about organizations and cultures and societies and, you know.

01:18:18.000 --> 01:18:23.000
And humans, you know, basically every one of our atoms gets replaced, what, every year or something like that?

01:18:23.000 --> 01:18:26.000
Every seven years, every cells or whatever.

01:18:26.000 --> 01:18:27.000
Exactly.

01:18:27.000 --> 01:18:37.000
So I think I stick my neck out more than maybe I have a right to, but that's why I wanted to show in this new book that people say,

01:18:37.000 --> 01:18:39.000
you're reducing everything to physics and chemistry.

01:18:39.000 --> 01:18:52.000
No, I'm showing that there are, I never know the difference, homologous analogous constraint dynamics that operate all along the spiral.

01:18:52.000 --> 01:18:56.000
It's not a, it's not a reduction.

01:18:56.000 --> 01:19:07.000
It is to show that once you do the phase transition from physics to chemistry, then you've got new emergent properties, new codes, new everything.

01:19:07.000 --> 01:19:12.000
Once you go there from, from chemistry to biology and so on down the line.

01:19:12.000 --> 01:19:13.000
Got it.

01:19:13.000 --> 01:19:17.000
Well, let's wrap up with the future of these fields.

01:19:17.000 --> 01:19:29.000
And you talk a fair bit about the relatively new 4e approach to cognitive science, which I think is maybe getting closer to your way of thinking.

01:19:29.000 --> 01:19:30.000
Yes.

01:19:30.000 --> 01:19:37.000
I mean, I really like the work of the Paolo probably Andy Clark started the whole thing with the embodied mind idea.

01:19:37.000 --> 01:19:46.000
And people like Merlin Donald, who I love his book, all of these folks started realizing the mind just ain't in the brain.

01:19:47.000 --> 01:19:55.000
Because it takes me forever to write because I literally realize that I work out the ideas as I write.

01:19:55.000 --> 01:20:03.000
Now I type, but it's not that I sit down thinking all through and then I just write it out, you know, because it's all been worked out in my mind.

01:20:03.000 --> 01:20:15.000
Literally. So, so the notion that that that that our minds extend beyond the boundaries of our body to artifacts to tools.

01:20:15.000 --> 01:20:24.000
For example, when you're driving, I'm the designated teach your grandchild to parallel park person because their parents are petrified.

01:20:24.000 --> 01:20:26.000
Nobody else wants to do it.

01:20:26.000 --> 01:20:28.000
I'm a good parallel parker.

01:20:28.000 --> 01:20:39.000
You know, I say, look, after a while you realize that that you can almost feel the car as the extension, you know exactly where it's going to fit in a in a tight space.

01:20:39.000 --> 01:20:43.000
So the idea that the mind ain't just in the brain, it's embodied.

01:20:43.000 --> 01:20:58.000
But then it's also enacted because it's not just that it's embodied in my in the agent's body, but it's also the mind is enacted in their behavior within a particular context and so on.

01:20:59.000 --> 01:21:17.000
What I what I try to do in this new book is then the question is, well, how does this holistic ecosystem within which this embodiment and enlightenment, how does that coherent dynamic come about.

01:21:17.000 --> 01:21:23.000
And that's why I want to show that before you have a an enact.

01:21:23.000 --> 01:21:31.000
I don't think that if you're not Japanese, a tatami mat affords sleeping.

01:21:31.000 --> 01:21:39.000
I don't think a Victorian throne and that's seating to somebody who's never seen it before.

01:21:39.000 --> 01:21:44.000
So to somebody who's used to sleeping on the ground, and I don't think it does it automatically.

01:21:44.000 --> 01:21:48.000
It is part of a whole ecosystem, a whole coherent dynamic.

01:21:48.000 --> 01:21:52.000
And my question is, how do those coherent dynamics come about.

01:21:52.000 --> 01:22:00.000
And again, my answer seems to be I don't know what else to call constraints, all of these processes.

01:22:00.000 --> 01:22:04.000
And accumulation of constraints over time and their channel.

01:22:04.000 --> 01:22:08.000
But it's not just accumulation in that one at one damn thing after another.

01:22:08.000 --> 01:22:14.000
It's how they into how they interweave with one another.

01:22:14.000 --> 01:22:19.000
That's what creates this overarching interlocking set of constraints.

01:22:19.000 --> 01:22:23.000
Yeah, and then and that that and those constraints are real.

01:22:24.000 --> 01:22:29.000
See, I say from the beginning in the book, I'm never since can't ever.

01:22:29.000 --> 01:22:33.000
Every time something gets bored, we all we all hide behind epistemology.

01:22:33.000 --> 01:22:36.000
Oh, well, it's the way we make sense of things.

01:22:36.000 --> 01:22:39.000
No dammit, I think that's the way reality works.

01:22:39.000 --> 01:22:42.000
And you know, I don't need to I have to I have tenure.

01:22:42.000 --> 01:22:45.000
I don't need to worry about pleasing somebody else.

01:22:45.000 --> 01:22:48.000
I can say this if it's wrong, it's wrong, but that's okay.

01:22:48.000 --> 01:22:49.000
Oh, right.

01:22:49.000 --> 01:22:55.000
Well, I really want to thank Alicia Herrero and her new book, Context Changes Everything,

01:22:55.000 --> 01:22:57.000
as you can tell by our conversation.

01:22:57.000 --> 01:23:00.000
I learned some things, had some new ideas I've never been exposed to.

01:23:00.000 --> 01:23:02.000
I thought it was really interesting.

01:23:02.000 --> 01:23:04.000
And despite what she said, I thought it was damn well written.

01:23:04.000 --> 01:23:06.000
So thank you, Alicia.

01:23:06.000 --> 01:23:08.000
Thank you so much.

01:23:12.000 --> 01:23:15.000
Audio production and editing by Andrew Blevins Productions.

01:23:15.000 --> 01:23:20.000
Music by Tom Mueller at modernspacemusic.com

