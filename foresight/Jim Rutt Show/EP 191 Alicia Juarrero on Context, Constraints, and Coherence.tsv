start	end	text
0	4000	Howdy, this is Jim Rutt, and this is The Jim Rutt Show.
4000	11000	Music
11000	16000	Listeners have asked us to provide pointers to some of the resources we talk about on the show.
16000	22000	We now have links to books and articles referenced in recent podcasts that are available on our website.
22000	24000	We also offer full transcripts.
24000	29000	Go to JimRuttShow.com. That's JimRuttShow.com.
29000	32000	Music
32000	35000	Today's guest is Alicia Herrero.
35000	41000	She's a professor of philosophy emerita at Prince George's Community College in Maryland.
41000	43000	This is kind of old home week.
43000	48000	I actually grew up in PG County as we used to call it in the day.
48000	53000	They tell me you're not supposed to say PG anymore, but that's what we always call it.
54000	60000	I lived there from the time I was two to the time I was 22, and my wife is from PG also.
60000	66000	My brother is a distinguished alum of Prince George's Community College,
66000	71000	and probably half my friends went there, so it's great to connect with Alicia.
71000	73000	She is a complexity person.
73000	76000	She is the author of Dynamics in Action.
76000	80000	I have not read that book, but I ordered it and look forward to reading it.
80000	86000	It's very interesting, and she's co-editor of Reframing Complexity, Perspectives of North and South,
86000	91000	and Emergence, Self-Organization, and Complexity, Precursors, and Prototypes.
91000	96000	And she's written lots of publications and refereed philosophy journals.
96000	101000	She's also written a couple of things that I read while I was doing my research for this episode
101000	103000	that I think the audience might find interesting.
103000	107000	One's called Downward Causation, Poliani, and Progosian,
107000	110000	and another one called Western Science and Philosophy.
110000	114000	Can't deal with the relations between parts and holes.
114000	117000	You know, they're pretty serious, but they're not quite scholarly papers, right?
117000	122000	And so I think our audience could deal with them, and as always, links to those papers
122000	126000	and the books will be on our website at JimRucho.com.
126000	128000	So, welcome, Alicia!
128000	132000	Thank you for having me. It's a pleasure to meet you.
132000	136000	Yeah, it's a very good conversation. I really enjoyed reading the book.
136000	141000	It's quite short, 235 pages, but it is chock-full of stuff.
141000	145000	I mean, there's lots of ideas in this book, but we probably aren't going to get to them all.
145000	150000	My topic list is, I try to keep it to seven pages, but it looks like I got more like 11,
150000	152000	so we'll see how far we can get into it.
152000	155000	But I'd also like your writing styles very clear.
155000	157000	Oh, no, it is not.
157000	161000	You must have not read much of it because it is horrendously...
161000	165000	No, no, for philosophy book, it's damn readable.
165000	168000	No, no, no, it's awful. I wish I were here.
168000	171000	Well, no, no, I would disagree. I would disagree.
171000	175000	But today we're going to talk about her newest book just published called
175000	181000	Context Changes Everything, How Constraints Create Coherence.
181000	184000	So, the book was just published a couple of weeks ago, right?
184000	186000	A couple of weeks ago, yes.
186000	189000	Well, again, we'll have a link to the book on the episode page.
189000	191000	So, let's actually start with something.
191000	193000	We talk about a fair bit.
193000	196000	A number of our guests, for some reason, have found this framing useful.
196000	199000	And that is Aristotle's Four Causes.
199000	202000	This is a theme that runs throughout the book.
202000	207000	Why don't you remind the audience what the Four Causes are and what they are?
207000	211000	Well, I think Aristotle probably got it from the potter's wheel.
211000	218000	You know, he started thinking about causes and effects using the example of the potter's wheel.
218000	225000	Four Causes are material cause, the clay, the stuff from which the pot will be made.
225000	234000	Then final cause or purpose or teleology, which is the goal to which the thing that you're making will be put,
234000	236000	which is pouring water.
236000	239000	So, the final cause of the picture would be water.
239000	242000	The formal cause, it's not quite shape.
242000	246000	It's sort of the what makes a picture a picture.
246000	252000	So, it is the essence, the basic fundamental identity of the thing.
252000	264000	And then finally, efficient cause, which is the actual force exerted by the hands and the on the on the clay to turn it into the picture.
264000	265000	So, it's energetic.
265000	268000	Efficient cause is energetic exchange.
268000	274000	One of the things, the points you make is that prior to maybe the late 16th century,
274000	280000	people tended to consider all those causes when they were thinking about nature and the pre-scientific era.
280000	291000	But one of the moves that probably came off accidentally more or less from the invention of modern science was a very heavy focus on the efficient cause.
291000	292000	Correct, correct.
292000	297000	In a sense, material cause, people figured, well, science will take care of that.
297000	301000	And formal cause and final cause were sort of discarded.
301000	302000	They went out with a bustle.
302000	305000	You know, this is something we don't have to worry about anymore.
305000	310000	So, we can explain everything in terms of forceful causes.
311000	325000	It seems to me that when you're talking about complex dynamical systems, somehow final cause and formal cause kind of gets snuck in indirectly, not the way Aristotle thought.
325000	343000	People were born with an act or organisms or all natural phenomena had an inherent internal and teleki internal kind of like an acorn has the form of an oak built into it.
343000	348000	And all it has to do is unroll and unfold into the final form.
348000	362000	But I think what we have now with complex dynamical systems is that interactions with the environment and in my view constraints are the contemporary version of formal and final cause.
362000	370000	Yeah, and the over focus on efficient cause, matter and motion bumping into each other.
370000	378000	I often refer to that as naive Newtonianism and you know, most nerdy smart kids go through that period, right?
378000	390000	And they make the error of thinking the famous Laplacian area where he says, yeah, give me the position and velocity of everything in the universe and I can predict the future in the past with total precision.
390000	396000	But fortunately, once you get exposed to ideas of complexity, you realize it's completely crazy.
396000	405000	And that has actually caused for those people who've gotten the complexity lens to realize there's much more to our universe than naive Newtonism.
405000	409000	But, but it's amazing how it's persisted and you can't blame people.
409000	416000	I mean, it seems to do a hell of a job predicting eclipses, but even Newton knew the three body problem would mess things up.
416000	417000	Right.
417000	425000	But that was a warning Newton gave us that went on heated for many centuries.
425000	432000	My first paper was about Kant and Prigogene and exactly about that subject matter.
432000	433000	Yeah.
433000	439000	And then as you talk about in your book, one of the current manifestations of it, though, I will say it depends where you are in the sciences.
439000	443000	Now, I've had the good fortune to be around complexity people for the last 20 years.
443000	446000	And so there's much, much, much less of that there.
446000	453000	But I suppose out in the wilds of solid state physics and places like that, there's still a lot about what you call nothing but ism.
453000	454000	Right.
454000	457000	Explain what nothing but ism is.
457000	469000	Well, the idea that the whole is nothing but the sum of its parts and therefore anything that appears to be an emergent property is really an epiphenomenon.
469000	475000	It is, it is, it is sort of froth that's thrown up, but it really has no causal power.
475000	487000	Well, of course, not because if causal power is only thought of as efficient causality, then clearly the synchronization of the photon streams in a laser beam.
487000	493000	Don't align their component laser beams as another efficient cause.
493000	494000	So that's the problem.
494000	498000	Yeah, that's it leads very quickly to absurd conclusions.
498000	501000	What makes me wonder why did it hang in there so long?
501000	503000	Well, and you know where it hung in.
503000	511000	I came at this because I wrote a dissertation on the difference between explaining and justifying behavior.
511000	514000	Well, justification has to do with moral reasons so on.
514000	522000	But explaining behavior, the first sense of that first book that you quoted is what is the difference between a wink and a blink?
522000	526000	Presumably, it's the cause, right?
526000	535000	Meaning that an intention causes a wink, but a, my throwing some sand in your face would cause you to blink.
535000	544000	Well, but then the next question is what the hell's an intention and how can an intention cause the action in an efficient cause way?
544000	545000	Correct?
545000	550000	And my answer was obviously, well, there can't be just one neuron pushing another neuron pushing.
550000	551000	I mean, forget it.
551000	552000	That doesn't work that way.
552000	561000	And at the time I was living in Berkeley and I was hanging around people who were into network theory and systems analysis and so on.
561000	562000	I'm going, you know what?
562000	564000	There's got to be a network property.
564000	566000	We're talking the 70s gym.
566000	581000	There's got to be a network property that somehow produces emergent properties, which in turn can loop back down and cause the neurons that are responsible for motor control to move the arm in a way that it satisfies the intention that I started out with.
581000	582000	All right.
582000	583000	So how is this going to work?
583000	585000	You were talking about PG community college.
585000	589000	The nice thing about teaching a community college is nobody gives it them to publish anything or not.
589000	592000	You're going to be judged by how well you teach.
592000	594000	So nobody cares about whether you publish.
594000	601000	On the other hand, nobody's forcing you to write papers on the fifth decimal point of the existing theory.
601000	610000	So I could play around and in this area in DC, I could hang around NIH and start listening to people come talk.
610000	615000	And so you start understanding how patterns in neural systems work and so on.
615000	616000	So it's got to be something.
616000	618000	It's got to be something like that.
618000	621000	So that's when I decided, all right, you know what?
621000	624000	I'm going to give the term cause to the Newtonians.
624000	625000	I'm not going to fight that battle.
625000	627000	It's going to take me forever to fight that battle.
627000	639000	So instead, what I want to do is look at the notion of constraint because as soon as the hard scientists get into trouble with that Newtonian silly understanding of efficient causes.
639000	644000	You mentioned they retreat and hide behind the notion of constraint.
644000	646000	And I thought, you know what?
646000	647000	That's going to work.
647000	660000	So that's that's how the whole that's how my, my, my trajectory towards reconceptualizing causality and specially formal and final cause in terms of constraints developed.
660000	661000	It's interesting.
661000	665000	And actually it worked well with the little analogy I use.
665000	676000	When I'm trying to explain complexity to just random people at a party or something, I will say you can think of reductionism, you know, classic science as the study of the dancer.
676000	679000	While complexity is the study of the dance, right?
679000	682000	And a dance is not random motion.
682000	684000	It has constraints, right?
684000	686000	If it's going to be, it's going to be a jitterbug.
686000	688000	It has one form of constraints.
688000	690000	If it's going to be a waltz, it has another.
690000	695000	And so when I read that and saw the movie you were making, I say, works perfectly with my good old.
695000	696000	Absolutely.
696000	698000	My good old analogy.
698000	699000	Absolutely.
699000	702000	And it held held together quite well.
702000	708000	So now let's move on to your next topic, which is a term that most non philosophers will have never heard of.
708000	711000	I've heard of it a few times, but it's not term we use very often.
711000	712000	Santa Fe Institute.
712000	713000	Myriology.
713000	715000	Is that how you pronounce that?
715000	716000	Myriology.
716000	719000	And that's, again, the whole parts, parts whole.
719000	724000	Because let's use an example from Brian Arthur's note that I love.
724000	730000	That's a Santa Fe book on complexity of economics, economics and complexity.
730000	745000	What, what a, an economy is, are a bunch of individual elements that interact in a constrained way to result in an
745000	753000	emergent phenomenon that has certain properties that the components don't have.
753000	759000	An economy has certain characteristics that the individual trader and seller don't.
759000	770000	But once that whole WHLE, which is a coherent whole, and I really want to emphasize the fact that a coherent whole is different from a
771000	775000	mass clump of stuff because it's organized.
775000	779000	And what organizes it are the constraints.
779000	792000	But once it's organized, then all of a sudden the components also acquire different properties because suddenly they are now traders and regulators and so on and so forth.
792000	793000	Correct.
793000	796000	So there you have the whole part.
796000	803000	The parts of the components, correct, and, and the interact the constrained interactions among the components.
803000	809000	The whole is what I'm calling in this new book a constraint regime.
809000	822000	Because one of the problems we've also had, I don't know if it's Newtonianism or what, but we tend to reify things, things, no pun intended, we tend to reify things.
822000	839000	But an economy is nothing other than all these constraints all held together by an overarching set of constraint regimes once the constraints close into it into a coherent whole.
839000	848000	But they can then loop back down and affect their components and they acquire, they acquire, now they have a role, right?
848000	859000	In a society, once a society is a socially organized structure, people can be citizens, they can be senators, they can be teachers.
859000	864000	Those roles don't exist except within an organized society.
864000	874000	So then the next question is, well, on a more general level, what is the relationship between the parts and the holes and the holes and the parts?
874000	882000	If you really buy the whole Newtonian idea, ain't no difference between the parts and the holes, the holes are nothing but the sum of the parts.
882000	894000	But that means you cannot explain how it is that my behavior is constrained top down by my living in a particular culture.
894000	905000	The fact that I was born and raised in Cuba, the fact that all of these affect my behavior, but they don't do that as an efficient cause.
905000	917000	A culture, an economic system doesn't cause my behavior to differ in any kind of efficient cause.
918000	925000	But since the Newtonian Revolution, pretty much myriology got thrown out of the picture.
925000	931000	So that messes up philosophy of mind because you cannot explain mental events.
931000	940000	If you think of mental events as emergent properties because they should be reducible to a bunch of neurons pushing each other around.
940000	944000	But where does the emergent property go when you have that?
944000	950000	I'll tell you a little example. I've got my little homey examples that I love to use on this as people who doubt.
950000	953000	We'll get this later, the idea of top down causality.
953000	959000	I say, let's imagine me dead and run through a blender and poured into a bathtub, right?
959000	965000	What's the chances that those chemicals are going to hop out of the bathtub, walk down the hill and go to the ice cream store?
965000	967000	Essentially zero, right?
967000	974000	And on the other hand, if it's me and I'm operating up in cognitive space and it's after dinner and we just had a nice dinner
974000	981000	and I feel like a walk with my wife to go down and get something nice, then we may decide to haul all these atoms and molecules
981000	987000	and they have nothing to say about it because this top down idea, well, let's go get some ice cream, causes the,
987000	993000	and by the way, Newtonian physics is never, or let's say physics is never violated, right?
993000	997000	The atoms are dragged along and they are dragged along through efficient causes.
997000	1005000	You know, they're all stuck together and bound by various forces, but the decision to go get the ice cream came at a higher level in the stack.
1005000	1011000	And, you know, and again, some of the attempts to deny that that happens is just bizarre, right?
1011000	1014000	Well, it is to me and you, but it isn't to an awful lot of people.
1014000	1020000	And even folks, and I may, I hope there hasn't been a change in the last couple of years,
1020000	1037000	but even somebody like Brian Rockland, who recognizes the reality of the emergent properties nonetheless gets very weary about ascribing causal properties,
1037000	1043000	causal powers, let's use that for causal powers to those emergent properties.
1043000	1047000	In a sense, the notion of supervenience is continuous.
1047000	1057000	So they're very few of us, people like Carl Gillette, people like Robert Bishop, they're very few of us who are willing to go the next step and say,
1057000	1070000	not only are emergent properties real, they have causal powers with respect to their own components and that's what homeostasis is for God's sake.
1071000	1079000	Homeostasis readjusts the metabolism, the neural system and so on in order to maintain the integrity of the whole.
1079000	1091000	But the idea that nonetheless that should be explicable in a reductionist fashion, the power aspect of it is still not quite,
1091000	1093000	the physicists haven't bought it.
1093000	1097000	Philosophers, I hate to say this, I have, I never read philosophy anymore.
1097000	1105000	I, because all the, I grew up, I was trained as an analytic philosophy for in the United States, all they're worried about is the meaning of words.
1105000	1107000	I mean, they're very few people.
1107000	1120000	And you can tell why, how this is when you have people like Chalmers and Christoph Koch, who Chalmers has sort of thrown in the towel and he's really saying,
1120000	1128000	the only way you're going to have mental properties is if you build them in from the get go from the, from the bot, you know, so therefore electrons have mental quality.
1128000	1131000	Oh, come on, give me a break.
1131000	1132000	Yeah.
1132000	1138000	We had Christoph Koch on the show sometime back and he actually is a panpsychic.
1139000	1141000	But you, but do you understand why?
1141000	1155000	Because if all of reality comes from innate internal fundamental properties that only interact with efficient causes, there's no way you can get a coherent whole.
1155000	1164000	And that's the key word coherently organized that then and from which emergent causal powers come.
1164000	1171000	And it's interesting that they, another extremely bright guy named Ben Gertzel has been on my show many times, good friend of mine.
1171000	1177000	I think he's a panpsychic for exactly that reason, because otherwise he's wedded to his model of the universe.
1177000	1179000	And where does consciousness come from?
1179000	1185000	If it doesn't, if it isn't innate, while a complexitarian would say, well, it's obviously emerged just another level on the stack, right?
1185000	1186000	And that's not that hard.
1186000	1187000	Correct.
1188000	1208000	But it's this notion that my nature, you know, oh, it's in my nature is somehow given as an essence in the fundamental tiny, tiny bits that make up the rest of it.
1208000	1213000	That's still much more widespread than one would think.
1213000	1214000	Yeah.
1214000	1216000	We'll get to supervenience later.
1216000	1220000	And I think we have a somewhat different point of view, but not entirely different.
1220000	1221000	We'll get to that later.
1221000	1232000	But I think we're on the same page that, hey, this need to smuggle in something like consciousness or cognition as a fundamental property of matter seems to be a big overreach.
1232000	1236000	I mean, do we try to smuggle in the fundamental nature of digestion?
1236000	1237000	I don't think so, right?
1237000	1241000	But we get overly confused when it comes to cognitive processes.
1241000	1242000	But digestion is a good example.
1242000	1244000	And that's the one John Searle has always used.
1244000	1245000	That's why I always use it.
1245000	1246000	Yeah, exactly.
1246000	1247000	And I used to fight him.
1247000	1251000	We were on the NEH board together.
1251000	1258000	But the thing about digestion is digestion really doesn't do much.
1258000	1260000	I mean, it is an effect.
1260000	1263000	Digestion is an effect of all these other processes.
1264000	1271000	The reason I like homeostasis is because the metastability of homeostasis is causally effective.
1271000	1281000	It does, if I have the fudge brownie, it's going to switch all my glucose and all everything else around to keep the integrity of the whole.
1281000	1292000	So it has caused what I would want to call causal powers, but I've given up that term because people will say, oh, but it is an efficient causation.
1292000	1293000	No, that's right.
1293000	1294000	It isn't.
1294000	1300000	But it is DS Lewis's notion of cause meaning without which not.
1300000	1302000	If that weren't the case, it wouldn't be.
1302000	1306000	So that's the causal notion I would espouse.
1306000	1316000	Okay, let's now make the next step, which is why don't you start to define what you mean by constraints and lay out a taxonomy of different kinds of constraints.
1316000	1319000	This is where the book really started to get into new territory for me.
1319000	1321000	I've had it very interesting.
1321000	1324000	And that's what the new one is all about.
1324000	1328000	That's what the new one is all about.
1328000	1339000	I think in the first book, I made a distinction barring from Lila Gatlin's book called information in the living system, which was from 1960, something or other.
1339000	1347000	A distinction between I use the term at the time, context free and context sensitive or context dependent.
1347000	1352000	There's a lot of grief from people saying ain't nothing that's context independent.
1352000	1353000	All right.
1353000	1355000	So in this one, I call it context.
1355000	1357000	I mean, nothing's context free.
1357000	1373000	So in this book, I call it context independent and context dependent context independent according to Lila Gatlin are conditions that take a system far from equi probability.
1373000	1379000	Now, whatever takes conditions away from random from white noise from random noise.
1379000	1388000	So if you institute a gradient, you have you have instituted a context independent constraint.
1388000	1402000	If you institute if you institute polarity or charge, we were talking the early universe here probably that were those were probably the earliest constraints.
1403000	1418000	And I call them context independent because in a sense what they do is they set the context in a sense they set the boundaries of possibility space and inhomogeneities within that possibility space.
1418000	1422000	So it's no longer white noise.
1422000	1431000	Lila Gatlin calls context dependent constraints, those that take a system away from independence.
1431000	1438000	So one of the things that's that I find interesting also is that we might put Newtonian is now.
1438000	1446000	But when you look at the second law of thermodynamics and I'm petrified because I kind of talk about the second law of thermodynamics in this new book.
1446000	1457000	But according to the Boltzmannian everybody's interpretation of the second law of thermodynamics, the the events in the particles are independent of one another.
1457000	1462000	And I think you're never going to get complexity if you have independent particles.
1462000	1477000	That's the beauty of Stuart Kaussman's button example button mesh example, you know, you tie one button to another tower, and all of a sudden, the thing turns into a mesh, right you have a phase transition, and you have a mesh.
1477000	1486000	So what would I consider context dependent constraints that take a system far from independence.
1486000	1490000	I would consider catalysts.
1490000	1496000	Context dependent constraints. I would consider feedback loops.
1496000	1515000	Context dependent constraints. And I think since that first book was published 20 some years ago, what's nice to me is the burgeoning of epigenetics nowadays, because if epigenetics isn't an example of context dependent constraints with a vengeance.
1515000	1531000	I don't know what is so once you have all these context dependent constraints, acting inside a context independent possibility space set possibility space.
1531000	1543000	Then I think the possibility of complexity appears you don't have a possibility of complexity just with emergent, just with efficient causes.
1543000	1558000	These forms of constraints do. I also make a distinction between temporal and spatial constraints. I give two examples from from playground devices.
1558000	1577000	In the playground swing. The child learns very quickly that when they kick is as important as how strong they kick. And the timing of the kick does not impart more energy to the kick.
1577000	1587000	So that's an example of where Newton alone efficient causes alone won't work. Does that make sense. I mean you have to otherwise it won't kick.
1587000	1602000	So that's another example is another example of a spatial context dependent constraint, because depending on the length of that plank on the top and the plinth on the bottom the base on the bottom.
1602000	1613000	Then when where the child sits will be determined by those context dependent constraints in order for them to be able to do your daughter.
1613000	1619000	Another example that I like a lot which I know you know Dave Snowden and he likes to use a lot.
1619000	1642000	I think I used it first but that's okay is is the roundabout the the traffic circles. Right. The architecture of the roundabout is a context dependent constraint that affects the behavior of pedestrians and drivers in a system.
1642000	1658000	So that's another example of a context. I think sequencing is a beautiful example of temporal constraints. A has to be done before B which has to be done before C which has to be done before E and it's done in a different order.
1658000	1662000	The order of the make a huge difference in the outcome.
1662000	1686000	So all of these I consider context sensitive constraints. I lump a lot of those into enabling constraints because I think of enabling constraints as particularly those context dependent constraints that together achieve closure such that this coherent whole emerges.
1686000	1700000	Interesting. And you also I think that was interesting about your your use of the word constraint is you use it very broadly. Yes, you include it. I mean for instance one of my mentors in the complexity space was Harold Morowitz.
1700000	1710000	Oh, sure. He was here nearby at George Mason for a long time. Yeah, I used to live out in Loudoun County and see him quite once a week.
1710000	1728000	He has this idea that you know the 27 emergencies or whatever it is and then each one is defined by a set of pruning rules which you know tilt things one way or the other and that those faith those changes are fundamental inflection points in the evolution of the universe and some of them may have been
1728000	1742000	some of them probably are contingent and some of them aren't and the ones that aren't maybe maybe correspond to your non contextual constraints. For instance, one of his steps is defined by the poly exclusion principle for instance.
1742000	1760000	Absolutely. I mentioned that in the second book. I think notions of symmetry and conservation prints. You know, it's funny. Physicists all use word causality and so on and use half of the time they're talking about Newtonian cause then when they figure it can't fit and all of a sudden they move to principles.
1760000	1771000	Right. To to consider that sort of thing and I absolutely agree. I think rules regulations are examples of constraints.
1772000	1780000	They set the possibility space and they determine what is more likely within it than otherwise.
1780000	1789000	And I did like the point and this is Harold makes the same point that especially higher up in the stack. We're talking more probabilities than we are blacks and whites.
1789000	1806000	Absolutely. And perhaps what I speculate on in this new book is that whenever you have the emergence of a coherent dynamic, you have a phase transition to a continuous function.
1807000	1825000	If you have that if I'm right on that, then it seems to me that top down control is analog. It's a it's a change in the setting of the system to an analog notion so you're going from your old fashioned toggle switch to a dimmer switch.
1825000	1840000	And that's why homeostasis can keep the timeliness because that's very important for homeostasis in most ecosystems and it also can keep the sensitivity to local conditions.
1840000	1853000	I think only analog them do that. I the Dyson's have been were poo pooed a lot, but there's something that tells me that their emphasis on analog control somehow might be might be on to something.
1853000	1857000	I had to make it clear for the audience talk about Freeman and George.
1857000	1859000	All deceased now. Yeah.
1859000	1863000	Did George die recently about the last six months or a year.
1863000	1865000	I used to come by the Santa Fe Institute.
1865000	1882000	Freeman, I don't believe ever did at least I never met him there, but very interesting family also knew very interesting family also knew Esther Dyson who was George's brother who was a very, very extremely influential thinker in the early days of the computer industry and then later has become a
1882000	1886000	brilliant venture capitalist, particularly in the Eastern Eastern Europe.
1886000	1887000	That was her area.
1887000	1888000	I didn't know.
1888000	1890000	Yeah, quite amazing woman really.
1890000	1892000	Yeah, she really was really quite.
1892000	1899000	Okay, let's I haven't way later in my topic list, but let's talk about it now, which is analog versus digital.
1899000	1901000	I actually have a fair bit of background in this.
1901000	1903000	I had two of my companies back in my business career.
1903000	1904000	They weren't mine.
1904000	1906000	I was on the I was a chairman of one.
1906000	1911000	I was a investor and director or another were both involved in software for designing computer chips.
1911000	1914000	And in particular for designing analog computer chips.
1914000	1918000	And so I learned quite a bit about analog versus digital.
1918000	1924000	And for instance, I learned I probably should have known it that digital actually is analog below some level, right?
1924000	1930000	And then there's there's a whole series of clever things they do to go from analog to digital.
1930000	1941000	But then the other point, what you allude to is that on comparable computational tasks, analogs, literally six orders of magnitude more efficient.
1941000	1942000	That's it.
1942000	1946000	And that's not to be the reason why the brain doesn't overload.
1946000	1947000	Correct.
1947000	1949000	That has to be the reason why the brain.
1949000	1951000	So the brain is a good example of that.
1951000	1958000	Why the why the mind, why the mind when you transit, when you do the face transition to a mental event.
1958000	1971000	What you're doing is you're transitioning from neuronal electrical exchanges to control on the basis of some kind of typology, a facial recognition.
1971000	1977000	So now you're talking on the basis of how close is that pattern to this exemplar face.
1977000	1982000	Though, again, to keep in mind, the brain is a good example because the brain is both digital and analog.
1982000	1983000	Exactly.
1983000	1984000	Exactly.
1984000	1985000	Exactly.
1985000	1986000	Correct.
1986000	1987000	And it switches back and forth.
1987000	1988000	Yeah.
1988000	2002000	And so, you know, the domain of ideas or concepts or objects, you know, the, you know, the very important object ontology that at least mammals and above develop probably Burge to is continuously variable.
2002000	2003000	And it's not perfect.
2003000	2006000	It's classic analog classification.
2006000	2009000	And yet it's actually implemented on digital circuitry.
2009000	2010000	Correct.
2010000	2011000	Correct.
2011000	2015000	It's not digital, but the command top down is cut is analog.
2015000	2017000	That makes perfect sense to me.
2017000	2018000	Yeah.
2018000	2032000	Though I would also just add that the continuously variable while true of analog versus digital is maybe less important than people think is one of the principles of computation is you can simulate analog at any level of detail you want.
2032000	2041000	On the other hand, to simulate analog at extremely fine detail is very expensive computationally while you get it for free with analog.
2041000	2043000	So that's the, that's the cool thing about analog.
2043000	2054000	So that George Dyson used to use as an example, you know, even though the internet and all the computers that we use now are digital.
2054000	2060000	When you look at social media and that stuff, it's what's connected to what.
2060000	2062000	So we're back to the dance, right?
2062000	2063000	Yeah.
2063000	2065000	And that's the people who are analog, right?
2065000	2077000	And it's the dance of the people and the people in a sense are the condensated nodes of the intersections of all these constraints.
2077000	2078000	Right.
2078000	2088000	So that's what I argue in this new book that everybody's all bent out of shape about identity because they all think of identity of something internal essential.
2088000	2098000	The same thing as coach and and and Chalmers were concerned in, but we need to transition to identity as a set of interdependent constraints.
2098000	2100000	That's what makes me me.
2100000	2101000	Right.
2101000	2106000	I am a set of interdependent constraints and high dimensional.
2106000	2108000	Very high dimension.
2108000	2117000	The other thing that's so annoying about the stupid identity politics of both the left and the right is both sides want to condense down to just one or two dimensions.
2117000	2120000	And there's hundreds of dimensions, right?
2120000	2127000	You know, I'm a cat, you know, someone's a dog fancier who loves mountain laurel, but not Rotodendrons.
2127000	2129000	There's so many dimensions.
2129000	2134000	And I say that these two are the ultimate ones, just like just kind of dumb, right?
2134000	2143000	You know what did it for me that I finally decided I can finish that first book where was worked by Hinton, Jerry Hinton, who's now a big shot.
2143000	2150000	Clout and Chalmers and they were doing early work in artificial networks that read words.
2150000	2154000	It was one of the early text reading networks.
2154000	2159000	And they were working on simulating.
2159000	2161000	I had never heard it at the time.
2161000	2166000	Have you ever heard the difference between surface and deep dyslexia?
2166000	2168000	No, I was very interesting.
2168000	2170000	I thought that was in your book.
2170000	2172000	You gave a great example in your book.
2172000	2173000	Oh, God.
2173000	2174000	And I use it in a sense.
2174000	2176000	No, well, it was their example.
2176000	2177000	Okay.
2177000	2178000	It was their example.
2178000	2181000	They, you know, do you want me to repeat it here?
2181000	2182000	Sure.
2182000	2183000	I want you to tell the story.
2183000	2184000	It's very interesting.
2184000	2185000	I'll tell the story.
2185000	2188000	Surface dyslexia is what most dyslexic human beings have.
2188000	2190000	They transpose letters.
2190000	2195000	So they read caught for cat or they read tag for cat.
2195000	2200000	They just transpose letters or four gets read as a seven, that kind of thing.
2200000	2204000	There was the point being, there's no semantics involved.
2204000	2208000	It's purely the appearance of the input.
2208000	2210000	Okay.
2210000	2213000	Apparently deep dyslexia is very different.
2213000	2216000	Now what I'll give you the example first.
2216000	2220000	What Hinton Plout and Chalice, and the reason I plunked them all together is because Hinton
2220000	2223000	and Plout would write Hinton and Chalice Plout and Chalice.
2223000	2227000	So there's zillions of papers that came out about 25 years ago about this.
2227000	2234000	And they trained these early reading neural networks.
2234000	2239000	And when they had, when they train them with feedback loops, so they were current, recurrent
2239000	2250000	networks, and they lesioned the networks above the feedback loops.
2250000	2254000	The network would be shown cat and it would say tack.
2254000	2256000	So it would do surface dyslexia.
2256000	2260000	It would produce surface dyslexia kind of errors.
2260000	2268000	But then if they lesioned the artificial neural network below the feedback loops, they might
2268000	2271000	show the network again.
2271000	2274000	These are, these are silicone networks.
2274000	2276000	They're not organic.
2276000	2281000	They would show them B, A, N, D band.
2281000	2289000	And the thing output would say it had read orchestra or they would show it B, E, D.
2289000	2292000	And the thing would say it had read cut.
2292000	2295000	That is.
2295000	2301000	And so somebody, not me, asked one of them, Hinton, Blauser, Chalice, how do you explain this?
2301000	2307000	And their answer was the only way I can explain this is to postulate that the system, because of the
2307000	2310000	middle layers that we don't quite know what's going on.
2310000	2313000	And that has got to be what's going on with Chalice BD, by the way.
2313000	2317000	The middle layer has created semantic attractors, period.
2317000	2318000	Case closed.
2318000	2322000	And the output is just showing from the semantic attractor.
2322000	2324000	That makes perfect sense.
2324000	2327000	But there's your emergent property being causally powerful.
2327000	2328000	Interesting.
2328000	2334000	By the way, for all my computer people who listen, and there's a lot, the GE Hinton she's talking about is the
2334000	2335000	Jeffrey Hinton.
2335000	2337000	He's the Jerry Hinton.
2337000	2340000	I want, I shouldn't say this on, on the air, but I will.
2340000	2346000	I said to John Sterle at one of these NEH meetings, John, I think Hinton's work is so very good.
2346000	2348000	I don't understand why everybody's so interested in Hinton.
2348000	2350000	I thought, he's very good.
2350000	2352000	Trust me, he's very good.
2352000	2355000	It is, it is the Jerry Hinton.
2355000	2356000	Right.
2356000	2361000	He's the guy that broke through the breakthroughs that drove all the stuff that we're doing today.
2361000	2362000	Absolutely.
2362000	2368000	And everybody was paying attention to these reading networks a long time ago, or at least not as many people should have been.
2368000	2371000	Yeah, I was actually doing neural nets back in 2001, 2002.
2371000	2374000	In fact, that's how I got invited out to the Santa Fe Institute.
2374000	2376000	It was my work on evolutionary neural nets.
2376000	2381000	Well, my book was published by MIT 1999, and this has been published before.
2381000	2385000	So I think that stuff was published in 1995, 1998, thereabouts.
2385000	2386000	Yep, that was.
2386000	2387000	They did it for me.
2387000	2401000	I thought, now I can write this book because I have some kind of evidence that the semantic attractor in the brain, in a culture, whatever you want to call it, has causal effects.
2401000	2404000	Now, when I was reading the book, I write a lot of notes I always do.
2404000	2409000	One I wanted to ask you about, because how does it fit into your concept of constraints?
2409000	2411000	It certainly is one of Harold's pruning rules.
2411000	2416000	And that's the idea of the species competitive exclusion principle.
2416000	2420000	And which actually, my core field is evolutionary computing.
2420000	2426000	And so I understand a lot of how speciation works from a mathematical perspective.
2426000	2431000	And it's more or less a thing that is just true, right?
2431000	2441000	If a competitive dynamic has these attributes, there will be, and a fitness landscape has a certain shape, there will be competitive exclusion principle around species.
2441000	2445000	Does that fit into your idea of constraint?
2445000	2458000	Well, if what I speculate about there existing a constraint regime, correct, then that is the constraint regime for that possibility space, right?
2458000	2466000	Yeah, it basically says that if anything is competitive, if you get too far away from the center of what's efficient in that part of the fitness landscape,
2466000	2474000	inevitably you'll be less, not inevitably, most of the time you will be, you know, less fit than the ones right at the near the peak.
2474000	2476000	And therefore your numbers will go down.
2476000	2481000	So it's very hard to move away from the peak of the species definition.
2481000	2485000	The phenotypical collection, of course, as you point out, they're not all the same.
2485000	2490000	They're an ensemble, but they nonetheless cluster around a species type.
2490000	2491000	Correct.
2491000	2492000	Correct.
2492000	2496000	I don't know if this is an attempt to answer your question or attempt to evade it.
2496000	2498000	I'm not sure.
2498000	2503000	Tim Allen, T.H. Allen and Starr who have that book, they've got two editions of it.
2503000	2507000	I like the first one, the first edition better called Hierarchy Theory.
2508000	2522000	And they use as an example prairie grassland ecosystems in the Midwest, where apparently the prairie grassland competes against flowering plants.
2522000	2527000	It also competes of obviously against forbs, horses that eat the grasses.
2527000	2528000	Correct.
2528000	2536000	Apparently, if you look at the, if you look at that whole ecosystem, and you look at it from the point of view of the grass.
2536000	2538000	Right.
2538000	2545000	Competition with the flowers is a lot harder than competition with the horses.
2545000	2549000	Apparently, flowers will really do a number of flowering plants.
2549000	2550000	I don't know.
2550000	2552000	Dicotillodons or whatever the other things are called.
2552000	2553000	All right.
2553000	2560000	So over history, over a period of time, the prairie grasses send out have sent out.
2560000	2562000	And of course, this is all selection.
2562000	2564000	I'm not at all disputing, obviously.
2564000	2565000	They are winning.
2565000	2574000	They have sent out Mary stems, Mary stems or these shoots right below the surface, but that stick out enough that the horses can eat them.
2574000	2588000	And so in a sense, Jim, they, the grass invites the horse to come in to feed and incorporates it into what is now an enlarged ecosystem.
2588000	2601000	So instead of having two competing species, what you having is the enlargement of the niche or the constraint regime.
2601000	2612000	And Tim Allen says it's kind of like a Shanghai where was a predator and to incorporate it into a an enlarged constraint regime.
2612000	2617000	Now the, now the horse is part of the grasslands ecosystem.
2617000	2621000	And that's how they keep the flowers at bay.
2621000	2632000	I think that way of looking at it as a dynamical, mutual adjustment system is an awful lot better than two species competing.
2632000	2635000	Yeah, two species are competing, but this other stuff.
2635000	2653000	And then I get from the fact that I didn't realize until fairly recently that the understanding of the term fit during Darwin's era meant more like you go to a tailor to get a fitting for a new suit of clothes.
2653000	2658000	So when you think of fit in that sense, it's what is it?
2658000	2661000	It's a mutual adjustment, correct?
2661000	2673000	Which means that when I talk about constraint, the form of bottom up and top down relationships has to be one of mutual constraint adjustment.
2673000	2682000	That's what it basically is. You're adjusting all the constraints to see how you can best satisfy the overarching dynamic.
2682000	2688000	Yeah, then to your example of the grasses and the horses, etc. It's always in a co-evolutionary context.
2688000	2692000	Exactly. And that's your idea of context, right?
2692000	2697000	It's temporal too. It's temporal too. You've got to include temporality. Absolutely.
2697000	2701000	All right, so let's move on here. That was good, actually.
2701000	2709000	In the interest of time, I'm going to skip over the COVID example and let's talk more about time temporal constraints.
2709000	2716000	I think you did a really nice job of talking about cardinality, ordinality, and indexiality.
2716000	2717000	Inexicality.
2717000	2725000	Inexicality, okay. I want you to distinguish those, particularly the distinguished cardinality from ordinality.
2725000	2729000	Well, cardinality is just a mount, correct?
2729000	2731000	So a pile of sand has a cardinality.
2731000	2735000	A pile of sand is bigger or smaller, correct.
2735000	2739000	Ordinality is first, second, third.
2739000	2747000	I don't see where you can get first, second, thirds much out of Newtonian mechanics.
2747000	2759000	Whereas once you have temporal constraints instituted, this has to occur and this sets the stage for then the next thing to occur.
2759000	2771000	Once that sets the stage for the third thing to occur, then you have ordinality, which is first, second, third, orders, right?
2771000	2775000	Indexicality takes it a bit further.
2775000	2786000	It's like perspective or the position you are in in a complex dynamical structure means there are certain properties that are indexical.
2786000	2789000	This is to the left of this. This is to the right of this.
2789000	2792000	That's what I mean by indexicality.
2792000	2803000	It really has wreaked havoc in philosophy of mind because intentional causation again is eminently indexical.
2803000	2810000	So one example I use in this new book is that philosophers use all the time.
2810000	2820000	Mary told John's wife that he was cheating on her, but Mary doesn't know that John's wife's name is Alice.
2820000	2829000	So did Mary tell John's wife that it was Alice?
2829000	2836000	You see what I mean? It has to be interpreted, I think, in terms of the emergent dynamics and emergent properties.
2836000	2842000	So it has to be treated in terms of indexicals, inside and out.
2842000	2853000	So I think once you have emergent constraints in place, that's what, and I wish there were a verb that makes...
2853000	2856000	How could you make a verb out of the word rugged?
2856000	2858000	Ruggedify.
2858000	2862000	It ruggedifies the possibility space, right?
2862000	2870000	And each one of those valleys and attractor basins or attractor separate tricks is right.
2870000	2875000	They are the ruggedness of a possibility space.
2875000	2887000	And that explains why the view from inside an attractor looks real different from the view from the hill overlooking the next basin of attractor, correct?
2887000	2894000	And when we talk about causality, we have to take that kind of indexicality into account.
2894000	2899000	Yeah, then with respect to ordinality, many things are inherently ordered.
2899000	2907000	In fact, I just published last night a very interesting podcast, Currents Number 100, with Sarah Walker and Lee Cronin.
2907000	2913000	Ooh, I've got a note to her. Sarah and Mary Walker. Her stuff's really interesting.
2913000	2916000	Yeah, and on time, it's an object.
2916000	2927000	And their hypothesis is that evolution and other expanding complexity is essentially a series of steps that get taken, right?
2927000	2938000	They point out that the most complex chemicals created by abiotic processes never have more than 13 or 14 steps.
2938000	2946000	But abiotic processes can go much higher than that, and then man-made processes can go a bit further than that.
2946000	2950000	And so I thought it was a very interesting juxtaposition with your idea of ordinality.
2950000	2957000	One of the examples you gave was the social evolution of the processing of cassava.
2957000	2959000	I believe it was in South America.
2959000	2964000	That's from Heinrich's book on the secrets to our success or something.
2964000	2969000	Heinrich is what, head of sociology or something at Harvard.
2969000	2976000	It's apparently something that's poisonous, but yet nutritious if it weren't poisonous.
2976000	2988000	The indigenous community in South America has figured out a way of leaching out that poison, but the preparation for that root vegetable has to be done in a particular sequence,
2988000	2992000	because if you don't, you're going to kill out the entire population.
2992000	2999000	Going back to Sarah Walker, somebody told me day before yesterday that apparently there's something I'm not on Twitter,
2999000	3002000	which I probably should be neither on Twitter nor on Facebook.
3002000	3012000	Somebody told me that somebody wrote a Twitter comment saying that Sarah Walker's driving forces are my constraints,
3012000	3016000	which is flattering, I think, for me.
3017000	3018000	She's very good.
3018000	3019000	She's very good.
3019000	3025000	And Lee too, the two of them were one of the better science, hard science episodes I've had in a while.
3025000	3028000	Lee probably is very good. Yeah, I like his stuff.
3028000	3029000	Interesting.
3029000	3030000	Okay.
3030000	3036000	Now you mentioned, why not hit on these, because they're classic rich examples.
3036000	3040000	Kaufman's Buttons, Huygens Pendulums, and Benard Cells.
3040000	3042000	Benard Cells.
3042000	3045000	And paint those in with your ideas around.
3045000	3052000	Well, the Benard Cells was the source of all my interest in complexity theory.
3052000	3055000	It was the early 1980s, Jim.
3055000	3057000	Could you tell us, folks, what it is, not everybody knows.
3057000	3060000	Okay, a Benard Cells is you take a pan of water.
3060000	3067000	They're called Ray Lee Benard Cells, and they were discovered at the beginning of the 20th century by Ray Lee and Benard.
3067000	3074000	Take a pan of water, any kind of viscous fluid, and you heated the uniformity from below.
3074000	3077000	All right, you still have conduction.
3077000	3086000	After a certain gradient, after a certain threshold of instability, that's my context independent constraint, Jim.
3086000	3103000	After you pass a threshold of that gradient, the system cannot handle any kind of fluctuation, and the context will amplify any minor bubble or perturbation.
3103000	3114000	And all of a sudden, you will get convection cells, those rolling hexagonal cells made of billions of molecules of water that all align in a self-organized way.
3114000	3125000	And that the cell itself constraints top down the individual molecules of water cell they behave as if they knew what was the one next to them was doing.
3125000	3126000	All right.
3126000	3138000	So, it was the 1980s, and I had to go to jury duty here in Montgomery County, and so I took a bag full of stuff that I had to read, and I figured, and I was reading,
3138000	3142000	Kant's critique of practical reason.
3142000	3153000	Kant's critique of practical reason says the problem with T, and by the way, at the time that Kant wrote, teleology was synonymous with self-organization.
3153000	3156000	Go figure, 1804.
3156000	3167000	Kant said, in order to understand this kind of phenomena, he said, we need an understanding of circular causality that is unknown to us.
3167000	3176000	Because remember, Kant had bought the Newtonian-Humian collade that was all effective, efficient causality.
3176000	3180000	So, he said, but look at how nature works.
3180000	3186000	A tree produces the leaves and then is produced in turn by the leaves.
3186000	3196000	So, the whole tree is produced by the component parts and in turn loops back down and produces the components that created in the first place.
3196000	3203000	And so, I'm reading this, going all right, yeah, but how do we fit this into modern science?
3203000	3214000	And then the Prigogene and Stenger's order out of chaos had just come out of print, come in print, and he's looking at dissipated structures which all have that process.
3214000	3220000	You get individually constrained interactions that after a threshold of instability,
3220000	3228000	cross a phase transition and self-organize to produce a whole which then loops back down and constrains the component parts.
3228000	3237000	So, that to me was, whoa, I found a scientifically respectable way of explaining teleology and formal cause.
3237000	3240000	That's what did it for me in the 80s.
3240000	3243000	You were at the right place and right time because Prigogene certainly-
3243000	3248000	Well, and just seeing again, not having to publish so that you-
3248000	3251000	Go where you want to go, right?
3251000	3261000	Decimal point of whatever you already exist allowed me to be a dilettante and play around with ideas just because they were interesting.
3261000	3274000	And one of the things that Prigogene predicts is that these, especially these abiotic complex systems will actually be more efficient at burning energy than their predecessors.
3274000	3276000	And that's the Bernard cells for sure.
3276000	3279000	They actually move more heat through by convection.
3279000	3286000	And one of my favorites is the whirlpool in the toilet actually allows the water to go down faster.
3286000	3293000	So it actually is dissipating the potential energy of the water in the tank more quickly than if it didn't form the whirlpool.
3293000	3297000	You know what I used in class when I taught courses about mines, rains, and machines?
3297000	3301000	I actually taught a seminar on mines, rains, and machines at PG.
3301000	3305000	But I take the two, you know, the standard two large gallons.
3305000	3306000	Oh, yeah.
3306000	3307000	Put them together.
3307000	3309000	And then watch the tornadoes.
3309000	3312000	And the students would, ooh.
3312000	3316000	Yeah, we made one of those for my daughter when she was like a middle school student.
3316000	3317000	Yeah, that was a cool thing.
3317000	3318000	It's pretty cool.
3318000	3320000	They can really appreciate it intuitively.
3320000	3332000	Yeah, so the idea of Prigogene and the idea of dissipative systems, even though they have more structure and more interesting things going on, are also, generally speaking, more efficient at burning energy.
3332000	3336000	And so the good old second law never actually gets violated.
3336000	3338000	It's just in a different form.
3338000	3340000	So this, then, you've set me up perfectly.
3341000	3353000	But thermal equilibrium gets retarded a bit because you have a structure that gets created in the process that persists a bit longer than the component parts.
3353000	3356000	But that's the explanation for social systems.
3356000	3360000	That's an explanation for its cities, right?
3360000	3364000	Cities are more energy efficient than they were organized, right?
3364000	3371000	Though they burn a lot at per unit square foot, they burn a lot, but per person, they're less, which actually now it sets up to my next time.
3371000	3374000	You're not going to fool the second law.
3374000	3375000	No, exactly.
3375000	3376000	That's the one law.
3376000	3382000	If anyone ever comes to you and tells you they beat the second law, tell them to go pound sad, right?
3382000	3384000	And so now we get to where it gets more interesting.
3384000	3391000	And this, of course, is the secret of life is catalyst loops, autocatalytic networks, et cetera.
3391000	3399000	This is where we go from whirlpools, which have a self-forming part, but they're not fully closed loops, right?
3399000	3408000	Well, I really liked a book that came out about seven years ago by two...
3408000	3414000	Well, a lot of them worked out of the University of the Basque country in Spain.
3414000	3419000	And the good thing about those folks is they published in English, otherwise they would go into black hole.
3419000	3420000	But they published in there.
3420000	3424000	Unfortunately, this book is Springer, and Springer's so damn expensive, nobody buys the book.
3424000	3425000	But I think they're very good.
3425000	3428000	And the book is called Biological Autonomy.
3428000	3438000	And their argument is that, well, things like the Krebs cycle and so on, these are closures of process.
3438000	3447000	But once you start having autocatalytic and hypercycles, a la eigen and so on, what do you have that...
3447000	3455000	The constraint loop that closes is a loop of constraints themselves.
3455000	3462000	And so the constraints create the constraining conditions that make them possible to begin with.
3462000	3470000	And that is what enables their self-reinforcing, but their self-perpetuating.
3470000	3484000	And so these Matteo Moreno and Mocio argue that is what makes living things different from, say, even the BZ reaction,
3484000	3491000	where the boundary conditions, the constraints are, in a sense, self-set from without.
3491000	3497000	You set the conditions of the pan of water or the chemicals.
3497000	3505000	But once you get a situation where the constraints themselves become self-perpetuating,
3505000	3510000	then you have the possibility of reproduction of species and that sort of thing.
3510000	3513000	Now, you didn't really hit on it as hard as I thought you might.
3513000	3521000	But the perfect example of that is that the autocatalytic reactions within a cell are also responsible
3521000	3525000	for building and maintaining the membrane that allows the concentration.
3525000	3527000	And that's hugely important to my mind.
3527000	3529000	Absolutely, absolutely.
3529000	3535000	I think that's what they mean because, from memory, we've always thought of it as boundary conditions.
3535000	3544000	And that was my beef with Polani, because Polani says, Polani was ultimately religious.
3544000	3549000	And so Michael Polani, the philosopher at the beginning of the 20th century, I guess it was,
3549000	3554000	he believed that God sets the original boundary conditions.
3554000	3558000	And then once you've got that, then everything else self-organizes within it.
3558000	3567000	But the whole point of, I think, the closure of constraints is that it creates the boundary conditions
3567000	3570000	within which it self-organizes as well.
3570000	3572000	So yes, you're absolutely right.
3572000	3574000	Yeah, I think that's hugely important.
3574000	3579000	And of course, as we've learned, the nature of these membranes changed over time,
3579000	3581000	and it's continually changing.
3581000	3586000	And the fact that they're semi-permeable with different rules for what goes from the inside out
3586000	3594000	and what comes from the outside in are hugely important to maintain the reactions that are going inside.
3594000	3600000	I think we finally understood that because of the role of interfaces in computers.
3600000	3602000	Yeah, I think that helps.
3603000	3611000	And what, therefore, what that also means, I think, is once you have a phase transition to a new dynamic,
3611000	3614000	you have a new code.
3614000	3620000	And a new code means simply the settings and the rules that govern that membrane,
3620000	3628000	that boundary conditions, what it allows in and what it produces as waste and as action.
3628000	3629000	Absolutely.
3629000	3633000	And then the other interesting example you gave, which I had thought of before,
3633000	3637000	is you talked about the architecture of the circulatory system as another...
3637000	3640000	That's more anointing, which is a really nice example,
3640000	3648000	because the vasculature of the body, the lymph node and the blood circulating system,
3648000	3654000	really prevents the seeping out, right?
3654000	3656000	But it is not an energetic force.
3656000	3658000	That's what the heart does.
3659000	3671000	But the vasculature is more like the timing of the playground swing in that it controls the settings.
3671000	3672000	You know what?
3672000	3677000	After I submitted this MIT, which was, geez, it was almost a year and a half, two years ago,
3677000	3679000	but it took so long.
3679000	3688000	I am fascinated recently by the inflammatory system and the immune system connection,
3688000	3692000	because they are now talking about three levels.
3692000	3698000	They're talking about structure, function, and then regulation.
3698000	3704000	And that, you know, if my arm gets cut off,
3704000	3709000	then the inflammation hits it immediately to try to repair the wound.
3709000	3711000	All right?
3711000	3715000	If all of a sudden the interactions in the body are out of kilter,
3715000	3718000	then the function of homeostasis may not work as well.
3718000	3721000	That you get diabetes and so on and so forth.
3721000	3727000	But the idea recently is that perhaps there is a third level,
3727000	3731000	which is the setting of the functional system.
3731000	3735000	I'll call it the set points or the settings,
3735000	3742000	and that perhaps things like PTSD, chronic inflammatory disease syndrome,
3742000	3749000	that kind of thing is that on and off switch, for example,
3749000	3753000	the dimmer switch, the analog is screwy.
3753000	3761000	So it's the set point, it's the regulatory control of that function.
3761000	3765000	That's often that maybe that's the way to attack PTSD, for example.
3765000	3768000	There's nothing wrong with the function of PTSD.
3768000	3771000	We're supposed to freak out if we think someone's attacking us at night.
3771000	3777000	What's wrong is the fact that we are now reacting in a different context
3777000	3779000	the way it should have been before.
3779000	3782000	Then that means there's something wrong with the toggle switch.
3782000	3787000	There's nothing wrong with the switch, which I find really interesting,
3787000	3794000	because I think that has a lot to say with two for social systems.
3794000	3800000	It has a lot to say, not just for the inflammatory system.
3800000	3804000	Perhaps all of complex dynamical systems have those three layers,
3804000	3808000	structure, function, and then regulation.
3808000	3812000	And then, of course, the question is, how do these three levels interact?
3812000	3817000	And they do not interact by efficient causes, they interact by constraints.
3817000	3825000	That everybody who's done hierarchy theory in biology is comfortable with that.
3825000	3831000	Okay, let's move on to another topic here, which is that you described them as constraints,
3831000	3836000	though I would not normally think of them that way, but I think in your lens they work.
3836000	3841000	And that's the idea of scaffolds and scaffolding of affordances, etc.
3841000	3847000	Talk about your thoughts on scaffolding and how you can use the language of constraints around that.
3847000	3857000	I think you have the old-fashioned architectural scaffolds that are external artifacts
3857000	3863000	that are temporary and that guide the construction of new buildings, correct?
3863000	3871000	But if you think of constraints, of context-sensitive constraints as conditions and factors
3871000	3877000	that take a system away from independence, they link things together.
3877000	3888000	What scaffolds do, and I love the work of Bishop and especially the word of WimSat,
3889000	3894000	they've done work on scaffolding long before they got fashionable recently.
3894000	3903000	They provide a temporary equilibrium point from which to take the next step,
3903000	3907000	and it's not only, it's like a ratchet.
3907000	3910000	I think of scaffolds almost like ratchets.
3910000	3920000	They provide a temporary, metastable position from which the next step,
3920000	3928000	whose direction the scaffold itself also suggests, can be more easily taken.
3928000	3932000	But that chapter you're thinking about from the new book,
3932000	3937000	there's so many other different types of constraints, of that kind of constraints.
3937000	3939000	There's entrenchment.
3939000	3946000	That's a hell of a constraint that we use a lot, especially in social systems, correct?
3946000	3952000	To retard any innovation or buffers.
3952000	3959000	I think probably the difference between a buffer and an entrenchment might be how long it lasts, right?
3959000	3967000	But it's a way to control the relationships between the inside and the outside,
3967000	3972000	and the next step, that's why I think of it as a form of constraint.
3972000	3978000	Because the scaffold, again, is not, my bent noir is always efficient cause.
3978000	3983000	I'm always thinking, well, this is something that has effects, but it's not as an efficient cause.
3983000	3987000	So I have buffers, I have entrenchment, I have scaffolding.
3987000	3992000	I have that kind of process that we use a lot.
3992000	3995000	And now you could throw those in with catalysts.
3995000	3996000	Absolutely.
3996000	3999000	And certainly, let's say scaffolds and catalysts both have the effect,
3999000	4002000	while they don't necessarily provide energy themselves,
4002000	4006000	they lower the activation energy for something to occur.
4006000	4007000	Correct, correct.
4007000	4014000	And even those scaffolds that are not temporary like the flying buttresses of Gothic cathedrals
4014000	4016000	that end up being part of the structure,
4016000	4019000	and that is also true of these lattices.
4019000	4029000	They implant that are embedded with nutrients that promote bone growth, right?
4029000	4042000	The point being that the location and the direction of the holes in that lattice are what pattern the bone growth.
4042000	4048000	But then they end up getting absorbed and becoming part of the bone itself.
4048000	4058000	So these are all forms of affecting consequences that are not, or that are in addition to.
4058000	4062000	I don't want to discount efficient causes, obviously.
4062000	4067000	I just don't believe they're the full story.
4067000	4072000	And this, in some sense, the basic laws of physics continue to be true,
4072000	4077000	but there's much more interesting structure being built that's in addition.
4077000	4081000	And that's what the naive reductionism misses.
4081000	4082000	Correct.
4082000	4083000	And now, go ahead.
4083000	4084000	I'm sorry.
4084000	4085000	I interrupt.
4085000	4086000	I'm Cuban.
4086000	4087000	I'm sorry.
4087000	4088000	You talk with your hands.
4088000	4089000	That's right.
4089000	4090000	That's right.
4090000	4093000	And that's, again, I think that it's kind of this myopia of over-reductionism.
4093000	4094000	Nothing wrong with reductionism.
4094000	4096000	No, no, there's nothing wrong with that.
4096000	4098000	You need to know both the dance and the dancer.
4098000	4103000	But there's a sense that somehow the relational and the dynamical are not real.
4103000	4108000	Every bit is real as the primary properties.
4108000	4113000	And that's my problem with myriology and nothing but is so on.
4113000	4118000	The problem that everybody complained about top-down causation is not possible
4118000	4125000	is because it would violate physical closure and it would violate the conservation of energy.
4125000	4129000	Sure, if you think of it as efficient causes, of course, it's going to do those two things.
4129000	4136000	But if it operates as constraining dynamics, you're not violating physical closure
4136000	4140000	or constraint or conservation.
4140000	4143000	So that's why it works very nicely.
4143000	4148000	It's not violating any basic physics tenets.
4148000	4150000	Why don't you do a little riff on that?
4150000	4154000	Because that is one of the questions in complexity.
4154000	4156000	And it befuddles the laymen in particular.
4156000	4157000	What?
4157000	4159000	Top-down causality.
4159000	4164000	And how you can have top-down causality and no magic needs occur.
4164000	4169000	Well, in the very same way that homoestasis changes my glucose production
4169000	4172000	or how does a culture affect me?
4172000	4174000	That is top-down causality.
4174000	4177000	That is causality from the hole in which I am embedded.
4177000	4181000	If I were not part of that culture, it would not affect me.
4181000	4182000	Correct?
4182000	4183000	Right.
4183000	4189000	And that means that the constraint dynamic of the culture in which I am embedded
4189000	4195000	be the college at which I taught, the society in which I live, the family to which I belong,
4195000	4199000	the constraint structure of each of those organizations
4199000	4208000	changes the likelihood of different behaviors that might otherwise have been open to me that are not.
4208000	4215000	In the very same way that once entrained into a Benard cell, the molecule of water
4215000	4221000	has different probabilities of where it is going to go
4221000	4225000	because the constraint structure of the Benard cell affects it.
4225000	4227000	And that is what I mean by top-down causation.
4227000	4231000	So there is nothing magical about it, but it is not efficient causality.
4231000	4234000	If you think of it as efficient causality, then of course it is magical.
4234000	4235000	Gotcha.
4235000	4240000	And there has been many, many pointless conversation on this as you no doubt have experienced it.
4240000	4241000	Absolutely.
4241000	4244000	Well, my centuries of this going on.
4244000	4245000	Indeed.
4245000	4246000	Let's move on.
4246000	4247000	We are getting kind of late on time here.
4247000	4249000	We have got about another 13 minutes.
4249000	4251000	And this was something new to me.
4251000	4254000	Very interesting to always run across something new.
4254000	4257000	And that is the idea of many to one transitions.
4257000	4259000	Maybe you can dig into this in some depth.
4259000	4260000	Okay.
4260000	4267000	And that was, all right, when at the beginning, once behaviorism got put to bed,
4267000	4271000	then functionalism came into play or the identity theory.
4271000	4277000	So the idea was that mind is to brain as a computer software is to its hardware.
4277000	4282000	So then people said, all right, just like a lot of different,
4282000	4289000	Microsoft Office can be run on different, on Apple and the different hardware devices,
4289000	4294000	that's the explanation that gives some legitimacy to the notion of a mind.
4294000	4296000	These are the notion of the brain.
4296000	4299000	The brain is the hardware, the mind is the software fight.
4299000	4306000	But there was also always the idea that the notion of supervenience and Donald Davidson's
4306000	4314000	term is there will be no change in the supervenient properties without any corresponding changes
4314000	4318000	in the subvening in the hardware.
4318000	4324000	So there was always implicit in the notion of supervenience, a one to one relationship.
4324000	4328000	And the reason I think that was true was because I don't think they ever got away from the
4328000	4329000	physicals out.
4329000	4331000	So there was always that one to one relationship.
4331000	4338000	So the idea was, all right, so a mental event, my thinking of my grandmother,
4338000	4345000	my pain in my leg will always be correlated one to one with this particular neuro pattern
4345000	4348000	in the brain, which indicates pain in my leg.
4348000	4352000	This one about indicates that's my, my grandmother.
4352000	4360000	But very quickly, multiple realizability, many to one relationships, all sudden came about.
4360000	4366000	And that was that, well, though, and behold, if this part of the brain is excised,
4366000	4372000	the hearing function might be taken over by the other part of the brain.
4372000	4377000	Another part of the brain that was supposedly not at all dedicated to hearing, but all of
4377000	4378000	a sudden it was.
4378000	4385000	So the notion, and I almost wanted to name this title, this new book, Imprasive Degeneracy.
4385000	4391000	Don't get so, don't get cutesy here, because biologists have always been very comfortable
4391000	4392000	with degeneracy.
4392000	4399000	That is, there are many ways for the same amino acids to produce different amino acids to produce
4399000	4400000	the same protein.
4401000	4411000	That's what I mean by many to one, many different lower level paths to realize the same emergent
4411000	4412000	property.
4414000	4417000	That's what I mean by many to one.
4417000	4425000	And that seems to be true in general for the higher level properties of complex dynamical
4425000	4426000	systems.
4426000	4437000	An economy can stay itself despite many different varieties or many different configurations,
4437000	4444000	as long as that overarching constraint structure remains within a certain range.
4444000	4447000	Does that, have I made sense here?
4447000	4448000	Yes, ish.
4448000	4450000	Let me drill it a little further.
4450000	4451000	All right.
4451000	4456000	You also talk about many to one, because, you know, we do have multiple realizable domains,
4456000	4458000	and the idea of degeneracy is very important.
4458000	4464000	And for the audience, degeneracy basically means that things with different forms can
4464000	4466000	have the same function, right?
4466000	4467000	Correct.
4467000	4469000	Different lower levels, same higher levels.
4469000	4470000	Same higher level.
4470000	4474000	And there's a bunch of famous examples in biochemistry where it's more famous, but you also talked
4474000	4480000	about many to one as something analogous to dimensional reduction in systems.
4480000	4484000	And think about the fact that, you know, with the example I gave before, Jim gets up out
4484000	4488000	of his chair and goes down the hill to the ice cream store.
4488000	4493000	There's lots and lots and lots of predicate signals that probably led to that, right?
4493000	4498000	And they eventually got concentrated down to a single decision.
4498000	4503000	Should I get up, go down the hill, get an ice cream cone, or should I go to the refrigerator,
4503000	4507000	freezer and pull out a frozen yogurt bar, right?
4507000	4512000	And the fact that there's many, many, many inputs, but there's a single decision around
4512000	4516000	the affordance was also the way you described many to one.
4516000	4525000	The reverse of it is pluripotentiality, which is one lower level that has the potential
4525000	4529000	for becoming much more different functionality.
4529000	4532000	And of course, stem cells are the example of that, right?
4532000	4537000	They are pluripotents.
4537000	4542000	They are not totipotents, which people thought might, they might be for a while,
4542000	4544000	that they could become any other.
4544000	4548000	They're not quite their totipotentiality.
4548000	4551000	But that was the problem with supervenience.
4551000	4559000	Because then the question was, how can the same neural processes in the brain produce
4559000	4568000	such very different, differently property functions, higher level properties?
4568000	4575000	And Davidson said, if you can't identify a causal relationship between the two,
4575000	4578000	then you might as well go back to behaviorism.
4578000	4588000	And at that point, J-Wan Kim at Brown, who had been a big advocate of supervenience at the time,
4588000	4590000	decided supervenience won't work.
4590000	4594000	It either is one to one or it's not.
4594000	4596000	And that's why he titled that.
4596000	4599000	Was it a paper or was it a book called Descartes' Revenge?
4599000	4608000	Because then again, the problem was, how do you get top down causality in that once you decide to go to the fridge, Jim,
4608000	4611000	you could decide to walk directly to the fridge.
4611000	4617000	You could decide to go outside because somebody is going to watch you take something from the fridge
4617000	4619000	and you go outside, you go all the way around.
4619000	4625000	So there are a lot of different ways to implement that top down decision, correct?
4625000	4636000	And the problem with again, efficient causality is that it only worked for instantaneous relationships.
4636000	4641000	Efficient causality cannot handle what used to be called in philosophy standing causes.
4641000	4646000	In other words, I decided I'm going to write a book and it took me two damn years to do so.
4646000	4658000	So how on earth does that intention continue in force and continue exerting an influence all throughout those two years?
4658000	4665000	That's what I meant in that sense by multiple realizability top down.
4665000	4672000	Yeah, and then of course that goes back to the very classic Greek philosophical question of the ship of Theseus, right?
4672000	4678000	Our audience goes, okay, the supposed ship that Theseus took to Crete, I guess it was,
4678000	4684000	then it was preserved in Athenian harbor and then over the years, the boards rotted and they replaced one by one.
4684000	4687000	Eventually every plank on the ship had been replaced.
4687000	4691000	There was nothing original, but it was the same ship or was it, right?
4691000	4692000	Correct.
4692000	4698000	And we can say the same thing about organizations and cultures and societies and, you know.
4698000	4703000	And humans, you know, basically every one of our atoms gets replaced, what, every year or something like that?
4703000	4706000	Every seven years, every cells or whatever.
4706000	4707000	Exactly.
4707000	4717000	So I think I stick my neck out more than maybe I have a right to, but that's why I wanted to show in this new book that people say,
4717000	4719000	you're reducing everything to physics and chemistry.
4719000	4732000	No, I'm showing that there are, I never know the difference, homologous analogous constraint dynamics that operate all along the spiral.
4732000	4736000	It's not a, it's not a reduction.
4736000	4747000	It is to show that once you do the phase transition from physics to chemistry, then you've got new emergent properties, new codes, new everything.
4747000	4752000	Once you go there from, from chemistry to biology and so on down the line.
4752000	4753000	Got it.
4753000	4757000	Well, let's wrap up with the future of these fields.
4757000	4769000	And you talk a fair bit about the relatively new 4e approach to cognitive science, which I think is maybe getting closer to your way of thinking.
4769000	4770000	Yes.
4770000	4777000	I mean, I really like the work of the Paolo probably Andy Clark started the whole thing with the embodied mind idea.
4777000	4786000	And people like Merlin Donald, who I love his book, all of these folks started realizing the mind just ain't in the brain.
4787000	4795000	Because it takes me forever to write because I literally realize that I work out the ideas as I write.
4795000	4803000	Now I type, but it's not that I sit down thinking all through and then I just write it out, you know, because it's all been worked out in my mind.
4803000	4815000	Literally. So, so the notion that that that that our minds extend beyond the boundaries of our body to artifacts to tools.
4815000	4824000	For example, when you're driving, I'm the designated teach your grandchild to parallel park person because their parents are petrified.
4824000	4826000	Nobody else wants to do it.
4826000	4828000	I'm a good parallel parker.
4828000	4839000	You know, I say, look, after a while you realize that that you can almost feel the car as the extension, you know exactly where it's going to fit in a in a tight space.
4839000	4843000	So the idea that the mind ain't just in the brain, it's embodied.
4843000	4858000	But then it's also enacted because it's not just that it's embodied in my in the agent's body, but it's also the mind is enacted in their behavior within a particular context and so on.
4859000	4877000	What I what I try to do in this new book is then the question is, well, how does this holistic ecosystem within which this embodiment and enlightenment, how does that coherent dynamic come about.
4877000	4883000	And that's why I want to show that before you have a an enact.
4883000	4891000	I don't think that if you're not Japanese, a tatami mat affords sleeping.
4891000	4899000	I don't think a Victorian throne and that's seating to somebody who's never seen it before.
4899000	4904000	So to somebody who's used to sleeping on the ground, and I don't think it does it automatically.
4904000	4908000	It is part of a whole ecosystem, a whole coherent dynamic.
4908000	4912000	And my question is, how do those coherent dynamics come about.
4912000	4920000	And again, my answer seems to be I don't know what else to call constraints, all of these processes.
4920000	4924000	And accumulation of constraints over time and their channel.
4924000	4928000	But it's not just accumulation in that one at one damn thing after another.
4928000	4934000	It's how they into how they interweave with one another.
4934000	4939000	That's what creates this overarching interlocking set of constraints.
4939000	4943000	Yeah, and then and that that and those constraints are real.
4944000	4949000	See, I say from the beginning in the book, I'm never since can't ever.
4949000	4953000	Every time something gets bored, we all we all hide behind epistemology.
4953000	4956000	Oh, well, it's the way we make sense of things.
4956000	4959000	No dammit, I think that's the way reality works.
4959000	4962000	And you know, I don't need to I have to I have tenure.
4962000	4965000	I don't need to worry about pleasing somebody else.
4965000	4968000	I can say this if it's wrong, it's wrong, but that's okay.
4968000	4969000	Oh, right.
4969000	4975000	Well, I really want to thank Alicia Herrero and her new book, Context Changes Everything,
4975000	4977000	as you can tell by our conversation.
4977000	4980000	I learned some things, had some new ideas I've never been exposed to.
4980000	4982000	I thought it was really interesting.
4982000	4984000	And despite what she said, I thought it was damn well written.
4984000	4986000	So thank you, Alicia.
4986000	4988000	Thank you so much.
4992000	4995000	Audio production and editing by Andrew Blevins Productions.
4995000	5000000	Music by Tom Mueller at modernspacemusic.com
