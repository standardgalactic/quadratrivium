WEBVTT

00:00.000 --> 00:06.080
Academia is broken. Universities are broken. The way that academic research is published

00:06.080 --> 00:10.720
is broken. That's the message that's come through loud and clear over the last few weeks,

00:10.720 --> 00:15.440
thanks to three articles concerning the research of Francesca Geno. If you don't know what I'm

00:15.440 --> 00:20.320
talking about, let me explain. Francesca Geno is a professor of behavioral science at Harvard

00:20.320 --> 00:25.120
University. She is extremely well known in the field. I've talked about her research to clients

00:25.120 --> 00:29.920
before. I've recommended books on this channel to you guys that use her work as a key reference,

00:30.000 --> 00:34.560
I've used her research before as references in my own essays and work that I did at university

00:34.560 --> 00:39.520
when it comes to academic fame, Francesca Geno is up there, as you would expect from someone

00:39.520 --> 00:44.080
who is a professor at Harvard. However, the reason why she's so well known is because her

00:44.080 --> 00:48.880
research tends to bring out a lot of very surprising findings. Now, some people just think this

00:48.880 --> 00:52.960
research is cool and don't think much more about it, but a lot of people in the industry have been

00:52.960 --> 00:58.080
quite skeptical of Francesca Geno and her work because her results just seem a little bit too

00:58.080 --> 01:02.320
good. Her hypotheses are really wacky, but yet they always seem to be proved correct,

01:02.320 --> 01:07.680
the effect sizes from her study seem to be really large, and her statistical significance just seem

01:07.680 --> 01:11.600
a little bit too significant. So while some of us have been skeptical of her work for a while,

01:11.600 --> 01:16.000
nobody has taken the time to actually investigate her research and go into her data to see if they

01:16.000 --> 01:22.000
can find anything fishy... until now. These three guys, Yuri, Joe and Leif, are also professors

01:22.000 --> 01:26.560
of behavioral science and other related subjects from different universities across the world,

01:26.560 --> 01:31.120
and they took it upon themselves to investigate Francesca Geno and her data to see if there was

01:31.120 --> 01:35.760
anything fishy going on. And spoiler alert, they found a lot of fishy stuff in the data,

01:35.760 --> 01:39.600
and that's what the three articles that they released are talking about. Each article relates

01:39.600 --> 01:43.440
to a different study by Francesca Geno, and in this video I'm going to be taking you through

01:43.440 --> 01:48.240
each one. The results of their investigation are shocking, damning for Francesca Geno,

01:48.240 --> 01:52.080
but I think they speak even louder volumes about the state of academia in general,

01:52.080 --> 01:55.920
and that's what I'm going to be concluding on at the end of this video. So without further ado,

01:56.000 --> 01:59.920
let's jump into the first study. So this first article is called clusterfake, and it's referring

01:59.920 --> 02:05.520
to a paper written by Geno in 2012, along with their collaborators Shu, Nina Mazar, Dan Ariely,

02:05.520 --> 02:09.520
and Max Bazeman. Given the fact that I know the first names of all of those researchers with the

02:09.520 --> 02:13.760
exception of Shu, I should tell you that all of these researchers are very well-known people in

02:13.760 --> 02:18.400
the field of behavioral science. So in this study, they were trying to get participants to be more

02:18.400 --> 02:22.960
honest, and their hypothesis was that if you put an honesty pledge at the top of a form,

02:22.960 --> 02:27.280
that'll make people more honest when they then fill out the rest of the form. So all of the studies

02:27.280 --> 02:32.000
in this paper by these authors were looking at this idea, that if you put an honesty pledge at the

02:32.000 --> 02:36.320
top of a form, people will be more honest than if you put the honesty pledge at the bottom of a form.

02:36.320 --> 02:41.200
Now the first study in this paper was led by Francesca Geno, our protagonist. So in this study,

02:41.200 --> 02:46.000
students were brought into a lab to complete 20 math puzzles in five minutes. The students were

02:46.000 --> 02:50.560
told that they would be paid one dollar for each math puzzle they solved correctly, and the way that

02:50.560 --> 02:54.800
this worked was that when students walked into the room, there were two pieces of paper. They had

02:54.800 --> 02:59.120
their work paper and their report paper. So on the work paper, they'd write down their workings for

02:59.120 --> 03:03.040
the math questions and of course their answers, and then on the report paper, they would then have

03:03.040 --> 03:07.600
to report how many answers they got correctly and therefore how much they should get paid. The students

03:07.600 --> 03:11.520
were then told that before handing in their report paper to the researchers and getting paid, that

03:11.520 --> 03:16.480
they should shred their original work paper. The idea behind this is that by shredding their work

03:16.480 --> 03:20.960
paper, there's then a stronger incentive for them to cheat on the report paper and lie about

03:20.960 --> 03:25.040
how many answers they got correct, since the researchers in theory should never know how

03:25.040 --> 03:29.040
many answers they got right on the work paper. But what the students didn't know was that the

03:29.040 --> 03:33.440
shredder at the back of the room was not a normal shredder. What the people in the experiment don't

03:33.440 --> 03:39.120
know is that the shredder has been fixed. So the shredder only shreds the sides of the page,

03:39.120 --> 03:45.120
but the main body of the page remains intact. Now in order to test the hypothesis of the researchers,

03:45.120 --> 03:49.600
on the reporting paper, the participants were split into two groups. Half of them had an honesty

03:49.600 --> 03:53.840
pledge at the top of the paper, and half of them had an honesty pledge at the bottom of the paper,

03:53.840 --> 03:57.440
with the idea being of course that those who signed the honesty pledge at the top would

03:57.440 --> 04:03.440
then cheat less going forward. So what was the result? Well the result showed a massive effect

04:03.440 --> 04:07.200
from this simple intervention. According to what was published in the study originally,

04:07.200 --> 04:12.000
for the students who signed the honesty pledge at the top of the form, only 37% of them lied,

04:12.000 --> 04:17.680
but when students signed at the bottom of the form, 79% of students lied. This is a massive

04:17.680 --> 04:22.480
effect size that the researchers are reporting, and as a result of that, this study gained a lot

04:22.480 --> 04:26.960
of public attention, and I have talked about it with many people in the past before because it is

04:26.960 --> 04:32.880
so surprising. But that's why these vigilantes were suspicious. The results just seem a bit too good.

04:32.880 --> 04:37.040
Can it really be the case that simply moving an honesty pledge from the bottom to the top of a

04:37.040 --> 04:41.920
form can have such a dramatic effect on the amount of cheating that happens? It seems pretty

04:41.920 --> 04:47.600
unlikely. So our vigilantes managed to source the original data set that was published by the

04:47.600 --> 04:52.560
authors of the study, and when they looked into the data it just seemed a little bit fishy. If you

04:52.560 --> 04:58.000
look at this table and specifically look at the left hand column, the P hash column, this is referring

04:58.000 --> 05:03.920
to participant ID. This is the unique ID given to each participant in a study, and as it's highlighted

05:03.920 --> 05:08.080
in yellow, there are some weird anomalies in the way that this data has been sorted. Because

05:08.080 --> 05:12.480
when you look at this data, it seems obvious that this has been sorted by first the condition, so

05:12.480 --> 05:16.640
all of condition one are together, and all of condition two are together, and then in ascending

05:16.640 --> 05:21.920
order of the participant ID, which means that the numbers should consistently get bigger as you go

05:21.920 --> 05:26.560
down the line, and there should be no duplicates. Remember, each participant has a unique ID. So

05:26.560 --> 05:30.720
when you look at this data, it's a bit weird. We've got two 49s here, that's a duplicate,

05:30.720 --> 05:34.720
that should never happen, and then at the end of the condition one set of participants,

05:34.720 --> 05:40.720
you have participant 51 coming after 95, then 12, then 101, like that sequence doesn't make any

05:40.720 --> 05:45.840
sense. And similarly, when you get to condition two, we start with seven, then 91, then 52,

05:45.840 --> 05:50.160
then all the way back down to five again. These entries in the data set look suspicious. They

05:50.160 --> 05:54.640
look like they're out of sequence, which suggests that somebody maybe has tampered with them. So

05:54.640 --> 05:59.840
our vigilantes are suspicious of these rows. So then you have to ask the question, why would the

05:59.840 --> 06:04.560
researchers want to tamper with the data? Well, it's because they would want to show a bigger

06:04.560 --> 06:09.760
effect than those actually seen in the real data. The more dramatic the effect of the intervention

06:09.760 --> 06:14.240
is, the more surprising the result of the study is, and therefore the more likely it is to get

06:14.240 --> 06:18.320
published in the top journal, the more likely it is that this will make a lot of press headlines,

06:18.320 --> 06:22.160
that they will get lots of interviews and work off the back of it. And so there's a strong incentive

06:22.160 --> 06:27.200
for the researchers to fudge the data a little bit, make the effect seem larger than it really is.

06:27.200 --> 06:32.000
And so that's what our vigilantes were looking for. They wanted to see if these suspicious rows

06:32.000 --> 06:37.200
in the data set showed a bigger effect than the normal data that wasn't suspicious. And sure

06:37.200 --> 06:42.000
enough, that's exactly what they found. If you look at this graph, the red circles with the cross

06:42.000 --> 06:46.880
show the suspicious data and the blue dots show the unsuspicious data. And as you can see, the

06:46.880 --> 06:51.680
circles with the red crosses are the most extreme ones, meaning that these few data points are

06:51.680 --> 06:57.120
inflating the effect size. Now the article goes on to show how our vigilantes did some very clever

06:57.120 --> 07:01.600
work to unpack the Excel file that this data was stored in, and they were able to show quite clearly

07:01.600 --> 07:06.800
that these suspicious rows were manually resorted in the data set. I won't go into it on this video

07:06.800 --> 07:10.400
because it's quite technical, but I'll have a link to all of these articles in the description if

07:10.400 --> 07:15.600
you want to read them in full. But as you'll soon see, this theme of suspicious data and then those

07:15.600 --> 07:21.200
data showing extremely strong effect sizes will be a recurring pattern. So let's move on to study

07:21.200 --> 07:26.080
two. Now this second article is called My Class Year is Harvard and you'll see why in a second.

07:26.080 --> 07:31.520
They're looking at a study from 2015 written by Francesca Geno as well as Kuchaki and Galinsky,

07:31.520 --> 07:36.320
again two fairly well known researchers in the field. Now the hypothesis for this study, in my

07:36.320 --> 07:41.360
opinion, is pretty stupid. The hypothesis is that if you argue against something that you really

07:41.360 --> 07:47.200
believe in, that makes you feel dirty, which then increases your desire for cleansing products,

07:47.200 --> 07:52.080
which is kind of silly in my opinion. But nevertheless, this is what they were researching.

07:52.080 --> 07:57.440
So this study was done at Harvard University with almost 500 students and what they asked the

07:57.440 --> 08:01.520
participants to do was the following. So students of Harvard University were brought into the lab

08:01.520 --> 08:05.360
and then asked how they felt about this thing called the Q Guide. I don't really know what the Q

08:05.360 --> 08:09.200
Guide is, but apparently it's a hot topic at Harvard and it's very controversial. Some people are for

08:09.200 --> 08:12.720
it, some people are against it. So when they were brought into the lab, they were asked how do you

08:12.720 --> 08:16.720
feel about the Q Guide and they either said they were for or against it and then the participants

08:16.720 --> 08:21.360
were split into two groups. Half the participants were asked to write an essay supporting the

08:21.360 --> 08:25.600
view that they just gave. So if they said I'm for the Q Guide, they had to then write an essay

08:25.600 --> 08:29.680
explaining why they were for the Q Guide. But then half the participants were asked to write an essay

08:29.680 --> 08:34.080
arguing opposite to the point that they just gave. So if they said I'm for the Q Guide, they would

08:34.080 --> 08:38.800
then have to write an essay explaining why they should be against the Q Guide. Again, the idea

08:38.800 --> 08:43.120
being that those who are writing an essay against what they actually believe in would make them feel

08:43.120 --> 08:47.680
dirty. Because after they'd written this essay, they were then shown five different cleansing

08:47.680 --> 08:52.080
products. And the participants in the study had to rate how desirable they felt these cleansing

08:52.080 --> 08:57.920
products were on a scale of one to seven, with one being completely undesirable and seven being

08:57.920 --> 09:03.920
completely desirable. And again, the authors found a strong effect. You can see here that the p value

09:03.920 --> 09:09.280
is less than 0.0001. And for those of you who haven't had any academic training in statistics,

09:09.280 --> 09:12.720
basically when you're doing a study like this, you're looking for a p value that's less than

09:12.720 --> 09:18.240
0.05. That's the industry standard. If it's less than 0.05, you say, yes, I'm confident that the

09:18.240 --> 09:24.000
effect that I'm seeing is caused by the manipulation that I just did. So less than 0.0001 is an

09:24.000 --> 09:29.760
extremely strong effect. You're basically 100% confident that what you're seeing in the data

09:29.760 --> 09:35.040
is caused by the manipulation that you did. So once again, our vigilantes are suspicious of this

09:35.040 --> 09:39.360
very strong effect sites. So they managed to source the data online and do a little bit of

09:39.360 --> 09:43.920
investigating. And what they find are some weird anomalies in the kind of demographic data that

09:43.920 --> 09:47.520
the participants have to give when they enter the study. And this is very common in psychological

09:47.520 --> 09:51.440
studies that participants have to give a little bit of demographic data about themselves, which

09:51.440 --> 09:55.440
gives the researchers a little bit more flexibility about how they cut up the data later on. So in

09:55.440 --> 09:59.280
this particular study, the participants were asked a number of demographic questions, including their

09:59.280 --> 10:03.840
age, their gender, and then number six was what year in school they were. Now the way this question

10:03.840 --> 10:08.000
is structured isn't very good, in my opinion, in terms of research design. But nevertheless,

10:08.000 --> 10:12.160
there are a number of acceptable answers that you can give to year in school. Because Harvard is an

10:12.160 --> 10:16.160
American school, you might say, I'm a senior, right, which is a common thing, or a sophomore,

10:16.160 --> 10:21.760
you might write the year that you're supposed to graduate, 2015, 2016, etc. Or you might indicate a

10:21.760 --> 10:26.080
one, a two, a three, a four, or a five to indicate how many years of school that you've been in there.

10:26.080 --> 10:29.760
These are all different answers, but they're all acceptable and make sense in the context of being

10:29.760 --> 10:34.000
asked what year in school you. And so when our vigilantes go into the data, that's exactly what

10:34.000 --> 10:37.920
they saw in this column, a range of different answers that were all acceptable, except for

10:37.920 --> 10:42.880
one, there were 20 entries in this data set, where the answer to the question what year in school

10:42.880 --> 10:50.080
are you was Harvard. That doesn't make any sense. What year in school are you? Harvard. What? Right,

10:50.080 --> 10:53.680
that doesn't make any sense. And the other thing that was suspicious about these Harvard entries

10:53.680 --> 10:58.800
is that they were all grouped together within 35 rows. Again, this was a data set of nearly 500

10:58.800 --> 11:04.400
different participants, and yet all of these weird Harvard answers were within 35 rows. So once again,

11:04.400 --> 11:09.840
our vigilantes treat these Harvard answers as suspicious data entries. They mark them in red

11:09.840 --> 11:15.520
circles with crosses. And as you can see, the ones that are suspicious are again, the most

11:15.520 --> 11:21.200
extreme answers supporting the hypothesis of the researchers, with the exception of this one. But

11:21.200 --> 11:25.680
come on, it's most suspicious when you look at the ones on argued other side. So these are the

11:25.680 --> 11:30.000
people who wrote an essay arguing against what they didn't believe in, and therefore was supposed

11:30.080 --> 11:34.880
to feel more dirty and find cleansing products more appealing. All of these suspicious entries on

11:34.880 --> 11:39.360
that side of the manipulation went for seven, that they found all of the cleaning products

11:39.360 --> 11:44.240
completely desirable. And so what our vigilantes go on to say is that these were just the 20 entries

11:44.240 --> 11:48.640
in the data set that looked suspicious because of this Harvard answer to the demographic question.

11:48.640 --> 11:53.120
But who's to say that the other data in the data set was not also tampered with, but just they were

11:53.120 --> 11:57.040
more careful when they filled in this column and didn't put Harvard. Since it seems pretty clear

11:57.040 --> 12:01.360
that at least these 20 entries were manipulated and tampered with some way, it probably means that

12:01.360 --> 12:05.280
there are other entries within this data set that were also tampered with. Are you shocked yet? I

12:05.280 --> 12:09.280
hope you are, but it's about to get worse because there's a third article to do with Francesca

12:09.280 --> 12:13.760
Geno. So this third article was released literally yesterday, the day before I'm filming this video,

12:13.760 --> 12:18.720
and it's called the cheaters are out of order. This is written by Francesca Geno and a guy called

12:18.720 --> 12:23.920
Wilta Muth. I don't know Wilta Muth, but again, I find it incredibly ironic that all of this

12:23.920 --> 12:27.760
cheating and fake data is being conducted by researchers who are studying

12:27.760 --> 12:33.680
the science of honesty. It is incredibly ironic. So in this third study, Geno and her co-author

12:33.680 --> 12:39.360
are investigating the idea that people who cheat, people that lie, who are dishonest,

12:39.360 --> 12:45.200
are actually more creative. And they call the paper evil genius, how dishonesty can lead to

12:45.200 --> 12:52.480
greater creativity. So let's quickly go through how the study worked. Participants were brought

12:52.480 --> 12:57.520
into a lab where they were sat at a machine with a virtual coin flipping mechanism. What the

12:57.520 --> 13:02.960
participants are asked to do is to predict whether the coin will flip heads or tails, and then they

13:02.960 --> 13:07.120
would push a button to actually flip the coin. And if they had predicted correctly about whether

13:07.120 --> 13:11.600
it would go heads or tails, then they would get a dollar. So again, there's a strong incentive to

13:11.600 --> 13:14.960
cheat. So the participants would write down on a piece of paper how many predictions they got

13:14.960 --> 13:18.480
correct, and then they would hand that to the researcher in order to get paid. Then of course,

13:18.480 --> 13:22.400
the researcher would then go back and look at the machine that they were flipping the coin on

13:22.400 --> 13:26.640
to see how many they actually got correct. And then they were able to tell how many times that

13:26.640 --> 13:31.280
participant had cheated. So after they completed the coin flipping task, they were then given a

13:31.280 --> 13:36.720
creativity task. And the creativity task was how many different uses can you think of for a

13:36.720 --> 13:41.040
piece of newspaper? So in psychology, this is a pretty common technique for testing creativity.

13:41.040 --> 13:45.280
You give somebody an inanimate object, and then you say how many uses can you think of

13:45.280 --> 13:51.040
for this inanimate object. And again, with this study, we see a very strong effect size. Remember,

13:51.040 --> 13:58.400
the magic number that academics look for is P less than 0.05. And here we have P less than 0.001.

13:58.400 --> 14:02.320
So basically what that means is that there's an extremely high likelihood that the effect that

14:02.320 --> 14:07.440
the academics are seeing is caused by the manipulation that they did. So again, our vigilantes

14:07.440 --> 14:11.840
are suspicious. But this one is interesting because our vigilantes were able to actually

14:11.920 --> 14:17.280
get the data set from Gino several years ago. So they got this data set directly from Gino.

14:17.280 --> 14:22.160
So again, when our vigilantes look into the data, they find some weird things going on.

14:22.160 --> 14:26.720
As you can see, it seems to be sorted by two things. Firstly, by the number of times the

14:26.720 --> 14:31.040
participant cheated. So all of the people who didn't cheat at all are zeros. And then the

14:31.040 --> 14:35.120
number of responses is the number of different uses for a newspaper that that participant could

14:35.120 --> 14:39.040
come up with. And those are clearly ranked in ascending order. But as you can see from this

14:39.040 --> 14:43.600
next screenshot, some of the cheaters are out of order. So these are the people who cheated once,

14:43.600 --> 14:47.600
who basically over reported one time, and the number of uses that they could come up with for

14:47.600 --> 14:53.680
the newspaper are out of sequence. Here we have three, four, 13, then nine, and then back down to

14:53.680 --> 14:58.480
five again, then back up to nine, then five, then nine, then eight, then nine is just a total mess,

14:58.480 --> 15:02.240
right? So these ones that are highlighted in yellow are the suspicious ones. They're the ones

15:02.240 --> 15:06.720
that are out of order, according to how the data appears to have been sorted. So what our

15:06.720 --> 15:11.440
vigilantes did was they basically took this data set and then made a new column and they called

15:11.440 --> 15:16.480
it imputed low or imputed high. What that basically means is that rather than taking the number of

15:16.480 --> 15:20.240
responses that are written down in this original data set, they're going to say, well, where does

15:20.240 --> 15:25.520
this entry sit in the ranking order? And so we're going to replace the value that is given here

15:25.520 --> 15:29.440
with what the value should really be. So if it's between four and five, then that number should

15:29.440 --> 15:33.760
be either four or five, whether it's imputed low or imputed high. Does that make sense? So once

15:33.840 --> 15:39.040
again, our researchers plotted the data, suspicious entries are marked with a circle and a cross.

15:39.600 --> 15:44.320
And as you can see, the suspicious entries are the ones that deviate from the pattern that you see

15:44.320 --> 15:48.080
in the non cheaters, the blue line. So in other words, the ones that are out of order,

15:48.080 --> 15:53.040
the suspicious entries, they're the ones showing the effect. But when you use the imputed position,

15:53.040 --> 15:58.000
so that's the number that is implied by the row that the entry was in, then suddenly the entire

15:58.000 --> 16:02.480
effect disappears. And the group of cheaters seem to show a very similar pattern to the group of

16:02.480 --> 16:07.600
non cheaters. And the result of this statistically speaking is significant. Remember the original

16:07.600 --> 16:13.680
p value for this study was p less than 0.0001. But once you use the data that's implied by the

16:13.680 --> 16:20.480
row, suddenly the significance completely disappears. It then goes to p equals 0.292 or p equals 0.180,

16:20.480 --> 16:24.640
depending on whether you're imputing low or high. Remember, in order for an academic study to be

16:24.640 --> 16:31.120
significant, the standard is p less than 0.05. And here the p is clearly more than 0.05. Again,

16:31.120 --> 16:35.120
this article goes on. The vigilantes do a little bit more research to really back up the point and

16:35.120 --> 16:40.160
really drive home the fact that this data is very suspicious. I won't go into the details now. Again,

16:40.160 --> 16:43.600
all of these articles are linked in the description. Go check them out. And you'll notice that these

16:43.600 --> 16:47.600
were all called part one, part two, part three. And that's because this is actually a four part

16:47.600 --> 16:52.080
series. So I'm expecting a fourth article to come out after this video is published looking at yet

16:52.080 --> 16:56.880
another study from Francesca Geno. But I hope by this point, you get the picture, there's a number

16:56.880 --> 17:01.200
of studies conducted by Francesca Geno with very suspicious looking data. So at this point,

17:01.200 --> 17:06.160
you're probably wondering how did Harvard allow this? And the short answer is, well,

17:06.160 --> 17:10.160
they don't really seem to have done. If you go on Francesca Geno's page on the Harvard website,

17:10.160 --> 17:14.880
it shows that she's on administrative leave. I think we all know what that means. And Harvard,

17:14.880 --> 17:19.360
who have even more access to Francesca Geno's data than our vigilantes do, have since asked for

17:19.360 --> 17:23.280
several of Francesca Geno's papers to be retracted from the journals that they were originally

17:23.360 --> 17:28.080
published in. Now, this is a bad look for Francesca Geno, right? And we can't be sure that it was

17:28.080 --> 17:32.160
Francesca Geno who was doing this manipulation. It could be one of her co-authors. But given that

17:32.160 --> 17:36.080
she's the common thread between all of these different papers, it seems pretty likely that

17:36.080 --> 17:41.520
it was her in the world of psychology and writing good quality academic papers. This is really bad.

17:41.520 --> 17:46.400
It's not only bad for Francesca Geno, but it's bad for the field as a whole. It casts doubt over

17:46.400 --> 17:50.800
the entire field of behavioral science, because we don't know the extent of the damage that bad

17:50.800 --> 17:55.360
actors like Geno have been causing in the field and for how long. Like I said, Francesca Geno has

17:55.360 --> 17:59.840
been a prominent name in the field for years, gaining a position at one of the top universities,

17:59.840 --> 18:04.240
Harvard. So who's to say that this isn't a problem that is rife amongst many other researchers

18:04.240 --> 18:08.800
in the field? We certainly hope not. But you can't really know when somebody so high profile like

18:08.800 --> 18:12.720
this has been engaging in this kind of behavior for years and getting away with it. It also looks

18:12.720 --> 18:17.440
bad for people like me who work in the industry, who trust these academics to publish good quality

18:17.520 --> 18:21.840
research that we then use to try and influence real world change in businesses, in government,

18:21.840 --> 18:26.320
and so on and so forth. Like I said, I've used Geno's work before to make recommendations to my

18:26.320 --> 18:30.240
clients. And I've recommended to you guys to read Dan Ariely's book, The Honest Truth About

18:30.240 --> 18:34.400
Dishonesty in the Past, a book which I no longer recommend since the paper that was talked about

18:34.400 --> 18:38.240
in the first article here is used heavily as a reference for a lot of the claims that Ariely

18:38.240 --> 18:42.480
is making in that book. And while it's tempting here to just completely lay into Francesca Geno

18:42.480 --> 18:46.480
and just, you know, really have a go at her for this kind of bad behavior, I actually kind of

18:46.560 --> 18:50.560
understand why she did it, right? If you're an academic at a top institution like Harvard,

18:50.560 --> 18:54.960
you are under an enormous amount of pressure to publish surprising results and consistently.

18:54.960 --> 18:59.200
Surprising results with big effect sizes are more likely to get published in top journals when you

18:59.200 --> 19:03.760
more press interviews and basically cement your position there at a top university like Harvard.

19:03.760 --> 19:07.680
So there is a strong incentive for academics to fudge data like this and come up with more

19:07.680 --> 19:12.080
surprising results in order to try and maintain their position. I'm not condoning the behavior in

19:12.080 --> 19:16.640
the slightest. It's completely unacceptable that an academic would do this, but I can somewhat

19:16.640 --> 19:20.880
empathize that she's under a lot of pressure and can see how the incentives are working against

19:20.880 --> 19:25.120
the practice of following good science. But what do you guys think of Francesca Geno and all of

19:25.120 --> 19:28.800
this nonsense? Let me know in the comments below. Please go read the articles that are in the

19:28.800 --> 19:33.040
description. Thank you to Yuri, Joe, and Leigh for publishing this research. You guys are absolute

19:33.040 --> 19:36.160
legends. And Francesca Geno, if you're watching this video, I know you must be going through a

19:36.160 --> 19:40.560
really rough time right now to have your sort of entire career ripped away from you so publicly

19:40.560 --> 19:44.400
like this. While I think that what you did is completely unacceptable, please don't do anything

19:44.400 --> 19:48.560
stupid with your own life. You're still a valuable human being. But thank you guys so much for watching

19:48.560 --> 19:50.000
and I'll see you next time. Bye bye.

