start	end	text
0	3060	The best thing I hope my lab does on their best days,
3060	4860	taking these ideas from deep philosophy
4860	6940	that people have argued about for thousands of years
6940	9420	and bringing them to the bedside, to the clinic.
9420	11100	What you look like and where you come from
11100	13500	simply cannot be the foundation
13500	15420	for how we're going to relate to each other.
15420	18060	But I don't feel in any way diminished by the idea
18060	20820	that there are an infinitude of other minds,
20820	24420	highly diverse minds, endless sentient forms
24420	27180	that are also having experiences that strive
27180	29140	and suffer to various degrees.
29220	30900	I think what we have is essential.
30900	33940	I would like humanity to scale its cognitive capacity
33940	35860	more specifically, not just the intelligence,
35860	39460	but the radius of concern, of care, and of compassion.
39460	40980	I think we need to scale that up.
40980	43140	The amount of emails that I get every day
43140	45980	from people with the most unbelievable examples
45980	48700	of biomedical suffering is just incredible.
48700	51420	So I think it is utter moral cowardice
51420	54060	to focus on what we shouldn't do,
54060	56300	as opposed to our duty now that we have,
56300	58260	for the first time, we have the ability
58260	60820	to actually rationally approach these matters,
60820	63980	to try to guarantee a better embodiment
63980	65420	for sentient beings on Earth.
76300	77980	Cool, well, good morning, Mike.
77980	79100	How are you?
79100	79940	Good morning, excellent.
79940	80780	Thanks for having me.
80780	82780	Yeah, it's wonderful to get the chance to talk to you.
82780	84140	I'm very much an amateur in this field,
84140	85820	but I've admired your work for a long while.
85820	89500	And I can't offer you the size of audiences
89500	90940	you're used to with your TED Talk
90940	93460	and with some of the other interviews you've given,
93460	95380	but I can trade that for quality,
95380	97500	because my audience might be small,
97500	99180	but they're lovely and deeply thoughtful.
99180	101540	So I'm sure they'll appreciate your work
101540	103340	and your thinking, because it's great to have you here.
103340	105660	And I think you're probably, in nearly 200 episodes,
105660	108380	my first full-on biologist,
108380	111740	which is a gap I should have filled long ago,
111740	115540	because there's this sense that maybe the mathematicians
115540	117740	look down on the messiness of science,
117740	119300	and maybe even the physicists look down
119300	122060	on the mess of chemistry, biology.
122060	123540	But I think the hierarchy goes the other way.
123540	126940	I think biology is the harder, more challenging space,
126940	129620	whereas the mathematicians and the physicists
129620	132060	with their spherical cows can abstract
132060	133380	some of the interesting stuff away.
133380	135420	You upped your elbows in it quite often,
135420	136420	so it's great to get the chance
136420	139740	to have a biology-focused conversation.
139740	140580	Well, thank you, yeah.
140580	143700	I mean, biologists have plenty of spherical cows.
144260	147180	A lot of people talk about some of our constructs
147180	149180	as real pathways and things like this,
149180	152940	but of course, these are all imaginary kinds of constructs
152940	154540	that we do our best with.
154540	155580	Yeah, cool.
155580	157260	So this is a series of conversations
157260	160180	about what I think of as the deepest philosophical questions
160180	162340	and also the most important.
162340	164620	And they're questions of what's real,
164620	167060	really more epistemology than ontology.
167060	168740	How should we go about best understanding
168740	170300	this crazy world we all share?
170300	172740	But just as importantly, the questions of ethics
172780	174660	and within that complex field,
174660	176660	the simple question of who gets to count.
176660	178260	Who should we count as another
178260	180620	as we're thinking about how to lead a good life?
180620	181780	And I have an obvious bias
181780	183260	because this sentientism worldview
183260	185180	I'm trying to popularize and develop
185180	187460	is very pluralistic and very broad,
187460	189340	but in a sentence is evidence, reason,
189340	191140	and compassion for sentient beings.
191140	192940	So when we're answering the what's real
192940	194620	and how to understand the universe question,
194620	196140	it suggests a really broad,
196140	197780	humble, naturalistic approach
197780	199580	that uses evidence and reasoning.
199580	201420	And when it comes to the ethical scope question,
201420	202260	the clue is in the name.
202260	204180	It says that all sentient beings,
204180	206540	any being that has the capacity to experience things,
206540	208700	to flourish, to suffer should count
208700	211260	at least to some minimal regard and moral consideration.
211260	213380	I'm talking to people in this series of conversations,
213380	215100	some of whom agree and some of whom don't.
215100	217820	So it'll be interesting to see how you have gone
217820	219340	through your own philosophical journey
219340	221100	and answering those questions where you are now
221100	223780	and how that runs through the work you do today.
223780	225220	But before we get onto those big questions,
225220	226700	how would you best introduce yourself
226700	228580	for those people in my audience
228580	230700	who haven't come across your work so far?
230700	231540	Well, let's see.
231540	232740	So my name is Mike Levin.
232740	235540	I'm a professor at Tufts University.
235540	238060	I run the Allen Discovery Center here at Tufts.
238060	242660	I'm also an affiliate faculty member
242660	244460	at the Bees Institute at Harvard.
245460	247100	I do a number of other things.
247100	249420	I co-direct the ICDO,
249420	252940	the Institute for Computer Design Organisms
252940	254700	with Josh Bongard.
254700	256780	And yeah, that's me.
256780	259020	I study a range of things.
259020	260660	I mean, we'll get into all the details
260660	262860	but in my group here,
262860	266860	we do a combination of biology or biophysics,
266860	269780	mostly computer science and cognitive science
269780	271460	to understand embodied minds.
271460	272500	That's really what we do.
272500	273340	Yeah, that's great.
273340	274180	Thank you.
274180	275020	Yeah, we'll dig in.
275020	277460	So let's start with the first of these big philosophical
277460	281180	questions, the question of what's real and epistemology.
281180	282980	Quite often an interesting way into that space
282980	283820	because it's so broad.
283820	286140	It covers anything we might choose to believe
286140	287060	or have credences in.
287060	288980	But an interesting way in many of my guests
289620	291540	is to talk about their journey with respect to religion
291540	293740	and spirituality and whether they grew up
293740	296220	in a religious spiritual sort of context and household,
296220	299860	whether they held onto those types of beliefs or not,
299860	301260	and how that side of their thinking about
301260	303020	some of the sort of ultimate questions
303020	306340	of the nature of reality might have shifted since.
306340	308020	But so I don't know if you wanna wind the clock back
308020	310140	and sort of tell us your story in that space.
310140	312100	And then we could get into, I guess,
312100	315300	more of the field of science and so.
315300	316780	Yeah, yeah.
316820	319460	My background, I think you could say,
319460	322580	is not religious, but highly spiritual.
322580	327580	So I went for a few years, I went to a Hebrew day school
328260	332420	and my background from that perspective is Jewish
332420	337420	and we studied some thoughts around that whole thing.
339620	341700	And I harassed everybody with questions
341700	344580	about what happens in conjoint twinning
344620	347780	and how souls are supposed to work
347780	351620	and how they solve the problems of the hard problem
351620	353740	of consciousness and all that kind of a thing.
353740	357140	And the answers weren't terribly forthcoming
357140	358460	from that direction.
358460	363460	But in my home, I think it was always very clear
363700	366740	from the time I was very young that we had an emphasis
366740	370180	on inquiry, on asking big questions,
370180	373820	on making sure that whatever we spend energy on
373820	377500	is towards things that matter in an ethical way.
377500	380460	I was always encouraged to find things
380460	383980	that I'm passionate about and to use intellect
383980	386940	and every other tool at my disposal
386940	388180	to sort of get to the bottom of things.
388180	391860	So we had lots of deep conversations
391860	393860	about kind of the big questions
393860	396380	and how they might be addressed.
396380	398060	The question, how do you know,
398060	400620	what figure prominently in my childhood?
401500	402820	So we're always encouraged to think
402820	404100	about those kinds of things.
404100	406420	So that in the way I'm describing that naturalistic
406420	408140	epistemology of using evidence and reason
408140	409140	and sort of thinking things through
409140	411740	and that inquiry was there for quite an early age,
411740	414380	even within a family that sat within a broader
414380	418700	sort of religiously defined community and culture, I guess.
418700	422500	Yeah, yeah, but also to be clear that,
424420	428380	there are many ways of enhancing wisdom
428380	429620	or at least attempting to.
429660	433100	And so rationality is an amazing tool,
433100	436340	but one can also ask questions about its limitations
436340	438820	and what other alternatives might be on offer
438820	442020	and making sure that we understand
442020	444100	but what are the things that we're not seeing?
444100	446540	And it's sort of, there's an old saying that says,
446540	448580	show me the net with which you're fishing
448580	450140	and I'll tell you what you're not going to catch.
450140	453340	I forget who said it, but that's that being,
453340	455980	having that level of skepticism about the approaches
455980	457700	you bring to a problem, whether that be
457780	460740	different kinds of logic or whatever else,
460740	462820	that was always emphasized as well.
462820	465860	Yeah, and that if your choice of evidence
465860	468300	or your choice of methods are too narrow,
468300	469700	that can become its own dogma, as you say,
469700	473460	you've got to be able to question those choices too.
473460	475620	And part of the way I try and counter that
475620	477620	is to talk about evidence and reason
477620	479300	in a very broad sense.
479300	480860	So some people will think of that as being
480860	483020	a narrowly rational or empiric
483020	486180	or even a scientific process that doesn't count as evidence
486740	488620	until you've done a randomized control trial.
488620	490100	And I don't think that in those terms at all,
490100	493580	I think of evidence and reason in a very broad open sense
493580	496060	that can include the experience from our senses,
496060	498660	our subjective experience, you know,
498660	499660	how a weird those might be.
499660	501260	I think those are all types of evidence too.
501260	502460	We can be skeptical of them,
502460	505260	but I think that broad conception of naturalism
505260	506700	is something I'm much more comfortable with
506700	509540	than something that's really narrowly
509540	511980	scientific if you like, which can be,
511980	514740	I think narrow down too, too early.
514740	519220	And how did that sense of inquiry,
519220	521380	but a broad sense of inquiry,
521380	524180	shift your actual beliefs over time?
524180	525940	Even when you're asking the awkward questions,
525940	528940	did you still hold onto some of the supernatural beliefs
528940	530060	anyway?
530060	532700	Have those shifted over time?
532700	534580	So I guess there's probably two linked questions there.
534580	536860	How do you think about the possibility
536860	539740	of some of those supernatural constructs now,
539740	541700	gods and souls and spirits?
541700	544740	And is your sense of those still lead
544740	547300	to this inquiry and a naturalistic approach?
547300	549460	Or do you sort of reserve certain areas of knowledge
549460	551380	for different epistemologies
551380	554340	that might be more faith-based or revelatory?
555180	557580	Yeah, I mean, I think that to me too,
557580	560780	I pretty much, I think I pretty much only have one
560780	562860	supernatural belief, which is that
562860	565420	the universe is understandable in some fashion,
565420	568180	whatever that may mean to be understood
568180	571100	and that we are at least to some extent capable
571100	574540	of resonating with a fundamental principles
574540	578060	that guide its development and therefore knowledge seeking
578060	580260	and things like this are not hopeless.
580260	582940	That I fully admit is a supernatural belief
582940	585660	because that's the kind of thing you can't really get behind.
585660	587540	But once you've taken that on,
587540	590060	then everything else becomes possible.
590060	591380	So I don't think anything,
591380	594220	I can't think of anything that would be truly supernatural
594220	597220	in the sense that it might be completely outside
597220	599220	of current abilities to understand,
599220	601380	maybe beyond current scientific formalisms,
601380	604780	but also perhaps beyond our cognitive capacities.
604780	606900	So all of us are finite beings,
606900	608460	guaranteed there are going to be things
608460	610700	that we are simply not capable of comprehending
610700	612580	as well as we can comprehend other things.
612580	615140	And so beyond that, I don't think anything
615140	616660	is really supernatural.
616660	621660	I think all of us are doing our best in cobbling together
623300	627540	some kind of coherent understanding of the world
627540	628780	and our place in it.
628780	631460	And then the interesting empirical part
631460	634220	is then you get to find out how well it's working for you.
634220	636380	So not just in the narrow scientific sense
636380	638860	of specific paradigms that help you do experiments
638860	640580	and make predictions and things like that,
640580	644100	but the same idea applied to one's life.
644100	646280	And so you have various outlooks
646280	648420	that you might take on various frameworks
648420	650420	and then you have to ask yourself,
650420	652340	so how is this working out?
652340	654980	Is this helping me have a more meaningful life?
654980	658300	Is it helping me be a more ethical person
658300	661220	to have better relationships with others?
661220	662340	Those are the kinds of things
662340	664660	that are not specifically sort of scientific outcomes,
664660	666180	but the process is exactly the same.
666180	668980	You examine your framing and you ask yourself,
668980	672140	are there ways to tune that framing to do better,
672140	674020	to have a better experience with others?
674020	674860	Yeah, thank you.
674860	676740	And I quite like describing this naturalistic approach
676740	681140	as being just an attempt to honestly engage with reality
681140	683020	and an attempt to understand it.
683020	684940	And that understanding will always be partial
684940	686500	and probabilistic and provisional
686500	688500	and uncertain and open to revision.
688500	690980	But I guess that's an interesting way of putting it.
690980	693940	It's not just about, does the evidence start
693940	697380	with my hypothesis, it's also how does the application
697380	699740	of this knowledge or these beliefs actually work
699740	701300	for me in practical terms,
701300	703780	whether they're my life or engineering context.
703780	704940	So yeah, thank you.
704940	707460	Yeah, it became pretty clear early on
707460	711420	that how one looks at data or at life
711420	714780	or at anything else is a very strong determined
714820	717980	of how one is going to interpret everything that happens.
717980	722060	And these kind of frames are, they drive what happens next
722060	725340	and they drive the kinds of things
725340	727420	that become possible for you or impossible.
727420	731380	You know, they determine which things are facilitated
731380	733500	and which things are constrained.
733500	737580	And so that aspect of it being really in control
737580	742380	of how you interpret things, I think is really important.
742380	744060	Yeah, thank you.
744060	746900	And if we narrow down now, I think of, I guess,
746900	749260	the scientific pursuit as being a subset of naturalism,
749260	752620	it's the sort of a formalized way of doing that.
752620	756700	And your focus is in the field of biology.
756700	758420	And it's been, it's fascinating
758420	760820	because I think for most people with their memory
760820	762620	of the sort of high school sense
762620	764940	of what biology is involved in,
764940	769020	you've been taking the field in very different ways,
769020	773060	although some of the different ways have quite old roots too.
773060	776100	How have you come to understand biology as a field,
776100	778500	writ large, and what are the sort of distinctive angles
778500	780300	that you've been trying to develop,
780300	782860	particularly as you think about
782860	785700	one of the introductory comments on your lab's website
785700	788860	talks about this fascination with the fact
788860	792660	that all of us have gone from matter to mind in some sense.
792660	796860	Yeah, I don't really think of myself as a biologist.
796860	800100	I mean, we certainly do biology in my lab,
800140	801460	among other things,
801460	806460	but my fundamental commitment in my career and my life
807260	809940	basically has been to understand embodied mind.
809940	813100	So I've got this mind map that I print out every once a year,
813100	815020	I refresh it and print it out every once in a while
815020	816460	and it hangs in the lab.
816460	818460	And it's about nine feet wide,
818460	819900	this big kind of poster thing.
819900	820860	And in the middle of it,
820860	825380	the root node of this mind map is embodied mind.
825380	826540	That's really what I'm interested in.
826580	830060	I'm interested in cognition, intelligence,
830060	834780	and inner perspective in a wide range of diverse systems,
834780	836980	some of which we would call alive nowadays.
836980	838940	I actually spend very little time
838940	840580	figuring out a definition of life,
840580	842380	although if you want, we can talk about it,
842380	844700	but I don't worry about it too much at all.
844700	846660	I'm interested in the things
846660	849060	that all cognitive agents have in common.
849060	850980	I'm interested in the scaling of mind
850980	855820	from its most sort of primitive and humble examples
856580	857420	in the world,
857420	859420	which I don't think anybody would call alive necessarily,
859420	862260	but I think cognition is broader than life,
862260	864140	broader category than life.
864140	866980	And yeah, and that's what we're interested in now.
866980	869740	Now it just so happens that life is our best example
869740	873140	of so far of how that gets scaled.
873140	875540	So we do a lot of work in our lab
875540	878940	using the phenomenon of molecular networks,
878940	881420	scaling into cells, scaling into tissues,
881420	882820	scaling into organisms,
882820	884820	and beyond as an example
884820	887340	of how to understand collective intelligence,
887340	889460	how to communicate and ethically relate to those
889460	891380	that collective intelligence is,
891380	893780	where do the goals of those collective intelligences come
893780	895260	from and so on.
895260	898220	So biology is an excellent playground
898220	899260	for these kinds of things,
899260	902300	but I actually think the question is bigger than that.
902300	903260	Yeah, thank you.
903260	906220	And the, again, the sort of high school,
906220	907580	and when I talk about it in the third person,
907580	910140	it's really my high school sense of these things,
911140	913820	it does reflect this sense
913820	917180	that there are different scales of reality,
917180	919500	and you're interestingly trying to span them
919500	921780	and work across them and look at some phenomena
921780	924020	that may be scale free in some sense.
924020	926300	But I guess you can start,
926300	927900	you can think about the fundamentals of physics,
927900	930740	whether those are fields or fluctuations
930740	932180	in them represented as particles,
932180	935380	and you can come up through the different layers.
935380	936980	For our purposes, I guess,
936980	939300	where it starts to get useful,
939300	941740	most people would think of life as being the point
941740	944900	where we're getting into the realms
944900	946940	of considering the possibility of mind,
946940	950580	at least there are entities that are separated
950580	951740	from their environment,
951740	955300	that have some sort of evolutionary history
955300	958740	that have some form of drive to live,
958740	960140	but you've hinted there already,
960140	962900	you don't necessarily find the concept of life
962900	964100	that interesting,
964100	968780	but then you can move through simple types of life
968780	972340	in the earlier evolutionary stages,
972340	974420	but also in the degree of complexity as well.
974420	977740	So in our current panoply of living beings,
977740	980980	very simple single-celled organisms,
980980	982580	plants and fungi,
982580	985300	and then it feels intuitively like we take another step
985300	987420	on the cognition path
987420	989980	when we're starting to think about animals as well.
989980	993100	So as we're sort of working across that boundary
993100	996660	from non-life to very simple life
996660	999740	through to plants, fungi, and the simplest animals,
1000660	1005340	where do you see this idea of cognition emerging?
1005340	1006620	Where did it come from?
1006620	1008220	And I guess, what is it?
1008220	1009380	But as one of the things I find interesting
1009380	1011220	in at least your public writing
1011220	1012820	is that sometimes it does feel like
1012820	1014780	there's a little bit of slippage in the term
1014780	1017940	because sometimes cognition feels like
1017940	1020940	something that's more narrowly computational.
1020940	1022740	You know, it's something that maybe my spreadsheet
1022740	1024140	on a laptop could be doing,
1024140	1026380	but sometimes there is an implication of mind
1026380	1029780	and a subjective perspective
1029780	1031420	in the way you talk about cognition as well.
1031420	1034020	So I should ask a better question than that,
1034020	1038340	but in that sort of space of simpler living organisms,
1038340	1041260	how does cognition emerge and what do you think of?
1041260	1043380	It is in its simplest terms.
1043380	1047060	Yeah, so here's how I think about these things.
1049580	1053020	All of these cognitive claims, in other words,
1053020	1056100	where you think something is on the spectrum of cognition,
1056340	1057820	how much mind and all of that,
1057820	1060820	I don't think these are terms describing particular systems.
1060820	1062300	I think these are terms describing
1062300	1064620	our intended relationship to them.
1064620	1067860	So I don't think any of this is about the system itself.
1067860	1070380	It's when you make a cognitive claim about something,
1070380	1073340	you say this system is at the level of whatever,
1073340	1074340	which you're really telling me
1074340	1076740	is an engineering interaction protocol.
1076740	1079420	You're telling me what your viewpoint on that system is
1079420	1080820	and that viewpoint is gonna determine
1080820	1082180	how you interact with it.
1082180	1084660	So I'll give you a simple example.
1084660	1088180	People argue all the time about whether humans are machines.
1088180	1089860	And now this is a long conversation
1089860	1091020	because you have to define machine,
1091020	1092180	you have to define human and all that,
1092180	1095500	but if you have an orthopedic surgeon
1095500	1098300	who does not believe you are a machine, you're in trouble.
1098300	1100740	You need to find a different orthopedic surgeon.
1100740	1102900	If you have a spouse or a psychotherapist
1102900	1105420	who thinks you're a simple machine, you're also in trouble.
1105420	1109100	Not a great fit there.
1109100	1111100	There are plenty of supposed doctors out there
1111100	1113180	who think you're a fluctuation in the cosmic
1113220	1115700	on some wide vibrations, so yeah.
1115700	1118340	Yeah, yeah, I mean, so my framework,
1118340	1120060	so I'm working on this framework called TAME,
1120060	1122500	T-A-M-E, Technological Approach to Mind Everywhere.
1122500	1125020	And one of the main claims of this framework
1125020	1129260	is that none of these things can be determined
1129260	1130580	from a philosophical armchair.
1130580	1132260	You can't just decide what things are,
1132260	1133420	you have to do experiments.
1133420	1136220	So if you think you're a quantum fluctuation,
1136220	1138300	whatever, whatever, that's great.
1138300	1140900	It's all open, it's a fine hypothesis.
1140900	1142700	What has it done for you, right?
1142700	1143860	Like what are the benefits?
1143860	1146580	And so I think this is the difference
1146580	1149060	between this kind of pluralistic view that I have
1149060	1151740	where multiple observers can differ
1151740	1154500	as to their assessment of any given system.
1154500	1156180	That's what I believe,
1156180	1158140	but it doesn't mean that anything goes
1158140	1161220	because those observers can then compare,
1161220	1163600	well, how well did that worldview work out for you?
1163600	1165060	What has that enabled you to do?
1165060	1167180	What has that enabled you to discover?
1167180	1170340	How rich are your relationships with the various systems
1170340	1171980	given the view that you have?
1172420	1174380	So what you wanna do is you wanna get it right
1174380	1175500	or at least optimize it.
1175500	1176860	You don't wanna have false negatives
1176860	1180500	where you attribute cognitive qualities to systems
1180500	1183980	that where they don't give you any new purchase.
1183980	1188980	So for example, kind of old school animist ideas
1190100	1191740	where there's a spirit in every rock,
1191740	1194700	it's a fine hypothesis, how has that worked out?
1194700	1195900	What does that do for you?
1195900	1197580	You need to do experiments and you need to show that,
1197580	1199980	hey, by saying that this thing has goals,
1199980	1201960	it has learning capacity, it has whatever,
1201960	1203420	this is now what I'm able to do.
1203420	1207320	I'm able to either make better prediction and control
1207320	1211360	or we're having a more richer interpersonal experience
1211360	1212200	or something.
1212200	1215100	So all of these things need to be empirically testable.
1215100	1220100	So in this framework, your spreadsheet may or may not
1220760	1224360	be doing some of the things that are tractable
1224360	1226520	using the tools of cognitive science,
1226520	1229080	for a spreadsheet probably not, but you'd be surprised.
1229080	1231120	The thing about treating these things
1231240	1233200	as empirical questions, not philosophy,
1233200	1234880	is that you are often surprised,
1234880	1236800	which is what is good about science,
1236800	1239200	is that when you were surprised,
1239200	1241000	that that's an opportunity to learn.
1241000	1244480	And so what I think all of these cognitive claims really are
1244480	1248080	are hypotheses about which set of tools
1248080	1249040	am I going to apply?
1249040	1251280	So am I going to apply the tools of physics
1251280	1252280	and simple engineering?
1252280	1254760	Am I going to apply the tool of cybernetics
1254760	1256800	and control theory, the tools of behaviorism
1256800	1261800	and learning and training and things like that,
1261840	1265640	or the tools of communication and psychoanalysis
1265640	1267480	and love and all these other things.
1267480	1270080	So the thing is that when you treat that
1270080	1272960	as an empirical question, you get to do experiments
1272960	1273800	and you get to be surprised.
1273800	1278640	So for example, we have found that very simple systems
1278640	1281000	that represent gene regulatory networks,
1281000	1283260	so just small numbers of chemicals
1283260	1285000	that turn each other on and off, that's it.
1285040	1290280	No cell, no indeterminism, no magic,
1290280	1293040	just differential equations of describing
1293040	1295360	how genes turn each other on and off.
1295360	1298080	That system, which most people would assume
1298080	1300560	is has zero cognition, they would say,
1300560	1303160	well, that's a very mechanical, it's justice.
1303160	1304920	As people say, it's just obeying the laws
1304920	1306640	of physics and chemistry.
1306640	1307840	That turns out-
1307840	1309360	There's a lot in that, just.
1309360	1312560	Yeah, right, I mean, I really hate that framing,
1312560	1314200	but that's what people often say.
1314200	1316160	That system by itself is capable
1316160	1317480	of six different kinds of learning,
1317480	1319880	including Pavlovian conditioning, just there.
1319880	1321120	So with nothing else.
1321120	1324800	We've also done work on sorting algorithms.
1324800	1328400	So these are extremely simple, deterministic,
1328400	1330320	fully transparent algorithms that people
1330320	1331680	in computer science have been studying
1331680	1334360	for, I don't know, 60 years or longer,
1334360	1335800	things like bubble sort and so on.
1335800	1339200	Even those things, when you probe them the right way,
1339200	1341600	show novel problem-solving capacities
1341680	1345000	and behaviors that are not in the algorithm themselves.
1345000	1347880	So what I am taking from all of this
1347880	1350720	is that we really need a sense of humility
1350720	1352680	about what things can do
1352680	1356640	and what kinds of tools are best appropriate for them.
1356640	1357480	You don't know.
1357480	1358880	We are not good at guessing.
1358880	1361480	We think we are, and people assume this all the time,
1361480	1362640	but we're not good at guessing.
1362640	1364080	And so we need a mature science.
1364080	1367160	So this is, if I had to pick one field
1367160	1369360	that I think I work in, it's diverse intelligence research.
1369360	1370400	That's what I think we do.
1370960	1372920	We are trying to develop principle frameworks
1372920	1377720	for really knowing which kinds of cognitive tools,
1377720	1379680	which scale of cognitive tools are appropriate
1379680	1381160	for various systems.
1381160	1384800	And we're just not very good at guessing
1384800	1385760	from the beginning.
1385760	1386600	Yeah, thank you.
1386600	1389320	And intelligence, I think, again,
1389320	1392440	you can spend three hours talking about definitions of it,
1392440	1394200	but I think many people would talk about it
1394200	1397560	in simple terms as being the capacity to solve problems,
1397560	1399400	which is something that could be done
1399400	1402880	without mind and without subjectivity
1402880	1404360	and without feeling,
1404360	1408800	whereas cognition or maybe, again,
1408800	1411440	you're gonna tell me that these distinctions are
1411440	1415000	maybe not even well posed.
1415920	1418680	Yeah, so let's break it down a little bit.
1418680	1420920	So intelligence, I agree with you
1420920	1422640	that a good definition of intelligence
1422640	1424080	has to do with problem solving.
1424080	1425720	Now, I'm not claiming that problem solving
1425760	1428280	encompasses everything that's interesting about cognition.
1428280	1432160	There are other things that are not about problem solving,
1432160	1433920	but problem solving is good
1433920	1435640	because it's publicly observable.
1435640	1437760	It's a good scientific thing to study.
1438640	1443280	And it's about competency in navigating some problem space.
1443280	1445400	And there are many tools and tricks
1445400	1449160	that the system can use to navigate that problem space.
1449160	1452360	Now, the thing about inner perspective is this,
1452360	1455120	which is, and at this point,
1455120	1457960	I'm not talking about the hard problem of consciousness.
1457960	1459600	We can sort of talk about that separately,
1459600	1462960	but here's the thing about inner perspective.
1462960	1464080	It's not a binary.
1464080	1466600	I don't think any of these categories are usefully binary.
1466600	1469800	What I think is important about inner perspective is this.
1469800	1471200	For any kind of system,
1471200	1473440	you want to be able to answer the question,
1473440	1477160	how important is the system's perspective onto the world
1477160	1478760	for me to understand what's happening?
1478760	1480880	So let's make a, let's do, we have a simple example.
1480880	1483560	I suppose you have a bowling ball on a hilly landscape.
1483560	1484880	So you've got this energy landscape,
1484880	1487000	you've got bumps and valleys and you've got a bowling ball.
1487000	1489400	If you want to know what that bowling ball is going to do,
1489400	1492320	your view as a third party observer to this
1492320	1493880	as an external observer,
1493880	1496720	your view of the landscape tells the whole story.
1496720	1497600	Okay, there's nothing more.
1497600	1498720	You don't need anything else.
1498720	1501760	You will have everything you need to know
1501760	1502920	to predict what's going to happen
1502920	1505160	from your external view of the landscape.
1505160	1506000	By the way-
1506000	1508040	You don't need to imagine what it's like to be the ball.
1508040	1510360	Well, that's the next step.
1510360	1512320	That's the next step, which is that
1512320	1513520	if you want to now know
1513520	1515680	what a mouse is going to do on that landscape,
1515680	1517040	your view of that landscape
1517040	1519240	isn't really very interesting at all.
1519240	1520960	The important thing, and it's not predictive of much,
1520960	1523240	the important thing is the mouse's view of that landscape,
1523240	1526080	because if it has an internal representation
1526080	1529720	of the valence of different portions of that landscape,
1529720	1530920	so rewards and punishments
1530920	1532120	and which things are important to it
1532120	1533720	and what attention it's paying and all that,
1533720	1536960	the inner landscape of the mouse is the actual landscape
1536960	1538760	that's going to determine what happens next,
1538760	1540480	not your view of the landscape.
1540480	1543840	So different kinds of systems
1543840	1546320	have different degrees of representation
1546320	1547480	of their outside world.
1547480	1549720	It's not just brainy, smart animals that do this.
1549720	1552240	All systems represent the world to some extent.
1552240	1553680	And the question is how much?
1553680	1556800	The question is how much do I need to worry about?
1556800	1559800	And one way to sort of quantify this
1559800	1562960	is in terms of the size of the cognitive light cone.
1562960	1565160	So you can sort of ask for any given system,
1565160	1567480	if you were to draw a space time,
1567520	1569080	it's sort of a butchering of Minkowski's
1569080	1570600	space time cone diagrams,
1570600	1573480	you can draw a little diagram that says,
1573480	1576400	what are the events both back in time and forward,
1576400	1577760	because some systems anticipate,
1577760	1580760	so both back in time and forward in time and spatially,
1580760	1582200	what are the things you need to know
1582200	1585800	to have a really rich relationship with the system,
1585800	1587760	meaning prediction, control,
1587760	1588920	something that benefits you,
1588920	1592120	and in some cases, something that's ethical and all that.
1592120	1593000	What do you need to know?
1593000	1596120	So for a bowling ball, the cognitive light cone is tiny,
1596120	1597640	because everything you need to know is right there.
1597640	1599240	You add up all the pushes and pulls on it,
1599240	1602000	you're more or less done.
1602000	1605640	But once you start entering the systems
1605640	1607240	that are even as simple as a collection
1607240	1609200	of genes regulating each other,
1609200	1611080	that's no longer satisfactory,
1611080	1612920	because they learn from experience
1612920	1614320	and things that have happened before
1614320	1616880	are gonna make huge differences to what happens next.
1616880	1619520	You cannot gain a full understanding of what's happening
1619520	1621040	or to gain good control
1621040	1622880	without understanding their inner perspective.
1622880	1627320	So I think inner perspective is something
1627320	1629840	that to some degree is wider than biology.
1629840	1631520	I think what biology is really good at
1631520	1634400	is scaling up these cognitive light cones.
1634400	1637440	So in a rock, the cognitive light cone of the pieces,
1637440	1638920	which by the way is not zero, it's very small,
1638920	1640280	but I don't think it's zero,
1641440	1644040	is not really summed up in the rock.
1644040	1645680	The rock has exactly the same level
1645680	1647320	of cognitive light cone as its pieces,
1647320	1649400	but biology is super good.
1649400	1650240	To say it another way,
1651160	1653640	we call living things any system
1653640	1655960	that's good at scaling up the cognitive light cone
1655960	1658800	of its parts, it's going to look alive to us.
1658800	1660520	And just the final kind of thing,
1660520	1663120	which we'll probably get to again later
1663120	1665760	in terms of what kind of world we want to live in,
1665760	1669520	I think that evolution has no monopoly
1669520	1671920	on producing cognition.
1671920	1673080	In other words, up until now,
1673080	1674800	yes, that's probably, at least on Earth,
1674800	1676960	that's probably mostly where cognition came from,
1676960	1680720	is from the fumblings of mutation of selection
1680720	1682320	and of some other things.
1682320	1684520	But I don't think intrinsically,
1684520	1687040	that's where cognition has to come from.
1687040	1688760	I don't see any reason whatsoever
1688760	1692600	why the rational efforts of other cognitive agents,
1692600	1697160	such as ourselves, couldn't make new minds going forward.
1697160	1698160	Yeah, thank you.
1698160	1699560	Yeah, we get to dig into that.
1699560	1703680	And the point you mentioned about the approach to genetics
1703680	1705360	is one of the things that you've helped
1705760	1706960	radicalize this view,
1706960	1710480	this simplistic view that DNA is some form of blueprint
1710480	1713280	where you programmatically and linearly follow it.
1713280	1714600	And that's one of the things
1714600	1717400	as I understand your work has radically opened up.
1717400	1718600	It's nowhere near that simple.
1718600	1721480	It's much more about systems interacting
1721480	1723880	and memory can be held in different forms and so on.
1723880	1727720	So yeah, it's broadened out that view.
1727720	1730320	And as we're sort of moving further up
1732040	1733960	the scale, if there is such a scale,
1734960	1737440	one of the things I've heard you resist before
1737440	1739120	as you are here in a way
1740480	1742840	is this idea of really clear binary concepts,
1742840	1745560	concepts like sentience and consciousness
1745560	1750160	that try to take ideas like cognition
1750160	1755000	and map them onto this intuitive sense that we have,
1755000	1759000	that we are ineffable, distinct,
1759000	1762320	somehow unique entities
1762320	1764680	that feel like we're separate.
1764680	1765960	We're not just physics.
1765960	1769920	And I empathize with that resistance
1769920	1773480	because I think there's a danger in that intuition
1773480	1777800	that we reify these ideas
1777800	1780560	because they're obviously important to us intuitively.
1780560	1782240	I can understand why anyone's consciousness
1782240	1783080	will be important to them.
1783080	1784520	Ultimately, it's all they experience, right?
1784520	1786360	And everything we experience comes through the consciousness.
1786360	1788480	But there's a danger in reifying that,
1788480	1790320	you take it away from just being physics
1790320	1791920	because ultimately I think I share your view
1792680	1794480	that just physics,
1794480	1797560	we are all just part of the natural world all the way down.
1797560	1799240	That doesn't mean these aren't interesting concepts,
1799240	1802560	but they're not distinct from physical reality.
1804480	1806320	But at the same time,
1806320	1809600	I prefer not to put them completely to one side.
1809600	1813240	And I think in the way you're describing,
1813240	1816240	needing some sort of research concept
1816240	1820840	or some concept of relationality
1820880	1823680	can still provide at least a couple of reasons
1823680	1826040	why it's important to still focus on ideas
1826040	1827600	like sentience and consciousness.
1827600	1828800	And I guess one,
1828800	1831320	it came partly through my conversation with Mark Solms,
1831320	1833080	who I know you spent a lot of quality time with.
1833080	1835000	I've loved some of your discussions
1835000	1840000	because part of the way he tells the story about evolution
1840040	1841600	is that sentience,
1841600	1844440	the capacity to actually experience a valence
1844440	1846520	is one of the things that's probably driven
1846520	1850200	the process of broader cognition
1850200	1852520	and evolution in the first place.
1852520	1857200	So he puts that concept or the ability to feel things,
1857200	1859080	feel good, feel good, bad,
1859080	1862600	how am I doing now in this environment as quite central?
1862600	1865280	And I guess that's the way I think of sentience
1865280	1867240	as being just that capacity to have an experience
1867240	1871280	and to value it from yourself, whatever yourself is.
1871280	1872560	But I guess another reason,
1872560	1874760	another potential research project
1874800	1876360	links to our next question,
1876360	1878640	which is that these things also seem to have
1878640	1883640	some quite deep moral or ethical significance too,
1883840	1886360	in that, you know, and we'll come back to that.
1886360	1887720	But I guess those are two of the reasons
1887720	1890560	why those sometimes problematic concepts,
1890560	1895200	and I certainly don't think they're binary in any sense.
1895200	1898760	There's still a drive for us to understand and dig in.
1900240	1901800	What do you think about those sorts of challenges about,
1901800	1903560	you know, is there a,
1903560	1905320	because you could go to a point of view
1905320	1909320	where you never talk about sentience and consciousness
1909320	1913320	or subjective experience in those senses at all,
1913320	1916480	and you stick purely with a more neutral description
1916480	1921480	of cognition and agent spaces and Markov blanket.
1922760	1927360	Do you feel that there is some meaningful pull
1927360	1930200	to delve into and better understand those ideas
1930200	1932120	of sentience and consciousness in their own right,
1932120	1932960	or how do you think of this?
1933800	1936520	Well, I think those are essential.
1936520	1941520	My resistance to binary categories is not to,
1941880	1945360	you know, kind of reduce these aspects
1945360	1946720	that you're talking about at all.
1946720	1949280	It's to, on the contrary,
1949280	1951640	it's to have a better understanding of them
1951640	1952760	and their potential.
1952760	1955680	You know, I get a lot of pushback from both directions.
1955680	1957960	So I get mechanistic, you know,
1957960	1961520	sort of supposedly reductionist scientists who say,
1961560	1962640	well, this is crazy.
1962640	1966520	You're painting feelings onto cells
1966520	1970560	and chemistry is the best kind of explanation.
1970560	1972000	You know, and that's not really reductionist
1972000	1974080	because then if you say, well, you mean quantum foam,
1974080	1975280	you want to talk about quantum foam,
1975280	1976880	they say, nah, nah, nah, that's not it.
1976880	1978280	It's chemistry, it's got to be chemistry.
1978280	1981480	So they've picked the level, okay.
1981480	1985120	But I also get a lot of flak from the organists,
1985120	1987320	which, and I consider myself in the organist tradition,
1987320	1990840	but who say, look, by putting non-living things
1990840	1993520	on the other side, such as physical objects
1993520	1994880	and computers and whatnot on that,
1994880	1996480	somewhere on that spectrum,
1996480	2001160	you're undermining this battle that we've had
2001160	2004160	for hundreds of years to preserve the magic
2004160	2007520	and the importance of life and of inner perspective
2007520	2008360	and so on.
2008360	2010040	I don't think understanding these things better
2010040	2013840	and understanding how they scale up reduces the importance
2013840	2018840	or the majesty of the obvious sentience of living beings.
2018920	2021240	I think much like with any kind of science,
2021240	2023000	it helps us to understand what we are
2023000	2025560	and what our potential is and what we need to do.
2025560	2029880	I think that this weird obsession with chemistry
2029880	2034880	and with physics too is what undermines the efforts
2035680	2036760	to really understand this.
2036760	2040560	And I'll give you a simple example, well, two examples.
2040560	2045360	One is, I often hear people say this,
2045400	2050040	that's not real goals,
2050040	2054160	real preferences, real valence, real anything.
2054160	2056840	That's just, it's just following the laws
2056840	2058040	of physics and chemistry.
2058040	2058880	Well, guess what?
2058880	2062120	If you were to zoom in to your brain
2062120	2064000	or the rest of your body, guess what you would find?
2064000	2064840	You wouldn't find fairies,
2064840	2067160	you would find physics and chemistry.
2067160	2068000	So it's very-
2068000	2069040	And even if you found fairies,
2069040	2070440	they'd be following the laws of physics too.
2070440	2072640	They would have to be following something, right?
2072640	2076040	So I'm not against, if you have a model of,
2076040	2077440	people sometimes email me,
2077440	2078400	well, what about the soul?
2078400	2079360	I say, bring it on.
2079360	2082240	If you've got a model of the soul,
2082240	2085840	explain how that works and how that solves these problems
2085840	2087040	and we're good to go.
2087040	2089000	The problem is, I've never seen such a model,
2089000	2092240	but the question, I always bring it back
2092240	2095800	to the paramecium or a single cell.
2095800	2097920	Do you or do you not believe that that thing has
2097920	2101720	to some small extent a preference about what happens?
2101720	2106520	If you do, then we simply point out that,
2106520	2108560	well, look, it's very clearly made
2108560	2111120	of a set of interacting chemicals.
2111120	2112800	At some point we'll be able to reconstitute one.
2112800	2114280	So what's the issue?
2114280	2116360	If you don't, then you have to explain to me
2116360	2118120	what happens in embryonic development,
2118120	2120360	where you actually go very slowly
2120360	2123480	and gradually from a single cell
2123480	2125440	into whatever it is that we are.
2125440	2127480	And again, there is no magic lightning flash
2127480	2129840	that converts the chemistry of the oocyte
2129880	2133120	into the mind of the adult human.
2133120	2135800	So this continuity, you can't escape it.
2135800	2138640	What we owe is not a story about magic of bright lines,
2138640	2140480	we owe a story about scaling.
2140480	2144440	And the other thing that I think is really curious
2144440	2148680	and it's kind of, I don't know if it's my bringing
2148680	2150240	with too much science fiction or what,
2150240	2151880	but I find it really amazing.
2151880	2153680	There was a great scene in,
2153680	2156160	there's a movie called Ex Machina, you know?
2157160	2158960	And there's a great scene in that movie
2158960	2163800	where the protagonist is now so confused by this AI
2163800	2164920	that he's been dealing with it.
2164920	2166200	He's standing there in front of a mirror
2166200	2168760	and he starts cutting his hand because his arm,
2168760	2171320	because he wants to see if he is a robot too, right?
2171320	2172800	And it's very important to him.
2172800	2177240	So this is critical to him, it's very stressful.
2177240	2179840	And I get emails all the time also from people who say,
2179840	2182200	I've read your paper, I understand now
2182200	2185160	that I'm a walking bag of cells, now I'm depressed.
2185160	2187880	I don't know what to do with myself, this is terrible, right?
2187880	2191280	And let's just unpack this, this cutting your arm thing.
2191280	2195200	So what that means is, if you were to find,
2195200	2196360	so you cut open your arm
2196360	2198240	and you find a bunch of cogs and gears,
2198240	2200360	you've had, I don't know, 40, 50,
2200360	2203800	however many years of experience in your own skin,
2203800	2207800	being an agent, exerting effort towards various outcomes
2207800	2211040	and having moral quandaries and having, you know,
2211040	2212720	Qualey and all these things.
2212720	2214760	And when you see those cogs and gears,
2214760	2218360	what you're gonna decide is, none of that was real
2218360	2220560	because I am committed to the idea
2220560	2222800	that cogs and gears can't support it.
2222800	2224760	This is so bizarre to me.
2224760	2226800	And it's bizarre because we don't know
2226800	2228960	what cogs and gears can and can't support.
2228960	2232440	You know, why are you so attached to a protoplasm
2232440	2235280	and proteins and whatever else is inside you
2235280	2237920	over something else that you might find?
2237920	2239920	What do you think you know about those things
2239920	2243200	that overrides your primary experience as a human?
2243200	2245080	It's just, it's amazing to me
2245080	2248520	that what people naturally tend to say is,
2248520	2251480	okay, well, then I guess I'm not real, I'm not important,
2251480	2254080	I can't do all of the amazing things I was going to do
2254080	2256320	versus, wow, I guess I just learned something great
2256320	2258440	about cogs and gears, look at that.
2258440	2260200	You know, I guess cogs and gears can do it,
2260200	2262880	not too much more shocking than finding out the proteins
2262880	2265640	and, you know, and carbohydrates and whatever else
2265640	2267040	is in our bodies can do it.
2267040	2269000	Yeah, and neurons firing, it's like.
2269000	2271880	Yeah, yeah, but people are so committed
2271880	2276400	to simple, well, to two things, to, first of all,
2276400	2279720	to the idea that if your parts obey the laws of physics,
2279720	2282680	then you are somehow reduced, which I think, you know,
2282680	2285200	this allegiance to a low level of description,
2285200	2286720	I think it's completely arbitrary.
2286720	2289000	Dennis Noble does a really nice job in his work
2289000	2293560	on against privileged levels of causation and things like that.
2293560	2298080	And then the idea that we know what various kinds
2298080	2300000	of materials and architectures can do,
2300040	2302120	we have absolutely no idea.
2302120	2305440	You know, we need, this actual field is at a,
2305440	2308920	despite the rest of science is at a very young stage.
2308920	2310920	We do not know, there are emergent,
2310920	2312360	not just emergent complexity,
2312360	2314480	so everybody studies emergent complexity,
2314480	2315640	that's been around for a long time.
2315640	2317000	It's not emergent complexity here,
2317000	2320520	it's emergent goal-directedness and emergent cognition.
2320520	2322840	And that happens and even in very simple systems,
2322840	2324520	it surprises us constantly.
2324520	2325880	We are not good at predicting it,
2325880	2328200	we are not good at creating it yet.
2328200	2331400	Well, I should say we may create it unwittingly all the time.
2331400	2333120	And so people who say, you know,
2333120	2336080	I know what this is because I made it,
2336080	2338560	I think that's a really dangerous idea
2338560	2340880	because you don't know what something is
2340880	2342880	just because you made it or because,
2342880	2345040	people say this a bunch of language models or whatever,
2345040	2347480	just because you know the parts that went into it,
2347480	2349720	we do not yet know what it is, what it can do
2349720	2351960	and how important is the inner perspective
2351960	2353960	and what kind of inner perspective it has.
2353960	2357960	So yeah, I think a lot of humility here
2357960	2360920	is needed and a letting go of this idea
2360920	2363800	that the right level of description is chemistry.
2363800	2366200	And you know, I think it's fine that that's there,
2366200	2369360	it does not tell the whole story in any practical way.
2369360	2370200	Yeah, thank you.
2370200	2372360	You need to understand that these things run
2372360	2375840	and operate at different levels and interlocking levels.
2375840	2379560	Well, just very specifically,
2379560	2383720	the business of physics and determinism, right?
2383720	2385600	One of the key issues here is that
2385600	2387920	determinism is well and good
2387920	2390920	if what you're interested in doing is looking backwards.
2390920	2392480	So something has happened
2392480	2394880	and you're going to tell a mechanistic story
2394880	2395720	of why it happened.
2395720	2396640	And then you can always do that,
2396640	2397480	that's always on the table.
2397480	2399080	So you zoom down and you say, look,
2399080	2401760	this person did that because these neurotransmitters
2401760	2403920	zigged and zagged and they did that
2403920	2406960	because of the electron forces and all of this stuff, right?
2406960	2409680	You can always tell a story going backwards.
2409680	2411240	But that isn't what we're interested in,
2411240	2413120	both as humans and scientists,
2413120	2414600	we're interested in going forwards
2414600	2417080	as in what can and should I do next
2417080	2418440	and what can I invent
2418440	2421240	or how can I increase my understanding next?
2421240	2423320	And that is a completely different kind of task.
2423320	2426120	So here's one of my favorite examples.
2426120	2429120	The game of life, cellular automaton, right?
2429120	2432480	So you've got three simple rules that dictate
2432480	2435640	how the state of each cell is going to be on or off
2435640	2437160	based on what its neighbors do.
2437160	2438000	Okay, so just-
2438000	2439800	It's a simple two-dimensional grid, isn't it?
2439800	2441440	Completely simple, yep.
2441440	2443320	Super simple, two-dimensional grid
2443360	2446960	the cells are on or off and it's fully deterministic.
2446960	2448720	Okay, there's not even an ecstasy here.
2448720	2451200	So every cell in every tick of the clock,
2451200	2453840	each cell becomes on or off
2453840	2455240	based on how many neighbors it has.
2455240	2456080	That's it.
2456080	2458960	Now, we know, and if anybody in the audience
2458960	2460520	hasn't seen it, look it up
2460520	2462920	and you can see these amazing things that happen, right?
2462920	2465040	So emerging complexity is very strong here.
2465040	2466200	And if anyone hasn't played with it,
2466200	2468120	I'd recommend go and find some of the online tools
2468120	2470160	because you can play with this stuff yourself.
2470160	2471440	It's mind-blowing, yeah.
2471440	2473320	Absolutely, absolutely amazing.
2473320	2477800	And so now, look, you can imagine being a reductionist
2477800	2479600	determinist about this world and say,
2479600	2481360	so for example, one of the things that happens
2481360	2483280	in this world is there are things called gliders.
2483280	2486200	So gliders are patterns that are a particular shape
2486200	2487600	and the shape moves across.
2487600	2490120	Now, to be clear, nothing actually moves across,
2490120	2492120	the cells are just turning on and off,
2492120	2494560	but the pattern itself, it's like a wave in the,
2494560	2497400	the pattern itself moves and those are called gliders.
2497400	2500280	So now you could be a reductionist about this
2500280	2501960	and you can say, look, there are no gliders.
2501960	2503760	All there is are the individual cells
2503760	2505480	and I can tell you precisely which cells
2505480	2506640	are gonna come on and off.
2506640	2508360	And the fact that you think you see gliders
2508360	2510440	is an epiphenomenon, it does nothing.
2510440	2511720	In the system, there are no gliders,
2511720	2513680	all it is is the rules.
2513680	2515240	And that isn't exactly wrong
2515240	2517400	because the physics of the world are quite clear,
2517400	2519680	but it's absolutely limiting in the following way.
2519680	2521640	If you don't believe in gliders,
2521640	2525360	you can predict the next state of whatever state
2525360	2526400	I set up in the game,
2526400	2528520	you can tell me exactly what's gonna happen next.
2528560	2530480	There's no escape from that level of determinism.
2530480	2531600	But here's what you won't ever do.
2531600	2533360	You won't ever build a Turing machine
2533360	2535280	made out of gliders as somebody did.
2535280	2537720	Somebody designed a pattern that does computations
2537720	2539840	by sending gliders back and forth.
2539840	2541840	If you don't believe in gliders, you're not gonna do that.
2541840	2544480	It closes off that level of inventiveness.
2544480	2548160	So looking, so a key thing about these higher levels
2548160	2549880	is that they enable you to have a more,
2549880	2553400	a richer relationship with the system going forward,
2553400	2556000	not just explain what happens backwards
2556000	2557640	after somebody's done the interesting work
2557680	2559360	of preparing a system for you.
2559360	2560680	Yeah, it's fascinating.
2560680	2562800	And the idea of a universal Turing machine
2562800	2566560	is essentially a computer
2566560	2568840	that can carry out any computation,
2568840	2570400	given enough time and enough resources.
2570400	2573320	So, and this is from individual cells,
2573320	2576600	linking on and off based on a super simple rule set
2576600	2578040	clicking forward all the time.
2578040	2580800	And the other, and I don't know if this is right,
2580800	2584800	but I like the difference between the side of determinism
2584800	2586080	looking backwards and looking forwards,
2586080	2587080	because in a sense,
2587080	2590280	it's the same deterministic mechanism going forwards.
2590280	2592280	Yeah, but for it to be useful,
2592280	2593640	we need to actually shortcut
2593640	2597240	whatever that deterministic computation is going to be
2597240	2599120	for us to be able to predict.
2599120	2601520	And to do that, we need to understand patterns
2601520	2602520	at different levels.
2602520	2604480	And sometimes we can't do it.
2604480	2607840	You know, sometimes the thing is computationally irreducible
2607840	2611480	such that the only way of finding out what's gonna happen
2611480	2612840	is to let the process run
2612840	2615160	or to create a simulation that's so perfect.
2615160	2617360	You basically just duplicated reality, right?
2617360	2621920	So, so even if it's conceptually deterministic in the future,
2621920	2624040	that doesn't necessarily help you anticipate
2624040	2626880	and the idea of these high level concepts,
2626880	2628400	as you said, give you useful tools
2628400	2631640	and your relation to these phenomena to, you know,
2631640	2634280	anticipate maybe the future and understand the past.
2634280	2636160	Yeah, and control what happens next.
2636160	2638400	So, so as a simple, and some of these systems,
2638400	2639880	the cool thing about living
2639880	2642960	and other kinds of systems of this type
2643000	2645240	is that they offer this kind of shortcut.
2645240	2646680	So, so here's a simple example.
2646680	2648160	Imagine that you had a rat,
2648160	2650520	then you wanted him to do a simple circus trick.
2650520	2652640	You know, I don't know, sit on a little bicycle or something.
2652640	2653960	One thing that you might do
2653960	2656240	from the level of chemistry and physics is you might say,
2656240	2659040	okay, so I want the muscles to move in this particular way.
2659040	2661040	I need to calculate which neuronal impulses
2661040	2663040	are gonna move exactly these muscles to do it.
2663040	2665380	I need to trace it back into the brain, figure out
2665380	2667960	all the circuits, how, how everything is gonna
2667960	2669400	propagate through the brain and figure out
2669400	2671560	which pixels on the retina I need to stimulate
2671560	2674080	with various images, you know, shown to the rat
2674080	2675480	to get him to get on the little bicycle.
2675480	2677720	Okay, if you try to actually calculate,
2677720	2680000	so that's completely computationally intractable.
2680000	2682240	If you try to do that, the sun will burn out
2682240	2684360	long before you actually get it done.
2684360	2686400	But there's an amazing thing here,
2686400	2688600	which is that you can just train the rat.
2688600	2690960	And that's because the rat has a particular
2690960	2694160	cognitive causal architecture that hides all that stuff.
2694160	2696560	And it takes on all the complexity of figuring out
2696560	2700960	how should my internal parts be arranged
2701000	2702240	in order for meaning,
2702240	2703560	meaning all the different neurotransmitters
2703560	2705640	and everything else, how should that all be arranged
2705640	2707560	in order to achieve a particular goal?
2707560	2710840	So the way you do this is you get the buy-in of the rat.
2710840	2712720	You make your goal, the rat's goal,
2712720	2715400	and then the rat does all the hard work for you.
2715400	2717780	You don't have to calculate all this stuff forward.
2717780	2721240	So one of the things that understanding these,
2721240	2724280	the large scale capabilities of your system
2724280	2728040	is critical in having a productive interaction,
2728160	2731120	a predictive, powerful productive interaction going forward.
2731120	2733160	And this is something that I think is the rate limiting
2733160	2736000	step right now for regenerative medicine.
2736000	2739760	Because in biology and biomedicine,
2739760	2742000	the standard operating assumption is that cells
2742000	2743240	are mechanical agents.
2743240	2745040	All the excitement is about the hardware.
2745040	2749240	So CRISPR, genomic editing, pathway rewiring,
2749240	2751460	everything is down at the level of hardware.
2751460	2754920	And that closes off a huge number
2754920	2757800	of potentially really powerful interventions
2758400	2761240	which we're doing in our lab like cellular training,
2762320	2764360	exploiting cellular problem solving,
2764360	2767520	because if you insist on viewing systems
2767520	2770040	from that low level perspective, not that it's wrong,
2770040	2771400	it's, I mean, that perspective is there.
2771400	2774000	It's there for you to take, but it limits you.
2774000	2775560	Reductionism is well-named.
2775560	2777720	It reduces what you can do.
2777720	2781640	It reduces your ability to really exploit
2781640	2784480	what's powerful about these systems.
2784480	2786640	And we are leaving so much on the table
2786640	2790320	by refusing to test out the tools,
2790320	2791960	the interaction tools that we have
2791960	2794080	and that have been used for,
2794080	2796200	this is why humans train to dogs and horses
2796200	2798760	for thousands of years knowing zero neuroscience.
2798760	2803040	It's because these systems make it accessible,
2803040	2807080	make that whole process, the goal rewriting process
2807080	2808840	so accessibly offered a beautiful interface,
2808840	2810000	that learning interface.
2810000	2811720	So cells and tissues do this too.
2811720	2814560	And if you refuse to test those hypotheses,
2814560	2816320	you leave a lot on the table.
2816320	2817240	Yeah, thank you.
2817240	2821200	So these ideas of sentience and consciousness
2821200	2824400	are very important to you still.
2824400	2825880	They're not things you discard,
2825880	2828120	but you refuse to say they're binary,
2828120	2830080	they're on or off switches.
2830080	2831600	If there are boundaries, they're fuzzy
2831600	2834120	and in your sense, there may not even be a boundary at all.
2834120	2837120	Ultimately, it may just be a question of degree
2837120	2839680	across every possible system,
2839680	2842520	but that doesn't destroy their meaningfulness
2842520	2845160	because there's a sense, I think,
2845160	2847840	with some people who have a very expansive view
2847840	2851720	of consciousness that they either reify it in some sense.
2851720	2854040	Again, they pull away from the physical
2854040	2857160	and that can lead people into, again,
2857160	2860080	back into some sort of mystical or soul-based ways
2860080	2861160	of thinking about it.
2861160	2864280	Or they declare it universal,
2865240	2866840	as some might say, you would,
2866840	2868760	because you're saying, well, it's a spectrum
2868760	2870280	and there's no real end to the spectrum.
2870280	2872200	So in a sense, maybe everything shares
2872200	2875240	in these characteristics to some degree,
2875240	2876720	but by declaring it universal,
2876720	2880040	they almost destroy what's meaningful about the concept.
2880040	2880880	Yeah.
2880880	2882440	And it sort of flattens out.
2882440	2883640	And I don't think you're doing either
2883640	2885240	because you're recognizing that
2885240	2886680	while you don't want it to make it binary,
2886680	2887880	there's still something distinctive
2887880	2890240	that you can describe in terms
2890240	2893160	of how we relate to these entities
2893160	2898160	and what these concepts can help us understand
2898160	2901000	about these entities, so it retains their meaning.
2901000	2904280	Yeah, it doesn't just, it's not just for explaining,
2904280	2907880	it is essential and useful.
2907880	2912440	My claim is that ideas about cognitive capacities
2912440	2915800	and unfamiliar contexts and unfamiliar embodiments
2915800	2918720	are essential, they're practical and they're essential.
2918720	2921880	This is not philosophy,
2921880	2925120	it's not some kind of feel-good mysticism.
2925120	2927720	My claim is, and it's a testable claim
2927720	2930600	that we've been testing for now for 20 years successfully,
2931600	2935720	is that it helps you do better in the empirical world.
2935720	2939400	I mean, the best thing I hope my lab does
2939400	2942560	is what I hope on their best day,
2942560	2944320	what I think we're doing is taking these ideas
2944320	2945920	from deep philosophy that people have argued
2945920	2947280	about for thousands of years
2947280	2949680	and bringing them to the bedside, to the clinic.
2949680	2953760	And these things, these ideas are empirically essential
2953760	2955760	to get the kind of outcomes that you want.
2955760	2959600	So that's, I don't know what more we can say about
2959600	2961320	why these ideas are real,
2961320	2963280	because by taking that inner perspective,
2963280	2965560	by asking what do cells remember?
2965560	2966680	What do they care about?
2966680	2968760	What is their, the size of their goals?
2968760	2970000	What are their goals?
2970000	2973160	These are questions that lead directly to therapeutics.
2973160	2975720	They lead to work in regenerative medicine, in cancer.
2976600	2978800	I don't know what more evidence we could have
2978800	2980320	that these things are critical.
2980320	2983720	And the other issue is that this idea
2983720	2987640	that if we start to apply the tools
2987640	2989440	that we use with cognitive systems,
2989440	2991160	we try to apply them elsewhere,
2991160	2994720	that that kind of leads to some sort of sliding creep
2994720	2999720	that devalues our own cognition and our own majesty.
3001320	3005800	That's a weird zero-sum game that I don't buy into.
3005800	3009360	I am in no way diminished by, I don't feel in any way
3009360	3013520	diminished by the idea that there are basically
3013520	3016760	an infinitude of other minds, highly diverse minds,
3016760	3019520	endless sentient forms throughout the universe,
3019520	3022640	and I think I'm certainly here on earth,
3022640	3026560	that are also having experiences that strive and suffer
3026560	3028680	and to various degrees.
3028680	3030440	I don't think that diminishes us at all.
3030440	3035440	It seems childish to me to somehow pin our,
3036000	3038080	the quality of what we have on the fact
3038080	3039960	that no one else has it, that just seems,
3039960	3041760	I don't know why we need to make that move.
3041760	3044520	I think what we have is essential.
3044520	3046000	I think understanding it is essential
3046040	3047640	so that we can scale it up.
3047640	3049800	I would like to scale my cognitive capacity.
3049800	3052720	I would like humanity to scale its cognitive capacity
3052720	3054640	more specifically, not just the intelligence,
3054640	3059640	but the radius of concern, of care, and of compassion.
3060440	3061600	I think we need to scale that up,
3061600	3062840	and you only do that if you understand
3062840	3064360	what it is that you're scaling.
3064360	3065600	You've done the perfect segue
3065600	3067960	into our second question about the ethics.
3067960	3070200	And what I might do is collapse these questions
3070200	3073320	of what matters and who matters just into one,
3073320	3075920	because in the big questions of ethics,
3075920	3078120	in a sense, there are a bunch of different choices.
3078120	3079720	You could take a nihilist route
3079720	3081320	where you sort of give up on the idea.
3081320	3083120	You could take a relativist approach
3083120	3087040	where you think about ethics as just sets of rules
3087040	3089000	that groups have negotiated
3089000	3091280	in a more transactional relational sense,
3091280	3094240	but there's no real truth of the matter
3094240	3098120	about whether those rules do good or bad.
3098120	3099880	You could follow a divine command theory,
3099880	3101440	going back to our early conversation
3101440	3104040	where you could turn to the Bible or the Quran
3104080	3106400	or some other source of supernatural authority
3106400	3108480	and go basically following those rules
3108480	3110880	or being obedient to that deity
3110880	3113920	is the ultimate arbiter of what's good or bad.
3113920	3115000	But if we put those aside,
3115000	3117000	and personally, I think we should,
3117000	3121000	whatever sort of moral philosophy we have,
3122640	3125360	whether it's about rights and day ontology
3125360	3128120	or whether it's about consequences and utilitarianism,
3128120	3129920	whether it's about feminist care ethic
3129920	3131800	where we have relations of care,
3131800	3133600	whether it's about virtues,
3133600	3135880	whatever the system is,
3135880	3140440	they do all seem to share a sort of common sense ethical call,
3140440	3143040	which is that somehow morality is about
3143040	3145240	whether and how we care about others.
3146920	3148400	And the obvious question then is,
3148400	3150280	okay, well, who gets to count as another?
3150280	3153440	That's really our who matters question.
3153440	3156480	And again, I and this podcast have a bias
3156480	3157880	because we tend to focus on this idea
3157880	3160240	of sentience as being the qualifier
3160240	3165240	in that for an entity to count as another,
3165280	3168760	they need to have their own perspective
3168760	3171880	within which they value their own experiences,
3171880	3176000	states, interests, and lives, I guess.
3176000	3179280	And because they value those things themselves,
3179280	3183000	that's the rationale for us also caring about them.
3183000	3183840	Because in a way,
3183840	3186280	if morality is about caring about others,
3186280	3188600	let's care about all of the others
3188640	3191000	that have their own perspective and so qualify as others.
3191000	3192840	So it's almost a little bit secular.
3192840	3195360	But anyway, that's I guess the starting point
3195360	3197160	from this centio-centric ethic
3197160	3199040	is to care about all of those others.
3199040	3201600	But I'd be really interested in your own
3201600	3204400	thinking about either the sort of foundations of ethics
3204400	3206560	when you're right, wrong, and good, and bad,
3206560	3209800	but also given what we've talked about so far,
3209800	3213120	how you think about moral scope and who gets to count
3213120	3214440	and what are the implications of that
3214440	3217840	and what journey have you gone on through your life so far
3217880	3220480	and thinking about those big questions?
3220480	3224680	Yeah, well, you know, it's somewhat beyond my pay grade
3224680	3228040	to try to lay out a global theory of ethics
3228040	3229200	for everybody else and so on.
3229200	3230560	That's, I won't try to do that,
3230560	3232280	but I will give you some thoughts
3232280	3234560	and how I think about these things.
3235420	3236260	Couple of things.
3236260	3240040	First, I think it's important to not pretend
3240040	3243980	that once we understand how sentient something is,
3243980	3246680	we are automatically good at treating it ethically.
3246720	3248240	Okay, so we know that's not the case.
3248240	3252920	We know factory farming, we all know pigs are,
3252920	3256200	pigs value their experience that they feel pain,
3256200	3257640	all that, and yet here we are.
3257640	3261920	So I think what we know and how we treat them
3261920	3264200	are not unfortunately the same thing,
3264200	3268480	but certainly we should have a principled way
3268480	3272120	of apportioning our relationships
3272120	3275600	with other beings of all different kinds.
3275640	3280640	I think that moving forward in assuming we all survive
3282960	3285480	the next few decades, I think moving forward
3285480	3288120	for the flourishing of humanity, of ecosystems,
3288120	3291720	of other beings on earth really requires
3291720	3293560	the deep lessons of diverse intelligence.
3293560	3295680	I think we need to understand
3295680	3299440	that there is no such thing as a magical standard human
3299440	3303160	that is the subject of all these philosophical arguments.
3303320	3306200	First of all, because evolutionarily,
3306200	3308280	we have a lineage going back to single cells.
3308280	3312560	So anything that you think about human responsibilities,
3312560	3315480	whatever, well, how about a human of 200,000 years ago?
3315480	3317080	How about 500,000 years ago?
3317080	3318680	Where was it?
3318680	3319800	How did it get here?
3319800	3320720	And so on.
3320720	3323600	So all of those things are continual.
3323600	3325720	The same thing is true of embryonic development.
3325720	3328560	You can ask how these things showed up in your journey
3328560	3330880	from an OSI to a being.
3330920	3335680	And all of the current discussions
3335680	3340680	of neuroatypical humans and the bodily modifications
3340680	3345000	that some people do, these things are going to be laughable
3345000	3347880	to the humans of the next couple of generations
3347880	3352680	in their minor sort of degree, their timid degree.
3352680	3354400	I mean, you're going to have humans
3354400	3357960	that are so modified in body and mind, cyborgs,
3358640	3362280	with various biological and technological changes
3362280	3365440	that it's going to be completely obvious.
3365440	3367640	Right now, we're kind of lulled into a fault.
3367640	3370080	Well, we have been for centuries,
3370080	3371720	lulled into a false sense of security
3371720	3373280	in the sense that it was easy.
3373280	3375440	Before you could say, does it speak?
3375440	3377440	If it speaks, then it's like us.
3377440	3379280	And even that humanity fails.
3379280	3381680	We were really terrible to each other
3381680	3383720	for much smaller differences.
3383720	3386960	But you could say, where did you come from?
3386960	3389520	Meaning, were you evolved or did you come from a factory?
3389520	3390880	And you could sort of knock on something.
3390880	3392640	And if you hear a metallic clanging sound, you say,
3392640	3395040	okay, we know how we're going to deal with this.
3395040	3398840	And if you heard some kind of soft and kind of a thud,
3398840	3400400	then that's something else.
3400400	3401960	Those categories were never any good,
3401960	3404920	but they served us kind of okay for a long time.
3404920	3405760	Those are gone.
3405760	3407360	Those are gone now.
3407360	3408960	They're going to be left in the dust
3408960	3410880	by the next couple of decades.
3410880	3413040	It's going to be essential that we learn
3413040	3415960	to have an ethical, I call it synthbiosis,
3415960	3418760	with other beings that are nowhere with us
3418760	3419600	on the tree of life.
3419600	3421600	They are modified in body and mind.
3421600	3423960	And what you look like and where you come from
3423960	3426320	simply cannot be the foundation
3426320	3428200	for how we're going to relate to each other.
3428200	3431760	And again, science fiction dealt with this a long time ago.
3431760	3436760	But somehow people today have lost sight of some of those
3436760	3440160	things, again, the current debates over AI,
3440160	3442240	it's very easy to say that language models
3442240	3443240	aren't this and aren't that.
3443240	3445480	And I'm not a defender of any particular view
3445480	3447240	of sentience and language models,
3447240	3449000	although more generally, I don't believe
3449000	3450760	we really know what we have once we've made it.
3450760	3453640	But the thing is those kind of language models,
3453640	3455880	they're so different from us that it's very easy
3455880	3458720	for people to say, oh, that's not the things
3458720	3459760	we want to care about.
3459760	3461560	What are you going to do when you're confronted
3461560	3465680	with humans that have 51% of their brain replaced
3465680	3470600	by various silicon appliances and they're linked together
3470600	3473480	with other people and also a few AIs
3473480	3474640	and some things like that.
3474680	3479480	So all of this is coming, we are going to have
3479480	3483160	to develop a better, better more principled
3483160	3486360	ethical frameworks for dealing with beings
3486360	3489920	that are just very alien in their construction.
3489920	3492000	And so that means that you need frameworks
3492000	3495160	to understand what do all these beings have in common?
3495160	3497240	And this is something that a few years ago,
3497240	3499800	I developed this notion of a cognitive light cone
3499800	3503760	to try to get away from the idea of what kind
3503800	3507240	of material embodiment you're in and instead focus on
3507240	3508600	what are the things you care about?
3508600	3513600	What is the size of the biggest goals you can pursue?
3514760	3516600	And regardless of your embodiment
3516600	3518680	or implementation or origin story.
3518680	3522920	And that kind of a thing at least begins to give us
3522920	3527680	a way to apportion our degree of moral concern
3527680	3531880	to beings that are capable of pursuing goals
3532520	3536320	and having various kinds of competencies
3536320	3539200	of navigating problem spaces and suffering
3539200	3543440	when those goals are not reached.
3543440	3548440	So for that reason, I think the diversity
3550680	3554080	of who and what we think counts is gonna be enormous
3554080	3556680	and this business of language models and so on,
3556680	3560000	it's a distraction from a much deeper puzzle.
3560040	3560960	Yeah, thank you.
3560960	3563520	And one of my previous guests, Josh Gellis
3563520	3565720	has done quite a lot of work in that space
3565720	3569000	about thinking about potential artificial intelligences
3569000	3570440	and sentience and so on.
3570440	3571840	And actually he's quite challenging
3571840	3573360	about the idea of sentience
3573360	3575840	because he's worried it's seen too much
3575840	3579000	as a sort of easily isolatable property
3579000	3581640	that we will then deny to, for example,
3581640	3583440	artificial intelligence and robots and so on.
3583440	3586040	And he prefers a much more relational approach,
3586040	3588640	which we can go back and forth about the risks
3588640	3589880	and the challenges of that.
3589880	3592440	But one thing I do agree with him and I think you
3592440	3595360	is that we're gonna be forced into working this stuff out
3595360	3596600	whether we like it or not.
3596600	3598760	And I think it will open up and radicalize
3598760	3600560	the way we think about what it is to be another
3600560	3604440	and that need to appreciate radically different perspective
3604440	3605560	from different beings.
3605560	3608960	But I was really glad you mentioned animal agriculture
3608960	3611200	because one of the frustrations with many people
3611200	3614440	who are involved in sentientism or the worldview
3614440	3617760	is that there's a frustration in the current zeitgeist
3617760	3619840	that people seem really excited about talking
3619840	3622960	about artificial intelligences and artificial sentience
3622960	3624920	and whether robots could ever feel something
3624920	3626280	and become moral patients.
3626280	3629440	But people seem to conveniently skip over the hundreds
3629440	3632280	of billions, if not trillions, if we include aquatic,
3632280	3635200	non-human sentient beings that we brutally exploit today.
3635200	3637480	And it's a really interesting case study
3637480	3642480	because I think when you take a naturalistic epistemology
3643440	3645960	and you understand the facts of what farming
3645960	3647880	and fishing are like, not just factory farming,
3647880	3650720	but all of it, and you take the ethical perspective
3650720	3653320	of the beings that are going through those processes,
3653320	3657880	it quite easily leads you to a point of quite extreme ethical
3657880	3660920	condemnation of what's going on in those situations.
3660920	3665000	But our society is trained us to think this so normal
3665000	3668640	that there's a brutal clash between, you know,
3668640	3671200	if you like the epistemology and the centiocentric ethic
3671200	3673240	and today's social norms.
3673800	3676200	Thank you for mentioning that.
3676200	3678680	I mean, so a couple of things there.
3678680	3681360	One is that, yeah, I mean, you're absolutely right,
3681360	3686360	of course, in talking about these AIs
3686640	3690360	and instead of other problems with the existing life forms
3690360	3691880	is a huge issue.
3691880	3693920	It also comes up when people say,
3693920	3697480	oh, wow, we're gonna make these high level intelligences
3697480	3699840	and who knows how they'll be raised
3699840	3701440	and what they're gonna do in the future.
3701480	3703680	I mean, you've heard of having kids, right?
3703680	3706400	Like, I'm just, you know, we do this all the time.
3706400	3709640	We have an enormous amount of guaranteed high level
3710400	3712240	intelligences that are created all the time
3712240	3715720	and a huge diversity of good and bad environments
3715720	3716720	that they're raised in.
3716720	3719800	We have a very limited ability to make sure
3719800	3722280	that they have a good embodied experience
3722280	3723800	and are aligned with our values
3723800	3725760	and some of them go on to do wonderful things
3725760	3728640	and some of them go on to, you know, to do horrible things.
3728640	3729680	That's already an issue.
3729680	3731400	We already have that.
3731400	3734240	The thing with, so these, in many ways,
3734240	3736600	these problems are not new problems brought on by AI.
3736600	3739600	They're perennial existential problems
3739600	3742720	that humanity has faced forever, you know,
3742720	3745240	in terms of being supplanted by the next generation
3745240	3747840	that finds your values, you know, irrelevant
3747840	3749600	and how much control do you want
3749600	3751360	over how your neighbor is raising their kids
3751360	3752320	and all these kinds of things.
3752320	3755920	This has been with us for the longest time.
3756320	3760880	The one unique thing about AI intelligences, though,
3760880	3765160	is that they can be copied in a much easier fashion.
3765160	3766560	They can be reproduced and copied
3766560	3769200	in a much easier fashion than real animals.
3769200	3774200	And I think that now, while there are some good debates
3775200	3777680	about whether something that actually can be copied
3777680	3779720	even counts in this case.
3779720	3782160	So, you know, there's a few arguments
3782160	3785600	that that's not an issue, but I'm not sure yet.
3785600	3788240	And I think that for that reason,
3788240	3791320	because there's just gonna be such an uncountable number
3791320	3794400	of intelligences of the software variety,
3794400	3795840	whether embodied or not,
3795840	3798960	it's something that we need to consider, you know.
3798960	3801520	And I'm hopeful that with the advent
3801520	3805440	of different ways to grow food proteins and so on,
3805440	3808440	we're gonna eventually completely do away
3808440	3810600	with animal farming and so on.
3810840	3815840	But the creation of novel synthetic organisms
3815840	3817040	is only gonna increase.
3817040	3819520	And I mean, you know, digital or embodied or not.
3819520	3822400	So that's, you know, I think we need to focus
3822400	3824640	on both sides of that equation.
3824640	3825920	Yeah, I agree, agree.
3825920	3828000	And I don't know if you're thinking on that
3828000	3830680	as led you down the path of boycotting animal agriculture
3830680	3831760	and its product so far,
3831760	3835520	or whether I can help you offline on that path, but...
3835520	3838040	Yeah, why don't we talk offline?
3838040	3839080	Sounds good, sounds good.
3839120	3842640	So the other ethical question I wanted to touch on with you
3842640	3845320	is how that bears on your own work in the lab,
3845320	3847680	because you do work with a variety
3847680	3849960	of different entities, animal and non.
3849960	3851200	How does that play in?
3851200	3854120	Because you're into your choices,
3854120	3856480	because you're working with some very simple organisms
3856480	3858840	and you're working with more complex organisms as well
3858840	3860240	that would have richer experiences.
3860240	3861480	How do you think about that?
3861480	3863000	Again, I won't take you through it in depth,
3863000	3865520	but I'm interested in sort of simple perspective
3865520	3867960	you take on animals and research.
3868000	3869040	Yeah, yeah.
3869040	3873720	Well, first, just to say that animal use and research
3873720	3876320	is incredibly stringently regulated.
3876320	3878480	So in order to do the things
3878480	3881240	that somebody would do when they go fishing for an afternoon,
3881240	3884600	we have three months of paperwork and oversight
3884600	3886720	by veterinarians and ethicists and all that.
3886720	3889240	So there's a huge amount of oversight,
3889240	3892640	as there should be, I'm not in full favor of that.
3892640	3896120	But this is something I think that's really important
3896120	3898560	and it gets to this issue of what matters.
3899560	3904160	A lot of folks see scientific ethics in the following way.
3904160	3906560	Everything's great and you scientists
3906560	3908240	better not screw it up, right?
3908240	3911840	So here's a long list of things we don't want you to do.
3911840	3913720	We don't want this, we don't want that.
3913720	3915200	Don't make things worse.
3915200	3920200	Now that could, I suppose could have been a viable worldview
3920560	3922960	when people believe that our current world
3922960	3926560	is in some way set up in the right way for us.
3926560	3928880	In other words, it is the best possible world.
3928880	3931600	Everything is great now, now don't screw it up.
3931600	3935880	What we now know is that that's not the world we live in.
3935880	3940880	We are the process of meandering evolutionary path.
3940920	3942480	Evolution, as far as I can tell,
3942480	3944640	does not optimize for any of our values.
3944640	3945960	It doesn't optimize for happiness,
3945960	3947800	for intelligence, for any of that stuff.
3947800	3950400	No, we are where evolution dumped us
3950400	3952600	with all of our ridiculous susceptibilities
3952640	3955960	to bacteria, viruses, lower back pain,
3955960	3959320	stray cosmic rays that might have hit a DNA molecule
3959320	3960160	during development,
3960160	3962640	and now your potential is radically limited.
3962640	3964080	When you broaden that scope out
3964080	3965880	to all of the potentially sentient beings,
3965880	3967840	that just becomes even starker, right?
3967840	3970440	If there is some tealoss to this universe,
3970440	3971960	it's a pretty brutal one, yeah.
3971960	3973640	It is, it is, there's no doubt.
3973640	3975920	And so I'm not even a clinician,
3975920	3978320	but the amount of emails that I get every day
3978320	3981160	from people with the most unbelievable examples
3981400	3984680	of biomedical suffering is just incredible.
3984680	3987400	So I think it is utter moral cowardice
3987400	3989960	to focus on what we shouldn't do.
3990880	3995240	And as opposed to our duty now that we have,
3995240	3997000	for the first time, I guess, on Earth,
3997000	4000320	we have the ability to actually rationally approach
4000320	4005320	these matters to try to guarantee a better embodiment
4005920	4007880	for sentient beings on Earth.
4009320	4010760	The number of people that are suffering
4010760	4012160	because of our ignorance,
4012160	4013720	because we don't know what to do,
4013720	4016160	and also because of our timidity
4016160	4021160	and our unwillingness to take responsibility for,
4023080	4025080	we are the ones that are now,
4025080	4028840	it is on us now to improve this for people.
4030080	4031960	And not just people, for ecosystems,
4031960	4035920	for other beings, for just the amount of ignorance
4035920	4039560	and inaction that is letting a sentient being suffer
4039560	4041440	worldwide is incredible.
4041440	4046440	And so I take animal use ethics extremely seriously,
4047080	4050160	but I think to the extent that it is our responsibility
4050160	4053640	to relieve the suffering worldwide, science has to go on.
4053640	4056480	And we have to do experiments that are going to enable us
4056480	4059920	to improve embodied experience for all.
4061000	4066000	This is just, the Buddhists have this concept
4066120	4067720	of an inauspicious birth.
4067720	4070160	And it's this idea that in one of your many lifetimes,
4070160	4072840	you're born in a body during which you just can't make
4072840	4075360	progress towards enlightenment.
4075360	4079200	I think at this point, I know this is a controversial view,
4079200	4080960	but I think basically right now,
4080960	4083360	every birth is an inauspicious birth.
4083360	4088240	All of us are limited by the vagaries of random mutation
4088240	4090320	and selection and all these dumb things and viruses,
4090320	4093200	all these dumb things that have no one's best interest.
4093200	4095160	And I think in the future,
4095160	4100080	sometimes I sort of imagine this dialogue that children
4100080	4102280	in the future are going to have with their teachers,
4102280	4103960	the kind of thing where you tell the kids,
4103960	4107320	yeah, we wrote on chalkboards and we didn't have cell phones
4107320	4108480	and like, what?
4108480	4110960	And so they're gonna say,
4110960	4113360	you're telling me you would just have to stay
4113360	4115480	in whatever body you randomly got.
4115480	4116600	And if you had some sort of defect,
4116600	4117760	you just have to live that way.
4117760	4121680	And if the IQ and the lifespan that you were born with
4121680	4124040	wasn't enough to fulfill your goals, that's it.
4124040	4125760	You just have to, you know, that was your bad luck.
4125760	4130760	That will be unthinkable to a modern humans going forward.
4131960	4133640	And in a way, that's a beautiful link
4133640	4135520	into the final question, which is how do we make
4135520	4138280	a better future, which is what are the promises
4138280	4142160	of these types of research and thinking?
4142160	4144680	Yeah, I mean, I think ultimately
4144680	4147000	from the kind of the bigger picture for me
4147000	4148840	is freedom of embodiment.
4148840	4151280	I think that every sentient being should have the,
4151280	4154040	and we need to, we should offer assistance
4154040	4155920	in the same way that we offer assistance
4155920	4160920	to beings via education, via support of every kind.
4161440	4165180	We should be in a position to offer the ability
4165180	4168080	for sentient beings to have better embodiments
4168080	4171200	to fulfill their potential, their goals and so on.
4171200	4174280	Practically speaking, what that requires
4174280	4177480	is complete control over growth and form.
4177480	4181320	It means that we need to really be able to direct
4181320	4183420	what it is that cells build.
4183420	4186080	Now, right now that just looks like regenerative medicine
4186080	4188600	in the sense that if we knew how to get cells
4188600	4191400	to build specifics as anatomical structures,
4191400	4194640	then birth defects, traumatic injuries, cancer, aging,
4194640	4197280	degenerative disease, all these things would go away
4197280	4199720	if we could communicate our goals to groups of cells.
4199720	4202320	And this is something that we and some other labs
4202320	4204840	are working on now is this kind of, you know,
4204840	4206740	this idea of an anatomical compiler
4206820	4208700	where you can just specify the shape
4208700	4210380	of the structure that you want
4210380	4214420	and it gives stimuli to cells to make them grow exactly that.
4214420	4216300	And again, linking to what you said before,
4216300	4218660	this is different from the classical ideas
4218660	4220980	of genetic engineering or, you know,
4220980	4222020	what you do with CRISPR and so on.
4222020	4226420	This is a different mode of engagement with a system.
4226420	4230420	Yeah, the goal is similar because certainly people,
4230420	4232980	you know, at the time that genetics was getting off
4232980	4235340	the ground, this is a vision that people had then too,
4235340	4236820	that if we understood the genetics,
4236820	4238420	we could control the shape.
4238420	4242820	I think we have a much more practical path to it
4242820	4246060	because I think the genetics specifies the hardware
4246060	4248700	that every cell gets to have, so the proteins.
4248700	4253700	But as we know from the advances of computer science
4253880	4255380	and information technology programming
4255380	4258540	at the level of hardware, while possible, it's really hard.
4258540	4261140	And if you have good hardware that's actually reprogrammable
4261140	4263220	and offers high level interfaces, you know,
4263220	4265220	you might say APIs, which I think is exactly
4265260	4268580	what it offers, then you can do this in a much better way,
4268580	4273580	specifically by honoring the agency of the cells and tissues
4273740	4275300	and being a collaborator with them.
4275300	4278620	We don't micromanage our cells and tissues here.
4278620	4281100	I mean, in my group, we basically collaborate with them
4281100	4284060	and modulate their goals and take advantage
4284060	4286960	of their competencies, their problem-solving capacities,
4286960	4288220	their memories and so on.
4288220	4292540	So I think that is a way to move the field forward
4292540	4293440	much faster.
4293440	4295100	I think that CRISPR and those kinds of things
4295100	4298380	are going to flatten out soon because after you've picked
4298380	4300580	the low-hanging fruit of single gene diseases,
4300580	4303020	the next question is gonna be, well, what genes do you add
4303020	4305260	to make the changes, the anatomical changes do you want?
4305260	4307060	And development's not reversible in that way.
4307060	4310780	You can't just figure out what, in any easy way,
4310780	4311620	what to edit.
4311620	4316380	So I think taking advantage of the interfaces
4316380	4319380	that cells use to hack each other is critical.
4319380	4322540	But initially that just looks like reprogramming tumors
4322540	4326460	and regrowing limbs and growing new organs and so on,
4326460	4328020	all of which by the way we've done here
4328020	4330460	in various model systems.
4330460	4333180	But ultimately it leads to freedom of embodiment.
4333180	4335940	It means that if you want to have a different embodiment
4335940	4338140	you can, and if you decide you wanna change it,
4338140	4339700	you should be able to do that too.
4339700	4342500	There is no reason any of us should be stuck
4342500	4345100	in the embodiment that we got,
4345100	4348740	including IQ and lifespan and all those things.
4348740	4350300	Because those things were not chosen
4350300	4351820	with your welfare in mind.
4352500	4355900	They were a long process shaped by forces
4355900	4358020	that don't honor any of our values.
4358020	4359020	Yeah, thank you.
4359020	4360300	It's quite a vision.
4360300	4362380	And it will lead to some of the things I've touched on
4362380	4364220	with some of the people who are interested
4364220	4366260	in the transhumanist space like David Pearson
4366260	4367220	and so on as well.
4367220	4369140	And again, it's that freedom of embodiment
4369140	4373020	for human and non-human sentient beings
4373020	4376420	that is, to put it a different way,
4376420	4378980	shaped by their own values and aspirations
4379060	4383980	and experiences rather than constrained by inherited biology
4383980	4386500	and freeing from some of those constraints.
4386500	4391500	But some of my audience will love that sort of vision
4391620	4394020	and see the potential.
4394020	4397060	Others will be nervous about classic problem
4397060	4398700	of human hubris and intervening
4398700	4400620	where we're not really ready to intervene.
4400620	4401900	What do you think of the risk profile
4401900	4403380	and the approach you're taking?
4403380	4404780	Are there risks we need to watch out for
4404780	4407980	that we need to build in?
4407980	4409620	For sure, there are going to be risks,
4409620	4412860	but I'm pushing in the very opposite direction
4412860	4415180	of the hubris.
4415180	4418780	My argument isn't that everything is great.
4418780	4422820	And then in an effort to make it even better,
4422820	4424340	we're going to screw things up.
4424340	4426020	And we may screw some things up.
4426020	4427780	It's pretty inevitable.
4427780	4431460	My argument is that things are so bad right now
4431460	4435500	for so many that it is a moral imperative.
4435620	4438260	We do not have the luxury of saying,
4438260	4440140	don't do this.
4440140	4441900	Inaction is a choice too.
4441900	4443060	Yeah, exactly right.
4443060	4447700	The opportunity cost of doing nothing is massive.
4447700	4448820	It's absolutely massive.
4448820	4453820	And this idea that we don't have to do anything
4455700	4459620	because we can let things go how they are now,
4459620	4461380	that's simply not acceptable.
4461380	4464940	That opportunity cost is too huge.
4464980	4468220	So yes, we're going to make mistakes,
4468220	4471380	but anybody who, we know from our personal lives,
4471380	4474740	if the thing that you are most optimizing
4474740	4476700	is to never make a mistake,
4476700	4479460	what's going to be the value of your life
4479460	4481940	and all the huffing and puffing
4481940	4485500	that we do during our brief time here?
4485500	4486500	What's the goal?
4486500	4488140	If that's, I mean, obviously you want to minimize
4488140	4490300	making mistakes, but there should be a constructive,
4490300	4492780	I believe there should be a constructive element to this
4492820	4496380	where you have a purpose to elevate and help others.
4496380	4498780	And that is not going to happen by focusing
4498780	4500900	on the things we shouldn't do.
4500900	4505220	And just more broadly, I ask people who focus
4505220	4509900	on this negative risk-based perspective,
4509900	4512420	what does humanity look like 100 years from now?
4512420	4515500	Are we still getting lower back pain and bad knees
4515500	4518460	and dying into our 80s once we've gotten this
4518460	4519660	a little bit of wisdom under our belts?
4519660	4520500	Like that's it.
4521420	4523020	And if you happen to, you know,
4523020	4527020	some cosmic ray or something hits one of your chromosomes,
4527020	4529060	then are we still living like that?
4529060	4529940	I mean, I can't imagine.
4529940	4532900	I just, that would seem like such a waste
4532900	4534940	of this incredible gift of intelligence
4534940	4536180	and compassion that we have
4536180	4538060	that it seems ludicrous to me.
4538060	4540700	But anybody, I think people should spend time
4540700	4543260	painting the future that they do want, you know?
4543260	4544420	Everybody's already paid, you know,
4544420	4545780	written down all the things they don't want.
4545780	4546620	That's fine.
4546620	4548860	Now, paint me a picture of what do you want?
4548980	4550820	Where should we be 100 years from now?
4550820	4551660	Yeah, thank you.
4551660	4553460	I'm a sucker for a bit of utopian thinking.
4553460	4555540	I know you're a fellow sci-fi fan as well.
4555540	4558220	And some people will use that as a way of discarding
4558220	4560500	some of the ideas you're working on and saying,
4560500	4563420	it's just sci-fi, but I think sci-fi's got a lot to teach you.
4563420	4566580	So I often find better philosophy in sci-fi
4566580	4568260	than I do in actual philosophy.
4568260	4570460	And one of the things about sci-fi is it's very good
4570460	4573380	at sort of intuitive sentientist stance
4573380	4576180	because it's so common and just natural
4576180	4580100	and even unthinking, most science fiction stories
4580100	4583260	to recognize the salience of sentient beings
4583260	4584740	that are radically different from ourselves.
4584740	4586380	And I think there's a lesson there we can take too.
4586380	4587220	So yeah.
4587220	4588060	For sure.
4588060	4590380	And you know, sci-fi, to me, if somebody says,
4590380	4593060	this is just sci-fi, my question is very simple.
4593060	4594540	Are you saying it's impossible
4594540	4596100	or are you just saying it's gonna take a while?
4596100	4597980	Like that's a certain things that maybe,
4597980	4598820	I don't know what those would be,
4598820	4599660	but there are certain things
4599660	4601540	that may be physically impossible, fine.
4601540	4603020	Everything else is just a time to,
4603020	4605100	then we're just quibbling over a timetable.
4605140	4607660	Everything that's possible is gonna be done.
4607660	4608980	And there's dystopian sci-fi,
4608980	4610500	but there's also utopian sci-fi.
4610500	4612980	So yeah, like I say, paint those pictures.
4612980	4614540	Well, it's been an inspirational conversation.
4614540	4617060	Thank you so much for talking to me today, Mike.
4617060	4619100	What's the best way of people following you,
4619100	4620620	finding out more about your work?
4620620	4622180	I'll include links in the show notes, of course,
4622180	4624340	but where's the main place you point people?
4624340	4626580	Yeah, the official lab website
4626580	4629860	that has all of the kind of peer reviewed hard stuff
4629860	4634220	is darmike11.org, one word, darmike11.org.
4634260	4636100	The more speculative, you know,
4636100	4638180	the photography, the pros and all that stuff,
4638180	4639780	and so just some thoughts that I wouldn't,
4639780	4641700	you know, I wouldn't put in a scientific paper
4641700	4643820	is at thoughtforms.life.
4643820	4645700	It's a blog called thoughtforms.life.
4645700	4649060	And I'm on Twitter at at darmike11.
4649060	4649900	Yeah, that's awesome.
4649900	4650740	Thank you.
4650740	4652580	And I'll follow up with some vegan tips offline.
4652580	4654060	Cool, that would be great.
4654060	4654900	I appreciate it.
4654900	4655900	All right, well, thank you so much
4655900	4657300	for being a guest on Sentientism.
4657300	4658300	It's been a pleasure, Mike.
4658300	4660100	Take care, enjoy the rest of your day.
4660100	4661740	Thank you, you too.
4661740	4662740	Please stay in touch.
