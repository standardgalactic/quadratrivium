1
00:00:00,000 --> 00:00:03,060
The best thing I hope my lab does on their best days,

2
00:00:03,060 --> 00:00:04,860
taking these ideas from deep philosophy

3
00:00:04,860 --> 00:00:06,940
that people have argued about for thousands of years

4
00:00:06,940 --> 00:00:09,420
and bringing them to the bedside, to the clinic.

5
00:00:09,420 --> 00:00:11,100
What you look like and where you come from

6
00:00:11,100 --> 00:00:13,500
simply cannot be the foundation

7
00:00:13,500 --> 00:00:15,420
for how we're going to relate to each other.

8
00:00:15,420 --> 00:00:18,060
But I don't feel in any way diminished by the idea

9
00:00:18,060 --> 00:00:20,820
that there are an infinitude of other minds,

10
00:00:20,820 --> 00:00:24,420
highly diverse minds, endless sentient forms

11
00:00:24,420 --> 00:00:27,180
that are also having experiences that strive

12
00:00:27,180 --> 00:00:29,140
and suffer to various degrees.

13
00:00:29,220 --> 00:00:30,900
I think what we have is essential.

14
00:00:30,900 --> 00:00:33,940
I would like humanity to scale its cognitive capacity

15
00:00:33,940 --> 00:00:35,860
more specifically, not just the intelligence,

16
00:00:35,860 --> 00:00:39,460
but the radius of concern, of care, and of compassion.

17
00:00:39,460 --> 00:00:40,980
I think we need to scale that up.

18
00:00:40,980 --> 00:00:43,140
The amount of emails that I get every day

19
00:00:43,140 --> 00:00:45,980
from people with the most unbelievable examples

20
00:00:45,980 --> 00:00:48,700
of biomedical suffering is just incredible.

21
00:00:48,700 --> 00:00:51,420
So I think it is utter moral cowardice

22
00:00:51,420 --> 00:00:54,060
to focus on what we shouldn't do,

23
00:00:54,060 --> 00:00:56,300
as opposed to our duty now that we have,

24
00:00:56,300 --> 00:00:58,260
for the first time, we have the ability

25
00:00:58,260 --> 00:01:00,820
to actually rationally approach these matters,

26
00:01:00,820 --> 00:01:03,980
to try to guarantee a better embodiment

27
00:01:03,980 --> 00:01:05,420
for sentient beings on Earth.

28
00:01:16,300 --> 00:01:17,980
Cool, well, good morning, Mike.

29
00:01:17,980 --> 00:01:19,100
How are you?

30
00:01:19,100 --> 00:01:19,940
Good morning, excellent.

31
00:01:19,940 --> 00:01:20,780
Thanks for having me.

32
00:01:20,780 --> 00:01:22,780
Yeah, it's wonderful to get the chance to talk to you.

33
00:01:22,780 --> 00:01:24,140
I'm very much an amateur in this field,

34
00:01:24,140 --> 00:01:25,820
but I've admired your work for a long while.

35
00:01:25,820 --> 00:01:29,500
And I can't offer you the size of audiences

36
00:01:29,500 --> 00:01:30,940
you're used to with your TED Talk

37
00:01:30,940 --> 00:01:33,460
and with some of the other interviews you've given,

38
00:01:33,460 --> 00:01:35,380
but I can trade that for quality,

39
00:01:35,380 --> 00:01:37,500
because my audience might be small,

40
00:01:37,500 --> 00:01:39,180
but they're lovely and deeply thoughtful.

41
00:01:39,180 --> 00:01:41,540
So I'm sure they'll appreciate your work

42
00:01:41,540 --> 00:01:43,340
and your thinking, because it's great to have you here.

43
00:01:43,340 --> 00:01:45,660
And I think you're probably, in nearly 200 episodes,

44
00:01:45,660 --> 00:01:48,380
my first full-on biologist,

45
00:01:48,380 --> 00:01:51,740
which is a gap I should have filled long ago,

46
00:01:51,740 --> 00:01:55,540
because there's this sense that maybe the mathematicians

47
00:01:55,540 --> 00:01:57,740
look down on the messiness of science,

48
00:01:57,740 --> 00:01:59,300
and maybe even the physicists look down

49
00:01:59,300 --> 00:02:02,060
on the mess of chemistry, biology.

50
00:02:02,060 --> 00:02:03,540
But I think the hierarchy goes the other way.

51
00:02:03,540 --> 00:02:06,940
I think biology is the harder, more challenging space,

52
00:02:06,940 --> 00:02:09,620
whereas the mathematicians and the physicists

53
00:02:09,620 --> 00:02:12,060
with their spherical cows can abstract

54
00:02:12,060 --> 00:02:13,380
some of the interesting stuff away.

55
00:02:13,380 --> 00:02:15,420
You upped your elbows in it quite often,

56
00:02:15,420 --> 00:02:16,420
so it's great to get the chance

57
00:02:16,420 --> 00:02:19,740
to have a biology-focused conversation.

58
00:02:19,740 --> 00:02:20,580
Well, thank you, yeah.

59
00:02:20,580 --> 00:02:23,700
I mean, biologists have plenty of spherical cows.

60
00:02:24,260 --> 00:02:27,180
A lot of people talk about some of our constructs

61
00:02:27,180 --> 00:02:29,180
as real pathways and things like this,

62
00:02:29,180 --> 00:02:32,940
but of course, these are all imaginary kinds of constructs

63
00:02:32,940 --> 00:02:34,540
that we do our best with.

64
00:02:34,540 --> 00:02:35,580
Yeah, cool.

65
00:02:35,580 --> 00:02:37,260
So this is a series of conversations

66
00:02:37,260 --> 00:02:40,180
about what I think of as the deepest philosophical questions

67
00:02:40,180 --> 00:02:42,340
and also the most important.

68
00:02:42,340 --> 00:02:44,620
And they're questions of what's real,

69
00:02:44,620 --> 00:02:47,060
really more epistemology than ontology.

70
00:02:47,060 --> 00:02:48,740
How should we go about best understanding

71
00:02:48,740 --> 00:02:50,300
this crazy world we all share?

72
00:02:50,300 --> 00:02:52,740
But just as importantly, the questions of ethics

73
00:02:52,780 --> 00:02:54,660
and within that complex field,

74
00:02:54,660 --> 00:02:56,660
the simple question of who gets to count.

75
00:02:56,660 --> 00:02:58,260
Who should we count as another

76
00:02:58,260 --> 00:03:00,620
as we're thinking about how to lead a good life?

77
00:03:00,620 --> 00:03:01,780
And I have an obvious bias

78
00:03:01,780 --> 00:03:03,260
because this sentientism worldview

79
00:03:03,260 --> 00:03:05,180
I'm trying to popularize and develop

80
00:03:05,180 --> 00:03:07,460
is very pluralistic and very broad,

81
00:03:07,460 --> 00:03:09,340
but in a sentence is evidence, reason,

82
00:03:09,340 --> 00:03:11,140
and compassion for sentient beings.

83
00:03:11,140 --> 00:03:12,940
So when we're answering the what's real

84
00:03:12,940 --> 00:03:14,620
and how to understand the universe question,

85
00:03:14,620 --> 00:03:16,140
it suggests a really broad,

86
00:03:16,140 --> 00:03:17,780
humble, naturalistic approach

87
00:03:17,780 --> 00:03:19,580
that uses evidence and reasoning.

88
00:03:19,580 --> 00:03:21,420
And when it comes to the ethical scope question,

89
00:03:21,420 --> 00:03:22,260
the clue is in the name.

90
00:03:22,260 --> 00:03:24,180
It says that all sentient beings,

91
00:03:24,180 --> 00:03:26,540
any being that has the capacity to experience things,

92
00:03:26,540 --> 00:03:28,700
to flourish, to suffer should count

93
00:03:28,700 --> 00:03:31,260
at least to some minimal regard and moral consideration.

94
00:03:31,260 --> 00:03:33,380
I'm talking to people in this series of conversations,

95
00:03:33,380 --> 00:03:35,100
some of whom agree and some of whom don't.

96
00:03:35,100 --> 00:03:37,820
So it'll be interesting to see how you have gone

97
00:03:37,820 --> 00:03:39,340
through your own philosophical journey

98
00:03:39,340 --> 00:03:41,100
and answering those questions where you are now

99
00:03:41,100 --> 00:03:43,780
and how that runs through the work you do today.

100
00:03:43,780 --> 00:03:45,220
But before we get onto those big questions,

101
00:03:45,220 --> 00:03:46,700
how would you best introduce yourself

102
00:03:46,700 --> 00:03:48,580
for those people in my audience

103
00:03:48,580 --> 00:03:50,700
who haven't come across your work so far?

104
00:03:50,700 --> 00:03:51,540
Well, let's see.

105
00:03:51,540 --> 00:03:52,740
So my name is Mike Levin.

106
00:03:52,740 --> 00:03:55,540
I'm a professor at Tufts University.

107
00:03:55,540 --> 00:03:58,060
I run the Allen Discovery Center here at Tufts.

108
00:03:58,060 --> 00:04:02,660
I'm also an affiliate faculty member

109
00:04:02,660 --> 00:04:04,460
at the Bees Institute at Harvard.

110
00:04:05,460 --> 00:04:07,100
I do a number of other things.

111
00:04:07,100 --> 00:04:09,420
I co-direct the ICDO,

112
00:04:09,420 --> 00:04:12,940
the Institute for Computer Design Organisms

113
00:04:12,940 --> 00:04:14,700
with Josh Bongard.

114
00:04:14,700 --> 00:04:16,780
And yeah, that's me.

115
00:04:16,780 --> 00:04:19,020
I study a range of things.

116
00:04:19,020 --> 00:04:20,660
I mean, we'll get into all the details

117
00:04:20,660 --> 00:04:22,860
but in my group here,

118
00:04:22,860 --> 00:04:26,860
we do a combination of biology or biophysics,

119
00:04:26,860 --> 00:04:29,780
mostly computer science and cognitive science

120
00:04:29,780 --> 00:04:31,460
to understand embodied minds.

121
00:04:31,460 --> 00:04:32,500
That's really what we do.

122
00:04:32,500 --> 00:04:33,340
Yeah, that's great.

123
00:04:33,340 --> 00:04:34,180
Thank you.

124
00:04:34,180 --> 00:04:35,020
Yeah, we'll dig in.

125
00:04:35,020 --> 00:04:37,460
So let's start with the first of these big philosophical

126
00:04:37,460 --> 00:04:41,180
questions, the question of what's real and epistemology.

127
00:04:41,180 --> 00:04:42,980
Quite often an interesting way into that space

128
00:04:42,980 --> 00:04:43,820
because it's so broad.

129
00:04:43,820 --> 00:04:46,140
It covers anything we might choose to believe

130
00:04:46,140 --> 00:04:47,060
or have credences in.

131
00:04:47,060 --> 00:04:48,980
But an interesting way in many of my guests

132
00:04:49,620 --> 00:04:51,540
is to talk about their journey with respect to religion

133
00:04:51,540 --> 00:04:53,740
and spirituality and whether they grew up

134
00:04:53,740 --> 00:04:56,220
in a religious spiritual sort of context and household,

135
00:04:56,220 --> 00:04:59,860
whether they held onto those types of beliefs or not,

136
00:04:59,860 --> 00:05:01,260
and how that side of their thinking about

137
00:05:01,260 --> 00:05:03,020
some of the sort of ultimate questions

138
00:05:03,020 --> 00:05:06,340
of the nature of reality might have shifted since.

139
00:05:06,340 --> 00:05:08,020
But so I don't know if you wanna wind the clock back

140
00:05:08,020 --> 00:05:10,140
and sort of tell us your story in that space.

141
00:05:10,140 --> 00:05:12,100
And then we could get into, I guess,

142
00:05:12,100 --> 00:05:15,300
more of the field of science and so.

143
00:05:15,300 --> 00:05:16,780
Yeah, yeah.

144
00:05:16,820 --> 00:05:19,460
My background, I think you could say,

145
00:05:19,460 --> 00:05:22,580
is not religious, but highly spiritual.

146
00:05:22,580 --> 00:05:27,580
So I went for a few years, I went to a Hebrew day school

147
00:05:28,260 --> 00:05:32,420
and my background from that perspective is Jewish

148
00:05:32,420 --> 00:05:37,420
and we studied some thoughts around that whole thing.

149
00:05:39,620 --> 00:05:41,700
And I harassed everybody with questions

150
00:05:41,700 --> 00:05:44,580
about what happens in conjoint twinning

151
00:05:44,620 --> 00:05:47,780
and how souls are supposed to work

152
00:05:47,780 --> 00:05:51,620
and how they solve the problems of the hard problem

153
00:05:51,620 --> 00:05:53,740
of consciousness and all that kind of a thing.

154
00:05:53,740 --> 00:05:57,140
And the answers weren't terribly forthcoming

155
00:05:57,140 --> 00:05:58,460
from that direction.

156
00:05:58,460 --> 00:06:03,460
But in my home, I think it was always very clear

157
00:06:03,700 --> 00:06:06,740
from the time I was very young that we had an emphasis

158
00:06:06,740 --> 00:06:10,180
on inquiry, on asking big questions,

159
00:06:10,180 --> 00:06:13,820
on making sure that whatever we spend energy on

160
00:06:13,820 --> 00:06:17,500
is towards things that matter in an ethical way.

161
00:06:17,500 --> 00:06:20,460
I was always encouraged to find things

162
00:06:20,460 --> 00:06:23,980
that I'm passionate about and to use intellect

163
00:06:23,980 --> 00:06:26,940
and every other tool at my disposal

164
00:06:26,940 --> 00:06:28,180
to sort of get to the bottom of things.

165
00:06:28,180 --> 00:06:31,860
So we had lots of deep conversations

166
00:06:31,860 --> 00:06:33,860
about kind of the big questions

167
00:06:33,860 --> 00:06:36,380
and how they might be addressed.

168
00:06:36,380 --> 00:06:38,060
The question, how do you know,

169
00:06:38,060 --> 00:06:40,620
what figure prominently in my childhood?

170
00:06:41,500 --> 00:06:42,820
So we're always encouraged to think

171
00:06:42,820 --> 00:06:44,100
about those kinds of things.

172
00:06:44,100 --> 00:06:46,420
So that in the way I'm describing that naturalistic

173
00:06:46,420 --> 00:06:48,140
epistemology of using evidence and reason

174
00:06:48,140 --> 00:06:49,140
and sort of thinking things through

175
00:06:49,140 --> 00:06:51,740
and that inquiry was there for quite an early age,

176
00:06:51,740 --> 00:06:54,380
even within a family that sat within a broader

177
00:06:54,380 --> 00:06:58,700
sort of religiously defined community and culture, I guess.

178
00:06:58,700 --> 00:07:02,500
Yeah, yeah, but also to be clear that,

179
00:07:04,420 --> 00:07:08,380
there are many ways of enhancing wisdom

180
00:07:08,380 --> 00:07:09,620
or at least attempting to.

181
00:07:09,660 --> 00:07:13,100
And so rationality is an amazing tool,

182
00:07:13,100 --> 00:07:16,340
but one can also ask questions about its limitations

183
00:07:16,340 --> 00:07:18,820
and what other alternatives might be on offer

184
00:07:18,820 --> 00:07:22,020
and making sure that we understand

185
00:07:22,020 --> 00:07:24,100
but what are the things that we're not seeing?

186
00:07:24,100 --> 00:07:26,540
And it's sort of, there's an old saying that says,

187
00:07:26,540 --> 00:07:28,580
show me the net with which you're fishing

188
00:07:28,580 --> 00:07:30,140
and I'll tell you what you're not going to catch.

189
00:07:30,140 --> 00:07:33,340
I forget who said it, but that's that being,

190
00:07:33,340 --> 00:07:35,980
having that level of skepticism about the approaches

191
00:07:35,980 --> 00:07:37,700
you bring to a problem, whether that be

192
00:07:37,780 --> 00:07:40,740
different kinds of logic or whatever else,

193
00:07:40,740 --> 00:07:42,820
that was always emphasized as well.

194
00:07:42,820 --> 00:07:45,860
Yeah, and that if your choice of evidence

195
00:07:45,860 --> 00:07:48,300
or your choice of methods are too narrow,

196
00:07:48,300 --> 00:07:49,700
that can become its own dogma, as you say,

197
00:07:49,700 --> 00:07:53,460
you've got to be able to question those choices too.

198
00:07:53,460 --> 00:07:55,620
And part of the way I try and counter that

199
00:07:55,620 --> 00:07:57,620
is to talk about evidence and reason

200
00:07:57,620 --> 00:07:59,300
in a very broad sense.

201
00:07:59,300 --> 00:08:00,860
So some people will think of that as being

202
00:08:00,860 --> 00:08:03,020
a narrowly rational or empiric

203
00:08:03,020 --> 00:08:06,180
or even a scientific process that doesn't count as evidence

204
00:08:06,740 --> 00:08:08,620
until you've done a randomized control trial.

205
00:08:08,620 --> 00:08:10,100
And I don't think that in those terms at all,

206
00:08:10,100 --> 00:08:13,580
I think of evidence and reason in a very broad open sense

207
00:08:13,580 --> 00:08:16,060
that can include the experience from our senses,

208
00:08:16,060 --> 00:08:18,660
our subjective experience, you know,

209
00:08:18,660 --> 00:08:19,660
how a weird those might be.

210
00:08:19,660 --> 00:08:21,260
I think those are all types of evidence too.

211
00:08:21,260 --> 00:08:22,460
We can be skeptical of them,

212
00:08:22,460 --> 00:08:25,260
but I think that broad conception of naturalism

213
00:08:25,260 --> 00:08:26,700
is something I'm much more comfortable with

214
00:08:26,700 --> 00:08:29,540
than something that's really narrowly

215
00:08:29,540 --> 00:08:31,980
scientific if you like, which can be,

216
00:08:31,980 --> 00:08:34,740
I think narrow down too, too early.

217
00:08:34,740 --> 00:08:39,220
And how did that sense of inquiry,

218
00:08:39,220 --> 00:08:41,380
but a broad sense of inquiry,

219
00:08:41,380 --> 00:08:44,180
shift your actual beliefs over time?

220
00:08:44,180 --> 00:08:45,940
Even when you're asking the awkward questions,

221
00:08:45,940 --> 00:08:48,940
did you still hold onto some of the supernatural beliefs

222
00:08:48,940 --> 00:08:50,060
anyway?

223
00:08:50,060 --> 00:08:52,700
Have those shifted over time?

224
00:08:52,700 --> 00:08:54,580
So I guess there's probably two linked questions there.

225
00:08:54,580 --> 00:08:56,860
How do you think about the possibility

226
00:08:56,860 --> 00:08:59,740
of some of those supernatural constructs now,

227
00:08:59,740 --> 00:09:01,700
gods and souls and spirits?

228
00:09:01,700 --> 00:09:04,740
And is your sense of those still lead

229
00:09:04,740 --> 00:09:07,300
to this inquiry and a naturalistic approach?

230
00:09:07,300 --> 00:09:09,460
Or do you sort of reserve certain areas of knowledge

231
00:09:09,460 --> 00:09:11,380
for different epistemologies

232
00:09:11,380 --> 00:09:14,340
that might be more faith-based or revelatory?

233
00:09:15,180 --> 00:09:17,580
Yeah, I mean, I think that to me too,

234
00:09:17,580 --> 00:09:20,780
I pretty much, I think I pretty much only have one

235
00:09:20,780 --> 00:09:22,860
supernatural belief, which is that

236
00:09:22,860 --> 00:09:25,420
the universe is understandable in some fashion,

237
00:09:25,420 --> 00:09:28,180
whatever that may mean to be understood

238
00:09:28,180 --> 00:09:31,100
and that we are at least to some extent capable

239
00:09:31,100 --> 00:09:34,540
of resonating with a fundamental principles

240
00:09:34,540 --> 00:09:38,060
that guide its development and therefore knowledge seeking

241
00:09:38,060 --> 00:09:40,260
and things like this are not hopeless.

242
00:09:40,260 --> 00:09:42,940
That I fully admit is a supernatural belief

243
00:09:42,940 --> 00:09:45,660
because that's the kind of thing you can't really get behind.

244
00:09:45,660 --> 00:09:47,540
But once you've taken that on,

245
00:09:47,540 --> 00:09:50,060
then everything else becomes possible.

246
00:09:50,060 --> 00:09:51,380
So I don't think anything,

247
00:09:51,380 --> 00:09:54,220
I can't think of anything that would be truly supernatural

248
00:09:54,220 --> 00:09:57,220
in the sense that it might be completely outside

249
00:09:57,220 --> 00:09:59,220
of current abilities to understand,

250
00:09:59,220 --> 00:10:01,380
maybe beyond current scientific formalisms,

251
00:10:01,380 --> 00:10:04,780
but also perhaps beyond our cognitive capacities.

252
00:10:04,780 --> 00:10:06,900
So all of us are finite beings,

253
00:10:06,900 --> 00:10:08,460
guaranteed there are going to be things

254
00:10:08,460 --> 00:10:10,700
that we are simply not capable of comprehending

255
00:10:10,700 --> 00:10:12,580
as well as we can comprehend other things.

256
00:10:12,580 --> 00:10:15,140
And so beyond that, I don't think anything

257
00:10:15,140 --> 00:10:16,660
is really supernatural.

258
00:10:16,660 --> 00:10:21,660
I think all of us are doing our best in cobbling together

259
00:10:23,300 --> 00:10:27,540
some kind of coherent understanding of the world

260
00:10:27,540 --> 00:10:28,780
and our place in it.

261
00:10:28,780 --> 00:10:31,460
And then the interesting empirical part

262
00:10:31,460 --> 00:10:34,220
is then you get to find out how well it's working for you.

263
00:10:34,220 --> 00:10:36,380
So not just in the narrow scientific sense

264
00:10:36,380 --> 00:10:38,860
of specific paradigms that help you do experiments

265
00:10:38,860 --> 00:10:40,580
and make predictions and things like that,

266
00:10:40,580 --> 00:10:44,100
but the same idea applied to one's life.

267
00:10:44,100 --> 00:10:46,280
And so you have various outlooks

268
00:10:46,280 --> 00:10:48,420
that you might take on various frameworks

269
00:10:48,420 --> 00:10:50,420
and then you have to ask yourself,

270
00:10:50,420 --> 00:10:52,340
so how is this working out?

271
00:10:52,340 --> 00:10:54,980
Is this helping me have a more meaningful life?

272
00:10:54,980 --> 00:10:58,300
Is it helping me be a more ethical person

273
00:10:58,300 --> 00:11:01,220
to have better relationships with others?

274
00:11:01,220 --> 00:11:02,340
Those are the kinds of things

275
00:11:02,340 --> 00:11:04,660
that are not specifically sort of scientific outcomes,

276
00:11:04,660 --> 00:11:06,180
but the process is exactly the same.

277
00:11:06,180 --> 00:11:08,980
You examine your framing and you ask yourself,

278
00:11:08,980 --> 00:11:12,140
are there ways to tune that framing to do better,

279
00:11:12,140 --> 00:11:14,020
to have a better experience with others?

280
00:11:14,020 --> 00:11:14,860
Yeah, thank you.

281
00:11:14,860 --> 00:11:16,740
And I quite like describing this naturalistic approach

282
00:11:16,740 --> 00:11:21,140
as being just an attempt to honestly engage with reality

283
00:11:21,140 --> 00:11:23,020
and an attempt to understand it.

284
00:11:23,020 --> 00:11:24,940
And that understanding will always be partial

285
00:11:24,940 --> 00:11:26,500
and probabilistic and provisional

286
00:11:26,500 --> 00:11:28,500
and uncertain and open to revision.

287
00:11:28,500 --> 00:11:30,980
But I guess that's an interesting way of putting it.

288
00:11:30,980 --> 00:11:33,940
It's not just about, does the evidence start

289
00:11:33,940 --> 00:11:37,380
with my hypothesis, it's also how does the application

290
00:11:37,380 --> 00:11:39,740
of this knowledge or these beliefs actually work

291
00:11:39,740 --> 00:11:41,300
for me in practical terms,

292
00:11:41,300 --> 00:11:43,780
whether they're my life or engineering context.

293
00:11:43,780 --> 00:11:44,940
So yeah, thank you.

294
00:11:44,940 --> 00:11:47,460
Yeah, it became pretty clear early on

295
00:11:47,460 --> 00:11:51,420
that how one looks at data or at life

296
00:11:51,420 --> 00:11:54,780
or at anything else is a very strong determined

297
00:11:54,820 --> 00:11:57,980
of how one is going to interpret everything that happens.

298
00:11:57,980 --> 00:12:02,060
And these kind of frames are, they drive what happens next

299
00:12:02,060 --> 00:12:05,340
and they drive the kinds of things

300
00:12:05,340 --> 00:12:07,420
that become possible for you or impossible.

301
00:12:07,420 --> 00:12:11,380
You know, they determine which things are facilitated

302
00:12:11,380 --> 00:12:13,500
and which things are constrained.

303
00:12:13,500 --> 00:12:17,580
And so that aspect of it being really in control

304
00:12:17,580 --> 00:12:22,380
of how you interpret things, I think is really important.

305
00:12:22,380 --> 00:12:24,060
Yeah, thank you.

306
00:12:24,060 --> 00:12:26,900
And if we narrow down now, I think of, I guess,

307
00:12:26,900 --> 00:12:29,260
the scientific pursuit as being a subset of naturalism,

308
00:12:29,260 --> 00:12:32,620
it's the sort of a formalized way of doing that.

309
00:12:32,620 --> 00:12:36,700
And your focus is in the field of biology.

310
00:12:36,700 --> 00:12:38,420
And it's been, it's fascinating

311
00:12:38,420 --> 00:12:40,820
because I think for most people with their memory

312
00:12:40,820 --> 00:12:42,620
of the sort of high school sense

313
00:12:42,620 --> 00:12:44,940
of what biology is involved in,

314
00:12:44,940 --> 00:12:49,020
you've been taking the field in very different ways,

315
00:12:49,020 --> 00:12:53,060
although some of the different ways have quite old roots too.

316
00:12:53,060 --> 00:12:56,100
How have you come to understand biology as a field,

317
00:12:56,100 --> 00:12:58,500
writ large, and what are the sort of distinctive angles

318
00:12:58,500 --> 00:13:00,300
that you've been trying to develop,

319
00:13:00,300 --> 00:13:02,860
particularly as you think about

320
00:13:02,860 --> 00:13:05,700
one of the introductory comments on your lab's website

321
00:13:05,700 --> 00:13:08,860
talks about this fascination with the fact

322
00:13:08,860 --> 00:13:12,660
that all of us have gone from matter to mind in some sense.

323
00:13:12,660 --> 00:13:16,860
Yeah, I don't really think of myself as a biologist.

324
00:13:16,860 --> 00:13:20,100
I mean, we certainly do biology in my lab,

325
00:13:20,140 --> 00:13:21,460
among other things,

326
00:13:21,460 --> 00:13:26,460
but my fundamental commitment in my career and my life

327
00:13:27,260 --> 00:13:29,940
basically has been to understand embodied mind.

328
00:13:29,940 --> 00:13:33,100
So I've got this mind map that I print out every once a year,

329
00:13:33,100 --> 00:13:35,020
I refresh it and print it out every once in a while

330
00:13:35,020 --> 00:13:36,460
and it hangs in the lab.

331
00:13:36,460 --> 00:13:38,460
And it's about nine feet wide,

332
00:13:38,460 --> 00:13:39,900
this big kind of poster thing.

333
00:13:39,900 --> 00:13:40,860
And in the middle of it,

334
00:13:40,860 --> 00:13:45,380
the root node of this mind map is embodied mind.

335
00:13:45,380 --> 00:13:46,540
That's really what I'm interested in.

336
00:13:46,580 --> 00:13:50,060
I'm interested in cognition, intelligence,

337
00:13:50,060 --> 00:13:54,780
and inner perspective in a wide range of diverse systems,

338
00:13:54,780 --> 00:13:56,980
some of which we would call alive nowadays.

339
00:13:56,980 --> 00:13:58,940
I actually spend very little time

340
00:13:58,940 --> 00:14:00,580
figuring out a definition of life,

341
00:14:00,580 --> 00:14:02,380
although if you want, we can talk about it,

342
00:14:02,380 --> 00:14:04,700
but I don't worry about it too much at all.

343
00:14:04,700 --> 00:14:06,660
I'm interested in the things

344
00:14:06,660 --> 00:14:09,060
that all cognitive agents have in common.

345
00:14:09,060 --> 00:14:10,980
I'm interested in the scaling of mind

346
00:14:10,980 --> 00:14:15,820
from its most sort of primitive and humble examples

347
00:14:16,580 --> 00:14:17,420
in the world,

348
00:14:17,420 --> 00:14:19,420
which I don't think anybody would call alive necessarily,

349
00:14:19,420 --> 00:14:22,260
but I think cognition is broader than life,

350
00:14:22,260 --> 00:14:24,140
broader category than life.

351
00:14:24,140 --> 00:14:26,980
And yeah, and that's what we're interested in now.

352
00:14:26,980 --> 00:14:29,740
Now it just so happens that life is our best example

353
00:14:29,740 --> 00:14:33,140
of so far of how that gets scaled.

354
00:14:33,140 --> 00:14:35,540
So we do a lot of work in our lab

355
00:14:35,540 --> 00:14:38,940
using the phenomenon of molecular networks,

356
00:14:38,940 --> 00:14:41,420
scaling into cells, scaling into tissues,

357
00:14:41,420 --> 00:14:42,820
scaling into organisms,

358
00:14:42,820 --> 00:14:44,820
and beyond as an example

359
00:14:44,820 --> 00:14:47,340
of how to understand collective intelligence,

360
00:14:47,340 --> 00:14:49,460
how to communicate and ethically relate to those

361
00:14:49,460 --> 00:14:51,380
that collective intelligence is,

362
00:14:51,380 --> 00:14:53,780
where do the goals of those collective intelligences come

363
00:14:53,780 --> 00:14:55,260
from and so on.

364
00:14:55,260 --> 00:14:58,220
So biology is an excellent playground

365
00:14:58,220 --> 00:14:59,260
for these kinds of things,

366
00:14:59,260 --> 00:15:02,300
but I actually think the question is bigger than that.

367
00:15:02,300 --> 00:15:03,260
Yeah, thank you.

368
00:15:03,260 --> 00:15:06,220
And the, again, the sort of high school,

369
00:15:06,220 --> 00:15:07,580
and when I talk about it in the third person,

370
00:15:07,580 --> 00:15:10,140
it's really my high school sense of these things,

371
00:15:11,140 --> 00:15:13,820
it does reflect this sense

372
00:15:13,820 --> 00:15:17,180
that there are different scales of reality,

373
00:15:17,180 --> 00:15:19,500
and you're interestingly trying to span them

374
00:15:19,500 --> 00:15:21,780
and work across them and look at some phenomena

375
00:15:21,780 --> 00:15:24,020
that may be scale free in some sense.

376
00:15:24,020 --> 00:15:26,300
But I guess you can start,

377
00:15:26,300 --> 00:15:27,900
you can think about the fundamentals of physics,

378
00:15:27,900 --> 00:15:30,740
whether those are fields or fluctuations

379
00:15:30,740 --> 00:15:32,180
in them represented as particles,

380
00:15:32,180 --> 00:15:35,380
and you can come up through the different layers.

381
00:15:35,380 --> 00:15:36,980
For our purposes, I guess,

382
00:15:36,980 --> 00:15:39,300
where it starts to get useful,

383
00:15:39,300 --> 00:15:41,740
most people would think of life as being the point

384
00:15:41,740 --> 00:15:44,900
where we're getting into the realms

385
00:15:44,900 --> 00:15:46,940
of considering the possibility of mind,

386
00:15:46,940 --> 00:15:50,580
at least there are entities that are separated

387
00:15:50,580 --> 00:15:51,740
from their environment,

388
00:15:51,740 --> 00:15:55,300
that have some sort of evolutionary history

389
00:15:55,300 --> 00:15:58,740
that have some form of drive to live,

390
00:15:58,740 --> 00:16:00,140
but you've hinted there already,

391
00:16:00,140 --> 00:16:02,900
you don't necessarily find the concept of life

392
00:16:02,900 --> 00:16:04,100
that interesting,

393
00:16:04,100 --> 00:16:08,780
but then you can move through simple types of life

394
00:16:08,780 --> 00:16:12,340
in the earlier evolutionary stages,

395
00:16:12,340 --> 00:16:14,420
but also in the degree of complexity as well.

396
00:16:14,420 --> 00:16:17,740
So in our current panoply of living beings,

397
00:16:17,740 --> 00:16:20,980
very simple single-celled organisms,

398
00:16:20,980 --> 00:16:22,580
plants and fungi,

399
00:16:22,580 --> 00:16:25,300
and then it feels intuitively like we take another step

400
00:16:25,300 --> 00:16:27,420
on the cognition path

401
00:16:27,420 --> 00:16:29,980
when we're starting to think about animals as well.

402
00:16:29,980 --> 00:16:33,100
So as we're sort of working across that boundary

403
00:16:33,100 --> 00:16:36,660
from non-life to very simple life

404
00:16:36,660 --> 00:16:39,740
through to plants, fungi, and the simplest animals,

405
00:16:40,660 --> 00:16:45,340
where do you see this idea of cognition emerging?

406
00:16:45,340 --> 00:16:46,620
Where did it come from?

407
00:16:46,620 --> 00:16:48,220
And I guess, what is it?

408
00:16:48,220 --> 00:16:49,380
But as one of the things I find interesting

409
00:16:49,380 --> 00:16:51,220
in at least your public writing

410
00:16:51,220 --> 00:16:52,820
is that sometimes it does feel like

411
00:16:52,820 --> 00:16:54,780
there's a little bit of slippage in the term

412
00:16:54,780 --> 00:16:57,940
because sometimes cognition feels like

413
00:16:57,940 --> 00:17:00,940
something that's more narrowly computational.

414
00:17:00,940 --> 00:17:02,740
You know, it's something that maybe my spreadsheet

415
00:17:02,740 --> 00:17:04,140
on a laptop could be doing,

416
00:17:04,140 --> 00:17:06,380
but sometimes there is an implication of mind

417
00:17:06,380 --> 00:17:09,780
and a subjective perspective

418
00:17:09,780 --> 00:17:11,420
in the way you talk about cognition as well.

419
00:17:11,420 --> 00:17:14,020
So I should ask a better question than that,

420
00:17:14,020 --> 00:17:18,340
but in that sort of space of simpler living organisms,

421
00:17:18,340 --> 00:17:21,260
how does cognition emerge and what do you think of?

422
00:17:21,260 --> 00:17:23,380
It is in its simplest terms.

423
00:17:23,380 --> 00:17:27,060
Yeah, so here's how I think about these things.

424
00:17:29,580 --> 00:17:33,020
All of these cognitive claims, in other words,

425
00:17:33,020 --> 00:17:36,100
where you think something is on the spectrum of cognition,

426
00:17:36,340 --> 00:17:37,820
how much mind and all of that,

427
00:17:37,820 --> 00:17:40,820
I don't think these are terms describing particular systems.

428
00:17:40,820 --> 00:17:42,300
I think these are terms describing

429
00:17:42,300 --> 00:17:44,620
our intended relationship to them.

430
00:17:44,620 --> 00:17:47,860
So I don't think any of this is about the system itself.

431
00:17:47,860 --> 00:17:50,380
It's when you make a cognitive claim about something,

432
00:17:50,380 --> 00:17:53,340
you say this system is at the level of whatever,

433
00:17:53,340 --> 00:17:54,340
which you're really telling me

434
00:17:54,340 --> 00:17:56,740
is an engineering interaction protocol.

435
00:17:56,740 --> 00:17:59,420
You're telling me what your viewpoint on that system is

436
00:17:59,420 --> 00:18:00,820
and that viewpoint is gonna determine

437
00:18:00,820 --> 00:18:02,180
how you interact with it.

438
00:18:02,180 --> 00:18:04,660
So I'll give you a simple example.

439
00:18:04,660 --> 00:18:08,180
People argue all the time about whether humans are machines.

440
00:18:08,180 --> 00:18:09,860
And now this is a long conversation

441
00:18:09,860 --> 00:18:11,020
because you have to define machine,

442
00:18:11,020 --> 00:18:12,180
you have to define human and all that,

443
00:18:12,180 --> 00:18:15,500
but if you have an orthopedic surgeon

444
00:18:15,500 --> 00:18:18,300
who does not believe you are a machine, you're in trouble.

445
00:18:18,300 --> 00:18:20,740
You need to find a different orthopedic surgeon.

446
00:18:20,740 --> 00:18:22,900
If you have a spouse or a psychotherapist

447
00:18:22,900 --> 00:18:25,420
who thinks you're a simple machine, you're also in trouble.

448
00:18:25,420 --> 00:18:29,100
Not a great fit there.

449
00:18:29,100 --> 00:18:31,100
There are plenty of supposed doctors out there

450
00:18:31,100 --> 00:18:33,180
who think you're a fluctuation in the cosmic

451
00:18:33,220 --> 00:18:35,700
on some wide vibrations, so yeah.

452
00:18:35,700 --> 00:18:38,340
Yeah, yeah, I mean, so my framework,

453
00:18:38,340 --> 00:18:40,060
so I'm working on this framework called TAME,

454
00:18:40,060 --> 00:18:42,500
T-A-M-E, Technological Approach to Mind Everywhere.

455
00:18:42,500 --> 00:18:45,020
And one of the main claims of this framework

456
00:18:45,020 --> 00:18:49,260
is that none of these things can be determined

457
00:18:49,260 --> 00:18:50,580
from a philosophical armchair.

458
00:18:50,580 --> 00:18:52,260
You can't just decide what things are,

459
00:18:52,260 --> 00:18:53,420
you have to do experiments.

460
00:18:53,420 --> 00:18:56,220
So if you think you're a quantum fluctuation,

461
00:18:56,220 --> 00:18:58,300
whatever, whatever, that's great.

462
00:18:58,300 --> 00:19:00,900
It's all open, it's a fine hypothesis.

463
00:19:00,900 --> 00:19:02,700
What has it done for you, right?

464
00:19:02,700 --> 00:19:03,860
Like what are the benefits?

465
00:19:03,860 --> 00:19:06,580
And so I think this is the difference

466
00:19:06,580 --> 00:19:09,060
between this kind of pluralistic view that I have

467
00:19:09,060 --> 00:19:11,740
where multiple observers can differ

468
00:19:11,740 --> 00:19:14,500
as to their assessment of any given system.

469
00:19:14,500 --> 00:19:16,180
That's what I believe,

470
00:19:16,180 --> 00:19:18,140
but it doesn't mean that anything goes

471
00:19:18,140 --> 00:19:21,220
because those observers can then compare,

472
00:19:21,220 --> 00:19:23,600
well, how well did that worldview work out for you?

473
00:19:23,600 --> 00:19:25,060
What has that enabled you to do?

474
00:19:25,060 --> 00:19:27,180
What has that enabled you to discover?

475
00:19:27,180 --> 00:19:30,340
How rich are your relationships with the various systems

476
00:19:30,340 --> 00:19:31,980
given the view that you have?

477
00:19:32,420 --> 00:19:34,380
So what you wanna do is you wanna get it right

478
00:19:34,380 --> 00:19:35,500
or at least optimize it.

479
00:19:35,500 --> 00:19:36,860
You don't wanna have false negatives

480
00:19:36,860 --> 00:19:40,500
where you attribute cognitive qualities to systems

481
00:19:40,500 --> 00:19:43,980
that where they don't give you any new purchase.

482
00:19:43,980 --> 00:19:48,980
So for example, kind of old school animist ideas

483
00:19:50,100 --> 00:19:51,740
where there's a spirit in every rock,

484
00:19:51,740 --> 00:19:54,700
it's a fine hypothesis, how has that worked out?

485
00:19:54,700 --> 00:19:55,900
What does that do for you?

486
00:19:55,900 --> 00:19:57,580
You need to do experiments and you need to show that,

487
00:19:57,580 --> 00:19:59,980
hey, by saying that this thing has goals,

488
00:19:59,980 --> 00:20:01,960
it has learning capacity, it has whatever,

489
00:20:01,960 --> 00:20:03,420
this is now what I'm able to do.

490
00:20:03,420 --> 00:20:07,320
I'm able to either make better prediction and control

491
00:20:07,320 --> 00:20:11,360
or we're having a more richer interpersonal experience

492
00:20:11,360 --> 00:20:12,200
or something.

493
00:20:12,200 --> 00:20:15,100
So all of these things need to be empirically testable.

494
00:20:15,100 --> 00:20:20,100
So in this framework, your spreadsheet may or may not

495
00:20:20,760 --> 00:20:24,360
be doing some of the things that are tractable

496
00:20:24,360 --> 00:20:26,520
using the tools of cognitive science,

497
00:20:26,520 --> 00:20:29,080
for a spreadsheet probably not, but you'd be surprised.

498
00:20:29,080 --> 00:20:31,120
The thing about treating these things

499
00:20:31,240 --> 00:20:33,200
as empirical questions, not philosophy,

500
00:20:33,200 --> 00:20:34,880
is that you are often surprised,

501
00:20:34,880 --> 00:20:36,800
which is what is good about science,

502
00:20:36,800 --> 00:20:39,200
is that when you were surprised,

503
00:20:39,200 --> 00:20:41,000
that that's an opportunity to learn.

504
00:20:41,000 --> 00:20:44,480
And so what I think all of these cognitive claims really are

505
00:20:44,480 --> 00:20:48,080
are hypotheses about which set of tools

506
00:20:48,080 --> 00:20:49,040
am I going to apply?

507
00:20:49,040 --> 00:20:51,280
So am I going to apply the tools of physics

508
00:20:51,280 --> 00:20:52,280
and simple engineering?

509
00:20:52,280 --> 00:20:54,760
Am I going to apply the tool of cybernetics

510
00:20:54,760 --> 00:20:56,800
and control theory, the tools of behaviorism

511
00:20:56,800 --> 00:21:01,800
and learning and training and things like that,

512
00:21:01,840 --> 00:21:05,640
or the tools of communication and psychoanalysis

513
00:21:05,640 --> 00:21:07,480
and love and all these other things.

514
00:21:07,480 --> 00:21:10,080
So the thing is that when you treat that

515
00:21:10,080 --> 00:21:12,960
as an empirical question, you get to do experiments

516
00:21:12,960 --> 00:21:13,800
and you get to be surprised.

517
00:21:13,800 --> 00:21:18,640
So for example, we have found that very simple systems

518
00:21:18,640 --> 00:21:21,000
that represent gene regulatory networks,

519
00:21:21,000 --> 00:21:23,260
so just small numbers of chemicals

520
00:21:23,260 --> 00:21:25,000
that turn each other on and off, that's it.

521
00:21:25,040 --> 00:21:30,280
No cell, no indeterminism, no magic,

522
00:21:30,280 --> 00:21:33,040
just differential equations of describing

523
00:21:33,040 --> 00:21:35,360
how genes turn each other on and off.

524
00:21:35,360 --> 00:21:38,080
That system, which most people would assume

525
00:21:38,080 --> 00:21:40,560
is has zero cognition, they would say,

526
00:21:40,560 --> 00:21:43,160
well, that's a very mechanical, it's justice.

527
00:21:43,160 --> 00:21:44,920
As people say, it's just obeying the laws

528
00:21:44,920 --> 00:21:46,640
of physics and chemistry.

529
00:21:46,640 --> 00:21:47,840
That turns out-

530
00:21:47,840 --> 00:21:49,360
There's a lot in that, just.

531
00:21:49,360 --> 00:21:52,560
Yeah, right, I mean, I really hate that framing,

532
00:21:52,560 --> 00:21:54,200
but that's what people often say.

533
00:21:54,200 --> 00:21:56,160
That system by itself is capable

534
00:21:56,160 --> 00:21:57,480
of six different kinds of learning,

535
00:21:57,480 --> 00:21:59,880
including Pavlovian conditioning, just there.

536
00:21:59,880 --> 00:22:01,120
So with nothing else.

537
00:22:01,120 --> 00:22:04,800
We've also done work on sorting algorithms.

538
00:22:04,800 --> 00:22:08,400
So these are extremely simple, deterministic,

539
00:22:08,400 --> 00:22:10,320
fully transparent algorithms that people

540
00:22:10,320 --> 00:22:11,680
in computer science have been studying

541
00:22:11,680 --> 00:22:14,360
for, I don't know, 60 years or longer,

542
00:22:14,360 --> 00:22:15,800
things like bubble sort and so on.

543
00:22:15,800 --> 00:22:19,200
Even those things, when you probe them the right way,

544
00:22:19,200 --> 00:22:21,600
show novel problem-solving capacities

545
00:22:21,680 --> 00:22:25,000
and behaviors that are not in the algorithm themselves.

546
00:22:25,000 --> 00:22:27,880
So what I am taking from all of this

547
00:22:27,880 --> 00:22:30,720
is that we really need a sense of humility

548
00:22:30,720 --> 00:22:32,680
about what things can do

549
00:22:32,680 --> 00:22:36,640
and what kinds of tools are best appropriate for them.

550
00:22:36,640 --> 00:22:37,480
You don't know.

551
00:22:37,480 --> 00:22:38,880
We are not good at guessing.

552
00:22:38,880 --> 00:22:41,480
We think we are, and people assume this all the time,

553
00:22:41,480 --> 00:22:42,640
but we're not good at guessing.

554
00:22:42,640 --> 00:22:44,080
And so we need a mature science.

555
00:22:44,080 --> 00:22:47,160
So this is, if I had to pick one field

556
00:22:47,160 --> 00:22:49,360
that I think I work in, it's diverse intelligence research.

557
00:22:49,360 --> 00:22:50,400
That's what I think we do.

558
00:22:50,960 --> 00:22:52,920
We are trying to develop principle frameworks

559
00:22:52,920 --> 00:22:57,720
for really knowing which kinds of cognitive tools,

560
00:22:57,720 --> 00:22:59,680
which scale of cognitive tools are appropriate

561
00:22:59,680 --> 00:23:01,160
for various systems.

562
00:23:01,160 --> 00:23:04,800
And we're just not very good at guessing

563
00:23:04,800 --> 00:23:05,760
from the beginning.

564
00:23:05,760 --> 00:23:06,600
Yeah, thank you.

565
00:23:06,600 --> 00:23:09,320
And intelligence, I think, again,

566
00:23:09,320 --> 00:23:12,440
you can spend three hours talking about definitions of it,

567
00:23:12,440 --> 00:23:14,200
but I think many people would talk about it

568
00:23:14,200 --> 00:23:17,560
in simple terms as being the capacity to solve problems,

569
00:23:17,560 --> 00:23:19,400
which is something that could be done

570
00:23:19,400 --> 00:23:22,880
without mind and without subjectivity

571
00:23:22,880 --> 00:23:24,360
and without feeling,

572
00:23:24,360 --> 00:23:28,800
whereas cognition or maybe, again,

573
00:23:28,800 --> 00:23:31,440
you're gonna tell me that these distinctions are

574
00:23:31,440 --> 00:23:35,000
maybe not even well posed.

575
00:23:35,920 --> 00:23:38,680
Yeah, so let's break it down a little bit.

576
00:23:38,680 --> 00:23:40,920
So intelligence, I agree with you

577
00:23:40,920 --> 00:23:42,640
that a good definition of intelligence

578
00:23:42,640 --> 00:23:44,080
has to do with problem solving.

579
00:23:44,080 --> 00:23:45,720
Now, I'm not claiming that problem solving

580
00:23:45,760 --> 00:23:48,280
encompasses everything that's interesting about cognition.

581
00:23:48,280 --> 00:23:52,160
There are other things that are not about problem solving,

582
00:23:52,160 --> 00:23:53,920
but problem solving is good

583
00:23:53,920 --> 00:23:55,640
because it's publicly observable.

584
00:23:55,640 --> 00:23:57,760
It's a good scientific thing to study.

585
00:23:58,640 --> 00:24:03,280
And it's about competency in navigating some problem space.

586
00:24:03,280 --> 00:24:05,400
And there are many tools and tricks

587
00:24:05,400 --> 00:24:09,160
that the system can use to navigate that problem space.

588
00:24:09,160 --> 00:24:12,360
Now, the thing about inner perspective is this,

589
00:24:12,360 --> 00:24:15,120
which is, and at this point,

590
00:24:15,120 --> 00:24:17,960
I'm not talking about the hard problem of consciousness.

591
00:24:17,960 --> 00:24:19,600
We can sort of talk about that separately,

592
00:24:19,600 --> 00:24:22,960
but here's the thing about inner perspective.

593
00:24:22,960 --> 00:24:24,080
It's not a binary.

594
00:24:24,080 --> 00:24:26,600
I don't think any of these categories are usefully binary.

595
00:24:26,600 --> 00:24:29,800
What I think is important about inner perspective is this.

596
00:24:29,800 --> 00:24:31,200
For any kind of system,

597
00:24:31,200 --> 00:24:33,440
you want to be able to answer the question,

598
00:24:33,440 --> 00:24:37,160
how important is the system's perspective onto the world

599
00:24:37,160 --> 00:24:38,760
for me to understand what's happening?

600
00:24:38,760 --> 00:24:40,880
So let's make a, let's do, we have a simple example.

601
00:24:40,880 --> 00:24:43,560
I suppose you have a bowling ball on a hilly landscape.

602
00:24:43,560 --> 00:24:44,880
So you've got this energy landscape,

603
00:24:44,880 --> 00:24:47,000
you've got bumps and valleys and you've got a bowling ball.

604
00:24:47,000 --> 00:24:49,400
If you want to know what that bowling ball is going to do,

605
00:24:49,400 --> 00:24:52,320
your view as a third party observer to this

606
00:24:52,320 --> 00:24:53,880
as an external observer,

607
00:24:53,880 --> 00:24:56,720
your view of the landscape tells the whole story.

608
00:24:56,720 --> 00:24:57,600
Okay, there's nothing more.

609
00:24:57,600 --> 00:24:58,720
You don't need anything else.

610
00:24:58,720 --> 00:25:01,760
You will have everything you need to know

611
00:25:01,760 --> 00:25:02,920
to predict what's going to happen

612
00:25:02,920 --> 00:25:05,160
from your external view of the landscape.

613
00:25:05,160 --> 00:25:06,000
By the way-

614
00:25:06,000 --> 00:25:08,040
You don't need to imagine what it's like to be the ball.

615
00:25:08,040 --> 00:25:10,360
Well, that's the next step.

616
00:25:10,360 --> 00:25:12,320
That's the next step, which is that

617
00:25:12,320 --> 00:25:13,520
if you want to now know

618
00:25:13,520 --> 00:25:15,680
what a mouse is going to do on that landscape,

619
00:25:15,680 --> 00:25:17,040
your view of that landscape

620
00:25:17,040 --> 00:25:19,240
isn't really very interesting at all.

621
00:25:19,240 --> 00:25:20,960
The important thing, and it's not predictive of much,

622
00:25:20,960 --> 00:25:23,240
the important thing is the mouse's view of that landscape,

623
00:25:23,240 --> 00:25:26,080
because if it has an internal representation

624
00:25:26,080 --> 00:25:29,720
of the valence of different portions of that landscape,

625
00:25:29,720 --> 00:25:30,920
so rewards and punishments

626
00:25:30,920 --> 00:25:32,120
and which things are important to it

627
00:25:32,120 --> 00:25:33,720
and what attention it's paying and all that,

628
00:25:33,720 --> 00:25:36,960
the inner landscape of the mouse is the actual landscape

629
00:25:36,960 --> 00:25:38,760
that's going to determine what happens next,

630
00:25:38,760 --> 00:25:40,480
not your view of the landscape.

631
00:25:40,480 --> 00:25:43,840
So different kinds of systems

632
00:25:43,840 --> 00:25:46,320
have different degrees of representation

633
00:25:46,320 --> 00:25:47,480
of their outside world.

634
00:25:47,480 --> 00:25:49,720
It's not just brainy, smart animals that do this.

635
00:25:49,720 --> 00:25:52,240
All systems represent the world to some extent.

636
00:25:52,240 --> 00:25:53,680
And the question is how much?

637
00:25:53,680 --> 00:25:56,800
The question is how much do I need to worry about?

638
00:25:56,800 --> 00:25:59,800
And one way to sort of quantify this

639
00:25:59,800 --> 00:26:02,960
is in terms of the size of the cognitive light cone.

640
00:26:02,960 --> 00:26:05,160
So you can sort of ask for any given system,

641
00:26:05,160 --> 00:26:07,480
if you were to draw a space time,

642
00:26:07,520 --> 00:26:09,080
it's sort of a butchering of Minkowski's

643
00:26:09,080 --> 00:26:10,600
space time cone diagrams,

644
00:26:10,600 --> 00:26:13,480
you can draw a little diagram that says,

645
00:26:13,480 --> 00:26:16,400
what are the events both back in time and forward,

646
00:26:16,400 --> 00:26:17,760
because some systems anticipate,

647
00:26:17,760 --> 00:26:20,760
so both back in time and forward in time and spatially,

648
00:26:20,760 --> 00:26:22,200
what are the things you need to know

649
00:26:22,200 --> 00:26:25,800
to have a really rich relationship with the system,

650
00:26:25,800 --> 00:26:27,760
meaning prediction, control,

651
00:26:27,760 --> 00:26:28,920
something that benefits you,

652
00:26:28,920 --> 00:26:32,120
and in some cases, something that's ethical and all that.

653
00:26:32,120 --> 00:26:33,000
What do you need to know?

654
00:26:33,000 --> 00:26:36,120
So for a bowling ball, the cognitive light cone is tiny,

655
00:26:36,120 --> 00:26:37,640
because everything you need to know is right there.

656
00:26:37,640 --> 00:26:39,240
You add up all the pushes and pulls on it,

657
00:26:39,240 --> 00:26:42,000
you're more or less done.

658
00:26:42,000 --> 00:26:45,640
But once you start entering the systems

659
00:26:45,640 --> 00:26:47,240
that are even as simple as a collection

660
00:26:47,240 --> 00:26:49,200
of genes regulating each other,

661
00:26:49,200 --> 00:26:51,080
that's no longer satisfactory,

662
00:26:51,080 --> 00:26:52,920
because they learn from experience

663
00:26:52,920 --> 00:26:54,320
and things that have happened before

664
00:26:54,320 --> 00:26:56,880
are gonna make huge differences to what happens next.

665
00:26:56,880 --> 00:26:59,520
You cannot gain a full understanding of what's happening

666
00:26:59,520 --> 00:27:01,040
or to gain good control

667
00:27:01,040 --> 00:27:02,880
without understanding their inner perspective.

668
00:27:02,880 --> 00:27:07,320
So I think inner perspective is something

669
00:27:07,320 --> 00:27:09,840
that to some degree is wider than biology.

670
00:27:09,840 --> 00:27:11,520
I think what biology is really good at

671
00:27:11,520 --> 00:27:14,400
is scaling up these cognitive light cones.

672
00:27:14,400 --> 00:27:17,440
So in a rock, the cognitive light cone of the pieces,

673
00:27:17,440 --> 00:27:18,920
which by the way is not zero, it's very small,

674
00:27:18,920 --> 00:27:20,280
but I don't think it's zero,

675
00:27:21,440 --> 00:27:24,040
is not really summed up in the rock.

676
00:27:24,040 --> 00:27:25,680
The rock has exactly the same level

677
00:27:25,680 --> 00:27:27,320
of cognitive light cone as its pieces,

678
00:27:27,320 --> 00:27:29,400
but biology is super good.

679
00:27:29,400 --> 00:27:30,240
To say it another way,

680
00:27:31,160 --> 00:27:33,640
we call living things any system

681
00:27:33,640 --> 00:27:35,960
that's good at scaling up the cognitive light cone

682
00:27:35,960 --> 00:27:38,800
of its parts, it's going to look alive to us.

683
00:27:38,800 --> 00:27:40,520
And just the final kind of thing,

684
00:27:40,520 --> 00:27:43,120
which we'll probably get to again later

685
00:27:43,120 --> 00:27:45,760
in terms of what kind of world we want to live in,

686
00:27:45,760 --> 00:27:49,520
I think that evolution has no monopoly

687
00:27:49,520 --> 00:27:51,920
on producing cognition.

688
00:27:51,920 --> 00:27:53,080
In other words, up until now,

689
00:27:53,080 --> 00:27:54,800
yes, that's probably, at least on Earth,

690
00:27:54,800 --> 00:27:56,960
that's probably mostly where cognition came from,

691
00:27:56,960 --> 00:28:00,720
is from the fumblings of mutation of selection

692
00:28:00,720 --> 00:28:02,320
and of some other things.

693
00:28:02,320 --> 00:28:04,520
But I don't think intrinsically,

694
00:28:04,520 --> 00:28:07,040
that's where cognition has to come from.

695
00:28:07,040 --> 00:28:08,760
I don't see any reason whatsoever

696
00:28:08,760 --> 00:28:12,600
why the rational efforts of other cognitive agents,

697
00:28:12,600 --> 00:28:17,160
such as ourselves, couldn't make new minds going forward.

698
00:28:17,160 --> 00:28:18,160
Yeah, thank you.

699
00:28:18,160 --> 00:28:19,560
Yeah, we get to dig into that.

700
00:28:19,560 --> 00:28:23,680
And the point you mentioned about the approach to genetics

701
00:28:23,680 --> 00:28:25,360
is one of the things that you've helped

702
00:28:25,760 --> 00:28:26,960
radicalize this view,

703
00:28:26,960 --> 00:28:30,480
this simplistic view that DNA is some form of blueprint

704
00:28:30,480 --> 00:28:33,280
where you programmatically and linearly follow it.

705
00:28:33,280 --> 00:28:34,600
And that's one of the things

706
00:28:34,600 --> 00:28:37,400
as I understand your work has radically opened up.

707
00:28:37,400 --> 00:28:38,600
It's nowhere near that simple.

708
00:28:38,600 --> 00:28:41,480
It's much more about systems interacting

709
00:28:41,480 --> 00:28:43,880
and memory can be held in different forms and so on.

710
00:28:43,880 --> 00:28:47,720
So yeah, it's broadened out that view.

711
00:28:47,720 --> 00:28:50,320
And as we're sort of moving further up

712
00:28:52,040 --> 00:28:53,960
the scale, if there is such a scale,

713
00:28:54,960 --> 00:28:57,440
one of the things I've heard you resist before

714
00:28:57,440 --> 00:28:59,120
as you are here in a way

715
00:29:00,480 --> 00:29:02,840
is this idea of really clear binary concepts,

716
00:29:02,840 --> 00:29:05,560
concepts like sentience and consciousness

717
00:29:05,560 --> 00:29:10,160
that try to take ideas like cognition

718
00:29:10,160 --> 00:29:15,000
and map them onto this intuitive sense that we have,

719
00:29:15,000 --> 00:29:19,000
that we are ineffable, distinct,

720
00:29:19,000 --> 00:29:22,320
somehow unique entities

721
00:29:22,320 --> 00:29:24,680
that feel like we're separate.

722
00:29:24,680 --> 00:29:25,960
We're not just physics.

723
00:29:25,960 --> 00:29:29,920
And I empathize with that resistance

724
00:29:29,920 --> 00:29:33,480
because I think there's a danger in that intuition

725
00:29:33,480 --> 00:29:37,800
that we reify these ideas

726
00:29:37,800 --> 00:29:40,560
because they're obviously important to us intuitively.

727
00:29:40,560 --> 00:29:42,240
I can understand why anyone's consciousness

728
00:29:42,240 --> 00:29:43,080
will be important to them.

729
00:29:43,080 --> 00:29:44,520
Ultimately, it's all they experience, right?

730
00:29:44,520 --> 00:29:46,360
And everything we experience comes through the consciousness.

731
00:29:46,360 --> 00:29:48,480
But there's a danger in reifying that,

732
00:29:48,480 --> 00:29:50,320
you take it away from just being physics

733
00:29:50,320 --> 00:29:51,920
because ultimately I think I share your view

734
00:29:52,680 --> 00:29:54,480
that just physics,

735
00:29:54,480 --> 00:29:57,560
we are all just part of the natural world all the way down.

736
00:29:57,560 --> 00:29:59,240
That doesn't mean these aren't interesting concepts,

737
00:29:59,240 --> 00:30:02,560
but they're not distinct from physical reality.

738
00:30:04,480 --> 00:30:06,320
But at the same time,

739
00:30:06,320 --> 00:30:09,600
I prefer not to put them completely to one side.

740
00:30:09,600 --> 00:30:13,240
And I think in the way you're describing,

741
00:30:13,240 --> 00:30:16,240
needing some sort of research concept

742
00:30:16,240 --> 00:30:20,840
or some concept of relationality

743
00:30:20,880 --> 00:30:23,680
can still provide at least a couple of reasons

744
00:30:23,680 --> 00:30:26,040
why it's important to still focus on ideas

745
00:30:26,040 --> 00:30:27,600
like sentience and consciousness.

746
00:30:27,600 --> 00:30:28,800
And I guess one,

747
00:30:28,800 --> 00:30:31,320
it came partly through my conversation with Mark Solms,

748
00:30:31,320 --> 00:30:33,080
who I know you spent a lot of quality time with.

749
00:30:33,080 --> 00:30:35,000
I've loved some of your discussions

750
00:30:35,000 --> 00:30:40,000
because part of the way he tells the story about evolution

751
00:30:40,040 --> 00:30:41,600
is that sentience,

752
00:30:41,600 --> 00:30:44,440
the capacity to actually experience a valence

753
00:30:44,440 --> 00:30:46,520
is one of the things that's probably driven

754
00:30:46,520 --> 00:30:50,200
the process of broader cognition

755
00:30:50,200 --> 00:30:52,520
and evolution in the first place.

756
00:30:52,520 --> 00:30:57,200
So he puts that concept or the ability to feel things,

757
00:30:57,200 --> 00:30:59,080
feel good, feel good, bad,

758
00:30:59,080 --> 00:31:02,600
how am I doing now in this environment as quite central?

759
00:31:02,600 --> 00:31:05,280
And I guess that's the way I think of sentience

760
00:31:05,280 --> 00:31:07,240
as being just that capacity to have an experience

761
00:31:07,240 --> 00:31:11,280
and to value it from yourself, whatever yourself is.

762
00:31:11,280 --> 00:31:12,560
But I guess another reason,

763
00:31:12,560 --> 00:31:14,760
another potential research project

764
00:31:14,800 --> 00:31:16,360
links to our next question,

765
00:31:16,360 --> 00:31:18,640
which is that these things also seem to have

766
00:31:18,640 --> 00:31:23,640
some quite deep moral or ethical significance too,

767
00:31:23,840 --> 00:31:26,360
in that, you know, and we'll come back to that.

768
00:31:26,360 --> 00:31:27,720
But I guess those are two of the reasons

769
00:31:27,720 --> 00:31:30,560
why those sometimes problematic concepts,

770
00:31:30,560 --> 00:31:35,200
and I certainly don't think they're binary in any sense.

771
00:31:35,200 --> 00:31:38,760
There's still a drive for us to understand and dig in.

772
00:31:40,240 --> 00:31:41,800
What do you think about those sorts of challenges about,

773
00:31:41,800 --> 00:31:43,560
you know, is there a,

774
00:31:43,560 --> 00:31:45,320
because you could go to a point of view

775
00:31:45,320 --> 00:31:49,320
where you never talk about sentience and consciousness

776
00:31:49,320 --> 00:31:53,320
or subjective experience in those senses at all,

777
00:31:53,320 --> 00:31:56,480
and you stick purely with a more neutral description

778
00:31:56,480 --> 00:32:01,480
of cognition and agent spaces and Markov blanket.

779
00:32:02,760 --> 00:32:07,360
Do you feel that there is some meaningful pull

780
00:32:07,360 --> 00:32:10,200
to delve into and better understand those ideas

781
00:32:10,200 --> 00:32:12,120
of sentience and consciousness in their own right,

782
00:32:12,120 --> 00:32:12,960
or how do you think of this?

783
00:32:13,800 --> 00:32:16,520
Well, I think those are essential.

784
00:32:16,520 --> 00:32:21,520
My resistance to binary categories is not to,

785
00:32:21,880 --> 00:32:25,360
you know, kind of reduce these aspects

786
00:32:25,360 --> 00:32:26,720
that you're talking about at all.

787
00:32:26,720 --> 00:32:29,280
It's to, on the contrary,

788
00:32:29,280 --> 00:32:31,640
it's to have a better understanding of them

789
00:32:31,640 --> 00:32:32,760
and their potential.

790
00:32:32,760 --> 00:32:35,680
You know, I get a lot of pushback from both directions.

791
00:32:35,680 --> 00:32:37,960
So I get mechanistic, you know,

792
00:32:37,960 --> 00:32:41,520
sort of supposedly reductionist scientists who say,

793
00:32:41,560 --> 00:32:42,640
well, this is crazy.

794
00:32:42,640 --> 00:32:46,520
You're painting feelings onto cells

795
00:32:46,520 --> 00:32:50,560
and chemistry is the best kind of explanation.

796
00:32:50,560 --> 00:32:52,000
You know, and that's not really reductionist

797
00:32:52,000 --> 00:32:54,080
because then if you say, well, you mean quantum foam,

798
00:32:54,080 --> 00:32:55,280
you want to talk about quantum foam,

799
00:32:55,280 --> 00:32:56,880
they say, nah, nah, nah, that's not it.

800
00:32:56,880 --> 00:32:58,280
It's chemistry, it's got to be chemistry.

801
00:32:58,280 --> 00:33:01,480
So they've picked the level, okay.

802
00:33:01,480 --> 00:33:05,120
But I also get a lot of flak from the organists,

803
00:33:05,120 --> 00:33:07,320
which, and I consider myself in the organist tradition,

804
00:33:07,320 --> 00:33:10,840
but who say, look, by putting non-living things

805
00:33:10,840 --> 00:33:13,520
on the other side, such as physical objects

806
00:33:13,520 --> 00:33:14,880
and computers and whatnot on that,

807
00:33:14,880 --> 00:33:16,480
somewhere on that spectrum,

808
00:33:16,480 --> 00:33:21,160
you're undermining this battle that we've had

809
00:33:21,160 --> 00:33:24,160
for hundreds of years to preserve the magic

810
00:33:24,160 --> 00:33:27,520
and the importance of life and of inner perspective

811
00:33:27,520 --> 00:33:28,360
and so on.

812
00:33:28,360 --> 00:33:30,040
I don't think understanding these things better

813
00:33:30,040 --> 00:33:33,840
and understanding how they scale up reduces the importance

814
00:33:33,840 --> 00:33:38,840
or the majesty of the obvious sentience of living beings.

815
00:33:38,920 --> 00:33:41,240
I think much like with any kind of science,

816
00:33:41,240 --> 00:33:43,000
it helps us to understand what we are

817
00:33:43,000 --> 00:33:45,560
and what our potential is and what we need to do.

818
00:33:45,560 --> 00:33:49,880
I think that this weird obsession with chemistry

819
00:33:49,880 --> 00:33:54,880
and with physics too is what undermines the efforts

820
00:33:55,680 --> 00:33:56,760
to really understand this.

821
00:33:56,760 --> 00:34:00,560
And I'll give you a simple example, well, two examples.

822
00:34:00,560 --> 00:34:05,360
One is, I often hear people say this,

823
00:34:05,400 --> 00:34:10,040
that's not real goals,

824
00:34:10,040 --> 00:34:14,160
real preferences, real valence, real anything.

825
00:34:14,160 --> 00:34:16,840
That's just, it's just following the laws

826
00:34:16,840 --> 00:34:18,040
of physics and chemistry.

827
00:34:18,040 --> 00:34:18,880
Well, guess what?

828
00:34:18,880 --> 00:34:22,120
If you were to zoom in to your brain

829
00:34:22,120 --> 00:34:24,000
or the rest of your body, guess what you would find?

830
00:34:24,000 --> 00:34:24,840
You wouldn't find fairies,

831
00:34:24,840 --> 00:34:27,160
you would find physics and chemistry.

832
00:34:27,160 --> 00:34:28,000
So it's very-

833
00:34:28,000 --> 00:34:29,040
And even if you found fairies,

834
00:34:29,040 --> 00:34:30,440
they'd be following the laws of physics too.

835
00:34:30,440 --> 00:34:32,640
They would have to be following something, right?

836
00:34:32,640 --> 00:34:36,040
So I'm not against, if you have a model of,

837
00:34:36,040 --> 00:34:37,440
people sometimes email me,

838
00:34:37,440 --> 00:34:38,400
well, what about the soul?

839
00:34:38,400 --> 00:34:39,360
I say, bring it on.

840
00:34:39,360 --> 00:34:42,240
If you've got a model of the soul,

841
00:34:42,240 --> 00:34:45,840
explain how that works and how that solves these problems

842
00:34:45,840 --> 00:34:47,040
and we're good to go.

843
00:34:47,040 --> 00:34:49,000
The problem is, I've never seen such a model,

844
00:34:49,000 --> 00:34:52,240
but the question, I always bring it back

845
00:34:52,240 --> 00:34:55,800
to the paramecium or a single cell.

846
00:34:55,800 --> 00:34:57,920
Do you or do you not believe that that thing has

847
00:34:57,920 --> 00:35:01,720
to some small extent a preference about what happens?

848
00:35:01,720 --> 00:35:06,520
If you do, then we simply point out that,

849
00:35:06,520 --> 00:35:08,560
well, look, it's very clearly made

850
00:35:08,560 --> 00:35:11,120
of a set of interacting chemicals.

851
00:35:11,120 --> 00:35:12,800
At some point we'll be able to reconstitute one.

852
00:35:12,800 --> 00:35:14,280
So what's the issue?

853
00:35:14,280 --> 00:35:16,360
If you don't, then you have to explain to me

854
00:35:16,360 --> 00:35:18,120
what happens in embryonic development,

855
00:35:18,120 --> 00:35:20,360
where you actually go very slowly

856
00:35:20,360 --> 00:35:23,480
and gradually from a single cell

857
00:35:23,480 --> 00:35:25,440
into whatever it is that we are.

858
00:35:25,440 --> 00:35:27,480
And again, there is no magic lightning flash

859
00:35:27,480 --> 00:35:29,840
that converts the chemistry of the oocyte

860
00:35:29,880 --> 00:35:33,120
into the mind of the adult human.

861
00:35:33,120 --> 00:35:35,800
So this continuity, you can't escape it.

862
00:35:35,800 --> 00:35:38,640
What we owe is not a story about magic of bright lines,

863
00:35:38,640 --> 00:35:40,480
we owe a story about scaling.

864
00:35:40,480 --> 00:35:44,440
And the other thing that I think is really curious

865
00:35:44,440 --> 00:35:48,680
and it's kind of, I don't know if it's my bringing

866
00:35:48,680 --> 00:35:50,240
with too much science fiction or what,

867
00:35:50,240 --> 00:35:51,880
but I find it really amazing.

868
00:35:51,880 --> 00:35:53,680
There was a great scene in,

869
00:35:53,680 --> 00:35:56,160
there's a movie called Ex Machina, you know?

870
00:35:57,160 --> 00:35:58,960
And there's a great scene in that movie

871
00:35:58,960 --> 00:36:03,800
where the protagonist is now so confused by this AI

872
00:36:03,800 --> 00:36:04,920
that he's been dealing with it.

873
00:36:04,920 --> 00:36:06,200
He's standing there in front of a mirror

874
00:36:06,200 --> 00:36:08,760
and he starts cutting his hand because his arm,

875
00:36:08,760 --> 00:36:11,320
because he wants to see if he is a robot too, right?

876
00:36:11,320 --> 00:36:12,800
And it's very important to him.

877
00:36:12,800 --> 00:36:17,240
So this is critical to him, it's very stressful.

878
00:36:17,240 --> 00:36:19,840
And I get emails all the time also from people who say,

879
00:36:19,840 --> 00:36:22,200
I've read your paper, I understand now

880
00:36:22,200 --> 00:36:25,160
that I'm a walking bag of cells, now I'm depressed.

881
00:36:25,160 --> 00:36:27,880
I don't know what to do with myself, this is terrible, right?

882
00:36:27,880 --> 00:36:31,280
And let's just unpack this, this cutting your arm thing.

883
00:36:31,280 --> 00:36:35,200
So what that means is, if you were to find,

884
00:36:35,200 --> 00:36:36,360
so you cut open your arm

885
00:36:36,360 --> 00:36:38,240
and you find a bunch of cogs and gears,

886
00:36:38,240 --> 00:36:40,360
you've had, I don't know, 40, 50,

887
00:36:40,360 --> 00:36:43,800
however many years of experience in your own skin,

888
00:36:43,800 --> 00:36:47,800
being an agent, exerting effort towards various outcomes

889
00:36:47,800 --> 00:36:51,040
and having moral quandaries and having, you know,

890
00:36:51,040 --> 00:36:52,720
Qualey and all these things.

891
00:36:52,720 --> 00:36:54,760
And when you see those cogs and gears,

892
00:36:54,760 --> 00:36:58,360
what you're gonna decide is, none of that was real

893
00:36:58,360 --> 00:37:00,560
because I am committed to the idea

894
00:37:00,560 --> 00:37:02,800
that cogs and gears can't support it.

895
00:37:02,800 --> 00:37:04,760
This is so bizarre to me.

896
00:37:04,760 --> 00:37:06,800
And it's bizarre because we don't know

897
00:37:06,800 --> 00:37:08,960
what cogs and gears can and can't support.

898
00:37:08,960 --> 00:37:12,440
You know, why are you so attached to a protoplasm

899
00:37:12,440 --> 00:37:15,280
and proteins and whatever else is inside you

900
00:37:15,280 --> 00:37:17,920
over something else that you might find?

901
00:37:17,920 --> 00:37:19,920
What do you think you know about those things

902
00:37:19,920 --> 00:37:23,200
that overrides your primary experience as a human?

903
00:37:23,200 --> 00:37:25,080
It's just, it's amazing to me

904
00:37:25,080 --> 00:37:28,520
that what people naturally tend to say is,

905
00:37:28,520 --> 00:37:31,480
okay, well, then I guess I'm not real, I'm not important,

906
00:37:31,480 --> 00:37:34,080
I can't do all of the amazing things I was going to do

907
00:37:34,080 --> 00:37:36,320
versus, wow, I guess I just learned something great

908
00:37:36,320 --> 00:37:38,440
about cogs and gears, look at that.

909
00:37:38,440 --> 00:37:40,200
You know, I guess cogs and gears can do it,

910
00:37:40,200 --> 00:37:42,880
not too much more shocking than finding out the proteins

911
00:37:42,880 --> 00:37:45,640
and, you know, and carbohydrates and whatever else

912
00:37:45,640 --> 00:37:47,040
is in our bodies can do it.

913
00:37:47,040 --> 00:37:49,000
Yeah, and neurons firing, it's like.

914
00:37:49,000 --> 00:37:51,880
Yeah, yeah, but people are so committed

915
00:37:51,880 --> 00:37:56,400
to simple, well, to two things, to, first of all,

916
00:37:56,400 --> 00:37:59,720
to the idea that if your parts obey the laws of physics,

917
00:37:59,720 --> 00:38:02,680
then you are somehow reduced, which I think, you know,

918
00:38:02,680 --> 00:38:05,200
this allegiance to a low level of description,

919
00:38:05,200 --> 00:38:06,720
I think it's completely arbitrary.

920
00:38:06,720 --> 00:38:09,000
Dennis Noble does a really nice job in his work

921
00:38:09,000 --> 00:38:13,560
on against privileged levels of causation and things like that.

922
00:38:13,560 --> 00:38:18,080
And then the idea that we know what various kinds

923
00:38:18,080 --> 00:38:20,000
of materials and architectures can do,

924
00:38:20,040 --> 00:38:22,120
we have absolutely no idea.

925
00:38:22,120 --> 00:38:25,440
You know, we need, this actual field is at a,

926
00:38:25,440 --> 00:38:28,920
despite the rest of science is at a very young stage.

927
00:38:28,920 --> 00:38:30,920
We do not know, there are emergent,

928
00:38:30,920 --> 00:38:32,360
not just emergent complexity,

929
00:38:32,360 --> 00:38:34,480
so everybody studies emergent complexity,

930
00:38:34,480 --> 00:38:35,640
that's been around for a long time.

931
00:38:35,640 --> 00:38:37,000
It's not emergent complexity here,

932
00:38:37,000 --> 00:38:40,520
it's emergent goal-directedness and emergent cognition.

933
00:38:40,520 --> 00:38:42,840
And that happens and even in very simple systems,

934
00:38:42,840 --> 00:38:44,520
it surprises us constantly.

935
00:38:44,520 --> 00:38:45,880
We are not good at predicting it,

936
00:38:45,880 --> 00:38:48,200
we are not good at creating it yet.

937
00:38:48,200 --> 00:38:51,400
Well, I should say we may create it unwittingly all the time.

938
00:38:51,400 --> 00:38:53,120
And so people who say, you know,

939
00:38:53,120 --> 00:38:56,080
I know what this is because I made it,

940
00:38:56,080 --> 00:38:58,560
I think that's a really dangerous idea

941
00:38:58,560 --> 00:39:00,880
because you don't know what something is

942
00:39:00,880 --> 00:39:02,880
just because you made it or because,

943
00:39:02,880 --> 00:39:05,040
people say this a bunch of language models or whatever,

944
00:39:05,040 --> 00:39:07,480
just because you know the parts that went into it,

945
00:39:07,480 --> 00:39:09,720
we do not yet know what it is, what it can do

946
00:39:09,720 --> 00:39:11,960
and how important is the inner perspective

947
00:39:11,960 --> 00:39:13,960
and what kind of inner perspective it has.

948
00:39:13,960 --> 00:39:17,960
So yeah, I think a lot of humility here

949
00:39:17,960 --> 00:39:20,920
is needed and a letting go of this idea

950
00:39:20,920 --> 00:39:23,800
that the right level of description is chemistry.

951
00:39:23,800 --> 00:39:26,200
And you know, I think it's fine that that's there,

952
00:39:26,200 --> 00:39:29,360
it does not tell the whole story in any practical way.

953
00:39:29,360 --> 00:39:30,200
Yeah, thank you.

954
00:39:30,200 --> 00:39:32,360
You need to understand that these things run

955
00:39:32,360 --> 00:39:35,840
and operate at different levels and interlocking levels.

956
00:39:35,840 --> 00:39:39,560
Well, just very specifically,

957
00:39:39,560 --> 00:39:43,720
the business of physics and determinism, right?

958
00:39:43,720 --> 00:39:45,600
One of the key issues here is that

959
00:39:45,600 --> 00:39:47,920
determinism is well and good

960
00:39:47,920 --> 00:39:50,920
if what you're interested in doing is looking backwards.

961
00:39:50,920 --> 00:39:52,480
So something has happened

962
00:39:52,480 --> 00:39:54,880
and you're going to tell a mechanistic story

963
00:39:54,880 --> 00:39:55,720
of why it happened.

964
00:39:55,720 --> 00:39:56,640
And then you can always do that,

965
00:39:56,640 --> 00:39:57,480
that's always on the table.

966
00:39:57,480 --> 00:39:59,080
So you zoom down and you say, look,

967
00:39:59,080 --> 00:40:01,760
this person did that because these neurotransmitters

968
00:40:01,760 --> 00:40:03,920
zigged and zagged and they did that

969
00:40:03,920 --> 00:40:06,960
because of the electron forces and all of this stuff, right?

970
00:40:06,960 --> 00:40:09,680
You can always tell a story going backwards.

971
00:40:09,680 --> 00:40:11,240
But that isn't what we're interested in,

972
00:40:11,240 --> 00:40:13,120
both as humans and scientists,

973
00:40:13,120 --> 00:40:14,600
we're interested in going forwards

974
00:40:14,600 --> 00:40:17,080
as in what can and should I do next

975
00:40:17,080 --> 00:40:18,440
and what can I invent

976
00:40:18,440 --> 00:40:21,240
or how can I increase my understanding next?

977
00:40:21,240 --> 00:40:23,320
And that is a completely different kind of task.

978
00:40:23,320 --> 00:40:26,120
So here's one of my favorite examples.

979
00:40:26,120 --> 00:40:29,120
The game of life, cellular automaton, right?

980
00:40:29,120 --> 00:40:32,480
So you've got three simple rules that dictate

981
00:40:32,480 --> 00:40:35,640
how the state of each cell is going to be on or off

982
00:40:35,640 --> 00:40:37,160
based on what its neighbors do.

983
00:40:37,160 --> 00:40:38,000
Okay, so just-

984
00:40:38,000 --> 00:40:39,800
It's a simple two-dimensional grid, isn't it?

985
00:40:39,800 --> 00:40:41,440
Completely simple, yep.

986
00:40:41,440 --> 00:40:43,320
Super simple, two-dimensional grid

987
00:40:43,360 --> 00:40:46,960
the cells are on or off and it's fully deterministic.

988
00:40:46,960 --> 00:40:48,720
Okay, there's not even an ecstasy here.

989
00:40:48,720 --> 00:40:51,200
So every cell in every tick of the clock,

990
00:40:51,200 --> 00:40:53,840
each cell becomes on or off

991
00:40:53,840 --> 00:40:55,240
based on how many neighbors it has.

992
00:40:55,240 --> 00:40:56,080
That's it.

993
00:40:56,080 --> 00:40:58,960
Now, we know, and if anybody in the audience

994
00:40:58,960 --> 00:41:00,520
hasn't seen it, look it up

995
00:41:00,520 --> 00:41:02,920
and you can see these amazing things that happen, right?

996
00:41:02,920 --> 00:41:05,040
So emerging complexity is very strong here.

997
00:41:05,040 --> 00:41:06,200
And if anyone hasn't played with it,

998
00:41:06,200 --> 00:41:08,120
I'd recommend go and find some of the online tools

999
00:41:08,120 --> 00:41:10,160
because you can play with this stuff yourself.

1000
00:41:10,160 --> 00:41:11,440
It's mind-blowing, yeah.

1001
00:41:11,440 --> 00:41:13,320
Absolutely, absolutely amazing.

1002
00:41:13,320 --> 00:41:17,800
And so now, look, you can imagine being a reductionist

1003
00:41:17,800 --> 00:41:19,600
determinist about this world and say,

1004
00:41:19,600 --> 00:41:21,360
so for example, one of the things that happens

1005
00:41:21,360 --> 00:41:23,280
in this world is there are things called gliders.

1006
00:41:23,280 --> 00:41:26,200
So gliders are patterns that are a particular shape

1007
00:41:26,200 --> 00:41:27,600
and the shape moves across.

1008
00:41:27,600 --> 00:41:30,120
Now, to be clear, nothing actually moves across,

1009
00:41:30,120 --> 00:41:32,120
the cells are just turning on and off,

1010
00:41:32,120 --> 00:41:34,560
but the pattern itself, it's like a wave in the,

1011
00:41:34,560 --> 00:41:37,400
the pattern itself moves and those are called gliders.

1012
00:41:37,400 --> 00:41:40,280
So now you could be a reductionist about this

1013
00:41:40,280 --> 00:41:41,960
and you can say, look, there are no gliders.

1014
00:41:41,960 --> 00:41:43,760
All there is are the individual cells

1015
00:41:43,760 --> 00:41:45,480
and I can tell you precisely which cells

1016
00:41:45,480 --> 00:41:46,640
are gonna come on and off.

1017
00:41:46,640 --> 00:41:48,360
And the fact that you think you see gliders

1018
00:41:48,360 --> 00:41:50,440
is an epiphenomenon, it does nothing.

1019
00:41:50,440 --> 00:41:51,720
In the system, there are no gliders,

1020
00:41:51,720 --> 00:41:53,680
all it is is the rules.

1021
00:41:53,680 --> 00:41:55,240
And that isn't exactly wrong

1022
00:41:55,240 --> 00:41:57,400
because the physics of the world are quite clear,

1023
00:41:57,400 --> 00:41:59,680
but it's absolutely limiting in the following way.

1024
00:41:59,680 --> 00:42:01,640
If you don't believe in gliders,

1025
00:42:01,640 --> 00:42:05,360
you can predict the next state of whatever state

1026
00:42:05,360 --> 00:42:06,400
I set up in the game,

1027
00:42:06,400 --> 00:42:08,520
you can tell me exactly what's gonna happen next.

1028
00:42:08,560 --> 00:42:10,480
There's no escape from that level of determinism.

1029
00:42:10,480 --> 00:42:11,600
But here's what you won't ever do.

1030
00:42:11,600 --> 00:42:13,360
You won't ever build a Turing machine

1031
00:42:13,360 --> 00:42:15,280
made out of gliders as somebody did.

1032
00:42:15,280 --> 00:42:17,720
Somebody designed a pattern that does computations

1033
00:42:17,720 --> 00:42:19,840
by sending gliders back and forth.

1034
00:42:19,840 --> 00:42:21,840
If you don't believe in gliders, you're not gonna do that.

1035
00:42:21,840 --> 00:42:24,480
It closes off that level of inventiveness.

1036
00:42:24,480 --> 00:42:28,160
So looking, so a key thing about these higher levels

1037
00:42:28,160 --> 00:42:29,880
is that they enable you to have a more,

1038
00:42:29,880 --> 00:42:33,400
a richer relationship with the system going forward,

1039
00:42:33,400 --> 00:42:36,000
not just explain what happens backwards

1040
00:42:36,000 --> 00:42:37,640
after somebody's done the interesting work

1041
00:42:37,680 --> 00:42:39,360
of preparing a system for you.

1042
00:42:39,360 --> 00:42:40,680
Yeah, it's fascinating.

1043
00:42:40,680 --> 00:42:42,800
And the idea of a universal Turing machine

1044
00:42:42,800 --> 00:42:46,560
is essentially a computer

1045
00:42:46,560 --> 00:42:48,840
that can carry out any computation,

1046
00:42:48,840 --> 00:42:50,400
given enough time and enough resources.

1047
00:42:50,400 --> 00:42:53,320
So, and this is from individual cells,

1048
00:42:53,320 --> 00:42:56,600
linking on and off based on a super simple rule set

1049
00:42:56,600 --> 00:42:58,040
clicking forward all the time.

1050
00:42:58,040 --> 00:43:00,800
And the other, and I don't know if this is right,

1051
00:43:00,800 --> 00:43:04,800
but I like the difference between the side of determinism

1052
00:43:04,800 --> 00:43:06,080
looking backwards and looking forwards,

1053
00:43:06,080 --> 00:43:07,080
because in a sense,

1054
00:43:07,080 --> 00:43:10,280
it's the same deterministic mechanism going forwards.

1055
00:43:10,280 --> 00:43:12,280
Yeah, but for it to be useful,

1056
00:43:12,280 --> 00:43:13,640
we need to actually shortcut

1057
00:43:13,640 --> 00:43:17,240
whatever that deterministic computation is going to be

1058
00:43:17,240 --> 00:43:19,120
for us to be able to predict.

1059
00:43:19,120 --> 00:43:21,520
And to do that, we need to understand patterns

1060
00:43:21,520 --> 00:43:22,520
at different levels.

1061
00:43:22,520 --> 00:43:24,480
And sometimes we can't do it.

1062
00:43:24,480 --> 00:43:27,840
You know, sometimes the thing is computationally irreducible

1063
00:43:27,840 --> 00:43:31,480
such that the only way of finding out what's gonna happen

1064
00:43:31,480 --> 00:43:32,840
is to let the process run

1065
00:43:32,840 --> 00:43:35,160
or to create a simulation that's so perfect.

1066
00:43:35,160 --> 00:43:37,360
You basically just duplicated reality, right?

1067
00:43:37,360 --> 00:43:41,920
So, so even if it's conceptually deterministic in the future,

1068
00:43:41,920 --> 00:43:44,040
that doesn't necessarily help you anticipate

1069
00:43:44,040 --> 00:43:46,880
and the idea of these high level concepts,

1070
00:43:46,880 --> 00:43:48,400
as you said, give you useful tools

1071
00:43:48,400 --> 00:43:51,640
and your relation to these phenomena to, you know,

1072
00:43:51,640 --> 00:43:54,280
anticipate maybe the future and understand the past.

1073
00:43:54,280 --> 00:43:56,160
Yeah, and control what happens next.

1074
00:43:56,160 --> 00:43:58,400
So, so as a simple, and some of these systems,

1075
00:43:58,400 --> 00:43:59,880
the cool thing about living

1076
00:43:59,880 --> 00:44:02,960
and other kinds of systems of this type

1077
00:44:03,000 --> 00:44:05,240
is that they offer this kind of shortcut.

1078
00:44:05,240 --> 00:44:06,680
So, so here's a simple example.

1079
00:44:06,680 --> 00:44:08,160
Imagine that you had a rat,

1080
00:44:08,160 --> 00:44:10,520
then you wanted him to do a simple circus trick.

1081
00:44:10,520 --> 00:44:12,640
You know, I don't know, sit on a little bicycle or something.

1082
00:44:12,640 --> 00:44:13,960
One thing that you might do

1083
00:44:13,960 --> 00:44:16,240
from the level of chemistry and physics is you might say,

1084
00:44:16,240 --> 00:44:19,040
okay, so I want the muscles to move in this particular way.

1085
00:44:19,040 --> 00:44:21,040
I need to calculate which neuronal impulses

1086
00:44:21,040 --> 00:44:23,040
are gonna move exactly these muscles to do it.

1087
00:44:23,040 --> 00:44:25,380
I need to trace it back into the brain, figure out

1088
00:44:25,380 --> 00:44:27,960
all the circuits, how, how everything is gonna

1089
00:44:27,960 --> 00:44:29,400
propagate through the brain and figure out

1090
00:44:29,400 --> 00:44:31,560
which pixels on the retina I need to stimulate

1091
00:44:31,560 --> 00:44:34,080
with various images, you know, shown to the rat

1092
00:44:34,080 --> 00:44:35,480
to get him to get on the little bicycle.

1093
00:44:35,480 --> 00:44:37,720
Okay, if you try to actually calculate,

1094
00:44:37,720 --> 00:44:40,000
so that's completely computationally intractable.

1095
00:44:40,000 --> 00:44:42,240
If you try to do that, the sun will burn out

1096
00:44:42,240 --> 00:44:44,360
long before you actually get it done.

1097
00:44:44,360 --> 00:44:46,400
But there's an amazing thing here,

1098
00:44:46,400 --> 00:44:48,600
which is that you can just train the rat.

1099
00:44:48,600 --> 00:44:50,960
And that's because the rat has a particular

1100
00:44:50,960 --> 00:44:54,160
cognitive causal architecture that hides all that stuff.

1101
00:44:54,160 --> 00:44:56,560
And it takes on all the complexity of figuring out

1102
00:44:56,560 --> 00:45:00,960
how should my internal parts be arranged

1103
00:45:01,000 --> 00:45:02,240
in order for meaning,

1104
00:45:02,240 --> 00:45:03,560
meaning all the different neurotransmitters

1105
00:45:03,560 --> 00:45:05,640
and everything else, how should that all be arranged

1106
00:45:05,640 --> 00:45:07,560
in order to achieve a particular goal?

1107
00:45:07,560 --> 00:45:10,840
So the way you do this is you get the buy-in of the rat.

1108
00:45:10,840 --> 00:45:12,720
You make your goal, the rat's goal,

1109
00:45:12,720 --> 00:45:15,400
and then the rat does all the hard work for you.

1110
00:45:15,400 --> 00:45:17,780
You don't have to calculate all this stuff forward.

1111
00:45:17,780 --> 00:45:21,240
So one of the things that understanding these,

1112
00:45:21,240 --> 00:45:24,280
the large scale capabilities of your system

1113
00:45:24,280 --> 00:45:28,040
is critical in having a productive interaction,

1114
00:45:28,160 --> 00:45:31,120
a predictive, powerful productive interaction going forward.

1115
00:45:31,120 --> 00:45:33,160
And this is something that I think is the rate limiting

1116
00:45:33,160 --> 00:45:36,000
step right now for regenerative medicine.

1117
00:45:36,000 --> 00:45:39,760
Because in biology and biomedicine,

1118
00:45:39,760 --> 00:45:42,000
the standard operating assumption is that cells

1119
00:45:42,000 --> 00:45:43,240
are mechanical agents.

1120
00:45:43,240 --> 00:45:45,040
All the excitement is about the hardware.

1121
00:45:45,040 --> 00:45:49,240
So CRISPR, genomic editing, pathway rewiring,

1122
00:45:49,240 --> 00:45:51,460
everything is down at the level of hardware.

1123
00:45:51,460 --> 00:45:54,920
And that closes off a huge number

1124
00:45:54,920 --> 00:45:57,800
of potentially really powerful interventions

1125
00:45:58,400 --> 00:46:01,240
which we're doing in our lab like cellular training,

1126
00:46:02,320 --> 00:46:04,360
exploiting cellular problem solving,

1127
00:46:04,360 --> 00:46:07,520
because if you insist on viewing systems

1128
00:46:07,520 --> 00:46:10,040
from that low level perspective, not that it's wrong,

1129
00:46:10,040 --> 00:46:11,400
it's, I mean, that perspective is there.

1130
00:46:11,400 --> 00:46:14,000
It's there for you to take, but it limits you.

1131
00:46:14,000 --> 00:46:15,560
Reductionism is well-named.

1132
00:46:15,560 --> 00:46:17,720
It reduces what you can do.

1133
00:46:17,720 --> 00:46:21,640
It reduces your ability to really exploit

1134
00:46:21,640 --> 00:46:24,480
what's powerful about these systems.

1135
00:46:24,480 --> 00:46:26,640
And we are leaving so much on the table

1136
00:46:26,640 --> 00:46:30,320
by refusing to test out the tools,

1137
00:46:30,320 --> 00:46:31,960
the interaction tools that we have

1138
00:46:31,960 --> 00:46:34,080
and that have been used for,

1139
00:46:34,080 --> 00:46:36,200
this is why humans train to dogs and horses

1140
00:46:36,200 --> 00:46:38,760
for thousands of years knowing zero neuroscience.

1141
00:46:38,760 --> 00:46:43,040
It's because these systems make it accessible,

1142
00:46:43,040 --> 00:46:47,080
make that whole process, the goal rewriting process

1143
00:46:47,080 --> 00:46:48,840
so accessibly offered a beautiful interface,

1144
00:46:48,840 --> 00:46:50,000
that learning interface.

1145
00:46:50,000 --> 00:46:51,720
So cells and tissues do this too.

1146
00:46:51,720 --> 00:46:54,560
And if you refuse to test those hypotheses,

1147
00:46:54,560 --> 00:46:56,320
you leave a lot on the table.

1148
00:46:56,320 --> 00:46:57,240
Yeah, thank you.

1149
00:46:57,240 --> 00:47:01,200
So these ideas of sentience and consciousness

1150
00:47:01,200 --> 00:47:04,400
are very important to you still.

1151
00:47:04,400 --> 00:47:05,880
They're not things you discard,

1152
00:47:05,880 --> 00:47:08,120
but you refuse to say they're binary,

1153
00:47:08,120 --> 00:47:10,080
they're on or off switches.

1154
00:47:10,080 --> 00:47:11,600
If there are boundaries, they're fuzzy

1155
00:47:11,600 --> 00:47:14,120
and in your sense, there may not even be a boundary at all.

1156
00:47:14,120 --> 00:47:17,120
Ultimately, it may just be a question of degree

1157
00:47:17,120 --> 00:47:19,680
across every possible system,

1158
00:47:19,680 --> 00:47:22,520
but that doesn't destroy their meaningfulness

1159
00:47:22,520 --> 00:47:25,160
because there's a sense, I think,

1160
00:47:25,160 --> 00:47:27,840
with some people who have a very expansive view

1161
00:47:27,840 --> 00:47:31,720
of consciousness that they either reify it in some sense.

1162
00:47:31,720 --> 00:47:34,040
Again, they pull away from the physical

1163
00:47:34,040 --> 00:47:37,160
and that can lead people into, again,

1164
00:47:37,160 --> 00:47:40,080
back into some sort of mystical or soul-based ways

1165
00:47:40,080 --> 00:47:41,160
of thinking about it.

1166
00:47:41,160 --> 00:47:44,280
Or they declare it universal,

1167
00:47:45,240 --> 00:47:46,840
as some might say, you would,

1168
00:47:46,840 --> 00:47:48,760
because you're saying, well, it's a spectrum

1169
00:47:48,760 --> 00:47:50,280
and there's no real end to the spectrum.

1170
00:47:50,280 --> 00:47:52,200
So in a sense, maybe everything shares

1171
00:47:52,200 --> 00:47:55,240
in these characteristics to some degree,

1172
00:47:55,240 --> 00:47:56,720
but by declaring it universal,

1173
00:47:56,720 --> 00:48:00,040
they almost destroy what's meaningful about the concept.

1174
00:48:00,040 --> 00:48:00,880
Yeah.

1175
00:48:00,880 --> 00:48:02,440
And it sort of flattens out.

1176
00:48:02,440 --> 00:48:03,640
And I don't think you're doing either

1177
00:48:03,640 --> 00:48:05,240
because you're recognizing that

1178
00:48:05,240 --> 00:48:06,680
while you don't want it to make it binary,

1179
00:48:06,680 --> 00:48:07,880
there's still something distinctive

1180
00:48:07,880 --> 00:48:10,240
that you can describe in terms

1181
00:48:10,240 --> 00:48:13,160
of how we relate to these entities

1182
00:48:13,160 --> 00:48:18,160
and what these concepts can help us understand

1183
00:48:18,160 --> 00:48:21,000
about these entities, so it retains their meaning.

1184
00:48:21,000 --> 00:48:24,280
Yeah, it doesn't just, it's not just for explaining,

1185
00:48:24,280 --> 00:48:27,880
it is essential and useful.

1186
00:48:27,880 --> 00:48:32,440
My claim is that ideas about cognitive capacities

1187
00:48:32,440 --> 00:48:35,800
and unfamiliar contexts and unfamiliar embodiments

1188
00:48:35,800 --> 00:48:38,720
are essential, they're practical and they're essential.

1189
00:48:38,720 --> 00:48:41,880
This is not philosophy,

1190
00:48:41,880 --> 00:48:45,120
it's not some kind of feel-good mysticism.

1191
00:48:45,120 --> 00:48:47,720
My claim is, and it's a testable claim

1192
00:48:47,720 --> 00:48:50,600
that we've been testing for now for 20 years successfully,

1193
00:48:51,600 --> 00:48:55,720
is that it helps you do better in the empirical world.

1194
00:48:55,720 --> 00:48:59,400
I mean, the best thing I hope my lab does

1195
00:48:59,400 --> 00:49:02,560
is what I hope on their best day,

1196
00:49:02,560 --> 00:49:04,320
what I think we're doing is taking these ideas

1197
00:49:04,320 --> 00:49:05,920
from deep philosophy that people have argued

1198
00:49:05,920 --> 00:49:07,280
about for thousands of years

1199
00:49:07,280 --> 00:49:09,680
and bringing them to the bedside, to the clinic.

1200
00:49:09,680 --> 00:49:13,760
And these things, these ideas are empirically essential

1201
00:49:13,760 --> 00:49:15,760
to get the kind of outcomes that you want.

1202
00:49:15,760 --> 00:49:19,600
So that's, I don't know what more we can say about

1203
00:49:19,600 --> 00:49:21,320
why these ideas are real,

1204
00:49:21,320 --> 00:49:23,280
because by taking that inner perspective,

1205
00:49:23,280 --> 00:49:25,560
by asking what do cells remember?

1206
00:49:25,560 --> 00:49:26,680
What do they care about?

1207
00:49:26,680 --> 00:49:28,760
What is their, the size of their goals?

1208
00:49:28,760 --> 00:49:30,000
What are their goals?

1209
00:49:30,000 --> 00:49:33,160
These are questions that lead directly to therapeutics.

1210
00:49:33,160 --> 00:49:35,720
They lead to work in regenerative medicine, in cancer.

1211
00:49:36,600 --> 00:49:38,800
I don't know what more evidence we could have

1212
00:49:38,800 --> 00:49:40,320
that these things are critical.

1213
00:49:40,320 --> 00:49:43,720
And the other issue is that this idea

1214
00:49:43,720 --> 00:49:47,640
that if we start to apply the tools

1215
00:49:47,640 --> 00:49:49,440
that we use with cognitive systems,

1216
00:49:49,440 --> 00:49:51,160
we try to apply them elsewhere,

1217
00:49:51,160 --> 00:49:54,720
that that kind of leads to some sort of sliding creep

1218
00:49:54,720 --> 00:49:59,720
that devalues our own cognition and our own majesty.

1219
00:50:01,320 --> 00:50:05,800
That's a weird zero-sum game that I don't buy into.

1220
00:50:05,800 --> 00:50:09,360
I am in no way diminished by, I don't feel in any way

1221
00:50:09,360 --> 00:50:13,520
diminished by the idea that there are basically

1222
00:50:13,520 --> 00:50:16,760
an infinitude of other minds, highly diverse minds,

1223
00:50:16,760 --> 00:50:19,520
endless sentient forms throughout the universe,

1224
00:50:19,520 --> 00:50:22,640
and I think I'm certainly here on earth,

1225
00:50:22,640 --> 00:50:26,560
that are also having experiences that strive and suffer

1226
00:50:26,560 --> 00:50:28,680
and to various degrees.

1227
00:50:28,680 --> 00:50:30,440
I don't think that diminishes us at all.

1228
00:50:30,440 --> 00:50:35,440
It seems childish to me to somehow pin our,

1229
00:50:36,000 --> 00:50:38,080
the quality of what we have on the fact

1230
00:50:38,080 --> 00:50:39,960
that no one else has it, that just seems,

1231
00:50:39,960 --> 00:50:41,760
I don't know why we need to make that move.

1232
00:50:41,760 --> 00:50:44,520
I think what we have is essential.

1233
00:50:44,520 --> 00:50:46,000
I think understanding it is essential

1234
00:50:46,040 --> 00:50:47,640
so that we can scale it up.

1235
00:50:47,640 --> 00:50:49,800
I would like to scale my cognitive capacity.

1236
00:50:49,800 --> 00:50:52,720
I would like humanity to scale its cognitive capacity

1237
00:50:52,720 --> 00:50:54,640
more specifically, not just the intelligence,

1238
00:50:54,640 --> 00:50:59,640
but the radius of concern, of care, and of compassion.

1239
00:51:00,440 --> 00:51:01,600
I think we need to scale that up,

1240
00:51:01,600 --> 00:51:02,840
and you only do that if you understand

1241
00:51:02,840 --> 00:51:04,360
what it is that you're scaling.

1242
00:51:04,360 --> 00:51:05,600
You've done the perfect segue

1243
00:51:05,600 --> 00:51:07,960
into our second question about the ethics.

1244
00:51:07,960 --> 00:51:10,200
And what I might do is collapse these questions

1245
00:51:10,200 --> 00:51:13,320
of what matters and who matters just into one,

1246
00:51:13,320 --> 00:51:15,920
because in the big questions of ethics,

1247
00:51:15,920 --> 00:51:18,120
in a sense, there are a bunch of different choices.

1248
00:51:18,120 --> 00:51:19,720
You could take a nihilist route

1249
00:51:19,720 --> 00:51:21,320
where you sort of give up on the idea.

1250
00:51:21,320 --> 00:51:23,120
You could take a relativist approach

1251
00:51:23,120 --> 00:51:27,040
where you think about ethics as just sets of rules

1252
00:51:27,040 --> 00:51:29,000
that groups have negotiated

1253
00:51:29,000 --> 00:51:31,280
in a more transactional relational sense,

1254
00:51:31,280 --> 00:51:34,240
but there's no real truth of the matter

1255
00:51:34,240 --> 00:51:38,120
about whether those rules do good or bad.

1256
00:51:38,120 --> 00:51:39,880
You could follow a divine command theory,

1257
00:51:39,880 --> 00:51:41,440
going back to our early conversation

1258
00:51:41,440 --> 00:51:44,040
where you could turn to the Bible or the Quran

1259
00:51:44,080 --> 00:51:46,400
or some other source of supernatural authority

1260
00:51:46,400 --> 00:51:48,480
and go basically following those rules

1261
00:51:48,480 --> 00:51:50,880
or being obedient to that deity

1262
00:51:50,880 --> 00:51:53,920
is the ultimate arbiter of what's good or bad.

1263
00:51:53,920 --> 00:51:55,000
But if we put those aside,

1264
00:51:55,000 --> 00:51:57,000
and personally, I think we should,

1265
00:51:57,000 --> 00:52:01,000
whatever sort of moral philosophy we have,

1266
00:52:02,640 --> 00:52:05,360
whether it's about rights and day ontology

1267
00:52:05,360 --> 00:52:08,120
or whether it's about consequences and utilitarianism,

1268
00:52:08,120 --> 00:52:09,920
whether it's about feminist care ethic

1269
00:52:09,920 --> 00:52:11,800
where we have relations of care,

1270
00:52:11,800 --> 00:52:13,600
whether it's about virtues,

1271
00:52:13,600 --> 00:52:15,880
whatever the system is,

1272
00:52:15,880 --> 00:52:20,440
they do all seem to share a sort of common sense ethical call,

1273
00:52:20,440 --> 00:52:23,040
which is that somehow morality is about

1274
00:52:23,040 --> 00:52:25,240
whether and how we care about others.

1275
00:52:26,920 --> 00:52:28,400
And the obvious question then is,

1276
00:52:28,400 --> 00:52:30,280
okay, well, who gets to count as another?

1277
00:52:30,280 --> 00:52:33,440
That's really our who matters question.

1278
00:52:33,440 --> 00:52:36,480
And again, I and this podcast have a bias

1279
00:52:36,480 --> 00:52:37,880
because we tend to focus on this idea

1280
00:52:37,880 --> 00:52:40,240
of sentience as being the qualifier

1281
00:52:40,240 --> 00:52:45,240
in that for an entity to count as another,

1282
00:52:45,280 --> 00:52:48,760
they need to have their own perspective

1283
00:52:48,760 --> 00:52:51,880
within which they value their own experiences,

1284
00:52:51,880 --> 00:52:56,000
states, interests, and lives, I guess.

1285
00:52:56,000 --> 00:52:59,280
And because they value those things themselves,

1286
00:52:59,280 --> 00:53:03,000
that's the rationale for us also caring about them.

1287
00:53:03,000 --> 00:53:03,840
Because in a way,

1288
00:53:03,840 --> 00:53:06,280
if morality is about caring about others,

1289
00:53:06,280 --> 00:53:08,600
let's care about all of the others

1290
00:53:08,640 --> 00:53:11,000
that have their own perspective and so qualify as others.

1291
00:53:11,000 --> 00:53:12,840
So it's almost a little bit secular.

1292
00:53:12,840 --> 00:53:15,360
But anyway, that's I guess the starting point

1293
00:53:15,360 --> 00:53:17,160
from this centio-centric ethic

1294
00:53:17,160 --> 00:53:19,040
is to care about all of those others.

1295
00:53:19,040 --> 00:53:21,600
But I'd be really interested in your own

1296
00:53:21,600 --> 00:53:24,400
thinking about either the sort of foundations of ethics

1297
00:53:24,400 --> 00:53:26,560
when you're right, wrong, and good, and bad,

1298
00:53:26,560 --> 00:53:29,800
but also given what we've talked about so far,

1299
00:53:29,800 --> 00:53:33,120
how you think about moral scope and who gets to count

1300
00:53:33,120 --> 00:53:34,440
and what are the implications of that

1301
00:53:34,440 --> 00:53:37,840
and what journey have you gone on through your life so far

1302
00:53:37,880 --> 00:53:40,480
and thinking about those big questions?

1303
00:53:40,480 --> 00:53:44,680
Yeah, well, you know, it's somewhat beyond my pay grade

1304
00:53:44,680 --> 00:53:48,040
to try to lay out a global theory of ethics

1305
00:53:48,040 --> 00:53:49,200
for everybody else and so on.

1306
00:53:49,200 --> 00:53:50,560
That's, I won't try to do that,

1307
00:53:50,560 --> 00:53:52,280
but I will give you some thoughts

1308
00:53:52,280 --> 00:53:54,560
and how I think about these things.

1309
00:53:55,420 --> 00:53:56,260
Couple of things.

1310
00:53:56,260 --> 00:54:00,040
First, I think it's important to not pretend

1311
00:54:00,040 --> 00:54:03,980
that once we understand how sentient something is,

1312
00:54:03,980 --> 00:54:06,680
we are automatically good at treating it ethically.

1313
00:54:06,720 --> 00:54:08,240
Okay, so we know that's not the case.

1314
00:54:08,240 --> 00:54:12,920
We know factory farming, we all know pigs are,

1315
00:54:12,920 --> 00:54:16,200
pigs value their experience that they feel pain,

1316
00:54:16,200 --> 00:54:17,640
all that, and yet here we are.

1317
00:54:17,640 --> 00:54:21,920
So I think what we know and how we treat them

1318
00:54:21,920 --> 00:54:24,200
are not unfortunately the same thing,

1319
00:54:24,200 --> 00:54:28,480
but certainly we should have a principled way

1320
00:54:28,480 --> 00:54:32,120
of apportioning our relationships

1321
00:54:32,120 --> 00:54:35,600
with other beings of all different kinds.

1322
00:54:35,640 --> 00:54:40,640
I think that moving forward in assuming we all survive

1323
00:54:42,960 --> 00:54:45,480
the next few decades, I think moving forward

1324
00:54:45,480 --> 00:54:48,120
for the flourishing of humanity, of ecosystems,

1325
00:54:48,120 --> 00:54:51,720
of other beings on earth really requires

1326
00:54:51,720 --> 00:54:53,560
the deep lessons of diverse intelligence.

1327
00:54:53,560 --> 00:54:55,680
I think we need to understand

1328
00:54:55,680 --> 00:54:59,440
that there is no such thing as a magical standard human

1329
00:54:59,440 --> 00:55:03,160
that is the subject of all these philosophical arguments.

1330
00:55:03,320 --> 00:55:06,200
First of all, because evolutionarily,

1331
00:55:06,200 --> 00:55:08,280
we have a lineage going back to single cells.

1332
00:55:08,280 --> 00:55:12,560
So anything that you think about human responsibilities,

1333
00:55:12,560 --> 00:55:15,480
whatever, well, how about a human of 200,000 years ago?

1334
00:55:15,480 --> 00:55:17,080
How about 500,000 years ago?

1335
00:55:17,080 --> 00:55:18,680
Where was it?

1336
00:55:18,680 --> 00:55:19,800
How did it get here?

1337
00:55:19,800 --> 00:55:20,720
And so on.

1338
00:55:20,720 --> 00:55:23,600
So all of those things are continual.

1339
00:55:23,600 --> 00:55:25,720
The same thing is true of embryonic development.

1340
00:55:25,720 --> 00:55:28,560
You can ask how these things showed up in your journey

1341
00:55:28,560 --> 00:55:30,880
from an OSI to a being.

1342
00:55:30,920 --> 00:55:35,680
And all of the current discussions

1343
00:55:35,680 --> 00:55:40,680
of neuroatypical humans and the bodily modifications

1344
00:55:40,680 --> 00:55:45,000
that some people do, these things are going to be laughable

1345
00:55:45,000 --> 00:55:47,880
to the humans of the next couple of generations

1346
00:55:47,880 --> 00:55:52,680
in their minor sort of degree, their timid degree.

1347
00:55:52,680 --> 00:55:54,400
I mean, you're going to have humans

1348
00:55:54,400 --> 00:55:57,960
that are so modified in body and mind, cyborgs,

1349
00:55:58,640 --> 00:56:02,280
with various biological and technological changes

1350
00:56:02,280 --> 00:56:05,440
that it's going to be completely obvious.

1351
00:56:05,440 --> 00:56:07,640
Right now, we're kind of lulled into a fault.

1352
00:56:07,640 --> 00:56:10,080
Well, we have been for centuries,

1353
00:56:10,080 --> 00:56:11,720
lulled into a false sense of security

1354
00:56:11,720 --> 00:56:13,280
in the sense that it was easy.

1355
00:56:13,280 --> 00:56:15,440
Before you could say, does it speak?

1356
00:56:15,440 --> 00:56:17,440
If it speaks, then it's like us.

1357
00:56:17,440 --> 00:56:19,280
And even that humanity fails.

1358
00:56:19,280 --> 00:56:21,680
We were really terrible to each other

1359
00:56:21,680 --> 00:56:23,720
for much smaller differences.

1360
00:56:23,720 --> 00:56:26,960
But you could say, where did you come from?

1361
00:56:26,960 --> 00:56:29,520
Meaning, were you evolved or did you come from a factory?

1362
00:56:29,520 --> 00:56:30,880
And you could sort of knock on something.

1363
00:56:30,880 --> 00:56:32,640
And if you hear a metallic clanging sound, you say,

1364
00:56:32,640 --> 00:56:35,040
okay, we know how we're going to deal with this.

1365
00:56:35,040 --> 00:56:38,840
And if you heard some kind of soft and kind of a thud,

1366
00:56:38,840 --> 00:56:40,400
then that's something else.

1367
00:56:40,400 --> 00:56:41,960
Those categories were never any good,

1368
00:56:41,960 --> 00:56:44,920
but they served us kind of okay for a long time.

1369
00:56:44,920 --> 00:56:45,760
Those are gone.

1370
00:56:45,760 --> 00:56:47,360
Those are gone now.

1371
00:56:47,360 --> 00:56:48,960
They're going to be left in the dust

1372
00:56:48,960 --> 00:56:50,880
by the next couple of decades.

1373
00:56:50,880 --> 00:56:53,040
It's going to be essential that we learn

1374
00:56:53,040 --> 00:56:55,960
to have an ethical, I call it synthbiosis,

1375
00:56:55,960 --> 00:56:58,760
with other beings that are nowhere with us

1376
00:56:58,760 --> 00:56:59,600
on the tree of life.

1377
00:56:59,600 --> 00:57:01,600
They are modified in body and mind.

1378
00:57:01,600 --> 00:57:03,960
And what you look like and where you come from

1379
00:57:03,960 --> 00:57:06,320
simply cannot be the foundation

1380
00:57:06,320 --> 00:57:08,200
for how we're going to relate to each other.

1381
00:57:08,200 --> 00:57:11,760
And again, science fiction dealt with this a long time ago.

1382
00:57:11,760 --> 00:57:16,760
But somehow people today have lost sight of some of those

1383
00:57:16,760 --> 00:57:20,160
things, again, the current debates over AI,

1384
00:57:20,160 --> 00:57:22,240
it's very easy to say that language models

1385
00:57:22,240 --> 00:57:23,240
aren't this and aren't that.

1386
00:57:23,240 --> 00:57:25,480
And I'm not a defender of any particular view

1387
00:57:25,480 --> 00:57:27,240
of sentience and language models,

1388
00:57:27,240 --> 00:57:29,000
although more generally, I don't believe

1389
00:57:29,000 --> 00:57:30,760
we really know what we have once we've made it.

1390
00:57:30,760 --> 00:57:33,640
But the thing is those kind of language models,

1391
00:57:33,640 --> 00:57:35,880
they're so different from us that it's very easy

1392
00:57:35,880 --> 00:57:38,720
for people to say, oh, that's not the things

1393
00:57:38,720 --> 00:57:39,760
we want to care about.

1394
00:57:39,760 --> 00:57:41,560
What are you going to do when you're confronted

1395
00:57:41,560 --> 00:57:45,680
with humans that have 51% of their brain replaced

1396
00:57:45,680 --> 00:57:50,600
by various silicon appliances and they're linked together

1397
00:57:50,600 --> 00:57:53,480
with other people and also a few AIs

1398
00:57:53,480 --> 00:57:54,640
and some things like that.

1399
00:57:54,680 --> 00:57:59,480
So all of this is coming, we are going to have

1400
00:57:59,480 --> 00:58:03,160
to develop a better, better more principled

1401
00:58:03,160 --> 00:58:06,360
ethical frameworks for dealing with beings

1402
00:58:06,360 --> 00:58:09,920
that are just very alien in their construction.

1403
00:58:09,920 --> 00:58:12,000
And so that means that you need frameworks

1404
00:58:12,000 --> 00:58:15,160
to understand what do all these beings have in common?

1405
00:58:15,160 --> 00:58:17,240
And this is something that a few years ago,

1406
00:58:17,240 --> 00:58:19,800
I developed this notion of a cognitive light cone

1407
00:58:19,800 --> 00:58:23,760
to try to get away from the idea of what kind

1408
00:58:23,800 --> 00:58:27,240
of material embodiment you're in and instead focus on

1409
00:58:27,240 --> 00:58:28,600
what are the things you care about?

1410
00:58:28,600 --> 00:58:33,600
What is the size of the biggest goals you can pursue?

1411
00:58:34,760 --> 00:58:36,600
And regardless of your embodiment

1412
00:58:36,600 --> 00:58:38,680
or implementation or origin story.

1413
00:58:38,680 --> 00:58:42,920
And that kind of a thing at least begins to give us

1414
00:58:42,920 --> 00:58:47,680
a way to apportion our degree of moral concern

1415
00:58:47,680 --> 00:58:51,880
to beings that are capable of pursuing goals

1416
00:58:52,520 --> 00:58:56,320
and having various kinds of competencies

1417
00:58:56,320 --> 00:58:59,200
of navigating problem spaces and suffering

1418
00:58:59,200 --> 00:59:03,440
when those goals are not reached.

1419
00:59:03,440 --> 00:59:08,440
So for that reason, I think the diversity

1420
00:59:10,680 --> 00:59:14,080
of who and what we think counts is gonna be enormous

1421
00:59:14,080 --> 00:59:16,680
and this business of language models and so on,

1422
00:59:16,680 --> 00:59:20,000
it's a distraction from a much deeper puzzle.

1423
00:59:20,040 --> 00:59:20,960
Yeah, thank you.

1424
00:59:20,960 --> 00:59:23,520
And one of my previous guests, Josh Gellis

1425
00:59:23,520 --> 00:59:25,720
has done quite a lot of work in that space

1426
00:59:25,720 --> 00:59:29,000
about thinking about potential artificial intelligences

1427
00:59:29,000 --> 00:59:30,440
and sentience and so on.

1428
00:59:30,440 --> 00:59:31,840
And actually he's quite challenging

1429
00:59:31,840 --> 00:59:33,360
about the idea of sentience

1430
00:59:33,360 --> 00:59:35,840
because he's worried it's seen too much

1431
00:59:35,840 --> 00:59:39,000
as a sort of easily isolatable property

1432
00:59:39,000 --> 00:59:41,640
that we will then deny to, for example,

1433
00:59:41,640 --> 00:59:43,440
artificial intelligence and robots and so on.

1434
00:59:43,440 --> 00:59:46,040
And he prefers a much more relational approach,

1435
00:59:46,040 --> 00:59:48,640
which we can go back and forth about the risks

1436
00:59:48,640 --> 00:59:49,880
and the challenges of that.

1437
00:59:49,880 --> 00:59:52,440
But one thing I do agree with him and I think you

1438
00:59:52,440 --> 00:59:55,360
is that we're gonna be forced into working this stuff out

1439
00:59:55,360 --> 00:59:56,600
whether we like it or not.

1440
00:59:56,600 --> 00:59:58,760
And I think it will open up and radicalize

1441
00:59:58,760 --> 01:00:00,560
the way we think about what it is to be another

1442
01:00:00,560 --> 01:00:04,440
and that need to appreciate radically different perspective

1443
01:00:04,440 --> 01:00:05,560
from different beings.

1444
01:00:05,560 --> 01:00:08,960
But I was really glad you mentioned animal agriculture

1445
01:00:08,960 --> 01:00:11,200
because one of the frustrations with many people

1446
01:00:11,200 --> 01:00:14,440
who are involved in sentientism or the worldview

1447
01:00:14,440 --> 01:00:17,760
is that there's a frustration in the current zeitgeist

1448
01:00:17,760 --> 01:00:19,840
that people seem really excited about talking

1449
01:00:19,840 --> 01:00:22,960
about artificial intelligences and artificial sentience

1450
01:00:22,960 --> 01:00:24,920
and whether robots could ever feel something

1451
01:00:24,920 --> 01:00:26,280
and become moral patients.

1452
01:00:26,280 --> 01:00:29,440
But people seem to conveniently skip over the hundreds

1453
01:00:29,440 --> 01:00:32,280
of billions, if not trillions, if we include aquatic,

1454
01:00:32,280 --> 01:00:35,200
non-human sentient beings that we brutally exploit today.

1455
01:00:35,200 --> 01:00:37,480
And it's a really interesting case study

1456
01:00:37,480 --> 01:00:42,480
because I think when you take a naturalistic epistemology

1457
01:00:43,440 --> 01:00:45,960
and you understand the facts of what farming

1458
01:00:45,960 --> 01:00:47,880
and fishing are like, not just factory farming,

1459
01:00:47,880 --> 01:00:50,720
but all of it, and you take the ethical perspective

1460
01:00:50,720 --> 01:00:53,320
of the beings that are going through those processes,

1461
01:00:53,320 --> 01:00:57,880
it quite easily leads you to a point of quite extreme ethical

1462
01:00:57,880 --> 01:01:00,920
condemnation of what's going on in those situations.

1463
01:01:00,920 --> 01:01:05,000
But our society is trained us to think this so normal

1464
01:01:05,000 --> 01:01:08,640
that there's a brutal clash between, you know,

1465
01:01:08,640 --> 01:01:11,200
if you like the epistemology and the centiocentric ethic

1466
01:01:11,200 --> 01:01:13,240
and today's social norms.

1467
01:01:13,800 --> 01:01:16,200
Thank you for mentioning that.

1468
01:01:16,200 --> 01:01:18,680
I mean, so a couple of things there.

1469
01:01:18,680 --> 01:01:21,360
One is that, yeah, I mean, you're absolutely right,

1470
01:01:21,360 --> 01:01:26,360
of course, in talking about these AIs

1471
01:01:26,640 --> 01:01:30,360
and instead of other problems with the existing life forms

1472
01:01:30,360 --> 01:01:31,880
is a huge issue.

1473
01:01:31,880 --> 01:01:33,920
It also comes up when people say,

1474
01:01:33,920 --> 01:01:37,480
oh, wow, we're gonna make these high level intelligences

1475
01:01:37,480 --> 01:01:39,840
and who knows how they'll be raised

1476
01:01:39,840 --> 01:01:41,440
and what they're gonna do in the future.

1477
01:01:41,480 --> 01:01:43,680
I mean, you've heard of having kids, right?

1478
01:01:43,680 --> 01:01:46,400
Like, I'm just, you know, we do this all the time.

1479
01:01:46,400 --> 01:01:49,640
We have an enormous amount of guaranteed high level

1480
01:01:50,400 --> 01:01:52,240
intelligences that are created all the time

1481
01:01:52,240 --> 01:01:55,720
and a huge diversity of good and bad environments

1482
01:01:55,720 --> 01:01:56,720
that they're raised in.

1483
01:01:56,720 --> 01:01:59,800
We have a very limited ability to make sure

1484
01:01:59,800 --> 01:02:02,280
that they have a good embodied experience

1485
01:02:02,280 --> 01:02:03,800
and are aligned with our values

1486
01:02:03,800 --> 01:02:05,760
and some of them go on to do wonderful things

1487
01:02:05,760 --> 01:02:08,640
and some of them go on to, you know, to do horrible things.

1488
01:02:08,640 --> 01:02:09,680
That's already an issue.

1489
01:02:09,680 --> 01:02:11,400
We already have that.

1490
01:02:11,400 --> 01:02:14,240
The thing with, so these, in many ways,

1491
01:02:14,240 --> 01:02:16,600
these problems are not new problems brought on by AI.

1492
01:02:16,600 --> 01:02:19,600
They're perennial existential problems

1493
01:02:19,600 --> 01:02:22,720
that humanity has faced forever, you know,

1494
01:02:22,720 --> 01:02:25,240
in terms of being supplanted by the next generation

1495
01:02:25,240 --> 01:02:27,840
that finds your values, you know, irrelevant

1496
01:02:27,840 --> 01:02:29,600
and how much control do you want

1497
01:02:29,600 --> 01:02:31,360
over how your neighbor is raising their kids

1498
01:02:31,360 --> 01:02:32,320
and all these kinds of things.

1499
01:02:32,320 --> 01:02:35,920
This has been with us for the longest time.

1500
01:02:36,320 --> 01:02:40,880
The one unique thing about AI intelligences, though,

1501
01:02:40,880 --> 01:02:45,160
is that they can be copied in a much easier fashion.

1502
01:02:45,160 --> 01:02:46,560
They can be reproduced and copied

1503
01:02:46,560 --> 01:02:49,200
in a much easier fashion than real animals.

1504
01:02:49,200 --> 01:02:54,200
And I think that now, while there are some good debates

1505
01:02:55,200 --> 01:02:57,680
about whether something that actually can be copied

1506
01:02:57,680 --> 01:02:59,720
even counts in this case.

1507
01:02:59,720 --> 01:03:02,160
So, you know, there's a few arguments

1508
01:03:02,160 --> 01:03:05,600
that that's not an issue, but I'm not sure yet.

1509
01:03:05,600 --> 01:03:08,240
And I think that for that reason,

1510
01:03:08,240 --> 01:03:11,320
because there's just gonna be such an uncountable number

1511
01:03:11,320 --> 01:03:14,400
of intelligences of the software variety,

1512
01:03:14,400 --> 01:03:15,840
whether embodied or not,

1513
01:03:15,840 --> 01:03:18,960
it's something that we need to consider, you know.

1514
01:03:18,960 --> 01:03:21,520
And I'm hopeful that with the advent

1515
01:03:21,520 --> 01:03:25,440
of different ways to grow food proteins and so on,

1516
01:03:25,440 --> 01:03:28,440
we're gonna eventually completely do away

1517
01:03:28,440 --> 01:03:30,600
with animal farming and so on.

1518
01:03:30,840 --> 01:03:35,840
But the creation of novel synthetic organisms

1519
01:03:35,840 --> 01:03:37,040
is only gonna increase.

1520
01:03:37,040 --> 01:03:39,520
And I mean, you know, digital or embodied or not.

1521
01:03:39,520 --> 01:03:42,400
So that's, you know, I think we need to focus

1522
01:03:42,400 --> 01:03:44,640
on both sides of that equation.

1523
01:03:44,640 --> 01:03:45,920
Yeah, I agree, agree.

1524
01:03:45,920 --> 01:03:48,000
And I don't know if you're thinking on that

1525
01:03:48,000 --> 01:03:50,680
as led you down the path of boycotting animal agriculture

1526
01:03:50,680 --> 01:03:51,760
and its product so far,

1527
01:03:51,760 --> 01:03:55,520
or whether I can help you offline on that path, but...

1528
01:03:55,520 --> 01:03:58,040
Yeah, why don't we talk offline?

1529
01:03:58,040 --> 01:03:59,080
Sounds good, sounds good.

1530
01:03:59,120 --> 01:04:02,640
So the other ethical question I wanted to touch on with you

1531
01:04:02,640 --> 01:04:05,320
is how that bears on your own work in the lab,

1532
01:04:05,320 --> 01:04:07,680
because you do work with a variety

1533
01:04:07,680 --> 01:04:09,960
of different entities, animal and non.

1534
01:04:09,960 --> 01:04:11,200
How does that play in?

1535
01:04:11,200 --> 01:04:14,120
Because you're into your choices,

1536
01:04:14,120 --> 01:04:16,480
because you're working with some very simple organisms

1537
01:04:16,480 --> 01:04:18,840
and you're working with more complex organisms as well

1538
01:04:18,840 --> 01:04:20,240
that would have richer experiences.

1539
01:04:20,240 --> 01:04:21,480
How do you think about that?

1540
01:04:21,480 --> 01:04:23,000
Again, I won't take you through it in depth,

1541
01:04:23,000 --> 01:04:25,520
but I'm interested in sort of simple perspective

1542
01:04:25,520 --> 01:04:27,960
you take on animals and research.

1543
01:04:28,000 --> 01:04:29,040
Yeah, yeah.

1544
01:04:29,040 --> 01:04:33,720
Well, first, just to say that animal use and research

1545
01:04:33,720 --> 01:04:36,320
is incredibly stringently regulated.

1546
01:04:36,320 --> 01:04:38,480
So in order to do the things

1547
01:04:38,480 --> 01:04:41,240
that somebody would do when they go fishing for an afternoon,

1548
01:04:41,240 --> 01:04:44,600
we have three months of paperwork and oversight

1549
01:04:44,600 --> 01:04:46,720
by veterinarians and ethicists and all that.

1550
01:04:46,720 --> 01:04:49,240
So there's a huge amount of oversight,

1551
01:04:49,240 --> 01:04:52,640
as there should be, I'm not in full favor of that.

1552
01:04:52,640 --> 01:04:56,120
But this is something I think that's really important

1553
01:04:56,120 --> 01:04:58,560
and it gets to this issue of what matters.

1554
01:04:59,560 --> 01:05:04,160
A lot of folks see scientific ethics in the following way.

1555
01:05:04,160 --> 01:05:06,560
Everything's great and you scientists

1556
01:05:06,560 --> 01:05:08,240
better not screw it up, right?

1557
01:05:08,240 --> 01:05:11,840
So here's a long list of things we don't want you to do.

1558
01:05:11,840 --> 01:05:13,720
We don't want this, we don't want that.

1559
01:05:13,720 --> 01:05:15,200
Don't make things worse.

1560
01:05:15,200 --> 01:05:20,200
Now that could, I suppose could have been a viable worldview

1561
01:05:20,560 --> 01:05:22,960
when people believe that our current world

1562
01:05:22,960 --> 01:05:26,560
is in some way set up in the right way for us.

1563
01:05:26,560 --> 01:05:28,880
In other words, it is the best possible world.

1564
01:05:28,880 --> 01:05:31,600
Everything is great now, now don't screw it up.

1565
01:05:31,600 --> 01:05:35,880
What we now know is that that's not the world we live in.

1566
01:05:35,880 --> 01:05:40,880
We are the process of meandering evolutionary path.

1567
01:05:40,920 --> 01:05:42,480
Evolution, as far as I can tell,

1568
01:05:42,480 --> 01:05:44,640
does not optimize for any of our values.

1569
01:05:44,640 --> 01:05:45,960
It doesn't optimize for happiness,

1570
01:05:45,960 --> 01:05:47,800
for intelligence, for any of that stuff.

1571
01:05:47,800 --> 01:05:50,400
No, we are where evolution dumped us

1572
01:05:50,400 --> 01:05:52,600
with all of our ridiculous susceptibilities

1573
01:05:52,640 --> 01:05:55,960
to bacteria, viruses, lower back pain,

1574
01:05:55,960 --> 01:05:59,320
stray cosmic rays that might have hit a DNA molecule

1575
01:05:59,320 --> 01:06:00,160
during development,

1576
01:06:00,160 --> 01:06:02,640
and now your potential is radically limited.

1577
01:06:02,640 --> 01:06:04,080
When you broaden that scope out

1578
01:06:04,080 --> 01:06:05,880
to all of the potentially sentient beings,

1579
01:06:05,880 --> 01:06:07,840
that just becomes even starker, right?

1580
01:06:07,840 --> 01:06:10,440
If there is some tealoss to this universe,

1581
01:06:10,440 --> 01:06:11,960
it's a pretty brutal one, yeah.

1582
01:06:11,960 --> 01:06:13,640
It is, it is, there's no doubt.

1583
01:06:13,640 --> 01:06:15,920
And so I'm not even a clinician,

1584
01:06:15,920 --> 01:06:18,320
but the amount of emails that I get every day

1585
01:06:18,320 --> 01:06:21,160
from people with the most unbelievable examples

1586
01:06:21,400 --> 01:06:24,680
of biomedical suffering is just incredible.

1587
01:06:24,680 --> 01:06:27,400
So I think it is utter moral cowardice

1588
01:06:27,400 --> 01:06:29,960
to focus on what we shouldn't do.

1589
01:06:30,880 --> 01:06:35,240
And as opposed to our duty now that we have,

1590
01:06:35,240 --> 01:06:37,000
for the first time, I guess, on Earth,

1591
01:06:37,000 --> 01:06:40,320
we have the ability to actually rationally approach

1592
01:06:40,320 --> 01:06:45,320
these matters to try to guarantee a better embodiment

1593
01:06:45,920 --> 01:06:47,880
for sentient beings on Earth.

1594
01:06:49,320 --> 01:06:50,760
The number of people that are suffering

1595
01:06:50,760 --> 01:06:52,160
because of our ignorance,

1596
01:06:52,160 --> 01:06:53,720
because we don't know what to do,

1597
01:06:53,720 --> 01:06:56,160
and also because of our timidity

1598
01:06:56,160 --> 01:07:01,160
and our unwillingness to take responsibility for,

1599
01:07:03,080 --> 01:07:05,080
we are the ones that are now,

1600
01:07:05,080 --> 01:07:08,840
it is on us now to improve this for people.

1601
01:07:10,080 --> 01:07:11,960
And not just people, for ecosystems,

1602
01:07:11,960 --> 01:07:15,920
for other beings, for just the amount of ignorance

1603
01:07:15,920 --> 01:07:19,560
and inaction that is letting a sentient being suffer

1604
01:07:19,560 --> 01:07:21,440
worldwide is incredible.

1605
01:07:21,440 --> 01:07:26,440
And so I take animal use ethics extremely seriously,

1606
01:07:27,080 --> 01:07:30,160
but I think to the extent that it is our responsibility

1607
01:07:30,160 --> 01:07:33,640
to relieve the suffering worldwide, science has to go on.

1608
01:07:33,640 --> 01:07:36,480
And we have to do experiments that are going to enable us

1609
01:07:36,480 --> 01:07:39,920
to improve embodied experience for all.

1610
01:07:41,000 --> 01:07:46,000
This is just, the Buddhists have this concept

1611
01:07:46,120 --> 01:07:47,720
of an inauspicious birth.

1612
01:07:47,720 --> 01:07:50,160
And it's this idea that in one of your many lifetimes,

1613
01:07:50,160 --> 01:07:52,840
you're born in a body during which you just can't make

1614
01:07:52,840 --> 01:07:55,360
progress towards enlightenment.

1615
01:07:55,360 --> 01:07:59,200
I think at this point, I know this is a controversial view,

1616
01:07:59,200 --> 01:08:00,960
but I think basically right now,

1617
01:08:00,960 --> 01:08:03,360
every birth is an inauspicious birth.

1618
01:08:03,360 --> 01:08:08,240
All of us are limited by the vagaries of random mutation

1619
01:08:08,240 --> 01:08:10,320
and selection and all these dumb things and viruses,

1620
01:08:10,320 --> 01:08:13,200
all these dumb things that have no one's best interest.

1621
01:08:13,200 --> 01:08:15,160
And I think in the future,

1622
01:08:15,160 --> 01:08:20,080
sometimes I sort of imagine this dialogue that children

1623
01:08:20,080 --> 01:08:22,280
in the future are going to have with their teachers,

1624
01:08:22,280 --> 01:08:23,960
the kind of thing where you tell the kids,

1625
01:08:23,960 --> 01:08:27,320
yeah, we wrote on chalkboards and we didn't have cell phones

1626
01:08:27,320 --> 01:08:28,480
and like, what?

1627
01:08:28,480 --> 01:08:30,960
And so they're gonna say,

1628
01:08:30,960 --> 01:08:33,360
you're telling me you would just have to stay

1629
01:08:33,360 --> 01:08:35,480
in whatever body you randomly got.

1630
01:08:35,480 --> 01:08:36,600
And if you had some sort of defect,

1631
01:08:36,600 --> 01:08:37,760
you just have to live that way.

1632
01:08:37,760 --> 01:08:41,680
And if the IQ and the lifespan that you were born with

1633
01:08:41,680 --> 01:08:44,040
wasn't enough to fulfill your goals, that's it.

1634
01:08:44,040 --> 01:08:45,760
You just have to, you know, that was your bad luck.

1635
01:08:45,760 --> 01:08:50,760
That will be unthinkable to a modern humans going forward.

1636
01:08:51,960 --> 01:08:53,640
And in a way, that's a beautiful link

1637
01:08:53,640 --> 01:08:55,520
into the final question, which is how do we make

1638
01:08:55,520 --> 01:08:58,280
a better future, which is what are the promises

1639
01:08:58,280 --> 01:09:02,160
of these types of research and thinking?

1640
01:09:02,160 --> 01:09:04,680
Yeah, I mean, I think ultimately

1641
01:09:04,680 --> 01:09:07,000
from the kind of the bigger picture for me

1642
01:09:07,000 --> 01:09:08,840
is freedom of embodiment.

1643
01:09:08,840 --> 01:09:11,280
I think that every sentient being should have the,

1644
01:09:11,280 --> 01:09:14,040
and we need to, we should offer assistance

1645
01:09:14,040 --> 01:09:15,920
in the same way that we offer assistance

1646
01:09:15,920 --> 01:09:20,920
to beings via education, via support of every kind.

1647
01:09:21,440 --> 01:09:25,180
We should be in a position to offer the ability

1648
01:09:25,180 --> 01:09:28,080
for sentient beings to have better embodiments

1649
01:09:28,080 --> 01:09:31,200
to fulfill their potential, their goals and so on.

1650
01:09:31,200 --> 01:09:34,280
Practically speaking, what that requires

1651
01:09:34,280 --> 01:09:37,480
is complete control over growth and form.

1652
01:09:37,480 --> 01:09:41,320
It means that we need to really be able to direct

1653
01:09:41,320 --> 01:09:43,420
what it is that cells build.

1654
01:09:43,420 --> 01:09:46,080
Now, right now that just looks like regenerative medicine

1655
01:09:46,080 --> 01:09:48,600
in the sense that if we knew how to get cells

1656
01:09:48,600 --> 01:09:51,400
to build specifics as anatomical structures,

1657
01:09:51,400 --> 01:09:54,640
then birth defects, traumatic injuries, cancer, aging,

1658
01:09:54,640 --> 01:09:57,280
degenerative disease, all these things would go away

1659
01:09:57,280 --> 01:09:59,720
if we could communicate our goals to groups of cells.

1660
01:09:59,720 --> 01:10:02,320
And this is something that we and some other labs

1661
01:10:02,320 --> 01:10:04,840
are working on now is this kind of, you know,

1662
01:10:04,840 --> 01:10:06,740
this idea of an anatomical compiler

1663
01:10:06,820 --> 01:10:08,700
where you can just specify the shape

1664
01:10:08,700 --> 01:10:10,380
of the structure that you want

1665
01:10:10,380 --> 01:10:14,420
and it gives stimuli to cells to make them grow exactly that.

1666
01:10:14,420 --> 01:10:16,300
And again, linking to what you said before,

1667
01:10:16,300 --> 01:10:18,660
this is different from the classical ideas

1668
01:10:18,660 --> 01:10:20,980
of genetic engineering or, you know,

1669
01:10:20,980 --> 01:10:22,020
what you do with CRISPR and so on.

1670
01:10:22,020 --> 01:10:26,420
This is a different mode of engagement with a system.

1671
01:10:26,420 --> 01:10:30,420
Yeah, the goal is similar because certainly people,

1672
01:10:30,420 --> 01:10:32,980
you know, at the time that genetics was getting off

1673
01:10:32,980 --> 01:10:35,340
the ground, this is a vision that people had then too,

1674
01:10:35,340 --> 01:10:36,820
that if we understood the genetics,

1675
01:10:36,820 --> 01:10:38,420
we could control the shape.

1676
01:10:38,420 --> 01:10:42,820
I think we have a much more practical path to it

1677
01:10:42,820 --> 01:10:46,060
because I think the genetics specifies the hardware

1678
01:10:46,060 --> 01:10:48,700
that every cell gets to have, so the proteins.

1679
01:10:48,700 --> 01:10:53,700
But as we know from the advances of computer science

1680
01:10:53,880 --> 01:10:55,380
and information technology programming

1681
01:10:55,380 --> 01:10:58,540
at the level of hardware, while possible, it's really hard.

1682
01:10:58,540 --> 01:11:01,140
And if you have good hardware that's actually reprogrammable

1683
01:11:01,140 --> 01:11:03,220
and offers high level interfaces, you know,

1684
01:11:03,220 --> 01:11:05,220
you might say APIs, which I think is exactly

1685
01:11:05,260 --> 01:11:08,580
what it offers, then you can do this in a much better way,

1686
01:11:08,580 --> 01:11:13,580
specifically by honoring the agency of the cells and tissues

1687
01:11:13,740 --> 01:11:15,300
and being a collaborator with them.

1688
01:11:15,300 --> 01:11:18,620
We don't micromanage our cells and tissues here.

1689
01:11:18,620 --> 01:11:21,100
I mean, in my group, we basically collaborate with them

1690
01:11:21,100 --> 01:11:24,060
and modulate their goals and take advantage

1691
01:11:24,060 --> 01:11:26,960
of their competencies, their problem-solving capacities,

1692
01:11:26,960 --> 01:11:28,220
their memories and so on.

1693
01:11:28,220 --> 01:11:32,540
So I think that is a way to move the field forward

1694
01:11:32,540 --> 01:11:33,440
much faster.

1695
01:11:33,440 --> 01:11:35,100
I think that CRISPR and those kinds of things

1696
01:11:35,100 --> 01:11:38,380
are going to flatten out soon because after you've picked

1697
01:11:38,380 --> 01:11:40,580
the low-hanging fruit of single gene diseases,

1698
01:11:40,580 --> 01:11:43,020
the next question is gonna be, well, what genes do you add

1699
01:11:43,020 --> 01:11:45,260
to make the changes, the anatomical changes do you want?

1700
01:11:45,260 --> 01:11:47,060
And development's not reversible in that way.

1701
01:11:47,060 --> 01:11:50,780
You can't just figure out what, in any easy way,

1702
01:11:50,780 --> 01:11:51,620
what to edit.

1703
01:11:51,620 --> 01:11:56,380
So I think taking advantage of the interfaces

1704
01:11:56,380 --> 01:11:59,380
that cells use to hack each other is critical.

1705
01:11:59,380 --> 01:12:02,540
But initially that just looks like reprogramming tumors

1706
01:12:02,540 --> 01:12:06,460
and regrowing limbs and growing new organs and so on,

1707
01:12:06,460 --> 01:12:08,020
all of which by the way we've done here

1708
01:12:08,020 --> 01:12:10,460
in various model systems.

1709
01:12:10,460 --> 01:12:13,180
But ultimately it leads to freedom of embodiment.

1710
01:12:13,180 --> 01:12:15,940
It means that if you want to have a different embodiment

1711
01:12:15,940 --> 01:12:18,140
you can, and if you decide you wanna change it,

1712
01:12:18,140 --> 01:12:19,700
you should be able to do that too.

1713
01:12:19,700 --> 01:12:22,500
There is no reason any of us should be stuck

1714
01:12:22,500 --> 01:12:25,100
in the embodiment that we got,

1715
01:12:25,100 --> 01:12:28,740
including IQ and lifespan and all those things.

1716
01:12:28,740 --> 01:12:30,300
Because those things were not chosen

1717
01:12:30,300 --> 01:12:31,820
with your welfare in mind.

1718
01:12:32,500 --> 01:12:35,900
They were a long process shaped by forces

1719
01:12:35,900 --> 01:12:38,020
that don't honor any of our values.

1720
01:12:38,020 --> 01:12:39,020
Yeah, thank you.

1721
01:12:39,020 --> 01:12:40,300
It's quite a vision.

1722
01:12:40,300 --> 01:12:42,380
And it will lead to some of the things I've touched on

1723
01:12:42,380 --> 01:12:44,220
with some of the people who are interested

1724
01:12:44,220 --> 01:12:46,260
in the transhumanist space like David Pearson

1725
01:12:46,260 --> 01:12:47,220
and so on as well.

1726
01:12:47,220 --> 01:12:49,140
And again, it's that freedom of embodiment

1727
01:12:49,140 --> 01:12:53,020
for human and non-human sentient beings

1728
01:12:53,020 --> 01:12:56,420
that is, to put it a different way,

1729
01:12:56,420 --> 01:12:58,980
shaped by their own values and aspirations

1730
01:12:59,060 --> 01:13:03,980
and experiences rather than constrained by inherited biology

1731
01:13:03,980 --> 01:13:06,500
and freeing from some of those constraints.

1732
01:13:06,500 --> 01:13:11,500
But some of my audience will love that sort of vision

1733
01:13:11,620 --> 01:13:14,020
and see the potential.

1734
01:13:14,020 --> 01:13:17,060
Others will be nervous about classic problem

1735
01:13:17,060 --> 01:13:18,700
of human hubris and intervening

1736
01:13:18,700 --> 01:13:20,620
where we're not really ready to intervene.

1737
01:13:20,620 --> 01:13:21,900
What do you think of the risk profile

1738
01:13:21,900 --> 01:13:23,380
and the approach you're taking?

1739
01:13:23,380 --> 01:13:24,780
Are there risks we need to watch out for

1740
01:13:24,780 --> 01:13:27,980
that we need to build in?

1741
01:13:27,980 --> 01:13:29,620
For sure, there are going to be risks,

1742
01:13:29,620 --> 01:13:32,860
but I'm pushing in the very opposite direction

1743
01:13:32,860 --> 01:13:35,180
of the hubris.

1744
01:13:35,180 --> 01:13:38,780
My argument isn't that everything is great.

1745
01:13:38,780 --> 01:13:42,820
And then in an effort to make it even better,

1746
01:13:42,820 --> 01:13:44,340
we're going to screw things up.

1747
01:13:44,340 --> 01:13:46,020
And we may screw some things up.

1748
01:13:46,020 --> 01:13:47,780
It's pretty inevitable.

1749
01:13:47,780 --> 01:13:51,460
My argument is that things are so bad right now

1750
01:13:51,460 --> 01:13:55,500
for so many that it is a moral imperative.

1751
01:13:55,620 --> 01:13:58,260
We do not have the luxury of saying,

1752
01:13:58,260 --> 01:14:00,140
don't do this.

1753
01:14:00,140 --> 01:14:01,900
Inaction is a choice too.

1754
01:14:01,900 --> 01:14:03,060
Yeah, exactly right.

1755
01:14:03,060 --> 01:14:07,700
The opportunity cost of doing nothing is massive.

1756
01:14:07,700 --> 01:14:08,820
It's absolutely massive.

1757
01:14:08,820 --> 01:14:13,820
And this idea that we don't have to do anything

1758
01:14:15,700 --> 01:14:19,620
because we can let things go how they are now,

1759
01:14:19,620 --> 01:14:21,380
that's simply not acceptable.

1760
01:14:21,380 --> 01:14:24,940
That opportunity cost is too huge.

1761
01:14:24,980 --> 01:14:28,220
So yes, we're going to make mistakes,

1762
01:14:28,220 --> 01:14:31,380
but anybody who, we know from our personal lives,

1763
01:14:31,380 --> 01:14:34,740
if the thing that you are most optimizing

1764
01:14:34,740 --> 01:14:36,700
is to never make a mistake,

1765
01:14:36,700 --> 01:14:39,460
what's going to be the value of your life

1766
01:14:39,460 --> 01:14:41,940
and all the huffing and puffing

1767
01:14:41,940 --> 01:14:45,500
that we do during our brief time here?

1768
01:14:45,500 --> 01:14:46,500
What's the goal?

1769
01:14:46,500 --> 01:14:48,140
If that's, I mean, obviously you want to minimize

1770
01:14:48,140 --> 01:14:50,300
making mistakes, but there should be a constructive,

1771
01:14:50,300 --> 01:14:52,780
I believe there should be a constructive element to this

1772
01:14:52,820 --> 01:14:56,380
where you have a purpose to elevate and help others.

1773
01:14:56,380 --> 01:14:58,780
And that is not going to happen by focusing

1774
01:14:58,780 --> 01:15:00,900
on the things we shouldn't do.

1775
01:15:00,900 --> 01:15:05,220
And just more broadly, I ask people who focus

1776
01:15:05,220 --> 01:15:09,900
on this negative risk-based perspective,

1777
01:15:09,900 --> 01:15:12,420
what does humanity look like 100 years from now?

1778
01:15:12,420 --> 01:15:15,500
Are we still getting lower back pain and bad knees

1779
01:15:15,500 --> 01:15:18,460
and dying into our 80s once we've gotten this

1780
01:15:18,460 --> 01:15:19,660
a little bit of wisdom under our belts?

1781
01:15:19,660 --> 01:15:20,500
Like that's it.

1782
01:15:21,420 --> 01:15:23,020
And if you happen to, you know,

1783
01:15:23,020 --> 01:15:27,020
some cosmic ray or something hits one of your chromosomes,

1784
01:15:27,020 --> 01:15:29,060
then are we still living like that?

1785
01:15:29,060 --> 01:15:29,940
I mean, I can't imagine.

1786
01:15:29,940 --> 01:15:32,900
I just, that would seem like such a waste

1787
01:15:32,900 --> 01:15:34,940
of this incredible gift of intelligence

1788
01:15:34,940 --> 01:15:36,180
and compassion that we have

1789
01:15:36,180 --> 01:15:38,060
that it seems ludicrous to me.

1790
01:15:38,060 --> 01:15:40,700
But anybody, I think people should spend time

1791
01:15:40,700 --> 01:15:43,260
painting the future that they do want, you know?

1792
01:15:43,260 --> 01:15:44,420
Everybody's already paid, you know,

1793
01:15:44,420 --> 01:15:45,780
written down all the things they don't want.

1794
01:15:45,780 --> 01:15:46,620
That's fine.

1795
01:15:46,620 --> 01:15:48,860
Now, paint me a picture of what do you want?

1796
01:15:48,980 --> 01:15:50,820
Where should we be 100 years from now?

1797
01:15:50,820 --> 01:15:51,660
Yeah, thank you.

1798
01:15:51,660 --> 01:15:53,460
I'm a sucker for a bit of utopian thinking.

1799
01:15:53,460 --> 01:15:55,540
I know you're a fellow sci-fi fan as well.

1800
01:15:55,540 --> 01:15:58,220
And some people will use that as a way of discarding

1801
01:15:58,220 --> 01:16:00,500
some of the ideas you're working on and saying,

1802
01:16:00,500 --> 01:16:03,420
it's just sci-fi, but I think sci-fi's got a lot to teach you.

1803
01:16:03,420 --> 01:16:06,580
So I often find better philosophy in sci-fi

1804
01:16:06,580 --> 01:16:08,260
than I do in actual philosophy.

1805
01:16:08,260 --> 01:16:10,460
And one of the things about sci-fi is it's very good

1806
01:16:10,460 --> 01:16:13,380
at sort of intuitive sentientist stance

1807
01:16:13,380 --> 01:16:16,180
because it's so common and just natural

1808
01:16:16,180 --> 01:16:20,100
and even unthinking, most science fiction stories

1809
01:16:20,100 --> 01:16:23,260
to recognize the salience of sentient beings

1810
01:16:23,260 --> 01:16:24,740
that are radically different from ourselves.

1811
01:16:24,740 --> 01:16:26,380
And I think there's a lesson there we can take too.

1812
01:16:26,380 --> 01:16:27,220
So yeah.

1813
01:16:27,220 --> 01:16:28,060
For sure.

1814
01:16:28,060 --> 01:16:30,380
And you know, sci-fi, to me, if somebody says,

1815
01:16:30,380 --> 01:16:33,060
this is just sci-fi, my question is very simple.

1816
01:16:33,060 --> 01:16:34,540
Are you saying it's impossible

1817
01:16:34,540 --> 01:16:36,100
or are you just saying it's gonna take a while?

1818
01:16:36,100 --> 01:16:37,980
Like that's a certain things that maybe,

1819
01:16:37,980 --> 01:16:38,820
I don't know what those would be,

1820
01:16:38,820 --> 01:16:39,660
but there are certain things

1821
01:16:39,660 --> 01:16:41,540
that may be physically impossible, fine.

1822
01:16:41,540 --> 01:16:43,020
Everything else is just a time to,

1823
01:16:43,020 --> 01:16:45,100
then we're just quibbling over a timetable.

1824
01:16:45,140 --> 01:16:47,660
Everything that's possible is gonna be done.

1825
01:16:47,660 --> 01:16:48,980
And there's dystopian sci-fi,

1826
01:16:48,980 --> 01:16:50,500
but there's also utopian sci-fi.

1827
01:16:50,500 --> 01:16:52,980
So yeah, like I say, paint those pictures.

1828
01:16:52,980 --> 01:16:54,540
Well, it's been an inspirational conversation.

1829
01:16:54,540 --> 01:16:57,060
Thank you so much for talking to me today, Mike.

1830
01:16:57,060 --> 01:16:59,100
What's the best way of people following you,

1831
01:16:59,100 --> 01:17:00,620
finding out more about your work?

1832
01:17:00,620 --> 01:17:02,180
I'll include links in the show notes, of course,

1833
01:17:02,180 --> 01:17:04,340
but where's the main place you point people?

1834
01:17:04,340 --> 01:17:06,580
Yeah, the official lab website

1835
01:17:06,580 --> 01:17:09,860
that has all of the kind of peer reviewed hard stuff

1836
01:17:09,860 --> 01:17:14,220
is darmike11.org, one word, darmike11.org.

1837
01:17:14,260 --> 01:17:16,100
The more speculative, you know,

1838
01:17:16,100 --> 01:17:18,180
the photography, the pros and all that stuff,

1839
01:17:18,180 --> 01:17:19,780
and so just some thoughts that I wouldn't,

1840
01:17:19,780 --> 01:17:21,700
you know, I wouldn't put in a scientific paper

1841
01:17:21,700 --> 01:17:23,820
is at thoughtforms.life.

1842
01:17:23,820 --> 01:17:25,700
It's a blog called thoughtforms.life.

1843
01:17:25,700 --> 01:17:29,060
And I'm on Twitter at at darmike11.

1844
01:17:29,060 --> 01:17:29,900
Yeah, that's awesome.

1845
01:17:29,900 --> 01:17:30,740
Thank you.

1846
01:17:30,740 --> 01:17:32,580
And I'll follow up with some vegan tips offline.

1847
01:17:32,580 --> 01:17:34,060
Cool, that would be great.

1848
01:17:34,060 --> 01:17:34,900
I appreciate it.

1849
01:17:34,900 --> 01:17:35,900
All right, well, thank you so much

1850
01:17:35,900 --> 01:17:37,300
for being a guest on Sentientism.

1851
01:17:37,300 --> 01:17:38,300
It's been a pleasure, Mike.

1852
01:17:38,300 --> 01:17:40,100
Take care, enjoy the rest of your day.

1853
01:17:40,100 --> 01:17:41,740
Thank you, you too.

1854
01:17:41,740 --> 01:17:42,740
Please stay in touch.

