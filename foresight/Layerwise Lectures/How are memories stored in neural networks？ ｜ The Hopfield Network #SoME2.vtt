WEBVTT

00:00.000 --> 00:06.880
The amount of random access memory, RAM, in a typical laptop is probably around 8 to 32GB.

00:06.880 --> 00:12.000
That's the part that directly interacts with the CPU. Aside from that, your hard disk might have,

00:12.000 --> 00:18.480
say, another terabyte or so of memory. But how much memory do you, that's to say, the human brain

00:18.480 --> 00:24.320
have? And can we even measure it in bytes? But maybe that's not even the first question we should

00:24.320 --> 00:31.760
ask. However much memory the brain has, where is it? Because every piece of memory in a computer

00:31.760 --> 00:37.280
has a physical location. To access a piece of data in RAM, for example, you have to know the

00:37.280 --> 00:42.800
binary address associated with that location. In fact, for the CPU, this really comes down to

00:42.800 --> 00:48.720
turning on just the right wires to retrieve the bits at the desired location. Now imagine a different

00:48.720 --> 00:54.960
kind of memory. Instead of specifying the where of a memory, its binary address, how about we could

00:54.960 --> 01:02.400
specify the what? Its content. A memory system, where if we provide an incomplete version of the

01:02.400 --> 01:08.320
memory, it just sort of autocompletes. Of course, with the right software, your computer can already

01:08.320 --> 01:13.840
do this. But it's not how computer memory works on its basic level. The point of this video is

01:13.840 --> 01:19.680
to convince you that autocompleting memories, also known as associative memory, is a kind of

01:19.680 --> 01:24.800
natural behavior of networks of neurons. With that, it'll become clear that it doesn't really

01:24.800 --> 01:29.920
make sense to measure memory capacity in networks of neurons in the same way we measure computer

01:29.920 --> 01:35.520
memory. The biggest difference might be computer memories have a place, a fixed location, but as

01:35.520 --> 01:39.360
we'll see, the memories in an associative network rather have a time.

01:46.880 --> 01:52.080
Computer memory is measured in bits, binary switches of ones and zeros. A string of eight

01:52.080 --> 01:58.160
such bits can represent anything from letters to integers. For our purposes, let's visualize them

01:58.160 --> 02:04.240
as patterns of this kind, like these 64 bits representing this 8x8 image of binary pixels.

02:05.200 --> 02:08.960
I always find that there's a piece missing from the story of bits as memory,

02:08.960 --> 02:14.880
and that's the following. How do I get to a memory once it's saved, say, in RAM? Because

02:14.880 --> 02:20.640
on its own, it doesn't do much. It's only when we retrieve it that it becomes useful.

02:21.360 --> 02:26.400
So how do we? Well, broadly speaking, and I'm glossing over tons of technical detail here,

02:26.400 --> 02:32.240
every piece of data in RAM is matched to a binary address. And this binary address really

02:32.240 --> 02:37.600
eventually boils down to a set of wires, in this case eight, that are either turned on or off.

02:38.160 --> 02:43.120
Each piece of data is in a different physical location, and can only be retrieved by knowing

02:43.120 --> 02:48.080
its address. How the reading and writing of memories is accomplished is really the meat of

02:48.080 --> 02:53.840
programming and is another story. What I want you to remember is the peculiar fact that memories

02:53.840 --> 02:59.600
are matched to addresses, and that's ultimately the only way to retrieve them. Contrast this with

02:59.600 --> 03:04.880
what we believe about the brain. There isn't a central orchestrator, like a CPU, and there aren't

03:04.880 --> 03:12.000
any addresses. Rather, there is a constant buzz of activity of many independent units called neurons.

03:12.000 --> 03:17.280
In this video, we'll try to make some sense of the buzzing of activity of networks of neurons

03:17.280 --> 03:23.520
by introducing a mathematical model called the Hopfield Network, named after the author of this

03:23.600 --> 03:29.360
1982 paper. And as much as this has to do with memory, more generally, this video aims to be a

03:29.360 --> 03:36.640
lesson in modeling itself, which I always think of as the art of the essential. This is a neuron.

03:36.640 --> 03:40.880
I'm almost certain you've seen something like this before, but it sometimes pays to remember

03:40.880 --> 03:45.680
why we always come back to this when we want to understand things about the brain. The reason is,

03:45.680 --> 03:51.520
I think, that it has a rather simple behavior. It integrates electrical signals from other neurons

03:51.520 --> 03:56.240
to determine its own activity, and then it broadcasts that activity back to the network.

03:56.880 --> 04:01.520
Mathematically, the story goes something like this. There's electrical signals coming in from

04:01.520 --> 04:07.120
other neurons, which we will say are just some numbers. Then the synapses act as multipliers

04:07.120 --> 04:12.800
on these signals, another set of numbers. And then the activity of the neuron is based on the sum

04:12.800 --> 04:18.400
of the weighted inputs. And by based on, I mean that it's fine to apply some function

04:18.400 --> 04:23.520
after computing the sum. And that's it. So it gets interesting once we turn this into a network,

04:23.520 --> 04:28.720
connecting the outputs of neurons to the inputs of other neurons. This is a special type of neural

04:28.720 --> 04:33.520
network. It's a recurrent network, meaning that there are back and forth connections between the

04:33.520 --> 04:39.520
neurons. I haven't drawn them, but remember that any such edge is actually two edges, so that the

04:39.520 --> 04:46.560
two neurons influence each other. Okay, there's details here that we need to get into. But first,

04:46.560 --> 04:51.200
what does this have to do with memory? Well, it needs to be somewhere in here, doesn't it?

04:51.760 --> 04:57.520
Where? Remember the idea of an associative memory, which is the ability of a system to sort of pattern

04:57.520 --> 05:03.120
autocomplete? Let's try a definition of memory that's slightly wider than maybe what we're used to.

05:03.120 --> 05:08.080
Let a memory system be a system, that after having been in a certain state, a configuration,

05:08.080 --> 05:14.400
it has the ability to return to that state later on. Now, our computer memory from earlier actually

05:14.400 --> 05:20.720
has this property, if we include the CPU into the memory system. Our network seems different, though.

05:21.280 --> 05:26.400
So let's get creative. There's other things in our everyday lives that fall under our definition

05:26.400 --> 05:32.560
of memory. And one might be, and hear me out on this, a simple plastic bottle. If it's crushed,

05:32.560 --> 05:37.520
in other words, its configuration changed, it can sometimes return to its earlier state,

05:37.520 --> 05:42.400
which in that sense could be said to have been memorized. And the metaphor is not arbitrary.

05:42.400 --> 05:48.240
I actually do think that networks of neurons are kind of like that. What I mean is a neural network

05:48.240 --> 05:53.840
is a system with a pattern of activity that dynamically evolves. If somehow we could construct

05:53.840 --> 05:59.280
our network such that it would have some preferred state and would return to that state over time,

05:59.280 --> 06:03.600
if it was perturbed, then that could reasonably be qualified as a memory.

06:04.960 --> 06:10.720
This is a network of 64 neurons that I cleverly constructed such that it memorized this pattern

06:10.720 --> 06:16.880
of 8x8 binary pixels. So what's going on? To describe what this model is actually doing,

06:16.880 --> 06:21.920
we need to take the following steps. Remember I said time was important? We need to describe how

06:21.920 --> 06:27.120
the activity of the network changes over time. And then there's the question of learning. How do

06:27.120 --> 06:32.080
we actually imprint memories into the network? And this will have to do with the connections

06:32.080 --> 06:37.280
between the neurons. Finally, we need to understand if and when the network converges to its memory

06:37.280 --> 06:44.000
states. The crucial ingredient of our network really is the fact that it is a dynamical system.

06:44.000 --> 06:50.080
Its activity changes over time. By activity, we mean that each of the now 16 neurons in the

06:50.080 --> 06:55.760
network is described by a number and that this number is a function of time. And let's just

06:55.760 --> 07:01.360
assume that time moves forward in discrete steps. Furthermore, since we are interested in binary

07:01.360 --> 07:07.280
memory states, we will assume that activity means that the neurons can only be in one of two states,

07:07.280 --> 07:14.880
inactive, say minus one, and active, say plus one. Anyway, this all leaves us with 16 minus or

07:14.880 --> 07:22.560
plus ones at any given time, which we will call the state of the network. What actually happens

07:22.560 --> 07:29.440
if we increase time by one step? Imagine folding out the time dimension in space. Now we select

07:29.440 --> 07:35.120
one of the neurons at random and update its state according to the input of all other neurons

07:35.120 --> 07:41.600
in the network. The rest of the neurons stay the same. And this we simply continue.

07:45.040 --> 07:51.120
But hold on, you might ask. How do we update the state exactly? And why update only one neuron at

07:51.120 --> 07:56.880
a time? Well, for the second question, we could in fact update all neurons at once. But the issue

07:56.880 --> 08:02.480
here is plausibility, because that would require a global updating signal, almost like a clock,

08:02.480 --> 08:08.560
instructing all neurons to update simultaneously. It's slightly more realistic, although not too

08:08.560 --> 08:14.320
much to be honest, to let them update asynchronously. Okay, and for the other question, yes, what is the

08:14.320 --> 08:19.760
actual update equation? Well, it's remarkably simple. It's a weighted sum of the states of the

08:19.760 --> 08:25.360
other neurons. Weighted meaning that each state is multiplied by the strength of the connection

08:25.360 --> 08:31.120
between the neurons. And since the connections, in that sense, weigh the inputs, from now on,

08:31.120 --> 08:36.160
I'm actually going to call them weights. But then of course, to ensure that the result is plus one

08:36.160 --> 08:41.440
or minus one again, we'll make use of that function I mentioned earlier, F. And that's it.

08:41.440 --> 08:46.560
Those of you familiar with linear algebra will have recognized this as computing the dot product

08:46.560 --> 08:50.560
between the vector of neuron states and the vector of connection weights.

08:50.960 --> 08:58.240
This is a network of 64 neurons. And I'm just going to tell you without explaining how

08:58.240 --> 09:04.160
that it has memorized this pattern, starting it off in different initial states, and then running the

09:04.160 --> 09:09.920
equations I just described, selecting one neuron at a time at random and updating its activity.

09:09.920 --> 09:14.720
And wait, let's just make this a little simpler. We can see that the network really has this

09:14.720 --> 09:21.440
intriguing property that it gravitates towards the memory pattern in all cases. Or well, it ends

09:21.440 --> 09:25.680
up with the anti memory in some cases, we'll ignore that it has to do with a certain symmetry in the

09:25.680 --> 09:32.160
network that we will get to. Moreover, once it's settled into that state, it doesn't change anymore.

09:32.160 --> 09:38.160
The memory pattern is what is called a stable state of the network. So can we be sure that this

09:38.160 --> 09:42.960
always happens? Well, no. For example, things start to get complicated when there is more than one

09:42.960 --> 09:47.920
memory stored in the network. We'll get to that. But for the simple case of just a single memory,

09:47.920 --> 09:53.120
yeah, the network will converge to either the memory or its anti memory or as an edge case

09:53.120 --> 09:59.040
to the completely inactive state. So let's recap. Networks are just vectors that evolve in time and

09:59.040 --> 10:04.400
we update their elements asynchronously. Given some configuration of weights, there are stable

10:04.400 --> 10:09.680
states in the network, which we call memory states. And we have seen, although not proved,

10:09.680 --> 10:14.480
that the network is kind of attracted to these states. That leaves the following question.

10:14.480 --> 10:19.760
How do we make the network memorize a certain pattern? In other words, how can we design the

10:19.760 --> 10:24.720
stable states of the network? This amounts to setting the weights of the network, which turns

10:24.720 --> 10:30.880
out to be a matrix with as many rows and columns as there are neurons. For example, the state of

10:30.880 --> 10:37.680
this neuron is determined by the weights in this row of the matrix. At first, this might seem impossible,

10:37.680 --> 10:40.640
especially if we wish to store more than one memory in the network.

10:42.800 --> 10:47.920
So I'm just going to tell you the magic rule and then I'll motivate it. Given a desired memory

10:47.920 --> 10:54.000
state with, say, eight elements, we are looking for an eight by eight matrix. We will just say,

10:54.000 --> 11:00.400
seemingly out of nowhere, that the weight between two neurons, i, j in general, is determined by

11:00.400 --> 11:05.920
the product of their states in the memory. For all of you keen on linear algebra, this means

11:05.920 --> 11:11.440
that the matrix is an outer product of the memory vector with itself, except for the diagonal,

11:11.440 --> 11:19.040
which we set to zero, since we don't want any self-reinforcement. But why? Think of it this way.

11:19.040 --> 11:23.520
Our whole approach was in some sense to build something interesting from many simple parts.

11:24.400 --> 11:29.040
So there really should be a way for the two neurons to determine the weight between them,

11:29.040 --> 11:33.920
independent of the rest of the network. This is a principle called Hebbian learning,

11:33.920 --> 11:38.480
and it is exceedingly plausible, because remember that weights are supposed to be synapses?

11:39.040 --> 11:44.000
And synapses in actual neurons also would have no way of knowing what goes on in the broader

11:44.000 --> 11:50.480
network. And so why the multiplication? Well, here comes the reason I called it the binary states,

11:50.480 --> 11:54.960
minus one and plus one. If you map out all four combinations of states of the neurons,

11:55.520 --> 12:00.320
you'll see that the weight will have positive sign whenever the neurons in their memory state

12:00.320 --> 12:06.480
agree and negative if they disagree. And this should make sense, because a positive weight

12:06.480 --> 12:14.240
lets a neuron project its state onto other neurons, and a negative weight lets a neuron flip the state

12:14.240 --> 12:22.080
of other neurons. It's almost like the neurons behave like charged particles, maybe. One last

12:22.080 --> 12:26.720
question before we can see it in action, and that's how do we store multiple patterns at once

12:26.720 --> 12:32.000
in the same network? We do it by computing the outer products for all desired memory patterns,

12:32.000 --> 12:37.840
this gives us a matrix for each, and then we average those matrices. This gives finer and

12:37.840 --> 12:43.120
finer gradations of the weights. Now, however, things start to become a little bit more complicated.

12:43.680 --> 12:48.800
There's no way to guarantee that all memory patterns are stable states. The memories will

12:48.800 --> 12:54.880
start talking to each other, fusing into new memories, which I find frustrating and super

12:54.880 --> 13:00.000
interesting at the same time. Here's the network with four memories again. It sometimes converges

13:00.000 --> 13:05.680
to one of the memory states, yes, but in other cases, it converges to something in between,

13:06.320 --> 13:11.840
a merging of memories, which I find, well, almost a kind of human mistake.

13:13.200 --> 13:17.840
And with this, we are finally making some progress on our question from the very beginning of the

13:17.840 --> 13:24.080
video. How much memory do you have? Originally, we might have answered this by giving some number

13:24.080 --> 13:29.120
of bytes. But now the question presents itself very differently. It's more like, how many

13:29.120 --> 13:35.600
memory patterns can we store in a recurrent network of a given size, such that they are stable states

13:35.600 --> 13:41.600
of the network? And the answer is, at least for this model, not very many. The original paper

13:41.600 --> 13:46.080
showed that this model has only linear memory capacity. That's to say, the number of stable

13:46.080 --> 13:51.200
states grows as a linear function of the size of the network. Plus, there's a hidden assumption

13:51.280 --> 13:56.000
in this graph too, which is that all memory states are uncorrelated, which, for any set of

13:56.000 --> 14:01.280
pictures like this, is totally not the case. I tried my best picking out some not-so-correlated

14:01.280 --> 14:05.760
images to really show what this network can do, and the results are, well, see for yourself.

14:10.160 --> 14:15.520
Realistically, that means that this model is maybe too simple after all. And that's not

14:15.520 --> 14:20.000
surprising given all the violence we did to these networks with our many simplifications.

14:20.000 --> 14:23.920
But the goal of this video wasn't to convince you that this model can be used in any practical

14:23.920 --> 14:28.560
sense anyway. Although, in a follow-up video, I want to tell you what steps people took to

14:28.560 --> 14:33.120
make this model actually useful for deep neural networks. What I wanted to achieve with this

14:33.120 --> 14:40.640
video is, first, to warn you of false comparisons. Networks of neurons don't behave like USB sticks,

14:40.640 --> 14:46.720
and why should they? But secondly, it's to show you how with modeling approaches, walking a very

14:46.800 --> 14:51.840
thin line between complexity and simplicity, we can sometimes start to conceive of the world

14:51.840 --> 14:56.800
differently than otherwise we would have. You might have set out picturing memory as

14:56.800 --> 15:02.240
something static, but I'm hoping now you're willing to consider that it might be something dynamic,

15:02.880 --> 15:08.240
the invisible, stable states of a network buzzing with activity.

