start	end	text
0	6880	The amount of random access memory, RAM, in a typical laptop is probably around 8 to 32GB.
6880	12000	That's the part that directly interacts with the CPU. Aside from that, your hard disk might have,
12000	18480	say, another terabyte or so of memory. But how much memory do you, that's to say, the human brain
18480	24320	have? And can we even measure it in bytes? But maybe that's not even the first question we should
24320	31760	ask. However much memory the brain has, where is it? Because every piece of memory in a computer
31760	37280	has a physical location. To access a piece of data in RAM, for example, you have to know the
37280	42800	binary address associated with that location. In fact, for the CPU, this really comes down to
42800	48720	turning on just the right wires to retrieve the bits at the desired location. Now imagine a different
48720	54960	kind of memory. Instead of specifying the where of a memory, its binary address, how about we could
54960	62400	specify the what? Its content. A memory system, where if we provide an incomplete version of the
62400	68320	memory, it just sort of autocompletes. Of course, with the right software, your computer can already
68320	73840	do this. But it's not how computer memory works on its basic level. The point of this video is
73840	79680	to convince you that autocompleting memories, also known as associative memory, is a kind of
79680	84800	natural behavior of networks of neurons. With that, it'll become clear that it doesn't really
84800	89920	make sense to measure memory capacity in networks of neurons in the same way we measure computer
89920	95520	memory. The biggest difference might be computer memories have a place, a fixed location, but as
95520	99360	we'll see, the memories in an associative network rather have a time.
106880	112080	Computer memory is measured in bits, binary switches of ones and zeros. A string of eight
112080	118160	such bits can represent anything from letters to integers. For our purposes, let's visualize them
118160	124240	as patterns of this kind, like these 64 bits representing this 8x8 image of binary pixels.
125200	128960	I always find that there's a piece missing from the story of bits as memory,
128960	134880	and that's the following. How do I get to a memory once it's saved, say, in RAM? Because
134880	140640	on its own, it doesn't do much. It's only when we retrieve it that it becomes useful.
141360	146400	So how do we? Well, broadly speaking, and I'm glossing over tons of technical detail here,
146400	152240	every piece of data in RAM is matched to a binary address. And this binary address really
152240	157600	eventually boils down to a set of wires, in this case eight, that are either turned on or off.
158160	163120	Each piece of data is in a different physical location, and can only be retrieved by knowing
163120	168080	its address. How the reading and writing of memories is accomplished is really the meat of
168080	173840	programming and is another story. What I want you to remember is the peculiar fact that memories
173840	179600	are matched to addresses, and that's ultimately the only way to retrieve them. Contrast this with
179600	184880	what we believe about the brain. There isn't a central orchestrator, like a CPU, and there aren't
184880	192000	any addresses. Rather, there is a constant buzz of activity of many independent units called neurons.
192000	197280	In this video, we'll try to make some sense of the buzzing of activity of networks of neurons
197280	203520	by introducing a mathematical model called the Hopfield Network, named after the author of this
203600	209360	1982 paper. And as much as this has to do with memory, more generally, this video aims to be a
209360	216640	lesson in modeling itself, which I always think of as the art of the essential. This is a neuron.
216640	220880	I'm almost certain you've seen something like this before, but it sometimes pays to remember
220880	225680	why we always come back to this when we want to understand things about the brain. The reason is,
225680	231520	I think, that it has a rather simple behavior. It integrates electrical signals from other neurons
231520	236240	to determine its own activity, and then it broadcasts that activity back to the network.
236880	241520	Mathematically, the story goes something like this. There's electrical signals coming in from
241520	247120	other neurons, which we will say are just some numbers. Then the synapses act as multipliers
247120	252800	on these signals, another set of numbers. And then the activity of the neuron is based on the sum
252800	258400	of the weighted inputs. And by based on, I mean that it's fine to apply some function
258400	263520	after computing the sum. And that's it. So it gets interesting once we turn this into a network,
263520	268720	connecting the outputs of neurons to the inputs of other neurons. This is a special type of neural
268720	273520	network. It's a recurrent network, meaning that there are back and forth connections between the
273520	279520	neurons. I haven't drawn them, but remember that any such edge is actually two edges, so that the
279520	286560	two neurons influence each other. Okay, there's details here that we need to get into. But first,
286560	291200	what does this have to do with memory? Well, it needs to be somewhere in here, doesn't it?
291760	297520	Where? Remember the idea of an associative memory, which is the ability of a system to sort of pattern
297520	303120	autocomplete? Let's try a definition of memory that's slightly wider than maybe what we're used to.
303120	308080	Let a memory system be a system, that after having been in a certain state, a configuration,
308080	314400	it has the ability to return to that state later on. Now, our computer memory from earlier actually
314400	320720	has this property, if we include the CPU into the memory system. Our network seems different, though.
321280	326400	So let's get creative. There's other things in our everyday lives that fall under our definition
326400	332560	of memory. And one might be, and hear me out on this, a simple plastic bottle. If it's crushed,
332560	337520	in other words, its configuration changed, it can sometimes return to its earlier state,
337520	342400	which in that sense could be said to have been memorized. And the metaphor is not arbitrary.
342400	348240	I actually do think that networks of neurons are kind of like that. What I mean is a neural network
348240	353840	is a system with a pattern of activity that dynamically evolves. If somehow we could construct
353840	359280	our network such that it would have some preferred state and would return to that state over time,
359280	363600	if it was perturbed, then that could reasonably be qualified as a memory.
364960	370720	This is a network of 64 neurons that I cleverly constructed such that it memorized this pattern
370720	376880	of 8x8 binary pixels. So what's going on? To describe what this model is actually doing,
376880	381920	we need to take the following steps. Remember I said time was important? We need to describe how
381920	387120	the activity of the network changes over time. And then there's the question of learning. How do
387120	392080	we actually imprint memories into the network? And this will have to do with the connections
392080	397280	between the neurons. Finally, we need to understand if and when the network converges to its memory
397280	404000	states. The crucial ingredient of our network really is the fact that it is a dynamical system.
404000	410080	Its activity changes over time. By activity, we mean that each of the now 16 neurons in the
410080	415760	network is described by a number and that this number is a function of time. And let's just
415760	421360	assume that time moves forward in discrete steps. Furthermore, since we are interested in binary
421360	427280	memory states, we will assume that activity means that the neurons can only be in one of two states,
427280	434880	inactive, say minus one, and active, say plus one. Anyway, this all leaves us with 16 minus or
434880	442560	plus ones at any given time, which we will call the state of the network. What actually happens
442560	449440	if we increase time by one step? Imagine folding out the time dimension in space. Now we select
449440	455120	one of the neurons at random and update its state according to the input of all other neurons
455120	461600	in the network. The rest of the neurons stay the same. And this we simply continue.
465040	471120	But hold on, you might ask. How do we update the state exactly? And why update only one neuron at
471120	476880	a time? Well, for the second question, we could in fact update all neurons at once. But the issue
476880	482480	here is plausibility, because that would require a global updating signal, almost like a clock,
482480	488560	instructing all neurons to update simultaneously. It's slightly more realistic, although not too
488560	494320	much to be honest, to let them update asynchronously. Okay, and for the other question, yes, what is the
494320	499760	actual update equation? Well, it's remarkably simple. It's a weighted sum of the states of the
499760	505360	other neurons. Weighted meaning that each state is multiplied by the strength of the connection
505360	511120	between the neurons. And since the connections, in that sense, weigh the inputs, from now on,
511120	516160	I'm actually going to call them weights. But then of course, to ensure that the result is plus one
516160	521440	or minus one again, we'll make use of that function I mentioned earlier, F. And that's it.
521440	526560	Those of you familiar with linear algebra will have recognized this as computing the dot product
526560	530560	between the vector of neuron states and the vector of connection weights.
530960	538240	This is a network of 64 neurons. And I'm just going to tell you without explaining how
538240	544160	that it has memorized this pattern, starting it off in different initial states, and then running the
544160	549920	equations I just described, selecting one neuron at a time at random and updating its activity.
549920	554720	And wait, let's just make this a little simpler. We can see that the network really has this
554720	561440	intriguing property that it gravitates towards the memory pattern in all cases. Or well, it ends
561440	565680	up with the anti memory in some cases, we'll ignore that it has to do with a certain symmetry in the
565680	572160	network that we will get to. Moreover, once it's settled into that state, it doesn't change anymore.
572160	578160	The memory pattern is what is called a stable state of the network. So can we be sure that this
578160	582960	always happens? Well, no. For example, things start to get complicated when there is more than one
582960	587920	memory stored in the network. We'll get to that. But for the simple case of just a single memory,
587920	593120	yeah, the network will converge to either the memory or its anti memory or as an edge case
593120	599040	to the completely inactive state. So let's recap. Networks are just vectors that evolve in time and
599040	604400	we update their elements asynchronously. Given some configuration of weights, there are stable
604400	609680	states in the network, which we call memory states. And we have seen, although not proved,
609680	614480	that the network is kind of attracted to these states. That leaves the following question.
614480	619760	How do we make the network memorize a certain pattern? In other words, how can we design the
619760	624720	stable states of the network? This amounts to setting the weights of the network, which turns
624720	630880	out to be a matrix with as many rows and columns as there are neurons. For example, the state of
630880	637680	this neuron is determined by the weights in this row of the matrix. At first, this might seem impossible,
637680	640640	especially if we wish to store more than one memory in the network.
642800	647920	So I'm just going to tell you the magic rule and then I'll motivate it. Given a desired memory
647920	654000	state with, say, eight elements, we are looking for an eight by eight matrix. We will just say,
654000	660400	seemingly out of nowhere, that the weight between two neurons, i, j in general, is determined by
660400	665920	the product of their states in the memory. For all of you keen on linear algebra, this means
665920	671440	that the matrix is an outer product of the memory vector with itself, except for the diagonal,
671440	679040	which we set to zero, since we don't want any self-reinforcement. But why? Think of it this way.
679040	683520	Our whole approach was in some sense to build something interesting from many simple parts.
684400	689040	So there really should be a way for the two neurons to determine the weight between them,
689040	693920	independent of the rest of the network. This is a principle called Hebbian learning,
693920	698480	and it is exceedingly plausible, because remember that weights are supposed to be synapses?
699040	704000	And synapses in actual neurons also would have no way of knowing what goes on in the broader
704000	710480	network. And so why the multiplication? Well, here comes the reason I called it the binary states,
710480	714960	minus one and plus one. If you map out all four combinations of states of the neurons,
715520	720320	you'll see that the weight will have positive sign whenever the neurons in their memory state
720320	726480	agree and negative if they disagree. And this should make sense, because a positive weight
726480	734240	lets a neuron project its state onto other neurons, and a negative weight lets a neuron flip the state
734240	742080	of other neurons. It's almost like the neurons behave like charged particles, maybe. One last
742080	746720	question before we can see it in action, and that's how do we store multiple patterns at once
746720	752000	in the same network? We do it by computing the outer products for all desired memory patterns,
752000	757840	this gives us a matrix for each, and then we average those matrices. This gives finer and
757840	763120	finer gradations of the weights. Now, however, things start to become a little bit more complicated.
763680	768800	There's no way to guarantee that all memory patterns are stable states. The memories will
768800	774880	start talking to each other, fusing into new memories, which I find frustrating and super
774880	780000	interesting at the same time. Here's the network with four memories again. It sometimes converges
780000	785680	to one of the memory states, yes, but in other cases, it converges to something in between,
786320	791840	a merging of memories, which I find, well, almost a kind of human mistake.
793200	797840	And with this, we are finally making some progress on our question from the very beginning of the
797840	804080	video. How much memory do you have? Originally, we might have answered this by giving some number
804080	809120	of bytes. But now the question presents itself very differently. It's more like, how many
809120	815600	memory patterns can we store in a recurrent network of a given size, such that they are stable states
815600	821600	of the network? And the answer is, at least for this model, not very many. The original paper
821600	826080	showed that this model has only linear memory capacity. That's to say, the number of stable
826080	831200	states grows as a linear function of the size of the network. Plus, there's a hidden assumption
831280	836000	in this graph too, which is that all memory states are uncorrelated, which, for any set of
836000	841280	pictures like this, is totally not the case. I tried my best picking out some not-so-correlated
841280	845760	images to really show what this network can do, and the results are, well, see for yourself.
850160	855520	Realistically, that means that this model is maybe too simple after all. And that's not
855520	860000	surprising given all the violence we did to these networks with our many simplifications.
860000	863920	But the goal of this video wasn't to convince you that this model can be used in any practical
863920	868560	sense anyway. Although, in a follow-up video, I want to tell you what steps people took to
868560	873120	make this model actually useful for deep neural networks. What I wanted to achieve with this
873120	880640	video is, first, to warn you of false comparisons. Networks of neurons don't behave like USB sticks,
880640	886720	and why should they? But secondly, it's to show you how with modeling approaches, walking a very
886800	891840	thin line between complexity and simplicity, we can sometimes start to conceive of the world
891840	896800	differently than otherwise we would have. You might have set out picturing memory as
896800	902240	something static, but I'm hoping now you're willing to consider that it might be something dynamic,
902880	908240	the invisible, stable states of a network buzzing with activity.
