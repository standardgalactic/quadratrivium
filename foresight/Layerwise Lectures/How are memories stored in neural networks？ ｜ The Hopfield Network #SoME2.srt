1
00:00:00,000 --> 00:00:06,880
The amount of random access memory, RAM, in a typical laptop is probably around 8 to 32GB.

2
00:00:06,880 --> 00:00:12,000
That's the part that directly interacts with the CPU. Aside from that, your hard disk might have,

3
00:00:12,000 --> 00:00:18,480
say, another terabyte or so of memory. But how much memory do you, that's to say, the human brain

4
00:00:18,480 --> 00:00:24,320
have? And can we even measure it in bytes? But maybe that's not even the first question we should

5
00:00:24,320 --> 00:00:31,760
ask. However much memory the brain has, where is it? Because every piece of memory in a computer

6
00:00:31,760 --> 00:00:37,280
has a physical location. To access a piece of data in RAM, for example, you have to know the

7
00:00:37,280 --> 00:00:42,800
binary address associated with that location. In fact, for the CPU, this really comes down to

8
00:00:42,800 --> 00:00:48,720
turning on just the right wires to retrieve the bits at the desired location. Now imagine a different

9
00:00:48,720 --> 00:00:54,960
kind of memory. Instead of specifying the where of a memory, its binary address, how about we could

10
00:00:54,960 --> 00:01:02,400
specify the what? Its content. A memory system, where if we provide an incomplete version of the

11
00:01:02,400 --> 00:01:08,320
memory, it just sort of autocompletes. Of course, with the right software, your computer can already

12
00:01:08,320 --> 00:01:13,840
do this. But it's not how computer memory works on its basic level. The point of this video is

13
00:01:13,840 --> 00:01:19,680
to convince you that autocompleting memories, also known as associative memory, is a kind of

14
00:01:19,680 --> 00:01:24,800
natural behavior of networks of neurons. With that, it'll become clear that it doesn't really

15
00:01:24,800 --> 00:01:29,920
make sense to measure memory capacity in networks of neurons in the same way we measure computer

16
00:01:29,920 --> 00:01:35,520
memory. The biggest difference might be computer memories have a place, a fixed location, but as

17
00:01:35,520 --> 00:01:39,360
we'll see, the memories in an associative network rather have a time.

18
00:01:46,880 --> 00:01:52,080
Computer memory is measured in bits, binary switches of ones and zeros. A string of eight

19
00:01:52,080 --> 00:01:58,160
such bits can represent anything from letters to integers. For our purposes, let's visualize them

20
00:01:58,160 --> 00:02:04,240
as patterns of this kind, like these 64 bits representing this 8x8 image of binary pixels.

21
00:02:05,200 --> 00:02:08,960
I always find that there's a piece missing from the story of bits as memory,

22
00:02:08,960 --> 00:02:14,880
and that's the following. How do I get to a memory once it's saved, say, in RAM? Because

23
00:02:14,880 --> 00:02:20,640
on its own, it doesn't do much. It's only when we retrieve it that it becomes useful.

24
00:02:21,360 --> 00:02:26,400
So how do we? Well, broadly speaking, and I'm glossing over tons of technical detail here,

25
00:02:26,400 --> 00:02:32,240
every piece of data in RAM is matched to a binary address. And this binary address really

26
00:02:32,240 --> 00:02:37,600
eventually boils down to a set of wires, in this case eight, that are either turned on or off.

27
00:02:38,160 --> 00:02:43,120
Each piece of data is in a different physical location, and can only be retrieved by knowing

28
00:02:43,120 --> 00:02:48,080
its address. How the reading and writing of memories is accomplished is really the meat of

29
00:02:48,080 --> 00:02:53,840
programming and is another story. What I want you to remember is the peculiar fact that memories

30
00:02:53,840 --> 00:02:59,600
are matched to addresses, and that's ultimately the only way to retrieve them. Contrast this with

31
00:02:59,600 --> 00:03:04,880
what we believe about the brain. There isn't a central orchestrator, like a CPU, and there aren't

32
00:03:04,880 --> 00:03:12,000
any addresses. Rather, there is a constant buzz of activity of many independent units called neurons.

33
00:03:12,000 --> 00:03:17,280
In this video, we'll try to make some sense of the buzzing of activity of networks of neurons

34
00:03:17,280 --> 00:03:23,520
by introducing a mathematical model called the Hopfield Network, named after the author of this

35
00:03:23,600 --> 00:03:29,360
1982 paper. And as much as this has to do with memory, more generally, this video aims to be a

36
00:03:29,360 --> 00:03:36,640
lesson in modeling itself, which I always think of as the art of the essential. This is a neuron.

37
00:03:36,640 --> 00:03:40,880
I'm almost certain you've seen something like this before, but it sometimes pays to remember

38
00:03:40,880 --> 00:03:45,680
why we always come back to this when we want to understand things about the brain. The reason is,

39
00:03:45,680 --> 00:03:51,520
I think, that it has a rather simple behavior. It integrates electrical signals from other neurons

40
00:03:51,520 --> 00:03:56,240
to determine its own activity, and then it broadcasts that activity back to the network.

41
00:03:56,880 --> 00:04:01,520
Mathematically, the story goes something like this. There's electrical signals coming in from

42
00:04:01,520 --> 00:04:07,120
other neurons, which we will say are just some numbers. Then the synapses act as multipliers

43
00:04:07,120 --> 00:04:12,800
on these signals, another set of numbers. And then the activity of the neuron is based on the sum

44
00:04:12,800 --> 00:04:18,400
of the weighted inputs. And by based on, I mean that it's fine to apply some function

45
00:04:18,400 --> 00:04:23,520
after computing the sum. And that's it. So it gets interesting once we turn this into a network,

46
00:04:23,520 --> 00:04:28,720
connecting the outputs of neurons to the inputs of other neurons. This is a special type of neural

47
00:04:28,720 --> 00:04:33,520
network. It's a recurrent network, meaning that there are back and forth connections between the

48
00:04:33,520 --> 00:04:39,520
neurons. I haven't drawn them, but remember that any such edge is actually two edges, so that the

49
00:04:39,520 --> 00:04:46,560
two neurons influence each other. Okay, there's details here that we need to get into. But first,

50
00:04:46,560 --> 00:04:51,200
what does this have to do with memory? Well, it needs to be somewhere in here, doesn't it?

51
00:04:51,760 --> 00:04:57,520
Where? Remember the idea of an associative memory, which is the ability of a system to sort of pattern

52
00:04:57,520 --> 00:05:03,120
autocomplete? Let's try a definition of memory that's slightly wider than maybe what we're used to.

53
00:05:03,120 --> 00:05:08,080
Let a memory system be a system, that after having been in a certain state, a configuration,

54
00:05:08,080 --> 00:05:14,400
it has the ability to return to that state later on. Now, our computer memory from earlier actually

55
00:05:14,400 --> 00:05:20,720
has this property, if we include the CPU into the memory system. Our network seems different, though.

56
00:05:21,280 --> 00:05:26,400
So let's get creative. There's other things in our everyday lives that fall under our definition

57
00:05:26,400 --> 00:05:32,560
of memory. And one might be, and hear me out on this, a simple plastic bottle. If it's crushed,

58
00:05:32,560 --> 00:05:37,520
in other words, its configuration changed, it can sometimes return to its earlier state,

59
00:05:37,520 --> 00:05:42,400
which in that sense could be said to have been memorized. And the metaphor is not arbitrary.

60
00:05:42,400 --> 00:05:48,240
I actually do think that networks of neurons are kind of like that. What I mean is a neural network

61
00:05:48,240 --> 00:05:53,840
is a system with a pattern of activity that dynamically evolves. If somehow we could construct

62
00:05:53,840 --> 00:05:59,280
our network such that it would have some preferred state and would return to that state over time,

63
00:05:59,280 --> 00:06:03,600
if it was perturbed, then that could reasonably be qualified as a memory.

64
00:06:04,960 --> 00:06:10,720
This is a network of 64 neurons that I cleverly constructed such that it memorized this pattern

65
00:06:10,720 --> 00:06:16,880
of 8x8 binary pixels. So what's going on? To describe what this model is actually doing,

66
00:06:16,880 --> 00:06:21,920
we need to take the following steps. Remember I said time was important? We need to describe how

67
00:06:21,920 --> 00:06:27,120
the activity of the network changes over time. And then there's the question of learning. How do

68
00:06:27,120 --> 00:06:32,080
we actually imprint memories into the network? And this will have to do with the connections

69
00:06:32,080 --> 00:06:37,280
between the neurons. Finally, we need to understand if and when the network converges to its memory

70
00:06:37,280 --> 00:06:44,000
states. The crucial ingredient of our network really is the fact that it is a dynamical system.

71
00:06:44,000 --> 00:06:50,080
Its activity changes over time. By activity, we mean that each of the now 16 neurons in the

72
00:06:50,080 --> 00:06:55,760
network is described by a number and that this number is a function of time. And let's just

73
00:06:55,760 --> 00:07:01,360
assume that time moves forward in discrete steps. Furthermore, since we are interested in binary

74
00:07:01,360 --> 00:07:07,280
memory states, we will assume that activity means that the neurons can only be in one of two states,

75
00:07:07,280 --> 00:07:14,880
inactive, say minus one, and active, say plus one. Anyway, this all leaves us with 16 minus or

76
00:07:14,880 --> 00:07:22,560
plus ones at any given time, which we will call the state of the network. What actually happens

77
00:07:22,560 --> 00:07:29,440
if we increase time by one step? Imagine folding out the time dimension in space. Now we select

78
00:07:29,440 --> 00:07:35,120
one of the neurons at random and update its state according to the input of all other neurons

79
00:07:35,120 --> 00:07:41,600
in the network. The rest of the neurons stay the same. And this we simply continue.

80
00:07:45,040 --> 00:07:51,120
But hold on, you might ask. How do we update the state exactly? And why update only one neuron at

81
00:07:51,120 --> 00:07:56,880
a time? Well, for the second question, we could in fact update all neurons at once. But the issue

82
00:07:56,880 --> 00:08:02,480
here is plausibility, because that would require a global updating signal, almost like a clock,

83
00:08:02,480 --> 00:08:08,560
instructing all neurons to update simultaneously. It's slightly more realistic, although not too

84
00:08:08,560 --> 00:08:14,320
much to be honest, to let them update asynchronously. Okay, and for the other question, yes, what is the

85
00:08:14,320 --> 00:08:19,760
actual update equation? Well, it's remarkably simple. It's a weighted sum of the states of the

86
00:08:19,760 --> 00:08:25,360
other neurons. Weighted meaning that each state is multiplied by the strength of the connection

87
00:08:25,360 --> 00:08:31,120
between the neurons. And since the connections, in that sense, weigh the inputs, from now on,

88
00:08:31,120 --> 00:08:36,160
I'm actually going to call them weights. But then of course, to ensure that the result is plus one

89
00:08:36,160 --> 00:08:41,440
or minus one again, we'll make use of that function I mentioned earlier, F. And that's it.

90
00:08:41,440 --> 00:08:46,560
Those of you familiar with linear algebra will have recognized this as computing the dot product

91
00:08:46,560 --> 00:08:50,560
between the vector of neuron states and the vector of connection weights.

92
00:08:50,960 --> 00:08:58,240
This is a network of 64 neurons. And I'm just going to tell you without explaining how

93
00:08:58,240 --> 00:09:04,160
that it has memorized this pattern, starting it off in different initial states, and then running the

94
00:09:04,160 --> 00:09:09,920
equations I just described, selecting one neuron at a time at random and updating its activity.

95
00:09:09,920 --> 00:09:14,720
And wait, let's just make this a little simpler. We can see that the network really has this

96
00:09:14,720 --> 00:09:21,440
intriguing property that it gravitates towards the memory pattern in all cases. Or well, it ends

97
00:09:21,440 --> 00:09:25,680
up with the anti memory in some cases, we'll ignore that it has to do with a certain symmetry in the

98
00:09:25,680 --> 00:09:32,160
network that we will get to. Moreover, once it's settled into that state, it doesn't change anymore.

99
00:09:32,160 --> 00:09:38,160
The memory pattern is what is called a stable state of the network. So can we be sure that this

100
00:09:38,160 --> 00:09:42,960
always happens? Well, no. For example, things start to get complicated when there is more than one

101
00:09:42,960 --> 00:09:47,920
memory stored in the network. We'll get to that. But for the simple case of just a single memory,

102
00:09:47,920 --> 00:09:53,120
yeah, the network will converge to either the memory or its anti memory or as an edge case

103
00:09:53,120 --> 00:09:59,040
to the completely inactive state. So let's recap. Networks are just vectors that evolve in time and

104
00:09:59,040 --> 00:10:04,400
we update their elements asynchronously. Given some configuration of weights, there are stable

105
00:10:04,400 --> 00:10:09,680
states in the network, which we call memory states. And we have seen, although not proved,

106
00:10:09,680 --> 00:10:14,480
that the network is kind of attracted to these states. That leaves the following question.

107
00:10:14,480 --> 00:10:19,760
How do we make the network memorize a certain pattern? In other words, how can we design the

108
00:10:19,760 --> 00:10:24,720
stable states of the network? This amounts to setting the weights of the network, which turns

109
00:10:24,720 --> 00:10:30,880
out to be a matrix with as many rows and columns as there are neurons. For example, the state of

110
00:10:30,880 --> 00:10:37,680
this neuron is determined by the weights in this row of the matrix. At first, this might seem impossible,

111
00:10:37,680 --> 00:10:40,640
especially if we wish to store more than one memory in the network.

112
00:10:42,800 --> 00:10:47,920
So I'm just going to tell you the magic rule and then I'll motivate it. Given a desired memory

113
00:10:47,920 --> 00:10:54,000
state with, say, eight elements, we are looking for an eight by eight matrix. We will just say,

114
00:10:54,000 --> 00:11:00,400
seemingly out of nowhere, that the weight between two neurons, i, j in general, is determined by

115
00:11:00,400 --> 00:11:05,920
the product of their states in the memory. For all of you keen on linear algebra, this means

116
00:11:05,920 --> 00:11:11,440
that the matrix is an outer product of the memory vector with itself, except for the diagonal,

117
00:11:11,440 --> 00:11:19,040
which we set to zero, since we don't want any self-reinforcement. But why? Think of it this way.

118
00:11:19,040 --> 00:11:23,520
Our whole approach was in some sense to build something interesting from many simple parts.

119
00:11:24,400 --> 00:11:29,040
So there really should be a way for the two neurons to determine the weight between them,

120
00:11:29,040 --> 00:11:33,920
independent of the rest of the network. This is a principle called Hebbian learning,

121
00:11:33,920 --> 00:11:38,480
and it is exceedingly plausible, because remember that weights are supposed to be synapses?

122
00:11:39,040 --> 00:11:44,000
And synapses in actual neurons also would have no way of knowing what goes on in the broader

123
00:11:44,000 --> 00:11:50,480
network. And so why the multiplication? Well, here comes the reason I called it the binary states,

124
00:11:50,480 --> 00:11:54,960
minus one and plus one. If you map out all four combinations of states of the neurons,

125
00:11:55,520 --> 00:12:00,320
you'll see that the weight will have positive sign whenever the neurons in their memory state

126
00:12:00,320 --> 00:12:06,480
agree and negative if they disagree. And this should make sense, because a positive weight

127
00:12:06,480 --> 00:12:14,240
lets a neuron project its state onto other neurons, and a negative weight lets a neuron flip the state

128
00:12:14,240 --> 00:12:22,080
of other neurons. It's almost like the neurons behave like charged particles, maybe. One last

129
00:12:22,080 --> 00:12:26,720
question before we can see it in action, and that's how do we store multiple patterns at once

130
00:12:26,720 --> 00:12:32,000
in the same network? We do it by computing the outer products for all desired memory patterns,

131
00:12:32,000 --> 00:12:37,840
this gives us a matrix for each, and then we average those matrices. This gives finer and

132
00:12:37,840 --> 00:12:43,120
finer gradations of the weights. Now, however, things start to become a little bit more complicated.

133
00:12:43,680 --> 00:12:48,800
There's no way to guarantee that all memory patterns are stable states. The memories will

134
00:12:48,800 --> 00:12:54,880
start talking to each other, fusing into new memories, which I find frustrating and super

135
00:12:54,880 --> 00:13:00,000
interesting at the same time. Here's the network with four memories again. It sometimes converges

136
00:13:00,000 --> 00:13:05,680
to one of the memory states, yes, but in other cases, it converges to something in between,

137
00:13:06,320 --> 00:13:11,840
a merging of memories, which I find, well, almost a kind of human mistake.

138
00:13:13,200 --> 00:13:17,840
And with this, we are finally making some progress on our question from the very beginning of the

139
00:13:17,840 --> 00:13:24,080
video. How much memory do you have? Originally, we might have answered this by giving some number

140
00:13:24,080 --> 00:13:29,120
of bytes. But now the question presents itself very differently. It's more like, how many

141
00:13:29,120 --> 00:13:35,600
memory patterns can we store in a recurrent network of a given size, such that they are stable states

142
00:13:35,600 --> 00:13:41,600
of the network? And the answer is, at least for this model, not very many. The original paper

143
00:13:41,600 --> 00:13:46,080
showed that this model has only linear memory capacity. That's to say, the number of stable

144
00:13:46,080 --> 00:13:51,200
states grows as a linear function of the size of the network. Plus, there's a hidden assumption

145
00:13:51,280 --> 00:13:56,000
in this graph too, which is that all memory states are uncorrelated, which, for any set of

146
00:13:56,000 --> 00:14:01,280
pictures like this, is totally not the case. I tried my best picking out some not-so-correlated

147
00:14:01,280 --> 00:14:05,760
images to really show what this network can do, and the results are, well, see for yourself.

148
00:14:10,160 --> 00:14:15,520
Realistically, that means that this model is maybe too simple after all. And that's not

149
00:14:15,520 --> 00:14:20,000
surprising given all the violence we did to these networks with our many simplifications.

150
00:14:20,000 --> 00:14:23,920
But the goal of this video wasn't to convince you that this model can be used in any practical

151
00:14:23,920 --> 00:14:28,560
sense anyway. Although, in a follow-up video, I want to tell you what steps people took to

152
00:14:28,560 --> 00:14:33,120
make this model actually useful for deep neural networks. What I wanted to achieve with this

153
00:14:33,120 --> 00:14:40,640
video is, first, to warn you of false comparisons. Networks of neurons don't behave like USB sticks,

154
00:14:40,640 --> 00:14:46,720
and why should they? But secondly, it's to show you how with modeling approaches, walking a very

155
00:14:46,800 --> 00:14:51,840
thin line between complexity and simplicity, we can sometimes start to conceive of the world

156
00:14:51,840 --> 00:14:56,800
differently than otherwise we would have. You might have set out picturing memory as

157
00:14:56,800 --> 00:15:02,240
something static, but I'm hoping now you're willing to consider that it might be something dynamic,

158
00:15:02,880 --> 00:15:08,240
the invisible, stable states of a network buzzing with activity.

