{"text": " Monicarlo rendering can produce beautiful images like the ones shown here, but requires calculating many expensive rays resulting in lengthy render times. A few samples can be quickly evaluated, but the inaccuracy of this estimate appears as noise in the final image. One way to address this problem is to apply a denoising filter to generate a pleasing noise-free image. In this paper, we observe that there is a complex underlying relationship between the input noisy data and the optimal filter parameters, and thus we propose to learn it. In our system, the renderer outputs a set of primary features at each pixel, including screen position, color, world position, and shading normal. A local neighborhood of each pixel is processed to get a set of secondary features such as feature statistics, among others. These in turn are given to a multi-layer perceptron neural network to output a set of filter parameters. Finally, the filter takes these computed parameters and the noisy output of the rendering system to generate a filtered pixel. This process is done for all of the pixels to generate a filtered image with comparable quality to the ground truth. We train the network on a set of scenes containing a variety of Monicarlo effects such as depth of field, area light sampling, motion blur, and global illumination. The network is trained with the iterative backpropagation process. Here is a video sequence showing how the network converges for a particular scene during training. Here are some results generated by our system using a cross bilateral filter on a set of test scenes not included in the training set. Our approach can be extended to handle animated sequences by performing the filtering process on spatiotemporal volumes.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.92, "text": " Monicarlo rendering can produce beautiful images like the ones shown here, but requires", "tokens": [50364, 4713, 299, 19457, 22407, 393, 5258, 2238, 5267, 411, 264, 2306, 4898, 510, 11, 457, 7029, 50860], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 1, "seek": 0, "start": 9.92, "end": 14.64, "text": " calculating many expensive rays resulting in lengthy render times.", "tokens": [50860, 28258, 867, 5124, 24417, 16505, 294, 35374, 15529, 1413, 13, 51096], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 2, "seek": 0, "start": 14.64, "end": 19.0, "text": " A few samples can be quickly evaluated, but the inaccuracy of this estimate appears as", "tokens": [51096, 316, 1326, 10938, 393, 312, 2661, 25509, 11, 457, 264, 37957, 374, 2551, 295, 341, 12539, 7038, 382, 51314], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 3, "seek": 0, "start": 19.0, "end": 21.0, "text": " noise in the final image.", "tokens": [51314, 5658, 294, 264, 2572, 3256, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 4, "seek": 0, "start": 21.0, "end": 24.96, "text": " One way to address this problem is to apply a denoising filter to generate a pleasing", "tokens": [51414, 1485, 636, 281, 2985, 341, 1154, 307, 281, 3079, 257, 1441, 78, 3436, 6608, 281, 8460, 257, 32798, 51612], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 5, "seek": 0, "start": 24.96, "end": 26.64, "text": " noise-free image.", "tokens": [51612, 5658, 12, 10792, 3256, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12948295987885575, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.19845199584960938}, {"id": 6, "seek": 2664, "start": 26.64, "end": 30.6, "text": " In this paper, we observe that there is a complex underlying relationship between the", "tokens": [50364, 682, 341, 3035, 11, 321, 11441, 300, 456, 307, 257, 3997, 14217, 2480, 1296, 264, 50562], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 7, "seek": 2664, "start": 30.6, "end": 36.44, "text": " input noisy data and the optimal filter parameters, and thus we propose to learn it.", "tokens": [50562, 4846, 24518, 1412, 293, 264, 16252, 6608, 9834, 11, 293, 8807, 321, 17421, 281, 1466, 309, 13, 50854], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 8, "seek": 2664, "start": 36.44, "end": 41.24, "text": " In our system, the renderer outputs a set of primary features at each pixel, including", "tokens": [50854, 682, 527, 1185, 11, 264, 15529, 260, 23930, 257, 992, 295, 6194, 4122, 412, 1184, 19261, 11, 3009, 51094], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 9, "seek": 2664, "start": 41.24, "end": 45.24, "text": " screen position, color, world position, and shading normal.", "tokens": [51094, 2568, 2535, 11, 2017, 11, 1002, 2535, 11, 293, 30556, 2710, 13, 51294], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 10, "seek": 2664, "start": 45.24, "end": 50.08, "text": " A local neighborhood of each pixel is processed to get a set of secondary features such as", "tokens": [51294, 316, 2654, 7630, 295, 1184, 19261, 307, 18846, 281, 483, 257, 992, 295, 11396, 4122, 1270, 382, 51536], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 11, "seek": 2664, "start": 50.08, "end": 52.96, "text": " feature statistics, among others.", "tokens": [51536, 4111, 12523, 11, 3654, 2357, 13, 51680], "temperature": 0.0, "avg_logprob": -0.13636740289553248, "compression_ratio": 1.7, "no_speech_prob": 0.011504164896905422}, {"id": 12, "seek": 5296, "start": 52.96, "end": 57.44, "text": " These in turn are given to a multi-layer perceptron neural network to output a set of", "tokens": [50364, 1981, 294, 1261, 366, 2212, 281, 257, 4825, 12, 8376, 260, 43276, 2044, 18161, 3209, 281, 5598, 257, 992, 295, 50588], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 13, "seek": 5296, "start": 57.44, "end": 58.8, "text": " filter parameters.", "tokens": [50588, 6608, 9834, 13, 50656], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 14, "seek": 5296, "start": 58.8, "end": 64.0, "text": " Finally, the filter takes these computed parameters and the noisy output of the rendering system", "tokens": [50656, 6288, 11, 264, 6608, 2516, 613, 40610, 9834, 293, 264, 24518, 5598, 295, 264, 22407, 1185, 50916], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 15, "seek": 5296, "start": 64.0, "end": 66.4, "text": " to generate a filtered pixel.", "tokens": [50916, 281, 8460, 257, 37111, 19261, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 16, "seek": 5296, "start": 66.4, "end": 70.8, "text": " This process is done for all of the pixels to generate a filtered image with comparable", "tokens": [51036, 639, 1399, 307, 1096, 337, 439, 295, 264, 18668, 281, 8460, 257, 37111, 3256, 365, 25323, 51256], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 17, "seek": 5296, "start": 70.8, "end": 73.2, "text": " quality to the ground truth.", "tokens": [51256, 3125, 281, 264, 2727, 3494, 13, 51376], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 18, "seek": 5296, "start": 73.2, "end": 78.4, "text": " We train the network on a set of scenes containing a variety of Monicarlo effects such as depth", "tokens": [51376, 492, 3847, 264, 3209, 322, 257, 992, 295, 8026, 19273, 257, 5673, 295, 4713, 299, 19457, 5065, 1270, 382, 7161, 51636], "temperature": 0.0, "avg_logprob": -0.10254666411760942, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.02713005803525448}, {"id": 19, "seek": 7840, "start": 78.4, "end": 83.36, "text": " of field, area light sampling, motion blur, and global illumination.", "tokens": [50364, 295, 2519, 11, 1859, 1442, 21179, 11, 5394, 14257, 11, 293, 4338, 30579, 2486, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1134484424147495, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.027151115238666534}, {"id": 20, "seek": 7840, "start": 83.36, "end": 87.2, "text": " The network is trained with the iterative backpropagation process.", "tokens": [50612, 440, 3209, 307, 8895, 365, 264, 17138, 1166, 646, 79, 1513, 559, 399, 1399, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1134484424147495, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.027151115238666534}, {"id": 21, "seek": 7840, "start": 87.2, "end": 94.56, "text": " Here is a video sequence showing how the network converges for a particular scene during training.", "tokens": [50804, 1692, 307, 257, 960, 8310, 4099, 577, 264, 3209, 9652, 2880, 337, 257, 1729, 4145, 1830, 3097, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1134484424147495, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.027151115238666534}, {"id": 22, "seek": 7840, "start": 94.56, "end": 98.80000000000001, "text": " Here are some results generated by our system using a cross bilateral filter on a set of", "tokens": [51172, 1692, 366, 512, 3542, 10833, 538, 527, 1185, 1228, 257, 3278, 38772, 6608, 322, 257, 992, 295, 51384], "temperature": 0.0, "avg_logprob": -0.1134484424147495, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.027151115238666534}, {"id": 23, "seek": 7840, "start": 98.80000000000001, "end": 105.2, "text": " test scenes not included in the training set.", "tokens": [51384, 1500, 8026, 406, 5556, 294, 264, 3097, 992, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1134484424147495, "compression_ratio": 1.6043478260869566, "no_speech_prob": 0.027151115238666534}, {"id": 24, "seek": 10520, "start": 105.2, "end": 110.12, "text": " Our approach can be extended to handle animated sequences by performing the filtering process", "tokens": [50364, 2621, 3109, 393, 312, 10913, 281, 4813, 18947, 22978, 538, 10205, 264, 30822, 1399, 50610], "temperature": 0.0, "avg_logprob": -0.19981142190786508, "compression_ratio": 1.2121212121212122, "no_speech_prob": 0.6408185362815857}, {"id": 25, "seek": 10520, "start": 110.12, "end": 112.08, "text": " on spatiotemporal volumes.", "tokens": [50610, 322, 15000, 6471, 11840, 304, 22219, 13, 50708], "temperature": 0.0, "avg_logprob": -0.19981142190786508, "compression_ratio": 1.2121212121212122, "no_speech_prob": 0.6408185362815857}], "language": "en"}