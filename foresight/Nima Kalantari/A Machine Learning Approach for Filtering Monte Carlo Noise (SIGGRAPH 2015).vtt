WEBVTT

00:00.000 --> 00:09.920
Monicarlo rendering can produce beautiful images like the ones shown here, but requires

00:09.920 --> 00:14.640
calculating many expensive rays resulting in lengthy render times.

00:14.640 --> 00:19.000
A few samples can be quickly evaluated, but the inaccuracy of this estimate appears as

00:19.000 --> 00:21.000
noise in the final image.

00:21.000 --> 00:24.960
One way to address this problem is to apply a denoising filter to generate a pleasing

00:24.960 --> 00:26.640
noise-free image.

00:26.640 --> 00:30.600
In this paper, we observe that there is a complex underlying relationship between the

00:30.600 --> 00:36.440
input noisy data and the optimal filter parameters, and thus we propose to learn it.

00:36.440 --> 00:41.240
In our system, the renderer outputs a set of primary features at each pixel, including

00:41.240 --> 00:45.240
screen position, color, world position, and shading normal.

00:45.240 --> 00:50.080
A local neighborhood of each pixel is processed to get a set of secondary features such as

00:50.080 --> 00:52.960
feature statistics, among others.

00:52.960 --> 00:57.440
These in turn are given to a multi-layer perceptron neural network to output a set of

00:57.440 --> 00:58.800
filter parameters.

00:58.800 --> 01:04.000
Finally, the filter takes these computed parameters and the noisy output of the rendering system

01:04.000 --> 01:06.400
to generate a filtered pixel.

01:06.400 --> 01:10.800
This process is done for all of the pixels to generate a filtered image with comparable

01:10.800 --> 01:13.200
quality to the ground truth.

01:13.200 --> 01:18.400
We train the network on a set of scenes containing a variety of Monicarlo effects such as depth

01:18.400 --> 01:23.360
of field, area light sampling, motion blur, and global illumination.

01:23.360 --> 01:27.200
The network is trained with the iterative backpropagation process.

01:27.200 --> 01:34.560
Here is a video sequence showing how the network converges for a particular scene during training.

01:34.560 --> 01:38.800
Here are some results generated by our system using a cross bilateral filter on a set of

01:38.800 --> 01:45.200
test scenes not included in the training set.

01:45.200 --> 01:50.120
Our approach can be extended to handle animated sequences by performing the filtering process

01:50.120 --> 01:52.080
on spatiotemporal volumes.

