1
00:00:00,000 --> 00:00:09,920
Monicarlo rendering can produce beautiful images like the ones shown here, but requires

2
00:00:09,920 --> 00:00:14,640
calculating many expensive rays resulting in lengthy render times.

3
00:00:14,640 --> 00:00:19,000
A few samples can be quickly evaluated, but the inaccuracy of this estimate appears as

4
00:00:19,000 --> 00:00:21,000
noise in the final image.

5
00:00:21,000 --> 00:00:24,960
One way to address this problem is to apply a denoising filter to generate a pleasing

6
00:00:24,960 --> 00:00:26,640
noise-free image.

7
00:00:26,640 --> 00:00:30,600
In this paper, we observe that there is a complex underlying relationship between the

8
00:00:30,600 --> 00:00:36,440
input noisy data and the optimal filter parameters, and thus we propose to learn it.

9
00:00:36,440 --> 00:00:41,240
In our system, the renderer outputs a set of primary features at each pixel, including

10
00:00:41,240 --> 00:00:45,240
screen position, color, world position, and shading normal.

11
00:00:45,240 --> 00:00:50,080
A local neighborhood of each pixel is processed to get a set of secondary features such as

12
00:00:50,080 --> 00:00:52,960
feature statistics, among others.

13
00:00:52,960 --> 00:00:57,440
These in turn are given to a multi-layer perceptron neural network to output a set of

14
00:00:57,440 --> 00:00:58,800
filter parameters.

15
00:00:58,800 --> 00:01:04,000
Finally, the filter takes these computed parameters and the noisy output of the rendering system

16
00:01:04,000 --> 00:01:06,400
to generate a filtered pixel.

17
00:01:06,400 --> 00:01:10,800
This process is done for all of the pixels to generate a filtered image with comparable

18
00:01:10,800 --> 00:01:13,200
quality to the ground truth.

19
00:01:13,200 --> 00:01:18,400
We train the network on a set of scenes containing a variety of Monicarlo effects such as depth

20
00:01:18,400 --> 00:01:23,360
of field, area light sampling, motion blur, and global illumination.

21
00:01:23,360 --> 00:01:27,200
The network is trained with the iterative backpropagation process.

22
00:01:27,200 --> 00:01:34,560
Here is a video sequence showing how the network converges for a particular scene during training.

23
00:01:34,560 --> 00:01:38,800
Here are some results generated by our system using a cross bilateral filter on a set of

24
00:01:38,800 --> 00:01:45,200
test scenes not included in the training set.

25
00:01:45,200 --> 00:01:50,120
Our approach can be extended to handle animated sequences by performing the filtering process

26
00:01:50,120 --> 00:01:52,080
on spatiotemporal volumes.

