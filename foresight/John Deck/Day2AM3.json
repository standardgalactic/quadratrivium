{"text": " John asked me, in the absence of Stephen Camm, who developed Darwinist W, John asked me to talk a little bit about it. And I thought I would, it's okay with everybody, take the liberty of situating that work in the context of the general issue of how to represent Darwin core in RDF. And so, because I know that both Stephen Camm have created Darwinist W for two reasons. One, they had an immediate need to represent data and perhaps before consensus was reached within TADWIG about how exactly to do that. And two, they saw it as a first step towards building consensus around a canonical way to do it. But I think that everybody, with one exception at the end, who has sort of proposed a way of doing it, agrees that these are initial steps and some consensus and further thought is required. So the first thing, so just to give a brief overview, even before we talk about any extensions, I wanted to illustrate the fact that Darwin core as it is is an ontology. And like any ontology, you can represent data with it and you can query over that data. And then we can talk a little bit about some of the shortcomings in Darwin core as it is an ontology and some of the proposed solutions. So I'll exit out of the show. I'll wait for refresh at 75 Hertz. Okay. So here is Darwin core. This is the canonical description. It's, you can see in the URL, it's an RDF document. This is the HTML representation of it. And it is, as John said, a bag of terms. Behavior, binomial, collection ID, decimal latitude. You can look at its RDF representation. It's somewhat difficult to read in Safari. But the, you know, John said that when they created this canonical RDF representation, they sort of didn't have the semantic web in mind or rather they had it in mind and didn't want to deal with it because I thought it would be dealt with later on. But to my mind, this is well suited for the semantic web and is a legitimate ontology in its own right. It's a list of the things that there are in the world of biodiversity. And to illustrate that, I expressed the occurrences from the Woods Hole Bioblitz in RDF only using the Darwin core namespace. So without, without any additions, you could say, well, so here's, here's an occurrence and here are a couple. There are two different identifications of it. One saying it was an ampelopsis and one saying that it was something else. Parthenosisis kinchifolia. And then each of those identifications and occurrences have their own, have their own good. And you might, this right away sort of illustrates one of the, one of the issues that here identification is being used as a property of occurrence. But then if you, if you look at the GUID of that identification, you'll see that you can also use identification as a class. And that's, that's okay. The reasoners don't, you know, overheat and, and blow a fuse because of course a property is a class. And so there's no, you know, there's no, not necessarily attention there. Nevertheless, it's, you know, it's bad form, of course. I mean, I think to have the same term that's both a property and a class. So at a minimum, my suggestion, you know, as a first layer, semantic layer would be to roughly double the number of terms and to introduce, you know, disambiguate when you're using identification as a class and when you're using it as a property. So introduce a hazard identification, hazard occurrence, hazard habitat, et cetera. But even as it is, you can, you know, reason over the data, you can issue sparkle queries and, and get, you know, get answers. So I guess we're going to be talking more this afternoon and tomorrow. But I guess my viewer, the viewer's preview of my position is that I think we should make as small changes to the existing way of doing things as possible. So the next, so, so Steve, now I've opened up Darwin S.W., the class diagram. I know that it can't be seen from the back, but it can't be seen any, any better on the slide. If you, if you click on the last, the ready talk slide there, it'll show the same thing we have. Okay. The one. Ready talk, here we go. So. That's what's being shown. All right. So can you go to the slide that has the, the class diagram? I think it's the third slide. So as there was a lot of discussion, as John was mentioning about how to move, how to, how to move Darwin core, how to make Darwin core more appropriate for, for, for representing data in RDF and on the semantic web in general. And a lot of it centered around the overloading of the term occurrence. So Steve, since you're with us, I'll let you talk about, you know, Darwin S.W. in a minute. But I wanted to sort of just say what, what I think is it's, you know, most important contribution, which is that it teases out some of the overloading of occurrence that went on. And, and it does this by introducing a new term token. So, and John, correct me if I'm wrong, but I think that part of the issue was that coming out of a collections mentality, an occurrence was thought of as it could be a specimen or it could be an image or it could be a tissue sample. And, or it could just be something that, that you, that you saw. And so Steve says, well, actually, to be more correct, the specimen or the tissue sample or the photograph are tokens of the occurrence. Word of mouth could be a token of the occurrence and those tokens all serve as evidence. So I think he settled on token because evidence, he tried to introduce the term evidence. I might be wrong about the history and then there was too much argument over what evidence properly means and so he settled on token. Similarly, he tried to introduce the term individual and I think there was agreement that that would be a good term to add, a good concept to add to the graph. But there is no agreement on what it should be called and what its scope should be and whether it would include a flock of geese or a pack of wolves. And so I think that's left out, right? So there's still no individual in Darwin Corps. Individual Darwin Corps, but the discussion did go forward and accept as a scope for the concept of populations down to mixed tax on things. Right. And it would be called enormous. So that's still though to be, that's not yet introduced. So the other thing to, I guess, notice is that these classes and the properties associated to them are normalized in the sense that if you look at identification, that can only be applied to a token, not to an occurrence or so. And similarly, the tax on itself, which is the determination, is then a property of the identification. Joel, can you do full screen? Yeah, that would be a good idea. That's a great idea. So just to point to what I was talking to, here's the occurrence, here are the new terms, token and individual organism. And looking back, I didn't find the email, but from about two years ago, when a Darwin Corps was first represented in that RDF manner, there was a question, should there be any domain constraints on any of these terms, like, for example, identification? And the decision was made, you know, no, because that could lead to too much potential for misuse if people apply these terms. And this is something that I'm, you know, interested in, is in a very loose context, if people are applying identifications to samples or to pictures or to occurrences or to organisms. But Steve is sort of much more principled and says, you know, identification properly has, you know, the domain of the token. Is there identification by identification? Steve? I'm sorry, what was the question? The question is, is there a definition of identification? And I think... Well, I mean, identification, in all of the Darwin Corps classes, there's not a clear definition in the sense of what the, how they are connected to the other classes. And I mean, I think that identification, well, identification connects something to a taxon concept. And I guess the question is, what is that something that is being identified? So, you know, we took the position that identification was connecting some kind of a nebulous thing, which we call the individual organism to a taxon. Is the, is an identification an event? Yes. I'm sorry? Is identification an event? No. It is not defined as an event. It's defined as a category of information in Darwin Corps. Result of the event. Conceptually, it is an event. The term event in Darwin Corps derives from the Dublin Corps, which is why it doesn't say collecting event within the current session or the current sense of Darwin Corps. So, we know there are many kinds of events in all the work we do. So, I'll make a general point, which is, if you're going to do a semantic version of the Darwin Corps, then you need definitions, which would be formulated using something like owl. That's, you should be nodding your head. Well, only if I agree with you, right? And then the second point I would make is that, at the moment, I think many of these terms are just going to create puzzlement, because they're so abstract. So, most people don't use token in their daily data collection business, I would suppose. Can they understand, actually, and the work we just pointed out, some of the problems with the n-view of the year that we're dealing with, in that you do have tractable terms of the year. Identification, and it has a definition, says it's information, or category of information. That's not, it doesn't tell you much. It says a thing. But at the same time, it's the same point I got here. Oh, wait. In my mind, when you say identification, I see a process. I see a narrative. We have a long history of modeling in this community. Yeah. As I was telling, you know, it goes back to, you know, 92 or 90 when we started doing this. And it's an identification as an event with, as an association of something biological with a taxonomy done by someone at some time is common to virtually all the models that we have done. When they have that. Except that it's not an event. Except that in the Darwin court, because we didn't do assembly of terms into concepts like this, you know, the structure that we've been talking about, it's not included. So I'm making a general point that if you're using abstract terms, that's fine. But then you're not going to help the user unless you define those abstract terms. And if he said, but we have an established community here, which knows what they're doing, you're creating a mystery. Because you want your data to be viewable from the outside by Japanese people with really nice machines. They will not understand. Japanese have really nice machines. This is the point that we're at. We're at the point of saying, yes, we all agree that we need to have a structural thing that's called a taxonomic identification or something like that. And that it has the properties or that it has the same basic shape as an event. Although, I mean, defining identification as an event, I'm not saying it isn't. I'm not saying. No, I don't care how it's done. I just want to see the result. But I'm just saying that if you want to avoid, that could also be confusing. If the goal is to avoid confusion, people have an idea of what identification is. Is it an event? So I don't know. I'm just saying you need definitions. And there is a way of doing definitions within the semantic web, which is well understood and which will give you all kinds of benefits. But just let me let me repeat what John and I discussed yesterday. You have Darwin Core. It's full of terms. It's full of quasi-definition. Go through Darwin Core as it is and try and define every single term using our, which is the standard that we're more or less forced to use for doing this currently. Sometimes it will be easy. A comment. Yeah? I think one of the way we looked at things like identification, occurrence, and event, in some sense, there are nodes that connect different things. So, you know, identification is the thing that connects an organism to a taxon or a taxon concept. And so I think that was one of the reasons why when we got hung up on trying to define what these different things meant, that really we were essentially talking about joins between other categories of things. So that is one way of doing definitions. When you do it, then we will see whether the definition is intelligible. But the result has to help people to understand what particular data expressed in a certain way means. And it has to help people understand how to annotate their own data in the same way. And it seems that within this community, there are indeed people who know exactly what you just said means. I don't know what it means. And I can see all kinds of objections that other people might have based on what you've said. But Barry, I mean, sometimes the semantics that can be expressed in English, I mean, do you say that the full semantics that would express natural language should be expressed in owl? What I say is there should be an experiment. Take the Darwin quote, try and define all the terms using owl, because that's the standard that we're forced to use today. And see what you get. You will learn all kinds of things. You will learn that you don't know whether identification is an event or not an event, maybe. I know that the word token is used in a funny way, because some things which meet the definition of token are not listed on the token within the structure that you have now. And then the ontology that will be generated automatically from that set of definitions, when you run it through the reasoner, will give you a list of categorization errors. I'm assuming. So this is an experiment. I have no idea how it will turn out. Once you get that list, you can change some of the definitions and you can consult with your colleagues to find better definitions. And the result will be something which will be a step forward. Maybe it won't replace the Darwin quote, but it will be a step forward and understand it. Right. So I mean, those experiments have been done. They're being done, you know, as we speak. And it's not clear to me that it will result in a step forward. And for example, if you get a categorization error, we don't need to classify. I mean, in a lot of ontology applications, the goal is to classify the ontology to get a complete listing of the type hierarchy, of the class hierarchy, and also an instance categorization. But the artifacts of biodiversity informatics are typed. They come typed. I mean, we don't need to, you know, run some record into a machine and know whether or not that's an identification. I mean, it will tell us it's an identification. If something's a picture, if something's a digital still image, we'll know that it's a digital still image. I truly think that you do need to do this. It's a basic quality assurance step. And anyone who's working with this magic web would assume that that would be the basic step that everyone does. Well, that's, I mean, the fact that you don't want to do it is strange. It's like not wanting to use a spellchecker. Well, I mean, not every class, if you want to say, I mean, a class is defined simply by introducing it as a class. You need to define it. It inherits from our class. And there, it's defined. And now, as human beings, we attach some meaning to it. And so we write our application code to understand that term according to our understanding of it. And yes, there's a vision of the semantic web in which, you know, we don't have to write the code because we'll have general purpose processors that can look at the machine definition and understand how to process it. I'm not saying that that won't happen, but it doesn't have to happen to get a lot of value out of the semantic web. Let me, let me just say one more thing. So the gene ontology used to be a very clunky back of the envelope word list, just a very, very minimal structure. After a few years, people have the idea to try and produce logically coherent definitions of the gene ontology terms. Immediately, immediately, they started that with just a few definitions. They discovered errors, they discovered gaps. And when they actually finished with all the definitions, they discovered all kinds of interesting things about the ontology, which helped the ontology from a biological point of view. It became better in every respect. Now, you should want to do that. It's a healthy desire. It's a sign of a clean living individual. The fact that you don't want to do it is strange. I mean, I think a rule of ontologies should be no naked terms. Except highly general primitives. Because you can't define everything. You can't define everything like the W3 specs or in some sort of a form. Yeah, but you can't define everything. Otherwise, you would have an infinite change. You have to use some words without that. It becomes problematic. But, you know, at the level that we're talking about in Darwin Park, we completely agree with Barry. Minimally, we should have a natural language definition and ideally something a bit more formal. Well, I certainly agree we should have a natural language definition. But I think a legitimate vision for the semantic web is that the ontologies serve as dictionaries for human users, that you have the namespace, and you say, if we're talking about a Darwin core identification, everybody can look and say, oh, that's what a Darwin core identification is. Anybody that can understand natural language. And then only write code that uses Darwin core colon identification in that way. And that, I think, is already a big step forward because you have a canonical place where people look and say, if you're using a DWC identification, you have to use it in this way. So, if you want to say that there shouldn't be naked terms, I can't know. I don't know what there should and shouldn't be, but I know that there is value from naked terms. Because 90% of the value of the semantic web comes from the namespace. It comes from the disambiguation. For any naked term you put up there, unless you want it to be completely unconstrained, run a little bit of a few hints about usage or formal definitions. I think it can do nothing but help as long as it doesn't over constrain. But you can try to constrain it as much as you want. But those hints can be in English. They don't have to be in Al. What's the danger of that? What do you lose by having them in Al? I don't get what the resistance is to it. Because it's a lot harder to figure out how to model them in Al. Well, because it's a lot easier than for people to say things that they don't really mean. For example, the Darwin core type hierarchy used to define subclasses of events and subclasses of collection events, subclasses of specimens. And it was pointed out, and I think it was Steve that pointed it out, that the result was that a preserved specimen is an event. Obviously, if your Al hierarchy is wrong, it's going to cause problems. For a particular point of view, from a particular point of view, that Al hierarchy was right. Another example is that one of the first descriptions of terms that people add, especially if they're using prot\u00e9g\u00e9 because it encourages it, is domain constraints. What does this term apply to? But, of course, those constraints don't act as integrity constraints as they do in a database. They act as grist for a reasoning mill. And so now, if you say identification, and Steve gets to this, if we ever get to his slides, we'll see that he recognizes this as one of the potential criticism, one of the criticisms of his current representation, is that by having this highly normalized view where identification only applies to a token, if somebody identifies an image using the term identification, then that reasoner will assume that, well, okay, an image is a token. If somebody identifies, well, what if somebody identifies an occurrence, then you have to reason that the occurrence is a token. If somebody tries to identify a species... If they identify wrong, they're not using the definition of... This is exactly my point, is that the more complicated the ontology it is, the easier it is to say things that have implications that you don't want to imply. So the idea is that you would have good language definitions to help the user, and you would have good logical definitions to do basic quality control. Doing both of those will help the other. So you'll get better English definitions by doing the logic. You'll get better logical definitions by doing the English definitions. And users will have some clue as to how to use. Like, if I go to the Dharma Corp. now as a naive user, I wouldn't know how to use the term because I don't know what they're supposed to mean. And there's no guidance for me. There's no logical relationship that attacks the definitions are vague. So I don't know what to put where. I'm even saying, like in semantic Dharma Corp. Saying that an occurrence is a junction of an event with an identification, I think it's helpful compared to the circular definition that exists in the current Dharma Corp. Dharma Corp. standard that says an occurrence is an occurrence. And I think it's a good practice to have those best practice examples. They established within all the Ikea world that I think nearly everywhere they are needed. You need some guidelines with good examples in there where you can find yourself again with fewer things. I just say one thing. Buffer is designed to incorporate exactly those best practices. And if you're forced to specify whether a token is an occurrence or a continuum, or whether an identification is an occurrence or a continuum, that will bring almost cost-free and immediate improvement in usability. Do you want to show the slides? Yeah, Steve, are you still in the mood to go through your slides? Yeah, well, I don't know if you have to go through all of them, but could you go back one slide from the one you're on right now? So, I mean, this is really the kind of core relationships between the different classes. And, you know, the discussion was going on about, like, well, what is an identification? And essentially, the reason identification has to be in there is because you have many to one relationship between taxons and identifications. There can be many identifications that relate to a particular taxon concept. And likewise, the reason that there's a connection between identification and an organism is because you can have many identifications for a particular organism. So essentially, each of those connections between the pink things there represent one to many relationships. And that's why they were separated out as different classes. So, I don't, you know, I didn't get terribly hung up on what the exact definition was of event or occurrence, but just simply saying that there are connections between things where you have one to many relationships. The blue section in the middle, could you advance down two slides? This is, I think, the place where we sort of don't have agreement on what the structure of this should be. I mean, the slide that I just showed you, there really seemed to be more or less a consensus among people in our discussion that that was how things were related. But in terms of what's the relationship between identifications and occurrences, you know, we stuck this thing which essentially should have probably been defined as taxonomically heterogeneous identity in between identifications and occurrences. And what exactly that means is a subject of discussion. But I think the idea of token, really, if you just don't call it token and you call it evidence, that essentially defines what token is. It could be evidence that an organism occurred at a particular spot. It could be evidence that's the basis for an identification. It's just simply evidence. And it could even be the same thing as an individual organism, or it could be something derived from an individual organism. So, you know, what we call token just simply means evidence of some form. So, anyway, that's about all I wanted to say. So, Steve, you haven't been here for earlier discussions, but one, I've made a series of very simple and very boring points. And I'll continue to make them until I die. And one boring point that I've made is that when you're building an ontology or a terminology resource, then you should be aware of using a very general term which has all kinds of meanings in other contexts to mean exactly what you want to mean for your specific purpose. And one of the reasons why that is a bad thing is because other people are going to want to use the data which you've annotated using your resource to do all kinds of unanticipated things. And if they find that you're using a word that for them has a much more general meaning, then they will not find it easy to use the data annotated in your terms. Now, the word evidence is going to be used by nearly every scientist. And it's going to mean statistical evidence. It's going to mean evidence on the basis of what was calculated. It's going to mean evidence in your sense, evidence pertaining to a sample, for instance. So, you shouldn't use the word evidence. Maybe you can call it Darwin evidence or Herborium evidence, but you can't just call it evidence. Right. Well, I mean, this is a part of the whole problem with defining what an individual organism was because the term individual has a particular meaning. And so that's why it really probably should have been called taxonomically homogenous entity because that's essentially what we intended for it to mean. But, you know, there's history in what people call things. And, you know, I'm not sure what the best thing, token, was something that basically we made up. And so that might be a better term than evidence. Token is not a good word because it too has a history, unfortunately. So this is really hard. What is almost every term you can think of to use has somebody has used previously to mean something? Absolutely. So maybe long names like Darwin-Cora evidence or something are better. So it's hard work, but it has been done successfully in many different fields. And we've learned things. There are some lessons learned from all of that. I'm just going to mention one further lesson learned because I think it's important to see one difference between the Dublin-Cora and the Darwin-Cora. The Dublin-Cora is pretty straightforwardly what we might call first order. And what that means is that if it's talking about, say, a registration for copyright purposes, then it will introduce a term which means registration for copyright purposes. The Darwin-Cora is sometimes first order in that sense. So I think I have an example here. So establishment means is defined as a process by which an individual establishes itself. So that's first order. The term refers to what we would think the term would mean. But behavior in Darwin-Cora is defined as the second order. Behavior doesn't mean behavior in the Darwin-Cora. It means the description of behavior. So it's second order. And very many terms in the Darwin-Cora are terms of the form an X is information about an X. So a good clean first order terminology would define every term as an X is an X. Darwin-Cora defines very many terms as an X is an information about X. Now that's a mistake. If it was done systematically, it might be okay. But generally it's not been done systematically. And it's a mistake which has to be fixed. And the reason why I draw attention to this one is because other similar resources. So there's one very famous resource in medicine called HL7. Made exactly the same mistake. And the result is that it's now unusable. It's so complicated because people never know whether they're talking about X. For instance, somebody giving somebody a drug or information about X, which would be the description of somebody giving somebody a drug. Now I don't know why I'm addressing this comment to you, because it's really a comment to all Darwin-Core people. But this is something which needs to be got right, I think. In what sense is divusing the term evidence that clashes with other uses of the word evidence? Because you don't mean any kind of evidence. You mean evidence incorporated in a certain collection object, either as a report or as a seed sample. That really, from our point of view, a token could be any kind of evidence. I mean, it could be a photograph, it could be a specimen, it could be notes that somebody has written down. So we really didn't have a restriction as to what that should be. And maybe that's not well-defined enough, but the reason why we added these two blue bubbles in the middle is mostly because of the extreme overloading of occurrence. You know, you would ask people what does an occurrence mean, and they would say it means that there was an organism at a particular location in a particular time. But then when you would see how people were actually using the term occurrence, they were using it to mean a specimen glued onto a piece of paper. So, you know, it may be that we didn't choose the best terms for these classes that we introduced, but it was an attempt to try to separate out some of the different ways that people were using a term, particularly occurrence. In this case, we're not arguing about the term class, which is a token, but the word for the property, which has evidence, or evidence for, and I guess I can't see the way you're using it, sort of, you know, I can't see the way you're using it being incompatible. What I came up with in Darwin S.W. was really a compromise between Kim and me about, and actually originally I had suggested that we don't even have a class called token, that we have the terms that are shown on the slide there, like is basis for identification and identification based on, or evidence for, or has evidence, those terms could simply be applied to anything that people would use for evidence, and so I actually was originally advocating that we don't have a class named token, and Kim said, let's have a class named token so that we could say what the object, we could have a term to describe what the object of something like has evidence, what is that an instance of. I didn't really see token as a thing necessarily that needed to be defined. Yeah, so I have right now, just for, I guess contrast, Pete's taxonconcept.org, so Pete DeVries has put a lot of time into not only creating an ontology, but populating it and putting a sparkle front end onto the resulting knowledge base, and Barry, I wonder if, you know, he takes the approach that I think that Barry is suggesting where there's no ambiguity in the term, identification has label image, so the domain of the term is part of the property. I don't like that. That commits the sin of not reusing established relations, but inventing new ones. I don't like it either, but it, I mean, it, in a sense, it's of the same approach as, so why don't you like it? Because relations are the glue, and they are going to be gluing different ontology resources, as well as gluing terms within ontology resources, and that means that we need, as far as possible, to have a small number of relations which everyone uses, rather than having highly specific relations which are tied just to a particular small locus. So the more we can have generalizable glue, like part of and so forth, the more our ontologies will work well together. And it's, so one of the things that you said earlier is right. If people get hold of owl, if people get hold of owl, they'll do bad things. Owl is such a nice thing. You can create all kinds of filigree with owl, and most of it doesn't have any thought attached to it. So owl is not good enough. What you need is owl plus thinking, and that's why writing English definitions is a good thing. Now one way in which once people get hold of owl, they go mad is inventing these new relations. Has Paris temperature preference for, which means they like Paris because it's hot or something? Yeah, that's one step in the right direction, but ideally you don't need a relation with the word Paris. So what is the guideline for when you have a special relationship that you call out and define when you try to just use some generics? So providing you define the relation, you can always eliminate it if you need to. So that's already a good step, but that's another reason why we need to have definitions. Right, so taking the example has evidence. You were suggesting that that needs to be qualified so that we know this is Darwin has evidence. So I think evidence could be the subject of another three-day meeting all by itself. So that evidence is a very difficult topic, and I think that what you really mean by evidence is the stuff in the box, whether it's a piece of paper or a photograph or a seed stuck to a piece of paper. You don't mean evidence in the sense in which most scientists mean evidence, which is arguments, data. You mean that specific stuff in the box. But Steve, everything that Steve would call evidence that also fits your definition of evidence. Wait a second. Yeah, and vice versa. No, but it doesn't because it doesn't. So let's suppose that somebody steals something from Eric, is it? You're Herbarium. Greg. Greg. Greg, sorry. At least I got a number of letters. Somebody steals a box from Greg's Herbarium and gives it to his girlfriend as a Christmas present. And it's a nice flower or something, so she's happy. That's not Eric's girlfriend, is it? No, the thief gives it to his girlfriend. Then it's the same object, but it's not evidence. Evidence is a role that an object plays or something like that. An object is not evidence. Having this category of token is really what do you call specimens? And I think people have been saying that specimens are occurrences. If you ask people what they mean when they say occurrence, they don't really mean a specimen. And so the question, the problem is that within the existing Darwin core classes, there isn't really any class that's appropriate to place the descriptive metadata about a specimen. I think there needs to be perhaps some other classes that are related to organisms and parts of organisms. But we didn't define in Darwin SW. I mean, I think they need to be defined. But those are the kinds of things that could be used as evidence. So I think everyone agrees with that proposal that you just made. That's one I've talked to anyway. Right now it's 11.30, and we were going to move on to end vote too. So that might be a good stopping point, unless there's any other pressing... I just wanted to clarify, and I think I'm not sure if the impression that you've got of people in this room is complete. In that is that the Darwin core was a synthesis of people focused on observation data, monitoring data, there's no evidence except what the human saw and then records. But then there would be the record. Can I ask? Or if it's a digital or whatever, and then there's the stuff in the box that could be a physicist. Okay, that's fine, but we... This may be a question for Steve, but I mean, it seems like there should be or is at least a philosophical relationship between token and basis of reference. Is that correct? I couldn't hear the whole question. It seems like there's at least a philosophical or underlying relationship between the Darwin core term, basis of record, and what you guys are referring to as tokens, which is basically a basis for an assertion or a word. I think you were right. Yeah, isn't that right, Steve, that you were trying to clarify basis of record? Were we trying to clarify basis of record? Well, in other words, the difference is though that it's really not the basis of the record, it's the basis of the assertion that a certain individual occurred in a certain place. And again, basis of record seemed, and Steve, I think... Maybe Steve should say why he didn't use basis of record, but that seemed tied to collection objects. Well, basis of record is another thing that I think is overloaded, because when you look at the possible values for it, it contains things like location, events, identifications. So I think part of the problem is what basis of record means isn't exactly clear. So I promised John that I'd make way for Norman. I wanted to mention an ontology that Bob Morris developed, primarily taking Darwin SW and then grafting on some pieces of Roger Hayam's earlier Tadwick ontology for certain components of AOD records, data annotation records. And I told him I wanted to mention it, so I'll just read you what it replied. If you say anything at all about it, it probably should be that it is an ontology of convenience for dealing with the concerns of curators largely made by trimming Darwin SW, adding some things from the Tadwick ontologies. And then it goes on to say, I think section undertaking needs a workshop of comparable length to the one in Kansas, and maybe this is also a viewer's preview of the discussions tomorrow, which would be where do we take this...", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.0, "text": " John asked me, in the absence of Stephen Camm, who developed Darwinist W, John asked me to talk a little bit about it.", "tokens": [50364, 2619, 2351, 385, 11, 294, 264, 17145, 295, 13391, 383, 5136, 11, 567, 4743, 30233, 468, 343, 11, 2619, 2351, 385, 281, 751, 257, 707, 857, 466, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.37313206990559894, "compression_ratio": 1.4292929292929293, "no_speech_prob": 0.028818370774388313}, {"id": 1, "seek": 0, "start": 11.0, "end": 23.0, "text": " And I thought I would, it's okay with everybody, take the liberty of situating that work in the context of the general issue of how to represent Darwin core in RDF.", "tokens": [50914, 400, 286, 1194, 286, 576, 11, 309, 311, 1392, 365, 2201, 11, 747, 264, 22849, 295, 2054, 990, 300, 589, 294, 264, 4319, 295, 264, 2674, 2734, 295, 577, 281, 2906, 30233, 4965, 294, 49488, 37, 13, 51514], "temperature": 0.0, "avg_logprob": -0.37313206990559894, "compression_ratio": 1.4292929292929293, "no_speech_prob": 0.028818370774388313}, {"id": 2, "seek": 2300, "start": 23.0, "end": 32.0, "text": " And so, because I know that both Stephen Camm have created Darwinist W for two reasons.", "tokens": [50364, 400, 370, 11, 570, 286, 458, 300, 1293, 13391, 383, 5136, 362, 2942, 30233, 468, 343, 337, 732, 4112, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1631953274762189, "compression_ratio": 1.3454545454545455, "no_speech_prob": 0.03505135327577591}, {"id": 3, "seek": 2300, "start": 32.0, "end": 43.0, "text": " One, they had an immediate need to represent data and perhaps before consensus was reached within TADWIG about how exactly to do that.", "tokens": [50814, 1485, 11, 436, 632, 364, 11629, 643, 281, 2906, 1412, 293, 4317, 949, 19115, 390, 6488, 1951, 314, 6112, 54, 10489, 466, 577, 2293, 281, 360, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1631953274762189, "compression_ratio": 1.3454545454545455, "no_speech_prob": 0.03505135327577591}, {"id": 4, "seek": 4300, "start": 43.0, "end": 51.0, "text": " And two, they saw it as a first step towards building consensus around a canonical way to do it.", "tokens": [50364, 400, 732, 11, 436, 1866, 309, 382, 257, 700, 1823, 3030, 2390, 19115, 926, 257, 46491, 636, 281, 360, 309, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08543333862767075, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.49090415239334106}, {"id": 5, "seek": 4300, "start": 51.0, "end": 66.0, "text": " But I think that everybody, with one exception at the end, who has sort of proposed a way of doing it, agrees that these are initial steps and some consensus and further thought is required.", "tokens": [50764, 583, 286, 519, 300, 2201, 11, 365, 472, 11183, 412, 264, 917, 11, 567, 575, 1333, 295, 10348, 257, 636, 295, 884, 309, 11, 26383, 300, 613, 366, 5883, 4439, 293, 512, 19115, 293, 3052, 1194, 307, 4739, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08543333862767075, "compression_ratio": 1.5026178010471205, "no_speech_prob": 0.49090415239334106}, {"id": 6, "seek": 6600, "start": 66.0, "end": 76.0, "text": " So the first thing, so just to give a brief overview, even before we talk about any extensions, I wanted to illustrate the fact that Darwin core as it is is an ontology.", "tokens": [50364, 407, 264, 700, 551, 11, 370, 445, 281, 976, 257, 5353, 12492, 11, 754, 949, 321, 751, 466, 604, 25129, 11, 286, 1415, 281, 23221, 264, 1186, 300, 30233, 4965, 382, 309, 307, 307, 364, 6592, 1793, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07448915640513103, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.09798096120357513}, {"id": 7, "seek": 6600, "start": 76.0, "end": 83.0, "text": " And like any ontology, you can represent data with it and you can query over that data.", "tokens": [50864, 400, 411, 604, 6592, 1793, 11, 291, 393, 2906, 1412, 365, 309, 293, 291, 393, 14581, 670, 300, 1412, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07448915640513103, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.09798096120357513}, {"id": 8, "seek": 6600, "start": 83.0, "end": 92.0, "text": " And then we can talk a little bit about some of the shortcomings in Darwin core as it is an ontology and some of the proposed solutions.", "tokens": [51214, 400, 550, 321, 393, 751, 257, 707, 857, 466, 512, 295, 264, 2099, 49886, 294, 30233, 4965, 382, 309, 307, 364, 6592, 1793, 293, 512, 295, 264, 10348, 6547, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07448915640513103, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.09798096120357513}, {"id": 9, "seek": 9200, "start": 92.0, "end": 98.0, "text": " So I'll exit out of the show.", "tokens": [50364, 407, 286, 603, 11043, 484, 295, 264, 855, 13, 50664], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 10, "seek": 9200, "start": 98.0, "end": 101.0, "text": " I'll wait for refresh at 75 Hertz.", "tokens": [50664, 286, 603, 1699, 337, 15134, 412, 9562, 46910, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 11, "seek": 9200, "start": 101.0, "end": 103.0, "text": " Okay.", "tokens": [50814, 1033, 13, 50914], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 12, "seek": 9200, "start": 103.0, "end": 109.0, "text": " So here is Darwin core.", "tokens": [50914, 407, 510, 307, 30233, 4965, 13, 51214], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 13, "seek": 9200, "start": 109.0, "end": 112.0, "text": " This is the canonical description.", "tokens": [51214, 639, 307, 264, 46491, 3855, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 14, "seek": 9200, "start": 112.0, "end": 115.0, "text": " It's, you can see in the URL, it's an RDF document.", "tokens": [51364, 467, 311, 11, 291, 393, 536, 294, 264, 12905, 11, 309, 311, 364, 49488, 37, 4166, 13, 51514], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 15, "seek": 9200, "start": 115.0, "end": 119.0, "text": " This is the HTML representation of it.", "tokens": [51514, 639, 307, 264, 17995, 10290, 295, 309, 13, 51714], "temperature": 0.0, "avg_logprob": -0.16243696865970142, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.02403803914785385}, {"id": 16, "seek": 11900, "start": 119.0, "end": 124.0, "text": " And it is, as John said, a bag of terms.", "tokens": [50364, 400, 309, 307, 11, 382, 2619, 848, 11, 257, 3411, 295, 2115, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10792657962212196, "compression_ratio": 1.24822695035461, "no_speech_prob": 0.0010317818960174918}, {"id": 17, "seek": 11900, "start": 124.0, "end": 128.0, "text": " Behavior, binomial, collection ID, decimal latitude.", "tokens": [50614, 45807, 11, 5171, 47429, 11, 5765, 7348, 11, 26601, 45436, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10792657962212196, "compression_ratio": 1.24822695035461, "no_speech_prob": 0.0010317818960174918}, {"id": 18, "seek": 11900, "start": 128.0, "end": 132.0, "text": " You can look at its RDF representation.", "tokens": [50814, 509, 393, 574, 412, 1080, 49488, 37, 10290, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10792657962212196, "compression_ratio": 1.24822695035461, "no_speech_prob": 0.0010317818960174918}, {"id": 19, "seek": 11900, "start": 132.0, "end": 140.0, "text": " It's somewhat difficult to read in Safari.", "tokens": [51014, 467, 311, 8344, 2252, 281, 1401, 294, 43820, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10792657962212196, "compression_ratio": 1.24822695035461, "no_speech_prob": 0.0010317818960174918}, {"id": 20, "seek": 14000, "start": 140.0, "end": 158.0, "text": " But the, you know, John said that when they created this canonical RDF representation, they sort of didn't have the semantic web in mind or rather they had it in mind and didn't want to deal with it because I thought it would be dealt with later on.", "tokens": [50364, 583, 264, 11, 291, 458, 11, 2619, 848, 300, 562, 436, 2942, 341, 46491, 49488, 37, 10290, 11, 436, 1333, 295, 994, 380, 362, 264, 47982, 3670, 294, 1575, 420, 2831, 436, 632, 309, 294, 1575, 293, 994, 380, 528, 281, 2028, 365, 309, 570, 286, 1194, 309, 576, 312, 15991, 365, 1780, 322, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09601842094870175, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.007342049852013588}, {"id": 21, "seek": 14000, "start": 158.0, "end": 168.0, "text": " But to my mind, this is well suited for the semantic web and is a legitimate ontology in its own right.", "tokens": [51264, 583, 281, 452, 1575, 11, 341, 307, 731, 24736, 337, 264, 47982, 3670, 293, 307, 257, 17956, 6592, 1793, 294, 1080, 1065, 558, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09601842094870175, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.007342049852013588}, {"id": 22, "seek": 16800, "start": 168.0, "end": 174.0, "text": " It's a list of the things that there are in the world of biodiversity.", "tokens": [50364, 467, 311, 257, 1329, 295, 264, 721, 300, 456, 366, 294, 264, 1002, 295, 36453, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10214874791164025, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.028820859268307686}, {"id": 23, "seek": 16800, "start": 174.0, "end": 190.0, "text": " And to illustrate that, I expressed the occurrences from the Woods Hole Bioblitz in RDF only using the Darwin core namespace.", "tokens": [50664, 400, 281, 23221, 300, 11, 286, 12675, 264, 5160, 38983, 490, 264, 31559, 47635, 13007, 996, 75, 6862, 294, 49488, 37, 787, 1228, 264, 30233, 4965, 5288, 17940, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10214874791164025, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.028820859268307686}, {"id": 24, "seek": 19000, "start": 190.0, "end": 197.0, "text": " So without, without any additions, you could say, well, so here's, here's an occurrence and here are a couple.", "tokens": [50364, 407, 1553, 11, 1553, 604, 35113, 11, 291, 727, 584, 11, 731, 11, 370, 510, 311, 11, 510, 311, 364, 36122, 293, 510, 366, 257, 1916, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17896457428627827, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.21664655208587646}, {"id": 25, "seek": 19000, "start": 197.0, "end": 199.0, "text": " There are two different identifications of it.", "tokens": [50714, 821, 366, 732, 819, 2473, 7833, 295, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17896457428627827, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.21664655208587646}, {"id": 26, "seek": 19000, "start": 199.0, "end": 205.0, "text": " One saying it was an ampelopsis and one saying that it was something else.", "tokens": [50814, 1485, 1566, 309, 390, 364, 18648, 338, 3370, 271, 293, 472, 1566, 300, 309, 390, 746, 1646, 13, 51114], "temperature": 0.0, "avg_logprob": -0.17896457428627827, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.21664655208587646}, {"id": 27, "seek": 19000, "start": 205.0, "end": 209.0, "text": " Parthenosisis kinchifolia.", "tokens": [51114, 3457, 19096, 8211, 271, 15784, 339, 351, 29760, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17896457428627827, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.21664655208587646}, {"id": 28, "seek": 19000, "start": 209.0, "end": 219.0, "text": " And then each of those identifications and occurrences have their own, have their own good.", "tokens": [51314, 400, 550, 1184, 295, 729, 2473, 7833, 293, 5160, 38983, 362, 641, 1065, 11, 362, 641, 1065, 665, 13, 51814], "temperature": 0.0, "avg_logprob": -0.17896457428627827, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.21664655208587646}, {"id": 29, "seek": 21900, "start": 219.0, "end": 231.0, "text": " And you might, this right away sort of illustrates one of the, one of the issues that here identification is being used as a property of occurrence.", "tokens": [50364, 400, 291, 1062, 11, 341, 558, 1314, 1333, 295, 41718, 472, 295, 264, 11, 472, 295, 264, 2663, 300, 510, 22065, 307, 885, 1143, 382, 257, 4707, 295, 36122, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06732149857741136, "compression_ratio": 1.625, "no_speech_prob": 0.0026302263140678406}, {"id": 30, "seek": 21900, "start": 231.0, "end": 243.0, "text": " But then if you, if you look at the GUID of that identification, you'll see that you can also use identification as a class.", "tokens": [50964, 583, 550, 498, 291, 11, 498, 291, 574, 412, 264, 17917, 2777, 295, 300, 22065, 11, 291, 603, 536, 300, 291, 393, 611, 764, 22065, 382, 257, 1508, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06732149857741136, "compression_ratio": 1.625, "no_speech_prob": 0.0026302263140678406}, {"id": 31, "seek": 24300, "start": 244.0, "end": 247.0, "text": " And that's, that's okay.", "tokens": [50414, 400, 300, 311, 11, 300, 311, 1392, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10688854949642913, "compression_ratio": 1.7010309278350515, "no_speech_prob": 0.017652900889515877}, {"id": 32, "seek": 24300, "start": 247.0, "end": 256.0, "text": " The reasoners don't, you know, overheat and, and blow a fuse because of course a property is a class.", "tokens": [50564, 440, 1778, 433, 500, 380, 11, 291, 458, 11, 29807, 267, 293, 11, 293, 6327, 257, 31328, 570, 295, 1164, 257, 4707, 307, 257, 1508, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10688854949642913, "compression_ratio": 1.7010309278350515, "no_speech_prob": 0.017652900889515877}, {"id": 33, "seek": 24300, "start": 256.0, "end": 260.0, "text": " And so there's no, you know, there's no, not necessarily attention there.", "tokens": [51014, 400, 370, 456, 311, 572, 11, 291, 458, 11, 456, 311, 572, 11, 406, 4725, 3202, 456, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10688854949642913, "compression_ratio": 1.7010309278350515, "no_speech_prob": 0.017652900889515877}, {"id": 34, "seek": 24300, "start": 260.0, "end": 263.0, "text": " Nevertheless, it's, you know, it's bad form, of course.", "tokens": [51214, 26554, 11, 309, 311, 11, 291, 458, 11, 309, 311, 1578, 1254, 11, 295, 1164, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10688854949642913, "compression_ratio": 1.7010309278350515, "no_speech_prob": 0.017652900889515877}, {"id": 35, "seek": 24300, "start": 263.0, "end": 267.0, "text": " I mean, I think to have the same term that's both a property and a class.", "tokens": [51364, 286, 914, 11, 286, 519, 281, 362, 264, 912, 1433, 300, 311, 1293, 257, 4707, 293, 257, 1508, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10688854949642913, "compression_ratio": 1.7010309278350515, "no_speech_prob": 0.017652900889515877}, {"id": 36, "seek": 26700, "start": 267.0, "end": 281.0, "text": " So at a minimum, my suggestion, you know, as a first layer, semantic layer would be to roughly double the number of terms and to introduce, you know, disambiguate when you're using identification as a class and when you're using it as a property.", "tokens": [50364, 407, 412, 257, 7285, 11, 452, 16541, 11, 291, 458, 11, 382, 257, 700, 4583, 11, 47982, 4583, 576, 312, 281, 9810, 3834, 264, 1230, 295, 2115, 293, 281, 5366, 11, 291, 458, 11, 717, 2173, 328, 10107, 562, 291, 434, 1228, 22065, 382, 257, 1508, 293, 562, 291, 434, 1228, 309, 382, 257, 4707, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11528335918079723, "compression_ratio": 1.7098445595854923, "no_speech_prob": 0.001048018573783338}, {"id": 37, "seek": 26700, "start": 281.0, "end": 290.0, "text": " So introduce a hazard identification, hazard occurrence, hazard habitat, et cetera.", "tokens": [51064, 407, 5366, 257, 20790, 22065, 11, 20790, 36122, 11, 20790, 20110, 11, 1030, 11458, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11528335918079723, "compression_ratio": 1.7098445595854923, "no_speech_prob": 0.001048018573783338}, {"id": 38, "seek": 29000, "start": 290.0, "end": 306.0, "text": " But even as it is, you can, you know, reason over the data, you can issue sparkle queries and, and get, you know, get answers.", "tokens": [50364, 583, 754, 382, 309, 307, 11, 291, 393, 11, 291, 458, 11, 1778, 670, 264, 1412, 11, 291, 393, 2734, 48558, 24109, 293, 11, 293, 483, 11, 291, 458, 11, 483, 6338, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09058204857078758, "compression_ratio": 1.3404255319148937, "no_speech_prob": 0.0029796839226037264}, {"id": 39, "seek": 30600, "start": 307.0, "end": 314.0, "text": " So I guess we're going to be talking more this afternoon and tomorrow.", "tokens": [50414, 407, 286, 2041, 321, 434, 516, 281, 312, 1417, 544, 341, 6499, 293, 4153, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1377706351103606, "compression_ratio": 1.4487179487179487, "no_speech_prob": 0.40676185488700867}, {"id": 40, "seek": 30600, "start": 314.0, "end": 325.0, "text": " But I guess my viewer, the viewer's preview of my position is that I think we should make as small changes to the existing way of doing things as possible.", "tokens": [50764, 583, 286, 2041, 452, 16767, 11, 264, 16767, 311, 14281, 295, 452, 2535, 307, 300, 286, 519, 321, 820, 652, 382, 1359, 2962, 281, 264, 6741, 636, 295, 884, 721, 382, 1944, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1377706351103606, "compression_ratio": 1.4487179487179487, "no_speech_prob": 0.40676185488700867}, {"id": 41, "seek": 32500, "start": 326.0, "end": 335.0, "text": " So the next, so, so Steve, now I've opened up Darwin S.W., the class diagram.", "tokens": [50414, 407, 264, 958, 11, 370, 11, 370, 7466, 11, 586, 286, 600, 5625, 493, 30233, 318, 13, 54, 7933, 264, 1508, 10686, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 42, "seek": 32500, "start": 335.0, "end": 341.0, "text": " I know that it can't be seen from the back, but it can't be seen any, any better on the slide.", "tokens": [50864, 286, 458, 300, 309, 393, 380, 312, 1612, 490, 264, 646, 11, 457, 309, 393, 380, 312, 1612, 604, 11, 604, 1101, 322, 264, 4137, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 43, "seek": 32500, "start": 341.0, "end": 347.0, "text": " If you, if you click on the last, the ready talk slide there, it'll show the same thing we have.", "tokens": [51164, 759, 291, 11, 498, 291, 2052, 322, 264, 1036, 11, 264, 1919, 751, 4137, 456, 11, 309, 603, 855, 264, 912, 551, 321, 362, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 44, "seek": 32500, "start": 347.0, "end": 348.0, "text": " Okay.", "tokens": [51464, 1033, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 45, "seek": 32500, "start": 348.0, "end": 349.0, "text": " The one.", "tokens": [51514, 440, 472, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 46, "seek": 32500, "start": 349.0, "end": 350.0, "text": " Ready talk, here we go.", "tokens": [51564, 9944, 751, 11, 510, 321, 352, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 47, "seek": 32500, "start": 350.0, "end": 351.0, "text": " So.", "tokens": [51614, 407, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 48, "seek": 32500, "start": 351.0, "end": 353.0, "text": " That's what's being shown.", "tokens": [51664, 663, 311, 437, 311, 885, 4898, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18036342722124757, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.10368377715349197}, {"id": 49, "seek": 35300, "start": 353.0, "end": 354.0, "text": " All right.", "tokens": [50364, 1057, 558, 13, 50414], "temperature": 0.0, "avg_logprob": -0.12322670763189142, "compression_ratio": 1.6318407960199004, "no_speech_prob": 0.00035673717502504587}, {"id": 50, "seek": 35300, "start": 354.0, "end": 358.0, "text": " So can you go to the slide that has the, the class diagram?", "tokens": [50414, 407, 393, 291, 352, 281, 264, 4137, 300, 575, 264, 11, 264, 1508, 10686, 30, 50614], "temperature": 0.0, "avg_logprob": -0.12322670763189142, "compression_ratio": 1.6318407960199004, "no_speech_prob": 0.00035673717502504587}, {"id": 51, "seek": 35300, "start": 358.0, "end": 362.0, "text": " I think it's the third slide.", "tokens": [50614, 286, 519, 309, 311, 264, 2636, 4137, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12322670763189142, "compression_ratio": 1.6318407960199004, "no_speech_prob": 0.00035673717502504587}, {"id": 52, "seek": 35300, "start": 362.0, "end": 381.0, "text": " So as there was a lot of discussion, as John was mentioning about how to move, how to, how to move Darwin core, how to make Darwin core more appropriate for, for, for representing data in RDF and on the semantic web in general.", "tokens": [50814, 407, 382, 456, 390, 257, 688, 295, 5017, 11, 382, 2619, 390, 18315, 466, 577, 281, 1286, 11, 577, 281, 11, 577, 281, 1286, 30233, 4965, 11, 577, 281, 652, 30233, 4965, 544, 6854, 337, 11, 337, 11, 337, 13460, 1412, 294, 49488, 37, 293, 322, 264, 47982, 3670, 294, 2674, 13, 51764], "temperature": 0.0, "avg_logprob": -0.12322670763189142, "compression_ratio": 1.6318407960199004, "no_speech_prob": 0.00035673717502504587}, {"id": 53, "seek": 38100, "start": 381.0, "end": 385.0, "text": " And a lot of it centered around the overloading of the term occurrence.", "tokens": [50364, 400, 257, 688, 295, 309, 18988, 926, 264, 28777, 278, 295, 264, 1433, 36122, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06711174823619702, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.009841579012572765}, {"id": 54, "seek": 38100, "start": 385.0, "end": 392.0, "text": " So Steve, since you're with us, I'll let you talk about, you know, Darwin S.W. in a minute.", "tokens": [50564, 407, 7466, 11, 1670, 291, 434, 365, 505, 11, 286, 603, 718, 291, 751, 466, 11, 291, 458, 11, 30233, 318, 13, 54, 13, 294, 257, 3456, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06711174823619702, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.009841579012572765}, {"id": 55, "seek": 38100, "start": 392.0, "end": 404.0, "text": " But I wanted to sort of just say what, what I think is it's, you know, most important contribution, which is that it teases out some of the overloading of occurrence that went on.", "tokens": [50914, 583, 286, 1415, 281, 1333, 295, 445, 584, 437, 11, 437, 286, 519, 307, 309, 311, 11, 291, 458, 11, 881, 1021, 13150, 11, 597, 307, 300, 309, 535, 1957, 484, 512, 295, 264, 28777, 278, 295, 36122, 300, 1437, 322, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06711174823619702, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.009841579012572765}, {"id": 56, "seek": 38100, "start": 404.0, "end": 408.0, "text": " And, and it does this by introducing a new term token.", "tokens": [51514, 400, 11, 293, 309, 775, 341, 538, 15424, 257, 777, 1433, 14862, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06711174823619702, "compression_ratio": 1.6178861788617886, "no_speech_prob": 0.009841579012572765}, {"id": 57, "seek": 40800, "start": 408.0, "end": 427.0, "text": " So, and John, correct me if I'm wrong, but I think that part of the issue was that coming out of a collections mentality, an occurrence was thought of as it could be a specimen or it could be an image or it could be a tissue sample.", "tokens": [50364, 407, 11, 293, 2619, 11, 3006, 385, 498, 286, 478, 2085, 11, 457, 286, 519, 300, 644, 295, 264, 2734, 390, 300, 1348, 484, 295, 257, 16641, 21976, 11, 364, 36122, 390, 1194, 295, 382, 309, 727, 312, 257, 34204, 420, 309, 727, 312, 364, 3256, 420, 309, 727, 312, 257, 12404, 6889, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10789264332164418, "compression_ratio": 1.6685393258426966, "no_speech_prob": 0.001324792392551899}, {"id": 58, "seek": 40800, "start": 427.0, "end": 432.0, "text": " And, or it could just be something that, that you, that you saw.", "tokens": [51314, 400, 11, 420, 309, 727, 445, 312, 746, 300, 11, 300, 291, 11, 300, 291, 1866, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10789264332164418, "compression_ratio": 1.6685393258426966, "no_speech_prob": 0.001324792392551899}, {"id": 59, "seek": 43200, "start": 432.0, "end": 444.0, "text": " And so Steve says, well, actually, to be more correct, the specimen or the tissue sample or the photograph are tokens of the occurrence.", "tokens": [50364, 400, 370, 7466, 1619, 11, 731, 11, 767, 11, 281, 312, 544, 3006, 11, 264, 34204, 420, 264, 12404, 6889, 420, 264, 8348, 366, 22667, 295, 264, 36122, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09636829977166163, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.0675119161605835}, {"id": 60, "seek": 43200, "start": 444.0, "end": 449.0, "text": " Word of mouth could be a token of the occurrence and those tokens all serve as evidence.", "tokens": [50964, 8725, 295, 4525, 727, 312, 257, 14862, 295, 264, 36122, 293, 729, 22667, 439, 4596, 382, 4467, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09636829977166163, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.0675119161605835}, {"id": 61, "seek": 43200, "start": 449.0, "end": 456.0, "text": " So I think he settled on token because evidence, he tried to introduce the term evidence.", "tokens": [51214, 407, 286, 519, 415, 14819, 322, 14862, 570, 4467, 11, 415, 3031, 281, 5366, 264, 1433, 4467, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09636829977166163, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.0675119161605835}, {"id": 62, "seek": 45600, "start": 456.0, "end": 462.0, "text": " I might be wrong about the history and then there was too much argument over what evidence properly means and so he settled on token.", "tokens": [50364, 286, 1062, 312, 2085, 466, 264, 2503, 293, 550, 456, 390, 886, 709, 6770, 670, 437, 4467, 6108, 1355, 293, 370, 415, 14819, 322, 14862, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07232663655045009, "compression_ratio": 1.772, "no_speech_prob": 0.025164656341075897}, {"id": 63, "seek": 45600, "start": 462.0, "end": 475.0, "text": " Similarly, he tried to introduce the term individual and I think there was agreement that that would be a good term to add, a good concept to add to the graph.", "tokens": [50664, 13157, 11, 415, 3031, 281, 5366, 264, 1433, 2609, 293, 286, 519, 456, 390, 8106, 300, 300, 576, 312, 257, 665, 1433, 281, 909, 11, 257, 665, 3410, 281, 909, 281, 264, 4295, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07232663655045009, "compression_ratio": 1.772, "no_speech_prob": 0.025164656341075897}, {"id": 64, "seek": 45600, "start": 475.0, "end": 482.0, "text": " But there is no agreement on what it should be called and what its scope should be and whether it would include a flock of geese or a pack of wolves.", "tokens": [51314, 583, 456, 307, 572, 8106, 322, 437, 309, 820, 312, 1219, 293, 437, 1080, 11923, 820, 312, 293, 1968, 309, 576, 4090, 257, 34819, 295, 1519, 1130, 420, 257, 2844, 295, 30404, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07232663655045009, "compression_ratio": 1.772, "no_speech_prob": 0.025164656341075897}, {"id": 65, "seek": 48200, "start": 482.0, "end": 487.0, "text": " And so I think that's left out, right? So there's still no individual in Darwin Corps.", "tokens": [50364, 400, 370, 286, 519, 300, 311, 1411, 484, 11, 558, 30, 407, 456, 311, 920, 572, 2609, 294, 30233, 20169, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2394733199154038, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.053998272866010666}, {"id": 66, "seek": 48200, "start": 487.0, "end": 500.0, "text": " Individual Darwin Corps, but the discussion did go forward and accept as a scope for the concept of populations down to mixed tax on things.", "tokens": [50614, 37292, 30233, 20169, 11, 457, 264, 5017, 630, 352, 2128, 293, 3241, 382, 257, 11923, 337, 264, 3410, 295, 12822, 760, 281, 7467, 3366, 322, 721, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2394733199154038, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.053998272866010666}, {"id": 67, "seek": 48200, "start": 500.0, "end": 501.0, "text": " Right.", "tokens": [51264, 1779, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2394733199154038, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.053998272866010666}, {"id": 68, "seek": 48200, "start": 501.0, "end": 503.0, "text": " And it would be called enormous.", "tokens": [51314, 400, 309, 576, 312, 1219, 11322, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2394733199154038, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.053998272866010666}, {"id": 69, "seek": 48200, "start": 503.0, "end": 506.0, "text": " So that's still though to be, that's not yet introduced.", "tokens": [51414, 407, 300, 311, 920, 1673, 281, 312, 11, 300, 311, 406, 1939, 7268, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2394733199154038, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.053998272866010666}, {"id": 70, "seek": 50600, "start": 506.0, "end": 534.0, "text": " So the other thing to, I guess, notice is that these classes and the properties associated to them are normalized in the sense that if you look at identification, that can only be applied to a token, not to an occurrence or so.", "tokens": [50364, 407, 264, 661, 551, 281, 11, 286, 2041, 11, 3449, 307, 300, 613, 5359, 293, 264, 7221, 6615, 281, 552, 366, 48704, 294, 264, 2020, 300, 498, 291, 574, 412, 22065, 11, 300, 393, 787, 312, 6456, 281, 257, 14862, 11, 406, 281, 364, 36122, 420, 370, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13022084419543928, "compression_ratio": 1.5133333333333334, "no_speech_prob": 0.02159247361123562}, {"id": 71, "seek": 53400, "start": 534.0, "end": 544.0, "text": " And similarly, the tax on itself, which is the determination, is then a property of the identification.", "tokens": [50364, 400, 14138, 11, 264, 3366, 322, 2564, 11, 597, 307, 264, 18432, 11, 307, 550, 257, 4707, 295, 264, 22065, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12134854190320854, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.024032488465309143}, {"id": 72, "seek": 53400, "start": 544.0, "end": 546.0, "text": " Joel, can you do full screen?", "tokens": [50864, 21522, 11, 393, 291, 360, 1577, 2568, 30, 50964], "temperature": 0.0, "avg_logprob": -0.12134854190320854, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.024032488465309143}, {"id": 73, "seek": 53400, "start": 546.0, "end": 550.0, "text": " Yeah, that would be a good idea.", "tokens": [50964, 865, 11, 300, 576, 312, 257, 665, 1558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12134854190320854, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.024032488465309143}, {"id": 74, "seek": 53400, "start": 550.0, "end": 553.0, "text": " That's a great idea.", "tokens": [51164, 663, 311, 257, 869, 1558, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12134854190320854, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.024032488465309143}, {"id": 75, "seek": 53400, "start": 553.0, "end": 561.0, "text": " So just to point to what I was talking to, here's the occurrence, here are the new terms, token and individual organism.", "tokens": [51314, 407, 445, 281, 935, 281, 437, 286, 390, 1417, 281, 11, 510, 311, 264, 36122, 11, 510, 366, 264, 777, 2115, 11, 14862, 293, 2609, 24128, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12134854190320854, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.024032488465309143}, {"id": 76, "seek": 56100, "start": 561.0, "end": 575.0, "text": " And looking back, I didn't find the email, but from about two years ago, when a Darwin Corps was first represented in that RDF manner, there was a question, should there be any domain constraints on any of these terms, like, for example, identification?", "tokens": [50364, 400, 1237, 646, 11, 286, 994, 380, 915, 264, 3796, 11, 457, 490, 466, 732, 924, 2057, 11, 562, 257, 30233, 20169, 390, 700, 10379, 294, 300, 49488, 37, 9060, 11, 456, 390, 257, 1168, 11, 820, 456, 312, 604, 9274, 18491, 322, 604, 295, 613, 2115, 11, 411, 11, 337, 1365, 11, 22065, 30, 51064], "temperature": 0.0, "avg_logprob": -0.10658180579710543, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.12232746183872223}, {"id": 77, "seek": 56100, "start": 575.0, "end": 586.0, "text": " And the decision was made, you know, no, because that could lead to too much potential for misuse if people apply these terms.", "tokens": [51064, 400, 264, 3537, 390, 1027, 11, 291, 458, 11, 572, 11, 570, 300, 727, 1477, 281, 886, 709, 3995, 337, 3346, 438, 498, 561, 3079, 613, 2115, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10658180579710543, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.12232746183872223}, {"id": 78, "seek": 58600, "start": 586.0, "end": 598.0, "text": " And this is something that I'm, you know, interested in, is in a very loose context, if people are applying identifications to samples or to pictures or to occurrences or to organisms.", "tokens": [50364, 400, 341, 307, 746, 300, 286, 478, 11, 291, 458, 11, 3102, 294, 11, 307, 294, 257, 588, 9612, 4319, 11, 498, 561, 366, 9275, 2473, 7833, 281, 10938, 420, 281, 5242, 420, 281, 5160, 38983, 420, 281, 22110, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14106240383414334, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.10646506398916245}, {"id": 79, "seek": 58600, "start": 598.0, "end": 606.0, "text": " But Steve is sort of much more principled and says, you know, identification properly has, you know, the domain of the token.", "tokens": [50964, 583, 7466, 307, 1333, 295, 709, 544, 3681, 15551, 293, 1619, 11, 291, 458, 11, 22065, 6108, 575, 11, 291, 458, 11, 264, 9274, 295, 264, 14862, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14106240383414334, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.10646506398916245}, {"id": 80, "seek": 58600, "start": 606.0, "end": 611.0, "text": " Is there identification by identification?", "tokens": [51364, 1119, 456, 22065, 538, 22065, 30, 51614], "temperature": 0.0, "avg_logprob": -0.14106240383414334, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.10646506398916245}, {"id": 81, "seek": 58600, "start": 611.0, "end": 613.0, "text": " Steve?", "tokens": [51614, 7466, 30, 51714], "temperature": 0.0, "avg_logprob": -0.14106240383414334, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.10646506398916245}, {"id": 82, "seek": 61300, "start": 613.0, "end": 615.0, "text": " I'm sorry, what was the question?", "tokens": [50364, 286, 478, 2597, 11, 437, 390, 264, 1168, 30, 50464], "temperature": 0.0, "avg_logprob": -0.12278644131942534, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.0007090707076713443}, {"id": 83, "seek": 61300, "start": 615.0, "end": 619.0, "text": " The question is, is there a definition of identification?", "tokens": [50464, 440, 1168, 307, 11, 307, 456, 257, 7123, 295, 22065, 30, 50664], "temperature": 0.0, "avg_logprob": -0.12278644131942534, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.0007090707076713443}, {"id": 84, "seek": 61300, "start": 619.0, "end": 622.0, "text": " And I think...", "tokens": [50664, 400, 286, 519, 485, 50814], "temperature": 0.0, "avg_logprob": -0.12278644131942534, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.0007090707076713443}, {"id": 85, "seek": 61300, "start": 622.0, "end": 640.0, "text": " Well, I mean, identification, in all of the Darwin Corps classes, there's not a clear definition in the sense of what the, how they are connected to the other classes.", "tokens": [50814, 1042, 11, 286, 914, 11, 22065, 11, 294, 439, 295, 264, 30233, 20169, 5359, 11, 456, 311, 406, 257, 1850, 7123, 294, 264, 2020, 295, 437, 264, 11, 577, 436, 366, 4582, 281, 264, 661, 5359, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12278644131942534, "compression_ratio": 1.583815028901734, "no_speech_prob": 0.0007090707076713443}, {"id": 86, "seek": 64000, "start": 640.0, "end": 651.0, "text": " And I mean, I think that identification, well, identification connects something to a taxon concept.", "tokens": [50364, 400, 286, 914, 11, 286, 519, 300, 22065, 11, 731, 11, 22065, 16967, 746, 281, 257, 3366, 266, 3410, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10618740862066095, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.1200636476278305}, {"id": 87, "seek": 64000, "start": 651.0, "end": 655.0, "text": " And I guess the question is, what is that something that is being identified?", "tokens": [50914, 400, 286, 2041, 264, 1168, 307, 11, 437, 307, 300, 746, 300, 307, 885, 9234, 30, 51114], "temperature": 0.0, "avg_logprob": -0.10618740862066095, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.1200636476278305}, {"id": 88, "seek": 64000, "start": 655.0, "end": 669.0, "text": " So, you know, we took the position that identification was connecting some kind of a nebulous thing,", "tokens": [51114, 407, 11, 291, 458, 11, 321, 1890, 264, 2535, 300, 22065, 390, 11015, 512, 733, 295, 257, 408, 65, 6893, 551, 11, 51814], "temperature": 0.0, "avg_logprob": -0.10618740862066095, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.1200636476278305}, {"id": 89, "seek": 66900, "start": 669.0, "end": 673.0, "text": " which we call the individual organism to a taxon.", "tokens": [50364, 597, 321, 818, 264, 2609, 24128, 281, 257, 3366, 266, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 90, "seek": 66900, "start": 673.0, "end": 677.0, "text": " Is the, is an identification an event?", "tokens": [50564, 1119, 264, 11, 307, 364, 22065, 364, 2280, 30, 50764], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 91, "seek": 66900, "start": 677.0, "end": 678.0, "text": " Yes.", "tokens": [50764, 1079, 13, 50814], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 92, "seek": 66900, "start": 678.0, "end": 679.0, "text": " I'm sorry?", "tokens": [50814, 286, 478, 2597, 30, 50864], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 93, "seek": 66900, "start": 679.0, "end": 682.0, "text": " Is identification an event?", "tokens": [50864, 1119, 22065, 364, 2280, 30, 51014], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 94, "seek": 66900, "start": 682.0, "end": 683.0, "text": " No.", "tokens": [51014, 883, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 95, "seek": 66900, "start": 683.0, "end": 689.0, "text": " It is not defined as an event.", "tokens": [51064, 467, 307, 406, 7642, 382, 364, 2280, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 96, "seek": 66900, "start": 689.0, "end": 693.0, "text": " It's defined as a category of information in Darwin Corps.", "tokens": [51364, 467, 311, 7642, 382, 257, 7719, 295, 1589, 294, 30233, 20169, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 97, "seek": 66900, "start": 693.0, "end": 695.0, "text": " Result of the event.", "tokens": [51564, 5015, 723, 295, 264, 2280, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 98, "seek": 66900, "start": 695.0, "end": 697.0, "text": " Conceptually, it is an event.", "tokens": [51664, 47482, 671, 11, 309, 307, 364, 2280, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17911800641692086, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.012698034755885601}, {"id": 99, "seek": 69700, "start": 697.0, "end": 709.0, "text": " The term event in Darwin Corps derives from the Dublin Corps, which is why it doesn't say collecting event within the current session or the current sense of Darwin Corps.", "tokens": [50364, 440, 1433, 2280, 294, 30233, 20169, 1163, 1539, 490, 264, 42323, 20169, 11, 597, 307, 983, 309, 1177, 380, 584, 12510, 2280, 1951, 264, 2190, 5481, 420, 264, 2190, 2020, 295, 30233, 20169, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09734068013200856, "compression_ratio": 1.7172131147540983, "no_speech_prob": 0.015169596299529076}, {"id": 100, "seek": 69700, "start": 709.0, "end": 713.0, "text": " So, we know there are many kinds of events in all the work we do.", "tokens": [50964, 407, 11, 321, 458, 456, 366, 867, 3685, 295, 3931, 294, 439, 264, 589, 321, 360, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09734068013200856, "compression_ratio": 1.7172131147540983, "no_speech_prob": 0.015169596299529076}, {"id": 101, "seek": 69700, "start": 713.0, "end": 726.0, "text": " So, I'll make a general point, which is, if you're going to do a semantic version of the Darwin Corps, then you need definitions, which would be formulated using something like owl.", "tokens": [51164, 407, 11, 286, 603, 652, 257, 2674, 935, 11, 597, 307, 11, 498, 291, 434, 516, 281, 360, 257, 47982, 3037, 295, 264, 30233, 20169, 11, 550, 291, 643, 21988, 11, 597, 576, 312, 48936, 1228, 746, 411, 34488, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09734068013200856, "compression_ratio": 1.7172131147540983, "no_speech_prob": 0.015169596299529076}, {"id": 102, "seek": 72600, "start": 727.0, "end": 730.0, "text": " That's, you should be nodding your head.", "tokens": [50414, 663, 311, 11, 291, 820, 312, 15224, 3584, 428, 1378, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11088416742724042, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.007898838259279728}, {"id": 103, "seek": 72600, "start": 730.0, "end": 734.0, "text": " Well, only if I agree with you, right?", "tokens": [50564, 1042, 11, 787, 498, 286, 3986, 365, 291, 11, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.11088416742724042, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.007898838259279728}, {"id": 104, "seek": 72600, "start": 734.0, "end": 746.0, "text": " And then the second point I would make is that, at the moment, I think many of these terms are just going to create puzzlement, because they're so abstract.", "tokens": [50764, 400, 550, 264, 1150, 935, 286, 576, 652, 307, 300, 11, 412, 264, 1623, 11, 286, 519, 867, 295, 613, 2115, 366, 445, 516, 281, 1884, 18741, 3054, 11, 570, 436, 434, 370, 12649, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11088416742724042, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.007898838259279728}, {"id": 105, "seek": 72600, "start": 746.0, "end": 753.0, "text": " So, most people don't use token in their daily data collection business, I would suppose.", "tokens": [51364, 407, 11, 881, 561, 500, 380, 764, 14862, 294, 641, 5212, 1412, 5765, 1606, 11, 286, 576, 7297, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11088416742724042, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.007898838259279728}, {"id": 106, "seek": 75300, "start": 753.0, "end": 762.0, "text": " Can they understand, actually, and the work we just pointed out, some of the problems with the n-view of the year that we're dealing with, in that you do have tractable terms of the year.", "tokens": [50364, 1664, 436, 1223, 11, 767, 11, 293, 264, 589, 321, 445, 10932, 484, 11, 512, 295, 264, 2740, 365, 264, 297, 12, 1759, 295, 264, 1064, 300, 321, 434, 6260, 365, 11, 294, 300, 291, 360, 362, 24207, 712, 2115, 295, 264, 1064, 13, 50814], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 107, "seek": 75300, "start": 762.0, "end": 769.0, "text": " Identification, and it has a definition, says it's information, or category of information.", "tokens": [50814, 25905, 3774, 11, 293, 309, 575, 257, 7123, 11, 1619, 309, 311, 1589, 11, 420, 7719, 295, 1589, 13, 51164], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 108, "seek": 75300, "start": 769.0, "end": 771.0, "text": " That's not, it doesn't tell you much.", "tokens": [51164, 663, 311, 406, 11, 309, 1177, 380, 980, 291, 709, 13, 51264], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 109, "seek": 75300, "start": 771.0, "end": 773.0, "text": " It says a thing.", "tokens": [51264, 467, 1619, 257, 551, 13, 51364], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 110, "seek": 75300, "start": 773.0, "end": 776.0, "text": " But at the same time, it's the same point I got here.", "tokens": [51364, 583, 412, 264, 912, 565, 11, 309, 311, 264, 912, 935, 286, 658, 510, 13, 51514], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 111, "seek": 75300, "start": 776.0, "end": 777.0, "text": " Oh, wait.", "tokens": [51514, 876, 11, 1699, 13, 51564], "temperature": 0.0, "avg_logprob": -0.312659706388201, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.030162043869495392}, {"id": 112, "seek": 77700, "start": 777.0, "end": 782.0, "text": " In my mind, when you say identification, I see a process.", "tokens": [50364, 682, 452, 1575, 11, 562, 291, 584, 22065, 11, 286, 536, 257, 1399, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13714372938957767, "compression_ratio": 1.425, "no_speech_prob": 0.007444476708769798}, {"id": 113, "seek": 77700, "start": 782.0, "end": 784.0, "text": " I see a narrative.", "tokens": [50614, 286, 536, 257, 9977, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13714372938957767, "compression_ratio": 1.425, "no_speech_prob": 0.007444476708769798}, {"id": 114, "seek": 77700, "start": 784.0, "end": 787.0, "text": " We have a long history of modeling in this community.", "tokens": [50714, 492, 362, 257, 938, 2503, 295, 15983, 294, 341, 1768, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13714372938957767, "compression_ratio": 1.425, "no_speech_prob": 0.007444476708769798}, {"id": 115, "seek": 77700, "start": 787.0, "end": 788.0, "text": " Yeah.", "tokens": [50864, 865, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13714372938957767, "compression_ratio": 1.425, "no_speech_prob": 0.007444476708769798}, {"id": 116, "seek": 77700, "start": 788.0, "end": 794.0, "text": " As I was telling, you know, it goes back to, you know, 92 or 90 when we started doing this.", "tokens": [50914, 1018, 286, 390, 3585, 11, 291, 458, 11, 309, 1709, 646, 281, 11, 291, 458, 11, 28225, 420, 4289, 562, 321, 1409, 884, 341, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13714372938957767, "compression_ratio": 1.425, "no_speech_prob": 0.007444476708769798}, {"id": 117, "seek": 79400, "start": 794.0, "end": 809.0, "text": " And it's an identification as an event with, as an association of something biological with a taxonomy done by someone at some time is common to virtually all the models that we have done.", "tokens": [50364, 400, 309, 311, 364, 22065, 382, 364, 2280, 365, 11, 382, 364, 14598, 295, 746, 13910, 365, 257, 3366, 23423, 1096, 538, 1580, 412, 512, 565, 307, 2689, 281, 14103, 439, 264, 5245, 300, 321, 362, 1096, 13, 51114], "temperature": 0.0, "avg_logprob": -0.16904289868413186, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.14002975821495056}, {"id": 118, "seek": 79400, "start": 809.0, "end": 810.0, "text": " When they have that.", "tokens": [51114, 1133, 436, 362, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16904289868413186, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.14002975821495056}, {"id": 119, "seek": 79400, "start": 810.0, "end": 812.0, "text": " Except that it's not an event.", "tokens": [51164, 16192, 300, 309, 311, 406, 364, 2280, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16904289868413186, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.14002975821495056}, {"id": 120, "seek": 79400, "start": 812.0, "end": 823.0, "text": " Except that in the Darwin court, because we didn't do assembly of terms into concepts like this, you know, the structure that we've been talking about, it's not included.", "tokens": [51264, 16192, 300, 294, 264, 30233, 4753, 11, 570, 321, 994, 380, 360, 12103, 295, 2115, 666, 10392, 411, 341, 11, 291, 458, 11, 264, 3877, 300, 321, 600, 668, 1417, 466, 11, 309, 311, 406, 5556, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16904289868413186, "compression_ratio": 1.691358024691358, "no_speech_prob": 0.14002975821495056}, {"id": 121, "seek": 82300, "start": 824.0, "end": 829.0, "text": " So I'm making a general point that if you're using abstract terms, that's fine.", "tokens": [50414, 407, 286, 478, 1455, 257, 2674, 935, 300, 498, 291, 434, 1228, 12649, 2115, 11, 300, 311, 2489, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 122, "seek": 82300, "start": 829.0, "end": 835.0, "text": " But then you're not going to help the user unless you define those abstract terms.", "tokens": [50664, 583, 550, 291, 434, 406, 516, 281, 854, 264, 4195, 5969, 291, 6964, 729, 12649, 2115, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 123, "seek": 82300, "start": 835.0, "end": 842.0, "text": " And if he said, but we have an established community here, which knows what they're doing, you're creating a mystery.", "tokens": [50964, 400, 498, 415, 848, 11, 457, 321, 362, 364, 7545, 1768, 510, 11, 597, 3255, 437, 436, 434, 884, 11, 291, 434, 4084, 257, 11422, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 124, "seek": 82300, "start": 842.0, "end": 848.0, "text": " Because you want your data to be viewable from the outside by Japanese people with really nice machines.", "tokens": [51314, 1436, 291, 528, 428, 1412, 281, 312, 1910, 712, 490, 264, 2380, 538, 5433, 561, 365, 534, 1481, 8379, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 125, "seek": 82300, "start": 848.0, "end": 850.0, "text": " They will not understand.", "tokens": [51614, 814, 486, 406, 1223, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 126, "seek": 82300, "start": 850.0, "end": 851.0, "text": " Japanese have really nice machines.", "tokens": [51714, 5433, 362, 534, 1481, 8379, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09728348812210226, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.012896137312054634}, {"id": 127, "seek": 85100, "start": 851.0, "end": 852.0, "text": " This is the point that we're at.", "tokens": [50364, 639, 307, 264, 935, 300, 321, 434, 412, 13, 50414], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 128, "seek": 85100, "start": 852.0, "end": 862.0, "text": " We're at the point of saying, yes, we all agree that we need to have a structural thing that's called a taxonomic identification or something like that.", "tokens": [50414, 492, 434, 412, 264, 935, 295, 1566, 11, 2086, 11, 321, 439, 3986, 300, 321, 643, 281, 362, 257, 15067, 551, 300, 311, 1219, 257, 3366, 12481, 299, 22065, 420, 746, 411, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 129, "seek": 85100, "start": 862.0, "end": 867.0, "text": " And that it has the properties or that it has the same basic shape as an event.", "tokens": [50914, 400, 300, 309, 575, 264, 7221, 420, 300, 309, 575, 264, 912, 3875, 3909, 382, 364, 2280, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 130, "seek": 85100, "start": 867.0, "end": 873.0, "text": " Although, I mean, defining identification as an event, I'm not saying it isn't.", "tokens": [51164, 5780, 11, 286, 914, 11, 17827, 22065, 382, 364, 2280, 11, 286, 478, 406, 1566, 309, 1943, 380, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 131, "seek": 85100, "start": 873.0, "end": 874.0, "text": " I'm not saying.", "tokens": [51464, 286, 478, 406, 1566, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 132, "seek": 85100, "start": 874.0, "end": 875.0, "text": " No, I don't care how it's done.", "tokens": [51514, 883, 11, 286, 500, 380, 1127, 577, 309, 311, 1096, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 133, "seek": 85100, "start": 875.0, "end": 877.0, "text": " I just want to see the result.", "tokens": [51564, 286, 445, 528, 281, 536, 264, 1874, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15741526285807292, "compression_ratio": 1.7593360995850622, "no_speech_prob": 0.006554487161338329}, {"id": 134, "seek": 87700, "start": 877.0, "end": 881.0, "text": " But I'm just saying that if you want to avoid, that could also be confusing.", "tokens": [50364, 583, 286, 478, 445, 1566, 300, 498, 291, 528, 281, 5042, 11, 300, 727, 611, 312, 13181, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 135, "seek": 87700, "start": 881.0, "end": 885.0, "text": " If the goal is to avoid confusion, people have an idea of what identification is.", "tokens": [50564, 759, 264, 3387, 307, 281, 5042, 15075, 11, 561, 362, 364, 1558, 295, 437, 22065, 307, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 136, "seek": 87700, "start": 885.0, "end": 887.0, "text": " Is it an event?", "tokens": [50764, 1119, 309, 364, 2280, 30, 50864], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 137, "seek": 87700, "start": 887.0, "end": 888.0, "text": " So I don't know.", "tokens": [50864, 407, 286, 500, 380, 458, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 138, "seek": 87700, "start": 888.0, "end": 890.0, "text": " I'm just saying you need definitions.", "tokens": [50914, 286, 478, 445, 1566, 291, 643, 21988, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 139, "seek": 87700, "start": 890.0, "end": 897.0, "text": " And there is a way of doing definitions within the semantic web, which is well understood and which will give you all kinds of benefits.", "tokens": [51014, 400, 456, 307, 257, 636, 295, 884, 21988, 1951, 264, 47982, 3670, 11, 597, 307, 731, 7320, 293, 597, 486, 976, 291, 439, 3685, 295, 5311, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 140, "seek": 87700, "start": 897.0, "end": 905.0, "text": " But just let me let me repeat what John and I discussed yesterday.", "tokens": [51364, 583, 445, 718, 385, 718, 385, 7149, 437, 2619, 293, 286, 7152, 5186, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09329398043520816, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.009340005926787853}, {"id": 141, "seek": 90500, "start": 905.0, "end": 908.0, "text": " You have Darwin Core.", "tokens": [50364, 509, 362, 30233, 14798, 13, 50514], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 142, "seek": 90500, "start": 908.0, "end": 909.0, "text": " It's full of terms.", "tokens": [50514, 467, 311, 1577, 295, 2115, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 143, "seek": 90500, "start": 909.0, "end": 911.0, "text": " It's full of quasi-definition.", "tokens": [50564, 467, 311, 1577, 295, 20954, 12, 1479, 5194, 849, 13, 50664], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 144, "seek": 90500, "start": 911.0, "end": 925.0, "text": " Go through Darwin Core as it is and try and define every single term using our, which is the standard that we're more or less forced to use for doing this currently.", "tokens": [50664, 1037, 807, 30233, 14798, 382, 309, 307, 293, 853, 293, 6964, 633, 2167, 1433, 1228, 527, 11, 597, 307, 264, 3832, 300, 321, 434, 544, 420, 1570, 7579, 281, 764, 337, 884, 341, 4362, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 145, "seek": 90500, "start": 925.0, "end": 927.0, "text": " Sometimes it will be easy.", "tokens": [51364, 4803, 309, 486, 312, 1858, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 146, "seek": 90500, "start": 927.0, "end": 928.0, "text": " A comment.", "tokens": [51464, 316, 2871, 13, 51514], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 147, "seek": 90500, "start": 928.0, "end": 929.0, "text": " Yeah?", "tokens": [51514, 865, 30, 51564], "temperature": 0.0, "avg_logprob": -0.16288325298263365, "compression_ratio": 1.5, "no_speech_prob": 0.05005832761526108}, {"id": 148, "seek": 92900, "start": 930.0, "end": 945.0, "text": " I think one of the way we looked at things like identification, occurrence, and event, in some sense, there are nodes that connect different things.", "tokens": [50414, 286, 519, 472, 295, 264, 636, 321, 2956, 412, 721, 411, 22065, 11, 36122, 11, 293, 2280, 11, 294, 512, 2020, 11, 456, 366, 13891, 300, 1745, 819, 721, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15230401895814022, "compression_ratio": 1.603896103896104, "no_speech_prob": 0.036123126745224}, {"id": 149, "seek": 92900, "start": 945.0, "end": 955.0, "text": " So, you know, identification is the thing that connects an organism to a taxon or a taxon concept.", "tokens": [51164, 407, 11, 291, 458, 11, 22065, 307, 264, 551, 300, 16967, 364, 24128, 281, 257, 3366, 266, 420, 257, 3366, 266, 3410, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15230401895814022, "compression_ratio": 1.603896103896104, "no_speech_prob": 0.036123126745224}, {"id": 150, "seek": 95500, "start": 955.0, "end": 974.0, "text": " And so I think that was one of the reasons why when we got hung up on trying to define what these different things meant, that really we were essentially talking about joins between other categories of things.", "tokens": [50364, 400, 370, 286, 519, 300, 390, 472, 295, 264, 4112, 983, 562, 321, 658, 5753, 493, 322, 1382, 281, 6964, 437, 613, 819, 721, 4140, 11, 300, 534, 321, 645, 4476, 1417, 466, 24397, 1296, 661, 10479, 295, 721, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10382254340431907, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0013219867832958698}, {"id": 151, "seek": 95500, "start": 974.0, "end": 979.0, "text": " So that is one way of doing definitions.", "tokens": [51314, 407, 300, 307, 472, 636, 295, 884, 21988, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10382254340431907, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0013219867832958698}, {"id": 152, "seek": 97900, "start": 979.0, "end": 983.0, "text": " When you do it, then we will see whether the definition is intelligible.", "tokens": [50364, 1133, 291, 360, 309, 11, 550, 321, 486, 536, 1968, 264, 7123, 307, 5613, 964, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06742907131419462, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.20250137150287628}, {"id": 153, "seek": 97900, "start": 983.0, "end": 990.0, "text": " But the result has to help people to understand what particular data expressed in a certain way means.", "tokens": [50564, 583, 264, 1874, 575, 281, 854, 561, 281, 1223, 437, 1729, 1412, 12675, 294, 257, 1629, 636, 1355, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06742907131419462, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.20250137150287628}, {"id": 154, "seek": 97900, "start": 990.0, "end": 996.0, "text": " And it has to help people understand how to annotate their own data in the same way.", "tokens": [50914, 400, 309, 575, 281, 854, 561, 1223, 577, 281, 25339, 473, 641, 1065, 1412, 294, 264, 912, 636, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06742907131419462, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.20250137150287628}, {"id": 155, "seek": 97900, "start": 996.0, "end": 1003.0, "text": " And it seems that within this community, there are indeed people who know exactly what you just said means.", "tokens": [51214, 400, 309, 2544, 300, 1951, 341, 1768, 11, 456, 366, 6451, 561, 567, 458, 2293, 437, 291, 445, 848, 1355, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06742907131419462, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.20250137150287628}, {"id": 156, "seek": 100300, "start": 1003.0, "end": 1005.0, "text": " I don't know what it means.", "tokens": [50364, 286, 500, 380, 458, 437, 309, 1355, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13609822591145834, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.08213668316602707}, {"id": 157, "seek": 100300, "start": 1005.0, "end": 1012.0, "text": " And I can see all kinds of objections that other people might have based on what you've said.", "tokens": [50464, 400, 286, 393, 536, 439, 3685, 295, 44649, 300, 661, 561, 1062, 362, 2361, 322, 437, 291, 600, 848, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13609822591145834, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.08213668316602707}, {"id": 158, "seek": 100300, "start": 1012.0, "end": 1024.0, "text": " But Barry, I mean, sometimes the semantics that can be expressed in English, I mean, do you say that the full semantics that would express natural language should be expressed in owl?", "tokens": [50814, 583, 21639, 11, 286, 914, 11, 2171, 264, 4361, 45298, 300, 393, 312, 12675, 294, 3669, 11, 286, 914, 11, 360, 291, 584, 300, 264, 1577, 4361, 45298, 300, 576, 5109, 3303, 2856, 820, 312, 12675, 294, 34488, 30, 51414], "temperature": 0.0, "avg_logprob": -0.13609822591145834, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.08213668316602707}, {"id": 159, "seek": 102400, "start": 1024.0, "end": 1027.0, "text": " What I say is there should be an experiment.", "tokens": [50364, 708, 286, 584, 307, 456, 820, 312, 364, 5120, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13698958201580738, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.8538566827774048}, {"id": 160, "seek": 102400, "start": 1027.0, "end": 1036.0, "text": " Take the Darwin quote, try and define all the terms using owl, because that's the standard that we're forced to use today.", "tokens": [50514, 3664, 264, 30233, 6513, 11, 853, 293, 6964, 439, 264, 2115, 1228, 34488, 11, 570, 300, 311, 264, 3832, 300, 321, 434, 7579, 281, 764, 965, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13698958201580738, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.8538566827774048}, {"id": 161, "seek": 102400, "start": 1036.0, "end": 1038.0, "text": " And see what you get.", "tokens": [50964, 400, 536, 437, 291, 483, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13698958201580738, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.8538566827774048}, {"id": 162, "seek": 102400, "start": 1038.0, "end": 1040.0, "text": " You will learn all kinds of things.", "tokens": [51064, 509, 486, 1466, 439, 3685, 295, 721, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13698958201580738, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.8538566827774048}, {"id": 163, "seek": 102400, "start": 1040.0, "end": 1046.0, "text": " You will learn that you don't know whether identification is an event or not an event, maybe.", "tokens": [51164, 509, 486, 1466, 300, 291, 500, 380, 458, 1968, 22065, 307, 364, 2280, 420, 406, 364, 2280, 11, 1310, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13698958201580738, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.8538566827774048}, {"id": 164, "seek": 104600, "start": 1046.0, "end": 1056.0, "text": " I know that the word token is used in a funny way, because some things which meet the definition of token are not listed on the token within the structure that you have now.", "tokens": [50364, 286, 458, 300, 264, 1349, 14862, 307, 1143, 294, 257, 4074, 636, 11, 570, 512, 721, 597, 1677, 264, 7123, 295, 14862, 366, 406, 10052, 322, 264, 14862, 1951, 264, 3877, 300, 291, 362, 586, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11196102216405776, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.667212188243866}, {"id": 165, "seek": 104600, "start": 1056.0, "end": 1067.0, "text": " And then the ontology that will be generated automatically from that set of definitions, when you run it through the reasoner, will give you a list of categorization errors.", "tokens": [50864, 400, 550, 264, 6592, 1793, 300, 486, 312, 10833, 6772, 490, 300, 992, 295, 21988, 11, 562, 291, 1190, 309, 807, 264, 1778, 260, 11, 486, 976, 291, 257, 1329, 295, 19250, 2144, 13603, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11196102216405776, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.667212188243866}, {"id": 166, "seek": 104600, "start": 1067.0, "end": 1068.0, "text": " I'm assuming.", "tokens": [51414, 286, 478, 11926, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11196102216405776, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.667212188243866}, {"id": 167, "seek": 104600, "start": 1068.0, "end": 1069.0, "text": " So this is an experiment.", "tokens": [51464, 407, 341, 307, 364, 5120, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11196102216405776, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.667212188243866}, {"id": 168, "seek": 104600, "start": 1069.0, "end": 1071.0, "text": " I have no idea how it will turn out.", "tokens": [51514, 286, 362, 572, 1558, 577, 309, 486, 1261, 484, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11196102216405776, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.667212188243866}, {"id": 169, "seek": 107100, "start": 1071.0, "end": 1080.0, "text": " Once you get that list, you can change some of the definitions and you can consult with your colleagues to find better definitions.", "tokens": [50364, 3443, 291, 483, 300, 1329, 11, 291, 393, 1319, 512, 295, 264, 21988, 293, 291, 393, 7189, 365, 428, 7734, 281, 915, 1101, 21988, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 170, "seek": 107100, "start": 1080.0, "end": 1085.0, "text": " And the result will be something which will be a step forward.", "tokens": [50814, 400, 264, 1874, 486, 312, 746, 597, 486, 312, 257, 1823, 2128, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 171, "seek": 107100, "start": 1085.0, "end": 1089.0, "text": " Maybe it won't replace the Darwin quote, but it will be a step forward and understand it.", "tokens": [51064, 2704, 309, 1582, 380, 7406, 264, 30233, 6513, 11, 457, 309, 486, 312, 257, 1823, 2128, 293, 1223, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 172, "seek": 107100, "start": 1089.0, "end": 1090.0, "text": " Right.", "tokens": [51264, 1779, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 173, "seek": 107100, "start": 1090.0, "end": 1092.0, "text": " So I mean, those experiments have been done.", "tokens": [51314, 407, 286, 914, 11, 729, 12050, 362, 668, 1096, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 174, "seek": 107100, "start": 1092.0, "end": 1097.0, "text": " They're being done, you know, as we speak.", "tokens": [51414, 814, 434, 885, 1096, 11, 291, 458, 11, 382, 321, 1710, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08718976378440857, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.008596131578087807}, {"id": 175, "seek": 109700, "start": 1097.0, "end": 1102.0, "text": " And it's not clear to me that it will result in a step forward.", "tokens": [50364, 400, 309, 311, 406, 1850, 281, 385, 300, 309, 486, 1874, 294, 257, 1823, 2128, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07671983469100226, "compression_ratio": 1.6683417085427135, "no_speech_prob": 0.0016995283076539636}, {"id": 176, "seek": 109700, "start": 1102.0, "end": 1112.0, "text": " And for example, if you get a categorization error, we don't need to classify.", "tokens": [50614, 400, 337, 1365, 11, 498, 291, 483, 257, 19250, 2144, 6713, 11, 321, 500, 380, 643, 281, 33872, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07671983469100226, "compression_ratio": 1.6683417085427135, "no_speech_prob": 0.0016995283076539636}, {"id": 177, "seek": 109700, "start": 1112.0, "end": 1126.0, "text": " I mean, in a lot of ontology applications, the goal is to classify the ontology to get a complete listing of the type hierarchy, of the class hierarchy, and also an instance categorization.", "tokens": [51114, 286, 914, 11, 294, 257, 688, 295, 6592, 1793, 5821, 11, 264, 3387, 307, 281, 33872, 264, 6592, 1793, 281, 483, 257, 3566, 22161, 295, 264, 2010, 22333, 11, 295, 264, 1508, 22333, 11, 293, 611, 364, 5197, 19250, 2144, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07671983469100226, "compression_ratio": 1.6683417085427135, "no_speech_prob": 0.0016995283076539636}, {"id": 178, "seek": 112600, "start": 1126.0, "end": 1132.0, "text": " But the artifacts of biodiversity informatics are typed.", "tokens": [50364, 583, 264, 24617, 295, 36453, 1356, 30292, 366, 33941, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 179, "seek": 112600, "start": 1132.0, "end": 1134.0, "text": " They come typed.", "tokens": [50664, 814, 808, 33941, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 180, "seek": 112600, "start": 1134.0, "end": 1146.0, "text": " I mean, we don't need to, you know, run some record into a machine and know whether or not that's an identification.", "tokens": [50764, 286, 914, 11, 321, 500, 380, 643, 281, 11, 291, 458, 11, 1190, 512, 2136, 666, 257, 3479, 293, 458, 1968, 420, 406, 300, 311, 364, 22065, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 181, "seek": 112600, "start": 1146.0, "end": 1148.0, "text": " I mean, it will tell us it's an identification.", "tokens": [51364, 286, 914, 11, 309, 486, 980, 505, 309, 311, 364, 22065, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 182, "seek": 112600, "start": 1148.0, "end": 1152.0, "text": " If something's a picture, if something's a digital still image, we'll know that it's a digital still image.", "tokens": [51464, 759, 746, 311, 257, 3036, 11, 498, 746, 311, 257, 4562, 920, 3256, 11, 321, 603, 458, 300, 309, 311, 257, 4562, 920, 3256, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 183, "seek": 112600, "start": 1152.0, "end": 1154.0, "text": " I truly think that you do need to do this.", "tokens": [51664, 286, 4908, 519, 300, 291, 360, 643, 281, 360, 341, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09356633516458365, "compression_ratio": 1.792626728110599, "no_speech_prob": 0.010805214755237103}, {"id": 184, "seek": 115400, "start": 1154.0, "end": 1158.0, "text": " It's a basic quality assurance step.", "tokens": [50364, 467, 311, 257, 3875, 3125, 32189, 1823, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17929049713970863, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.041632913053035736}, {"id": 185, "seek": 115400, "start": 1158.0, "end": 1165.0, "text": " And anyone who's working with this magic web would assume that that would be the basic step that everyone does.", "tokens": [50564, 400, 2878, 567, 311, 1364, 365, 341, 5585, 3670, 576, 6552, 300, 300, 576, 312, 264, 3875, 1823, 300, 1518, 775, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17929049713970863, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.041632913053035736}, {"id": 186, "seek": 115400, "start": 1165.0, "end": 1170.0, "text": " Well, that's, I mean, the fact that you don't want to do it is strange.", "tokens": [50914, 1042, 11, 300, 311, 11, 286, 914, 11, 264, 1186, 300, 291, 500, 380, 528, 281, 360, 309, 307, 5861, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17929049713970863, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.041632913053035736}, {"id": 187, "seek": 115400, "start": 1170.0, "end": 1175.0, "text": " It's like not wanting to use a spellchecker.", "tokens": [51164, 467, 311, 411, 406, 7935, 281, 764, 257, 9827, 1876, 9178, 13, 51414], "temperature": 0.0, "avg_logprob": -0.17929049713970863, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.041632913053035736}, {"id": 188, "seek": 117500, "start": 1175.0, "end": 1184.0, "text": " Well, I mean, not every class, if you want to say, I mean, a class is defined simply by introducing it as a class.", "tokens": [50364, 1042, 11, 286, 914, 11, 406, 633, 1508, 11, 498, 291, 528, 281, 584, 11, 286, 914, 11, 257, 1508, 307, 7642, 2935, 538, 15424, 309, 382, 257, 1508, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 189, "seek": 117500, "start": 1184.0, "end": 1185.0, "text": " You need to define it.", "tokens": [50814, 509, 643, 281, 6964, 309, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 190, "seek": 117500, "start": 1185.0, "end": 1187.0, "text": " It inherits from our class.", "tokens": [50864, 467, 9484, 1208, 490, 527, 1508, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 191, "seek": 117500, "start": 1187.0, "end": 1189.0, "text": " And there, it's defined.", "tokens": [50964, 400, 456, 11, 309, 311, 7642, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 192, "seek": 117500, "start": 1189.0, "end": 1193.0, "text": " And now, as human beings, we attach some meaning to it.", "tokens": [51064, 400, 586, 11, 382, 1952, 8958, 11, 321, 5085, 512, 3620, 281, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 193, "seek": 117500, "start": 1193.0, "end": 1199.0, "text": " And so we write our application code to understand that term according to our understanding of it.", "tokens": [51264, 400, 370, 321, 2464, 527, 3861, 3089, 281, 1223, 300, 1433, 4650, 281, 527, 3701, 295, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11938704053560893, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03256557509303093}, {"id": 194, "seek": 119900, "start": 1199.0, "end": 1208.0, "text": " And yes, there's a vision of the semantic web in which, you know, we don't have to write the code because we'll have general purpose processors", "tokens": [50364, 400, 2086, 11, 456, 311, 257, 5201, 295, 264, 47982, 3670, 294, 597, 11, 291, 458, 11, 321, 500, 380, 362, 281, 2464, 264, 3089, 570, 321, 603, 362, 2674, 4334, 27751, 50814], "temperature": 0.0, "avg_logprob": -0.08036077453429441, "compression_ratio": 1.6243902439024391, "no_speech_prob": 0.031045353040099144}, {"id": 195, "seek": 119900, "start": 1208.0, "end": 1215.0, "text": " that can look at the machine definition and understand how to process it.", "tokens": [50814, 300, 393, 574, 412, 264, 3479, 7123, 293, 1223, 577, 281, 1399, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08036077453429441, "compression_ratio": 1.6243902439024391, "no_speech_prob": 0.031045353040099144}, {"id": 196, "seek": 119900, "start": 1215.0, "end": 1223.0, "text": " I'm not saying that that won't happen, but it doesn't have to happen to get a lot of value out of the semantic web.", "tokens": [51164, 286, 478, 406, 1566, 300, 300, 1582, 380, 1051, 11, 457, 309, 1177, 380, 362, 281, 1051, 281, 483, 257, 688, 295, 2158, 484, 295, 264, 47982, 3670, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08036077453429441, "compression_ratio": 1.6243902439024391, "no_speech_prob": 0.031045353040099144}, {"id": 197, "seek": 122300, "start": 1223.0, "end": 1226.0, "text": " Let me, let me just say one more thing.", "tokens": [50364, 961, 385, 11, 718, 385, 445, 584, 472, 544, 551, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1286206752695936, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.17510472238063812}, {"id": 198, "seek": 122300, "start": 1226.0, "end": 1235.0, "text": " So the gene ontology used to be a very clunky back of the envelope word list, just a very, very minimal structure.", "tokens": [50514, 407, 264, 12186, 6592, 1793, 1143, 281, 312, 257, 588, 596, 25837, 646, 295, 264, 19989, 1349, 1329, 11, 445, 257, 588, 11, 588, 13206, 3877, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1286206752695936, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.17510472238063812}, {"id": 199, "seek": 122300, "start": 1235.0, "end": 1243.0, "text": " After a few years, people have the idea to try and produce logically coherent definitions of the gene ontology terms.", "tokens": [50964, 2381, 257, 1326, 924, 11, 561, 362, 264, 1558, 281, 853, 293, 5258, 38887, 36239, 21988, 295, 264, 12186, 6592, 1793, 2115, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1286206752695936, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.17510472238063812}, {"id": 200, "seek": 122300, "start": 1243.0, "end": 1247.0, "text": " Immediately, immediately, they started that with just a few definitions.", "tokens": [51364, 34457, 11, 4258, 11, 436, 1409, 300, 365, 445, 257, 1326, 21988, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1286206752695936, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.17510472238063812}, {"id": 201, "seek": 122300, "start": 1247.0, "end": 1250.0, "text": " They discovered errors, they discovered gaps.", "tokens": [51564, 814, 6941, 13603, 11, 436, 6941, 15031, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1286206752695936, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.17510472238063812}, {"id": 202, "seek": 125000, "start": 1250.0, "end": 1255.0, "text": " And when they actually finished with all the definitions, they discovered all kinds of interesting things about the ontology,", "tokens": [50364, 400, 562, 436, 767, 4335, 365, 439, 264, 21988, 11, 436, 6941, 439, 3685, 295, 1880, 721, 466, 264, 6592, 1793, 11, 50614], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 203, "seek": 125000, "start": 1255.0, "end": 1259.0, "text": " which helped the ontology from a biological point of view.", "tokens": [50614, 597, 4254, 264, 6592, 1793, 490, 257, 13910, 935, 295, 1910, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 204, "seek": 125000, "start": 1259.0, "end": 1261.0, "text": " It became better in every respect.", "tokens": [50814, 467, 3062, 1101, 294, 633, 3104, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 205, "seek": 125000, "start": 1261.0, "end": 1264.0, "text": " Now, you should want to do that.", "tokens": [50914, 823, 11, 291, 820, 528, 281, 360, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 206, "seek": 125000, "start": 1264.0, "end": 1266.0, "text": " It's a healthy desire.", "tokens": [51064, 467, 311, 257, 4627, 7516, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 207, "seek": 125000, "start": 1266.0, "end": 1270.0, "text": " It's a sign of a clean living individual.", "tokens": [51164, 467, 311, 257, 1465, 295, 257, 2541, 2647, 2609, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 208, "seek": 125000, "start": 1270.0, "end": 1274.0, "text": " The fact that you don't want to do it is strange.", "tokens": [51364, 440, 1186, 300, 291, 500, 380, 528, 281, 360, 309, 307, 5861, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07432878393875925, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0020451582968235016}, {"id": 209, "seek": 127400, "start": 1274.0, "end": 1280.0, "text": " I mean, I think a rule of ontologies should be no naked terms.", "tokens": [50364, 286, 914, 11, 286, 519, 257, 4978, 295, 6592, 6204, 820, 312, 572, 15791, 2115, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 210, "seek": 127400, "start": 1280.0, "end": 1283.0, "text": " Except highly general primitives.", "tokens": [50664, 16192, 5405, 2674, 2886, 38970, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 211, "seek": 127400, "start": 1283.0, "end": 1285.0, "text": " Because you can't define everything.", "tokens": [50814, 1436, 291, 393, 380, 6964, 1203, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 212, "seek": 127400, "start": 1285.0, "end": 1287.0, "text": " You can't define everything like the W3 specs or in some sort of a form.", "tokens": [50914, 509, 393, 380, 6964, 1203, 411, 264, 343, 18, 27911, 420, 294, 512, 1333, 295, 257, 1254, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 213, "seek": 127400, "start": 1287.0, "end": 1289.0, "text": " Yeah, but you can't define everything.", "tokens": [51014, 865, 11, 457, 291, 393, 380, 6964, 1203, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 214, "seek": 127400, "start": 1289.0, "end": 1291.0, "text": " Otherwise, you would have an infinite change.", "tokens": [51114, 10328, 11, 291, 576, 362, 364, 13785, 1319, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 215, "seek": 127400, "start": 1291.0, "end": 1293.0, "text": " You have to use some words without that.", "tokens": [51214, 509, 362, 281, 764, 512, 2283, 1553, 300, 13, 51314], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 216, "seek": 127400, "start": 1293.0, "end": 1295.0, "text": " It becomes problematic.", "tokens": [51314, 467, 3643, 19011, 13, 51414], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 217, "seek": 127400, "start": 1295.0, "end": 1299.0, "text": " But, you know, at the level that we're talking about in Darwin Park, we completely agree with Barry.", "tokens": [51414, 583, 11, 291, 458, 11, 412, 264, 1496, 300, 321, 434, 1417, 466, 294, 30233, 4964, 11, 321, 2584, 3986, 365, 21639, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 218, "seek": 127400, "start": 1299.0, "end": 1303.0, "text": " Minimally, we should have a natural language definition and ideally something a bit more formal.", "tokens": [51614, 2829, 332, 379, 11, 321, 820, 362, 257, 3303, 2856, 7123, 293, 22915, 746, 257, 857, 544, 9860, 13, 51814], "temperature": 0.0, "avg_logprob": -0.19928668922101947, "compression_ratio": 1.747634069400631, "no_speech_prob": 0.07445332407951355}, {"id": 219, "seek": 130300, "start": 1303.0, "end": 1306.0, "text": " Well, I certainly agree we should have a natural language definition.", "tokens": [50364, 1042, 11, 286, 3297, 3986, 321, 820, 362, 257, 3303, 2856, 7123, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11614931783368511, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0016216823132708669}, {"id": 220, "seek": 130300, "start": 1306.0, "end": 1316.0, "text": " But I think a legitimate vision for the semantic web is that the ontologies serve as dictionaries for human users,", "tokens": [50514, 583, 286, 519, 257, 17956, 5201, 337, 264, 47982, 3670, 307, 300, 264, 6592, 6204, 4596, 382, 22352, 4889, 337, 1952, 5022, 11, 51014], "temperature": 0.0, "avg_logprob": -0.11614931783368511, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0016216823132708669}, {"id": 221, "seek": 130300, "start": 1316.0, "end": 1321.0, "text": " that you have the namespace, and you say, if we're talking about a Darwin core identification,", "tokens": [51014, 300, 291, 362, 264, 5288, 17940, 11, 293, 291, 584, 11, 498, 321, 434, 1417, 466, 257, 30233, 4965, 22065, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11614931783368511, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0016216823132708669}, {"id": 222, "seek": 130300, "start": 1321.0, "end": 1324.0, "text": " everybody can look and say, oh, that's what a Darwin core identification is.", "tokens": [51264, 2201, 393, 574, 293, 584, 11, 1954, 11, 300, 311, 437, 257, 30233, 4965, 22065, 307, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11614931783368511, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0016216823132708669}, {"id": 223, "seek": 130300, "start": 1324.0, "end": 1327.0, "text": " Anybody that can understand natural language.", "tokens": [51414, 19082, 300, 393, 1223, 3303, 2856, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11614931783368511, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0016216823132708669}, {"id": 224, "seek": 132700, "start": 1327.0, "end": 1334.0, "text": " And then only write code that uses Darwin core colon identification in that way.", "tokens": [50364, 400, 550, 787, 2464, 3089, 300, 4960, 30233, 4965, 8255, 22065, 294, 300, 636, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09613545451845441, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.13457953929901123}, {"id": 225, "seek": 132700, "start": 1334.0, "end": 1339.0, "text": " And that, I think, is already a big step forward because you have a canonical place where people look and say,", "tokens": [50714, 400, 300, 11, 286, 519, 11, 307, 1217, 257, 955, 1823, 2128, 570, 291, 362, 257, 46491, 1081, 689, 561, 574, 293, 584, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09613545451845441, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.13457953929901123}, {"id": 226, "seek": 132700, "start": 1339.0, "end": 1342.0, "text": " if you're using a DWC identification, you have to use it in this way.", "tokens": [50964, 498, 291, 434, 1228, 257, 45318, 34, 22065, 11, 291, 362, 281, 764, 309, 294, 341, 636, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09613545451845441, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.13457953929901123}, {"id": 227, "seek": 132700, "start": 1342.0, "end": 1348.0, "text": " So, if you want to say that there shouldn't be naked terms, I can't know.", "tokens": [51114, 407, 11, 498, 291, 528, 281, 584, 300, 456, 4659, 380, 312, 15791, 2115, 11, 286, 393, 380, 458, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09613545451845441, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.13457953929901123}, {"id": 228, "seek": 132700, "start": 1348.0, "end": 1352.0, "text": " I don't know what there should and shouldn't be, but I know that there is value from naked terms.", "tokens": [51414, 286, 500, 380, 458, 437, 456, 820, 293, 4659, 380, 312, 11, 457, 286, 458, 300, 456, 307, 2158, 490, 15791, 2115, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09613545451845441, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.13457953929901123}, {"id": 229, "seek": 135200, "start": 1353.0, "end": 1356.0, "text": " Because 90% of the value of the semantic web comes from the namespace.", "tokens": [50414, 1436, 4289, 4, 295, 264, 2158, 295, 264, 47982, 3670, 1487, 490, 264, 5288, 17940, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 230, "seek": 135200, "start": 1356.0, "end": 1358.0, "text": " It comes from the disambiguation.", "tokens": [50564, 467, 1487, 490, 264, 717, 2173, 328, 16073, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 231, "seek": 135200, "start": 1358.0, "end": 1364.0, "text": " For any naked term you put up there, unless you want it to be completely unconstrained,", "tokens": [50664, 1171, 604, 15791, 1433, 291, 829, 493, 456, 11, 5969, 291, 528, 309, 281, 312, 2584, 35847, 19639, 2001, 11, 50964], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 232, "seek": 135200, "start": 1364.0, "end": 1370.0, "text": " run a little bit of a few hints about usage or formal definitions.", "tokens": [50964, 1190, 257, 707, 857, 295, 257, 1326, 27271, 466, 14924, 420, 9860, 21988, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 233, "seek": 135200, "start": 1370.0, "end": 1374.0, "text": " I think it can do nothing but help as long as it doesn't over constrain.", "tokens": [51264, 286, 519, 309, 393, 360, 1825, 457, 854, 382, 938, 382, 309, 1177, 380, 670, 1817, 7146, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 234, "seek": 135200, "start": 1374.0, "end": 1376.0, "text": " But you can try to constrain it as much as you want.", "tokens": [51464, 583, 291, 393, 853, 281, 1817, 7146, 309, 382, 709, 382, 291, 528, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 235, "seek": 135200, "start": 1376.0, "end": 1380.0, "text": " But those hints can be in English. They don't have to be in Al.", "tokens": [51564, 583, 729, 27271, 393, 312, 294, 3669, 13, 814, 500, 380, 362, 281, 312, 294, 967, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13004399884131648, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.14564917981624603}, {"id": 236, "seek": 138000, "start": 1381.0, "end": 1385.0, "text": " What's the danger of that? What do you lose by having them in Al?", "tokens": [50414, 708, 311, 264, 4330, 295, 300, 30, 708, 360, 291, 3624, 538, 1419, 552, 294, 967, 30, 50614], "temperature": 0.0, "avg_logprob": -0.17522940317789715, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.004463579040020704}, {"id": 237, "seek": 138000, "start": 1385.0, "end": 1387.0, "text": " I don't get what the resistance is to it.", "tokens": [50614, 286, 500, 380, 483, 437, 264, 7335, 307, 281, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.17522940317789715, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.004463579040020704}, {"id": 238, "seek": 138000, "start": 1387.0, "end": 1390.0, "text": " Because it's a lot harder to figure out how to model them in Al.", "tokens": [50714, 1436, 309, 311, 257, 688, 6081, 281, 2573, 484, 577, 281, 2316, 552, 294, 967, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17522940317789715, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.004463579040020704}, {"id": 239, "seek": 138000, "start": 1390.0, "end": 1398.0, "text": " Well, because it's a lot easier than for people to say things that they don't really mean.", "tokens": [50864, 1042, 11, 570, 309, 311, 257, 688, 3571, 813, 337, 561, 281, 584, 721, 300, 436, 500, 380, 534, 914, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17522940317789715, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.004463579040020704}, {"id": 240, "seek": 139800, "start": 1398.0, "end": 1412.0, "text": " For example, the Darwin core type hierarchy used to define subclasses of events", "tokens": [50364, 1171, 1365, 11, 264, 30233, 4965, 2010, 22333, 1143, 281, 6964, 1422, 11665, 279, 295, 3931, 51064], "temperature": 0.0, "avg_logprob": -0.11851788434115323, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.023618541657924652}, {"id": 241, "seek": 139800, "start": 1412.0, "end": 1419.0, "text": " and subclasses of collection events, subclasses of specimens.", "tokens": [51064, 293, 1422, 11665, 279, 295, 5765, 3931, 11, 1422, 11665, 279, 295, 41007, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11851788434115323, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.023618541657924652}, {"id": 242, "seek": 139800, "start": 1419.0, "end": 1424.0, "text": " And it was pointed out, and I think it was Steve that pointed it out,", "tokens": [51414, 400, 309, 390, 10932, 484, 11, 293, 286, 519, 309, 390, 7466, 300, 10932, 309, 484, 11, 51664], "temperature": 0.0, "avg_logprob": -0.11851788434115323, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.023618541657924652}, {"id": 243, "seek": 142400, "start": 1424.0, "end": 1429.0, "text": " that the result was that a preserved specimen is an event.", "tokens": [50364, 300, 264, 1874, 390, 300, 257, 22242, 34204, 307, 364, 2280, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17901948520115443, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00033508019987493753}, {"id": 244, "seek": 142400, "start": 1429.0, "end": 1434.0, "text": " Obviously, if your Al hierarchy is wrong, it's going to cause problems.", "tokens": [50614, 7580, 11, 498, 428, 967, 22333, 307, 2085, 11, 309, 311, 516, 281, 3082, 2740, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17901948520115443, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00033508019987493753}, {"id": 245, "seek": 142400, "start": 1434.0, "end": 1443.0, "text": " For a particular point of view, from a particular point of view, that Al hierarchy was right.", "tokens": [50864, 1171, 257, 1729, 935, 295, 1910, 11, 490, 257, 1729, 935, 295, 1910, 11, 300, 967, 22333, 390, 558, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17901948520115443, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00033508019987493753}, {"id": 246, "seek": 144300, "start": 1444.0, "end": 1454.0, "text": " Another example is that one of the first descriptions of terms that people add,", "tokens": [50414, 3996, 1365, 307, 300, 472, 295, 264, 700, 24406, 295, 2115, 300, 561, 909, 11, 50914], "temperature": 0.0, "avg_logprob": -0.10287183955095816, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0015478890854865313}, {"id": 247, "seek": 144300, "start": 1454.0, "end": 1458.0, "text": " especially if they're using prot\u00e9g\u00e9 because it encourages it, is domain constraints.", "tokens": [50914, 2318, 498, 436, 434, 1228, 1742, 9095, 526, 570, 309, 28071, 309, 11, 307, 9274, 18491, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10287183955095816, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0015478890854865313}, {"id": 248, "seek": 144300, "start": 1458.0, "end": 1460.0, "text": " What does this term apply to?", "tokens": [51114, 708, 775, 341, 1433, 3079, 281, 30, 51214], "temperature": 0.0, "avg_logprob": -0.10287183955095816, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0015478890854865313}, {"id": 249, "seek": 144300, "start": 1460.0, "end": 1466.0, "text": " But, of course, those constraints don't act as integrity constraints as they do in a database.", "tokens": [51214, 583, 11, 295, 1164, 11, 729, 18491, 500, 380, 605, 382, 16000, 18491, 382, 436, 360, 294, 257, 8149, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10287183955095816, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0015478890854865313}, {"id": 250, "seek": 146600, "start": 1466.0, "end": 1472.0, "text": " They act as grist for a reasoning mill.", "tokens": [50364, 814, 605, 382, 677, 468, 337, 257, 21577, 1728, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11308772223336357, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.02258135750889778}, {"id": 251, "seek": 146600, "start": 1472.0, "end": 1479.0, "text": " And so now, if you say identification, and Steve gets to this, if we ever get to his slides,", "tokens": [50664, 400, 370, 586, 11, 498, 291, 584, 22065, 11, 293, 7466, 2170, 281, 341, 11, 498, 321, 1562, 483, 281, 702, 9788, 11, 51014], "temperature": 0.0, "avg_logprob": -0.11308772223336357, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.02258135750889778}, {"id": 252, "seek": 146600, "start": 1479.0, "end": 1484.0, "text": " we'll see that he recognizes this as one of the potential criticism,", "tokens": [51014, 321, 603, 536, 300, 415, 26564, 341, 382, 472, 295, 264, 3995, 15835, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11308772223336357, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.02258135750889778}, {"id": 253, "seek": 146600, "start": 1484.0, "end": 1488.0, "text": " one of the criticisms of his current representation,", "tokens": [51264, 472, 295, 264, 48519, 295, 702, 2190, 10290, 11, 51464], "temperature": 0.0, "avg_logprob": -0.11308772223336357, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.02258135750889778}, {"id": 254, "seek": 146600, "start": 1488.0, "end": 1493.0, "text": " is that by having this highly normalized view where identification only applies to a token,", "tokens": [51464, 307, 300, 538, 1419, 341, 5405, 48704, 1910, 689, 22065, 787, 13165, 281, 257, 14862, 11, 51714], "temperature": 0.0, "avg_logprob": -0.11308772223336357, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.02258135750889778}, {"id": 255, "seek": 149300, "start": 1493.0, "end": 1498.0, "text": " if somebody identifies an image using the term identification,", "tokens": [50364, 498, 2618, 34597, 364, 3256, 1228, 264, 1433, 22065, 11, 50614], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 256, "seek": 149300, "start": 1498.0, "end": 1502.0, "text": " then that reasoner will assume that, well, okay, an image is a token.", "tokens": [50614, 550, 300, 1778, 260, 486, 6552, 300, 11, 731, 11, 1392, 11, 364, 3256, 307, 257, 14862, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 257, "seek": 149300, "start": 1502.0, "end": 1510.0, "text": " If somebody identifies, well, what if somebody identifies an occurrence,", "tokens": [50814, 759, 2618, 34597, 11, 731, 11, 437, 498, 2618, 34597, 364, 36122, 11, 51214], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 258, "seek": 149300, "start": 1510.0, "end": 1512.0, "text": " then you have to reason that the occurrence is a token.", "tokens": [51214, 550, 291, 362, 281, 1778, 300, 264, 36122, 307, 257, 14862, 13, 51314], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 259, "seek": 149300, "start": 1512.0, "end": 1514.0, "text": " If somebody tries to identify a species...", "tokens": [51314, 759, 2618, 9898, 281, 5876, 257, 6172, 485, 51414], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 260, "seek": 149300, "start": 1514.0, "end": 1517.0, "text": " If they identify wrong, they're not using the definition of...", "tokens": [51414, 759, 436, 5876, 2085, 11, 436, 434, 406, 1228, 264, 7123, 295, 485, 51564], "temperature": 0.0, "avg_logprob": -0.14944292198527942, "compression_ratio": 2.0164835164835164, "no_speech_prob": 0.006485885940492153}, {"id": 261, "seek": 151700, "start": 1517.0, "end": 1524.0, "text": " This is exactly my point, is that the more complicated the ontology it is,", "tokens": [50364, 639, 307, 2293, 452, 935, 11, 307, 300, 264, 544, 6179, 264, 6592, 1793, 309, 307, 11, 50714], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 262, "seek": 151700, "start": 1524.0, "end": 1530.0, "text": " the easier it is to say things that have implications that you don't want to imply.", "tokens": [50714, 264, 3571, 309, 307, 281, 584, 721, 300, 362, 16602, 300, 291, 500, 380, 528, 281, 33616, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 263, "seek": 151700, "start": 1530.0, "end": 1535.0, "text": " So the idea is that you would have good language definitions to help the user,", "tokens": [51014, 407, 264, 1558, 307, 300, 291, 576, 362, 665, 2856, 21988, 281, 854, 264, 4195, 11, 51264], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 264, "seek": 151700, "start": 1535.0, "end": 1540.0, "text": " and you would have good logical definitions to do basic quality control.", "tokens": [51264, 293, 291, 576, 362, 665, 14978, 21988, 281, 360, 3875, 3125, 1969, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 265, "seek": 151700, "start": 1540.0, "end": 1542.0, "text": " Doing both of those will help the other.", "tokens": [51514, 18496, 1293, 295, 729, 486, 854, 264, 661, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 266, "seek": 151700, "start": 1542.0, "end": 1544.0, "text": " So you'll get better English definitions by doing the logic.", "tokens": [51614, 407, 291, 603, 483, 1101, 3669, 21988, 538, 884, 264, 9952, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07752232599740076, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.03232560306787491}, {"id": 267, "seek": 154400, "start": 1544.0, "end": 1547.0, "text": " You'll get better logical definitions by doing the English definitions.", "tokens": [50364, 509, 603, 483, 1101, 14978, 21988, 538, 884, 264, 3669, 21988, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 268, "seek": 154400, "start": 1547.0, "end": 1551.0, "text": " And users will have some clue as to how to use.", "tokens": [50514, 400, 5022, 486, 362, 512, 13602, 382, 281, 577, 281, 764, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 269, "seek": 154400, "start": 1551.0, "end": 1555.0, "text": " Like, if I go to the Dharma Corp. now as a naive user,", "tokens": [50714, 1743, 11, 498, 286, 352, 281, 264, 40552, 3925, 79, 13, 586, 382, 257, 29052, 4195, 11, 50914], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 270, "seek": 154400, "start": 1555.0, "end": 1558.0, "text": " I wouldn't know how to use the term because I don't know what they're supposed to mean.", "tokens": [50914, 286, 2759, 380, 458, 577, 281, 764, 264, 1433, 570, 286, 500, 380, 458, 437, 436, 434, 3442, 281, 914, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 271, "seek": 154400, "start": 1558.0, "end": 1560.0, "text": " And there's no guidance for me.", "tokens": [51064, 400, 456, 311, 572, 10056, 337, 385, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 272, "seek": 154400, "start": 1560.0, "end": 1564.0, "text": " There's no logical relationship that attacks the definitions are vague.", "tokens": [51164, 821, 311, 572, 14978, 2480, 300, 8122, 264, 21988, 366, 24247, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 273, "seek": 154400, "start": 1564.0, "end": 1566.0, "text": " So I don't know what to put where.", "tokens": [51364, 407, 286, 500, 380, 458, 437, 281, 829, 689, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 274, "seek": 154400, "start": 1566.0, "end": 1570.0, "text": " I'm even saying, like in semantic Dharma Corp.", "tokens": [51464, 286, 478, 754, 1566, 11, 411, 294, 47982, 40552, 3925, 79, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18524925044325533, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.02250843308866024}, {"id": 275, "seek": 157000, "start": 1570.0, "end": 1578.0, "text": " Saying that an occurrence is a junction of an event with an identification,", "tokens": [50364, 34087, 300, 364, 36122, 307, 257, 33718, 295, 364, 2280, 365, 364, 22065, 11, 50764], "temperature": 0.0, "avg_logprob": -0.17420377731323242, "compression_ratio": 1.7155172413793103, "no_speech_prob": 0.07196561992168427}, {"id": 276, "seek": 157000, "start": 1578.0, "end": 1582.0, "text": " I think it's helpful compared to the circular definition that exists in the current Dharma Corp.", "tokens": [50764, 286, 519, 309, 311, 4961, 5347, 281, 264, 16476, 7123, 300, 8198, 294, 264, 2190, 40552, 3925, 79, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17420377731323242, "compression_ratio": 1.7155172413793103, "no_speech_prob": 0.07196561992168427}, {"id": 277, "seek": 157000, "start": 1582.0, "end": 1586.0, "text": " Dharma Corp. standard that says an occurrence is an occurrence.", "tokens": [50964, 40552, 3925, 79, 13, 3832, 300, 1619, 364, 36122, 307, 364, 36122, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17420377731323242, "compression_ratio": 1.7155172413793103, "no_speech_prob": 0.07196561992168427}, {"id": 278, "seek": 157000, "start": 1586.0, "end": 1591.0, "text": " And I think it's a good practice to have those best practice examples.", "tokens": [51164, 400, 286, 519, 309, 311, 257, 665, 3124, 281, 362, 729, 1151, 3124, 5110, 13, 51414], "temperature": 0.0, "avg_logprob": -0.17420377731323242, "compression_ratio": 1.7155172413793103, "no_speech_prob": 0.07196561992168427}, {"id": 279, "seek": 157000, "start": 1591.0, "end": 1598.0, "text": " They established within all the Ikea world that I think nearly everywhere they are needed.", "tokens": [51414, 814, 7545, 1951, 439, 264, 286, 39153, 1002, 300, 286, 519, 6217, 5315, 436, 366, 2978, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17420377731323242, "compression_ratio": 1.7155172413793103, "no_speech_prob": 0.07196561992168427}, {"id": 280, "seek": 159800, "start": 1598.0, "end": 1605.0, "text": " You need some guidelines with good examples in there where you can find yourself again with fewer things.", "tokens": [50364, 509, 643, 512, 12470, 365, 665, 5110, 294, 456, 689, 291, 393, 915, 1803, 797, 365, 13366, 721, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 281, "seek": 159800, "start": 1605.0, "end": 1608.0, "text": " I just say one thing.", "tokens": [50714, 286, 445, 584, 472, 551, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 282, "seek": 159800, "start": 1608.0, "end": 1612.0, "text": " Buffer is designed to incorporate exactly those best practices.", "tokens": [50864, 20254, 260, 307, 4761, 281, 16091, 2293, 729, 1151, 7525, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 283, "seek": 159800, "start": 1612.0, "end": 1616.0, "text": " And if you're forced to specify whether a token is an occurrence or a continuum,", "tokens": [51064, 400, 498, 291, 434, 7579, 281, 16500, 1968, 257, 14862, 307, 364, 36122, 420, 257, 36120, 11, 51264], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 284, "seek": 159800, "start": 1616.0, "end": 1619.0, "text": " or whether an identification is an occurrence or a continuum,", "tokens": [51264, 420, 1968, 364, 22065, 307, 364, 36122, 420, 257, 36120, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 285, "seek": 159800, "start": 1619.0, "end": 1626.0, "text": " that will bring almost cost-free and immediate improvement in usability.", "tokens": [51414, 300, 486, 1565, 1920, 2063, 12, 10792, 293, 11629, 10444, 294, 46878, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1302994843367692, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.00567346066236496}, {"id": 286, "seek": 162600, "start": 1627.0, "end": 1632.0, "text": " Do you want to show the slides?", "tokens": [50414, 1144, 291, 528, 281, 855, 264, 9788, 30, 50664], "temperature": 0.0, "avg_logprob": -0.14299671216444534, "compression_ratio": 1.58, "no_speech_prob": 0.06153803691267967}, {"id": 287, "seek": 162600, "start": 1632.0, "end": 1636.0, "text": " Yeah, Steve, are you still in the mood to go through your slides?", "tokens": [50664, 865, 11, 7466, 11, 366, 291, 920, 294, 264, 9268, 281, 352, 807, 428, 9788, 30, 50864], "temperature": 0.0, "avg_logprob": -0.14299671216444534, "compression_ratio": 1.58, "no_speech_prob": 0.06153803691267967}, {"id": 288, "seek": 162600, "start": 1636.0, "end": 1640.0, "text": " Yeah, well, I don't know if you have to go through all of them,", "tokens": [50864, 865, 11, 731, 11, 286, 500, 380, 458, 498, 291, 362, 281, 352, 807, 439, 295, 552, 11, 51064], "temperature": 0.0, "avg_logprob": -0.14299671216444534, "compression_ratio": 1.58, "no_speech_prob": 0.06153803691267967}, {"id": 289, "seek": 162600, "start": 1640.0, "end": 1644.0, "text": " but could you go back one slide from the one you're on right now?", "tokens": [51064, 457, 727, 291, 352, 646, 472, 4137, 490, 264, 472, 291, 434, 322, 558, 586, 30, 51264], "temperature": 0.0, "avg_logprob": -0.14299671216444534, "compression_ratio": 1.58, "no_speech_prob": 0.06153803691267967}, {"id": 290, "seek": 162600, "start": 1644.0, "end": 1652.0, "text": " So, I mean, this is really the kind of core relationships between the different classes.", "tokens": [51264, 407, 11, 286, 914, 11, 341, 307, 534, 264, 733, 295, 4965, 6159, 1296, 264, 819, 5359, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14299671216444534, "compression_ratio": 1.58, "no_speech_prob": 0.06153803691267967}, {"id": 291, "seek": 165200, "start": 1652.0, "end": 1659.0, "text": " And, you know, the discussion was going on about, like, well, what is an identification?", "tokens": [50364, 400, 11, 291, 458, 11, 264, 5017, 390, 516, 322, 466, 11, 411, 11, 731, 11, 437, 307, 364, 22065, 30, 50714], "temperature": 0.0, "avg_logprob": -0.1223720974392361, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.022938154637813568}, {"id": 292, "seek": 165200, "start": 1659.0, "end": 1669.0, "text": " And essentially, the reason identification has to be in there is because you have many to one relationship", "tokens": [50714, 400, 4476, 11, 264, 1778, 22065, 575, 281, 312, 294, 456, 307, 570, 291, 362, 867, 281, 472, 2480, 51214], "temperature": 0.0, "avg_logprob": -0.1223720974392361, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.022938154637813568}, {"id": 293, "seek": 165200, "start": 1669.0, "end": 1672.0, "text": " between taxons and identifications.", "tokens": [51214, 1296, 3366, 892, 293, 2473, 7833, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1223720974392361, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.022938154637813568}, {"id": 294, "seek": 165200, "start": 1672.0, "end": 1678.0, "text": " There can be many identifications that relate to a particular taxon concept.", "tokens": [51364, 821, 393, 312, 867, 2473, 7833, 300, 10961, 281, 257, 1729, 3366, 266, 3410, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1223720974392361, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.022938154637813568}, {"id": 295, "seek": 167800, "start": 1678.0, "end": 1685.0, "text": " And likewise, the reason that there's a connection between identification and an organism", "tokens": [50364, 400, 32407, 11, 264, 1778, 300, 456, 311, 257, 4984, 1296, 22065, 293, 364, 24128, 50714], "temperature": 0.0, "avg_logprob": -0.0833960771560669, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.005213170312345028}, {"id": 296, "seek": 167800, "start": 1685.0, "end": 1691.0, "text": " is because you can have many identifications for a particular organism.", "tokens": [50714, 307, 570, 291, 393, 362, 867, 2473, 7833, 337, 257, 1729, 24128, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0833960771560669, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.005213170312345028}, {"id": 297, "seek": 167800, "start": 1691.0, "end": 1699.0, "text": " So essentially, each of those connections between the pink things there represent one to many relationships.", "tokens": [51014, 407, 4476, 11, 1184, 295, 729, 9271, 1296, 264, 7022, 721, 456, 2906, 472, 281, 867, 6159, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0833960771560669, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.005213170312345028}, {"id": 298, "seek": 167800, "start": 1699.0, "end": 1703.0, "text": " And that's why they were separated out as different classes.", "tokens": [51414, 400, 300, 311, 983, 436, 645, 12005, 484, 382, 819, 5359, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0833960771560669, "compression_ratio": 1.6305418719211822, "no_speech_prob": 0.005213170312345028}, {"id": 299, "seek": 170300, "start": 1703.0, "end": 1713.0, "text": " So, I don't, you know, I didn't get terribly hung up on what the exact definition was of event or occurrence,", "tokens": [50364, 407, 11, 286, 500, 380, 11, 291, 458, 11, 286, 994, 380, 483, 22903, 5753, 493, 322, 437, 264, 1900, 7123, 390, 295, 2280, 420, 36122, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09218523395595266, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.016138624399900436}, {"id": 300, "seek": 170300, "start": 1713.0, "end": 1721.0, "text": " but just simply saying that there are connections between things where you have one to many relationships.", "tokens": [50864, 457, 445, 2935, 1566, 300, 456, 366, 9271, 1296, 721, 689, 291, 362, 472, 281, 867, 6159, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09218523395595266, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.016138624399900436}, {"id": 301, "seek": 170300, "start": 1721.0, "end": 1730.0, "text": " The blue section in the middle, could you advance down two slides?", "tokens": [51264, 440, 3344, 3541, 294, 264, 2808, 11, 727, 291, 7295, 760, 732, 9788, 30, 51714], "temperature": 0.0, "avg_logprob": -0.09218523395595266, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.016138624399900436}, {"id": 302, "seek": 173000, "start": 1730.0, "end": 1738.0, "text": " This is, I think, the place where we sort of don't have agreement on what the structure of this should be.", "tokens": [50364, 639, 307, 11, 286, 519, 11, 264, 1081, 689, 321, 1333, 295, 500, 380, 362, 8106, 322, 437, 264, 3877, 295, 341, 820, 312, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07086473987216041, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.0022501202765852213}, {"id": 303, "seek": 173000, "start": 1738.0, "end": 1743.0, "text": " I mean, the slide that I just showed you, there really seemed to be more or less a consensus among people", "tokens": [50764, 286, 914, 11, 264, 4137, 300, 286, 445, 4712, 291, 11, 456, 534, 6576, 281, 312, 544, 420, 1570, 257, 19115, 3654, 561, 51014], "temperature": 0.0, "avg_logprob": -0.07086473987216041, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.0022501202765852213}, {"id": 304, "seek": 173000, "start": 1743.0, "end": 1746.0, "text": " in our discussion that that was how things were related.", "tokens": [51014, 294, 527, 5017, 300, 300, 390, 577, 721, 645, 4077, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07086473987216041, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.0022501202765852213}, {"id": 305, "seek": 173000, "start": 1746.0, "end": 1753.0, "text": " But in terms of what's the relationship between identifications and occurrences,", "tokens": [51164, 583, 294, 2115, 295, 437, 311, 264, 2480, 1296, 2473, 7833, 293, 5160, 38983, 11, 51514], "temperature": 0.0, "avg_logprob": -0.07086473987216041, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.0022501202765852213}, {"id": 306, "seek": 175300, "start": 1753.0, "end": 1760.0, "text": " you know, we stuck this thing which essentially should have probably been defined", "tokens": [50364, 291, 458, 11, 321, 5541, 341, 551, 597, 4476, 820, 362, 1391, 668, 7642, 50714], "temperature": 0.0, "avg_logprob": -0.09211514369550958, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.04018785059452057}, {"id": 307, "seek": 175300, "start": 1760.0, "end": 1766.0, "text": " as taxonomically heterogeneous identity in between identifications and occurrences.", "tokens": [50714, 382, 3366, 12481, 984, 20789, 31112, 6575, 294, 1296, 2473, 7833, 293, 5160, 38983, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09211514369550958, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.04018785059452057}, {"id": 308, "seek": 175300, "start": 1766.0, "end": 1772.0, "text": " And what exactly that means is a subject of discussion.", "tokens": [51014, 400, 437, 2293, 300, 1355, 307, 257, 3983, 295, 5017, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09211514369550958, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.04018785059452057}, {"id": 309, "seek": 175300, "start": 1772.0, "end": 1778.0, "text": " But I think the idea of token, really, if you just don't call it token and you call it evidence,", "tokens": [51314, 583, 286, 519, 264, 1558, 295, 14862, 11, 534, 11, 498, 291, 445, 500, 380, 818, 309, 14862, 293, 291, 818, 309, 4467, 11, 51614], "temperature": 0.0, "avg_logprob": -0.09211514369550958, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.04018785059452057}, {"id": 310, "seek": 175300, "start": 1778.0, "end": 1782.0, "text": " that essentially defines what token is.", "tokens": [51614, 300, 4476, 23122, 437, 14862, 307, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09211514369550958, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.04018785059452057}, {"id": 311, "seek": 178200, "start": 1782.0, "end": 1786.0, "text": " It could be evidence that an organism occurred at a particular spot.", "tokens": [50364, 467, 727, 312, 4467, 300, 364, 24128, 11068, 412, 257, 1729, 4008, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 312, "seek": 178200, "start": 1786.0, "end": 1789.0, "text": " It could be evidence that's the basis for an identification.", "tokens": [50564, 467, 727, 312, 4467, 300, 311, 264, 5143, 337, 364, 22065, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 313, "seek": 178200, "start": 1789.0, "end": 1791.0, "text": " It's just simply evidence.", "tokens": [50714, 467, 311, 445, 2935, 4467, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 314, "seek": 178200, "start": 1791.0, "end": 1795.0, "text": " And it could even be the same thing as an individual organism,", "tokens": [50814, 400, 309, 727, 754, 312, 264, 912, 551, 382, 364, 2609, 24128, 11, 51014], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 315, "seek": 178200, "start": 1795.0, "end": 1798.0, "text": " or it could be something derived from an individual organism.", "tokens": [51014, 420, 309, 727, 312, 746, 18949, 490, 364, 2609, 24128, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 316, "seek": 178200, "start": 1798.0, "end": 1811.0, "text": " So, you know, what we call token just simply means evidence of some form.", "tokens": [51164, 407, 11, 291, 458, 11, 437, 321, 818, 14862, 445, 2935, 1355, 4467, 295, 512, 1254, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0626163593558378, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.008177544921636581}, {"id": 317, "seek": 181100, "start": 1811.0, "end": 1820.0, "text": " So, anyway, that's about all I wanted to say.", "tokens": [50364, 407, 11, 4033, 11, 300, 311, 466, 439, 286, 1415, 281, 584, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07306998351524616, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.003771102288737893}, {"id": 318, "seek": 181100, "start": 1820.0, "end": 1824.0, "text": " So, Steve, you haven't been here for earlier discussions,", "tokens": [50814, 407, 11, 7466, 11, 291, 2378, 380, 668, 510, 337, 3071, 11088, 11, 51014], "temperature": 0.0, "avg_logprob": -0.07306998351524616, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.003771102288737893}, {"id": 319, "seek": 181100, "start": 1824.0, "end": 1829.0, "text": " but one, I've made a series of very simple and very boring points.", "tokens": [51014, 457, 472, 11, 286, 600, 1027, 257, 2638, 295, 588, 2199, 293, 588, 9989, 2793, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07306998351524616, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.003771102288737893}, {"id": 320, "seek": 181100, "start": 1829.0, "end": 1832.0, "text": " And I'll continue to make them until I die.", "tokens": [51264, 400, 286, 603, 2354, 281, 652, 552, 1826, 286, 978, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07306998351524616, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.003771102288737893}, {"id": 321, "seek": 181100, "start": 1832.0, "end": 1840.0, "text": " And one boring point that I've made is that when you're building an ontology or a terminology resource,", "tokens": [51414, 400, 472, 9989, 935, 300, 286, 600, 1027, 307, 300, 562, 291, 434, 2390, 364, 6592, 1793, 420, 257, 27575, 7684, 11, 51814], "temperature": 0.0, "avg_logprob": -0.07306998351524616, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.003771102288737893}, {"id": 322, "seek": 184000, "start": 1840.0, "end": 1847.0, "text": " then you should be aware of using a very general term which has all kinds of meanings in other contexts", "tokens": [50364, 550, 291, 820, 312, 3650, 295, 1228, 257, 588, 2674, 1433, 597, 575, 439, 3685, 295, 28138, 294, 661, 30628, 50714], "temperature": 0.0, "avg_logprob": -0.06516232891617535, "compression_ratio": 1.784, "no_speech_prob": 0.02830987609922886}, {"id": 323, "seek": 184000, "start": 1847.0, "end": 1852.0, "text": " to mean exactly what you want to mean for your specific purpose.", "tokens": [50714, 281, 914, 2293, 437, 291, 528, 281, 914, 337, 428, 2685, 4334, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06516232891617535, "compression_ratio": 1.784, "no_speech_prob": 0.02830987609922886}, {"id": 324, "seek": 184000, "start": 1852.0, "end": 1858.0, "text": " And one of the reasons why that is a bad thing is because other people are going to want to use the data", "tokens": [50964, 400, 472, 295, 264, 4112, 983, 300, 307, 257, 1578, 551, 307, 570, 661, 561, 366, 516, 281, 528, 281, 764, 264, 1412, 51264], "temperature": 0.0, "avg_logprob": -0.06516232891617535, "compression_ratio": 1.784, "no_speech_prob": 0.02830987609922886}, {"id": 325, "seek": 184000, "start": 1858.0, "end": 1864.0, "text": " which you've annotated using your resource to do all kinds of unanticipated things.", "tokens": [51264, 597, 291, 600, 25339, 770, 1228, 428, 7684, 281, 360, 439, 3685, 295, 517, 394, 6537, 770, 721, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06516232891617535, "compression_ratio": 1.784, "no_speech_prob": 0.02830987609922886}, {"id": 326, "seek": 184000, "start": 1864.0, "end": 1869.0, "text": " And if they find that you're using a word that for them has a much more general meaning,", "tokens": [51564, 400, 498, 436, 915, 300, 291, 434, 1228, 257, 1349, 300, 337, 552, 575, 257, 709, 544, 2674, 3620, 11, 51814], "temperature": 0.0, "avg_logprob": -0.06516232891617535, "compression_ratio": 1.784, "no_speech_prob": 0.02830987609922886}, {"id": 327, "seek": 186900, "start": 1869.0, "end": 1876.0, "text": " then they will not find it easy to use the data annotated in your terms.", "tokens": [50364, 550, 436, 486, 406, 915, 309, 1858, 281, 764, 264, 1412, 25339, 770, 294, 428, 2115, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 328, "seek": 186900, "start": 1876.0, "end": 1882.0, "text": " Now, the word evidence is going to be used by nearly every scientist.", "tokens": [50714, 823, 11, 264, 1349, 4467, 307, 516, 281, 312, 1143, 538, 6217, 633, 12662, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 329, "seek": 186900, "start": 1882.0, "end": 1884.0, "text": " And it's going to mean statistical evidence.", "tokens": [51014, 400, 309, 311, 516, 281, 914, 22820, 4467, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 330, "seek": 186900, "start": 1884.0, "end": 1888.0, "text": " It's going to mean evidence on the basis of what was calculated.", "tokens": [51114, 467, 311, 516, 281, 914, 4467, 322, 264, 5143, 295, 437, 390, 15598, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 331, "seek": 186900, "start": 1888.0, "end": 1894.0, "text": " It's going to mean evidence in your sense, evidence pertaining to a sample, for instance.", "tokens": [51314, 467, 311, 516, 281, 914, 4467, 294, 428, 2020, 11, 4467, 49582, 281, 257, 6889, 11, 337, 5197, 13, 51614], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 332, "seek": 186900, "start": 1894.0, "end": 1896.0, "text": " So, you shouldn't use the word evidence.", "tokens": [51614, 407, 11, 291, 4659, 380, 764, 264, 1349, 4467, 13, 51714], "temperature": 0.0, "avg_logprob": -0.05704835483006069, "compression_ratio": 1.8682926829268294, "no_speech_prob": 0.00312154577113688}, {"id": 333, "seek": 189600, "start": 1896.0, "end": 1903.0, "text": " Maybe you can call it Darwin evidence or Herborium evidence, but you can't just call it evidence.", "tokens": [50364, 2704, 291, 393, 818, 309, 30233, 4467, 420, 3204, 3918, 2197, 4467, 11, 457, 291, 393, 380, 445, 818, 309, 4467, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12808300536355854, "compression_ratio": 1.563063063063063, "no_speech_prob": 0.0018018251284956932}, {"id": 334, "seek": 189600, "start": 1903.0, "end": 1910.0, "text": " Right. Well, I mean, this is a part of the whole problem with defining what an individual organism was", "tokens": [50714, 1779, 13, 1042, 11, 286, 914, 11, 341, 307, 257, 644, 295, 264, 1379, 1154, 365, 17827, 437, 364, 2609, 24128, 390, 51064], "temperature": 0.0, "avg_logprob": -0.12808300536355854, "compression_ratio": 1.563063063063063, "no_speech_prob": 0.0018018251284956932}, {"id": 335, "seek": 189600, "start": 1910.0, "end": 1915.0, "text": " because the term individual has a particular meaning.", "tokens": [51064, 570, 264, 1433, 2609, 575, 257, 1729, 3620, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12808300536355854, "compression_ratio": 1.563063063063063, "no_speech_prob": 0.0018018251284956932}, {"id": 336, "seek": 189600, "start": 1915.0, "end": 1923.0, "text": " And so that's why it really probably should have been called taxonomically homogenous entity", "tokens": [51314, 400, 370, 300, 311, 983, 309, 534, 1391, 820, 362, 668, 1219, 3366, 12481, 984, 3655, 45519, 13977, 51714], "temperature": 0.0, "avg_logprob": -0.12808300536355854, "compression_ratio": 1.563063063063063, "no_speech_prob": 0.0018018251284956932}, {"id": 337, "seek": 192300, "start": 1923.0, "end": 1928.0, "text": " because that's essentially what we intended for it to mean.", "tokens": [50364, 570, 300, 311, 4476, 437, 321, 10226, 337, 309, 281, 914, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 338, "seek": 192300, "start": 1928.0, "end": 1933.0, "text": " But, you know, there's history in what people call things.", "tokens": [50614, 583, 11, 291, 458, 11, 456, 311, 2503, 294, 437, 561, 818, 721, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 339, "seek": 192300, "start": 1933.0, "end": 1940.0, "text": " And, you know, I'm not sure what the best thing, token, was something that basically we made up.", "tokens": [50864, 400, 11, 291, 458, 11, 286, 478, 406, 988, 437, 264, 1151, 551, 11, 14862, 11, 390, 746, 300, 1936, 321, 1027, 493, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 340, "seek": 192300, "start": 1940.0, "end": 1944.0, "text": " And so that might be a better term than evidence.", "tokens": [51214, 400, 370, 300, 1062, 312, 257, 1101, 1433, 813, 4467, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 341, "seek": 192300, "start": 1944.0, "end": 1947.0, "text": " Token is not a good word because it too has a history, unfortunately.", "tokens": [51414, 314, 8406, 307, 406, 257, 665, 1349, 570, 309, 886, 575, 257, 2503, 11, 7015, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 342, "seek": 192300, "start": 1947.0, "end": 1949.0, "text": " So this is really hard.", "tokens": [51564, 407, 341, 307, 534, 1152, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10757090381740295, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.0009374124929308891}, {"id": 343, "seek": 194900, "start": 1949.0, "end": 1956.0, "text": " What is almost every term you can think of to use has somebody has used previously to mean something?", "tokens": [50364, 708, 307, 1920, 633, 1433, 291, 393, 519, 295, 281, 764, 575, 2618, 575, 1143, 8046, 281, 914, 746, 30, 50714], "temperature": 0.0, "avg_logprob": -0.1992806225288205, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0045085265301167965}, {"id": 344, "seek": 194900, "start": 1956.0, "end": 1957.0, "text": " Absolutely.", "tokens": [50714, 7021, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1992806225288205, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0045085265301167965}, {"id": 345, "seek": 194900, "start": 1957.0, "end": 1962.0, "text": " So maybe long names like Darwin-Cora evidence or something are better.", "tokens": [50764, 407, 1310, 938, 5288, 411, 30233, 12, 34, 3252, 4467, 420, 746, 366, 1101, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1992806225288205, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0045085265301167965}, {"id": 346, "seek": 194900, "start": 1962.0, "end": 1968.0, "text": " So it's hard work, but it has been done successfully in many different fields.", "tokens": [51014, 407, 309, 311, 1152, 589, 11, 457, 309, 575, 668, 1096, 10727, 294, 867, 819, 7909, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1992806225288205, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0045085265301167965}, {"id": 347, "seek": 194900, "start": 1968.0, "end": 1973.0, "text": " And we've learned things. There are some lessons learned from all of that.", "tokens": [51314, 400, 321, 600, 3264, 721, 13, 821, 366, 512, 8820, 3264, 490, 439, 295, 300, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1992806225288205, "compression_ratio": 1.515695067264574, "no_speech_prob": 0.0045085265301167965}, {"id": 348, "seek": 197300, "start": 1973.0, "end": 1979.0, "text": " I'm just going to mention one further lesson learned because I think it's important to see one difference", "tokens": [50364, 286, 478, 445, 516, 281, 2152, 472, 3052, 6898, 3264, 570, 286, 519, 309, 311, 1021, 281, 536, 472, 2649, 50664], "temperature": 0.0, "avg_logprob": -0.09085459045217006, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.07422608882188797}, {"id": 349, "seek": 197300, "start": 1979.0, "end": 1983.0, "text": " between the Dublin-Cora and the Darwin-Cora.", "tokens": [50664, 1296, 264, 42323, 12, 34, 3252, 293, 264, 30233, 12, 34, 3252, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09085459045217006, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.07422608882188797}, {"id": 350, "seek": 197300, "start": 1983.0, "end": 1991.0, "text": " The Dublin-Cora is pretty straightforwardly what we might call first order.", "tokens": [50864, 440, 42323, 12, 34, 3252, 307, 1238, 15325, 356, 437, 321, 1062, 818, 700, 1668, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09085459045217006, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.07422608882188797}, {"id": 351, "seek": 197300, "start": 1991.0, "end": 2001.0, "text": " And what that means is that if it's talking about, say, a registration for copyright purposes,", "tokens": [51264, 400, 437, 300, 1355, 307, 300, 498, 309, 311, 1417, 466, 11, 584, 11, 257, 16847, 337, 17996, 9932, 11, 51764], "temperature": 0.0, "avg_logprob": -0.09085459045217006, "compression_ratio": 1.5432692307692308, "no_speech_prob": 0.07422608882188797}, {"id": 352, "seek": 200100, "start": 2001.0, "end": 2007.0, "text": " then it will introduce a term which means registration for copyright purposes.", "tokens": [50364, 550, 309, 486, 5366, 257, 1433, 597, 1355, 16847, 337, 17996, 9932, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 353, "seek": 200100, "start": 2007.0, "end": 2012.0, "text": " The Darwin-Cora is sometimes first order in that sense.", "tokens": [50664, 440, 30233, 12, 34, 3252, 307, 2171, 700, 1668, 294, 300, 2020, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 354, "seek": 200100, "start": 2012.0, "end": 2016.0, "text": " So I think I have an example here.", "tokens": [50914, 407, 286, 519, 286, 362, 364, 1365, 510, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 355, "seek": 200100, "start": 2016.0, "end": 2024.0, "text": " So establishment means is defined as a process by which an individual establishes itself.", "tokens": [51114, 407, 20971, 1355, 307, 7642, 382, 257, 1399, 538, 597, 364, 2609, 8327, 279, 2564, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 356, "seek": 200100, "start": 2024.0, "end": 2025.0, "text": " So that's first order.", "tokens": [51514, 407, 300, 311, 700, 1668, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 357, "seek": 200100, "start": 2025.0, "end": 2029.0, "text": " The term refers to what we would think the term would mean.", "tokens": [51564, 440, 1433, 14942, 281, 437, 321, 576, 519, 264, 1433, 576, 914, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06506039415087018, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0018037828849628568}, {"id": 358, "seek": 202900, "start": 2029.0, "end": 2034.0, "text": " But behavior in Darwin-Cora is defined as the second order.", "tokens": [50364, 583, 5223, 294, 30233, 12, 34, 3252, 307, 7642, 382, 264, 1150, 1668, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 359, "seek": 202900, "start": 2034.0, "end": 2036.0, "text": " Behavior doesn't mean behavior in the Darwin-Cora.", "tokens": [50614, 45807, 1177, 380, 914, 5223, 294, 264, 30233, 12, 34, 3252, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 360, "seek": 202900, "start": 2036.0, "end": 2039.0, "text": " It means the description of behavior.", "tokens": [50714, 467, 1355, 264, 3855, 295, 5223, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 361, "seek": 202900, "start": 2039.0, "end": 2040.0, "text": " So it's second order.", "tokens": [50864, 407, 309, 311, 1150, 1668, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 362, "seek": 202900, "start": 2040.0, "end": 2051.0, "text": " And very many terms in the Darwin-Cora are terms of the form an X is information about an X.", "tokens": [50914, 400, 588, 867, 2115, 294, 264, 30233, 12, 34, 3252, 366, 2115, 295, 264, 1254, 364, 1783, 307, 1589, 466, 364, 1783, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 363, "seek": 202900, "start": 2051.0, "end": 2058.0, "text": " So a good clean first order terminology would define every term as an X is an X.", "tokens": [51464, 407, 257, 665, 2541, 700, 1668, 27575, 576, 6964, 633, 1433, 382, 364, 1783, 307, 364, 1783, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07223156665233856, "compression_ratio": 1.8105263157894738, "no_speech_prob": 0.005351679865270853}, {"id": 364, "seek": 205800, "start": 2058.0, "end": 2062.0, "text": " Darwin-Cora defines very many terms as an X is an information about X.", "tokens": [50364, 30233, 12, 34, 3252, 23122, 588, 867, 2115, 382, 364, 1783, 307, 364, 1589, 466, 1783, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 365, "seek": 205800, "start": 2062.0, "end": 2065.0, "text": " Now that's a mistake.", "tokens": [50564, 823, 300, 311, 257, 6146, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 366, "seek": 205800, "start": 2065.0, "end": 2068.0, "text": " If it was done systematically, it might be okay.", "tokens": [50714, 759, 309, 390, 1096, 39531, 11, 309, 1062, 312, 1392, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 367, "seek": 205800, "start": 2068.0, "end": 2071.0, "text": " But generally it's not been done systematically.", "tokens": [50864, 583, 5101, 309, 311, 406, 668, 1096, 39531, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 368, "seek": 205800, "start": 2071.0, "end": 2075.0, "text": " And it's a mistake which has to be fixed.", "tokens": [51014, 400, 309, 311, 257, 6146, 597, 575, 281, 312, 6806, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 369, "seek": 205800, "start": 2075.0, "end": 2083.0, "text": " And the reason why I draw attention to this one is because other similar resources.", "tokens": [51214, 400, 264, 1778, 983, 286, 2642, 3202, 281, 341, 472, 307, 570, 661, 2531, 3593, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 370, "seek": 205800, "start": 2083.0, "end": 2086.0, "text": " So there's one very famous resource in medicine called HL7.", "tokens": [51614, 407, 456, 311, 472, 588, 4618, 7684, 294, 7195, 1219, 389, 43, 22, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10595929145812988, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0058730775490403175}, {"id": 371, "seek": 208600, "start": 2086.0, "end": 2088.0, "text": " Made exactly the same mistake.", "tokens": [50364, 18330, 2293, 264, 912, 6146, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 372, "seek": 208600, "start": 2088.0, "end": 2091.0, "text": " And the result is that it's now unusable.", "tokens": [50464, 400, 264, 1874, 307, 300, 309, 311, 586, 10054, 712, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 373, "seek": 208600, "start": 2091.0, "end": 2096.0, "text": " It's so complicated because people never know whether they're talking about X.", "tokens": [50614, 467, 311, 370, 6179, 570, 561, 1128, 458, 1968, 436, 434, 1417, 466, 1783, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 374, "seek": 208600, "start": 2096.0, "end": 2102.0, "text": " For instance, somebody giving somebody a drug or information about X,", "tokens": [50864, 1171, 5197, 11, 2618, 2902, 2618, 257, 4110, 420, 1589, 466, 1783, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 375, "seek": 208600, "start": 2102.0, "end": 2106.0, "text": " which would be the description of somebody giving somebody a drug.", "tokens": [51164, 597, 576, 312, 264, 3855, 295, 2618, 2902, 2618, 257, 4110, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 376, "seek": 208600, "start": 2106.0, "end": 2109.0, "text": " Now I don't know why I'm addressing this comment to you,", "tokens": [51364, 823, 286, 500, 380, 458, 983, 286, 478, 14329, 341, 2871, 281, 291, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 377, "seek": 208600, "start": 2109.0, "end": 2112.0, "text": " because it's really a comment to all Darwin-Core people.", "tokens": [51514, 570, 309, 311, 534, 257, 2871, 281, 439, 30233, 12, 34, 418, 561, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08888887650895827, "compression_ratio": 1.675, "no_speech_prob": 0.024240510538220406}, {"id": 378, "seek": 211200, "start": 2112.0, "end": 2116.0, "text": " But this is something which needs to be got right, I think.", "tokens": [50364, 583, 341, 307, 746, 597, 2203, 281, 312, 658, 558, 11, 286, 519, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13410393815291555, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05144288018345833}, {"id": 379, "seek": 211200, "start": 2116.0, "end": 2127.0, "text": " In what sense is divusing the term evidence that clashes with other uses of the word evidence?", "tokens": [50564, 682, 437, 2020, 307, 3414, 7981, 264, 1433, 4467, 300, 596, 12808, 365, 661, 4960, 295, 264, 1349, 4467, 30, 51114], "temperature": 0.0, "avg_logprob": -0.13410393815291555, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05144288018345833}, {"id": 380, "seek": 211200, "start": 2127.0, "end": 2132.0, "text": " Because you don't mean any kind of evidence.", "tokens": [51114, 1436, 291, 500, 380, 914, 604, 733, 295, 4467, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13410393815291555, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05144288018345833}, {"id": 381, "seek": 211200, "start": 2132.0, "end": 2137.0, "text": " You mean evidence incorporated in a certain collection object,", "tokens": [51364, 509, 914, 4467, 21654, 294, 257, 1629, 5765, 2657, 11, 51614], "temperature": 0.0, "avg_logprob": -0.13410393815291555, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05144288018345833}, {"id": 382, "seek": 211200, "start": 2137.0, "end": 2141.0, "text": " either as a report or as a seed sample.", "tokens": [51614, 2139, 382, 257, 2275, 420, 382, 257, 8871, 6889, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13410393815291555, "compression_ratio": 1.5487179487179488, "no_speech_prob": 0.05144288018345833}, {"id": 383, "seek": 214100, "start": 2141.0, "end": 2149.0, "text": " That really, from our point of view, a token could be any kind of evidence.", "tokens": [50364, 663, 534, 11, 490, 527, 935, 295, 1910, 11, 257, 14862, 727, 312, 604, 733, 295, 4467, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 384, "seek": 214100, "start": 2149.0, "end": 2154.0, "text": " I mean, it could be a photograph, it could be a specimen,", "tokens": [50764, 286, 914, 11, 309, 727, 312, 257, 8348, 11, 309, 727, 312, 257, 34204, 11, 51014], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 385, "seek": 214100, "start": 2154.0, "end": 2157.0, "text": " it could be notes that somebody has written down.", "tokens": [51014, 309, 727, 312, 5570, 300, 2618, 575, 3720, 760, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 386, "seek": 214100, "start": 2157.0, "end": 2161.0, "text": " So we really didn't have a restriction as to what that should be.", "tokens": [51164, 407, 321, 534, 994, 380, 362, 257, 29529, 382, 281, 437, 300, 820, 312, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 387, "seek": 214100, "start": 2161.0, "end": 2163.0, "text": " And maybe that's not well-defined enough,", "tokens": [51364, 400, 1310, 300, 311, 406, 731, 12, 37716, 1547, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 388, "seek": 214100, "start": 2163.0, "end": 2168.0, "text": " but the reason why we added these two blue bubbles in the middle", "tokens": [51464, 457, 264, 1778, 983, 321, 3869, 613, 732, 3344, 16295, 294, 264, 2808, 51714], "temperature": 0.0, "avg_logprob": -0.08123763234991777, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.004001368302851915}, {"id": 389, "seek": 216800, "start": 2168.0, "end": 2172.0, "text": " is mostly because of the extreme overloading of occurrence.", "tokens": [50364, 307, 5240, 570, 295, 264, 8084, 28777, 278, 295, 36122, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 390, "seek": 216800, "start": 2172.0, "end": 2175.0, "text": " You know, you would ask people what does an occurrence mean,", "tokens": [50564, 509, 458, 11, 291, 576, 1029, 561, 437, 775, 364, 36122, 914, 11, 50714], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 391, "seek": 216800, "start": 2175.0, "end": 2181.0, "text": " and they would say it means that there was an organism at a particular location in a particular time.", "tokens": [50714, 293, 436, 576, 584, 309, 1355, 300, 456, 390, 364, 24128, 412, 257, 1729, 4914, 294, 257, 1729, 565, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 392, "seek": 216800, "start": 2181.0, "end": 2184.0, "text": " But then when you would see how people were actually using the term occurrence,", "tokens": [51014, 583, 550, 562, 291, 576, 536, 577, 561, 645, 767, 1228, 264, 1433, 36122, 11, 51164], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 393, "seek": 216800, "start": 2184.0, "end": 2189.0, "text": " they were using it to mean a specimen glued onto a piece of paper.", "tokens": [51164, 436, 645, 1228, 309, 281, 914, 257, 34204, 28008, 3911, 257, 2522, 295, 3035, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 394, "seek": 216800, "start": 2189.0, "end": 2195.0, "text": " So, you know, it may be that we didn't choose the best terms for these classes that we introduced,", "tokens": [51414, 407, 11, 291, 458, 11, 309, 815, 312, 300, 321, 994, 380, 2826, 264, 1151, 2115, 337, 613, 5359, 300, 321, 7268, 11, 51714], "temperature": 0.0, "avg_logprob": -0.05558572373948656, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0038787119556218386}, {"id": 395, "seek": 219500, "start": 2195.0, "end": 2200.0, "text": " but it was an attempt to try to separate out some of the different ways", "tokens": [50364, 457, 309, 390, 364, 5217, 281, 853, 281, 4994, 484, 512, 295, 264, 819, 2098, 50614], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 396, "seek": 219500, "start": 2200.0, "end": 2205.0, "text": " that people were using a term, particularly occurrence.", "tokens": [50614, 300, 561, 645, 1228, 257, 1433, 11, 4098, 36122, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 397, "seek": 219500, "start": 2205.0, "end": 2209.0, "text": " In this case, we're not arguing about the term class, which is a token,", "tokens": [50864, 682, 341, 1389, 11, 321, 434, 406, 19697, 466, 264, 1433, 1508, 11, 597, 307, 257, 14862, 11, 51064], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 398, "seek": 219500, "start": 2209.0, "end": 2214.0, "text": " but the word for the property, which has evidence, or evidence for,", "tokens": [51064, 457, 264, 1349, 337, 264, 4707, 11, 597, 575, 4467, 11, 420, 4467, 337, 11, 51314], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 399, "seek": 219500, "start": 2214.0, "end": 2221.0, "text": " and I guess I can't see the way you're using it, sort of, you know,", "tokens": [51314, 293, 286, 2041, 286, 393, 380, 536, 264, 636, 291, 434, 1228, 309, 11, 1333, 295, 11, 291, 458, 11, 51664], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 400, "seek": 219500, "start": 2221.0, "end": 2224.0, "text": " I can't see the way you're using it being incompatible.", "tokens": [51664, 286, 393, 380, 536, 264, 636, 291, 434, 1228, 309, 885, 40393, 267, 964, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15736319639972438, "compression_ratio": 1.7533632286995515, "no_speech_prob": 0.002630263101309538}, {"id": 401, "seek": 222400, "start": 2224.0, "end": 2232.0, "text": " What I came up with in Darwin S.W. was really a compromise between Kim and me about,", "tokens": [50364, 708, 286, 1361, 493, 365, 294, 30233, 318, 13, 54, 13, 390, 534, 257, 18577, 1296, 5652, 293, 385, 466, 11, 50764], "temperature": 0.0, "avg_logprob": -0.17650041700918465, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.053277067840099335}, {"id": 402, "seek": 222400, "start": 2232.0, "end": 2238.0, "text": " and actually originally I had suggested that we don't even have a class called token,", "tokens": [50764, 293, 767, 7993, 286, 632, 10945, 300, 321, 500, 380, 754, 362, 257, 1508, 1219, 14862, 11, 51064], "temperature": 0.0, "avg_logprob": -0.17650041700918465, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.053277067840099335}, {"id": 403, "seek": 222400, "start": 2238.0, "end": 2242.0, "text": " that we have the terms that are shown on the slide there,", "tokens": [51064, 300, 321, 362, 264, 2115, 300, 366, 4898, 322, 264, 4137, 456, 11, 51264], "temperature": 0.0, "avg_logprob": -0.17650041700918465, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.053277067840099335}, {"id": 404, "seek": 222400, "start": 2242.0, "end": 2250.0, "text": " like is basis for identification and identification based on, or evidence for, or has evidence,", "tokens": [51264, 411, 307, 5143, 337, 22065, 293, 22065, 2361, 322, 11, 420, 4467, 337, 11, 420, 575, 4467, 11, 51664], "temperature": 0.0, "avg_logprob": -0.17650041700918465, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.053277067840099335}, {"id": 405, "seek": 225000, "start": 2250.0, "end": 2254.0, "text": " those terms could simply be applied to anything that people would use for evidence,", "tokens": [50364, 729, 2115, 727, 2935, 312, 6456, 281, 1340, 300, 561, 576, 764, 337, 4467, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08908755203773236, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0040047201327979565}, {"id": 406, "seek": 225000, "start": 2254.0, "end": 2259.0, "text": " and so I actually was originally advocating that we don't have a class named token,", "tokens": [50564, 293, 370, 286, 767, 390, 7993, 32050, 300, 321, 500, 380, 362, 257, 1508, 4926, 14862, 11, 50814], "temperature": 0.0, "avg_logprob": -0.08908755203773236, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0040047201327979565}, {"id": 407, "seek": 225000, "start": 2259.0, "end": 2267.0, "text": " and Kim said, let's have a class named token so that we could say what the object,", "tokens": [50814, 293, 5652, 848, 11, 718, 311, 362, 257, 1508, 4926, 14862, 370, 300, 321, 727, 584, 437, 264, 2657, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08908755203773236, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0040047201327979565}, {"id": 408, "seek": 225000, "start": 2267.0, "end": 2273.0, "text": " we could have a term to describe what the object of something like has evidence,", "tokens": [51214, 321, 727, 362, 257, 1433, 281, 6786, 437, 264, 2657, 295, 746, 411, 575, 4467, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08908755203773236, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0040047201327979565}, {"id": 409, "seek": 225000, "start": 2273.0, "end": 2276.0, "text": " what is that an instance of.", "tokens": [51514, 437, 307, 300, 364, 5197, 295, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08908755203773236, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0040047201327979565}, {"id": 410, "seek": 227600, "start": 2276.0, "end": 2281.0, "text": " I didn't really see token as a thing necessarily that needed to be defined.", "tokens": [50364, 286, 994, 380, 534, 536, 14862, 382, 257, 551, 4725, 300, 2978, 281, 312, 7642, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14380482061585384, "compression_ratio": 1.3712574850299402, "no_speech_prob": 0.0032189504709094763}, {"id": 411, "seek": 227600, "start": 2281.0, "end": 2287.0, "text": " Yeah, so I have right now, just for, I guess contrast,", "tokens": [50614, 865, 11, 370, 286, 362, 558, 586, 11, 445, 337, 11, 286, 2041, 8712, 11, 50914], "temperature": 0.0, "avg_logprob": -0.14380482061585384, "compression_ratio": 1.3712574850299402, "no_speech_prob": 0.0032189504709094763}, {"id": 412, "seek": 227600, "start": 2287.0, "end": 2300.0, "text": " Pete's taxonconcept.org, so Pete DeVries has put a lot of time into not only creating an ontology,", "tokens": [50914, 19013, 311, 3366, 266, 1671, 1336, 13, 4646, 11, 370, 19013, 1346, 53, 2244, 575, 829, 257, 688, 295, 565, 666, 406, 787, 4084, 364, 6592, 1793, 11, 51564], "temperature": 0.0, "avg_logprob": -0.14380482061585384, "compression_ratio": 1.3712574850299402, "no_speech_prob": 0.0032189504709094763}, {"id": 413, "seek": 230000, "start": 2300.0, "end": 2307.0, "text": " but populating it and putting a sparkle front end onto the resulting knowledge base,", "tokens": [50364, 457, 1665, 12162, 309, 293, 3372, 257, 48558, 1868, 917, 3911, 264, 16505, 3601, 3096, 11, 50714], "temperature": 0.0, "avg_logprob": -0.11216051284581015, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.030893836170434952}, {"id": 414, "seek": 230000, "start": 2307.0, "end": 2314.0, "text": " and Barry, I wonder if, you know, he takes the approach that I think that Barry is suggesting", "tokens": [50714, 293, 21639, 11, 286, 2441, 498, 11, 291, 458, 11, 415, 2516, 264, 3109, 300, 286, 519, 300, 21639, 307, 18094, 51064], "temperature": 0.0, "avg_logprob": -0.11216051284581015, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.030893836170434952}, {"id": 415, "seek": 230000, "start": 2314.0, "end": 2319.0, "text": " where there's no ambiguity in the term, identification has label image,", "tokens": [51064, 689, 456, 311, 572, 46519, 294, 264, 1433, 11, 22065, 575, 7645, 3256, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11216051284581015, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.030893836170434952}, {"id": 416, "seek": 230000, "start": 2319.0, "end": 2325.0, "text": " so the domain of the term is part of the property.", "tokens": [51314, 370, 264, 9274, 295, 264, 1433, 307, 644, 295, 264, 4707, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11216051284581015, "compression_ratio": 1.5595854922279793, "no_speech_prob": 0.030893836170434952}, {"id": 417, "seek": 232500, "start": 2325.0, "end": 2331.0, "text": " I don't like that. That commits the sin of not reusing established relations,", "tokens": [50364, 286, 500, 380, 411, 300, 13, 663, 48311, 264, 3343, 295, 406, 319, 7981, 7545, 2299, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1615941935572131, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.009990946389734745}, {"id": 418, "seek": 232500, "start": 2331.0, "end": 2333.0, "text": " but inventing new ones.", "tokens": [50664, 457, 7962, 278, 777, 2306, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1615941935572131, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.009990946389734745}, {"id": 419, "seek": 232500, "start": 2333.0, "end": 2352.0, "text": " I don't like it either, but it, I mean, it, in a sense, it's of the same approach as,", "tokens": [50764, 286, 500, 380, 411, 309, 2139, 11, 457, 309, 11, 286, 914, 11, 309, 11, 294, 257, 2020, 11, 309, 311, 295, 264, 912, 3109, 382, 11, 51714], "temperature": 0.0, "avg_logprob": -0.1615941935572131, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.009990946389734745}, {"id": 420, "seek": 235200, "start": 2352.0, "end": 2361.0, "text": " so why don't you like it?", "tokens": [50364, 370, 983, 500, 380, 291, 411, 309, 30, 50814], "temperature": 0.0, "avg_logprob": -0.14938875655053366, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.007229201029986143}, {"id": 421, "seek": 235200, "start": 2361.0, "end": 2370.0, "text": " Because relations are the glue, and they are going to be gluing different ontology resources,", "tokens": [50814, 1436, 2299, 366, 264, 8998, 11, 293, 436, 366, 516, 281, 312, 1563, 9635, 819, 6592, 1793, 3593, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14938875655053366, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.007229201029986143}, {"id": 422, "seek": 235200, "start": 2370.0, "end": 2373.0, "text": " as well as gluing terms within ontology resources,", "tokens": [51264, 382, 731, 382, 1563, 9635, 2115, 1951, 6592, 1793, 3593, 11, 51414], "temperature": 0.0, "avg_logprob": -0.14938875655053366, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.007229201029986143}, {"id": 423, "seek": 235200, "start": 2373.0, "end": 2378.0, "text": " and that means that we need, as far as possible, to have a small number of relations which everyone uses,", "tokens": [51414, 293, 300, 1355, 300, 321, 643, 11, 382, 1400, 382, 1944, 11, 281, 362, 257, 1359, 1230, 295, 2299, 597, 1518, 4960, 11, 51664], "temperature": 0.0, "avg_logprob": -0.14938875655053366, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.007229201029986143}, {"id": 424, "seek": 237800, "start": 2378.0, "end": 2385.0, "text": " rather than having highly specific relations which are tied just to a particular small locus.", "tokens": [50364, 2831, 813, 1419, 5405, 2685, 2299, 597, 366, 9601, 445, 281, 257, 1729, 1359, 450, 1149, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10312883750252101, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.07057221978902817}, {"id": 425, "seek": 237800, "start": 2385.0, "end": 2390.0, "text": " So the more we can have generalizable glue, like part of and so forth,", "tokens": [50714, 407, 264, 544, 321, 393, 362, 2674, 22395, 8998, 11, 411, 644, 295, 293, 370, 5220, 11, 50964], "temperature": 0.0, "avg_logprob": -0.10312883750252101, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.07057221978902817}, {"id": 426, "seek": 237800, "start": 2390.0, "end": 2394.0, "text": " the more our ontologies will work well together.", "tokens": [50964, 264, 544, 527, 6592, 6204, 486, 589, 731, 1214, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10312883750252101, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.07057221978902817}, {"id": 427, "seek": 237800, "start": 2394.0, "end": 2398.0, "text": " And it's, so one of the things that you said earlier is right.", "tokens": [51164, 400, 309, 311, 11, 370, 472, 295, 264, 721, 300, 291, 848, 3071, 307, 558, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10312883750252101, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.07057221978902817}, {"id": 428, "seek": 237800, "start": 2398.0, "end": 2404.0, "text": " If people get hold of owl, if people get hold of owl, they'll do bad things.", "tokens": [51364, 759, 561, 483, 1797, 295, 34488, 11, 498, 561, 483, 1797, 295, 34488, 11, 436, 603, 360, 1578, 721, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10312883750252101, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.07057221978902817}, {"id": 429, "seek": 240400, "start": 2404.0, "end": 2410.0, "text": " Owl is such a nice thing. You can create all kinds of filigree with owl,", "tokens": [50364, 12773, 75, 307, 1270, 257, 1481, 551, 13, 509, 393, 1884, 439, 3685, 295, 1387, 328, 701, 365, 34488, 11, 50664], "temperature": 0.0, "avg_logprob": -0.09039716517671625, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.01599220186471939}, {"id": 430, "seek": 240400, "start": 2410.0, "end": 2413.0, "text": " and most of it doesn't have any thought attached to it.", "tokens": [50664, 293, 881, 295, 309, 1177, 380, 362, 604, 1194, 8570, 281, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09039716517671625, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.01599220186471939}, {"id": 431, "seek": 240400, "start": 2413.0, "end": 2417.0, "text": " So owl is not good enough. What you need is owl plus thinking,", "tokens": [50814, 407, 34488, 307, 406, 665, 1547, 13, 708, 291, 643, 307, 34488, 1804, 1953, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09039716517671625, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.01599220186471939}, {"id": 432, "seek": 240400, "start": 2417.0, "end": 2420.0, "text": " and that's why writing English definitions is a good thing.", "tokens": [51014, 293, 300, 311, 983, 3579, 3669, 21988, 307, 257, 665, 551, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09039716517671625, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.01599220186471939}, {"id": 433, "seek": 240400, "start": 2420.0, "end": 2427.0, "text": " Now one way in which once people get hold of owl, they go mad is inventing these new relations.", "tokens": [51164, 823, 472, 636, 294, 597, 1564, 561, 483, 1797, 295, 34488, 11, 436, 352, 5244, 307, 7962, 278, 613, 777, 2299, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09039716517671625, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.01599220186471939}, {"id": 434, "seek": 242700, "start": 2427.0, "end": 2432.0, "text": " Has Paris temperature preference for,", "tokens": [50364, 8646, 8380, 4292, 17502, 337, 11, 50614], "temperature": 0.0, "avg_logprob": -0.17758304595947266, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.18718461692333221}, {"id": 435, "seek": 242700, "start": 2432.0, "end": 2436.0, "text": " which means they like Paris because it's hot or something?", "tokens": [50614, 597, 1355, 436, 411, 8380, 570, 309, 311, 2368, 420, 746, 30, 50814], "temperature": 0.0, "avg_logprob": -0.17758304595947266, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.18718461692333221}, {"id": 436, "seek": 242700, "start": 2444.0, "end": 2450.0, "text": " Yeah, that's one step in the right direction, but ideally you don't need a relation with the word Paris.", "tokens": [51214, 865, 11, 300, 311, 472, 1823, 294, 264, 558, 3513, 11, 457, 22915, 291, 500, 380, 643, 257, 9721, 365, 264, 1349, 8380, 13, 51514], "temperature": 0.0, "avg_logprob": -0.17758304595947266, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.18718461692333221}, {"id": 437, "seek": 245000, "start": 2450.0, "end": 2457.0, "text": " So what is the guideline for when you have a special relationship that you call out and define", "tokens": [50364, 407, 437, 307, 264, 41653, 337, 562, 291, 362, 257, 2121, 2480, 300, 291, 818, 484, 293, 6964, 50714], "temperature": 0.0, "avg_logprob": -0.1167806581009266, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.0037470348179340363}, {"id": 438, "seek": 245000, "start": 2457.0, "end": 2460.0, "text": " when you try to just use some generics?", "tokens": [50714, 562, 291, 853, 281, 445, 764, 512, 1337, 1167, 30, 50864], "temperature": 0.0, "avg_logprob": -0.1167806581009266, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.0037470348179340363}, {"id": 439, "seek": 245000, "start": 2460.0, "end": 2465.0, "text": " So providing you define the relation, you can always eliminate it if you need to.", "tokens": [50864, 407, 6530, 291, 6964, 264, 9721, 11, 291, 393, 1009, 13819, 309, 498, 291, 643, 281, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1167806581009266, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.0037470348179340363}, {"id": 440, "seek": 245000, "start": 2465.0, "end": 2470.0, "text": " So that's already a good step, but that's another reason why we need to have definitions.", "tokens": [51114, 407, 300, 311, 1217, 257, 665, 1823, 11, 457, 300, 311, 1071, 1778, 983, 321, 643, 281, 362, 21988, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1167806581009266, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.0037470348179340363}, {"id": 441, "seek": 245000, "start": 2470.0, "end": 2473.0, "text": " Right, so taking the example has evidence.", "tokens": [51364, 1779, 11, 370, 1940, 264, 1365, 575, 4467, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1167806581009266, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.0037470348179340363}, {"id": 442, "seek": 247300, "start": 2473.0, "end": 2481.0, "text": " You were suggesting that that needs to be qualified so that we know this is Darwin has evidence.", "tokens": [50364, 509, 645, 18094, 300, 300, 2203, 281, 312, 15904, 370, 300, 321, 458, 341, 307, 30233, 575, 4467, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1214600122103127, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.020001128315925598}, {"id": 443, "seek": 247300, "start": 2481.0, "end": 2487.0, "text": " So I think evidence could be the subject of another three-day meeting all by itself.", "tokens": [50764, 407, 286, 519, 4467, 727, 312, 264, 3983, 295, 1071, 1045, 12, 810, 3440, 439, 538, 2564, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1214600122103127, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.020001128315925598}, {"id": 444, "seek": 247300, "start": 2487.0, "end": 2496.0, "text": " So that evidence is a very difficult topic, and I think that what you really mean by evidence", "tokens": [51064, 407, 300, 4467, 307, 257, 588, 2252, 4829, 11, 293, 286, 519, 300, 437, 291, 534, 914, 538, 4467, 51514], "temperature": 0.0, "avg_logprob": -0.1214600122103127, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.020001128315925598}, {"id": 445, "seek": 247300, "start": 2496.0, "end": 2502.0, "text": " is the stuff in the box, whether it's a piece of paper or a photograph or a seed stuck to a piece of paper.", "tokens": [51514, 307, 264, 1507, 294, 264, 2424, 11, 1968, 309, 311, 257, 2522, 295, 3035, 420, 257, 8348, 420, 257, 8871, 5541, 281, 257, 2522, 295, 3035, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1214600122103127, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.020001128315925598}, {"id": 446, "seek": 250200, "start": 2502.0, "end": 2512.0, "text": " You don't mean evidence in the sense in which most scientists mean evidence, which is arguments, data.", "tokens": [50364, 509, 500, 380, 914, 4467, 294, 264, 2020, 294, 597, 881, 7708, 914, 4467, 11, 597, 307, 12869, 11, 1412, 13, 50864], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 447, "seek": 250200, "start": 2512.0, "end": 2515.0, "text": " You mean that specific stuff in the box.", "tokens": [50864, 509, 914, 300, 2685, 1507, 294, 264, 2424, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 448, "seek": 250200, "start": 2515.0, "end": 2524.0, "text": " But Steve, everything that Steve would call evidence that also fits your definition of evidence.", "tokens": [51014, 583, 7466, 11, 1203, 300, 7466, 576, 818, 4467, 300, 611, 9001, 428, 7123, 295, 4467, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 449, "seek": 250200, "start": 2524.0, "end": 2525.0, "text": " Wait a second.", "tokens": [51464, 3802, 257, 1150, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 450, "seek": 250200, "start": 2525.0, "end": 2526.0, "text": " Yeah, and vice versa.", "tokens": [51514, 865, 11, 293, 11964, 25650, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 451, "seek": 250200, "start": 2526.0, "end": 2529.0, "text": " No, but it doesn't because it doesn't.", "tokens": [51564, 883, 11, 457, 309, 1177, 380, 570, 309, 1177, 380, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14618451420853779, "compression_ratio": 1.58, "no_speech_prob": 0.002423994243144989}, {"id": 452, "seek": 252900, "start": 2530.0, "end": 2537.0, "text": " So let's suppose that somebody steals something from Eric, is it?", "tokens": [50414, 407, 718, 311, 7297, 300, 2618, 46962, 746, 490, 9336, 11, 307, 309, 30, 50764], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 453, "seek": 252900, "start": 2537.0, "end": 2538.0, "text": " You're Herbarium.", "tokens": [50764, 509, 434, 3204, 5356, 2197, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 454, "seek": 252900, "start": 2538.0, "end": 2539.0, "text": " Greg.", "tokens": [50814, 11490, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 455, "seek": 252900, "start": 2539.0, "end": 2540.0, "text": " Greg.", "tokens": [50864, 11490, 13, 50914], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 456, "seek": 252900, "start": 2540.0, "end": 2541.0, "text": " Greg, sorry.", "tokens": [50914, 11490, 11, 2597, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 457, "seek": 252900, "start": 2541.0, "end": 2542.0, "text": " At least I got a number of letters.", "tokens": [50964, 1711, 1935, 286, 658, 257, 1230, 295, 7825, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 458, "seek": 252900, "start": 2542.0, "end": 2549.0, "text": " Somebody steals a box from Greg's Herbarium and gives it to his girlfriend as a Christmas present.", "tokens": [51014, 13463, 46962, 257, 2424, 490, 11490, 311, 3204, 5356, 2197, 293, 2709, 309, 281, 702, 10369, 382, 257, 5272, 1974, 13, 51364], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 459, "seek": 252900, "start": 2549.0, "end": 2552.0, "text": " And it's a nice flower or something, so she's happy.", "tokens": [51364, 400, 309, 311, 257, 1481, 8617, 420, 746, 11, 370, 750, 311, 2055, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 460, "seek": 252900, "start": 2552.0, "end": 2554.0, "text": " That's not Eric's girlfriend, is it?", "tokens": [51514, 663, 311, 406, 9336, 311, 10369, 11, 307, 309, 30, 51614], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 461, "seek": 252900, "start": 2554.0, "end": 2558.0, "text": " No, the thief gives it to his girlfriend.", "tokens": [51614, 883, 11, 264, 23176, 2709, 309, 281, 702, 10369, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15991256111546567, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.018566079437732697}, {"id": 462, "seek": 255800, "start": 2558.0, "end": 2563.0, "text": " Then it's the same object, but it's not evidence.", "tokens": [50364, 1396, 309, 311, 264, 912, 2657, 11, 457, 309, 311, 406, 4467, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10518567662843516, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.01403067447245121}, {"id": 463, "seek": 255800, "start": 2563.0, "end": 2567.0, "text": " Evidence is a role that an object plays or something like that.", "tokens": [50614, 5689, 2778, 307, 257, 3090, 300, 364, 2657, 5749, 420, 746, 411, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10518567662843516, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.01403067447245121}, {"id": 464, "seek": 255800, "start": 2567.0, "end": 2570.0, "text": " An object is not evidence.", "tokens": [50814, 1107, 2657, 307, 406, 4467, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10518567662843516, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.01403067447245121}, {"id": 465, "seek": 255800, "start": 2570.0, "end": 2577.0, "text": " Having this category of token is really what do you call specimens?", "tokens": [50964, 10222, 341, 7719, 295, 14862, 307, 534, 437, 360, 291, 818, 41007, 30, 51314], "temperature": 0.0, "avg_logprob": -0.10518567662843516, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.01403067447245121}, {"id": 466, "seek": 255800, "start": 2577.0, "end": 2582.0, "text": " And I think people have been saying that specimens are occurrences.", "tokens": [51314, 400, 286, 519, 561, 362, 668, 1566, 300, 41007, 366, 5160, 38983, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10518567662843516, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.01403067447245121}, {"id": 467, "seek": 258200, "start": 2582.0, "end": 2589.0, "text": " If you ask people what they mean when they say occurrence, they don't really mean a specimen.", "tokens": [50364, 759, 291, 1029, 561, 437, 436, 914, 562, 436, 584, 36122, 11, 436, 500, 380, 534, 914, 257, 34204, 13, 50714], "temperature": 0.0, "avg_logprob": -0.19320944816835464, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.15982449054718018}, {"id": 468, "seek": 258200, "start": 2589.0, "end": 2594.0, "text": " And so the question, the problem is that within the existing Darwin core classes,", "tokens": [50714, 400, 370, 264, 1168, 11, 264, 1154, 307, 300, 1951, 264, 6741, 30233, 4965, 5359, 11, 50964], "temperature": 0.0, "avg_logprob": -0.19320944816835464, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.15982449054718018}, {"id": 469, "seek": 258200, "start": 2594.0, "end": 2605.0, "text": " there isn't really any class that's appropriate to place the descriptive metadata about a specimen.", "tokens": [50964, 456, 1943, 380, 534, 604, 1508, 300, 311, 6854, 281, 1081, 264, 42585, 26603, 466, 257, 34204, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19320944816835464, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.15982449054718018}, {"id": 470, "seek": 260500, "start": 2606.0, "end": 2616.0, "text": " I think there needs to be perhaps some other classes that are related to organisms and parts of organisms.", "tokens": [50414, 286, 519, 456, 2203, 281, 312, 4317, 512, 661, 5359, 300, 366, 4077, 281, 22110, 293, 3166, 295, 22110, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11599096467223348, "compression_ratio": 1.5858585858585859, "no_speech_prob": 0.13179421424865723}, {"id": 471, "seek": 260500, "start": 2616.0, "end": 2621.0, "text": " But we didn't define in Darwin SW.", "tokens": [50914, 583, 321, 994, 380, 6964, 294, 30233, 20346, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11599096467223348, "compression_ratio": 1.5858585858585859, "no_speech_prob": 0.13179421424865723}, {"id": 472, "seek": 260500, "start": 2621.0, "end": 2624.0, "text": " I mean, I think they need to be defined.", "tokens": [51164, 286, 914, 11, 286, 519, 436, 643, 281, 312, 7642, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11599096467223348, "compression_ratio": 1.5858585858585859, "no_speech_prob": 0.13179421424865723}, {"id": 473, "seek": 260500, "start": 2624.0, "end": 2629.0, "text": " But those are the kinds of things that could be used as evidence.", "tokens": [51314, 583, 729, 366, 264, 3685, 295, 721, 300, 727, 312, 1143, 382, 4467, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11599096467223348, "compression_ratio": 1.5858585858585859, "no_speech_prob": 0.13179421424865723}, {"id": 474, "seek": 260500, "start": 2629.0, "end": 2633.0, "text": " So I think everyone agrees with that proposal that you just made.", "tokens": [51564, 407, 286, 519, 1518, 26383, 365, 300, 11494, 300, 291, 445, 1027, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11599096467223348, "compression_ratio": 1.5858585858585859, "no_speech_prob": 0.13179421424865723}, {"id": 475, "seek": 263300, "start": 2633.0, "end": 2636.0, "text": " That's one I've talked to anyway.", "tokens": [50364, 663, 311, 472, 286, 600, 2825, 281, 4033, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21212930225190663, "compression_ratio": 1.592885375494071, "no_speech_prob": 0.038251835852861404}, {"id": 476, "seek": 263300, "start": 2636.0, "end": 2640.0, "text": " Right now it's 11.30, and we were going to move on to end vote too.", "tokens": [50514, 1779, 586, 309, 311, 2975, 13, 3446, 11, 293, 321, 645, 516, 281, 1286, 322, 281, 917, 4740, 886, 13, 50714], "temperature": 0.0, "avg_logprob": -0.21212930225190663, "compression_ratio": 1.592885375494071, "no_speech_prob": 0.038251835852861404}, {"id": 477, "seek": 263300, "start": 2640.0, "end": 2645.0, "text": " So that might be a good stopping point, unless there's any other pressing...", "tokens": [50714, 407, 300, 1062, 312, 257, 665, 12767, 935, 11, 5969, 456, 311, 604, 661, 12417, 485, 50964], "temperature": 0.0, "avg_logprob": -0.21212930225190663, "compression_ratio": 1.592885375494071, "no_speech_prob": 0.038251835852861404}, {"id": 478, "seek": 263300, "start": 2645.0, "end": 2653.0, "text": " I just wanted to clarify, and I think I'm not sure if the impression that you've got of people in this room is complete.", "tokens": [50964, 286, 445, 1415, 281, 17594, 11, 293, 286, 519, 286, 478, 406, 988, 498, 264, 9995, 300, 291, 600, 658, 295, 561, 294, 341, 1808, 307, 3566, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21212930225190663, "compression_ratio": 1.592885375494071, "no_speech_prob": 0.038251835852861404}, {"id": 479, "seek": 263300, "start": 2653.0, "end": 2662.0, "text": " In that is that the Darwin core was a synthesis of people focused on observation data, monitoring data,", "tokens": [51364, 682, 300, 307, 300, 264, 30233, 4965, 390, 257, 30252, 295, 561, 5178, 322, 14816, 1412, 11, 11028, 1412, 11, 51814], "temperature": 0.0, "avg_logprob": -0.21212930225190663, "compression_ratio": 1.592885375494071, "no_speech_prob": 0.038251835852861404}, {"id": 480, "seek": 266200, "start": 2662.0, "end": 2666.0, "text": " there's no evidence except what the human saw and then records.", "tokens": [50364, 456, 311, 572, 4467, 3993, 437, 264, 1952, 1866, 293, 550, 7724, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 481, "seek": 266200, "start": 2666.0, "end": 2668.0, "text": " But then there would be the record.", "tokens": [50564, 583, 550, 456, 576, 312, 264, 2136, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 482, "seek": 266200, "start": 2668.0, "end": 2670.0, "text": " Can I ask?", "tokens": [50664, 1664, 286, 1029, 30, 50764], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 483, "seek": 266200, "start": 2670.0, "end": 2675.0, "text": " Or if it's a digital or whatever, and then there's the stuff in the box that could be a physicist.", "tokens": [50764, 1610, 498, 309, 311, 257, 4562, 420, 2035, 11, 293, 550, 456, 311, 264, 1507, 294, 264, 2424, 300, 727, 312, 257, 42466, 13, 51014], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 484, "seek": 266200, "start": 2675.0, "end": 2677.0, "text": " Okay, that's fine, but we...", "tokens": [51014, 1033, 11, 300, 311, 2489, 11, 457, 321, 485, 51114], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 485, "seek": 266200, "start": 2677.0, "end": 2684.0, "text": " This may be a question for Steve, but I mean, it seems like there should be or is at least a philosophical relationship", "tokens": [51114, 639, 815, 312, 257, 1168, 337, 7466, 11, 457, 286, 914, 11, 309, 2544, 411, 456, 820, 312, 420, 307, 412, 1935, 257, 25066, 2480, 51464], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 486, "seek": 266200, "start": 2684.0, "end": 2687.0, "text": " between token and basis of reference. Is that correct?", "tokens": [51464, 1296, 14862, 293, 5143, 295, 6408, 13, 1119, 300, 3006, 30, 51614], "temperature": 0.0, "avg_logprob": -0.23539364554665304, "compression_ratio": 1.6454183266932272, "no_speech_prob": 0.055619560182094574}, {"id": 487, "seek": 268700, "start": 2687.0, "end": 2692.0, "text": " I couldn't hear the whole question.", "tokens": [50364, 286, 2809, 380, 1568, 264, 1379, 1168, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14769377178615994, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.006766422651708126}, {"id": 488, "seek": 268700, "start": 2692.0, "end": 2702.0, "text": " It seems like there's at least a philosophical or underlying relationship between the Darwin core term, basis of record,", "tokens": [50614, 467, 2544, 411, 456, 311, 412, 1935, 257, 25066, 420, 14217, 2480, 1296, 264, 30233, 4965, 1433, 11, 5143, 295, 2136, 11, 51114], "temperature": 0.0, "avg_logprob": -0.14769377178615994, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.006766422651708126}, {"id": 489, "seek": 268700, "start": 2702.0, "end": 2708.0, "text": " and what you guys are referring to as tokens, which is basically a basis for an assertion or a word.", "tokens": [51114, 293, 437, 291, 1074, 366, 13761, 281, 382, 22667, 11, 597, 307, 1936, 257, 5143, 337, 364, 19810, 313, 420, 257, 1349, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14769377178615994, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.006766422651708126}, {"id": 490, "seek": 268700, "start": 2708.0, "end": 2711.0, "text": " I think you were right.", "tokens": [51414, 286, 519, 291, 645, 558, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14769377178615994, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.006766422651708126}, {"id": 491, "seek": 268700, "start": 2711.0, "end": 2715.0, "text": " Yeah, isn't that right, Steve, that you were trying to clarify basis of record?", "tokens": [51564, 865, 11, 1943, 380, 300, 558, 11, 7466, 11, 300, 291, 645, 1382, 281, 17594, 5143, 295, 2136, 30, 51764], "temperature": 0.0, "avg_logprob": -0.14769377178615994, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.006766422651708126}, {"id": 492, "seek": 271500, "start": 2716.0, "end": 2720.0, "text": " Were we trying to clarify basis of record?", "tokens": [50414, 12448, 321, 1382, 281, 17594, 5143, 295, 2136, 30, 50614], "temperature": 0.0, "avg_logprob": -0.11549320391246251, "compression_ratio": 1.5524475524475525, "no_speech_prob": 0.004532119259238243}, {"id": 493, "seek": 271500, "start": 2720.0, "end": 2730.0, "text": " Well, in other words, the difference is though that it's really not the basis of the record,", "tokens": [50614, 1042, 11, 294, 661, 2283, 11, 264, 2649, 307, 1673, 300, 309, 311, 534, 406, 264, 5143, 295, 264, 2136, 11, 51114], "temperature": 0.0, "avg_logprob": -0.11549320391246251, "compression_ratio": 1.5524475524475525, "no_speech_prob": 0.004532119259238243}, {"id": 494, "seek": 271500, "start": 2730.0, "end": 2738.0, "text": " it's the basis of the assertion that a certain individual occurred in a certain place.", "tokens": [51114, 309, 311, 264, 5143, 295, 264, 19810, 313, 300, 257, 1629, 2609, 11068, 294, 257, 1629, 1081, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11549320391246251, "compression_ratio": 1.5524475524475525, "no_speech_prob": 0.004532119259238243}, {"id": 495, "seek": 273800, "start": 2738.0, "end": 2742.0, "text": " And again, basis of record seemed, and Steve, I think...", "tokens": [50364, 400, 797, 11, 5143, 295, 2136, 6576, 11, 293, 7466, 11, 286, 519, 485, 50564], "temperature": 0.0, "avg_logprob": -0.13628004818427852, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.0236497912555933}, {"id": 496, "seek": 273800, "start": 2742.0, "end": 2748.0, "text": " Maybe Steve should say why he didn't use basis of record, but that seemed tied to collection objects.", "tokens": [50564, 2704, 7466, 820, 584, 983, 415, 994, 380, 764, 5143, 295, 2136, 11, 457, 300, 6576, 9601, 281, 5765, 6565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13628004818427852, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.0236497912555933}, {"id": 497, "seek": 273800, "start": 2748.0, "end": 2756.0, "text": " Well, basis of record is another thing that I think is overloaded, because when you look at the possible values for it,", "tokens": [50864, 1042, 11, 5143, 295, 2136, 307, 1071, 551, 300, 286, 519, 307, 28777, 292, 11, 570, 562, 291, 574, 412, 264, 1944, 4190, 337, 309, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13628004818427852, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.0236497912555933}, {"id": 498, "seek": 273800, "start": 2756.0, "end": 2761.0, "text": " it contains things like location, events, identifications.", "tokens": [51264, 309, 8306, 721, 411, 4914, 11, 3931, 11, 2473, 7833, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13628004818427852, "compression_ratio": 1.6201923076923077, "no_speech_prob": 0.0236497912555933}, {"id": 499, "seek": 276100, "start": 2761.0, "end": 2770.0, "text": " So I think part of the problem is what basis of record means isn't exactly clear.", "tokens": [50364, 407, 286, 519, 644, 295, 264, 1154, 307, 437, 5143, 295, 2136, 1355, 1943, 380, 2293, 1850, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1310386848449707, "compression_ratio": 1.303448275862069, "no_speech_prob": 0.0020820230711251497}, {"id": 500, "seek": 276100, "start": 2773.0, "end": 2777.0, "text": " So I promised John that I'd make way for Norman.", "tokens": [50964, 407, 286, 10768, 2619, 300, 286, 1116, 652, 636, 337, 30475, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1310386848449707, "compression_ratio": 1.303448275862069, "no_speech_prob": 0.0020820230711251497}, {"id": 501, "seek": 276100, "start": 2777.0, "end": 2782.0, "text": " I wanted to mention an ontology that Bob Morris developed,", "tokens": [51164, 286, 1415, 281, 2152, 364, 6592, 1793, 300, 6085, 23619, 4743, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1310386848449707, "compression_ratio": 1.303448275862069, "no_speech_prob": 0.0020820230711251497}, {"id": 502, "seek": 278200, "start": 2782.0, "end": 2791.0, "text": " primarily taking Darwin SW and then grafting on some pieces of Roger Hayam's earlier Tadwick ontology", "tokens": [50364, 10029, 1940, 30233, 20346, 293, 550, 1295, 20930, 322, 512, 3755, 295, 17666, 8721, 335, 311, 3071, 314, 345, 16038, 6592, 1793, 50814], "temperature": 0.0, "avg_logprob": -0.10495189217960134, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.01853773556649685}, {"id": 503, "seek": 278200, "start": 2791.0, "end": 2800.0, "text": " for certain components of AOD records, data annotation records.", "tokens": [50814, 337, 1629, 6677, 295, 316, 14632, 7724, 11, 1412, 48654, 7724, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10495189217960134, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.01853773556649685}, {"id": 504, "seek": 278200, "start": 2800.0, "end": 2804.0, "text": " And I told him I wanted to mention it, so I'll just read you what it replied.", "tokens": [51264, 400, 286, 1907, 796, 286, 1415, 281, 2152, 309, 11, 370, 286, 603, 445, 1401, 291, 437, 309, 20345, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10495189217960134, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.01853773556649685}, {"id": 505, "seek": 278200, "start": 2804.0, "end": 2808.0, "text": " If you say anything at all about it, it probably should be that it is an ontology of convenience", "tokens": [51464, 759, 291, 584, 1340, 412, 439, 466, 309, 11, 309, 1391, 820, 312, 300, 309, 307, 364, 6592, 1793, 295, 19283, 51664], "temperature": 0.0, "avg_logprob": -0.10495189217960134, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.01853773556649685}, {"id": 506, "seek": 280800, "start": 2808.0, "end": 2815.0, "text": " for dealing with the concerns of curators largely made by trimming Darwin SW, adding some things from the Tadwick ontologies.", "tokens": [50364, 337, 6260, 365, 264, 7389, 295, 1262, 3391, 11611, 1027, 538, 47212, 30233, 20346, 11, 5127, 512, 721, 490, 264, 314, 345, 16038, 6592, 6204, 13, 50714], "temperature": 0.0, "avg_logprob": -0.101841402053833, "compression_ratio": 1.5042735042735043, "no_speech_prob": 0.08240378648042679}, {"id": 507, "seek": 280800, "start": 2815.0, "end": 2822.0, "text": " And then it goes on to say, I think section undertaking needs a workshop of comparable length to the one in Kansas,", "tokens": [50714, 400, 550, 309, 1709, 322, 281, 584, 11, 286, 519, 3541, 39250, 2203, 257, 13541, 295, 25323, 4641, 281, 264, 472, 294, 19422, 11, 51064], "temperature": 0.0, "avg_logprob": -0.101841402053833, "compression_ratio": 1.5042735042735043, "no_speech_prob": 0.08240378648042679}, {"id": 508, "seek": 280800, "start": 2822.0, "end": 2830.0, "text": " and maybe this is also a viewer's preview of the discussions tomorrow, which would be where do we take this...", "tokens": [51064, 293, 1310, 341, 307, 611, 257, 16767, 311, 14281, 295, 264, 11088, 4153, 11, 597, 576, 312, 689, 360, 321, 747, 341, 485, 51464], "temperature": 0.0, "avg_logprob": -0.101841402053833, "compression_ratio": 1.5042735042735043, "no_speech_prob": 0.08240378648042679}], "language": "en"}