1
00:00:00,000 --> 00:00:05,000
Hi, and welcome to my course on the Jupyter Notebook for Data Science Teams.

2
00:00:05,000 --> 00:00:09,000
I'll just give you a brief overview of the course so you can know what you're getting into.

3
00:00:09,000 --> 00:00:14,000
So we'll start off by doing what you expect, getting Jupyter Notebook set up on your machines.

4
00:00:14,000 --> 00:00:18,000
The second thing I'll go over then is Jupyter Notebook features.

5
00:00:18,000 --> 00:00:21,000
So there's a lot of really interesting things going on with the Jupyter Notebook.

6
00:00:21,000 --> 00:00:25,000
Some of the most useful functionality comes from what's called Notebook Extensions.

7
00:00:25,000 --> 00:00:27,000
So I'll be going over a lot of those.

8
00:00:27,000 --> 00:00:30,000
I'll be showing you how you can use both Python and R in the same Notebook.

9
00:00:30,000 --> 00:00:33,000
So if you have some piece of your analysis that needs to be done on R,

10
00:00:33,000 --> 00:00:36,000
it's very easy to actually do part of it in R, send it back to Python,

11
00:00:36,000 --> 00:00:41,000
or even use R natively as the entire kernel that runs your Jupyter Notebook.

12
00:00:41,000 --> 00:00:45,000
Also, different things like using SQL in the Notebook to query databases,

13
00:00:45,000 --> 00:00:49,000
some really nice post-save hook functionality and widgets,

14
00:00:49,000 --> 00:00:51,000
which I'll just demonstrate right here.

15
00:00:51,000 --> 00:00:56,000
This is an example of a widget where I've created a function that generates data

16
00:00:56,000 --> 00:00:59,000
according to some line, and the green line shows you the actual function

17
00:00:59,000 --> 00:01:04,000
with some noise, and the blue dots are data that gets drawn from this distribution.

18
00:01:04,000 --> 00:01:08,000
So the total number of points is 10, and as I click and drag this off to the right,

19
00:01:08,000 --> 00:01:12,000
increase the number of points, and you can see that the fit dynamically moves around

20
00:01:12,000 --> 00:01:18,000
as I add data points and actually slowly but surely converges on the underlying distribution.

21
00:01:18,000 --> 00:01:22,000
So this is an example of a widget which is very easy to do

22
00:01:22,000 --> 00:01:26,000
and provides lots of functionality for all kinds of data exploration.

23
00:01:26,000 --> 00:01:31,000
Finally, I'll get into sharing the notebooks on a data science team,

24
00:01:31,000 --> 00:01:35,000
so there's a lot of questions you have to consider for your particular situation,

25
00:01:35,000 --> 00:01:39,000
so I'll try to give you a strategic framework so that you can actually identify

26
00:01:39,000 --> 00:01:42,000
what kind of workflow makes sense for your situation.

27
00:01:42,000 --> 00:01:46,000
There's various other things about conceptually breaking up your notebook structure

28
00:01:46,000 --> 00:01:50,000
into lab notebooks and deliverable notebooks, and a lot more that goes into that.

29
00:01:50,000 --> 00:01:53,000
Finally, I'll go through two different data science projects,

30
00:01:53,000 --> 00:01:56,000
which will just demonstrate the principles I talked about above,

31
00:01:56,000 --> 00:02:00,000
and you get to see it in an environment where I'm explaining and going through

32
00:02:00,000 --> 00:02:03,000
how to actually do a data science project from end to end

33
00:02:03,000 --> 00:02:07,000
using all the different techniques I was already talking about.

34
00:02:07,000 --> 00:02:11,000
In this lesson, we'll be installing the R version of Python,

35
00:02:11,000 --> 00:02:14,000
iPython, and Jupyter so that we can run the Jupyter notebook.

36
00:02:14,000 --> 00:02:18,000
The way we run this is by installing the Anaconda distribution.

37
00:02:18,000 --> 00:02:21,000
There are other ways of installing the iPython notebook,

38
00:02:21,000 --> 00:02:24,000
but I recommend the Anaconda for its ease of use.

39
00:02:24,000 --> 00:02:29,000
We'll first go over to any web browser and search for Anaconda Python.

40
00:02:29,000 --> 00:02:34,000
What you'll see here is that the top link is the continuum Anaconda distribution.

41
00:02:34,000 --> 00:02:36,000
Clicking on that takes you right to the downloads page,

42
00:02:36,000 --> 00:02:38,000
and you see that you have different options.

43
00:02:38,000 --> 00:02:43,000
You can get it with Windows, OSX, or Linux, whichever one you prefer.

44
00:02:43,000 --> 00:02:46,000
Since I'm using OSX, I'll click on OSX.

45
00:02:46,000 --> 00:02:50,000
The choice between using Python 2.7 and 3.4 is a tough one.

46
00:02:50,000 --> 00:02:55,000
I'll be using 2.7 just because many of the legacy code bases still use 2.7,

47
00:02:55,000 --> 00:02:59,000
but feel free to, if you're feeling experimental, to go to Python 3.4.

48
00:02:59,000 --> 00:03:02,000
I'll be using this Mac OSX 64-bit one.

49
00:03:02,000 --> 00:03:05,000
If you have a different system, please use that one.

50
00:03:05,000 --> 00:03:08,000
Okay, great. Now that that package has downloaded,

51
00:03:08,000 --> 00:03:12,000
install it by following the instructions on the screen.

52
00:03:12,000 --> 00:03:16,000
So, clicking through and agreeing to various licenses.

53
00:03:16,000 --> 00:03:20,000
And hopefully you get to this stage where it says the installation was successful.

54
00:03:20,000 --> 00:03:22,000
Click Close.

55
00:03:22,000 --> 00:03:24,000
We can close our browser as well.

56
00:03:24,000 --> 00:03:28,000
At this stage, if we typed IPython, it still won't work.

57
00:03:28,000 --> 00:03:32,000
One thing that the graphical interface does is actually adds a command to your bash profile.

58
00:03:32,000 --> 00:03:36,000
So if I were to actually go into vi.bash underscore profile,

59
00:03:36,000 --> 00:03:39,000
the first piece of the profile has been there from before,

60
00:03:39,000 --> 00:03:42,000
but this was added by the Anaconda 2.3 installer,

61
00:03:42,000 --> 00:03:47,000
which exports this path, shows you that the Anaconda folder has been created in my home directory,

62
00:03:47,000 --> 00:03:49,000
and adds that to my path.

63
00:03:49,000 --> 00:03:53,000
So if I type ls, you actually do see the Anaconda directory right here.

64
00:03:53,000 --> 00:03:56,000
This makes it really easy to uninstall Anaconda if you want.

65
00:03:56,000 --> 00:04:00,000
You can remove that line from that path in your bash profile,

66
00:04:00,000 --> 00:04:03,000
and you can delete this folder, and everything should be gone off your system,

67
00:04:03,000 --> 00:04:05,000
and you can use the old system defaults.

68
00:04:05,000 --> 00:04:09,000
But now that we have this, we have to source our bash profile,

69
00:04:09,000 --> 00:04:12,000
and we should now be able to type IPython.

70
00:04:12,000 --> 00:04:17,000
Now that we've run IPython, we see we are running Python 2.7, in this case 0.10.

71
00:04:17,000 --> 00:04:22,000
It's the Anaconda distribution, and this is IPython version 3.2.

72
00:04:22,000 --> 00:04:24,000
So a lot of different numbers here.

73
00:04:24,000 --> 00:04:27,000
The ones that are important are the Python version, which is 2.7,

74
00:04:27,000 --> 00:04:29,000
and the IPython version, which is 3.2.

75
00:04:29,000 --> 00:04:31,000
Now this is actually a bit behind.

76
00:04:31,000 --> 00:04:34,000
So what we're going to do is hit Ctrl-D, and it says, do you really want to exit?

77
00:04:34,000 --> 00:04:36,000
You can either type yes in return,

78
00:04:36,000 --> 00:04:39,000
or you can type Ctrl-D a second time to actually exit it.

79
00:04:39,000 --> 00:04:43,000
But what we'd like to do now is actually update to the most recent version of Anaconda,

80
00:04:43,000 --> 00:04:45,000
so that we have the most recent version.

81
00:04:45,000 --> 00:04:47,000
The way to do this is to type conda.

82
00:04:47,000 --> 00:04:49,000
This is a new command line argument that you have.

83
00:04:49,000 --> 00:04:54,000
The way that we update the Anaconda distribution is by typing conda in various packages.

84
00:04:54,000 --> 00:04:57,000
So in this case, we want to conda, install conda.

85
00:04:57,000 --> 00:05:00,000
What this should do is check to see various things.

86
00:05:00,000 --> 00:05:02,000
This tells us the following packages will be updated.

87
00:05:02,000 --> 00:05:07,000
Conda will go from this version 3.14 to 3.18, conda environment, and so on.

88
00:05:07,000 --> 00:05:11,000
And we would like to set this up, and we will hit yes to this.

89
00:05:11,000 --> 00:05:15,000
It actually takes quite a bit of time to install all of these things from source,

90
00:05:15,000 --> 00:05:19,000
but most of these things are actually pre-compiled, so everything's already completed.

91
00:05:19,000 --> 00:05:22,000
We'd like to also update a number of packages.

92
00:05:22,000 --> 00:05:28,000
So let's conda install Jupyter, and now you can actually chain which packages you'd like to see.

93
00:05:28,000 --> 00:05:35,000
So in this case, we'll install Jupyter, the pandas package, and scikit-learn.

94
00:05:35,000 --> 00:05:37,000
So these are the packages to be updated.

95
00:05:37,000 --> 00:05:41,000
We see that a number of things are going from ipython, which is important,

96
00:05:41,000 --> 00:05:43,000
going from version 3.2 to version 4.0.

97
00:05:43,000 --> 00:05:46,000
We'd like to proceed with that.

98
00:05:46,000 --> 00:05:51,000
I'd like to just say a few words about why I find the Anaconda package to be a useful thing to use.

99
00:05:51,000 --> 00:05:55,000
They make sure that all the packages you've installed will play nicely with each other.

100
00:05:55,000 --> 00:06:01,000
So sometimes if you're using pip by itself, you can actually install dependencies that overlap each other out of place,

101
00:06:01,000 --> 00:06:04,000
so they end up with a conflict when you're trying to import these libraries,

102
00:06:04,000 --> 00:06:08,000
and Anaconda does a really nice job of making sure, checking those dependencies really well.

103
00:06:08,000 --> 00:06:14,000
So now if we type ipython, we should see that we are running ipython 4.0, which we are.

104
00:06:14,000 --> 00:06:17,000
Now we would like to actually check out the ipython notebook,

105
00:06:17,000 --> 00:06:19,000
because that's the part where it really gets interesting.

106
00:06:19,000 --> 00:06:24,000
So let's create an example directory, and from here we can type Jupyter notebook.

107
00:06:25,000 --> 00:06:27,000
Just typing Jupyter notebook, a couple of things happened.

108
00:06:27,000 --> 00:06:29,000
First of all, go back to the terminal.

109
00:06:29,000 --> 00:06:32,000
I typed Jupyter notebook, and ran it.

110
00:06:32,000 --> 00:06:37,000
And a notebook server started from the directory we are in, so a user's jbw example in this case.

111
00:06:37,000 --> 00:06:41,000
So an ipython notebook, which has been started with a Jupyter, is now at this location.

112
00:06:41,000 --> 00:06:45,000
HTTP colon slash slash localhost, in this case, quadruple 8.

113
00:06:45,000 --> 00:06:49,000
And it says here this useful thing, control C to stop this server and shut down all kernels,

114
00:06:49,000 --> 00:06:51,000
and you have to do it twice to skip the confirmation.

115
00:06:51,000 --> 00:06:55,000
Now this starts the server running, and this terminal needs to stay open.

116
00:06:55,000 --> 00:07:01,000
If we go back to this, what it runs is a web server, and it automatically by default opens your default browser.

117
00:07:01,000 --> 00:07:05,000
So in this case, here we are at this location, localhost, quadruple 8, underscore 3.

118
00:07:05,000 --> 00:07:10,000
And if we'd like to start a new notebook, we can click new, Python 2 notebook.

119
00:07:10,000 --> 00:07:12,000
And again, this is referring to which version of Python you're running.

120
00:07:12,000 --> 00:07:15,000
This is a 2 version 3 versus 3.

121
00:07:15,000 --> 00:07:21,000
And we see now that we're running a Jupyter notebook, and we can start typing valid Python code,

122
00:07:21,000 --> 00:07:24,000
and see the output from it right there.

123
00:07:24,000 --> 00:07:26,000
Let's do something a little bit more interesting.

124
00:07:26,000 --> 00:07:31,000
So we import the NumPy library as np, and then print numpy.a range 10.

125
00:07:31,000 --> 00:07:40,000
So we see the first bit of Python code, and we know that we have the installation working just as we hoped.

126
00:07:40,000 --> 00:07:45,000
In this video, we're going to start a GitHub repo to house a data science project.

127
00:07:45,000 --> 00:07:48,000
First, we have to go to github.com.

128
00:07:48,000 --> 00:07:54,000
If you don't have GitHub or Git setup, I highly recommend starting out by picking a username,

129
00:07:54,000 --> 00:07:57,000
by giving your email and creating a GitHub account.

130
00:07:57,000 --> 00:08:02,000
Now, if you have Windows or Linux or Mac operating system,

131
00:08:02,000 --> 00:08:08,000
GitHub itself has a really nice tutorial for how to actually set up Git on your machine and for your setup.

132
00:08:08,000 --> 00:08:09,000
So I recommend doing that.

133
00:08:09,000 --> 00:08:16,000
So once you have a GitHub account, which is free, or if you already have one, click sign in, let's go to the next step.

134
00:08:16,000 --> 00:08:23,000
So you've signed into GitHub, click the plus next to your name in the upper right hand corner, and start a new repository.

135
00:08:23,000 --> 00:08:28,000
I prefer to start a new repository through the GitHub website itself, and then clone it to my local machine.

136
00:08:28,000 --> 00:08:31,000
So that way, the remote connection has already set up.

137
00:08:31,000 --> 00:08:37,000
And that's usually a stumbling block that can be a little bit annoying to overcome if you try to do it the other way around.

138
00:08:37,000 --> 00:08:40,000
In this case, I'm going to be looking at some cold data.

139
00:08:40,000 --> 00:08:43,000
So I'm going to call it cold exploration.

140
00:08:43,000 --> 00:08:46,000
I'm going to give it a quick description.

141
00:08:46,000 --> 00:08:49,000
I'm giving it the description a first look at the cold data.

142
00:08:49,000 --> 00:08:52,000
I'm going to let it be public so anyone can see this repository.

143
00:08:52,000 --> 00:08:55,000
So afterward, you can also see this if you'd like to go to it.

144
00:08:55,000 --> 00:09:00,000
I will initialize this repository with a readme and I will add a gitignore.

145
00:09:00,000 --> 00:09:07,000
A .gitignore file will let you ignore the machine generated code that comes along with various programming languages.

146
00:09:07,000 --> 00:09:13,000
Now Python doesn't have that many, but there is usually a .pyc if you're running a Python file.

147
00:09:13,000 --> 00:09:19,000
I also recommend having a license, especially if it's going to be public, so that you can share your repositories with others.

148
00:09:19,000 --> 00:09:22,000
If you work for a company, obviously you have different licensing concerns.

149
00:09:22,000 --> 00:09:24,000
So then click create repository.

150
00:09:24,000 --> 00:09:25,000
It's as easy as that.

151
00:09:25,000 --> 00:09:30,000
So now I have the cold exploration repository in my GitHub account.

152
00:09:30,000 --> 00:09:35,000
From here, we would like to actually tie this account to our local machine.

153
00:09:35,000 --> 00:09:40,000
So we can copy this text that's just to the right of this SSH tab.

154
00:09:40,000 --> 00:09:46,000
Now, if it doesn't say SSH, if it says HTTPS, I would recommend clicking it to SSH.

155
00:09:46,000 --> 00:09:50,000
And once you do that, copy the text that's in this text box.

156
00:09:50,000 --> 00:09:56,000
Navigate with your terminal to a place that you think is an appropriate spot for this repository.

157
00:09:56,000 --> 00:10:03,000
Type in git clone and paste the text that you just copied from the website itself.

158
00:10:03,000 --> 00:10:08,000
So now we see the license and the readme files that we created on the website itself.

159
00:10:08,000 --> 00:10:17,000
All right, so we have set up our GitHub repository and we've cloned it to our local machine and we're ready to start doing some data science.

160
00:10:17,000 --> 00:10:24,000
In this lesson, I'm going to give you some extra intuition so you can understand what's happening when the Jupyter Notebook is running.

161
00:10:24,000 --> 00:10:29,000
So in my terminal, if I type ls, I get to see the directories now underneath this current directory.

162
00:10:29,000 --> 00:10:31,000
I see deliver, dev and source.

163
00:10:31,000 --> 00:10:36,000
By typing Jupyter Notebook, I again start the Jupyter server.

164
00:10:36,000 --> 00:10:38,000
My default browser is Chrome.

165
00:10:38,000 --> 00:10:41,000
So again, we see those same three directories deliver, dev and source.

166
00:10:41,000 --> 00:10:45,000
If we toggle back to the terminal, we can see several messages.

167
00:10:45,000 --> 00:10:49,000
The first is the directory under which the notebook server has been started.

168
00:10:49,000 --> 00:10:51,000
The second message is the number of active kernels.

169
00:10:51,000 --> 00:10:56,000
The third message is the location that you can point your browser to to find this notebook.

170
00:10:56,000 --> 00:10:59,000
And finally a message to say how to stop this server.

171
00:10:59,000 --> 00:11:06,000
So going back to the notebook itself, if we click on the development branch, we see that there's no notebooks in here.

172
00:11:06,000 --> 00:11:10,000
We can start a notebook by clicking on new and then clicking on Python 2.

173
00:11:10,000 --> 00:11:13,000
So after clicking new, we see a new tab appear.

174
00:11:13,000 --> 00:11:18,000
It's currently named untitled and the last checkpoint comes from a few seconds ago.

175
00:11:18,000 --> 00:11:19,000
So let's type a few things.

176
00:11:19,000 --> 00:11:23,000
So let's just say first as a variable is equal to the 5.0.

177
00:11:23,000 --> 00:11:27,000
I execute that cell by holding down shift and hitting return.

178
00:11:27,000 --> 00:11:30,000
When I do that, a new cell appears beneath it.

179
00:11:30,000 --> 00:11:39,000
And as I type a second variable and label it say 23.0, again hitting return with the shift key produces another cell beneath it.

180
00:11:39,000 --> 00:11:43,000
So I now have two variables, one named first and one named second.

181
00:11:43,000 --> 00:11:49,000
And there's unsaved changes, which means if I lose this current browser, I will lose the changes that happened from the last time it was saved.

182
00:11:49,000 --> 00:11:51,000
In this case, there's nothing that's been saved.

183
00:11:51,000 --> 00:11:53,000
So let me go ahead and save this right now.

184
00:11:53,000 --> 00:11:54,000
There's two ways of doing this.

185
00:11:54,000 --> 00:11:59,000
One, typing command S if you're on the Mac or control S on Windows, which I just did.

186
00:11:59,000 --> 00:12:03,000
Or you can click this save disk and it will also save it.

187
00:12:03,000 --> 00:12:07,000
Now that it's been saved and there's no unsaved changes.

188
00:12:07,000 --> 00:12:18,000
If I close this tab, or if I even close the whole browser by quitting the Chrome browser, all of the actual information has been stored in the kernel itself.

189
00:12:18,000 --> 00:12:24,000
In other words, there's this kernel and everything that's happened with the kernel is being stored in state by this kernel.

190
00:12:24,000 --> 00:12:31,000
This means if I open up a brand new version of Chrome and I go to where the notebook is running from the previous message before.

191
00:12:31,000 --> 00:12:36,000
I copied that with control C, go back to Chrome browser and type it in here.

192
00:12:36,000 --> 00:12:39,000
I go back to the exact view we had before.

193
00:12:39,000 --> 00:12:41,000
Clicking on Dev, because that's where we were.

194
00:12:41,000 --> 00:12:45,000
We actually see that the untitled IPython notebook is actually still running.

195
00:12:45,000 --> 00:12:50,000
So if we click on this, we reattach the browser to the underlying kernel.

196
00:12:50,000 --> 00:12:56,000
So if you have saved your notebook as you work and you close the browser, the work still remains in memory.

197
00:12:56,000 --> 00:13:01,000
So if I say print first comma second, now we see the actual results is here.

198
00:13:01,000 --> 00:13:03,000
So this is all been saved.

199
00:13:03,000 --> 00:13:09,000
And that's one interesting thing that you should know is that the browser itself is a front end to what's really going on in the kernel.

200
00:13:09,000 --> 00:13:16,000
Now, the converse to this is what happens if I completely close and shut down the server.

201
00:13:16,000 --> 00:13:19,000
So I hit control C twice and shut down the kernels.

202
00:13:19,000 --> 00:13:21,000
So all the kernels have been shutting down.

203
00:13:21,000 --> 00:13:26,000
So going back to the browser, you see a message that says connection to the notebook server cannot be established.

204
00:13:26,000 --> 00:13:30,000
Let's continue to try to reconnect, but you won't be able to run any code.

205
00:13:30,000 --> 00:13:40,000
So in this case, if I try to do something, say I want to say first times second and execute this and shift enter, nothing happens.

206
00:13:40,000 --> 00:13:43,000
And this is what you see when it's trying to connect to the kernel and it's failing to.

207
00:13:43,000 --> 00:13:49,000
So this is the part where it actually needs to be running and needs to be continually talking to your browser.

208
00:13:49,000 --> 00:13:54,000
Unfortunately, restarting the kernel does not give us back to where we were before.

209
00:13:54,000 --> 00:14:04,000
So here I can try to reload this notebook and we still see what we had previously done, but watch what happens when I try to run this third cell.

210
00:14:04,000 --> 00:14:08,000
The name first is not defined and the input name of the cell one to one.

211
00:14:08,000 --> 00:14:14,000
So the kernel has completely restarted as you saw me do in the terminal, which means that now we have to start from the beginning.

212
00:14:14,000 --> 00:14:21,000
And now everything has been stored in state saving it keeps it so that the kernel is now running in the background.

213
00:14:21,000 --> 00:14:23,000
Hopefully that gave you a little bit of insight into what's happening.

214
00:14:23,000 --> 00:14:28,000
The browser acts as a front end to this process that's running in the back end on this terminal.

215
00:14:28,000 --> 00:14:41,000
The browser can be closed or blown away after you've saved all of the changes that you've made, but the kernel cannot be the kernel has to stay running if you want to keep the changes that you've done in memory.

216
00:14:41,000 --> 00:14:45,000
In this lesson, we'll be talking about Jupyter notebook extensions.

217
00:14:46,000 --> 00:14:53,000
Notebook extensions, as the name suggests, are extensions to the capabilities that the Jupyter notebook already comes with.

218
00:14:53,000 --> 00:14:57,000
Now there's many different ways that you can actually extend the behavior of a Jupyter notebook.

219
00:14:57,000 --> 00:14:59,000
I'm going to show you just two.

220
00:14:59,000 --> 00:15:03,000
The first extension that I'll show you is called Jupyter Pivot Tables.

221
00:15:03,000 --> 00:15:07,000
And if you click on this link here, you'll see that you go to this website.

222
00:15:07,000 --> 00:15:13,000
Nicholas.crucian.com slash content 2015-09 Jupyter Pivot Tables.

223
00:15:13,000 --> 00:15:17,000
And this allows for drag and drop pivot tables and charts.

224
00:15:17,000 --> 00:15:20,000
And this write-up he has is actually a really nice write-up.

225
00:15:20,000 --> 00:15:27,000
I recommend you reading and watching this video as well because he explains in some detail how you can actually use his extension.

226
00:15:27,000 --> 00:15:33,000
To install this, all you have to do is go to this pip install command.

227
00:15:33,000 --> 00:15:40,000
So copy pip install pivot table JS and run that command in your terminal.

228
00:15:40,000 --> 00:15:43,000
So it's successfully installed the pivot table JS.

229
00:15:43,000 --> 00:15:45,000
We go back to our notebook.

230
00:15:45,000 --> 00:15:55,000
We can now run the cells that import both pandas and numpy and this command, which is from pivot table JS import pivot UI.

231
00:15:55,000 --> 00:15:58,000
So that loaded correctly without any errors.

232
00:15:58,000 --> 00:16:01,000
So we have now loaded this extension.

233
00:16:01,000 --> 00:16:09,000
As of Jupyter 4.0, the preferred way of installing notebook extensions is through a pip install of the extension.

234
00:16:09,000 --> 00:16:13,000
There are other ways of doing it as well and I'll show you a second way at the end of this video.

235
00:16:13,000 --> 00:16:18,000
So let's actually take a look at some data with this pivot table extension.

236
00:16:18,000 --> 00:16:24,000
Go to HTTPS colon slash slash data dot austintexas.gov.

237
00:16:24,000 --> 00:16:30,000
In this website, we're going to go down and look at the restaurant inspection scores.

238
00:16:30,000 --> 00:16:33,000
From this, we will export data.

239
00:16:33,000 --> 00:16:35,000
The format we want is CSV.

240
00:16:35,000 --> 00:16:40,000
We do want it to go into our data folder and it's called restaurant inspection scores.

241
00:16:40,000 --> 00:16:42,000
Return to save that.

242
00:16:42,000 --> 00:16:45,000
You can now close this tab and go back to our notebook.

243
00:16:45,000 --> 00:16:50,000
Now that we've downloaded the CSV file, let's read it into pandas data frame.

244
00:16:50,000 --> 00:16:59,000
I'm going to split the cell at the current place where it's blinking by typing control shift minus because I want to run this on just one cell by itself.

245
00:16:59,000 --> 00:17:05,000
So reselecting that cell, I now hit shift and return and it correctly loads in the data frame.

246
00:17:05,000 --> 00:17:10,000
So ways to check that is actually look at what the top of this data frame looks like.

247
00:17:10,000 --> 00:17:19,000
We see that the restaurant name, the zip code, inspection date, the score, the address, facility ID and the process description actually looks like it's been read in correctly.

248
00:17:19,000 --> 00:17:25,000
One thing you will notice is that the address has return characters in it because standard address has multiple lines.

249
00:17:25,000 --> 00:17:27,000
And I'm actually going to be okay with that.

250
00:17:27,000 --> 00:17:32,000
I'm going to say I would like to keep the address on one line in the data frame, not have that split up in different ways.

251
00:17:32,000 --> 00:17:39,000
So let's take a look at what we get when we look at just the data frame itself is pivot underscore UI.

252
00:17:39,000 --> 00:17:43,000
So we've imported pivot underscore UI up here in the first cell.

253
00:17:43,000 --> 00:17:45,000
Let's execute the cell here.

254
00:17:45,000 --> 00:17:47,000
Now a number of things happened in the background.

255
00:17:47,000 --> 00:17:52,000
But what you end up seeing, we close this window down here that shows what we downloaded.

256
00:17:52,000 --> 00:17:56,000
And I will actually toggle this toolbar for now.

257
00:17:56,000 --> 00:17:58,000
So we can actually see a bit more.

258
00:17:58,000 --> 00:18:02,000
We have the various columns of the data frame available on the top here.

259
00:18:02,000 --> 00:18:04,000
So zip code, inspection date, score.

260
00:18:04,000 --> 00:18:07,000
They are now dragable into these two places.

261
00:18:07,000 --> 00:18:08,000
So let's do that.

262
00:18:08,000 --> 00:18:12,000
Let's actually drag score along the top.

263
00:18:12,000 --> 00:18:17,000
Let's see if there's a relationship between the zip code of a restaurant and the score.

264
00:18:17,000 --> 00:18:24,000
So just by dragging those two columns in, we see that there are, for each of these zip codes, different scores that have been given to the restaurant.

265
00:18:24,000 --> 00:18:28,000
Of course, a really good score is a 100 for the health score.

266
00:18:28,000 --> 00:18:33,000
And we can actually scroll down and take a look at this data in a really intuitive way.

267
00:18:33,000 --> 00:18:37,000
This looks pretty neat, but there's a lot of numbers going on.

268
00:18:37,000 --> 00:18:39,000
It's actually kind of hard to read.

269
00:18:39,000 --> 00:18:44,000
So one thing we can do is actually change the output type from table to something else like a heat map.

270
00:18:44,000 --> 00:18:51,000
So this does the same data as we saw before, but it actually highlights the outlying points that are large with a darker color.

271
00:18:51,000 --> 00:18:56,000
So now by eye, you can visually see the different relationships between these two variables.

272
00:18:56,000 --> 00:18:58,000
I still think this is actually a little bit too big.

273
00:18:58,000 --> 00:19:05,000
So I'll give one extra hint of taking data that actually has a lot of different granular pieces.

274
00:19:05,000 --> 00:19:14,000
So let's take this very granular number across the top and bin it by something, let's say five to give us a little bit less granularity.

275
00:19:14,000 --> 00:19:16,000
So here's some code that will actually do that.

276
00:19:16,000 --> 00:19:21,000
So we're going to create a new column in this data frame called bin score for bin to score.

277
00:19:21,000 --> 00:19:31,000
I'm going to use a pandas function called cut, which will now cut up these column df.score into bins that go from 30 to 100,

278
00:19:31,000 --> 00:19:37,000
because no b.a range is not inclusive of the last data point and stepping by five.

279
00:19:37,000 --> 00:19:39,000
So I'm going to run this cell.

280
00:19:39,000 --> 00:19:43,000
It's going to create a data frame column named bin score.

281
00:19:43,000 --> 00:19:46,000
And let's see what this one looks like.

282
00:19:46,000 --> 00:19:51,000
We can drag bin score along the x-axis here and zip code along the y-axis.

283
00:19:51,000 --> 00:20:00,000
We now see that the binned scores are now counting everything that has a zip code off to the left and any score within a certain range.

284
00:20:00,000 --> 00:20:02,000
In a range of five.

285
00:20:02,000 --> 00:20:04,000
We can then also take a look at this.

286
00:20:04,000 --> 00:20:06,000
Instead of a table, we can look at it as a heat map.

287
00:20:06,000 --> 00:20:11,000
You can also see if it looks okay in terms of a bar chart, for example.

288
00:20:11,000 --> 00:20:15,000
And this doesn't quite make sense, but there's many different things that are different here.

289
00:20:15,000 --> 00:20:19,000
You can actually look at tree map, for example.

290
00:20:19,000 --> 00:20:25,000
So the various visualizations that are available to you may or may not make sense to the data that you're looking at.

291
00:20:25,000 --> 00:20:34,000
But the availability of this is actually a really nice extension to the notebook capability that Jupyter already comes with.

292
00:20:34,000 --> 00:20:39,000
Alright, so picking up on where the last video left off, notebook extensions.

293
00:20:39,000 --> 00:20:41,000
We've already installed one extension.

294
00:20:41,000 --> 00:20:43,000
This is the pivot table extension.

295
00:20:43,000 --> 00:20:47,000
It's one of the extensions that I'd like to highlight for this video.

296
00:20:47,000 --> 00:20:51,000
And it actually comes from this URL here.

297
00:20:51,000 --> 00:20:55,000
I want to turn this into, let me just show you this real quick.

298
00:20:55,000 --> 00:20:59,000
This code block is currently set as code.

299
00:20:59,000 --> 00:21:01,000
I'd like to actually change it to mark down.

300
00:21:01,000 --> 00:21:02,000
There's two ways to do that.

301
00:21:02,000 --> 00:21:10,000
By clicking on the toolbar like I just did, or by typing M when this cell is selected in this gray circle right now.

302
00:21:10,000 --> 00:21:13,000
If I type Y, it would turn back to code.

303
00:21:13,000 --> 00:21:17,000
So I just typed Y, you saw the drop down menu turned to code.

304
00:21:17,000 --> 00:21:23,000
And since it's still selected with a gray box, I can type M and it goes to mark down.

305
00:21:23,000 --> 00:21:29,000
So I want it marked down so that when I click this, I can actually open a new tab.

306
00:21:29,000 --> 00:21:33,000
So the Jupyter slideshow extension is this GitHub repo right here.

307
00:21:33,000 --> 00:21:39,000
It has a lot of really interesting capabilities that I will be showing you at the very end of this course.

308
00:21:39,000 --> 00:21:49,000
I'll be using the rise Jupyter slideshow extension to help us make a final slideshow presentation out of some of our data science projects.

309
00:21:49,000 --> 00:21:56,000
To install this notebook extension, it says to simply run python setup.py install from the rise repository.

310
00:21:56,000 --> 00:22:00,000
Now this means we actually have to first download this extension code.

311
00:22:00,000 --> 00:22:03,000
So this isn't done in the usual PIP install way.

312
00:22:03,000 --> 00:22:07,000
This is done by choosing the SSH version here at the top of the page.

313
00:22:07,000 --> 00:22:09,000
Selecting this by clicking once.

314
00:22:09,000 --> 00:22:14,000
GitHub actually makes it so that the entire thing is highlighted so you can now command C to copy this.

315
00:22:14,000 --> 00:22:17,000
Go to your terminal.

316
00:22:17,000 --> 00:22:29,000
And at this point, if you don't have a folder for your GitHub repositories that you just grabbed from wild, basically, I would recommend creating one.

317
00:22:29,000 --> 00:22:35,000
So we type git clone and then paste in the code we had copied from GitHub web page.

318
00:22:35,000 --> 00:22:38,000
So it clones into this thing called rise.

319
00:22:38,000 --> 00:22:40,000
Let's CD into this.

320
00:22:40,000 --> 00:22:43,000
We see various things here, the live reveal package, Jason and so on.

321
00:22:43,000 --> 00:22:46,000
Let's go back to the GitHub page.

322
00:22:46,000 --> 00:22:49,000
This is we simply run python setup.py install.

323
00:22:49,000 --> 00:22:52,000
So I'll copy that code and paste.

324
00:22:52,000 --> 00:22:58,000
Okay, so we have now installed this live reveal.js notebook extension.

325
00:22:58,000 --> 00:23:00,000
So we go back to our notebook.

326
00:23:00,000 --> 00:23:07,000
We see that there's an extra toolbar cell here, which has something different than we normally see, including a slideshow option.

327
00:23:07,000 --> 00:23:13,000
And we actually need to restart this notebook to actually get the ability to make this look like a slideshow.

328
00:23:13,000 --> 00:23:16,000
So let me go ahead and do that.

329
00:23:16,000 --> 00:23:21,000
I'll do save and checkpoint and then close and halt.

330
00:23:21,000 --> 00:23:26,000
I'll go back to where it's running in the terminal and hit control C once.

331
00:23:26,000 --> 00:23:29,000
It says it's currently running, shut down the server, yes or no.

332
00:23:29,000 --> 00:23:32,000
If you wait too long, it'll actually say I didn't see an answer.

333
00:23:32,000 --> 00:23:34,000
So I'm just going to assume you did that by mistake.

334
00:23:34,000 --> 00:23:37,000
We actually do want to quit this.

335
00:23:37,000 --> 00:23:39,000
So we'll do control C twice.

336
00:23:39,000 --> 00:23:41,000
You can have also selected why.

337
00:23:41,000 --> 00:23:43,000
So we shut down all the kernels.

338
00:23:43,000 --> 00:23:46,000
And this thing, if I reload this should not be available.

339
00:23:46,000 --> 00:23:51,000
Let's rerun Jupyter notebook and it will give us a new version of this exact thing.

340
00:23:51,000 --> 00:23:53,000
Click notebook extensions.

341
00:23:53,000 --> 00:23:58,000
And now you still see this toolbar here with the currently being non the slideshow option,

342
00:23:58,000 --> 00:24:01,000
but you also have a new button off to the right.

343
00:24:01,000 --> 00:24:05,000
So let's actually click this and click the slideshow option.

344
00:24:05,000 --> 00:24:12,000
If you'd actually like to turn one of your notebooks into a slideshow, the functionality is now at your fingertips.

345
00:24:12,000 --> 00:24:17,000
And if you don't want to see all these extra cell toolbars, you can always put this back to none.

346
00:24:17,000 --> 00:24:18,000
They should be saved.

347
00:24:18,000 --> 00:24:22,000
So any clicking slideshow again, the fact that these are all slides has been preserved.

348
00:24:22,000 --> 00:24:29,000
To look at the slideshow itself, we just click this button and type into the right gives you the different slides.

349
00:24:29,000 --> 00:24:36,000
And one interesting thing about this or one thing that I think is very, very useful is that this is not just a rendered notebook of this.

350
00:24:36,000 --> 00:24:41,000
This is actually a live cell that we can actually import and actually run new code.

351
00:24:41,000 --> 00:24:46,000
So I just ran that piece of Python code during the slideshow while it's up.

352
00:24:46,000 --> 00:24:51,000
So this is very nice for interactive demonstrations.

353
00:24:52,000 --> 00:24:59,000
In this video, I'll be showing you how to actually query SQL databases from the Jupyter notebook itself.

354
00:24:59,000 --> 00:25:04,000
A lot of enterprise data is stored in databases, so dealing with them will be part of your everyday job.

355
00:25:04,000 --> 00:25:11,000
The Jupyter notebook makes it really nice to be able to document very clearly the SQL queries that you are creating.

356
00:25:11,000 --> 00:25:19,000
So I recommend if you're going to be using SQL connections using a Jupyter notebook extension called ipython SQL.

357
00:25:19,000 --> 00:25:24,000
It's installed by typing pip install ipython dash SQL.

358
00:25:24,000 --> 00:25:33,000
Once you install that, you then have access to an extension that you can load by simply typing percent load extension space SQL.

359
00:25:33,000 --> 00:25:37,000
When you run this cell, it actually loads in this magic extension.

360
00:25:37,000 --> 00:25:42,000
It gives you a number of warning signs, but these are just warnings. The package will still work just fine.

361
00:25:42,000 --> 00:25:48,000
This next line percent config will actually configure our ipython SQL extension.

362
00:25:48,000 --> 00:25:57,000
And what this configuration does, we say SQL magic, we would like to automatically return results that are a table as a pandas data frame.

363
00:25:57,000 --> 00:26:07,000
You don't have to do this, but I recommend it because most of the time you'd actually like to take the data you've queried the database from and transform it and use it in the standard data science tools.

364
00:26:07,000 --> 00:26:09,000
So I'll run that command as well.

365
00:26:09,000 --> 00:26:15,000
Next import pandas and for this demonstration, I'll be using SQL lite.

366
00:26:15,000 --> 00:26:19,000
You can use any of the standard SQL engine connections.

367
00:26:19,000 --> 00:26:24,000
I'm just using SQL lite because it's a simple and easy database to run with for an example.

368
00:26:24,000 --> 00:26:29,000
This next cell, I'm actually going to create a table and put some data into it.

369
00:26:29,000 --> 00:26:38,000
So if you're familiar with SQL, you'll notice that everything below the first line of this cell is SQL commands that leaves this top line to be explained.

370
00:26:38,000 --> 00:26:42,000
So what we have here is a double percent sign and then SQL.

371
00:26:42,000 --> 00:26:45,000
This is how you call what's called a cell magic.

372
00:26:45,000 --> 00:26:56,000
If I hit tab while I'm at the end of these double percent sign, I will see a little pop up that tells us of all the different options we can have to change this into a cell magic.

373
00:26:56,000 --> 00:27:03,000
When I say cell magic, what this means is that this is a special flag that tells ipython that something different is going to happen for this entire cell.

374
00:27:03,000 --> 00:27:07,000
In this case, we're telling it everything after this first line is going to be a SQL query.

375
00:27:07,000 --> 00:27:09,000
As you can tell, there's other ways you can do this as well.

376
00:27:09,000 --> 00:27:11,000
You can have HTML, you can have bash.

377
00:27:11,000 --> 00:27:15,000
There's various other options as well, but I'm just showing you right now the SQL one.

378
00:27:15,000 --> 00:27:19,000
Now this is how you connect to a SQL database that's just stored in memory.

379
00:27:19,000 --> 00:27:27,000
If you have a different package, a different engine, then you can use the various documentation to tell you which connection you should use.

380
00:27:27,000 --> 00:27:30,000
So we're going to create a very simple small table called presidents.

381
00:27:30,000 --> 00:27:35,000
We're going to have first and last name and we're going to include the year that they were born.

382
00:27:35,000 --> 00:27:40,000
And I just have a random sampling of about 10 US presidents here.

383
00:27:40,000 --> 00:27:44,000
So running this cell, we get some output here that says one row is affected.

384
00:27:44,000 --> 00:27:46,000
We've inserted values into this table.

385
00:27:46,000 --> 00:27:52,000
And now we can actually run a SQL command that's in inline again with a single percent.

386
00:27:52,000 --> 00:27:55,000
When you have this command here, it says everything after it will be SQL.

387
00:27:55,000 --> 00:28:02,000
So we're going to store an object called later presidents, the SQL command and the results that come from the SQL query.

388
00:28:02,000 --> 00:28:09,000
The SQL query being select everything from the presidents table where the year of birth was later than 1825.

389
00:28:09,000 --> 00:28:12,000
And then I'm going to show you what that looks like by typing it there.

390
00:28:12,000 --> 00:28:18,000
So we see that there were three presidents that were born in that table after 1825.

391
00:28:18,000 --> 00:28:24,000
And if we took a look at the type of this return, we will see that it is actually a pandas core data frame.

392
00:28:24,000 --> 00:28:28,000
So we have returned a SQL query into a pandas data frame.

393
00:28:28,000 --> 00:28:33,000
And now we can use all of the normal tools and functionality of pandas directly.

394
00:28:33,000 --> 00:28:39,000
If we would like to write out this into a file, we can do that by doing this SQL three command here.

395
00:28:39,000 --> 00:28:41,000
So we make a connection to a new file.

396
00:28:41,000 --> 00:28:49,000
And then you run the pandas data frame method to SQL and say, we'll write out the presidents table to the connection.

397
00:28:49,000 --> 00:28:57,000
Now, if you don't want to use cell magic in this way, you can also use pandas directly to query our SQL database.

398
00:28:57,000 --> 00:29:01,000
So I'll show you how to do that from reading in that file that we just wrote out.

399
00:29:01,000 --> 00:29:05,000
So we're going to connect it out to this presidents SQL output.

400
00:29:05,000 --> 00:29:08,000
We're going to now create a cursor that connects to that connection.

401
00:29:08,000 --> 00:29:14,000
And we will create a new data frame by doing the pandas function read SQL.

402
00:29:14,000 --> 00:29:19,000
If you hit shift tab while your cursor is inside the parentheses, you get to see the various calls here.

403
00:29:19,000 --> 00:29:25,000
So we have the SQL command, you're giving it the SQL, then you're following it with the connection.

404
00:29:25,000 --> 00:29:30,000
And then everything else can be these many other options that you have to really customize it.

405
00:29:30,000 --> 00:29:36,000
And once you've done that, be sure to remember to close the connection by doing com.close.

406
00:29:36,000 --> 00:29:41,000
So the new data frame should have everything that we stored in the previous query.

407
00:29:41,000 --> 00:29:45,000
So the three presidents that we saved from above.

408
00:29:45,000 --> 00:29:49,000
And again, this is a data frame that was returned from that.

409
00:29:49,000 --> 00:29:54,000
So I just showed you two different ways that you can query databases.

410
00:29:54,000 --> 00:29:59,000
You can query them with an inline magic, or you can query them through pandas directly.

411
00:29:59,000 --> 00:30:10,000
And either one will return to a pandas data frame so that you can actually use the output in some exploratory data analysis or your full-fledged project.

412
00:30:10,000 --> 00:30:16,000
In this video, we'll be talking about how to actually use R in the Jupyter Notebook ecosystem.

413
00:30:16,000 --> 00:30:22,000
Previously, we talked about how we can actually set up different Python and R environments.

414
00:30:22,000 --> 00:30:26,000
To set up a unique conda environment for Python 2, for example,

415
00:30:26,000 --> 00:30:33,000
we can do conda create minus n for name pi2, for example, just as a descriptive name that you could use.

416
00:30:33,000 --> 00:30:38,000
We set the Python version to be equal to 2, and then the other packages that we would like to install.

417
00:30:38,000 --> 00:30:41,000
So anaconda, Jupyter itself, notebook.

418
00:30:41,000 --> 00:30:44,000
We do the same thing for the Python 3 environment.

419
00:30:44,000 --> 00:30:50,000
So conda create with a different name, Python 3, for example, and setting the Python version equaling to 3.

420
00:30:50,000 --> 00:30:53,000
We also do the same thing when we want to do an R environment.

421
00:30:53,000 --> 00:30:57,000
So in this case, conda create minus n, and we're going to call this Jupyter underscore R.

422
00:30:57,000 --> 00:31:06,000
And with creating the channel by minus C, R tells Jupyter and tells conda that you're actually creating an R kernel as well as the default other ones.

423
00:31:06,000 --> 00:31:12,000
And this creates the R kernel so that the Jupyter Notebook can actually run R natively,

424
00:31:12,000 --> 00:31:17,000
as well as installing a number of different packages that it thinks are both recommended and essential.

425
00:31:17,000 --> 00:31:20,000
And finally, a Python package called rpi2.

426
00:31:20,000 --> 00:31:27,000
The way to activate these commands is you say source activate and then the name of the environment that you created.

427
00:31:27,000 --> 00:31:30,000
And when you're done with it, source deactivate.

428
00:31:30,000 --> 00:31:36,000
And if you ever forget which environments you've actually installed or what the names you used were, you can do conda environment list.

429
00:31:36,000 --> 00:31:40,000
Let's do that to start with conda env list.

430
00:31:40,000 --> 00:31:44,000
And we see that there are four different environments installed.

431
00:31:44,000 --> 00:31:49,000
There's the root one, which doesn't really qualify as an environment, but then we have pi2, pi3, and Jupyter R.

432
00:31:49,000 --> 00:31:56,000
So let's source activate pi3 and say Jupyter Notebook.

433
00:31:56,000 --> 00:31:59,000
Once we start that, we can start a Python Notebook.

434
00:31:59,000 --> 00:32:06,000
And we see in the upper right-hand corner, not only a blue flag that says using the pi3 kernel just for a second before it flashed away,

435
00:32:06,000 --> 00:32:10,000
you actually see that it types Python 3 in the upper right-hand corner.

436
00:32:10,000 --> 00:32:15,000
Let's verify that by doing a print 5 plus 5 as a statement and as we can do in Python 2.

437
00:32:15,000 --> 00:32:17,000
And this doesn't work in Python 3.

438
00:32:17,000 --> 00:32:20,000
The syntax for Python 3 is with parentheses.

439
00:32:20,000 --> 00:32:23,000
All right, so we are using Python 3.

440
00:32:23,000 --> 00:32:28,000
Let's close and halt this and shut down the server by hitting control C twice.

441
00:32:28,000 --> 00:32:33,000
We can tell that we're using Python 3 because pi3 is at the beginning of our terminal screen right there.

442
00:32:33,000 --> 00:32:36,000
So I have to say source deactivate.

443
00:32:36,000 --> 00:32:38,000
Again, conda env list.

444
00:32:38,000 --> 00:32:43,000
Let's switch to Jupyter.

445
00:32:43,000 --> 00:32:46,000
The command is the same Jupyter Notebook.

446
00:32:46,000 --> 00:32:50,000
Now we can click this pure R example and it loads up R.

447
00:32:50,000 --> 00:32:56,000
Just in case you're curious, we can go back to this home directory and create a new, in this case, R.

448
00:32:56,000 --> 00:33:00,000
And this is an R kernel running natively.

449
00:33:00,000 --> 00:33:04,000
So you can tell again, look in the upper right-hand corner, not only is it not using Python,

450
00:33:04,000 --> 00:33:08,000
it's actually using the R kernel natively for this entire notebook.

451
00:33:08,000 --> 00:33:10,000
Let's go back to this pure R example.

452
00:33:10,000 --> 00:33:12,000
So what is it that R can do?

453
00:33:12,000 --> 00:33:16,000
R is a language that has some design choices that are slightly different than Python,

454
00:33:16,000 --> 00:33:20,000
but it does have a huge statistics library packages.

455
00:33:20,000 --> 00:33:25,000
So you load them in and everything you'll be done in this notebook will be actual R code itself.

456
00:33:25,000 --> 00:33:28,000
And again, just looking in the upper-hand corner, this is now R code.

457
00:33:28,000 --> 00:33:30,000
I loaded a few libraries here.

458
00:33:30,000 --> 00:33:36,000
These are some standard, actually really nice libraries in R, the plier package and ggplot2.

459
00:33:36,000 --> 00:33:43,000
This economics data comes when you load in the plier library and you see the head of this economics data.

460
00:33:43,000 --> 00:33:48,000
You can create a ggplot command by doing this R code here.

461
00:33:48,000 --> 00:33:58,000
And just like with the Jupyter Notebook, we're using Python, we see inline plotting so that all of the workflow is in the same really nice way

462
00:33:58,000 --> 00:34:05,000
where you can do this piecemeal exploring by looking at a single piece of R code in the output.

463
00:34:05,000 --> 00:34:07,000
Let's close and save this.

464
00:34:07,000 --> 00:34:11,000
And now let's open up this Rpy2 example.

465
00:34:11,000 --> 00:34:18,000
We are now running again a Python 2 kernel and we're actually using the Jupyter R environment.

466
00:34:18,000 --> 00:34:22,000
So Jupyter R environment can run Python and it can run R itself.

467
00:34:22,000 --> 00:34:25,000
It's running either one depending on what you started the notebook as.

468
00:34:25,000 --> 00:34:27,000
So we're running this one as a Python notebook.

469
00:34:27,000 --> 00:34:31,000
But here's a really nice feature of the Jupyter Notebook.

470
00:34:31,000 --> 00:34:36,000
You can intermingle Python code and R code in the same notebook.

471
00:34:36,000 --> 00:34:38,000
I'll show you how this works.

472
00:34:38,000 --> 00:34:40,000
So the top here importing numpy as NP.

473
00:34:40,000 --> 00:34:46,000
So again, just Python code, we're creating X and Y where X is this a range.

474
00:34:46,000 --> 00:34:53,000
Let's just look at what X is an array from zero to nine and Y is some random number plus the X variable.

475
00:34:53,000 --> 00:34:59,000
We import this library Rpy2 and load this extension Rpy2.ipython.

476
00:34:59,000 --> 00:35:05,000
So we load it by doing this percent magic percent load extension Rpy2.ipython.

477
00:35:05,000 --> 00:35:08,000
And you can do this in a cell that has other code.

478
00:35:08,000 --> 00:35:10,000
You don't have to make this a single cell.

479
00:35:10,000 --> 00:35:17,000
Just wrote it five plus five just so you can see that we've loaded in an extension and we have this other code running as well.

480
00:35:17,000 --> 00:35:22,000
So we have these two numpy arrays, a capital X and a capital Y.

481
00:35:22,000 --> 00:35:28,000
If we would actually like to do some analysis in R and then push something back into Python,

482
00:35:28,000 --> 00:35:31,000
we do that by now doing a thing called a cell magic.

483
00:35:31,000 --> 00:35:36,000
So cell magics are known by having a double percent sign at the very beginning of a cell.

484
00:35:36,000 --> 00:35:41,000
That means that this top line is a special thing that in this case we're having it.

485
00:35:41,000 --> 00:35:43,000
There's HTML and bash and various other options.

486
00:35:43,000 --> 00:35:50,000
We are using the R option and we are sending in with this input X and Y from the Python environment.

487
00:35:50,000 --> 00:35:58,000
So we are sending to R the two numpy arrays and we would like to get back from R this thing called XY coefficient.

488
00:35:58,000 --> 00:36:01,000
Everything else in this cell is R code.

489
00:36:01,000 --> 00:36:06,000
So XYLM is equal to linear model of Y goes as X.

490
00:36:06,000 --> 00:36:14,000
XY coefficient which we will be returning back to Python after this cell completes is the coefficients of this model.

491
00:36:14,000 --> 00:36:17,000
We're going to print the summary and we're going to make a plot.

492
00:36:17,000 --> 00:36:25,000
So run that cell and we see the formula call here, the residual, some intercept and X coefficients.

493
00:36:25,000 --> 00:36:30,000
And we have some plots that are displayed in our Python notebook.

494
00:36:30,000 --> 00:36:37,000
And again, we actually get our XY coefficient out back into our Python environment.

495
00:36:37,000 --> 00:36:45,000
So if you're a person who actually likes to use R just as much as you like to use Python or you like to use R for particular tasks

496
00:36:45,000 --> 00:36:49,000
or you like to use Python for lots of it, the Jupyter notebook is very, very flexible.

497
00:36:49,000 --> 00:36:57,000
It lets you work in whichever environment you prefer while dropping into the alternate Python or R environment to do just even a few pieces of it.

498
00:36:57,000 --> 00:37:02,000
So if you're in the middle of a long piece of data science analysis and you need one functionality from R,

499
00:37:02,000 --> 00:37:11,000
you can keep that not only in the notebook but passing it back and forth through native types.

500
00:37:11,000 --> 00:37:16,000
In this video, we'll be doing a somewhat more advanced topic and it's definitely 100% optional.

501
00:37:16,000 --> 00:37:23,000
We'll be talking about how to get into the guts of the Jupyter notebook system itself and create a post save hook,

502
00:37:23,000 --> 00:37:31,000
which will, for our purposes, save a script and an HTML file version of our Jupyter notebooks themselves.

503
00:37:31,000 --> 00:37:32,000
So how do we do this?

504
00:37:32,000 --> 00:37:37,000
The first step is to actually create a notebook configuration file.

505
00:37:37,000 --> 00:37:41,000
Now you can do that if you're interested in doing it in just your root environment

506
00:37:41,000 --> 00:37:47,000
or having this behavior be copied everywhere you are actually working on anything to do with the Jupyter notebook.

507
00:37:47,000 --> 00:37:53,000
Just go ahead and run Jupyter notebook generate config and I will copy and paste this into the terminal.

508
00:37:53,000 --> 00:37:55,000
So you can see what it looks like when you run this.

509
00:37:55,000 --> 00:38:03,000
The key takeaway here is this writing default config to now this should be your home directory dot Jupyter slash

510
00:38:03,000 --> 00:38:06,000
and then it's going to be this file called Jupyter notebook config.

511
00:38:06,000 --> 00:38:11,000
There's another way you can do this if you want to make this for a specific type of analysis.

512
00:38:11,000 --> 00:38:14,000
So maybe only the analysis you do involving housing data.

513
00:38:14,000 --> 00:38:17,000
Do you want to have a special behavior happen?

514
00:38:17,000 --> 00:38:19,000
You can do that in a somewhat roundabout way.

515
00:38:19,000 --> 00:38:22,000
You set this Jupyter config directory.

516
00:38:22,000 --> 00:38:26,000
It's an environment variable and set that to be a thing that doesn't exist yet.

517
00:38:26,000 --> 00:38:31,000
A home directory so tilde slash dot Jupyter save.

518
00:38:31,000 --> 00:38:35,000
You run a command that starts like this and then you generate the config.

519
00:38:35,000 --> 00:38:37,000
So I will show you what this looks like.

520
00:38:37,000 --> 00:38:41,000
So it wrote the default configuration file to dot Jupyter underscore save,

521
00:38:41,000 --> 00:38:47,000
which is the name of this profile and then the same Jupyter notebook config file.

522
00:38:47,000 --> 00:38:55,000
Now, running it in this way, you have Jupyter and configure before you do the actual command sets it as a temporary environment variable,

523
00:38:55,000 --> 00:38:58,000
meaning it's only set for that one command.

524
00:38:58,000 --> 00:39:01,000
If I try to echo this, I won't have anything stored in it.

525
00:39:01,000 --> 00:39:04,000
So I'm not exporting this as an environment variable.

526
00:39:04,000 --> 00:39:12,000
Now, I have a bit of code here that I'm going to actually toggle this header and this toolbar just to give us a little bit of extra space.

527
00:39:12,000 --> 00:39:19,000
I have some code here that I would like you to add to your Jupyter config profile file.

528
00:39:19,000 --> 00:39:24,000
So this Jupyter notebook config dot pi and instead of trying to type it off the screen,

529
00:39:24,000 --> 00:39:34,000
you can actually access it by typing HTTP colon slash slash b i t dot l y so bit dot l y and then Jupyter underscore profile.

530
00:39:34,000 --> 00:39:40,000
You click on that, you will go to the same exact code I have that I typed out here.

531
00:39:40,000 --> 00:39:47,000
In this case, I will actually copy this code and we're going to open up the file that we would like to modify.

532
00:39:47,000 --> 00:39:53,000
So in this case, we're going to be modifying this Jupyter save underscore Jupyter notebook config file.

533
00:39:53,000 --> 00:39:58,000
You can do with any text editor, I'm going to use sublime text, so sublime text open it up.

534
00:39:58,000 --> 00:40:00,000
Now, here's what the file looks like.

535
00:40:00,000 --> 00:40:07,000
It's actually a whole lot of things you can do to modify the behavior of your Jupyter notebook and they're almost all commented out.

536
00:40:07,000 --> 00:40:11,000
So you can read through this if you want to actually make different changes than what I'm going to recommend.

537
00:40:11,000 --> 00:40:17,000
But this is where we post just at the top this code, just a brief overview what's happening.

538
00:40:17,000 --> 00:40:24,000
It defines a function called post save, and it basically grabs the path of the notebook that's currently running,

539
00:40:24,000 --> 00:40:29,000
and it actually tries to run this command ipython nb convert to script,

540
00:40:29,000 --> 00:40:35,000
which means it's going to be a .py file if it's a Python file or a .r file if it's a r notebook,

541
00:40:35,000 --> 00:40:40,000
and an HTML file, which means that it'll just be the rendered HTML version of it.

542
00:40:40,000 --> 00:40:45,000
And the C dot file contents manager post save hook equals post save.

543
00:40:45,000 --> 00:40:52,000
So this is a way that Jupyter developers have allowed a person to make changes after every save that they do.

544
00:40:52,000 --> 00:40:57,000
So let's save that, and let's go back to our notebook.

545
00:40:57,000 --> 00:40:59,000
So let's list what's in this directory.

546
00:40:59,000 --> 00:41:05,000
We see the name of this current notebook is autosave other formats.

547
00:41:05,000 --> 00:41:07,000
I'm going to toggle that away again.

548
00:41:07,000 --> 00:41:09,000
So we see it here when I type ls.

549
00:41:09,000 --> 00:41:14,000
We can also do exclamation mark ls to do a command like this.

550
00:41:14,000 --> 00:41:18,000
And we see that when we save this, we see a checkpoint is created,

551
00:41:18,000 --> 00:41:21,000
but no other new files are being created.

552
00:41:21,000 --> 00:41:28,000
If we would like to see what happens when we run Jupyter notebook with this new Jupyter save configuration file,

553
00:41:28,000 --> 00:41:30,000
we'll have to run a command that looks like this.

554
00:41:30,000 --> 00:41:34,000
Jupyterconfigure equals this with Jupyter notebook.

555
00:41:34,000 --> 00:41:40,000
And in this case, I would actually like to save this entire thing as an alias,

556
00:41:40,000 --> 00:41:45,000
and then you can add this to your bash RC, or you can simply run this in a single line on your terminal.

557
00:41:45,000 --> 00:41:49,000
If you just want it in your terminal, however, it will not set it as a thing.

558
00:41:49,000 --> 00:41:53,000
So if you restart your computer or open up a new terminal, typing Jupyter save won't work.

559
00:41:53,000 --> 00:41:59,000
If you add this to your dot bash RC, then this special way of opening Jupyter notebook will be saved.

560
00:41:59,000 --> 00:42:07,000
So let's close this current notebook and let's type Jupyter save.

561
00:42:08,000 --> 00:42:11,000
And let's reopen it again in this new way.

562
00:42:11,000 --> 00:42:13,000
So we just opened it up.

563
00:42:13,000 --> 00:42:16,000
The list function down here should show us what we saw before.

564
00:42:16,000 --> 00:42:19,000
So we see the same files in this directory.

565
00:42:19,000 --> 00:42:23,000
When I click save, if our post save hook worked correctly,

566
00:42:23,000 --> 00:42:29,000
we will see autosaveotherformats.py and autosaveotherformats.html.

567
00:42:29,000 --> 00:42:34,000
So I'm going to do that after I click save type ls again.

568
00:42:34,000 --> 00:42:37,000
And we see that we do have two other forms.

569
00:42:37,000 --> 00:42:39,000
I have html and .py.

570
00:42:39,000 --> 00:42:43,000
Just to show you what those html and py versions look like, let's open that up.

571
00:42:43,000 --> 00:42:45,000
Oh, one last note.

572
00:42:45,000 --> 00:42:48,000
Every time you hit save, it will overwrite the same file a bunch of times.

573
00:42:48,000 --> 00:42:50,000
So it's not going to create new versions of this.

574
00:42:50,000 --> 00:42:56,000
It's going to just continually overwrite this and always keep the .html and the .py files completely up to date.

575
00:42:56,000 --> 00:42:58,000
Let's look at one of these html files actually looks like.

576
00:42:58,000 --> 00:43:01,000
So let's go back to the terminal to open a new one.

577
00:43:01,000 --> 00:43:08,000
So by typing open autosaveotherformats.html, we actually have the fully rendered notebook here.

578
00:43:08,000 --> 00:43:11,000
So what we see here is what we saw on the other page.

579
00:43:11,000 --> 00:43:13,000
And this is now the html version of this.

580
00:43:13,000 --> 00:43:15,000
This can be emailed somewhere.

581
00:43:15,000 --> 00:43:18,000
This can be posted online somewhere and people can see this.

582
00:43:18,000 --> 00:43:26,000
Now the links work like you'd expect and the code is all formatted and looks like it looks in the notebook.

583
00:43:26,000 --> 00:43:29,000
But since it's just an html file and it's not an actual notebook running,

584
00:43:29,000 --> 00:43:32,000
none of these cells are actually computable.

585
00:43:32,000 --> 00:43:34,000
I can't actually rerun these cells.

586
00:43:34,000 --> 00:43:47,000
So now we have a way of creating a post-save hook that lets us save out automatically html and script versions of any notebook that you're saving.

587
00:43:47,000 --> 00:43:53,000
If you would like to commit this to your GitHub repository for fellow members of the team to review in different ways,

588
00:43:53,000 --> 00:43:58,000
then having a post-save hook like this can save you tons of time and keep everything up to date.

589
00:43:59,000 --> 00:44:04,000
In this video, we'll be talking about a really fun topic called widgets.

590
00:44:04,000 --> 00:44:11,000
Widgets is an entire aspect of the Jupyter Notebook ecosystem that lets you do interactive things with the notebook.

591
00:44:11,000 --> 00:44:13,000
Let's go over to the notebook.

592
00:44:13,000 --> 00:44:18,000
This top cell has various imports, matplotlib, numpy, and so forth.

593
00:44:18,000 --> 00:44:22,000
This last line in this cell actually imports the ipython widgets.

594
00:44:22,000 --> 00:44:30,000
And we're going to import a number of sliders, a float slider, the integer slider, a toggle button, and this interactive thing as well.

595
00:44:30,000 --> 00:44:33,000
So let's execute that by typing shift enter.

596
00:44:33,000 --> 00:44:35,000
Now this next cell contains a simple formula.

597
00:44:35,000 --> 00:44:38,000
We define a Python function named polynomial.

598
00:44:38,000 --> 00:44:46,000
It takes three arguments, which has default values, so slope of 2.0 and intercept of 5 and show points, which can be either true or false.

599
00:44:46,000 --> 00:44:52,000
We're going to create some x values, which is just a linear spacing from negative 10 to 10 using 50 points.

600
00:44:52,000 --> 00:44:57,000
We're having a y value, which is just the slope times x plus the intercept.

601
00:44:57,000 --> 00:45:01,000
Everything else in this function is actually going to be plotting something.

602
00:45:01,000 --> 00:45:04,000
So this tells us the figure size we're going to use.

603
00:45:04,000 --> 00:45:07,000
The next line tells you that we're going to actually use a figure.

604
00:45:07,000 --> 00:45:12,000
The next two lines actually talk about whether or not the show points is true or false.

605
00:45:12,000 --> 00:45:21,000
If it says show points, we'll see what this actually does in a second, but it'll add the actual data points we are plotting up when we define this x at the top line here.

606
00:45:21,000 --> 00:45:27,000
Finally, we plot x and y and we set some window parameters and give ourselves some axes.

607
00:45:27,000 --> 00:45:30,000
The last thing we do is add this tight layout call at the very bottom.

608
00:45:30,000 --> 00:45:35,000
This just helps clean up the map plotlib plots before they're finally ready.

609
00:45:35,000 --> 00:45:39,000
So after executing this cell, we now have defined polynomial.

610
00:45:39,000 --> 00:45:41,000
Let's scroll down to this next cell.

611
00:45:41,000 --> 00:45:44,000
I'm defining a thing called a slope slider.

612
00:45:44,000 --> 00:45:48,000
This slope slider is called a float slider, which means it can actually take float values.

613
00:45:48,000 --> 00:45:50,000
That's what it's actually sweeping across.

614
00:45:50,000 --> 00:45:54,000
The value is 2.0, meaning that that's the starting value for the slope.

615
00:45:54,000 --> 00:46:01,000
Let's actually start this at minus 10 at the maximum of plus 10 and step size of, oh, let's say 1.0.

616
00:46:01,000 --> 00:46:06,000
The next line defines this object called w, which is interactive.

617
00:46:06,000 --> 00:46:11,000
The first argument you give interactive is actually the function that you want to be interacting with.

618
00:46:11,000 --> 00:46:17,000
In this case, the function we just defined polynomial and any other widgets that need to be connected to it.

619
00:46:17,000 --> 00:46:25,000
So in this case, we're going to connect the slope parameter that's given to the polynomial function to the slope slider.

620
00:46:25,000 --> 00:46:28,000
Now we call it slope slider, which is because we want to have a descriptive name.

621
00:46:28,000 --> 00:46:30,000
You can name it anything you want.

622
00:46:30,000 --> 00:46:34,000
The last thing we do is actually execute this w. Let's see what we see.

623
00:46:34,000 --> 00:46:41,000
We see three widgets that we can interact with, the slope, the intercept, and show points, which is toggle.

624
00:46:41,000 --> 00:46:47,000
Let's scroll down and I'm going to actually hide this toolbar so we have a little extra space.

625
00:46:47,000 --> 00:46:54,000
We have the slope, which is 2, and now you can actually click and drag this to different values.

626
00:46:54,000 --> 00:47:03,000
As you drag it to the right, you're increasing the slope and we can see that it's actually correspondingly increasing the slope of that line in the plot.

627
00:47:03,000 --> 00:47:06,000
We can also move the intercept point up and down.

628
00:47:06,000 --> 00:47:12,000
And as we know, an intercept just changes the y-positioning, shifting these things linearly up and down.

629
00:47:12,000 --> 00:47:17,000
And of course, the last thing is to toggle on and off show points.

630
00:47:17,000 --> 00:47:24,000
If you want to change this, we can actually make this much more sensitive by saying let's make the minimum minus 100, the maximum plus 100,

631
00:47:24,000 --> 00:47:27,000
step size of, oh, let's say five.

632
00:47:27,000 --> 00:47:35,000
Now, as we change the slope, it should be much more sensitive than it is because we're now at slope of 75.

633
00:47:35,000 --> 00:47:38,000
And as we go negative, we can see that as well.

634
00:47:38,000 --> 00:47:45,000
So as you can tell, having this kind of functionality at your fingertips is actually incredibly useful during all phases of doing a data science project,

635
00:47:45,000 --> 00:47:48,000
especially during the exploratory data analysis stage.

636
00:47:48,000 --> 00:47:53,000
So you can imagine if you did something like k-means to look at your data.

637
00:47:53,000 --> 00:47:57,000
You can set k, the number of clusters you're fitting for, the number of centroids.

638
00:47:57,000 --> 00:48:07,000
And as you can move that back and forth with the integer slider, for example, you can see how well the algorithm is actually clustering on that number of centroids.

639
00:48:07,000 --> 00:48:12,000
So being able to do that in an interactive way can speed things up quite a bit, and it's really nice.

640
00:48:12,000 --> 00:48:15,000
So this is a somewhat simple example that I just showed.

641
00:48:15,000 --> 00:48:22,000
Here is a much more complicated example, but just to give you a sense of what is possible with this kind of a thing.

642
00:48:22,000 --> 00:48:28,000
So I'm not expecting you to actually read this and understand the code that goes behind it, but let's just execute this real fast.

643
00:48:28,000 --> 00:48:35,000
This is one of the projects I was working on just on my own, where I want to actually have some random points in a small area,

644
00:48:35,000 --> 00:48:42,000
and I would like to interpolate with a spline interpolate those random points, and I wanted to see what that looked like at the end.

645
00:48:42,000 --> 00:48:47,000
So I can say the number of points that I'm randomly generating and splining between.

646
00:48:47,000 --> 00:48:51,000
And as I slide this to the right, you can see the pattern becomes more and more complicated.

647
00:48:51,000 --> 00:48:55,000
And as I slide this to the left, we get much simpler shapes.

648
00:48:55,000 --> 00:49:01,000
We also have a smoothing parameter here, which can give you a smoothing factor to these kind of more complicated shapes.

649
00:49:01,000 --> 00:49:09,000
It sort of unwinds the and rewinds up the knots and the alpha value, for example, like how dark this is.

650
00:49:09,000 --> 00:49:17,000
Or if I want to have a slight jitter to each of these strokes, I can add the number of brush strokes and then increase or decrease the jitter for this.

651
00:49:17,000 --> 00:49:26,000
So obviously there's a lot going on here, but this is one aspect that shows you just how, first of all, how quickly this can refresh, but also how useful it is.

652
00:49:26,000 --> 00:49:39,000
In this video, we saw how we can use interactive capabilities of the Jupyter Notebook to help us plot and look at data and change the values by sliding sliders around.

653
00:49:39,000 --> 00:49:44,000
In this video, I'll be talking about some bleeding edge developments in the Jupyter project.

654
00:49:44,000 --> 00:49:47,000
A specific thing called Jupyter Hub.

655
00:49:47,000 --> 00:49:59,000
If we were to go to Google, let's just search for it by saying Jupyter, then HUB, the top link will be this GitHub repository, which is Jupyter slash Jupyter Hub.

656
00:49:59,000 --> 00:50:04,000
And this allows, as it says, multi-user servers for Jupyter Notebooks.

657
00:50:04,000 --> 00:50:13,000
In other words, if you have a server where there's data being held for a data science team, you can run a single instance of this thing called Jupyter Hub.

658
00:50:13,000 --> 00:50:21,000
And it allows many different data scientists to log in and start a Jupyter Notebook on that server co-located with the data.

659
00:50:21,000 --> 00:50:25,000
Now, this is an active development. It's changing on weekly time scales.

660
00:50:25,000 --> 00:50:32,000
So if I were to actually show you how to set it up today, by the time you saw this video, it would probably be different from how you're supposed to be setting it up then.

661
00:50:32,000 --> 00:50:41,000
So for right now, I'll point you to this documentation and mention that it's actually very much bleeding edge, but I think it will be the future for data science teams.

662
00:50:41,000 --> 00:50:50,000
Just to give you a sense of what it looks like when you were to use Jupyter Hub, you can go to try.jupyter.org and hit Return.

663
00:50:50,000 --> 00:50:59,000
And what you're actually interfacing with here is a Jupyter Hub server somewhere in the back end, currently being hosted by Rackspace, apparently.

664
00:50:59,000 --> 00:51:09,000
And you can start a new notebook in any of these different styles, so Bash, Haskell, Julia, Python 2, or Python 3, R, Ruby, and Scala.

665
00:51:09,000 --> 00:51:16,000
So you can start a notebook here, and this is just letting you run a temporary quick one. You can also start one of these notebooks, like this Python one.

666
00:51:16,000 --> 00:51:22,000
And it starts with this warning. Don't rely on this server for anything you want to last. The server will be deleted after 10 minutes of inactivity.

667
00:51:22,000 --> 00:51:35,000
So that's important. This is just a demonstration area, so it's not for long-term storage of some sort of data science analysis, but it gives you a flavor of what the Jupyter Hub will be doing if you were to install this for your own sake.

668
00:51:35,000 --> 00:51:42,000
Now you can actually run this Jupyter Python 3 notebook, and you can actually see the fun results that come out from this.

669
00:51:42,000 --> 00:51:52,000
So we see some plots here, and everything works just like you expected to when you're running the Jupyter server locally, which is how all the videos I'm doing in this lesson are.

670
00:51:52,000 --> 00:52:00,000
Separating the server from the notebook aspect is that you can do something like this in the future, have the server being hosted on some server somewhere,

671
00:52:00,000 --> 00:52:07,000
and being able to access it just through the browser, and having the same exact functionality that I've been showing you for the entire course so far.

672
00:52:07,000 --> 00:52:14,000
And one last thing just to show you how fun this is, let's navigate back to our initials-try.jupyter thing.

673
00:52:14,000 --> 00:52:24,000
There's a couple other things you can do besides notebooks. This is true for the local server as well, but just to give you a sense of this, you can add a new folder, which is kind of unexciting.

674
00:52:24,000 --> 00:52:34,000
You just have a new unentitled folder here. Then you can do this new text file. So if you click text file, instead of starting a new notebook, you're starting a new file.

675
00:52:34,000 --> 00:52:40,000
And this is a lightweight in-browser text editor that has various options. You can choose what kind of key mapping you'd like.

676
00:52:40,000 --> 00:52:47,000
So I prefer sublime text these days as ways of interfacing with your text editor.

677
00:52:47,000 --> 00:52:58,000
So from here, you can do your standard Python, and you can both create and edit Python scripts or any kind of text file that you want to that's located on the server.

678
00:52:58,000 --> 00:53:05,000
And of course, renaming the file is as simple as clicking this top thing, calling it startup.py, for example.

679
00:53:05,000 --> 00:53:14,000
And once you do that, syntax highlighting gets turned on. You can save this and rename it, and then navigate back to the main server page.

680
00:53:14,000 --> 00:53:19,000
And the last thing to show you is that you can also start a terminal.

681
00:53:19,000 --> 00:53:25,000
And here you actually have the terminal for your tri-Jupiter. And this is the same case for if you're running this on a server.

682
00:53:25,000 --> 00:53:31,000
So you can actually have access to the terminal with all the functionality of a standard bash terminal there.

683
00:53:31,000 --> 00:53:36,000
So we see the startup thing we can copy that startup.py folder and call it something else.

684
00:53:36,000 --> 00:53:39,000
And going back, we should be able to see this.

685
00:53:39,000 --> 00:53:51,000
It's a very cool thing, and it will definitely be the way of the future if you have data science teams working and needing access to a single server somewhere that has the data in some database, for example.

686
00:53:51,000 --> 00:54:02,000
So Jupyter Hub, it will be the future. It is bleeding edge. So try it out. It should be pretty usable, but the exact instructions will be different from what I would say today.

687
00:54:02,000 --> 00:54:09,000
In this lesson, we'll be taking a look at organizing the overall structure for a data science team to be working on their various projects.

688
00:54:09,000 --> 00:54:14,000
So in this notebook, I'm going to use the slideshow button that we installed in a different video.

689
00:54:14,000 --> 00:54:18,000
And I make this full screen by clicking shift command F.

690
00:54:18,000 --> 00:54:24,000
The initial topic is questions to ask to organize the workflow of a data science team.

691
00:54:24,000 --> 00:54:29,000
So the first question is how many data scientists will be working on a single problem?

692
00:54:29,000 --> 00:54:36,000
And the high level view of this is to basically break this up into thinking about this in terms of Git repositories.

693
00:54:36,000 --> 00:54:45,000
What I mean by that is, if you have different data sources and different problems working in a single company, let's say, then you should definitely use different Git repositories.

694
00:54:45,000 --> 00:54:54,000
If you have fewer than 10 data scientists working on the same data, but working on different problems, it also probably makes sense to keep everything in a single Git repository, although it doesn't have to.

695
00:54:54,000 --> 00:54:57,000
If you have different concerns, feel free to break that up.

696
00:54:57,000 --> 00:55:08,000
And if you have more than 10 data scientists and they're working on the same data, but they're working on different problems, fundamentally addressing different data science issues, then I recommend using different Git repositories.

697
00:55:08,000 --> 00:55:13,000
And all of my recommendations will be within context of a single Git repository.

698
00:55:13,000 --> 00:55:17,000
The second main question to be asked is where is the data actually hosted?

699
00:55:17,000 --> 00:55:26,000
If it's small enough data to be loaded onto a data scientist's personal laptop, then it's very simple to actually just use the data on the laptop locally.

700
00:55:26,000 --> 00:55:36,000
So I would recommend just running the Jupyter Notebook as I'm doing in most of the videos for this course, where you just open up a terminal on your local laptop or local desktop and just run Jupyter Notebook.

701
00:55:36,000 --> 00:55:39,000
However, many data science projects actually use big data.

702
00:55:39,000 --> 00:55:42,000
They access the data on some other server or something like this.

703
00:55:42,000 --> 00:55:45,000
And in this case, you have a couple of options.

704
00:55:45,000 --> 00:56:00,000
The obvious one is to say, if you can access this server data via SSH and you can actually do work in a server, then you can actually run a Jupyter server on that server and you can SSH tunnel and forward your connection to that server.

705
00:56:00,000 --> 00:56:05,000
That way, both the data and the Jupyter server are on the same machine.

706
00:56:05,000 --> 00:56:08,000
Another option is to consider using a thing called Jupyter Hub.

707
00:56:08,000 --> 00:56:13,000
The Jupyter Hub would have to be installed on the server where the data is actually being held.

708
00:56:13,000 --> 00:56:16,000
And if I click this link, you go to this GitHub page here.

709
00:56:16,000 --> 00:56:21,000
So it can be found at github.com slash Jupyter slash Jupyter Hub.

710
00:56:21,000 --> 00:56:24,000
And you can see it's a bit more work than we can go into.

711
00:56:24,000 --> 00:56:26,000
It's a bit outside the scope of this class.

712
00:56:26,000 --> 00:56:30,000
But Jupyter Hub is a multi-user server for Jupyter Notebooks.

713
00:56:30,000 --> 00:56:37,000
And there's actually some really nice documentation to explain how this can be set up on a server or some AWS instance, for example.

714
00:56:37,000 --> 00:56:41,000
There's lots of installation instructions and things to work on here.

715
00:56:41,000 --> 00:56:43,000
So those are the main questions to be asking.

716
00:56:43,000 --> 00:56:46,000
At what level do you set the Git repository?

717
00:56:46,000 --> 00:56:48,000
And where are you going to be running this server?

718
00:56:48,000 --> 00:56:50,000
Are you going to be running it on a server somewhere?

719
00:56:50,000 --> 00:56:54,000
Or will you be running it locally on your local laptop or something else?

720
00:56:54,000 --> 00:57:04,000
Once you have those two questions settled, then the mechanics of actually how do you work on a Jupyter Notebook in a single repository or what we'll deal with next?

721
00:57:07,000 --> 00:57:12,000
In this lesson, we'll be organizing our work into two different types of notebooks.

722
00:57:12,000 --> 00:57:16,000
Conceptually, there are two types of notebooks I'd like to introduce.

723
00:57:16,000 --> 00:57:20,000
One called a laboratory notebook and one called a deliverable notebook.

724
00:57:20,000 --> 00:57:28,000
The difference here, a laboratory notebook is in the same style as lab notebooks that are actually in science labs throughout the world.

725
00:57:28,000 --> 00:57:34,000
And by that, a lab notebook keeps a historical record of the analysis that's been explored.

726
00:57:34,000 --> 00:57:43,000
So each day, a person goes to a lab bench, writes down the date at the top of the page, writes down what happened in lab that day for that particular experiment.

727
00:57:43,000 --> 00:57:46,000
And this record just continually gets amended to.

728
00:57:46,000 --> 00:57:55,000
It is also meant to be a place where there's development or scratch ideas or initial analyses, and it's very much not a polished piece of work.

729
00:57:55,000 --> 00:57:59,000
It is meant for record keeping of scratch pad type nature.

730
00:57:59,000 --> 00:58:02,000
And each notebook is controlled by a single data scientist.

731
00:58:02,000 --> 00:58:12,000
And by this, I'm talking about a Jupyter notebook where it is a single person single data scientists record of what they were doing that day and it is not shared by anyone else.

732
00:58:12,000 --> 00:58:20,000
Now, it's not secret people can look at it and you can upload it as well, but it's not meant to be viewed by other people necessarily.

733
00:58:20,000 --> 00:58:22,000
A few more final points on lab notebooks.

734
00:58:22,000 --> 00:58:27,000
Split the notebook when it gets too long and too long is just sort of a personal preference.

735
00:58:27,000 --> 00:58:35,000
As you start scrolling down the page as a point when a lab notebook or any notebook gets to the point where, okay, this is too much of a document to look at at one time.

736
00:58:35,000 --> 00:58:36,000
So then split it.

737
00:58:36,000 --> 00:58:37,000
There's no cost in splitting it.

738
00:58:37,000 --> 00:58:40,000
And you can think of this as just turning the page in a lab notebook.

739
00:58:40,000 --> 00:58:45,000
And finally, if you're working on a single day, you can actually split notebooks into different topics.

740
00:58:45,000 --> 00:58:49,000
So for the same day, you can actually have two different or more notebooks.

741
00:58:49,000 --> 00:58:52,000
And if you're splitting by topic, that makes sense as well.

742
00:58:52,000 --> 00:58:56,000
On contrast to a lab notebook, there's another idea of a deliverable notebook.

743
00:58:56,000 --> 00:59:02,000
As I work as a consultant, most of my work is actually going to be delivered either to a project manager or to a client.

744
00:59:02,000 --> 00:59:10,000
And these notebooks are different from lab notebooks in the sense that these will be delivered to someone to consume besides myself.

745
00:59:10,000 --> 00:59:15,000
Now candidates for deliverable notebooks can be any notebook that will be referenced in the future.

746
00:59:15,000 --> 00:59:21,000
By this, I mean, if I expect someone else to also use the same data cleaning notebook, for example,

747
00:59:21,000 --> 00:59:29,000
so I might have a notebook that explains how I took raw data and transformed it into the clean data that I use for the rest of the analysis.

748
00:59:29,000 --> 00:59:35,000
And I might provide a single link to a deliverable notebook, which is simply the data cleaning of the raw data.

749
00:59:35,000 --> 00:59:42,000
And in that notebook, I'll have things like what the actual transformations were, but also reasoning behind it and some documentation around it.

750
00:59:42,000 --> 00:59:45,000
So this is for anyone who wants to know how is this data actually cleaned?

751
00:59:45,000 --> 00:59:47,000
There's a single spot for it to look at.

752
00:59:47,000 --> 00:59:57,000
And obviously, of course, the final fully polished and final analysis of a data science piece of work will also be considered a deliverable notebook.

753
00:59:57,000 --> 01:00:02,000
I also recommend that deliverable notebooks should be peer reviewed via pull requests,

754
01:00:02,000 --> 01:00:06,000
which means other members will actually review the notebook before it's accepted.

755
01:00:06,000 --> 01:00:10,000
Other members can be other data scientists or it can be a manager or something else.

756
01:00:10,000 --> 01:00:13,000
And these notebooks are controlled by the whole data science team.

757
01:00:13,000 --> 01:00:18,000
If we think about these notebooks as living in a certain repository, for example,

758
01:00:18,000 --> 01:00:21,000
then the whole data science team will have these deliverable notebooks,

759
01:00:21,000 --> 01:00:26,000
which are in the same topic scope as the problem that they're all together trying to solve.

760
01:00:26,000 --> 01:00:33,000
So how do we organize the directories so that the lab notebooks and deliverable notebooks all are in their proper place?

761
01:00:33,000 --> 01:00:38,000
So these are the minimum directories, and I think it can be expanded by a few or taken away by a few.

762
01:00:38,000 --> 01:00:45,000
So I have listed here the directories I think belong at the top level of a data science git repository.

763
01:00:45,000 --> 01:00:47,000
The first one is data. This is optional.

764
01:00:47,000 --> 01:00:53,000
If you have very small data and you want to have it locally, it's possible to include it in a git repository.

765
01:00:53,000 --> 01:00:57,000
Generally, though, data science data is actually backed up outside of version control.

766
01:00:57,000 --> 01:00:59,000
It's in a different environment.

767
01:00:59,000 --> 01:01:02,000
So this is definitely an optional directory to have.

768
01:01:02,000 --> 01:01:04,000
The second one is the deliver directory.

769
01:01:04,000 --> 01:01:08,000
This is where the final polished notebooks for consumption.

770
01:01:08,000 --> 01:01:16,000
If a new data scientist is coming onto the project, they will look in the deliver directory to see what has been done before.

771
01:01:16,000 --> 01:01:22,000
In the develop directory, we store the lab notebooks, and I will explain the naming convention in a further video,

772
01:01:22,000 --> 01:01:28,000
but this will say all the scratch work that has been done by each of the data scientists working on this problem.

773
01:01:28,000 --> 01:01:36,000
The directory called figures will contain the figures that have been the output from both to develop and the deliver notebooks.

774
01:01:36,000 --> 01:01:39,000
I will be expressing a bit more on that in the future.

775
01:01:39,000 --> 01:01:45,000
And finally, a source directory where as you come up with various scripts or modules or anything else that needs to be,

776
01:01:45,000 --> 01:01:50,000
that's actual computer code that doesn't belong in a notebook directory, goes in a source directory.

777
01:01:50,000 --> 01:01:53,000
Again, you can add to this or you can modify this as you want to,

778
01:01:53,000 --> 01:02:00,000
but I think this is a good starting structure to work from and modify it as your needs evolve.

779
01:02:00,000 --> 01:02:06,000
In this video, I'll be telling you about my recommended convention for naming lab notebooks.

780
01:02:06,000 --> 01:02:10,000
So naming a lab notebook can be a more difficult problem than you might expect,

781
01:02:10,000 --> 01:02:14,000
especially if there's many different data scientists working on a similar problem.

782
01:02:14,000 --> 01:02:17,000
So to help with that, the following convention is what I recommend.

783
01:02:17,000 --> 01:02:20,000
You can obviously change this to fit your own needs.

784
01:02:20,000 --> 01:02:26,000
I recommend prepending each file name with the current date that you started the work on that notebook.

785
01:02:26,000 --> 01:02:31,000
So in this case, it was started 2015 dash 11 dash 21.

786
01:02:31,000 --> 01:02:36,000
I also recommend it in that format where it's the year dash the two digit month,

787
01:02:36,000 --> 01:02:43,000
meaning if it's three, it'd be dash zero three dash the two digit day like the month in zero four and so on.

788
01:02:43,000 --> 01:02:51,000
This is called an ISO 8601 formatted date, and it just helps with keeping everything so that it's sortable in a nice way.

789
01:02:51,000 --> 01:02:57,000
So the initial part of the name is the date that you started working on that particular notebook.

790
01:02:57,000 --> 01:03:01,000
The second piece immediately after that is the data scientists initials.

791
01:03:01,000 --> 01:03:03,000
So in my case, my initials are JBW.

792
01:03:03,000 --> 01:03:09,000
So I put dash after the date my initials, or you can put it if you have a data scientists with the same initials,

793
01:03:09,000 --> 01:03:12,000
you can just put some unique signifier that's the same every time.

794
01:03:12,000 --> 01:03:16,000
So that if you want to look at a directory that has many different data scientists notebooks,

795
01:03:16,000 --> 01:03:21,000
you can do an LS for that person's initials and find their notebooks.

796
01:03:21,000 --> 01:03:27,000
And finally, I recommend putting a two to forward description that describes what goes in that notebook.

797
01:03:27,000 --> 01:03:32,000
So in this case, Cole predict RF for random forest regression.

798
01:03:32,000 --> 01:03:36,000
So looking through this later on, I can think back, okay, what was I doing two months ago,

799
01:03:36,000 --> 01:03:38,000
something with random forest, and it was a regression.

800
01:03:38,000 --> 01:03:44,000
And on a classifier, seeing this in the title helps pick this out.

801
01:03:44,000 --> 01:03:47,000
In this video, we'll be talking about version control.

802
01:03:47,000 --> 01:03:53,000
One of the key questions you have when dealing with a data science team is how do you peer review code?

803
01:03:53,000 --> 01:03:57,000
How do you store analysis in version control like get?

804
01:03:57,000 --> 01:03:59,000
And I'm going to assume a number of further constraints.

805
01:03:59,000 --> 01:04:03,000
And I think this is probably the most restrictive constraints I can think of.

806
01:04:03,000 --> 01:04:05,000
This might not apply to you.

807
01:04:05,000 --> 01:04:10,000
But I think if it does apply to you, I have reasonable work rounds for each of the possible concerns.

808
01:04:10,000 --> 01:04:15,000
For example, imagine you have a project manager who would like to see the notebooks you're working on,

809
01:04:15,000 --> 01:04:18,000
but they don't want to install Python or I Python or anything like this,

810
01:04:18,000 --> 01:04:22,000
or consider that you might not be using GitHub for whatever reason.

811
01:04:22,000 --> 01:04:27,000
And some of the nice tools that GitHub has for showing diffs aren't available to you.

812
01:04:27,000 --> 01:04:33,000
Or if you would want to review the Python code itself and don't want to have to look at it in a notebook environment.

813
01:04:33,000 --> 01:04:40,000
How do I recommend dealing with these kinds of constraints while also maintaining a peer review of the code stored in the version control?

814
01:04:40,000 --> 01:04:46,000
The standard practice for my answer is that each data scientist who's working on the same problem in the same repo

815
01:04:46,000 --> 01:04:48,000
should have their own development branch.

816
01:04:48,000 --> 01:04:52,000
And each day or even more frequently than each day,

817
01:04:52,000 --> 01:04:57,000
but at minimum work is saved and pushed to the dev branch that they have daily,

818
01:04:57,000 --> 01:05:02,000
which means that anyone can then check out another data scientist development branch.

819
01:05:02,000 --> 01:05:05,000
When ready to merge to master, you have to do a pull request.

820
01:05:05,000 --> 01:05:14,000
So a data scientist says, OK, I think the deliverable notebooks as well as my laboratory notebooks are ready to be reviewed and pulled into master.

821
01:05:14,000 --> 01:05:17,000
Now the question of what exactly to commit.

822
01:05:17,000 --> 01:05:24,000
This is a question that people who come from a more software engineering background might start to recoil at my suggestions here.

823
01:05:24,000 --> 01:05:29,000
I say this after a lot of thought and there might be a better way of doing it, but this is the best way that I can come up with.

824
01:05:29,000 --> 01:05:40,000
So I recommend committing the .ipynb files, which are the notebook files, the .py and the .html of all notebooks, both develop and deliver.

825
01:05:40,000 --> 01:05:44,000
And I'll also say any of the figures that are saved should also be committed.

826
01:05:44,000 --> 01:05:48,000
Now, when I say the .py and the .html, what am I referring to?

827
01:05:48,000 --> 01:05:51,000
So I'll go to an open notebook right now.

828
01:05:51,000 --> 01:05:55,000
This is a notebook for making a prediction about call production.

829
01:05:55,000 --> 01:05:58,000
And this is in the develop folder of a certain directory.

830
01:05:58,000 --> 01:06:05,000
And I have this notebook that's currently running and you can tell it's running by the green symbol here and the words running green all the way to the right.

831
01:06:05,000 --> 01:06:14,000
So let's go to this running notebook and actually save it, save in checkpoint and download as a Python file.

832
01:06:14,000 --> 01:06:24,000
Let's download it to the same directory of develop, save that, and let's download this as an .html file and save it in the same spot.

833
01:06:24,000 --> 01:06:31,000
So if we take a look at what this is, it has taken all of the Python code and none of the output,

834
01:06:31,000 --> 01:06:35,000
but it's shipped out everything else in this file that's not Python code.

835
01:06:35,000 --> 01:06:38,000
And so you see this input three, input four, and so on.

836
01:06:38,000 --> 01:06:44,000
This is delineating the cells in the notebook, but everything you see here is actually Python code.

837
01:06:44,000 --> 01:06:49,000
So this can actually run as a .py or you can run it as Python, this file name.

838
01:06:49,000 --> 01:06:56,000
And this .html file, if we open up this file, we actually see the HTML representation of the notebook.

839
01:06:56,000 --> 01:06:58,000
So this is not executable.

840
01:06:58,000 --> 01:07:00,000
This is just a .html file.

841
01:07:00,000 --> 01:07:06,000
And so this can be copied into an email and read by anyone who opens this with a web browser.

842
01:07:06,000 --> 01:07:10,000
You don't need to run Python or IPython to actually see the output here.

843
01:07:10,000 --> 01:07:14,000
Again, the limitation, though, is you cannot actually edit this code and make a new plot,

844
01:07:14,000 --> 01:07:18,000
but this is great for being able to share a particular notebook.

845
01:07:18,000 --> 01:07:24,000
So I recommend saving both of those file types to your Git repository.

846
01:07:24,000 --> 01:07:28,000
And of course, all of the figures as well if you create separate figures.

847
01:07:28,000 --> 01:07:36,000
The reasoning behind that is that the .py files allows a person to make easy changes to the actual Python code itself,

848
01:07:36,000 --> 01:07:38,000
as well as to track those changes.

849
01:07:38,000 --> 01:07:44,000
The .html file allows a person to see the fully rendered notebook without having to run a notebook themselves.

850
01:07:44,000 --> 01:07:48,000
So the benefits of structuring your repository this way are several fold.

851
01:07:48,000 --> 01:07:52,000
First of all, you have a complete record of the analysis that includes dead ends.

852
01:07:52,000 --> 01:07:57,000
So if one day you worked down a single hypothesis and turned out that it wasn't very useful,

853
01:07:57,000 --> 01:08:00,000
that is still saved in the lab notebook directory.

854
01:08:00,000 --> 01:08:05,000
It also allows for easy peer review of the analysis and of the dead ends.

855
01:08:05,000 --> 01:08:11,000
If in the future, a different team member has an idea to try to do a random forest regression on the data,

856
01:08:11,000 --> 01:08:14,000
they can actually see if someone else has done the same type of analysis,

857
01:08:14,000 --> 01:08:17,000
and if so, what led to a dead end, for example.

858
01:08:17,000 --> 01:08:22,000
And finally, project managers can easily see and read the analysis with GitHub

859
01:08:22,000 --> 01:08:25,000
because GitHub itself renders IP, UI, and Bs natively.

860
01:08:25,000 --> 01:08:29,000
Or if you don't have GitHub access or not rendering it for whatever reason,

861
01:08:29,000 --> 01:08:35,000
if you save the .html files, anyone can actually see the rendered notebook without having to run any code themselves,

862
01:08:35,000 --> 01:08:38,000
or installing IPython or anything else.

863
01:08:38,000 --> 01:08:41,000
Some final organization thoughts of this whole structure.

864
01:08:41,000 --> 01:08:44,000
So organizing the workflow for teams is actually a difficult problem,

865
01:08:44,000 --> 01:08:48,000
and I think this is a very good framework for having some standards.

866
01:08:48,000 --> 01:08:51,000
And this bullet point about the wrong thing solves the problem.

867
01:08:51,000 --> 01:08:56,000
Often with version control, software engineering types think we need the source that's version control

868
01:08:56,000 --> 01:09:00,000
and we don't need to track the output, or that output is something that's blown away.

869
01:09:00,000 --> 01:09:04,000
In data science work, the output is often the thing we need to look at.

870
01:09:04,000 --> 01:09:07,000
For example, if there is a plot that shows some deviation,

871
01:09:07,000 --> 01:09:13,000
that plot is best viewed in the peer review process, actually in the notebook itself,

872
01:09:13,000 --> 01:09:19,000
or in an .html rendering of that notebook, because that gives rise to any sort of correction

873
01:09:19,000 --> 01:09:21,000
or reinterpretation that needs to happen.

874
01:09:21,000 --> 01:09:25,000
So the output actually is the thing that matters in a lot of data science work.

875
01:09:25,000 --> 01:09:28,000
So storing that in version control is actually the right thing to do,

876
01:09:28,000 --> 01:09:32,000
even though in typical practice it's the wrong to actually store the output.

877
01:09:32,000 --> 01:09:36,000
Finally, I am open to new ideas if you have a better way of solving these problems,

878
01:09:36,000 --> 01:09:40,000
or if your situation is completely different so that such that you will always be using GitHub,

879
01:09:40,000 --> 01:09:44,000
you never have to worry about seeing a rendered .html file.

880
01:09:44,000 --> 01:09:49,000
You can make these modifications by doing your own version of this kind of organization.

881
01:09:49,000 --> 01:09:54,000
So hopefully this gave you some structure to organize how a team of data scientists

882
01:09:54,000 --> 01:09:57,000
would work in a Git environment.

883
01:09:59,000 --> 01:10:03,000
In this lesson, we'll be getting some data that we can actually do some data science with.

884
01:10:03,000 --> 01:10:08,000
I recommend having a data folder in your projects directory that actually is at the same level

885
01:10:08,000 --> 01:10:12,000
as your deliver directory, your development directory, and your source directory.

886
01:10:12,000 --> 01:10:17,000
In my case, I have about 10 files in here that are coal data from the U.S. government.

887
01:10:17,000 --> 01:10:24,000
If you'd like to grab this same data set so you can follow along, go to www.eia.gov.

888
01:10:24,000 --> 01:10:28,000
This is the government's energy information administration website,

889
01:10:28,000 --> 01:10:34,000
and if you go to the data tab, you can scroll down to where it says production, give that a click.

890
01:10:34,000 --> 01:10:37,000
And there's lots of different data available here,

891
01:10:37,000 --> 01:10:43,000
but we're looking at the historical detailed coal production data available from 1983 to 2013.

892
01:10:43,000 --> 01:10:47,000
Select which year you'd like to do, and in case I picked 10 of them,

893
01:10:47,000 --> 01:10:50,000
click the arrow here and save it into that data directory.

894
01:10:50,000 --> 01:10:55,000
Once you do that, you'll then have the data that we'll need for this upcoming lessons.

895
01:10:57,000 --> 01:11:00,000
In this lesson, we're going to take our very first look at the data.

896
01:11:00,000 --> 01:11:03,000
We might even do some initial data cleaning.

897
01:11:03,000 --> 01:11:09,000
I'm currently in this directory where you can see we have data, deliver, development, and source directories.

898
01:11:09,000 --> 01:11:13,000
I'm going to start the Jupyter Notebook by, again, typing Jupyter Notebook.

899
01:11:13,000 --> 01:11:16,000
From here, we see the same directories I just saw in that directory.

900
01:11:16,000 --> 01:11:23,000
Let's open up the development list and start a new notebook by going over to new Python 2 notebook.

901
01:11:23,000 --> 01:11:26,000
From here, we see the familiar text box where you can type in code.

902
01:11:26,000 --> 01:11:29,000
In here, we see the code box is actually surrounded by green,

903
01:11:29,000 --> 01:11:33,000
which means as we type, it should be typing in text into that cell.

904
01:11:33,000 --> 01:11:38,000
We're going to need the pandas library, and we're going to import it as import pandas as pd.

905
01:11:38,000 --> 01:11:43,000
This can create alias for the pandas library to actually be called pd.

906
01:11:43,000 --> 01:11:48,000
This is a standard way of calling pandas, and I recommend you following the standards as often as possible.

907
01:11:48,000 --> 01:11:52,000
This lets you share your code with other people in the most seamless way possible.

908
01:11:52,000 --> 01:11:56,000
To run the cell, I can click the run cell button in the toolbar,

909
01:11:56,000 --> 01:12:03,000
or I can have done the shift enter technique, which, as you can see, increments which input number it is by one.

910
01:12:03,000 --> 01:12:10,000
The pandas version that I'm actually running is done by doing a print double underscore and then hitting the tab button.

911
01:12:10,000 --> 01:12:14,000
Hitting tab is a thing you should be thinking about doing quite often,

912
01:12:14,000 --> 01:12:17,000
because it often lets you make sure you don't have to type everything out.

913
01:12:17,000 --> 01:12:22,000
It's faster, but also make sure you are in the right vicinity of what you're hoping to do.

914
01:12:22,000 --> 01:12:25,000
There's a version, I'm going to hit return here, and then shift return,

915
01:12:25,000 --> 01:12:30,000
and it prints the pandas version that we're using, which is 0.17.0.

916
01:12:30,000 --> 01:12:34,000
From here, let's actually take a look at our very first data file.

917
01:12:34,000 --> 01:12:38,000
The way we can read this in, we happen to know, and here's an interesting side note,

918
01:12:38,000 --> 01:12:43,000
if you type ls and execute that, you actually see all the folders in the directory you're currently in.

919
01:12:43,000 --> 01:12:47,000
If you type ls up one, we see the parent directory,

920
01:12:47,000 --> 01:12:50,000
and if you'd like to look at what's in data,

921
01:12:50,000 --> 01:12:54,000
we see the files that we just downloaded in the previous video.

922
01:12:54,000 --> 01:12:59,000
Let's load in one of these Excel files and take a look at what's actually in them.

923
01:12:59,000 --> 01:13:05,000
I'm going to create a variable called df for data frame, and I'm going to df1 for the first one.

924
01:13:05,000 --> 01:13:09,000
I'm going to do pd.read, and I think it's going to be Excel,

925
01:13:09,000 --> 01:13:12,000
but I type the tab and I see an option pull up, and it is.

926
01:13:12,000 --> 01:13:16,000
It is pd.read underscore Excel, open parentheses.

927
01:13:16,000 --> 01:13:21,000
At this point, if you're not sure what a function does, there's a function called tooltip,

928
01:13:21,000 --> 01:13:24,000
which is generated by holding down shift and hitting tab once.

929
01:13:24,000 --> 01:13:30,000
Here it tells you the signature for this function, which has an input output, a sheet name, header, and so on.

930
01:13:30,000 --> 01:13:34,000
A lot of different options available for reading in Excel files.

931
01:13:34,000 --> 01:13:39,000
There's actually a longer version of this, where if you do shift tab tab in rapid succession,

932
01:13:39,000 --> 01:13:44,000
so it's a double tab, then you have the full doc string and the examples that go along with it.

933
01:13:44,000 --> 01:13:49,000
This is a very useful feature, so you can actually look up documentation on the fly, and it's very useful.

934
01:13:49,000 --> 01:13:53,000
In this case, we're going to try to load in the data from above.

935
01:13:53,000 --> 01:13:57,000
Again, tab completing commands will make your life much easier.

936
01:13:57,000 --> 01:14:03,000
As I start typing out this, I can hit tab and it actually produces again a list of possible data sources.

937
01:14:03,000 --> 01:14:05,000
Let's just see if this works.

938
01:14:05,000 --> 01:14:10,000
Head is a function on a data frame, and it lets you show the various options.

939
01:14:10,000 --> 01:14:12,000
We see that a number of things have happened here.

940
01:14:12,000 --> 01:14:17,000
First, we have the year, the MSHA ID, the mine name, the mine state.

941
01:14:17,000 --> 01:14:21,000
We actually see some of the data, and this is just the first few rows by doing head.

942
01:14:21,000 --> 01:14:26,000
I recommend doing head because it actually stores the full output of this.

943
01:14:26,000 --> 01:14:28,000
It's a separate thing that you can actually call.

944
01:14:28,000 --> 01:14:33,000
In future lessons, I'll explain exactly why using .head as best practices,

945
01:14:33,000 --> 01:14:39,000
but for now, let's just use .head to look into the contents of our pandas data frames.

946
01:14:39,000 --> 01:14:44,000
At this point, we've taken a first look at loading in some Excel data files,

947
01:14:44,000 --> 01:14:47,000
and we're going to start looking at this and playing around with it.

948
01:14:49,000 --> 01:14:54,000
In this lesson, we're going to take a look at how we can start to manipulate the data that we've read in

949
01:14:54,000 --> 01:14:56,000
in ways that are useful for analysis.

950
01:14:56,000 --> 01:15:01,000
Last time, we read in the CoalPublic2013 file and took a look at the header.

951
01:15:01,000 --> 01:15:04,000
The heading had an interesting, well, let's call it a problem.

952
01:15:04,000 --> 01:15:07,000
The historical Coal production data is the title here.

953
01:15:07,000 --> 01:15:12,000
There's a source function. There's also a bunch of nans, and all the columns are unnamed.

954
01:15:12,000 --> 01:15:20,000
This is most useful when this line, line 2, which is our row 2, is actually year MSHA ID, mine name.

955
01:15:20,000 --> 01:15:26,000
This is supposed to be the headers or the column names, and all the rest of it should be the actual rows of data.

956
01:15:26,000 --> 01:15:30,000
We're going to put the second row here up to the columns at the top.

957
01:15:30,000 --> 01:15:33,000
We'd also like to make this ID the index for the pandas data frame.

958
01:15:33,000 --> 01:15:38,000
We'll go into exactly why in the future, but for now, let's merge the reading in of the data frame

959
01:15:38,000 --> 01:15:42,000
with the printing out of what the head of that data frame looks like.

960
01:15:42,000 --> 01:15:48,000
We're going up here and clicking Edit, Merge Cell Below, because we've actually selected the above cell.

961
01:15:48,000 --> 01:15:50,000
So merge the cell below into one.

962
01:15:50,000 --> 01:15:58,000
So now that I execute this cell, we see that there is in one cell both reading the file and looking at the head of the file.

963
01:15:58,000 --> 01:16:02,000
Now, this is, again, wrong. We would like to remove this top part.

964
01:16:02,000 --> 01:16:07,000
So the way to remove this is we're actually going to use a thing called header and start giving it a number.

965
01:16:07,000 --> 01:16:12,000
Because if we look at this, we can see that it actually takes a header equals zero as the default value.

966
01:16:12,000 --> 01:16:16,000
So if we do header equals one, it actually deletes that top row.

967
01:16:16,000 --> 01:16:21,000
And so this is a way of telling the pandas that, hey, you don't have to modify that Excel file.

968
01:16:21,000 --> 01:16:25,000
You can just, when you read it in, know that there's two lines of header files.

969
01:16:25,000 --> 01:16:30,000
Now, there was two lines that had data in it, and there was a third NAN line that just, it knew it could not possibly be the header.

970
01:16:30,000 --> 01:16:31,000
So it removed that.

971
01:16:31,000 --> 01:16:35,000
So now the column names are these bolded ones are at the top.

972
01:16:35,000 --> 01:16:37,000
We're getting very close to what we actually want.

973
01:16:37,000 --> 01:16:40,000
Another thing we'd like to actually do is set the index.

974
01:16:40,000 --> 01:16:46,000
So we set the index by typing index and hitting tab because we think it's going to be something like set index or index set.

975
01:16:46,000 --> 01:16:50,000
And it's index columns equals, if this type, we like the name of it.

976
01:16:50,000 --> 01:16:54,000
So we would like to do the MSHA ID as the index column.

977
01:16:54,000 --> 01:17:04,000
And doing that, we see that the MSHA ID is indeed the index for this data and the columns are all appropriately named.

978
01:17:04,000 --> 01:17:07,000
This is one way to interact with the pandas library.

979
01:17:07,000 --> 01:17:12,000
But it actually applies to all Python libraries that have any sort of documentation strings.

980
01:17:12,000 --> 01:17:18,000
Just to give you an example of that, I'm going to save this currently and just show you example function, right?

981
01:17:18,000 --> 01:17:20,000
We define a function by typing def.

982
01:17:20,000 --> 01:17:22,000
We'll do it test function.

983
01:17:22,000 --> 01:17:31,000
Let's say it takes two values first equals five and second equals 10 and it will return first plus second.

984
01:17:31,000 --> 01:17:35,000
Let's give it a doc string and we execute that line.

985
01:17:35,000 --> 01:17:44,000
If we start typing test underscore f and then hit tab, it will automatically complete that because we have a defined function here called def function.

986
01:17:44,000 --> 01:17:47,000
We do the initial parentheses and hit shift tab.

987
01:17:47,000 --> 01:17:50,000
You actually see the doc string that we wrote just above.

988
01:17:50,000 --> 01:17:56,000
This is an example and it has the signature of it to the first equals five second equals 10.

989
01:17:56,000 --> 01:18:02,000
If you want to redefine what actually we give it, we can say first equals three and the test function gives us 13, which is what we'd expect.

990
01:18:02,000 --> 01:18:16,000
So that's just a fun side note on how the interaction with Jupiter notebook lets you look into the doc strings of functions that you define yourself as well as any of the libraries that you'll be using your data science day to day.

991
01:18:16,000 --> 01:18:21,000
In this lesson, we'll be making a new GitHub repository for a new data science project.

992
01:18:21,000 --> 01:18:28,000
So let's go over to GitHub and from GitHub, if you go all the way over to the right, you can create new repository.

993
01:18:28,000 --> 01:18:31,000
Give the repository some name that you think makes sense.

994
01:18:31,000 --> 01:18:33,000
So we'll do some coal exploration.

995
01:18:33,000 --> 01:18:37,000
So let's make a coal exploration repository name.

996
01:18:37,000 --> 01:18:39,000
You can give it a description if you'd like to.

997
01:18:39,000 --> 01:18:42,000
You don't need to decide whether it will be public or private.

998
01:18:42,000 --> 01:18:45,000
I'll let it be public so that you can see this as well.

999
01:18:45,000 --> 01:18:48,000
And generally, I like to initialize the repository with a read me.

1000
01:18:48,000 --> 01:18:52,000
It get ignore file that's Python because I use a lot of Python code.

1001
01:18:52,000 --> 01:18:55,000
And I add an MIT license.

1002
01:18:55,000 --> 01:18:58,000
After doing all this, click create repository.

1003
01:18:58,000 --> 01:19:04,000
Once you click create repository, you can go over to this place here where you can click SSH.

1004
01:19:04,000 --> 01:19:07,000
You can have HTTPS or SSH.

1005
01:19:07,000 --> 01:19:09,000
I just use SSH most of the time.

1006
01:19:09,000 --> 01:19:11,000
Clicking once in here highlights everything.

1007
01:19:11,000 --> 01:19:13,000
Command C will copy this.

1008
01:19:13,000 --> 01:19:21,000
And going back into a terminal, type git clone and then command V to paste the required link.

1009
01:19:21,000 --> 01:19:22,000
Hit return.

1010
01:19:22,000 --> 01:19:27,000
And you will now clone the GitHub repository to your local machine.

1011
01:19:27,000 --> 01:19:32,000
And from here, we see a new coal exploration folder being created.

1012
01:19:32,000 --> 01:19:42,000
And if we CD into coal exploration, we see that it has a license and a read me file that we've made previously.

1013
01:19:42,000 --> 01:19:45,000
In this lesson, we'll be taking our GitHub repository that we've just started.

1014
01:19:45,000 --> 01:19:47,000
We'll first look at the data.

1015
01:19:47,000 --> 01:19:52,000
So the directory as we last left, it has two files in it, a license and a read me file.

1016
01:19:52,000 --> 01:19:55,000
We're going to create some extra directories and some structure around here.

1017
01:19:55,000 --> 01:19:58,000
And I'll go through the reasoning behind this in other videos.

1018
01:19:58,000 --> 01:20:05,000
But we're going to create using the make directory command, a data directory, a deliver directory,

1019
01:20:05,000 --> 01:20:12,000
which is going to house the final deliverable important Jupyter notebooks, a develop directory,

1020
01:20:12,000 --> 01:20:15,000
which is where we're going to mostly do our development place,

1021
01:20:15,000 --> 01:20:19,000
place to put our source code if we have any scripts that we'll end up using.

1022
01:20:19,000 --> 01:20:23,000
So separate from ipython notebooks, usually Python files or other kinds of scripts,

1023
01:20:23,000 --> 01:20:28,000
we'll go in a source directory and a figures directory running that command.

1024
01:20:28,000 --> 01:20:33,000
The folder structure that we have now has a data deliver develop figures and source directories.

1025
01:20:33,000 --> 01:20:36,000
So let's actually get that data and put it into this directory.

1026
01:20:36,000 --> 01:20:37,000
You might have already downloaded it.

1027
01:20:37,000 --> 01:20:42,000
If not, again, the way to get this is to go to eia.gov slash coal.

1028
01:20:42,000 --> 01:20:46,000
Go to the data tab down to production.

1029
01:20:46,000 --> 01:20:49,000
And we go to the historical detailed coal production data.

1030
01:20:49,000 --> 01:20:52,000
And let's just use the year 2013 for now.

1031
01:20:52,000 --> 01:20:57,000
We're going to go into this coal exploration, navigate to the data folder and save.

1032
01:20:57,000 --> 01:21:00,000
That is done downloading.

1033
01:21:00,000 --> 01:21:04,000
You can see it in this folder as coal public 2013.

1034
01:21:04,000 --> 01:21:05,000
Great.

1035
01:21:05,000 --> 01:21:06,000
So let's take a look at this.

1036
01:21:06,000 --> 01:21:08,000
We'll open up a Jupyter notebook and take a look.

1037
01:21:08,000 --> 01:21:12,000
So from this top level directory, I will start Jupyter notebook.

1038
01:21:12,000 --> 01:21:15,000
You can now close this download file.

1039
01:21:15,000 --> 01:21:19,000
And you can navigate this structure similarly to the terminal itself.

1040
01:21:19,000 --> 01:21:22,000
So you can actually click data and you see the coal public data that we had before.

1041
01:21:22,000 --> 01:21:29,000
We can navigate back and let's go into the develop and start a new Python to notebook.

1042
01:21:29,000 --> 01:21:31,000
It starts off being called untitled.

1043
01:21:31,000 --> 01:21:33,000
And that is a not very helpful name.

1044
01:21:33,000 --> 01:21:38,000
So I recommend using the date in ISO 8601 format.

1045
01:21:38,000 --> 01:21:41,000
And the reason for that is that it helps with sorting.

1046
01:21:41,000 --> 01:21:46,000
But basically it goes year dash month dash dates today is the 21st.

1047
01:21:46,000 --> 01:21:55,000
After you do the date, I recommend, especially if you're working in teams to have your initials or some other identifier that creates it so that people know it's your notebook.

1048
01:21:55,000 --> 01:21:57,000
And so I'm going to type my initials here.

1049
01:21:57,000 --> 01:22:03,000
And then I recommend having a couple words that describe what you think you're doing in this notebook.

1050
01:22:03,000 --> 01:22:06,000
So I think I'll just say a first look.

1051
01:22:06,000 --> 01:22:12,000
So now I've renamed that notebook and it helpfully tells us when it lasted the last checkpoint.

1052
01:22:12,000 --> 01:22:15,000
This means when it's been saved auto saves every once in a while.

1053
01:22:15,000 --> 01:22:20,000
You can also click this button, but you just see that the last checkpoint saved.

1054
01:22:20,000 --> 01:22:22,000
And you can also do command s, which is how I normally do it.

1055
01:22:22,000 --> 01:22:27,000
So this means that it's keeping auto saved versions of this as we go along.

1056
01:22:27,000 --> 01:22:28,000
All right.

1057
01:22:28,000 --> 01:22:31,000
So there's a number of libraries that we'd like to import.

1058
01:22:31,000 --> 01:22:35,000
And I import these almost every time and it starts off with matplotlib inline.

1059
01:22:35,000 --> 01:22:39,000
So this percent sign at the top of the line means it's a magic import.

1060
01:22:39,000 --> 01:22:48,000
And we also have to import matplotlib like so importing it as PLT is the standard best practice for doing that next we import pandas.

1061
01:22:48,000 --> 01:22:52,000
And we should also import seaborne, which is a package that wraps matplotlib.

1062
01:22:52,000 --> 01:22:56,000
Interestingly, you're supposed to import seaborne as SNS.

1063
01:22:56,000 --> 01:23:00,000
I don't know exactly why, but importing it as SNS is the standard way of doing it.

1064
01:23:00,000 --> 01:23:04,000
Also, if you do SNS dot set, it actually sets a number of the default parameters for matplotlib.

1065
01:23:04,000 --> 01:23:07,000
So it already looks nicer if you just use it from there.

1066
01:23:07,000 --> 01:23:09,000
So let's go ahead and start with that.

1067
01:23:09,000 --> 01:23:14,000
And now let's read into a data frame, the data file that we just downloaded.

1068
01:23:14,000 --> 01:23:21,000
So we say df equals pandas library dot read hit tab to see the options go to Excel.

1069
01:23:21,000 --> 01:23:26,000
And we navigate to the directory by going up one directory by doing dot dot slash.

1070
01:23:26,000 --> 01:23:30,000
If we hit tab, we also get the possible navigation options.

1071
01:23:30,000 --> 01:23:34,000
It's in the data and if you tap again, it will have complete to say cold public 2013.

1072
01:23:34,000 --> 01:23:40,000
If we actually execute that and take a look at the head, we notice that we again have this unnamed part at the top.

1073
01:23:40,000 --> 01:23:43,000
So we actually wouldn't like to remember that it has a header.

1074
01:23:43,000 --> 01:23:48,000
Set the headers equal to two and that correctly gets the column types labeled in there.

1075
01:23:48,000 --> 01:23:52,000
And we want to set the index to the MSH ID.

1076
01:23:52,000 --> 01:24:01,000
So if it's annoying, you set index by doing index something hit tab and its index column equals MSHA space ID.

1077
01:24:01,000 --> 01:24:07,000
Excelling those two cells, you have the ID of the mine setting as the index of this data frame

1078
01:24:07,000 --> 01:24:11,000
and all the data in here correctly parsed from that Excel file.

1079
01:24:11,000 --> 01:24:20,000
Okay, so I'm going to stop it here and we'll begin to actually start to plot this and take a look at what this data actually looks like.

1080
01:24:20,000 --> 01:24:25,000
In this lesson, we'll take a look at the data and do some data cleaning and maybe do some visualizations.

1081
01:24:25,000 --> 01:24:32,000
Let's go back into this notebook and rerun the first cell here, load everything in that warning that we've seen before.

1082
01:24:32,000 --> 01:24:36,000
Load in the data and take a look at the data dot head.

1083
01:24:36,000 --> 01:24:38,000
So everything here looks normal.

1084
01:24:38,000 --> 01:24:44,000
And the day to day data science work, you often take a look at what's in each of these columns.

1085
01:24:44,000 --> 01:24:50,000
So we can just do a very quick look, for example, at a data frame and take a look at the company type.

1086
01:24:50,000 --> 01:24:57,000
Now, if we have thousands of rows, we don't want to look at all of them, but we do want to look at the unique ones.

1087
01:24:57,000 --> 01:25:02,000
In here, we see that there's three types of unique companies according into our file right now.

1088
01:25:02,000 --> 01:25:06,000
We have what I think the word is supposed to be independent producer operator.

1089
01:25:06,000 --> 01:25:10,000
The next one is operating subsidiary and contractor.

1090
01:25:10,000 --> 01:25:16,000
Now, obviously, this first piece of information is that the data has some data quality issues.

1091
01:25:16,000 --> 01:25:19,000
So let's go ahead and actually make a correction here for this data.

1092
01:25:19,000 --> 01:25:26,000
We'd actually like to replace all of the independent producer operators with independent producer operators.

1093
01:25:26,000 --> 01:25:33,000
So the way to do this in place is to actually do a company type to replace it.

1094
01:25:33,000 --> 01:25:38,000
And if you don't remember the syntax for replacing, if you do a shift tab, you can actually see the tool tip come up.

1095
01:25:38,000 --> 01:25:40,000
There's two ways to do this.

1096
01:25:40,000 --> 01:25:44,000
You can say to replace equals x, the value in place, everything else.

1097
01:25:44,000 --> 01:25:47,000
And we can also do it by giving it a dictionary.

1098
01:25:47,000 --> 01:25:49,000
I'm actually going to do it the standard way.

1099
01:25:49,000 --> 01:25:56,000
So to replace should be equal to, we'll just copy the words from above.

1100
01:25:56,000 --> 01:26:02,000
And the value I would like to replace it with is going to be the independent producer operator.

1101
01:26:02,000 --> 01:26:05,000
This cell is already becoming wider than the screen.

1102
01:26:05,000 --> 01:26:09,000
So I'm going to actually hit return here so that it's lined up with the beginning of this.

1103
01:26:09,000 --> 01:26:12,000
So you can say one later on can actually read this in a much nicer way.

1104
01:26:12,000 --> 01:26:17,000
Suppose a DF company replace this thing and then do head on this.

1105
01:26:17,000 --> 01:26:24,000
It should show us that it is indeed replacing the independent producer, but it hasn't replaced it in the actual data frame itself.

1106
01:26:24,000 --> 01:26:30,000
To do that, we have to add an extra command here, which is in place equals true.

1107
01:26:30,000 --> 01:26:34,000
One extra interesting, let's call it a quirk of the Jupiter system.

1108
01:26:34,000 --> 01:26:40,000
If you're in line with the beginning of this command, if you do a tool tip by doing a shift tab, it appears.

1109
01:26:40,000 --> 01:26:45,000
If you're not on that first line and it's broken up across multiple lines, then doing the shift tab in the middle here will not work.

1110
01:26:45,000 --> 01:26:48,000
If you're thinking, is it in place one word or is it in underscore place?

1111
01:26:48,000 --> 01:26:50,000
You have to do it up here to get the tool tip help.

1112
01:26:50,000 --> 01:26:52,000
So it's in place one word.

1113
01:26:52,000 --> 01:26:53,000
So I typed it down here.

1114
01:26:53,000 --> 01:26:59,000
This will in place change the DF company type to be independent.

1115
01:26:59,000 --> 01:27:02,000
So this has now been replaced in place.

1116
01:27:02,000 --> 01:27:10,000
Now we also see that even though I could actually hit tab, which is a very useful thing to be able to call the column heading by just typing the beginning of it.

1117
01:27:11,000 --> 01:27:17,000
Having these spaces is going to just make life a little bit more difficult than it should be.

1118
01:27:17,000 --> 01:27:24,000
So what I'd like to do is actually go through all of the columns in this data frame and replace every single space with an underscore.

1119
01:27:24,000 --> 01:27:27,000
So it's still readable, but I'd just like to actually do that.

1120
01:27:27,000 --> 01:27:30,000
So to do that, we actually would like to do a name of the columns.

1121
01:27:30,000 --> 01:27:35,000
So we DF dot rename index columns equals and keyword arguments.

1122
01:27:35,000 --> 01:27:37,000
So you can say columns equals.

1123
01:27:37,000 --> 01:27:41,000
Now this is a really fun trick because you actually pass a Lambda function.

1124
01:27:41,000 --> 01:27:46,000
Lambda function says for everything in that columns, I'd like to do X dot replace.

1125
01:27:46,000 --> 01:27:53,000
So similar syntax as above, but I replace all of the spaces with underscores.

1126
01:27:53,000 --> 01:28:00,000
So the thing that's being quoted is the thing that's being found single space replacing that space with is the underscore.

1127
01:28:00,000 --> 01:28:06,000
So I'd like to rename the data frame where every column space will be turned into an underscore.

1128
01:28:06,000 --> 01:28:10,000
And of course, I would also like to actually make this happen to the data frame in place.

1129
01:28:10,000 --> 01:28:16,000
So I say in place equals true now to check if that actually worked as we hope we can look at the DF dot head.

1130
01:28:16,000 --> 01:28:21,000
And we see that underscore name mine underscore state mine underscore county and so on.

1131
01:28:21,000 --> 01:28:27,000
So this with one line and very quickly typing it out replaced all of the spaces here with underscores.

1132
01:28:27,000 --> 01:28:31,000
And this will just make life much easier as we go on from here.

1133
01:28:31,000 --> 01:28:33,000
Let's also take a look at how big is this data frame.

1134
01:28:33,000 --> 01:28:35,000
We have 1400 data points.

1135
01:28:35,000 --> 01:28:38,000
And let's take a first look at just what's in here.

1136
01:28:38,000 --> 01:28:45,000
So we just read this off as my name all the way through regions and average employees and labor hours.

1137
01:28:45,000 --> 01:28:51,000
Let's see what the relationship between the number of employees for a mine and the number of labor hours looks like.

1138
01:28:51,000 --> 01:28:53,000
There's a couple of ways we can do this.

1139
01:28:53,000 --> 01:28:55,000
Let's see the simplest way I can think of is to do a scatter plot.

1140
01:28:55,000 --> 01:29:00,000
So we can do PLT dot scatter and DF dot average employees.

1141
01:29:00,000 --> 01:29:08,000
So now I've indexed the data frames column by simply doing a dot before it because it has a space in it.

1142
01:29:08,000 --> 01:29:13,000
I would have to have done it the DF bracket space labor hours, for example.

1143
01:29:13,000 --> 01:29:15,000
So this will actually work.

1144
01:29:15,000 --> 01:29:17,000
You see that the plot actually works as expected.

1145
01:29:17,000 --> 01:29:24,000
But now instead of having to type out labor hours previously with a space there, I can actually do dot labor hours.

1146
01:29:24,000 --> 01:29:28,000
And that just makes my life just ever so slightly bit better.

1147
01:29:28,000 --> 01:29:32,000
Let's label this.

1148
01:29:32,000 --> 01:29:35,000
Okay, so just as we expect, number of employees goes up.

1149
01:29:35,000 --> 01:29:39,000
The total number of hours worked at that mine goes up in a pretty linear fashion.

1150
01:29:39,000 --> 01:29:43,000
Another way of doing this would actually be linear regression plot on this.

1151
01:29:43,000 --> 01:29:45,000
And you can use Seaborn for that.

1152
01:29:45,000 --> 01:29:47,000
So SNS dot regression plot.

1153
01:29:47,000 --> 01:29:51,000
And I'll do, I'll pass it the X and Y this way.

1154
01:29:51,000 --> 01:29:55,000
And so when you can see here, the regression plot does the same thing as above,

1155
01:29:55,000 --> 01:30:00,000
but it actually fits aligned in the data and gives it a bootstrapping in the middle of it.

1156
01:30:00,000 --> 01:30:03,000
This bootstrap is done by a confidence interval of 95%.

1157
01:30:03,000 --> 01:30:09,000
And it bootstraps a thousand times the underlying data to actually figure out what the variance is.

1158
01:30:09,000 --> 01:30:15,000
So this is a kind of neat, very quick way of getting an initial look at two variables that you think might have a relationship and they clearly do.

1159
01:30:15,000 --> 01:30:21,000
Now, if you'd like to actually save this figure as in this isn't just to look at and have it for later on,

1160
01:30:21,000 --> 01:30:25,000
you should actually save this figure into the figures directory.

1161
01:30:25,000 --> 01:30:29,000
So I would do PLT dot save fig figures.

1162
01:30:29,000 --> 01:30:38,000
And I like to actually have the same beginning date structure for these figures so that if I am looking through the figures directory later on

1163
01:30:38,000 --> 01:30:45,000
across all the different notebooks that I'll be looking at, I can easily re-correspond which figure came from which notebook.

1164
01:30:45,000 --> 01:30:50,000
So this is just a little bit of mental accounting to get this straightforward.

1165
01:30:50,000 --> 01:30:55,000
And let's do employees versus hours.

1166
01:30:55,000 --> 01:30:58,000
Let's keep our underscores and spaces being the same.

1167
01:30:58,000 --> 01:31:05,000
All right, so that's our first look at the data and it is a quick linear regression plot against two of the features that we found inside,

1168
01:31:05,000 --> 01:31:11,000
as well as a bit of data frame manipulation using pandas.

1169
01:31:11,000 --> 01:31:15,000
We've seen a very first look at this and we see that there's at least some trends in this data.

1170
01:31:15,000 --> 01:31:17,000
There's probably something pretty interesting in here.

1171
01:31:17,000 --> 01:31:21,000
So I'll keep going with this data set and seeing what I can come out with this.

1172
01:31:21,000 --> 01:31:28,000
Now I will actually remove this header and I will toggle the toolbar as well as I need space.

1173
01:31:28,000 --> 01:31:30,000
So let me go ahead and do that.

1174
01:31:30,000 --> 01:31:36,000
So previously we saw with seaborne a really nice regression of the average number of employees versus labor hours.

1175
01:31:36,000 --> 01:31:38,000
Let's keep seeing what's in this data set.

1176
01:31:38,000 --> 01:31:41,000
Let's take a look at the columns for column in.

1177
01:31:41,000 --> 01:31:43,000
So these are the columns in the data frame.

1178
01:31:43,000 --> 01:31:51,000
We have year and then various things about the mind itself, the name, the state, the county, its status and its type, the company type, union code.

1179
01:31:51,000 --> 01:31:57,000
There's a coal supply region, the production in short tons and the number of employees in labor hours.

1180
01:31:57,000 --> 01:32:04,000
So see if the amount people work, like the labor hours total is very predictive of the production in short tons.

1181
01:32:04,000 --> 01:32:06,000
Let's take a look at that scatter plot.

1182
01:32:08,000 --> 01:32:09,000
Let's take a look here.

1183
01:32:09,000 --> 01:32:13,000
So it doesn't appear to be a fantastic relationship here.

1184
01:32:13,000 --> 01:32:15,000
Let's take a look at the actual histogram of this.

1185
01:32:15,000 --> 01:32:21,000
So I'll do df production short tons dot hist, which is a function on pandas.

1186
01:32:21,000 --> 01:32:25,000
And we see a very bad looking histogram.

1187
01:32:25,000 --> 01:32:31,000
So it looks like a lot of things in this first one, which is either typical of a power law or some other kind of problem.

1188
01:32:31,000 --> 01:32:33,000
Let's do a few transformations on this production.

1189
01:32:33,000 --> 01:32:40,000
Let's see if we can find the minimum value or yeah, let's take a look at the minimum value zero.

1190
01:32:40,000 --> 01:32:44,000
Let's take the length of the data frame where this is equal to zero.

1191
01:32:44,000 --> 01:32:49,000
So if we did first, let's just look at this where the production short tons is equal to zero.

1192
01:32:49,000 --> 01:32:54,000
We have what's returned as a series that tells us false false true true false and so forth.

1193
01:32:54,000 --> 01:32:56,000
So this tells us whether or not the production is equal to zero.

1194
01:32:56,000 --> 01:33:03,000
So we say df where you actually give this as an argument to data frame saying where this is equal to zero.

1195
01:33:03,000 --> 01:33:07,000
We get the full data frame where all of the production values are equal to zero.

1196
01:33:07,000 --> 01:33:11,000
And it looks to be like quite a few of these things produced zero tons of coal.

1197
01:33:11,000 --> 01:33:17,000
In the interest of how much a coal mine is producing, let's take the ones that have produced at least one ton.

1198
01:33:17,000 --> 01:33:22,000
We will say the data frame where the production of short tons is greater than zero.

1199
01:33:22,000 --> 01:33:26,000
This has, okay, values that are not zero. This is good.

1200
01:33:26,000 --> 01:33:28,000
From here, we will now set the data frame equal to this.

1201
01:33:28,000 --> 01:33:30,000
Now we are at this point doing a slice.

1202
01:33:30,000 --> 01:33:31,000
So I will make a note here.

1203
01:33:31,000 --> 01:33:34,000
We are removing data here.

1204
01:33:34,000 --> 01:33:37,000
That's okay as long as you're keeping track of what you're doing and why.

1205
01:33:37,000 --> 01:33:41,000
So the reasoning behind this is if we're going to try to predict, let's say the production of mines

1206
01:33:41,000 --> 01:33:45,000
and use things like what state the mine is in as a predictive indicator.

1207
01:33:45,000 --> 01:33:49,000
Let's actually restrict ourselves to mines that produced something more than zero.

1208
01:33:49,000 --> 01:33:52,000
And that's the reasoning behind how I choose something like this.

1209
01:33:52,000 --> 01:33:58,000
So now data frame is equal to where the data frame production values is over zero.

1210
01:33:58,000 --> 01:34:00,000
So let's see what the length of data frame is now.

1211
01:34:00,000 --> 01:34:03,000
Okay, so we have 1061 data points.

1212
01:34:03,000 --> 01:34:05,000
Let's redo this one.

1213
01:34:05,000 --> 01:34:08,000
I'm going to copy this and place it down here just so that we can do a comparison.

1214
01:34:08,000 --> 01:34:13,000
And it appears to still have quite the skew distribution.

1215
01:34:13,000 --> 01:34:18,000
So I will try to do something now where I will actually take the log of this.

1216
01:34:18,000 --> 01:34:20,000
So let's create a new column.

1217
01:34:20,000 --> 01:34:26,000
And the way to create a new column in pandas is to actually just create a column as though it exists

1218
01:34:26,000 --> 01:34:29,000
and set it equal to a function of this.

1219
01:34:29,000 --> 01:34:32,000
So I don't know if I have NumPy installed just yet.

1220
01:34:32,000 --> 01:34:34,000
So I'll give this a try.

1221
01:34:34,000 --> 01:34:36,000
So let's go to the top of the page.

1222
01:34:36,000 --> 01:34:40,000
And in all of our imports at the top of the notebook, I recommend keeping them together

1223
01:34:40,000 --> 01:34:45,000
so that if and everyone later on can see where things were imported, import NumPy as NPs.

1224
01:34:45,000 --> 01:34:47,000
Now this input is 30.

1225
01:34:47,000 --> 01:34:50,000
I've imported it and I should be able to rerun this one all the way to the bottom here

1226
01:34:50,000 --> 01:34:51,000
and create a new one.

1227
01:34:51,000 --> 01:34:55,000
So let's look at df.logproduction.hist.

1228
01:34:55,000 --> 01:34:59,000
So what we see here is a very close to a log normal distribution.

1229
01:34:59,000 --> 01:35:03,000
So the production of coal mines follows a log normal distribution,

1230
01:35:03,000 --> 01:35:06,000
which is reasonable from first guesses.

1231
01:35:06,000 --> 01:35:07,000
All right, great.

1232
01:35:07,000 --> 01:35:11,000
So I think I'm going to stick with this as a thing we're going to be interested in predicting.

1233
01:35:11,000 --> 01:35:13,000
So we have our prediction variable.

1234
01:35:13,000 --> 01:35:17,000
Now at this point, we've done quite a few things to the data frame itself.

1235
01:35:17,000 --> 01:35:20,000
So we loaded it in, we renamed the columns.

1236
01:35:20,000 --> 01:35:24,000
We actually created what's going to be my target variable is going to be the production of these mines

1237
01:35:24,000 --> 01:35:27,000
and did a transformation, which is the log of this value.

1238
01:35:27,000 --> 01:35:31,000
So after doing all this, I think I would like to actually save out this data frame

1239
01:35:31,000 --> 01:35:34,000
that I can load it into any future analysis.

1240
01:35:34,000 --> 01:35:36,000
So I'll do df.2.

1241
01:35:36,000 --> 01:35:38,000
Let's save it as a CSV.

1242
01:35:38,000 --> 01:35:42,000
So I'll call it, let's find it in the data directory, coal public this thing.

1243
01:35:42,000 --> 01:35:44,000
We'll do cleaned version of this.

1244
01:35:44,000 --> 01:35:46,000
And it's a CSV.

1245
01:35:46,000 --> 01:35:51,000
So now that I've done this exploratory analysis, I would have this first look that I've taken at

1246
01:35:51,000 --> 01:35:53,000
and I've saved the data out into this CSV file.

1247
01:35:53,000 --> 01:35:56,000
I'm going to copy this into a new one that's going to be called data cleaning.

1248
01:35:56,000 --> 01:36:00,000
And in the future, all I'll have to do is load in this CSV file

1249
01:36:00,000 --> 01:36:02,000
and all the transformations will have already been done.

1250
01:36:02,000 --> 01:36:09,000
And I'll have a link back to the reasoning behind it as well as the actual code that does this process.

1251
01:36:09,000 --> 01:36:13,000
In this video, I'll be cleaning up the data cleaning notebook

1252
01:36:13,000 --> 01:36:19,000
and I'll be doing our first commits to a new branch to keep everything organized.

1253
01:36:19,000 --> 01:36:23,000
I last laughed off with this first look and their develop directory.

1254
01:36:23,000 --> 01:36:27,000
So what we're going to do now is actually make a copy of this

1255
01:36:27,000 --> 01:36:29,000
and I will toggle the header for this.

1256
01:36:29,000 --> 01:36:31,000
Make a copy.

1257
01:36:31,000 --> 01:36:34,000
And the first thing it does is it opens a new tab with everything copied in the previous one.

1258
01:36:34,000 --> 01:36:38,000
And none of the code has been run here even though all of the inputs have been copied.

1259
01:36:38,000 --> 01:36:41,000
What we're going to do here is actually call this something completely different

1260
01:36:41,000 --> 01:36:43,000
which is data cleaning.

1261
01:36:43,000 --> 01:36:46,000
I didn't put a date in front of it because this is the notebook

1262
01:36:46,000 --> 01:36:51,000
that's going to be the one that people look at if they actually want to see how we changed the data.

1263
01:36:51,000 --> 01:36:55,000
So I'm going to actually close this from this directory,

1264
01:36:55,000 --> 01:36:58,000
go over to my actual terminal here

1265
01:36:58,000 --> 01:37:02,000
and move from the develop the data cleaning ipython nb

1266
01:37:02,000 --> 01:37:04,000
which we just created into the deliver.

1267
01:37:04,000 --> 01:37:07,000
So we move the file from develop into deliver

1268
01:37:07,000 --> 01:37:10,000
because deliver is the directory that people should be looking at

1269
01:37:10,000 --> 01:37:14,000
if they're actually interested in seeing the final analysis that matters.

1270
01:37:14,000 --> 01:37:18,000
In this case, we don't want to hide data cleaning in this development directory

1271
01:37:18,000 --> 01:37:20,000
which has many, many files.

1272
01:37:20,000 --> 01:37:24,000
So we've moved it into deliver and if we go back to our browser here

1273
01:37:24,000 --> 01:37:27,000
go up into deliver and open up the data cleaning.

1274
01:37:27,000 --> 01:37:31,000
Now we should actually start to do things like actually creating the markdown file

1275
01:37:31,000 --> 01:37:34,000
changing the code from code to markdown

1276
01:37:34,000 --> 01:37:37,000
giving it a nice title and continuing on with this.

1277
01:37:37,000 --> 01:37:41,000
So we can say Jonathan by Jonathan to say like who actually did this

1278
01:37:41,000 --> 01:37:45,000
and then you can look it up in the get repo cleaned up the data

1279
01:37:45,000 --> 01:37:49,000
removed zero production coal mines.

1280
01:37:49,000 --> 01:37:51,000
You can actually do a bit more of that in the end

1281
01:37:51,000 --> 01:37:53,000
but for now that should suffice.

1282
01:37:53,000 --> 01:37:55,000
We don't need to actually have any of these plots in here.

1283
01:37:55,000 --> 01:37:58,000
So I'm going to be cleaning this up as quickly as I can.

1284
01:37:58,000 --> 01:38:01,000
So numpy as NP pandas as PD.

1285
01:38:01,000 --> 01:38:03,000
We need to read in the file still.

1286
01:38:03,000 --> 01:38:04,000
We don't need to see the head.

1287
01:38:04,000 --> 01:38:05,000
We know what that looks like.

1288
01:38:05,000 --> 01:38:09,000
This can be left in because it tells us the transformation we made and why

1289
01:38:09,000 --> 01:38:12,000
the head part doesn't need to be here for the second one

1290
01:38:12,000 --> 01:38:15,000
but we can add a note above it that says mistake

1291
01:38:15,000 --> 01:38:18,000
renaming indipedent to independent.

1292
01:38:18,000 --> 01:38:24,000
Now we're in here changing spaces to underscores

1293
01:38:24,000 --> 01:38:26,000
double check that still looks right.

1294
01:38:26,000 --> 01:38:29,000
Okay, it does and we will now delete this head,

1295
01:38:29,000 --> 01:38:35,000
delete the different plots here and give an extra sentence here.

1296
01:38:35,000 --> 01:38:41,000
Coal mines without any coal production are removed.

1297
01:38:41,000 --> 01:38:45,000
The length is 1061 and we are now creating a new column called log

1298
01:38:45,000 --> 01:38:50,000
production which is the log of the production of the data frame.

1299
01:38:50,000 --> 01:38:53,000
And we can put we don't have any histograms here.

1300
01:38:53,000 --> 01:38:57,000
We need that out and now the output file is this guy and I will

1301
01:38:57,000 --> 01:39:02,000
actually move this to the top here to the output file.

1302
01:39:02,000 --> 01:39:05,000
The very first thing you see here will be the name of the output file

1303
01:39:05,000 --> 01:39:09,000
and the last thing we'll do is actually write that CSV to that output file.

1304
01:39:09,000 --> 01:39:13,000
So now when I load in this cleaned coal public 2013 and notice

1305
01:39:13,000 --> 01:39:15,000
that I did not overwrite the old file.

1306
01:39:15,000 --> 01:39:18,000
So I strongly recommend keeping the raw files and creating a new file.

1307
01:39:18,000 --> 01:39:21,000
That's the cleaned version of it so that if you ever made a mistake

1308
01:39:21,000 --> 01:39:23,000
in your cleaning which has happened before,

1309
01:39:23,000 --> 01:39:25,000
you can easily revert and change that back.

1310
01:39:25,000 --> 01:39:28,000
And if someone says, oh, something happened in the cleaning process,

1311
01:39:28,000 --> 01:39:30,000
you have a full documentation of what happened here.

1312
01:39:30,000 --> 01:39:34,000
So we've created the final document that went through and cleaned up

1313
01:39:34,000 --> 01:39:37,000
what actually happened in the cleaning process.

1314
01:39:37,000 --> 01:39:40,000
So anyone looking in the future can easily follow what happened.

1315
01:39:40,000 --> 01:39:44,000
So I will now close and halt this directory and I'm going to actually

1316
01:39:44,000 --> 01:39:48,000
do our first commit and we are in the master branch as it sits.

1317
01:39:48,000 --> 01:39:51,000
So I will actually check out a new branch.

1318
01:39:51,000 --> 01:39:58,000
The branch will be called JBW underscore predict production.

1319
01:39:58,000 --> 01:39:59,000
And so we're here.

1320
01:39:59,000 --> 01:40:02,000
There's two theories here on adding the data.

1321
01:40:02,000 --> 01:40:04,000
So the data here is actually pretty small.

1322
01:40:04,000 --> 01:40:06,000
So I'm going to add it to this.

1323
01:40:06,000 --> 01:40:09,000
This is also so that you can actually get the data as well.

1324
01:40:09,000 --> 01:40:10,000
Generally in a production environment,

1325
01:40:10,000 --> 01:40:12,000
you don't add the data to your Git repository.

1326
01:40:12,000 --> 01:40:14,000
This is stored and tracked in some other way.

1327
01:40:14,000 --> 01:40:16,000
So I'll add the data cleaning.

1328
01:40:16,000 --> 01:40:21,000
I'll add develop and not going to add the figures just yet.

1329
01:40:21,000 --> 01:40:25,000
I usually will only add this when I actually have something interesting there.

1330
01:40:25,000 --> 01:40:28,000
So this figures is going to be kept on my own directory for now,

1331
01:40:28,000 --> 01:40:30,000
not put into the branch just yet.

1332
01:40:30,000 --> 01:40:32,000
Let's look at the status one more time.

1333
01:40:32,000 --> 01:40:36,000
So we have a number of new files, the actual data file, the cleaned data file,

1334
01:40:36,000 --> 01:40:40,000
the data cleaning that is the official way of actually making this file

1335
01:40:40,000 --> 01:40:42,000
and this develop one.

1336
01:40:42,000 --> 01:40:45,000
So let's commit this.

1337
01:40:45,000 --> 01:40:47,000
Let's not call it that then.

1338
01:40:47,000 --> 01:40:50,000
And I have to actually configure this.

1339
01:40:50,000 --> 01:40:52,000
So I will configure my Git.

1340
01:40:52,000 --> 01:40:58,000
Do this commit and continue this on in just a second.

1341
01:40:58,000 --> 01:41:06,000
So commit the data and I will be pushing it to GitHub.

1342
01:41:06,000 --> 01:41:10,000
So the final command I ran was git push origin JBW predict production.

1343
01:41:10,000 --> 01:41:13,000
And this means that I have now sent this off to GitHub.

1344
01:41:13,000 --> 01:41:17,000
Go back to the GitHub of the coal exploration, reload this.

1345
01:41:17,000 --> 01:41:21,000
What we see here is the master branch where you can actually go to the

1346
01:41:21,000 --> 01:41:25,000
JBW production branch and see the various things we've done here.

1347
01:41:25,000 --> 01:41:29,000
Let's actually look at the deliver and click this IPYNB.

1348
01:41:29,000 --> 01:41:33,000
And we'll notice that GitHub does a fantastically nice job of actually rendering

1349
01:41:33,000 --> 01:41:36,000
the notebook as it looks correctly.

1350
01:41:36,000 --> 01:41:40,000
And this is even more dramatic when you actually look at the develop one.

1351
01:41:40,000 --> 01:41:44,000
So we can see this and you can see in here if you're browsing with GitHub,

1352
01:41:44,000 --> 01:41:46,000
the figures are faithfully reproduced here.

1353
01:41:46,000 --> 01:41:50,000
And this is a very useful thing to be able to look at the files being used

1354
01:41:50,000 --> 01:41:54,000
and especially when we do a pull request in the future.

1355
01:41:54,000 --> 01:41:56,000
Okay, so we've cleaned the data.

1356
01:41:56,000 --> 01:41:59,000
We have the way that we cleaned it separated out so that anyone else

1357
01:41:59,000 --> 01:42:01,000
can look at it in a reproducible way.

1358
01:42:01,000 --> 01:42:04,000
And so let's actually try to predict something.

1359
01:42:04,000 --> 01:42:08,000
So I'll go back into this develop directory and it will make a copy

1360
01:42:08,000 --> 01:42:11,000
of the first look notebook that we had.

1361
01:42:11,000 --> 01:42:15,000
So I'll make a copy of this and I'm going to call it CoalPredict.

1362
01:42:15,000 --> 01:42:19,000
I'm going to go back to the previous tab and actually finish closing this

1363
01:42:19,000 --> 01:42:20,000
and halting it.

1364
01:42:20,000 --> 01:42:24,000
And just to give you a sense of how everything is standing,

1365
01:42:24,000 --> 01:42:27,000
I'm now back at the home of this develop thing.

1366
01:42:27,000 --> 01:42:31,000
You can see the first look notebook and it's currently black because it's not running.

1367
01:42:31,000 --> 01:42:34,000
This one is green because you can see on the right here it says running.

1368
01:42:34,000 --> 01:42:37,000
So this is a notebook that's currently being run.

1369
01:42:37,000 --> 01:42:40,000
There's a couple of things I want to do different here since this is now the prediction one.

1370
01:42:40,000 --> 01:42:46,000
When I start off by saying what the goal of this notebook is going to be

1371
01:42:46,000 --> 01:42:50,000
and because everything that's here is a direct copy of the previous notebook,

1372
01:42:50,000 --> 01:42:52,000
most of this stuff I'll just be able to delete.

1373
01:42:52,000 --> 01:42:56,000
So I'm going to toggle the header, give us a little bit more space

1374
01:42:56,000 --> 01:43:01,000
and the changes I'm going to make are basically going to drive me toward being able to make this new prediction.

1375
01:43:01,000 --> 01:43:05,000
So first of all, I don't want to reproduce all this cleaning I did before.

1376
01:43:05,000 --> 01:43:08,000
So I will actually instead of reading in the previous raw data,

1377
01:43:08,000 --> 01:43:11,000
I'll actually go into and read the CSV that we saved.

1378
01:43:11,000 --> 01:43:17,000
And this is up into the data directory and it's the cleaned public CSV.

1379
01:43:17,000 --> 01:43:22,000
And we still need to set the index column to be the MSHA ID.

1380
01:43:22,000 --> 01:43:27,000
So that's loaded in and actually one thing I like to do is look at the head of the data frame

1381
01:43:27,000 --> 01:43:31,000
and read it in at the same time in case I need to make any changes.

1382
01:43:31,000 --> 01:43:35,000
So the way to do this is since the four is selected with a gray box,

1383
01:43:35,000 --> 01:43:41,000
if I hold down shift and type K, I'm selecting both the second and third cell which are index three and four.

1384
01:43:41,000 --> 01:43:46,000
If I type shift M, they are now combined into a single merged cell.

1385
01:43:46,000 --> 01:43:53,000
So let me just run this one cell and I read in the CSV and then you are seeing the head of that data frame as well.

1386
01:43:53,000 --> 01:43:58,000
So we can see that we're loading in the cleaned CSV and the head is looking nice.

1387
01:43:58,000 --> 01:44:02,000
I'm going to now delete a number of these things because we don't need them.

1388
01:44:02,000 --> 01:44:07,000
One thing I will remain is that we initially did this LEN of the data frame before.

1389
01:44:07,000 --> 01:44:10,000
This was on the first one that you saw on the raw data.

1390
01:44:10,000 --> 01:44:13,000
So since this is the clean data, I expect this to be just over a thousand.

1391
01:44:13,000 --> 01:44:16,000
Yep, it went to 1061.

1392
01:44:16,000 --> 01:44:18,000
Simply delete these.

1393
01:44:18,000 --> 01:44:24,000
I'll leave the number of columns in here so we can actually think about what's in each of these columns a bit.

1394
01:44:24,000 --> 01:44:27,000
Alright, so as we see, this is the production.

1395
01:44:27,000 --> 01:44:31,000
Longer the production is the thing that we're going to be trying to predict.

1396
01:44:31,000 --> 01:44:36,000
And let's take a look at just a high level view of the different categories that might be able to help us.

1397
01:44:36,000 --> 01:44:38,000
So let me get the columns here.

1398
01:44:38,000 --> 01:44:42,000
I think that the mine status might be a predictive variable.

1399
01:44:42,000 --> 01:44:45,000
So I do df.mine status.

1400
01:44:45,000 --> 01:44:51,000
You see that there's an active men working, not producing, permanently abandoned, active,

1401
01:44:51,000 --> 01:44:55,000
temporarily closed and new under construction of the different status types.

1402
01:44:55,000 --> 01:45:00,000
I suspect this will give me a pretty good predictor into how productive the mine actually is.

1403
01:45:00,000 --> 01:45:04,000
So I will actually do a group by on this to see what is in here.

1404
01:45:04,000 --> 01:45:08,000
So df.mine status.

1405
01:45:08,000 --> 01:45:16,000
Let's do production.

1406
01:45:16,000 --> 01:45:25,000
What I did here was I said, take all the ones that have the same status of active and take the average or the mean of the production in short tons.

1407
01:45:25,000 --> 01:45:31,000
And we can see that the active ones are much more productive than the temporarily closed ones or the permanently abandoned ones.

1408
01:45:31,000 --> 01:45:36,000
It's interesting to me that permanently abandoned has on average 60,000 tons.

1409
01:45:36,000 --> 01:45:40,000
Let's look at it in terms of the log of the production though.

1410
01:45:40,000 --> 01:45:43,000
This will be what I think we're going to be going against.

1411
01:45:43,000 --> 01:45:50,000
So huge difference in the overall production capabilities, but we'll see how good this is at making a final prediction.

1412
01:45:50,000 --> 01:45:56,000
So from here is we would like to predict the log of coal mines.

1413
01:45:56,000 --> 01:46:02,000
And we'd also like to know what actually leads to the production, higher production and lower production.

1414
01:46:02,000 --> 01:46:08,000
If we look again at all the columns in our data frame, the data that we have year is the same for all of them.

1415
01:46:08,000 --> 01:46:11,000
And various things that shouldn't matter at all.

1416
01:46:11,000 --> 01:46:20,000
Like the union code is just going to be a code that's given to the mine from a, let's just look at that.

1417
01:46:20,000 --> 01:46:22,000
Actually, that might be predictive.

1418
01:46:22,000 --> 01:46:27,000
So I'm going to try to throw as many of these things as we can into a predictive model.

1419
01:46:27,000 --> 01:46:29,000
So I'll call these features.

1420
01:46:29,000 --> 01:46:32,000
And let's start with this as our list of features.

1421
01:46:32,000 --> 01:46:36,000
We'll have our target be log production.

1422
01:46:36,000 --> 01:46:42,000
So year is going to be entirely unpredictable because it's a single thing.

1423
01:46:42,000 --> 01:46:46,000
Mine name, I suspect will not be predictive because it's simply the mine.

1424
01:46:46,000 --> 01:46:51,000
The state might be what state is it in, what county is it in that could be useful.

1425
01:46:51,000 --> 01:46:54,000
The mine status, I'm sure will be predictive.

1426
01:46:54,000 --> 01:47:05,000
Mine type will probably be it's possible that the operating type, the address of the operating company probably isn't because we already have the geographic things done with the county and the state.

1427
01:47:05,000 --> 01:47:09,000
Though it's interesting, we'll definitely have some collinearity between the state and the county.

1428
01:47:09,000 --> 01:47:11,000
So it's possible that particular county and the state's good.

1429
01:47:11,000 --> 01:47:12,000
We'll leave those in.

1430
01:47:12,000 --> 01:47:16,000
Leave in the union code, the coal supply region.

1431
01:47:16,000 --> 01:47:22,000
We can't give it the production of short tons as a prediction of the log of the production because that's cheating.

1432
01:47:22,000 --> 01:47:26,000
The number of employees that are employed and the number of labor hours.

1433
01:47:26,000 --> 01:47:27,000
Just to clean this up.

1434
01:47:27,000 --> 01:47:32,000
So I hold down shift and push the down arrow key and I've highlighted everything to indent.

1435
01:47:32,000 --> 01:47:36,000
I'm going to hold down command and hit the right bracket key, which is the square brackets.

1436
01:47:36,000 --> 01:47:38,000
So the parentheses are curved all the way around.

1437
01:47:38,000 --> 01:47:42,000
There's curly braces, which have a lot of curls in the square brackets.

1438
01:47:42,000 --> 01:47:46,000
So holding down command and typing the right one will indent an entire block of text.

1439
01:47:46,000 --> 01:47:49,000
If you do the left bracket, it unindents.

1440
01:47:49,000 --> 01:47:52,000
This is a quick way of formatting lists.

1441
01:47:52,000 --> 01:47:57,000
So the features that we're going to be giving our model are going to be all of these features here.

1442
01:47:57,000 --> 01:48:00,000
The target's going to be the log of the production.

1443
01:48:00,000 --> 01:48:06,000
Now of these, I think only two of these are actually numbers to start with.

1444
01:48:06,000 --> 01:48:11,000
So I think average employees and labor hours are the only ones that are proper features.

1445
01:48:11,000 --> 01:48:14,000
And the rest of them are what I'm going to call categorical.

1446
01:48:14,000 --> 01:48:23,000
So the categoricals are these minus the average employees in the labor hours.

1447
01:48:23,000 --> 01:48:26,000
And having a trailing comma here is actually okay.

1448
01:48:26,000 --> 01:48:28,000
We need commas between all the rest of them otherwise.

1449
01:48:28,000 --> 01:48:30,000
But this is one of my favorite features of Python.

1450
01:48:30,000 --> 01:48:32,000
And I don't know why it makes me so happy.

1451
01:48:32,000 --> 01:48:36,000
But having a trailing comma and having it not have a problem just makes me really happy.

1452
01:48:36,000 --> 01:48:40,000
So the features, which I'm going to just call the ones that are numeric,

1453
01:48:40,000 --> 01:48:43,000
are the average employees and labor hours.

1454
01:48:43,000 --> 01:48:46,000
The categoricals are the ones that are category variables.

1455
01:48:46,000 --> 01:48:51,000
So mine state, county, status, type, company type, operating type, union code,

1456
01:48:51,000 --> 01:48:54,000
and coal supply region are all categoricals.

1457
01:48:54,000 --> 01:48:58,000
One thing that we'll have to do is create, because we'll be using scikit-learn,

1458
01:48:58,000 --> 01:49:03,000
we'll have to turn these categoricals into numbers or into some sort of numerical thing.

1459
01:49:03,000 --> 01:49:06,000
And we'll be doing that with what's called a one-hot encoding.

1460
01:49:06,000 --> 01:49:09,000
Also called dummy variables. There's probably a few other names as well.

1461
01:49:09,000 --> 01:49:11,000
So we split this up into numeric features.

1462
01:49:11,000 --> 01:49:14,000
So things that have numbers representing how long people worked,

1463
01:49:14,000 --> 01:49:18,000
how many employees a mine has, categorical, which is what state

1464
01:49:18,000 --> 01:49:20,000
or some other thing that actually has a category,

1465
01:49:20,000 --> 01:49:23,000
and the target variable, which is log of the production.

1466
01:49:23,000 --> 01:49:26,000
From here, we need to do a bit more data munging after it's all been cleaned.

1467
01:49:26,000 --> 01:49:34,000
We now have to do some munging to make this into a form that scikit-learn can actually predict with.

1468
01:49:34,000 --> 01:49:40,000
In this lesson, we'll be looking at the final data munging and the final prediction for this data.

1469
01:49:40,000 --> 01:49:42,000
So I've actually changed up this slightly.

1470
01:49:42,000 --> 01:49:45,000
So the features that we'll be looking at, these are numeric features to start with.

1471
01:49:45,000 --> 01:49:50,000
The average number of employees per mine and the number of labor hours total worked for that mine.

1472
01:49:50,000 --> 01:49:54,000
And also a categorical list. This categorical list contains features

1473
01:49:54,000 --> 01:50:00,000
which have a small number of string representations instead of actual numbers.

1474
01:50:00,000 --> 01:50:06,000
And again, the target we're looking at is the log value of the production in tons.

1475
01:50:06,000 --> 01:50:10,000
So one thing that I recommend you doing is taking a look at the interplay

1476
01:50:10,000 --> 01:50:13,000
between each of the variables and the target variable.

1477
01:50:13,000 --> 01:50:16,000
So I'll do a quick example of this.

1478
01:50:16,000 --> 01:50:20,000
So let's take a look at the relationship between mine status,

1479
01:50:20,000 --> 01:50:23,000
which is a categorical variable, and the log of the production.

1480
01:50:23,000 --> 01:50:28,000
I'll be doing that with this Seaborn code here, which I just executed.

1481
01:50:28,000 --> 01:50:32,000
And the set context has to be run twice the first time.

1482
01:50:32,000 --> 01:50:35,000
What this is doing is doing a violin plot.

1483
01:50:35,000 --> 01:50:38,000
So this is the Seaborn library SNS, and it's creating this.

1484
01:50:38,000 --> 01:50:40,000
It's using the violin plot function.

1485
01:50:40,000 --> 01:50:45,000
And what we see here on the y-axis is the mine status, the five possible values,

1486
01:50:45,000 --> 01:50:49,000
active with men working but not producing, permanently abandoned, active,

1487
01:50:49,000 --> 01:50:52,000
temporarily closed, and new under construction.

1488
01:50:52,000 --> 01:50:56,000
And on the x-axis, we see the log of the production.

1489
01:50:56,000 --> 01:51:01,000
So you see that each of these mine status types corresponds to a different log

1490
01:51:01,000 --> 01:51:03,000
of the production value of that mine.

1491
01:51:03,000 --> 01:51:06,000
But also the distribution has this interesting shape,

1492
01:51:06,000 --> 01:51:08,000
and it changes between these categories.

1493
01:51:08,000 --> 01:51:11,000
This kind of a plot is a very nice high level view of what these variables

1494
01:51:11,000 --> 01:51:13,000
interactions look like.

1495
01:51:13,000 --> 01:51:14,000
I'll do just one more.

1496
01:51:14,000 --> 01:51:17,000
How does company type corresponds to the production?

1497
01:51:17,000 --> 01:51:20,000
So we see that there are three company types here, independent producer,

1498
01:51:20,000 --> 01:51:23,000
operating subsidiary and contractor, and each of those corresponds

1499
01:51:23,000 --> 01:51:25,000
to a very different distribution.

1500
01:51:25,000 --> 01:51:28,000
So you can do this for all of the variables, and I recommend doing that,

1501
01:51:28,000 --> 01:51:31,000
especially before and getting a sense of what the data actually looks like.

1502
01:51:31,000 --> 01:51:35,000
But for us, we just look at this company type a little bit more closely.

1503
01:51:35,000 --> 01:51:40,000
So if we do a DF company type dot unique, we return all the unique values.

1504
01:51:40,000 --> 01:51:42,000
Of course, we see the three that we see in the plot above.

1505
01:51:42,000 --> 01:51:46,000
An independent producer operator operating subsidiary and contractor.

1506
01:51:46,000 --> 01:51:51,000
The scikit-learn functions don't take in these strings as separate

1507
01:51:51,000 --> 01:51:53,000
category variables.

1508
01:51:53,000 --> 01:51:55,000
We actually have to encode this ourselves.

1509
01:51:55,000 --> 01:51:58,000
Now one way to encode this would be to do something like assign

1510
01:51:58,000 --> 01:52:02,000
independent producer to be one, operating subsidiary to be two,

1511
01:52:02,000 --> 01:52:03,000
and contractor to be three.

1512
01:52:03,000 --> 01:52:06,000
And that would work except that we are then implicitly telling,

1513
01:52:06,000 --> 01:52:10,000
let's say a scikit-learn random forest function that three is greater than two,

1514
01:52:10,000 --> 01:52:11,000
which is also greater than one.

1515
01:52:11,000 --> 01:52:13,000
And there's an implicit ordering there.

1516
01:52:13,000 --> 01:52:17,000
And it might start to try to cut the features in a way that doesn't make sense.

1517
01:52:17,000 --> 01:52:21,000
A more safe way to do this is to actually create what's called dummy variables.

1518
01:52:21,000 --> 01:52:24,000
Pandas has a built-in dummy variable function.

1519
01:52:24,000 --> 01:52:28,000
So we do PD dot get dummies on the data frame with just,

1520
01:52:28,000 --> 01:52:31,000
we're looking at the single column of company type.

1521
01:52:31,000 --> 01:52:33,000
And I'm taking a sample of 50 so that we get a mix of types,

1522
01:52:33,000 --> 01:52:35,000
because it's actually ordered in this data set,

1523
01:52:35,000 --> 01:52:37,000
and just taking a look at the top 10.

1524
01:52:37,000 --> 01:52:39,000
So I'm going to run this a couple of times.

1525
01:52:39,000 --> 01:52:41,000
This sample will actually re-sample every time I run it.

1526
01:52:41,000 --> 01:52:45,000
So what we see here is the contractor independent and operating subsidiary,

1527
01:52:45,000 --> 01:52:48,000
this MSHA ID corresponds to an independent producer operator,

1528
01:52:48,000 --> 01:52:50,000
because it has a one in that column,

1529
01:52:50,000 --> 01:52:52,000
and zeros in each of the other columns.

1530
01:52:52,000 --> 01:52:55,000
And if you go down to this 4407123 ID,

1531
01:52:55,000 --> 01:52:57,000
it is an operating subsidiary company,

1532
01:52:57,000 --> 01:52:59,000
and it has zeros in the rest of the column.

1533
01:52:59,000 --> 01:53:02,000
So this is what the get dummies function does with pandas.

1534
01:53:02,000 --> 01:53:05,000
Now what we want to do is actually turn each of the categorical variables

1535
01:53:05,000 --> 01:53:07,000
that we're looking at into dummy variables.

1536
01:53:07,000 --> 01:53:10,000
And then we'll actually learn to drop one of the variables

1537
01:53:10,000 --> 01:53:12,000
to avoid the dummy variable trap.

1538
01:53:12,000 --> 01:53:15,000
We're then going to concat the data frames together.

1539
01:53:15,000 --> 01:53:18,000
So we're taking the data frame and the temporary data frame together.

1540
01:53:18,000 --> 01:53:23,000
And axis equals 1 means it will add it as columns to the existing data frames.

1541
01:53:23,000 --> 01:53:27,000
And we will then drop the drop variable from the data frame

1542
01:53:27,000 --> 01:53:33,000
and call that to list function on the columns of the temporary data frame

1543
01:53:33,000 --> 01:53:37,000
so that we have a final list of what the dummy categories look like.

1544
01:53:37,000 --> 01:53:39,000
Let's run that real fast.

1545
01:53:39,000 --> 01:53:40,000
It completes very quickly.

1546
01:53:40,000 --> 01:53:44,000
We see that there are 29 mine states, 164 mine counties.

1547
01:53:44,000 --> 01:53:45,000
So this might be a little bit high.

1548
01:53:45,000 --> 01:53:47,000
We might have to come back and look at that.

1549
01:53:47,000 --> 01:53:51,000
The mine status, there's five, mine type 3, company type 3, and so on.

1550
01:53:51,000 --> 01:53:53,000
And the actual value of the dummy variables themselves,

1551
01:53:53,000 --> 01:53:55,000
let's take a look at say the first 10.

1552
01:53:55,000 --> 01:53:59,000
We see mine state, Alabama, mine state, Alaska, and so on.

1553
01:53:59,000 --> 01:54:01,000
So these are the different state variables

1554
01:54:01,000 --> 01:54:03,000
that have been created.

1555
01:54:03,000 --> 01:54:05,000
Let's actually start to build a model.

1556
01:54:05,000 --> 01:54:09,000
So we'll say, so I created this as a markdown

1557
01:54:09,000 --> 01:54:13,000
by typing escape to make me into select mode instead of insert mode

1558
01:54:13,000 --> 01:54:15,000
and typing m, m for markdown.

1559
01:54:15,000 --> 01:54:17,000
You can also go up here and click it.

1560
01:54:17,000 --> 01:54:20,000
So if I could go back to code, this is simply commented out Python code

1561
01:54:20,000 --> 01:54:21,000
as far as the notebook is concerned.

1562
01:54:21,000 --> 01:54:23,000
We actually want this to be markdown.

1563
01:54:23,000 --> 01:54:26,000
So we click markdown and you can see it pre-rendered

1564
01:54:26,000 --> 01:54:27,000
before we actually execute the cell.

1565
01:54:27,000 --> 01:54:29,000
And it looks like this nice bold font.

1566
01:54:29,000 --> 01:54:32,000
We're going to need to import a couple of things from scikit-learn itself.

1567
01:54:32,000 --> 01:54:35,000
So we're going to say from scikit-learn dot cross validation.

1568
01:54:35,000 --> 01:54:38,000
So this is the sub module of scikit-learn.

1569
01:54:38,000 --> 01:54:42,000
We're going to import the test train split function, which is labeled here.

1570
01:54:42,000 --> 01:54:46,000
And we're also going to use a random force regressor as our algorithm.

1571
01:54:46,000 --> 01:54:51,000
Loading that in, you look at total length of the dummy categoricals is 213.

1572
01:54:51,000 --> 01:54:55,000
The train and test is going to be the names of the data frames

1573
01:54:55,000 --> 01:54:59,000
that's going to be split by this test train split function.

1574
01:54:59,000 --> 01:55:02,000
The function takes in our data frame.

1575
01:55:02,000 --> 01:55:05,000
And you tell it how large you'd like the test size to be.

1576
01:55:05,000 --> 01:55:09,000
So in this case, we're going to have a 30% of the data frame is going to be the holdout set.

1577
01:55:09,000 --> 01:55:13,000
And the nice thing about this function is that we actually retain

1578
01:55:13,000 --> 01:55:16,000
the data frame structure of these variables.

1579
01:55:16,000 --> 01:55:19,000
Scikit-learn likes to think in terms of native numpy arrays,

1580
01:55:19,000 --> 01:55:23,000
but many of the features can actually read in a pandas data frame as well.

1581
01:55:23,000 --> 01:55:27,000
And the utility of having a pandas data frame around just makes it really nice to keep it,

1582
01:55:27,000 --> 01:55:29,000
to stay in data frames as long as you can.

1583
01:55:29,000 --> 01:55:32,000
So we can actually do it the whole way through. So that's really nice.

1584
01:55:32,000 --> 01:55:35,000
Our train is a data frame. Our test is a data frame.

1585
01:55:35,000 --> 01:55:39,000
And they've been split from the data frame that contains all of our data.

1586
01:55:39,000 --> 01:55:41,000
So now we're going to create a random forest.

1587
01:55:41,000 --> 01:55:43,000
And I would like to run these separately.

1588
01:55:43,000 --> 01:55:49,000
So I'm going to split this cell here by typing control shift minus splits the cells into two.

1589
01:55:49,000 --> 01:55:51,000
And I will execute this one.

1590
01:55:51,000 --> 01:55:54,000
This says RF is an instantiation of this random forest regressor,

1591
01:55:54,000 --> 01:55:56,000
which we imported above.

1592
01:55:56,000 --> 01:55:58,000
And there's two things we're going to initialize it with.

1593
01:55:58,000 --> 01:56:00,000
Number of estimators is 100.

1594
01:56:00,000 --> 01:56:03,000
This is a number of trees that we're going to be building a random forest out of.

1595
01:56:03,000 --> 01:56:05,000
And whether or not we're going to be using the out of bag score,

1596
01:56:05,000 --> 01:56:07,000
which we are in this case.

1597
01:56:07,000 --> 01:56:11,000
So we have an RF model and we'd like to fit on this by giving it

1598
01:56:11,000 --> 01:56:15,000
x comma y and sample equals non as default.

1599
01:56:15,000 --> 01:56:19,000
So the x value is the design matrix.

1600
01:56:19,000 --> 01:56:21,000
The y is the target variable.

1601
01:56:21,000 --> 01:56:24,000
So in our case, we're going to do the train data frame.

1602
01:56:24,000 --> 01:56:26,000
And we're going to give it all the features,

1603
01:56:26,000 --> 01:56:30,000
which is just those two average employees and the total laborer,

1604
01:56:30,000 --> 01:56:32,000
as well as the dummy categoricals.

1605
01:56:32,000 --> 01:56:35,000
Now, these two things together is just adding them together.

1606
01:56:35,000 --> 01:56:37,000
It creates a large Python list.

1607
01:56:37,000 --> 01:56:40,000
We can see the top two things up here at the top,

1608
01:56:40,000 --> 01:56:42,000
average employees and labor hours,

1609
01:56:42,000 --> 01:56:44,000
and then everything else is dummy categoricals.

1610
01:56:44,000 --> 01:56:47,000
We then run the fit method on the random forest

1611
01:56:47,000 --> 01:56:50,000
and we can get the design matrix of train features

1612
01:56:50,000 --> 01:56:53,000
plus dummy categoricals and the target,

1613
01:56:53,000 --> 01:56:56,000
which is train just selected on the target variable,

1614
01:56:56,000 --> 01:56:58,000
which we defined above as log production.

1615
01:56:58,000 --> 01:57:02,000
So it tells us some features or it gives us a little summary

1616
01:57:02,000 --> 01:57:05,000
where it talks about the bootstrap, the criterion as mean squared error,

1617
01:57:05,000 --> 01:57:06,000
various other things here.

1618
01:57:06,000 --> 01:57:08,000
So this is all the variables that you can change very easily.

1619
01:57:08,000 --> 01:57:11,000
If you'd like to actually tweak this for your own problems.

1620
01:57:11,000 --> 01:57:13,000
So let's take a look at how well this does.

1621
01:57:13,000 --> 01:57:16,000
And we're going to do this by giving a seaborne plot again,

1622
01:57:16,000 --> 01:57:18,000
a regression plot, but except the train,

1623
01:57:18,000 --> 01:57:21,000
we're going to be using the test data frame.

1624
01:57:21,000 --> 01:57:24,000
So I test the target and the regression plot here is going to be

1625
01:57:24,000 --> 01:57:29,000
in target versus what we actually predict this to be.

1626
01:57:29,000 --> 01:57:31,000
So the actual is along the x-axis here.

1627
01:57:31,000 --> 01:57:33,000
This is what the actual production is.

1628
01:57:33,000 --> 01:57:37,000
And the y-axis is the predicted value.

1629
01:57:37,000 --> 01:57:39,000
I can actually add that in.

1630
01:57:39,000 --> 01:57:40,000
I think it should be there.

1631
01:57:40,000 --> 01:57:43,000
So we say predicted production.

1632
01:57:43,000 --> 01:57:45,000
So predicted production is on the y-axis

1633
01:57:45,000 --> 01:57:47,000
and the actual production is along the x-axis.

1634
01:57:47,000 --> 01:57:50,000
So perfectly calibrated and perfectly predictive thing.

1635
01:57:50,000 --> 01:57:54,000
Everything would line along this one to one ratio line here.

1636
01:57:54,000 --> 01:57:55,000
We see that there's some scatter around it,

1637
01:57:55,000 --> 01:57:58,000
but actually it looks like it's a pretty good overall predictor

1638
01:57:58,000 --> 01:58:00,000
of the actual production.

1639
01:58:00,000 --> 01:58:02,000
We'd like to actually see how good is this fit

1640
01:58:02,000 --> 01:58:03,000
rather than just look at the plot and say,

1641
01:58:03,000 --> 01:58:04,000
oh, it looks pretty good.

1642
01:58:04,000 --> 01:58:08,000
So let's import a few of the test metrics that we can actually look at.

1643
01:58:08,000 --> 01:58:12,000
So we can say we can import explained variance score,

1644
01:58:12,000 --> 01:58:15,000
the R2 scored, and the mean squared error.

1645
01:58:15,000 --> 01:58:17,000
So the way these functions work,

1646
01:58:17,000 --> 01:58:21,000
they always take in the true and then they take in the predicted.

1647
01:58:21,000 --> 01:58:23,000
So this is going to be test target

1648
01:58:23,000 --> 01:58:25,000
and then the predicted test target.

1649
01:58:25,000 --> 01:58:29,000
And actually I think this way of writing it is a little bit too verbose.

1650
01:58:29,000 --> 01:58:32,000
So I'm going to call it predicted equals this.

1651
01:58:32,000 --> 01:58:35,000
And I'm going to say predicted here.

1652
01:58:35,000 --> 01:58:38,000
So the R squared score is 0.88.

1653
01:58:38,000 --> 01:58:42,000
Explained variance score is 0.88 as well.

1654
01:58:42,000 --> 01:58:45,000
The mean squared error is 0.54.

1655
01:58:45,000 --> 01:58:47,000
And now because this is a random forest,

1656
01:58:47,000 --> 01:58:50,000
we actually have the feature importance of the model.

1657
01:58:50,000 --> 01:58:54,000
And I don't know of a good way that's naturally given by scikit-learn

1658
01:58:54,000 --> 01:58:55,000
to actually report this,

1659
01:58:55,000 --> 01:58:57,000
but here's a little bit of code that I have written to make it

1660
01:58:57,000 --> 01:59:00,000
so that I can actually read this in a way that I actually think is useful.

1661
01:59:00,000 --> 01:59:02,000
So I'm going to create a new pandas data frame

1662
01:59:02,000 --> 01:59:04,000
called rf underscore importances,

1663
01:59:04,000 --> 01:59:09,000
which actually takes out the features and the importances from the fit model.

1664
01:59:09,000 --> 01:59:12,000
And I'm going to look at that at the top 20 here.

1665
01:59:12,000 --> 01:59:16,000
All of the importances of every variable we give it to in total adds up to one.

1666
01:59:16,000 --> 01:59:19,000
So we can think of this as fractional importance

1667
01:59:19,000 --> 01:59:21,000
in terms of what the random forest has decided

1668
01:59:21,000 --> 01:59:25,000
is going to be discriminative in giving us a final regression score.

1669
01:59:25,000 --> 01:59:28,000
So of utmost importance is the labor hours

1670
01:59:28,000 --> 01:59:30,000
and then average employees is down from there.

1671
01:59:30,000 --> 01:59:33,000
The mine type being surface is predictive.

1672
01:59:33,000 --> 01:59:35,000
The mine county being campel

1673
01:59:35,000 --> 01:59:39,000
and coal supply region powder river basin is apparently moderately predictive.

1674
01:59:39,000 --> 01:59:41,000
And then it goes down from there.

1675
01:59:41,000 --> 01:59:42,000
So this is just the first 20.

1676
01:59:42,000 --> 01:59:46,000
And we have not only a final fit with a nice plot,

1677
01:59:46,000 --> 01:59:48,000
we also have some diagnostics and metrics,

1678
01:59:48,000 --> 01:59:51,000
as well as a list of what's important.

1679
01:59:53,000 --> 01:59:54,000
In this video,

1680
01:59:54,000 --> 01:59:58,000
I'll be showing you how to take a development lab notebook

1681
01:59:58,000 --> 02:00:01,000
and turn it into a deliverable notebook.

1682
02:00:01,000 --> 02:00:06,000
So let's go into our directory and we go to the develop folder.

1683
02:00:06,000 --> 02:00:08,000
Clicking that we navigate into that folder

1684
02:00:08,000 --> 02:00:10,000
and we see we had our first look notebook

1685
02:00:10,000 --> 02:00:12,000
and then this coal prediction notebook.

1686
02:00:12,000 --> 02:00:15,000
And what we'd like to do is make a copy of this notebook.

1687
02:00:15,000 --> 02:00:19,000
So you can select it by clicking this checkbox here

1688
02:00:19,000 --> 02:00:21,000
and clicking duplicate.

1689
02:00:21,000 --> 02:00:24,000
When we do that, we have a second copy of this,

1690
02:00:24,000 --> 02:00:27,000
which is added to the end of the name copy one.

1691
02:00:27,000 --> 02:00:31,000
Now this file should exist in this directory and we see it here.

1692
02:00:31,000 --> 02:00:32,000
Copy one.

1693
02:00:32,000 --> 02:00:34,000
Because it's going to be a deliverable notebook,

1694
02:00:34,000 --> 02:00:37,000
we should actually move this into the delivery folder.

1695
02:00:37,000 --> 02:00:44,000
So let's move 2015 coal predict copy into the deliver directory.

1696
02:00:44,000 --> 02:00:46,000
Go over to the deliver directory

1697
02:00:46,000 --> 02:00:50,000
and let's navigate there with the notebook server itself.

1698
02:00:50,000 --> 02:00:52,000
Let's open this up.

1699
02:00:52,000 --> 02:00:54,000
Okay, so let's first give this a title

1700
02:00:54,000 --> 02:00:56,000
that we think is an appropriate title.

1701
02:00:56,000 --> 02:00:58,000
And because it's going to be a deliverable notebook,

1702
02:00:58,000 --> 02:01:00,000
it shouldn't start with a date.

1703
02:01:00,000 --> 02:01:06,000
So it should start with something like coal prediction of production.

1704
02:01:06,000 --> 02:01:08,000
So we have a new name for this.

1705
02:01:08,000 --> 02:01:11,000
You can save this and I'm going to toggle that header bar.

1706
02:01:11,000 --> 02:01:13,000
So I have a little bit more space

1707
02:01:13,000 --> 02:01:16,000
and I'm going to toggle this toolbar as well

1708
02:01:16,000 --> 02:01:19,000
because I'll mostly be using keyboard shortcuts.

1709
02:01:19,000 --> 02:01:23,000
So at this stage, we have this long notebook that went through

1710
02:01:23,000 --> 02:01:26,000
and it's a complete copy of our lab notebook style.

1711
02:01:26,000 --> 02:01:29,000
So we can delete things here pretty freely

1712
02:01:29,000 --> 02:01:32,000
and just focus on the main story that you'd like to tell

1713
02:01:32,000 --> 02:01:34,000
to either your teammates or your manager

1714
02:01:34,000 --> 02:01:36,000
or whoever is going to be consuming this.

1715
02:01:36,000 --> 02:01:39,000
So keep in mind with your audience what you think they would like to see

1716
02:01:39,000 --> 02:01:41,000
and cut out the extraneous stuff

1717
02:01:41,000 --> 02:01:43,000
and adding in as much text as you think is useful.

1718
02:01:43,000 --> 02:01:45,000
And in that keyboard shortcuts,

1719
02:01:45,000 --> 02:01:48,000
especially are going to be make your life a lot easier

1720
02:01:48,000 --> 02:01:50,000
and make this whole process really fast.

1721
02:01:50,000 --> 02:01:52,000
All right, so let's just go through this.

1722
02:01:52,000 --> 02:01:55,000
And initially what I'd like to do is give a good title

1723
02:01:55,000 --> 02:02:00,000
and you can just call it coal production in mines 2013, let's say.

1724
02:02:00,000 --> 02:02:03,000
And so we have our first setup here

1725
02:02:03,000 --> 02:02:05,000
and you can also give a little abstracts.

1726
02:02:05,000 --> 02:02:07,000
You can say we did a lot of analysis,

1727
02:02:07,000 --> 02:02:09,000
came to some interesting conclusions.

1728
02:02:09,000 --> 02:02:13,000
Now, of course, fill that out with more verbiage as you see fit.

1729
02:02:13,000 --> 02:02:15,000
Keeping the code in this notebook is useful

1730
02:02:15,000 --> 02:02:17,000
so that someone else looking down the road

1731
02:02:17,000 --> 02:02:19,000
can actually reproduce all the key results

1732
02:02:19,000 --> 02:02:21,000
that you think you can find.

1733
02:02:21,000 --> 02:02:23,000
Now, this isn't always possible, but as far as it is possible,

1734
02:02:23,000 --> 02:02:25,000
I recommend trying to do it.

1735
02:02:25,000 --> 02:02:27,000
So try to keep the imports neat and tidy.

1736
02:02:27,000 --> 02:02:29,000
Keep only the imports that are required

1737
02:02:29,000 --> 02:02:31,000
and remove the ones that are extraneous.

1738
02:02:31,000 --> 02:02:33,000
I think we actually use all of these.

1739
02:02:33,000 --> 02:02:35,000
I would recommend keeping these magic imports

1740
02:02:35,000 --> 02:02:37,000
on their own line at the top.

1741
02:02:37,000 --> 02:02:40,000
So having matplotlib inline at the top, that is good.

1742
02:02:40,000 --> 02:02:42,000
Put a space between that.

1743
02:02:42,000 --> 02:02:44,000
The Pepe convention is to have one of the standard libraries,

1744
02:02:44,000 --> 02:02:46,000
like import string, let's say.

1745
02:02:46,000 --> 02:02:48,000
That would be next and any of the other ones here,

1746
02:02:48,000 --> 02:02:51,000
and then another blank line before third-party libraries,

1747
02:02:51,000 --> 02:02:53,000
which is what these are.

1748
02:02:53,000 --> 02:02:56,000
And finally, we have an actual plotting change

1749
02:02:56,000 --> 02:02:59,000
that we make with this SNS command here.

1750
02:02:59,000 --> 02:03:02,000
So we execute that cell and make sure everything is making sense.

1751
02:03:02,000 --> 02:03:04,000
Yes, we see this warning, we've seen this before,

1752
02:03:04,000 --> 02:03:06,000
so we're not too worried about it.

1753
02:03:06,000 --> 02:03:08,000
Now, from here on out, we should be making decisions

1754
02:03:08,000 --> 02:03:10,000
about whether this actually improves the story

1755
02:03:10,000 --> 02:03:13,000
for the person reading this or if it becomes just tedious.

1756
02:03:13,000 --> 02:03:16,000
And when you have data that's being imported

1757
02:03:16,000 --> 02:03:18,000
and it's changed from the raw data,

1758
02:03:18,000 --> 02:03:20,000
there's this clean data set here.

1759
02:03:20,000 --> 02:03:23,000
I think it needs to have some extra commentary around it

1760
02:03:23,000 --> 02:03:25,000
so that people know what's going on.

1761
02:03:25,000 --> 02:03:27,000
So I might say...

1762
02:03:30,000 --> 02:03:32,000
I might give it a description about where exactly it is

1763
02:03:32,000 --> 02:03:35,000
in this repo, and let's just type an ls here.

1764
02:03:35,000 --> 02:03:38,000
The name of the notebook is data underscore cleaning.

1765
02:03:38,000 --> 02:03:41,000
So we will say the same thing.

1766
02:03:41,000 --> 02:03:44,000
Double click, drag over, command C to copy that,

1767
02:03:44,000 --> 02:03:46,000
command V to paste.

1768
02:03:46,000 --> 02:03:49,000
And this ls command, which is handy, we can be deleted.

1769
02:03:49,000 --> 02:03:52,000
So typing escape to get out of the insert mode

1770
02:03:52,000 --> 02:03:55,000
so that the cell is now surrounded by a gray box.

1771
02:03:55,000 --> 02:03:58,000
And then typing D twice, it deletes that cell.

1772
02:03:58,000 --> 02:04:01,000
And in this cell, we are starting to write some markdown.

1773
02:04:01,000 --> 02:04:03,000
We can tell it's markdown because it's just a text

1774
02:04:03,000 --> 02:04:05,000
for people to look at.

1775
02:04:05,000 --> 02:04:07,000
But also, we've put a double header marking too.

1776
02:04:07,000 --> 02:04:10,000
So let's just change this cell type to be markdown.

1777
02:04:10,000 --> 02:04:12,000
So we're currently in a code cell.

1778
02:04:12,000 --> 02:04:14,000
We can change it to be markdown by typing M.

1779
02:04:14,000 --> 02:04:17,000
And as soon as you type M, it switches into markdown

1780
02:04:17,000 --> 02:04:19,000
and gives you a preview of what this will look like

1781
02:04:19,000 --> 02:04:20,000
when you render it.

1782
02:04:20,000 --> 02:04:22,000
So let's render it real fast, shift, enter.

1783
02:04:22,000 --> 02:04:24,000
And we see that this is indeed bolded.

1784
02:04:24,000 --> 02:04:27,000
This two pound signs, or hash signs,

1785
02:04:27,000 --> 02:04:29,000
means it's a H2 heading.

1786
02:04:29,000 --> 02:04:32,000
So this is H1, this is H2,

1787
02:04:32,000 --> 02:04:35,000
and it keeps getting smaller as you go down.

1788
02:04:35,000 --> 02:04:37,000
So in this case, I think clean data just deserves

1789
02:04:37,000 --> 02:04:39,000
a second level heading.

1790
02:04:39,000 --> 02:04:41,000
We said we clean this data in the notebook stored in this.

1791
02:04:41,000 --> 02:04:44,000
So deliver slash data cleaning IPYB.

1792
02:04:44,000 --> 02:04:46,000
So we've told people where this cleaned data file

1793
02:04:46,000 --> 02:04:48,000
actually sits.

1794
02:04:48,000 --> 02:04:51,000
And we actually know the exact steps that went through

1795
02:04:51,000 --> 02:04:53,000
to take it from the raw data into this cleaned data,

1796
02:04:53,000 --> 02:04:55,000
which we've pointed to here.

1797
02:04:55,000 --> 02:04:58,000
This head is actually quite a bit of text,

1798
02:04:58,000 --> 02:05:00,000
even though it should be the top five lines.

1799
02:05:00,000 --> 02:05:03,000
So if we're going to include something here to make sure

1800
02:05:03,000 --> 02:05:05,000
that the data is read in correctly,

1801
02:05:05,000 --> 02:05:08,000
we might select a few columns that we think are useful.

1802
02:05:08,000 --> 02:05:13,000
So in this case, maybe we have year and maybe mine name.

1803
02:05:13,000 --> 02:05:16,000
And so we read in just the heading with those two columns.

1804
02:05:16,000 --> 02:05:19,000
Okay, just to give people a flavor of what's in that data frame.

1805
02:05:19,000 --> 02:05:21,000
This length we don't need to worry about.

1806
02:05:21,000 --> 02:05:23,000
This column thing we don't need to worry about.

1807
02:05:23,000 --> 02:05:25,000
So we delete with 2Ds.

1808
02:05:25,000 --> 02:05:27,000
Now, consider the different plots that you have included.

1809
02:05:27,000 --> 02:05:29,000
And is this something that tells a story?

1810
02:05:29,000 --> 02:05:31,000
If so, leave it in and clean it up so that the axes

1811
02:05:31,000 --> 02:05:33,000
and the colors all look right.

1812
02:05:33,000 --> 02:05:35,000
If not, you can go ahead and just delete it.

1813
02:05:35,000 --> 02:05:37,000
So I think this is deleteable, also deleteable,

1814
02:05:37,000 --> 02:05:39,000
and finally deleteable.

1815
02:05:39,000 --> 02:05:41,000
Okay, so we get to the point where we're predicting

1816
02:05:41,000 --> 02:05:42,000
the production of coal mines.

1817
02:05:42,000 --> 02:05:44,000
Again, we're just looking at what the columns are.

1818
02:05:44,000 --> 02:05:45,000
We don't need this.

1819
02:05:45,000 --> 02:05:47,000
Don't need to know what unique year it is.

1820
02:05:47,000 --> 02:05:50,000
So this is required code, so we need to leave this in.

1821
02:05:50,000 --> 02:05:53,000
Again, clean it up if it needs to be broken up into different cells

1822
02:05:53,000 --> 02:05:56,000
or if you think it needs to be changed in some other way.

1823
02:05:56,000 --> 02:05:58,000
So let's delete a few of these empty ones.

1824
02:05:58,000 --> 02:06:00,000
And let's say we want to like to keep this.

1825
02:06:00,000 --> 02:06:04,000
Let's decide one of these violin plots to keep.

1826
02:06:04,000 --> 02:06:06,000
So let's keep the second one.

1827
02:06:06,000 --> 02:06:08,000
So I'm going to delete this one.

1828
02:06:08,000 --> 02:06:11,000
And to save this, I will say plt.savefig

1829
02:06:11,000 --> 02:06:14,000
and using tab complete and it'll help us know

1830
02:06:14,000 --> 02:06:17,000
where proper structure to put this in here.

1831
02:06:17,000 --> 02:06:20,000
And as I said before, I like to give the same name,

1832
02:06:20,000 --> 02:06:23,000
beginning of the figure that the notebook itself has.

1833
02:06:23,000 --> 02:06:27,000
So in this case, it starts with coal prediction

1834
02:06:27,000 --> 02:06:29,000
as the starting of this notebook name.

1835
02:06:29,000 --> 02:06:32,000
So that looking at this figures folder separately later on,

1836
02:06:32,000 --> 02:06:34,000
someone knows which notebook it came from.

1837
02:06:34,000 --> 02:06:37,000
And then what it's actually being plotted here.

1838
02:06:37,000 --> 02:06:40,000
So we have company type versus log of production.

1839
02:06:40,000 --> 02:06:43,000
So company type versus log production.

1840
02:06:43,000 --> 02:06:46,000
Again, we get a warning, but this should work out just fine.

1841
02:06:46,000 --> 02:06:49,000
Let's run this a second time to make sure everything.

1842
02:06:49,000 --> 02:06:51,000
Okay, so that looks better.

1843
02:06:51,000 --> 02:06:53,000
Running at the second time with the set context

1844
02:06:53,000 --> 02:06:57,000
actually lets the font sizes get to a nice reasonable size.

1845
02:06:57,000 --> 02:06:59,000
Okay, so we are saving this output.

1846
02:06:59,000 --> 02:07:01,000
We think it's useful for our story.

1847
02:07:01,000 --> 02:07:04,000
We again don't need this or looking at this.

1848
02:07:04,000 --> 02:07:06,000
So just typing DD to delete these cells.

1849
02:07:06,000 --> 02:07:08,000
We need to create the dummy categoricals.

1850
02:07:08,000 --> 02:07:10,000
This is required for our analysis.

1851
02:07:10,000 --> 02:07:14,000
We don't necessarily need to actually print the categoricals each time.

1852
02:07:14,000 --> 02:07:16,000
So let's run this comment out that line

1853
02:07:16,000 --> 02:07:19,000
and just double check that that is the same answer as before.

1854
02:07:19,000 --> 02:07:21,000
Okay, let's delete that.

1855
02:07:21,000 --> 02:07:24,000
And we've made a note here about avoiding dummy variable trap.

1856
02:07:24,000 --> 02:07:27,000
You might decide that that needs to be elevated from a comment

1857
02:07:27,000 --> 02:07:29,000
and to mark down cell above it.

1858
02:07:29,000 --> 02:07:31,000
Okay, so let's leave it as a comment here.

1859
02:07:31,000 --> 02:07:34,000
And we don't need to actually look at the categoricals for the final report.

1860
02:07:34,000 --> 02:07:36,000
So let's just delete that.

1861
02:07:36,000 --> 02:07:37,000
Build our model.

1862
02:07:37,000 --> 02:07:39,000
Let's call it a little bit something more descriptive.

1863
02:07:39,000 --> 02:07:42,000
So it's going to be a random forest regressor.

1864
02:07:42,000 --> 02:07:45,000
And we should always put all of the imports

1865
02:07:45,000 --> 02:07:47,000
all the way at the top of the notebook.

1866
02:07:47,000 --> 02:07:50,000
And so let's move this to the top.

1867
02:07:50,000 --> 02:07:53,000
But first let's combine a few of the other imports.

1868
02:07:53,000 --> 02:07:55,000
I think I have a few more imports down here I do.

1869
02:07:55,000 --> 02:07:58,000
So let's move this, I'm going to turn on the toolbar

1870
02:07:58,000 --> 02:08:02,000
and move this up so that it's next to the previous one.

1871
02:08:02,000 --> 02:08:07,000
I'll scroll back down and see if I can find another import.

1872
02:08:07,000 --> 02:08:10,000
It looks like it should be everything.

1873
02:08:10,000 --> 02:08:13,000
A keyboard shortcut that I find that I'm using all the time

1874
02:08:13,000 --> 02:08:16,000
and really saves me time is knowing how to merge and split cells

1875
02:08:16,000 --> 02:08:18,000
with keyboard shortcuts.

1876
02:08:18,000 --> 02:08:21,000
Knowing this will save you tons of time with moving your mouse around.

1877
02:08:21,000 --> 02:08:24,000
So we currently have input cell 30 selected.

1878
02:08:24,000 --> 02:08:27,000
We can type shift and hold it down and then type K.

1879
02:08:27,000 --> 02:08:29,000
We will now select the cell above it.

1880
02:08:29,000 --> 02:08:32,000
We can select as many cells like this as we'd like

1881
02:08:32,000 --> 02:08:35,000
or unselected by typing J to go back down.

1882
02:08:35,000 --> 02:08:37,000
Also, if we go J from here,

1883
02:08:37,000 --> 02:08:40,000
we can select down from the current cell that's selected.

1884
02:08:40,000 --> 02:08:42,000
But let's go up shift K.

1885
02:08:42,000 --> 02:08:46,000
We have selected two cells to merge this type shift M.

1886
02:08:46,000 --> 02:08:48,000
So we've now merged those two cells together.

1887
02:08:48,000 --> 02:08:50,000
Again, you can do that for 10, 20 cells,

1888
02:08:50,000 --> 02:08:52,000
or you can easily split them again.

1889
02:08:52,000 --> 02:08:55,000
I've said multiple times, control shift minus, splits in part,

1890
02:08:55,000 --> 02:08:59,000
escape, shift K, shift M, merges them back together again.

1891
02:08:59,000 --> 02:09:02,000
So this needs to go at the top of the notebook.

1892
02:09:02,000 --> 02:09:05,000
So I will put this to the top by typing this up arrow.

1893
02:09:05,000 --> 02:09:07,000
So bear with me for a second.

1894
02:09:07,000 --> 02:09:09,000
And we need to merge these two cells

1895
02:09:09,000 --> 02:09:11,000
and then do some recombination.

1896
02:09:11,000 --> 02:09:15,000
So shift K, shift M, type return to get a cursor in the cell.

1897
02:09:15,000 --> 02:09:17,000
And we're importing things from sklearn,

1898
02:09:17,000 --> 02:09:19,000
which should go after C-Born,

1899
02:09:19,000 --> 02:09:21,000
for this set command.

1900
02:09:21,000 --> 02:09:24,000
Execute that, and everything looks good again.

1901
02:09:24,000 --> 02:09:27,000
Let's scroll back down to where we've made our progress.

1902
02:09:27,000 --> 02:09:30,000
Down to here, we don't need the length of our demi-categoricals.

1903
02:09:30,000 --> 02:09:33,000
We do need to test train, split our data.

1904
02:09:33,000 --> 02:09:35,000
Let's merge these two cells by typing shift J,

1905
02:09:35,000 --> 02:09:38,000
shift M, and let's just leave that middle line.

1906
02:09:38,000 --> 02:09:40,000
Execute, shift enter.

1907
02:09:40,000 --> 02:09:43,000
And look at our final plot here.

1908
02:09:43,000 --> 02:09:45,000
And this looks like a reasonable good plot.

1909
02:09:45,000 --> 02:09:46,000
Thing looks nice.

1910
02:09:46,000 --> 02:09:49,000
Let's save it out again into the figures directory.

1911
02:09:49,000 --> 02:09:52,000
Let's call this coal production RF prediction.

1912
02:09:52,000 --> 02:09:55,000
Great. So we've now saved this out.

1913
02:09:55,000 --> 02:09:58,000
And we can do our various scores that we'd like to do.

1914
02:09:58,000 --> 02:10:01,000
If we're going to be printing out this output for consumption,

1915
02:10:01,000 --> 02:10:03,000
we should make this look a little bit prettier.

1916
02:10:03,000 --> 02:10:06,000
So let's just do this first one.

1917
02:10:06,000 --> 02:10:10,000
And let's combine these two cells.

1918
02:10:10,000 --> 02:10:12,000
So now we have the R-squared score

1919
02:10:12,000 --> 02:10:14,000
and our mean-squared error scores.

1920
02:10:14,000 --> 02:10:16,000
And finally, our random forest importances.

1921
02:10:16,000 --> 02:10:18,000
And let's just look at the top five.

1922
02:10:18,000 --> 02:10:20,000
So the top five are labor hours all the way down.

1923
02:10:20,000 --> 02:10:21,000
Cool.

1924
02:10:21,000 --> 02:10:23,000
So we've done a lot of rearranging of the code.

1925
02:10:23,000 --> 02:10:27,000
So at this point, I think it's crucial to restart the kernel

1926
02:10:27,000 --> 02:10:29,000
and try to run the entire notebook again.

1927
02:10:29,000 --> 02:10:32,000
If you have some process that actually takes a very long time,

1928
02:10:32,000 --> 02:10:33,000
you can decide not to do that.

1929
02:10:33,000 --> 02:10:35,000
But this, you'd have to take a little bit more care

1930
02:10:35,000 --> 02:10:38,000
into making sure that each piece runs correctly.

1931
02:10:38,000 --> 02:10:41,000
But in this case, this entire analysis runs very quickly.

1932
02:10:41,000 --> 02:10:45,000
So we have no problem clearing all outputs and restarting.

1933
02:10:45,000 --> 02:10:49,000
And clicking cell run all should run every single cell.

1934
02:10:49,000 --> 02:10:52,000
If we've deleted some piece of code that was necessary,

1935
02:10:52,000 --> 02:10:55,000
we'll have an error and we have to go back and correct that.

1936
02:10:55,000 --> 02:10:59,000
Let's go through all the way down to the bottom thing was actually done.

1937
02:10:59,000 --> 02:11:03,000
If there was an error, so let's say it would stop at this fifth cell here.

1938
02:11:03,000 --> 02:11:06,000
It would have an error printout here and nothing else would be executed

1939
02:11:06,000 --> 02:11:08,000
below that when you do this run all cells.

1940
02:11:08,000 --> 02:11:11,000
That's a good way of identifying where the error happened.

1941
02:11:11,000 --> 02:11:13,000
We don't have an error, thankfully, so that's good.

1942
02:11:13,000 --> 02:11:17,000
We do have something that is somewhat annoying to me that this has to be run twice.

1943
02:11:17,000 --> 02:11:21,000
As we can tell, we run this a second time we get our font gets bigger.

1944
02:11:21,000 --> 02:11:23,000
So I think I know what happened.

1945
02:11:23,000 --> 02:11:26,000
I set the context after I set the figure.

1946
02:11:26,000 --> 02:11:29,000
So I'm going to re-align the order of these two pieces of code.

1947
02:11:29,000 --> 02:11:35,000
Save this, restart the kernel, clear all outputs, cell run all.

1948
02:11:35,000 --> 02:11:38,000
And now we see that the font size is the correct size

1949
02:11:38,000 --> 02:11:40,000
and we've run all the way to the bottom.

1950
02:11:40,000 --> 02:11:43,000
And each time we run this, do note that we are overwriting these figure files,

1951
02:11:43,000 --> 02:11:45,000
which is what we were hoping to do,

1952
02:11:45,000 --> 02:11:49,000
but also keep track that is what you indeed want to do when you're running this.

1953
02:11:49,000 --> 02:11:52,000
I guess a good thing to add at the end, of course, would be some sort of conclusion,

1954
02:11:52,000 --> 02:11:56,000
so we can just add a conclusion statement.

1955
02:11:56,000 --> 02:11:59,000
Okay, so a detailed and amazing conclusion goes there.

1956
02:11:59,000 --> 02:12:00,000
So we're done with this.

1957
02:12:00,000 --> 02:12:04,000
We will close and halt and we need to submit this to GitHub.

1958
02:12:04,000 --> 02:12:07,000
So we can do a get status back at our terminal.

1959
02:12:07,000 --> 02:12:09,000
We've modified a figure.

1960
02:12:09,000 --> 02:12:12,000
We have added a figure and we've created a new file.

1961
02:12:12,000 --> 02:12:19,000
So let's add those type get status to make sure we know what we're doing.

1962
02:12:19,000 --> 02:12:21,000
We are adding two new files or modifying another file.

1963
02:12:21,000 --> 02:12:22,000
This looks good.

1964
02:12:22,000 --> 02:12:30,000
So get commit, get push, origin, Jonathan prediction production.

1965
02:12:30,000 --> 02:12:33,000
And this should be sent up to GitHub and everything is now

1966
02:12:33,000 --> 02:12:34,000
up to date.

1967
02:12:34,000 --> 02:12:36,000
So let's go to our get repository.

1968
02:12:36,000 --> 02:12:39,000
So in my case, JBWit Coal Exploration.

1969
02:12:39,000 --> 02:12:42,000
And there is a new branch which we can click on.

1970
02:12:42,000 --> 02:12:48,000
And if we click on the deliver, we should be able to see our Coal Prediction Production Notebook,

1971
02:12:48,000 --> 02:12:54,000
including all of the code and everything else in here.

1972
02:12:54,000 --> 02:13:01,000
In this video, we'll be talking about how to do a pull request and how to merge this back into a final branch

1973
02:13:01,000 --> 02:13:04,000
so the team members can review it and check off on it.

1974
02:13:04,000 --> 02:13:05,000
All right.

1975
02:13:05,000 --> 02:13:07,000
So we last left us.

1976
02:13:07,000 --> 02:13:12,000
We had just put in our deliverable notebook that talks about the Coal Prediction Production.

1977
02:13:12,000 --> 02:13:17,000
And so at this point, after pushing it to master, we have this branch.

1978
02:13:17,000 --> 02:13:23,000
If you go back to the home directory under your username and whatever you've named your data science project,

1979
02:13:23,000 --> 02:13:26,000
you can actually see this button here called new pull request.

1980
02:13:26,000 --> 02:13:31,000
And I like to switch to the branch that I'm going to generate the pull request from.

1981
02:13:31,000 --> 02:13:36,000
So this is all predicated on using GitHub as your repository of choice.

1982
02:13:36,000 --> 02:13:43,000
So after you click new pull request, you'll ask you to do one last step here where it'll say you're creating a new pull request

1983
02:13:43,000 --> 02:13:45,000
by comparing changes across two branches.

1984
02:13:45,000 --> 02:13:51,000
You're going to be taking stuff from this Jonathan Predict Production branch and putting it into master.

1985
02:13:51,000 --> 02:13:54,000
And GitHub does this nice thing which says it's able to be merged,

1986
02:13:54,000 --> 02:13:58,000
which means that if it's approved, it can just be approved at the single button click.

1987
02:13:58,000 --> 02:13:59,000
That's always nice.

1988
02:13:59,000 --> 02:14:03,000
So give your commit an extra bit of detail here.

1989
02:14:03,000 --> 02:14:06,000
So say something like final review.

1990
02:14:06,000 --> 02:14:11,000
And then if you want to leave a few more comments, create pull request.

1991
02:14:11,000 --> 02:14:18,000
So now what this does is it creates a pull request and lets you see the various commits that have happened in this branch

1992
02:14:18,000 --> 02:14:23,000
and allows a person who can possibly merge this to review the pull request.

1993
02:14:23,000 --> 02:14:31,000
So a person coming into this would see who's not me, for example, would look at the pull request and see that there's one open pull request.

1994
02:14:31,000 --> 02:14:34,000
And it was open 25 seconds ago by me.

1995
02:14:34,000 --> 02:14:37,000
So if you click on this, then you'll see the comment here.

1996
02:14:37,000 --> 02:14:38,000
Please check the figures especially.

1997
02:14:38,000 --> 02:14:40,000
They're going to be put into a slideshow.

1998
02:14:40,000 --> 02:14:41,000
Okay, so this must be pretty important.

1999
02:14:41,000 --> 02:14:45,000
And so I'll take a look at the different files that were committed.

2000
02:14:45,000 --> 02:14:47,000
So I'll click to the files changed.

2001
02:14:47,000 --> 02:14:52,000
I see that we have a couple of notebooks and we have a couple of figures.

2002
02:14:52,000 --> 02:14:56,000
So let's take a look at, let's say this current figure here.

2003
02:14:56,000 --> 02:14:57,000
This one was added.

2004
02:14:57,000 --> 02:15:00,000
Let's say we want to change that color.

2005
02:15:00,000 --> 02:15:03,000
So in the pull request, you can actually make changes.

2006
02:15:03,000 --> 02:15:05,000
And this is where you actually wanted to be doing this.

2007
02:15:05,000 --> 02:15:13,000
You click in the conversation part of the pull request, say, I need a few changes.

2008
02:15:13,000 --> 02:15:14,000
Add a comment.

2009
02:15:14,000 --> 02:15:17,000
Now, of course, I'm commenting on my own pull request.

2010
02:15:17,000 --> 02:15:21,000
Normally what happens is you make a pull request and your team members or your

2011
02:15:21,000 --> 02:15:24,000
manager will be actually the one reviewing the pull request.

2012
02:15:24,000 --> 02:15:28,000
But in this case, just for demonstration purposes, I'm both the submitter and the

2013
02:15:28,000 --> 02:15:31,000
reviewer just so that it's easy to see what needs to happen.

2014
02:15:31,000 --> 02:15:32,000
So added a comment.

2015
02:15:32,000 --> 02:15:33,000
I need a few changes.

2016
02:15:33,000 --> 02:15:35,000
Please change the figure to be green.

2017
02:15:35,000 --> 02:15:36,000
Okay.

2018
02:15:36,000 --> 02:15:41,000
Now that we go back to our terminal, we see that still on the Jonathan prediction

2019
02:15:41,000 --> 02:15:46,000
production branch, so we'll need to make some changes to the pull request.

2020
02:15:46,000 --> 02:15:48,000
So this is actually pretty simple.

2021
02:15:48,000 --> 02:15:53,000
So I'm going to switch tabs back to our deliver directory that is running under the

2022
02:15:53,000 --> 02:15:55,000
Jupyter Notebook server.

2023
02:15:55,000 --> 02:15:59,000
And so let's go into this cold predict production and make the requisite changes.

2024
02:15:59,000 --> 02:16:03,000
Now we'll have to actually shift return and work our way through this so that

2025
02:16:03,000 --> 02:16:05,000
everything is loaded into the namespace.

2026
02:16:05,000 --> 02:16:09,000
So that one is probably the one that should stay the same.

2027
02:16:09,000 --> 02:16:14,000
We get down to this one here where sure enough, the figure itself is printing

2028
02:16:15,000 --> 02:16:16,000
something that's blue.

2029
02:16:16,000 --> 02:16:19,000
We want to change this color to be green.

2030
02:16:19,000 --> 02:16:20,000
Okay.

2031
02:16:20,000 --> 02:16:24,000
In this plot, we will actually make the color equal to green.

2032
02:16:24,000 --> 02:16:27,000
C is not what it takes as a thing.

2033
02:16:27,000 --> 02:16:30,000
So we'll see if color works and color is indeed the keyword.

2034
02:16:30,000 --> 02:16:31,000
Okay.

2035
02:16:31,000 --> 02:16:35,000
So changing the color to be green, the figure is now green and we have

2036
02:16:35,000 --> 02:16:37,000
overwritten that figure file.

2037
02:16:37,000 --> 02:16:42,000
So cold production RF prediction is now a green plot rather than blue.

2038
02:16:42,000 --> 02:16:47,000
And so we can want to redo everything just to make sure that you haven't made

2039
02:16:47,000 --> 02:16:48,000
any catastrophic changes.

2040
02:16:48,000 --> 02:16:50,000
You can do this one more time.

2041
02:16:50,000 --> 02:16:57,000
Takes just a few seconds to go through the entire pipeline and save this file

2042
02:16:57,000 --> 02:16:58,000
close and halt.

2043
02:16:58,000 --> 02:17:01,000
Go back to your terminal, get status.

2044
02:17:01,000 --> 02:17:02,000
Two things have been changed.

2045
02:17:02,000 --> 02:17:03,000
And that's as we expect.

2046
02:17:03,000 --> 02:17:07,000
They changed the notebook itself that created this figure and the figure

2047
02:17:07,000 --> 02:17:08,000
itself.

2048
02:17:08,000 --> 02:17:10,000
So let's add those two files.

2049
02:17:10,000 --> 02:17:14,000
Those two files have been modified.

2050
02:17:14,000 --> 02:17:20,000
So we then get push origin, your branch name, and it's now updated on GitHub.

2051
02:17:20,000 --> 02:17:24,000
The nice thing about how GitHub handles these pull requests as a tab back to this

2052
02:17:24,000 --> 02:17:27,000
Chrome tab, this commit is already added now.

2053
02:17:27,000 --> 02:17:29,000
You actually can see the commit that was done here.

2054
02:17:29,000 --> 02:17:32,000
And if you click on that commit, you get to see that things that were changed.

2055
02:17:32,000 --> 02:17:36,000
So the few things were changed in the IPYNB, which is not shown partly because

2056
02:17:36,000 --> 02:17:39,000
the actual changes in the notebook don't look so great.

2057
02:17:39,000 --> 02:17:43,000
But the change in the figures has been changed.

2058
02:17:43,000 --> 02:17:45,000
So this figure, the blue one was deleted.

2059
02:17:45,000 --> 02:17:48,000
And the one on the right, the green one was added.

2060
02:17:48,000 --> 02:17:51,000
So this is one of the reasons that changing it in the notebook, which it

2061
02:17:51,000 --> 02:17:52,000
actually did.

2062
02:17:52,000 --> 02:17:54,000
So it changed the embedded figure in the notebook.

2063
02:17:54,000 --> 02:17:56,000
It's hard to see the differences there.

2064
02:17:56,000 --> 02:18:00,000
This is why I advocate creating these figures in a separate folder and a separate

2065
02:18:00,000 --> 02:18:02,000
PNG file for each of them.

2066
02:18:02,000 --> 02:18:06,000
So you see the diffs in the figures if you have feedback on the output.

2067
02:18:06,000 --> 02:18:10,000
Now, as an extra piece of sugar or something nice that GitHub has given us,

2068
02:18:10,000 --> 02:18:14,000
there's this to side by side approach where you can see what was deleted and

2069
02:18:14,000 --> 02:18:15,000
see what was added.

2070
02:18:15,000 --> 02:18:20,000
You can also choose the swipe option where as you swipe this thing across the

2071
02:18:20,000 --> 02:18:23,000
figure that you've just done, you can actually see the changes that have been

2072
02:18:23,000 --> 02:18:25,000
made, which is turning the figure green.

2073
02:18:25,000 --> 02:18:29,000
Last one is onion skin where it fades from the entire thing from behind.

2074
02:18:29,000 --> 02:18:31,000
So this is what it currently is.

2075
02:18:31,000 --> 02:18:33,000
And previously it was blue.

2076
02:18:33,000 --> 02:18:34,000
You can see this.

2077
02:18:34,000 --> 02:18:37,000
So having this functionality is actually really nice.

2078
02:18:37,000 --> 02:18:43,000
And another reason why I advocate for this figures being submitted separately.

2079
02:18:43,000 --> 02:18:47,000
Just a final note, you saw that the points are slightly different in this swipe.

2080
02:18:47,000 --> 02:18:51,000
And that's because during our test train split, we were taking a random selection

2081
02:18:51,000 --> 02:18:55,000
of points that were going to be the testing set and the training set.

2082
02:18:55,000 --> 02:18:59,000
So those differences, well, shouldn't matter much and they don't change the

2083
02:18:59,000 --> 02:19:02,000
actual scatter points, but the fit itself, as you can tell is almost completely

2084
02:19:02,000 --> 02:19:03,000
unchanged.

2085
02:19:03,000 --> 02:19:06,000
It's actually a nice robustness check to look at this as well.

2086
02:19:06,000 --> 02:19:12,000
So once I've looked at these changes, I can now go back to this pull request

2087
02:19:12,000 --> 02:19:13,000
branch.

2088
02:19:13,000 --> 02:19:14,000
So I need a few changes.

2089
02:19:14,000 --> 02:19:15,000
Please make the figure green.

2090
02:19:15,000 --> 02:19:17,000
I committed made the figure green.

2091
02:19:17,000 --> 02:19:22,000
The only thing I need to do to update this whole threat of changes was to just

2092
02:19:22,000 --> 02:19:25,000
say get push origin branch title.

2093
02:19:25,000 --> 02:19:29,000
So I'll say it looks good to me plus one.

2094
02:19:30,000 --> 02:19:34,000
And then clicking merge pull request will take everything from this branch

2095
02:19:34,000 --> 02:19:36,000
and pull it into the master branch.

2096
02:19:36,000 --> 02:19:41,000
So I'll say figures ready to be put into a slideshow.

2097
02:19:41,000 --> 02:19:46,000
So once you pull request is successfully merged and accepted, then you should

2098
02:19:46,000 --> 02:19:49,000
delete the branch to keep these branches from floating around.

2099
02:19:49,000 --> 02:19:53,000
So I just deleted the branch on GitHub and should now do the same thing

2100
02:19:53,000 --> 02:19:55,000
in your local environment.

2101
02:19:55,000 --> 02:19:59,000
So first I'm going to check out master and I'll say get pull origin master

2102
02:19:59,000 --> 02:20:03,000
to pull everything down from GitHub and all these changes have been made

2103
02:20:03,000 --> 02:20:07,000
and say get branch minus D Jonathan predict.

2104
02:20:07,000 --> 02:20:11,000
So I've deleted the prediction branch and get does a final check to make sure

2105
02:20:11,000 --> 02:20:14,000
that any of the changes that have been made on that prediction branch have

2106
02:20:14,000 --> 02:20:15,000
been already pulled into master.

2107
02:20:15,000 --> 02:20:18,000
So if you just try to do this and it doesn't think it's been fully merged,

2108
02:20:18,000 --> 02:20:21,000
you get an error at that point and you have to figure out what happened at

2109
02:20:21,000 --> 02:20:22,000
that stage.

2110
02:20:22,000 --> 02:20:26,000
In this video, we just over reviewed the basic process of going through a

2111
02:20:26,000 --> 02:20:30,000
pull request and how the peer review process works in a pull request.

2112
02:20:30,000 --> 02:20:38,000
So we saw how to merge our development branch into master after doing a pull request.

2113
02:20:38,000 --> 02:20:43,000
In this video, we'll start our data science project number two.

2114
02:20:43,000 --> 02:20:47,000
And in this project, our main focus will be to focus on various plotting

2115
02:20:47,000 --> 02:20:50,000
and statistical libraries that I think you should know about.

2116
02:20:50,000 --> 02:20:55,000
All right, so to start a new data science project, let's start out by

2117
02:20:55,000 --> 02:21:01,000
going to GitHub and signing in going up to the plus by our little icon and

2118
02:21:01,000 --> 02:21:03,000
clicking on a new repository.

2119
02:21:03,000 --> 02:21:11,000
So we can call this data vis project to in this case and give it a

2120
02:21:11,000 --> 02:21:15,000
description that says I will make it public.

2121
02:21:15,000 --> 02:21:18,000
So you can see this project as you go forward.

2122
02:21:18,000 --> 02:21:20,000
We'll initialize with a read me.

2123
02:21:20,000 --> 02:21:23,000
We will include a Python dot get ignore.

2124
02:21:23,000 --> 02:21:28,000
We'll add an MIT license and create the repository.

2125
02:21:28,000 --> 02:21:33,000
Once we've created it, go to this SSH option, click in this box.

2126
02:21:33,000 --> 02:21:37,000
It'll select all the text by default command C copies it, go back to our

2127
02:21:37,000 --> 02:21:42,000
terminal, say get clone and then command V to paste that URL.

2128
02:21:42,000 --> 02:21:47,000
All right, so let's CD into data vis projects and look at what we have here.

2129
02:21:47,000 --> 02:21:49,000
And we're currently on the master branch.

2130
02:21:49,000 --> 02:21:54,000
So first step, let's create a development branch and we'll call it

2131
02:21:54,000 --> 02:21:59,000
Jonathan vis and let's create our normal directory structure.

2132
02:21:59,000 --> 02:22:05,000
So we have data deliver develop figures start with and I happen to

2133
02:22:05,000 --> 02:22:09,000
know that I've already started a few of these notebooks.

2134
02:22:09,000 --> 02:22:14,000
So I'll move them from a previous location into our develop folder.

2135
02:22:14,000 --> 02:22:16,000
So let's look at our develop folder.

2136
02:22:16,000 --> 02:22:17,000
Okay, we got some stuff there.

2137
02:22:17,000 --> 02:22:21,000
And now that we have a new branch and we have a new directory structure

2138
02:22:21,000 --> 02:22:22,000
and some stuff to look at.

2139
02:22:22,000 --> 02:22:25,000
Let's start up the Jupyter notebook server.

2140
02:22:25,000 --> 02:22:28,000
All right, so we see the same directories we were just looking at in the

2141
02:22:28,000 --> 02:22:29,000
terminal.

2142
02:22:29,000 --> 02:22:33,000
I will now right click on this tab and pin this tab so that it goes all the

2143
02:22:33,000 --> 02:22:36,000
way to the left and stays in place so that if I have a lot of tabs because

2144
02:22:36,000 --> 02:22:39,000
I'm searching for a bunch of different things, I always know where to go

2145
02:22:39,000 --> 02:22:41,000
back to find the home server directory.

2146
02:22:41,000 --> 02:22:44,000
And I just find that useful to pin that tab all the way to the left.

2147
02:22:44,000 --> 02:22:47,000
All right, so let's take a look at some of the notebooks.

2148
02:22:47,000 --> 02:22:53,000
I've already pre populated what I'll do here is I only have my usual date

2149
02:22:53,000 --> 02:22:57,000
and then my initials at the top of the page from the actual name of my

2150
02:22:57,000 --> 02:23:00,000
notebook, just including your short description, which is exploratory

2151
02:23:00,000 --> 02:23:02,000
data analysis, which is pretty long title.

2152
02:23:02,000 --> 02:23:06,000
So I'll do all caps EDA and that is a standard way of talking about that.

2153
02:23:06,000 --> 02:23:11,000
So I'll view and toggle the header and toggle the toolbar just so that we

2154
02:23:11,000 --> 02:23:12,000
have some extra space.

2155
02:23:12,000 --> 02:23:15,000
Remember, if you want to save it when you're in this kind of configuration,

2156
02:23:15,000 --> 02:23:17,000
you just command S to save it.

2157
02:23:17,000 --> 02:23:20,000
So one more time, I'll just give you a brief overview of what I'm hoping to

2158
02:23:20,000 --> 02:23:21,000
do here.

2159
02:23:21,000 --> 02:23:23,000
So this isn't to teach you how to do data science.

2160
02:23:23,000 --> 02:23:27,000
It's more of an exposure to the tools that I think most people haven't seen

2161
02:23:27,000 --> 02:23:29,000
all of them or haven't seen enough of them.

2162
02:23:29,000 --> 02:23:34,000
And I just think these tools will allow you to do your data science much

2163
02:23:34,000 --> 02:23:37,000
more efficiently and usefully.

2164
02:23:37,000 --> 02:23:40,000
I'll go over a few of these plotting and statistical packages that you might

2165
02:23:40,000 --> 02:23:41,000
not know about.

2166
02:23:41,000 --> 02:23:44,000
So the first thing we have is importing map plot lib inline.

2167
02:23:44,000 --> 02:23:47,000
Almost all these plotting libraries uses map plot lib.

2168
02:23:47,000 --> 02:23:48,000
So I'll be using that for now.

2169
02:23:48,000 --> 02:23:52,000
And I'm importing map plot lib dot pie plot as PLT, which is the

2170
02:23:52,000 --> 02:23:53,000
standard way of doing that.

2171
02:23:53,000 --> 02:23:57,000
Seaborn as SNS, which is the standard way of importing Seaborn,

2172
02:23:57,000 --> 02:24:00,000
importing pandas as PD, NumPy as NP.

2173
02:24:00,000 --> 02:24:04,000
I'll also load in some data sets from scikit-learn and importing some

2174
02:24:04,000 --> 02:24:08,000
stats models, which I'll be talking about at length in a later video.

2175
02:24:08,000 --> 02:24:09,000
Execute this cell.

2176
02:24:09,000 --> 02:24:12,000
Now, if I do shift return, it will execute it and go to the next cell.

2177
02:24:12,000 --> 02:24:16,000
If I hold down control and hit return, it will execute the cell in place,

2178
02:24:16,000 --> 02:24:18,000
and it won't go to the next cell.

2179
02:24:18,000 --> 02:24:22,000
So I can continue to stay in the same cell if I hit control and return.

2180
02:24:22,000 --> 02:24:26,000
I've used Seaborn in other videos, but I would really like to just double

2181
02:24:26,000 --> 02:24:28,000
emphasize how useful this is.

2182
02:24:28,000 --> 02:24:32,000
You can find the main library for this by Google searching Seaborn,

2183
02:24:32,000 --> 02:24:35,000
and Seaborn Python should do it.

2184
02:24:35,000 --> 02:24:39,000
And the top result is the statistical data visualization library here.

2185
02:24:39,000 --> 02:24:42,000
This is what you should see, something like this, unless he's updated the page.

2186
02:24:42,000 --> 02:24:45,000
And this website has a lot of really good information on it.

2187
02:24:45,000 --> 02:24:46,000
The documentation is excellent.

2188
02:24:46,000 --> 02:24:49,000
The features with these different tutorials is also excellent.

2189
02:24:49,000 --> 02:24:53,000
These images that you can click on here will show you different capability,

2190
02:24:53,000 --> 02:24:55,000
the tutorial and the gallery.

2191
02:24:55,000 --> 02:24:58,000
If you click on gallery, you get to see many different visualization types

2192
02:24:58,000 --> 02:25:01,000
that Seaborn makes really easy, especially like heat map.

2193
02:25:01,000 --> 02:25:03,000
That's a nice one.

2194
02:25:03,000 --> 02:25:05,000
Look through the example gallery.

2195
02:25:05,000 --> 02:25:08,000
If you have some data and you have some sense that you should be able to visualize it in a way,

2196
02:25:08,000 --> 02:25:11,000
see if Seaborn has a response to that.

2197
02:25:11,000 --> 02:25:14,000
So let's go back to our notebook and load in some data.

2198
02:25:14,000 --> 02:25:18,000
So Seaborn SNS has data sets that you can load in by default.

2199
02:25:18,000 --> 02:25:21,000
We will load in the Titanic data set.

2200
02:25:21,000 --> 02:25:25,000
This is actually the data of passengers on the ill-fated Titanic.

2201
02:25:25,000 --> 02:25:31,000
And it has various information about them, their age, their sex, their class of ticket.

2202
02:25:31,000 --> 02:25:33,000
So first class, second class, third class.

2203
02:25:33,000 --> 02:25:36,000
And it talks about whether or not they survived the crash.

2204
02:25:36,000 --> 02:25:42,000
So doing a factor plot like this where you set this G object to be equal to this factor plot

2205
02:25:42,000 --> 02:25:45,000
and then modify the G label like this.

2206
02:25:45,000 --> 02:25:50,000
This is modified from a Seaborn example, commenting out this hue equals sex line.

2207
02:25:50,000 --> 02:25:52,000
And I'll talk about that in a second.

2208
02:25:52,000 --> 02:25:55,000
But I will shift return and execute this cell.

2209
02:25:55,000 --> 02:26:02,000
What you see here is the survival probability against the class of passengers on Titanic held.

2210
02:26:02,000 --> 02:26:05,000
You can see that first class had by far the best survival probability,

2211
02:26:05,000 --> 02:26:08,000
followed by second, followed finally by third class.

2212
02:26:08,000 --> 02:26:13,000
So this is a very nice high level summary of the data that underlies this.

2213
02:26:13,000 --> 02:26:19,000
Some of the nice things about Seaborn is that you can actually give it dimensions to also give you the same plot.

2214
02:26:19,000 --> 02:26:22,000
So let's uncomment this hue equals sex line and see what that does.

2215
02:26:22,000 --> 02:26:26,000
So what you see here is each of these classes is now been split out by sex.

2216
02:26:26,000 --> 02:26:29,000
So male and female, survivability for first class.

2217
02:26:29,000 --> 02:26:33,000
You can tell the very high difference in probability for surviving in each of those,

2218
02:26:33,000 --> 02:26:36,000
whether you're male or female in each of the classes.

2219
02:26:36,000 --> 02:26:41,000
So this tells you a more rich and deeper story of the underlying data set than the previous plot.

2220
02:26:41,000 --> 02:26:45,000
And you can see the first, second, third class, all of the different responses here.

2221
02:26:45,000 --> 02:26:48,000
So this is just one aspect of Seaborn.

2222
02:26:48,000 --> 02:26:51,000
I recommend getting to know it and use it as much as you can.

2223
02:26:51,000 --> 02:26:54,000
And that's going to be all for this video.

2224
02:26:54,000 --> 02:26:57,000
We've set up in this video a new Git repository.

2225
02:26:57,000 --> 02:26:59,000
We've started a new development branch.

2226
02:26:59,000 --> 02:27:03,000
We have our directory structure set up as we like to do it for our data science projects.

2227
02:27:03,000 --> 02:27:09,000
And we've taken a look at the Seaborn visualization library.

2228
02:27:09,000 --> 02:27:14,000
In this video, we'll continue to look at some visualization methods and techniques.

2229
02:27:14,000 --> 02:27:17,000
So let's go on to exploratory data analysis two.

2230
02:27:17,000 --> 02:27:24,000
Again, it starts off the same way with Matplotlib inline and the various other things being imported.

2231
02:27:24,000 --> 02:27:26,000
This warning message, which we can ignore for now.

2232
02:27:26,000 --> 02:27:30,000
So we will load in this Boston data from the scikit-learn data sets.

2233
02:27:30,000 --> 02:27:35,000
And we will first of all print what the data dictionary describes it as.

2234
02:27:35,000 --> 02:27:40,000
The way this load Boston gets imported, I'm calling it a data frame dictionary

2235
02:27:40,000 --> 02:27:43,000
and just calling this description key.

2236
02:27:43,000 --> 02:27:49,000
So let's toggle the top header and the top toolbar to give us some extra space.

2237
02:27:49,000 --> 02:27:53,000
And we see that this is the Boston house prices data set.

2238
02:27:53,000 --> 02:27:58,000
Now, it's worth reading through this data set and knowing what each of these attributes actually means

2239
02:27:58,000 --> 02:28:02,000
because if we're doing a deep data science project, it's really important to know the attributes,

2240
02:28:02,000 --> 02:28:04,000
especially if there's only 13 of them.

2241
02:28:04,000 --> 02:28:09,000
But what the main takeaway will be trying to predict the median value of the house

2242
02:28:09,000 --> 02:28:14,000
and by looking at the 13 categories that predict this house,

2243
02:28:14,000 --> 02:28:17,000
we have 506 total instances of this data set.

2244
02:28:17,000 --> 02:28:22,000
The different attributes are crime, we've written as CRIM, all caps.

2245
02:28:22,000 --> 02:28:27,000
Zone or the proportion of residential land zone for lots over 25,000 square feet.

2246
02:28:27,000 --> 02:28:32,000
Indus, which is a proportion of non-retail business acres per town.

2247
02:28:32,000 --> 02:28:38,000
A dummy variable where if you're next to the Charles River, then you're equaling to one, otherwise you're zero.

2248
02:28:38,000 --> 02:28:41,000
The nitric oxides concentration in parts per 10 million.

2249
02:28:41,000 --> 02:28:43,000
The average number of rooms per dwelling.

2250
02:28:43,000 --> 02:28:48,000
The proportion of owner occupied units built prior to 1940, which is age,

2251
02:28:48,000 --> 02:28:53,000
weighted distances to five Boston employment centers, distance.

2252
02:28:53,000 --> 02:28:56,000
Rad is index of accessibility to radial highways.

2253
02:28:56,000 --> 02:29:01,000
Tax, the full value property tax per $10,000.

2254
02:29:01,000 --> 02:29:04,000
People to teacher ratio by town.

2255
02:29:04,000 --> 02:29:09,000
The B, which is the formula that says the BK is the proportion of blacks by town.

2256
02:29:09,000 --> 02:29:12,000
L stat, which is percentage of lower status of the population.

2257
02:29:12,000 --> 02:29:16,000
And median value, the thing we are tending to be predicting,

2258
02:29:16,000 --> 02:29:20,000
which is median value of the owner occupied home in terms of 1000s.

2259
02:29:20,000 --> 02:29:22,000
This is the information that the data comes from.

2260
02:29:22,000 --> 02:29:24,000
So it's from Harrison and Rubenfeld.

2261
02:29:24,000 --> 02:29:31,000
And this is all the information about exactly where it was taken from the stat lab library maintained at Carnegie Mellon University.

2262
02:29:31,000 --> 02:29:36,000
So this data dictionary as it comes from scikit-learn is not in my favorite format.

2263
02:29:36,000 --> 02:29:38,000
It's this weird data dictionary.

2264
02:29:38,000 --> 02:29:41,000
If we actually say type on this, it'll be this weird like data set bunch.

2265
02:29:41,000 --> 02:29:44,000
So instead of using it in the form that it's given to us,

2266
02:29:44,000 --> 02:29:49,000
I like to convert this into a panda's data frame because those in my view are much easier to use.

2267
02:29:49,000 --> 02:29:52,000
So we'll create a data frame called features.

2268
02:29:52,000 --> 02:29:54,000
I'll create a data frame called target.

2269
02:29:54,000 --> 02:29:59,000
Now features will take the DF underscore dict, which is the the scikit-learn bunch thing.

2270
02:29:59,000 --> 02:30:05,000
And the dot data element and assign the columns to this data frame to be the feature names.

2271
02:30:05,000 --> 02:30:07,000
We'll also do this with target.

2272
02:30:07,000 --> 02:30:11,000
So we'll do this with another create another pandas dot data frame to create the data frame.

2273
02:30:11,000 --> 02:30:14,000
And then it'll be this DF dict dot target.

2274
02:30:14,000 --> 02:30:18,000
So run this and we can look at the head of the features by doing dot head on it.

2275
02:30:18,000 --> 02:30:24,000
So here are the different values of the different features for the first five elements of our data set.

2276
02:30:24,000 --> 02:30:28,000
We have the crime number here, zone, the industry.

2277
02:30:28,000 --> 02:30:33,000
Are you close to the Charles River, the nitrous oxide, average number of rooms, the age,

2278
02:30:33,000 --> 02:30:36,000
all the different features that we're reading about before.

2279
02:30:36,000 --> 02:30:42,000
If we look at the target, we would see that it's a single element or a single column data frame.

2280
02:30:42,000 --> 02:30:45,000
So what we'll like to do is actually for most of our visualization,

2281
02:30:45,000 --> 02:30:48,000
we will like to put these two things together side by side.

2282
02:30:48,000 --> 02:30:51,000
Well, we can use concat for that pandas dot concat.

2283
02:30:51,000 --> 02:30:54,000
We give it a list of the data frames you'd like to concatenate together.

2284
02:30:54,000 --> 02:30:57,000
And we have to tell it which axis that we would like to use.

2285
02:30:57,000 --> 02:31:02,000
Now, I'm sure there's some very useful mnemonic that will tell us the right way to do it every time,

2286
02:31:02,000 --> 02:31:07,000
but I prefer to not trust that I remembered it correctly, but always test that I have it right.

2287
02:31:07,000 --> 02:31:10,000
So if we start out with axis equals zero and look at the head,

2288
02:31:10,000 --> 02:31:15,000
we will see that it's trying to combine it in a way that they're stacked on top of each other.

2289
02:31:15,000 --> 02:31:16,000
And there's two ways to know this.

2290
02:31:16,000 --> 02:31:21,000
One is that everything has a value except for medv, which is the target data frame.

2291
02:31:21,000 --> 02:31:22,000
All of them have nans.

2292
02:31:22,000 --> 02:31:29,000
And if we were to look at the tail, we will see that everything else has nans and medv has values.

2293
02:31:29,000 --> 02:31:31,000
That's one way to know that we've done it wrong.

2294
02:31:31,000 --> 02:31:35,000
So this is trying to do some sort of concatenating the two data frames vertically.

2295
02:31:35,000 --> 02:31:40,000
And if we do it axis equals one, we will see that we've put them side by side,

2296
02:31:40,000 --> 02:31:41,000
which is what we actually want.

2297
02:31:41,000 --> 02:31:42,000
And let's look at the head.

2298
02:31:42,000 --> 02:31:47,000
We will see that all of them are here, including medv being the very final column in this data frame.

2299
02:31:47,000 --> 02:31:49,000
So we now have a new data frame called df.

2300
02:31:49,000 --> 02:31:53,000
It contains a target and the feature variables underneath it.

2301
02:31:53,000 --> 02:31:58,000
Now to give you a sense of the data underneath it, there's many different ways you can slice and dice this.

2302
02:31:58,000 --> 02:32:03,000
One very simple quick way to start with is to iterate over all of the columns of the data frame

2303
02:32:03,000 --> 02:32:08,000
and to print both the column name and the number of unique values in that column.

2304
02:32:08,000 --> 02:32:16,000
For column in df, the data frame columns, print the column name and df of the column, the number of unique values.

2305
02:32:16,000 --> 02:32:20,000
This n unique is a method you can call on a data frame.

2306
02:32:20,000 --> 02:32:27,000
So there are 504 unique values in crime and there's two totally unique values in chance, which is a boolean value.

2307
02:32:27,000 --> 02:32:29,000
Makes sense, we'd expect that.

2308
02:32:29,000 --> 02:32:30,000
Some of them are pretty low.

2309
02:32:30,000 --> 02:32:32,000
So our ad, for example, is at nine.

2310
02:32:32,000 --> 02:32:35,000
Some of these have many values and they're continuous values.

2311
02:32:35,000 --> 02:32:38,000
Other of them have smaller numbers of possible values.

2312
02:32:38,000 --> 02:32:41,000
You can see rad here is this kind of numbers here.

2313
02:32:41,000 --> 02:32:48,000
One thing you might not know is that pandas not only has fantastic data frame support, but also has some very useful plotting tools.

2314
02:32:48,000 --> 02:32:54,000
So in this case, we will be importing a thing called scatter matrix from pandas.

2315
02:32:54,000 --> 02:32:58,000
And this can be done in a couple of libraries as well, but let's just look at the pandas version of this.

2316
02:32:58,000 --> 02:33:04,000
Recreating a figure with some plots in pi plot, making a large figure 12 by 12 fig size.

2317
02:33:04,000 --> 02:33:15,000
And we're going to call it on this data frame with some see-through value of alpha and the diagonal will be KDE, which is this kernel density estimation plot that we see here.

2318
02:33:15,000 --> 02:33:22,000
Again, we see a warning that we can safely ignore, but this is a very information dense plot.

2319
02:33:22,000 --> 02:33:25,000
There's no way to go over all of it in this video as we look at it.

2320
02:33:25,000 --> 02:33:29,000
But this, if you have your own data set, will give you a lot of things to look at.

2321
02:33:29,000 --> 02:33:37,000
What is being plotted here on the x-axis and the y-axis is every possible pair of the two columns in this data frame, which is why it took a while to actually plot this.

2322
02:33:37,000 --> 02:33:45,000
Along the diagonal, this KDE plot, it's showing interactions with itself or basically the histogram of that variable itself.

2323
02:33:45,000 --> 02:33:49,000
So this is what medv looks like. It's just this histogram here.

2324
02:33:49,000 --> 02:33:53,000
Along the diagonal, it's just a histogram of the values of that variable.

2325
02:33:53,000 --> 02:34:01,000
Everything else is going to be what the response from this variable looks like with every other variable on the x-axis.

2326
02:34:01,000 --> 02:34:03,000
So you can see a number of really nice trends here.

2327
02:34:03,000 --> 02:34:05,000
You can see some kind of this U-shaped trend here.

2328
02:34:05,000 --> 02:34:09,000
We see something that's basically a straight line, which means there's not much information there at all.

2329
02:34:09,000 --> 02:34:11,000
That's from the Boolean value.

2330
02:34:11,000 --> 02:34:17,000
We can see some of these have very fuzzy relationships where it's not really showing anything very interesting.

2331
02:34:17,000 --> 02:34:23,000
But spending some time looking at plots like this, getting to know your data set is a vital part of data science.

2332
02:34:23,000 --> 02:34:25,000
And I highly recommend looking at this.

2333
02:34:25,000 --> 02:34:29,000
If you have far too many columns to look at it in one, I would say this is probably too many.

2334
02:34:29,000 --> 02:34:34,000
If you have even more than this, though, you can take subsets of this and plot this with the same command,

2335
02:34:34,000 --> 02:34:41,000
but you would be giving it a list inside of double brackets of feature one, feature two, and so on.

2336
02:34:41,000 --> 02:34:43,000
And this will plot just those features against each other.

2337
02:34:43,000 --> 02:34:46,000
So there's a downside of that is that you're not getting all of the interaction terms,

2338
02:34:46,000 --> 02:34:53,000
but if it's a trade-off between possible to view in one screen or not look at it at all, I recommend that.

2339
02:34:55,000 --> 02:34:59,000
Okay, in the last video, we last looked at this scatterplot functionality within Pandas.

2340
02:34:59,000 --> 02:35:07,000
In this video, we're going to continue taking a look at this data and some of the plotting functionality that's built into the Pandas library itself.

2341
02:35:07,000 --> 02:35:16,000
Just as a brief overview, again, this scatterplot gives you a very nice, fast way of looking at all of the interactions between the terms in your data frame.

2342
02:35:16,000 --> 02:35:22,000
If you suspect that there might be something interesting going on with, let's say, rad, we see something happening here,

2343
02:35:22,000 --> 02:35:26,000
or this diagonal term for rad, the intersection of rad and rad on the X and Y axis.

2344
02:35:26,000 --> 02:35:32,000
You see a histogram plot or a KDE plot that shows a very bimodal distribution.

2345
02:35:32,000 --> 02:35:40,000
So you can take a deeper look into that and see what it looks like by selecting that column by saying df of rad.hist.

2346
02:35:40,000 --> 02:35:44,000
And we will see this bimodal shape really appear again.

2347
02:35:44,000 --> 02:35:49,000
So it's really values that are greater than 20 and then a bunch of different values that are around 10 and lower.

2348
02:35:49,000 --> 02:35:53,000
You can also, of course, select it if you have a nice column name.

2349
02:35:53,000 --> 02:35:56,000
In other words, there's no spaces or any other characters in that column name.

2350
02:35:56,000 --> 02:36:00,000
You do the same exact thing by doing df.rad.hist.

2351
02:36:00,000 --> 02:36:02,000
See the same exact plot.

2352
02:36:02,000 --> 02:36:07,000
When you see a feature like this, in this case, it might not make sense, but if you have the thought that,

2353
02:36:07,000 --> 02:36:10,000
you know what, let's actually consider this as two separate groups.

2354
02:36:10,000 --> 02:36:15,000
This bimodal characteristic should actually be characterized as really a high group and a low group.

2355
02:36:15,000 --> 02:36:21,000
One way to do this is to apply a lambda function, which will create a Boolean value of these values.

2356
02:36:21,000 --> 02:36:25,000
So everything down here gets one flag of the low group and everything up here gets the high group.

2357
02:36:25,000 --> 02:36:31,000
And so we will build up this command below by getting some intuition here.

2358
02:36:31,000 --> 02:36:34,000
So let's grab our data frame like this.

2359
02:36:34,000 --> 02:36:39,000
This apply function is a method that goes to the column that you've selected in your data frame.

2360
02:36:39,000 --> 02:36:42,000
And there's a number of ways you can actually call this apply.

2361
02:36:42,000 --> 02:36:45,000
You give it a function and the default axis is zero.

2362
02:36:45,000 --> 02:36:48,000
You can do it in various other ways, so you can access equals one.

2363
02:36:48,000 --> 02:36:53,000
But in this case, most of the time you'll end up doing a lambda function, which is an anonymous function.

2364
02:36:53,000 --> 02:36:58,000
It's like you define a function in Python, but you don't give it a name.

2365
02:36:58,000 --> 02:37:03,000
You're giving it via this apply method every value in the RAD column.

2366
02:37:03,000 --> 02:37:08,000
And you're saying for each of those values in that column, is it greater than say 15?

2367
02:37:08,000 --> 02:37:12,000
So 15 is clearly going to split us into the low and high group.

2368
02:37:12,000 --> 02:37:14,000
And let's just take a look at the first few values of that.

2369
02:37:14,000 --> 02:37:20,000
So I did not head on that to give us the first values and we see that is this X value greater than 15?

2370
02:37:20,000 --> 02:37:22,000
It was false, false, false, false, false.

2371
02:37:22,000 --> 02:37:29,000
And if we want to look at just what that head value looks like without the Boolean, we see that it's 1, 1, 2, 2, 3, 3.

2372
02:37:29,000 --> 02:37:32,000
So everything here is indeed less than 15.

2373
02:37:32,000 --> 02:37:39,000
So we have this function call, which will return a Boolean series false.

2374
02:37:39,000 --> 02:37:43,000
And what we'd like to do is say we want a new column in this data frame.

2375
02:37:43,000 --> 02:37:49,000
We're not going to overwrite this column, but we're going to give a new data frame that we're going to call radian underscore bool,

2376
02:37:49,000 --> 02:37:52,000
because we want to have a nice descriptive name of where it came from.

2377
02:37:52,000 --> 02:37:59,000
And the way you create a new column in a pandas data frame is you give a column that doesn't quite exist yet or doesn't exist yet in the data frame

2378
02:37:59,000 --> 02:38:02,000
and assign it equaling to something else.

2379
02:38:02,000 --> 02:38:07,000
So in this case, we have this rad dot apply lambda greater than or equal to 15.

2380
02:38:07,000 --> 02:38:09,000
And I'm just adding this as type bool.

2381
02:38:09,000 --> 02:38:16,000
Just to give you a sense that if it doesn't automatically get incurred into a type of bool, which we see right here, the d type is boolean.

2382
02:38:16,000 --> 02:38:19,000
You can force it by doing this as type.

2383
02:38:19,000 --> 02:38:21,000
There's other times when this is useful as well.

2384
02:38:21,000 --> 02:38:28,000
So I'll just leave it in here as kind of a best practices or a hint for future ways if you're trying to do something similar and having some problems with it.

2385
02:38:28,000 --> 02:38:33,000
So we've just created a new column in the data frame of rad underscore bool.

2386
02:38:33,000 --> 02:38:38,000
And if we look at what the type of this single value is this I location of zero is a boolean.

2387
02:38:38,000 --> 02:38:42,000
Let's take a look at the histogram on that now that we've created this new column.

2388
02:38:42,000 --> 02:38:45,000
And we see this perfect bimolality of 0 and 1.

2389
02:38:45,000 --> 02:38:48,000
That's one way if you have different features that you want to create.

2390
02:38:48,000 --> 02:38:52,000
It's very flexible to say if it's greater than 15, give it as bool.

2391
02:38:52,000 --> 02:38:57,000
You can also do something if you had a trimol tool or so three different groups or various other ways of slicing this.

2392
02:38:57,000 --> 02:39:00,000
Any function you can think of that can be written down in Python.

2393
02:39:00,000 --> 02:39:08,000
You can then use to filter out the columns and I recommend creating new columns, but sometimes you can overwrite columns if that makes more sense.

2394
02:39:08,000 --> 02:39:17,000
So after doing this we have another seaborne plot that's called a pair plot and let's execute this and then explain what's happening here.

2395
02:39:17,000 --> 02:39:26,000
This is very similar to what's happening above in the scatter plot where we're having the same x value versus y value and the where they intersect.

2396
02:39:26,000 --> 02:39:31,000
So this medium value here is the same intersection of medium value on the x and y axis.

2397
02:39:31,000 --> 02:39:39,000
Instead of a KDE or a kernel density estimation, which is that line, we did it with a histogram and that is a flag given right here.

2398
02:39:39,000 --> 02:39:44,000
I guess it's just the default value. It's under dyag kind equals hist.

2399
02:39:44,000 --> 02:39:49,000
And if we did KDE it would give us the KDE plot as before.

2400
02:39:49,000 --> 02:39:54,000
There's one difference here though where we've given an extra character of hue.

2401
02:39:54,000 --> 02:40:02,000
So there is a Boolean value which is are you near the Charles River and this is similar to splitting the Titanic data set into male and female for each class.

2402
02:40:02,000 --> 02:40:08,000
So it says give us the pairwise interactions between these variables. I just picked four of them.

2403
02:40:08,000 --> 02:40:16,000
And for each of these though I would like to see the differences whether you're close to this river split up by a different color.

2404
02:40:16,000 --> 02:40:25,000
So we have this hue value can take a zero or a one and we see if there's possibly different distributions behavior conditioned on whether it's actually close to the river.

2405
02:40:25,000 --> 02:40:40,000
So this gives you an extra dimension of interaction and interpretability so you can see like oh I see that there's a behavior but it only exists if there's let's say the green dots had a nice tight relationship here and the blue dots were all kind of all vague and all over the place.

2406
02:40:40,000 --> 02:40:50,000
And so if you looked at this without splitting by this Boolean value you might say oh there's not much of a relationship here but turns out that this underlying feature could have been the really important thing.

2407
02:40:50,000 --> 02:40:57,000
Now I don't actually see anything that jumps out at me in this case but having this availability is something that's worth noting.

2408
02:40:57,000 --> 02:41:02,000
So we'll do sms.kde plot and it'll be df.nox.

2409
02:41:02,000 --> 02:41:09,000
So we're seeing here it's not a histogram it's a kernel density estimation of the distribution of this underlying feature here.

2410
02:41:09,000 --> 02:41:13,000
So this is like a histogram but it's more of a smoothed out version of that.

2411
02:41:13,000 --> 02:41:18,000
This is what happens if you give this kde plot method in seaborne single column of values.

2412
02:41:18,000 --> 02:41:26,000
If you gave it two values let's give kde plot the Boolean value of rad versus the Knox value which we just plotted above.

2413
02:41:26,000 --> 02:41:32,000
And we'll get a two dimensional plot which shows the distribution of these two values together.

2414
02:41:32,000 --> 02:41:40,000
So radian is a Boolean value when split it's in the x and y and you can see that if Boolean is true then the Knox values are actually conditioned higher.

2415
02:41:40,000 --> 02:41:45,000
If it's zero then it's conditioned lower with a little bit of data points up here in the upper one.

2416
02:41:45,000 --> 02:41:52,000
So giving two dimensions to a kde plot you get this 2d map which shows you some contour plots some really nice things.

2417
02:41:52,000 --> 02:41:57,000
One final thing for the pandas plotting thing is a thing called Andrew's curves.

2418
02:41:57,000 --> 02:42:04,000
Now I haven't used them much myself but in Wikipedia it has this as their answer of what Andrew's plots are.

2419
02:42:04,000 --> 02:42:07,000
It's a way apparently to visualize structured high dimensional data.

2420
02:42:07,000 --> 02:42:14,000
They show it with the iris data set and the iris data set is the ubiquitous data set from Fisher way back in the day.

2421
02:42:15,000 --> 02:42:20,000
And if we import this we can take a look at a specific value of a data frame.

2422
02:42:20,000 --> 02:42:28,000
So let's look at this whether this Boolean value has much structure to it and it doesn't look like it but perhaps this Knox value does.

2423
02:42:28,000 --> 02:42:34,000
And looks like there's too much to that one. Let's go with rad which is only a nine values for that.

2424
02:42:34,000 --> 02:42:37,000
So you can try to see if there's clustering of behavior.

2425
02:42:37,000 --> 02:42:43,000
Now the actual numbers here I think aren't so easy to read but the fact that this should give you a sense of

2426
02:42:43,000 --> 02:42:48,000
if there's different behaviors going on. Too many data points overlying each other I will do a sample like this

2427
02:42:48,000 --> 02:42:54,000
and a sample is another built-in function of data frames where you can say give me only a hundred values and then do the same exact plot.

2428
02:42:54,000 --> 02:43:01,000
And it'll pick out randomly a hundred values from this data frame and then you're doing the same kind of estimation here.

2429
02:43:01,000 --> 02:43:06,000
And so at this point you might say hey this value of 24 for the data framework is rad.

2430
02:43:06,000 --> 02:43:11,000
That looks like it's having fundamentally different behavior than the other values which seem to be clustered together.

2431
02:43:11,000 --> 02:43:17,000
I don't know that this actually tells us much in this case but it's another piece of functionality that I think is worth knowing about.

2432
02:43:17,000 --> 02:43:22,000
I'll go through the last few bits here and just talk about them really quickly.

2433
02:43:22,000 --> 02:43:29,000
So here's another KDE plot of this median value for the houses which is what we've seen before but this is going to be the target

2434
02:43:29,000 --> 02:43:33,000
like how much the price of the house is actually going to be sold for.

2435
02:43:33,000 --> 02:43:38,000
And we can add to that by saying we want to also see what's called this rug being true.

2436
02:43:38,000 --> 02:43:45,000
So instead of doing a KDE plot we can give it a distribution plot and add the fringe kind of rug thing at the bottom

2437
02:43:45,000 --> 02:43:49,000
which adds the actual density of points at these different values.

2438
02:43:49,000 --> 02:43:53,000
So you can see that it is actually very dense here as we go across these values.

2439
02:43:53,000 --> 02:43:58,000
So sometimes if you've chosen a kernel that's too wide or too narrow for your underlying dataset

2440
02:43:58,000 --> 02:44:03,000
seeing the rug along the bottom here gives you extra clues into what's going on.

2441
02:44:03,000 --> 02:44:09,000
And one last look here at two variables that might actually be more useful for looking at relationships.

2442
02:44:09,000 --> 02:44:17,000
The median value versus the L stat and you can see that there's this kind of banana shaped curve here going on in the relationships.

2443
02:44:17,000 --> 02:44:20,000
Okay so that's going to be it for this video.

2444
02:44:20,000 --> 02:44:24,000
What we did in this video is we showed a number of different visualization techniques.

2445
02:44:24,000 --> 02:44:31,000
We took a value that had a clear bimodality of a low and a high group and created a new data frame column to encode that.

2446
02:44:31,000 --> 02:44:41,000
Went through also and saw various methods of doing kernel density estimations, scatter plots and various other features.

2447
02:44:41,000 --> 02:44:44,000
In this video we'll be talking about stats models.

2448
02:44:44,000 --> 02:44:52,000
Stats models is a library that you can use that allows for a lot of statistical machinery that can help you with your data science work.

2449
02:44:52,000 --> 02:44:59,000
So we'll continue with the same Boston housing dataset as before which we were just looking at in the last video.

2450
02:44:59,000 --> 02:45:03,000
And take a look at some of these Boston housing prices.

2451
02:45:03,000 --> 02:45:07,000
Let me toggle this header in this toolbar real fast.

2452
02:45:07,000 --> 02:45:10,000
Make this full screen so we have a little extra room to look at.

2453
02:45:10,000 --> 02:45:17,000
So we will load in the scikit-learn dataset load Boston which again has the same attributes as we saw in the previous videos.

2454
02:45:17,000 --> 02:45:26,000
We will construct our pandas data frame from this scikit-learn dataset so that we can use the standard tools we've learned over the years.

2455
02:45:26,000 --> 02:45:34,000
We've combined the features and the target into one data frame and here's that scatter matrix plot we made in the previous video as well.

2456
02:45:34,000 --> 02:45:36,000
This is a pandas call.

2457
02:45:36,000 --> 02:45:41,000
So with this function call we get all of the pairwise interaction terms for this dataset.

2458
02:45:41,000 --> 02:45:49,000
And from this we see a number of features that look like they have some strong trends with the thing we would try to predict which is the median value of the house.

2459
02:45:49,000 --> 02:45:51,000
There's a trend here with this RM.

2460
02:45:51,000 --> 02:45:56,000
It looks like there's this kind of banana shaped L-stat curve that we talked about at the end of the previous video.

2461
02:45:56,000 --> 02:46:03,000
So we have a few things that we think you might be able to combine into some sort of model that will predict our median value.

2462
02:46:03,000 --> 02:46:07,000
Again, let's look at the columns and the number of unique values for each of these.

2463
02:46:07,000 --> 02:46:09,000
In particular, Rad has nine values.

2464
02:46:09,000 --> 02:46:10,000
We previously made that a Boolean.

2465
02:46:10,000 --> 02:46:13,000
Let's actually take a look at what the values comprise it.

2466
02:46:13,000 --> 02:46:17,000
So there are nine values and these are the values.

2467
02:46:17,000 --> 02:46:20,000
And then 24 is obviously the outlier here.

2468
02:46:20,000 --> 02:46:23,000
And we previously made a Boolean variable, which we can do again right now.

2469
02:46:23,000 --> 02:46:35,000
So we'll split everything from less than 15, which means everything up to here, 1, 2, 3, 4, 5, 6, 7, 8 will be labeled as 0 and 24 will be labeled as 1.

2470
02:46:35,000 --> 02:46:42,000
Let's look at the target variable, which is this median value plot just done as a distribution plot with a rug at the bottom.

2471
02:46:42,000 --> 02:46:47,000
And so this will be the target variable and we see some interesting structure going on here.

2472
02:46:47,000 --> 02:46:53,000
So plot again L-stat, which we identified just a second ago, versus median value.

2473
02:46:53,000 --> 02:46:56,000
We have again this kind of weird shaped banana plot.

2474
02:46:56,000 --> 02:46:59,000
This is sort of a tapering off effect of this thing.

2475
02:46:59,000 --> 02:47:01,000
So stats models.

2476
02:47:01,000 --> 02:47:06,000
Let's actually go and take a look at this as a Google search.

2477
02:47:06,000 --> 02:47:09,000
So stats models for Python.

2478
02:47:09,000 --> 02:47:15,000
The current documentation for this sits at statsmodels.sourceforge.net.

2479
02:47:15,000 --> 02:47:25,000
And it has, as it says, it's a Python module that allows users to look at data to estimate statistical models and perform statistical tests as many different modeling choices.

2480
02:47:25,000 --> 02:47:34,000
So our options, we have linear regression, generalized linear models and all the things listed here, and also some nice examples that explain more.

2481
02:47:34,000 --> 02:47:43,000
This is definitely a package that's geared more toward the statistical side of data science than the machine learning side, which is how I'd classify scikit-learn.

2482
02:47:43,000 --> 02:47:49,000
So with that comes a number of useful tools that if you haven't used them, it can be very powerful.

2483
02:47:49,000 --> 02:47:52,000
So this is where the documentation resides.

2484
02:47:52,000 --> 02:47:54,000
I recommend looking at that.

2485
02:47:54,000 --> 02:47:56,000
We imported this at the top.

2486
02:47:56,000 --> 02:47:58,000
So I'll scroll up to the top real fast.

2487
02:47:58,000 --> 02:48:04,000
We imported statsmodels.api as SM, which is not a typical way of importing Python modules.

2488
02:48:04,000 --> 02:48:07,000
This is one of the standard ways of doing stats models.

2489
02:48:07,000 --> 02:48:14,000
And then there's this formula.api, from which we're going to import ordinary least squares, which is just OLS in this case.

2490
02:48:14,000 --> 02:48:16,000
So let's scroll back down.

2491
02:48:16,000 --> 02:48:19,000
The formulas work in a way that's very similar to R.

2492
02:48:19,000 --> 02:48:27,000
So if you've used R before, or if you've used the Python package Patsy or various other ones, what you end up writing is the dependent variables.

2493
02:48:28,000 --> 02:48:30,000
Or the thing you're trying to predict.

2494
02:48:30,000 --> 02:48:36,000
So in this case, the median value, this tilde, which goes as Lstat, which is this thing that we're just plotting up here.

2495
02:48:36,000 --> 02:48:39,000
So Lstat versus medv median value.

2496
02:48:39,000 --> 02:48:43,000
So we've given the formula in terms of the relationship between these different variables.

2497
02:48:43,000 --> 02:48:46,000
I have to tell the model where the data comes from.

2498
02:48:46,000 --> 02:48:47,000
So we say this data frame.

2499
02:48:47,000 --> 02:48:56,000
When you give it this data frame, it says, okay, I'm going to look in this data source, df, four columns that are named in the same way that you've written it out in this formula here.

2500
02:48:56,000 --> 02:49:02,000
So we've said, okay, we've rewritten out medv and Lstat are actual columns.

2501
02:49:02,000 --> 02:49:05,000
And at the end, we will fit this with the dot fit function.

2502
02:49:05,000 --> 02:49:09,000
And the end, you have a model, which we've written down as mod.

2503
02:49:09,000 --> 02:49:15,000
And running the method dot summary tells us the output of trying to fit this data.

2504
02:49:15,000 --> 02:49:17,000
So we have the results from that.

2505
02:49:17,000 --> 02:49:19,000
So the dependent variable is median value.

2506
02:49:19,000 --> 02:49:25,000
The model is ordinarily squares method least squares tells you a bunch of different pieces of information that are pretty good.

2507
02:49:25,000 --> 02:49:27,000
These pieces of information that are pretty useful here.

2508
02:49:27,000 --> 02:49:35,000
So we have r squared, adjusted r squared, f statistics, log likelihood, AIC, the Ikeke information criteria, or however you say that.

2509
02:49:35,000 --> 02:49:41,000
Of course, the values of the coefficients and the intercepts, standard error, the 95% confidence intervals and so on.

2510
02:49:41,000 --> 02:49:48,000
If you're looking at this and wanting to evaluate this model statistically, you have all kinds of things at your fingertips here to look at.

2511
02:49:48,000 --> 02:49:54,000
Now, the relationship between Lstat and median value of the houses does not look linear to me.

2512
02:49:54,000 --> 02:49:58,000
This looks like a weird shape here and we can actually plot this with the river.

2513
02:49:58,000 --> 02:50:08,000
We can reverse this and see how this kind of tapering off of the median value versus Lstat can be a combination of features.

2514
02:50:08,000 --> 02:50:12,000
So I'm going to add an extra term here.

2515
02:50:12,000 --> 02:50:18,000
I'll actually take the log of the value and you can actually write it in this way in this string.

2516
02:50:18,000 --> 02:50:23,000
So you say numpy.log or np.log of the variable that you want to look at.

2517
02:50:23,000 --> 02:50:29,000
And you have to wrap it in this extra I for wrapping up because this doesn't actually exist as a column.

2518
02:50:29,000 --> 02:50:32,000
You have to wrap it in this I. There's other ways you can wrap this as well.

2519
02:50:32,000 --> 02:50:40,000
But I think having this and this both be in this linear model is likely to give a much better fit than just the Lstat by itself.

2520
02:50:40,000 --> 02:50:47,000
Or even Lstat squared, which we could also do simply by just instead of it numpy.log, we do Lstat star star squared.

2521
02:50:47,000 --> 02:50:56,000
So let's run this and we see our summary comes out and we have our R squared and AIC and all these different various intercepts and log values.

2522
02:50:56,000 --> 02:50:58,000
So let's actually compare the two.

2523
02:50:58,000 --> 02:51:00,000
So one way to compare it is to look at the AIC.

2524
02:51:00,000 --> 02:51:07,000
So this one from 3200 down to 3100, which is a pretty substantial decrease in the AIC.

2525
02:51:07,000 --> 02:51:14,000
So we think this is actually a better fit statistically, although we have to look at the residuals and do many other tests to make sure that this is actually is a viable model.

2526
02:51:14,000 --> 02:51:21,000
So that we're nowhere near done and like to double emphasize that what I'm showing you here is not a final rigorous data science result.

2527
02:51:21,000 --> 02:51:26,000
This is more of a sketch of what's possible with the tools that I think are useful.

2528
02:51:26,000 --> 02:51:29,000
Don't be taking directly from this lessons on how to do data science.

2529
02:51:29,000 --> 02:51:32,000
This is more of a sketch of how the tools should work.

2530
02:51:32,000 --> 02:51:34,000
Let's make this a little bit bigger so we have more room again.

2531
02:51:34,000 --> 02:51:41,000
One way to start to evaluate how good this fit is to actually look at this graphics from the stats models.

2532
02:51:41,000 --> 02:51:45,000
So statsmodels.graphics has a lot of different plotting options.

2533
02:51:45,000 --> 02:51:56,000
And there's these component and component plus residual plots, which is the CCPR plots, which you feed it the model itself contained within this model object is the underlying formula.

2534
02:51:56,000 --> 02:52:02,000
And so you can tell it, I want to know this one term here, the term that went with the log of the LSTAT score.

2535
02:52:02,000 --> 02:52:07,000
How does that look versus the residuals of this plus the I squared?

2536
02:52:07,000 --> 02:52:13,000
So we can see that the component actually does a decent job at this log stat versus residuals plus log stat.

2537
02:52:13,000 --> 02:52:17,000
So this line actually does a pretty good job of fitting this.

2538
02:52:17,000 --> 02:52:24,000
And for some reason that I don't quite understand, it actually plots it twice to the same exact plot, but was just LSTAT by itself.

2539
02:52:24,000 --> 02:52:34,000
So the first term in that model, we can see a little bit wonky behavior where it's not quite as good as the previous one where the residuals has some extra structure here in the low end, especially.

2540
02:52:34,000 --> 02:52:41,000
But we can start to have various goodness of fits and start to model out how good our model is at capturing the underlying data.

2541
02:52:41,000 --> 02:52:44,000
Again, it shows it twice. And again, I don't know why.

2542
02:52:44,000 --> 02:52:47,000
We can also add more terms to this model.

2543
02:52:47,000 --> 02:52:52,000
So previously we had LSTAT and this the log of LSTAT plus one for the intercept.

2544
02:52:52,000 --> 02:52:55,000
We can also add the RM category.

2545
02:52:55,000 --> 02:53:01,000
We can also add the Boolean value, which is whether it's in the higher low of the RAD variable.

2546
02:53:01,000 --> 02:53:13,000
And because it's a categorical, you can feed it to the model with this C value, and it will properly take into account the fact that what's in this column should be considered a category.

2547
02:53:13,000 --> 02:53:17,000
And it won't get you in trouble with the dummy variable trap that I had to mention at the last time.

2548
02:53:17,000 --> 02:53:30,000
So if we look at this, we see a number of things, including the fact that it starts off with the categorical variable radian bool, the categorical value where the default value is false.

2549
02:53:30,000 --> 02:53:36,000
And if it's true, what the change in the coefficient is for that value and the various other values as well.

2550
02:53:36,000 --> 02:53:42,000
Another thing to look at, depending on what you prefer to look at the BIC or the AIC or log likelihood F statistics.

2551
02:53:42,000 --> 02:53:53,000
To compare this to the previous models, this again has lowered the AIC substantially so that in terms of is it a better fit or not, it has some statistical basis for saying that this is a better fit.

2552
02:53:53,000 --> 02:54:01,000
We still have to do a lot of work still before we decide this is actually a reasonable fit and all the assumptions behind an ordinarily squares fit are holding true.

2553
02:54:01,000 --> 02:54:08,000
But just as a first pass, we have a lot of really nice information here.

2554
02:54:08,000 --> 02:54:18,000
In this video, I would like to continue from the previous video where we had just run a model to find the intercept and the categorical RAD value.

2555
02:54:18,000 --> 02:54:31,000
We can also run the same exact model as before deciding that this RAD values that are doing the boolean version of this, we can actually run on the entire column itself and telling stats models that we're actually using a categorical variable here as well.

2556
02:54:31,000 --> 02:54:40,000
So now we're trying to predict the median value of the house using all of these possible variables where these each have a coefficient in front of it.

2557
02:54:40,000 --> 02:54:49,000
We run a dot fit method on that and save it as a model as MOD and we're going to output the summary of that fit ran just then.

2558
02:54:49,000 --> 02:54:53,000
And again, dependent variable is this MED V variable.

2559
02:54:53,000 --> 02:54:59,000
And we see in the output here various goodness of fit and metrics about how the fit actually worked out.

2560
02:54:59,000 --> 02:55:12,000
We see an R squared of 0.73 and ASC of 3040, which is a slight improvement from the previous one, meaning that encoding the RAD variable where each value is independently stored.

2561
02:55:12,000 --> 02:55:17,000
So since it's a categorical, this is all with a baseline of one, which is why it doesn't appear here.

2562
02:55:17,000 --> 02:55:24,000
These coefficients are all based off of comparing each of these terms with the baseline of RAD equals to one.

2563
02:55:24,000 --> 02:55:26,000
If that doesn't make sense to you, don't worry about it.

2564
02:55:26,000 --> 02:55:28,000
Don't worry about this kind of statistical model.

2565
02:55:28,000 --> 02:55:31,000
And if it does make sense to you, then you understand what I just said.

2566
02:55:31,000 --> 02:55:38,000
So anyway, you get the output from this, but we actually want to see some plots to see how good this fit actually is.

2567
02:55:38,000 --> 02:55:45,000
Because just looking at the diagnostics and the metrics that come out from these fits isn't enough to tell us whether we're making a good model here.

2568
02:55:45,000 --> 02:55:48,000
So let's start to look at how we can assess fit quality.

2569
02:55:48,000 --> 02:55:51,000
One of the easy things you can do is to look at a thing called leverage.

2570
02:55:51,000 --> 02:56:02,000
StatsModels gives us a nice way to see this and visualize this by using the sm.graphics.influence plot and the plot leverage residual squared plots.

2571
02:56:02,000 --> 02:56:04,000
So let's take a look at these two plots.

2572
02:56:04,000 --> 02:56:06,000
I will first do this one.

2573
02:56:06,000 --> 02:56:15,000
So what we see here is on the y-axis, studentized residuals versus the x-axis, the h-leverage is using the cooks method for influence.

2574
02:56:15,000 --> 02:56:23,000
What you see on the leverage corresponds to an outside influence on the overall fit for its values.

2575
02:56:23,000 --> 02:56:30,000
So if you see something with high residuals and high leverage, that's something that we should possibly consider looking at that point and figuring out what's going on at that exact point.

2576
02:56:30,000 --> 02:56:37,000
So like 368, for example, would be a candidate to be looking at here because it has high residuals and high leverage.

2577
02:56:37,000 --> 02:56:38,000
That's one way of looking at it.

2578
02:56:38,000 --> 02:56:42,000
Another way is to look at it through this leverage residual squared.

2579
02:56:42,000 --> 02:56:46,000
And you give it simply the model object that you just fit above.

2580
02:56:46,000 --> 02:56:51,000
You just give it mod and it will give normalized residuals squared versus the leverage.

2581
02:56:51,000 --> 02:56:59,000
Again, 368, 365, 372, 371 are all outliers in terms of points that we should possibly take another look at again.

2582
02:56:59,000 --> 02:57:02,000
That corresponds to those four points up here.

2583
02:57:02,000 --> 02:57:09,000
So this leverage plots is one way of assessing the fit and the data points to make sure something isn't going crazy.

2584
02:57:09,000 --> 02:57:15,000
There's also a way of doing partial regression and I've quoted a bit from the documentation stats models here.

2585
02:57:15,000 --> 02:57:21,000
It says the slope of the fitted line is that of the exogenous in the full multiple regressions.

2586
02:57:21,000 --> 02:57:22,000
That's what's going on here.

2587
02:57:22,000 --> 02:57:27,000
The individual points can be used to assess the influence of points on the estimated coefficient.

2588
02:57:27,000 --> 02:57:29,000
So let's take a look at what this means visually.

2589
02:57:29,000 --> 02:57:32,000
I think it's easier to see what's happening this way.

2590
02:57:32,000 --> 02:57:39,000
So we have a partial regression plot and we're evaluating the expectation value of L-stat given the values that we have

2591
02:57:39,000 --> 02:57:43,000
and same plotting against the dependent variable, the median value that we're trying to predict.

2592
02:57:43,000 --> 02:57:52,000
And in this, we see that a lot of the points are kind of in a mass right here and the outliers are sitting here at this very low end.

2593
02:57:52,000 --> 02:57:55,000
And the same culprits appear again and you can actually see the effect that it's having on this.

2594
02:57:55,000 --> 02:57:57,000
It's pulling the slope up a bit.

2595
02:57:57,000 --> 02:58:03,000
So that's with a plot partial regression and giving various features as you're holding constant.

2596
02:58:03,000 --> 02:58:06,000
You can give it the entire model and see what that looks like.

2597
02:58:06,000 --> 02:58:12,000
When we get an entire grid, you're going to have a lot more involved to look at this grid of plots.

2598
02:58:12,000 --> 02:58:21,000
But it's the various features here so that the RAD variable is a feature three given X versus the median value on the X and the Y axis.

2599
02:58:21,000 --> 02:58:26,000
And so you can look at the various categorical variables and how they are being fit with the lines

2600
02:58:26,000 --> 02:58:34,000
and how they are interacting with the overall fit as well as the values that clearly are more continuous and having a nicer time of it.

2601
02:58:34,000 --> 02:58:39,000
So there's two ways to do this partial regression plot and both give you different ways of looking at this data.

2602
02:58:39,000 --> 02:58:42,000
Again, this is plotted twice for reasons unknown.

2603
02:58:42,000 --> 02:58:44,000
Finally, we have regression.

2604
02:58:44,000 --> 02:58:47,000
We can do this as a plot regress exogenous.

2605
02:58:47,000 --> 02:58:54,000
It gives you this four panel plot of median value versus L-stat and residuals versus L-stat.

2606
02:58:54,000 --> 02:58:56,000
So this is the data minus the fit itself.

2607
02:58:56,000 --> 02:59:04,000
And what you're hoping to see is noise pretty symmetrically about this axis here, the estimated variables and the CCPR plots.

2608
02:59:04,000 --> 02:59:09,000
So we see fit versus the actual values in this plot here.

2609
02:59:09,000 --> 02:59:15,000
And then we can also do it versus any other term in that model, which is, in this case, the natural log of the L-stat.

2610
02:59:15,000 --> 02:59:21,000
And then we get this plot here, which shows much tighter fit to this instance.

2611
02:59:21,000 --> 02:59:26,000
If you've built up a model, then again, I'm not saying I've built up some amazing model at this point.

2612
02:59:26,000 --> 02:59:29,000
This is definitely more descriptive of how this kind of process can work.

2613
02:59:29,000 --> 02:59:39,000
But if you would like to build up a model and look through a lot of diagnostic plots and have a true statistics, robust package manager behind you,

2614
02:59:39,000 --> 02:59:44,000
look into stats models and really try to dive into this because there's a lot of really good stuff in this.

2615
02:59:44,000 --> 02:59:49,000
So with that, I am concluding the second data science project.

2616
02:59:49,000 --> 02:59:58,000
And what I really try to focus on this time was a little bit of some more advanced features of using the plotting features of pandas,

2617
02:59:58,000 --> 03:00:04,000
really taking a deep dive into how one aspect of the stats models library and there's many aspects of it.

2618
03:00:04,000 --> 03:00:12,000
So I highlighted the ordinarily squares and how fitting linear model there with the statistical analysis and output that comes out of every fit,

2619
03:00:12,000 --> 03:00:16,000
as well as fitting the diagnostics and doing a quality of fit.

2620
03:00:16,000 --> 03:00:24,000
I also spent a lot of time on the visuals of this diving a little bit deeper into Seaborn and a few of the other options there.

2621
03:00:24,000 --> 03:00:31,000
So just as a kind of a wrap up of this, using map plot live and Seaborn stats models and pandas,

2622
03:00:31,000 --> 03:00:35,000
these data sets can be explored and manipulated and fit.

2623
03:00:35,000 --> 03:00:44,000
And these tools give a lot of flexibility and exploring and analyzing data in a notebook lets someone else take a look at what you did through your analysis.

2624
03:00:44,000 --> 03:00:51,000
So if you've made some horrendous error as you went through, that is something that's easy to point out and point to the plot.

2625
03:00:51,000 --> 03:00:57,000
As I said, this was a decent fit, for example. This is clearly bad because of reason X and you can point to it and circle it.

2626
03:00:57,000 --> 03:01:02,000
And it's not just a bunch of random files sitting in a directory somewhere.

2627
03:01:02,000 --> 03:01:13,000
To close off this project, the last thing that remains to do is to save this and to close it and push it back to GitHub so that you guys can also look at the same data sets and follow along yourself.

2628
03:01:13,000 --> 03:01:18,000
So I'm going to file, close and halt, go back to the terminal.

2629
03:01:18,000 --> 03:01:22,000
Git status has only this develop directory that has any changes in it.

2630
03:01:22,000 --> 03:01:27,000
So git add, develop, git status, we have three new files.

2631
03:01:27,000 --> 03:01:31,000
Okay. And I've closed down all of them. Just double check the server here.

2632
03:01:31,000 --> 03:01:38,000
Yep. Everything looks to be closed and say git commit.

2633
03:01:38,000 --> 03:01:40,000
Give a commit message that makes sense.

2634
03:01:40,000 --> 03:01:45,000
Git push origin Jonathan viz, which is the name of this branch.

2635
03:01:45,000 --> 03:01:54,000
Go back to GitHub, see that we've already made a change this we can compare and pull request and create a pull request.

2636
03:01:54,000 --> 03:02:02,000
I'll go ahead and actually merge this pull request because I've demonstrated how to do the full pull request and peer review aspect of it before.

2637
03:02:02,000 --> 03:02:07,000
And going back to the data viz project, what we have here is don't save that.

2638
03:02:07,000 --> 03:02:15,000
So the data viz project to will have the notebooks that I went through during this project available right there.

2639
03:02:15,000 --> 03:02:27,000
Just to recap what happened in this video, finished up looking at the plots from stats models and finished up the second data science project for this course.

2640
03:02:27,000 --> 03:02:33,000
Let's talk about some of the security issues with using the Jupiter notebook as is out of the box.

2641
03:02:33,000 --> 03:02:36,000
The notebook only listens to requests on local host.

2642
03:02:36,000 --> 03:02:39,000
This means that it ignores requests from the Internet.

2643
03:02:39,000 --> 03:02:44,000
People connecting from the Internet can't see your server and they won't be able to connect.

2644
03:02:44,000 --> 03:02:50,000
In order to allow them to connect, you have to explicitly configure the notebook to listen to the correct IP.

2645
03:02:50,000 --> 03:02:53,000
Once you do, anybody can access your notebook server.

2646
03:02:53,000 --> 03:03:02,000
The notebook server has no password by default and permissions of the users that are connecting are the same as the permissions of the user who had launched the server.

2647
03:03:02,000 --> 03:03:09,000
So this means if you launch the server, everybody who connects to the notebook will be executing things as if they were you.

2648
03:03:09,000 --> 03:03:13,000
The second main problem with using the notebook is it's using an insecure line.

2649
03:03:13,000 --> 03:03:19,000
So typically, the notebook is broken into three pieces, the kernel, the web server, and the client.

2650
03:03:19,000 --> 03:03:22,000
The client is what you see in the web browser.

2651
03:03:22,000 --> 03:03:24,000
It's the notebook as you know it.

2652
03:03:24,000 --> 03:03:29,000
And the web server is the thing that relays messages from the kernel to the client.

2653
03:03:29,000 --> 03:03:32,000
The web server communicates with the kernel using ZMQ.

2654
03:03:32,000 --> 03:03:35,000
Usually, the kernel and the web server exist on the same machine.

2655
03:03:35,000 --> 03:03:40,000
The kernel is the server that executes code and runs requests.

2656
03:03:40,000 --> 03:03:45,000
The line between the kernel and the web server you don't have to worry about usually because it's on the same machine.

2657
03:03:45,000 --> 03:03:51,000
However, the line between the web server and the client you have to worry about because it's over the open Internet.

2658
03:03:51,000 --> 03:03:57,000
This means that it's available for people to listen to and inject messages.

2659
03:03:57,000 --> 03:04:03,000
However, there are some setups where it makes sense to separate the kernel onto its own machine.

2660
03:04:03,000 --> 03:04:09,000
For example, you may have a cluster of computers running kernels, one computer running the web server.

2661
03:04:09,000 --> 03:04:15,000
In this case, you also have to worry about the ZMQ communication between the kernel and the web server

2662
03:04:15,000 --> 03:04:20,000
if the kernel and the web server are not on a VPN or in a secured network.

2663
03:04:20,000 --> 03:04:27,000
I'd just like to note, we aren't security experts, but we do have experts in the community and they do help us.

2664
03:04:27,000 --> 03:04:32,000
If you spot a problem, I ask you, please email us at our security mailing list.

2665
03:04:32,000 --> 03:04:35,000
The address is security at ipython.org.

2666
03:04:35,000 --> 03:04:38,000
Once you do, we'll work quickly to open a CVE.

2667
03:04:38,000 --> 03:04:49,000
In the next set of slides, I'll talk about how you can mitigate some of these problems and rest assured that your notebook deployment is as secure as can be.

2668
03:04:49,000 --> 03:04:54,000
In the last video, we talked about some of the limitations of running the notebook server publicly.

2669
03:04:54,000 --> 03:04:58,000
Specifically, we talked about security vulnerabilities.

2670
03:04:58,000 --> 03:05:05,000
In this video, I'll describe to you some of the solutions provided by the notebook software and some of the limitations of the notebook software.

2671
03:05:05,000 --> 03:05:13,000
First, in the last video, I showed you this diagram and told you that the communication between the web server and client was insecure by default.

2672
03:05:13,000 --> 03:05:20,000
The notebook actually provides support for HTTPS, industry grade encryption, for this communication line.

2673
03:05:20,000 --> 03:05:22,000
I'll show you how to configure this.

2674
03:05:22,000 --> 03:05:28,000
However, the notebook does not provide support out of the box for encrypting the line between the kernel and the web server.

2675
03:05:28,000 --> 03:05:37,000
Therefore, I recommend you either run the kernel and the web server on the same machine, if possible, or run them within a VPN.

2676
03:05:37,000 --> 03:05:40,000
The latest version of ZMQ does support encryption.

2677
03:05:40,000 --> 03:05:44,000
However, the notebook is not using that version of ZMQ currently.

2678
03:05:44,000 --> 03:05:50,000
Before we secure the notebook server, we need to be able to launch it so that people on the internet can connect to it.

2679
03:05:50,000 --> 03:05:53,000
In the previous chapter, you learned about Tralits.

2680
03:05:53,000 --> 03:05:58,000
We can configure the notebook to listen to all IP addresses using Tralits.

2681
03:05:58,000 --> 03:06:07,000
If I do jupiter, notebook, double dash help, I can list all the configuration options of the notebook.

2682
03:06:07,000 --> 03:06:12,000
The third to last configuration option is double dash IP.

2683
03:06:12,000 --> 03:06:16,000
That allows me to change the IP that the notebook server is listening on.

2684
03:06:16,000 --> 03:06:22,000
Just to cement the idea that this is a Tralit, I'll show you in the notebook source where this Tralit can be found.

2685
03:06:22,000 --> 03:06:28,000
In parentheses next to the configuration value, you see that notebook app.ip is listed.

2686
03:06:28,000 --> 03:06:33,000
This means that IP is a Tralit inside the notebook app class.

2687
03:06:33,000 --> 03:06:43,000
So opening up the notebook subfolder of the notebook repository and then the notebook app module inside that, we should be able to find the IP trait.

2688
03:06:43,000 --> 03:06:46,000
I'll use the search function of Adam to find IP.

2689
03:06:46,000 --> 03:06:49,000
Here's the definition of the IP trait.

2690
03:06:49,000 --> 03:06:54,000
If you want to configure something of the application and you don't see the option in the help string,

2691
03:06:54,000 --> 03:07:00,000
it's a good skill to be able to look through the source code and see if there's a Tralit that isn't being listed.

2692
03:07:00,000 --> 03:07:03,000
So we have two ways to set this IP trait.

2693
03:07:03,000 --> 03:07:12,000
We can either pass it in at the command line, like so, or we can specify it via config, so it's the new default.

2694
03:07:12,000 --> 03:07:19,000
By specifying IP to asterisk, we're telling the server to listen to requests on all IP addresses.

2695
03:07:19,000 --> 03:07:27,000
You may get two warnings, one from your system firewall prompting for Python to have the ability to accept incoming network connection.

2696
03:07:27,000 --> 03:07:30,000
This is because the notebook server is written in Python.

2697
03:07:30,000 --> 03:07:35,000
The other warning you'll see is in your terminal output from the notebook server itself,

2698
03:07:35,000 --> 03:07:42,000
warning you that the server is listening on all IP addresses and is not using encryption or authentication.

2699
03:07:42,000 --> 03:07:45,000
Don't worry, I'll show you how to set these up.

2700
03:07:45,000 --> 03:07:49,000
But first, let's try setting IP equals asterisk in the config.

2701
03:07:49,000 --> 03:07:57,000
If you recall from the earlier Tralits video, the config is stored inside the .jupiter folder inside my home directory.

2702
03:07:57,000 --> 03:08:05,000
Opening the folder up in Adam, we see that the config files from the earlier weekend and weekday demonstration still exist.

2703
03:08:05,000 --> 03:08:10,000
We'll go ahead and erase that here inside the jupiter notebook config.py file.

2704
03:08:10,000 --> 03:08:21,000
Now, recalling what the help text said in the terminal, we'll set notebook app.ip equal to asterisk.

2705
03:08:21,000 --> 03:08:27,000
Go ahead and save the file and we'll try launching the notebook server again.

2706
03:08:27,000 --> 03:08:35,000
This time, however, we won't specify the double-dash IP equals asterisk on the command line because it's already specified inside our config.

2707
03:08:35,000 --> 03:08:37,000
It looks like the launch was a success.

2708
03:08:37,000 --> 03:08:46,000
We still received the warnings about the server listening on all IP addresses, even though we didn't specify the IP equals asterisk flag in the command line.

2709
03:08:46,000 --> 03:08:52,000
This means that the line that we added to the config file worked as expected.

2710
03:08:52,000 --> 03:08:56,000
In the last video, we added password security to the notebook.

2711
03:08:56,000 --> 03:09:01,000
However, we did not encrypt the line between the web browser and the notebook web server.

2712
03:09:01,000 --> 03:09:10,000
This means that the notebook is vulnerable to people eavesdropping on the communication between it and you or any other users of your server.

2713
03:09:10,000 --> 03:09:15,000
In this video, we'll add HTTPS encryption to your notebook web server.

2714
03:09:15,000 --> 03:09:22,000
To get the notebook to start using HTTPS, all you have to do is point it to your key file and cert file.

2715
03:09:22,000 --> 03:09:27,000
If you don't have a key file and cert file, you can generate one yourself.

2716
03:09:27,000 --> 03:09:35,000
Before I show you how to tell the notebook to use your key file and cert file, I'll show you how to generate one using OpenSSL.

2717
03:09:35,000 --> 03:09:38,000
If you already have a key, you can skip this step.

2718
03:09:38,000 --> 03:09:41,000
Anaconda already comes with OpenSSL installed.

2719
03:09:41,000 --> 03:09:49,000
However, OpenSSL frequently releases security updates, so I highly recommend that you update to the latest version.

2720
03:09:49,000 --> 03:09:54,000
To do so, you can run conda space update OpenSSL.

2721
03:09:54,000 --> 03:09:57,000
I'm currently inside my Jupyter config directory.

2722
03:09:57,000 --> 03:10:03,000
I'm going to run OpenSSL to generate the key insert file.

2723
03:10:03,000 --> 03:10:06,000
I'm going to generate the cert so it lasts for one year.

2724
03:10:06,000 --> 03:10:14,000
To do so, I'm going to pass in 365 days into the days argument.

2725
03:10:14,000 --> 03:10:22,000
I'm going to output both the key and the cert file into the same file.

2726
03:10:22,000 --> 03:10:25,000
Once I run the command, an interactive wizard will start.

2727
03:10:25,000 --> 03:10:27,000
I'll answer some of these questions.

2728
03:10:27,000 --> 03:10:35,000
However, if you want, you can skip any of the questions just by hitting return to accept the default value.

2729
03:10:35,000 --> 03:10:40,000
Once that is done, we'll have to configure the notebook to use this key insert file.

2730
03:10:40,000 --> 03:10:46,000
To do so, I'm going to open up Adam inside the Jupyter configuration directory.

2731
03:10:46,000 --> 03:10:50,000
After the shaw from the password trait, I'm going to create a new line.

2732
03:10:50,000 --> 03:10:52,000
I'm going to specify the cert file first.

2733
03:10:52,000 --> 03:10:55,000
The cert file is a trait of the notebook app.

2734
03:10:55,000 --> 03:11:02,000
It's important that I pass the full path to the cert file.

2735
03:11:02,000 --> 03:11:04,000
Next, I'm going to specify the key file.

2736
03:11:04,000 --> 03:11:09,000
The key file is a trait of the session class.

2737
03:11:09,000 --> 03:11:14,000
Since we output it the key into the cert file, we can just specify the same file here.

2738
03:11:14,000 --> 03:11:17,000
Now I'm going to save the config.

2739
03:11:17,000 --> 03:11:22,000
Back in the terminal, I'm going to try launching the notebook.

2740
03:11:22,000 --> 03:11:26,000
When the notebook launches, you'll probably see this security error from your web browser,

2741
03:11:26,000 --> 03:11:30,000
saying that your connection is not private and that the authority is invalid.

2742
03:11:30,000 --> 03:11:33,000
This is because you self-generated the cert.

2743
03:11:33,000 --> 03:11:36,000
You can get around this by having a third party generate your cert.

2744
03:11:36,000 --> 03:11:41,000
For now, let's just click Advanced and proceed the local host.

2745
03:11:41,000 --> 03:11:43,000
Now our connection is being encrypted.

2746
03:11:43,000 --> 03:11:47,000
If you are interested in getting a cert that's verified by a third party,

2747
03:11:47,000 --> 03:11:49,000
I recommend using StartSSL.

2748
03:11:49,000 --> 03:11:51,000
They'll do it for free.

2749
03:11:51,000 --> 03:11:56,000
You can visit their website at www.startssl.com.

2750
03:11:56,000 --> 03:12:00,000
The StartSSL free cert should be fine for basic setups.

2751
03:12:00,000 --> 03:12:04,000
The other two offer slightly more features that are verified,

2752
03:12:04,000 --> 03:12:10,000
whereas the most expensive gives your site a green bar inside the address bar when the user is connected.

2753
03:12:10,000 --> 03:12:17,000
You can see that in the screenshot in the side column of their website.

2754
03:12:17,000 --> 03:12:22,000
In the last chapter, we talked about how you could deploy the notebook securely.

2755
03:12:22,000 --> 03:12:24,000
In this chapter, we'll change gears.

2756
03:12:24,000 --> 03:12:26,000
We'll start looking at NB Viewer.

2757
03:12:26,000 --> 03:12:32,000
Before I discuss installing NB Viewer, I'm going to show you what NB Viewer looks like in the wild.

2758
03:12:32,000 --> 03:12:36,000
I'm currently on the Jupyter public deployment of NB Viewer,

2759
03:12:36,000 --> 03:12:41,000
which is accessible at nbviewer.jupyter.org.

2760
03:12:41,000 --> 03:12:48,000
NB Viewer is a web application that is used to render static views of notebooks online.

2761
03:12:48,000 --> 03:12:51,000
In the back end, NB Viewer uses NB Convert,

2762
03:12:51,000 --> 03:12:58,000
the application that I showed you in chapter one, which can be used to convert notebooks to various static formats.

2763
03:12:58,000 --> 03:13:04,000
NB Viewer just uses NB Convert to convert notebooks to static HTML representations.

2764
03:13:04,000 --> 03:13:10,000
NB Viewer itself is a simple website that has a title and then an address bar

2765
03:13:10,000 --> 03:13:13,000
where you can paste the link to your notebook file.

2766
03:13:13,000 --> 03:13:17,000
After pasting the link, you click Go and it will render that notebook file.

2767
03:13:17,000 --> 03:13:21,000
Below that, there's a showcase of notebooks for various categories.

2768
03:13:21,000 --> 03:13:27,000
Here, for example, we can click on this iRuby notebook to see what iRuby is.

2769
03:13:27,000 --> 03:13:29,000
This is what a rendered notebook looks like.

2770
03:13:29,000 --> 03:13:33,000
You can see it looks quite different than the notebook client that you're used to.

2771
03:13:33,000 --> 03:13:39,000
It's quite a bit more bare, but it still bears some resemblance to pieces of the interactive notebook,

2772
03:13:39,000 --> 03:13:43,000
such as these prompts and cell formatting.

2773
03:13:43,000 --> 03:13:51,000
At the top, there are links to download the notebook, view the notebook on GitHub if it is a GitHub hosted file,

2774
03:13:51,000 --> 03:13:53,000
and a link to go to the top of the file.

2775
03:13:53,000 --> 03:13:58,000
At the bottom of the page, you can see the version of NB Viewer that we're running,

2776
03:13:58,000 --> 03:14:03,000
the notebooks version, and the version of NB Convert that NB Viewer is running against.

2777
03:14:03,000 --> 03:14:11,000
NB Viewer tries to be aggressive about caching notebooks, so you also get a status of when the notebook was last rendered.

2778
03:14:11,000 --> 03:14:19,000
Because NB Viewer is not a user application and it's actually a web application, it's not included with Anaconda.

2779
03:14:19,000 --> 03:14:21,000
Therefore, I'll have to show you how to install it.

2780
03:14:21,000 --> 03:14:25,000
The easiest way to install NB Viewer is using Docker.

2781
03:14:25,000 --> 03:14:31,000
Docker is not included with Anaconda either, so I'll also have to show you how to install that.

2782
03:14:31,000 --> 03:14:33,000
Docker is an emulation platform.

2783
03:14:33,000 --> 03:14:39,000
It allows you to run applications inside an isolated environment called containers.

2784
03:14:39,000 --> 03:14:45,000
Docker containers differ from virtual machines in that the containers share the host OS.

2785
03:14:45,000 --> 03:14:49,000
Containers can also share dependencies with each other.

2786
03:14:49,000 --> 03:14:58,000
This minimizes the distance between the container and the system hardware, which makes containers faster and smaller to install.

2787
03:14:58,000 --> 03:15:05,000
To install Docker, first go to Docker's website at www.docker.com.

2788
03:15:05,000 --> 03:15:09,000
Then click on the Get Started link in the top right hand corner.

2789
03:15:09,000 --> 03:15:13,000
The instructions for getting started are operating system dependent.

2790
03:15:13,000 --> 03:15:17,000
Because I'm running a Mac, I'll show you how to get started with Docker on a Mac.

2791
03:15:17,000 --> 03:15:22,000
If you're running Linux or Windows, this page will look a little different for you.

2792
03:15:22,000 --> 03:15:25,000
The first step is to install Docker tools.

2793
03:15:25,000 --> 03:15:28,000
You can click on Install Docker on OS X.

2794
03:15:28,000 --> 03:15:34,000
Scroll down to step two, where you'll see Install Docker Toolbox.

2795
03:15:34,000 --> 03:15:36,000
Click on that and then scroll down.

2796
03:15:36,000 --> 03:15:40,000
Click the Download button for Mac if you're on OS X.

2797
03:15:40,000 --> 03:15:43,000
Once you have the Toolbox installer, run it.

2798
03:15:43,000 --> 03:15:45,000
Follow the prompts in the wizard.

2799
03:15:45,000 --> 03:15:48,000
Select a hard drive to install to.

2800
03:15:48,000 --> 03:15:51,000
Enter your password when prompted.

2801
03:15:51,000 --> 03:15:53,000
When done, click Continue.

2802
03:15:53,000 --> 03:15:55,000
Then click Close.

2803
03:15:55,000 --> 03:15:59,000
Now launch the Docker Quick Start Terminal.

2804
03:15:59,000 --> 03:16:02,000
It takes a little while for it to start the machine.

2805
03:16:02,000 --> 03:16:13,000
Once the process finishes, you can run Docker space run space hello dash world.

2806
03:16:13,000 --> 03:16:21,000
You should see a Hello from Docker message, which confirms that your installation is working.

2807
03:16:21,000 --> 03:16:25,000
In the last video, I introduced you to NBViewer and Docker.

2808
03:16:25,000 --> 03:16:28,000
We then installed Docker on your machine.

2809
03:16:28,000 --> 03:16:31,000
In this video, we'll install the NBViewer Docker image.

2810
03:16:31,000 --> 03:16:35,000
To get started, open the Docker Quick Terminal.

2811
03:16:35,000 --> 03:16:37,000
Your terminal may take a while to start.

2812
03:16:37,000 --> 03:16:42,000
Once the terminal has started, pay attention to the IP address listed in green.

2813
03:16:42,000 --> 03:16:46,000
Mine's 192.168.99.100.

2814
03:16:46,000 --> 03:16:49,000
That is the IP address of the Docker image.

2815
03:16:49,000 --> 03:16:55,000
You'll use that IP address to access your NBViewer server once it's started.

2816
03:16:55,000 --> 03:16:57,000
The first step is to download NBViewer.

2817
03:16:57,000 --> 03:16:59,000
Now, I've already done this ahead of time.

2818
03:16:59,000 --> 03:17:04,000
So mine will download fairly quick because it will just be verifying that I have the latest version.

2819
03:17:04,000 --> 03:17:10,000
But the first time you run this command, it may take a while.

2820
03:17:10,000 --> 03:17:18,000
Next, let's try launching NBViewer.

2821
03:17:18,000 --> 03:17:22,000
Once the server starts, it should tell you the port it's listening on.

2822
03:17:22,000 --> 03:17:27,000
In a new web browser, go ahead and try accessing that IP address that you remember that was in green,

2823
03:17:27,000 --> 03:17:32,000
followed by colon 8080.

2824
03:17:32,000 --> 03:17:35,000
If all worked well, you should see NBViewer.

2825
03:17:35,000 --> 03:17:38,000
Go ahead and try to open up a notebook.

2826
03:17:38,000 --> 03:17:41,000
Once the notebook opens, go back to your terminal.

2827
03:17:41,000 --> 03:17:46,000
You should see output from the NBViewer server verifying your request.

2828
03:17:46,000 --> 03:17:49,000
Without this, it would be hard to tell if you were actually running the server or not,

2829
03:17:49,000 --> 03:17:53,000
or if you were just accessing the public NBViewer deployment by Jupyter.

2830
03:17:53,000 --> 03:17:59,000
NBViewer has this wonderful feature that allows you to access notebooks on GitHub using short URLs.

2831
03:17:59,000 --> 03:18:05,000
To demonstrate this, I'll access a notebook that's stored as a gist under my GitHub account.

2832
03:18:05,000 --> 03:18:08,000
So here's a simple notebook I created for PyData.

2833
03:18:08,000 --> 03:18:12,000
It's stored under my account as this gist.

2834
03:18:12,000 --> 03:18:14,000
I'm going to just copy this URL.

2835
03:18:14,000 --> 03:18:20,000
Because NBViewer has support for gist, I can just paste it directly in and click go.

2836
03:18:20,000 --> 03:18:26,000
Alternatively, I can use an even shorter form, which is just the gist ID.

2837
03:18:26,000 --> 03:18:30,000
To do so, I'll remove all the stuff before the last forward slash.

2838
03:18:30,000 --> 03:18:32,000
This is my gist ID.

2839
03:18:32,000 --> 03:18:34,000
You can see NBViewer still renders it.

2840
03:18:34,000 --> 03:18:37,000
The GitHub public APIs have rate limiting.

2841
03:18:37,000 --> 03:18:43,000
So if you plan on supporting this feature, it's a good idea to generate an access token for NBViewer.

2842
03:18:43,000 --> 03:18:45,000
Doing so is relatively painless.

2843
03:18:45,000 --> 03:18:48,000
Log on to github.com using your account.

2844
03:18:48,000 --> 03:18:52,000
Then in the top right hand corner, click view profile and more.

2845
03:18:52,000 --> 03:18:56,000
Next, select your profile.

2846
03:18:56,000 --> 03:18:58,000
Click edit profile.

2847
03:18:58,000 --> 03:19:03,000
Then click personal access tokens in the left hand column.

2848
03:19:03,000 --> 03:19:06,000
Next, click generate new token.

2849
03:19:06,000 --> 03:19:08,000
Give the token a name.

2850
03:19:08,000 --> 03:19:12,000
And then change the scopes that you want to use to restrict the token.

2851
03:19:12,000 --> 03:19:14,000
When you're done, click generate token.

2852
03:19:14,000 --> 03:19:17,000
Your token will be displayed in the green bar.

2853
03:19:17,000 --> 03:19:20,000
I've blurred a couple of the numbers of my token for security.

2854
03:19:20,000 --> 03:19:24,000
Click the copy button to copy the token to your clipboard.

2855
03:19:24,000 --> 03:19:29,000
Now in the terminal that's running NBViewer, hit ctrl C to stop NBViewer.

2856
03:19:29,000 --> 03:19:37,000
Now let's relaunch NBViewer, adding our new access token to the command line.

2857
03:19:37,000 --> 03:19:44,000
Because we're running NBViewer as a Docker image, we can't specify arguments directly to NBViewer.

2858
03:19:44,000 --> 03:19:49,000
Instead, we have to set environment variables to cause NBViewer to change its behavior.

2859
03:19:49,000 --> 03:19:59,000
Here, I'm telling Docker to set the github underscore api underscore token variable to the token that I just copied from github.

2860
03:19:59,000 --> 03:20:03,000
Now when I try accessing NBViewer, it should be using that token.

2861
03:20:03,000 --> 03:20:06,000
Let's paste the same gist id from earlier.

2862
03:20:06,000 --> 03:20:12,000
Now let's go to github.com to see if the api token was used.

2863
03:20:12,000 --> 03:20:16,000
We can see that it was just used because github says it was used within the last day.

2864
03:20:16,000 --> 03:20:21,000
Using this token should help lift some of the rate limits for github access.

2865
03:20:21,000 --> 03:20:28,000
And it's also nice because it allows github to control who's accessing their APIs.

2866
03:20:28,000 --> 03:20:32,000
In the last video, we installed NBViewer using Docker.

2867
03:20:32,000 --> 03:20:34,000
This is great for most use cases.

2868
03:20:34,000 --> 03:20:39,000
However, sometimes it's necessary to maintain more control over the distribution.

2869
03:20:39,000 --> 03:20:43,000
To do this, you can install NBViewer from source.

2870
03:20:43,000 --> 03:20:45,000
This will allow you to do two things.

2871
03:20:45,000 --> 03:20:50,000
One, it will allow you to control what dependencies NBViewer is using.

2872
03:20:50,000 --> 03:21:00,000
And two, it will allow you to modify NBViewer's source code directly, including installing additional extensions without having to recompile the Docker image.

2873
03:21:00,000 --> 03:21:03,000
The first step is to clone the NBViewer repository.

2874
03:21:03,000 --> 03:21:13,000
You can either clone the upstream fork, like I will do here, or you can clone your own fork.

2875
03:21:13,000 --> 03:21:17,000
Once NBViewer has finished cloning, cd into that directory.

2876
03:21:17,000 --> 03:21:25,000
Now run pip install-r requirements dev.txt.

2877
03:21:25,000 --> 03:21:32,000
Next run npm space install, then run invoke bower.

2878
03:21:32,000 --> 03:21:34,000
This is installing the static assets.

2879
03:21:34,000 --> 03:21:39,000
Next run invoke less, which will compile the less into CSS.

2880
03:21:39,000 --> 03:21:41,000
CSS is what styles NBViewer.

2881
03:21:41,000 --> 03:21:43,000
I've cleared my console.

2882
03:21:43,000 --> 03:21:46,000
Now I'm going to run pip install markdown.

2883
03:21:46,000 --> 03:21:51,000
Once that finishes, I should be able to launch NBViewer.

2884
03:21:51,000 --> 03:21:55,000
Now I can access NBViewer using localhost.

2885
03:21:55,000 --> 03:21:59,000
To verify that this is actually running locally, let's try changing some of the code.

2886
03:21:59,000 --> 03:22:01,000
Let's change the title.

2887
03:22:01,000 --> 03:22:04,000
I'm going to hit ctrl-c to stop the server.

2888
03:22:04,000 --> 03:22:07,000
I'm going to open up Adam in the NBViewer repository.

2889
03:22:07,000 --> 03:22:16,000
Once Adam opens, I'm going to open the NBViewer sub directory, the template sub folder, and then the index.html file.

2890
03:22:16,000 --> 03:22:18,000
Let's change the title of the website.

2891
03:22:18,000 --> 03:22:21,000
We'll change NBViewer to myNBViewer.

2892
03:22:21,000 --> 03:22:23,000
We'll go ahead and save.

2893
03:22:23,000 --> 03:22:27,000
Editing these templates directly is actually not the best way to modify NBViewer,

2894
03:22:27,000 --> 03:22:31,000
but we'll do it for now just to verify that we've installed from source.

2895
03:22:31,000 --> 03:22:35,000
Now back at the terminal, go ahead and relaunch the server.

2896
03:22:35,000 --> 03:22:39,000
Back in your web browser, refresh the page.

2897
03:22:39,000 --> 03:22:46,000
When you see the title update to myNBViewer, you know that the changes that we made to the template file were loaded.

2898
03:22:46,000 --> 03:22:51,000
If when you refresh the page, the title doesn't change, try emptying your web browser's cache.

2899
03:22:51,000 --> 03:22:58,000
If you want a quicker way to see if this is the problem, open an incognito tab and then navigate to the NBViewer web page.

2900
03:22:58,000 --> 03:23:01,000
The incognito tab should prevent the web browser from caching.

2901
03:23:01,000 --> 03:23:09,000
Often when you do web app development, caching causes problems because it doesn't let you see your most recent changes to the code.

2902
03:23:09,000 --> 03:23:16,000
Earlier, I had mentioned that modifying the template directly in NBViewer's source was not the right way to modify the template.

2903
03:23:16,000 --> 03:23:22,000
A better way would be to configure NBViewer's template directory to a different directory,

2904
03:23:22,000 --> 03:23:29,000
have it load from one of your own custom templates, which inherit it from the template included with NBViewer.

2905
03:23:29,000 --> 03:23:37,000
In the following videos, we'll look at how we can do that in addition to customizing NBViewer different ways.

2906
03:23:37,000 --> 03:23:43,000
In this video, we'll look at what we can do just by extending the NBViewer templates.

2907
03:23:43,000 --> 03:23:47,000
Before we get started, we need to remove the hack that we added in the last video.

2908
03:23:47,000 --> 03:23:51,000
I'm going to go ahead and launch Adam from within the NBViewer repository.

2909
03:23:51,000 --> 03:23:59,000
Once Adam's launched, I'll open the NBViewer subfolder, then the template subfolder, and then index.html.

2910
03:23:59,000 --> 03:24:02,000
In there, I'll remove my space.

2911
03:24:02,000 --> 03:24:04,000
Now, I'll save the file.

2912
03:24:04,000 --> 03:24:07,000
Let's see who loads this index.html file.

2913
03:24:07,000 --> 03:24:16,000
I'm going to open the find in project dialog by hitting command shift F, which is control shift F on Linux and Windows.

2914
03:24:16,000 --> 03:24:21,000
Looks like the template is rendered here in the index handler method.

2915
03:24:21,000 --> 03:24:27,000
Let's see where the render template method searches for index.html.

2916
03:24:27,000 --> 03:24:33,000
Looks like the definition of render template is in the NBViewer provider's base.py class.

2917
03:24:33,000 --> 03:24:36,000
The get template method is used to load the template.

2918
03:24:36,000 --> 03:24:40,000
Inside the get template method, which is above the render template method,

2919
03:24:40,000 --> 03:24:46,000
we can see that the Jinja2 environment has another get template method defined, which we call out to.

2920
03:24:46,000 --> 03:24:50,000
Let's see where this Jinja2 environment comes from.

2921
03:24:50,000 --> 03:24:53,000
Looks like it's defined in app.py.

2922
03:24:53,000 --> 03:25:02,000
Scrolling up to see where nv is defined, we see nv is an instance of environment, which is imported from Jinja2.

2923
03:25:03,000 --> 03:25:08,000
The template loader is a file system loader, which loads from template paths.

2924
03:25:08,000 --> 03:25:13,000
Template paths is hard coded to the repository directory template subdirectory.

2925
03:25:13,000 --> 03:25:21,000
However, if you specify a custom template path using the nbViewer underscore template underscore path environment variable,

2926
03:25:21,000 --> 03:25:28,000
it gets propended to a list of paths, which then is used as the higher priority path.

2927
03:25:28,000 --> 03:25:33,000
So we can set a custom template search path just by setting that environment variable.

2928
03:25:33,000 --> 03:25:37,000
Knowing this, we can set the nbViewer template path.

2929
03:25:37,000 --> 03:25:44,000
I'm going to set it to the nbViewer underscore templates subfolder of my home directory.

2930
03:25:44,000 --> 03:25:47,000
Now I'm going to create that directory.

2931
03:25:47,000 --> 03:25:51,000
I'll cd into it and open Adam.

2932
03:25:51,000 --> 03:25:55,000
In Adam, I'll create an index.html file.

2933
03:25:55,000 --> 03:26:02,000
This file will override the index.html file in the nbViewer templates folder.

2934
03:26:02,000 --> 03:26:05,000
For now, I'll just write hello world and save the file.

2935
03:26:05,000 --> 03:26:11,000
Now, switching back to the terminal, I'll cd back into the nbViewer repository.

2936
03:26:11,000 --> 03:26:15,000
I'll launch nbViewer using the same command from earlier.

2937
03:26:15,000 --> 03:26:19,000
Now when I try to access nbViewer, the page just says hello world.

2938
03:26:19,000 --> 03:26:21,000
This means that our template was loaded successfully.

2939
03:26:21,000 --> 03:26:23,000
Let's try to complicate things.

2940
03:26:23,000 --> 03:26:28,000
Back inside the Adam that is opened in the nbViewer repository,

2941
03:26:28,000 --> 03:26:33,000
I'm going to go to the templates folder and open index.html again.

2942
03:26:33,000 --> 03:26:38,000
nbViewer uses the Jinja templating library to render its HTML pages.

2943
03:26:38,000 --> 03:26:41,000
This funky syntax extends and block body.

2944
03:26:41,000 --> 03:26:44,000
Those are Jinja 2 specific keywords.

2945
03:26:44,000 --> 03:26:47,000
The rest of the code that you see is vanilla HTML.

2946
03:26:47,000 --> 03:26:50,000
Let's go ahead and copy all the contents of this file.

2947
03:26:50,000 --> 03:26:57,000
Back into our index.html file inside the nbViewer templates folder.

2948
03:26:57,000 --> 03:27:01,000
Now let's change the title here and save.

2949
03:27:01,000 --> 03:27:06,000
If we've done this correctly, we'll have changed the look of the nbViewer landing page

2950
03:27:06,000 --> 03:27:09,000
without actually modifying nbViewer's source code.

2951
03:27:09,000 --> 03:27:16,000
I refreshed the nbViewer page and it looks like our custom template was loaded.

2952
03:27:16,000 --> 03:27:21,000
To give ourselves a target, let's try to set up an O'Reilly themed nbViewer.

2953
03:27:21,000 --> 03:27:25,000
Our O'Reilly nbViewer should look like its O'Reilly's nbViewer,

2954
03:27:25,000 --> 03:27:28,000
but also host O'Reilly content.

2955
03:27:28,000 --> 03:27:33,000
First, let's change the basic index template that we created in the last video.

2956
03:27:33,000 --> 03:27:39,000
To do so, I'll open up the nbViewer templates folder that we created in my home directory.

2957
03:27:39,000 --> 03:27:43,000
Now I'll open Adam in that directory.

2958
03:27:43,000 --> 03:27:47,000
I'll change the title to O'Reilly notebooks.

2959
03:27:47,000 --> 03:27:51,000
We'll also change the descriptive paragraph below.

2960
03:27:51,000 --> 03:27:54,000
Eventually, we won't want to be hosting notebooks from GitHub,

2961
03:27:54,000 --> 03:27:58,000
so let's change the placeholder text to reflect that.

2962
03:27:58,000 --> 03:28:00,000
Now I'll save and see how it looks.

2963
03:28:00,000 --> 03:28:04,000
We can launch nbViewer using the same command that we used in the previous video.

2964
03:28:04,000 --> 03:28:06,000
I'll create a new tab of my terminal.

2965
03:28:06,000 --> 03:28:12,000
Before starting nbViewer, I need to set the environment variable again for the custom templates.

2966
03:28:13,000 --> 03:28:16,000
Now I can launch the server.

2967
03:28:16,000 --> 03:28:18,000
It looks like our change is rendered.

2968
03:28:18,000 --> 03:28:21,000
However, we should probably change this logo in the top left,

2969
03:28:21,000 --> 03:28:24,000
and also remove this link to Jupyter.

2970
03:28:24,000 --> 03:28:27,000
Let's scroll down to see if there's anything else we need to change.

2971
03:28:27,000 --> 03:28:32,000
We'll have to change this section of showcased notebooks.

2972
03:28:32,000 --> 03:28:36,000
And at the very bottom, it looks like we'll want to change the footer.

2973
03:28:36,000 --> 03:28:39,000
Lastly, we should probably change the styling

2974
03:28:39,000 --> 03:28:42,000
and maybe use JavaScript to spiff up the page a bit.

2975
03:28:42,000 --> 03:28:45,000
First, let's see if we can change the header and footer.

2976
03:28:45,000 --> 03:28:49,000
Let's go back to the index.html file in our custom template folder.

2977
03:28:49,000 --> 03:28:54,000
Looking at the index.html file, it looks like layout.html is extended

2978
03:28:54,000 --> 03:28:56,000
for the basic layout of the page.

2979
03:28:56,000 --> 03:28:57,000
Let's open that.

2980
03:28:57,000 --> 03:29:00,000
It should be inside the nbViewer directory.

2981
03:29:00,000 --> 03:29:04,000
Inside the nbViewer repository in the nbViewer subfolder,

2982
03:29:05,000 --> 03:29:09,000
under templates, we can find layout.html.

2983
03:29:09,000 --> 03:29:12,000
Like we did with index, let's copy everything in here.

2984
03:29:12,000 --> 03:29:16,000
Then, back inside our custom nbViewer templates folder,

2985
03:29:16,000 --> 03:29:19,000
let's create a layout.html.

2986
03:29:19,000 --> 03:29:23,000
Here, I'll paste all the contents from the other layout.html.

2987
03:29:23,000 --> 03:29:25,000
Let's remove this link to Google Analytics,

2988
03:29:25,000 --> 03:29:31,000
because this is the Google Analytics for the Jupyter deployment of nbViewer.

2989
03:29:31,000 --> 03:29:34,000
Also, we'll want to get rid of these links to Fastly

2990
03:29:34,000 --> 03:29:39,000
and change the Rackspace link to O'Reilly.

2991
03:29:39,000 --> 03:29:43,000
Scrolling up, let's get rid of the text that says this website does not host notebooks.

2992
03:29:43,000 --> 03:29:46,000
It only renders notebooks available on other websites,

2993
03:29:46,000 --> 03:29:51,000
because we're going to be using this pseudo-website to host O'Reilly notebooks.

2994
03:29:51,000 --> 03:29:55,000
Here's the link to Jupyter that we wanted to remove.

2995
03:29:55,000 --> 03:29:59,000
Lastly, we'll want to change the nav logo to O'Reilly's logo.

2996
03:29:59,000 --> 03:30:03,000
Let's go to O'Reilly's website to see if we can get the link to their logo.

2997
03:30:03,000 --> 03:30:07,000
I'm on O'Reilly's website now at www.oreilly.com.

2998
03:30:07,000 --> 03:30:09,000
I like this logo in the top left-hand corner.

2999
03:30:09,000 --> 03:30:13,000
I'm going to right-click on it and click Copy Image URL.

3000
03:30:13,000 --> 03:30:16,000
Back inside the layout.html file,

3001
03:30:16,000 --> 03:30:23,000
I'm then going to paste that URL over the image URL for the existing nav logo.

3002
03:30:23,000 --> 03:30:26,000
We'll also get rid of the New Relic reference.

3003
03:30:26,000 --> 03:30:31,000
Let's save what we have and go back to the browser to see how it renders.

3004
03:30:31,000 --> 03:30:35,000
Awesome! This is already looking a little more O'Reilly-like.

3005
03:30:35,000 --> 03:30:37,000
We'll probably still want to change the color scheme,

3006
03:30:37,000 --> 03:30:40,000
because I noticed when I roll over FAQ, it highlights orange,

3007
03:30:40,000 --> 03:30:45,000
which doesn't match O'Reilly's red.

3008
03:30:45,000 --> 03:30:50,000
Looking at the bottom of the page, it looks like our footer updated it correctly.

3009
03:30:50,000 --> 03:30:53,000
Let's check out the FAQ page.

3010
03:30:53,000 --> 03:30:55,000
It looks like there's some questions that shouldn't be here.

3011
03:30:55,000 --> 03:30:57,000
Let's remove them.

3012
03:30:57,000 --> 03:30:59,000
Back inside the nbviewer repository,

3013
03:30:59,000 --> 03:31:03,000
it looks like the FAQ.md file might be the file that's getting rendered.

3014
03:31:03,000 --> 03:31:04,000
Let's open that.

3015
03:31:04,000 --> 03:31:08,000
It looks like this file does indeed extend the layout.html file

3016
03:31:08,000 --> 03:31:12,000
and uses a special markdown filter to convert itself from markdown to html.

3017
03:31:12,000 --> 03:31:16,000
In the process, it automatically generates its table of contents.

3018
03:31:16,000 --> 03:31:22,000
Let's do what we did for index.html and layout.html in our custom templates folder.

3019
03:31:22,000 --> 03:31:32,000
Let's create an FAQ.md file and copy the contents from the FAQ.md file in nbviewer.

3020
03:31:32,000 --> 03:31:34,000
Let's get rid of the first two questions,

3021
03:31:34,000 --> 03:31:38,000
because they are completely specific to Jupyter's nbviewer.

3022
03:31:38,000 --> 03:31:50,000
We'll defer them to nbviewer for this information.

3023
03:31:50,000 --> 03:31:53,000
This paragraph doesn't relate at all to our viewer,

3024
03:31:53,000 --> 03:31:56,000
nor does the one below or the one below that.

3025
03:31:56,000 --> 03:31:58,000
This paragraph also doesn't relate.

3026
03:31:58,000 --> 03:31:59,000
This is related, though.

3027
03:31:59,000 --> 03:32:03,000
We just need to update it to point to our email address.

3028
03:32:03,000 --> 03:32:06,000
The last few before the final one also don't relate,

3029
03:32:06,000 --> 03:32:12,000
and we'll replace the text of the final one with an email link to the O'Reilly administrator.

3030
03:32:12,000 --> 03:32:16,000
Now let's save and see if the FAQ page renders how we want.

3031
03:32:16,000 --> 03:32:19,000
Back in the web browser, I'm going to refresh the page.

3032
03:32:19,000 --> 03:32:26,000
Looks like we should remove the first question as well.

3033
03:32:26,000 --> 03:32:29,000
Let's refresh the page again.

3034
03:32:29,000 --> 03:32:31,000
Ah, much better.

3035
03:32:31,000 --> 03:32:34,000
Let's try clicking on the O'Reilly image to go back to the homepage.

3036
03:32:34,000 --> 03:32:36,000
Sweet, it worked.

3037
03:32:36,000 --> 03:32:44,000
In the next tutorial, we'll look at adding custom CSS to style it more like O'Reilly's main website.

3038
03:32:44,000 --> 03:32:49,000
In this video, we'll talk about how nbviewer compiles its less into CSS.

3039
03:32:49,000 --> 03:32:54,000
We'll then look at adding our own CSS to our custom nbviewer templates.

3040
03:32:54,000 --> 03:32:58,000
I've still left the nbviewer server running from the last video.

3041
03:32:58,000 --> 03:33:01,000
This is because I do not need to restart it.

3042
03:33:01,000 --> 03:33:08,000
As long as I'm only changing static files, all I have to do is refresh the webpage to update the contents.

3043
03:33:08,000 --> 03:33:12,000
If I were working on server-side files, for example the Python files,

3044
03:33:12,000 --> 03:33:15,000
then I would have to restart the server.

3045
03:33:15,000 --> 03:33:20,000
Let's go ahead and open up Adam inside the nbviewer repository.

3046
03:33:20,000 --> 03:33:26,000
When you installed nbviewer from source code, you had to run a command called invoke less.

3047
03:33:26,000 --> 03:33:34,000
When you ran that command, what it did was run a function called less inside the tasks.py file.

3048
03:33:34,000 --> 03:33:36,000
Here's that function.

3049
03:33:36,000 --> 03:33:42,000
What this function does is compile the less into CSS using the less compiler.

3050
03:33:42,000 --> 03:33:46,000
It outputs the compiled CSS into a build subdirectory.

3051
03:33:46,000 --> 03:33:52,000
It outputs a styles.css, notebook.css, and slides.css.

3052
03:33:52,000 --> 03:33:59,000
Likewise, the source files used are styles, notebook, and slides.less.

3053
03:33:59,000 --> 03:34:03,000
Let's open the nbviewer static directory.

3054
03:34:03,000 --> 03:34:07,000
In here, you see the folder less and the build folder.

3055
03:34:07,000 --> 03:34:12,000
The build folder is grayed out here because it's not included in the git repository.

3056
03:34:12,000 --> 03:34:15,000
That's because we don't want to check in the built files.

3057
03:34:15,000 --> 03:34:17,000
That would just be including changes twice.

3058
03:34:17,000 --> 03:34:20,000
The less folder is where the less is stored.

3059
03:34:20,000 --> 03:34:24,000
We can open up the notebook.less to get an idea of how notebooks are styled.

3060
03:34:24,000 --> 03:34:29,000
A major difference between less and CSS is that less allows you to import.

3061
03:34:29,000 --> 03:34:34,000
Here you can see that bootstrap is imported and styling from ipython.

3062
03:34:34,000 --> 03:34:38,000
Let's go ahead and see where the build files are referenced.

3063
03:34:38,000 --> 03:34:46,000
In the layout template, inside the header, we see that styles.css is referenced.

3064
03:34:46,000 --> 03:34:52,000
Inside notebook.html, we can see where notebook.css is referenced.

3065
03:34:52,000 --> 03:34:56,000
Let's go ahead and add our own styling to our custom templates.

3066
03:34:56,000 --> 03:35:01,000
Going back to the terminal, I'm going to cd into our custom templates directory.

3067
03:35:01,000 --> 03:35:04,000
Here I'll open Adam.

3068
03:35:04,000 --> 03:35:10,000
Inside our layout.html, below the existing CSS import, let's add our own.

3069
03:35:10,000 --> 03:35:16,000
It's important that you do this below the existing because this will cause your style to override the existing.

3070
03:35:16,000 --> 03:35:22,000
Unfortunately, nbviewer doesn't support pulling files from directories outside of its own, so we have two options.

3071
03:35:22,000 --> 03:35:29,000
We could either place our custom style inside the nbviewer repository, which I'd rather not do,

3072
03:35:29,000 --> 03:35:36,000
or we can use the ginga templating to load it from our nbviewer templates directory and then inline it directly into the html.

3073
03:35:36,000 --> 03:35:42,000
First, let me show you what it would look like if you were to put the CSS inside the nbviewer repository.

3074
03:35:42,000 --> 03:35:48,000
You would change build to CSS and then give your CSS file a name, like custom.

3075
03:35:48,000 --> 03:35:56,000
You would then save this file and inside the nbviewer repository under the static directory in CSS,

3076
03:35:56,000 --> 03:36:01,000
you would right-click, create a new file called custom.css.

3077
03:36:01,000 --> 03:36:06,000
And then inside here, you would put whatever custom CSS you want.

3078
03:36:06,000 --> 03:36:14,000
Moving back into our nbviewer templates directory, the alternative, I think, makes more sense because then you can keep your CSS next to your templates.

3079
03:36:14,000 --> 03:36:19,000
For this, instead of using a link tag, you'll use a style tag.

3080
03:36:19,000 --> 03:36:26,000
Then inside style tags, use the ginga include to include your style file.

3081
03:36:26,000 --> 03:36:32,000
The only downside to using this method is that you're disabling the browser's ability to cache your style,

3082
03:36:32,000 --> 03:36:36,000
which means that every time a page is requested, client will have to download the CSS again.

3083
03:36:36,000 --> 03:36:43,000
That's usually not a problem with small CSS files, and if it is a problem, you can use the other method that I just showed you.

3084
03:36:43,000 --> 03:36:48,000
So now let's save this file and create our own custom CSS.

3085
03:36:48,000 --> 03:36:55,000
To test to see if our custom CSS is working, let's try setting the body background color.

3086
03:36:55,000 --> 03:37:00,000
I'm going to use important just to make sure it overrides any other values.

3087
03:37:00,000 --> 03:37:06,000
However, it's important to note that important isn't the best practice.

3088
03:37:06,000 --> 03:37:10,000
Using important disables you from later overriding styles.

3089
03:37:10,000 --> 03:37:15,000
In a new browser window, let's navigate to our NB viewer page to see if our style gets loaded.

3090
03:37:15,000 --> 03:37:21,000
Awesome, it looks like the style loaded successfully.

3091
03:37:21,000 --> 03:37:28,000
Now, instead of applying such a hideous style, let's try to override the orange highlight color that's applied to buttons.

3092
03:37:28,000 --> 03:37:33,000
Let's inspect the FAQ button to see how we can select it using CSS.

3093
03:37:33,000 --> 03:37:40,000
Looks like a good selector would be to use the navbar right class and then the anchor tag.

3094
03:37:40,000 --> 03:37:44,000
Back inside our custom CSS, let's do that.

3095
03:37:44,000 --> 03:37:49,000
To specify that we want to change the styling when it is hovered over, add the hover sudo selector.

3096
03:37:49,000 --> 03:37:52,000
For now, let's just try changing the background color.

3097
03:37:52,000 --> 03:37:58,000
Again, let's use the important tag just to make sure that what we're doing gets applied.

3098
03:37:58,000 --> 03:38:00,000
Looks like that worked.

3099
03:38:00,000 --> 03:38:07,000
So now, let's change the font color instead of changing the background color and let's actually use O'Reilly's red.

3100
03:38:07,000 --> 03:38:14,000
Let's go to O'Reilly's website and we'll right click on the home link to look at its color.

3101
03:38:14,000 --> 03:38:17,000
Now, I'll just double click this and copy it.

3102
03:38:17,000 --> 03:38:23,000
Back inside our custom CSS, I'm going to change background color to color and paste this new color.

3103
03:38:23,000 --> 03:38:30,000
Let's save the file, then go back to the web browser where I'll open our MB Viewer tab and refresh the page.

3104
03:38:30,000 --> 03:38:32,000
Looks like that works.

3105
03:38:32,000 --> 03:38:37,000
Now back inside the custom CSS, let's try to move the important flag.

3106
03:38:37,000 --> 03:38:42,000
Like I said earlier, it's better to not use important when you can get away with it.

3107
03:38:42,000 --> 03:38:46,000
Back in the browser, let's refresh the page and see if it still works.

3108
03:38:46,000 --> 03:38:48,000
Looks like it's no longer working.

3109
03:38:48,000 --> 03:38:55,000
We have two options. We can either stick with the important flag or we can try to make our selector more specific.

3110
03:38:55,000 --> 03:39:03,000
Because I know that I'm applying the top most level styling and nobody's going to come in and inherit from the O'Reilly page and add their own styling,

3111
03:39:03,000 --> 03:39:05,000
it's okay for me to use important.

3112
03:39:05,000 --> 03:39:11,000
If, however, you were writing something that would later be styled by somebody else, you'd want to make the selector more specific.

3113
03:39:11,000 --> 03:39:19,000
To do so, you could inspect the element and either A, add more levels of elements to your selector,

3114
03:39:19,000 --> 03:39:26,000
or B, in the templates, actually add an ID to this anchor tag and then address the anchor tag by ID.

3115
03:39:26,000 --> 03:39:32,000
Addressing an element by ID has a higher specificity than addressing it otherwise.

3116
03:39:32,000 --> 03:39:36,000
Back inside the custom CSS, let's re-add the important.

3117
03:39:36,000 --> 03:39:39,000
I'm going to refresh the browser page.

3118
03:39:39,000 --> 03:39:41,000
Looks like that's still working.

3119
03:39:41,000 --> 03:39:43,000
Let's scroll down to the bottom of the page.

3120
03:39:43,000 --> 03:39:47,000
Maybe we should use one of O'Reilly's grays for this bottom.

3121
03:39:47,000 --> 03:39:51,000
We could also use O'Reilly's red for the links.

3122
03:39:51,000 --> 03:39:53,000
This gray looks nice.

3123
03:39:53,000 --> 03:39:56,000
We'll copy the background color.

3124
03:39:56,000 --> 03:40:02,000
Now back on the Jupyter NB viewer tab, let's try styling this footer.

3125
03:40:02,000 --> 03:40:07,000
The font doesn't have enough contrast now. Let's change it to black.

3126
03:40:07,000 --> 03:40:13,000
That seems like it has too much contrast. Let's see what O'Reilly does.

3127
03:40:13,000 --> 03:40:18,000
Looks like they use an off black. We'll use that too.

3128
03:40:18,000 --> 03:40:24,000
I'd also like to add a top border.

3129
03:40:24,000 --> 03:40:28,000
Let's copy the border color that O'Reilly uses.

3130
03:40:28,000 --> 03:40:33,000
Looks like they use this off-shaded gray.

3131
03:40:33,000 --> 03:40:38,000
Now we can just copy this CSS that we've designed in the browser

3132
03:40:38,000 --> 03:40:42,000
and paste it into our custom CSS in a footer selector.

3133
03:40:42,000 --> 03:40:44,000
Now let's refresh the page.

3134
03:40:44,000 --> 03:40:48,000
Scrolling to the bottom, we see that our new styling has been applied.

3135
03:40:48,000 --> 03:40:52,000
Lastly, we need to change the default link color to that red.

3136
03:40:52,000 --> 03:40:58,000
Back on our custom CSS, let's define an anchor selector.

3137
03:40:58,000 --> 03:41:03,000
We have four C problems with this anchor tag and this anchor tag.

3138
03:41:03,000 --> 03:41:10,000
Let's define a color for when the FAQ anchor tag is not hovered on.

3139
03:41:10,000 --> 03:41:16,000
We'll use the color that we used for text.

3140
03:41:16,000 --> 03:41:22,000
I'm going to save and then go back to the browser and refresh the page one more time.

3141
03:41:22,000 --> 03:41:25,000
The FAQ button is still working. Scroll to the bottom.

3142
03:41:25,000 --> 03:41:30,000
And it looks like our links are formatted correctly now.

3143
03:41:30,000 --> 03:41:36,000
In the last video, we looked at customizing our MbViewer deployments CSS.

3144
03:41:36,000 --> 03:41:40,000
In this video, we used JavaScript to spiff up the website a little bit.

3145
03:41:40,000 --> 03:41:44,000
I found this really cool carousel on Bootstrap's website.

3146
03:41:44,000 --> 03:41:45,000
Here it is.

3147
03:41:45,000 --> 03:41:48,000
Bootstrap is a component that MbViewer already uses,

3148
03:41:48,000 --> 03:41:51,000
so we should be able to just drag and drop this code into place.

3149
03:41:51,000 --> 03:41:56,000
What I want to do is replace the notebook listing in the showcase

3150
03:41:56,000 --> 03:41:59,000
on our MbViewer with a carousel.

3151
03:41:59,000 --> 03:42:06,000
So I'm going to go back to the Bootstrap website and copy and paste the code here.

3152
03:42:06,000 --> 03:42:10,000
Inside the index template in our custom templates folder,

3153
03:42:10,000 --> 03:42:15,000
scrolling down towards the bottom, you can see where the showcase is built.

3154
03:42:15,000 --> 03:42:19,000
The JINJA templating for loop is used to iterate over each section

3155
03:42:19,000 --> 03:42:23,000
and then it's used again to iterate over each link in each section.

3156
03:42:23,000 --> 03:42:27,000
We'll use this logic to compile the different slides for our carousel.

3157
03:42:27,000 --> 03:42:32,000
For now, I'm going to insert the carousel code above this existing code

3158
03:42:32,000 --> 03:42:35,000
in between the header and the showcase,

3159
03:42:35,000 --> 03:42:38,000
pasting what we copied from Bootstrap's website.

3160
03:42:38,000 --> 03:42:41,000
I'm going to remove the indicator dots on the carousel.

3161
03:42:41,000 --> 03:42:47,000
Also, from experience, I know that we're not loading glyph icon on MbViewer by default,

3162
03:42:47,000 --> 03:42:49,000
and I don't feel like adding that dependency.

3163
03:42:49,000 --> 03:42:51,000
Instead, we're using font awesome.

3164
03:42:51,000 --> 03:43:00,000
Equivalent icons would be icon-prev and icon-next.

3165
03:43:00,000 --> 03:43:05,000
Now, what we need to do is use that JINJA code that iterates through each item

3166
03:43:05,000 --> 03:43:07,000
to construct our carousel slides.

3167
03:43:07,000 --> 03:43:10,000
It looks like each individual unit is an item.

3168
03:43:10,000 --> 03:43:12,000
The first item is active.

3169
03:43:12,000 --> 03:43:15,000
Let's go ahead and delete the ellipses.

3170
03:43:15,000 --> 03:43:20,000
Now, let's move the JINJA templating loop logic below this first item

3171
03:43:20,000 --> 03:43:25,000
to create the latter items.

3172
03:43:25,000 --> 03:43:29,000
We're going to just ignore the notion of sections,

3173
03:43:29,000 --> 03:43:35,000
so we'll group both the loops next to each other.

3174
03:43:35,000 --> 03:43:39,000
Now, let's copy the item template into the loop.

3175
03:43:39,000 --> 03:43:43,000
Then we'll copy the image source into the item's image.

3176
03:43:43,000 --> 03:43:48,000
We'll also copy the link text as the alternative text

3177
03:43:48,000 --> 03:43:50,000
and use it as the caption.

3178
03:43:50,000 --> 03:43:54,000
Then we'll take the anchor tag and put it around the caption.

3179
03:43:54,000 --> 03:43:57,000
This will make the caption clickable.

3180
03:43:57,000 --> 03:44:01,000
Now, finally, we'll remove the original code from the gallery.

3181
03:44:01,000 --> 03:44:07,000
We'll save our changes and refresh the page to see how it renders.

3182
03:44:07,000 --> 03:44:08,000
So here's the page.

3183
03:44:08,000 --> 03:44:11,000
You can see it doesn't have the gallery below anymore.

3184
03:44:11,000 --> 03:44:14,000
Now it just has this carousel that rotates through images.

3185
03:44:14,000 --> 03:44:19,000
And each image has a link that we can click to open that notebook.

3186
03:44:19,000 --> 03:44:24,000
However, you may notice the size is constantly changing.

3187
03:44:24,000 --> 03:44:27,000
It must depend on the image height.

3188
03:44:27,000 --> 03:44:29,000
Let's fix the size of the carousel.

3189
03:44:29,000 --> 03:44:31,000
We'll do so using CSS.

3190
03:44:31,000 --> 03:44:34,000
First, let's get the ID of the carousel.

3191
03:44:34,000 --> 03:44:35,000
Copy that.

3192
03:44:35,000 --> 03:44:39,000
Then in your custom CSS, add a selector for the carousel.

3193
03:44:39,000 --> 03:44:42,000
To select an ID, prefix with the hashtag.

3194
03:44:42,000 --> 03:44:48,000
Now set the height to 300 pixels and the width to 300 pixels.

3195
03:44:48,000 --> 03:44:50,000
Save.

3196
03:44:50,000 --> 03:44:53,000
And let's go back to the web browser to see how that renders.

3197
03:44:53,000 --> 03:44:55,000
We're going to refresh the page.

3198
03:44:55,000 --> 03:44:58,000
Here's what our smaller carousel looks like.

3199
03:44:58,000 --> 03:45:02,000
We should probably center it in the page and add a margin.

3200
03:45:02,000 --> 03:45:07,000
It looks kind of weird hugging the bottom so closely in the top.

3201
03:45:07,000 --> 03:45:12,000
Let's try centering it in the web browser.

3202
03:45:12,000 --> 03:45:16,000
By setting margin left and right to auto, the element will center.

3203
03:45:16,000 --> 03:45:22,000
Now let's add a top margin to give it some distance from this horizontal line.

3204
03:45:22,000 --> 03:45:24,000
40 pixels looks good.

3205
03:45:24,000 --> 03:45:27,000
Let's do the same with the bottom.

3206
03:45:27,000 --> 03:45:29,000
Now take one last look.

3207
03:45:29,000 --> 03:45:31,000
That looks good.

3208
03:45:31,000 --> 03:45:35,000
Let's copy and paste this style back to our CSS.

3209
03:45:35,000 --> 03:45:42,000
Oops, looks like I forgot to copy margin left and right auto.

3210
03:45:42,000 --> 03:45:46,000
Now we need to get rid of that placeholder for the first active item.

3211
03:45:46,000 --> 03:45:51,000
In index.html, in the carousel code, you can see that item here.

3212
03:45:51,000 --> 03:45:53,000
Go ahead and remove that.

3213
03:45:53,000 --> 03:45:57,000
What we need to do is only add active to the first class.

3214
03:45:57,000 --> 03:46:00,000
To do that, let's create a flag.

3215
03:46:00,000 --> 03:46:03,000
Once that flag is used once, we'll set it the false.

3216
03:46:03,000 --> 03:46:11,000
We can use the ginger set command to set this flag.

3217
03:46:11,000 --> 03:46:17,000
Then we'll test for that in class.

3218
03:46:17,000 --> 03:46:23,000
Lastly, let's make sure we set first the false.

3219
03:46:23,000 --> 03:46:27,000
When we set first the false here, we're actually declaring a new variable first

3220
03:46:27,000 --> 03:46:33,000
within the scope of this for loop that overrides the first declared in the outer scope.

3221
03:46:33,000 --> 03:46:37,000
This means when we get to the next for loop, first will be set to true again.

3222
03:46:37,000 --> 03:46:40,000
So we have to set first the false twice.

3223
03:46:40,000 --> 03:46:42,000
Let's refresh the page.

3224
03:46:42,000 --> 03:46:44,000
Ah, looks like that worked.

3225
03:46:44,000 --> 03:46:47,000
Awesome.

3226
03:46:47,000 --> 03:46:55,000
In the last video, we talked about adding custom CSS and custom JavaScript to your NB viewer deployment.

3227
03:46:55,000 --> 03:47:00,000
In this video, we'll talk about changing what NB viewer is hosting to the user.

3228
03:47:00,000 --> 03:47:07,000
NB viewer has a notion of providers, which are the things that dictate what NB viewer can host.

3229
03:47:07,000 --> 03:47:13,000
There are two types of providers, URI rewrites and handlers.

3230
03:47:13,000 --> 03:47:18,000
URI rewrites take textual content that's entered into the go bar of NB viewer

3231
03:47:18,000 --> 03:47:22,000
and translate it to a canonical NB viewer URL,

3232
03:47:22,000 --> 03:47:26,000
a URL that NB viewer understands and is capable of rendering.

3233
03:47:26,000 --> 03:47:32,000
Handlers are things that are designed to interpret and load from NB viewer URLs.

3234
03:47:32,000 --> 03:47:39,000
The handler is the thing that actually fetches the resources from the local or remote location.

3235
03:47:39,000 --> 03:47:49,000
For example, the GitHub handler accesses notebook content directly from GitHub using GitHub's API instead of standard HTTP.

3236
03:47:49,000 --> 03:47:53,000
Let's start by configuring NB viewer to host local files.

3237
03:47:53,000 --> 03:48:01,000
Sticking to our O'Reilly themed example, let's pretend that O'Reilly wants to host files from a network-attached storage device.

3238
03:48:01,000 --> 03:48:05,000
Let's say that that storage device is SimLink into the home directory.

3239
03:48:05,000 --> 03:48:08,000
We'll pretend that that SimLink is called network.

3240
03:48:08,000 --> 03:48:16,000
I'm going to create this folder just as an example that we can use to demonstrate this feature of NB viewer.

3241
03:48:16,000 --> 03:48:22,000
Let's pretend that in the network-attached storage drive, there's a subfolder called notebooks.

3242
03:48:22,000 --> 03:48:26,000
And then inside the notebooks folder, there are author folders.

3243
03:48:26,000 --> 03:48:31,000
For now, I'll just create an authored folder for myself.

3244
03:48:31,000 --> 03:48:35,000
I have some example notebooks that are sitting inside my home folder.

3245
03:48:35,000 --> 03:48:43,000
I'm going to copy those over to here.

3246
03:48:43,000 --> 03:48:45,000
Now let's take a look at the NB viewer source code.

3247
03:48:45,000 --> 03:48:51,000
I'm going to CD into the NB viewer repository and open Adam.

3248
03:48:51,000 --> 03:48:56,000
Inside the NB viewer subfolder, I'm going to open app.py.

3249
03:48:56,000 --> 03:49:02,000
Scrolling down to the very bottom of app.py, we see all the command line arguments that we can pass to NB viewer.

3250
03:49:02,000 --> 03:49:05,000
One of the command line arguments is local files.

3251
03:49:05,000 --> 03:49:09,000
This tells NB viewer to host files from the local file system.

3252
03:49:09,000 --> 03:49:11,000
Let's use this.

3253
03:49:11,000 --> 03:49:13,000
I've closed the NB viewer server.

3254
03:49:13,000 --> 03:49:15,000
I'll relaunch it with this new command.

3255
03:49:15,000 --> 03:49:26,000
But before I launch, remember that we need to set the correct environment variable in order for our custom templates to be loaded.

3256
03:49:26,000 --> 03:49:33,000
Now let's launch NB viewer.

3257
03:49:33,000 --> 03:49:38,000
Let's switch to the web browser to see if we can load files from the local files system.

3258
03:49:38,000 --> 03:49:41,000
I'm going to try accessing the notebook using the go bar.

3259
03:49:41,000 --> 03:49:48,000
I'll type in the subpath to the notebook from its location inside network.

3260
03:49:48,000 --> 03:49:50,000
Doing that didn't work.

3261
03:49:50,000 --> 03:49:55,000
This would make you want to jump to the conclusion that the local files setting isn't working.

3262
03:49:55,000 --> 03:49:58,000
However, this is an invalid conclusion.

3263
03:49:58,000 --> 03:50:06,000
If you pay attention to the URL, you'll see that URL for slash was prefixed to what we tried to access.

3264
03:50:06,000 --> 03:50:12,000
This is telling NB viewer to use the URL handler to load the following content.

3265
03:50:12,000 --> 03:50:21,000
Of course, notebooks for slash jd frederick four slash one dot ipynb is not a domain name and is not located within a public top level domain name.

3266
03:50:21,000 --> 03:50:26,000
So it makes sense that URL would fail to load this content.

3267
03:50:26,000 --> 03:50:31,000
Instead, what we need to do is change the URL prefix to local file.

3268
03:50:31,000 --> 03:50:33,000
And that will get the notebook to load.

3269
03:50:33,000 --> 03:50:35,000
We want to automate this though.

3270
03:50:35,000 --> 03:50:46,000
We don't want the go bar to not work and we would like the go bar to automatically translate to this canonical and be viewer local file format.

3271
03:50:46,000 --> 03:50:50,000
In the last video, we got the NB viewer local files provider working.

3272
03:50:50,000 --> 03:50:54,000
However, we weren't able to access it via the go bar.

3273
03:50:54,000 --> 03:51:02,000
In this video, we'll write a URI rewrite provider that will allow us to access local files easily from the go bar.

3274
03:51:02,000 --> 03:51:07,000
The first step is to open up Adam inside your NB viewer repository.

3275
03:51:07,000 --> 03:51:11,000
Next, open the NB viewer sub folder and inside that open providers.

3276
03:51:11,000 --> 03:51:15,000
Here, you'll see a list of the providers that are default with NB viewer.

3277
03:51:15,000 --> 03:51:21,000
The Dropbox provider has a URI rewrite, which is a good example for the rewrite that we're going to do.

3278
03:51:21,000 --> 03:51:31,000
Let's copy the handlers dot py file and create a sub folder inside the providers folder called X for X for is going to be the name of our plugin.

3279
03:51:31,000 --> 03:51:33,000
Paste the file inside there.

3280
03:51:33,000 --> 03:51:38,000
You can also copy the init file.

3281
03:51:38,000 --> 03:51:41,000
Now open the handlers dot py file that you copied.

3282
03:51:41,000 --> 03:51:44,000
Go ahead and remove the ipython header.

3283
03:51:44,000 --> 03:51:51,000
We want this URI rewrite to accept URIs of the form author forward slash notebook name.

3284
03:51:51,000 --> 03:51:56,000
We'll accept the notebook name either with or without an IPYNB extension.

3285
03:51:56,000 --> 03:51:59,000
The first step is to replace the first string in the tuple.

3286
03:51:59,000 --> 03:52:02,000
This string is the string that is used to search.

3287
03:52:02,000 --> 03:52:06,000
The second string is the string that replaces the search string.

3288
03:52:06,000 --> 03:52:15,000
Each group of the regular expression where a group is defined by parentheses can be accessed in the replacement string by using curly brackets.

3289
03:52:15,000 --> 03:52:24,000
So this zero refers to this first item here, whereas the one refers to this second group here.

3290
03:52:24,000 --> 03:52:30,000
Without explaining too much of regular expressions, I'll tell you that this matches a set of characters of variable length.

3291
03:52:30,000 --> 03:52:35,000
I'll remove this text here where this first group will match the author.

3292
03:52:35,000 --> 03:52:37,000
Add a forward slash.

3293
03:52:37,000 --> 03:52:38,000
Copy this first group.

3294
03:52:38,000 --> 03:52:41,000
This second group will match the notebook name.

3295
03:52:41,000 --> 03:52:44,000
And at the end, I'll add dot ipynb.

3296
03:52:44,000 --> 03:52:49,000
And I have to escape the dot because dot has a special meaning in regular expressions.

3297
03:52:49,000 --> 03:52:54,000
And add a question mark because we don't know if the user is going to write dot ipynb or not.

3298
03:52:54,000 --> 03:53:05,000
Now in the replacement string, I'll replace the URL with local file because local file is the canonical form of the URI accepted by the local file provider.

3299
03:53:05,000 --> 03:53:12,000
I'll also add notebooks because notebooks is the subfolder that sits inside the network folder.

3300
03:53:12,000 --> 03:53:21,000
The first value will be the author name, followed by the notebook name, and then we'll append a dot ipynb file extension.

3301
03:53:21,000 --> 03:53:27,000
Now let's save this and we'll go back to the terminal and try launching nbviewer.

3302
03:53:27,000 --> 03:53:36,000
But first make sure to set the environment variable that uses the custom templates that we created earlier.

3303
03:53:36,000 --> 03:53:38,000
Now let's try launching nbviewer.

3304
03:53:42,000 --> 03:53:52,000
To get nbviewer to use our URI rewrite, we use the double dash provider underscore rewrites.

3305
03:53:52,000 --> 03:53:58,000
The provider rewrites flag takes a full Python namespace to a rewrite provider.

3306
03:53:58,000 --> 03:54:02,000
You may be wondering why we had to edit nbviewer directly.

3307
03:54:02,000 --> 03:54:04,000
Well, we actually didn't have to.

3308
03:54:04,000 --> 03:54:09,000
We could have wrote our own Python package and then reference that Python namespace here.

3309
03:54:09,000 --> 03:54:14,000
However, writing a Python package is outside of the scope of this video series.

3310
03:54:14,000 --> 03:54:18,000
So for simplicity, we edit it nbviewer directly.

3311
03:54:18,000 --> 03:54:21,000
That allows us to piggyback on nbviewer's namespace here.

3312
03:54:21,000 --> 03:54:29,000
So to access our rewrite, we can use nbviewer.providers.exfer.

3313
03:54:29,000 --> 03:54:33,000
Lastly, we'll want to disable github and gis providers.

3314
03:54:33,000 --> 03:54:39,000
To do so, we'll set the URL provider as the only provider used by nbviewer.

3315
03:54:39,000 --> 03:54:49,000
We can do that using the double dash providers flag and setting that to nbviewer.providers.url.

3316
03:54:49,000 --> 03:54:52,000
Now that the server is launched, let's go to our web browser.

3317
03:54:52,000 --> 03:54:58,000
Let's try accessing the first notebook under my name here.

3318
03:54:58,000 --> 03:55:00,000
Looks like that worked correctly.

3319
03:55:00,000 --> 03:55:07,000
Let's go back to the homepage and try accessing it without the ipynb to make sure it still works.

3320
03:55:07,000 --> 03:55:09,000
Looks like that worked too.

3321
03:55:09,000 --> 03:55:16,000
The last thing we'll want to do is change the showcase so it shows notebooks that are actually hosted by us.

3322
03:55:16,000 --> 03:55:20,000
To understand how this is done, let's look at the source code of nbviewer.

3323
03:55:20,000 --> 03:55:25,000
Back inside Adam in the nbviewer repository, open up app.py.

3324
03:55:25,000 --> 03:55:30,000
If you scroll towards the bottom, you'll see where all the command line arguments are defined.

3325
03:55:30,000 --> 03:55:34,000
The command line argument that we're interested in is this front page argument.

3326
03:55:34,000 --> 03:55:41,000
This argument points to a JSON file which defines the content that will be used on the front page to render the showcase.

3327
03:55:41,000 --> 03:55:48,000
The default used by nbviewer sits inside the nbviewer repository under frontpage.json.

3328
03:55:48,000 --> 03:55:49,000
Let's open that.

3329
03:55:49,000 --> 03:55:52,000
Here you can see the links that we see when nbviewer runs.

3330
03:55:52,000 --> 03:55:56,000
Let's copy all the contents of this file.

3331
03:55:56,000 --> 03:56:05,000
And then in a new terminal window, let's cd into our custom nbviewer templates directory.

3332
03:56:05,000 --> 03:56:10,000
The reason why I had you open this directory is because it's where we're storing a lot of other custom things for our server.

3333
03:56:10,000 --> 03:56:15,000
We might as well store other content in here just to keep it all grouped in one place.

3334
03:56:15,000 --> 03:56:18,000
Create a new file called gallery.json.

3335
03:56:18,000 --> 03:56:25,000
Inside that file, paste the contents from the front page.json that we copied out of the nbviewer repository.

3336
03:56:25,000 --> 03:56:31,000
Now, looking at this file, we see that it has groups defined by this header attribute.

3337
03:56:31,000 --> 03:56:36,000
Since we're ignoring the notion of groups, let's get rid of all the other groups below.

3338
03:56:36,000 --> 03:56:41,000
When we set up the dummy directory, I only copied two files into my author directory.

3339
03:56:41,000 --> 03:56:43,000
So let's get rid of the third entry.

3340
03:56:43,000 --> 03:56:48,000
We'll give the first two names.

3341
03:56:48,000 --> 03:56:55,000
And then change the target to the canonical URL that points to the correct notebook.

3342
03:56:55,000 --> 03:57:00,000
The URL for the second notebook is almost the same, just the notebook file is different.

3343
03:57:00,000 --> 03:57:06,000
Now we could change the image as well, but I don't have any nice images for my test notebooks.

3344
03:57:06,000 --> 03:57:09,000
So I'm just going to leave the images as is.

3345
03:57:09,000 --> 03:57:13,000
I'm going to save this file and go back to the terminal.

3346
03:57:13,000 --> 03:57:18,000
Opening the tab of the terminal that's running nbviewer, I'm going to stop nbviewer by hitting Ctrl C.

3347
03:57:18,000 --> 03:57:29,000
I'm going to rerun the same command except this time I'll change front page to the full path of the JSON that specifies our gallery.

3348
03:57:29,000 --> 03:57:32,000
Now let's open the web browser to see if that worked.

3349
03:57:32,000 --> 03:57:36,000
Refreshing the home page, we see that my JSON was loaded.

3350
03:57:36,000 --> 03:57:41,000
Does this URL now points to the Jons notebook, even though it's still using the old screenshot?

3351
03:57:41,000 --> 03:57:45,000
Jons notebook 2 is also available, even though it's using the old screenshot.

3352
03:57:45,000 --> 03:57:48,000
Let's click on the link to see if it works.

3353
03:57:48,000 --> 03:57:50,000
Awesome, it looks like that worked.

3354
03:57:50,000 --> 03:58:03,000
If you want to find out more about nbviewer, visit the nbviewer repository at www.github.com forward slash Jupiter forward slash nbviewer.

3355
03:58:03,000 --> 03:58:06,000
In this chapter, I'm going to talk about temp nb.

3356
03:58:06,000 --> 03:58:09,000
It stands for Temporary Notebook Server.

3357
03:58:09,000 --> 03:58:15,000
Temp nb is a service that launches sandboxed ephemeral notebook servers on demand,

3358
03:58:15,000 --> 03:58:19,000
where ephemeral is defined as something lasting for a short time.

3359
03:58:19,000 --> 03:58:22,000
It's kind of like an interactive version of nbviewer.

3360
03:58:22,000 --> 03:58:29,000
Temp nb is useful for cases where you need to share notebooks that lose importance if they're not interactive.

3361
03:58:29,000 --> 03:58:34,000
Temp nb users can interact with your notebooks to see what they have to provide.

3362
03:58:34,000 --> 03:58:38,000
They can explore the data sets and write their own code inside the notebooks.

3363
03:58:38,000 --> 03:58:45,000
The changes that they make won't be persistent anywhere, so it's okay to open a Temp nb service to the public.

3364
03:58:45,000 --> 03:58:52,000
In my web browser, I'm going to navigate to Temp nb's website at www.github.com forward slash Jupiter Temp nb.

3365
03:58:52,000 --> 03:58:55,000
I'm now going to scroll down to the readme.

3366
03:58:55,000 --> 03:59:00,000
At the top of the readme, there's this very useful diagram for describing how Temp nb works.

3367
03:59:00,000 --> 03:59:03,000
Temp nb can be broken into a few pieces.

3368
03:59:03,000 --> 03:59:07,000
The user-facing piece is the configurable HTTP proxy.

3369
03:59:07,000 --> 03:59:10,000
This piece routes traffic to the correct sub-pieces.

3370
03:59:10,000 --> 03:59:16,000
The Temp nb orchestrator is what is used to launch the temporary notebook servers.

3371
03:59:16,000 --> 03:59:19,000
Docker is the technology that is used to containerize them.

3372
03:59:19,000 --> 03:59:25,000
Once a server is launched, the Temp nb orchestrator communicates to the configurable HTTP proxy,

3373
03:59:25,000 --> 03:59:31,000
telling it to route a certain subset of addresses to the correct Temp nb container.

3374
03:59:31,000 --> 03:59:35,000
Jupiter runs and maintains its own instance of Temp nb.

3375
03:59:35,000 --> 03:59:38,000
You can access it at try.jupiter.org.

3376
03:59:38,000 --> 03:59:43,000
The notebook itself is the same notebook that you're used to running on your local machine.

3377
03:59:43,000 --> 03:59:47,000
You can see that this notebook comes pre-populated with example notebook files.

3378
03:59:47,000 --> 03:59:50,000
In this video chapter, I'll show you how to do this.

3379
03:59:50,000 --> 03:59:56,000
I'll also show you how to customize your notebook server image so that it reflects your organization's needs.

3380
03:59:59,000 --> 04:00:02,000
In this video, I'll talk about installing Temp nb.

3381
04:00:02,000 --> 04:00:10,000
Temp nb, like nbViewer, can be installed either using a Docker image or in development mode from source code.

3382
04:00:11,000 --> 04:00:19,000
However, unlike nbViewer, it doesn't really make sense to install Temp nb from source code unless you're planning on developing Temp nb.

3383
04:00:19,000 --> 04:00:25,000
That's because all the common configuration that one would want to do can be done through custom Docker images,

3384
04:00:25,000 --> 04:00:30,000
the images that are launched by Temp nb as temporary servers.

3385
04:00:30,000 --> 04:00:33,000
First, let's open up the Docker quick terminal.

3386
04:00:33,000 --> 04:00:38,000
As we did in the last chapter, remember the IP address that's printed by Docker in green.

3387
04:00:38,000 --> 04:00:42,000
This is the IP address to use to access your server later.

3388
04:00:42,000 --> 04:00:46,000
The first step is to tell Docker to download Temp nb.

3389
04:00:46,000 --> 04:00:51,000
You can do that by running Docker pull Jupyter minimal.

3390
04:00:51,000 --> 04:00:56,000
Once that is finished downloading, you should have a full copy of the Jupyter minimal image.

3391
04:00:56,000 --> 04:00:59,000
Now you'll need to generate a random token.

3392
04:00:59,000 --> 04:01:04,000
This token will be used to authenticate with configurable HTTP proxy.

3393
04:01:04,000 --> 04:01:10,000
This command works on Linux and Mac operating systems to generate a random string of 30 characters.

3394
04:01:10,000 --> 04:01:14,000
However, you can use any random string you'd like for your token.

3395
04:01:14,000 --> 04:01:19,000
So on a Windows machine, you can use the equivalent command provided by that operating system.

3396
04:01:19,000 --> 04:01:21,000
Copy the random token.

3397
04:01:21,000 --> 04:01:24,000
Now we'll launch the configurable HTTP proxy.

3398
04:01:24,000 --> 04:01:27,000
To do so, I'll start with Docker run.

3399
04:01:27,000 --> 04:01:32,000
And then I'm going to tell Docker to use the network adapter of the host.

3400
04:01:32,000 --> 04:01:36,000
To do that, I'll use double dash net equals host.

3401
04:01:36,000 --> 04:01:42,000
Then I'll tell Docker to run in the background and print its ID using the dash D flag.

3402
04:01:42,000 --> 04:01:48,000
Next, I'll pass in the proxy token as an environment variable within the image.

3403
04:01:48,000 --> 04:01:53,000
To do that, I'll use the dash E flag, specify the environment variable,

3404
04:01:53,000 --> 04:01:56,000
and I'll paste the token that I generated in the last step.

3405
04:01:56,000 --> 04:01:59,000
I'll set the name of this container to proxy.

3406
04:01:59,000 --> 04:02:03,000
Then I'll specify the name of the container I want to launch.

3407
04:02:03,000 --> 04:02:07,000
And I'll specify default target.

3408
04:02:07,000 --> 04:02:13,000
Since this is the first time I've ran the command, Docker will load the image from its repository.

3409
04:02:13,000 --> 04:02:18,000
Once that is finished downloading and has launched, we'll launch the tempnb orchestrator.

3410
04:02:18,000 --> 04:02:24,000
To do so, we'll use the same type of command except we'll change the last couple pieces of it.

3411
04:02:24,000 --> 04:02:27,000
The name will change to tempnb.

3412
04:02:27,000 --> 04:02:35,000
And then we'll use the special dash V flag to tell the Docker image to bind the Docker client within itself.

3413
04:02:35,000 --> 04:02:39,000
This will allow the Docker image to spawn other Docker images.

3414
04:02:39,000 --> 04:02:42,000
Specifically, we'll bind the Docker sock.

3415
04:02:42,000 --> 04:02:45,000
And lastly, we'll specify the name of the image.

3416
04:02:45,000 --> 04:02:48,000
The orchestrator's name is tempnb.

3417
04:02:48,000 --> 04:02:53,000
Since this is the first time I've ran this command too, Docker will download the image.

3418
04:02:53,000 --> 04:02:57,000
Once that finishes, you should be able to visit your tempnb service.

3419
04:02:57,000 --> 04:03:01,000
In the web browser, navigate to the IP address you remembered from earlier.

3420
04:03:01,000 --> 04:03:07,000
At the end, append colon 8000 to visit port 8000.

3421
04:03:07,000 --> 04:03:10,000
This is the port that tempnb is listening on by default.

3422
04:03:10,000 --> 04:03:13,000
If all is well, tempnb should just work.

3423
04:03:13,000 --> 04:03:18,000
And accessing that address will spawn a notebook server for you in a Docker image.

3424
04:03:18,000 --> 04:03:22,000
In the top right hand corner, you'll see a hosted by Rackspace logo.

3425
04:03:22,000 --> 04:03:24,000
This is not actually being hosted by Rackspace.

3426
04:03:24,000 --> 04:03:26,000
This is being hosted on your machine.

3427
04:03:26,000 --> 04:03:30,000
It's just that the image that you downloaded, Jupyter 4 slash minimal,

3428
04:03:30,000 --> 04:03:35,000
is based on the same image that we use in the Jupyter deployment.

3429
04:03:35,000 --> 04:03:42,000
In this video, we'll look at how we can use custom Docker notebook images with tempnb.

3430
04:03:42,000 --> 04:03:47,000
Jupyter has a bunch of notebook images predefined in the Jupyter organization.

3431
04:03:47,000 --> 04:03:54,000
In your web browser, open up the Jupyter organization GitHub page at github.com forward slash Jupyter.

3432
04:03:54,000 --> 04:04:00,000
Once the page loads, scroll down and you'll see a repository called Docker stacks.

3433
04:04:00,000 --> 04:04:01,000
Open that.

3434
04:04:01,000 --> 04:04:05,000
This repository contains a bunch of Docker images for various tasks.

3435
04:04:05,000 --> 04:04:08,000
Let's go ahead and clone this repository.

3436
04:04:08,000 --> 04:04:12,000
To do so, copy the clone URL in the right hand column.

3437
04:04:12,000 --> 04:04:16,000
Now, in a terminal, navigate to your home directory.

3438
04:04:16,000 --> 04:04:21,000
Run, get, space, clone, and then paste the URL.

3439
04:04:21,000 --> 04:04:25,000
Once the cloning is finished, CD into that directory.

3440
04:04:25,000 --> 04:04:28,000
And let's open Adam.

3441
04:04:28,000 --> 04:04:31,000
Once Adam opens, open the minimal notebook directory.

3442
04:04:31,000 --> 04:04:37,000
This minimal notebook image is actually different than the minimal notebook image you used in the last video,

3443
04:04:37,000 --> 04:04:40,000
but the one that we used in the last video is actually deprecated.

3444
04:04:40,000 --> 04:04:42,000
And this is the modern replacement.

3445
04:04:42,000 --> 04:04:46,000
This image doesn't have a racks based logo in the top right hand corner.

3446
04:04:46,000 --> 04:04:48,000
Let's open up the Docker file.

3447
04:04:48,000 --> 04:04:51,000
This is the file that tells Docker how to build the image.

3448
04:04:51,000 --> 04:04:56,000
This from line is how Docker knows what this image inherits from.

3449
04:04:56,000 --> 04:04:59,000
The Debbie and Jesse image is used as a base.

3450
04:04:59,000 --> 04:05:04,000
You can see the list of Docker commands used to build this image.

3451
04:05:04,000 --> 04:05:10,000
At the end, we specify that the start notebook dot shell file should be executed.

3452
04:05:10,000 --> 04:05:11,000
Let's open that.

3453
04:05:11,000 --> 04:05:14,000
Here you can see how the notebook is launched.

3454
04:05:14,000 --> 04:05:19,000
The config file used for the notebook is stored under jupiter underscore notebook underscore config.

3455
04:05:19,000 --> 04:05:23,000
This is the same kind of config file that we looked at in the second chapter.

3456
04:05:23,000 --> 04:05:26,000
The files as they are in this repository are not a Docker image.

3457
04:05:26,000 --> 04:05:28,000
We have to first build them.

3458
04:05:28,000 --> 04:05:31,000
The build process is described in the make file.

3459
04:05:31,000 --> 04:05:33,000
Let's open that.

3460
04:05:33,000 --> 04:05:37,000
The help section describes how the build make file is used.

3461
04:05:37,000 --> 04:05:43,000
To build the minimal notebook, we just need to run build forward slash minimal dash notebook.

3462
04:05:43,000 --> 04:05:46,000
Let's try that within this directory.

3463
04:05:46,000 --> 04:05:49,000
First, Docker will download the base image.

3464
04:05:49,000 --> 04:05:56,000
It will take a while, but once it's done, your image will be built.

3465
04:05:56,000 --> 04:05:59,000
Now let's try using this image with Tempenby.

3466
04:05:59,000 --> 04:06:02,000
Start a Docker quick terminal.

3467
04:06:02,000 --> 04:06:06,000
Once the terminal starts, pay attention to the IP address like you did before.

3468
04:06:06,000 --> 04:06:10,000
We're going to run the same commands that we did in the video before the last video,

3469
04:06:10,000 --> 04:06:15,000
skipping the Docker pull command and changing some of the contents of the last command.

3470
04:06:15,000 --> 04:06:18,000
If you're continuing on from the last video,

3471
04:06:18,000 --> 04:06:23,000
make sure that you close all the existing Docker containers before trying to do this.

3472
04:06:23,000 --> 04:06:26,000
To do so, you can run the following command.

3473
04:06:26,000 --> 04:06:36,000
Docker space stop, dollar sign, and then in parentheses Docker space PS space dash a space dash Q.

3474
04:06:36,000 --> 04:06:41,000
I don't have any Docker containers running right now, so I get the help output.

3475
04:06:41,000 --> 04:06:47,000
After running that command, you want to run almost the same command, but replacing stop with RM.

3476
04:06:56,000 --> 04:07:08,000
The last command is almost identical, just changing from the name forward.

3477
04:07:08,000 --> 04:07:13,000
Once again, we'll tell it to connect to itself, so it's capable of launching other Docker images.

3478
04:07:13,000 --> 04:07:17,000
And here's where the command will start to change significantly from the last video,

3479
04:07:17,000 --> 04:07:20,000
in addition to the omitted name flag.

3480
04:07:20,000 --> 04:07:24,000
We'll start specifying the Python command that launches the orchestrator.

3481
04:07:24,000 --> 04:07:27,000
We'll specify the image that we just built.

3482
04:07:27,000 --> 04:07:32,000
Now the tricky part is that we'll have to tell the image how to launch the notebook server.

3483
04:07:32,000 --> 04:07:35,000
We do so using the double dash command flag.

3484
04:07:35,000 --> 04:07:39,000
We have to tell the notebook app what its base URL is.

3485
04:07:39,000 --> 04:07:45,000
The image will format the string and you can insert special variables using curly brackets.

3486
04:07:45,000 --> 04:07:48,000
Base path is one of those special variables that you can insert.

3487
04:07:48,000 --> 04:07:54,000
We'll tell it to listen to IP0.0.0.0, which will allow it to listen to anything.

3488
04:07:54,000 --> 04:07:57,000
Lastly, we'll specify the port that it's listening on.

3489
04:07:57,000 --> 04:08:03,000
Once you run that command, in your web browser, try accessing the Docker image.

3490
04:08:03,000 --> 04:08:07,000
If everything works, you should see a new notebook server.

3491
04:08:07,000 --> 04:08:12,000
This notebook server won't have a Rackspace logo in the top right-hand corner.

3492
04:08:12,000 --> 04:08:15,000
If you have troubles, most likely you mistyped something.

3493
04:08:15,000 --> 04:08:21,000
If you need to debug why it's not working, open up another Docker quick terminal.

3494
04:08:21,000 --> 04:08:26,000
When the Docker quick terminal launches, you can run docker ps-a.

3495
04:08:26,000 --> 04:08:29,000
This will list all the Docker processes that are running.

3496
04:08:29,000 --> 04:08:34,000
If you see one that says exit it with an exit code in parentheses,

3497
04:08:34,000 --> 04:08:36,000
you can look at the logs of that Docker image.

3498
04:08:36,000 --> 04:08:46,000
To do so, run docker logs and then copy the container ID, which is in the far left column, and paste it.

3499
04:08:46,000 --> 04:08:52,000
In one of the attempts I made earlier to run this long command, I misspelled orchestrate.

3500
04:08:52,000 --> 04:08:56,000
This caused the server to not run and me to receive gateway errors.

3501
04:08:56,000 --> 04:09:03,000
By looking at the logs, I could tell that that was the problem and was able to correct it quickly.

3502
04:09:03,000 --> 04:09:09,000
In the last couple of videos, we looked at launching TempNB using custom notebook image.

3503
04:09:09,000 --> 04:09:16,000
In the following videos, including this one, we'll look at creating our own custom notebook image for use with TempNB.

3504
04:09:16,000 --> 04:09:19,000
To get started, launch the Docker quick start terminal.

3505
04:09:19,000 --> 04:09:23,000
Once the terminal launches, pay attention to the IP address like you did before.

3506
04:09:23,000 --> 04:09:27,000
We'll be using that IP address to access TempNB.

3507
04:09:27,000 --> 04:09:32,000
In the last couple of videos, we used the Jupyter Docker stacks minimal notebook image.

3508
04:09:32,000 --> 04:09:36,000
We'll use that image as a base for our new custom image.

3509
04:09:36,000 --> 04:09:40,000
To do so, let's copy the image out of the repository.

3510
04:09:40,000 --> 04:09:43,000
I'll copy it into a directory called custom notebook.

3511
04:09:43,000 --> 04:09:46,000
This will be the name of the custom image that I'm going to create.

3512
04:09:46,000 --> 04:09:50,000
I'll then cd into custom notebook and I'll open Adam.

3513
04:09:50,000 --> 04:09:58,000
Once Adam opens, I'll open the config file inside custom notebook Jupyter notebook underscore config.py.

3514
04:09:58,000 --> 04:10:03,000
This is the configuration file that will be loaded by the Jupyter notebook inside the notebook image.

3515
04:10:03,000 --> 04:10:07,000
Recalling from an earlier chapter, I'm going to set the untitled notebook name.

3516
04:10:07,000 --> 04:10:13,000
This is an easy variable to set that we can use to quickly judge whether or not our config file is being loaded.

3517
04:10:13,000 --> 04:10:20,000
The variable is c.contentsManager.untitled notebook.

3518
04:10:20,000 --> 04:10:23,000
I'll set that to test. Now I'll save the file.

3519
04:10:23,000 --> 04:10:28,000
Next, I'm going to create a shell file that we'll use to build this image.

3520
04:10:28,000 --> 04:10:32,000
I'm going to copy the shebang from the start notebook file.

3521
04:10:32,000 --> 04:10:35,000
We'll call the new file build.sh.

3522
04:10:35,000 --> 04:10:38,000
I'm going to go back to my Docker quick start terminal.

3523
04:10:38,000 --> 04:10:43,000
I'm going to open Adam up inside the Docker stacks repository.

3524
04:10:43,000 --> 04:10:46,000
When Adam opens, I'm going to open the make file.

3525
04:10:46,000 --> 04:10:50,000
I'm going to scroll down to the build line so I can see how images are built.

3526
04:10:50,000 --> 04:10:52,000
I'll go ahead and copy this line.

3527
04:10:52,000 --> 04:10:57,000
I'm going to go back to the Adam that we opened up inside the custom notebook directory.

3528
04:10:57,000 --> 04:11:01,000
I'm going to paste this line inside the build.sh file.

3529
04:11:01,000 --> 04:11:07,000
I'm going to remove drgs and replace owner with JD Fredder.

3530
04:11:07,000 --> 04:11:11,000
You can use whatever you want here to identify yourself.

3531
04:11:11,000 --> 04:11:16,000
And I'm going to replace this notdir $at with the name of my notebook image.

3532
04:11:16,000 --> 04:11:21,000
I'll also get rid of the notdir $at at the end and the forward slash.

3533
04:11:21,000 --> 04:11:27,000
This tells Docker to build the contents inside the current directory.

3534
04:11:27,000 --> 04:11:31,000
Now I'm going to copy this shebang again.

3535
04:11:31,000 --> 04:11:35,000
And create a new file for testing this image with tempnb.

3536
04:11:35,000 --> 04:11:37,000
I'll call this file test.sh.

3537
04:11:37,000 --> 04:11:39,000
I'll paste the shebang.

3538
04:11:39,000 --> 04:11:44,000
And then I'll enter a command that causes all the images that are currently running in Docker to close.

3539
04:11:44,000 --> 04:11:48,000
It's important to note that this command is inside this file.

3540
04:11:48,000 --> 04:11:52,000
We don't want to run this file if there are Docker images on our system that we don't want to close.

3541
04:11:52,000 --> 04:12:00,000
The reason I'm adding this line is because it becomes tedious to constantly close Docker images each time you want to run your test.

3542
04:12:00,000 --> 04:12:10,000
To close all the images that are currently running, I'll use docker stop and dollar parentheses docker ps-a-q.

3543
04:12:10,000 --> 04:12:16,000
What this does is runs docker stop on every docker image that's currently running.

3544
04:12:16,000 --> 04:12:21,000
I'm going to copy this line, paste it below, and replace stop with rm.

3545
04:12:21,000 --> 04:12:25,000
This will do the same thing but remove the images instead of stopping them.

3546
04:12:25,000 --> 04:12:29,000
Next, I'm going to create a token for use with the HTTP config proxy.

3547
04:12:29,000 --> 04:12:42,000
I'll use export to define the variable token as head 30 characters long of dev urandom piped with xxd-p.

3548
04:12:42,000 --> 04:12:46,000
Next, I'll run the configurable HTTP proxy image.

3549
04:12:46,000 --> 04:12:49,000
To do so, I'll use docker run.

3550
04:12:49,000 --> 04:12:59,000
Double dash net equals host dash d dash e config proxy auth token equal the token variable.

3551
04:12:59,000 --> 04:13:09,000
Double dash name equals proxy image name jupiter configurable HTTP proxy space.

3552
04:13:09,000 --> 04:13:20,000
Double dash default dash target 127.0.0.1 port 9999.

3553
04:13:20,000 --> 04:13:24,000
I'm going to turn on word wrap so you can see the whole command.

3554
04:13:24,000 --> 04:13:29,000
Next, I'm going to launch the tempnb orchestrator image.

3555
04:13:29,000 --> 04:13:33,000
I'll start with the same command but deviate once I get to the name.

3556
04:13:33,000 --> 04:13:44,000
I'll use dash v bar run docker dot sock colon four slash docker dot sock to cause the image to connect to the docker client.

3557
04:13:44,000 --> 04:13:53,000
Next, I'll specify the jupiter tempnb image and the command python orchestrate dot pi.

3558
04:13:53,000 --> 04:14:04,000
I'll specify the image to jd fredder custom notebook and the command to start dash notebook dot sh.

3559
04:14:04,000 --> 04:14:06,000
This part's really important.

3560
04:14:06,000 --> 04:14:12,000
The minimal notebook image requires you to start the notebook server using start dash notebook dot sh

3561
04:14:12,000 --> 04:14:17,000
instead of running ipython space notebook or jupiter space notebook.

3562
04:14:17,000 --> 04:14:22,000
That's because if you run either of those, the notebook will be launched as root

3563
04:14:22,000 --> 04:14:27,000
and the notebook will be looking for the configuration file inside the root home directory.

3564
04:14:27,000 --> 04:14:32,000
However, the configuration file is installed into the jovian user's home directory.

3565
04:14:32,000 --> 04:14:40,000
So running start dash notebook dot sh does some special things that causes the notebook to launch the server as the jovian user.

3566
04:14:40,000 --> 04:14:43,000
I'll have to pass some commands into the start notebook shell script.

3567
04:14:43,000 --> 04:14:46,000
To do so, I'll escape quotes.

3568
04:14:46,000 --> 04:14:53,000
Inside those quotes, I'll set the base URL,

3569
04:14:53,000 --> 04:14:56,000
allow origin,

3570
04:14:56,000 --> 04:14:57,000
and the port.

3571
04:14:57,000 --> 04:15:03,000
I'll save this file and go back to the docker terminal.

3572
04:15:03,000 --> 04:15:08,000
Now I'll navigate to the custom notebook directory that I created earlier

3573
04:15:08,000 --> 04:15:11,000
and I'll try running the build dot sh file I just created.

3574
04:15:11,000 --> 04:15:15,000
If you get a permission denied, it's probably because permissions aren't set correctly on the file.

3575
04:15:15,000 --> 04:15:22,000
You can do so by running chmod plus x build dot sh.

3576
04:15:22,000 --> 04:15:24,000
Looks like the image built successfully.

3577
04:15:24,000 --> 04:15:27,000
Now let's try running the test shell file.

3578
04:15:27,000 --> 04:15:33,000
We'll have to change the permissions of that as well.

3579
04:15:33,000 --> 04:15:34,000
Looks like that worked.

3580
04:15:34,000 --> 04:15:38,000
We get these help outputs because no images were running at the time.

3581
04:15:38,000 --> 04:15:43,000
The last two outputs are the grids for the images that were launched.

3582
04:15:43,000 --> 04:15:45,000
Let's go to the web browser.

3583
04:15:45,000 --> 04:15:50,000
Try accessing the tempnb server via the ip address that docker printed.

3584
04:15:50,000 --> 04:15:52,000
Looks like the server launched successfully.

3585
04:15:52,000 --> 04:15:55,000
Now let's see if the config worked.

3586
04:15:55,000 --> 04:15:56,000
Awesome.

3587
04:15:56,000 --> 04:16:00,000
It looks like the default notebook name is no longer untitled, but is test,

3588
04:16:00,000 --> 04:16:05,000
which implies that our config is being loaded.

3589
04:16:05,000 --> 04:16:11,000
In this video, we'll add custom content to our tempnb notebook custom image.

3590
04:16:11,000 --> 04:16:17,000
This process is very similar to the process that you use for adding custom content to your nb viewer deployment.

3591
04:16:17,000 --> 04:16:23,000
That's because the notebook itself uses ginga2, like nb viewer, to do its templating.

3592
04:16:23,000 --> 04:16:26,000
First, let's start the docker quick start terminal.

3593
04:16:26,000 --> 04:16:31,000
Pay attention to the ip address that is listed, for that's the ip you'll use to access docker.

3594
04:16:31,000 --> 04:16:37,000
Let's go ahead and navigate into our custom notebook directory and open atom.

3595
04:16:37,000 --> 04:16:41,000
The first thing we'll do is create a page.html template.

3596
04:16:41,000 --> 04:16:46,000
This template will override the page.html template of the notebook.

3597
04:16:46,000 --> 04:16:52,000
Inside the page.html template, we'll extend the base template of the notebook.

3598
04:16:52,000 --> 04:16:56,000
Next, we'll override the header underscore buttons block.

3599
04:16:56,000 --> 04:17:00,000
This block exists at the top of the notebook pages.

3600
04:17:00,000 --> 04:17:02,000
We can use this to add our own logo.

3601
04:17:02,000 --> 04:17:05,000
We'll go ahead and add an O'Reilly logo here.

3602
04:17:05,000 --> 04:17:07,000
We have two options to do this.

3603
04:17:07,000 --> 04:17:12,000
We could either add the O'Reilly picture to our custom notebook image,

3604
04:17:12,000 --> 04:17:16,000
or we could host it externally and reference it here.

3605
04:17:16,000 --> 04:17:25,000
For tempnb, it's better to host your images and other static content externally to the images that are launched by the orchestrator.

3606
04:17:25,000 --> 04:17:29,000
That's because the notebook server uses tornado to host its files,

3607
04:17:29,000 --> 04:17:34,000
and tornado isn't as fast as other servers like engine x or Apache,

3608
04:17:34,000 --> 04:17:38,000
which are even slower than services like CDNs.

3609
04:17:38,000 --> 04:17:43,000
So what we'll do is open our web browser and get the link for the O'Reilly image.

3610
04:17:43,000 --> 04:17:46,000
www.oreilly.com

3611
04:17:46,000 --> 04:17:52,000
Once the page loads, right-click on the image and say copy image URL.

3612
04:17:52,000 --> 04:17:54,000
Then go back to atom.

3613
04:17:54,000 --> 04:17:57,000
Now on the header buttons block, add an image tag.

3614
04:17:57,000 --> 04:18:01,000
Set the source of that image tag to the link that you copied from O'Reilly.

3615
04:18:01,000 --> 04:18:03,000
Save the page.

3616
04:18:03,000 --> 04:18:06,000
Now we'll need to copy this template into our image.

3617
04:18:06,000 --> 04:18:08,000
To do so, open your docker file.

3618
04:18:08,000 --> 04:18:10,000
Scroll down to the bottom.

3619
04:18:10,000 --> 04:18:14,000
The first thing you'll need to do is create a directory that contains templates.

3620
04:18:14,000 --> 04:18:20,000
To do so, we're going to copy this line that creates the dot Jupyter directory inside the user directory.

3621
04:18:20,000 --> 04:18:23,000
We'll put our template directory inside that.

3622
04:18:23,000 --> 04:18:25,000
We'll call it custom.

3623
04:18:25,000 --> 04:18:28,000
We'll then need to copy the file into that directory.

3624
04:18:28,000 --> 04:18:31,000
Go ahead and copy the line that does the notebook config.

3625
04:18:31,000 --> 04:18:38,000
Change notebook config.py to page.html and update the path to custom.

3626
04:18:38,000 --> 04:18:40,000
Save the file.

3627
04:18:40,000 --> 04:18:44,000
Lastly, you'll need to go into your Jupyter notebook config.py file.

3628
04:18:44,000 --> 04:18:51,000
Inside here, below the untitled notebook line, set the extra template paths variable of the notebook app.

3629
04:18:51,000 --> 04:18:54,000
This variable accepts a list, a path.

3630
04:18:54,000 --> 04:18:57,000
Give it the path to your custom template folder.

3631
04:18:57,000 --> 04:18:59,000
And then save the file.

3632
04:18:59,000 --> 04:19:01,000
Now go back to your docker terminal.

3633
04:19:01,000 --> 04:19:05,000
And inside here, run the build script again.

3634
04:19:05,000 --> 04:19:10,000
Once the build script finishes, you can run the test script.

3635
04:19:10,000 --> 04:19:12,000
Now go back to your web browser.

3636
04:19:12,000 --> 04:19:14,000
Try accessing tempnb.

3637
04:19:14,000 --> 04:19:18,000
If all goes well, you should see the O'Reilly logo on the top of the header bar.

3638
04:19:18,000 --> 04:19:22,000
You could style this better by using css in your template page.

3639
04:19:22,000 --> 04:19:25,000
But the point here is not to make something that looks good.

3640
04:19:25,000 --> 04:19:31,000
It's just to show you how to get static content into your tempnb images.

3641
04:19:31,000 --> 04:19:36,000
In this video, I'm going to talk to you about setting limits on your tempnb service.

3642
04:19:36,000 --> 04:19:39,000
And then briefly, I'll talk about security.

3643
04:19:39,000 --> 04:19:41,000
To get started, open up a terminal.

3644
04:19:41,000 --> 04:19:45,000
Then navigate into the custom notebook directory.

3645
04:19:45,000 --> 04:19:49,000
This is the directory that contains the custom image we've created.

3646
04:19:49,000 --> 04:19:51,000
Now open Adam.

3647
04:19:51,000 --> 04:19:55,000
Once Adam opens, open the test.sh file.

3648
04:19:55,000 --> 04:20:00,000
This is the file that contains the lines that can launch this image in tempnb.

3649
04:20:00,000 --> 04:20:02,000
In a real deployment, you could use these same lines.

3650
04:20:02,000 --> 04:20:06,000
Just remove the two docker stop and docker rn lines.

3651
04:20:06,000 --> 04:20:11,000
I'm going to enable word wrap so you can see the whole commands.

3652
04:20:11,000 --> 04:20:14,000
The last command is the command that launches the orchestrator.

3653
04:20:14,000 --> 04:20:19,000
We pass in a command into the image using the double dash command flag.

3654
04:20:19,000 --> 04:20:23,000
You can tell the orchestrator what image to use using the double dash image flag.

3655
04:20:23,000 --> 04:20:26,000
There are also additional flags.

3656
04:20:26,000 --> 04:20:32,000
For example, if you need to limit the number of CPUs any particular container can use,

3657
04:20:32,000 --> 04:20:36,000
you can use the double dash CPU underscore shares flag.

3658
04:20:36,000 --> 04:20:41,000
And this accepts an integer value for how many CPUs are allowed.

3659
04:20:41,000 --> 04:20:47,000
For example, we could limit each image to using two CPUs at most by doing equals two.

3660
04:20:47,000 --> 04:20:52,000
The next useful flag for limiting is the coal period flag.

3661
04:20:52,000 --> 04:21:00,000
This flag accepts an integer in seconds that determines how often containers are examined for their age

3662
04:21:00,000 --> 04:21:02,000
and then collect it if old enough.

3663
04:21:02,000 --> 04:21:05,000
The default for this is 600 seconds.

3664
04:21:05,000 --> 04:21:07,000
This is 10 minutes.

3665
04:21:07,000 --> 04:21:11,000
We could make this faster, for example, by doing 300 seconds.

3666
04:21:11,000 --> 04:21:19,000
Cold timeout is the variable that sets how long it takes for a container to be sitting idle that it will get cold.

3667
04:21:19,000 --> 04:21:23,000
The default for this is 3600 seconds.

3668
04:21:23,000 --> 04:21:27,000
This variable is also an integer specified in seconds.

3669
04:21:27,000 --> 04:21:32,000
We can half that time by setting it to 1800 seconds.

3670
04:21:32,000 --> 04:21:40,000
We can also set a limit on the amount of memory each container is allowed to use by setting mem underscore limit.

3671
04:21:40,000 --> 04:21:46,000
This accepts a string specifying the amount of memory that each container is allowed to use.

3672
04:21:46,000 --> 04:21:51,000
It defaults to 512M for our 512 megabytes.

3673
04:21:51,000 --> 04:21:56,000
We can half this by setting it to 256M.

3674
04:21:56,000 --> 04:22:01,000
The last important flag I would like to mention is the pool size flag.

3675
04:22:01,000 --> 04:22:08,000
This flag accepts an integer which specifies how many child docker containers can be launched by the orchestrator.

3676
04:22:08,000 --> 04:22:13,000
We can think of this as a limit as how many users can use Temp Add B at any given time.

3677
04:22:13,000 --> 04:22:15,000
The default for this is 10.

3678
04:22:15,000 --> 04:22:18,000
We can limit it to half that by setting it to 5.

3679
04:22:18,000 --> 04:22:26,000
Note that these flags are all set outside of the double dash command because they're not actually getting passed into the image but to the orchestrator itself.

3680
04:22:26,000 --> 04:22:29,000
Lastly, let's talk a little bit about security.

3681
04:22:29,000 --> 04:22:33,000
Go ahead and open up your Jupyter underscore notebook underscore config.

3682
04:22:33,000 --> 04:22:40,000
You see here in this configuration file that there's a flag for HTTPS encryption and password.

3683
04:22:40,000 --> 04:22:47,000
This is the same HTTPS encryption and password that you used in the earlier chapter where you learned how to deploy the Jupyter notebook.

3684
04:22:47,000 --> 04:22:54,000
This may be useful to you but take note that this is not affecting the orchestrator itself.

3685
04:22:54,000 --> 04:23:00,000
So any random user can still access your deployment of Temp Add B and launch containers.

3686
04:23:00,000 --> 04:23:06,000
They just may not be able to take advantage of those containers if they don't have the appropriate credentials to log on to them.

3687
04:23:06,000 --> 04:23:15,000
This means that those people could still spawn up a bunch of containers and use your entire pool even if they're not authenticated.

3688
04:23:15,000 --> 04:23:22,000
This is a limitation of Temp Add B as the Temp Add B orchestrator does not yet have a password mechanism.

3689
04:23:22,000 --> 04:23:28,000
You could, however, wrap the orchestrator in your own password at Proxy.

3690
04:23:28,000 --> 04:23:32,000
In this chapter, I'll teach you about Jupyter Hub.

3691
04:23:32,000 --> 04:23:43,000
The technical definition of Jupyter Hub is that it's a multi-user server that manages in Proxy's multiple instances of the single user Jupyter notebook server.

3692
04:23:43,000 --> 04:23:50,000
A less technical definition is that Jupyter Hub is a multi-user version of the Jupyter notebook.

3693
04:23:50,000 --> 04:24:01,000
Jupyter Hub is a Python 3 only application, but that doesn't mean that the kernels that are ran by the notebook servers launched by Jupyter Hub are restricted to Python 3 only.

3694
04:24:01,000 --> 04:24:05,000
In other words, the user isn't restricted to Python 3.

3695
04:24:05,000 --> 04:24:18,000
Jupyter Hub is comprised of three main pieces, the multi-user hub, the configurable HTTP proxy, and the multiple single user notebook servers that are launched by the hub.

3696
04:24:18,000 --> 04:24:22,000
When you start Jupyter Hub, you're actually starting the hub application.

3697
04:24:22,000 --> 04:24:26,000
The hub application then spawns the configurable proxy.

3698
04:24:26,000 --> 04:24:31,000
The proxy forwards all requests on the root domain to the hub.

3699
04:24:31,000 --> 04:24:34,000
The proxy is what's exposed to the internet.

3700
04:24:34,000 --> 04:24:42,000
The hub then authenticates the user when the user connects, and the hub will launch a single user notebook server for that user.

3701
04:24:42,000 --> 04:24:52,000
It then configures the proxy to route all requests on the root domain forward slash the username to that new single user notebook server that it launched.

3702
04:24:52,000 --> 04:24:55,000
Jupyter Hub is highly configurable.

3703
04:24:55,000 --> 04:24:57,000
The authentication is configurable.

3704
04:24:57,000 --> 04:25:07,000
We're going to look specifically at the O authenticator extension, which allows you to use GitHub authentication with Jupyter Hub, but you could write your own authenticator.

3705
04:25:07,000 --> 04:25:13,000
This is useful if your organization uses a specialized authentication scheme.

3706
04:25:13,000 --> 04:25:15,000
Second, you can configure the spawning.

3707
04:25:15,000 --> 04:25:19,000
In other words, you can configure how single user notebook servers are launched.

3708
04:25:19,000 --> 04:25:28,000
We're going to look specifically at the Docker spawner, which is a tool that allows Jupyter Hub to spawn the single user notebook servers using Docker.

3709
04:25:28,000 --> 04:25:32,000
And lastly, you can configure the spawn notebook itself.

3710
04:25:32,000 --> 04:25:36,000
By default, Jupyter Hub launches the notebook that's installed on the local machine.

3711
04:25:36,000 --> 04:25:49,000
If you're using something like the Docker spawner, you can customize the notebook by using the techniques described in the last chapter where we created a custom Jupyter notebook Docker image.

3712
04:25:49,000 --> 04:25:54,000
In the following videos, we'll look at three ways to install Jupyter Hub.

3713
04:25:54,000 --> 04:25:59,000
The first is a completely vanilla installed directly from package managers.

3714
04:25:59,000 --> 04:26:03,000
The second is a vanilla install with the Docker launcher extension.

3715
04:26:03,000 --> 04:26:18,000
And the last is a more complex install that uses a combination of the Docker launcher extension and Docker swarm to handle more users to redistribute the demand across multiple machines in order to handle a higher user load.

3716
04:26:18,000 --> 04:26:27,000
First, let's remove the dot Jupyter folder that we created in the earlier chapter where we examined installing the vanilla notebook.

3717
04:26:27,000 --> 04:26:32,000
We need to do this because Jupyter Hub relies on the local notebook install.

3718
04:26:32,000 --> 04:26:37,000
We don't want to dirty our new Jupyter Hub install with the config options that we set earlier.

3719
04:26:37,000 --> 04:26:52,000
On the other hand, later you'll find configuration of Jupyter Hub to be easy because configuring the notebook servers that get launched by Jupyter Hub is the exact same procedure that we examined earlier using traitlets in the config machinery to config the vanilla notebook.

3720
04:26:52,000 --> 04:26:58,000
All the configuration that you have for the vanilla notebook will apply to the vanilla notebook that's launched by Jupyter Hub.

3721
04:26:58,000 --> 04:27:01,000
You'll want to verify that you have Python 3 on your machine.

3722
04:27:01,000 --> 04:27:05,000
You can do so by running Python double-dash version.

3723
04:27:05,000 --> 04:27:10,000
If your system does not print Python 3, try Python 3 double-dash version.

3724
04:27:10,000 --> 04:27:23,000
If that too does not work or does not print version 3, then you'll want to revisit chapter 1 video 3 where we talk about prerequisites and you'll want to make sure that you have Python 3 installed on your machine.

3725
04:27:23,000 --> 04:27:26,000
Next, let's look at the version of Node that we have installed.

3726
04:27:26,000 --> 04:27:30,000
You can do so by running npm-v.

3727
04:27:30,000 --> 04:27:33,000
I have version 3.4.1 installed on my machine.

3728
04:27:33,000 --> 04:27:41,000
If your version is lesser than that, you can update it by running sudo npm install-g npm.

3729
04:27:41,000 --> 04:27:49,000
What this will do is cause npm to uninstall itself and then install the latest version of itself in its place.

3730
04:27:49,000 --> 04:27:54,000
If this command fails partway through, you'll find that you need to reinstall Node and npm.

3731
04:27:54,000 --> 04:27:58,000
The first thing we'll install is the configurable HTTP proxy.

3732
04:27:58,000 --> 04:28:03,000
You'll recognize that name from the earlier chapter where we looked at deploying tempnb.

3733
04:28:03,000 --> 04:28:08,000
However, in that chapter, we used a configurable HTTP proxy docker image.

3734
04:28:08,000 --> 04:28:13,000
So we didn't actually install the configurable HTTP proxy on the local machine.

3735
04:28:13,000 --> 04:28:17,000
Because we're installing Jupyter Hub on the local machine, we'll need to do that here.

3736
04:28:17,000 --> 04:28:30,000
Go ahead and run sudo npm install-g where this dash-g flag installs the software globally configurable HTTP proxy.

3737
04:28:30,000 --> 04:28:33,000
Once that is finished, you'll want to install Jupyter Hub.

3738
04:28:33,000 --> 04:28:38,000
You can do so by running pip3 install Jupyter Hub.

3739
04:28:38,000 --> 04:28:42,000
By running pip3, we force the python3 pip to be used.

3740
04:28:42,000 --> 04:28:47,000
If you receive a permission denied error, go ahead and prepend the command with sudo.

3741
04:28:47,000 --> 04:28:50,000
Now you can try launching Jupyter Hub.

3742
04:28:50,000 --> 04:29:01,000
If you have an error like this, go ahead and uninstall Jupyter Hub and then reinstall it.

3743
04:29:01,000 --> 04:29:05,000
When you first run the hub, you may get an error that there's a bad configuration file.

3744
04:29:05,000 --> 04:29:09,000
You can fix this by running the command that is recommended.

3745
04:29:09,000 --> 04:29:13,000
This command will generate a configuration file for you.

3746
04:29:13,000 --> 04:29:16,000
Say yes when asked if you want to override the file.

3747
04:29:16,000 --> 04:29:19,000
Now try launching the hub.

3748
04:29:19,000 --> 04:29:25,000
If everything is successful, you should get a message saying that the hub is now running at localhost 8000.

3749
04:29:25,000 --> 04:29:29,000
In your web browser, try accessing that.

3750
04:29:29,000 --> 04:29:31,000
Awesome, looks like that worked.

3751
04:29:31,000 --> 04:29:37,000
Now you should be able to log on using your local system credentials.

3752
04:29:37,000 --> 04:29:41,000
Now that Jupyter Hub is installed, let's see how it works.

3753
04:29:41,000 --> 04:29:44,000
You can launch Jupyter Hub by running Jupyter Hub.

3754
04:29:44,000 --> 04:29:48,000
When Jupyter Hub launches, you'll notice a couple warnings.

3755
04:29:48,000 --> 04:29:54,000
The first warning is that the config proxy auth token had to be generated by Jupyter Hub.

3756
04:29:54,000 --> 04:29:57,000
You can bypass this warning by setting that variable explicitly.

3757
04:29:57,000 --> 04:30:04,000
In the future, when you decide to use extensions with Jupyter Hub, such as NBGrader, you'll need to set this token.

3758
04:30:04,000 --> 04:30:10,000
This token is how applications can communicate with the configurable HTTP proxy.

3759
04:30:10,000 --> 04:30:19,000
NBGrader, for example, adds a handle to the configurable HTTP proxy that allows graders to access notebooks with a special interface.

3760
04:30:19,000 --> 04:30:25,000
The second warning you'll see is that no admin users are defined, so the admin interface will not be accessible.

3761
04:30:25,000 --> 04:30:27,000
We'll go ahead and ignore that for now.

3762
04:30:27,000 --> 04:30:29,000
Switch to your web browser.

3763
04:30:29,000 --> 04:30:31,000
We'll access the address listed here.

3764
04:30:31,000 --> 04:30:34,000
It should be available at localhost8000.

3765
04:30:34,000 --> 04:30:38,000
When you access that address, you'll be presented with a login screen.

3766
04:30:38,000 --> 04:30:42,000
Jupyter Hub uses PAM as a default authentication method.

3767
04:30:42,000 --> 04:30:47,000
This means that to access Jupyter Hub, you use credentials on the host machine.

3768
04:30:47,000 --> 04:30:51,000
In other words, you use your current account name if you're running it locally.

3769
04:30:51,000 --> 04:30:56,000
The password is the same password for the account on the host operating system.

3770
04:30:56,000 --> 04:31:00,000
When you sign in, you'll be presented with your own notebook server.

3771
04:31:00,000 --> 04:31:05,000
In the top right-hand corner, you'll see a button for a control panel and a button to log out.

3772
04:31:05,000 --> 04:31:07,000
Go ahead and click on control panel.

3773
04:31:07,000 --> 04:31:12,000
In the control panel, you'll see an option to stop your server or access your server.

3774
04:31:12,000 --> 04:31:14,000
Go ahead and stop your server.

3775
04:31:14,000 --> 04:31:17,000
You'll also see an option to administrate Jupyter Hub.

3776
04:31:17,000 --> 04:31:18,000
Click on that.

3777
04:31:18,000 --> 04:31:24,000
Here, you'll see a screen that allows you to define new users and remove users.

3778
04:31:24,000 --> 04:31:27,000
Here, I'm going to remove JD Fredder.

3779
04:31:27,000 --> 04:31:33,000
You can also change users from admin to normal users.

3780
04:31:33,000 --> 04:31:37,000
Go ahead and log out.

3781
04:31:37,000 --> 04:31:42,000
In this video, I'll show you how to install the Jupyter Hub Docker Launcher extension.

3782
04:31:42,000 --> 04:31:45,000
Jupyter Hub is a highly configurable application.

3783
04:31:45,000 --> 04:31:50,000
Even the way that Jupyter Hub launches single-user notebook servers is configurable.

3784
04:31:50,000 --> 04:31:57,000
The Docker Launcher extension allows you to force Jupyter Hub to launch the single-user notebook servers as Docker images.

3785
04:31:57,000 --> 04:32:03,000
With this extension, you can launch any custom Docker image that you have that contains a Jupyter notebook server.

3786
04:32:03,000 --> 04:32:08,000
If you want Jupyter Hub to launch the single-user notebook servers using something other than Docker,

3787
04:32:08,000 --> 04:32:10,000
you can write your own extension to do so.

3788
04:32:10,000 --> 04:32:13,000
To get started, open up a Docker Quick Term.

3789
04:32:13,000 --> 04:32:17,000
Once the Docker Quick Terminal launches, pay attention to the IP address.

3790
04:32:17,000 --> 04:32:20,000
You'll need that IP address for later during configuration.

3791
04:32:20,000 --> 04:32:24,000
Before we get started, we should close all existing Docker images,

3792
04:32:24,000 --> 04:32:28,000
just to make sure that none are running that will conflict with what we're trying to do.

3793
04:32:28,000 --> 04:32:37,000
To do so, you can run Docker, stop, and then dollar parentheses, Docker PS-A-Q,

3794
04:32:37,000 --> 04:32:46,000
semicolon, Docker RM, dollar parentheses, Docker PS-A-Q.

3795
04:32:46,000 --> 04:32:51,000
Now, you can get the Docker Spawner extension source code by cloning it from GitHub.

3796
04:32:51,000 --> 04:33:01,000
To do so, run git clone, HTTPS, github.com, Jupyter Docker Spawner.git.

3797
04:33:01,000 --> 04:33:05,000
You want to run this inside the directory that you want to install the source code to.

3798
04:33:05,000 --> 04:33:08,000
I'm doing it inside my home directory.

3799
04:33:08,000 --> 04:33:11,000
Now, CD into that repository.

3800
04:33:11,000 --> 04:33:17,000
Run pip3 install-r requirements.txt.

3801
04:33:17,000 --> 04:33:20,000
This will install the requirements of the Docker Spawner.

3802
04:33:20,000 --> 04:33:24,000
Don't forget to add a sudo in front if your permissions require it.

3803
04:33:24,000 --> 04:33:31,000
Next, run python3 setup.py install.

3804
04:33:31,000 --> 04:33:37,000
Lastly, run sudo pip3 install-e.

3805
04:33:37,000 --> 04:33:43,000
Now, we'll need to change our Jupyter Hub config file so it launches using the Docker Spawner.

3806
04:33:43,000 --> 04:33:49,000
CD back out into your home directory or whatever directory that you launched Jupyter Hub from.

3807
04:33:49,000 --> 04:33:51,000
I launched Jupyter Hub from my home directory.

3808
04:33:51,000 --> 04:33:57,000
Once there, open up Jupyter Hub underscore config.py file in your text editor.

3809
04:33:57,000 --> 04:34:00,000
I'm going to open it in Adam.

3810
04:34:00,000 --> 04:34:11,000
Below the first line, add c.jupyterhub.spawner underscore class equals dockerspawner.dockerspawner.

3811
04:34:11,000 --> 04:34:13,000
Pay attention to the capitalization.

3812
04:34:13,000 --> 04:34:17,000
This tells Jupyter Hub to use the Docker Spawner.

3813
04:34:17,000 --> 04:34:29,000
Next, add c.dockerspawner.use underscore docker underscore client underscore env equal to true.

3814
04:34:29,000 --> 04:34:33,000
This allows the Docker Spawner to work with the Docker Quick Terminal.

3815
04:34:33,000 --> 04:34:42,000
Next, add c.dockerspawner.tls assert underscore hostname equal to false.

3816
04:34:42,000 --> 04:34:48,000
This is also required to use the Docker Quick Term in your custom image with Docker Spawner.

3817
04:34:48,000 --> 04:34:57,000
Next, add c.dockerspawner.container underscore image equal the name of your custom image.

3818
04:34:57,000 --> 04:35:01,000
I'm going to use the image that I created earlier in the tempnb chapter.

3819
04:35:01,000 --> 04:35:03,000
Use your custom image here too.

3820
04:35:03,000 --> 04:35:07,000
Now go ahead and save the file.

3821
04:35:07,000 --> 04:35:11,000
Now cd into your custom notebook image directory.

3822
04:35:11,000 --> 04:35:15,000
This is the same directory from the chapter where we investigate at tempnb.

3823
04:35:15,000 --> 04:35:17,000
Open Adam.

3824
04:35:17,000 --> 04:35:20,000
Open up your Jupyter underscore notebook config file.

3825
04:35:20,000 --> 04:35:34,000
Inside here, add c.notebookapp.baseurl equals os.environ.jpy underscore base underscore url.

3826
04:35:34,000 --> 04:35:39,000
This configures the notebook server to listen to the URL that's a subset of Jupyter Hub.

3827
04:35:39,000 --> 04:35:42,000
Go ahead and click save and then close Adam.

3828
04:35:42,000 --> 04:35:45,000
Now you should be able to launch Jupyter Hub.

3829
04:35:45,000 --> 04:35:48,000
Navigate back to the directory that you launched Jupyter Hub from.

3830
04:35:48,000 --> 04:35:50,000
Mine is the home directory.

3831
04:35:50,000 --> 04:36:02,000
Type Jupyter Hub double dash Docker Spawner.container underscore ip equals 192.168.99.100.

3832
04:36:02,000 --> 04:36:08,000
Replace this IP address with the IP address that was listed by Docker when you launched the Quick Term.

3833
04:36:08,000 --> 04:36:10,000
Click return.

3834
04:36:10,000 --> 04:36:12,000
Once the server launches, go to your web browser.

3835
04:36:12,000 --> 04:36:14,000
You should be prompted with a login.

3836
04:36:14,000 --> 04:36:17,000
Login using your local credentials.

3837
04:36:17,000 --> 04:36:21,000
Once you log in, you should see your custom notebook image running.

3838
04:36:21,000 --> 04:36:25,000
This means that everything we did worked.

3839
04:36:25,000 --> 04:36:30,000
In the last video, we set up Jupyter Hub with the Docker Spawner extension.

3840
04:36:30,000 --> 04:36:34,000
This made Jupyter Hub spawn notebook servers inside Docker images.

3841
04:36:34,000 --> 04:36:39,000
In this video, we'll take it a step further and customize how Jupyter Hub does authentication.

3842
04:36:39,000 --> 04:36:46,000
Jupyter Hub has a notion of authenticators, which allow you to change how users authenticate with Jupyter Hub.

3843
04:36:46,000 --> 04:36:52,000
You can use authentication methods ranging from traditional, used in academia and in the industry,

3844
04:36:52,000 --> 04:36:58,000
to more specialized methods, like using social networking or social media authentication.

3845
04:36:58,000 --> 04:37:02,000
In this video, we'll look at using GitHub's authentication system.

3846
04:37:02,000 --> 04:37:08,000
There's an extension called the O authenticator, which was written for Jupyter Hub to allow us to do this.

3847
04:37:08,000 --> 04:37:10,000
First, open up a Docker Quick Terminal.

3848
04:37:10,000 --> 04:37:15,000
Once the Quick Terminal launches, make sure to close all images that are already running on the machine.

3849
04:37:15,000 --> 04:37:25,000
Include it in the Docker Spawner extension repository is an example of how they use the Docker Spawner with the O authenticator.

3850
04:37:25,000 --> 04:37:27,000
We'll use that as a starting point.

3851
04:37:27,000 --> 04:37:31,000
First, you want to copy your Jupyter Hub config into that directory.

3852
04:37:31,000 --> 04:37:36,000
My Jupyter Hub config is located in my home directory because that's where I launched Jupyter Hub.

3853
04:37:36,000 --> 04:37:41,000
So I'm going to copy that from my home directory into that repository example folder.

3854
04:37:41,000 --> 04:37:44,000
Next, cd into that directory.

3855
04:37:44,000 --> 04:37:50,000
Now run sudo pip3 install get plus HTTPS

3856
04:37:50,000 --> 04:37:58,000
forward slash forward slash github.com forward slash Jupyter forward slash O authenticator dot get.

3857
04:37:58,000 --> 04:38:02,000
When that finishes, you want to create a user list file.

3858
04:38:02,000 --> 04:38:04,000
Let's open up Adam inside this directory.

3859
04:38:04,000 --> 04:38:09,000
Once Adam opens, go ahead and right click and create a user list file.

3860
04:38:09,000 --> 04:38:14,000
Inside the user list, add GitHub user names that you want to have access to your server.

3861
04:38:14,000 --> 04:38:16,000
Don't forget to add your own.

3862
04:38:16,000 --> 04:38:19,000
I'm going to add Brian and Kyle, my colleagues.

3863
04:38:19,000 --> 04:38:24,000
Make yourself an admin by adding a space and admin after your account name.

3864
04:38:24,000 --> 04:38:30,000
Save the file and go ahead and close Adam for now.

3865
04:38:30,000 --> 04:38:39,000
In your web browser, go to github.com forward slash settings forward slash applications forward slash new.

3866
04:38:39,000 --> 04:38:42,000
When that page loads, give your application a name.

3867
04:38:42,000 --> 04:38:44,000
I'm going to call mine Jupyter Hub.

3868
04:38:44,000 --> 04:38:49,000
This is the name that users will see when authenticating while connecting to your Jupyter Hub instance.

3869
04:38:49,000 --> 04:38:53,000
Set the homepage URL to the Jupyter Hub URL.

3870
04:38:53,000 --> 04:38:57,000
This should be for now local host 8000.

3871
04:38:57,000 --> 04:38:59,000
Go ahead and copy that URL.

3872
04:38:59,000 --> 04:39:03,000
Paste it below where it says authorization callback URL.

3873
04:39:03,000 --> 04:39:08,000
Then append hub forward slash OAuth underscore callback.

3874
04:39:08,000 --> 04:39:10,000
Now click register application.

3875
04:39:10,000 --> 04:39:12,000
Go back to your desktop.

3876
04:39:12,000 --> 04:39:15,000
Launch a Docker quick start terminal.

3877
04:39:15,000 --> 04:39:19,000
Once the quick start terminal launches, pay attention to the IP address that's listed.

3878
04:39:19,000 --> 04:39:20,000
You'll need this later.

3879
04:39:20,000 --> 04:39:23,000
Now let's CD into the Docker Spanner directory.

3880
04:39:23,000 --> 04:39:27,000
Inside that, CD into the OAuth examples directory.

3881
04:39:27,000 --> 04:39:29,000
Now open Adam.

3882
04:39:29,000 --> 04:39:34,000
Once Adam opens in that directory, open the Jupyter Hub config file.

3883
04:39:34,000 --> 04:39:38,000
Below the container image line, you're going to need to add a new line.

3884
04:39:38,000 --> 04:39:49,000
Add C dot Jupyter Hub dot authenticator underscore class equal to in quotes OAuth.github OAuth.

3885
04:39:50,000 --> 04:39:59,000
Now below that line, add C dot GitHub OAuth authenticator dot OAuth underscore callback underscore URL

3886
04:39:59,000 --> 04:40:05,000
equal to the URL that you provided for the authentication callback while creating the application on github.com.

3887
04:40:05,000 --> 04:40:09,000
I'm going to go back to my web browser to show you what that URL is.

3888
04:40:09,000 --> 04:40:11,000
At the bottom of the page, you'll see it.

3889
04:40:11,000 --> 04:40:14,000
Go ahead and copy that.

3890
04:40:14,000 --> 04:40:21,000
Now below that line, add C dot GitHub OAuth authenticator dot client underscore ID

3891
04:40:21,000 --> 04:40:25,000
equal to the client ID provided to you by github.

3892
04:40:25,000 --> 04:40:29,000
It's located at the top of the page.

3893
04:40:29,000 --> 04:40:35,000
Now below that line, add C dot GitHub OAuth authenticator dot client underscore secret

3894
04:40:35,000 --> 04:40:41,000
equal to the secret provided to you by github.

3895
04:40:41,000 --> 04:40:46,000
Lastly, on the line below that, you'll need to set yourself as an administrator.

3896
04:40:46,000 --> 04:40:54,000
To do so, set C dot authenticator dot admin underscore users equal to

3897
04:40:54,000 --> 04:40:58,000
and then in square brackets and quotes your account name.

3898
04:40:58,000 --> 04:41:00,000
This is your GitHub account name.

3899
04:41:00,000 --> 04:41:02,000
Now save the file.

3900
04:41:02,000 --> 04:41:10,000
Back in the terminal run dash run dot sh double dash Docker spawner dot container IP

3901
04:41:10,000 --> 04:41:14,000
equal to the IP address listed in green.

3902
04:41:14,000 --> 04:41:18,000
Now in your web browser, navigate to the Jupyter Hub instance.

3903
04:41:18,000 --> 04:41:21,000
It should be at local host colon 8000.

3904
04:41:21,000 --> 04:41:25,000
Once you arrive on that page, click the sign in with GitHub button.

3905
04:41:25,000 --> 04:41:27,000
You should be asked to authorize the application.

3906
04:41:27,000 --> 04:41:29,000
Click authorize.

3907
04:41:29,000 --> 04:41:32,000
You'll then be redirected back to your Jupyter Hub instance.

3908
04:41:32,000 --> 04:41:37,000
You can click my server to access your server or admin to administrate Jupyter Hub.

3909
04:41:37,000 --> 04:41:39,000
I'm going to click on my server.

3910
04:41:39,000 --> 04:41:44,000
Note that our custom image is still being loaded.

3911
04:41:44,000 --> 04:41:49,000
In the previous videos, we were able to get Jupyter Hub working with GitHub OAuth

3912
04:41:49,000 --> 04:41:52,000
and a custom Docker image.

3913
04:41:52,000 --> 04:41:58,000
In this video, we'll look at how we can enable our users to share files across their different accounts

3914
04:41:58,000 --> 04:42:00,000
inside the Jupyter Hub instance.

3915
04:42:00,000 --> 04:42:05,000
To do so, we'll mount a shared directory on the host operating system.

3916
04:42:05,000 --> 04:42:07,000
We'll do this two ways.

3917
04:42:07,000 --> 04:42:12,000
One, we'll mount it as read only for content that all users should be able to see,

3918
04:42:12,000 --> 04:42:14,000
but not necessarily edit.

3919
04:42:14,000 --> 04:42:18,000
Two, we'll mount it as read write so users can have a shared directory

3920
04:42:18,000 --> 04:42:21,000
from which they can save files and fetch files.

3921
04:42:21,000 --> 04:42:24,000
To get started, open up a Docker quick terminal.

3922
04:42:24,000 --> 04:42:31,000
Once your Docker quick terminal launches, go ahead and make sure no Docker images are currently running.

3923
04:42:31,000 --> 04:42:35,000
Inside my home directory, I'm going to create two shared folders.

3924
04:42:35,000 --> 04:42:40,000
One will be called shared underscore RW for shared read write,

3925
04:42:40,000 --> 04:42:44,000
and the other shared underscore R for read only shared.

3926
04:42:44,000 --> 04:42:47,000
You can use any directory that's accessible on your file system.

3927
04:42:47,000 --> 04:42:50,000
I'm using my home directory as a convenience.

3928
04:42:50,000 --> 04:42:54,000
Now, I'm going to copy two example notebooks into each of those folders.

3929
04:42:54,000 --> 04:43:00,000
I'm going to CD into the shared read write folder and launch a normal Jupyter notebook server.

3930
04:43:00,000 --> 04:43:05,000
When the notebook server launches, I'm going to go ahead and create a new Python notebook.

3931
04:43:05,000 --> 04:43:08,000
First, I'm going to change the name of this notebook.

3932
04:43:08,000 --> 04:43:11,000
I'll change it to test one.

3933
04:43:11,000 --> 04:43:13,000
Now, I'll give the notebook some content.

3934
04:43:13,000 --> 04:43:16,000
I'll make the first cell a markdown cell.

3935
04:43:16,000 --> 04:43:19,000
In the second cell, I'll add some code.

3936
04:43:19,000 --> 04:43:21,000
Now, I'm going to save this notebook.

3937
04:43:21,000 --> 04:43:24,000
Now, close the web browser and go back to the terminal.

3938
04:43:24,000 --> 04:43:28,000
In the terminal, I'll hit Ctrl C twice to close the server.

3939
04:43:28,000 --> 04:43:31,000
Now, I'll CD into the read only directory.

3940
04:43:31,000 --> 04:43:36,000
I'll launch the notebook server here too.

3941
04:43:36,000 --> 04:43:43,000
Once the notebook server launches, I'm going to create a new notebook.

3942
04:43:43,000 --> 04:43:46,000
I'll call this notebook test two.

3943
04:43:47,000 --> 04:43:52,000
I'll make the first cell a markdown cell.

3944
04:43:52,000 --> 04:43:55,000
In the second cell, I'll add some code.

3945
04:43:55,000 --> 04:43:58,000
Now, I'll save the file and close the web browser.

3946
04:43:58,000 --> 04:44:03,000
Next, I'll close the Jupyter notebook server by hitting Ctrl C twice.

3947
04:44:03,000 --> 04:44:07,000
Now, CD into the Docker spawner directory.

3948
04:44:07,000 --> 04:44:13,000
Inside there, I'll CD into the example's OAuth directory and open Adam.

3949
04:44:13,000 --> 04:44:18,000
Once Adam opens, I'll make sure my Jupyter Hub underscore config file is opened.

3950
04:44:18,000 --> 04:44:27,000
Then, below the admin users line, I'll add c.dockersponer.volumes equals a mapping of volumes.

3951
04:44:27,000 --> 04:44:32,000
The volume mapping is path on the local machine as the key

3952
04:44:32,000 --> 04:44:37,000
and as the value path that it should be mounted inside the Docker image.

3953
04:44:37,000 --> 04:44:40,000
I'll mount the read-write directory.

3954
04:44:40,000 --> 04:44:47,000
I'll have it mounted to home jovian for slash work for slash shared.

3955
04:44:47,000 --> 04:44:54,000
That's because home jovian work is the directory that's loaded by default inside the Docker image.

3956
04:44:54,000 --> 04:44:58,000
To mount read-only directories, the syntax is almost the same.

3957
04:44:58,000 --> 04:45:02,000
Go ahead and copy that line and paste a copy of it below.

3958
04:45:02,000 --> 04:45:05,000
On this line, we'll change the name of the path that's mounted.

3959
04:45:05,000 --> 04:45:07,000
Let's change it to read-only.

3960
04:45:07,000 --> 04:45:12,000
Likewise, we'll change the path on the parent system to the read-only directory.

3961
04:45:12,000 --> 04:45:21,000
The important part is that the key is not docersponer.volumes, it's actually dot read underscore only underscore volumes.

3962
04:45:21,000 --> 04:45:24,000
Once you make that change, go ahead and save the file.

3963
04:45:24,000 --> 04:45:27,000
Go back to the terminal.

3964
04:45:27,000 --> 04:45:30,000
Now, launch the server like you did before.

3965
04:45:30,000 --> 04:45:34,000
Don't forget to set the Docker spawner container IP trait.

3966
04:45:34,000 --> 04:45:40,000
The IP address is the IP listed by the Docker quick terminal in green when you launched it.

3967
04:45:40,000 --> 04:45:43,000
Once your server is launched, go back to your web browser.

3968
04:45:43,000 --> 04:45:47,000
In your web browser, navigate to your Jupyter Hub instance.

3969
04:45:47,000 --> 04:45:52,000
You may still be logged on to your other session from the earlier videos. That's okay.

3970
04:45:52,000 --> 04:45:54,000
Go ahead and click on my server.

3971
04:45:54,000 --> 04:46:00,000
When my server loads, you should see two folders, read-only and shared.

3972
04:46:00,000 --> 04:46:02,000
Go ahead and open shared.

3973
04:46:02,000 --> 04:46:05,000
Inside shared, you should see the test one notebook.

3974
04:46:05,000 --> 04:46:07,000
Go ahead and open that.

3975
04:46:07,000 --> 04:46:09,000
Make a change to this notebook.

3976
04:46:09,000 --> 04:46:13,000
It doesn't matter what change, just a change that you can see.

3977
04:46:13,000 --> 04:46:15,000
Then go ahead and try saving the notebook.

3978
04:46:15,000 --> 04:46:20,000
When you save, you should have seen the checkpoint flash up to the left of the kernel name.

3979
04:46:20,000 --> 04:46:22,000
Go ahead and close the notebook.

3980
04:46:22,000 --> 04:46:24,000
And try reopening it.

3981
04:46:24,000 --> 04:46:26,000
Looks like that worked.

3982
04:46:26,000 --> 04:46:28,000
Go ahead and close the notebook.

3983
04:46:28,000 --> 04:46:30,000
Go back to your home directory.

3984
04:46:30,000 --> 04:46:33,000
Then go inside the read-only directory.

3985
04:46:33,000 --> 04:46:36,000
Open up the test to that notebook.

3986
04:46:36,000 --> 04:46:43,000
When you open this notebook, you should see a notification that flashes quickly to the left of the kernel that says auto-save disabled.

3987
04:46:43,000 --> 04:46:50,000
You should also see an icon of a floppy with a red circle above it indicating that saving is disabled.

3988
04:46:50,000 --> 04:46:52,000
Try making changes to this file.

3989
04:46:52,000 --> 04:46:54,000
Any changes, it doesn't matter.

3990
04:46:54,000 --> 04:46:56,000
I'm going to remove this read-only.

3991
04:46:56,000 --> 04:46:58,000
Now I'm going to try saving.

3992
04:46:58,000 --> 04:47:03,000
When I save, I should see another notification in yellow that says the notebook is read-only.

3993
04:47:03,000 --> 04:47:06,000
Go ahead and close the notebook.

3994
04:47:06,000 --> 04:47:08,000
Reopen the notebook.

3995
04:47:08,000 --> 04:47:11,000
And you should notice your changes weren't saved.

3996
04:47:11,000 --> 04:47:16,000
This means that the read-only is working correctly.

3997
04:47:16,000 --> 04:47:23,000
In this video, we'll talk about how you can increase the performance of your Jupyter Hub deployment using EngineX.

3998
04:47:24,000 --> 04:47:29,000
EngineX will be used to host the static files of the Jupyter notebook.

3999
04:47:29,000 --> 04:47:32,000
The Jupyter notebook uses Tornado to host its web content.

4000
04:47:32,000 --> 04:47:36,000
Tornado is great for templating and hosting dynamic content.

4001
04:47:36,000 --> 04:47:42,000
However, it's slower than things like EngineX or Apache to host static files.

4002
04:47:42,000 --> 04:47:49,000
The methods described in this video can also be extended to redirect and host the static content on CDNs.

4003
04:47:49,000 --> 04:47:52,000
First, we're going to launch Jupyter Hub.

4004
04:47:52,000 --> 04:47:55,000
Go ahead and open up a Docker quick terminal.

4005
04:47:55,000 --> 04:47:57,000
Pay attention to the IP in green.

4006
04:47:57,000 --> 04:48:01,000
Then make sure that all Docker images are closed.

4007
04:48:01,000 --> 04:48:08,000
Next, navigate into the OAuth example folder inside the Docker spawner directory.

4008
04:48:08,000 --> 04:48:15,000
Launch Jupyter Hub by running the run.sh script.

4009
04:48:15,000 --> 04:48:21,000
Once Jupyter Hub launches, open up your web browser and verify that Jupyter Hub is running.

4010
04:48:21,000 --> 04:48:25,000
This should be available at localhost colon 8000.

4011
04:48:25,000 --> 04:48:27,000
Now, go back to the terminal.

4012
04:48:27,000 --> 04:48:31,000
Open up a new tab by hitting command T.

4013
04:48:31,000 --> 04:48:35,000
If you're on a machine that doesn't support tabs in your terminal, open up a new terminal.

4014
04:48:35,000 --> 04:48:38,000
Now, we'll install EngineX.

4015
04:48:38,000 --> 04:48:41,000
On OS X, you can do this using brew.

4016
04:48:41,000 --> 04:48:46,000
On Linux operating systems, you'll want to use the package manager of that system.

4017
04:48:46,000 --> 04:48:50,000
Typically, this is apt-get or yum.

4018
04:48:50,000 --> 04:48:53,000
If you're on OS X, go to your web browser.

4019
04:48:53,000 --> 04:48:56,000
Go to brew.sh.

4020
04:48:56,000 --> 04:48:58,000
This is the home page for brew.

4021
04:48:58,000 --> 04:49:05,000
If you don't have brew installed already, copy the line under the install home brew section inside the text box.

4022
04:49:05,000 --> 04:49:09,000
Paste that line in your terminal and execute it to install home brew.

4023
04:49:09,000 --> 04:49:14,000
I've already installed home brew on my machine, so I'm not going to demonstrate this for you.

4024
04:49:14,000 --> 04:49:16,000
Go back to your terminal.

4025
04:49:16,000 --> 04:49:19,000
Now, make sure that brew is up to date.

4026
04:49:19,000 --> 04:49:22,000
To do so, you're going to run brew update.

4027
04:49:22,000 --> 04:49:25,000
Now, we'll use brew to install EngineX.

4028
04:49:25,000 --> 04:49:30,000
Once brew is finished installing EngineX, run EngineX.

4029
04:49:30,000 --> 04:49:32,000
Now, go back to your web browser.

4030
04:49:32,000 --> 04:49:38,000
Access localhost 8080 to see if EngineX is running.

4031
04:49:38,000 --> 04:49:42,000
If EngineX is running, you should see a welcome to EngineX page.

4032
04:49:42,000 --> 04:49:44,000
Now, go back to your terminal.

4033
04:49:44,000 --> 04:49:51,000
Run EngineX-S to stop the EngineX service.

4034
04:49:51,000 --> 04:49:53,000
Now, go back to your web browser.

4035
04:49:53,000 --> 04:49:56,000
Go to github.com.

4036
04:49:56,000 --> 04:50:03,000
You should see the Jupyter Hub application that you registered earlier.

4037
04:50:03,000 --> 04:50:05,000
Click on that.

4038
04:50:05,000 --> 04:50:13,000
Now, change the port on the home page and the authentication callback URL to 8080.

4039
04:50:13,000 --> 04:50:17,000
Go back to your terminal.

4040
04:50:17,000 --> 04:50:23,000
Now, change the EngineX configuration file so that it proxies all requests to Jupyter Hub.

4041
04:50:23,000 --> 04:50:27,000
We'll also proxy the web socket connections to Jupyter Hub.

4042
04:50:27,000 --> 04:50:33,000
However, we'll intercept requests to static assets and host those directly using EngineX.

4043
04:50:33,000 --> 04:50:39,000
To edit the EngineX configuration file on OS X, run atom or open up

4044
04:50:39,000 --> 04:50:47,000
forward slash usr forward slash local forward slash Etsy forward slash EngineX forward slash EngineX.conf.

4045
04:50:47,000 --> 04:50:50,000
This is the path to the configuration file for EngineX.

4046
04:50:50,000 --> 04:50:55,000
If you're running EngineX on a machine other than OS X, this path may be different.

4047
04:50:55,000 --> 04:51:02,000
You'll have to refer to your installation method to figure out where the configuration file lives by default.

4048
04:51:02,000 --> 04:51:06,000
I'm going to open this file in atom.

4049
04:51:06,000 --> 04:51:10,000
The first thing we'll do is trim a lot of the comments and access lines.

4050
04:51:10,000 --> 04:51:16,000
This will allow us to focus better on what the contents of the configuration file should be.

4051
04:51:16,000 --> 04:51:19,000
I'm going to go ahead and remove this userNobody comment.

4052
04:51:19,000 --> 04:51:23,000
And also the log comments and process ID comment below.

4053
04:51:23,000 --> 04:51:29,000
I'll leave the events block and remove the log format comment, access log comment,

4054
04:51:29,000 --> 04:51:37,000
send file, TCP push, keep a live time out, gzip, all the way down to the server block.

4055
04:51:37,000 --> 04:51:44,000
Inside the server block, I'll leave the listen to port 8080 and server name local host lines.

4056
04:51:44,000 --> 04:51:48,000
I'll remove the lines down to the location forward slash.

4057
04:51:48,000 --> 04:51:55,000
Everything from here on out, I'll remove.

4058
04:51:55,000 --> 04:52:00,000
Now we'll configure all requests on root to forward to Jupyter Hub.

4059
04:52:00,000 --> 04:52:04,000
To do so, remove the lines inside the root block.

4060
04:52:04,000 --> 04:52:12,000
The first line you'll need is proxy underscore pass space, the address to Jupyter Hub.

4061
04:52:12,000 --> 04:52:26,000
Next, proxy underscore set underscore header, capital X dash capital R real dash all caps IP space dollar remote underscore add semicolon.

4062
04:52:26,000 --> 04:52:36,000
Next, you'll want proxy underscore set underscore header host with the capital H dollar HTTP underscore host semicolon.

4063
04:52:36,000 --> 04:52:56,000
In the last line you'll want in the root section proxy underscore set underscore header space capital X dash capital F forward it dash capital F four space dollar proxy underscore add underscore X underscore forward it underscore four.

4064
04:52:56,000 --> 04:53:00,000
Now copy these four lines that you just wrote.

4065
04:53:00,000 --> 04:53:08,000
Below the location root block, we'll need to add another location block, which will only intercept attempts to connect to WebSockets.

4066
04:53:08,000 --> 04:53:15,000
We have to handle WebSocket forwarding specially. This is a detail of engine X configuration.

4067
04:53:15,000 --> 04:53:19,000
To do so, write location space till day asterisk.

4068
04:53:19,000 --> 04:53:24,000
Then we're going to add a long regular expression that will look kind of funky.

4069
04:53:24,000 --> 04:53:30,000
This regular expression will be used to match the request path for WebSocket connections.

4070
04:53:30,000 --> 04:53:37,000
This first group is matching the user forward slash account name section of the URL.

4071
04:53:37,000 --> 04:53:42,000
The second group matches the WebSocket request specific to the notebook server.

4072
04:53:42,000 --> 04:53:50,000
Then suffix with forward slash question mark, and that's all you need for the regular expression that identifies WebSocket requests.

4073
04:53:50,000 --> 04:53:55,000
I'll turn on word wrap so you can see this whole line.

4074
04:53:55,000 --> 04:53:59,000
Inside that group, paste the four lines that you copied earlier.

4075
04:53:59,000 --> 04:54:04,000
You'll need to add some additional lines to get WebSocket forwarding the work.

4076
04:54:04,000 --> 04:54:11,000
First, you'll want to add proxy underscore HTTP underscore version space one point one.

4077
04:54:11,000 --> 04:54:22,000
Next, you'll want to add proxy underscore set underscore header space capital U upgrade space dollar HTTP underscore upgrade semicolon.

4078
04:54:22,000 --> 04:54:32,000
Next, add proxy underscore set underscore header space capital C connection space upgrade in quotes semicolon.

4079
04:54:32,000 --> 04:54:40,000
Last, you'll want to add proxy underscore read underscore timeout space 86,400 semicolon.

4080
04:54:40,000 --> 04:54:46,000
This is all you need to get content to forward to Jupyter Hub using engine X.

4081
04:54:46,000 --> 04:54:51,000
The last piece we'll want to add is to intercept request for static assets.

4082
04:54:51,000 --> 04:54:55,000
We'll want to host directly from the notebook directory.

4083
04:54:55,000 --> 04:54:58,000
But first, let's make sure that this is working.

4084
04:54:58,000 --> 04:55:00,000
Save the file.

4085
04:55:00,000 --> 04:55:04,000
Go back to your terminal.

4086
04:55:04,000 --> 04:55:06,000
Launch engine X.

4087
04:55:06,000 --> 04:55:11,000
If you get a message like this, it means there's something wrong with your configuration file.

4088
04:55:11,000 --> 04:55:13,000
It looks like mine has a typo.

4089
04:55:13,000 --> 04:55:17,000
Remote underscore add was supposed to be remote underscore adder.

4090
04:55:17,000 --> 04:55:20,000
I'm going to add an R and then save the file.

4091
04:55:20,000 --> 04:55:22,000
Now I'm going to go back to the terminal.

4092
04:55:22,000 --> 04:55:25,000
I'm going to try launching engine X again.

4093
04:55:25,000 --> 04:55:29,000
It looks like I missed another instance of remote add.

4094
04:55:29,000 --> 04:55:33,000
Also down here where I copied that content from the root.

4095
04:55:33,000 --> 04:55:35,000
I'm going to save the file.

4096
04:55:35,000 --> 04:55:38,000
I'll try launching engine X again.

4097
04:55:38,000 --> 04:55:40,000
Looks like it launched successfully.

4098
04:55:40,000 --> 04:55:43,000
Now I'm going to go to my web browser to verify that it launched.

4099
04:55:43,000 --> 04:55:46,000
I'm going to try accessing engine X.

4100
04:55:46,000 --> 04:55:50,000
If you recall correctly, it's at localhost 8080.

4101
04:55:50,000 --> 04:55:55,000
When I first access it, it looks as if what I did had no effect on engine X.

4102
04:55:55,000 --> 04:56:00,000
However, this is because my web browser is caching the contents of the last request.

4103
04:56:00,000 --> 04:56:04,000
By refreshing the page, I should see the right contents.

4104
04:56:04,000 --> 04:56:09,000
If refreshing the page doesn't fix the problem for you, you may need to clear your web browser's cache.

4105
04:56:09,000 --> 04:56:13,000
To do so, you'll have to follow steps specific to your web browser.

4106
04:56:13,000 --> 04:56:16,000
I'm going to go ahead and click on my server.

4107
04:56:16,000 --> 04:56:21,000
I need to validate that the proxy for the web sockets is working.

4108
04:56:21,000 --> 04:56:24,000
I'm going to open up the shared folder.

4109
04:56:24,000 --> 04:56:26,000
And then the test one notebook.

4110
04:56:26,000 --> 04:56:30,000
I'm going to try to run the cell with a change.

4111
04:56:30,000 --> 04:56:36,000
If it works, I know that the web sockets are forwarding correctly because the notebook is able to execute code.

4112
04:56:36,000 --> 04:56:40,000
I'm going to save and close this notebook.

4113
04:56:40,000 --> 04:56:44,000
Now I want to try to speed up this Jupyter Hub instance.

4114
04:56:44,000 --> 04:56:47,000
To do so, I'll have to intercept request the static.

4115
04:56:47,000 --> 04:56:49,000
I'm going to go back to my terminal.

4116
04:56:49,000 --> 04:56:55,000
The first thing I need to do is make sure that I have the static notebook files somewhere on my computer.

4117
04:56:55,000 --> 04:56:57,000
That way, Nginx can host them.

4118
04:56:57,000 --> 04:57:00,000
I'm going to navigate to my root directory.

4119
04:57:00,000 --> 04:57:12,000
Here, to clone the notebook, I'm going to run getClone, space, HTTPS, github.com, forward slash Jupyter, forward slash notebook.

4120
04:57:12,000 --> 04:57:20,000
Once the notebook clones successfully, I'm going to go back to the atom instance that I used to open the Nginx configuration.

4121
04:57:20,000 --> 04:57:24,000
Above the location root block, I'm going to add a new block.

4122
04:57:24,000 --> 04:57:27,000
This block will recognize requests for static assets.

4123
04:57:27,000 --> 04:57:30,000
To do so, I'll have to use a regular expression again.

4124
04:57:30,000 --> 04:57:34,000
This time, just use tilde, no asterisk.

4125
04:57:34,000 --> 04:57:36,000
The regular expression is as follows.

4126
04:57:36,000 --> 04:57:37,000
Forward slash.

4127
04:57:37,000 --> 04:57:41,000
And the first group is the user block, just like we did earlier.

4128
04:57:41,000 --> 04:57:46,000
And then the next block is forward slash static forward slash.

4129
04:57:46,000 --> 04:57:59,000
Lastly, parentheses dot asterisk to match all characters, forward slash, question, v equals, and then parentheses dot asterisk to match all characters.

4130
04:57:59,000 --> 04:58:06,000
Now, you're going to specify the root directory to the directory that we clone the notebook repository to.

4131
04:58:06,000 --> 04:58:10,000
When that is finished, save the file and return to your terminal.

4132
04:58:10,000 --> 04:58:17,000
Make sure to stop Nginx if it's already running by running Nginx, dash s, stop.

4133
04:58:17,000 --> 04:58:21,000
Then run Nginx to launch Nginx again.

4134
04:58:21,000 --> 04:58:23,000
Now let's go back to the web browser.

4135
04:58:23,000 --> 04:58:27,000
Navigate back to the root page, refresh the page.

4136
04:58:27,000 --> 04:58:31,000
If everything worked, the page shouldn't look any different.

4137
04:58:31,000 --> 04:58:36,000
However, this Jupyter logo, for example, is being hosted by Nginx.

