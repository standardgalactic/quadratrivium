{"text": " So, hi everybody, as a guy gentleman just said, I'm the CEO of a consulting company in London called Deep Learning Partnership and I'm going to talk to you today about something I don't really do on my day-to-day job, it doesn't pay my rent, but it affords me nice trips to exotic places. So, who here has heard of artificial general intelligence? Yeah, so quite a few. And so, what we label today is AI, isn't really AI, it's matrix multiplication. So, I'm going to talk to you today about how we might actually get to AGI and it's more of a neuroscience based approach. It's how the brain works, it's how biology does it. So, it's okay, everything that we've heard the speakers talk about so far, which has been labeled AI, it's really deep learning or artificial neural networks and the early creators of that said this is nothing to do with how the brain works, right? It's just it kind of works to classify cats and dogs and that's about it. We do a lot more than that. So, how do we get there? Is it even possible to build an artificial brain basically how biology does it? And I'm here to tell you, yes it is, I'll just give it away, you can go now, but if you're interested, I'll walk you through how that might look and how that might be done. Okay, so here's a little book I wrote for Riley, it's a booklet. There's my company website, there's my Twitter handle, you can follow me, I tweet a little bit about AGI and sometimes quantum computing, my other hobby or interest. So, this is what we're going to outline just briefly. We're going to look at physical systems, how biology does intelligence, and where we are with the non-biological, I've kind of just explained that in a broad sense, but we'll look at some of the, well, we'll go through the slides, deep learning recap and then we'll look at how we might build AGI and some of the theories and in particular one called active inference that I find particularly compelling to how the brain might work. Okay, so at that point it's sort of theoretical neuroscience, so I hope I don't lose you. I try to keep this kind of high level and not too much code or anything, although there is code and math for this stuff. And then we'll wrap it up by saying is it possible, how long might it take? Okay, so why do we even want to build AGI? Why don't we just stop here with the cats and dogs and TensorFlow? Well, if we do, like DeepMind says, if we can solve intelligence and we can use it to solve everything else. I mean, we're quite good at stuff, we've got here today, we've had Einstein's theory of relativity, we've had quantum physics, we've had classical physics, Newton, all the big names, why do we need any help? Well, clearly if we do manage to figure this out and build an artificially general intelligent system, then we can accelerate progress, which is probably, we can all agree, is a good thing. Although some people like Elon must say that, let's not build it because it will straight away kill us all, right? Well, we don't know, but I don't think it will. Okay, so I'm the anti-Elon Musk, okay? I'm the opposite. Okay, so I'm an optimist, he's a pessimist. So he's a good entrepreneur anyway. So what about all of these things here? AlphaGo, this is DeepMind in London, I'm sure we all saw on TV, AlphaGo beating the best go player in the world, was that AI, was that AGI? AlphaStar, it's a new project to beat the world's best video game players, a little bit more general one might argue than just playing a board game. DeepBlue, IBM's DeepBlue and Chess, Landmark, and IBM Watson, that's actually natural language processing, so that's quite clever, that's quite getting a little closer to AGI maybe, because it's having to understand language, but was it just doing it statistically? Was it just a massive computer hardware system that could crunch numbers really well and just do everything statistically? Is it how we learn language and understand language? I would argue no. So actually, all of those are just narrow AI, they're just statistical mathematical analysis of big data sets, okay? So it's not really how the brain does anything. If it were, I mean we do all of that in that little three pound thing above our sitting, above our shoulders, right? We don't need huge data centers, so clearly biology is doing it in a slightly different way, okay? So how is it doing it and how is it different? So first of all, to build something, we have to understand what we're building. What is intelligence, general intelligence? Well, it's all these things, right? So we don't just classify things, we do all of that. I won't read them out, because I've only got 30 minutes and sometimes I give this talk, it's an hour, but there's basically nine types of intelligence there, maybe even 10. And this guy at Harvard, Howard Gardner, just mapped it all out. See, existential thinking language, we can do math using ANNs, but the rest of it is pretty much music, creating art, spatial navigation, that's all. We can do all of that in three pound. We don't need a huge data center, hardware cluster of GPUs. So what's different? What are we missing? Okay. Well, first of all, how far have we come? Like I said, the mathematical part, we're like 50%, we're pretty good, we're not bad, we're about halfway there, linguistic, but it's only statistical analysis. Spatial navigation, self-driving cars, robots who can navigate through systems. I'd say we're about something called SLAM. I'd say we're about 50% there, that's the algorithm, simultaneous mapping and I forgot what the LAM stands for, but don't worry. We're about 50% there. You've probably seen simultaneous localization and mapping. You've probably seen the Atlas, you know, robot that do flips and run around outside and do good stuff, busts and dynamics. So that's why I'm giving it a generous 50%. We do a lot more than that. We can do gymnastics, we can run around, we learn stuff very quickly, we don't need millions of datasets to train, but as we go through that list of nine types of intelligence, it gets really, it just gets worse, right? Robots understanding each other or even algorithms running on a computer virtual sort of intelligence. Intrapersonal understanding themselves and existential, you know, show me an algorithm or a robot that kind of questions why it's there, or even understands that it exists, it's kind of zero. So we haven't figured that intelligence out at all. So the brain is pretty special, right? Biology is kind of special. We could argue chimpanzees, self-aware, well, yes, right, a dog, cats, probably. And as you go, you know, snails, maybe not, you know, bacteria, no. So there's clearly a continuum in what makes us a little different is our neocortex, that sort of outer layer of the brain. So we kind of have to figure out how that works, basically. But we've got all this other stuff in the brain like the amygdala for emotional intelligence, you know, the reptilian brain and there's sort of layers, you can trace it. In fact, you know, as babies are born and embryos develop over the nine months, you can see, you know, evolution, it starts off, you know, with the, you know, reptilian brain and it goes out monkey and then, you know, humans as we develop in the womb. So, you know, it's all, all of that evolution is still captured, all that information is actually captured by biology. It's just that last layer of the neocortex that makes us be able to come up with, you know, science, special theory, relativity, whatever, you know, that, that. So what are we missing? Why can't we do that yet in TensorFlow? Okay, why can't Google or DeepMind do that yet? So how will we get there? Well, it takes a village to create a child and I'm going to argue it takes, it's going to take a big community to create AGI. We're going to need computer scientists, physicists to understand the physics of the brain, neuroscientists, clearly, and also psychologists. So what I'm seeing really at the moment where these teams trying to build AGI or AI are just computer scientists, you know, just computer scientists, you know, you're clever people, they have PhDs and computer science, which involves a lot of math and understanding hardware and algorithm, algorithmic complexity. But it's not really understanding how much about biology at all. Okay, so we're going to need a whole bunch of people. And so I'll speed up a little bit now. I've kind of laid the foundations for what we might need. So this is basically what we've got in hardware. So this is how biology does it in hardware. So, you know, like I mentioned, we have a continuum from bacteria. That's a simple, C elegance is the simplest biological system with a central nervous system, it has, I think, about 300 neurons, then the bumblebee, the humble bumblebee with about a million, a few million neurons, and then us with about 80 billion or 100 billion neurons. Okay, so what, you know, what basically, maybe if we start at the simple, the C elegance and then build a bumblebee, then maybe one day, you know, we'll get to us. That's one sort of thought. The other, the other observation really is that nature is very hierarchical. You know, we built neurons, built of, they're not magic, you know, the built of atoms, molecules. And then if we just go up the different layers, we have synapses, neurons, and collection of neurons as connectome. So these 80 billion neurons are organized into some kind of structure. Maybe, you know, we should start there. So the question here is, you know, what level do we start at? Do we have to start at molecules or can we start at neurons or should we start a little more holistically at the connectome? You know, and on and on up until the central nervous system, us, which is about a meter in dimensions. So we're going from 10 to the minus 10 up to a meter. So it's a hard problem. It's kind of no wonder we haven't solved it yet. There's a lot of physics in there. And so that's what it looks like. This is how nature has done it. It's complicated, isn't it? You know, I mean, do we need all that little tiny microstructure? Probably not, I might argue. So you know, this is how, you know, what do we for in a half billion years of evolution on the earth, maybe a billion since the first sort of organisms, bacteria, whatever, the first, you know, primitive life. So over that billion year, this is what this is what nature's ended up with, right? This is what makes us intelligent, these things, right? You couldn't guess that. You start with a blank piece of paper, but this is just the universe we live in, the laws of physics. This is this is how we work. Okay. So there's no magic, but there's certainly a lot of complication. It's a complicated looking thing. That's a neuron. Okay. And so the next level of the hierarchy, we see that these neurons are kind of organized into some kind of structure called cortical columns, which each have about two, two million neurons. So maybe this is a good level to start. Maybe we don't have to go right down to all that complicated structure, maybe here. So that's kind of an interesting thing that we know. And then up onto the connectome, and then the central nervous system. If we want to build a robot, we need that those flips, we'll probably need all of that connected to the brain at the top. Okay. So and then we have societies where we're organized into societies. Bees are, you know, in their swarms and humans in their villages, towns, cities, countries, and then the global national community. So there's all these layers of hierarchy, which are intelligent, right? So, you know, we have this kind of macro meta intelligence built into communities and systems of communities, which has enabled us to, you know, survive reproduced into the next generation. So, okay. So that's biology. That's how it works. That's how it does it. That's what we know, plus a whole lot of other details, which I haven't really covered. So what have we done? How far are we along the line with hardware? So basically, the talks that we'll see here, you know, talking about CPUs, HGO, GPUs, that's what they use, sparkling water all runs on these things. There's a new sort of endeavor to build ASICs, which are specialized for deep learning. But again, it's just narrow AIS, it's matrix multiplication. But is it grok and cerebrus, graph core, Intel, Nirvana, they're all coming out with these amazing things that can do, you know, petaflops operations, which is more than the brain does. It's actually more than biology does. But all they're doing is multiplying matrices, right? They're incredible feats of micro engineering, incredible. These fabs cost, you know, billions of dollars to build. They've already, you know, graph core just raised $200 million. And they're impressive things, right? And that's what I look like that CPU GPU. There's a Google TPU, which is an ASIC, and runs in their data centers, you can hire them, run them in the cloud. And then there's the graph core IPU. And they all look the same, but you know, the micro architecture is a little different. So that, you know, this is all digital classical. If you do a computer science, you'd understand, you know, the details of how bits move around in there, how much energy it takes, how the memory in the processor, you know, interact together. But they're not intelligent, right? They're just very good mathematical processors. Okay, that's what a hundred petaflops looks like. And you can, you know, log in today to these things. The Google data center, this is the most powerful, you know, three exaflops, we're going to say that that's 1000 million, almost a million times more powerful than the brain. But it says dumb as a brick, it's the sun, it's incredibly impressive engineering, it takes up a football field, it's a data center size, but you can't do much except for model plane numbers together, it's not intelligent. Okay, so clearly we're heading into a dead end, if we just follow that computer science classical digital hardware route. See the brain does all of that and all the other types of intelligence in that little three pound mass. So clearly, it's not just about speed of compute, right? It's not just about horsepower. So what is it about? Okay, so recently, some of you, who's heard of neuromorphic computing? Who's heard of that? Yeah, maybe a few, right? A couple. So there's a project called Spinnaker in the UK. There's, there's IBM True North, Intel, the OHE. There's, you know, a few different projects that are trying to do mimic how biology in hardware, you know, does, does computation. Okay, it's called neuromorphic computing. So it's based on the brain. And so there's Steve Furber, he's one of the guys who come up, invented, founded the ARM computer processor company. And so he, 20 years ago, left ARM and started on this neuromorphic journey. He's based at University of Manchester. And recently, the human brain project has folded. It's called Spinnaker into itself because it's biopausable hardware. So they have lots of nice funding now, again, as IBM True North and Intel. I mean, these companies have a lot of money too. So that's what it looks like. So there's five racks there. That is about as powerful as the brain of a mouse. So it's not human level yet, but it can do things that can go through a maze, it can solve Sudoku and stuff like that, just like we do. So it's kind of getting there. And I would argue, you know, to build intelligence, rather than just simulating it on classical digital hardware, this is a more intelligent route to take. Okay. So, and there's a little bit of detail. So this is an important, you know, technology and a new path that not many have heard of here, you know, which is very interesting. It's probably like we were in the 50s with digital computing. You know, there's just a few main frames in the world right now, a few of these devices, but they actually exist. And you can actually log into Spinnaker. It's part of the human brain project. You can create an account, log in and watch it do stuff in real time. So they're not these magical, mystical things in a lab. They're kind of getting in real. And let's see. So that's okay. That's another initiative from Heidelberg, the brain scales project, which is also part of the human brain project. So the one on the left, I would argue, will get us to general intelligence. The one on the right, no matter how impressive that looks, won't. Okay. So, and then there's quantum computing, how about it? Is the brain quantum? No, it's warm, it's squidgy, nothing to do with quantum at all. Okay. Although birds navigate and plants photosynthesize using quantum processes, but it's not really generally how we do it. Okay. But the pictures look really nice. I decided to include a couple and it is what a quantum circuit looks like. I also quite like quantum computing because I have a physical background, but it's probably we don't need to worry about that if we're building AGI. It might help some of the computations initially, but ultimately we're not a quantum computer up here. It's a neuromorphic computer. Okay. So that's the sort of four different types of hardware. And I'd argue the one on the top right, neuromorphic will get us there. And that's how they look in a little bit more detail. And so, you know, it's not magic. It's just really hard engineering, which is why we haven't built it yet. It's just hard. Okay. It's small. It's, you know, and to understand it's difficult. Do we have a mathematical theory of the brain? Well, I would argue sort of before I go there. So the data center of the future right now is just full of those very clever chips we saw the graph core, the, you know, TPU GPU CPUs, very, you know, amazing engineering, but soon we'll see them being filled up with neuromorphic and quantum as well. So Google announced quantum supremacy last week, a couple of weeks ago, which means that a quantum computer, it can do something faster than the biggest classical computer. So the data center of future will look like this. Okay. So we're interesting. We're entering a very interesting time in human history, I think, in terms of computation, because we haven't just got classical computing, we have neuromorphic and quantum as well coming online. It's been 80 years, right, since we first started doing a computation. So at a very interesting time, I think in the history of computation with these other two major types of computation coming online. So deep learning, I've argued that won't get us anywhere near intelligence. It will classify stuff really well and do a little bit of statistical language processing, but it doesn't do the nine types of intelligence. Okay. And so the most popular framework by far as TensorFlow, PyTorch is kind of also increasing in the last little while, but you know, general intelligence, how biology does it, it doesn't do matrix multiplication. So deep learning is not AGI. So we won't talk about that, but we will talk about more neuroscience stuff. Okay. Sorry to be so harsh, but you know, it's reality. All that clever stuff isn't actually AGI, but it's good at certain things. Okay. So what do we do? I mean, where do we even start, right, with the general theory of intelligence? Well, you know, the brain is a physical system, right? It's just three pounds of physics, just, okay. So what do we know about physics? Well, we've pretty much discovered all of the laws of physics. I think dark matter is kind of a new one. It's a bit of a bold statement. I'm a physicist. I'm allowed to say that. So what are, I mean, what out of there do we use? Okay. You know, probably thermodynamics and electromagnetism in a complex system, right? So it's nothing magic. Now the underlying theory of all of this, all of that can be described in something called the principle of least action, which is that, and it's just been a book published last year. Surprisingly, it wasn't one before that sort of says, okay, all of physics, that's, you know, classical quantum, everything can be, you know, derived starting with this principle of least action. Now, if anyone's who's got a PhD in physics here, yeah, a few people. And so we've all, this is what you get at grad school in physics, right? We do Lagrangians and Hamiltonians and principles of least action. So everything we learn, if equals ma and undergrad, we're told, yeah, that's very nice and quaint. But really, this is the powerful machinery that's been developed. But we don't, you know, that we sort of, we get, we get there, but I think we're not really taught that, you know, it's very unifying principle. Okay, so I'm saying, okay, probably that's a nice place to start if we want to try to come up with a general theory of intelligence. Okay, it's a big statement and bold statement, but, you know, the brain is not doing anything that physical systems can't do, even though it feels kind of, it is different, right? Because we have consciousness and, you know, that subjective experience and self-awareness and that kind of stuff. But I'm going to argue it's all just physics. There are people in the room and elsewhere who will say, no, there's something beyond physics, metaphysics. I'm not one of those people. Okay, so I'm just going to keep it really simple. So, you know, what can we do? Well, we can explain and understand what we see. We can imagine things, you know, imagination, imagine that. Problem solving, planning actions to make these things real, we can do all of that. That's what intelligence is really. And we can build new models as we learn about the world. So, probably, okay, we've got five minutes. So, these are the sort of major, some of the major theories of general intelligence, mathematical theory. These are all smart people who have spent their whole lives dedicating to this. You can look them up later. There's a guy called Carl Friston at UCL in London. And so, his theory of active inference is the one that I think is particularly compelling. And I won't spend any time going through the details, because it's pretty hard math, actually, but he uses something called a free energy principle. It's based on physics and information theory. It's nothing kind of new and crazy. It's just applying it to the brain. And he is a theoretical neuroscientist. And so, here he is. And we don't have time to play it. So, the slides will be made available, I think, so you can listen to him. And he's on YouTube, if you want to Google. And so, that's how he sets it up. There's internal, there's us agents acting in an environment. That's the same if we're bacteria, monkeys, birds, human beings. It's a system, right? A physical system. We act in our environment. The environment acts back on us. So, there it is, bacteria to brains. And the math gets really ugly, because it is statistical, probabilistic, and physical all at the same time. It's complex information theory, essentially. But the ultimate question is, can we build general intelligence? So, I would argue yes, because we have theories. We have very compelling theories. All of those are, you know, hundreds and hundreds and hundreds, literally thousands of papers written deep mathematical theory, which keeps hundreds of graduate students in PhDs. So, yes, we have the theory. We have candidate theories. We have the algorithms and software. We have the hardware, neuromorphic in particular, and we have data sets nowadays. So, yes. And I think we're kind of on our way with these projects like Spinnaker and IBM True North. So, we're starting to build the hardware. It's just a sort of, it's always just an engineering problem, right? Yeah. So, you know, what else? So, should we? That's an ethics question. We won't go into that, because we could spend the rest of our lives arguing should we do it or not. We're going to do it anyway. So, there are some projects. DeepMind is trying to, although, you know, all the go and stuff isn't general. It's just specific. But there's a whole bunch of AGI projects and all super interesting things. I definitely encourage you to look and explore if you're interested in this subject at all on the internet. In conclusion, so, it's obvious that deep learning is just statistical. It's not based on physics at all. There's like zero physics in there. So, it's definitely not going to get us anywhere towards general intelligence. But research groups are, many are looking into biopausable models. That's both on the theoretical and the hardware side. We're sort of getting the glimpse of the very first systems. We have the rat brain there with Spinnaker. So, we're sort of at the very beginning of a steep exponential. So, maybe that will improve and in 10 years we'll have a human level brain, which will be conscious and self-aware and subjective experience, which is kind of spooky and creepy, right? There's nothing. I'm trying to argue there's nothing that mysterious about the brain. It's just a complex system. And so, what do we do then? Well, we'll figure it out as we go along, as we have done everything. And so, the future of AI, Jeff Hinton, he's the godfather of AI. He's in Canada and he, let him have the final word, except there's no volume. Okay. So, he's just basically saying that the brain is super, everything he's done in his whole life. He's just clearly admits he wasn't working on general intelligence and to do, to figure out how it works, we're going to have to look at neuroscience. That's pretty much his message. And it's pretty much my message. And so, I hope you've enjoyed my talk. It's been a little bit different from everyone else's, but thanks. Yeah. And we have questions, of course. Okay. One interesting question is, could AGI be achieved without emulating human brain but building a completely different model? No. That was a short one. You kind of answered this one, but maybe you can elaborate a little bit more. When do you think AGI will arrive? And I can follow with another one. As you said, you're at 50% of achieving AGI. What are the main challenges you are facing to get to 100% what technology breakthroughs are needed? Yeah. So, it's basically a hardware engineering problem. So, I did show the Spinnaker and there are the hardware projects around the world doing this, like IBM and Intel. And so, with that's the mouse brain right there. So, basically, it's a scaling problem now. I mean, we started at one transistor at one point with classical computing and then companies like Intel were formed and AMD and NVIDIA and the rest is history, right? It'll go on its own Moore's law. So, right now, we're at the kind of like 10 transistor stage that we were with classical. So, we'll just see that scale. I'm going to say something really bold. It's just a scaling problem at this point in time. So, watch this space. So, what will you say? Well, it'll go mouse and then it will go Bumblebee and then mouse and then monkey and then human. So, we're on a curve. So, human in 10 years, that's my prediction. They're too optimistic. I mean, in 1969, when people flew to moon, they thought that they would be living on the moon by now. Okay. I'm an optimist. I'm saying 10. Yeah. Okay. But I appreciate that. The last one, a comment about the Soul Machines Baby X project and the potential to get closer to general AI. What's that? Say that again? Yeah. I haven't heard about the Soul Machines Baby X project. Oh, yeah. I have. Yeah. Okay. Well, certainly. What was the question? The Baby X? I mean, your comment about it and the potential to get closer to general AI. Yeah. I didn't actually mention Baby X, but that's a nice project in New Zealand. And it's another AGI project. But basically, it's going to come back to neuroscience. You know, we saw the mass, we saw some of the mathematics involved. It's going to be people working at that level from a theoretical point of view. And other people like Steve Furber and the Human Brain Project, you know, brilliant engineers basically working on the hardware level, and these people talking to each other. And I know Carl Friston and Steve Furber do talk to each other and building this very complex system. Okay, Peter, thank you. Thank you. I will present you with a certificate. Thank you, Peter. Thank you, sir. Thank you, sir. Thank you, sir. Thank you. We, we got to, we got to fill in with the certificate.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.56, "text": " So, hi everybody, as a guy gentleman just said, I'm the CEO of a consulting company", "tokens": [50364, 407, 11, 4879, 2201, 11, 382, 257, 2146, 15761, 445, 848, 11, 286, 478, 264, 9282, 295, 257, 23682, 2237, 51092], "temperature": 0.0, "avg_logprob": -0.2144509996686663, "compression_ratio": 1.3837837837837839, "no_speech_prob": 0.19269844889640808}, {"id": 1, "seek": 0, "start": 14.56, "end": 19.52, "text": " in London called Deep Learning Partnership and I'm going to talk to you today about", "tokens": [51092, 294, 7042, 1219, 14895, 15205, 49589, 293, 286, 478, 516, 281, 751, 281, 291, 965, 466, 51340], "temperature": 0.0, "avg_logprob": -0.2144509996686663, "compression_ratio": 1.3837837837837839, "no_speech_prob": 0.19269844889640808}, {"id": 2, "seek": 0, "start": 19.52, "end": 24.88, "text": " something I don't really do on my day-to-day job, it doesn't pay my rent, but it affords", "tokens": [51340, 746, 286, 500, 380, 534, 360, 322, 452, 786, 12, 1353, 12, 810, 1691, 11, 309, 1177, 380, 1689, 452, 6214, 11, 457, 309, 2096, 5703, 51608], "temperature": 0.0, "avg_logprob": -0.2144509996686663, "compression_ratio": 1.3837837837837839, "no_speech_prob": 0.19269844889640808}, {"id": 3, "seek": 2488, "start": 24.88, "end": 34.8, "text": " me nice trips to exotic places. So, who here has heard of artificial general intelligence?", "tokens": [50364, 385, 1481, 16051, 281, 27063, 3190, 13, 407, 11, 567, 510, 575, 2198, 295, 11677, 2674, 7599, 30, 50860], "temperature": 0.0, "avg_logprob": -0.16701776956774525, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.17103780806064606}, {"id": 4, "seek": 2488, "start": 35.84, "end": 43.519999999999996, "text": " Yeah, so quite a few. And so, what we label today is AI, isn't really AI, it's matrix", "tokens": [50912, 865, 11, 370, 1596, 257, 1326, 13, 400, 370, 11, 437, 321, 7645, 965, 307, 7318, 11, 1943, 380, 534, 7318, 11, 309, 311, 8141, 51296], "temperature": 0.0, "avg_logprob": -0.16701776956774525, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.17103780806064606}, {"id": 5, "seek": 2488, "start": 43.519999999999996, "end": 48.239999999999995, "text": " multiplication. So, I'm going to talk to you today about how we might actually get to AGI", "tokens": [51296, 27290, 13, 407, 11, 286, 478, 516, 281, 751, 281, 291, 965, 466, 577, 321, 1062, 767, 483, 281, 316, 26252, 51532], "temperature": 0.0, "avg_logprob": -0.16701776956774525, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.17103780806064606}, {"id": 6, "seek": 2488, "start": 49.120000000000005, "end": 54.32, "text": " and it's more of a neuroscience based approach. It's how the brain works, it's how biology does it.", "tokens": [51576, 293, 309, 311, 544, 295, 257, 42762, 2361, 3109, 13, 467, 311, 577, 264, 3567, 1985, 11, 309, 311, 577, 14956, 775, 309, 13, 51836], "temperature": 0.0, "avg_logprob": -0.16701776956774525, "compression_ratio": 1.5443037974683544, "no_speech_prob": 0.17103780806064606}, {"id": 7, "seek": 5488, "start": 55.04, "end": 59.84, "text": " So, it's okay, everything that we've heard the speakers talk about so far,", "tokens": [50372, 407, 11, 309, 311, 1392, 11, 1203, 300, 321, 600, 2198, 264, 9518, 751, 466, 370, 1400, 11, 50612], "temperature": 0.0, "avg_logprob": -0.13442911795519907, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.0027058753184974194}, {"id": 8, "seek": 5488, "start": 61.760000000000005, "end": 66.16, "text": " which has been labeled AI, it's really deep learning or artificial neural networks", "tokens": [50708, 597, 575, 668, 21335, 7318, 11, 309, 311, 534, 2452, 2539, 420, 11677, 18161, 9590, 50928], "temperature": 0.0, "avg_logprob": -0.13442911795519907, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.0027058753184974194}, {"id": 9, "seek": 5488, "start": 66.16, "end": 71.52000000000001, "text": " and the early creators of that said this is nothing to do with how the brain works, right?", "tokens": [50928, 293, 264, 2440, 16039, 295, 300, 848, 341, 307, 1825, 281, 360, 365, 577, 264, 3567, 1985, 11, 558, 30, 51196], "temperature": 0.0, "avg_logprob": -0.13442911795519907, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.0027058753184974194}, {"id": 10, "seek": 5488, "start": 71.52000000000001, "end": 77.6, "text": " It's just it kind of works to classify cats and dogs and that's about it. We do a lot more than", "tokens": [51196, 467, 311, 445, 309, 733, 295, 1985, 281, 33872, 11111, 293, 7197, 293, 300, 311, 466, 309, 13, 492, 360, 257, 688, 544, 813, 51500], "temperature": 0.0, "avg_logprob": -0.13442911795519907, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.0027058753184974194}, {"id": 11, "seek": 5488, "start": 77.6, "end": 83.92, "text": " that. So, how do we get there? Is it even possible to build an artificial brain basically", "tokens": [51500, 300, 13, 407, 11, 577, 360, 321, 483, 456, 30, 1119, 309, 754, 1944, 281, 1322, 364, 11677, 3567, 1936, 51816], "temperature": 0.0, "avg_logprob": -0.13442911795519907, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.0027058753184974194}, {"id": 12, "seek": 8392, "start": 83.92, "end": 89.84, "text": " how biology does it? And I'm here to tell you, yes it is, I'll just give it away,", "tokens": [50364, 577, 14956, 775, 309, 30, 400, 286, 478, 510, 281, 980, 291, 11, 2086, 309, 307, 11, 286, 603, 445, 976, 309, 1314, 11, 50660], "temperature": 0.0, "avg_logprob": -0.10521356491815476, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.009952075779438019}, {"id": 13, "seek": 8392, "start": 90.48, "end": 96.32000000000001, "text": " you can go now, but if you're interested, I'll walk you through how that might look and how that", "tokens": [50692, 291, 393, 352, 586, 11, 457, 498, 291, 434, 3102, 11, 286, 603, 1792, 291, 807, 577, 300, 1062, 574, 293, 577, 300, 50984], "temperature": 0.0, "avg_logprob": -0.10521356491815476, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.009952075779438019}, {"id": 14, "seek": 8392, "start": 96.32000000000001, "end": 102.72, "text": " might be done. Okay, so here's a little book I wrote for Riley, it's a booklet. There's my", "tokens": [50984, 1062, 312, 1096, 13, 1033, 11, 370, 510, 311, 257, 707, 1446, 286, 4114, 337, 31373, 11, 309, 311, 257, 48469, 13, 821, 311, 452, 51304], "temperature": 0.0, "avg_logprob": -0.10521356491815476, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.009952075779438019}, {"id": 15, "seek": 8392, "start": 102.72, "end": 108.16, "text": " company website, there's my Twitter handle, you can follow me, I tweet a little bit about AGI and", "tokens": [51304, 2237, 3144, 11, 456, 311, 452, 5794, 4813, 11, 291, 393, 1524, 385, 11, 286, 15258, 257, 707, 857, 466, 316, 26252, 293, 51576], "temperature": 0.0, "avg_logprob": -0.10521356491815476, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.009952075779438019}, {"id": 16, "seek": 10816, "start": 108.24, "end": 114.32, "text": " sometimes quantum computing, my other hobby or interest. So, this is what we're going to", "tokens": [50368, 2171, 13018, 15866, 11, 452, 661, 18240, 420, 1179, 13, 407, 11, 341, 307, 437, 321, 434, 516, 281, 50672], "temperature": 0.0, "avg_logprob": -0.12294031984062605, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.08884231001138687}, {"id": 17, "seek": 10816, "start": 114.32, "end": 120.56, "text": " outline just briefly. We're going to look at physical systems, how biology does intelligence,", "tokens": [50672, 16387, 445, 10515, 13, 492, 434, 516, 281, 574, 412, 4001, 3652, 11, 577, 14956, 775, 7599, 11, 50984], "temperature": 0.0, "avg_logprob": -0.12294031984062605, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.08884231001138687}, {"id": 18, "seek": 10816, "start": 120.56, "end": 127.28, "text": " and where we are with the non-biological, I've kind of just explained that in a broad sense,", "tokens": [50984, 293, 689, 321, 366, 365, 264, 2107, 12, 5614, 4383, 11, 286, 600, 733, 295, 445, 8825, 300, 294, 257, 4152, 2020, 11, 51320], "temperature": 0.0, "avg_logprob": -0.12294031984062605, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.08884231001138687}, {"id": 19, "seek": 10816, "start": 127.28, "end": 134.88, "text": " but we'll look at some of the, well, we'll go through the slides, deep learning recap and then", "tokens": [51320, 457, 321, 603, 574, 412, 512, 295, 264, 11, 731, 11, 321, 603, 352, 807, 264, 9788, 11, 2452, 2539, 20928, 293, 550, 51700], "temperature": 0.0, "avg_logprob": -0.12294031984062605, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.08884231001138687}, {"id": 20, "seek": 13488, "start": 134.88, "end": 141.51999999999998, "text": " we'll look at how we might build AGI and some of the theories and in particular one called", "tokens": [50364, 321, 603, 574, 412, 577, 321, 1062, 1322, 316, 26252, 293, 512, 295, 264, 13667, 293, 294, 1729, 472, 1219, 50696], "temperature": 0.0, "avg_logprob": -0.11481619393953713, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.005444980226457119}, {"id": 21, "seek": 13488, "start": 141.51999999999998, "end": 149.76, "text": " active inference that I find particularly compelling to how the brain might work. Okay, so at that", "tokens": [50696, 4967, 38253, 300, 286, 915, 4098, 20050, 281, 577, 264, 3567, 1062, 589, 13, 1033, 11, 370, 412, 300, 51108], "temperature": 0.0, "avg_logprob": -0.11481619393953713, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.005444980226457119}, {"id": 22, "seek": 13488, "start": 149.76, "end": 154.56, "text": " point it's sort of theoretical neuroscience, so I hope I don't lose you. I try to keep this kind of", "tokens": [51108, 935, 309, 311, 1333, 295, 20864, 42762, 11, 370, 286, 1454, 286, 500, 380, 3624, 291, 13, 286, 853, 281, 1066, 341, 733, 295, 51348], "temperature": 0.0, "avg_logprob": -0.11481619393953713, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.005444980226457119}, {"id": 23, "seek": 13488, "start": 154.56, "end": 159.76, "text": " high level and not too much code or anything, although there is code and math for this stuff.", "tokens": [51348, 1090, 1496, 293, 406, 886, 709, 3089, 420, 1340, 11, 4878, 456, 307, 3089, 293, 5221, 337, 341, 1507, 13, 51608], "temperature": 0.0, "avg_logprob": -0.11481619393953713, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.005444980226457119}, {"id": 24, "seek": 15976, "start": 160.39999999999998, "end": 168.07999999999998, "text": " And then we'll wrap it up by saying is it possible, how long might it take? Okay, so why do we even", "tokens": [50396, 400, 550, 321, 603, 7019, 309, 493, 538, 1566, 307, 309, 1944, 11, 577, 938, 1062, 309, 747, 30, 1033, 11, 370, 983, 360, 321, 754, 50780], "temperature": 0.0, "avg_logprob": -0.13972850157835773, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.04441425949335098}, {"id": 25, "seek": 15976, "start": 168.07999999999998, "end": 176.64, "text": " want to build AGI? Why don't we just stop here with the cats and dogs and TensorFlow? Well,", "tokens": [50780, 528, 281, 1322, 316, 26252, 30, 1545, 500, 380, 321, 445, 1590, 510, 365, 264, 11111, 293, 7197, 293, 37624, 30, 1042, 11, 51208], "temperature": 0.0, "avg_logprob": -0.13972850157835773, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.04441425949335098}, {"id": 26, "seek": 15976, "start": 176.64, "end": 181.68, "text": " if we do, like DeepMind says, if we can solve intelligence and we can use it to solve everything", "tokens": [51208, 498, 321, 360, 11, 411, 14895, 44, 471, 1619, 11, 498, 321, 393, 5039, 7599, 293, 321, 393, 764, 309, 281, 5039, 1203, 51460], "temperature": 0.0, "avg_logprob": -0.13972850157835773, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.04441425949335098}, {"id": 27, "seek": 15976, "start": 181.68, "end": 187.04, "text": " else. I mean, we're quite good at stuff, we've got here today, we've had Einstein's theory of", "tokens": [51460, 1646, 13, 286, 914, 11, 321, 434, 1596, 665, 412, 1507, 11, 321, 600, 658, 510, 965, 11, 321, 600, 632, 23486, 311, 5261, 295, 51728], "temperature": 0.0, "avg_logprob": -0.13972850157835773, "compression_ratio": 1.534136546184739, "no_speech_prob": 0.04441425949335098}, {"id": 28, "seek": 18704, "start": 187.04, "end": 194.16, "text": " relativity, we've had quantum physics, we've had classical physics, Newton, all the big names,", "tokens": [50364, 45675, 11, 321, 600, 632, 13018, 10649, 11, 321, 600, 632, 13735, 10649, 11, 19541, 11, 439, 264, 955, 5288, 11, 50720], "temperature": 0.0, "avg_logprob": -0.11836533797414679, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.008238330483436584}, {"id": 29, "seek": 18704, "start": 194.16, "end": 200.88, "text": " why do we need any help? Well, clearly if we do manage to figure this out and build an artificially", "tokens": [50720, 983, 360, 321, 643, 604, 854, 30, 1042, 11, 4448, 498, 321, 360, 3067, 281, 2573, 341, 484, 293, 1322, 364, 39905, 2270, 51056], "temperature": 0.0, "avg_logprob": -0.11836533797414679, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.008238330483436584}, {"id": 30, "seek": 18704, "start": 200.88, "end": 208.16, "text": " general intelligent system, then we can accelerate progress, which is probably, we can all agree,", "tokens": [51056, 2674, 13232, 1185, 11, 550, 321, 393, 21341, 4205, 11, 597, 307, 1391, 11, 321, 393, 439, 3986, 11, 51420], "temperature": 0.0, "avg_logprob": -0.11836533797414679, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.008238330483436584}, {"id": 31, "seek": 18704, "start": 208.16, "end": 214.39999999999998, "text": " is a good thing. Although some people like Elon must say that, let's not build it because it will", "tokens": [51420, 307, 257, 665, 551, 13, 5780, 512, 561, 411, 28498, 1633, 584, 300, 11, 718, 311, 406, 1322, 309, 570, 309, 486, 51732], "temperature": 0.0, "avg_logprob": -0.11836533797414679, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.008238330483436584}, {"id": 32, "seek": 21440, "start": 214.4, "end": 224.56, "text": " straight away kill us all, right? Well, we don't know, but I don't think it will. Okay, so I'm", "tokens": [50364, 2997, 1314, 1961, 505, 439, 11, 558, 30, 1042, 11, 321, 500, 380, 458, 11, 457, 286, 500, 380, 519, 309, 486, 13, 1033, 11, 370, 286, 478, 50872], "temperature": 0.0, "avg_logprob": -0.15468114965102253, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.025211360305547714}, {"id": 33, "seek": 21440, "start": 224.56, "end": 230.8, "text": " the anti-Elon Musk, okay? I'm the opposite. Okay, so I'm an optimist, he's a pessimist.", "tokens": [50872, 264, 6061, 12, 36, 14864, 26019, 11, 1392, 30, 286, 478, 264, 6182, 13, 1033, 11, 370, 286, 478, 364, 5028, 468, 11, 415, 311, 257, 37399, 468, 13, 51184], "temperature": 0.0, "avg_logprob": -0.15468114965102253, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.025211360305547714}, {"id": 34, "seek": 21440, "start": 231.44, "end": 237.04000000000002, "text": " So he's a good entrepreneur anyway. So what about all of these things here? AlphaGo,", "tokens": [51216, 407, 415, 311, 257, 665, 14307, 4033, 13, 407, 437, 466, 439, 295, 613, 721, 510, 30, 20588, 12104, 11, 51496], "temperature": 0.0, "avg_logprob": -0.15468114965102253, "compression_ratio": 1.459016393442623, "no_speech_prob": 0.025211360305547714}, {"id": 35, "seek": 23704, "start": 238.0, "end": 245.68, "text": " this is DeepMind in London, I'm sure we all saw on TV, AlphaGo beating the best go player in the", "tokens": [50412, 341, 307, 14895, 44, 471, 294, 7042, 11, 286, 478, 988, 321, 439, 1866, 322, 3558, 11, 20588, 12104, 13497, 264, 1151, 352, 4256, 294, 264, 50796], "temperature": 0.0, "avg_logprob": -0.16159601564760562, "compression_ratio": 1.467005076142132, "no_speech_prob": 0.246913880109787}, {"id": 36, "seek": 23704, "start": 245.68, "end": 256.71999999999997, "text": " world, was that AI, was that AGI? AlphaStar, it's a new project to beat the world's best video game", "tokens": [50796, 1002, 11, 390, 300, 7318, 11, 390, 300, 316, 26252, 30, 20588, 24659, 11, 309, 311, 257, 777, 1716, 281, 4224, 264, 1002, 311, 1151, 960, 1216, 51348], "temperature": 0.0, "avg_logprob": -0.16159601564760562, "compression_ratio": 1.467005076142132, "no_speech_prob": 0.246913880109787}, {"id": 37, "seek": 23704, "start": 256.71999999999997, "end": 261.92, "text": " players, a little bit more general one might argue than just playing a board game. DeepBlue,", "tokens": [51348, 4150, 11, 257, 707, 857, 544, 2674, 472, 1062, 9695, 813, 445, 2433, 257, 3150, 1216, 13, 14895, 45231, 11, 51608], "temperature": 0.0, "avg_logprob": -0.16159601564760562, "compression_ratio": 1.467005076142132, "no_speech_prob": 0.246913880109787}, {"id": 38, "seek": 26192, "start": 261.92, "end": 267.68, "text": " IBM's DeepBlue and Chess, Landmark, and IBM Watson, that's actually natural language processing,", "tokens": [50364, 23487, 311, 14895, 45231, 293, 761, 442, 11, 6607, 5638, 11, 293, 23487, 25640, 11, 300, 311, 767, 3303, 2856, 9007, 11, 50652], "temperature": 0.0, "avg_logprob": -0.13742917159508014, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.17008724808692932}, {"id": 39, "seek": 26192, "start": 267.68, "end": 272.8, "text": " so that's quite clever, that's quite getting a little closer to AGI maybe, because it's having", "tokens": [50652, 370, 300, 311, 1596, 13494, 11, 300, 311, 1596, 1242, 257, 707, 4966, 281, 316, 26252, 1310, 11, 570, 309, 311, 1419, 50908], "temperature": 0.0, "avg_logprob": -0.13742917159508014, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.17008724808692932}, {"id": 40, "seek": 26192, "start": 272.8, "end": 278.16, "text": " to understand language, but was it just doing it statistically? Was it just a massive computer", "tokens": [50908, 281, 1223, 2856, 11, 457, 390, 309, 445, 884, 309, 36478, 30, 3027, 309, 445, 257, 5994, 3820, 51176], "temperature": 0.0, "avg_logprob": -0.13742917159508014, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.17008724808692932}, {"id": 41, "seek": 26192, "start": 279.12, "end": 285.68, "text": " hardware system that could crunch numbers really well and just do everything statistically? Is", "tokens": [51224, 8837, 1185, 300, 727, 13386, 3547, 534, 731, 293, 445, 360, 1203, 36478, 30, 1119, 51552], "temperature": 0.0, "avg_logprob": -0.13742917159508014, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.17008724808692932}, {"id": 42, "seek": 28568, "start": 285.76, "end": 293.2, "text": " it how we learn language and understand language? I would argue no. So actually, all of those are", "tokens": [50368, 309, 577, 321, 1466, 2856, 293, 1223, 2856, 30, 286, 576, 9695, 572, 13, 407, 767, 11, 439, 295, 729, 366, 50740], "temperature": 0.0, "avg_logprob": -0.13485785612125986, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.02148638851940632}, {"id": 43, "seek": 28568, "start": 293.2, "end": 299.92, "text": " just narrow AI, they're just statistical mathematical analysis of big data sets, okay? So it's not really", "tokens": [50740, 445, 9432, 7318, 11, 436, 434, 445, 22820, 18894, 5215, 295, 955, 1412, 6352, 11, 1392, 30, 407, 309, 311, 406, 534, 51076], "temperature": 0.0, "avg_logprob": -0.13485785612125986, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.02148638851940632}, {"id": 44, "seek": 28568, "start": 299.92, "end": 307.12, "text": " how the brain does anything. If it were, I mean we do all of that in that little three pound thing", "tokens": [51076, 577, 264, 3567, 775, 1340, 13, 759, 309, 645, 11, 286, 914, 321, 360, 439, 295, 300, 294, 300, 707, 1045, 12013, 551, 51436], "temperature": 0.0, "avg_logprob": -0.13485785612125986, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.02148638851940632}, {"id": 45, "seek": 28568, "start": 307.12, "end": 312.88, "text": " above our sitting, above our shoulders, right? We don't need huge data centers, so clearly biology", "tokens": [51436, 3673, 527, 3798, 11, 3673, 527, 10245, 11, 558, 30, 492, 500, 380, 643, 2603, 1412, 10898, 11, 370, 4448, 14956, 51724], "temperature": 0.0, "avg_logprob": -0.13485785612125986, "compression_ratio": 1.6300813008130082, "no_speech_prob": 0.02148638851940632}, {"id": 46, "seek": 31288, "start": 312.88, "end": 318.48, "text": " is doing it in a slightly different way, okay? So how is it doing it and how is it different?", "tokens": [50364, 307, 884, 309, 294, 257, 4748, 819, 636, 11, 1392, 30, 407, 577, 307, 309, 884, 309, 293, 577, 307, 309, 819, 30, 50644], "temperature": 0.0, "avg_logprob": -0.1274552345275879, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.01979403756558895}, {"id": 47, "seek": 31288, "start": 319.2, "end": 323.6, "text": " So first of all, to build something, we have to understand what we're building. What is", "tokens": [50680, 407, 700, 295, 439, 11, 281, 1322, 746, 11, 321, 362, 281, 1223, 437, 321, 434, 2390, 13, 708, 307, 50900], "temperature": 0.0, "avg_logprob": -0.1274552345275879, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.01979403756558895}, {"id": 48, "seek": 31288, "start": 323.6, "end": 328.96, "text": " intelligence, general intelligence? Well, it's all these things, right? So we don't just classify", "tokens": [50900, 7599, 11, 2674, 7599, 30, 1042, 11, 309, 311, 439, 613, 721, 11, 558, 30, 407, 321, 500, 380, 445, 33872, 51168], "temperature": 0.0, "avg_logprob": -0.1274552345275879, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.01979403756558895}, {"id": 49, "seek": 31288, "start": 328.96, "end": 335.84, "text": " things, we do all of that. I won't read them out, because I've only got 30 minutes and sometimes", "tokens": [51168, 721, 11, 321, 360, 439, 295, 300, 13, 286, 1582, 380, 1401, 552, 484, 11, 570, 286, 600, 787, 658, 2217, 2077, 293, 2171, 51512], "temperature": 0.0, "avg_logprob": -0.1274552345275879, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.01979403756558895}, {"id": 50, "seek": 31288, "start": 335.84, "end": 340.64, "text": " I give this talk, it's an hour, but there's basically nine types of intelligence there,", "tokens": [51512, 286, 976, 341, 751, 11, 309, 311, 364, 1773, 11, 457, 456, 311, 1936, 4949, 3467, 295, 7599, 456, 11, 51752], "temperature": 0.0, "avg_logprob": -0.1274552345275879, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.01979403756558895}, {"id": 51, "seek": 34064, "start": 341.36, "end": 346.47999999999996, "text": " maybe even 10. And this guy at Harvard, Howard Gardner, just mapped it all out. See,", "tokens": [50400, 1310, 754, 1266, 13, 400, 341, 2146, 412, 13378, 11, 17626, 12882, 1193, 11, 445, 33318, 309, 439, 484, 13, 3008, 11, 50656], "temperature": 0.0, "avg_logprob": -0.16773748397827148, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.005617085844278336}, {"id": 52, "seek": 34064, "start": 347.03999999999996, "end": 356.32, "text": " existential thinking language, we can do math using ANNs, but the rest of it is pretty much", "tokens": [50684, 37133, 1953, 2856, 11, 321, 393, 360, 5221, 1228, 5252, 45, 82, 11, 457, 264, 1472, 295, 309, 307, 1238, 709, 51148], "temperature": 0.0, "avg_logprob": -0.16773748397827148, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.005617085844278336}, {"id": 53, "seek": 34064, "start": 356.32, "end": 363.36, "text": " music, creating art, spatial navigation, that's all. We can do all of that in three pound. We", "tokens": [51148, 1318, 11, 4084, 1523, 11, 23598, 17346, 11, 300, 311, 439, 13, 492, 393, 360, 439, 295, 300, 294, 1045, 12013, 13, 492, 51500], "temperature": 0.0, "avg_logprob": -0.16773748397827148, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.005617085844278336}, {"id": 54, "seek": 34064, "start": 363.36, "end": 369.2, "text": " don't need a huge data center, hardware cluster of GPUs. So what's different? What are we missing?", "tokens": [51500, 500, 380, 643, 257, 2603, 1412, 3056, 11, 8837, 13630, 295, 18407, 82, 13, 407, 437, 311, 819, 30, 708, 366, 321, 5361, 30, 51792], "temperature": 0.0, "avg_logprob": -0.16773748397827148, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.005617085844278336}, {"id": 55, "seek": 36920, "start": 369.28, "end": 374.4, "text": " Okay. Well, first of all, how far have we come? Like I said, the mathematical part,", "tokens": [50368, 1033, 13, 1042, 11, 700, 295, 439, 11, 577, 1400, 362, 321, 808, 30, 1743, 286, 848, 11, 264, 18894, 644, 11, 50624], "temperature": 0.0, "avg_logprob": -0.11552119741634446, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.003909039776772261}, {"id": 56, "seek": 36920, "start": 374.4, "end": 378.24, "text": " we're like 50%, we're pretty good, we're not bad, we're about halfway there, linguistic,", "tokens": [50624, 321, 434, 411, 2625, 8923, 321, 434, 1238, 665, 11, 321, 434, 406, 1578, 11, 321, 434, 466, 15461, 456, 11, 43002, 11, 50816], "temperature": 0.0, "avg_logprob": -0.11552119741634446, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.003909039776772261}, {"id": 57, "seek": 36920, "start": 378.24, "end": 385.12, "text": " but it's only statistical analysis. Spatial navigation, self-driving cars, robots who can", "tokens": [50816, 457, 309, 311, 787, 22820, 5215, 13, 1738, 267, 831, 17346, 11, 2698, 12, 47094, 5163, 11, 14733, 567, 393, 51160], "temperature": 0.0, "avg_logprob": -0.11552119741634446, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.003909039776772261}, {"id": 58, "seek": 36920, "start": 385.12, "end": 392.48, "text": " navigate through systems. I'd say we're about something called SLAM. I'd say we're about 50%", "tokens": [51160, 12350, 807, 3652, 13, 286, 1116, 584, 321, 434, 466, 746, 1219, 22999, 2865, 13, 286, 1116, 584, 321, 434, 466, 2625, 4, 51528], "temperature": 0.0, "avg_logprob": -0.11552119741634446, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.003909039776772261}, {"id": 59, "seek": 39248, "start": 392.48, "end": 401.44, "text": " there, that's the algorithm, simultaneous mapping and I forgot what the LAM stands for,", "tokens": [50364, 456, 11, 300, 311, 264, 9284, 11, 46218, 18350, 293, 286, 5298, 437, 264, 441, 2865, 7382, 337, 11, 50812], "temperature": 0.0, "avg_logprob": -0.14706974029541015, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.14008964598178864}, {"id": 60, "seek": 39248, "start": 401.44, "end": 411.04, "text": " but don't worry. We're about 50% there. You've probably seen simultaneous localization and mapping.", "tokens": [50812, 457, 500, 380, 3292, 13, 492, 434, 466, 2625, 4, 456, 13, 509, 600, 1391, 1612, 46218, 2654, 2144, 293, 18350, 13, 51292], "temperature": 0.0, "avg_logprob": -0.14706974029541015, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.14008964598178864}, {"id": 61, "seek": 39248, "start": 411.04, "end": 416.56, "text": " You've probably seen the Atlas, you know, robot that do flips and run around outside and do good", "tokens": [51292, 509, 600, 1391, 1612, 264, 32485, 11, 291, 458, 11, 7881, 300, 360, 40249, 293, 1190, 926, 2380, 293, 360, 665, 51568], "temperature": 0.0, "avg_logprob": -0.14706974029541015, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.14008964598178864}, {"id": 62, "seek": 41656, "start": 416.64, "end": 424.88, "text": " stuff, busts and dynamics. So that's why I'm giving it a generous 50%. We do a lot more than that.", "tokens": [50368, 1507, 11, 19432, 82, 293, 15679, 13, 407, 300, 311, 983, 286, 478, 2902, 309, 257, 14537, 2625, 6856, 492, 360, 257, 688, 544, 813, 300, 13, 50780], "temperature": 0.0, "avg_logprob": -0.11809178761073522, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.032240357249975204}, {"id": 63, "seek": 41656, "start": 424.88, "end": 430.96, "text": " We can do gymnastics, we can run around, we learn stuff very quickly, we don't need millions of", "tokens": [50780, 492, 393, 360, 48461, 11, 321, 393, 1190, 926, 11, 321, 1466, 1507, 588, 2661, 11, 321, 500, 380, 643, 6803, 295, 51084], "temperature": 0.0, "avg_logprob": -0.11809178761073522, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.032240357249975204}, {"id": 64, "seek": 41656, "start": 430.96, "end": 436.4, "text": " datasets to train, but as we go through that list of nine types of intelligence, it gets really,", "tokens": [51084, 42856, 281, 3847, 11, 457, 382, 321, 352, 807, 300, 1329, 295, 4949, 3467, 295, 7599, 11, 309, 2170, 534, 11, 51356], "temperature": 0.0, "avg_logprob": -0.11809178761073522, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.032240357249975204}, {"id": 65, "seek": 41656, "start": 436.4, "end": 444.56, "text": " it just gets worse, right? Robots understanding each other or even algorithms running on a", "tokens": [51356, 309, 445, 2170, 5324, 11, 558, 30, 5424, 1971, 3701, 1184, 661, 420, 754, 14642, 2614, 322, 257, 51764], "temperature": 0.0, "avg_logprob": -0.11809178761073522, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.032240357249975204}, {"id": 66, "seek": 44456, "start": 444.56, "end": 450.16, "text": " computer virtual sort of intelligence. Intrapersonal understanding themselves and existential,", "tokens": [50364, 3820, 6374, 1333, 295, 7599, 13, 5681, 4007, 3953, 304, 3701, 2969, 293, 37133, 11, 50644], "temperature": 0.0, "avg_logprob": -0.16440081066555448, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.015555670484900475}, {"id": 67, "seek": 44456, "start": 450.96, "end": 456.56, "text": " you know, show me an algorithm or a robot that kind of questions why it's there,", "tokens": [50684, 291, 458, 11, 855, 385, 364, 9284, 420, 257, 7881, 300, 733, 295, 1651, 983, 309, 311, 456, 11, 50964], "temperature": 0.0, "avg_logprob": -0.16440081066555448, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.015555670484900475}, {"id": 68, "seek": 44456, "start": 456.56, "end": 462.0, "text": " or even understands that it exists, it's kind of zero. So we haven't figured that intelligence", "tokens": [50964, 420, 754, 15146, 300, 309, 8198, 11, 309, 311, 733, 295, 4018, 13, 407, 321, 2378, 380, 8932, 300, 7599, 51236], "temperature": 0.0, "avg_logprob": -0.16440081066555448, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.015555670484900475}, {"id": 69, "seek": 44456, "start": 462.0, "end": 470.72, "text": " out at all. So the brain is pretty special, right? Biology is kind of special. We could argue chimpanzees,", "tokens": [51236, 484, 412, 439, 13, 407, 264, 3567, 307, 1238, 2121, 11, 558, 30, 48132, 307, 733, 295, 2121, 13, 492, 727, 9695, 18375, 48410, 279, 11, 51672], "temperature": 0.0, "avg_logprob": -0.16440081066555448, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.015555670484900475}, {"id": 70, "seek": 47072, "start": 470.72, "end": 476.72, "text": " self-aware, well, yes, right, a dog, cats, probably. And as you go, you know, snails,", "tokens": [50364, 2698, 12, 17074, 11, 731, 11, 2086, 11, 558, 11, 257, 3000, 11, 11111, 11, 1391, 13, 400, 382, 291, 352, 11, 291, 458, 11, 14528, 4174, 11, 50664], "temperature": 0.0, "avg_logprob": -0.15321672323978308, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.014397569932043552}, {"id": 71, "seek": 47072, "start": 476.72, "end": 483.44000000000005, "text": " maybe not, you know, bacteria, no. So there's clearly a continuum in what makes us a little", "tokens": [50664, 1310, 406, 11, 291, 458, 11, 11763, 11, 572, 13, 407, 456, 311, 4448, 257, 36120, 294, 437, 1669, 505, 257, 707, 51000], "temperature": 0.0, "avg_logprob": -0.15321672323978308, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.014397569932043552}, {"id": 72, "seek": 47072, "start": 483.44000000000005, "end": 488.8, "text": " different is our neocortex, that sort of outer layer of the brain. So we kind of have to figure", "tokens": [51000, 819, 307, 527, 408, 905, 36143, 11, 300, 1333, 295, 10847, 4583, 295, 264, 3567, 13, 407, 321, 733, 295, 362, 281, 2573, 51268], "temperature": 0.0, "avg_logprob": -0.15321672323978308, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.014397569932043552}, {"id": 73, "seek": 47072, "start": 488.8, "end": 493.20000000000005, "text": " out how that works, basically. But we've got all this other stuff in the brain like the amygdala", "tokens": [51268, 484, 577, 300, 1985, 11, 1936, 13, 583, 321, 600, 658, 439, 341, 661, 1507, 294, 264, 3567, 411, 264, 669, 18103, 67, 5159, 51488], "temperature": 0.0, "avg_logprob": -0.15321672323978308, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.014397569932043552}, {"id": 74, "seek": 47072, "start": 493.20000000000005, "end": 498.40000000000003, "text": " for emotional intelligence, you know, the reptilian brain and there's sort of layers, you can trace it.", "tokens": [51488, 337, 6863, 7599, 11, 291, 458, 11, 264, 29143, 48666, 3567, 293, 456, 311, 1333, 295, 7914, 11, 291, 393, 13508, 309, 13, 51748], "temperature": 0.0, "avg_logprob": -0.15321672323978308, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.014397569932043552}, {"id": 75, "seek": 49840, "start": 498.4, "end": 503.2, "text": " In fact, you know, as babies are born and embryos develop over the nine months,", "tokens": [50364, 682, 1186, 11, 291, 458, 11, 382, 10917, 366, 4232, 293, 31588, 329, 1499, 670, 264, 4949, 2493, 11, 50604], "temperature": 0.0, "avg_logprob": -0.15514829535233346, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.003853050759062171}, {"id": 76, "seek": 49840, "start": 504.64, "end": 508.88, "text": " you can see, you know, evolution, it starts off, you know, with the, you know,", "tokens": [50676, 291, 393, 536, 11, 291, 458, 11, 9303, 11, 309, 3719, 766, 11, 291, 458, 11, 365, 264, 11, 291, 458, 11, 50888], "temperature": 0.0, "avg_logprob": -0.15514829535233346, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.003853050759062171}, {"id": 77, "seek": 49840, "start": 508.88, "end": 516.72, "text": " reptilian brain and it goes out monkey and then, you know, humans as we develop in the womb. So,", "tokens": [50888, 29143, 48666, 3567, 293, 309, 1709, 484, 17847, 293, 550, 11, 291, 458, 11, 6255, 382, 321, 1499, 294, 264, 34310, 13, 407, 11, 51280], "temperature": 0.0, "avg_logprob": -0.15514829535233346, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.003853050759062171}, {"id": 78, "seek": 49840, "start": 516.72, "end": 522.16, "text": " you know, it's all, all of that evolution is still captured, all that information is actually", "tokens": [51280, 291, 458, 11, 309, 311, 439, 11, 439, 295, 300, 9303, 307, 920, 11828, 11, 439, 300, 1589, 307, 767, 51552], "temperature": 0.0, "avg_logprob": -0.15514829535233346, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.003853050759062171}, {"id": 79, "seek": 52216, "start": 522.16, "end": 528.9599999999999, "text": " captured by biology. It's just that last layer of the neocortex that makes us be able to come up", "tokens": [50364, 11828, 538, 14956, 13, 467, 311, 445, 300, 1036, 4583, 295, 264, 408, 905, 36143, 300, 1669, 505, 312, 1075, 281, 808, 493, 50704], "temperature": 0.0, "avg_logprob": -0.13287633549083364, "compression_ratio": 1.58, "no_speech_prob": 0.08710496127605438}, {"id": 80, "seek": 52216, "start": 528.9599999999999, "end": 535.28, "text": " with, you know, science, special theory, relativity, whatever, you know, that, that. So what are we", "tokens": [50704, 365, 11, 291, 458, 11, 3497, 11, 2121, 5261, 11, 45675, 11, 2035, 11, 291, 458, 11, 300, 11, 300, 13, 407, 437, 366, 321, 51020], "temperature": 0.0, "avg_logprob": -0.13287633549083364, "compression_ratio": 1.58, "no_speech_prob": 0.08710496127605438}, {"id": 81, "seek": 52216, "start": 535.28, "end": 542.9599999999999, "text": " missing? Why can't we do that yet in TensorFlow? Okay, why can't Google or DeepMind do that yet?", "tokens": [51020, 5361, 30, 1545, 393, 380, 321, 360, 300, 1939, 294, 37624, 30, 1033, 11, 983, 393, 380, 3329, 420, 14895, 44, 471, 360, 300, 1939, 30, 51404], "temperature": 0.0, "avg_logprob": -0.13287633549083364, "compression_ratio": 1.58, "no_speech_prob": 0.08710496127605438}, {"id": 82, "seek": 52216, "start": 542.9599999999999, "end": 548.3199999999999, "text": " So how will we get there? Well, it takes a village to create a child and I'm going to argue it takes,", "tokens": [51404, 407, 577, 486, 321, 483, 456, 30, 1042, 11, 309, 2516, 257, 7288, 281, 1884, 257, 1440, 293, 286, 478, 516, 281, 9695, 309, 2516, 11, 51672], "temperature": 0.0, "avg_logprob": -0.13287633549083364, "compression_ratio": 1.58, "no_speech_prob": 0.08710496127605438}, {"id": 83, "seek": 54832, "start": 548.32, "end": 551.9200000000001, "text": " it's going to take a big community to create AGI. We're going to need computer scientists,", "tokens": [50364, 309, 311, 516, 281, 747, 257, 955, 1768, 281, 1884, 316, 26252, 13, 492, 434, 516, 281, 643, 3820, 7708, 11, 50544], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 84, "seek": 54832, "start": 552.8000000000001, "end": 556.5600000000001, "text": " physicists to understand the physics of the brain, neuroscientists, clearly,", "tokens": [50588, 48716, 281, 1223, 264, 10649, 295, 264, 3567, 11, 28813, 5412, 1751, 11, 4448, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 85, "seek": 54832, "start": 557.6, "end": 562.8000000000001, "text": " and also psychologists. So what I'm seeing really at the moment where these teams trying to build", "tokens": [50828, 293, 611, 41562, 13, 407, 437, 286, 478, 2577, 534, 412, 264, 1623, 689, 613, 5491, 1382, 281, 1322, 51088], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 86, "seek": 54832, "start": 563.44, "end": 567.84, "text": " AGI or AI are just computer scientists, you know, just computer scientists, you know,", "tokens": [51120, 316, 26252, 420, 7318, 366, 445, 3820, 7708, 11, 291, 458, 11, 445, 3820, 7708, 11, 291, 458, 11, 51340], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 87, "seek": 54832, "start": 567.84, "end": 572.5600000000001, "text": " you're clever people, they have PhDs and computer science, which involves a lot of math and", "tokens": [51340, 291, 434, 13494, 561, 11, 436, 362, 14476, 82, 293, 3820, 3497, 11, 597, 11626, 257, 688, 295, 5221, 293, 51576], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 88, "seek": 54832, "start": 572.5600000000001, "end": 578.0, "text": " understanding hardware and algorithm, algorithmic complexity. But it's not really", "tokens": [51576, 3701, 8837, 293, 9284, 11, 9284, 299, 14024, 13, 583, 309, 311, 406, 534, 51848], "temperature": 0.0, "avg_logprob": -0.1491538344836626, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.024757174775004387}, {"id": 89, "seek": 57800, "start": 578.0, "end": 584.24, "text": " understanding how much about biology at all. Okay, so we're going to need a whole bunch of people.", "tokens": [50364, 3701, 577, 709, 466, 14956, 412, 439, 13, 1033, 11, 370, 321, 434, 516, 281, 643, 257, 1379, 3840, 295, 561, 13, 50676], "temperature": 0.0, "avg_logprob": -0.12117607153735115, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.005232029594480991}, {"id": 90, "seek": 57800, "start": 584.8, "end": 589.92, "text": " And so I'll speed up a little bit now. I've kind of laid the foundations for what we might need.", "tokens": [50704, 400, 370, 286, 603, 3073, 493, 257, 707, 857, 586, 13, 286, 600, 733, 295, 9897, 264, 22467, 337, 437, 321, 1062, 643, 13, 50960], "temperature": 0.0, "avg_logprob": -0.12117607153735115, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.005232029594480991}, {"id": 91, "seek": 57800, "start": 590.72, "end": 596.96, "text": " So this is basically what we've got in hardware. So this is how biology does it in hardware. So,", "tokens": [51000, 407, 341, 307, 1936, 437, 321, 600, 658, 294, 8837, 13, 407, 341, 307, 577, 14956, 775, 309, 294, 8837, 13, 407, 11, 51312], "temperature": 0.0, "avg_logprob": -0.12117607153735115, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.005232029594480991}, {"id": 92, "seek": 57800, "start": 596.96, "end": 603.52, "text": " you know, like I mentioned, we have a continuum from bacteria. That's a simple, C elegance is the", "tokens": [51312, 291, 458, 11, 411, 286, 2835, 11, 321, 362, 257, 36120, 490, 11763, 13, 663, 311, 257, 2199, 11, 383, 14459, 719, 307, 264, 51640], "temperature": 0.0, "avg_logprob": -0.12117607153735115, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.005232029594480991}, {"id": 93, "seek": 60352, "start": 603.52, "end": 609.76, "text": " simplest biological system with a central nervous system, it has, I think, about 300 neurons, then", "tokens": [50364, 22811, 13910, 1185, 365, 257, 5777, 6296, 1185, 11, 309, 575, 11, 286, 519, 11, 466, 6641, 22027, 11, 550, 50676], "temperature": 0.0, "avg_logprob": -0.14109474478416073, "compression_ratio": 1.7972350230414746, "no_speech_prob": 0.009830290451645851}, {"id": 94, "seek": 60352, "start": 609.76, "end": 614.88, "text": " the bumblebee, the humble bumblebee with about a million, a few million neurons, and then us with", "tokens": [50676, 264, 13309, 638, 24872, 11, 264, 16735, 13309, 638, 24872, 365, 466, 257, 2459, 11, 257, 1326, 2459, 22027, 11, 293, 550, 505, 365, 50932], "temperature": 0.0, "avg_logprob": -0.14109474478416073, "compression_ratio": 1.7972350230414746, "no_speech_prob": 0.009830290451645851}, {"id": 95, "seek": 60352, "start": 614.88, "end": 623.1999999999999, "text": " about 80 billion or 100 billion neurons. Okay, so what, you know, what basically, maybe if we", "tokens": [50932, 466, 4688, 5218, 420, 2319, 5218, 22027, 13, 1033, 11, 370, 437, 11, 291, 458, 11, 437, 1936, 11, 1310, 498, 321, 51348], "temperature": 0.0, "avg_logprob": -0.14109474478416073, "compression_ratio": 1.7972350230414746, "no_speech_prob": 0.009830290451645851}, {"id": 96, "seek": 60352, "start": 623.1999999999999, "end": 628.16, "text": " start at the simple, the C elegance and then build a bumblebee, then maybe one day, you know, we'll", "tokens": [51348, 722, 412, 264, 2199, 11, 264, 383, 14459, 719, 293, 550, 1322, 257, 13309, 638, 24872, 11, 550, 1310, 472, 786, 11, 291, 458, 11, 321, 603, 51596], "temperature": 0.0, "avg_logprob": -0.14109474478416073, "compression_ratio": 1.7972350230414746, "no_speech_prob": 0.009830290451645851}, {"id": 97, "seek": 62816, "start": 628.16, "end": 635.12, "text": " get to us. That's one sort of thought. The other, the other observation really is that nature is", "tokens": [50364, 483, 281, 505, 13, 663, 311, 472, 1333, 295, 1194, 13, 440, 661, 11, 264, 661, 14816, 534, 307, 300, 3687, 307, 50712], "temperature": 0.0, "avg_logprob": -0.16762226759785354, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.010944247245788574}, {"id": 98, "seek": 62816, "start": 635.12, "end": 641.28, "text": " very hierarchical. You know, we built neurons, built of, they're not magic, you know, the built", "tokens": [50712, 588, 35250, 804, 13, 509, 458, 11, 321, 3094, 22027, 11, 3094, 295, 11, 436, 434, 406, 5585, 11, 291, 458, 11, 264, 3094, 51020], "temperature": 0.0, "avg_logprob": -0.16762226759785354, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.010944247245788574}, {"id": 99, "seek": 62816, "start": 641.28, "end": 647.28, "text": " of atoms, molecules. And then if we just go up the different layers, we have synapses, neurons,", "tokens": [51020, 295, 16871, 11, 13093, 13, 400, 550, 498, 321, 445, 352, 493, 264, 819, 7914, 11, 321, 362, 5451, 2382, 279, 11, 22027, 11, 51320], "temperature": 0.0, "avg_logprob": -0.16762226759785354, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.010944247245788574}, {"id": 100, "seek": 62816, "start": 647.28, "end": 653.6, "text": " and collection of neurons as connectome. So these 80 billion neurons are organized into some kind of", "tokens": [51320, 293, 5765, 295, 22027, 382, 1745, 423, 13, 407, 613, 4688, 5218, 22027, 366, 9983, 666, 512, 733, 295, 51636], "temperature": 0.0, "avg_logprob": -0.16762226759785354, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.010944247245788574}, {"id": 101, "seek": 65360, "start": 653.6800000000001, "end": 660.0, "text": " structure. Maybe, you know, we should start there. So the question here is, you know, what level do", "tokens": [50368, 3877, 13, 2704, 11, 291, 458, 11, 321, 820, 722, 456, 13, 407, 264, 1168, 510, 307, 11, 291, 458, 11, 437, 1496, 360, 50684], "temperature": 0.0, "avg_logprob": -0.0906980832417806, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008621401153504848}, {"id": 102, "seek": 65360, "start": 660.0, "end": 665.76, "text": " we start at? Do we have to start at molecules or can we start at neurons or should we start a little", "tokens": [50684, 321, 722, 412, 30, 1144, 321, 362, 281, 722, 412, 13093, 420, 393, 321, 722, 412, 22027, 420, 820, 321, 722, 257, 707, 50972], "temperature": 0.0, "avg_logprob": -0.0906980832417806, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008621401153504848}, {"id": 103, "seek": 65360, "start": 665.76, "end": 672.08, "text": " more holistically at the connectome? You know, and on and on up until the central nervous system,", "tokens": [50972, 544, 4091, 20458, 412, 264, 1745, 423, 30, 509, 458, 11, 293, 322, 293, 322, 493, 1826, 264, 5777, 6296, 1185, 11, 51288], "temperature": 0.0, "avg_logprob": -0.0906980832417806, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008621401153504848}, {"id": 104, "seek": 65360, "start": 672.08, "end": 678.4, "text": " us, which is about a meter in dimensions. So we're going from 10 to the minus 10 up to a meter.", "tokens": [51288, 505, 11, 597, 307, 466, 257, 9255, 294, 12819, 13, 407, 321, 434, 516, 490, 1266, 281, 264, 3175, 1266, 493, 281, 257, 9255, 13, 51604], "temperature": 0.0, "avg_logprob": -0.0906980832417806, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008621401153504848}, {"id": 105, "seek": 65360, "start": 678.4, "end": 682.96, "text": " So it's a hard problem. It's kind of no wonder we haven't solved it yet. There's a lot of physics", "tokens": [51604, 407, 309, 311, 257, 1152, 1154, 13, 467, 311, 733, 295, 572, 2441, 321, 2378, 380, 13041, 309, 1939, 13, 821, 311, 257, 688, 295, 10649, 51832], "temperature": 0.0, "avg_logprob": -0.0906980832417806, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.008621401153504848}, {"id": 106, "seek": 68296, "start": 682.96, "end": 690.64, "text": " in there. And so that's what it looks like. This is how nature has done it. It's complicated,", "tokens": [50364, 294, 456, 13, 400, 370, 300, 311, 437, 309, 1542, 411, 13, 639, 307, 577, 3687, 575, 1096, 309, 13, 467, 311, 6179, 11, 50748], "temperature": 0.0, "avg_logprob": -0.09417915344238281, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.0038215192034840584}, {"id": 107, "seek": 68296, "start": 690.64, "end": 696.48, "text": " isn't it? You know, I mean, do we need all that little tiny microstructure? Probably not, I might", "tokens": [50748, 1943, 380, 309, 30, 509, 458, 11, 286, 914, 11, 360, 321, 643, 439, 300, 707, 5870, 3123, 27494, 2885, 30, 9210, 406, 11, 286, 1062, 51040], "temperature": 0.0, "avg_logprob": -0.09417915344238281, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.0038215192034840584}, {"id": 108, "seek": 68296, "start": 696.48, "end": 703.84, "text": " argue. So you know, this is how, you know, what do we for in a half billion years of evolution", "tokens": [51040, 9695, 13, 407, 291, 458, 11, 341, 307, 577, 11, 291, 458, 11, 437, 360, 321, 337, 294, 257, 1922, 5218, 924, 295, 9303, 51408], "temperature": 0.0, "avg_logprob": -0.09417915344238281, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.0038215192034840584}, {"id": 109, "seek": 68296, "start": 703.84, "end": 710.88, "text": " on the earth, maybe a billion since the first sort of organisms, bacteria, whatever, the first,", "tokens": [51408, 322, 264, 4120, 11, 1310, 257, 5218, 1670, 264, 700, 1333, 295, 22110, 11, 11763, 11, 2035, 11, 264, 700, 11, 51760], "temperature": 0.0, "avg_logprob": -0.09417915344238281, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.0038215192034840584}, {"id": 110, "seek": 71088, "start": 710.88, "end": 716.4, "text": " you know, primitive life. So over that billion year, this is what this is what nature's ended", "tokens": [50364, 291, 458, 11, 28540, 993, 13, 407, 670, 300, 5218, 1064, 11, 341, 307, 437, 341, 307, 437, 3687, 311, 4590, 50640], "temperature": 0.0, "avg_logprob": -0.13323812636118088, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.004450312815606594}, {"id": 111, "seek": 71088, "start": 716.4, "end": 722.48, "text": " up with, right? This is what makes us intelligent, these things, right? You couldn't guess that.", "tokens": [50640, 493, 365, 11, 558, 30, 639, 307, 437, 1669, 505, 13232, 11, 613, 721, 11, 558, 30, 509, 2809, 380, 2041, 300, 13, 50944], "temperature": 0.0, "avg_logprob": -0.13323812636118088, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.004450312815606594}, {"id": 112, "seek": 71088, "start": 722.48, "end": 727.52, "text": " You start with a blank piece of paper, but this is just the universe we live in, the laws of physics.", "tokens": [50944, 509, 722, 365, 257, 8247, 2522, 295, 3035, 11, 457, 341, 307, 445, 264, 6445, 321, 1621, 294, 11, 264, 6064, 295, 10649, 13, 51196], "temperature": 0.0, "avg_logprob": -0.13323812636118088, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.004450312815606594}, {"id": 113, "seek": 71088, "start": 727.52, "end": 733.04, "text": " This is this is how we work. Okay. So there's no magic, but there's certainly a lot of", "tokens": [51196, 639, 307, 341, 307, 577, 321, 589, 13, 1033, 13, 407, 456, 311, 572, 5585, 11, 457, 456, 311, 3297, 257, 688, 295, 51472], "temperature": 0.0, "avg_logprob": -0.13323812636118088, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.004450312815606594}, {"id": 114, "seek": 71088, "start": 733.04, "end": 739.44, "text": " complication. It's a complicated looking thing. That's a neuron. Okay. And so the next level of", "tokens": [51472, 1209, 8758, 13, 467, 311, 257, 6179, 1237, 551, 13, 663, 311, 257, 34090, 13, 1033, 13, 400, 370, 264, 958, 1496, 295, 51792], "temperature": 0.0, "avg_logprob": -0.13323812636118088, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.004450312815606594}, {"id": 115, "seek": 73944, "start": 739.44, "end": 744.0, "text": " the hierarchy, we see that these neurons are kind of organized into some kind of structure", "tokens": [50364, 264, 22333, 11, 321, 536, 300, 613, 22027, 366, 733, 295, 9983, 666, 512, 733, 295, 3877, 50592], "temperature": 0.0, "avg_logprob": -0.11771972622491617, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.009510288015007973}, {"id": 116, "seek": 73944, "start": 744.0, "end": 751.12, "text": " called cortical columns, which each have about two, two million neurons. So maybe this is a", "tokens": [50592, 1219, 11278, 804, 13766, 11, 597, 1184, 362, 466, 732, 11, 732, 2459, 22027, 13, 407, 1310, 341, 307, 257, 50948], "temperature": 0.0, "avg_logprob": -0.11771972622491617, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.009510288015007973}, {"id": 117, "seek": 73944, "start": 751.12, "end": 756.1600000000001, "text": " good level to start. Maybe we don't have to go right down to all that complicated structure,", "tokens": [50948, 665, 1496, 281, 722, 13, 2704, 321, 500, 380, 362, 281, 352, 558, 760, 281, 439, 300, 6179, 3877, 11, 51200], "temperature": 0.0, "avg_logprob": -0.11771972622491617, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.009510288015007973}, {"id": 118, "seek": 73944, "start": 756.1600000000001, "end": 760.96, "text": " maybe here. So that's kind of an interesting thing that we know. And then up onto the connectome,", "tokens": [51200, 1310, 510, 13, 407, 300, 311, 733, 295, 364, 1880, 551, 300, 321, 458, 13, 400, 550, 493, 3911, 264, 1745, 423, 11, 51440], "temperature": 0.0, "avg_logprob": -0.11771972622491617, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.009510288015007973}, {"id": 119, "seek": 73944, "start": 761.6, "end": 765.84, "text": " and then the central nervous system. If we want to build a robot, we need that those flips,", "tokens": [51472, 293, 550, 264, 5777, 6296, 1185, 13, 759, 321, 528, 281, 1322, 257, 7881, 11, 321, 643, 300, 729, 40249, 11, 51684], "temperature": 0.0, "avg_logprob": -0.11771972622491617, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.009510288015007973}, {"id": 120, "seek": 76584, "start": 765.84, "end": 770.24, "text": " we'll probably need all of that connected to the brain at the top. Okay. So", "tokens": [50364, 321, 603, 1391, 643, 439, 295, 300, 4582, 281, 264, 3567, 412, 264, 1192, 13, 1033, 13, 407, 50584], "temperature": 0.0, "avg_logprob": -0.11214654105050223, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.008406050503253937}, {"id": 121, "seek": 76584, "start": 770.88, "end": 776.4, "text": " and then we have societies where we're organized into societies. Bees are, you know,", "tokens": [50616, 293, 550, 321, 362, 19329, 689, 321, 434, 9983, 666, 19329, 13, 879, 279, 366, 11, 291, 458, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11214654105050223, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.008406050503253937}, {"id": 122, "seek": 76584, "start": 776.4, "end": 782.48, "text": " in their swarms and humans in their villages, towns, cities, countries, and then the global", "tokens": [50892, 294, 641, 1693, 19537, 293, 6255, 294, 641, 20444, 11, 18104, 11, 6486, 11, 3517, 11, 293, 550, 264, 4338, 51196], "temperature": 0.0, "avg_logprob": -0.11214654105050223, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.008406050503253937}, {"id": 123, "seek": 76584, "start": 782.48, "end": 788.08, "text": " national community. So there's all these layers of hierarchy, which are intelligent, right? So,", "tokens": [51196, 4048, 1768, 13, 407, 456, 311, 439, 613, 7914, 295, 22333, 11, 597, 366, 13232, 11, 558, 30, 407, 11, 51476], "temperature": 0.0, "avg_logprob": -0.11214654105050223, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.008406050503253937}, {"id": 124, "seek": 76584, "start": 788.08, "end": 793.76, "text": " you know, we have this kind of macro meta intelligence built into communities and systems", "tokens": [51476, 291, 458, 11, 321, 362, 341, 733, 295, 18887, 19616, 7599, 3094, 666, 4456, 293, 3652, 51760], "temperature": 0.0, "avg_logprob": -0.11214654105050223, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.008406050503253937}, {"id": 125, "seek": 79376, "start": 793.76, "end": 798.64, "text": " of communities, which has enabled us to, you know, survive reproduced into the next generation.", "tokens": [50364, 295, 4456, 11, 597, 575, 15172, 505, 281, 11, 291, 458, 11, 7867, 11408, 1232, 666, 264, 958, 5125, 13, 50608], "temperature": 0.0, "avg_logprob": -0.09002749463345142, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003052634885534644}, {"id": 126, "seek": 79376, "start": 800.08, "end": 805.2, "text": " So, okay. So that's biology. That's how it works. That's how it does it. That's what we know,", "tokens": [50680, 407, 11, 1392, 13, 407, 300, 311, 14956, 13, 663, 311, 577, 309, 1985, 13, 663, 311, 577, 309, 775, 309, 13, 663, 311, 437, 321, 458, 11, 50936], "temperature": 0.0, "avg_logprob": -0.09002749463345142, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003052634885534644}, {"id": 127, "seek": 79376, "start": 805.2, "end": 808.0, "text": " plus a whole lot of other details, which I haven't really covered.", "tokens": [50936, 1804, 257, 1379, 688, 295, 661, 4365, 11, 597, 286, 2378, 380, 534, 5343, 13, 51076], "temperature": 0.0, "avg_logprob": -0.09002749463345142, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003052634885534644}, {"id": 128, "seek": 79376, "start": 810.16, "end": 817.04, "text": " So what have we done? How far are we along the line with hardware? So basically, the talks", "tokens": [51184, 407, 437, 362, 321, 1096, 30, 1012, 1400, 366, 321, 2051, 264, 1622, 365, 8837, 30, 407, 1936, 11, 264, 6686, 51528], "temperature": 0.0, "avg_logprob": -0.09002749463345142, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.003052634885534644}, {"id": 129, "seek": 81704, "start": 817.04, "end": 824.24, "text": " that we'll see here, you know, talking about CPUs, HGO, GPUs, that's what they use, sparkling water", "tokens": [50364, 300, 321, 603, 536, 510, 11, 291, 458, 11, 1417, 466, 13199, 82, 11, 389, 11601, 11, 18407, 82, 11, 300, 311, 437, 436, 764, 11, 39967, 1281, 50724], "temperature": 0.0, "avg_logprob": -0.2131501848452559, "compression_ratio": 1.4922480620155039, "no_speech_prob": 0.1971973478794098}, {"id": 130, "seek": 81704, "start": 824.24, "end": 831.5999999999999, "text": " all runs on these things. There's a new sort of endeavor to build ASICs, which are specialized", "tokens": [50724, 439, 6676, 322, 613, 721, 13, 821, 311, 257, 777, 1333, 295, 34975, 281, 1322, 7469, 2532, 82, 11, 597, 366, 19813, 51092], "temperature": 0.0, "avg_logprob": -0.2131501848452559, "compression_ratio": 1.4922480620155039, "no_speech_prob": 0.1971973478794098}, {"id": 131, "seek": 81704, "start": 831.5999999999999, "end": 837.68, "text": " for deep learning. But again, it's just narrow AIS, it's matrix multiplication. But is it grok", "tokens": [51092, 337, 2452, 2539, 13, 583, 797, 11, 309, 311, 445, 9432, 316, 2343, 11, 309, 311, 8141, 27290, 13, 583, 307, 309, 4634, 74, 51396], "temperature": 0.0, "avg_logprob": -0.2131501848452559, "compression_ratio": 1.4922480620155039, "no_speech_prob": 0.1971973478794098}, {"id": 132, "seek": 81704, "start": 837.68, "end": 844.48, "text": " and cerebrus, graph core, Intel, Nirvana, they're all coming out with these amazing things that", "tokens": [51396, 293, 11643, 1443, 301, 11, 4295, 4965, 11, 19762, 11, 44813, 39259, 11, 436, 434, 439, 1348, 484, 365, 613, 2243, 721, 300, 51736], "temperature": 0.0, "avg_logprob": -0.2131501848452559, "compression_ratio": 1.4922480620155039, "no_speech_prob": 0.1971973478794098}, {"id": 133, "seek": 84448, "start": 844.48, "end": 850.8000000000001, "text": " can do, you know, petaflops operations, which is more than the brain does. It's actually more", "tokens": [50364, 393, 360, 11, 291, 458, 11, 3817, 2792, 75, 3370, 7705, 11, 597, 307, 544, 813, 264, 3567, 775, 13, 467, 311, 767, 544, 50680], "temperature": 0.0, "avg_logprob": -0.1410101338436729, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.016848670318722725}, {"id": 134, "seek": 84448, "start": 850.8000000000001, "end": 856.0, "text": " than biology does. But all they're doing is multiplying matrices, right? They're incredible", "tokens": [50680, 813, 14956, 775, 13, 583, 439, 436, 434, 884, 307, 30955, 32284, 11, 558, 30, 814, 434, 4651, 50940], "temperature": 0.0, "avg_logprob": -0.1410101338436729, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.016848670318722725}, {"id": 135, "seek": 84448, "start": 856.0, "end": 860.8000000000001, "text": " feats of micro engineering, incredible. These fabs cost, you know, billions of dollars to build.", "tokens": [50940, 579, 1720, 295, 4532, 7043, 11, 4651, 13, 1981, 5355, 82, 2063, 11, 291, 458, 11, 17375, 295, 3808, 281, 1322, 13, 51180], "temperature": 0.0, "avg_logprob": -0.1410101338436729, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.016848670318722725}, {"id": 136, "seek": 84448, "start": 861.6, "end": 867.76, "text": " They've already, you know, graph core just raised $200 million. And they're impressive things,", "tokens": [51220, 814, 600, 1217, 11, 291, 458, 11, 4295, 4965, 445, 6005, 1848, 7629, 2459, 13, 400, 436, 434, 8992, 721, 11, 51528], "temperature": 0.0, "avg_logprob": -0.1410101338436729, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.016848670318722725}, {"id": 137, "seek": 86776, "start": 867.76, "end": 875.12, "text": " right? And that's what I look like that CPU GPU. There's a Google TPU, which is an ASIC,", "tokens": [50364, 558, 30, 400, 300, 311, 437, 286, 574, 411, 300, 13199, 18407, 13, 821, 311, 257, 3329, 314, 8115, 11, 597, 307, 364, 7469, 2532, 11, 50732], "temperature": 0.0, "avg_logprob": -0.1471125235924354, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.07034880667924881}, {"id": 138, "seek": 86776, "start": 875.12, "end": 879.92, "text": " and runs in their data centers, you can hire them, run them in the cloud. And then there's the graph", "tokens": [50732, 293, 6676, 294, 641, 1412, 10898, 11, 291, 393, 11158, 552, 11, 1190, 552, 294, 264, 4588, 13, 400, 550, 456, 311, 264, 4295, 50972], "temperature": 0.0, "avg_logprob": -0.1471125235924354, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.07034880667924881}, {"id": 139, "seek": 86776, "start": 879.92, "end": 885.52, "text": " core IPU. And they all look the same, but you know, the micro architecture is a little different.", "tokens": [50972, 4965, 8671, 52, 13, 400, 436, 439, 574, 264, 912, 11, 457, 291, 458, 11, 264, 4532, 9482, 307, 257, 707, 819, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1471125235924354, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.07034880667924881}, {"id": 140, "seek": 86776, "start": 886.24, "end": 891.92, "text": " So that, you know, this is all digital classical. If you do a computer science, you'd understand,", "tokens": [51288, 407, 300, 11, 291, 458, 11, 341, 307, 439, 4562, 13735, 13, 759, 291, 360, 257, 3820, 3497, 11, 291, 1116, 1223, 11, 51572], "temperature": 0.0, "avg_logprob": -0.1471125235924354, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.07034880667924881}, {"id": 141, "seek": 86776, "start": 891.92, "end": 897.36, "text": " you know, the details of how bits move around in there, how much energy it takes, how the memory", "tokens": [51572, 291, 458, 11, 264, 4365, 295, 577, 9239, 1286, 926, 294, 456, 11, 577, 709, 2281, 309, 2516, 11, 577, 264, 4675, 51844], "temperature": 0.0, "avg_logprob": -0.1471125235924354, "compression_ratio": 1.6678200692041523, "no_speech_prob": 0.07034880667924881}, {"id": 142, "seek": 89736, "start": 897.36, "end": 905.6800000000001, "text": " in the processor, you know, interact together. But they're not intelligent, right? They're just", "tokens": [50364, 294, 264, 15321, 11, 291, 458, 11, 4648, 1214, 13, 583, 436, 434, 406, 13232, 11, 558, 30, 814, 434, 445, 50780], "temperature": 0.0, "avg_logprob": -0.20051983864076675, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.006116839125752449}, {"id": 143, "seek": 89736, "start": 905.6800000000001, "end": 912.8000000000001, "text": " very good mathematical processors. Okay, that's what a hundred petaflops looks like. And you can,", "tokens": [50780, 588, 665, 18894, 27751, 13, 1033, 11, 300, 311, 437, 257, 3262, 3817, 2792, 75, 3370, 1542, 411, 13, 400, 291, 393, 11, 51136], "temperature": 0.0, "avg_logprob": -0.20051983864076675, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.006116839125752449}, {"id": 144, "seek": 89736, "start": 912.8000000000001, "end": 918.16, "text": " you know, log in today to these things. The Google data center, this is the most powerful,", "tokens": [51136, 291, 458, 11, 3565, 294, 965, 281, 613, 721, 13, 440, 3329, 1412, 3056, 11, 341, 307, 264, 881, 4005, 11, 51404], "temperature": 0.0, "avg_logprob": -0.20051983864076675, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.006116839125752449}, {"id": 145, "seek": 89736, "start": 918.16, "end": 922.72, "text": " you know, three exaflops, we're going to say that that's 1000 million, almost a million times more", "tokens": [51404, 291, 458, 11, 1045, 454, 2792, 75, 3370, 11, 321, 434, 516, 281, 584, 300, 300, 311, 9714, 2459, 11, 1920, 257, 2459, 1413, 544, 51632], "temperature": 0.0, "avg_logprob": -0.20051983864076675, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.006116839125752449}, {"id": 146, "seek": 89736, "start": 922.72, "end": 926.64, "text": " powerful than the brain. But it says dumb as a brick, it's the sun, it's incredibly impressive", "tokens": [51632, 4005, 813, 264, 3567, 13, 583, 309, 1619, 10316, 382, 257, 16725, 11, 309, 311, 264, 3295, 11, 309, 311, 6252, 8992, 51828], "temperature": 0.0, "avg_logprob": -0.20051983864076675, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.006116839125752449}, {"id": 147, "seek": 92664, "start": 926.72, "end": 933.4399999999999, "text": " engineering, it takes up a football field, it's a data center size, but you can't do much except", "tokens": [50368, 7043, 11, 309, 2516, 493, 257, 7346, 2519, 11, 309, 311, 257, 1412, 3056, 2744, 11, 457, 291, 393, 380, 360, 709, 3993, 50704], "temperature": 0.0, "avg_logprob": -0.16024952275412424, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.004522353410720825}, {"id": 148, "seek": 92664, "start": 933.4399999999999, "end": 936.88, "text": " for model plane numbers together, it's not intelligent. Okay, so clearly we're heading", "tokens": [50704, 337, 2316, 5720, 3547, 1214, 11, 309, 311, 406, 13232, 13, 1033, 11, 370, 4448, 321, 434, 9864, 50876], "temperature": 0.0, "avg_logprob": -0.16024952275412424, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.004522353410720825}, {"id": 149, "seek": 92664, "start": 936.88, "end": 942.88, "text": " into a dead end, if we just follow that computer science classical digital hardware route.", "tokens": [50876, 666, 257, 3116, 917, 11, 498, 321, 445, 1524, 300, 3820, 3497, 13735, 4562, 8837, 7955, 13, 51176], "temperature": 0.0, "avg_logprob": -0.16024952275412424, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.004522353410720825}, {"id": 150, "seek": 92664, "start": 943.68, "end": 948.48, "text": " See the brain does all of that and all the other types of intelligence in that little three pound", "tokens": [51216, 3008, 264, 3567, 775, 439, 295, 300, 293, 439, 264, 661, 3467, 295, 7599, 294, 300, 707, 1045, 12013, 51456], "temperature": 0.0, "avg_logprob": -0.16024952275412424, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.004522353410720825}, {"id": 151, "seek": 92664, "start": 949.04, "end": 955.6, "text": " mass. So clearly, it's not just about speed of compute, right? It's not just about horsepower.", "tokens": [51484, 2758, 13, 407, 4448, 11, 309, 311, 406, 445, 466, 3073, 295, 14722, 11, 558, 30, 467, 311, 406, 445, 466, 25250, 13, 51812], "temperature": 0.0, "avg_logprob": -0.16024952275412424, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.004522353410720825}, {"id": 152, "seek": 95560, "start": 955.6, "end": 963.44, "text": " So what is it about? Okay, so recently, some of you, who's heard of neuromorphic computing?", "tokens": [50364, 407, 437, 307, 309, 466, 30, 1033, 11, 370, 3938, 11, 512, 295, 291, 11, 567, 311, 2198, 295, 12087, 32702, 299, 15866, 30, 50756], "temperature": 0.0, "avg_logprob": -0.19439067397006723, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.005351257044821978}, {"id": 153, "seek": 95560, "start": 963.44, "end": 969.52, "text": " Who's heard of that? Yeah, maybe a few, right? A couple. So there's a project called Spinnaker", "tokens": [50756, 2102, 311, 2198, 295, 300, 30, 865, 11, 1310, 257, 1326, 11, 558, 30, 316, 1916, 13, 407, 456, 311, 257, 1716, 1219, 1738, 7729, 4003, 51060], "temperature": 0.0, "avg_logprob": -0.19439067397006723, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.005351257044821978}, {"id": 154, "seek": 95560, "start": 969.52, "end": 977.9200000000001, "text": " in the UK. There's, there's IBM True North, Intel, the OHE. There's, you know, a few different", "tokens": [51060, 294, 264, 7051, 13, 821, 311, 11, 456, 311, 23487, 13587, 4067, 11, 19762, 11, 264, 13931, 36, 13, 821, 311, 11, 291, 458, 11, 257, 1326, 819, 51480], "temperature": 0.0, "avg_logprob": -0.19439067397006723, "compression_ratio": 1.4263959390862944, "no_speech_prob": 0.005351257044821978}, {"id": 155, "seek": 97792, "start": 977.92, "end": 987.04, "text": " projects that are trying to do mimic how biology in hardware, you know, does, does computation.", "tokens": [50364, 4455, 300, 366, 1382, 281, 360, 31075, 577, 14956, 294, 8837, 11, 291, 458, 11, 775, 11, 775, 24903, 13, 50820], "temperature": 0.0, "avg_logprob": -0.1769427730612559, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.07720312476158142}, {"id": 156, "seek": 97792, "start": 987.04, "end": 995.1999999999999, "text": " Okay, it's called neuromorphic computing. So it's based on the brain. And so there's Steve Furber,", "tokens": [50820, 1033, 11, 309, 311, 1219, 12087, 32702, 299, 15866, 13, 407, 309, 311, 2361, 322, 264, 3567, 13, 400, 370, 456, 311, 7466, 11705, 607, 11, 51228], "temperature": 0.0, "avg_logprob": -0.1769427730612559, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.07720312476158142}, {"id": 157, "seek": 97792, "start": 995.1999999999999, "end": 1003.5999999999999, "text": " he's one of the guys who come up, invented, founded the ARM computer processor company.", "tokens": [51228, 415, 311, 472, 295, 264, 1074, 567, 808, 493, 11, 14479, 11, 13234, 264, 45209, 3820, 15321, 2237, 13, 51648], "temperature": 0.0, "avg_logprob": -0.1769427730612559, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.07720312476158142}, {"id": 158, "seek": 100360, "start": 1003.6, "end": 1011.76, "text": " And so he, 20 years ago, left ARM and started on this neuromorphic journey. He's based at", "tokens": [50364, 400, 370, 415, 11, 945, 924, 2057, 11, 1411, 45209, 293, 1409, 322, 341, 12087, 32702, 299, 4671, 13, 634, 311, 2361, 412, 50772], "temperature": 0.0, "avg_logprob": -0.14165454549887746, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005617156624794006}, {"id": 159, "seek": 100360, "start": 1011.76, "end": 1019.12, "text": " University of Manchester. And recently, the human brain project has folded. It's called Spinnaker", "tokens": [50772, 3535, 295, 27180, 13, 400, 3938, 11, 264, 1952, 3567, 1716, 575, 23940, 13, 467, 311, 1219, 1738, 7729, 4003, 51140], "temperature": 0.0, "avg_logprob": -0.14165454549887746, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005617156624794006}, {"id": 160, "seek": 100360, "start": 1019.12, "end": 1025.44, "text": " into itself because it's biopausable hardware. So they have lots of nice funding now, again,", "tokens": [51140, 666, 2564, 570, 309, 311, 3228, 404, 8463, 712, 8837, 13, 407, 436, 362, 3195, 295, 1481, 6137, 586, 11, 797, 11, 51456], "temperature": 0.0, "avg_logprob": -0.14165454549887746, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005617156624794006}, {"id": 161, "seek": 100360, "start": 1025.44, "end": 1030.96, "text": " as IBM True North and Intel. I mean, these companies have a lot of money too. So that's", "tokens": [51456, 382, 23487, 13587, 4067, 293, 19762, 13, 286, 914, 11, 613, 3431, 362, 257, 688, 295, 1460, 886, 13, 407, 300, 311, 51732], "temperature": 0.0, "avg_logprob": -0.14165454549887746, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005617156624794006}, {"id": 162, "seek": 103096, "start": 1030.96, "end": 1038.0, "text": " what it looks like. So there's five racks there. That is about as powerful as the brain of a mouse.", "tokens": [50364, 437, 309, 1542, 411, 13, 407, 456, 311, 1732, 47063, 456, 13, 663, 307, 466, 382, 4005, 382, 264, 3567, 295, 257, 9719, 13, 50716], "temperature": 0.0, "avg_logprob": -0.09418769066150372, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.010956237092614174}, {"id": 163, "seek": 103096, "start": 1038.96, "end": 1044.32, "text": " So it's not human level yet, but it can do things that can go through a maze, it can solve Sudoku", "tokens": [50764, 407, 309, 311, 406, 1952, 1496, 1939, 11, 457, 309, 393, 360, 721, 300, 393, 352, 807, 257, 33032, 11, 309, 393, 5039, 12323, 13275, 51032], "temperature": 0.0, "avg_logprob": -0.09418769066150372, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.010956237092614174}, {"id": 164, "seek": 103096, "start": 1044.32, "end": 1048.24, "text": " and stuff like that, just like we do. So it's kind of getting there. And I would argue, you know,", "tokens": [51032, 293, 1507, 411, 300, 11, 445, 411, 321, 360, 13, 407, 309, 311, 733, 295, 1242, 456, 13, 400, 286, 576, 9695, 11, 291, 458, 11, 51228], "temperature": 0.0, "avg_logprob": -0.09418769066150372, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.010956237092614174}, {"id": 165, "seek": 103096, "start": 1048.24, "end": 1055.76, "text": " to build intelligence, rather than just simulating it on classical digital hardware, this is a more", "tokens": [51228, 281, 1322, 7599, 11, 2831, 813, 445, 1034, 12162, 309, 322, 13735, 4562, 8837, 11, 341, 307, 257, 544, 51604], "temperature": 0.0, "avg_logprob": -0.09418769066150372, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.010956237092614174}, {"id": 166, "seek": 105576, "start": 1055.76, "end": 1061.92, "text": " intelligent route to take. Okay. So, and there's a little bit of detail. So this is an important,", "tokens": [50364, 13232, 7955, 281, 747, 13, 1033, 13, 407, 11, 293, 456, 311, 257, 707, 857, 295, 2607, 13, 407, 341, 307, 364, 1021, 11, 50672], "temperature": 0.0, "avg_logprob": -0.10554406756446474, "compression_ratio": 1.6418918918918919, "no_speech_prob": 0.08492264896631241}, {"id": 167, "seek": 105576, "start": 1061.92, "end": 1068.56, "text": " you know, technology and a new path that not many have heard of here, you know, which is very", "tokens": [50672, 291, 458, 11, 2899, 293, 257, 777, 3100, 300, 406, 867, 362, 2198, 295, 510, 11, 291, 458, 11, 597, 307, 588, 51004], "temperature": 0.0, "avg_logprob": -0.10554406756446474, "compression_ratio": 1.6418918918918919, "no_speech_prob": 0.08492264896631241}, {"id": 168, "seek": 105576, "start": 1068.56, "end": 1073.68, "text": " interesting. It's probably like we were in the 50s with digital computing. You know, there's just a", "tokens": [51004, 1880, 13, 467, 311, 1391, 411, 321, 645, 294, 264, 2625, 82, 365, 4562, 15866, 13, 509, 458, 11, 456, 311, 445, 257, 51260], "temperature": 0.0, "avg_logprob": -0.10554406756446474, "compression_ratio": 1.6418918918918919, "no_speech_prob": 0.08492264896631241}, {"id": 169, "seek": 105576, "start": 1073.68, "end": 1079.44, "text": " few main frames in the world right now, a few of these devices, but they actually exist. And you", "tokens": [51260, 1326, 2135, 12083, 294, 264, 1002, 558, 586, 11, 257, 1326, 295, 613, 5759, 11, 457, 436, 767, 2514, 13, 400, 291, 51548], "temperature": 0.0, "avg_logprob": -0.10554406756446474, "compression_ratio": 1.6418918918918919, "no_speech_prob": 0.08492264896631241}, {"id": 170, "seek": 105576, "start": 1079.44, "end": 1083.84, "text": " can actually log into Spinnaker. It's part of the human brain project. You can create an account,", "tokens": [51548, 393, 767, 3565, 666, 1738, 7729, 4003, 13, 467, 311, 644, 295, 264, 1952, 3567, 1716, 13, 509, 393, 1884, 364, 2696, 11, 51768], "temperature": 0.0, "avg_logprob": -0.10554406756446474, "compression_ratio": 1.6418918918918919, "no_speech_prob": 0.08492264896631241}, {"id": 171, "seek": 108384, "start": 1083.84, "end": 1089.76, "text": " log in and watch it do stuff in real time. So they're not these magical, mystical things in a", "tokens": [50364, 3565, 294, 293, 1159, 309, 360, 1507, 294, 957, 565, 13, 407, 436, 434, 406, 613, 12066, 11, 40565, 721, 294, 257, 50660], "temperature": 0.0, "avg_logprob": -0.09745412826538086, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0173913836479187}, {"id": 172, "seek": 108384, "start": 1089.76, "end": 1099.4399999999998, "text": " lab. They're kind of getting in real. And let's see. So that's okay. That's another initiative", "tokens": [50660, 2715, 13, 814, 434, 733, 295, 1242, 294, 957, 13, 400, 718, 311, 536, 13, 407, 300, 311, 1392, 13, 663, 311, 1071, 11552, 51144], "temperature": 0.0, "avg_logprob": -0.09745412826538086, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0173913836479187}, {"id": 173, "seek": 108384, "start": 1099.4399999999998, "end": 1103.9199999999998, "text": " from Heidelberg, the brain scales project, which is also part of the human brain project.", "tokens": [51144, 490, 634, 16189, 6873, 11, 264, 3567, 17408, 1716, 11, 597, 307, 611, 644, 295, 264, 1952, 3567, 1716, 13, 51368], "temperature": 0.0, "avg_logprob": -0.09745412826538086, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0173913836479187}, {"id": 174, "seek": 108384, "start": 1103.9199999999998, "end": 1110.08, "text": " So the one on the left, I would argue, will get us to general intelligence. The one on the right,", "tokens": [51368, 407, 264, 472, 322, 264, 1411, 11, 286, 576, 9695, 11, 486, 483, 505, 281, 2674, 7599, 13, 440, 472, 322, 264, 558, 11, 51676], "temperature": 0.0, "avg_logprob": -0.09745412826538086, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.0173913836479187}, {"id": 175, "seek": 111008, "start": 1110.08, "end": 1115.04, "text": " no matter how impressive that looks, won't. Okay. So, and then there's quantum computing,", "tokens": [50364, 572, 1871, 577, 8992, 300, 1542, 11, 1582, 380, 13, 1033, 13, 407, 11, 293, 550, 456, 311, 13018, 15866, 11, 50612], "temperature": 0.0, "avg_logprob": -0.15079622467358908, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.02034827508032322}, {"id": 176, "seek": 111008, "start": 1115.04, "end": 1120.0, "text": " how about it? Is the brain quantum? No, it's warm, it's squidgy, nothing to do with quantum", "tokens": [50612, 577, 466, 309, 30, 1119, 264, 3567, 13018, 30, 883, 11, 309, 311, 4561, 11, 309, 311, 28015, 1480, 11, 1825, 281, 360, 365, 13018, 50860], "temperature": 0.0, "avg_logprob": -0.15079622467358908, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.02034827508032322}, {"id": 177, "seek": 111008, "start": 1120.72, "end": 1128.72, "text": " at all. Okay. Although birds navigate and plants photosynthesize using quantum processes,", "tokens": [50896, 412, 439, 13, 1033, 13, 5780, 9009, 12350, 293, 5972, 5787, 18656, 279, 1125, 1228, 13018, 7555, 11, 51296], "temperature": 0.0, "avg_logprob": -0.15079622467358908, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.02034827508032322}, {"id": 178, "seek": 111008, "start": 1128.72, "end": 1135.1999999999998, "text": " but it's not really generally how we do it. Okay. But the pictures look really nice. I decided", "tokens": [51296, 457, 309, 311, 406, 534, 5101, 577, 321, 360, 309, 13, 1033, 13, 583, 264, 5242, 574, 534, 1481, 13, 286, 3047, 51620], "temperature": 0.0, "avg_logprob": -0.15079622467358908, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.02034827508032322}, {"id": 179, "seek": 113520, "start": 1135.2, "end": 1139.76, "text": " to include a couple and it is what a quantum circuit looks like. I also quite like quantum", "tokens": [50364, 281, 4090, 257, 1916, 293, 309, 307, 437, 257, 13018, 9048, 1542, 411, 13, 286, 611, 1596, 411, 13018, 50592], "temperature": 0.0, "avg_logprob": -0.11439853069210841, "compression_ratio": 1.6747404844290656, "no_speech_prob": 0.04029319807887077}, {"id": 180, "seek": 113520, "start": 1139.76, "end": 1145.2, "text": " computing because I have a physical background, but it's probably we don't need to worry about that", "tokens": [50592, 15866, 570, 286, 362, 257, 4001, 3678, 11, 457, 309, 311, 1391, 321, 500, 380, 643, 281, 3292, 466, 300, 50864], "temperature": 0.0, "avg_logprob": -0.11439853069210841, "compression_ratio": 1.6747404844290656, "no_speech_prob": 0.04029319807887077}, {"id": 181, "seek": 113520, "start": 1145.92, "end": 1151.04, "text": " if we're building AGI. It might help some of the computations initially, but ultimately we're not", "tokens": [50900, 498, 321, 434, 2390, 316, 26252, 13, 467, 1062, 854, 512, 295, 264, 2807, 763, 9105, 11, 457, 6284, 321, 434, 406, 51156], "temperature": 0.0, "avg_logprob": -0.11439853069210841, "compression_ratio": 1.6747404844290656, "no_speech_prob": 0.04029319807887077}, {"id": 182, "seek": 113520, "start": 1151.04, "end": 1157.28, "text": " a quantum computer up here. It's a neuromorphic computer. Okay. So that's the sort of four different", "tokens": [51156, 257, 13018, 3820, 493, 510, 13, 467, 311, 257, 12087, 32702, 299, 3820, 13, 1033, 13, 407, 300, 311, 264, 1333, 295, 1451, 819, 51468], "temperature": 0.0, "avg_logprob": -0.11439853069210841, "compression_ratio": 1.6747404844290656, "no_speech_prob": 0.04029319807887077}, {"id": 183, "seek": 113520, "start": 1157.28, "end": 1162.32, "text": " types of hardware. And I'd argue the one on the top right, neuromorphic will get us there. And", "tokens": [51468, 3467, 295, 8837, 13, 400, 286, 1116, 9695, 264, 472, 322, 264, 1192, 558, 11, 12087, 32702, 299, 486, 483, 505, 456, 13, 400, 51720], "temperature": 0.0, "avg_logprob": -0.11439853069210841, "compression_ratio": 1.6747404844290656, "no_speech_prob": 0.04029319807887077}, {"id": 184, "seek": 116232, "start": 1162.32, "end": 1166.96, "text": " that's how they look in a little bit more detail. And so, you know, it's not magic. It's just really", "tokens": [50364, 300, 311, 577, 436, 574, 294, 257, 707, 857, 544, 2607, 13, 400, 370, 11, 291, 458, 11, 309, 311, 406, 5585, 13, 467, 311, 445, 534, 50596], "temperature": 0.0, "avg_logprob": -0.10563459187528512, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0016969632124528289}, {"id": 185, "seek": 116232, "start": 1166.96, "end": 1171.84, "text": " hard engineering, which is why we haven't built it yet. It's just hard. Okay. It's small. It's,", "tokens": [50596, 1152, 7043, 11, 597, 307, 983, 321, 2378, 380, 3094, 309, 1939, 13, 467, 311, 445, 1152, 13, 1033, 13, 467, 311, 1359, 13, 467, 311, 11, 50840], "temperature": 0.0, "avg_logprob": -0.10563459187528512, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0016969632124528289}, {"id": 186, "seek": 116232, "start": 1171.84, "end": 1176.96, "text": " you know, and to understand it's difficult. Do we have a mathematical theory of the brain? Well,", "tokens": [50840, 291, 458, 11, 293, 281, 1223, 309, 311, 2252, 13, 1144, 321, 362, 257, 18894, 5261, 295, 264, 3567, 30, 1042, 11, 51096], "temperature": 0.0, "avg_logprob": -0.10563459187528512, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0016969632124528289}, {"id": 187, "seek": 116232, "start": 1176.96, "end": 1183.6799999999998, "text": " I would argue sort of before I go there. So the data center of the future right now is just full", "tokens": [51096, 286, 576, 9695, 1333, 295, 949, 286, 352, 456, 13, 407, 264, 1412, 3056, 295, 264, 2027, 558, 586, 307, 445, 1577, 51432], "temperature": 0.0, "avg_logprob": -0.10563459187528512, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0016969632124528289}, {"id": 188, "seek": 116232, "start": 1183.6799999999998, "end": 1191.28, "text": " of those very clever chips we saw the graph core, the, you know, TPU GPU CPUs, very, you know,", "tokens": [51432, 295, 729, 588, 13494, 11583, 321, 1866, 264, 4295, 4965, 11, 264, 11, 291, 458, 11, 314, 8115, 18407, 13199, 82, 11, 588, 11, 291, 458, 11, 51812], "temperature": 0.0, "avg_logprob": -0.10563459187528512, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0016969632124528289}, {"id": 189, "seek": 119128, "start": 1191.36, "end": 1196.0, "text": " amazing engineering, but soon we'll see them being filled up with neuromorphic and quantum as well.", "tokens": [50368, 2243, 7043, 11, 457, 2321, 321, 603, 536, 552, 885, 6412, 493, 365, 12087, 32702, 299, 293, 13018, 382, 731, 13, 50600], "temperature": 0.0, "avg_logprob": -0.0905619455040048, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.006812759209424257}, {"id": 190, "seek": 119128, "start": 1196.0, "end": 1202.8, "text": " So Google announced quantum supremacy last week, a couple of weeks ago, which means that a quantum", "tokens": [50600, 407, 3329, 7548, 13018, 35572, 1036, 1243, 11, 257, 1916, 295, 3259, 2057, 11, 597, 1355, 300, 257, 13018, 50940], "temperature": 0.0, "avg_logprob": -0.0905619455040048, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.006812759209424257}, {"id": 191, "seek": 119128, "start": 1202.8, "end": 1208.6399999999999, "text": " computer, it can do something faster than the biggest classical computer. So the data center", "tokens": [50940, 3820, 11, 309, 393, 360, 746, 4663, 813, 264, 3880, 13735, 3820, 13, 407, 264, 1412, 3056, 51232], "temperature": 0.0, "avg_logprob": -0.0905619455040048, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.006812759209424257}, {"id": 192, "seek": 119128, "start": 1208.6399999999999, "end": 1213.76, "text": " of future will look like this. Okay. So we're interesting. We're entering a very interesting", "tokens": [51232, 295, 2027, 486, 574, 411, 341, 13, 1033, 13, 407, 321, 434, 1880, 13, 492, 434, 11104, 257, 588, 1880, 51488], "temperature": 0.0, "avg_logprob": -0.0905619455040048, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.006812759209424257}, {"id": 193, "seek": 119128, "start": 1213.76, "end": 1218.48, "text": " time in human history, I think, in terms of computation, because we haven't just got classical", "tokens": [51488, 565, 294, 1952, 2503, 11, 286, 519, 11, 294, 2115, 295, 24903, 11, 570, 321, 2378, 380, 445, 658, 13735, 51724], "temperature": 0.0, "avg_logprob": -0.0905619455040048, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.006812759209424257}, {"id": 194, "seek": 121848, "start": 1218.48, "end": 1223.52, "text": " computing, we have neuromorphic and quantum as well coming online. It's been 80 years, right,", "tokens": [50364, 15866, 11, 321, 362, 12087, 32702, 299, 293, 13018, 382, 731, 1348, 2950, 13, 467, 311, 668, 4688, 924, 11, 558, 11, 50616], "temperature": 0.0, "avg_logprob": -0.09878659479826399, "compression_ratio": 1.645985401459854, "no_speech_prob": 0.005283752456307411}, {"id": 195, "seek": 121848, "start": 1223.52, "end": 1229.28, "text": " since we first started doing a computation. So at a very interesting time, I think in", "tokens": [50616, 1670, 321, 700, 1409, 884, 257, 24903, 13, 407, 412, 257, 588, 1880, 565, 11, 286, 519, 294, 50904], "temperature": 0.0, "avg_logprob": -0.09878659479826399, "compression_ratio": 1.645985401459854, "no_speech_prob": 0.005283752456307411}, {"id": 196, "seek": 121848, "start": 1229.28, "end": 1234.24, "text": " the history of computation with these other two major types of computation coming online.", "tokens": [50904, 264, 2503, 295, 24903, 365, 613, 661, 732, 2563, 3467, 295, 24903, 1348, 2950, 13, 51152], "temperature": 0.0, "avg_logprob": -0.09878659479826399, "compression_ratio": 1.645985401459854, "no_speech_prob": 0.005283752456307411}, {"id": 197, "seek": 121848, "start": 1235.52, "end": 1240.64, "text": " So deep learning, I've argued that won't get us anywhere near intelligence. It will classify", "tokens": [51216, 407, 2452, 2539, 11, 286, 600, 20219, 300, 1582, 380, 483, 505, 4992, 2651, 7599, 13, 467, 486, 33872, 51472], "temperature": 0.0, "avg_logprob": -0.09878659479826399, "compression_ratio": 1.645985401459854, "no_speech_prob": 0.005283752456307411}, {"id": 198, "seek": 121848, "start": 1240.64, "end": 1244.88, "text": " stuff really well and do a little bit of statistical language processing, but it doesn't", "tokens": [51472, 1507, 534, 731, 293, 360, 257, 707, 857, 295, 22820, 2856, 9007, 11, 457, 309, 1177, 380, 51684], "temperature": 0.0, "avg_logprob": -0.09878659479826399, "compression_ratio": 1.645985401459854, "no_speech_prob": 0.005283752456307411}, {"id": 199, "seek": 124488, "start": 1244.88, "end": 1251.2800000000002, "text": " do the nine types of intelligence. Okay. And so the most popular framework by far as TensorFlow,", "tokens": [50364, 360, 264, 4949, 3467, 295, 7599, 13, 1033, 13, 400, 370, 264, 881, 3743, 8388, 538, 1400, 382, 37624, 11, 50684], "temperature": 0.0, "avg_logprob": -0.1153755717807346, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.008127991110086441}, {"id": 200, "seek": 124488, "start": 1251.2800000000002, "end": 1260.16, "text": " PyTorch is kind of also increasing in the last little while, but you know,", "tokens": [50684, 9953, 51, 284, 339, 307, 733, 295, 611, 5662, 294, 264, 1036, 707, 1339, 11, 457, 291, 458, 11, 51128], "temperature": 0.0, "avg_logprob": -0.1153755717807346, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.008127991110086441}, {"id": 201, "seek": 124488, "start": 1261.5200000000002, "end": 1266.96, "text": " general intelligence, how biology does it, it doesn't do matrix multiplication. So deep learning", "tokens": [51196, 2674, 7599, 11, 577, 14956, 775, 309, 11, 309, 1177, 380, 360, 8141, 27290, 13, 407, 2452, 2539, 51468], "temperature": 0.0, "avg_logprob": -0.1153755717807346, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.008127991110086441}, {"id": 202, "seek": 124488, "start": 1266.96, "end": 1274.3200000000002, "text": " is not AGI. So we won't talk about that, but we will talk about more neuroscience stuff. Okay.", "tokens": [51468, 307, 406, 316, 26252, 13, 407, 321, 1582, 380, 751, 466, 300, 11, 457, 321, 486, 751, 466, 544, 42762, 1507, 13, 1033, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1153755717807346, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.008127991110086441}, {"id": 203, "seek": 127488, "start": 1274.96, "end": 1280.16, "text": " Sorry to be so harsh, but you know, it's reality. All that clever stuff isn't actually AGI, but", "tokens": [50368, 4919, 281, 312, 370, 14897, 11, 457, 291, 458, 11, 309, 311, 4103, 13, 1057, 300, 13494, 1507, 1943, 380, 767, 316, 26252, 11, 457, 50628], "temperature": 0.0, "avg_logprob": -0.11309746539953983, "compression_ratio": 1.6819787985865724, "no_speech_prob": 0.005456814542412758}, {"id": 204, "seek": 127488, "start": 1280.16, "end": 1287.6000000000001, "text": " it's good at certain things. Okay. So what do we do? I mean, where do we even start, right,", "tokens": [50628, 309, 311, 665, 412, 1629, 721, 13, 1033, 13, 407, 437, 360, 321, 360, 30, 286, 914, 11, 689, 360, 321, 754, 722, 11, 558, 11, 51000], "temperature": 0.0, "avg_logprob": -0.11309746539953983, "compression_ratio": 1.6819787985865724, "no_speech_prob": 0.005456814542412758}, {"id": 205, "seek": 127488, "start": 1288.48, "end": 1292.5600000000002, "text": " with the general theory of intelligence? Well, you know, the brain is a physical system, right?", "tokens": [51044, 365, 264, 2674, 5261, 295, 7599, 30, 1042, 11, 291, 458, 11, 264, 3567, 307, 257, 4001, 1185, 11, 558, 30, 51248], "temperature": 0.0, "avg_logprob": -0.11309746539953983, "compression_ratio": 1.6819787985865724, "no_speech_prob": 0.005456814542412758}, {"id": 206, "seek": 127488, "start": 1292.5600000000002, "end": 1298.4, "text": " It's just three pounds of physics, just, okay. So what do we know about physics? Well, we've", "tokens": [51248, 467, 311, 445, 1045, 8319, 295, 10649, 11, 445, 11, 1392, 13, 407, 437, 360, 321, 458, 466, 10649, 30, 1042, 11, 321, 600, 51540], "temperature": 0.0, "avg_logprob": -0.11309746539953983, "compression_ratio": 1.6819787985865724, "no_speech_prob": 0.005456814542412758}, {"id": 207, "seek": 127488, "start": 1298.4, "end": 1303.92, "text": " pretty much discovered all of the laws of physics. I think dark matter is kind of a new one. It's a", "tokens": [51540, 1238, 709, 6941, 439, 295, 264, 6064, 295, 10649, 13, 286, 519, 2877, 1871, 307, 733, 295, 257, 777, 472, 13, 467, 311, 257, 51816], "temperature": 0.0, "avg_logprob": -0.11309746539953983, "compression_ratio": 1.6819787985865724, "no_speech_prob": 0.005456814542412758}, {"id": 208, "seek": 130392, "start": 1303.92, "end": 1310.0800000000002, "text": " bit of a bold statement. I'm a physicist. I'm allowed to say that. So what are, I mean, what", "tokens": [50364, 857, 295, 257, 11928, 5629, 13, 286, 478, 257, 42466, 13, 286, 478, 4350, 281, 584, 300, 13, 407, 437, 366, 11, 286, 914, 11, 437, 50672], "temperature": 0.0, "avg_logprob": -0.13977464815465415, "compression_ratio": 1.6054421768707483, "no_speech_prob": 0.0009223891538567841}, {"id": 209, "seek": 130392, "start": 1310.0800000000002, "end": 1317.3600000000001, "text": " out of there do we use? Okay. You know, probably thermodynamics and electromagnetism in a complex", "tokens": [50672, 484, 295, 456, 360, 321, 764, 30, 1033, 13, 509, 458, 11, 1391, 8810, 35483, 293, 27528, 302, 1434, 294, 257, 3997, 51036], "temperature": 0.0, "avg_logprob": -0.13977464815465415, "compression_ratio": 1.6054421768707483, "no_speech_prob": 0.0009223891538567841}, {"id": 210, "seek": 130392, "start": 1317.3600000000001, "end": 1322.48, "text": " system, right? So it's nothing magic. Now the underlying theory of all of this, all of that", "tokens": [51036, 1185, 11, 558, 30, 407, 309, 311, 1825, 5585, 13, 823, 264, 14217, 5261, 295, 439, 295, 341, 11, 439, 295, 300, 51292], "temperature": 0.0, "avg_logprob": -0.13977464815465415, "compression_ratio": 1.6054421768707483, "no_speech_prob": 0.0009223891538567841}, {"id": 211, "seek": 130392, "start": 1323.1200000000001, "end": 1327.1200000000001, "text": " can be described in something called the principle of least action, which is that, and it's just", "tokens": [51324, 393, 312, 7619, 294, 746, 1219, 264, 8665, 295, 1935, 3069, 11, 597, 307, 300, 11, 293, 309, 311, 445, 51524], "temperature": 0.0, "avg_logprob": -0.13977464815465415, "compression_ratio": 1.6054421768707483, "no_speech_prob": 0.0009223891538567841}, {"id": 212, "seek": 130392, "start": 1327.1200000000001, "end": 1332.64, "text": " been a book published last year. Surprisingly, it wasn't one before that sort of says, okay,", "tokens": [51524, 668, 257, 1446, 6572, 1036, 1064, 13, 49908, 11, 309, 2067, 380, 472, 949, 300, 1333, 295, 1619, 11, 1392, 11, 51800], "temperature": 0.0, "avg_logprob": -0.13977464815465415, "compression_ratio": 1.6054421768707483, "no_speech_prob": 0.0009223891538567841}, {"id": 213, "seek": 133264, "start": 1332.64, "end": 1338.24, "text": " all of physics, that's, you know, classical quantum, everything can be, you know, derived", "tokens": [50364, 439, 295, 10649, 11, 300, 311, 11, 291, 458, 11, 13735, 13018, 11, 1203, 393, 312, 11, 291, 458, 11, 18949, 50644], "temperature": 0.0, "avg_logprob": -0.13795334292996314, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0037200136575847864}, {"id": 214, "seek": 133264, "start": 1338.24, "end": 1345.3600000000001, "text": " starting with this principle of least action. Now, if anyone's who's got a PhD in physics here,", "tokens": [50644, 2891, 365, 341, 8665, 295, 1935, 3069, 13, 823, 11, 498, 2878, 311, 567, 311, 658, 257, 14476, 294, 10649, 510, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13795334292996314, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0037200136575847864}, {"id": 215, "seek": 133264, "start": 1345.3600000000001, "end": 1351.5200000000002, "text": " yeah, a few people. And so we've all, this is what you get at grad school in physics, right? We do", "tokens": [51000, 1338, 11, 257, 1326, 561, 13, 400, 370, 321, 600, 439, 11, 341, 307, 437, 291, 483, 412, 2771, 1395, 294, 10649, 11, 558, 30, 492, 360, 51308], "temperature": 0.0, "avg_logprob": -0.13795334292996314, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0037200136575847864}, {"id": 216, "seek": 133264, "start": 1351.5200000000002, "end": 1355.3600000000001, "text": " Lagrangians and Hamiltonians and principles of least action. So everything we learn,", "tokens": [51308, 24886, 32926, 2567, 293, 18484, 2567, 293, 9156, 295, 1935, 3069, 13, 407, 1203, 321, 1466, 11, 51500], "temperature": 0.0, "avg_logprob": -0.13795334292996314, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0037200136575847864}, {"id": 217, "seek": 133264, "start": 1355.3600000000001, "end": 1360.24, "text": " if equals ma and undergrad, we're told, yeah, that's very nice and quaint. But really, this is", "tokens": [51500, 498, 6915, 463, 293, 14295, 11, 321, 434, 1907, 11, 1338, 11, 300, 311, 588, 1481, 293, 421, 5114, 13, 583, 534, 11, 341, 307, 51744], "temperature": 0.0, "avg_logprob": -0.13795334292996314, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0037200136575847864}, {"id": 218, "seek": 136024, "start": 1360.24, "end": 1365.44, "text": " the powerful machinery that's been developed. But we don't, you know, that we sort of, we get,", "tokens": [50364, 264, 4005, 27302, 300, 311, 668, 4743, 13, 583, 321, 500, 380, 11, 291, 458, 11, 300, 321, 1333, 295, 11, 321, 483, 11, 50624], "temperature": 0.0, "avg_logprob": -0.10172411346435548, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.017363663762807846}, {"id": 219, "seek": 136024, "start": 1365.44, "end": 1370.96, "text": " we get there, but I think we're not really taught that, you know, it's very unifying principle.", "tokens": [50624, 321, 483, 456, 11, 457, 286, 519, 321, 434, 406, 534, 5928, 300, 11, 291, 458, 11, 309, 311, 588, 517, 5489, 8665, 13, 50900], "temperature": 0.0, "avg_logprob": -0.10172411346435548, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.017363663762807846}, {"id": 220, "seek": 136024, "start": 1372.08, "end": 1377.1200000000001, "text": " Okay, so I'm saying, okay, probably that's a nice place to start if we want to try to come", "tokens": [50956, 1033, 11, 370, 286, 478, 1566, 11, 1392, 11, 1391, 300, 311, 257, 1481, 1081, 281, 722, 498, 321, 528, 281, 853, 281, 808, 51208], "temperature": 0.0, "avg_logprob": -0.10172411346435548, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.017363663762807846}, {"id": 221, "seek": 136024, "start": 1377.1200000000001, "end": 1381.84, "text": " up with a general theory of intelligence. Okay, it's a big statement and bold statement, but,", "tokens": [51208, 493, 365, 257, 2674, 5261, 295, 7599, 13, 1033, 11, 309, 311, 257, 955, 5629, 293, 11928, 5629, 11, 457, 11, 51444], "temperature": 0.0, "avg_logprob": -0.10172411346435548, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.017363663762807846}, {"id": 222, "seek": 136024, "start": 1382.4, "end": 1387.04, "text": " you know, the brain is not doing anything that physical systems can't do, even though it feels", "tokens": [51472, 291, 458, 11, 264, 3567, 307, 406, 884, 1340, 300, 4001, 3652, 393, 380, 360, 11, 754, 1673, 309, 3417, 51704], "temperature": 0.0, "avg_logprob": -0.10172411346435548, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.017363663762807846}, {"id": 223, "seek": 138704, "start": 1387.04, "end": 1392.1599999999999, "text": " kind of, it is different, right? Because we have consciousness and, you know, that subjective", "tokens": [50364, 733, 295, 11, 309, 307, 819, 11, 558, 30, 1436, 321, 362, 10081, 293, 11, 291, 458, 11, 300, 25972, 50620], "temperature": 0.0, "avg_logprob": -0.09543186520773267, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.014052036218345165}, {"id": 224, "seek": 138704, "start": 1392.1599999999999, "end": 1396.8, "text": " experience and self-awareness and that kind of stuff. But I'm going to argue it's all just physics.", "tokens": [50620, 1752, 293, 2698, 12, 17074, 1287, 293, 300, 733, 295, 1507, 13, 583, 286, 478, 516, 281, 9695, 309, 311, 439, 445, 10649, 13, 50852], "temperature": 0.0, "avg_logprob": -0.09543186520773267, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.014052036218345165}, {"id": 225, "seek": 138704, "start": 1397.6, "end": 1402.72, "text": " There are people in the room and elsewhere who will say, no, there's something beyond physics,", "tokens": [50892, 821, 366, 561, 294, 264, 1808, 293, 14517, 567, 486, 584, 11, 572, 11, 456, 311, 746, 4399, 10649, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09543186520773267, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.014052036218345165}, {"id": 226, "seek": 138704, "start": 1402.72, "end": 1407.68, "text": " metaphysics. I'm not one of those people. Okay, so I'm just going to keep it really simple.", "tokens": [51148, 30946, 41732, 13, 286, 478, 406, 472, 295, 729, 561, 13, 1033, 11, 370, 286, 478, 445, 516, 281, 1066, 309, 534, 2199, 13, 51396], "temperature": 0.0, "avg_logprob": -0.09543186520773267, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.014052036218345165}, {"id": 227, "seek": 138704, "start": 1408.3999999999999, "end": 1416.08, "text": " So, you know, what can we do? Well, we can explain and understand what we see. We can imagine things,", "tokens": [51432, 407, 11, 291, 458, 11, 437, 393, 321, 360, 30, 1042, 11, 321, 393, 2903, 293, 1223, 437, 321, 536, 13, 492, 393, 3811, 721, 11, 51816], "temperature": 0.0, "avg_logprob": -0.09543186520773267, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.014052036218345165}, {"id": 228, "seek": 141608, "start": 1416.08, "end": 1421.1999999999998, "text": " you know, imagination, imagine that. Problem solving, planning actions to make these things", "tokens": [50364, 291, 458, 11, 12938, 11, 3811, 300, 13, 11676, 12606, 11, 5038, 5909, 281, 652, 613, 721, 50620], "temperature": 0.0, "avg_logprob": -0.1167552927707104, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.003559021046385169}, {"id": 229, "seek": 141608, "start": 1421.1999999999998, "end": 1426.32, "text": " real, we can do all of that. That's what intelligence is really. And we can build new models as we", "tokens": [50620, 957, 11, 321, 393, 360, 439, 295, 300, 13, 663, 311, 437, 7599, 307, 534, 13, 400, 321, 393, 1322, 777, 5245, 382, 321, 50876], "temperature": 0.0, "avg_logprob": -0.1167552927707104, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.003559021046385169}, {"id": 230, "seek": 141608, "start": 1426.32, "end": 1436.24, "text": " learn about the world. So, probably, okay, we've got five minutes. So, these are the sort of major,", "tokens": [50876, 1466, 466, 264, 1002, 13, 407, 11, 1391, 11, 1392, 11, 321, 600, 658, 1732, 2077, 13, 407, 11, 613, 366, 264, 1333, 295, 2563, 11, 51372], "temperature": 0.0, "avg_logprob": -0.1167552927707104, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.003559021046385169}, {"id": 231, "seek": 141608, "start": 1436.24, "end": 1440.3999999999999, "text": " some of the major theories of general intelligence, mathematical theory. These are all smart people", "tokens": [51372, 512, 295, 264, 2563, 13667, 295, 2674, 7599, 11, 18894, 5261, 13, 1981, 366, 439, 4069, 561, 51580], "temperature": 0.0, "avg_logprob": -0.1167552927707104, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.003559021046385169}, {"id": 232, "seek": 144040, "start": 1441.3600000000001, "end": 1445.92, "text": " who have spent their whole lives dedicating to this. You can look them up later. There's", "tokens": [50412, 567, 362, 4418, 641, 1379, 2909, 4172, 30541, 281, 341, 13, 509, 393, 574, 552, 493, 1780, 13, 821, 311, 50640], "temperature": 0.0, "avg_logprob": -0.08969874131052118, "compression_ratio": 1.5782312925170068, "no_speech_prob": 0.04668835923075676}, {"id": 233, "seek": 144040, "start": 1445.92, "end": 1451.6000000000001, "text": " a guy called Carl Friston at UCL in London. And so, his theory of active inference is the one", "tokens": [50640, 257, 2146, 1219, 14256, 1526, 47345, 412, 14079, 43, 294, 7042, 13, 400, 370, 11, 702, 5261, 295, 4967, 38253, 307, 264, 472, 50924], "temperature": 0.0, "avg_logprob": -0.08969874131052118, "compression_ratio": 1.5782312925170068, "no_speech_prob": 0.04668835923075676}, {"id": 234, "seek": 144040, "start": 1451.6000000000001, "end": 1457.0400000000002, "text": " that I think is particularly compelling. And I won't spend any time going through the details,", "tokens": [50924, 300, 286, 519, 307, 4098, 20050, 13, 400, 286, 1582, 380, 3496, 604, 565, 516, 807, 264, 4365, 11, 51196], "temperature": 0.0, "avg_logprob": -0.08969874131052118, "compression_ratio": 1.5782312925170068, "no_speech_prob": 0.04668835923075676}, {"id": 235, "seek": 144040, "start": 1457.0400000000002, "end": 1460.96, "text": " because it's pretty hard math, actually, but he uses something called a free energy principle.", "tokens": [51196, 570, 309, 311, 1238, 1152, 5221, 11, 767, 11, 457, 415, 4960, 746, 1219, 257, 1737, 2281, 8665, 13, 51392], "temperature": 0.0, "avg_logprob": -0.08969874131052118, "compression_ratio": 1.5782312925170068, "no_speech_prob": 0.04668835923075676}, {"id": 236, "seek": 144040, "start": 1460.96, "end": 1466.0, "text": " It's based on physics and information theory. It's nothing kind of new and crazy. It's just", "tokens": [51392, 467, 311, 2361, 322, 10649, 293, 1589, 5261, 13, 467, 311, 1825, 733, 295, 777, 293, 3219, 13, 467, 311, 445, 51644], "temperature": 0.0, "avg_logprob": -0.08969874131052118, "compression_ratio": 1.5782312925170068, "no_speech_prob": 0.04668835923075676}, {"id": 237, "seek": 146600, "start": 1466.0, "end": 1470.88, "text": " applying it to the brain. And he is a theoretical neuroscientist. And so, here he is.", "tokens": [50364, 9275, 309, 281, 264, 3567, 13, 400, 415, 307, 257, 20864, 28813, 5412, 468, 13, 400, 370, 11, 510, 415, 307, 13, 50608], "temperature": 0.0, "avg_logprob": -0.11128165905292217, "compression_ratio": 1.6214285714285714, "no_speech_prob": 0.053482383489608765}, {"id": 238, "seek": 146600, "start": 1473.68, "end": 1478.56, "text": " And we don't have time to play it. So, the slides will be made available, I think,", "tokens": [50748, 400, 321, 500, 380, 362, 565, 281, 862, 309, 13, 407, 11, 264, 9788, 486, 312, 1027, 2435, 11, 286, 519, 11, 50992], "temperature": 0.0, "avg_logprob": -0.11128165905292217, "compression_ratio": 1.6214285714285714, "no_speech_prob": 0.053482383489608765}, {"id": 239, "seek": 146600, "start": 1478.56, "end": 1483.52, "text": " so you can listen to him. And he's on YouTube, if you want to Google. And so, that's how he", "tokens": [50992, 370, 291, 393, 2140, 281, 796, 13, 400, 415, 311, 322, 3088, 11, 498, 291, 528, 281, 3329, 13, 400, 370, 11, 300, 311, 577, 415, 51240], "temperature": 0.0, "avg_logprob": -0.11128165905292217, "compression_ratio": 1.6214285714285714, "no_speech_prob": 0.053482383489608765}, {"id": 240, "seek": 146600, "start": 1483.52, "end": 1488.8, "text": " sets it up. There's internal, there's us agents acting in an environment. That's the same if we're", "tokens": [51240, 6352, 309, 493, 13, 821, 311, 6920, 11, 456, 311, 505, 12554, 6577, 294, 364, 2823, 13, 663, 311, 264, 912, 498, 321, 434, 51504], "temperature": 0.0, "avg_logprob": -0.11128165905292217, "compression_ratio": 1.6214285714285714, "no_speech_prob": 0.053482383489608765}, {"id": 241, "seek": 146600, "start": 1488.8, "end": 1494.16, "text": " bacteria, monkeys, birds, human beings. It's a system, right? A physical system. We act in our", "tokens": [51504, 11763, 11, 29534, 11, 9009, 11, 1952, 8958, 13, 467, 311, 257, 1185, 11, 558, 30, 316, 4001, 1185, 13, 492, 605, 294, 527, 51772], "temperature": 0.0, "avg_logprob": -0.11128165905292217, "compression_ratio": 1.6214285714285714, "no_speech_prob": 0.053482383489608765}, {"id": 242, "seek": 149416, "start": 1494.16, "end": 1499.6000000000001, "text": " environment. The environment acts back on us. So, there it is, bacteria to brains.", "tokens": [50364, 2823, 13, 440, 2823, 10672, 646, 322, 505, 13, 407, 11, 456, 309, 307, 11, 11763, 281, 15442, 13, 50636], "temperature": 0.0, "avg_logprob": -0.1170019171703821, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0022421882022172213}, {"id": 243, "seek": 149416, "start": 1500.72, "end": 1505.28, "text": " And the math gets really ugly, because it is statistical, probabilistic, and physical all", "tokens": [50692, 400, 264, 5221, 2170, 534, 12246, 11, 570, 309, 307, 22820, 11, 31959, 3142, 11, 293, 4001, 439, 50920], "temperature": 0.0, "avg_logprob": -0.1170019171703821, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0022421882022172213}, {"id": 244, "seek": 149416, "start": 1505.28, "end": 1513.1200000000001, "text": " at the same time. It's complex information theory, essentially. But the ultimate question is,", "tokens": [50920, 412, 264, 912, 565, 13, 467, 311, 3997, 1589, 5261, 11, 4476, 13, 583, 264, 9705, 1168, 307, 11, 51312], "temperature": 0.0, "avg_logprob": -0.1170019171703821, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0022421882022172213}, {"id": 245, "seek": 149416, "start": 1513.8400000000001, "end": 1519.28, "text": " can we build general intelligence? So, I would argue yes, because we have theories. We have very", "tokens": [51348, 393, 321, 1322, 2674, 7599, 30, 407, 11, 286, 576, 9695, 2086, 11, 570, 321, 362, 13667, 13, 492, 362, 588, 51620], "temperature": 0.0, "avg_logprob": -0.1170019171703821, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0022421882022172213}, {"id": 246, "seek": 151928, "start": 1519.36, "end": 1523.04, "text": " compelling theories. All of those are, you know, hundreds and hundreds and hundreds,", "tokens": [50368, 20050, 13667, 13, 1057, 295, 729, 366, 11, 291, 458, 11, 6779, 293, 6779, 293, 6779, 11, 50552], "temperature": 0.0, "avg_logprob": -0.14044179828888778, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.04213681071996689}, {"id": 247, "seek": 151928, "start": 1523.04, "end": 1527.44, "text": " literally thousands of papers written deep mathematical theory, which keeps hundreds of", "tokens": [50552, 3736, 5383, 295, 10577, 3720, 2452, 18894, 5261, 11, 597, 5965, 6779, 295, 50772], "temperature": 0.0, "avg_logprob": -0.14044179828888778, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.04213681071996689}, {"id": 248, "seek": 151928, "start": 1527.44, "end": 1532.96, "text": " graduate students in PhDs. So, yes, we have the theory. We have candidate theories. We have the", "tokens": [50772, 8080, 1731, 294, 14476, 82, 13, 407, 11, 2086, 11, 321, 362, 264, 5261, 13, 492, 362, 11532, 13667, 13, 492, 362, 264, 51048], "temperature": 0.0, "avg_logprob": -0.14044179828888778, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.04213681071996689}, {"id": 249, "seek": 151928, "start": 1532.96, "end": 1538.56, "text": " algorithms and software. We have the hardware, neuromorphic in particular, and we have data", "tokens": [51048, 14642, 293, 4722, 13, 492, 362, 264, 8837, 11, 12087, 32702, 299, 294, 1729, 11, 293, 321, 362, 1412, 51328], "temperature": 0.0, "avg_logprob": -0.14044179828888778, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.04213681071996689}, {"id": 250, "seek": 151928, "start": 1538.56, "end": 1545.04, "text": " sets nowadays. So, yes. And I think we're kind of on our way with these projects like Spinnaker and", "tokens": [51328, 6352, 13434, 13, 407, 11, 2086, 13, 400, 286, 519, 321, 434, 733, 295, 322, 527, 636, 365, 613, 4455, 411, 1738, 7729, 4003, 293, 51652], "temperature": 0.0, "avg_logprob": -0.14044179828888778, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.04213681071996689}, {"id": 251, "seek": 154504, "start": 1545.04, "end": 1551.44, "text": " IBM True North. So, we're starting to build the hardware. It's just a sort of, it's always", "tokens": [50364, 23487, 13587, 4067, 13, 407, 11, 321, 434, 2891, 281, 1322, 264, 8837, 13, 467, 311, 445, 257, 1333, 295, 11, 309, 311, 1009, 50684], "temperature": 0.0, "avg_logprob": -0.10057747828495966, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.007135861553251743}, {"id": 252, "seek": 154504, "start": 1551.44, "end": 1560.48, "text": " just an engineering problem, right? Yeah. So, you know, what else? So, should we? That's an", "tokens": [50684, 445, 364, 7043, 1154, 11, 558, 30, 865, 13, 407, 11, 291, 458, 11, 437, 1646, 30, 407, 11, 820, 321, 30, 663, 311, 364, 51136], "temperature": 0.0, "avg_logprob": -0.10057747828495966, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.007135861553251743}, {"id": 253, "seek": 154504, "start": 1560.48, "end": 1565.12, "text": " ethics question. We won't go into that, because we could spend the rest of our lives arguing", "tokens": [51136, 19769, 1168, 13, 492, 1582, 380, 352, 666, 300, 11, 570, 321, 727, 3496, 264, 1472, 295, 527, 2909, 19697, 51368], "temperature": 0.0, "avg_logprob": -0.10057747828495966, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.007135861553251743}, {"id": 254, "seek": 156512, "start": 1565.12, "end": 1573.6, "text": " should we do it or not. We're going to do it anyway. So, there are some projects. DeepMind is", "tokens": [50364, 820, 321, 360, 309, 420, 406, 13, 492, 434, 516, 281, 360, 309, 4033, 13, 407, 11, 456, 366, 512, 4455, 13, 14895, 44, 471, 307, 50788], "temperature": 0.0, "avg_logprob": -0.13223204320790816, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.09112589806318283}, {"id": 255, "seek": 156512, "start": 1573.6, "end": 1579.28, "text": " trying to, although, you know, all the go and stuff isn't general. It's just specific. But", "tokens": [50788, 1382, 281, 11, 4878, 11, 291, 458, 11, 439, 264, 352, 293, 1507, 1943, 380, 2674, 13, 467, 311, 445, 2685, 13, 583, 51072], "temperature": 0.0, "avg_logprob": -0.13223204320790816, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.09112589806318283}, {"id": 256, "seek": 156512, "start": 1579.28, "end": 1585.1999999999998, "text": " there's a whole bunch of AGI projects and all super interesting things. I definitely encourage", "tokens": [51072, 456, 311, 257, 1379, 3840, 295, 316, 26252, 4455, 293, 439, 1687, 1880, 721, 13, 286, 2138, 5373, 51368], "temperature": 0.0, "avg_logprob": -0.13223204320790816, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.09112589806318283}, {"id": 257, "seek": 156512, "start": 1585.1999999999998, "end": 1591.28, "text": " you to look and explore if you're interested in this subject at all on the internet. In conclusion,", "tokens": [51368, 291, 281, 574, 293, 6839, 498, 291, 434, 3102, 294, 341, 3983, 412, 439, 322, 264, 4705, 13, 682, 10063, 11, 51672], "temperature": 0.0, "avg_logprob": -0.13223204320790816, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.09112589806318283}, {"id": 258, "seek": 159128, "start": 1592.16, "end": 1597.76, "text": " so, it's obvious that deep learning is just statistical. It's not based on physics at all.", "tokens": [50408, 370, 11, 309, 311, 6322, 300, 2452, 2539, 307, 445, 22820, 13, 467, 311, 406, 2361, 322, 10649, 412, 439, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1159771960714589, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.00636119581758976}, {"id": 259, "seek": 159128, "start": 1597.76, "end": 1601.68, "text": " There's like zero physics in there. So, it's definitely not going to get us anywhere towards", "tokens": [50688, 821, 311, 411, 4018, 10649, 294, 456, 13, 407, 11, 309, 311, 2138, 406, 516, 281, 483, 505, 4992, 3030, 50884], "temperature": 0.0, "avg_logprob": -0.1159771960714589, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.00636119581758976}, {"id": 260, "seek": 159128, "start": 1601.68, "end": 1607.6, "text": " general intelligence. But research groups are, many are looking into biopausable models. That's", "tokens": [50884, 2674, 7599, 13, 583, 2132, 3935, 366, 11, 867, 366, 1237, 666, 3228, 404, 8463, 712, 5245, 13, 663, 311, 51180], "temperature": 0.0, "avg_logprob": -0.1159771960714589, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.00636119581758976}, {"id": 261, "seek": 159128, "start": 1607.6, "end": 1613.44, "text": " both on the theoretical and the hardware side. We're sort of getting the glimpse of the very", "tokens": [51180, 1293, 322, 264, 20864, 293, 264, 8837, 1252, 13, 492, 434, 1333, 295, 1242, 264, 25838, 295, 264, 588, 51472], "temperature": 0.0, "avg_logprob": -0.1159771960714589, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.00636119581758976}, {"id": 262, "seek": 159128, "start": 1613.44, "end": 1618.16, "text": " first systems. We have the rat brain there with Spinnaker. So, we're sort of at the very", "tokens": [51472, 700, 3652, 13, 492, 362, 264, 5937, 3567, 456, 365, 1738, 7729, 4003, 13, 407, 11, 321, 434, 1333, 295, 412, 264, 588, 51708], "temperature": 0.0, "avg_logprob": -0.1159771960714589, "compression_ratio": 1.6702898550724639, "no_speech_prob": 0.00636119581758976}, {"id": 263, "seek": 161816, "start": 1618.8000000000002, "end": 1624.96, "text": " beginning of a steep exponential. So, maybe that will improve and in 10 years we'll have a human", "tokens": [50396, 2863, 295, 257, 16841, 21510, 13, 407, 11, 1310, 300, 486, 3470, 293, 294, 1266, 924, 321, 603, 362, 257, 1952, 50704], "temperature": 0.0, "avg_logprob": -0.16999557337810084, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.007396431639790535}, {"id": 264, "seek": 161816, "start": 1624.96, "end": 1630.88, "text": " level brain, which will be conscious and self-aware and subjective experience, which is kind of", "tokens": [50704, 1496, 3567, 11, 597, 486, 312, 6648, 293, 2698, 12, 17074, 293, 25972, 1752, 11, 597, 307, 733, 295, 51000], "temperature": 0.0, "avg_logprob": -0.16999557337810084, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.007396431639790535}, {"id": 265, "seek": 161816, "start": 1630.88, "end": 1635.8400000000001, "text": " spooky and creepy, right? There's nothing. I'm trying to argue there's nothing that mysterious", "tokens": [51000, 30510, 293, 14717, 11, 558, 30, 821, 311, 1825, 13, 286, 478, 1382, 281, 9695, 456, 311, 1825, 300, 13831, 51248], "temperature": 0.0, "avg_logprob": -0.16999557337810084, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.007396431639790535}, {"id": 266, "seek": 161816, "start": 1635.8400000000001, "end": 1642.0, "text": " about the brain. It's just a complex system. And so, what do we do then? Well, we'll figure it out", "tokens": [51248, 466, 264, 3567, 13, 467, 311, 445, 257, 3997, 1185, 13, 400, 370, 11, 437, 360, 321, 360, 550, 30, 1042, 11, 321, 603, 2573, 309, 484, 51556], "temperature": 0.0, "avg_logprob": -0.16999557337810084, "compression_ratio": 1.5502008032128514, "no_speech_prob": 0.007396431639790535}, {"id": 267, "seek": 164200, "start": 1642.0, "end": 1650.08, "text": " as we go along, as we have done everything. And so, the future of AI, Jeff Hinton, he's the", "tokens": [50364, 382, 321, 352, 2051, 11, 382, 321, 362, 1096, 1203, 13, 400, 370, 11, 264, 2027, 295, 7318, 11, 7506, 389, 12442, 11, 415, 311, 264, 50768], "temperature": 0.0, "avg_logprob": -0.16220778006094475, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.060828957706689835}, {"id": 268, "seek": 164200, "start": 1650.08, "end": 1658.4, "text": " godfather of AI. He's in Canada and he, let him have the final word, except there's no volume.", "tokens": [50768, 3044, 11541, 295, 7318, 13, 634, 311, 294, 6309, 293, 415, 11, 718, 796, 362, 264, 2572, 1349, 11, 3993, 456, 311, 572, 5523, 13, 51184], "temperature": 0.0, "avg_logprob": -0.16220778006094475, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.060828957706689835}, {"id": 269, "seek": 164200, "start": 1658.4, "end": 1665.44, "text": " Okay. So, he's just basically saying that the brain is super, everything he's done in his whole", "tokens": [51184, 1033, 13, 407, 11, 415, 311, 445, 1936, 1566, 300, 264, 3567, 307, 1687, 11, 1203, 415, 311, 1096, 294, 702, 1379, 51536], "temperature": 0.0, "avg_logprob": -0.16220778006094475, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.060828957706689835}, {"id": 270, "seek": 166544, "start": 1665.44, "end": 1673.04, "text": " life. He's just clearly admits he wasn't working on general intelligence and to do, to figure out", "tokens": [50364, 993, 13, 634, 311, 445, 4448, 46682, 415, 2067, 380, 1364, 322, 2674, 7599, 293, 281, 360, 11, 281, 2573, 484, 50744], "temperature": 0.0, "avg_logprob": -0.12498669823010762, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.046158771961927414}, {"id": 271, "seek": 166544, "start": 1673.04, "end": 1676.48, "text": " how it works, we're going to have to look at neuroscience. That's pretty much his message.", "tokens": [50744, 577, 309, 1985, 11, 321, 434, 516, 281, 362, 281, 574, 412, 42762, 13, 663, 311, 1238, 709, 702, 3636, 13, 50916], "temperature": 0.0, "avg_logprob": -0.12498669823010762, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.046158771961927414}, {"id": 272, "seek": 166544, "start": 1676.48, "end": 1681.44, "text": " And it's pretty much my message. And so, I hope you've enjoyed my talk. It's been a little bit", "tokens": [50916, 400, 309, 311, 1238, 709, 452, 3636, 13, 400, 370, 11, 286, 1454, 291, 600, 4626, 452, 751, 13, 467, 311, 668, 257, 707, 857, 51164], "temperature": 0.0, "avg_logprob": -0.12498669823010762, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.046158771961927414}, {"id": 273, "seek": 166544, "start": 1681.44, "end": 1685.04, "text": " different from everyone else's, but thanks. Yeah. And we have questions, of course.", "tokens": [51164, 819, 490, 1518, 1646, 311, 11, 457, 3231, 13, 865, 13, 400, 321, 362, 1651, 11, 295, 1164, 13, 51344], "temperature": 0.0, "avg_logprob": -0.12498669823010762, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.046158771961927414}, {"id": 274, "seek": 168504, "start": 1685.04, "end": 1698.48, "text": " Okay. One interesting question is, could AGI be achieved without emulating human brain but", "tokens": [50364, 1033, 13, 1485, 1880, 1168, 307, 11, 727, 316, 26252, 312, 11042, 1553, 846, 12162, 1952, 3567, 457, 51036], "temperature": 0.0, "avg_logprob": -0.13325931714928668, "compression_ratio": 1.3969849246231156, "no_speech_prob": 0.03847823664546013}, {"id": 275, "seek": 168504, "start": 1698.48, "end": 1706.72, "text": " building a completely different model? No. That was a short one. You kind of answered this one,", "tokens": [51036, 2390, 257, 2584, 819, 2316, 30, 883, 13, 663, 390, 257, 2099, 472, 13, 509, 733, 295, 10103, 341, 472, 11, 51448], "temperature": 0.0, "avg_logprob": -0.13325931714928668, "compression_ratio": 1.3969849246231156, "no_speech_prob": 0.03847823664546013}, {"id": 276, "seek": 168504, "start": 1706.72, "end": 1711.92, "text": " but maybe you can elaborate a little bit more. When do you think AGI will arrive? And I can", "tokens": [51448, 457, 1310, 291, 393, 20945, 257, 707, 857, 544, 13, 1133, 360, 291, 519, 316, 26252, 486, 8881, 30, 400, 286, 393, 51708], "temperature": 0.0, "avg_logprob": -0.13325931714928668, "compression_ratio": 1.3969849246231156, "no_speech_prob": 0.03847823664546013}, {"id": 277, "seek": 171192, "start": 1711.92, "end": 1717.6000000000001, "text": " follow with another one. As you said, you're at 50% of achieving AGI. What are the main", "tokens": [50364, 1524, 365, 1071, 472, 13, 1018, 291, 848, 11, 291, 434, 412, 2625, 4, 295, 19626, 316, 26252, 13, 708, 366, 264, 2135, 50648], "temperature": 0.0, "avg_logprob": -0.13909970988398013, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.08742382377386093}, {"id": 278, "seek": 171192, "start": 1717.6000000000001, "end": 1722.48, "text": " challenges you are facing to get to 100% what technology breakthroughs are needed?", "tokens": [50648, 4759, 291, 366, 7170, 281, 483, 281, 2319, 4, 437, 2899, 22397, 82, 366, 2978, 30, 50892], "temperature": 0.0, "avg_logprob": -0.13909970988398013, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.08742382377386093}, {"id": 279, "seek": 171192, "start": 1722.48, "end": 1728.88, "text": " Yeah. So, it's basically a hardware engineering problem. So, I did show the Spinnaker and there", "tokens": [50892, 865, 13, 407, 11, 309, 311, 1936, 257, 8837, 7043, 1154, 13, 407, 11, 286, 630, 855, 264, 1738, 7729, 4003, 293, 456, 51212], "temperature": 0.0, "avg_logprob": -0.13909970988398013, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.08742382377386093}, {"id": 280, "seek": 171192, "start": 1728.88, "end": 1734.0, "text": " are the hardware projects around the world doing this, like IBM and Intel. And so,", "tokens": [51212, 366, 264, 8837, 4455, 926, 264, 1002, 884, 341, 11, 411, 23487, 293, 19762, 13, 400, 370, 11, 51468], "temperature": 0.0, "avg_logprob": -0.13909970988398013, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.08742382377386093}, {"id": 281, "seek": 171192, "start": 1734.0, "end": 1738.0800000000002, "text": " with that's the mouse brain right there. So, basically, it's a scaling problem now. I mean,", "tokens": [51468, 365, 300, 311, 264, 9719, 3567, 558, 456, 13, 407, 11, 1936, 11, 309, 311, 257, 21589, 1154, 586, 13, 286, 914, 11, 51672], "temperature": 0.0, "avg_logprob": -0.13909970988398013, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.08742382377386093}, {"id": 282, "seek": 173808, "start": 1738.08, "end": 1745.36, "text": " we started at one transistor at one point with classical computing and then companies like Intel", "tokens": [50364, 321, 1409, 412, 472, 34750, 412, 472, 935, 365, 13735, 15866, 293, 550, 3431, 411, 19762, 50728], "temperature": 0.0, "avg_logprob": -0.12991265455881754, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.04410403221845627}, {"id": 283, "seek": 173808, "start": 1745.36, "end": 1751.76, "text": " were formed and AMD and NVIDIA and the rest is history, right? It'll go on its own Moore's law.", "tokens": [50728, 645, 8693, 293, 34808, 293, 426, 3958, 6914, 293, 264, 1472, 307, 2503, 11, 558, 30, 467, 603, 352, 322, 1080, 1065, 21644, 311, 2101, 13, 51048], "temperature": 0.0, "avg_logprob": -0.12991265455881754, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.04410403221845627}, {"id": 284, "seek": 173808, "start": 1751.76, "end": 1756.6399999999999, "text": " So, right now, we're at the kind of like 10 transistor stage that we were with classical. So,", "tokens": [51048, 407, 11, 558, 586, 11, 321, 434, 412, 264, 733, 295, 411, 1266, 34750, 3233, 300, 321, 645, 365, 13735, 13, 407, 11, 51292], "temperature": 0.0, "avg_logprob": -0.12991265455881754, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.04410403221845627}, {"id": 285, "seek": 173808, "start": 1756.6399999999999, "end": 1762.8799999999999, "text": " we'll just see that scale. I'm going to say something really bold. It's just a scaling", "tokens": [51292, 321, 603, 445, 536, 300, 4373, 13, 286, 478, 516, 281, 584, 746, 534, 11928, 13, 467, 311, 445, 257, 21589, 51604], "temperature": 0.0, "avg_logprob": -0.12991265455881754, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.04410403221845627}, {"id": 286, "seek": 176288, "start": 1762.88, "end": 1767.0400000000002, "text": " problem at this point in time. So, watch this space. So, what will you say?", "tokens": [50364, 1154, 412, 341, 935, 294, 565, 13, 407, 11, 1159, 341, 1901, 13, 407, 11, 437, 486, 291, 584, 30, 50572], "temperature": 0.0, "avg_logprob": -0.17889560900236431, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.08275802433490753}, {"id": 287, "seek": 176288, "start": 1769.3600000000001, "end": 1776.72, "text": " Well, it'll go mouse and then it will go Bumblebee and then mouse and then monkey and then human.", "tokens": [50688, 1042, 11, 309, 603, 352, 9719, 293, 550, 309, 486, 352, 363, 16473, 24872, 293, 550, 9719, 293, 550, 17847, 293, 550, 1952, 13, 51056], "temperature": 0.0, "avg_logprob": -0.17889560900236431, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.08275802433490753}, {"id": 288, "seek": 176288, "start": 1776.72, "end": 1781.7600000000002, "text": " So, we're on a curve. So, human in 10 years, that's my prediction.", "tokens": [51056, 407, 11, 321, 434, 322, 257, 7605, 13, 407, 11, 1952, 294, 1266, 924, 11, 300, 311, 452, 17630, 13, 51308], "temperature": 0.0, "avg_logprob": -0.17889560900236431, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.08275802433490753}, {"id": 289, "seek": 176288, "start": 1781.7600000000002, "end": 1787.1200000000001, "text": " They're too optimistic. I mean, in 1969, when people flew to moon, they thought that they", "tokens": [51308, 814, 434, 886, 19397, 13, 286, 914, 11, 294, 32090, 11, 562, 561, 15728, 281, 7135, 11, 436, 1194, 300, 436, 51576], "temperature": 0.0, "avg_logprob": -0.17889560900236431, "compression_ratio": 1.6019417475728155, "no_speech_prob": 0.08275802433490753}, {"id": 290, "seek": 178712, "start": 1787.36, "end": 1792.56, "text": " would be living on the moon by now. Okay. I'm an optimist. I'm saying 10. Yeah.", "tokens": [50376, 576, 312, 2647, 322, 264, 7135, 538, 586, 13, 1033, 13, 286, 478, 364, 5028, 468, 13, 286, 478, 1566, 1266, 13, 865, 13, 50636], "temperature": 0.0, "avg_logprob": -0.22089700878791088, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.03692664951086044}, {"id": 291, "seek": 178712, "start": 1793.6799999999998, "end": 1798.6399999999999, "text": " Okay. But I appreciate that. The last one, a comment about the Soul Machines Baby X project", "tokens": [50692, 1033, 13, 583, 286, 4449, 300, 13, 440, 1036, 472, 11, 257, 2871, 466, 264, 13588, 12089, 1652, 9425, 1783, 1716, 50940], "temperature": 0.0, "avg_logprob": -0.22089700878791088, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.03692664951086044}, {"id": 292, "seek": 178712, "start": 1798.6399999999999, "end": 1804.4799999999998, "text": " and the potential to get closer to general AI. What's that? Say that again? Yeah. I haven't heard", "tokens": [50940, 293, 264, 3995, 281, 483, 4966, 281, 2674, 7318, 13, 708, 311, 300, 30, 6463, 300, 797, 30, 865, 13, 286, 2378, 380, 2198, 51232], "temperature": 0.0, "avg_logprob": -0.22089700878791088, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.03692664951086044}, {"id": 293, "seek": 178712, "start": 1804.4799999999998, "end": 1810.56, "text": " about the Soul Machines Baby X project. Oh, yeah. I have. Yeah. Okay. Well, certainly. What was the", "tokens": [51232, 466, 264, 13588, 12089, 1652, 9425, 1783, 1716, 13, 876, 11, 1338, 13, 286, 362, 13, 865, 13, 1033, 13, 1042, 11, 3297, 13, 708, 390, 264, 51536], "temperature": 0.0, "avg_logprob": -0.22089700878791088, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.03692664951086044}, {"id": 294, "seek": 181056, "start": 1810.56, "end": 1817.76, "text": " question? The Baby X? I mean, your comment about it and the potential to get closer to general AI.", "tokens": [50364, 1168, 30, 440, 9425, 1783, 30, 286, 914, 11, 428, 2871, 466, 309, 293, 264, 3995, 281, 483, 4966, 281, 2674, 7318, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1494162625605517, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.07080230861902237}, {"id": 295, "seek": 181056, "start": 1817.76, "end": 1823.2, "text": " Yeah. I didn't actually mention Baby X, but that's a nice project in New Zealand. And it's another", "tokens": [50724, 865, 13, 286, 994, 380, 767, 2152, 9425, 1783, 11, 457, 300, 311, 257, 1481, 1716, 294, 1873, 13883, 13, 400, 309, 311, 1071, 50996], "temperature": 0.0, "avg_logprob": -0.1494162625605517, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.07080230861902237}, {"id": 296, "seek": 181056, "start": 1824.08, "end": 1830.24, "text": " AGI project. But basically, it's going to come back to neuroscience. You know, we saw the mass,", "tokens": [51040, 316, 26252, 1716, 13, 583, 1936, 11, 309, 311, 516, 281, 808, 646, 281, 42762, 13, 509, 458, 11, 321, 1866, 264, 2758, 11, 51348], "temperature": 0.0, "avg_logprob": -0.1494162625605517, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.07080230861902237}, {"id": 297, "seek": 181056, "start": 1830.24, "end": 1836.24, "text": " we saw some of the mathematics involved. It's going to be people working at that level from a", "tokens": [51348, 321, 1866, 512, 295, 264, 18666, 3288, 13, 467, 311, 516, 281, 312, 561, 1364, 412, 300, 1496, 490, 257, 51648], "temperature": 0.0, "avg_logprob": -0.1494162625605517, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.07080230861902237}, {"id": 298, "seek": 183624, "start": 1836.24, "end": 1840.56, "text": " theoretical point of view. And other people like Steve Furber and the Human Brain Project,", "tokens": [50364, 20864, 935, 295, 1910, 13, 400, 661, 561, 411, 7466, 11705, 607, 293, 264, 10294, 29783, 9849, 11, 50580], "temperature": 0.0, "avg_logprob": -0.19226512041958896, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.023326491937041283}, {"id": 299, "seek": 183624, "start": 1841.28, "end": 1845.84, "text": " you know, brilliant engineers basically working on the hardware level, and these people talking", "tokens": [50616, 291, 458, 11, 10248, 11955, 1936, 1364, 322, 264, 8837, 1496, 11, 293, 613, 561, 1417, 50844], "temperature": 0.0, "avg_logprob": -0.19226512041958896, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.023326491937041283}, {"id": 300, "seek": 183624, "start": 1845.84, "end": 1851.52, "text": " to each other. And I know Carl Friston and Steve Furber do talk to each other and building this", "tokens": [50844, 281, 1184, 661, 13, 400, 286, 458, 14256, 1526, 47345, 293, 7466, 11705, 607, 360, 751, 281, 1184, 661, 293, 2390, 341, 51128], "temperature": 0.0, "avg_logprob": -0.19226512041958896, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.023326491937041283}, {"id": 301, "seek": 183624, "start": 1851.52, "end": 1856.56, "text": " very complex system. Okay, Peter, thank you. Thank you. I will present you with a certificate.", "tokens": [51128, 588, 3997, 1185, 13, 1033, 11, 6508, 11, 1309, 291, 13, 1044, 291, 13, 286, 486, 1974, 291, 365, 257, 15953, 13, 51380], "temperature": 0.0, "avg_logprob": -0.19226512041958896, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.023326491937041283}, {"id": 302, "seek": 185656, "start": 1856.56, "end": 1864.56, "text": " Thank you, Peter. Thank you, sir. Thank you, sir. Thank you, sir.", "tokens": [50364, 1044, 291, 11, 6508, 13, 1044, 291, 11, 4735, 13, 1044, 291, 11, 4735, 13, 1044, 291, 11, 4735, 13, 50764], "temperature": 0.0, "avg_logprob": -0.6385278036428053, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.4226206839084625}, {"id": 303, "seek": 185656, "start": 1864.56, "end": 1868.56, "text": " Thank you. We, we got to, we got to fill in with the certificate.", "tokens": [50764, 1044, 291, 13, 492, 11, 321, 658, 281, 11, 321, 658, 281, 2836, 294, 365, 264, 15953, 13, 50964], "temperature": 0.0, "avg_logprob": -0.6385278036428053, "compression_ratio": 1.6794871794871795, "no_speech_prob": 0.4226206839084625}], "language": "en"}