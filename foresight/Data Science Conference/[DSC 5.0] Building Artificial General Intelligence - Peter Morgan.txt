So, hi everybody, as a guy gentleman just said, I'm the CEO of a consulting company
in London called Deep Learning Partnership and I'm going to talk to you today about
something I don't really do on my day-to-day job, it doesn't pay my rent, but it affords
me nice trips to exotic places. So, who here has heard of artificial general intelligence?
Yeah, so quite a few. And so, what we label today is AI, isn't really AI, it's matrix
multiplication. So, I'm going to talk to you today about how we might actually get to AGI
and it's more of a neuroscience based approach. It's how the brain works, it's how biology does it.
So, it's okay, everything that we've heard the speakers talk about so far,
which has been labeled AI, it's really deep learning or artificial neural networks
and the early creators of that said this is nothing to do with how the brain works, right?
It's just it kind of works to classify cats and dogs and that's about it. We do a lot more than
that. So, how do we get there? Is it even possible to build an artificial brain basically
how biology does it? And I'm here to tell you, yes it is, I'll just give it away,
you can go now, but if you're interested, I'll walk you through how that might look and how that
might be done. Okay, so here's a little book I wrote for Riley, it's a booklet. There's my
company website, there's my Twitter handle, you can follow me, I tweet a little bit about AGI and
sometimes quantum computing, my other hobby or interest. So, this is what we're going to
outline just briefly. We're going to look at physical systems, how biology does intelligence,
and where we are with the non-biological, I've kind of just explained that in a broad sense,
but we'll look at some of the, well, we'll go through the slides, deep learning recap and then
we'll look at how we might build AGI and some of the theories and in particular one called
active inference that I find particularly compelling to how the brain might work. Okay, so at that
point it's sort of theoretical neuroscience, so I hope I don't lose you. I try to keep this kind of
high level and not too much code or anything, although there is code and math for this stuff.
And then we'll wrap it up by saying is it possible, how long might it take? Okay, so why do we even
want to build AGI? Why don't we just stop here with the cats and dogs and TensorFlow? Well,
if we do, like DeepMind says, if we can solve intelligence and we can use it to solve everything
else. I mean, we're quite good at stuff, we've got here today, we've had Einstein's theory of
relativity, we've had quantum physics, we've had classical physics, Newton, all the big names,
why do we need any help? Well, clearly if we do manage to figure this out and build an artificially
general intelligent system, then we can accelerate progress, which is probably, we can all agree,
is a good thing. Although some people like Elon must say that, let's not build it because it will
straight away kill us all, right? Well, we don't know, but I don't think it will. Okay, so I'm
the anti-Elon Musk, okay? I'm the opposite. Okay, so I'm an optimist, he's a pessimist.
So he's a good entrepreneur anyway. So what about all of these things here? AlphaGo,
this is DeepMind in London, I'm sure we all saw on TV, AlphaGo beating the best go player in the
world, was that AI, was that AGI? AlphaStar, it's a new project to beat the world's best video game
players, a little bit more general one might argue than just playing a board game. DeepBlue,
IBM's DeepBlue and Chess, Landmark, and IBM Watson, that's actually natural language processing,
so that's quite clever, that's quite getting a little closer to AGI maybe, because it's having
to understand language, but was it just doing it statistically? Was it just a massive computer
hardware system that could crunch numbers really well and just do everything statistically? Is
it how we learn language and understand language? I would argue no. So actually, all of those are
just narrow AI, they're just statistical mathematical analysis of big data sets, okay? So it's not really
how the brain does anything. If it were, I mean we do all of that in that little three pound thing
above our sitting, above our shoulders, right? We don't need huge data centers, so clearly biology
is doing it in a slightly different way, okay? So how is it doing it and how is it different?
So first of all, to build something, we have to understand what we're building. What is
intelligence, general intelligence? Well, it's all these things, right? So we don't just classify
things, we do all of that. I won't read them out, because I've only got 30 minutes and sometimes
I give this talk, it's an hour, but there's basically nine types of intelligence there,
maybe even 10. And this guy at Harvard, Howard Gardner, just mapped it all out. See,
existential thinking language, we can do math using ANNs, but the rest of it is pretty much
music, creating art, spatial navigation, that's all. We can do all of that in three pound. We
don't need a huge data center, hardware cluster of GPUs. So what's different? What are we missing?
Okay. Well, first of all, how far have we come? Like I said, the mathematical part,
we're like 50%, we're pretty good, we're not bad, we're about halfway there, linguistic,
but it's only statistical analysis. Spatial navigation, self-driving cars, robots who can
navigate through systems. I'd say we're about something called SLAM. I'd say we're about 50%
there, that's the algorithm, simultaneous mapping and I forgot what the LAM stands for,
but don't worry. We're about 50% there. You've probably seen simultaneous localization and mapping.
You've probably seen the Atlas, you know, robot that do flips and run around outside and do good
stuff, busts and dynamics. So that's why I'm giving it a generous 50%. We do a lot more than that.
We can do gymnastics, we can run around, we learn stuff very quickly, we don't need millions of
datasets to train, but as we go through that list of nine types of intelligence, it gets really,
it just gets worse, right? Robots understanding each other or even algorithms running on a
computer virtual sort of intelligence. Intrapersonal understanding themselves and existential,
you know, show me an algorithm or a robot that kind of questions why it's there,
or even understands that it exists, it's kind of zero. So we haven't figured that intelligence
out at all. So the brain is pretty special, right? Biology is kind of special. We could argue chimpanzees,
self-aware, well, yes, right, a dog, cats, probably. And as you go, you know, snails,
maybe not, you know, bacteria, no. So there's clearly a continuum in what makes us a little
different is our neocortex, that sort of outer layer of the brain. So we kind of have to figure
out how that works, basically. But we've got all this other stuff in the brain like the amygdala
for emotional intelligence, you know, the reptilian brain and there's sort of layers, you can trace it.
In fact, you know, as babies are born and embryos develop over the nine months,
you can see, you know, evolution, it starts off, you know, with the, you know,
reptilian brain and it goes out monkey and then, you know, humans as we develop in the womb. So,
you know, it's all, all of that evolution is still captured, all that information is actually
captured by biology. It's just that last layer of the neocortex that makes us be able to come up
with, you know, science, special theory, relativity, whatever, you know, that, that. So what are we
missing? Why can't we do that yet in TensorFlow? Okay, why can't Google or DeepMind do that yet?
So how will we get there? Well, it takes a village to create a child and I'm going to argue it takes,
it's going to take a big community to create AGI. We're going to need computer scientists,
physicists to understand the physics of the brain, neuroscientists, clearly,
and also psychologists. So what I'm seeing really at the moment where these teams trying to build
AGI or AI are just computer scientists, you know, just computer scientists, you know,
you're clever people, they have PhDs and computer science, which involves a lot of math and
understanding hardware and algorithm, algorithmic complexity. But it's not really
understanding how much about biology at all. Okay, so we're going to need a whole bunch of people.
And so I'll speed up a little bit now. I've kind of laid the foundations for what we might need.
So this is basically what we've got in hardware. So this is how biology does it in hardware. So,
you know, like I mentioned, we have a continuum from bacteria. That's a simple, C elegance is the
simplest biological system with a central nervous system, it has, I think, about 300 neurons, then
the bumblebee, the humble bumblebee with about a million, a few million neurons, and then us with
about 80 billion or 100 billion neurons. Okay, so what, you know, what basically, maybe if we
start at the simple, the C elegance and then build a bumblebee, then maybe one day, you know, we'll
get to us. That's one sort of thought. The other, the other observation really is that nature is
very hierarchical. You know, we built neurons, built of, they're not magic, you know, the built
of atoms, molecules. And then if we just go up the different layers, we have synapses, neurons,
and collection of neurons as connectome. So these 80 billion neurons are organized into some kind of
structure. Maybe, you know, we should start there. So the question here is, you know, what level do
we start at? Do we have to start at molecules or can we start at neurons or should we start a little
more holistically at the connectome? You know, and on and on up until the central nervous system,
us, which is about a meter in dimensions. So we're going from 10 to the minus 10 up to a meter.
So it's a hard problem. It's kind of no wonder we haven't solved it yet. There's a lot of physics
in there. And so that's what it looks like. This is how nature has done it. It's complicated,
isn't it? You know, I mean, do we need all that little tiny microstructure? Probably not, I might
argue. So you know, this is how, you know, what do we for in a half billion years of evolution
on the earth, maybe a billion since the first sort of organisms, bacteria, whatever, the first,
you know, primitive life. So over that billion year, this is what this is what nature's ended
up with, right? This is what makes us intelligent, these things, right? You couldn't guess that.
You start with a blank piece of paper, but this is just the universe we live in, the laws of physics.
This is this is how we work. Okay. So there's no magic, but there's certainly a lot of
complication. It's a complicated looking thing. That's a neuron. Okay. And so the next level of
the hierarchy, we see that these neurons are kind of organized into some kind of structure
called cortical columns, which each have about two, two million neurons. So maybe this is a
good level to start. Maybe we don't have to go right down to all that complicated structure,
maybe here. So that's kind of an interesting thing that we know. And then up onto the connectome,
and then the central nervous system. If we want to build a robot, we need that those flips,
we'll probably need all of that connected to the brain at the top. Okay. So
and then we have societies where we're organized into societies. Bees are, you know,
in their swarms and humans in their villages, towns, cities, countries, and then the global
national community. So there's all these layers of hierarchy, which are intelligent, right? So,
you know, we have this kind of macro meta intelligence built into communities and systems
of communities, which has enabled us to, you know, survive reproduced into the next generation.
So, okay. So that's biology. That's how it works. That's how it does it. That's what we know,
plus a whole lot of other details, which I haven't really covered.
So what have we done? How far are we along the line with hardware? So basically, the talks
that we'll see here, you know, talking about CPUs, HGO, GPUs, that's what they use, sparkling water
all runs on these things. There's a new sort of endeavor to build ASICs, which are specialized
for deep learning. But again, it's just narrow AIS, it's matrix multiplication. But is it grok
and cerebrus, graph core, Intel, Nirvana, they're all coming out with these amazing things that
can do, you know, petaflops operations, which is more than the brain does. It's actually more
than biology does. But all they're doing is multiplying matrices, right? They're incredible
feats of micro engineering, incredible. These fabs cost, you know, billions of dollars to build.
They've already, you know, graph core just raised $200 million. And they're impressive things,
right? And that's what I look like that CPU GPU. There's a Google TPU, which is an ASIC,
and runs in their data centers, you can hire them, run them in the cloud. And then there's the graph
core IPU. And they all look the same, but you know, the micro architecture is a little different.
So that, you know, this is all digital classical. If you do a computer science, you'd understand,
you know, the details of how bits move around in there, how much energy it takes, how the memory
in the processor, you know, interact together. But they're not intelligent, right? They're just
very good mathematical processors. Okay, that's what a hundred petaflops looks like. And you can,
you know, log in today to these things. The Google data center, this is the most powerful,
you know, three exaflops, we're going to say that that's 1000 million, almost a million times more
powerful than the brain. But it says dumb as a brick, it's the sun, it's incredibly impressive
engineering, it takes up a football field, it's a data center size, but you can't do much except
for model plane numbers together, it's not intelligent. Okay, so clearly we're heading
into a dead end, if we just follow that computer science classical digital hardware route.
See the brain does all of that and all the other types of intelligence in that little three pound
mass. So clearly, it's not just about speed of compute, right? It's not just about horsepower.
So what is it about? Okay, so recently, some of you, who's heard of neuromorphic computing?
Who's heard of that? Yeah, maybe a few, right? A couple. So there's a project called Spinnaker
in the UK. There's, there's IBM True North, Intel, the OHE. There's, you know, a few different
projects that are trying to do mimic how biology in hardware, you know, does, does computation.
Okay, it's called neuromorphic computing. So it's based on the brain. And so there's Steve Furber,
he's one of the guys who come up, invented, founded the ARM computer processor company.
And so he, 20 years ago, left ARM and started on this neuromorphic journey. He's based at
University of Manchester. And recently, the human brain project has folded. It's called Spinnaker
into itself because it's biopausable hardware. So they have lots of nice funding now, again,
as IBM True North and Intel. I mean, these companies have a lot of money too. So that's
what it looks like. So there's five racks there. That is about as powerful as the brain of a mouse.
So it's not human level yet, but it can do things that can go through a maze, it can solve Sudoku
and stuff like that, just like we do. So it's kind of getting there. And I would argue, you know,
to build intelligence, rather than just simulating it on classical digital hardware, this is a more
intelligent route to take. Okay. So, and there's a little bit of detail. So this is an important,
you know, technology and a new path that not many have heard of here, you know, which is very
interesting. It's probably like we were in the 50s with digital computing. You know, there's just a
few main frames in the world right now, a few of these devices, but they actually exist. And you
can actually log into Spinnaker. It's part of the human brain project. You can create an account,
log in and watch it do stuff in real time. So they're not these magical, mystical things in a
lab. They're kind of getting in real. And let's see. So that's okay. That's another initiative
from Heidelberg, the brain scales project, which is also part of the human brain project.
So the one on the left, I would argue, will get us to general intelligence. The one on the right,
no matter how impressive that looks, won't. Okay. So, and then there's quantum computing,
how about it? Is the brain quantum? No, it's warm, it's squidgy, nothing to do with quantum
at all. Okay. Although birds navigate and plants photosynthesize using quantum processes,
but it's not really generally how we do it. Okay. But the pictures look really nice. I decided
to include a couple and it is what a quantum circuit looks like. I also quite like quantum
computing because I have a physical background, but it's probably we don't need to worry about that
if we're building AGI. It might help some of the computations initially, but ultimately we're not
a quantum computer up here. It's a neuromorphic computer. Okay. So that's the sort of four different
types of hardware. And I'd argue the one on the top right, neuromorphic will get us there. And
that's how they look in a little bit more detail. And so, you know, it's not magic. It's just really
hard engineering, which is why we haven't built it yet. It's just hard. Okay. It's small. It's,
you know, and to understand it's difficult. Do we have a mathematical theory of the brain? Well,
I would argue sort of before I go there. So the data center of the future right now is just full
of those very clever chips we saw the graph core, the, you know, TPU GPU CPUs, very, you know,
amazing engineering, but soon we'll see them being filled up with neuromorphic and quantum as well.
So Google announced quantum supremacy last week, a couple of weeks ago, which means that a quantum
computer, it can do something faster than the biggest classical computer. So the data center
of future will look like this. Okay. So we're interesting. We're entering a very interesting
time in human history, I think, in terms of computation, because we haven't just got classical
computing, we have neuromorphic and quantum as well coming online. It's been 80 years, right,
since we first started doing a computation. So at a very interesting time, I think in
the history of computation with these other two major types of computation coming online.
So deep learning, I've argued that won't get us anywhere near intelligence. It will classify
stuff really well and do a little bit of statistical language processing, but it doesn't
do the nine types of intelligence. Okay. And so the most popular framework by far as TensorFlow,
PyTorch is kind of also increasing in the last little while, but you know,
general intelligence, how biology does it, it doesn't do matrix multiplication. So deep learning
is not AGI. So we won't talk about that, but we will talk about more neuroscience stuff. Okay.
Sorry to be so harsh, but you know, it's reality. All that clever stuff isn't actually AGI, but
it's good at certain things. Okay. So what do we do? I mean, where do we even start, right,
with the general theory of intelligence? Well, you know, the brain is a physical system, right?
It's just three pounds of physics, just, okay. So what do we know about physics? Well, we've
pretty much discovered all of the laws of physics. I think dark matter is kind of a new one. It's a
bit of a bold statement. I'm a physicist. I'm allowed to say that. So what are, I mean, what
out of there do we use? Okay. You know, probably thermodynamics and electromagnetism in a complex
system, right? So it's nothing magic. Now the underlying theory of all of this, all of that
can be described in something called the principle of least action, which is that, and it's just
been a book published last year. Surprisingly, it wasn't one before that sort of says, okay,
all of physics, that's, you know, classical quantum, everything can be, you know, derived
starting with this principle of least action. Now, if anyone's who's got a PhD in physics here,
yeah, a few people. And so we've all, this is what you get at grad school in physics, right? We do
Lagrangians and Hamiltonians and principles of least action. So everything we learn,
if equals ma and undergrad, we're told, yeah, that's very nice and quaint. But really, this is
the powerful machinery that's been developed. But we don't, you know, that we sort of, we get,
we get there, but I think we're not really taught that, you know, it's very unifying principle.
Okay, so I'm saying, okay, probably that's a nice place to start if we want to try to come
up with a general theory of intelligence. Okay, it's a big statement and bold statement, but,
you know, the brain is not doing anything that physical systems can't do, even though it feels
kind of, it is different, right? Because we have consciousness and, you know, that subjective
experience and self-awareness and that kind of stuff. But I'm going to argue it's all just physics.
There are people in the room and elsewhere who will say, no, there's something beyond physics,
metaphysics. I'm not one of those people. Okay, so I'm just going to keep it really simple.
So, you know, what can we do? Well, we can explain and understand what we see. We can imagine things,
you know, imagination, imagine that. Problem solving, planning actions to make these things
real, we can do all of that. That's what intelligence is really. And we can build new models as we
learn about the world. So, probably, okay, we've got five minutes. So, these are the sort of major,
some of the major theories of general intelligence, mathematical theory. These are all smart people
who have spent their whole lives dedicating to this. You can look them up later. There's
a guy called Carl Friston at UCL in London. And so, his theory of active inference is the one
that I think is particularly compelling. And I won't spend any time going through the details,
because it's pretty hard math, actually, but he uses something called a free energy principle.
It's based on physics and information theory. It's nothing kind of new and crazy. It's just
applying it to the brain. And he is a theoretical neuroscientist. And so, here he is.
And we don't have time to play it. So, the slides will be made available, I think,
so you can listen to him. And he's on YouTube, if you want to Google. And so, that's how he
sets it up. There's internal, there's us agents acting in an environment. That's the same if we're
bacteria, monkeys, birds, human beings. It's a system, right? A physical system. We act in our
environment. The environment acts back on us. So, there it is, bacteria to brains.
And the math gets really ugly, because it is statistical, probabilistic, and physical all
at the same time. It's complex information theory, essentially. But the ultimate question is,
can we build general intelligence? So, I would argue yes, because we have theories. We have very
compelling theories. All of those are, you know, hundreds and hundreds and hundreds,
literally thousands of papers written deep mathematical theory, which keeps hundreds of
graduate students in PhDs. So, yes, we have the theory. We have candidate theories. We have the
algorithms and software. We have the hardware, neuromorphic in particular, and we have data
sets nowadays. So, yes. And I think we're kind of on our way with these projects like Spinnaker and
IBM True North. So, we're starting to build the hardware. It's just a sort of, it's always
just an engineering problem, right? Yeah. So, you know, what else? So, should we? That's an
ethics question. We won't go into that, because we could spend the rest of our lives arguing
should we do it or not. We're going to do it anyway. So, there are some projects. DeepMind is
trying to, although, you know, all the go and stuff isn't general. It's just specific. But
there's a whole bunch of AGI projects and all super interesting things. I definitely encourage
you to look and explore if you're interested in this subject at all on the internet. In conclusion,
so, it's obvious that deep learning is just statistical. It's not based on physics at all.
There's like zero physics in there. So, it's definitely not going to get us anywhere towards
general intelligence. But research groups are, many are looking into biopausable models. That's
both on the theoretical and the hardware side. We're sort of getting the glimpse of the very
first systems. We have the rat brain there with Spinnaker. So, we're sort of at the very
beginning of a steep exponential. So, maybe that will improve and in 10 years we'll have a human
level brain, which will be conscious and self-aware and subjective experience, which is kind of
spooky and creepy, right? There's nothing. I'm trying to argue there's nothing that mysterious
about the brain. It's just a complex system. And so, what do we do then? Well, we'll figure it out
as we go along, as we have done everything. And so, the future of AI, Jeff Hinton, he's the
godfather of AI. He's in Canada and he, let him have the final word, except there's no volume.
Okay. So, he's just basically saying that the brain is super, everything he's done in his whole
life. He's just clearly admits he wasn't working on general intelligence and to do, to figure out
how it works, we're going to have to look at neuroscience. That's pretty much his message.
And it's pretty much my message. And so, I hope you've enjoyed my talk. It's been a little bit
different from everyone else's, but thanks. Yeah. And we have questions, of course.
Okay. One interesting question is, could AGI be achieved without emulating human brain but
building a completely different model? No. That was a short one. You kind of answered this one,
but maybe you can elaborate a little bit more. When do you think AGI will arrive? And I can
follow with another one. As you said, you're at 50% of achieving AGI. What are the main
challenges you are facing to get to 100% what technology breakthroughs are needed?
Yeah. So, it's basically a hardware engineering problem. So, I did show the Spinnaker and there
are the hardware projects around the world doing this, like IBM and Intel. And so,
with that's the mouse brain right there. So, basically, it's a scaling problem now. I mean,
we started at one transistor at one point with classical computing and then companies like Intel
were formed and AMD and NVIDIA and the rest is history, right? It'll go on its own Moore's law.
So, right now, we're at the kind of like 10 transistor stage that we were with classical. So,
we'll just see that scale. I'm going to say something really bold. It's just a scaling
problem at this point in time. So, watch this space. So, what will you say?
Well, it'll go mouse and then it will go Bumblebee and then mouse and then monkey and then human.
So, we're on a curve. So, human in 10 years, that's my prediction.
They're too optimistic. I mean, in 1969, when people flew to moon, they thought that they
would be living on the moon by now. Okay. I'm an optimist. I'm saying 10. Yeah.
Okay. But I appreciate that. The last one, a comment about the Soul Machines Baby X project
and the potential to get closer to general AI. What's that? Say that again? Yeah. I haven't heard
about the Soul Machines Baby X project. Oh, yeah. I have. Yeah. Okay. Well, certainly. What was the
question? The Baby X? I mean, your comment about it and the potential to get closer to general AI.
Yeah. I didn't actually mention Baby X, but that's a nice project in New Zealand. And it's another
AGI project. But basically, it's going to come back to neuroscience. You know, we saw the mass,
we saw some of the mathematics involved. It's going to be people working at that level from a
theoretical point of view. And other people like Steve Furber and the Human Brain Project,
you know, brilliant engineers basically working on the hardware level, and these people talking
to each other. And I know Carl Friston and Steve Furber do talk to each other and building this
very complex system. Okay, Peter, thank you. Thank you. I will present you with a certificate.
Thank you, Peter. Thank you, sir. Thank you, sir. Thank you, sir.
Thank you. We, we got to, we got to fill in with the certificate.
