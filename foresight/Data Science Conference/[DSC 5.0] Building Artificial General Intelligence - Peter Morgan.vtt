WEBVTT

00:00.000 --> 00:14.560
So, hi everybody, as a guy gentleman just said, I'm the CEO of a consulting company

00:14.560 --> 00:19.520
in London called Deep Learning Partnership and I'm going to talk to you today about

00:19.520 --> 00:24.880
something I don't really do on my day-to-day job, it doesn't pay my rent, but it affords

00:24.880 --> 00:34.800
me nice trips to exotic places. So, who here has heard of artificial general intelligence?

00:35.840 --> 00:43.520
Yeah, so quite a few. And so, what we label today is AI, isn't really AI, it's matrix

00:43.520 --> 00:48.240
multiplication. So, I'm going to talk to you today about how we might actually get to AGI

00:49.120 --> 00:54.320
and it's more of a neuroscience based approach. It's how the brain works, it's how biology does it.

00:55.040 --> 00:59.840
So, it's okay, everything that we've heard the speakers talk about so far,

01:01.760 --> 01:06.160
which has been labeled AI, it's really deep learning or artificial neural networks

01:06.160 --> 01:11.520
and the early creators of that said this is nothing to do with how the brain works, right?

01:11.520 --> 01:17.600
It's just it kind of works to classify cats and dogs and that's about it. We do a lot more than

01:17.600 --> 01:23.920
that. So, how do we get there? Is it even possible to build an artificial brain basically

01:23.920 --> 01:29.840
how biology does it? And I'm here to tell you, yes it is, I'll just give it away,

01:30.480 --> 01:36.320
you can go now, but if you're interested, I'll walk you through how that might look and how that

01:36.320 --> 01:42.720
might be done. Okay, so here's a little book I wrote for Riley, it's a booklet. There's my

01:42.720 --> 01:48.160
company website, there's my Twitter handle, you can follow me, I tweet a little bit about AGI and

01:48.240 --> 01:54.320
sometimes quantum computing, my other hobby or interest. So, this is what we're going to

01:54.320 --> 02:00.560
outline just briefly. We're going to look at physical systems, how biology does intelligence,

02:00.560 --> 02:07.280
and where we are with the non-biological, I've kind of just explained that in a broad sense,

02:07.280 --> 02:14.880
but we'll look at some of the, well, we'll go through the slides, deep learning recap and then

02:14.880 --> 02:21.520
we'll look at how we might build AGI and some of the theories and in particular one called

02:21.520 --> 02:29.760
active inference that I find particularly compelling to how the brain might work. Okay, so at that

02:29.760 --> 02:34.560
point it's sort of theoretical neuroscience, so I hope I don't lose you. I try to keep this kind of

02:34.560 --> 02:39.760
high level and not too much code or anything, although there is code and math for this stuff.

02:40.400 --> 02:48.080
And then we'll wrap it up by saying is it possible, how long might it take? Okay, so why do we even

02:48.080 --> 02:56.640
want to build AGI? Why don't we just stop here with the cats and dogs and TensorFlow? Well,

02:56.640 --> 03:01.680
if we do, like DeepMind says, if we can solve intelligence and we can use it to solve everything

03:01.680 --> 03:07.040
else. I mean, we're quite good at stuff, we've got here today, we've had Einstein's theory of

03:07.040 --> 03:14.160
relativity, we've had quantum physics, we've had classical physics, Newton, all the big names,

03:14.160 --> 03:20.880
why do we need any help? Well, clearly if we do manage to figure this out and build an artificially

03:20.880 --> 03:28.160
general intelligent system, then we can accelerate progress, which is probably, we can all agree,

03:28.160 --> 03:34.400
is a good thing. Although some people like Elon must say that, let's not build it because it will

03:34.400 --> 03:44.560
straight away kill us all, right? Well, we don't know, but I don't think it will. Okay, so I'm

03:44.560 --> 03:50.800
the anti-Elon Musk, okay? I'm the opposite. Okay, so I'm an optimist, he's a pessimist.

03:51.440 --> 03:57.040
So he's a good entrepreneur anyway. So what about all of these things here? AlphaGo,

03:58.000 --> 04:05.680
this is DeepMind in London, I'm sure we all saw on TV, AlphaGo beating the best go player in the

04:05.680 --> 04:16.720
world, was that AI, was that AGI? AlphaStar, it's a new project to beat the world's best video game

04:16.720 --> 04:21.920
players, a little bit more general one might argue than just playing a board game. DeepBlue,

04:21.920 --> 04:27.680
IBM's DeepBlue and Chess, Landmark, and IBM Watson, that's actually natural language processing,

04:27.680 --> 04:32.800
so that's quite clever, that's quite getting a little closer to AGI maybe, because it's having

04:32.800 --> 04:38.160
to understand language, but was it just doing it statistically? Was it just a massive computer

04:39.120 --> 04:45.680
hardware system that could crunch numbers really well and just do everything statistically? Is

04:45.760 --> 04:53.200
it how we learn language and understand language? I would argue no. So actually, all of those are

04:53.200 --> 04:59.920
just narrow AI, they're just statistical mathematical analysis of big data sets, okay? So it's not really

04:59.920 --> 05:07.120
how the brain does anything. If it were, I mean we do all of that in that little three pound thing

05:07.120 --> 05:12.880
above our sitting, above our shoulders, right? We don't need huge data centers, so clearly biology

05:12.880 --> 05:18.480
is doing it in a slightly different way, okay? So how is it doing it and how is it different?

05:19.200 --> 05:23.600
So first of all, to build something, we have to understand what we're building. What is

05:23.600 --> 05:28.960
intelligence, general intelligence? Well, it's all these things, right? So we don't just classify

05:28.960 --> 05:35.840
things, we do all of that. I won't read them out, because I've only got 30 minutes and sometimes

05:35.840 --> 05:40.640
I give this talk, it's an hour, but there's basically nine types of intelligence there,

05:41.360 --> 05:46.480
maybe even 10. And this guy at Harvard, Howard Gardner, just mapped it all out. See,

05:47.040 --> 05:56.320
existential thinking language, we can do math using ANNs, but the rest of it is pretty much

05:56.320 --> 06:03.360
music, creating art, spatial navigation, that's all. We can do all of that in three pound. We

06:03.360 --> 06:09.200
don't need a huge data center, hardware cluster of GPUs. So what's different? What are we missing?

06:09.280 --> 06:14.400
Okay. Well, first of all, how far have we come? Like I said, the mathematical part,

06:14.400 --> 06:18.240
we're like 50%, we're pretty good, we're not bad, we're about halfway there, linguistic,

06:18.240 --> 06:25.120
but it's only statistical analysis. Spatial navigation, self-driving cars, robots who can

06:25.120 --> 06:32.480
navigate through systems. I'd say we're about something called SLAM. I'd say we're about 50%

06:32.480 --> 06:41.440
there, that's the algorithm, simultaneous mapping and I forgot what the LAM stands for,

06:41.440 --> 06:51.040
but don't worry. We're about 50% there. You've probably seen simultaneous localization and mapping.

06:51.040 --> 06:56.560
You've probably seen the Atlas, you know, robot that do flips and run around outside and do good

06:56.640 --> 07:04.880
stuff, busts and dynamics. So that's why I'm giving it a generous 50%. We do a lot more than that.

07:04.880 --> 07:10.960
We can do gymnastics, we can run around, we learn stuff very quickly, we don't need millions of

07:10.960 --> 07:16.400
datasets to train, but as we go through that list of nine types of intelligence, it gets really,

07:16.400 --> 07:24.560
it just gets worse, right? Robots understanding each other or even algorithms running on a

07:24.560 --> 07:30.160
computer virtual sort of intelligence. Intrapersonal understanding themselves and existential,

07:30.960 --> 07:36.560
you know, show me an algorithm or a robot that kind of questions why it's there,

07:36.560 --> 07:42.000
or even understands that it exists, it's kind of zero. So we haven't figured that intelligence

07:42.000 --> 07:50.720
out at all. So the brain is pretty special, right? Biology is kind of special. We could argue chimpanzees,

07:50.720 --> 07:56.720
self-aware, well, yes, right, a dog, cats, probably. And as you go, you know, snails,

07:56.720 --> 08:03.440
maybe not, you know, bacteria, no. So there's clearly a continuum in what makes us a little

08:03.440 --> 08:08.800
different is our neocortex, that sort of outer layer of the brain. So we kind of have to figure

08:08.800 --> 08:13.200
out how that works, basically. But we've got all this other stuff in the brain like the amygdala

08:13.200 --> 08:18.400
for emotional intelligence, you know, the reptilian brain and there's sort of layers, you can trace it.

08:18.400 --> 08:23.200
In fact, you know, as babies are born and embryos develop over the nine months,

08:24.640 --> 08:28.880
you can see, you know, evolution, it starts off, you know, with the, you know,

08:28.880 --> 08:36.720
reptilian brain and it goes out monkey and then, you know, humans as we develop in the womb. So,

08:36.720 --> 08:42.160
you know, it's all, all of that evolution is still captured, all that information is actually

08:42.160 --> 08:48.960
captured by biology. It's just that last layer of the neocortex that makes us be able to come up

08:48.960 --> 08:55.280
with, you know, science, special theory, relativity, whatever, you know, that, that. So what are we

08:55.280 --> 09:02.960
missing? Why can't we do that yet in TensorFlow? Okay, why can't Google or DeepMind do that yet?

09:02.960 --> 09:08.320
So how will we get there? Well, it takes a village to create a child and I'm going to argue it takes,

09:08.320 --> 09:11.920
it's going to take a big community to create AGI. We're going to need computer scientists,

09:12.800 --> 09:16.560
physicists to understand the physics of the brain, neuroscientists, clearly,

09:17.600 --> 09:22.800
and also psychologists. So what I'm seeing really at the moment where these teams trying to build

09:23.440 --> 09:27.840
AGI or AI are just computer scientists, you know, just computer scientists, you know,

09:27.840 --> 09:32.560
you're clever people, they have PhDs and computer science, which involves a lot of math and

09:32.560 --> 09:38.000
understanding hardware and algorithm, algorithmic complexity. But it's not really

09:38.000 --> 09:44.240
understanding how much about biology at all. Okay, so we're going to need a whole bunch of people.

09:44.800 --> 09:49.920
And so I'll speed up a little bit now. I've kind of laid the foundations for what we might need.

09:50.720 --> 09:56.960
So this is basically what we've got in hardware. So this is how biology does it in hardware. So,

09:56.960 --> 10:03.520
you know, like I mentioned, we have a continuum from bacteria. That's a simple, C elegance is the

10:03.520 --> 10:09.760
simplest biological system with a central nervous system, it has, I think, about 300 neurons, then

10:09.760 --> 10:14.880
the bumblebee, the humble bumblebee with about a million, a few million neurons, and then us with

10:14.880 --> 10:23.200
about 80 billion or 100 billion neurons. Okay, so what, you know, what basically, maybe if we

10:23.200 --> 10:28.160
start at the simple, the C elegance and then build a bumblebee, then maybe one day, you know, we'll

10:28.160 --> 10:35.120
get to us. That's one sort of thought. The other, the other observation really is that nature is

10:35.120 --> 10:41.280
very hierarchical. You know, we built neurons, built of, they're not magic, you know, the built

10:41.280 --> 10:47.280
of atoms, molecules. And then if we just go up the different layers, we have synapses, neurons,

10:47.280 --> 10:53.600
and collection of neurons as connectome. So these 80 billion neurons are organized into some kind of

10:53.680 --> 11:00.000
structure. Maybe, you know, we should start there. So the question here is, you know, what level do

11:00.000 --> 11:05.760
we start at? Do we have to start at molecules or can we start at neurons or should we start a little

11:05.760 --> 11:12.080
more holistically at the connectome? You know, and on and on up until the central nervous system,

11:12.080 --> 11:18.400
us, which is about a meter in dimensions. So we're going from 10 to the minus 10 up to a meter.

11:18.400 --> 11:22.960
So it's a hard problem. It's kind of no wonder we haven't solved it yet. There's a lot of physics

11:22.960 --> 11:30.640
in there. And so that's what it looks like. This is how nature has done it. It's complicated,

11:30.640 --> 11:36.480
isn't it? You know, I mean, do we need all that little tiny microstructure? Probably not, I might

11:36.480 --> 11:43.840
argue. So you know, this is how, you know, what do we for in a half billion years of evolution

11:43.840 --> 11:50.880
on the earth, maybe a billion since the first sort of organisms, bacteria, whatever, the first,

11:50.880 --> 11:56.400
you know, primitive life. So over that billion year, this is what this is what nature's ended

11:56.400 --> 12:02.480
up with, right? This is what makes us intelligent, these things, right? You couldn't guess that.

12:02.480 --> 12:07.520
You start with a blank piece of paper, but this is just the universe we live in, the laws of physics.

12:07.520 --> 12:13.040
This is this is how we work. Okay. So there's no magic, but there's certainly a lot of

12:13.040 --> 12:19.440
complication. It's a complicated looking thing. That's a neuron. Okay. And so the next level of

12:19.440 --> 12:24.000
the hierarchy, we see that these neurons are kind of organized into some kind of structure

12:24.000 --> 12:31.120
called cortical columns, which each have about two, two million neurons. So maybe this is a

12:31.120 --> 12:36.160
good level to start. Maybe we don't have to go right down to all that complicated structure,

12:36.160 --> 12:40.960
maybe here. So that's kind of an interesting thing that we know. And then up onto the connectome,

12:41.600 --> 12:45.840
and then the central nervous system. If we want to build a robot, we need that those flips,

12:45.840 --> 12:50.240
we'll probably need all of that connected to the brain at the top. Okay. So

12:50.880 --> 12:56.400
and then we have societies where we're organized into societies. Bees are, you know,

12:56.400 --> 13:02.480
in their swarms and humans in their villages, towns, cities, countries, and then the global

13:02.480 --> 13:08.080
national community. So there's all these layers of hierarchy, which are intelligent, right? So,

13:08.080 --> 13:13.760
you know, we have this kind of macro meta intelligence built into communities and systems

13:13.760 --> 13:18.640
of communities, which has enabled us to, you know, survive reproduced into the next generation.

13:20.080 --> 13:25.200
So, okay. So that's biology. That's how it works. That's how it does it. That's what we know,

13:25.200 --> 13:28.000
plus a whole lot of other details, which I haven't really covered.

13:30.160 --> 13:37.040
So what have we done? How far are we along the line with hardware? So basically, the talks

13:37.040 --> 13:44.240
that we'll see here, you know, talking about CPUs, HGO, GPUs, that's what they use, sparkling water

13:44.240 --> 13:51.600
all runs on these things. There's a new sort of endeavor to build ASICs, which are specialized

13:51.600 --> 13:57.680
for deep learning. But again, it's just narrow AIS, it's matrix multiplication. But is it grok

13:57.680 --> 14:04.480
and cerebrus, graph core, Intel, Nirvana, they're all coming out with these amazing things that

14:04.480 --> 14:10.800
can do, you know, petaflops operations, which is more than the brain does. It's actually more

14:10.800 --> 14:16.000
than biology does. But all they're doing is multiplying matrices, right? They're incredible

14:16.000 --> 14:20.800
feats of micro engineering, incredible. These fabs cost, you know, billions of dollars to build.

14:21.600 --> 14:27.760
They've already, you know, graph core just raised $200 million. And they're impressive things,

14:27.760 --> 14:35.120
right? And that's what I look like that CPU GPU. There's a Google TPU, which is an ASIC,

14:35.120 --> 14:39.920
and runs in their data centers, you can hire them, run them in the cloud. And then there's the graph

14:39.920 --> 14:45.520
core IPU. And they all look the same, but you know, the micro architecture is a little different.

14:46.240 --> 14:51.920
So that, you know, this is all digital classical. If you do a computer science, you'd understand,

14:51.920 --> 14:57.360
you know, the details of how bits move around in there, how much energy it takes, how the memory

14:57.360 --> 15:05.680
in the processor, you know, interact together. But they're not intelligent, right? They're just

15:05.680 --> 15:12.800
very good mathematical processors. Okay, that's what a hundred petaflops looks like. And you can,

15:12.800 --> 15:18.160
you know, log in today to these things. The Google data center, this is the most powerful,

15:18.160 --> 15:22.720
you know, three exaflops, we're going to say that that's 1000 million, almost a million times more

15:22.720 --> 15:26.640
powerful than the brain. But it says dumb as a brick, it's the sun, it's incredibly impressive

15:26.720 --> 15:33.440
engineering, it takes up a football field, it's a data center size, but you can't do much except

15:33.440 --> 15:36.880
for model plane numbers together, it's not intelligent. Okay, so clearly we're heading

15:36.880 --> 15:42.880
into a dead end, if we just follow that computer science classical digital hardware route.

15:43.680 --> 15:48.480
See the brain does all of that and all the other types of intelligence in that little three pound

15:49.040 --> 15:55.600
mass. So clearly, it's not just about speed of compute, right? It's not just about horsepower.

15:55.600 --> 16:03.440
So what is it about? Okay, so recently, some of you, who's heard of neuromorphic computing?

16:03.440 --> 16:09.520
Who's heard of that? Yeah, maybe a few, right? A couple. So there's a project called Spinnaker

16:09.520 --> 16:17.920
in the UK. There's, there's IBM True North, Intel, the OHE. There's, you know, a few different

16:17.920 --> 16:27.040
projects that are trying to do mimic how biology in hardware, you know, does, does computation.

16:27.040 --> 16:35.200
Okay, it's called neuromorphic computing. So it's based on the brain. And so there's Steve Furber,

16:35.200 --> 16:43.600
he's one of the guys who come up, invented, founded the ARM computer processor company.

16:43.600 --> 16:51.760
And so he, 20 years ago, left ARM and started on this neuromorphic journey. He's based at

16:51.760 --> 16:59.120
University of Manchester. And recently, the human brain project has folded. It's called Spinnaker

16:59.120 --> 17:05.440
into itself because it's biopausable hardware. So they have lots of nice funding now, again,

17:05.440 --> 17:10.960
as IBM True North and Intel. I mean, these companies have a lot of money too. So that's

17:10.960 --> 17:18.000
what it looks like. So there's five racks there. That is about as powerful as the brain of a mouse.

17:18.960 --> 17:24.320
So it's not human level yet, but it can do things that can go through a maze, it can solve Sudoku

17:24.320 --> 17:28.240
and stuff like that, just like we do. So it's kind of getting there. And I would argue, you know,

17:28.240 --> 17:35.760
to build intelligence, rather than just simulating it on classical digital hardware, this is a more

17:35.760 --> 17:41.920
intelligent route to take. Okay. So, and there's a little bit of detail. So this is an important,

17:41.920 --> 17:48.560
you know, technology and a new path that not many have heard of here, you know, which is very

17:48.560 --> 17:53.680
interesting. It's probably like we were in the 50s with digital computing. You know, there's just a

17:53.680 --> 17:59.440
few main frames in the world right now, a few of these devices, but they actually exist. And you

17:59.440 --> 18:03.840
can actually log into Spinnaker. It's part of the human brain project. You can create an account,

18:03.840 --> 18:09.760
log in and watch it do stuff in real time. So they're not these magical, mystical things in a

18:09.760 --> 18:19.440
lab. They're kind of getting in real. And let's see. So that's okay. That's another initiative

18:19.440 --> 18:23.920
from Heidelberg, the brain scales project, which is also part of the human brain project.

18:23.920 --> 18:30.080
So the one on the left, I would argue, will get us to general intelligence. The one on the right,

18:30.080 --> 18:35.040
no matter how impressive that looks, won't. Okay. So, and then there's quantum computing,

18:35.040 --> 18:40.000
how about it? Is the brain quantum? No, it's warm, it's squidgy, nothing to do with quantum

18:40.720 --> 18:48.720
at all. Okay. Although birds navigate and plants photosynthesize using quantum processes,

18:48.720 --> 18:55.200
but it's not really generally how we do it. Okay. But the pictures look really nice. I decided

18:55.200 --> 18:59.760
to include a couple and it is what a quantum circuit looks like. I also quite like quantum

18:59.760 --> 19:05.200
computing because I have a physical background, but it's probably we don't need to worry about that

19:05.920 --> 19:11.040
if we're building AGI. It might help some of the computations initially, but ultimately we're not

19:11.040 --> 19:17.280
a quantum computer up here. It's a neuromorphic computer. Okay. So that's the sort of four different

19:17.280 --> 19:22.320
types of hardware. And I'd argue the one on the top right, neuromorphic will get us there. And

19:22.320 --> 19:26.960
that's how they look in a little bit more detail. And so, you know, it's not magic. It's just really

19:26.960 --> 19:31.840
hard engineering, which is why we haven't built it yet. It's just hard. Okay. It's small. It's,

19:31.840 --> 19:36.960
you know, and to understand it's difficult. Do we have a mathematical theory of the brain? Well,

19:36.960 --> 19:43.680
I would argue sort of before I go there. So the data center of the future right now is just full

19:43.680 --> 19:51.280
of those very clever chips we saw the graph core, the, you know, TPU GPU CPUs, very, you know,

19:51.360 --> 19:56.000
amazing engineering, but soon we'll see them being filled up with neuromorphic and quantum as well.

19:56.000 --> 20:02.800
So Google announced quantum supremacy last week, a couple of weeks ago, which means that a quantum

20:02.800 --> 20:08.640
computer, it can do something faster than the biggest classical computer. So the data center

20:08.640 --> 20:13.760
of future will look like this. Okay. So we're interesting. We're entering a very interesting

20:13.760 --> 20:18.480
time in human history, I think, in terms of computation, because we haven't just got classical

20:18.480 --> 20:23.520
computing, we have neuromorphic and quantum as well coming online. It's been 80 years, right,

20:23.520 --> 20:29.280
since we first started doing a computation. So at a very interesting time, I think in

20:29.280 --> 20:34.240
the history of computation with these other two major types of computation coming online.

20:35.520 --> 20:40.640
So deep learning, I've argued that won't get us anywhere near intelligence. It will classify

20:40.640 --> 20:44.880
stuff really well and do a little bit of statistical language processing, but it doesn't

20:44.880 --> 20:51.280
do the nine types of intelligence. Okay. And so the most popular framework by far as TensorFlow,

20:51.280 --> 21:00.160
PyTorch is kind of also increasing in the last little while, but you know,

21:01.520 --> 21:06.960
general intelligence, how biology does it, it doesn't do matrix multiplication. So deep learning

21:06.960 --> 21:14.320
is not AGI. So we won't talk about that, but we will talk about more neuroscience stuff. Okay.

21:14.960 --> 21:20.160
Sorry to be so harsh, but you know, it's reality. All that clever stuff isn't actually AGI, but

21:20.160 --> 21:27.600
it's good at certain things. Okay. So what do we do? I mean, where do we even start, right,

21:28.480 --> 21:32.560
with the general theory of intelligence? Well, you know, the brain is a physical system, right?

21:32.560 --> 21:38.400
It's just three pounds of physics, just, okay. So what do we know about physics? Well, we've

21:38.400 --> 21:43.920
pretty much discovered all of the laws of physics. I think dark matter is kind of a new one. It's a

21:43.920 --> 21:50.080
bit of a bold statement. I'm a physicist. I'm allowed to say that. So what are, I mean, what

21:50.080 --> 21:57.360
out of there do we use? Okay. You know, probably thermodynamics and electromagnetism in a complex

21:57.360 --> 22:02.480
system, right? So it's nothing magic. Now the underlying theory of all of this, all of that

22:03.120 --> 22:07.120
can be described in something called the principle of least action, which is that, and it's just

22:07.120 --> 22:12.640
been a book published last year. Surprisingly, it wasn't one before that sort of says, okay,

22:12.640 --> 22:18.240
all of physics, that's, you know, classical quantum, everything can be, you know, derived

22:18.240 --> 22:25.360
starting with this principle of least action. Now, if anyone's who's got a PhD in physics here,

22:25.360 --> 22:31.520
yeah, a few people. And so we've all, this is what you get at grad school in physics, right? We do

22:31.520 --> 22:35.360
Lagrangians and Hamiltonians and principles of least action. So everything we learn,

22:35.360 --> 22:40.240
if equals ma and undergrad, we're told, yeah, that's very nice and quaint. But really, this is

22:40.240 --> 22:45.440
the powerful machinery that's been developed. But we don't, you know, that we sort of, we get,

22:45.440 --> 22:50.960
we get there, but I think we're not really taught that, you know, it's very unifying principle.

22:52.080 --> 22:57.120
Okay, so I'm saying, okay, probably that's a nice place to start if we want to try to come

22:57.120 --> 23:01.840
up with a general theory of intelligence. Okay, it's a big statement and bold statement, but,

23:02.400 --> 23:07.040
you know, the brain is not doing anything that physical systems can't do, even though it feels

23:07.040 --> 23:12.160
kind of, it is different, right? Because we have consciousness and, you know, that subjective

23:12.160 --> 23:16.800
experience and self-awareness and that kind of stuff. But I'm going to argue it's all just physics.

23:17.600 --> 23:22.720
There are people in the room and elsewhere who will say, no, there's something beyond physics,

23:22.720 --> 23:27.680
metaphysics. I'm not one of those people. Okay, so I'm just going to keep it really simple.

23:28.400 --> 23:36.080
So, you know, what can we do? Well, we can explain and understand what we see. We can imagine things,

23:36.080 --> 23:41.200
you know, imagination, imagine that. Problem solving, planning actions to make these things

23:41.200 --> 23:46.320
real, we can do all of that. That's what intelligence is really. And we can build new models as we

23:46.320 --> 23:56.240
learn about the world. So, probably, okay, we've got five minutes. So, these are the sort of major,

23:56.240 --> 24:00.400
some of the major theories of general intelligence, mathematical theory. These are all smart people

24:01.360 --> 24:05.920
who have spent their whole lives dedicating to this. You can look them up later. There's

24:05.920 --> 24:11.600
a guy called Carl Friston at UCL in London. And so, his theory of active inference is the one

24:11.600 --> 24:17.040
that I think is particularly compelling. And I won't spend any time going through the details,

24:17.040 --> 24:20.960
because it's pretty hard math, actually, but he uses something called a free energy principle.

24:20.960 --> 24:26.000
It's based on physics and information theory. It's nothing kind of new and crazy. It's just

24:26.000 --> 24:30.880
applying it to the brain. And he is a theoretical neuroscientist. And so, here he is.

24:33.680 --> 24:38.560
And we don't have time to play it. So, the slides will be made available, I think,

24:38.560 --> 24:43.520
so you can listen to him. And he's on YouTube, if you want to Google. And so, that's how he

24:43.520 --> 24:48.800
sets it up. There's internal, there's us agents acting in an environment. That's the same if we're

24:48.800 --> 24:54.160
bacteria, monkeys, birds, human beings. It's a system, right? A physical system. We act in our

24:54.160 --> 24:59.600
environment. The environment acts back on us. So, there it is, bacteria to brains.

25:00.720 --> 25:05.280
And the math gets really ugly, because it is statistical, probabilistic, and physical all

25:05.280 --> 25:13.120
at the same time. It's complex information theory, essentially. But the ultimate question is,

25:13.840 --> 25:19.280
can we build general intelligence? So, I would argue yes, because we have theories. We have very

25:19.360 --> 25:23.040
compelling theories. All of those are, you know, hundreds and hundreds and hundreds,

25:23.040 --> 25:27.440
literally thousands of papers written deep mathematical theory, which keeps hundreds of

25:27.440 --> 25:32.960
graduate students in PhDs. So, yes, we have the theory. We have candidate theories. We have the

25:32.960 --> 25:38.560
algorithms and software. We have the hardware, neuromorphic in particular, and we have data

25:38.560 --> 25:45.040
sets nowadays. So, yes. And I think we're kind of on our way with these projects like Spinnaker and

25:45.040 --> 25:51.440
IBM True North. So, we're starting to build the hardware. It's just a sort of, it's always

25:51.440 --> 26:00.480
just an engineering problem, right? Yeah. So, you know, what else? So, should we? That's an

26:00.480 --> 26:05.120
ethics question. We won't go into that, because we could spend the rest of our lives arguing

26:05.120 --> 26:13.600
should we do it or not. We're going to do it anyway. So, there are some projects. DeepMind is

26:13.600 --> 26:19.280
trying to, although, you know, all the go and stuff isn't general. It's just specific. But

26:19.280 --> 26:25.200
there's a whole bunch of AGI projects and all super interesting things. I definitely encourage

26:25.200 --> 26:31.280
you to look and explore if you're interested in this subject at all on the internet. In conclusion,

26:32.160 --> 26:37.760
so, it's obvious that deep learning is just statistical. It's not based on physics at all.

26:37.760 --> 26:41.680
There's like zero physics in there. So, it's definitely not going to get us anywhere towards

26:41.680 --> 26:47.600
general intelligence. But research groups are, many are looking into biopausable models. That's

26:47.600 --> 26:53.440
both on the theoretical and the hardware side. We're sort of getting the glimpse of the very

26:53.440 --> 26:58.160
first systems. We have the rat brain there with Spinnaker. So, we're sort of at the very

26:58.800 --> 27:04.960
beginning of a steep exponential. So, maybe that will improve and in 10 years we'll have a human

27:04.960 --> 27:10.880
level brain, which will be conscious and self-aware and subjective experience, which is kind of

27:10.880 --> 27:15.840
spooky and creepy, right? There's nothing. I'm trying to argue there's nothing that mysterious

27:15.840 --> 27:22.000
about the brain. It's just a complex system. And so, what do we do then? Well, we'll figure it out

27:22.000 --> 27:30.080
as we go along, as we have done everything. And so, the future of AI, Jeff Hinton, he's the

27:30.080 --> 27:38.400
godfather of AI. He's in Canada and he, let him have the final word, except there's no volume.

27:38.400 --> 27:45.440
Okay. So, he's just basically saying that the brain is super, everything he's done in his whole

27:45.440 --> 27:53.040
life. He's just clearly admits he wasn't working on general intelligence and to do, to figure out

27:53.040 --> 27:56.480
how it works, we're going to have to look at neuroscience. That's pretty much his message.

27:56.480 --> 28:01.440
And it's pretty much my message. And so, I hope you've enjoyed my talk. It's been a little bit

28:01.440 --> 28:05.040
different from everyone else's, but thanks. Yeah. And we have questions, of course.

28:05.040 --> 28:18.480
Okay. One interesting question is, could AGI be achieved without emulating human brain but

28:18.480 --> 28:26.720
building a completely different model? No. That was a short one. You kind of answered this one,

28:26.720 --> 28:31.920
but maybe you can elaborate a little bit more. When do you think AGI will arrive? And I can

28:31.920 --> 28:37.600
follow with another one. As you said, you're at 50% of achieving AGI. What are the main

28:37.600 --> 28:42.480
challenges you are facing to get to 100% what technology breakthroughs are needed?

28:42.480 --> 28:48.880
Yeah. So, it's basically a hardware engineering problem. So, I did show the Spinnaker and there

28:48.880 --> 28:54.000
are the hardware projects around the world doing this, like IBM and Intel. And so,

28:54.000 --> 28:58.080
with that's the mouse brain right there. So, basically, it's a scaling problem now. I mean,

28:58.080 --> 29:05.360
we started at one transistor at one point with classical computing and then companies like Intel

29:05.360 --> 29:11.760
were formed and AMD and NVIDIA and the rest is history, right? It'll go on its own Moore's law.

29:11.760 --> 29:16.640
So, right now, we're at the kind of like 10 transistor stage that we were with classical. So,

29:16.640 --> 29:22.880
we'll just see that scale. I'm going to say something really bold. It's just a scaling

29:22.880 --> 29:27.040
problem at this point in time. So, watch this space. So, what will you say?

29:29.360 --> 29:36.720
Well, it'll go mouse and then it will go Bumblebee and then mouse and then monkey and then human.

29:36.720 --> 29:41.760
So, we're on a curve. So, human in 10 years, that's my prediction.

29:41.760 --> 29:47.120
They're too optimistic. I mean, in 1969, when people flew to moon, they thought that they

29:47.360 --> 29:52.560
would be living on the moon by now. Okay. I'm an optimist. I'm saying 10. Yeah.

29:53.680 --> 29:58.640
Okay. But I appreciate that. The last one, a comment about the Soul Machines Baby X project

29:58.640 --> 30:04.480
and the potential to get closer to general AI. What's that? Say that again? Yeah. I haven't heard

30:04.480 --> 30:10.560
about the Soul Machines Baby X project. Oh, yeah. I have. Yeah. Okay. Well, certainly. What was the

30:10.560 --> 30:17.760
question? The Baby X? I mean, your comment about it and the potential to get closer to general AI.

30:17.760 --> 30:23.200
Yeah. I didn't actually mention Baby X, but that's a nice project in New Zealand. And it's another

30:24.080 --> 30:30.240
AGI project. But basically, it's going to come back to neuroscience. You know, we saw the mass,

30:30.240 --> 30:36.240
we saw some of the mathematics involved. It's going to be people working at that level from a

30:36.240 --> 30:40.560
theoretical point of view. And other people like Steve Furber and the Human Brain Project,

30:41.280 --> 30:45.840
you know, brilliant engineers basically working on the hardware level, and these people talking

30:45.840 --> 30:51.520
to each other. And I know Carl Friston and Steve Furber do talk to each other and building this

30:51.520 --> 30:56.560
very complex system. Okay, Peter, thank you. Thank you. I will present you with a certificate.

30:56.560 --> 31:04.560
Thank you, Peter. Thank you, sir. Thank you, sir. Thank you, sir.

31:04.560 --> 31:08.560
Thank you. We, we got to, we got to fill in with the certificate.

