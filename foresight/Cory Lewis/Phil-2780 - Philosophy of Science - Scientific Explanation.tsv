start	end	text
0	8160	Okay, so welcome back. Right, so we've kind of finished a broad arc in this
8160	12800	course that I was kind of setting up from the beginning and finished with our
12800	18960	discussion of social construction, broadly trying to motivate the idea that
18960	24400	there's both values influence on science, especially in the sense of deciding
24400	29560	which questions we ask and how we ask them, but that nonetheless science can
29560	34920	come up with reliable and in some sense objective knowledge in the sense that
34920	39160	it's at least intersubjectively reliable. So that was kind of the point of that
39160	45400	the course so far. We're going to shift gears a little bit now, so the rest of
45400	50520	the course is basically just taking a look at a couple of various issues in
50520	55240	philosophy of science. Today we're going to shift to doing more philosophy-ish
55320	59960	philosophy, so less. We've been doing a kind of integrated history and philosophy
59960	64680	of science largely for the course, so lots of interest in actual scientific
64680	68600	practice and that sort of thing. Now at least today we're going to start talking
68600	72760	about kind of more pure philosophy of science, so we're going to take a step
72760	77080	back historically, start talking about stuff that happened in the 40s in
77080	81960	philosophy of science and move on to more modern stuff. Specifically we're going
81960	85640	to start talking about explanation. One of my favorite topics in philosophy of
85640	92840	science is something I dealt with a lot in my PhD thesis. So if we think about
92840	100040	what we want out of science, so consider what we're after. We want to be
100040	103560	able to predict things, of course. You want to be able to know what's going to
103560	109560	happen next, but you also want some capacity. I would insist that
109560	112520	these are two different things. You also want to be able to explain things.
113240	116520	So if you think about how long it's been the case that we were able to predict
116520	121000	that the sun was going to rise tomorrow, I mean we've been able to predict that
121000	125640	for ever. I mean as long as we've been able to predict things, we've been able
125640	130120	to predict that the sun would rise tomorrow. But when would you say that
130120	132440	we have a correct explanation for that fact?
140040	147560	When you can explain why we didn't have a...
147560	153160	So when did we learn how to explain that the sun's rising tomorrow?
153160	163400	Like where we infer, because if the sun has come up every time, every 24 hours.
163400	168360	Yeah, but that's the prediction part. So this is, I mean there's the prediction
168360	171560	that it's going to come up tomorrow, which we've been very reliably right about
171560	175880	for a very, very long time. Probably before language, we had this figure there.
182680	187800	Yeah, yeah, that's where I would roughly put it. There might be some gray areas there where like
187800	192200	Copernicus had a, you know, here's why the sun rises, it's because the earth is spinning
192200	195240	round and round. I take it that that's the correct explanation, roughly.
195960	202680	So we didn't have that until 500 years ago, something like that. So there's this vast
202680	206840	difference between being able to, historically at least, being able to predict that the sun's
206840	213000	going to rise and actually understanding why it rises. Like we had previous explanations,
213000	220680	one of which was that the sun is spinning round and round us, or that the chariots of the gods
220680	225800	are dragging it across the heavens. That was a previous explanation. I take those are attempts
225800	232120	at explanation, but we might want to require that our explanations be true. Like an explanation in
232120	237960	some sense is a, it's a success term, right? You say you've explained something when your
237960	246040	explanation is both good and true, rather than just trying to explain. Yeah. So let's distinguish
246040	250280	prediction from explanation. Explanation might say you have explanations when you
251000	257960	understand something in some deep way. So there's a, typically there's a connection made between
257960	265160	explanation and understanding. And philosophers have spent a whole bunch of time and energy trying
265160	271000	to understand specifically scientific explanations, that there might be something different about
271000	277560	scientific explanations than other kinds of explanations, not just sort of pseudoscientific
277560	284040	explanations, but the style of explanation that scientists are interested in seems to be different
284040	290040	than other types of explanation. So let me give you a contrast for scientific explanation,
290040	297480	which is something like historical explanation. Okay, now I don't want to insist that historical
297480	303000	explanation has to have this character, but I'll tell you as a matter of fact, the kind of explanation
303000	307720	that professional academic historians have been interested in, since like the 70s or 80s or
307720	316280	something like that, has been less focused on grand overarching theories of history. Something
316280	322120	happened in the 70s where historians noticed that their explanations had a specific character,
322120	328920	they call it wig history, where, you know, they developed these grand historical stories that
330040	338040	basically had the narrative structure of Europe saves the universe, that the grand march of
338040	343320	history was all heading towards the modern European nation state, and that that's where it was all
343320	348840	leading the whole time. They noticed that their stories had this character and got really uncomfortable
348840	355480	with that fact, probably rightly so. A, because it was politically bad, and B, because it was
355480	361000	simply distorting how things happen, like that's not how history works, it doesn't head specifically
361000	366520	towards some outcome, it's things happen and there's a bunch of reasons why they happen. So
367640	373720	they got really nervous about these grand historical narratives and started telling historical stories
373720	381480	that were very specific in their time and place. So a historian now will focus on like medical history
381480	388440	in Italy in 1450 to 1470 in this specific social class or something like that, right? They'll get
388440	394760	these really, really specific things that they want to explain and the style of explanation that
394760	400040	historians tend to use, again this is not a fact of nature, this is just the historians that I hang
400120	407800	it with. They want to understand things not by trying to fit them into kinds and categories of
407800	415160	events. What they want to do is understand all of the detailed specifics of that moment in time
415160	422840	and space. They understand the event more deeply by layering in more and more context so that you
422840	430440	can see what's absolutely unique about that thing that they're trying to understand. So this is a
430440	436520	way of explaining and understanding the world. It's a kind of contextual specific focused and
436520	442760	detailed way of understanding and the explanations they give are kind of long detailed stories about
442760	449880	that time and place. And I want to suggest that this contrasts with the way that scientists are
449880	456840	typically interested in explaining and understanding things. So in scientific explanation the tendency
456840	462920	is to be focused more on understanding the similarities between different things than
462920	469480	understanding one thing in its kind of complex context. So every single snowflake is of course unique
470280	476760	but that's the uniqueness of the snowflake is not what somebody who's doing a scientific study on
476760	482760	it wants to understand. They want to understand the general regularities of all snowflakes. What
482760	488200	are the rules of construction that snowflakes follow? What are the general principles that
488200	494120	describe their geometry? These are the kind of things that scientists try to understand. So their
494120	500120	explanations are not pitched at the level of why does this specific snowflake have this specific
500120	506040	structure? It's an extreme example but I think it kind of carries over. Scientific explanations
506040	512840	typically more interested in the general features of the world rather than zooming in and getting
512840	519320	the very detailed understanding of one specific thing. Does that contrast make some sense? Good.
519320	525080	So again these are not, I mean it's not a fact of, it's not a fact about nature that these different
525080	530360	disciplines have to have these different interests but there's certainly an actual fact about what
530360	535640	these groups are interested in today and that seems to be the distinction. So yeah.
536200	542680	Maybe it's the difference between memorizing all the code for a piece of software versus
543400	548040	knowing the principles of how to code. Something like that. Yeah. And knowing the
548040	554040	principles of how to code would be more valuable than just memorizing an individual piece of software.
554040	560040	What depends what you're interested in, right? Like I take it that these are two different ways
560040	565880	of processing the world actually. So there's different styles of understanding and each
565880	570520	style of understanding is more appropriate for some context than for others. So for example,
570520	577000	when you're dealing with human beings on a one-to-one basis, you probably don't want to go,
577000	580680	ah well here are the general categories that you fall under and I'm going to just
580680	584520	understand you in terms of those general categories. Most people, if you're dealing with
584520	589160	somebody on a one-to-one basis, prefer for you to be interested in the specifics and details of
589160	593880	their actual life, right? Like you don't want to just reduce somebody to a category, you want them
593880	599560	to meet you as a unique individual with unique properties that have to be understood in terms
599560	605800	of your life history and context. I don't know, that's how I prefer to be met and understood.
606360	612040	So depending on your project, depending on your interests, one or the other of those styles of
612040	616280	understanding might be more appropriate and we kind of mix and match them, right? So it's not the
616280	621560	case that all scientific explanation is purely general. I mean if you're doing paleontology,
621560	625960	you're interested in history, if you're doing some types of history, you're interested in
625960	631400	generalities, but this is a this is the broad trend and there are these two sort of semi-separate
631400	636600	but interacting ways of getting at the world. And today we're going to talk about just one of them,
636600	641800	we're really going to focus on the scientific style, the general style of explanation, okay?
643320	650680	Okay, so as I said, scientific explanation tends to be interested in classes and categories,
650680	655080	right? You want to find the kinds of things and understand the kind of thing that you're looking
655160	661320	at. A political scientist, for example, kind of science, might want to try to understand
661320	666840	revolutions in general, right? So political revolutions, say under what conditions do
666840	671800	revolutions arise? And to understand that and to answer that question, what you do is
672440	678200	try to find all the conditions that are similar across revolutions in history, right? And then
678200	683560	if you have that, maybe you'll be able to do things like predict future revolutions and
683560	689800	understand the causes and factors that lead to one coming about. Whereas a historian, somebody in
689800	695000	a more historical mode, doesn't want to understand, so they say they're looking at the French
695000	699160	Revolution, they don't want to understand the similarity between the French Revolution and
699160	705480	all the other revolutions. They want to understand that moment, what exactly was going on in France
705480	711400	at that time, you know, kind of very detailed way without really worrying too much about whether
711480	718200	it generalizes. So it's about the difference between understanding the class kind or category of thing
718200	725960	that you're interested in versus trying to understand this specific object. Okay, so
728040	735720	and the way that this has usually been formulated by philosophers of science is trying to understand
735720	742600	things in terms of the laws of nature. So for most of the 20th century, philosophers assumed
743320	749560	that scientific knowledge takes the form of laws of nature. And the assumption was that they'd be
749560	754520	universal laws of nature. We've had some debate about that since, but for our purposes, this is a
754520	762360	good place to start. So laws have the form, the following form, all members of the category X
762440	767560	have the property Y. That's a universal claim. It's a claim of all members of the category.
767560	773000	And it's attributing to all members of the category, some property. So all copper is
773000	779160	conductive. That's a classic, for philosophers, that's a classic law of nature, or all electrons
779160	785640	have negative charge, all massive objects attract each other gravitation. These are the kind of
785640	790840	laws that philosophers are interested in. You can see how they are categorical in the sense that they
790840	800760	try to understand the properties of a category. Just saying that it's got this form is probably
800760	807640	not sufficient. So just having universal form doesn't make something a law of nature. Philosophers
807640	815560	spend a lot of time trying to figure out what the extra secret sauce is. But here's the problem. So
815640	823320	compare the following three claims, and they all have that universal form. They all attribute to
823320	831000	all members of a category the property. So there are no spheres of uranium bigger than one kilometer
831000	836440	in diameter. And I'm pretty confident that that one's true. I've never been to most of the universe,
836440	842440	but if you put that much uranium all in one place, it explodes. Like it has a very strong
842440	851880	tendency to undergo a nuclear reaction. So you can't have a sphere of uranium bigger than one
851880	859240	kilometer. Okay. Probably there's also no spheres of gold bigger than one kilometer in diameter.
860040	868040	I don't know of any. But I can't say that with the same certainty. Because there's no law, I don't
868040	874760	think this one is a law of nature. Some bizarrely motivated alien species could go around and collect
874760	881240	just an unbelievable amount of gold and put it all into a sphere. It's not impossible in the same way.
889720	895080	I think there's no naturally occurring ones. Very probable. But again, there's a sort of
895080	900600	difference in character here where one's very unlikely and one is just not going to happen.
902360	908280	Like if you studied all the asteroids in the universe, you might find one that just has
908280	913400	a ridiculous amount of gold in it? It could. I mean, it's extremely unlikely.
914520	918840	But even if both of this, so let's for the for the minute, for the for now, let's assume that
918840	923320	both of these are actually true. I think it's not unreasonable to say that there's probably no spheres
923320	929880	of gold bigger than a kilometer. But one of them has to be true. One of them kind of happens to be
929880	937400	true. Consider this one, all the coins in Corey's pocket on March 9th are quarters. I should have
937400	940920	brought some quarters to make this true. This is I have no change in my pocket right now. But
940920	947080	suppose I've got a couple of quarters in my pocket, that sentence is true of the entire
947080	952680	class or category of things that it's describing. But that could definitely be some other way,
952680	956360	right? Like if I put a loony in my pocket, it wouldn't suddenly turn into a quarter.
957080	963880	So all of these have got the structure that I just described. So it's attributing so all
963880	971480	members of the category X have the property Y. If you put these in logical form, they actually
971480	976040	apply to every object in the universe because they say, if something is a coin in Corey's
976040	981320	pocket on March 9th, then it is a quarter. And that's true of literally every object of the
981320	986600	universe. You say that's the chair, it's not a coin in Corey's pocket. Therefore, it's true that
986600	992840	if it's a coin, then it's a quarter, that kind of thing. So these in the kind of logical form that
992840	1000120	philosophers like to phrase these things, these are all true of literally every object in the
1000120	1008120	universe. But only the top one, only this one about uranium seems to have the sometimes talk
1008120	1013640	about the modal force of a law of nature. Laws of nature are not supposed to be coincidentally
1013640	1019720	true generalizations. They're supposed to be things that have to be true. Not in a logical sense,
1019720	1025240	but in a physical, the physical properties of the universe preclude something from being
1025240	1029720	a uranium sphere bigger than a kilometer. Whereas there's nothing in the laws of nature,
1029720	1036120	as far as I can tell, that requires that there can't be a one kilometer sphere of gold,
1036200	1040840	or that I could have a coin in my pocket that's not a quarter. That one I'm very confident about.
1042200	1047000	So these laws are supposed to be universal generalizations, and they're supposed to have this
1047000	1053320	kind of sort of necessity. So this is the thing that philosophers, I won't spend too much time
1053320	1060680	troubling you about this, but trying to characterize what property this top one has that these other
1060760	1067480	two don't has been a bone of contention. Because if you're an empiricist, if you believe that
1067480	1072920	all of our knowledge comes through our senses, all you ever observe is something never happening.
1073880	1081880	Like, I never see any gold spheres bigger than a kilometer. That's a true observation,
1081880	1088280	and you don't see the necessity of this, of this uranium thing. Necessity is not something you
1088360	1094760	can observe. You just see that it never happens. So trying to describe what makes one of these
1094760	1100200	necessary, an actual law, and the other two not laws, is we've been working on it. There's some
1100200	1107800	debate. Okay, so there's laws of nature. The classic view of scientific explanation is that
1107800	1114920	your explanation should involve a law of nature, of this form. So I'd like to introduce you to the
1114920	1121960	deductive, nomological account of explanation. So Carl Hempel and Paul Oppenheim wrote this up in
1121960	1130600	the 40s, mid 40s, presented this as a trying to kind of very clearly say what counts as a scientific
1130600	1137640	explanation. And the basics, the basic idea is a scientific explanation deduces the thing that
1137640	1145800	you want explained from a law of nature and some initial conditions. So what an explanation does is
1145800	1151240	take a law of nature and some specific facts about the world and then deduces the thing you want
1151240	1156360	explained from that pair. That's what makes something a good scientific explanation.
1158760	1164520	Here's the general form of it. There's a condition or fact. There's a general law,
1164600	1170040	and then you just deduce that from that, from the conditional condition or in general law.
1170920	1175240	In the explanation literature, we separate the parts of an explanation into
1175800	1182680	explanands and explanandum. I won't make you memorize that, but this is if you want to refer to
1182680	1189320	the thing you want explained, that's the explanandum, and the thing doing the explaining is the explanands.
1190280	1193320	Okay, so here's an example very similar to the one
1194120	1200360	Hempel and Oppenheim give. So the explanandum is why did the pipes in my house burst? So you go
1200360	1208200	to your kitchen and you see water pouring out, and you say why, why? Well, here's a condition,
1208200	1212360	here's a fact of the world. The pipes are made of metal and they're filled with water and it's
1212360	1218680	freezing. So you're allowed to give yourself several facts, but like metal pipes, water in them,
1218680	1227720	freezing cold. And here's two general laws. When water freezes, it expands. When metal gets cold,
1227720	1233560	it contracts. And you can put those facts and those rules together to get that the pipes are
1233560	1239320	going to break. Hempel's one was like a radiator, but I don't know if I think it's more familiar
1239320	1245880	now than having a radiator filled with water. Okay, so this is what a scientific explanation is,
1245880	1250520	according to Hempel and Oppenheim. Here's the picture. Here's what it is to explain something
1250520	1256120	scientifically. You take some facts, you take some laws, and you use them to deduce the thing that
1256120	1263240	you're interested in. Yeah, pretty good, right? And then we figured it out and it was all over
1263240	1268520	and nobody talks about it again. Hey, like it always happens in philosophy. We just come straight
1268520	1274280	to the correct answer and then nobody talks about it anymore. Okay, not really. All right.
1274280	1280760	Okay, so that was their first pass at this, the deductive nomological account, deductive in
1280760	1287240	that you deduce things nomological in that it's law based. Of course, a lot of our scientific
1287240	1293240	knowledge is not universal in that way, right? The laws of nature that I just showed you are
1293240	1298920	kind of exceptions because most of our scientific knowledge takes the form of statistical facts.
1298920	1303640	We know something happens a lot of the time or most of the time or regularly, something like that.
1304680	1311960	So they developed a second model to kind of handle the second style of laws of nature,
1311960	1318520	the inductive statistical method. So instead of deducing the thing to explain what you get,
1318520	1324920	so in a deduction, if you haven't done sort of philosophy stuff, in deductions, you get the
1324920	1330360	conclusion with certainty. So if the premises are true, the conclusion is certain to be true.
1331000	1336280	In induction, what you say is, if the premises are true, then the conclusion is likely to be
1336280	1343320	true. So you get a high probability or something like that. So you suppose you've got a tank of
1343320	1350040	water and you drop an ink drop in it, and it spreads out. So why does that happen? Why does
1350040	1358600	the ink spread out? And you can give a really good statistical answer to this. So if you characterize
1358600	1365880	the number of possible states of the system, so all of the ways that the ink can be distributed,
1365880	1371320	there's just way, way more ways in which it's evenly distributed than if it's like clumped up
1371320	1377880	in one little spot. So if you say the system is randomly chugging through states, it's just going
1377880	1383960	to go to some random state, there's almost infinitely more states in which it's randomly and
1383960	1388600	evenly distributed than there are states in which it's clumped up in one corner or something. So
1388600	1394840	if you drop an ink drop in a thing of water and it all zooms to just one spot, that's super weird.
1394840	1402440	It's not impossible. Statistically speaking, that is a thing that it could do, but it's exceptionally
1402440	1407560	unlikely. This is by the way the same kind of explanation you'd give if you want to know why
1407560	1412920	is the air in this room roughly evenly distributed? Like why isn't it all pressed down against the
1413000	1419480	floor or against one wall? The answer is because there's just way, way, way more ways for it to
1419480	1426040	be roughly evenly distributed than there are for it to be pressed up against one wall. And the system
1426040	1433560	is just randomly going through states. If you sat in this room for a trillion, trillion, trillion
1433560	1439240	years, maybe for one second, it would be unevenly distributed. It would mostly be on this side as
1439320	1443480	it just kind of randomly goes through its states. But you can get that the air is not going to do
1443480	1449320	that with extremely high probability by doing this kind of statistical explanation. Okay,
1450200	1454920	so good. We've got the deductive account for things that are always true. We've got the
1454920	1460440	inductive account for things that are mostly or usually true. Yeah. So in that situation,
1461080	1468760	wouldn't the vacuum created destroy the room? Maybe. It could only be, it could happen for a
1468760	1476920	split second and not destroy the room. I don't know. It's extremely, I'm not super worried about
1476920	1482280	what would happen because it's so hilariously unlikely to happen. We could sit here for many
1482280	1490280	times the age of the universe and it would never happen. Yeah. If you're laying in bed waiting,
1490280	1493960	worried at night that the air might all suddenly rush to one side of your room,
1494680	1502680	it's you'll be fine. Don't worry. Okay. Okay. So let's do some problems with this. So this,
1502680	1507080	this was the kind of first pass at this stuff comes out in the 40s. People pretty quickly
1507080	1513800	noticed that there are some issues with both of these accounts. So I started by saying that
1513800	1517880	there's some big difference between explanation and prediction. Temple actually just goes ahead
1517880	1521560	and denies this. He says, no, no, no, that's basically the same thing. Because if you can
1521560	1526120	deduce that something's going to happen, then you've got a prediction that it's going to happen.
1526120	1530680	The only real difference between an explanation and a prediction for temple is that an explanation,
1530680	1535960	the thing has already happened. Whereas in a prediction is still in the future. That's it.
1535960	1544920	That's the only difference. But that produces some weird results for his view. For example,
1544920	1552280	the famous flagpole. So if I want to explanation, so we got a flagpole, we got the sun and the
1552280	1559720	flagpole is casting a shadow. So on Hempel's account, you can explain the length of the shadow
1559720	1565800	by citing the specific position of the sun, and then some universal laws about geometry.
1565800	1572120	You just your, your, you know, grade A geometry lets you predict how long that shadow is going to be.
1575160	1582920	But you can do this the other way as well. Suppose you ask, why is the sun where it is?
1583960	1590040	I want an explanation for the position of the sun in the sky. Well, I know the length of the shadow
1590040	1597560	and the height of the flagpole. And I know some geometry. And I can deduce where the sun is.
1597560	1606120	Now, it's perfectly fine to say you can predict where the sun is based on those facts. That's no
1606120	1612440	worry. But can you explain basis? So say, can you explain to me why the sun is right there? And you
1612440	1618760	say, well, there's a flagpole, it's this high, and there's a shadow, it's this long. Therefore,
1618760	1626520	that's why the sun is where it is. That's weird, right? That's not why the sun is where it is.
1626840	1634200	But on Hempel's account, that comes out as a good explanation, as good as the other way around.
1634200	1639080	Like, I'm real happy with like, why is the shadow that long? Like, well, the sun's there and had
1639080	1645320	flagpoles this high. Why is the sun there? You shouldn't know facts about the flagpole are helpful
1645320	1651480	for understanding why the sun is where it is, right? Predicting yes, explaining people like,
1651480	1657240	no, no, no, no, no, that's not that's not going to work. Okay, so the famous flagpole example,
1658360	1664520	people get pretty worried about that. They also get worried about things being cited that are
1664520	1670920	kind of irrelevant. So here's John Jones, John Jones does not have a uterus. But every day,
1670920	1676760	John Jones takes a birth control pill. And John Jones does not get pregnant.
1677720	1680920	Good for him. He's very careful. He's very cautious.
1682440	1687080	He's got no uterus, but he does take birth controls. John Jones fails to get pregnant.
1688360	1692840	Well, here's a good, here's a good deductive explanation for that.
1693720	1697800	Anybody who doesn't have a uterus and takes birth control pills will not get pregnant.
1698520	1702920	John Jones does not have a uterus. He takes birth control pills. Therefore, he does not get pregnant.
1703640	1705640	Yeah.
1715320	1723560	It's not recommended. Okay, it's not generally recommended. Yeah. But if you're going to ask,
1723560	1729480	why does John Jones not get pregnant, the birth control pills are really a super important
1729480	1734040	part of the story, right? I mean, maybe the problem is his boyfriend isn't for time.
1737080	1744840	Right. Thank you. Thank you for that. That's okay. So you can cite, so following
1744840	1750680	Hempel's model to the letter, you can cite stuff that's irrelevant. You can put it into the story,
1751240	1753960	and it still counts as part of the explanation.
1754600	1762280	Yeah. So you can cite irrelevancies. Another example that he uses, critics of Hempel use,
1762840	1767800	every morning I have a cup of coffee and I say a magical ritual over it, and then I drink the
1767800	1774680	coffee and it wakes me up. Therefore, saying a magical ritual over my coffee and drinking it
1774680	1781720	is responsible for explains why the coffee wakes me up. Like, yeah, no, it doesn't. You can deduce
1781720	1786120	it, right? So there's a very strong regularity. Every time you drink a cup of coffee that you
1786120	1790200	set a little magical ritual over, it does wake you up. So that's a universal regularity.
1791320	1796440	You can say a law of nature about it if you want. But that's not an explanation.
1797800	1806760	Okay. So diagnosing these problems, philosopher said, okay, here's what you messed up,
1806760	1815000	Hempel, here's what you left out. You can't just cite the universal laws to explain something.
1815000	1822040	You need to cite the causes of that thing, right? You have to cite the things that caused it to
1822040	1829160	happen. That's the problem with these examples, right? What you're citing are true universal
1829160	1836360	regularities, but you're not citing the causes of things. So yeah, you can explain the length of the
1836360	1840760	shadow by citing the position of the sun and the height because they caused the length of the
1840760	1848200	shadow. That's what caused the shadow to be where it is, the sun and the flagpole and geometry, I
1848200	1854920	guess. But the length of the shadow doesn't cause the sun to do anything, right? There's no, if you
1854920	1861240	somehow manipulate the length of the shadow, you're not manipulating the sun, right? So that's the
1861240	1866120	problem with that example. Say, look, you cited a universal regularity, but you didn't cite the
1866120	1871400	causes. You can explain stuff, you got to tell me what caused it. That's the critique.
1873400	1876280	And again, you can't explain why John Jones feels to get pregnant
1877960	1883640	because that's not what caused it. That's not the causal story about John Jones not getting pregnant.
1884360	1888520	If he hadn't taken the pills, he still wouldn't have gotten pregnant. So this is one of the tests
1888520	1893640	that you do for something being a cause. If it's there, then you get the effect. If you take it
1893640	1902520	away, then you shouldn't get the effect anymore, right? And similar problems appear for the
1903080	1909560	inductive statistical explanations. You get similar issues. So let me, I don't expect I can do this
1909560	1915640	better than the article. Right. So this is an old-timey example. I don't think
1916760	1921480	syphilis gets talked a lot about anymore, but here's the classic example.
1922280	1931160	Okay. Okay. Then this is topical. All right. All right. So the town mayor suffers from a
1931160	1935880	motor deficiency characterized by the limitation of certain movements and a loss in muscular strength,
1935880	1941000	which is called peresis. And we know roughly a quarter of patients with untreated latent syphilis
1941000	1946120	are victim to peresis. And we know that the mayor has precisely such latent syphilis,
1946120	1949720	the condition he was not aware of and was constantly not having, consequently not having
1949720	1955960	treated. Intuitively, what we have here is an explanation of the mayor's peresis, right? Why
1955960	1964280	did the mayor have this muscular condition? Because he had syphilis. However, the law linking
1964280	1970840	syphilis to peresis only brings the, and the fact that the mayor's got syphilis, only brings the
1970840	1978760	mayor's probability up to 25%. And the inductive statistical account doesn't tell us exactly what
1978760	1986760	counts as high probability, but 25% doesn't sound about, doesn't sound right. That doesn't sound
1986760	1992680	like a high probability. It's actually odds are lower than even that he's going to get this condition.
1993320	1998760	So inductive statistical account said, you explain something by showing how it was very likely.
1999480	2005240	I mean, the ink blot thing is the ink spreading in water is unimaginably likely. It's so close to
2006040	2012120	100% probable that there's kind of no difference. But this time it's like less than half. It's a quarter.
2013800	2022440	Nonetheless, seems like we can explain why he has peresis based on citing the fact that he's got
2022440	2026920	untreated syphilis. Yeah? Okay.
2033800	2040680	Would it depend on there being another way of explaining, like if there was another medical
2040680	2047720	condition that could? Well, in this scenario, so supposing this scenario, this is the cause of
2047720	2057240	his peresis. We know for a fact that syphilis caused his peresis. So if what we wanted of our
2057240	2065560	explanations is the causes, then this is fine as an explanation. And intuitively, most people say,
2065560	2071560	yeah, that's a good explanation. Why is this guy got peresis? Because he had untreated syphilis.
2072520	2076280	But on the inductive statistical account, this doesn't work as an explanation because you're
2076280	2087400	supposed to get out that it's got a high probability. So that's weird, right? It's worrisome for the
2087400	2094920	inductive statistical account. Yeah? Yeah, yeah.
2095560	2098440	They didn't do it that everyone got syphilis in the town.
2099320	2105800	Then you could say, I think it was 100% or it was very likely that 25% would have syphilis.
2105800	2109960	Good. Okay. So interesting. Now, what you've done is shift the
2109960	2116360	explanandum there. So you say, why is it the case that 25 people, so if there's 100 people in
2116360	2122280	town with syphilis, why is it the case that there's 25 people with peresis? Now you've got
2122280	2129080	this nice statistical explanation, 25% of cases develop into peresis, and you've got 100 cases,
2129080	2133400	therefore it's very likely that 25 people will have it. Yeah. So if you shift the thing you're
2133400	2140120	trying to explain to the population, then that works nicely. Yeah. But if we're just interested
2140120	2145080	in the mayor, then the inductive statistics, it seems like intuitively, it should still explain
2145080	2155480	why this one specific guy got peresis, and it doesn't seem to do that. Yeah. Good. Okay.
2156760	2164520	So all of the examples I've shown you so far are pretty neatly resolved by just looking at
2165400	2171000	the causes. Say, how do you explain something? Well, you cite the causes that brought it about.
2171800	2174600	Ta-da. Pretty good, right?
2178120	2184680	So, but that gets us into some weird and tricky issues. So,
2187880	2193000	like, what does it mean for one thing to cause another thing? It turns out there's a
2193560	2199000	humongous debate about this, especially in complex cases. Yeah.
2199320	2205000	One of the issues is that something always causes another thing to cause effects. So
2206120	2212920	you might know how snow is caused, temperature and stuff, but then you have to ask why. Like,
2212920	2217560	if there's another, once you know how snow is made, you ask why does water create this, and then
2219320	2225320	why does it just keep going? There is, there is, this is how people end up being philosophers.
2225320	2229080	They do this, like, why is, okay, say, why is it, why does snow create it? Oh, because
2229080	2232600	water freezes. Why does water freeze? Because chemical properties. Why does it have those
2232600	2235960	chemical properties? And then eventually you get to metaphysical questions and
2236840	2241720	A, people stop talking to you and B, you end up doing philosophy degree. So careful, careful
2241720	2248680	about that. Yeah. In order to make an apple pie from scratch, you must first recreate the universe.
2248680	2252360	Close Carl Sagan. Very good. That was my best Carl Sagan person.
2255480	2261400	Okay. But even absent this kind of regressive why questions, we've got serious and difficult
2261400	2266920	questions about assigning causes to things that were pretty sure happened. So what are, what would
2266920	2273560	you say are the causes of the weather today? I mean, you obvious things. There's pressure. There's
2273640	2284760	season. There's geography. But what we know about weather is that it's unimaginably sensitive to
2284760	2294760	small changes. So if you make an incredibly tiny difference 100 years ago, it, or even 10, 10 days
2294760	2299240	ago, sometimes it translates into big, big changes in the overall system. So this is one of the
2299240	2304200	things we learned by studying weather simulations. For example, when you run a weather simulation,
2304200	2311400	and you change one variable at the like 10th significant digit, you run it for a little while,
2311400	2315480	it very quickly diverges to some other state. Yeah, yeah.
2320920	2323640	That's right. Yeah. So this is the sometimes called the butterfly effect.
2324600	2329080	It's the idea that a butterfly flaps its wings in the Andes. And then two weeks later,
2329080	2335160	there's rain instead of sun across the world. And that's, I mean, so it's a general property of
2335160	2339880	complex nonlinear dynamical systems that that's going to be true, or at least some class of them.
2339880	2344840	And we're pretty confident that it's true of the weather. So if you want to ask, okay, so what's
2344840	2351800	the weather? Why is the weather the way it is today? You might have to talk about the weather on
2351800	2359240	Jupiter 10 years ago. You might have to talk about an errant comet passing beyond the bounds
2359240	2366200	of our solar system. Like, you might have to talk about random quantum mechanical fluctuations in the
2366200	2379960	sun. Like, yeah. Yeah, yeah. So the, the number of factors and the numbers factors, if you say,
2379960	2386360	I want to explain something, okay, great. So just cite the causes. Well, that makes the explanation
2387640	2394840	very quickly expand out to include the whole history of the universe, which is kind of inconvenient.
2395880	2401160	I take it that I mean, the assumption in this is that my assumption is typically that an explanation
2401160	2406360	is something that a human being could give or receive, right? Explanation is something that
2406360	2411880	we do amongst people. And if you have to cite the entire history of the universe since the Big Bang,
2412920	2418680	that's not going to work for us in any practical sense, right? I take it the scientific explanation
2418680	2422680	is something that we can do. And if it's suddenly the case that, okay, we figured out that it's
2422680	2426760	got to be causes, but now we just figured out that we can't explain anything because you'd have to
2426760	2434760	describe the entire history of the universe. That's kind of worrying. So Hempel notices this
2434760	2441640	actually. And one way, one way of dealing with this is to just say, look, we got too many causes.
2442360	2451080	The real explanation of any event is actually infinitely complex or practically, for our
2451880	2457720	practical purposes, it's infinitely complex. And that all that you've ever received or given
2457720	2465560	are what you might call explanation sketches, tiny, tiny, tiny little slices of the real
2465560	2474680	explanation, something like that. Yeah, so it's a weird, it's a weird philosophers move that
2474680	2481560	they get kind of pushed into here. So this, you start out from, hey, people explain things.
2481880	2485720	I know that you know that we explain things, explain things all the time.
2487560	2492680	How does that work? Well, here's a story. Okay, that story doesn't work. Here's another story.
2493240	2496920	That story has the consequence that that thing that we started off trying to understand
2498200	2505240	is kind of impossible. In the sense that you can't ever actually explain so you can't give
2505240	2512120	the whole explanation for anything. All you can ever give is the tiniest infinitesimal fraction
2512120	2519560	of the explanatory story. I don't know how you I don't know how you feel about that. I'm a little
2519560	2524920	uncomfortable with this as a move to sort of turn something very normal and ordinary into something
2524920	2531640	inconceivably complex and unrelated to any human activity. I don't know, you could be okay with
2531640	2543080	that. So this is, yeah, this is the human activity, this end of the front end of the
2543080	2547720	horse. And then the back end is what the universe is like. It's got much more detail and complexity
2547720	2551800	than this is what happened. What happened if I tried to draw a horse the front, the front half.
2552760	2559640	Okay, yeah, yeah, okay, so you could have a reverse situation where like the truth is
2559640	2565880	this stranger or sorry, sometimes fiction is stranger than truth, where you have a very boring
2565880	2571480	event that's exaggerated in a way to appear more complex than what actually happened. Okay,
2571480	2579400	that's a possibility, but that's not what's happening here, right? Okay, so causes as explanatory.
2580360	2582920	They got some issues. There's some serious questions about
2585080	2590760	whether this story is acceptable. They kind of hang on what you mean by cause.
2591960	2597480	So maybe you're willing to consider something much smaller as the cause of today's weather. So
2597480	2602040	you might say, look, I'm not going to talk about the weather on Jupiter 10 years ago. That's not
2602040	2607320	part of the story. It's not a big enough factor or an interesting enough factor, something like that.
2607320	2611880	But now we have to be sort of somewhat more selective. Once again, our interests have kind
2611880	2617080	of come back into the story. Once again, we've sort of been unable to get this clear. I mean,
2617080	2623000	what Hemple was going for was a clear objective criteria for what counts as an explanation.
2623000	2628040	The story he told us was too simple. And as soon as you start trying to complexify it are
2628920	2635480	what we're interested in gets back into the story. And we'll all develop this a little more next
2635480	2640120	time. We'll talk a little bit more about causes, what counts as a cause, what counts as a causal
2640120	2645560	explanation. We'll also talk a little bit about whether all scientific explanations have to cite
2645560	2652200	causes. So it might be the case that there are non-causal explanations. So that's our topic for
2652200	2655320	next time. Okay, that's it for today. Thanks everyone.
