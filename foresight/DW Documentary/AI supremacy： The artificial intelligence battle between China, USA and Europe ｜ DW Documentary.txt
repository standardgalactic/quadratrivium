After many, many years later, maybe we will look back.
We recognize that, oh, that's the moment when everything changed.
In five years, AI is going to literally be in everything we do.
As humans, we have to, first of all, understand that this is going to happen.
Many technologists try to solve human problems using technology when actually what we need
are human solutions.
The deeper question is, what does it mean to be human?
What are the things I'll still be proud of?
I find this moment extremely profound, because it really forces us as a humanity to think
through exactly what consciousness is, what makes humans human.
There's a whole lot at stake here.
It's careers, unbelievable amounts of money, and who gets to shape the future.
It's already begun.
A global race for supremacy in the age of artificial intelligence.
China, the United States, and the European Union are vying for economic growth, political
influence, and power.
So are the big tech companies, and startups are hot on their heels.
For those who lose, there'll be no second chances.
Jonas Andrewles founded one of the most influential European AI companies.
With his help, the European Union could catch up with the world's AI leaders, become independent
from the US and China, secure a prosperous future.
This is a watershed moment for Europe, the last roll of the dice.
If Europe wants to decide how to use technology in accordance with European values, then it
has to be able to build that technology itself.
Thomas Wolff co-founded Huggingface, a major open source AI platform.
He wants to stop one of the most powerful technologies in human history from ending
up in the hands of a few corporations.
What we need is a multitude of players, not just one that owns AI.
We don't want a future where such a fundamental technology is in the hands of a single company.
There are plenty of films where that's the mark of a dystopia, one company that controls
everything.
Han Chao is a Chinese AI entrepreneur.
He wants his company, Gina AI, to be successful on both the Western and Chinese markets.
So what role do Chinese AI companies play in this global race, and how is the Chinese
Communist Party using them to achieve its political goals?
Chai GPT or GPT-4, it basically serves as a brain, and this brain cannot be made in
the US.
So this is some worry that the Chinese government has.
The culture of each country, how each government runs this country will eventually be reflected
into this brain.
It is absolutely clear that at the highest levels of leadership in the United States
and in China, artificial intelligence is viewed as foundational to the future of economic
and military power.
We've created an economic and financial system that's based on the assumption that everything's
going to keep running smoothly.
We get cheap gas from Russia.
The Americans look after us, so we don't need to spend money on arms.
And as always friendly, we've gotten comfortable, and now we have to break out of that comfort
and say, we can go on the political offensive again, we can compete, we can create competitive
conditions here, we can make sure that the cool companies we have can also grow and play
a role in the global market.
At the end of 2023, German Vice Chancellor Robert Harbeck made significant progress towards
these geopolitical goals.
Aleph Alfa, a German AI company, raised around half a billion euros from investors.
It was one of the largest rounds of European financing for artificial intelligence technology,
and it was a signal that the European Union can produce elite players in the field of
AI.
Aleph Alfa's founder and CEO is Jonas Androulis.
His given priority to investment from German industry, SAP, Bosch and the Schwarz Group,
which owns supermarket retailers Liedl and Kauffland.
I was an amateur radio enthusiast.
I soldered radios together and built my own antennas.
Early on, my father had computers at home, so I was able to start programming and playing
around with them at a very young age.
When we started out, the term generative AI didn't exist.
Hardly anyone had heard of open AI.
We were very technical.
We managed to create category defining innovations.
We were just nerds, researchers.
And there were times when I felt like I wasn't coping with the amount of work and the challenges.
Every night, I could answer emails until I was so tired I fell off the couch.
And there were still things I was neglecting, which I didn't want to neglect.
In spring 2023, the European AI landscape was a lonely place.
With his startup, Alfa, Jonas Androulis had built the only generative AI that could compete
at an international level.
He'd acquired the expertise from his work as a high-ranking AI researcher at Apple.
Suddenly he'd become one of Europe's great hopes in the global AI race.
Right now we simply can't cope with the onslaught of potential customers and partners.
Most of the German stock index companies have been in touch, lots of medium-sized companies.
There are briefings, press engagements, events, an unbelievable amount of stuff.
It's like the Cambrian explosion right now, an incredible amount of new and creative things
are emerging.
We're the only Europeans to be involved on this scale.
It was an exciting development.
We also had things like open AI and maybe ours were even cooler.
What is missing and what I think deserves more attention in the EU is why there are
not more domestic companies that actually grow and scale.
A lot of company leaders, startup innovators end up going to the US and the access to capital
is really one of the main challenges.
If you look at what we did, it's enabling technology.
What I need for that is a carefully selected, effective team of brilliant researchers.
Then I need money.
More money than you normally get as a German startup.
These days we're talking about billions.
And then you need partners to help you, the kind of help that money can't buy.
Open AI doesn't just get 10 billion from Microsoft, it also gets incredible support
in integrating its technology into all Microsoft products and platforms.
At the time, Aleph Alpha had 60 employees at various locations.
Most were at the company's headquarters in Heidelberg in southwest Germany, unlike
Open AI, and Drullus wasn't gearing his AI towards private users, but rather industry
in the public sector.
But they tend to be sluggish and not easy to win over.
That posed a challenge for Jonas Andrullus.
He needed pilot projects to prove his technology works.
You stand here and you're greeted by a virtual person.
Hello, may I help you?
Where do you want to go?
Then I can use the screen.
We have to keep moving in this direction.
That's not good.
That's my job.
I know it is, but we're very happy to still have you.
She'll probably be taking her well-earned retirement soon.
It's become a standard question.
I ask if you'd like to stay on a little longer, because I need you, and because there aren't
enough skilled workers coming in.
It's a big issue.
That's important for us.
Solidarity.
And, of course, the main topic is innovation.
Heidelberg is one of the first municipalities in the world to introduce an AI citizen assistant
using a language model provided by Aleph Alpha.
We have a partner, a customer, with whom we can look at these new technologies.
They also act as a testimonial for us, because anyone can go and try it out.
That's a huge advantage, because a lot of our customers don't want to be named right now.
They don't want people to know exactly what they're doing,
so it's great to have a pilot customer with a bit of vision and courage.
The hope is that in the long term, AI will improve public administration and speed up services.
I just enter a question. Motor vehicle traffic on the B-37, which is a busy road.
Then I get it to search. Of course, that's a very general question.
The question now is what point in time, whether we're talking daily or annually.
Of course, the AI has to work out what the user actually wants.
The B-37 is closed between 7 a.m. and 6 p.m.
Now I can ask, how do I apply for child benefit?
That wasn't the right answer. It can't find anything now.
So the error messages that we get back from the public and from tests we do ourselves
get passed on to Aleph Alpha to figure out what needs to change to make the inputs more accurate.
It's always about the accuracy of the input.
The technology is still in the test phase and not yet reliable.
2023 was a delicate time for Aleph Alpha.
Jonas and Droolers needed fresh money from investors.
Meanwhile, Microsoft and OpenAI were gaining more of an advantage.
In fact, a race starts today and we're going to move.
We're going to move fast and for us, every day, we want to bring out new things.
On March 14th, 2023, OpenAI released ChatGPT4,
the most powerful artificial intelligence to date.
At the same time, it greatly reduced costs for users.
For Jonas and Droolers and his team, it was a threat to their business model.
We might have a poem about fly fishing from the perspective of a fish.
And it goes on for hours.
In the depths where shadows weave and play,
in this cool clear waters where I stay,
I am the fish beneath the silver stream,
where life's a dream or so it seems,
a wily being, sleek and sly,
with ancient instincts to live and die.
Yeah, it goes on.
Yeah, they see the ends of my heart.
I went to an apartment with a number of colleagues
and we watched on a big projector screen
the announcement of GPT4.
Someone had a ChatGPT Pro account,
so they could use GPT4 and we could play with it.
And we were, like, very impressed and surprised by how good it was.
It's not upsetting when someone comes out with a great piece of technology
because we're researchers and building technology and that's how it is.
You know, when you're a violinist and you go and you watch
an amazing solo by an incredible violinist,
you don't feel, oh, you know, I'll give up.
You know, it's inspiring.
I was a little stressed out.
I was in the middle of conversations with potential investors, business partners,
and I knew that in every conversation I was going into,
somebody would say, but GPT4.
I would have wanted to build GPT4 myself.
Two years ago, get 200 million,
be the first model at that level of capabilities
out of Heidelberg, out of Europe.
It caused a lot of frustration in the team and I saw that.
That's painful to see.
In fact, comparing open AI with ALEF Alpha was absurd.
Open AI was almost half owned by tech giant Microsoft,
which had pumped over 10 billion dollars into the company.
Jonas Androulas had raised just 28 million euros.
Still, he wanted to take them on.
We're all under enormous pressure.
We're fighting for security.
We're all under enormous pressure.
We're fighting for survival.
We've created something world-class with a lot less money.
We're basically at the forefront on the highest level.
But we all know that there's now a wave of Microsoft money rolling towards us,
and we can't do anything to stop it.
Is it very easier to speak in French or English?
I might find it difficult to make really French
without English words everywhere.
Yes.
Yeah, because, yeah.
While Jonas Androulas was filling the heat
from industry top dogs Microsoft and open AI,
Thomas Wolff was more worried
about the fact that he could not speak English.
He was worried about the fact that he could not speak English.
With Microsoft and open AI, Thomas Wolff was more relaxed.
He co-founded Huggingface,
which has 200 employees and offices in Paris, New York and Amsterdam.
The company has built a successful platform
where programmers and companies can share AI models
and further develop them.
The philosophy, the mission and the values that we push
are actually very European by some way.
Being careful about the data,
trying to build something responsible
and not just go fast and break it.
There are definitely Anglo-American values in chat GPT.
We wondered whether we could set up a project
to analyze and document that.
For example, with benchmarks that could show
whether a model has Anglo-American, French or German values.
It would be interesting to do a comparative study
between chat GPT and bloom chat, wouldn't it?
If you ask a question in different languages,
how different are the answers depending on the kind of question?
Is the approach more American or European?
That would be an interesting study.
That would be an interesting study.
That would be an interesting study.
When I talk about pluralism of values,
I mean that every population in the world has its own value system.
We have a lot of different nationalities here
and we have to ask ourselves, what are our values?
What's important to us?
Optimistic sparks in Europe, like new startups.
Germany, Aleph Alpha is already a big player.
In the UK, stability is obviously a very visible player.
Here in Europe, in France, there's Mistral,
there's a new player in Finland.
In almost every European country,
I see at least one or two startups with this ambition
to become and to build something big.
As idealistic as Thomas and his team from Hugging Face appear,
there is also criticism.
Open source or not, the end result is that a small elite of tech professionals
is determining what our future looks like
and what risks we're exposed to.
All the business people I meet say,
we need education, society has to educate itself.
We only create the systems,
but you can design those systems in different ways.
For example, you can make it so that a person can understand what's going on,
at least a little.
This could be one of the obligations we impose on the industry.
These machines have processed all cultural knowledge
and are created by mathematicians who don't know anything about culture.
That's a bit of an exaggeration, of course,
but we have to find ways of explaining this to people who aren't interested in the math.
They just use the machines as tools.
They need to understand where the limits are,
in which situations the machine will or won't work.
Just like with GPS devices,
where we recognize when they give us the wrong route.
Isn't it great that such a huge research field is opening up?
But there's also a huge gulf opening up.
Who's actually responsible in the end?
Because as a developer or researcher,
you have a certain responsibility.
It's not about restricting research,
but when there are applications that are harmful to society,
we have to be aware of that.
There is a huge potential for manipulation.
Just think of the influence of chat GPT on elections.
I think there needs to be an antidote.
More education.
That's a good topic for the upcoming elections.
What education do we need to stop us being manipulated?
That's a big question.
What happens when people start asking AI who they should vote for?
Because the AI will give them an answer, as it always does.
Who decides how it answers?
Who should decide that?
Unfortunately, I have no answer to that.
Generative AI is developing at breathtaking speed
and tech giants are battling it out in the ring.
That's spurring development even more.
There's a massive new market up for grabs.
Leading AI experts worry that big tech,
in its eagerness to compete,
is creating technologies beyond our control.
I think we've made a mistake
when my Swedish countryman Carl von Linnaeus branded our species
as homo sapiens, because sapiens means the thinking homo,
the smart one.
We're not going to be the smartest anymore.
Maybe we should re-brand ourselves the homo sentience,
the feeling human.
We can feel curiosity, meaning, purpose, love.
That is what really makes us unique.
We should ask, how can we keep control over the machine?
So that we can use them as tools to build a world
where we can really have human flourishing with positive experiences.
In 2014, when I founded the Future Life Institute,
it was quite taboo to even talk about AI safety at all,
because that would imply that it wasn't totally safe.
And a lot of AI researchers thought that it would be bad for funding,
and that only weird people worried about this.
It was very much like coming out of the closet moment
for people to sign this letter and say,
oh, you too are worried?
I think we should slow down a little bit.
Oh, I didn't know that.
And then it suddenly became socially acceptable.
Max Tegmark and his Future of Life Institute
published an open letter,
warning that artificial intelligence
posed an existential danger to humanity.
Civilisation itself could be under threat.
The letter was signed by hundreds of AI researchers
and tech industry leaders,
including Tesla boss and ex-owner Elon Musk,
Apple co-founder Steve Wozniak,
and touring award winner Joshua Benio.
And it's been quite shocking that once we put this letter out
and kind of a who's who of AI researchers signed it,
the conversation really exploded.
My worst fears are that we cause significant...
We, the field, the technology, the industry
cause significant harm to the world.
I think that could happen in a lot of different ways.
It's why we started the company.
I think if this technology goes wrong,
it can go quite wrong.
And we want to be vocal about that.
We want to work with the government.
I think he was serious about that.
I think that's kind of...
So we were talking about existential risks
and I also believe there are existential risks.
There are also a whole spectrum of other risks.
And I know of some, I talked to him a couple of times about this.
He very much recognises them as well.
On the one hand, of course, these warnings
about the major power of this new technology
also amplify the significance of the products
that these people are building.
So it could also have an indirect marketing effect.
Right? Like look at the incredible things that we're building.
But also, let's make sure that nothing goes wrong.
And for that, they look to the politicians.
The net effect of that could be that
if heaven forbid something goes wrong,
they could say, well, we warned you,
but the politicians did not act
or they did not act in time.
So I'm looking at a paper here
entitled Large Language Models Trained on Media Diets
Can Predict Public Opinion.
This is just posted about a month ago.
This work was done at MIT and then also at Google.
The conclusion is that large language models
can indeed predict public opinion.
I want to think about this in the context of elections.
Should we be concerned about large language models
that can predict survey opinion
and then can help organisations into these fine-tuned strategies
to elicit behaviours from voters?
Should we be worried about this for our elections?
Yeah. Thank you, Senator Holly, for the question.
It's one of my areas of greatest concern.
The more general ability of these models
to manipulate, to persuade,
to provide sort of one-on-one interactive disinformation.
I'm nervous about it.
I think people are able to adapt quite quickly
when Photoshop came onto the scene a long time ago.
For a while, people were really quite fooled
by Photoshopped images
and then pretty quickly developed
an understanding that images might be Photoshopped.
This will be like that, but on steroids.
And the interactivity,
the ability to really model, predict humans well
as you talked about, I think is going to require
a combination of companies doing the right thing,
regulation and public education.
2024 is a crucial election year.
Not only in the United States, but worldwide.
There will be European Parliament elections.
There will be elections in India.
I mean, it's a large amount of people in the world
will actually go to the polls.
And while we're living in this big experiment
where it's very hard for independent researchers,
journalists, civil society organisations
to probe these models,
that we may only find out, you know,
what the harms and malign uses
as a weapon against democracy were when it is too late.
Shortly after Sam Altman appeared before the US Senate,
he co-signed a statement
along with a number of high-ranking executives
from Google, Microsoft and other tech companies.
The fact that it was the companies
who themselves were asking for this type of regulation
and it was the leading researchers
who were asking for the government to get involved,
that really was the turning point in the conversation.
To understand the effect that generative AI
was having behind the scenes of global politics at the time,
you have to travel north to a small Swedish city called Luleå,
around 150 kilometres south of the Arctic Circle.
When people say that artificial intelligence
is going to be like the next industrial revolution,
I think they're underestimating its impact.
It's not just going to be a new technology
like the steam engine.
It's like building a new species.
A species that's much smarter than us.
President Biden himself was having meetings
on artificial intelligence in some cases
as often as three times per week.
And I will tell you that not very many things
get on the president's calendar for three times a week.
May 31st, 2023.
The sirens and motorcades descending on this Swedish coastal city
gave a sense of how much was at stake.
Leaders came here to discuss nothing less
than how humanity should react to the arrival of this new,
albeit artificial, form of intelligence.
What role should politicians play?
Democracy needs to show that we are as fast as technology.
You saw the first letter on asking for a course of six months.
You saw yesterday a number of very, very insightful people
signing up to say you need to do something
for the very existential risks.
And then you have the non-existential risks as well.
Why is it important for the European Union
to have a common policy with the US concerning AI
and shouldn't other parts of the globe
be included in the conversation?
Europe is important, but this is bigger than Europe.
US is important, but it is bigger than the US.
But if the two of us take the lead with close friends,
I think we can push something
that will make us all much more comfortable
with the fact that generative AI is now in the world
and is developing at amazing speeds.
Jonas Androulos was also invited to the top-level meeting in Sweden
to represent the views of European AI startups
and call for fair competition.
Of course there are other AI companies in Europe,
but we're the one that's keeping pace the most
with the global leaders.
I assume that's the reason why we're here,
not because we're so charming.
What kind of change is coming in some industries?
How do you feel about that?
We can raise more capital.
I think we have...
Two weeks ago I was at SFI conference,
SAP SFI conference,
and Christian Klein on his opening keynote
he kind of said,
our key partners for generative AI
are Aleph, Alfa, Google and Microsoft.
And then I'll have events coming up
with HPE, with Antonio Neri.
What do you think about
our colleagues on the other end here,
from Anthropics and the latest...
Statements, etc.
Oh, so the statements on safety?
Yeah, like yesterday and so on.
Long-term it is possible to conceive catastrophic events.
I've had Brussels and Berlin
and they basically are scared.
We will start with Jonas Androulis,
who's the founder and CEO of Aleph, Alfa.
The floor is yours,
and thank you very much for being with us today.
All right, thanks for having me.
I think we're all a little bit dizzy.
The speed of change,
like everybody I know that is in AI
is kind of stressed out,
and with this technology
we're only even just stretching the surface.
I fear that knowledge work
is in the hands of the world
and I fear that knowledge work
is an important part of what is happening in Europe.
So this is an opportunity for us
to build new empires,
to build new value,
but it's also a risk
that we're losing a substantial pillar
that we're standing on.
Thinking about how we can
make this a fair playing field,
because I think it's in everybody's interest
that Europe will contribute to a safer future in AI.
Thank you very much.
While the U.S. and the EU
were trying to come up with a common strategy
on the other side of the world in China,
an artificial intelligence ecosystem
was emerging with its own set of rules.
AI is a key part of China's efforts
to become a global power.
I always remember my mom and my dad
pushing me to this Olympic school
in order to get specialized in mathematics
and also English school.
It's like extra work
besides this regular schoolwork.
So basically you have to take the lessons
on Saturday, on weekend.
It makes me a quick learner.
And my mom is correct, right?
So in order to keep progress,
in order to keep pushing yourself,
you have to keep learning.
And I always tell my employees
also to keep learning,
to keep up this fast pace in AI.
My father was a professor
in computer science,
so I am very lucky to get
in touch with AI in the very early days.
Back in 2009, I was trying to
build some AI models,
very simple AI models.
Nowadays, if you look
from today's large language model perspective,
that model is like a very simple,
simple like a small ant.
Han Xiaoh has worked in both the East and the West.
He's held positions at the Chinese tech giant Tencent
and German online retailer Zalando.
Three years ago, he founded his own company.
Gina is an AI startup
with offices in Shenzhen and Beijing.
But its headquarters are in Berlin.
Oh, where do we have another interview here?
Why?
Yes, for the website.
For the website?
We have the internship program with interns
and now we want to add also like employees experience
so people can see how it is to work at Gina.
Not only from an intern perspective.
Yes, I see, I see.
So, Kalimia of course from India,
Isabella from South Africa.
Aladdin from Tunisia.
Jack Mian from Malaysia.
Michelle finally from Germany.
I have a limited amount of wires.
So I can only power one monitor.
Sometimes I really need to show people the architecture
and also show people the results of the model.
So it's nice that I have this second screen
where I can draw on it as well.
It basically becomes touchscreen.
So this is basically showing the progress
of training the model.
It's kind of like stock market, right?
I see this model performs relatively good
because you can see it's increasing over time.
But sometimes it's not very successful.
For example, this one, this model start very high
but then the progress kind of stopped.
That is wasting our time, it's wasting GPU resources,
energy and so on, right?
Han Shao and his team are working on optimizing
AI models for specific applications.
For example, linking text, video and images.
Their goal is to make communication between humans
and machines more intuitive and natural.
A lot of people may recognize this.
This guy, this is a kind of grand-par meme, right?
So it's very popular on social media, right?
So if you upload this picture to the algorithm,
it will generate a story.
You can generate comedy, erotic, fantasy, horror,
all this kind of story.
So we just keep it default and then we just do.
It wasn't supposed to be like this.
I was meant for more.
He whispered to the room, his words echoing into silence.
I am more than the lonely man I've become,
more than these disappointments.
Suddenly, his eyes glinted, a revelation forming within his mind.
Perhaps, it is time I showed the world that again.
With strengthened resolve, Arthur placed the coffee down,
marking an end to his solitary reflection
and the beginning of a new chapter.
So basically, this is what you can do
when you push multimodal AI into an extreme, right?
So you can see from a single image,
you are able to generate not only a text description,
but an emotional audio story.
Eventually, Chinese companies will be in the leading position
in this generative AI.
Two months ago, I was participating in this World AI Congress in Shanghai.
And during that conference, there were 30 large language models
released on one day.
Some from big companies like Tencent, Alibaba, Baidu,
some also from middle-sized companies from different industries.
For example, from Bank.
This Chinese company is usually very good at learning from U.S. companies.
So they kind of copycat what U.S. companies are doing
and then make it even better.
I don't doubt that one day, you will see one of the top models
in the benchmark in the leaderboard are actually from China.
The question of which companies will dominate the age of artificial intelligence
has real geopolitical consequences.
China is using the expertise of its tech companies to expand its power.
Western nations, meanwhile, are trying to counter this.
I'm going to go back.
My name is Jeffrey Kane.
I was a long-time journalist and foreign correspondent in China.
I wrote a book called The Perfect Police State,
and I was an advisor to the U.S. Congress,
to the House of Representatives on sanctions and Chinese politics.
From what I have seen around the world in China and elsewhere,
I am deeply concerned that we do not know how to manage AI yet.
We do not know what's coming.
We do not know how to rein in this technology
and put it to the good use of our democracy.
China has been leading in bringing technology under state control
and, in fact, using it as an instrument for state power,
whether it is for internal control and censorship, a grip on society,
or whether it is their global ambition to have digital infrastructure around the world
and to work with countries, for example, I think, about the African continent.
It is, of course, a vision that is at direct odds with that of democratic societies.
In 2017, China's national strategy for artificial intelligence,
and this is a public document,
set out the explicit goal of dominating global AI technology.
And so I think the United States has explicitly set the goal
that we are not going to assist China in rising as an AI-enabled authoritarian superpower.
Ironically, in the past, it's been large U.S. companies
that have undermined their government's policies
in order to gain access to the massive Chinese market,
foremost among them, Microsoft.
Microsoft is the most pivotal and important western company operating in China
that has helped the Chinese government develop its AI dystopia.
Microsoft set up an office in China called Microsoft Research Asia.
This was a gesture from Bill Gates back in the 1990s
because he wanted to guarantee stronger market access to China.
This laboratory has gone on to train the who's who list,
the superstars of the Chinese artificial intelligence world.
Many of the key people in this laboratory have gone on to found companies
such as MakeV, SenseTime, or either found them
or they've taken on very senior roles in them.
That was like the incubator of the modern Chinese internet or AI industry.
A lot of great people, great researchers, startup founders
actually come from Microsoft Research.
And those talents are now becoming kind of the very, very big influencers,
opinion leaders, and really like entrepreneurs in China.
Microsoft helped build China's tech elite.
This in turn has been used by the Chinese government
to create a gigantic surveillance state that operates with the help of AI.
Like in China, in Beijing and Shenzhen,
you can find the most CCTV camera in the world.
And to be honest, like a general public get used to it.
So they don't see this as intrusion to their own privacy
or having a software that analyze their behavior,
because the kind of the narrative there was to protect them,
to make the society more secure,
provide, protect from terrorists and so on.
So in general, like the public over the last 10 years
has already accept the fact that there are surveillance everywhere.
And now, not only you have an option of listening to all the information
that people exchange in society,
now you also have the cognitive capacity to process all of this.
So that's a scary, scary future.
Unfortunately, it's definitely not an impossible one.
Right now we have like over 500 city brands across the country.
That means one city is just like Shanghai.
They have a lot of big data analysis center.
They're collecting all this data from different areas.
And they have the machine, they have the algorithm,
like centralized it and do the computation analysis
and making all these decisions.
The Chinese government has used all forms of AI so far.
They see AI as an extremely powerful tool
that they can use for the military, for national security,
for state surveillance, police work,
also the management of cities, traffic.
They have been selling these same technologies all over the world,
especially to authoritarian governments
with the promise of total surveillance
and a nation free of crime, free of dissident,
it's a brave new world
because we have not yet found a solution to this in the West.
China is forging ahead.
The US is pursuing its own interests.
And the EU?
It's striving for independence.
If Europeans don't play a part in shaping this future technology,
then it will be American or Chinese AI
that will penetrate our lives to an unprecedented extent.
It will know us as well as our closest friends and relatives.
It will communicate with us around the clock
and influence our thoughts and actions.
To prevent this, the EU needs companies
that can not only program
but also build their own hardware infrastructure
to keep highly sensitive data safe.
The most precious commodity, the most important resource
for the future of generative AI is GPU power.
In other words, computing power.
In the future, it will be as essential as electricity
and water have been for developments that have taken place in the past.
There's already a saying in Silicon Valley, the GPU poor,
the people with fewer graphics cards.
Training high-end AI language models
requires thousands of high-performance graphics cards,
which is also why supplies are scarce.
That's another reason why many smaller players
ally themselves with large tech companies.
A lot of the deals in the field of generative AI in recent months
have come at the cost of independence.
Many companies have partnered with large corporations
by accepting restrictions on things like hardware selection,
cloud selection, integration.
We absolutely didn't want to do that.
Early on, Jonas Androulis recognized the value
of having one's own hardware.
He built a data center for his company in Germany.
For that reason, Alif Alpha is becoming increasingly strategically important
for politicians.
The media talks about you as Germany's answer to chatGPT.
Is that right?
That's wrong.
You could say Germany's answer to open AI,
but chatGPT is a product aimed at the consumer.
It's really intended to help school kids do their homework
and to help them understand what's going on in the world.
That's right.
That's not our target group at all.
We want to go where the most complex and critical processes are.
For example, in the financial industry,
in administration, in security, in healthcare,
that's where we want to build systems that assist and support people.
We're in a government ministry here.
We're in a government ministry here.
We're in a government ministry here.
And public administration could benefit enormously from AI.
We have an incredible number of processes
that could be systematized and carried out.
So the focus of my work here was a bit like asking
how the public sector could act as a mainstay consumer,
generating work, if you can put it like that,
which would create demand for German and European AI technology.
I mean, it's an AI company that targets the public sector,
and we are the public sector.
So we only have to see that we generate opportunities
for these technologies to be tested,
be it through customer experience, funding decisions, or even permits.
We talk a lot about regulation and that kind of thing,
but if we continue to be dependent on foreign countries
and commercial enterprises for the future,
we're going to be able to do that.
And if we continue to be dependent on foreign countries
and commercial enterprises for this essential technology,
then in the future, things could potentially end up
like they did with energy, like with gas recently,
where we wanted to say certain things, but we couldn't,
because otherwise it would have gotten cold and dark around here.
The data center that so far ensured Aleph Alpha's independence
is the US company Hewlett Packard Enterprise.
Hewlett Packard Enterprise is one of the biggest players
when it comes to setting up computer infrastructure.
They build data centers.
They set up internal server rooms.
A lot of the high quality infrastructure
in which the modern world runs comes from HPE.
MUSIC
Andrew Lewis secured a strategic partnership with HPE,
giving him access to hardware
without tying him to the company exclusively.
He also hoped it would help him gain a foothold in the US market.
He finalized the deal in Las Vegas
with HPE CEO Antonio Neri.
We're announcing a major joint project with HPE today.
There will be a press release going out simultaneously.
It'll be a big joint market venture.
That's the important thing.
Not that I'm going to go on a stage,
but that we're now taking a joint step with a major partner.
Am I nervous? Maybe a little.
We've been working towards this for months.
I'm sure it'll go well.
What is the competitive advantage of Marvel, eventually?
We're building our bond.
We have an independent tax tax,
so we're not relying on any external dependencies.
We recently solved explainability in a new way
so you can not only see positive, confirming sources,
but also disagreeing sources.
You share with me an example of that.
Yes, exactly. From your own kind of speech.
They are analysts here, so be careful.
Americans move fast.
They're willing to take risks,
but, of course, this partnership also has to benefit HPE,
and any partnership can come to an end at any time.
Jonas Andrewles wanted to avoid becoming dependent
on a large corporation,
as with open AI and Microsoft.
But that strategy brought with it a major risk.
If his technology doesn't keep up with the competition,
he'll be out of the race.
We'll have more money soon.
I'm hoping that yesterday helped a little bit with that.
Yeah, certainly didn't hurt,
and I've got some kind of immediate feedback
after the show from investors on my cell phone.
And, of course, I want to put this money to work.
I think if we can get your help,
if we could get your help to really say,
okay, these are the application use cases,
I think we can get that list from you,
and then we can turn around and look at,
okay, one, how do we package it?
Two, can we use it internally?
I think that would be great.
And then, obviously, three,
how do we make sure we line up the services offer?
Thanks again for the partnership. Great to see you.
Thanks a lot.
I think what always attracted us to the relationship was,
LFLFA's mission was to enable enterprise application use cases
for LLMs and multimodal models,
and most of the customers in the Valley
or most of the companies in Silicon Valley
were much more consumer-oriented.
So this concept of a single-tenant LLM
that can be trained with your data for your application
really fits our core customer base.
For all their friendliness,
and Drulles knew the Americans wanted to see concrete results,
he had to deliver and fast.
I will show you anger.
I have a smile for you.
Are you happy with the trade fair so far?
What's been most interesting?
The AI race is also a competition for attention.
It's about catching the eye of investors
sitting on panels, being noticed, being quoted.
We've already heard from a few masterminds on this topic today,
and there are still a few more to come.
With you, we'll be asking to what extent
AI itself will drive innovation.
This one's niche technology is now the subject of massive hype.
Jonas S. Drulles is suddenly in the spotlight.
His AI is being tested and evaluated,
not always favourably.
News Magazine did cite accused LFLFA of allowing its AI
to be provoked into making racist and chauvinistic statements.
And Drulles pointed out that its basic technology
has deliberately not been restricted.
That's just low-hanging fruit for journalists.
I took a screenshot.
The model used a bad word.
Every time I fine-tune the model or tune the instructions,
that diminishes it in certain areas.
It loses capabilities in exchange for me making it more pleasant or safer,
and those might be the exact capabilities that I need
in an industrial context for automating processes.
We want the embedding technology to become a well-known brand,
just like the iPhone.
That's the most important thing.
Don't forget to subscribe to our channel
for more videos like this.
We want to think about whether it makes sense or not.
We want to become a company like OpenAI,
the top provider in the embedding world.
What is the best way to push the team to focus on this product?
We have teams with different cultural backgrounds,
and sometimes it's very hard to organize everybody to concentrate on one thing.
This is also because the AI is developing so fast,
and a lot of hypes are here and there,
and people want to try this out, try that out.
So I just talk to my CEO and make sure that all the senior engineers,
senior leaders are kind of on the same page.
For me as a CEO,
my primary job is actually killing the fun,
killing the fun part by killing all this distraction
to make sure that people concentrate on the single mission
to make this company successful.
We are kind of a developer-driven company,
and most of our customers or users are actually developers,
software engineers.
So for example, right now there is a talentus sitting there,
and their engineering team is also our customer.
The biggest challenge is the competition in AI is just too intense.
Investors are not stupid, like most of the investors,
especially when it comes to later round,
investors have a very strict evaluation about this company.
So the companies that we are competing with,
such as Hackingface from France,
and Coher from the US,
so those companies are not like those guys who previously worked at Google,
or graduated from MIT, Stanford,
so they are very smart people.
Most of the investors will look at us as not as a small company,
but they will evaluate us with more,
not based on the hype, but based on the performance of the company.
So that means we have to show two things,
either the hyper growth of the user,
so we need to grow the user base super fast,
or we show them a solid revenue.
Summer 2023.
Thomas Wolff has managed to make time for a family vacation in Brittany, France.
As Chief Scientific Officer, he's primarily responsible
for research and development at Hackingface,
a job that allows him to take a break from time to time.
What are you up to today? Anything special?
We're practicing ceiling with a trapeze.
Didn't you do that yesterday?
Yes, today we'll do something else.
I'm here to help.
Meanwhile, Thomas' business partner, Clemente Long, is in the spotlight.
He's the CEO of Hackingface, the public face of the company.
Tech industry heavyweights like Google, Amazon, NVIDIA and AMD
have invested $235 million into Hackingface.
The open development platform for AI models has become a billion-dollar business.
It's not.
The company gained even more prestige
when Mark Zuckerberg's Meta used Hackingface
to publish its high-end language model, Lama 2.
It's a model that was recently published by Facebook, or Meta.
It's similar to ChatGBT, an open-source competitor.
The difference is that it's free.
You can just install it on your computer.
You don't have to access it through the ChatGBT interface or pay for it.
It's like a set of Lego.
Everything is open. Everything is freely accessible.
You can also buy it pre-built.
If someone builds an open-source model for you,
it's like they're building Lego for you,
a beautiful sports car made from Lego.
And then it's yours.
You can open up the hood and look inside.
The greatest advantage of open-source, its free accessibility,
is also its greatest weakness.
What if a model was developed further by criminals,
terrorists or other bad actors and used to cause harm?
Any security mechanisms built into a language model
can easily be removed.
That's a big question we're asking ourselves.
In the beginning, our aim was to make this technology
as widely accessible as possible.
We thought it would help lots of developers,
but there are two sides to the technology.
There are some people who can access it
who really shouldn't be able to.
There was a guy I met last year who had an AI.
Designed to develop medicines, molecules that are good for your health.
Just as an experiment, he put in a minus sign
and trained it to look for molecules that were bad for your health.
Within four hours, it discovered thousands of chemical weapons,
including VX, the most powerful nerve gas
that we here in the US have developed.
Of course, you shouldn't open-source things like that.
It's just crazy.
I'm a scientist. I love open-source, right?
And it's undeniable if you think about the pace of progress,
how do you make sure that there is the most progress?
Open-source is your friend.
Having said that, I just cannot completely ignore all the dangers.
And of course, the only argument I have seen so far
from supporters of open-sourcing, everything is saying,
well, we will figure it out.
It's easy to comment from the sidelines
to simply warn that it's all dangerous.
It's more difficult to actively get involved,
to try to create something positive, something good.
It won't necessarily be successful.
There'll be mistakes and then fresh attempts,
but I'm going to try.
It's risky, but we'll follow the path we think is right.
MIT is one of the most renowned tech universities in the world.
It has close ties to industry.
The research carried out here has the potential to change the world.
Needless to say, MIT is at the forefront of artificial intelligence.
In addition to his work with the Future of Life Institute,
Max Tegmark is a professor here.
The topic of AI security is part of his day-to-day.
So we want to ramp up the effort and pace at which we do things.
And it's also very inspiring whenever I go to Silicon Valley
and meet with various companies there,
how quickly they do things,
often compared to what we do in universities.
So I thought it'd be fun to...
Now we have a whole...
We're lucky to have a whole bunch of talented people here.
We can wrap up.
Tegmark and his fellow campaigners want to keep a close eye
on the tech startups from Silicon Valley,
uncover risks and use scientific methodology
to show people just how little time we have left
to counteract the pull of the tech industry.
So you've been working very hard on finishing our paper.
We had a very, very long conversation about it yesterday.
I thought the very last part of what we talked about
might be kind of fun for the whole group.
Yeah, I completely agree.
Do you want to draw that table on the board
and maybe they can contribute to good quotes for it?
So we basically, as you know,
modeled the conflict between the movement
to replace human livelihoods
and maybe replace humans period
versus the movement to resist this
and to preserve the status quo.
So this doesn't just come...
It's not just something Peter pulled out of a hat.
It just actually comes from the math.
So if you're naive, like,
oh, we have AI that can do everything a human can do but better,
my life will still be good.
So we call that naivete.
So if a lot of people believe this,
then they will not invest personal sacrifices
and personal costs to greater unite
and for the movement to be in a better position
to resist as a team.
There's companies and open-source developers
that are working day and night
with the goal of taking people's income streams
by creating AI models that are better
than them at their job and their capabilities.
So once you lose your income streams and your leverage,
like, it's too late.
Your options are more limited.
The biggest danger is that we'll look back in 20 years
and realize that we've automated everything
because it was so easy and because it worked
and the AI behaved correctly in 99% of cases
and suddenly we no longer have control
over something that's crucial for society.
The process has already begun.
Until now, it's been the intellectual and creative abilities
of humans that have set us apart from other creatures
and machines.
But what if those qualities are now being taken away?
My name is Dr. Inongo Lumumba-Casango,
a.k.a. Samus.
I'm a rapper, I'm a producer,
and I'm an assistant professor
at Brown University and the Music Department.
Initially, I wasn't sort of tapped into all of the discussions
that were happening around AI.
Of course, peripherally, I was sort of listening,
watching, reading,
but I really started to tap into these conversations
when I noticed what was happening
at the intersection of hip-hop and AI,
and that's when I realized, whoa, this thing is moving
really quickly.
I mean, last year, we were talking about
a sort of AI-generated rapper,
and this year, we're talking about rappers like Drake
and artists like The Weeknd having their voices
actually sort of cloned using AI technologies,
and so the speed at which this has become
sort of an immediate challenge for working artists
is very alarming.
Ultimately, it's the logic of capitalism,
and as a human creator, what you can do is
try not to be left behind.
As a Chinese, we always feel that, like,
technology, if you use it in a smarter way,
it can, like, push you,
uplift you yourself
to become a smarter, greater creator.
You know, machine and AI could do the job faster,
cheaper, and they don't have strike,
and, you know, they don't resist any, like,
ridiculous demand from the clients or from the bosses,
and I can see that Chinese companies are already,
like, using it to replace human labors.
So I think this is a very critical moment right now
for the creators around the world.
So this is something happening,
and it's gonna be big in the next three to five years.
So for folks like myself who, you know,
I've been able to build a life for myself,
but I would definitely not say that I'm in the,
sort of, like, top tier of the music industry.
There's a way that I think we're able to skirt under the radar
and continue doing work as we're doing it,
because it's so much about experimentation,
it's so much about trying out weird things,
and AI is so much about averaging.
It's the people who are invested in playing
in that space of the anomaly and playing with the unexpected,
who will, sort of, continue to thrive.
The impact of artificial intelligence
on our society is far-reaching and complex.
How can we regulate a technology
that's developing so quickly
and whose potential is almost impossible to gauge?
The United States is struggling.
Here in Washington, the tech industry's influence is huge,
and governing majorities are fragile.
The fact of the matter is that the U.S. government moves slowly.
It is a democracy.
That slowness is built into the system.
The U.S. government is not supposed to be efficient
and not supposed to be able to tackle problems quickly,
because a government that is too efficient,
you know, can use that against its own citizens, too.
I think that we've now reached a state in our society
that many philosophers and writers
in the 20th century warned about,
which is the inability to govern technology
due to the increasing pace of change.
Well, I certainly would not bet against democracies,
but it will be a really tough adjustment period.
The first major piece of legislation
aimed at regulating artificial intelligence
on a far-reaching scale came from the EU, the AI Act.
I definitely kind of really admire European Union
for being essentially the leader in this space.
They took on this kind of regulation very seriously
before anyone else really fought seriously all that.
Jonas Androulas has come to Brussels.
Together with other startup founders,
he wants to let politicians know
that strong regulation could put smaller European players
at a disadvantage compared to the competition
in the U.S. and China.
Meetings like this are always a bit difficult,
because you say your piece,
and you never really know what reaction you're going to get.
A few new people will listen,
and of course it's clear that cooperation
within Europe and with Europe is important,
but it's always hard to say how much we can achieve here and now.
No.
Do you have documents?
I could just talk. I've prepared something.
It's your session. You can decide where you want to sit.
So, good afternoon to all of you. I'm pleased to welcome you to the European Parliament to this
meeting, an important meeting at the right time. Something that will happen and we already see
basically a few steps down the road is like the cloud, like the hyperscalers have done
with cloud compute, there will be an infrastructure for general intelligence, that all the value
creation, all the apps, all the new innovations in the world will build upon. And for us, there
will be no second chance. If we cannot move fast, then we won't be able to try again in 12 months.
Thank you very much.
APPLAUSE
Androulos has repeated his message over and over again, whether on international stages,
to German politicians or here at the European Parliament. Over the course of a year, networking
and lobbying has become second nature to him.
So, I started my career as an investment banker and management consultant, wearing a suit and
38 degree weather with no air conditioning.
MUSIC
I don't think I'd make a good politician. I realize that in my days at Apple.
What's the probability of success? Is it worth investing this time? Is it worth fighting this battle?
I think so. I think it's a battle worth fighting, but I also have moments when I think that doing
something else would be pretty nice.
Shortly after his meeting with the European Parliament, it passed the AI Act.
MUSIC
Ten or even five years down the line, it is this governance structure that will give Europe the
ability to deal with the rapid evolution of AI and to reap the most benefits from it.
And we have worked first and foremost to ensure our citizens' rights and freedoms are not just
respected, but protected and strengthened. We don't want mass surveillance. We don't want social
scoring. We don't want predictive policing in the European Union. Full stop.
My name is Dragosh Daraque. I'm a member of the European Parliament, representing the
Renew Group, the Liberal Group in the European Parliament. I'm a judge by profession. I was
also a member of government in Romania, Minister of Digitalization, Minister of Interior, prior
to coming to Parliament.
AI will play very much into the power balance. Why? Because it drives our economies, but not
only. It becomes also a geopolitical factor, both in terms of how warfare is going to look
like, but also how this technology will play into many of the processes that will keep
one part of the world or the other competitive. And therefore, also the way you write the
standards and how those standards become globally accepted standards is very important in that
power balance that you mentioned earlier. So we're going to see very soon also, I think,
a competition or possible clash in terms of global standards. And that is why we have
to take measures to protect our interests and also to make sure that, again, our understanding
of the role of technology is one that is shared by as many on the global stage as possible.
In renegotiations, Germany, France and Italy lobbied again to soften the rules of the
AI Act to protect domestic players like Alpha Alpha from heavy regulation. But in the end,
the European Parliament prevailed.
In terms of regulation, we're the economy that's leading the way. And there's a concern that
that will take too much creativity out of the market. So in Europe, we're better at regulation
than at putting technology on the market, unfortunately.
The truth is, it's ultimately going to be good for the tech industry as well to be regulated,
level playing field. Even seatbelts in cars were viciously opposed by the auto industry at first.
But then when we got the law saying all cars have to have seatbelts, they started to sell much more cars.
Han Shao has travelled to Shenzhen. In order to keep his team on the same page, the CEO has to visit
the various company offices regularly.
So you see that there's red letters on the building that is basically our office. But we are not that big.
We are just one small room inside that big building.
He wants to take his company Gina to the next level. That will require all his employees to pull together
as much as possible.
I'll just put this down.
I brought some waffles. Try them. They're delicious.
You have to eat them.
You don't eat them.
I told them you have to eat now and make a happy face to the camera.
When I work at Germany, people are greeting each other like telling jokes,
talking random stuff, football match yesterday, all these kind of things.
Here is more introvert. The office is more introvert.
It's just like different working cultures.
Both of them are pretty productive under my weep.
I always think that a sequence of small success will make the team stronger
and make the team more confident on building things.
Because larger success means larger hope.
A larger hope could mean larger disappointment.
Here in the start-up, everything moves very quickly.
Then we become a little bit stressed.
We become a little bit nervous because we could lose the advantages
against the other competitors, against the market and so on.
It's not about what we did. It's about how people perceive us on what we did.
In Germany, there is also a team working on releasing a new large-language model.
Yesterday, the leaders told me that this model can be ready on Monday,
but it has been postponed for many times.
I have to see how it goes.
In the evening, Han Xiaoh has another meeting with a potential investor.
On the way, he calls his technical director to ask whether the launch
of the new language model is going as planned.
Hey, Wan Nan, your embedding platform has to get into the global best model list.
This company won't succeed unless everyone does their best.
If you don't get into the top 10, it'll be much more difficult.
Who uses a platform that's not in the top 10?
You need to think more about these practical things.
Is the LinkedIn post done? The Twitter post?
There needs to be a strategy here.
Okay, that's it. Bye.
We want to get into the top 10 model, a leaderboard.
Our models get into the top 10, but the German team just told me
they probably cannot get into the top 10.
That's why I get a little bit intense on my conversation,
because I said this is something that we promised to ourselves.
In this world, it's a very, very attention-based world.
If you cannot get into the top 10, even if you get into number 11, nobody cares.
This is why I'm telling the team that it's not about engineering only.
You also have to think about the whole company, the marketing sales.
It all depends on the top 10 models on this leaderboard.
Hi, Grace.
Grace Liu works for a Chinese investment bank.
The two first met a couple of years ago during the start-up phase of Han Xiaos' company.
You're just starting to bring AI-generated content to people, right?
Multimodal AI. We're working on two things right now.
One is prompt technology, and the other is embedding technology.
This year will be quite a challenge for you.
We've made a new software with prompt perfect aimed at developers.
We've already got 200,000 registered users.
Ah, that means there's a lot of demand.
I don't think I can jump to my conclusion yet,
but Han mentioned something very interesting to me about his new development and two new products.
Actually, the most important thing is the CEO, him or herself, right?
And whether he is a good entrepreneur, not only a scientist or a good developer.
Meetings like this one put opportunities on the table for Han Xiaos' company,
both in China and in the West.
And there's good news about his important project.
The new developer tool performs just as well as the equivalent technology from OpenAI.
By the end of 2023, Jonas Androulas has plenty to celebrate.
He's completed a major round of financing.
The company prevailed and convinced enough investors to raise half a billion dollars.
That's money Androulas is going to need,
because competitor OpenAI is already triggering a new technology.
We did a lot of things that smart people told me.
Four years ago, they would be impossible.
They signed the contract,
But what about technologies?
four years ago, they would be impossible.
Build deep tech, AIR&D out of Germany, impossible.
Fund this with mostly European capital, impossible.
Build our own data center, impossible.
Contribute category defining research, impossible.
And now we are entering into a new era
and I'm super happy to have you all with us.
Yeah, and thanks for being here
and help us make this the best party
that Heidelberg has ever seen.
Thanks.
And for Thomas Wolff, quiet holidays
may soon be a thing of the past.
Hugging face is now valued at $4.5 billion.
Thanks to successful startups and the AI Act,
the EU at least has a seat at the table
alongside the US and China.
For now, for humanity at large, the question remains,
what kind of world are we building right now
for ourselves and for our children?
I was holding my little baby Leo,
you know, who just turned nine months old
and looking into his eyes and thinking that, you know,
right now his language abilities are much worse
than chat's GPT-4 and he's never gonna catch up with AI ever.
I have two kids that are in middle school
and I'm thinking exactly about that,
what I should teach them about,
so they kind of prepared for the AI-infused future.
How do we teach our kids to kind of build something
like unique and individual?
The machine is our something,
it's our brothers or sisters, so we're working together.
So I think that's how I feel.
Even in these pivotal moments,
in these complex times, people always find a way.
They're creative and resourceful.
My son is already learning to code.
He's really interested in AI.
He wants to understand things and create things using AI.
Our children will probably create a world
that's completely different from ours.
We have a lot of people who are interested in AI,
who are interested in AI,
who will probably create a world
that's completely different from ours.
But I'm not worried.
At the end of the day, I'm an optimist.
