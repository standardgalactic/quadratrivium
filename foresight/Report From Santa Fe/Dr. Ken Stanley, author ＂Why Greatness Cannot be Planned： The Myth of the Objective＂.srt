1
00:00:00,000 --> 00:00:16,600
Report from Santa Fe is made possible in part by grants from the members of the National

2
00:00:16,600 --> 00:00:22,760
Education Association of New Mexico, an organization of professionals who believe that investing

3
00:00:22,760 --> 00:00:29,400
in public education is an investment in our state's economic future, and by a grant from

4
00:00:29,400 --> 00:00:33,600
the Healy Foundation, Taos, New Mexico.

5
00:00:33,600 --> 00:00:37,400
Hello, I'm Loreen Mills, and welcome to Report from Santa Fe.

6
00:00:37,400 --> 00:00:39,800
Our guest today is Kenneth Stanley.

7
00:00:39,800 --> 00:00:41,400
Thank you for joining us.

8
00:00:41,400 --> 00:00:42,400
Thank you, Loreen.

9
00:00:42,400 --> 00:00:43,400
Really happy to be here.

10
00:00:43,400 --> 00:00:47,720
Well, you are an associate professor at the University of Central Florida.

11
00:00:47,720 --> 00:00:52,760
You're a computer scientist, an artificial intelligence researcher, and you're here on

12
00:00:52,760 --> 00:00:55,320
sabbatical with the Santa Fe Institute.

13
00:00:55,320 --> 00:00:56,320
That's right.

14
00:00:56,320 --> 00:00:58,440
So that's how we get to have you.

15
00:00:58,440 --> 00:01:05,440
You are the co-author with Joel Lehman of this fascinating book, Why Greatness Cannot

16
00:01:05,440 --> 00:01:08,960
Be Planned, and the subtitle is?

17
00:01:08,960 --> 00:01:10,880
The Myth of the Objective.

18
00:01:10,880 --> 00:01:12,560
What is the objective?

19
00:01:12,560 --> 00:01:14,960
What do you mean, the myth of the objective?

20
00:01:14,960 --> 00:01:19,800
So when I'm talking about the myth of the objective, I'm talking about the fact that

21
00:01:19,800 --> 00:01:24,840
so many things that we do in our lives and in our culture are guided by what we call

22
00:01:24,840 --> 00:01:25,840
objectives.

23
00:01:25,840 --> 00:01:28,640
Like, it's something that you set that you want to achieve, and you say, this is now

24
00:01:28,640 --> 00:01:33,360
my objective, or this is our objective as a society, or as an institution, or something

25
00:01:33,360 --> 00:01:34,640
like that.

26
00:01:34,640 --> 00:01:39,760
And we believe, and this is like a really deeply entrenched aspect of our culture, that by setting

27
00:01:39,760 --> 00:01:43,200
an objective, it makes it possible to achieve it.

28
00:01:43,200 --> 00:01:47,280
And the message of the book, and the reason we call it the myth of the objective, is that

29
00:01:47,280 --> 00:01:52,520
actually many times, and this is a surprise, having an objective can actually prevent you

30
00:01:52,520 --> 00:01:54,800
from achieving your objective.

31
00:01:54,920 --> 00:02:00,920
So, it is a surprise, and something that we intuit, but the fact that you've come through

32
00:02:00,920 --> 00:02:07,320
it through computer science, and you wonder how many times does a theory in computer science

33
00:02:07,320 --> 00:02:12,360
affect our real life, but you have almost, some have said that this is in a way a scientific

34
00:02:12,360 --> 00:02:14,080
proof of serendipity.

35
00:02:14,080 --> 00:02:17,400
Yeah, I mean, this is a really unusual story.

36
00:02:17,400 --> 00:02:18,400
It's true.

37
00:02:18,400 --> 00:02:24,160
You usually don't end up prescribing social policy based on algorithms in computer science.

38
00:02:24,160 --> 00:02:29,520
And it was a long, you know, circuitous path for us to get from these scientific experiments

39
00:02:29,520 --> 00:02:33,840
to the point where we're actually critiquing certain things about culture and society.

40
00:02:33,840 --> 00:02:35,640
It wasn't our intention from the beginning.

41
00:02:35,640 --> 00:02:37,040
But that's what the whole book is about.

42
00:02:37,040 --> 00:02:38,040
Yeah, it's kind of...

43
00:02:38,040 --> 00:02:41,040
It had been your intention, you wouldn't have been able to do it.

44
00:02:41,040 --> 00:02:44,880
Yeah, I mean, it's like the story behind the book is almost like part of the theme of the

45
00:02:44,880 --> 00:02:45,880
book.

46
00:02:45,880 --> 00:02:47,200
Well, let's tell us that story.

47
00:02:47,200 --> 00:02:52,880
How did you arrive at this through your studies of algorithms and artificial intelligence?

48
00:02:53,240 --> 00:02:58,200
Right, so this is going to sound a little off topic, but actually this is the story

49
00:02:58,200 --> 00:02:59,200
of how we got to it.

50
00:02:59,200 --> 00:03:00,720
We were doing something completely different.

51
00:03:00,720 --> 00:03:02,880
We had no idea we were going to get here.

52
00:03:02,880 --> 00:03:08,760
But we had created a website on the internet, which is called Pick Breeder, where people

53
00:03:08,760 --> 00:03:12,160
can come in and breed pictures.

54
00:03:12,160 --> 00:03:16,040
And I know that probably listeners don't really know what that means to breed a picture,

55
00:03:16,040 --> 00:03:19,200
like you don't mate Picasso with a van Gogh.

56
00:03:19,200 --> 00:03:22,760
But you know, I come from artificial intelligence and in that field, actually, we had been

57
00:03:22,800 --> 00:03:28,760
working on technologies that would allow us to, in effect, give a picture a child.

58
00:03:28,760 --> 00:03:32,880
And just as when you have a child, it might look somewhat like you, but be a little bit

59
00:03:32,880 --> 00:03:34,080
different.

60
00:03:34,080 --> 00:03:40,360
When Pick Breeder images have children, they also look like their parents, but not exactly.

61
00:03:40,360 --> 00:03:44,800
And that allows users to, in effect, breed pictures the way you might breed horses or

62
00:03:44,800 --> 00:03:47,120
dogs or something like that.

63
00:03:47,120 --> 00:03:49,920
So I know that our audience is going to want to go look at this.

64
00:03:49,920 --> 00:03:56,320
So it's www.pickbreeder, P-I-C-B-R-E-E-D-E-R dot org.

65
00:03:56,320 --> 00:04:02,000
So show us some of the images, say a person would go to that site, and then track us down

66
00:04:02,000 --> 00:04:03,800
the amazing work that you had done.

67
00:04:03,800 --> 00:04:07,680
Yeah, so it's really surprising, I think, some of the images that people have discovered.

68
00:04:07,680 --> 00:04:15,440
I'm just going to show a few images that give a sense of what people have discovered.

69
00:04:15,440 --> 00:04:20,760
And you can see that these images actually look like real things.

70
00:04:20,760 --> 00:04:24,200
Like there's a skull there, there's a butterfly, and this is just a small sampling of what

71
00:04:24,200 --> 00:04:25,760
people discovered.

72
00:04:25,760 --> 00:04:30,080
And it's important to point out that people evolved these things from blobs.

73
00:04:30,080 --> 00:04:33,520
That's how things start, just total random blobs.

74
00:04:33,520 --> 00:04:36,040
And they got to these amazing images.

75
00:04:36,040 --> 00:04:40,440
And that's the beginning of the story of how we came to this realization, because we started

76
00:04:40,440 --> 00:04:44,480
to look at how people were making these discoveries.

77
00:04:44,480 --> 00:04:50,040
How people were breeding, say, an image that looks like a car or a skull.

78
00:04:50,040 --> 00:04:55,840
And it turns out, and this is sort of where the insight began, that you might expect that

79
00:04:55,840 --> 00:04:59,760
if you came into this site and you were trying to breed, breed images like you might breed

80
00:04:59,760 --> 00:05:03,040
horses, that you would say, well, I'm trying to breed a butterfly or something.

81
00:05:03,040 --> 00:05:06,120
And then you would sort of pick things that look more and more butterfly-like, and that's

82
00:05:06,120 --> 00:05:08,040
your objective, and then you get it.

83
00:05:08,040 --> 00:05:13,040
And we thought that too, but what we discovered was that, in fact, the only way that any of

84
00:05:13,040 --> 00:05:17,200
these interesting discoveries were being made was when they were not the objective of the

85
00:05:17,200 --> 00:05:18,840
user who bred them.

86
00:05:18,840 --> 00:05:22,800
And this was just a huge revelation for us, completely unexpected.

87
00:05:22,800 --> 00:05:27,440
It blew me over because it contradicted everything that I understood about achievement and how

88
00:05:27,440 --> 00:05:29,400
to get to an objective.

89
00:05:29,400 --> 00:05:36,240
Show us, I think one of the clearest examples is the image of the alien face, which then,

90
00:05:36,240 --> 00:05:41,360
through evolutionary art, as they call this, became the image of a car.

91
00:05:41,360 --> 00:05:46,080
And tell me how many generations it took, but first let's see the image.

92
00:05:46,080 --> 00:05:48,680
So let me show you a picture of this alien face.

93
00:05:48,680 --> 00:05:54,280
This is a story, part of a story about how this initial realization came about.

94
00:05:54,280 --> 00:06:00,440
And this alien face, it's important to note, was not bred by me, it was bred by someone

95
00:06:00,440 --> 00:06:01,440
else.

96
00:06:01,440 --> 00:06:06,360
It had been posted on the site so that I was able to see that it was there, and then I

97
00:06:06,360 --> 00:06:11,200
decided to continue from there, which we call branching.

98
00:06:11,200 --> 00:06:13,400
And here's what happened.

99
00:06:13,400 --> 00:06:17,200
It was several generations, actually I don't know the exact number, maybe 15 generations

100
00:06:17,200 --> 00:06:23,600
or 20 generations, of picking children and continually breeding that then led me to this

101
00:06:23,600 --> 00:06:27,360
really surprising discovery, which is a car.

102
00:06:27,360 --> 00:06:32,600
So what happened, the story is that the alien face was bred into a car.

103
00:06:32,600 --> 00:06:38,320
And what's so important about this is the fact that I had this experience myself, so

104
00:06:38,320 --> 00:06:42,460
I know for a fact I was not trying to evolve a car.

105
00:06:42,460 --> 00:06:46,240
And if you put all that together, I mean just think about how strange this story is.

106
00:06:46,240 --> 00:06:50,360
I chose an alien face, which someone else evolved, it wasn't me, so I wouldn't have

107
00:06:50,360 --> 00:06:52,200
evolved that myself.

108
00:06:52,200 --> 00:06:56,440
And then I evolved a car, which is something that I wasn't trying to evolve.

109
00:06:56,440 --> 00:07:00,560
So someone else had to do something that I never would have done, and then I had to not

110
00:07:00,560 --> 00:07:04,720
be trying to do what I ultimately did for me to make this discovery.

111
00:07:04,720 --> 00:07:09,080
And if you hear that story, it sounds like, wow, that was a big coincidence, you got really

112
00:07:09,080 --> 00:07:10,800
lucky that one time.

113
00:07:10,800 --> 00:07:15,200
But the amazing thing that we discovered is that that actually is always the story.

114
00:07:15,200 --> 00:07:19,280
Almost every interesting discovery in the site has that exact same story.

115
00:07:19,280 --> 00:07:22,760
Somebody evolved something that the other person would never have evolved, and then the second

116
00:07:22,760 --> 00:07:27,200
person kind of took it in a handoff and bred it to a place that they weren't actually trying

117
00:07:27,200 --> 00:07:28,480
to get to.

118
00:07:28,480 --> 00:07:31,440
And that's how you actually find things on Pick Reader.

119
00:07:31,440 --> 00:07:35,720
But one of the most amazing statistics that you told me was that there are some that have

120
00:07:35,720 --> 00:07:43,600
taken 50 generations or 90, 74 generations, but then when you programmed a computer to

121
00:07:43,600 --> 00:07:51,200
do it, to go from the alien to the car, after 30,000 generations, they could not do it.

122
00:07:51,200 --> 00:07:53,960
With that intention of going there, they couldn't.

123
00:07:53,960 --> 00:07:55,720
The computer, try and make it.

124
00:07:55,720 --> 00:08:00,320
This is a really important point, it's really surprising if you think about it.

125
00:08:00,320 --> 00:08:05,080
I mean, what I told you basically is that people find things by not looking for them,

126
00:08:05,080 --> 00:08:09,480
but the converse is also really surprising, which is people do not find things by looking

127
00:08:09,480 --> 00:08:10,480
for them.

128
00:08:10,480 --> 00:08:14,840
Like if you came in there and you wanted to evolve a butterfly, you would fail because

129
00:08:14,840 --> 00:08:18,040
as an objective, it's too hard to actually discover.

130
00:08:18,040 --> 00:08:22,240
And these experiments that you just described are basically confirmation of that fact in

131
00:08:22,240 --> 00:08:28,320
kind of an extreme way by giving it 30,000 generations to try to reproduce an image that

132
00:08:28,320 --> 00:08:29,920
already had been discovered.

133
00:08:29,920 --> 00:08:35,000
So we know it's even possible and every time we tried it, each 30,000 generation attempt

134
00:08:35,000 --> 00:08:40,520
it failed, it never succeeded and it just illustrates that it's sometimes impossible

135
00:08:40,520 --> 00:08:45,480
to reach a destination by trying, even though we know that these destinations can be reached

136
00:08:45,480 --> 00:08:47,120
because they have been.

137
00:08:47,120 --> 00:08:52,040
And I just want to point out again that the image on the cover of your book is one of

138
00:08:52,040 --> 00:08:57,720
the butterflies that was evolved from something completely different without trying to make

139
00:08:57,720 --> 00:08:58,720
a butterfly.

140
00:08:58,720 --> 00:09:04,560
It's just another example and basically every image has that story behind it.

141
00:09:04,560 --> 00:09:06,440
And you know, the reason is kind of important.

142
00:09:06,440 --> 00:09:08,240
So you may ask, well, why is it like that?

143
00:09:08,240 --> 00:09:11,560
You know, why is it that you can only find things by not looking for them?

144
00:09:11,560 --> 00:09:14,600
And the reason is because if you think about it, like if you think about the example of

145
00:09:14,600 --> 00:09:20,560
the car, an alien face led to that car, no one would ever guess that you can get from

146
00:09:20,560 --> 00:09:22,400
an alien face to a car.

147
00:09:22,400 --> 00:09:25,360
If you look closely in hindsight, you can see that...

148
00:09:25,480 --> 00:09:28,520
I think you have a picture of the eyes and the wheels.

149
00:09:28,520 --> 00:09:40,840
Yeah, I can show a connection there that, in fact, the eyes of the alien turned into

150
00:09:40,840 --> 00:09:42,400
the wheels of the car.

151
00:09:42,400 --> 00:09:46,640
And this is something that's only obvious in hindsight.

152
00:09:46,640 --> 00:09:49,560
But looking forward, you would never realize something like that.

153
00:09:49,560 --> 00:09:53,600
And so the point is that the stepping stones, in this case the stepping stone is this alien

154
00:09:53,600 --> 00:09:54,600
face that led to a car.

155
00:09:54,600 --> 00:09:59,000
The stepping stones never resemble the final product, and that's why you would not know

156
00:09:59,000 --> 00:10:03,520
to go through those stepping stones if the final product was your objective.

157
00:10:03,520 --> 00:10:08,360
So the only way you can get to these important stepping stones is by not being single-mindedly

158
00:10:08,360 --> 00:10:10,560
focused on a single objective.

159
00:10:10,560 --> 00:10:14,040
And then you open up all that possibility of eventually reaching these destinations

160
00:10:14,040 --> 00:10:15,640
that were not your objective.

161
00:10:15,640 --> 00:10:21,080
Now I'm going to expand this a little bit because it is as incredible cultural and social and

162
00:10:21,080 --> 00:10:22,960
evolutionary.

163
00:10:22,960 --> 00:10:29,480
So our world is so governed by objectives and talked about goal-oriented, whether it's

164
00:10:29,480 --> 00:10:34,920
test scores, scientific funding, I mean, we could go on and on, bottom line profits, career

165
00:10:34,920 --> 00:10:36,120
tracks, everything.

166
00:10:36,120 --> 00:10:39,080
You have a goal and then you work toward that goal.

167
00:10:39,080 --> 00:10:44,920
And then what you're saying, if the objective paradox is that sometimes you have to give

168
00:10:44,920 --> 00:10:51,120
up that goal to achieve what you, you know, something maybe greater, if your goal is making

169
00:10:51,120 --> 00:10:53,800
a sandwich, it's very clear what the steps are.

170
00:10:53,800 --> 00:11:01,520
But if your goal is to end world hunger or to cure cancer or to make man fly, you shouldn't

171
00:11:01,520 --> 00:11:05,840
be, there's no trajectory that will step by step take you there.

172
00:11:05,840 --> 00:11:07,400
It often hinders you.

173
00:11:07,400 --> 00:11:08,400
Yes.

174
00:11:08,400 --> 00:11:10,560
I mean, and I think, you know, we're making a leap here.

175
00:11:10,560 --> 00:11:16,160
We're going from picture breeding to how really important discoveries happen.

176
00:11:16,160 --> 00:11:21,800
And while this is a strange leap, we should really be concerned when we think about this.

177
00:11:21,800 --> 00:11:26,560
You know, because really the way that discovery happens is no different from pick breeder.

178
00:11:26,560 --> 00:11:31,320
All of us, when we lead, when we discover something, are building on something that was created

179
00:11:31,320 --> 00:11:33,200
by our predecessors.

180
00:11:33,200 --> 00:11:35,440
And those are the stepping stones.

181
00:11:35,440 --> 00:11:41,440
And what this lesson teaches us is that if those stepping stones do not resemble what

182
00:11:41,440 --> 00:11:45,960
we're ultimately trying to achieve, then there's almost no way that we're going to actually

183
00:11:45,960 --> 00:11:49,040
traverse those stepping stones intentionally.

184
00:11:49,040 --> 00:11:54,200
And therefore, we should be worried about a society that's molded in such a way that

185
00:11:54,200 --> 00:11:59,280
we're always trying to constrain everything we do through some kind of objective compass

186
00:11:59,280 --> 00:12:03,160
because the effect is going to be that we prune out the stepping stones, which don't

187
00:12:03,160 --> 00:12:04,720
look like the objective.

188
00:12:04,720 --> 00:12:08,960
And that, in fact, is how we run a lot of our society.

189
00:12:08,960 --> 00:12:16,280
Now, serendipity, let's talk about what great discoveries that have been—I mean, your

190
00:12:16,280 --> 00:12:21,000
book is full of its fascinating read—is full of these ways that—how about Elvis?

191
00:12:21,000 --> 00:12:25,320
Talk to me about Elvis and the microwave and some of your favorite stories.

192
00:12:25,320 --> 00:12:26,320
Yeah, sure.

193
00:12:26,320 --> 00:12:32,360
So the book gives a lot of these examples of—sometimes we call it serendipitous discovery.

194
00:12:32,360 --> 00:12:36,520
And these are really important because they illustrate that this is not just about pick

195
00:12:36,520 --> 00:12:37,520
breeder.

196
00:12:38,520 --> 00:12:43,520
Like Elvis is an example because Elvis was not trying to invent rock and roll.

197
00:12:43,520 --> 00:12:48,960
But he effectively did at least become one of the inventors of rock and roll.

198
00:12:48,960 --> 00:12:54,760
And his colleagues say that he was just playing around and being himself.

199
00:12:54,760 --> 00:12:58,200
And it's almost inconceivable that someone could have an objective of inventing rock

200
00:12:58,200 --> 00:13:01,320
and roll because if you did, then you probably already invented it.

201
00:13:01,320 --> 00:13:04,520
And it just goes to show that there's lots of things like that in life that you're not

202
00:13:04,520 --> 00:13:07,560
going to run across unless you're not trying to create them.

203
00:13:07,560 --> 00:13:10,160
Now, there are more practical things than just rock and roll.

204
00:13:10,160 --> 00:13:13,000
I mean, there's things like the computer.

205
00:13:13,000 --> 00:13:14,000
I like this example.

206
00:13:14,000 --> 00:13:18,040
You know, the computers—the first computers were made out of vacuum tubes.

207
00:13:18,040 --> 00:13:21,360
So vacuum tubes are a stepping stone that leads to computers.

208
00:13:21,360 --> 00:13:22,920
But here's an interesting fact.

209
00:13:22,920 --> 00:13:27,100
The people who invented vacuum tubes were not thinking about computers.

210
00:13:27,100 --> 00:13:29,280
They were used for electrical experiments.

211
00:13:29,280 --> 00:13:33,200
In fact, if your interest had been in computers, why would you be making vacuum tubes?

212
00:13:33,200 --> 00:13:36,000
It has nothing to do, obviously, with computers.

213
00:13:36,000 --> 00:13:39,680
So it's a good thing that their objective was not to make computers or else we wouldn't

214
00:13:39,680 --> 00:13:41,400
have them.

215
00:13:41,400 --> 00:13:43,640
And these kind of examples, you can go on and on.

216
00:13:43,640 --> 00:13:44,880
The microwave one I like.

217
00:13:44,880 --> 00:13:46,920
The microwave one's another good one.

218
00:13:46,920 --> 00:13:51,080
And this is where Percy Spencer—and this is a very serendipitous thing—where he

219
00:13:51,080 --> 00:13:54,880
had a candy bar in his pocket and he was working on radars, which had microwave technology

220
00:13:54,880 --> 00:13:55,880
in them.

221
00:13:55,880 --> 00:13:59,600
And he noticed that the candy bar melted and suddenly realized, you know what, this actually

222
00:13:59,600 --> 00:14:01,360
leads to a microwave oven.

223
00:14:01,360 --> 00:14:05,480
So you get radar technology as a stepping stone to microwave ovens.

224
00:14:05,480 --> 00:14:09,320
Once again, no way to project looking forward that you go from radars to a new kind of an

225
00:14:09,320 --> 00:14:10,320
oven.

226
00:14:10,320 --> 00:14:14,000
But looking in hindsight, you can see where the connection came in.

227
00:14:14,000 --> 00:14:17,800
And this kind of example happens again and again, and in fact, I just would like to point

228
00:14:17,800 --> 00:14:23,520
the viewers to the Wikipedia page on serendipity, where there are tons of examples like this.

229
00:14:23,520 --> 00:14:26,880
And the suspicious thing about it, the thing that I think people should take note of is

230
00:14:26,880 --> 00:14:31,600
that the people who made these discoveries all have a good track record or all educated

231
00:14:31,600 --> 00:14:34,400
or have been successful in the past.

232
00:14:34,400 --> 00:14:41,720
I mean, if this was just a complete accident, then you wouldn't have these very well respected

233
00:14:41,720 --> 00:14:43,680
people making these discoveries.

234
00:14:43,680 --> 00:14:47,880
So it suggests that—and I think we're going to get to this—that this kind of process

235
00:14:47,880 --> 00:14:49,640
of discovery is not pure random.

236
00:14:49,640 --> 00:14:56,400
You can actually try to fasten your life in such a way that you have more opportunities

237
00:14:56,440 --> 00:14:58,600
to encounter this kind of serendipity.

238
00:14:58,600 --> 00:15:01,760
And this is something as a society that we can also try to facilitate.

239
00:15:01,760 --> 00:15:07,360
Well, we're speaking today with Kenneth Stanley about his new book, Why Greatness

240
00:15:07,360 --> 00:15:08,880
Cannot Be Planned.

241
00:15:08,880 --> 00:15:14,240
But as you described this, again, we have an unconscious understanding, and perhaps it's

242
00:15:14,240 --> 00:15:21,400
artists and musicians the most who understand this.

243
00:15:21,400 --> 00:15:26,120
Talk to me about stepping stones and talk to me about how we can live in a way that

244
00:15:26,120 --> 00:15:31,600
we are aware of these evolutionary steps.

245
00:15:31,600 --> 00:15:32,600
What do you call it?

246
00:15:32,600 --> 00:15:33,600
Treasure hunter.

247
00:15:33,600 --> 00:15:34,600
What is it?

248
00:15:34,600 --> 00:15:36,040
Who would be a treasure hunter?

249
00:15:36,040 --> 00:15:37,680
How do we become treasure hunters?

250
00:15:37,680 --> 00:15:42,760
Yeah, so the natural question that follows from the story that I've kind of given so

251
00:15:42,760 --> 00:15:46,360
far is, well, how do we make this happen?

252
00:15:46,360 --> 00:15:49,920
It sounds nice that, well, we can all just do whatever we want.

253
00:15:50,040 --> 00:15:53,840
What's the real formula here that actually someone can key in on?

254
00:15:53,840 --> 00:15:57,280
And the answer is that when you look at a system like Pick Breeder, what we're actually

255
00:15:57,280 --> 00:16:00,320
observing when we came to understand what was happening, why people were making all

256
00:16:00,320 --> 00:16:05,600
these discoveries, is that the system as a whole, the website in this example, is collecting

257
00:16:05,600 --> 00:16:06,880
stepping stones.

258
00:16:06,880 --> 00:16:11,120
Every time someone comes to that website and discovers something and publishes it to the

259
00:16:11,120 --> 00:16:16,600
community, everybody can see it, like the alien face that I saw that I eventually evolved

260
00:16:16,600 --> 00:16:17,600
into a car.

261
00:16:17,600 --> 00:16:18,600
That's a stepping stone.

262
00:16:18,600 --> 00:16:23,520
And the more stepping stones people publish, the more opportunities or departure points

263
00:16:23,520 --> 00:16:25,840
are created for further discovery.

264
00:16:25,840 --> 00:16:29,120
And that's what I mean by a stepping stone collector.

265
00:16:29,120 --> 00:16:35,200
And it's in our interest to try to fashion society, especially the parts of it that are

266
00:16:35,200 --> 00:16:39,160
focused on innovation or discovery, as a stepping stone collector.

267
00:16:39,160 --> 00:16:42,040
And I sometimes also, like you said, call it a treasure hunter, because you can think

268
00:16:42,040 --> 00:16:43,520
of these as treasures that are sort of buried.

269
00:16:43,520 --> 00:16:44,520
We don't know what they are.

270
00:16:44,520 --> 00:16:48,480
It's not an objective, but we know that there's lots of interesting stuff out there.

271
00:16:48,680 --> 00:16:53,120
And we go hunting and trying to uncover them as much as we can.

272
00:16:53,120 --> 00:16:54,640
You're used to the word interesting.

273
00:16:54,640 --> 00:17:01,320
So you have created a noun, I don't know if it exists, called interestingness, right?

274
00:17:01,320 --> 00:17:07,200
And you say that the scent of interestingness can lead us across these chains of stepping

275
00:17:07,200 --> 00:17:10,120
stones into who knows what.

276
00:17:10,120 --> 00:17:14,120
But because we do this, because it's interesting, and when people are choosing those images,

277
00:17:14,120 --> 00:17:15,600
it's just the one that kind of interests them.

278
00:17:15,600 --> 00:17:18,640
They're not thinking about the ratios or the proportion.

279
00:17:18,640 --> 00:17:23,600
And so when you're guided by your own instincts, where will this take you?

280
00:17:23,600 --> 00:17:24,600
Yeah.

281
00:17:24,600 --> 00:17:27,800
So we tend not to trust people's instincts.

282
00:17:27,800 --> 00:17:32,840
I mean, that's one of the morals here, is when we talk about interestingness, that's

283
00:17:32,840 --> 00:17:35,680
the scent you have to follow if you don't have an objective.

284
00:17:35,680 --> 00:17:38,920
You know, you're saying, well, which path should I follow?

285
00:17:38,920 --> 00:17:42,120
And you don't know where any of them lead, because there's no objective.

286
00:17:42,120 --> 00:17:45,760
That doesn't mean that you can't make an intelligent decision.

287
00:17:45,760 --> 00:17:49,680
Often people will follow the path that's most interesting to them.

288
00:17:49,680 --> 00:17:54,560
And what we've kind of done as a culture is decided that that's not a legitimate thing

289
00:17:54,560 --> 00:17:55,560
to do.

290
00:17:55,560 --> 00:17:59,960
In other words, we say that just about anything that you do has to somehow be objectively

291
00:17:59,960 --> 00:18:01,120
validated.

292
00:18:01,120 --> 00:18:03,880
You have to say what your objective is, and then we have to prove that you're actually

293
00:18:03,880 --> 00:18:05,680
moving towards that objective.

294
00:18:05,680 --> 00:18:09,880
Which means that nobody can get away with actually following the scent of interestingness.

295
00:18:09,880 --> 00:18:13,640
If you think about, you know, accountability and metrics, and these things are pervasive

296
00:18:13,640 --> 00:18:18,000
in our society, they're all objectively driven, and they're all pruning out this concept of

297
00:18:18,000 --> 00:18:22,800
interestingness, which ultimately means we don't trust people to use their instincts

298
00:18:22,800 --> 00:18:27,360
or their expertise, and we think it's too risky to let them do that, and so we're pruning

299
00:18:27,360 --> 00:18:31,720
out all of the creative possibilities that those people could potentially uncover.

300
00:18:31,720 --> 00:18:37,120
So here we have the objective paradox, which is to achieve our highest goals.

301
00:18:37,120 --> 00:18:39,360
We must be willing to abandon them.

302
00:18:39,360 --> 00:18:44,000
And then how can we create an environment for ourselves to go against the myth of the

303
00:18:44,000 --> 00:18:45,000
objective?

304
00:18:45,000 --> 00:18:47,840
Because you're saying working toward an objective is not going to do it.

305
00:18:47,840 --> 00:18:50,960
So you have posited a day without objectives.

306
00:18:50,960 --> 00:18:52,640
What would that do?

307
00:18:52,640 --> 00:18:57,720
And you say that not meeting our objectives, which are superimposed on this, or come from

308
00:18:57,720 --> 00:18:59,760
within, is very stressful.

309
00:18:59,760 --> 00:19:03,400
You feel like an underachiever because you didn't win the Nobel Prize today.

310
00:19:03,400 --> 00:19:09,040
And how would society be different just even if we could take some time off from objectives?

311
00:19:09,040 --> 00:19:10,520
For kids, for example.

312
00:19:10,520 --> 00:19:11,520
Yeah.

313
00:19:11,520 --> 00:19:15,120
I mean, and you could think about this in the context of the education system where

314
00:19:15,120 --> 00:19:19,920
people just saturated with things like standardized tests.

315
00:19:19,920 --> 00:19:21,800
And this is no doubt.

316
00:19:21,800 --> 00:19:26,320
Most people have an instinct that this is having a bad effect on children.

317
00:19:26,320 --> 00:19:33,040
And we've done experiments, further experiments, beyond Pick Reader, where we actually formalized

318
00:19:33,040 --> 00:19:35,000
Pick Reader in a computer program.

319
00:19:35,000 --> 00:19:40,280
We called it Novelty Search, which we used to kind of demonstrate and show that it is

320
00:19:40,280 --> 00:19:46,600
actually possible to implement this principle in practice and use it to make discoveries

321
00:19:46,600 --> 00:19:47,600
that are useful.

322
00:19:47,600 --> 00:19:51,040
And one of the things that we found in these experiments is that allowing things to make

323
00:19:51,040 --> 00:19:56,720
mistakes and do things that we think are objectively perhaps bad or subpar actually leads them

324
00:19:56,720 --> 00:20:02,160
eventually to discovering really important skills and abilities.

325
00:20:02,160 --> 00:20:06,040
And so that might be a difference if we could allow people to do that, is that we would

326
00:20:06,040 --> 00:20:11,920
get to places that we couldn't get to in a more efficient and also satisfying way.

327
00:20:11,920 --> 00:20:14,960
Well, you talk about it being a different path to achievement.

328
00:20:14,960 --> 00:20:21,000
And you did have, in the Novelty Search, you had a program where you created the jogger.

329
00:20:21,000 --> 00:20:25,120
And I think you have an illustration of this jogger.

330
00:20:25,120 --> 00:20:33,440
And the jogger's job was to go down through these walls.

331
00:20:33,440 --> 00:20:34,440
And well, tell me.

332
00:20:34,440 --> 00:20:35,440
Tell me what you're...

333
00:20:35,440 --> 00:20:42,440
Yeah, so we made this program, which is a kind of demonstration of this principle, this

334
00:20:42,440 --> 00:20:44,960
non-objective principle.

335
00:20:44,960 --> 00:20:48,640
And you know, Pick Reader has humans in the loop, humans are making decisions.

336
00:20:48,640 --> 00:20:52,200
We wanted to show that we can do this completely inside of a computer, partly because I'm

337
00:20:52,200 --> 00:20:53,280
an AI researcher.

338
00:20:53,280 --> 00:20:57,160
So people in my field want computers to do stuff on their own that's intelligent.

339
00:20:57,160 --> 00:21:02,040
But usually in the field of artificial intelligence, if you were making a program to train a robot

340
00:21:02,040 --> 00:21:05,800
to walk, and here I'll show a picture of what this robot looks like.

341
00:21:05,800 --> 00:21:09,460
This is a robot in different kind of steps of walking.

342
00:21:09,460 --> 00:21:15,640
Usually if you were trying to do something like this, you would reward the robot in some

343
00:21:15,640 --> 00:21:17,840
sense for getting better at walking.

344
00:21:17,840 --> 00:21:19,840
So it's like if it can get farther, it's better.

345
00:21:19,840 --> 00:21:23,480
And then we would elaborate on that strategy, and then we get better and so forth.

346
00:21:23,480 --> 00:21:29,020
What we did is we created this program called Novelty Search, which does not try to improve

347
00:21:29,020 --> 00:21:30,520
with respect to walking.

348
00:21:30,520 --> 00:21:34,280
Rather, it just says you're doing a good job if you're doing something different than

349
00:21:34,280 --> 00:21:35,880
you've done before.

350
00:21:35,880 --> 00:21:38,800
And so it falls on its face, it does all kinds of stupid things.

351
00:21:38,800 --> 00:21:41,600
But if it falls on its face in a different way, that's good.

352
00:21:41,600 --> 00:21:42,840
We say great.

353
00:21:42,840 --> 00:21:46,360
That means that that's a stepping stone that we should explore further to see what might

354
00:21:46,360 --> 00:21:48,880
happen if we elaborate on that idea.

355
00:21:48,880 --> 00:21:53,480
And in so doing, eventually it actually led to walkers, and it actually led to walking

356
00:21:53,480 --> 00:21:57,880
robots that walk better than the ones that were trained by rewarding them for trying

357
00:21:57,880 --> 00:21:58,880
to pursue the objective.

358
00:21:58,880 --> 00:22:05,240
So it kind of demonstrated this point in a real concrete, scientific, empirical way.

359
00:22:05,240 --> 00:22:11,040
So one of the things that you say, it's sometimes better to start from where you are instead

360
00:22:11,040 --> 00:22:12,400
of where you want to go.

361
00:22:12,400 --> 00:22:14,920
Talk to me about the Wright brothers.

362
00:22:15,360 --> 00:22:20,960
So when you think about objectives, what an objective really is, it's about comparing

363
00:22:20,960 --> 00:22:24,520
where you are to where you want to be.

364
00:22:24,520 --> 00:22:29,600
And when you talk about something like novelty, which is not an objective concept, novelty

365
00:22:29,600 --> 00:22:33,840
is basically comparing where you are to where you've been before.

366
00:22:33,840 --> 00:22:35,840
And for some reason, we don't like doing that.

367
00:22:35,840 --> 00:22:38,960
We want to always compare ourselves to the future.

368
00:22:38,960 --> 00:22:42,960
But something like the Wright brothers, we can view, sometimes that's used as a counter

369
00:22:42,960 --> 00:22:43,960
example.

370
00:22:44,400 --> 00:22:47,400
They wanted to build something that can fly, and then they did.

371
00:22:47,400 --> 00:22:51,880
But we can also view it as the Wright brothers were at the right stepping stone at the right

372
00:22:51,880 --> 00:22:57,880
time and realized that right at that moment, the stepping stones had been laid.

373
00:22:57,880 --> 00:23:01,680
So this is where they are right now that have suddenly enabled us to move in a direction

374
00:23:01,680 --> 00:23:02,680
towards.

375
00:23:02,680 --> 00:23:04,800
And they were bicycle manufacturers.

376
00:23:04,800 --> 00:23:05,800
They were making bicycles.

377
00:23:05,800 --> 00:23:06,800
Yeah, right.

378
00:23:06,800 --> 00:23:10,120
So in some sense for them, a bicycle was a stepping stone that kind of made an analogy

379
00:23:10,120 --> 00:23:11,120
with a plane.

380
00:23:11,120 --> 00:23:14,120
And they saw that you can bridge that gap.

381
00:23:14,120 --> 00:23:20,320
So sometimes it makes sense to just sort of appreciate the possibilities of where you

382
00:23:20,320 --> 00:23:25,180
are, as opposed to saying this is this long term vision that we need to achieve and everything

383
00:23:25,180 --> 00:23:26,840
I do will now be compared to that.

384
00:23:26,840 --> 00:23:28,560
We only have a couple of minutes left.

385
00:23:28,560 --> 00:23:32,480
Steve Jobs talks about this a lot.

386
00:23:32,480 --> 00:23:36,680
Because he was in college, he dropped out, he took a calligraphy class, he said, only

387
00:23:36,680 --> 00:23:40,120
looking back, can I see how one thing led to another?

388
00:23:40,120 --> 00:23:45,840
And that's why Apple and his products were as beautiful and as sensible as they were.

389
00:23:45,840 --> 00:23:49,840
Yeah, I mean, Steve Jobs, he could have been a co-author of this book because his life

390
00:23:49,840 --> 00:23:53,480
was really kind of lived in the spirit.

391
00:23:53,480 --> 00:23:57,680
And like this calligraphy class that he took, and he didn't know that this was going to

392
00:23:57,680 --> 00:24:03,120
lead to a revolution in computer fonts, until in hindsight he saw that a connection was

393
00:24:03,120 --> 00:24:04,120
there.

394
00:24:04,120 --> 00:24:05,120
And he has a lot of stories like this.

395
00:24:05,120 --> 00:24:08,040
He dropped out of college and that's what allowed him to take the calligraphy class.

396
00:24:08,040 --> 00:24:13,400
And most people would not think of dropping out of a college as an objectively good decision.

397
00:24:13,400 --> 00:24:18,240
So a lot of people have done great things, have followed this philosophy in some sense.

398
00:24:18,240 --> 00:24:23,060
Well, you have taken your research in the physical world into the metaphysical.

399
00:24:23,060 --> 00:24:29,040
And there's overtones of Zen Buddhism and a lot of paths that say, if there's no destination,

400
00:24:29,040 --> 00:24:32,200
every path is the right path, because it moves you along.

401
00:24:32,200 --> 00:24:36,680
In the last part of your book, I just want to read this beautiful sentence of yours.

402
00:24:36,680 --> 00:24:40,880
It's called, farewell to the...

403
00:24:40,880 --> 00:24:41,880
Farewell to the mirage?

404
00:24:41,880 --> 00:24:42,880
That's the chapter.

405
00:24:42,880 --> 00:24:43,880
The mirage of object.

406
00:24:43,880 --> 00:24:44,880
Right.

407
00:24:44,880 --> 00:24:47,980
This mirage that objectives can get you where you want to go.

408
00:24:47,980 --> 00:24:54,200
And you say, when all is said and done, even when visionaries grow weary of stale visions,

409
00:24:54,200 --> 00:25:00,520
when the ash of unrequited expectation settles on the cloak of the impenetrable future, there

410
00:25:00,520 --> 00:25:04,320
is but one principle that may yet pierce the darkness.

411
00:25:04,320 --> 00:25:09,080
To achieve our highest goals, we must be willing to abandon them.

412
00:25:09,080 --> 00:25:10,080
Yeah.

413
00:25:10,080 --> 00:25:11,920
I mean, that sort of recaps the book.

414
00:25:11,920 --> 00:25:14,520
That's the concluding paragraph.

415
00:25:14,520 --> 00:25:17,720
And it's a difficult pill to swallow.

416
00:25:17,720 --> 00:25:19,040
It sounds strange.

417
00:25:19,040 --> 00:25:23,080
Giving up objectives is like giving up a security blanket.

418
00:25:23,080 --> 00:25:27,360
But I hope that the evidence there is compelling enough to make people think twice about using

419
00:25:27,360 --> 00:25:32,080
objectives for almost everything that we do in our culture, because it is going to lead

420
00:25:32,080 --> 00:25:36,400
to this kind of ash falling on the cloak of the impenetrable future.

421
00:25:36,400 --> 00:25:37,800
Yes.

422
00:25:37,800 --> 00:25:39,880
And your book is full of examples.

423
00:25:39,880 --> 00:25:47,320
I mean, from history that we all know and understand of people who have given up their

424
00:25:47,320 --> 00:25:51,920
stated objective just to find out and discover what was out there.

425
00:25:51,920 --> 00:25:54,240
And look what it's done for our world.

426
00:25:54,240 --> 00:26:00,560
I must tell you, Kenneth, your book, I think this is a stepping stone.

427
00:26:00,560 --> 00:26:02,000
Why greatness cannot be planned.

428
00:26:02,000 --> 00:26:04,480
I really urge people to read it.

429
00:26:04,480 --> 00:26:07,040
You're in challenging territory here.

430
00:26:07,040 --> 00:26:08,520
And I think it's really life-changing.

431
00:26:08,520 --> 00:26:09,920
I want people to read your book.

432
00:26:09,920 --> 00:26:13,680
And I'm so grateful that you, our guest today, is Ken Stanley.

433
00:26:13,680 --> 00:26:16,280
Thank you for taking the time to join us today.

434
00:26:16,280 --> 00:26:17,280
Thank you so much.

435
00:26:17,280 --> 00:26:19,920
I'm really glad to have this opportunity to get this message out.

436
00:26:19,920 --> 00:26:21,000
Yes, yes.

437
00:26:21,000 --> 00:26:25,120
And I'd like to thank you, our audience, for being with us today on Report from Santa Fe.

438
00:26:25,120 --> 00:26:26,620
I'm Loreen Mills.

439
00:26:26,620 --> 00:26:29,560
We'll see you next week.

440
00:26:29,560 --> 00:26:37,320
Most archival programs of Report from Santa Fe are available at the website, reportfromsantafe.com.

441
00:26:37,320 --> 00:26:45,080
If you have questions or comments, please email info at reportfromsantafe.com.

442
00:26:45,080 --> 00:26:49,720
Report from Santa Fe is made possible in part by grants from the members of the National

443
00:26:49,720 --> 00:26:55,860
Education Association of New Mexico, an organization of professionals who believe that investing

444
00:26:55,860 --> 00:27:02,540
in public education is an investment in our state's economic future, and by a grant from

445
00:27:02,540 --> 00:27:05,540
the Healy Foundation, Taos, New Mexico.

