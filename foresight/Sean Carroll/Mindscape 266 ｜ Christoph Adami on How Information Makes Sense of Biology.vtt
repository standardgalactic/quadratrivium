WEBVTT

00:00.000 --> 00:04.000
Hello, everyone. Welcome to the Mindscape Podcast. I'm your host, Sean Carroll.

00:04.000 --> 00:09.000
Long time listeners will know that I've long been a fan of Las Vegas.

00:09.000 --> 00:14.000
I like to go to Vegas, play poker, eat, shop, whatever, just relax and have a good time.

00:14.000 --> 00:18.000
Haven't been able to do it quite as much. Now that we're on the East Coast, that's okay.

00:18.000 --> 00:23.000
There's always pluses and minuses. Now we can go to New York. It's like the Las Vegas of the East.

00:23.000 --> 00:28.000
But anyway, one of the reasons why I like Las Vegas is in addition to the stereotypes.

00:28.000 --> 00:35.000
So the stereotypes are absolutely there, right? There are long rows of slot machines

00:35.000 --> 00:40.000
with dull-eyed people mindlessly pressing buttons hoping to get rich someday.

00:40.000 --> 00:46.000
It's kind of depressing, that part. But there's a lot of weird stuff in Vegas if you look closely enough.

00:46.000 --> 00:53.000
So by Vegas standards, one of the weird things that I really like is there's an outpost of Bowman Rare Books.

00:53.000 --> 00:57.000
This is a well-known rare book store with headquarters in New York.

00:57.000 --> 01:04.000
But they have a Vegas store in the Palazzo Hotel Casino, where I used to stay sometimes.

01:04.000 --> 01:08.000
And it's just weird. Among all the glitz and glamour, here's rare books.

01:08.000 --> 01:13.000
And they actually have a lot of first editions of things, but also some weird sciency books.

01:13.000 --> 01:16.000
They have a signed Albert Einstein, for example.

01:16.000 --> 01:23.000
And I was very amused to see in Bowman's Rare Books in Vegas a copy of Claude Shannon's Master's Thesis.

01:23.000 --> 01:28.000
Claude Shannon, famous 20th century scientist for many reasons.

01:28.000 --> 01:34.000
And his Master's thesis, I didn't actually know this before I saw it in the bookstore, is very famous.

01:34.000 --> 01:41.000
It's been called by Howard Gardner the most influential Master's thesis of all 20th century science.

01:41.000 --> 01:45.000
This is a Master's thesis that has its own Wikipedia page, okay?

01:45.000 --> 01:54.000
And it's about basically using Boolean analysis to model and improve the efficiency of circuits and things like that.

01:54.000 --> 01:57.000
Pretty awesome for a Master's thesis kind of thing.

01:57.000 --> 02:05.000
But for my purposes today, I'm just using this as a somewhat strained segue into, of course, Claude Shannon's big contribution,

02:05.000 --> 02:11.000
even bigger than the Master's thesis came 10 years after when he essentially invented information theory.

02:11.000 --> 02:15.000
He wrote a paper called The Mathematical Theory of Communication.

02:15.000 --> 02:25.000
And like many great scientific breakthroughs, theoretical breakthroughs, this was driven by a down-to-earth technological practical need.

02:25.000 --> 02:30.000
Shannon was interested in sending signals across the Atlantic Ocean in wires.

02:30.000 --> 02:33.000
And you want to send a signal in a way that is efficient, right?

02:33.000 --> 02:38.000
That is least likely to be garbled or to lose the information.

02:38.000 --> 02:44.000
And to do that, to figure out how to do that, you need to have a mathematical way of characterizing what you mean by information.

02:44.000 --> 02:53.000
And it turns out, as he discovered by doing the math, that it's very, very similar to the formula for entropy in statistical mechanics.

02:53.000 --> 03:05.000
So there was clearly some interesting hidden relationship here between information and communication on the one side and statistical mechanics and thermodynamics on the other side.

03:05.000 --> 03:09.000
And of course, so this is the middle of the century, 1948.

03:09.000 --> 03:12.000
This idea has blossomed quite a bit.

03:12.000 --> 03:14.000
You hear about information all the time.

03:14.000 --> 03:16.000
You hear about it in the political arena, right?

03:16.000 --> 03:18.000
Misinformation, disinformation.

03:18.000 --> 03:20.000
You hear about it in technology.

03:20.000 --> 03:23.000
The information superhighway, that was a big thing.

03:23.000 --> 03:31.000
And you must have heard that information as a concept is useful in biology, in neuroscience, quantum mechanics, quantum information, and so on.

03:31.000 --> 03:44.000
So today, on the podcast, we have Christoph Adami, who is, like many mindscape guests, he started out his career as a relatively traditional physicist doing nuclear and particle physics.

03:44.000 --> 03:50.000
And now he's a professor at Michigan State, not only in physics, but also in, I think, molecular biology department.

03:50.000 --> 03:54.000
But he studies evolution and life, including artificial life.

03:54.000 --> 04:03.000
And he has a new book out called The Evolution of Biological Information, How Evolution Creates Complexity from Viruses to Brains.

04:03.000 --> 04:11.000
So I'm going to use this as an excuse to really get clear on what is this information theory stuff.

04:11.000 --> 04:13.000
I mean, by the way, the book is a little technical.

04:13.000 --> 04:16.000
I'm not going to advocate it for people who don't like equations.

04:16.000 --> 04:19.000
There are some equations there, but the equations are quite mild.

04:19.000 --> 04:27.000
You know, if you're the kind of person who doesn't read equations every day, but doesn't blanch when you see one, it might be a good book to pick up.

04:27.000 --> 04:39.000
And we're going to talk about what information theory is in general and specifically how biologists or people who care about biology, even if they're physicists, are going to use information theory to better understand things like evolution

04:39.000 --> 04:41.000
and even the origin of life.

04:41.000 --> 04:48.000
I would say that 75 years later, the idea of information theory we got from Claude Shannon is still not settled in.

04:48.000 --> 04:52.000
You know, we're still working through the basic implications of this.

04:52.000 --> 04:53.000
So it's very exciting.

04:53.000 --> 04:54.000
It's fun.

04:54.000 --> 04:58.000
It's a new lens with which to look at the world in a detailed way.

04:58.000 --> 05:01.000
And, you know, that's all we like to do here at the Mindscape Podcast.

05:01.000 --> 05:02.000
So let's go.

05:09.000 --> 05:22.000
Chris Hadami, welcome to the Mindscape Podcast.

05:22.000 --> 05:23.000
Glad to be here.

05:23.000 --> 05:27.000
You know, let's start with this idea of information theory.

05:27.000 --> 05:37.000
It's always going to be a challenge when you have an idea like information theory that uses a natural language word that people are familiar with, right?

05:37.000 --> 05:38.000
Information.

05:38.000 --> 05:42.000
They think they know what information is, but now we have math behind it.

05:42.000 --> 05:48.000
We've talked about information theory a lot on the podcast without ever just taking a breath and saying what it is.

05:48.000 --> 05:54.000
So do you have a best way, a favorite way of explaining information theory to the person on the street?

05:54.000 --> 05:55.000
I do.

05:55.000 --> 06:05.000
It's actually strange that in this case, the mathematical understanding of the word information is actually very similar or very close to our understanding,

06:05.000 --> 06:09.000
generally speaking, in our normal, you know, everyday usage.

06:09.000 --> 06:25.000
So to really define information mathematically or even in words, we can just say that information is that which allows someone who has that information to make predictions with accuracy better than chance.

06:25.000 --> 06:26.000
Right?

06:26.000 --> 06:29.000
So there's a system that I know something about it.

06:29.000 --> 06:33.000
And then that means I can actually predict some of its states.

06:33.000 --> 06:38.000
For example, you know, where I can find coffee with accuracy better than chance.

06:38.000 --> 06:44.000
If I would be just randomly go somewhere, well, I would most likely not end up in a coffee place.

06:44.000 --> 06:50.000
But if I have information, that means I can actually say, hey, I have to go to this particular place.

06:50.000 --> 06:55.000
And that's how we understand it normally in our everyday language.

06:55.000 --> 06:59.000
And it is also exactly how it is defined mathematically.

06:59.000 --> 07:06.000
Mathematically, information is that which is used to make predictions, but it has to be better than chance to be information.

07:06.000 --> 07:09.000
Otherwise, it's just a guess, right?

07:09.000 --> 07:17.000
And so because making predictions with accuracy better than chance is really powerful, that means it's also powerful in biology.

07:17.000 --> 07:20.000
But of course, it's also powerful, let's say in the stock market.

07:20.000 --> 07:28.000
If I have inside information, I can get rich using information because I can make predictions about, for example, the stock price was accuracy better than chance.

07:28.000 --> 07:37.000
And Shannon, when he defined this concept in 1948, he defined it precisely that way, even though he didn't use exactly those words.

07:37.000 --> 07:43.000
And as a consequence, there's a lot of misunderstanding about what information really is.

07:43.000 --> 07:48.000
It's often confounded with entropy, which is in a sense the absolute opposite of information.

07:48.000 --> 07:51.000
Namely, it is about what we don't know.

07:52.000 --> 07:59.000
And so if you then confound information and entropy, then you're going to get a lot of misunderstandings.

07:59.000 --> 08:04.000
But didn't, I completely agree with you, by the way, but didn't Shannon himself do that?

08:04.000 --> 08:15.000
I mean, didn't he use the word information, like maximal information for him in a code or an alphabet is maximum entropy, right, when every symbol is equally likely?

08:15.000 --> 08:18.000
You are right. He has done that.

08:18.000 --> 08:30.000
I should say not so much in his original article, but you know, there was a book written or co-written, but I forgot it's Shannon and Macmillan or something, Shannon and Weaver.

08:30.000 --> 08:35.000
In particular, in the book Shannon and Weaver, the words entropy and information get mixed up.

08:35.000 --> 08:39.000
And I have a suspicion that this was mostly Weaver doing that.

08:39.000 --> 08:47.000
I would have to actually look at the original article if Shannon himself does that, because in a sense, you know, he should know better.

08:47.000 --> 08:55.000
Just because I saw so much of the confounding between entropy and information, I felt compelled to just simply write an article called What is Information?

08:55.000 --> 08:56.000
Yeah.

08:56.000 --> 09:03.000
Which this main purpose was to say, Hey guys, you know, you have to be careful. One is not the other.

09:03.000 --> 09:04.000
No, that's great.

09:04.000 --> 09:11.000
But I do sometimes wonder, you know, I agree with everything you just said, and I wonder if it's just my physics training.

09:11.000 --> 09:23.000
Because to me, thinking like Boltzmann would have thought, a low entropy state, if you tell me that you're in a low entry macro state, all the molecules are in one corner of the room, you've given me a lot of information, right?

09:23.000 --> 09:27.000
Low entropy is a lot of information, and that makes perfect sense to me.

09:27.000 --> 09:36.000
That's right. Low entropy is a lot of information. You can think of information as simply a difference between two entropies, namely the maximum entropy and the actual entropy.

09:36.000 --> 09:37.000
Okay, good.

09:37.000 --> 09:45.000
So that's why when your actual entropy is low, then your information is high, because it's this difference.

09:45.000 --> 09:49.000
And the fact that it's a difference, by the way, is a fundamentally important thing.

09:49.000 --> 09:56.000
Namely, entropy itself, in a sense, has no real meaning or existence, just like energy doesn't have in physics.

09:56.000 --> 10:05.000
Only differences of entropy have a meaning, just like in physics, only differences between energies have any real life effect.

10:05.000 --> 10:14.000
And so the fact that it's a difference is important, but it's important that the first term is a maximum entropy, like how much there is to know about the system.

10:14.000 --> 10:22.000
And if you forget about that, then your information is just minus entropy, or what a bunch of people have called negentropy, right?

10:22.000 --> 10:29.000
Which is nonsense. It's forgetting the first term, which is the maximum entropy, so that this thing, which is information, is always positive.

10:29.000 --> 10:37.000
So basically, in this way of talking, you would say, when I have some configuration, and I have some statistical knowledge about it,

10:37.000 --> 10:46.000
I can divide the state into sort of the entropy part, which I don't understand very well, and the information part, which specifies something.

10:46.000 --> 10:57.000
Right, or very simply speaking, for every system, write down or understand what is the maximum uncertainty that you have.

10:57.000 --> 11:03.000
It's just really counting the number of degrees of freedom that there are, and then taking the log of that, right?

11:03.000 --> 11:08.000
And then you ask yourself, well, how much entropy do I actually have?

11:08.000 --> 11:14.000
In other words, do I have a probability distribution that is different than the maximum entropy distribution?

11:14.000 --> 11:18.000
And if the answer is yes, then that means already you know something.

11:18.000 --> 11:23.000
That means that the actual distribution has a lower entropy, and then you have some information.

11:23.000 --> 11:27.000
However, you may not know at that point exactly what this information is about.

11:27.000 --> 11:28.000
Okay.

11:28.000 --> 11:31.000
In a gas, of course, very often you do.

11:31.000 --> 11:37.000
Just like you said, when you have a bunch of molecules in a corner, well, then you have information about where these molecules are.

11:37.000 --> 11:44.000
Of course, if you allow the molecules to disappear or to sort of like do their thing,

11:44.000 --> 11:48.000
what happens is that your knowledge about the positions of the molecules starts decreasing.

11:49.000 --> 11:54.000
And at the same time, of course, the actual entropy starts increasing.

11:54.000 --> 11:57.000
That is what we call the second law of thermodynamics.

11:57.000 --> 12:00.000
It's literally just the loss of information that you have.

12:00.000 --> 12:09.000
And of course, during that equilibration phase, the system is returning to its equilibrium, but it's actually at its equilibrium.

12:09.000 --> 12:16.000
So in other words, whenever you have information, it gives you a hint that the system is not at equilibrium.

12:16.000 --> 12:23.000
It is away from equilibrium, and the amount of information is in fact characterizing how far away from equilibrium you are.

12:23.000 --> 12:29.000
So when I'm speaking to you right now, you're actually in an ordered state, a very ordered state,

12:29.000 --> 12:31.000
as far as the molecules are concerned.

12:31.000 --> 12:35.000
And I can tell you in a sense how much ordered state there is.

12:35.000 --> 12:37.000
It's about half a million bits.

12:37.000 --> 12:38.000
Why?

12:38.000 --> 12:42.000
Because in fact, that is the amount of information that's actually stored in your genome.

12:42.000 --> 12:44.000
Ah, okay.

12:44.000 --> 12:49.000
This is probably going to be leaping ahead, but what about like the particular configuration of my body?

12:49.000 --> 12:52.000
Certainly that is more than half a million bits.

12:52.000 --> 13:02.000
Um, that's a good question, but since in fact that organization is done by the half a million bits,

13:02.000 --> 13:10.000
my suspicion is that in fact that must be the same, because how else would you achieve this ordered state?

13:10.000 --> 13:12.000
So this is actually an interesting question.

13:12.000 --> 13:19.000
If I just sit down and think a little bit, my intuition is that even though it seems that, you know,

13:19.000 --> 13:22.000
that would be more than half a million bits, that in fact it is not.

13:22.000 --> 13:26.000
However, it's such a good question that I cannot actually tell you right now why.

13:26.000 --> 13:29.000
Good final exam question for the next time you teach a course based on your book.

13:29.000 --> 13:30.000
Yeah, that's actually a good point.

13:30.000 --> 13:35.000
I mean, if I, you know, after this interview, I'll try to sit down and figure this out.

13:35.000 --> 13:36.000
Okay, that's a good one.

13:36.000 --> 13:40.000
And it's simply because the information cannot be anywhere else.

13:40.000 --> 13:46.000
The fact that you ordered, the only thing that makes that possible is the information in your genome.

13:46.000 --> 13:49.000
And as a consequence, in a sense, mathematically, it has to be like that,

13:49.000 --> 13:54.000
even though just like you said, that seems low.

13:54.000 --> 13:55.000
It does seem low.

13:55.000 --> 13:57.000
I like to think I can make more information than that.

13:57.000 --> 14:04.000
I mean, certainly in my brain, there are neurons with certain weights and things like that,

14:04.000 --> 14:07.000
and there's probably more than half a million bits there.

14:07.000 --> 14:08.000
Right, okay.

14:08.000 --> 14:10.000
Now, you're making another point.

14:10.000 --> 14:14.000
Of course, there's information that you have acquired during your lifetime that is not being counted.

14:14.000 --> 14:16.000
That is definitely there.

14:16.000 --> 14:17.000
Good.

14:17.000 --> 14:25.000
However, if you take, let's say a brain, before it learns something, let's say a baby brain,

14:25.000 --> 14:29.000
physically speaking, of course, there are differences.

14:29.000 --> 14:35.000
Yeah, but I mean, like the information is stored in the weights of the neurons in the brain in some way.

14:36.000 --> 14:41.000
So, definitely, that is in addition.

14:41.000 --> 14:44.000
However, that, of course, does not give you your physical appearance.

14:44.000 --> 14:48.000
It doesn't change the organization of the rest of your body.

14:48.000 --> 14:51.000
It's an interesting train of thought, but no doubt.

14:51.000 --> 14:54.000
Either a final exam question or a paper to be written here, I think, about this.

14:54.000 --> 14:55.000
How many bits am I?

14:55.000 --> 15:01.000
But okay, something very interesting and important happened just now in your discussion of information,

15:01.000 --> 15:08.000
because I think that if you asked people on the street, do you have information about where your car keys are?

15:08.000 --> 15:11.000
They would think about that as a yes-no question.

15:11.000 --> 15:13.000
I know where they are or I don't.

15:13.000 --> 15:18.000
And you've sneaked in the idea of a probability distribution, which is kind of central here.

15:18.000 --> 15:19.000
Right.

15:19.000 --> 15:21.000
So, how does that come in?

15:21.000 --> 15:24.000
How central is probability to information theory?

15:24.000 --> 15:28.000
Well, actually, it is the central aspect of it.

15:28.000 --> 15:37.000
So, before you can really understand information theory, you should have a very basic course in probability statistics.

15:37.000 --> 15:43.000
Now, to tell you the truth, not everybody who is working in the field did have that, and that shows.

15:43.000 --> 15:49.000
But simply because the concept of probability, actually, to fully understand it,

15:49.000 --> 15:54.000
is not as simple as just writing down, you know, p sub i or some distribution, you know.

15:54.000 --> 16:02.000
What a probability is, and I know you're familiar with this because you've thought about this in the context of quantum mechanics for a long time,

16:02.000 --> 16:06.000
is, you know, not immediately trivial.

16:06.000 --> 16:10.000
Some people think, oh, a probability exists by itself.

16:10.000 --> 16:20.000
Other people say, no, a probability is just simply something that you can estimate, but that itself, in a sense, really doesn't exist.

16:20.000 --> 16:26.000
But the idea of prediction, of course, is central to that.

16:26.000 --> 16:32.000
So, when you're asking yourself, can I predict with accuracy better than chance,

16:32.000 --> 16:38.000
then you have to, in a sense, have an idea of, well, what is the chance prediction here?

16:38.000 --> 16:44.000
And for that, in a sense, you need a prior, you need an assumption about what is expected.

16:44.000 --> 16:46.000
Right.

16:46.000 --> 16:57.000
And so, if you're going to talk about a probability distribution, then you're really talking about, what am I expecting?

16:57.000 --> 17:00.000
So, let's go to the example of the car keys.

17:00.000 --> 17:01.000
Right.

17:01.000 --> 17:07.000
So, generally speaking, we could say, okay, here's a person who's looking for their car keys.

17:07.000 --> 17:13.000
They know, with 90% of the chance, from past experience, right, we're setting up the priors now.

17:13.000 --> 17:16.000
From past experience, 90% of the time, it's in my pocket.

17:16.000 --> 17:17.000
Right.

17:17.000 --> 17:22.000
But if it's not in my pocket, it could be in 10 different places.

17:22.000 --> 17:23.000
Yeah.

17:23.000 --> 17:24.000
Right.

17:24.000 --> 17:28.000
If that is the case, you can set up, just set up the probability distribution for you,

17:28.000 --> 17:32.000
because that means that there are 11 possible places that the keys could be in.

17:32.000 --> 17:33.000
Right.

17:33.000 --> 17:38.000
And the chance to find it in your pocket is 10%, sorry, 90%.

17:38.000 --> 17:44.000
And then, in each of the 10 other places, the chance to find it is 1 out of 100.

17:44.000 --> 17:45.000
Right.

17:45.000 --> 17:46.000
Yeah.

17:46.000 --> 17:48.000
So, now, I've set the expectation.

17:48.000 --> 17:50.000
Before, I've done any experiment.

17:50.000 --> 17:51.000
Right.

17:51.000 --> 17:53.000
Now, I'm doing an experiment.

17:53.000 --> 17:55.000
And of course, what experiment are you going to be doing?

17:55.000 --> 17:57.000
You're going to check your pocket.

17:57.000 --> 17:58.000
First, yes.

17:58.000 --> 17:59.000
Right.

17:59.000 --> 18:05.000
And now, what happens is that this measurement is going to give you information.

18:05.000 --> 18:06.000
Right.

18:06.000 --> 18:12.000
And in fact, we call this, you know, this outcome of this measurement, it's called a

18:12.000 --> 18:13.000
specific information.

18:13.000 --> 18:14.000
Okay.

18:14.000 --> 18:19.000
It's a specific information, because I can do 11 measurements.

18:19.000 --> 18:26.000
And the average of the outcomes of that, that's actually the information gained from the measurement

18:26.000 --> 18:28.000
of the locations.

18:28.000 --> 18:36.680
The interesting thing here is that if I don't find the key in my pocket, then I have a problem.

18:36.680 --> 18:38.000
Now, it could be in 10 different places.

18:38.000 --> 18:42.400
So, it turns out that the specific information of this measurement, namely that the key is

18:42.400 --> 18:44.000
not in your pocket, is negative.

18:44.000 --> 18:45.000
Yeah.

18:45.000 --> 18:49.000
It's a negative specific information, even though the average information gained from

18:49.000 --> 18:52.760
the car key searching measurement is still positive.

18:52.760 --> 18:55.440
Because you're now less sure of where the keys are than you are before.

18:55.440 --> 18:56.440
Exactly.

18:56.440 --> 18:57.440
Exactly.

18:57.440 --> 19:00.000
And it's like, oh my God, it's like, I thought I knew.

19:00.000 --> 19:01.000
See, that's the thing.

19:01.000 --> 19:02.000
Yeah.

19:02.000 --> 19:03.600
I thought I knew means that's the priors.

19:03.600 --> 19:06.440
From the priors, you had a pretty good idea.

19:06.440 --> 19:10.960
Then you make your measurement and you go like, oh my God, now I don't know anything.

19:10.960 --> 19:15.960
And this is mathematically, in fact, it's an exercise in my book in chapter three.

19:15.960 --> 19:17.080
Very good.

19:17.080 --> 19:22.760
And let me just raise, again, I'm super on your side, but it's my job to, you know,

19:22.760 --> 19:25.600
play the devil's advocate sometimes.

19:25.600 --> 19:30.720
Don't worry about this way of thinking about information because it sounds a little subjective.

19:30.720 --> 19:32.040
It's not out there in the world.

19:32.040 --> 19:38.000
You're talking about information as an ability for some agent to make predictions, right?

19:38.000 --> 19:44.080
Is it truly objective or is it only relative to the capacities of some thinking being?

19:44.080 --> 19:48.320
So you're asking, of course, the most important question about information.

19:48.320 --> 19:51.640
And the answer is information is contextual always.

19:51.640 --> 19:53.120
It is never absolute.

19:53.120 --> 19:57.240
Now I'm going to give you a great example that will get you, you know, to think about

19:57.240 --> 19:58.240
this.

19:58.240 --> 20:04.880
Suppose you are a virus and you are, in fact, reaching a wreaking havoc inside of a patient,

20:04.880 --> 20:05.880
right?

20:05.880 --> 20:07.400
You are replicating fast.

20:07.400 --> 20:10.200
Everything is going good for you, right?

20:10.200 --> 20:14.680
Let's imagine your mutation rate is actually kind of low so you don't change much while.

20:14.680 --> 20:19.280
So the information that you have about doing your job is doing its job, right?

20:19.280 --> 20:23.840
Now the patient takes an antiviral, right?

20:23.840 --> 20:28.600
The patient takes an antiviral and suddenly this virus goes like, man, you know, this

20:28.600 --> 20:32.680
replicating thing is now really, really, really hard, right?

20:32.680 --> 20:38.080
And what you can now do is you can calculate the information about how to do this job and

20:38.080 --> 20:39.800
it has changed dramatically.

20:39.800 --> 20:47.040
In fact, now the virus does not have this amount of information about doing its job anymore.

20:47.400 --> 20:49.760
But the sequence is the same.

20:49.760 --> 20:52.640
How can a sequence is the same?

20:52.640 --> 20:56.680
Earlier I have lots of information and then have very little information.

20:56.680 --> 21:02.720
The answer is because the context changed because that what you have information about has changed.

21:02.720 --> 21:07.800
So what was the environment yesterday, isn't the environment today?

21:07.800 --> 21:12.760
You have information about yesterday's world, not about today's world.

21:12.760 --> 21:14.840
And that is the important thing.

21:14.840 --> 21:16.400
Information is completely contextual.

21:16.400 --> 21:21.840
The same sequence evaluated in different environments will have different information

21:21.840 --> 21:24.120
and therefore different meaning.

21:24.120 --> 21:27.120
A lot of times people think like, oh, information theory can't deal with meaning.

21:27.120 --> 21:28.680
It's absolutely untrue.

21:28.680 --> 21:35.440
My molecular sequence means something here on earth, actually, you know, above the surface

21:35.440 --> 21:37.000
of the water, for example.

21:37.000 --> 21:43.320
You put me underwater and my sequence is making wrong predictions, right?

21:43.840 --> 21:47.600
About how to breathe, no underwater, that thing doesn't work.

21:47.600 --> 21:49.320
Your fitness is zero.

21:49.320 --> 21:55.440
I will have zero offspring underwater unless I actually, you know, am in a submarine or

21:55.440 --> 21:59.560
something like that where I'm taking the environment with me, right?

21:59.560 --> 22:01.400
Then I could still have information.

22:01.400 --> 22:09.560
So very, you know, very nearly so in biology, information and fitness are exchangeable.

22:10.280 --> 22:14.960
You have high information about how to do something, how to survive in the environment

22:14.960 --> 22:16.880
means having high fitness.

22:16.880 --> 22:18.360
They are related.

22:18.360 --> 22:22.040
In fact, they are mathematically related and we don't have to talk about what that relationship

22:22.040 --> 22:24.280
is, but you can read about it in my book.

22:24.280 --> 22:29.120
So in other words, what happened in evolution is that fitness and information are essentially

22:29.120 --> 22:30.600
intertwined.

22:30.600 --> 22:32.880
They are almost the same thing.

22:32.880 --> 22:37.520
And so the way you are increasing your fitness is you're increasing the information about

22:37.520 --> 22:39.960
how to live in that environment.

22:39.960 --> 22:44.160
I guess I was trying to make a similar point to what you just said in my book, The Big

22:44.160 --> 22:45.160
Picture.

22:45.160 --> 22:48.320
I mentioned the Voynich manuscript, right?

22:48.320 --> 22:53.960
This wonderful old book full of symbols and nobody knows whether it's nonsense or whether

22:53.960 --> 22:54.960
it refers to something.

22:54.960 --> 23:00.720
And so I asked the question, how much information is there in the Voynich manuscript?

23:00.720 --> 23:02.680
How would you answer that question?

23:02.680 --> 23:07.480
The answer is unless we know what the information is about, this is entropy for us.

23:08.440 --> 23:14.560
So if you have text or any data, that is not information.

23:14.560 --> 23:21.760
In fact, it is literally just entropy in the sense that you are talking about, oh, it represents

23:21.760 --> 23:25.680
an example of another similar set of things.

23:25.680 --> 23:30.160
And so you're setting up your hypothetical ensemble so that you can talk about an entropy.

23:30.160 --> 23:36.640
The moment that you know what things you can predict with it, then it becomes information.

23:36.640 --> 23:41.960
If you do not know this, the same piece of information or the same text, should I say,

23:41.960 --> 23:46.160
the same symbolic sequence would just be entropy to you.

23:46.160 --> 23:50.400
In other words, just to repeat it, because information is that which allows you to make

23:50.400 --> 23:55.260
predictions about a particular system with accuracy better than chance.

23:55.260 --> 23:58.080
If you don't know what this is, it's not information.

23:58.080 --> 24:05.400
Another example is somebody hands you a subway chart, and he goes like, well, that's fantastic,

24:05.480 --> 24:07.640
except I don't know which city this is.

24:07.640 --> 24:09.200
Well then it's useless to you.

24:09.200 --> 24:13.320
And if it's useless, so in other words, useless information is entropy.

24:13.320 --> 24:14.320
Got it.

24:14.320 --> 24:19.160
The other idea at the technical level that I have found super important in my tiny little

24:19.160 --> 24:22.600
forays into information theory is mutual information.

24:22.600 --> 24:27.720
I love this concept, and it never gets explained in a popular level, so maybe you can give

24:27.720 --> 24:29.720
us a shot.

24:29.720 --> 24:30.720
Right.

24:30.720 --> 24:35.320
So first of all, information is really a mutual entropy.

24:35.320 --> 24:37.040
It's a shared entropy.

24:37.040 --> 24:43.880
So in other words, the reason why me, if I have information, can make predictions about

24:43.880 --> 24:48.440
another system is because, in a sense, we have certain correlations.

24:48.440 --> 24:54.640
We know something about each other, and so information, even though I showed you earlier

24:54.640 --> 24:58.360
that it's really a difference of entropy, you can also think of it as a shared entropy.

24:58.360 --> 25:03.200
The mathematics to show that this is one and the same thing, we're not going to go into.

25:03.560 --> 25:09.920
Just trust me here that if you think about a Venn diagram about a system and the one

25:09.920 --> 25:15.840
who's trying to measure the system, the intersection of that Venn diagram, that's the information

25:15.840 --> 25:20.760
that the measurement device has about the system.

25:20.760 --> 25:22.360
That's a shared entropy.

25:22.360 --> 25:24.360
That shared entropy is, of course, the information.

25:24.360 --> 25:31.000
So when people say mutual information, they're meaning mutual, mutual entropy.

25:31.320 --> 25:34.240
So in fact, nobody should be using that word.

25:34.240 --> 25:40.920
In my book, for example, when I have an index where it says mutual information, I say C

25:40.920 --> 25:41.920
information.

25:41.920 --> 25:42.920
Fair enough.

25:42.920 --> 25:50.040
But it's just that for the reason that we talked about earlier that people are using

25:50.040 --> 25:56.880
information and entropy synonymously, they have taken mutual entropy, which is an information,

25:56.880 --> 26:00.560
and called that mutual information.

26:01.120 --> 26:03.000
But in principle, they're one and the same thing.

26:03.000 --> 26:04.520
We just should call it information.

26:04.520 --> 26:08.400
It is that that correlates the two systems.

26:08.400 --> 26:12.720
Because remember, we always have to talk about two systems when we are talking about information.

26:12.720 --> 26:17.760
One that makes the prediction and one that is being predicted.

26:17.760 --> 26:21.880
And what is shared, the shared correlation between them.

26:21.880 --> 26:26.400
In other words, what's not random between them, that is information.

26:26.400 --> 26:27.400
Good.

26:27.400 --> 26:31.240
So now we have a pretty firm grounding on information theory.

26:31.240 --> 26:35.600
We can move on to applying it to biology, which is what your book is all about.

26:35.600 --> 26:38.520
But let me just first ask the background question.

26:38.520 --> 26:47.200
How popular in biology is this task of thinking about things in terms of information theory?

26:47.200 --> 26:50.360
Is it everyone does it or no one does it?

26:50.360 --> 26:54.240
Or it is the new hotness and it's sweeping the field?

26:54.240 --> 26:55.720
Let me put it this way.

26:55.720 --> 27:01.040
If this was something that everybody does, I wouldn't have had to write this book.

27:01.040 --> 27:06.920
This book really came out of a frustration that I have this tool.

27:06.920 --> 27:13.120
I see how valuable it is to understand essentially anything in biology and nobody is using it.

27:13.120 --> 27:14.560
When I say nobody, that's not quite true.

27:14.560 --> 27:17.240
There are a few people who do.

27:17.240 --> 27:22.000
Bill Bialek in Princeton, for example, has certainly done this and he does know how to

27:22.000 --> 27:23.880
do this.

27:23.880 --> 27:30.560
There's a few people often, in fact, in Bill Bialek's orbit who have looked at information

27:30.560 --> 27:37.080
transmission in cells, for example, in gene regulation and calculated the channel capacity

27:37.080 --> 27:41.120
of a cellular communication channel and did this very well.

27:41.120 --> 27:44.320
And I, in fact, have these examples in my book.

27:44.320 --> 27:48.600
But it is woefully underrepresented.

27:48.600 --> 27:55.440
There is something about information theory that presents a barrier, a hurdle in a sense

27:55.440 --> 27:58.440
to acceptance.

27:58.440 --> 28:03.240
I only have a vague memory of when I first learned about information theory, which was

28:03.240 --> 28:10.760
in fact at Caltech when a postdoc that was placed into my office actually first started

28:10.760 --> 28:14.840
explaining classical information theory to me because we were actually working in quantum

28:14.840 --> 28:15.840
information.

28:15.840 --> 28:19.060
And it was like, well, let's do the classical theory first.

28:19.060 --> 28:24.200
And I remember when he was first writing these formulas on the board, which has these vertical

28:24.200 --> 28:30.160
bars and these columns and semicolons, thinking, like, what is this?

28:30.160 --> 28:32.080
This is not my mathematics.

28:32.080 --> 28:38.120
My mathematics, there's integrals, there's differentials, you know, there are matrices.

28:38.120 --> 28:43.440
And now I'm seeing these weird symbols and my brain doesn't really understand them.

28:43.440 --> 28:48.720
In a sense, from the cognitive science perspective, is you don't have these representations that

28:48.720 --> 28:52.480
allow you to recognize these things and they have to build over time.

28:52.480 --> 28:58.320
And I think this barrier that I felt at the time and was like, oh, there's all these different

28:58.320 --> 29:03.320
entropies, there's a mutual, there's a shared, a conditional, and you were like, how am I

29:03.320 --> 29:05.200
going to keep them apart?

29:05.200 --> 29:09.200
And you have to get used to them just like you got used to integrals and differentials

29:09.200 --> 29:11.320
and things like that.

29:11.320 --> 29:17.560
If I ask anyone who had algebra and calculus, it's like, would you ever confound differentials

29:17.560 --> 29:18.560
with integrals?

29:18.560 --> 29:20.600
And it goes like, of course not, right?

29:20.600 --> 29:23.120
Yes, because you got used to this stuff, right?

29:23.120 --> 29:28.520
So there seems to be this barrier and in particular, very often information theory is perceived

29:28.520 --> 29:32.360
as being an engineering discipline, right?

29:32.360 --> 29:35.680
And they're going like, well, the engineers, you know, like, well, they want to do error-correcting

29:35.680 --> 29:38.240
codes and like, what does this have to do with biology?

29:38.600 --> 29:43.120
In fact, I've seen this in print saying like, you know, the engineering discipline of information

29:43.120 --> 29:47.360
theory has nothing to say about biology because these are very different things.

29:47.360 --> 29:51.160
It's like saying, well, information theory can't apply to physics when in fact we do

29:51.160 --> 29:52.720
know very well that it does.

29:52.720 --> 29:57.560
In fact, I just explained the second law of thermodynamics in terms of information theory.

29:57.560 --> 30:00.720
And so this barrier is very palpable.

30:00.720 --> 30:05.840
So if somebody is an established scientist and you tell them, well, you know what, you

30:05.840 --> 30:09.400
should really be using information theory, they're not going to do it.

30:09.400 --> 30:11.680
They're entrenched in their ways.

30:11.680 --> 30:20.840
And they usually are not receptive to learning in a sense a whole new bag of tricks, right?

30:20.840 --> 30:24.680
It is not that different from what happened in black hole physics where they constantly

30:24.680 --> 30:29.560
talk about information loss in black holes and not a single paper is trying to calculate

30:29.560 --> 30:32.920
the capacity of the black hole channel, except of course, me.

30:33.800 --> 30:40.000
That's because, you know, because I know information theory, but, you know, these people

30:40.000 --> 30:45.640
have been working in this area for 30 years and not picked up a single book or article

30:45.640 --> 30:47.040
on information theory.

30:47.040 --> 30:51.360
Again, there's this barrier, they're saying like, this concept is different from the concept

30:51.360 --> 30:52.360
I need.

30:52.360 --> 30:54.040
And the answer is no, it is the same concept.

30:54.040 --> 30:59.200
You know, I'm a little bit sympathetic because I know that when I read papers in economics,

30:59.200 --> 31:07.000
they have this habit of denoting variables in equations by words rather than by single

31:07.000 --> 31:08.000
letters.

31:08.000 --> 31:13.920
And it's so trivial and silly, but it truly rubs me the wrong way and I have trouble

31:13.920 --> 31:15.720
wrapping my brain around it.

31:15.720 --> 31:22.280
No, I fully agree with you because that is not how we write equations, right?

31:23.280 --> 31:30.040
You know, I still almost vividly remember this aversion where I'm like, this is not

31:30.040 --> 31:31.040
my thing, right?

31:31.040 --> 31:32.760
But you have to power through this, right?

31:32.760 --> 31:37.840
And in my lab, everybody gets, you know, the basic, you know, introduction to information

31:37.840 --> 31:38.840
theory.

31:38.840 --> 31:44.000
And then once you've sort of internalized it, you cannot see the world except through

31:44.000 --> 31:45.640
that lens of information theory.

31:45.640 --> 31:50.480
It's like the hammer that makes everything look like a nail, right?

31:50.480 --> 31:56.680
And in my book, in fact, I sort of co-op the famous saying which we all know in biology

31:56.680 --> 32:00.480
which says nothing in biology makes sense except in the light of evolution, which certainly

32:00.480 --> 32:01.480
is true.

32:01.480 --> 32:05.840
But I basically have changed it around to say nothing in biology makes sense except

32:05.840 --> 32:08.840
in the light of information.

32:08.840 --> 32:11.640
Then of course, information is that which evolves, really.

32:11.640 --> 32:16.480
I mean, people would say, well, organisms involve, no, what evolves actually is information.

32:16.480 --> 32:19.680
The information is what is essential in an organism.

32:19.680 --> 32:24.880
The organism itself isn't really that essential in the sense it's replaceable, right?

32:24.880 --> 32:29.880
If we have offspring, they carry most of the information with them.

32:29.880 --> 32:36.320
But only the encoded information, of course, what we think as specific to ourselves is

32:36.320 --> 32:40.080
of course the stuff in our brain that we have talked about about 25 minutes earlier.

32:40.080 --> 32:45.160
The information that we acquired over a lifetime is, of course, making us special, right?

32:45.160 --> 32:50.360
The information in your genome does not make you special, but it is what makes you alive.

32:50.360 --> 32:57.840
So is it fair to think of Charles Darwin as an early information theorist?

32:57.840 --> 33:07.640
Well, I would say no, simply because he didn't really, and he had no way of understanding

33:07.640 --> 33:15.440
that the basis of inheritance was really the replication of information.

33:15.440 --> 33:22.880
He didn't even know how any of the stuff was encoded because that was discovered in 1958.

33:22.880 --> 33:27.760
Or we should say that John von Neumann kind of figured it out a little bit earlier when

33:27.760 --> 33:36.680
he came up with this theory of self-replicating machines, which essentially could have told

33:36.680 --> 33:42.640
Watson and Crick where to look for stored information.

33:42.640 --> 33:48.480
So Darwin did not know that, but he had, via his sleuthing, in a sense, going on boats

33:48.480 --> 33:54.680
and looking at stuff, figured out, hey, there's variation going on, there's selection going

33:54.680 --> 33:56.800
on, and there's inheritance going on.

33:56.800 --> 34:02.920
The fact that these three things are properties of information, so inheritance being the replication

34:02.920 --> 34:08.640
of information, variance being the mutation of information, the changing of information,

34:08.640 --> 34:11.280
and selection is the meaning of information.

34:11.280 --> 34:16.640
In other words, those pieces of information that have a lot of information are fitter

34:16.640 --> 34:20.840
and therefore will have more offspring, and therefore, in fact, because I told you about

34:20.840 --> 34:26.920
the relationship between information and fitness, then the meaning of information is selection.

34:26.920 --> 34:33.160
So we can think of the entire evolutionary process in terms of what happens to information,

34:33.160 --> 34:35.520
and we should, in fact.

34:35.520 --> 34:40.240
But Darwin did not think that way, even though, of course, I haven't read all of his works,

34:40.240 --> 34:45.720
even though many of them are in my little natural history collection in my bookshelf,

34:45.720 --> 34:46.880
but they are big, big tomes.

34:46.880 --> 34:53.760
I mean, one of the things that is so astonishing to me is that Darwin had, in his head, essentially

34:53.760 --> 35:00.080
had 12 book treaties and then was forced to publish the abstract of it as the first book,

35:00.080 --> 35:06.200
which is now the origin of species, but he had so much more to say, and then over the

35:06.200 --> 35:10.280
rest of his life, in fact, said many of these things.

35:10.280 --> 35:16.000
And of course, most of those things, you know, like about worms and about plants and things

35:16.000 --> 35:17.000
like that.

35:17.000 --> 35:18.000
Barnacles.

35:18.000 --> 35:21.160
We don't usually read.

35:21.160 --> 35:29.240
But in there, if you study those volumes maybe with more attention to the concept of information,

35:29.240 --> 35:38.040
in the idea that what makes these plants how they are, in fact, is making predictions.

35:38.040 --> 35:41.080
But he's, in fact, a good example.

35:41.080 --> 35:48.240
Darwin himself, at some point, noticed a particular orchid which had a very, very long neck, you

35:48.240 --> 35:51.640
know, which he knew had to be pollinated, right?

35:51.640 --> 35:59.240
And it was about 30 centimeters over, you know, what is that, and it's about a foot,

35:59.240 --> 36:00.240
right?

36:00.240 --> 36:01.240
Yeah.

36:01.240 --> 36:03.800
Or even longer, in fact.

36:03.800 --> 36:06.520
But basically he said, now I will make a prediction.

36:06.520 --> 36:10.800
I will predict that there is a pollinated exists with a proboscis or a nose, you know,

36:10.800 --> 36:14.840
what they're using for, which is about that length, right?

36:14.840 --> 36:22.600
And even though he didn't live to see that prediction come true, in fact, his competitor

36:22.600 --> 36:27.880
in the evolutionary field that almost scooped him, he, in fact, basically said, oh, and

36:27.880 --> 36:30.840
I'm going to tell you that this must be a Sphinx moth.

36:30.840 --> 36:34.680
And in fact, they later found it after Darwin died.

36:34.680 --> 36:37.480
And that was exactly, you know, as he had predicted it.

36:37.480 --> 36:43.760
So to some extent, you know, he knew that evolution, this idea, the theory of evolution

36:43.760 --> 36:46.080
is a predictive theory, right?

36:46.080 --> 36:51.420
Even though he didn't think of it in terms of information, theoretical terms.

36:51.420 --> 36:56.600
So yeah, a typical evolutionary biologist would try to explain things in terms of there's

36:56.600 --> 37:01.800
a population with certain traits, and there's a fitness landscape, and they, you know, move

37:01.800 --> 37:03.840
towards peaks of the fitness landscape.

37:03.840 --> 37:08.280
And so you're not undermining that, you're just saying that a useful way of thinking

37:08.280 --> 37:13.360
about fitness is having the information to successfully predict what's going to happen

37:13.360 --> 37:15.960
in your environment, and therefore survive.

37:15.960 --> 37:16.960
That's right.

37:16.960 --> 37:19.120
I don't undermine any of the standard population genetics.

37:19.120 --> 37:25.440
It is really just a very different way of understanding what fitness is.

37:25.440 --> 37:31.280
You know, after all, fitness, the way, you know, it is not the same word as we talk about

37:31.280 --> 37:33.840
physical fitness, of course, right?

37:33.840 --> 37:38.280
Fitness in biology means fitting your environment well, right?

37:38.280 --> 37:43.200
It means being adapted to your environment, which means corresponding to, right?

37:43.200 --> 37:48.400
And see, we're seeing, aha, that means in a sense that your body structure, you know,

37:48.400 --> 37:51.840
is predictive about what world you live in, right?

37:51.840 --> 37:59.240
So for example, E. coli bacteria, they grow best at 37 degrees Celsius.

37:59.240 --> 38:01.200
Well, that's weird, isn't it?

38:01.200 --> 38:02.320
Well, no, it's not weird.

38:02.320 --> 38:04.800
That's the temperature of our stomach.

38:04.800 --> 38:10.200
So basically, their molecular biology makes a prediction about what environment they're

38:10.200 --> 38:12.680
in, namely one at 37 degrees Celsius.

38:12.680 --> 38:17.640
Their prediction is off, where that means, in fact, you know, they don't have as much

38:17.640 --> 38:21.840
information as they think, and they're actually not going to grow as fast, right?

38:21.840 --> 38:30.680
So this correlation between the genome and the environment gives you the fitness because

38:30.680 --> 38:36.280
it tells you, you're fitting this environment well, you're well adapted to it.

38:36.280 --> 38:39.800
And that concept information is precisely that, this correlation, right?

38:39.800 --> 38:44.440
And this is a very important point because it reminds us that just so people don't get

38:44.440 --> 38:48.560
the wrong idea, information isn't necessarily conscious, right?

38:48.560 --> 38:52.880
It's not something that you might say, you know, the information in your genome is very

38:52.880 --> 38:56.600
well adapted to your environment, even though you personally might have no idea with the

38:56.600 --> 39:00.680
arrangement of nucleotides in your DNA is.

39:00.680 --> 39:01.680
That's right.

39:01.680 --> 39:06.440
So obviously, you know, when we're talking about the fact that cells make predictions

39:06.440 --> 39:10.440
about their environment, which they do all the time because cells have to make decisions,

39:10.440 --> 39:12.440
it's not like they have a brain.

39:12.440 --> 39:16.880
But to some extent, we also know that because once you understand that information is just

39:16.880 --> 39:22.240
a correlation, which is a non-random correlation, because sometimes you get correlation by chance.

39:22.240 --> 39:27.160
But no, we're looking for correlations that are not by chance and that are on top of that

39:27.160 --> 39:29.200
being maintained, right?

39:29.200 --> 39:33.200
Because in thermodynamics, you might have correlations by chance, but they are going

39:33.200 --> 39:35.600
to disappear very soon, right?

39:35.600 --> 39:42.280
The genome is making sure that these correlations are being maintained so that we can continue

39:42.280 --> 39:46.960
using, you know, what we have to make predictions about the environment.

39:46.960 --> 39:53.080
If you would be loosening this continuous maintenance, then information would go away

39:53.080 --> 39:55.680
and we call that death.

39:55.680 --> 39:56.680
Is that what we call death?

39:56.680 --> 39:57.680
Good.

39:57.680 --> 39:58.680
Now that we know.

39:58.680 --> 40:04.160
But this does bring us to a very fun point you make in the book is that we can think of

40:04.160 --> 40:09.960
evolution as a kind of Maxwell's demon and maybe be fun to explain what Maxwell's demon

40:09.960 --> 40:13.680
is, not everyone knows, and what it has to do with evolution.

40:13.680 --> 40:14.680
Right.

40:14.680 --> 40:18.560
So that's a good point and thank you for leading me into that because it's one of my favorite

40:18.560 --> 40:21.160
parts of the book, actually.

40:21.160 --> 40:30.000
So Maxwell's demon, let's not talk about why this sort of devil was invented, but let's

40:30.000 --> 40:31.680
focus on what he does.

40:31.680 --> 40:39.120
So the Maxwell's demon basically is sitting at the intersection of two, let's say, boxes

40:39.120 --> 40:41.760
and there's a little window inside of the box.

40:41.760 --> 40:48.680
And now both boxes have gas in them, gas molecules who have different speeds, you know, by in

40:48.680 --> 40:53.160
fact described by the Maxwell distribution, right?

40:53.160 --> 40:58.800
Turns out that and now imagine that this demon who sits there, he operates sort of the door

40:58.800 --> 41:02.120
between the two, the two boxes.

41:02.120 --> 41:05.800
And he also has a measurement device that he uses in order to measure the speed of a

41:05.800 --> 41:12.040
molecule, for example, one that is about to go through the through the through the door.

41:12.040 --> 41:16.960
And then he goes like, OK, if this is a fast molecule, I'm going to let it go through.

41:16.960 --> 41:21.760
But if it's a slow molecule, I'm going to shut the door and so that it is in fact going

41:21.760 --> 41:23.000
to be reflected.

41:23.000 --> 41:29.160
If he does that a lot, he's going to have one half of the two boxes, I mean, or should

41:29.160 --> 41:33.120
say the left box as opposed to the right box, with lots of fast molecules.

41:33.120 --> 41:36.840
And the other one will be, you know, stuck with all the slow molecules.

41:36.840 --> 41:42.280
That is in violation, in apparent violation, I should say, of the second law of thermodynamics,

41:42.280 --> 41:48.280
which basically says no, that can't happen, namely the formation of a non-equilibrium

41:48.280 --> 41:50.200
situation from an equilibrium.

41:50.200 --> 41:58.080
So mathematically, it looks like what the demon has achieved is, in fact, creating order

41:58.080 --> 42:01.720
or violating the second law of thermodynamics.

42:01.720 --> 42:08.720
The fact that he didn't do such a thing was, in fact, proven mathematically and fully correctly

42:08.720 --> 42:19.880
a later by Rolf Landauer, a Rudolf Landauer, a German-American physicist.

42:19.960 --> 42:23.680
We're not going to go into how that proof goes, but it is not a violation of the second

42:23.680 --> 42:24.880
law of thermodynamics.

42:24.880 --> 42:31.880
But this idea that via measurement, you can actually reduce entropy is, of course, a

42:31.880 --> 42:35.880
very common one, because measurements give you information and information is sort of

42:35.880 --> 42:37.600
the opposite of entropy.

42:37.600 --> 42:43.280
So yeah, if you, for example, look into a room of molecules and then essentially measure

42:43.280 --> 42:47.200
the speed and position of all the molecules you're looking at, you could in principle

42:47.280 --> 42:52.200
achieve a lot of order because you could punch them, so to speak, with a laser and then all

42:52.200 --> 42:54.000
go into one corner.

42:54.000 --> 42:57.560
So in other words, measurements do allow you to decrease entropy.

42:57.560 --> 43:03.080
Now that we have described the Maxwell demon, now let's think about the Darwin demon.

43:03.080 --> 43:10.160
So in order to understand this, let's imagine that instead of these measurements that the

43:10.160 --> 43:17.080
demon does, we're basically doing, so the molecules are now mutations.

43:17.080 --> 43:19.200
So you have a genome and a mutation happens.

43:19.200 --> 43:21.920
The mutation happens is completely random.

43:21.920 --> 43:26.120
It could actually increase your fitness or it could decrease your fitness.

43:26.120 --> 43:32.440
And now the demon basically says, look, I'm actually closing the door and not allowing

43:32.440 --> 43:39.480
the decreasing fitness mutations to persist, but I'm going to keep those that actually

43:39.480 --> 43:42.520
are increasing my fitness.

43:42.520 --> 43:47.160
So in a sense, the organism now performs a measurement, but it turns out, of course,

43:47.160 --> 43:55.640
that the mechanism of evolution is precisely that way, namely the deleterious mutation

43:55.640 --> 44:01.720
will make it such that the organism carrying it doesn't have as many offspring.

44:01.720 --> 44:02.720
It's less fit.

44:02.720 --> 44:07.720
And as a consequence, its frequency in the population will go down, or else even if it's

44:07.720 --> 44:15.240
a lethal mutation will disappear, whereas the beneficial mutations will in fact be enhanced.

44:15.240 --> 44:21.860
So because the beneficial mutations create order, because there's now a type that increases

44:21.860 --> 44:28.600
in frequency, maybe even very fast at the detriment of all of the other sequences where

44:28.600 --> 44:31.440
that creates order in the population.

44:31.440 --> 44:36.440
And it's essentially because you learn something about the environment.

44:36.440 --> 44:41.480
You have extracted information about the environment by having this measurement of the environment.

44:41.480 --> 44:45.320
So in other words, these mutations that are being kept, they are measurements of the environment.

44:45.320 --> 44:48.280
It's like, ah, 37 degrees Celsius.

44:48.280 --> 44:54.920
Okay, so let's adjust our genome in such a way that we grow well at 37 degrees Celsius.

44:54.920 --> 45:00.200
Whereas the deleterious mutations, of course, are misinformation, and they reduce your

45:00.200 --> 45:03.560
fitness and as a consequence, they're thrown out of the window.

45:03.880 --> 45:07.960
That's the Maxwell-Diemann closing the door on them.

45:07.960 --> 45:14.200
And what that means is that, well, if this is a continuous process, then it should lead

45:14.200 --> 45:23.080
to a constant increase of information inside of an organism over time as evolution proceeds.

45:23.080 --> 45:29.360
And therefore, we can actually formulate this as a law, namely the law of increasing information

45:29.360 --> 45:36.480
in evolution that actually predicts that if you start out with a low information

45:37.040 --> 45:43.280
beginning sequence, that over time, the information must increase, but not all the time.

45:43.280 --> 45:46.960
For example, if the environment changes, well, we already discussed that,

45:46.960 --> 45:49.600
then your information drops, right?

45:49.600 --> 45:52.320
And you have to sort of relearn things, right?

45:52.960 --> 45:56.640
There are other ways in which information can get lost.

45:57.600 --> 46:02.400
For example, recombination can actually destroy information, right?

46:02.400 --> 46:04.160
It can also lead to a good thing.

46:04.160 --> 46:10.400
So this natural demon, this Darwin-Diemann, is not perfect in a sense.

46:10.400 --> 46:11.200
It's leaky.

46:11.200 --> 46:17.440
It sometimes makes wrong decisions where information can actually go down instead of up, right?

46:17.440 --> 46:23.200
But overall, on average, this theory of evolution predicts that the amount of information

46:23.920 --> 46:27.840
that is stored in a population of genomes has to be going up.

46:27.840 --> 46:33.360
And that is very interesting because we've been searching for a way to understand the

46:33.360 --> 46:39.280
bio-complexity that we are seeing around us and asking, how on earth is all of this possible?

46:39.280 --> 46:43.360
And can I understand if one organism is more complex than another?

46:43.360 --> 46:48.160
And this idea of complexity, of course, is difficult to put in mathematics.

46:48.160 --> 46:52.320
But in fact, it turns out that complexity is literally just information.

46:52.320 --> 46:56.960
In other words, complexity is just a proxy for information.

46:56.960 --> 46:57.520
Why?

46:57.520 --> 47:03.920
Complexity essentially is stuff that is complicated but helps you do something interesting, right?

47:03.920 --> 47:09.520
We don't associate complexity with something that is just structurally interesting,

47:09.520 --> 47:11.760
but actually doesn't do anything, right?

47:11.760 --> 47:17.040
What was called a spandrel by Gould and Lewinton in biology, right?

47:17.040 --> 47:18.560
Something that looks very complicated.

47:18.560 --> 47:21.920
Once we understand it, it's actually just, let's say an icicle.

47:22.160 --> 47:23.840
Oh, it's not really that complex.

47:23.840 --> 47:27.680
But there are really complex things, for example, our brains, right?

47:29.440 --> 47:35.520
But that is in fact reflected by the information necessary to make it, right?

47:35.520 --> 47:42.480
So it turns out, therefore, that information is really the correct way of measuring complexity.

47:42.480 --> 47:49.280
And therefore, the question of is complexity increasing in evolution is simply answered

47:49.280 --> 47:52.800
as a yes, as long as you understand that complexity is really information.

47:52.800 --> 47:57.360
And the natural demon is responsible for that law of increasing information.

47:57.920 --> 48:02.080
Good, because naively, we might look at an organism and try to figure out,

48:02.080 --> 48:03.440
oh, that looks complicated.

48:03.440 --> 48:04.560
That looks pretty simple.

48:05.200 --> 48:08.640
And we wonder why all this complexity has grown.

48:08.640 --> 48:13.200
But you're saying that that's just a pale reflection of what's really going on underneath the hood.

48:14.160 --> 48:14.880
That's right.

48:14.880 --> 48:18.160
But it's almost like saying, if I look at a sequence, right?

48:18.160 --> 48:23.280
Somebody's genome or some animal's genome or a bacterial genome, I can't immediately see,

48:23.280 --> 48:24.880
well, this is information.

48:24.880 --> 48:26.160
This is not information.

48:26.160 --> 48:27.120
Here's some information.

48:27.120 --> 48:29.840
Is it like, they look the same, right?

48:29.840 --> 48:32.880
So we need to figure out how they're making predictions.

48:32.880 --> 48:35.280
Or in other words, how are they functioning in the world?

48:35.280 --> 48:39.840
So if you have something that looks complex, then you have to ask yourself,

48:39.840 --> 48:45.440
let's observe this thing and see whether what looks such an intricate mechanism

48:45.440 --> 48:47.200
is in fact necessary for survival.

48:48.320 --> 48:55.280
Or whether it is just something that is a consequence of something else, right?

48:55.280 --> 48:59.760
We see sometimes like these complex display behaviors in animals.

48:59.760 --> 49:02.240
And they are obviously important in mating.

49:02.240 --> 49:06.080
And if you would remove them, in fact, your fitness drops to zero

49:06.080 --> 49:09.840
because you don't get to mate, zero offspring, zero fitness, right?

49:10.640 --> 49:12.640
But then there are other things that are in a sense just

49:13.360 --> 49:15.680
no, they're not important for the actual survival.

49:15.680 --> 49:18.880
You would take them away and it doesn't change the fitness.

49:18.880 --> 49:22.320
It's like saying, you're removing a section of the genomic code,

49:22.320 --> 49:25.520
but if that is not predictive evidence, if it does not carry any information,

49:25.520 --> 49:26.560
it is not important for fitness.

49:26.560 --> 49:27.840
You can take it away.

49:27.840 --> 49:31.760
And we don't, so to get, if I understood what you said correctly,

49:31.760 --> 49:36.560
we don't right now have a clear cut way of looking at a genome and saying,

49:36.560 --> 49:38.640
this part contains information, this part doesn't.

49:39.440 --> 49:45.520
We actually do, but only if we're looking at many of them, not a single one, right?

49:46.160 --> 49:53.680
If I have a hundred versions of a gene, there are regions in it

49:53.680 --> 49:55.520
that are unimportant for survival.

49:55.520 --> 49:59.200
If I then make an alignment of them, then I can recognize, oh, look,

49:59.200 --> 50:01.920
this changes all the time at this position.

50:01.920 --> 50:05.200
Clearly, that doesn't mean anything because you can just willy-nilly change it.

50:05.200 --> 50:07.520
But then you go like, oh, but look at this section.

50:07.600 --> 50:09.200
It's the same everywhere.

50:09.200 --> 50:10.880
The same for every organism.

50:10.880 --> 50:14.080
I bet you it is because when you change it, you die.

50:14.720 --> 50:16.880
And that's why I haven't seen it, right?

50:16.880 --> 50:19.440
If you would make it, it would simply die.

50:19.440 --> 50:21.760
And therefore, it doesn't enter your database.

50:21.760 --> 50:24.080
So you have to do these multiple sequence alignment,

50:24.080 --> 50:26.480
as they're called in bioinformatics.

50:26.480 --> 50:30.080
And when you're looking across column by column,

50:30.720 --> 50:35.040
and you see some columns being completely conserved by evolution,

50:35.840 --> 50:38.400
even though evolution constantly tries to change them, right?

50:38.400 --> 50:39.760
Because it's through the mutational process.

50:40.400 --> 50:43.680
And then you see columns which are willy-nilly.

50:43.680 --> 50:47.760
Like on the nucleotide level, you see A, Cs, Gs, and Ts with 25% frequency.

50:47.760 --> 50:50.800
And you go like clearly, not information, right?

50:50.800 --> 50:54.560
And so that is, in fact, the basis of the algorithm

50:54.560 --> 50:56.480
that I describe in the book that allows you to measure

50:56.480 --> 50:58.400
the amount of information in a sequence.

50:58.400 --> 51:01.760
But if you do not have a multiple sequence alignment,

51:01.760 --> 51:03.280
in other words, a bunch of examples,

51:03.840 --> 51:06.240
then you cannot understand what is information,

51:06.240 --> 51:07.440
because everything looks the same.

51:08.000 --> 51:09.600
And this reminds me that you, of course,

51:09.600 --> 51:12.400
have collaborated with your colleague Richard Lensky

51:12.400 --> 51:15.920
on his long-term, who is the boss of the was,

51:15.920 --> 51:17.600
of the long-term evolution experiments.

51:17.600 --> 51:19.200
You've actually seen data like this.

51:20.240 --> 51:20.720
That's right.

51:20.720 --> 51:22.480
In fact, we constantly see this.

51:22.480 --> 51:26.080
We see this more easily in digital life experiments

51:26.080 --> 51:28.480
where we have self-replicating computer programs

51:28.480 --> 51:30.160
that live inside of a computer,

51:30.160 --> 51:32.240
just like the one I'm staring at right now,

51:32.240 --> 51:33.840
and that you're staring at right now.

51:35.200 --> 51:37.040
And there, we can extract these sequences

51:37.040 --> 51:39.760
and we can look precisely where the information is.

51:39.760 --> 51:41.360
And in fact, we can measure the information

51:41.360 --> 51:45.200
and see as the fitness increases, the information increases.

51:45.200 --> 51:48.080
It's literally, if you would be taking the log of the fitness

51:48.800 --> 51:52.240
and superimpose it with the calculated information,

51:52.240 --> 51:54.320
they're almost on top of each other, right?

51:54.320 --> 51:55.920
Because it's the log fitness,

51:55.920 --> 51:57.840
which is basically the growth rate,

51:57.840 --> 52:00.240
which is, in a sense, mathematically equivalent

52:00.240 --> 52:00.880
to information.

52:00.880 --> 52:04.560
So if information is zero, your growth rate is zero, right?

52:05.680 --> 52:09.200
So my own biological knowledge is not very big,

52:09.200 --> 52:13.040
but I do recall understanding that the human genome

52:13.040 --> 52:18.320
is not the longest out there in the ecosystem, right?

52:18.320 --> 52:19.520
Is that something we understand?

52:19.520 --> 52:23.360
But, so you're addressing an important question.

52:24.080 --> 52:27.280
In the biological literature, it's called the C-value paradox.

52:27.280 --> 52:30.480
If you just look at the length of genomes,

52:30.480 --> 52:35.760
there is an amoeba out there, which has 200 times more DNA

52:35.760 --> 52:36.800
than we have.

52:36.800 --> 52:39.200
It's called amoeba dubia, actually.

52:39.200 --> 52:42.160
So it's almost like the W in a former president.

52:42.160 --> 52:42.720
Yeah.

52:42.720 --> 52:45.280
So, you know, you can think of that as you may.

52:46.400 --> 52:50.160
So clearly, genomic content isn't information, right?

52:50.960 --> 52:54.160
But if you would take the genome of, let's say,

52:54.160 --> 52:57.440
a thousand of these amoeba and then align it,

52:57.440 --> 52:59.120
then you would see that most of the stuff

52:59.120 --> 53:00.480
is completely meaningless.

53:00.480 --> 53:04.160
Or else, in fact, it might not be haploid.

53:04.160 --> 53:06.720
So in other words, you have 100 copies

53:06.720 --> 53:09.120
of the same small piece of information.

53:09.120 --> 53:10.960
And here's another thing that you need to understand

53:10.960 --> 53:12.240
about information.

53:12.240 --> 53:16.320
If I have one book that, let's say,

53:16.320 --> 53:18.560
is predictive about certain things,

53:18.560 --> 53:20.400
and then you have a copy of the book,

53:20.400 --> 53:22.560
that's not twice as much information.

53:22.560 --> 53:24.880
It is exactly one time as much information.

53:24.880 --> 53:28.160
So if you have 100 copies because you have 100 copies

53:28.160 --> 53:29.840
of your genome, like we, for example,

53:29.840 --> 53:31.840
have two copies, we are deployed.

53:31.840 --> 53:34.400
There's many other organisms, like in particular plants,

53:34.400 --> 53:36.160
which are teraploid, you know,

53:36.160 --> 53:38.080
they have 16 copies and so on.

53:38.080 --> 53:41.200
So this amoeba probably has over 100 copies

53:41.200 --> 53:42.240
of its own genome.

53:42.240 --> 53:45.120
So in other words, clearly, this amount of DNA

53:45.120 --> 53:47.760
you have divided by 100, that still wouldn't get us

53:47.760 --> 53:49.920
to the three billion that we have,

53:50.640 --> 53:54.080
three billion per chromosome, right?

53:54.080 --> 53:54.880
So, yeah.

53:54.880 --> 53:56.880
And it's not six billion, you know,

53:56.880 --> 53:58.400
it's six billion base pairs.

53:58.400 --> 54:02.640
But in fact, out of the three billion nucleotides,

54:02.640 --> 54:07.040
which in a sense give you a entropy or potential

54:07.040 --> 54:09.440
information of six billion bits,

54:10.880 --> 54:12.320
but it's potential information,

54:12.320 --> 54:14.400
which is the same thing as entropy, right?

54:17.040 --> 54:20.880
Only a small fraction of this actually encodes information.

54:20.880 --> 54:24.400
And from the encode project, it is probably about 8%.

54:25.360 --> 54:28.560
And that's how you're getting to that number of 500 million bits,

54:28.560 --> 54:35.520
which is about 8%, I think, of the 3.1 billion or so, right?

54:35.520 --> 54:39.280
And so there are some plant genomes that are enormous

54:39.280 --> 54:41.520
because of this, you know, explosion.

54:41.520 --> 54:43.760
But, you know, if you have several copies,

54:43.760 --> 54:45.360
and if you have in plants, for example,

54:45.360 --> 54:47.760
there's lots and lots of intergenic regions,

54:47.760 --> 54:49.520
which are meaningless.

54:49.520 --> 54:51.600
In other words, there's no information in there.

54:51.600 --> 54:53.840
Plants are sort of spectacular for that.

54:53.840 --> 54:56.880
They have far more intergenic stuff than humans, for example.

54:58.000 --> 55:00.960
Some of them have up to 70% intergenic stuff.

55:01.920 --> 55:05.200
And this intergenic stuff is probably also riddled with transposons.

55:05.200 --> 55:08.080
So literally, if you would be taking it out or mutating it,

55:08.080 --> 55:10.640
it would not change what the plant does at all.

55:10.640 --> 55:12.640
So there is no information encoded there.

55:12.640 --> 55:15.920
So if you really want to plot just information content,

55:16.960 --> 55:22.480
in fact, Eugene Coonan, who works at the NIH, he has done that.

55:22.480 --> 55:24.240
In fact, his plot is in my book.

55:24.240 --> 55:29.040
And you find out that, yeah, bacteria are sort of very low there.

55:29.040 --> 55:32.400
And humans, as far as we can measure,

55:32.400 --> 55:34.400
in fact, have the most information.

55:34.400 --> 55:37.280
Mammals generally, but humans the most.

55:37.920 --> 55:40.800
So this idea that humans are, in a sense,

55:40.800 --> 55:46.000
the apex of complexity that some people think is sort of very self-serving,

55:46.000 --> 55:48.000
that might not be wrong.

55:48.000 --> 55:51.200
Certainly, if you take a look at it through the lens of information theory.

55:51.760 --> 55:52.560
I believe that.

55:52.560 --> 55:54.560
Let me, that number went by pretty quickly.

55:54.560 --> 55:55.360
So I want to get it right.

55:55.360 --> 55:59.680
8% of the human genome is information theory?

55:59.680 --> 56:00.480
It's coding.

56:00.480 --> 56:01.040
Yeah.

56:01.040 --> 56:01.280
Okay.

56:01.280 --> 56:04.640
And the rest is intergenic stuff or repetitive stuff.

56:05.440 --> 56:07.120
In other words, it's uninformative.

56:07.120 --> 56:08.400
It seems a little inefficient.

56:08.400 --> 56:08.800
I don't know.

56:09.840 --> 56:13.040
Well, I mean, it's because there is so much, for example,

56:13.680 --> 56:18.960
if you have a gene, there are regions that are called introns,

56:19.920 --> 56:21.360
which just have junk in it.

56:21.360 --> 56:24.960
And they're being excised before the stuff is being translated into proteins.

56:26.000 --> 56:28.240
And so there's a vast amount of that.

56:28.240 --> 56:32.640
And then inside of chromosomes, there's vast regions of repetitive stuff.

56:33.360 --> 56:38.880
Some of it might even serve structural features so that molecules can attach to it.

56:38.880 --> 56:42.800
But it does not actually provide information about surviving.

56:43.200 --> 56:44.320
Right.

56:44.320 --> 56:48.880
So obviously, it is difficult to measure the information content

56:50.320 --> 56:55.760
because we would have to have thousands of human genomes that you can align.

56:55.760 --> 56:58.880
Now, we have, in fact, now thousands of human genomes,

56:58.880 --> 57:01.120
but nobody's actually tried to do that.

57:01.760 --> 57:11.920
And I should say that in order for a good ensemble to really be reflective of the information,

57:11.920 --> 57:14.640
we needed to have a good amount of variation.

57:14.640 --> 57:21.840
In other words, those nucleotides that are mutatable, they should have had a chance to mutate.

57:21.840 --> 57:26.080
But because we humans have a relatively common recent ancestor,

57:27.360 --> 57:31.440
there's a lot of conservation in the genome that is common through common descent.

57:32.000 --> 57:32.560
Right.

57:32.560 --> 57:37.520
And it looks like it might be information if I'm making such an alignment of a thousand genomes,

57:37.520 --> 57:39.280
but in fact, might not be.

57:39.280 --> 57:43.680
So one of the things you might want to do is you want to take a lot of African genomes

57:43.680 --> 57:47.200
for this alignment because there's much more variation in the African genomes

57:47.200 --> 57:51.040
because they have, in a sense, been evolving longer.

57:51.040 --> 57:53.120
And their common ancestor is much, much, much earlier,

57:53.760 --> 57:56.080
which is why there is so much more variation.

57:56.640 --> 57:56.800
Right.

57:56.800 --> 58:02.800
And that would be a much better estimate is if you take European genomes and make that alignment

58:02.800 --> 58:08.640
because really, we're looking at like a hundred thousand years of variation,

58:08.640 --> 58:14.320
which, given the population sizes, might not be enough to really reveal the information content.

58:14.320 --> 58:18.640
So if you have a population that has a fairly common recent ancestor,

58:18.640 --> 58:24.240
then even this alignment is not going to do a very good job of giving you the information.

58:24.240 --> 58:28.800
But very often in proteins, single proteins, for example, or viral proteins,

58:28.800 --> 58:32.720
which are evolving very quickly, you can actually measure this information.

58:32.720 --> 58:37.760
And I've done this, for example, for the HIV protease, which is a 99 amino acid sequence.

58:38.480 --> 58:43.680
And then C, for example, like the example with drugs that I gave you,

58:43.680 --> 58:48.960
but when you introduce anti-HIV drugs in the population, you see the information dropping

58:49.520 --> 58:50.320
very rapidly.

58:50.880 --> 58:58.240
And then because we have data over time, you can see how as the virus evolves drug resistance,

58:58.240 --> 59:02.400
it really learns about this new world that is being cast into.

59:02.400 --> 59:07.760
And you see the information over 10 years really approaching the pre-introduction levels.

59:09.120 --> 59:14.800
So for certain proteins and molecules, it's much easier to actually do this analysis

59:14.800 --> 59:18.960
and measuring information than, for example, to do it for a whole genome.

59:18.960 --> 59:26.400
In principle, it can be done, but ideally, you would do assays where you're trying to

59:26.400 --> 59:30.560
mutate every nucleotide and see how it reacts.

59:30.640 --> 59:32.160
And that's, of course, not feasible right now.

59:32.720 --> 59:34.320
And it would be unethical, by the way, also.

59:34.320 --> 59:37.680
By the way, yeah, that happens in other podcasts I do.

59:37.680 --> 59:39.040
It'd be fun to do certain experiments.

59:39.040 --> 59:40.080
You just can't really do it.

59:40.080 --> 59:45.040
But one way of saying what you just said a little while ago is that the human genome

59:45.040 --> 59:48.080
has not had time to equilibrate in some sense.

59:48.720 --> 59:50.320
That is exactly what I say, yeah.

59:50.320 --> 59:50.800
Good.

59:50.800 --> 59:54.000
So there's plenty of unexplored variation in it.

59:54.000 --> 59:58.880
Because I was going to ask, are there sections of the human genome or, for that matter,

59:58.880 --> 01:00:04.400
other advanced genomes where there is some continuity over time?

01:00:04.400 --> 01:00:10.560
So clearly, this section of the DNA is carrying information, but we don't know what it does.

01:00:11.920 --> 01:00:12.480
Absolutely.

01:00:13.840 --> 01:00:20.320
One of my favorite examples is that there are untranslated regions in the genome

01:00:20.880 --> 01:00:23.040
that seem to be completely conserved.

01:00:24.160 --> 01:00:27.600
And it goes like it's untranslated, which means no protein is being made.

01:00:28.320 --> 01:00:31.040
Well, an RNA is actually being made.

01:00:32.000 --> 01:00:35.440
So in fact, these are long stretches of RNA.

01:00:35.440 --> 01:00:38.880
And what they do is they can form molecules called ribozymes.

01:00:39.760 --> 01:00:43.360
And it is a fairly recent discovery that these, in fact, are actually very important

01:00:43.360 --> 01:00:45.040
in understanding brain function.

01:00:45.040 --> 01:00:47.680
So there are these long, non-coding RNAs.

01:00:49.120 --> 01:00:54.160
And remember, DNA has this neutrality in the third position of a codon.

01:00:54.160 --> 01:01:00.400
So for many of the amino acids, when you mutate the third codon, because every amino acid is

01:01:00.400 --> 01:01:03.360
encoded by a triplet, you can change it willy-nilly.

01:01:03.360 --> 01:01:04.800
It doesn't change the amino acid.

01:01:04.800 --> 01:01:06.800
So there should be neutrality in that position.

01:01:06.800 --> 01:01:09.280
And you see this throughout the genome.

01:01:09.920 --> 01:01:14.080
But then you have these non-coding regions where there's no neutrality whatsoever.

01:01:14.080 --> 01:01:21.600
Well, yes, because if you translate it into an RNA, the ribozyme, there is no codon translation.

01:01:21.600 --> 01:01:23.280
It's not made from amino acids.

01:01:23.280 --> 01:01:25.840
So in fact, every nucleotide is important.

01:01:25.840 --> 01:01:32.400
And that's how it comes that these vast, long, non-coding RNA regions are completely conserved,

01:01:32.400 --> 01:01:36.320
which means that they carry 100% information or close to that.

01:01:36.320 --> 01:01:38.160
They're not 100% conserved.

01:01:38.160 --> 01:01:44.400
But that's because sometimes in these ribozymes, because they're folding into structures,

01:01:44.400 --> 01:01:50.240
you can make a mutation on one nucleotide as long as you're making the complementary mutation

01:01:50.240 --> 01:01:51.600
at the corresponding one.

01:01:52.400 --> 01:01:56.880
But this is a fundamental discovery because it means that these ribozymes

01:01:56.880 --> 01:02:03.280
that are super important in the survival of the organism, and in fact may explain,

01:02:03.280 --> 01:02:10.080
so they did this study in brains of flies, that they are super important in controlling

01:02:10.080 --> 01:02:13.600
mating behavior of the fly, which was previously not understood.

01:02:14.400 --> 01:02:16.000
And you can't find a protein that does it.

01:02:16.000 --> 01:02:19.600
Well, it's because done by these RNA sequences.

01:02:19.600 --> 01:02:21.360
That's actually super interesting.

01:02:21.360 --> 01:02:23.680
And I'm pretty sure I didn't know this.

01:02:23.680 --> 01:02:30.160
So the central dogma in molecular biology is that the DNA contains information that gets

01:02:30.160 --> 01:02:35.120
transcribed into RNA that tells the ribosome, which proteins to make.

01:02:35.120 --> 01:02:38.000
And what you're saying is that that's not all the DNA does.

01:02:38.000 --> 01:02:41.760
There's a separate function where parts of it get transcribed into RNA,

01:02:41.760 --> 01:02:45.600
and then don't make proteins, they make ribozymes instead.

01:02:45.600 --> 01:02:47.120
And those also play a crucial role.

01:02:48.160 --> 01:02:49.040
That's absolutely right.

01:02:49.040 --> 01:02:52.400
So whenever you hear the word dogma, then you're always going like,

01:02:52.400 --> 01:02:54.720
well, okay, so I'm sure it's not really a dogma.

01:02:54.720 --> 01:02:56.640
So let's actually look for the violations of it.

01:02:56.640 --> 01:03:00.880
And that's always a fruitful avenue of investigation.

01:03:00.880 --> 01:03:10.720
So yeah, in fact, the role that RNAs play in the molecular biology of the cell

01:03:10.720 --> 01:03:12.080
cannot be underestimated.

01:03:12.080 --> 01:03:14.000
I mean, these are highly functional molecules.

01:03:14.480 --> 01:03:16.080
They modify DNA.

01:03:17.840 --> 01:03:21.440
If you didn't know that, there's a whole bunch of gene editing going on,

01:03:22.720 --> 01:03:26.240
certainly in single celled eukaryotes.

01:03:26.240 --> 01:03:29.600
And I talk a little bit about that in my book about the tropanosomes,

01:03:29.600 --> 01:03:36.640
a fantastic, absolutely stunning story of how these RNAs are ensuring, in a sense,

01:03:36.640 --> 01:03:41.280
the survival of genetic information that should have died 100 million years ago, in a sense.

01:03:42.000 --> 01:03:47.520
And so these molecules, they're also regulators.

01:03:47.520 --> 01:03:51.120
So the RNA molecules, the ribozymes, which are untranslated,

01:03:51.120 --> 01:03:54.960
are so functionally important that we cannot understand, really,

01:03:54.960 --> 01:03:58.320
the molecular biology of the cell without their action.

01:03:58.320 --> 01:03:59.040
Interesting.

01:03:59.040 --> 01:04:03.200
And that's actually a great segue into the sort of final topic that I wanted to hit here.

01:04:03.200 --> 01:04:07.120
It would be a shame if we didn't talk about the origin of life.

01:04:07.120 --> 01:04:11.040
And of course, you know that there's a lot of people who put RNA front and center

01:04:11.040 --> 01:04:15.200
in that story, but we don't know what the right story is for the origin of life.

01:04:15.200 --> 01:04:17.120
So how can information theory help us here?

01:04:18.160 --> 01:04:26.400
Right. So that's a great segue because, in fact, the current thinking is that

01:04:26.400 --> 01:04:32.080
prior to DNA, we know that DNA and proteins cannot have been at the very origin of life

01:04:32.080 --> 01:04:39.280
because you need proteins to, in a sense, understand how DNA is acting.

01:04:39.280 --> 01:04:42.400
And you cannot understand one without the other.

01:04:42.400 --> 01:04:48.240
So you cannot have this separation between storage material, which is DNA,

01:04:48.240 --> 01:04:53.360
and machine, which is the proteins, in the origin.

01:04:53.360 --> 01:04:57.760
Now, it turns out that RNAs, they can store information because really,

01:04:57.760 --> 01:05:02.240
the RNA nucleotides are cousins of DNA.

01:05:02.240 --> 01:05:06.800
They just basically have an oxygen compound more.

01:05:07.600 --> 01:05:13.760
That's why the RNAs are called ribonucleotides and the DNA is called deoxy, namely removed

01:05:15.120 --> 01:05:17.360
ribonucleotides with an oxygen removed.

01:05:18.640 --> 01:05:22.960
That difference is actually very important because it affects the stability of the molecule.

01:05:22.960 --> 01:05:26.640
And of course, if you're going to do information storage, you want to have a stable one,

01:05:26.640 --> 01:05:33.120
and that's the DNA. However, the RNA molecule, which it's almost like a DNA, but can actually

01:05:33.200 --> 01:05:37.520
conform in all kinds of different ways, they can play the role of a machine,

01:05:37.520 --> 01:05:39.680
the ribozymes that we just talked about.

01:05:39.680 --> 01:05:44.320
So according to the RNA world framework, you're going like,

01:05:44.320 --> 01:05:49.360
hey, how do you have something where information and machine is one and the same,

01:05:50.000 --> 01:05:52.640
and that would be the RNA world?

01:05:52.640 --> 01:05:59.760
So in other words, self-replicating RNA molecules, like where they store information

01:05:59.760 --> 01:06:04.480
and are folding into the machinery that replicates the information.

01:06:04.480 --> 01:06:09.760
We, as you correctly pointed out, we don't know if that is the ancestor,

01:06:09.760 --> 01:06:14.240
because the biochemists tell me that there are some fundamental problems

01:06:15.200 --> 01:06:18.320
of how this whole stuff could have worked out.

01:06:18.320 --> 01:06:21.520
And that's a problem in biochemistry, which I'd only likely touch upon in the book

01:06:22.320 --> 01:06:24.000
because I'm certainly not an expert on that.

01:06:25.200 --> 01:06:28.160
But the important thing to understand the origin of life

01:06:28.160 --> 01:06:30.320
is to first understand what life is.

01:06:31.040 --> 01:06:36.320
And what life is, is basically information, a string of information,

01:06:36.320 --> 01:06:41.760
or a string that contains information about how to make copies of that information.

01:06:44.720 --> 01:06:47.200
You might think, oh, but that's not so difficult.

01:06:47.200 --> 01:06:48.880
I make copies of information all the time.

01:06:48.880 --> 01:06:50.000
I have a copy machine.

01:06:50.000 --> 01:06:52.080
It's like, yes, but who built the copy machine?

01:06:53.280 --> 01:06:56.160
The copy machine isn't some random thing.

01:06:56.960 --> 01:07:02.240
If you just throw a bunch of piles of metal together,

01:07:02.240 --> 01:07:04.080
it's not going to form a copy machine.

01:07:04.080 --> 01:07:09.760
In fact, it takes an enormously complex set of instructions to make that copy machine.

01:07:09.760 --> 01:07:12.320
So yes, it makes copies, and it's great at doing that.

01:07:12.320 --> 01:07:17.360
And you could, in fact, make copies of the blueprint of a copy machine.

01:07:18.640 --> 01:07:24.400
But that copy machine isn't going to make the copy machine from that blueprint.

01:07:24.400 --> 01:07:27.520
It's not. It makes copies. That's it.

01:07:27.520 --> 01:07:34.640
But if you had a machine that is, in fact, built from information,

01:07:34.640 --> 01:07:38.960
and therefore then, once it's crumpled up, in a sense, into this ribosome,

01:07:38.960 --> 01:07:43.120
then makes copies of the actual information, well, that's life.

01:07:43.120 --> 01:07:45.200
So life is information that copies itself.

01:07:46.560 --> 01:07:50.560
But if you just have a little bit of information, it is not going to do that.

01:07:50.560 --> 01:07:55.120
Because, like I said, to create a machine that can make copies of information,

01:07:55.120 --> 01:07:58.880
you need a minimum amount. Five bits is not going to do it.

01:07:58.880 --> 01:08:00.400
Maybe 100 bits is not going to do it.

01:08:00.400 --> 01:08:04.480
In fact, we don't know what the smallest amount of information is

01:08:07.520 --> 01:08:09.200
that has a capacity to replicate.

01:08:09.200 --> 01:08:13.600
You know why? Because we also don't know what the environment is within which

01:08:14.480 --> 01:08:15.760
this replication happened.

01:08:15.760 --> 01:08:19.440
Because I told you that the information is really an information about the environment.

01:08:20.000 --> 01:08:25.760
A string of 100 bits, that's 100 potential information.

01:08:25.760 --> 01:08:28.880
But depending on the environment, it could be a lot and it could be a little.

01:08:30.080 --> 01:08:33.760
We don't know a whole lot about the very early Earth,

01:08:34.480 --> 01:08:36.560
but there could be very many different environments.

01:08:37.200 --> 01:08:41.840
But what we do know, and I can say that unequivocally, is that there is a minimum

01:08:41.840 --> 01:08:46.160
about information and that amount of information cannot be obtained by chance

01:08:47.120 --> 01:08:48.400
under no circumstance.

01:08:48.400 --> 01:08:49.200
Okay.

01:08:49.200 --> 01:08:53.360
Right? Well, I should say, mathematically speaking,

01:08:54.000 --> 01:09:02.880
if the likelihood of finding any of these molecules would be a chance.

01:09:03.840 --> 01:09:11.840
However, there are in fact mechanisms that could make an avenue where information can

01:09:11.920 --> 01:09:16.640
actually gradually accumulate without a Darwinian process.

01:09:16.640 --> 01:09:19.040
This is speculation, but think of it this way.

01:09:20.000 --> 01:09:24.320
We can imagine a process where a molecule that carries no information,

01:09:24.320 --> 01:09:31.040
but is in fact a sequence in some alphabet.

01:09:31.040 --> 01:09:32.960
Let's imagine even it to be an RNA.

01:09:33.600 --> 01:09:37.440
We can imagine that there is a process by which it can be replicated,

01:09:37.520 --> 01:09:42.240
but in a sense passively.

01:09:42.960 --> 01:09:46.000
For example, it could be laying on a clay surface,

01:09:46.720 --> 01:09:50.800
and then you can basically have a process that will make sure

01:09:50.800 --> 01:09:53.920
that only complementary bases are being added.

01:09:54.720 --> 01:09:58.720
Then basically it becomes copied, but there's no information in it.

01:09:58.720 --> 01:10:02.880
So this copying of information or of a sequence, you're copying entropy really.

01:10:03.840 --> 01:10:07.920
But now, because the copying machinery is actually in the hardware,

01:10:07.920 --> 01:10:14.080
not in the software, it's this clay and it's the process of complementation.

01:10:15.120 --> 01:10:26.000
Now imagine that if in fact the rate of making errors in the complementarity

01:10:26.960 --> 01:10:28.320
can sort of vary.

01:10:28.320 --> 01:10:34.560
So it turns out that the speed of this operation of copying varies

01:10:34.560 --> 01:10:39.520
depending on how many errors you are making in that complementarity.

01:10:39.520 --> 01:10:43.040
So if for some reason you have something that makes this faster,

01:10:43.920 --> 01:10:47.120
well that's actually a good thing and you're going to make more of these copies,

01:10:47.120 --> 01:10:48.800
even though you might think there's no information.

01:10:48.800 --> 01:10:55.120
But now imagine that what makes this faster, which means makes it more accurate,

01:10:55.200 --> 01:11:01.360
because you have the same thing, is actually something that is part of that information,

01:11:01.360 --> 01:11:03.040
that sort of helps and binds.

01:11:03.040 --> 01:11:06.080
Like something breaks off and then sort of goes like,

01:11:06.080 --> 01:11:14.720
hey, I'm using that broken-off piece to actually make that process more error-free

01:11:14.720 --> 01:11:16.160
and therefore faster.

01:11:16.160 --> 01:11:20.720
What just happened then is that information just seeped into the genome,

01:11:20.720 --> 01:11:24.880
because remember that piece that broke off is actually one of your own.

01:11:24.960 --> 01:11:27.040
And you can imagine, but so a process like that,

01:11:27.040 --> 01:11:31.040
that slowly but surely information about how to do the replication

01:11:31.040 --> 01:11:33.600
moves from the hardware into the software.

01:11:33.600 --> 01:11:37.440
It's a non-equilibrium process, but it is at least imaginable,

01:11:38.480 --> 01:11:43.600
because you have to reach this limit until there's enough information in the sequence

01:11:43.600 --> 01:11:47.520
that it autonomously replicates without the support of the hardware.

01:11:48.160 --> 01:11:51.840
That is my sort of imaginary view of the origin of life,

01:11:51.840 --> 01:11:54.960
but it is a hard thing because you have to reach this limit.

01:11:54.960 --> 01:11:56.640
Let's say the limit is 200 bits.

01:11:58.000 --> 01:12:00.640
Only after 200 bits can evolution take hold,

01:12:00.640 --> 01:12:04.800
which then means I can have the evolutionary process increase this amount of information

01:12:06.560 --> 01:12:09.840
to infinity, theoretically.

01:12:11.120 --> 01:12:14.240
But before you have achieved Darwinian evolution,

01:12:14.240 --> 01:12:17.680
any information that is in the sequence is now highly fragile.

01:12:17.680 --> 01:12:24.160
It is basically prone to deteriorating due to the second law of thermodynamics.

01:12:24.800 --> 01:12:29.920
So you basically have to have a process where you are constantly working against this law,

01:12:30.560 --> 01:12:36.720
but it is because information from the replicative machinery,

01:12:36.720 --> 01:12:39.600
that the hardware is seeping into your sequence.

01:12:39.600 --> 01:12:44.320
And if this happens fast enough, you might actually get to this point

01:12:44.320 --> 01:12:48.080
where Darwinian evolution can take place, and therefore,

01:12:48.080 --> 01:12:50.880
you separated yourself from the second law of thermodynamics.

01:12:50.880 --> 01:12:52.960
Okay, good. I actually think I understand that.

01:12:52.960 --> 01:12:56.160
Let me try to run it by you again and see if I got the right idea.

01:12:57.360 --> 01:13:02.640
We talked about Maxwell's demon and evolution, and that was pretty clear to me.

01:13:02.640 --> 01:13:07.680
If you just had a set of genomes and you just acted randomly on them,

01:13:07.680 --> 01:13:10.640
they would randomly walk through the space of all possible genomes,

01:13:10.640 --> 01:13:13.680
and the entropy of that distribution would go up.

01:13:13.680 --> 01:13:15.680
That's the second law of thermodynamics.

01:13:15.680 --> 01:13:20.400
But you're saying that selection kicks in in the case of evolution,

01:13:20.400 --> 01:13:23.920
and that basically acts like Maxwell's demon to lower the entropy

01:13:23.920 --> 01:13:28.560
by sort of nudging all of the genomes towards areas of higher fitness.

01:13:28.560 --> 01:13:30.880
And that's pretty darn efficient.

01:13:30.880 --> 01:13:36.880
And you're suggesting that maybe the origin of life was a similar mechanism,

01:13:36.960 --> 01:13:41.120
not quite the same and not quite as efficient, but something that was a little Maxwell's

01:13:41.120 --> 01:13:47.200
demon to allow the distribution to become lower entropy until Darwin could kick in.

01:13:48.560 --> 01:13:50.000
That's exactly right.

01:13:51.600 --> 01:13:57.040
If you think about this idea that if you're making fewer mistakes in the copying process,

01:13:57.040 --> 01:14:02.240
that the copying goes faster and you're therefore making more copies,

01:14:02.240 --> 01:14:05.840
that means that there is a Darwin-y mechanism at work,

01:14:05.920 --> 01:14:08.160
even though there is no self-replication.

01:14:08.160 --> 01:14:13.920
But there is replication, but it is replication of non-informative things,

01:14:13.920 --> 01:14:17.440
which by this mechanism, well, some of the stuff by chance

01:14:17.440 --> 01:14:21.760
happens to increase your speed of replication, well, those are being maintained.

01:14:22.960 --> 01:14:26.960
And that's this idea, well, yes, the information about to replicate

01:14:26.960 --> 01:14:31.440
is in the hardware, not in the software, but it slowly starts seeping in.

01:14:31.440 --> 01:14:34.800
Slowly or fast, it really depends on the environment that you're in.

01:14:35.680 --> 01:14:38.720
And of course, we have no glimpse of any of that.

01:14:38.720 --> 01:14:42.960
Because if you imagine that, you know, let's say it's actually a process that

01:14:42.960 --> 01:14:49.760
isn't that difficult to achieve, well, wherever it constantly keeps occurring,

01:14:49.760 --> 01:14:52.400
it would be dwarfed by any form of life that is actually there,

01:14:52.400 --> 01:14:54.400
that has perfected this for four billion years.

01:14:55.280 --> 01:14:59.840
So there are these dark smokers and like these underground,

01:15:00.080 --> 01:15:03.040
what are they called?

01:15:04.480 --> 01:15:09.200
This pure hydrogen, basically, these underground volcanoes almost.

01:15:09.840 --> 01:15:12.800
And there is all kinds of interesting bacterial life going on,

01:15:12.800 --> 01:15:14.800
and who knows what else goes on there.

01:15:14.800 --> 01:15:20.080
There are some theorists that claim that, yes, these type of environments

01:15:20.080 --> 01:15:21.760
are perfect for the origin of life.

01:15:22.400 --> 01:15:24.880
But even if it would be constantly reoccurring there,

01:15:24.880 --> 01:15:27.600
we wouldn't see it because bacteria have already colonized them.

01:15:28.160 --> 01:15:29.120
Okay, that is great.

01:15:29.120 --> 01:15:31.440
That's a very interesting set of ideas.

01:15:31.440 --> 01:15:33.520
I hope that it's followed up on.

01:15:34.800 --> 01:15:38.000
But we're near the end of the podcast, so we are allowed to think big now.

01:15:38.000 --> 01:15:42.480
And it does lead into, I guess, the last question, which is,

01:15:43.600 --> 01:15:48.320
human beings have developed capacities for manipulating information

01:15:48.320 --> 01:15:51.600
that didn't exist before human beings came along, right?

01:15:51.600 --> 01:15:53.440
We can not only think, but we can learn.

01:15:53.440 --> 01:15:56.080
We can teach in ways that other species don't.

01:15:56.080 --> 01:16:00.480
We can store information and replicate it in books and on computers and so forth.

01:16:01.200 --> 01:16:04.960
Is this analogous to the origin of life?

01:16:04.960 --> 01:16:09.680
Is this another way that information is reproducing itself?

01:16:09.680 --> 01:16:13.840
Are we seeing a phase transition to a new kind of information phase?

01:16:15.600 --> 01:16:16.880
I think you're right about that.

01:16:16.880 --> 01:16:24.080
I mean, just imagine the advance of being able to write down what you have learned

01:16:24.160 --> 01:16:27.520
so that other people can build upon that.

01:16:27.520 --> 01:16:30.320
That obviously, in a sense, I'm saying obviously,

01:16:30.320 --> 01:16:32.640
but maybe that's not obvious to everyone.

01:16:32.640 --> 01:16:38.320
But obviously, that is the magic power that we have acquired as a human species

01:16:38.320 --> 01:16:40.640
that no other species has.

01:16:40.640 --> 01:16:46.960
The best that other species can do is to somehow teach young generations

01:16:46.960 --> 01:16:49.120
about certain behaviors, hunting behaviors,

01:16:49.120 --> 01:16:53.680
or maybe even tricks that you can use with rocks and sticks and things like that.

01:16:53.680 --> 01:16:58.160
But to actually figure out mathematics and write it down into a book

01:16:58.160 --> 01:17:02.240
and then teach that to other people so that they can, for example,

01:17:02.240 --> 01:17:06.640
predict the orbit of a planet 100 million years from now.

01:17:07.280 --> 01:17:11.360
I mean, if that is not mind-boggling, then I don't know what.

01:17:11.360 --> 01:17:17.040
Now, if you think about it, what we call our ability

01:17:17.040 --> 01:17:21.280
to make predictions over long distances as far as humans are concerned,

01:17:21.280 --> 01:17:23.440
in a sense, we call that intelligence, right?

01:17:23.440 --> 01:17:29.440
We're making intelligent decisions so that we, in a sense, can survive better, right?

01:17:29.440 --> 01:17:34.240
But in fact, clearly, making predictions about what the environment is tomorrow

01:17:34.240 --> 01:17:37.280
is going to be an important element in my survival.

01:17:37.280 --> 01:17:41.040
It was an important element for survival for any hunting species that goes like,

01:17:41.040 --> 01:17:46.240
oh, I predict that this prey is going to be at this location in about 10 seconds.

01:17:46.240 --> 01:17:50.240
And if I can make that prediction very accurate, I will catch that prey, right?

01:17:50.240 --> 01:17:55.040
Now, if you think about intelligence as the temporal radius

01:17:55.040 --> 01:17:58.560
at which you can make predictions with accuracy better than chance,

01:17:58.560 --> 01:18:01.840
well, then you realize, well, bacteria make predictions all the time,

01:18:01.840 --> 01:18:04.480
but they make predictions about the next second, right?

01:18:04.480 --> 01:18:07.120
Because they're making predictions about where the nutrient is,

01:18:07.120 --> 01:18:09.840
but that could change very quickly.

01:18:09.840 --> 01:18:17.120
But for example, this behavior of finding food, chemotaxis,

01:18:17.120 --> 01:18:20.400
well, that's clearly, in a sense, an intelligent behavior in the sense

01:18:20.400 --> 01:18:25.200
that it makes certain predictions that are going to come true or not within a second or so.

01:18:26.240 --> 01:18:32.480
But other animals, for example, let's say chipmunks, they make predictions about,

01:18:32.480 --> 01:18:36.400
well, the next season will be such that there will be winter,

01:18:36.400 --> 01:18:39.280
so I may have to actually store some food, right?

01:18:39.280 --> 01:18:42.080
But we as humans, by having developed writing systems,

01:18:42.080 --> 01:18:46.000
by having developed mathematics, can now make predictions in time

01:18:46.000 --> 01:18:50.000
over a far, far longer period that are accurate better than chance.

01:18:50.000 --> 01:18:52.720
The fact that we are talking about global warming

01:18:52.720 --> 01:18:59.040
and how that could affect us as a species is an obvious intelligent concept

01:18:59.040 --> 01:19:03.440
because we have understood that if we don't do anything,

01:19:03.440 --> 01:19:05.600
then we might be in big, big trouble, right?

01:19:05.600 --> 01:19:09.280
That is making predictions in a time scale far removed

01:19:09.280 --> 01:19:12.560
of our day-to-day activity, right?

01:19:13.520 --> 01:19:17.360
And our brain does that, but our brain, of course, has been doing this

01:19:17.360 --> 01:19:20.640
before we had figured out writing systems, right?

01:19:20.640 --> 01:19:25.840
But now the conjunction of our brain, where information during a lifetime is stored,

01:19:25.840 --> 01:19:28.480
and then we can make it permanent in books,

01:19:28.480 --> 01:19:33.200
that is the real secret sauce to the success of this species, as far as I'm concerned.

01:19:33.200 --> 01:19:38.320
Well, we'll see whether or not we have the collective strength of will

01:19:38.320 --> 01:19:41.280
to actually act on these predictions that we're making or not.

01:19:41.280 --> 01:19:43.760
Yeah, that's right. Of course, that's the big political question.

01:19:43.760 --> 01:19:46.800
Unfortunately, it is a political one and not a mathematical one.

01:19:46.800 --> 01:19:48.800
The mathematical one is very obvious.

01:19:48.800 --> 01:19:51.360
Good. That helps us a little bit.

01:19:51.360 --> 01:19:54.160
Chris and Tommy, thanks so much for being on the Mindscape Podcast.

01:19:54.160 --> 01:19:56.240
It was really my pleasure. Thank you, Sean.

