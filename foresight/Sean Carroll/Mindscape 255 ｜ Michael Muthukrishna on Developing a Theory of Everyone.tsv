start	end	text
0	4000	Hello, everyone. Welcome to the Mindscape Podcast. I'm your host, Sean Carroll.
4000	10000	Probably everyone listening has heard the phrase, a theory of everything, right?
10000	13000	The origins of this phrase are actually a little bit murky.
13000	18000	You know, it's not such a weird collection of words that it hadn't appeared in the literature a long time ago.
18000	22000	You know, people have talked about the idea of a theory of everything.
22000	33000	But the context in which we currently usually talk about it is either super string theory in physics or some other competitor to super string theory.
33000	39000	As far as I can tell, that coinage came from John Ellis, who is a theorist at CERN.
39000	48000	He wrote a little article in the early days of the super string revolution, 1980s, called the super string, a theory of everything or of nothing.
48000	55000	So it wasn't completely triumphant, right? He was actually talking about whether or not this possibly could be a theory of everything.
55000	63000	It was immediately pointed out by non-physicists and even some physicists that the idea of a theory of everything in this sense
63000	70000	is actually very, very restricted to a certain reductionistic way of looking at the fundamental constituents of nature,
70000	75000	the idea being that nevertheless those fundamental constituents make up everything else.
75000	82000	But there's no sense in which that idea of a theory of everything would be the final theory that we ever need in science, right?
82000	90000	Because we do have higher level emergent things. We have biological organisms, we have economies and societies,
90000	100000	and we have people in psychology, all this stuff, right, that is certainly not covered, not to mention easy questions about astrophysics or chemistry or so forth.
100000	106000	So the root from that kind of theory of everything to many other scientific questions is a complicated one.
106000	113000	Therefore, we still have room for other theories of large grandiose scope.
113000	120000	And today's guest is Michael Muthukrishna, who has a book coming out called A Theory of Every One.
120000	124000	That's intentional play on words from the theory of everything idea.
124000	131000	The subtitle is The New Science of Who We Are, How We Got Here and Where We're Going.
131000	136000	Obviously, kind of an ambitious book trying to synthesize many kinds of ideas.
136000	139000	Michael is at the London School of Economics.
139000	145000	He's sort of, I think his official title is a Professor of Economic Psychology.
145000	147000	So there's both economics in there and psychology.
147000	154000	He's actually collaborated with some of our previous Minescape guests, Joe Henrich and Edward Slingerland.
154000	166000	So he thinks about the grand scope of human history and how we are influenced by biology and evolution, cultural evolution,
166000	170000	how we pass down ideas from generation to generation.
170000	178000	And a big thing, as he'll say in the episode, a big thing for him is the fact that human beings, unlike other animals,
178000	184000	do have this sort of distributed cultural knowledge that we can pass down.
184000	189000	Human beings have schools, right? Have an educational system in a way that other animals don't.
189000	192000	Other animals do teach their young. Some of them do.
193000	203000	I don't know. Lions, I'm told, teach their cubs to hunt by pretending to be in pain when their cubs bite them a little bit.
203000	206000	So they're teaching them, like, oh, yes, that's the right thing you should do.
206000	208000	But they don't have a curriculum. They don't have a syllabus.
208000	212000	They don't have it quite as organized and systematized as human beings do.
212000	218000	So that plays a large role in the exceptionalism of human beings.
218000	223000	And of course, it's tied to other capacities, our brains, our languages, things like that.
223000	224000	So we'll talk about all of that.
224000	226000	But then Michael wants to go much further.
226000	231000	He talks about not only economics, but the technological side of economics,
231000	240000	the importance of different ways we have of harnessing energy from, you know, just burning wood to burning fossil fuels to solar energy
240000	249000	and how these allow for expansions of the economy and therefore of human opportunity in a very clear way.
249000	256000	And then he brings it back or brings it down, I should say, to the current era, our political polarization,
256000	263000	our stagnation of innovation, if that's true, and what we can do about it, how we can do better.
263000	268000	There are parts of this long, elaborate story that I am 100% on board with.
268000	273000	Other parts that I will wait to see, let's put it that way, not 100%, but I'm open to it.
273000	275000	I think it's fascinating stuff.
275000	279000	And Michael is very clear and very well educated on a whole bunch of things.
279000	281000	So I think it's a very good listen.
281000	284000	With that in mind, let's go.
293000	303000	Michael Muthukrishna, welcome to the Mindscape podcast.
303000	305000	Thanks for having me, Sean.
305000	311000	So you've written what sounds to the average reader of titles like an ambitious book.
311000	313000	It's called A Theory of Everyone.
313000	316000	And I like that you're kind of making fun of the physicists there.
316000	319000	It is, you know, it's a modest title.
319000	321000	It could have been a theory of everything, right?
321000	323000	Yeah, exactly. Just people.
323000	326000	Yeah, no, it's a play on a theory of everything, of course.
326000	333000	But I mean, the title hints at the central claim of the book, which is that, you know, we are...
333000	337000	So I'm sure your listeners know already, but, you know, the theory of everything in physics
337000	343000	is this grand, unifying theory, you know, general relativity meets quantum mechanics, whatever.
343000	350000	The idea or the central premise of the book is that we have reached this point in the human and social sciences
350000	354000	where we have this overarching theoretical framework that unifies things
354000	359000	that make sense of an otherwise chaotic and confusing world and turns it into a real science.
359000	364000	And so, you know, I tell the story of how this happened in the more mature sciences
364000	368000	to illustrate how this has happened for the human and social sciences.
368000	372000	So, you know, like in physics, right?
372000	375000	We used to think that Thor was banging his hammer
375000	378000	and the physical world was the result of capricious gods.
378000	383000	And then, you know, folks like Newton and Maxwell and Einstein come along and they write down equations.
383000	387000	I mean, Maxwell is crazy, right? At the time of like whale oil and horse-drawn carriages,
387000	389000	he's writing down equations for like a magnet.
389000	391000	It is. It's amazing, yeah.
391000	394000	But suddenly, like the world is less chaotic and confusing.
394000	396000	We know, like the weather is still difficult to predict, actually,
396000	399000	but we know that it's not caused by capricious gods.
399000	402000	It's caused by these rules. We have the rules.
402000	405000	And once we have those, we can also turn them into technologies, right?
405000	409000	Like we can eventually land, you know, a spacecraft on an asteroid.
409000	412000	And the same thing happened to chemistry.
412000	417000	Now, Newton's not a dumb guy, as we just said, but he's trying to turn lead into gold.
417000	419000	And again, it's not because he's a dumb guy.
419000	422000	It's because he doesn't understand like collusion theory.
422000	426000	He doesn't know the world is made up of elements that fit into a periodic table.
426000	432000	But once you have a periodic table, you know, then alchemy becomes chemistry.
432000	435000	So you can do stuff before you have a periodic table.
435000	437000	Like we got to gunpowder, for example.
437000	441000	But, you know, why is it that when you pour this acid on a metal,
441000	443000	you're creating this gas and it's bubbling away?
443000	444000	Like what's happening there, right?
444000	446000	And can we turn lead into gold?
446000	448000	Maybe it seems like another chemical reaction.
448000	450000	But once you have a periodic table, you can be like,
450000	452000	yes, we can make gunpowder and it's like,
452000	454000	okay, yes, we know what's going on here.
454000	456000	But no, we can't learn to turn lead into gold.
456000	457000	Those are different elements.
457000	459000	The world is less chaotic and confusing.
459000	463000	And eventually you make your way not only to chemistry,
463000	466000	like, you know, turning oil into plastics or whatever,
466000	469000	but even, you know, eventually to things like protein folding.
469000	472000	And of course, this happened in biology too, right?
472000	476000	So it was a chaotic and confusing world.
476000	479000	Why do some animals have live words and others lay eggs
479000	481000	and why does the peacock have this giant elaborate tail
481000	483000	and the peahen doesn't?
483000	487000	And then along comes Darwin and later on the modern synthesis
487000	490000	with, you know, Fisher and Wright and Hamilton and so on.
490000	493000	And suddenly the world is less chaotic and confusing.
493000	496000	It's still difficult to predict the trajectory of species
496000	498000	or the behavior of ecologies.
498000	500000	But if you're trying to do that without the rules
500000	502000	that underlie the system, you're running blind.
502000	503000	Right.
503000	505000	So yeah, in other words, what I hear is that
505000	509000	this underlying theoretical perspective on what's going on
509000	512000	can be helpful at a higher practical level.
512000	515000	And let me guess, you want to extend this to human beings.
515000	516000	Exactly.
516000	518000	I mean, the claim I make is not that, like,
518000	520000	I have extended to human beings.
520000	522000	But actually we are in the midst of a revolution
522000	525000	on the scale of Newton and Maxwell and Einstein
525000	527000	and the scale of the periodic table
527000	529000	and the scale of Darwin and the modern synthesis.
529000	531000	That is, we know the rules.
531000	534000	We know why humans are different to other animals.
534000	536000	We know the rules by which humans acquire
536000	538000	and synthesize information.
538000	541000	We know the rules by which societies are changing over time.
541000	544000	And that should allow us to build the equivalent of technologies,
544000	546000	a better job of public policy, for example,
546000	548000	by applying that.
548000	550000	So part one of the book is kind of laying out
550000	552000	that theory of everyone, that theory of human behavior.
552000	554000	And then part two is like, okay, well,
554000	556000	take me at face value and assume that I'm correct
556000	558000	about what I'm saying.
558000	562000	Here's what this means about inequality and innovation
562000	564000	and how we design the internet and, you know,
564000	566000	what the future of education should look like
566000	570000	and how we get past energy transitions and so on.
570000	572000	And how many pages is this book, like 5,000?
572000	574000	I was like 480 pages or something.
574000	576000	You know, I mean, I lean heavily.
576000	578000	It is a book for the public.
578000	580000	So what I try to stay away from, like,
580000	582000	you'll read some behavior books and it's like,
582000	584000	in this study we showed XYZ.
584000	586000	I mean, the studies are there.
586000	588000	But what I'm really trying to say is like,
588000	590000	there is a tapestry.
590000	592000	There's a world that everything is connected up.
592000	594000	It's like once I explain the periodic table to you,
594000	596000	everything makes a lot more sense.
596000	598000	And so I rely heavily on like, let me explain it to you
598000	600000	so you can check it against your own life.
600000	603000	It's that allow you to see the world as you never saw before.
603000	605000	And once you see it, you can't unsee it.
605000	608000	So maybe a good starting point then is the classic question
608000	611000	of what makes human beings so special?
611000	616000	What makes us different than the rest of our animal cousins
616000	619000	even though we're actually very similar at the DNA level, right?
619000	620000	Yeah.
620000	623000	So what humans are a different kind of animal
623000	625000	that have a third line of information
625000	627000	or a second line of inheritance.
627000	629000	And this is really fundamentally what allowed us
629000	631000	to build the world that we have today.
631000	635000	So we not only have a genetic inheritance like hardware
635000	638000	that we get from our parents, right?
638000	641000	And we not only have kind of a lifetime of experience
641000	644000	where we learn things, but we have cultural software
644000	647000	that has accumulated over time
647000	649000	and is literally running on our brains
649000	651000	allowing us to think new thoughts,
651000	653000	see the world in richer new ways
653000	656000	and understand the world as no other species ever has.
656000	659000	And that cultural line isn't just learned.
659000	661000	It is evolving.
661000	664000	It's not an analogy to genetic evolution.
664000	667000	It is an extension of population genetics
667000	668000	into the world of culture.
668000	670000	We call this cultural evolution.
670000	673000	And it's evolving beyond conscious awareness.
673000	676000	So we have a set of behaviors and values
676000	680000	and sometimes technologies that are not only...
680000	682000	The world is not only more complicated
682000	685000	than the smartest among us could ever recreate,
685000	688000	but often we don't really understand why it is
688000	689000	that we do the things we do,
689000	690000	certainly at an individual level
690000	692000	and sometimes at a population level.
692000	694000	Like you probably brush your teeth twice a day
694000	696000	and if I ask you why,
696000	698000	you'll tell me something about plaque and tartar
698000	699000	or something like that,
699000	701000	but you don't really have a good causal model of that.
701000	704000	Or you probably finish your course of antibiotics, right?
704000	706000	To avoid superbugs.
706000	709000	And you probably have a causal explanation for that.
709000	711000	But you have an illusion of explanatory depth
711000	713000	that stops you from checking further.
713000	715000	I'm going to say to you, it's like obviously Sean,
715000	717000	like not every one of those bacteria are going to die.
717000	719000	And so surely if not all of them die,
719000	721000	surely finishing your course of antibiotics
721000	724000	would have the most resistant bacteria left.
724000	726000	That's what would create superbugs.
726000	728000	And now you're like, oh, wait a minute.
728000	730000	You know, but you don't have to worry
730000	732000	about kind of antibiotic kill curves
732000	735000	or, you know, the optimal dosage or anything like that.
735000	738000	You have just acquired the interfaces
738000	739000	to interact with the world.
739000	742000	You check your emails on a device that may as well be magic.
742000	745000	So the book is about how we evolved to have that.
745000	749000	How it is that we became a different kind of animal.
749000	751000	How that connects everything up.
751000	754000	And what that means about how we should study ourselves
754000	756000	and think about our future, right?
756000	758000	Like if you want to understand the secrets of pivot tables
758000	761000	in Excel, if you want to understand how chatGPT works,
761000	763000	you don't look inside the CPU and GPU.
763000	764000	It's not in the brain.
764000	765000	It's not in the neuroscience actually.
765000	767000	It's in the software that's running on that hardware.
767000	769000	So the difference in other words,
769000	771000	obviously other kinds of animals and so forth
771000	776000	do have behaviors that are passed down from generations,
776000	778000	but they're not through learning, right?
778000	781000	I mean, are there, it's always a worry
781000	784000	when you talk about vast generalizations to other species
784000	787000	that there's going to be counter examples.
787000	790000	Are there any counter examples of, you know,
790000	792000	things that are not genetically encoded,
792000	795000	but our knowledge that other animal species
795000	797000	passed down from generation to generation?
797000	798000	Yeah.
798000	800000	So this area is called dual inheritance theory
800000	802000	or gene culture co-evolution
802000	804000	or the extended evolutionary synthesis.
804000	806000	And particularly the extended evolutionary synthesis
806000	809000	does, it is about like these other transmission,
809000	811000	like so environments are transmitted, right?
811000	814000	An earthworm can inherit the environment created,
814000	817000	that more moist environment created by its ancestors.
817000	820000	There's also information being transmitted,
820000	823000	just not to the degree that humans do, right?
823000	825000	So like chimps, for example, learn from their mothers
825000	827000	and they have traditions of, you know,
827000	830000	wadding up leaves into sponges and sponging up water
830000	833000	or using sticks for digging termites or whatever.
833000	834000	And those do seem to be trying,
834000	836000	or cracking nuts is another example of this.
836000	838000	They're entering the stone age, if you like.
838000	840000	They do have that, but humans,
840000	842000	for reasons I explained in the book,
842000	844000	and maybe I can say a little bit about that now,
844000	847000	rely on that social information
847000	851000	and agree to use that information if you like.
851000	853000	We use that information at the expense
853000	855000	of our own everyday experience.
855000	857000	And chimps do not do that.
857000	859000	Like, let me give you an example.
859000	861000	You're the worst person to give this example to,
861000	862000	but I'm going to give it to you anyway.
862000	864000	You'll see in a moment why that is.
864000	866000	Like, if I ask the average person, right?
866000	868000	Or the average person will swear up and down
868000	871000	that we are on a spheroid rotating around a star,
871000	873000	one of many stars in the Milky Way,
873000	875000	you know, one of many galaxies in the universe.
875000	877000	They will swear that up and down.
877000	879000	And every day they look outside at a flat earth
879000	882000	with a sun tracing the sky from east to west, right?
882000	883000	Now you might be, you know,
883000	886000	you're among a handful of people who checked, right?
886000	888000	But for most people, they don't.
888000	891000	They just believe it because the smartest people
891000	894000	in their society, most people in their society,
894000	896000	they believe that, right?
896000	899000	For the longest time,
899000	902000	UFOs were like in the realm of the flat earth, right?
902000	904000	And maybe they still should be, but at the moment,
904000	907000	because like the reliable sources are talking about
907000	910000	what are they called now, UAPs or whatever, and aliens.
910000	912000	Now people are like, wait, is that actually a thing?
912000	915000	Like, should I be reconsidering my model of the world?
915000	918000	We should go back to the previous consensus understanding,
918000	919000	I think there.
919000	922000	But this is interesting because you're saying two things,
922000	926000	one of which I was expecting and one of which is a little bit,
926000	929000	I've heard it before, but it's unexpected in this context.
929000	932000	The expected thing is, you know, we not only have knowledge,
932000	935000	we have some kind of symbolic knowledge, right?
935000	937000	So, you know, we can package the knowledge
937000	940000	and spread it more efficiently between ourselves.
940000	943000	And that's obviously some kind of phased transition
943000	945000	in human behavior that we can talk about.
945000	947000	But you're putting more emphasis than I would have guessed
947000	951000	on our limitations, you know, which I think are very important.
951000	953000	But it's interesting to hear in this context, you know,
953000	957000	we're finite, we don't have infinite ability to do our own research
957000	959000	in the current parlance.
959000	963000	So we kind of have to rely on our social networks a bit.
963000	964000	That's right.
964000	966000	And so it's actually because of those limitations
966000	969000	that we ended up with this cultural evolutionary system.
969000	972000	It's because of those limitations that we deferred the calculation,
972000	976000	the computation, the innovation to the population level.
976000	981000	So because we couldn't, you know, we couldn't fit all of that in our heads,
981000	987000	we ended up like selectively learning and copying without really understanding
987000	989000	that we were able to surpass it.
989000	991000	So I'll give you, there's an experiment I talk about in the book
991000	992000	that really illustrates this,
992000	994000	what humans do compared to other great apes.
994000	998000	So this was an experiment done with young children and young chimps, right?
998000	1001000	And so the experimenter has a box, and the box has a hole on the top
1001000	1003000	and the hole on the side, right?
1003000	1004000	And the experimenter takes the stick
1004000	1007000	and pokes it through the hole in the top and pokes it through the hole on the side.
1007000	1010000	And when they do this they poke it through the hole in the side,
1010000	1013000	they, they get a piece of fruit, which the chimps love.
1013000	1015000	And they get a sticker, which the kids love.
1015000	1018000	So the experimenter pokes a hole through the top, pokes a hole through the side,
1018000	1019000	you know, hands it to the chimp.
1019000	1020000	What does the chimp do?
1020000	1022000	Pokes a hole through the top, pokes a hole through the side.
1022000	1024000	All right, experimenter pokes a hole through the top,
1024000	1026000	pokes a hole through the side, hands it to the child.
1026000	1027000	What does the child do?
1027000	1029160	Pokes a hole through the top, pokes a hole through the side.
1029160	1034440	Okay. Now in the key variation in the treatment, you have the same box, but it's no longer
1034440	1037240	a black box. It's transparent. You can see into it.
1037240	1037720	Okay.
1037720	1042040	And you realize that that first action doesn't do anything. There's actually like a ceiling
1042040	1046600	or a floor, you know, where it's just hitting that. It's to retrieve the fruit and the stick,
1046600	1047960	or you just need the second action.
1048520	1048920	Okay.
1048920	1052760	But again, the experiment to take the stick pokes a hole through the top, pokes a hole through
1052760	1055960	the side, hands it to the chimp. Now, if you've ever watched like a chimp, you know,
1055960	1059000	doing a working memory task or spinning through Instagram, chips are smart, man.
1059000	1059400	Very good.
1059400	1059720	Yeah.
1059720	1063560	And so what do they do? Ignore that first action. Go straight to the second action
1063560	1065880	and they retrieve their fruit and they're a happy chimp.
1067000	1069800	What does the child do? Experiment to pokes a hole through the top, pokes a hole through
1069800	1072520	the side, hands to the child. What does the child do? Pokes a hole through the top,
1072520	1073480	pokes a hole through the side.
1074200	1078840	So children, you have a head full of recipes that you don't fully understand.
1078840	1079240	Interesting.
1080280	1084840	That you've accumulated and you acquire from the smartest people since you were a child around
1084840	1089240	you. Some of those you've checked, many of those you haven't and if your life is going well,
1089240	1092440	you've never had a need to check some of the beliefs that you hold and the behaviors you
1092440	1099560	engage in. But because we're smart because we're dumb, we're smart because we ate better than
1099560	1104760	apes do. And because we're willing to defer to that body of information culture,
1105800	1109720	we don't sit naked in the rain like they do. They want to figure everything out from first
1109720	1114440	principles. They want to understand it before they do it. And so they're stuck. They're stuck
1114520	1116200	at a particular limit by their brains.
1116200	1120280	That's a wonderful example. I love that experiment because the cynic might have said,
1120280	1124440	see the children, human children, not as smart as the chimps because they can't figure it out.
1124440	1130600	But your spin on it is whether or not they're smarter, they're relying on a whole thing that
1130600	1135240	the chimps don't have access to, this sort of collective knowledge that gets us through the
1135880	1137480	complicated social environment we're in.
1138040	1143240	That's right. But you see that collective knowledge isn't just about behaviors and
1143240	1148680	beliefs. It's also about mental tools, like literal upgrades to our cultural software for
1148680	1153720	thinking. And we know some of this through history, thanks to history, which is the cultural
1153720	1158760	fossil record if you like. So if you take something like numeracy, some small-scale
1158760	1164280	societies still count one, two, three, and then many. And our ancestors probably counted like that
1164280	1172760	too. We were able to get further using a metaphor. So many societies would use stones, think calcium,
1172760	1178840	calculus, maybe stones pressed into clay. So you've got notches as well or cut into wood.
1178840	1183880	Many societies use body parts. So we have a decimal system, which is super annoying,
1183880	1187800	to be honest. It doesn't translate well to binary. It's the worst of all systems.
1188920	1192920	And other societies use phalanges. So they count 12 with their thumb, the finger bones,
1193560	1197000	and various other body parts. I wish we'd landed on 16, but here we are.
1197880	1204040	And so as a result of this, we now had a metaphor for thinking that we no longer had to use. We
1204040	1207880	could just store it in our heads, represent it in our heads. And now we could count the natural
1207880	1214360	numbers above one. But stones and fingers and whatever, they don't make zero obvious,
1215000	1221480	because zero stones is nothing. And nothing is, well, it's nothing. And so it took centuries
1221480	1226680	before zero was recognized as a number. And centuries, it was actually the 17th, 18th century,
1226680	1232120	the negative numbers became more obvious. And again, it became, it was an upgrade thanks to a,
1232120	1237240	the number line. So we moved away from objects to position, right? And, you know, there's this
1237240	1241560	quote I have in the book from a British mathematician Francis Mezry, and he's something like, you
1241560	1246280	know, negative numbers darken the very fabric of reality. It's like way melodramatic, right? And
1246280	1249640	he's right. But once you have a number line, it's simple enough that you can teach it to young
1249640	1253480	children, which is what we do. Yeah. But it's given us a new ability, because obviously, once you
1253480	1258920	can count, you can count to do anything. And then the number line itself gets extended, right? So
1258920	1263560	it's like, what if you have another number line that is, you know, orthogonal to the other one,
1263560	1270520	it's like, Oh, a complex plane emerges, right? And so you don't, you don't, you can't see this,
1270520	1275000	because we live in a bubble, a very big bubble. So I don't mean like you and I, you know,
1275640	1279720	in our ivory towers, you know, I don't mean like coastal elites and rural small town. I mean,
1279720	1285000	we're all every person we ever meet went through education through school. And school has become
1285000	1288840	since the Industrial Revolution, the primary means by which we download a cultural package to the
1288840	1293400	next generation. Because we are a species that relies on socially transmitted information,
1293400	1297160	you have every child has to catch up on the last several thousand years of human history. And we
1297160	1301560	try to do it more efficiently, because if we lose that link, we literally become dumber. We
1301640	1306360	literally lose, lose a bunch of technology, right? We have to transmit that every generation.
1306360	1309880	But as a result of that, many of the things that we think of as being human
1311000	1316360	are in fact endowed by us by accumulated cultural knowledge, and you can't get it by measuring it.
1316360	1319400	So the Stroop test, I don't know if you've ever seen the Stroop test, basically,
1319400	1323560	you've got words, the color words, and they're written in the color, like red written in red,
1323560	1325640	blue written in blue. Oh yeah, I do know what you're talking about, but go ahead. Or,
1325720	1332520	mismatched, right? And you ask people, don't say, don't read the word, just say the color. So,
1332520	1338360	you know, even though it says red, it's written in blue, so say blue. And people struggle. Reading
1338360	1342840	has become an instinct that overrides color perception. Now imagine, you know, a psychologist
1342840	1347080	from Venus, you know, like the anthropologist from Mars. A psychologist from Venus comes down
1347080	1350840	and studies these crazy apes on, you know, on the planet, and they give them the Stroop test,
1350840	1355880	and they're like, oh, it appears that humans have an innate ability to read, but no innate
1355880	1360440	ability or it overrides any kind of color perception, which would be wrong, of course, right?
1360440	1366280	But because these culturally endowed skills have become part of our thinking, and they're
1366280	1371560	ubiquitous at this point, you can't measure it. You know, all of experimental psychology, all of,
1372440	1378200	even IQ tests were developed after the advent of truancy laws and compulsory formal education.
1379080	1382600	So, even something like the ability to reason. So, I talk about some of my own work, right?
1383320	1387640	So, Alexander Luria, we were replicating some of his work. So, Luria goes out to Uzbekistan. He
1387640	1392440	wants to understand how education is changing people's psychology. And he uses if p, then Q
1392440	1397640	reasoning, okay? So, this is actually one of his questions. He says, where it snows, the bears are
1397640	1402360	white. In Novia's Emilia, it snows, what color are the bears? Now, you didn't say it, but you're
1402360	1408840	thinking white. You know, like Uzbeks with education, white. My six-year-old, white, you know?
1409800	1414440	But what happens to the Uzbeks who didn't have education? How do they answer? They're like,
1414440	1419160	I think probably brown. I've seen a brown bear. You're like, what? Listen to what I'm saying.
1419160	1423000	And you're like, well, I don't know what color the bears are. I haven't been to Novia's Emilia.
1423000	1427240	So, it's not that humans can't reason. Of course we can, right? But it's a grounded,
1427240	1433640	cultural reality-based reasoning. And it becomes an ability and a hypothetical ability to reason
1433640	1440280	through our education system. And then the whole world becomes more complex, right? Like, a new
1440280	1447720	baseline is achieved. So, if you think about TV shows, right? Like, think of like Wambam Batman
1447720	1453480	for the 1960s, where it is like the dark night from the early Nazis, right? Like, even the most
1453480	1458920	low-brow television has more convoluted storylines, more characters than, you know, what our parents
1458920	1464760	and grandparents watched, right? So, that is the central premise. And so, the book is all about,
1464760	1468920	well, how does that software get written? And how do we write better software for the future?
1468920	1473720	Because although IQ test results have been going up, they have now stagnated and so have our schools.
1473720	1478200	Let me ask the sort of chicken and egg problem here, because when we talk about human exceptionalism,
1478200	1482760	there's a whole bunch of things that happen and maybe they're all related. There was some kind
1482760	1488200	of phase transition, right? Like, some people will emphasize language and symbolic manipulation
1488200	1494920	of information. Some people, I had Adam Bulley on the podcast, who is part of a group that likes
1494920	1500200	mental time travel, the ability to hypothesize the future and speak counterfactually as something
1500200	1505240	that is uniquely human. And you're, you know, like other people, emphasizing this communal aspect,
1505240	1512440	the sort of offloading certain cognitive tasks to the collective. Which came first? Is there
1512440	1516520	some causality there or is it a package deal? Absolutely. So, actually, the book is about,
1516520	1521000	it tackles this very problem. So, you know, people who, people who posit things like,
1521000	1524680	so I know Adam, you know, and I know the language people, I'm not sure who you spoke to, but
1525240	1531640	people who posit language as an explanation are wrong because language is part of the
1531640	1537640	package of humans. It doesn't explain anything because, you know, in evolutionary biology,
1537640	1541800	you have a startup problem, right? So, let's say I'm the first person with like some genes for
1541880	1547240	language. Well, that's useless because nobody else speaks, you know? So, like, you've got a,
1547240	1552120	you've got a startup problem. And language only works if you've got something worth transmitting.
1553240	1557480	So, so language isn't an explanation. And a lot of the other features of our,
1557480	1561720	of our cognition are also this part of this package. So, you know, the story, the,
1562600	1565880	here's what, here's what a mix of kind of the models and evidence and what you can kind of piece
1565880	1572200	together tells us, okay? So, the first thing that happened was that there was a transition
1572200	1575720	across the animal kingdom, but certainly for humans because of our generation length,
1575720	1580600	toward relying on social information. And it is, it is, if you look at the models and
1580600	1585400	population genetics, these are the models where you can branch off into a world of social learning.
1585400	1592120	So, if you, when, when the environment is highly stable, then genes do the best job of adapting
1592120	1597080	to that environment. So, even among humans, right? Skin color is a genetic adaptation that
1597080	1603000	is well predicted by latitude because of UV radiation. You don't want so much UV radiation
1603000	1606840	that you get cancer, but you don't want so little that you have vitamin D deficiency,
1606840	1608840	which also leads to cancers and other diseases, right?
1608840	1613320	But the time scale is very long for those adaptations to happen. So, a stable environment
1613320	1618280	is where it works. They're fairly long, but they happen, right? For, for, for our, for the human
1618280	1621880	generation length, which is not, you know, the last several thousand years, a hundred thousand years,
1621880	1627480	right? It's not, sometimes if there's, if selection is strong enough, it can be quite fast.
1627480	1629560	Okay. And if there's variation in the population.
1630520	1634280	And so, by the way, you know, remember like humans, like part of this puzzle is that humans,
1634280	1637400	when most animals encounter a new environment, they're forced to genetically adapt.
1637960	1644200	And we did a little bit like human skin color, but, you know, like more, more fat for the arctic,
1644200	1650600	more, you know, proteins to process the local plants. We, as hunter-gatherers, before, you know,
1650600	1654840	physics, chemistry, biology, psychology, all of this stuff. And even before agriculture,
1654840	1659800	we marched across the planet and we figured it out in each stage. You know, we figured out how
1659800	1665320	to process the proteins using, you know, like new, new techniques and so that we could eat them.
1665960	1672840	You know, we, we, we didn't get much more fat and fur. We hunted the local animals and avoided
1672920	1679000	prey and war. Sometimes the predators, you know, skins as our own, right? So this is what we need
1679000	1683000	to explain. This is what we need to explain. So genes do a great job if, if the environment is
1683000	1688920	highly stable, if the environment is highly unstable, then genes are not a good solution.
1688920	1692120	Because, you know, today the red berries are edible tomorrow. It's the, the blueberries and
1692120	1697320	the water is here. The water is there or whatever, right? Instead, evolution has to rely on trial
1697320	1701240	and error learning across the lifespan to figure it out. You got to have a big brain to do that.
1701240	1705880	And you got to do a lot of trial and error and it's really inefficient. And so these key models
1705880	1711000	developed by, you know, mostly by Roy, Rob Boyd and Pete Richardson and also by, you know,
1711000	1717000	Kveli Shorts and Mark Feldman over at Stanford. There's an intermediate zone of environmental
1717000	1721880	variability where it is matched to generation length such that your parents and grandparents
1721880	1726840	have some knowledge worth paying attention to. And it is, it is at this point that we begin
1726840	1730840	to rely on the information they have. So imagine something like a cyclical drought.
1731240	1736760	Yeah. Maybe, you know, you've, you've never experienced one and the lag is too long, right?
1736760	1739800	Maybe your parents haven't either, but grandma remembers that when she was a child, there was
1739800	1743240	a drought and they went left to the forest past the mountain and, you know, she leads her tribe
1743240	1748360	to safely. And, you know, I was, I was recently talking to an anthropologist, she was like,
1748360	1752920	that actually happens. You know, this is a real thing. Kim Hill, you know, was telling me,
1752920	1758520	you know, from his group. Yeah, check. So, so now in this zone, so this was a nice model developed
1758520	1764360	in the 1980s, right? In 1981 and 1985, these models were developed. And everyone was like,
1764360	1768520	oh, that's cool. Yeah, maybe that's what happened. And what happened was in the late 90s and early
1768520	1773880	2000s, we actually got ice core data. So we could see climatic variation. What did we find?
1773880	1778920	Massive amounts of variation followed by a moderate zone as, you know, exactly the moment
1778920	1782680	when humans evolve. Now you should have to, you should pause for a second and be like, well,
1782680	1786520	wait a minute, all those animals, surely they all experienced, right? There is a, there is a link to
1786520	1790200	there is a link to generation length for the first step, but you also need something else
1790200	1795320	to kick this thing off. You've got this bootstrap problem. Okay. So I suspect, you know, in the
1795320	1798520	book, this is going a little, we don't have a model of this, you know, by the way, you know,
1798520	1804200	theories only become theories if you can write them down. So, you know, this, what I just said,
1804200	1809320	we've got good models for good empirical evidence, what I'm about to say, we don't have as good models
1809320	1815560	except when it comes to brain evolution, which is some of my own work. So I suspect bipedalism
1815560	1820440	actually did a lot for us. Okay. And the reason for that, so we were, we probably bipedal for
1821000	1825800	completely separate reasons, right? This is kind of an early adaptation. And by being bipedal,
1825800	1831880	it did two things. One, it freed our hands for you, for making tools and carrying them around,
1831880	1835960	right? So you can invest in that stone axe, because you can carry it to the next location
1835960	1840440	and use it again. Whereas if you're a quadrupedal ape, like a chimp or a orangutan or a gorilla,
1840440	1844440	whatever, like, you don't want to carry this big ass rock around. So you don't, you have to reuse it.
1844440	1849400	So cheapen the cost of tools. The second thing that it did is what I'm doing with you right now
1849400	1852760	that unfortunately, audio listeners can't see, which is talking with my hands, right?
1852760	1857000	Those Italians, we all do it. I saw you do it, you know, we talk with our hands. And so that
1857000	1862680	opened up a new modality for communicating with. So now, now we can begin to solve that language
1862680	1867000	problem, which as I said, it's not an explanation as part of that package. So imagine, I should say
1867000	1873480	more, so the information begins to accumulate, because cultural evolution becomes a second
1873480	1877880	line of inheritance. And that happens because of what I described there. So for any evolutionary
1877880	1883560	system needs three ingredients, variation, like diversity, easy to solve for culture,
1883560	1886600	people do all kinds of things for all kinds of reasons, different information, different
1886600	1892760	personalities, whatever, transmission. So you need reliable, you don't want too much information
1892760	1897320	to be lost during the transmission process. So for, for, for genes, of course, it's because
1897320	1902440	genes are, are not mutating at a very high rate. And you need variation reduction. And if you
1902440	1906600	want it to be adaptive, you need selection where more of the good stuff sticks around and less of
1906600	1911320	the bad stuff. And if you meet those criteria, you have an evolutionary system. It's how genetic
1911320	1916280	algorithms work, right? So genes, we know how that works. For culture, I just gave you the
1916280	1920760	transmission. We copy without understanding. And so we don't lose too much information. And we do
1920760	1925720	it selectively. We copy people who are more successful. We copy people who other people
1925720	1930280	are copying. We copy people who are experts. You know, we have a, we have a psychology that
1930280	1933800	it leads us to, for example, if a celebrity says, I'm drinking this drink, you're like,
1933800	1937880	I want that drink. We do it instinctively. Why? It's got nothing to do with their success, right?
1937880	1942040	But other people, you know, but we don't know. It's a black box. I don't know why, you know,
1943080	1946360	Beyonce is such a great singer. So I'm just going to, I'm going to wear her perfume and I'm going
1946360	1950120	to dress like her. I'm going to do everything because, you know, if I'm trying to copy the best
1950120	1955320	hunter, maybe it's because of the shoes he wears or, you know, his weapons or where he goes hunting,
1955320	1959800	but equally it's because of his kick-ass beard or fact that he shaves his head or the gods he
1959800	1963640	worships. So a little hunter copies everything about them. Now, if you have that system, you've
1963640	1968440	already deferred to the population level and information begins to accumulate. Okay. Now,
1968440	1972760	we have evidence for early accumulation of information because one of the best pieces of
1972760	1978120	evidence from, in my view, that this is absolutely why humans evolve is the fact that we rely on
1978120	1983400	cooked food. Our jaws are too, too weak for chewing on like a gorilla on leaves all day.
1983400	1988600	And our guts are too short to process that food anyway, even if we could, right? So that means
1988600	1993480	we were cooking food. We had fire. Now, I don't know if you've ever tried to light a fire,
1993480	1999160	but it's hard, man. It's hard, right? Even once you're taught, it's hard, right? And so like that
1999160	2004040	meant that we needed fire to survive and we don't have genes for it. It's got to have been culturally
2004040	2009960	transmitted. You couldn't have figured it out. So that's a very early, very early bit of information
2009960	2013640	and maybe the stone tools too, and probably before the stone tools, the bone tools and the
2013640	2017240	wooden tools that didn't survive the passage of time. When you say very early, what years are we
2017240	2023560	guessing? So we're talking like millions of years. Millions of years ago. One and a half. Yeah. Yeah.
2023560	2028600	So this is like very early on. So before like modern humans. Yeah. And we have evidence for
2028600	2032120	this, right? Like we have little bits of evidence for, for a very, and so that meant while we were
2032120	2038360	bipedal, we had information worth transmitting, right? And so that means you can get what's called
2038440	2044440	a Baldwinian process in evolution. So a Baldwinian process is one where you can get to a place through
2044440	2049160	learning. But if you can get there through genes more efficiently, those genes can be selected.
2050280	2054600	So in this case, I can, there is a bunch of gestures I can give you so you can build the tool
2054600	2059080	or light the fire or know that, you know, I can, I can have guttural utterances and I can wave my
2059080	2063320	hands in a particular way. And you can learn that that means just through, you know, reinforcement
2063320	2067960	learning, figure out what I'm talking about. But now if you have cognitive changes that allow you
2067960	2072680	to acquire that bit of language, that you can do it more efficiently. And that means the next
2072680	2076280	generation, you can do a little bit more and a little bit more and a little bit more. Now you
2076280	2081800	have the ratchet to get up in the presence of an accumulating body of knowledge. You see where I'm
2081800	2087880	going? Yeah, I do. And go ahead, keep going there. Yeah. So you have, you have, you can begin to
2087880	2092200	accumulate this knowledge, right? And so some of the genetic changes, by the way, like made us
2092200	2096280	more susceptible to choking. So as I say in the book, we were literally dying to speak to one
2096280	2102440	another. And so, you know, and so we had, so this did a few things. So one, now we had all
2102440	2106520	this knowledge, we had language begin to evolve, language continues to evolve, by the way. So for
2106520	2112600	example, it becomes more efficient. Some of my research. And our brains grew. So they tripled
2112600	2116680	in size compared to our last common ancestor, you know, five to seven million years ago with a chimp.
2117960	2121160	Our brains were to the point where if you look at the medical literature today,
2121960	2125320	once you hit about the 85th percentile, so doctors used to think it was like big babies were
2125320	2129400	difficult to birth. Turns out it's not big babies, it's big heads. Once you hit about the 85th percentile,
2129400	2136920	it hockey sticks up in terms of emergency cesareans and emergency, you know, forceps. So basically,
2136920	2140760	you need these. So that means for our species, like it was kind of the curse of Eve, right? Like
2140760	2145480	we had all this knowledge, big brain, it's painful and dangerous childbirth for mother and baby.
2145960	2154040	Yeah. So we did other things. We began to, for example, extend our childhoods, right? So one
2154040	2158760	change that seems to have happened for us is we had a self-domestication and we became neotonous,
2158760	2163720	which is an easy change for evolution to make. I mean, we turned the magnificent wolf into a poodle.
2165000	2168520	You know, so we neotonized dogs into permanent puppies. And the same thing happened for us.
2168520	2173560	We are permanent youthful apes, able to learn for a very long time. So we had a longer child,
2173560	2177960	a longer juvenile period, and we created an adolescence, which is the period from when you
2177960	2183800	could reproduce to when you actually do, which has been growing and growing as the body of knowledge
2183800	2187400	has begun to grow. It used to be that like a high school degree was enough to get a good job.
2187400	2191000	Then it was a high school degree, plus any college degree, then a STEM degree,
2191000	2194440	then also a master's degree and an unpaid internship and so on. And so now we're actually
2194440	2198840	hitting a new limit. So before, the primary selection was on like being able to give birth
2198840	2202760	to these bigger heads. Now it's like about giving birth at an older age, right? Yeah.
2204040	2209080	All of this completely changed our societies in a variety of ways that puts the whole human
2209080	2214200	package together. It's what created grandmothers. It's what created, you know, the difference between
2214200	2221000	men and women, like you created dads, very unusual among great apes. It, yeah, I mean,
2221000	2225080	the division of labor, you know, the division of information, all of this emerges. So it's not
2225080	2230840	what, you know, the theory of everyone isn't like, so I make fun of what I call, I love this genre
2230840	2235160	of book, by the way, the one thing that explains everything, you know, the Toti kind of books,
2235160	2239320	you know, it's like, let me show you why my little bit of research that I just love happens to
2239320	2244600	explain the whole damn world, right? This is a Toti adjacent book, like Toti's like an acronym
2244600	2248360	for that, you know, it's adjacent, right? For sure. But I'm not like doing this one thing. Like I've
2248360	2252680	got, you know, I kind of talk about the role that energy, like the big theme of the book is the role
2252680	2258200	that energy and particularly excess energy has played in all of life and certainly in our civilization.
2258200	2261480	And I talk about the fact that there are kind of four laws and you're going to hate this as a
2261480	2265480	physicist, but I don't mean Newtonian laws. I mean, kind of lenses of how in which we can view the
2265480	2270760	world, you know, the law of energy, which is fundamentally life is competing over excess
2270760	2276840	energy, the law of innovations and efficiency. So life is evolving new ways to use that energy
2276840	2281720	more efficiently, the law of cooperation, that the scale of cooperation to the level at which
2281720	2287560	the individual unit, be they cells or individuals, or you know, in a society, or in a, or employees
2287640	2293880	in a business is the level at which the per person per unit return on energy is not going to be higher
2293880	2299400	in a larger or a smaller group. And the law of evolution, which is that both through genetic
2299400	2303400	and cultural evolution and the interaction between these, we find the space of how to cooperate,
2303400	2308040	how to innovate at a population level, and how to, and how to unlock new bits of energy,
2308040	2311400	which, you know, thanks to the fossil fuel revolution with the industrial revolution,
2311400	2314680	we now live in that world. Well, let's talk about energy a little bit, because the story
2314680	2321240	that you just painted reminds us of this idea that history is basically a search for calories,
2321240	2327560	right? Yeah. Food calories back in the day. And then when we invent industrial technology,
2327560	2333480	we're just, we need even more calories in the sense of an energy source. And part of the theme
2333480	2338840	of your book is how much of a central organizing principle that is for human history. Correct.
2339480	2344920	Yeah, that's exactly right. So, you know, for, for us, the first, this is an ancient thing,
2344920	2348040	you know, what you just said about calories. And, you know, I put it in terms of jewels or
2348040	2351880	watts, like this is fundamentally what matters, you know, the first organisms,
2351880	2355160	whenever we turn from RNA into the first self replicators or whatever.
2357000	2361480	Sorry, the other way around, you know, the first several applicators into RNA and eventually
2361480	2368120	organisms. The only energy we had is like the fact that we got a large moon, which was closer to
2368120	2372200	the earth, sloshing the water back and forth over the, you know, the land and the seas. So,
2372200	2377160	you got some gravitational energy there. But some of it's the sun falling. So, we have the earliest
2377160	2384280	proto photosynthesis, which was, which didn't use any oxygen, right? Right. And then we had a
2384280	2389400	mutation, which led to a more efficient photosynthesis, which, you know, polluted the world, a great
2389400	2393880	oxygenation event, mass, mass extinction. But there was also a new opportunity. So, once we had
2393960	2398600	photosynthesis turning solar energy into chemical energy in the form of like ATP and
2398600	2403800	little sugar, little sugar cubes, basically, it meant that other organisms could begin to find
2403800	2408120	a new niche of not directly converting the sun into, into organism and moving at plant pace,
2408120	2412440	but eating other organisms and moving a little faster, right? There were like a little bundle,
2412440	2416440	just as a story of colonialization, actually, you know, an energy rich little corner of Eurasia
2416440	2421240	creates the largest empire the world has ever seen out competing other less energy, less,
2421400	2427720	less cooperative societies in devastating ways. And so, you know, and so the same pattern happens
2427720	2432040	throughout life. You got prokaryotes getting eaten by eukaryotes, eukaryotes being eaten by
2432840	2436600	multicellular life, complex multicellular life, and eventually all the way to you,
2436600	2441880	who is more like an ecosystem and Amazon rainforest of a microbiome and, you know,
2441880	2447240	and interacting differentiated cells more than you are a single organism. And if you run out of
2447240	2451400	energy, you're going to get defeated by the lower scales by the bacteria, or you're going to get
2451400	2456120	your stuff stolen from you by the bigger scale, same pattern across the across everything. So,
2456120	2460600	for humans, the in terms of our calories, the first unlocking of energy was the one I described
2460600	2466520	before, which is fire, right? We it was a chemical energy technology that allowed us to predigest
2466520	2471080	foods and make them those calories more bio available, which allowed us to grow those brains
2471080	2477400	and shrink those guts, right? Occupy a new niche. The next major revolution was agriculture,
2477400	2482920	which was a solar technology, right? Where now, rather than expending all that energy,
2482920	2486680	walking around, searching, you know, hunting and gathering, like trying to find plants and small
2486680	2495080	animals or large animals in a group, you domesticate and look after animals and you grow food more
2495080	2499400	efficiently. It was a law of innovation, if you like, and the law of energy and you grow your
2499400	2504600	population to the point where you out compete the hunter gather groups to the margins that are
2504600	2509080	not suitable to agriculture, which is still where they live today, right? And those larger groups
2509080	2512440	are able to innovate more and you lay the foundations for the beginnings of cities as
2512440	2518600	kind of massive nodes of collective intelligence, right? This continues and we live in a Malthusian
2518600	2524600	world, right? Because the pattern in this story across every scale is that when you get this
2524600	2528600	unlocking, you get an era of abundance, and that would have been that first era of abundance. And
2528600	2532360	then, because carrying capacity has gone up, the number of individuals meets that carrying
2532360	2537560	capacity and you once again enter an era of scarcity where the per person calories or energy
2537560	2542280	is lower. The next major unlocking that is most relevant to us was the industrial revolution,
2542280	2546520	which if you look at any metric of progress, the size of our polities, the, you know, child
2546520	2553000	survival rates, anything you care about, it just shoots up into the sky, right? And as in Morris
2553000	2557400	puts it, it made a mockery of all the world's earlier history, scientific revolution, black death,
2557400	2563800	renaissance, blips in anything we care about. And that's because we exploited stored solar energy
2563800	2569000	in the form of like Pete turned to black rock coal and, you know, algae, you know, whatever turned
2569000	2573880	to oil and natural gas, right? And we unlocked that in a matter of centuries, we began to burn
2573880	2578520	that down. And we, using that excess energy, we multiplied ourselves and our efforts, we had
2578520	2584120	another agricultural revolution, the green revolution, you know, Norman Borlag, where we
2584200	2588520	synthesized through the Haber-Bosch process, we synthesized fertilizer with nitrogen in the air
2588520	2593800	and, you know, natural gas. And this allowed us like four billion people, half the population
2593800	2597160	along our life today, thanks to that process, we're literally eating our fossil fuels,
2597160	2601560	we use them to develop new technologies. Now, here's, here's, here's where we transition to,
2601560	2605800	you know, part two of the book in which is that the energy return on investment, which is a key
2605800	2612440	metric I care a lot about, is decreasing. So the excess energy is shrinking and economics and a lot
2612440	2616360	of what we do, we've focused on efficiency, because they all developed long after the industrial
2616360	2620440	revolution, right? Or after the industrial revolution. And so if you look at one metric,
2620440	2625960	like oil discovery, and all the metrics look like this, in 1919, one barrel of oil found
2625960	2632200	you another 1,000 barrels. Okay. So massive return on energy. By 1950, one barrel of oil,
2632200	2636120	a barrel of oil found you another 100. And by 2010, one barrel found you another five.
2636920	2642120	So, so the level of cooperation is governed by this, if you like the space of the possible,
2642120	2646680	created by an energy ceiling, and an efficiency floor, and that is shrinking. Our ability to
2646680	2650920	innovate new efficiencies is decreasing, the rate of that is decreasing, and the ceiling is
2650920	2655640	rapidly falling on us. And so our societies, all of the fractures are cracking, we're falling back
2655640	2661320	to lower scales of cooperation, as a result of this. Let's actually get out of this. Let's pause
2661320	2666840	and dwell on this, because I think this is an important thing. First, let me just sort of
2666840	2671480	summarize this point, which I'm going to be very much in favor of as a physicist, that
2672040	2677080	the progress, progress in the sense of just change, not necessarily improvement,
2677080	2683240	of human society, is a story of transitions, right? It's more punctuated equilibrium than
2683240	2687320	gradual improvement. We, you know, innovate, gradual and occasional punctuated. Yeah, sure.
2687320	2692360	Yeah. But the, but the idea that we do innovate, we find some new mode for doing something,
2692360	2697160	whether it's producing energy or technology or whatever. And then that gives us space, right?
2697160	2703320	We can then grow into that. But you're saying that as we do grow into that, as we sort of reach
2703320	2710440	what might be a new equilibrium, we also, because there's less spare excess wealth in various forms
2710440	2715880	to go around, things get squeezed a little bit. Our social fabric gets a little bit harder to
2716760	2722520	maintain. That's right. So I mean, our, not only does population grown, and so that alone is,
2722520	2726200	but that's a good thing for the most part, because it means more innovation, right? Like more people
2726760	2730760	insofar as everyone is able to access all of that cultural knowledge and, you know,
2730760	2734600	opportunity matches talent and all of that stuff, which as we both know, isn't often.
2734600	2739400	Not always true. Yeah. But, but, you know, the other side of it is simply that the space itself
2739400	2743240	is shrinking, because not only is abundance turning to scarcity for the usual reasons,
2743240	2747320	but we're reentering a Malthusian world simply because our excess energy is decreasing.
2747320	2751000	Like it doesn't matter how fancy your gadgets and technology are, if you can't charge them.
2751720	2755640	Like our ability to access energy isn't just like price, it's a proxy for it that's affected by a
2755640	2759400	bunch of other things. It's literally how much energy do I need to get some amount of energy back?
2760120	2764360	Ideal world, you want a small energy sector. It's like 5% of the economy at the moment, right?
2764360	2768840	That's great. But as, because it means that the returns on that energy allow you to do
2768840	2773400	everything else that makes life worth it. Like traveling on flights across the planet and, you
2773400	2777320	know, hanging out with your friends and eating great food that requires ingredients drawn from
2777320	2782120	all around the world. All of that stuff relies on abundant energy.
2783800	2788760	And I guess, yeah, I think you're going to have to convince me of this one a little bit more,
2788760	2795560	because I can imagine, you know, the same kind of general story, but then saying, well, once we
2795560	2802440	reach some equilibrium, once we have some steady flow of energy in and things out,
2802440	2809400	then we can figure out a way to organize our society that fits in to that equilibrium. You
2809400	2813880	know, the moments of change in a different telling than what you just gave, the moments of change
2813880	2818840	are the scary ones where we're not sure what's going on. But once everything is a steady flow,
2818840	2822920	there we might reach a happy equilibrium. But you seem to be saying that's not empirically
2822920	2828680	what happens. That's a very physicist answer, Sean. I mean, in biology, regardless of our,
2828680	2834120	you know, our evolutionary game theory, there are no equilibrium. And the reason for that is
2834120	2838520	because, you know, in a world, so, you know, I tell the story in the beginning of the book,
2838520	2841720	like why I got into this, I'm trained as an engineer, you know, originally, and I kind of
2841720	2846120	switched fields. And the reason that I did that is I got really concerned around climate change.
2846120	2849560	And I got concerned about a lot of, I lived in a lot of different places like Africa and
2849560	2852520	New Guinea and things like that. And I was concerned that people don't understand culture,
2852520	2857960	first off. And second, climate change, we're all focused on mitigation. But as the world changes,
2858040	2861240	we're also going to have to figure out how to live in a climate changed world. And some of that we
2861240	2865560	get like carbon capture and those kinds of technologies. But how do you deal with a million
2865560	2870120	Bangladeshis underwater coming into India? How do you like not have civilization come apart? What
2870120	2874120	does that mean for, you know, the Middle East and then for Europe? Like the Syrian migration crisis
2874120	2878200	is the first example of that, you know, you had climate change, probably induced droughts, you
2878200	2881480	have a bunch of people coming into cities, there's not enough jobs to go around, not enough infrastructure
2881480	2886520	to support them. Eventually, they start to, you know, to, and then the geopolitics kicks in,
2886520	2890360	eventually you have a difficult problem at Europe store stuff, right? That's what I wanted to work
2890360	2895960	on. So the thing is that in a world, like, you know, I remember watching Al Gore's documentary
2895960	2900040	in 2007, and I was like, and I started reading the IPCC reports, I was reading the Pentagon
2900040	2904280	reports, and I was like, Gore is absolutely right about the problem. But he's crazy. Like,
2904280	2909240	are we going to slow the economy to save the planet? If we do, amazing, I'm happy. But I just,
2909240	2915640	I just don't believe that because in a world where every, every country is trying to outcompete
2915640	2920200	every other country, every company is trying to outcompete every other company, and every individual
2920200	2926360	wants more than their neighbors, you're not going to get this equilibrium sustainable, you know,
2926360	2930680	whatever, you're, all you're going to do is encourage a zero sum Malthusian world where your
2930680	2936280	success means my loss because there's a limited pie from which we are taking stuff, unless you
2936280	2940760	somehow equalize everything and people don't like that. So I mean, any theory of change or any theory
2940760	2946040	of society that requires a complete shift in human nature and not just constraining in some way
2946760	2951480	is broken. It's, it's broken from the beginning. It's broken before you got there. So this is
2951480	2956760	an example. There isn't, you know, so like ideas like degrowth or, you know, like just pure sustainability
2956760	2961000	of stagnation are dangerous because they will shove us back into a zero sum environment.
2961000	2963560	Is that what it was like back in the hunter-gatherers?
2964600	2967480	Yeah. So hunter-gatherers are really interesting. So we have some new work where we're trying to,
2967480	2972120	so hunter-gatherers are, oh well, some hunter-gatherer groups are known for their egalitarianism,
2972120	2977480	right? They do equalize, right? If you move to like pastoralists and chiefdoms, you start to see
2977480	2981160	a bit more inequality and things like this. And so people sometimes interpret that as the ancestral
2981160	2986680	state was, you know, was, was an egalitarian, humans are by nature egalitarian. No, that is
2986680	2992120	probably an adaptation to those zero sum conditions where there's weak property rights. Why? Because
2992120	2997000	in a world that is zero sum, and that means your, your gain is my loss and vice versa.
2998040	3002280	If you like, you start a pizza business, right? And I'm like, you start a pizza business, you took
3002280	3005720	a piece of that limited market. I'm going to like burn your business down or take from you. That's
3005720	3010440	what it incentivizes. It incentivizes destructive competition. In a world that's positive sum,
3010440	3014120	you start a pizza business. I'm like, yo, I got to start my own chain of pizza, you know, like,
3014120	3017880	obviously the pizza business is booming, very different psychology, productive competition.
3017880	3021320	So hunter-gatherers in a world of destructive competition, and there's two equilibria that
3021320	3025960	emerge in the model. One, they just kill each other to extinction because of these destructive
3025960	3031640	cycles, or two, they manage to flatten. But the consequence of that flattening is a decrease
3031640	3036280	in productivity, because what is the point if you can't rise higher, right? It's a little decrease
3036280	3041640	in production. And it is a kind of stagnation, if you like, right, that eventually gets you
3041640	3047160	outcompeted by the pastoralists, by the agriculturalists, by, you know, the larger
3047160	3051720	societies that are not engaged in that. And so that's the central problem with what I think the
3051720	3055080	solution you're alluding to. Well, it's not even a solution. I'm just wondering what the
3055080	3060360	space of possibilities is. But you're pointing out that, to put it in the harshest possible
3060360	3069800	terms, inequality can be a driver of innovation. Correct. And evolution, like life, is competing.
3069800	3074040	Now, you could get cycles, if you like, you know, like predator prey model type stuff, you know,
3074040	3078360	where it's like you get a nice bird, and the rabbits go up, and you know, the hair go up,
3078360	3081880	and then, you know, the foxes will catch up, and then you get a lion. You can get these kind of
3081880	3086120	equilibrium urge, but it's not a, it's a Malthusian world that most animals inhabit.
3086120	3092840	We escape the Malthusian trap simply because we got a little boost. So the question is, so my view
3092840	3097560	is that in order to tackle these very real problems around sustainability, climate change,
3097560	3103080	and not destroying ourselves and our planet, we need the next era of abundance, not, you know,
3103080	3108440	an era of scarcity. Because, you know, the countries that are, first off, it's easy to
3108440	3113320	be nice to people when there's plenty to go around, right? And second, the countries that can invest
3113320	3117880	in looking after their environment and preserving blocks of land and wanting to live in a clean
3117880	3121800	environment are those that are wealthy enough, energy rich enough, that they're not worried
3121800	3126760	about simple things like food and, you know, having enough resources for hospitals and education and
3126760	3130520	other infrastructure. Those are the countries, like, you know, as in Australia recently,
3130920	3134920	I'm Australian citizen, actually, you know, like, so I, you know, I was, I was at the Great
3134920	3139320	Barry Reef. I was there as a, as a teenager and I remember like, oh my God, like I was in these
3139320	3144440	areas, I was like so bleached, right? This was in, I don't know, early 2000s or something. And I was
3144440	3148280	back again last year and I was astonished. I was talking to people like, how did you manage to
3148280	3153240	restore the reef? They have money, they have resources and they care about it enough because
3153240	3156920	they have the highest household wealth in the world and the only country in the world that has,
3156920	3161880	you know, positive migration from America, right? So they were able to invest in it,
3161880	3165960	if they want to. You do that in a world of abundance, not scarcity.
3166520	3171080	Well, I'm, yeah, and I don't want to disagree because I don't know enough to be able to disagree,
3171080	3178120	but I'm curious about the possibilities. Like I said, is that, that story you just told is,
3178120	3184440	is compatible in my mind with an equilibrium zero sum game where everybody has that level
3184440	3190120	of wealth, right? I mean, I haven't quite seen the connection to inequality and competition.
3190120	3194280	It's just exactly what you said. So there is no baseline, right? There's no like,
3194280	3200120	now I'm satisfied, right? You know, like I have enough, like progress and, you know, and, and
3200120	3203960	competition, like we want more, we want more than our neighbors and there's always problems to be
3203960	3208920	solved. And even if you as a society, even if you as an individual decide, you know what, I have
3209000	3214600	enough, we as a society, you're going to get outcompeted by the mutation, cultural or genetic,
3214600	3219640	right? Where that says, actually, I want a little more. Yeah, it's not inequality. In other words,
3219640	3224280	it's invadible by that other mutation. Okay, I'll make, I'll make one more stab at
3224280	3232760	utopian egalitarianism and then we can move on. Even if we bought the idea that inequality is,
3232760	3237720	is going to happen unless it's sort of, we enforce some kind of rigid, you know,
3237720	3244280	equitability that everyone is unhappy. Can we imagine that we're in a world of such abundance now
3244280	3251160	that we can have some equality, some competition, some motivation for innovation, and yet the worse
3251160	3254760	off people are still much better off than they are today in the actual world.
3255800	3262680	Yeah, I mean, I think the issue is, so I kind of surveyed the energy technologies available
3262680	3267640	to us. And I really, apart from solar, if we solve the battery problem and hydro, which is
3267640	3272280	fantastic, if you've got fast flowing rivers, please use them, get on your Canada, you know,
3272280	3277000	it's really, it's really nuclear as having the right numbers apart from fossil fuels. And the
3277000	3280840	fact that those are decreasing, we're in real trouble. And you know, there are, there are,
3280840	3284520	you can have a society that's more redistributive and it comes at a cost or
3285320	3294440	or look at the top 100 European companies, right? They're old, you know, very few were,
3294440	3299080	you know, invented, you know, created like this, this century, if you like, look at the top 100
3299080	3304040	American companies, how many of them, right? Europe redistributes a lot. And so it squashes,
3304040	3307320	you know, it's a good, it's like, I live in Europe, right? I live in the UK, somewhere between,
3307320	3312360	it squashes things. And so productivity is lower, production is low. And so you end up,
3312360	3315560	you know, with America doing a lot of the innovation, and there's a little bit of
3315560	3319400	free writing, you know, where you get to benefit from all of those drugs and all of those technologies,
3319400	3322520	you get to use the iPhone, you get to use, you know, the internet, you get to use all
3322520	3327400	of these different technologies. But it's being driven by this American, you know,
3329480	3333560	this creation of inequality in America driven, like, you know, so I talk about Silicon Valley,
3333560	3337720	right? Silicon Valley is a, people think of it as like a bastion of success. Now, man,
3337720	3343960	it's a grave, you're at a failure, right? And that's what America, you know, America says,
3343960	3348280	you do you, everybody go try, you can do this too, right? It's terrible at an individual level.
3348280	3352680	The Asian model, like, you know, Asian tiger mom, you know, Japan, whatever is,
3352680	3356040	you know, you don't do you, you do me, like you do this, you follow the script,
3356040	3359640	and everyone is better off, but it leads to incremental innovation, like you have to believe
3359640	3364680	in a crowded market where everybody also thinks this, and most people still fail,
3364680	3369720	that you are going to make it. And a society that encourages that in a large enough marketplace with
3369720	3375720	enough energy results in finding the few apples, what we call unicorns for a reason, right? The
3375720	3381240	apples, the Amazons, the alphabets, the whatever's, right? And the graveyard of failure is forgotten
3381240	3388520	because America is richer as a result of this. And you draw, good, I'm going to give up on
3388520	3392760	the utopia there, you know, the egalitarian, I'm actually not highly committed to it.
3392840	3399240	I would enjoy this. I'm not highly committed to it, but I want to learn. But you then take this
3399240	3403720	picture, I know we've given it very short shrift because it's a deep book with a lot of things
3403720	3408360	going on, but you take this picture of human nature and the development of history through
3408360	3414280	these transitions and getting the energy, and you apply it to current issues that we have.
3414280	3419320	I mean, climate change is one of them, of course, but also political polarization. I mean, what about,
3419320	3425240	you know, the growth of populism and authoritarianism and so forth? How do we understand that through
3425240	3429320	this lens? So, I mean, the first thing is, you know, like, ideally you want to predict,
3429320	3431560	you want to explain, but then you want to be able to do something about it.
3431560	3436840	I mean, so I see the rise of, there are always fractures that exist in a society, right? There
3436840	3440840	are always fractures. They are the class divisions, ethnic divisions, you know,
3443400	3446680	regional divisions, there's all these fractures that exist. But in a world where there's plenty
3446680	3451240	to go around, people just mumble and grumble. So, you know, this analogy, imagine the buses
3451240	3455880	coming along, right? That's the rate of economic growth. And people are waiting for the buses,
3455880	3459880	and you know, you've got some people who have special passes, the 1%, get to the front of the
3459880	3464120	line first. And you've got groups that favor their in-group, and they're like, come on, you can come
3464120	3467560	in front, and you're waiting there. But if the buses are coming every five minutes, you mumble,
3467560	3472040	you grumble, but you put up with it because you're going to get a seat. Just wait five minutes more.
3472040	3476440	But if the rate of buses slows down, what an hour, what a day,
3478120	3481800	it's like driving around at car park where there's plenty of spaces versus only one. And now some
3481800	3487480	asshole, so can I say that in your podcast? Someone tries to take your place, right?
3489880	3495320	It's a very different psychology. So, and it doesn't even have to be like a reality,
3495320	3499560	like the perception that that is happening, the created perception can create the reality,
3500200	3504040	right? Or if you're looking at, if you're, if you're, if we have a psychology that's sensitive
3504040	3508520	to rate of change, right? And you feel like things are slowing down a little bit, right?
3508520	3513160	That alone is enough to trigger this, those fractures becoming something more. So then you
3513160	3517560	can have the rise of the right wing, you can, you end up with more ethnic fractures, you get
3517560	3523080	political polarization, you get all those fractures becoming something more. And the solution to that
3523080	3527720	is one, if you've got the resources, invest, right? You can have a million people turn up
3527720	3532520	at your door if you don't have enough food and water and prepare for those guests, right?
3532520	3536440	So you need to invest in infrastructure so that already stretched schools, you know,
3536440	3539960	the good schools, the hospital lines, you know, people are not waiting and waiting and now they're
3539960	3545320	annoyed because you're giving things to newcomers. Like that's a recipe for ethnic conflict. But if
3545320	3548600	you're investing and you're like, you know, alongside this, this new group of people, we're
3548600	3551800	going to put in all this money so that there's enough space for everyone. That's a good thing.
3551800	3555960	And if you don't have that, you need to be investing in energy technologies that allow
3555960	3560600	us to raise that ceiling. So talking about the umbrella model of multiculturalism is really
3560600	3565880	fusing all of these solutions into something that would work in a way that current melting pots or
3565880	3571640	mosaics or, you know, no hyphen French models really just don't.
3571640	3575400	So just to try to rephrase it, because I do think this resonates with something that I
3575400	3582200	had believed for a while, they're one of the things, the major factor that what is the acronym
3582200	3586360	you use that, you know, the one thing that explains everything when it comes to,
3587880	3592840	you know, populism, et cetera, is the idea that people who are not well off,
3592840	3597480	which you might think are going to go for like leftists who are who want to spread the wealth,
3597480	3603000	but they really are feeling powerless and both in the sense that their political voices aren't
3603000	3609240	heard and that their lives are getting worse, right? And then they that, that combination
3609240	3612600	pushes them toward appealing to a strong figure who can shake things up.
3613240	3617400	Yeah. Yeah. Look, you know, as I pointed in the book, I don't think there's good evidence that
3617400	3622520	people don't like inequality. What people don't like is a double negative. So you're saying that
3622520	3628440	they're people like it like equality. No, I'm not saying that people like equality or inequality
3628440	3633000	or whatever. What the people want is fairness. Yeah. Okay. Right. Like people want the outcomes
3633000	3637800	to be matched to the input, you know, like they want a return like they don't want necessarily
3637800	3643560	the hand down. Maybe some people do, right? But like people want the opportunity so that what
3643560	3648360	they do that they're hard working, if they choose to wake up early and get to the front of the line
3648360	3652840	at that bus stop, they will get at their seat. And when that stops happening, no matter how
3652840	3657160	early they wake up or because of where they're born or who they're born to, they just never get
3657160	3662760	that seat. That is the problem. That's when society starts to come apart. And that's what we need
3662760	3667640	to resolve. So, you know, in the section on inequality, I differentiate between, you know,
3667880	3674200	wealth creation versus wealth appropriation. Wealth appropriation is rent seeking. It's
3674200	3678840	monopolistic behavior. It's like land, you know, like holding on to land for centuries,
3678840	3682760	as in the country I live in, you know, where you're just, you're just, you're just taking,
3682760	3687160	you know, a rent on the land, providing no additional value, right? This is why we need like
3687160	3690840	land value taxes are kind of a way out of this. It's like a huge thing that I talk about in the
3690840	3696920	book. Whereas wealth creation is like you created Apple or you created, you know, Windows or you
3696920	3701400	created Amazon. Yeah, you put like a bunch of high streets and malls out of work, but you made
3701400	3705960	things more efficient that consumers like. And you actually, you created wealth in some sense,
3705960	3709240	either through the efficiency, the law of efficiency, sorry, the law of innovations and
3709240	3713480	efficiency, or because you've found some new energy technology or something, right? You've
3713480	3717640	literally created a new, you've increased the space as possible, and you are allowed to keep a part
3717640	3723240	of that space. And you are allowed to make other bets that we hope will continue to expand the space.
3723240	3728200	But the issue is that under an intergenerational transmission of wealth that entrenched that
3728200	3734120	inequality slowly over time, having the remaining people fight over smaller and smaller scraps.
3734120	3736840	That is when society comes apart. And that's what we need to solve.
3736840	3742040	So you'd be in favor of larger estate taxes. Would be great. As I pointed out in the book,
3742040	3747080	that would be great. But it runs up against a few issues. One is a smart estate planning wealth
3747080	3752280	flight where people take their money out of the country. And it also goes against, you know,
3752280	3756040	it goes against kind of instincts about like provisioning for your children and working
3756040	3760600	harder later in life. It would be great. Here's the outcome you want. You want to create a world
3761240	3766200	that is, every generation has a fairly fair playing field to start with, so that the best
3766200	3769880	and brightest of every generation can push forward our species to where we need to go.
3770440	3774440	And over time, things accrue that prevent that happening. So what I actually, so there's a,
3774440	3778920	you know, there's a, there's an open secret within economics where across the political
3778920	3784280	spectrum, you know, people agree that most taxes are distortionary. You know, they affect your
3784280	3787720	behavior in negative ways. Like your income tax, right? Like if you are afraid, you're going to
3787720	3791400	earn a little bit more and move into the next income bracket, you're like, that marginal gain
3791400	3797640	is not worth it for me. So now it's distortionary on your productivity or production. You know,
3797640	3801640	sales tax, like I'm not going to buy that because of the sales tax. It's distortionary on commerce.
3802440	3808040	There's one tax that is non distortionary. And there's a moral case for it. And it is fair.
3808120	3814360	And it would do away with the need for the other taxes. You could get rid of income tax. You can
3814360	3818440	get rid of sales tax and get rid of capital gains tax. And you could still pay for the
3818440	3823640	US military and Medicare and, you know, this country, many more. So that is land value taxes.
3823640	3829320	So the one asset that people own that they did not create, the one asset that stands above all
3829320	3833400	others is the land. And I don't mean like what you do on the land. You shouldn't be taxed for
3833400	3839240	your buildings or anything you do on the land. But the land itself is common. And there's a moral
3839240	3844280	case almost like slavery, where we really need to get rid of this ability to own land. Or at the
3844280	3850520	very least, those who take that land should be taxed for, you know, for that use of that land,
3850520	3854760	for its most, and this does all kinds of things. So it's non distortionary. It leads to the most
3854760	3860600	productive use of that land. It solves a lot of housing issues. And the only barrier to it that
3860600	3864360	people agree is is going to require revolution. Unless I guess the middle class realized that
3864360	3867880	because we all, you know, I own land, you own land, you know, like we own land. But what you
3867880	3873880	don't realize is how little you own relative to, you know, many others. 25,000 Britons who own
3873880	3878040	Brits who own half of the country or, you know, the 10% of Americans who own I think 60% of the
3878040	3884680	country. But just to just to point out, this is very radical as a proposal. And there's probably,
3884680	3890520	you know, unanticipated consequences here. The difference in utopia and, you know,
3890520	3894760	in a better world are constraints. And what you want, you know, there are real constraints on
3894760	3898680	this. And so what I suggest, you know, I suggest pathways out of this. So the path dependence
3898680	3902280	leads us into a world, like it's hard to rewrite the Constitution, it's hard to like change the
3902280	3907880	tax code overnight. But what you can do is do what, for example, so, you know, last week I was in
3907880	3911640	Estonia, because I want to understand how they are the top of the pizza tables in the Western
3911640	3917640	world, beaten only by a handful of other handful of East Asian countries. And they do it while
3917640	3923320	spending less per student than the rest of the OECD average and certainly less than the US,
3923320	3927400	Canada, UK, Australia, you know, then, and they have better outcomes. How did they do that?
3927400	3929560	Sorry, explain what these tables are that you're talking about?
3929560	3934520	Oh, sorry. Yeah, sorry. The OECD's pizza tables test students around the world on mathematics,
3934520	3940360	on reading, and on science. Good. Okay. And Estonia tops that table. Their students top the
3940360	3945720	table. Right. A part, as I said, from a couple of a few Asian countries, how did they do that?
3945720	3948840	So I went there to understand, you know, I spoke to the former education minister, I spoke to the
3948840	3954040	person who founded what was called the Tiger Leap Foundation. So after the fall of the, well,
3954040	3959720	after the Soviet occupation ended in 1991, only half the country had a telephone. So, you know,
3959720	3963000	when Estonia became its own country, they were like, okay, if we want to leap ahead,
3963000	3965480	we're going to have to do something different. We're not like super wealthy. We don't have like
3965480	3969080	a bunch of resources. We just have our people, right? That's it. We got to invest in our people.
3969080	3973560	And so, you know, you can tell, you can see how, why the people who did this thought of it because
3973560	3977320	of their own experiences, but they decided to really invest in technology. So they created what
3977320	3982120	was called the Tiger Leap Foundation, where they overnight gave it the access to computers,
3983000	3985880	you know, for every student, they internet connected everybody, they train the teachers
3985880	3990680	and so on, right? Then they were able to do this, because they have radical decentralization.
3990680	3994760	Every school has autonomy over what they do. Every municipality has autonomy. And
3994760	3999240	central government can't just say, let's do this. They have to incentivize. So teachers were
3999240	4003000	incentivized to share knowledge through this teacher social network called School Life.
4003000	4007560	They gave them opportunities and incentivized by sharing that knowledge. They increased their
4007560	4011160	pay. They gave them opportunities to travel to other places to borrow the best from things from
4011160	4016440	around the world, creating a brand new curriculum. And they tested them onto things at a local level.
4016440	4021720	And when it worked, it got spread to the rest of the country. Many, you know, so, you know,
4021720	4024680	in this case, for example, robotics is taught, like they were the first country to teach
4024680	4027960	reading, writing, arithmetic, and now algorithms to like elementary school students.
4028680	4034520	They, they trialed and, you know, Conrad Wolframs, I don't know if you come across Conrad
4034520	4040040	Wolframs criticism of math education, where he says, you know, math education recapitulates
4040040	4044200	history for some reason, like, we, you know, we're like, we're going to learn numbers. Now,
4044200	4048920	the Greeks and Pythagoras for some reason, and, you know, eventually get to algebra and
4048920	4054680	eventually calculus, right? Many students never get to calculus, and we don't learn any 20th century
4054680	4059800	math in high school, let alone 21st century. Like we're missing huge swaths. Why is that really
4059800	4064680	the most efficient way to do it? So Conrad, you know, obviously wanting to sell some Wolfram
4064680	4069960	products, but, you know, he, he argues, well, in the real world, you and I do math on computers,
4069960	4073880	right? Like we're not back in the envelope calculations. That's not where the hard stuff
4073880	4081000	gets done. Right. And so what you want is for kids to understand what it means to take a derivative,
4081000	4084440	what it means to what an integral actually is and how it can be used and maybe some stats.
4084440	4088200	And, you know, like, you want them to have mental models and work alongside computers,
4088200	4093160	and you can teach that before you, what's hard about calculus is not the derivatives and integrals,
4093160	4096840	it's the chain rule and it's the mechanics, the quadratic, you know, like it's those that are
4096840	4100600	difficult. I agree with you there. That's not what's important. That was built for a world before,
4100600	4103400	you know, one middle school teacher was like, make sure you learn how to do mental math,
4103400	4107160	you're not going to carry a calculator in your pocket. He didn't force you to do that, right?
4107160	4111480	So we, so they were able to trial that. And now they're trialing this really radical new
4111480	4118440	education system, where they, the learning happens at home, right? Where homework and
4118440	4122920	schoolwork are swapped, basically, right? How can a teacher teach to 20 to 30 kids of different
4122920	4128440	abilities? They can't. So the lower end get left behind, the upper end are ignored, right? And so
4128440	4132680	in order to do that, what happens is you when you're at home, you get educational material,
4132680	4136920	you get teachers and whatever, you get this from the best minds. And then you come to school to
4136920	4140280	practice that you do the homework where the teacher is not the deliverer of knowledge,
4140280	4144280	that the facilitator helping you use the internet and AI to practice your skills
4144280	4148680	in a very kind of practical real world focus. And you do that through radical decentralization.
4148680	4152840	So the US works the same way, by the way, you know, Justice Brandeis referred to each state as a
4152840	4157960	laboratory for democracy, right? Arizona, you want to try something? Go try it. If you fail,
4157960	4161640	you fail it at an Arizona level. And if it works, we bubble it up to the top.
4162200	4167240	Such a Nadella converted Microsoft from a monolith to a series of startups using the same
4167240	4170920	principle, you know, it's like, you're going to try different things and we're going to bubble
4170920	4175240	it up to Microsoft and it works. And that they invested in chat GPT and open AI, right? Great
4175240	4179480	moves. And the shares have been, have been soaring. The Catholic Church works this way, by the way.
4179480	4183160	You know, it's like lasted for so long because they're like, well, we got a central authority,
4183160	4187320	but you know, Jesuits, you go do your weird thing and we're going to laugh at you for most of it.
4187320	4191400	Oh, now we have a Jesuit Pope because that worked out, right? You have to have space to
4191400	4195800	kind of explore these possibilities to get out of that trap. So what do I why am I saying,
4195800	4199400	talking about all this because land value taxes are something you can do in what I call startup
4199400	4205720	cities, right? Like cities are the place where we all live and countries are increasingly untenable
4205720	4209560	in some ways. Like how do you get that? But if you empower cities, give them more autonomy,
4209560	4214600	allow them to learn from one another, have a more startup ecosystem around that. This is a way out,
4214600	4218360	right? This is the engine of development that Hong Kong represented for China. This is why
4218360	4223240	Singapore is at the top of the piece of tables, you know, it's, it's how Guangzhou works. And now
4223240	4227000	there's a bunch of startup cities or charter cities sometimes, you know, in, in Africa.
4227000	4231720	But this is a way past current democracy and eventually maybe programmable politics. But
4231720	4235320	I don't have time to explain that it's in the book. It's in the book. I think there's a lot in
4235320	4240040	the book and you know, we've covered a lot of it. But I do want to encourage people to check out the
4240040	4244920	book because it paints a much folder picture. But maybe we can sort of wind things up by
4245560	4251560	returning to something that we talked about right at the beginning, the, the children learning from
4251560	4257080	the adults rather than using their reasoning, right? That we rely on our cultural transmission
4257080	4261560	of knowledge. I want to feed that back into what we were just talking about in terms of
4262120	4269320	inequality and fairness and innovation and things like that. How much of a problem is it
4269320	4275800	that in the modern era, we're able to get that cultural knowledge in a, in a quite fine-tuned
4275800	4282360	or at least quite differentiated way, even within one culture, right? Like if I, in your
4282360	4289800	bus analogy, if I am constantly told that the buses come very rarely and discriminate against me,
4289800	4293480	even if it's not true, that becomes a problem for how society works.
4294600	4297960	Yeah. You know, like, you know, people talk about this as like the Walter Cronkite problem,
4297960	4300520	you know, like once upon a time we all got our news, well, not me, I'm too young.
4301240	4307160	Walter Cronkite, you know, was on the evening news and now like we all read different, you know,
4307160	4311080	we read Breitbart and, you know, and Huffington Post and New York Times, we're all getting it from
4311080	4316600	like different places. So I think the internet is interesting in that, so I argue that the internet
4316600	4320760	is actually creating, we are not in the midst of a fourth industrial revolution or fifth industrial
4320760	4326200	revolution. We are in the midst of a second enlightenment. Okay. One driven not by coffee
4326200	4332200	shops and pamphlets and books, but by tweets and, you know, and shared articles on social media
4332200	4336600	that piss you off. And they piss you off because they expose you to ideas that are not in your
4336600	4343240	in group. Now, alongside that is a countervailing force, which is that we are also able to assort
4343240	4348040	in smaller and smaller groups, and those groups can compete with one another. In other words,
4348040	4354920	the internet creates new tribes, right? So, you know, there's a show here, Little Britain,
4354920	4359160	and there's a character, you know, he's like, I'm the only gay in the village, you know, it's
4359160	4364600	not true. He actually, there's lots of other gays in the village. But once upon a time, you might
4364600	4369560	have been like, if you had, if you were a small minority in a small village, you were, you did
4369560	4374040	not have a critical mass to do anything. Right. But the internet enables you to find. So, you know,
4374040	4379240	I point to a couple of examples. So are you, are you into carrying sand in your pocket,
4379320	4384360	Sean? I am not. I've never have done it. Well, you know, like 30,000 people on like our, you know,
4384360	4388600	Reddit subreddit on pocket sand, talk about all the benefits of carrying sand in their pockets.
4388600	4393080	But that's actually kind of a niche interest on like stapling bread to trees. Like listeners,
4393080	4398760	go and Google bread staple to a tree. It is a hobby held by around 300,000 people. Right. So,
4398760	4402680	yeah, you get these different groups, but it's very hard. It's very hard to generalize whether
4402680	4408360	that is silo. Like it's an empirical question, whether we are now in silos or actually exposed
4408360	4413080	to more information and both are true. I think what is actually the case is it's not about the
4413080	4417480	information. It was never about the information. It was never about misinformation. It was about
4417480	4423880	whom we trust. And what has happened is that our trust in our institutions and to some degree,
4423880	4429880	as a result of that, in each other has decreased. And that is resulting in selective access to
4429880	4434440	that information and greater assortment. And the ultimate issue here, the ultimate level problem
4434440	4437640	needs to be solved. And that is it's an energy problem, actually.
4438920	4444760	Sorry, you made a leap there that I need to figure out. I mean, I agree that the trust in
4444760	4452520	institutions has waned. It seems to me like in some ways that's an outcome of the same game
4452520	4460200	theoretic analysis of different groups jockeying for space and things like that. And of course,
4460200	4465720	with the caveat that some institutions are super untrustworthy. So it's correct to not
4465720	4467800	trust them. But so how do you bring it back down to energy?
4468760	4472280	So sorry. So, you know, why I say that it's, you know, it's about the information is like,
4473160	4478520	there are always people always calling for the end of the world or saying that, you know, we live in
4478520	4482040	a racist society or that, you know, we live in a society where you are getting screwed over. There's
4482040	4487480	always people. There's always a bunch of people saying everything. But whom people listen to
4488200	4493240	depends on on circumstances. Right. And so what I'm arguing is there is a both a perception
4493240	4498440	and a reality. And yes, they can like feedback on each other. And the reality is that out truly
4498440	4505400	our space of the possible has indeed trunk. The amount of access energy available to each of us
4505400	4511080	has actually shrunk. And, you know, around about the 19, you know, the oil crisis, 1980s, 1970s,
4511080	4515960	you know, like, it was around, you know, what the fuck happened in 1971 1973. This was when it all
4515960	4520040	happened. The American dream died around then, because you suddenly had a 5050 probability of
4520040	4525960	being better off than your parents. That has truly happened. Right. And so that is fundamentally
4525960	4531320	an issue of excess energy, which ultimately drives GDP growth. So like 50% roughly of GDP
4531320	4536280	growth is energy or 50% is about it, you know, innovations and efficiency. Okay, I do get it
4536280	4541640	now. So it comes back to this shrinking distance between the ceiling and the floor basically
4541640	4547000	in our society. The amount that we have to all live in together, the scale of cooperation
4547560	4553240	that is that is incentivized. And I will let you close the these sets of thoughts with your
4553240	4556520	optimistic spin on how we're eventually going to work our way out of this.
4557240	4560440	Well, you know, so as I said, you know, part one of the book lays it all out lays out the
4560440	4565960	science lays out the problem. But then part two is is exactly about, you know, how do we
4566280	4571640	do the chapter titles like how do we reunite humanity? How do we create a new forms of
4571640	4577000	governance for the 21st century? How do we shatter that glass ceiling of inequality?
4577000	4581800	How do we trigger a creative explosion that maybe gets us diffusion and becoming the first
4581800	4586440	generation of a galactic civilization? How do we improve the internet? How do we as individuals
4586440	4592360	become brighter? And because like imagine you are the first generation to have the periodic table,
4592360	4596680	right? We can stop doing alchemy, we start doing some chemistry. And there are actual
4597720	4602760	solutions, given the constraints that we face, real life solutions that are possible
4602760	4609000	for tackling each of these problems. And that means that a brighter future is possible if we so
4609000	4613720	choose. I cannot close on any better sentence than that. So Michael Muthukrishna, thanks
4613720	4625080	very much for being on the Mindscape podcast. Thank you so much for having me, Sean. I loved it.
