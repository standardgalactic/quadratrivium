1
00:00:00,000 --> 00:00:05,000
Hello, everyone, and welcome to the Mindscape Podcast. I'm your host, Sean Carroll.

2
00:00:05,000 --> 00:00:10,000
If any of you out there own a copy of my book, Something Deeply Hidden,

3
00:00:10,000 --> 00:00:15,000
you can go to the copyright page, the page right after the title page,

4
00:00:15,000 --> 00:00:20,000
where there's the copyright information, et cetera, printed in the United States of America, or whatever.

5
00:00:20,000 --> 00:00:27,000
There is a little notation on that page that gives the version number.

6
00:00:27,000 --> 00:00:31,000
And the version number is not your copy of the book personally.

7
00:00:31,000 --> 00:00:37,000
All of you and your friends and I and everyone else that we know has the same version number.

8
00:00:37,000 --> 00:00:48,000
And the version number is 756 trillion, 132 billion, 390 million, 815,553.

9
00:00:48,000 --> 00:00:53,000
If you know the story about what that version number is, when I wrote the book,

10
00:00:53,000 --> 00:01:02,000
I generated a quantum random number between one and a quadrillion, an integer.

11
00:01:02,000 --> 00:01:05,000
And that's what this version number is.

12
00:01:05,000 --> 00:01:13,000
If you believe or if you, for the moment, imagine that the world is described

13
00:01:13,000 --> 00:01:19,000
by the many worlds interpretation of quantum mechanics, which I explain and defend in the book,

14
00:01:19,000 --> 00:01:27,000
then there are different branches of the wave function with almost exactly the same book written in them,

15
00:01:27,000 --> 00:01:29,000
but different version numbers.

16
00:01:29,000 --> 00:01:36,000
Every different integer of that size is represented somewhere on the branches of the wave function of the universe,

17
00:01:36,000 --> 00:01:43,000
somewhere it's all zeros or all threes or whatever, and there's got to be some comment in that version of the book.

18
00:01:43,000 --> 00:01:46,000
Well, wow, I guess we got really unlucky about that.

19
00:01:46,000 --> 00:01:55,000
But this idea, this little joke that we sneaked into the book was supposed to be a way of really making you face up

20
00:01:55,000 --> 00:02:00,000
to the claims involved in the many worlds formulation of quantum mechanics.

21
00:02:00,000 --> 00:02:05,000
And those claims, I am very quick to admit, are weird.

22
00:02:05,000 --> 00:02:07,000
They are bizarre.

23
00:02:07,000 --> 00:02:15,000
The implications of the many worlds interpretation of quantum mechanics are very, very far away from our intuitive,

24
00:02:15,000 --> 00:02:18,000
everyday experience of the world.

25
00:02:18,000 --> 00:02:23,000
And some people will say, you know what, they're too far away.

26
00:02:23,000 --> 00:02:24,000
I'm just not going to go there.

27
00:02:24,000 --> 00:02:30,000
I do not believe there are a quadrillion different versions of something deeply hidden out there

28
00:02:30,000 --> 00:02:34,000
and some quantum multiverse with different version numbers in them.

29
00:02:34,000 --> 00:02:43,000
So what are we to do about that objection that this idea that many worlds interpretation of quantum mechanics is just too weird?

30
00:02:43,000 --> 00:02:48,000
Because quantum mechanics is not the only place where this issue arises.

31
00:02:48,000 --> 00:02:55,000
There are other attempts to make sense of the world, in other words, understand it even better than we do,

32
00:02:55,000 --> 00:03:01,000
that like it or not lead us to some place that seems bizarre and weird to us.

33
00:03:01,000 --> 00:03:06,000
That is the theme of Eric Schwitzgabel's new book.

34
00:03:06,000 --> 00:03:11,000
Eric is a philosopher at University of California Riverside,

35
00:03:11,000 --> 00:03:16,000
and he has a new book that is going to come out tomorrow by the day that this podcast gets released.

36
00:03:16,000 --> 00:03:19,000
And it is literally called The Weirdness of the World.

37
00:03:19,000 --> 00:03:29,000
And in this book, he basically faces up to the fact that some of our best attempts to make sense of the world end up looking pretty weird.

38
00:03:29,000 --> 00:03:34,000
In fact, he argues that in some cases, they're going to have to look pretty weird.

39
00:03:34,000 --> 00:03:39,000
There is no version of the correct theory that doesn't look weird to us.

40
00:03:39,000 --> 00:03:42,000
Now, weird is an interesting thing.

41
00:03:42,000 --> 00:03:47,000
Weird in his definition of it is a little bit different from bizarre.

42
00:03:47,000 --> 00:03:55,000
He defines bizarre to mean contrary to our common sense, and weird is a little bit stronger than that.

43
00:03:55,000 --> 00:03:58,000
It's contrary to our common sense in kind of an irrevocable way.

44
00:03:58,000 --> 00:04:01,000
It's not going to go away just because we understand it better.

45
00:04:01,000 --> 00:04:03,000
We're going to have to buy into it.

46
00:04:03,000 --> 00:04:07,000
So he talks about not only quantum mechanics, but consciousness is a big theme.

47
00:04:07,000 --> 00:04:13,000
All the different versions of consciousness theory, just like all the different versions of the foundations of quantum mechanics,

48
00:04:13,000 --> 00:04:16,000
Eric will argue, involve a certain degree of weirdness.

49
00:04:16,000 --> 00:04:23,000
And there's other weird things that may just be false, like maybe we live in a simulation or maybe we're brain in a vat or whatever.

50
00:04:23,000 --> 00:04:27,000
Maybe those you can dismiss, but what about when you can't dismiss it?

51
00:04:27,000 --> 00:04:33,000
What do you do when you need to balance different levels of weirdness of different kinds of theories?

52
00:04:33,000 --> 00:04:36,000
Should we just ignore the weird possibilities?

53
00:04:36,000 --> 00:04:39,000
Should we give substantial credence to them?

54
00:04:39,000 --> 00:04:44,000
Should we be more cautious when all the options on the table are pretty weird?

55
00:04:44,000 --> 00:04:55,000
So I like it as a work of philosophy that faces up to the real challenges that come along with taking seriously our best ways of understanding the world.

56
00:04:55,000 --> 00:05:01,000
So over the course of all our different podcasts here, we've gone to some pretty weird places we might as well celebrate it.

57
00:05:01,000 --> 00:05:02,000
Let's go.

58
00:05:19,000 --> 00:05:21,000
Eric Schwitzkable, welcome to the Mindscape podcast.

59
00:05:21,000 --> 00:05:23,000
Thanks for having me.

60
00:05:23,000 --> 00:05:30,000
So you've written a book about the weirdness of the world, which is just a great provocative title that I'm sure will give us a lot to talk about.

61
00:05:30,000 --> 00:05:38,000
But before we do that, I have to bring up a couple of things that you've also been involved with that are really interesting, but not on that topic.

62
00:05:38,000 --> 00:05:40,000
But I have to get them out of the way a little bit.

63
00:05:40,000 --> 00:05:43,000
One is virtual Dan Dennett.

64
00:05:43,000 --> 00:05:47,000
You know, we had Dan Dennett as a previous Mindscape guest.

65
00:05:47,000 --> 00:05:49,000
I think that's his claim to fame these days.

66
00:05:49,000 --> 00:05:56,000
But those are before the days when we had large language models and could just program up a Dan Dennett to interview.

67
00:05:56,000 --> 00:05:59,000
So you did that and did a little experiment.

68
00:05:59,000 --> 00:06:01,000
So tell us about that.

69
00:06:01,000 --> 00:06:03,000
Yeah, we sure did.

70
00:06:03,000 --> 00:06:09,000
So we did this, I should say, this is collaborative with Anna Strasser and my son, David Schwitzkable.

71
00:06:09,000 --> 00:06:15,000
And Matthew Crosby was a collaborator earlier on, but he had to leave to work for DeepMind.

72
00:06:15,000 --> 00:06:17,000
That happens, yeah.

73
00:06:17,000 --> 00:06:21,000
So we couldn't publish something using open AI technology.

74
00:06:21,000 --> 00:06:26,000
I'm sure he's handsomely compensated for his problems.

75
00:06:26,000 --> 00:06:30,000
He was involved early on and actually did some of the fine tuning.

76
00:06:30,000 --> 00:06:37,000
So people know chat GPT, probably most of your listeners know where this is a large language model.

77
00:06:37,000 --> 00:06:38,000
It can produce texts.

78
00:06:38,000 --> 00:06:40,000
It's very human-like.

79
00:06:40,000 --> 00:06:48,000
A precursor to that that came out, I think, in 2020 was GPT-3.

80
00:06:48,000 --> 00:06:54,000
And one of the things that you could do with GPT-3 was you could fine tune it on a corpus of text.

81
00:06:54,000 --> 00:06:59,000
So it's basically, it consumes large portions of the internet.

82
00:06:59,000 --> 00:07:03,000
And from this, it can predict the next word when you input likely text.

83
00:07:03,000 --> 00:07:07,000
So when you fine tune it, what you do is you add some more corpus.

84
00:07:07,000 --> 00:07:16,000
And then it readjusts its weights so that its outputs look like a compromise between what it is in its original state

85
00:07:16,000 --> 00:07:20,000
and the corpus that you've input, you fine-tuned it on.

86
00:07:20,000 --> 00:07:27,000
So what we did was we took GPT-3 and we fine-tuned it on the corpus of Dan Dennett, about 2 million words.

87
00:07:27,000 --> 00:07:35,000
Most of his, I don't know how many books he has, in the teens, in articles, we just pumped them into GPT.

88
00:07:35,000 --> 00:07:40,000
And then what we did was we asked the actual Dan Dennett 10 philosophical questions

89
00:07:40,000 --> 00:07:46,000
and we asked our fine-tuned model, we called DigiDan, the same 10 questions.

90
00:07:46,000 --> 00:07:48,000
We did it four times.

91
00:07:48,000 --> 00:07:52,000
We got four answers from each of the DigiDans.

92
00:07:52,000 --> 00:07:57,000
We didn't do any cherry picking of those answers to see for quality.

93
00:07:57,000 --> 00:08:00,000
We did make sure that they were sufficient length.

94
00:08:00,000 --> 00:08:02,000
So we excluded short answers.

95
00:08:02,000 --> 00:08:06,000
We wanted length similar to Dennett's own answers.

96
00:08:06,000 --> 00:08:09,000
And then what we did was we took experts in Dennett's work and we said,

97
00:08:09,000 --> 00:08:14,000
hey, could you guess which is Dennett's real answer and which has come from the model?

98
00:08:14,000 --> 00:08:17,000
So chance would have been 20%.

99
00:08:17,000 --> 00:08:20,000
The experts got it about 50%, right?

100
00:08:20,000 --> 00:08:27,000
So they did better than chance, but still half the time they chose the model's answer over Dennett's answers.

101
00:08:27,000 --> 00:08:34,000
And on two of the questions, the plurality of experts actually chose one of the model's answers over Dennett's answer.

102
00:08:34,000 --> 00:08:38,000
And on one of the questions, Dennett said, you know what?

103
00:08:38,000 --> 00:08:41,000
I kind of see why the experts chose that answer over my own answer.

104
00:08:41,000 --> 00:08:44,000
If I'd thought about it more, I should have said something different.

105
00:08:44,000 --> 00:08:51,000
Arguably, on one question, the model actually outperformed Dan himself.

106
00:08:51,000 --> 00:08:53,000
So anyway, that was our experiment.

107
00:08:53,000 --> 00:08:56,000
We wrote it up, we published it, and it was a lot of fun.

108
00:08:56,000 --> 00:09:01,000
And when you did it, it was only a short while ago, but probably it was much more surprising at the time.

109
00:09:01,000 --> 00:09:08,000
It wasn't quite as public the whole excitement these days about Lore's language models.

110
00:09:08,000 --> 00:09:09,000
That's right.

111
00:09:09,000 --> 00:09:12,000
We actually ran the experiment before ChatGPT was released.

112
00:09:12,000 --> 00:09:20,000
And so people were getting the wind about the power of GPT-3, but it wasn't quite the phenomenon that it has since become.

113
00:09:20,000 --> 00:09:29,000
And just as a technical matter, when you download this corpus, does that mean you had to have electronic copies of all of Dan's writings?

114
00:09:29,000 --> 00:09:33,000
Did he help you with that, or did you just pirate a book or get a Kindle edition?

115
00:09:33,000 --> 00:09:38,000
He helped us with this, and he collaborated with us on the project throughout.

116
00:09:39,000 --> 00:09:51,000
And Anna Strosser did a huge amount of work converting these old PDFs and junky files into clean text that could be uploaded into the model.

117
00:09:51,000 --> 00:09:52,000
But you've written things.

118
00:09:52,000 --> 00:09:53,000
You have a blog.

119
00:09:53,000 --> 00:09:56,000
Have you been tempted to do this for yourself, too?

120
00:09:56,000 --> 00:09:58,000
Does that save you time?

121
00:09:58,000 --> 00:09:59,000
Yes.

122
00:09:59,000 --> 00:10:04,000
Actually, the first thing we did was we uploaded my blog into this.

123
00:10:04,000 --> 00:10:14,000
So this didn't become a publication, but we uploaded my blog into GPT-3 kind of lower power version of it.

124
00:10:14,000 --> 00:10:19,000
Actually, not the Da Vinci model, but the Curie model, which is a slightly lower powered version.

125
00:10:19,000 --> 00:10:22,000
And then we had it produce blog posts in the style.

126
00:10:22,000 --> 00:10:30,000
And so readers can go if they want, look on my blog, the Splintered Mind, and they can see the GPT-generated blog posts, which were actually pretty interesting.

127
00:10:31,000 --> 00:10:36,000
I think I write blog posts better, but it was kind of cool.

128
00:10:36,000 --> 00:10:37,000
Yeah.

129
00:10:37,000 --> 00:10:46,000
And at the time that we did this, it was not generally well known that GPT could create well-structured answers over long strings of text.

130
00:10:46,000 --> 00:10:50,000
I mean, if you're thinking, it essentially does next word prediction.

131
00:10:50,000 --> 00:10:58,000
So you would kind of think it would lose the thread of ideas over time and wouldn't be able to create a well-structured argument that runs for paragraphs.

132
00:10:58,000 --> 00:11:01,000
Anyway, that's kind of what we thought, but it was surprising.

133
00:11:01,000 --> 00:11:16,000
One of the blog posts was, I think, not a convincing argument, but at least it had a kind of philosophical argumentative structure over the course of several paragraphs, which we found really interesting and surprising, given the basic structure of these models.

134
00:11:16,000 --> 00:11:20,000
Clearly, GPT does have some memory of what it's recently said, right?

135
00:11:20,000 --> 00:11:23,000
It's not literally going from one word to another.

136
00:11:23,000 --> 00:11:24,000
Right.

137
00:11:24,000 --> 00:11:34,000
It's got a window of, I forget how, something like a thousand tokens, and a token's like three-quarters of a word, something in that ballpark.

138
00:11:34,000 --> 00:11:35,000
So yes.

139
00:11:35,000 --> 00:11:43,000
So did you give it topics for those blog posts, or did you just say write another blog post that would fit in here?

140
00:11:43,000 --> 00:11:49,000
We gave it titles, and then it wrote the post given the title, yeah.

141
00:11:49,000 --> 00:11:50,000
This is very scary.

142
00:11:50,000 --> 00:11:55,000
Do you think that the world is going to change dramatically because of this technology?

143
00:11:55,000 --> 00:11:56,000
Yes.

144
00:11:56,000 --> 00:11:57,000
Yeah.

145
00:11:57,000 --> 00:11:58,000
Okay.

146
00:11:58,000 --> 00:12:00,000
It's hard to know exactly how it's going to change.

147
00:12:00,000 --> 00:12:01,000
Hard to know how.

148
00:12:01,000 --> 00:12:02,000
Right.

149
00:12:02,000 --> 00:12:03,000
Yeah.

150
00:12:03,000 --> 00:12:04,000
Okay.

151
00:12:04,000 --> 00:12:05,000
But for sure, it's going to change.

152
00:12:05,000 --> 00:12:07,000
So that was one thing I wanted to get out of the way.

153
00:12:07,000 --> 00:12:21,000
The other one, which I only found when I saw your Wikipedia page, is that you were one of the people involved in asking the questions, are ethicists, especially ethical, or does studying moral philosophy make you a more moral person?

154
00:12:21,000 --> 00:12:23,000
Is that right?

155
00:12:23,000 --> 00:12:24,000
Yeah.

156
00:12:24,000 --> 00:12:28,000
Arguably, I'm the world's foremost expert on the moral behavior of ethics professors.

157
00:12:28,000 --> 00:12:32,000
And what are your conclusions about this?

158
00:12:32,000 --> 00:12:49,000
Well, I've done a fair number of empirical studies on this, and what I found over and over again, almost without exception, is that they behave about the same as comparison groups of other professors.

159
00:12:49,000 --> 00:12:54,000
So sometimes we do the comparison group would be other philosophers who don't specialize in ethics.

160
00:12:54,000 --> 00:13:01,000
Sometimes the comparison group is other professors at the same university in different departments.

161
00:13:02,000 --> 00:13:09,000
There have been a couple studies where we found a little bit worse or a little bit better behavior in some respects for ethicists.

162
00:13:09,000 --> 00:13:15,000
But generally speaking, it's a big null result.

163
00:13:15,000 --> 00:13:16,000
Well, okay.

164
00:13:16,000 --> 00:13:30,000
You just find they behave the same as other people, which I think is kind of interesting because you might have thought that ethicists would reflect on ethics and then behave differently as a result of their reflections.

165
00:13:30,000 --> 00:13:35,000
And mostly that seems not to be the case.

166
00:13:35,000 --> 00:13:46,000
One particularly interesting example of this is with respect to vegetarianism because ethicists on some issues will embrace more demanding moral standards.

167
00:13:46,000 --> 00:13:54,000
So for example, ethicists are much more likely than professors in departments other than philosophy, where they were in 2009 when we collected these data.

168
00:13:54,000 --> 00:14:01,000
To say that it's bad to eat meat, bad to eat the meat of mammals in particular is what we asked about.

169
00:14:01,000 --> 00:14:09,000
And yet in our research, we found them just as likely to report having eaten meat at their previous evening meal.

170
00:14:09,000 --> 00:14:11,000
Now, is that correlated?

171
00:14:11,000 --> 00:14:17,000
I mean, are the people who say it is bad to eat meat also eating the meat?

172
00:14:17,000 --> 00:14:18,000
Right.

173
00:14:18,000 --> 00:14:20,000
It had the correlation, they would think.

174
00:14:20,000 --> 00:14:25,000
So the people who, we gave them a nine point scale from very morally bad to very morally good.

175
00:14:25,000 --> 00:14:36,000
And the people who ticked one or two very morally bad or one tick toward good from that, few of them reported having eaten meat at their previous evening meal.

176
00:14:36,000 --> 00:14:47,000
But the ones who ticked three or four on our nine point scale, which was a lot of ethicists, seemed basically just as likely to have reported eating meat.

177
00:14:47,000 --> 00:14:55,000
So there was a individual, there was a kind of correlation between the strength of the opinion and the self reported eating.

178
00:14:55,000 --> 00:14:57,000
But there wasn't the group difference that we expected.

179
00:14:57,000 --> 00:14:58,000
Right.

180
00:14:58,000 --> 00:15:05,000
So ethicists as a group said the majority, 60% said it was morally bad.

181
00:15:05,000 --> 00:15:16,000
But I don't know, 30 some percent of them reported having done at their previous evening meal nonetheless compared to I think was 38% of ethicists.

182
00:15:16,000 --> 00:15:21,000
And 37% of ethicists and 38% of respondents overall.

183
00:15:21,000 --> 00:15:29,000
So if this is a surprising result, which I'll entertain the possibility that it is, what's your theoretical understanding of what's going on?

184
00:15:29,000 --> 00:15:35,000
Is it just that ethicists are better at arguing about ethics, but not actually better at being ethical?

185
00:15:35,000 --> 00:15:40,000
Is there a different kind of study that would make you better at ethics?

186
00:15:40,000 --> 00:15:42,000
Is it like coaching versus playing a sport?

187
00:15:43,000 --> 00:15:48,000
Yeah, I think coaching versus playing is an interesting comparison.

188
00:15:48,000 --> 00:15:55,000
We don't hire ethicists to be saints, just like we don't hire coaches to be football stars.

189
00:15:55,000 --> 00:15:56,000
Yeah.

190
00:15:56,000 --> 00:16:05,000
And yet you would expect if you took a coach and a random member of the population of the same age and gender and put them on a football field together,

191
00:16:05,000 --> 00:16:11,000
you would expect the coach would still outperform, even if the coach is not a superstar.

192
00:16:12,000 --> 00:16:13,000
Right.

193
00:16:13,000 --> 00:16:20,000
So I think that's an interesting comparison that reveals partly why you might think it's still a little surprising,

194
00:16:20,000 --> 00:16:25,000
even if we don't hold ethicists to saint-like standards.

195
00:16:25,000 --> 00:16:32,000
I mean, in the vegetarianism results again, I think that strikes people as somewhat surprising.

196
00:16:32,000 --> 00:16:33,000
Yeah.

197
00:16:33,000 --> 00:16:43,000
So one of the things that I draw from this is it fits with a view I have about moral psychology.

198
00:16:43,000 --> 00:16:47,000
I suspect that real answer is complex and multi-causal.

199
00:16:47,000 --> 00:16:56,000
But one of the things I think it fits pretty well with is the idea that people in general aim to be morally mediocre.

200
00:16:56,000 --> 00:16:57,000
Okay.

201
00:16:57,000 --> 00:17:06,000
So my inclination is to think, and this is grounded both in personal experience and in reading social and moral psychology,

202
00:17:06,000 --> 00:17:13,000
that people don't generally aim to be good or bad by absolute standards.

203
00:17:13,000 --> 00:17:19,000
Instead, they aim to be about as morally good as their peers.

204
00:17:19,000 --> 00:17:26,000
They don't want to make the sacrifices that would be involved in being very morally better.

205
00:17:26,000 --> 00:17:29,000
But they also don't want to be the worst in the bunch.

206
00:17:29,000 --> 00:17:30,000
Interesting.

207
00:17:30,000 --> 00:17:33,000
So people aim for peer-relative moral standards.

208
00:17:33,000 --> 00:17:38,000
So if you think about that from the point of view of thinking philosophically about ethics,

209
00:17:38,000 --> 00:17:43,000
maybe what you do when you think about ethics is you discover moral truths,

210
00:17:43,000 --> 00:17:46,000
like maybe you discover it's bad to eat the meat of mammals.

211
00:17:46,000 --> 00:17:53,000
But if you're aiming just for peer-relative goodness, your peers are still eating meat.

212
00:17:53,000 --> 00:17:59,000
So what happens is your opinion about your peers' moral behavior and your own moral behavior goes down,

213
00:17:59,000 --> 00:18:02,000
but your behavior doesn't change.

214
00:18:02,000 --> 00:18:12,000
That's actually very nicely consonant with other podcasts I've done recently about other aspects of things like psychology or even epistemology,

215
00:18:12,000 --> 00:18:17,000
having much more of a social slant than we would expect.

216
00:18:17,000 --> 00:18:24,000
Brian Lowry explained to us how our sense of selves serves mostly as social function.

217
00:18:24,000 --> 00:18:30,000
Hugo Mercier explained how our use of reasons serves largely as social function.

218
00:18:30,000 --> 00:18:38,000
And you're saying that there's a very big social function that is served by our ethical practice at any rate.

219
00:18:38,000 --> 00:18:40,000
Yeah, right. Absolutely.

220
00:18:40,000 --> 00:18:42,000
Social animals. There we are.

221
00:18:42,000 --> 00:18:50,000
But I guess this does segue even more smoothly than I thought it would into the weirdness of the world,

222
00:18:50,000 --> 00:18:55,000
because when you say the world is weird and now we're going to get into the topic of your book,

223
00:18:55,000 --> 00:19:01,000
immediately part of me wants to say, come on, the world can't be weird.

224
00:19:01,000 --> 00:19:02,000
It's the world.

225
00:19:02,000 --> 00:19:07,000
What we're seeing is a mismatch between our expectations and the world,

226
00:19:07,000 --> 00:19:10,000
and maybe those can be colored somehow.

227
00:19:10,000 --> 00:19:14,000
So what is the title of your book mean?

228
00:19:14,000 --> 00:19:15,000
Right.

229
00:19:15,000 --> 00:19:17,000
So, yeah, you're right.

230
00:19:17,000 --> 00:19:20,000
It's not that the world is intrinsically weird.

231
00:19:20,000 --> 00:19:23,000
I'm not sure what that would mean.

232
00:19:23,000 --> 00:19:31,000
The idea of weirdness or bizarreness, which is a closely related idea in my book,

233
00:19:31,000 --> 00:19:43,000
involves violating our expectations or our standards or a sense of what's normal or violating a common sense.

234
00:19:43,000 --> 00:19:53,000
So when I say that the world is weird, I mean something like our common sense understandings of how the world is

235
00:19:53,000 --> 00:19:59,000
are going to be sharply violated by how the world actually is.

236
00:20:00,000 --> 00:20:02,000
That's the bizarreness element.

237
00:20:02,000 --> 00:20:08,000
And then there's also an element which I call dubiety, which is that, and all of our answers to this are dubious.

238
00:20:08,000 --> 00:20:15,000
It's not like, oh, well, it violates common sense, but we perfectly well understand it.

239
00:20:15,000 --> 00:20:22,000
It's also a dimension of weirdness is that it kind of exceeds our ability to fully comprehend.

240
00:20:22,000 --> 00:20:23,000
Right.

241
00:20:23,000 --> 00:20:30,000
The example you gave in the book is special relativity, which tells us various things that happen at the speed of light

242
00:20:30,000 --> 00:20:31,000
might seem bizarre to us.

243
00:20:31,000 --> 00:20:35,000
It's anti-common sensical, but it's not weird in the same sense.

244
00:20:35,000 --> 00:20:38,000
We can fully understand it once we learn what's going on.

245
00:20:38,000 --> 00:20:39,000
Correct.

246
00:20:39,000 --> 00:20:42,000
So special relativity is a nice example of something that's highly bizarre.

247
00:20:42,000 --> 00:20:47,000
It violates common sense, but it's not dubious.

248
00:20:48,000 --> 00:20:53,000
The full weirdness thesis also involves this dubiety claim.

249
00:20:53,000 --> 00:20:54,000
Yeah.

250
00:20:54,000 --> 00:20:58,000
You use the word dubiety in your book much more often than I've ever seen it used before.

251
00:20:58,000 --> 00:21:08,000
So just to let people know, it's the existence of, or I guess, the claim that you should be dubious about something.

252
00:21:08,000 --> 00:21:09,000
Right.

253
00:21:09,000 --> 00:21:11,000
That doubt is justified.

254
00:21:11,000 --> 00:21:12,000
Doubt is justified.

255
00:21:12,000 --> 00:21:13,000
Good.

256
00:21:13,000 --> 00:21:22,000
So the name, the URL of my personal website is preposterousuniverse.com for exactly the same reason.

257
00:21:22,000 --> 00:21:29,000
It came out of thinking about naturalness and cosmology and the cosmological constant and the fact that the universe is surprising to us.

258
00:21:29,000 --> 00:21:37,000
And it's funny because I get critics, you know, the usual crackpot on the street with opinions about cosmology saying,

259
00:21:37,000 --> 00:21:39,000
No, Sean Carroll thinks the universe is preposterous.

260
00:21:39,000 --> 00:21:42,000
He doesn't realize that it's just our ideas that are wrong.

261
00:21:42,000 --> 00:21:45,000
But I'm trying to say, like, no, that's the point.

262
00:21:45,000 --> 00:21:48,000
I don't think the universe is making a mistake.

263
00:21:48,000 --> 00:21:50,000
It's definitely we are making a mistake.

264
00:21:50,000 --> 00:21:54,000
That's the whole message that is trying to get across.

265
00:21:54,000 --> 00:21:55,000
Exactly.

266
00:21:55,000 --> 00:21:56,000
And I like the word preposterous too.

267
00:21:56,000 --> 00:22:03,000
I was flirting with just borrowing that word from you, but I decided I liked weirdness a little bit better.

268
00:22:03,000 --> 00:22:06,000
Weirdness works, especially weirdness of the world, the alliteration, etc.

269
00:22:07,000 --> 00:22:13,000
OK, so is then let's take the universe's point of view here.

270
00:22:13,000 --> 00:22:18,000
You know, why is it our fault that the universe looks weird to us?

271
00:22:18,000 --> 00:22:27,000
Is there something about us that is, despite the fact that we're part of the world that kind of doesn't quite match on to what we see out there in principle?

272
00:22:27,000 --> 00:22:28,000
Right.

273
00:22:28,000 --> 00:22:35,000
Well, I'm inclined to think that our theories and our common sense.

274
00:22:35,000 --> 00:22:37,000
Well, especially our common sense.

275
00:22:37,000 --> 00:22:38,000
Let's start with that.

276
00:22:38,000 --> 00:22:47,000
Our common sense is trained upon, built upon a very limited range of experiences.

277
00:22:47,000 --> 00:22:48,000
Yeah.

278
00:22:48,000 --> 00:22:49,000
Right.

279
00:22:49,000 --> 00:22:58,000
So with respect to big picture cosmology, right, it's relatively low energy, middle sized, slow moving moving stuff on Earth.

280
00:22:58,000 --> 00:22:59,000
Right.

281
00:22:59,000 --> 00:23:00,000
And that's what we're good at.

282
00:23:00,000 --> 00:23:02,000
That's what we evolve to be good at.

283
00:23:02,000 --> 00:23:04,000
That's what the social pressures and learning environment is.

284
00:23:04,000 --> 00:23:10,000
Makes us good at you take something at a very different scale, much larger, much smaller, much more energetic.

285
00:23:10,000 --> 00:23:22,000
And those aren't the kinds of things that there's any particularly good evolutionary or developmental or social reason to think we would have well tuned common sense judgments about.

286
00:23:22,000 --> 00:23:32,000
So in other words, the way that I've said similar things in some cases, we have, we only experience a tiny fraction of what the world is.

287
00:23:32,000 --> 00:23:35,000
And but we make efforts to experience more and more of it.

288
00:23:35,000 --> 00:23:36,000
And guess what?

289
00:23:36,000 --> 00:23:38,000
It looks different and surprising to us.

290
00:23:38,000 --> 00:23:39,000
Yes.

291
00:23:39,000 --> 00:23:41,000
I completely agree with that.

292
00:23:41,000 --> 00:23:48,000
So I think the same is true for our understanding of consciousness, although less, less obviously so.

293
00:23:48,000 --> 00:23:49,000
Right.

294
00:23:49,000 --> 00:23:59,000
So the thesis of the weirdness of the world is partly about large big picture cosmological issues.

295
00:23:59,000 --> 00:24:02,000
It's also equally or even more about consciousness.

296
00:24:02,000 --> 00:24:03,000
Yeah.

297
00:24:03,000 --> 00:24:04,000
Right.

298
00:24:04,000 --> 00:24:17,000
So again, with respect to issues of consciousness, we're familiar with the human case and with, you know, certain familiar vertebrates we like.

299
00:24:17,000 --> 00:24:21,000
And that's about what we know about consciousness.

300
00:24:21,000 --> 00:24:26,000
And we have not had experience, for example, with sophisticated AI systems.

301
00:24:26,000 --> 00:24:27,000
Yeah.

302
00:24:27,000 --> 00:24:36,000
So we shouldn't expect particularly to have well tuned common sensical intuitions about such things.

303
00:24:36,000 --> 00:24:37,000
Good.

304
00:24:37,000 --> 00:24:46,000
And so in some sense, I don't want to put words in your mouth, but it seems to me that the model of your book should be that you're asking us to be courageous.

305
00:24:46,000 --> 00:25:02,000
To say, you know, we should expect that as we learn more and more about the world, we'll find that what we're learning seems weird to us and we need to develop tools and techniques to deal with that and handle it.

306
00:25:02,000 --> 00:25:04,000
Yeah, absolutely.

307
00:25:04,000 --> 00:25:14,000
And yeah, I guess that's in a sense courageous, although I'm not sure that's the word I would use.

308
00:25:14,000 --> 00:25:17,000
I like the word wonderful instead.

309
00:25:17,000 --> 00:25:18,000
Okay.

310
00:25:18,000 --> 00:25:23,000
Because it's got this, it's got to the idea of wonderful, it's got two dimensions to it, right?

311
00:25:23,000 --> 00:25:31,000
So it's got the root sense of wonder, right, that we live in a world that promotes wonder in us.

312
00:25:31,000 --> 00:25:38,000
And wonderful, of course, is also something like a synonym for one for good.

313
00:25:38,000 --> 00:25:45,000
So I think that's a good thing about the world that it's going to defies our understanding.

314
00:25:45,000 --> 00:26:00,000
So you have lessons and nostrums that we should get from contemplating the weirdness of the world, but I thought that maybe we could just go through some examples, really think about them in depth, and that will help us extract what these lessons are.

315
00:26:00,000 --> 00:26:10,000
And as you said, consciousness is a big one, but I first wanted to just talk about the existence of the external world, you know, these radically skeptical scenarios.

316
00:26:10,000 --> 00:26:17,000
Like you talk a lot about, are we sure that we're awake, for example.

317
00:26:17,000 --> 00:26:19,000
So give us the general lay of the land here.

318
00:26:19,000 --> 00:26:25,000
Like how do you think about these skeptical possibilities and what are your favorite ones?

319
00:26:25,000 --> 00:26:27,000
Right.

320
00:26:27,000 --> 00:26:34,000
So you have a few different chapters where I tangle with these skeptical possibilities in different ways.

321
00:26:34,000 --> 00:26:37,000
The dream argument, of course, is a famous one.

322
00:26:37,000 --> 00:26:39,000
That's the one that you started with.

323
00:26:39,000 --> 00:26:44,000
But I'm also interested in the simulation hypothesis, the idea that we might be living in a simulation.

324
00:26:44,000 --> 00:26:51,000
The Boltzmann brain idea, which you, of course, talked about in your work very wonderfully.

325
00:26:51,000 --> 00:26:59,000
And, you know, just the idea that even the idea that the universe might consist wholly of my own mind and nothing else.

326
00:26:59,000 --> 00:27:00,000
Right.

327
00:27:00,000 --> 00:27:04,000
So I talk about all of those possibilities in the book.

328
00:27:04,000 --> 00:27:08,000
But we could start with the dream one, which is maybe the most familiar one.

329
00:27:08,000 --> 00:27:09,000
Sure.

330
00:27:09,000 --> 00:27:18,000
So this goes back in philosophy all the way at least to the ancient Chinese philosopher Zhuangze, although, of course, Descartes makes famous use of it.

331
00:27:18,000 --> 00:27:19,000
Right.

332
00:27:19,000 --> 00:27:27,000
The idea is how do you know, if you do know, that you're not currently dreaming right now?

333
00:27:27,000 --> 00:27:34,000
And normally we think we feel pretty confident that we're awake.

334
00:27:34,000 --> 00:27:39,000
At least if you ask a waking person, if they're confident they're awake, they'll tend to say yes.

335
00:27:39,000 --> 00:27:40,000
Yeah.

336
00:27:40,000 --> 00:27:43,000
But what justifies that?

337
00:27:43,000 --> 00:27:47,000
And I think there are a few ways it could be justified.

338
00:27:47,000 --> 00:27:58,000
I think there are some empirical features of dreams that make them different from waking life.

339
00:27:58,000 --> 00:28:06,000
So, for example, I think of waking sensory experience as pretty richly detailed and pretty stable.

340
00:28:06,000 --> 00:28:18,000
Whereas the experiences we have in dreams, arguably, are less detailed, kind of sketchier, more image-like, less stable.

341
00:28:18,000 --> 00:28:21,000
Do you know this claim that in dream?

342
00:28:21,000 --> 00:28:22,000
Go ahead.

343
00:28:22,000 --> 00:28:31,000
There's a claim that I think actually has some backing, but I'm not sure how right it is, that you can't read text in dreams.

344
00:28:31,000 --> 00:28:33,000
The text does not look like text.

345
00:28:33,000 --> 00:28:40,000
It looks like that sort of bad AI text that's sort of like letter-like without actually having any meaning.

346
00:28:40,000 --> 00:28:44,000
Yes, that is sometimes called a dream sign.

347
00:28:44,000 --> 00:28:49,000
These are hypothesized tests for whether you're dreaming or not.

348
00:28:49,000 --> 00:28:52,000
So, look at text and see if it's stable and if you can read it.

349
00:28:52,000 --> 00:28:56,000
And some people think of that as, for themselves, a good dream sign.

350
00:28:56,000 --> 00:29:02,000
But of course, there are also dream reports in which people report reading stable text, so it's not universally accepted.

351
00:29:03,000 --> 00:29:17,000
So, I think that if we accept this fact about the stability of text as maybe, at least in the majority of dreams, you can't have a stable text,

352
00:29:17,000 --> 00:29:24,000
that creates some evidence that I'm not dreaming right now.

353
00:29:24,000 --> 00:29:36,000
But a lot of dream researchers, including, for example, Jennifer Vint, who I think is really amazingly knowledgeable about this kind of stuff,

354
00:29:36,000 --> 00:29:46,000
think that we do often in dreams have stable experiences that are a lot like waking life,

355
00:29:46,000 --> 00:29:51,000
maybe even experientially indistinguishable from waking life.

356
00:29:51,000 --> 00:29:58,000
Even boring mundane experiences like that of listening to a podcast.

357
00:29:58,000 --> 00:30:03,000
That's a very exciting experience, Eric.

358
00:30:04,000 --> 00:30:14,000
And so, if we think that there are some dreams like this, or if we invest some credence in a theory of dreaming,

359
00:30:14,000 --> 00:30:23,000
according to which there are either often, or at least sometimes, experiences like I'm having right now,

360
00:30:23,000 --> 00:30:31,000
or like your listeners or you are having right now, in dreams, then it becomes kind of less experientially obvious.

361
00:30:31,000 --> 00:30:44,000
Okay, I can't now be sure that I'm not dreaming based on what seems to be this stable experience that I'm having right now,

362
00:30:44,000 --> 00:30:46,000
of seeming to be awake.

363
00:30:46,000 --> 00:30:52,000
And of course, lots of people, including me and probably most of your listeners,

364
00:30:52,000 --> 00:30:58,000
have had false awakening experiences where you kind of seem to wake up and think,

365
00:30:58,000 --> 00:31:04,000
oh, I just had a dream, now I'm awake, right, and then you wake up again.

366
00:31:04,000 --> 00:31:13,000
So there are reasons, I think, not to be perfectly certain that you are not dreaming right now.

367
00:31:13,000 --> 00:31:21,000
Is it also worth contemplating a kind of inception scenario where we're all dreaming?

368
00:31:21,000 --> 00:31:31,000
There's a more awake version of us that dreams like our existence, pretty detailed, we can read text, etc.,

369
00:31:31,000 --> 00:31:38,000
and then we dream that we are dreaming in this fuzzier way, right?

370
00:31:38,000 --> 00:31:49,000
I think that's possible, but I want to draw a distinction between what I think of as grounded and ungrounded skepticism.

371
00:31:49,000 --> 00:31:57,000
So ungrounded skepticism says, well, I could be a brain in a vat, and then I wouldn't be able to tell the difference.

372
00:31:57,000 --> 00:31:59,000
So can I really rule that out?

373
00:31:59,000 --> 00:32:08,000
An ungrounded dream skepticism could be like, oh, well, maybe we're in an inception scenario.

374
00:32:08,000 --> 00:32:16,000
Grounded skepticism starts with our ordinary background assumptions and says,

375
00:32:16,000 --> 00:32:23,000
looking at these assumptions, there's some positive reason to give some credence to skeptical doubt, right?

376
00:32:23,000 --> 00:32:31,000
So there's no real positive reason to think that you're a brain in a vat to assign that any more than the most trivial likelihood, right?

377
00:32:31,000 --> 00:32:40,000
There's no positive reason to think we're in an inception scenario, but there is positive reason to think that this experience might be a dream experience.

378
00:32:40,000 --> 00:32:48,000
Once we start thinking about the nature of dream experiences and weather experiences like this, at least maybe sometimes occur in dreams,

379
00:32:48,000 --> 00:32:52,000
at least according to some theories that might be true, right?

380
00:32:52,000 --> 00:32:59,000
So I prefer to focus on these grounded kind of sources of skepticism.

381
00:32:59,000 --> 00:33:06,000
So I think it's not just, I mean, one of the critiques that philosophers sometimes give with skepticism is you could cook up anything.

382
00:33:06,000 --> 00:33:09,000
There's no reason for us to take it seriously.

383
00:33:09,000 --> 00:33:13,000
Whereas I think with dream skepticism, given the fact that we dream every night,

384
00:33:13,000 --> 00:33:21,000
given that theories of dreams, at least some mainstream theories of dreams postulate that we have experiences like this in our sleep,

385
00:33:21,000 --> 00:33:23,000
that creates grounds for doubt.

386
00:33:23,000 --> 00:33:26,000
It's not completely just cooked up out of nothing.

387
00:33:26,000 --> 00:33:34,000
Maybe you can add to that the idea that at least most of the time while we're dreaming, we don't think of ourselves as dreaming.

388
00:33:34,000 --> 00:33:35,000
Right?

389
00:33:35,000 --> 00:33:36,000
Most of the time.

390
00:33:36,000 --> 00:33:39,000
Of course, there are some so-called lucid dreams.

391
00:33:39,000 --> 00:33:47,000
And it is the case that if you can get yourself in the habit of thinking,

392
00:33:47,000 --> 00:33:54,000
am I awake so much that that thought starts to come to you while you're actually dreaming,

393
00:33:54,000 --> 00:33:59,000
then that's one way to discover that you're dreaming and start to have lucid dreams.

394
00:33:59,000 --> 00:34:00,000
I'm very bad at remembering.

395
00:34:00,000 --> 00:34:04,000
Even in the dream, sometimes people will say, am I dreaming and then decide,

396
00:34:04,000 --> 00:34:06,000
no, I'm not dreaming, even though they really are.

397
00:34:06,000 --> 00:34:09,000
That's just what I was going to ask because I was just going to say,

398
00:34:09,000 --> 00:34:11,000
I don't remember my own dreams very well at all,

399
00:34:11,000 --> 00:34:15,000
but I don't have any memory of ever being in a dream saying,

400
00:34:15,000 --> 00:34:17,000
I wonder if I'm in a dream and then going,

401
00:34:17,000 --> 00:34:19,000
nope, I don't think I am.

402
00:34:19,000 --> 00:34:23,000
But you're saying other people have reported that experience.

403
00:34:23,000 --> 00:34:26,000
Yes, that's definitely not an uncommon experience.

404
00:34:26,000 --> 00:34:27,000
All right.

405
00:34:28,000 --> 00:34:32,000
It could be the case that the majority of times when people are dreaming

406
00:34:32,000 --> 00:34:34,000
and think to themselves explicitly, am I dreaming?

407
00:34:34,000 --> 00:34:36,000
They come to realize they are,

408
00:34:36,000 --> 00:34:39,000
but it's not clear that that's the majority.

409
00:34:39,000 --> 00:34:42,000
And even if it is, it's not an overwhelming majority.

410
00:34:42,000 --> 00:34:45,000
Yeah, okay, good.

411
00:34:45,000 --> 00:34:48,000
Let's just go through some of the other famous ones

412
00:34:48,000 --> 00:34:53,000
because you draw a very interesting distinction between grounded and ungrounded skeptical scenarios.

413
00:34:53,000 --> 00:34:56,000
What are some of the other skeptical scenarios

414
00:34:56,000 --> 00:34:59,000
you would classify as grounded, in other words, worthy of our attention?

415
00:34:59,000 --> 00:35:03,000
So I find the simulation hypothesis pretty interesting.

416
00:35:03,000 --> 00:35:07,000
So this is the idea that we might be artificial intelligences

417
00:35:07,000 --> 00:35:12,000
living inside a simulated reality, kind of like the matrix.

418
00:35:12,000 --> 00:35:15,000
Except in the matrix, they're really biological bodies,

419
00:35:15,000 --> 00:35:17,000
but you might, you could have a matrix type scenario

420
00:35:17,000 --> 00:35:23,000
where the confused entities are AI systems, right?

421
00:35:23,000 --> 00:35:26,000
Or you could imagine the video game, the Sims,

422
00:35:26,000 --> 00:35:29,000
with these artificial simulated people going around these environments,

423
00:35:29,000 --> 00:35:31,000
except the Sims are really conscious.

424
00:35:31,000 --> 00:35:35,000
There's a couple of ways of thinking about the simulation hypothesis, right?

425
00:35:35,000 --> 00:35:42,000
So Nick Bostrom has a famous argument that gives us some grounds

426
00:35:42,000 --> 00:35:47,000
for thinking it's at least possible that we are Sims, right?

427
00:35:47,000 --> 00:35:56,000
So the idea here would be that it's not ridiculous to think

428
00:35:56,000 --> 00:36:03,000
that consciousness could arise in artificially intelligent computational systems, right?

429
00:36:03,000 --> 00:36:05,000
Philosophers have disputed that.

430
00:36:05,000 --> 00:36:08,000
John Searle, who was actually one of my dissertation advisors,

431
00:36:08,000 --> 00:36:10,000
is one of the most famous skeptics about that.

432
00:36:10,000 --> 00:36:16,000
But there's, it's certainly no consensus that it's impossible.

433
00:36:16,000 --> 00:36:24,000
So if we accept, give at least some credence to the possibility

434
00:36:24,000 --> 00:36:30,000
that artificially intelligent beings could arise on computers,

435
00:36:30,000 --> 00:36:34,000
then it seems possible that such beings could exist

436
00:36:34,000 --> 00:36:40,000
in simulated artificial environments that they take to be their own,

437
00:36:40,000 --> 00:36:44,000
the base level of reality, as Bostrom puts it.

438
00:36:44,000 --> 00:36:51,000
Some of them might even think they're living in Earth in the 21st century.

439
00:36:51,000 --> 00:36:56,000
And then the question arises, okay, how many such beings are there?

440
00:36:56,000 --> 00:37:01,000
And one possibility would be, look, you know, they're not ever going to be beings

441
00:37:01,000 --> 00:37:03,000
like this out there, right?

442
00:37:03,000 --> 00:37:05,000
The civilization will not get that far enough.

443
00:37:05,000 --> 00:37:09,000
Maybe it's really expensive to make such things and no one would bother.

444
00:37:09,000 --> 00:37:13,000
Or maybe there'd be some ethical regulations, like you don't want to create real,

445
00:37:13,000 --> 00:37:16,000
you want to create really conscious entities inside your computer

446
00:37:16,000 --> 00:37:19,000
who think they're living in reality, right?

447
00:37:19,000 --> 00:37:23,000
But on the other hand, it also seems like it's possible

448
00:37:23,000 --> 00:37:26,000
that there would be many such beings, right?

449
00:37:26,000 --> 00:37:30,000
Just like we run computer games like the Sims right now

450
00:37:30,000 --> 00:37:32,000
and we run scientific simulations,

451
00:37:32,000 --> 00:37:36,000
it could be the case that there are lots of games or scientific projects

452
00:37:36,000 --> 00:37:40,000
that involve real conscious beings inside them

453
00:37:40,000 --> 00:37:43,000
who think they're living in the base level of reality.

454
00:37:43,000 --> 00:37:47,000
If the universe contains many such beings,

455
00:37:47,000 --> 00:37:53,000
then it seems not totally implausible to think we might be among them.

456
00:37:53,000 --> 00:37:58,000
So there are various reasons to think we're probably not them, right?

457
00:37:58,000 --> 00:38:02,000
Every step of this argument admits of doubt.

458
00:38:02,000 --> 00:38:06,000
And you kind of stack those doubts on top of each other

459
00:38:06,000 --> 00:38:08,000
and it seems like, okay, probably not.

460
00:38:08,000 --> 00:38:11,000
But again, it's like with the dream case,

461
00:38:11,000 --> 00:38:16,000
it doesn't seem like we should be absolutely certain that we're not Sims.

462
00:38:16,000 --> 00:38:19,000
So yeah, I guess it could be.

463
00:38:19,000 --> 00:38:22,000
So I find that possibility interesting.

464
00:38:22,000 --> 00:38:26,000
And then I guess to turn this into a skeptical scenario,

465
00:38:26,000 --> 00:38:30,000
so one of the things that David Chalmers has particularly emphasized

466
00:38:30,000 --> 00:38:32,000
in talking about this is he says,

467
00:38:32,000 --> 00:38:36,000
well, look, if you're living in a simulation but it's large and stable,

468
00:38:36,000 --> 00:38:39,000
then that's not really a skeptical scenario at all.

469
00:38:39,000 --> 00:38:44,000
He says, because you have a long past, you're going to have a long future.

470
00:38:44,000 --> 00:38:47,000
All the people you know really exist.

471
00:38:47,000 --> 00:38:50,000
And there might be, say, a coffee mug,

472
00:38:50,000 --> 00:38:53,000
and it might be fundamentally made out of computational bits,

473
00:38:53,000 --> 00:38:55,000
but that's enough.

474
00:38:55,000 --> 00:38:57,000
It's still going to be there.

475
00:38:57,000 --> 00:38:59,000
It's going to react the way that you want.

476
00:38:59,000 --> 00:39:02,000
So it really is kind of a coffee mug.

477
00:39:02,000 --> 00:39:07,000
Well, basically, most of your ordinary beliefs would end up being true.

478
00:39:07,000 --> 00:39:12,000
So to turn this into a skeptical simulation scenario,

479
00:39:12,000 --> 00:39:14,000
what we have to do is think about what's the possibility

480
00:39:14,000 --> 00:39:19,000
that if we're living in a Sim, it's a small or unstable one.

481
00:39:19,000 --> 00:39:23,000
And there I guess I'm inclined to disagree with Chalmers.

482
00:39:23,000 --> 00:39:26,000
And I'm inclined to think that if we are in a Sim,

483
00:39:26,000 --> 00:39:30,000
there is a decent chance that it's a small or unstable one.

484
00:39:30,000 --> 00:39:33,000
So if we think about the simulations we run,

485
00:39:33,000 --> 00:39:36,000
they tend to be small and unstable.

486
00:39:36,000 --> 00:39:40,000
If we think about the question of resources,

487
00:39:40,000 --> 00:39:45,000
it probably would take a lot of resources to run a whole galaxy

488
00:39:45,000 --> 00:39:49,000
from the Big Bang through now and on into the future.

489
00:39:49,000 --> 00:39:52,000
So what scientist is really going to want to do that

490
00:39:52,000 --> 00:39:55,000
if maybe all they're interested in is human cognition?

491
00:39:55,000 --> 00:39:58,000
So just run a short, a few people having a discussion on a podcast

492
00:39:58,000 --> 00:40:00,000
or something like that.

493
00:40:00,000 --> 00:40:04,000
So I think conditional upon thinking we're living in a Sim,

494
00:40:04,000 --> 00:40:08,000
we should assign a substantial portion of that credence,

495
00:40:08,000 --> 00:40:14,000
maybe 50%, maybe 90%, maybe 10% to it's being a smaller, unstable simulation.

496
00:40:14,000 --> 00:40:20,000
And in that case, then that in my mind counts as a radically skeptical scenario

497
00:40:20,000 --> 00:40:22,000
because you might be radically wrong.

498
00:40:22,000 --> 00:40:25,000
Maybe this whole simulation was created only 10 minutes ago,

499
00:40:25,000 --> 00:40:28,000
maybe there's no one outside of your room,

500
00:40:28,000 --> 00:40:30,000
it's just you listening to a podcast

501
00:40:30,000 --> 00:40:32,000
or just the two of us having a conversation

502
00:40:32,000 --> 00:40:35,000
and beyond the walls of our rooms, nothing exists.

503
00:40:35,000 --> 00:40:38,000
Those would be various ways of it's being smaller and stable.

504
00:40:38,000 --> 00:40:40,000
So as a professional philosopher, of course,

505
00:40:40,000 --> 00:40:45,000
you know that the idea of these skeptical scenarios goes back to antiquity,

506
00:40:45,000 --> 00:40:49,000
not just Zhuangzi, but the ancient Greeks thought about this.

507
00:40:49,000 --> 00:40:53,000
So we've been worried for millennia now

508
00:40:53,000 --> 00:40:57,000
that reality is not anything like what we think it is.

509
00:40:57,000 --> 00:41:03,000
Absolutely. I love the ancient skeptics.

510
00:41:03,000 --> 00:41:06,000
So what are some of your favorite ones?

511
00:41:06,000 --> 00:41:09,000
Well, Zhuangzi is probably my favorite philosopher,

512
00:41:09,000 --> 00:41:13,000
but Sexist Empiricus is also really wonderful.

513
00:41:13,000 --> 00:41:17,000
And they did not know about the simulation argument.

514
00:41:17,000 --> 00:41:20,000
Right, they didn't know about the simulation argument,

515
00:41:20,000 --> 00:41:26,000
but that opens up the possibility that there are some rounds for doubt

516
00:41:26,000 --> 00:41:31,000
that future philosophers and physicists will think of

517
00:41:31,000 --> 00:41:35,000
that didn't even occur to us.

518
00:41:35,000 --> 00:41:41,000
And maybe we should have some degree of skepticism reserved for that.

519
00:41:41,000 --> 00:41:43,000
Right, I call this wildcard skepticism.

520
00:41:43,000 --> 00:41:49,000
The idea that I should have a certain amount of doubt

521
00:41:49,000 --> 00:41:52,000
about my ordinary assumptions about the world,

522
00:41:52,000 --> 00:41:55,000
just on the basis of the fact that there's some skeptical possibility

523
00:41:55,000 --> 00:41:58,000
that I'm not even capable of considering.

524
00:41:58,000 --> 00:42:00,000
Right. Okay, good.

525
00:42:00,000 --> 00:42:02,000
So there are other skeptical scenarios,

526
00:42:02,000 --> 00:42:06,000
but we have the general feeling between living in a simulation,

527
00:42:06,000 --> 00:42:09,000
we're just dreaming, what do we do about it?

528
00:42:09,000 --> 00:42:15,000
Do we just ignore those possibilities because they're too weird?

529
00:42:15,000 --> 00:42:18,000
Do we reserve a little bit of our credences to say,

530
00:42:18,000 --> 00:42:23,000
who knows, maybe tomorrow I'll change my mind and think this is right?

531
00:42:23,000 --> 00:42:26,000
Yeah, I think we reserve a little bit of our credence.

532
00:42:26,000 --> 00:42:31,000
So the way that I think about it in terms of numerical credence

533
00:42:31,000 --> 00:42:38,000
is that I think it's rational to assign about a 0.1 to 1% credence

534
00:42:38,000 --> 00:42:45,000
to some radically skeptical scenario or other being correct.

535
00:42:45,000 --> 00:42:48,000
That's rough and fuzzy.

536
00:42:48,000 --> 00:42:53,000
It's somewhere between just being completely confident they're false

537
00:42:53,000 --> 00:42:58,000
and being radically uncertain.

538
00:42:58,000 --> 00:43:04,000
So 99.9%, the world's basically just how we think it is.

539
00:43:04,000 --> 00:43:08,000
Setting aside the big picture cosmological stuff,

540
00:43:08,000 --> 00:43:14,000
the ordinary Earth world of middle-sized dry goods at slow speeds

541
00:43:14,000 --> 00:43:16,000
is more or less how we think.

542
00:43:16,000 --> 00:43:20,000
99.9% of our credence maybe should go to that,

543
00:43:20,000 --> 00:43:23,000
but save a little bit of your credence space, so to speak,

544
00:43:23,000 --> 00:43:26,000
for these radically skeptical possibilities.

545
00:43:26,000 --> 00:43:31,000
And then I think that having that little bit of space there

546
00:43:31,000 --> 00:43:34,000
has some influence on your choices and your behavior.

547
00:43:34,000 --> 00:43:37,000
Actually, I do want to get to exactly that issue,

548
00:43:37,000 --> 00:43:40,000
but I realize there's a hanging thread that we should deal with,

549
00:43:40,000 --> 00:43:47,000
which is there's another kind of way in which the world could be very different

550
00:43:47,000 --> 00:43:52,000
than what we think it is, which is just there is a lower microscopic level

551
00:43:52,000 --> 00:43:56,000
beneath our manifest image kind of world, right?

552
00:43:56,000 --> 00:43:59,000
So you're not counting.

553
00:43:59,000 --> 00:44:02,000
We are not talking about something like,

554
00:44:02,000 --> 00:44:07,000
oh, there's a whole new theory where everything is little strings

555
00:44:07,000 --> 00:44:09,000
or wave functions or whatever.

556
00:44:09,000 --> 00:44:11,000
That doesn't count because in those scenarios,

557
00:44:11,000 --> 00:44:16,000
the macroscopic world is still the macroscopic world and obeys the rules, right?

558
00:44:16,000 --> 00:44:18,000
Exactly, right.

559
00:44:18,000 --> 00:44:21,000
So I don't count that as a radically skeptical scenario of the relevant.

560
00:44:22,000 --> 00:44:27,000
Because there still would be our everyday beliefs would still mostly be true, right?

561
00:44:27,000 --> 00:44:31,000
It would be true that Earth has existed for billions of years

562
00:44:31,000 --> 00:44:34,000
and it would be true that there's a coffee mug here

563
00:44:34,000 --> 00:44:38,000
and that sort of stuff and the sun will rise tomorrow, so to speak.

564
00:44:38,000 --> 00:44:40,000
Good, okay, good.

565
00:44:40,000 --> 00:44:46,000
So then we can go back to that 1% skepticism that you're advocating.

566
00:44:46,000 --> 00:44:49,000
I mean, one question is just where did that number come from?

567
00:44:49,000 --> 00:44:53,000
You're saying we should attach a 10 to the minus 2, 10 to the minus 3 credence

568
00:44:53,000 --> 00:44:55,000
to just being completely wrong.

569
00:44:55,000 --> 00:45:02,000
I absolutely agree that we should attach some credence to any crazy idea you have.

570
00:45:02,000 --> 00:45:07,000
I'm a disbeliever that you should attach zero credence to almost anything,

571
00:45:07,000 --> 00:45:09,000
but why not tend to the minus 10?

572
00:45:09,000 --> 00:45:14,000
Why something as big as 10 to the minus 2 or 3?

573
00:45:15,000 --> 00:45:21,000
I don't have a rigorous argument for that,

574
00:45:21,000 --> 00:45:28,000
but let me just do it for, say, the dream scenario, right?

575
00:45:28,000 --> 00:45:35,000
So let's say we invest a 20% credence in the theory,

576
00:45:35,000 --> 00:45:38,000
which some major dream researchers accept,

577
00:45:38,000 --> 00:45:43,000
that we commonly have experiences like we're currently having in our dreams.

578
00:45:43,000 --> 00:45:47,000
Let's say we get 20% credence to that and 80% credence to now dreams

579
00:45:47,000 --> 00:45:49,000
are basically just always sketchy.

580
00:45:49,000 --> 00:45:53,000
Then conditional on that, we say,

581
00:45:53,000 --> 00:45:59,000
okay, how often do I have experiences relevantly like this in dreams?

582
00:45:59,000 --> 00:46:06,000
Well, maybe this is not the kind of thing that I would tend to dream about very much.

583
00:46:07,000 --> 00:46:14,000
Again, if we ordinarily have ordinary sensory experiences of mundane things,

584
00:46:14,000 --> 00:46:17,000
it seems like this is the kind of thing that we should have.

585
00:46:17,000 --> 00:46:27,000
So maybe I should assign a 2% of the time I'm having experiences like this

586
00:46:27,000 --> 00:46:30,000
is actually in sleep, or I should invest 2% of my credence

587
00:46:30,000 --> 00:46:35,000
to the idea that I have experiences like this in my sleep.

588
00:46:35,000 --> 00:46:39,000
Now, once I've attached a 2% credence to the idea that I have experiences like this

589
00:46:39,000 --> 00:46:43,000
commonly in my sleep, it's hard for me to see on the basis of that

590
00:46:43,000 --> 00:46:48,000
how you would then go, okay, so I now only have a 1 in 10 billion credence

591
00:46:48,000 --> 00:46:51,000
that this is a dream, right?

592
00:46:51,000 --> 00:46:59,000
It seems like you can't knock too many orders of magnitude down off that 2%.

593
00:46:59,000 --> 00:47:04,000
I'm not sure what the grounds would be for that kind of decrement.

594
00:47:05,000 --> 00:47:12,000
I think it's a big philosophical problem that I don't know whether you know

595
00:47:12,000 --> 00:47:15,000
if anyone sort of specializes in this particular question,

596
00:47:15,000 --> 00:47:20,000
but what do we do with issues or questions or scenarios

597
00:47:20,000 --> 00:47:24,000
where the credence that it'll happen is incredibly tiny,

598
00:47:24,000 --> 00:47:28,000
but the consequences of it happening are incredibly large.

599
00:47:28,000 --> 00:47:33,000
And it seems maybe AI destroying the world is an example of that

600
00:47:33,000 --> 00:47:37,000
or even better because people think that AI destroying the world might be 10%,

601
00:47:37,000 --> 00:47:41,000
but the large Hadron Collider turning on in a black hole eating up the world

602
00:47:41,000 --> 00:47:45,000
and someone says, well, it's less than a 1 in 10 billion chance.

603
00:47:45,000 --> 00:47:49,000
And someone else says, but it destroys the world, that should still count.

604
00:47:49,000 --> 00:47:51,000
How do we reason about those cases?

605
00:47:51,000 --> 00:47:55,000
1 in 10 billion times 10 billion people, so...

606
00:47:55,000 --> 00:47:57,000
That's why I chose the number, right.

607
00:47:57,000 --> 00:48:00,000
One expected murder as soon as you turn it on.

608
00:48:02,000 --> 00:48:05,000
But even the number 1 in the 10 billion, I mean, if someone said,

609
00:48:05,000 --> 00:48:08,000
oh, no, it's really only 1 in 10 million or it's 1 in 10 trillion,

610
00:48:08,000 --> 00:48:12,000
probably I couldn't give a principled argument in any direction.

611
00:48:12,000 --> 00:48:13,000
Right.

612
00:48:13,000 --> 00:48:15,000
So I don't know how to deal with them.

613
00:48:15,000 --> 00:48:17,000
You talk about those kinds of magnitudes, sometimes it's hard to get...

614
00:48:17,000 --> 00:48:21,000
You lose your sense of magnitude once you get over, I don't know,

615
00:48:21,000 --> 00:48:23,000
a trillion or something like that.

616
00:48:23,000 --> 00:48:27,000
So do philosophers have a toolkit for dealing with these weird numbers?

617
00:48:29,000 --> 00:48:30,000
No.

618
00:48:31,000 --> 00:48:32,000
It's becoming...

619
00:48:32,000 --> 00:48:37,000
It's an interesting issue that's been starting to get attention in the philosophical literature.

620
00:48:39,000 --> 00:48:43,000
There's this idea that's sometimes called Nicolossian discounting,

621
00:48:43,000 --> 00:48:50,000
which is the thought that once something has a low enough chance

622
00:48:50,000 --> 00:48:54,000
or you give a low enough credence to it, you just ignore it completely.

623
00:48:54,000 --> 00:48:55,000
Yeah.

624
00:48:55,000 --> 00:48:56,000
Yeah.

625
00:48:56,000 --> 00:48:57,000
So that is one approach.

626
00:48:57,000 --> 00:48:58,000
What was that called?

627
00:48:58,000 --> 00:48:59,000
And I...

628
00:48:59,000 --> 00:49:02,000
Nicolossian discounting.

629
00:49:03,000 --> 00:49:08,000
After someone named Nicholas, but I've forgotten which Nicholas it is.

630
00:49:10,000 --> 00:49:13,000
So, right, so for example, in the weirdness of the world,

631
00:49:13,000 --> 00:49:20,000
I suggest that once you give something 10 to the negative 30 credence,

632
00:49:20,000 --> 00:49:23,000
you kind of just forget about it.

633
00:49:23,000 --> 00:49:28,000
And this helps solve certain kinds of puzzles and paradoxes in decision theory.

634
00:49:30,000 --> 00:49:33,000
But there are also arguments against this.

635
00:49:33,000 --> 00:49:35,000
So there's been back and forth about this.

636
00:49:35,000 --> 00:49:39,000
This also comes up in the debate about the ethics of long-termism.

637
00:49:39,000 --> 00:49:40,000
Right, exactly.

638
00:49:40,000 --> 00:49:44,000
Right, so long-termism is this idea in the effective altruism movement

639
00:49:44,000 --> 00:49:52,000
that there's a small chance that things we do today could have a huge impact

640
00:49:52,000 --> 00:49:54,000
on a huge number of lives in the future.

641
00:49:55,000 --> 00:50:00,000
Right, so for example, if humanity goes extinct now,

642
00:50:00,000 --> 00:50:07,000
then maybe there are no other entities in our galaxy who will ever have the kinds of lives

643
00:50:07,000 --> 00:50:10,000
with the kind of value that our lives have, right?

644
00:50:10,000 --> 00:50:12,000
And if we manage not to go extinct now,

645
00:50:12,000 --> 00:50:17,000
then maybe we will have 10 to the 40 happy descendants

646
00:50:17,000 --> 00:50:20,000
before the heat death of the universe, right?

647
00:50:20,000 --> 00:50:24,000
So even if there is a one in a quadrillion chance

648
00:50:24,000 --> 00:50:28,000
that something you did now could prevent humanity from going extinct,

649
00:50:29,000 --> 00:50:35,000
given the stakes, maybe you should invest a huge amount in that tiny little chance.

650
00:50:37,000 --> 00:50:42,000
So that's an interesting issue that's been coming up recently with long-termism

651
00:50:42,000 --> 00:50:48,000
where this issue about what do you do when you're trying to balance tiny credences

652
00:50:48,000 --> 00:50:50,000
and giant values against each other?

653
00:50:50,000 --> 00:50:55,000
Do you have a take on what we should do, or is it just an open kind of question?

654
00:50:58,000 --> 00:50:59,000
So I have two takes.

655
00:50:59,000 --> 00:51:05,000
One is I'm still going to stand by Nicolassian discounting.

656
00:51:05,000 --> 00:51:06,000
Okay.

657
00:51:06,000 --> 00:51:15,000
And the other take is radical ignorance about what actions that are currently available to us

658
00:51:15,000 --> 00:51:17,000
would have good versus bad effects.

659
00:51:17,000 --> 00:51:28,000
So the long-termists will typically say or assume that human extinction is likely to have a bad effect

660
00:51:28,000 --> 00:51:31,000
instead of a good effect on future history.

661
00:51:31,000 --> 00:51:35,000
I don't think that that's necessarily true.

662
00:51:36,000 --> 00:51:47,000
So for example, maybe humanity, because we are so technological and prone to violence,

663
00:51:47,000 --> 00:51:55,000
is a kind of unstable species that is more or less certain to doom itself

664
00:51:55,000 --> 00:52:02,000
sometime in the next 10,000 to 100,000 years we're going to blow ourselves up.

665
00:52:02,000 --> 00:52:11,000
And if we do it in an explosive way, then we ruin the Earth for other future inhabitants.

666
00:52:11,000 --> 00:52:16,000
But if we were to say bow out peacefully now by deciding never to reproduce again,

667
00:52:16,000 --> 00:52:24,000
as anti-natalists suggest, then maybe we leave the Earth in a good position for other species

668
00:52:24,000 --> 00:52:33,000
like say dolphins, who might have descendants that are capable of lives as rich as ours

669
00:52:33,000 --> 00:52:36,000
but who aren't technological, aren't going to blow themselves up

670
00:52:36,000 --> 00:52:40,000
and could endure potentially four billions of years on the planet

671
00:52:40,000 --> 00:52:45,000
or maybe not billions, but maybe a billion.

672
00:52:45,000 --> 00:52:50,000
If that's the case, then and you put the numbers into the equation in a certain way,

673
00:52:50,000 --> 00:52:54,000
it turns out that would be better from a kind of long term perspective for human beings

674
00:52:54,000 --> 00:52:59,000
to peacefully extinguish ourselves now.

675
00:52:59,000 --> 00:53:01,000
So I'm not saying that's true.

676
00:53:01,000 --> 00:53:07,000
What I'm saying is it's very hard to know what really,

677
00:53:07,000 --> 00:53:10,000
when you take a billion year time perspective,

678
00:53:10,000 --> 00:53:18,000
what really is kind of objectively good versus bad among options that we have available to us now.

679
00:53:18,000 --> 00:53:20,000
I think that's fair.

680
00:53:20,000 --> 00:53:25,000
So radical ignorance about the very distant future.

681
00:53:25,000 --> 00:53:32,000
And relatedly then, what is the actionable fact about 1% skepticism?

682
00:53:32,000 --> 00:53:37,000
Like how does it affect our daily lives to think that maybe there's a 1% chance

683
00:53:37,000 --> 00:53:42,000
or a tenth of a percent chance that I'm dreaming or that I'm living the simulation?

684
00:53:42,000 --> 00:53:45,000
Right.

685
00:53:45,000 --> 00:53:51,000
Well, for example, just a fun example to start with,

686
00:53:51,000 --> 00:54:00,000
I had been reading a lot about dream skepticism and it was particularly vivid for me this one particular winter break

687
00:54:00,000 --> 00:54:04,000
when I was walking across campus and no else was around.

688
00:54:04,000 --> 00:54:06,000
I was thinking, I wonder if I'm dreaming.

689
00:54:06,000 --> 00:54:10,000
Maybe I should try to fly because I'm probably not dreaming.

690
00:54:10,000 --> 00:54:13,000
But look, if I'm dreaming, it would be so awesome to fly.

691
00:54:13,000 --> 00:54:15,000
No one's around, no one's looking.

692
00:54:15,000 --> 00:54:17,000
There's no cost.

693
00:54:17,000 --> 00:54:20,000
I was kind of walking across campus to the science library to get a book, right?

694
00:54:20,000 --> 00:54:23,000
So why not just like try to fly to the library?

695
00:54:23,000 --> 00:54:27,000
So I did try to fly to the library and I failed.

696
00:54:27,000 --> 00:54:35,000
But I think that was a rational decision because I could have been dreaming

697
00:54:35,000 --> 00:54:37,000
and then it would have been awesome.

698
00:54:37,000 --> 00:54:41,000
It was not so rational that you would have done it had people been watching.

699
00:54:41,000 --> 00:54:42,000
Right.

700
00:54:42,000 --> 00:54:44,000
So low cost things, right?

701
00:54:44,000 --> 00:54:47,000
Don't try to fly when you're standing on the edge of the cliff.

702
00:54:47,000 --> 00:54:51,000
Plug that into your utility calculus and you will not get a positive result.

703
00:54:51,000 --> 00:54:57,000
But if they're very small or no costs to trying to fly,

704
00:54:57,000 --> 00:55:04,000
then why not if you think this might be a dream and could fly?

705
00:55:04,000 --> 00:55:06,000
Of course, as soon as you try to fly and fail,

706
00:55:06,000 --> 00:55:09,000
that should reduce your credence either that this is a dream

707
00:55:09,000 --> 00:55:13,000
or that if this is a dream, you could fly.

708
00:55:13,000 --> 00:55:15,000
So you might, it might not be repeatable.

709
00:55:15,000 --> 00:55:17,000
You might not just be spending all your time trying to fly.

710
00:55:17,000 --> 00:55:19,000
In my dreams, I can fly at least a little bit.

711
00:55:19,000 --> 00:55:21,000
I can float.

712
00:55:21,000 --> 00:55:23,000
Right.

713
00:55:23,000 --> 00:55:26,000
It's just a matter of willpower.

714
00:55:26,000 --> 00:55:29,000
Anyway, this is all, you know, fun, but it is 1% stuff

715
00:55:29,000 --> 00:55:32,000
and a lot of the book, I don't want to give people the wrong impression.

716
00:55:32,000 --> 00:55:35,000
A lot of your book, you're talking about consciousness,

717
00:55:35,000 --> 00:55:39,000
which has the feature that we're all familiar with it.

718
00:55:39,000 --> 00:55:41,000
I don't even want to say the feature that it exists

719
00:55:41,000 --> 00:55:44,000
because people argue about that, but at least we're all familiar with the idea.

720
00:55:44,000 --> 00:55:48,000
So what is it about our attempts to understand consciousness

721
00:55:48,000 --> 00:55:52,000
that drives us into the weird zone?

722
00:55:52,000 --> 00:55:54,000
Right.

723
00:55:54,000 --> 00:55:59,000
So philosophers have tried over and over again for centuries

724
00:55:59,000 --> 00:56:04,000
to make sense of how consciousness fits into the world.

725
00:56:04,000 --> 00:56:11,000
And one of the striking empirical facts about the history of philosophy

726
00:56:11,000 --> 00:56:17,000
is that every single attempt to make sense of this is jaw-droppingly bizarre.

727
00:56:17,000 --> 00:56:24,000
So there are, I divide attempts to deal with the question

728
00:56:24,000 --> 00:56:29,000
of how consciousness fits into the broader world into four broad categories.

729
00:56:29,000 --> 00:56:31,000
One is substance dualism.

730
00:56:31,000 --> 00:56:33,000
You've got an immaterial soul.

731
00:56:33,000 --> 00:56:35,000
Another one is materialism.

732
00:56:35,000 --> 00:56:37,000
There are no immaterial souls.

733
00:56:37,000 --> 00:56:39,000
You're just a biological entity.

734
00:56:39,000 --> 00:56:41,000
Another one is idealism.

735
00:56:41,000 --> 00:56:44,000
This is the idea that there is no material world at all.

736
00:56:44,000 --> 00:56:47,000
All that exists are minds or souls.

737
00:56:47,000 --> 00:56:51,000
And then there's what I call compromise slash rejection views,

738
00:56:51,000 --> 00:56:54,000
this kind of grab bag of other alternatives.

739
00:56:54,000 --> 00:56:58,000
And the striking thing to me about this is

740
00:56:58,000 --> 00:57:05,000
all of these alternatives end up committing to bizarre and dubious

741
00:57:05,000 --> 00:57:08,000
theses of one form or another.

742
00:57:08,000 --> 00:57:13,000
There's not really a live option here that is non-bizarre.

743
00:57:13,000 --> 00:57:14,000
It's not always obvious.

744
00:57:14,000 --> 00:57:17,000
I mean, idealism is bizarre on its face, I think.

745
00:57:17,000 --> 00:57:20,000
It's contrary to common sense to think there's no material world,

746
00:57:20,000 --> 00:57:22,000
and it's only just minds.

747
00:57:22,000 --> 00:57:26,000
Dualism and materialism are not maybe bizarre in their face,

748
00:57:26,000 --> 00:57:29,000
but once you try to get into the metaphysical details

749
00:57:29,000 --> 00:57:31,000
and think about how it really works,

750
00:57:31,000 --> 00:57:35,000
end up pretty swiftly faced with theoretical choices

751
00:57:35,000 --> 00:57:38,000
where there are going to be bizarre consequences

752
00:57:38,000 --> 00:57:42,000
for any of the choices that you make.

753
00:57:42,000 --> 00:57:43,000
I think that's the important point,

754
00:57:43,000 --> 00:57:45,000
because people are going to hear you say that,

755
00:57:45,000 --> 00:57:48,000
and they'll be both materialists and dualists in the audience

756
00:57:48,000 --> 00:57:52,000
who go, I have no trouble thinking that consciousness works that way.

757
00:57:52,000 --> 00:57:57,000
But your point is that if you really take the consequences of that view

758
00:57:57,000 --> 00:58:02,000
seriously, you're led to something that we should recognize as bizarre.

759
00:58:02,000 --> 00:58:04,000
Correct.

760
00:58:04,000 --> 00:58:05,000
Right.

761
00:58:05,000 --> 00:58:07,000
So why don't you tell us for Ethan Pink one?

762
00:58:07,000 --> 00:58:10,000
So for example with dualism, right?

763
00:58:10,000 --> 00:58:18,000
The dualist faces two questions where all of the answers seem to be bizarre.

764
00:58:18,000 --> 00:58:23,000
One concerns what kinds of entities have souls,

765
00:58:23,000 --> 00:58:30,000
and the other concerns the causal relationship between material world and souls.

766
00:58:30,000 --> 00:58:34,000
The causal question is a little more complicated,

767
00:58:34,000 --> 00:58:38,000
so let me just talk about the question of what entities have souls.

768
00:58:38,000 --> 00:58:40,000
Basically, you have four choices.

769
00:58:40,000 --> 00:58:44,000
You could say only humans have souls,

770
00:58:44,000 --> 00:58:48,000
or you could say everything in the world has a soul.

771
00:58:48,000 --> 00:58:50,000
Both of those are pretty bizarre,

772
00:58:50,000 --> 00:58:53,000
because if you think souls are the locus of consciousness,

773
00:58:53,000 --> 00:58:57,000
then except the first, like Descartes,

774
00:58:57,000 --> 00:59:00,000
then you think dogs and cats aren't conscious.

775
00:59:00,000 --> 00:59:02,000
So there's this story of Descartes taking a cat

776
00:59:02,000 --> 00:59:05,000
and throwing it out of a second-story window saying,

777
00:59:05,000 --> 00:59:07,000
see, cats, they're just machines.

778
00:59:07,000 --> 00:59:08,000
I never heard that story.

779
00:59:08,000 --> 00:59:11,000
He probably didn't actually do this.

780
00:59:11,000 --> 00:59:12,000
Man.

781
00:59:12,000 --> 00:59:15,000
But that story kind of reveals the bizarreness of those

782
00:59:15,000 --> 00:59:18,000
that only humans have souls.

783
00:59:18,000 --> 00:59:21,000
And of course the panpsychist view that everything has a soul,

784
00:59:21,000 --> 00:59:25,000
even say a proton, that's also pretty bizarre.

785
00:59:25,000 --> 00:59:27,000
So then there are two other options.

786
00:59:27,000 --> 00:59:31,000
One is that there's a sharp line somewhere.

787
00:59:31,000 --> 00:59:38,000
So dogs have souls, cats have souls, but not frogs.

788
00:59:38,000 --> 00:59:40,000
Where do you draw that line?

789
00:59:40,000 --> 00:59:42,000
Across the continuum of animals,

790
00:59:42,000 --> 00:59:45,000
it seems like there's a continuum of psychological capacities,

791
00:59:45,000 --> 00:59:47,000
a continuum of physiology.

792
00:59:47,000 --> 00:59:49,000
It would be weird if you said, OK,

793
00:59:49,000 --> 00:59:51,000
toads of this genus have souls,

794
00:59:51,000 --> 00:59:53,000
toads of this other genus do not.

795
00:59:53,000 --> 00:59:58,000
So a sharp line is pretty implausible,

796
00:59:58,000 --> 01:00:00,000
at least bizarre.

797
01:00:00,000 --> 01:00:02,000
And then that gives you maybe the fourth option,

798
01:00:02,000 --> 01:00:05,000
which is having a soul is not an on or off thing.

799
01:00:05,000 --> 01:00:08,000
You could have a kind of soul or a half soul.

800
01:00:08,000 --> 01:00:10,000
Dogs have an eighth of a soul.

801
01:00:10,000 --> 01:00:12,000
What would that even mean?

802
01:00:12,000 --> 01:00:15,000
We normally think of souls as things that either have or don't have.

803
01:00:15,000 --> 01:00:18,000
It seems like a discrete category rather than a graded category.

804
01:00:18,000 --> 01:00:21,000
But you've got to take one of those horns,

805
01:00:21,000 --> 01:00:23,000
but they're all bizarre.

806
01:00:23,000 --> 01:00:27,000
So that illustrates why I think on the face of it,

807
01:00:27,000 --> 01:00:30,000
it seems like having a soul is not a bizarre view.

808
01:00:30,000 --> 01:00:32,000
But as soon as you face that choice of saying, OK,

809
01:00:32,000 --> 01:00:34,000
what animals have souls?

810
01:00:34,000 --> 01:00:38,000
You're forced into committing to some

811
01:00:38,000 --> 01:00:40,000
strikingly bizarre position.

812
01:00:40,000 --> 01:00:42,000
And as a matter of fact,

813
01:00:42,000 --> 01:00:44,000
this was a hot topic in ancient philosophy,

814
01:00:44,000 --> 01:00:46,000
which animals have souls, right?

815
01:00:46,000 --> 01:00:48,000
Exactly.

816
01:00:48,000 --> 01:00:52,000
And the modern conception of the soul as a locus of consciousness

817
01:00:52,000 --> 01:00:55,000
is a little different from an ancient philosophy.

818
01:00:55,000 --> 01:00:58,000
There was the vegetative soul as well.

819
01:00:58,000 --> 01:01:01,000
So there's a sense in which even plants had souls,

820
01:01:01,000 --> 01:01:03,000
but they didn't think of souls maybe as a locus of consciousness.

821
01:01:03,000 --> 01:01:07,000
So actually, the concept of a soul that we find

822
01:01:07,000 --> 01:01:10,000
in our current philosophical and religious tradition

823
01:01:10,000 --> 01:01:12,000
has a certain history.

824
01:01:12,000 --> 01:01:14,000
It is not a straightforward translation from, say,

825
01:01:14,000 --> 01:01:16,000
ancient Greek.

826
01:01:16,000 --> 01:01:18,000
So it's complicated, but it's been an issue

827
01:01:18,000 --> 01:01:21,000
throughout philosophical history.

828
01:01:21,000 --> 01:01:23,000
But here at the Mindscape Podcasts,

829
01:01:23,000 --> 01:01:26,000
we are hardcore materialists about consciousness.

830
01:01:26,000 --> 01:01:29,000
So tell us why that leads us to weirdness.

831
01:01:30,000 --> 01:01:39,000
Well, one of the issues here to think about

832
01:01:39,000 --> 01:01:44,000
is, again, what kind of entities have experiences.

833
01:01:44,000 --> 01:01:48,000
I guess there are a few different ways to angle in on this.

834
01:01:48,000 --> 01:01:58,000
But one of them, and this is the theme of Chapter 3

835
01:01:59,000 --> 01:02:07,000
is to point out that according to a broad class

836
01:02:07,000 --> 01:02:11,000
of materialist theories, it's very plausible

837
01:02:11,000 --> 01:02:15,000
that the United States has a stream of conscious experience.

838
01:02:15,000 --> 01:02:19,000
The United States conceived of as a concrete entity

839
01:02:19,000 --> 01:02:22,000
with people as its parts, kind of like you are a concrete entity

840
01:02:22,000 --> 01:02:24,000
with cells as your parts.

841
01:02:24,000 --> 01:02:27,000
So think about that concrete thing

842
01:02:27,000 --> 01:02:30,000
with hundreds of billions of people.

843
01:02:30,000 --> 01:02:32,000
Hundreds of millions.

844
01:02:32,000 --> 01:02:34,000
Sorry, hundreds of millions.

845
01:02:34,000 --> 01:02:36,000
Sorry, I misspoke there.

846
01:02:36,000 --> 01:02:38,000
Don't want you misquoted, yeah.

847
01:02:40,000 --> 01:02:46,000
So that entity processes a lot of information.

848
01:02:46,000 --> 01:02:50,000
That entity represents itself.

849
01:02:50,000 --> 01:02:53,000
That entity responds to its environment,

850
01:02:53,000 --> 01:02:56,000
kind of intelligently or semi-intelligently.

851
01:02:57,000 --> 01:03:00,000
You scan space for asteroids that might threaten Earth

852
01:03:00,000 --> 01:03:03,000
and we're prepared to try to deal with them if that happens.

853
01:03:03,000 --> 01:03:06,000
The United States monitors its borders.

854
01:03:06,000 --> 01:03:08,000
It engages in import and export.

855
01:03:08,000 --> 01:03:11,000
It sends its army out to do certain things.

856
01:03:11,000 --> 01:03:16,000
It scolds people in UN Security Council meetings.

857
01:03:16,000 --> 01:03:20,000
It digests bananas, mounts the bananas.

858
01:03:20,000 --> 01:03:23,000
It exudes smoggy exhalations.

859
01:03:24,000 --> 01:03:28,000
So if you take standard,

860
01:03:28,000 --> 01:03:32,000
materialist theories of consciousness out of the box

861
01:03:32,000 --> 01:03:35,000
and you don't rule around with them post-hoc

862
01:03:35,000 --> 01:03:37,000
to try to exclude the case,

863
01:03:37,000 --> 01:03:42,000
then I think it turns out that probably

864
01:03:42,000 --> 01:03:46,000
the United States is going to count as conscious.

865
01:03:46,000 --> 01:03:50,000
So there are a couple of ways to react to this.

866
01:03:50,000 --> 01:03:54,000
You could say, okay, well, so much the worse for materialism.

867
01:03:54,000 --> 01:03:56,000
Or you could say, okay, well, look,

868
01:03:56,000 --> 01:03:58,000
we need to mess around with these theories

869
01:03:58,000 --> 01:04:03,000
to exclude this bizarre possibility.

870
01:04:03,000 --> 01:04:09,000
And I think that is maybe a reasonable response.

871
01:04:09,000 --> 01:04:12,000
One question here is how we know

872
01:04:12,000 --> 01:04:14,000
the United States is not conscious

873
01:04:14,000 --> 01:04:16,000
whether you should take that as a fixed point

874
01:04:16,000 --> 01:04:19,000
in our theorizing about consciousness or not.

875
01:04:19,000 --> 01:04:21,000
You know, and the third possibility is to say,

876
01:04:21,000 --> 01:04:25,000
okay, well, maybe there is group consciousness.

877
01:04:25,000 --> 01:04:28,000
I mean, we don't have a consciousnessometer

878
01:04:28,000 --> 01:04:31,000
that we could put up against the head of the United States.

879
01:04:31,000 --> 01:04:33,000
It doesn't even really have a head, right,

880
01:04:33,000 --> 01:04:37,000
to determine whether it's conscious.

881
01:04:37,000 --> 01:04:41,000
So that would be one area where I think

882
01:04:41,000 --> 01:04:44,000
if you accept the United States is conscious,

883
01:04:44,000 --> 01:04:48,000
then you end up, I take that as a pretty bizarre kind of view.

884
01:04:48,000 --> 01:04:52,000
If you don't, then you adopt other theoretical commitments,

885
01:04:52,000 --> 01:04:54,000
and then we could get into the details of those.

886
01:04:54,000 --> 01:04:56,000
But I think those other theoretical commitments

887
01:04:56,000 --> 01:04:59,000
often then involve kind of further choices

888
01:04:59,000 --> 01:05:02,000
among various bizarre possibilities, right,

889
01:05:02,000 --> 01:05:06,000
kind of like with the immaterial soul case, right?

890
01:05:06,000 --> 01:05:09,000
As soon as you start making those commitments,

891
01:05:09,000 --> 01:05:12,000
once you develop them, you see, oh boy,

892
01:05:12,000 --> 01:05:14,000
this is going to have this consequence.

893
01:05:14,000 --> 01:05:16,000
This is pretty unintuitive.

894
01:05:16,000 --> 01:05:20,000
Well, how certain should we be in that conclusion?

895
01:05:20,000 --> 01:05:23,000
Is there a theorem that says that any version

896
01:05:23,000 --> 01:05:26,000
of materialist theories of consciousness

897
01:05:26,000 --> 01:05:28,000
are going to have this property,

898
01:05:28,000 --> 01:05:30,000
or is it just, well, as far as we know,

899
01:05:30,000 --> 01:05:32,000
according to our best current art,

900
01:05:32,000 --> 01:05:34,000
that seems to be the case?

901
01:05:34,000 --> 01:05:36,000
In other words, could the appearance of bizarreness

902
01:05:36,000 --> 01:05:40,000
go away with better understanding?

903
01:05:40,000 --> 01:05:42,000
Yes, it could.

904
01:05:42,000 --> 01:05:44,000
And there are two separate reasons, right?

905
01:05:44,000 --> 01:05:48,000
One is, kind of as you suggested, right?

906
01:05:48,000 --> 01:05:52,000
Unlike what I call the dualist quadrilemma,

907
01:05:52,000 --> 01:05:54,000
I don't think we have a kind of rigorous argument

908
01:05:54,000 --> 01:05:56,000
that all of the choices have to be bizarre.

909
01:05:56,000 --> 01:06:01,000
It's that the choices that I've seen articulated

910
01:06:01,000 --> 01:06:03,000
all have bizarre consequences.

911
01:06:03,000 --> 01:06:05,000
But there might be some unarticulated choice

912
01:06:05,000 --> 01:06:07,000
that I haven't run across yet

913
01:06:07,000 --> 01:06:09,000
that turns out to be commonsensical, right?

914
01:06:09,000 --> 01:06:12,000
So I think that's possible, but empirically unlikely,

915
01:06:12,000 --> 01:06:14,000
given the current state of things

916
01:06:14,000 --> 01:06:17,000
and the history of philosophical discussion on this.

917
01:06:17,000 --> 01:06:20,000
So it's an empirical conjecture.

918
01:06:20,000 --> 01:06:23,000
The other way in which bizarreness could end up vanishing

919
01:06:23,000 --> 01:06:26,000
is our intuitions and our sense of commonsense could change, right?

920
01:06:26,000 --> 01:06:30,000
So the idea that the Earth moved around the Sun

921
01:06:30,000 --> 01:06:34,000
was bizarre when Copernicus suggested it,

922
01:06:34,000 --> 01:06:38,000
but we no longer seem to find that

923
01:06:38,000 --> 01:06:40,000
a sharp violation of commonsense.

924
01:06:40,000 --> 01:06:42,000
Commonsense has changed over time, right?

925
01:06:42,000 --> 01:06:47,000
So it could be that someday we'll find it very commonsensical,

926
01:06:47,000 --> 01:06:49,000
for example, that the United States is conscious.

927
01:06:49,000 --> 01:06:51,000
You say, oh, yeah, of course.

928
01:06:51,000 --> 01:06:52,000
Or maybe panpsychism.

929
01:06:52,000 --> 01:06:54,000
Oh, the whole universe is conscious, right?

930
01:06:54,000 --> 01:06:57,000
The ordinary person in the street, of course they think that.

931
01:06:57,000 --> 01:06:59,000
Commonsense can change.

932
01:06:59,000 --> 01:07:02,000
It's not a fixed point.

933
01:07:02,000 --> 01:07:03,000
And we should...

934
01:07:03,000 --> 01:07:05,000
So it's a little bit different

935
01:07:05,000 --> 01:07:09,000
than the previous examples of the skeptical scenarios, right?

936
01:07:09,000 --> 01:07:11,000
Here, unless I'm misinterpreting,

937
01:07:11,000 --> 01:07:14,000
you're not arguing that we should hold out 1% credence

938
01:07:14,000 --> 01:07:16,000
for some bizarre possibilities.

939
01:07:16,000 --> 01:07:19,000
You're just saying, look, all the possibilities

940
01:07:19,000 --> 01:07:21,000
seem to be bizarre.

941
01:07:21,000 --> 01:07:23,000
We should, I guess, learn to accept that

942
01:07:23,000 --> 01:07:26,000
or fold that in, not use it as a draft,

943
01:07:26,000 --> 01:07:29,000
as a knockout argument against something.

944
01:07:29,000 --> 01:07:32,000
We can't say, well, I can't accept that it's bizarre,

945
01:07:32,000 --> 01:07:34,000
because all the other options are too.

946
01:07:34,000 --> 01:07:35,000
Exactly.

947
01:07:35,000 --> 01:07:38,000
So this is why people like panpsychists and idealists

948
01:07:38,000 --> 01:07:39,000
like my stuff on this, right?

949
01:07:39,000 --> 01:07:41,000
Because part of the reason,

950
01:07:41,000 --> 01:07:44,000
the main reason I think people reject panpsychism,

951
01:07:44,000 --> 01:07:47,000
for example, the idea that everything in the universe

952
01:07:47,000 --> 01:07:49,000
or maybe the universe as a whole is conscious,

953
01:07:49,000 --> 01:07:52,000
is that it just seems so contrary to common sense.

954
01:07:52,000 --> 01:07:54,000
But if I'm right,

955
01:07:54,000 --> 01:07:57,000
well, something contrary to common sense is probably true,

956
01:07:57,000 --> 01:07:59,000
so maybe that's it, right?

957
01:07:59,000 --> 01:08:01,000
So, right.

958
01:08:01,000 --> 01:08:04,000
I mean, I do think we have to rely on common sense

959
01:08:04,000 --> 01:08:05,000
to some extent.

960
01:08:05,000 --> 01:08:07,000
I don't think we can just toss it out the window

961
01:08:07,000 --> 01:08:09,000
when we talk about issues like this.

962
01:08:09,000 --> 01:08:11,000
We don't have, in my view,

963
01:08:11,000 --> 01:08:14,000
really any great tools for answering these questions,

964
01:08:14,000 --> 01:08:17,000
and so we have to rely on highly imperfect ones

965
01:08:17,000 --> 01:08:19,000
like common sense.

966
01:08:19,000 --> 01:08:22,000
But the fact that something violates common sense

967
01:08:22,000 --> 01:08:25,000
is not automatically defeated.

968
01:08:25,000 --> 01:08:28,000
It does seem very similar to things

969
01:08:28,000 --> 01:08:31,000
that even I have said about quantum mechanics.

970
01:08:31,000 --> 01:08:34,000
I presume that we're going to put

971
01:08:34,000 --> 01:08:36,000
the many-worlds interpretation of quantum mechanics

972
01:08:36,000 --> 01:08:38,000
into the bucket of things that you would say

973
01:08:38,000 --> 01:08:40,000
are pretty bizarre.

974
01:08:40,000 --> 01:08:42,000
Yes.

975
01:08:42,000 --> 01:08:45,000
I remember a quote from,

976
01:08:45,000 --> 01:08:47,000
I think it was David Merman,

977
01:08:47,000 --> 01:08:49,000
who is a very famous, very great physicist,

978
01:08:49,000 --> 01:08:53,000
who is an epistemic person

979
01:08:53,000 --> 01:08:55,000
when it comes to quantum mechanics.

980
01:08:55,000 --> 01:08:57,000
So he thinks the wave function is just a tool

981
01:08:57,000 --> 01:08:59,000
for understanding our knowledge and prediction,

982
01:08:59,000 --> 01:09:01,000
not reflecting anything real.

983
01:09:01,000 --> 01:09:03,000
And, you know, he does little surveys of the field,

984
01:09:03,000 --> 01:09:06,000
et cetera, and at some point comes to many worlds,

985
01:09:06,000 --> 01:09:09,000
and he says, yes, you can follow the Schrodinger equation

986
01:09:09,000 --> 01:09:12,000
and its consequences, and you end up with a theory,

987
01:09:12,000 --> 01:09:15,000
and the price you pay is seriousness.

988
01:09:15,000 --> 01:09:18,000
So basically he's just saying, like,

989
01:09:18,000 --> 01:09:21,000
surely you can't take that seriously, right?

990
01:09:21,000 --> 01:09:23,000
And that's it. That's the entire argument.

991
01:09:23,000 --> 01:09:26,000
And that feels like not a good enough argument to me,

992
01:09:26,000 --> 01:09:29,000
because, like you said, in the context of consciousness,

993
01:09:29,000 --> 01:09:32,000
for me, every version of quantum mechanics

994
01:09:32,000 --> 01:09:35,000
is going to lead us somewhere strange.

995
01:09:35,000 --> 01:09:39,000
Right. In fact, I think the,

996
01:09:39,000 --> 01:09:42,000
I like the interpretations of quantum mechanics

997
01:09:42,000 --> 01:09:46,000
as an illustration of what I call the universe of Dubaiity

998
01:09:46,000 --> 01:09:49,000
and the universal bizarreness claim,

999
01:09:49,000 --> 01:09:51,000
because I think maybe especially your listeners

1000
01:09:51,000 --> 01:09:53,000
will find that plausible, right?

1001
01:09:53,000 --> 01:09:58,000
Every viable interpretation of quantum mechanics is bizarre.

1002
01:09:58,000 --> 01:10:01,000
There's no, like, common sense way of thinking

1003
01:10:01,000 --> 01:10:03,000
about quantum mechanics, right?

1004
01:10:03,000 --> 01:10:08,000
And, you know, with apologies to the many worlds advocates,

1005
01:10:08,000 --> 01:10:10,000
right, they're all dubious, right?

1006
01:10:10,000 --> 01:10:13,000
There's at least grounds for doubting all of them.

1007
01:10:13,000 --> 01:10:16,000
I don't mean, when I say dubious,

1008
01:10:16,000 --> 01:10:18,000
I don't mean that we have to assign

1009
01:10:18,000 --> 01:10:20,000
a very low credence to them,

1010
01:10:20,000 --> 01:10:22,000
but it's reasonable to be doubtful among them,

1011
01:10:22,000 --> 01:10:25,000
to not feel like, ah, we're epistemically compelled

1012
01:10:25,000 --> 01:10:29,000
to accept many worlds over all the other interpretations.

1013
01:10:29,000 --> 01:10:32,000
So it's a good, interpretations of quantum mechanics

1014
01:10:32,000 --> 01:10:35,000
is a good example of a domain in which I think

1015
01:10:35,000 --> 01:10:40,000
the universal Dubaiity and universal bizarreness claim is true.

1016
01:10:40,000 --> 01:10:43,000
And then I want to say the same thing about, say,

1017
01:10:43,000 --> 01:10:46,000
the theories of consciousness,

1018
01:10:46,000 --> 01:10:50,000
and theories of the fundamental structure of the cosmos.

1019
01:10:50,000 --> 01:10:52,000
And both of those, I think, are, I mean,

1020
01:10:52,000 --> 01:10:54,000
the interpretation of quantum mechanics

1021
01:10:54,000 --> 01:10:56,000
and the nature of consciousness are both part of

1022
01:10:56,000 --> 01:10:58,000
the fundamental structure of the cosmos.

1023
01:10:58,000 --> 01:11:02,000
I kind of almost get that for free once you get those two.

1024
01:11:02,000 --> 01:11:06,000
You know, I generally, when pressed,

1025
01:11:06,000 --> 01:11:10,000
put my credence in many worlds at between 90% and 95%.

1026
01:11:10,000 --> 01:11:11,000
You know, depending on the time of day,

1027
01:11:11,000 --> 01:11:13,000
I'll give one of those two numbers.

1028
01:11:13,000 --> 01:11:15,000
And I did that in conversation with Philip Goff,

1029
01:11:15,000 --> 01:11:18,000
the famous panpsychist and previous mindscape cast,

1030
01:11:18,000 --> 01:11:21,000
and he was just flabbergasted.

1031
01:11:21,000 --> 01:11:24,000
He's like, you give a 95% credence

1032
01:11:24,000 --> 01:11:27,000
to the many worlds interpretation of quantum mechanics.

1033
01:11:27,000 --> 01:11:29,000
But dude, you're a panpsychist.

1034
01:11:29,000 --> 01:11:31,000
You think electrons have feelings.

1035
01:11:31,000 --> 01:11:33,000
Don't give me a hard time for giving large credence

1036
01:11:33,000 --> 01:11:35,000
to following the Schrodinger equation.

1037
01:11:35,000 --> 01:11:38,000
I'm sorry.

1038
01:11:38,000 --> 01:11:41,000
Right. Totally fair. Totally fair.

1039
01:11:41,000 --> 01:11:43,000
I mean, I wouldn't give many worlds quite that high

1040
01:11:43,000 --> 01:11:44,000
in interpretation.

1041
01:11:44,000 --> 01:11:48,000
I think we should be more epistemically cautious

1042
01:11:48,000 --> 01:11:51,000
about our favorite interpretation of quantum mechanics.

1043
01:11:51,000 --> 01:11:53,000
But yeah, there's room for reasonable disagreement.

1044
01:11:53,000 --> 01:11:56,000
I mean, I think if you're in the ballpark of 90 to 95%,

1045
01:11:57,000 --> 01:12:02,000
you're getting on the cusp of denying universal dubiety.

1046
01:12:02,000 --> 01:12:07,000
But you know, how, what exactly counts as being dubious

1047
01:12:07,000 --> 01:12:08,000
is kind of a fuzzy.

1048
01:12:08,000 --> 01:12:11,000
You do suggest in the book that when you're in this position

1049
01:12:11,000 --> 01:12:13,000
where every option is bizarre,

1050
01:12:13,000 --> 01:12:17,000
we should give fairly large credences

1051
01:12:17,000 --> 01:12:19,000
to the competing possibilities

1052
01:12:19,000 --> 01:12:22,000
because we kind of don't have a right to be too confident

1053
01:12:22,000 --> 01:12:25,000
about preferring one bizarre alternative

1054
01:12:25,000 --> 01:12:27,000
to other bizarre alternatives.

1055
01:12:27,000 --> 01:12:30,000
We shouldn't be too definitive.

1056
01:12:30,000 --> 01:12:32,000
Yes.

1057
01:12:32,000 --> 01:12:34,000
I think that's generally true

1058
01:12:34,000 --> 01:12:36,000
about the kinds of questions that we're asking

1059
01:12:36,000 --> 01:12:39,000
because I think we have basically three

1060
01:12:39,000 --> 01:12:43,000
broad types of epistemic grounds

1061
01:12:43,000 --> 01:12:45,000
for choosing among these theories, right?

1062
01:12:45,000 --> 01:12:47,000
One is common sense,

1063
01:12:47,000 --> 01:12:49,000
which is that what we've already talked about

1064
01:12:49,000 --> 01:12:50,000
is going to be imperfect

1065
01:12:50,000 --> 01:12:52,000
and things are going to violate it.

1066
01:12:52,000 --> 01:12:53,000
These theories are going to violate it

1067
01:12:53,000 --> 01:12:55,000
in one respect or another.

1068
01:12:55,000 --> 01:12:58,000
Another is scientific evidence.

1069
01:12:58,000 --> 01:13:00,000
You know, just kind of direct scientific evidence,

1070
01:13:00,000 --> 01:13:02,000
you know, like measure it, right?

1071
01:13:02,000 --> 01:13:07,000
And on something like whether electrons have souls

1072
01:13:07,000 --> 01:13:11,000
or what interpretation of quantum mechanics is correct,

1073
01:13:11,000 --> 01:13:14,000
we can't now at least run an experiment that says,

1074
01:13:14,000 --> 01:13:16,000
ah, yeah, this experiment proves,

1075
01:13:16,000 --> 01:13:17,000
obviously on the face of it,

1076
01:13:17,000 --> 01:13:19,000
that many worlds interpretation, right?

1077
01:13:19,000 --> 01:13:21,000
And then the third tool we have is something

1078
01:13:21,000 --> 01:13:24,000
like theoretical elegance.

1079
01:13:24,000 --> 01:13:26,000
And again, that's kind of going to be indecisive

1080
01:13:26,000 --> 01:13:28,000
because, you know, there's something elegant

1081
01:13:28,000 --> 01:13:30,000
about panpsychism

1082
01:13:30,000 --> 01:13:33,000
and there's something elegant about materialism

1083
01:13:33,000 --> 01:13:35,000
and there's something elegant about many worlds

1084
01:13:35,000 --> 01:13:39,000
and there's something elegant about other approaches too.

1085
01:13:39,000 --> 01:13:41,000
So these are not going to be,

1086
01:13:41,000 --> 01:13:44,000
they're going to be trade-offs among these very imperfect ways

1087
01:13:44,000 --> 01:13:46,000
of trying to settle these questions

1088
01:13:46,000 --> 01:13:50,000
rather than

1089
01:13:50,000 --> 01:13:53,000
bronze solid grounds.

1090
01:13:53,000 --> 01:13:55,000
Well, I wanted to ask you this specifically

1091
01:13:55,000 --> 01:13:57,000
in the context of quantum mechanics

1092
01:13:57,000 --> 01:14:00,000
because I've put it the following way sometimes.

1093
01:14:00,000 --> 01:14:02,000
I wanted to see how it fits in with your views.

1094
01:14:02,000 --> 01:14:05,000
If you take something like hidden variables,

1095
01:14:05,000 --> 01:14:07,000
versions of quantum mechanics,

1096
01:14:07,000 --> 01:14:10,000
so those listeners who don't know what I'm talking about,

1097
01:14:10,000 --> 01:14:12,000
we did an episode with Tim Maudlin recently

1098
01:14:12,000 --> 01:14:13,000
where he will explain.

1099
01:14:13,000 --> 01:14:15,000
And in those theories, you have particles

1100
01:14:15,000 --> 01:14:17,000
and they have locations.

1101
01:14:17,000 --> 01:14:19,000
And that's what you observe when you do a measurement

1102
01:14:19,000 --> 01:14:21,000
and you also have a wave function.

1103
01:14:21,000 --> 01:14:25,000
The phenomenology is much closer to the world

1104
01:14:25,000 --> 01:14:28,000
than it is in something like many worlds

1105
01:14:28,000 --> 01:14:30,000
where you have this abstract wave function

1106
01:14:30,000 --> 01:14:33,000
and there's many copies of reality, etc.

1107
01:14:33,000 --> 01:14:37,000
I think that there's much less elegance, simplicity,

1108
01:14:37,000 --> 01:14:41,000
austerity to the hidden variables version

1109
01:14:41,000 --> 01:14:42,000
as a theory.

1110
01:14:42,000 --> 01:14:44,000
I think this is indisputable.

1111
01:14:44,000 --> 01:14:46,000
Do you agree that it's the best theory or not?

1112
01:14:46,000 --> 01:14:50,000
You should also agree it's a clunkier theory

1113
01:14:50,000 --> 01:14:51,000
than many worlds.

1114
01:14:51,000 --> 01:14:53,000
Many worlds is very simple and austere,

1115
01:14:53,000 --> 01:14:57,000
but I should also accept that many worlds

1116
01:14:57,000 --> 01:15:01,000
is much further away from our everyday life

1117
01:15:01,000 --> 01:15:05,000
and our experience than the hidden variables theory is.

1118
01:15:05,000 --> 01:15:07,000
So the question is how do we weigh

1119
01:15:07,000 --> 01:15:09,000
these different considerations?

1120
01:15:09,000 --> 01:15:12,000
It's good to have a simple theory.

1121
01:15:12,000 --> 01:15:15,000
It's also good to have one that tells you pretty directly

1122
01:15:15,000 --> 01:15:19,000
and immediately what it predicts and how to understand it.

1123
01:15:19,000 --> 01:15:22,000
How do we be good philosophers and scientists

1124
01:15:22,000 --> 01:15:25,000
when we're faced with that kind of choice?

1125
01:15:25,000 --> 01:15:26,000
Right, exactly.

1126
01:15:26,000 --> 01:15:29,000
And I'd say just leave that hanging as a question.

1127
01:15:29,000 --> 01:15:31,000
So I am inclined to agree.

1128
01:15:31,000 --> 01:15:33,000
You're much more expert on this than I am,

1129
01:15:33,000 --> 01:15:35,000
but one of the things that I like about many worlds

1130
01:15:35,000 --> 01:15:38,000
is that it is have a certain kind of simplicity to it.

1131
01:15:38,000 --> 01:15:41,000
And these other theories all seem to involve

1132
01:15:41,000 --> 01:15:45,000
a lot of fussing around.

1133
01:15:45,000 --> 01:15:50,000
But right, how do you weigh that against other aspects

1134
01:15:50,000 --> 01:15:55,000
that reasonably draw people to resist many worlds

1135
01:15:55,000 --> 01:15:57,000
and prefer these other approaches?

1136
01:15:57,000 --> 01:16:02,000
And I don't think that there is a really good general answer

1137
01:16:02,000 --> 01:16:04,000
to that kind of question.

1138
01:16:04,000 --> 01:16:07,000
And that's one of the reasons to have kind of

1139
01:16:07,000 --> 01:16:12,000
non-extreme credences in these various theoretical possibilities.

1140
01:16:12,000 --> 01:16:13,000
Good, yeah.

1141
01:16:13,000 --> 01:16:15,000
And if you do have non-extreme credences,

1142
01:16:15,000 --> 01:16:17,000
then you can hope for progress.

1143
01:16:17,000 --> 01:16:19,000
You can hope to get better.

1144
01:16:19,000 --> 01:16:22,000
I guess maybe to wind up the conversation,

1145
01:16:22,000 --> 01:16:27,000
I like giving actionable advice to the people out there.

1146
01:16:27,000 --> 01:16:30,000
We've talked a little about how to deal with these crazy things.

1147
01:16:30,000 --> 01:16:34,000
Maybe to go back to that idea that I'd never heard of before,

1148
01:16:34,000 --> 01:16:36,000
Nicolosi and discounting.

1149
01:16:36,000 --> 01:16:41,000
Maybe that's the same idea as when your credences get small enough,

1150
01:16:41,000 --> 01:16:43,000
I'm allowed to stop thinking about it.

1151
01:16:43,000 --> 01:16:45,000
Is that right?

1152
01:16:45,000 --> 01:16:47,000
That is basically the idea, yeah.

1153
01:16:47,000 --> 01:16:48,000
That's basically the idea.

1154
01:16:48,000 --> 01:16:50,000
I think that idea is important,

1155
01:16:50,000 --> 01:16:56,000
but maybe part of your message in the book is

1156
01:16:56,000 --> 01:17:03,000
don't be quite so quick to dismiss the tinier, more bizarre possibilities.

1157
01:17:03,000 --> 01:17:04,000
I don't know.

1158
01:17:04,000 --> 01:17:05,000
Is that right?

1159
01:17:05,000 --> 01:17:06,000
Yes.

1160
01:17:06,000 --> 01:17:08,000
That is one of the messages.

1161
01:17:08,000 --> 01:17:10,000
Absolutely.

1162
01:17:10,000 --> 01:17:14,000
I think that people will tend to have a gut reaction

1163
01:17:14,000 --> 01:17:18,000
against views that strike them as bizarre,

1164
01:17:18,000 --> 01:17:21,000
whether it's many worlds or panpsychism

1165
01:17:21,000 --> 01:17:26,000
or the idea that only humans have souls or whatever it is.

1166
01:17:27,000 --> 01:17:33,000
I think there's reason to take that kind of reaction seriously,

1167
01:17:33,000 --> 01:17:39,000
but there's also reason to not just rely on that

1168
01:17:39,000 --> 01:17:46,000
and to allow that some of these theories that you might think are

1169
01:17:46,000 --> 01:17:50,000
so bizarre as to be absurd,

1170
01:17:50,000 --> 01:17:55,000
maybe they're only bizarre and not actually absurd.

1171
01:17:55,000 --> 01:17:59,000
I guess I'm caught maybe in a little bit of hypocrisy here

1172
01:17:59,000 --> 01:18:03,000
because that's exactly what I want to say to David Merman and his friends.

1173
01:18:03,000 --> 01:18:06,000
He will just dismiss many worlds,

1174
01:18:06,000 --> 01:18:08,000
even though he's a brilliant physicist,

1175
01:18:08,000 --> 01:18:10,000
he'll just say, that's too bizarre.

1176
01:18:10,000 --> 01:18:12,000
I'm just not going to accept that.

1177
01:18:12,000 --> 01:18:15,000
I want to say, no, you have to take it seriously.

1178
01:18:15,000 --> 01:18:17,000
But then there are other people, panpsychists,

1179
01:18:17,000 --> 01:18:20,000
maybe you're an example, who I will say,

1180
01:18:20,000 --> 01:18:22,000
no, that's too bizarre.

1181
01:18:22,000 --> 01:18:23,000
I don't need it.

1182
01:18:23,000 --> 01:18:27,000
I'm not quite sure what the principle stance is here.

1183
01:18:27,000 --> 01:18:29,000
Right, yeah.

1184
01:18:29,000 --> 01:18:32,000
Maybe you should give a little bit of your credence space to panpsychism.

1185
01:18:32,000 --> 01:18:34,000
Just a little.

1186
01:18:34,000 --> 01:18:37,000
Maybe here is the issue.

1187
01:18:37,000 --> 01:18:40,000
There's sort of in principle credence space

1188
01:18:40,000 --> 01:18:44,000
and then there's what I will spend my time worrying about credence space.

1189
01:18:44,000 --> 01:18:46,000
When the credence has become so small,

1190
01:18:46,000 --> 01:18:48,000
I'm not going to lose sleep over it,

1191
01:18:48,000 --> 01:18:52,000
even if maybe someday evidence will come in that will change my mind.

1192
01:18:52,000 --> 01:18:54,000
Right, yeah, that's fair.

1193
01:18:54,000 --> 01:18:56,000
That's fair, yeah.

1194
01:18:56,000 --> 01:18:59,000
Especially as an academic choice, right?

1195
01:18:59,000 --> 01:19:03,000
So there's also this question of,

1196
01:19:03,000 --> 01:19:06,000
what do you spend your academic time thinking about?

1197
01:19:06,000 --> 01:19:08,000
What do you invest your energy in?

1198
01:19:08,000 --> 01:19:11,000
And even if you were to say, give a non-trivial,

1199
01:19:11,000 --> 01:19:15,000
say, 5% credence to panpsychism, that's not tiny.

1200
01:19:15,000 --> 01:19:20,000
But that might not be worth enough of your academic time

1201
01:19:20,000 --> 01:19:23,000
to build theories on.

1202
01:19:23,000 --> 01:19:26,000
I have spent more time than my credence would warrant

1203
01:19:26,000 --> 01:19:28,000
thinking about panpsychism,

1204
01:19:28,000 --> 01:19:31,000
so I actually take this advice very well.

1205
01:19:31,000 --> 01:19:33,000
You've given it more than it's 5% due.

1206
01:19:33,000 --> 01:19:35,000
I think so, I think so.

1207
01:19:35,000 --> 01:19:38,000
Anyway, Eric Schwitzcape, if it was all a dream,

1208
01:19:38,000 --> 01:19:41,000
it was a very fun dream to have.

1209
01:19:41,000 --> 01:19:44,000
So I appreciate, thanks very much for being on the Mindscape podcast.

1210
01:19:44,000 --> 01:19:47,000
Yeah, thanks for having me. It's been fun.

1211
01:19:50,000 --> 01:19:52,000
Thank you.

