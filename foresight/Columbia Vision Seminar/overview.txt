Processing Overview for Columbia Vision Seminar
============================
Checking Columbia Vision Seminar/Hila Chefer - Transformer Explainability.txt
1. **Mistakes are Subjective**: There isn't a clear-cut automatic way to quantify mistakes in image classification tasks. Google has worked on re-tagging ImageNet to account for "mistakes" that may actually make sense, indicating that the concept of a mistake can be subjective.

2. **Evaluating Model Accuracy on Distribution Shifts**: The primary method for evaluating models is by their accuracy on datasets with distribution shifts. This helps to determine if the model can generalize beyond the typical dataset it was trained on.

3. **Manual Example Analysis**: A significant amount of manual work is often required to understand and improve model performance, especially when initially assessing whether certain intuitions are correct.

4. **Semi-Automatic Verification Method**: A semi-automatic verification method could be implemented where a segmentation map identifies the region of interest, which is then fed into another Oracle network for confirmation.

5. **Model Consistency**: Using different models to check if they consistently make the same predictions can indicate whether spurious correlations are learned.

6. **Limitations of Current Approaches**: The current relevancy extraction approach using VITs (Vision Transformers) is limited by tile resolution, and attempts to propagate relevance back to the pixel level have been unsuccessful due to issues with positional encoding.

7. **Explainability Methods**: There are explainability methods that can create decision trees from a model to understand its decision-making process. These methods can help determine if the model is considering factors like color by testing with modified images (e.g., black and white). However, these explainability methods may come at the cost of some accuracy.

8. **Potential for Future Research**: There might be future research that could address the positional encoding issue or develop new architectures that can directly handle pixels without being constrained by tile resolution. This would enable more detailed and nuanced explanations from models.

