{"text": " The following is a conversation with Yann LeCun, his second time in the podcast. He is the chief AI scientist at Meta, formerly Facebook, professor at NYU, touring award winner, one of the seminal figures in the history of machine learning and artificial intelligence, and someone who is brilliant and opinionated in the best kind of way. And so it was always fun to talk to him. This is the Lex Friedman podcast to support it. Please check out our sponsors in the description. And now here's my conversation with Yann LeCun. You co-wrote the article, Self-Supervised Learning, the Dark Matter of Intelligence. Great title, by the way, with Yann Mizra. So let me ask, what is self-supervised learning and why is it the dark matter of intelligence? I'll start by the dark matter part. There is obviously a kind of learning that humans and animals are doing that we currently are not reproducing properly with machines or with AI, right? So the most popular approaches to machine learning today are, or pydimes, I should say, are supervised learning and reinforcement learning. And they are extremely inefficient. Supervised learning requires many samples for learning anything. And reinforcement learning requires a ridiculously large number of trial and errors to, for, you know, a system to run anything. And that's why we don't have self-driving cars. That's a big leap from one to the other. Okay. So that to solve difficult problems, you have to have a lot of human annotation for supervised learning to work and to solve those difficult problems with reinforcement learning. You have to have some way to maybe simulate that problem such that you can do that large scale kind of learning that reinforcement learning requires. Right. So how is it that, you know, most teenagers can learn to drive a car in about 20 hours of practice, whereas even with millions of hours of simulated practice, a self-driving car can't actually learn to drive itself properly. And so obviously we're missing something, right? And it's quite obvious for a lot of people that, you know, the immediate response you get from many people is, well, you know, humans use their background knowledge to learn faster. And they're right. Now, how was that background knowledge acquired? And that's the big question. So now you have to ask, you know, how do babies in the first few months of life learn how the world works, mostly by observation, because they can hardly act in the world. And they learn an enormous amount of background knowledge about the world that may be the basis of what we call common sense. This type of learning is not learning a task. It's not being reinforced for anything. It's just observing the world and figuring out how it works. Building world models, learning world models. How do we do this? And how do we reproduce this in machine? So self-supervisioning is, you know, one instance or one attempt at trying to reproduce this kind of learning. Okay. So you're looking at just observation. So not even the interacting part of a child. It's just sitting there watching mom and dad walk around, pick up stuff, all of that. That's what we mean by background knowledge. Perhaps not even watching mom and dad, just, you know, watching the world go by. Just having eyes open or having eyes closed or the very act of opening and closing eyes. That the world appears and disappears, all of that basic information. And you're saying in order to learn to drive, like the reason humans are able to learn to drive quickly, some faster than others, is because of the background knowledge. They were able to watch cars operate in the world in the many years leading up to it, the physics of basics, objects, all that kind of stuff. That's right. I mean, the basic physics of objects, you don't even know, you don't even need to know, you know, how a car works, right? Because that you can learn fairly quickly. I mean, the example I use very often is you're driving next to a cliff and you know in advance because of your, you know, understanding of intuitive physics that if you turn the wheel to the right, the car will veer to the right, we'll run off the cliff, fall off the cliff and nothing good will come out of this, right? But if you are a sort of, you know, tabular rice reinforcement learning system that doesn't have a model of the world, you have to repeat folding off this cliff thousands of times before you figure out it's a bad idea. And then a few more thousand times before you figure out how to not do it. And then a few more million times before you figure out how to not do it in every situation you ever encounter. So self-supervised learning still has to have some source of truth being told to it by somebody. And so you have to figure out a way without human assistance or without significant amount of human assistance to get that truth from the world. So the mystery there is how much signal is there? How much truth is there that the world gives you, whether it's the human world, like you watch YouTube or something like that, or it's the more natural world. So how much signal is there? So here's the trick. There is way more signal in sort of a self-supervised setting than there is in either a supervised or reinforcement setting. And this is going to my, you know, analogy of the cake. The, you know, low cake has someone that's called it, where when you try to figure out how much information you ask the machine to predict and how much feedback you give the machine at every trial. In reinforcement learning, you give the machine a single scalar. You tell the machine you did good, you did bad. And you only tell this to the machine once in a while. When I say you, it could be the universe telling the machine, right? But it's just one scalar. So as a consequence of this, you cannot possibly learn something very complicated without many, many, many trials where you get many, many feedbacks of this type. Supervised learning, you, you give a few bits to the machine at every, every sample. Let's say your training image system on, you know, recognizing images on the image net. There is 1000 categories, that's a little less than 10 bits of information per sample. But self-supervised learning, here is the setting. You ideally, we don't know how to do this yet, but ideally you would show a machine a segment of a video and then stop the video and ask, ask the machine to predict what's going to happen next. So you let the machine predict and then you let time go by and show the machine what actually happened and hope the machine will, you know, learn to do a better job at predicting next time around. There's a huge amount of information you give the machine because it's an entire video clip of, you know, of the future after the video clip you fed it in the first place. So both for language and for vision, there's a subtle, seemingly trivial construction, but maybe that's representative of what is required to create intelligence, which is filling the gap. So it sounds dumb, but can you it's, it is possible that you can solve all of intelligence in this way. Just for both language, just give a sentence and continue it or give a sentence and there's a gap in it, some words blanked out and you fill in what words go there. For vision, you give a sequence of images and predict what's going to happen next or you fill in what happened in between. Do you think it's possible that formulation alone as a signal for self-supervised learning can solve intelligence for vision and language? I think that's our best shot at the moment. So whether this will take us all the way to, you know, human level intelligence or something or just cat level intelligence is not clear, but among all the possible approaches that people have proposed, I think it's our best shot. So I think this idea of an intelligent system filling in the blanks, either, predicting the future, inferring the past, filling in missing information. I'm currently filling the blank of what is behind your head and what your head looks like and from the back because I have a basic knowledge about how humans are made. And I don't know if you're going to say at which point you're going to speak, whether you're going to move your head this way or that way, which way you're going to look, but I know you're not going to just dematerialize and reappear three meters down the hall because I know what's possible and what's impossible according to the physics. But you have a model of what's possible, what's impossible and then you'd be very surprised if it happens and then you'll have to reconstruct your model. Right. So that's the model of the world. It's what tells you, you know, what fills in the blanks. So given your partial information about the state of the world, given by your perception, your model of the world fills in the missing information and that includes predicting the future, rich predicting the past, you know, filling in things you don't immediately perceive. And that doesn't have to be purely generic vision or visual information or generic language. You can go to specifics like predicting what control decision you make when you're driving in a lane. You have a sequence of images from a vehicle and then you could, you have information if you recorded on video where the car ended up going. So you can go back in time and predict where the car went based on the visual information. That's very specific, domain specific. Right. But the question is whether we can come up with sort of a generic method for, you know, training machines to do this kind of prediction or filling in the blanks. So right now, this type of approach has been unbelievably successful in the context of natural language processing. Every modern natural language processing is pre-trained in self-supervised manner to fill in the blanks. You show it a sequence of words, you remove 10% of them, and then you train some gigantic neural net to predict the words that are missing. And once you've pre-trained that network, you can use the internal representation learned by it as input to, you know, something that you train supervised or whatever. That's been incredibly successful, not so successful in images, although it's making progress. And it's based on sort of manual data augmentation. We can go into this later. But what has not been successful yet is training from video. So getting a machine to learn, to represent the visual world, for example, by just watching video. Nobody has really succeeded in doing this. Okay. Well, let's kind of give a high-level overview. What's the difference in kind and in difficulty between vision and language? So you said people haven't been able to really kind of crack the problem of vision open in terms of self-supervised learning, but that may not be necessarily because it's fundamentally more difficult. Maybe like when we're talking about achieving, like passing the Turing test in the full spirit of the Turing test in language might be harder than vision. That's not obvious. So in your view, which is harder or perhaps are they just the same problem? When the farther we get to solving each, the more we realize it's all the same thing. It's all the same cake. I think what I'm looking for are methods that make them look essentially like the same cake, but currently they're not. And the main issue with learning world models or learning predictive models is that the prediction is never a single thing because the world is not entirely predictable. It may be deterministic or stochastic. We can get into the philosophical discussion about it, but even if it's deterministic, it's not entirely predictable. And so if I play a short video clip and then I ask you to predict what's going to happen next, there's many, many plausible continuations for that video clip. And the number of continuation grows with the interval of time that you're asking the system to make a prediction for. And so one big question with self-provisioning is how you represent this uncertainty, how you represent multiple discrete outcomes, how you represent a continuum of possible outcomes, et cetera. And if you are a classical machine learning person, you say, oh, you just represent a distribution. And that we know how to do when we're predicting words, missing words in the text, because you can have a neural net give a score for every word in the dictionary. It's a big list of numbers, maybe 100,000 or so. And you can turn them into a probability distribution that tells you when I say a sentence, the cat is chasing the blank in the kitchen. There are only a few words that make sense there. It could be a mouse or it could be a lizard spot or something like that. And if I say the blank is chasing the blank in the savannah, you also have a bunch of plausible options for those two words. Because you have kind of a underlying reality that you can refer to to fill in those blanks. So you cannot say for sure in the savannah, if it's a lion or a cheetah or whatever, you cannot know if it's a zebra or a goo or whatever. We're the beast, the same thing. But you can represent the uncertainty by just a long list of numbers. Now, if I do the same thing with video and I ask you to predict a video clip, it's not a discrete set of potential frames. You have to have somewhere representing a sort of infinite number of plausible continuations of multiple frames in a high-dimensional, continuous space. And we just have no idea how to do this properly. Finite high-dimensional. It's finite high-dimensional, yes. Just like the words. They try to get it down to a small finite set of like under a million, something like that. I mean, it's kind of ridiculous that we're doing a distribution over every single possible word for language, and it works. It feels like that's a really dumb way to do it. It seems to be like there should be some more compressed representation of the distribution of the words. You're right about that. I agree. Do you have any interesting ideas about how to represent all the reality in a compressed way such that you can form a distribution over it? That's one of the big questions. How do you do that? I mean, another thing that really is stupid about, I shouldn't say stupid, but simplistic about current approaches to self-supervisioning in NLP in text is that not only do you represent a giant distribution over words, but for multiple words that are missing, those distributions are essentially independent of each other. You don't pay too much of a price for this. The system, in the sentence that I gave earlier, if it gives a certain probability for a lion and cheetah, and then a certain probability for gazelle, wildebeest, and zebra, those two probabilities are independent of each other. It's not the case that those things are independent lions actually attack bigger animals than cheetahs. There's a huge independent hypothesis in this process which is not actually true. The reason for this is that we don't know how to represent properly distributions over combinatorial sequences of symbols, essentially, because the number grows exponentially with the length of the symbols. We have to use tricks for this, but those techniques don't even deal with it. The big question is, would there be some sort of abstract latent representation of text that would say that when I switch lion for cheetah, I also have to switch zebra for gazelle. Yeah, so this independence assumption, let me throw some criticism at you that I often hear and see how you respond. This kind of feeling in the blanks is just statistics. You're not learning anything, like the deep underlying concepts. You're just mimicking stuff from the past. You're not learning anything new such that you can use it to generalize about the world. Okay, let me just say the crude version, which is just statistics. It's not intelligence. What do you have to say to that? What do you usually say to that if you hear this kind of thing? I don't get into those discussions because they are kind of pointless. First of all, it's quite possible that intelligence is just statistics. It's just statistics of a particular kind. This is the philosophical question. Is it possible that intelligence is just statistics? Yeah, but what kind of statistics? So if you're asking the question, are the models of the world that we learn, do they have some notion of causality? Yes. So if the criticism comes from people who say a current machine non-existent don't care about causality, which by the way is wrong, I agree with that. Your model of the world should have your actions as one of the inputs and that will drive you to learn causal models of the world where you know what intervention in the world will cause, what results, or you can do this by observation of other agents acting in the world and observing the effect of other humans, for example. So I think at some level of description, intelligence is just statistics, but that doesn't mean you won't have models that have deep mechanistic explanation for what goes on. The question is how do you learn them? That's the question I'm interested in. Because a lot of people who actually voice their criticism say that those mechanistic models have to come from someplace else. They have to come from human designers. They have to come from, I don't know what, and obviously we learn them. Or if we don't learn them as an individual, nature learned them for us using evolution. So regardless of what you think, those processes have been learned somehow. So if you look at the human brain, just like when we humans introspect about how the brain works, it seems like when we think about what is intelligence, we think about the high level stuff, like the models we've constructed, concepts like cognitive science, like concepts of memory and reasoning module, almost like these high level modules. Is this serve as a good analogy? Like, are we ignoring the dark matter, the basic low level mechanisms, just like we ignore the way the operating system works, we're just using the high level software. We're ignoring that at the low level, the neural network might be doing something like statistics. Like, meaning, sorry to use this word, probably incorrectly and crudely, but doing this kind of fill in the gap kind of learning and just kind of updating the model constantly in order to be able to support the raw sensory information, to predict it and then adjust to the prediction when it's wrong. But like when we look at our brain at the high level, it feels like we're doing, like we're playing chess, like we're, we're like playing with high level concepts and we're stitching them together and we're putting them into long term memory. But really what's going underneath is something we're not able to introspect, which is this kind of simple large neural network that's just filling in the gaps. Right. Well, okay, so there's a lot of questions that are answers there. Okay, so first of all, there's a whole school of thought in neuroscience, competition on neuroscience in particular, that likes the idea of predictive coding, which is really related to the idea I was talking about in self supervised running. So everything is about prediction. The essence of intelligence is the ability to predict. And everything the brain does is trying to predict, predict everything from everything else. Okay, and that's really sort of the underlying principle if you want that self supervised learning is trying to kind of reproduce this idea of prediction as kind of an essential mechanism of task independent learning if you want. The next step is what kind of intelligence are you interested in reproducing? And of course, you know, we all think about, you know, trying to reproduce sort of, you know, high level cognitive processes in humans. But like with machines, we're not even at the level of even reproducing the running processes in a cat brain. You know, the most intelligent or intelligent systems don't have as much common sense as a house cat. So how is it that cats learn? And, you know, cats don't do a whole lot of reasoning. They certainly have causal models. They certainly have, because, you know, many cats can figure out like how they can act on the world to get what they want. They certainly have a fantastic model of intuitive physics, certainly the dynamics of their own bodies, but also praise and things like that. Right. So they're pretty smart. They only do this with about 800 million neurons. We are not anywhere close to reproducing this kind of thing. So to some extent, I could say, let's not even worry about like the high level cognition and kind of, you know, long term planning and reasoning that humans can do until we figure out like, you know, can we even reproduce what cats are doing? Now that said, this ability to learn world models, I think is the key to the possibility of running machines that can also reason. So whenever I give a talk, I say there are three challenges in the three main challenges in machine learning. The first one is, you know, getting machines to learn to represent the world and proposing self supervised learning. The second is getting machines to reason in ways that are compatible with essentially gradient based learning because this is what deep learning is all about really. And the third one is something we have no idea how to solve. At least I have no idea how to solve is can we get machines to learn hierarchical representations of action plans? You know, like, you know, we know how to train them to learn hierarchical representations of perception, you know, with convolutional nets and things like that and transformers. But what about action plans? Can we get them to spontaneously learn good hierarchical representations of actions also gradient based? Yeah, all of that, you know, needs to be somewhat differentiable so that you can apply sort of gradient based learning, which is really what deep learning is about. So it's background knowledge, ability to reason in a way that's differentiable that is somehow connected deeply integrated with that background knowledge or builds on top of that background knowledge. And then giving that background knowledge be able to make hierarchical plans right in the world. So if you take classical optimal control, there's something classical optimal control called model predictive control. And it's, you know, it's been around since the early 60s. NASA uses that to compute trajectories of rockets. And the basic idea is that you have a predictive model of the rocket, let's say, or whatever system you are, you intend to control, which given the state of the system at time t and given an action that you're taking the system. So for a rocket to be thrust and, you know, all the controls you can have, it gives you the state of the system at time t plus delta t, right? So basically differential equation, something like that. And if you have this model, and you have this model in the form of some sort of neural net, or some sort of set of formula that you can back propagate gradient through, you can do what's called model predictive control, or gradient based model predictive control. So you have, you can enroll that model in time, you feel it a hypothesized sequence of actions. And then you have some objective function that measures how well at the end of the trajectory of the system has succeeded or matched what you wanted to do. You know, is it a robot harm, as if you grasp the object you want to grasp, if it's a rocket, you know, are you at the right place near the space station, things like that. And by back propagation through time, and again, this was invented in the 1960s by optimal control theorists, you can figure out what is the optimal sequence of actions that will, you know, get my system to the best final state. So that's a form of reasoning. It's basically planning. And a lot of planning systems in robotics are actually based on this. And, and you can think of this as a form of reasoning. So, you know, to take the example of the teenager driving a car again, you have a pretty good dynamical model of the car, it doesn't need to be very accurate. But you know, again, that if you turn the wheel to the right, and there is a cliff, you're going to run off the cliff, right, you don't need to have a very accurate model to predict that. And you can run this in your mind, and decide not to do it for that reason. Because you can predict in advance that the result is going to be bad. So you can sort of imagine different scenarios, and, and then, you know, employ, or take the first step in the scenario that is most favorable, and then repeat the process of planning that's called receding horizon model predictive control. So even, you know, all those things have names, you know, going back, you know, decades. And so, if you're not not the, you know, in classical optimal control, the model of the world is not generally learned. This, you know, sometimes a few parameters you have to identify that's called systems identification. But, but generally, the model is mostly deterministic and mostly built by hand. So the big question of AI, I think the big challenge of AI for the next decade is how do we get machines to learn predictive models of the world that deal with uncertainty, and deal with the real world in all this complexity. So it's not just trajectory of a rocket, which you can reduce to first principles, it's not, it's not even just a trajectory of a robot arm, which again, you can model by, you know, careful mathematics. But it's everything else, everything we observe in the world, you know, people, behavior, you know, physical systems that involve collective phenomena, like water or, or, you know, trees and, you know, branches in a tree or something, or, or like complex things that, you know, humans have no trouble developing abstract representations and predictive model for, but we still don't know how to deal with machines. Where do you put in, in these three, maybe in the, in the planning stages, the, the game theoretic nature of this world, where your actions not only respond to the dynamic nature of the world, the environment, but also affect it. So if there's other humans involved, is this, is this point number four, or is it somehow integrated into the hierarchical representation of action in your view? I think it's integrated. It's just, it's just that now your model of the world has to deal with, you know, it just makes it more complicated, right? The fact that humans are complicated and not easily predictable, that makes your model of the world much more complicated, that much more complicated. Well, there's a chess, I mean, I suppose chess is an analogy. So multi-carvel tree search. I mean, it, there's a, I go, you go, I go, you go, like, under Kapatha recently gave a talk at MIT about car doors. I think there's some machine learning too, but mostly car doors. And there's a dynamic nature to the car, like the person opening the door, checking, I mean, he wasn't talking about that. He was talking about the perception problem of what the, the ontology of what defines a car door, this big philosophical question. But to me, it was interesting because like, it's obvious that the person opening the car doors, they're trying to get out like here in New York, trying to get out of the car, you slowing down is going to signal something, you speeding up is going to signal something. And that's a dance. It's a asynchronous chess game. I don't know. So it feels like it's not just, I mean, I guess you can integrate all of them to one giant model, like the entirety of the, these little interactions, because it's not as complicated as chess, it's just like a little dance. We do like a little dance together. And then we figure it out. Well, in some ways, it's way more complicated than chess because, because it's continuous, it's uncertain in a continuous manner. It doesn't feel more complicated, but it doesn't feel more complicated because that's what we're, we've evolved to solve. This is the kind of problem we've evolved to solve. And so we're good at it because, you know, nature has made us good at it. Nature has not made us good at chess. We completely suck at chess. In fact, that's why we designed it as a game is to be challenging. And if there is something that, you know, recent progress in chess and Go has made us realize is that humans are really terrible at those things, like really bad. You know, there was a story, right, before Alpha Go that, you know, the best Go player thought there were maybe two or three stones behind, you know, an ideal player that they would call God. In fact, no, there are like nine or 10 stones behind. I mean, we're just bad. So we're not good at, and it's because we have limited working memory. We know we're not very good at like doing this tree exploration that, you know, computers are much better at doing than we are, but we are much better at learning differentiable models to the world. I mean, I said differentiable in the kind of, you know, I should say not differentiable in the sense that, you know, we run back from through it, but in the sense that our brain has some mechanism for estimating gradients of some kind. And that's what, you know, makes us efficient. So if you have an agent that consists of a model of the world, which, you know, in the human brain is basically the entire front half of your brain, an objective function, which in humans is a combination of two things. There is your sort of intrinsic motivation module, which is in the basal ganglia, you know, the base of your brain. That's the thing that measures pain and hunger and things like that, like immediate feelings and emotions. And then there is, you know, the equivalent of what people in Reference Metronomy call a critic, which is a sort of module that predicts ahead what the outcome of a situation will be. And so it's not a cost function, but it's sort of not an objective function, but it's sort of a, you know, trained predictor of the ultimate objective function. And that also is differentiable. And so if all of this is differentiable, your cost function, your critic, your, you know, your world model, then you can use gradient based type methods to do planning, to do reasoning, to do learning, you know, to do all the things that would like an intelligent agent to do. And gradient based learning, like what's your intuition, that's probably at the core of what can solve intelligence. So you don't need like a logic based reasoning in your view. I don't know how to make logic based reasoning compatible with efficient learning. And okay, I mean, there is a big question, perhaps a philosophical question. I mean, it's not that philosophical, but that we can ask is, is that, you know, all the learning algorithms we know from engineering and computer science, proceed by optimizing some objective function? Yeah, right. So one question we may ask is, is those learning in the brain minimize an objective function? I mean, it could be, you know, a composite of multiple objective functions, but it's still an objective function. Second, if it does optimize an objective function, does it do, does it do it by some sort of gradient estimation? You know, it doesn't need to be backdrop, but you know, some way of estimating the gradient in efficient manner, whose complexity is on the same order of magnitude as, you know, actually running the inference. Because you can't afford to do things like, you know, perturbing a weight in your brain to figure out what the effect is, and then sort of, you know, you can do sort of estimating gradient by perturbation. It's, to me, it seems very implausible that the brain uses some sort of, you know, zero-thorough black box gradient free optimization, because it's so much less efficient than gradient optimization. So it has to have a way of estimating gradient. Is it possible that some kind of logic-based reasoning emerges in pockets as a useful, like you said, if the brain is an objective function? Maybe it's a mechanism for creating objective functions. It's a mechanism for creating knowledge bases, for example, that can then be quarried. Like maybe it's an efficient representation of knowledge that's learned in a gradient-based way or something like that. Well, so I think there is a lot of different types of intelligence. So first of all, I think the type of logical reasoning that we think about that we are, you know, maybe stemming from, you know, sort of classical AI of the 1970s and 80s, I think humans use that relatively rarely and are not particularly good at it. But we judge each other based on our ability to solve those rare problems called IQ tests. I think so. Like, I'm not very good at chess. Yes, I'm judging you this whole time because, well, we actually... With your, you know, heritage, I'm sure you're good at chess. No, stereotypes. Not all stereotypes are true. Well, I'm terrible at chess. So, you know, but I think perhaps another type of intelligence that I have is this, you know, ability of sort of building models to the world from, you know, reasoning, obviously, but also data. And those models generally are more kind of analogical, right? So it's reasoning by simulation and by analogy, where you use one model to apply to a new situation. Even though you've never seen that situation, you can sort of connect it to a situation you've encountered before. And your reasoning is more akin to some sort of internal simulation. So you're kind of simulating what's happening when you're building, I don't know, a box out of wood or something, right? You're going to imagine in advance, like, will we be the result of, you know, cutting the wood in this particular way? Are you going to use, you know, screws on nails or whatever? When you are interacting with someone, you also have a model of that person and sort of interact with that person. You know, having this model in mind to kind of tell the person what you think is useful to them. So I think this ability to construct models to the world is basically the essence of intelligence. And the ability to use it then to plan actions that will fulfill a particular criterion, of course, is necessary as well. So I'm going to ask you a series of impossible questions as we keep asking, as I've been doing. So if that's the fundamental sort of dark matter of intelligence, this ability to form a background model, what's your intuition about how much knowledge is required? You know, I think dark matter, you could put a percentage on it of the composition of the universe and how much of it is dark matter, how much of it is dark energy, how much information do you think is required to be a house cat? So you have to be able to, when you see a box going, when you see a human compute the most evil action, if there's a thing that's near an edge, you knock it off, all of that, plus the extra stuff you mentioned, which is a great self-awareness of the physics of your own body and the world. How much knowledge is required, do you think, to solve it? I don't even know how to measure an answer to that question. I'm not sure how to measure it, but whatever it is, it fits in about 800,000 neurons, 800 million neurons. The representation does. Everything, all knowledge, everything, right? You know, it's less than a billion, a dog is 2 billion, but a cat is less than 1 billion. And so multiply that by a thousand and you get the number of synapses. And I think almost all of it is learned through this, you know, a sort of self-supervised running, although, you know, I think a tiny sliver is learned through reinforcement running, and certainly very little through, you know, classical supervised running, although it's not even clear how supervised running actually works in the biological world. So I think almost all of it is self-supervised running, but it's driven by the sort of ingrained objective functions that a cat or human have at the base of their brain, which kind of drives their behavior. So, you know, nature tells us you're hungry. It doesn't tell us how to feed ourselves. That's something that the rest of our brain has to figure out, right? What's interesting, because there might be more like deeper objective functions than allowing the whole thing. So hunger may be some kind of, now you go to like neurobiology, it might be just the brain trying to maintain homeostasis. So hunger is just one of the human perceivable symptoms of the brain being unhappy with the way things are currently. It could be just like one really dumb objective function at the core. But that's how behavior is driven. The fact that, you know, the, or basal ganglia drivers to do things that are different from say an orangutan or certainly a cat is what makes, you know, human nature versus orangutan nature versus cat nature. So for example, you know, our basal ganglia drives us to seek the company of other humans. And that's because nature has figured out that we need to be social animals for our species to survive. And it's true of many primates. It's not true of orangutans, orangutans are solitary animals. They don't seek the company of others. In fact, they avoid them. In fact, they scream at them when they come too close because they're territorial. Because for their survival, you know, evolution has figured out that's the best thing. I mean, they're occasionally social, of course, for, you know, reproduction and stuff like that. But they're mostly solitary. So all of those behaviors are not part of intelligence. You know, people say, oh, you're never going to have intelligent machines because, you know, human intelligence is social. But then you look at orangutans, you look at octopus. Octopus never know their parents. They barely interact with any other and they get to be really smart in less than a year, in like half a year. You know, in a year or they're adults, in two years they're dead. So there are things that we think, as humans, are intimately linked with intelligence, like social interaction, like language. We think, I think we give way too much importance to language as a substrate of intelligence as humans, because we think our reasoning is so linked with language. So for, to solve the house cat intelligence problem, you think you could do it on a desert island. You could have a cat sitting there, looking at the waves, at the ocean waves, and figure a lot of it out. It needs to have sort of, you know, the right set of drives to kind of, you know, get it to do the thing and learn the appropriate things, right? But like, for example, you know, baby humans are driven to learn to stand up and walk. Okay, that's kind of, this desire is hardwired. How to do it precisely is not, that's learned. But the desire to, to walk, move around and stand up, that's sort of hardwired. It's very simple to hardwire this kind of stuff. Oh, like the desire to, well, that's interesting. You're hardwired to want to walk. That's not a, there's got to be a deeper need for walking. I think it was probably socially imposed by society that you need to walk all the other bipedal. No, no, like a lot of simple animals that, you know, would probably walk without ever watching any other members of the species. It seems like a scary thing to have to do because you suck at bipedal walking at first. It seems crawling is much safer, much more like, why are you in a hurry? Well, because, because you have this thing that drives you to do it, you know, which is sort of part of the sort of human development. Is that understood actually what? Not entirely, no. What is, what's the reason to get on two feet? It's really hard. Like most animals don't get on two feet. Why not? Well, they get on four feet. You know, many mammals get on four feet. Yeah, they do. Very quickly. Some of them extremely quickly. But I don't, you know, like from the last time I've interacted with a table, that's much more stable than a thing on two legs. It's just a really hard problem. Yeah, I mean birds have figured it out with two feet. Well, technically, we can go into ontology. They have four, I guess they have two feet. They have two feet. Chickens. You know, dinosaurs have two feet, many of them. Allegedly. I'm just now learning that T-Rex was eating grass, not other animals. T-Rex might have been a friendly pet. What do you think about, I don't know if you looked at the test for general intelligence that Francois Chalet put together? I don't know if you got a chance to look at that kind of thing. Like what's your intuition about how to solve like an IQ type of test? I don't know. I think it's so outside of my radar screen that it's not really relevant, I think in the short term. Well, I guess one way to ask another way, perhaps more closer to what to your work is like, how do you solve MNIST with very little example data? That's right. And that's the answer to this probably is self-supervised running. Just learn to represent images and then learning, you know, to recognize handwritten digits on top of this will only require a few samples. And we observe this in humans, right? You show a young child a picture book with a couple of pictures of an elephant and that's it. The child knows what an elephant is. And we see this today with practical systems that we train image recognition systems with enormous amounts of images either completely self-supervised or very weakly supervised. For example, you can train a neural net to predict whatever hashtag people type on Instagram, right? Then you can do this with billions of images because it's billions per day that are showing up. So the amount of training data there is essentially unlimited. And then you take the output representation, you know, a couple layers down from the outputs of what the system learned and feed this as input to a classifier for any object in the world that you want and it works pretty well. So that's transfer learning, okay? Or weekly supervised transfer learning. People are making very, very fast progress using self-supervised learning with this kind of scenario as well. And my guess is that that's going to be the future. For self-supervised learning, how much cleaning do you think is needed for filtering malicious signal or with a better term? But a lot of people use hashtags on Instagram to get good SEO that doesn't fully represent the contents of the image. Like they'll put a picture of a cat and hashtag it with like science, awesome, fun, I don't know, all kind of... Why would you put science? That's not very good SEO. The way my colleagues who worked on this project at Facebook now, META, META AI, a few years ago, they helped with this is that they only selected something like 17,000 tags that correspond to kind of physical things or situations. Like, you know, that has some visual content. So, you wouldn't have like hash TBT or anything like that. Also, they keep a very select set of hashtags. Is that what you're saying? Yeah. Okay. But it's still on the order of 10 to 20,000. So it's fairly large. Okay. Can you tell me about data augmentation? What the heck is data augmentation? And how is it used maybe contrast of learning for video? What are some cool ideas here? Right. So data augmentation, I mean, first, data augmentation, you know, is the idea of artificially increasing the size of your training set by distorting the images that you have in ways that don't change the nature of the image. Right? So you take... You do MNIST, you can do data augmentation on MNIST, and people have done this since the 1990s, right? You take a MNIST digit and you shift it a little bit or you change the size or rotate it, skew it, you know, etc. Add noise. Add noise, etc. And it works better. If you train a supervised classifier with augmented data, you're going to get better results. Now, it's become really interesting over the last couple years because a lot of self-supervised learning techniques to pre-train vision systems are based on data augmentation. And the basic techniques is originally inspired by techniques that I worked on in the early 90s and Jeff Hinton worked on also in the early 90s. They were sort of parallel work. I used to call this Siamese network. So basically, you take two identical copies of the same network, they share the same weights, and you show two different views of the same object. Either those two different views may have been obtained by data augmentation, or maybe it's two different views of the same scene from a camera that you moved or at different times or something like that, right? Or two pictures of the same person, things like that. And then you train this neural net, those two identical copies of this neural net, to produce an output representation, a vector, in such a way that the representation for those two images are as close to each other as possible, as identical to each other as possible, right? Because you want the system to basically learn a function that will be invariant, that will not change, whose output will not change when you transform those inputs in those particular ways, right? So that's easy to do. What's complicated is how do you make sure that when you show two images that are different, the system will produce different things. Because if you don't have a specific provision for this, the system will just ignore the inputs when you train it, it will end up ignoring the input and just produce a constant vector that is the same for every input, right? That's called a collapse. Now, how do you avoid collapse? So there's two ideas. One idea that I proposed in the early 90s with my colleagues at Bell Labs, Gene Bromley and a couple other people, which we now call contrastive learning, which is to have negative examples, right? So you have pairs of images that you know are different, and you show them to the network and those two copies, and then you push the two output vectors away from each other, and they will eventually guarantee that things that are symmetrically similar produce similar representations and things that are different produce different representations. We actually came up with this idea for a project of doing signature verification. So we would collect signatures from multiple signatures on the same person and then train a neural net to produce the same representation, and then force the system to produce different representation for different signatures. This was actually the problem was proposed by people from what was a subsidiary of AT&T at the time called NCR, and they were interested in storing representation of the signature on the 80 bytes of the magnetic strip of a credit card. So we came up with this idea of having a neural net with 80 outputs that we would quantize on bytes so that we could encode the... And that encoding was then used to compare whether the signature matches or not? That's right. So then you would sign, it would run through the neural net, and then you would compare the output vector to whatever is stored on your card. Did it actually work? It worked, but they ended up not using it because nobody cares actually. I mean, the American financial payment system is incredibly lax in that respect compared to Europe. Over the signatures? What's the purpose of the signatures anyway? Nobody looks at them, nobody cares. So that's contrastive learning, right? So you need positive and negative pairs, and the problem with that is that even though I had the original paper on this, I'm actually not very positive about it because it doesn't work in high dimension. If your representation is high dimensional, there's just too many ways for two things to be different. And so you would need lots and lots and lots of negative pairs. So there is a particular implementation of this, which is relatively recent, from actually the Google Toronto group, where Jeff Hinton is the senior member there, and it's called Simclear, S-I-M-C-L-R. And it's basically a particular way of implementing this idea of contrastive learning, the particular objective function. Now, what I'm much more enthusiastic about these days is non-contrastive methods. So other ways to guarantee that the representations would be different for different inputs. And it's actually based on an idea that Jeff Hinton proposed in the early 90s with his student at the time, Sue Becker. And it's based on the idea of maximizing the mutual information between the outputs of the two systems. You only show positive pairs, you only show pairs of images that you know are somewhat similar. And you're trying the two networks to be informative, but also to be as informative of each other as possible. So basically, one representation has to be predictable from the other, essentially. And he proposed that idea had a couple of papers in the early 90s, and then nothing was done about it for decades. And I kind of revived this idea together with my postdocs at FAIR, particularly a postdoc called Steph Anthony, who's now a junior professor in Finland at University of Alto. We came up with something called, that we call Balu twins. And it's a particular way of maximizing the information content of a vector, you know, using some hypothesis. And we have kind of another version of it that's more recent now called Vicreg, V-I-C-A-R-E-G, that means variance invariance covariance regularization. And it's the thing I'm the most excited about in machine learning in the last 15 years. I mean, I'm not, I'm really, really excited about this. What kind of data augmentation is useful for that non-contrasting learning method? Are we talking about, does that not matter that much? Or it seems like a very important part of the step. Yeah. How you generate the images that are similar, but sufficiently different. Yeah, that's right. It's an important step. And it's also an annoying step because you need to have that knowledge of what the documentation you can do that do not change the nature of the object. And so the standard scenario, which a lot of people working in this area are using, is you use the type of distortion. So basically you do geometric distortion. So one basically just shifts the image a little bit, it's called cropping. Another one kind of changes the scale a little bit. Another one kind of rotates it. Another one changes the colors. You know, you can do a shift in color balance or something like that. Saturation. Another one sort of blurs it. Another one adds noise. So you have like a catalog of kind of standard things and people try to use the same ones for different algorithms so that they can compare. But some algorithms, some self-supervised algorithm actually can deal with much bigger, like more aggressive data augmentation and some don't. So that kind of makes the whole thing difficult. But that's the kind of distortions we're talking about. And so you train with those distortions. And then you chop off the last layer or couple layers of the network. And you use the representation as input to a classifier. You train the classifier on ImageNet, let's say, or whatever, and measure the performance. And interestingly enough, the methods that are really good at eliminating the information that is irrelevant, which is the distortions between those images, do a good job at eliminating it. And as a consequence, you cannot use the representations in those systems for things like object detection and localization because that information is gone. So the type of data augmentation you need to do depends on the tasks you want eventually the system to solve. And the type of standard data augmentation that we use today are only appropriate for object recognition or image classification. They're not appropriate for things like... Can you help me out understand why the localization... So you're saying it's just not good at the negative, like at classifying the negative. So that's why it can't be used for the localization? No, it's just that you train the system, you give it an image and then you give it the same image shifted and scaled, and you tell it that's the same image. So the system basically is trained to eliminate the information about position and size. So now, and now you want to use that to figure out where an object is and what size it is. Like a bounding box, like they'd be able to actually... Okay, it can still find the object in the image. It's just not very good at finding the exact boundaries of that object. Interesting. Which, you know, that's an interesting sort of philosophical question. How important is object localization anyway? We're like obsessed by measuring like image segmentation, obsessed by measuring perfectly knowing the boundaries of objects when arguably that's not that essential to understanding what are the contents of the scene. On the other hand, I think evolutionarily, the first vision systems in animals were basically all about localization, very little about recognition. And in the human brain, you have two separate pathways for recognizing the nature of a scene or an object and localizing objects. So you use the first pathway called the ventral pathway for telling what you're looking at. The other pathway, the dorsal pathway is used for navigation, for grasping, for everything else. And basically, a lot of the things you need for survival are localization and detection. Is similarity learning or contrastive learning or these non-contrastive methods the same as understanding something? Just because you know a distorted cat is the same as a non-distorted cat, does that mean you understand what it means to be a cat? To some extent. I mean, it's a superficial understanding, obviously. But what is the ceiling of this method, do you think? Is this just one trick on the path to doing self-supervised learning or can we go really, really far? I think we can go really far. So if we figure out how to use techniques of that type, perhaps very different, but of the same nature, to train a system from video to do video prediction, essentially. I think we'll have a path towards, I wouldn't say unlimited, but a path towards some level of physical common sense in machines. And I also think that that ability to learn how the world works from a high throughput channel like vision is a necessary step towards real artificial intelligence. In other words, I believe in grounded intelligence. I don't think we can train a machine to be intelligent purely from text. Because I think the amount of information about the world that's contained in text is tiny compared to what we need to know. So, for example, people have attempted to do this for 30 years, the SAG project and things like that, of basically writing down all the facts that are known and hoping that some sort of common sense would emerge. I think it's basically hopeless. But let me take an example. You take an object. I describe a situation to you. I take an object, I put it on the table, and I push the table. It's completely obvious to you that the object will be pushed with the table, because it's sitting on it. There's no text in the world, I believe, that explains this. And so, if you train a machine as powerful as it could be, your GPT 5000 or whatever it is, it's never going to learn about this. That information is just not present in any text. Well, the question with the SAG project, the dream I think is to have like 10 million, say, facts like that, that give you a head start, like a parent guiding you. Now, we humans don't need a parent to tell us that the table will move, sorry, the smartphone will move with the table. But we get a lot of guidance in other ways, so it's possible that we can give it a quick shortcut. And what about cat? The cat knows that. No, but they evolved. No, they learned like us. Sorry, the physics of stuff. Well, yeah, so you're putting a lot of intelligence onto the nurture side, not the nature. There's a very inefficient, arguably, process of evolution that got us from bacteria to who we are today. Started at the bottom, now we're here. So the question is how fundamental is that the nature of the whole hardware? And then is there any way to shortcut it if it's fundamental? If it's not, if it's most of intelligence, most of the cool stuff we've been talking about is mostly nurture, mostly trained. We figured out by observing the world. We can form that big, beautiful, sexy background model that you're talking about just by sitting there. Then, okay, then you need to then like maybe it is all supervised learning all the way down. It's all supervised learning. Whatever it is that makes human intelligence different from other animals, which a lot of people think is language and logical reasoning and this kind of stuff. It cannot be that complicated because it only popped up in the last million years. It only involves less than 1% of a genome, right, which is the difference between human genome and chimps or whatever. So it can be that complicated. It can be that fundamental. Most of the so complicated stuff already exist in cats and dogs and certainly primates, non-human primates. Yeah, that little thing with humans might be just something about social interaction and ability to maintain ideas across like a collective of people. It sounds very dramatic and very impressive, but it probably isn't mechanistically speaking. It is, but we're not there yet. We have, I mean, this is number 634 in the list of problems we have to solve. So basic physics of the world is number one. What are you, just a quick tangent on data augmentation. So a lot of it is hard coded versus learned. Do you have any intuition that maybe there could be some weird data augmentation, like generative type of data augmentation, like doing something weird to images, which then improves the similarity learning process. So not just kind of dumb, simple distortions, but by you shaking your head, just saying that even simple distortions are enough. I think no, I think data augmentation is a temporary necessary evil. So what people are working on now is two things. One is the type of self-supervisioning, like trying to translate the type of self-supervisioning people using language, translating these two images, which is basically a denosing autoencoder method. So you take an image, you block, you mask some parts of it, and then you train some giant neural net to reconstruct the parts that are missing. And until very recently, there was no working methods for that. All the autoencoder type methods for images weren't producing very good representation. But there's a paper now coming out of the Fair Group at Immelo Park that actually works very well. So that doesn't require the documentation, that requires only masking. Okay. Only masking for images. Okay. Right. So you mask a part of the image and you train a system, which in this case is a transformer because the transformer represents the image as non-overlapping patches. So it's easy to mask patches and things like that. Okay. Then my question transfers to that problem, then masking. Why should the mask be a square rectangle? So it doesn't matter. I think we're gonna come up probably in the future with ways to mask that are kind of random, essentially. I mean, they are random already, but... No, no. But something that's challenging, optimally challenging. So maybe it's a metaphor that doesn't apply, but it seems like there's a data augmentation or masking. There's an interactive element with it. You're almost playing with an image, and it's the way we play with an image in our minds. No, but it's like dropout. It's like Boston Machine Training. You know, every time you see a percept, you can perturb it in some way. And then the principle of the training procedure is to minimize the difference of the output or the representation between the clean version and the corrupted version, essentially. And you can do this in real time. So Boston Machine worked like this. You show a percept, you tell the machine that's a good combination of activities or your input neurons. And then you either let them go their merry way without clamping them to values, or you only do this with a subset. And what you're doing is you're training the system so that the stable state of the entire network is the same, regardless of whether it sees the entire input or whether it sees only part of it. You know, the nosing autoencoder method is basically the same thing, right? You're training a system to reproduce the input, the complete input and filling the blanks, regardless of which parts are missing. And that's really the underlying principle. And you could imagine, sort of even in the brain, some sort of neural principle where, you know, neurons can oscillate, right? So they take their activity and then temporarily they kind of shut off to, you know, force the rest of the system to basically reconstruct the input without their help, you know? And I mean, you can imagine, you know, more or less biologically possible processes. Something like that. And I guess with this denoising autoencoder and masking and data augmentation, you don't have to worry about being super efficient. You can just do as much as you want and get better over time. Because I was thinking like you might want to be clever about the way you do all these procedures, you know, but that's only if it's somehow costly to do every iteration, but it's not really. Not really. And then there is, you know, data augmentation without explicit data augmentation is data augmentation by weighting, which is, you know, the sort of video prediction. You're observing a video clip, observing the, you know, the continuation of that video clip. You try to learn a representation using the joint embedding architectures in such a way that the representation of the future clip is easily predictable from the representation of the observed clip. Do you think YouTube has enough raw data from which to learn how to be a cat? I think so. So the amount of data is not the constraint? No, it would require some selection, I think. Some selection of, you know, maybe the right type of data. Don't go down the rabbit hole of just cat videos. You might need to watch some lectures or something. How meta would that be if it like watches lectures about intelligence and then learns, watches your lectures in NYU and learns from that how to be intelligent? I don't think that would be enough. What's your, do you find multimodal learning interesting? We've been talking about visual language, like combining those together, maybe audio, all those kinds of things. There's a lot of things that I find interesting in the short term, but are not addressing the important problem that I think are really kind of the big challenges. So I think, you know, things like multitask learning, continual learning, you know, adversarial issues. I mean, those have, you know, great practical interests in the relatively short term, possibly, but I don't think they're fundamental, you know, active learning, even to some extent reinforcement learning. I think those things will become either obsolete or useless or easy once we figure out how to do self-supervised representation learning or predictive world models. And so I think that's what, you know, the entire community should be focusing on. At least people are interested in sort of fundamental questions or, you know, really kind of pushing the envelope of AI towards the next stage. But of course, there is like a huge amount of, you know, very interesting work to do in sort of practical questions that have, you know, short term impact. Well, you know, it's difficult to talk about the temporal scale because all of human civilization will eventually be destroyed because the the sun will die out. And even if Elon Musk is successful, multi-planetary colonization across the galaxy, eventually the entirety of it will just become giant black holes. And that's gonna take a while though. So, but what I'm saying is then that logic can be used to say it's all meaningless. I'm saying all that to say that multitask learning might be your song, you're calling it practical or pragmatic or whatever. That might be the thing that achieves something very akin to intelligence while we're trying to solve the more general problem of self-supervised learning of background knowledge. So the reason I bring that up may be one way to ask that question. I've been very impressed by what Tesla autopilot team is doing. I don't know if you've gotten a chance to glance at this particular one example of multitask learning where they're literally taking the problem like, I don't know, Charles Darwin start studying animals. They're studying the problem of driving and asking, okay, what are all the things you have to perceive? And the way they're solving it is one, there's an ontology where you're bringing that to the table. So you're formulating a bunch of different tasks. It's like over a hundred tasks or something like that that they're involved in driving. And then they're deploying it and then getting data back from people that run to trouble. And they're trying to figure out, do we add tasks? Do we, like we focus on each individual task separately? In fact, half. So the, I would say, I'll classify Andre Carpathi's talk in two ways. So one was about doors. And the other one about how much ImageNet sucks. He kept going back and forth on those two topics, which ImageNet sucks, meaning you can't just use a single benchmark. There's so like, you have to have like a giant suite of benchmarks to understand how well your system actually works. Oh, I agree with him. I mean, he's a very sensible guy. Now, okay, it's very clear that if you're faced with an engineering problem that you need to solve in a relatively short time, particularly if you have Elon Musk breathing down your neck, you're going to have to take shortcuts, right? You might think about the fact that the right thing to do and the long-term solution involves some fancy self-improvement running, but you have Elon Musk breathing down your neck. And this involves human lives. And so you have to basically just do the systematic engineering and fine-tuning and refinements and try and error and all that stuff. There's nothing wrong with that. That's called engineering. That's called putting technology out in the world. And you have to kind of ironclad it before you do this so much for grand ideas and principles. But I'm placing myself sort of some upstream of this, quite a bit upstream of this. You're a play-doh think about platonic forms. It's not platonic because eventually, I want the stuff to get used, but it's okay if it takes five or 10 years for the community to realize this is the right thing to do. I've done this before. It's been the case before that I've made that case. I mean, if you look back in the mid-2000, for example, and you ask yourself the question, okay, I want to recognize cars or faces or whatever. You know, I can use convolutional nets, so I can use more conventional kind of computer vision techniques using interest point detectors or sift density features and sticking an SVM on top. At that time, the datasets were so small that those methods that use more hand-engineering worked better than comnets. There was just not enough data for comnets. And comnets were a little slow with the kind of hardware that was available at the time. And there was a sea change when, basically, when datasets became bigger and GPUs became available. That's what two of the main factors that basically made people change their mind. And you can look at the history of all sub-branches of AI or pattern recognition. And there's a similar trajectory followed by techniques where people start by, you know, engineering the hell out of it. You know, be it optical character recognition, speech recognition, computer vision like image recognition in general, natural language understanding like, you know, translation, things like that, right? You start to engineer the hell out of it. You start to acquire all the knowledge, the prior knowledge you know about image formation, about, you know, the shape of characters, about, you know, morphological operations, about like feature extraction, Fourier transforms, you know, vernike moments, you know, whatever, right? People have come up with thousands of ways of representing images so that they could be easily classified afterwards. Same for speech recognition, right? There is, you know, two decades for people to figure out a good front-end to prepossess a speech signal so that, you know, the information about what is being said is preserved, but most of the information about the identity of the speaker is gone. You know, casserole coefficients or whatever, right? And same for text, right? You do name identity recognition and you parse and you do tagging of the parts of speech and, you know, you do this sort of tree representation of clauses and all that stuff right before you can do anything. So that's how it starts, right? Just engineer the hell out of it. And then you start having data and maybe you have more powerful computers, maybe you know something about statistical learning. So you start using machine learning and it's usually a small sliver on top of your kind of handcrafted system where, you know, you extract features by hand, okay? And now, you know, nowadays the standard way of doing this is that you train the entire thing end-to-end with a deep learning system and it learns its own features and, you know, speech recognition systems nowadays, OCR systems are completely end-to-end. It's, you know, it's some giant neural net that takes raw waveforms and produces a sequence of characters coming out. And it's just a huge neural net, right? There's no, you know, Markov model, there's no language model that is explicit other than, you know, something that's ingrained in the, in the sort of neural language model if you want. Same for translation, same for all kinds of stuff. So you see this continuous evolution from, you know, less and less hand-crafting and more and more learning. And I think it's true in biology as well. So, I mean, we might disagree about this, maybe not in this one little piece at the end, you mentioned active learning. It feels like active learning, which is the selection of data, and also the interactivity needs to be part of this giant neural network. You cannot just be an observer to do self-supervised learning. You have to, well, self-supervised learning is just a word, but I would, whatever this giant stack of a neural network that's automatically learning, it feels, my intuition is that you have to have a system, whether it's a physical robot or a digital robot that's interacting with the world and doing so in a flawed way and improving over time in order to form the self-supervised learning. Well, you can't just give it a giant sea of data. Okay, I agree and I disagree. I agree in the sense that I think, I agree in two ways. The first way I agree is that if you want and you certainly need a causal model of the world that allows you to predict the consequences of your actions, to train that model, you need to take actions. You need to be able to act in a world and see the effect for you to learn causal models of the world. So that's not obvious because you can observe others and you can infer that they're similar to you and then you can learn from that. Yeah, but then you have to kind of hardware that part and mirror neurons and all that stuff. And it's not clear to me how you would do this in a machine. So I think the action part would be necessary for having causal models of the world. The second reason it may be necessary or at least more efficient is that active learning basically goes for the juggler of what you don't know. Right? There's obvious areas of uncertainty about your world and about how the world behaves. And you can resolve this uncertainty by systematic exploration of that part that you don't know. And if you know that you don't know, then it makes you curious. You kind of look into situations that and across the animal world, different species at different levels of curiosity. Depending on how they're built. So cats and rats are incredibly curious. Dogs know so much, I mean less. So it could be useful to have that kind of curiosity. So it'd be useful, but curiosity just makes the process faster. It doesn't make the process exist. So what process, what learning process is it that active learning makes more efficient? And I'm asking that first question. We haven't answered that question yet, so I'll worry about active learning once this question is... So it's the more fundamental question to ask. And if active learning or interaction increases the efficiency of the learning. See, sometimes it becomes very different if the increase is several orders of magnitude. Right? That's true. But fundamentally, it's still the same thing. And building up the intuition about how to in a self-supervised way to construct background models, efficient or inefficient, is the core problem. What do you think about Yosha Ben-Jos talking about consciousness and all of these kinds of concepts? Okay. I don't know what consciousness is, but... It's a good opener. And to some extent, a lot of the things that are said about consciousness remind me of the questions people were asking themselves in the 18th century or 17th century when they discovered that how the eye works and the fact that the image at the back of the eye was upside down because you have a lens. And so on your retina, the image that forms is an image of the world, but it's upside down. How is it that you see right side up? And with what we know today in science, we realize this question doesn't make any sense or is kind of ridiculous in some way. Right? So I think a lot of what is said about consciousness is of that nature. Now that said, there's a lot of really smart people for whom I have a lot of respect who are talking about this topic, people like David Chalmers, who is a colleague of mine at NYU. I have kind of an orthodox folk speculative hypothesis about consciousness. So we're talking about this idea of a world model. And I think our entire prefrontal context basically is the engine for a world model. But when we are attending at a particular situation, we're focused on that situation, we basically cannot attend to anything else. And that seems to suggest that we basically have only one world model engine in our prefrontal context. That engine is configurable to the situation at hand. So we are building a box out of wood or we are driving down the highway playing chess. We basically have a single model of the world that we configure into the situation at hand, which is why we can only attend to one task at a time. Now, if there is a task that we do repeatedly, it goes from the sort of deliberate reasoning using model of the world and prediction and perhaps something like model predictive control, which I was talking about earlier, to something that is more subconscious that becomes automatic. So I don't know if you've ever played against a chess grandmaster. I get wiped out in 10 plays. And I have to think about my move for like 15 minutes. And the person in front of me, the grandmaster, would just like react within seconds. He doesn't need to think about it. That's become part of the subconscious because it's basically just pattern recognition at this point. The first few hours you drive a car, you are really attentive, you can't do anything else. And then after 20, 30 hours of practice, 50 hours, it's subconscious. You can talk to the person next to you, things like that. Unless the situation becomes unpredictable, and then you have to stop talking. So that suggests you only have one model in your head. And it might suggest the idea that consciousness basically is the module that configures this world model of yours. You need to have some sort of executive kind of overseer that configures your world model for the situation at hand. And that needs to kind of the really curious concept that consciousness is not a consequence of the power of our mind, but of the limitation of our brains. But because we have only one world model, we have to be conscious. If we had as many world models as there are situations we encounter, then we could do all of them simultaneously. And we wouldn't need this sort of executive control that we call consciousness. Yeah, interesting. And somehow maybe that executive controller, I mean, the hard problem of consciousness, there's some kind of chemicals and biology that's creating a feeling like it feels to experience some of these things. That's kind of like the hard question is, what the heck is that? And why is that useful? Maybe the more pragmatic question? Why is it useful to feel like this is really you experiencing this versus just like information being processed? It could be just a very nice side effect of the way we evolved. That's just very useful to feel a sense of ownership to the decisions you make, to the perceptions you make, to the model you're trying to maintain, like you own this thing. And this is the only one you got. And if you lose it, it's going to really suck. And so you should really send the brain some signals about it. What ideas do you believe might be true that most or at least many people disagree with you with? Let's say in the space of machine learning. Well, depends who you talk about. So certainly there is a bunch of people who are nativists, who think that a lot of the basic things about the world are kind of hardwired in our minds. Things like the world is three dimensional, for example, is that hardwired. Things like object permanence is something that we learn before the age of three months or so, or are we born with it? And there are very wide disagreements among the cognitive scientists for this. I think those things are actually very simple to learn. Is it the case that the oriented edge detectors in V1 are learned or are they hardwired? I think they are learned. They might be learned before both because it's really easy to generate signals from the retina that actually will train edge detectors. And again, those are things that can be learned within minutes of opening your eyes. Since the 1990s, we have algorithms that can learn oriented edge detectors completely unsupervised with the equivalent of a few minutes of real time. So those things have to be learned. And there's also those MIT experiments where you kind of plug the optical nerve on the auditory cortex of a baby ferret and that auditory cortex become a visual cortex essentially. So clearly, there's running taking place there. So I think a lot of what people think are so basic that they need to be hardwired, I think a lot of those things are learned because they're easy to learn. So you put a lot of value in the power of learning. What kind of things do you suspect might not be learned? Is there something that could not be learned? So your intrinsic drives are not learned. There are the things that make humans human or make cats different from dogs. It's the basic drives that are kind of hardwired in our Bezo Ganglia. I mean, there are people who are working on this kind of stuff that's called intrinsic motivation in the context of reinforcement learning. So these are objective functions where the reward doesn't come from the external world. It's computed by your own brain. Your own brain computes whether you're happy or not. It measures your degree of comfort or in comfort. And because it's your brain computing this, presumably it knows also how to estimate gradients of this. So it's easier to learn when your objective is intrinsic. So that has to be hardwired. The critic that makes long-term prediction of the outcome, which is the eventual result of this, that's learned. And perception is learned and your model of the world is learned. But let me take an example of why the critic... I mean, an example of how the critic may be learned. If I come to you, I reach across the table and I pinch your arm, complete surprise for you. You would not have expected this from me. I was expecting that the whole time, but yes. Let's say for the sake of the story. Okay. Your bezelganglia is going to light up because it's going to hurt, right? And now your model of the world includes the fact that I may pinch you if I approach my... Don't trust humans. My hand to your arm. So if I try again, you're going to recoil. And that's your critic, your predictor of your ultimate pain system that predicts that something bad is going to happen and you recoil to avoid it. So even that can be learned. That is learned, definitely. This is what allows you also to define some goals, right? So the fact that you're a school child who wake up in the morning and you go to school and it's not because you necessarily like waking up early and going to school, but you know that there is a long-term objective you're trying to optimize. So Ernest Becker, I'm not sure if you're familiar with the philosopher who wrote the book Denial of Death. And his idea is that one of the core motivations of human beings is our terror of death, our fear of death. That's what makes us unique from cats. Cats are just surviving. They do not have a deep, like cognizance introspection that over the horizon is the end. And he says that, I mean, there's a terror management theory that just all these psychological experiments that show basically this idea that all of human civilization, everything we create, is kind of trying to forget if even for a brief moment that we're going to die. When do you think humans understand that they're going to die? Is it learned early on also? I don't know at what point. I mean, it's a question like, at what point do you realize that what death really is? And I think most people don't actually realize what death is, right? I mean, most people believe that you go to heaven or something, right? So to push back on that, what Ernest Becker says and Sheldon Solomon, all of those folks, and I find those ideas a little bit compelling is that there is moments in life, early in life. A lot of this fun happens early in life when you are, when you do deeply experience the terror of this realization and all the things you think about about religion, all those kinds of things that we kind of think about more like teenage years and later. We're talking about way earlier. No, there's like seven or eight years or something like that. Yeah. You realize, holy crap, this is like the mystery, the terror, like it's almost like you're a little prey, a little baby deer sitting in the darkness of the jungle of the woods, looking all around you, there's darkness full of terror. I mean, that's, that realization says, okay, I'm going to go back in the comfort of my mind where there is a, where there is a deep meaning where there is a, maybe like pretend I'm immortal and however way, however kind of idea I can construct to help me understand that I'm immortal. Religion helps with that. You can, you can delude yourself in all kinds of ways, like lose yourself in the busyness of each day, have little goals in mind, all those kinds of things to think that it's going to go on forever. And you kind of know you're going to die. Yeah. And it's going to be sad, but you don't really understand that you're going to die. And so that's, that's their idea. And I find that compelling because it does seem to be a core unique aspect of human nature that we were able to think that we're going, we're able to really understand that this life is finite. That seems important. There's, there's a bunch of different things there. So first of all, I don't think there is a qualitative difference between, between us and cats in the term. I think the difference is that we just have a better long term ability to predict, you know, in the long term. And so we have a better understanding of other world works. So we have better understanding of, you know, funniness of life and things like that. Do we have a better planning engine than cats? Yeah. Okay. But what's the motivation for planning that far? Well, I think it's just a side effect to the fact that we have just a better planning engine because it makes us, as I said, you know, the essence of intelligence is the ability to predict. And so the, because we're smarter, as a side effect, we also have this ability to kind of make predictions about our own future existence or lack the rough. You say religion helps with that. I think religion hurts actually. It makes people worry about like, you know, what's going to happen after their death, etc. If you believe that, you know, you just don't exist after death, like, you know, it solves completely the problem at least. You're saying if you don't believe in God, you don't worry about what happens after death? Yeah. I don't know. You only worry about the, about, you know, this life, because that's the only one you have. I think it's, well, I don't, I don't know, if I were to say what Ernest Becker says, and I'll say I agree with him more than not is you do deeply worry. If you, if you believe there's no God, there's still a deep worry like of the mystery of it all. Like, how does that make any sense that it just ends? I don't think we can truly understand that this right. I mean, so much of our life, the consciousness, the ego is invested in this, in this being. And then science keeps bringing humanity down from its pedestal. And that's, that's just another, example of it. That's wonderful. But for us individual humans, we don't like to be brought down from a pedestal. You're saying like, but see, you're fine with it because, well, so what Ernest Becker would say is you're fine with it because that's just a more peaceful existence for you, but you're not really fine. You're hiding from, in fact, some of the people that experienced the deepest trauma that earlier in life, they often, before they seek extensive therapy will say that I'm fine. It's like, when you talk to people who are truly angry, how are you doing? I'm fine. The question is, what's going on? Now I had a near death experience. I had a very bad motorbike accident when I was 17. So, but that didn't have any impact on my reflection on that topic. So I'm basically just playing a bit of devil's advocate and pushing back and wondering, is it truly possible to accept death? And the flip side that's more interesting, I think, for AI and robotics is how important is it to have this as one of the suite of motivations is to not just avoid falling off the roof or something like that, but ponder the end of the ride. Well, if you listen to the Stoics, it's a great motivator. It adds a sense of urgency. So it might be to truly fear death or be cognizant of it might give a deeper meaning and urgency to the moment to live fully. Maybe I don't disagree with that. I mean, I think what motivates me here is knowing more about human nature. I mean, I think human nature and human intelligence is a big mystery. It's a scientific mystery in addition to philosophical and etc. But I'm a true believer in science. And I do have kind of a belief that for complex systems like the brain and the mind, the way to understand it is to try to reproduce it with artifacts that you built. Because you know what's essential to it when you try to build it. The same way, I've used this analogy before with you, I believe, the same way we only started to understand aerodynamics when we started building airplanes. And that helped us understand how birds fly. So I think there's a similar process here where we don't have a theory of a full theory of intelligence. But building intelligent artifacts will help us perhaps develop some underlying theory that encompasses not just artificial implements, but also human and biological intelligence in general. So you're an interesting person to ask this question about sort of all kinds of different other intelligent entities or intelligences. What are your thoughts about kind of like the touring or the Chinese room question? If we create an AI system that exhibits a lot of properties of intelligence and consciousness, how comfortable are you thinking of that entity as intelligent or conscious? So you're trying to build now systems that have intelligence and there's metrics about their performance. But that metric is external. So are you okay calling a thing intelligent? Or are you going to be like most humans and be once again unhappy to be brought down from a pedestal of consciousness slash intelligence? No, I'll be very happy to understand more about human nature, human mind and human intelligence through the construction of machines that have similar abilities. And if a consequence of this is to bring down humanity one notch down from its already low pedestal, I'm just fine with it. That's just a reality of life. So I'm fine with that. Now you were asking me about things that opinions I have that a lot of people may disagree with. I think if we think about the design of an autonomous intelligence system, so assuming that we are somewhat successful at some level of getting machines to learn models of the world, predictive models of the world, we build intrinsic motivation, objective functions to drive the behavior of that system. The system also has perception modules that allows it to estimate the state of the world and then have some way of figuring out a sequence of actions that to optimize a particular objective. If it has a critic of the type that was describing before, the thing that makes recoil your arm the second time I try to pinch you, intelligent autonomous machine will have emotions. I think emotions are an integral part of autonomous intelligence. If you have an intelligence system that is driven by intrinsic motivation, by objectives, if it has a critic that allows it to predict in advance whether the outcome of a situation is going to be good or bad, it's going to have emotions. It's going to have fear when it predicts that the outcome is going to be bad and something to avoid is going to have elation when it predicts it's going to be good. If it has drives to relate with humans in some ways, the way humans have, it's going to be social. It's going to have emotions about attachment and things of that type. I think the sci-fi thing where you see commander data like having an emotion chip that you can turn off, I think that's ridiculous. So, here's the difficult philosophical social question. Do you think there will be a time like a civil rights movement for robots where, okay, forget the movement, but a discussion like the Supreme Court that particular kinds of robots, particular kinds of systems, deserve the same rights as humans because they can suffer just as humans can, all those kinds of things? Well, perhaps not. Imagine that humans were that you could die and be restored. You could be 3D reprinted and your brain could be reconstructed in its finest details. Our ideas of rights will change in that case. If there's always a backup, you could always restore. Maybe the importance of murder will go down one notch. That's right. But also, your desire to do dangerous things like skydiving or race car racing or that kind of stuff would probably increase or airplane aerobatics or that kind of stuff. It would be fine to do a lot of those things or explore dangerous areas and things like that. It would change your relationship. Now, it's very likely that robots would be like that because they'll be based on perhaps technology that is somewhat similar to this technology and you can always have a backup. So, it's possible. I don't know if you like video games, but there's a game called Diablo. My sons are huge fans of this. Yes. In fact, they made a game that's inspired by it. Awesome. Like built a game? My three sons have a game design studio between them. That's awesome. They came out with a game. They just came out of the game. Last year? No, this was last year, about a year ago. That's awesome. But in Diablo, there's something called hardcore mode, which if you die, there's no, you're gone. That's it. And so, it's possible with AI systems for them to be able to operate successfully and for us to treat them in a certain way because they have to be integrated in human society, they have to be able to die no copies allowed. In fact, copying is illegal. It's possible with humans as well, like cloning will be illegal, even when it's possible. But cloning is not copying, right? I mean, you don't reproduce the mind of the person and experience. It's just a delayed twin. But then, we were talking about with computers that you'll be able to copy. You'll be able to perfectly save, pickle the mind state. And it's possible that that would be illegal because that will destroy the motivation of the system. Okay, so let's say you have a domestic robot, sometime in the future. And the domestic robot comes to you somewhat pre-trained, can do a bunch of things. But it has a particular personality that makes it slightly different from the other robots because that makes them more interesting. And then because it's lived with you for five years, you've grown some attachment to it and vice versa. And it's learned a lot about you. Or maybe it's not a household robot, maybe it's a virtual assistant that lives in your augmented reality glasses or whatever, right? The HER movie type thing, right? And that system to some extent, the intelligence in that system is a bit like your child or maybe your PhD student in the sense that there's a lot of you in that machine now, right? And so, if it were a living thing, you would do this for free if you want, right? If it's your child, your child can then live his or her own life. And the fact that they learn stuff from you doesn't mean that you have any ownership of it, right? But if it's a robot that you've trained, perhaps you have some intellectual property claim about... Going to intellectual property. Oh, I thought you meant like permanent value in the sense that's part of you is in... Well, there is permanent value, right? So you would lose a lot if that robot were to be destroyed and you had no backup, you would lose a lot. You would lose a lot of investment, you know, kind of like a person dying, you know, that a friend of yours dying or a co-worker or something like that. But also you have intellectual property rights in the sense that that system is fine-tuned to your particular existence. So that's now a very unique instantiation of that original background model, whatever it was that arrived. And then there are issues of privacy, right? Because now imagine that that robot has its own kind of volition and decides to work for someone else or kind of thinks life with you is sort of untenable or whatever. Now, all the things that that system learned from you, you know, how can you like, you know, delete all the personal information that that system knows about you? Yeah. I mean, that would be kind of an ethical question. Like, you know, can you erase the mind of an intelligent robot to protect your privacy? You can't do this with humans. You can ask them to shut up, but that you don't have complete power over them. Can't erase humans. Yeah, it's the problem with the relationships, you know, that you break up, you can't you can't erase the other human with robots. I think it will have to be the same thing with robots that that risk that there has to be some risk to our interactions to truly experience them deeply, it feels like. So you have to be able to lose your robot friend. And that robot friend to go tweeting about how much of an asshole you are. But then are you allowed to, you know, murder the robot to protect your private information? Yeah, probably not. I have this intuition that for robots with with certain, like it's almost like a regulation, if you declare your robot to be, let's call it sentient or something like that, like this, this robot is designed for human interaction, then you're not allowed to murder these robots, it's the same as murdering other humans. Well, but what about you do a backup of the robot, you do preserve on the on a high drive or the equivalent in the future, that might be illegal, just like it's a piracy, piracy is illegal. But it's your own, it's your own robot, right? But you can't, you don't, but then but then you can wipe out his brain. So the this robot doesn't know anything about you anymore, but you still have technically is still in existence because you backed it up. And then there'll be these great speeches at the Supreme Court by saying, Oh, sure, you can erase the mind of the robot, just like you can erase the mind of a human, we both can suffer. There'll be some epic like Obama type character with a speech that we we like the robots and the humans are the same. We can both suffer, we can both hope, we can both all those all those kinds of things, raise families, all that kind of stuff. It's it's interesting for these just like you said, emotion seems to be a fascinatingly powerful aspect of human human interaction, human robot interaction. And if they're able to exhibit emotions at the end of the day, that's probably going to have us deeply consider human rights, like what we value in humans, what we value in other animals. That's why robots and AI is great. It makes us ask as the hard questions. Yeah. But you, I mean, you asked about you asked about the Chinese room type argument, you know, is it real? If it looks real? I think the Chinese room argument is the ridiculous one. So, so for people who don't know Chinese room is you can, I don't even know how to formulate it well, but basically, you can mimic the behavior of an intelligent system by just following a giant algorithm code book that tells you exactly how to respond in exactly each case. But is that really intelligent? It's like a giant lookup table. When this person says this, you answer this, when this person says this, you answer this. And if you understand how that works, you have this giant nearly infinite lookup table. Is that really intelligence? Because intelligence seems to be a mechanism that's much more interesting and complex than this lookup table. I don't think so. So the, I mean, the real question comes down to, do you think, you know, you can, you can mechanize intelligence in some way, even if that involves learning? And the answer is, of course, yes, there's no question. There's a second question then, which is assuming you can reproduce intelligence in sort of different hardware than biological hardware, you know, like computers. Can you, you know, match human intelligence in all the domains in which humans are intelligent? Is it possible, right? So this is quite the hypothesis of strong AI. The answer to this, in my opinion, is an unqualified yes. This would as well happen at some point. There's no question that machines at some point will become more intelligent than humans in all domains where humans are intelligent. This is not for tomorrow, it's going to take a long time, regardless of what, you know, Elon and others have claimed or believed. This is a lot, a lot harder than many of, many of those guys think it is. And many of those guys who thought it was simpler than that years, you know, five years ago, now think it's hard because it's been five years and they realize it's going to take a lot longer than includes a bunch of people at DeepMind, for example. But Oh, interesting. I haven't actually touched base with the DeepMind folks, but some of it, Elon or Dennis Sousa, I mean, sometimes in your role, you have to kind of create deadlines that are nearer than farther away to kind of create an urgency, because, you know, you have to believe the impossible is possible in order to accomplish it. And there's, of course, a flip side to that coin, but it's a weird, you can't be too cynical if you want to get something done. Absolutely. I agree with that. But I mean, you have to inspire people to work on sort of ambitious things. So, you know, it's certainly a lot harder than we believe, but there's no question in my mind that this will, this will happen. And now, you know, people are kind of worried about what does that mean for humans, they are going to be brought down from their pedestal, you know, a bunch of notches with that. And, you know, is that going to be good or bad? I mean, it's just going to give more power, right? It's an amplifier for human intelligence really. So speaking of doing cool, ambitious things, FAIR, the Facebook AI Research Group, has recently celebrated its eighth birthday. Or maybe you can correct me on that. Looking back, what has been the successes, the failures, the lessons learned from the eight years of FAIR? And maybe you can also give context of where does the newly minted meta AI fit into how does it relate to FAIR? Right. So let me tell you a little bit about the organization of all this. Yeah, FAIR was created almost exactly eight years ago. It wasn't called FAIR yet. It took that name a few months later. And at the time, I joined Facebook. There was a group called the AI Group that had about 12 engineers and a few scientists, like, you know, 10 engineers and two scientists or something like that. I ran it for three and a half years as a director, you know, hired the first few scientists and kind of set up the culture and organized it, you know, explained to the Facebook leadership what fundamental research was about and how it can work within industry and how it needs to be open and everything. And I think it's been an unqualified success in the sense that FAIR has simultaneously produced, you know, top level research and advanced the science and the technology provided tools, open source tools like PyTorch and many others. But at the same time as had a direct or mostly indirect impact on Facebook at the time, now meta, in the sense that a lot of systems that are that meta is built around now are based on research projects that started at FAIR. And so if you were to take out, you know, deep running out of Facebook services now and meta more generally, I mean, the company would literally crumble. I mean, it's completely built around AI these days. And it's really essential to the operations. So what happened after three and a half years is that I changed role, I became chief scientist. So I'm not doing day to day management of FAIR anymore. I'm more of a kind of, you know, think about strategy and things like that. And I carry my, I conduct my own research, I've, you know, my own kind of research group working on self supervised learning and things like this, which I didn't have time to do when I was director. So now FAIR is run by Joel Pinot and Antoine Baud together, because FAIR is kind of split into now there's something called FAIR Labs, which is sort of bottom up census driven research and FAIR Excel, which is slightly more organized for bigger projects that require a little more kind of focus and more engineering support and things like that. So Joel needs FAIR Lab and Antoine Baud needs FAIR Excel. Where are they located? It's delocalized all over. So there's no question that the leadership of the company believes that this was a very worthwhile investment. And what that means is that it's there for the long run, right? So there is, if you want to talk in these terms, which I don't like, there's a business model, if you want, where FAIR, despite being a very fundamental research lab brings a lot of value to the company, either mostly indirectly through other groups. Now, what happened three and a half years ago when I stepped down was also the creation of Facebook AI, which was basically a larger organization that covers FAIR. So FAIR is included in it, but also has other organizations that are focused on applied research or advanced development of AI technology that is more focused on the products of the company. So less emphasis on fundamental research? Less fundamental, but it's still a research. I mean, there's a lot of papers coming out of those organizations and people are awesome and wonderful to interact with. But it serves as a way to scale up, if you want, AI technology, which may be very experimental and lab prototypes in two things that are usable. So FAIR is a subset of meta AI. If FAIR becomes like KFC, it'll just keep the F. Nobody cares what the F stands for. Will knows soon enough by probably by the end of 2021. This is not a giant change, FAIR. Well, FAIR doesn't sound too good. But the brand people are kind of deciding on this, and they've been hesitating for a while now, and they tell us they're going to come up with an answer as to whether FAIR is going to change name or whether we're going to change just the meaning of the F. Oh, that's a good call. I will keep FAIR and change the meaning of the F. That would be my preference. I would turn the F into fundamental. Oh, that's good. Fundamental AI research. Oh, that's really good. Yeah. Within meta AI. So this would be meta FAIR, but people will call it FAIR, right? Yeah, exactly. I like it. And now meta AI is part of the reality lab. So meta now, the new Facebook where it's called meta, and it's kind of divided into Facebook, Instagram, WhatsApp, and reality lab. And reality lab is about AR, VR, telepresence, communication technology, and stuff like that. It's kind of the, you can think of it as the sort of a combination of sort of new products and technology part of meta. Is that where the touch sensing for robots? I saw that you were posting about that. Touch sensing for robots is part of FAIR, actually. That's a fact. Oh, it is. Okay, cool. Yeah. There's also the, no, but there is the other way, the haptic glove, right? Yes. That's more reality lab. That's reality lab research. Reality lab research. But by the way, the touch sense is super interesting, like integrating that modality into the whole sensing suite is very interesting. So what do you think about the metaverse? What do you think about this whole, this whole kind of expansion of the view of the role of Facebook and meta in the world? Well, metaverse really should be thought of as the next step in the internet, right? Sort of trying to kind of make the experience more compelling of being connected either with other people or with content. And we are evolved and trained to evolve in 3D environments where we can see other people, we can talk to them when you're near them, or, you know, and other people are far away, can hear us, you know, things like that, right? So it, it, there's a lot of social conventions that exist in the real world that we can try to transpose. Now, what is going to be eventually the, the, how compelling is it going to be? Like our, you know, is it going to be the case that people are going to be willing to do this if they have to wear, you know, a huge pair of goggles all day? Maybe not. But then again, if the experience is sufficiently compelling, maybe so. Or if the device that you have to wear is just basically a pair of glasses, you know, technology makes sufficient progress for that. You know, AR is a much easier concept to grasp that you're going to have, you know, augmented reality glasses that basically contain some sort of, you know, virtual assistant that can help you in your daily lives. But at the same time with the AR, you have to contend with reality. With VR, you can completely detach yourself from reality. So it gives you freedom. It might be easier to design worlds in VR. Yeah, but you, you can imagine how, you know, the metaverse being a mix, a mix, right? Or, or like you can have objects that exist in a metaverse that, you know, pop up on top of the real world or only exist in virtual reality. Okay, let me ask the hard question. Because all of this was easy. This was easy. The Facebook now meta, the social network has been painted by the media as net negative for society, even destructive and evil at times. You've pushed back against this defending Facebook. Can you explain your defense? Yeah, so the, the description, the company that is being described in the, in some media is not the company we know when we work inside. And, you know, it could be claimed that a lot of employees are uninformed about what really goes on in the company. But, you know, I'm a vice president. I mean, I have a pretty good vision of what goes on. You know, I don't know everything, obviously, I'm not involved in, in, in everything, but certainly not in decision about like, you know, content moderation or anything like this. But, but I have some decent vision of what goes on. And this evil that is being described, I just don't see it. And then, you know, I think there is an easy story to buy, which is that, you know, all the bad things in the, in the world and, you know, the, the reason your friend believe crazy stuff, you know, there's an easy scapegoat, right, in the, in, in, in social media, in general, Facebook in particular, we have to look at the data, like, is it the case that Facebook, for example, polarizes people politically? Are there academic studies that show this? Is it the case that, you know, teenagers think of themselves less if they use Instagram more? Is it the case that, you know, people get more riled up against, you know, opposite sides in a, in a debate or political opinion, if they, if they are more on Facebook, or if they are less. And study after study show that none of this is true. This is independent studies by academic, they're not funded by Facebook or Meta, you know, studied by Stanford, by some of my colleagues at NYU, actually, with whom I have no connection. You know, there's a study recently, they, they, they paid people, I think it was in, in, in, in the former Yugoslavia, I'm not exactly sure in what, what part, but they paid people to not use Facebook for a while in the period before the anniversary of the cybernature massacres, right? So, you know, people get riled up like, you know, should we have a celebration? I mean, a memorial kind of celebration for it or not. So they paid a bunch of people to not use Facebook for a few weeks. And it turns out that those people ended up being more polarized than they were at the beginning. And the people who were more on Facebook were less polarized. There's a study, you know, from Stanford of economics at Stanford that tried to identify the causes of increasing polarization in the US. And it's been going on for 40 years before, you know, Mark Zuckerberg was born continuously. And, and so if there is a cause, it's not Facebook or social media. So you could say if social media just accelerated, but no, I mean, it's basically a continuous evolution by some measure of polarization in the US. And then you compare this with other countries like the West half of Germany, because you can go 40 years in the East side, or Denmark or other countries. And they use Facebook just as much. And they're not getting more polarized, they're getting less polarized. So if you want to look for, you know, a causal relationship there, you can find a scapegoat, but you can't find a cause. Now, if you want to fix the problem, you have to find the right cause. And what rise me up is that people now are accusing Facebook of bad deeds that are done by others. And those others are, we're not doing anything about them. And by the way, those others include the owner of the Wall Street Journal in which all of those papers were published. So I should mention that I'm talking to Shrep, Mike Shrep on this podcast, and also Mark Zuckerberg, and probably these are the conversations you can have with them. Because it's very interesting to me, even if Facebook has some measurable negative effect, you can't just consider that in isolation, you have to consider about all the positive ways it connects us. So like every technology, you can't just say like, there's an increase in division. Yes, probably Google search engine has created increase in division, we have to consider about how much information are brought to the world. Like, I'm sure Wikipedia created more division, if you just look at the division, we have to look at the full context of the world and it didn't make a better world. I mean, the printing press has created more difference, right? Exactly. So, you know, when the printing press was invented, the first books that were printed were things like the Bible, and that allowed people to read the Bible by themselves, not get the message uniquely from priests in Europe, and that created the Protestant movement and 200 years of religious persecution and wars. So, that's a bad side effect of the printing press. Social networks aren't being nearly as bad as the printing press, but nobody would say the printing press was a bad idea. Yeah, a lot of this perception, and there's a lot of different incentives operating here. Maybe a quick comment, since you're one of the top leaders at Facebook and at Meta, sorry, that's in the tech space, I'm sure Facebook involves a lot of incredible technological challenges that need to be solved. A lot of it probably is in the computer infrastructure, the hardware, I mean, it's just a huge amount. Maybe can you give me context about how much of Shrep's life is AI and how much of it is low-level compute, how much of it is flying all around doing business stuff, and the same with Mark Zuckerberg? They really focus on AI. I mean, certainly in the run-up of the Creation Affair, and for at least a year after that, if not more, Mark was very, very much focused on AI and was spending quite a lot of effort on it, and that's his style. When he gets interested in something, he reads everything about it. He read some of my papers, for example, before I joined. And so he learns a lot about it. And Shrep was really to it also. I mean, Shrep is really kind of, has something I've tried to preserve also, despite my not so young age, which is a sense of wonder about science and technology, and he certainly has that. He's also a wonderful person. I mean, in terms of, as a manager, like dealing with people and everything, Mark also actually. I mean, they're very human people. In the case of Mark, it's shockingly human, given his trajectory. I mean, the personality of him that he's spending in the press, it's just completely wrong. Yeah. But you have to know how to play the press. So that's, I put some of that responsibility on him, too. You have to, it's like, you know, like the director, the conductor of an orchestra, you have to play the press and the public in a certain kind of way, where you convey your true self to them, if there's a depth of kindness. And it's probably not the best at it. So, yeah. You have to learn. And it's sad to see, I'll talk to him about it, but the Shrep is slowly stepping down. It's always sad to see folks sort of be there for a long time and slowly, I guess time is sad. I think he's done the thing he said had to do and, you know, he's got, you know, you know, family priorities and stuff like that. And I understand, you know, after 13 years or something. It's been a good run. Which in Silicon Valley is basically a lifetime. Yeah. You know, because, you know, it's dog years. So, in Europe, the conference just wrapped up. Let me just go back to something else. You posted the paper you co-authored was rejected from Europe. As you said, proudly in quotes rejected. Can you describe this paper and like, what was the idea in it? And also, maybe this is a good opportunity to ask what are the pros and cons, what works and what doesn't about the review process. Yeah. Let me talk about the paper first. I'll talk about the review process afterwards. The paper is called Vicreg. So this is, I mentioned that before, variance in variance, covariance, regularization. And it's a technique, a non- contrastive learning technique for what I call joint embedding architecture. So, sami's nets are an example of joint embedding architecture. So joint embedding architecture is let me back up a little bit, right? So if you want to do self-supervised learning, you can do it by prediction. So let's say you want to train a system to predict video, right? You show it a video clip and you train the system to predict the next, the continuation of that video clip. Now, because you need to handle uncertainty, because there are many, you know, many continuations that are plausible, you need to have, you need to handle this in some way. You need to have a way for the system to be able to produce multiple predictions. And the way, the only way I know to do this is through what's called a latent variable. So you have some sort of hidden vector of a variable that you can vary over a set or draw from a distribution. And as you vary this vector over a set, the output, the prediction varies over a set of plausible predictions. Okay. So that's called, I call this a generative latent variable model. Got it. Okay. Now, there is an alternative to this to handle uncertainty. And instead of directly predicting the next frames of the clip, you also run those through another neural net. So you now have two neural nets, one that looks at the, you know, the initial segment of the video clip. And another one that looks at the continuation during training, right? And what you're trying to do is learn a representation of those two video clips that is maximally informative about the video clips themselves. But it's such that you can predict the representation of the second video clip from the representation of the first one easily. Okay. And you can sort of formalize this in terms of maximizing mutual information and some stuff like that, but it doesn't matter. What you want is informative, representative, you know, informative representations of the two video clips that are mutually predictable. What that means is that there's a lot of details in the second video clips that are irrelevant. You know, I, let's say a video clip consists in, you know, a camera panning the scene, there's going to be a piece of that room that is going to be revealed. And I can somewhat predict what the, what that room is going to look like, but I may not be able to predict the details of the texture of the ground and where the tiles are ending and stuff like that. Right. So those are irrelevant details that perhaps my representation will eliminate. And so what I need is to train this second neural net in such a way that whenever the continuation video clip varies over all the plausible continuations, the representation doesn't change. Got it. So it's the, yeah, yeah. Got it. Over the space of representations, doing the same kind of thing as you do with similarity learning. Right. So, so these are two ways to handle multimodality in a prediction, right? In the first way, you prioritize the prediction with a latent variable, but you predict pixels essentially, right? In the second one, you don't, you don't predict pixels. You predict an abstract representation of pixels. And you guarantee that this abstract representation has as much information as possible about the input, but sort of, you know, drops all the stuff that you really can't predict essentially. I used to be a big fan of the first approach. And in fact, in this paper with the Chen Mishra, this blog post, the dark matter intelligence, I was kind of advocating for this. And in the last year and a half, I've completely changed my mind. I'm now a big fan of the second one. And it's because of a small collection of algorithms that have been proposed over the last year and a half or so, two years to do this, including V Craig. It's predecessor called Barlow Twins, which I mentioned, a method from our friends at DeepMind could be YOL. And, and, and there's a bunch of others now that kind of work similarly. So they're all based on this idea of joint embedding. Some of them have an explicit criterion that is an approximation of mutual information. Some others are BOL work, but we don't really know why. And there's been like lots of theoretical papers about why BOL works. No, it's not that because we take it out and it still works. And, you know, blah, blah, blah. I mean, so there's like a big debate. But, but the important point is that we now have a collection of non-contrastive joint embedding methods, which I think is the best thing since sliced bread. So I'm super excited about this, because I think it's our best shot for techniques that would allow us to kind of build predictive work models. And at the same time, learn hierarchical representations of the world, where what matters about the world is preserved and what is irrelevant is eliminated. By the way, the representations that before and after is across in the space in a sequence of images, or is it for single images? It would be either for a single image for a sequence. It doesn't have to be images. This could be applied to text. This could be applied to just about any signal. I'm looking at, you know, I'm looking for methods that are generally applicable, that are not specific to, you know, one particular modality, you know, it could be audio or whatever. Got it. So what's the story behind this paper? This paper is what is describing one of the one such method? This is this Vicreg method. So this is co-authored. The first author is a student called Adrien Bard, who is a resident PhD student at Fer Paris. He's co-advised by me and Jean Ponce, who's a professor at Economa Sup\u00e9rieure, also a research director at INRIA. So this is a wonderful program in France where PhD students can basically do their PhD in industry. And that's kind of what's happening here. And this paper is a follow-up on this Balotuin paper by my former postdoc, now St\u00e9phane Denis, with Lijing and Yorish Bontar and a bunch of other people from Fer. And one of the main criticism from reviewers is that Vicreg is not different enough from Balotuin's. But, you know, my impression is that it's, you know, Balotuin's with a few bugs fixed, essentially. And in the end, this is what people will use. Right. So, but, you know, I'm used to stuff that I submit being rejected forward. So it might be rejected and actually exceptionally well cited because people use it. Well, it's already cited like a bunch of times. So, I mean, the question is then to the deeper question about peer review and conferences. I mean, computer science is a field that's kind of unique that the conference is highly prized. That's one. Right. And it's interesting because the peer review process there is similar, I suppose, to journals, but it's accelerated significantly. Well, not significantly, but it goes fast. And it's a nice way to get stuff out quickly, to peer review quickly, go to present it quickly to the community. So, not quickly, but quicker. But nevertheless, it has many of the same flaws of peer review because it's a limited number of people look at it. There's bias and following, like that if you want to do new ideas, you're going to get pushed back. There's self-interested people that kind of can infer who submitted it and kind of, you know, be cranky about it, all that kind of stuff. Yeah. I mean, there's a lot of, you know, social phenomena there. There's one social phenomenon, which is that because the field has been growing exponentially, the vast majority of people in the field are extremely junior. So, as a consequence, and that's just a consequence of the field growing, right? So, as the number of, as the size of the field kind of starts saturating, you will have less of that problem of reviewers being very inexperienced. A consequence of this is that, you know, young reviewers, I mean, there's a phenomenon which is that reviewers try to make their life easy. And to make their life easy when reviewing a paper is very simple. You just have to find a flaw in the paper, right? So, basically, they see their task as finding flaws in papers. And most papers have flaws, even the good ones. So, it's easy to do that. Your job is easier as a reviewer if you just focus on this. But what's important is, like, is there a new idea in that paper that is likely to influence? It doesn't matter if the experiments are not that great, if the protocol is, you know, so things like that. As long as there is a worthy idea in it, that will influence the way people think about the problem. Even if they make it better, you know, eventually, I think that's really what makes a paper useful. And so, this combination of social phenomena creates a disease that has plagued, you know, other fields in the past, like speech recognition, where basically, you know, people chase numbers on benchmarks. And it's much easier to get a paper accepted if it brings an incremental improvement on a sort of mainstream, well-accepted method or problem. And those are, to me, boring papers. I mean, they're not useless, right? Because industry, you know, strives on those kind of progress. But they're not the ones that I'm interested in, in terms of, like, new concepts and new ideas. So, papers that are really trying to strike kind of new advances generally don't make it. Now, thankfully, we have archive. Archive, exactly. And then there's open review type of situations we use. And then, I mean, Twitter is a kind of open review. I'm a huge believer that review should be done by thousands of people, not two people. I agree. And so, archive, like, do you see a future where a lot of really strong papers, it's already the present, but a growing future where it'll just be archive. And you're presenting an ongoing continuous conference called Twitter slash the internet slash archive sanity. Andre just released a new version. So, just not, you know, not being so elitist about this particular gating. It's not a question of being elitist or not. It's a question of being basically recommendation and zero approvals for people who don't see themselves having the ability to do so by themselves, right? And so, it saves time, right? If you rely on other people's opinion, and you trust those people or those groups to evaluate a paper for you, that saves you time because, you know, you don't have to, like, scrutinize the paper as much, you know, it is brought to your attention. I mean, it's the whole idea of sort of, you know, collective recommender system. So, I actually thought about this a lot, you know, about 10, 15 years ago, because there were discussions at NIPPS and, you know, and we're about to create iClear with Yosha Benjo. And so, I wrote a document kind of describing a reviewing system, which basically was, you know, you post your paper on some repository, let's say archive, or now could be open review. And then you can form a reviewing entity, which is equivalent to a reviewing board, you know, of a journal or program committee of a conference. You have to list the members. And then that group reviewing entity can choose to review a particular paper spontaneously or not. There is no exclusive relationship anymore between a paper and a venue or reviewing entity. Any reviewing entity can review any paper or may choose not to. And then, you know, give an evaluation. It's not published, not published, it's just an evaluation and a comment, which would be public, signed by the reviewing entity. And if it's signed by a reviewing entity, you know, it's one of the members of reviewing entity. So, if the reviewing entity is, you know, Lex Friedman's, you know, preferred papers, right, you know, it's Lex Friedman writing a review. Yes. What, so for me, one, that's a beautiful system, I think. But what's in addition to that, it feels like there should be a reputation system for the reviewers. Absolutely. For the reviewing entities. Not the reviewers individually. The reviewing entities, sure. But even within that, the reviewers too. Because there's another thing here. It's not just the reputation. It's an incentive for an individual person to do great. Right now, in the academic setting, the incentive is kind of internal, just wanting to do a good job. But honestly, that's not a strong enough incentive to do a really good job at reading a paper and finding the beautiful amidst the mistakes and the flaws and all that kind of stuff. Right. Like, if you're the person that first discovered a powerful paper, and you get to be proud of that discovery, then that gives a huge incentive to you. That's, that's a big part of my proposal. Actually, I described that as, you know, if, if your evaluation of papers is predictive of future success, then your reputation should go up as a reviewing entity. So yeah, exactly. I mean, I even had a master's student who was a master's student in library science and computer science, actually kind of work out exactly how that should work with formulas and everything. But so in terms of implementation, do you think that's something that's doable? I mean, I've been sort of, you know, talking about this to sort of various people like, you know, Andrew McCallum, who started Open Review. And the reason why we picked Open Review for iClear initially, even though it was very early for them, is because my hope was that iClear, it was eventually going to kind of inaugurate this type of system. So iClear kept the idea of Open Reviews. So whether reviews are, you know, published with a paper, which I think is very useful. But in many ways, that's kind of reverted to kind of more of a conventional type conferences for everything else. And that, I mean, I don't run iClear, I'm just the president of the foundation. But, you know, people who run it should make decisions about how to run it. And I'm not going to tell them, because they are volunteers. And I'm really thankful that they do that. So, but I'm saddened by the fact that we're not being innovative enough. Yeah, me too. I hope that changes. Yeah. Because the communication science broadly, but communication, computer science ideas is how you make those ideas have impact, I think. Yeah. And I think, you know, a lot of this is because people have in their minds kind of an objective, which is, you know, fairness for authors, and the ability to count points, basically, and give credits accurately. But that comes at the expense of the progress of science. So to some extent, we're slowing down the progress of science. And are we actually achieving fairness? And we're not achieving fairness, you know, we still have biases, you know, we're doing, you know, a double blind review, but, you know, the biases are still there, there are different kinds of biases. You write that the phenomenon of emergence, collective behavior exhibited by large collection of simple elements in interaction is one of the things that got you into neural nets in the first place. I love cellular automata. I love simple interacting elements and the things that emerge from them. Do you think we understand how complex systems can emerge from such simple components that interact simply? No, we don't. It's a big mystery. Also, it's a mystery for physicists, it's a mystery for biologists. You know, how is it that the universe around us seems to be increasing in complexity and not decreasing? I mean, that is a kind of curious property of physics that despite the second law of thermodynamics, we seem to be, you know, evolution and learning and et cetera seems to be kind of at least locally to increase complexity and not decrease it. So, perhaps the ultimate purpose of the universe is to just get more complex. Have these, I mean, small pockets of beautiful complexity. Does that, to sell your time under these kinds of emergence and complex systems give you some intuition or guide your understanding of machine learning systems and neural networks and so on? Are these for you right now disparate concepts? Well, it got me into it. You know, I discovered the existence of the perceptron when I was a college student by reading a good book. It was a debate between Chomsky and Piaget and Seymour Papert from MIT who was kind of singing the praise of the perceptron in that book. And the first time I heard about the running machine, right? So, I started digging the literature and I found those books which were basically transcription of, you know, workshops or conferences from the 50s and 60s about self-organizing systems. So, there was a series of conferences on self-organizing systems and these books on this. Some of them are, you can actually get them at the Internet Archive, you know, the digital version. And there are like fascinating articles in there by, there's a guy whose name has been largely forgotten, Heinz von F\u00f6rster. He's a German physicist who emigrated to the US and worked on self-organizing systems in the 50s. And in the 60s, he created at the University of Illinois, Japan, Japan, he created the biological computer laboratory, VCL, which was, you know, all about neural nets. Unfortunately, that was kind of towards the end of the popularity of neural nets. So, that lab never kind of strived very much. But he wrote a bunch of papers about self-organization and about the mystery of self-organization. An example he has is, you take, imagine you are in space, there's no gravity. You have a big box with magnets in it, okay? You know, kind of rectangular magnets with north pole on one end, south pole on the other end. You shake the box gently and the magnets will kind of stick to themselves and probably form like complex structure, you know, spontaneously. You know, that could be an example of self-organization. But, you know, you have lots of example, neural nets are an example of self-organization to, you know, in many respects. And it's a bit of a mystery, you know, how, like, what is possible with this? You know, pattern formation in physical systems, in chaotic system and things like that, you know, the emergence of life, you know, things like that. So, you know, how does that happen? So, it's a big puzzle for physicists as well. It feels like understanding this, the mathematics of emergence in some constrained situations might help us create intelligence. Like, help us add a little spice to the systems because you seem to be able to, in complex systems with emergence, to be able to get a lot from little. And so, that seems like a shortcut to get big leaps in performance. But there's a missing concept that we don't have. And it's something also I've been fascinated by since my undergrad days. And it's how you measure complexity, right? So, we don't actually have good ways of measuring or at least we don't have good ways of interpreting the measures that we have at our disposal. Like, how do you measure the complexity of something, right? So, there's all those things, you know, like, you know, Karmogorov, Chaitin, Solomonov complexity of, you know, the length of the shortest program that would generate a bit string can be thought of as the complexity of that bit string. I've been fascinated by that concept. The problem with that is that that complexity is defined up to a constant, which can be very large. There are similar concepts that are derived from, you know, Bayesian probability theory, where, you know, the complexity of something is the negative log of its probability essentially, right? And you have a complete equivalence between the two things. And there you would think, you know, the probability is something that's well defined mathematically, which means complexity is well defined. But it's not true. You need to have a model of the distribution. You may need to have a prior, if you're doing Bayesian inference. And the prior plays the same role as the choice of the computer with which you measure your Karmogorov complexity. And so, every measure of complexity we have has some arbitraryness in it, you know, an additive constant, which is, can be arbitrarily large. And so, you know, how can we come up with a good theory of how things become more complex if we don't have a good measure of complexity? Yeah, which we need for is one way that people study this in the space of biology, the people that study the origin of life or try to recreate life in the laboratory. And the more interesting one is the alien one is when we go to other planets, how do we recognize this life? Because, you know, complexity, we associate complexity, maybe some level of mobility with life, you know, we have to be able to, like, have concrete algorithms for, like, measuring the level of complexity we see in order to know the difference between life and non-life. And the problem is that complexity is in the IODB holder. So, let me give you an example. If I give you an image of the MNIST digits, right, and I flip through MNIST digits, there is some, obviously some structure to it because local structure, you know, neighboring pixels are correlated across the entire dataset. Now, imagine that I apply a random permutation to all the pixels, a fixed random permutation. Now, I show you those images, they will look, you know, really disorganized to you, more complex. In fact, they're not more complex in absolute terms, they're exactly the same as originally, right? And if you knew what the permutation was, you know, you could undo the permutation. Now, imagine I give you special glasses that undo that permutation. Now, all of a sudden, what looked complicated becomes simple. Right. So, if you have two, if you have, you know, humans on one end, and then another race of aliens that sees the universe with permutation glasses. Yeah, with the permutation glasses. What we perceive as simple to them is hardly complicated, it's probably heat. Yeah, heat, yeah. Okay. And what they perceive as simple to us is random fluctuation, it's heat. Yeah. So, truly in the eye of the beholder, depends what kind of glasses you're wearing. Right. Depends what kind of algorithm you're running in your perception system. So, I don't think we'll have a theory of intelligence, self-organization, evolution, things like that, until we have a good handle on a notion of complexity, which we know is in the high, the eye of the beholder. Yeah, it's sad to think that we might not be able to detect or interact with alien species because we're wearing different glasses. Because their notion of locality might be different from ours. Yeah. This actually connects with fascinating questions in physics at the moment, like modern physics, quantum physics, like, you know, questions about like, you know, can we recover the information that's lost in a black hole and things like this, right? And that relies on notions of complexity, which, you know, I find it's fascinating. Can you describe your personal quest to build an expressive electronic wind instrument EWI? What is it? What does it take to build it? Well, I'm a thinker. I like building things. I like building things with combinations of electronics and, you know, mechanical stuff. You know, I have a bunch of different hobbies, but you know, probably my first one was little was building model airplanes and stuff like that. And I still do that to some extent. But also electronics, I taught myself electronics before I studied it. And the reason I taught myself electronics is because of music. My cousin was an aspiring electronic musician, and then he had an analog synthesizer. And I was, you know, basically modifying it for him and building sequencers and stuff like that, right, for him. I was in high school when I was doing this. How's the interest in like progressive rock like 80s? Like, what's the greatest band of all time, according to Yonah Kuhn? There's too many of them. But, you know, it's a combination of you know, my vision orchestra, weather report, yes, Genesis, you know, yes, Genesis, Peter Gabriel, gentle giant, you know, things like that. Great. Okay. So this, this love of electronics and this love of music combined together. Right. So I was actually trained to play Baroque and Renaissance music. And I played in orchestra when I was in high school and first years of college. And I played the recorder, Cromhorn, a little bit of oboe, you know, things like that. So I'm a wind instrument player. But I always wanted to play improvised music, even though I don't know anything about it. And the only way I figured, you know, short of like learning to play saxophone was to play electronic wind instruments. So they behave on the fingering is similar to a saxophone, but, you know, you have a wide variety of sound because you control the synthesizer with it. So I had a bunch of those, you know, going back to the late 80s from either Yamaha or Akai, they're both kind of the main manufacturers of those that they were classically, you know, going back several decades. But I've never been completely satisfied with them because of lack of expressivity. And, you know, those things, you know, are somewhat expressive. I mean, they measure the breath pressure, they measure the lip pressure, and, you know, you have various parameters, you can vary with fingers, but they're not really as expressive as an acoustic instrument, right? You hear John Coltrane play two notes, and you know it's John Coltrane, you know, it's got a unique sound. Or Miles Davis, right? You can hear it's Miles Davis playing the trumpet because the sound reflects their, you know, physiognomy, basically the shape of the vocal track kind of shapes the sound. So how do you do this with an electronic instrument? And I was, many years ago, I met a guy called David Wessel. He was a professor at Berkeley and created the center for like, you know, music technology there. And he was interested in that question. And so I kept kind of thinking about this for many years. And finally, because of COVID, you know, I was at home, I was in my workshop, my workshop serves also as my kind of Zoom room and home office. And this is in New Jersey? In New Jersey. And I started really being serious about, you know, building my own EWI instrument. What else is going on in the New Jersey workshop? Is some crazy stuff you built or like left on the workshop floor left behind? A lot of crazy stuff is, you know, electronics built with microcontrollers of various kinds. And, you know, weird flying contraptions. So you still love flying? It's a family disease. My dad got me into it when I was a kid. And he was building model airplanes when he was a kid. And he was a mechanical engineer. He taught himself electronics also. So he built his early radio control systems in the late 60s, early 70s. And so that's what got me into, I mean, he got me into kind of, you know, engineering and science and technology. Do you also have an interest in appreciation of flight in other forms, like with drones, quadroptors? Or do you, is it model airplane? You know, before drones were, you know, kind of consumer products, you know, I built my own, you know, with also building a microcontroller with JavaScripts and accelerometers for stabilization, writing the firmware for it, you know, and then when it became kind of a standard thing you could buy, it was boring, you know, I stopped doing it. It was in front anymore. Yeah, you were doing it before it was cool. What advice would you give to a young person today in high school and college that dreams of doing something big, like young like Coon, like let's talk in the space of intelligence, dreams of having a chance to solve some fundamental problem in space of intelligence, both for their career and just in life, being somebody who was a part of creating something special. So try to get interested by big questions, things like, you know, what is intelligence? What is the universe made of? What's life all about? Things like that. Like even like crazy big questions like what's time, like nobody knows what time is. And then learn basic things like basic methods, either from math, from physics, or from engineering. Things that have a long shelf life. Like if you have a choice between like, you know, learning, you know, mobile programming on iPhone, or quantum mechanics, take quantum mechanics. Because you're going to learn things that you have no idea exist. You may not, you may never be a quantum physicist, but you'll learn about path integrals. And path integrals are used everywhere. It's the same formula that you use for, you know, vision integration and stuff like that. So the ideas, the little ideas within quantum mechanics within some of these kind of more solidified fields will have a longer shelf life, they will use somehow use indirectly in your work. Learn classical mechanics, like you learn about Lagrangians, for example, which is like a huge, hugely useful concept, you know, for all kinds of different things. Learn statistical physics, because all the math that comes out of, you know, for machine learning, basically comes out of what we got out by statistical physicists in the, you know, late 19, early 20th century. Right. So, and for some of them, actually, more recently, by people like George O'Parisi, who just got the Nobel Prize for the replica method, among other things, it's used for a lot of different things, you know, variational inference, that math comes from statistical physics. So, so a lot of those kind of, you know, basic courses, you know, you'll, if you do it like you're engineering, you take signal processing, you'll learn about Fourier transforms. Again, something super useful is at the basis of things like graph neural nets, which is an entirely new subarea of, you know, AI machine learning, deep learning, which I think is super promising for all kinds of applications. Something very promising, if you're more interested in applications is the applications of AI machine learning and deep learning to science, or to science that can help solve big problems in the world. I have colleagues at Meta, at fair, who started this project called Open Catalyst, and it's an open project collaborative. And the idea is to use deep learning to help design new chemical compounds or materials that would facilitate the separation of hydrogen from oxygen. If you can efficiently separate oxygen from hydrogen with electricity, you solve climate change. It's as simple as that, because you cover, you know, some random desert with solar panels, and you have them work all day, produce hydrogen, and then you see the hydrogen wherever it's needed. You don't need anything else. You know, you have controllable power that can be transported anywhere. So if we have a large-scale, efficient energy storage technology like producing hydrogen, we solve climate change. Here's another way to solve climate change is figuring out how to make fusion work. Now, the problem with fusion is that you make a super hot plasma, and the plasma is unstable, and you can control it. Maybe with deep learning, you can find controllers that will stabilize plasma and make, you know, practical fusion reactors. I mean, that's very speculative, but, you know, it's worth trying, because, you know, the payoff is huge. There's a group at Google working on this led by John Platt. So control, convert as many problems in science and physics and biology and chemistry into a, into a learnable problem and see if a machine can learn it. Right. I mean, there's properties of, you know, complex materials that we don't understand from first principle, for example. Right. So, you know, if we could design new, you know, new materials, we could make more efficient batteries, you know, we could make maybe faster electronics. We could, I mean, there's a lot of things we can imagine doing, or, you know, lighter materials for, for cars or airplanes or things like that, maybe better fuel cells. I mean, there's all kinds of stuff we can imagine. If we had good fuel cells, hydrogen fuel cells, we could use them to power airplanes, and, you know, transportation wouldn't be, or cars, and we wouldn't have a emission problem, CO2 emission problems for, for air transportation anymore. So there's a lot of those things, I think, where AI, you know, can be used. And this is not even talking about all the sort of medicine biology and everything like that, right? You know, like protein folding, you know, figuring out, like, how could you design your proteins, that it sticks to another protein that a particular site, because that's how you design drugs in the end. So, you know, deep learning would be useful, all of this. And those are kind of, you know, would be sort of enormous progress if we could use it for that. Here's an example. If you take, this is like from recent material physics, you take a monoatomic layer of graphene, right? So it's just carbon on an hexagonal mesh, and you make this single, single atom thick. You put another one on top, you twist them by some magic number of degrees, three degrees or something. It becomes superconductor. Nobody has any idea why. I want to know how that was discovered, but that's the kind of thing that machine learning can actually discover, these kinds of things. Well, maybe not, but there is a hint, perhaps, that with machine learning, we would train a system to basically be a phenomenological model of some complex emergent phenomenon, which, you know, superconductivity is one of those, where, you know, this collective phenomenon is too difficult to describe from first principles with the current, you know, the usual sort of reductionist type method. But we could have deep learning systems that predict the properties of a system from a description of it after being trained with sufficiently many samples. This guy, Pascal Foua at DPFL, he has a startup company that where he basically trained a convolutional net essentially to predict the aerodynamic properties of solids. And you can generate as much data as you want by just running a computational free dynamics, right? So you give, like, a wing, a foil or something shape of some kind, and you run computational free dynamics, you get, as a result, the drag and, you know, lift and all that stuff, right? And you can generate lots of data, train a neural net to make those predictions. And now what you have is a differentiable model of, let's say, drag and lift as a function of the shape of that solid. And so you can do background and design, you can optimize the shape, so you get the properties you want. Yeah, that's incredible. That's incredible. And on top of all that, probably, you should read a little bit of literature and a little bit of history for inspiration and for wisdom, because after all, all of these technologies will have to work in a human world. And the human world is complicated. Yeah, and this is an amazing conversation. I really honored that you talked with me today. Thank you for all the amazing work you're doing at FAIR at Metta. And thank you for being so passionate after all these years about everything that's going on. You're a beacon of hope for the machine learning community. And thank you so much for spending your valuable time with me today. That was awesome. Thanks for having me on. That was a pleasure. Thanks for listening to this conversation with Yann LeCun. To support this podcast, please check out our sponsors in the description. And now let me leave you some words from Isaac Asimov. Your assumptions are your windows on the world. Scrub them off every once in a while, or the light won't come in. Thank you for listening and hope to see you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.4, "text": " The following is a conversation with Yann LeCun, his second time in the podcast.", "tokens": [50364, 440, 3480, 307, 257, 3761, 365, 398, 969, 1456, 34, 409, 11, 702, 1150, 565, 294, 264, 7367, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 1, "seek": 0, "start": 4.72, "end": 11.28, "text": " He is the chief AI scientist at Meta, formerly Facebook, professor at NYU,", "tokens": [50600, 634, 307, 264, 9588, 7318, 12662, 412, 6377, 64, 11, 34777, 4384, 11, 8304, 412, 42682, 11, 50928], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 2, "seek": 0, "start": 11.68, "end": 16.12, "text": " touring award winner, one of the seminal figures in the history of machine", "tokens": [50948, 32487, 7130, 8507, 11, 472, 295, 264, 4361, 2071, 9624, 294, 264, 2503, 295, 3479, 51170], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 3, "seek": 0, "start": 16.12, "end": 21.64, "text": " learning and artificial intelligence, and someone who is brilliant and opinionated", "tokens": [51170, 2539, 293, 11677, 7599, 11, 293, 1580, 567, 307, 10248, 293, 4800, 770, 51446], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 4, "seek": 0, "start": 22.0, "end": 23.240000000000002, "text": " in the best kind of way.", "tokens": [51464, 294, 264, 1151, 733, 295, 636, 13, 51526], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 5, "seek": 0, "start": 23.6, "end": 25.2, "text": " And so it was always fun to talk to him.", "tokens": [51544, 400, 370, 309, 390, 1009, 1019, 281, 751, 281, 796, 13, 51624], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 6, "seek": 0, "start": 26.0, "end": 28.64, "text": " This is the Lex Friedman podcast to support it.", "tokens": [51664, 639, 307, 264, 24086, 17605, 1601, 7367, 281, 1406, 309, 13, 51796], "temperature": 0.0, "avg_logprob": -0.2931352317880053, "compression_ratio": 1.5698529411764706, "no_speech_prob": 0.04454423859715462}, {"id": 7, "seek": 2864, "start": 28.84, "end": 30.8, "text": " Please check out our sponsors in the description.", "tokens": [50374, 2555, 1520, 484, 527, 22593, 294, 264, 3855, 13, 50472], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 8, "seek": 2864, "start": 31.240000000000002, "end": 34.88, "text": " And now here's my conversation with Yann LeCun.", "tokens": [50494, 400, 586, 510, 311, 452, 3761, 365, 398, 969, 1456, 34, 409, 13, 50676], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 9, "seek": 2864, "start": 36.120000000000005, "end": 40.84, "text": " You co-wrote the article, Self-Supervised Learning, the Dark Matter of Intelligence.", "tokens": [50738, 509, 598, 12, 7449, 1370, 264, 7222, 11, 16348, 12, 30152, 24420, 15205, 11, 264, 9563, 20285, 295, 27274, 13, 50974], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 10, "seek": 2864, "start": 40.88, "end": 43.2, "text": " Great title, by the way, with Yann Mizra.", "tokens": [50976, 3769, 4876, 11, 538, 264, 636, 11, 365, 398, 969, 37793, 424, 13, 51092], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 11, "seek": 2864, "start": 43.68, "end": 49.36, "text": " So let me ask, what is self-supervised learning and why is it the dark matter of intelligence?", "tokens": [51116, 407, 718, 385, 1029, 11, 437, 307, 2698, 12, 48172, 24420, 2539, 293, 983, 307, 309, 264, 2877, 1871, 295, 7599, 30, 51400], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 12, "seek": 2864, "start": 49.88, "end": 51.56, "text": " I'll start by the dark matter part.", "tokens": [51426, 286, 603, 722, 538, 264, 2877, 1871, 644, 13, 51510], "temperature": 0.0, "avg_logprob": -0.21965576171875, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0067719100043177605}, {"id": 13, "seek": 5156, "start": 52.2, "end": 61.120000000000005, "text": " There is obviously a kind of learning that humans and animals are doing that we currently", "tokens": [50396, 821, 307, 2745, 257, 733, 295, 2539, 300, 6255, 293, 4882, 366, 884, 300, 321, 4362, 50842], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 14, "seek": 5156, "start": 61.120000000000005, "end": 64.64, "text": " are not reproducing properly with machines or with AI, right?", "tokens": [50842, 366, 406, 11408, 2175, 6108, 365, 8379, 420, 365, 7318, 11, 558, 30, 51018], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 15, "seek": 5156, "start": 64.64, "end": 69.64, "text": " So the most popular approaches to machine learning today are, or pydimes, I should say,", "tokens": [51018, 407, 264, 881, 3743, 11587, 281, 3479, 2539, 965, 366, 11, 420, 10664, 67, 1532, 11, 286, 820, 584, 11, 51268], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 16, "seek": 5156, "start": 69.64, "end": 71.68, "text": " are supervised learning and reinforcement learning.", "tokens": [51268, 366, 46533, 2539, 293, 29280, 2539, 13, 51370], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 17, "seek": 5156, "start": 72.68, "end": 74.56, "text": " And they are extremely inefficient.", "tokens": [51420, 400, 436, 366, 4664, 43495, 13, 51514], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 18, "seek": 5156, "start": 75.08, "end": 78.92, "text": " Supervised learning requires many samples for learning anything.", "tokens": [51540, 4548, 24420, 2539, 7029, 867, 10938, 337, 2539, 1340, 13, 51732], "temperature": 0.0, "avg_logprob": -0.22973479781039927, "compression_ratio": 1.7268722466960353, "no_speech_prob": 0.0729820504784584}, {"id": 19, "seek": 7892, "start": 79.76, "end": 84.88, "text": " And reinforcement learning requires a ridiculously large number of trial and errors", "tokens": [50406, 400, 29280, 2539, 7029, 257, 41358, 2416, 1230, 295, 7308, 293, 13603, 50662], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 20, "seek": 7892, "start": 84.88, "end": 87.16, "text": " to, for, you know, a system to run anything.", "tokens": [50662, 281, 11, 337, 11, 291, 458, 11, 257, 1185, 281, 1190, 1340, 13, 50776], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 21, "seek": 7892, "start": 89.32000000000001, "end": 90.96000000000001, "text": " And that's why we don't have self-driving cars.", "tokens": [50884, 400, 300, 311, 983, 321, 500, 380, 362, 2698, 12, 47094, 5163, 13, 50966], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 22, "seek": 7892, "start": 92.96000000000001, "end": 94.56, "text": " That's a big leap from one to the other.", "tokens": [51066, 663, 311, 257, 955, 19438, 490, 472, 281, 264, 661, 13, 51146], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 23, "seek": 7892, "start": 94.8, "end": 95.24000000000001, "text": " Okay.", "tokens": [51158, 1033, 13, 51180], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 24, "seek": 7892, "start": 95.32, "end": 102.56, "text": " So that to solve difficult problems, you have to have a lot of human annotation for", "tokens": [51184, 407, 300, 281, 5039, 2252, 2740, 11, 291, 362, 281, 362, 257, 688, 295, 1952, 48654, 337, 51546], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 25, "seek": 7892, "start": 102.56, "end": 106.36, "text": " supervised learning to work and to solve those difficult problems with reinforcement", "tokens": [51546, 46533, 2539, 281, 589, 293, 281, 5039, 729, 2252, 2740, 365, 29280, 51736], "temperature": 0.0, "avg_logprob": -0.17453718185424805, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0025483339559286833}, {"id": 26, "seek": 10636, "start": 106.36, "end": 110.92, "text": " learning. You have to have some way to maybe simulate that problem such that you can do", "tokens": [50364, 2539, 13, 509, 362, 281, 362, 512, 636, 281, 1310, 27817, 300, 1154, 1270, 300, 291, 393, 360, 50592], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 27, "seek": 10636, "start": 110.92, "end": 114.24, "text": " that large scale kind of learning that reinforcement learning requires.", "tokens": [50592, 300, 2416, 4373, 733, 295, 2539, 300, 29280, 2539, 7029, 13, 50758], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 28, "seek": 10636, "start": 114.4, "end": 114.76, "text": " Right.", "tokens": [50766, 1779, 13, 50784], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 29, "seek": 10636, "start": 114.76, "end": 120.72, "text": " So how is it that, you know, most teenagers can learn to drive a car in about 20 hours of", "tokens": [50784, 407, 577, 307, 309, 300, 11, 291, 458, 11, 881, 23618, 393, 1466, 281, 3332, 257, 1032, 294, 466, 945, 2496, 295, 51082], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 30, "seek": 10636, "start": 120.84, "end": 128.52, "text": " practice, whereas even with millions of hours of simulated practice, a self-driving car can't", "tokens": [51088, 3124, 11, 9735, 754, 365, 6803, 295, 2496, 295, 41713, 3124, 11, 257, 2698, 12, 47094, 1032, 393, 380, 51472], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 31, "seek": 10636, "start": 128.64, "end": 130.6, "text": " actually learn to drive itself properly.", "tokens": [51478, 767, 1466, 281, 3332, 2564, 6108, 13, 51576], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 32, "seek": 10636, "start": 132.12, "end": 133.92000000000002, "text": " And so obviously we're missing something, right?", "tokens": [51652, 400, 370, 2745, 321, 434, 5361, 746, 11, 558, 30, 51742], "temperature": 0.0, "avg_logprob": -0.15684561956496465, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.0050572301261126995}, {"id": 33, "seek": 13392, "start": 133.92, "end": 138.48, "text": " And it's quite obvious for a lot of people that, you know, the immediate response you get from", "tokens": [50364, 400, 309, 311, 1596, 6322, 337, 257, 688, 295, 561, 300, 11, 291, 458, 11, 264, 11629, 4134, 291, 483, 490, 50592], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 34, "seek": 13392, "start": 138.92, "end": 144.23999999999998, "text": " many people is, well, you know, humans use their background knowledge to learn faster.", "tokens": [50614, 867, 561, 307, 11, 731, 11, 291, 458, 11, 6255, 764, 641, 3678, 3601, 281, 1466, 4663, 13, 50880], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 35, "seek": 13392, "start": 144.67999999999998, "end": 145.32, "text": " And they're right.", "tokens": [50902, 400, 436, 434, 558, 13, 50934], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 36, "seek": 13392, "start": 145.83999999999997, "end": 148.07999999999998, "text": " Now, how was that background knowledge acquired?", "tokens": [50960, 823, 11, 577, 390, 300, 3678, 3601, 17554, 30, 51072], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 37, "seek": 13392, "start": 148.27999999999997, "end": 149.35999999999999, "text": " And that's the big question.", "tokens": [51082, 400, 300, 311, 264, 955, 1168, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 38, "seek": 13392, "start": 150.07999999999998, "end": 156.0, "text": " So now you have to ask, you know, how do babies in the first few months of life learn how the", "tokens": [51172, 407, 586, 291, 362, 281, 1029, 11, 291, 458, 11, 577, 360, 10917, 294, 264, 700, 1326, 2493, 295, 993, 1466, 577, 264, 51468], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 39, "seek": 13392, "start": 156.0, "end": 160.04, "text": " world works, mostly by observation, because they can hardly act in the world.", "tokens": [51468, 1002, 1985, 11, 5240, 538, 14816, 11, 570, 436, 393, 13572, 605, 294, 264, 1002, 13, 51670], "temperature": 0.0, "avg_logprob": -0.1490385801895805, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0020805890671908855}, {"id": 40, "seek": 16004, "start": 160.92, "end": 165.95999999999998, "text": " And they learn an enormous amount of background knowledge about the world that may be the basis", "tokens": [50408, 400, 436, 1466, 364, 11322, 2372, 295, 3678, 3601, 466, 264, 1002, 300, 815, 312, 264, 5143, 50660], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 41, "seek": 16004, "start": 165.95999999999998, "end": 167.23999999999998, "text": " of what we call common sense.", "tokens": [50660, 295, 437, 321, 818, 2689, 2020, 13, 50724], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 42, "seek": 16004, "start": 168.07999999999998, "end": 171.2, "text": " This type of learning is not learning a task.", "tokens": [50766, 639, 2010, 295, 2539, 307, 406, 2539, 257, 5633, 13, 50922], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 43, "seek": 16004, "start": 171.23999999999998, "end": 173.64, "text": " It's not being reinforced for anything.", "tokens": [50924, 467, 311, 406, 885, 31365, 337, 1340, 13, 51044], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 44, "seek": 16004, "start": 173.68, "end": 177.07999999999998, "text": " It's just observing the world and figuring out how it works.", "tokens": [51046, 467, 311, 445, 22107, 264, 1002, 293, 15213, 484, 577, 309, 1985, 13, 51216], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 45, "seek": 16004, "start": 178.32, "end": 180.56, "text": " Building world models, learning world models.", "tokens": [51278, 18974, 1002, 5245, 11, 2539, 1002, 5245, 13, 51390], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 46, "seek": 16004, "start": 181.16, "end": 181.88, "text": " How do we do this?", "tokens": [51420, 1012, 360, 321, 360, 341, 30, 51456], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 47, "seek": 16004, "start": 182.04, "end": 184.48, "text": " And how do we reproduce this in machine?", "tokens": [51464, 400, 577, 360, 321, 29501, 341, 294, 3479, 30, 51586], "temperature": 0.0, "avg_logprob": -0.17909322182337442, "compression_ratio": 1.6651982378854626, "no_speech_prob": 0.0012442766455933452}, {"id": 48, "seek": 18448, "start": 184.48, "end": 191.39999999999998, "text": " So self-supervisioning is, you know, one instance or one attempt at trying to reproduce", "tokens": [50364, 407, 2698, 12, 48172, 6763, 278, 307, 11, 291, 458, 11, 472, 5197, 420, 472, 5217, 412, 1382, 281, 29501, 50710], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 49, "seek": 18448, "start": 191.39999999999998, "end": 192.04, "text": " this kind of learning.", "tokens": [50710, 341, 733, 295, 2539, 13, 50742], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 50, "seek": 18448, "start": 193.04, "end": 193.32, "text": " Okay.", "tokens": [50792, 1033, 13, 50806], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 51, "seek": 18448, "start": 193.32, "end": 196.32, "text": " So you're looking at just observation.", "tokens": [50806, 407, 291, 434, 1237, 412, 445, 14816, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 52, "seek": 18448, "start": 196.32, "end": 198.44, "text": " So not even the interacting part of a child.", "tokens": [50956, 407, 406, 754, 264, 18017, 644, 295, 257, 1440, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 53, "seek": 18448, "start": 198.64, "end": 203.35999999999999, "text": " It's just sitting there watching mom and dad walk around, pick up stuff, all of that.", "tokens": [51072, 467, 311, 445, 3798, 456, 1976, 1225, 293, 3546, 1792, 926, 11, 1888, 493, 1507, 11, 439, 295, 300, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 54, "seek": 18448, "start": 203.39999999999998, "end": 205.28, "text": " That's what we mean by background knowledge.", "tokens": [51310, 663, 311, 437, 321, 914, 538, 3678, 3601, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 55, "seek": 18448, "start": 205.44, "end": 209.32, "text": " Perhaps not even watching mom and dad, just, you know, watching the world go by.", "tokens": [51412, 10517, 406, 754, 1976, 1225, 293, 3546, 11, 445, 11, 291, 458, 11, 1976, 264, 1002, 352, 538, 13, 51606], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 56, "seek": 18448, "start": 209.92, "end": 213.92, "text": " Just having eyes open or having eyes closed or the very act of opening and closing eyes.", "tokens": [51636, 1449, 1419, 2575, 1269, 420, 1419, 2575, 5395, 420, 264, 588, 605, 295, 5193, 293, 10377, 2575, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1522668691781851, "compression_ratio": 1.7335640138408304, "no_speech_prob": 0.0016465375665575266}, {"id": 57, "seek": 21448, "start": 214.48, "end": 217.67999999999998, "text": " That the world appears and disappears, all of that basic information.", "tokens": [50364, 663, 264, 1002, 7038, 293, 25527, 11, 439, 295, 300, 3875, 1589, 13, 50524], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 58, "seek": 21448, "start": 219.11999999999998, "end": 224.95999999999998, "text": " And you're saying in order to learn to drive, like the reason humans are able to learn to", "tokens": [50596, 400, 291, 434, 1566, 294, 1668, 281, 1466, 281, 3332, 11, 411, 264, 1778, 6255, 366, 1075, 281, 1466, 281, 50888], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 59, "seek": 21448, "start": 224.95999999999998, "end": 228.67999999999998, "text": " drive quickly, some faster than others, is because of the background knowledge.", "tokens": [50888, 3332, 2661, 11, 512, 4663, 813, 2357, 11, 307, 570, 295, 264, 3678, 3601, 13, 51074], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 60, "seek": 21448, "start": 228.67999999999998, "end": 233.72, "text": " They were able to watch cars operate in the world in the many years leading up to it, the", "tokens": [51074, 814, 645, 1075, 281, 1159, 5163, 9651, 294, 264, 1002, 294, 264, 867, 924, 5775, 493, 281, 309, 11, 264, 51326], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 61, "seek": 21448, "start": 233.72, "end": 235.79999999999998, "text": " physics of basics, objects, all that kind of stuff.", "tokens": [51326, 10649, 295, 14688, 11, 6565, 11, 439, 300, 733, 295, 1507, 13, 51430], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 62, "seek": 21448, "start": 235.79999999999998, "end": 236.12, "text": " That's right.", "tokens": [51430, 663, 311, 558, 13, 51446], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 63, "seek": 21448, "start": 236.16, "end": 239.67999999999998, "text": " I mean, the basic physics of objects, you don't even know, you don't even need to know, you", "tokens": [51448, 286, 914, 11, 264, 3875, 10649, 295, 6565, 11, 291, 500, 380, 754, 458, 11, 291, 500, 380, 754, 643, 281, 458, 11, 291, 51624], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 64, "seek": 21448, "start": 239.67999999999998, "end": 240.88, "text": " know, how a car works, right?", "tokens": [51624, 458, 11, 577, 257, 1032, 1985, 11, 558, 30, 51684], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 65, "seek": 21448, "start": 240.88, "end": 242.39999999999998, "text": " Because that you can learn fairly quickly.", "tokens": [51684, 1436, 300, 291, 393, 1466, 6457, 2661, 13, 51760], "temperature": 0.0, "avg_logprob": -0.1720012796336207, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.0008555044769309461}, {"id": 66, "seek": 24240, "start": 242.48000000000002, "end": 247.64000000000001, "text": " I mean, the example I use very often is you're driving next to a cliff and you know in", "tokens": [50368, 286, 914, 11, 264, 1365, 286, 764, 588, 2049, 307, 291, 434, 4840, 958, 281, 257, 22316, 293, 291, 458, 294, 50626], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 67, "seek": 24240, "start": 247.64000000000001, "end": 253.0, "text": " advance because of your, you know, understanding of intuitive physics that if you turn the", "tokens": [50626, 7295, 570, 295, 428, 11, 291, 458, 11, 3701, 295, 21769, 10649, 300, 498, 291, 1261, 264, 50894], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 68, "seek": 24240, "start": 253.0, "end": 257.24, "text": " wheel to the right, the car will veer to the right, we'll run off the cliff, fall off the", "tokens": [50894, 5589, 281, 264, 558, 11, 264, 1032, 486, 1241, 260, 281, 264, 558, 11, 321, 603, 1190, 766, 264, 22316, 11, 2100, 766, 264, 51106], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 69, "seek": 24240, "start": 257.24, "end": 259.2, "text": " cliff and nothing good will come out of this, right?", "tokens": [51106, 22316, 293, 1825, 665, 486, 808, 484, 295, 341, 11, 558, 30, 51204], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 70, "seek": 24240, "start": 260.4, "end": 265.52, "text": " But if you are a sort of, you know, tabular rice reinforcement learning system that doesn't", "tokens": [51264, 583, 498, 291, 366, 257, 1333, 295, 11, 291, 458, 11, 4421, 1040, 5090, 29280, 2539, 1185, 300, 1177, 380, 51520], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 71, "seek": 24240, "start": 265.52, "end": 271.28000000000003, "text": " have a model of the world, you have to repeat folding off this cliff thousands of times", "tokens": [51520, 362, 257, 2316, 295, 264, 1002, 11, 291, 362, 281, 7149, 25335, 766, 341, 22316, 5383, 295, 1413, 51808], "temperature": 0.0, "avg_logprob": -0.1573646938990033, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.0012250151485204697}, {"id": 72, "seek": 27128, "start": 271.28, "end": 272.79999999999995, "text": " before you figure out it's a bad idea.", "tokens": [50364, 949, 291, 2573, 484, 309, 311, 257, 1578, 1558, 13, 50440], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 73, "seek": 27128, "start": 272.79999999999995, "end": 276.55999999999995, "text": " And then a few more thousand times before you figure out how to not do it.", "tokens": [50440, 400, 550, 257, 1326, 544, 4714, 1413, 949, 291, 2573, 484, 577, 281, 406, 360, 309, 13, 50628], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 74, "seek": 27128, "start": 277.11999999999995, "end": 280.67999999999995, "text": " And then a few more million times before you figure out how to not do it in every situation", "tokens": [50656, 400, 550, 257, 1326, 544, 2459, 1413, 949, 291, 2573, 484, 577, 281, 406, 360, 309, 294, 633, 2590, 50834], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 75, "seek": 27128, "start": 280.67999999999995, "end": 281.52, "text": " you ever encounter.", "tokens": [50834, 291, 1562, 8593, 13, 50876], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 76, "seek": 27128, "start": 282.52, "end": 289.28, "text": " So self-supervised learning still has to have some source of truth being told to it by", "tokens": [50926, 407, 2698, 12, 48172, 24420, 2539, 920, 575, 281, 362, 512, 4009, 295, 3494, 885, 1907, 281, 309, 538, 51264], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 77, "seek": 27128, "start": 289.28, "end": 289.88, "text": " somebody.", "tokens": [51264, 2618, 13, 51294], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 78, "seek": 27128, "start": 290.11999999999995, "end": 295.47999999999996, "text": " And so you have to figure out a way without human assistance or without significant", "tokens": [51306, 400, 370, 291, 362, 281, 2573, 484, 257, 636, 1553, 1952, 9683, 420, 1553, 4776, 51574], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 79, "seek": 27128, "start": 295.47999999999996, "end": 298.71999999999997, "text": " amount of human assistance to get that truth from the world.", "tokens": [51574, 2372, 295, 1952, 9683, 281, 483, 300, 3494, 490, 264, 1002, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13158316447817045, "compression_ratio": 1.978813559322034, "no_speech_prob": 0.0022160832304507494}, {"id": 80, "seek": 29872, "start": 299.08000000000004, "end": 303.96000000000004, "text": " So the mystery there is how much signal is there?", "tokens": [50382, 407, 264, 11422, 456, 307, 577, 709, 6358, 307, 456, 30, 50626], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 81, "seek": 29872, "start": 303.96000000000004, "end": 308.44000000000005, "text": " How much truth is there that the world gives you, whether it's the human world, like you", "tokens": [50626, 1012, 709, 3494, 307, 456, 300, 264, 1002, 2709, 291, 11, 1968, 309, 311, 264, 1952, 1002, 11, 411, 291, 50850], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 82, "seek": 29872, "start": 308.44000000000005, "end": 312.36, "text": " watch YouTube or something like that, or it's the more natural world.", "tokens": [50850, 1159, 3088, 420, 746, 411, 300, 11, 420, 309, 311, 264, 544, 3303, 1002, 13, 51046], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 83, "seek": 29872, "start": 312.96000000000004, "end": 314.36, "text": " So how much signal is there?", "tokens": [51076, 407, 577, 709, 6358, 307, 456, 30, 51146], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 84, "seek": 29872, "start": 314.88000000000005, "end": 316.0, "text": " So here's the trick.", "tokens": [51172, 407, 510, 311, 264, 4282, 13, 51228], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 85, "seek": 29872, "start": 316.28000000000003, "end": 322.48, "text": " There is way more signal in sort of a self-supervised setting than there is in either a supervised", "tokens": [51242, 821, 307, 636, 544, 6358, 294, 1333, 295, 257, 2698, 12, 48172, 24420, 3287, 813, 456, 307, 294, 2139, 257, 46533, 51552], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 86, "seek": 29872, "start": 322.48, "end": 323.68, "text": " or reinforcement setting.", "tokens": [51552, 420, 29280, 3287, 13, 51612], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 87, "seek": 29872, "start": 324.52000000000004, "end": 328.20000000000005, "text": " And this is going to my, you know, analogy of the cake.", "tokens": [51654, 400, 341, 307, 516, 281, 452, 11, 291, 458, 11, 21663, 295, 264, 5908, 13, 51838], "temperature": 0.0, "avg_logprob": -0.13331378739455652, "compression_ratio": 1.8140495867768596, "no_speech_prob": 0.0013641206314787269}, {"id": 88, "seek": 32872, "start": 329.52000000000004, "end": 334.56, "text": " The, you know, low cake has someone that's called it, where when you try to figure out", "tokens": [50404, 440, 11, 291, 458, 11, 2295, 5908, 575, 1580, 300, 311, 1219, 309, 11, 689, 562, 291, 853, 281, 2573, 484, 50656], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 89, "seek": 32872, "start": 334.56, "end": 339.08000000000004, "text": " how much information you ask the machine to predict and how much feedback you give the", "tokens": [50656, 577, 709, 1589, 291, 1029, 264, 3479, 281, 6069, 293, 577, 709, 5824, 291, 976, 264, 50882], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 90, "seek": 32872, "start": 339.08000000000004, "end": 340.28000000000003, "text": " machine at every trial.", "tokens": [50882, 3479, 412, 633, 7308, 13, 50942], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 91, "seek": 32872, "start": 340.96000000000004, "end": 343.28000000000003, "text": " In reinforcement learning, you give the machine a single scalar.", "tokens": [50976, 682, 29280, 2539, 11, 291, 976, 264, 3479, 257, 2167, 39684, 13, 51092], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 92, "seek": 32872, "start": 343.28000000000003, "end": 345.0, "text": " You tell the machine you did good, you did bad.", "tokens": [51092, 509, 980, 264, 3479, 291, 630, 665, 11, 291, 630, 1578, 13, 51178], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 93, "seek": 32872, "start": 345.36, "end": 348.96000000000004, "text": " And you only tell this to the machine once in a while.", "tokens": [51196, 400, 291, 787, 980, 341, 281, 264, 3479, 1564, 294, 257, 1339, 13, 51376], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 94, "seek": 32872, "start": 349.56, "end": 352.32000000000005, "text": " When I say you, it could be the universe telling the machine, right?", "tokens": [51406, 1133, 286, 584, 291, 11, 309, 727, 312, 264, 6445, 3585, 264, 3479, 11, 558, 30, 51544], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 95, "seek": 32872, "start": 354.04, "end": 355.36, "text": " But it's just one scalar.", "tokens": [51630, 583, 309, 311, 445, 472, 39684, 13, 51696], "temperature": 0.0, "avg_logprob": -0.17409175237019855, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0011070797918364406}, {"id": 96, "seek": 35536, "start": 355.84000000000003, "end": 360.12, "text": " So as a consequence of this, you cannot possibly learn something very complicated without many,", "tokens": [50388, 407, 382, 257, 18326, 295, 341, 11, 291, 2644, 6264, 1466, 746, 588, 6179, 1553, 867, 11, 50602], "temperature": 0.0, "avg_logprob": -0.20256941926245595, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0011435345513746142}, {"id": 97, "seek": 35536, "start": 360.12, "end": 364.2, "text": " many, many trials where you get many, many feedbacks of this type.", "tokens": [50602, 867, 11, 867, 12450, 689, 291, 483, 867, 11, 867, 5824, 82, 295, 341, 2010, 13, 50806], "temperature": 0.0, "avg_logprob": -0.20256941926245595, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0011435345513746142}, {"id": 98, "seek": 35536, "start": 364.72, "end": 370.04, "text": " Supervised learning, you, you give a few bits to the machine at every, every sample.", "tokens": [50832, 4548, 24420, 2539, 11, 291, 11, 291, 976, 257, 1326, 9239, 281, 264, 3479, 412, 633, 11, 633, 6889, 13, 51098], "temperature": 0.0, "avg_logprob": -0.20256941926245595, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0011435345513746142}, {"id": 99, "seek": 35536, "start": 371.24, "end": 376.32, "text": " Let's say your training image system on, you know, recognizing images on the image net.", "tokens": [51158, 961, 311, 584, 428, 3097, 3256, 1185, 322, 11, 291, 458, 11, 18538, 5267, 322, 264, 3256, 2533, 13, 51412], "temperature": 0.0, "avg_logprob": -0.20256941926245595, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0011435345513746142}, {"id": 100, "seek": 35536, "start": 376.32, "end": 380.72, "text": " There is 1000 categories, that's a little less than 10 bits of information per sample.", "tokens": [51412, 821, 307, 9714, 10479, 11, 300, 311, 257, 707, 1570, 813, 1266, 9239, 295, 1589, 680, 6889, 13, 51632], "temperature": 0.0, "avg_logprob": -0.20256941926245595, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.0011435345513746142}, {"id": 101, "seek": 38072, "start": 380.96000000000004, "end": 382.56, "text": " But self-supervised learning, here is the setting.", "tokens": [50376, 583, 2698, 12, 48172, 24420, 2539, 11, 510, 307, 264, 3287, 13, 50456], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 102, "seek": 38072, "start": 382.56, "end": 388.32000000000005, "text": " You ideally, we don't know how to do this yet, but ideally you would show a machine a segment", "tokens": [50456, 509, 22915, 11, 321, 500, 380, 458, 577, 281, 360, 341, 1939, 11, 457, 22915, 291, 576, 855, 257, 3479, 257, 9469, 50744], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 103, "seek": 38072, "start": 388.32000000000005, "end": 394.08000000000004, "text": " of a video and then stop the video and ask, ask the machine to predict what's going to happen next.", "tokens": [50744, 295, 257, 960, 293, 550, 1590, 264, 960, 293, 1029, 11, 1029, 264, 3479, 281, 6069, 437, 311, 516, 281, 1051, 958, 13, 51032], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 104, "seek": 38072, "start": 396.32000000000005, "end": 402.16, "text": " So you let the machine predict and then you let time go by and show the machine what actually", "tokens": [51144, 407, 291, 718, 264, 3479, 6069, 293, 550, 291, 718, 565, 352, 538, 293, 855, 264, 3479, 437, 767, 51436], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 105, "seek": 38072, "start": 402.16, "end": 407.44000000000005, "text": " happened and hope the machine will, you know, learn to do a better job at predicting next", "tokens": [51436, 2011, 293, 1454, 264, 3479, 486, 11, 291, 458, 11, 1466, 281, 360, 257, 1101, 1691, 412, 32884, 958, 51700], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 106, "seek": 38072, "start": 407.44000000000005, "end": 408.04, "text": " time around.", "tokens": [51700, 565, 926, 13, 51730], "temperature": 0.0, "avg_logprob": -0.3024653366633824, "compression_ratio": 1.8375, "no_speech_prob": 0.0010302480077371001}, {"id": 107, "seek": 40804, "start": 408.20000000000005, "end": 413.40000000000003, "text": " There's a huge amount of information you give the machine because it's an entire video clip", "tokens": [50372, 821, 311, 257, 2603, 2372, 295, 1589, 291, 976, 264, 3479, 570, 309, 311, 364, 2302, 960, 7353, 50632], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 108, "seek": 40804, "start": 414.6, "end": 420.04, "text": " of, you know, of the future after the video clip you fed it in the first place.", "tokens": [50692, 295, 11, 291, 458, 11, 295, 264, 2027, 934, 264, 960, 7353, 291, 4636, 309, 294, 264, 700, 1081, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 109, "seek": 40804, "start": 420.04, "end": 426.76, "text": " So both for language and for vision, there's a subtle, seemingly trivial construction,", "tokens": [50964, 407, 1293, 337, 2856, 293, 337, 5201, 11, 456, 311, 257, 13743, 11, 18709, 26703, 6435, 11, 51300], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 110, "seek": 40804, "start": 426.76, "end": 430.92, "text": " but maybe that's representative of what is required to create intelligence, which is", "tokens": [51300, 457, 1310, 300, 311, 12424, 295, 437, 307, 4739, 281, 1884, 7599, 11, 597, 307, 51508], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 111, "seek": 40804, "start": 431.72, "end": 432.52000000000004, "text": " filling the gap.", "tokens": [51548, 10623, 264, 7417, 13, 51588], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 112, "seek": 40804, "start": 433.64000000000004, "end": 437.48, "text": " So it sounds dumb, but can you", "tokens": [51644, 407, 309, 3263, 10316, 11, 457, 393, 291, 51836], "temperature": 0.0, "avg_logprob": -0.21079980950606497, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002979506039991975}, {"id": 113, "seek": 43804, "start": 438.52000000000004, "end": 443.0, "text": " it's, it is possible that you can solve all of intelligence in this way.", "tokens": [50388, 309, 311, 11, 309, 307, 1944, 300, 291, 393, 5039, 439, 295, 7599, 294, 341, 636, 13, 50612], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 114, "seek": 43804, "start": 443.0, "end": 450.12, "text": " Just for both language, just give a sentence and continue it or give a sentence and there's", "tokens": [50612, 1449, 337, 1293, 2856, 11, 445, 976, 257, 8174, 293, 2354, 309, 420, 976, 257, 8174, 293, 456, 311, 50968], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 115, "seek": 43804, "start": 450.12, "end": 455.0, "text": " a gap in it, some words blanked out and you fill in what words go there.", "tokens": [50968, 257, 7417, 294, 309, 11, 512, 2283, 8247, 292, 484, 293, 291, 2836, 294, 437, 2283, 352, 456, 13, 51212], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 116, "seek": 43804, "start": 455.64000000000004, "end": 461.08000000000004, "text": " For vision, you give a sequence of images and predict what's going to happen next or", "tokens": [51244, 1171, 5201, 11, 291, 976, 257, 8310, 295, 5267, 293, 6069, 437, 311, 516, 281, 1051, 958, 420, 51516], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 117, "seek": 43804, "start": 461.08000000000004, "end": 462.68, "text": " you fill in what happened in between.", "tokens": [51516, 291, 2836, 294, 437, 2011, 294, 1296, 13, 51596], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 118, "seek": 43804, "start": 463.64000000000004, "end": 466.6, "text": " Do you think it's possible that formulation alone", "tokens": [51644, 1144, 291, 519, 309, 311, 1944, 300, 37642, 3312, 51792], "temperature": 0.0, "avg_logprob": -0.14115642806858691, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.0006460686563514173}, {"id": 119, "seek": 46804, "start": 468.52000000000004, "end": 473.56, "text": " as a signal for self-supervised learning can solve intelligence for vision and language?", "tokens": [50388, 382, 257, 6358, 337, 2698, 12, 48172, 24420, 2539, 393, 5039, 7599, 337, 5201, 293, 2856, 30, 50640], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 120, "seek": 46804, "start": 473.56, "end": 475.24, "text": " I think that's our best shot at the moment.", "tokens": [50640, 286, 519, 300, 311, 527, 1151, 3347, 412, 264, 1623, 13, 50724], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 121, "seek": 46804, "start": 476.28000000000003, "end": 481.40000000000003, "text": " So whether this will take us all the way to, you know, human level intelligence or", "tokens": [50776, 407, 1968, 341, 486, 747, 505, 439, 264, 636, 281, 11, 291, 458, 11, 1952, 1496, 7599, 420, 51032], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 122, "seek": 46804, "start": 481.40000000000003, "end": 487.24, "text": " something or just cat level intelligence is not clear, but among all the possible approaches", "tokens": [51032, 746, 420, 445, 3857, 1496, 7599, 307, 406, 1850, 11, 457, 3654, 439, 264, 1944, 11587, 51324], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 123, "seek": 46804, "start": 487.24, "end": 489.48, "text": " that people have proposed, I think it's our best shot.", "tokens": [51324, 300, 561, 362, 10348, 11, 286, 519, 309, 311, 527, 1151, 3347, 13, 51436], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 124, "seek": 46804, "start": 489.48, "end": 496.44, "text": " So I think this idea of an intelligent system filling in the blanks, either,", "tokens": [51436, 407, 286, 519, 341, 1558, 295, 364, 13232, 1185, 10623, 294, 264, 8247, 82, 11, 2139, 11, 51784], "temperature": 0.0, "avg_logprob": -0.10183474702655144, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.0011871160240843892}, {"id": 125, "seek": 49644, "start": 497.16, "end": 501.8, "text": " predicting the future, inferring the past, filling in missing information.", "tokens": [50400, 32884, 264, 2027, 11, 13596, 2937, 264, 1791, 11, 10623, 294, 5361, 1589, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 126, "seek": 49644, "start": 503.71999999999997, "end": 508.12, "text": " I'm currently filling the blank of what is behind your head and what your head looks like", "tokens": [50728, 286, 478, 4362, 10623, 264, 8247, 295, 437, 307, 2261, 428, 1378, 293, 437, 428, 1378, 1542, 411, 50948], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 127, "seek": 49644, "start": 508.12, "end": 513.16, "text": " and from the back because I have a basic knowledge about how humans are made.", "tokens": [50948, 293, 490, 264, 646, 570, 286, 362, 257, 3875, 3601, 466, 577, 6255, 366, 1027, 13, 51200], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 128, "seek": 49644, "start": 513.72, "end": 517.16, "text": " And I don't know if you're going to say at which point you're going to speak,", "tokens": [51228, 400, 286, 500, 380, 458, 498, 291, 434, 516, 281, 584, 412, 597, 935, 291, 434, 516, 281, 1710, 11, 51400], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 129, "seek": 49644, "start": 517.16, "end": 520.12, "text": " whether you're going to move your head this way or that way, which way you're going to look,", "tokens": [51400, 1968, 291, 434, 516, 281, 1286, 428, 1378, 341, 636, 420, 300, 636, 11, 597, 636, 291, 434, 516, 281, 574, 11, 51548], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 130, "seek": 49644, "start": 520.12, "end": 524.68, "text": " but I know you're not going to just dematerialize and reappear three meters down the hall", "tokens": [51548, 457, 286, 458, 291, 434, 406, 516, 281, 445, 1371, 40364, 1125, 293, 35638, 14881, 1045, 8146, 760, 264, 6500, 51776], "temperature": 0.0, "avg_logprob": -0.11975912124879899, "compression_ratio": 1.8424908424908424, "no_speech_prob": 0.001985519425943494}, {"id": 131, "seek": 52468, "start": 525.64, "end": 530.76, "text": " because I know what's possible and what's impossible according to the physics.", "tokens": [50412, 570, 286, 458, 437, 311, 1944, 293, 437, 311, 6243, 4650, 281, 264, 10649, 13, 50668], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 132, "seek": 52468, "start": 530.76, "end": 534.3599999999999, "text": " But you have a model of what's possible, what's impossible and then you'd be very surprised", "tokens": [50668, 583, 291, 362, 257, 2316, 295, 437, 311, 1944, 11, 437, 311, 6243, 293, 550, 291, 1116, 312, 588, 6100, 50848], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 133, "seek": 52468, "start": 534.3599999999999, "end": 537.16, "text": " if it happens and then you'll have to reconstruct your model.", "tokens": [50848, 498, 309, 2314, 293, 550, 291, 603, 362, 281, 31499, 428, 2316, 13, 50988], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 134, "seek": 52468, "start": 537.7199999999999, "end": 542.12, "text": " Right. So that's the model of the world. It's what tells you, you know, what fills in the blanks.", "tokens": [51016, 1779, 13, 407, 300, 311, 264, 2316, 295, 264, 1002, 13, 467, 311, 437, 5112, 291, 11, 291, 458, 11, 437, 22498, 294, 264, 8247, 82, 13, 51236], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 135, "seek": 52468, "start": 542.12, "end": 546.76, "text": " So given your partial information about the state of the world, given by your perception,", "tokens": [51236, 407, 2212, 428, 14641, 1589, 466, 264, 1785, 295, 264, 1002, 11, 2212, 538, 428, 12860, 11, 51468], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 136, "seek": 52468, "start": 547.9599999999999, "end": 552.68, "text": " your model of the world fills in the missing information and that includes predicting the", "tokens": [51528, 428, 2316, 295, 264, 1002, 22498, 294, 264, 5361, 1589, 293, 300, 5974, 32884, 264, 51764], "temperature": 0.0, "avg_logprob": -0.15328369455889237, "compression_ratio": 1.9540229885057472, "no_speech_prob": 0.0027567341458052397}, {"id": 137, "seek": 55268, "start": 552.68, "end": 558.28, "text": " future, rich predicting the past, you know, filling in things you don't immediately perceive.", "tokens": [50364, 2027, 11, 4593, 32884, 264, 1791, 11, 291, 458, 11, 10623, 294, 721, 291, 500, 380, 4258, 20281, 13, 50644], "temperature": 0.0, "avg_logprob": -0.10479343368346433, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0014081173576414585}, {"id": 138, "seek": 55268, "start": 558.28, "end": 564.1999999999999, "text": " And that doesn't have to be purely generic vision or visual information or generic language.", "tokens": [50644, 400, 300, 1177, 380, 362, 281, 312, 17491, 19577, 5201, 420, 5056, 1589, 420, 19577, 2856, 13, 50940], "temperature": 0.0, "avg_logprob": -0.10479343368346433, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0014081173576414585}, {"id": 139, "seek": 55268, "start": 564.1999999999999, "end": 571.0, "text": " You can go to specifics like predicting what control decision you make when you're driving", "tokens": [50940, 509, 393, 352, 281, 28454, 411, 32884, 437, 1969, 3537, 291, 652, 562, 291, 434, 4840, 51280], "temperature": 0.0, "avg_logprob": -0.10479343368346433, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0014081173576414585}, {"id": 140, "seek": 55268, "start": 571.0, "end": 578.28, "text": " in a lane. You have a sequence of images from a vehicle and then you could, you have information", "tokens": [51280, 294, 257, 12705, 13, 509, 362, 257, 8310, 295, 5267, 490, 257, 5864, 293, 550, 291, 727, 11, 291, 362, 1589, 51644], "temperature": 0.0, "avg_logprob": -0.10479343368346433, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.0014081173576414585}, {"id": 141, "seek": 57828, "start": 578.36, "end": 584.12, "text": " if you recorded on video where the car ended up going. So you can go back in time and predict", "tokens": [50368, 498, 291, 8287, 322, 960, 689, 264, 1032, 4590, 493, 516, 13, 407, 291, 393, 352, 646, 294, 565, 293, 6069, 50656], "temperature": 0.0, "avg_logprob": -0.08968034157386193, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005466181319206953}, {"id": 142, "seek": 57828, "start": 584.12, "end": 588.52, "text": " where the car went based on the visual information. That's very specific, domain specific.", "tokens": [50656, 689, 264, 1032, 1437, 2361, 322, 264, 5056, 1589, 13, 663, 311, 588, 2685, 11, 9274, 2685, 13, 50876], "temperature": 0.0, "avg_logprob": -0.08968034157386193, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005466181319206953}, {"id": 143, "seek": 57828, "start": 589.4, "end": 592.68, "text": " Right. But the question is whether we can come up with sort of a generic", "tokens": [50920, 1779, 13, 583, 264, 1168, 307, 1968, 321, 393, 808, 493, 365, 1333, 295, 257, 19577, 51084], "temperature": 0.0, "avg_logprob": -0.08968034157386193, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005466181319206953}, {"id": 144, "seek": 57828, "start": 594.12, "end": 599.8, "text": " method for, you know, training machines to do this kind of prediction or filling in the blanks.", "tokens": [51156, 3170, 337, 11, 291, 458, 11, 3097, 8379, 281, 360, 341, 733, 295, 17630, 420, 10623, 294, 264, 8247, 82, 13, 51440], "temperature": 0.0, "avg_logprob": -0.08968034157386193, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005466181319206953}, {"id": 145, "seek": 57828, "start": 599.8, "end": 606.1999999999999, "text": " So right now, this type of approach has been unbelievably successful in the context of", "tokens": [51440, 407, 558, 586, 11, 341, 2010, 295, 3109, 575, 668, 43593, 4406, 294, 264, 4319, 295, 51760], "temperature": 0.0, "avg_logprob": -0.08968034157386193, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.005466181319206953}, {"id": 146, "seek": 60620, "start": 606.2, "end": 610.44, "text": " natural language processing. Every modern natural language processing is pre-trained in", "tokens": [50364, 3303, 2856, 9007, 13, 2048, 4363, 3303, 2856, 9007, 307, 659, 12, 17227, 2001, 294, 50576], "temperature": 0.0, "avg_logprob": -0.09930320921398345, "compression_ratio": 1.75, "no_speech_prob": 0.000999986194074154}, {"id": 147, "seek": 60620, "start": 610.44, "end": 615.72, "text": " self-supervised manner to fill in the blanks. You show it a sequence of words, you remove 10%", "tokens": [50576, 2698, 12, 48172, 24420, 9060, 281, 2836, 294, 264, 8247, 82, 13, 509, 855, 309, 257, 8310, 295, 2283, 11, 291, 4159, 1266, 4, 50840], "temperature": 0.0, "avg_logprob": -0.09930320921398345, "compression_ratio": 1.75, "no_speech_prob": 0.000999986194074154}, {"id": 148, "seek": 60620, "start": 615.72, "end": 619.08, "text": " of them, and then you train some gigantic neural net to predict the words that are missing.", "tokens": [50840, 295, 552, 11, 293, 550, 291, 3847, 512, 26800, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 51008], "temperature": 0.0, "avg_logprob": -0.09930320921398345, "compression_ratio": 1.75, "no_speech_prob": 0.000999986194074154}, {"id": 149, "seek": 60620, "start": 620.2800000000001, "end": 625.8000000000001, "text": " And once you've pre-trained that network, you can use the internal representation", "tokens": [51068, 400, 1564, 291, 600, 659, 12, 17227, 2001, 300, 3209, 11, 291, 393, 764, 264, 6920, 10290, 51344], "temperature": 0.0, "avg_logprob": -0.09930320921398345, "compression_ratio": 1.75, "no_speech_prob": 0.000999986194074154}, {"id": 150, "seek": 60620, "start": 625.8000000000001, "end": 631.1600000000001, "text": " learned by it as input to, you know, something that you train supervised or whatever.", "tokens": [51344, 3264, 538, 309, 382, 4846, 281, 11, 291, 458, 11, 746, 300, 291, 3847, 46533, 420, 2035, 13, 51612], "temperature": 0.0, "avg_logprob": -0.09930320921398345, "compression_ratio": 1.75, "no_speech_prob": 0.000999986194074154}, {"id": 151, "seek": 63116, "start": 632.04, "end": 636.68, "text": " That's been incredibly successful, not so successful in images, although it's making progress.", "tokens": [50408, 663, 311, 668, 6252, 4406, 11, 406, 370, 4406, 294, 5267, 11, 4878, 309, 311, 1455, 4205, 13, 50640], "temperature": 0.0, "avg_logprob": -0.10785715295634138, "compression_ratio": 1.5971731448763251, "no_speech_prob": 0.013425396755337715}, {"id": 152, "seek": 63116, "start": 637.48, "end": 644.04, "text": " And it's based on sort of manual data augmentation. We can go into this later. But", "tokens": [50680, 400, 309, 311, 2361, 322, 1333, 295, 9688, 1412, 14501, 19631, 13, 492, 393, 352, 666, 341, 1780, 13, 583, 51008], "temperature": 0.0, "avg_logprob": -0.10785715295634138, "compression_ratio": 1.5971731448763251, "no_speech_prob": 0.013425396755337715}, {"id": 153, "seek": 63116, "start": 644.04, "end": 648.36, "text": " what has not been successful yet is training from video. So getting a machine to learn,", "tokens": [51008, 437, 575, 406, 668, 4406, 1939, 307, 3097, 490, 960, 13, 407, 1242, 257, 3479, 281, 1466, 11, 51224], "temperature": 0.0, "avg_logprob": -0.10785715295634138, "compression_ratio": 1.5971731448763251, "no_speech_prob": 0.013425396755337715}, {"id": 154, "seek": 63116, "start": 648.36, "end": 653.48, "text": " to represent the visual world, for example, by just watching video. Nobody has really", "tokens": [51224, 281, 2906, 264, 5056, 1002, 11, 337, 1365, 11, 538, 445, 1976, 960, 13, 9297, 575, 534, 51480], "temperature": 0.0, "avg_logprob": -0.10785715295634138, "compression_ratio": 1.5971731448763251, "no_speech_prob": 0.013425396755337715}, {"id": 155, "seek": 63116, "start": 653.48, "end": 658.76, "text": " succeeded in doing this. Okay. Well, let's kind of give a high-level overview. What's the difference", "tokens": [51480, 20263, 294, 884, 341, 13, 1033, 13, 1042, 11, 718, 311, 733, 295, 976, 257, 1090, 12, 12418, 12492, 13, 708, 311, 264, 2649, 51744], "temperature": 0.0, "avg_logprob": -0.10785715295634138, "compression_ratio": 1.5971731448763251, "no_speech_prob": 0.013425396755337715}, {"id": 156, "seek": 65876, "start": 658.84, "end": 666.36, "text": " in kind and in difficulty between vision and language? So you said people haven't been able to", "tokens": [50368, 294, 733, 293, 294, 10360, 1296, 5201, 293, 2856, 30, 407, 291, 848, 561, 2378, 380, 668, 1075, 281, 50744], "temperature": 0.0, "avg_logprob": -0.11503456223685786, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.009408501908183098}, {"id": 157, "seek": 65876, "start": 667.72, "end": 671.88, "text": " really kind of crack the problem of vision open in terms of self-supervised learning,", "tokens": [50812, 534, 733, 295, 6226, 264, 1154, 295, 5201, 1269, 294, 2115, 295, 2698, 12, 48172, 24420, 2539, 11, 51020], "temperature": 0.0, "avg_logprob": -0.11503456223685786, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.009408501908183098}, {"id": 158, "seek": 65876, "start": 671.88, "end": 676.92, "text": " but that may not be necessarily because it's fundamentally more difficult. Maybe like when", "tokens": [51020, 457, 300, 815, 406, 312, 4725, 570, 309, 311, 17879, 544, 2252, 13, 2704, 411, 562, 51272], "temperature": 0.0, "avg_logprob": -0.11503456223685786, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.009408501908183098}, {"id": 159, "seek": 65876, "start": 676.92, "end": 683.24, "text": " we're talking about achieving, like passing the Turing test in the full spirit of the Turing test", "tokens": [51272, 321, 434, 1417, 466, 19626, 11, 411, 8437, 264, 314, 1345, 1500, 294, 264, 1577, 3797, 295, 264, 314, 1345, 1500, 51588], "temperature": 0.0, "avg_logprob": -0.11503456223685786, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.009408501908183098}, {"id": 160, "seek": 65876, "start": 683.24, "end": 688.68, "text": " in language might be harder than vision. That's not obvious. So in your view, which is harder", "tokens": [51588, 294, 2856, 1062, 312, 6081, 813, 5201, 13, 663, 311, 406, 6322, 13, 407, 294, 428, 1910, 11, 597, 307, 6081, 51860], "temperature": 0.0, "avg_logprob": -0.11503456223685786, "compression_ratio": 1.6714801444043321, "no_speech_prob": 0.009408501908183098}, {"id": 161, "seek": 68876, "start": 689.3199999999999, "end": 694.68, "text": " or perhaps are they just the same problem? When the farther we get to solving each,", "tokens": [50392, 420, 4317, 366, 436, 445, 264, 912, 1154, 30, 1133, 264, 20344, 321, 483, 281, 12606, 1184, 11, 50660], "temperature": 0.0, "avg_logprob": -0.07422913655196087, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.001753566786646843}, {"id": 162, "seek": 68876, "start": 694.68, "end": 698.04, "text": " the more we realize it's all the same thing. It's all the same cake. I think", "tokens": [50660, 264, 544, 321, 4325, 309, 311, 439, 264, 912, 551, 13, 467, 311, 439, 264, 912, 5908, 13, 286, 519, 50828], "temperature": 0.0, "avg_logprob": -0.07422913655196087, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.001753566786646843}, {"id": 163, "seek": 68876, "start": 698.84, "end": 703.48, "text": " what I'm looking for are methods that make them look essentially like the same cake,", "tokens": [50868, 437, 286, 478, 1237, 337, 366, 7150, 300, 652, 552, 574, 4476, 411, 264, 912, 5908, 11, 51100], "temperature": 0.0, "avg_logprob": -0.07422913655196087, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.001753566786646843}, {"id": 164, "seek": 68876, "start": 703.48, "end": 709.08, "text": " but currently they're not. And the main issue with learning world models or learning predictive", "tokens": [51100, 457, 4362, 436, 434, 406, 13, 400, 264, 2135, 2734, 365, 2539, 1002, 5245, 420, 2539, 35521, 51380], "temperature": 0.0, "avg_logprob": -0.07422913655196087, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.001753566786646843}, {"id": 165, "seek": 68876, "start": 709.08, "end": 718.36, "text": " models is that the prediction is never a single thing because the world is not entirely predictable.", "tokens": [51380, 5245, 307, 300, 264, 17630, 307, 1128, 257, 2167, 551, 570, 264, 1002, 307, 406, 7696, 27737, 13, 51844], "temperature": 0.0, "avg_logprob": -0.07422913655196087, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.001753566786646843}, {"id": 166, "seek": 71876, "start": 719.16, "end": 722.92, "text": " It may be deterministic or stochastic. We can get into the philosophical discussion about it,", "tokens": [50384, 467, 815, 312, 15957, 3142, 420, 342, 8997, 2750, 13, 492, 393, 483, 666, 264, 25066, 5017, 466, 309, 11, 50572], "temperature": 0.0, "avg_logprob": -0.07454826718284971, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0017439309740439057}, {"id": 167, "seek": 71876, "start": 722.92, "end": 729.48, "text": " but even if it's deterministic, it's not entirely predictable. And so if I play", "tokens": [50572, 457, 754, 498, 309, 311, 15957, 3142, 11, 309, 311, 406, 7696, 27737, 13, 400, 370, 498, 286, 862, 50900], "temperature": 0.0, "avg_logprob": -0.07454826718284971, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0017439309740439057}, {"id": 168, "seek": 71876, "start": 730.68, "end": 734.04, "text": " a short video clip and then I ask you to predict what's going to happen next,", "tokens": [50960, 257, 2099, 960, 7353, 293, 550, 286, 1029, 291, 281, 6069, 437, 311, 516, 281, 1051, 958, 11, 51128], "temperature": 0.0, "avg_logprob": -0.07454826718284971, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0017439309740439057}, {"id": 169, "seek": 71876, "start": 734.04, "end": 739.88, "text": " there's many, many plausible continuations for that video clip. And the number of continuation", "tokens": [51128, 456, 311, 867, 11, 867, 39925, 2993, 763, 337, 300, 960, 7353, 13, 400, 264, 1230, 295, 29357, 51420], "temperature": 0.0, "avg_logprob": -0.07454826718284971, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0017439309740439057}, {"id": 170, "seek": 71876, "start": 739.88, "end": 745.48, "text": " grows with the interval of time that you're asking the system to make a prediction for.", "tokens": [51420, 13156, 365, 264, 15035, 295, 565, 300, 291, 434, 3365, 264, 1185, 281, 652, 257, 17630, 337, 13, 51700], "temperature": 0.0, "avg_logprob": -0.07454826718284971, "compression_ratio": 1.688715953307393, "no_speech_prob": 0.0017439309740439057}, {"id": 171, "seek": 74548, "start": 746.36, "end": 752.52, "text": " And so one big question with self-provisioning is how you represent this uncertainty, how you", "tokens": [50408, 400, 370, 472, 955, 1168, 365, 2698, 12, 4318, 6763, 278, 307, 577, 291, 2906, 341, 15697, 11, 577, 291, 50716], "temperature": 0.0, "avg_logprob": -0.14940403125904225, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0012803984573110938}, {"id": 172, "seek": 74548, "start": 752.52, "end": 758.12, "text": " represent multiple discrete outcomes, how you represent a continuum of possible outcomes,", "tokens": [50716, 2906, 3866, 27706, 10070, 11, 577, 291, 2906, 257, 36120, 295, 1944, 10070, 11, 50996], "temperature": 0.0, "avg_logprob": -0.14940403125904225, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0012803984573110938}, {"id": 173, "seek": 74548, "start": 759.32, "end": 765.5600000000001, "text": " et cetera. And if you are a classical machine learning person, you say, oh,", "tokens": [51056, 1030, 11458, 13, 400, 498, 291, 366, 257, 13735, 3479, 2539, 954, 11, 291, 584, 11, 1954, 11, 51368], "temperature": 0.0, "avg_logprob": -0.14940403125904225, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0012803984573110938}, {"id": 174, "seek": 74548, "start": 765.5600000000001, "end": 772.44, "text": " you just represent a distribution. And that we know how to do when we're predicting words,", "tokens": [51368, 291, 445, 2906, 257, 7316, 13, 400, 300, 321, 458, 577, 281, 360, 562, 321, 434, 32884, 2283, 11, 51712], "temperature": 0.0, "avg_logprob": -0.14940403125904225, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0012803984573110938}, {"id": 175, "seek": 77244, "start": 772.5200000000001, "end": 777.8800000000001, "text": " missing words in the text, because you can have a neural net give a score for every word in the", "tokens": [50368, 5361, 2283, 294, 264, 2487, 11, 570, 291, 393, 362, 257, 18161, 2533, 976, 257, 6175, 337, 633, 1349, 294, 264, 50636], "temperature": 0.0, "avg_logprob": -0.11344157771060341, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.014240922406315804}, {"id": 176, "seek": 77244, "start": 777.8800000000001, "end": 783.72, "text": " dictionary. It's a big list of numbers, maybe 100,000 or so. And you can turn them into a", "tokens": [50636, 25890, 13, 467, 311, 257, 955, 1329, 295, 3547, 11, 1310, 2319, 11, 1360, 420, 370, 13, 400, 291, 393, 1261, 552, 666, 257, 50928], "temperature": 0.0, "avg_logprob": -0.11344157771060341, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.014240922406315804}, {"id": 177, "seek": 77244, "start": 783.72, "end": 791.48, "text": " probability distribution that tells you when I say a sentence, the cat is chasing the blank", "tokens": [50928, 8482, 7316, 300, 5112, 291, 562, 286, 584, 257, 8174, 11, 264, 3857, 307, 17876, 264, 8247, 51316], "temperature": 0.0, "avg_logprob": -0.11344157771060341, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.014240922406315804}, {"id": 178, "seek": 77244, "start": 791.48, "end": 797.24, "text": " in the kitchen. There are only a few words that make sense there. It could be a mouse or it could", "tokens": [51316, 294, 264, 6525, 13, 821, 366, 787, 257, 1326, 2283, 300, 652, 2020, 456, 13, 467, 727, 312, 257, 9719, 420, 309, 727, 51604], "temperature": 0.0, "avg_logprob": -0.11344157771060341, "compression_ratio": 1.5756302521008403, "no_speech_prob": 0.014240922406315804}, {"id": 179, "seek": 79724, "start": 797.24, "end": 805.72, "text": " be a lizard spot or something like that. And if I say the blank is chasing the blank in the savannah,", "tokens": [50364, 312, 257, 39215, 4008, 420, 746, 411, 300, 13, 400, 498, 286, 584, 264, 8247, 307, 17876, 264, 8247, 294, 264, 11163, 15143, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1394536230299208, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00536704296246171}, {"id": 180, "seek": 79724, "start": 805.72, "end": 812.6800000000001, "text": " you also have a bunch of plausible options for those two words. Because you have kind of a", "tokens": [50788, 291, 611, 362, 257, 3840, 295, 39925, 3956, 337, 729, 732, 2283, 13, 1436, 291, 362, 733, 295, 257, 51136], "temperature": 0.0, "avg_logprob": -0.1394536230299208, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00536704296246171}, {"id": 181, "seek": 79724, "start": 812.6800000000001, "end": 821.4, "text": " underlying reality that you can refer to to fill in those blanks. So you cannot say for sure in", "tokens": [51136, 14217, 4103, 300, 291, 393, 2864, 281, 281, 2836, 294, 729, 8247, 82, 13, 407, 291, 2644, 584, 337, 988, 294, 51572], "temperature": 0.0, "avg_logprob": -0.1394536230299208, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00536704296246171}, {"id": 182, "seek": 82140, "start": 821.4, "end": 826.92, "text": " the savannah, if it's a lion or a cheetah or whatever, you cannot know if it's a zebra or", "tokens": [50364, 264, 11163, 15143, 11, 498, 309, 311, 257, 17226, 420, 257, 947, 47947, 420, 2035, 11, 291, 2644, 458, 498, 309, 311, 257, 47060, 420, 50640], "temperature": 0.0, "avg_logprob": -0.1398344138233932, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.004812559578567743}, {"id": 183, "seek": 82140, "start": 827.56, "end": 836.68, "text": " a goo or whatever. We're the beast, the same thing. But you can represent the uncertainty", "tokens": [50672, 257, 33192, 420, 2035, 13, 492, 434, 264, 13464, 11, 264, 912, 551, 13, 583, 291, 393, 2906, 264, 15697, 51128], "temperature": 0.0, "avg_logprob": -0.1398344138233932, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.004812559578567743}, {"id": 184, "seek": 82140, "start": 836.68, "end": 842.92, "text": " by just a long list of numbers. Now, if I do the same thing with video and I ask you to predict", "tokens": [51128, 538, 445, 257, 938, 1329, 295, 3547, 13, 823, 11, 498, 286, 360, 264, 912, 551, 365, 960, 293, 286, 1029, 291, 281, 6069, 51440], "temperature": 0.0, "avg_logprob": -0.1398344138233932, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.004812559578567743}, {"id": 185, "seek": 82140, "start": 842.92, "end": 847.96, "text": " a video clip, it's not a discrete set of potential frames. You have to have", "tokens": [51440, 257, 960, 7353, 11, 309, 311, 406, 257, 27706, 992, 295, 3995, 12083, 13, 509, 362, 281, 362, 51692], "temperature": 0.0, "avg_logprob": -0.1398344138233932, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.004812559578567743}, {"id": 186, "seek": 84796, "start": 848.76, "end": 853.4000000000001, "text": " somewhere representing a sort of infinite number of plausible continuations", "tokens": [50404, 4079, 13460, 257, 1333, 295, 13785, 1230, 295, 39925, 2993, 763, 50636], "temperature": 0.0, "avg_logprob": -0.18112421035766602, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.004606078378856182}, {"id": 187, "seek": 84796, "start": 853.4000000000001, "end": 858.36, "text": " of multiple frames in a high-dimensional, continuous space. And we just have no idea", "tokens": [50636, 295, 3866, 12083, 294, 257, 1090, 12, 18759, 11, 10957, 1901, 13, 400, 321, 445, 362, 572, 1558, 50884], "temperature": 0.0, "avg_logprob": -0.18112421035766602, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.004606078378856182}, {"id": 188, "seek": 84796, "start": 858.36, "end": 865.32, "text": " how to do this properly. Finite high-dimensional. It's finite high-dimensional, yes.", "tokens": [50884, 577, 281, 360, 341, 6108, 13, 3773, 642, 1090, 12, 18759, 13, 467, 311, 19362, 1090, 12, 18759, 11, 2086, 13, 51232], "temperature": 0.0, "avg_logprob": -0.18112421035766602, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.004606078378856182}, {"id": 189, "seek": 84796, "start": 865.32, "end": 873.32, "text": " Just like the words. They try to get it down to a small finite set of like under a million,", "tokens": [51232, 1449, 411, 264, 2283, 13, 814, 853, 281, 483, 309, 760, 281, 257, 1359, 19362, 992, 295, 411, 833, 257, 2459, 11, 51632], "temperature": 0.0, "avg_logprob": -0.18112421035766602, "compression_ratio": 1.6047619047619048, "no_speech_prob": 0.004606078378856182}, {"id": 190, "seek": 87332, "start": 873.32, "end": 878.9200000000001, "text": " something like that. I mean, it's kind of ridiculous that we're doing a distribution", "tokens": [50364, 746, 411, 300, 13, 286, 914, 11, 309, 311, 733, 295, 11083, 300, 321, 434, 884, 257, 7316, 50644], "temperature": 0.0, "avg_logprob": -0.0879598924483376, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.10182590037584305}, {"id": 191, "seek": 87332, "start": 878.9200000000001, "end": 884.2800000000001, "text": " over every single possible word for language, and it works. It feels like that's a really dumb", "tokens": [50644, 670, 633, 2167, 1944, 1349, 337, 2856, 11, 293, 309, 1985, 13, 467, 3417, 411, 300, 311, 257, 534, 10316, 50912], "temperature": 0.0, "avg_logprob": -0.0879598924483376, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.10182590037584305}, {"id": 192, "seek": 87332, "start": 884.2800000000001, "end": 893.08, "text": " way to do it. It seems to be like there should be some more compressed representation of the", "tokens": [50912, 636, 281, 360, 309, 13, 467, 2544, 281, 312, 411, 456, 820, 312, 512, 544, 30353, 10290, 295, 264, 51352], "temperature": 0.0, "avg_logprob": -0.0879598924483376, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.10182590037584305}, {"id": 193, "seek": 87332, "start": 893.08, "end": 898.84, "text": " distribution of the words. You're right about that. I agree. Do you have any interesting ideas", "tokens": [51352, 7316, 295, 264, 2283, 13, 509, 434, 558, 466, 300, 13, 286, 3986, 13, 1144, 291, 362, 604, 1880, 3487, 51640], "temperature": 0.0, "avg_logprob": -0.0879598924483376, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.10182590037584305}, {"id": 194, "seek": 89884, "start": 898.84, "end": 903.32, "text": " about how to represent all the reality in a compressed way such that you can form a distribution", "tokens": [50364, 466, 577, 281, 2906, 439, 264, 4103, 294, 257, 30353, 636, 1270, 300, 291, 393, 1254, 257, 7316, 50588], "temperature": 0.0, "avg_logprob": -0.1446005623295622, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.003645470831543207}, {"id": 195, "seek": 89884, "start": 903.32, "end": 909.32, "text": " over it? That's one of the big questions. How do you do that? I mean, another thing that really is", "tokens": [50588, 670, 309, 30, 663, 311, 472, 295, 264, 955, 1651, 13, 1012, 360, 291, 360, 300, 30, 286, 914, 11, 1071, 551, 300, 534, 307, 50888], "temperature": 0.0, "avg_logprob": -0.1446005623295622, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.003645470831543207}, {"id": 196, "seek": 89884, "start": 910.6, "end": 915.5600000000001, "text": " stupid about, I shouldn't say stupid, but simplistic about current approaches to", "tokens": [50952, 6631, 466, 11, 286, 4659, 380, 584, 6631, 11, 457, 44199, 466, 2190, 11587, 281, 51200], "temperature": 0.0, "avg_logprob": -0.1446005623295622, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.003645470831543207}, {"id": 197, "seek": 89884, "start": 915.5600000000001, "end": 922.84, "text": " self-supervisioning in NLP in text is that not only do you represent a giant distribution over", "tokens": [51200, 2698, 12, 48172, 6763, 278, 294, 426, 45196, 294, 2487, 307, 300, 406, 787, 360, 291, 2906, 257, 7410, 7316, 670, 51564], "temperature": 0.0, "avg_logprob": -0.1446005623295622, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.003645470831543207}, {"id": 198, "seek": 89884, "start": 922.84, "end": 927.5600000000001, "text": " words, but for multiple words that are missing, those distributions are essentially independent", "tokens": [51564, 2283, 11, 457, 337, 3866, 2283, 300, 366, 5361, 11, 729, 37870, 366, 4476, 6695, 51800], "temperature": 0.0, "avg_logprob": -0.1446005623295622, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.003645470831543207}, {"id": 199, "seek": 92756, "start": 927.56, "end": 938.1999999999999, "text": " of each other. You don't pay too much of a price for this. The system, in the sentence that I gave", "tokens": [50364, 295, 1184, 661, 13, 509, 500, 380, 1689, 886, 709, 295, 257, 3218, 337, 341, 13, 440, 1185, 11, 294, 264, 8174, 300, 286, 2729, 50896], "temperature": 0.0, "avg_logprob": -0.149509523955869, "compression_ratio": 1.5730337078651686, "no_speech_prob": 0.010797589085996151}, {"id": 200, "seek": 92756, "start": 938.1999999999999, "end": 944.1199999999999, "text": " earlier, if it gives a certain probability for a lion and cheetah, and then a certain", "tokens": [50896, 3071, 11, 498, 309, 2709, 257, 1629, 8482, 337, 257, 17226, 293, 947, 47947, 11, 293, 550, 257, 1629, 51192], "temperature": 0.0, "avg_logprob": -0.149509523955869, "compression_ratio": 1.5730337078651686, "no_speech_prob": 0.010797589085996151}, {"id": 201, "seek": 92756, "start": 944.1199999999999, "end": 954.3599999999999, "text": " probability for gazelle, wildebeest, and zebra, those two probabilities are independent of each", "tokens": [51192, 8482, 337, 26232, 4434, 11, 4868, 48593, 377, 11, 293, 47060, 11, 729, 732, 33783, 366, 6695, 295, 1184, 51704], "temperature": 0.0, "avg_logprob": -0.149509523955869, "compression_ratio": 1.5730337078651686, "no_speech_prob": 0.010797589085996151}, {"id": 202, "seek": 95436, "start": 954.36, "end": 959.96, "text": " other. It's not the case that those things are independent lions actually attack bigger animals", "tokens": [50364, 661, 13, 467, 311, 406, 264, 1389, 300, 729, 721, 366, 6695, 32564, 767, 2690, 3801, 4882, 50644], "temperature": 0.0, "avg_logprob": -0.1367634278309496, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0026648850180208683}, {"id": 203, "seek": 95436, "start": 959.96, "end": 967.64, "text": " than cheetahs. There's a huge independent hypothesis in this process which is not actually true.", "tokens": [50644, 813, 947, 47947, 82, 13, 821, 311, 257, 2603, 6695, 17291, 294, 341, 1399, 597, 307, 406, 767, 2074, 13, 51028], "temperature": 0.0, "avg_logprob": -0.1367634278309496, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0026648850180208683}, {"id": 204, "seek": 95436, "start": 967.64, "end": 973.08, "text": " The reason for this is that we don't know how to represent properly distributions over", "tokens": [51028, 440, 1778, 337, 341, 307, 300, 321, 500, 380, 458, 577, 281, 2906, 6108, 37870, 670, 51300], "temperature": 0.0, "avg_logprob": -0.1367634278309496, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0026648850180208683}, {"id": 205, "seek": 95436, "start": 973.08, "end": 979.08, "text": " combinatorial sequences of symbols, essentially, because the number grows exponentially with the", "tokens": [51300, 2512, 31927, 831, 22978, 295, 16944, 11, 4476, 11, 570, 264, 1230, 13156, 37330, 365, 264, 51600], "temperature": 0.0, "avg_logprob": -0.1367634278309496, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0026648850180208683}, {"id": 206, "seek": 97908, "start": 979.08, "end": 987.1600000000001, "text": " length of the symbols. We have to use tricks for this, but those techniques don't even deal with", "tokens": [50364, 4641, 295, 264, 16944, 13, 492, 362, 281, 764, 11733, 337, 341, 11, 457, 729, 7512, 500, 380, 754, 2028, 365, 50768], "temperature": 0.0, "avg_logprob": -0.13118544868800952, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.01740357279777527}, {"id": 207, "seek": 97908, "start": 987.1600000000001, "end": 994.84, "text": " it. The big question is, would there be some sort of abstract latent representation of text", "tokens": [50768, 309, 13, 440, 955, 1168, 307, 11, 576, 456, 312, 512, 1333, 295, 12649, 48994, 10290, 295, 2487, 51152], "temperature": 0.0, "avg_logprob": -0.13118544868800952, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.01740357279777527}, {"id": 208, "seek": 97908, "start": 995.48, "end": 1004.44, "text": " that would say that when I switch lion for cheetah, I also have to switch zebra for gazelle.", "tokens": [51184, 300, 576, 584, 300, 562, 286, 3679, 17226, 337, 947, 47947, 11, 286, 611, 362, 281, 3679, 47060, 337, 26232, 4434, 13, 51632], "temperature": 0.0, "avg_logprob": -0.13118544868800952, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.01740357279777527}, {"id": 209, "seek": 100444, "start": 1005.1600000000001, "end": 1011.0, "text": " Yeah, so this independence assumption, let me throw some criticism at you that I often hear", "tokens": [50400, 865, 11, 370, 341, 14640, 15302, 11, 718, 385, 3507, 512, 15835, 412, 291, 300, 286, 2049, 1568, 50692], "temperature": 0.0, "avg_logprob": -0.14893148137235093, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0185268372297287}, {"id": 210, "seek": 100444, "start": 1011.0, "end": 1016.5200000000001, "text": " and see how you respond. This kind of feeling in the blanks is just statistics. You're not", "tokens": [50692, 293, 536, 577, 291, 4196, 13, 639, 733, 295, 2633, 294, 264, 8247, 82, 307, 445, 12523, 13, 509, 434, 406, 50968], "temperature": 0.0, "avg_logprob": -0.14893148137235093, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0185268372297287}, {"id": 211, "seek": 100444, "start": 1016.5200000000001, "end": 1023.72, "text": " learning anything, like the deep underlying concepts. You're just mimicking stuff from", "tokens": [50968, 2539, 1340, 11, 411, 264, 2452, 14217, 10392, 13, 509, 434, 445, 12247, 10401, 1507, 490, 51328], "temperature": 0.0, "avg_logprob": -0.14893148137235093, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0185268372297287}, {"id": 212, "seek": 100444, "start": 1025.0, "end": 1030.44, "text": " the past. You're not learning anything new such that you can use it to generalize about the world.", "tokens": [51392, 264, 1791, 13, 509, 434, 406, 2539, 1340, 777, 1270, 300, 291, 393, 764, 309, 281, 2674, 1125, 466, 264, 1002, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14893148137235093, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0185268372297287}, {"id": 213, "seek": 103044, "start": 1031.4, "end": 1037.16, "text": " Okay, let me just say the crude version, which is just statistics. It's not intelligence.", "tokens": [50412, 1033, 11, 718, 385, 445, 584, 264, 30796, 3037, 11, 597, 307, 445, 12523, 13, 467, 311, 406, 7599, 13, 50700], "temperature": 0.0, "avg_logprob": -0.13456035354762402, "compression_ratio": 1.8212765957446808, "no_speech_prob": 0.008441727608442307}, {"id": 214, "seek": 103044, "start": 1038.2, "end": 1042.52, "text": " What do you have to say to that? What do you usually say to that if you hear this kind of thing?", "tokens": [50752, 708, 360, 291, 362, 281, 584, 281, 300, 30, 708, 360, 291, 2673, 584, 281, 300, 498, 291, 1568, 341, 733, 295, 551, 30, 50968], "temperature": 0.0, "avg_logprob": -0.13456035354762402, "compression_ratio": 1.8212765957446808, "no_speech_prob": 0.008441727608442307}, {"id": 215, "seek": 103044, "start": 1042.52, "end": 1045.64, "text": " I don't get into those discussions because they are kind of pointless.", "tokens": [50968, 286, 500, 380, 483, 666, 729, 11088, 570, 436, 366, 733, 295, 32824, 13, 51124], "temperature": 0.0, "avg_logprob": -0.13456035354762402, "compression_ratio": 1.8212765957446808, "no_speech_prob": 0.008441727608442307}, {"id": 216, "seek": 103044, "start": 1047.24, "end": 1050.76, "text": " First of all, it's quite possible that intelligence is just statistics. It's just", "tokens": [51204, 2386, 295, 439, 11, 309, 311, 1596, 1944, 300, 7599, 307, 445, 12523, 13, 467, 311, 445, 51380], "temperature": 0.0, "avg_logprob": -0.13456035354762402, "compression_ratio": 1.8212765957446808, "no_speech_prob": 0.008441727608442307}, {"id": 217, "seek": 103044, "start": 1050.76, "end": 1058.44, "text": " statistics of a particular kind. This is the philosophical question. Is it possible that", "tokens": [51380, 12523, 295, 257, 1729, 733, 13, 639, 307, 264, 25066, 1168, 13, 1119, 309, 1944, 300, 51764], "temperature": 0.0, "avg_logprob": -0.13456035354762402, "compression_ratio": 1.8212765957446808, "no_speech_prob": 0.008441727608442307}, {"id": 218, "seek": 105844, "start": 1058.44, "end": 1065.8, "text": " intelligence is just statistics? Yeah, but what kind of statistics? So if you're asking the question,", "tokens": [50364, 7599, 307, 445, 12523, 30, 865, 11, 457, 437, 733, 295, 12523, 30, 407, 498, 291, 434, 3365, 264, 1168, 11, 50732], "temperature": 0.0, "avg_logprob": -0.10829559285589989, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012057615676894784}, {"id": 219, "seek": 105844, "start": 1067.0800000000002, "end": 1072.52, "text": " are the models of the world that we learn, do they have some notion of causality? Yes.", "tokens": [50796, 366, 264, 5245, 295, 264, 1002, 300, 321, 1466, 11, 360, 436, 362, 512, 10710, 295, 3302, 1860, 30, 1079, 13, 51068], "temperature": 0.0, "avg_logprob": -0.10829559285589989, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012057615676894784}, {"id": 220, "seek": 105844, "start": 1073.3200000000002, "end": 1078.68, "text": " So if the criticism comes from people who say a current machine non-existent don't care about", "tokens": [51108, 407, 498, 264, 15835, 1487, 490, 561, 567, 584, 257, 2190, 3479, 2107, 12, 18217, 317, 500, 380, 1127, 466, 51376], "temperature": 0.0, "avg_logprob": -0.10829559285589989, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012057615676894784}, {"id": 221, "seek": 105844, "start": 1078.68, "end": 1085.64, "text": " causality, which by the way is wrong, I agree with that. Your model of the world should have", "tokens": [51376, 3302, 1860, 11, 597, 538, 264, 636, 307, 2085, 11, 286, 3986, 365, 300, 13, 2260, 2316, 295, 264, 1002, 820, 362, 51724], "temperature": 0.0, "avg_logprob": -0.10829559285589989, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012057615676894784}, {"id": 222, "seek": 108564, "start": 1085.72, "end": 1091.3200000000002, "text": " your actions as one of the inputs and that will drive you to learn causal models of the world", "tokens": [50368, 428, 5909, 382, 472, 295, 264, 15743, 293, 300, 486, 3332, 291, 281, 1466, 38755, 5245, 295, 264, 1002, 50648], "temperature": 0.0, "avg_logprob": -0.10274427990580715, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0027557401917874813}, {"id": 223, "seek": 108564, "start": 1091.3200000000002, "end": 1097.4, "text": " where you know what intervention in the world will cause, what results, or you can do this by", "tokens": [50648, 689, 291, 458, 437, 13176, 294, 264, 1002, 486, 3082, 11, 437, 3542, 11, 420, 291, 393, 360, 341, 538, 50952], "temperature": 0.0, "avg_logprob": -0.10274427990580715, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0027557401917874813}, {"id": 224, "seek": 108564, "start": 1097.4, "end": 1103.4, "text": " observation of other agents acting in the world and observing the effect of other humans, for", "tokens": [50952, 14816, 295, 661, 12554, 6577, 294, 264, 1002, 293, 22107, 264, 1802, 295, 661, 6255, 11, 337, 51252], "temperature": 0.0, "avg_logprob": -0.10274427990580715, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0027557401917874813}, {"id": 225, "seek": 108564, "start": 1103.4, "end": 1112.1200000000001, "text": " example. So I think at some level of description, intelligence is just statistics, but that doesn't", "tokens": [51252, 1365, 13, 407, 286, 519, 412, 512, 1496, 295, 3855, 11, 7599, 307, 445, 12523, 11, 457, 300, 1177, 380, 51688], "temperature": 0.0, "avg_logprob": -0.10274427990580715, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0027557401917874813}, {"id": 226, "seek": 111212, "start": 1112.12, "end": 1119.0, "text": " mean you won't have models that have deep mechanistic explanation for what goes on.", "tokens": [50364, 914, 291, 1582, 380, 362, 5245, 300, 362, 2452, 4236, 3142, 10835, 337, 437, 1709, 322, 13, 50708], "temperature": 0.0, "avg_logprob": -0.12510705548663473, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.004298568703234196}, {"id": 227, "seek": 111212, "start": 1119.8799999999999, "end": 1126.1999999999998, "text": " The question is how do you learn them? That's the question I'm interested in. Because a lot of people", "tokens": [50752, 440, 1168, 307, 577, 360, 291, 1466, 552, 30, 663, 311, 264, 1168, 286, 478, 3102, 294, 13, 1436, 257, 688, 295, 561, 51068], "temperature": 0.0, "avg_logprob": -0.12510705548663473, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.004298568703234196}, {"id": 228, "seek": 111212, "start": 1126.1999999999998, "end": 1131.8799999999999, "text": " who actually voice their criticism say that those mechanistic models have to come from", "tokens": [51068, 567, 767, 3177, 641, 15835, 584, 300, 729, 4236, 3142, 5245, 362, 281, 808, 490, 51352], "temperature": 0.0, "avg_logprob": -0.12510705548663473, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.004298568703234196}, {"id": 229, "seek": 111212, "start": 1131.8799999999999, "end": 1135.3999999999999, "text": " someplace else. They have to come from human designers. They have to come from, I don't know", "tokens": [51352, 37126, 1646, 13, 814, 362, 281, 808, 490, 1952, 16196, 13, 814, 362, 281, 808, 490, 11, 286, 500, 380, 458, 51528], "temperature": 0.0, "avg_logprob": -0.12510705548663473, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.004298568703234196}, {"id": 230, "seek": 113540, "start": 1135.4, "end": 1142.1200000000001, "text": " what, and obviously we learn them. Or if we don't learn them as an individual, nature", "tokens": [50364, 437, 11, 293, 2745, 321, 1466, 552, 13, 1610, 498, 321, 500, 380, 1466, 552, 382, 364, 2609, 11, 3687, 50700], "temperature": 0.0, "avg_logprob": -0.07941510460593483, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.010806522332131863}, {"id": 231, "seek": 113540, "start": 1143.0800000000002, "end": 1148.0400000000002, "text": " learned them for us using evolution. So regardless of what you think, those processes have been", "tokens": [50748, 3264, 552, 337, 505, 1228, 9303, 13, 407, 10060, 295, 437, 291, 519, 11, 729, 7555, 362, 668, 50996], "temperature": 0.0, "avg_logprob": -0.07941510460593483, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.010806522332131863}, {"id": 232, "seek": 113540, "start": 1148.0400000000002, "end": 1154.76, "text": " learned somehow. So if you look at the human brain, just like when we humans introspect about", "tokens": [50996, 3264, 6063, 13, 407, 498, 291, 574, 412, 264, 1952, 3567, 11, 445, 411, 562, 321, 6255, 560, 28713, 466, 51332], "temperature": 0.0, "avg_logprob": -0.07941510460593483, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.010806522332131863}, {"id": 233, "seek": 113540, "start": 1154.76, "end": 1161.48, "text": " how the brain works, it seems like when we think about what is intelligence, we think about the", "tokens": [51332, 577, 264, 3567, 1985, 11, 309, 2544, 411, 562, 321, 519, 466, 437, 307, 7599, 11, 321, 519, 466, 264, 51668], "temperature": 0.0, "avg_logprob": -0.07941510460593483, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.010806522332131863}, {"id": 234, "seek": 116148, "start": 1161.48, "end": 1166.28, "text": " high level stuff, like the models we've constructed, concepts like cognitive science, like concepts of", "tokens": [50364, 1090, 1496, 1507, 11, 411, 264, 5245, 321, 600, 17083, 11, 10392, 411, 15605, 3497, 11, 411, 10392, 295, 50604], "temperature": 0.0, "avg_logprob": -0.16540378873998468, "compression_ratio": 1.722466960352423, "no_speech_prob": 0.01064765639603138}, {"id": 235, "seek": 116148, "start": 1166.28, "end": 1173.88, "text": " memory and reasoning module, almost like these high level modules. Is this serve as a good analogy?", "tokens": [50604, 4675, 293, 21577, 10088, 11, 1920, 411, 613, 1090, 1496, 16679, 13, 1119, 341, 4596, 382, 257, 665, 21663, 30, 50984], "temperature": 0.0, "avg_logprob": -0.16540378873998468, "compression_ratio": 1.722466960352423, "no_speech_prob": 0.01064765639603138}, {"id": 236, "seek": 116148, "start": 1175.32, "end": 1184.52, "text": " Like, are we ignoring the dark matter, the basic low level mechanisms, just like we ignore the way", "tokens": [51056, 1743, 11, 366, 321, 26258, 264, 2877, 1871, 11, 264, 3875, 2295, 1496, 15902, 11, 445, 411, 321, 11200, 264, 636, 51516], "temperature": 0.0, "avg_logprob": -0.16540378873998468, "compression_ratio": 1.722466960352423, "no_speech_prob": 0.01064765639603138}, {"id": 237, "seek": 116148, "start": 1184.52, "end": 1190.44, "text": " the operating system works, we're just using the high level software. We're ignoring that", "tokens": [51516, 264, 7447, 1185, 1985, 11, 321, 434, 445, 1228, 264, 1090, 1496, 4722, 13, 492, 434, 26258, 300, 51812], "temperature": 0.0, "avg_logprob": -0.16540378873998468, "compression_ratio": 1.722466960352423, "no_speech_prob": 0.01064765639603138}, {"id": 238, "seek": 119044, "start": 1191.16, "end": 1196.92, "text": " at the low level, the neural network might be doing something like statistics. Like,", "tokens": [50400, 412, 264, 2295, 1496, 11, 264, 18161, 3209, 1062, 312, 884, 746, 411, 12523, 13, 1743, 11, 50688], "temperature": 0.0, "avg_logprob": -0.11364051645452326, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.001169033464975655}, {"id": 239, "seek": 119044, "start": 1196.92, "end": 1201.64, "text": " meaning, sorry to use this word, probably incorrectly and crudely, but doing this kind", "tokens": [50688, 3620, 11, 2597, 281, 764, 341, 1349, 11, 1391, 42892, 293, 941, 532, 736, 11, 457, 884, 341, 733, 50924], "temperature": 0.0, "avg_logprob": -0.11364051645452326, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.001169033464975655}, {"id": 240, "seek": 119044, "start": 1201.64, "end": 1206.28, "text": " of fill in the gap kind of learning and just kind of updating the model constantly in order to be", "tokens": [50924, 295, 2836, 294, 264, 7417, 733, 295, 2539, 293, 445, 733, 295, 25113, 264, 2316, 6460, 294, 1668, 281, 312, 51156], "temperature": 0.0, "avg_logprob": -0.11364051645452326, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.001169033464975655}, {"id": 241, "seek": 119044, "start": 1206.28, "end": 1211.48, "text": " able to support the raw sensory information, to predict it and then adjust to the prediction when", "tokens": [51156, 1075, 281, 1406, 264, 8936, 27233, 1589, 11, 281, 6069, 309, 293, 550, 4369, 281, 264, 17630, 562, 51416], "temperature": 0.0, "avg_logprob": -0.11364051645452326, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.001169033464975655}, {"id": 242, "seek": 119044, "start": 1211.48, "end": 1217.16, "text": " it's wrong. But like when we look at our brain at the high level, it feels like we're doing,", "tokens": [51416, 309, 311, 2085, 13, 583, 411, 562, 321, 574, 412, 527, 3567, 412, 264, 1090, 1496, 11, 309, 3417, 411, 321, 434, 884, 11, 51700], "temperature": 0.0, "avg_logprob": -0.11364051645452326, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.001169033464975655}, {"id": 243, "seek": 121716, "start": 1217.16, "end": 1222.44, "text": " like we're playing chess, like we're, we're like playing with high level concepts and we're", "tokens": [50364, 411, 321, 434, 2433, 24122, 11, 411, 321, 434, 11, 321, 434, 411, 2433, 365, 1090, 1496, 10392, 293, 321, 434, 50628], "temperature": 0.0, "avg_logprob": -0.12312840578848855, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.003944207914173603}, {"id": 244, "seek": 121716, "start": 1222.44, "end": 1227.16, "text": " stitching them together and we're putting them into long term memory. But really what's going", "tokens": [50628, 30714, 552, 1214, 293, 321, 434, 3372, 552, 666, 938, 1433, 4675, 13, 583, 534, 437, 311, 516, 50864], "temperature": 0.0, "avg_logprob": -0.12312840578848855, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.003944207914173603}, {"id": 245, "seek": 121716, "start": 1227.16, "end": 1233.64, "text": " underneath is something we're not able to introspect, which is this kind of simple large", "tokens": [50864, 7223, 307, 746, 321, 434, 406, 1075, 281, 560, 28713, 11, 597, 307, 341, 733, 295, 2199, 2416, 51188], "temperature": 0.0, "avg_logprob": -0.12312840578848855, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.003944207914173603}, {"id": 246, "seek": 121716, "start": 1233.64, "end": 1238.1200000000001, "text": " neural network that's just filling in the gaps. Right. Well, okay, so there's a lot of questions", "tokens": [51188, 18161, 3209, 300, 311, 445, 10623, 294, 264, 15031, 13, 1779, 13, 1042, 11, 1392, 11, 370, 456, 311, 257, 688, 295, 1651, 51412], "temperature": 0.0, "avg_logprob": -0.12312840578848855, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.003944207914173603}, {"id": 247, "seek": 121716, "start": 1238.1200000000001, "end": 1242.6000000000001, "text": " that are answers there. Okay, so first of all, there's a whole school of thought in neuroscience,", "tokens": [51412, 300, 366, 6338, 456, 13, 1033, 11, 370, 700, 295, 439, 11, 456, 311, 257, 1379, 1395, 295, 1194, 294, 42762, 11, 51636], "temperature": 0.0, "avg_logprob": -0.12312840578848855, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.003944207914173603}, {"id": 248, "seek": 124260, "start": 1242.6, "end": 1247.7199999999998, "text": " competition on neuroscience in particular, that likes the idea of predictive coding,", "tokens": [50364, 6211, 322, 42762, 294, 1729, 11, 300, 5902, 264, 1558, 295, 35521, 17720, 11, 50620], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 249, "seek": 124260, "start": 1247.7199999999998, "end": 1252.1999999999998, "text": " which is really related to the idea I was talking about in self supervised running. So", "tokens": [50620, 597, 307, 534, 4077, 281, 264, 1558, 286, 390, 1417, 466, 294, 2698, 46533, 2614, 13, 407, 50844], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 250, "seek": 124260, "start": 1252.1999999999998, "end": 1255.6399999999999, "text": " everything is about prediction. The essence of intelligence is the ability to predict.", "tokens": [50844, 1203, 307, 466, 17630, 13, 440, 12801, 295, 7599, 307, 264, 3485, 281, 6069, 13, 51016], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 251, "seek": 124260, "start": 1256.28, "end": 1261.24, "text": " And everything the brain does is trying to predict, predict everything from everything", "tokens": [51048, 400, 1203, 264, 3567, 775, 307, 1382, 281, 6069, 11, 6069, 1203, 490, 1203, 51296], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 252, "seek": 124260, "start": 1261.24, "end": 1265.3999999999999, "text": " else. Okay, and that's really sort of the underlying principle if you want that", "tokens": [51296, 1646, 13, 1033, 11, 293, 300, 311, 534, 1333, 295, 264, 14217, 8665, 498, 291, 528, 300, 51504], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 253, "seek": 124260, "start": 1266.9199999999998, "end": 1271.08, "text": " self supervised learning is trying to kind of reproduce this idea of prediction as kind of an", "tokens": [51580, 2698, 46533, 2539, 307, 1382, 281, 733, 295, 29501, 341, 1558, 295, 17630, 382, 733, 295, 364, 51788], "temperature": 0.0, "avg_logprob": -0.12279456633108633, "compression_ratio": 1.8804347826086956, "no_speech_prob": 0.006676551420241594}, {"id": 254, "seek": 127108, "start": 1271.08, "end": 1278.76, "text": " essential mechanism of task independent learning if you want. The next step is what kind of", "tokens": [50364, 7115, 7513, 295, 5633, 6695, 2539, 498, 291, 528, 13, 440, 958, 1823, 307, 437, 733, 295, 50748], "temperature": 0.0, "avg_logprob": -0.10516308321811185, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.0003147981478832662}, {"id": 255, "seek": 127108, "start": 1278.76, "end": 1283.3999999999999, "text": " intelligence are you interested in reproducing? And of course, you know, we all think about,", "tokens": [50748, 7599, 366, 291, 3102, 294, 11408, 2175, 30, 400, 295, 1164, 11, 291, 458, 11, 321, 439, 519, 466, 11, 50980], "temperature": 0.0, "avg_logprob": -0.10516308321811185, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.0003147981478832662}, {"id": 256, "seek": 127108, "start": 1283.3999999999999, "end": 1288.28, "text": " you know, trying to reproduce sort of, you know, high level cognitive processes in humans.", "tokens": [50980, 291, 458, 11, 1382, 281, 29501, 1333, 295, 11, 291, 458, 11, 1090, 1496, 15605, 7555, 294, 6255, 13, 51224], "temperature": 0.0, "avg_logprob": -0.10516308321811185, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.0003147981478832662}, {"id": 257, "seek": 127108, "start": 1288.28, "end": 1292.52, "text": " But like with machines, we're not even at the level of even reproducing the", "tokens": [51224, 583, 411, 365, 8379, 11, 321, 434, 406, 754, 412, 264, 1496, 295, 754, 11408, 2175, 264, 51436], "temperature": 0.0, "avg_logprob": -0.10516308321811185, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.0003147981478832662}, {"id": 258, "seek": 127108, "start": 1293.24, "end": 1299.0, "text": " running processes in a cat brain. You know, the most intelligent or intelligent systems", "tokens": [51472, 2614, 7555, 294, 257, 3857, 3567, 13, 509, 458, 11, 264, 881, 13232, 420, 13232, 3652, 51760], "temperature": 0.0, "avg_logprob": -0.10516308321811185, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.0003147981478832662}, {"id": 259, "seek": 129900, "start": 1299.32, "end": 1305.64, "text": " don't have as much common sense as a house cat. So how is it that cats learn? And, you know,", "tokens": [50380, 500, 380, 362, 382, 709, 2689, 2020, 382, 257, 1782, 3857, 13, 407, 577, 307, 309, 300, 11111, 1466, 30, 400, 11, 291, 458, 11, 50696], "temperature": 0.0, "avg_logprob": -0.11916522979736328, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0009677440975792706}, {"id": 260, "seek": 129900, "start": 1305.64, "end": 1310.28, "text": " cats don't do a whole lot of reasoning. They certainly have causal models. They certainly have,", "tokens": [50696, 11111, 500, 380, 360, 257, 1379, 688, 295, 21577, 13, 814, 3297, 362, 38755, 5245, 13, 814, 3297, 362, 11, 50928], "temperature": 0.0, "avg_logprob": -0.11916522979736328, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0009677440975792706}, {"id": 261, "seek": 129900, "start": 1311.48, "end": 1315.4, "text": " because, you know, many cats can figure out like how they can act on the world to get what they want.", "tokens": [50988, 570, 11, 291, 458, 11, 867, 11111, 393, 2573, 484, 411, 577, 436, 393, 605, 322, 264, 1002, 281, 483, 437, 436, 528, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11916522979736328, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0009677440975792706}, {"id": 262, "seek": 129900, "start": 1316.52, "end": 1324.12, "text": " They certainly have a fantastic model of intuitive physics, certainly the dynamics of their own", "tokens": [51240, 814, 3297, 362, 257, 5456, 2316, 295, 21769, 10649, 11, 3297, 264, 15679, 295, 641, 1065, 51620], "temperature": 0.0, "avg_logprob": -0.11916522979736328, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.0009677440975792706}, {"id": 263, "seek": 132412, "start": 1324.12, "end": 1330.52, "text": " bodies, but also praise and things like that. Right. So they're pretty smart. They only do", "tokens": [50364, 7510, 11, 457, 611, 13286, 293, 721, 411, 300, 13, 1779, 13, 407, 436, 434, 1238, 4069, 13, 814, 787, 360, 50684], "temperature": 0.0, "avg_logprob": -0.10473097695244683, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.005892683286219835}, {"id": 264, "seek": 132412, "start": 1330.52, "end": 1337.8799999999999, "text": " this with about 800 million neurons. We are not anywhere close to reproducing this kind of thing.", "tokens": [50684, 341, 365, 466, 13083, 2459, 22027, 13, 492, 366, 406, 4992, 1998, 281, 11408, 2175, 341, 733, 295, 551, 13, 51052], "temperature": 0.0, "avg_logprob": -0.10473097695244683, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.005892683286219835}, {"id": 265, "seek": 132412, "start": 1337.8799999999999, "end": 1344.6, "text": " So to some extent, I could say, let's not even worry about like the high level cognition", "tokens": [51052, 407, 281, 512, 8396, 11, 286, 727, 584, 11, 718, 311, 406, 754, 3292, 466, 411, 264, 1090, 1496, 46905, 51388], "temperature": 0.0, "avg_logprob": -0.10473097695244683, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.005892683286219835}, {"id": 266, "seek": 132412, "start": 1346.1999999999998, "end": 1349.3999999999999, "text": " and kind of, you know, long term planning and reasoning that humans can do until we figure", "tokens": [51468, 293, 733, 295, 11, 291, 458, 11, 938, 1433, 5038, 293, 21577, 300, 6255, 393, 360, 1826, 321, 2573, 51628], "temperature": 0.0, "avg_logprob": -0.10473097695244683, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.005892683286219835}, {"id": 267, "seek": 134940, "start": 1349.4, "end": 1354.76, "text": " out like, you know, can we even reproduce what cats are doing? Now that said, this ability to", "tokens": [50364, 484, 411, 11, 291, 458, 11, 393, 321, 754, 29501, 437, 11111, 366, 884, 30, 823, 300, 848, 11, 341, 3485, 281, 50632], "temperature": 0.0, "avg_logprob": -0.09468321042640188, "compression_ratio": 1.83203125, "no_speech_prob": 0.0017801595386117697}, {"id": 268, "seek": 134940, "start": 1355.64, "end": 1362.0400000000002, "text": " learn world models, I think is the key to the possibility of running machines that can also", "tokens": [50676, 1466, 1002, 5245, 11, 286, 519, 307, 264, 2141, 281, 264, 7959, 295, 2614, 8379, 300, 393, 611, 50996], "temperature": 0.0, "avg_logprob": -0.09468321042640188, "compression_ratio": 1.83203125, "no_speech_prob": 0.0017801595386117697}, {"id": 269, "seek": 134940, "start": 1362.0400000000002, "end": 1366.68, "text": " reason. So whenever I give a talk, I say there are three challenges in the three main challenges", "tokens": [50996, 1778, 13, 407, 5699, 286, 976, 257, 751, 11, 286, 584, 456, 366, 1045, 4759, 294, 264, 1045, 2135, 4759, 51228], "temperature": 0.0, "avg_logprob": -0.09468321042640188, "compression_ratio": 1.83203125, "no_speech_prob": 0.0017801595386117697}, {"id": 270, "seek": 134940, "start": 1366.68, "end": 1370.76, "text": " in machine learning. The first one is, you know, getting machines to learn to represent the world", "tokens": [51228, 294, 3479, 2539, 13, 440, 700, 472, 307, 11, 291, 458, 11, 1242, 8379, 281, 1466, 281, 2906, 264, 1002, 51432], "temperature": 0.0, "avg_logprob": -0.09468321042640188, "compression_ratio": 1.83203125, "no_speech_prob": 0.0017801595386117697}, {"id": 271, "seek": 134940, "start": 1371.72, "end": 1378.2800000000002, "text": " and proposing self supervised learning. The second is getting machines to reason in ways", "tokens": [51480, 293, 29939, 2698, 46533, 2539, 13, 440, 1150, 307, 1242, 8379, 281, 1778, 294, 2098, 51808], "temperature": 0.0, "avg_logprob": -0.09468321042640188, "compression_ratio": 1.83203125, "no_speech_prob": 0.0017801595386117697}, {"id": 272, "seek": 137828, "start": 1378.28, "end": 1382.76, "text": " that are compatible with essentially gradient based learning because this is what deep learning is", "tokens": [50364, 300, 366, 18218, 365, 4476, 16235, 2361, 2539, 570, 341, 307, 437, 2452, 2539, 307, 50588], "temperature": 0.0, "avg_logprob": -0.11402102497136482, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0032184512820094824}, {"id": 273, "seek": 137828, "start": 1382.76, "end": 1388.2, "text": " all about really. And the third one is something we have no idea how to solve. At least I have no", "tokens": [50588, 439, 466, 534, 13, 400, 264, 2636, 472, 307, 746, 321, 362, 572, 1558, 577, 281, 5039, 13, 1711, 1935, 286, 362, 572, 50860], "temperature": 0.0, "avg_logprob": -0.11402102497136482, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0032184512820094824}, {"id": 274, "seek": 137828, "start": 1388.2, "end": 1395.6399999999999, "text": " idea how to solve is can we get machines to learn hierarchical representations of action plans?", "tokens": [50860, 1558, 577, 281, 5039, 307, 393, 321, 483, 8379, 281, 1466, 35250, 804, 33358, 295, 3069, 5482, 30, 51232], "temperature": 0.0, "avg_logprob": -0.11402102497136482, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0032184512820094824}, {"id": 275, "seek": 137828, "start": 1396.92, "end": 1400.28, "text": " You know, like, you know, we know how to train them to learn hierarchical representations of", "tokens": [51296, 509, 458, 11, 411, 11, 291, 458, 11, 321, 458, 577, 281, 3847, 552, 281, 1466, 35250, 804, 33358, 295, 51464], "temperature": 0.0, "avg_logprob": -0.11402102497136482, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0032184512820094824}, {"id": 276, "seek": 137828, "start": 1400.28, "end": 1405.16, "text": " perception, you know, with convolutional nets and things like that and transformers. But what", "tokens": [51464, 12860, 11, 291, 458, 11, 365, 45216, 304, 36170, 293, 721, 411, 300, 293, 4088, 433, 13, 583, 437, 51708], "temperature": 0.0, "avg_logprob": -0.11402102497136482, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0032184512820094824}, {"id": 277, "seek": 140516, "start": 1405.16, "end": 1409.96, "text": " about action plans? Can we get them to spontaneously learn good hierarchical representations of", "tokens": [50364, 466, 3069, 5482, 30, 1664, 321, 483, 552, 281, 47632, 1466, 665, 35250, 804, 33358, 295, 50604], "temperature": 0.0, "avg_logprob": -0.0947754067110728, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0003052378015127033}, {"id": 278, "seek": 140516, "start": 1409.96, "end": 1415.8000000000002, "text": " actions also gradient based? Yeah, all of that, you know, needs to be somewhat differentiable", "tokens": [50604, 5909, 611, 16235, 2361, 30, 865, 11, 439, 295, 300, 11, 291, 458, 11, 2203, 281, 312, 8344, 819, 9364, 50896], "temperature": 0.0, "avg_logprob": -0.0947754067110728, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0003052378015127033}, {"id": 279, "seek": 140516, "start": 1415.8000000000002, "end": 1419.88, "text": " so that you can apply sort of gradient based learning, which is really what deep learning is", "tokens": [50896, 370, 300, 291, 393, 3079, 1333, 295, 16235, 2361, 2539, 11, 597, 307, 534, 437, 2452, 2539, 307, 51100], "temperature": 0.0, "avg_logprob": -0.0947754067110728, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0003052378015127033}, {"id": 280, "seek": 140516, "start": 1419.88, "end": 1430.68, "text": " about. So it's background knowledge, ability to reason in a way that's differentiable that", "tokens": [51100, 466, 13, 407, 309, 311, 3678, 3601, 11, 3485, 281, 1778, 294, 257, 636, 300, 311, 819, 9364, 300, 51640], "temperature": 0.0, "avg_logprob": -0.0947754067110728, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0003052378015127033}, {"id": 281, "seek": 143068, "start": 1431.64, "end": 1436.2, "text": " is somehow connected deeply integrated with that background knowledge or builds on top of", "tokens": [50412, 307, 6063, 4582, 8760, 10919, 365, 300, 3678, 3601, 420, 15182, 322, 1192, 295, 50640], "temperature": 0.0, "avg_logprob": -0.14882624269735933, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.0022512946743518114}, {"id": 282, "seek": 143068, "start": 1436.2, "end": 1440.3600000000001, "text": " that background knowledge. And then giving that background knowledge be able to make hierarchical", "tokens": [50640, 300, 3678, 3601, 13, 400, 550, 2902, 300, 3678, 3601, 312, 1075, 281, 652, 35250, 804, 50848], "temperature": 0.0, "avg_logprob": -0.14882624269735933, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.0022512946743518114}, {"id": 283, "seek": 143068, "start": 1440.3600000000001, "end": 1445.8, "text": " plans right in the world. So if you take classical optimal control, there's something", "tokens": [50848, 5482, 558, 294, 264, 1002, 13, 407, 498, 291, 747, 13735, 16252, 1969, 11, 456, 311, 746, 51120], "temperature": 0.0, "avg_logprob": -0.14882624269735933, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.0022512946743518114}, {"id": 284, "seek": 143068, "start": 1445.8, "end": 1451.5600000000002, "text": " classical optimal control called model predictive control. And it's, you know, it's been around", "tokens": [51120, 13735, 16252, 1969, 1219, 2316, 35521, 1969, 13, 400, 309, 311, 11, 291, 458, 11, 309, 311, 668, 926, 51408], "temperature": 0.0, "avg_logprob": -0.14882624269735933, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.0022512946743518114}, {"id": 285, "seek": 143068, "start": 1451.5600000000002, "end": 1457.5600000000002, "text": " since the early 60s. NASA uses that to compute trajectories of rockets. And the basic idea is", "tokens": [51408, 1670, 264, 2440, 4060, 82, 13, 12077, 4960, 300, 281, 14722, 18257, 2083, 295, 28361, 13, 400, 264, 3875, 1558, 307, 51708], "temperature": 0.0, "avg_logprob": -0.14882624269735933, "compression_ratio": 1.801556420233463, "no_speech_prob": 0.0022512946743518114}, {"id": 286, "seek": 145756, "start": 1457.6399999999999, "end": 1463.8, "text": " that you have a predictive model of the rocket, let's say, or whatever system you are, you intend", "tokens": [50368, 300, 291, 362, 257, 35521, 2316, 295, 264, 13012, 11, 718, 311, 584, 11, 420, 2035, 1185, 291, 366, 11, 291, 19759, 50676], "temperature": 0.0, "avg_logprob": -0.1261506326419791, "compression_ratio": 1.7824074074074074, "no_speech_prob": 0.0037055539432913065}, {"id": 287, "seek": 145756, "start": 1463.8, "end": 1470.84, "text": " to control, which given the state of the system at time t and given an action that you're taking", "tokens": [50676, 281, 1969, 11, 597, 2212, 264, 1785, 295, 264, 1185, 412, 565, 256, 293, 2212, 364, 3069, 300, 291, 434, 1940, 51028], "temperature": 0.0, "avg_logprob": -0.1261506326419791, "compression_ratio": 1.7824074074074074, "no_speech_prob": 0.0037055539432913065}, {"id": 288, "seek": 145756, "start": 1470.84, "end": 1476.84, "text": " the system. So for a rocket to be thrust and, you know, all the controls you can have, it gives", "tokens": [51028, 264, 1185, 13, 407, 337, 257, 13012, 281, 312, 24030, 293, 11, 291, 458, 11, 439, 264, 9003, 291, 393, 362, 11, 309, 2709, 51328], "temperature": 0.0, "avg_logprob": -0.1261506326419791, "compression_ratio": 1.7824074074074074, "no_speech_prob": 0.0037055539432913065}, {"id": 289, "seek": 145756, "start": 1476.84, "end": 1480.84, "text": " you the state of the system at time t plus delta t, right? So basically differential equation,", "tokens": [51328, 291, 264, 1785, 295, 264, 1185, 412, 565, 256, 1804, 8289, 256, 11, 558, 30, 407, 1936, 15756, 5367, 11, 51528], "temperature": 0.0, "avg_logprob": -0.1261506326419791, "compression_ratio": 1.7824074074074074, "no_speech_prob": 0.0037055539432913065}, {"id": 290, "seek": 148084, "start": 1480.9199999999998, "end": 1488.36, "text": " something like that. And if you have this model, and you have this model in the form of some sort", "tokens": [50368, 746, 411, 300, 13, 400, 498, 291, 362, 341, 2316, 11, 293, 291, 362, 341, 2316, 294, 264, 1254, 295, 512, 1333, 50740], "temperature": 0.0, "avg_logprob": -0.12184943574847597, "compression_ratio": 1.7974683544303798, "no_speech_prob": 0.004262991715222597}, {"id": 291, "seek": 148084, "start": 1488.36, "end": 1493.48, "text": " of neural net, or some sort of set of formula that you can back propagate gradient through,", "tokens": [50740, 295, 18161, 2533, 11, 420, 512, 1333, 295, 992, 295, 8513, 300, 291, 393, 646, 48256, 16235, 807, 11, 50996], "temperature": 0.0, "avg_logprob": -0.12184943574847597, "compression_ratio": 1.7974683544303798, "no_speech_prob": 0.004262991715222597}, {"id": 292, "seek": 148084, "start": 1493.48, "end": 1498.28, "text": " you can do what's called model predictive control, or gradient based model predictive control.", "tokens": [50996, 291, 393, 360, 437, 311, 1219, 2316, 35521, 1969, 11, 420, 16235, 2361, 2316, 35521, 1969, 13, 51236], "temperature": 0.0, "avg_logprob": -0.12184943574847597, "compression_ratio": 1.7974683544303798, "no_speech_prob": 0.004262991715222597}, {"id": 293, "seek": 149828, "start": 1498.28, "end": 1509.8799999999999, "text": " So you have, you can enroll that model in time, you feel it a hypothesized sequence of actions.", "tokens": [50364, 407, 291, 362, 11, 291, 393, 12266, 300, 2316, 294, 565, 11, 291, 841, 309, 257, 14276, 1602, 8310, 295, 5909, 13, 50944], "temperature": 0.0, "avg_logprob": -0.15790497263272604, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.0008688662201166153}, {"id": 294, "seek": 149828, "start": 1511.0, "end": 1515.96, "text": " And then you have some objective function that measures how well at the end of the trajectory", "tokens": [51000, 400, 550, 291, 362, 512, 10024, 2445, 300, 8000, 577, 731, 412, 264, 917, 295, 264, 21512, 51248], "temperature": 0.0, "avg_logprob": -0.15790497263272604, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.0008688662201166153}, {"id": 295, "seek": 149828, "start": 1515.96, "end": 1520.92, "text": " of the system has succeeded or matched what you wanted to do. You know, is it a robot harm,", "tokens": [51248, 295, 264, 1185, 575, 20263, 420, 21447, 437, 291, 1415, 281, 360, 13, 509, 458, 11, 307, 309, 257, 7881, 6491, 11, 51496], "temperature": 0.0, "avg_logprob": -0.15790497263272604, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.0008688662201166153}, {"id": 296, "seek": 149828, "start": 1520.92, "end": 1525.96, "text": " as if you grasp the object you want to grasp, if it's a rocket, you know, are you at the right", "tokens": [51496, 382, 498, 291, 21743, 264, 2657, 291, 528, 281, 21743, 11, 498, 309, 311, 257, 13012, 11, 291, 458, 11, 366, 291, 412, 264, 558, 51748], "temperature": 0.0, "avg_logprob": -0.15790497263272604, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.0008688662201166153}, {"id": 297, "seek": 152596, "start": 1525.96, "end": 1531.08, "text": " place near the space station, things like that. And by back propagation through time, and again,", "tokens": [50364, 1081, 2651, 264, 1901, 5214, 11, 721, 411, 300, 13, 400, 538, 646, 38377, 807, 565, 11, 293, 797, 11, 50620], "temperature": 0.0, "avg_logprob": -0.10403247546124202, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0016197747318074107}, {"id": 298, "seek": 152596, "start": 1531.08, "end": 1537.96, "text": " this was invented in the 1960s by optimal control theorists, you can figure out what is the optimal", "tokens": [50620, 341, 390, 14479, 294, 264, 16157, 82, 538, 16252, 1969, 27423, 1751, 11, 291, 393, 2573, 484, 437, 307, 264, 16252, 50964], "temperature": 0.0, "avg_logprob": -0.10403247546124202, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0016197747318074107}, {"id": 299, "seek": 152596, "start": 1537.96, "end": 1546.92, "text": " sequence of actions that will, you know, get my system to the best final state. So that's a form", "tokens": [50964, 8310, 295, 5909, 300, 486, 11, 291, 458, 11, 483, 452, 1185, 281, 264, 1151, 2572, 1785, 13, 407, 300, 311, 257, 1254, 51412], "temperature": 0.0, "avg_logprob": -0.10403247546124202, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0016197747318074107}, {"id": 300, "seek": 152596, "start": 1546.92, "end": 1551.56, "text": " of reasoning. It's basically planning. And a lot of planning systems in robotics are actually based", "tokens": [51412, 295, 21577, 13, 467, 311, 1936, 5038, 13, 400, 257, 688, 295, 5038, 3652, 294, 34145, 366, 767, 2361, 51644], "temperature": 0.0, "avg_logprob": -0.10403247546124202, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0016197747318074107}, {"id": 301, "seek": 155156, "start": 1551.56, "end": 1558.52, "text": " on this. And, and you can think of this as a form of reasoning. So, you know, to take the example", "tokens": [50364, 322, 341, 13, 400, 11, 293, 291, 393, 519, 295, 341, 382, 257, 1254, 295, 21577, 13, 407, 11, 291, 458, 11, 281, 747, 264, 1365, 50712], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 302, "seek": 155156, "start": 1558.52, "end": 1563.08, "text": " of the teenager driving a car again, you have a pretty good dynamical model of the car, it doesn't", "tokens": [50712, 295, 264, 21440, 4840, 257, 1032, 797, 11, 291, 362, 257, 1238, 665, 5999, 804, 2316, 295, 264, 1032, 11, 309, 1177, 380, 50940], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 303, "seek": 155156, "start": 1563.08, "end": 1567.56, "text": " need to be very accurate. But you know, again, that if you turn the wheel to the right, and there", "tokens": [50940, 643, 281, 312, 588, 8559, 13, 583, 291, 458, 11, 797, 11, 300, 498, 291, 1261, 264, 5589, 281, 264, 558, 11, 293, 456, 51164], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 304, "seek": 155156, "start": 1567.56, "end": 1570.52, "text": " is a cliff, you're going to run off the cliff, right, you don't need to have a very accurate", "tokens": [51164, 307, 257, 22316, 11, 291, 434, 516, 281, 1190, 766, 264, 22316, 11, 558, 11, 291, 500, 380, 643, 281, 362, 257, 588, 8559, 51312], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 305, "seek": 155156, "start": 1570.52, "end": 1575.3999999999999, "text": " model to predict that. And you can run this in your mind, and decide not to do it for that reason.", "tokens": [51312, 2316, 281, 6069, 300, 13, 400, 291, 393, 1190, 341, 294, 428, 1575, 11, 293, 4536, 406, 281, 360, 309, 337, 300, 1778, 13, 51556], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 306, "seek": 155156, "start": 1575.96, "end": 1579.24, "text": " Because you can predict in advance that the result is going to be bad. So you can sort of", "tokens": [51584, 1436, 291, 393, 6069, 294, 7295, 300, 264, 1874, 307, 516, 281, 312, 1578, 13, 407, 291, 393, 1333, 295, 51748], "temperature": 0.0, "avg_logprob": -0.05506856364588584, "compression_ratio": 1.9264214046822743, "no_speech_prob": 0.0044662365689873695}, {"id": 307, "seek": 157924, "start": 1579.24, "end": 1585.16, "text": " imagine different scenarios, and, and then, you know, employ, or take the first step in the scenario", "tokens": [50364, 3811, 819, 15077, 11, 293, 11, 293, 550, 11, 291, 458, 11, 3188, 11, 420, 747, 264, 700, 1823, 294, 264, 9005, 50660], "temperature": 0.0, "avg_logprob": -0.13314671801705646, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.001924930838868022}, {"id": 308, "seek": 157924, "start": 1585.16, "end": 1589.16, "text": " that is most favorable, and then repeat the process of planning that's called receding horizon", "tokens": [50660, 300, 307, 881, 29557, 11, 293, 550, 7149, 264, 1399, 295, 5038, 300, 311, 1219, 850, 9794, 18046, 50860], "temperature": 0.0, "avg_logprob": -0.13314671801705646, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.001924930838868022}, {"id": 309, "seek": 157924, "start": 1589.16, "end": 1593.64, "text": " model predictive control. So even, you know, all those things have names, you know, going back,", "tokens": [50860, 2316, 35521, 1969, 13, 407, 754, 11, 291, 458, 11, 439, 729, 721, 362, 5288, 11, 291, 458, 11, 516, 646, 11, 51084], "temperature": 0.0, "avg_logprob": -0.13314671801705646, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.001924930838868022}, {"id": 310, "seek": 157924, "start": 1593.64, "end": 1599.88, "text": " you know, decades. And so, if you're not not the, you know, in classical optimal control,", "tokens": [51084, 291, 458, 11, 7878, 13, 400, 370, 11, 498, 291, 434, 406, 406, 264, 11, 291, 458, 11, 294, 13735, 16252, 1969, 11, 51396], "temperature": 0.0, "avg_logprob": -0.13314671801705646, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.001924930838868022}, {"id": 311, "seek": 157924, "start": 1599.88, "end": 1604.84, "text": " the model of the world is not generally learned. This, you know, sometimes a few parameters you", "tokens": [51396, 264, 2316, 295, 264, 1002, 307, 406, 5101, 3264, 13, 639, 11, 291, 458, 11, 2171, 257, 1326, 9834, 291, 51644], "temperature": 0.0, "avg_logprob": -0.13314671801705646, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.001924930838868022}, {"id": 312, "seek": 160484, "start": 1604.84, "end": 1610.12, "text": " have to identify that's called systems identification. But, but generally, the model is", "tokens": [50364, 362, 281, 5876, 300, 311, 1219, 3652, 22065, 13, 583, 11, 457, 5101, 11, 264, 2316, 307, 50628], "temperature": 0.0, "avg_logprob": -0.11529925891331264, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.002840088913217187}, {"id": 313, "seek": 160484, "start": 1610.9199999999998, "end": 1616.76, "text": " mostly deterministic and mostly built by hand. So the big question of AI, I think the big challenge", "tokens": [50668, 5240, 15957, 3142, 293, 5240, 3094, 538, 1011, 13, 407, 264, 955, 1168, 295, 7318, 11, 286, 519, 264, 955, 3430, 50960], "temperature": 0.0, "avg_logprob": -0.11529925891331264, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.002840088913217187}, {"id": 314, "seek": 160484, "start": 1616.76, "end": 1621.8, "text": " of AI for the next decade is how do we get machines to learn predictive models of the world", "tokens": [50960, 295, 7318, 337, 264, 958, 10378, 307, 577, 360, 321, 483, 8379, 281, 1466, 35521, 5245, 295, 264, 1002, 51212], "temperature": 0.0, "avg_logprob": -0.11529925891331264, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.002840088913217187}, {"id": 315, "seek": 160484, "start": 1621.8, "end": 1626.28, "text": " that deal with uncertainty, and deal with the real world in all this complexity. So it's not", "tokens": [51212, 300, 2028, 365, 15697, 11, 293, 2028, 365, 264, 957, 1002, 294, 439, 341, 14024, 13, 407, 309, 311, 406, 51436], "temperature": 0.0, "avg_logprob": -0.11529925891331264, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.002840088913217187}, {"id": 316, "seek": 160484, "start": 1626.28, "end": 1631.1599999999999, "text": " just trajectory of a rocket, which you can reduce to first principles, it's not, it's not even just", "tokens": [51436, 445, 21512, 295, 257, 13012, 11, 597, 291, 393, 5407, 281, 700, 9156, 11, 309, 311, 406, 11, 309, 311, 406, 754, 445, 51680], "temperature": 0.0, "avg_logprob": -0.11529925891331264, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.002840088913217187}, {"id": 317, "seek": 163116, "start": 1631.16, "end": 1636.1200000000001, "text": " a trajectory of a robot arm, which again, you can model by, you know, careful mathematics.", "tokens": [50364, 257, 21512, 295, 257, 7881, 3726, 11, 597, 797, 11, 291, 393, 2316, 538, 11, 291, 458, 11, 5026, 18666, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1092557465588605, "compression_ratio": 1.790513833992095, "no_speech_prob": 0.003170581767335534}, {"id": 318, "seek": 163116, "start": 1636.1200000000001, "end": 1639.64, "text": " But it's everything else, everything we observe in the world, you know, people, behavior,", "tokens": [50612, 583, 309, 311, 1203, 1646, 11, 1203, 321, 11441, 294, 264, 1002, 11, 291, 458, 11, 561, 11, 5223, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1092557465588605, "compression_ratio": 1.790513833992095, "no_speech_prob": 0.003170581767335534}, {"id": 319, "seek": 163116, "start": 1641.64, "end": 1647.72, "text": " you know, physical systems that involve collective phenomena, like water or, or, you know,", "tokens": [50888, 291, 458, 11, 4001, 3652, 300, 9494, 12590, 22004, 11, 411, 1281, 420, 11, 420, 11, 291, 458, 11, 51192], "temperature": 0.0, "avg_logprob": -0.1092557465588605, "compression_ratio": 1.790513833992095, "no_speech_prob": 0.003170581767335534}, {"id": 320, "seek": 163116, "start": 1649.0, "end": 1654.76, "text": " trees and, you know, branches in a tree or something, or, or like complex things that,", "tokens": [51256, 5852, 293, 11, 291, 458, 11, 14770, 294, 257, 4230, 420, 746, 11, 420, 11, 420, 411, 3997, 721, 300, 11, 51544], "temperature": 0.0, "avg_logprob": -0.1092557465588605, "compression_ratio": 1.790513833992095, "no_speech_prob": 0.003170581767335534}, {"id": 321, "seek": 163116, "start": 1654.76, "end": 1659.64, "text": " you know, humans have no trouble developing abstract representations and predictive model for,", "tokens": [51544, 291, 458, 11, 6255, 362, 572, 5253, 6416, 12649, 33358, 293, 35521, 2316, 337, 11, 51788], "temperature": 0.0, "avg_logprob": -0.1092557465588605, "compression_ratio": 1.790513833992095, "no_speech_prob": 0.003170581767335534}, {"id": 322, "seek": 165964, "start": 1659.64, "end": 1661.5600000000002, "text": " but we still don't know how to deal with machines.", "tokens": [50364, 457, 321, 920, 500, 380, 458, 577, 281, 2028, 365, 8379, 13, 50460], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 323, "seek": 165964, "start": 1661.5600000000002, "end": 1665.72, "text": " Where do you put in, in these three, maybe in the, in the planning stages,", "tokens": [50460, 2305, 360, 291, 829, 294, 11, 294, 613, 1045, 11, 1310, 294, 264, 11, 294, 264, 5038, 10232, 11, 50668], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 324, "seek": 165964, "start": 1667.24, "end": 1673.96, "text": " the, the game theoretic nature of this world, where your actions not only respond to the dynamic", "tokens": [50744, 264, 11, 264, 1216, 14308, 299, 3687, 295, 341, 1002, 11, 689, 428, 5909, 406, 787, 4196, 281, 264, 8546, 51080], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 325, "seek": 165964, "start": 1673.96, "end": 1679.72, "text": " nature of the world, the environment, but also affect it. So if there's other humans involved,", "tokens": [51080, 3687, 295, 264, 1002, 11, 264, 2823, 11, 457, 611, 3345, 309, 13, 407, 498, 456, 311, 661, 6255, 3288, 11, 51368], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 326, "seek": 165964, "start": 1679.72, "end": 1684.44, "text": " is this, is this point number four, or is it somehow integrated into the hierarchical", "tokens": [51368, 307, 341, 11, 307, 341, 935, 1230, 1451, 11, 420, 307, 309, 6063, 10919, 666, 264, 35250, 804, 51604], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 327, "seek": 165964, "start": 1684.44, "end": 1689.4, "text": " representation of action in your view? I think it's integrated. It's just, it's just that now", "tokens": [51604, 10290, 295, 3069, 294, 428, 1910, 30, 286, 519, 309, 311, 10919, 13, 467, 311, 445, 11, 309, 311, 445, 300, 586, 51852], "temperature": 0.0, "avg_logprob": -0.11220508151584202, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0036389906890690327}, {"id": 328, "seek": 168940, "start": 1689.4, "end": 1693.0, "text": " your model of the world has to deal with, you know, it just makes it more complicated, right?", "tokens": [50364, 428, 2316, 295, 264, 1002, 575, 281, 2028, 365, 11, 291, 458, 11, 309, 445, 1669, 309, 544, 6179, 11, 558, 30, 50544], "temperature": 0.0, "avg_logprob": -0.2130807350421774, "compression_ratio": 1.8170212765957447, "no_speech_prob": 0.0005440698587335646}, {"id": 329, "seek": 168940, "start": 1693.0, "end": 1698.1200000000001, "text": " The fact that humans are complicated and not easily predictable, that makes your model of", "tokens": [50544, 440, 1186, 300, 6255, 366, 6179, 293, 406, 3612, 27737, 11, 300, 1669, 428, 2316, 295, 50800], "temperature": 0.0, "avg_logprob": -0.2130807350421774, "compression_ratio": 1.8170212765957447, "no_speech_prob": 0.0005440698587335646}, {"id": 330, "seek": 168940, "start": 1698.1200000000001, "end": 1700.8400000000001, "text": " the world much more complicated, that much more complicated.", "tokens": [50800, 264, 1002, 709, 544, 6179, 11, 300, 709, 544, 6179, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2130807350421774, "compression_ratio": 1.8170212765957447, "no_speech_prob": 0.0005440698587335646}, {"id": 331, "seek": 168940, "start": 1700.8400000000001, "end": 1707.24, "text": " Well, there's a chess, I mean, I suppose chess is an analogy. So multi-carvel tree search.", "tokens": [50936, 1042, 11, 456, 311, 257, 24122, 11, 286, 914, 11, 286, 7297, 24122, 307, 364, 21663, 13, 407, 4825, 12, 6166, 779, 4230, 3164, 13, 51256], "temperature": 0.0, "avg_logprob": -0.2130807350421774, "compression_ratio": 1.8170212765957447, "no_speech_prob": 0.0005440698587335646}, {"id": 332, "seek": 168940, "start": 1707.96, "end": 1714.8400000000001, "text": " I mean, it, there's a, I go, you go, I go, you go, like, under Kapatha recently gave a talk", "tokens": [51292, 286, 914, 11, 309, 11, 456, 311, 257, 11, 286, 352, 11, 291, 352, 11, 286, 352, 11, 291, 352, 11, 411, 11, 833, 21216, 29441, 3938, 2729, 257, 751, 51636], "temperature": 0.0, "avg_logprob": -0.2130807350421774, "compression_ratio": 1.8170212765957447, "no_speech_prob": 0.0005440698587335646}, {"id": 333, "seek": 171484, "start": 1714.84, "end": 1720.84, "text": " at MIT about car doors. I think there's some machine learning too, but mostly car doors.", "tokens": [50364, 412, 13100, 466, 1032, 8077, 13, 286, 519, 456, 311, 512, 3479, 2539, 886, 11, 457, 5240, 1032, 8077, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 334, "seek": 171484, "start": 1720.84, "end": 1725.0, "text": " And there's a dynamic nature to the car, like the person opening the door, checking,", "tokens": [50664, 400, 456, 311, 257, 8546, 3687, 281, 264, 1032, 11, 411, 264, 954, 5193, 264, 2853, 11, 8568, 11, 50872], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 335, "seek": 171484, "start": 1725.56, "end": 1728.76, "text": " I mean, he wasn't talking about that. He was talking about the perception problem of what", "tokens": [50900, 286, 914, 11, 415, 2067, 380, 1417, 466, 300, 13, 634, 390, 1417, 466, 264, 12860, 1154, 295, 437, 51060], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 336, "seek": 171484, "start": 1728.76, "end": 1733.32, "text": " the, the ontology of what defines a car door, this big philosophical question. But to me,", "tokens": [51060, 264, 11, 264, 6592, 1793, 295, 437, 23122, 257, 1032, 2853, 11, 341, 955, 25066, 1168, 13, 583, 281, 385, 11, 51288], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 337, "seek": 171484, "start": 1733.32, "end": 1737.3999999999999, "text": " it was interesting because like, it's obvious that the person opening the car doors, they're", "tokens": [51288, 309, 390, 1880, 570, 411, 11, 309, 311, 6322, 300, 264, 954, 5193, 264, 1032, 8077, 11, 436, 434, 51492], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 338, "seek": 171484, "start": 1737.3999999999999, "end": 1742.6799999999998, "text": " trying to get out like here in New York, trying to get out of the car, you slowing down is going", "tokens": [51492, 1382, 281, 483, 484, 411, 510, 294, 1873, 3609, 11, 1382, 281, 483, 484, 295, 264, 1032, 11, 291, 26958, 760, 307, 516, 51756], "temperature": 0.0, "avg_logprob": -0.11498882858841508, "compression_ratio": 1.8595890410958904, "no_speech_prob": 0.1111716479063034}, {"id": 339, "seek": 174268, "start": 1742.68, "end": 1746.8400000000001, "text": " to signal something, you speeding up is going to signal something. And that's a dance. It's a", "tokens": [50364, 281, 6358, 746, 11, 291, 35593, 493, 307, 516, 281, 6358, 746, 13, 400, 300, 311, 257, 4489, 13, 467, 311, 257, 50572], "temperature": 0.0, "avg_logprob": -0.11288046403364702, "compression_ratio": 1.7679324894514767, "no_speech_prob": 0.039625562727451324}, {"id": 340, "seek": 174268, "start": 1747.64, "end": 1757.0800000000002, "text": " asynchronous chess game. I don't know. So it feels like it's not just, I mean,", "tokens": [50612, 49174, 24122, 1216, 13, 286, 500, 380, 458, 13, 407, 309, 3417, 411, 309, 311, 406, 445, 11, 286, 914, 11, 51084], "temperature": 0.0, "avg_logprob": -0.11288046403364702, "compression_ratio": 1.7679324894514767, "no_speech_prob": 0.039625562727451324}, {"id": 341, "seek": 174268, "start": 1757.0800000000002, "end": 1761.48, "text": " I guess you can integrate all of them to one giant model, like the entirety of the,", "tokens": [51084, 286, 2041, 291, 393, 13365, 439, 295, 552, 281, 472, 7410, 2316, 11, 411, 264, 31557, 295, 264, 11, 51304], "temperature": 0.0, "avg_logprob": -0.11288046403364702, "compression_ratio": 1.7679324894514767, "no_speech_prob": 0.039625562727451324}, {"id": 342, "seek": 174268, "start": 1762.68, "end": 1766.44, "text": " these little interactions, because it's not as complicated as chess, it's just like a little", "tokens": [51364, 613, 707, 13280, 11, 570, 309, 311, 406, 382, 6179, 382, 24122, 11, 309, 311, 445, 411, 257, 707, 51552], "temperature": 0.0, "avg_logprob": -0.11288046403364702, "compression_ratio": 1.7679324894514767, "no_speech_prob": 0.039625562727451324}, {"id": 343, "seek": 174268, "start": 1766.44, "end": 1769.88, "text": " dance. We do like a little dance together. And then we figure it out.", "tokens": [51552, 4489, 13, 492, 360, 411, 257, 707, 4489, 1214, 13, 400, 550, 321, 2573, 309, 484, 13, 51724], "temperature": 0.0, "avg_logprob": -0.11288046403364702, "compression_ratio": 1.7679324894514767, "no_speech_prob": 0.039625562727451324}, {"id": 344, "seek": 176988, "start": 1769.88, "end": 1774.92, "text": " Well, in some ways, it's way more complicated than chess because, because it's continuous,", "tokens": [50364, 1042, 11, 294, 512, 2098, 11, 309, 311, 636, 544, 6179, 813, 24122, 570, 11, 570, 309, 311, 10957, 11, 50616], "temperature": 0.0, "avg_logprob": -0.13211769806711296, "compression_ratio": 2.0, "no_speech_prob": 0.006092574913054705}, {"id": 345, "seek": 176988, "start": 1774.92, "end": 1779.72, "text": " it's uncertain in a continuous manner. It doesn't feel more complicated,", "tokens": [50616, 309, 311, 11308, 294, 257, 10957, 9060, 13, 467, 1177, 380, 841, 544, 6179, 11, 50856], "temperature": 0.0, "avg_logprob": -0.13211769806711296, "compression_ratio": 2.0, "no_speech_prob": 0.006092574913054705}, {"id": 346, "seek": 176988, "start": 1779.72, "end": 1783.5600000000002, "text": " but it doesn't feel more complicated because that's what we're, we've evolved to solve.", "tokens": [50856, 457, 309, 1177, 380, 841, 544, 6179, 570, 300, 311, 437, 321, 434, 11, 321, 600, 14178, 281, 5039, 13, 51048], "temperature": 0.0, "avg_logprob": -0.13211769806711296, "compression_ratio": 2.0, "no_speech_prob": 0.006092574913054705}, {"id": 347, "seek": 176988, "start": 1783.5600000000002, "end": 1787.0800000000002, "text": " This is the kind of problem we've evolved to solve. And so we're good at it because, you know,", "tokens": [51048, 639, 307, 264, 733, 295, 1154, 321, 600, 14178, 281, 5039, 13, 400, 370, 321, 434, 665, 412, 309, 570, 11, 291, 458, 11, 51224], "temperature": 0.0, "avg_logprob": -0.13211769806711296, "compression_ratio": 2.0, "no_speech_prob": 0.006092574913054705}, {"id": 348, "seek": 176988, "start": 1787.64, "end": 1793.88, "text": " nature has made us good at it. Nature has not made us good at chess. We completely suck at chess.", "tokens": [51252, 3687, 575, 1027, 505, 665, 412, 309, 13, 20159, 575, 406, 1027, 505, 665, 412, 24122, 13, 492, 2584, 9967, 412, 24122, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13211769806711296, "compression_ratio": 2.0, "no_speech_prob": 0.006092574913054705}, {"id": 349, "seek": 179388, "start": 1794.44, "end": 1801.4, "text": " In fact, that's why we designed it as a game is to be challenging. And if there is something that,", "tokens": [50392, 682, 1186, 11, 300, 311, 983, 321, 4761, 309, 382, 257, 1216, 307, 281, 312, 7595, 13, 400, 498, 456, 307, 746, 300, 11, 50740], "temperature": 0.0, "avg_logprob": -0.14389437336032673, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.04458130896091461}, {"id": 350, "seek": 179388, "start": 1801.4, "end": 1806.5200000000002, "text": " you know, recent progress in chess and Go has made us realize is that humans are", "tokens": [50740, 291, 458, 11, 5162, 4205, 294, 24122, 293, 1037, 575, 1027, 505, 4325, 307, 300, 6255, 366, 50996], "temperature": 0.0, "avg_logprob": -0.14389437336032673, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.04458130896091461}, {"id": 351, "seek": 179388, "start": 1806.5200000000002, "end": 1811.4, "text": " really terrible at those things, like really bad. You know, there was a story, right, before Alpha Go", "tokens": [50996, 534, 6237, 412, 729, 721, 11, 411, 534, 1578, 13, 509, 458, 11, 456, 390, 257, 1657, 11, 558, 11, 949, 20588, 1037, 51240], "temperature": 0.0, "avg_logprob": -0.14389437336032673, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.04458130896091461}, {"id": 352, "seek": 179388, "start": 1811.4, "end": 1817.24, "text": " that, you know, the best Go player thought there were maybe two or three stones behind,", "tokens": [51240, 300, 11, 291, 458, 11, 264, 1151, 1037, 4256, 1194, 456, 645, 1310, 732, 420, 1045, 14083, 2261, 11, 51532], "temperature": 0.0, "avg_logprob": -0.14389437336032673, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.04458130896091461}, {"id": 353, "seek": 179388, "start": 1817.24, "end": 1822.1200000000001, "text": " you know, an ideal player that they would call God. In fact, no, there are like nine or 10", "tokens": [51532, 291, 458, 11, 364, 7157, 4256, 300, 436, 576, 818, 1265, 13, 682, 1186, 11, 572, 11, 456, 366, 411, 4949, 420, 1266, 51776], "temperature": 0.0, "avg_logprob": -0.14389437336032673, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.04458130896091461}, {"id": 354, "seek": 182212, "start": 1822.6799999999998, "end": 1829.0, "text": " stones behind. I mean, we're just bad. So we're not good at, and it's because we have limited", "tokens": [50392, 14083, 2261, 13, 286, 914, 11, 321, 434, 445, 1578, 13, 407, 321, 434, 406, 665, 412, 11, 293, 309, 311, 570, 321, 362, 5567, 50708], "temperature": 0.0, "avg_logprob": -0.11333912509982869, "compression_ratio": 1.860655737704918, "no_speech_prob": 0.005630691070109606}, {"id": 355, "seek": 182212, "start": 1829.0, "end": 1833.0, "text": " working memory. We know we're not very good at like doing this tree exploration that,", "tokens": [50708, 1364, 4675, 13, 492, 458, 321, 434, 406, 588, 665, 412, 411, 884, 341, 4230, 16197, 300, 11, 50908], "temperature": 0.0, "avg_logprob": -0.11333912509982869, "compression_ratio": 1.860655737704918, "no_speech_prob": 0.005630691070109606}, {"id": 356, "seek": 182212, "start": 1833.0, "end": 1838.36, "text": " you know, computers are much better at doing than we are, but we are much better at learning", "tokens": [50908, 291, 458, 11, 10807, 366, 709, 1101, 412, 884, 813, 321, 366, 11, 457, 321, 366, 709, 1101, 412, 2539, 51176], "temperature": 0.0, "avg_logprob": -0.11333912509982869, "compression_ratio": 1.860655737704918, "no_speech_prob": 0.005630691070109606}, {"id": 357, "seek": 182212, "start": 1838.36, "end": 1843.6399999999999, "text": " differentiable models to the world. I mean, I said differentiable in the kind of, you know,", "tokens": [51176, 819, 9364, 5245, 281, 264, 1002, 13, 286, 914, 11, 286, 848, 819, 9364, 294, 264, 733, 295, 11, 291, 458, 11, 51440], "temperature": 0.0, "avg_logprob": -0.11333912509982869, "compression_ratio": 1.860655737704918, "no_speech_prob": 0.005630691070109606}, {"id": 358, "seek": 182212, "start": 1843.6399999999999, "end": 1847.32, "text": " I should say not differentiable in the sense that, you know, we run back from through it,", "tokens": [51440, 286, 820, 584, 406, 819, 9364, 294, 264, 2020, 300, 11, 291, 458, 11, 321, 1190, 646, 490, 807, 309, 11, 51624], "temperature": 0.0, "avg_logprob": -0.11333912509982869, "compression_ratio": 1.860655737704918, "no_speech_prob": 0.005630691070109606}, {"id": 359, "seek": 184732, "start": 1847.3999999999999, "end": 1853.1599999999999, "text": " but in the sense that our brain has some mechanism for estimating gradients of some kind.", "tokens": [50368, 457, 294, 264, 2020, 300, 527, 3567, 575, 512, 7513, 337, 8017, 990, 2771, 2448, 295, 512, 733, 13, 50656], "temperature": 0.0, "avg_logprob": -0.09419987227890518, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0043832166120409966}, {"id": 360, "seek": 184732, "start": 1853.96, "end": 1860.04, "text": " And that's what, you know, makes us efficient. So if you have an agent that consists of", "tokens": [50696, 400, 300, 311, 437, 11, 291, 458, 11, 1669, 505, 7148, 13, 407, 498, 291, 362, 364, 9461, 300, 14689, 295, 51000], "temperature": 0.0, "avg_logprob": -0.09419987227890518, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0043832166120409966}, {"id": 361, "seek": 184732, "start": 1861.24, "end": 1865.72, "text": " a model of the world, which, you know, in the human brain is basically the entire front half of", "tokens": [51060, 257, 2316, 295, 264, 1002, 11, 597, 11, 291, 458, 11, 294, 264, 1952, 3567, 307, 1936, 264, 2302, 1868, 1922, 295, 51284], "temperature": 0.0, "avg_logprob": -0.09419987227890518, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0043832166120409966}, {"id": 362, "seek": 184732, "start": 1865.72, "end": 1875.1599999999999, "text": " your brain, an objective function, which in humans is a combination of two things. There is", "tokens": [51284, 428, 3567, 11, 364, 10024, 2445, 11, 597, 294, 6255, 307, 257, 6562, 295, 732, 721, 13, 821, 307, 51756], "temperature": 0.0, "avg_logprob": -0.09419987227890518, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0043832166120409966}, {"id": 363, "seek": 187516, "start": 1875.24, "end": 1879.0, "text": " your sort of intrinsic motivation module, which is in the basal ganglia, you know,", "tokens": [50368, 428, 1333, 295, 35698, 12335, 10088, 11, 597, 307, 294, 264, 987, 304, 10145, 14218, 11, 291, 458, 11, 50556], "temperature": 0.0, "avg_logprob": -0.15730059277880323, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.0015928709181025624}, {"id": 364, "seek": 187516, "start": 1879.0, "end": 1883.0800000000002, "text": " the base of your brain. That's the thing that measures pain and hunger and things like that,", "tokens": [50556, 264, 3096, 295, 428, 3567, 13, 663, 311, 264, 551, 300, 8000, 1822, 293, 19229, 293, 721, 411, 300, 11, 50760], "temperature": 0.0, "avg_logprob": -0.15730059277880323, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.0015928709181025624}, {"id": 365, "seek": 187516, "start": 1883.0800000000002, "end": 1891.0800000000002, "text": " like immediate feelings and emotions. And then there is, you know, the equivalent of what people", "tokens": [50760, 411, 11629, 6640, 293, 8462, 13, 400, 550, 456, 307, 11, 291, 458, 11, 264, 10344, 295, 437, 561, 51160], "temperature": 0.0, "avg_logprob": -0.15730059277880323, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.0015928709181025624}, {"id": 366, "seek": 187516, "start": 1891.0800000000002, "end": 1896.8400000000001, "text": " in Reference Metronomy call a critic, which is a sort of module that predicts ahead what the outcome", "tokens": [51160, 294, 1300, 5158, 6377, 2044, 8488, 818, 257, 7850, 11, 597, 307, 257, 1333, 295, 10088, 300, 6069, 82, 2286, 437, 264, 9700, 51448], "temperature": 0.0, "avg_logprob": -0.15730059277880323, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.0015928709181025624}, {"id": 367, "seek": 189684, "start": 1897.8, "end": 1904.9199999999998, "text": " of a situation will be. And so it's not a cost function, but it's sort of not an objective", "tokens": [50412, 295, 257, 2590, 486, 312, 13, 400, 370, 309, 311, 406, 257, 2063, 2445, 11, 457, 309, 311, 1333, 295, 406, 364, 10024, 50768], "temperature": 0.0, "avg_logprob": -0.07354409915884745, "compression_ratio": 1.9381443298969072, "no_speech_prob": 0.002432148903608322}, {"id": 368, "seek": 189684, "start": 1904.9199999999998, "end": 1910.76, "text": " function, but it's sort of a, you know, trained predictor of the ultimate objective function.", "tokens": [50768, 2445, 11, 457, 309, 311, 1333, 295, 257, 11, 291, 458, 11, 8895, 6069, 284, 295, 264, 9705, 10024, 2445, 13, 51060], "temperature": 0.0, "avg_logprob": -0.07354409915884745, "compression_ratio": 1.9381443298969072, "no_speech_prob": 0.002432148903608322}, {"id": 369, "seek": 189684, "start": 1910.76, "end": 1915.6399999999999, "text": " And that also is differentiable. And so if all of this is differentiable, your cost function,", "tokens": [51060, 400, 300, 611, 307, 819, 9364, 13, 400, 370, 498, 439, 295, 341, 307, 819, 9364, 11, 428, 2063, 2445, 11, 51304], "temperature": 0.0, "avg_logprob": -0.07354409915884745, "compression_ratio": 1.9381443298969072, "no_speech_prob": 0.002432148903608322}, {"id": 370, "seek": 189684, "start": 1915.6399999999999, "end": 1923.32, "text": " your critic, your, you know, your world model, then you can use gradient based type methods to do", "tokens": [51304, 428, 7850, 11, 428, 11, 291, 458, 11, 428, 1002, 2316, 11, 550, 291, 393, 764, 16235, 2361, 2010, 7150, 281, 360, 51688], "temperature": 0.0, "avg_logprob": -0.07354409915884745, "compression_ratio": 1.9381443298969072, "no_speech_prob": 0.002432148903608322}, {"id": 371, "seek": 192332, "start": 1923.32, "end": 1928.2, "text": " planning, to do reasoning, to do learning, you know, to do all the things that would like an", "tokens": [50364, 5038, 11, 281, 360, 21577, 11, 281, 360, 2539, 11, 291, 458, 11, 281, 360, 439, 264, 721, 300, 576, 411, 364, 50608], "temperature": 0.0, "avg_logprob": -0.1143318442411201, "compression_ratio": 1.79, "no_speech_prob": 0.0052136704325675964}, {"id": 372, "seek": 192332, "start": 1928.2, "end": 1935.56, "text": " intelligent agent to do. And gradient based learning, like what's your intuition, that's", "tokens": [50608, 13232, 9461, 281, 360, 13, 400, 16235, 2361, 2539, 11, 411, 437, 311, 428, 24002, 11, 300, 311, 50976], "temperature": 0.0, "avg_logprob": -0.1143318442411201, "compression_ratio": 1.79, "no_speech_prob": 0.0052136704325675964}, {"id": 373, "seek": 192332, "start": 1935.56, "end": 1943.6399999999999, "text": " probably at the core of what can solve intelligence. So you don't need like a logic based reasoning", "tokens": [50976, 1391, 412, 264, 4965, 295, 437, 393, 5039, 7599, 13, 407, 291, 500, 380, 643, 411, 257, 9952, 2361, 21577, 51380], "temperature": 0.0, "avg_logprob": -0.1143318442411201, "compression_ratio": 1.79, "no_speech_prob": 0.0052136704325675964}, {"id": 374, "seek": 192332, "start": 1944.52, "end": 1947.96, "text": " in your view. I don't know how to make logic based reasoning compatible with", "tokens": [51424, 294, 428, 1910, 13, 286, 500, 380, 458, 577, 281, 652, 9952, 2361, 21577, 18218, 365, 51596], "temperature": 0.0, "avg_logprob": -0.1143318442411201, "compression_ratio": 1.79, "no_speech_prob": 0.0052136704325675964}, {"id": 375, "seek": 194796, "start": 1948.76, "end": 1953.72, "text": " efficient learning. And okay, I mean, there is a big question, perhaps a philosophical question.", "tokens": [50404, 7148, 2539, 13, 400, 1392, 11, 286, 914, 11, 456, 307, 257, 955, 1168, 11, 4317, 257, 25066, 1168, 13, 50652], "temperature": 0.0, "avg_logprob": -0.12705393897162542, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.00853382982313633}, {"id": 376, "seek": 194796, "start": 1953.72, "end": 1958.68, "text": " I mean, it's not that philosophical, but that we can ask is, is that, you know, all the learning", "tokens": [50652, 286, 914, 11, 309, 311, 406, 300, 25066, 11, 457, 300, 321, 393, 1029, 307, 11, 307, 300, 11, 291, 458, 11, 439, 264, 2539, 50900], "temperature": 0.0, "avg_logprob": -0.12705393897162542, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.00853382982313633}, {"id": 377, "seek": 194796, "start": 1959.32, "end": 1965.08, "text": " algorithms we know from engineering and computer science, proceed by optimizing some objective", "tokens": [50932, 14642, 321, 458, 490, 7043, 293, 3820, 3497, 11, 8991, 538, 40425, 512, 10024, 51220], "temperature": 0.0, "avg_logprob": -0.12705393897162542, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.00853382982313633}, {"id": 378, "seek": 194796, "start": 1965.08, "end": 1973.0, "text": " function? Yeah, right. So one question we may ask is, is those learning in the brain minimize", "tokens": [51220, 2445, 30, 865, 11, 558, 13, 407, 472, 1168, 321, 815, 1029, 307, 11, 307, 729, 2539, 294, 264, 3567, 17522, 51616], "temperature": 0.0, "avg_logprob": -0.12705393897162542, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.00853382982313633}, {"id": 379, "seek": 197300, "start": 1973.0, "end": 1978.36, "text": " an objective function? I mean, it could be, you know, a composite of multiple objective functions,", "tokens": [50364, 364, 10024, 2445, 30, 286, 914, 11, 309, 727, 312, 11, 291, 458, 11, 257, 25557, 295, 3866, 10024, 6828, 11, 50632], "temperature": 0.0, "avg_logprob": -0.10200607884037602, "compression_ratio": 1.8930041152263375, "no_speech_prob": 0.007922806777060032}, {"id": 380, "seek": 197300, "start": 1978.36, "end": 1984.76, "text": " but it's still an objective function. Second, if it does optimize an objective function,", "tokens": [50632, 457, 309, 311, 920, 364, 10024, 2445, 13, 5736, 11, 498, 309, 775, 19719, 364, 10024, 2445, 11, 50952], "temperature": 0.0, "avg_logprob": -0.10200607884037602, "compression_ratio": 1.8930041152263375, "no_speech_prob": 0.007922806777060032}, {"id": 381, "seek": 197300, "start": 1984.76, "end": 1990.36, "text": " does it do, does it do it by some sort of gradient estimation? You know, it doesn't need to be", "tokens": [50952, 775, 309, 360, 11, 775, 309, 360, 309, 538, 512, 1333, 295, 16235, 35701, 30, 509, 458, 11, 309, 1177, 380, 643, 281, 312, 51232], "temperature": 0.0, "avg_logprob": -0.10200607884037602, "compression_ratio": 1.8930041152263375, "no_speech_prob": 0.007922806777060032}, {"id": 382, "seek": 197300, "start": 1990.36, "end": 1995.56, "text": " backdrop, but you know, some way of estimating the gradient in efficient manner, whose complexity", "tokens": [51232, 32697, 11, 457, 291, 458, 11, 512, 636, 295, 8017, 990, 264, 16235, 294, 7148, 9060, 11, 6104, 14024, 51492], "temperature": 0.0, "avg_logprob": -0.10200607884037602, "compression_ratio": 1.8930041152263375, "no_speech_prob": 0.007922806777060032}, {"id": 383, "seek": 197300, "start": 1995.56, "end": 2000.52, "text": " is on the same order of magnitude as, you know, actually running the inference.", "tokens": [51492, 307, 322, 264, 912, 1668, 295, 15668, 382, 11, 291, 458, 11, 767, 2614, 264, 38253, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10200607884037602, "compression_ratio": 1.8930041152263375, "no_speech_prob": 0.007922806777060032}, {"id": 384, "seek": 200052, "start": 2001.48, "end": 2006.52, "text": " Because you can't afford to do things like, you know, perturbing a weight in your brain to", "tokens": [50412, 1436, 291, 393, 380, 6157, 281, 360, 721, 411, 11, 291, 458, 11, 13269, 374, 4324, 257, 3364, 294, 428, 3567, 281, 50664], "temperature": 0.0, "avg_logprob": -0.12891299845808643, "compression_ratio": 1.808, "no_speech_prob": 0.003753113793209195}, {"id": 385, "seek": 200052, "start": 2006.52, "end": 2011.48, "text": " figure out what the effect is, and then sort of, you know, you can do sort of estimating gradient", "tokens": [50664, 2573, 484, 437, 264, 1802, 307, 11, 293, 550, 1333, 295, 11, 291, 458, 11, 291, 393, 360, 1333, 295, 8017, 990, 16235, 50912], "temperature": 0.0, "avg_logprob": -0.12891299845808643, "compression_ratio": 1.808, "no_speech_prob": 0.003753113793209195}, {"id": 386, "seek": 200052, "start": 2011.48, "end": 2017.24, "text": " by perturbation. It's, to me, it seems very implausible that the brain uses some sort of,", "tokens": [50912, 538, 40468, 399, 13, 467, 311, 11, 281, 385, 11, 309, 2544, 588, 8484, 8463, 964, 300, 264, 3567, 4960, 512, 1333, 295, 11, 51200], "temperature": 0.0, "avg_logprob": -0.12891299845808643, "compression_ratio": 1.808, "no_speech_prob": 0.003753113793209195}, {"id": 387, "seek": 200052, "start": 2018.84, "end": 2024.6, "text": " you know, zero-thorough black box gradient free optimization, because it's so much less", "tokens": [51280, 291, 458, 11, 4018, 12, 392, 284, 581, 2211, 2424, 16235, 1737, 19618, 11, 570, 309, 311, 370, 709, 1570, 51568], "temperature": 0.0, "avg_logprob": -0.12891299845808643, "compression_ratio": 1.808, "no_speech_prob": 0.003753113793209195}, {"id": 388, "seek": 200052, "start": 2024.6, "end": 2028.12, "text": " efficient than gradient optimization. So it has to have a way of estimating gradient.", "tokens": [51568, 7148, 813, 16235, 19618, 13, 407, 309, 575, 281, 362, 257, 636, 295, 8017, 990, 16235, 13, 51744], "temperature": 0.0, "avg_logprob": -0.12891299845808643, "compression_ratio": 1.808, "no_speech_prob": 0.003753113793209195}, {"id": 389, "seek": 202812, "start": 2029.08, "end": 2035.32, "text": " Is it possible that some kind of logic-based reasoning emerges in pockets as a useful,", "tokens": [50412, 1119, 309, 1944, 300, 512, 733, 295, 9952, 12, 6032, 21577, 38965, 294, 16491, 382, 257, 4420, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 390, "seek": 202812, "start": 2035.32, "end": 2039.56, "text": " like you said, if the brain is an objective function? Maybe it's a mechanism for creating", "tokens": [50724, 411, 291, 848, 11, 498, 264, 3567, 307, 364, 10024, 2445, 30, 2704, 309, 311, 257, 7513, 337, 4084, 50936], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 391, "seek": 202812, "start": 2039.56, "end": 2045.6399999999999, "text": " objective functions. It's a mechanism for creating knowledge bases, for example,", "tokens": [50936, 10024, 6828, 13, 467, 311, 257, 7513, 337, 4084, 3601, 17949, 11, 337, 1365, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 392, "seek": 202812, "start": 2046.36, "end": 2051.0, "text": " that can then be quarried. Like maybe it's an efficient representation of knowledge that's", "tokens": [51276, 300, 393, 550, 312, 4723, 2428, 13, 1743, 1310, 309, 311, 364, 7148, 10290, 295, 3601, 300, 311, 51508], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 393, "seek": 202812, "start": 2051.0, "end": 2053.56, "text": " learned in a gradient-based way or something like that.", "tokens": [51508, 3264, 294, 257, 16235, 12, 6032, 636, 420, 746, 411, 300, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 394, "seek": 202812, "start": 2053.56, "end": 2057.88, "text": " Well, so I think there is a lot of different types of intelligence. So first of all,", "tokens": [51636, 1042, 11, 370, 286, 519, 456, 307, 257, 688, 295, 819, 3467, 295, 7599, 13, 407, 700, 295, 439, 11, 51852], "temperature": 0.0, "avg_logprob": -0.1061154398424872, "compression_ratio": 1.7097902097902098, "no_speech_prob": 0.0008828912978060544}, {"id": 395, "seek": 205788, "start": 2057.96, "end": 2063.7200000000003, "text": " I think the type of logical reasoning that we think about that we are, you know, maybe stemming", "tokens": [50368, 286, 519, 264, 2010, 295, 14978, 21577, 300, 321, 519, 466, 300, 321, 366, 11, 291, 458, 11, 1310, 12312, 2810, 50656], "temperature": 0.0, "avg_logprob": -0.10288815645827461, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.000869178504217416}, {"id": 396, "seek": 205788, "start": 2063.7200000000003, "end": 2071.4, "text": " from, you know, sort of classical AI of the 1970s and 80s, I think humans use that relatively", "tokens": [50656, 490, 11, 291, 458, 11, 1333, 295, 13735, 7318, 295, 264, 14577, 82, 293, 4688, 82, 11, 286, 519, 6255, 764, 300, 7226, 51040], "temperature": 0.0, "avg_logprob": -0.10288815645827461, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.000869178504217416}, {"id": 397, "seek": 205788, "start": 2071.4, "end": 2074.52, "text": " rarely and are not particularly good at it.", "tokens": [51040, 13752, 293, 366, 406, 4098, 665, 412, 309, 13, 51196], "temperature": 0.0, "avg_logprob": -0.10288815645827461, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.000869178504217416}, {"id": 398, "seek": 205788, "start": 2074.52, "end": 2081.56, "text": " But we judge each other based on our ability to solve those rare problems called IQ tests.", "tokens": [51196, 583, 321, 6995, 1184, 661, 2361, 322, 527, 3485, 281, 5039, 729, 5892, 2740, 1219, 28921, 6921, 13, 51548], "temperature": 0.0, "avg_logprob": -0.10288815645827461, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.000869178504217416}, {"id": 399, "seek": 205788, "start": 2081.56, "end": 2084.28, "text": " I think so. Like, I'm not very good at chess.", "tokens": [51548, 286, 519, 370, 13, 1743, 11, 286, 478, 406, 588, 665, 412, 24122, 13, 51684], "temperature": 0.0, "avg_logprob": -0.10288815645827461, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.000869178504217416}, {"id": 400, "seek": 208428, "start": 2085.1600000000003, "end": 2089.6400000000003, "text": " Yes, I'm judging you this whole time because, well, we actually...", "tokens": [50408, 1079, 11, 286, 478, 23587, 291, 341, 1379, 565, 570, 11, 731, 11, 321, 767, 485, 50632], "temperature": 0.0, "avg_logprob": -0.16443490982055664, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.005382188130170107}, {"id": 401, "seek": 208428, "start": 2089.6400000000003, "end": 2092.6800000000003, "text": " With your, you know, heritage, I'm sure you're good at chess.", "tokens": [50632, 2022, 428, 11, 291, 458, 11, 16040, 11, 286, 478, 988, 291, 434, 665, 412, 24122, 13, 50784], "temperature": 0.0, "avg_logprob": -0.16443490982055664, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.005382188130170107}, {"id": 402, "seek": 208428, "start": 2093.4, "end": 2096.44, "text": " No, stereotypes. Not all stereotypes are true.", "tokens": [50820, 883, 11, 30853, 13, 1726, 439, 30853, 366, 2074, 13, 50972], "temperature": 0.0, "avg_logprob": -0.16443490982055664, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.005382188130170107}, {"id": 403, "seek": 208428, "start": 2097.88, "end": 2104.6000000000004, "text": " Well, I'm terrible at chess. So, you know, but I think perhaps another type of intelligence", "tokens": [51044, 1042, 11, 286, 478, 6237, 412, 24122, 13, 407, 11, 291, 458, 11, 457, 286, 519, 4317, 1071, 2010, 295, 7599, 51380], "temperature": 0.0, "avg_logprob": -0.16443490982055664, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.005382188130170107}, {"id": 404, "seek": 208428, "start": 2104.6000000000004, "end": 2109.7200000000003, "text": " that I have is this, you know, ability of sort of building models to the world from,", "tokens": [51380, 300, 286, 362, 307, 341, 11, 291, 458, 11, 3485, 295, 1333, 295, 2390, 5245, 281, 264, 1002, 490, 11, 51636], "temperature": 0.0, "avg_logprob": -0.16443490982055664, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.005382188130170107}, {"id": 405, "seek": 210972, "start": 2110.68, "end": 2114.9199999999996, "text": " you know, reasoning, obviously, but also data.", "tokens": [50412, 291, 458, 11, 21577, 11, 2745, 11, 457, 611, 1412, 13, 50624], "temperature": 0.0, "avg_logprob": -0.10749836170927007, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0006983072380535305}, {"id": 406, "seek": 210972, "start": 2115.7999999999997, "end": 2121.48, "text": " And those models generally are more kind of analogical, right? So it's reasoning by simulation", "tokens": [50668, 400, 729, 5245, 5101, 366, 544, 733, 295, 16660, 804, 11, 558, 30, 407, 309, 311, 21577, 538, 16575, 50952], "temperature": 0.0, "avg_logprob": -0.10749836170927007, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0006983072380535305}, {"id": 407, "seek": 210972, "start": 2122.2, "end": 2126.7599999999998, "text": " and by analogy, where you use one model to apply to a new situation.", "tokens": [50988, 293, 538, 21663, 11, 689, 291, 764, 472, 2316, 281, 3079, 281, 257, 777, 2590, 13, 51216], "temperature": 0.0, "avg_logprob": -0.10749836170927007, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0006983072380535305}, {"id": 408, "seek": 210972, "start": 2126.7599999999998, "end": 2131.64, "text": " Even though you've never seen that situation, you can sort of connect it to a situation you've", "tokens": [51216, 2754, 1673, 291, 600, 1128, 1612, 300, 2590, 11, 291, 393, 1333, 295, 1745, 309, 281, 257, 2590, 291, 600, 51460], "temperature": 0.0, "avg_logprob": -0.10749836170927007, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0006983072380535305}, {"id": 409, "seek": 210972, "start": 2131.64, "end": 2138.3599999999997, "text": " encountered before. And your reasoning is more akin to some sort of internal simulation.", "tokens": [51460, 20381, 949, 13, 400, 428, 21577, 307, 544, 47540, 281, 512, 1333, 295, 6920, 16575, 13, 51796], "temperature": 0.0, "avg_logprob": -0.10749836170927007, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0006983072380535305}, {"id": 410, "seek": 213836, "start": 2138.36, "end": 2142.1200000000003, "text": " So you're kind of simulating what's happening when you're building, I don't know,", "tokens": [50364, 407, 291, 434, 733, 295, 1034, 12162, 437, 311, 2737, 562, 291, 434, 2390, 11, 286, 500, 380, 458, 11, 50552], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 411, "seek": 213836, "start": 2142.1200000000003, "end": 2145.7200000000003, "text": " a box out of wood or something, right? You're going to imagine in advance,", "tokens": [50552, 257, 2424, 484, 295, 4576, 420, 746, 11, 558, 30, 509, 434, 516, 281, 3811, 294, 7295, 11, 50732], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 412, "seek": 213836, "start": 2146.28, "end": 2149.48, "text": " like, will we be the result of, you know, cutting the wood in this particular way?", "tokens": [50760, 411, 11, 486, 321, 312, 264, 1874, 295, 11, 291, 458, 11, 6492, 264, 4576, 294, 341, 1729, 636, 30, 50920], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 413, "seek": 213836, "start": 2149.48, "end": 2151.48, "text": " Are you going to use, you know, screws on nails or whatever?", "tokens": [50920, 2014, 291, 516, 281, 764, 11, 291, 458, 11, 13050, 322, 15394, 420, 2035, 30, 51020], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 414, "seek": 213836, "start": 2152.76, "end": 2156.92, "text": " When you are interacting with someone, you also have a model of that person and sort of", "tokens": [51084, 1133, 291, 366, 18017, 365, 1580, 11, 291, 611, 362, 257, 2316, 295, 300, 954, 293, 1333, 295, 51292], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 415, "seek": 213836, "start": 2156.92, "end": 2163.56, "text": " interact with that person. You know, having this model in mind to kind of tell the person", "tokens": [51292, 4648, 365, 300, 954, 13, 509, 458, 11, 1419, 341, 2316, 294, 1575, 281, 733, 295, 980, 264, 954, 51624], "temperature": 0.0, "avg_logprob": -0.13714876482563634, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.00046533162822015584}, {"id": 416, "seek": 216356, "start": 2163.72, "end": 2170.2, "text": " what you think is useful to them. So I think this ability to construct models to the world", "tokens": [50372, 437, 291, 519, 307, 4420, 281, 552, 13, 407, 286, 519, 341, 3485, 281, 7690, 5245, 281, 264, 1002, 50696], "temperature": 0.0, "avg_logprob": -0.15034793672107516, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004678241442888975}, {"id": 417, "seek": 216356, "start": 2170.2, "end": 2176.6, "text": " is basically the essence of intelligence. And the ability to use it then to plan", "tokens": [50696, 307, 1936, 264, 12801, 295, 7599, 13, 400, 264, 3485, 281, 764, 309, 550, 281, 1393, 51016], "temperature": 0.0, "avg_logprob": -0.15034793672107516, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004678241442888975}, {"id": 418, "seek": 216356, "start": 2177.4, "end": 2185.32, "text": " actions that will fulfill a particular criterion, of course, is necessary as well.", "tokens": [51056, 5909, 300, 486, 13875, 257, 1729, 46691, 11, 295, 1164, 11, 307, 4818, 382, 731, 13, 51452], "temperature": 0.0, "avg_logprob": -0.15034793672107516, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004678241442888975}, {"id": 419, "seek": 216356, "start": 2185.32, "end": 2190.12, "text": " So I'm going to ask you a series of impossible questions as we keep asking, as I've been doing.", "tokens": [51452, 407, 286, 478, 516, 281, 1029, 291, 257, 2638, 295, 6243, 1651, 382, 321, 1066, 3365, 11, 382, 286, 600, 668, 884, 13, 51692], "temperature": 0.0, "avg_logprob": -0.15034793672107516, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.004678241442888975}, {"id": 420, "seek": 219012, "start": 2190.12, "end": 2195.16, "text": " So if that's the fundamental sort of dark matter of intelligence, this ability to form", "tokens": [50364, 407, 498, 300, 311, 264, 8088, 1333, 295, 2877, 1871, 295, 7599, 11, 341, 3485, 281, 1254, 50616], "temperature": 0.0, "avg_logprob": -0.13364583253860474, "compression_ratio": 1.6633165829145728, "no_speech_prob": 0.00039186817593872547}, {"id": 421, "seek": 219012, "start": 2195.16, "end": 2200.2799999999997, "text": " a background model, what's your intuition about how much knowledge is required?", "tokens": [50616, 257, 3678, 2316, 11, 437, 311, 428, 24002, 466, 577, 709, 3601, 307, 4739, 30, 50872], "temperature": 0.0, "avg_logprob": -0.13364583253860474, "compression_ratio": 1.6633165829145728, "no_speech_prob": 0.00039186817593872547}, {"id": 422, "seek": 219012, "start": 2201.3199999999997, "end": 2206.04, "text": " You know, I think dark matter, you could put a percentage on it of", "tokens": [50924, 509, 458, 11, 286, 519, 2877, 1871, 11, 291, 727, 829, 257, 9668, 322, 309, 295, 51160], "temperature": 0.0, "avg_logprob": -0.13364583253860474, "compression_ratio": 1.6633165829145728, "no_speech_prob": 0.00039186817593872547}, {"id": 423, "seek": 219012, "start": 2208.68, "end": 2212.6, "text": " the composition of the universe and how much of it is dark matter, how much of it is dark energy,", "tokens": [51292, 264, 12686, 295, 264, 6445, 293, 577, 709, 295, 309, 307, 2877, 1871, 11, 577, 709, 295, 309, 307, 2877, 2281, 11, 51488], "temperature": 0.0, "avg_logprob": -0.13364583253860474, "compression_ratio": 1.6633165829145728, "no_speech_prob": 0.00039186817593872547}, {"id": 424, "seek": 221260, "start": 2212.6, "end": 2221.08, "text": " how much information do you think is required to be a house cat? So you have to be able to,", "tokens": [50364, 577, 709, 1589, 360, 291, 519, 307, 4739, 281, 312, 257, 1782, 3857, 30, 407, 291, 362, 281, 312, 1075, 281, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1132369978087289, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.018537303432822227}, {"id": 425, "seek": 221260, "start": 2221.08, "end": 2227.0, "text": " when you see a box going, when you see a human compute the most evil action, if there's a thing", "tokens": [50788, 562, 291, 536, 257, 2424, 516, 11, 562, 291, 536, 257, 1952, 14722, 264, 881, 6724, 3069, 11, 498, 456, 311, 257, 551, 51084], "temperature": 0.0, "avg_logprob": -0.1132369978087289, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.018537303432822227}, {"id": 426, "seek": 221260, "start": 2227.0, "end": 2232.68, "text": " that's near an edge, you knock it off, all of that, plus the extra stuff you mentioned,", "tokens": [51084, 300, 311, 2651, 364, 4691, 11, 291, 6728, 309, 766, 11, 439, 295, 300, 11, 1804, 264, 2857, 1507, 291, 2835, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1132369978087289, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.018537303432822227}, {"id": 427, "seek": 221260, "start": 2232.68, "end": 2237.7999999999997, "text": " which is a great self-awareness of the physics of your own body and the world.", "tokens": [51368, 597, 307, 257, 869, 2698, 12, 17074, 1287, 295, 264, 10649, 295, 428, 1065, 1772, 293, 264, 1002, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1132369978087289, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.018537303432822227}, {"id": 428, "seek": 221260, "start": 2238.6, "end": 2240.8399999999997, "text": " How much knowledge is required, do you think, to solve it?", "tokens": [51664, 1012, 709, 3601, 307, 4739, 11, 360, 291, 519, 11, 281, 5039, 309, 30, 51776], "temperature": 0.0, "avg_logprob": -0.1132369978087289, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.018537303432822227}, {"id": 429, "seek": 224084, "start": 2241.8, "end": 2245.48, "text": " I don't even know how to measure an answer to that question.", "tokens": [50412, 286, 500, 380, 754, 458, 577, 281, 3481, 364, 1867, 281, 300, 1168, 13, 50596], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 430, "seek": 224084, "start": 2245.48, "end": 2250.76, "text": " I'm not sure how to measure it, but whatever it is, it fits in about 800,000 neurons,", "tokens": [50596, 286, 478, 406, 988, 577, 281, 3481, 309, 11, 457, 2035, 309, 307, 11, 309, 9001, 294, 466, 13083, 11, 1360, 22027, 11, 50860], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 431, "seek": 224084, "start": 2252.28, "end": 2253.6400000000003, "text": " 800 million neurons.", "tokens": [50936, 13083, 2459, 22027, 13, 51004], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 432, "seek": 224084, "start": 2253.6400000000003, "end": 2255.0, "text": " The representation does.", "tokens": [51004, 440, 10290, 775, 13, 51072], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 433, "seek": 224084, "start": 2256.28, "end": 2258.1200000000003, "text": " Everything, all knowledge, everything, right?", "tokens": [51136, 5471, 11, 439, 3601, 11, 1203, 11, 558, 30, 51228], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 434, "seek": 224084, "start": 2259.88, "end": 2264.1200000000003, "text": " You know, it's less than a billion, a dog is 2 billion, but a cat is less than 1 billion.", "tokens": [51316, 509, 458, 11, 309, 311, 1570, 813, 257, 5218, 11, 257, 3000, 307, 568, 5218, 11, 457, 257, 3857, 307, 1570, 813, 502, 5218, 13, 51528], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 435, "seek": 224084, "start": 2265.32, "end": 2269.2400000000002, "text": " And so multiply that by a thousand and you get the number of synapses.", "tokens": [51588, 400, 370, 12972, 300, 538, 257, 4714, 293, 291, 483, 264, 1230, 295, 5451, 2382, 279, 13, 51784], "temperature": 0.0, "avg_logprob": -0.19109914984021867, "compression_ratio": 1.6352459016393444, "no_speech_prob": 0.0016475473530590534}, {"id": 436, "seek": 226924, "start": 2270.2, "end": 2275.8799999999997, "text": " And I think almost all of it is learned through this, you know, a sort of self-supervised running,", "tokens": [50412, 400, 286, 519, 1920, 439, 295, 309, 307, 3264, 807, 341, 11, 291, 458, 11, 257, 1333, 295, 2698, 12, 48172, 24420, 2614, 11, 50696], "temperature": 0.0, "avg_logprob": -0.11050689220428467, "compression_ratio": 2.0861244019138754, "no_speech_prob": 0.002305346541106701}, {"id": 437, "seek": 226924, "start": 2275.8799999999997, "end": 2279.7999999999997, "text": " although, you know, I think a tiny sliver is learned through reinforcement running,", "tokens": [50696, 4878, 11, 291, 458, 11, 286, 519, 257, 5870, 1061, 1837, 307, 3264, 807, 29280, 2614, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11050689220428467, "compression_ratio": 2.0861244019138754, "no_speech_prob": 0.002305346541106701}, {"id": 438, "seek": 226924, "start": 2279.7999999999997, "end": 2283.56, "text": " and certainly very little through, you know, classical supervised running, although it's", "tokens": [50892, 293, 3297, 588, 707, 807, 11, 291, 458, 11, 13735, 46533, 2614, 11, 4878, 309, 311, 51080], "temperature": 0.0, "avg_logprob": -0.11050689220428467, "compression_ratio": 2.0861244019138754, "no_speech_prob": 0.002305346541106701}, {"id": 439, "seek": 226924, "start": 2283.56, "end": 2287.8799999999997, "text": " not even clear how supervised running actually works in the biological world.", "tokens": [51080, 406, 754, 1850, 577, 46533, 2614, 767, 1985, 294, 264, 13910, 1002, 13, 51296], "temperature": 0.0, "avg_logprob": -0.11050689220428467, "compression_ratio": 2.0861244019138754, "no_speech_prob": 0.002305346541106701}, {"id": 440, "seek": 226924, "start": 2289.16, "end": 2296.68, "text": " So I think almost all of it is self-supervised running, but it's driven by the sort of", "tokens": [51360, 407, 286, 519, 1920, 439, 295, 309, 307, 2698, 12, 48172, 24420, 2614, 11, 457, 309, 311, 9555, 538, 264, 1333, 295, 51736], "temperature": 0.0, "avg_logprob": -0.11050689220428467, "compression_ratio": 2.0861244019138754, "no_speech_prob": 0.002305346541106701}, {"id": 441, "seek": 229668, "start": 2296.68, "end": 2301.3199999999997, "text": " ingrained objective functions that a cat or human have at the base of their brain,", "tokens": [50364, 3957, 31774, 10024, 6828, 300, 257, 3857, 420, 1952, 362, 412, 264, 3096, 295, 641, 3567, 11, 50596], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 442, "seek": 229668, "start": 2301.3199999999997, "end": 2304.8399999999997, "text": " which kind of drives their behavior.", "tokens": [50596, 597, 733, 295, 11754, 641, 5223, 13, 50772], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 443, "seek": 229668, "start": 2304.8399999999997, "end": 2308.2799999999997, "text": " So, you know, nature tells us you're hungry.", "tokens": [50772, 407, 11, 291, 458, 11, 3687, 5112, 505, 291, 434, 8067, 13, 50944], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 444, "seek": 229668, "start": 2309.3199999999997, "end": 2311.7999999999997, "text": " It doesn't tell us how to feed ourselves.", "tokens": [50996, 467, 1177, 380, 980, 505, 577, 281, 3154, 4175, 13, 51120], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 445, "seek": 229668, "start": 2311.7999999999997, "end": 2314.52, "text": " That's something that the rest of our brain has to figure out, right?", "tokens": [51120, 663, 311, 746, 300, 264, 1472, 295, 527, 3567, 575, 281, 2573, 484, 11, 558, 30, 51256], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 446, "seek": 229668, "start": 2315.64, "end": 2319.72, "text": " What's interesting, because there might be more like deeper objective functions than", "tokens": [51312, 708, 311, 1880, 11, 570, 456, 1062, 312, 544, 411, 7731, 10024, 6828, 813, 51516], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 447, "seek": 229668, "start": 2319.72, "end": 2320.68, "text": " allowing the whole thing.", "tokens": [51516, 8293, 264, 1379, 551, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11976321702150955, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0011332599679008126}, {"id": 448, "seek": 232068, "start": 2321.24, "end": 2327.16, "text": " So hunger may be some kind of, now you go to like neurobiology, it might be just the brain", "tokens": [50392, 407, 19229, 815, 312, 512, 733, 295, 11, 586, 291, 352, 281, 411, 16499, 5614, 1793, 11, 309, 1062, 312, 445, 264, 3567, 50688], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 449, "seek": 232068, "start": 2329.96, "end": 2331.56, "text": " trying to maintain homeostasis.", "tokens": [50828, 1382, 281, 6909, 1280, 555, 26632, 13, 50908], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 450, "seek": 232068, "start": 2332.3599999999997, "end": 2339.48, "text": " So hunger is just one of the human perceivable symptoms of the brain being unhappy with the", "tokens": [50948, 407, 19229, 307, 445, 472, 295, 264, 1952, 9016, 34376, 8332, 295, 264, 3567, 885, 22172, 365, 264, 51304], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 451, "seek": 232068, "start": 2339.48, "end": 2340.52, "text": " way things are currently.", "tokens": [51304, 636, 721, 366, 4362, 13, 51356], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 452, "seek": 232068, "start": 2341.3199999999997, "end": 2344.7599999999998, "text": " It could be just like one really dumb objective function at the core.", "tokens": [51396, 467, 727, 312, 445, 411, 472, 534, 10316, 10024, 2445, 412, 264, 4965, 13, 51568], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 453, "seek": 232068, "start": 2344.7599999999998, "end": 2347.56, "text": " But that's how behavior is driven.", "tokens": [51568, 583, 300, 311, 577, 5223, 307, 9555, 13, 51708], "temperature": 0.0, "avg_logprob": -0.12279968047409914, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.036198727786540985}, {"id": 454, "seek": 234756, "start": 2348.44, "end": 2351.08, "text": " The fact that, you know, the, or basal ganglia", "tokens": [50408, 440, 1186, 300, 11, 291, 458, 11, 264, 11, 420, 987, 304, 10145, 14218, 50540], "temperature": 0.0, "avg_logprob": -0.156759090423584, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.0033202904742211103}, {"id": 455, "seek": 234756, "start": 2352.36, "end": 2357.24, "text": " drivers to do things that are different from say an orangutan or certainly a cat", "tokens": [50604, 11590, 281, 360, 721, 300, 366, 819, 490, 584, 364, 17481, 30624, 420, 3297, 257, 3857, 50848], "temperature": 0.0, "avg_logprob": -0.156759090423584, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.0033202904742211103}, {"id": 456, "seek": 234756, "start": 2358.12, "end": 2362.2799999999997, "text": " is what makes, you know, human nature versus orangutan nature versus cat nature.", "tokens": [50892, 307, 437, 1669, 11, 291, 458, 11, 1952, 3687, 5717, 17481, 30624, 3687, 5717, 3857, 3687, 13, 51100], "temperature": 0.0, "avg_logprob": -0.156759090423584, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.0033202904742211103}, {"id": 457, "seek": 234756, "start": 2363.24, "end": 2371.32, "text": " So for example, you know, our basal ganglia drives us to seek the company of other humans.", "tokens": [51148, 407, 337, 1365, 11, 291, 458, 11, 527, 987, 304, 10145, 14218, 11754, 505, 281, 8075, 264, 2237, 295, 661, 6255, 13, 51552], "temperature": 0.0, "avg_logprob": -0.156759090423584, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.0033202904742211103}, {"id": 458, "seek": 234756, "start": 2372.12, "end": 2377.08, "text": " And that's because nature has figured out that we need to be social animals for our species to", "tokens": [51592, 400, 300, 311, 570, 3687, 575, 8932, 484, 300, 321, 643, 281, 312, 2093, 4882, 337, 527, 6172, 281, 51840], "temperature": 0.0, "avg_logprob": -0.156759090423584, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.0033202904742211103}, {"id": 459, "seek": 237708, "start": 2377.08, "end": 2383.08, "text": " survive. And it's true of many primates. It's not true of orangutans, orangutans are", "tokens": [50364, 7867, 13, 400, 309, 311, 2074, 295, 867, 2886, 1024, 13, 467, 311, 406, 2074, 295, 17481, 325, 599, 11, 17481, 325, 599, 366, 50664], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 460, "seek": 237708, "start": 2383.08, "end": 2387.88, "text": " solitary animals. They don't seek the company of others. In fact, they avoid them.", "tokens": [50664, 44155, 4882, 13, 814, 500, 380, 8075, 264, 2237, 295, 2357, 13, 682, 1186, 11, 436, 5042, 552, 13, 50904], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 461, "seek": 237708, "start": 2389.24, "end": 2391.96, "text": " In fact, they scream at them when they come too close because they're territorial.", "tokens": [50972, 682, 1186, 11, 436, 7291, 412, 552, 562, 436, 808, 886, 1998, 570, 436, 434, 34888, 13, 51108], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 462, "seek": 237708, "start": 2392.6, "end": 2397.4, "text": " Because for their survival, you know, evolution has figured out that's the best thing.", "tokens": [51140, 1436, 337, 641, 12559, 11, 291, 458, 11, 9303, 575, 8932, 484, 300, 311, 264, 1151, 551, 13, 51380], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 463, "seek": 237708, "start": 2398.12, "end": 2400.7599999999998, "text": " I mean, they're occasionally social, of course, for, you know,", "tokens": [51416, 286, 914, 11, 436, 434, 16895, 2093, 11, 295, 1164, 11, 337, 11, 291, 458, 11, 51548], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 464, "seek": 237708, "start": 2402.12, "end": 2405.88, "text": " reproduction and stuff like that. But they're mostly solitary.", "tokens": [51616, 33934, 293, 1507, 411, 300, 13, 583, 436, 434, 5240, 44155, 13, 51804], "temperature": 0.0, "avg_logprob": -0.14188904762268068, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.006021049339324236}, {"id": 465, "seek": 240588, "start": 2406.84, "end": 2410.36, "text": " So all of those behaviors are not part of intelligence. You know, people say, oh,", "tokens": [50412, 407, 439, 295, 729, 15501, 366, 406, 644, 295, 7599, 13, 509, 458, 11, 561, 584, 11, 1954, 11, 50588], "temperature": 0.0, "avg_logprob": -0.11436947679097674, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0012205296661704779}, {"id": 466, "seek": 240588, "start": 2410.36, "end": 2413.8, "text": " you're never going to have intelligent machines because, you know, human intelligence is social.", "tokens": [50588, 291, 434, 1128, 516, 281, 362, 13232, 8379, 570, 11, 291, 458, 11, 1952, 7599, 307, 2093, 13, 50760], "temperature": 0.0, "avg_logprob": -0.11436947679097674, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0012205296661704779}, {"id": 467, "seek": 240588, "start": 2413.8, "end": 2417.96, "text": " But then you look at orangutans, you look at octopus. Octopus never know their parents.", "tokens": [50760, 583, 550, 291, 574, 412, 17481, 325, 599, 11, 291, 574, 412, 27962, 13, 6788, 23280, 1128, 458, 641, 3152, 13, 50968], "temperature": 0.0, "avg_logprob": -0.11436947679097674, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0012205296661704779}, {"id": 468, "seek": 240588, "start": 2418.6800000000003, "end": 2423.8, "text": " They barely interact with any other and they get to be really smart in less than a year,", "tokens": [51004, 814, 10268, 4648, 365, 604, 661, 293, 436, 483, 281, 312, 534, 4069, 294, 1570, 813, 257, 1064, 11, 51260], "temperature": 0.0, "avg_logprob": -0.11436947679097674, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0012205296661704779}, {"id": 469, "seek": 240588, "start": 2423.8, "end": 2428.76, "text": " in like half a year. You know, in a year or they're adults, in two years they're dead.", "tokens": [51260, 294, 411, 1922, 257, 1064, 13, 509, 458, 11, 294, 257, 1064, 420, 436, 434, 8865, 11, 294, 732, 924, 436, 434, 3116, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11436947679097674, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0012205296661704779}, {"id": 470, "seek": 242876, "start": 2428.76, "end": 2435.7200000000003, "text": " So there are things that we think, as humans, are intimately linked with intelligence,", "tokens": [50364, 407, 456, 366, 721, 300, 321, 519, 11, 382, 6255, 11, 366, 560, 5401, 9408, 365, 7599, 11, 50712], "temperature": 0.0, "avg_logprob": -0.11069589250543144, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0023946010041981936}, {"id": 471, "seek": 242876, "start": 2435.7200000000003, "end": 2442.28, "text": " like social interaction, like language. We think, I think we give way too much", "tokens": [50712, 411, 2093, 9285, 11, 411, 2856, 13, 492, 519, 11, 286, 519, 321, 976, 636, 886, 709, 51040], "temperature": 0.0, "avg_logprob": -0.11069589250543144, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0023946010041981936}, {"id": 472, "seek": 242876, "start": 2442.28, "end": 2445.88, "text": " importance to language as a substrate of intelligence as humans,", "tokens": [51040, 7379, 281, 2856, 382, 257, 27585, 295, 7599, 382, 6255, 11, 51220], "temperature": 0.0, "avg_logprob": -0.11069589250543144, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0023946010041981936}, {"id": 473, "seek": 242876, "start": 2446.6800000000003, "end": 2449.8, "text": " because we think our reasoning is so linked with language.", "tokens": [51260, 570, 321, 519, 527, 21577, 307, 370, 9408, 365, 2856, 13, 51416], "temperature": 0.0, "avg_logprob": -0.11069589250543144, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0023946010041981936}, {"id": 474, "seek": 242876, "start": 2449.8, "end": 2455.0800000000004, "text": " So for, to solve the house cat intelligence problem, you think you could do it on a desert", "tokens": [51416, 407, 337, 11, 281, 5039, 264, 1782, 3857, 7599, 1154, 11, 291, 519, 291, 727, 360, 309, 322, 257, 11029, 51680], "temperature": 0.0, "avg_logprob": -0.11069589250543144, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0023946010041981936}, {"id": 475, "seek": 245508, "start": 2455.08, "end": 2463.08, "text": " island. You could have a cat sitting there, looking at the waves, at the ocean waves,", "tokens": [50364, 6077, 13, 509, 727, 362, 257, 3857, 3798, 456, 11, 1237, 412, 264, 9417, 11, 412, 264, 7810, 9417, 11, 50764], "temperature": 0.0, "avg_logprob": -0.14105675437233664, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.048777032643556595}, {"id": 476, "seek": 245508, "start": 2463.08, "end": 2468.6, "text": " and figure a lot of it out. It needs to have sort of, you know, the right set of drives", "tokens": [50764, 293, 2573, 257, 688, 295, 309, 484, 13, 467, 2203, 281, 362, 1333, 295, 11, 291, 458, 11, 264, 558, 992, 295, 11754, 51040], "temperature": 0.0, "avg_logprob": -0.14105675437233664, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.048777032643556595}, {"id": 477, "seek": 245508, "start": 2470.04, "end": 2474.44, "text": " to kind of, you know, get it to do the thing and learn the appropriate things, right? But", "tokens": [51112, 281, 733, 295, 11, 291, 458, 11, 483, 309, 281, 360, 264, 551, 293, 1466, 264, 6854, 721, 11, 558, 30, 583, 51332], "temperature": 0.0, "avg_logprob": -0.14105675437233664, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.048777032643556595}, {"id": 478, "seek": 245508, "start": 2476.12, "end": 2479.56, "text": " like, for example, you know, baby humans are driven to", "tokens": [51416, 411, 11, 337, 1365, 11, 291, 458, 11, 3186, 6255, 366, 9555, 281, 51588], "temperature": 0.0, "avg_logprob": -0.14105675437233664, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.048777032643556595}, {"id": 479, "seek": 247956, "start": 2480.52, "end": 2486.36, "text": " learn to stand up and walk. Okay, that's kind of, this desire is hardwired. How to do it", "tokens": [50412, 1466, 281, 1463, 493, 293, 1792, 13, 1033, 11, 300, 311, 733, 295, 11, 341, 7516, 307, 1152, 86, 1824, 13, 1012, 281, 360, 309, 50704], "temperature": 0.0, "avg_logprob": -0.15483861923217773, "compression_ratio": 1.7724867724867726, "no_speech_prob": 0.09661976993083954}, {"id": 480, "seek": 247956, "start": 2486.36, "end": 2491.48, "text": " precisely is not, that's learned. But the desire to, to walk, move around and stand up,", "tokens": [50704, 13402, 307, 406, 11, 300, 311, 3264, 13, 583, 264, 7516, 281, 11, 281, 1792, 11, 1286, 926, 293, 1463, 493, 11, 50960], "temperature": 0.0, "avg_logprob": -0.15483861923217773, "compression_ratio": 1.7724867724867726, "no_speech_prob": 0.09661976993083954}, {"id": 481, "seek": 247956, "start": 2492.7599999999998, "end": 2497.4, "text": " that's sort of hardwired. It's very simple to hardwire this kind of stuff.", "tokens": [51024, 300, 311, 1333, 295, 1152, 86, 1824, 13, 467, 311, 588, 2199, 281, 1152, 42689, 341, 733, 295, 1507, 13, 51256], "temperature": 0.0, "avg_logprob": -0.15483861923217773, "compression_ratio": 1.7724867724867726, "no_speech_prob": 0.09661976993083954}, {"id": 482, "seek": 247956, "start": 2498.84, "end": 2503.96, "text": " Oh, like the desire to, well, that's interesting. You're hardwired to want to walk.", "tokens": [51328, 876, 11, 411, 264, 7516, 281, 11, 731, 11, 300, 311, 1880, 13, 509, 434, 1152, 86, 1824, 281, 528, 281, 1792, 13, 51584], "temperature": 0.0, "avg_logprob": -0.15483861923217773, "compression_ratio": 1.7724867724867726, "no_speech_prob": 0.09661976993083954}, {"id": 483, "seek": 250396, "start": 2504.36, "end": 2511.96, "text": " That's not a, there's got to be a deeper need for walking. I think it was probably socially", "tokens": [50384, 663, 311, 406, 257, 11, 456, 311, 658, 281, 312, 257, 7731, 643, 337, 4494, 13, 286, 519, 309, 390, 1391, 21397, 50764], "temperature": 0.0, "avg_logprob": -0.15999500950177512, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.013633577153086662}, {"id": 484, "seek": 250396, "start": 2511.96, "end": 2517.08, "text": " imposed by society that you need to walk all the other bipedal. No, no, like a lot of simple", "tokens": [50764, 26491, 538, 4086, 300, 291, 643, 281, 1792, 439, 264, 661, 19016, 292, 304, 13, 883, 11, 572, 11, 411, 257, 688, 295, 2199, 51020], "temperature": 0.0, "avg_logprob": -0.15999500950177512, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.013633577153086662}, {"id": 485, "seek": 250396, "start": 2517.08, "end": 2522.84, "text": " animals that, you know, would probably walk without ever watching any other members of the", "tokens": [51020, 4882, 300, 11, 291, 458, 11, 576, 1391, 1792, 1553, 1562, 1976, 604, 661, 2679, 295, 264, 51308], "temperature": 0.0, "avg_logprob": -0.15999500950177512, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.013633577153086662}, {"id": 486, "seek": 250396, "start": 2522.84, "end": 2529.16, "text": " species. It seems like a scary thing to have to do because you suck at bipedal walking at first.", "tokens": [51308, 6172, 13, 467, 2544, 411, 257, 6958, 551, 281, 362, 281, 360, 570, 291, 9967, 412, 19016, 292, 304, 4494, 412, 700, 13, 51624], "temperature": 0.0, "avg_logprob": -0.15999500950177512, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.013633577153086662}, {"id": 487, "seek": 252916, "start": 2529.16, "end": 2534.8399999999997, "text": " It seems crawling is much safer, much more like, why are you in a hurry?", "tokens": [50364, 467, 2544, 32979, 307, 709, 15856, 11, 709, 544, 411, 11, 983, 366, 291, 294, 257, 11025, 30, 50648], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 488, "seek": 252916, "start": 2535.56, "end": 2538.8399999999997, "text": " Well, because, because you have this thing that drives you to do it, you know,", "tokens": [50684, 1042, 11, 570, 11, 570, 291, 362, 341, 551, 300, 11754, 291, 281, 360, 309, 11, 291, 458, 11, 50848], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 489, "seek": 252916, "start": 2540.2, "end": 2544.92, "text": " which is sort of part of the sort of human development.", "tokens": [50916, 597, 307, 1333, 295, 644, 295, 264, 1333, 295, 1952, 3250, 13, 51152], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 490, "seek": 252916, "start": 2544.92, "end": 2546.6, "text": " Is that understood actually what?", "tokens": [51152, 1119, 300, 7320, 767, 437, 30, 51236], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 491, "seek": 252916, "start": 2546.6, "end": 2547.64, "text": " Not entirely, no.", "tokens": [51236, 1726, 7696, 11, 572, 13, 51288], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 492, "seek": 252916, "start": 2547.64, "end": 2551.7999999999997, "text": " What is, what's the reason to get on two feet? It's really hard. Like most animals don't get on", "tokens": [51288, 708, 307, 11, 437, 311, 264, 1778, 281, 483, 322, 732, 3521, 30, 467, 311, 534, 1152, 13, 1743, 881, 4882, 500, 380, 483, 322, 51496], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 493, "seek": 252916, "start": 2551.7999999999997, "end": 2552.7599999999998, "text": " two feet. Why not?", "tokens": [51496, 732, 3521, 13, 1545, 406, 30, 51544], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 494, "seek": 252916, "start": 2552.7599999999998, "end": 2555.72, "text": " Well, they get on four feet. You know, many mammals get on four feet.", "tokens": [51544, 1042, 11, 436, 483, 322, 1451, 3521, 13, 509, 458, 11, 867, 35408, 483, 322, 1451, 3521, 13, 51692], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 495, "seek": 252916, "start": 2555.72, "end": 2556.04, "text": " Yeah, they do.", "tokens": [51692, 865, 11, 436, 360, 13, 51708], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 496, "seek": 252916, "start": 2556.04, "end": 2557.7999999999997, "text": " Very quickly. Some of them extremely quickly.", "tokens": [51708, 4372, 2661, 13, 2188, 295, 552, 4664, 2661, 13, 51796], "temperature": 0.0, "avg_logprob": -0.16453654848296068, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.004981501027941704}, {"id": 497, "seek": 255780, "start": 2558.44, "end": 2562.52, "text": " But I don't, you know, like from the last time I've interacted with a table,", "tokens": [50396, 583, 286, 500, 380, 11, 291, 458, 11, 411, 490, 264, 1036, 565, 286, 600, 49621, 365, 257, 3199, 11, 50600], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 498, "seek": 255780, "start": 2562.52, "end": 2566.36, "text": " that's much more stable than a thing on two legs. It's just a really hard problem.", "tokens": [50600, 300, 311, 709, 544, 8351, 813, 257, 551, 322, 732, 5668, 13, 467, 311, 445, 257, 534, 1152, 1154, 13, 50792], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 499, "seek": 255780, "start": 2566.36, "end": 2568.36, "text": " Yeah, I mean birds have figured it out with two feet.", "tokens": [50792, 865, 11, 286, 914, 9009, 362, 8932, 309, 484, 365, 732, 3521, 13, 50892], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 500, "seek": 255780, "start": 2569.2400000000002, "end": 2574.28, "text": " Well, technically, we can go into ontology. They have four, I guess they have two feet.", "tokens": [50936, 1042, 11, 12120, 11, 321, 393, 352, 666, 6592, 1793, 13, 814, 362, 1451, 11, 286, 2041, 436, 362, 732, 3521, 13, 51188], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 501, "seek": 255780, "start": 2574.28, "end": 2575.0, "text": " They have two feet.", "tokens": [51188, 814, 362, 732, 3521, 13, 51224], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 502, "seek": 255780, "start": 2575.0, "end": 2575.48, "text": " Chickens.", "tokens": [51224, 38930, 694, 13, 51248], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 503, "seek": 255780, "start": 2576.28, "end": 2578.76, "text": " You know, dinosaurs have two feet, many of them.", "tokens": [51288, 509, 458, 11, 25851, 362, 732, 3521, 11, 867, 295, 552, 13, 51412], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 504, "seek": 255780, "start": 2578.76, "end": 2579.4, "text": " Allegedly.", "tokens": [51412, 47486, 13516, 13, 51444], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 505, "seek": 255780, "start": 2581.4, "end": 2585.32, "text": " I'm just now learning that T-Rex was eating grass, not other animals.", "tokens": [51544, 286, 478, 445, 586, 2539, 300, 314, 12, 49, 3121, 390, 3936, 8054, 11, 406, 661, 4882, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14009958155014934, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.0007436529849655926}, {"id": 506, "seek": 258532, "start": 2585.32, "end": 2591.0800000000004, "text": " T-Rex might have been a friendly pet. What do you think about, I don't know if you looked at", "tokens": [50364, 314, 12, 49, 3121, 1062, 362, 668, 257, 9208, 3817, 13, 708, 360, 291, 519, 466, 11, 286, 500, 380, 458, 498, 291, 2956, 412, 50652], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 507, "seek": 258532, "start": 2592.44, "end": 2596.2000000000003, "text": " the test for general intelligence that Francois Chalet put together?", "tokens": [50720, 264, 1500, 337, 2674, 7599, 300, 34695, 271, 761, 49744, 829, 1214, 30, 50908], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 508, "seek": 258532, "start": 2596.2000000000003, "end": 2598.6000000000004, "text": " I don't know if you got a chance to look at that kind of thing.", "tokens": [50908, 286, 500, 380, 458, 498, 291, 658, 257, 2931, 281, 574, 412, 300, 733, 295, 551, 13, 51028], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 509, "seek": 258532, "start": 2598.6000000000004, "end": 2603.6400000000003, "text": " Like what's your intuition about how to solve like an IQ type of test?", "tokens": [51028, 1743, 437, 311, 428, 24002, 466, 577, 281, 5039, 411, 364, 28921, 2010, 295, 1500, 30, 51280], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 510, "seek": 258532, "start": 2603.6400000000003, "end": 2607.32, "text": " I don't know. I think it's so outside of my radar screen that it's not really", "tokens": [51280, 286, 500, 380, 458, 13, 286, 519, 309, 311, 370, 2380, 295, 452, 16544, 2568, 300, 309, 311, 406, 534, 51464], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 511, "seek": 258532, "start": 2608.1200000000003, "end": 2609.88, "text": " relevant, I think in the short term.", "tokens": [51504, 7340, 11, 286, 519, 294, 264, 2099, 1433, 13, 51592], "temperature": 0.0, "avg_logprob": -0.13690895783273796, "compression_ratio": 1.6374501992031874, "no_speech_prob": 0.01589319109916687}, {"id": 512, "seek": 260988, "start": 2610.6, "end": 2615.7200000000003, "text": " Well, I guess one way to ask another way, perhaps more closer to what", "tokens": [50400, 1042, 11, 286, 2041, 472, 636, 281, 1029, 1071, 636, 11, 4317, 544, 4966, 281, 437, 50656], "temperature": 0.0, "avg_logprob": -0.17225486827346514, "compression_ratio": 1.5485074626865671, "no_speech_prob": 0.003119220258668065}, {"id": 513, "seek": 260988, "start": 2616.6, "end": 2622.6, "text": " to your work is like, how do you solve MNIST with very little example data?", "tokens": [50700, 281, 428, 589, 307, 411, 11, 577, 360, 291, 5039, 376, 45, 19756, 365, 588, 707, 1365, 1412, 30, 51000], "temperature": 0.0, "avg_logprob": -0.17225486827346514, "compression_ratio": 1.5485074626865671, "no_speech_prob": 0.003119220258668065}, {"id": 514, "seek": 260988, "start": 2622.6, "end": 2625.8, "text": " That's right. And that's the answer to this probably is self-supervised running.", "tokens": [51000, 663, 311, 558, 13, 400, 300, 311, 264, 1867, 281, 341, 1391, 307, 2698, 12, 48172, 24420, 2614, 13, 51160], "temperature": 0.0, "avg_logprob": -0.17225486827346514, "compression_ratio": 1.5485074626865671, "no_speech_prob": 0.003119220258668065}, {"id": 515, "seek": 260988, "start": 2625.8, "end": 2631.2400000000002, "text": " Just learn to represent images and then learning, you know, to recognize handwritten digits on top", "tokens": [51160, 1449, 1466, 281, 2906, 5267, 293, 550, 2539, 11, 291, 458, 11, 281, 5521, 1011, 26859, 27011, 322, 1192, 51432], "temperature": 0.0, "avg_logprob": -0.17225486827346514, "compression_ratio": 1.5485074626865671, "no_speech_prob": 0.003119220258668065}, {"id": 516, "seek": 260988, "start": 2631.2400000000002, "end": 2637.1600000000003, "text": " of this will only require a few samples. And we observe this in humans, right? You show a", "tokens": [51432, 295, 341, 486, 787, 3651, 257, 1326, 10938, 13, 400, 321, 11441, 341, 294, 6255, 11, 558, 30, 509, 855, 257, 51728], "temperature": 0.0, "avg_logprob": -0.17225486827346514, "compression_ratio": 1.5485074626865671, "no_speech_prob": 0.003119220258668065}, {"id": 517, "seek": 263716, "start": 2637.16, "end": 2641.08, "text": " young child a picture book with a couple of pictures of an elephant and that's it.", "tokens": [50364, 2037, 1440, 257, 3036, 1446, 365, 257, 1916, 295, 5242, 295, 364, 19791, 293, 300, 311, 309, 13, 50560], "temperature": 0.0, "avg_logprob": -0.12244930652656941, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.00666429428383708}, {"id": 518, "seek": 263716, "start": 2641.7999999999997, "end": 2647.0, "text": " The child knows what an elephant is. And we see this today with practical systems that we", "tokens": [50596, 440, 1440, 3255, 437, 364, 19791, 307, 13, 400, 321, 536, 341, 965, 365, 8496, 3652, 300, 321, 50856], "temperature": 0.0, "avg_logprob": -0.12244930652656941, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.00666429428383708}, {"id": 519, "seek": 263716, "start": 2647.96, "end": 2655.64, "text": " train image recognition systems with enormous amounts of images either completely self-supervised", "tokens": [50904, 3847, 3256, 11150, 3652, 365, 11322, 11663, 295, 5267, 2139, 2584, 2698, 12, 48172, 24420, 51288], "temperature": 0.0, "avg_logprob": -0.12244930652656941, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.00666429428383708}, {"id": 520, "seek": 263716, "start": 2655.64, "end": 2661.96, "text": " or very weakly supervised. For example, you can train a neural net to predict whatever", "tokens": [51288, 420, 588, 5336, 356, 46533, 13, 1171, 1365, 11, 291, 393, 3847, 257, 18161, 2533, 281, 6069, 2035, 51604], "temperature": 0.0, "avg_logprob": -0.12244930652656941, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.00666429428383708}, {"id": 521, "seek": 263716, "start": 2661.96, "end": 2665.72, "text": " hashtag people type on Instagram, right? Then you can do this with billions of images because", "tokens": [51604, 20379, 561, 2010, 322, 5281, 11, 558, 30, 1396, 291, 393, 360, 341, 365, 17375, 295, 5267, 570, 51792], "temperature": 0.0, "avg_logprob": -0.12244930652656941, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.00666429428383708}, {"id": 522, "seek": 266572, "start": 2665.7999999999997, "end": 2671.08, "text": " it's billions per day that are showing up. So the amount of training data there is essentially", "tokens": [50368, 309, 311, 17375, 680, 786, 300, 366, 4099, 493, 13, 407, 264, 2372, 295, 3097, 1412, 456, 307, 4476, 50632], "temperature": 0.0, "avg_logprob": -0.10235111735691534, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.0011725551448762417}, {"id": 523, "seek": 266572, "start": 2671.08, "end": 2676.7599999999998, "text": " unlimited. And then you take the output representation, you know, a couple layers down from the outputs", "tokens": [50632, 21950, 13, 400, 550, 291, 747, 264, 5598, 10290, 11, 291, 458, 11, 257, 1916, 7914, 760, 490, 264, 23930, 50916], "temperature": 0.0, "avg_logprob": -0.10235111735691534, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.0011725551448762417}, {"id": 524, "seek": 266572, "start": 2677.56, "end": 2683.08, "text": " of what the system learned and feed this as input to a classifier for any object in the", "tokens": [50956, 295, 437, 264, 1185, 3264, 293, 3154, 341, 382, 4846, 281, 257, 1508, 9902, 337, 604, 2657, 294, 264, 51232], "temperature": 0.0, "avg_logprob": -0.10235111735691534, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.0011725551448762417}, {"id": 525, "seek": 266572, "start": 2683.08, "end": 2687.8799999999997, "text": " world that you want and it works pretty well. So that's transfer learning, okay? Or weekly", "tokens": [51232, 1002, 300, 291, 528, 293, 309, 1985, 1238, 731, 13, 407, 300, 311, 5003, 2539, 11, 1392, 30, 1610, 12460, 51472], "temperature": 0.0, "avg_logprob": -0.10235111735691534, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.0011725551448762417}, {"id": 526, "seek": 266572, "start": 2687.8799999999997, "end": 2694.2799999999997, "text": " supervised transfer learning. People are making very, very fast progress using self-supervised", "tokens": [51472, 46533, 5003, 2539, 13, 3432, 366, 1455, 588, 11, 588, 2370, 4205, 1228, 2698, 12, 48172, 24420, 51792], "temperature": 0.0, "avg_logprob": -0.10235111735691534, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.0011725551448762417}, {"id": 527, "seek": 269428, "start": 2694.28, "end": 2702.36, "text": " learning with this kind of scenario as well. And my guess is that that's going to be the future.", "tokens": [50364, 2539, 365, 341, 733, 295, 9005, 382, 731, 13, 400, 452, 2041, 307, 300, 300, 311, 516, 281, 312, 264, 2027, 13, 50768], "temperature": 0.0, "avg_logprob": -0.11617065947732808, "compression_ratio": 1.5, "no_speech_prob": 0.0041311150416731834}, {"id": 528, "seek": 269428, "start": 2702.36, "end": 2708.28, "text": " For self-supervised learning, how much cleaning do you think is needed for filtering", "tokens": [50768, 1171, 2698, 12, 48172, 24420, 2539, 11, 577, 709, 8924, 360, 291, 519, 307, 2978, 337, 30822, 51064], "temperature": 0.0, "avg_logprob": -0.11617065947732808, "compression_ratio": 1.5, "no_speech_prob": 0.0041311150416731834}, {"id": 529, "seek": 269428, "start": 2710.6000000000004, "end": 2715.48, "text": " malicious signal or with a better term? But a lot of people use hashtags on Instagram", "tokens": [51180, 33496, 6358, 420, 365, 257, 1101, 1433, 30, 583, 257, 688, 295, 561, 764, 50016, 322, 5281, 51424], "temperature": 0.0, "avg_logprob": -0.11617065947732808, "compression_ratio": 1.5, "no_speech_prob": 0.0041311150416731834}, {"id": 530, "seek": 269428, "start": 2716.6800000000003, "end": 2722.2000000000003, "text": " to get good SEO that doesn't fully represent the contents of the image.", "tokens": [51484, 281, 483, 665, 22964, 300, 1177, 380, 4498, 2906, 264, 15768, 295, 264, 3256, 13, 51760], "temperature": 0.0, "avg_logprob": -0.11617065947732808, "compression_ratio": 1.5, "no_speech_prob": 0.0041311150416731834}, {"id": 531, "seek": 272220, "start": 2722.9199999999996, "end": 2728.4399999999996, "text": " Like they'll put a picture of a cat and hashtag it with like science, awesome, fun, I don't know,", "tokens": [50400, 1743, 436, 603, 829, 257, 3036, 295, 257, 3857, 293, 20379, 309, 365, 411, 3497, 11, 3476, 11, 1019, 11, 286, 500, 380, 458, 11, 50676], "temperature": 0.0, "avg_logprob": -0.19542612822159477, "compression_ratio": 1.5335689045936396, "no_speech_prob": 0.01336085144430399}, {"id": 532, "seek": 272220, "start": 2728.4399999999996, "end": 2732.2, "text": " all kind of... Why would you put science? That's not very good SEO.", "tokens": [50676, 439, 733, 295, 485, 1545, 576, 291, 829, 3497, 30, 663, 311, 406, 588, 665, 22964, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19542612822159477, "compression_ratio": 1.5335689045936396, "no_speech_prob": 0.01336085144430399}, {"id": 533, "seek": 272220, "start": 2732.2, "end": 2738.2799999999997, "text": " The way my colleagues who worked on this project at Facebook now, META, META AI,", "tokens": [50864, 440, 636, 452, 7734, 567, 2732, 322, 341, 1716, 412, 4384, 586, 11, 376, 4850, 32, 11, 376, 4850, 32, 7318, 11, 51168], "temperature": 0.0, "avg_logprob": -0.19542612822159477, "compression_ratio": 1.5335689045936396, "no_speech_prob": 0.01336085144430399}, {"id": 534, "seek": 272220, "start": 2738.8399999999997, "end": 2743.64, "text": " a few years ago, they helped with this is that they only selected something like 17,000 tags", "tokens": [51196, 257, 1326, 924, 2057, 11, 436, 4254, 365, 341, 307, 300, 436, 787, 8209, 746, 411, 3282, 11, 1360, 18632, 51436], "temperature": 0.0, "avg_logprob": -0.19542612822159477, "compression_ratio": 1.5335689045936396, "no_speech_prob": 0.01336085144430399}, {"id": 535, "seek": 272220, "start": 2743.64, "end": 2749.64, "text": " that correspond to kind of physical things or situations. Like, you know, that has some visual", "tokens": [51436, 300, 6805, 281, 733, 295, 4001, 721, 420, 6851, 13, 1743, 11, 291, 458, 11, 300, 575, 512, 5056, 51736], "temperature": 0.0, "avg_logprob": -0.19542612822159477, "compression_ratio": 1.5335689045936396, "no_speech_prob": 0.01336085144430399}, {"id": 536, "seek": 274964, "start": 2749.64, "end": 2756.44, "text": " content. So, you wouldn't have like hash TBT or anything like that.", "tokens": [50364, 2701, 13, 407, 11, 291, 2759, 380, 362, 411, 22019, 29711, 51, 420, 1340, 411, 300, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1767022153164478, "compression_ratio": 1.485981308411215, "no_speech_prob": 0.0031225222628563643}, {"id": 537, "seek": 274964, "start": 2757.0, "end": 2761.16, "text": " Also, they keep a very select set of hashtags. Is that what you're saying?", "tokens": [50732, 2743, 11, 436, 1066, 257, 588, 3048, 992, 295, 50016, 13, 1119, 300, 437, 291, 434, 1566, 30, 50940], "temperature": 0.0, "avg_logprob": -0.1767022153164478, "compression_ratio": 1.485981308411215, "no_speech_prob": 0.0031225222628563643}, {"id": 538, "seek": 274964, "start": 2761.16, "end": 2762.04, "text": " Yeah. Okay.", "tokens": [50940, 865, 13, 1033, 13, 50984], "temperature": 0.0, "avg_logprob": -0.1767022153164478, "compression_ratio": 1.485981308411215, "no_speech_prob": 0.0031225222628563643}, {"id": 539, "seek": 274964, "start": 2762.04, "end": 2767.7999999999997, "text": " But it's still on the order of 10 to 20,000. So it's fairly large.", "tokens": [50984, 583, 309, 311, 920, 322, 264, 1668, 295, 1266, 281, 945, 11, 1360, 13, 407, 309, 311, 6457, 2416, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1767022153164478, "compression_ratio": 1.485981308411215, "no_speech_prob": 0.0031225222628563643}, {"id": 540, "seek": 274964, "start": 2767.7999999999997, "end": 2773.96, "text": " Okay. Can you tell me about data augmentation? What the heck is data augmentation? And how is it", "tokens": [51272, 1033, 13, 1664, 291, 980, 385, 466, 1412, 14501, 19631, 30, 708, 264, 12872, 307, 1412, 14501, 19631, 30, 400, 577, 307, 309, 51580], "temperature": 0.0, "avg_logprob": -0.1767022153164478, "compression_ratio": 1.485981308411215, "no_speech_prob": 0.0031225222628563643}, {"id": 541, "seek": 277396, "start": 2773.96, "end": 2780.12, "text": " used maybe contrast of learning for video? What are some cool ideas here?", "tokens": [50364, 1143, 1310, 8712, 295, 2539, 337, 960, 30, 708, 366, 512, 1627, 3487, 510, 30, 50672], "temperature": 0.0, "avg_logprob": -0.15007504549893466, "compression_ratio": 1.696629213483146, "no_speech_prob": 0.006190278567373753}, {"id": 542, "seek": 277396, "start": 2780.76, "end": 2784.68, "text": " Right. So data augmentation, I mean, first, data augmentation, you know, is the idea of", "tokens": [50704, 1779, 13, 407, 1412, 14501, 19631, 11, 286, 914, 11, 700, 11, 1412, 14501, 19631, 11, 291, 458, 11, 307, 264, 1558, 295, 50900], "temperature": 0.0, "avg_logprob": -0.15007504549893466, "compression_ratio": 1.696629213483146, "no_speech_prob": 0.006190278567373753}, {"id": 543, "seek": 277396, "start": 2784.68, "end": 2790.28, "text": " artificially increasing the size of your training set by distorting the images that you have in ways", "tokens": [50900, 39905, 2270, 5662, 264, 2744, 295, 428, 3097, 992, 538, 37555, 278, 264, 5267, 300, 291, 362, 294, 2098, 51180], "temperature": 0.0, "avg_logprob": -0.15007504549893466, "compression_ratio": 1.696629213483146, "no_speech_prob": 0.006190278567373753}, {"id": 544, "seek": 277396, "start": 2790.28, "end": 2794.36, "text": " that don't change the nature of the image. Right? So you take... You do MNIST, you can do data", "tokens": [51180, 300, 500, 380, 1319, 264, 3687, 295, 264, 3256, 13, 1779, 30, 407, 291, 747, 485, 509, 360, 376, 45, 19756, 11, 291, 393, 360, 1412, 51384], "temperature": 0.0, "avg_logprob": -0.15007504549893466, "compression_ratio": 1.696629213483146, "no_speech_prob": 0.006190278567373753}, {"id": 545, "seek": 277396, "start": 2794.36, "end": 2799.56, "text": " augmentation on MNIST, and people have done this since the 1990s, right? You take a MNIST digit", "tokens": [51384, 14501, 19631, 322, 376, 45, 19756, 11, 293, 561, 362, 1096, 341, 1670, 264, 13384, 82, 11, 558, 30, 509, 747, 257, 376, 45, 19756, 14293, 51644], "temperature": 0.0, "avg_logprob": -0.15007504549893466, "compression_ratio": 1.696629213483146, "no_speech_prob": 0.006190278567373753}, {"id": 546, "seek": 279956, "start": 2799.64, "end": 2806.84, "text": " and you shift it a little bit or you change the size or rotate it, skew it, you know, etc.", "tokens": [50368, 293, 291, 5513, 309, 257, 707, 857, 420, 291, 1319, 264, 2744, 420, 13121, 309, 11, 8756, 86, 309, 11, 291, 458, 11, 5183, 13, 50728], "temperature": 0.0, "avg_logprob": -0.11583149909973145, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.06182081252336502}, {"id": 547, "seek": 279956, "start": 2806.84, "end": 2807.56, "text": " Add noise.", "tokens": [50728, 5349, 5658, 13, 50764], "temperature": 0.0, "avg_logprob": -0.11583149909973145, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.06182081252336502}, {"id": 548, "seek": 279956, "start": 2808.2, "end": 2813.4, "text": " Add noise, etc. And it works better. If you train a supervised classifier with augmented data,", "tokens": [50796, 5349, 5658, 11, 5183, 13, 400, 309, 1985, 1101, 13, 759, 291, 3847, 257, 46533, 1508, 9902, 365, 36155, 1412, 11, 51056], "temperature": 0.0, "avg_logprob": -0.11583149909973145, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.06182081252336502}, {"id": 549, "seek": 279956, "start": 2813.4, "end": 2819.96, "text": " you're going to get better results. Now, it's become really interesting over the last couple", "tokens": [51056, 291, 434, 516, 281, 483, 1101, 3542, 13, 823, 11, 309, 311, 1813, 534, 1880, 670, 264, 1036, 1916, 51384], "temperature": 0.0, "avg_logprob": -0.11583149909973145, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.06182081252336502}, {"id": 550, "seek": 279956, "start": 2819.96, "end": 2826.44, "text": " years because a lot of self-supervised learning techniques to pre-train vision systems are based", "tokens": [51384, 924, 570, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7512, 281, 659, 12, 83, 7146, 5201, 3652, 366, 2361, 51708], "temperature": 0.0, "avg_logprob": -0.11583149909973145, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.06182081252336502}, {"id": 551, "seek": 282644, "start": 2826.44, "end": 2834.84, "text": " on data augmentation. And the basic techniques is originally inspired by techniques that I worked", "tokens": [50364, 322, 1412, 14501, 19631, 13, 400, 264, 3875, 7512, 307, 7993, 7547, 538, 7512, 300, 286, 2732, 50784], "temperature": 0.0, "avg_logprob": -0.1377421037866435, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.006705882493406534}, {"id": 552, "seek": 282644, "start": 2834.84, "end": 2838.6, "text": " on in the early 90s and Jeff Hinton worked on also in the early 90s. They were sort of parallel", "tokens": [50784, 322, 294, 264, 2440, 4289, 82, 293, 7506, 389, 12442, 2732, 322, 611, 294, 264, 2440, 4289, 82, 13, 814, 645, 1333, 295, 8952, 50972], "temperature": 0.0, "avg_logprob": -0.1377421037866435, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.006705882493406534}, {"id": 553, "seek": 282644, "start": 2839.4, "end": 2845.0, "text": " work. I used to call this Siamese network. So basically, you take two identical copies of", "tokens": [51012, 589, 13, 286, 1143, 281, 818, 341, 318, 2918, 1130, 3209, 13, 407, 1936, 11, 291, 747, 732, 14800, 14341, 295, 51292], "temperature": 0.0, "avg_logprob": -0.1377421037866435, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.006705882493406534}, {"id": 554, "seek": 282644, "start": 2845.0, "end": 2851.7200000000003, "text": " the same network, they share the same weights, and you show two different views of the same object.", "tokens": [51292, 264, 912, 3209, 11, 436, 2073, 264, 912, 17443, 11, 293, 291, 855, 732, 819, 6809, 295, 264, 912, 2657, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1377421037866435, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.006705882493406534}, {"id": 555, "seek": 282644, "start": 2851.7200000000003, "end": 2855.32, "text": " Either those two different views may have been obtained by data augmentation,", "tokens": [51628, 13746, 729, 732, 819, 6809, 815, 362, 668, 14879, 538, 1412, 14501, 19631, 11, 51808], "temperature": 0.0, "avg_logprob": -0.1377421037866435, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.006705882493406534}, {"id": 556, "seek": 285532, "start": 2855.32, "end": 2859.2400000000002, "text": " or maybe it's two different views of the same scene from a camera that you moved", "tokens": [50364, 420, 1310, 309, 311, 732, 819, 6809, 295, 264, 912, 4145, 490, 257, 2799, 300, 291, 4259, 50560], "temperature": 0.0, "avg_logprob": -0.06854593753814697, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0006984944338910282}, {"id": 557, "seek": 285532, "start": 2859.2400000000002, "end": 2863.1600000000003, "text": " or at different times or something like that, right? Or two pictures of the same person,", "tokens": [50560, 420, 412, 819, 1413, 420, 746, 411, 300, 11, 558, 30, 1610, 732, 5242, 295, 264, 912, 954, 11, 50756], "temperature": 0.0, "avg_logprob": -0.06854593753814697, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0006984944338910282}, {"id": 558, "seek": 285532, "start": 2863.1600000000003, "end": 2868.36, "text": " things like that. And then you train this neural net, those two identical copies of this neural net,", "tokens": [50756, 721, 411, 300, 13, 400, 550, 291, 3847, 341, 18161, 2533, 11, 729, 732, 14800, 14341, 295, 341, 18161, 2533, 11, 51016], "temperature": 0.0, "avg_logprob": -0.06854593753814697, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0006984944338910282}, {"id": 559, "seek": 285532, "start": 2868.36, "end": 2874.44, "text": " to produce an output representation, a vector, in such a way that the representation for those two", "tokens": [51016, 281, 5258, 364, 5598, 10290, 11, 257, 8062, 11, 294, 1270, 257, 636, 300, 264, 10290, 337, 729, 732, 51320], "temperature": 0.0, "avg_logprob": -0.06854593753814697, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0006984944338910282}, {"id": 560, "seek": 285532, "start": 2875.4, "end": 2880.84, "text": " images are as close to each other as possible, as identical to each other as possible, right?", "tokens": [51368, 5267, 366, 382, 1998, 281, 1184, 661, 382, 1944, 11, 382, 14800, 281, 1184, 661, 382, 1944, 11, 558, 30, 51640], "temperature": 0.0, "avg_logprob": -0.06854593753814697, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0006984944338910282}, {"id": 561, "seek": 288084, "start": 2880.84, "end": 2886.04, "text": " Because you want the system to basically learn a function that will be invariant,", "tokens": [50364, 1436, 291, 528, 264, 1185, 281, 1936, 1466, 257, 2445, 300, 486, 312, 33270, 394, 11, 50624], "temperature": 0.0, "avg_logprob": -0.08443400439094095, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.003062907140702009}, {"id": 562, "seek": 288084, "start": 2886.04, "end": 2890.1200000000003, "text": " that will not change, whose output will not change when you transform those inputs", "tokens": [50624, 300, 486, 406, 1319, 11, 6104, 5598, 486, 406, 1319, 562, 291, 4088, 729, 15743, 50828], "temperature": 0.0, "avg_logprob": -0.08443400439094095, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.003062907140702009}, {"id": 563, "seek": 288084, "start": 2890.84, "end": 2897.7200000000003, "text": " in those particular ways, right? So that's easy to do. What's complicated is how do you make sure", "tokens": [50864, 294, 729, 1729, 2098, 11, 558, 30, 407, 300, 311, 1858, 281, 360, 13, 708, 311, 6179, 307, 577, 360, 291, 652, 988, 51208], "temperature": 0.0, "avg_logprob": -0.08443400439094095, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.003062907140702009}, {"id": 564, "seek": 288084, "start": 2897.7200000000003, "end": 2902.52, "text": " that when you show two images that are different, the system will produce different things. Because", "tokens": [51208, 300, 562, 291, 855, 732, 5267, 300, 366, 819, 11, 264, 1185, 486, 5258, 819, 721, 13, 1436, 51448], "temperature": 0.0, "avg_logprob": -0.08443400439094095, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.003062907140702009}, {"id": 565, "seek": 288084, "start": 2902.52, "end": 2907.6400000000003, "text": " if you don't have a specific provision for this, the system will just ignore the inputs", "tokens": [51448, 498, 291, 500, 380, 362, 257, 2685, 17225, 337, 341, 11, 264, 1185, 486, 445, 11200, 264, 15743, 51704], "temperature": 0.0, "avg_logprob": -0.08443400439094095, "compression_ratio": 1.792828685258964, "no_speech_prob": 0.003062907140702009}, {"id": 566, "seek": 290764, "start": 2908.3599999999997, "end": 2911.8799999999997, "text": " when you train it, it will end up ignoring the input and just produce a constant vector that", "tokens": [50400, 562, 291, 3847, 309, 11, 309, 486, 917, 493, 26258, 264, 4846, 293, 445, 5258, 257, 5754, 8062, 300, 50576], "temperature": 0.0, "avg_logprob": -0.09189392780435496, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.003264449071139097}, {"id": 567, "seek": 290764, "start": 2911.8799999999997, "end": 2916.6, "text": " is the same for every input, right? That's called a collapse. Now, how do you avoid collapse?", "tokens": [50576, 307, 264, 912, 337, 633, 4846, 11, 558, 30, 663, 311, 1219, 257, 15584, 13, 823, 11, 577, 360, 291, 5042, 15584, 30, 50812], "temperature": 0.0, "avg_logprob": -0.09189392780435496, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.003264449071139097}, {"id": 568, "seek": 290764, "start": 2916.6, "end": 2923.0, "text": " So there's two ideas. One idea that I proposed in the early 90s with my colleagues at Bell Labs,", "tokens": [50812, 407, 456, 311, 732, 3487, 13, 1485, 1558, 300, 286, 10348, 294, 264, 2440, 4289, 82, 365, 452, 7734, 412, 11485, 40047, 11, 51132], "temperature": 0.0, "avg_logprob": -0.09189392780435496, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.003264449071139097}, {"id": 569, "seek": 290764, "start": 2923.0, "end": 2928.2, "text": " Gene Bromley and a couple other people, which we now call contrastive learning,", "tokens": [51132, 18083, 1603, 298, 3420, 293, 257, 1916, 661, 561, 11, 597, 321, 586, 818, 8712, 488, 2539, 11, 51392], "temperature": 0.0, "avg_logprob": -0.09189392780435496, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.003264449071139097}, {"id": 570, "seek": 290764, "start": 2928.2, "end": 2933.0, "text": " which is to have negative examples, right? So you have pairs of images that you know are different,", "tokens": [51392, 597, 307, 281, 362, 3671, 5110, 11, 558, 30, 407, 291, 362, 15494, 295, 5267, 300, 291, 458, 366, 819, 11, 51632], "temperature": 0.0, "avg_logprob": -0.09189392780435496, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.003264449071139097}, {"id": 571, "seek": 293300, "start": 2933.96, "end": 2939.0, "text": " and you show them to the network and those two copies, and then you push the two output vectors", "tokens": [50412, 293, 291, 855, 552, 281, 264, 3209, 293, 729, 732, 14341, 11, 293, 550, 291, 2944, 264, 732, 5598, 18875, 50664], "temperature": 0.0, "avg_logprob": -0.1788507311531667, "compression_ratio": 1.8477366255144032, "no_speech_prob": 0.003425344591960311}, {"id": 572, "seek": 293300, "start": 2939.0, "end": 2943.72, "text": " away from each other, and they will eventually guarantee that things that are symmetrically", "tokens": [50664, 1314, 490, 1184, 661, 11, 293, 436, 486, 4728, 10815, 300, 721, 300, 366, 14232, 27965, 984, 50900], "temperature": 0.0, "avg_logprob": -0.1788507311531667, "compression_ratio": 1.8477366255144032, "no_speech_prob": 0.003425344591960311}, {"id": 573, "seek": 293300, "start": 2943.72, "end": 2947.4, "text": " similar produce similar representations and things that are different produce different", "tokens": [50900, 2531, 5258, 2531, 33358, 293, 721, 300, 366, 819, 5258, 819, 51084], "temperature": 0.0, "avg_logprob": -0.1788507311531667, "compression_ratio": 1.8477366255144032, "no_speech_prob": 0.003425344591960311}, {"id": 574, "seek": 293300, "start": 2947.4, "end": 2953.24, "text": " representations. We actually came up with this idea for a project of doing signature", "tokens": [51084, 33358, 13, 492, 767, 1361, 493, 365, 341, 1558, 337, 257, 1716, 295, 884, 13397, 51376], "temperature": 0.0, "avg_logprob": -0.1788507311531667, "compression_ratio": 1.8477366255144032, "no_speech_prob": 0.003425344591960311}, {"id": 575, "seek": 293300, "start": 2953.24, "end": 2959.56, "text": " verification. So we would collect signatures from multiple signatures on the same person", "tokens": [51376, 30206, 13, 407, 321, 576, 2500, 32322, 490, 3866, 32322, 322, 264, 912, 954, 51692], "temperature": 0.0, "avg_logprob": -0.1788507311531667, "compression_ratio": 1.8477366255144032, "no_speech_prob": 0.003425344591960311}, {"id": 576, "seek": 295956, "start": 2960.12, "end": 2963.56, "text": " and then train a neural net to produce the same representation, and then", "tokens": [50392, 293, 550, 3847, 257, 18161, 2533, 281, 5258, 264, 912, 10290, 11, 293, 550, 50564], "temperature": 0.0, "avg_logprob": -0.1143599638004893, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0006067418726161122}, {"id": 577, "seek": 295956, "start": 2965.72, "end": 2969.4, "text": " force the system to produce different representation for different signatures.", "tokens": [50672, 3464, 264, 1185, 281, 5258, 819, 10290, 337, 819, 32322, 13, 50856], "temperature": 0.0, "avg_logprob": -0.1143599638004893, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0006067418726161122}, {"id": 578, "seek": 295956, "start": 2970.84, "end": 2976.2799999999997, "text": " This was actually the problem was proposed by people from what was a subsidiary of AT&T at", "tokens": [50928, 639, 390, 767, 264, 1154, 390, 10348, 538, 561, 490, 437, 390, 257, 48296, 822, 295, 8872, 5, 51, 412, 51200], "temperature": 0.0, "avg_logprob": -0.1143599638004893, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0006067418726161122}, {"id": 579, "seek": 295956, "start": 2976.2799999999997, "end": 2982.68, "text": " the time called NCR, and they were interested in storing representation of the signature on the 80", "tokens": [51200, 264, 565, 1219, 426, 18547, 11, 293, 436, 645, 3102, 294, 26085, 10290, 295, 264, 13397, 322, 264, 4688, 51520], "temperature": 0.0, "avg_logprob": -0.1143599638004893, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0006067418726161122}, {"id": 580, "seek": 295956, "start": 2982.68, "end": 2988.52, "text": " bytes of the magnetic strip of a credit card. So we came up with this idea of having a neural", "tokens": [51520, 36088, 295, 264, 12688, 12828, 295, 257, 5397, 2920, 13, 407, 321, 1361, 493, 365, 341, 1558, 295, 1419, 257, 18161, 51812], "temperature": 0.0, "avg_logprob": -0.1143599638004893, "compression_ratio": 1.7755102040816326, "no_speech_prob": 0.0006067418726161122}, {"id": 581, "seek": 298852, "start": 2988.52, "end": 2993.8, "text": " net with 80 outputs that we would quantize on bytes so that we could encode the...", "tokens": [50364, 2533, 365, 4688, 23930, 300, 321, 576, 4426, 1125, 322, 36088, 370, 300, 321, 727, 2058, 1429, 264, 485, 50628], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 582, "seek": 298852, "start": 2993.8, "end": 2997.0, "text": " And that encoding was then used to compare whether the signature matches or not?", "tokens": [50628, 400, 300, 43430, 390, 550, 1143, 281, 6794, 1968, 264, 13397, 10676, 420, 406, 30, 50788], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 583, "seek": 298852, "start": 2997.0, "end": 3001.0, "text": " That's right. So then you would sign, it would run through the neural net, and then you would", "tokens": [50788, 663, 311, 558, 13, 407, 550, 291, 576, 1465, 11, 309, 576, 1190, 807, 264, 18161, 2533, 11, 293, 550, 291, 576, 50988], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 584, "seek": 298852, "start": 3001.0, "end": 3003.4, "text": " compare the output vector to whatever is stored on your card.", "tokens": [50988, 6794, 264, 5598, 8062, 281, 2035, 307, 12187, 322, 428, 2920, 13, 51108], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 585, "seek": 298852, "start": 3003.4, "end": 3004.04, "text": " Did it actually work?", "tokens": [51108, 2589, 309, 767, 589, 30, 51140], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 586, "seek": 298852, "start": 3004.6, "end": 3010.52, "text": " It worked, but they ended up not using it because nobody cares actually. I mean, the", "tokens": [51168, 467, 2732, 11, 457, 436, 4590, 493, 406, 1228, 309, 570, 5079, 12310, 767, 13, 286, 914, 11, 264, 51464], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 587, "seek": 298852, "start": 3011.48, "end": 3017.48, "text": " American financial payment system is incredibly lax in that respect compared to Europe.", "tokens": [51512, 2665, 4669, 10224, 1185, 307, 6252, 635, 87, 294, 300, 3104, 5347, 281, 3315, 13, 51812], "temperature": 0.0, "avg_logprob": -0.15423467682629097, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.0032214170787483454}, {"id": 588, "seek": 301748, "start": 3017.56, "end": 3020.52, "text": " Over the signatures? What's the purpose of the signatures anyway?", "tokens": [50368, 4886, 264, 32322, 30, 708, 311, 264, 4334, 295, 264, 32322, 4033, 30, 50516], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 589, "seek": 301748, "start": 3020.52, "end": 3022.52, "text": " Nobody looks at them, nobody cares.", "tokens": [50516, 9297, 1542, 412, 552, 11, 5079, 12310, 13, 50616], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 590, "seek": 301748, "start": 3025.96, "end": 3029.4, "text": " So that's contrastive learning, right? So you need positive and negative pairs,", "tokens": [50788, 407, 300, 311, 8712, 488, 2539, 11, 558, 30, 407, 291, 643, 3353, 293, 3671, 15494, 11, 50960], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 591, "seek": 301748, "start": 3029.4, "end": 3034.04, "text": " and the problem with that is that even though I had the original paper on this,", "tokens": [50960, 293, 264, 1154, 365, 300, 307, 300, 754, 1673, 286, 632, 264, 3380, 3035, 322, 341, 11, 51192], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 592, "seek": 301748, "start": 3034.68, "end": 3038.6, "text": " I'm actually not very positive about it because it doesn't work in high dimension.", "tokens": [51224, 286, 478, 767, 406, 588, 3353, 466, 309, 570, 309, 1177, 380, 589, 294, 1090, 10139, 13, 51420], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 593, "seek": 301748, "start": 3038.6, "end": 3043.0, "text": " If your representation is high dimensional, there's just too many ways for two things to be", "tokens": [51420, 759, 428, 10290, 307, 1090, 18795, 11, 456, 311, 445, 886, 867, 2098, 337, 732, 721, 281, 312, 51640], "temperature": 0.0, "avg_logprob": -0.15172008367685172, "compression_ratio": 1.6452830188679246, "no_speech_prob": 0.004131898283958435}, {"id": 594, "seek": 304300, "start": 3043.0, "end": 3047.32, "text": " different. And so you would need lots and lots and lots of negative pairs.", "tokens": [50364, 819, 13, 400, 370, 291, 576, 643, 3195, 293, 3195, 293, 3195, 295, 3671, 15494, 13, 50580], "temperature": 0.0, "avg_logprob": -0.193604806456903, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.025796329602599144}, {"id": 595, "seek": 304300, "start": 3048.12, "end": 3053.48, "text": " So there is a particular implementation of this, which is relatively recent, from actually the", "tokens": [50620, 407, 456, 307, 257, 1729, 11420, 295, 341, 11, 597, 307, 7226, 5162, 11, 490, 767, 264, 50888], "temperature": 0.0, "avg_logprob": -0.193604806456903, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.025796329602599144}, {"id": 596, "seek": 304300, "start": 3053.48, "end": 3059.64, "text": " Google Toronto group, where Jeff Hinton is the senior member there, and it's called Simclear,", "tokens": [50888, 3329, 14140, 1594, 11, 689, 7506, 389, 12442, 307, 264, 7965, 4006, 456, 11, 293, 309, 311, 1219, 3998, 43679, 11, 51196], "temperature": 0.0, "avg_logprob": -0.193604806456903, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.025796329602599144}, {"id": 597, "seek": 304300, "start": 3059.64, "end": 3065.4, "text": " S-I-M-C-L-R. And it's basically a particular way of implementing this idea of", "tokens": [51196, 318, 12, 40, 12, 44, 12, 34, 12, 43, 12, 49, 13, 400, 309, 311, 1936, 257, 1729, 636, 295, 18114, 341, 1558, 295, 51484], "temperature": 0.0, "avg_logprob": -0.193604806456903, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.025796329602599144}, {"id": 598, "seek": 304300, "start": 3065.4, "end": 3067.96, "text": " contrastive learning, the particular objective function.", "tokens": [51484, 8712, 488, 2539, 11, 264, 1729, 10024, 2445, 13, 51612], "temperature": 0.0, "avg_logprob": -0.193604806456903, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.025796329602599144}, {"id": 599, "seek": 306796, "start": 3068.6, "end": 3074.84, "text": " Now, what I'm much more enthusiastic about these days is non-contrastive methods. So", "tokens": [50396, 823, 11, 437, 286, 478, 709, 544, 28574, 466, 613, 1708, 307, 2107, 12, 9000, 4148, 488, 7150, 13, 407, 50708], "temperature": 0.0, "avg_logprob": -0.08403175952387791, "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.0013442477211356163}, {"id": 600, "seek": 306796, "start": 3074.84, "end": 3083.0, "text": " other ways to guarantee that the representations would be different for different inputs.", "tokens": [50708, 661, 2098, 281, 10815, 300, 264, 33358, 576, 312, 819, 337, 819, 15743, 13, 51116], "temperature": 0.0, "avg_logprob": -0.08403175952387791, "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.0013442477211356163}, {"id": 601, "seek": 306796, "start": 3084.28, "end": 3089.88, "text": " And it's actually based on an idea that Jeff Hinton proposed in the early 90s with his", "tokens": [51180, 400, 309, 311, 767, 2361, 322, 364, 1558, 300, 7506, 389, 12442, 10348, 294, 264, 2440, 4289, 82, 365, 702, 51460], "temperature": 0.0, "avg_logprob": -0.08403175952387791, "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.0013442477211356163}, {"id": 602, "seek": 306796, "start": 3089.88, "end": 3093.7200000000003, "text": " student at the time, Sue Becker. And it's based on the idea of maximizing the mutual", "tokens": [51460, 3107, 412, 264, 565, 11, 25332, 879, 9178, 13, 400, 309, 311, 2361, 322, 264, 1558, 295, 5138, 3319, 264, 16917, 51652], "temperature": 0.0, "avg_logprob": -0.08403175952387791, "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.0013442477211356163}, {"id": 603, "seek": 306796, "start": 3093.7200000000003, "end": 3097.32, "text": " information between the outputs of the two systems. You only show positive pairs,", "tokens": [51652, 1589, 1296, 264, 23930, 295, 264, 732, 3652, 13, 509, 787, 855, 3353, 15494, 11, 51832], "temperature": 0.0, "avg_logprob": -0.08403175952387791, "compression_ratio": 1.6150943396226416, "no_speech_prob": 0.0013442477211356163}, {"id": 604, "seek": 309732, "start": 3097.32, "end": 3102.2000000000003, "text": " you only show pairs of images that you know are somewhat similar. And you're trying the two", "tokens": [50364, 291, 787, 855, 15494, 295, 5267, 300, 291, 458, 366, 8344, 2531, 13, 400, 291, 434, 1382, 264, 732, 50608], "temperature": 0.0, "avg_logprob": -0.11069525795421381, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.000828809104859829}, {"id": 605, "seek": 309732, "start": 3102.2000000000003, "end": 3110.1200000000003, "text": " networks to be informative, but also to be as informative of each other as possible. So basically,", "tokens": [50608, 9590, 281, 312, 27759, 11, 457, 611, 281, 312, 382, 27759, 295, 1184, 661, 382, 1944, 13, 407, 1936, 11, 51004], "temperature": 0.0, "avg_logprob": -0.11069525795421381, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.000828809104859829}, {"id": 606, "seek": 309732, "start": 3110.1200000000003, "end": 3117.0800000000004, "text": " one representation has to be predictable from the other, essentially. And he proposed that idea", "tokens": [51004, 472, 10290, 575, 281, 312, 27737, 490, 264, 661, 11, 4476, 13, 400, 415, 10348, 300, 1558, 51352], "temperature": 0.0, "avg_logprob": -0.11069525795421381, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.000828809104859829}, {"id": 607, "seek": 309732, "start": 3117.0800000000004, "end": 3122.92, "text": " had a couple of papers in the early 90s, and then nothing was done about it for decades.", "tokens": [51352, 632, 257, 1916, 295, 10577, 294, 264, 2440, 4289, 82, 11, 293, 550, 1825, 390, 1096, 466, 309, 337, 7878, 13, 51644], "temperature": 0.0, "avg_logprob": -0.11069525795421381, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.000828809104859829}, {"id": 608, "seek": 312292, "start": 3123.0, "end": 3129.0, "text": " And I kind of revived this idea together with my postdocs at FAIR, particularly a postdoc called", "tokens": [50368, 400, 286, 733, 295, 48358, 341, 1558, 1214, 365, 452, 2183, 39966, 82, 412, 19894, 7740, 11, 4098, 257, 2183, 39966, 1219, 50668], "temperature": 0.0, "avg_logprob": -0.21655879550509982, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.004576616920530796}, {"id": 609, "seek": 312292, "start": 3129.0, "end": 3135.96, "text": " Steph Anthony, who's now a junior professor in Finland at University of Alto. We came up with", "tokens": [50668, 31418, 15853, 11, 567, 311, 586, 257, 16195, 8304, 294, 24869, 412, 3535, 295, 50066, 13, 492, 1361, 493, 365, 51016], "temperature": 0.0, "avg_logprob": -0.21655879550509982, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.004576616920530796}, {"id": 610, "seek": 312292, "start": 3135.96, "end": 3141.56, "text": " something called, that we call Balu twins. And it's a particular way of maximizing the", "tokens": [51016, 746, 1219, 11, 300, 321, 818, 363, 4929, 22555, 13, 400, 309, 311, 257, 1729, 636, 295, 5138, 3319, 264, 51296], "temperature": 0.0, "avg_logprob": -0.21655879550509982, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.004576616920530796}, {"id": 611, "seek": 312292, "start": 3141.56, "end": 3150.04, "text": " information content of a vector, you know, using some hypothesis. And we have kind of", "tokens": [51296, 1589, 2701, 295, 257, 8062, 11, 291, 458, 11, 1228, 512, 17291, 13, 400, 321, 362, 733, 295, 51720], "temperature": 0.0, "avg_logprob": -0.21655879550509982, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.004576616920530796}, {"id": 612, "seek": 315004, "start": 3151.0, "end": 3155.64, "text": " another version of it that's more recent now called Vicreg, V-I-C-A-R-E-G, that means", "tokens": [50412, 1071, 3037, 295, 309, 300, 311, 544, 5162, 586, 1219, 33316, 3375, 11, 691, 12, 40, 12, 34, 12, 32, 12, 49, 12, 36, 12, 38, 11, 300, 1355, 50644], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 613, "seek": 315004, "start": 3155.64, "end": 3159.88, "text": " variance invariance covariance regularization. And it's the thing I'm the most excited about", "tokens": [50644, 21977, 33270, 719, 49851, 719, 3890, 2144, 13, 400, 309, 311, 264, 551, 286, 478, 264, 881, 2919, 466, 50856], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 614, "seek": 315004, "start": 3159.88, "end": 3164.36, "text": " in machine learning in the last 15 years. I mean, I'm not, I'm really, really excited about this.", "tokens": [50856, 294, 3479, 2539, 294, 264, 1036, 2119, 924, 13, 286, 914, 11, 286, 478, 406, 11, 286, 478, 534, 11, 534, 2919, 466, 341, 13, 51080], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 615, "seek": 315004, "start": 3164.36, "end": 3169.24, "text": " What kind of data augmentation is useful for that non-contrasting learning method?", "tokens": [51080, 708, 733, 295, 1412, 14501, 19631, 307, 4420, 337, 300, 2107, 12, 9000, 4148, 278, 2539, 3170, 30, 51324], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 616, "seek": 315004, "start": 3170.12, "end": 3175.16, "text": " Are we talking about, does that not matter that much? Or it seems like a very important part of", "tokens": [51368, 2014, 321, 1417, 466, 11, 775, 300, 406, 1871, 300, 709, 30, 1610, 309, 2544, 411, 257, 588, 1021, 644, 295, 51620], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 617, "seek": 315004, "start": 3175.16, "end": 3179.48, "text": " the step. Yeah. How you generate the images that are similar, but sufficiently different.", "tokens": [51620, 264, 1823, 13, 865, 13, 1012, 291, 8460, 264, 5267, 300, 366, 2531, 11, 457, 31868, 819, 13, 51836], "temperature": 0.0, "avg_logprob": -0.16118509239620632, "compression_ratio": 1.6366366366366367, "no_speech_prob": 0.007573866285383701}, {"id": 618, "seek": 317948, "start": 3179.48, "end": 3183.0, "text": " Yeah, that's right. It's an important step. And it's also an annoying step because you need to", "tokens": [50364, 865, 11, 300, 311, 558, 13, 467, 311, 364, 1021, 1823, 13, 400, 309, 311, 611, 364, 11304, 1823, 570, 291, 643, 281, 50540], "temperature": 0.0, "avg_logprob": -0.12916401336933003, "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.0018934531835839152}, {"id": 619, "seek": 317948, "start": 3183.0, "end": 3189.32, "text": " have that knowledge of what the documentation you can do that do not change the nature of the", "tokens": [50540, 362, 300, 3601, 295, 437, 264, 14333, 291, 393, 360, 300, 360, 406, 1319, 264, 3687, 295, 264, 50856], "temperature": 0.0, "avg_logprob": -0.12916401336933003, "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.0018934531835839152}, {"id": 620, "seek": 317948, "start": 3189.32, "end": 3196.36, "text": " object. And so the standard scenario, which a lot of people working in this area are using, is you", "tokens": [50856, 2657, 13, 400, 370, 264, 3832, 9005, 11, 597, 257, 688, 295, 561, 1364, 294, 341, 1859, 366, 1228, 11, 307, 291, 51208], "temperature": 0.0, "avg_logprob": -0.12916401336933003, "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.0018934531835839152}, {"id": 621, "seek": 317948, "start": 3196.36, "end": 3203.32, "text": " use the type of distortion. So basically you do geometric distortion. So one basically just shifts", "tokens": [51208, 764, 264, 2010, 295, 28426, 13, 407, 1936, 291, 360, 33246, 28426, 13, 407, 472, 1936, 445, 19201, 51556], "temperature": 0.0, "avg_logprob": -0.12916401336933003, "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.0018934531835839152}, {"id": 622, "seek": 317948, "start": 3203.32, "end": 3207.64, "text": " the image a little bit, it's called cropping. Another one kind of changes the scale a little bit.", "tokens": [51556, 264, 3256, 257, 707, 857, 11, 309, 311, 1219, 4848, 3759, 13, 3996, 472, 733, 295, 2962, 264, 4373, 257, 707, 857, 13, 51772], "temperature": 0.0, "avg_logprob": -0.12916401336933003, "compression_ratio": 1.7664233576642336, "no_speech_prob": 0.0018934531835839152}, {"id": 623, "seek": 320764, "start": 3207.72, "end": 3212.2799999999997, "text": " Another one kind of rotates it. Another one changes the colors. You know, you can do a shift in", "tokens": [50368, 3996, 472, 733, 295, 42133, 309, 13, 3996, 472, 2962, 264, 4577, 13, 509, 458, 11, 291, 393, 360, 257, 5513, 294, 50596], "temperature": 0.0, "avg_logprob": -0.11773251620205966, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010380680905655026}, {"id": 624, "seek": 320764, "start": 3212.2799999999997, "end": 3217.72, "text": " color balance or something like that. Saturation. Another one sort of blurs it. Another one adds", "tokens": [50596, 2017, 4772, 420, 746, 411, 300, 13, 5344, 8167, 13, 3996, 472, 1333, 295, 888, 2156, 309, 13, 3996, 472, 10860, 50868], "temperature": 0.0, "avg_logprob": -0.11773251620205966, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010380680905655026}, {"id": 625, "seek": 320764, "start": 3217.72, "end": 3222.3599999999997, "text": " noise. So you have like a catalog of kind of standard things and people try to use the same", "tokens": [50868, 5658, 13, 407, 291, 362, 411, 257, 19746, 295, 733, 295, 3832, 721, 293, 561, 853, 281, 764, 264, 912, 51100], "temperature": 0.0, "avg_logprob": -0.11773251620205966, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010380680905655026}, {"id": 626, "seek": 320764, "start": 3222.3599999999997, "end": 3227.7999999999997, "text": " ones for different algorithms so that they can compare. But some algorithms, some self-supervised", "tokens": [51100, 2306, 337, 819, 14642, 370, 300, 436, 393, 6794, 13, 583, 512, 14642, 11, 512, 2698, 12, 48172, 24420, 51372], "temperature": 0.0, "avg_logprob": -0.11773251620205966, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010380680905655026}, {"id": 627, "seek": 320764, "start": 3227.7999999999997, "end": 3233.16, "text": " algorithm actually can deal with much bigger, like more aggressive data augmentation and some", "tokens": [51372, 9284, 767, 393, 2028, 365, 709, 3801, 11, 411, 544, 10762, 1412, 14501, 19631, 293, 512, 51640], "temperature": 0.0, "avg_logprob": -0.11773251620205966, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0010380680905655026}, {"id": 628, "seek": 323316, "start": 3233.16, "end": 3237.8799999999997, "text": " don't. So that kind of makes the whole thing difficult. But that's the kind of distortions", "tokens": [50364, 500, 380, 13, 407, 300, 733, 295, 1669, 264, 1379, 551, 2252, 13, 583, 300, 311, 264, 733, 295, 37555, 626, 50600], "temperature": 0.0, "avg_logprob": -0.0962178352031302, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.010268490761518478}, {"id": 629, "seek": 323316, "start": 3237.8799999999997, "end": 3247.24, "text": " we're talking about. And so you train with those distortions. And then you chop off the last layer", "tokens": [50600, 321, 434, 1417, 466, 13, 400, 370, 291, 3847, 365, 729, 37555, 626, 13, 400, 550, 291, 7931, 766, 264, 1036, 4583, 51068], "temperature": 0.0, "avg_logprob": -0.0962178352031302, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.010268490761518478}, {"id": 630, "seek": 323316, "start": 3247.24, "end": 3253.64, "text": " or couple layers of the network. And you use the representation as input to a classifier. You", "tokens": [51068, 420, 1916, 7914, 295, 264, 3209, 13, 400, 291, 764, 264, 10290, 382, 4846, 281, 257, 1508, 9902, 13, 509, 51388], "temperature": 0.0, "avg_logprob": -0.0962178352031302, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.010268490761518478}, {"id": 631, "seek": 323316, "start": 3253.64, "end": 3260.7599999999998, "text": " train the classifier on ImageNet, let's say, or whatever, and measure the performance. And", "tokens": [51388, 3847, 264, 1508, 9902, 322, 29903, 31890, 11, 718, 311, 584, 11, 420, 2035, 11, 293, 3481, 264, 3389, 13, 400, 51744], "temperature": 0.0, "avg_logprob": -0.0962178352031302, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.010268490761518478}, {"id": 632, "seek": 326076, "start": 3261.6400000000003, "end": 3265.96, "text": " interestingly enough, the methods that are really good at eliminating the information that is", "tokens": [50408, 25873, 1547, 11, 264, 7150, 300, 366, 534, 665, 412, 31203, 264, 1589, 300, 307, 50624], "temperature": 0.0, "avg_logprob": -0.08961914976437886, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00023376189346890897}, {"id": 633, "seek": 326076, "start": 3265.96, "end": 3271.32, "text": " irrelevant, which is the distortions between those images, do a good job at eliminating it.", "tokens": [50624, 28682, 11, 597, 307, 264, 37555, 626, 1296, 729, 5267, 11, 360, 257, 665, 1691, 412, 31203, 309, 13, 50892], "temperature": 0.0, "avg_logprob": -0.08961914976437886, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00023376189346890897}, {"id": 634, "seek": 326076, "start": 3272.36, "end": 3277.8, "text": " And as a consequence, you cannot use the representations in those systems for things", "tokens": [50944, 400, 382, 257, 18326, 11, 291, 2644, 764, 264, 33358, 294, 729, 3652, 337, 721, 51216], "temperature": 0.0, "avg_logprob": -0.08961914976437886, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00023376189346890897}, {"id": 635, "seek": 326076, "start": 3277.8, "end": 3283.4, "text": " like object detection and localization because that information is gone. So the type of", "tokens": [51216, 411, 2657, 17784, 293, 2654, 2144, 570, 300, 1589, 307, 2780, 13, 407, 264, 2010, 295, 51496], "temperature": 0.0, "avg_logprob": -0.08961914976437886, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00023376189346890897}, {"id": 636, "seek": 326076, "start": 3283.4, "end": 3288.6000000000004, "text": " data augmentation you need to do depends on the tasks you want eventually the system to solve.", "tokens": [51496, 1412, 14501, 19631, 291, 643, 281, 360, 5946, 322, 264, 9608, 291, 528, 4728, 264, 1185, 281, 5039, 13, 51756], "temperature": 0.0, "avg_logprob": -0.08961914976437886, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00023376189346890897}, {"id": 637, "seek": 328860, "start": 3288.6, "end": 3293.48, "text": " And the type of standard data augmentation that we use today are only appropriate for", "tokens": [50364, 400, 264, 2010, 295, 3832, 1412, 14501, 19631, 300, 321, 764, 965, 366, 787, 6854, 337, 50608], "temperature": 0.0, "avg_logprob": -0.14294659554421366, "compression_ratio": 1.81640625, "no_speech_prob": 0.003705478273332119}, {"id": 638, "seek": 328860, "start": 3293.48, "end": 3297.64, "text": " object recognition or image classification. They're not appropriate for things like...", "tokens": [50608, 2657, 11150, 420, 3256, 21538, 13, 814, 434, 406, 6854, 337, 721, 411, 485, 50816], "temperature": 0.0, "avg_logprob": -0.14294659554421366, "compression_ratio": 1.81640625, "no_speech_prob": 0.003705478273332119}, {"id": 639, "seek": 328860, "start": 3297.64, "end": 3302.04, "text": " Can you help me out understand why the localization... So you're saying it's just not good at the", "tokens": [50816, 1664, 291, 854, 385, 484, 1223, 983, 264, 2654, 2144, 485, 407, 291, 434, 1566, 309, 311, 445, 406, 665, 412, 264, 51036], "temperature": 0.0, "avg_logprob": -0.14294659554421366, "compression_ratio": 1.81640625, "no_speech_prob": 0.003705478273332119}, {"id": 640, "seek": 328860, "start": 3302.04, "end": 3307.7999999999997, "text": " negative, like at classifying the negative. So that's why it can't be used for the localization?", "tokens": [51036, 3671, 11, 411, 412, 1508, 5489, 264, 3671, 13, 407, 300, 311, 983, 309, 393, 380, 312, 1143, 337, 264, 2654, 2144, 30, 51324], "temperature": 0.0, "avg_logprob": -0.14294659554421366, "compression_ratio": 1.81640625, "no_speech_prob": 0.003705478273332119}, {"id": 641, "seek": 328860, "start": 3307.7999999999997, "end": 3313.56, "text": " No, it's just that you train the system, you give it an image and then you give it the same image", "tokens": [51324, 883, 11, 309, 311, 445, 300, 291, 3847, 264, 1185, 11, 291, 976, 309, 364, 3256, 293, 550, 291, 976, 309, 264, 912, 3256, 51612], "temperature": 0.0, "avg_logprob": -0.14294659554421366, "compression_ratio": 1.81640625, "no_speech_prob": 0.003705478273332119}, {"id": 642, "seek": 331356, "start": 3313.56, "end": 3319.0, "text": " shifted and scaled, and you tell it that's the same image. So the system basically is trained", "tokens": [50364, 18892, 293, 36039, 11, 293, 291, 980, 309, 300, 311, 264, 912, 3256, 13, 407, 264, 1185, 1936, 307, 8895, 50636], "temperature": 0.0, "avg_logprob": -0.18465956995042704, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.04531154781579971}, {"id": 643, "seek": 331356, "start": 3319.0, "end": 3324.2, "text": " to eliminate the information about position and size. So now, and now you want to use that", "tokens": [50636, 281, 13819, 264, 1589, 466, 2535, 293, 2744, 13, 407, 586, 11, 293, 586, 291, 528, 281, 764, 300, 50896], "temperature": 0.0, "avg_logprob": -0.18465956995042704, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.04531154781579971}, {"id": 644, "seek": 331356, "start": 3325.0, "end": 3329.32, "text": " to figure out where an object is and what size it is. Like a bounding box, like they'd be able to", "tokens": [50936, 281, 2573, 484, 689, 364, 2657, 307, 293, 437, 2744, 309, 307, 13, 1743, 257, 5472, 278, 2424, 11, 411, 436, 1116, 312, 1075, 281, 51152], "temperature": 0.0, "avg_logprob": -0.18465956995042704, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.04531154781579971}, {"id": 645, "seek": 331356, "start": 3329.32, "end": 3335.88, "text": " actually... Okay, it can still find the object in the image. It's just not very good at finding", "tokens": [51152, 767, 485, 1033, 11, 309, 393, 920, 915, 264, 2657, 294, 264, 3256, 13, 467, 311, 445, 406, 588, 665, 412, 5006, 51480], "temperature": 0.0, "avg_logprob": -0.18465956995042704, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.04531154781579971}, {"id": 646, "seek": 331356, "start": 3335.88, "end": 3342.2799999999997, "text": " the exact boundaries of that object. Interesting. Which, you know, that's an interesting sort of", "tokens": [51480, 264, 1900, 13180, 295, 300, 2657, 13, 14711, 13, 3013, 11, 291, 458, 11, 300, 311, 364, 1880, 1333, 295, 51800], "temperature": 0.0, "avg_logprob": -0.18465956995042704, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.04531154781579971}, {"id": 647, "seek": 334228, "start": 3342.36, "end": 3348.52, "text": " philosophical question. How important is object localization anyway? We're like obsessed by", "tokens": [50368, 25066, 1168, 13, 1012, 1021, 307, 2657, 2654, 2144, 4033, 30, 492, 434, 411, 16923, 538, 50676], "temperature": 0.0, "avg_logprob": -0.11906492082696211, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0005526199238374829}, {"id": 648, "seek": 334228, "start": 3348.52, "end": 3354.1200000000003, "text": " measuring like image segmentation, obsessed by measuring perfectly knowing the boundaries of", "tokens": [50676, 13389, 411, 3256, 9469, 399, 11, 16923, 538, 13389, 6239, 5276, 264, 13180, 295, 50956], "temperature": 0.0, "avg_logprob": -0.11906492082696211, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0005526199238374829}, {"id": 649, "seek": 334228, "start": 3354.1200000000003, "end": 3363.7200000000003, "text": " objects when arguably that's not that essential to understanding what are the contents of the scene.", "tokens": [50956, 6565, 562, 26771, 300, 311, 406, 300, 7115, 281, 3701, 437, 366, 264, 15768, 295, 264, 4145, 13, 51436], "temperature": 0.0, "avg_logprob": -0.11906492082696211, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0005526199238374829}, {"id": 650, "seek": 334228, "start": 3363.7200000000003, "end": 3368.6800000000003, "text": " On the other hand, I think evolutionarily, the first vision systems in animals were basically", "tokens": [51436, 1282, 264, 661, 1011, 11, 286, 519, 9303, 3289, 11, 264, 700, 5201, 3652, 294, 4882, 645, 1936, 51684], "temperature": 0.0, "avg_logprob": -0.11906492082696211, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0005526199238374829}, {"id": 651, "seek": 336868, "start": 3368.68, "end": 3374.3599999999997, "text": " all about localization, very little about recognition. And in the human brain, you have two", "tokens": [50364, 439, 466, 2654, 2144, 11, 588, 707, 466, 11150, 13, 400, 294, 264, 1952, 3567, 11, 291, 362, 732, 50648], "temperature": 0.0, "avg_logprob": -0.11147394947622014, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.004586362279951572}, {"id": 652, "seek": 336868, "start": 3374.3599999999997, "end": 3382.8399999999997, "text": " separate pathways for recognizing the nature of a scene or an object and localizing objects. So", "tokens": [50648, 4994, 22988, 337, 18538, 264, 3687, 295, 257, 4145, 420, 364, 2657, 293, 2654, 3319, 6565, 13, 407, 51072], "temperature": 0.0, "avg_logprob": -0.11147394947622014, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.004586362279951572}, {"id": 653, "seek": 336868, "start": 3382.8399999999997, "end": 3387.8799999999997, "text": " you use the first pathway called the ventral pathway for telling what you're looking at.", "tokens": [51072, 291, 764, 264, 700, 18590, 1219, 264, 6931, 2155, 18590, 337, 3585, 437, 291, 434, 1237, 412, 13, 51324], "temperature": 0.0, "avg_logprob": -0.11147394947622014, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.004586362279951572}, {"id": 654, "seek": 336868, "start": 3389.0, "end": 3394.04, "text": " The other pathway, the dorsal pathway is used for navigation, for grasping, for everything else.", "tokens": [51380, 440, 661, 18590, 11, 264, 274, 830, 304, 18590, 307, 1143, 337, 17346, 11, 337, 29444, 3381, 11, 337, 1203, 1646, 13, 51632], "temperature": 0.0, "avg_logprob": -0.11147394947622014, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.004586362279951572}, {"id": 655, "seek": 339404, "start": 3394.04, "end": 3399.48, "text": " And basically, a lot of the things you need for survival are localization and detection.", "tokens": [50364, 400, 1936, 11, 257, 688, 295, 264, 721, 291, 643, 337, 12559, 366, 2654, 2144, 293, 17784, 13, 50636], "temperature": 0.0, "avg_logprob": -0.09816681970026075, "compression_ratio": 1.738197424892704, "no_speech_prob": 0.0034819089341908693}, {"id": 656, "seek": 339404, "start": 3401.8, "end": 3407.0, "text": " Is similarity learning or contrastive learning or these non-contrastive methods the same as", "tokens": [50752, 1119, 32194, 2539, 420, 8712, 488, 2539, 420, 613, 2107, 12, 9000, 4148, 488, 7150, 264, 912, 382, 51012], "temperature": 0.0, "avg_logprob": -0.09816681970026075, "compression_ratio": 1.738197424892704, "no_speech_prob": 0.0034819089341908693}, {"id": 657, "seek": 339404, "start": 3407.0, "end": 3412.68, "text": " understanding something? Just because you know a distorted cat is the same as a non-distorted cat,", "tokens": [51012, 3701, 746, 30, 1449, 570, 291, 458, 257, 33431, 3857, 307, 264, 912, 382, 257, 2107, 12, 42649, 14813, 3857, 11, 51296], "temperature": 0.0, "avg_logprob": -0.09816681970026075, "compression_ratio": 1.738197424892704, "no_speech_prob": 0.0034819089341908693}, {"id": 658, "seek": 339404, "start": 3412.68, "end": 3415.8, "text": " does that mean you understand what it means to be a cat?", "tokens": [51296, 775, 300, 914, 291, 1223, 437, 309, 1355, 281, 312, 257, 3857, 30, 51452], "temperature": 0.0, "avg_logprob": -0.09816681970026075, "compression_ratio": 1.738197424892704, "no_speech_prob": 0.0034819089341908693}, {"id": 659, "seek": 339404, "start": 3416.6, "end": 3419.96, "text": " To some extent. I mean, it's a superficial understanding, obviously.", "tokens": [51492, 1407, 512, 8396, 13, 286, 914, 11, 309, 311, 257, 34622, 3701, 11, 2745, 13, 51660], "temperature": 0.0, "avg_logprob": -0.09816681970026075, "compression_ratio": 1.738197424892704, "no_speech_prob": 0.0034819089341908693}, {"id": 660, "seek": 341996, "start": 3419.96, "end": 3423.16, "text": " But what is the ceiling of this method, do you think? Is this just one", "tokens": [50364, 583, 437, 307, 264, 13655, 295, 341, 3170, 11, 360, 291, 519, 30, 1119, 341, 445, 472, 50524], "temperature": 0.0, "avg_logprob": -0.11995820249064584, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0036468678154051304}, {"id": 661, "seek": 341996, "start": 3423.88, "end": 3429.96, "text": " trick on the path to doing self-supervised learning or can we go really, really far?", "tokens": [50560, 4282, 322, 264, 3100, 281, 884, 2698, 12, 48172, 24420, 2539, 420, 393, 321, 352, 534, 11, 534, 1400, 30, 50864], "temperature": 0.0, "avg_logprob": -0.11995820249064584, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0036468678154051304}, {"id": 662, "seek": 341996, "start": 3429.96, "end": 3436.6, "text": " I think we can go really far. So if we figure out how to use techniques of that type, perhaps", "tokens": [50864, 286, 519, 321, 393, 352, 534, 1400, 13, 407, 498, 321, 2573, 484, 577, 281, 764, 7512, 295, 300, 2010, 11, 4317, 51196], "temperature": 0.0, "avg_logprob": -0.11995820249064584, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0036468678154051304}, {"id": 663, "seek": 341996, "start": 3436.6, "end": 3443.32, "text": " very different, but of the same nature, to train a system from video to do video prediction,", "tokens": [51196, 588, 819, 11, 457, 295, 264, 912, 3687, 11, 281, 3847, 257, 1185, 490, 960, 281, 360, 960, 17630, 11, 51532], "temperature": 0.0, "avg_logprob": -0.11995820249064584, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0036468678154051304}, {"id": 664, "seek": 344332, "start": 3443.32, "end": 3452.84, "text": " essentially. I think we'll have a path towards, I wouldn't say unlimited, but a path towards", "tokens": [50364, 4476, 13, 286, 519, 321, 603, 362, 257, 3100, 3030, 11, 286, 2759, 380, 584, 21950, 11, 457, 257, 3100, 3030, 50840], "temperature": 0.0, "avg_logprob": -0.15515459102133047, "compression_ratio": 1.4, "no_speech_prob": 0.026235708966851234}, {"id": 665, "seek": 344332, "start": 3452.84, "end": 3464.52, "text": " some level of physical common sense in machines. And I also think that that ability to learn how", "tokens": [50840, 512, 1496, 295, 4001, 2689, 2020, 294, 8379, 13, 400, 286, 611, 519, 300, 300, 3485, 281, 1466, 577, 51424], "temperature": 0.0, "avg_logprob": -0.15515459102133047, "compression_ratio": 1.4, "no_speech_prob": 0.026235708966851234}, {"id": 666, "seek": 346452, "start": 3464.6, "end": 3472.36, "text": " the world works from a high throughput channel like vision is a necessary step towards", "tokens": [50368, 264, 1002, 1985, 490, 257, 1090, 44629, 2269, 411, 5201, 307, 257, 4818, 1823, 3030, 50756], "temperature": 0.0, "avg_logprob": -0.10908761024475097, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.31140148639678955}, {"id": 667, "seek": 346452, "start": 3474.04, "end": 3478.52, "text": " real artificial intelligence. In other words, I believe in grounded intelligence. I don't think", "tokens": [50840, 957, 11677, 7599, 13, 682, 661, 2283, 11, 286, 1697, 294, 23535, 7599, 13, 286, 500, 380, 519, 51064], "temperature": 0.0, "avg_logprob": -0.10908761024475097, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.31140148639678955}, {"id": 668, "seek": 346452, "start": 3478.52, "end": 3484.28, "text": " we can train a machine to be intelligent purely from text. Because I think the amount of information", "tokens": [51064, 321, 393, 3847, 257, 3479, 281, 312, 13232, 17491, 490, 2487, 13, 1436, 286, 519, 264, 2372, 295, 1589, 51352], "temperature": 0.0, "avg_logprob": -0.10908761024475097, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.31140148639678955}, {"id": 669, "seek": 346452, "start": 3484.28, "end": 3489.64, "text": " about the world that's contained in text is tiny compared to what we need to know.", "tokens": [51352, 466, 264, 1002, 300, 311, 16212, 294, 2487, 307, 5870, 5347, 281, 437, 321, 643, 281, 458, 13, 51620], "temperature": 0.0, "avg_logprob": -0.10908761024475097, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.31140148639678955}, {"id": 670, "seek": 348964, "start": 3490.2799999999997, "end": 3497.72, "text": " So, for example, people have attempted to do this for 30 years, the SAG project and things", "tokens": [50396, 407, 11, 337, 1365, 11, 561, 362, 18997, 281, 360, 341, 337, 2217, 924, 11, 264, 16482, 38, 1716, 293, 721, 50768], "temperature": 0.0, "avg_logprob": -0.17173343234592015, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.033478934317827225}, {"id": 671, "seek": 348964, "start": 3497.72, "end": 3503.48, "text": " like that, of basically writing down all the facts that are known and hoping that some sort", "tokens": [50768, 411, 300, 11, 295, 1936, 3579, 760, 439, 264, 9130, 300, 366, 2570, 293, 7159, 300, 512, 1333, 51056], "temperature": 0.0, "avg_logprob": -0.17173343234592015, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.033478934317827225}, {"id": 672, "seek": 348964, "start": 3503.48, "end": 3508.2, "text": " of common sense would emerge. I think it's basically hopeless. But let me take an example.", "tokens": [51056, 295, 2689, 2020, 576, 21511, 13, 286, 519, 309, 311, 1936, 27317, 13, 583, 718, 385, 747, 364, 1365, 13, 51292], "temperature": 0.0, "avg_logprob": -0.17173343234592015, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.033478934317827225}, {"id": 673, "seek": 348964, "start": 3508.2, "end": 3513.4, "text": " You take an object. I describe a situation to you. I take an object, I put it on the table,", "tokens": [51292, 509, 747, 364, 2657, 13, 286, 6786, 257, 2590, 281, 291, 13, 286, 747, 364, 2657, 11, 286, 829, 309, 322, 264, 3199, 11, 51552], "temperature": 0.0, "avg_logprob": -0.17173343234592015, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.033478934317827225}, {"id": 674, "seek": 348964, "start": 3513.4, "end": 3518.52, "text": " and I push the table. It's completely obvious to you that the object will be pushed with the table,", "tokens": [51552, 293, 286, 2944, 264, 3199, 13, 467, 311, 2584, 6322, 281, 291, 300, 264, 2657, 486, 312, 9152, 365, 264, 3199, 11, 51808], "temperature": 0.0, "avg_logprob": -0.17173343234592015, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.033478934317827225}, {"id": 675, "seek": 351852, "start": 3519.08, "end": 3524.28, "text": " because it's sitting on it. There's no text in the world, I believe, that explains this.", "tokens": [50392, 570, 309, 311, 3798, 322, 309, 13, 821, 311, 572, 2487, 294, 264, 1002, 11, 286, 1697, 11, 300, 13948, 341, 13, 50652], "temperature": 0.0, "avg_logprob": -0.12089468843193464, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.001476492267102003}, {"id": 676, "seek": 351852, "start": 3524.92, "end": 3533.8, "text": " And so, if you train a machine as powerful as it could be, your GPT 5000 or whatever it is,", "tokens": [50684, 400, 370, 11, 498, 291, 3847, 257, 3479, 382, 4005, 382, 309, 727, 312, 11, 428, 26039, 51, 23777, 420, 2035, 309, 307, 11, 51128], "temperature": 0.0, "avg_logprob": -0.12089468843193464, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.001476492267102003}, {"id": 677, "seek": 351852, "start": 3533.8, "end": 3540.2, "text": " it's never going to learn about this. That information is just not present in any text.", "tokens": [51128, 309, 311, 1128, 516, 281, 1466, 466, 341, 13, 663, 1589, 307, 445, 406, 1974, 294, 604, 2487, 13, 51448], "temperature": 0.0, "avg_logprob": -0.12089468843193464, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.001476492267102003}, {"id": 678, "seek": 351852, "start": 3540.92, "end": 3544.6, "text": " Well, the question with the SAG project, the dream I think is to have like", "tokens": [51484, 1042, 11, 264, 1168, 365, 264, 16482, 38, 1716, 11, 264, 3055, 286, 519, 307, 281, 362, 411, 51668], "temperature": 0.0, "avg_logprob": -0.12089468843193464, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.001476492267102003}, {"id": 679, "seek": 354460, "start": 3545.56, "end": 3554.68, "text": " 10 million, say, facts like that, that give you a head start, like a parent guiding you.", "tokens": [50412, 1266, 2459, 11, 584, 11, 9130, 411, 300, 11, 300, 976, 291, 257, 1378, 722, 11, 411, 257, 2596, 25061, 291, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1729709506034851, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.006689311936497688}, {"id": 680, "seek": 354460, "start": 3555.4, "end": 3558.44, "text": " Now, we humans don't need a parent to tell us that the table will move,", "tokens": [50904, 823, 11, 321, 6255, 500, 380, 643, 257, 2596, 281, 980, 505, 300, 264, 3199, 486, 1286, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1729709506034851, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.006689311936497688}, {"id": 681, "seek": 354460, "start": 3559.08, "end": 3565.7999999999997, "text": " sorry, the smartphone will move with the table. But we get a lot of guidance in other ways,", "tokens": [51088, 2597, 11, 264, 13307, 486, 1286, 365, 264, 3199, 13, 583, 321, 483, 257, 688, 295, 10056, 294, 661, 2098, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1729709506034851, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.006689311936497688}, {"id": 682, "seek": 354460, "start": 3565.7999999999997, "end": 3568.2, "text": " so it's possible that we can give it a quick shortcut.", "tokens": [51424, 370, 309, 311, 1944, 300, 321, 393, 976, 309, 257, 1702, 24822, 13, 51544], "temperature": 0.0, "avg_logprob": -0.1729709506034851, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.006689311936497688}, {"id": 683, "seek": 354460, "start": 3568.2, "end": 3570.04, "text": " And what about cat? The cat knows that.", "tokens": [51544, 400, 437, 466, 3857, 30, 440, 3857, 3255, 300, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1729709506034851, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.006689311936497688}, {"id": 684, "seek": 357004, "start": 3570.92, "end": 3574.36, "text": " No, but they evolved. No, they learned like us.", "tokens": [50408, 883, 11, 457, 436, 14178, 13, 883, 11, 436, 3264, 411, 505, 13, 50580], "temperature": 0.0, "avg_logprob": -0.21822221595120717, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0031708148308098316}, {"id": 685, "seek": 357004, "start": 3575.96, "end": 3585.4, "text": " Sorry, the physics of stuff. Well, yeah, so you're putting a lot of intelligence onto the", "tokens": [50660, 4919, 11, 264, 10649, 295, 1507, 13, 1042, 11, 1338, 11, 370, 291, 434, 3372, 257, 688, 295, 7599, 3911, 264, 51132], "temperature": 0.0, "avg_logprob": -0.21822221595120717, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0031708148308098316}, {"id": 686, "seek": 357004, "start": 3585.4, "end": 3593.56, "text": " nurture side, not the nature. There's a very inefficient, arguably, process of evolution", "tokens": [51132, 41451, 1252, 11, 406, 264, 3687, 13, 821, 311, 257, 588, 43495, 11, 26771, 11, 1399, 295, 9303, 51540], "temperature": 0.0, "avg_logprob": -0.21822221595120717, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0031708148308098316}, {"id": 687, "seek": 357004, "start": 3593.56, "end": 3599.8, "text": " that got us from bacteria to who we are today. Started at the bottom, now we're here.", "tokens": [51540, 300, 658, 505, 490, 11763, 281, 567, 321, 366, 965, 13, 39715, 412, 264, 2767, 11, 586, 321, 434, 510, 13, 51852], "temperature": 0.0, "avg_logprob": -0.21822221595120717, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.0031708148308098316}, {"id": 688, "seek": 359980, "start": 3599.8, "end": 3607.6400000000003, "text": " So the question is how fundamental is that the nature of the whole hardware?", "tokens": [50364, 407, 264, 1168, 307, 577, 8088, 307, 300, 264, 3687, 295, 264, 1379, 8837, 30, 50756], "temperature": 0.0, "avg_logprob": -0.13645846048990887, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.00034587958361953497}, {"id": 689, "seek": 359980, "start": 3608.52, "end": 3614.2000000000003, "text": " And then is there any way to shortcut it if it's fundamental? If it's not, if it's most of intelligence,", "tokens": [50800, 400, 550, 307, 456, 604, 636, 281, 24822, 309, 498, 309, 311, 8088, 30, 759, 309, 311, 406, 11, 498, 309, 311, 881, 295, 7599, 11, 51084], "temperature": 0.0, "avg_logprob": -0.13645846048990887, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.00034587958361953497}, {"id": 690, "seek": 359980, "start": 3614.2000000000003, "end": 3619.0800000000004, "text": " most of the cool stuff we've been talking about is mostly nurture, mostly trained. We figured", "tokens": [51084, 881, 295, 264, 1627, 1507, 321, 600, 668, 1417, 466, 307, 5240, 41451, 11, 5240, 8895, 13, 492, 8932, 51328], "temperature": 0.0, "avg_logprob": -0.13645846048990887, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.00034587958361953497}, {"id": 691, "seek": 359980, "start": 3619.0800000000004, "end": 3625.0, "text": " out by observing the world. We can form that big, beautiful, sexy background model that you're", "tokens": [51328, 484, 538, 22107, 264, 1002, 13, 492, 393, 1254, 300, 955, 11, 2238, 11, 13701, 3678, 2316, 300, 291, 434, 51624], "temperature": 0.0, "avg_logprob": -0.13645846048990887, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.00034587958361953497}, {"id": 692, "seek": 362500, "start": 3625.0, "end": 3632.12, "text": " talking about just by sitting there. Then, okay, then you need to then like maybe", "tokens": [50364, 1417, 466, 445, 538, 3798, 456, 13, 1396, 11, 1392, 11, 550, 291, 643, 281, 550, 411, 1310, 50720], "temperature": 0.0, "avg_logprob": -0.1490763028462728, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.01080058328807354}, {"id": 693, "seek": 362500, "start": 3634.76, "end": 3638.76, "text": " it is all supervised learning all the way down. It's all supervised learning.", "tokens": [50852, 309, 307, 439, 46533, 2539, 439, 264, 636, 760, 13, 467, 311, 439, 46533, 2539, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1490763028462728, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.01080058328807354}, {"id": 694, "seek": 362500, "start": 3638.76, "end": 3644.92, "text": " Whatever it is that makes human intelligence different from other animals, which a lot of", "tokens": [51052, 8541, 309, 307, 300, 1669, 1952, 7599, 819, 490, 661, 4882, 11, 597, 257, 688, 295, 51360], "temperature": 0.0, "avg_logprob": -0.1490763028462728, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.01080058328807354}, {"id": 695, "seek": 362500, "start": 3644.92, "end": 3649.8, "text": " people think is language and logical reasoning and this kind of stuff. It cannot be that complicated", "tokens": [51360, 561, 519, 307, 2856, 293, 14978, 21577, 293, 341, 733, 295, 1507, 13, 467, 2644, 312, 300, 6179, 51604], "temperature": 0.0, "avg_logprob": -0.1490763028462728, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.01080058328807354}, {"id": 696, "seek": 364980, "start": 3649.8, "end": 3659.1600000000003, "text": " because it only popped up in the last million years. It only involves less than 1% of a genome,", "tokens": [50364, 570, 309, 787, 21545, 493, 294, 264, 1036, 2459, 924, 13, 467, 787, 11626, 1570, 813, 502, 4, 295, 257, 21953, 11, 50832], "temperature": 0.0, "avg_logprob": -0.1607663487813559, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.01541555393487215}, {"id": 697, "seek": 364980, "start": 3659.1600000000003, "end": 3663.5600000000004, "text": " right, which is the difference between human genome and chimps or whatever. So", "tokens": [50832, 558, 11, 597, 307, 264, 2649, 1296, 1952, 21953, 293, 18375, 1878, 420, 2035, 13, 407, 51052], "temperature": 0.0, "avg_logprob": -0.1607663487813559, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.01541555393487215}, {"id": 698, "seek": 364980, "start": 3665.48, "end": 3670.76, "text": " it can be that complicated. It can be that fundamental. Most of the so complicated stuff", "tokens": [51148, 309, 393, 312, 300, 6179, 13, 467, 393, 312, 300, 8088, 13, 4534, 295, 264, 370, 6179, 1507, 51412], "temperature": 0.0, "avg_logprob": -0.1607663487813559, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.01541555393487215}, {"id": 699, "seek": 364980, "start": 3670.76, "end": 3675.5600000000004, "text": " already exist in cats and dogs and certainly primates, non-human primates.", "tokens": [51412, 1217, 2514, 294, 11111, 293, 7197, 293, 3297, 2886, 1024, 11, 2107, 12, 18796, 2886, 1024, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1607663487813559, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.01541555393487215}, {"id": 700, "seek": 367556, "start": 3675.88, "end": 3682.44, "text": " Yeah, that little thing with humans might be just something about social interaction and", "tokens": [50380, 865, 11, 300, 707, 551, 365, 6255, 1062, 312, 445, 746, 466, 2093, 9285, 293, 50708], "temperature": 0.0, "avg_logprob": -0.1199961442213792, "compression_ratio": 1.4885844748858448, "no_speech_prob": 0.0017000152729451656}, {"id": 701, "seek": 367556, "start": 3682.44, "end": 3690.2, "text": " ability to maintain ideas across like a collective of people. It sounds very dramatic and very", "tokens": [50708, 3485, 281, 6909, 3487, 2108, 411, 257, 12590, 295, 561, 13, 467, 3263, 588, 12023, 293, 588, 51096], "temperature": 0.0, "avg_logprob": -0.1199961442213792, "compression_ratio": 1.4885844748858448, "no_speech_prob": 0.0017000152729451656}, {"id": 702, "seek": 367556, "start": 3690.2, "end": 3693.24, "text": " impressive, but it probably isn't mechanistically speaking.", "tokens": [51096, 8992, 11, 457, 309, 1391, 1943, 380, 4236, 20458, 4124, 13, 51248], "temperature": 0.0, "avg_logprob": -0.1199961442213792, "compression_ratio": 1.4885844748858448, "no_speech_prob": 0.0017000152729451656}, {"id": 703, "seek": 367556, "start": 3693.24, "end": 3700.92, "text": " It is, but we're not there yet. We have, I mean, this is number 634 in the list of", "tokens": [51248, 467, 307, 11, 457, 321, 434, 406, 456, 1939, 13, 492, 362, 11, 286, 914, 11, 341, 307, 1230, 1386, 12249, 294, 264, 1329, 295, 51632], "temperature": 0.0, "avg_logprob": -0.1199961442213792, "compression_ratio": 1.4885844748858448, "no_speech_prob": 0.0017000152729451656}, {"id": 704, "seek": 370092, "start": 3700.92, "end": 3707.2400000000002, "text": " problems we have to solve. So basic physics of the world is number one. What are you,", "tokens": [50364, 2740, 321, 362, 281, 5039, 13, 407, 3875, 10649, 295, 264, 1002, 307, 1230, 472, 13, 708, 366, 291, 11, 50680], "temperature": 0.0, "avg_logprob": -0.1374302714704031, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003426087787374854}, {"id": 705, "seek": 370092, "start": 3708.2000000000003, "end": 3716.76, "text": " just a quick tangent on data augmentation. So a lot of it is hard coded versus learned.", "tokens": [50728, 445, 257, 1702, 27747, 322, 1412, 14501, 19631, 13, 407, 257, 688, 295, 309, 307, 1152, 34874, 5717, 3264, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1374302714704031, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003426087787374854}, {"id": 706, "seek": 370092, "start": 3718.2000000000003, "end": 3722.84, "text": " Do you have any intuition that maybe there could be some weird data augmentation,", "tokens": [51228, 1144, 291, 362, 604, 24002, 300, 1310, 456, 727, 312, 512, 3657, 1412, 14501, 19631, 11, 51460], "temperature": 0.0, "avg_logprob": -0.1374302714704031, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003426087787374854}, {"id": 707, "seek": 370092, "start": 3723.56, "end": 3728.28, "text": " like generative type of data augmentation, like doing something weird to images, which", "tokens": [51496, 411, 1337, 1166, 2010, 295, 1412, 14501, 19631, 11, 411, 884, 746, 3657, 281, 5267, 11, 597, 51732], "temperature": 0.0, "avg_logprob": -0.1374302714704031, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003426087787374854}, {"id": 708, "seek": 372828, "start": 3728.28, "end": 3736.1200000000003, "text": " then improves the similarity learning process. So not just kind of dumb, simple distortions,", "tokens": [50364, 550, 24771, 264, 32194, 2539, 1399, 13, 407, 406, 445, 733, 295, 10316, 11, 2199, 37555, 626, 11, 50756], "temperature": 0.0, "avg_logprob": -0.1360593318939209, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.0019539666827768087}, {"id": 709, "seek": 372828, "start": 3736.1200000000003, "end": 3740.76, "text": " but by you shaking your head, just saying that even simple distortions are enough.", "tokens": [50756, 457, 538, 291, 15415, 428, 1378, 11, 445, 1566, 300, 754, 2199, 37555, 626, 366, 1547, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1360593318939209, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.0019539666827768087}, {"id": 710, "seek": 372828, "start": 3740.76, "end": 3744.84, "text": " I think no, I think data augmentation is a temporary necessary evil.", "tokens": [50988, 286, 519, 572, 11, 286, 519, 1412, 14501, 19631, 307, 257, 13413, 4818, 6724, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1360593318939209, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.0019539666827768087}, {"id": 711, "seek": 372828, "start": 3746.36, "end": 3751.8, "text": " So what people are working on now is two things. One is the type of self-supervisioning,", "tokens": [51268, 407, 437, 561, 366, 1364, 322, 586, 307, 732, 721, 13, 1485, 307, 264, 2010, 295, 2698, 12, 48172, 6763, 278, 11, 51540], "temperature": 0.0, "avg_logprob": -0.1360593318939209, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.0019539666827768087}, {"id": 712, "seek": 372828, "start": 3753.0800000000004, "end": 3756.92, "text": " like trying to translate the type of self-supervisioning people using language,", "tokens": [51604, 411, 1382, 281, 13799, 264, 2010, 295, 2698, 12, 48172, 6763, 278, 561, 1228, 2856, 11, 51796], "temperature": 0.0, "avg_logprob": -0.1360593318939209, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.0019539666827768087}, {"id": 713, "seek": 375692, "start": 3757.0, "end": 3761.08, "text": " translating these two images, which is basically a denosing autoencoder method.", "tokens": [50368, 35030, 613, 732, 5267, 11, 597, 307, 1936, 257, 1441, 6110, 8399, 22660, 19866, 3170, 13, 50572], "temperature": 0.0, "avg_logprob": -0.09681127184913271, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00721782399341464}, {"id": 714, "seek": 375692, "start": 3761.7200000000003, "end": 3769.32, "text": " So you take an image, you block, you mask some parts of it, and then you train some giant neural", "tokens": [50604, 407, 291, 747, 364, 3256, 11, 291, 3461, 11, 291, 6094, 512, 3166, 295, 309, 11, 293, 550, 291, 3847, 512, 7410, 18161, 50984], "temperature": 0.0, "avg_logprob": -0.09681127184913271, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00721782399341464}, {"id": 715, "seek": 375692, "start": 3769.32, "end": 3777.64, "text": " net to reconstruct the parts that are missing. And until very recently, there was no working", "tokens": [50984, 2533, 281, 31499, 264, 3166, 300, 366, 5361, 13, 400, 1826, 588, 3938, 11, 456, 390, 572, 1364, 51400], "temperature": 0.0, "avg_logprob": -0.09681127184913271, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00721782399341464}, {"id": 716, "seek": 375692, "start": 3777.64, "end": 3782.36, "text": " methods for that. All the autoencoder type methods for images weren't producing very", "tokens": [51400, 7150, 337, 300, 13, 1057, 264, 8399, 22660, 19866, 2010, 7150, 337, 5267, 4999, 380, 10501, 588, 51636], "temperature": 0.0, "avg_logprob": -0.09681127184913271, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00721782399341464}, {"id": 717, "seek": 378236, "start": 3782.36, "end": 3787.2400000000002, "text": " good representation. But there's a paper now coming out of the Fair Group at Immelo Park", "tokens": [50364, 665, 10290, 13, 583, 456, 311, 257, 3035, 586, 1348, 484, 295, 264, 12157, 10500, 412, 17322, 10590, 4964, 50608], "temperature": 0.0, "avg_logprob": -0.1718563978699432, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.023295234888792038}, {"id": 718, "seek": 378236, "start": 3787.2400000000002, "end": 3793.08, "text": " that actually works very well. So that doesn't require the documentation, that requires only", "tokens": [50608, 300, 767, 1985, 588, 731, 13, 407, 300, 1177, 380, 3651, 264, 14333, 11, 300, 7029, 787, 50900], "temperature": 0.0, "avg_logprob": -0.1718563978699432, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.023295234888792038}, {"id": 719, "seek": 378236, "start": 3793.08, "end": 3800.44, "text": " masking. Okay. Only masking for images. Okay. Right. So you mask a part of the image and you", "tokens": [50900, 31226, 13, 1033, 13, 5686, 31226, 337, 5267, 13, 1033, 13, 1779, 13, 407, 291, 6094, 257, 644, 295, 264, 3256, 293, 291, 51268], "temperature": 0.0, "avg_logprob": -0.1718563978699432, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.023295234888792038}, {"id": 720, "seek": 378236, "start": 3800.44, "end": 3808.52, "text": " train a system, which in this case is a transformer because the transformer represents the image as", "tokens": [51268, 3847, 257, 1185, 11, 597, 294, 341, 1389, 307, 257, 31782, 570, 264, 31782, 8855, 264, 3256, 382, 51672], "temperature": 0.0, "avg_logprob": -0.1718563978699432, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.023295234888792038}, {"id": 721, "seek": 380852, "start": 3809.24, "end": 3813.16, "text": " non-overlapping patches. So it's easy to mask patches and things like that.", "tokens": [50400, 2107, 12, 3570, 15639, 26531, 13, 407, 309, 311, 1858, 281, 6094, 26531, 293, 721, 411, 300, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1635902276199855, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.007340527605265379}, {"id": 722, "seek": 380852, "start": 3813.16, "end": 3818.7599999999998, "text": " Okay. Then my question transfers to that problem, then masking. Why should the mask be a square", "tokens": [50596, 1033, 13, 1396, 452, 1168, 29137, 281, 300, 1154, 11, 550, 31226, 13, 1545, 820, 264, 6094, 312, 257, 3732, 50876], "temperature": 0.0, "avg_logprob": -0.1635902276199855, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.007340527605265379}, {"id": 723, "seek": 380852, "start": 3818.7599999999998, "end": 3826.52, "text": " rectangle? So it doesn't matter. I think we're gonna come up probably in the future with ways", "tokens": [50876, 21930, 30, 407, 309, 1177, 380, 1871, 13, 286, 519, 321, 434, 799, 808, 493, 1391, 294, 264, 2027, 365, 2098, 51264], "temperature": 0.0, "avg_logprob": -0.1635902276199855, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.007340527605265379}, {"id": 724, "seek": 380852, "start": 3826.52, "end": 3832.84, "text": " to mask that are kind of random, essentially. I mean, they are random already, but...", "tokens": [51264, 281, 6094, 300, 366, 733, 295, 4974, 11, 4476, 13, 286, 914, 11, 436, 366, 4974, 1217, 11, 457, 485, 51580], "temperature": 0.0, "avg_logprob": -0.1635902276199855, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.007340527605265379}, {"id": 725, "seek": 383284, "start": 3832.84, "end": 3841.48, "text": " No, no. But something that's challenging, optimally challenging. So maybe it's a metaphor", "tokens": [50364, 883, 11, 572, 13, 583, 746, 300, 311, 7595, 11, 5028, 379, 7595, 13, 407, 1310, 309, 311, 257, 19157, 50796], "temperature": 0.0, "avg_logprob": -0.1957162491818692, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.002629420952871442}, {"id": 726, "seek": 383284, "start": 3841.48, "end": 3848.1200000000003, "text": " that doesn't apply, but it seems like there's a data augmentation or masking. There's an", "tokens": [50796, 300, 1177, 380, 3079, 11, 457, 309, 2544, 411, 456, 311, 257, 1412, 14501, 19631, 420, 31226, 13, 821, 311, 364, 51128], "temperature": 0.0, "avg_logprob": -0.1957162491818692, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.002629420952871442}, {"id": 727, "seek": 383284, "start": 3848.1200000000003, "end": 3853.88, "text": " interactive element with it. You're almost playing with an image, and it's the way we", "tokens": [51128, 15141, 4478, 365, 309, 13, 509, 434, 1920, 2433, 365, 364, 3256, 11, 293, 309, 311, 264, 636, 321, 51416], "temperature": 0.0, "avg_logprob": -0.1957162491818692, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.002629420952871442}, {"id": 728, "seek": 383284, "start": 3853.88, "end": 3857.96, "text": " play with an image in our minds. No, but it's like dropout. It's like Boston Machine Training.", "tokens": [51416, 862, 365, 364, 3256, 294, 527, 9634, 13, 883, 11, 457, 309, 311, 411, 3270, 346, 13, 467, 311, 411, 12333, 22155, 20620, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1957162491818692, "compression_ratio": 1.617117117117117, "no_speech_prob": 0.002629420952871442}, {"id": 729, "seek": 385796, "start": 3858.76, "end": 3868.92, "text": " You know, every time you see a percept, you can perturb it in some way. And then the principle", "tokens": [50404, 509, 458, 11, 633, 565, 291, 536, 257, 43276, 11, 291, 393, 40468, 309, 294, 512, 636, 13, 400, 550, 264, 8665, 50912], "temperature": 0.0, "avg_logprob": -0.15539204092586742, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.007447743322700262}, {"id": 730, "seek": 385796, "start": 3868.92, "end": 3875.0, "text": " of the training procedure is to minimize the difference of the output or the representation", "tokens": [50912, 295, 264, 3097, 10747, 307, 281, 17522, 264, 2649, 295, 264, 5598, 420, 264, 10290, 51216], "temperature": 0.0, "avg_logprob": -0.15539204092586742, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.007447743322700262}, {"id": 731, "seek": 385796, "start": 3875.0, "end": 3881.4, "text": " between the clean version and the corrupted version, essentially. And you can do this in", "tokens": [51216, 1296, 264, 2541, 3037, 293, 264, 39480, 3037, 11, 4476, 13, 400, 291, 393, 360, 341, 294, 51536], "temperature": 0.0, "avg_logprob": -0.15539204092586742, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.007447743322700262}, {"id": 732, "seek": 385796, "start": 3881.4, "end": 3887.7200000000003, "text": " real time. So Boston Machine worked like this. You show a percept, you tell the machine that's", "tokens": [51536, 957, 565, 13, 407, 12333, 22155, 2732, 411, 341, 13, 509, 855, 257, 43276, 11, 291, 980, 264, 3479, 300, 311, 51852], "temperature": 0.0, "avg_logprob": -0.15539204092586742, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.007447743322700262}, {"id": 733, "seek": 388772, "start": 3887.72, "end": 3896.7599999999998, "text": " a good combination of activities or your input neurons. And then you either let them go their", "tokens": [50364, 257, 665, 6562, 295, 5354, 420, 428, 4846, 22027, 13, 400, 550, 291, 2139, 718, 552, 352, 641, 50816], "temperature": 0.0, "avg_logprob": -0.09402630246918776, "compression_ratio": 1.7596153846153846, "no_speech_prob": 0.003372657811269164}, {"id": 734, "seek": 388772, "start": 3896.7599999999998, "end": 3902.68, "text": " merry way without clamping them to values, or you only do this with a subset. And what you're", "tokens": [50816, 41545, 636, 1553, 17690, 278, 552, 281, 4190, 11, 420, 291, 787, 360, 341, 365, 257, 25993, 13, 400, 437, 291, 434, 51112], "temperature": 0.0, "avg_logprob": -0.09402630246918776, "compression_ratio": 1.7596153846153846, "no_speech_prob": 0.003372657811269164}, {"id": 735, "seek": 388772, "start": 3902.68, "end": 3908.4399999999996, "text": " doing is you're training the system so that the stable state of the entire network is the same,", "tokens": [51112, 884, 307, 291, 434, 3097, 264, 1185, 370, 300, 264, 8351, 1785, 295, 264, 2302, 3209, 307, 264, 912, 11, 51400], "temperature": 0.0, "avg_logprob": -0.09402630246918776, "compression_ratio": 1.7596153846153846, "no_speech_prob": 0.003372657811269164}, {"id": 736, "seek": 388772, "start": 3908.4399999999996, "end": 3912.12, "text": " regardless of whether it sees the entire input or whether it sees only part of it.", "tokens": [51400, 10060, 295, 1968, 309, 8194, 264, 2302, 4846, 420, 1968, 309, 8194, 787, 644, 295, 309, 13, 51584], "temperature": 0.0, "avg_logprob": -0.09402630246918776, "compression_ratio": 1.7596153846153846, "no_speech_prob": 0.003372657811269164}, {"id": 737, "seek": 391212, "start": 3913.08, "end": 3917.88, "text": " You know, the nosing autoencoder method is basically the same thing, right? You're training", "tokens": [50412, 509, 458, 11, 264, 3269, 278, 8399, 22660, 19866, 3170, 307, 1936, 264, 912, 551, 11, 558, 30, 509, 434, 3097, 50652], "temperature": 0.0, "avg_logprob": -0.18848604769320101, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.0013663597637787461}, {"id": 738, "seek": 391212, "start": 3917.88, "end": 3922.92, "text": " a system to reproduce the input, the complete input and filling the blanks, regardless of which", "tokens": [50652, 257, 1185, 281, 29501, 264, 4846, 11, 264, 3566, 4846, 293, 10623, 264, 8247, 82, 11, 10060, 295, 597, 50904], "temperature": 0.0, "avg_logprob": -0.18848604769320101, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.0013663597637787461}, {"id": 739, "seek": 391212, "start": 3922.92, "end": 3926.92, "text": " parts are missing. And that's really the underlying principle. And you could imagine,", "tokens": [50904, 3166, 366, 5361, 13, 400, 300, 311, 534, 264, 14217, 8665, 13, 400, 291, 727, 3811, 11, 51104], "temperature": 0.0, "avg_logprob": -0.18848604769320101, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.0013663597637787461}, {"id": 740, "seek": 391212, "start": 3926.92, "end": 3932.44, "text": " sort of even in the brain, some sort of neural principle where, you know, neurons can oscillate,", "tokens": [51104, 1333, 295, 754, 294, 264, 3567, 11, 512, 1333, 295, 18161, 8665, 689, 11, 291, 458, 11, 22027, 393, 18225, 473, 11, 51380], "temperature": 0.0, "avg_logprob": -0.18848604769320101, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.0013663597637787461}, {"id": 741, "seek": 391212, "start": 3932.44, "end": 3937.96, "text": " right? So they take their activity and then temporarily they kind of shut off to, you know,", "tokens": [51380, 558, 30, 407, 436, 747, 641, 5191, 293, 550, 23750, 436, 733, 295, 5309, 766, 281, 11, 291, 458, 11, 51656], "temperature": 0.0, "avg_logprob": -0.18848604769320101, "compression_ratio": 1.7238805970149254, "no_speech_prob": 0.0013663597637787461}, {"id": 742, "seek": 393796, "start": 3937.96, "end": 3943.8, "text": " force the rest of the system to basically reconstruct the input without their help,", "tokens": [50364, 3464, 264, 1472, 295, 264, 1185, 281, 1936, 31499, 264, 4846, 1553, 641, 854, 11, 50656], "temperature": 0.0, "avg_logprob": -0.1262478606645451, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0037642805837094784}, {"id": 743, "seek": 393796, "start": 3943.8, "end": 3950.52, "text": " you know? And I mean, you can imagine, you know, more or less biologically possible", "tokens": [50656, 291, 458, 30, 400, 286, 914, 11, 291, 393, 3811, 11, 291, 458, 11, 544, 420, 1570, 3228, 17157, 1944, 50992], "temperature": 0.0, "avg_logprob": -0.1262478606645451, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0037642805837094784}, {"id": 744, "seek": 393796, "start": 3950.52, "end": 3956.92, "text": " processes. Something like that. And I guess with this denoising autoencoder and masking and", "tokens": [50992, 7555, 13, 6595, 411, 300, 13, 400, 286, 2041, 365, 341, 1441, 78, 3436, 8399, 22660, 19866, 293, 31226, 293, 51312], "temperature": 0.0, "avg_logprob": -0.1262478606645451, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0037642805837094784}, {"id": 745, "seek": 393796, "start": 3956.92, "end": 3962.76, "text": " data augmentation, you don't have to worry about being super efficient. You can just do as much", "tokens": [51312, 1412, 14501, 19631, 11, 291, 500, 380, 362, 281, 3292, 466, 885, 1687, 7148, 13, 509, 393, 445, 360, 382, 709, 51604], "temperature": 0.0, "avg_logprob": -0.1262478606645451, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.0037642805837094784}, {"id": 746, "seek": 396276, "start": 3962.76, "end": 3968.6800000000003, "text": " as you want and get better over time. Because I was thinking like you might want to be clever", "tokens": [50364, 382, 291, 528, 293, 483, 1101, 670, 565, 13, 1436, 286, 390, 1953, 411, 291, 1062, 528, 281, 312, 13494, 50660], "temperature": 0.0, "avg_logprob": -0.11659700220281427, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.012616206891834736}, {"id": 747, "seek": 396276, "start": 3968.6800000000003, "end": 3975.0, "text": " about the way you do all these procedures, you know, but that's only if it's somehow costly", "tokens": [50660, 466, 264, 636, 291, 360, 439, 613, 13846, 11, 291, 458, 11, 457, 300, 311, 787, 498, 309, 311, 6063, 28328, 50976], "temperature": 0.0, "avg_logprob": -0.11659700220281427, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.012616206891834736}, {"id": 748, "seek": 396276, "start": 3975.0, "end": 3981.4, "text": " to do every iteration, but it's not really. Not really. And then there is, you know,", "tokens": [50976, 281, 360, 633, 24784, 11, 457, 309, 311, 406, 534, 13, 1726, 534, 13, 400, 550, 456, 307, 11, 291, 458, 11, 51296], "temperature": 0.0, "avg_logprob": -0.11659700220281427, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.012616206891834736}, {"id": 749, "seek": 396276, "start": 3981.4, "end": 3985.48, "text": " data augmentation without explicit data augmentation is data augmentation by weighting,", "tokens": [51296, 1412, 14501, 19631, 1553, 13691, 1412, 14501, 19631, 307, 1412, 14501, 19631, 538, 3364, 278, 11, 51500], "temperature": 0.0, "avg_logprob": -0.11659700220281427, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.012616206891834736}, {"id": 750, "seek": 396276, "start": 3985.48, "end": 3991.4, "text": " which is, you know, the sort of video prediction. You're observing a video clip,", "tokens": [51500, 597, 307, 11, 291, 458, 11, 264, 1333, 295, 960, 17630, 13, 509, 434, 22107, 257, 960, 7353, 11, 51796], "temperature": 0.0, "avg_logprob": -0.11659700220281427, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.012616206891834736}, {"id": 751, "seek": 399140, "start": 3991.48, "end": 3998.04, "text": " observing the, you know, the continuation of that video clip. You try to learn a representation", "tokens": [50368, 22107, 264, 11, 291, 458, 11, 264, 29357, 295, 300, 960, 7353, 13, 509, 853, 281, 1466, 257, 10290, 50696], "temperature": 0.0, "avg_logprob": -0.13014056042927066, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0011875409400090575}, {"id": 752, "seek": 399140, "start": 3998.04, "end": 4002.28, "text": " using the joint embedding architectures in such a way that the representation of the", "tokens": [50696, 1228, 264, 7225, 12240, 3584, 6331, 1303, 294, 1270, 257, 636, 300, 264, 10290, 295, 264, 50908], "temperature": 0.0, "avg_logprob": -0.13014056042927066, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0011875409400090575}, {"id": 753, "seek": 399140, "start": 4002.28, "end": 4007.1600000000003, "text": " future clip is easily predictable from the representation of the observed clip.", "tokens": [50908, 2027, 7353, 307, 3612, 27737, 490, 264, 10290, 295, 264, 13095, 7353, 13, 51152], "temperature": 0.0, "avg_logprob": -0.13014056042927066, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0011875409400090575}, {"id": 754, "seek": 399140, "start": 4008.52, "end": 4015.4, "text": " Do you think YouTube has enough raw data from which to learn how to be a cat?", "tokens": [51220, 1144, 291, 519, 3088, 575, 1547, 8936, 1412, 490, 597, 281, 1466, 577, 281, 312, 257, 3857, 30, 51564], "temperature": 0.0, "avg_logprob": -0.13014056042927066, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0011875409400090575}, {"id": 755, "seek": 399140, "start": 4016.28, "end": 4016.84, "text": " I think so.", "tokens": [51608, 286, 519, 370, 13, 51636], "temperature": 0.0, "avg_logprob": -0.13014056042927066, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.0011875409400090575}, {"id": 756, "seek": 401684, "start": 4017.7200000000003, "end": 4021.1600000000003, "text": " So the amount of data is not the constraint?", "tokens": [50408, 407, 264, 2372, 295, 1412, 307, 406, 264, 25534, 30, 50580], "temperature": 0.0, "avg_logprob": -0.18075819576487823, "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.004680213518440723}, {"id": 757, "seek": 401684, "start": 4021.1600000000003, "end": 4023.4, "text": " No, it would require some selection, I think.", "tokens": [50580, 883, 11, 309, 576, 3651, 512, 9450, 11, 286, 519, 13, 50692], "temperature": 0.0, "avg_logprob": -0.18075819576487823, "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.004680213518440723}, {"id": 758, "seek": 401684, "start": 4024.04, "end": 4028.36, "text": " Some selection of, you know, maybe the right type of data.", "tokens": [50724, 2188, 9450, 295, 11, 291, 458, 11, 1310, 264, 558, 2010, 295, 1412, 13, 50940], "temperature": 0.0, "avg_logprob": -0.18075819576487823, "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.004680213518440723}, {"id": 759, "seek": 401684, "start": 4028.36, "end": 4033.8, "text": " Don't go down the rabbit hole of just cat videos. You might need to watch some lectures or something.", "tokens": [50940, 1468, 380, 352, 760, 264, 19509, 5458, 295, 445, 3857, 2145, 13, 509, 1062, 643, 281, 1159, 512, 16564, 420, 746, 13, 51212], "temperature": 0.0, "avg_logprob": -0.18075819576487823, "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.004680213518440723}, {"id": 760, "seek": 401684, "start": 4035.7200000000003, "end": 4042.1200000000003, "text": " How meta would that be if it like watches lectures about intelligence and then learns,", "tokens": [51308, 1012, 19616, 576, 300, 312, 498, 309, 411, 17062, 16564, 466, 7599, 293, 550, 27152, 11, 51628], "temperature": 0.0, "avg_logprob": -0.18075819576487823, "compression_ratio": 1.5576036866359446, "no_speech_prob": 0.004680213518440723}, {"id": 761, "seek": 404212, "start": 4042.2, "end": 4046.04, "text": " watches your lectures in NYU and learns from that how to be intelligent?", "tokens": [50368, 17062, 428, 16564, 294, 42682, 293, 27152, 490, 300, 577, 281, 312, 13232, 30, 50560], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 762, "seek": 404212, "start": 4046.04, "end": 4047.08, "text": " I don't think that would be enough.", "tokens": [50560, 286, 500, 380, 519, 300, 576, 312, 1547, 13, 50612], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 763, "seek": 404212, "start": 4050.2799999999997, "end": 4054.3599999999997, "text": " What's your, do you find multimodal learning interesting? We've been talking about visual", "tokens": [50772, 708, 311, 428, 11, 360, 291, 915, 32972, 378, 304, 2539, 1880, 30, 492, 600, 668, 1417, 466, 5056, 50976], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 764, "seek": 404212, "start": 4054.3599999999997, "end": 4058.04, "text": " language, like combining those together, maybe audio, all those kinds of things.", "tokens": [50976, 2856, 11, 411, 21928, 729, 1214, 11, 1310, 6278, 11, 439, 729, 3685, 295, 721, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 765, "seek": 404212, "start": 4058.04, "end": 4061.96, "text": " There's a lot of things that I find interesting in the short term, but are not", "tokens": [51160, 821, 311, 257, 688, 295, 721, 300, 286, 915, 1880, 294, 264, 2099, 1433, 11, 457, 366, 406, 51356], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 766, "seek": 404212, "start": 4062.52, "end": 4067.16, "text": " addressing the important problem that I think are really kind of the big challenges. So I think,", "tokens": [51384, 14329, 264, 1021, 1154, 300, 286, 519, 366, 534, 733, 295, 264, 955, 4759, 13, 407, 286, 519, 11, 51616], "temperature": 0.0, "avg_logprob": -0.12850587302391683, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.009119169786572456}, {"id": 767, "seek": 406716, "start": 4067.16, "end": 4071.24, "text": " you know, things like multitask learning, continual learning, you know,", "tokens": [50364, 291, 458, 11, 721, 411, 42338, 3863, 2539, 11, 1421, 901, 2539, 11, 291, 458, 11, 50568], "temperature": 0.0, "avg_logprob": -0.172436145821003, "compression_ratio": 1.7620967741935485, "no_speech_prob": 0.005694041959941387}, {"id": 768, "seek": 406716, "start": 4073.3199999999997, "end": 4077.64, "text": " adversarial issues. I mean, those have, you know, great practical interests in the", "tokens": [50672, 17641, 44745, 2663, 13, 286, 914, 11, 729, 362, 11, 291, 458, 11, 869, 8496, 8847, 294, 264, 50888], "temperature": 0.0, "avg_logprob": -0.172436145821003, "compression_ratio": 1.7620967741935485, "no_speech_prob": 0.005694041959941387}, {"id": 769, "seek": 406716, "start": 4077.64, "end": 4082.52, "text": " relatively short term, possibly, but I don't think they're fundamental, you know, active learning,", "tokens": [50888, 7226, 2099, 1433, 11, 6264, 11, 457, 286, 500, 380, 519, 436, 434, 8088, 11, 291, 458, 11, 4967, 2539, 11, 51132], "temperature": 0.0, "avg_logprob": -0.172436145821003, "compression_ratio": 1.7620967741935485, "no_speech_prob": 0.005694041959941387}, {"id": 770, "seek": 406716, "start": 4082.52, "end": 4088.12, "text": " even to some extent reinforcement learning. I think those things will become either obsolete or", "tokens": [51132, 754, 281, 512, 8396, 29280, 2539, 13, 286, 519, 729, 721, 486, 1813, 2139, 46333, 420, 51412], "temperature": 0.0, "avg_logprob": -0.172436145821003, "compression_ratio": 1.7620967741935485, "no_speech_prob": 0.005694041959941387}, {"id": 771, "seek": 406716, "start": 4089.0, "end": 4096.12, "text": " useless or easy once we figure out how to do self-supervised representation learning or", "tokens": [51456, 14115, 420, 1858, 1564, 321, 2573, 484, 577, 281, 360, 2698, 12, 48172, 24420, 10290, 2539, 420, 51812], "temperature": 0.0, "avg_logprob": -0.172436145821003, "compression_ratio": 1.7620967741935485, "no_speech_prob": 0.005694041959941387}, {"id": 772, "seek": 409716, "start": 4097.5599999999995, "end": 4103.0, "text": " predictive world models. And so I think that's what, you know, the entire community should be", "tokens": [50384, 35521, 1002, 5245, 13, 400, 370, 286, 519, 300, 311, 437, 11, 291, 458, 11, 264, 2302, 1768, 820, 312, 50656], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 773, "seek": 409716, "start": 4103.0, "end": 4107.16, "text": " focusing on. At least people are interested in sort of fundamental questions or, you know,", "tokens": [50656, 8416, 322, 13, 1711, 1935, 561, 366, 3102, 294, 1333, 295, 8088, 1651, 420, 11, 291, 458, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 774, "seek": 409716, "start": 4107.16, "end": 4111.72, "text": " really kind of pushing the envelope of AI towards the next stage. But of course,", "tokens": [50864, 534, 733, 295, 7380, 264, 19989, 295, 7318, 3030, 264, 958, 3233, 13, 583, 295, 1164, 11, 51092], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 775, "seek": 409716, "start": 4111.72, "end": 4115.16, "text": " there is like a huge amount of, you know, very interesting work to do in sort of practical", "tokens": [51092, 456, 307, 411, 257, 2603, 2372, 295, 11, 291, 458, 11, 588, 1880, 589, 281, 360, 294, 1333, 295, 8496, 51264], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 776, "seek": 409716, "start": 4115.16, "end": 4121.4, "text": " questions that have, you know, short term impact. Well, you know, it's difficult to talk about the", "tokens": [51264, 1651, 300, 362, 11, 291, 458, 11, 2099, 1433, 2712, 13, 1042, 11, 291, 458, 11, 309, 311, 2252, 281, 751, 466, 264, 51576], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 777, "seek": 409716, "start": 4121.4, "end": 4126.36, "text": " temporal scale because all of human civilization will eventually be destroyed because the", "tokens": [51576, 30881, 4373, 570, 439, 295, 1952, 18036, 486, 4728, 312, 8937, 570, 264, 51824], "temperature": 0.0, "avg_logprob": -0.09250429368788196, "compression_ratio": 1.7637540453074434, "no_speech_prob": 0.001672732993029058}, {"id": 778, "seek": 412716, "start": 4127.48, "end": 4133.24, "text": " the sun will die out. And even if Elon Musk is successful, multi-planetary colonization across", "tokens": [50380, 264, 3295, 486, 978, 484, 13, 400, 754, 498, 28498, 26019, 307, 4406, 11, 4825, 12, 16554, 302, 822, 8255, 2144, 2108, 50668], "temperature": 0.0, "avg_logprob": -0.1930516560872396, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.00036254138103686273}, {"id": 779, "seek": 412716, "start": 4133.24, "end": 4139.24, "text": " the galaxy, eventually the entirety of it will just become giant black holes. And", "tokens": [50668, 264, 17639, 11, 4728, 264, 31557, 295, 309, 486, 445, 1813, 7410, 2211, 8118, 13, 400, 50968], "temperature": 0.0, "avg_logprob": -0.1930516560872396, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.00036254138103686273}, {"id": 780, "seek": 412716, "start": 4140.28, "end": 4145.5599999999995, "text": " that's gonna take a while though. So, but what I'm saying is then that logic can be used to say", "tokens": [51020, 300, 311, 799, 747, 257, 1339, 1673, 13, 407, 11, 457, 437, 286, 478, 1566, 307, 550, 300, 9952, 393, 312, 1143, 281, 584, 51284], "temperature": 0.0, "avg_logprob": -0.1930516560872396, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.00036254138103686273}, {"id": 781, "seek": 412716, "start": 4145.5599999999995, "end": 4154.28, "text": " it's all meaningless. I'm saying all that to say that multitask learning might be your song,", "tokens": [51284, 309, 311, 439, 33232, 13, 286, 478, 1566, 439, 300, 281, 584, 300, 42338, 3863, 2539, 1062, 312, 428, 2153, 11, 51720], "temperature": 0.0, "avg_logprob": -0.1930516560872396, "compression_ratio": 1.5598290598290598, "no_speech_prob": 0.00036254138103686273}, {"id": 782, "seek": 415428, "start": 4154.28, "end": 4158.92, "text": " you're calling it practical or pragmatic or whatever. That might be the thing that achieves", "tokens": [50364, 291, 434, 5141, 309, 8496, 420, 46904, 420, 2035, 13, 663, 1062, 312, 264, 551, 300, 3538, 977, 50596], "temperature": 0.0, "avg_logprob": -0.10320506005916956, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.007119486108422279}, {"id": 783, "seek": 415428, "start": 4158.92, "end": 4167.08, "text": " something very akin to intelligence while we're trying to solve the more general problem of", "tokens": [50596, 746, 588, 47540, 281, 7599, 1339, 321, 434, 1382, 281, 5039, 264, 544, 2674, 1154, 295, 51004], "temperature": 0.0, "avg_logprob": -0.10320506005916956, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.007119486108422279}, {"id": 784, "seek": 415428, "start": 4167.08, "end": 4172.2, "text": " self-supervised learning of background knowledge. So the reason I bring that up may be one way to", "tokens": [51004, 2698, 12, 48172, 24420, 2539, 295, 3678, 3601, 13, 407, 264, 1778, 286, 1565, 300, 493, 815, 312, 472, 636, 281, 51260], "temperature": 0.0, "avg_logprob": -0.10320506005916956, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.007119486108422279}, {"id": 785, "seek": 415428, "start": 4172.2, "end": 4176.599999999999, "text": " ask that question. I've been very impressed by what Tesla autopilot team is doing. I don't know", "tokens": [51260, 1029, 300, 1168, 13, 286, 600, 668, 588, 11679, 538, 437, 13666, 31090, 31516, 1469, 307, 884, 13, 286, 500, 380, 458, 51480], "temperature": 0.0, "avg_logprob": -0.10320506005916956, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.007119486108422279}, {"id": 786, "seek": 415428, "start": 4176.599999999999, "end": 4181.96, "text": " if you've gotten a chance to glance at this particular one example of multitask learning", "tokens": [51480, 498, 291, 600, 5768, 257, 2931, 281, 21094, 412, 341, 1729, 472, 1365, 295, 42338, 3863, 2539, 51748], "temperature": 0.0, "avg_logprob": -0.10320506005916956, "compression_ratio": 1.646643109540636, "no_speech_prob": 0.007119486108422279}, {"id": 787, "seek": 418196, "start": 4182.04, "end": 4188.84, "text": " where they're literally taking the problem like, I don't know, Charles Darwin start studying animals.", "tokens": [50368, 689, 436, 434, 3736, 1940, 264, 1154, 411, 11, 286, 500, 380, 458, 11, 10523, 30233, 722, 7601, 4882, 13, 50708], "temperature": 0.0, "avg_logprob": -0.11533167423346104, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.0037643297109752893}, {"id": 788, "seek": 418196, "start": 4188.84, "end": 4194.12, "text": " They're studying the problem of driving and asking, okay, what are all the things you have to perceive?", "tokens": [50708, 814, 434, 7601, 264, 1154, 295, 4840, 293, 3365, 11, 1392, 11, 437, 366, 439, 264, 721, 291, 362, 281, 20281, 30, 50972], "temperature": 0.0, "avg_logprob": -0.11533167423346104, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.0037643297109752893}, {"id": 789, "seek": 418196, "start": 4195.0, "end": 4199.96, "text": " And the way they're solving it is one, there's an ontology where you're bringing that to the", "tokens": [51016, 400, 264, 636, 436, 434, 12606, 309, 307, 472, 11, 456, 311, 364, 6592, 1793, 689, 291, 434, 5062, 300, 281, 264, 51264], "temperature": 0.0, "avg_logprob": -0.11533167423346104, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.0037643297109752893}, {"id": 790, "seek": 418196, "start": 4199.96, "end": 4203.8, "text": " table. So you're formulating a bunch of different tasks. It's like over a hundred tasks or something", "tokens": [51264, 3199, 13, 407, 291, 434, 1254, 12162, 257, 3840, 295, 819, 9608, 13, 467, 311, 411, 670, 257, 3262, 9608, 420, 746, 51456], "temperature": 0.0, "avg_logprob": -0.11533167423346104, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.0037643297109752893}, {"id": 791, "seek": 418196, "start": 4203.8, "end": 4208.52, "text": " like that that they're involved in driving. And then they're deploying it and then getting data", "tokens": [51456, 411, 300, 300, 436, 434, 3288, 294, 4840, 13, 400, 550, 436, 434, 34198, 309, 293, 550, 1242, 1412, 51692], "temperature": 0.0, "avg_logprob": -0.11533167423346104, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.0037643297109752893}, {"id": 792, "seek": 420852, "start": 4208.52, "end": 4213.320000000001, "text": " back from people that run to trouble. And they're trying to figure out, do we add tasks? Do we,", "tokens": [50364, 646, 490, 561, 300, 1190, 281, 5253, 13, 400, 436, 434, 1382, 281, 2573, 484, 11, 360, 321, 909, 9608, 30, 1144, 321, 11, 50604], "temperature": 0.0, "avg_logprob": -0.17606200571135272, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.04738115146756172}, {"id": 793, "seek": 420852, "start": 4213.320000000001, "end": 4218.84, "text": " like we focus on each individual task separately? In fact, half. So the, I would say, I'll classify", "tokens": [50604, 411, 321, 1879, 322, 1184, 2609, 5633, 14759, 30, 682, 1186, 11, 1922, 13, 407, 264, 11, 286, 576, 584, 11, 286, 603, 33872, 50880], "temperature": 0.0, "avg_logprob": -0.17606200571135272, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.04738115146756172}, {"id": 794, "seek": 420852, "start": 4218.84, "end": 4223.64, "text": " Andre Carpathi's talk in two ways. So one was about doors. And the other one about how much", "tokens": [50880, 20667, 2741, 31852, 72, 311, 751, 294, 732, 2098, 13, 407, 472, 390, 466, 8077, 13, 400, 264, 661, 472, 466, 577, 709, 51120], "temperature": 0.0, "avg_logprob": -0.17606200571135272, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.04738115146756172}, {"id": 795, "seek": 420852, "start": 4223.64, "end": 4230.84, "text": " ImageNet sucks. He kept going back and forth on those two topics, which ImageNet sucks, meaning", "tokens": [51120, 29903, 31890, 15846, 13, 634, 4305, 516, 646, 293, 5220, 322, 729, 732, 8378, 11, 597, 29903, 31890, 15846, 11, 3620, 51480], "temperature": 0.0, "avg_logprob": -0.17606200571135272, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.04738115146756172}, {"id": 796, "seek": 420852, "start": 4230.84, "end": 4237.320000000001, "text": " you can't just use a single benchmark. There's so like, you have to have like a giant suite of", "tokens": [51480, 291, 393, 380, 445, 764, 257, 2167, 18927, 13, 821, 311, 370, 411, 11, 291, 362, 281, 362, 411, 257, 7410, 14205, 295, 51804], "temperature": 0.0, "avg_logprob": -0.17606200571135272, "compression_ratio": 1.5933333333333333, "no_speech_prob": 0.04738115146756172}, {"id": 797, "seek": 423732, "start": 4237.32, "end": 4239.88, "text": " benchmarks to understand how well your system actually works.", "tokens": [50364, 43751, 281, 1223, 577, 731, 428, 1185, 767, 1985, 13, 50492], "temperature": 0.0, "avg_logprob": -0.10862982048178618, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.00250554783269763}, {"id": 798, "seek": 423732, "start": 4239.88, "end": 4247.24, "text": " Oh, I agree with him. I mean, he's a very sensible guy. Now, okay, it's very clear that if you're", "tokens": [50492, 876, 11, 286, 3986, 365, 796, 13, 286, 914, 11, 415, 311, 257, 588, 25380, 2146, 13, 823, 11, 1392, 11, 309, 311, 588, 1850, 300, 498, 291, 434, 50860], "temperature": 0.0, "avg_logprob": -0.10862982048178618, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.00250554783269763}, {"id": 799, "seek": 423732, "start": 4247.24, "end": 4251.88, "text": " faced with an engineering problem that you need to solve in a relatively short time,", "tokens": [50860, 11446, 365, 364, 7043, 1154, 300, 291, 643, 281, 5039, 294, 257, 7226, 2099, 565, 11, 51092], "temperature": 0.0, "avg_logprob": -0.10862982048178618, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.00250554783269763}, {"id": 800, "seek": 423732, "start": 4251.88, "end": 4256.5199999999995, "text": " particularly if you have Elon Musk breathing down your neck, you're going to have to take", "tokens": [51092, 4098, 498, 291, 362, 28498, 26019, 9570, 760, 428, 6189, 11, 291, 434, 516, 281, 362, 281, 747, 51324], "temperature": 0.0, "avg_logprob": -0.10862982048178618, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.00250554783269763}, {"id": 801, "seek": 423732, "start": 4256.5199999999995, "end": 4263.0, "text": " shortcuts, right? You might think about the fact that the right thing to do and the long-term", "tokens": [51324, 34620, 11, 558, 30, 509, 1062, 519, 466, 264, 1186, 300, 264, 558, 551, 281, 360, 293, 264, 938, 12, 7039, 51648], "temperature": 0.0, "avg_logprob": -0.10862982048178618, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.00250554783269763}, {"id": 802, "seek": 426300, "start": 4263.0, "end": 4269.24, "text": " solution involves some fancy self-improvement running, but you have Elon Musk breathing down", "tokens": [50364, 3827, 11626, 512, 10247, 2698, 12, 332, 46955, 518, 2614, 11, 457, 291, 362, 28498, 26019, 9570, 760, 50676], "temperature": 0.0, "avg_logprob": -0.1743105108087713, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.021571028977632523}, {"id": 803, "seek": 426300, "start": 4269.24, "end": 4278.76, "text": " your neck. And this involves human lives. And so you have to basically just do the systematic", "tokens": [50676, 428, 6189, 13, 400, 341, 11626, 1952, 2909, 13, 400, 370, 291, 362, 281, 1936, 445, 360, 264, 27249, 51152], "temperature": 0.0, "avg_logprob": -0.1743105108087713, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.021571028977632523}, {"id": 804, "seek": 426300, "start": 4278.76, "end": 4286.68, "text": " engineering and fine-tuning and refinements and try and error and all that stuff. There's nothing", "tokens": [51152, 7043, 293, 2489, 12, 83, 37726, 293, 44395, 6400, 293, 853, 293, 6713, 293, 439, 300, 1507, 13, 821, 311, 1825, 51548], "temperature": 0.0, "avg_logprob": -0.1743105108087713, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.021571028977632523}, {"id": 805, "seek": 428668, "start": 4286.68, "end": 4294.84, "text": " wrong with that. That's called engineering. That's called putting technology out in the world.", "tokens": [50364, 2085, 365, 300, 13, 663, 311, 1219, 7043, 13, 663, 311, 1219, 3372, 2899, 484, 294, 264, 1002, 13, 50772], "temperature": 0.0, "avg_logprob": -0.14426186505485983, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.5534476041793823}, {"id": 806, "seek": 428668, "start": 4295.8, "end": 4305.96, "text": " And you have to kind of ironclad it before you do this so much for grand ideas and principles.", "tokens": [50820, 400, 291, 362, 281, 733, 295, 6497, 3474, 345, 309, 949, 291, 360, 341, 370, 709, 337, 2697, 3487, 293, 9156, 13, 51328], "temperature": 0.0, "avg_logprob": -0.14426186505485983, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.5534476041793823}, {"id": 807, "seek": 428668, "start": 4308.200000000001, "end": 4315.64, "text": " But I'm placing myself sort of some upstream of this, quite a bit upstream of this.", "tokens": [51440, 583, 286, 478, 17221, 2059, 1333, 295, 512, 33915, 295, 341, 11, 1596, 257, 857, 33915, 295, 341, 13, 51812], "temperature": 0.0, "avg_logprob": -0.14426186505485983, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.5534476041793823}, {"id": 808, "seek": 431564, "start": 4315.72, "end": 4317.8, "text": " You're a play-doh think about platonic forms.", "tokens": [50368, 509, 434, 257, 862, 12, 67, 1445, 519, 466, 3403, 11630, 6422, 13, 50472], "temperature": 0.0, "avg_logprob": -0.1734347143093077, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.007566817104816437}, {"id": 809, "seek": 431564, "start": 4319.0, "end": 4326.12, "text": " It's not platonic because eventually, I want the stuff to get used, but it's okay if it takes", "tokens": [50532, 467, 311, 406, 3403, 11630, 570, 4728, 11, 286, 528, 264, 1507, 281, 483, 1143, 11, 457, 309, 311, 1392, 498, 309, 2516, 50888], "temperature": 0.0, "avg_logprob": -0.1734347143093077, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.007566817104816437}, {"id": 810, "seek": 431564, "start": 4326.12, "end": 4330.280000000001, "text": " five or 10 years for the community to realize this is the right thing to do. I've done this", "tokens": [50888, 1732, 420, 1266, 924, 337, 264, 1768, 281, 4325, 341, 307, 264, 558, 551, 281, 360, 13, 286, 600, 1096, 341, 51096], "temperature": 0.0, "avg_logprob": -0.1734347143093077, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.007566817104816437}, {"id": 811, "seek": 431564, "start": 4330.280000000001, "end": 4336.84, "text": " before. It's been the case before that I've made that case. I mean, if you look back in the mid-2000,", "tokens": [51096, 949, 13, 467, 311, 668, 264, 1389, 949, 300, 286, 600, 1027, 300, 1389, 13, 286, 914, 11, 498, 291, 574, 646, 294, 264, 2062, 12, 25743, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1734347143093077, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.007566817104816437}, {"id": 812, "seek": 431564, "start": 4336.84, "end": 4341.8, "text": " for example, and you ask yourself the question, okay, I want to recognize cars or faces or whatever.", "tokens": [51424, 337, 1365, 11, 293, 291, 1029, 1803, 264, 1168, 11, 1392, 11, 286, 528, 281, 5521, 5163, 420, 8475, 420, 2035, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1734347143093077, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.007566817104816437}, {"id": 813, "seek": 434180, "start": 4342.2, "end": 4346.92, "text": " You know, I can use convolutional nets, so I can use more conventional", "tokens": [50384, 509, 458, 11, 286, 393, 764, 45216, 304, 36170, 11, 370, 286, 393, 764, 544, 16011, 50620], "temperature": 0.0, "avg_logprob": -0.19910946458873183, "compression_ratio": 1.656, "no_speech_prob": 0.0008963322034105659}, {"id": 814, "seek": 434180, "start": 4348.2, "end": 4352.04, "text": " kind of computer vision techniques using interest point detectors or sift", "tokens": [50684, 733, 295, 3820, 5201, 7512, 1228, 1179, 935, 46866, 420, 262, 2008, 50876], "temperature": 0.0, "avg_logprob": -0.19910946458873183, "compression_ratio": 1.656, "no_speech_prob": 0.0008963322034105659}, {"id": 815, "seek": 434180, "start": 4352.6, "end": 4358.04, "text": " density features and sticking an SVM on top. At that time, the datasets were so small that", "tokens": [50904, 10305, 4122, 293, 13465, 364, 31910, 44, 322, 1192, 13, 1711, 300, 565, 11, 264, 42856, 645, 370, 1359, 300, 51176], "temperature": 0.0, "avg_logprob": -0.19910946458873183, "compression_ratio": 1.656, "no_speech_prob": 0.0008963322034105659}, {"id": 816, "seek": 434180, "start": 4358.76, "end": 4363.96, "text": " those methods that use more hand-engineering worked better than comnets. There was just", "tokens": [51212, 729, 7150, 300, 764, 544, 1011, 12, 25609, 1794, 2732, 1101, 813, 395, 77, 1385, 13, 821, 390, 445, 51472], "temperature": 0.0, "avg_logprob": -0.19910946458873183, "compression_ratio": 1.656, "no_speech_prob": 0.0008963322034105659}, {"id": 817, "seek": 434180, "start": 4363.96, "end": 4368.92, "text": " not enough data for comnets. And comnets were a little slow with the kind of hardware that", "tokens": [51472, 406, 1547, 1412, 337, 395, 77, 1385, 13, 400, 395, 77, 1385, 645, 257, 707, 2964, 365, 264, 733, 295, 8837, 300, 51720], "temperature": 0.0, "avg_logprob": -0.19910946458873183, "compression_ratio": 1.656, "no_speech_prob": 0.0008963322034105659}, {"id": 818, "seek": 436892, "start": 4368.92, "end": 4376.12, "text": " was available at the time. And there was a sea change when, basically, when datasets became", "tokens": [50364, 390, 2435, 412, 264, 565, 13, 400, 456, 390, 257, 4158, 1319, 562, 11, 1936, 11, 562, 42856, 3062, 50724], "temperature": 0.0, "avg_logprob": -0.1511811649098116, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0006665088003501296}, {"id": 819, "seek": 436892, "start": 4376.12, "end": 4384.28, "text": " bigger and GPUs became available. That's what two of the main factors that basically made people", "tokens": [50724, 3801, 293, 18407, 82, 3062, 2435, 13, 663, 311, 437, 732, 295, 264, 2135, 6771, 300, 1936, 1027, 561, 51132], "temperature": 0.0, "avg_logprob": -0.1511811649098116, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0006665088003501296}, {"id": 820, "seek": 436892, "start": 4384.28, "end": 4394.52, "text": " change their mind. And you can look at the history of all sub-branches of AI or pattern", "tokens": [51132, 1319, 641, 1575, 13, 400, 291, 393, 574, 412, 264, 2503, 295, 439, 1422, 12, 1443, 282, 3781, 295, 7318, 420, 5102, 51644], "temperature": 0.0, "avg_logprob": -0.1511811649098116, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0006665088003501296}, {"id": 821, "seek": 439452, "start": 4394.52, "end": 4401.56, "text": " recognition. And there's a similar trajectory followed by techniques where people start by,", "tokens": [50364, 11150, 13, 400, 456, 311, 257, 2531, 21512, 6263, 538, 7512, 689, 561, 722, 538, 11, 50716], "temperature": 0.0, "avg_logprob": -0.12197043345524715, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00768606923520565}, {"id": 822, "seek": 439452, "start": 4401.56, "end": 4409.160000000001, "text": " you know, engineering the hell out of it. You know, be it optical character recognition,", "tokens": [50716, 291, 458, 11, 7043, 264, 4921, 484, 295, 309, 13, 509, 458, 11, 312, 309, 20674, 2517, 11150, 11, 51096], "temperature": 0.0, "avg_logprob": -0.12197043345524715, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00768606923520565}, {"id": 823, "seek": 439452, "start": 4409.160000000001, "end": 4414.84, "text": " speech recognition, computer vision like image recognition in general, natural language", "tokens": [51096, 6218, 11150, 11, 3820, 5201, 411, 3256, 11150, 294, 2674, 11, 3303, 2856, 51380], "temperature": 0.0, "avg_logprob": -0.12197043345524715, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00768606923520565}, {"id": 824, "seek": 439452, "start": 4414.84, "end": 4419.0, "text": " understanding like, you know, translation, things like that, right? You start to engineer the hell", "tokens": [51380, 3701, 411, 11, 291, 458, 11, 12853, 11, 721, 411, 300, 11, 558, 30, 509, 722, 281, 11403, 264, 4921, 51588], "temperature": 0.0, "avg_logprob": -0.12197043345524715, "compression_ratio": 1.7069767441860466, "no_speech_prob": 0.00768606923520565}, {"id": 825, "seek": 441900, "start": 4419.0, "end": 4424.68, "text": " out of it. You start to acquire all the knowledge, the prior knowledge you know about image formation,", "tokens": [50364, 484, 295, 309, 13, 509, 722, 281, 20001, 439, 264, 3601, 11, 264, 4059, 3601, 291, 458, 466, 3256, 11723, 11, 50648], "temperature": 0.0, "avg_logprob": -0.12335641534478815, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.003693933365866542}, {"id": 826, "seek": 441900, "start": 4424.68, "end": 4429.48, "text": " about, you know, the shape of characters, about, you know, morphological operations,", "tokens": [50648, 466, 11, 291, 458, 11, 264, 3909, 295, 4342, 11, 466, 11, 291, 458, 11, 25778, 4383, 7705, 11, 50888], "temperature": 0.0, "avg_logprob": -0.12335641534478815, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.003693933365866542}, {"id": 827, "seek": 441900, "start": 4429.48, "end": 4434.2, "text": " about like feature extraction, Fourier transforms, you know, vernike moments, you know, whatever,", "tokens": [50888, 466, 411, 4111, 30197, 11, 36810, 35592, 11, 291, 458, 11, 35793, 1123, 6065, 11, 291, 458, 11, 2035, 11, 51124], "temperature": 0.0, "avg_logprob": -0.12335641534478815, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.003693933365866542}, {"id": 828, "seek": 441900, "start": 4434.2, "end": 4438.92, "text": " right? People have come up with thousands of ways of representing images so that they could be easily", "tokens": [51124, 558, 30, 3432, 362, 808, 493, 365, 5383, 295, 2098, 295, 13460, 5267, 370, 300, 436, 727, 312, 3612, 51360], "temperature": 0.0, "avg_logprob": -0.12335641534478815, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.003693933365866542}, {"id": 829, "seek": 441900, "start": 4439.8, "end": 4444.92, "text": " classified afterwards. Same for speech recognition, right? There is, you know, two decades for people", "tokens": [51404, 20627, 10543, 13, 10635, 337, 6218, 11150, 11, 558, 30, 821, 307, 11, 291, 458, 11, 732, 7878, 337, 561, 51660], "temperature": 0.0, "avg_logprob": -0.12335641534478815, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.003693933365866542}, {"id": 830, "seek": 444492, "start": 4444.92, "end": 4451.08, "text": " to figure out a good front-end to prepossess a speech signal so that, you know, the information", "tokens": [50364, 281, 2573, 484, 257, 665, 1868, 12, 521, 281, 2666, 772, 442, 257, 6218, 6358, 370, 300, 11, 291, 458, 11, 264, 1589, 50672], "temperature": 0.0, "avg_logprob": -0.15297890724019803, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.005104979500174522}, {"id": 831, "seek": 444492, "start": 4451.08, "end": 4456.36, "text": " about what is being said is preserved, but most of the information about the identity of the speaker", "tokens": [50672, 466, 437, 307, 885, 848, 307, 22242, 11, 457, 881, 295, 264, 1589, 466, 264, 6575, 295, 264, 8145, 50936], "temperature": 0.0, "avg_logprob": -0.15297890724019803, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.005104979500174522}, {"id": 832, "seek": 444492, "start": 4456.36, "end": 4463.56, "text": " is gone. You know, casserole coefficients or whatever, right? And same for text, right?", "tokens": [50936, 307, 2780, 13, 509, 458, 11, 21943, 2032, 306, 31994, 420, 2035, 11, 558, 30, 400, 912, 337, 2487, 11, 558, 30, 51296], "temperature": 0.0, "avg_logprob": -0.15297890724019803, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.005104979500174522}, {"id": 833, "seek": 444492, "start": 4464.4400000000005, "end": 4473.32, "text": " You do name identity recognition and you parse and you do tagging of the parts of speech and,", "tokens": [51340, 509, 360, 1315, 6575, 11150, 293, 291, 48377, 293, 291, 360, 6162, 3249, 295, 264, 3166, 295, 6218, 293, 11, 51784], "temperature": 0.0, "avg_logprob": -0.15297890724019803, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.005104979500174522}, {"id": 834, "seek": 447332, "start": 4473.32, "end": 4478.36, "text": " you know, you do this sort of tree representation of clauses and all that stuff right before you", "tokens": [50364, 291, 458, 11, 291, 360, 341, 1333, 295, 4230, 10290, 295, 49072, 293, 439, 300, 1507, 558, 949, 291, 50616], "temperature": 0.0, "avg_logprob": -0.08234932076217782, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.00041081482777372}, {"id": 835, "seek": 447332, "start": 4478.36, "end": 4487.24, "text": " can do anything. So that's how it starts, right? Just engineer the hell out of it. And then you", "tokens": [50616, 393, 360, 1340, 13, 407, 300, 311, 577, 309, 3719, 11, 558, 30, 1449, 11403, 264, 4921, 484, 295, 309, 13, 400, 550, 291, 51060], "temperature": 0.0, "avg_logprob": -0.08234932076217782, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.00041081482777372}, {"id": 836, "seek": 447332, "start": 4487.24, "end": 4492.679999999999, "text": " start having data and maybe you have more powerful computers, maybe you know something about statistical", "tokens": [51060, 722, 1419, 1412, 293, 1310, 291, 362, 544, 4005, 10807, 11, 1310, 291, 458, 746, 466, 22820, 51332], "temperature": 0.0, "avg_logprob": -0.08234932076217782, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.00041081482777372}, {"id": 837, "seek": 447332, "start": 4492.679999999999, "end": 4496.679999999999, "text": " learning. So you start using machine learning and it's usually a small sliver on top of your", "tokens": [51332, 2539, 13, 407, 291, 722, 1228, 3479, 2539, 293, 309, 311, 2673, 257, 1359, 1061, 1837, 322, 1192, 295, 428, 51532], "temperature": 0.0, "avg_logprob": -0.08234932076217782, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.00041081482777372}, {"id": 838, "seek": 447332, "start": 4496.679999999999, "end": 4501.96, "text": " kind of handcrafted system where, you know, you extract features by hand, okay? And now, you know,", "tokens": [51532, 733, 295, 1011, 5611, 292, 1185, 689, 11, 291, 458, 11, 291, 8947, 4122, 538, 1011, 11, 1392, 30, 400, 586, 11, 291, 458, 11, 51796], "temperature": 0.0, "avg_logprob": -0.08234932076217782, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.00041081482777372}, {"id": 839, "seek": 450196, "start": 4501.96, "end": 4505.72, "text": " nowadays the standard way of doing this is that you train the entire thing end-to-end with a deep", "tokens": [50364, 13434, 264, 3832, 636, 295, 884, 341, 307, 300, 291, 3847, 264, 2302, 551, 917, 12, 1353, 12, 521, 365, 257, 2452, 50552], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 840, "seek": 450196, "start": 4505.72, "end": 4511.0, "text": " learning system and it learns its own features and, you know, speech recognition systems nowadays,", "tokens": [50552, 2539, 1185, 293, 309, 27152, 1080, 1065, 4122, 293, 11, 291, 458, 11, 6218, 11150, 3652, 13434, 11, 50816], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 841, "seek": 450196, "start": 4511.88, "end": 4517.16, "text": " OCR systems are completely end-to-end. It's, you know, it's some giant neural net that takes", "tokens": [50860, 422, 18547, 3652, 366, 2584, 917, 12, 1353, 12, 521, 13, 467, 311, 11, 291, 458, 11, 309, 311, 512, 7410, 18161, 2533, 300, 2516, 51124], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 842, "seek": 450196, "start": 4517.16, "end": 4522.76, "text": " raw waveforms and produces a sequence of characters coming out. And it's just a huge neural net,", "tokens": [51124, 8936, 36512, 82, 293, 14725, 257, 8310, 295, 4342, 1348, 484, 13, 400, 309, 311, 445, 257, 2603, 18161, 2533, 11, 51404], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 843, "seek": 450196, "start": 4522.76, "end": 4528.12, "text": " right? There's no, you know, Markov model, there's no language model that is explicit other than,", "tokens": [51404, 558, 30, 821, 311, 572, 11, 291, 458, 11, 3934, 5179, 2316, 11, 456, 311, 572, 2856, 2316, 300, 307, 13691, 661, 813, 11, 51672], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 844, "seek": 450196, "start": 4528.12, "end": 4531.64, "text": " you know, something that's ingrained in the, in the sort of neural language model if you want.", "tokens": [51672, 291, 458, 11, 746, 300, 311, 3957, 31774, 294, 264, 11, 294, 264, 1333, 295, 18161, 2856, 2316, 498, 291, 528, 13, 51848], "temperature": 0.0, "avg_logprob": -0.11916211884597253, "compression_ratio": 1.8150470219435737, "no_speech_prob": 0.005453680641949177}, {"id": 845, "seek": 453196, "start": 4531.96, "end": 4537.8, "text": " Same for translation, same for all kinds of stuff. So you see this continuous evolution from,", "tokens": [50364, 10635, 337, 12853, 11, 912, 337, 439, 3685, 295, 1507, 13, 407, 291, 536, 341, 10957, 9303, 490, 11, 50656], "temperature": 0.0, "avg_logprob": -0.18264848535711115, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0006874869577586651}, {"id": 846, "seek": 453196, "start": 4539.24, "end": 4549.0, "text": " you know, less and less hand-crafting and more and more learning. And I think it's true in biology", "tokens": [50728, 291, 458, 11, 1570, 293, 1570, 1011, 12, 66, 10437, 783, 293, 544, 293, 544, 2539, 13, 400, 286, 519, 309, 311, 2074, 294, 14956, 51216], "temperature": 0.0, "avg_logprob": -0.18264848535711115, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0006874869577586651}, {"id": 847, "seek": 453196, "start": 4549.0, "end": 4556.76, "text": " as well. So, I mean, we might disagree about this, maybe not in this one little piece at the end,", "tokens": [51216, 382, 731, 13, 407, 11, 286, 914, 11, 321, 1062, 14091, 466, 341, 11, 1310, 406, 294, 341, 472, 707, 2522, 412, 264, 917, 11, 51604], "temperature": 0.0, "avg_logprob": -0.18264848535711115, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0006874869577586651}, {"id": 848, "seek": 455676, "start": 4556.76, "end": 4562.84, "text": " you mentioned active learning. It feels like active learning, which is the selection of data,", "tokens": [50364, 291, 2835, 4967, 2539, 13, 467, 3417, 411, 4967, 2539, 11, 597, 307, 264, 9450, 295, 1412, 11, 50668], "temperature": 0.0, "avg_logprob": -0.07057192590501574, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.038441456854343414}, {"id": 849, "seek": 455676, "start": 4562.84, "end": 4567.64, "text": " and also the interactivity needs to be part of this giant neural network. You cannot just be", "tokens": [50668, 293, 611, 264, 4648, 4253, 2203, 281, 312, 644, 295, 341, 7410, 18161, 3209, 13, 509, 2644, 445, 312, 50908], "temperature": 0.0, "avg_logprob": -0.07057192590501574, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.038441456854343414}, {"id": 850, "seek": 455676, "start": 4567.64, "end": 4573.8, "text": " an observer to do self-supervised learning. You have to, well, self-supervised learning is just", "tokens": [50908, 364, 27878, 281, 360, 2698, 12, 48172, 24420, 2539, 13, 509, 362, 281, 11, 731, 11, 2698, 12, 48172, 24420, 2539, 307, 445, 51216], "temperature": 0.0, "avg_logprob": -0.07057192590501574, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.038441456854343414}, {"id": 851, "seek": 455676, "start": 4573.8, "end": 4579.56, "text": " a word, but I would, whatever this giant stack of a neural network that's automatically learning,", "tokens": [51216, 257, 1349, 11, 457, 286, 576, 11, 2035, 341, 7410, 8630, 295, 257, 18161, 3209, 300, 311, 6772, 2539, 11, 51504], "temperature": 0.0, "avg_logprob": -0.07057192590501574, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.038441456854343414}, {"id": 852, "seek": 457956, "start": 4579.56, "end": 4588.200000000001, "text": " it feels, my intuition is that you have to have a system, whether it's a physical robot", "tokens": [50364, 309, 3417, 11, 452, 24002, 307, 300, 291, 362, 281, 362, 257, 1185, 11, 1968, 309, 311, 257, 4001, 7881, 50796], "temperature": 0.0, "avg_logprob": -0.09464551400447237, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00817821640521288}, {"id": 853, "seek": 457956, "start": 4588.200000000001, "end": 4594.68, "text": " or a digital robot that's interacting with the world and doing so in a flawed way and", "tokens": [50796, 420, 257, 4562, 7881, 300, 311, 18017, 365, 264, 1002, 293, 884, 370, 294, 257, 38823, 636, 293, 51120], "temperature": 0.0, "avg_logprob": -0.09464551400447237, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00817821640521288}, {"id": 854, "seek": 457956, "start": 4594.68, "end": 4603.0, "text": " improving over time in order to form the self-supervised learning. Well, you can't just give it a", "tokens": [51120, 11470, 670, 565, 294, 1668, 281, 1254, 264, 2698, 12, 48172, 24420, 2539, 13, 1042, 11, 291, 393, 380, 445, 976, 309, 257, 51536], "temperature": 0.0, "avg_logprob": -0.09464551400447237, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00817821640521288}, {"id": 855, "seek": 460300, "start": 4603.08, "end": 4608.52, "text": " giant sea of data. Okay, I agree and I disagree. I agree in the sense that I think,", "tokens": [50368, 7410, 4158, 295, 1412, 13, 1033, 11, 286, 3986, 293, 286, 14091, 13, 286, 3986, 294, 264, 2020, 300, 286, 519, 11, 50640], "temperature": 0.0, "avg_logprob": -0.12373191431949013, "compression_ratio": 1.8619246861924685, "no_speech_prob": 0.12747052311897278}, {"id": 856, "seek": 460300, "start": 4610.12, "end": 4616.28, "text": " I agree in two ways. The first way I agree is that if you want and you certainly need", "tokens": [50720, 286, 3986, 294, 732, 2098, 13, 440, 700, 636, 286, 3986, 307, 300, 498, 291, 528, 293, 291, 3297, 643, 51028], "temperature": 0.0, "avg_logprob": -0.12373191431949013, "compression_ratio": 1.8619246861924685, "no_speech_prob": 0.12747052311897278}, {"id": 857, "seek": 460300, "start": 4616.28, "end": 4619.72, "text": " a causal model of the world that allows you to predict the consequences of your actions,", "tokens": [51028, 257, 38755, 2316, 295, 264, 1002, 300, 4045, 291, 281, 6069, 264, 10098, 295, 428, 5909, 11, 51200], "temperature": 0.0, "avg_logprob": -0.12373191431949013, "compression_ratio": 1.8619246861924685, "no_speech_prob": 0.12747052311897278}, {"id": 858, "seek": 460300, "start": 4620.36, "end": 4624.92, "text": " to train that model, you need to take actions. You need to be able to act in a world and see the", "tokens": [51232, 281, 3847, 300, 2316, 11, 291, 643, 281, 747, 5909, 13, 509, 643, 281, 312, 1075, 281, 605, 294, 257, 1002, 293, 536, 264, 51460], "temperature": 0.0, "avg_logprob": -0.12373191431949013, "compression_ratio": 1.8619246861924685, "no_speech_prob": 0.12747052311897278}, {"id": 859, "seek": 460300, "start": 4624.92, "end": 4630.36, "text": " effect for you to learn causal models of the world. So that's not obvious because you can", "tokens": [51460, 1802, 337, 291, 281, 1466, 38755, 5245, 295, 264, 1002, 13, 407, 300, 311, 406, 6322, 570, 291, 393, 51732], "temperature": 0.0, "avg_logprob": -0.12373191431949013, "compression_ratio": 1.8619246861924685, "no_speech_prob": 0.12747052311897278}, {"id": 860, "seek": 463036, "start": 4630.44, "end": 4635.88, "text": " observe others and you can infer that they're similar to you and then you can learn from that.", "tokens": [50368, 11441, 2357, 293, 291, 393, 13596, 300, 436, 434, 2531, 281, 291, 293, 550, 291, 393, 1466, 490, 300, 13, 50640], "temperature": 0.0, "avg_logprob": -0.14214635664416897, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.012047512456774712}, {"id": 861, "seek": 463036, "start": 4635.88, "end": 4640.28, "text": " Yeah, but then you have to kind of hardware that part and mirror neurons and all that stuff.", "tokens": [50640, 865, 11, 457, 550, 291, 362, 281, 733, 295, 8837, 300, 644, 293, 8013, 22027, 293, 439, 300, 1507, 13, 50860], "temperature": 0.0, "avg_logprob": -0.14214635664416897, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.012047512456774712}, {"id": 862, "seek": 463036, "start": 4642.12, "end": 4649.32, "text": " And it's not clear to me how you would do this in a machine. So I think the action part would be", "tokens": [50952, 400, 309, 311, 406, 1850, 281, 385, 577, 291, 576, 360, 341, 294, 257, 3479, 13, 407, 286, 519, 264, 3069, 644, 576, 312, 51312], "temperature": 0.0, "avg_logprob": -0.14214635664416897, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.012047512456774712}, {"id": 863, "seek": 463036, "start": 4649.32, "end": 4656.92, "text": " necessary for having causal models of the world. The second reason it may be necessary or at least", "tokens": [51312, 4818, 337, 1419, 38755, 5245, 295, 264, 1002, 13, 440, 1150, 1778, 309, 815, 312, 4818, 420, 412, 1935, 51692], "temperature": 0.0, "avg_logprob": -0.14214635664416897, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.012047512456774712}, {"id": 864, "seek": 465692, "start": 4657.0, "end": 4663.96, "text": " more efficient is that active learning basically goes for the juggler of what you don't know.", "tokens": [50368, 544, 7148, 307, 300, 4967, 2539, 1936, 1709, 337, 264, 361, 3562, 1918, 295, 437, 291, 500, 380, 458, 13, 50716], "temperature": 0.0, "avg_logprob": -0.12802464934601182, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.007544454652816057}, {"id": 865, "seek": 465692, "start": 4663.96, "end": 4671.8, "text": " Right? There's obvious areas of uncertainty about your world and about how the world behaves.", "tokens": [50716, 1779, 30, 821, 311, 6322, 3179, 295, 15697, 466, 428, 1002, 293, 466, 577, 264, 1002, 36896, 13, 51108], "temperature": 0.0, "avg_logprob": -0.12802464934601182, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.007544454652816057}, {"id": 866, "seek": 465692, "start": 4672.92, "end": 4680.2, "text": " And you can resolve this uncertainty by systematic exploration of that part that you don't know.", "tokens": [51164, 400, 291, 393, 14151, 341, 15697, 538, 27249, 16197, 295, 300, 644, 300, 291, 500, 380, 458, 13, 51528], "temperature": 0.0, "avg_logprob": -0.12802464934601182, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.007544454652816057}, {"id": 867, "seek": 465692, "start": 4680.2, "end": 4684.12, "text": " And if you know that you don't know, then it makes you curious. You kind of look into", "tokens": [51528, 400, 498, 291, 458, 300, 291, 500, 380, 458, 11, 550, 309, 1669, 291, 6369, 13, 509, 733, 295, 574, 666, 51724], "temperature": 0.0, "avg_logprob": -0.12802464934601182, "compression_ratio": 1.6742081447963801, "no_speech_prob": 0.007544454652816057}, {"id": 868, "seek": 468412, "start": 4684.12, "end": 4692.5199999999995, "text": " situations that and across the animal world, different species at different levels of curiosity.", "tokens": [50364, 6851, 300, 293, 2108, 264, 5496, 1002, 11, 819, 6172, 412, 819, 4358, 295, 18769, 13, 50784], "temperature": 0.0, "avg_logprob": -0.19058883757818312, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.006898269057273865}, {"id": 869, "seek": 468412, "start": 4693.72, "end": 4699.5599999999995, "text": " Depending on how they're built. So cats and rats are incredibly curious. Dogs know so much,", "tokens": [50844, 22539, 322, 577, 436, 434, 3094, 13, 407, 11111, 293, 25691, 366, 6252, 6369, 13, 35504, 458, 370, 709, 11, 51136], "temperature": 0.0, "avg_logprob": -0.19058883757818312, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.006898269057273865}, {"id": 870, "seek": 468412, "start": 4699.5599999999995, "end": 4703.8, "text": " I mean less. So it could be useful to have that kind of curiosity.", "tokens": [51136, 286, 914, 1570, 13, 407, 309, 727, 312, 4420, 281, 362, 300, 733, 295, 18769, 13, 51348], "temperature": 0.0, "avg_logprob": -0.19058883757818312, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.006898269057273865}, {"id": 871, "seek": 468412, "start": 4703.8, "end": 4708.44, "text": " So it'd be useful, but curiosity just makes the process faster. It doesn't make the process exist.", "tokens": [51348, 407, 309, 1116, 312, 4420, 11, 457, 18769, 445, 1669, 264, 1399, 4663, 13, 467, 1177, 380, 652, 264, 1399, 2514, 13, 51580], "temperature": 0.0, "avg_logprob": -0.19058883757818312, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.006898269057273865}, {"id": 872, "seek": 470844, "start": 4709.4, "end": 4717.639999999999, "text": " So what process, what learning process is it that active learning makes more efficient?", "tokens": [50412, 407, 437, 1399, 11, 437, 2539, 1399, 307, 309, 300, 4967, 2539, 1669, 544, 7148, 30, 50824], "temperature": 0.0, "avg_logprob": -0.1751700522194446, "compression_ratio": 1.7228260869565217, "no_speech_prob": 0.009402455762028694}, {"id": 873, "seek": 470844, "start": 4718.599999999999, "end": 4724.679999999999, "text": " And I'm asking that first question. We haven't answered that question yet,", "tokens": [50872, 400, 286, 478, 3365, 300, 700, 1168, 13, 492, 2378, 380, 10103, 300, 1168, 1939, 11, 51176], "temperature": 0.0, "avg_logprob": -0.1751700522194446, "compression_ratio": 1.7228260869565217, "no_speech_prob": 0.009402455762028694}, {"id": 874, "seek": 470844, "start": 4724.679999999999, "end": 4727.96, "text": " so I'll worry about active learning once this question is...", "tokens": [51176, 370, 286, 603, 3292, 466, 4967, 2539, 1564, 341, 1168, 307, 485, 51340], "temperature": 0.0, "avg_logprob": -0.1751700522194446, "compression_ratio": 1.7228260869565217, "no_speech_prob": 0.009402455762028694}, {"id": 875, "seek": 470844, "start": 4727.96, "end": 4735.24, "text": " So it's the more fundamental question to ask. And if active learning or interaction increases", "tokens": [51340, 407, 309, 311, 264, 544, 8088, 1168, 281, 1029, 13, 400, 498, 4967, 2539, 420, 9285, 8637, 51704], "temperature": 0.0, "avg_logprob": -0.1751700522194446, "compression_ratio": 1.7228260869565217, "no_speech_prob": 0.009402455762028694}, {"id": 876, "seek": 473524, "start": 4735.32, "end": 4741.5599999999995, "text": " the efficiency of the learning. See, sometimes it becomes very different if the increase is", "tokens": [50368, 264, 10493, 295, 264, 2539, 13, 3008, 11, 2171, 309, 3643, 588, 819, 498, 264, 3488, 307, 50680], "temperature": 0.0, "avg_logprob": -0.17633240397383526, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.004533789120614529}, {"id": 877, "seek": 473524, "start": 4741.5599999999995, "end": 4748.04, "text": " several orders of magnitude. Right? That's true. But fundamentally, it's still the same thing.", "tokens": [50680, 2940, 9470, 295, 15668, 13, 1779, 30, 663, 311, 2074, 13, 583, 17879, 11, 309, 311, 920, 264, 912, 551, 13, 51004], "temperature": 0.0, "avg_logprob": -0.17633240397383526, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.004533789120614529}, {"id": 878, "seek": 473524, "start": 4748.04, "end": 4752.84, "text": " And building up the intuition about how to in a self-supervised way to construct", "tokens": [51004, 400, 2390, 493, 264, 24002, 466, 577, 281, 294, 257, 2698, 12, 48172, 24420, 636, 281, 7690, 51244], "temperature": 0.0, "avg_logprob": -0.17633240397383526, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.004533789120614529}, {"id": 879, "seek": 473524, "start": 4752.84, "end": 4759.24, "text": " background models, efficient or inefficient, is the core problem. What do you think about", "tokens": [51244, 3678, 5245, 11, 7148, 420, 43495, 11, 307, 264, 4965, 1154, 13, 708, 360, 291, 519, 466, 51564], "temperature": 0.0, "avg_logprob": -0.17633240397383526, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.004533789120614529}, {"id": 880, "seek": 475924, "start": 4759.24, "end": 4764.5199999999995, "text": " Yosha Ben-Jos talking about consciousness and all of these kinds of concepts?", "tokens": [50364, 398, 329, 1641, 3964, 12, 41, 329, 1417, 466, 10081, 293, 439, 295, 613, 3685, 295, 10392, 30, 50628], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 881, "seek": 475924, "start": 4764.5199999999995, "end": 4768.679999999999, "text": " Okay. I don't know what consciousness is, but...", "tokens": [50628, 1033, 13, 286, 500, 380, 458, 437, 10081, 307, 11, 457, 485, 50836], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 882, "seek": 475924, "start": 4770.12, "end": 4771.0, "text": " It's a good opener.", "tokens": [50908, 467, 311, 257, 665, 43850, 13, 50952], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 883, "seek": 475924, "start": 4771.88, "end": 4776.12, "text": " And to some extent, a lot of the things that are said about consciousness remind me of", "tokens": [50996, 400, 281, 512, 8396, 11, 257, 688, 295, 264, 721, 300, 366, 848, 466, 10081, 4160, 385, 295, 51208], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 884, "seek": 475924, "start": 4777.0, "end": 4781.5599999999995, "text": " the questions people were asking themselves in the 18th century or 17th century when they", "tokens": [51252, 264, 1651, 561, 645, 3365, 2969, 294, 264, 2443, 392, 4901, 420, 3282, 392, 4901, 562, 436, 51480], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 885, "seek": 475924, "start": 4781.5599999999995, "end": 4788.679999999999, "text": " discovered that how the eye works and the fact that the image at the back of the eye was upside", "tokens": [51480, 6941, 300, 577, 264, 3313, 1985, 293, 264, 1186, 300, 264, 3256, 412, 264, 646, 295, 264, 3313, 390, 14119, 51836], "temperature": 0.0, "avg_logprob": -0.12940523965018136, "compression_ratio": 1.676, "no_speech_prob": 0.012041032314300537}, {"id": 886, "seek": 478868, "start": 4788.68, "end": 4794.4400000000005, "text": " down because you have a lens. And so on your retina, the image that forms is an image of the", "tokens": [50364, 760, 570, 291, 362, 257, 6765, 13, 400, 370, 322, 428, 1533, 1426, 11, 264, 3256, 300, 6422, 307, 364, 3256, 295, 264, 50652], "temperature": 0.0, "avg_logprob": -0.1259653742720441, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.01172885112464428}, {"id": 887, "seek": 478868, "start": 4794.4400000000005, "end": 4799.72, "text": " world, but it's upside down. How is it that you see right side up? And with what we know today", "tokens": [50652, 1002, 11, 457, 309, 311, 14119, 760, 13, 1012, 307, 309, 300, 291, 536, 558, 1252, 493, 30, 400, 365, 437, 321, 458, 965, 50916], "temperature": 0.0, "avg_logprob": -0.1259653742720441, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.01172885112464428}, {"id": 888, "seek": 478868, "start": 4799.72, "end": 4805.88, "text": " in science, we realize this question doesn't make any sense or is kind of ridiculous in some way.", "tokens": [50916, 294, 3497, 11, 321, 4325, 341, 1168, 1177, 380, 652, 604, 2020, 420, 307, 733, 295, 11083, 294, 512, 636, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1259653742720441, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.01172885112464428}, {"id": 889, "seek": 478868, "start": 4805.88, "end": 4809.56, "text": " Right? So I think a lot of what is said about consciousness is of that nature. Now that said,", "tokens": [51224, 1779, 30, 407, 286, 519, 257, 688, 295, 437, 307, 848, 466, 10081, 307, 295, 300, 3687, 13, 823, 300, 848, 11, 51408], "temperature": 0.0, "avg_logprob": -0.1259653742720441, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.01172885112464428}, {"id": 890, "seek": 478868, "start": 4809.56, "end": 4814.52, "text": " there's a lot of really smart people for whom I have a lot of respect who are talking about this", "tokens": [51408, 456, 311, 257, 688, 295, 534, 4069, 561, 337, 7101, 286, 362, 257, 688, 295, 3104, 567, 366, 1417, 466, 341, 51656], "temperature": 0.0, "avg_logprob": -0.1259653742720441, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.01172885112464428}, {"id": 891, "seek": 481452, "start": 4814.52, "end": 4821.88, "text": " topic, people like David Chalmers, who is a colleague of mine at NYU. I have kind of an", "tokens": [50364, 4829, 11, 561, 411, 4389, 761, 304, 18552, 11, 567, 307, 257, 13532, 295, 3892, 412, 42682, 13, 286, 362, 733, 295, 364, 50732], "temperature": 0.0, "avg_logprob": -0.15374133770282453, "compression_ratio": 1.3854166666666667, "no_speech_prob": 0.01893121376633644}, {"id": 892, "seek": 481452, "start": 4821.88, "end": 4829.96, "text": " orthodox folk speculative hypothesis about consciousness. So we're talking about this", "tokens": [50732, 19052, 22189, 15748, 49415, 17291, 466, 10081, 13, 407, 321, 434, 1417, 466, 341, 51136], "temperature": 0.0, "avg_logprob": -0.15374133770282453, "compression_ratio": 1.3854166666666667, "no_speech_prob": 0.01893121376633644}, {"id": 893, "seek": 481452, "start": 4829.96, "end": 4838.360000000001, "text": " idea of a world model. And I think our entire prefrontal context basically is the engine for", "tokens": [51136, 1558, 295, 257, 1002, 2316, 13, 400, 286, 519, 527, 2302, 659, 11496, 304, 4319, 1936, 307, 264, 2848, 337, 51556], "temperature": 0.0, "avg_logprob": -0.15374133770282453, "compression_ratio": 1.3854166666666667, "no_speech_prob": 0.01893121376633644}, {"id": 894, "seek": 483836, "start": 4838.44, "end": 4845.32, "text": " a world model. But when we are attending at a particular situation, we're focused on that", "tokens": [50368, 257, 1002, 2316, 13, 583, 562, 321, 366, 15862, 412, 257, 1729, 2590, 11, 321, 434, 5178, 322, 300, 50712], "temperature": 0.0, "avg_logprob": -0.090462492800307, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.006661863531917334}, {"id": 895, "seek": 483836, "start": 4845.32, "end": 4853.24, "text": " situation, we basically cannot attend to anything else. And that seems to suggest that we basically", "tokens": [50712, 2590, 11, 321, 1936, 2644, 6888, 281, 1340, 1646, 13, 400, 300, 2544, 281, 3402, 300, 321, 1936, 51108], "temperature": 0.0, "avg_logprob": -0.090462492800307, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.006661863531917334}, {"id": 896, "seek": 483836, "start": 4853.24, "end": 4861.32, "text": " have only one world model engine in our prefrontal context. That engine is configurable to the", "tokens": [51108, 362, 787, 472, 1002, 2316, 2848, 294, 527, 659, 11496, 304, 4319, 13, 663, 2848, 307, 22192, 712, 281, 264, 51512], "temperature": 0.0, "avg_logprob": -0.090462492800307, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.006661863531917334}, {"id": 897, "seek": 483836, "start": 4861.32, "end": 4868.28, "text": " situation at hand. So we are building a box out of wood or we are driving down the highway", "tokens": [51512, 2590, 412, 1011, 13, 407, 321, 366, 2390, 257, 2424, 484, 295, 4576, 420, 321, 366, 4840, 760, 264, 17205, 51860], "temperature": 0.0, "avg_logprob": -0.090462492800307, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.006661863531917334}, {"id": 898, "seek": 486828, "start": 4868.28, "end": 4874.2, "text": " playing chess. We basically have a single model of the world that we configure into the situation", "tokens": [50364, 2433, 24122, 13, 492, 1936, 362, 257, 2167, 2316, 295, 264, 1002, 300, 321, 22162, 666, 264, 2590, 50660], "temperature": 0.0, "avg_logprob": -0.06207834225948726, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0010000234469771385}, {"id": 899, "seek": 486828, "start": 4874.2, "end": 4880.44, "text": " at hand, which is why we can only attend to one task at a time. Now, if there is a task that we", "tokens": [50660, 412, 1011, 11, 597, 307, 983, 321, 393, 787, 6888, 281, 472, 5633, 412, 257, 565, 13, 823, 11, 498, 456, 307, 257, 5633, 300, 321, 50972], "temperature": 0.0, "avg_logprob": -0.06207834225948726, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0010000234469771385}, {"id": 900, "seek": 486828, "start": 4880.44, "end": 4887.32, "text": " do repeatedly, it goes from the sort of deliberate reasoning using model of the world and prediction", "tokens": [50972, 360, 18227, 11, 309, 1709, 490, 264, 1333, 295, 30515, 21577, 1228, 2316, 295, 264, 1002, 293, 17630, 51316], "temperature": 0.0, "avg_logprob": -0.06207834225948726, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0010000234469771385}, {"id": 901, "seek": 486828, "start": 4887.32, "end": 4890.36, "text": " and perhaps something like model predictive control, which I was talking about earlier,", "tokens": [51316, 293, 4317, 746, 411, 2316, 35521, 1969, 11, 597, 286, 390, 1417, 466, 3071, 11, 51468], "temperature": 0.0, "avg_logprob": -0.06207834225948726, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0010000234469771385}, {"id": 902, "seek": 486828, "start": 4891.24, "end": 4895.48, "text": " to something that is more subconscious that becomes automatic. So I don't know if you've", "tokens": [51512, 281, 746, 300, 307, 544, 27389, 300, 3643, 12509, 13, 407, 286, 500, 380, 458, 498, 291, 600, 51724], "temperature": 0.0, "avg_logprob": -0.06207834225948726, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0010000234469771385}, {"id": 903, "seek": 489548, "start": 4895.48, "end": 4905.4, "text": " ever played against a chess grandmaster. I get wiped out in 10 plays. And I have to think about", "tokens": [50364, 1562, 3737, 1970, 257, 24122, 2697, 21640, 13, 286, 483, 26879, 484, 294, 1266, 5749, 13, 400, 286, 362, 281, 519, 466, 50860], "temperature": 0.0, "avg_logprob": -0.1312825944688585, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0257699117064476}, {"id": 904, "seek": 489548, "start": 4905.4, "end": 4913.08, "text": " my move for like 15 minutes. And the person in front of me, the grandmaster, would just like", "tokens": [50860, 452, 1286, 337, 411, 2119, 2077, 13, 400, 264, 954, 294, 1868, 295, 385, 11, 264, 2697, 21640, 11, 576, 445, 411, 51244], "temperature": 0.0, "avg_logprob": -0.1312825944688585, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0257699117064476}, {"id": 905, "seek": 489548, "start": 4913.719999999999, "end": 4919.879999999999, "text": " react within seconds. He doesn't need to think about it. That's become part of the subconscious", "tokens": [51276, 4515, 1951, 3949, 13, 634, 1177, 380, 643, 281, 519, 466, 309, 13, 663, 311, 1813, 644, 295, 264, 27389, 51584], "temperature": 0.0, "avg_logprob": -0.1312825944688585, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0257699117064476}, {"id": 906, "seek": 491988, "start": 4919.88, "end": 4927.56, "text": " because it's basically just pattern recognition at this point. The first few hours you drive a car,", "tokens": [50364, 570, 309, 311, 1936, 445, 5102, 11150, 412, 341, 935, 13, 440, 700, 1326, 2496, 291, 3332, 257, 1032, 11, 50748], "temperature": 0.0, "avg_logprob": -0.1193490116684525, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.01362849585711956}, {"id": 907, "seek": 491988, "start": 4927.56, "end": 4931.72, "text": " you are really attentive, you can't do anything else. And then after 20, 30 hours of practice,", "tokens": [50748, 291, 366, 534, 43661, 11, 291, 393, 380, 360, 1340, 1646, 13, 400, 550, 934, 945, 11, 2217, 2496, 295, 3124, 11, 50956], "temperature": 0.0, "avg_logprob": -0.1193490116684525, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.01362849585711956}, {"id": 908, "seek": 491988, "start": 4931.72, "end": 4936.12, "text": " 50 hours, it's subconscious. You can talk to the person next to you, things like that.", "tokens": [50956, 2625, 2496, 11, 309, 311, 27389, 13, 509, 393, 751, 281, 264, 954, 958, 281, 291, 11, 721, 411, 300, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1193490116684525, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.01362849585711956}, {"id": 909, "seek": 491988, "start": 4936.92, "end": 4940.04, "text": " Unless the situation becomes unpredictable, and then you have to stop talking.", "tokens": [51216, 16581, 264, 2590, 3643, 31160, 11, 293, 550, 291, 362, 281, 1590, 1417, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1193490116684525, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.01362849585711956}, {"id": 910, "seek": 491988, "start": 4941.0, "end": 4947.24, "text": " So that suggests you only have one model in your head. And it might suggest the idea that", "tokens": [51420, 407, 300, 13409, 291, 787, 362, 472, 2316, 294, 428, 1378, 13, 400, 309, 1062, 3402, 264, 1558, 300, 51732], "temperature": 0.0, "avg_logprob": -0.1193490116684525, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.01362849585711956}, {"id": 911, "seek": 494724, "start": 4947.24, "end": 4952.44, "text": " consciousness basically is the module that configures this world model of yours. You need to have", "tokens": [50364, 10081, 1936, 307, 264, 10088, 300, 6662, 1303, 341, 1002, 2316, 295, 6342, 13, 509, 643, 281, 362, 50624], "temperature": 0.0, "avg_logprob": -0.10225829623994373, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.00045797889470122755}, {"id": 912, "seek": 494724, "start": 4952.44, "end": 4959.16, "text": " some sort of executive kind of overseer that configures your world model for the situation", "tokens": [50624, 512, 1333, 295, 10140, 733, 295, 11916, 260, 300, 6662, 1303, 428, 1002, 2316, 337, 264, 2590, 50960], "temperature": 0.0, "avg_logprob": -0.10225829623994373, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.00045797889470122755}, {"id": 913, "seek": 494724, "start": 4959.16, "end": 4965.4, "text": " at hand. And that needs to kind of the really curious concept that consciousness is not a", "tokens": [50960, 412, 1011, 13, 400, 300, 2203, 281, 733, 295, 264, 534, 6369, 3410, 300, 10081, 307, 406, 257, 51272], "temperature": 0.0, "avg_logprob": -0.10225829623994373, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.00045797889470122755}, {"id": 914, "seek": 494724, "start": 4965.4, "end": 4970.84, "text": " consequence of the power of our mind, but of the limitation of our brains. But because we have only", "tokens": [51272, 18326, 295, 264, 1347, 295, 527, 1575, 11, 457, 295, 264, 27432, 295, 527, 15442, 13, 583, 570, 321, 362, 787, 51544], "temperature": 0.0, "avg_logprob": -0.10225829623994373, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.00045797889470122755}, {"id": 915, "seek": 497084, "start": 4970.84, "end": 4977.72, "text": " one world model, we have to be conscious. If we had as many world models as there are situations we", "tokens": [50364, 472, 1002, 2316, 11, 321, 362, 281, 312, 6648, 13, 759, 321, 632, 382, 867, 1002, 5245, 382, 456, 366, 6851, 321, 50708], "temperature": 0.0, "avg_logprob": -0.12394002340372326, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.04269446060061455}, {"id": 916, "seek": 497084, "start": 4977.72, "end": 4981.96, "text": " encounter, then we could do all of them simultaneously. And we wouldn't need this sort of", "tokens": [50708, 8593, 11, 550, 321, 727, 360, 439, 295, 552, 16561, 13, 400, 321, 2759, 380, 643, 341, 1333, 295, 50920], "temperature": 0.0, "avg_logprob": -0.12394002340372326, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.04269446060061455}, {"id": 917, "seek": 497084, "start": 4981.96, "end": 4986.84, "text": " executive control that we call consciousness. Yeah, interesting. And somehow maybe that", "tokens": [50920, 10140, 1969, 300, 321, 818, 10081, 13, 865, 11, 1880, 13, 400, 6063, 1310, 300, 51164], "temperature": 0.0, "avg_logprob": -0.12394002340372326, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.04269446060061455}, {"id": 918, "seek": 497084, "start": 4986.84, "end": 4992.12, "text": " executive controller, I mean, the hard problem of consciousness, there's some kind of chemicals", "tokens": [51164, 10140, 10561, 11, 286, 914, 11, 264, 1152, 1154, 295, 10081, 11, 456, 311, 512, 733, 295, 16152, 51428], "temperature": 0.0, "avg_logprob": -0.12394002340372326, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.04269446060061455}, {"id": 919, "seek": 497084, "start": 4992.12, "end": 4997.4800000000005, "text": " and biology that's creating a feeling like it feels to experience some of these things.", "tokens": [51428, 293, 14956, 300, 311, 4084, 257, 2633, 411, 309, 3417, 281, 1752, 512, 295, 613, 721, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12394002340372326, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.04269446060061455}, {"id": 920, "seek": 499748, "start": 4998.44, "end": 5005.08, "text": " That's kind of like the hard question is, what the heck is that? And why is that useful? Maybe the", "tokens": [50412, 663, 311, 733, 295, 411, 264, 1152, 1168, 307, 11, 437, 264, 12872, 307, 300, 30, 400, 983, 307, 300, 4420, 30, 2704, 264, 50744], "temperature": 0.0, "avg_logprob": -0.14131528052730838, "compression_ratio": 1.5561497326203209, "no_speech_prob": 0.0020183688029646873}, {"id": 921, "seek": 499748, "start": 5005.08, "end": 5011.5599999999995, "text": " more pragmatic question? Why is it useful to feel like this is really you experiencing this versus", "tokens": [50744, 544, 46904, 1168, 30, 1545, 307, 309, 4420, 281, 841, 411, 341, 307, 534, 291, 11139, 341, 5717, 51068], "temperature": 0.0, "avg_logprob": -0.14131528052730838, "compression_ratio": 1.5561497326203209, "no_speech_prob": 0.0020183688029646873}, {"id": 922, "seek": 499748, "start": 5011.5599999999995, "end": 5020.919999999999, "text": " just like information being processed? It could be just a very nice side effect of the way we", "tokens": [51068, 445, 411, 1589, 885, 18846, 30, 467, 727, 312, 445, 257, 588, 1481, 1252, 1802, 295, 264, 636, 321, 51536], "temperature": 0.0, "avg_logprob": -0.14131528052730838, "compression_ratio": 1.5561497326203209, "no_speech_prob": 0.0020183688029646873}, {"id": 923, "seek": 502092, "start": 5020.92, "end": 5029.8, "text": " evolved. That's just very useful to feel a sense of ownership to the decisions you make,", "tokens": [50364, 14178, 13, 663, 311, 445, 588, 4420, 281, 841, 257, 2020, 295, 15279, 281, 264, 5327, 291, 652, 11, 50808], "temperature": 0.0, "avg_logprob": -0.13466343437273479, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.12748666107654572}, {"id": 924, "seek": 502092, "start": 5029.8, "end": 5034.04, "text": " to the perceptions you make, to the model you're trying to maintain, like you own this thing.", "tokens": [50808, 281, 264, 35258, 291, 652, 11, 281, 264, 2316, 291, 434, 1382, 281, 6909, 11, 411, 291, 1065, 341, 551, 13, 51020], "temperature": 0.0, "avg_logprob": -0.13466343437273479, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.12748666107654572}, {"id": 925, "seek": 502092, "start": 5034.76, "end": 5039.08, "text": " And this is the only one you got. And if you lose it, it's going to really suck. And so you should", "tokens": [51056, 400, 341, 307, 264, 787, 472, 291, 658, 13, 400, 498, 291, 3624, 309, 11, 309, 311, 516, 281, 534, 9967, 13, 400, 370, 291, 820, 51272], "temperature": 0.0, "avg_logprob": -0.13466343437273479, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.12748666107654572}, {"id": 926, "seek": 502092, "start": 5039.08, "end": 5047.8, "text": " really send the brain some signals about it. What ideas do you believe might be true that most or at", "tokens": [51272, 534, 2845, 264, 3567, 512, 12354, 466, 309, 13, 708, 3487, 360, 291, 1697, 1062, 312, 2074, 300, 881, 420, 412, 51708], "temperature": 0.0, "avg_logprob": -0.13466343437273479, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.12748666107654572}, {"id": 927, "seek": 504780, "start": 5047.8, "end": 5052.84, "text": " least many people disagree with you with? Let's say in the space of machine learning.", "tokens": [50364, 1935, 867, 561, 14091, 365, 291, 365, 30, 961, 311, 584, 294, 264, 1901, 295, 3479, 2539, 13, 50616], "temperature": 0.0, "avg_logprob": -0.14690648859197444, "compression_ratio": 1.7131782945736433, "no_speech_prob": 0.004393450915813446}, {"id": 928, "seek": 504780, "start": 5053.64, "end": 5061.0, "text": " Well, depends who you talk about. So certainly there is a bunch of people who are nativists,", "tokens": [50656, 1042, 11, 5946, 567, 291, 751, 466, 13, 407, 3297, 456, 307, 257, 3840, 295, 561, 567, 366, 2249, 592, 1751, 11, 51024], "temperature": 0.0, "avg_logprob": -0.14690648859197444, "compression_ratio": 1.7131782945736433, "no_speech_prob": 0.004393450915813446}, {"id": 929, "seek": 504780, "start": 5061.0, "end": 5065.0, "text": " who think that a lot of the basic things about the world are kind of hardwired in our minds.", "tokens": [51024, 567, 519, 300, 257, 688, 295, 264, 3875, 721, 466, 264, 1002, 366, 733, 295, 1152, 86, 1824, 294, 527, 9634, 13, 51224], "temperature": 0.0, "avg_logprob": -0.14690648859197444, "compression_ratio": 1.7131782945736433, "no_speech_prob": 0.004393450915813446}, {"id": 930, "seek": 504780, "start": 5066.360000000001, "end": 5069.56, "text": " Things like the world is three dimensional, for example, is that hardwired.", "tokens": [51292, 9514, 411, 264, 1002, 307, 1045, 18795, 11, 337, 1365, 11, 307, 300, 1152, 86, 1824, 13, 51452], "temperature": 0.0, "avg_logprob": -0.14690648859197444, "compression_ratio": 1.7131782945736433, "no_speech_prob": 0.004393450915813446}, {"id": 931, "seek": 504780, "start": 5070.360000000001, "end": 5077.400000000001, "text": " Things like object permanence is something that we learn before the age of three months or so,", "tokens": [51492, 9514, 411, 2657, 8105, 655, 307, 746, 300, 321, 1466, 949, 264, 3205, 295, 1045, 2493, 420, 370, 11, 51844], "temperature": 0.0, "avg_logprob": -0.14690648859197444, "compression_ratio": 1.7131782945736433, "no_speech_prob": 0.004393450915813446}, {"id": 932, "seek": 507740, "start": 5077.799999999999, "end": 5084.28, "text": " or are we born with it? And there are very wide disagreements among the cognitive scientists", "tokens": [50384, 420, 366, 321, 4232, 365, 309, 30, 400, 456, 366, 588, 4874, 23926, 6400, 3654, 264, 15605, 7708, 50708], "temperature": 0.0, "avg_logprob": -0.1107927285707914, "compression_ratio": 1.7698412698412698, "no_speech_prob": 0.000880931387655437}, {"id": 933, "seek": 507740, "start": 5085.5599999999995, "end": 5088.28, "text": " for this. I think those things are actually very simple to learn.", "tokens": [50772, 337, 341, 13, 286, 519, 729, 721, 366, 767, 588, 2199, 281, 1466, 13, 50908], "temperature": 0.0, "avg_logprob": -0.1107927285707914, "compression_ratio": 1.7698412698412698, "no_speech_prob": 0.000880931387655437}, {"id": 934, "seek": 507740, "start": 5090.5199999999995, "end": 5096.36, "text": " Is it the case that the oriented edge detectors in V1 are learned or are they hardwired? I think", "tokens": [51020, 1119, 309, 264, 1389, 300, 264, 21841, 4691, 46866, 294, 691, 16, 366, 3264, 420, 366, 436, 1152, 86, 1824, 30, 286, 519, 51312], "temperature": 0.0, "avg_logprob": -0.1107927285707914, "compression_ratio": 1.7698412698412698, "no_speech_prob": 0.000880931387655437}, {"id": 935, "seek": 507740, "start": 5096.36, "end": 5100.5199999999995, "text": " they are learned. They might be learned before both because it's really easy to generate signals", "tokens": [51312, 436, 366, 3264, 13, 814, 1062, 312, 3264, 949, 1293, 570, 309, 311, 534, 1858, 281, 8460, 12354, 51520], "temperature": 0.0, "avg_logprob": -0.1107927285707914, "compression_ratio": 1.7698412698412698, "no_speech_prob": 0.000880931387655437}, {"id": 936, "seek": 507740, "start": 5100.5199999999995, "end": 5106.36, "text": " from the retina that actually will train edge detectors. And again, those are things that can", "tokens": [51520, 490, 264, 1533, 1426, 300, 767, 486, 3847, 4691, 46866, 13, 400, 797, 11, 729, 366, 721, 300, 393, 51812], "temperature": 0.0, "avg_logprob": -0.1107927285707914, "compression_ratio": 1.7698412698412698, "no_speech_prob": 0.000880931387655437}, {"id": 937, "seek": 510636, "start": 5106.36, "end": 5114.12, "text": " be learned within minutes of opening your eyes. Since the 1990s, we have algorithms that can", "tokens": [50364, 312, 3264, 1951, 2077, 295, 5193, 428, 2575, 13, 4162, 264, 13384, 82, 11, 321, 362, 14642, 300, 393, 50752], "temperature": 0.0, "avg_logprob": -0.0947641882785531, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008518955437466502}, {"id": 938, "seek": 510636, "start": 5114.12, "end": 5118.759999999999, "text": " learn oriented edge detectors completely unsupervised with the equivalent of a few minutes of real", "tokens": [50752, 1466, 21841, 4691, 46866, 2584, 2693, 12879, 24420, 365, 264, 10344, 295, 257, 1326, 2077, 295, 957, 50984], "temperature": 0.0, "avg_logprob": -0.0947641882785531, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008518955437466502}, {"id": 939, "seek": 510636, "start": 5118.759999999999, "end": 5124.839999999999, "text": " time. So those things have to be learned. And there's also those MIT experiments where you", "tokens": [50984, 565, 13, 407, 729, 721, 362, 281, 312, 3264, 13, 400, 456, 311, 611, 729, 13100, 12050, 689, 291, 51288], "temperature": 0.0, "avg_logprob": -0.0947641882785531, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008518955437466502}, {"id": 940, "seek": 510636, "start": 5124.839999999999, "end": 5131.24, "text": " kind of plug the optical nerve on the auditory cortex of a baby ferret and that auditory cortex", "tokens": [51288, 733, 295, 5452, 264, 20674, 16355, 322, 264, 17748, 827, 33312, 295, 257, 3186, 7202, 1505, 293, 300, 17748, 827, 33312, 51608], "temperature": 0.0, "avg_logprob": -0.0947641882785531, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008518955437466502}, {"id": 941, "seek": 513124, "start": 5131.24, "end": 5137.0, "text": " become a visual cortex essentially. So clearly, there's running taking place there.", "tokens": [50364, 1813, 257, 5056, 33312, 4476, 13, 407, 4448, 11, 456, 311, 2614, 1940, 1081, 456, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11760908184629498, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.005137368571013212}, {"id": 942, "seek": 513124, "start": 5137.88, "end": 5142.44, "text": " So I think a lot of what people think are so basic that they need to be hardwired,", "tokens": [50696, 407, 286, 519, 257, 688, 295, 437, 561, 519, 366, 370, 3875, 300, 436, 643, 281, 312, 1152, 86, 1824, 11, 50924], "temperature": 0.0, "avg_logprob": -0.11760908184629498, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.005137368571013212}, {"id": 943, "seek": 513124, "start": 5143.08, "end": 5145.32, "text": " I think a lot of those things are learned because they're easy to learn.", "tokens": [50956, 286, 519, 257, 688, 295, 729, 721, 366, 3264, 570, 436, 434, 1858, 281, 1466, 13, 51068], "temperature": 0.0, "avg_logprob": -0.11760908184629498, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.005137368571013212}, {"id": 944, "seek": 513124, "start": 5146.2, "end": 5151.48, "text": " So you put a lot of value in the power of learning. What kind of things do you suspect", "tokens": [51112, 407, 291, 829, 257, 688, 295, 2158, 294, 264, 1347, 295, 2539, 13, 708, 733, 295, 721, 360, 291, 9091, 51376], "temperature": 0.0, "avg_logprob": -0.11760908184629498, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.005137368571013212}, {"id": 945, "seek": 513124, "start": 5151.48, "end": 5155.32, "text": " might not be learned? Is there something that could not be learned?", "tokens": [51376, 1062, 406, 312, 3264, 30, 1119, 456, 746, 300, 727, 406, 312, 3264, 30, 51568], "temperature": 0.0, "avg_logprob": -0.11760908184629498, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.005137368571013212}, {"id": 946, "seek": 515532, "start": 5155.96, "end": 5163.32, "text": " So your intrinsic drives are not learned. There are the things that make humans human", "tokens": [50396, 407, 428, 35698, 11754, 366, 406, 3264, 13, 821, 366, 264, 721, 300, 652, 6255, 1952, 50764], "temperature": 0.0, "avg_logprob": -0.13742502836080697, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0035338308662176132}, {"id": 947, "seek": 515532, "start": 5163.32, "end": 5170.2, "text": " or make cats different from dogs. It's the basic drives that are kind of hardwired in our", "tokens": [50764, 420, 652, 11111, 819, 490, 7197, 13, 467, 311, 264, 3875, 11754, 300, 366, 733, 295, 1152, 86, 1824, 294, 527, 51108], "temperature": 0.0, "avg_logprob": -0.13742502836080697, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0035338308662176132}, {"id": 948, "seek": 515532, "start": 5170.84, "end": 5175.24, "text": " Bezo Ganglia. I mean, there are people who are working on this kind of stuff that's called", "tokens": [51140, 879, 4765, 17984, 14218, 13, 286, 914, 11, 456, 366, 561, 567, 366, 1364, 322, 341, 733, 295, 1507, 300, 311, 1219, 51360], "temperature": 0.0, "avg_logprob": -0.13742502836080697, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0035338308662176132}, {"id": 949, "seek": 515532, "start": 5175.24, "end": 5179.48, "text": " intrinsic motivation in the context of reinforcement learning. So these are objective", "tokens": [51360, 35698, 12335, 294, 264, 4319, 295, 29280, 2539, 13, 407, 613, 366, 10024, 51572], "temperature": 0.0, "avg_logprob": -0.13742502836080697, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0035338308662176132}, {"id": 950, "seek": 515532, "start": 5179.48, "end": 5184.44, "text": " functions where the reward doesn't come from the external world. It's computed by your own brain.", "tokens": [51572, 6828, 689, 264, 7782, 1177, 380, 808, 490, 264, 8320, 1002, 13, 467, 311, 40610, 538, 428, 1065, 3567, 13, 51820], "temperature": 0.0, "avg_logprob": -0.13742502836080697, "compression_ratio": 1.6791044776119404, "no_speech_prob": 0.0035338308662176132}, {"id": 951, "seek": 518444, "start": 5184.44, "end": 5189.16, "text": " Your own brain computes whether you're happy or not. It measures your degree of", "tokens": [50364, 2260, 1065, 3567, 715, 1819, 1968, 291, 434, 2055, 420, 406, 13, 467, 8000, 428, 4314, 295, 50600], "temperature": 0.0, "avg_logprob": -0.10377307270848474, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0008553583174943924}, {"id": 952, "seek": 518444, "start": 5190.839999999999, "end": 5197.0, "text": " comfort or in comfort. And because it's your brain computing this, presumably it knows also", "tokens": [50684, 3400, 420, 294, 3400, 13, 400, 570, 309, 311, 428, 3567, 15866, 341, 11, 26742, 309, 3255, 611, 50992], "temperature": 0.0, "avg_logprob": -0.10377307270848474, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0008553583174943924}, {"id": 953, "seek": 518444, "start": 5197.0, "end": 5205.24, "text": " how to estimate gradients of this. So it's easier to learn when your objective is intrinsic.", "tokens": [50992, 577, 281, 12539, 2771, 2448, 295, 341, 13, 407, 309, 311, 3571, 281, 1466, 562, 428, 10024, 307, 35698, 13, 51404], "temperature": 0.0, "avg_logprob": -0.10377307270848474, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0008553583174943924}, {"id": 954, "seek": 518444, "start": 5206.919999999999, "end": 5213.24, "text": " So that has to be hardwired. The critic that makes long-term prediction of the outcome,", "tokens": [51488, 407, 300, 575, 281, 312, 1152, 86, 1824, 13, 440, 7850, 300, 1669, 938, 12, 7039, 17630, 295, 264, 9700, 11, 51804], "temperature": 0.0, "avg_logprob": -0.10377307270848474, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0008553583174943924}, {"id": 955, "seek": 521324, "start": 5213.32, "end": 5219.5599999999995, "text": " which is the eventual result of this, that's learned. And perception is learned and your", "tokens": [50368, 597, 307, 264, 33160, 1874, 295, 341, 11, 300, 311, 3264, 13, 400, 12860, 307, 3264, 293, 428, 50680], "temperature": 0.0, "avg_logprob": -0.1331759849480823, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006367925088852644}, {"id": 956, "seek": 521324, "start": 5219.5599999999995, "end": 5224.36, "text": " model of the world is learned. But let me take an example of why the critic... I mean,", "tokens": [50680, 2316, 295, 264, 1002, 307, 3264, 13, 583, 718, 385, 747, 364, 1365, 295, 983, 264, 7850, 485, 286, 914, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1331759849480823, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006367925088852644}, {"id": 957, "seek": 521324, "start": 5224.36, "end": 5231.48, "text": " an example of how the critic may be learned. If I come to you, I reach across the table and", "tokens": [50920, 364, 1365, 295, 577, 264, 7850, 815, 312, 3264, 13, 759, 286, 808, 281, 291, 11, 286, 2524, 2108, 264, 3199, 293, 51276], "temperature": 0.0, "avg_logprob": -0.1331759849480823, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006367925088852644}, {"id": 958, "seek": 521324, "start": 5231.48, "end": 5236.04, "text": " I pinch your arm, complete surprise for you. You would not have expected this from me.", "tokens": [51276, 286, 14614, 428, 3726, 11, 3566, 6365, 337, 291, 13, 509, 576, 406, 362, 5176, 341, 490, 385, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1331759849480823, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006367925088852644}, {"id": 959, "seek": 521324, "start": 5236.04, "end": 5239.8, "text": " I was expecting that the whole time, but yes. Let's say for the sake of the story.", "tokens": [51504, 286, 390, 9650, 300, 264, 1379, 565, 11, 457, 2086, 13, 961, 311, 584, 337, 264, 9717, 295, 264, 1657, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1331759849480823, "compression_ratio": 1.7003891050583657, "no_speech_prob": 0.006367925088852644}, {"id": 960, "seek": 523980, "start": 5240.52, "end": 5246.52, "text": " Okay. Your bezelganglia is going to light up because it's going to hurt, right?", "tokens": [50400, 1033, 13, 2260, 10782, 338, 19619, 14218, 307, 516, 281, 1442, 493, 570, 309, 311, 516, 281, 4607, 11, 558, 30, 50700], "temperature": 0.0, "avg_logprob": -0.17821083068847657, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.010148510336875916}, {"id": 961, "seek": 523980, "start": 5248.28, "end": 5252.84, "text": " And now your model of the world includes the fact that I may pinch you if I approach my...", "tokens": [50788, 400, 586, 428, 2316, 295, 264, 1002, 5974, 264, 1186, 300, 286, 815, 14614, 291, 498, 286, 3109, 452, 485, 51016], "temperature": 0.0, "avg_logprob": -0.17821083068847657, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.010148510336875916}, {"id": 962, "seek": 523980, "start": 5254.68, "end": 5255.8, "text": " Don't trust humans.", "tokens": [51108, 1468, 380, 3361, 6255, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17821083068847657, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.010148510336875916}, {"id": 963, "seek": 523980, "start": 5256.92, "end": 5261.320000000001, "text": " My hand to your arm. So if I try again, you're going to recoil. And that's your critic,", "tokens": [51220, 1222, 1011, 281, 428, 3726, 13, 407, 498, 286, 853, 797, 11, 291, 434, 516, 281, 42053, 13, 400, 300, 311, 428, 7850, 11, 51440], "temperature": 0.0, "avg_logprob": -0.17821083068847657, "compression_ratio": 1.4479166666666667, "no_speech_prob": 0.010148510336875916}, {"id": 964, "seek": 526132, "start": 5262.28, "end": 5271.96, "text": " your predictor of your ultimate pain system that predicts that something bad is going to", "tokens": [50412, 428, 6069, 284, 295, 428, 9705, 1822, 1185, 300, 6069, 82, 300, 746, 1578, 307, 516, 281, 50896], "temperature": 0.0, "avg_logprob": -0.1597043828266423, "compression_ratio": 1.65, "no_speech_prob": 0.10361452400684357}, {"id": 965, "seek": 526132, "start": 5271.96, "end": 5275.08, "text": " happen and you recoil to avoid it. So even that can be learned.", "tokens": [50896, 1051, 293, 291, 42053, 281, 5042, 309, 13, 407, 754, 300, 393, 312, 3264, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1597043828266423, "compression_ratio": 1.65, "no_speech_prob": 0.10361452400684357}, {"id": 966, "seek": 526132, "start": 5275.08, "end": 5280.759999999999, "text": " That is learned, definitely. This is what allows you also to define some goals, right? So", "tokens": [51052, 663, 307, 3264, 11, 2138, 13, 639, 307, 437, 4045, 291, 611, 281, 6964, 512, 5493, 11, 558, 30, 407, 51336], "temperature": 0.0, "avg_logprob": -0.1597043828266423, "compression_ratio": 1.65, "no_speech_prob": 0.10361452400684357}, {"id": 967, "seek": 526132, "start": 5282.28, "end": 5286.759999999999, "text": " the fact that you're a school child who wake up in the morning and you go to school and", "tokens": [51412, 264, 1186, 300, 291, 434, 257, 1395, 1440, 567, 6634, 493, 294, 264, 2446, 293, 291, 352, 281, 1395, 293, 51636], "temperature": 0.0, "avg_logprob": -0.1597043828266423, "compression_ratio": 1.65, "no_speech_prob": 0.10361452400684357}, {"id": 968, "seek": 528676, "start": 5287.0, "end": 5292.68, "text": " it's not because you necessarily like waking up early and going to school,", "tokens": [50376, 309, 311, 406, 570, 291, 4725, 411, 20447, 493, 2440, 293, 516, 281, 1395, 11, 50660], "temperature": 0.0, "avg_logprob": -0.101746815222281, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.0023200486321002245}, {"id": 969, "seek": 528676, "start": 5292.68, "end": 5295.8, "text": " but you know that there is a long-term objective you're trying to optimize.", "tokens": [50660, 457, 291, 458, 300, 456, 307, 257, 938, 12, 7039, 10024, 291, 434, 1382, 281, 19719, 13, 50816], "temperature": 0.0, "avg_logprob": -0.101746815222281, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.0023200486321002245}, {"id": 970, "seek": 528676, "start": 5295.8, "end": 5299.8, "text": " So Ernest Becker, I'm not sure if you're familiar with the philosopher who wrote the", "tokens": [50816, 407, 24147, 377, 879, 9178, 11, 286, 478, 406, 988, 498, 291, 434, 4963, 365, 264, 29805, 567, 4114, 264, 51016], "temperature": 0.0, "avg_logprob": -0.101746815222281, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.0023200486321002245}, {"id": 971, "seek": 528676, "start": 5299.8, "end": 5304.68, "text": " book Denial of Death. And his idea is that one of the core motivations of human beings is our", "tokens": [51016, 1446, 6458, 831, 295, 13703, 13, 400, 702, 1558, 307, 300, 472, 295, 264, 4965, 39034, 295, 1952, 8958, 307, 527, 51260], "temperature": 0.0, "avg_logprob": -0.101746815222281, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.0023200486321002245}, {"id": 972, "seek": 528676, "start": 5304.68, "end": 5310.4400000000005, "text": " terror of death, our fear of death. That's what makes us unique from cats. Cats are just surviving.", "tokens": [51260, 8127, 295, 2966, 11, 527, 4240, 295, 2966, 13, 663, 311, 437, 1669, 505, 3845, 490, 11111, 13, 40902, 366, 445, 24948, 13, 51548], "temperature": 0.0, "avg_logprob": -0.101746815222281, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.0023200486321002245}, {"id": 973, "seek": 531044, "start": 5310.44, "end": 5321.0, "text": " They do not have a deep, like cognizance introspection that over the horizon is the end.", "tokens": [50364, 814, 360, 406, 362, 257, 2452, 11, 411, 11786, 590, 719, 560, 2635, 19997, 300, 670, 264, 18046, 307, 264, 917, 13, 50892], "temperature": 0.0, "avg_logprob": -0.16142529707688552, "compression_ratio": 1.5, "no_speech_prob": 0.009122010320425034}, {"id": 974, "seek": 531044, "start": 5321.719999999999, "end": 5325.639999999999, "text": " And he says that, I mean, there's a terror management theory that just all these psychological", "tokens": [50928, 400, 415, 1619, 300, 11, 286, 914, 11, 456, 311, 257, 8127, 4592, 5261, 300, 445, 439, 613, 14346, 51124], "temperature": 0.0, "avg_logprob": -0.16142529707688552, "compression_ratio": 1.5, "no_speech_prob": 0.009122010320425034}, {"id": 975, "seek": 531044, "start": 5325.639999999999, "end": 5334.28, "text": " experiments that show basically this idea that all of human civilization, everything we create,", "tokens": [51124, 12050, 300, 855, 1936, 341, 1558, 300, 439, 295, 1952, 18036, 11, 1203, 321, 1884, 11, 51556], "temperature": 0.0, "avg_logprob": -0.16142529707688552, "compression_ratio": 1.5, "no_speech_prob": 0.009122010320425034}, {"id": 976, "seek": 533428, "start": 5334.28, "end": 5339.639999999999, "text": " is kind of trying to forget if even for a brief moment that we're going to die.", "tokens": [50364, 307, 733, 295, 1382, 281, 2870, 498, 754, 337, 257, 5353, 1623, 300, 321, 434, 516, 281, 978, 13, 50632], "temperature": 0.0, "avg_logprob": -0.13573378485602303, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.025547293946146965}, {"id": 977, "seek": 533428, "start": 5340.84, "end": 5347.16, "text": " When do you think humans understand that they're going to die? Is it learned early on also?", "tokens": [50692, 1133, 360, 291, 519, 6255, 1223, 300, 436, 434, 516, 281, 978, 30, 1119, 309, 3264, 2440, 322, 611, 30, 51008], "temperature": 0.0, "avg_logprob": -0.13573378485602303, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.025547293946146965}, {"id": 978, "seek": 533428, "start": 5348.92, "end": 5354.04, "text": " I don't know at what point. I mean, it's a question like, at what point do you realize", "tokens": [51096, 286, 500, 380, 458, 412, 437, 935, 13, 286, 914, 11, 309, 311, 257, 1168, 411, 11, 412, 437, 935, 360, 291, 4325, 51352], "temperature": 0.0, "avg_logprob": -0.13573378485602303, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.025547293946146965}, {"id": 979, "seek": 533428, "start": 5354.04, "end": 5358.759999999999, "text": " that what death really is? And I think most people don't actually realize what death is,", "tokens": [51352, 300, 437, 2966, 534, 307, 30, 400, 286, 519, 881, 561, 500, 380, 767, 4325, 437, 2966, 307, 11, 51588], "temperature": 0.0, "avg_logprob": -0.13573378485602303, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.025547293946146965}, {"id": 980, "seek": 533428, "start": 5358.759999999999, "end": 5361.8, "text": " right? I mean, most people believe that you go to heaven or something, right?", "tokens": [51588, 558, 30, 286, 914, 11, 881, 561, 1697, 300, 291, 352, 281, 7162, 420, 746, 11, 558, 30, 51740], "temperature": 0.0, "avg_logprob": -0.13573378485602303, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.025547293946146965}, {"id": 981, "seek": 536180, "start": 5361.88, "end": 5368.6, "text": " So to push back on that, what Ernest Becker says and Sheldon Solomon, all of those folks,", "tokens": [50368, 407, 281, 2944, 646, 322, 300, 11, 437, 24147, 377, 879, 9178, 1619, 293, 1160, 5957, 266, 32209, 11, 439, 295, 729, 4024, 11, 50704], "temperature": 0.0, "avg_logprob": -0.12111485388971144, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00745451170951128}, {"id": 982, "seek": 536180, "start": 5369.24, "end": 5374.04, "text": " and I find those ideas a little bit compelling is that there is moments in life, early in life.", "tokens": [50736, 293, 286, 915, 729, 3487, 257, 707, 857, 20050, 307, 300, 456, 307, 6065, 294, 993, 11, 2440, 294, 993, 13, 50976], "temperature": 0.0, "avg_logprob": -0.12111485388971144, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00745451170951128}, {"id": 983, "seek": 536180, "start": 5374.04, "end": 5382.12, "text": " A lot of this fun happens early in life when you are, when you do deeply experience the terror", "tokens": [50976, 316, 688, 295, 341, 1019, 2314, 2440, 294, 993, 562, 291, 366, 11, 562, 291, 360, 8760, 1752, 264, 8127, 51380], "temperature": 0.0, "avg_logprob": -0.12111485388971144, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00745451170951128}, {"id": 984, "seek": 536180, "start": 5382.12, "end": 5387.08, "text": " of this realization and all the things you think about about religion, all those kinds of things", "tokens": [51380, 295, 341, 25138, 293, 439, 264, 721, 291, 519, 466, 466, 7561, 11, 439, 729, 3685, 295, 721, 51628], "temperature": 0.0, "avg_logprob": -0.12111485388971144, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.00745451170951128}, {"id": 985, "seek": 538708, "start": 5387.08, "end": 5391.96, "text": " that we kind of think about more like teenage years and later. We're talking about way earlier.", "tokens": [50364, 300, 321, 733, 295, 519, 466, 544, 411, 26866, 924, 293, 1780, 13, 492, 434, 1417, 466, 636, 3071, 13, 50608], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 986, "seek": 538708, "start": 5391.96, "end": 5394.12, "text": " No, there's like seven or eight years or something like that. Yeah.", "tokens": [50608, 883, 11, 456, 311, 411, 3407, 420, 3180, 924, 420, 746, 411, 300, 13, 865, 13, 50716], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 987, "seek": 538708, "start": 5394.12, "end": 5402.76, "text": " You realize, holy crap, this is like the mystery, the terror, like it's almost like you're a little", "tokens": [50716, 509, 4325, 11, 10622, 12426, 11, 341, 307, 411, 264, 11422, 11, 264, 8127, 11, 411, 309, 311, 1920, 411, 291, 434, 257, 707, 51148], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 988, "seek": 538708, "start": 5402.76, "end": 5406.44, "text": " prey, a little baby deer sitting in the darkness of the jungle of the woods,", "tokens": [51148, 21107, 11, 257, 707, 3186, 17120, 3798, 294, 264, 11262, 295, 264, 18228, 295, 264, 15296, 11, 51332], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 989, "seek": 538708, "start": 5407.0, "end": 5411.48, "text": " looking all around you, there's darkness full of terror. I mean, that's, that realization says,", "tokens": [51360, 1237, 439, 926, 291, 11, 456, 311, 11262, 1577, 295, 8127, 13, 286, 914, 11, 300, 311, 11, 300, 25138, 1619, 11, 51584], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 990, "seek": 538708, "start": 5411.48, "end": 5416.28, "text": " okay, I'm going to go back in the comfort of my mind where there is a, where there is a deep", "tokens": [51584, 1392, 11, 286, 478, 516, 281, 352, 646, 294, 264, 3400, 295, 452, 1575, 689, 456, 307, 257, 11, 689, 456, 307, 257, 2452, 51824], "temperature": 0.0, "avg_logprob": -0.135795913473533, "compression_ratio": 1.8054607508532423, "no_speech_prob": 0.05744538828730583}, {"id": 991, "seek": 541628, "start": 5416.28, "end": 5423.8, "text": " meaning where there is a, maybe like pretend I'm immortal and however way, however kind of idea I", "tokens": [50364, 3620, 689, 456, 307, 257, 11, 1310, 411, 11865, 286, 478, 31414, 293, 4461, 636, 11, 4461, 733, 295, 1558, 286, 50740], "temperature": 0.0, "avg_logprob": -0.10826908955808545, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.002933079143986106}, {"id": 992, "seek": 541628, "start": 5423.8, "end": 5429.08, "text": " can construct to help me understand that I'm immortal. Religion helps with that. You can,", "tokens": [50740, 393, 7690, 281, 854, 385, 1223, 300, 286, 478, 31414, 13, 40127, 3665, 365, 300, 13, 509, 393, 11, 51004], "temperature": 0.0, "avg_logprob": -0.10826908955808545, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.002933079143986106}, {"id": 993, "seek": 541628, "start": 5429.08, "end": 5434.12, "text": " you can delude yourself in all kinds of ways, like lose yourself in the busyness of each day,", "tokens": [51004, 291, 393, 1103, 2303, 1803, 294, 439, 3685, 295, 2098, 11, 411, 3624, 1803, 294, 264, 5856, 1287, 295, 1184, 786, 11, 51256], "temperature": 0.0, "avg_logprob": -0.10826908955808545, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.002933079143986106}, {"id": 994, "seek": 541628, "start": 5434.12, "end": 5438.12, "text": " have little goals in mind, all those kinds of things to think that it's going to go on forever.", "tokens": [51256, 362, 707, 5493, 294, 1575, 11, 439, 729, 3685, 295, 721, 281, 519, 300, 309, 311, 516, 281, 352, 322, 5680, 13, 51456], "temperature": 0.0, "avg_logprob": -0.10826908955808545, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.002933079143986106}, {"id": 995, "seek": 541628, "start": 5438.12, "end": 5443.08, "text": " And you kind of know you're going to die. Yeah. And it's going to be sad, but you don't really", "tokens": [51456, 400, 291, 733, 295, 458, 291, 434, 516, 281, 978, 13, 865, 13, 400, 309, 311, 516, 281, 312, 4227, 11, 457, 291, 500, 380, 534, 51704], "temperature": 0.0, "avg_logprob": -0.10826908955808545, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.002933079143986106}, {"id": 996, "seek": 544308, "start": 5443.16, "end": 5447.8, "text": " understand that you're going to die. And so that's, that's their idea. And I find that compelling", "tokens": [50368, 1223, 300, 291, 434, 516, 281, 978, 13, 400, 370, 300, 311, 11, 300, 311, 641, 1558, 13, 400, 286, 915, 300, 20050, 50600], "temperature": 0.0, "avg_logprob": -0.09096651810866135, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.002357218414545059}, {"id": 997, "seek": 544308, "start": 5448.5199999999995, "end": 5454.5199999999995, "text": " because it does seem to be a core unique aspect of human nature that we were able to think that", "tokens": [50636, 570, 309, 775, 1643, 281, 312, 257, 4965, 3845, 4171, 295, 1952, 3687, 300, 321, 645, 1075, 281, 519, 300, 50936], "temperature": 0.0, "avg_logprob": -0.09096651810866135, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.002357218414545059}, {"id": 998, "seek": 544308, "start": 5454.5199999999995, "end": 5460.5199999999995, "text": " we're going, we're able to really understand that this life is finite. That seems important.", "tokens": [50936, 321, 434, 516, 11, 321, 434, 1075, 281, 534, 1223, 300, 341, 993, 307, 19362, 13, 663, 2544, 1021, 13, 51236], "temperature": 0.0, "avg_logprob": -0.09096651810866135, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.002357218414545059}, {"id": 999, "seek": 544308, "start": 5460.5199999999995, "end": 5463.5599999999995, "text": " There's, there's a bunch of different things there. So first of all, I don't think there is", "tokens": [51236, 821, 311, 11, 456, 311, 257, 3840, 295, 819, 721, 456, 13, 407, 700, 295, 439, 11, 286, 500, 380, 519, 456, 307, 51388], "temperature": 0.0, "avg_logprob": -0.09096651810866135, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.002357218414545059}, {"id": 1000, "seek": 544308, "start": 5463.5599999999995, "end": 5468.6, "text": " a qualitative difference between, between us and cats in the term. I think the difference is that", "tokens": [51388, 257, 31312, 2649, 1296, 11, 1296, 505, 293, 11111, 294, 264, 1433, 13, 286, 519, 264, 2649, 307, 300, 51640], "temperature": 0.0, "avg_logprob": -0.09096651810866135, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.002357218414545059}, {"id": 1001, "seek": 546860, "start": 5468.6, "end": 5475.4800000000005, "text": " we just have a better long term ability to predict, you know, in the long term. And so", "tokens": [50364, 321, 445, 362, 257, 1101, 938, 1433, 3485, 281, 6069, 11, 291, 458, 11, 294, 264, 938, 1433, 13, 400, 370, 50708], "temperature": 0.0, "avg_logprob": -0.12361019493168236, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.008153440430760384}, {"id": 1002, "seek": 546860, "start": 5475.4800000000005, "end": 5478.68, "text": " we have a better understanding of other world works. So we have better understanding of,", "tokens": [50708, 321, 362, 257, 1101, 3701, 295, 661, 1002, 1985, 13, 407, 321, 362, 1101, 3701, 295, 11, 50868], "temperature": 0.0, "avg_logprob": -0.12361019493168236, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.008153440430760384}, {"id": 1003, "seek": 546860, "start": 5478.68, "end": 5483.4800000000005, "text": " you know, funniness of life and things like that. Do we have a better planning engine than cats?", "tokens": [50868, 291, 458, 11, 1019, 77, 1324, 295, 993, 293, 721, 411, 300, 13, 1144, 321, 362, 257, 1101, 5038, 2848, 813, 11111, 30, 51108], "temperature": 0.0, "avg_logprob": -0.12361019493168236, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.008153440430760384}, {"id": 1004, "seek": 546860, "start": 5483.4800000000005, "end": 5489.72, "text": " Yeah. Okay. But what's the motivation for planning that far? Well, I think it's just a side", "tokens": [51108, 865, 13, 1033, 13, 583, 437, 311, 264, 12335, 337, 5038, 300, 1400, 30, 1042, 11, 286, 519, 309, 311, 445, 257, 1252, 51420], "temperature": 0.0, "avg_logprob": -0.12361019493168236, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.008153440430760384}, {"id": 1005, "seek": 546860, "start": 5489.72, "end": 5494.360000000001, "text": " effect to the fact that we have just a better planning engine because it makes us, as I said,", "tokens": [51420, 1802, 281, 264, 1186, 300, 321, 362, 445, 257, 1101, 5038, 2848, 570, 309, 1669, 505, 11, 382, 286, 848, 11, 51652], "temperature": 0.0, "avg_logprob": -0.12361019493168236, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.008153440430760384}, {"id": 1006, "seek": 549436, "start": 5494.36, "end": 5499.24, "text": " you know, the essence of intelligence is the ability to predict. And so the, because we're", "tokens": [50364, 291, 458, 11, 264, 12801, 295, 7599, 307, 264, 3485, 281, 6069, 13, 400, 370, 264, 11, 570, 321, 434, 50608], "temperature": 0.0, "avg_logprob": -0.0994205725820441, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.054880328476428986}, {"id": 1007, "seek": 549436, "start": 5499.24, "end": 5503.88, "text": " smarter, as a side effect, we also have this ability to kind of make predictions about our own", "tokens": [50608, 20294, 11, 382, 257, 1252, 1802, 11, 321, 611, 362, 341, 3485, 281, 733, 295, 652, 21264, 466, 527, 1065, 50840], "temperature": 0.0, "avg_logprob": -0.0994205725820441, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.054880328476428986}, {"id": 1008, "seek": 549436, "start": 5505.08, "end": 5511.08, "text": " future existence or lack the rough. You say religion helps with that. I think religion", "tokens": [50900, 2027, 9123, 420, 5011, 264, 5903, 13, 509, 584, 7561, 3665, 365, 300, 13, 286, 519, 7561, 51200], "temperature": 0.0, "avg_logprob": -0.0994205725820441, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.054880328476428986}, {"id": 1009, "seek": 549436, "start": 5511.08, "end": 5515.799999999999, "text": " hurts actually. It makes people worry about like, you know, what's going to happen after", "tokens": [51200, 11051, 767, 13, 467, 1669, 561, 3292, 466, 411, 11, 291, 458, 11, 437, 311, 516, 281, 1051, 934, 51436], "temperature": 0.0, "avg_logprob": -0.0994205725820441, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.054880328476428986}, {"id": 1010, "seek": 549436, "start": 5515.799999999999, "end": 5521.08, "text": " their death, etc. If you believe that, you know, you just don't exist after death, like, you know,", "tokens": [51436, 641, 2966, 11, 5183, 13, 759, 291, 1697, 300, 11, 291, 458, 11, 291, 445, 500, 380, 2514, 934, 2966, 11, 411, 11, 291, 458, 11, 51700], "temperature": 0.0, "avg_logprob": -0.0994205725820441, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.054880328476428986}, {"id": 1011, "seek": 552108, "start": 5521.08, "end": 5524.84, "text": " it solves completely the problem at least. You're saying if you don't believe in God,", "tokens": [50364, 309, 39890, 2584, 264, 1154, 412, 1935, 13, 509, 434, 1566, 498, 291, 500, 380, 1697, 294, 1265, 11, 50552], "temperature": 0.0, "avg_logprob": -0.15273832102290918, "compression_ratio": 1.7183673469387755, "no_speech_prob": 0.006899764761328697}, {"id": 1012, "seek": 552108, "start": 5524.84, "end": 5529.96, "text": " you don't worry about what happens after death? Yeah. I don't know. You only worry about the,", "tokens": [50552, 291, 500, 380, 3292, 466, 437, 2314, 934, 2966, 30, 865, 13, 286, 500, 380, 458, 13, 509, 787, 3292, 466, 264, 11, 50808], "temperature": 0.0, "avg_logprob": -0.15273832102290918, "compression_ratio": 1.7183673469387755, "no_speech_prob": 0.006899764761328697}, {"id": 1013, "seek": 552108, "start": 5529.96, "end": 5533.0, "text": " about, you know, this life, because that's the only one you have.", "tokens": [50808, 466, 11, 291, 458, 11, 341, 993, 11, 570, 300, 311, 264, 787, 472, 291, 362, 13, 50960], "temperature": 0.0, "avg_logprob": -0.15273832102290918, "compression_ratio": 1.7183673469387755, "no_speech_prob": 0.006899764761328697}, {"id": 1014, "seek": 552108, "start": 5534.12, "end": 5537.64, "text": " I think it's, well, I don't, I don't know, if I were to say what Ernest Becker says,", "tokens": [51016, 286, 519, 309, 311, 11, 731, 11, 286, 500, 380, 11, 286, 500, 380, 458, 11, 498, 286, 645, 281, 584, 437, 24147, 377, 879, 9178, 1619, 11, 51192], "temperature": 0.0, "avg_logprob": -0.15273832102290918, "compression_ratio": 1.7183673469387755, "no_speech_prob": 0.006899764761328697}, {"id": 1015, "seek": 552108, "start": 5537.64, "end": 5547.08, "text": " and I'll say I agree with him more than not is you do deeply worry. If you, if you believe", "tokens": [51192, 293, 286, 603, 584, 286, 3986, 365, 796, 544, 813, 406, 307, 291, 360, 8760, 3292, 13, 759, 291, 11, 498, 291, 1697, 51664], "temperature": 0.0, "avg_logprob": -0.15273832102290918, "compression_ratio": 1.7183673469387755, "no_speech_prob": 0.006899764761328697}, {"id": 1016, "seek": 554708, "start": 5547.08, "end": 5552.6, "text": " there's no God, there's still a deep worry like of the mystery of it all. Like, how does that make", "tokens": [50364, 456, 311, 572, 1265, 11, 456, 311, 920, 257, 2452, 3292, 411, 295, 264, 11422, 295, 309, 439, 13, 1743, 11, 577, 775, 300, 652, 50640], "temperature": 0.0, "avg_logprob": -0.14883779992862622, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.027545036748051643}, {"id": 1017, "seek": 554708, "start": 5552.6, "end": 5559.88, "text": " any sense that it just ends? I don't think we can truly understand that this right. I mean,", "tokens": [50640, 604, 2020, 300, 309, 445, 5314, 30, 286, 500, 380, 519, 321, 393, 4908, 1223, 300, 341, 558, 13, 286, 914, 11, 51004], "temperature": 0.0, "avg_logprob": -0.14883779992862622, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.027545036748051643}, {"id": 1018, "seek": 554708, "start": 5559.88, "end": 5566.5199999999995, "text": " so much of our life, the consciousness, the ego is invested in this, in this being. And then", "tokens": [51004, 370, 709, 295, 527, 993, 11, 264, 10081, 11, 264, 14495, 307, 13104, 294, 341, 11, 294, 341, 885, 13, 400, 550, 51336], "temperature": 0.0, "avg_logprob": -0.14883779992862622, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.027545036748051643}, {"id": 1019, "seek": 554708, "start": 5567.5599999999995, "end": 5573.08, "text": " science keeps bringing humanity down from its pedestal. And that's, that's just another,", "tokens": [51388, 3497, 5965, 5062, 10243, 760, 490, 1080, 20497, 304, 13, 400, 300, 311, 11, 300, 311, 445, 1071, 11, 51664], "temperature": 0.0, "avg_logprob": -0.14883779992862622, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.027545036748051643}, {"id": 1020, "seek": 557308, "start": 5573.8, "end": 5578.5199999999995, "text": " example of it. That's wonderful. But for us individual humans, we don't like to be", "tokens": [50400, 1365, 295, 309, 13, 663, 311, 3715, 13, 583, 337, 505, 2609, 6255, 11, 321, 500, 380, 411, 281, 312, 50636], "temperature": 0.0, "avg_logprob": -0.11698277791341145, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00757299130782485}, {"id": 1021, "seek": 557308, "start": 5578.5199999999995, "end": 5584.04, "text": " brought down from a pedestal. You're saying like, but see, you're fine with it because, well,", "tokens": [50636, 3038, 760, 490, 257, 20497, 304, 13, 509, 434, 1566, 411, 11, 457, 536, 11, 291, 434, 2489, 365, 309, 570, 11, 731, 11, 50912], "temperature": 0.0, "avg_logprob": -0.11698277791341145, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00757299130782485}, {"id": 1022, "seek": 557308, "start": 5584.04, "end": 5587.72, "text": " so what Ernest Becker would say is you're fine with it because that's just a more peaceful", "tokens": [50912, 370, 437, 24147, 377, 879, 9178, 576, 584, 307, 291, 434, 2489, 365, 309, 570, 300, 311, 445, 257, 544, 13962, 51096], "temperature": 0.0, "avg_logprob": -0.11698277791341145, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00757299130782485}, {"id": 1023, "seek": 557308, "start": 5587.72, "end": 5591.88, "text": " existence for you, but you're not really fine. You're hiding from, in fact, some of the people", "tokens": [51096, 9123, 337, 291, 11, 457, 291, 434, 406, 534, 2489, 13, 509, 434, 10596, 490, 11, 294, 1186, 11, 512, 295, 264, 561, 51304], "temperature": 0.0, "avg_logprob": -0.11698277791341145, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00757299130782485}, {"id": 1024, "seek": 557308, "start": 5591.88, "end": 5599.0, "text": " that experienced the deepest trauma that earlier in life, they often, before they seek extensive", "tokens": [51304, 300, 6751, 264, 28288, 11407, 300, 3071, 294, 993, 11, 436, 2049, 11, 949, 436, 8075, 13246, 51660], "temperature": 0.0, "avg_logprob": -0.11698277791341145, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.00757299130782485}, {"id": 1025, "seek": 559900, "start": 5599.08, "end": 5603.4, "text": " therapy will say that I'm fine. It's like, when you talk to people who are truly angry,", "tokens": [50368, 9492, 486, 584, 300, 286, 478, 2489, 13, 467, 311, 411, 11, 562, 291, 751, 281, 561, 567, 366, 4908, 6884, 11, 50584], "temperature": 0.0, "avg_logprob": -0.12769813181083894, "compression_ratio": 1.5252918287937742, "no_speech_prob": 0.010005086660385132}, {"id": 1026, "seek": 559900, "start": 5603.4, "end": 5607.08, "text": " how are you doing? I'm fine. The question is, what's going on?", "tokens": [50584, 577, 366, 291, 884, 30, 286, 478, 2489, 13, 440, 1168, 307, 11, 437, 311, 516, 322, 30, 50768], "temperature": 0.0, "avg_logprob": -0.12769813181083894, "compression_ratio": 1.5252918287937742, "no_speech_prob": 0.010005086660385132}, {"id": 1027, "seek": 559900, "start": 5607.64, "end": 5613.8, "text": " Now I had a near death experience. I had a very bad motorbike accident when I was 17. So,", "tokens": [50796, 823, 286, 632, 257, 2651, 2966, 1752, 13, 286, 632, 257, 588, 1578, 5932, 30283, 6398, 562, 286, 390, 3282, 13, 407, 11, 51104], "temperature": 0.0, "avg_logprob": -0.12769813181083894, "compression_ratio": 1.5252918287937742, "no_speech_prob": 0.010005086660385132}, {"id": 1028, "seek": 559900, "start": 5614.92, "end": 5620.36, "text": " but that didn't have any impact on my reflection on that topic.", "tokens": [51160, 457, 300, 994, 380, 362, 604, 2712, 322, 452, 12914, 322, 300, 4829, 13, 51432], "temperature": 0.0, "avg_logprob": -0.12769813181083894, "compression_ratio": 1.5252918287937742, "no_speech_prob": 0.010005086660385132}, {"id": 1029, "seek": 559900, "start": 5620.36, "end": 5625.0, "text": " So I'm basically just playing a bit of devil's advocate and pushing back and wondering,", "tokens": [51432, 407, 286, 478, 1936, 445, 2433, 257, 857, 295, 13297, 311, 14608, 293, 7380, 646, 293, 6359, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12769813181083894, "compression_ratio": 1.5252918287937742, "no_speech_prob": 0.010005086660385132}, {"id": 1030, "seek": 562500, "start": 5625.72, "end": 5629.32, "text": " is it truly possible to accept death? And the flip side that's more interesting,", "tokens": [50400, 307, 309, 4908, 1944, 281, 3241, 2966, 30, 400, 264, 7929, 1252, 300, 311, 544, 1880, 11, 50580], "temperature": 0.0, "avg_logprob": -0.10383945873805454, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.03408852964639664}, {"id": 1031, "seek": 562500, "start": 5629.32, "end": 5637.08, "text": " I think, for AI and robotics is how important is it to have this as one of the suite of motivations", "tokens": [50580, 286, 519, 11, 337, 7318, 293, 34145, 307, 577, 1021, 307, 309, 281, 362, 341, 382, 472, 295, 264, 14205, 295, 39034, 50968], "temperature": 0.0, "avg_logprob": -0.10383945873805454, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.03408852964639664}, {"id": 1032, "seek": 562500, "start": 5637.08, "end": 5649.0, "text": " is to not just avoid falling off the roof or something like that, but ponder the end of the ride.", "tokens": [50968, 307, 281, 406, 445, 5042, 7440, 766, 264, 8418, 420, 746, 411, 300, 11, 457, 280, 8548, 264, 917, 295, 264, 5077, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10383945873805454, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.03408852964639664}, {"id": 1033, "seek": 564900, "start": 5649.72, "end": 5656.76, "text": " Well, if you listen to the Stoics, it's a great motivator. It adds a sense of urgency.", "tokens": [50400, 1042, 11, 498, 291, 2140, 281, 264, 745, 78, 1167, 11, 309, 311, 257, 869, 5426, 1639, 13, 467, 10860, 257, 2020, 295, 29734, 13, 50752], "temperature": 0.0, "avg_logprob": -0.13767636694559238, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.009255873039364815}, {"id": 1034, "seek": 564900, "start": 5656.76, "end": 5662.2, "text": " So it might be to truly fear death or be cognizant of it might give", "tokens": [50752, 407, 309, 1062, 312, 281, 4908, 4240, 2966, 420, 312, 11786, 590, 394, 295, 309, 1062, 976, 51024], "temperature": 0.0, "avg_logprob": -0.13767636694559238, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.009255873039364815}, {"id": 1035, "seek": 564900, "start": 5663.64, "end": 5667.96, "text": " a deeper meaning and urgency to the moment to live fully.", "tokens": [51096, 257, 7731, 3620, 293, 29734, 281, 264, 1623, 281, 1621, 4498, 13, 51312], "temperature": 0.0, "avg_logprob": -0.13767636694559238, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.009255873039364815}, {"id": 1036, "seek": 564900, "start": 5670.44, "end": 5674.44, "text": " Maybe I don't disagree with that. I mean, I think what motivates me here is", "tokens": [51436, 2704, 286, 500, 380, 14091, 365, 300, 13, 286, 914, 11, 286, 519, 437, 42569, 385, 510, 307, 51636], "temperature": 0.0, "avg_logprob": -0.13767636694559238, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.009255873039364815}, {"id": 1037, "seek": 567444, "start": 5674.679999999999, "end": 5681.96, "text": " knowing more about human nature. I mean, I think human nature and human intelligence is a big", "tokens": [50376, 5276, 544, 466, 1952, 3687, 13, 286, 914, 11, 286, 519, 1952, 3687, 293, 1952, 7599, 307, 257, 955, 50740], "temperature": 0.0, "avg_logprob": -0.17837903119515683, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.005531453527510166}, {"id": 1038, "seek": 567444, "start": 5681.96, "end": 5690.12, "text": " mystery. It's a scientific mystery in addition to philosophical and etc. But I'm a true believer", "tokens": [50740, 11422, 13, 467, 311, 257, 8134, 11422, 294, 4500, 281, 25066, 293, 5183, 13, 583, 286, 478, 257, 2074, 23892, 51148], "temperature": 0.0, "avg_logprob": -0.17837903119515683, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.005531453527510166}, {"id": 1039, "seek": 567444, "start": 5690.12, "end": 5698.839999999999, "text": " in science. And I do have kind of a belief that for complex systems like the brain and the mind,", "tokens": [51148, 294, 3497, 13, 400, 286, 360, 362, 733, 295, 257, 7107, 300, 337, 3997, 3652, 411, 264, 3567, 293, 264, 1575, 11, 51584], "temperature": 0.0, "avg_logprob": -0.17837903119515683, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.005531453527510166}, {"id": 1040, "seek": 569884, "start": 5699.8, "end": 5707.32, "text": " the way to understand it is to try to reproduce it with artifacts that you built. Because you", "tokens": [50412, 264, 636, 281, 1223, 309, 307, 281, 853, 281, 29501, 309, 365, 24617, 300, 291, 3094, 13, 1436, 291, 50788], "temperature": 0.0, "avg_logprob": -0.11771928745767345, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.00910853873938322}, {"id": 1041, "seek": 569884, "start": 5707.32, "end": 5712.28, "text": " know what's essential to it when you try to build it. The same way, I've used this analogy before", "tokens": [50788, 458, 437, 311, 7115, 281, 309, 562, 291, 853, 281, 1322, 309, 13, 440, 912, 636, 11, 286, 600, 1143, 341, 21663, 949, 51036], "temperature": 0.0, "avg_logprob": -0.11771928745767345, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.00910853873938322}, {"id": 1042, "seek": 569884, "start": 5712.28, "end": 5718.76, "text": " with you, I believe, the same way we only started to understand aerodynamics when we started building", "tokens": [51036, 365, 291, 11, 286, 1697, 11, 264, 912, 636, 321, 787, 1409, 281, 1223, 11207, 35483, 562, 321, 1409, 2390, 51360], "temperature": 0.0, "avg_logprob": -0.11771928745767345, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.00910853873938322}, {"id": 1043, "seek": 569884, "start": 5718.76, "end": 5725.400000000001, "text": " airplanes. And that helped us understand how birds fly. So I think there's a similar process here", "tokens": [51360, 32947, 13, 400, 300, 4254, 505, 1223, 577, 9009, 3603, 13, 407, 286, 519, 456, 311, 257, 2531, 1399, 510, 51692], "temperature": 0.0, "avg_logprob": -0.11771928745767345, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.00910853873938322}, {"id": 1044, "seek": 572540, "start": 5725.4, "end": 5731.639999999999, "text": " where we don't have a theory of a full theory of intelligence. But building intelligent artifacts", "tokens": [50364, 689, 321, 500, 380, 362, 257, 5261, 295, 257, 1577, 5261, 295, 7599, 13, 583, 2390, 13232, 24617, 50676], "temperature": 0.0, "avg_logprob": -0.1253270834264621, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.001263929414562881}, {"id": 1045, "seek": 572540, "start": 5731.639999999999, "end": 5738.679999999999, "text": " will help us perhaps develop some underlying theory that encompasses not just artificial", "tokens": [50676, 486, 854, 505, 4317, 1499, 512, 14217, 5261, 300, 49866, 406, 445, 11677, 51028], "temperature": 0.0, "avg_logprob": -0.1253270834264621, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.001263929414562881}, {"id": 1046, "seek": 572540, "start": 5738.679999999999, "end": 5743.719999999999, "text": " implements, but also human and biological intelligence in general.", "tokens": [51028, 704, 17988, 11, 457, 611, 1952, 293, 13910, 7599, 294, 2674, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1253270834264621, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.001263929414562881}, {"id": 1047, "seek": 572540, "start": 5743.719999999999, "end": 5748.759999999999, "text": " So you're an interesting person to ask this question about sort of all kinds of different other", "tokens": [51280, 407, 291, 434, 364, 1880, 954, 281, 1029, 341, 1168, 466, 1333, 295, 439, 3685, 295, 819, 661, 51532], "temperature": 0.0, "avg_logprob": -0.1253270834264621, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.001263929414562881}, {"id": 1048, "seek": 574876, "start": 5749.400000000001, "end": 5756.280000000001, "text": " intelligent entities or intelligences. What are your thoughts about kind of like the touring or", "tokens": [50396, 13232, 16667, 420, 5613, 2667, 13, 708, 366, 428, 4598, 466, 733, 295, 411, 264, 32487, 420, 50740], "temperature": 0.0, "avg_logprob": -0.08475092741159293, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.05831173434853554}, {"id": 1049, "seek": 574876, "start": 5756.280000000001, "end": 5764.12, "text": " the Chinese room question? If we create an AI system that exhibits a lot of properties of", "tokens": [50740, 264, 4649, 1808, 1168, 30, 759, 321, 1884, 364, 7318, 1185, 300, 39205, 257, 688, 295, 7221, 295, 51132], "temperature": 0.0, "avg_logprob": -0.08475092741159293, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.05831173434853554}, {"id": 1050, "seek": 574876, "start": 5764.12, "end": 5771.16, "text": " intelligence and consciousness, how comfortable are you thinking of that entity as intelligent or", "tokens": [51132, 7599, 293, 10081, 11, 577, 4619, 366, 291, 1953, 295, 300, 13977, 382, 13232, 420, 51484], "temperature": 0.0, "avg_logprob": -0.08475092741159293, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.05831173434853554}, {"id": 1051, "seek": 574876, "start": 5771.16, "end": 5776.52, "text": " conscious? So you're trying to build now systems that have intelligence and there's metrics about", "tokens": [51484, 6648, 30, 407, 291, 434, 1382, 281, 1322, 586, 3652, 300, 362, 7599, 293, 456, 311, 16367, 466, 51752], "temperature": 0.0, "avg_logprob": -0.08475092741159293, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.05831173434853554}, {"id": 1052, "seek": 577652, "start": 5776.52, "end": 5786.280000000001, "text": " their performance. But that metric is external. So are you okay calling a thing intelligent?", "tokens": [50364, 641, 3389, 13, 583, 300, 20678, 307, 8320, 13, 407, 366, 291, 1392, 5141, 257, 551, 13232, 30, 50852], "temperature": 0.0, "avg_logprob": -0.12005860358476639, "compression_ratio": 1.4631578947368422, "no_speech_prob": 0.002320543397217989}, {"id": 1053, "seek": 577652, "start": 5786.280000000001, "end": 5792.84, "text": " Or are you going to be like most humans and be once again unhappy to be brought down from a", "tokens": [50852, 1610, 366, 291, 516, 281, 312, 411, 881, 6255, 293, 312, 1564, 797, 22172, 281, 312, 3038, 760, 490, 257, 51180], "temperature": 0.0, "avg_logprob": -0.12005860358476639, "compression_ratio": 1.4631578947368422, "no_speech_prob": 0.002320543397217989}, {"id": 1054, "seek": 577652, "start": 5792.84, "end": 5802.200000000001, "text": " pedestal of consciousness slash intelligence? No, I'll be very happy to understand more about", "tokens": [51180, 20497, 304, 295, 10081, 17330, 7599, 30, 883, 11, 286, 603, 312, 588, 2055, 281, 1223, 544, 466, 51648], "temperature": 0.0, "avg_logprob": -0.12005860358476639, "compression_ratio": 1.4631578947368422, "no_speech_prob": 0.002320543397217989}, {"id": 1055, "seek": 580220, "start": 5802.2, "end": 5807.4, "text": " human nature, human mind and human intelligence through the construction of machines that", "tokens": [50364, 1952, 3687, 11, 1952, 1575, 293, 1952, 7599, 807, 264, 6435, 295, 8379, 300, 50624], "temperature": 0.0, "avg_logprob": -0.10075281978992934, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015125581994652748}, {"id": 1056, "seek": 580220, "start": 5808.84, "end": 5815.48, "text": " have similar abilities. And if a consequence of this is to bring down humanity one notch down from", "tokens": [50696, 362, 2531, 11582, 13, 400, 498, 257, 18326, 295, 341, 307, 281, 1565, 760, 10243, 472, 26109, 760, 490, 51028], "temperature": 0.0, "avg_logprob": -0.10075281978992934, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015125581994652748}, {"id": 1057, "seek": 580220, "start": 5816.2, "end": 5821.96, "text": " its already low pedestal, I'm just fine with it. That's just a reality of life. So I'm fine with", "tokens": [51064, 1080, 1217, 2295, 20497, 304, 11, 286, 478, 445, 2489, 365, 309, 13, 663, 311, 445, 257, 4103, 295, 993, 13, 407, 286, 478, 2489, 365, 51352], "temperature": 0.0, "avg_logprob": -0.10075281978992934, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015125581994652748}, {"id": 1058, "seek": 580220, "start": 5821.96, "end": 5826.92, "text": " that. Now you were asking me about things that opinions I have that a lot of people may disagree", "tokens": [51352, 300, 13, 823, 291, 645, 3365, 385, 466, 721, 300, 11819, 286, 362, 300, 257, 688, 295, 561, 815, 14091, 51600], "temperature": 0.0, "avg_logprob": -0.10075281978992934, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.015125581994652748}, {"id": 1059, "seek": 582692, "start": 5826.92, "end": 5835.16, "text": " with. I think if we think about the design of an autonomous intelligence system, so assuming that", "tokens": [50364, 365, 13, 286, 519, 498, 321, 519, 466, 264, 1715, 295, 364, 23797, 7599, 1185, 11, 370, 11926, 300, 50776], "temperature": 0.0, "avg_logprob": -0.13312839739250415, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.0017196708358824253}, {"id": 1060, "seek": 582692, "start": 5835.16, "end": 5840.28, "text": " we are somewhat successful at some level of getting machines to learn models of the world,", "tokens": [50776, 321, 366, 8344, 4406, 412, 512, 1496, 295, 1242, 8379, 281, 1466, 5245, 295, 264, 1002, 11, 51032], "temperature": 0.0, "avg_logprob": -0.13312839739250415, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.0017196708358824253}, {"id": 1061, "seek": 582692, "start": 5840.28, "end": 5846.4400000000005, "text": " predictive models of the world, we build intrinsic motivation, objective functions to drive the", "tokens": [51032, 35521, 5245, 295, 264, 1002, 11, 321, 1322, 35698, 12335, 11, 10024, 6828, 281, 3332, 264, 51340], "temperature": 0.0, "avg_logprob": -0.13312839739250415, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.0017196708358824253}, {"id": 1062, "seek": 582692, "start": 5846.4400000000005, "end": 5851.4800000000005, "text": " behavior of that system. The system also has perception modules that allows it to estimate", "tokens": [51340, 5223, 295, 300, 1185, 13, 440, 1185, 611, 575, 12860, 16679, 300, 4045, 309, 281, 12539, 51592], "temperature": 0.0, "avg_logprob": -0.13312839739250415, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.0017196708358824253}, {"id": 1063, "seek": 582692, "start": 5851.4800000000005, "end": 5856.2, "text": " the state of the world and then have some way of figuring out a sequence of actions that to", "tokens": [51592, 264, 1785, 295, 264, 1002, 293, 550, 362, 512, 636, 295, 15213, 484, 257, 8310, 295, 5909, 300, 281, 51828], "temperature": 0.0, "avg_logprob": -0.13312839739250415, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.0017196708358824253}, {"id": 1064, "seek": 585620, "start": 5856.28, "end": 5862.599999999999, "text": " optimize a particular objective. If it has a critic of the type that was describing before,", "tokens": [50368, 19719, 257, 1729, 10024, 13, 759, 309, 575, 257, 7850, 295, 264, 2010, 300, 390, 16141, 949, 11, 50684], "temperature": 0.0, "avg_logprob": -0.09715988211435815, "compression_ratio": 1.6699029126213591, "no_speech_prob": 0.001012840075418353}, {"id": 1065, "seek": 585620, "start": 5862.599999999999, "end": 5865.8, "text": " the thing that makes recoil your arm the second time I try to pinch you,", "tokens": [50684, 264, 551, 300, 1669, 42053, 428, 3726, 264, 1150, 565, 286, 853, 281, 14614, 291, 11, 50844], "temperature": 0.0, "avg_logprob": -0.09715988211435815, "compression_ratio": 1.6699029126213591, "no_speech_prob": 0.001012840075418353}, {"id": 1066, "seek": 585620, "start": 5868.44, "end": 5874.2, "text": " intelligent autonomous machine will have emotions. I think emotions are an integral part of", "tokens": [50976, 13232, 23797, 3479, 486, 362, 8462, 13, 286, 519, 8462, 366, 364, 11573, 644, 295, 51264], "temperature": 0.0, "avg_logprob": -0.09715988211435815, "compression_ratio": 1.6699029126213591, "no_speech_prob": 0.001012840075418353}, {"id": 1067, "seek": 585620, "start": 5874.2, "end": 5881.5599999999995, "text": " autonomous intelligence. If you have an intelligence system that is driven by intrinsic", "tokens": [51264, 23797, 7599, 13, 759, 291, 362, 364, 7599, 1185, 300, 307, 9555, 538, 35698, 51632], "temperature": 0.0, "avg_logprob": -0.09715988211435815, "compression_ratio": 1.6699029126213591, "no_speech_prob": 0.001012840075418353}, {"id": 1068, "seek": 588156, "start": 5881.56, "end": 5887.96, "text": " motivation, by objectives, if it has a critic that allows it to predict in advance whether the", "tokens": [50364, 12335, 11, 538, 15961, 11, 498, 309, 575, 257, 7850, 300, 4045, 309, 281, 6069, 294, 7295, 1968, 264, 50684], "temperature": 0.0, "avg_logprob": -0.08852082675265283, "compression_ratio": 1.9593908629441625, "no_speech_prob": 0.030955953523516655}, {"id": 1069, "seek": 588156, "start": 5887.96, "end": 5892.6, "text": " outcome of a situation is going to be good or bad, it's going to have emotions. It's going to have", "tokens": [50684, 9700, 295, 257, 2590, 307, 516, 281, 312, 665, 420, 1578, 11, 309, 311, 516, 281, 362, 8462, 13, 467, 311, 516, 281, 362, 50916], "temperature": 0.0, "avg_logprob": -0.08852082675265283, "compression_ratio": 1.9593908629441625, "no_speech_prob": 0.030955953523516655}, {"id": 1070, "seek": 588156, "start": 5892.6, "end": 5900.120000000001, "text": " fear when it predicts that the outcome is going to be bad and something to avoid is going to have", "tokens": [50916, 4240, 562, 309, 6069, 82, 300, 264, 9700, 307, 516, 281, 312, 1578, 293, 746, 281, 5042, 307, 516, 281, 362, 51292], "temperature": 0.0, "avg_logprob": -0.08852082675265283, "compression_ratio": 1.9593908629441625, "no_speech_prob": 0.030955953523516655}, {"id": 1071, "seek": 588156, "start": 5900.120000000001, "end": 5908.84, "text": " elation when it predicts it's going to be good. If it has drives to relate with humans in some", "tokens": [51292, 806, 399, 562, 309, 6069, 82, 309, 311, 516, 281, 312, 665, 13, 759, 309, 575, 11754, 281, 10961, 365, 6255, 294, 512, 51728], "temperature": 0.0, "avg_logprob": -0.08852082675265283, "compression_ratio": 1.9593908629441625, "no_speech_prob": 0.030955953523516655}, {"id": 1072, "seek": 590884, "start": 5908.92, "end": 5916.68, "text": " ways, the way humans have, it's going to be social. It's going to have emotions about", "tokens": [50368, 2098, 11, 264, 636, 6255, 362, 11, 309, 311, 516, 281, 312, 2093, 13, 467, 311, 516, 281, 362, 8462, 466, 50756], "temperature": 0.0, "avg_logprob": -0.156362430865948, "compression_ratio": 1.5617283950617284, "no_speech_prob": 0.004977969452738762}, {"id": 1073, "seek": 590884, "start": 5916.68, "end": 5926.84, "text": " attachment and things of that type. I think the sci-fi thing where you see commander data", "tokens": [50756, 19431, 293, 721, 295, 300, 2010, 13, 286, 519, 264, 2180, 12, 13325, 551, 689, 291, 536, 17885, 1412, 51264], "temperature": 0.0, "avg_logprob": -0.156362430865948, "compression_ratio": 1.5617283950617284, "no_speech_prob": 0.004977969452738762}, {"id": 1074, "seek": 590884, "start": 5926.84, "end": 5931.08, "text": " like having an emotion chip that you can turn off, I think that's ridiculous.", "tokens": [51264, 411, 1419, 364, 8913, 11409, 300, 291, 393, 1261, 766, 11, 286, 519, 300, 311, 11083, 13, 51476], "temperature": 0.0, "avg_logprob": -0.156362430865948, "compression_ratio": 1.5617283950617284, "no_speech_prob": 0.004977969452738762}, {"id": 1075, "seek": 593108, "start": 5931.48, "end": 5939.0, "text": " So, here's the difficult philosophical social question. Do you think there will be a time", "tokens": [50384, 407, 11, 510, 311, 264, 2252, 25066, 2093, 1168, 13, 1144, 291, 519, 456, 486, 312, 257, 565, 50760], "temperature": 0.0, "avg_logprob": -0.20105146957656084, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.010004118084907532}, {"id": 1076, "seek": 593108, "start": 5939.88, "end": 5946.36, "text": " like a civil rights movement for robots where, okay, forget the movement, but a discussion", "tokens": [50804, 411, 257, 5605, 4601, 3963, 337, 14733, 689, 11, 1392, 11, 2870, 264, 3963, 11, 457, 257, 5017, 51128], "temperature": 0.0, "avg_logprob": -0.20105146957656084, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.010004118084907532}, {"id": 1077, "seek": 593108, "start": 5946.36, "end": 5954.5199999999995, "text": " like the Supreme Court that particular kinds of robots, particular kinds of systems,", "tokens": [51128, 411, 264, 11032, 7873, 300, 1729, 3685, 295, 14733, 11, 1729, 3685, 295, 3652, 11, 51536], "temperature": 0.0, "avg_logprob": -0.20105146957656084, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.010004118084907532}, {"id": 1078, "seek": 595452, "start": 5955.4800000000005, "end": 5961.320000000001, "text": " deserve the same rights as humans because they can suffer just as humans can,", "tokens": [50412, 9948, 264, 912, 4601, 382, 6255, 570, 436, 393, 9753, 445, 382, 6255, 393, 11, 50704], "temperature": 0.0, "avg_logprob": -0.17036173078748915, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.016138151288032532}, {"id": 1079, "seek": 595452, "start": 5962.84, "end": 5970.040000000001, "text": " all those kinds of things? Well, perhaps not. Imagine that humans were that you could", "tokens": [50780, 439, 729, 3685, 295, 721, 30, 1042, 11, 4317, 406, 13, 11739, 300, 6255, 645, 300, 291, 727, 51140], "temperature": 0.0, "avg_logprob": -0.17036173078748915, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.016138151288032532}, {"id": 1080, "seek": 595452, "start": 5972.200000000001, "end": 5979.400000000001, "text": " die and be restored. You could be 3D reprinted and your brain could be reconstructed in its", "tokens": [51248, 978, 293, 312, 23143, 13, 509, 727, 312, 805, 35, 1085, 19014, 292, 293, 428, 3567, 727, 312, 31499, 292, 294, 1080, 51608], "temperature": 0.0, "avg_logprob": -0.17036173078748915, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.016138151288032532}, {"id": 1081, "seek": 597940, "start": 5979.4, "end": 5986.759999999999, "text": " finest details. Our ideas of rights will change in that case. If there's always a backup,", "tokens": [50364, 28141, 4365, 13, 2621, 3487, 295, 4601, 486, 1319, 294, 300, 1389, 13, 759, 456, 311, 1009, 257, 14807, 11, 50732], "temperature": 0.0, "avg_logprob": -0.15475034713745117, "compression_ratio": 1.4114285714285715, "no_speech_prob": 0.034080106765031815}, {"id": 1082, "seek": 597940, "start": 5986.759999999999, "end": 5991.879999999999, "text": " you could always restore. Maybe the importance of murder will go down one notch.", "tokens": [50732, 291, 727, 1009, 15227, 13, 2704, 264, 7379, 295, 6568, 486, 352, 760, 472, 26109, 13, 50988], "temperature": 0.0, "avg_logprob": -0.15475034713745117, "compression_ratio": 1.4114285714285715, "no_speech_prob": 0.034080106765031815}, {"id": 1083, "seek": 597940, "start": 5991.879999999999, "end": 6000.5199999999995, "text": " That's right. But also, your desire to do dangerous things like skydiving or", "tokens": [50988, 663, 311, 558, 13, 583, 611, 11, 428, 7516, 281, 360, 5795, 721, 411, 5443, 67, 2123, 420, 51420], "temperature": 0.0, "avg_logprob": -0.15475034713745117, "compression_ratio": 1.4114285714285715, "no_speech_prob": 0.034080106765031815}, {"id": 1084, "seek": 600052, "start": 6000.68, "end": 6011.160000000001, "text": " race car racing or that kind of stuff would probably increase or airplane aerobatics or", "tokens": [50372, 4569, 1032, 12553, 420, 300, 733, 295, 1507, 576, 1391, 3488, 420, 17130, 11207, 996, 30292, 420, 50896], "temperature": 0.0, "avg_logprob": -0.17593403322150908, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.005128657910972834}, {"id": 1085, "seek": 600052, "start": 6011.160000000001, "end": 6016.76, "text": " that kind of stuff. It would be fine to do a lot of those things or explore dangerous areas and", "tokens": [50896, 300, 733, 295, 1507, 13, 467, 576, 312, 2489, 281, 360, 257, 688, 295, 729, 721, 420, 6839, 5795, 3179, 293, 51176], "temperature": 0.0, "avg_logprob": -0.17593403322150908, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.005128657910972834}, {"id": 1086, "seek": 600052, "start": 6016.76, "end": 6021.96, "text": " things like that. It would change your relationship. Now, it's very likely that robots would be like", "tokens": [51176, 721, 411, 300, 13, 467, 576, 1319, 428, 2480, 13, 823, 11, 309, 311, 588, 3700, 300, 14733, 576, 312, 411, 51436], "temperature": 0.0, "avg_logprob": -0.17593403322150908, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.005128657910972834}, {"id": 1087, "seek": 600052, "start": 6021.96, "end": 6027.88, "text": " that because they'll be based on perhaps technology that is somewhat similar to", "tokens": [51436, 300, 570, 436, 603, 312, 2361, 322, 4317, 2899, 300, 307, 8344, 2531, 281, 51732], "temperature": 0.0, "avg_logprob": -0.17593403322150908, "compression_ratio": 1.7089201877934272, "no_speech_prob": 0.005128657910972834}, {"id": 1088, "seek": 602788, "start": 6028.76, "end": 6035.32, "text": " this technology and you can always have a backup. So, it's possible. I don't know if you like video", "tokens": [50408, 341, 2899, 293, 291, 393, 1009, 362, 257, 14807, 13, 407, 11, 309, 311, 1944, 13, 286, 500, 380, 458, 498, 291, 411, 960, 50736], "temperature": 0.0, "avg_logprob": -0.18979728335425966, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.029278531670570374}, {"id": 1089, "seek": 602788, "start": 6035.32, "end": 6044.52, "text": " games, but there's a game called Diablo. My sons are huge fans of this. Yes. In fact,", "tokens": [50736, 2813, 11, 457, 456, 311, 257, 1216, 1219, 8789, 21991, 13, 1222, 13476, 366, 2603, 4499, 295, 341, 13, 1079, 13, 682, 1186, 11, 51196], "temperature": 0.0, "avg_logprob": -0.18979728335425966, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.029278531670570374}, {"id": 1090, "seek": 602788, "start": 6044.52, "end": 6051.08, "text": " they made a game that's inspired by it. Awesome. Like built a game? My three sons have a game design", "tokens": [51196, 436, 1027, 257, 1216, 300, 311, 7547, 538, 309, 13, 10391, 13, 1743, 3094, 257, 1216, 30, 1222, 1045, 13476, 362, 257, 1216, 1715, 51524], "temperature": 0.0, "avg_logprob": -0.18979728335425966, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.029278531670570374}, {"id": 1091, "seek": 602788, "start": 6051.08, "end": 6055.08, "text": " studio between them. That's awesome. They came out with a game. They just came out of the game.", "tokens": [51524, 6811, 1296, 552, 13, 663, 311, 3476, 13, 814, 1361, 484, 365, 257, 1216, 13, 814, 445, 1361, 484, 295, 264, 1216, 13, 51724], "temperature": 0.0, "avg_logprob": -0.18979728335425966, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.029278531670570374}, {"id": 1092, "seek": 605508, "start": 6055.08, "end": 6058.04, "text": " Last year? No, this was last year, about a year ago.", "tokens": [50364, 5264, 1064, 30, 883, 11, 341, 390, 1036, 1064, 11, 466, 257, 1064, 2057, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1369860437181261, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.017965074628591537}, {"id": 1093, "seek": 605508, "start": 6058.04, "end": 6063.32, "text": " That's awesome. But in Diablo, there's something called hardcore mode, which if you die,", "tokens": [50512, 663, 311, 3476, 13, 583, 294, 8789, 21991, 11, 456, 311, 746, 1219, 28196, 4391, 11, 597, 498, 291, 978, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1369860437181261, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.017965074628591537}, {"id": 1094, "seek": 605508, "start": 6063.32, "end": 6069.24, "text": " there's no, you're gone. That's it. And so, it's possible with AI systems", "tokens": [50776, 456, 311, 572, 11, 291, 434, 2780, 13, 663, 311, 309, 13, 400, 370, 11, 309, 311, 1944, 365, 7318, 3652, 51072], "temperature": 0.0, "avg_logprob": -0.1369860437181261, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.017965074628591537}, {"id": 1095, "seek": 605508, "start": 6070.6, "end": 6075.8, "text": " for them to be able to operate successfully and for us to treat them in a certain way because", "tokens": [51140, 337, 552, 281, 312, 1075, 281, 9651, 10727, 293, 337, 505, 281, 2387, 552, 294, 257, 1629, 636, 570, 51400], "temperature": 0.0, "avg_logprob": -0.1369860437181261, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.017965074628591537}, {"id": 1096, "seek": 605508, "start": 6075.8, "end": 6081.96, "text": " they have to be integrated in human society, they have to be able to die no copies allowed.", "tokens": [51400, 436, 362, 281, 312, 10919, 294, 1952, 4086, 11, 436, 362, 281, 312, 1075, 281, 978, 572, 14341, 4350, 13, 51708], "temperature": 0.0, "avg_logprob": -0.1369860437181261, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.017965074628591537}, {"id": 1097, "seek": 608196, "start": 6081.96, "end": 6086.92, "text": " In fact, copying is illegal. It's possible with humans as well, like cloning will be illegal,", "tokens": [50364, 682, 1186, 11, 27976, 307, 11905, 13, 467, 311, 1944, 365, 6255, 382, 731, 11, 411, 596, 16638, 486, 312, 11905, 11, 50612], "temperature": 0.0, "avg_logprob": -0.18037534834028365, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.018241282552480698}, {"id": 1098, "seek": 608196, "start": 6086.92, "end": 6090.04, "text": " even when it's possible. But cloning is not copying, right? I mean,", "tokens": [50612, 754, 562, 309, 311, 1944, 13, 583, 596, 16638, 307, 406, 27976, 11, 558, 30, 286, 914, 11, 50768], "temperature": 0.0, "avg_logprob": -0.18037534834028365, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.018241282552480698}, {"id": 1099, "seek": 608196, "start": 6090.04, "end": 6095.4, "text": " you don't reproduce the mind of the person and experience. It's just a delayed twin.", "tokens": [50768, 291, 500, 380, 29501, 264, 1575, 295, 264, 954, 293, 1752, 13, 467, 311, 445, 257, 20268, 18397, 13, 51036], "temperature": 0.0, "avg_logprob": -0.18037534834028365, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.018241282552480698}, {"id": 1100, "seek": 608196, "start": 6096.28, "end": 6101.4, "text": " But then, we were talking about with computers that you'll be able to copy. You'll be able to", "tokens": [51080, 583, 550, 11, 321, 645, 1417, 466, 365, 10807, 300, 291, 603, 312, 1075, 281, 5055, 13, 509, 603, 312, 1075, 281, 51336], "temperature": 0.0, "avg_logprob": -0.18037534834028365, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.018241282552480698}, {"id": 1101, "seek": 608196, "start": 6101.4, "end": 6110.04, "text": " perfectly save, pickle the mind state. And it's possible that that would be illegal because", "tokens": [51336, 6239, 3155, 11, 31433, 264, 1575, 1785, 13, 400, 309, 311, 1944, 300, 300, 576, 312, 11905, 570, 51768], "temperature": 0.0, "avg_logprob": -0.18037534834028365, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.018241282552480698}, {"id": 1102, "seek": 611004, "start": 6110.84, "end": 6118.84, "text": " that will destroy the motivation of the system. Okay, so let's say you have a domestic robot,", "tokens": [50404, 300, 486, 5293, 264, 12335, 295, 264, 1185, 13, 1033, 11, 370, 718, 311, 584, 291, 362, 257, 10939, 7881, 11, 50804], "temperature": 0.0, "avg_logprob": -0.15729443232218424, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.003370956750586629}, {"id": 1103, "seek": 611004, "start": 6120.2, "end": 6127.24, "text": " sometime in the future. And the domestic robot comes to you somewhat pre-trained,", "tokens": [50872, 15053, 294, 264, 2027, 13, 400, 264, 10939, 7881, 1487, 281, 291, 8344, 659, 12, 17227, 2001, 11, 51224], "temperature": 0.0, "avg_logprob": -0.15729443232218424, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.003370956750586629}, {"id": 1104, "seek": 611004, "start": 6127.24, "end": 6131.4, "text": " can do a bunch of things. But it has a particular personality that makes it slightly different", "tokens": [51224, 393, 360, 257, 3840, 295, 721, 13, 583, 309, 575, 257, 1729, 9033, 300, 1669, 309, 4748, 819, 51432], "temperature": 0.0, "avg_logprob": -0.15729443232218424, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.003370956750586629}, {"id": 1105, "seek": 611004, "start": 6131.4, "end": 6136.36, "text": " from the other robots because that makes them more interesting. And then because it's lived", "tokens": [51432, 490, 264, 661, 14733, 570, 300, 1669, 552, 544, 1880, 13, 400, 550, 570, 309, 311, 5152, 51680], "temperature": 0.0, "avg_logprob": -0.15729443232218424, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.003370956750586629}, {"id": 1106, "seek": 613636, "start": 6136.36, "end": 6142.839999999999, "text": " with you for five years, you've grown some attachment to it and vice versa. And it's learned", "tokens": [50364, 365, 291, 337, 1732, 924, 11, 291, 600, 7709, 512, 19431, 281, 309, 293, 11964, 25650, 13, 400, 309, 311, 3264, 50688], "temperature": 0.0, "avg_logprob": -0.13441951458270734, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.019650042057037354}, {"id": 1107, "seek": 613636, "start": 6142.839999999999, "end": 6148.92, "text": " a lot about you. Or maybe it's not a household robot, maybe it's a virtual assistant that lives in", "tokens": [50688, 257, 688, 466, 291, 13, 1610, 1310, 309, 311, 406, 257, 9888, 7881, 11, 1310, 309, 311, 257, 6374, 10994, 300, 2909, 294, 50992], "temperature": 0.0, "avg_logprob": -0.13441951458270734, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.019650042057037354}, {"id": 1108, "seek": 613636, "start": 6148.92, "end": 6154.759999999999, "text": " your augmented reality glasses or whatever, right? The HER movie type thing, right?", "tokens": [50992, 428, 36155, 4103, 10812, 420, 2035, 11, 558, 30, 440, 29060, 3169, 2010, 551, 11, 558, 30, 51284], "temperature": 0.0, "avg_logprob": -0.13441951458270734, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.019650042057037354}, {"id": 1109, "seek": 613636, "start": 6156.599999999999, "end": 6164.28, "text": " And that system to some extent, the intelligence in that system is a bit like your child or maybe", "tokens": [51376, 400, 300, 1185, 281, 512, 8396, 11, 264, 7599, 294, 300, 1185, 307, 257, 857, 411, 428, 1440, 420, 1310, 51760], "temperature": 0.0, "avg_logprob": -0.13441951458270734, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.019650042057037354}, {"id": 1110, "seek": 616428, "start": 6164.28, "end": 6170.5199999999995, "text": " your PhD student in the sense that there's a lot of you in that machine now, right? And so,", "tokens": [50364, 428, 14476, 3107, 294, 264, 2020, 300, 456, 311, 257, 688, 295, 291, 294, 300, 3479, 586, 11, 558, 30, 400, 370, 11, 50676], "temperature": 0.0, "avg_logprob": -0.09383551279703777, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.007179354317486286}, {"id": 1111, "seek": 616428, "start": 6171.08, "end": 6177.24, "text": " if it were a living thing, you would do this for free if you want, right? If it's your child,", "tokens": [50704, 498, 309, 645, 257, 2647, 551, 11, 291, 576, 360, 341, 337, 1737, 498, 291, 528, 11, 558, 30, 759, 309, 311, 428, 1440, 11, 51012], "temperature": 0.0, "avg_logprob": -0.09383551279703777, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.007179354317486286}, {"id": 1112, "seek": 616428, "start": 6177.24, "end": 6183.88, "text": " your child can then live his or her own life. And the fact that they learn stuff from you", "tokens": [51012, 428, 1440, 393, 550, 1621, 702, 420, 720, 1065, 993, 13, 400, 264, 1186, 300, 436, 1466, 1507, 490, 291, 51344], "temperature": 0.0, "avg_logprob": -0.09383551279703777, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.007179354317486286}, {"id": 1113, "seek": 616428, "start": 6183.88, "end": 6189.24, "text": " doesn't mean that you have any ownership of it, right? But if it's a robot that you've trained,", "tokens": [51344, 1177, 380, 914, 300, 291, 362, 604, 15279, 295, 309, 11, 558, 30, 583, 498, 309, 311, 257, 7881, 300, 291, 600, 8895, 11, 51612], "temperature": 0.0, "avg_logprob": -0.09383551279703777, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.007179354317486286}, {"id": 1114, "seek": 618924, "start": 6189.24, "end": 6193.8, "text": " perhaps you have some intellectual property claim about...", "tokens": [50364, 4317, 291, 362, 512, 12576, 4707, 3932, 466, 485, 50592], "temperature": 0.0, "avg_logprob": -0.22488798293392215, "compression_ratio": 1.8185483870967742, "no_speech_prob": 0.011663907207548618}, {"id": 1115, "seek": 618924, "start": 6193.8, "end": 6199.08, "text": " Going to intellectual property. Oh, I thought you meant like permanent value in the sense that's part", "tokens": [50592, 10963, 281, 12576, 4707, 13, 876, 11, 286, 1194, 291, 4140, 411, 10996, 2158, 294, 264, 2020, 300, 311, 644, 50856], "temperature": 0.0, "avg_logprob": -0.22488798293392215, "compression_ratio": 1.8185483870967742, "no_speech_prob": 0.011663907207548618}, {"id": 1116, "seek": 618924, "start": 6199.08, "end": 6203.719999999999, "text": " of you is in... Well, there is permanent value, right? So you would lose a lot if that robot", "tokens": [50856, 295, 291, 307, 294, 485, 1042, 11, 456, 307, 10996, 2158, 11, 558, 30, 407, 291, 576, 3624, 257, 688, 498, 300, 7881, 51088], "temperature": 0.0, "avg_logprob": -0.22488798293392215, "compression_ratio": 1.8185483870967742, "no_speech_prob": 0.011663907207548618}, {"id": 1117, "seek": 618924, "start": 6203.719999999999, "end": 6207.8, "text": " were to be destroyed and you had no backup, you would lose a lot. You would lose a lot of investment,", "tokens": [51088, 645, 281, 312, 8937, 293, 291, 632, 572, 14807, 11, 291, 576, 3624, 257, 688, 13, 509, 576, 3624, 257, 688, 295, 6078, 11, 51292], "temperature": 0.0, "avg_logprob": -0.22488798293392215, "compression_ratio": 1.8185483870967742, "no_speech_prob": 0.011663907207548618}, {"id": 1118, "seek": 618924, "start": 6207.8, "end": 6215.639999999999, "text": " you know, kind of like a person dying, you know, that a friend of yours dying or a co-worker or", "tokens": [51292, 291, 458, 11, 733, 295, 411, 257, 954, 8639, 11, 291, 458, 11, 300, 257, 1277, 295, 6342, 8639, 420, 257, 598, 12, 49402, 420, 51684], "temperature": 0.0, "avg_logprob": -0.22488798293392215, "compression_ratio": 1.8185483870967742, "no_speech_prob": 0.011663907207548618}, {"id": 1119, "seek": 621564, "start": 6215.64, "end": 6225.0, "text": " something like that. But also you have intellectual property rights in the sense that that system", "tokens": [50364, 746, 411, 300, 13, 583, 611, 291, 362, 12576, 4707, 4601, 294, 264, 2020, 300, 300, 1185, 50832], "temperature": 0.0, "avg_logprob": -0.09822566088508157, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0018095825798809528}, {"id": 1120, "seek": 621564, "start": 6225.0, "end": 6230.6, "text": " is fine-tuned to your particular existence. So that's now a very unique instantiation of that", "tokens": [50832, 307, 2489, 12, 83, 43703, 281, 428, 1729, 9123, 13, 407, 300, 311, 586, 257, 588, 3845, 9836, 6642, 295, 300, 51112], "temperature": 0.0, "avg_logprob": -0.09822566088508157, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0018095825798809528}, {"id": 1121, "seek": 621564, "start": 6230.6, "end": 6235.400000000001, "text": " original background model, whatever it was that arrived. And then there are issues of privacy,", "tokens": [51112, 3380, 3678, 2316, 11, 2035, 309, 390, 300, 6678, 13, 400, 550, 456, 366, 2663, 295, 11427, 11, 51352], "temperature": 0.0, "avg_logprob": -0.09822566088508157, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0018095825798809528}, {"id": 1122, "seek": 621564, "start": 6235.400000000001, "end": 6241.4800000000005, "text": " right? Because now imagine that that robot has its own kind of volition and decides to work", "tokens": [51352, 558, 30, 1436, 586, 3811, 300, 300, 7881, 575, 1080, 1065, 733, 295, 1996, 849, 293, 14898, 281, 589, 51656], "temperature": 0.0, "avg_logprob": -0.09822566088508157, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0018095825798809528}, {"id": 1123, "seek": 624148, "start": 6241.48, "end": 6247.639999999999, "text": " for someone else or kind of thinks life with you is sort of untenable or whatever.", "tokens": [50364, 337, 1580, 1646, 420, 733, 295, 7309, 993, 365, 291, 307, 1333, 295, 25693, 712, 420, 2035, 13, 50672], "temperature": 0.0, "avg_logprob": -0.15368161751673773, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.03795202821493149}, {"id": 1124, "seek": 624148, "start": 6249.5599999999995, "end": 6252.28, "text": " Now, all the things that that system learned from you,", "tokens": [50768, 823, 11, 439, 264, 721, 300, 300, 1185, 3264, 490, 291, 11, 50904], "temperature": 0.0, "avg_logprob": -0.15368161751673773, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.03795202821493149}, {"id": 1125, "seek": 624148, "start": 6254.5199999999995, "end": 6258.5199999999995, "text": " you know, how can you like, you know, delete all the personal information that that system", "tokens": [51016, 291, 458, 11, 577, 393, 291, 411, 11, 291, 458, 11, 12097, 439, 264, 2973, 1589, 300, 300, 1185, 51216], "temperature": 0.0, "avg_logprob": -0.15368161751673773, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.03795202821493149}, {"id": 1126, "seek": 624148, "start": 6258.5199999999995, "end": 6262.44, "text": " knows about you? Yeah. I mean, that would be kind of an ethical question. Like, you know,", "tokens": [51216, 3255, 466, 291, 30, 865, 13, 286, 914, 11, 300, 576, 312, 733, 295, 364, 18890, 1168, 13, 1743, 11, 291, 458, 11, 51412], "temperature": 0.0, "avg_logprob": -0.15368161751673773, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.03795202821493149}, {"id": 1127, "seek": 624148, "start": 6262.44, "end": 6270.5199999999995, "text": " can you erase the mind of an intelligent robot to protect your privacy? You can't do this with", "tokens": [51412, 393, 291, 23525, 264, 1575, 295, 364, 13232, 7881, 281, 2371, 428, 11427, 30, 509, 393, 380, 360, 341, 365, 51816], "temperature": 0.0, "avg_logprob": -0.15368161751673773, "compression_ratio": 1.7426160337552743, "no_speech_prob": 0.03795202821493149}, {"id": 1128, "seek": 627052, "start": 6270.6, "end": 6275.56, "text": " humans. You can ask them to shut up, but that you don't have complete power over them.", "tokens": [50368, 6255, 13, 509, 393, 1029, 552, 281, 5309, 493, 11, 457, 300, 291, 500, 380, 362, 3566, 1347, 670, 552, 13, 50616], "temperature": 0.0, "avg_logprob": -0.12943299946032072, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.002799517475068569}, {"id": 1129, "seek": 627052, "start": 6275.56, "end": 6280.040000000001, "text": " Can't erase humans. Yeah, it's the problem with the relationships, you know, that you break up,", "tokens": [50616, 1664, 380, 23525, 6255, 13, 865, 11, 309, 311, 264, 1154, 365, 264, 6159, 11, 291, 458, 11, 300, 291, 1821, 493, 11, 50840], "temperature": 0.0, "avg_logprob": -0.12943299946032072, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.002799517475068569}, {"id": 1130, "seek": 627052, "start": 6280.040000000001, "end": 6284.84, "text": " you can't you can't erase the other human with robots. I think it will have to be the same thing", "tokens": [50840, 291, 393, 380, 291, 393, 380, 23525, 264, 661, 1952, 365, 14733, 13, 286, 519, 309, 486, 362, 281, 312, 264, 912, 551, 51080], "temperature": 0.0, "avg_logprob": -0.12943299946032072, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.002799517475068569}, {"id": 1131, "seek": 627052, "start": 6284.84, "end": 6294.4400000000005, "text": " with robots that that risk that there has to be some risk to our interactions to truly experience", "tokens": [51080, 365, 14733, 300, 300, 3148, 300, 456, 575, 281, 312, 512, 3148, 281, 527, 13280, 281, 4908, 1752, 51560], "temperature": 0.0, "avg_logprob": -0.12943299946032072, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.002799517475068569}, {"id": 1132, "seek": 629444, "start": 6294.44, "end": 6300.5199999999995, "text": " them deeply, it feels like. So you have to be able to lose your robot friend. And that robot", "tokens": [50364, 552, 8760, 11, 309, 3417, 411, 13, 407, 291, 362, 281, 312, 1075, 281, 3624, 428, 7881, 1277, 13, 400, 300, 7881, 50668], "temperature": 0.0, "avg_logprob": -0.13058120893395464, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.13284644484519958}, {"id": 1133, "seek": 629444, "start": 6300.5199999999995, "end": 6306.12, "text": " friend to go tweeting about how much of an asshole you are. But then are you allowed to, you know,", "tokens": [50668, 1277, 281, 352, 40090, 466, 577, 709, 295, 364, 28599, 291, 366, 13, 583, 550, 366, 291, 4350, 281, 11, 291, 458, 11, 50948], "temperature": 0.0, "avg_logprob": -0.13058120893395464, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.13284644484519958}, {"id": 1134, "seek": 629444, "start": 6306.12, "end": 6310.679999999999, "text": " murder the robot to protect your private information? Yeah, probably not. I have this", "tokens": [50948, 6568, 264, 7881, 281, 2371, 428, 4551, 1589, 30, 865, 11, 1391, 406, 13, 286, 362, 341, 51176], "temperature": 0.0, "avg_logprob": -0.13058120893395464, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.13284644484519958}, {"id": 1135, "seek": 629444, "start": 6310.679999999999, "end": 6317.5599999999995, "text": " intuition that for robots with with certain, like it's almost like a regulation, if you declare", "tokens": [51176, 24002, 300, 337, 14733, 365, 365, 1629, 11, 411, 309, 311, 1920, 411, 257, 15062, 11, 498, 291, 19710, 51520], "temperature": 0.0, "avg_logprob": -0.13058120893395464, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.13284644484519958}, {"id": 1136, "seek": 629444, "start": 6317.5599999999995, "end": 6322.599999999999, "text": " your robot to be, let's call it sentient or something like that, like this, this robot is", "tokens": [51520, 428, 7881, 281, 312, 11, 718, 311, 818, 309, 2279, 1196, 420, 746, 411, 300, 11, 411, 341, 11, 341, 7881, 307, 51772], "temperature": 0.0, "avg_logprob": -0.13058120893395464, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.13284644484519958}, {"id": 1137, "seek": 632260, "start": 6322.6, "end": 6326.68, "text": " designed for human interaction, then you're not allowed to murder these robots, it's the same as", "tokens": [50364, 4761, 337, 1952, 9285, 11, 550, 291, 434, 406, 4350, 281, 6568, 613, 14733, 11, 309, 311, 264, 912, 382, 50568], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1138, "seek": 632260, "start": 6326.68, "end": 6331.400000000001, "text": " murdering other humans. Well, but what about you do a backup of the robot, you do preserve on the", "tokens": [50568, 6568, 278, 661, 6255, 13, 1042, 11, 457, 437, 466, 291, 360, 257, 14807, 295, 264, 7881, 11, 291, 360, 15665, 322, 264, 50804], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1139, "seek": 632260, "start": 6331.400000000001, "end": 6336.200000000001, "text": " on a high drive or the equivalent in the future, that might be illegal, just like it's a piracy,", "tokens": [50804, 322, 257, 1090, 3332, 420, 264, 10344, 294, 264, 2027, 11, 300, 1062, 312, 11905, 11, 445, 411, 309, 311, 257, 13528, 2551, 11, 51044], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1140, "seek": 632260, "start": 6336.200000000001, "end": 6341.4800000000005, "text": " piracy is illegal. But it's your own, it's your own robot, right? But you can't, you don't,", "tokens": [51044, 13528, 2551, 307, 11905, 13, 583, 309, 311, 428, 1065, 11, 309, 311, 428, 1065, 7881, 11, 558, 30, 583, 291, 393, 380, 11, 291, 500, 380, 11, 51308], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1141, "seek": 632260, "start": 6341.4800000000005, "end": 6346.84, "text": " but then but then you can wipe out his brain. So the this robot doesn't know anything about you", "tokens": [51308, 457, 550, 457, 550, 291, 393, 14082, 484, 702, 3567, 13, 407, 264, 341, 7881, 1177, 380, 458, 1340, 466, 291, 51576], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1142, "seek": 632260, "start": 6346.84, "end": 6351.56, "text": " anymore, but you still have technically is still in existence because you backed it up.", "tokens": [51576, 3602, 11, 457, 291, 920, 362, 12120, 307, 920, 294, 9123, 570, 291, 20391, 309, 493, 13, 51812], "temperature": 0.0, "avg_logprob": -0.18659341254201875, "compression_ratio": 1.8115015974440896, "no_speech_prob": 0.039605189114809036}, {"id": 1143, "seek": 635156, "start": 6351.56, "end": 6356.6, "text": " And then there'll be these great speeches at the Supreme Court by saying, Oh, sure, you can erase", "tokens": [50364, 400, 550, 456, 603, 312, 613, 869, 29982, 412, 264, 11032, 7873, 538, 1566, 11, 876, 11, 988, 11, 291, 393, 23525, 50616], "temperature": 0.0, "avg_logprob": -0.11401469648376969, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006664849352091551}, {"id": 1144, "seek": 635156, "start": 6356.6, "end": 6361.080000000001, "text": " the mind of the robot, just like you can erase the mind of a human, we both can suffer. There'll", "tokens": [50616, 264, 1575, 295, 264, 7881, 11, 445, 411, 291, 393, 23525, 264, 1575, 295, 257, 1952, 11, 321, 1293, 393, 9753, 13, 821, 603, 50840], "temperature": 0.0, "avg_logprob": -0.11401469648376969, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006664849352091551}, {"id": 1145, "seek": 635156, "start": 6361.080000000001, "end": 6367.080000000001, "text": " be some epic like Obama type character with a speech that we we like the robots and the humans", "tokens": [50840, 312, 512, 13581, 411, 9560, 2010, 2517, 365, 257, 6218, 300, 321, 321, 411, 264, 14733, 293, 264, 6255, 51140], "temperature": 0.0, "avg_logprob": -0.11401469648376969, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006664849352091551}, {"id": 1146, "seek": 635156, "start": 6367.080000000001, "end": 6374.200000000001, "text": " are the same. We can both suffer, we can both hope, we can both all those all those kinds of", "tokens": [51140, 366, 264, 912, 13, 492, 393, 1293, 9753, 11, 321, 393, 1293, 1454, 11, 321, 393, 1293, 439, 729, 439, 729, 3685, 295, 51496], "temperature": 0.0, "avg_logprob": -0.11401469648376969, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006664849352091551}, {"id": 1147, "seek": 635156, "start": 6374.200000000001, "end": 6379.72, "text": " things, raise families, all that kind of stuff. It's it's interesting for these just like you", "tokens": [51496, 721, 11, 5300, 4466, 11, 439, 300, 733, 295, 1507, 13, 467, 311, 309, 311, 1880, 337, 613, 445, 411, 291, 51772], "temperature": 0.0, "avg_logprob": -0.11401469648376969, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006664849352091551}, {"id": 1148, "seek": 637972, "start": 6379.72, "end": 6386.360000000001, "text": " said, emotion seems to be a fascinatingly powerful aspect of human human interaction, human robot", "tokens": [50364, 848, 11, 8913, 2544, 281, 312, 257, 10343, 356, 4005, 4171, 295, 1952, 1952, 9285, 11, 1952, 7881, 50696], "temperature": 0.0, "avg_logprob": -0.13919237758336442, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.009658812545239925}, {"id": 1149, "seek": 637972, "start": 6386.360000000001, "end": 6392.280000000001, "text": " interaction. And if they're able to exhibit emotions at the end of the day, that's probably", "tokens": [50696, 9285, 13, 400, 498, 436, 434, 1075, 281, 20487, 8462, 412, 264, 917, 295, 264, 786, 11, 300, 311, 1391, 50992], "temperature": 0.0, "avg_logprob": -0.13919237758336442, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.009658812545239925}, {"id": 1150, "seek": 637972, "start": 6392.280000000001, "end": 6399.08, "text": " going to have us deeply consider human rights, like what we value in humans, what we value in", "tokens": [50992, 516, 281, 362, 505, 8760, 1949, 1952, 4601, 11, 411, 437, 321, 2158, 294, 6255, 11, 437, 321, 2158, 294, 51332], "temperature": 0.0, "avg_logprob": -0.13919237758336442, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.009658812545239925}, {"id": 1151, "seek": 637972, "start": 6399.08, "end": 6404.84, "text": " other animals. That's why robots and AI is great. It makes us ask as the hard questions.", "tokens": [51332, 661, 4882, 13, 663, 311, 983, 14733, 293, 7318, 307, 869, 13, 467, 1669, 505, 1029, 382, 264, 1152, 1651, 13, 51620], "temperature": 0.0, "avg_logprob": -0.13919237758336442, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.009658812545239925}, {"id": 1152, "seek": 640484, "start": 6404.84, "end": 6409.24, "text": " Yeah. But you, I mean, you asked about you asked about the Chinese room type argument,", "tokens": [50364, 865, 13, 583, 291, 11, 286, 914, 11, 291, 2351, 466, 291, 2351, 466, 264, 4649, 1808, 2010, 6770, 11, 50584], "temperature": 0.0, "avg_logprob": -0.19045115783151273, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.020564142614603043}, {"id": 1153, "seek": 640484, "start": 6409.24, "end": 6413.16, "text": " you know, is it real? If it looks real? I think the Chinese room argument is the", "tokens": [50584, 291, 458, 11, 307, 309, 957, 30, 759, 309, 1542, 957, 30, 286, 519, 264, 4649, 1808, 6770, 307, 264, 50780], "temperature": 0.0, "avg_logprob": -0.19045115783151273, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.020564142614603043}, {"id": 1154, "seek": 640484, "start": 6413.16, "end": 6419.88, "text": " ridiculous one. So, so for people who don't know Chinese room is you can, I don't even know how", "tokens": [50780, 11083, 472, 13, 407, 11, 370, 337, 561, 567, 500, 380, 458, 4649, 1808, 307, 291, 393, 11, 286, 500, 380, 754, 458, 577, 51116], "temperature": 0.0, "avg_logprob": -0.19045115783151273, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.020564142614603043}, {"id": 1155, "seek": 640484, "start": 6419.88, "end": 6426.2, "text": " to formulate it well, but basically, you can mimic the behavior of an intelligent system by just", "tokens": [51116, 281, 47881, 309, 731, 11, 457, 1936, 11, 291, 393, 31075, 264, 5223, 295, 364, 13232, 1185, 538, 445, 51432], "temperature": 0.0, "avg_logprob": -0.19045115783151273, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.020564142614603043}, {"id": 1156, "seek": 640484, "start": 6426.2, "end": 6432.76, "text": " following a giant algorithm code book that tells you exactly how to respond in exactly each case.", "tokens": [51432, 3480, 257, 7410, 9284, 3089, 1446, 300, 5112, 291, 2293, 577, 281, 4196, 294, 2293, 1184, 1389, 13, 51760], "temperature": 0.0, "avg_logprob": -0.19045115783151273, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.020564142614603043}, {"id": 1157, "seek": 643276, "start": 6432.76, "end": 6437.72, "text": " But is that really intelligent? It's like a giant lookup table. When this person says this,", "tokens": [50364, 583, 307, 300, 534, 13232, 30, 467, 311, 411, 257, 7410, 574, 1010, 3199, 13, 1133, 341, 954, 1619, 341, 11, 50612], "temperature": 0.0, "avg_logprob": -0.09757236041853913, "compression_ratio": 1.9208333333333334, "no_speech_prob": 0.019095104187726974}, {"id": 1158, "seek": 643276, "start": 6437.72, "end": 6443.88, "text": " you answer this, when this person says this, you answer this. And if you understand how that", "tokens": [50612, 291, 1867, 341, 11, 562, 341, 954, 1619, 341, 11, 291, 1867, 341, 13, 400, 498, 291, 1223, 577, 300, 50920], "temperature": 0.0, "avg_logprob": -0.09757236041853913, "compression_ratio": 1.9208333333333334, "no_speech_prob": 0.019095104187726974}, {"id": 1159, "seek": 643276, "start": 6443.88, "end": 6448.76, "text": " works, you have this giant nearly infinite lookup table. Is that really intelligence? Because", "tokens": [50920, 1985, 11, 291, 362, 341, 7410, 6217, 13785, 574, 1010, 3199, 13, 1119, 300, 534, 7599, 30, 1436, 51164], "temperature": 0.0, "avg_logprob": -0.09757236041853913, "compression_ratio": 1.9208333333333334, "no_speech_prob": 0.019095104187726974}, {"id": 1160, "seek": 643276, "start": 6448.76, "end": 6453.96, "text": " intelligence seems to be a mechanism that's much more interesting and complex than this lookup", "tokens": [51164, 7599, 2544, 281, 312, 257, 7513, 300, 311, 709, 544, 1880, 293, 3997, 813, 341, 574, 1010, 51424], "temperature": 0.0, "avg_logprob": -0.09757236041853913, "compression_ratio": 1.9208333333333334, "no_speech_prob": 0.019095104187726974}, {"id": 1161, "seek": 643276, "start": 6453.96, "end": 6459.400000000001, "text": " table. I don't think so. So the, I mean, the real question comes down to, do you think,", "tokens": [51424, 3199, 13, 286, 500, 380, 519, 370, 13, 407, 264, 11, 286, 914, 11, 264, 957, 1168, 1487, 760, 281, 11, 360, 291, 519, 11, 51696], "temperature": 0.0, "avg_logprob": -0.09757236041853913, "compression_ratio": 1.9208333333333334, "no_speech_prob": 0.019095104187726974}, {"id": 1162, "seek": 645940, "start": 6460.28, "end": 6466.679999999999, "text": " you know, you can, you can mechanize intelligence in some way, even if that involves learning?", "tokens": [50408, 291, 458, 11, 291, 393, 11, 291, 393, 4236, 1125, 7599, 294, 512, 636, 11, 754, 498, 300, 11626, 2539, 30, 50728], "temperature": 0.0, "avg_logprob": -0.12620195500990924, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027938983403146267}, {"id": 1163, "seek": 645940, "start": 6467.48, "end": 6472.04, "text": " And the answer is, of course, yes, there's no question. There's a second question then,", "tokens": [50768, 400, 264, 1867, 307, 11, 295, 1164, 11, 2086, 11, 456, 311, 572, 1168, 13, 821, 311, 257, 1150, 1168, 550, 11, 50996], "temperature": 0.0, "avg_logprob": -0.12620195500990924, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027938983403146267}, {"id": 1164, "seek": 645940, "start": 6472.04, "end": 6478.36, "text": " which is assuming you can reproduce intelligence in sort of different hardware than biological", "tokens": [50996, 597, 307, 11926, 291, 393, 29501, 7599, 294, 1333, 295, 819, 8837, 813, 13910, 51312], "temperature": 0.0, "avg_logprob": -0.12620195500990924, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027938983403146267}, {"id": 1165, "seek": 645940, "start": 6478.36, "end": 6486.679999999999, "text": " hardware, you know, like computers. Can you, you know, match human intelligence in", "tokens": [51312, 8837, 11, 291, 458, 11, 411, 10807, 13, 1664, 291, 11, 291, 458, 11, 2995, 1952, 7599, 294, 51728], "temperature": 0.0, "avg_logprob": -0.12620195500990924, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0027938983403146267}, {"id": 1166, "seek": 648668, "start": 6487.16, "end": 6494.84, "text": " all the domains in which humans are intelligent? Is it possible, right? So this is quite the", "tokens": [50388, 439, 264, 25514, 294, 597, 6255, 366, 13232, 30, 1119, 309, 1944, 11, 558, 30, 407, 341, 307, 1596, 264, 50772], "temperature": 0.0, "avg_logprob": -0.1629210291682063, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.002393335336819291}, {"id": 1167, "seek": 648668, "start": 6494.84, "end": 6501.08, "text": " hypothesis of strong AI. The answer to this, in my opinion, is an unqualified yes. This would", "tokens": [50772, 17291, 295, 2068, 7318, 13, 440, 1867, 281, 341, 11, 294, 452, 4800, 11, 307, 364, 517, 46094, 2086, 13, 639, 576, 51084], "temperature": 0.0, "avg_logprob": -0.1629210291682063, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.002393335336819291}, {"id": 1168, "seek": 648668, "start": 6501.08, "end": 6505.64, "text": " as well happen at some point. There's no question that machines at some point will become more", "tokens": [51084, 382, 731, 1051, 412, 512, 935, 13, 821, 311, 572, 1168, 300, 8379, 412, 512, 935, 486, 1813, 544, 51312], "temperature": 0.0, "avg_logprob": -0.1629210291682063, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.002393335336819291}, {"id": 1169, "seek": 648668, "start": 6505.64, "end": 6510.04, "text": " intelligent than humans in all domains where humans are intelligent. This is not for tomorrow,", "tokens": [51312, 13232, 813, 6255, 294, 439, 25514, 689, 6255, 366, 13232, 13, 639, 307, 406, 337, 4153, 11, 51532], "temperature": 0.0, "avg_logprob": -0.1629210291682063, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.002393335336819291}, {"id": 1170, "seek": 648668, "start": 6510.04, "end": 6516.360000000001, "text": " it's going to take a long time, regardless of what, you know, Elon and others have claimed", "tokens": [51532, 309, 311, 516, 281, 747, 257, 938, 565, 11, 10060, 295, 437, 11, 291, 458, 11, 28498, 293, 2357, 362, 12941, 51848], "temperature": 0.0, "avg_logprob": -0.1629210291682063, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.002393335336819291}, {"id": 1171, "seek": 651636, "start": 6516.44, "end": 6521.799999999999, "text": " or believed. This is a lot, a lot harder than many of, many of those guys think it is.", "tokens": [50368, 420, 7847, 13, 639, 307, 257, 688, 11, 257, 688, 6081, 813, 867, 295, 11, 867, 295, 729, 1074, 519, 309, 307, 13, 50636], "temperature": 0.0, "avg_logprob": -0.16016271839971127, "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.006896936800330877}, {"id": 1172, "seek": 651636, "start": 6523.24, "end": 6527.4, "text": " And many of those guys who thought it was simpler than that years, you know, five years ago,", "tokens": [50708, 400, 867, 295, 729, 1074, 567, 1194, 309, 390, 18587, 813, 300, 924, 11, 291, 458, 11, 1732, 924, 2057, 11, 50916], "temperature": 0.0, "avg_logprob": -0.16016271839971127, "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.006896936800330877}, {"id": 1173, "seek": 651636, "start": 6527.4, "end": 6532.36, "text": " now think it's hard because it's been five years and they realize it's going to take a lot longer", "tokens": [50916, 586, 519, 309, 311, 1152, 570, 309, 311, 668, 1732, 924, 293, 436, 4325, 309, 311, 516, 281, 747, 257, 688, 2854, 51164], "temperature": 0.0, "avg_logprob": -0.16016271839971127, "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.006896936800330877}, {"id": 1174, "seek": 651636, "start": 6533.24, "end": 6535.32, "text": " than includes a bunch of people at DeepMind, for example. But", "tokens": [51208, 813, 5974, 257, 3840, 295, 561, 412, 14895, 44, 471, 11, 337, 1365, 13, 583, 51312], "temperature": 0.0, "avg_logprob": -0.16016271839971127, "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.006896936800330877}, {"id": 1175, "seek": 651636, "start": 6535.96, "end": 6540.2, "text": " Oh, interesting. I haven't actually touched base with the DeepMind folks, but some of it,", "tokens": [51344, 876, 11, 1880, 13, 286, 2378, 380, 767, 9828, 3096, 365, 264, 14895, 44, 471, 4024, 11, 457, 512, 295, 309, 11, 51556], "temperature": 0.0, "avg_logprob": -0.16016271839971127, "compression_ratio": 1.6692607003891051, "no_speech_prob": 0.006896936800330877}, {"id": 1176, "seek": 654020, "start": 6540.2, "end": 6548.84, "text": " Elon or Dennis Sousa, I mean, sometimes in your role, you have to kind of create deadlines that", "tokens": [50364, 28498, 420, 23376, 318, 563, 64, 11, 286, 914, 11, 2171, 294, 428, 3090, 11, 291, 362, 281, 733, 295, 1884, 37548, 300, 50796], "temperature": 0.0, "avg_logprob": -0.15700310807887133, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.12222111225128174}, {"id": 1177, "seek": 654020, "start": 6548.84, "end": 6553.88, "text": " are nearer than farther away to kind of create an urgency, because, you know, you have to believe", "tokens": [50796, 366, 2651, 260, 813, 20344, 1314, 281, 733, 295, 1884, 364, 29734, 11, 570, 11, 291, 458, 11, 291, 362, 281, 1697, 51048], "temperature": 0.0, "avg_logprob": -0.15700310807887133, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.12222111225128174}, {"id": 1178, "seek": 654020, "start": 6553.88, "end": 6558.12, "text": " the impossible is possible in order to accomplish it. And there's, of course, a flip side to that", "tokens": [51048, 264, 6243, 307, 1944, 294, 1668, 281, 9021, 309, 13, 400, 456, 311, 11, 295, 1164, 11, 257, 7929, 1252, 281, 300, 51260], "temperature": 0.0, "avg_logprob": -0.15700310807887133, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.12222111225128174}, {"id": 1179, "seek": 654020, "start": 6558.12, "end": 6562.36, "text": " coin, but it's a weird, you can't be too cynical if you want to get something done.", "tokens": [51260, 11464, 11, 457, 309, 311, 257, 3657, 11, 291, 393, 380, 312, 886, 46345, 498, 291, 528, 281, 483, 746, 1096, 13, 51472], "temperature": 0.0, "avg_logprob": -0.15700310807887133, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.12222111225128174}, {"id": 1180, "seek": 654020, "start": 6562.36, "end": 6568.12, "text": " Absolutely. I agree with that. But I mean, you have to inspire people to work on sort of ambitious", "tokens": [51472, 7021, 13, 286, 3986, 365, 300, 13, 583, 286, 914, 11, 291, 362, 281, 15638, 561, 281, 589, 322, 1333, 295, 20239, 51760], "temperature": 0.0, "avg_logprob": -0.15700310807887133, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.12222111225128174}, {"id": 1181, "seek": 656812, "start": 6568.12, "end": 6576.28, "text": " things. So, you know, it's certainly a lot harder than we believe, but there's no question in my", "tokens": [50364, 721, 13, 407, 11, 291, 458, 11, 309, 311, 3297, 257, 688, 6081, 813, 321, 1697, 11, 457, 456, 311, 572, 1168, 294, 452, 50772], "temperature": 0.0, "avg_logprob": -0.09165933055262412, "compression_ratio": 1.75, "no_speech_prob": 0.007686310447752476}, {"id": 1182, "seek": 656812, "start": 6576.28, "end": 6580.36, "text": " mind that this will, this will happen. And now, you know, people are kind of worried about what", "tokens": [50772, 1575, 300, 341, 486, 11, 341, 486, 1051, 13, 400, 586, 11, 291, 458, 11, 561, 366, 733, 295, 5804, 466, 437, 50976], "temperature": 0.0, "avg_logprob": -0.09165933055262412, "compression_ratio": 1.75, "no_speech_prob": 0.007686310447752476}, {"id": 1183, "seek": 656812, "start": 6580.36, "end": 6585.64, "text": " does that mean for humans, they are going to be brought down from their pedestal, you know,", "tokens": [50976, 775, 300, 914, 337, 6255, 11, 436, 366, 516, 281, 312, 3038, 760, 490, 641, 20497, 304, 11, 291, 458, 11, 51240], "temperature": 0.0, "avg_logprob": -0.09165933055262412, "compression_ratio": 1.75, "no_speech_prob": 0.007686310447752476}, {"id": 1184, "seek": 656812, "start": 6585.64, "end": 6591.8, "text": " a bunch of notches with that. And, you know, is that going to be good or bad? I mean,", "tokens": [51240, 257, 3840, 295, 406, 3781, 365, 300, 13, 400, 11, 291, 458, 11, 307, 300, 516, 281, 312, 665, 420, 1578, 30, 286, 914, 11, 51548], "temperature": 0.0, "avg_logprob": -0.09165933055262412, "compression_ratio": 1.75, "no_speech_prob": 0.007686310447752476}, {"id": 1185, "seek": 656812, "start": 6591.8, "end": 6595.5599999999995, "text": " it's just going to give more power, right? It's an amplifier for human intelligence really.", "tokens": [51548, 309, 311, 445, 516, 281, 976, 544, 1347, 11, 558, 30, 467, 311, 364, 27439, 337, 1952, 7599, 534, 13, 51736], "temperature": 0.0, "avg_logprob": -0.09165933055262412, "compression_ratio": 1.75, "no_speech_prob": 0.007686310447752476}, {"id": 1186, "seek": 659556, "start": 6596.120000000001, "end": 6598.84, "text": " So speaking of doing cool, ambitious things,", "tokens": [50392, 407, 4124, 295, 884, 1627, 11, 20239, 721, 11, 50528], "temperature": 0.0, "avg_logprob": -0.1321786177785773, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.003016269998624921}, {"id": 1187, "seek": 659556, "start": 6599.8, "end": 6604.84, "text": " FAIR, the Facebook AI Research Group, has recently celebrated its eighth birthday.", "tokens": [50576, 19894, 7740, 11, 264, 4384, 7318, 10303, 10500, 11, 575, 3938, 19366, 1080, 19495, 6154, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1321786177785773, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.003016269998624921}, {"id": 1188, "seek": 659556, "start": 6605.400000000001, "end": 6612.280000000001, "text": " Or maybe you can correct me on that. Looking back, what has been the successes, the failures,", "tokens": [50856, 1610, 1310, 291, 393, 3006, 385, 322, 300, 13, 11053, 646, 11, 437, 575, 668, 264, 26101, 11, 264, 20774, 11, 51200], "temperature": 0.0, "avg_logprob": -0.1321786177785773, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.003016269998624921}, {"id": 1189, "seek": 659556, "start": 6612.280000000001, "end": 6616.4400000000005, "text": " the lessons learned from the eight years of FAIR? And maybe you can also give context of", "tokens": [51200, 264, 8820, 3264, 490, 264, 3180, 924, 295, 19894, 7740, 30, 400, 1310, 291, 393, 611, 976, 4319, 295, 51408], "temperature": 0.0, "avg_logprob": -0.1321786177785773, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.003016269998624921}, {"id": 1190, "seek": 659556, "start": 6616.4400000000005, "end": 6622.52, "text": " where does the newly minted meta AI fit into how does it relate to FAIR?", "tokens": [51408, 689, 775, 264, 15109, 18189, 292, 19616, 7318, 3318, 666, 577, 775, 309, 10961, 281, 19894, 7740, 30, 51712], "temperature": 0.0, "avg_logprob": -0.1321786177785773, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.003016269998624921}, {"id": 1191, "seek": 662252, "start": 6622.52, "end": 6624.92, "text": " Right. So let me tell you a little bit about the organization of all this.", "tokens": [50364, 1779, 13, 407, 718, 385, 980, 291, 257, 707, 857, 466, 264, 4475, 295, 439, 341, 13, 50484], "temperature": 0.0, "avg_logprob": -0.10500319658127506, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.003156221704557538}, {"id": 1192, "seek": 662252, "start": 6626.6, "end": 6631.080000000001, "text": " Yeah, FAIR was created almost exactly eight years ago. It wasn't called FAIR yet.", "tokens": [50568, 865, 11, 19894, 7740, 390, 2942, 1920, 2293, 3180, 924, 2057, 13, 467, 2067, 380, 1219, 19894, 7740, 1939, 13, 50792], "temperature": 0.0, "avg_logprob": -0.10500319658127506, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.003156221704557538}, {"id": 1193, "seek": 662252, "start": 6631.080000000001, "end": 6638.4400000000005, "text": " It took that name a few months later. And at the time, I joined Facebook. There was a group", "tokens": [50792, 467, 1890, 300, 1315, 257, 1326, 2493, 1780, 13, 400, 412, 264, 565, 11, 286, 6869, 4384, 13, 821, 390, 257, 1594, 51160], "temperature": 0.0, "avg_logprob": -0.10500319658127506, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.003156221704557538}, {"id": 1194, "seek": 662252, "start": 6638.4400000000005, "end": 6644.68, "text": " called the AI Group that had about 12 engineers and a few scientists, like, you know, 10 engineers", "tokens": [51160, 1219, 264, 7318, 10500, 300, 632, 466, 2272, 11955, 293, 257, 1326, 7708, 11, 411, 11, 291, 458, 11, 1266, 11955, 51472], "temperature": 0.0, "avg_logprob": -0.10500319658127506, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.003156221704557538}, {"id": 1195, "seek": 662252, "start": 6644.68, "end": 6649.64, "text": " and two scientists or something like that. I ran it for three and a half years as a director,", "tokens": [51472, 293, 732, 7708, 420, 746, 411, 300, 13, 286, 5872, 309, 337, 1045, 293, 257, 1922, 924, 382, 257, 5391, 11, 51720], "temperature": 0.0, "avg_logprob": -0.10500319658127506, "compression_ratio": 1.6455223880597014, "no_speech_prob": 0.003156221704557538}, {"id": 1196, "seek": 664964, "start": 6650.52, "end": 6654.92, "text": " you know, hired the first few scientists and kind of set up the culture and organized it,", "tokens": [50408, 291, 458, 11, 13144, 264, 700, 1326, 7708, 293, 733, 295, 992, 493, 264, 3713, 293, 9983, 309, 11, 50628], "temperature": 0.0, "avg_logprob": -0.07531709205813525, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0020386676769703627}, {"id": 1197, "seek": 664964, "start": 6654.92, "end": 6660.68, "text": " you know, explained to the Facebook leadership what fundamental research was about and how it", "tokens": [50628, 291, 458, 11, 8825, 281, 264, 4384, 5848, 437, 8088, 2132, 390, 466, 293, 577, 309, 50916], "temperature": 0.0, "avg_logprob": -0.07531709205813525, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0020386676769703627}, {"id": 1198, "seek": 664964, "start": 6660.68, "end": 6670.360000000001, "text": " can work within industry and how it needs to be open and everything. And I think it's been an", "tokens": [50916, 393, 589, 1951, 3518, 293, 577, 309, 2203, 281, 312, 1269, 293, 1203, 13, 400, 286, 519, 309, 311, 668, 364, 51400], "temperature": 0.0, "avg_logprob": -0.07531709205813525, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0020386676769703627}, {"id": 1199, "seek": 664964, "start": 6670.360000000001, "end": 6677.88, "text": " unqualified success in the sense that FAIR has simultaneously produced, you know,", "tokens": [51400, 517, 46094, 2245, 294, 264, 2020, 300, 19894, 7740, 575, 16561, 7126, 11, 291, 458, 11, 51776], "temperature": 0.0, "avg_logprob": -0.07531709205813525, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0020386676769703627}, {"id": 1200, "seek": 667788, "start": 6677.96, "end": 6683.32, "text": " top level research and advanced the science and the technology provided tools, open source tools", "tokens": [50368, 1192, 1496, 2132, 293, 7339, 264, 3497, 293, 264, 2899, 5649, 3873, 11, 1269, 4009, 3873, 50636], "temperature": 0.0, "avg_logprob": -0.13009733393572379, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.004184809513390064}, {"id": 1201, "seek": 667788, "start": 6683.32, "end": 6691.32, "text": " like PyTorch and many others. But at the same time as had a direct or mostly indirect impact", "tokens": [50636, 411, 9953, 51, 284, 339, 293, 867, 2357, 13, 583, 412, 264, 912, 565, 382, 632, 257, 2047, 420, 5240, 19523, 2712, 51036], "temperature": 0.0, "avg_logprob": -0.13009733393572379, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.004184809513390064}, {"id": 1202, "seek": 667788, "start": 6691.96, "end": 6700.36, "text": " on Facebook at the time, now meta, in the sense that a lot of systems that are that meta is built", "tokens": [51068, 322, 4384, 412, 264, 565, 11, 586, 19616, 11, 294, 264, 2020, 300, 257, 688, 295, 3652, 300, 366, 300, 19616, 307, 3094, 51488], "temperature": 0.0, "avg_logprob": -0.13009733393572379, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.004184809513390064}, {"id": 1203, "seek": 670036, "start": 6700.36, "end": 6709.32, "text": " around now are based on research projects that started at FAIR. And so if you were to take out,", "tokens": [50364, 926, 586, 366, 2361, 322, 2132, 4455, 300, 1409, 412, 19894, 7740, 13, 400, 370, 498, 291, 645, 281, 747, 484, 11, 50812], "temperature": 0.0, "avg_logprob": -0.11061455408732096, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.013286037370562553}, {"id": 1204, "seek": 670036, "start": 6709.32, "end": 6716.36, "text": " you know, deep running out of Facebook services now and meta more generally, I mean, the company", "tokens": [50812, 291, 458, 11, 2452, 2614, 484, 295, 4384, 3328, 586, 293, 19616, 544, 5101, 11, 286, 914, 11, 264, 2237, 51164], "temperature": 0.0, "avg_logprob": -0.11061455408732096, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.013286037370562553}, {"id": 1205, "seek": 670036, "start": 6716.36, "end": 6721.719999999999, "text": " would literally crumble. I mean, it's completely built around AI these days. And it's really", "tokens": [51164, 576, 3736, 47478, 13, 286, 914, 11, 309, 311, 2584, 3094, 926, 7318, 613, 1708, 13, 400, 309, 311, 534, 51432], "temperature": 0.0, "avg_logprob": -0.11061455408732096, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.013286037370562553}, {"id": 1206, "seek": 670036, "start": 6721.719999999999, "end": 6728.599999999999, "text": " essential to the operations. So what happened after three and a half years is that I changed", "tokens": [51432, 7115, 281, 264, 7705, 13, 407, 437, 2011, 934, 1045, 293, 257, 1922, 924, 307, 300, 286, 3105, 51776], "temperature": 0.0, "avg_logprob": -0.11061455408732096, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.013286037370562553}, {"id": 1207, "seek": 672860, "start": 6728.6, "end": 6735.56, "text": " role, I became chief scientist. So I'm not doing day to day management of FAIR anymore. I'm more of a", "tokens": [50364, 3090, 11, 286, 3062, 9588, 12662, 13, 407, 286, 478, 406, 884, 786, 281, 786, 4592, 295, 19894, 7740, 3602, 13, 286, 478, 544, 295, 257, 50712], "temperature": 0.0, "avg_logprob": -0.13763678624079778, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.007166169583797455}, {"id": 1208, "seek": 672860, "start": 6735.56, "end": 6741.320000000001, "text": " kind of, you know, think about strategy and things like that. And I carry my, I conduct my own research,", "tokens": [50712, 733, 295, 11, 291, 458, 11, 519, 466, 5206, 293, 721, 411, 300, 13, 400, 286, 3985, 452, 11, 286, 6018, 452, 1065, 2132, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13763678624079778, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.007166169583797455}, {"id": 1209, "seek": 672860, "start": 6741.320000000001, "end": 6744.6, "text": " I've, you know, my own kind of research group working on self supervised learning and things", "tokens": [51000, 286, 600, 11, 291, 458, 11, 452, 1065, 733, 295, 2132, 1594, 1364, 322, 2698, 46533, 2539, 293, 721, 51164], "temperature": 0.0, "avg_logprob": -0.13763678624079778, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.007166169583797455}, {"id": 1210, "seek": 672860, "start": 6744.6, "end": 6751.56, "text": " like this, which I didn't have time to do when I was director. So now FAIR is run by Joel Pinot", "tokens": [51164, 411, 341, 11, 597, 286, 994, 380, 362, 565, 281, 360, 562, 286, 390, 5391, 13, 407, 586, 19894, 7740, 307, 1190, 538, 21522, 22619, 310, 51512], "temperature": 0.0, "avg_logprob": -0.13763678624079778, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.007166169583797455}, {"id": 1211, "seek": 672860, "start": 6751.56, "end": 6757.160000000001, "text": " and Antoine Baud together, because FAIR is kind of split into now there's something called FAIR", "tokens": [51512, 293, 5130, 44454, 363, 3751, 1214, 11, 570, 19894, 7740, 307, 733, 295, 7472, 666, 586, 456, 311, 746, 1219, 19894, 7740, 51792], "temperature": 0.0, "avg_logprob": -0.13763678624079778, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.007166169583797455}, {"id": 1212, "seek": 675716, "start": 6757.16, "end": 6762.92, "text": " Labs, which is sort of bottom up census driven research and FAIR Excel, which is slightly more", "tokens": [50364, 40047, 11, 597, 307, 1333, 295, 2767, 493, 23725, 9555, 2132, 293, 19894, 7740, 19060, 11, 597, 307, 4748, 544, 50652], "temperature": 0.0, "avg_logprob": -0.14270231940529562, "compression_ratio": 1.5397489539748954, "no_speech_prob": 0.006995000876486301}, {"id": 1213, "seek": 675716, "start": 6762.92, "end": 6768.36, "text": " organized for bigger projects that require a little more kind of focus and more engineering", "tokens": [50652, 9983, 337, 3801, 4455, 300, 3651, 257, 707, 544, 733, 295, 1879, 293, 544, 7043, 50924], "temperature": 0.0, "avg_logprob": -0.14270231940529562, "compression_ratio": 1.5397489539748954, "no_speech_prob": 0.006995000876486301}, {"id": 1214, "seek": 675716, "start": 6768.36, "end": 6772.76, "text": " support and things like that. So Joel needs FAIR Lab and Antoine Baud needs FAIR Excel.", "tokens": [50924, 1406, 293, 721, 411, 300, 13, 407, 21522, 2203, 19894, 7740, 10137, 293, 5130, 44454, 363, 3751, 2203, 19894, 7740, 19060, 13, 51144], "temperature": 0.0, "avg_logprob": -0.14270231940529562, "compression_ratio": 1.5397489539748954, "no_speech_prob": 0.006995000876486301}, {"id": 1215, "seek": 675716, "start": 6772.76, "end": 6780.2, "text": " Where are they located? It's delocalized all over. So there's no question that the leadership", "tokens": [51144, 2305, 366, 436, 6870, 30, 467, 311, 1103, 36483, 1602, 439, 670, 13, 407, 456, 311, 572, 1168, 300, 264, 5848, 51516], "temperature": 0.0, "avg_logprob": -0.14270231940529562, "compression_ratio": 1.5397489539748954, "no_speech_prob": 0.006995000876486301}, {"id": 1216, "seek": 678020, "start": 6781.16, "end": 6787.5599999999995, "text": " of the company believes that this was a very worthwhile investment. And what that means is that", "tokens": [50412, 295, 264, 2237, 12307, 300, 341, 390, 257, 588, 28159, 6078, 13, 400, 437, 300, 1355, 307, 300, 50732], "temperature": 0.0, "avg_logprob": -0.11619851944294382, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.015766961500048637}, {"id": 1217, "seek": 678020, "start": 6790.12, "end": 6797.08, "text": " it's there for the long run, right? So there is, if you want to talk in these terms, which I don't", "tokens": [50860, 309, 311, 456, 337, 264, 938, 1190, 11, 558, 30, 407, 456, 307, 11, 498, 291, 528, 281, 751, 294, 613, 2115, 11, 597, 286, 500, 380, 51208], "temperature": 0.0, "avg_logprob": -0.11619851944294382, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.015766961500048637}, {"id": 1218, "seek": 678020, "start": 6797.08, "end": 6802.92, "text": " like, there's a business model, if you want, where FAIR, despite being a very fundamental", "tokens": [51208, 411, 11, 456, 311, 257, 1606, 2316, 11, 498, 291, 528, 11, 689, 19894, 7740, 11, 7228, 885, 257, 588, 8088, 51500], "temperature": 0.0, "avg_logprob": -0.11619851944294382, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.015766961500048637}, {"id": 1219, "seek": 678020, "start": 6802.92, "end": 6807.5599999999995, "text": " research lab brings a lot of value to the company, either mostly indirectly through other groups.", "tokens": [51500, 2132, 2715, 5607, 257, 688, 295, 2158, 281, 264, 2237, 11, 2139, 5240, 37779, 807, 661, 3935, 13, 51732], "temperature": 0.0, "avg_logprob": -0.11619851944294382, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.015766961500048637}, {"id": 1220, "seek": 680756, "start": 6807.56, "end": 6813.8, "text": " Now, what happened three and a half years ago when I stepped down was also the creation of", "tokens": [50364, 823, 11, 437, 2011, 1045, 293, 257, 1922, 924, 2057, 562, 286, 15251, 760, 390, 611, 264, 8016, 295, 50676], "temperature": 0.0, "avg_logprob": -0.11010707508433949, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.003809327259659767}, {"id": 1221, "seek": 680756, "start": 6813.8, "end": 6820.6, "text": " Facebook AI, which was basically a larger organization that covers FAIR. So FAIR is", "tokens": [50676, 4384, 7318, 11, 597, 390, 1936, 257, 4833, 4475, 300, 10538, 19894, 7740, 13, 407, 19894, 7740, 307, 51016], "temperature": 0.0, "avg_logprob": -0.11010707508433949, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.003809327259659767}, {"id": 1222, "seek": 680756, "start": 6820.6, "end": 6828.4400000000005, "text": " included in it, but also has other organizations that are focused on applied research or advanced", "tokens": [51016, 5556, 294, 309, 11, 457, 611, 575, 661, 6150, 300, 366, 5178, 322, 6456, 2132, 420, 7339, 51408], "temperature": 0.0, "avg_logprob": -0.11010707508433949, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.003809327259659767}, {"id": 1223, "seek": 680756, "start": 6828.4400000000005, "end": 6834.52, "text": " development of AI technology that is more focused on the products of the company.", "tokens": [51408, 3250, 295, 7318, 2899, 300, 307, 544, 5178, 322, 264, 3383, 295, 264, 2237, 13, 51712], "temperature": 0.0, "avg_logprob": -0.11010707508433949, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.003809327259659767}, {"id": 1224, "seek": 680756, "start": 6834.52, "end": 6836.52, "text": " So less emphasis on fundamental research?", "tokens": [51712, 407, 1570, 16271, 322, 8088, 2132, 30, 51812], "temperature": 0.0, "avg_logprob": -0.11010707508433949, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.003809327259659767}, {"id": 1225, "seek": 683652, "start": 6836.6, "end": 6839.72, "text": " Less fundamental, but it's still a research. I mean, there's a lot of papers coming out of", "tokens": [50368, 18649, 8088, 11, 457, 309, 311, 920, 257, 2132, 13, 286, 914, 11, 456, 311, 257, 688, 295, 10577, 1348, 484, 295, 50524], "temperature": 0.0, "avg_logprob": -0.15637307471417367, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0035200119018554688}, {"id": 1226, "seek": 683652, "start": 6839.72, "end": 6848.120000000001, "text": " those organizations and people are awesome and wonderful to interact with. But it serves as", "tokens": [50524, 729, 6150, 293, 561, 366, 3476, 293, 3715, 281, 4648, 365, 13, 583, 309, 13451, 382, 50944], "temperature": 0.0, "avg_logprob": -0.15637307471417367, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0035200119018554688}, {"id": 1227, "seek": 683652, "start": 6850.280000000001, "end": 6859.320000000001, "text": " a way to scale up, if you want, AI technology, which may be very experimental and lab prototypes", "tokens": [51052, 257, 636, 281, 4373, 493, 11, 498, 291, 528, 11, 7318, 2899, 11, 597, 815, 312, 588, 17069, 293, 2715, 42197, 51504], "temperature": 0.0, "avg_logprob": -0.15637307471417367, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0035200119018554688}, {"id": 1228, "seek": 683652, "start": 6859.320000000001, "end": 6864.76, "text": " in two things that are usable. So FAIR is a subset of meta AI. If FAIR becomes like KFC,", "tokens": [51504, 294, 732, 721, 300, 366, 29975, 13, 407, 19894, 7740, 307, 257, 25993, 295, 19616, 7318, 13, 759, 19894, 7740, 3643, 411, 591, 18671, 11, 51776], "temperature": 0.0, "avg_logprob": -0.15637307471417367, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.0035200119018554688}, {"id": 1229, "seek": 686476, "start": 6865.08, "end": 6868.280000000001, "text": " it'll just keep the F. Nobody cares what the F stands for.", "tokens": [50380, 309, 603, 445, 1066, 264, 479, 13, 9297, 12310, 437, 264, 479, 7382, 337, 13, 50540], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1230, "seek": 686476, "start": 6869.400000000001, "end": 6875.400000000001, "text": " Will knows soon enough by probably by the end of 2021.", "tokens": [50596, 3099, 3255, 2321, 1547, 538, 1391, 538, 264, 917, 295, 7201, 13, 50896], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1231, "seek": 686476, "start": 6875.400000000001, "end": 6878.2, "text": " This is not a giant change, FAIR.", "tokens": [50896, 639, 307, 406, 257, 7410, 1319, 11, 19894, 7740, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1232, "seek": 686476, "start": 6878.2, "end": 6883.400000000001, "text": " Well, FAIR doesn't sound too good. But the brand people are kind of deciding on this,", "tokens": [51036, 1042, 11, 19894, 7740, 1177, 380, 1626, 886, 665, 13, 583, 264, 3360, 561, 366, 733, 295, 17990, 322, 341, 11, 51296], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1233, "seek": 686476, "start": 6883.400000000001, "end": 6887.88, "text": " and they've been hesitating for a while now, and they tell us they're going to come up with", "tokens": [51296, 293, 436, 600, 668, 10453, 16350, 337, 257, 1339, 586, 11, 293, 436, 980, 505, 436, 434, 516, 281, 808, 493, 365, 51520], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1234, "seek": 686476, "start": 6887.88, "end": 6891.56, "text": " an answer as to whether FAIR is going to change name or whether we're going to change just the", "tokens": [51520, 364, 1867, 382, 281, 1968, 19894, 7740, 307, 516, 281, 1319, 1315, 420, 1968, 321, 434, 516, 281, 1319, 445, 264, 51704], "temperature": 0.0, "avg_logprob": -0.1517848305080248, "compression_ratio": 1.6342412451361867, "no_speech_prob": 0.05330684036016464}, {"id": 1235, "seek": 689156, "start": 6891.56, "end": 6896.04, "text": " meaning of the F. Oh, that's a good call. I will keep FAIR and change the meaning of the F.", "tokens": [50364, 3620, 295, 264, 479, 13, 876, 11, 300, 311, 257, 665, 818, 13, 286, 486, 1066, 19894, 7740, 293, 1319, 264, 3620, 295, 264, 479, 13, 50588], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1236, "seek": 689156, "start": 6896.04, "end": 6899.8, "text": " That would be my preference. I would turn the F into fundamental.", "tokens": [50588, 663, 576, 312, 452, 17502, 13, 286, 576, 1261, 264, 479, 666, 8088, 13, 50776], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1237, "seek": 689156, "start": 6900.84, "end": 6902.200000000001, "text": " Oh, that's good. Fundamental AI research.", "tokens": [50828, 876, 11, 300, 311, 665, 13, 13493, 44538, 7318, 2132, 13, 50896], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1238, "seek": 689156, "start": 6902.200000000001, "end": 6903.0, "text": " Oh, that's really good. Yeah.", "tokens": [50896, 876, 11, 300, 311, 534, 665, 13, 865, 13, 50936], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1239, "seek": 689156, "start": 6903.0, "end": 6908.200000000001, "text": " Within meta AI. So this would be meta FAIR, but people will call it FAIR, right?", "tokens": [50936, 15996, 19616, 7318, 13, 407, 341, 576, 312, 19616, 19894, 7740, 11, 457, 561, 486, 818, 309, 19894, 7740, 11, 558, 30, 51196], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1240, "seek": 689156, "start": 6908.200000000001, "end": 6909.72, "text": " Yeah, exactly. I like it.", "tokens": [51196, 865, 11, 2293, 13, 286, 411, 309, 13, 51272], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1241, "seek": 689156, "start": 6909.72, "end": 6920.92, "text": " And now meta AI is part of the reality lab. So meta now, the new Facebook", "tokens": [51272, 400, 586, 19616, 7318, 307, 644, 295, 264, 4103, 2715, 13, 407, 19616, 586, 11, 264, 777, 4384, 51832], "temperature": 0.0, "avg_logprob": -0.17374706268310547, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.01587209850549698}, {"id": 1242, "seek": 692092, "start": 6920.92, "end": 6928.36, "text": " where it's called meta, and it's kind of divided into Facebook, Instagram, WhatsApp,", "tokens": [50364, 689, 309, 311, 1219, 19616, 11, 293, 309, 311, 733, 295, 6666, 666, 4384, 11, 5281, 11, 30513, 11, 50736], "temperature": 0.0, "avg_logprob": -0.24015434810093472, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.0028685263823717833}, {"id": 1243, "seek": 692092, "start": 6930.36, "end": 6939.8, "text": " and reality lab. And reality lab is about AR, VR, telepresence, communication technology,", "tokens": [50836, 293, 4103, 2715, 13, 400, 4103, 2715, 307, 466, 8943, 11, 13722, 11, 4304, 14508, 655, 11, 6101, 2899, 11, 51308], "temperature": 0.0, "avg_logprob": -0.24015434810093472, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.0028685263823717833}, {"id": 1244, "seek": 692092, "start": 6939.8, "end": 6945.0, "text": " and stuff like that. It's kind of the, you can think of it as the sort of a combination of", "tokens": [51308, 293, 1507, 411, 300, 13, 467, 311, 733, 295, 264, 11, 291, 393, 519, 295, 309, 382, 264, 1333, 295, 257, 6562, 295, 51568], "temperature": 0.0, "avg_logprob": -0.24015434810093472, "compression_ratio": 1.4887640449438202, "no_speech_prob": 0.0028685263823717833}, {"id": 1245, "seek": 694500, "start": 6945.72, "end": 6951.88, "text": " sort of new products and technology part of meta.", "tokens": [50400, 1333, 295, 777, 3383, 293, 2899, 644, 295, 19616, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1246, "seek": 694500, "start": 6951.88, "end": 6956.04, "text": " Is that where the touch sensing for robots? I saw that you were posting about that.", "tokens": [50708, 1119, 300, 689, 264, 2557, 30654, 337, 14733, 30, 286, 1866, 300, 291, 645, 15978, 466, 300, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1247, "seek": 694500, "start": 6956.04, "end": 6958.84, "text": " Touch sensing for robots is part of FAIR, actually. That's a fact.", "tokens": [50916, 20029, 30654, 337, 14733, 307, 644, 295, 19894, 7740, 11, 767, 13, 663, 311, 257, 1186, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1248, "seek": 694500, "start": 6958.84, "end": 6959.88, "text": " Oh, it is. Okay, cool.", "tokens": [51056, 876, 11, 309, 307, 13, 1033, 11, 1627, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1249, "seek": 694500, "start": 6959.88, "end": 6965.56, "text": " Yeah. There's also the, no, but there is the other way, the haptic glove, right?", "tokens": [51108, 865, 13, 821, 311, 611, 264, 11, 572, 11, 457, 456, 307, 264, 661, 636, 11, 264, 324, 32307, 26928, 11, 558, 30, 51392], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1250, "seek": 694500, "start": 6965.56, "end": 6967.56, "text": " Yes. That's more reality lab.", "tokens": [51392, 1079, 13, 663, 311, 544, 4103, 2715, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1251, "seek": 694500, "start": 6967.56, "end": 6969.88, "text": " That's reality lab research.", "tokens": [51492, 663, 311, 4103, 2715, 2132, 13, 51608], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1252, "seek": 694500, "start": 6969.88, "end": 6973.64, "text": " Reality lab research. But by the way, the touch sense is super interesting,", "tokens": [51608, 33822, 2715, 2132, 13, 583, 538, 264, 636, 11, 264, 2557, 2020, 307, 1687, 1880, 11, 51796], "temperature": 0.0, "avg_logprob": -0.2529221801757813, "compression_ratio": 1.777327935222672, "no_speech_prob": 0.0026720231398940086}, {"id": 1253, "seek": 697364, "start": 6974.280000000001, "end": 6980.04, "text": " like integrating that modality into the whole sensing suite is very interesting.", "tokens": [50396, 411, 26889, 300, 1072, 1860, 666, 264, 1379, 30654, 14205, 307, 588, 1880, 13, 50684], "temperature": 0.0, "avg_logprob": -0.09009124040603637, "compression_ratio": 1.7150259067357514, "no_speech_prob": 0.00239483080804348}, {"id": 1254, "seek": 697364, "start": 6980.04, "end": 6984.6, "text": " So what do you think about the metaverse? What do you think about this whole,", "tokens": [50684, 407, 437, 360, 291, 519, 466, 264, 19616, 4308, 30, 708, 360, 291, 519, 466, 341, 1379, 11, 50912], "temperature": 0.0, "avg_logprob": -0.09009124040603637, "compression_ratio": 1.7150259067357514, "no_speech_prob": 0.00239483080804348}, {"id": 1255, "seek": 697364, "start": 6985.96, "end": 6990.68, "text": " this whole kind of expansion of the view of the role of Facebook and meta in the world?", "tokens": [50980, 341, 1379, 733, 295, 11260, 295, 264, 1910, 295, 264, 3090, 295, 4384, 293, 19616, 294, 264, 1002, 30, 51216], "temperature": 0.0, "avg_logprob": -0.09009124040603637, "compression_ratio": 1.7150259067357514, "no_speech_prob": 0.00239483080804348}, {"id": 1256, "seek": 697364, "start": 6990.68, "end": 6995.240000000001, "text": " Well, metaverse really should be thought of as the next step in the internet, right?", "tokens": [51216, 1042, 11, 19616, 4308, 534, 820, 312, 1194, 295, 382, 264, 958, 1823, 294, 264, 4705, 11, 558, 30, 51444], "temperature": 0.0, "avg_logprob": -0.09009124040603637, "compression_ratio": 1.7150259067357514, "no_speech_prob": 0.00239483080804348}, {"id": 1257, "seek": 699524, "start": 6995.24, "end": 7006.5199999999995, "text": " Sort of trying to kind of make the experience more compelling of being connected either with", "tokens": [50364, 26149, 295, 1382, 281, 733, 295, 652, 264, 1752, 544, 20050, 295, 885, 4582, 2139, 365, 50928], "temperature": 0.0, "avg_logprob": -0.1684844970703125, "compression_ratio": 1.5515151515151515, "no_speech_prob": 0.01769189164042473}, {"id": 1258, "seek": 699524, "start": 7006.5199999999995, "end": 7015.639999999999, "text": " other people or with content. And we are evolved and trained to evolve in 3D environments where", "tokens": [50928, 661, 561, 420, 365, 2701, 13, 400, 321, 366, 14178, 293, 8895, 281, 16693, 294, 805, 35, 12388, 689, 51384], "temperature": 0.0, "avg_logprob": -0.1684844970703125, "compression_ratio": 1.5515151515151515, "no_speech_prob": 0.01769189164042473}, {"id": 1259, "seek": 699524, "start": 7017.16, "end": 7020.92, "text": " we can see other people, we can talk to them when you're near them,", "tokens": [51460, 321, 393, 536, 661, 561, 11, 321, 393, 751, 281, 552, 562, 291, 434, 2651, 552, 11, 51648], "temperature": 0.0, "avg_logprob": -0.1684844970703125, "compression_ratio": 1.5515151515151515, "no_speech_prob": 0.01769189164042473}, {"id": 1260, "seek": 702092, "start": 7021.0, "end": 7025.0, "text": " or, you know, and other people are far away, can hear us, you know, things like that, right?", "tokens": [50368, 420, 11, 291, 458, 11, 293, 661, 561, 366, 1400, 1314, 11, 393, 1568, 505, 11, 291, 458, 11, 721, 411, 300, 11, 558, 30, 50568], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1261, "seek": 702092, "start": 7025.0, "end": 7029.96, "text": " So it, it, there's a lot of social conventions that exist in the real world that we can try to", "tokens": [50568, 407, 309, 11, 309, 11, 456, 311, 257, 688, 295, 2093, 33520, 300, 2514, 294, 264, 957, 1002, 300, 321, 393, 853, 281, 50816], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1262, "seek": 702092, "start": 7029.96, "end": 7036.2, "text": " transpose. Now, what is going to be eventually the, the, how compelling is it going to be?", "tokens": [50816, 25167, 13, 823, 11, 437, 307, 516, 281, 312, 4728, 264, 11, 264, 11, 577, 20050, 307, 309, 516, 281, 312, 30, 51128], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1263, "seek": 702092, "start": 7036.2, "end": 7039.8, "text": " Like our, you know, is it going to be the case that people are going to be willing to", "tokens": [51128, 1743, 527, 11, 291, 458, 11, 307, 309, 516, 281, 312, 264, 1389, 300, 561, 366, 516, 281, 312, 4950, 281, 51308], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1264, "seek": 702092, "start": 7040.76, "end": 7045.16, "text": " do this if they have to wear, you know, a huge pair of goggles all day? Maybe not.", "tokens": [51356, 360, 341, 498, 436, 362, 281, 3728, 11, 291, 458, 11, 257, 2603, 6119, 295, 39808, 439, 786, 30, 2704, 406, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1265, "seek": 702092, "start": 7046.28, "end": 7050.2, "text": " But then again, if the experience is sufficiently compelling, maybe so.", "tokens": [51632, 583, 550, 797, 11, 498, 264, 1752, 307, 31868, 20050, 11, 1310, 370, 13, 51828], "temperature": 0.0, "avg_logprob": -0.14001144246852143, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.015414680354297161}, {"id": 1266, "seek": 705020, "start": 7050.2, "end": 7054.44, "text": " Or if the device that you have to wear is just basically a pair of glasses, you know,", "tokens": [50364, 1610, 498, 264, 4302, 300, 291, 362, 281, 3728, 307, 445, 1936, 257, 6119, 295, 10812, 11, 291, 458, 11, 50576], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1267, "seek": 705020, "start": 7054.44, "end": 7061.48, "text": " technology makes sufficient progress for that. You know, AR is a much easier concept to grasp", "tokens": [50576, 2899, 1669, 11563, 4205, 337, 300, 13, 509, 458, 11, 8943, 307, 257, 709, 3571, 3410, 281, 21743, 50928], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1268, "seek": 705020, "start": 7061.48, "end": 7067.0, "text": " that you're going to have, you know, augmented reality glasses that basically contain some sort", "tokens": [50928, 300, 291, 434, 516, 281, 362, 11, 291, 458, 11, 36155, 4103, 10812, 300, 1936, 5304, 512, 1333, 51204], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1269, "seek": 705020, "start": 7067.0, "end": 7070.12, "text": " of, you know, virtual assistant that can help you in your daily lives.", "tokens": [51204, 295, 11, 291, 458, 11, 6374, 10994, 300, 393, 854, 291, 294, 428, 5212, 2909, 13, 51360], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1270, "seek": 705020, "start": 7070.12, "end": 7074.12, "text": " But at the same time with the AR, you have to contend with reality. With VR, you can", "tokens": [51360, 583, 412, 264, 912, 565, 365, 264, 8943, 11, 291, 362, 281, 660, 521, 365, 4103, 13, 2022, 13722, 11, 291, 393, 51560], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1271, "seek": 705020, "start": 7074.12, "end": 7078.44, "text": " completely detach yourself from reality. So it gives you freedom. It might be easier to design", "tokens": [51560, 2584, 43245, 1803, 490, 4103, 13, 407, 309, 2709, 291, 5645, 13, 467, 1062, 312, 3571, 281, 1715, 51776], "temperature": 0.0, "avg_logprob": -0.09730369325668092, "compression_ratio": 1.771043771043771, "no_speech_prob": 0.001925198594108224}, {"id": 1272, "seek": 707844, "start": 7078.44, "end": 7085.96, "text": " worlds in VR. Yeah, but you, you can imagine how, you know, the metaverse being a mix, a mix,", "tokens": [50364, 13401, 294, 13722, 13, 865, 11, 457, 291, 11, 291, 393, 3811, 577, 11, 291, 458, 11, 264, 19616, 4308, 885, 257, 2890, 11, 257, 2890, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1736176921203073, "compression_ratio": 1.656, "no_speech_prob": 0.007929344661533833}, {"id": 1273, "seek": 707844, "start": 7085.96, "end": 7089.799999999999, "text": " right? Or, or like you can have objects that exist in a metaverse that, you know,", "tokens": [50740, 558, 30, 1610, 11, 420, 411, 291, 393, 362, 6565, 300, 2514, 294, 257, 19616, 4308, 300, 11, 291, 458, 11, 50932], "temperature": 0.0, "avg_logprob": -0.1736176921203073, "compression_ratio": 1.656, "no_speech_prob": 0.007929344661533833}, {"id": 1274, "seek": 707844, "start": 7089.799999999999, "end": 7093.719999999999, "text": " pop up on top of the real world or only exist in virtual reality.", "tokens": [50932, 1665, 493, 322, 1192, 295, 264, 957, 1002, 420, 787, 2514, 294, 6374, 4103, 13, 51128], "temperature": 0.0, "avg_logprob": -0.1736176921203073, "compression_ratio": 1.656, "no_speech_prob": 0.007929344661533833}, {"id": 1275, "seek": 707844, "start": 7094.28, "end": 7099.16, "text": " Okay, let me ask the hard question. Because all of this was easy. This was easy.", "tokens": [51156, 1033, 11, 718, 385, 1029, 264, 1152, 1168, 13, 1436, 439, 295, 341, 390, 1858, 13, 639, 390, 1858, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1736176921203073, "compression_ratio": 1.656, "no_speech_prob": 0.007929344661533833}, {"id": 1276, "seek": 707844, "start": 7100.599999999999, "end": 7107.4, "text": " The Facebook now meta, the social network has been painted by the media as net negative for", "tokens": [51472, 440, 4384, 586, 19616, 11, 264, 2093, 3209, 575, 668, 11797, 538, 264, 3021, 382, 2533, 3671, 337, 51812], "temperature": 0.0, "avg_logprob": -0.1736176921203073, "compression_ratio": 1.656, "no_speech_prob": 0.007929344661533833}, {"id": 1277, "seek": 710740, "start": 7107.4, "end": 7113.48, "text": " society, even destructive and evil at times. You've pushed back against this defending Facebook.", "tokens": [50364, 4086, 11, 754, 26960, 293, 6724, 412, 1413, 13, 509, 600, 9152, 646, 1970, 341, 21377, 4384, 13, 50668], "temperature": 0.0, "avg_logprob": -0.10508409437242446, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.0015223863301798701}, {"id": 1278, "seek": 710740, "start": 7114.04, "end": 7119.96, "text": " Can you explain your defense? Yeah, so the, the description, the company that is being described", "tokens": [50696, 1664, 291, 2903, 428, 7654, 30, 865, 11, 370, 264, 11, 264, 3855, 11, 264, 2237, 300, 307, 885, 7619, 50992], "temperature": 0.0, "avg_logprob": -0.10508409437242446, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.0015223863301798701}, {"id": 1279, "seek": 710740, "start": 7119.96, "end": 7128.36, "text": " in the, in some media is not the company we know when we work inside. And, you know,", "tokens": [50992, 294, 264, 11, 294, 512, 3021, 307, 406, 264, 2237, 321, 458, 562, 321, 589, 1854, 13, 400, 11, 291, 458, 11, 51412], "temperature": 0.0, "avg_logprob": -0.10508409437242446, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.0015223863301798701}, {"id": 1280, "seek": 710740, "start": 7129.32, "end": 7134.5199999999995, "text": " it could be claimed that a lot of employees are uninformed about what really goes on in the company.", "tokens": [51460, 309, 727, 312, 12941, 300, 257, 688, 295, 6619, 366, 43456, 22892, 466, 437, 534, 1709, 322, 294, 264, 2237, 13, 51720], "temperature": 0.0, "avg_logprob": -0.10508409437242446, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.0015223863301798701}, {"id": 1281, "seek": 713452, "start": 7134.52, "end": 7138.68, "text": " But, you know, I'm a vice president. I mean, I have a pretty good vision of what goes on. You", "tokens": [50364, 583, 11, 291, 458, 11, 286, 478, 257, 11964, 3868, 13, 286, 914, 11, 286, 362, 257, 1238, 665, 5201, 295, 437, 1709, 322, 13, 509, 50572], "temperature": 0.0, "avg_logprob": -0.10008257217989623, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.003638205351307988}, {"id": 1282, "seek": 713452, "start": 7138.68, "end": 7142.92, "text": " know, I don't know everything, obviously, I'm not involved in, in, in everything, but certainly", "tokens": [50572, 458, 11, 286, 500, 380, 458, 1203, 11, 2745, 11, 286, 478, 406, 3288, 294, 11, 294, 11, 294, 1203, 11, 457, 3297, 50784], "temperature": 0.0, "avg_logprob": -0.10008257217989623, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.003638205351307988}, {"id": 1283, "seek": 713452, "start": 7142.92, "end": 7147.0, "text": " not in decision about like, you know, content moderation or anything like this. But, but I", "tokens": [50784, 406, 294, 3537, 466, 411, 11, 291, 458, 11, 2701, 49471, 420, 1340, 411, 341, 13, 583, 11, 457, 286, 50988], "temperature": 0.0, "avg_logprob": -0.10008257217989623, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.003638205351307988}, {"id": 1284, "seek": 713452, "start": 7147.0, "end": 7152.84, "text": " have some decent vision of what goes on. And this evil that is being described, I just don't see it.", "tokens": [50988, 362, 512, 8681, 5201, 295, 437, 1709, 322, 13, 400, 341, 6724, 300, 307, 885, 7619, 11, 286, 445, 500, 380, 536, 309, 13, 51280], "temperature": 0.0, "avg_logprob": -0.10008257217989623, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.003638205351307988}, {"id": 1285, "seek": 713452, "start": 7153.56, "end": 7160.52, "text": " And then, you know, I think there is an easy story to buy, which is that, you know, all the bad", "tokens": [51316, 400, 550, 11, 291, 458, 11, 286, 519, 456, 307, 364, 1858, 1657, 281, 2256, 11, 597, 307, 300, 11, 291, 458, 11, 439, 264, 1578, 51664], "temperature": 0.0, "avg_logprob": -0.10008257217989623, "compression_ratio": 1.8488372093023255, "no_speech_prob": 0.003638205351307988}, {"id": 1286, "seek": 716052, "start": 7160.52, "end": 7164.76, "text": " things in the, in the world and, you know, the, the reason your friend believe crazy stuff,", "tokens": [50364, 721, 294, 264, 11, 294, 264, 1002, 293, 11, 291, 458, 11, 264, 11, 264, 1778, 428, 1277, 1697, 3219, 1507, 11, 50576], "temperature": 0.0, "avg_logprob": -0.14134105833450167, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.01237666979432106}, {"id": 1287, "seek": 716052, "start": 7166.6, "end": 7172.68, "text": " you know, there's an easy scapegoat, right, in the, in, in, in social media, in general,", "tokens": [50668, 291, 458, 11, 456, 311, 364, 1858, 4216, 494, 1571, 267, 11, 558, 11, 294, 264, 11, 294, 11, 294, 11, 294, 2093, 3021, 11, 294, 2674, 11, 50972], "temperature": 0.0, "avg_logprob": -0.14134105833450167, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.01237666979432106}, {"id": 1288, "seek": 716052, "start": 7172.68, "end": 7178.84, "text": " Facebook in particular, we have to look at the data, like, is it the case that Facebook, for", "tokens": [50972, 4384, 294, 1729, 11, 321, 362, 281, 574, 412, 264, 1412, 11, 411, 11, 307, 309, 264, 1389, 300, 4384, 11, 337, 51280], "temperature": 0.0, "avg_logprob": -0.14134105833450167, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.01237666979432106}, {"id": 1289, "seek": 716052, "start": 7178.84, "end": 7185.88, "text": " example, polarizes people politically? Are there academic studies that show this? Is it the case", "tokens": [51280, 1365, 11, 12367, 5660, 561, 21154, 30, 2014, 456, 7778, 5313, 300, 855, 341, 30, 1119, 309, 264, 1389, 51632], "temperature": 0.0, "avg_logprob": -0.14134105833450167, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.01237666979432106}, {"id": 1290, "seek": 718588, "start": 7185.88, "end": 7193.08, "text": " that, you know, teenagers think of themselves less if they use Instagram more? Is it the case that,", "tokens": [50364, 300, 11, 291, 458, 11, 23618, 519, 295, 2969, 1570, 498, 436, 764, 5281, 544, 30, 1119, 309, 264, 1389, 300, 11, 50724], "temperature": 0.0, "avg_logprob": -0.11310057838757832, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0018942777533084154}, {"id": 1291, "seek": 718588, "start": 7194.52, "end": 7201.32, "text": " you know, people get more riled up against, you know, opposite sides in a, in a debate or", "tokens": [50796, 291, 458, 11, 561, 483, 544, 367, 7292, 493, 1970, 11, 291, 458, 11, 6182, 4881, 294, 257, 11, 294, 257, 7958, 420, 51136], "temperature": 0.0, "avg_logprob": -0.11310057838757832, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0018942777533084154}, {"id": 1292, "seek": 718588, "start": 7201.32, "end": 7207.400000000001, "text": " political opinion, if they, if they are more on Facebook, or if they are less. And study after", "tokens": [51136, 3905, 4800, 11, 498, 436, 11, 498, 436, 366, 544, 322, 4384, 11, 420, 498, 436, 366, 1570, 13, 400, 2979, 934, 51440], "temperature": 0.0, "avg_logprob": -0.11310057838757832, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0018942777533084154}, {"id": 1293, "seek": 718588, "start": 7207.400000000001, "end": 7212.6, "text": " study show that none of this is true. This is independent studies by academic, they're not", "tokens": [51440, 2979, 855, 300, 6022, 295, 341, 307, 2074, 13, 639, 307, 6695, 5313, 538, 7778, 11, 436, 434, 406, 51700], "temperature": 0.0, "avg_logprob": -0.11310057838757832, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0018942777533084154}, {"id": 1294, "seek": 721260, "start": 7212.6, "end": 7218.200000000001, "text": " funded by Facebook or Meta, you know, studied by Stanford, by some of my colleagues at NYU,", "tokens": [50364, 14385, 538, 4384, 420, 6377, 64, 11, 291, 458, 11, 9454, 538, 20374, 11, 538, 512, 295, 452, 7734, 412, 42682, 11, 50644], "temperature": 0.0, "avg_logprob": -0.14150530620686058, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.016610540449619293}, {"id": 1295, "seek": 721260, "start": 7218.200000000001, "end": 7223.320000000001, "text": " actually, with whom I have no connection. You know, there's a study recently, they, they,", "tokens": [50644, 767, 11, 365, 7101, 286, 362, 572, 4984, 13, 509, 458, 11, 456, 311, 257, 2979, 3938, 11, 436, 11, 436, 11, 50900], "temperature": 0.0, "avg_logprob": -0.14150530620686058, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.016610540449619293}, {"id": 1296, "seek": 721260, "start": 7223.320000000001, "end": 7230.76, "text": " they paid people, I think it was in, in, in, in the former Yugoslavia, I'm not exactly sure in", "tokens": [50900, 436, 4835, 561, 11, 286, 519, 309, 390, 294, 11, 294, 11, 294, 11, 294, 264, 5819, 41949, 329, 75, 23015, 11, 286, 478, 406, 2293, 988, 294, 51272], "temperature": 0.0, "avg_logprob": -0.14150530620686058, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.016610540449619293}, {"id": 1297, "seek": 721260, "start": 7230.76, "end": 7239.400000000001, "text": " what, what part, but they paid people to not use Facebook for a while in the period before the", "tokens": [51272, 437, 11, 437, 644, 11, 457, 436, 4835, 561, 281, 406, 764, 4384, 337, 257, 1339, 294, 264, 2896, 949, 264, 51704], "temperature": 0.0, "avg_logprob": -0.14150530620686058, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.016610540449619293}, {"id": 1298, "seek": 723940, "start": 7239.4, "end": 7245.48, "text": " anniversary of the cybernature massacres, right? So, you know, people get riled up like, you know,", "tokens": [50364, 12962, 295, 264, 13411, 77, 1503, 2758, 326, 495, 11, 558, 30, 407, 11, 291, 458, 11, 561, 483, 367, 7292, 493, 411, 11, 291, 458, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14183186039780127, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.005974460393190384}, {"id": 1299, "seek": 723940, "start": 7245.48, "end": 7251.4, "text": " should we have a celebration? I mean, a memorial kind of celebration for it or not. So they paid", "tokens": [50668, 820, 321, 362, 257, 14184, 30, 286, 914, 11, 257, 24089, 733, 295, 14184, 337, 309, 420, 406, 13, 407, 436, 4835, 50964], "temperature": 0.0, "avg_logprob": -0.14183186039780127, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.005974460393190384}, {"id": 1300, "seek": 723940, "start": 7251.4, "end": 7259.32, "text": " a bunch of people to not use Facebook for a few weeks. And it turns out that those people ended", "tokens": [50964, 257, 3840, 295, 561, 281, 406, 764, 4384, 337, 257, 1326, 3259, 13, 400, 309, 4523, 484, 300, 729, 561, 4590, 51360], "temperature": 0.0, "avg_logprob": -0.14183186039780127, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.005974460393190384}, {"id": 1301, "seek": 723940, "start": 7259.32, "end": 7263.719999999999, "text": " up being more polarized than they were at the beginning. And the people who were more on Facebook", "tokens": [51360, 493, 885, 544, 48623, 813, 436, 645, 412, 264, 2863, 13, 400, 264, 561, 567, 645, 544, 322, 4384, 51580], "temperature": 0.0, "avg_logprob": -0.14183186039780127, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.005974460393190384}, {"id": 1302, "seek": 726372, "start": 7263.72, "end": 7270.6, "text": " were less polarized. There's a study, you know, from Stanford of economics at Stanford that", "tokens": [50364, 645, 1570, 48623, 13, 821, 311, 257, 2979, 11, 291, 458, 11, 490, 20374, 295, 14564, 412, 20374, 300, 50708], "temperature": 0.0, "avg_logprob": -0.12203614976671007, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.021896367892622948}, {"id": 1303, "seek": 726372, "start": 7271.240000000001, "end": 7276.92, "text": " tried to identify the causes of increasing polarization in the US. And it's been going", "tokens": [50740, 3031, 281, 5876, 264, 7700, 295, 5662, 37736, 294, 264, 2546, 13, 400, 309, 311, 668, 516, 51024], "temperature": 0.0, "avg_logprob": -0.12203614976671007, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.021896367892622948}, {"id": 1304, "seek": 726372, "start": 7276.92, "end": 7285.08, "text": " on for 40 years before, you know, Mark Zuckerberg was born continuously. And, and so if there is", "tokens": [51024, 322, 337, 3356, 924, 949, 11, 291, 458, 11, 3934, 34032, 6873, 390, 4232, 15684, 13, 400, 11, 293, 370, 498, 456, 307, 51432], "temperature": 0.0, "avg_logprob": -0.12203614976671007, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.021896367892622948}, {"id": 1305, "seek": 726372, "start": 7285.08, "end": 7289.4800000000005, "text": " a cause, it's not Facebook or social media. So you could say if social media just accelerated,", "tokens": [51432, 257, 3082, 11, 309, 311, 406, 4384, 420, 2093, 3021, 13, 407, 291, 727, 584, 498, 2093, 3021, 445, 29763, 11, 51652], "temperature": 0.0, "avg_logprob": -0.12203614976671007, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.021896367892622948}, {"id": 1306, "seek": 728948, "start": 7289.48, "end": 7294.919999999999, "text": " but no, I mean, it's basically a continuous evolution by some measure of polarization in the", "tokens": [50364, 457, 572, 11, 286, 914, 11, 309, 311, 1936, 257, 10957, 9303, 538, 512, 3481, 295, 37736, 294, 264, 50636], "temperature": 0.0, "avg_logprob": -0.11297481290755733, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.008034661412239075}, {"id": 1307, "seek": 728948, "start": 7294.919999999999, "end": 7302.04, "text": " US. And then you compare this with other countries like the West half of Germany, because you can", "tokens": [50636, 2546, 13, 400, 550, 291, 6794, 341, 365, 661, 3517, 411, 264, 4055, 1922, 295, 7244, 11, 570, 291, 393, 50992], "temperature": 0.0, "avg_logprob": -0.11297481290755733, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.008034661412239075}, {"id": 1308, "seek": 728948, "start": 7302.04, "end": 7309.32, "text": " go 40 years in the East side, or Denmark or other countries. And they use Facebook just as much.", "tokens": [50992, 352, 3356, 924, 294, 264, 6747, 1252, 11, 420, 28065, 420, 661, 3517, 13, 400, 436, 764, 4384, 445, 382, 709, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11297481290755733, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.008034661412239075}, {"id": 1309, "seek": 728948, "start": 7309.32, "end": 7313.32, "text": " And they're not getting more polarized, they're getting less polarized. So if you want to look for,", "tokens": [51356, 400, 436, 434, 406, 1242, 544, 48623, 11, 436, 434, 1242, 1570, 48623, 13, 407, 498, 291, 528, 281, 574, 337, 11, 51556], "temperature": 0.0, "avg_logprob": -0.11297481290755733, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.008034661412239075}, {"id": 1310, "seek": 731332, "start": 7313.4, "end": 7319.88, "text": " you know, a causal relationship there, you can find a scapegoat, but you can't find a cause. Now,", "tokens": [50368, 291, 458, 11, 257, 38755, 2480, 456, 11, 291, 393, 915, 257, 4216, 494, 1571, 267, 11, 457, 291, 393, 380, 915, 257, 3082, 13, 823, 11, 50692], "temperature": 0.0, "avg_logprob": -0.09394687652587891, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.10657897591590881}, {"id": 1311, "seek": 731332, "start": 7319.88, "end": 7325.08, "text": " if you want to fix the problem, you have to find the right cause. And what rise me up is that people", "tokens": [50692, 498, 291, 528, 281, 3191, 264, 1154, 11, 291, 362, 281, 915, 264, 558, 3082, 13, 400, 437, 6272, 385, 493, 307, 300, 561, 50952], "temperature": 0.0, "avg_logprob": -0.09394687652587891, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.10657897591590881}, {"id": 1312, "seek": 731332, "start": 7325.08, "end": 7330.44, "text": " now are accusing Facebook of bad deeds that are done by others. And those others are, we're not", "tokens": [50952, 586, 366, 47436, 4384, 295, 1578, 24539, 300, 366, 1096, 538, 2357, 13, 400, 729, 2357, 366, 11, 321, 434, 406, 51220], "temperature": 0.0, "avg_logprob": -0.09394687652587891, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.10657897591590881}, {"id": 1313, "seek": 731332, "start": 7330.44, "end": 7335.5599999999995, "text": " doing anything about them. And by the way, those others include the owner of the Wall Street Journal", "tokens": [51220, 884, 1340, 466, 552, 13, 400, 538, 264, 636, 11, 729, 2357, 4090, 264, 7289, 295, 264, 9551, 7638, 16936, 51476], "temperature": 0.0, "avg_logprob": -0.09394687652587891, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.10657897591590881}, {"id": 1314, "seek": 731332, "start": 7335.5599999999995, "end": 7340.04, "text": " in which all of those papers were published. So I should mention that I'm talking to Shrep,", "tokens": [51476, 294, 597, 439, 295, 729, 10577, 645, 6572, 13, 407, 286, 820, 2152, 300, 286, 478, 1417, 281, 1160, 19919, 11, 51700], "temperature": 0.0, "avg_logprob": -0.09394687652587891, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.10657897591590881}, {"id": 1315, "seek": 734004, "start": 7340.04, "end": 7344.5199999999995, "text": " Mike Shrep on this podcast, and also Mark Zuckerberg, and probably these are the conversations", "tokens": [50364, 6602, 1160, 19919, 322, 341, 7367, 11, 293, 611, 3934, 34032, 6873, 11, 293, 1391, 613, 366, 264, 7315, 50588], "temperature": 0.0, "avg_logprob": -0.16809089438429156, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.04397478327155113}, {"id": 1316, "seek": 734004, "start": 7344.5199999999995, "end": 7349.88, "text": " you can have with them. Because it's very interesting to me, even if Facebook has some", "tokens": [50588, 291, 393, 362, 365, 552, 13, 1436, 309, 311, 588, 1880, 281, 385, 11, 754, 498, 4384, 575, 512, 50856], "temperature": 0.0, "avg_logprob": -0.16809089438429156, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.04397478327155113}, {"id": 1317, "seek": 734004, "start": 7349.88, "end": 7354.68, "text": " measurable negative effect, you can't just consider that in isolation, you have to consider about", "tokens": [50856, 43615, 3671, 1802, 11, 291, 393, 380, 445, 1949, 300, 294, 16001, 11, 291, 362, 281, 1949, 466, 51096], "temperature": 0.0, "avg_logprob": -0.16809089438429156, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.04397478327155113}, {"id": 1318, "seek": 734004, "start": 7354.68, "end": 7360.6, "text": " all the positive ways it connects us. So like every technology, you can't just say like,", "tokens": [51096, 439, 264, 3353, 2098, 309, 16967, 505, 13, 407, 411, 633, 2899, 11, 291, 393, 380, 445, 584, 411, 11, 51392], "temperature": 0.0, "avg_logprob": -0.16809089438429156, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.04397478327155113}, {"id": 1319, "seek": 734004, "start": 7361.72, "end": 7366.84, "text": " there's an increase in division. Yes, probably Google search engine has created", "tokens": [51448, 456, 311, 364, 3488, 294, 10044, 13, 1079, 11, 1391, 3329, 3164, 2848, 575, 2942, 51704], "temperature": 0.0, "avg_logprob": -0.16809089438429156, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.04397478327155113}, {"id": 1320, "seek": 736684, "start": 7366.92, "end": 7371.08, "text": " increase in division, we have to consider about how much information are brought to the world.", "tokens": [50368, 3488, 294, 10044, 11, 321, 362, 281, 1949, 466, 577, 709, 1589, 366, 3038, 281, 264, 1002, 13, 50576], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1321, "seek": 736684, "start": 7371.08, "end": 7375.16, "text": " Like, I'm sure Wikipedia created more division, if you just look at the division,", "tokens": [50576, 1743, 11, 286, 478, 988, 28999, 2942, 544, 10044, 11, 498, 291, 445, 574, 412, 264, 10044, 11, 50780], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1322, "seek": 736684, "start": 7375.16, "end": 7379.0, "text": " we have to look at the full context of the world and it didn't make a better world.", "tokens": [50780, 321, 362, 281, 574, 412, 264, 1577, 4319, 295, 264, 1002, 293, 309, 994, 380, 652, 257, 1101, 1002, 13, 50972], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1323, "seek": 736684, "start": 7379.0, "end": 7382.04, "text": " I mean, the printing press has created more difference, right? Exactly.", "tokens": [50972, 286, 914, 11, 264, 14699, 1886, 575, 2942, 544, 2649, 11, 558, 30, 7587, 13, 51124], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1324, "seek": 736684, "start": 7383.0, "end": 7389.72, "text": " So, you know, when the printing press was invented, the first books that were printed were", "tokens": [51172, 407, 11, 291, 458, 11, 562, 264, 14699, 1886, 390, 14479, 11, 264, 700, 3642, 300, 645, 13567, 645, 51508], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1325, "seek": 736684, "start": 7389.72, "end": 7393.72, "text": " things like the Bible, and that allowed people to read the Bible by themselves,", "tokens": [51508, 721, 411, 264, 6544, 11, 293, 300, 4350, 561, 281, 1401, 264, 6544, 538, 2969, 11, 51708], "temperature": 0.0, "avg_logprob": -0.16208779017130534, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.02589382790029049}, {"id": 1326, "seek": 739372, "start": 7393.72, "end": 7400.360000000001, "text": " not get the message uniquely from priests in Europe, and that created the Protestant movement", "tokens": [50364, 406, 483, 264, 3636, 31474, 490, 27192, 294, 3315, 11, 293, 300, 2942, 264, 38345, 3963, 50696], "temperature": 0.0, "avg_logprob": -0.10733240955280808, "compression_ratio": 1.7116104868913857, "no_speech_prob": 0.0013030157424509525}, {"id": 1327, "seek": 739372, "start": 7400.360000000001, "end": 7405.64, "text": " and 200 years of religious persecution and wars. So, that's a bad side effect of the printing", "tokens": [50696, 293, 2331, 924, 295, 7185, 36878, 293, 13718, 13, 407, 11, 300, 311, 257, 1578, 1252, 1802, 295, 264, 14699, 50960], "temperature": 0.0, "avg_logprob": -0.10733240955280808, "compression_ratio": 1.7116104868913857, "no_speech_prob": 0.0013030157424509525}, {"id": 1328, "seek": 739372, "start": 7405.64, "end": 7409.8, "text": " press. Social networks aren't being nearly as bad as the printing press, but nobody would", "tokens": [50960, 1886, 13, 9909, 9590, 3212, 380, 885, 6217, 382, 1578, 382, 264, 14699, 1886, 11, 457, 5079, 576, 51168], "temperature": 0.0, "avg_logprob": -0.10733240955280808, "compression_ratio": 1.7116104868913857, "no_speech_prob": 0.0013030157424509525}, {"id": 1329, "seek": 739372, "start": 7409.8, "end": 7416.04, "text": " say the printing press was a bad idea. Yeah, a lot of this perception, and there's a lot of", "tokens": [51168, 584, 264, 14699, 1886, 390, 257, 1578, 1558, 13, 865, 11, 257, 688, 295, 341, 12860, 11, 293, 456, 311, 257, 688, 295, 51480], "temperature": 0.0, "avg_logprob": -0.10733240955280808, "compression_ratio": 1.7116104868913857, "no_speech_prob": 0.0013030157424509525}, {"id": 1330, "seek": 739372, "start": 7416.04, "end": 7421.56, "text": " different incentives operating here. Maybe a quick comment, since you're one of the top", "tokens": [51480, 819, 23374, 7447, 510, 13, 2704, 257, 1702, 2871, 11, 1670, 291, 434, 472, 295, 264, 1192, 51756], "temperature": 0.0, "avg_logprob": -0.10733240955280808, "compression_ratio": 1.7116104868913857, "no_speech_prob": 0.0013030157424509525}, {"id": 1331, "seek": 742156, "start": 7421.56, "end": 7428.4400000000005, "text": " leaders at Facebook and at Meta, sorry, that's in the tech space, I'm sure Facebook involves", "tokens": [50364, 3523, 412, 4384, 293, 412, 6377, 64, 11, 2597, 11, 300, 311, 294, 264, 7553, 1901, 11, 286, 478, 988, 4384, 11626, 50708], "temperature": 0.0, "avg_logprob": -0.1207712073075144, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.017694566398859024}, {"id": 1332, "seek": 742156, "start": 7428.4400000000005, "end": 7433.64, "text": " a lot of incredible technological challenges that need to be solved. A lot of it probably", "tokens": [50708, 257, 688, 295, 4651, 18439, 4759, 300, 643, 281, 312, 13041, 13, 316, 688, 295, 309, 1391, 50968], "temperature": 0.0, "avg_logprob": -0.1207712073075144, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.017694566398859024}, {"id": 1333, "seek": 742156, "start": 7433.64, "end": 7439.4800000000005, "text": " is in the computer infrastructure, the hardware, I mean, it's just a huge amount. Maybe can you", "tokens": [50968, 307, 294, 264, 3820, 6896, 11, 264, 8837, 11, 286, 914, 11, 309, 311, 445, 257, 2603, 2372, 13, 2704, 393, 291, 51260], "temperature": 0.0, "avg_logprob": -0.1207712073075144, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.017694566398859024}, {"id": 1334, "seek": 742156, "start": 7439.4800000000005, "end": 7446.120000000001, "text": " give me context about how much of Shrep's life is AI and how much of it is low-level compute,", "tokens": [51260, 976, 385, 4319, 466, 577, 709, 295, 1160, 19919, 311, 993, 307, 7318, 293, 577, 709, 295, 309, 307, 2295, 12, 12418, 14722, 11, 51592], "temperature": 0.0, "avg_logprob": -0.1207712073075144, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.017694566398859024}, {"id": 1335, "seek": 744612, "start": 7446.12, "end": 7451.96, "text": " how much of it is flying all around doing business stuff, and the same with Mark Zuckerberg?", "tokens": [50364, 577, 709, 295, 309, 307, 7137, 439, 926, 884, 1606, 1507, 11, 293, 264, 912, 365, 3934, 34032, 6873, 30, 50656], "temperature": 0.0, "avg_logprob": -0.12798849086171574, "compression_ratio": 1.5228215767634854, "no_speech_prob": 0.04994181543588638}, {"id": 1336, "seek": 744612, "start": 7451.96, "end": 7461.4, "text": " They really focus on AI. I mean, certainly in the run-up of the Creation Affair, and for at", "tokens": [50656, 814, 534, 1879, 322, 7318, 13, 286, 914, 11, 3297, 294, 264, 1190, 12, 1010, 295, 264, 42874, 12840, 1246, 11, 293, 337, 412, 51128], "temperature": 0.0, "avg_logprob": -0.12798849086171574, "compression_ratio": 1.5228215767634854, "no_speech_prob": 0.04994181543588638}, {"id": 1337, "seek": 744612, "start": 7461.4, "end": 7467.4, "text": " least a year after that, if not more, Mark was very, very much focused on AI and was spending", "tokens": [51128, 1935, 257, 1064, 934, 300, 11, 498, 406, 544, 11, 3934, 390, 588, 11, 588, 709, 5178, 322, 7318, 293, 390, 6434, 51428], "temperature": 0.0, "avg_logprob": -0.12798849086171574, "compression_ratio": 1.5228215767634854, "no_speech_prob": 0.04994181543588638}, {"id": 1338, "seek": 744612, "start": 7467.4, "end": 7471.96, "text": " quite a lot of effort on it, and that's his style. When he gets interested in something,", "tokens": [51428, 1596, 257, 688, 295, 4630, 322, 309, 11, 293, 300, 311, 702, 3758, 13, 1133, 415, 2170, 3102, 294, 746, 11, 51656], "temperature": 0.0, "avg_logprob": -0.12798849086171574, "compression_ratio": 1.5228215767634854, "no_speech_prob": 0.04994181543588638}, {"id": 1339, "seek": 747196, "start": 7471.96, "end": 7476.2, "text": " he reads everything about it. He read some of my papers, for example, before I joined.", "tokens": [50364, 415, 15700, 1203, 466, 309, 13, 634, 1401, 512, 295, 452, 10577, 11, 337, 1365, 11, 949, 286, 6869, 13, 50576], "temperature": 0.0, "avg_logprob": -0.20302482553430506, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.05789952725172043}, {"id": 1340, "seek": 747196, "start": 7479.56, "end": 7482.36, "text": " And so he learns a lot about it.", "tokens": [50744, 400, 370, 415, 27152, 257, 688, 466, 309, 13, 50884], "temperature": 0.0, "avg_logprob": -0.20302482553430506, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.05789952725172043}, {"id": 1341, "seek": 747196, "start": 7486.36, "end": 7492.2, "text": " And Shrep was really to it also. I mean, Shrep is really kind of,", "tokens": [51084, 400, 1160, 19919, 390, 534, 281, 309, 611, 13, 286, 914, 11, 1160, 19919, 307, 534, 733, 295, 11, 51376], "temperature": 0.0, "avg_logprob": -0.20302482553430506, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.05789952725172043}, {"id": 1342, "seek": 747196, "start": 7494.68, "end": 7500.04, "text": " has something I've tried to preserve also, despite my not so young age,", "tokens": [51500, 575, 746, 286, 600, 3031, 281, 15665, 611, 11, 7228, 452, 406, 370, 2037, 3205, 11, 51768], "temperature": 0.0, "avg_logprob": -0.20302482553430506, "compression_ratio": 1.511764705882353, "no_speech_prob": 0.05789952725172043}, {"id": 1343, "seek": 750004, "start": 7500.04, "end": 7505.0, "text": " which is a sense of wonder about science and technology, and he certainly has that.", "tokens": [50364, 597, 307, 257, 2020, 295, 2441, 466, 3497, 293, 2899, 11, 293, 415, 3297, 575, 300, 13, 50612], "temperature": 0.0, "avg_logprob": -0.15618242536272323, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.002688617678359151}, {"id": 1344, "seek": 750004, "start": 7506.12, "end": 7511.4, "text": " He's also a wonderful person. I mean, in terms of, as a manager, like dealing with people and", "tokens": [50668, 634, 311, 611, 257, 3715, 954, 13, 286, 914, 11, 294, 2115, 295, 11, 382, 257, 6598, 11, 411, 6260, 365, 561, 293, 50932], "temperature": 0.0, "avg_logprob": -0.15618242536272323, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.002688617678359151}, {"id": 1345, "seek": 750004, "start": 7511.4, "end": 7519.4, "text": " everything, Mark also actually. I mean, they're very human people. In the case of Mark, it's", "tokens": [50932, 1203, 11, 3934, 611, 767, 13, 286, 914, 11, 436, 434, 588, 1952, 561, 13, 682, 264, 1389, 295, 3934, 11, 309, 311, 51332], "temperature": 0.0, "avg_logprob": -0.15618242536272323, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.002688617678359151}, {"id": 1346, "seek": 750004, "start": 7519.4, "end": 7527.24, "text": " shockingly human, given his trajectory. I mean, the personality of him that he's", "tokens": [51332, 5588, 12163, 1952, 11, 2212, 702, 21512, 13, 286, 914, 11, 264, 9033, 295, 796, 300, 415, 311, 51724], "temperature": 0.0, "avg_logprob": -0.15618242536272323, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.002688617678359151}, {"id": 1347, "seek": 752724, "start": 7527.24, "end": 7531.32, "text": " spending in the press, it's just completely wrong. Yeah. But you have to know how to play", "tokens": [50364, 6434, 294, 264, 1886, 11, 309, 311, 445, 2584, 2085, 13, 865, 13, 583, 291, 362, 281, 458, 577, 281, 862, 50568], "temperature": 0.0, "avg_logprob": -0.16937009026022518, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.01972287893295288}, {"id": 1348, "seek": 752724, "start": 7531.32, "end": 7536.76, "text": " the press. So that's, I put some of that responsibility on him, too. You have to,", "tokens": [50568, 264, 1886, 13, 407, 300, 311, 11, 286, 829, 512, 295, 300, 6357, 322, 796, 11, 886, 13, 509, 362, 281, 11, 50840], "temperature": 0.0, "avg_logprob": -0.16937009026022518, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.01972287893295288}, {"id": 1349, "seek": 752724, "start": 7538.76, "end": 7544.92, "text": " it's like, you know, like the director, the conductor of an orchestra, you have to play", "tokens": [50940, 309, 311, 411, 11, 291, 458, 11, 411, 264, 5391, 11, 264, 29957, 295, 364, 25280, 11, 291, 362, 281, 862, 51248], "temperature": 0.0, "avg_logprob": -0.16937009026022518, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.01972287893295288}, {"id": 1350, "seek": 752724, "start": 7544.92, "end": 7549.719999999999, "text": " the press and the public in a certain kind of way, where you convey your true self to them,", "tokens": [51248, 264, 1886, 293, 264, 1908, 294, 257, 1629, 733, 295, 636, 11, 689, 291, 16965, 428, 2074, 2698, 281, 552, 11, 51488], "temperature": 0.0, "avg_logprob": -0.16937009026022518, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.01972287893295288}, {"id": 1351, "seek": 752724, "start": 7549.719999999999, "end": 7554.44, "text": " if there's a depth of kindness. And it's probably not the best at it. So, yeah.", "tokens": [51488, 498, 456, 311, 257, 7161, 295, 18171, 13, 400, 309, 311, 1391, 406, 264, 1151, 412, 309, 13, 407, 11, 1338, 13, 51724], "temperature": 0.0, "avg_logprob": -0.16937009026022518, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.01972287893295288}, {"id": 1352, "seek": 755444, "start": 7555.16, "end": 7562.44, "text": " You have to learn. And it's sad to see, I'll talk to him about it, but the Shrep is slowly", "tokens": [50400, 509, 362, 281, 1466, 13, 400, 309, 311, 4227, 281, 536, 11, 286, 603, 751, 281, 796, 466, 309, 11, 457, 264, 1160, 19919, 307, 5692, 50764], "temperature": 0.0, "avg_logprob": -0.18043742460363052, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.0027131366077810526}, {"id": 1353, "seek": 755444, "start": 7562.44, "end": 7568.679999999999, "text": " stepping down. It's always sad to see folks sort of be there for a long time and slowly,", "tokens": [50764, 16821, 760, 13, 467, 311, 1009, 4227, 281, 536, 4024, 1333, 295, 312, 456, 337, 257, 938, 565, 293, 5692, 11, 51076], "temperature": 0.0, "avg_logprob": -0.18043742460363052, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.0027131366077810526}, {"id": 1354, "seek": 755444, "start": 7569.4, "end": 7577.16, "text": " I guess time is sad. I think he's done the thing he said had to do and, you know, he's got, you know,", "tokens": [51112, 286, 2041, 565, 307, 4227, 13, 286, 519, 415, 311, 1096, 264, 551, 415, 848, 632, 281, 360, 293, 11, 291, 458, 11, 415, 311, 658, 11, 291, 458, 11, 51500], "temperature": 0.0, "avg_logprob": -0.18043742460363052, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.0027131366077810526}, {"id": 1355, "seek": 757716, "start": 7577.32, "end": 7585.96, "text": " you know, family priorities and stuff like that. And I understand, you know, after 13 years or", "tokens": [50372, 291, 458, 11, 1605, 15503, 293, 1507, 411, 300, 13, 400, 286, 1223, 11, 291, 458, 11, 934, 3705, 924, 420, 50804], "temperature": 0.0, "avg_logprob": -0.1690418322881063, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.02671937085688114}, {"id": 1356, "seek": 757716, "start": 7585.96, "end": 7592.76, "text": " something. It's been a good run. Which in Silicon Valley is basically a lifetime. Yeah. You know,", "tokens": [50804, 746, 13, 467, 311, 668, 257, 665, 1190, 13, 3013, 294, 25351, 10666, 307, 1936, 257, 11364, 13, 865, 13, 509, 458, 11, 51144], "temperature": 0.0, "avg_logprob": -0.1690418322881063, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.02671937085688114}, {"id": 1357, "seek": 757716, "start": 7592.76, "end": 7597.24, "text": " because, you know, it's dog years. So, in Europe, the conference just wrapped up.", "tokens": [51144, 570, 11, 291, 458, 11, 309, 311, 3000, 924, 13, 407, 11, 294, 3315, 11, 264, 7586, 445, 14226, 493, 13, 51368], "temperature": 0.0, "avg_logprob": -0.1690418322881063, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.02671937085688114}, {"id": 1358, "seek": 757716, "start": 7598.5199999999995, "end": 7603.32, "text": " Let me just go back to something else. You posted the paper you co-authored was rejected from", "tokens": [51432, 961, 385, 445, 352, 646, 281, 746, 1646, 13, 509, 9437, 264, 3035, 291, 598, 12, 40198, 2769, 390, 15749, 490, 51672], "temperature": 0.0, "avg_logprob": -0.1690418322881063, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.02671937085688114}, {"id": 1359, "seek": 760332, "start": 7603.4, "end": 7614.5199999999995, "text": " Europe. As you said, proudly in quotes rejected. Can you describe this paper and like, what was", "tokens": [50368, 3315, 13, 1018, 291, 848, 11, 33522, 294, 19963, 15749, 13, 1664, 291, 6786, 341, 3035, 293, 411, 11, 437, 390, 50924], "temperature": 0.0, "avg_logprob": -0.1668164361383497, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.009400973096489906}, {"id": 1360, "seek": 760332, "start": 7614.5199999999995, "end": 7620.44, "text": " the idea in it? And also, maybe this is a good opportunity to ask what are the pros and cons,", "tokens": [50924, 264, 1558, 294, 309, 30, 400, 611, 11, 1310, 341, 307, 257, 665, 2650, 281, 1029, 437, 366, 264, 6267, 293, 1014, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1668164361383497, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.009400973096489906}, {"id": 1361, "seek": 760332, "start": 7620.44, "end": 7624.84, "text": " what works and what doesn't about the review process. Yeah. Let me talk about the paper first.", "tokens": [51220, 437, 1985, 293, 437, 1177, 380, 466, 264, 3131, 1399, 13, 865, 13, 961, 385, 751, 466, 264, 3035, 700, 13, 51440], "temperature": 0.0, "avg_logprob": -0.1668164361383497, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.009400973096489906}, {"id": 1362, "seek": 760332, "start": 7624.84, "end": 7631.719999999999, "text": " I'll talk about the review process afterwards. The paper is called Vicreg. So this is, I mentioned", "tokens": [51440, 286, 603, 751, 466, 264, 3131, 1399, 10543, 13, 440, 3035, 307, 1219, 33316, 3375, 13, 407, 341, 307, 11, 286, 2835, 51784], "temperature": 0.0, "avg_logprob": -0.1668164361383497, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.009400973096489906}, {"id": 1363, "seek": 763172, "start": 7631.72, "end": 7636.52, "text": " that before, variance in variance, covariance, regularization. And it's a technique, a non-", "tokens": [50364, 300, 949, 11, 21977, 294, 21977, 11, 49851, 719, 11, 3890, 2144, 13, 400, 309, 311, 257, 6532, 11, 257, 2107, 12, 50604], "temperature": 0.0, "avg_logprob": -0.19680816515357094, "compression_ratio": 1.834710743801653, "no_speech_prob": 0.004341138061136007}, {"id": 1364, "seek": 763172, "start": 7636.52, "end": 7642.04, "text": " contrastive learning technique for what I call joint embedding architecture. So,", "tokens": [50604, 8712, 488, 2539, 6532, 337, 437, 286, 818, 7225, 12240, 3584, 9482, 13, 407, 11, 50880], "temperature": 0.0, "avg_logprob": -0.19680816515357094, "compression_ratio": 1.834710743801653, "no_speech_prob": 0.004341138061136007}, {"id": 1365, "seek": 763172, "start": 7642.04, "end": 7646.2, "text": " sami's nets are an example of joint embedding architecture. So joint embedding architecture is", "tokens": [50880, 3247, 72, 311, 36170, 366, 364, 1365, 295, 7225, 12240, 3584, 9482, 13, 407, 7225, 12240, 3584, 9482, 307, 51088], "temperature": 0.0, "avg_logprob": -0.19680816515357094, "compression_ratio": 1.834710743801653, "no_speech_prob": 0.004341138061136007}, {"id": 1366, "seek": 763172, "start": 7649.240000000001, "end": 7652.2, "text": " let me back up a little bit, right? So if you want to do self-supervised learning,", "tokens": [51240, 718, 385, 646, 493, 257, 707, 857, 11, 558, 30, 407, 498, 291, 528, 281, 360, 2698, 12, 48172, 24420, 2539, 11, 51388], "temperature": 0.0, "avg_logprob": -0.19680816515357094, "compression_ratio": 1.834710743801653, "no_speech_prob": 0.004341138061136007}, {"id": 1367, "seek": 763172, "start": 7653.240000000001, "end": 7658.68, "text": " you can do it by prediction. So let's say you want to train a system to predict video, right?", "tokens": [51440, 291, 393, 360, 309, 538, 17630, 13, 407, 718, 311, 584, 291, 528, 281, 3847, 257, 1185, 281, 6069, 960, 11, 558, 30, 51712], "temperature": 0.0, "avg_logprob": -0.19680816515357094, "compression_ratio": 1.834710743801653, "no_speech_prob": 0.004341138061136007}, {"id": 1368, "seek": 765868, "start": 7658.68, "end": 7664.360000000001, "text": " You show it a video clip and you train the system to predict the next, the continuation of that", "tokens": [50364, 509, 855, 309, 257, 960, 7353, 293, 291, 3847, 264, 1185, 281, 6069, 264, 958, 11, 264, 29357, 295, 300, 50648], "temperature": 0.0, "avg_logprob": -0.09072293990697616, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0036223595961928368}, {"id": 1369, "seek": 765868, "start": 7664.360000000001, "end": 7668.92, "text": " video clip. Now, because you need to handle uncertainty, because there are many, you know,", "tokens": [50648, 960, 7353, 13, 823, 11, 570, 291, 643, 281, 4813, 15697, 11, 570, 456, 366, 867, 11, 291, 458, 11, 50876], "temperature": 0.0, "avg_logprob": -0.09072293990697616, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0036223595961928368}, {"id": 1370, "seek": 765868, "start": 7668.92, "end": 7673.96, "text": " many continuations that are plausible, you need to have, you need to handle this in some way.", "tokens": [50876, 867, 2993, 763, 300, 366, 39925, 11, 291, 643, 281, 362, 11, 291, 643, 281, 4813, 341, 294, 512, 636, 13, 51128], "temperature": 0.0, "avg_logprob": -0.09072293990697616, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0036223595961928368}, {"id": 1371, "seek": 765868, "start": 7673.96, "end": 7681.4800000000005, "text": " You need to have a way for the system to be able to produce multiple predictions. And the way,", "tokens": [51128, 509, 643, 281, 362, 257, 636, 337, 264, 1185, 281, 312, 1075, 281, 5258, 3866, 21264, 13, 400, 264, 636, 11, 51504], "temperature": 0.0, "avg_logprob": -0.09072293990697616, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0036223595961928368}, {"id": 1372, "seek": 765868, "start": 7681.4800000000005, "end": 7686.360000000001, "text": " the only way I know to do this is through what's called a latent variable. So you have some sort of", "tokens": [51504, 264, 787, 636, 286, 458, 281, 360, 341, 307, 807, 437, 311, 1219, 257, 48994, 7006, 13, 407, 291, 362, 512, 1333, 295, 51748], "temperature": 0.0, "avg_logprob": -0.09072293990697616, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0036223595961928368}, {"id": 1373, "seek": 768636, "start": 7687.32, "end": 7692.92, "text": " hidden vector of a variable that you can vary over a set or draw from a distribution. And as you", "tokens": [50412, 7633, 8062, 295, 257, 7006, 300, 291, 393, 10559, 670, 257, 992, 420, 2642, 490, 257, 7316, 13, 400, 382, 291, 50692], "temperature": 0.0, "avg_logprob": -0.15708155042669747, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0031187550630420446}, {"id": 1374, "seek": 768636, "start": 7692.92, "end": 7697.5599999999995, "text": " vary this vector over a set, the output, the prediction varies over a set of plausible predictions.", "tokens": [50692, 10559, 341, 8062, 670, 257, 992, 11, 264, 5598, 11, 264, 17630, 21716, 670, 257, 992, 295, 39925, 21264, 13, 50924], "temperature": 0.0, "avg_logprob": -0.15708155042669747, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0031187550630420446}, {"id": 1375, "seek": 768636, "start": 7698.28, "end": 7702.839999999999, "text": " Okay. So that's called, I call this a generative latent variable model.", "tokens": [50960, 1033, 13, 407, 300, 311, 1219, 11, 286, 818, 341, 257, 1337, 1166, 48994, 7006, 2316, 13, 51188], "temperature": 0.0, "avg_logprob": -0.15708155042669747, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0031187550630420446}, {"id": 1376, "seek": 768636, "start": 7703.96, "end": 7710.12, "text": " Got it. Okay. Now, there is an alternative to this to handle uncertainty. And instead of directly", "tokens": [51244, 5803, 309, 13, 1033, 13, 823, 11, 456, 307, 364, 8535, 281, 341, 281, 4813, 15697, 13, 400, 2602, 295, 3838, 51552], "temperature": 0.0, "avg_logprob": -0.15708155042669747, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0031187550630420446}, {"id": 1377, "seek": 771012, "start": 7710.2, "end": 7719.4, "text": " predicting the next frames of the clip, you also run those through another neural net.", "tokens": [50368, 32884, 264, 958, 12083, 295, 264, 7353, 11, 291, 611, 1190, 729, 807, 1071, 18161, 2533, 13, 50828], "temperature": 0.0, "avg_logprob": -0.0970534647212309, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.05571051314473152}, {"id": 1378, "seek": 771012, "start": 7720.92, "end": 7727.88, "text": " So you now have two neural nets, one that looks at the, you know, the initial segment of the video", "tokens": [50904, 407, 291, 586, 362, 732, 18161, 36170, 11, 472, 300, 1542, 412, 264, 11, 291, 458, 11, 264, 5883, 9469, 295, 264, 960, 51252], "temperature": 0.0, "avg_logprob": -0.0970534647212309, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.05571051314473152}, {"id": 1379, "seek": 771012, "start": 7727.88, "end": 7734.44, "text": " clip. And another one that looks at the continuation during training, right? And what you're trying", "tokens": [51252, 7353, 13, 400, 1071, 472, 300, 1542, 412, 264, 29357, 1830, 3097, 11, 558, 30, 400, 437, 291, 434, 1382, 51580], "temperature": 0.0, "avg_logprob": -0.0970534647212309, "compression_ratio": 1.6193181818181819, "no_speech_prob": 0.05571051314473152}, {"id": 1380, "seek": 773444, "start": 7734.44, "end": 7741.4, "text": " to do is learn a representation of those two video clips that is maximally informative about", "tokens": [50364, 281, 360, 307, 1466, 257, 10290, 295, 729, 732, 960, 13117, 300, 307, 5138, 379, 27759, 466, 50712], "temperature": 0.0, "avg_logprob": -0.0819948252509622, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.12568524479866028}, {"id": 1381, "seek": 773444, "start": 7741.4, "end": 7747.879999999999, "text": " the video clips themselves. But it's such that you can predict the representation of the second", "tokens": [50712, 264, 960, 13117, 2969, 13, 583, 309, 311, 1270, 300, 291, 393, 6069, 264, 10290, 295, 264, 1150, 51036], "temperature": 0.0, "avg_logprob": -0.0819948252509622, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.12568524479866028}, {"id": 1382, "seek": 773444, "start": 7747.879999999999, "end": 7753.32, "text": " video clip from the representation of the first one easily. Okay. And you can sort of formalize", "tokens": [51036, 960, 7353, 490, 264, 10290, 295, 264, 700, 472, 3612, 13, 1033, 13, 400, 291, 393, 1333, 295, 9860, 1125, 51308], "temperature": 0.0, "avg_logprob": -0.0819948252509622, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.12568524479866028}, {"id": 1383, "seek": 773444, "start": 7753.32, "end": 7756.679999999999, "text": " this in terms of maximizing mutual information and some stuff like that, but it doesn't matter.", "tokens": [51308, 341, 294, 2115, 295, 5138, 3319, 16917, 1589, 293, 512, 1507, 411, 300, 11, 457, 309, 1177, 380, 1871, 13, 51476], "temperature": 0.0, "avg_logprob": -0.0819948252509622, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.12568524479866028}, {"id": 1384, "seek": 775668, "start": 7757.400000000001, "end": 7764.360000000001, "text": " What you want is informative, representative, you know, informative representations", "tokens": [50400, 708, 291, 528, 307, 27759, 11, 12424, 11, 291, 458, 11, 27759, 33358, 50748], "temperature": 0.0, "avg_logprob": -0.12591958600421285, "compression_ratio": 1.7889447236180904, "no_speech_prob": 0.034555938094854355}, {"id": 1385, "seek": 775668, "start": 7764.360000000001, "end": 7769.8, "text": " of the two video clips that are mutually predictable. What that means is that there's a", "tokens": [50748, 295, 264, 732, 960, 13117, 300, 366, 39144, 27737, 13, 708, 300, 1355, 307, 300, 456, 311, 257, 51020], "temperature": 0.0, "avg_logprob": -0.12591958600421285, "compression_ratio": 1.7889447236180904, "no_speech_prob": 0.034555938094854355}, {"id": 1386, "seek": 775668, "start": 7769.8, "end": 7777.8, "text": " lot of details in the second video clips that are irrelevant. You know, I, let's say a video clip", "tokens": [51020, 688, 295, 4365, 294, 264, 1150, 960, 13117, 300, 366, 28682, 13, 509, 458, 11, 286, 11, 718, 311, 584, 257, 960, 7353, 51420], "temperature": 0.0, "avg_logprob": -0.12591958600421285, "compression_ratio": 1.7889447236180904, "no_speech_prob": 0.034555938094854355}, {"id": 1387, "seek": 775668, "start": 7777.8, "end": 7783.0, "text": " consists in, you know, a camera panning the scene, there's going to be a piece of that", "tokens": [51420, 14689, 294, 11, 291, 458, 11, 257, 2799, 2462, 773, 264, 4145, 11, 456, 311, 516, 281, 312, 257, 2522, 295, 300, 51680], "temperature": 0.0, "avg_logprob": -0.12591958600421285, "compression_ratio": 1.7889447236180904, "no_speech_prob": 0.034555938094854355}, {"id": 1388, "seek": 778300, "start": 7783.0, "end": 7787.32, "text": " room that is going to be revealed. And I can somewhat predict what the, what that room is going", "tokens": [50364, 1808, 300, 307, 516, 281, 312, 9599, 13, 400, 286, 393, 8344, 6069, 437, 264, 11, 437, 300, 1808, 307, 516, 50580], "temperature": 0.0, "avg_logprob": -0.09218737343761409, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.005721121560782194}, {"id": 1389, "seek": 778300, "start": 7787.32, "end": 7792.52, "text": " to look like, but I may not be able to predict the details of the texture of the ground and where", "tokens": [50580, 281, 574, 411, 11, 457, 286, 815, 406, 312, 1075, 281, 6069, 264, 4365, 295, 264, 8091, 295, 264, 2727, 293, 689, 50840], "temperature": 0.0, "avg_logprob": -0.09218737343761409, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.005721121560782194}, {"id": 1390, "seek": 778300, "start": 7792.52, "end": 7797.24, "text": " the tiles are ending and stuff like that. Right. So those are irrelevant details that perhaps", "tokens": [50840, 264, 21982, 366, 8121, 293, 1507, 411, 300, 13, 1779, 13, 407, 729, 366, 28682, 4365, 300, 4317, 51076], "temperature": 0.0, "avg_logprob": -0.09218737343761409, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.005721121560782194}, {"id": 1391, "seek": 778300, "start": 7797.24, "end": 7803.96, "text": " my representation will eliminate. And so what I need is to train this second neural net in such a", "tokens": [51076, 452, 10290, 486, 13819, 13, 400, 370, 437, 286, 643, 307, 281, 3847, 341, 1150, 18161, 2533, 294, 1270, 257, 51412], "temperature": 0.0, "avg_logprob": -0.09218737343761409, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.005721121560782194}, {"id": 1392, "seek": 778300, "start": 7803.96, "end": 7811.88, "text": " way that whenever the continuation video clip varies over all the plausible continuations,", "tokens": [51412, 636, 300, 5699, 264, 29357, 960, 7353, 21716, 670, 439, 264, 39925, 2993, 763, 11, 51808], "temperature": 0.0, "avg_logprob": -0.09218737343761409, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.005721121560782194}, {"id": 1393, "seek": 781300, "start": 7813.48, "end": 7819.24, "text": " the representation doesn't change. Got it. So it's the, yeah, yeah. Got it. Over the space of", "tokens": [50388, 264, 10290, 1177, 380, 1319, 13, 5803, 309, 13, 407, 309, 311, 264, 11, 1338, 11, 1338, 13, 5803, 309, 13, 4886, 264, 1901, 295, 50676], "temperature": 0.0, "avg_logprob": -0.13831192624252453, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.0013883046340197325}, {"id": 1394, "seek": 781300, "start": 7819.24, "end": 7824.44, "text": " representations, doing the same kind of thing as you do with similarity learning. Right.", "tokens": [50676, 33358, 11, 884, 264, 912, 733, 295, 551, 382, 291, 360, 365, 32194, 2539, 13, 1779, 13, 50936], "temperature": 0.0, "avg_logprob": -0.13831192624252453, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.0013883046340197325}, {"id": 1395, "seek": 781300, "start": 7825.64, "end": 7830.68, "text": " So, so these are two ways to handle multimodality in a prediction, right? In the first way,", "tokens": [50996, 407, 11, 370, 613, 366, 732, 2098, 281, 4813, 32972, 378, 1860, 294, 257, 17630, 11, 558, 30, 682, 264, 700, 636, 11, 51248], "temperature": 0.0, "avg_logprob": -0.13831192624252453, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.0013883046340197325}, {"id": 1396, "seek": 781300, "start": 7830.68, "end": 7835.16, "text": " you prioritize the prediction with a latent variable, but you predict pixels essentially,", "tokens": [51248, 291, 25164, 264, 17630, 365, 257, 48994, 7006, 11, 457, 291, 6069, 18668, 4476, 11, 51472], "temperature": 0.0, "avg_logprob": -0.13831192624252453, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.0013883046340197325}, {"id": 1397, "seek": 781300, "start": 7835.16, "end": 7839.24, "text": " right? In the second one, you don't, you don't predict pixels. You predict an abstract", "tokens": [51472, 558, 30, 682, 264, 1150, 472, 11, 291, 500, 380, 11, 291, 500, 380, 6069, 18668, 13, 509, 6069, 364, 12649, 51676], "temperature": 0.0, "avg_logprob": -0.13831192624252453, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.0013883046340197325}, {"id": 1398, "seek": 783924, "start": 7839.24, "end": 7844.04, "text": " representation of pixels. And you guarantee that this abstract representation has as much", "tokens": [50364, 10290, 295, 18668, 13, 400, 291, 10815, 300, 341, 12649, 10290, 575, 382, 709, 50604], "temperature": 0.0, "avg_logprob": -0.11325852483765692, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.05482562258839607}, {"id": 1399, "seek": 783924, "start": 7844.04, "end": 7848.44, "text": " information as possible about the input, but sort of, you know, drops all the stuff that you really", "tokens": [50604, 1589, 382, 1944, 466, 264, 4846, 11, 457, 1333, 295, 11, 291, 458, 11, 11438, 439, 264, 1507, 300, 291, 534, 50824], "temperature": 0.0, "avg_logprob": -0.11325852483765692, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.05482562258839607}, {"id": 1400, "seek": 783924, "start": 7848.44, "end": 7854.599999999999, "text": " can't predict essentially. I used to be a big fan of the first approach. And in fact, in this paper", "tokens": [50824, 393, 380, 6069, 4476, 13, 286, 1143, 281, 312, 257, 955, 3429, 295, 264, 700, 3109, 13, 400, 294, 1186, 11, 294, 341, 3035, 51132], "temperature": 0.0, "avg_logprob": -0.11325852483765692, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.05482562258839607}, {"id": 1401, "seek": 783924, "start": 7854.599999999999, "end": 7859.16, "text": " with the Chen Mishra, this blog post, the dark matter intelligence, I was kind of advocating", "tokens": [51132, 365, 264, 13682, 376, 742, 424, 11, 341, 6968, 2183, 11, 264, 2877, 1871, 7599, 11, 286, 390, 733, 295, 32050, 51360], "temperature": 0.0, "avg_logprob": -0.11325852483765692, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.05482562258839607}, {"id": 1402, "seek": 783924, "start": 7859.16, "end": 7863.48, "text": " for this. And in the last year and a half, I've completely changed my mind. I'm now a big fan", "tokens": [51360, 337, 341, 13, 400, 294, 264, 1036, 1064, 293, 257, 1922, 11, 286, 600, 2584, 3105, 452, 1575, 13, 286, 478, 586, 257, 955, 3429, 51576], "temperature": 0.0, "avg_logprob": -0.11325852483765692, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.05482562258839607}, {"id": 1403, "seek": 786348, "start": 7863.5599999999995, "end": 7870.759999999999, "text": " of the second one. And it's because of a small collection of algorithms that have been proposed", "tokens": [50368, 295, 264, 1150, 472, 13, 400, 309, 311, 570, 295, 257, 1359, 5765, 295, 14642, 300, 362, 668, 10348, 50728], "temperature": 0.0, "avg_logprob": -0.17650381088256836, "compression_ratio": 1.4921259842519685, "no_speech_prob": 0.04652933031320572}, {"id": 1404, "seek": 786348, "start": 7870.759999999999, "end": 7878.5199999999995, "text": " over the last year and a half or so, two years to do this, including V Craig. It's predecessor", "tokens": [50728, 670, 264, 1036, 1064, 293, 257, 1922, 420, 370, 11, 732, 924, 281, 360, 341, 11, 3009, 691, 19732, 13, 467, 311, 34991, 51116], "temperature": 0.0, "avg_logprob": -0.17650381088256836, "compression_ratio": 1.4921259842519685, "no_speech_prob": 0.04652933031320572}, {"id": 1405, "seek": 786348, "start": 7878.5199999999995, "end": 7884.2, "text": " called Barlow Twins, which I mentioned, a method from our friends at DeepMind could be YOL.", "tokens": [51116, 1219, 4156, 14107, 2574, 1292, 11, 597, 286, 2835, 11, 257, 3170, 490, 527, 1855, 412, 14895, 44, 471, 727, 312, 398, 5046, 13, 51400], "temperature": 0.0, "avg_logprob": -0.17650381088256836, "compression_ratio": 1.4921259842519685, "no_speech_prob": 0.04652933031320572}, {"id": 1406, "seek": 786348, "start": 7885.959999999999, "end": 7890.36, "text": " And, and, and there's a bunch of others now that kind of work similarly. So they're all based on", "tokens": [51488, 400, 11, 293, 11, 293, 456, 311, 257, 3840, 295, 2357, 586, 300, 733, 295, 589, 14138, 13, 407, 436, 434, 439, 2361, 322, 51708], "temperature": 0.0, "avg_logprob": -0.17650381088256836, "compression_ratio": 1.4921259842519685, "no_speech_prob": 0.04652933031320572}, {"id": 1407, "seek": 789036, "start": 7890.44, "end": 7895.48, "text": " this idea of joint embedding. Some of them have an explicit criterion that is an approximation of", "tokens": [50368, 341, 1558, 295, 7225, 12240, 3584, 13, 2188, 295, 552, 362, 364, 13691, 46691, 300, 307, 364, 28023, 295, 50620], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1408, "seek": 789036, "start": 7895.48, "end": 7899.96, "text": " mutual information. Some others are BOL work, but we don't really know why. And there's been like", "tokens": [50620, 16917, 1589, 13, 2188, 2357, 366, 363, 5046, 589, 11, 457, 321, 500, 380, 534, 458, 983, 13, 400, 456, 311, 668, 411, 50844], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1409, "seek": 789036, "start": 7899.96, "end": 7904.04, "text": " lots of theoretical papers about why BOL works. No, it's not that because we take it out and it", "tokens": [50844, 3195, 295, 20864, 10577, 466, 983, 363, 5046, 1985, 13, 883, 11, 309, 311, 406, 300, 570, 321, 747, 309, 484, 293, 309, 51048], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1410, "seek": 789036, "start": 7904.04, "end": 7909.32, "text": " still works. And, you know, blah, blah, blah. I mean, so there's like a big debate. But, but", "tokens": [51048, 920, 1985, 13, 400, 11, 291, 458, 11, 12288, 11, 12288, 11, 12288, 13, 286, 914, 11, 370, 456, 311, 411, 257, 955, 7958, 13, 583, 11, 457, 51312], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1411, "seek": 789036, "start": 7909.32, "end": 7913.16, "text": " the important point is that we now have a collection of non-contrastive joint embedding", "tokens": [51312, 264, 1021, 935, 307, 300, 321, 586, 362, 257, 5765, 295, 2107, 12, 9000, 4148, 488, 7225, 12240, 3584, 51504], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1412, "seek": 789036, "start": 7913.16, "end": 7918.2, "text": " methods, which I think is the best thing since sliced bread. So I'm super excited about this,", "tokens": [51504, 7150, 11, 597, 286, 519, 307, 264, 1151, 551, 1670, 27098, 5961, 13, 407, 286, 478, 1687, 2919, 466, 341, 11, 51756], "temperature": 0.0, "avg_logprob": -0.12364064430703922, "compression_ratio": 1.715151515151515, "no_speech_prob": 0.004505116026848555}, {"id": 1413, "seek": 791820, "start": 7918.28, "end": 7925.16, "text": " because I think it's our best shot for techniques that would allow us to kind of build predictive", "tokens": [50368, 570, 286, 519, 309, 311, 527, 1151, 3347, 337, 7512, 300, 576, 2089, 505, 281, 733, 295, 1322, 35521, 50712], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1414, "seek": 791820, "start": 7925.16, "end": 7929.8, "text": " work models. And at the same time, learn hierarchical representations of the world,", "tokens": [50712, 589, 5245, 13, 400, 412, 264, 912, 565, 11, 1466, 35250, 804, 33358, 295, 264, 1002, 11, 50944], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1415, "seek": 791820, "start": 7929.8, "end": 7933.4, "text": " where what matters about the world is preserved and what is irrelevant is eliminated.", "tokens": [50944, 689, 437, 7001, 466, 264, 1002, 307, 22242, 293, 437, 307, 28682, 307, 20308, 13, 51124], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1416, "seek": 791820, "start": 7934.5199999999995, "end": 7939.8, "text": " By the way, the representations that before and after is across in the space in a sequence of", "tokens": [51180, 3146, 264, 636, 11, 264, 33358, 300, 949, 293, 934, 307, 2108, 294, 264, 1901, 294, 257, 8310, 295, 51444], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1417, "seek": 791820, "start": 7939.8, "end": 7944.599999999999, "text": " images, or is it for single images? It would be either for a single image for a sequence. It", "tokens": [51444, 5267, 11, 420, 307, 309, 337, 2167, 5267, 30, 467, 576, 312, 2139, 337, 257, 2167, 3256, 337, 257, 8310, 13, 467, 51684], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1418, "seek": 791820, "start": 7944.599999999999, "end": 7948.12, "text": " doesn't have to be images. This could be applied to text. This could be applied to just about any", "tokens": [51684, 1177, 380, 362, 281, 312, 5267, 13, 639, 727, 312, 6456, 281, 2487, 13, 639, 727, 312, 6456, 281, 445, 466, 604, 51860], "temperature": 0.0, "avg_logprob": -0.14400920271873474, "compression_ratio": 1.8338870431893688, "no_speech_prob": 0.004127830266952515}, {"id": 1419, "seek": 794812, "start": 7948.12, "end": 7952.84, "text": " signal. I'm looking at, you know, I'm looking for methods that are generally applicable,", "tokens": [50364, 6358, 13, 286, 478, 1237, 412, 11, 291, 458, 11, 286, 478, 1237, 337, 7150, 300, 366, 5101, 21142, 11, 50600], "temperature": 0.0, "avg_logprob": -0.20038391993596003, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.005010855384171009}, {"id": 1420, "seek": 794812, "start": 7952.84, "end": 7957.48, "text": " that are not specific to, you know, one particular modality, you know, it could be audio or whatever.", "tokens": [50600, 300, 366, 406, 2685, 281, 11, 291, 458, 11, 472, 1729, 1072, 1860, 11, 291, 458, 11, 309, 727, 312, 6278, 420, 2035, 13, 50832], "temperature": 0.0, "avg_logprob": -0.20038391993596003, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.005010855384171009}, {"id": 1421, "seek": 794812, "start": 7957.48, "end": 7962.76, "text": " Got it. So what's the story behind this paper? This paper is what is describing one of the one", "tokens": [50832, 5803, 309, 13, 407, 437, 311, 264, 1657, 2261, 341, 3035, 30, 639, 3035, 307, 437, 307, 16141, 472, 295, 264, 472, 51096], "temperature": 0.0, "avg_logprob": -0.20038391993596003, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.005010855384171009}, {"id": 1422, "seek": 794812, "start": 7962.76, "end": 7968.2, "text": " such method? This is this Vicreg method. So this is co-authored. The first author is a student", "tokens": [51096, 1270, 3170, 30, 639, 307, 341, 33316, 3375, 3170, 13, 407, 341, 307, 598, 12, 40198, 2769, 13, 440, 700, 3793, 307, 257, 3107, 51368], "temperature": 0.0, "avg_logprob": -0.20038391993596003, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.005010855384171009}, {"id": 1423, "seek": 794812, "start": 7968.2, "end": 7974.84, "text": " called Adrien Bard, who is a resident PhD student at Fer Paris. He's co-advised by me and Jean Ponce,", "tokens": [51368, 1219, 1999, 27378, 26841, 11, 567, 307, 257, 10832, 14476, 3107, 412, 10728, 8380, 13, 634, 311, 598, 12, 345, 24420, 538, 385, 293, 13854, 430, 26015, 11, 51700], "temperature": 0.0, "avg_logprob": -0.20038391993596003, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.005010855384171009}, {"id": 1424, "seek": 797484, "start": 7975.64, "end": 7980.4400000000005, "text": " who's a professor at Economa Sup\u00e9rieure, also a research director at INRIA.", "tokens": [50404, 567, 311, 257, 8304, 412, 462, 1671, 6440, 9141, 10746, 540, 11, 611, 257, 2132, 5391, 412, 6892, 41125, 13, 50644], "temperature": 0.0, "avg_logprob": -0.30312543869018554, "compression_ratio": 1.453061224489796, "no_speech_prob": 0.003466476686298847}, {"id": 1425, "seek": 797484, "start": 7981.4800000000005, "end": 7986.12, "text": " So this is a wonderful program in France where PhD students can basically do their PhD in", "tokens": [50696, 407, 341, 307, 257, 3715, 1461, 294, 6190, 689, 14476, 1731, 393, 1936, 360, 641, 14476, 294, 50928], "temperature": 0.0, "avg_logprob": -0.30312543869018554, "compression_ratio": 1.453061224489796, "no_speech_prob": 0.003466476686298847}, {"id": 1426, "seek": 797484, "start": 7986.12, "end": 7994.360000000001, "text": " industry. And that's kind of what's happening here. And this paper is a follow-up on this", "tokens": [50928, 3518, 13, 400, 300, 311, 733, 295, 437, 311, 2737, 510, 13, 400, 341, 3035, 307, 257, 1524, 12, 1010, 322, 341, 51340], "temperature": 0.0, "avg_logprob": -0.30312543869018554, "compression_ratio": 1.453061224489796, "no_speech_prob": 0.003466476686298847}, {"id": 1427, "seek": 797484, "start": 7994.360000000001, "end": 8001.96, "text": " Balotuin paper by my former postdoc, now St\u00e9phane Denis, with Lijing and Yorish Bontar and a bunch", "tokens": [51340, 13140, 310, 9445, 3035, 538, 452, 5819, 2183, 39966, 11, 586, 745, 526, 950, 1929, 45351, 11, 365, 441, 1718, 278, 293, 398, 284, 742, 363, 896, 289, 293, 257, 3840, 51720], "temperature": 0.0, "avg_logprob": -0.30312543869018554, "compression_ratio": 1.453061224489796, "no_speech_prob": 0.003466476686298847}, {"id": 1428, "seek": 800196, "start": 8001.96, "end": 8009.0, "text": " of other people from Fer. And one of the main criticism from reviewers is that Vicreg is not", "tokens": [50364, 295, 661, 561, 490, 10728, 13, 400, 472, 295, 264, 2135, 15835, 490, 45837, 307, 300, 33316, 3375, 307, 406, 50716], "temperature": 0.0, "avg_logprob": -0.15237184446685167, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06075979396700859}, {"id": 1429, "seek": 800196, "start": 8009.0, "end": 8016.04, "text": " different enough from Balotuin's. But, you know, my impression is that it's, you know,", "tokens": [50716, 819, 1547, 490, 13140, 310, 9445, 311, 13, 583, 11, 291, 458, 11, 452, 9995, 307, 300, 309, 311, 11, 291, 458, 11, 51068], "temperature": 0.0, "avg_logprob": -0.15237184446685167, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06075979396700859}, {"id": 1430, "seek": 800196, "start": 8016.76, "end": 8022.52, "text": " Balotuin's with a few bugs fixed, essentially. And in the end, this is what people will use.", "tokens": [51104, 13140, 310, 9445, 311, 365, 257, 1326, 15120, 6806, 11, 4476, 13, 400, 294, 264, 917, 11, 341, 307, 437, 561, 486, 764, 13, 51392], "temperature": 0.0, "avg_logprob": -0.15237184446685167, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06075979396700859}, {"id": 1431, "seek": 800196, "start": 8023.08, "end": 8028.84, "text": " Right. So, but, you know, I'm used to stuff that I submit being rejected forward.", "tokens": [51420, 1779, 13, 407, 11, 457, 11, 291, 458, 11, 286, 478, 1143, 281, 1507, 300, 286, 10315, 885, 15749, 2128, 13, 51708], "temperature": 0.0, "avg_logprob": -0.15237184446685167, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.06075979396700859}, {"id": 1432, "seek": 802884, "start": 8028.84, "end": 8032.12, "text": " So it might be rejected and actually exceptionally well cited because people use it.", "tokens": [50364, 407, 309, 1062, 312, 15749, 293, 767, 37807, 731, 30134, 570, 561, 764, 309, 13, 50528], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1433, "seek": 802884, "start": 8032.12, "end": 8034.360000000001, "text": " Well, it's already cited like a bunch of times.", "tokens": [50528, 1042, 11, 309, 311, 1217, 30134, 411, 257, 3840, 295, 1413, 13, 50640], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1434, "seek": 802884, "start": 8034.360000000001, "end": 8040.12, "text": " So, I mean, the question is then to the deeper question about peer review and conferences.", "tokens": [50640, 407, 11, 286, 914, 11, 264, 1168, 307, 550, 281, 264, 7731, 1168, 466, 15108, 3131, 293, 22032, 13, 50928], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1435, "seek": 802884, "start": 8040.12, "end": 8044.2, "text": " I mean, computer science is a field that's kind of unique that the conference is highly prized.", "tokens": [50928, 286, 914, 11, 3820, 3497, 307, 257, 2519, 300, 311, 733, 295, 3845, 300, 264, 7586, 307, 5405, 1790, 11312, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1436, "seek": 802884, "start": 8044.84, "end": 8046.04, "text": " That's one. Right.", "tokens": [51164, 663, 311, 472, 13, 1779, 13, 51224], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1437, "seek": 802884, "start": 8046.04, "end": 8051.08, "text": " And it's interesting because the peer review process there is similar, I suppose, to journals,", "tokens": [51224, 400, 309, 311, 1880, 570, 264, 15108, 3131, 1399, 456, 307, 2531, 11, 286, 7297, 11, 281, 29621, 11, 51476], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1438, "seek": 802884, "start": 8051.08, "end": 8055.64, "text": " but it's accelerated significantly. Well, not significantly, but it goes fast.", "tokens": [51476, 457, 309, 311, 29763, 10591, 13, 1042, 11, 406, 10591, 11, 457, 309, 1709, 2370, 13, 51704], "temperature": 0.0, "avg_logprob": -0.13910250509938887, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.004257456865161657}, {"id": 1439, "seek": 805564, "start": 8056.360000000001, "end": 8061.8, "text": " And it's a nice way to get stuff out quickly, to peer review quickly, go to present it quickly", "tokens": [50400, 400, 309, 311, 257, 1481, 636, 281, 483, 1507, 484, 2661, 11, 281, 15108, 3131, 2661, 11, 352, 281, 1974, 309, 2661, 50672], "temperature": 0.0, "avg_logprob": -0.15538350944845086, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.00312236649915576}, {"id": 1440, "seek": 805564, "start": 8061.8, "end": 8068.200000000001, "text": " to the community. So, not quickly, but quicker. But nevertheless, it has many of the same flaws of", "tokens": [50672, 281, 264, 1768, 13, 407, 11, 406, 2661, 11, 457, 16255, 13, 583, 26924, 11, 309, 575, 867, 295, 264, 912, 27108, 295, 50992], "temperature": 0.0, "avg_logprob": -0.15538350944845086, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.00312236649915576}, {"id": 1441, "seek": 805564, "start": 8068.200000000001, "end": 8072.68, "text": " peer review because it's a limited number of people look at it. There's bias and following,", "tokens": [50992, 15108, 3131, 570, 309, 311, 257, 5567, 1230, 295, 561, 574, 412, 309, 13, 821, 311, 12577, 293, 3480, 11, 51216], "temperature": 0.0, "avg_logprob": -0.15538350944845086, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.00312236649915576}, {"id": 1442, "seek": 805564, "start": 8072.68, "end": 8076.6, "text": " like that if you want to do new ideas, you're going to get pushed back.", "tokens": [51216, 411, 300, 498, 291, 528, 281, 360, 777, 3487, 11, 291, 434, 516, 281, 483, 9152, 646, 13, 51412], "temperature": 0.0, "avg_logprob": -0.15538350944845086, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.00312236649915576}, {"id": 1443, "seek": 805564, "start": 8077.96, "end": 8085.240000000001, "text": " There's self-interested people that kind of can infer who submitted it and kind of, you know,", "tokens": [51480, 821, 311, 2698, 12, 5106, 21885, 561, 300, 733, 295, 393, 13596, 567, 14405, 309, 293, 733, 295, 11, 291, 458, 11, 51844], "temperature": 0.0, "avg_logprob": -0.15538350944845086, "compression_ratio": 1.7213740458015268, "no_speech_prob": 0.00312236649915576}, {"id": 1444, "seek": 808524, "start": 8085.24, "end": 8089.08, "text": " be cranky about it, all that kind of stuff. Yeah. I mean, there's a lot of, you know,", "tokens": [50364, 312, 21263, 88, 466, 309, 11, 439, 300, 733, 295, 1507, 13, 865, 13, 286, 914, 11, 456, 311, 257, 688, 295, 11, 291, 458, 11, 50556], "temperature": 0.0, "avg_logprob": -0.1296580687813137, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.0016473786672577262}, {"id": 1445, "seek": 808524, "start": 8089.08, "end": 8094.12, "text": " social phenomena there. There's one social phenomenon, which is that because the field", "tokens": [50556, 2093, 22004, 456, 13, 821, 311, 472, 2093, 14029, 11, 597, 307, 300, 570, 264, 2519, 50808], "temperature": 0.0, "avg_logprob": -0.1296580687813137, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.0016473786672577262}, {"id": 1446, "seek": 808524, "start": 8094.12, "end": 8099.5599999999995, "text": " has been growing exponentially, the vast majority of people in the field are extremely junior.", "tokens": [50808, 575, 668, 4194, 37330, 11, 264, 8369, 6286, 295, 561, 294, 264, 2519, 366, 4664, 16195, 13, 51080], "temperature": 0.0, "avg_logprob": -0.1296580687813137, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.0016473786672577262}, {"id": 1447, "seek": 808524, "start": 8100.5199999999995, "end": 8105.48, "text": " So, as a consequence, and that's just a consequence of the field growing, right? So,", "tokens": [51128, 407, 11, 382, 257, 18326, 11, 293, 300, 311, 445, 257, 18326, 295, 264, 2519, 4194, 11, 558, 30, 407, 11, 51376], "temperature": 0.0, "avg_logprob": -0.1296580687813137, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.0016473786672577262}, {"id": 1448, "seek": 808524, "start": 8105.48, "end": 8110.36, "text": " as the number of, as the size of the field kind of starts saturating, you will have less of that", "tokens": [51376, 382, 264, 1230, 295, 11, 382, 264, 2744, 295, 264, 2519, 733, 295, 3719, 21160, 990, 11, 291, 486, 362, 1570, 295, 300, 51620], "temperature": 0.0, "avg_logprob": -0.1296580687813137, "compression_ratio": 1.7607843137254902, "no_speech_prob": 0.0016473786672577262}, {"id": 1449, "seek": 811036, "start": 8110.36, "end": 8117.24, "text": " problem of reviewers being very inexperienced. A consequence of this is that, you know,", "tokens": [50364, 1154, 295, 45837, 885, 588, 29961, 610, 47592, 13, 316, 18326, 295, 341, 307, 300, 11, 291, 458, 11, 50708], "temperature": 0.0, "avg_logprob": -0.11025692069012186, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.014010835438966751}, {"id": 1450, "seek": 811036, "start": 8118.28, "end": 8124.2, "text": " young reviewers, I mean, there's a phenomenon which is that reviewers try to make their life", "tokens": [50760, 2037, 45837, 11, 286, 914, 11, 456, 311, 257, 14029, 597, 307, 300, 45837, 853, 281, 652, 641, 993, 51056], "temperature": 0.0, "avg_logprob": -0.11025692069012186, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.014010835438966751}, {"id": 1451, "seek": 811036, "start": 8124.2, "end": 8128.599999999999, "text": " easy. And to make their life easy when reviewing a paper is very simple. You just have to find", "tokens": [51056, 1858, 13, 400, 281, 652, 641, 993, 1858, 562, 19576, 257, 3035, 307, 588, 2199, 13, 509, 445, 362, 281, 915, 51276], "temperature": 0.0, "avg_logprob": -0.11025692069012186, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.014010835438966751}, {"id": 1452, "seek": 811036, "start": 8128.599999999999, "end": 8134.839999999999, "text": " a flaw in the paper, right? So, basically, they see their task as finding flaws in papers. And", "tokens": [51276, 257, 13717, 294, 264, 3035, 11, 558, 30, 407, 11, 1936, 11, 436, 536, 641, 5633, 382, 5006, 27108, 294, 10577, 13, 400, 51588], "temperature": 0.0, "avg_logprob": -0.11025692069012186, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.014010835438966751}, {"id": 1453, "seek": 813484, "start": 8134.84, "end": 8143.56, "text": " most papers have flaws, even the good ones. So, it's easy to do that. Your job is easier as a", "tokens": [50364, 881, 10577, 362, 27108, 11, 754, 264, 665, 2306, 13, 407, 11, 309, 311, 1858, 281, 360, 300, 13, 2260, 1691, 307, 3571, 382, 257, 50800], "temperature": 0.0, "avg_logprob": -0.09232111260442451, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.005719575099647045}, {"id": 1454, "seek": 813484, "start": 8143.56, "end": 8151.0, "text": " reviewer if you just focus on this. But what's important is, like, is there a new idea in that", "tokens": [50800, 3131, 260, 498, 291, 445, 1879, 322, 341, 13, 583, 437, 311, 1021, 307, 11, 411, 11, 307, 456, 257, 777, 1558, 294, 300, 51172], "temperature": 0.0, "avg_logprob": -0.09232111260442451, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.005719575099647045}, {"id": 1455, "seek": 813484, "start": 8151.0, "end": 8156.12, "text": " paper that is likely to influence? It doesn't matter if the experiments are not that great,", "tokens": [51172, 3035, 300, 307, 3700, 281, 6503, 30, 467, 1177, 380, 1871, 498, 264, 12050, 366, 406, 300, 869, 11, 51428], "temperature": 0.0, "avg_logprob": -0.09232111260442451, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.005719575099647045}, {"id": 1456, "seek": 813484, "start": 8156.12, "end": 8164.28, "text": " if the protocol is, you know, so things like that. As long as there is a worthy idea in it,", "tokens": [51428, 498, 264, 10336, 307, 11, 291, 458, 11, 370, 721, 411, 300, 13, 1018, 938, 382, 456, 307, 257, 14829, 1558, 294, 309, 11, 51836], "temperature": 0.0, "avg_logprob": -0.09232111260442451, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.005719575099647045}, {"id": 1457, "seek": 816484, "start": 8165.0, "end": 8170.6, "text": " that will influence the way people think about the problem. Even if they make it better, you know,", "tokens": [50372, 300, 486, 6503, 264, 636, 561, 519, 466, 264, 1154, 13, 2754, 498, 436, 652, 309, 1101, 11, 291, 458, 11, 50652], "temperature": 0.0, "avg_logprob": -0.0950114418478573, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0030206642113626003}, {"id": 1458, "seek": 816484, "start": 8170.6, "end": 8177.64, "text": " eventually, I think that's really what makes a paper useful. And so, this combination of", "tokens": [50652, 4728, 11, 286, 519, 300, 311, 534, 437, 1669, 257, 3035, 4420, 13, 400, 370, 11, 341, 6562, 295, 51004], "temperature": 0.0, "avg_logprob": -0.0950114418478573, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0030206642113626003}, {"id": 1459, "seek": 816484, "start": 8178.2, "end": 8185.08, "text": " social phenomena creates a disease that has plagued, you know, other fields in the past,", "tokens": [51032, 2093, 22004, 7829, 257, 4752, 300, 575, 33756, 5827, 11, 291, 458, 11, 661, 7909, 294, 264, 1791, 11, 51376], "temperature": 0.0, "avg_logprob": -0.0950114418478573, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0030206642113626003}, {"id": 1460, "seek": 816484, "start": 8185.08, "end": 8190.6, "text": " like speech recognition, where basically, you know, people chase numbers on benchmarks.", "tokens": [51376, 411, 6218, 11150, 11, 689, 1936, 11, 291, 458, 11, 561, 15359, 3547, 322, 43751, 13, 51652], "temperature": 0.0, "avg_logprob": -0.0950114418478573, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0030206642113626003}, {"id": 1461, "seek": 819060, "start": 8191.56, "end": 8197.32, "text": " And it's much easier to get a paper accepted if it brings an incremental improvement on a", "tokens": [50412, 400, 309, 311, 709, 3571, 281, 483, 257, 3035, 9035, 498, 309, 5607, 364, 35759, 10444, 322, 257, 50700], "temperature": 0.0, "avg_logprob": -0.11518248558044433, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.016818681731820107}, {"id": 1462, "seek": 819060, "start": 8198.12, "end": 8205.880000000001, "text": " sort of mainstream, well-accepted method or problem. And those are, to me, boring papers.", "tokens": [50740, 1333, 295, 15960, 11, 731, 12, 24870, 292, 3170, 420, 1154, 13, 400, 729, 366, 11, 281, 385, 11, 9989, 10577, 13, 51128], "temperature": 0.0, "avg_logprob": -0.11518248558044433, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.016818681731820107}, {"id": 1463, "seek": 819060, "start": 8205.880000000001, "end": 8211.56, "text": " I mean, they're not useless, right? Because industry, you know, strives on those kind of progress.", "tokens": [51128, 286, 914, 11, 436, 434, 406, 14115, 11, 558, 30, 1436, 3518, 11, 291, 458, 11, 3575, 977, 322, 729, 733, 295, 4205, 13, 51412], "temperature": 0.0, "avg_logprob": -0.11518248558044433, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.016818681731820107}, {"id": 1464, "seek": 819060, "start": 8212.2, "end": 8215.720000000001, "text": " But they're not the ones that I'm interested in, in terms of, like, new concepts and new ideas. So,", "tokens": [51444, 583, 436, 434, 406, 264, 2306, 300, 286, 478, 3102, 294, 11, 294, 2115, 295, 11, 411, 11, 777, 10392, 293, 777, 3487, 13, 407, 11, 51620], "temperature": 0.0, "avg_logprob": -0.11518248558044433, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.016818681731820107}, {"id": 1465, "seek": 821572, "start": 8216.359999999999, "end": 8222.679999999998, "text": " papers that are really trying to strike kind of new advances generally don't make it. Now,", "tokens": [50396, 10577, 300, 366, 534, 1382, 281, 9302, 733, 295, 777, 25297, 5101, 500, 380, 652, 309, 13, 823, 11, 50712], "temperature": 0.0, "avg_logprob": -0.13425355706333128, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.0009395388187840581}, {"id": 1466, "seek": 821572, "start": 8222.679999999998, "end": 8228.039999999999, "text": " thankfully, we have archive. Archive, exactly. And then there's open review type of situations", "tokens": [50712, 27352, 11, 321, 362, 23507, 13, 10984, 488, 11, 2293, 13, 400, 550, 456, 311, 1269, 3131, 2010, 295, 6851, 50980], "temperature": 0.0, "avg_logprob": -0.13425355706333128, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.0009395388187840581}, {"id": 1467, "seek": 821572, "start": 8228.039999999999, "end": 8233.4, "text": " we use. And then, I mean, Twitter is a kind of open review. I'm a huge believer that review should", "tokens": [50980, 321, 764, 13, 400, 550, 11, 286, 914, 11, 5794, 307, 257, 733, 295, 1269, 3131, 13, 286, 478, 257, 2603, 23892, 300, 3131, 820, 51248], "temperature": 0.0, "avg_logprob": -0.13425355706333128, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.0009395388187840581}, {"id": 1468, "seek": 821572, "start": 8233.4, "end": 8239.08, "text": " be done by thousands of people, not two people. I agree. And so, archive, like, do you see a", "tokens": [51248, 312, 1096, 538, 5383, 295, 561, 11, 406, 732, 561, 13, 286, 3986, 13, 400, 370, 11, 23507, 11, 411, 11, 360, 291, 536, 257, 51532], "temperature": 0.0, "avg_logprob": -0.13425355706333128, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.0009395388187840581}, {"id": 1469, "seek": 821572, "start": 8239.08, "end": 8243.88, "text": " future where a lot of really strong papers, it's already the present, but a growing future where", "tokens": [51532, 2027, 689, 257, 688, 295, 534, 2068, 10577, 11, 309, 311, 1217, 264, 1974, 11, 457, 257, 4194, 2027, 689, 51772], "temperature": 0.0, "avg_logprob": -0.13425355706333128, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.0009395388187840581}, {"id": 1470, "seek": 824388, "start": 8243.88, "end": 8252.039999999999, "text": " it'll just be archive. And you're presenting an ongoing continuous conference called Twitter", "tokens": [50364, 309, 603, 445, 312, 23507, 13, 400, 291, 434, 15578, 364, 10452, 10957, 7586, 1219, 5794, 50772], "temperature": 0.0, "avg_logprob": -0.15786474684010382, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.01613953337073326}, {"id": 1471, "seek": 824388, "start": 8252.039999999999, "end": 8259.56, "text": " slash the internet slash archive sanity. Andre just released a new version. So, just not, you know,", "tokens": [50772, 17330, 264, 4705, 17330, 23507, 47892, 13, 20667, 445, 4736, 257, 777, 3037, 13, 407, 11, 445, 406, 11, 291, 458, 11, 51148], "temperature": 0.0, "avg_logprob": -0.15786474684010382, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.01613953337073326}, {"id": 1472, "seek": 824388, "start": 8259.56, "end": 8265.0, "text": " not being so elitist about this particular gating. It's not a question of being elitist or not. It's", "tokens": [51148, 406, 885, 370, 806, 270, 468, 466, 341, 1729, 290, 990, 13, 467, 311, 406, 257, 1168, 295, 885, 806, 270, 468, 420, 406, 13, 467, 311, 51420], "temperature": 0.0, "avg_logprob": -0.15786474684010382, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.01613953337073326}, {"id": 1473, "seek": 824388, "start": 8265.0, "end": 8273.56, "text": " a question of being basically recommendation and zero approvals for people who don't see themselves", "tokens": [51420, 257, 1168, 295, 885, 1936, 11879, 293, 4018, 2075, 19778, 337, 561, 567, 500, 380, 536, 2969, 51848], "temperature": 0.0, "avg_logprob": -0.15786474684010382, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.01613953337073326}, {"id": 1474, "seek": 827356, "start": 8273.56, "end": 8278.6, "text": " having the ability to do so by themselves, right? And so, it saves time, right? If you rely on other", "tokens": [50364, 1419, 264, 3485, 281, 360, 370, 538, 2969, 11, 558, 30, 400, 370, 11, 309, 19155, 565, 11, 558, 30, 759, 291, 10687, 322, 661, 50616], "temperature": 0.0, "avg_logprob": -0.1286868898887334, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.0036385224666446447}, {"id": 1475, "seek": 827356, "start": 8278.6, "end": 8287.0, "text": " people's opinion, and you trust those people or those groups to evaluate a paper for you,", "tokens": [50616, 561, 311, 4800, 11, 293, 291, 3361, 729, 561, 420, 729, 3935, 281, 13059, 257, 3035, 337, 291, 11, 51036], "temperature": 0.0, "avg_logprob": -0.1286868898887334, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.0036385224666446447}, {"id": 1476, "seek": 827356, "start": 8288.76, "end": 8293.24, "text": " that saves you time because, you know, you don't have to, like, scrutinize the paper as much,", "tokens": [51124, 300, 19155, 291, 565, 570, 11, 291, 458, 11, 291, 500, 380, 362, 281, 11, 411, 11, 28949, 259, 1125, 264, 3035, 382, 709, 11, 51348], "temperature": 0.0, "avg_logprob": -0.1286868898887334, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.0036385224666446447}, {"id": 1477, "seek": 827356, "start": 8293.24, "end": 8296.519999999999, "text": " you know, it is brought to your attention. I mean, it's the whole idea of sort of, you know,", "tokens": [51348, 291, 458, 11, 309, 307, 3038, 281, 428, 3202, 13, 286, 914, 11, 309, 311, 264, 1379, 1558, 295, 1333, 295, 11, 291, 458, 11, 51512], "temperature": 0.0, "avg_logprob": -0.1286868898887334, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.0036385224666446447}, {"id": 1478, "seek": 827356, "start": 8296.519999999999, "end": 8302.519999999999, "text": " collective recommender system. So, I actually thought about this a lot, you know, about 10,", "tokens": [51512, 12590, 2748, 260, 1185, 13, 407, 11, 286, 767, 1194, 466, 341, 257, 688, 11, 291, 458, 11, 466, 1266, 11, 51812], "temperature": 0.0, "avg_logprob": -0.1286868898887334, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.0036385224666446447}, {"id": 1479, "seek": 830252, "start": 8302.52, "end": 8309.48, "text": " 15 years ago, because there were discussions at NIPPS and, you know, and we're about to create", "tokens": [50364, 2119, 924, 2057, 11, 570, 456, 645, 11088, 412, 426, 9139, 6273, 293, 11, 291, 458, 11, 293, 321, 434, 466, 281, 1884, 50712], "temperature": 0.0, "avg_logprob": -0.17433544081084582, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01295497640967369}, {"id": 1480, "seek": 830252, "start": 8309.48, "end": 8316.12, "text": " iClear with Yosha Benjo. And so, I wrote a document kind of describing a reviewing system,", "tokens": [50712, 741, 34, 5797, 365, 398, 329, 1641, 3964, 5134, 13, 400, 370, 11, 286, 4114, 257, 4166, 733, 295, 16141, 257, 19576, 1185, 11, 51044], "temperature": 0.0, "avg_logprob": -0.17433544081084582, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01295497640967369}, {"id": 1481, "seek": 830252, "start": 8316.12, "end": 8320.52, "text": " which basically was, you know, you post your paper on some repository, let's say archive,", "tokens": [51044, 597, 1936, 390, 11, 291, 458, 11, 291, 2183, 428, 3035, 322, 512, 25841, 11, 718, 311, 584, 23507, 11, 51264], "temperature": 0.0, "avg_logprob": -0.17433544081084582, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01295497640967369}, {"id": 1482, "seek": 830252, "start": 8320.52, "end": 8327.32, "text": " or now could be open review. And then you can form a reviewing entity, which is equivalent to a", "tokens": [51264, 420, 586, 727, 312, 1269, 3131, 13, 400, 550, 291, 393, 1254, 257, 19576, 13977, 11, 597, 307, 10344, 281, 257, 51604], "temperature": 0.0, "avg_logprob": -0.17433544081084582, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01295497640967369}, {"id": 1483, "seek": 832732, "start": 8327.32, "end": 8334.199999999999, "text": " reviewing board, you know, of a journal or program committee of a conference. You have to", "tokens": [50364, 19576, 3150, 11, 291, 458, 11, 295, 257, 6708, 420, 1461, 7482, 295, 257, 7586, 13, 509, 362, 281, 50708], "temperature": 0.0, "avg_logprob": -0.10928932624527171, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.014170760288834572}, {"id": 1484, "seek": 832732, "start": 8334.199999999999, "end": 8341.72, "text": " list the members. And then that group reviewing entity can choose to review a particular paper", "tokens": [50708, 1329, 264, 2679, 13, 400, 550, 300, 1594, 19576, 13977, 393, 2826, 281, 3131, 257, 1729, 3035, 51084], "temperature": 0.0, "avg_logprob": -0.10928932624527171, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.014170760288834572}, {"id": 1485, "seek": 832732, "start": 8342.44, "end": 8347.0, "text": " spontaneously or not. There is no exclusive relationship anymore between a paper and a", "tokens": [51120, 47632, 420, 406, 13, 821, 307, 572, 13005, 2480, 3602, 1296, 257, 3035, 293, 257, 51348], "temperature": 0.0, "avg_logprob": -0.10928932624527171, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.014170760288834572}, {"id": 1486, "seek": 832732, "start": 8347.0, "end": 8353.8, "text": " venue or reviewing entity. Any reviewing entity can review any paper or may choose not to.", "tokens": [51348, 21645, 420, 19576, 13977, 13, 2639, 19576, 13977, 393, 3131, 604, 3035, 420, 815, 2826, 406, 281, 13, 51688], "temperature": 0.0, "avg_logprob": -0.10928932624527171, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.014170760288834572}, {"id": 1487, "seek": 835380, "start": 8354.759999999998, "end": 8358.199999999999, "text": " And then, you know, give an evaluation. It's not published, not published, it's just an", "tokens": [50412, 400, 550, 11, 291, 458, 11, 976, 364, 13344, 13, 467, 311, 406, 6572, 11, 406, 6572, 11, 309, 311, 445, 364, 50584], "temperature": 0.0, "avg_logprob": -0.17934383609430576, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.0074476138688623905}, {"id": 1488, "seek": 835380, "start": 8358.199999999999, "end": 8363.8, "text": " evaluation and a comment, which would be public, signed by the reviewing entity. And", "tokens": [50584, 13344, 293, 257, 2871, 11, 597, 576, 312, 1908, 11, 8175, 538, 264, 19576, 13977, 13, 400, 50864], "temperature": 0.0, "avg_logprob": -0.17934383609430576, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.0074476138688623905}, {"id": 1489, "seek": 835380, "start": 8364.519999999999, "end": 8367.88, "text": " if it's signed by a reviewing entity, you know, it's one of the members of reviewing entity. So,", "tokens": [50900, 498, 309, 311, 8175, 538, 257, 19576, 13977, 11, 291, 458, 11, 309, 311, 472, 295, 264, 2679, 295, 19576, 13977, 13, 407, 11, 51068], "temperature": 0.0, "avg_logprob": -0.17934383609430576, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.0074476138688623905}, {"id": 1490, "seek": 835380, "start": 8367.88, "end": 8373.88, "text": " if the reviewing entity is, you know, Lex Friedman's, you know, preferred papers, right, you know,", "tokens": [51068, 498, 264, 19576, 13977, 307, 11, 291, 458, 11, 24086, 17605, 1601, 311, 11, 291, 458, 11, 16494, 10577, 11, 558, 11, 291, 458, 11, 51368], "temperature": 0.0, "avg_logprob": -0.17934383609430576, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.0074476138688623905}, {"id": 1491, "seek": 835380, "start": 8373.88, "end": 8378.679999999998, "text": " it's Lex Friedman writing a review. Yes. What, so for me, one, that's a beautiful", "tokens": [51368, 309, 311, 24086, 17605, 1601, 3579, 257, 3131, 13, 1079, 13, 708, 11, 370, 337, 385, 11, 472, 11, 300, 311, 257, 2238, 51608], "temperature": 0.0, "avg_logprob": -0.17934383609430576, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.0074476138688623905}, {"id": 1492, "seek": 837868, "start": 8379.0, "end": 8385.720000000001, "text": " system, I think. But what's in addition to that, it feels like there should be a reputation system", "tokens": [50380, 1185, 11, 286, 519, 13, 583, 437, 311, 294, 4500, 281, 300, 11, 309, 3417, 411, 456, 820, 312, 257, 13061, 1185, 50716], "temperature": 0.0, "avg_logprob": -0.14147858436291033, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.13274413347244263}, {"id": 1493, "seek": 837868, "start": 8385.720000000001, "end": 8390.12, "text": " for the reviewers. Absolutely. For the reviewing entities. Not the reviewers individually.", "tokens": [50716, 337, 264, 45837, 13, 7021, 13, 1171, 264, 19576, 16667, 13, 1726, 264, 45837, 16652, 13, 50936], "temperature": 0.0, "avg_logprob": -0.14147858436291033, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.13274413347244263}, {"id": 1494, "seek": 837868, "start": 8390.12, "end": 8394.12, "text": " The reviewing entities, sure. But even within that, the reviewers too. Because", "tokens": [50936, 440, 19576, 16667, 11, 988, 13, 583, 754, 1951, 300, 11, 264, 45837, 886, 13, 1436, 51136], "temperature": 0.0, "avg_logprob": -0.14147858436291033, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.13274413347244263}, {"id": 1495, "seek": 837868, "start": 8395.720000000001, "end": 8401.0, "text": " there's another thing here. It's not just the reputation. It's an incentive for an individual", "tokens": [51216, 456, 311, 1071, 551, 510, 13, 467, 311, 406, 445, 264, 13061, 13, 467, 311, 364, 22346, 337, 364, 2609, 51480], "temperature": 0.0, "avg_logprob": -0.14147858436291033, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.13274413347244263}, {"id": 1496, "seek": 837868, "start": 8401.0, "end": 8406.12, "text": " person to do great. Right now, in the academic setting, the incentive is kind of", "tokens": [51480, 954, 281, 360, 869, 13, 1779, 586, 11, 294, 264, 7778, 3287, 11, 264, 22346, 307, 733, 295, 51736], "temperature": 0.0, "avg_logprob": -0.14147858436291033, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.13274413347244263}, {"id": 1497, "seek": 840612, "start": 8407.08, "end": 8411.160000000002, "text": " internal, just wanting to do a good job. But honestly, that's not a strong enough incentive", "tokens": [50412, 6920, 11, 445, 7935, 281, 360, 257, 665, 1691, 13, 583, 6095, 11, 300, 311, 406, 257, 2068, 1547, 22346, 50616], "temperature": 0.0, "avg_logprob": -0.116020955959288, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0019264192087575793}, {"id": 1498, "seek": 840612, "start": 8411.160000000002, "end": 8415.880000000001, "text": " to do a really good job at reading a paper and finding the beautiful amidst the mistakes and", "tokens": [50616, 281, 360, 257, 534, 665, 1691, 412, 3760, 257, 3035, 293, 5006, 264, 2238, 30153, 372, 264, 8038, 293, 50852], "temperature": 0.0, "avg_logprob": -0.116020955959288, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0019264192087575793}, {"id": 1499, "seek": 840612, "start": 8415.880000000001, "end": 8420.68, "text": " the flaws and all that kind of stuff. Right. Like, if you're the person that first discovered", "tokens": [50852, 264, 27108, 293, 439, 300, 733, 295, 1507, 13, 1779, 13, 1743, 11, 498, 291, 434, 264, 954, 300, 700, 6941, 51092], "temperature": 0.0, "avg_logprob": -0.116020955959288, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0019264192087575793}, {"id": 1500, "seek": 840612, "start": 8420.68, "end": 8427.240000000002, "text": " a powerful paper, and you get to be proud of that discovery, then that gives a huge incentive to", "tokens": [51092, 257, 4005, 3035, 11, 293, 291, 483, 281, 312, 4570, 295, 300, 12114, 11, 550, 300, 2709, 257, 2603, 22346, 281, 51420], "temperature": 0.0, "avg_logprob": -0.116020955959288, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0019264192087575793}, {"id": 1501, "seek": 840612, "start": 8427.240000000002, "end": 8431.560000000001, "text": " you. That's, that's a big part of my proposal. Actually, I described that as, you know, if,", "tokens": [51420, 291, 13, 663, 311, 11, 300, 311, 257, 955, 644, 295, 452, 11494, 13, 5135, 11, 286, 7619, 300, 382, 11, 291, 458, 11, 498, 11, 51636], "temperature": 0.0, "avg_logprob": -0.116020955959288, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0019264192087575793}, {"id": 1502, "seek": 843156, "start": 8431.64, "end": 8439.0, "text": " if your evaluation of papers is predictive of future success, then your reputation should", "tokens": [50368, 498, 428, 13344, 295, 10577, 307, 35521, 295, 2027, 2245, 11, 550, 428, 13061, 820, 50736], "temperature": 0.0, "avg_logprob": -0.1246401998731825, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.002978901844471693}, {"id": 1503, "seek": 843156, "start": 8439.0, "end": 8446.68, "text": " go up as a reviewing entity. So yeah, exactly. I mean, I even had a master's student who was a", "tokens": [50736, 352, 493, 382, 257, 19576, 13977, 13, 407, 1338, 11, 2293, 13, 286, 914, 11, 286, 754, 632, 257, 4505, 311, 3107, 567, 390, 257, 51120], "temperature": 0.0, "avg_logprob": -0.1246401998731825, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.002978901844471693}, {"id": 1504, "seek": 843156, "start": 8447.24, "end": 8451.72, "text": " master's student in library science and computer science, actually kind of work out exactly", "tokens": [51148, 4505, 311, 3107, 294, 6405, 3497, 293, 3820, 3497, 11, 767, 733, 295, 589, 484, 2293, 51372], "temperature": 0.0, "avg_logprob": -0.1246401998731825, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.002978901844471693}, {"id": 1505, "seek": 843156, "start": 8452.279999999999, "end": 8456.68, "text": " how that should work with formulas and everything. But so in terms of implementation,", "tokens": [51400, 577, 300, 820, 589, 365, 30546, 293, 1203, 13, 583, 370, 294, 2115, 295, 11420, 11, 51620], "temperature": 0.0, "avg_logprob": -0.1246401998731825, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.002978901844471693}, {"id": 1506, "seek": 843156, "start": 8456.68, "end": 8460.119999999999, "text": " do you think that's something that's doable? I mean, I've been sort of, you know, talking about", "tokens": [51620, 360, 291, 519, 300, 311, 746, 300, 311, 41183, 30, 286, 914, 11, 286, 600, 668, 1333, 295, 11, 291, 458, 11, 1417, 466, 51792], "temperature": 0.0, "avg_logprob": -0.1246401998731825, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.002978901844471693}, {"id": 1507, "seek": 846012, "start": 8460.2, "end": 8465.880000000001, "text": " this to sort of various people like, you know, Andrew McCallum, who started Open Review. And", "tokens": [50368, 341, 281, 1333, 295, 3683, 561, 411, 11, 291, 458, 11, 10110, 12061, 336, 449, 11, 567, 1409, 7238, 19954, 13, 400, 50652], "temperature": 0.0, "avg_logprob": -0.09244458537456418, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.010617521591484547}, {"id": 1508, "seek": 846012, "start": 8465.880000000001, "end": 8470.44, "text": " the reason why we picked Open Review for iClear initially, even though it was very early for them,", "tokens": [50652, 264, 1778, 983, 321, 6183, 7238, 19954, 337, 741, 34, 5797, 9105, 11, 754, 1673, 309, 390, 588, 2440, 337, 552, 11, 50880], "temperature": 0.0, "avg_logprob": -0.09244458537456418, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.010617521591484547}, {"id": 1509, "seek": 846012, "start": 8471.320000000002, "end": 8475.720000000001, "text": " is because my hope was that iClear, it was eventually going to kind of", "tokens": [50924, 307, 570, 452, 1454, 390, 300, 741, 34, 5797, 11, 309, 390, 4728, 516, 281, 733, 295, 51144], "temperature": 0.0, "avg_logprob": -0.09244458537456418, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.010617521591484547}, {"id": 1510, "seek": 846012, "start": 8476.6, "end": 8483.320000000002, "text": " inaugurate this type of system. So iClear kept the idea of Open Reviews. So whether reviews are,", "tokens": [51188, 23541, 33144, 341, 2010, 295, 1185, 13, 407, 741, 34, 5797, 4305, 264, 1558, 295, 7238, 19954, 82, 13, 407, 1968, 10229, 366, 11, 51524], "temperature": 0.0, "avg_logprob": -0.09244458537456418, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.010617521591484547}, {"id": 1511, "seek": 846012, "start": 8483.320000000002, "end": 8489.160000000002, "text": " you know, published with a paper, which I think is very useful. But in many ways, that's kind of", "tokens": [51524, 291, 458, 11, 6572, 365, 257, 3035, 11, 597, 286, 519, 307, 588, 4420, 13, 583, 294, 867, 2098, 11, 300, 311, 733, 295, 51816], "temperature": 0.0, "avg_logprob": -0.09244458537456418, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.010617521591484547}, {"id": 1512, "seek": 848916, "start": 8489.16, "end": 8495.56, "text": " reverted to kind of more of a conventional type conferences for everything else. And that, I mean,", "tokens": [50364, 319, 18537, 281, 733, 295, 544, 295, 257, 16011, 2010, 22032, 337, 1203, 1646, 13, 400, 300, 11, 286, 914, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12914832738729623, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013197544030845165}, {"id": 1513, "seek": 848916, "start": 8496.76, "end": 8504.039999999999, "text": " I don't run iClear, I'm just the president of the foundation. But, you know, people who run it", "tokens": [50744, 286, 500, 380, 1190, 741, 34, 5797, 11, 286, 478, 445, 264, 3868, 295, 264, 7030, 13, 583, 11, 291, 458, 11, 561, 567, 1190, 309, 51108], "temperature": 0.0, "avg_logprob": -0.12914832738729623, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013197544030845165}, {"id": 1514, "seek": 848916, "start": 8504.039999999999, "end": 8507.8, "text": " should make decisions about how to run it. And I'm not going to tell them, because they are", "tokens": [51108, 820, 652, 5327, 466, 577, 281, 1190, 309, 13, 400, 286, 478, 406, 516, 281, 980, 552, 11, 570, 436, 366, 51296], "temperature": 0.0, "avg_logprob": -0.12914832738729623, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013197544030845165}, {"id": 1515, "seek": 848916, "start": 8507.8, "end": 8513.88, "text": " volunteers. And I'm really thankful that they do that. So, but I'm saddened by the fact that we're", "tokens": [51296, 14352, 13, 400, 286, 478, 534, 13611, 300, 436, 360, 300, 13, 407, 11, 457, 286, 478, 4227, 1556, 292, 538, 264, 1186, 300, 321, 434, 51600], "temperature": 0.0, "avg_logprob": -0.12914832738729623, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013197544030845165}, {"id": 1516, "seek": 851388, "start": 8513.88, "end": 8521.24, "text": " not being innovative enough. Yeah, me too. I hope that changes. Yeah. Because the communication", "tokens": [50364, 406, 885, 12999, 1547, 13, 865, 11, 385, 886, 13, 286, 1454, 300, 2962, 13, 865, 13, 1436, 264, 6101, 50732], "temperature": 0.0, "avg_logprob": -0.11799291385117397, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.01063940767198801}, {"id": 1517, "seek": 851388, "start": 8521.24, "end": 8527.56, "text": " science broadly, but communication, computer science ideas is how you make those ideas have", "tokens": [50732, 3497, 19511, 11, 457, 6101, 11, 3820, 3497, 3487, 307, 577, 291, 652, 729, 3487, 362, 51048], "temperature": 0.0, "avg_logprob": -0.11799291385117397, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.01063940767198801}, {"id": 1518, "seek": 851388, "start": 8527.56, "end": 8534.039999999999, "text": " impact, I think. Yeah. And I think, you know, a lot of this is because people have in their minds", "tokens": [51048, 2712, 11, 286, 519, 13, 865, 13, 400, 286, 519, 11, 291, 458, 11, 257, 688, 295, 341, 307, 570, 561, 362, 294, 641, 9634, 51372], "temperature": 0.0, "avg_logprob": -0.11799291385117397, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.01063940767198801}, {"id": 1519, "seek": 851388, "start": 8534.039999999999, "end": 8541.64, "text": " kind of an objective, which is, you know, fairness for authors, and the ability to count points,", "tokens": [51372, 733, 295, 364, 10024, 11, 597, 307, 11, 291, 458, 11, 29765, 337, 16552, 11, 293, 264, 3485, 281, 1207, 2793, 11, 51752], "temperature": 0.0, "avg_logprob": -0.11799291385117397, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.01063940767198801}, {"id": 1520, "seek": 854164, "start": 8541.64, "end": 8548.039999999999, "text": " basically, and give credits accurately. But that comes at the expense of the progress of science.", "tokens": [50364, 1936, 11, 293, 976, 16816, 20095, 13, 583, 300, 1487, 412, 264, 18406, 295, 264, 4205, 295, 3497, 13, 50684], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1521, "seek": 854164, "start": 8548.68, "end": 8551.32, "text": " So to some extent, we're slowing down the progress of science.", "tokens": [50716, 407, 281, 512, 8396, 11, 321, 434, 26958, 760, 264, 4205, 295, 3497, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1522, "seek": 854164, "start": 8552.039999999999, "end": 8554.279999999999, "text": " And are we actually achieving fairness?", "tokens": [50884, 400, 366, 321, 767, 19626, 29765, 30, 50996], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1523, "seek": 854164, "start": 8554.279999999999, "end": 8558.519999999999, "text": " And we're not achieving fairness, you know, we still have biases, you know, we're doing,", "tokens": [50996, 400, 321, 434, 406, 19626, 29765, 11, 291, 458, 11, 321, 920, 362, 32152, 11, 291, 458, 11, 321, 434, 884, 11, 51208], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1524, "seek": 854164, "start": 8558.519999999999, "end": 8565.0, "text": " you know, a double blind review, but, you know, the biases are still there, there are different", "tokens": [51208, 291, 458, 11, 257, 3834, 6865, 3131, 11, 457, 11, 291, 458, 11, 264, 32152, 366, 920, 456, 11, 456, 366, 819, 51532], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1525, "seek": 854164, "start": 8565.0, "end": 8570.84, "text": " kinds of biases. You write that the phenomenon of emergence, collective behavior exhibited by", "tokens": [51532, 3685, 295, 32152, 13, 509, 2464, 300, 264, 14029, 295, 36211, 11, 12590, 5223, 49446, 538, 51824], "temperature": 0.0, "avg_logprob": -0.1372105782492119, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.008311189711093903}, {"id": 1526, "seek": 857084, "start": 8570.92, "end": 8576.44, "text": " large collection of simple elements in interaction is one of the things that got you into neural", "tokens": [50368, 2416, 5765, 295, 2199, 4959, 294, 9285, 307, 472, 295, 264, 721, 300, 658, 291, 666, 18161, 50644], "temperature": 0.0, "avg_logprob": -0.1058582670233223, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0027958026621490717}, {"id": 1527, "seek": 857084, "start": 8576.44, "end": 8582.84, "text": " nets in the first place. I love cellular automata. I love simple interacting elements and the things", "tokens": [50644, 36170, 294, 264, 700, 1081, 13, 286, 959, 29267, 3553, 3274, 13, 286, 959, 2199, 18017, 4959, 293, 264, 721, 50964], "temperature": 0.0, "avg_logprob": -0.1058582670233223, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0027958026621490717}, {"id": 1528, "seek": 857084, "start": 8582.84, "end": 8588.68, "text": " that emerge from them. Do you think we understand how complex systems can emerge from such simple", "tokens": [50964, 300, 21511, 490, 552, 13, 1144, 291, 519, 321, 1223, 577, 3997, 3652, 393, 21511, 490, 1270, 2199, 51256], "temperature": 0.0, "avg_logprob": -0.1058582670233223, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0027958026621490717}, {"id": 1529, "seek": 857084, "start": 8588.68, "end": 8593.8, "text": " components that interact simply? No, we don't. It's a big mystery. Also, it's a mystery for", "tokens": [51256, 6677, 300, 4648, 2935, 30, 883, 11, 321, 500, 380, 13, 467, 311, 257, 955, 11422, 13, 2743, 11, 309, 311, 257, 11422, 337, 51512], "temperature": 0.0, "avg_logprob": -0.1058582670233223, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0027958026621490717}, {"id": 1530, "seek": 859380, "start": 8593.8, "end": 8602.199999999999, "text": " physicists, it's a mystery for biologists. You know, how is it that the universe around us seems", "tokens": [50364, 48716, 11, 309, 311, 257, 11422, 337, 3228, 12256, 13, 509, 458, 11, 577, 307, 309, 300, 264, 6445, 926, 505, 2544, 50784], "temperature": 0.0, "avg_logprob": -0.10581893652257784, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.006230916827917099}, {"id": 1531, "seek": 859380, "start": 8602.199999999999, "end": 8608.279999999999, "text": " to be increasing in complexity and not decreasing? I mean, that is a kind of curious property of", "tokens": [50784, 281, 312, 5662, 294, 14024, 293, 406, 23223, 30, 286, 914, 11, 300, 307, 257, 733, 295, 6369, 4707, 295, 51088], "temperature": 0.0, "avg_logprob": -0.10581893652257784, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.006230916827917099}, {"id": 1532, "seek": 859380, "start": 8609.16, "end": 8615.88, "text": " physics that despite the second law of thermodynamics, we seem to be, you know, evolution and learning", "tokens": [51132, 10649, 300, 7228, 264, 1150, 2101, 295, 8810, 35483, 11, 321, 1643, 281, 312, 11, 291, 458, 11, 9303, 293, 2539, 51468], "temperature": 0.0, "avg_logprob": -0.10581893652257784, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.006230916827917099}, {"id": 1533, "seek": 861588, "start": 8615.88, "end": 8624.039999999999, "text": " and et cetera seems to be kind of at least locally to increase complexity and not decrease it. So,", "tokens": [50364, 293, 1030, 11458, 2544, 281, 312, 733, 295, 412, 1935, 16143, 281, 3488, 14024, 293, 406, 11514, 309, 13, 407, 11, 50772], "temperature": 0.0, "avg_logprob": -0.16929998397827148, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.004674737807363272}, {"id": 1534, "seek": 861588, "start": 8624.039999999999, "end": 8628.359999999999, "text": " perhaps the ultimate purpose of the universe is to just get more complex.", "tokens": [50772, 4317, 264, 9705, 4334, 295, 264, 6445, 307, 281, 445, 483, 544, 3997, 13, 50988], "temperature": 0.0, "avg_logprob": -0.16929998397827148, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.004674737807363272}, {"id": 1535, "seek": 861588, "start": 8629.0, "end": 8637.08, "text": " Have these, I mean, small pockets of beautiful complexity. Does that, to sell your time under", "tokens": [51020, 3560, 613, 11, 286, 914, 11, 1359, 16491, 295, 2238, 14024, 13, 4402, 300, 11, 281, 3607, 428, 565, 833, 51424], "temperature": 0.0, "avg_logprob": -0.16929998397827148, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.004674737807363272}, {"id": 1536, "seek": 861588, "start": 8637.08, "end": 8644.039999999999, "text": " these kinds of emergence and complex systems give you some intuition or guide your understanding", "tokens": [51424, 613, 3685, 295, 36211, 293, 3997, 3652, 976, 291, 512, 24002, 420, 5934, 428, 3701, 51772], "temperature": 0.0, "avg_logprob": -0.16929998397827148, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.004674737807363272}, {"id": 1537, "seek": 864404, "start": 8644.12, "end": 8648.76, "text": " of machine learning systems and neural networks and so on? Are these for you right now disparate", "tokens": [50368, 295, 3479, 2539, 3652, 293, 18161, 9590, 293, 370, 322, 30, 2014, 613, 337, 291, 558, 586, 14548, 473, 50600], "temperature": 0.0, "avg_logprob": -0.1470626221985376, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.020301861688494682}, {"id": 1538, "seek": 864404, "start": 8648.76, "end": 8655.480000000001, "text": " concepts? Well, it got me into it. You know, I discovered the existence of the perceptron", "tokens": [50600, 10392, 30, 1042, 11, 309, 658, 385, 666, 309, 13, 509, 458, 11, 286, 6941, 264, 9123, 295, 264, 43276, 2044, 50936], "temperature": 0.0, "avg_logprob": -0.1470626221985376, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.020301861688494682}, {"id": 1539, "seek": 864404, "start": 8655.480000000001, "end": 8661.640000000001, "text": " when I was a college student by reading a good book. It was a debate between Chomsky and Piaget", "tokens": [50936, 562, 286, 390, 257, 3859, 3107, 538, 3760, 257, 665, 1446, 13, 467, 390, 257, 7958, 1296, 761, 4785, 4133, 293, 17741, 559, 302, 51244], "temperature": 0.0, "avg_logprob": -0.1470626221985376, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.020301861688494682}, {"id": 1540, "seek": 864404, "start": 8661.640000000001, "end": 8667.160000000002, "text": " and Seymour Papert from MIT who was kind of singing the praise of the perceptron in that", "tokens": [51244, 293, 1100, 4199, 396, 15919, 911, 490, 13100, 567, 390, 733, 295, 6726, 264, 13286, 295, 264, 43276, 2044, 294, 300, 51520], "temperature": 0.0, "avg_logprob": -0.1470626221985376, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.020301861688494682}, {"id": 1541, "seek": 864404, "start": 8667.160000000002, "end": 8671.320000000002, "text": " book. And the first time I heard about the running machine, right? So, I started digging the literature", "tokens": [51520, 1446, 13, 400, 264, 700, 565, 286, 2198, 466, 264, 2614, 3479, 11, 558, 30, 407, 11, 286, 1409, 17343, 264, 10394, 51728], "temperature": 0.0, "avg_logprob": -0.1470626221985376, "compression_ratio": 1.643598615916955, "no_speech_prob": 0.020301861688494682}, {"id": 1542, "seek": 867132, "start": 8671.32, "end": 8677.8, "text": " and I found those books which were basically transcription of, you know, workshops or conferences", "tokens": [50364, 293, 286, 1352, 729, 3642, 597, 645, 1936, 35288, 295, 11, 291, 458, 11, 19162, 420, 22032, 50688], "temperature": 0.0, "avg_logprob": -0.11504446941873302, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.007850047200918198}, {"id": 1543, "seek": 867132, "start": 8678.6, "end": 8684.52, "text": " from the 50s and 60s about self-organizing systems. So, there was a series of conferences", "tokens": [50728, 490, 264, 2625, 82, 293, 4060, 82, 466, 2698, 12, 12372, 3319, 3652, 13, 407, 11, 456, 390, 257, 2638, 295, 22032, 51024], "temperature": 0.0, "avg_logprob": -0.11504446941873302, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.007850047200918198}, {"id": 1544, "seek": 867132, "start": 8684.52, "end": 8690.36, "text": " on self-organizing systems and these books on this. Some of them are, you can actually get them at the", "tokens": [51024, 322, 2698, 12, 12372, 3319, 3652, 293, 613, 3642, 322, 341, 13, 2188, 295, 552, 366, 11, 291, 393, 767, 483, 552, 412, 264, 51316], "temperature": 0.0, "avg_logprob": -0.11504446941873302, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.007850047200918198}, {"id": 1545, "seek": 867132, "start": 8690.36, "end": 8697.64, "text": " Internet Archive, you know, the digital version. And there are like fascinating articles in there", "tokens": [51316, 7703, 10984, 488, 11, 291, 458, 11, 264, 4562, 3037, 13, 400, 456, 366, 411, 10343, 11290, 294, 456, 51680], "temperature": 0.0, "avg_logprob": -0.11504446941873302, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.007850047200918198}, {"id": 1546, "seek": 869764, "start": 8697.64, "end": 8703.96, "text": " by, there's a guy whose name has been largely forgotten, Heinz von F\u00f6rster. He's a German", "tokens": [50364, 538, 11, 456, 311, 257, 2146, 6104, 1315, 575, 668, 11611, 11832, 11, 32789, 89, 2957, 20665, 3120, 13, 634, 311, 257, 6521, 50680], "temperature": 0.0, "avg_logprob": -0.21407373987063014, "compression_ratio": 1.4609375, "no_speech_prob": 0.00282108411192894}, {"id": 1547, "seek": 869764, "start": 8703.96, "end": 8711.56, "text": " physicist who emigrated to the US and worked on self-organizing systems in the 50s. And in the", "tokens": [50680, 42466, 567, 846, 328, 5468, 281, 264, 2546, 293, 2732, 322, 2698, 12, 12372, 3319, 3652, 294, 264, 2625, 82, 13, 400, 294, 264, 51060], "temperature": 0.0, "avg_logprob": -0.21407373987063014, "compression_ratio": 1.4609375, "no_speech_prob": 0.00282108411192894}, {"id": 1548, "seek": 869764, "start": 8711.56, "end": 8716.68, "text": " 60s, he created at the University of Illinois, Japan, Japan, he created the biological computer", "tokens": [51060, 4060, 82, 11, 415, 2942, 412, 264, 3535, 295, 17508, 11, 3367, 11, 3367, 11, 415, 2942, 264, 13910, 3820, 51316], "temperature": 0.0, "avg_logprob": -0.21407373987063014, "compression_ratio": 1.4609375, "no_speech_prob": 0.00282108411192894}, {"id": 1549, "seek": 869764, "start": 8716.68, "end": 8722.519999999999, "text": " laboratory, VCL, which was, you know, all about neural nets. Unfortunately, that was kind of", "tokens": [51316, 16523, 11, 691, 22458, 11, 597, 390, 11, 291, 458, 11, 439, 466, 18161, 36170, 13, 8590, 11, 300, 390, 733, 295, 51608], "temperature": 0.0, "avg_logprob": -0.21407373987063014, "compression_ratio": 1.4609375, "no_speech_prob": 0.00282108411192894}, {"id": 1550, "seek": 872252, "start": 8722.52, "end": 8727.640000000001, "text": " towards the end of the popularity of neural nets. So, that lab never kind of strived very much.", "tokens": [50364, 3030, 264, 917, 295, 264, 19301, 295, 18161, 36170, 13, 407, 11, 300, 2715, 1128, 733, 295, 3575, 937, 588, 709, 13, 50620], "temperature": 0.0, "avg_logprob": -0.1148262336605885, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.02328765019774437}, {"id": 1551, "seek": 872252, "start": 8727.640000000001, "end": 8733.32, "text": " But he wrote a bunch of papers about self-organization and about the mystery of self-organization.", "tokens": [50620, 583, 415, 4114, 257, 3840, 295, 10577, 466, 2698, 12, 12372, 2144, 293, 466, 264, 11422, 295, 2698, 12, 12372, 2144, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1148262336605885, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.02328765019774437}, {"id": 1552, "seek": 872252, "start": 8733.32, "end": 8738.76, "text": " An example he has is, you take, imagine you are in space, there's no gravity. You have a big box", "tokens": [50904, 1107, 1365, 415, 575, 307, 11, 291, 747, 11, 3811, 291, 366, 294, 1901, 11, 456, 311, 572, 12110, 13, 509, 362, 257, 955, 2424, 51176], "temperature": 0.0, "avg_logprob": -0.1148262336605885, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.02328765019774437}, {"id": 1553, "seek": 872252, "start": 8738.76, "end": 8745.4, "text": " with magnets in it, okay? You know, kind of rectangular magnets with north pole on one end,", "tokens": [51176, 365, 33022, 294, 309, 11, 1392, 30, 509, 458, 11, 733, 295, 31167, 33022, 365, 6830, 13208, 322, 472, 917, 11, 51508], "temperature": 0.0, "avg_logprob": -0.1148262336605885, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.02328765019774437}, {"id": 1554, "seek": 872252, "start": 8745.4, "end": 8749.640000000001, "text": " south pole on the other end. You shake the box gently and the magnets will kind of stick to", "tokens": [51508, 7377, 13208, 322, 264, 661, 917, 13, 509, 10283, 264, 2424, 13073, 293, 264, 33022, 486, 733, 295, 2897, 281, 51720], "temperature": 0.0, "avg_logprob": -0.1148262336605885, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.02328765019774437}, {"id": 1555, "seek": 874964, "start": 8749.64, "end": 8755.32, "text": " themselves and probably form like complex structure, you know, spontaneously. You know,", "tokens": [50364, 2969, 293, 1391, 1254, 411, 3997, 3877, 11, 291, 458, 11, 47632, 13, 509, 458, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1232649564743042, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.0020177578553557396}, {"id": 1556, "seek": 874964, "start": 8755.32, "end": 8758.519999999999, "text": " that could be an example of self-organization. But, you know, you have lots of example, neural", "tokens": [50648, 300, 727, 312, 364, 1365, 295, 2698, 12, 12372, 2144, 13, 583, 11, 291, 458, 11, 291, 362, 3195, 295, 1365, 11, 18161, 50808], "temperature": 0.0, "avg_logprob": -0.1232649564743042, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.0020177578553557396}, {"id": 1557, "seek": 874964, "start": 8758.519999999999, "end": 8764.519999999999, "text": " nets are an example of self-organization to, you know, in many respects. And it's a bit of a mystery,", "tokens": [50808, 36170, 366, 364, 1365, 295, 2698, 12, 12372, 2144, 281, 11, 291, 458, 11, 294, 867, 24126, 13, 400, 309, 311, 257, 857, 295, 257, 11422, 11, 51108], "temperature": 0.0, "avg_logprob": -0.1232649564743042, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.0020177578553557396}, {"id": 1558, "seek": 874964, "start": 8765.56, "end": 8771.08, "text": " you know, how, like, what is possible with this? You know, pattern formation in physical systems,", "tokens": [51160, 291, 458, 11, 577, 11, 411, 11, 437, 307, 1944, 365, 341, 30, 509, 458, 11, 5102, 11723, 294, 4001, 3652, 11, 51436], "temperature": 0.0, "avg_logprob": -0.1232649564743042, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.0020177578553557396}, {"id": 1559, "seek": 874964, "start": 8771.8, "end": 8776.439999999999, "text": " in chaotic system and things like that, you know, the emergence of life, you know, things", "tokens": [51472, 294, 27013, 1185, 293, 721, 411, 300, 11, 291, 458, 11, 264, 36211, 295, 993, 11, 291, 458, 11, 721, 51704], "temperature": 0.0, "avg_logprob": -0.1232649564743042, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.0020177578553557396}, {"id": 1560, "seek": 877644, "start": 8776.44, "end": 8782.44, "text": " like that. So, you know, how does that happen? So, it's a big puzzle for physicists as well.", "tokens": [50364, 411, 300, 13, 407, 11, 291, 458, 11, 577, 775, 300, 1051, 30, 407, 11, 309, 311, 257, 955, 12805, 337, 48716, 382, 731, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09614217409523584, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.02794177457690239}, {"id": 1561, "seek": 877644, "start": 8782.44, "end": 8789.880000000001, "text": " It feels like understanding this, the mathematics of emergence in some constrained situations might", "tokens": [50664, 467, 3417, 411, 3701, 341, 11, 264, 18666, 295, 36211, 294, 512, 38901, 6851, 1062, 51036], "temperature": 0.0, "avg_logprob": -0.09614217409523584, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.02794177457690239}, {"id": 1562, "seek": 877644, "start": 8789.880000000001, "end": 8797.640000000001, "text": " help us create intelligence. Like, help us add a little spice to the systems because you seem to", "tokens": [51036, 854, 505, 1884, 7599, 13, 1743, 11, 854, 505, 909, 257, 707, 19436, 281, 264, 3652, 570, 291, 1643, 281, 51424], "temperature": 0.0, "avg_logprob": -0.09614217409523584, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.02794177457690239}, {"id": 1563, "seek": 877644, "start": 8797.640000000001, "end": 8804.84, "text": " be able to, in complex systems with emergence, to be able to get a lot from little. And so,", "tokens": [51424, 312, 1075, 281, 11, 294, 3997, 3652, 365, 36211, 11, 281, 312, 1075, 281, 483, 257, 688, 490, 707, 13, 400, 370, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09614217409523584, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.02794177457690239}, {"id": 1564, "seek": 880484, "start": 8804.92, "end": 8811.960000000001, "text": " that seems like a shortcut to get big leaps in performance. But there's a missing", "tokens": [50368, 300, 2544, 411, 257, 24822, 281, 483, 955, 476, 2382, 294, 3389, 13, 583, 456, 311, 257, 5361, 50720], "temperature": 0.0, "avg_logprob": -0.13867999661353328, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00031974149169400334}, {"id": 1565, "seek": 880484, "start": 8811.960000000001, "end": 8820.6, "text": " concept that we don't have. And it's something also I've been fascinated by since my undergrad days.", "tokens": [50720, 3410, 300, 321, 500, 380, 362, 13, 400, 309, 311, 746, 611, 286, 600, 668, 24597, 538, 1670, 452, 14295, 1708, 13, 51152], "temperature": 0.0, "avg_logprob": -0.13867999661353328, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00031974149169400334}, {"id": 1566, "seek": 880484, "start": 8820.6, "end": 8827.08, "text": " And it's how you measure complexity, right? So, we don't actually have good ways of measuring or at", "tokens": [51152, 400, 309, 311, 577, 291, 3481, 14024, 11, 558, 30, 407, 11, 321, 500, 380, 767, 362, 665, 2098, 295, 13389, 420, 412, 51476], "temperature": 0.0, "avg_logprob": -0.13867999661353328, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00031974149169400334}, {"id": 1567, "seek": 880484, "start": 8827.08, "end": 8831.960000000001, "text": " least we don't have good ways of interpreting the measures that we have at our disposal. Like,", "tokens": [51476, 1935, 321, 500, 380, 362, 665, 2098, 295, 37395, 264, 8000, 300, 321, 362, 412, 527, 26400, 13, 1743, 11, 51720], "temperature": 0.0, "avg_logprob": -0.13867999661353328, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00031974149169400334}, {"id": 1568, "seek": 883196, "start": 8831.96, "end": 8835.64, "text": " how do you measure the complexity of something, right? So, there's all those things, you know,", "tokens": [50364, 577, 360, 291, 3481, 264, 14024, 295, 746, 11, 558, 30, 407, 11, 456, 311, 439, 729, 721, 11, 291, 458, 11, 50548], "temperature": 0.0, "avg_logprob": -0.13982455469980962, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.0009631038992665708}, {"id": 1569, "seek": 883196, "start": 8835.64, "end": 8839.96, "text": " like, you know, Karmogorov, Chaitin, Solomonov complexity of, you know, the length of the", "tokens": [50548, 411, 11, 291, 458, 11, 591, 4452, 664, 284, 5179, 11, 761, 1001, 259, 11, 32209, 5179, 14024, 295, 11, 291, 458, 11, 264, 4641, 295, 264, 50764], "temperature": 0.0, "avg_logprob": -0.13982455469980962, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.0009631038992665708}, {"id": 1570, "seek": 883196, "start": 8839.96, "end": 8844.599999999999, "text": " shortest program that would generate a bit string can be thought of as the complexity of that bit", "tokens": [50764, 31875, 1461, 300, 576, 8460, 257, 857, 6798, 393, 312, 1194, 295, 382, 264, 14024, 295, 300, 857, 50996], "temperature": 0.0, "avg_logprob": -0.13982455469980962, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.0009631038992665708}, {"id": 1571, "seek": 883196, "start": 8844.599999999999, "end": 8852.439999999999, "text": " string. I've been fascinated by that concept. The problem with that is that that complexity is", "tokens": [50996, 6798, 13, 286, 600, 668, 24597, 538, 300, 3410, 13, 440, 1154, 365, 300, 307, 300, 300, 14024, 307, 51388], "temperature": 0.0, "avg_logprob": -0.13982455469980962, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.0009631038992665708}, {"id": 1572, "seek": 883196, "start": 8852.439999999999, "end": 8858.759999999998, "text": " defined up to a constant, which can be very large. There are similar concepts that are derived from,", "tokens": [51388, 7642, 493, 281, 257, 5754, 11, 597, 393, 312, 588, 2416, 13, 821, 366, 2531, 10392, 300, 366, 18949, 490, 11, 51704], "temperature": 0.0, "avg_logprob": -0.13982455469980962, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.0009631038992665708}, {"id": 1573, "seek": 885876, "start": 8858.84, "end": 8866.76, "text": " you know, Bayesian probability theory, where, you know, the complexity of something is the", "tokens": [50368, 291, 458, 11, 7840, 42434, 8482, 5261, 11, 689, 11, 291, 458, 11, 264, 14024, 295, 746, 307, 264, 50764], "temperature": 0.0, "avg_logprob": -0.09617504772839246, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0008237681468017399}, {"id": 1574, "seek": 885876, "start": 8866.76, "end": 8870.68, "text": " negative log of its probability essentially, right? And you have a complete equivalence between", "tokens": [50764, 3671, 3565, 295, 1080, 8482, 4476, 11, 558, 30, 400, 291, 362, 257, 3566, 9052, 655, 1296, 50960], "temperature": 0.0, "avg_logprob": -0.09617504772839246, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0008237681468017399}, {"id": 1575, "seek": 885876, "start": 8870.68, "end": 8875.24, "text": " the two things. And there you would think, you know, the probability is something that's well", "tokens": [50960, 264, 732, 721, 13, 400, 456, 291, 576, 519, 11, 291, 458, 11, 264, 8482, 307, 746, 300, 311, 731, 51188], "temperature": 0.0, "avg_logprob": -0.09617504772839246, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0008237681468017399}, {"id": 1576, "seek": 885876, "start": 8875.24, "end": 8879.48, "text": " defined mathematically, which means complexity is well defined. But it's not true. You need to have", "tokens": [51188, 7642, 44003, 11, 597, 1355, 14024, 307, 731, 7642, 13, 583, 309, 311, 406, 2074, 13, 509, 643, 281, 362, 51400], "temperature": 0.0, "avg_logprob": -0.09617504772839246, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0008237681468017399}, {"id": 1577, "seek": 885876, "start": 8879.48, "end": 8885.16, "text": " a model of the distribution. You may need to have a prior, if you're doing Bayesian inference. And", "tokens": [51400, 257, 2316, 295, 264, 7316, 13, 509, 815, 643, 281, 362, 257, 4059, 11, 498, 291, 434, 884, 7840, 42434, 38253, 13, 400, 51684], "temperature": 0.0, "avg_logprob": -0.09617504772839246, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0008237681468017399}, {"id": 1578, "seek": 888516, "start": 8885.16, "end": 8889.32, "text": " the prior plays the same role as the choice of the computer with which you measure your Karmogorov", "tokens": [50364, 264, 4059, 5749, 264, 912, 3090, 382, 264, 3922, 295, 264, 3820, 365, 597, 291, 3481, 428, 591, 4452, 664, 284, 5179, 50572], "temperature": 0.0, "avg_logprob": -0.13741825007590927, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0008961905259639025}, {"id": 1579, "seek": 888516, "start": 8889.32, "end": 8896.6, "text": " complexity. And so, every measure of complexity we have has some arbitraryness in it, you know,", "tokens": [50572, 14024, 13, 400, 370, 11, 633, 3481, 295, 14024, 321, 362, 575, 512, 23211, 1287, 294, 309, 11, 291, 458, 11, 50936], "temperature": 0.0, "avg_logprob": -0.13741825007590927, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0008961905259639025}, {"id": 1580, "seek": 888516, "start": 8896.6, "end": 8903.48, "text": " an additive constant, which is, can be arbitrarily large. And so, you know, how can we come up with", "tokens": [50936, 364, 45558, 5754, 11, 597, 307, 11, 393, 312, 19071, 3289, 2416, 13, 400, 370, 11, 291, 458, 11, 577, 393, 321, 808, 493, 365, 51280], "temperature": 0.0, "avg_logprob": -0.13741825007590927, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0008961905259639025}, {"id": 1581, "seek": 888516, "start": 8903.48, "end": 8906.84, "text": " a good theory of how things become more complex if we don't have a good measure of complexity?", "tokens": [51280, 257, 665, 5261, 295, 577, 721, 1813, 544, 3997, 498, 321, 500, 380, 362, 257, 665, 3481, 295, 14024, 30, 51448], "temperature": 0.0, "avg_logprob": -0.13741825007590927, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0008961905259639025}, {"id": 1582, "seek": 888516, "start": 8906.84, "end": 8912.84, "text": " Yeah, which we need for is one way that people study this in the space of biology,", "tokens": [51448, 865, 11, 597, 321, 643, 337, 307, 472, 636, 300, 561, 2979, 341, 294, 264, 1901, 295, 14956, 11, 51748], "temperature": 0.0, "avg_logprob": -0.13741825007590927, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0008961905259639025}, {"id": 1583, "seek": 891284, "start": 8912.84, "end": 8917.16, "text": " the people that study the origin of life or try to recreate life in the laboratory.", "tokens": [50364, 264, 561, 300, 2979, 264, 4957, 295, 993, 420, 853, 281, 25833, 993, 294, 264, 16523, 13, 50580], "temperature": 0.0, "avg_logprob": -0.10752926983879608, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.004003908485174179}, {"id": 1584, "seek": 891284, "start": 8917.72, "end": 8921.16, "text": " And the more interesting one is the alien one is when we go to other planets,", "tokens": [50608, 400, 264, 544, 1880, 472, 307, 264, 12319, 472, 307, 562, 321, 352, 281, 661, 15126, 11, 50780], "temperature": 0.0, "avg_logprob": -0.10752926983879608, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.004003908485174179}, {"id": 1585, "seek": 891284, "start": 8921.960000000001, "end": 8927.48, "text": " how do we recognize this life? Because, you know, complexity, we associate complexity,", "tokens": [50820, 577, 360, 321, 5521, 341, 993, 30, 1436, 11, 291, 458, 11, 14024, 11, 321, 14644, 14024, 11, 51096], "temperature": 0.0, "avg_logprob": -0.10752926983879608, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.004003908485174179}, {"id": 1586, "seek": 891284, "start": 8927.48, "end": 8933.48, "text": " maybe some level of mobility with life, you know, we have to be able to, like, have concrete", "tokens": [51096, 1310, 512, 1496, 295, 16199, 365, 993, 11, 291, 458, 11, 321, 362, 281, 312, 1075, 281, 11, 411, 11, 362, 9859, 51396], "temperature": 0.0, "avg_logprob": -0.10752926983879608, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.004003908485174179}, {"id": 1587, "seek": 891284, "start": 8934.68, "end": 8941.32, "text": " algorithms for, like, measuring the level of complexity we see in order to know the", "tokens": [51456, 14642, 337, 11, 411, 11, 13389, 264, 1496, 295, 14024, 321, 536, 294, 1668, 281, 458, 264, 51788], "temperature": 0.0, "avg_logprob": -0.10752926983879608, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.004003908485174179}, {"id": 1588, "seek": 894132, "start": 8941.32, "end": 8944.84, "text": " difference between life and non-life. And the problem is that complexity is in the", "tokens": [50364, 2649, 1296, 993, 293, 2107, 12, 9073, 13, 400, 264, 1154, 307, 300, 14024, 307, 294, 264, 50540], "temperature": 0.0, "avg_logprob": -0.156671322716607, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.001622066949494183}, {"id": 1589, "seek": 894132, "start": 8944.84, "end": 8953.48, "text": " IODB holder. So, let me give you an example. If I give you an image of the MNIST digits,", "tokens": [50540, 286, 14632, 33, 20349, 13, 407, 11, 718, 385, 976, 291, 364, 1365, 13, 759, 286, 976, 291, 364, 3256, 295, 264, 376, 45, 19756, 27011, 11, 50972], "temperature": 0.0, "avg_logprob": -0.156671322716607, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.001622066949494183}, {"id": 1590, "seek": 894132, "start": 8953.48, "end": 8959.0, "text": " right, and I flip through MNIST digits, there is some, obviously some structure to it because", "tokens": [50972, 558, 11, 293, 286, 7929, 807, 376, 45, 19756, 27011, 11, 456, 307, 512, 11, 2745, 512, 3877, 281, 309, 570, 51248], "temperature": 0.0, "avg_logprob": -0.156671322716607, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.001622066949494183}, {"id": 1591, "seek": 894132, "start": 8959.72, "end": 8965.16, "text": " local structure, you know, neighboring pixels are correlated across the entire dataset.", "tokens": [51284, 2654, 3877, 11, 291, 458, 11, 31521, 18668, 366, 38574, 2108, 264, 2302, 28872, 13, 51556], "temperature": 0.0, "avg_logprob": -0.156671322716607, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.001622066949494183}, {"id": 1592, "seek": 896516, "start": 8965.96, "end": 8971.64, "text": " Now, imagine that I apply a random permutation to all the pixels,", "tokens": [50404, 823, 11, 3811, 300, 286, 3079, 257, 4974, 4784, 11380, 281, 439, 264, 18668, 11, 50688], "temperature": 0.0, "avg_logprob": -0.09815113761208275, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.014948872849345207}, {"id": 1593, "seek": 896516, "start": 8972.6, "end": 8977.96, "text": " a fixed random permutation. Now, I show you those images, they will look, you know,", "tokens": [50736, 257, 6806, 4974, 4784, 11380, 13, 823, 11, 286, 855, 291, 729, 5267, 11, 436, 486, 574, 11, 291, 458, 11, 51004], "temperature": 0.0, "avg_logprob": -0.09815113761208275, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.014948872849345207}, {"id": 1594, "seek": 896516, "start": 8977.96, "end": 8983.48, "text": " really disorganized to you, more complex. In fact, they're not more complex in absolute terms,", "tokens": [51004, 534, 717, 12372, 1602, 281, 291, 11, 544, 3997, 13, 682, 1186, 11, 436, 434, 406, 544, 3997, 294, 8236, 2115, 11, 51280], "temperature": 0.0, "avg_logprob": -0.09815113761208275, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.014948872849345207}, {"id": 1595, "seek": 896516, "start": 8983.48, "end": 8987.48, "text": " they're exactly the same as originally, right? And if you knew what the permutation was,", "tokens": [51280, 436, 434, 2293, 264, 912, 382, 7993, 11, 558, 30, 400, 498, 291, 2586, 437, 264, 4784, 11380, 390, 11, 51480], "temperature": 0.0, "avg_logprob": -0.09815113761208275, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.014948872849345207}, {"id": 1596, "seek": 896516, "start": 8987.48, "end": 8993.24, "text": " you know, you could undo the permutation. Now, imagine I give you special glasses that undo", "tokens": [51480, 291, 458, 11, 291, 727, 23779, 264, 4784, 11380, 13, 823, 11, 3811, 286, 976, 291, 2121, 10812, 300, 23779, 51768], "temperature": 0.0, "avg_logprob": -0.09815113761208275, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.014948872849345207}, {"id": 1597, "seek": 899324, "start": 8993.24, "end": 8998.68, "text": " that permutation. Now, all of a sudden, what looked complicated becomes simple. Right. So,", "tokens": [50364, 300, 4784, 11380, 13, 823, 11, 439, 295, 257, 3990, 11, 437, 2956, 6179, 3643, 2199, 13, 1779, 13, 407, 11, 50636], "temperature": 0.0, "avg_logprob": -0.12613560860617118, "compression_ratio": 1.8073770491803278, "no_speech_prob": 0.021578749641776085}, {"id": 1598, "seek": 899324, "start": 8998.68, "end": 9003.88, "text": " if you have two, if you have, you know, humans on one end, and then another race of aliens that", "tokens": [50636, 498, 291, 362, 732, 11, 498, 291, 362, 11, 291, 458, 11, 6255, 322, 472, 917, 11, 293, 550, 1071, 4569, 295, 21594, 300, 50896], "temperature": 0.0, "avg_logprob": -0.12613560860617118, "compression_ratio": 1.8073770491803278, "no_speech_prob": 0.021578749641776085}, {"id": 1599, "seek": 899324, "start": 9003.88, "end": 9007.32, "text": " sees the universe with permutation glasses. Yeah, with the permutation glasses.", "tokens": [50896, 8194, 264, 6445, 365, 4784, 11380, 10812, 13, 865, 11, 365, 264, 4784, 11380, 10812, 13, 51068], "temperature": 0.0, "avg_logprob": -0.12613560860617118, "compression_ratio": 1.8073770491803278, "no_speech_prob": 0.021578749641776085}, {"id": 1600, "seek": 899324, "start": 9008.6, "end": 9012.28, "text": " What we perceive as simple to them is hardly complicated, it's probably heat.", "tokens": [51132, 708, 321, 20281, 382, 2199, 281, 552, 307, 13572, 6179, 11, 309, 311, 1391, 3738, 13, 51316], "temperature": 0.0, "avg_logprob": -0.12613560860617118, "compression_ratio": 1.8073770491803278, "no_speech_prob": 0.021578749641776085}, {"id": 1601, "seek": 899324, "start": 9012.28, "end": 9019.0, "text": " Yeah, heat, yeah. Okay. And what they perceive as simple to us is random fluctuation, it's heat.", "tokens": [51316, 865, 11, 3738, 11, 1338, 13, 1033, 13, 400, 437, 436, 20281, 382, 2199, 281, 505, 307, 4974, 23448, 16073, 11, 309, 311, 3738, 13, 51652], "temperature": 0.0, "avg_logprob": -0.12613560860617118, "compression_ratio": 1.8073770491803278, "no_speech_prob": 0.021578749641776085}, {"id": 1602, "seek": 901900, "start": 9019.0, "end": 9024.28, "text": " Yeah. So, truly in the eye of the beholder, depends what kind of glasses you're wearing.", "tokens": [50364, 865, 13, 407, 11, 4908, 294, 264, 3313, 295, 264, 312, 20480, 11, 5946, 437, 733, 295, 10812, 291, 434, 4769, 13, 50628], "temperature": 0.0, "avg_logprob": -0.14122995279603084, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0011691502295434475}, {"id": 1603, "seek": 901900, "start": 9024.84, "end": 9028.28, "text": " Right. Depends what kind of algorithm you're running in your perception system.", "tokens": [50656, 1779, 13, 4056, 2581, 437, 733, 295, 9284, 291, 434, 2614, 294, 428, 12860, 1185, 13, 50828], "temperature": 0.0, "avg_logprob": -0.14122995279603084, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0011691502295434475}, {"id": 1604, "seek": 901900, "start": 9028.28, "end": 9033.24, "text": " So, I don't think we'll have a theory of intelligence, self-organization, evolution,", "tokens": [50828, 407, 11, 286, 500, 380, 519, 321, 603, 362, 257, 5261, 295, 7599, 11, 2698, 12, 12372, 2144, 11, 9303, 11, 51076], "temperature": 0.0, "avg_logprob": -0.14122995279603084, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0011691502295434475}, {"id": 1605, "seek": 901900, "start": 9033.24, "end": 9039.32, "text": " things like that, until we have a good handle on a notion of complexity, which we know is in the", "tokens": [51076, 721, 411, 300, 11, 1826, 321, 362, 257, 665, 4813, 322, 257, 10710, 295, 14024, 11, 597, 321, 458, 307, 294, 264, 51380], "temperature": 0.0, "avg_logprob": -0.14122995279603084, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0011691502295434475}, {"id": 1606, "seek": 901900, "start": 9039.32, "end": 9045.08, "text": " high, the eye of the beholder. Yeah, it's sad to think that we might not be able to detect or", "tokens": [51380, 1090, 11, 264, 3313, 295, 264, 312, 20480, 13, 865, 11, 309, 311, 4227, 281, 519, 300, 321, 1062, 406, 312, 1075, 281, 5531, 420, 51668], "temperature": 0.0, "avg_logprob": -0.14122995279603084, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0011691502295434475}, {"id": 1607, "seek": 904508, "start": 9045.08, "end": 9049.16, "text": " interact with alien species because we're wearing different glasses.", "tokens": [50364, 4648, 365, 12319, 6172, 570, 321, 434, 4769, 819, 10812, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1608, "seek": 904508, "start": 9050.2, "end": 9052.76, "text": " Because their notion of locality might be different from ours. Yeah.", "tokens": [50620, 1436, 641, 10710, 295, 1628, 1860, 1062, 312, 819, 490, 11896, 13, 865, 13, 50748], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1609, "seek": 904508, "start": 9052.76, "end": 9056.92, "text": " This actually connects with fascinating questions in physics at the moment, like modern physics,", "tokens": [50748, 639, 767, 16967, 365, 10343, 1651, 294, 10649, 412, 264, 1623, 11, 411, 4363, 10649, 11, 50956], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1610, "seek": 904508, "start": 9058.039999999999, "end": 9062.44, "text": " quantum physics, like, you know, questions about like, you know, can we recover the information", "tokens": [51012, 13018, 10649, 11, 411, 11, 291, 458, 11, 1651, 466, 411, 11, 291, 458, 11, 393, 321, 8114, 264, 1589, 51232], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1611, "seek": 904508, "start": 9062.44, "end": 9067.64, "text": " that's lost in a black hole and things like this, right? And that relies on notions of complexity,", "tokens": [51232, 300, 311, 2731, 294, 257, 2211, 5458, 293, 721, 411, 341, 11, 558, 30, 400, 300, 30910, 322, 35799, 295, 14024, 11, 51492], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1612, "seek": 904508, "start": 9069.0, "end": 9071.56, "text": " which, you know, I find it's fascinating.", "tokens": [51560, 597, 11, 291, 458, 11, 286, 915, 309, 311, 10343, 13, 51688], "temperature": 0.0, "avg_logprob": -0.14610216352674696, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.0023951129987835884}, {"id": 1613, "seek": 907156, "start": 9071.56, "end": 9079.08, "text": " Can you describe your personal quest to build an expressive electronic wind instrument EWI?", "tokens": [50364, 1664, 291, 6786, 428, 2973, 866, 281, 1322, 364, 40189, 10092, 2468, 7198, 462, 54, 40, 30, 50740], "temperature": 0.0, "avg_logprob": -0.12670602603834502, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.0013239242834970355}, {"id": 1614, "seek": 907156, "start": 9079.72, "end": 9083.96, "text": " What is it? What does it take to build it?", "tokens": [50772, 708, 307, 309, 30, 708, 775, 309, 747, 281, 1322, 309, 30, 50984], "temperature": 0.0, "avg_logprob": -0.12670602603834502, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.0013239242834970355}, {"id": 1615, "seek": 907156, "start": 9083.96, "end": 9088.359999999999, "text": " Well, I'm a thinker. I like building things. I like building things with combinations of", "tokens": [50984, 1042, 11, 286, 478, 257, 519, 260, 13, 286, 411, 2390, 721, 13, 286, 411, 2390, 721, 365, 21267, 295, 51204], "temperature": 0.0, "avg_logprob": -0.12670602603834502, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.0013239242834970355}, {"id": 1616, "seek": 907156, "start": 9088.359999999999, "end": 9094.279999999999, "text": " electronics and, you know, mechanical stuff. You know, I have a bunch of different hobbies, but", "tokens": [51204, 20611, 293, 11, 291, 458, 11, 12070, 1507, 13, 509, 458, 11, 286, 362, 257, 3840, 295, 819, 35750, 11, 457, 51500], "temperature": 0.0, "avg_logprob": -0.12670602603834502, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.0013239242834970355}, {"id": 1617, "seek": 907156, "start": 9095.48, "end": 9099.56, "text": " you know, probably my first one was little was building model airplanes and stuff like", "tokens": [51560, 291, 458, 11, 1391, 452, 700, 472, 390, 707, 390, 2390, 2316, 32947, 293, 1507, 411, 51764], "temperature": 0.0, "avg_logprob": -0.12670602603834502, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.0013239242834970355}, {"id": 1618, "seek": 909956, "start": 9099.56, "end": 9104.039999999999, "text": " that. And I still do that to some extent. But also electronics, I taught myself electronics before", "tokens": [50364, 300, 13, 400, 286, 920, 360, 300, 281, 512, 8396, 13, 583, 611, 20611, 11, 286, 5928, 2059, 20611, 949, 50588], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1619, "seek": 909956, "start": 9104.039999999999, "end": 9110.439999999999, "text": " I studied it. And the reason I taught myself electronics is because of music. My cousin", "tokens": [50588, 286, 9454, 309, 13, 400, 264, 1778, 286, 5928, 2059, 20611, 307, 570, 295, 1318, 13, 1222, 16207, 50908], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1620, "seek": 909956, "start": 9111.4, "end": 9115.56, "text": " was an aspiring electronic musician, and then he had an analog synthesizer. And I was, you know,", "tokens": [50956, 390, 364, 45405, 10092, 19570, 11, 293, 550, 415, 632, 364, 16660, 26617, 6545, 13, 400, 286, 390, 11, 291, 458, 11, 51164], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1621, "seek": 909956, "start": 9115.56, "end": 9120.119999999999, "text": " basically modifying it for him and building sequencers and stuff like that, right, for him.", "tokens": [51164, 1936, 42626, 309, 337, 796, 293, 2390, 5123, 268, 8530, 293, 1507, 411, 300, 11, 558, 11, 337, 796, 13, 51392], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1622, "seek": 909956, "start": 9120.119999999999, "end": 9121.8, "text": " I was in high school when I was doing this.", "tokens": [51392, 286, 390, 294, 1090, 1395, 562, 286, 390, 884, 341, 13, 51476], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1623, "seek": 909956, "start": 9122.519999999999, "end": 9127.88, "text": " How's the interest in like progressive rock like 80s? Like, what's the greatest band of all time,", "tokens": [51512, 1012, 311, 264, 1179, 294, 411, 16131, 3727, 411, 4688, 82, 30, 1743, 11, 437, 311, 264, 6636, 4116, 295, 439, 565, 11, 51780], "temperature": 0.0, "avg_logprob": -0.16903240978717804, "compression_ratio": 1.764505119453925, "no_speech_prob": 0.018226949498057365}, {"id": 1624, "seek": 912788, "start": 9127.88, "end": 9132.599999999999, "text": " according to Yonah Kuhn? There's too many of them. But, you know, it's a combination of", "tokens": [50364, 4650, 281, 398, 266, 545, 591, 3232, 77, 30, 821, 311, 886, 867, 295, 552, 13, 583, 11, 291, 458, 11, 309, 311, 257, 6562, 295, 50600], "temperature": 0.0, "avg_logprob": -0.3128291783707865, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.009539125487208366}, {"id": 1625, "seek": 912788, "start": 9135.8, "end": 9142.759999999998, "text": " you know, my vision orchestra, weather report, yes, Genesis, you know,", "tokens": [50760, 291, 458, 11, 452, 5201, 25280, 11, 5503, 2275, 11, 2086, 11, 20587, 11, 291, 458, 11, 51108], "temperature": 0.0, "avg_logprob": -0.3128291783707865, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.009539125487208366}, {"id": 1626, "seek": 912788, "start": 9142.759999999998, "end": 9148.519999999999, "text": " yes, Genesis, Peter Gabriel, gentle giant, you know, things like that.", "tokens": [51108, 2086, 11, 20587, 11, 6508, 20985, 11, 6424, 7410, 11, 291, 458, 11, 721, 411, 300, 13, 51396], "temperature": 0.0, "avg_logprob": -0.3128291783707865, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.009539125487208366}, {"id": 1627, "seek": 912788, "start": 9149.08, "end": 9154.199999999999, "text": " Great. Okay. So this, this love of electronics and this love of music combined together.", "tokens": [51424, 3769, 13, 1033, 13, 407, 341, 11, 341, 959, 295, 20611, 293, 341, 959, 295, 1318, 9354, 1214, 13, 51680], "temperature": 0.0, "avg_logprob": -0.3128291783707865, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.009539125487208366}, {"id": 1628, "seek": 915420, "start": 9154.2, "end": 9160.28, "text": " Right. So I was actually trained to play Baroque and Renaissance music. And I played in", "tokens": [50364, 1779, 13, 407, 286, 390, 767, 8895, 281, 862, 4156, 29743, 293, 32642, 1318, 13, 400, 286, 3737, 294, 50668], "temperature": 0.0, "avg_logprob": -0.12183937533148403, "compression_ratio": 1.661710037174721, "no_speech_prob": 0.002696467097848654}, {"id": 1629, "seek": 915420, "start": 9161.480000000001, "end": 9166.84, "text": " orchestra when I was in high school and first years of college. And I played the recorder,", "tokens": [50728, 25280, 562, 286, 390, 294, 1090, 1395, 293, 700, 924, 295, 3859, 13, 400, 286, 3737, 264, 37744, 11, 50996], "temperature": 0.0, "avg_logprob": -0.12183937533148403, "compression_ratio": 1.661710037174721, "no_speech_prob": 0.002696467097848654}, {"id": 1630, "seek": 915420, "start": 9166.84, "end": 9172.52, "text": " Cromhorn, a little bit of oboe, you know, things like that. So I'm a wind instrument player. But", "tokens": [50996, 383, 4397, 31990, 11, 257, 707, 857, 295, 1111, 7921, 11, 291, 458, 11, 721, 411, 300, 13, 407, 286, 478, 257, 2468, 7198, 4256, 13, 583, 51280], "temperature": 0.0, "avg_logprob": -0.12183937533148403, "compression_ratio": 1.661710037174721, "no_speech_prob": 0.002696467097848654}, {"id": 1631, "seek": 915420, "start": 9172.52, "end": 9175.240000000002, "text": " I always wanted to play improvised music, even though I don't know anything about it.", "tokens": [51280, 286, 1009, 1415, 281, 862, 2530, 24420, 1318, 11, 754, 1673, 286, 500, 380, 458, 1340, 466, 309, 13, 51416], "temperature": 0.0, "avg_logprob": -0.12183937533148403, "compression_ratio": 1.661710037174721, "no_speech_prob": 0.002696467097848654}, {"id": 1632, "seek": 915420, "start": 9176.28, "end": 9181.400000000001, "text": " And the only way I figured, you know, short of like learning to play saxophone was to", "tokens": [51468, 400, 264, 787, 636, 286, 8932, 11, 291, 458, 11, 2099, 295, 411, 2539, 281, 862, 42119, 32561, 390, 281, 51724], "temperature": 0.0, "avg_logprob": -0.12183937533148403, "compression_ratio": 1.661710037174721, "no_speech_prob": 0.002696467097848654}, {"id": 1633, "seek": 918140, "start": 9182.119999999999, "end": 9187.0, "text": " play electronic wind instruments. So they behave on the fingering is similar to a saxophone, but,", "tokens": [50400, 862, 10092, 2468, 12190, 13, 407, 436, 15158, 322, 264, 3823, 1794, 307, 2531, 281, 257, 42119, 32561, 11, 457, 11, 50644], "temperature": 0.0, "avg_logprob": -0.14097357632821067, "compression_ratio": 1.6654676258992807, "no_speech_prob": 0.002379886107519269}, {"id": 1634, "seek": 918140, "start": 9187.0, "end": 9191.0, "text": " you know, you have a wide variety of sound because you control the synthesizer with it.", "tokens": [50644, 291, 458, 11, 291, 362, 257, 4874, 5673, 295, 1626, 570, 291, 1969, 264, 26617, 6545, 365, 309, 13, 50844], "temperature": 0.0, "avg_logprob": -0.14097357632821067, "compression_ratio": 1.6654676258992807, "no_speech_prob": 0.002379886107519269}, {"id": 1635, "seek": 918140, "start": 9191.0, "end": 9198.119999999999, "text": " So I had a bunch of those, you know, going back to the late 80s from either Yamaha or", "tokens": [50844, 407, 286, 632, 257, 3840, 295, 729, 11, 291, 458, 11, 516, 646, 281, 264, 3469, 4688, 82, 490, 2139, 18992, 4408, 420, 51200], "temperature": 0.0, "avg_logprob": -0.14097357632821067, "compression_ratio": 1.6654676258992807, "no_speech_prob": 0.002379886107519269}, {"id": 1636, "seek": 918140, "start": 9198.119999999999, "end": 9203.64, "text": " Akai, they're both kind of the main manufacturers of those that they were classically, you know,", "tokens": [51200, 9629, 1301, 11, 436, 434, 1293, 733, 295, 264, 2135, 18455, 295, 729, 300, 436, 645, 1508, 984, 11, 291, 458, 11, 51476], "temperature": 0.0, "avg_logprob": -0.14097357632821067, "compression_ratio": 1.6654676258992807, "no_speech_prob": 0.002379886107519269}, {"id": 1637, "seek": 918140, "start": 9203.64, "end": 9208.199999999999, "text": " going back several decades. But I've never been completely satisfied with them because of lack", "tokens": [51476, 516, 646, 2940, 7878, 13, 583, 286, 600, 1128, 668, 2584, 11239, 365, 552, 570, 295, 5011, 51704], "temperature": 0.0, "avg_logprob": -0.14097357632821067, "compression_ratio": 1.6654676258992807, "no_speech_prob": 0.002379886107519269}, {"id": 1638, "seek": 920820, "start": 9208.2, "end": 9213.480000000001, "text": " of expressivity. And, you know, those things, you know, are somewhat expressive. I mean,", "tokens": [50364, 295, 5109, 4253, 13, 400, 11, 291, 458, 11, 729, 721, 11, 291, 458, 11, 366, 8344, 40189, 13, 286, 914, 11, 50628], "temperature": 0.0, "avg_logprob": -0.19451575009328015, "compression_ratio": 1.8190045248868778, "no_speech_prob": 0.009344827383756638}, {"id": 1639, "seek": 920820, "start": 9213.480000000001, "end": 9217.0, "text": " they measure the breath pressure, they measure the lip pressure, and, you know,", "tokens": [50628, 436, 3481, 264, 6045, 3321, 11, 436, 3481, 264, 8280, 3321, 11, 293, 11, 291, 458, 11, 50804], "temperature": 0.0, "avg_logprob": -0.19451575009328015, "compression_ratio": 1.8190045248868778, "no_speech_prob": 0.009344827383756638}, {"id": 1640, "seek": 920820, "start": 9218.36, "end": 9224.04, "text": " you have various parameters, you can vary with fingers, but they're not really", "tokens": [50872, 291, 362, 3683, 9834, 11, 291, 393, 10559, 365, 7350, 11, 457, 436, 434, 406, 534, 51156], "temperature": 0.0, "avg_logprob": -0.19451575009328015, "compression_ratio": 1.8190045248868778, "no_speech_prob": 0.009344827383756638}, {"id": 1641, "seek": 920820, "start": 9224.04, "end": 9229.320000000002, "text": " as expressive as an acoustic instrument, right? You hear John Coltrane play two notes,", "tokens": [51156, 382, 40189, 382, 364, 26753, 7198, 11, 558, 30, 509, 1568, 2619, 4004, 6903, 1929, 862, 732, 5570, 11, 51420], "temperature": 0.0, "avg_logprob": -0.19451575009328015, "compression_ratio": 1.8190045248868778, "no_speech_prob": 0.009344827383756638}, {"id": 1642, "seek": 920820, "start": 9229.320000000002, "end": 9231.960000000001, "text": " and you know it's John Coltrane, you know, it's got a unique sound.", "tokens": [51420, 293, 291, 458, 309, 311, 2619, 4004, 6903, 1929, 11, 291, 458, 11, 309, 311, 658, 257, 3845, 1626, 13, 51552], "temperature": 0.0, "avg_logprob": -0.19451575009328015, "compression_ratio": 1.8190045248868778, "no_speech_prob": 0.009344827383756638}, {"id": 1643, "seek": 923196, "start": 9232.919999999998, "end": 9239.56, "text": " Or Miles Davis, right? You can hear it's Miles Davis playing the trumpet because the sound", "tokens": [50412, 1610, 27384, 15658, 11, 558, 30, 509, 393, 1568, 309, 311, 27384, 15658, 2433, 264, 35160, 570, 264, 1626, 50744], "temperature": 0.0, "avg_logprob": -0.17701860492149096, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.2955347001552582}, {"id": 1644, "seek": 923196, "start": 9240.439999999999, "end": 9246.119999999999, "text": " reflects their, you know, physiognomy, basically the shape of the vocal track", "tokens": [50788, 18926, 641, 11, 291, 458, 11, 21265, 2912, 8488, 11, 1936, 264, 3909, 295, 264, 11657, 2837, 51072], "temperature": 0.0, "avg_logprob": -0.17701860492149096, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.2955347001552582}, {"id": 1645, "seek": 923196, "start": 9248.039999999999, "end": 9253.96, "text": " kind of shapes the sound. So how do you do this with an electronic instrument? And I was, many", "tokens": [51168, 733, 295, 10854, 264, 1626, 13, 407, 577, 360, 291, 360, 341, 365, 364, 10092, 7198, 30, 400, 286, 390, 11, 867, 51464], "temperature": 0.0, "avg_logprob": -0.17701860492149096, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.2955347001552582}, {"id": 1646, "seek": 923196, "start": 9253.96, "end": 9259.4, "text": " years ago, I met a guy called David Wessel. He was a professor at Berkeley and created the", "tokens": [51464, 924, 2057, 11, 286, 1131, 257, 2146, 1219, 4389, 343, 47166, 13, 634, 390, 257, 8304, 412, 23684, 293, 2942, 264, 51736], "temperature": 0.0, "avg_logprob": -0.17701860492149096, "compression_ratio": 1.5258620689655173, "no_speech_prob": 0.2955347001552582}, {"id": 1647, "seek": 925940, "start": 9259.64, "end": 9264.68, "text": " center for like, you know, music technology there. And he was interested in that question.", "tokens": [50376, 3056, 337, 411, 11, 291, 458, 11, 1318, 2899, 456, 13, 400, 415, 390, 3102, 294, 300, 1168, 13, 50628], "temperature": 0.0, "avg_logprob": -0.17415885294764494, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.009250309318304062}, {"id": 1648, "seek": 925940, "start": 9265.96, "end": 9270.119999999999, "text": " And so I kept kind of thinking about this for many years. And finally, because of COVID, you", "tokens": [50692, 400, 370, 286, 4305, 733, 295, 1953, 466, 341, 337, 867, 924, 13, 400, 2721, 11, 570, 295, 4566, 11, 291, 50900], "temperature": 0.0, "avg_logprob": -0.17415885294764494, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.009250309318304062}, {"id": 1649, "seek": 925940, "start": 9270.119999999999, "end": 9275.96, "text": " know, I was at home, I was in my workshop, my workshop serves also as my kind of Zoom room", "tokens": [50900, 458, 11, 286, 390, 412, 1280, 11, 286, 390, 294, 452, 13541, 11, 452, 13541, 13451, 611, 382, 452, 733, 295, 13453, 1808, 51192], "temperature": 0.0, "avg_logprob": -0.17415885294764494, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.009250309318304062}, {"id": 1650, "seek": 925940, "start": 9275.96, "end": 9283.24, "text": " and home office. And this is in New Jersey? In New Jersey. And I started really being serious about,", "tokens": [51192, 293, 1280, 3398, 13, 400, 341, 307, 294, 1873, 16601, 30, 682, 1873, 16601, 13, 400, 286, 1409, 534, 885, 3156, 466, 11, 51556], "temperature": 0.0, "avg_logprob": -0.17415885294764494, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.009250309318304062}, {"id": 1651, "seek": 925940, "start": 9283.24, "end": 9288.199999999999, "text": " you know, building my own EWI instrument. What else is going on in the New Jersey workshop? Is", "tokens": [51556, 291, 458, 11, 2390, 452, 1065, 462, 54, 40, 7198, 13, 708, 1646, 307, 516, 322, 294, 264, 1873, 16601, 13541, 30, 1119, 51804], "temperature": 0.0, "avg_logprob": -0.17415885294764494, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.009250309318304062}, {"id": 1652, "seek": 928820, "start": 9289.16, "end": 9295.320000000002, "text": " some crazy stuff you built or like left on the workshop floor left behind?", "tokens": [50412, 512, 3219, 1507, 291, 3094, 420, 411, 1411, 322, 264, 13541, 4123, 1411, 2261, 30, 50720], "temperature": 0.0, "avg_logprob": -0.16443706694103422, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.001098357024602592}, {"id": 1653, "seek": 928820, "start": 9295.320000000002, "end": 9301.0, "text": " A lot of crazy stuff is, you know, electronics built with microcontrollers of various kinds.", "tokens": [50720, 316, 688, 295, 3219, 1507, 307, 11, 291, 458, 11, 20611, 3094, 365, 4532, 9000, 3970, 433, 295, 3683, 3685, 13, 51004], "temperature": 0.0, "avg_logprob": -0.16443706694103422, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.001098357024602592}, {"id": 1654, "seek": 928820, "start": 9301.560000000001, "end": 9307.960000000001, "text": " And, you know, weird flying contraptions. So you still love flying?", "tokens": [51032, 400, 11, 291, 458, 11, 3657, 7137, 10742, 9799, 13, 407, 291, 920, 959, 7137, 30, 51352], "temperature": 0.0, "avg_logprob": -0.16443706694103422, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.001098357024602592}, {"id": 1655, "seek": 928820, "start": 9308.52, "end": 9315.0, "text": " It's a family disease. My dad got me into it when I was a kid. And he was building", "tokens": [51380, 467, 311, 257, 1605, 4752, 13, 1222, 3546, 658, 385, 666, 309, 562, 286, 390, 257, 1636, 13, 400, 415, 390, 2390, 51704], "temperature": 0.0, "avg_logprob": -0.16443706694103422, "compression_ratio": 1.5436893203883495, "no_speech_prob": 0.001098357024602592}, {"id": 1656, "seek": 931500, "start": 9315.08, "end": 9320.76, "text": " model airplanes when he was a kid. And he was a mechanical engineer. He taught himself electronics", "tokens": [50368, 2316, 32947, 562, 415, 390, 257, 1636, 13, 400, 415, 390, 257, 12070, 11403, 13, 634, 5928, 3647, 20611, 50652], "temperature": 0.0, "avg_logprob": -0.1531884283082098, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.008305654861032963}, {"id": 1657, "seek": 931500, "start": 9320.76, "end": 9328.84, "text": " also. So he built his early radio control systems in the late 60s, early 70s. And so that's what", "tokens": [50652, 611, 13, 407, 415, 3094, 702, 2440, 6477, 1969, 3652, 294, 264, 3469, 4060, 82, 11, 2440, 5285, 82, 13, 400, 370, 300, 311, 437, 51056], "temperature": 0.0, "avg_logprob": -0.1531884283082098, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.008305654861032963}, {"id": 1658, "seek": 931500, "start": 9328.84, "end": 9332.92, "text": " got me into, I mean, he got me into kind of, you know, engineering and science and technology.", "tokens": [51056, 658, 385, 666, 11, 286, 914, 11, 415, 658, 385, 666, 733, 295, 11, 291, 458, 11, 7043, 293, 3497, 293, 2899, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1531884283082098, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.008305654861032963}, {"id": 1659, "seek": 931500, "start": 9332.92, "end": 9337.4, "text": " Do you also have an interest in appreciation of flight in other forms, like with drones,", "tokens": [51260, 1144, 291, 611, 362, 364, 1179, 294, 18909, 295, 7018, 294, 661, 6422, 11, 411, 365, 23823, 11, 51484], "temperature": 0.0, "avg_logprob": -0.1531884283082098, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.008305654861032963}, {"id": 1660, "seek": 931500, "start": 9337.4, "end": 9344.04, "text": " quadroptors? Or do you, is it model airplane? You know, before drones were,", "tokens": [51484, 10787, 340, 662, 830, 30, 1610, 360, 291, 11, 307, 309, 2316, 17130, 30, 509, 458, 11, 949, 23823, 645, 11, 51816], "temperature": 0.0, "avg_logprob": -0.1531884283082098, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.008305654861032963}, {"id": 1661, "seek": 934500, "start": 9345.0, "end": 9351.08, "text": " you know, kind of consumer products, you know, I built my own, you know, with also building", "tokens": [50364, 291, 458, 11, 733, 295, 9711, 3383, 11, 291, 458, 11, 286, 3094, 452, 1065, 11, 291, 458, 11, 365, 611, 2390, 50668], "temperature": 0.0, "avg_logprob": -0.1471043507987206, "compression_ratio": 1.7211155378486056, "no_speech_prob": 0.001345388824120164}, {"id": 1662, "seek": 934500, "start": 9351.08, "end": 9356.52, "text": " a microcontroller with JavaScripts and accelerometers for stabilization, writing the", "tokens": [50668, 257, 4532, 9000, 22922, 365, 15778, 82, 293, 10172, 34675, 337, 35476, 11, 3579, 264, 50940], "temperature": 0.0, "avg_logprob": -0.1471043507987206, "compression_ratio": 1.7211155378486056, "no_speech_prob": 0.001345388824120164}, {"id": 1663, "seek": 934500, "start": 9356.52, "end": 9359.48, "text": " firmware for it, you know, and then when it became kind of a standard thing you could buy,", "tokens": [50940, 30289, 337, 309, 11, 291, 458, 11, 293, 550, 562, 309, 3062, 733, 295, 257, 3832, 551, 291, 727, 2256, 11, 51088], "temperature": 0.0, "avg_logprob": -0.1471043507987206, "compression_ratio": 1.7211155378486056, "no_speech_prob": 0.001345388824120164}, {"id": 1664, "seek": 934500, "start": 9359.48, "end": 9362.12, "text": " it was boring, you know, I stopped doing it. It was in front anymore.", "tokens": [51088, 309, 390, 9989, 11, 291, 458, 11, 286, 5936, 884, 309, 13, 467, 390, 294, 1868, 3602, 13, 51220], "temperature": 0.0, "avg_logprob": -0.1471043507987206, "compression_ratio": 1.7211155378486056, "no_speech_prob": 0.001345388824120164}, {"id": 1665, "seek": 934500, "start": 9363.4, "end": 9369.96, "text": " Yeah, you were doing it before it was cool. What advice would you give to a young person today", "tokens": [51284, 865, 11, 291, 645, 884, 309, 949, 309, 390, 1627, 13, 708, 5192, 576, 291, 976, 281, 257, 2037, 954, 965, 51612], "temperature": 0.0, "avg_logprob": -0.1471043507987206, "compression_ratio": 1.7211155378486056, "no_speech_prob": 0.001345388824120164}, {"id": 1666, "seek": 936996, "start": 9369.96, "end": 9375.8, "text": " in high school and college that dreams of doing something big, like young like Coon,", "tokens": [50364, 294, 1090, 1395, 293, 3859, 300, 7505, 295, 884, 746, 955, 11, 411, 2037, 411, 3066, 266, 11, 50656], "temperature": 0.0, "avg_logprob": -0.16013675782738662, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.07909372448921204}, {"id": 1667, "seek": 936996, "start": 9375.8, "end": 9381.56, "text": " like let's talk in the space of intelligence, dreams of having a chance to solve some fundamental", "tokens": [50656, 411, 718, 311, 751, 294, 264, 1901, 295, 7599, 11, 7505, 295, 1419, 257, 2931, 281, 5039, 512, 8088, 50944], "temperature": 0.0, "avg_logprob": -0.16013675782738662, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.07909372448921204}, {"id": 1668, "seek": 936996, "start": 9381.56, "end": 9387.56, "text": " problem in space of intelligence, both for their career and just in life, being somebody who was", "tokens": [50944, 1154, 294, 1901, 295, 7599, 11, 1293, 337, 641, 3988, 293, 445, 294, 993, 11, 885, 2618, 567, 390, 51244], "temperature": 0.0, "avg_logprob": -0.16013675782738662, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.07909372448921204}, {"id": 1669, "seek": 936996, "start": 9387.56, "end": 9395.32, "text": " a part of creating something special. So try to get interested by big questions,", "tokens": [51244, 257, 644, 295, 4084, 746, 2121, 13, 407, 853, 281, 483, 3102, 538, 955, 1651, 11, 51632], "temperature": 0.0, "avg_logprob": -0.16013675782738662, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.07909372448921204}, {"id": 1670, "seek": 939532, "start": 9395.32, "end": 9401.56, "text": " things like, you know, what is intelligence? What is the universe made of? What's life all about?", "tokens": [50364, 721, 411, 11, 291, 458, 11, 437, 307, 7599, 30, 708, 307, 264, 6445, 1027, 295, 30, 708, 311, 993, 439, 466, 30, 50676], "temperature": 0.0, "avg_logprob": -0.16605580996160638, "compression_ratio": 1.601063829787234, "no_speech_prob": 0.004744437988847494}, {"id": 1671, "seek": 939532, "start": 9401.56, "end": 9410.119999999999, "text": " Things like that. Like even like crazy big questions like what's time, like nobody knows what time is.", "tokens": [50676, 9514, 411, 300, 13, 1743, 754, 411, 3219, 955, 1651, 411, 437, 311, 565, 11, 411, 5079, 3255, 437, 565, 307, 13, 51104], "temperature": 0.0, "avg_logprob": -0.16605580996160638, "compression_ratio": 1.601063829787234, "no_speech_prob": 0.004744437988847494}, {"id": 1672, "seek": 939532, "start": 9413.08, "end": 9421.88, "text": " And then learn basic things like basic methods, either from math, from physics, or from engineering.", "tokens": [51252, 400, 550, 1466, 3875, 721, 411, 3875, 7150, 11, 2139, 490, 5221, 11, 490, 10649, 11, 420, 490, 7043, 13, 51692], "temperature": 0.0, "avg_logprob": -0.16605580996160638, "compression_ratio": 1.601063829787234, "no_speech_prob": 0.004744437988847494}, {"id": 1673, "seek": 942188, "start": 9422.839999999998, "end": 9427.64, "text": " Things that have a long shelf life. Like if you have a choice between like, you know,", "tokens": [50412, 9514, 300, 362, 257, 938, 15222, 993, 13, 1743, 498, 291, 362, 257, 3922, 1296, 411, 11, 291, 458, 11, 50652], "temperature": 0.0, "avg_logprob": -0.16847469029801615, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0016989402938634157}, {"id": 1674, "seek": 942188, "start": 9428.679999999998, "end": 9434.279999999999, "text": " learning, you know, mobile programming on iPhone, or quantum mechanics, take quantum mechanics.", "tokens": [50704, 2539, 11, 291, 458, 11, 6013, 9410, 322, 7252, 11, 420, 13018, 12939, 11, 747, 13018, 12939, 13, 50984], "temperature": 0.0, "avg_logprob": -0.16847469029801615, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0016989402938634157}, {"id": 1675, "seek": 942188, "start": 9437.0, "end": 9443.4, "text": " Because you're going to learn things that you have no idea exist. You may not, you may never be a", "tokens": [51120, 1436, 291, 434, 516, 281, 1466, 721, 300, 291, 362, 572, 1558, 2514, 13, 509, 815, 406, 11, 291, 815, 1128, 312, 257, 51440], "temperature": 0.0, "avg_logprob": -0.16847469029801615, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0016989402938634157}, {"id": 1676, "seek": 942188, "start": 9443.4, "end": 9447.88, "text": " quantum physicist, but you'll learn about path integrals. And path integrals are used", "tokens": [51440, 13018, 42466, 11, 457, 291, 603, 1466, 466, 3100, 3572, 1124, 13, 400, 3100, 3572, 1124, 366, 1143, 51664], "temperature": 0.0, "avg_logprob": -0.16847469029801615, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0016989402938634157}, {"id": 1677, "seek": 944788, "start": 9448.599999999999, "end": 9452.519999999999, "text": " everywhere. It's the same formula that you use for, you know, vision integration and stuff like", "tokens": [50400, 5315, 13, 467, 311, 264, 912, 8513, 300, 291, 764, 337, 11, 291, 458, 11, 5201, 10980, 293, 1507, 411, 50596], "temperature": 0.0, "avg_logprob": -0.17121075500141492, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0025492808781564236}, {"id": 1678, "seek": 944788, "start": 9452.519999999999, "end": 9459.16, "text": " that. So the ideas, the little ideas within quantum mechanics within some of these kind", "tokens": [50596, 300, 13, 407, 264, 3487, 11, 264, 707, 3487, 1951, 13018, 12939, 1951, 512, 295, 613, 733, 50928], "temperature": 0.0, "avg_logprob": -0.17121075500141492, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0025492808781564236}, {"id": 1679, "seek": 944788, "start": 9459.16, "end": 9466.279999999999, "text": " of more solidified fields will have a longer shelf life, they will use somehow use indirectly in your", "tokens": [50928, 295, 544, 5100, 2587, 7909, 486, 362, 257, 2854, 15222, 993, 11, 436, 486, 764, 6063, 764, 37779, 294, 428, 51284], "temperature": 0.0, "avg_logprob": -0.17121075500141492, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0025492808781564236}, {"id": 1680, "seek": 944788, "start": 9466.279999999999, "end": 9472.439999999999, "text": " work. Learn classical mechanics, like you learn about Lagrangians, for example, which is like a", "tokens": [51284, 589, 13, 17216, 13735, 12939, 11, 411, 291, 1466, 466, 24886, 32926, 2567, 11, 337, 1365, 11, 597, 307, 411, 257, 51592], "temperature": 0.0, "avg_logprob": -0.17121075500141492, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0025492808781564236}, {"id": 1681, "seek": 947244, "start": 9472.52, "end": 9477.480000000001, "text": " huge, hugely useful concept, you know, for all kinds of different things. Learn", "tokens": [50368, 2603, 11, 27417, 4420, 3410, 11, 291, 458, 11, 337, 439, 3685, 295, 819, 721, 13, 17216, 50616], "temperature": 0.0, "avg_logprob": -0.21128364370650604, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008515110239386559}, {"id": 1682, "seek": 947244, "start": 9478.36, "end": 9484.12, "text": " statistical physics, because all the math that comes out of, you know, for machine learning,", "tokens": [50660, 22820, 10649, 11, 570, 439, 264, 5221, 300, 1487, 484, 295, 11, 291, 458, 11, 337, 3479, 2539, 11, 50948], "temperature": 0.0, "avg_logprob": -0.21128364370650604, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008515110239386559}, {"id": 1683, "seek": 947244, "start": 9485.4, "end": 9490.2, "text": " basically comes out of what we got out by statistical physicists in the, you know, late 19, early 20th", "tokens": [51012, 1936, 1487, 484, 295, 437, 321, 658, 484, 538, 22820, 48716, 294, 264, 11, 291, 458, 11, 3469, 1294, 11, 2440, 945, 392, 51252], "temperature": 0.0, "avg_logprob": -0.21128364370650604, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008515110239386559}, {"id": 1684, "seek": 947244, "start": 9490.2, "end": 9496.04, "text": " century. Right. So, and for some of them, actually, more recently, by people like George O'Parisi,", "tokens": [51252, 4901, 13, 1779, 13, 407, 11, 293, 337, 512, 295, 552, 11, 767, 11, 544, 3938, 11, 538, 561, 411, 7136, 422, 6, 47, 289, 8021, 11, 51544], "temperature": 0.0, "avg_logprob": -0.21128364370650604, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008515110239386559}, {"id": 1685, "seek": 947244, "start": 9496.04, "end": 9501.640000000001, "text": " who just got the Nobel Prize for the replica method, among other things, it's used for a lot", "tokens": [51544, 567, 445, 658, 264, 24611, 22604, 337, 264, 35456, 3170, 11, 3654, 661, 721, 11, 309, 311, 1143, 337, 257, 688, 51824], "temperature": 0.0, "avg_logprob": -0.21128364370650604, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008515110239386559}, {"id": 1686, "seek": 950164, "start": 9501.64, "end": 9507.4, "text": " of different things, you know, variational inference, that math comes from statistical physics.", "tokens": [50364, 295, 819, 721, 11, 291, 458, 11, 3034, 1478, 38253, 11, 300, 5221, 1487, 490, 22820, 10649, 13, 50652], "temperature": 0.0, "avg_logprob": -0.15015361573961045, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001425527618266642}, {"id": 1687, "seek": 950164, "start": 9508.519999999999, "end": 9515.32, "text": " So, so a lot of those kind of, you know, basic courses, you know, you'll, if you do it", "tokens": [50708, 407, 11, 370, 257, 688, 295, 729, 733, 295, 11, 291, 458, 11, 3875, 7712, 11, 291, 458, 11, 291, 603, 11, 498, 291, 360, 309, 51048], "temperature": 0.0, "avg_logprob": -0.15015361573961045, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001425527618266642}, {"id": 1688, "seek": 950164, "start": 9515.32, "end": 9518.92, "text": " like you're engineering, you take signal processing, you'll learn about Fourier transforms.", "tokens": [51048, 411, 291, 434, 7043, 11, 291, 747, 6358, 9007, 11, 291, 603, 1466, 466, 36810, 35592, 13, 51228], "temperature": 0.0, "avg_logprob": -0.15015361573961045, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001425527618266642}, {"id": 1689, "seek": 950164, "start": 9519.8, "end": 9525.8, "text": " Again, something super useful is at the basis of things like graph neural nets, which is an", "tokens": [51272, 3764, 11, 746, 1687, 4420, 307, 412, 264, 5143, 295, 721, 411, 4295, 18161, 36170, 11, 597, 307, 364, 51572], "temperature": 0.0, "avg_logprob": -0.15015361573961045, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.001425527618266642}, {"id": 1690, "seek": 952580, "start": 9525.8, "end": 9531.64, "text": " entirely new subarea of, you know, AI machine learning, deep learning, which I think is super", "tokens": [50364, 7696, 777, 1422, 35425, 295, 11, 291, 458, 11, 7318, 3479, 2539, 11, 2452, 2539, 11, 597, 286, 519, 307, 1687, 50656], "temperature": 0.0, "avg_logprob": -0.16031218474765993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0010275341337546706}, {"id": 1691, "seek": 952580, "start": 9531.64, "end": 9536.039999999999, "text": " promising for all kinds of applications. Something very promising, if you're more interested in", "tokens": [50656, 20257, 337, 439, 3685, 295, 5821, 13, 6595, 588, 20257, 11, 498, 291, 434, 544, 3102, 294, 50876], "temperature": 0.0, "avg_logprob": -0.16031218474765993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0010275341337546706}, {"id": 1692, "seek": 952580, "start": 9536.039999999999, "end": 9541.88, "text": " applications is the applications of AI machine learning and deep learning to science, or to", "tokens": [50876, 5821, 307, 264, 5821, 295, 7318, 3479, 2539, 293, 2452, 2539, 281, 3497, 11, 420, 281, 51168], "temperature": 0.0, "avg_logprob": -0.16031218474765993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0010275341337546706}, {"id": 1693, "seek": 952580, "start": 9543.24, "end": 9548.519999999999, "text": " science that can help solve big problems in the world. I have colleagues at Meta, at fair,", "tokens": [51236, 3497, 300, 393, 854, 5039, 955, 2740, 294, 264, 1002, 13, 286, 362, 7734, 412, 6377, 64, 11, 412, 3143, 11, 51500], "temperature": 0.0, "avg_logprob": -0.16031218474765993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0010275341337546706}, {"id": 1694, "seek": 952580, "start": 9549.08, "end": 9554.679999999998, "text": " who started this project called Open Catalyst, and it's an open project collaborative. And the", "tokens": [51528, 567, 1409, 341, 1716, 1219, 7238, 9565, 19530, 11, 293, 309, 311, 364, 1269, 1716, 16555, 13, 400, 264, 51808], "temperature": 0.0, "avg_logprob": -0.16031218474765993, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0010275341337546706}, {"id": 1695, "seek": 955468, "start": 9554.68, "end": 9562.36, "text": " idea is to use deep learning to help design new chemical compounds or materials that would", "tokens": [50364, 1558, 307, 281, 764, 2452, 2539, 281, 854, 1715, 777, 7313, 21810, 420, 5319, 300, 576, 50748], "temperature": 0.0, "avg_logprob": -0.079464522803702, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0003088742378167808}, {"id": 1696, "seek": 955468, "start": 9562.36, "end": 9568.92, "text": " facilitate the separation of hydrogen from oxygen. If you can efficiently separate oxygen from hydrogen", "tokens": [50748, 20207, 264, 14634, 295, 12697, 490, 9169, 13, 759, 291, 393, 19621, 4994, 9169, 490, 12697, 51076], "temperature": 0.0, "avg_logprob": -0.079464522803702, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0003088742378167808}, {"id": 1697, "seek": 955468, "start": 9568.92, "end": 9577.24, "text": " with electricity, you solve climate change. It's as simple as that, because you cover,", "tokens": [51076, 365, 10356, 11, 291, 5039, 5659, 1319, 13, 467, 311, 382, 2199, 382, 300, 11, 570, 291, 2060, 11, 51492], "temperature": 0.0, "avg_logprob": -0.079464522803702, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0003088742378167808}, {"id": 1698, "seek": 955468, "start": 9577.24, "end": 9583.32, "text": " you know, some random desert with solar panels, and you have them work all day, produce hydrogen,", "tokens": [51492, 291, 458, 11, 512, 4974, 11029, 365, 7936, 13419, 11, 293, 291, 362, 552, 589, 439, 786, 11, 5258, 12697, 11, 51796], "temperature": 0.0, "avg_logprob": -0.079464522803702, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0003088742378167808}, {"id": 1699, "seek": 958332, "start": 9583.32, "end": 9586.199999999999, "text": " and then you see the hydrogen wherever it's needed. You don't need anything else.", "tokens": [50364, 293, 550, 291, 536, 264, 12697, 8660, 309, 311, 2978, 13, 509, 500, 380, 643, 1340, 1646, 13, 50508], "temperature": 0.0, "avg_logprob": -0.14058644744171495, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0013663691934198141}, {"id": 1700, "seek": 958332, "start": 9588.44, "end": 9599.0, "text": " You know, you have controllable power that can be transported anywhere. So if we have a large-scale,", "tokens": [50620, 509, 458, 11, 291, 362, 45159, 712, 1347, 300, 393, 312, 29373, 4992, 13, 407, 498, 321, 362, 257, 2416, 12, 20033, 11, 51148], "temperature": 0.0, "avg_logprob": -0.14058644744171495, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0013663691934198141}, {"id": 1701, "seek": 958332, "start": 9599.0, "end": 9606.92, "text": " efficient energy storage technology like producing hydrogen, we solve climate change. Here's another", "tokens": [51148, 7148, 2281, 6725, 2899, 411, 10501, 12697, 11, 321, 5039, 5659, 1319, 13, 1692, 311, 1071, 51544], "temperature": 0.0, "avg_logprob": -0.14058644744171495, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0013663691934198141}, {"id": 1702, "seek": 958332, "start": 9606.92, "end": 9611.48, "text": " way to solve climate change is figuring out how to make fusion work. Now, the problem with fusion", "tokens": [51544, 636, 281, 5039, 5659, 1319, 307, 15213, 484, 577, 281, 652, 23100, 589, 13, 823, 11, 264, 1154, 365, 23100, 51772], "temperature": 0.0, "avg_logprob": -0.14058644744171495, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0013663691934198141}, {"id": 1703, "seek": 961148, "start": 9611.48, "end": 9616.119999999999, "text": " is that you make a super hot plasma, and the plasma is unstable, and you can control it.", "tokens": [50364, 307, 300, 291, 652, 257, 1687, 2368, 22564, 11, 293, 264, 22564, 307, 23742, 11, 293, 291, 393, 1969, 309, 13, 50596], "temperature": 0.0, "avg_logprob": -0.12087561791403252, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0034750010818243027}, {"id": 1704, "seek": 961148, "start": 9616.119999999999, "end": 9619.72, "text": " Maybe with deep learning, you can find controllers that will stabilize plasma and make, you know,", "tokens": [50596, 2704, 365, 2452, 2539, 11, 291, 393, 915, 26903, 300, 486, 31870, 22564, 293, 652, 11, 291, 458, 11, 50776], "temperature": 0.0, "avg_logprob": -0.12087561791403252, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0034750010818243027}, {"id": 1705, "seek": 961148, "start": 9619.72, "end": 9624.439999999999, "text": " practical fusion reactors. I mean, that's very speculative, but, you know, it's worth trying,", "tokens": [50776, 8496, 23100, 41649, 13, 286, 914, 11, 300, 311, 588, 49415, 11, 457, 11, 291, 458, 11, 309, 311, 3163, 1382, 11, 51012], "temperature": 0.0, "avg_logprob": -0.12087561791403252, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0034750010818243027}, {"id": 1706, "seek": 961148, "start": 9624.439999999999, "end": 9631.08, "text": " because, you know, the payoff is huge. There's a group at Google working on this led by John Platt.", "tokens": [51012, 570, 11, 291, 458, 11, 264, 46547, 307, 2603, 13, 821, 311, 257, 1594, 412, 3329, 1364, 322, 341, 4684, 538, 2619, 2149, 1591, 13, 51344], "temperature": 0.0, "avg_logprob": -0.12087561791403252, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0034750010818243027}, {"id": 1707, "seek": 961148, "start": 9631.08, "end": 9636.76, "text": " So control, convert as many problems in science and physics and biology and chemistry", "tokens": [51344, 407, 1969, 11, 7620, 382, 867, 2740, 294, 3497, 293, 10649, 293, 14956, 293, 12558, 51628], "temperature": 0.0, "avg_logprob": -0.12087561791403252, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0034750010818243027}, {"id": 1708, "seek": 963676, "start": 9636.76, "end": 9640.92, "text": " into a, into a learnable problem and see if a machine can learn it.", "tokens": [50364, 666, 257, 11, 666, 257, 1466, 712, 1154, 293, 536, 498, 257, 3479, 393, 1466, 309, 13, 50572], "temperature": 0.0, "avg_logprob": -0.13343364101345256, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0014999598497524858}, {"id": 1709, "seek": 963676, "start": 9641.48, "end": 9646.36, "text": " Right. I mean, there's properties of, you know, complex materials that we don't understand from", "tokens": [50600, 1779, 13, 286, 914, 11, 456, 311, 7221, 295, 11, 291, 458, 11, 3997, 5319, 300, 321, 500, 380, 1223, 490, 50844], "temperature": 0.0, "avg_logprob": -0.13343364101345256, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0014999598497524858}, {"id": 1710, "seek": 963676, "start": 9646.36, "end": 9653.72, "text": " first principle, for example. Right. So, you know, if we could design new, you know, new materials,", "tokens": [50844, 700, 8665, 11, 337, 1365, 13, 1779, 13, 407, 11, 291, 458, 11, 498, 321, 727, 1715, 777, 11, 291, 458, 11, 777, 5319, 11, 51212], "temperature": 0.0, "avg_logprob": -0.13343364101345256, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0014999598497524858}, {"id": 1711, "seek": 963676, "start": 9654.6, "end": 9658.92, "text": " we could make more efficient batteries, you know, we could make maybe faster electronics. We could,", "tokens": [51256, 321, 727, 652, 544, 7148, 13070, 11, 291, 458, 11, 321, 727, 652, 1310, 4663, 20611, 13, 492, 727, 11, 51472], "temperature": 0.0, "avg_logprob": -0.13343364101345256, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0014999598497524858}, {"id": 1712, "seek": 963676, "start": 9658.92, "end": 9664.68, "text": " I mean, there's a lot of things we can imagine doing, or, you know, lighter materials for,", "tokens": [51472, 286, 914, 11, 456, 311, 257, 688, 295, 721, 321, 393, 3811, 884, 11, 420, 11, 291, 458, 11, 11546, 5319, 337, 11, 51760], "temperature": 0.0, "avg_logprob": -0.13343364101345256, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0014999598497524858}, {"id": 1713, "seek": 966468, "start": 9664.68, "end": 9668.36, "text": " for cars or airplanes or things like that, maybe better fuel cells. I mean, there's all kinds of", "tokens": [50364, 337, 5163, 420, 32947, 420, 721, 411, 300, 11, 1310, 1101, 6616, 5438, 13, 286, 914, 11, 456, 311, 439, 3685, 295, 50548], "temperature": 0.0, "avg_logprob": -0.1313970440723857, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.001866171252913773}, {"id": 1714, "seek": 966468, "start": 9668.36, "end": 9673.08, "text": " stuff we can imagine. If we had good fuel cells, hydrogen fuel cells, we could use them to power", "tokens": [50548, 1507, 321, 393, 3811, 13, 759, 321, 632, 665, 6616, 5438, 11, 12697, 6616, 5438, 11, 321, 727, 764, 552, 281, 1347, 50784], "temperature": 0.0, "avg_logprob": -0.1313970440723857, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.001866171252913773}, {"id": 1715, "seek": 966468, "start": 9673.08, "end": 9679.4, "text": " airplanes, and, you know, transportation wouldn't be, or cars, and we wouldn't have a emission", "tokens": [50784, 32947, 11, 293, 11, 291, 458, 11, 11328, 2759, 380, 312, 11, 420, 5163, 11, 293, 321, 2759, 380, 362, 257, 29513, 51100], "temperature": 0.0, "avg_logprob": -0.1313970440723857, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.001866171252913773}, {"id": 1716, "seek": 966468, "start": 9679.4, "end": 9685.880000000001, "text": " problem, CO2 emission problems for, for air transportation anymore. So there's a lot of", "tokens": [51100, 1154, 11, 3002, 17, 29513, 2740, 337, 11, 337, 1988, 11328, 3602, 13, 407, 456, 311, 257, 688, 295, 51424], "temperature": 0.0, "avg_logprob": -0.1313970440723857, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.001866171252913773}, {"id": 1717, "seek": 966468, "start": 9685.880000000001, "end": 9692.04, "text": " those things, I think, where AI, you know, can be used. And this is not even talking about all the", "tokens": [51424, 729, 721, 11, 286, 519, 11, 689, 7318, 11, 291, 458, 11, 393, 312, 1143, 13, 400, 341, 307, 406, 754, 1417, 466, 439, 264, 51732], "temperature": 0.0, "avg_logprob": -0.1313970440723857, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.001866171252913773}, {"id": 1718, "seek": 969204, "start": 9692.04, "end": 9697.720000000001, "text": " sort of medicine biology and everything like that, right? You know, like protein folding,", "tokens": [50364, 1333, 295, 7195, 14956, 293, 1203, 411, 300, 11, 558, 30, 509, 458, 11, 411, 7944, 25335, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1296385389859559, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.002465822035446763}, {"id": 1719, "seek": 969204, "start": 9697.720000000001, "end": 9701.800000000001, "text": " you know, figuring out, like, how could you design your proteins, that it sticks to another protein", "tokens": [50648, 291, 458, 11, 15213, 484, 11, 411, 11, 577, 727, 291, 1715, 428, 15577, 11, 300, 309, 12518, 281, 1071, 7944, 50852], "temperature": 0.0, "avg_logprob": -0.1296385389859559, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.002465822035446763}, {"id": 1720, "seek": 969204, "start": 9701.800000000001, "end": 9707.0, "text": " that a particular site, because that's how you design drugs in the end. So, you know, deep learning", "tokens": [50852, 300, 257, 1729, 3621, 11, 570, 300, 311, 577, 291, 1715, 7766, 294, 264, 917, 13, 407, 11, 291, 458, 11, 2452, 2539, 51112], "temperature": 0.0, "avg_logprob": -0.1296385389859559, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.002465822035446763}, {"id": 1721, "seek": 969204, "start": 9707.0, "end": 9711.080000000002, "text": " would be useful, all of this. And those are kind of, you know, would be sort of enormous progress", "tokens": [51112, 576, 312, 4420, 11, 439, 295, 341, 13, 400, 729, 366, 733, 295, 11, 291, 458, 11, 576, 312, 1333, 295, 11322, 4205, 51316], "temperature": 0.0, "avg_logprob": -0.1296385389859559, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.002465822035446763}, {"id": 1722, "seek": 969204, "start": 9711.080000000002, "end": 9718.2, "text": " if we could use it for that. Here's an example. If you take, this is like from recent material physics,", "tokens": [51316, 498, 321, 727, 764, 309, 337, 300, 13, 1692, 311, 364, 1365, 13, 759, 291, 747, 11, 341, 307, 411, 490, 5162, 2527, 10649, 11, 51672], "temperature": 0.0, "avg_logprob": -0.1296385389859559, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.002465822035446763}, {"id": 1723, "seek": 971820, "start": 9718.2, "end": 9725.560000000001, "text": " you take a monoatomic layer of graphene, right? So it's just carbon on an hexagonal mesh, and you", "tokens": [50364, 291, 747, 257, 35624, 267, 21401, 4583, 295, 4295, 1450, 11, 558, 30, 407, 309, 311, 445, 5954, 322, 364, 23291, 6709, 304, 17407, 11, 293, 291, 50732], "temperature": 0.0, "avg_logprob": -0.12431940406259864, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0017541164997965097}, {"id": 1724, "seek": 971820, "start": 9725.560000000001, "end": 9731.640000000001, "text": " make this single, single atom thick. You put another one on top, you twist them by some magic", "tokens": [50732, 652, 341, 2167, 11, 2167, 12018, 5060, 13, 509, 829, 1071, 472, 322, 1192, 11, 291, 8203, 552, 538, 512, 5585, 51036], "temperature": 0.0, "avg_logprob": -0.12431940406259864, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0017541164997965097}, {"id": 1725, "seek": 971820, "start": 9732.28, "end": 9737.960000000001, "text": " number of degrees, three degrees or something. It becomes superconductor. Nobody has any idea why.", "tokens": [51068, 1230, 295, 5310, 11, 1045, 5310, 420, 746, 13, 467, 3643, 1687, 18882, 84, 1672, 13, 9297, 575, 604, 1558, 983, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12431940406259864, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0017541164997965097}, {"id": 1726, "seek": 971820, "start": 9741.08, "end": 9743.800000000001, "text": " I want to know how that was discovered, but that's the kind of thing that machine learning", "tokens": [51508, 286, 528, 281, 458, 577, 300, 390, 6941, 11, 457, 300, 311, 264, 733, 295, 551, 300, 3479, 2539, 51644], "temperature": 0.0, "avg_logprob": -0.12431940406259864, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0017541164997965097}, {"id": 1727, "seek": 974380, "start": 9743.8, "end": 9749.32, "text": " can actually discover, these kinds of things. Well, maybe not, but there is a hint, perhaps, that", "tokens": [50364, 393, 767, 4411, 11, 613, 3685, 295, 721, 13, 1042, 11, 1310, 406, 11, 457, 456, 307, 257, 12075, 11, 4317, 11, 300, 50640], "temperature": 0.0, "avg_logprob": -0.14721942397783389, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.004977202508598566}, {"id": 1728, "seek": 974380, "start": 9749.32, "end": 9755.48, "text": " with machine learning, we would train a system to basically be a phenomenological model of some", "tokens": [50640, 365, 3479, 2539, 11, 321, 576, 3847, 257, 1185, 281, 1936, 312, 257, 9388, 4383, 2316, 295, 512, 50948], "temperature": 0.0, "avg_logprob": -0.14721942397783389, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.004977202508598566}, {"id": 1729, "seek": 974380, "start": 9755.48, "end": 9760.119999999999, "text": " complex emergent phenomenon, which, you know, superconductivity is one of those,", "tokens": [50948, 3997, 4345, 6930, 14029, 11, 597, 11, 291, 458, 11, 1687, 38150, 4253, 307, 472, 295, 729, 11, 51180], "temperature": 0.0, "avg_logprob": -0.14721942397783389, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.004977202508598566}, {"id": 1730, "seek": 974380, "start": 9762.359999999999, "end": 9766.84, "text": " where, you know, this collective phenomenon is too difficult to describe from first principles", "tokens": [51292, 689, 11, 291, 458, 11, 341, 12590, 14029, 307, 886, 2252, 281, 6786, 490, 700, 9156, 51516], "temperature": 0.0, "avg_logprob": -0.14721942397783389, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.004977202508598566}, {"id": 1731, "seek": 974380, "start": 9766.84, "end": 9772.679999999998, "text": " with the current, you know, the usual sort of reductionist type method. But we could have", "tokens": [51516, 365, 264, 2190, 11, 291, 458, 11, 264, 7713, 1333, 295, 11004, 468, 2010, 3170, 13, 583, 321, 727, 362, 51808], "temperature": 0.0, "avg_logprob": -0.14721942397783389, "compression_ratio": 1.6813186813186813, "no_speech_prob": 0.004977202508598566}, {"id": 1732, "seek": 977380, "start": 9774.039999999999, "end": 9779.48, "text": " deep learning systems that predict the properties of a system from a description of it after being", "tokens": [50376, 2452, 2539, 3652, 300, 6069, 264, 7221, 295, 257, 1185, 490, 257, 3855, 295, 309, 934, 885, 50648], "temperature": 0.0, "avg_logprob": -0.16177941546028043, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.0013333411188796163}, {"id": 1733, "seek": 977380, "start": 9779.48, "end": 9788.759999999998, "text": " trained with sufficiently many samples. This guy, Pascal Foua at DPFL, he has a startup company that", "tokens": [50648, 8895, 365, 31868, 867, 10938, 13, 639, 2146, 11, 41723, 479, 263, 64, 412, 42796, 31455, 11, 415, 575, 257, 18578, 2237, 300, 51112], "temperature": 0.0, "avg_logprob": -0.16177941546028043, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.0013333411188796163}, {"id": 1734, "seek": 977380, "start": 9789.64, "end": 9795.96, "text": " where he basically trained a convolutional net essentially to predict the aerodynamic", "tokens": [51156, 689, 415, 1936, 8895, 257, 45216, 304, 2533, 4476, 281, 6069, 264, 11207, 34988, 51472], "temperature": 0.0, "avg_logprob": -0.16177941546028043, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.0013333411188796163}, {"id": 1735, "seek": 977380, "start": 9795.96, "end": 9800.519999999999, "text": " properties of solids. And you can generate as much data as you want by just running", "tokens": [51472, 7221, 295, 38536, 13, 400, 291, 393, 8460, 382, 709, 1412, 382, 291, 528, 538, 445, 2614, 51700], "temperature": 0.0, "avg_logprob": -0.16177941546028043, "compression_ratio": 1.5905172413793103, "no_speech_prob": 0.0013333411188796163}, {"id": 1736, "seek": 980052, "start": 9800.52, "end": 9808.6, "text": " a computational free dynamics, right? So you give, like, a wing, a foil or something shape", "tokens": [50364, 257, 28270, 1737, 15679, 11, 558, 30, 407, 291, 976, 11, 411, 11, 257, 11162, 11, 257, 22444, 420, 746, 3909, 50768], "temperature": 0.0, "avg_logprob": -0.14889348454836035, "compression_ratio": 1.795275590551181, "no_speech_prob": 0.0011655117850750685}, {"id": 1737, "seek": 980052, "start": 9808.6, "end": 9814.44, "text": " of some kind, and you run computational free dynamics, you get, as a result, the drag and,", "tokens": [50768, 295, 512, 733, 11, 293, 291, 1190, 28270, 1737, 15679, 11, 291, 483, 11, 382, 257, 1874, 11, 264, 5286, 293, 11, 51060], "temperature": 0.0, "avg_logprob": -0.14889348454836035, "compression_ratio": 1.795275590551181, "no_speech_prob": 0.0011655117850750685}, {"id": 1738, "seek": 980052, "start": 9814.44, "end": 9820.6, "text": " you know, lift and all that stuff, right? And you can generate lots of data, train a neural", "tokens": [51060, 291, 458, 11, 5533, 293, 439, 300, 1507, 11, 558, 30, 400, 291, 393, 8460, 3195, 295, 1412, 11, 3847, 257, 18161, 51368], "temperature": 0.0, "avg_logprob": -0.14889348454836035, "compression_ratio": 1.795275590551181, "no_speech_prob": 0.0011655117850750685}, {"id": 1739, "seek": 980052, "start": 9820.6, "end": 9825.24, "text": " net to make those predictions. And now what you have is a differentiable model of, let's say,", "tokens": [51368, 2533, 281, 652, 729, 21264, 13, 400, 586, 437, 291, 362, 307, 257, 819, 9364, 2316, 295, 11, 718, 311, 584, 11, 51600], "temperature": 0.0, "avg_logprob": -0.14889348454836035, "compression_ratio": 1.795275590551181, "no_speech_prob": 0.0011655117850750685}, {"id": 1740, "seek": 980052, "start": 9825.24, "end": 9829.560000000001, "text": " drag and lift as a function of the shape of that solid. And so you can do background and", "tokens": [51600, 5286, 293, 5533, 382, 257, 2445, 295, 264, 3909, 295, 300, 5100, 13, 400, 370, 291, 393, 360, 3678, 293, 51816], "temperature": 0.0, "avg_logprob": -0.14889348454836035, "compression_ratio": 1.795275590551181, "no_speech_prob": 0.0011655117850750685}, {"id": 1741, "seek": 982956, "start": 9829.56, "end": 9832.68, "text": " design, you can optimize the shape, so you get the properties you want.", "tokens": [50364, 1715, 11, 291, 393, 19719, 264, 3909, 11, 370, 291, 483, 264, 7221, 291, 528, 13, 50520], "temperature": 0.0, "avg_logprob": -0.14828617459251767, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.0016734737437218428}, {"id": 1742, "seek": 982956, "start": 9834.68, "end": 9840.199999999999, "text": " Yeah, that's incredible. That's incredible. And on top of all that, probably, you should read a", "tokens": [50620, 865, 11, 300, 311, 4651, 13, 663, 311, 4651, 13, 400, 322, 1192, 295, 439, 300, 11, 1391, 11, 291, 820, 1401, 257, 50896], "temperature": 0.0, "avg_logprob": -0.14828617459251767, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.0016734737437218428}, {"id": 1743, "seek": 982956, "start": 9840.199999999999, "end": 9846.76, "text": " little bit of literature and a little bit of history for inspiration and for wisdom, because", "tokens": [50896, 707, 857, 295, 10394, 293, 257, 707, 857, 295, 2503, 337, 10249, 293, 337, 10712, 11, 570, 51224], "temperature": 0.0, "avg_logprob": -0.14828617459251767, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.0016734737437218428}, {"id": 1744, "seek": 982956, "start": 9846.76, "end": 9851.64, "text": " after all, all of these technologies will have to work in a human world. And the human world is", "tokens": [51224, 934, 439, 11, 439, 295, 613, 7943, 486, 362, 281, 589, 294, 257, 1952, 1002, 13, 400, 264, 1952, 1002, 307, 51468], "temperature": 0.0, "avg_logprob": -0.14828617459251767, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.0016734737437218428}, {"id": 1745, "seek": 982956, "start": 9851.64, "end": 9859.24, "text": " complicated. Yeah, and this is an amazing conversation. I really honored that you", "tokens": [51468, 6179, 13, 865, 11, 293, 341, 307, 364, 2243, 3761, 13, 286, 534, 14556, 300, 291, 51848], "temperature": 0.0, "avg_logprob": -0.14828617459251767, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.0016734737437218428}, {"id": 1746, "seek": 985924, "start": 9859.32, "end": 9863.16, "text": " talked with me today. Thank you for all the amazing work you're doing at FAIR at Metta.", "tokens": [50368, 2825, 365, 385, 965, 13, 1044, 291, 337, 439, 264, 2243, 589, 291, 434, 884, 412, 19894, 7740, 412, 6377, 1328, 13, 50560], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1747, "seek": 985924, "start": 9863.72, "end": 9868.68, "text": " And thank you for being so passionate after all these years about everything that's going on.", "tokens": [50588, 400, 1309, 291, 337, 885, 370, 11410, 934, 439, 613, 924, 466, 1203, 300, 311, 516, 322, 13, 50836], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1748, "seek": 985924, "start": 9868.68, "end": 9872.6, "text": " You're a beacon of hope for the machine learning community. And thank you so much", "tokens": [50836, 509, 434, 257, 41669, 295, 1454, 337, 264, 3479, 2539, 1768, 13, 400, 1309, 291, 370, 709, 51032], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1749, "seek": 985924, "start": 9872.6, "end": 9875.08, "text": " for spending your valuable time with me today. That was awesome.", "tokens": [51032, 337, 6434, 428, 8263, 565, 365, 385, 965, 13, 663, 390, 3476, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1750, "seek": 985924, "start": 9875.08, "end": 9877.48, "text": " Thanks for having me on. That was a pleasure.", "tokens": [51156, 2561, 337, 1419, 385, 322, 13, 663, 390, 257, 6834, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1751, "seek": 985924, "start": 9878.68, "end": 9882.68, "text": " Thanks for listening to this conversation with Yann LeCun. To support this podcast,", "tokens": [51336, 2561, 337, 4764, 281, 341, 3761, 365, 398, 969, 1456, 34, 409, 13, 1407, 1406, 341, 7367, 11, 51536], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1752, "seek": 985924, "start": 9882.68, "end": 9888.68, "text": " please check out our sponsors in the description. And now let me leave you some words from Isaac", "tokens": [51536, 1767, 1520, 484, 527, 22593, 294, 264, 3855, 13, 400, 586, 718, 385, 1856, 291, 512, 2283, 490, 22505, 51836], "temperature": 0.0, "avg_logprob": -0.1366675362658145, "compression_ratio": 1.7845659163987138, "no_speech_prob": 0.022918928414583206}, {"id": 1753, "seek": 988868, "start": 9888.68, "end": 9895.880000000001, "text": " Asimov. Your assumptions are your windows on the world. Scrub them off every once in a while,", "tokens": [50364, 1018, 332, 5179, 13, 2260, 17695, 366, 428, 9309, 322, 264, 1002, 13, 34944, 836, 552, 766, 633, 1564, 294, 257, 1339, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1636916697025299, "compression_ratio": 1.3037037037037038, "no_speech_prob": 0.02225521020591259}, {"id": 1754, "seek": 988868, "start": 9895.880000000001, "end": 9904.6, "text": " or the light won't come in. Thank you for listening and hope to see you next time.", "tokens": [50724, 420, 264, 1442, 1582, 380, 808, 294, 13, 1044, 291, 337, 4764, 293, 1454, 281, 536, 291, 958, 565, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1636916697025299, "compression_ratio": 1.3037037037037038, "no_speech_prob": 0.02225521020591259}], "language": "en"}