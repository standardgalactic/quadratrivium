start	end	text
0	4160	The following is a conversation with Chris Lattner, his second time in the podcast.
4720	8720	He's one of the most brilliant engineers in modern computing, having created
8720	14640	LLVM compiler infrastructure project, the Clang Compiler, the Swift programming language,
14640	19040	a lot of key contributions to TensorFlow and TPUs as part of Google.
19040	25440	He served as vice president of autopilot software at Tesla, was a software innovator and leader at
26160	32480	and now is at SyFive as senior vice president of platform engineering looking to revolutionize
32480	38160	chip design to make it faster, better, and cheaper. Quick mention of each sponsor,
38160	42320	followed by some thoughts related to the episode. First sponsor is Blinkist,
42320	47280	an app that summarizes key ideas from thousands of books. I use it almost every day to learn new
47280	53840	things or to pick which books I want to read or listen to next. Second is Nero,
53840	58400	the maker of functional sugar-free gum and mints that I use to supercharge my mind
58400	65840	with caffeine, Althianine, and B vitamins. Third is Masterclass, online courses from the best people
65840	72480	in the world on each of the topics covered from rockets to game design to poker to writing and
72480	78480	to guitar. And finally, Cash App, the app I use to send money to friends for food,
78480	83600	drinks, and unfortunately lost bets. Please check out the sponsors in the description
83600	89840	to get a discount and to support this podcast. As a side note, let me say that Chris has been an
89840	95760	inspiration to me on a human level because he is so damn good as an engineer and leader of
95760	100960	engineers and yet he's able to stay humble, especially humble enough to hear the voices
100960	106560	of disagreement and to learn from them. He was supportive of me and this podcast from the early
106560	112160	days and for that, I'm forever grateful. To be honest, most of my life, no one really believed
112160	117600	that I would amount to much. So when another human being looks at me and makes me feel like I might
117600	123760	be someone special, it can be truly inspiring. That's a lesson for educators. The weird kid in
123760	129280	the corner with a dream is someone who might need your love and support in order for that dream to
129280	134560	flourish. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple
134560	140560	Podcasts, follow on Spotify, support on Patreon, or connect with me on Twitter at Lex Freedman.
141280	144560	And now here's my conversation with Chris Latner.
145760	152160	What are the strongest qualities of Steve Jobs, Elon Musk, and the great and powerful
152160	155040	Jeff Dean since you've gotten the chance to work with each?
155920	161120	You're starting with an easy question there. These are three very different people. I guess
161120	165680	you could do maybe a pairwise comparison between them instead of a group comparison.
165680	170080	So if you look at Steve Jobs and Elon, I worked a lot more with Elon than I did with Steve.
170880	176000	They have a lot of commonality. They're both visionary in their own way. They're both very
176000	183120	demanding in their own way. My sense is Steve is much more human factor focused, where Elon is
183120	188000	more technology focused. What does human factor mean? Steve's trying to build things that feel
188000	194240	good, that people love, that affect people's lives, how they live. He's looking into the future a
194240	200640	little bit in terms of what people want, where I think that Elon focuses more on learning how
200640	206400	exponentials work and predicting the development of those. Steve worked a lot of engineers. That was
206400	213200	one of the things that reading the biography and how can a designer essentially talk to engineers
213200	218560	and get their respect? I did not work very closely with Steve. I'm not an expert at all.
218560	223760	My sense is that he pushed people really hard, but then when he got an explanation that made sense to
223760	230720	him, then he would let go. He did actually have a lot of respect for engineering, but he also knew
230720	237200	when to push. When you can read people well, you can know when they're holding back and when you
237200	242800	can get a little bit more out of them. I think he was very good at that. If you compare the other
242800	251840	folks, Jeff Dean is an amazing guy. He's super smart, as are the other guys. Jeff is a really,
251840	258880	really nice guy, well-meaning. He's a classic Googler. He wants people to be happy. He combines
258880	263760	it with brilliance so he can pull people together in a really great way. He's definitely not a CEO
263760	270480	type. I don't think he would even want to be that. If he still programs. He definitely programs.
270480	276160	Jeff is an amazing engineer today, and that has never changed. It's really hard to compare Jeff
276160	284880	to either of those two. I think that Jeff leads through technology and building it himself and
284880	290560	then pulling people in and inspiring them. I think that that's one of the amazing things about Jeff.
290560	295520	But each of these people, with their pros and cons, all are really inspirational and have achieved
295520	300640	amazing things. I've been very fortunate to get to work with these guys.
300640	307040	For yourself, you've led large teams. You've done so many incredible, difficult technical
307040	312480	challenges. Is there something you've picked up from them about how to lead?
312480	316080	Yeah. I think leadership is really hard. It really depends on what you're looking for there.
317040	322080	I think you really need to know what you're talking about. Being grounded on the product,
322160	326000	on the technology, on the business, on the mission is really important.
327040	331520	Being, understanding what people are looking for, why they're there. One of the most amazing
331520	336480	things about Tesla is the unifying vision. People are there because they believe in
336480	339360	clean energy and electrification and all these kinds of things.
341840	345760	The other is to understand what really motivates people, how to get the best people,
345760	349600	how to build a plan that actually can be executed. There's so many different
349600	353360	aspects of leadership and it really depends on the time, the place, the problems.
354880	358560	There's a lot of issues that don't need to be solved. If you focus on the right things and
358560	361440	prioritize well, that can really help move things.
361440	365360	Two interesting things you mentioned. One is you really have to know what you're talking about.
369200	371600	You've worked on a lot of very challenging technical things.
372160	379920	I assume you were born technically savvy, but I assume that's not the case.
381200	387760	How did you develop technical expertise? Even at Google, you worked on, I don't know,
387760	391280	how many projects, but really challenging, very varied.
392160	395440	Compilers, TPUs, hardware, cloud stuff, a bunch of different things.
396320	404240	The thing that I've become more comfortable with as I've gained experience is being okay
404240	410720	with not knowing. A major part of leadership is actually it's not about having the right answer,
410720	415120	it's about getting the right answer. If you're working in a team of amazing people,
416240	420160	and many of these places, many of these companies all have amazing people,
420160	424000	it's the question of how do you get people together? How do you build trust?
424080	430480	How do you get people to open up? How do you get people to be vulnerable sometimes with an idea
430480	434240	that maybe isn't good enough, but it's the start of something beautiful? How do you
436400	440400	provide an environment where you're not just top-down, don't do the thing that I tell you to
440400	446640	do, but you're encouraging people to be part of the solution, and providing a safe space where
446640	448960	if you're not doing the right thing, they're willing to tell you about it?
449520	451200	So you're asking dumb questions?
451200	455760	Oh yeah, dumb questions are my specialty. So I've been in the hardware realm recently,
455760	459920	and I don't know much at all about how chips are designed. I know a lot about using them.
459920	465600	I know some of the principles and the arse technical level of this, but it turns out that
465600	470000	if you ask a lot of dumb questions, you get smarter really quick. And when you're surrounded by
470000	473840	people that want to teach and learn themselves, it can be a beautiful thing.
474800	480800	So let's talk about programming languages, if it's okay, at the highest absurd philosophical
480800	488400	level. Don't get romantic on me, Lex. I will forever get romantic and torture you. I apologize.
490320	493120	Why do programming languages even matter?
494080	497840	Okay, well, thank you very much. So you're saying why should you care about any one
497840	500960	programming language, or why do we care about programming computers?
500960	507520	No, why do we care about programming language design, creating effective programming languages,
510080	513920	choosing a, you know, one program languages versus another programming language,
514560	519680	why we keep struggling and improving through the evolution of these programming languages?
519680	523360	Sure, sure. Okay, so I mean, I think you have to come back to what are we trying to do here,
523360	528160	right? So we have these these beasts called computers that are very good at specific
528160	533200	kinds of things, and we think it's useful to have them do it for us, right? Now, you have this
533200	538000	question of how best to express that, because you have a human brain still that has an idea in its
538000	543840	head, and you want to achieve something. So, well, there's lots of ways of doing this. You can go
543840	547760	directly to the machine and speak assembly language, and then you can express directly what the
547760	553440	computer understands. That's fine. You can then have higher and higher and higher levels of abstraction
553440	556960	up until machine learning, and you're designing a neural net to do the work for you.
558000	562800	The question is, where, where along this way do you want to stop? And what benefits do you get out
562800	568080	of doing so? And so programming languages in general, you have C, you have Fortran, Java, and
569120	574320	Ada, Pascal, Swift, you have lots of different things. They'll have different tradeoffs, and
574320	579040	they're tackling different parts of the problems. Now, one of the things that most programming
579040	583520	languages do is they're trying to make it so that you have pretty basic things like portability
583520	588000	across different hardware. So you've got, I'm going to run on an Intel PC, I'm going to run on a
588000	594080	RISC-5 PC, I'm going to run on an ARM phone or something like that. Fine. I want to write one
594080	598960	program and have it portable, and this is something the assembly doesn't do. Now, when you start looking
598960	604960	at the space of programming languages, this is where I think it's fun, because programming languages
604960	610480	all have tradeoffs, and most people will walk up to them and they look at the surface level of syntax
610480	616320	and say, oh, I like curly braces, or I like tabs, or I like, you know, semicolons or not,
616320	622320	or whatever, right? Subject, fairly subjective, very shallow things. But programming languages,
622320	629120	when done right, can actually be very powerful. And the, the benefit they bring is expression.
630080	633920	Okay. And if you look at programming languages, there's really kind of two different levels
633920	639200	to them. One is the down-in-the-dirt nuts and bolts of how do you get the computer to be efficient,
639200	644080	stuff like that, how they work, type systems, compiler stuff, things like that. The other is
644080	649440	the UI. And the UI for programming language is really a design problem, and a lot of people don't
649440	654160	think about it that way. And the UI, you mean all that stuff with the braces and... Yeah, all that
654160	660240	stuff's the UI, and what it is, and UI means user interface. And so what, what's really going on is
660320	667040	it's the interface between the guts and the human. And humans are hard, right? Humans have
667920	671600	feelings, they have things they like, they have things they don't like. And a lot of people
671600	676640	treat programming languages as though humans are just kind of abstract creatures that cannot be
676640	682560	predicted. But it turns out that actually there are, there is better and worse. Like, people can
682560	688400	tell when a program language is good or when it was an accident, right? And one of the things
688400	693120	with Swift in particular is that a tremendous amount of time by a tremendous number of people
693120	697920	has been put into really polishing and making it feel good. But it also has really good nuts and
697920	704000	bolts underneath it. You said that Swift makes a lot of people feel good. How do you get to that
704000	712720	point? So how do you predict that, you know, tens of thousands, hundreds of thousands of people
712720	717600	are going to enjoy using this, the user experience of this programming language? Well, you can,
717600	720960	you can look at it in terms of better and worse, right? So if you have to write lots of boiler
720960	725200	plate or something like that, you will feel unproductive. And so that's a bad thing. You can
725200	729920	look at it in terms of safety. If like C, for example, is what's called a memory unsafe language.
729920	733840	And so you get dangling pointers, and you get all these kinds of bugs that then you have spent
733840	738160	tons of time debugging, it's a real pain in the butt. And you feel unproductive. And so by
738160	744000	subtracting these things from the experience, you get, you know, happier people. But again,
744080	747440	keep interrupting. I'm sorry. It's so hard to deal with.
749120	752800	If you look at the people, people that are most productive on Stack Overflow,
754080	760080	they are, they have a set of priorities that may not always correlate perfectly with the
760080	766800	experience of the majority of users. You know, if you look at the most upvoted, quote unquote,
766800	777040	correct answer on Stack Overflow is usually really sort of prioritizes like safe code,
777040	783600	proper code, stable code, you know, that kind of stuff, as opposed to like, if I want to use
783600	791760	go to statements in my basic, right, I want to use go to state, like what if 99% of people want
791760	795920	to use go to statements are used completely improper, you know, unsafe syntax.
796480	800080	I don't think that people actually like if you boil it down, you get below the surface level,
800080	804720	people don't actually care about go tos or if statements or things like this, they care about
804720	809840	achieving a goal. Yeah. Right. So the real question is, I want to set up a web server,
809840	814880	and I want to do a thing, whatever, like how, how quickly can I achieve that? Right. And so the
814880	819360	from programming language perspective, there's really two things that matter there. One is
820000	825440	what libraries exist? And then how quickly can you put it together? And what are the tools around
825440	830320	that look like? Right. And, and when you want to build a library that's missing, what do you do?
830320	836240	Okay. Now, this is where you see huge divergence in the force between worlds. Okay. And so you
836240	840400	look at Python, for example, Python is really good at assembling things, but it's not so great
840400	844800	at building all the libraries. And so you get because of performance reasons, other things like
844800	850560	this, as you get Python layered on top of C, for example, and that means that doing certain
850560	854400	kinds of things, well, it doesn't really make sense to do in Python. Instead, you do it in C,
854400	858560	and then you wrap it and then you have, you're living in two worlds and two worlds never is
858560	863040	really great because tooling and the debugger doesn't work right and like all these kinds of things.
863680	868480	Can you clarify a little bit what, what do you mean by Python is not good at building libraries,
868480	873520	meaning it doesn't make it conducive? Certain kinds of libraries. No, but it's just the actual
873520	879280	meaning of the sentence. Yeah. Meaning like it's not conducive to developers to come in and add
879280	885680	libraries, or it's, it's, or the language, or is it the, the duality of the, it's a dance between
886560	891040	Python and C and... Well, so Python's amazing. Python's a great language. I do not mean to say
891040	896800	that Python is bad for libraries. What I meant to say is, they're Python, they're libraries that
896800	901440	Python's really good at, that you can write in Python. But there are other things like if you
901440	904640	want to build a machine learning framework, you're not going to build a machine learning
904640	909440	framework in Python because of performance, for example, or you want GPU acceleration or
909440	914320	things like this. Instead, what you do is you write a bunch of C or C++ code or something
914320	921120	like that, and then you talk to it from Python. Right. And so this is because of decisions that
921120	927120	were made in the Python design and, and those decisions have other counterbalancing forces.
927120	931280	But, but the trick when you start looking at this from a programming language perspective,
931280	937040	you sort of say, okay, cool, how do I build this catalog of libraries that are really powerful?
937680	942480	And how do I make it so that then they can be assembled into ways that feel good and they
942480	947120	generally work the first time? Because when you're talking about building a thing, you have to
947120	952400	include the debugging, the fixing, the turnaround cycle, the development cycle, all that kind of
952400	958320	stuff in, in, into the process of building the thing. It's not just about pounding out the code.
958320	962400	And so this is where things like, you know, catching bugs at compile time is valuable,
962400	969360	for example. But if you dive into the details in this, Swift, for example, has certain things
969360	975440	like value semantics, which is this fancy way of saying that when you treat a treat a variable
975440	984400	like a value, it acts like a mathematical object would. Okay, so in you have used PyTorch a little
984400	991840	bit. In PyTorch, you have tensors, tensors are any n dimensional grid of numbers. Very simple,
991840	996800	you can do plus and other operators on them. It's all totally fine. But why do you need to clone
996800	1002960	a tensor sometimes? Have you ever run into that? Yeah. Okay. And so why is that? Why do you need
1002960	1008880	to clone a tensor? It's the usual object thing that's in Python. So in Python, and just like with
1008880	1012720	Java and many other languages, this isn't unique to Python. In Python, it has a thing called
1012720	1016960	reference semantics, which is the nerdy way of explaining this. And what that means is you
1016960	1023680	actually have a pointer do a thing instead of the thing. Okay. Now, this is due to a bunch of
1023680	1028560	implementation details that you don't want to go into. But in Swift, you have this thing called
1028560	1033280	value semantics. And so when you have a tensor in Swift, it is a value. If you copy it, it looks
1033280	1038880	like you have a unique copy. And if you go change one of those copies, then it doesn't update the
1038880	1043680	other one, because you just made a copy of this thing. Right. So that's like highly error prone.
1044320	1051120	In at least computer science math centric disciplines about Python, that like the
1052000	1058400	the thing you would expect to behave like math, like math, it doesn't behave like math. And in
1058400	1063840	fact, quietly, it doesn't behave like math and then can ruin the entirety of your math. Exactly.
1063840	1067920	Well, and then it puts you in debugging land again. Yeah. Right. Now, now you just want to get
1067920	1071440	something done. And you're like, wait a second, where do I need, where do I need to put clone?
1071440	1076160	And what level of the stack, which is very complicated, which I thought I was using somebody's
1076160	1080560	library. And now I need to understand it to know where to clone a thing. Right. And hard to debug,
1080560	1084480	by the way. Exactly. Right. And so this is where programming languages really matter. Right. And
1084480	1090960	so in Swift, having value semantics, so that both you get the benefit of math, working like math,
1091680	1095680	right. But also the efficiency that comes with certain advantages there,
1095680	1099040	certain implementation details that really benefit you as a programmer. Right. So
1101040	1107200	how do you know that a thing should be treated like value? Yeah. So Swift has a pretty strong
1107200	1112560	culture and good language support for defining values. And so if you have an array, so tensors
1112560	1117680	are one example that the machine learning folks are very used to. Just think about arrays, same
1117680	1122960	thing, where you have an array, you put, you create an array, you put two or three or four
1122960	1129680	things into it, and then you pass it off to another function. What happens if that function
1129680	1134560	adds some more things to it? Well, you'll see it on the side that you pass it in. Right. This is
1134560	1142080	called reference semantics. Now, what if you pass an array off to a function? It scrolls it away in
1142080	1146160	some dictionary or some other data structure somewhere. Right. Well, it thought that you just
1146160	1151600	handed it that array. Then you return back and that reference to that array still exists in the
1151600	1158160	caller. And they go and put more stuff in it. Right. The person you handed it off to may have
1158160	1162720	thought they had the only reference to that. And so they didn't know that this was going to change
1162800	1167440	underneath the covers. And so this is where you end up having to do clone. So like, I was past a
1167440	1172720	thing, I'm not sure if I have the only version of it. So now I have to clone it. So what value
1172720	1178320	semantics does is it allows you to say, hey, I have a, so in Swift, it defaults to value semantics.
1178320	1184960	Also defaults to value semantics. And then, because most things should be changed, then it makes sense
1184960	1188000	for that to be the default. And one of the important things about that is that arrays and
1188000	1191680	dictionaries and all these other collections that are aggregations of other things also have
1191680	1196960	value semantics. And so when you pass this around to different parts of your program, you don't have
1196960	1201600	to do these defensive copies. And so this is, this is great for two sides, right? It's great
1201600	1206880	because you define away the bug, which is a big deal for productivity than the number one thing
1206880	1211440	most people care about. But it's also good for performance. Because when you're doing a clone,
1211440	1215280	so you pass the array down to the thing, it was like, I don't know if anybody else has it.
1215280	1219040	I have to clone it. Well, you just did a copy of a bunch of data. It could be big.
1219920	1224080	And then it could be that the thing that called you is not keeping track of the old thing. So
1224080	1229280	you just made a copy of it. And you may not have had to. And so the way the value semantics work
1229280	1233840	is in Swift is it uses a thing called copy on write, which means that you get, you get the
1233840	1240000	benefit of safety and performance. And it has another special trick. Because if you think
1240000	1244640	certain languages like Java, for example, they have immutable strings. And so what they're trying
1244640	1250160	to do is they provide value semantics by having pure immutability. Functional languages have pure
1250160	1254320	immutability in lots of different places. And this provides a much safer model and provides
1254320	1259440	value semantics. The problem with this is if you have immutability, everything is expensive.
1259440	1266160	Everything requires a copy. For example, in Java, if you have a string x and a string y,
1266880	1270720	you append them together, we have to allocate a new string to hold x, y.
1271200	1273280	Oh, if they're immutable.
1275120	1279280	Strings in Java are immutable. And if there's there's optimizations for short ones,
1279280	1284960	and it's complicated, but but generally think about them as a separate allocation. And so when
1284960	1289280	you append them together, you have to go allocate a third thing, because somebody might have a
1289280	1292400	point or two, either of the other ones, right? And you can't go change them. So you have to go
1292400	1297600	allocate a third thing. Because of the beauty of how the Swift value semantics system works out,
1297680	1303600	if you have a string and Swift, you say, hey, put in x, right? And they say, append on y, z, w,
1304880	1308800	it knows that there's only one reference to that. And so can do an in place update.
1310080	1314160	And so you're not allocating tons of stuff on the side, you're not, you don't have all these
1314160	1318240	problems. When you pass it off, you can know you have the only reference. If you pass it off to
1318240	1322880	multiple different people, but nobody changes it, they can all share the same thing. So you get a
1322880	1327680	lot of the benefit of purely immutable design. And so you get a really nice sweet spot that I
1327680	1331600	haven't seen in other languages. Yeah, that's interesting. Like, I thought I thought there
1331600	1338480	was going to be a philosophical like narrative here that you're going to have to pay a cost for it.
1339280	1347520	Because it sounds like I think value semantics is beneficial for easing of debugging, or
1348160	1353680	minimizing the risk of errors, like bringing the errors closer to the source,
1355760	1360080	bringing the symptom of the error closer to the source of the error, however you say that.
1360720	1366160	But you're saying there's not a performance cost either, if you implement correctly.
1366160	1371680	Well, so there's tradeoffs with everything. And so if you are doing very low level stuff,
1371680	1375840	then sometimes you can notice cost. But then what you're doing is you're saying, what is the right
1375920	1380640	default. So coming back to user interface, when you talk about programming languages,
1380640	1387200	one of the major things that Swift does that makes people love it, that is not obvious when it comes
1387200	1394080	to designing a language is this UI principle of progressive disclosure of complexity. So Swift,
1394080	1399280	like many languages, is very powerful. The question is, when do you have to learn the power as a user?
1400640	1403680	So Swift like Python allows you to start with like print hello world,
1404560	1408640	right, certain other languages, start with like public static void main class,
1410480	1415200	like all the ceremony, right. And so you go to teach, you teach a new person, hey, welcome,
1415200	1421120	welcome to this new thing. Let's talk about public access control classes, wait, what's that,
1421120	1428320	string system dot out, print land like packages, like, right. And so instead, if you take this,
1428320	1432800	and you say, hey, we need, you need, we need packages, you know, modules, we need, we need
1432800	1437200	powerful things like classes, we need data structures, we need like all these things.
1437200	1440880	The question is, how do you factor the complexity? And how do you make it so that
1440880	1446240	the normal case scenario is you're dealing with things that work the right way in the right way
1446240	1451680	and give you good performance right by default. But then as a power user, if you want to dive down
1451680	1456880	to it, you have full cc performance, full control over low level pointers, you can call malloc if
1456880	1461200	you want to call malloc. This is not recommended on the first page of every tutorial, but it's
1461200	1466080	actually really important when you want to get work done, right. And so being able to have that
1466080	1471360	is really the design in programming language design. And design is really, really hard. It's
1471360	1477840	something that I think a lot of people kind of outside of UI, again, a lot of people just think
1477840	1483760	is subjective, like there's nothing, you know, it's just like curly braces or whatever, it's just
1483760	1487760	like somebody's preference. But actually, good design is something that you can feel.
1488640	1494800	And how many people are involved with good design? So if we look at Swift, but look at historically,
1494800	1499920	I mean, this might touch like, there's almost like a Steve Jobs question too, like,
1500800	1509440	how much dictatorial decision making is required versus collaborative? And we'll talk about how
1509520	1514800	that can go wrong or right. But yeah, we'll Swift. So I can't speak to in general, all design
1514800	1521120	everywhere. So the way it works with Swift is that there's a core team. And so core team is
1521120	1525680	six or seven people ish something like that that is people that have been working with Swift since
1525680	1532720	very early days. And so by early days is not that long ago. Okay, yeah. So it's, it became public
1532720	1538240	in 2014. So it's been six years public now. But but so that's enough time that there's a story
1538240	1543600	arc there. Okay. And there's mistakes have been made that then get fixed and you learn something
1543600	1548960	and then you, you know, and so what the core team does is it provides continuity. And so you want
1548960	1555360	to have a, okay, well, there's a big hole that we want to fill. We know we want to fill it. So
1555360	1560400	don't do other things that invade that space until we fill the hole, right? There's a boulder
1560400	1563840	that's missing here. We want to, we will do that boulder, even though it's not today.
1564800	1570240	Keep, keep out of that space. And the whole team remembers of the remembers the myth of the boulder
1570240	1574320	that's there. Yeah, yeah, there's a general sense of what the future looks like in broad strokes
1574320	1578880	and a shared understanding of that, combined with a shared understanding of what has happened in the
1578880	1584320	past that worked out well and didn't work out well. The next level out is you have the what's
1584320	1588400	called the Swift Evolution community. And you've got in that case, hundreds of people that really
1588400	1592880	care passionately about the ways Swift evolves. And that's like an amazing thing to again,
1593840	1597440	the core team doesn't necessarily need to come up with all the good ideas. You got hundreds of
1597440	1600960	people out there that care about something, and they come up with really good ideas too.
1600960	1608400	And that provides this like tumbling rock tumbler for ideas. And so the, the evolution process is,
1608400	1611600	you know, a lot of people in a discourse forum, they're like hashing it out and trying to like
1611600	1615600	talk about, okay, well, should we go left or right? Or if we did this, what would be good?
1615600	1618960	And, you know, here you're talking about hundreds of people. So you're not going to get consensus,
1619600	1626160	necessarily. You're not obvious consensus. And so there's a proposal process that then allows
1626160	1631440	the core team and the community to work this out. And what the core team does is it aims to get
1631440	1636320	consensus out of the community and provide guardrails, but also provide long term,
1637440	1640240	make sure we're going the right direction kind of things.
1640240	1647280	So does that group represent like the how much people will love the user interface?
1647280	1649360	Like, do you think they're able to capture that?
1649360	1652240	Well, I mean, it's something we talk about a lot. It's something we care about.
1652240	1656720	How will we, how will we do that for debate? But I think that we've done pretty well so far.
1656720	1660560	Is the beginner in mind, like you said, the progressive disclosure?
1660560	1666560	Yeah, so we care a lot about a lot about that, a lot about power, a lot about efficiency, a lot
1666560	1670960	about there are many factors to good design. And you have to figure out a way to kind of
1671760	1674480	work your way through that. And so if you like think about
1675200	1680560	like a language I love is Lisp, probably still because I use Emacs, but I haven't done anything,
1680560	1684800	any serious working list, but it has a ridiculous amount of parentheses.
1686480	1692320	I've also, you know, with Java and C++, the braces,
1694240	1701680	you know, I, I like, I enjoyed the comfort of being between braces, you know, and then Python
1701680	1706560	is really excited to interrupt just like, and last thing to me as a design, if I was a language
1706560	1715120	designer, God forbid, is I would be very surprised that Python with no braces would nevertheless
1715120	1720480	somehow be comforting also. So like, I can see arguments for all of these.
1720480	1724240	But look at this, this is evidence that it's not about braces versus tabs.
1724240	1726960	Right. Exactly. You're good. It's a good point.
1726960	1729920	Right. So like, you know, there's, there's evidence that
1729920	1732240	but see, like it's one of the most argued about things.
1732240	1734880	Oh yeah, of course, just like tabs and spaces, which it doesn't, I mean,
1735600	1739040	there's one obvious right answer, but it doesn't, it doesn't actually matter.
1739040	1739440	What's that?
1740640	1743360	Come on for friends. Like, come on, what are you trying to do to me here?
1743360	1745680	People are going to, yeah, half the people are going to tune out. Yeah.
1746880	1751840	So, so these two, you're able to identify things that don't really matter for the experience.
1752480	1756560	Well, no, no, no, it's always a really hard, so the easy decisions are easy.
1756560	1759440	Right. I mean, you can, fine. Those are not the interesting ones.
1759440	1761680	The hard ones are the ones that are most interesting. Right.
1761680	1764800	The hard ones are the places where, hey, we want to do a thing.
1765360	1768720	Everybody agrees we should do it. There's one proposal on the table,
1768720	1771760	but it has all these bad things associated with it. Well,
1772320	1774880	okay, what are we going to do about that? Do we just take it?
1774880	1778400	Do we delay it? Do we say, hey, well, maybe there's this other feature
1778400	1780480	that if we do that first, this will work out better.
1781440	1785840	How does this, if we do this, are we paying ourselves into a corner?
1786080	1788720	Right. And so this is where, again, you're having that core team of people that
1789520	1793520	has some continuity and has perspective, has some of the historical understanding
1793520	1797040	is really valuable because you get, it's not just like one brain,
1797040	1800000	you get the power of multiple people coming together to make good decisions,
1800000	1806160	and then you get the best out of all these people, and you also can harness the community around it.
1806160	1810160	What about like the decision of whether like in Python having one type
1810800	1814000	or having, you know, strict typing?
1814000	1818880	Yeah, okay. Yeah, let's talk about this. So I like how you put that, by the way.
1818880	1821760	Like, so many people would say that Python doesn't have types.
1821760	1823120	Doesn't have types, yeah. But you're right.
1823120	1827680	Well, I've listened to you enough to where I'm a fan of yours,
1827680	1832320	and I've listened to way too many podcasts and videos of you talking about this.
1832320	1835120	Oh, yeah. So I would argue that Python has one type. And so,
1836240	1839680	so like when you import Python and Swift, which by the way works really well,
1839680	1841760	you have everything comes in as a Python object.
1841760	1847360	Now, here they're trade-offs because, you know, it depends on what you're optimizing for.
1847360	1850080	And Python is a super successful language for a really good reason,
1850960	1855200	because it has one type, you get duck typing for free and things like this.
1855200	1860400	But also, you're pushing, you're making it very easy to pound out code in one hand,
1860400	1865200	but you're also making it very easy to introduce complicated bugs, the F2D bug,
1865200	1870080	and you pass the string into something that expects an integer, and it doesn't immediately die,
1870080	1873280	it goes all the way down the stack trace, and you find yourself in the middle of some code
1873280	1876240	that you really didn't want to know anything about, and it blows up, and you're just saying,
1876240	1881600	well, what did I do wrong, right? And so, types are good and bad, and they have trade-offs,
1881600	1884560	are good for performance, and certain other things, depending on where you're coming from.
1884560	1888480	But it's all about trade-offs. And so this is what design is, right?
1888480	1893440	Design is about weighing trade-offs and trying to understand the ramifications of the things
1893440	1897040	that you're weighing, like types or not, or one type or many types.
1897360	1903360	But also, within many types, how powerful do you make that type system is another very complicated
1903360	1910560	question with lots of trade-offs. It's very interesting, by the way. But that's one dimension,
1911680	1915200	and there's a bunch of other dimensions. JIT-compiled versus static-compiled,
1915200	1920400	garbage-collected versus reference-counted versus manual memory management versus,
1921600	1925440	all these different trade-offs and how you balance them are what make the program language good.
1925520	1931200	Concurrency, so in all those things, I guess, when you're designing the language,
1931200	1934080	you also have to think of how that's going to get all compiled down to...
1935120	1939360	If you care about performance, yeah. Well, and go back to Lisp, right? So Lisp,
1939360	1945120	also I would say JavaScript is another example of a very simple language, right? And so one of the...
1945840	1949680	So I also love Lisp. I don't use it as much as maybe you do, or you did.
1949760	1955040	No, I think we're both everyone who loves Lisp. It's like, I don't know,
1955040	1959120	I love Frank Sinatra, but how often do I seriously listen to Frank Sinatra?
1959120	1964000	Sure. But you look at that, or you look at JavaScript, which is another very different,
1964000	1968240	but relatively simple language. And there are certain things that don't exist in the language,
1969040	1972960	but there is inherent complexity to the problems that we're trying to model.
1972960	1977040	And so what happens to the complexity? In the case of both of them, for example,
1977120	1980960	you say, well, what about large-scale software development? Okay. Well, you need something
1980960	1986320	like packages. Neither language has a language affordance for packages. And so what you get
1986320	1992000	is patterns. You get things like NPN. You get things like these ecosystems that get built around.
1992000	1997680	And I'm a believer that if you don't model at least the most important inherent complexity
1997680	2001440	in the language, then what ends up happening is that complexity gets pushed elsewhere.
2002400	2006560	And when it gets pushed elsewhere, sometimes that's great because often building things as
2006560	2010480	libraries is very flexible and very powerful and allows you to evolve and things like that.
2010480	2015440	But often it leads to a lot of unnecessary divergence in the force and fragmentation.
2016240	2021840	And when that happens, you just get kind of a mess. And so the question is, how do you balance that?
2022720	2025600	Don't put too much stuff in the language because that's really expensive and it makes things
2025600	2030240	complicated. But how do you model enough of the inherent complexity of the problem that
2031120	2034080	you provide the framework and the structure for people to think about?
2035120	2040240	So the key thing to think about with programming languages, and you think about what a programming
2040240	2045200	language is there for, is it's about making a human more productive. And so there's an old,
2045200	2052560	I think it's Steve Jobs quote about, it's a bicycle for the mind. You can definitely walk,
2053680	2056800	but you'll get there a lot faster if you can bicycle on your way.
2057440	2062000	And a programming language is a bicycle for the mind is basically, wow,
2062000	2063680	that's a really interesting way to think about it.
2063680	2067280	But by raising the level of abstraction now, you can fit more things in your head.
2067280	2070000	By being able to just directly leverage somebody's library,
2070000	2076080	you can now get something done quickly. In the case of Swift, SwiftUI is this new framework
2076080	2082000	that Apple has released recently for doing UI programming. And it has this declarative programming
2082000	2087680	model, which defines away entire classes of bugs. It builds on value semantics and many other nice
2087680	2092640	Swift things. And what this does is allows you just get way more done with way less code.
2093200	2098640	And now your productivity as a developer is much higher. And so that's really what
2098640	2102400	programming languages should be about is it's not about tabs versus spaces or curly braces or
2102400	2107680	whatever. It's about how productive do you make the person. And you can only see that when you
2107760	2113040	have libraries that were built with the right intention that the language was designed for.
2113600	2118000	And with Swift, I think we're still a little bit early. But SwiftUI and many other things
2118000	2122400	that are coming out now are really showing that. And I think that they're opening people's eyes.
2122400	2128960	It's kind of interesting to think about like how that, you know, the knowledge of something,
2129520	2136080	of how good the bicycle is, how people learn about that. You know, so I've used C++. Now,
2136080	2141680	this is not going to be a trash talking session about C++, but you use C++ for a really long
2141680	2149600	I can go there if you want. I have the scars. I feel like I spent many years without realizing
2149600	2156000	like there's languages that could, for my particular life style, brain style, thinking
2156000	2161760	style, there's languages that could make me a lot more productive in the debugging stage,
2162320	2166560	in just the development stage, and thinking like the bicycle for the mind that could fit
2166560	2170480	more stuff into my... Python's a great example of that, right? I mean, a machine learning framework
2170480	2175040	in Python is a great example of that. It's just very high abstraction level. And so you can be
2175040	2179920	thinking about things on a like very high level algorithmic level, instead of thinking about,
2179920	2185040	okay, well, am I copying this tensor to a GPU or not? Right? It's not what you want to be thinking
2185040	2190400	about. And as I was telling you, I mean, I guess the question I had is, you know, how does a person
2190400	2199040	like me or general people discover more productive, you know, languages? Like how I was, as I've been
2199040	2204320	telling you offline, I've been looking for like a project to work on in Swift, so I can really
2204320	2209680	try it out. I mean, my intuition was like doing a Hello World is not going to get me there,
2211200	2215920	to get me to experience the power of language. You need a few weeks to change your metabolism.
2215920	2221440	Exactly. I think it's beautifully put. That's one of the problems with people with diets.
2221440	2227760	Like I'm actually currently to go in parallel, but in a small tangent is I've been recently
2227760	2236400	eating only meat. Okay. Okay. And okay. So most people are like, the thing that's horribly unhealthy
2236400	2241760	or whatever, you have like a million, whatever the science is, it just doesn't sound right.
2242320	2246400	Well, so back when I was in college, we did the Atkins diet. That was, that was a thing and
2246400	2251920	similar. And, but if you, you have to always give these things a chance. I mean, with dieting,
2251920	2258000	always not dieting, but just the things that you like. If I eat personally, if I eat meat,
2258000	2264480	just everything, I could be super focused or more focused than usual. I just feel great. I've been,
2264480	2268560	I've been running a lot of, you know, doing push-ups and posts and so on. And your Python
2268560	2275120	is similar in that sense for me. Where are you going with this? I mean, literally, I just,
2275120	2281440	I felt ahead like a stupid smile on my face when I first started using Python. I could
2281440	2287680	code up really quick things. Like I, like I would see the world. I'll be empowered to write a script
2287680	2293440	to, to, um, you know, to do some basic data processing, to rename files on my computer.
2293440	2300480	Yeah. Right. And like Perl didn't do that for me, uh, a little bit. Well, and, and again, like
2300480	2304080	none of these are about which, which is best or something like that, but there's definitely
2304080	2308720	better and worse here. But it clicks, right? Well, yeah. And if you, if you look at Perl,
2308720	2314480	for example, you get bogged down in, uh, scalers versus arrays versus hashes versus type globs and
2314480	2319200	like all that kind of stuff. And, and Python's like, yeah, let's not do this. Right. And some of
2319200	2324240	it's debugging. Like everyone has different priorities, but for me it's, can I create systems
2324240	2331200	for myself that empower me to debug quickly? Like I've always been a big fan, even just crewed
2331200	2338800	like asserts, like always, uh, stating things that should be true, uh, which in Python I found
2338800	2343840	in myself do more because of type, all these kinds of stuff. Well, you could think of types in a
2343840	2347760	program language as being kind of assert. Yeah. They could check to compile time. Right.
2348880	2353600	So how do you learn a new thing? Well, so this, or how do, how do people learn new things? Right.
2353600	2358560	This, this is hard. Uh, people don't like to change. People generally don't like change around
2358560	2364560	them either. And so, uh, we're all very slow to adapt and change. And usually there's a catalyst
2364560	2369600	that's required to, to force yourself over the, over, over this. So for learning a programming
2369680	2375200	language, it just really comes down to finding an excuse, like build a thing that's, that the
2375200	2381680	language is actually good for that the ecosystem's ready for. Um, and so, um, and so if you were to
2381680	2385600	write an iOS app, for example, that'd be the easy case. Obviously you would, you would use Swift
2385600	2392320	for that. Right. There are Android. So Swift runs on Android. Oh, does it? Oh yeah. Yeah. Swift runs
2392320	2399440	in lots of places. So, uh, okay. So Swift, Swift, Swift is built on top of LLVM. LLVM runs
2399440	2406320	everywhere. LLVM, for example, builds the Android kernel. Oh, okay. So yeah. Um, so they realize
2406320	2411600	this. Yeah. So Swift, Swift is very portable, runs on Windows. There's, it runs on lots of
2411600	2416560	different things. And, uh, Swift, sorry to interrupt that. Swift UI. And then there's a thing called
2416640	2423120	UIKit. Can I build an app with Swift? Uh, well, so that, that's the thing is the ecosystem is what
2423120	2428640	matters there. So Swift UI and UIKit are Apple technologies. Okay. Got it. And so they happen
2428640	2433520	to, like Swift UI happens to be written in Swift, but it's an Apple proprietary framework that, um,
2433520	2437920	Apple loves and wants to keep on its platform, which makes total sense. You go, go to Android and
2437920	2443040	you don't have that library. Yeah. Right. And so Android has a different ecosystem of things that
2443120	2447280	hasn't been built out and doesn't work as well with Swift. And so you can totally use Swift to do,
2448000	2452480	like arithmetic and things like this, but building a UI with Swift on Android is not,
2452480	2457760	not, not a, not a great example right now. So, so if I wanted to, uh, to learn Swift, what's the,
2458720	2465520	I mean, the one practical different version of that is, um, Swift for TensorFlow, for example.
2465520	2471760	And one of the inspiring things for me with both TensorFlow and PyTorch is how quickly the community
2471760	2477920	can like switch from different libraries. Yep. Like you could see some of the communities switching
2477920	2483600	to PyTorch now, but it could, it's very easy to see and then TensorFlow is really stepping up its
2483600	2488960	game. And then there's no reason why, I think the way it works is basically it has to be one GitHub
2488960	2493600	repo, like one paper steps up. It gets people excited. It gets people excited and they're like,
2493600	2500720	ah, I have to learn this at Swift for what, what's Swift again? And then they learn and they fall
2500720	2504320	along with it. I mean, that's what happened with PyTorch. There has to be a reason, a catalyst.
2504320	2510080	Yeah. And so, and, and there, I mean, people don't like change, but it turns out that once you've
2510080	2514800	worked with one or two programming languages, the, the basics are pretty similar. And so
2514800	2518320	one of the fun things about learning programming languages, even, even maybe less, but I don't
2518320	2522560	know if you agree with this, is that when you start doing that, you start learning new things
2523840	2528160	because you have a new way to do things and you're forced to do them and that forces you to
2528240	2531920	explore. And it puts you in learning mode. And when you get in learning mode, your mind kind of
2531920	2536320	opens a little bit and you can, you can see things in a new way, even when you go back to the old
2536320	2543520	place. Right. Yeah. So it would list with functional stuff. But I wish there was a kind of window.
2543520	2549200	Maybe you can tell me if there is, there you go. This is a question to ask what is the most beautiful
2549200	2554800	feature in a programming language. Before I ask, let me say like with Python, I remember I saw
2554800	2563040	list comprehensions. It was like, when I like really took it in. Yeah. I don't know. I just
2563040	2567120	loved it. It was like fun to do like, it was fun to do that kind of,
2569280	2574240	it was something about it to be able to filter through a list and to create a new list on a
2574240	2581440	single line was elegant. I could all get into my head and it just made me fall in love with the
2581440	2587520	language. So it's there. Let me ask you a question. Is there what to use the most beautiful feature
2587520	2595040	in a program languages that you've ever encountered in Swift, maybe, and then outside of Swift?
2595040	2600000	I think the thing that I like the most from a programming language. So I think the thing you
2600000	2604400	have to think about with the programming language, again, what is the goal? You're trying to get
2604400	2610400	people to get things done quickly. And so you need libraries, you need high quality libraries.
2610400	2614320	And then you need a user base around them that can assemble them and do cool things with them.
2614320	2618000	Right. And so to me, the question is what enables high quality libraries?
2619680	2626720	Yeah. Yeah. And there's a huge divide in the world between libraries who enable high quality
2626720	2634240	libraries versus the ones that put special stuff in the language. So programming languages that
2634240	2641920	enable high quality libraries. Got it. So what I mean by that is expressive libraries that then
2641920	2648640	feel like a natural integrated part of the language itself. So an example of this in Swift is that
2648640	2653600	int and float and also array and string, things like this, these are all part of the library.
2653600	2661040	Like int is not hard coded into Swift. And so what that means is that because int is just a library
2661040	2664640	thing defined in the standard library, along with strings and arrays and all the other things that
2664640	2671520	come with the standard library. Well, hopefully you do like int. But anything that any language
2671520	2676720	features that you needed to define int, you can also use in your own types. So if you wanted to
2676720	2682880	find a quaternion or something like this, right? Well, it doesn't come in the standard library.
2683520	2689280	There's a very special set of people that care a lot about this. But those people are also important.
2689280	2693680	It's not about classism, right? It's not about the people who care about instant floats are more
2693680	2697440	important than the people who care about quaternions. And so to me, the beautiful things about programming
2697440	2702880	languages is when you allow those communities to build high quality libraries that feel native,
2702880	2706560	that feel like they're built into the compiler without having to be.
2707920	2717840	What does it mean for the int to be part of not hard coded in? So what is an int?
2719360	2724480	Int is just an integer. In this case, it's like a 64-bit integer or something like this.
2724480	2728080	But so the 64-bit is hard coded or no?
2728080	2732080	No, none of that's hard coded. So int, if you go look at how it's implemented,
2732080	2737520	it's just a struct in Swift. And so it's a struct. And then how do you add two structs? Well,
2737520	2743520	you define plus. And so you can define plus on int. Well, you can define plus on your thing, too.
2743520	2749120	You can define int as an odd method or something like that on it. And so, yeah, you can add methods
2749120	2757120	on a thing. So you can define operators like how it behaves. That's used beautiful when there's
2757120	2764720	something about the language which enables others to create libraries which are not hacky.
2765280	2769280	Yeah, they feel native. And so one of the best examples of this is Lisp.
2770800	2775760	Because in Lisp, all the libraries are basically part of the language. You write
2775760	2780880	term rewrite systems and things like this. And so can you, as a counter example, provide
2780880	2785360	what makes it difficult to write a library that's native? Is it the Python C?
2785360	2791280	Well, so one example, I'll give you two examples. Java and C++, there's Java and C.
2792960	2797360	They both allow you to define your own types. But int is hard coded in the language.
2798240	2802720	Okay. Well, why? Well, in Java, for example, coming back to this whole reference semantic
2802800	2813120	value semantic thing, int gets passed around by value. But if you make a pair or something like
2813120	2818640	that, a complex number, it's a class in Java. And now it gets passed around by reference,
2818640	2826800	by pointer. And so now you lose value semantics. You lost math. Okay. Well, that's not great.
2827040	2829120	If you can do something with int, why can't I do it with my type?
2830160	2837280	Right. So that's the negative side of the thing I find beautiful is when you can solve that,
2837280	2843440	when you can have full expressivity where you as a user of the language have as much or almost
2843440	2847840	as much power as the people who implemented all the standard built-in stuff. Because what that
2847840	2853840	enables is that enables truly beautiful libraries. You know, it's kind of weird because I've gotten
2853840	2859600	used to that. That's one, I guess, other aspect of program language design. You have to think,
2860480	2866160	you know, the old first principles thinking, like, why are we doing it this way? By the way,
2866160	2872400	I mean, I remember because I was thinking about the Waller's operator and I'll ask you about it
2872400	2880480	later. But it hit me that like the equal sign for assignment, like why are we using the equal
2880480	2885360	sign? It's wrong. And that's not the only solution, right? So if you look at Pascal,
2885360	2892720	they use colon equals for assignment and equals for equality. And they use like less and greater
2892720	2898720	than instead of the not equal. Like there are other answers here. So but like, and yeah, like I
2898720	2905760	ask you all, but how do you then decide to break convention to say, you know what?
2906720	2913600	That everybody's doing it wrong. We're going to do it right. Yeah. So it's like an ROI,
2913600	2918160	like return on investment trade off, right? So if you do something weird, let's just say like
2918160	2923520	not like colon equal instead of equal for assignment, that would be weird with today's
2923520	2928160	aesthetic, right? And so you'd say, cool, this is theoretically better. But is it better in which
2928160	2933200	ways? Like, what do I get out of that? Do I define away class of bugs? Well, one of the class of
2933200	2940480	bugs that C has is that you can use like, you know, if x equals without equals equals fx equals y.
2940480	2946320	Yeah. Right. Well, turns out you can solve that problem in lots of ways. Clang, for example,
2946320	2950640	GCC, all these compilers will detect that as a as a likely bug, produce a warning.
2950640	2956800	Do they? Yeah, I feel like they didn't or clang doesn't GCC didn't. And it's like,
2956800	2960640	one of the important things about programming language design is like, you're literally
2960640	2968000	creating suffering in the world. Like, I feel like, I mean, one way to see it is the
2968000	2972000	bicycle for the mind, but the other way is to like, minimizing suffering.
2972000	2975360	Well, you have to decide if it's worth it, right? And so let's come back to that.
2975360	2979920	Okay. But, but if you if you look at this, and again, this is where there's a lot of detail
2979920	2984800	that goes into each of these things. Equal and C returns a value.
2985520	2992000	Yep. That's messed up. That allows you to say x equals y equals z, like that works in C.
2992000	2998160	Yeah. Is it messed up? You know, well, so that most people think it's messed up, I think it is
2998160	3005360	very by messed up. What I mean is it is very rarely used for good. And it's often used for bugs.
3005360	3011920	Yeah. Right. And so that's a good definition. You could use, you know, it's a in hindsight,
3012000	3016000	this was not such a great idea, right? Now, one of the things with Swift that is really powerful
3016000	3020640	and one of the reasons it's actually good versus it being full of good ideas is that
3022000	3027040	when we launched Swift 1, we announced that it was public, people could use it, people could
3027040	3032160	build apps, but it was going to change and break. Okay. When Swift 2 came out, we said,
3032160	3037200	hey, it's open source, and there's this open process which people can help evolve and direct
3037200	3043040	the language. So the community at large like Swift users can now help shape the language as it is.
3043040	3048240	And what happened is that part as part of that process is a lot of really bad mistakes got taken
3048240	3054240	out. So for example, Swift used to have the C style plus plus and minus minus operators.
3054880	3060960	Like what does it mean when you put it before versus after? Right? Well, that got cargo-culted
3060960	3065840	from C into Swift early on. What's cargo-culted? Cargo-culted means brought forward without really
3066800	3070800	considering it. Okay. This is maybe not the most PC term.
3071360	3076640	But I have to look it up in Urban Dictionary. Yeah. So it got pulled into C without,
3077360	3082080	or it got pulled into Swift without very good consideration. And we went through this process
3082080	3086800	and one of the first things got ripped out was plus plus and minus minus because they lead to
3086800	3092880	confusion. They have very little value over saying X plus equals one. And X plus equals one is way
3092880	3098160	more clear. And so when you're optimizing for teachability and clarity and bugs and this
3098160	3103280	multidimensional space that you're looking at, things like that really matter. And so being
3103280	3107200	first principles on where you're coming from and what you're trying to achieve and being anchored
3107200	3116880	on, the objective is really important. Well, let me ask you about the most sort of this podcast
3116880	3122480	isn't about information, it's about drama. So let me talk to you about some drama. So you mentioned
3122560	3130880	Pascal and colon equals, there's something that's called the walrus operator. Okay. And Python
3132320	3137280	Python 3.8 added the walrus operator. And the reason I think it's interesting,
3138960	3143280	it's not just because of the feature, it does, it's, it has the same kind of expression feature
3143280	3148560	you can mention to see that it returns the value of the assignment. And maybe you can comment on
3148560	3155920	that in general. But on the other side of it, it's also the thing that toppled the dictator.
3157840	3163120	It finally drove Guido to step down from the DFL, the toxicity of the community. So maybe
3163920	3167920	what do you think about the walrus operator in Python? Is there an equivalent
3168560	3176480	thing in Swift that really stress tested the community? And then on the flip side,
3176480	3181040	what do you think about Guido stepping down over it? Yeah, well, like if I look past the details
3181040	3185120	of the walrus operator, one of the things that makes it most polarizing is that it's syntactic
3185120	3191200	sugar. Okay, what do you mean by syntactic sugar? It means you can take something that already exists
3191200	3195520	in language and you can express it in a more concise way. So okay, I'm going to play devil's
3195520	3203040	advocate. So this is great. Is that objective or subjective statement? Like, can you can you argue
3203040	3210560	that basically anything is syntactic sugar or not? No, not everything is syntactic sugar. So for
3210560	3219600	example, the type system, like can you have classes versus versus, like, do you have types or not?
3219600	3225360	Right. So one type versus many types is not something that affects syntactic sugar. And so
3225360	3229360	if you say I want to have the ability to define types, I have to have all this like language
3229360	3234480	mechanics to define classes. And oh, now I have to have inheritance. And I have like, I have all
3234480	3238800	this stuff that's just making my language more complicated. That's not that's not about sugaring
3238800	3246400	it. Swift has the sugar. So like Swift has this thing called if let and it has various operators
3246400	3253280	are used to concisify specific use cases. So the problem with syntactic sugar, when you're talking
3253280	3257840	about, Hey, I have a thing that takes a lot to write and I have a new way to write it. You have
3257920	3264080	this like horrible trade off, which becomes almost completely subjective, which is how often does
3264080	3268400	this happen? And does it matter? And one of the things that is true about human psychology,
3268400	3274480	particularly when you're talking about introducing a new thing is that people over over estimate the
3274480	3278720	burden of learning something. And so it looks foreign when you haven't gotten used to it.
3278720	3283040	But if it was there from the beginning, of course, just part of Python, like unquestionably,
3283040	3287360	like this is this is just the thing I know. And it's not a new thing that you're worried about
3287360	3293920	learning is just part of part of the deal. Now with Guido, I don't know Guido well.
3295360	3299360	Yeah, have you passed cost much? Yeah, I've met him a couple of times, but I don't know Guido
3299360	3305680	well. But the sense that I got out of that whole dynamic was that he had put the not just the
3306400	3312240	decision maker weight on his shoulders, but it was so tied to his personal identity that
3313040	3316960	he took it personally. And he felt the need and he kind of put himself in the situation of being
3316960	3322720	the person instead of building a base of support around him. I mean, this is probably not quite
3322720	3329440	literally true. But by too much so there's too much too much concentrated on him, right? And so
3329440	3334240	and that can wear you down. Well, yeah, particularly because people then say Guido,
3334240	3337520	you're a horrible person, I hate this thing, blah, blah, blah, blah, blah, blah, blah,
3337520	3342320	and sure, it's like, you know, maybe 1% of the community that's doing that. But Python's got a
3342320	3348480	big community in 1% of millions of people is a lot of hate mail. And that just from human factor
3348480	3353840	will just wear on you. Well, to clarify, it looked from just what I saw in the messaging for the
3353840	3359200	let's not look at the million Python users, but at the Python core developers, it feels like the
3359200	3366720	majority, the big majority on a vote were opposed to it. Okay, I'm not that close to it. So this
3366720	3373040	okay, so the situation is like literally, yeah, I mean, the majority of the core developers are
3373040	3382080	against it. So I and they weren't, they weren't even like against it. It was there was a few
3382080	3388160	while they were against it, but the against it wasn't like, this is a bad idea. They were more
3388160	3395040	like, we don't see why this is a good idea. And what that results in is there's a stalling feeling
3395120	3401760	like you just slow things down. Now, from my perspective, that you could argue this. And I
3401760	3407520	think it's a very, it's very interesting if we look at politics today, and the way Congress works,
3407520	3412960	it's slowed down everything. It's a dampener. Yeah, it's a dampener. But like, that's a dangerous
3412960	3418880	thing too, because if it dampens things like, you know, well, dampening results, what are you
3418880	3422880	talking about? Like, it's a low pass filter. But if you need billions of dollars injected into the
3422880	3429680	economy or trillions of dollars, then suddenly stuff happens. Right. And so for sure. So you're
3429680	3432560	talking about I'm not I'm not defending our political situation just to be clear.
3433200	3439760	But you're talking about like a global pandemic. Well, I was hoping we could fix like the healthcare
3439760	3445280	system and the education. So like, you know, I'm not I'm not a politics person. I don't I don't
3445280	3450880	I don't know. When it comes to languages, the community is kind of right in terms of it's a
3450880	3454480	very high burden to add something to a language. So as soon as you add something, you have a
3454480	3459200	community of people building on it, and you can't remove it. Okay. And if there's a community of
3459200	3464800	people that feel really uncomfortable with it, then taking it slow, I think is is is an important
3464800	3469600	thing to do. And there's no rush, particularly with something that's 25 years old and is very
3469600	3475200	established. And, you know, it's not like coming coming into its own. What about features?
3475760	3480560	Well, so I think that the issue with with Guido is that maybe this is a case where he
3480560	3486880	realized it had outgrown him. And it went from being or the language, the language. So Python,
3487760	3493680	I mean, Guido is amazing. But but Python isn't about Guido anymore. It's about the users. And to
3493680	3499600	a certain extent, the users own it. And, you know, Python Guido spent years of his life,
3499600	3504560	a significant fraction of his career on Python. And from his perspective, I imagine he's like,
3504560	3509120	well, this is my thing, I should be able to do the thing I think is right. But you can also
3509120	3514480	understand the users where they feel like, you know, this is my thing, I use this like, and
3515920	3521200	and I don't know, it's a hard, it's a hard thing. But what if we could talk about leadership in this
3521200	3524640	because it's so interesting to me, I'm going to, I'm going to make, I'm going to work, hopefully
3524640	3530240	somebody makes it, if not, I'll make it a water supply shirt, because I think it represents to me,
3530240	3536240	maybe it's my Russian roots or something. You know, it's the burden of leadership, like,
3536960	3545520	I feel like to push back, I feel like progress can own like most difficult decisions, just like
3545520	3550960	you said, there'll be a lot of divisiveness over, especially in the passionate community.
3552080	3559360	It just feels like leaders need to take those risky decisions that that if you like,
3559360	3565120	listen, that with some non-zero probability, maybe even a high probability will be the wrong
3565120	3568640	decision. But they have to use their gut and make that decision.
3569680	3575600	This is like one of the things where you see amazing founders. The founders understand exactly
3575600	3580080	what's happened and how the company got there and are willing to say, we have been doing
3580080	3586560	Thing X the last 20 years. But today, we're going to do Thing Y. And they make a major pivot for
3586560	3590560	the whole company, the company lines up behind them, they move, and it's the right thing. But
3590560	3597760	then when the founder dies, the successor doesn't always feel that agency to be able to make those
3597760	3602640	kinds of decisions. Even though they're a CEO, they could theoretically do whatever. There's two
3602640	3609280	reasons for that, in my opinion, or in many cases, it's always different. But one of which is they
3609280	3613280	weren't there for all the decisions that were made. And so they don't know the principles
3613280	3619360	in which those decisions were made. And once the principles change, you should be obligated
3619360	3625360	to change what you're doing and change direction. And so if you don't know how you got to where
3625360	3630640	you are, it just seems like gospel. And you're not going to question it. You may not understand
3630640	3633360	that it really is the right thing to do. So you just may not see it.
3633360	3639280	That's so brilliant. I never thought of it that way. It's so much higher burden when as a leader
3639280	3641680	you step into a thing that's already worked for a long time.
3641680	3645520	Yeah. And if you change it and it doesn't work out, now you're the person who screwed it up.
3646160	3650960	People always second guess that. And the second thing is that even if you decide to make a change,
3650960	3657360	even if you're theoretically in charge, you're just a person that thinks they're in charge.
3657360	3660000	Meanwhile, you have to motivate the troops. You have to explain it to them in terms of
3660000	3662960	understanding. You have to get them to buy into and believe in it because if they don't,
3663520	3667680	then they're not going to be able to make the turn even if you tell them their bonuses are
3667680	3672160	going to be curtailed. They're just not going to buy into it. And so there's only so much power you
3672160	3679600	have as a leader and you have to understand what those limitations are. You've been a BDFL of some
3679600	3690640	stuff. You're very heavy on the B, the benevolent dictated for life. I guess LVM. So I still lead
3690720	3698160	the LVM world. So then on Swift, you said that there's a group of people.
3699040	3704960	So if you contrast Python with Swift, one of the reasons... So everybody on the core team takes
3704960	3710160	the role really seriously. And I think we all really care about where Swift goes. But you're
3710160	3715920	almost delegating the final decision-making to the wisdom of the group. And so it doesn't become
3715920	3721920	personal. And also when you're talking with the community, so yeah, some people are very annoyed
3721920	3726960	at certain decisions that get made. There's a certain faith in the process because it's a very
3726960	3732080	transparent process. And when a decision gets made, a full rationale is provided, things like this.
3732080	3737440	These are almost defense mechanisms to help both guide future discussions and provide case lock.
3737440	3741840	And like Supreme Court does about this decision was made for this reason. And here's the rationale
3741840	3747520	and what we want to see more of or less of. But it's also a way to provide a defense mechanism
3747520	3751920	so that when somebody's griping about it, they're not saying that person did the wrong thing.
3751920	3758480	They're saying, well, this thing sucks. And later they move on and they get over it.
3758480	3764320	Yeah, the analogy is Supreme Court, I think, is really good. But then, okay, not to get
3764320	3771360	personal on the Swift team, but is there... It just seems like it's impossible for division
3771440	3776880	not to emerge. Well, each of the humans on the Swift core team, for example, are different
3776880	3781840	and the membership of the Swift core team changes slowly over time, which is, I think, a healthy
3781840	3786400	thing. And so each of these different humans have different opinions. Trust me, it's not a
3787360	3792800	singular consciousness by any stretch of the imagination. You've got three major organizations,
3792800	3798800	including Apple, Google and Sci-Fi, all working together. And it's a small group of people,
3798800	3803280	but you need high trust. Again, it comes back to the principles of what you're trying to achieve
3803280	3810400	and understanding what you're optimizing for. And I think that starting with strong principles
3810400	3816160	and working towards decisions is always a good way to both make wise decisions in general,
3816160	3821200	but then be able to communicate them to people so that they can buy into them. And that is hard.
3821200	3828560	And so you mentioned LVM. LVM is going to be 20 years old this December. So it's showing its own
3828560	3837200	age. Do you have a dragon cake plan? No, I should definitely do that. If we can have a pandemic
3837200	3847520	cake, everybody gets a slice of cake and it gets sent through email. But LVM has had tons of its
3847520	3852720	own challenges over time too. And one of the challenges that the LVM community has, in my
3852720	3858240	opinion, is that it has a whole bunch of people that have been working on LVM for 10 years.
3858960	3863680	Because this happens somehow. And LVM has always been one way, but it needs to be a different way.
3864960	3868720	And they've worked on it for like 10 years. It's a long time to work on something. And
3870080	3874720	you suddenly can't see the faults in the thing that you're working on. And LVM has lots of problems
3874720	3878080	and we need to address them and we need to make it better. And if we don't make it better, then
3878080	3882640	somebody else will come up with a better idea. And so it's just kind of of that age where the
3882720	3890320	community is in danger of getting too calcified. And so I'm happy to see new projects joining
3890320	3895280	and new things mixing it up. Fortran is now a new thing in the LVM community, which is hilarious
3895280	3901360	and good. I've been trying to find, on a little tangent, find people who program in Cobalt or
3901360	3909680	Fortran, Fortran especially, to talk to. They're hard to find. Yeah, look to the scientific community.
3909680	3913200	They still use Fortran quite a bit. Well, interesting thing you kind of mentioned
3913200	3919040	with LVM or just in general, that if something evolves, you're not able to see the faults.
3919600	3925120	So do you fall in love with the thing over time or do you start hating everything about the thing
3925120	3932640	over time? Well, so my personal folly is that I see maybe not all, but many of the faults
3933360	3937440	and they grate on me and I don't have time to go fix them. Yeah. And they get magnified over time.
3937440	3941200	Well, and they may not get magnified, but they never get fixed. And it's like sand underneath,
3941200	3945360	you know, it's just like grating against you and it's like sand underneath your fingernails
3945360	3951440	or something. It's just like, you know, it's there, you can't get rid of it. And so the problem is
3951440	3956160	that if other people don't see it, right, nobody ever get like, I can't go, I don't have time to
3956160	3961760	go write the code and fix it anymore. But then people are resistant to change. And so you say,
3961760	3966160	hey, we should go fix this thing. Like, oh, yeah, that sounds risky. Well, is it the right thing
3966160	3972480	or not? Are the challenges the group dynamics or is it also just technical? I mean, some of these
3972480	3980320	features like, yeah, I think as an observer is almost like a fan in the, you know, as a spectator
3980320	3985600	of the whole thing. I don't often think about, you know, some things might actually be technically
3985600	3990720	difficult to implement. An example of this is we built this new compiler framework called MLR.
3991200	3996560	Yes, MLR is this a whole new framework. It's not many people think it's about machine learning.
3997120	4001600	The ML stands for multi level because compiler people can't name things very well, I guess.
4001600	4009040	Can we dig into what MLIR is? Yeah, so when you look at compilers compilers have historically
4009040	4016400	been solutions for a given space. So LLVM is a it's really good for dealing with CPUs,
4016400	4022880	let's just say, at a high level, you look at Java. Java has a JVM. The JVM is very good for
4022880	4027360	garbage collected languages that need dynamic compilation, and it's very optimized for specific
4027360	4031760	space. And so hotspot is one of the compilers that gets used in that space. And that compiler's really
4031760	4036640	good at that kind of stuff. Usually, when you build these domain specific compilers,
4036640	4040240	you end up building whole thing from scratch for each domain.
4041040	4046480	What's a domain? So what's the scope of a domain?
4046480	4050640	Well, so here I would say like, if you look at Swift, there's several different parts to the
4050640	4056960	Swift compiler, one of which is covered by the LLVM part of it. There's also a high level
4056960	4062800	piece that's specific to Swift. And there's a huge amount of redundancy between those two
4062800	4068320	different infrastructures and a lot of re implemented stuff that is similar but different.
4068320	4074480	What is LLVM defined? LLVM is effectively an infrastructure. So you can mix and match it in
4074480	4077760	different ways. It's built out of libraries. You can use it for different things. But it's
4077760	4083120	really good at CPUs and GPUs. CPUs and like the tip of the iceberg on GPUs. It's not really great
4083120	4091920	at GPUs. Okay. But it turns out languages that then use it to talk to CPUs. Got it. And so it turns
4091920	4096080	out there's a lot of hardware out there that is custom accelerators. So machine learning, for example,
4096080	4101280	there are a lot of matrix multiply accelerators and things like this. There's a whole world of
4101280	4108400	hardware synthesis. So we're using MLIR to build circuits. Okay. And so you're compiling for a
4108400	4113840	domain of transistors. And so what MLIR does is it provides a tremendous amount of compiler
4113840	4118880	infrastructure that allows you to build these domain specific compilers in a much faster way
4118880	4125200	and have the result be good. If we're thinking about the future, now we're talking about like
4125200	4132960	ASICs. So anything. Yeah, yeah. So if we project into the future, it's very possible that the number
4132960	4140880	of these kinds of ASICs, very specific infrastructure thing, the architecture things,
4143120	4150880	like multiplies exponentially. I hope so. So that's MLIR. So what MLIR does is it allows you to build
4150880	4156640	these compilers very efficiently. Now, one of the things that coming back to the LVM thing,
4156640	4162800	and then we'll go to hardware, is LVM is a specific compiler for specific domain.
4163840	4168320	MLIR is now this very general, very flexible thing that can solve lots of different kinds of
4168320	4175200	problems. So LVM is a subset of what MLIR does. So MLIR is, I mean, it's an ambitious project then.
4175200	4180720	Yeah, it's a very ambitious project. Yeah. And so to make it even more confusing, MLIR has joined
4180720	4187200	the LVM umbrella project. So it's part of the LVM family. But where this comes full circle is now
4187200	4193440	folks that work on the LVM part, the classic part that's 20 years old, aren't aware of all the cool
4193440	4199440	new things that have been done and the new thing that MLIR was built by me and many other people
4199520	4204240	that knew a lot about LVM. And so we fixed a lot of the mistakes that lived in LVM.
4204880	4208960	I mean, we have this community dynamic where it's like, well, there's this new thing, but it's not
4208960	4213440	familiar. Nobody knows it. It feels like it's new. And so let's not trust it. And so it's just really
4213440	4218480	interesting to see the cultural social dynamic that comes out of that. And, you know, I think it's
4218480	4223120	super healthy because we're seeing the ideas percolate and we're seeing the technology diffusion
4223120	4227120	happen as people get more comfortable with it. They start to understand things in their own terms.
4227120	4233520	And this just gets to the it takes a while for ideas to propagate, even though they may be very
4233520	4237520	different than what people are used to. Maybe let's talk about that a little bit, the world of
4237520	4246800	Asics. And yeah, well, actually, you're, you're, you have a new role at SciFive. What's that place
4246800	4252880	about? What is the vision for their vision for, I would say, the future of computer?
4252960	4258240	Yeah. So I lead the engineering and product teams at SciFive. SciFive is a company who's
4258800	4264320	was founded with this architecture called Risk Five. Risk Five is a new instruction set.
4264320	4267440	Instruction sets are the things inside of your computer that tell it how to run things.
4268320	4273840	X86 from Intel and ARM from the ARM company and things like this or other instruction sets.
4273840	4276960	I've talked to, sorry to interrupt, I talked to Dave Patterson, who's super excited about
4277040	4282800	Risk Five. Dave is awesome. He's brilliant. Yeah. The Risk Five is distinguished by not being
4282800	4290800	proprietary. And so X86 can only be made by Intel and AMD. ARM can only be made by ARM. They
4290800	4294880	sell licenses to build ARM chips to other companies, things like this. MIPS is another
4294880	4299520	instruction set that is owned by the MIPS company, now Wave, and then it gets licensed out, things
4299520	4306000	like that. And so Risk Five is an open standard that anybody can build chips for. And so SciFive
4306000	4311440	was founded by three of the founders of Risk Five that designed and built it in Berkeley,
4311440	4317760	working with Dave. And so that was the genesis of the company. SciFive today has some of the
4317760	4321680	world's best Risk Five cores and we're selling them and that's really great. They're going to
4321680	4326400	tons of products. It's very exciting. So they're taking this thing that's open source and just
4326400	4331600	being trying to be or are the best in the world at building these things. Yeah. So here it's
4331600	4337920	the specifications open source. It's like saying TCPIP is an open standard or C is an open standard.
4337920	4342800	But then you have to build an implementation of the standard. And so SciFive, on the one hand,
4342800	4348000	pushes forward and defined and pushes forward the standard. On the other hand, we have implementations
4348000	4353120	that are best in class for different points in the space, depending on if you want a really tiny
4353120	4358480	CPU or if you want a really big beefy one that is faster, but it uses more area and things like
4358480	4364560	this. What about the actual manufacturer? So where does that all fit? I'm going to ask a bunch
4364560	4371520	of dumb questions. That's okay. This is how we learn, right? And so the way this works is that
4371520	4375680	there's generally a separation of the people who design the circuits and then the people who
4375680	4382000	manufacture them. And so you'll hear about fabs like TSMC and Samsung and things like this that
4382000	4387280	actually produce the chips, but they take a design coming in and that design specifies how
4388800	4398480	the, you know, you turn code for the chip into little rectangles that then use photo lithography
4398480	4406160	to make mask sets and then burn transistors onto a chip or onto silicon. And we're talking about
4406160	4410480	mass manufacturing. Yeah, they're talking about making hundreds of millions of parts and things
4410480	4415440	like that. And so the fab handles the volume production, things like that. But when you look
4415440	4422000	at this problem, the interesting thing about the space when you look at it is that these,
4422000	4426480	the steps that you go from designing a chip and writing the quote unquote code for it and things
4426480	4432720	like barrel log and languages like that down to what you hand off to the fab is a really well
4432720	4438720	studied really old problem. Okay. Tons of people have worked on it. Lots of smart people have built
4438720	4444400	systems and tools. These tools then have generally gone through acquisitions. And so they've ended
4444400	4448880	up at three different major companies that build and sell these tools. They're called EDA tools
4448880	4453200	like for electronic design automation. The problem with this is you have huge amounts of
4453200	4460240	fragmentation. You have loose standards. And the tools don't really work together. So you have
4460240	4465760	tons of duct tape, and you have tons of lost productivity. Now, these are, these are tools
4465760	4473040	for design. So the risk five is a instruction. Like what is risk five? Like how deep does it go?
4474000	4478320	How much does it touch the hardware? How much does it define how much of the hardware is?
4478320	4484880	Yeah. So risk five is all about given a CPU. So the processor and your computer,
4484880	4489600	how does the compiler like Swift compiler, the C compiler, things like this, how does it make it
4489600	4496000	work? So it's what is the assembly code? And so you write risk five assembly instead of XA6 assembly,
4496000	4501360	for example. But it's a set of instructions as opposed to instructions. What do you say it tells
4501360	4508080	you how the compiler works? Sorry, it's what the compiler talks to. Okay. And then the tooling you
4508080	4513760	mentioned that the disparate tools are for what? For when you're building a specific chip. So risk
4513760	4519760	five in hardware, in hardware. Yeah. So risk five, you can buy risk five core from sci five and say,
4519760	4524160	Hey, I want to have a certain number of run a certain number of gigahertz. I want it to be this
4524160	4530400	big. I want to be have these features. I want have like I want floating point or not, for example.
4531760	4535680	And then what you get is you get a description of a CPU with those characteristics.
4536480	4540880	Now, if you want to make a chip, you want to build like an iPhone chip or something like that,
4540880	4544880	right? You have to take both the CPU, but then you have to talk to memory. You have to have
4545440	4552160	timers, IOs, a GPU, other components. And so you need to pull all those things together into
4552160	4557520	what's called an ASIC, an application specific in a grade circuit. So custom chip. And then
4557600	4561920	you take that design, and then you have to transform it into something that the fabs,
4561920	4569200	like TSMC, for example, know how to take to production. Got it. So but yeah. And so that
4569200	4578240	process, I will, I can't help but see it as is a big compiler. It's a whole bunch of compilers
4578240	4583520	written without thinking about it through that lens. Isn't the universe a compiler?
4584240	4588400	Yeah. Compilers do two things. They represent things and transform them.
4588400	4593120	Yeah. And so there's a lot of things that end up being compilers. But this is a space where
4593760	4598160	we're talking about design and usability. And the way you think about things, the way
4598160	4603440	things compose correctly, it matters a lot. And so Sci-Fi is investing a lot into that space.
4603440	4607760	And we think that there's a lot of benefit that can be made by allowing people to design
4607760	4615360	chips faster, get them to market quicker and scale out. Because at the alleged end of Moore's
4615360	4621920	Law, you've got this problem of you're not getting free performance just by waiting another year
4621920	4626960	for a faster CPU. And so you have to find performance in other ways. And one of the
4626960	4630480	ways to do that is with custom accelerators and other things in hardware.
4631360	4641920	And so we'll talk a little more about ASICs. But do you see that a lot of people,
4641920	4647760	a lot of companies will try to have a different sets of requirements that this whole process
4647760	4655120	to go for. So almost different car companies might use different and different PC manufacturers.
4655680	4664080	Is risk five in this whole process, is it potentially the future of all computing devices?
4664720	4669520	Yeah, I think that, so if you look at risk five and step back from the silicon side of things,
4669520	4675360	risk five is an open standard. And one of the things that has happened over the course of decades,
4675360	4679120	if you look over the long arc of computing, somehow became decades old.
4679120	4679760	Yeah.
4679760	4684160	Because you have companies that come and go and you have instruction sets that come and go.
4684720	4689120	Like one example of this out of many is Sun with Spark.
4689760	4690240	Yeah.
4690240	4696320	Sun one way. Spark still lives on it if you just do. But we have HP had this instruction set called
4696320	4703680	PA risk. So PA risk was its big server business and had tons of customers. They decided to move
4703680	4708960	to this architecture called itanium from Intel. Yeah, it didn't work out so well.
4709520	4710000	Yeah.
4710000	4715520	Right. And so you have this issue of you're making many billion dollar investments on
4715520	4720800	instruction sets that are owned by a company. And even companies as big as Intel don't always
4720800	4723520	execute as well as they could. They have their own issues.
4724640	4728480	HP for example, decided that it wasn't in their best interest to continue investing in the space
4728480	4733040	because it was very expensive. And so they make technology decisions or they make their
4733040	4736720	own business decisions. And this means that as a customer, what do you do?
4737680	4741200	You've sunk all this time, all this engineering, all this software work, all these,
4741200	4743200	you've built other products around them and now you're stuck.
4744320	4748960	Right. What risk five does is provide you more optionality in the space because if you buy
4749840	4754160	an implementation of risk five from sci-fi, and you should, they're the best ones.
4756160	4761040	But if something that happens to sci-fi in 20 years, right, well, great, you can turn around
4761040	4765440	and buy risk five core from somebody else. And there's an ecosystem of people that are all making
4765440	4769920	different risk five cores with different trade-offs, which means that if you have more than one
4769920	4773840	requirement, if you have a family of products, you can probably find something in the risk five
4773840	4778960	space that fits your needs. Whereas with, if you're talking about XA6, for example,
4780240	4783200	Intel's only going to bother to make certain classes of devices.
4784640	4794640	Right. I see. So maybe a weird question, but like if sci-fi is infinitely successful
4794720	4800720	in the next 20, 30 years, what does the world look like? So like, how does the world of computing
4800720	4807040	change? So too much diversity in hardware instruction sets, I think is bad. We have a
4807040	4812160	lot of people that are using lots of different instruction sets, particularly in the embedded,
4812160	4819920	the very tiny microcontroller space, the thing in your toaster, that are just weird and different
4819920	4824320	for historical reasons. And so the compilers and the tool chains and the languages on top of them,
4825120	4831680	aren't there. And so the developers for that software have to use really weird tools because
4831680	4836560	the ecosystem that supports is not big enough. So I expect that will change. People will have
4836560	4840560	better tools and better languages, better features everywhere that then can serve as many
4840560	4847680	different points in the space. And I think risk five will progressively eat more of the ecosystem
4847680	4852800	because it can scale up, it can scale down sideways, left, right. It's very flexible and
4852800	4858080	very well-considered and well-designed instruction set. I think when you look at sci-fi of tackling
4858080	4864960	silicon and how people build chips, which is a very different space, that's where you say,
4864960	4869680	I think we'll see a lot more custom chips. And that means that you get much more battery life,
4869680	4878160	you get better, better tuned solutions for your IoT thingy. You get people that move faster,
4878160	4881280	you get the ability to have faster time to market, for example.
4881280	4887200	So how many custom... So first of all, on the IoT side of things, do you see the number of smart
4887920	4898800	toasters increasing exponentially? And if you do, how much customization per toaster is there?
4898800	4905120	Do all toasters in the world run the same silicon, the same design? Or is it different companies
4905120	4908800	have different designs? How much customization is possible here?
4909520	4916240	Well, a lot of it comes down to cost. And so the way that chips work is you end up paying by the...
4916240	4921680	One of the factors is the size of the chip. And so what ends up happening just from an
4921680	4927280	economic perspective is there's only so many chips that get made in any year of a given design.
4927280	4932080	And so often what customers end up having to do is they end up having to pick up a chip that exists
4932080	4937280	that was built for somebody else so that they can then ship their product. And the reason for that
4937280	4942240	is they don't have the volume of the iPhone. They can't afford to build a custom chip. However,
4942240	4948160	what that means is they're now buying an off-the-shelf chip that isn't a perfect fit for their needs.
4948160	4952400	And so they're paying a lot of money for it because they're buying silicon that they're not using.
4953360	4958160	Well, if you now reduce the cost of designing the chip, now you get a lot more chips. And
4958160	4964160	the more you reduce it, the easier it is to design chips. The more the world keeps evolving,
4964160	4968720	and we get more AI accelerators, we get more other things, we get more standards to talk to,
4968720	4974480	we get 6G, right? You get changes in the world that you want to be able to talk to these different
4974480	4979760	things. There's more diversity in the cross product of features that people want. And that drives
4980640	4985520	differentiated chips in another direction. And so nobody really knows what the future looks like.
4985520	4988800	But I think that there's a lot of silicon in the future.
4989600	4995520	Speaking of the future, you said Moore's Law allegedly is dead. So do you agree with
4997520	5003840	Dave Patterson and many folks that Moore's Law is dead? Or do you agree with Jim Keller,
5006080	5010640	who's standing at the helm of the pirate ship, saying it's still alive?
5010640	5017680	It's still alive. Well, so I agree with what they're saying, and different people are interpreting
5017680	5024080	the animal's law in different ways. So Jim would say, there's another 1000X left in physics,
5024080	5030000	and we can continue to squeeze the stone and make it faster and smaller and smaller geometries and
5030000	5037040	all that kind of stuff. He's right. So Jim is absolutely right that there's a ton of progress
5037040	5043760	left. And we're not at the limit of physics yet. That's not really what Moore's Law is, though.
5044880	5051360	If you look at what Moore's Law is, is that it's a very simple evaluation of, okay, well,
5051360	5056880	you look at the cost per, I think it was cost per area and the most economic point in that space.
5056880	5063040	And if you go look at the now quite old paper that describes this, Moore's Law has a specific
5063040	5068160	economic aspect to it. And I think this is something that Dave and others often point out.
5068160	5074320	And so on a technicality, that's right. I look at it from, so I can acknowledge both of those
5074320	5079040	viewpoints. They're both right. They're both right. I'll give you a third wrong viewpoint
5079040	5085040	that may be right in its own way, which is single threaded performance doesn't improve
5085040	5091120	like it used to. And it used to be back when you got a, you know, a Pentium 66 or something. And
5091200	5097600	the year before, you had a Pentium 33. And now it's twice as fast. Right? Well, it was twice as
5097600	5103680	fast at doing exactly the same thing. Okay. Like literally the same program ran twice as fast.
5103680	5108720	You just wrote a check and waited a year, year and a half. Well, so that's what a lot of people
5108720	5114160	think about Moore's Law. And I think that is dead. And so what we're seeing instead is we're pushing,
5115120	5118080	we're pushing people to write software in different ways. And so we're pushing people to
5118080	5124480	write CUDA so they can get GPU compute and the thousands of cores on GPU. We're talking about
5124480	5129840	C programmers having to use P threads because they now have, you know, 100 threads or 50 cores
5129840	5133680	in a machine or something like that. You're now talking about machine learning accelerators that
5133680	5139040	are now domain specific. And when you look at these kinds of use cases, you can still get
5139040	5145600	performance. And Jim will come up with cool things that utilize the silicon in new ways for sure.
5145600	5149600	But you're also going to change the programming model. Right. And now when you start talking
5149600	5153680	about changing the programming model, that's when you come back to languages and things like this
5153680	5160240	too. Because often what you see is like you take the C programming language, right? The C programming
5160240	5166720	language is designed for CPUs. And so if you want to talk to GPU, now you're talking to its cousin,
5166720	5172720	CUDA. Okay. CUDA is a different thing with a different set of tools, a different world,
5172800	5178080	a different way of thinking. And we don't have one world that scales. And I think that we can
5178080	5182800	get there. We can have one world that scales in a much better way. On a small tangent, then I think
5182800	5188800	most programming languages are designed for CPUs, for a single core, even just in their spirit,
5188800	5193360	even if they allow for parallelization. So what does it look like for programming language
5194080	5200640	to have parallelization or massive parallelization as it's like first principle?
5201200	5208480	So the canonical example of this is the hardware design world. So Verilog, VHDL,
5208480	5214880	these kinds of languages, they're what's called a high-level synthesis language. This is the thing
5214880	5220720	people design chips in. And when you're designing a chip, it's kind of like a brain where you have
5220720	5226480	infinite parallelism. Like you've got, you're like laying down transistors. Transistors are always
5226560	5231360	running. And so you're not saying run this transistor, then this transistor, then this
5231360	5235360	transistor. It's like your brain, like your neurons are always just doing something. They're
5235360	5243440	not clocked. They're just doing their thing. And so when you design a chip or when you design a CPU,
5243440	5246560	when you design a GPU, when you design when you're laying down the transistors,
5247200	5250320	similarly, you're talking about, well, okay, well, how do these things communicate?
5251200	5256000	And so these languages exist. Verilog is a kind of mixed example of that.
5256000	5259440	Now, these languages are really great. Yeah, very low level. Yeah.
5259440	5264080	Yeah, they're very low level. And abstraction is necessary here. And there's different approaches
5264080	5270960	with that. And it's itself a very complicated world. But it's implicitly parallel. And so
5271680	5278000	having that as the domain that you program towards makes it so that by default, you get
5278000	5283600	parallel systems. If you look at CUDA, CUDA is a point halfway in the space where in CUDA,
5283600	5288160	when you write a CUDA kernel for your GPU, it feels like you're writing a scalar program. So
5288160	5291360	you're like, you have ifs, you have for loops, stuff like this, you're just writing normal,
5291360	5296320	normal code. But what happens outside of that in your driver is that it actually is running you on
5296320	5301840	like 1000 things at once. Right. And so it's, it's parallel, but it has pulled it out of the
5301840	5308800	programming model. And so now you as a programmer are working in a, in a simpler world, and it's
5308800	5313360	solved that for you. How do you take the language like Swift?
5315360	5320800	You know, if we think about GPUs, but also ASICs, maybe if we can dance back and forth
5320800	5327600	between hardware and software, is, you know, how do you design for these features to be able to
5327600	5332960	program, make it a first class citizen to be able to do like Swift for TensorFlow,
5332960	5338240	to be able to do machine learning on current hardware, but also future hardware like
5338880	5342080	TPUs and all kinds of ASICs that I'm sure will be popping up more and more.
5342080	5346400	Yeah. Well, so, so a lot of this comes down to this whole idea of having the nuts and bolts
5346400	5351120	underneath the covers that work really well. So you need, if you're talking to TPUs, you need,
5351120	5357280	you know, MLIR or XLA or one of these compilers that talks to TPUs to build on top of. Okay.
5357280	5361440	And if you're talking to circuits, you need to figure out how to lay down the transistors and
5361440	5365440	how to organize it and how to set up clocking and like all the domain problems that you get with
5365520	5370400	circuits. Then you have to decide how to explain it to a human. What is EY?
5371520	5375280	Right. And if, if you do it right, that's a library problem, not a language problem.
5376320	5380160	And that works if you have a library or a language which allows your library
5381200	5385120	to write things that feel native in the language by implementing libraries,
5385760	5391040	because then you can innovate in programming models without having to change your syntax again.
5391040	5396560	And like you have to invent new code formatting tools and like all the other things that languages
5396560	5403040	come with. And this, this gets really interesting. And so if you look at this space, the interesting
5403040	5408960	thing once you separate out syntax becomes what is that programming model? And so do you want the
5408960	5416000	CUDA style? I write one program and it runs many places. The, do you want the implicitly parallel
5416000	5421440	model? How do you reason about that? How do you give developers, you know, chip architects the,
5421440	5426720	the ability to express their intent? And that comes into this whole design question of,
5426720	5431280	how do you detect bugs quickly? So you don't have to tape out a chip to find out it's wrong,
5431280	5437040	ideally, right? How do you, and, and, you know, this is a spectrum. How do you make it so that
5437040	5441440	people feel productive? So their turnaround time is very quick. All these things are really hard
5441440	5447600	problems. And, and this world, I think that not a lot of effort has been put into that design
5447600	5453360	problem and thinking about the layering and other pieces. Well, you've, on the topic of concurrency,
5453360	5458000	you've written the Swift concurrency manifesto. I think it's, it's kind of interesting. Anything
5458000	5465520	that has the word manifesto in is very interesting. Can you summarize the key ideas of each of the
5465520	5472240	five parts you've written about? So what is a manifesto? Yes. How about we start there? So in
5472240	5476720	the Swift community, we have this problem, which is on the one hand, you want to have
5477520	5482400	relatively small proposals that you can kind of fit in your head. You can understand the details
5482400	5487440	at a very fine grain level that move the world forward. But then you also have these big arcs.
5488000	5493120	Okay. And often when you're working on something that is a big arc, but you're tackling it in
5493120	5497920	small pieces, you have this question of, how do I know I'm not doing a random walk? Where are we
5497920	5503440	going? Like, how does this add up? Furthermore, when you start that first, the first small step,
5503440	5507760	what terminology do you use? How do we think about it? What is better and worse in the space?
5507760	5511280	What are the principles? What are we trying to achieve? And so what a manifesto in the Swift
5511280	5516480	community does is it starts to say, Hey, well, let's step back from the details of everything.
5516480	5521520	And let's paint a broad picture to talk about how, what we're trying to achieve. Let's give
5521520	5526560	an example design point. Let's try to paint the big picture so that then we can zero in on the
5526560	5530640	individual steps and make sure that we're making good progress. And so the Swift concurrency
5530640	5536400	manifesto is something I wrote three years ago, it's been a while, maybe, maybe more, trying to
5536400	5542960	do that for, for Swift in concurrency. It starts with some fairly simple things like making the
5542960	5547680	observation that when you have multiple different computers or multiple different threads that are
5547760	5553840	communicating, it's best for them to be asynchronous. And so you need things to be able to run
5553840	5558480	separately and then communicate with each other. And this means a synchrony. And this means that
5558480	5562960	you need a way to modeling asynchronous communication. Many languages have features like
5562960	5568000	this. Async await is a popular one. And so that's what I think is very likely in Swift.
5569280	5573600	But as you start building this tower of abstractions, it's not just about how do you write this,
5573600	5578640	you then reach into the, how do you get memory safety? Because you want correctness, you want
5579200	5584400	debuggability and sanity for developers. And how do you get that memory safety into,
5585200	5590800	into the language? So if you take a language like Go or C or any of these languages, you get what's
5590800	5595520	called a race condition when two different threads or Go routines or whatever touch the same point
5595520	5603680	in memory, right? This is a huge like maddening problem to debug because it's not reproducible
5603680	5608240	generally. And so there's tools, there's a whole ecosystem of solutions that built up around this,
5608240	5613280	but it's, it's a huge problem when you're writing concurrent code. And so with Swift, this whole
5613280	5618720	value semantics thing is really powerful there because it turns out that math and copies actually
5618720	5623520	work even in concurrent worlds. And so you get a lot of safety just out of the box, but there are
5623520	5628320	also some hard problems and it talks about some of that. When you start building up to the next
5628320	5631840	level up and you start talking beyond memory safety, you have to talk about what is the programmer
5631840	5636720	model? How does a human think about this? So a developer that's trying to build a program,
5636720	5642640	think about this, and it proposes a really old model with a new spin called actors. Actors are
5642640	5649120	about saying, we have islands of single threadedness, logically. So you write something that feels
5649120	5655040	like it's one programming, one program running in a unit, and then it communicates asynchronously
5655040	5661120	with other other things. And so making that expressive and natural feel good be the first
5661120	5665840	thing you reach for and being safe by default is a big part of the design of that proposal.
5666400	5670320	When you start going beyond that, now you start to say, cool, well, these things that communicate
5670320	5674240	asynchronously, they don't have to share memory. Well, if they don't have to share memory and
5674240	5677680	they're sending messages to each other, why do they have to be in the same process?
5679120	5683920	These things should be able to be in different processes on your machine. And why just processes?
5683920	5689920	Well, why not different machines? And so now you have a very nice gradual transition towards
5689920	5694720	distributed programming. And of course, when you start talking about the big future,
5694720	5702400	the manifesto doesn't go into it, but accelerators are things you talk to asynchronously by sending
5702400	5708400	messages to them. And how do you program those? Well, that gets very interesting. That's not in
5708400	5716480	the proposal. And how much do you want to make that explicit, like the control of that whole
5716480	5721680	process explicit to the programmer? Yeah, good question. So when you're designing any of these
5721680	5726960	kinds of features or language features or even libraries, you have this really hard tradeoff
5726960	5732320	you have to make, which is how much is it magic or how much is it in the human's control? How much
5732400	5738320	can they predict and control it? What do you do when the default case is the wrong case?
5740160	5746720	And so when you're designing a system, I won't name names, but there are systems where
5748640	5755520	it's really easy to get started. And then you jump it. So let's pick like logo. So something like this.
5755520	5760480	So it's really easy to get started. It's really designed for teaching kids. But as you get into
5760560	5764320	it, you hit a ceiling. And then you can't go any higher. And then what do you do? Well, you have
5764320	5769040	to go switch to a different world and rewrite all your code. And this logo is a silly example here.
5769040	5775840	This exists in many other languages. With Python, you would say like concurrency, right? So Python
5775840	5781520	has the global interpreter lock. So threading is challenging in Python. And so if you start writing
5781520	5786080	a large scale application in Python, and then suddenly you need concurrency, you're kind of
5786080	5792160	stuck with the series of bad trade-offs, right? There's other ways to go where you say like
5792160	5798720	foist all the complexity on the user all at once, right? And that's also bad in a different way.
5798720	5806000	And so what I prefer is building a simple model that you can explain that then has an escape
5806000	5812320	hatch. So you get in, you have guardrails, you memory safety works like this in Swift where
5812320	5817040	you can start with, like by default, if you use all the standard things, it's memory safe,
5817040	5822240	you're not going to shoot your foot off. But if you want to get a C level pointer to something,
5822240	5827440	you can explicitly do that. But by default, there's guardrails.
5827440	5830800	There's guardrails. Okay. So, but like, you know,
5832720	5836000	whose job is it to figure out which part of the code is paralyzable?
5836960	5840000	So in the case of the proposal, it is the human's job.
5840960	5847360	So they decide how to architect their application. And then the runtime in the compiler is very
5847360	5852880	predictable. And so this, this is in contrast to, like, there's a long body of work,
5852880	5860080	including on Fortran, for auto paralyzing compilers. And this is an example of a bad thing in my,
5860080	5864880	so as a compiler person, I can rag on compiler people. Often compiler people will say,
5865680	5868960	cool, since I can't change the code, I'm going to write my compiler that then takes
5868960	5874320	this unmodified code and makes it go way faster on this machine. Okay. Application development.
5874320	5879120	And so it does pattern matching, it does like really deep analysis, compiler people are really
5879120	5883680	smart. And so they like want to like do something really clever and tricky. And you get like 10x
5883680	5888000	speed up by taking like an array of structures and turn it into a structure of arrays or something,
5888000	5891520	because it's so much better for memory. Like there's bodies, like tons of tricks.
5892480	5895680	They love optimization. Yeah, you love optimization. Everyone loves optimization.
5895680	5899920	Everyone loves it. Well, and it's this promise of build with my compiler and your thing goes fast.
5899920	5903920	Yeah. Right. But here's the problem. Lex, you write, you write a program,
5904560	5908240	you run it with my compiler, it goes fast, you're very happy. Wow, it's so much faster than the
5908240	5912640	other compiler. Then you go and you got a feature to your program or you refactor some code. And
5912640	5917920	suddenly you got a 10x loss in performance. Well, why? What just happened there? What just happened
5918000	5922640	there is you, the heuristic, the pattern matching the compiler or whatever analysis
5922640	5928080	it was doing just got defeated because you didn't inline a function or something, right?
5928080	5930720	As a user, you don't know, you don't want to know, that was the whole point,
5930720	5934240	you don't want to know how the compiler works. You don't want to know how the memory hierarchy
5934240	5938000	works. You don't want to know how it got paralyzed across all these things. You wanted
5938000	5943440	that abstract away from you. But then the magic is lost as soon as you did something and you fall
5943440	5948400	off a performance cliff. And now you're in this funny position where what do I do? I don't change
5948400	5954240	my code. I don't fix that bug. It costs 10x performance. Now what do I do? Well, this is the
5954240	5958240	problem with unpredictable performance. If you care about performance, predictability is a very
5958240	5965440	important thing. And so what the proposal does is it provides architectural patterns for being able
5965440	5969920	to lay out your code, gives you full control over that, makes it really simple so you can explain
5970080	5975760	it. And then if you want to scale out in different ways, you have full control over that.
5976400	5981680	So in your sense, the intuition is for compilers too hard to do automated parallelization.
5983280	5989680	Because the compilers do stuff automatically that's incredibly impressive for other things.
5989680	5990320	Right.
5990320	5994480	But for parallelization, we're not even close to there.
5994480	5998240	Well, it depends on the programming model. So there's many different kinds of compilers.
5998240	6002560	And so if you talk about like a C compiler or a Swift compiler or something like that where
6002560	6007120	you're writing imperative code, parallelizing that and reasoning about all the pointers and
6007120	6012560	stuff like that is a very difficult problem. Now, if you switch domains, so there's this
6012560	6018560	cool thing called machine learning, right? So machine learning nerds among other endearing
6018560	6025280	things like solving cat detectors and other things like that have done this amazing breakthrough
6025280	6031040	of producing a programming model, operations that you compose together that has raised the
6031040	6036640	levels of abstraction high enough that suddenly you can have auto parallelizing compilers.
6036640	6042400	You can write a model using TensorFlow and have it run on 1024 nodes of a TPU.
6043280	6048080	Yeah, that's true. I didn't even think about like, you know, because there's so much flexibility
6048080	6052960	in the design of architectures that ultimately boil down to a graph that's parallelizable for you,
6052960	6056400	parallelized for you. And if you think about it, that's pretty cool.
6057520	6061920	And you think about batching, for example, as a way of being able to exploit more parallelism.
6062480	6066480	That's a very simple thing that now is very powerful. That didn't come out of the programming
6066480	6071360	language, nerds, those people. That came out of people that are just looking to solve a problem
6071360	6075920	and use a few GPUs and organically developed by the community of people focusing on machine
6075920	6082000	learning as an incredibly powerful abstraction layer that enables the compiler people to go
6082000	6087360	and exploit that. And now you can drive supercomputers from Python. That's pretty cool.
6087360	6092160	That's amazing. So just to pause on that, because I'm not sufficiently low level,
6092160	6098880	I forget to admire the beauty and power of that. But maybe just to linger on it, like what
6099600	6103920	does it take to run in your network fast? Like how hard is that compilation?
6103920	6108800	It's really hard. So we just skipped, you said like, it's amazing that that's a thing.
6109520	6111440	But how hard is that of a thing?
6111440	6116080	It's hard. And I would say that not all of the systems are really great,
6117040	6120560	including the ones I helped build. So there's a lot of work left to be done there.
6120560	6124480	Is it the compiler nerds working on that? Or is it a whole new group of people?
6124480	6130320	Well, it's a full stack problem, including compiler people, including APIs, like Keras and
6130320	6136560	the module API and PyTorch and JAX. And there's a bunch of people pushing on all the different
6136560	6141120	parts of these things. Because when you look at it, it's both, how do I express the computation?
6141120	6146160	Do I stack up layers? Well, cool. Setting up a linear sequence of layers is great for the
6146160	6149520	simple case. But how do I do the hard case? How do I do reinforcement learning? Well,
6149520	6154560	now I need to integrate my application logic in this. Then it's the next level down of,
6154560	6157920	how do you represent that for the runtime? How do you get hardware abstraction?
6158960	6161760	And then you get to the next level down of saying, forget about abstraction,
6161760	6167360	how do I get the peak performance out of my TPU or my iPhone accelerator or whatever,
6167360	6170800	right? And all these different things. And so this is a layered problem with a lot of really
6170800	6176800	interesting design and work going on in the space. And a lot of really smart people working on it.
6176800	6181520	Machine learning is a very well-funded area of investment right now. And so
6181520	6185120	there's a lot of progress being made. So how much innovation is there on the
6185120	6190960	lower level, so closer to the ASIC? So redesigning the hardware or redesigning
6191040	6195600	concurrently compilers with that hardware? If you were to predict the biggest,
6197600	6203120	you know, the equivalent of Moore's law improvements in the inference and the training
6203120	6206880	of neural networks and just all of that, where is that going to come from, you think?
6206880	6212160	Sure. You get scalability, you have different things. And so you get Jim Keller shrinking
6212160	6217600	process technology, you get three nanometers instead of five or seven or 10 or 28 or whatever.
6218320	6223440	And so that marches forward and that provides improvements. You get architectural level
6223440	6228720	performance. And so the, you know, a TPU with a matrix multiply unit in a systolic array is
6228720	6234240	much more efficient than having a scaler core doing multiplies and ads and things like that.
6234240	6241280	You then get system level improvements. So how you talk to memory, how you talk across a cluster
6241280	6247040	of machines, how you scale out, how you have fast interconnects between machines, you then get system
6247040	6251440	level programming models. So now that you have all this hardware, how do you utilize it? You then
6251440	6256160	have algorithmic breakthroughs where you say, Hey, wow, cool. Instead of training in, you know,
6256160	6264720	resident 50 and a week, I'm now training it in, you know, 25 seconds. And it's a combination of,
6264720	6270960	you know, new, new optimizers and new, new, new just training regimens and different,
6270960	6274880	different approaches to train. And, and all of these things come together to, to push the world
6274880	6283280	forward. That was a beautiful exposition. But if you were to force to bet all your money on one of
6283280	6291040	these, would you? Why do we have to? Unfortunately, we have people working on all this. It's an
6291040	6297040	exciting time, right? So I mean, you know, open the eye, did this little paper showing the algorithmic
6297040	6302480	improvement you can get has been, you know, improving exponentially. I haven't quite seen
6302480	6309200	the same kind of analysis on other layers of the stack. I'm sure it's also improving significantly.
6309200	6315360	I just, it's a, it's a nice intuition builder. I mean, there's a reason why Moore's law,
6316000	6321120	that's the beauty of Moore's law is somebody writes a paper that makes a ridiculous prediction.
6322560	6328800	And it, you know, becomes reality in a sense. There's, there's something about these narratives
6328880	6336560	when you, when Chris Latner on a silly little podcast makes bets, all his money on a particular
6336560	6341600	thing, somehow it can have a ripple effect of actually becoming real. That's an interesting
6342240	6348560	aspect of it. Cause like, it might have been, you know, we focused with Moore's law, most of the
6348560	6355200	computing industry really, really focused on the hardware. I mean, software innovation, I don't
6355280	6357200	know how much software innovation there was in terms of
6357200	6358800	what Intel give a bill takes away.
6360160	6363360	Yeah. I mean, compilers improved significantly also.
6364000	6368880	Well, not, not really. So actually, I mean, some, I'm joking about how software's gotten slower
6368880	6374240	pretty much as fast as Harvard got better, at least through the nineties. There's another joke,
6374240	6378480	another law in compilers, which is called, I think it's called probestine's law, which is
6379680	6383520	compilers double the performance of any given code every 18 years.
6386160	6387120	So they move slowly.
6387920	6390880	Yeah. Well, so well, yeah, it's exponential also.
6390880	6396960	Yeah. You're making progress, but there again, it's not about the power of compilers is not
6396960	6400640	just about how do you make the same thing go faster? It's how do you unlock the new hardware?
6401760	6405600	A new chip came out. How do you utilize it? You say, oh, the programming model, how do we make
6405600	6413520	people more productive? How do we, how do we like have better error messages? Even such mundane
6413520	6419200	things like how do I generate a very specific error message about your code actually makes people
6419200	6423760	happy because then they know how to fix it, right? And it comes back to how do you help people get
6423760	6430320	their job done? Yeah. And yeah. And then in this world of exponentially increasing smart toasters,
6430320	6438080	how do you expand computing to all these kinds of devices? Do you see this world where just
6438080	6444000	everything's a computing surface? You see that possibility? Just everything's a computer?
6444000	6447680	Yeah, I don't see any reason that that couldn't be achieved. It turns out that
6448480	6455200	sand goes into glass and glass is pretty useful too. And, you know, like, why not?
6455200	6465680	Why not? So a very important question then if, if we're living in a simulation and the simulation
6465680	6470320	is running a computer, like, what was the architecture of that computer, do you think?
6471760	6476080	So you're saying is it a quantum system? Is it? Yeah, like this whole quantum
6476080	6482400	discussion, is it needed? Or can we run it on a, you know, with a risk five architecture,
6483600	6488400	a bunch of CPUs? I think it comes down to the right tool for the job. Okay. And so.
6488400	6493600	And what's the compiler? Yeah, exactly. That's, that's my question. Did I get that job?
6493680	6500720	Feed the universe compiler. And so there, as far as we know, quantum, quantum,
6500720	6507440	quantum systems are the bottom of the pile of turtles so far. Yeah. And so we don't know
6507440	6510880	efficient ways to implement quantum systems without using quantum computers.
6512080	6515040	Yeah. And that's totally outside of everything we've talked about quantum.
6515040	6520400	But who runs that quantum computer? Yeah. Right. So if we really are living in a simulation,
6521360	6526480	then is it bigger quantum computers? Is it different ones? Like, how does that work out?
6526480	6531040	How does that scale? Well, it's the same size. It's the same size. But then,
6531040	6534720	but then the thought of the simulation is that you don't have to run the whole thing that,
6534720	6537440	you know, we humans are cognitively very limited. Do you do check points?
6537440	6543920	Do you do check points? Yeah. And, and if we, the point at which we human, so you basically do
6543920	6552960	minimal amount of, what is it, the SWIFT does on right, copy on right. So you only,
6552960	6557440	yeah, you only adjust the simulation and parallel universe theories. Right. And so,
6557440	6563680	and so every time a decision is made, somebody opens the shorting in your box, then there's a fork.
6563680	6570640	And then this could happen. And then thank you for considering the possibility. But yeah,
6570640	6574880	so it may not require, you know, the entirety of the universe to simulate it. But it's
6576000	6583760	interesting to think about as we create this, this higher and higher fidelity systems. But
6583760	6588240	I do want to ask on the, on the quantum computer side, because everything we've talked about
6588240	6592080	with us, with your work with sci-fi, with everything with compilers,
6592080	6596160	none of that includes quantum computers. Right. That's true. So
6597120	6605040	if you ever thought about what a, you know, this whole serious engineering work,
6605040	6610480	how quantum computers looks like of compilers, of architectures, all of that kind of stuff.
6610480	6614080	So I've looked at it a little bit. I'd know almost nothing about it,
6614080	6618000	which means that at some point I will have to find an excuse to get involved, because that's
6618000	6622400	how it works. But do you think, do you think that's the thing to be, like, is, with your little
6622480	6626720	tingly senses of the timing of when to be involved? Is it not yet?
6626720	6632800	Well, so the thing I do really well is I jump into messy systems and figure out how to make them
6633520	6639040	figure out what the truth in the situation is, try to figure out what the unifying theory is,
6639040	6642960	how to, like, factor the complexity, how to find a beautiful answer to a problem that
6643760	6647440	has been well studied and lots of people have bashed their heads against it. I don't know that
6647440	6653840	quantum computers are mature enough and accessible enough to be figured out yet, right? And
6656000	6660160	the, I think the open question with quantum computers is, is there a useful problem that
6660160	6665520	gets solved with the quantum computer that makes it worth the economic cost of, like,
6665520	6672400	having one of these things and having legions of people that set it up? You go back to the 50s,
6672480	6676880	right? And there's the projections of the world will only need seven computers,
6677520	6681840	right? Well, and part of that was that people hadn't figured out what they're useful for.
6681840	6684880	What are the algorithms we want to run? What are the problems that get solved? And this comes back
6684880	6689840	to how do we make the world better, either economically or making somebody's life better,
6689840	6695040	or, like, solving a problem that wasn't solved before, things like this. And I think that just
6695040	6698320	we're a little bit too early in that development cycle because it's still, like, literally a science
6698320	6704400	project, not a negative connotation, right? It's literally a science project. And the progress
6704400	6710560	there's amazing. And so I don't know if it's 10 years away, if it's two years away, exactly where
6710560	6717360	that breakthrough happens. But you look at machine learning, it, we went through a few winters
6718320	6724160	before the AlexNet transition, and then suddenly had its breakout moment. And that was the catalyst
6724240	6729840	that then drove the talent flocking into it. That's what drove the economic applications
6729840	6734880	of it. That's what drove the technology to go faster because you now have more minds thrown
6734880	6741200	at the problem. This is what caused, like, a serious knee and deep learning and the algorithms
6741200	6746080	that we're using. And so I think that's what quantum needs to go through. And so right now,
6746080	6752400	it's in that formidable finding itself, getting the, like, literally the physics figured out.
6752960	6757200	And then it has to figure out the application that makes that useful.
6758480	6762720	I'm not skeptical that I think that will happen. I think it's just, you know, 10 years away,
6762720	6766960	something like that. I forgot to ask, what programming language do you think the simulation
6766960	6778000	is written in? Probably Lisp. So not Swift. Like, if you were to bet, I'll just leave it at that.
6778000	6782320	So, I mean, we've mentioned that you worked with all these companies, we've talked about all these
6782320	6789920	projects. It's kind of, if we just step back and zoom out about the way you did that work,
6789920	6796000	and we look at COVID times, this pandemic we're living through, that may, if I look at the way
6796000	6801440	Silicon Valley folks are talking about it, the way MIT is talking about it, this might last for a
6801440	6811280	long time, not just the virus, but the remote nature. The economic impact. Yeah, it's going to
6811280	6821520	be a mess. Do you think, what's your prediction? I mean, from sci-fi to Google, to just all the
6821520	6824880	places you worked in, just Silicon Valley, you're in the middle of it. What do you think is,
6824880	6829680	how is this whole place going to change? Yeah, so, I mean, I really can only speak to the tech
6829680	6836720	perspective. I am in that bubble. I think it's going to be really interesting because the, you
6836720	6841040	know, the zoom culture of being remote and on video chat all the time has really interesting
6841040	6847120	effects on people. So on the one hand, it's a great normalizer. It's a normalizer that I think
6847120	6853280	will help communities of people that have traditionally been underrepresented. Because
6853280	6857360	now you're taking, in some cases, a face off, because you don't have to have a camera going,
6858320	6862560	right? And so you can have conversations without physical appearance being part of the dynamic,
6862560	6867040	which is pretty powerful. You're taking remote employees that have already been remote and
6867040	6872320	you're saying you're now on the same level and footing as everybody else. Nobody gets whiteboards.
6873280	6876400	You're not going to be the one person that doesn't get to be participating in the whiteboard
6876400	6882160	conversation. And that's pretty powerful. You've got, you're forcing people to think
6883120	6888240	asynchronously in some cases, because it's hard to just, just get people physically together and
6888240	6893120	the bumping into each other forces people to find new ways to solve those problems. And I think
6893120	6898160	that that leads to more inclusive behavior, which is good. On the other hand, it's also, it just
6898160	6906400	sucks, right? And so the, the nature, the, the actual communication or it just sucks being
6906400	6910720	not in, with people like on a daily basis and collaborating with them.
6911600	6916640	Yeah, all of that. I mean, everything, this whole situation is terrible. What I meant primarily
6916640	6923600	was the, I think that most humans like working physically with humans. I think this is something
6923600	6928800	that not everybody, but many people are programmed to do. And I think that we get something out of
6928800	6933280	that that is very hard to express, at least for me. And so maybe this isn't true of everybody. But
6933520	6938720	and so the question to me is, you know, when you get through that time of adaptation,
6939680	6944560	right, you get out of March and April and you get into December and you get into next March,
6944560	6949120	if it's not changed, right? It's already terrifying. Well, you think about that and you
6949120	6954160	think about what is the nature of work? And how do, how do we adapt? And humans are very adaptable
6954160	6959200	species, right? We can, we can learn things. And when we're forced to, and there's a catalyst to
6959200	6963680	make that happen. And so what is it that comes out of this? And are we better or worse off?
6964240	6968720	Right? I think that, you know, you look at the Bay Area, housing prices are insane.
6968720	6973120	Well, why? Well, there's a high incentive to be physically located, because if you don't have
6973120	6980240	proximity, you end up paying for it and commute, right? And there's, there has been huge social
6980240	6986080	social pressure in terms of like, you will be there for the meeting, right? Or whatever scenario
6986080	6990640	it is. And I think that's gonna be way better. I think it's gonna be much more the norm to have
6990640	6995120	remote employees. And I think this is gonna be really great. Do you, do you have friends or do
6995120	7002080	you hear of people moving? Yeah, I know one family friend that moved. They moved back to Michigan and
7003280	7008640	you know, they were a family with three kids living in a small apartment and like, we're going insane.
7010400	7015200	Right? And they're in tech, husband works for Google. So first of all,
7015200	7020960	friends of mine have, are in the process of or are have already lost the business. The thing that
7020960	7026240	represents their passion, their dream, it could be small entrepreneur projects, but it could be large
7026240	7030720	businesses like people that run gyms, like restaurants, like tons of things. Yeah. So,
7030720	7035200	but also people like look at themselves in the mirror and ask the question of like,
7036000	7040160	what do I want to do in life? For some reason, they don't, they haven't done it until COVID.
7040160	7046240	Like, they really ask that question and that results often in moving or leaving the company
7046240	7051360	here with starting your business or transitioning to a different company. Do you think we're gonna
7051360	7058000	see that a lot? Well, I can't speak to that. I mean, we're definitely gonna see it at a higher
7058000	7063600	frequency than we did before. Just because I think what you're trying to say is there are
7063600	7068000	decisions that you make yourself and big life decisions that you make yourself. And like,
7068000	7072800	I'm gonna like quit my job and start a new thing. There's also decisions that get made for you.
7072800	7077600	Like, I got fired from my job. What am I going to do? Right? And that's not a decision that you
7077600	7083520	think about, but you're forced to act. Okay. And so I think that those you're forced to act kind
7083520	7088320	of moments where like, you know, global pandemic comes and wipes out the economy. And now your
7088320	7093440	business doesn't exist. I think that does lead to more reflection, right? Because you're less
7093440	7099040	anchored on what you have. And it's not a, what do I have to lose versus what do I have to gain,
7099040	7105280	AB comparison? It's more of a fresh slate. Cool. I could do anything now. Do I want to do the same
7105280	7111360	thing I was doing? Did that make me happy? Is this now time to go back to college and take a class
7111360	7117680	and learn new skill? Is this a time to spend time with family? If you can afford to do that,
7117680	7122400	is this time to like, you know, literally move into the parents, right? I mean, all these things
7122400	7129120	that were not normative before suddenly become, I think, very, the value system has changed. And
7129120	7135600	I think that's actually a good thing in the short term, at least, because it leads to, you know,
7136480	7141680	there's kind of been an over optimization along one, one set of priorities for the world. And
7141680	7146400	now maybe we'll get to a more balanced and more interesting world where people are doing different
7146400	7149520	things. I think it could be good. I think there could be more innovation that comes out of it,
7149520	7154240	for example. What do you think about all the social chaos in the middle of? It sucks.
7157360	7159840	Let me ask you, I hope, do you think it's all going to be okay?
7160960	7166480	Well, I think humanity will survive. From the next extension, we're not all going to kill,
7166480	7170720	yeah, well. Yeah, I don't think the virus is going to kill all the humans. I don't think all the
7170720	7175120	humans are going to kill all the humans. I think that's unlikely. But I look at it as
7175360	7185840	progress requires a catalyst, right? So you need a reason for people to be willing to do
7185840	7191680	things that are uncomfortable. I think that the US, at least, but I think the world in general,
7191680	7198160	is a pretty unoptimal place to live in for a lot of people. And I think that what we're
7198160	7203440	seeing right now is we're seeing a lot of unhappiness. And because of all the pressure,
7203520	7207040	because of all the badness in the world that's coming together, it's really kind of igniting
7207040	7210560	some of that debate that should have happened a long time ago, right? I mean, I think that
7210560	7214400	we'll see more progress. You're asking about offline, you're asking about politics and wouldn't
7214400	7218080	be great if politics moved faster because there's all these problems in the world and we can move it.
7218080	7224880	Well, people are intentionally conservative. And so if you're talking about conservative people,
7224880	7228560	particularly if they have heavy burdens on their shoulders because they represent
7228560	7233840	literally thousands of people, it makes sense to be conservative. But on the other hand,
7233840	7239440	when you need change, how do you get it? The global pandemic will probably lead to some change.
7240480	7246880	And it's not a directed plan, but I think that it leads to people asking really interesting
7246880	7249440	questions. And some of those questions should have been asked a long time ago.
7249440	7254720	Well, let me know if you've observed this as well. Something has bothered me
7254720	7259040	in the machine learning community. I'm guessing it might be prevalent in other places
7259600	7266240	is something that feels like in 2020, increased level of toxicity. Like people are just
7267600	7278320	quicker to pile on, they're just harsh on each other to mob, pick a person that screwed up
7279200	7284400	and make it a big thing. And is there something that we can...
7286320	7290080	Have you observed that in other places? Is there some way out of this?
7290080	7293760	I think there's an inherent thing in humanity that's kind of an us versus them thing,
7294400	7298480	which is that you want to succeed. And how do you succeed? Well, it's relative to somebody else.
7299520	7306960	And so what's happening, at least in some part, is that with the internet and with online communication,
7306960	7315200	the world's getting smaller. And so we're having some of the social ties of my town versus your
7315200	7324800	town's football team turn into much larger and yet shallower problems. And people don't have time,
7324800	7330880	the incentives, clickbait and all these things really feed into this machine. And I don't know
7330960	7337040	where that goes. Yeah, I mean, the reason I think about that, I mentioned to you this offline a
7337040	7345040	little bit, but I have a few difficult conversations scheduled, some of them political-related,
7345040	7350480	some of them within the community, difficult personalities that went through some stuff.
7350480	7355760	I mean, one of them I've talked before, I will talk again, is Yann LeCun. He got a little crap on
7355760	7363840	Twitter for talking about a particular paper and the bias within a data set. And then there's been
7363840	7372720	a huge in my view, and I'm only comfortable saying it, irrational, over exaggerated pile on
7373360	7379280	on his comments, because he made pretty basic comments about the fact that if there's bias in
7379280	7385280	the data, there's going to be bias in the results. So we should not have bias in the data. But people
7385360	7391760	piled on to him because he said he trivialized the problem of bias. It's a lot more than just
7391760	7399920	bias in the data. But yes, that's a very good point. That's not what he was saying. And the
7399920	7409520	response, the implied response that he's basically sexist and racist is something that completely
7409600	7415600	drives away the possibility of a nuanced discussion. One nice thing about a pocket-long form
7417200	7424480	conversation is you can talk it out, you can lay your reasoning out, and even if you're wrong,
7424480	7427840	you can still show that you're a good human being underneath it.
7428400	7432400	Your point about you can't have a productive discussion, well, how do you get to that point
7432400	7437360	where people can turn, they can learn, they can listen, they can think, they can engage versus
7437440	7443200	just being a shallow like, like, and then keep moving, right? And I don't think that
7444640	7450080	progress really comes from that, right? And I don't think that one should expect that. I think
7450080	7455280	that you'd see that as reinforcing individual circles and the us versus them thing. And I
7455280	7462880	think that's fairly divisive. Yeah, I think there's a big role in, like, the people that bother me
7462880	7468880	most on Twitter when I observe things. It's not the people who get very emotional, angry,
7468880	7476640	like, over the top. It's the people who, like, prop them up. It's all the, it's that I think what
7476640	7483760	should be the, we should teach each other is to be sort of empathetic. The thing that it's really
7483760	7488320	easy to forget, particularly on, like, Twitter or the internet or the email, is that sometimes
7488320	7494160	people just have a bad day, right? You have a bad day, or you're like, I've been in this situation
7494160	7498160	where it's like, between meetings, like, fire off a quick response in emails, because I want to, like,
7498160	7505600	help get something unblocked, phrase it really objectively wrong. I screwed up. And suddenly,
7505600	7510880	this is now something that sticks with people. And it's not because they're bad. It's not because
7510880	7516480	you're bad, just psychology of like, you said a thing, it sticks with you, you didn't mean it
7516480	7521520	that way. But it really impacted somebody because the way they interpreted it, and this is just an
7521520	7526720	aspect of working together as humans. And I have a lot of optimism in the long term, the very long
7526720	7530720	term, about what we as humanity can do. But I think that's going to be, it's just always a rough
7530720	7536240	ride. And you came into this by saying, like, what is COVID and all the social strife that's
7536240	7541200	happening right now mean? And I think that it's really bad in the short term, but I think it
7541200	7547360	will lead to progress. And for that, I'm very thankful. Yeah, it's painful in the short term,
7547360	7551280	though. Well, yeah, I mean, people are out of jobs, like, some people can't eat, like, it's
7551280	7558800	horrible. And, but, but, you know, it's progress. So we'll see, we'll see what happens. I mean,
7558800	7564320	the real question is when you look back 10 years, 20 years, 100 years from now, how do we evaluate
7564320	7569680	the decisions that are being made right now? I think that's really the way you can frame that
7569680	7574160	and look at it. And you say, you know, you integrate across all the short term horribleness
7574160	7579520	that's happening. And you look at what that means. And is the, you know, improvement across the world
7579520	7584800	or the regression across the world significant enough to make it a good or bad thing? I think
7584800	7591280	that's the question. Yeah. And for that's good to study history. I mean, one of the big problems
7591280	7597680	for me right now is I'm reading the rise and fall of the third Reich. Light reading. So it's
7597680	7603440	everything is just, I just see parallels and it means it's, it's, you have to be really careful
7603440	7610160	not to overstep it, but just the, the thing that worries me the most is the pain that people feel
7610720	7616880	when, when a few things combined, which is like economic depression, which is quite possible
7616880	7623840	in this country. And then just being disrespected by in some kind of way, which the German people
7623920	7630880	were really disrespected by most of the world, like in a way that's over the top, that something
7630880	7637760	can, it can build up. And then all you need is a charismatic leader just to go either positive
7637760	7643280	or negative in both work, as long as they're charismatic. And it's taking advantage of,
7643280	7648400	again, that, that inflection point that the world's in and what they do with it could be good or bad.
7648960	7655680	And so it's a good way to think about times now, like on an individual level, what we decide to do
7655680	7660880	is when, when history is written, you know, 30 years from now, what happened in 2020,
7660880	7663840	probably history is going to remember 2020. Yeah, I think so.
7665440	7669440	Either for good or bad. And it's like up to us to write it. So it's good.
7669440	7674960	Well, one of the things I've observed that I find fascinating is most people act as though the world
7674960	7682080	doesn't change. You make decision knowingly, right, you make a decision where you're predicting
7682080	7685840	the future based on what you've seen in the recent past. And so if something's always been
7685840	7689360	had, it's rained every single day, then of course, you expect it to rain today too, right?
7689920	7696640	On the other hand, the world changes all the time. Yeah, constantly, like for better and for worse.
7696640	7700160	And so the question is, if you're interested in something that's not right,
7700800	7704320	what is the inflection point that led to a change? And you can look to history for this,
7704320	7709280	like what is, what is the catalyst that led to that, that explosion that led to that bill that
7709280	7715120	led to the, like you can kind of work your way backwards from that. And maybe if you pull together
7715120	7718240	the right people and you get the right ideas together, you can actually start driving that
7718240	7723040	change and doing it in a way that's productive and hurts fewer people. Yeah, like a single person,
7723040	7726960	single event can turn all. Yeah, absolutely. Everything starts somewhere. And often it's
7726960	7732480	a combination of multiple factors. But, but yeah, this is these, these things can be engineered.
7732480	7737840	That's actually the optimistic view that I'm a long-term optimist on pretty much everything and
7737840	7742160	human nature, you know, we can look to all the negative things that the humanity has,
7742160	7748640	all the pettiness and all the like self self-servingness and the just the the cruelty,
7749360	7754400	right? The biases, the just humans can be very horrible. But on the other hand,
7754400	7762240	we're capable of amazing things. And, and the progress across, you know, 100 year chunks is
7762320	7767680	striking. And even across decades, it's, we've come a long ways and there's so long ways to go,
7767680	7772960	but that doesn't mean that we've stopped. Yeah, the kind of stuff we've done in the last 100 years
7772960	7777760	is, is unbelievable. It's kind of scary to think what's going to happen this 100 years. It's scary,
7777760	7783280	like exciting, like scary in a sense that it's kind of sad that the kind of technology is going to
7783280	7788400	come out in 10, 20, 30 years will probably too old to really appreciate because you don't grow up
7788400	7794160	with it. It'll be like kids these days with their virtual reality and their talks and stuff like
7794160	7798800	this. Like, how does this thing and like, come on, give me my, you know, static photo.
7800800	7807120	My Commodore 64. Yeah, exactly. Okay. Sorry, we kind of skipped over. Let me ask on,
7808960	7815680	you know, the machine learning world has been kind of inspired, their imagination captivated
7815680	7822320	with GPT-3 and these language models. I thought it'd be cool to get your opinion on it. What's
7822320	7831040	your thoughts on this exciting world of, it connects to computation actually is of language
7831040	7838080	models that are huge and take multiple, many, many computers, not just to train, but to also
7838080	7843680	do inference on. Sure. Well, I mean, it depends on what you're speaking to there. But I mean,
7843680	7849280	I think that there's been a pretty well understood maximum deep learning that if you make the model
7849280	7853040	bigger and you shove more data into it, assuming you train it right and you have a good model
7853040	7859040	architecture, that you'll get a better model out. And so on one hand, GPT-3 was not that surprising.
7859680	7863200	On the other hand, a tremendous amount of engineering went into making it possible.
7864800	7869600	The implications of it are pretty huge. I think that when GPT-2 came out, there was a very
7869600	7874080	provocative blog post from OpenAI talking about, we're not going to release it because of the
7874080	7880480	social damage it could cause if it's misused. I think that's still a concern. I think that we
7880480	7886400	need to look at how technology is applied and well-meaning tools can be applied in very horrible
7886400	7892960	ways and they can have very profound impact on that. I think that GPT-3 is a huge technical
7892960	7897520	achievement. And what will GPT-4 be? Will it probably be bigger, more expensive to train?
7898560	7901120	Really cool architectural tricks.
7902240	7907680	What do you think? I don't know how much thought you've done on distributed computing.
7908640	7914560	Is there some technical challenges that are interesting that you're hopeful about exploring
7914560	7928240	in terms of a system like a piece of code that GPT-4 might have hundreds of trillions
7928240	7933840	of parameters which have to run on thousands of computers? Is there some hope that we can
7933840	7942320	make that happen? Today, you can write a check and get access to a thousand TPU cores and do
7942320	7946400	really interesting large-scale training and inference and things like that in Google Cloud,
7946400	7952320	for example. I don't think it's a question about scales, it's a question about utility.
7953120	7958640	And when I look at the Transformer series of architectures that the GPT series is based on,
7958640	7962960	it's really interesting to look at that because they're actually very simple designs. They're
7962960	7968720	not recurrent. The training regimens are pretty simple and so they don't really reflect like
7968720	7975760	human brains. But they're really good at learning language models and they're unrolled enough that
7976400	7983440	you can simulate some recurrence. And so the question I think about is, where does this take us?
7983440	7988400	We can just keep scaling it, have more parameters, more data, more things, we'll get a better result
7988400	7993840	for sure. But are there architectural techniques that can lead to progressive faster pace?
7994800	8000000	Right, this is when, you know, how do you get, instead of just like making it a constant time
8000000	8004400	bigger, how do you get like an algorithmic improvement out of this, right? And whether it
8004400	8011280	be a new training regimen, if it becomes sparse networks, for example, human brain sparse,
8011280	8016720	all these networks are dense. The connectivity patterns can be very different. I think this
8016720	8021360	is where I get very interested and I'm way out of my league on the deep learning side of this.
8021440	8026320	But I think that could lead to big breakthroughs. When we talk about large scale networks, one of
8026320	8032160	the things that Jeff Dean likes to talk about and he's given a few talks on is this idea of having
8032160	8038560	a sparsely gated mixture of experts kind of a model where you have, you know, different nets
8038560	8043840	that are trained and are really good at certain kinds of tasks. And so you have this distributor
8043840	8047520	across a cluster. And so you have a lot of different computers that end up being kind of
8047520	8052720	locally specialized in different demands. And then when a query comes in, you gate it and use
8052720	8057440	learn techniques to route to different parts of the network. And then you utilize the compute
8057440	8061840	resources of the entire cluster by having specialization within it. And I don't know
8062640	8066880	where that goes or if it starts when it starts to work. But I think things like that could be
8066880	8074160	really interesting as well. And on the data side too, if you can think of data selection as a
8074160	8079840	kind of programming. Yeah, I mean, at the center, if you look at like Karpathi talked about software
8079840	8086880	2.0, I mean, in a sense, data is the programming. Yeah, yeah. So I just, so let me try to summarize
8086880	8093520	Andre's position really quick before I disagree with it. Yeah. So Andre Karpathi is amazing. So
8093520	8099200	this is nothing personal with him. He's an amazing engineer and also a good blog post writer.
8099200	8103200	Yeah, well, he's a great communicator. I mean, he's just an amazing person. He's also really
8103280	8110640	sweet. So his basic premise is that software is suboptimal. I think we can all agree to that.
8111840	8116480	He also points out that deep learning and other learning based techniques are really great because
8116480	8122720	you can solve problems in more structured ways with less like ad hoc code that people write
8122720	8126240	out and don't write test cases for in some cases. And so they don't even know if it works in the
8126240	8134240	first place. And so if you start replacing systems of imperative code with deep learning models,
8134240	8141280	then you get better, a better result. Okay. And I think that he argues that software 2.0 is a
8141280	8147120	pervasively learned set of models. And you get away from writing code. And he's given talks where
8147120	8151680	he talks about, you know, swapping over more and more and more parts of the code to being learned
8151680	8158720	and driven that way. I think that works. And if you're pretty predisposed to liking machine
8158720	8163280	learning, then I think that that's definitely a good thing. I think this is also good for
8163280	8167600	accessibility in many ways because certain people are not going to write C code or something.
8167600	8172560	And so having a data driven approach to do this kind of stuff, I think can be very valuable.
8172560	8176480	On the other hand, they're huge trade offs. And it's not clear to me that software 2.0 is
8177040	8182320	the answer. And probably Andre wouldn't argue that it's the answer for every problem either.
8182960	8189440	But I look at machine learning as not a replacement for software 1.0. I look at it as a new programming
8189440	8196560	paradigm. And so programming paradigms, when you look across, across demands is the structured
8196560	8202320	programming where you go from go tos to if then else, or functional programming from Lisp. And
8202320	8206320	you start talking about higher order functions and values and things like this, or you talk about
8206320	8210320	object oriented programming, you're talking about encapsulation, subclassing inheritance,
8210320	8214640	you start talking about generic programming, where you start talking about code reuse through
8216560	8221120	specialization and different type instantiations. When you start talking about differentiable
8221120	8225840	programming, something that I am very excited about in the context of machine learning,
8225840	8231040	talking about taking functions and generating variants like the derivative of another function.
8231040	8236080	Like that's a programming paradigm that's very useful for solving certain classes of problems.
8236080	8239680	Machine learning is amazing at solving certain classes of problems. Like you're not going to
8239680	8247280	write a cat detector, or even a language translation system by writing C code. That's not a very
8247280	8251920	productive way to do things anymore. And so machine learning is absolutely the right way to do that.
8251920	8256640	In fact, I would say that learned models are really one of the best ways to work with the human
8256640	8261280	world in general. And so anytime you're talking about sensory input of different modalities,
8261280	8265680	anytime that you're talking about generating things in a way that makes sense to a human,
8265680	8270560	I think that learned models are really, really useful. And that's because humans are very difficult
8270560	8276960	to characterize. And so this is a very powerful paradigm for solving classes of problems.
8276960	8281680	But on the other hand, imperative code is too, you're not going to write a bootloader for your
8281680	8286960	computer with a deep learning model. Deep learning models are very hardware intensive,
8286960	8293280	they're very energy intensive, because you have a lot of parameters. And you can provably
8293360	8298320	implement any function with a learned model, like this has been shown. But that doesn't make it
8298320	8303600	efficient. And so if you're talking about caring about a few orders and magnitudes worth of energy
8303600	8306800	usage, then it's useful to have other tools in the toolbox.
8306800	8312400	There's also robustness too. I mean, exactly, all the problems of dealing with data and bias in data,
8312400	8317040	all the problems of, you know, software 2.0. And one of the great things that Andre is
8317920	8323680	arguing towards, which I completely agree with him, is that when you start implementing things
8323680	8328000	with deep learning, you need to learn from software 1.0 in terms of testing, continuous
8328000	8333840	integration, how you deploy, how do you validate all these things and building systems around that,
8333840	8338480	so that you're not just saying, like, ooh, it seems like it's good, ship it, right? Well,
8338480	8342000	what happens when I regress something? What happens when I make a classification that's
8342000	8347280	wrong and now I heard somebody, right? All these things you have to reason about.
8347280	8354240	Yeah, but at the same time, the bootloader that works for us humans looks awfully a lot like a
8354240	8360320	neural network, right? It's messy and you can cut out different parts of the brain. There's a lot of
8360320	8366880	this neuroplasticity work that shows that it's going to adjust. It's a really interesting question,
8366880	8371440	how much of the world's programming could be replaced by software 2.0?
8372720	8376320	Well, I mean, it's provably true that you could replace all of it.
8377440	8379040	Right, so then it's a question of the trade-offs.
8379040	8383840	So anything that's a function, you can. So it's not a question about if I think it's an
8383840	8388960	economic question. It's a, what kind of talent can you get? What kind of trade-offs in terms of
8388960	8393680	maintenance? Those kinds of questions, I think, what kind of data can you collect? I think one
8393760	8399040	of the reasons that I'm most interested in machine learning is a programming paradigm is that one
8399040	8404080	of the things that we've seen across computing in general is that being laser focused on one paradigm
8404640	8410320	often puts you in a box. It's not super great. And so you look at object-oriented programming,
8410320	8414320	like it was all the rage in the early 80s and like everything has to be objects and people
8414320	8419760	forgot about functional programming even though came first. And then people rediscovered that,
8419760	8424160	hey, if you mix functional and object-oriented and structure, like you mix these things together,
8424160	8428320	you can provide very interesting tools that are good at solving different problems.
8428320	8433360	And so the question there is, how do you get the best way to solve the problems? It's not about
8433360	8439120	whose tribe should win, right? It's not about, that shouldn't be the question. The question is,
8439120	8443440	how do you make it so that people can solve those problems the fastest and they have the right
8443440	8447760	tools in their box to build good libraries and they can solve these problems? And when you look
8447760	8452160	at that, that's like, you look at reinforcement learning as one really interesting subdomain
8452160	8456960	of this. Reinforcement learning, often you have to have the integration of a learned model
8457520	8462880	combined with your Atari or whatever the other scenario it is that you're working in. You have
8462880	8469440	to combine that thing with the robot control for the arm, right? And so now it's not just about
8469440	8475840	that one paradigm, it's about integrating that with all the other systems that you have, including
8475840	8481040	often legacy systems and things like this, right? And so to me, I think that the interesting thing
8481040	8485120	to say is like, how do you get the best out of this domain? And how do you enable people to
8485120	8490000	achieve things that they otherwise couldn't do without excluding all the good things we already
8490000	8498800	know how to do? Right. But okay, this is a crazy question. But we talked a little about GPT-3,
8498800	8507360	but do you think it's possible that these language models that in essence, in the language domain,
8507360	8514160	software 2.0 could replace some aspect of compilation, for example, or do program synthesis
8514160	8519680	replace some aspect of programming? Yeah, absolutely. So I think that the learned models
8519680	8522960	in general are extremely powerful. And I think the people underestimate them.
8523920	8530640	Maybe you can suggest what I should do. So of access to the GPT-3 API,
8531280	8535520	would I be able to generate Swift code, for example? Do you think that could do something
8535520	8542720	interesting? So GPT-3 is probably not trained on the right corpus. So it probably has the ability
8542720	8546880	to generate some Swift, I bet it does. It's probably not going to generate a large enough
8546880	8552080	body of Swift to be useful. But take it a next step further. If you had the goal of training
8552080	8559120	something like GPT-3, and you wanted to try to generate source code, it could definitely do that.
8559680	8564480	Now, the question is, how do you express the intent of what you want filled in? You can
8564480	8570480	definitely write scaffolding of code and say fill in the hole, and put in some for loops or put in
8570480	8574880	some classes or whatever. And the power of these models is impressive. But there's an unsolved
8574880	8579280	question, at least unsolved to me, which is, how do I express the intent of what to fill in?
8579840	8585840	Right. And kind of what you'd really want to have, and I don't know that these models are up to
8585840	8591040	the task, is you want to be able to say, here's the scaffolding, and here are the assertions at the end.
8592320	8596320	And the assertions always pass. And so you want a generative model, on the one hand, yes.
8596320	8597520	Oh, that's fascinating. Yeah.
8597520	8603040	Right. But you also want some loopback, some reinforcement learning system or something
8603040	8607680	where you're actually saying, like, I need to hill climb towards something that is more correct.
8608400	8614080	And I don't know that we have that. So it would generate not only a bunch of the code, but like
8614080	8618080	the checks that do the testing. It would generate the tests. I think the humans would generate
8618080	8623040	the tests, right? Oh, okay. But it would be fascinating if... Well, the tests are the requirements.
8623040	8626960	Yes, but the... Okay, so... Because you have to express to the model what you want to...
8626960	8630480	You don't just want gibberish code. Look at how compelling this code looks.
8631200	8634720	You want a story about four horned unicorns or something.
8634720	8640560	Well, okay, so exactly. But that's human requirements. But then I thought it's a compelling idea that
8640560	8652640	the GPT-4 model could generate checks that are more high fidelity, that check for correctness.
8652640	8660720	Because the code it generates, say I ask it to generate a function that gives me the Fibonacci
8660720	8667760	sequence. Sure. I don't like... So decompose the problem, right? So you have two things. You have...
8667760	8672320	You need the ability to generate syntactically corrects with code that's interesting, right?
8672960	8678720	I think GPT series of model architectures can do that. But then you need the ability to
8679360	8686240	add the requirements. So generate Fibonacci. The human needs to express that goal. We don't
8686240	8691200	have that language that I know of. No, I mean, it can generate stuff. Have you seen
8691200	8698240	what GPT-3 can generate? You can say, I mean, there's interface stuff. It can generate HTML.
8698240	8704880	It can generate basic for loops that give you... Right, but pick HTML. How do I say I want google.com?
8705920	8711040	Well, no, you can say... Or not literally google.com. How do I say I want a web page that's got a
8711040	8716880	shopping cart and this and that? It does that. Okay, so just... I don't know if you've seen these
8716880	8722640	demonstrations, but you type in, I want a red button with the text that says hello, and you
8722640	8727920	type that natural language, and it generates the correct HTML. I've done this demo. It's kind
8727920	8735040	of compelling. So you have to prompt it with similar kinds of mappings. Of course, it's probably
8735040	8740000	handpicked. I have to experiment that probably... But the fact that you can do that once, even out of
8740000	8747680	like 20 is quite impressive. Again, that's very basic. Like the HTML is kind of messy and bad.
8748320	8752480	But yes, the intent is... The idea is the intent is specified in natural language.
8753440	8759760	So I have not seen that. That's really cool. Yeah, but the question is the correctness of that.
8759760	8769520	Like visually, you can check, oh, the button is red. But for more complicated functions,
8770080	8775920	where the intent is harder to check, this goes into like NP completeness kind of things, like
8775920	8782400	I want to know that this code is correct and generates a giant thing that just some kind
8782400	8789520	of calculation. It seems to be working. It's interesting to think like should the system also
8789520	8794560	try to generate checks for itself for correctness? Yeah, I don't know. And this is way beyond my
8794560	8800400	experience. The thing that I think about is that there doesn't seem to be a lot of
8801040	8805920	equational reasoning going on. Right. There's a lot of pattern matching and filling in and
8805920	8809840	kind of propagating patterns that have been seen before into the future and into the
8809840	8814320	generated result. And so if you want to get correctness, you kind of need their improving
8814320	8819360	kind of things and like higher level logic. And I don't know that... You could talk to Yon about
8819360	8826160	that and see what the bright minds are thinking about right now. But I don't think the GPT
8826160	8832800	is in that vein. It's still really cool. Yeah. And who knows? Maybe reasoning is...
8833840	8839440	Is overrated. Yeah, it's overrated. I mean, do we reason? How do you tell? Are we just pattern
8839440	8842960	matching based on what we have and then reverse justifying it to ourselves?
8842960	8846240	Exactly. So like I think what the neural networks are missing
8846880	8853600	and I think GPT form might have is to be able to tell stories to itself about what it did.
8853600	8858160	Well, that's what humans do, right? I mean, you talk about like network explainability, right?
8858160	8862320	And we give... No, no, that's a hard time about this. But humans don't know why we make decisions.
8862320	8866160	We have this thing called intuition. And then we try to like say this feels like the right thing,
8866160	8870400	but why? Right? And you wrestle with that when you're making hard decisions. And
8871360	8877280	is that science? Not really. Let me ask you about a few high level questions, I guess, is
8879840	8885760	you've done a million things in your life and been very successful. A bunch of young folks
8885760	8893200	listen to this, ask for advice from successful people like you. If you were to give advice to
8893520	8901440	somebody, you know, another graduate student or some high school student about pursuing a
8901440	8907840	career in computing or just advice about life in general, is there some words of wisdom you can
8907840	8914320	give them? So I think you come back to change and, you know, profound leaps happen because
8914320	8919440	people are willing to believe that change is possible and that the world does change and
8919440	8924640	are willing to do the hard thing that it takes to make change happen. And whether it be implementing
8924640	8929120	a new programming language or implementing a new system or implementing a new research paper,
8929120	8933360	designing a new thing, moving the world forward in science and philosophy, whatever,
8933360	8937600	it really comes down to somebody who's willing to put in the work, right? And you have...
8939120	8943520	The work is hard for a whole bunch of different reasons. One of which is you...
8944080	8949680	It's work, right? And so you have to have the space in your life in which you can do that work,
8949680	8952960	which is why going to grad school can be a beautiful thing for certain people.
8954640	8958240	But also there's a self-doubt that happens. Like you're two years into a project,
8958240	8963120	is it going anywhere? Right? Well, what do you do? Do you just give up because it's hard?
8963120	8970160	Well, no. I mean, some people like suffering. And so you plow through it. The secret to me is
8970160	8976320	that you have to love what you're doing. And follow that passion because when you get to
8976320	8981520	the hard times, that's when... If you love what you're doing, you're willing to push through.
8983200	8989280	This is really hard because it's hard to know what you will love doing until you start doing
8989280	8993120	a lot of things. And so that's why I think that particularly early in your career,
8993120	8999360	it's good to experiment. Do a little bit of everything. Go take the survey class on the
8999360	9005760	first half of every class in your upper division lessons and just get exposure to things because
9005760	9009200	certain things will resonate with you and you'll find out, wow, I'm really good at this. I'm really
9009200	9013920	smart at this. Well, it's just because it works with the way your brain. And when something jumps
9013920	9019840	out, I mean, that's one of the things that people often ask about is like, well, I think there's
9019840	9027440	a bunch of cool stuff out there. Like, how do I pick the thing? Like, how do you hook in your life?
9027440	9031920	How did you just hook yourself in and stuck with it? Well, I got lucky, right? I mean,
9031920	9038880	I think that many people forget that a huge amount of it or most of it is luck, right? So
9039600	9046960	let's not forget that. So for me, I fell in love with computers early on because they spoke to me,
9046960	9057200	I guess. What language did they speak? Basic. But then it was just kind of following a set of
9057200	9062960	logical progressions, but also deciding that something that was hard was worth doing and a
9062960	9067600	lot of fun, right? And so I think that that is also something that's true for many other
9067600	9072800	domains, which is if you find something that you love doing that's also hard, if you invest
9072800	9077760	yourself in it and add value to the world, then it will mean something generally, right? And again,
9077760	9081920	that can be a research paper, that can be a software system, that can be a new robot,
9081920	9087440	that can be, there's many things that can be, but a lot of it is like real value comes from
9087440	9094560	doing things that are hard. And that doesn't mean you have to suffer. But it's hard. I mean,
9094560	9099600	you don't often hear that message. We talked about it last time a little bit, but it's one of my
9100240	9107280	not enough people talk about this. It's beautiful to hear a successful person.
9107280	9112560	Well, in self-doubt and imposter syndrome, and these are all things that successful people suffer
9112560	9118240	with as well, particularly when they put themselves in a point of being uncomfortable, which I like
9118240	9123120	to do now and then just because it puts you in learning mode. Like if you want to, if you want
9123120	9128400	to grow as a person, put yourself in a room with a bunch of people that know way more about whatever
9128400	9133840	you're talking about than you do and ask dumb questions. And guess what? Smart people love to
9133920	9138480	teach, often, not always, but often. And if you listen, if you're prepared to listen, if you're
9138480	9141840	prepared to grow, if you're prepared to make connections, you can do some really interesting
9141840	9147280	things. And I think a lot of progress is made by people who kind of hop between domains now and
9147280	9155360	then because they bring a perspective into a field that nobody else has, if people have only
9155360	9161040	been working in that field themselves. We mentioned that the universe is kind of like a compiler,
9161840	9166320	you know, the entirety of it, the whole evolution is kind of a kind of a compilation.
9167520	9173680	Maybe us human beings are kind of compilers. Let me ask the old sort of question that I
9173680	9178880	didn't ask you last time, which is, what's the meaning of it all? Is there a meaning? Like if
9178880	9184400	you asked a compiler why, what would a compiler say? What's the meaning of life?
9184400	9188240	What's the meaning of life? You know, I'm prepared for not to mean anything.
9188640	9199520	Here we are, all biological things programmed to survive and propagate our DNA. And maybe the
9199520	9204640	universe is just a computer and you just go until entropy takes over the world or takes
9204640	9210160	over the universe and then you're done. I don't think that's a very productive way to live your
9210160	9217120	life, if so. And so I prefer to bias towards the other way, which is saying the universe has a
9217120	9223360	lot of value. And I take happiness out of other people. And a lot of times part of that's having
9223360	9229040	kids, but also the relationships you build with other people. And so the way I try to live my
9229040	9233360	life is like, what can I do that has value? How can I move the world forward? How can I
9233360	9239360	take what I'm good at and like bring it into the world? And how can I, I'm one of these people
9239360	9244400	that likes to work really hard and be very focused on the things that I do. And so if I'm going to
9244400	9249920	do that, how can it be in a domain that actually will matter? Because a lot of things that we do,
9249920	9253600	we find ourselves in the cycle of like, okay, I'm doing a thing, I'm very familiar with it,
9253600	9258640	I've done it for a long time, I've never done anything else, but I'm not really learning.
9259680	9263680	I'm not really, I'm keeping things going, but there's a, there's a younger generation that
9263680	9268000	can do the same thing, maybe even better than me, right? Maybe if I actually step out of this and
9268000	9273840	jump into something I'm less comfortable with, it's scary. But on the other hand, it gives somebody
9273840	9278320	else a new opportunity. It also then puts you back in learning mode. And that can be really
9278320	9283280	interesting. And one of the things I've learned is that when you go through that, that first you're
9283280	9287760	deep into imposter syndrome. But when you start working your way out, you start to realize, hey,
9287760	9293600	well, there's actually a method to this. And, and now I'm able to add new things because I bring
9293600	9298240	different perspective. And this is one of the, the good things about bringing different kinds of
9298240	9304320	people together. Diversity of thought is really important. And if you can pull together people
9304320	9309600	that are coming at things from different directions, you often get innovation. And I love to see that,
9309600	9313920	that aha moment where you're like, we've like really cracked this, this is something nobody's
9313920	9318240	ever done before. And then if you can do it in the context where it adds value, other people can
9318240	9322560	build on it, it helps move the world, then that's what, that's what really excites me.
9322560	9327440	So that kind of description of the magic of the human experience, do you think we'll ever create
9327440	9337360	that in like an AGI system, you think we'll be able to create, give, give AI systems a sense of
9337360	9342160	meaning, where they operate in this kind of world exactly in the way you've described, which is they
9342160	9347360	interact with each other, they interact with us humans. Sure. Sure. Well, so I mean, I, why, why are
9347360	9359440	you being so a species, right? All right. So, so AGI versus bionets, you know, what are we about
9359440	9364080	machines, right? We're just programmed to run our, we have our objective function that we're
9364080	9369200	optimized for, right? And so we're doing our thing, we think we have purpose, but do we really?
9369200	9375440	Yeah. Right. I'm not prepared to say that those newfangled AGI's have no soul just because we
9375440	9380400	don't understand them, right? And I think that would be when they, when they exist, that would be
9380400	9386320	very premature to look at a new thing through your own lens without fully understanding it.
9388080	9392960	You might be just saying that because AI systems in the future will be listening to this and then,
9392960	9396960	Oh yeah, exactly. You don't want to say anything. Please be nice to me, you know, when Skynet,
9396960	9402560	Skynet kills everybody, please spare me. So why is, why is a look ahead thinking?
9402560	9406320	Yeah, but I mean, I think that people will spend a lot of time worrying about this kind of stuff.
9406320	9409840	And I think that what we should be worrying about is how do we make the world better?
9409840	9417360	And the thing that I'm most scared about with AGI's is not that, that necessarily the Skynet
9417360	9421840	will start shooting everybody with lasers and stuff like that to, to use us for our calories.
9422960	9428960	The thing that I'm worried about is that humanity, I think needs a challenge. And if we get into a
9428960	9434240	mode of not having a personal challenge, not having a personal contribution, whether that be
9434240	9439120	like, you know, your kids and seeing what they grow into and helping, helping guide them, whether it
9439120	9444160	be your community that you're engaged in, you're driving forward, whether it be your work and the
9444160	9447360	things that you're doing and the people you're working with in the product you're building and
9447360	9453600	the contribution there, if people don't have a objective, I'm afraid what that means. And
9454240	9460400	and I think that this would lead to a rise of the worst part of people, right? Instead of
9460400	9467760	people striving together and trying to make the world better, it could degrade into a very
9468560	9473920	unpleasant world. But, but I don't know. I mean, we hopefully have a long ways to go before we
9473920	9478400	discover that. And unfortunately, we have pretty on the ground problems with the pandemic right
9478400	9483680	now. And so I think we should be focused on that as well. Yeah, ultimately, just as you said,
9483680	9489440	you're optimistic. I think it helps for us to be optimistic. That's faking until you make it.
9490240	9493200	Yeah, well, and why not? I mean, what's what's the other side? Right? So I mean,
9495200	9499760	I'm not personally a very religious person. But I've heard people say like, Oh, yeah, of course,
9499760	9505360	I believe in God. Of course, I go to church because if God's real, I want to be on the right
9505360	9508640	side of that. And if it's not real, it doesn't matter. Yeah, it doesn't matter. And so, you know,
9509200	9515520	that's that's a fair way to do it. Yeah, I mean, the same thing with with nuclear deterrence,
9515520	9520640	all, you know, global warming, all these things, all these threats, natural engineer pandemics,
9521280	9530640	all these threats we face, I think it's, it's paralyzing to be terrified of all the possible
9530640	9537440	ways we could destroy ourselves. I think it's much better, or at least productive to be hopeful
9537440	9544800	and to engineer defenses against these things to engineer a future where like, you know,
9544800	9549200	see like a positive future and engineer that future. Yeah, well, and I think that's other
9549200	9554080	another thing to think about as, you know, a human, particularly if you're young and trying
9554080	9559120	to figure out what it is that you want to be when you grow up, like I am. I'm always looking for that.
9559840	9565600	The question then is, how do you want to spend your time? And right now, there seems to be a
9565600	9571760	norm of being a consumption culture, like I'm going to watch the news and, and revel in how
9571760	9576880	horrible everything is right now, I'm going to go find out about the latest atrocity and find out
9576880	9582400	all the details of like the terrible thing that happened and be outraged by it. You can spend
9582400	9587440	a lot of time watching TV and watching the news sitcom or whatever people watch these days, I
9587440	9593760	don't know. But that's a lot of hours, right? And those are hours that if you're turning to
9593760	9600400	being productive, learning, growing, experiencing, you know, when the pandemic's over, going exploring,
9601680	9606640	right, it leads to more growth. And I think it leads to more optimism and happiness because
9606640	9610880	you're, you're, you're building, right, you're building yourself, you're building your capabilities,
9610880	9615760	you're building your viewpoints, you're building your perspective. And I think that a lot of the
9616720	9622800	the consuming of other people's messages leads to kind of a negative viewpoint, which you need to
9622800	9627600	be aware of what's happening, because that's also important. But there's a balance that I think
9627600	9633360	focusing on creation is, is a very valuable thing to do. Yeah. So what you're saying is people should
9633360	9640000	focus on working on the sexiest field of all, which is compiler design. Exactly. Hey, you can
9640000	9644240	go work on machine learning and be crowded out by the thousands of graduates popping out of school
9644240	9648560	that all want to do the same thing, or you could work in the place that people overpay you,
9648560	9653360	because there's not enough smart people working in it. And here at the end of Moore's Law,
9653360	9656880	according to some people, actually the software is the hard part too.
9658400	9664800	I mean, optimization is truly, truly beautiful. And also on the YouTube side or education side,
9666080	9671120	you know, it's, there's a, it'd be nice to have some material that shows the beauty of
9671120	9677440	compilers. Yeah, yeah. That's, that's something. So that's a call for, for people to create that
9677440	9683680	kind of content as well. Chris, you're one of my favorite people to talk to. It's such a huge honor
9683680	9688400	that you would waste your time talking to me. I've always appreciated. Thank you so much for
9688400	9693200	talking to me. The truth of it is you spent a lot of time talking to me just on, you know,
9693200	9696000	walks and other things like that. So it's great to catch up with. Thanks, man.
9696000	9702240	Thanks for listening to this conversation with Chris Latner. And thank you to our sponsors,
9702240	9708240	Blinkist, an app that summarizes key ideas from thousands of books, Neuro, which is a maker of
9708240	9714240	functional gum and mints that supercharged my mind, Masterclass, which are online courses from
9714240	9720560	world experts, and finally, Cash App, which is an app for sending money to friends. Please check
9720560	9726240	out these sponsors in the description to get a discount and to support this podcast. If you
9726240	9730960	enjoyed this thing, subscribe on YouTube, review it with five stars on Apple podcast, follow on
9730960	9737120	Spotify, support on Patreon, connect with me on Twitter, Alex Friedman. And now let me leave you
9737120	9742000	with some words from Chris Latner. So much of language design is about trade offs. And you
9742000	9746880	can't see those trade offs unless you have a community of people that really represent those
9746880	9752160	different points. Thank you for listening and hope to see you next time.
