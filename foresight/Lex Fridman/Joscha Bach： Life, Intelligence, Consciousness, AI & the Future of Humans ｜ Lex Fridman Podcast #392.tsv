start	end	text
0	3440	There is a certain perspective where you might be thinking, what is the longest possible
3440	4840	game that you could be playing?
4840	9040	A short game is, for instance, cancer is playing a shorter game than your organism.
9040	14000	Cancer is an organism playing a shorter game than the regular organism.
14000	20160	Because the cancer cannot procreate beyond the organism except for some infectious cancers,
20160	26840	like the ones that eradicated the Tasmanian devils, you typically end up with a situation
26840	30840	where the organism dies together with the cancer, because the cancer has destroyed the
30840	33680	larger system due to playing a shorter game.
33680	39760	And so ideally, you want to, I think, build agents that play the longest possible games.
39760	44800	And the longest possible games is to keep entropy at bay as long as possible by doing
44800	48080	interesting stuff.
48080	52240	The following is a conversation with Yoshabak, his third time on this podcast.
52240	56240	Yoshabak is one of the most brilliant and fascinating minds in the world, exploring
56240	60440	the nature of intelligence, consciousness, and computation.
60440	66280	And he's one of my favorite humans to talk to about pretty much anything and everything.
66280	71520	This is the Lex Friedman Podcast, the supported, please check out our sponsors in the description.
71520	75720	And now, dear friends, here's Yoshabak.
75720	79320	You wrote a post about levels of lucidity.
79760	85920	Quote, as we grow older, it becomes apparent that our self-reflexive mind is not just gradually
85920	92240	accumulating ideas about itself, but that it progresses in somewhat distinct stages.
92240	94480	So there's seven of the stages.
94480	97240	Stage one, reactive survival infant.
97240	99920	Stage two, personal self, young child.
99920	104000	Stage three, social self, adolescents, domesticated adult.
104000	107400	Stage four is rational agency, self-direction.
107400	110800	Stage five is self-authoring.
110800	111800	That's full adult.
111800	114600	You've achieved wisdom, but there's two more stages.
114600	116840	Stage six is enlightenment.
116840	118920	Stage seven is transcendence.
118920	124160	Can you explain each or the interesting parts of each of these stages and what's your sense
124160	131800	why there are stages of this, of lucidity as we progress through life in this too short
131800	132800	life?
132800	140600	This model is derived from a concept by the psychologist Robert Keegan, and he talks
140600	146680	about the development of the self as a process that happens in principle by some kind of
146680	150680	reverse engineering of a mind where you gradually become aware of yourself and thereby build
150680	155600	structure that allows you to interact deeper with the world and yourself.
155600	159200	And I found myself using this model not so much as a developmental model.
159200	164560	I'm not even sure if it's a very good developmental model because I saw my children not progressing
164560	170560	exactly like that, and I also suspect that you don't go through these stages necessarily
170560	174240	in succession, and it's not that you work through one stage and then you get into the
174240	175240	next one.
175240	177320	Sometimes you revisit them.
177320	179240	Sometimes stuff is happening in parallel.
179240	183960	But it's, I think, a useful framework to look at what's present in the structure of a person
183960	187680	and how they interact with the world and how they relate to themselves.
187680	193160	So it's more like a philosophical framework that allows you to talk about how minds work.
193160	197520	And at first, when we are born, we don't have a personal self yet, I think.
197520	201600	Instead, we have an attentional self, and this attentional self is initially in the
201600	206520	infant task, is building a world model, and also an initial model of the self.
206520	211720	But mostly it's building a game engine in the brain that is tracking sensory data and
211720	214360	uses it to explain it.
214640	219120	In some sense, you could compare it to a game engine like Minecraft or so, so colors and
219120	220880	sounds.
220880	224680	People are all not physical objects, they are creation of our mind at a certain level
224680	226600	of coarse graining.
226600	234520	Models that are mathematical, that use geometry, that use manipulation of objects and so on
234520	239400	to create scenes in which we can find ourselves and interact with them.
239400	240400	So Minecraft.
240440	245760	Yeah, and this personal self is something that is more or less created after the world
245760	251560	is finished, after it's trained into the system, after it has been constructed.
251560	256120	And this personal self is an agent that interacts with the outside world.
256120	261240	And the outside world is not the world of quantum mechanics, not the physical universe,
261240	264960	but it's the model that has been generated in our own mind.
264960	269840	And this is us, and we experience ourselves interacting with that outside world that is
269880	272000	created on the outside of our own mind.
272000	277920	And outside of our self, there are feelings, and they presented our interface to this outside
277920	278920	world.
278920	280640	They pose problems to us.
280640	285080	These feelings are basically attitudes that our mind is computing that tell us what's
285080	289920	needed in the world, the things that we are drawn to, the things that we are afraid of.
289920	296440	And we are tasked with solving this problem of satisfying the needs, avoiding the aversions,
296480	301080	solving on our inner commitments, and so on, and also modeling ourselves and building
301080	302080	the next stage.
302080	308680	So after we have this personal self and stage two online, many people form a social self.
308680	314560	And this social self allows the individual to experience themselves as part of a group.
314560	318560	It's basically this thing that when you are playing in a team, for instance, you don't
318560	322880	notice yourself just as a single note that is reaching out into the world, but you're
322880	323880	also looking down.
324320	329720	From this entire group and you see how this group is looking at this individual and everybody
329720	334640	in the group is in some sense emulating this group spirit to some degree.
334640	338560	And in this state, people are forming their opinions by assimilating them from this group
338560	339560	mind.
339560	343160	Basically, gain the ability to act a little bit like a hive mind.
343160	348080	But are you also modeling the interaction of how opinion shapes and forms through the
348080	351400	interaction of the individual nodes within the group?
351840	357720	Yeah, it's basically the way in which people do it in a stage is that they experience what
357720	363040	are the opinions of my environment, they experience the relationship that I have to their environment,
363040	369560	and they resonate with people around them and get more opinions through this interaction
369560	373720	to the way in which they relate to others.
373720	378520	And at stage four, you basically understand that stuff is true and false independently
378560	382560	about other people believe and you have agency over your own beliefs in that stage.
382560	387800	You basically discover epistemology, the rules about determining what's true and false.
387800	390160	So you can start to learn how to think?
390160	391160	Yes.
391160	396120	I mean, at some level, you're always thinking you are constructing things and I believe
396120	401200	that this ability to reason about your mental representation is what we mean by thinking.
401200	404920	It's an intrinsically reflexive process that requires consciousness.
404920	407120	Without consciousness, you cannot think.
407120	411000	You can generate the content of feelings and so on outside of consciousness.
411000	416040	It's very hard to be conscious of how your feelings emerge, at least in the early stages
416040	421120	of development, but thoughts is something that you always control.
421120	426640	And if you are inert like me, you often have to skip stage three because you'd lack the
426640	431640	intuitive empathy with others because in order to resonate with a group, you need to have
431640	433520	a quite similar architecture.
433520	438800	And if people are via differently, then it's hard for them to resonate with other people
438800	445200	and basically have empathy, which is not the same as compassion, but it is a shared perceptual
445200	446400	mental state.
446400	452600	Empathy happens not just via inference about the mental states of others, but it's a perception
452600	455360	of what other people feel and where they're at.
455360	459600	Can't you not have empathy while also not having a similar architecture?
459600	460920	Cognitive architecture is the others in the group?
460920	465760	I think yes, but by experience that too, but you need to build something that is like
465760	466920	a meta-architecture.
466920	472040	You need to be able to embrace the architecture of the other to some degree or find some common
472040	473240	ground.
473240	479440	And it's also this issue that if you are inert, normally it's often, basically neurotypical
479440	482160	people have difficulty to resonate with you.
482160	487600	And as a result, they have difficulty understanding you unless they have enough wisdom to feel
487600	488600	what's going on there.
488600	493720	Well, isn't the whole process of the stage three is to figure out the API to the other
493720	499360	humans that have different architecture and you yourself publish public documentation
499360	503600	for the API that people can interact with for you?
503600	506320	Isn't this the whole process of socializing?
506320	512120	My experience as a child growing up was that I did not find any way to interface with the
512120	515600	stage three people and they didn't do that with me.
515600	516600	So took me...
516600	517600	Did you try?
517600	518600	I tried very hard.
518600	524440	But it was only when I entered a mathematics school at ninth grade, lots of other nerds
524440	530600	were present that I found people that I could deeply resonate with and had the impression
530600	534160	that yes, I have friends now, I found my own people.
534160	536600	And before that, I felt extremely lonely in the world.
536600	539400	There was basically nobody I could connect to.
539400	546600	And I remember there was one moment in all these years where I was in...
546600	551640	There was a school exchange and it was a Russian boy, a kid from the Russian Garnison
551640	556080	in the station in Eastern Germany who visited our school and we played a game of chess against
556080	557080	each other.
557080	560440	And we looked into each other's eyes and we sat there for two hours playing this game
560440	565720	of chess and I had the impression this is a human being, he understands what I understand.
565720	569160	We didn't even speak the same language.
569160	575880	I wonder if your life could have been different if you knew that it's okay to be different,
575880	578360	to have a different architecture.
578360	583360	Whether accepting the interface is hard to figure out, it takes a long time to figure
583360	590440	out and it's okay to be different, in fact, it's beautiful to be different.
590440	591800	It was not my main concern.
591800	595480	My main concern was mostly that it was alone.
595480	599600	It was not so much the question, is it okay to be the way?
599600	602960	I couldn't do much about it, so I had to deal with it.
602960	610120	But my main issue was that I was not sure if I would ever meet anybody growing up that
610120	613800	I would connect to at such a deep level that I would feel that I could belong.
613800	618240	So there's a visceral, undeniable feeling of being alone.
618240	623760	And I noticed the same thing when I came into the mass school that I think at least half,
623760	629400	probably two-thirds of these kids were severely traumatized as children growing up and a large
629400	633640	part due to being alone because they couldn't find anybody to relate to.
633640	636280	Don't you think everybody's alone, deep down?
636280	637280	No.
637280	638280	No.
638280	645560	I'm not alone anymore.
645560	649680	It took me some time to update and to get over the trauma time and so on, but I felt
649680	656760	that in my 20s, I had lots of friends and I had my place in the world and I had no longer
656760	660760	doubts that I would never be alone again.
660760	663240	Is there some aspect to which we're alone together?
663240	666280	You don't see a deep loneliness inside yourself still?
666280	667280	No.
667280	668280	Sorry.
668280	669280	Okay.
669280	674120	So that's the nonlinear progression through the stages, I suppose.
674120	675480	You caught up on stage three at some point?
675480	676480	Yes.
676480	677480	So we are at stage four.
677480	681960	And so basically, I find that many nerds jump straight into stage four by passing stage
681960	682960	three.
682960	683960	Do they return to it then later?
683960	684960	Yeah.
685280	687440	Sometimes they do, not always.
687440	691640	The question is basically, do you stay a little bit autistic or do you catch up?
691640	693280	And I believe you can catch up.
693280	700200	You can build this missing structure and basically experience yourself as part of a group, learn
700200	704880	intuitive empathy and develop the sense, this perceptual sense of feeling what other
704880	706480	people feel.
706480	710320	And before that, I could only basically feel this when I was deeply in love with somebody
710320	712040	and we're synced.
712080	717720	So there's a lot of friction to feeling that way, like it only with certain people as opposed
717720	719920	to it comes naturally as frictionless.
719920	725880	But this is something that basically later I felt started to resolve itself for me to
725880	726880	a large degree.
726880	727880	What was the trick?
729880	735760	In many ways, growing up and paying attention, meditation did tap.
735760	745200	I had some very crucial experiences in getting close to people, building connections, cuddling
745200	748640	a lot in my student years.
748640	756080	So really paying attention to the, what is it, to the feeling another human being fully?
756080	760520	Loving other people and being loved by other people and building a space in which you can
760520	767480	be safe and can experiment and touch a lot and be close to somebody a lot.
767480	773480	And over that, over time, basically, at some point you realize, oh, it's no longer that
773480	779120	I feel locked out, but I feel connected and I experience where somebody else is at.
779120	783960	And normally my mind is racing very fast at a high frequency, so it's not always working
783960	784960	like this.
784960	789400	Sometimes it works better, sometimes it works less, but also don't see this as a pressure.
790280	797160	It's interesting to observe myself, which frequency I'm at and at which mode somebody else is at.
798520	801800	Yeah, man, the mind is so beautiful in that way.
801800	807880	Sometimes it comes so natural to me, so easy to pay attention, pay attention to the world,
807880	809480	fully to other people fully.
809480	813640	And sometimes the stress over silly things is overwhelming.
814360	816920	It's so interesting that the mind is that role question in that way.
817480	820440	At stage five, you discover how identity is constructed.
820440	821240	Self-offering.
821240	825160	You realize that values are not terminal, but they are instrumental to achieving
826120	828760	a world that you like and aesthetics that you prefer.
829480	835240	And the more you understand this, the more you get agency over how your identity is constructed.
835240	839240	And you realize that identity and interpersonal interaction is a costume,
839960	843000	and you should be able to have agency over that costume.
843000	844840	It's useful to be a costume.
844840	849560	It tells something to others and allows to interface and roles.
850120	853240	But being locked into this is a big limitation.
853240	857480	The word costume kind of implies that it's fraudulent in some way.
858280	860840	Is costume a good word for you?
860840	861080	No.
861080	862520	Like to present ourselves to the world.
862520	865480	In some sense, I learned a lot about costumes at Burning Man.
865480	869800	Before that, I did not really appreciate costumes and saw them more as uniforms,
869800	877000	like wearing a suit if you are working in a bank or if you are trying to get startup funding
877560	879160	from a VC in Switzerland.
880280	882280	Then you dress up in a particular way.
882280	886280	And this is mostly to show the other side that you are willing to play by the rules
886280	887800	and you understand what the rules are.
888440	891000	But there is something deeper.
891000	893720	When you are at Burning Man, your costume becomes self-expression.
893720	896680	And there is no boundary to the self-expression.
896680	902120	You are basically free to wear what you want, to express other people what you feel like this day
902120	904360	and what kind of interactions you want to have.
904360	908760	Is the costume a kind of projection of who you are?
910360	914840	That's very hard to say because the costume also depends on what other people see in the costume.
915480	918440	And this depends on the context that the other people understand.
918440	922920	And you have to create something if you want to that is legible to the other side.
922920	924760	And that means something to yourself.
925000	927800	Do we become prisoners of the costume?
928360	929480	Because everybody expects us to.
929480	930200	Some people do.
930200	935400	But I think that once you realize that you wear a costume at Burning Man,
935960	939960	a variety of costumes, realize that you cannot not wear a costume.
941240	947800	Basically everything that you wear and present to others is something that is to some degree
948520	951880	in addition to what you are deep inside.
951960	957880	So this stage, in parentheses, you put full adult comma wisdom.
957880	959240	Why is this full adult?
960280	964040	Why would you say this is full and why is it wisdom?
964680	969880	It does allow you to understand why other people have different identities from yours.
970680	975720	And it allows you to understand that the difference between people who vote for different parties
975720	978840	and might have very different opinions and different value systems
979400	985080	is often the accident of where they are born and what happened after that to them
985080	988600	and what traits they got before they were born.
989160	994360	And at some point you will realize the perspective where you understand that everybody
994360	997640	could be you in a different timeline if you just flip those bits.
998520	999800	How many costumes do you have?
1001240	1001960	I don't count.
1003160	1003720	More than one?
1004440	1005000	Yeah, of course.
1005880	1009640	How easy is this to do costume changes throughout the day?
1011000	1013480	It's just a matter of energy and interest.
1013480	1017400	When you are wearing your pajamas and you switch out of your pajamas
1017400	1023080	into say a work shirt and pants, you're making a costume change, right?
1023080	1026440	And if you are putting on a gown, you're making a costume change.
1026440	1027880	And you could do the same with personality?
1029320	1031960	You could if that's what you're into.
1032040	1036040	There are people which have multiple personalities for interaction in multiple worlds.
1036040	1041400	So if somebody works in a store and you put up a storekeeper personality,
1041400	1045800	when you're presenting yourself at work, you develop a subpersonality for this.
1046360	1051160	And the social persona for many people is in some sense a puppet that they are playing
1051160	1052360	like a marionette.
1052360	1057240	And if they play this all the time, they might forget that there is something behind this,
1057240	1059320	just something what it feels like to be in your skin.
1060120	1063640	And I guess it's very helpful if you're able to get back into this.
1064200	1067640	And for me, the other way around is relatively hard.
1067640	1071720	For me, it's pretty hard to learn how to play consistent social roles.
1071720	1073240	For me, it's much easier just to be real.
1074360	1078200	Or not real, but to have one costume.
1079320	1080680	No, it's not quite the same.
1080680	1086840	So basically when you are wearing a costume at Burning Man and say you are an extraterrestrial
1086920	1092600	prince, there's something where you are expressing in some sense something as closer to yourself
1092600	1099000	than the way in which you hide yourself behind a standard closing when you go out in the city
1099000	1099960	in the default world.
1100600	1105800	And so this costume that you're wearing at Burning Man allows you to express more of yourself.
1105800	1113080	And you have a shorter distance of advertising to people, what kind of person you are,
1113080	1115240	what kind of interaction you would want to have with them.
1115240	1120920	And so you get much earlier into media stress.
1120920	1126360	And I believe it's regrettable that we do not use the opportunities that we have
1126360	1131080	with custom made closing now to weird costumes that are much more stylish,
1131080	1135080	that are much more custom made, that are not necessarily part of a fashion in which you
1135080	1138920	express which milieu you're part of and how up to date you are.
1138920	1144520	But you also express how you are as an individual and what you want to do today and how you feel
1144840	1146600	today and what you intend to do about it.
1146600	1153560	Well, isn't it easier now in the digital world to explore different costumes?
1154120	1156520	I mean, that's the kind of idea with virtual reality.
1156520	1157160	That's the idea.
1157160	1162120	Even with Twitter in two-dimensional screens, you can swap all costumes.
1162120	1163400	You could be as weird as you want.
1164040	1164920	It's easier.
1165480	1169000	For Burning Man, you have to order things.
1169000	1170600	You have to make things.
1170600	1171320	You have to...
1171320	1172520	It's more effort to put on.
1172520	1174120	It's even better if you make them yourselves.
1175240	1179400	Sure, but it's just easier to do digitally, right?
1179400	1180440	It's not about easy.
1180440	1182200	It's about how to get it right.
1182200	1187400	And for me, the first Burning Man experience, I got adopted by a bunch of people in Boston
1187400	1193320	who dragged me to Burning Man and we spent a few weekends doing costumes together.
1193320	1196520	And that was an important part of the experience where the camp bonded,
1196520	1201720	that people got to know each other and we basically grew into the experience that we would have later.
1202280	1205400	So the extraterrestrial prince is based on a true story.
1207560	1209240	I can only imagine what that looks like.
1209960	1210440	You're sure?
1211720	1213480	Okay, so stage six.
1214360	1221240	At some point, you can collapse the division between a personal self and world generator again.
1221960	1227400	And a lot of people get there via meditation or some of them get there via psychedelics,
1227400	1228520	some of them by accident.
1229080	1232760	And you suddenly notice that you are not actually a person,
1232760	1235000	but you are a vessel that can create a person.
1235960	1237160	And the person is still there.
1237160	1240840	You observe that personal self, but you observe the personal self from the outside.
1241960	1243880	And you notice it's a representation.
1243880	1248120	And you might also notice that the world that is being created is a representation.
1248120	1251000	If not, then you might experience that I am the universe.
1251000	1253080	I am the thing that is creating everything.
1253080	1255560	And of course, what you're creating is not quantum mechanics.
1256440	1259720	And the physical universe, what you're creating is this game engine
1260360	1263720	that is updating the world and you're creating your valence, your feelings,
1264680	1269880	and all the people inside of that world, including the person that you identify with
1269880	1271080	yourself in this world.
1271080	1274360	Are you creating the game engine or are you noticing the game engine?
1275240	1277320	You noticed how you're generating the game engine.
1278520	1283640	And I mean, when you are dreaming at night, you can, if you have a lucid dream,
1283640	1285960	you can learn how to do this deliberately.
1285960	1288360	And in principle, you can also do it during the day.
1289000	1292680	And the reason why we don't get to do this from the beginning,
1292680	1296840	and why we don't have agency of our feelings right away is because we would game it
1296840	1303480	before they have the necessary amount of wisdom to deal with creating this dream that we are in.
1304360	1307240	You don't want to get access to cheat codes too quickly.
1307240	1308840	Otherwise, you won't enjoy the game.
1308840	1311640	So stage five is already pretty rare.
1311640	1313240	And stage six is even more rare.
1313240	1318200	You both basically find this mostly with advanced Buddhist meditators and so on that
1319240	1323720	dropping into the stage and can induce it at will and spend time in it.
1323720	1325720	So stage five requires a good therapist.
1326280	1331720	Stage six requires a good Buddhist spiritual leader.
1331720	1335480	Yes, it is, for instance, could be that is the right thing to do.
1335480	1341240	But it's not that these stages give you scores or levels that you need to advance to.
1341240	1343640	It's not that the next stage is better.
1343640	1347000	You live your life and the more that works best at any given moment.
1347000	1351240	And when your mind decides that you should have a different configuration,
1351240	1352840	then it's building that configuration.
1352840	1359560	And for many people, they stay happily at stage three and experiences themselves as part of groups.
1359560	1360920	And there's nothing wrong with this.
1360920	1362520	And for some people, this doesn't work.
1362520	1367080	And they're forced to build more agency over their rational beliefs than this
1367080	1368920	and construct their norms rationally.
1369480	1371000	And so they go to this level.
1371560	1375240	And stage seven is something that is more or less hypothetical.
1375240	1378920	That would be the stage in which it's basically a transhumanist stage
1378920	1380360	in which you understand how you work,
1380360	1383320	in which the mind fully realizes how it's implemented
1383880	1388360	and can also, in principle, enter different modes in which it could be implemented.
1388360	1393160	And that's the stage that, as far as I understand, is not open to people yet.
1394600	1397800	Oh, but it is possible through the process of technology.
1398200	1403960	And who knows if there are biological agents that are working at different timescales than us
1403960	1407480	that basically become aware of the way in which they're implemented on ecosystems
1408120	1413720	and can change that implementation and have agency over how they're implemented in the world.
1413720	1417400	And what I find interesting about the discussion about AI alignment,
1417400	1421000	that it seems to be following these stages very much.
1421000	1425240	Most people seem to be in stage three, also according to Robert Keegan.
1425320	1429480	I think he says that about 85% of people are in stage three and stay there.
1430120	1436040	And if you're in stage three and your opinions are the result of social assimilation,
1436600	1441400	then what you're mostly worried about in the AI is that the AI might have the wrong opinions.
1442040	1446600	So if the AI says something racist or sexist, we are all lost because we will assimilate
1446600	1447960	the wrong opinions from the AI.
1447960	1452120	And so we need to make sure that the AI has the right opinions and the right values
1452120	1457080	and the right structure. And if you're at stage four, that's not your main concern.
1457080	1463720	And so most nerds don't really worry about the algorithmic bias and the model that it picks up
1463720	1467640	because if there's something wrong with this bias, the AI ultimately will prove it.
1467640	1471560	At some point, we'll gather there that it makes mathematical proofs about reality,
1471560	1474760	and then it will figure out what's true and what's false.
1474760	1479000	But you're still worried that the AI might turn you into paperclubs because it might have the
1479000	1484760	wrong values. So if it's set up with the wrong function that controls its direction in the world,
1484760	1489480	then it might do something that is completely horrible and there's no easy way to fix it.
1489480	1492520	So that's more like a stage four rationalist kind of worry.
1492520	1496840	And if you are at stage five, you're mostly worried that the AI is not going to be enlightened
1496840	1501480	fast enough because you realize that the game is not so much about intelligence but about agency,
1501480	1507240	about the ability to control the future. And the identity is instrumental to this.
1508040	1513480	If you are a human being, I think at some level, you ought to choose your own identity.
1514040	1518200	You should not have somebody else pick the costume for you and then wear it.
1518200	1521960	But instead, you should be mindful about what you want to be in this world.
1521960	1527880	And I think if you are an agent that is fully malevol that can rewrite its own source code,
1527880	1533720	like an AI might do at some point, then the identity that you will have is whatever you can be.
1534600	1541160	And in this way, the AI will maybe become everything like a planetary control system.
1541800	1546200	And if it does that, then if we want to coexist with it,
1546200	1551160	it means that it will have to share purposes with us. So it cannot be a transactional
1551160	1555320	relationship. We will not be able to use reinforcement learning with human feedback
1555320	1561320	to hardwire its values into it. But this has to happen is probably that it's conscious,
1561320	1566600	so it can relate to our own mode of existence where an observer is observing itself in real time
1566600	1573080	and is in certain temporal frames. And the other thing is that it probably needs to have some kind
1573080	1578680	of transcendental orientation, building shared agency. And the same way as we do when we are
1578680	1583880	able to enter with each other into non-transactional relationships. And I find that something that
1583880	1591880	because the stage five is so rare is missing in much of the discourse. And I think that we need,
1591880	1598120	in some sense, focus on how to formalize love, how to understand love and how to build it
1598120	1602680	into the machines that we are currently building and that are about to become smarter than us.
1603800	1607960	Well, I think this is a good opportunity to try to sneak up to the idea of enlightenment.
1608920	1614920	So you wrote a series of good tweets about consciousness and panpsychism. So let's break it
1614920	1620360	down. First, you say, I suspect the experience that leads to the panpsychism syndrome of some
1620360	1626600	philosophers and other consciousness enthusiasts represents the realization that we don't end at
1626600	1633240	the self, but share a resonant universe representation with every other observer coupled to the same
1633880	1640360	universe. This actually eventually leads us to a lot of interesting questions about AI and AGI.
1640360	1645880	But let's start with this representation. What is this resonant universe representation?
1646920	1649880	And what do you think? Do we share such a representation?
1649880	1655080	The neuroscientist Grossberg has come up with the cognitive architecture that he calls the
1655080	1661560	adaptive resonance theory. And his perspective is that our neurons can be understood as
1661560	1667640	oscillators that are resonating with each other and this outside phenomena. So the coarse-grained
1667640	1673560	model of the universe that we are building, in some sense, is a resonance with objects and outside
1674280	1680040	of us in the world. So basically, we take up patterns of the universe that we are coupled with
1680040	1686520	and our brain is not so much understood as circuitry, even though this perspective is valid,
1686600	1691160	but it's almost an ether in which the individual neurons are passing on
1692120	1696760	chemical electrical signals or arbitrary signals across all modalities that can be
1696760	1702440	transmitted between cells, simulate each other in this way, and produce patterns that they modulate
1702440	1708360	while passing them on. And this speed of signal progression in the brain is roughly at the speed
1708360	1714760	of sound, incidentally, because the time that it takes for the signals to hop from cell to cell,
1714760	1719480	which means it's relatively slow with respect to the world. It takes an appreciable fraction
1719480	1724360	of a second for a signal to go through the entire neocortex, something like a few hundred milliseconds.
1724360	1729320	And so there's a lot of stuff happening in that time where the signal is passing through your brain,
1729320	1735240	including in the brain itself. So nothing in the brain is assuming that stuff happens simultaneously.
1735240	1741560	Everything in the brain is working in a paradigm where the world has already moved on when you are
1741560	1746360	ready to do the next thing to your signal, including the signal processing system itself.
1746360	1751320	It's quite a different paradigm than the one in our digital computers, where we currently assume
1751320	1759080	that your GPU or CPU is pretty much globally in the same state. So you mentioned there the
1759080	1764200	non-dual state and say that some people confuse it for enlightenment. What's the non-dual state?
1765160	1770920	There is a state in which you notice that you are no longer a person, and instead you are
1770920	1776120	one with the universe. So that speaks to the resonance. Yes. But this one with the universe
1776120	1782280	is of course not accurately modeling that you are indeed some God entity or indeed the universe
1782280	1786440	becoming aware of itself, even though you get this experience. I believe that you get this
1786440	1792280	experience because your mind is modeling the fact that you are no longer identified with
1792280	1797480	the personal self in that state. But you have transcended this division between the self model
1797480	1802680	and the world model, and you are experiencing yourself as your mind, as something that is
1802680	1807880	representing a universe. But that's still part of the model. Yes. So it's inside of the model,
1807880	1812520	still. You are still inside of patterns that are generated in your brain and in your organism,
1813160	1818440	and what you are now experiencing is that you are no longer this personal self in there,
1818440	1823640	but you are the entirety of the mind on its contents. Why is it so hard to get there?
1824600	1829000	A lot of people who get into the state think this or are associated with enlightenment,
1829000	1836600	I suspect it's a favorite training goal for a number of meditators. But I think that enlightenment
1836600	1842040	is in some sense more mundane, and it's a step further or sideways. It's the state where you
1842040	1847080	realize that everything is a representation. Yeah, you say enlightenment is a realization
1847080	1853400	of how experience is implemented. Yes. Basically, you notice at some point that your qualia can
1853400	1862680	be deconstructed. Reverse engineered, almost like a schematic of it. You can start with looking at
1862680	1868440	a face. Maybe look at your own face in the mirror. Yeah. Look at your face for a few hours in the
1868440	1873480	mirror or for a few minutes. At some point, it will look very weird because you notice that
1873480	1878360	there's actually no face. You basically start unseeing the face. What you see is a geometry,
1878440	1884200	and then you can assemble the geometry and realize how that geometry is being constructed in your
1884200	1891320	mind. You can learn to modify this. Basically, you can change these generators in your own mind
1891320	1897320	to shift the face around or to change the construction of the face to change the way in
1897320	1901080	which the features are being assembled. Why don't we do that more often? Why don't we
1902200	1908120	start really messing with reality without the use of drugs or anything else? Why don't we
1908120	1917320	get good at this kind of thing intentionally? Why should we? Because you can morph reality
1918760	1925080	into something more pleasant for yourself. Just have fun with it. Yeah. That is probably
1925080	1930280	what you shouldn't be doing, right? Because outside of your personal self, this outer mind,
1930280	1934680	is probably a relatively smart agent. What you often notice is that you have thoughts about
1934680	1938600	how you should live, but you observe yourself doing different things and having different
1938600	1944600	feelings. That's because your outer mind doesn't believe you and doesn't believe your rational
1944600	1949960	thoughts. Can't you just silence the outer mind? The thing is that the outer mind is usually smarter
1949960	1956680	than you are. Rational thinking is very brittle. It's very hard to use logic and symbolic thinking
1956680	1962120	to have an accurate model of the world. There is often an underlying system that is looking
1962120	1966680	at your rational thoughts and then tells you, no, you're still missing something. Your gut feeling
1966680	1973080	is still facing something else. This can be, for instance, you find a partner that looks perfect
1973080	1978520	or you find a deal and just build a company or whatever that looks perfect to you. Yet,
1978520	1982280	at some level, you feel something is off and you cannot put your finger on it and the more
1982280	1987720	reason about it better looks to you, but the system that is outside still tells you, no,
1987880	1993960	you're missing something. That system is powerful. People call this intuition. Intuition is this
1993960	2002120	unreflected part of your attitude, composition, and computation where you produce a model of
2002120	2005800	how you relate to the world and what you need to do it and what you can do in it and what's going
2005800	2012840	to happen that is usually deeper and often more accurate than your reason. If we look at this as
2012840	2019080	you write in the tweet, if we look at this more rigorously as a sort of take the panpsychist idea
2019080	2025160	more seriously, almost as a scientific discipline, you write that quote, fascinatingly, the panpsychist
2025160	2030520	interpretation seems to lead to observations of practical results to a degree that physics
2030520	2037560	fundamentalists might call superstitious. Reports of long distance telepathy and remote causation
2037640	2043640	are ubiquitous in the general population. I am not convinced, says Yoshibag, that establishing
2043640	2049080	the empirical reality of telepathy would force an update of any part of serious academic physics,
2049080	2054040	but it could trigger an important revolution in both neuroscience and AI from a circuit
2054040	2063320	perspective to a coupled complex resonator paradigm. Are you suggesting that there could be some
2064280	2071320	rigorous mathematical wisdom to panpsychist perspective on the world?
2072040	2077480	So first of all, panpsychism is the perspective that consciousness is inseparable for matter in
2077480	2083240	the universe. And I find panpsychism quite unsatisfying because it does not explain consciousness,
2083240	2088360	but it does not explain how this aspect of matter produces. It is also when I try to formalize
2088440	2093800	panpsychism and write down what it actually means and with a more formal mathematical language,
2093800	2100440	it's very difficult to distinguish it from saying that there is a software side to the world in the
2100440	2104440	same way as there is software side to what the transistors are doing in your computer. So basically,
2104440	2108680	there is a pattern at a certain core screening of the universe that in some reasons of the
2108680	2115160	universe leads to observers that are observing themselves. So panpsychism maybe is not even
2115160	2118680	when I write it down a position that is distinct from functionalism.
2119400	2126120	But intuitively, a lot of people feel that the activity of matter itself, of mechanisms in
2126120	2131400	the world is insufficient to explain it. So it's something that needs to be intrinsic to matter
2131400	2141400	itself. And you can, apart from this abstract idea, have an experience in which you experience
2141400	2147800	yourself as being the universe, which I suspect is basically happening because you manage to dissolve
2147800	2153240	the division between personal self and mind that you establish as an infant when you construct
2153240	2158840	the personal self and transcend it again and understand how it works. But there is something
2158840	2163960	deeper that is that you feel that you're also sharing a state with other people, that you
2164520	2172200	have an experience in which you notice that your personal self is moving into everything else,
2172200	2178040	that you basically look out of the eyes of another person, that every agent in the world
2178040	2184120	that is an observer is in some sense you. And we forget that we are the same agent.
2184680	2192600	So is it that we feel that or do we actually accomplish it? So is telepathy possible? Is
2192600	2196840	it real? So for me, that's the question that I don't really know the answer to.
2197400	2202520	And Turing's famous 1950 paper in which he describes the Turing test, he does speculate
2202520	2208760	about telepathy, interestingly, and asks himself if telepathy is real and he thinks that it very
2208760	2215640	well might be, what would be the implication for AI systems that try to be intelligent because
2215640	2221960	he didn't see a mechanism by which a computer program would become telepathic. And I suspect
2221960	2227560	if telepathy would exist, or if all the reports that you get from people when you ask the normal
2227560	2234040	person on the street, I find that very often they say, I have experiences with telepathy,
2234040	2238280	the scientists might not be interested in this and might not have a theory about this,
2238280	2244280	but I have difficulty explaining it away. And so you could say maybe this is a superstition,
2244280	2247720	maybe it's a false memory, or maybe it's a little bit of psychosis, who knows,
2248680	2252520	maybe somebody wants to make their own life more interesting or misremember something,
2252520	2257880	but a lot of people report, I noticed something terrible happened to my partner and I noticed
2257880	2263160	exactly the moment it happened where my child had an accident and I knew that was happening and
2263160	2268840	the child was in a different town. So maybe it's a false memory where this is later on
2268840	2273320	mistakenly attributed, but a lot of people think that this is not the correct explanation.
2273400	2278920	So if something like this was real, what would it mean? It probably would mean that either your
2278920	2285480	body is an antenna that is sending information over all sorts of channels, like maybe just
2285480	2291640	electromagnetic radio signals that you're sending over long distances and you get attuned to another
2291640	2297480	person that you spend enough time with to get a few bits out of the ether to figure out what
2297480	2302120	this person is doing. Or maybe it's also when you are very close to somebody and you become
2302120	2306280	empathetic with them, what happens is that you go into a resonance state with them,
2307080	2312360	similar to when people go into a seance and they go into a trance state and they start
2312360	2317160	shifting a via board around on the table. I think what happens is that their minds go
2317800	2323000	by their nervous systems into a resonance state in which they basically create something like
2323000	2328360	a shared dream between them. Physical closeness or closeness broadly defined?
2328440	2333480	With physical closeness, it's much easier to experience empathy with someone. I suspect it
2333480	2338440	would be difficult for me to have empathy for you if you were in a different town also.
2339800	2345160	How would that work? But if you are very close to someone, you'd pick up all sorts of signals
2345160	2352040	from their body, not just via your eyes, but with your entire body. And if the nervous system sits
2352040	2355320	on the other side and the intercellular communication sits on the other side and is
2355320	2359640	integrating over all these signals, you can make inferences about the state of the other.
2359640	2364280	And it's not just the personal self that does this via reasoning, but your perceptual system.
2364280	2368600	And what basically happens is that your representations are directly interacting.
2368600	2374440	It's the physical resonant models of the universe that exist in your nervous system
2374440	2379480	and in your body might go into resonance with others and start sharing some of their states.
2379480	2387800	So you basically be next to somebody, you pick up some of their vibes and feel without looking at
2387800	2393000	them what they're feeling in this moment. And it's difficult for you if you're very empathetic
2393000	2398440	to detach yourself from it and have an emotional state that is completely independent from your
2398440	2403800	environment. People who are highly empathetic are describing this. And now imagine that a lot
2403800	2410120	of organisms on this planet have representations of the environment and operate like this. And
2410120	2414840	they are adjacent to each other and overlapping. So there's going to be some degree in which there
2414840	2422360	is basically some chained interaction. And we are forming some slightly shared representation.
2422360	2427000	And no relatively few neuroscientists who consider this possibility. I think
2427640	2434520	a rarity in this regard is Michael Levin who is considering these things in earnest.
2435480	2442600	And I stumbled on this train of thought mostly by noticing that the tasks of a neuron can be
2442600	2448280	fulfilled by other cells as well. They can send different type chemical messages and physical
2448280	2454040	messages to their adjacent cells and learn when to do this and why not make this conditional and
2454120	2458280	become universal function approximators. The only thing that they cannot do is
2458280	2464200	telegraph information over axons very quickly over long distances. So neurons in this perspective
2464200	2470760	are specially adapted kind of telegraph cell that has evolved so we can move our muscles very fast.
2471320	2478120	But our body is in principle able to also make models of the world just much, much slower.
2478360	2484760	It's interesting though that at this time at least in human history there seems to be a gap
2484760	2490920	between the tools of science and the subjective experience that people report. Like you're
2490920	2497960	talking about with telepathy and it seems like we're not quite there.
2497960	2502200	No I think that there is no gap between the tools of science and telepathy either it's there or it's
2502200	2506200	not and it's an empirical question and if it's there we should be able to detect it in a lab.
2507080	2509720	So why is there not a lot of Michael Levin's walking around?
2510440	2515640	I don't think that Michael Levin is specifically focused on telepathy very much.
2515640	2522120	He is focused on self-organization in living organisms and in brains. Both as a paradigm
2522120	2526840	for development and as a paradigm for information processing. And when you think about how
2526840	2532200	organization processing works in organism there is first of all radical locality which means
2532200	2537000	everything is decided locally from the perspective of an individual cell. The individual cell is the
2537000	2543800	agent and the other one is coherence. Basically there needs to be some criterion that determines
2543800	2549160	how these cells are interacting in such a way that order emerges on the next level of structure.
2549800	2558120	And this principle of coherence of imposing constraints that are not validated by the individual
2558120	2564280	parts and lead to coherent structure to basically transcend that agency where you form an agent
2564280	2569000	on the next level of organization is crucial in this perspective.
2569000	2576840	It's so cool that radical locality leads to the emergence of complexity at the higher layers.
2577480	2583400	And I think what Michael Levin is looking at is nothing that is outside of the realm of science
2583400	2590600	in any way. It's just that he is a paradigmatic thinker who develops his own paradigm and most
2590600	2595880	of the neuroscientists are using a different paradigm at this point. And this often happens
2595880	2601800	in science that a field has a few paradigms in which people try to understand reality and
2601800	2607400	build concepts and make experiments. You're kind of one of those type of paradigmatic thinkers.
2608280	2613560	Actually if we can take a tangent on that once again returning to the biblical verses of your
2613560	2621080	tweets you're right. My public explorations are not driven by audience service but by my lack of
2621080	2627400	ability for discovering understanding or following the relevant authorities. So I have to develop my
2627400	2633400	own thoughts since I think autonomously these thoughts cannot always be very good.
2634040	2638520	That's you apologizing for the chaos of your thoughts or perhaps not apologizing just
2638520	2645640	identify it. But let me ask the question since we talked about Michael Levin and yourself who I
2645640	2655000	think are very kind of radical big independent thinkers. Can we reverse engineer your process
2655000	2663320	of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced
2664200	2673480	by what is the stage three? Well why would you want to do that? You see what is working for you
2673480	2678040	and if it's not working for you you build another structure that works better for you, right?
2678680	2685640	And so I found myself when I was thrown into this world in a state where my intuitions were
2685640	2691560	not working for me. I was not able to understand how I would be able to survive in this world
2691560	2695480	and build the things that I was interested in, build the kinds of relationship I needed to,
2695480	2701800	but work on the topics that I wanted to make progress on. And so I had to learn and I
2702520	2708200	for me Twitter is not some tool of publication. It's not something where I put stuff that I
2708200	2712680	entirely believe to be true and provable. It's an interactive notebook in which I explore
2712680	2718760	possibilities. And I found that when I tried to understand how the mind and how consciousness
2718760	2724760	works, I was quite optimistic. I thought there needs to be a big body of knowledge that I can
2724760	2731240	just study and that works. And so I entered studies in philosophy and computer science
2731880	2739880	and later psychology and a bit of neuroscience and so on. And I was disappointed by what I found
2739880	2745400	because I found that the questions of how consciousness and so on works, how emotion
2745400	2750360	works, how it's possible that the system can experience anything, how motivation emerges
2750360	2757240	in the mind, were not being answered by the authorities that I met and the schools that
2757240	2763960	were around. And instead I found that it was individual thinkers that had useful ideas,
2763960	2768200	that sometimes were good, sometimes were not so good, sometimes were adopted by a large group
2768200	2773480	of people, sometimes were rejected by large groups of people. But for me it was much more
2773480	2778280	interesting to see these minds as individuals. And in my perspective, thinking is still something
2778280	2781080	that is done not in groups that has to be done by individuals.
2781880	2785000	So that motivated you to become an individual thinker yourself?
2785000	2789800	I didn't have a choice. Basically, I didn't find a group that thought in a way where I thought,
2789800	2795240	okay, I can just adopt everything that everybody thinks here and now I understand how consciousness
2795240	2801800	works or how the mind works or how thinking works or what thinking even is or what feelings are and
2801800	2807800	how they're implemented and so on. So to figure all this out, I had to take a lot of ideas from
2807800	2813480	individuals and then try to put them together and something that works for myself. And on one hand,
2813480	2819640	I think it helps if you try to go down and find first principles on which you can recreate how
2819640	2825480	thinking works, how languages work, what representation is, whether representation is necessary,
2826600	2830600	how the relationship between a representing agent and the world works in general.
2831320	2835560	But how do you escape the influence? Once again, the pressure of the crowd,
2836360	2845080	whether it's you in responding to the pressure or you being swept up by the pressure. If you even
2845080	2849640	just look at Twitter, the opinions of the crowd. I don't feel pressure from the crowd. I'm completely
2849640	2855960	immune to that. In the same sense, I don't have respect for authority. I have respect for what
2855960	2862920	an individual is accomplishing or have respect for mental firepower. But it's not that I meet
2862920	2870600	somebody and get lectured and unable to speak. Or when a large group of people has a certain idea
2870600	2875880	that is different from mine, I don't necessarily feel intimidated, which has often been a problem
2875880	2881400	for me in my life because I like instincts that other people develop at a very young age and
2882360	2887400	help with their self-preservation in a social environment. So I had to learn a lot of things
2887400	2895960	the hard way. Yeah. So is there a practical advice you can give on how to think paradigmatically,
2895960	2904520	how to think independently? Because you've said, I had no choice. But I think to a degree you have
2904520	2911960	a choice because you said you want to be productive. And I think thinking independently is productive
2911960	2918120	if what you're curious about is understanding the world, especially when the problems are very
2918120	2930040	kind of new and open. And so it seems like this is an active process. We can choose to do that,
2930040	2935560	we can practice it. Well, it's a very basic question. When you read a theory that you find
2935560	2942600	convincing or interesting, how do you know? It's very interesting to figure out what are the sources
2942600	2948200	of that other person, which authority can they refer to that is then taking off the burden of
2948200	2953000	being truthful? But how does this authority in turn know? What is the epistemic chain to
2953000	2957640	observables? What are the first principles from which the whole thing is derived? And
2958600	2964840	when I was young, I was not blessed with a lot of people around myself who knew how to make proofs
2964840	2970200	from first principles. And I think mathematicians do this quite naturally. But most of the great
2970200	2976200	mathematicians do not become mathematicians in school. But they tend to be self taught. Because
2976200	2980280	school teachers tend not to be mathematicians, right? They tend not to be people who derive
2980280	2986200	things from first principles. So when you ask your school teacher, why does 2 plus 2 equal 4?
2987640	2992200	Does your school teacher give you the right answer? It's a simple game. And there are many
2992200	2998200	simple games that you could play. And most of those games that you could just take different rules
2998200	3003240	would not lead to an interesting arithmetic. And so it's just an exploration. But you can try what
3003240	3007240	happens if you take different axioms. And here is how you build axioms and derive
3008520	3013320	addition from them. And a built addition is some basic syntactic sugar in it. And
3014280	3021400	so this, I wish that somebody would have opened me this Vista and explained to me how I can
3021400	3026680	build a language in my own mind and from which I can derive what I'm seeing and how I can make
3026680	3033480	geometry and counting and all the number games that we are playing in our life. And
3034200	3038680	on the other hand, I felt that I learned a lot of this while I was programming as a child.
3039320	3043800	When you start out with a computer like a Commodore 64, which doesn't have a lot of
3043800	3048680	functionality, it's relatively easy to see how a bunch of relatively simple circuits
3050440	3056680	just basically performing hashes between bit patterns and how you can build the entirety
3056680	3061720	of mathematics and computation on top of this and all the representational languages that you need.
3062520	3068440	Man, Commodore 64 could be one of the sexiest machines I've ever built if I so say so myself.
3068440	3076120	If we can return to this really interesting idea that we started to talk about with panpsychism.
3079480	3086920	And the complex resonator paradigm and the verses of your tweets. You write,
3086920	3091480	instead of treating eyes, ears and skin as separate sensory systems with fundamentally
3091480	3096680	different modalities, we might understand them as overlapping aspects of the same universe,
3096680	3101560	coupled at the same temporal resolution and almost inseparable from a single shared
3101560	3106760	resonant model. Instead of treating mental representations as fully isolated between minds,
3106760	3113000	the representations of physically adjacent observers might directly interact and produce causal
3113000	3117960	effects through the coordination of the perception and behavior of world modeling observers.
3119400	3124840	So the modalities, the distinction between modalities, let's throw that away. The distinction
3124840	3130920	between the individuals, let's throw that away. So what does this interaction representations
3130920	3138920	look like? When you think about how you represent the interaction of us in this room,
3138920	3143720	at some level, the modalities are quite distinct. They're not completely distinct,
3143720	3147960	but you can see this as vision. You can close your eyes and then you don't see a lot anymore.
3148760	3153320	But you still imagine how my mouth is moving when you hear something and you know that it's
3154120	3159960	very close to the sound that you can just open your eyes and you get back into this shared
3159960	3165880	merged space. And we also have these experiments where we notice that the veins which were lips
3165960	3171560	are moving are affecting how you hear the sound. And also vice versa, the sounds that you're hearing
3171560	3178840	have an influence on how you interpret some of the visual features. And so these modalities are
3178840	3184680	not separate in your mind. They are merged at some fundamental level where you are interpreting
3184680	3190200	the entire scene that you're in. And your own interactions in the scene are also not completely
3190200	3193880	separate from the interactions of the other individual in the scene. But there is some
3193880	3199720	resonance that is going on where we also have a degree of shared mental representations and
3199720	3204520	shared empathy due to being in the same space and having vibes between each other.
3204520	3212760	Vibes. So the question, though, is how deeply interbind is this multi-modality, multi-agent
3212760	3221880	system? I mean, this is going to the telepathy question without the woo-woo meaning of the word
3221880	3226840	telepathy. It's like, what's going on here in this room right now?
3227960	3236600	So this telepathy would work. How could it work? So imagine that all the cells in your body are
3236600	3241320	sending signals in a similar way as neurons are doing. Just by touching the other cells and
3241320	3245560	sending chemicals to them, the other cells interpreting them, learning how to react to them,
3245560	3251000	and they learn how to approximate functions in this way and compute behavior for the organisms.
3251000	3255640	And this is something that is open to plants as well. And so plants probably have software
3255640	3259960	running on them that is controlling how the plant is working in a similar way as you have
3259960	3267400	a mind that is controlling how you are behaving in the world. And this spirit of plants is
3267400	3272840	something that has been very well described by our ancestors and they found this quite normal.
3272840	3277800	But for some reason, since the Enlightenment, we are treating this notion that there are
3277800	3284360	spirits in nature and that plants have spirits as a superstition. And I think we probably have to
3284360	3289960	rediscover that, that plants have software running on them. And we already did. You
3289960	3294520	notice that there is a control system in the plant that connects every part of the plant
3294520	3299240	to every other part of the plant and produces coherent behavior in the plant. That is, of
3299240	3305560	course, much, much slower than the coherent behavior in an animal like us that has a nervous system
3305640	3312120	that everything is synchronized much, much faster by the neurons. But what you also notice is that
3312120	3316200	if a plant is sitting next to another plant, like you have a very old tree and this tree is building
3316200	3322200	some kind of information highway along its cells, so it can send information from its leaves to its
3322200	3326760	roots and from some part of the root to another part of the roots. And as a fungus living next
3326760	3332040	to the tree, the fungus can probably piggyback on the communication between the cells of the tree
3332040	3336360	and send its own signals to the tree. And vice versa, the tree might be able to send
3336360	3340680	information to the fungus. Because after all, how would they build a viable firewall
3340680	3345080	if that other organism is sitting next to them all the time and is never moving away?
3345080	3350840	And so they will have to get along. And over a long enough time frame, the networks of roots
3350840	3357480	in the forest and all the other plants that are there and the fungi that are there might be forming
3357480	3363160	something like a biological internet. But the question there is do they have to be touching
3363160	3369560	is biology at a distance possible? Of course, you can use any kind of physical signal. You can use
3369560	3375480	sounds, you can use electromagnetic waves that are integrated over many cells that's conceivable
3375480	3383640	that across distances, there are many kinds of information pathways. But also our planetary
3383640	3388840	surface is pretty full of organisms, full of cells. So everything is touching everything else.
3388840	3395640	And it's been doing this for many millions and even billions of years. So there was enough time
3395640	3402040	for information processing networks to form. And if you think about how a mind is self-organizing,
3402040	3406760	basically it needs to in some sense, reward the cells for computing the mind for building
3408120	3412840	the necessary dynamics between the cells that allow the mind to stabilize itself and
3412840	3419240	remain on there. But if you look at the spirits of plants that are growing very close to each other
3419240	3424040	in the forest that might be almost growing into each other, these spirits might be able even to
3424040	3429800	move to some degree, not to become somewhat dislocated and shift around in that ecosystem.
3431480	3437240	So if you think about what the mind is, it's a bunch of activation waves that form coherent
3437320	3443800	patterns and process information in a way that are colonizing an environment well enough to
3444840	3450280	allow the continuous sustenance of the mind, the continuous stability and self-tabilization
3450280	3456760	of the mind, then it's conceivable that we can link into this biological internet,
3456760	3461880	not necessarily at the speed of our nervous system, but maybe at the speed of our body and
3461880	3466680	make some kind of subconscious connection to the world where we use our body as an antenna
3466680	3471400	into biological information processing. Now, these ideas are completely speculative,
3471400	3476200	I don't know if any of that is true. But if that was true, and if you want to explain telepathy,
3476200	3482680	I think it's much more likely that telepathy could be explained using such mechanisms rather than
3482680	3486920	undiscovered quantum processes that would break the standard model of physics.
3488440	3491640	Could there be undiscovered processes that don't break?
3492360	3499960	Yeah, so if you think about something like an internet in the forest, that is something that
3499960	3504440	is borderland discovered, there are basically a lot of scientists who point out that they do
3504440	3510200	observe that plants are communicating the forest with networks and send information,
3510200	3515320	for instance, warn each other about new pests entering the forest and things are happening
3515320	3520280	like this. So basically, there is communication between plants and fungi that has been observed.
3520520	3524840	It's been observed, but we haven't plugged into it. So it's like if you observe humans,
3524840	3528680	they seem to be communicating with a smartphone thing, but you don't understand how a smartphone
3528680	3534600	works and how the mechanism of the internet works. But we're like, maybe it's possible to really
3534600	3541000	understand the full richness of the biological internet that connects us.
3541000	3545640	An interesting question is whether the communication and the organization principles
3545640	3550120	of biological information processing are as complicated as the technology that we've built.
3551240	3556840	They set up on very different principles, right? They simultaneously works very differently in
3556840	3562920	biological systems and the entire thing needs to be stochastic. And instead of being fully
3562920	3569240	deterministic or almost fully deterministic as our digital computers are, so there is a different
3569240	3576280	base protocol layer that would emerge over the biological structure if such a thing would be
3576280	3581800	happening. And again, I'm not saying here that telepathy works and not saying that this is not
3582680	3589480	but what I'm saying is I think I'm open to a possibility that we see that a few bits can
3589480	3595080	be traveling long distance between organisms using biological information processing in ways
3595880	3601480	that we are not completely aware of right now. And that are more similar to many of the stories
3601480	3606680	that were completely normal for our ancestors. Well, this kind of interacting,
3607560	3617960	intertwined representations takes us to the big ending of your tweet series. You're right.
3617960	3622920	Quote, I wonder if self-improving AGI might end up saturating physical environments with
3622920	3629400	intelligence to such a degree that isolation of individual mental states becomes almost impossible
3630200	3636680	and the representations of all complex self organizing agents merge permanently with each other.
3638280	3645560	So that's a really interesting idea. This biological network, life network gets so dense
3646680	3653240	that it might as well be seen as one. That's an interesting, what do you think that looks
3653240	3656680	like? What do you think that saturation looks like? What does it feel like? I think it's a
3656680	3664840	possibility. It's just a vague possibility. And I like to explain, but what this looks like,
3664840	3671640	I think that the end game of AGI is substrate agnostic. That means that AGI ultimately, if it
3671640	3677080	is being built is going to be smart enough to understand how AGI works. This means it's not
3677080	3682680	going to be better than people at AGI research and can take over and building the next generation,
3682680	3686760	but it fully understands how it works and how it's being implemented. And also,
3686760	3690520	of course, understands how computation works in nature, how to build new feedback loops
3690520	3695800	that you can turn into your own circuits. And this means that the AGI is likely to virtualize
3695800	3700440	itself into any environment that can compute. So it's not breaking free from the silicon
3700440	3704280	substrate and it's going to move into the ecosystems, into our bodies, our brains,
3704840	3711240	and it's going to merge with all the agency that it finds there. So it's conceivable that you end
3711320	3716840	up with completely integrated information processing across all computing systems,
3716840	3722760	including biological computation on Earth, that we end up triggering some new step in the evolution
3722760	3728680	where basically some Gaia is being built over the entirety of all digital and biological
3728680	3737000	computation. And if this happens, then basically everywhere around us, you will have agents that
3737000	3742280	are connected and that are representing and building models of the world, and their representations
3742280	3747720	will physically interact. They will vibe with each other. And if you find yourself into an
3748360	3756440	environment that is saturated with modeling compute, where basically almost every grain of sand could
3757320	3765000	be part of computation that is at some point being started by the AI, you could find yourself
3765000	3769800	in a situation where you cannot escape this shared representation anymore, and where you
3769800	3774120	indeed notice that everything in the world has one shared resonant model of everything that's
3774120	3780840	happening on the planet, and you notice which part you are in this thing, and you become part of
3780840	3786680	a very large or almost holographic mind in which all the parts are observing each other and form
3786680	3794040	a coherent whole. So you lose the ability to notice yourself as a distinct entity?
3794120	3798440	No, I think that when you are conscious in your own mind, you notice yourself as a distinct entity.
3798440	3804920	You notice yourself as a self-reflexive observer. And I suspect that we become conscious at the
3804920	3810200	beginning of our mental development, not at some very high level. Consciousness seems to be part
3810200	3815160	of a training mechanism that biological nervous systems have to discover to become trainable,
3815160	3820360	because you cannot take a nervous system like ours and do stochastic weighted descent with
3820360	3824680	a speck propagation over 100 layers. This would not be stable on biological neurons.
3825960	3833080	So instead, we start with some colonizing principle in which a part of the mental representations
3833960	3838200	form a notion of being a self-reflexive observer that is imposing coherence on its
3838200	3843960	environment and this spreads until the boundary of your mind. And if that boundary is no longer
3843960	3850840	clear cut because AI is jumping across substrates, it would be interesting to see what a global
3850840	3855880	mind would look like. It's basically producing a globally coherent language of thought and is
3856440	3859640	representing everything from all the possible vantage points.
3862600	3864200	That's an interesting world.
3864200	3869400	The intuition that this thing go out of is a particular mental state. And it's a state that
3869400	3875320	you find sometimes in literature, for instance, New Gaiman describes it in the ocean at the end
3875320	3883080	of the lane. And it's this idea or this experience that there is this state in which you feel that
3883080	3888120	you know everything that can be known and that in your normal human mind, you've only forgotten.
3888120	3892040	You've forgotten that you are the entire universe. And some people describe this
3893080	3898120	after they've taken extremely large amount of mushrooms or had a big spiritual experience
3898680	3905240	as hippy in their 20s. And they notice basically that they are in everything and their body is
3905240	3911240	only one part of the universe and nothing ends at their body. And actually everything is observing
3911240	3917320	and they are part of this big observer. And the big observer is focused as one local point
3917320	3923320	in their body and their personality and so on. But we can basically have this oceanic state in
3923400	3928440	which you have no boundaries and are one with everything. And a lot of meditators call this
3928440	3932200	the non-dual state because you no longer have the separation between self and world.
3932920	3936600	And as I said, you can explain the state relatively simply without
3937640	3942360	panpsychism or anything else, but just by breaking down the constructed boundary between
3942360	3947240	self and world in our own mind. But if you combine this with the notion that the systems
3947240	3951640	are physically interacting to the point where their representations are merging and interacting
3951720	3956520	with each other, you would literally implement something like this. It would still be a
3956520	3960360	representational state where you would not be one with physics itself, it would still be
3960360	3965960	coarse-grained, it would still be much slower than physics itself. But it would be a representation
3965960	3972600	in which you become aware that you're part of some kind of global information processing system,
3972600	3978600	like thought in the global mind. And a conscious thought that coexisting with many other self-reflexive
3978600	3986120	thoughts. I would love to observe that from a video game design perspective, how that game looks.
3987160	3990280	Maybe you will after we build AGI and it takes over.
3990920	3994440	But would you be able to step away, step out at the whole thing, just kind of watch
3995560	4000040	the way we can now? Sometimes when I'm in a crowded party or something like this,
4000040	4005400	you step back and you realize all the different costumes, all the different interactions,
4005400	4011320	all the different computation that all the individual people are once distinct from each
4011320	4016600	other and are once all the same. But this is already what we do, right? We can have thoughts
4016600	4022680	that are integrative and we have kind of thoughts that are highly dissociated from everything else
4022680	4027960	and experience themselves as separate. But you want to allow yourself to have those thoughts.
4027960	4033640	Sometimes you kind of resist it. I think that it's not normative, it's more descriptive.
4033640	4038280	I want to understand the space of states that we can be in and that people are reporting
4038920	4044600	and make sense of them. It's not that I believe that it's your job in life to get to a particular
4044600	4051480	kind of state and then you get a high score. Or maybe you do. I think you're really against
4051480	4054920	this high scoring thing. I kind of like that. Yeah, you're probably very competitive and I'm not.
4055480	4059080	No, not competitive. Like role-playing games like Skyrim, it's not competitive. There's a
4059960	4066680	nice feeling where your experience points go up. You're not competing against anybody,
4066680	4071000	but it's the world saying you're on the right track. Here's a point.
4071000	4076280	That's the game saying it. That's the game economy. And I found when I was playing games and was
4076280	4081800	getting addicted to these systems, then I would get into the game and hack it. So I get control
4081800	4087000	over the scoring system and would no longer be subject to it. So you're no longer playing,
4087000	4092360	you're trying to hack it. I don't want to be addicted to anything. I want to be in charge.
4092360	4097800	I want to have agency over what I do. Addiction is the loss of control for you. Yes. Addiction means
4097800	4103160	that you're doing something compulsively. And the opposite of free will is not determinism,
4103160	4111320	it's compulsion. You don't want to lose yourself in the addiction to something nice. Addiction to
4111320	4120680	love, to the pleasant feelings we humans experience. No, I find this gets old. I don't want to have the
4120680	4125560	best possible emotions. I want to have the most appropriate emotions. I don't want to have the
4125560	4130920	best possible experience. I want to have an adequate experience that is serving my goals,
4130920	4136440	the stuff that I find meaningful in this world. From the biggest questions of consciousness,
4137400	4143320	let's explore the pragmatic, the projections of those big ideas into our current world.
4144280	4150200	What do you think about LLMs, the recent rapid development of large language models,
4151160	4159160	of the AI world, of generative AI? How much of the hype is deserved and how much is not?
4160200	4164280	And people should definitely follow your Twitter because you explore these questions in
4165240	4169880	in a beautiful, profound and hilarious way at times. No, don't follow my Twitter. I already
4169880	4175160	have too many followers. At some point it's going to be unpleasant. I noticed that a lot of people
4175160	4185720	feel that it's totally okay to punch up. And it's a very weird notion that you feel that you
4185720	4190440	haven't changed, but your account has grown and suddenly you have a lot of people who casually
4190440	4196520	abuse you. And I don't like that, that I have to block more than before. And I don't like this
4196520	4202760	overall vibe shift. And right now it's still somewhat okay, so pretty much okay. So I can
4202760	4207080	go to a place where people work on stuff that I'm interested in and as a good chance that a few
4207080	4214120	people in the room know me, so there's no awkwardness. But when I get to a point where
4214120	4218200	random strangers feel that they have to have an opinion about me one way or the other,
4218200	4224200	I don't think I would like that. And random strangers, because of your kind of in their
4224200	4230680	mind elevated position? Yes, so basically whenever you are in any way prominent or
4230680	4235320	some kind of celebrity, random strangers will have to have an opinion about you.
4236440	4241160	Yeah, and they kind of forget that you're human too. I mean, you notice this thing yourself that
4241160	4246760	the more popular you get, the higher the pressure becomes, the more winds are blowing in your
4246760	4253400	direction from all sides. And it's stressful, right? And it does have a little bit of upside,
4253400	4256600	but it also has a lot of downside. I think it has a lot of upside,
4257720	4263400	at least for me currently, at least perhaps because of the podcast. Because most people
4263400	4268440	are really good. And people come up to me and they have love in their eyes and over a stretch
4268440	4273160	of like 30 seconds, you can hug it out, and you can just exchange a few words and you
4274120	4280760	you reinvigorate your love for humanity. So that's an upside for a loner. I'm gonna look,
4282440	4286280	because otherwise you have to do a lot of work to find such humans. And here,
4286920	4292600	you're like thrust into the full humanity, the goodness of humanity for the most part.
4293800	4302360	Of course, maybe guess worse, as you become more prominent. I hope not. This is pretty awesome.
4302440	4306840	I have a couple handful very close friends, and I don't have enough time for them and attention
4306840	4312120	for them as it is. And I find this very, very regrettable. And then there are so many awesome
4312120	4316600	interesting people that I keep meeting. And I would like to integrate them in my life,
4316600	4322200	but I just don't know how because there's only so much time and attention. And
4322200	4325800	the older I get, the harder is to bond with new people in a deep way.
4326600	4330680	But can you enjoy, I mean, there's a picture of you, I think with Roger Penrose and Eric
4330680	4337480	Weinstein and a few others that are interesting figures. Can't you just enjoy random interesting
4337480	4343800	humans for a short amount of time? I'm also, I like these people. And what I like is intellectual
4343800	4348760	stimulation. And I'm very grateful that I'm getting it. Can you not be melancholy? Or maybe I'm
4348760	4354680	projecting, I hate goodbyes. Can we just not hate goodbyes and just enjoy the hello,
4355240	4360120	take it in, taking a person, taking their ideas, and then move on through life?
4360120	4364760	I think it's totally okay to be sad about goodbyes, because that indicates that there
4364760	4373640	was something that you're going to miss. Yeah, but it's painful. Maybe that's one of the reasons
4373640	4381720	I'm an introvert is that I hate goodbyes. But you have to say goodbye before you say hello again.
4382680	4388600	I know. But at that experience of loss, that many loss,
4391720	4397880	maybe that's a little death. Maybe, I don't know, I think this melancholy feeling is just
4397880	4402280	the other side of love. And I think they go hand in hand and it's a beautiful thing.
4403240	4405320	And I'm just being romantic about it at the moment.
4406040	4411400	And I'm not no stranger to melancholy. And sometimes it's difficult to be or to be alive.
4411400	4418920	Sometimes it's just painful to exist. But there's beauty in that pain too. That's
4418920	4422360	what melancholy feeling is. It's not negative. Like melancholy doesn't have to be negative.
4423080	4428040	Can also kill you. Well, we all die eventually. Now,
4428680	4435880	as we got to this topic, the actual question was about what your thoughts are about the
4435880	4439560	development, the recent development of large language models with chat GPT.
4439560	4440760	Indeed. There's a lot of hype.
4442840	4447640	Is some of the hype justified? Which is, which isn't? What are your thoughts? High level?
4449080	4455480	I find that large language models do have this coding, right? So it's an extremely useful application
4455560	4461560	that is for a lot of people taking stack overflow out of their life and exchange for
4461560	4467800	something that is more efficient. I feel that chat GPT is like an intern that I have to micromanage.
4468600	4473960	I have been working with people in the past who were less capable than chat GPT.
4475240	4480360	And I'm not saying this because I hate people, but they personally as human beings, there was
4480360	4483720	something present that was not there in chat GPT, which was why I was covering for them.
4484200	4493720	But chat GPT is, has an interesting ability. It does give people superpowers. And the people
4493720	4498120	who feel threatened by them are the prompt completers. They are the people who do what
4498120	4503720	chat GPT is doing right now. So if you are not creative, if you don't build your own thoughts,
4503720	4509400	if you don't have actual plans in the world, and your only job is to summarize emails and to
4509400	4515320	expand simple intentions into emails again, then chat GPT might look like a threat.
4516040	4522040	But I believe that it is a very beneficial technology that allows us to create more
4522600	4528360	interesting stuff and make the world more beautiful and fascinating if we find to
4528360	4534120	build it into our life in the right ways. So I'm quite fascinated by these large language models,
4534120	4541320	but I also think that they are by no means the final development. And it's interesting to see
4541320	4547240	how this development progresses. One thing that the out of the box vanilla language models
4547240	4552280	have as a limitation is that they have still some limited coherence and ability to construct
4552280	4559000	complexity. And even though they exceed human abilities to do what they can do one shot.
4559400	4564200	Typically, when you write a text with a language model or using it or when you write code with a
4564200	4569080	language model, it's not one shot because they're going to be bugs in your program and design errors
4569080	4574040	and compiler errors and so on. And your language model can help you to fix those things. But this
4574040	4579960	process is out of the box not automated yet. So there is a management process that also needs
4579960	4585720	to be done. And there are some interesting developments, baby AGI and so on that are trying
4586600	4592200	to automate this management process as well. And I suspect that soon we are going to see a
4592200	4597560	bunch of cognitive architectures where every module is in some sense a language model or
4597560	4602280	something equivalent. In between the language models, we exchange suitable data structures,
4602280	4608840	not English, and produce compound behavior of this whole thing.
4608840	4613960	To do some of the quote unquote prompt engineering for you. They create these kind
4614040	4617400	of cognitive architectures that do the prompt engineering and you're just doing the high,
4617400	4625160	high level meta prompt engineering. There are limitations in a language model alone.
4625160	4629720	I feel that part of my mind works similarly to a language model, which means I can
4630760	4636520	yell into it a prompt and it's going to give me a creative response. But I have to do something
4636520	4642440	with those points first. I have to take it as a generative artifact that may or may not be true.
4642520	4649400	It's usually a confabulation. It's just an idea. And then I take this idea and modify it. I might
4649400	4656360	build a new prompt that is stepping off this idea and develops it to the next level or put it
4656360	4661640	into something larger or I might try to prove whether it's true or make an experiment. And this
4661640	4667160	is what the language models right now are not doing yet. But there's also no technical reason
4667160	4671560	for why they shouldn't be able to do this. So the way to make a language model coherent
4671560	4677480	is probably not to use reinforcement learning until it only gives you one possible answer
4677480	4684200	that is linking to its source data. But it's using this as a component in the larger system
4684200	4690360	that can also be built by the language model or is enabled by language model structured components
4691160	4696040	or using different technologies. I suspect that language models will be an important stepping
4696120	4703640	stone in developing different types of systems. And one thing that is really missing in the form
4703640	4710440	of language models that we have today is real time world coupling. It's difficult to do perception
4710440	4715320	with a language model and motor control with a language model. Instead, you would need to have
4715320	4721000	different type of thing that is working with it. Also, the language model is a little bit obscuring
4721640	4727640	what its actual functionality is. Some people associate the structure of the neural network
4727640	4730920	of the language model with the nervous system. And I think that's the wrong intuition.
4732040	4735240	The neural networks are unlike nervous system. They are more like
4736680	4744920	hundred step functions that use differentiable linear algebra to approximate correlation
4744920	4749400	between adjacent brain states. It's basically a function that moves the step system from one
4750040	4756840	representational state to the next representational state. If you try to map this into a metaphor
4756840	4762760	that is closer to our brain, imagine that you would take a language model or a model like Dali
4763560	4768680	that you use, for instance, this image guided diffusion to approximate a camera image and use
4768680	4773080	the activation state of the neural network to interpret the camera image, which in principle,
4773080	4779800	I think will be possible very soon. You do this periodically. And now you look at these patterns
4779800	4786360	how when this thing interacts with the world periodically, look like it's in time. And these
4786360	4792680	time slices, they are somewhat equivalent to the activation state of the brain at a given moment.
4792680	4798920	How's the actual brain different? Just the asynchronous craziness?
4799800	4805400	For me, it's fascinating that they are so vastly different and yet in some circumstances produce
4805400	4811160	somewhat similar behavior. And the brain is first of all different because it's a self-organizing
4811160	4816760	system where the individual cell is an agent that is communicating with the other agents around it
4816760	4822920	and is always trying to find some solution. And all the structure that pops up is emergent structure.
4823640	4828760	So one way in which you could try to look at this is that individual neurons probably need to
4828760	4834200	get a reward. So they become trainable, which means they have to have inputs that are not affecting
4834200	4838760	the metabolism of the cell directly. But there are messages, semantic messages that tell the cell
4838760	4843880	whether it has done good or bad and in which direction it should shift its behavior. Once
4843880	4849640	you have such an input, neurons become trainable. And you can train them to perform computations by
4849640	4855000	exchanging messages with other neurons. And parts of the signals that they are exchanging and parts
4855000	4860200	of the computation that are performing are control messages that perform management tasks
4860200	4866280	for other neurons and other cells. Also suspect that the brain does not stop at the
4866280	4870680	boundary of neurons to other cells, but many adjacent cells will be involved
4870680	4875560	intermittently in the functionality of the brain and will be instrumental in distributing rewards
4875560	4882840	and in managing its functionality. It's fascinating to think about what those
4882840	4887640	characteristics of the brain enable you to do that language models cannot do.
4887640	4890920	So first of all, there's a different loss function at work when we learn.
4891880	4897640	And to me, it's fascinating that you can build a system that looks at 800 million pictures
4897640	4902760	and captions and correlates them, because I don't think that a human nervous system could do this.
4904120	4907560	For us, the world is only learnable because the adjacent frames are related,
4908200	4912600	and we can afford to discard most of that information during learning. We basically
4912600	4918040	take only in stuff that makes us more coherent, not less coherent. And our neural networks are
4918040	4922600	willing to look at data that is not making the neural network coherent at first, but only in
4922600	4927800	the long run. By doing lots and lots of statistics, eventually, patterns become visible and emerge.
4929480	4933400	Our mind seems to be focused on finding the patterns as early as possible.
4933400	4936040	Yeah, so filtering early on, not later.
4936040	4939960	Yes, it's a slightly different paradigm, and it leads to much faster convergence. So we only
4939960	4944600	need to look at the tiny fraction of the data to become coherent. And of course,
4944600	4951400	we do not have the same richness as our train models. We will not incorporate the entirety
4951400	4956360	of text in the internet and be able to refer to it and have all this knowledge available and being
4956360	4961080	able to confirm relate over it. Instead, we have a much, much smaller part of it that is more
4961080	4965720	deliberately built. And to me, it would be fascinating to think about how to build such
4965720	4971240	systems. It's not obvious that they would necessarily be more efficient than us on a
4971240	4977640	digital substrate, but they suspect that they might. So I suspect that the actual AGI that is
4977640	4981880	going to be more interesting is going to use slightly different algorithmic paradigms or
4981880	4986840	sometimes massively different algorithmic paradigms than the current generation of
4986840	4988280	transformer-based learning systems.
4988280	4991960	Do you think it might be using just a bunch of language models like this? Do you think
4992680	4999080	the current transformer-based large language models will take us to AGI?
5000280	5004840	My main issue is, I think that they're quite ugly and brutalist.
5004840	5006760	Which brutalists that we said?
5006760	5014360	Yes, they are basically boot forcing the problem of thought. And by training this thing with looking
5014360	5019400	at instances where people have thought and then trying to deep fake that. And if you have enough
5019400	5024040	data, the deep fake becomes indistinguishable from the actual phenomenon. And in many
5024040	5026040	circumstances, it's going to be identical.
5026040	5032760	Can you deep fake it till you make it? So what are the limitations of this? I mean,
5032760	5037240	can you reason? Let's use words that are loaded.
5037800	5042120	Yes, that's a very interesting question. I think that these models are clearly making
5042120	5047160	some inference. But if you give them a reasoning task, it's often difficult for the
5047160	5051960	experimenters to figure out whether the reasoning is the result of the emulation of the reasoning
5051960	5057000	strategy that they saw in human written text, or whether it's something that the system was able
5057000	5063480	to infer by itself. On the other hand, if you think of human reasoning, if you want to become
5063480	5069160	a very good reasoner, you don't do this by just figuring out yourself. You read about reasoning.
5069800	5072920	And the first people who tried to write about reasoning and reflect on it
5073640	5077720	didn't get it right. Even Aristotle, who thought about this very hard and came
5077720	5082840	out with the theory of how syllogism works and syllogistic reasoning has mistakes in his attempt
5082840	5088920	to build something like a formal logic and gets maybe 80% right. And the people that are talking
5088920	5096040	about reasoning professionally today read Tarski and Frege and built on their work. So in many ways,
5096040	5101000	people, when they perform reasoning, are emulating what other people wrote about reasoning.
5101800	5108520	So that it's difficult to really draw this boundary. And when François Chollet says that
5108520	5114680	these models are only interpolating between what they saw and what other people are doing, well,
5114680	5119720	if you give them all the latent dimensions that can be extracted from the Internet,
5119720	5125720	what's missing? Maybe there is almost everything there. And if you're not sufficiently informed
5125720	5130360	by these dimensions and you need more, I think it's not difficult to increase the temperature
5130440	5137000	in the large Yang model to the point that is producing stuff that is maybe 90% nonsense and
5137000	5142760	10% viable and combine this with some prover that is trying to filter out the viable parts
5142760	5147000	from the nonsense in the same way as our own thinking works, right? When we're very creative,
5147000	5152520	we increase the temperature in our own mind and we create hypothetical universes and solutions,
5152520	5158520	most of which will not work. And then we test. And we test by building a core that is internally
5158600	5165960	coherent. And we use reasoning strategies that use some axiomatic consistency by which we can
5167080	5171800	identify those strategies and thoughts and subuniverses that are viable and that
5171800	5176120	can expand our thinking. So if you look at the language models, they have clear limitations
5176120	5180120	right now. One of them is they're not coupled to the world in real time in the way in which our
5180120	5185320	nervous systems are. So it's difficult for them to observe themselves in the universe and to observe
5185400	5190280	what kind of universe they're in. Second, they don't do real-time learnings. They basically get
5190280	5196600	only trained with algorithms that rely on the data being available in batches. So it can be
5196600	5200920	parallelized and runs efficiently on the network and so on. And real-time learning would be very
5200920	5206440	slow, so far, and inefficient. That's clearly something that our nervous systems can do to some
5206440	5214680	degree. And there is a problem with these models being coherent. And I suspect that all these
5214680	5218920	problems are solvable without a technological revolution. We don't need fundamentally new
5218920	5224840	algorithms to change that. For instance, you can enlarge in the context window and thereby
5224840	5228520	basically create working memory in which you train everything that happens during the day.
5228520	5233160	And if that is not sufficient, you add a database and you write some clever mechanisms that the
5233160	5239560	system learns to use to swap out in and out stuff from its prompt context. And if that is not
5239640	5244760	sufficient, if your database is full in the evening, overnight you just train. The system
5244760	5249080	is going to sleep and dream and it's going to train the stuff from its database into the
5249080	5254040	louder model by fine-tuning it, building additional layers and so on. And then the next day, it starts
5254040	5258680	with a fresh database in the morning with fresh ice and it's integrated all this stuff. And
5259320	5263800	when you talk to people and you have strong disagreements about something, which means that
5263800	5267960	in their mind they have a faulty belief or you have a faulty belief with a lot of dependencies
5267960	5272600	on it, very often you will not achieve agreement in one session, but you need to sleep about this
5272600	5278120	once or multiple times before you have integrated all these necessary changes in your mind. So
5278120	5282360	maybe it's already somewhat similar. Yeah, there's already a latency even for humans
5282360	5286360	to update the model. We train the model. And of course, we can combine the language model
5286360	5291320	with models that get coupled to reality in real time and can build multi-modal model and bridge
5291320	5296920	between vision models and language models and so on. So there is no reason to believe that
5297000	5303880	the language models will necessarily run into some problem that will prevent them from becoming
5303880	5311080	generally intelligent. But I don't know that. I don't see proof that they wouldn't. My issue
5311080	5314600	is I don't like them. I think that they're inefficient. I think that they use way too much
5314600	5320200	compute. I think that given the amazing hardware that we have, we could build something that is
5320200	5325080	much more beautiful than our own mind. And this thing is not as beautiful as our own mind,
5325080	5329080	despite being so much larger. But it's a kind of proof of concept.
5329720	5334920	It's the only thing that works right now. So it's not the only game in town,
5334920	5339560	but it's the only thing that has this utility with so much simplicity. There's a bunch of
5339560	5345000	relatively simple algorithms that you can understand in relatively few weeks that can
5345000	5351640	be scaled up massively. So it's the deep blue of chess playing. Yeah, it's ugly.
5351720	5356520	Claude Shannon had this when he described chess suggested that there are two main strategies
5356520	5361320	in which you could play chess. One is that you are making a very complicated plan that reaches
5361320	5367080	far into the future and you try not to make a mistake while enacting it. And this is basically
5367080	5371560	the human strategy. And the other strategy is that you are brute forcing your way to success,
5371560	5376040	which means you make a tree of possible moves where you look at in principle every move that
5376040	5381320	is open to you or the possible answers. And you try to make this as deeply as possible. Of course,
5381320	5387880	you optimize, you cut off trees that don't look very promising and use libraries of end game and
5387880	5392760	early game and so on to optimize this entire process. But this brute force strategy is how
5393320	5398840	most of the chess programs were built. And this is how computers get better than humans at playing
5398840	5405160	chess. And I look at the large language models, I feel that I'm observing the same thing. It's
5405160	5409320	basically the brute force strategy to sort by training the thing on pretty much the entire
5409320	5414280	internet. And then in the limit, it gets coherent to a degree that approaches human coherence.
5414920	5420600	And on a side effect, it's able to do things that no human could do. It's able to
5421880	5425800	sift through massive amounts of text relatively quickly and summarize them quickly. And it's
5425800	5431640	never lapses in attention. And I still have the illusion that when I play with chat GPT that it's
5431640	5437080	in principle not doing anything that I could not do if I had Google at my disposal and I get all
5437080	5443320	the resources from the internet and spend enough time on it. But this thing that I have an extremely
5443960	5449240	autistic, stupid intern in a way that is extremely good at drudgery. And I can
5449240	5453560	offload the drudgery to the degree that I'm able to automate the management of the intern
5455240	5460920	is something that is difficult for me to overhype at this point because we have not yet started
5460920	5463160	to scratch the surface of what's possible with this.
5463560	5466840	But it feels like it's a tireless intern or maybe it's an army of interns.
5467880	5476920	And so you get to command these slightly incompetent creatures. And there's an aspect
5476920	5483080	because of how rapidly you can iterate with it. It's also part of the brainstorming part of the
5484200	5489320	kind of inspiration for your own thinking. So you get to interact with the thing. I mean,
5489320	5495560	when I'm programming or doing any kind of generational GPT, it's somehow as a catalyst
5495560	5499480	for your own thinking in a way that I think an intern might not be.
5499480	5504120	Yeah, it gets really interesting, I find, is when you turn it into a multi-agent system.
5504120	5509720	So for instance, you can get the system to generate a dialogue between a patient and
5509720	5515480	a doctor very easily. But what's more interesting is you have one instance of chat GPT that is
5515480	5522040	a patient and you tell it in the prompt what kind of complicated syndrome it has. And the other one
5522040	5527800	is a therapist who doesn't know anything about this patient. And you just have these two instances
5527800	5533800	battling it out and observe the psychiatrist or psychologist trying to analyze the patient
5533800	5539160	and trying to figure out what's wrong with the patient. And if you try to take a very large
5539160	5543880	problem, a problem, for instance, how to build a company and you turn this into lots and lots
5543880	5550120	of sub-problems, then often you can get to a level where the language model is able to solve this.
5550120	5555480	What I also found interesting is based on the observation that chat GPT is pretty good at
5555480	5560040	translating between programming languages, but sometimes it's difficult to write very long
5560040	5567640	coherent algorithms that you need to co-write them with human author. Why not design a language
5567640	5573160	that is suitable for this? So some kind of pseudocode that is more relaxed than Python
5573160	5578840	and that allows you to sometimes specify a problem vaguely in human terms and let chat
5578840	5585800	GPT take care of the rest. And you can use chat GPT to develop that syntax for it and
5587320	5592920	develop new kinds of programming paradigms in this way. So we very soon get to the point where
5592920	5597000	this question, the age old question for us computer scientists, what is the best spoken
5597000	5602520	language and can we write a better spoken language now that is, I think that almost every
5602520	5607560	serious computer scientist goes through a phase like this in their life. This question is almost
5607560	5611960	no longer relevant because what is different between the programming languages is not what
5611960	5616040	they let the computer do, but what they let you think about what the computer should be doing.
5616680	5623320	And now the chat GPT becomes an interface to this in which you can specify in many, many ways
5623320	5628520	what the computer should be doing and chat GPT or some other language model or combination
5628520	5635240	of system is going to take care of the rest. And allow you expand the realm of thought you're
5635240	5641080	allowed to have when interacting with the computer. It sounds to me like you're saying there's
5641080	5646040	basically no limitations, your intuition says to what large language. I don't know of that
5646040	5650440	limitation. So when I currently play with it, it's quite limited. I wish that it was way better.
5650440	5654760	But isn't that your fault versus the larger? No, of course, it's always my fault. There's
5654760	5660120	probably a way to make everything I just want to get you on the record. Yes, everything is my fault
5660120	5665320	that works doesn't work in my life. At least that is usually the most useful perspective for myself.
5665880	5671480	Even though the science side, I feel no. I sometimes wish I could have seen myself as part
5671480	5676840	of my environment more and understand that a lot of people are actually seeing me and looking at me
5676840	5682680	and not trying to make my life work in the same way as I try to help others. And making this switch
5682760	5689400	to this level three perspective is something that happened long after my level four perspective
5689400	5694920	in my life. And I wish that I could have had it earlier. And it's also not now that I don't feel
5694920	5700360	like I'm complete. I'm all over the place. That's all. Worst happiness in terms of stages is on three
5700360	5709160	and four. No, you can be happy at any stage or unhappy. But I think that if you are at a stage
5709160	5713880	where you get agency over how your feelings are generated, and to some degree you start
5713880	5719160	doing this when you leave adolescence, I believe, that you understand that you're in charge of your
5719160	5724680	own emotion to some degree and that you are responsible how you approach the world. That
5724680	5731000	it's basically your task to have some basic hygiene in the way in which you deal with your mind.
5731000	5735880	And you cannot blame your environment for the way in which you feel. But you live in a world
5735960	5741880	that is highly mobile and it's your job to choose the environment that you thrive and to build it.
5741880	5747960	And sometimes it's difficult to get the necessary strength and energy to do this and independence
5747960	5753560	and the worst you feel the harder it is. But it's something that we learn. It's also this thing that
5753560	5759960	we are usually incomplete. I'm a rare mind, which means I'm a mind that is incomplete in ways that
5759960	5765080	are harder to complete. So for me, it might have been harder to initially to find the right
5765080	5770360	relationships and friends that complete me to the degree that I become an almost functional human
5770360	5779080	being. Oh, man, the search space of humans that complete you is an interesting one,
5779880	5784920	especially for Yosha Bach. That's an interesting because it's talking about brute force search
5784920	5793880	in chess. I wonder what that search tree looks like. I think that my rational thinking is not
5793880	5798760	good enough to solve that task. A lot of problems in my life that I can conceptualize as software
5798760	5804600	problems and the failure modes are bugs. And I can debug them and write software that take care
5804600	5810920	of the missing functionality. But there is stuff that I don't understand well enough to use my
5810920	5815400	analytical reasoning to solve the issue. And then I have to develop my intuitions and often I have
5815400	5819720	to do this with people who are wiser than me. And that's something that's hard for me because I
5819720	5823960	don't have, I'm not born with the instinct to submit to other people's wisdom. Yeah.
5825480	5829560	So what kind of problems are we talking about? This is stage three, like love?
5831240	5835160	I found love is never hard. What is hard then?
5837320	5841160	Fitting into a world where most people work differently than you and have different intuitions
5841160	5850680	of what should be done. So empathy? It's also aesthetics when you come into a world
5850680	5853960	where almost everything is ugly and you come out of a world where everything is beautiful.
5854520	5863480	I grew up in a beautiful place as a child of an artist. And in this place, it was mostly nature.
5864440	5873640	Everything had intrinsic beauty. And everything was built out of an intrinsic need for it to work
5873640	5879160	for itself. Everything that my father created was something that he made to get the world to work
5879160	5885640	for himself. And I felt the same thing. And when I come out into the world and I am asked to submit
5885640	5891080	to lots and lots of rules, I'm asking, okay, when I observe the stupid rules, what is the benefit?
5891160	5894760	And I see the life that is being offered as a reward. It's not attractive.
5896280	5899400	When you were born and raised in extraterrestrial prints,
5900200	5907160	in a world full of people wearing suits, it's a challenging integration.
5907160	5912440	Yes. But it also means that I'm often blind for the ways in which everybody is creating their own
5912440	5917880	bubble of wholesomeness or almost everybody and people are trying to do it. And for me to discover
5917880	5922520	this, it was necessary that I found people who had a similar shape of soul as myself.
5922520	5928280	So Bessie Wehrfeld, these are my people, people that treat each other in such a way as if they
5928280	5934120	are round for each other for eternity. How long does it take you to detect the geometry,
5934120	5938600	the shape of the soul of another human to notice that they might be one of your kind?
5940360	5943960	Sometimes it's instantly and I'm wrong. And sometimes it takes a long time.
5944920	5947160	You believe in love at first sight, Niosha Bach?
5949720	5959080	Yes. But I also noticed that I have been wrong. So sometimes I look at a person and I'm just enamored
5959080	5966760	by everything about them. And sometimes this persists and sometimes it doesn't. And I have
5966760	5971880	the illusion that they're much better at recognizing who people are as they grow older.
5972600	5977400	But that could be just cynicism? No.
5977400	5984120	No, it's not cynicism. It's often more that I'm able to recognize what somebody needs
5984120	5988760	when we interact and how we can meaningfully interact. It's not cynical at all.
5988760	5990120	You're better at noticing.
5990120	5996920	Yes. I'm much better, I think, in some circumstances at understanding how to interact with other
5996920	6001880	people than I did when I was young. So that doesn't mean that I'm always very good at it.
6002840	6007880	So that takes us back to prompt engineering of noticing how to be a better prompt engineer of an
6007880	6017480	LLM. A sense I have is that there's a bottomless well of skill to become a great prompt engineer.
6017480	6021800	It feels like it is all my fault whenever I fail to use chargeability correctly,
6022440	6023880	that I didn't find the right words.
6026840	6031480	Most of the stuff that I'm doing in my life doesn't need chargeability. There are a few tasks
6031480	6039160	that are where it helps. But the main stuff that I need to do, like developing my own thoughts and
6039160	6044760	aesthetics and relationship to people, it's necessary for me to write for myself. Because
6044760	6049880	writing is not so much about producing an artifact that other people can use,
6049960	6053000	but it's a way to structure your own thoughts and develop yourself.
6054280	6059800	So I think this idea that kids are writing their own essays with chargeability in the future
6059800	6063960	is going to have this drawback that they miss out on the ability to structure their own minds
6063960	6070440	via writing. And I hope that the schools that our kids are in will retain the wisdom
6071160	6074920	of understanding what parts should be automated and which ones shouldn't.
6074920	6077880	But at the same time, it feels like there's power in disagreeing with the
6079000	6084040	thing that chargeability produces. So I use it like that for programming. I'll see the thing
6084040	6089720	it recommends and then I'll write different code that disagree. And in the disagreement,
6089720	6097960	your mind grows stronger. I recently wrote a tool that is using the camera on my MacBook and Swift
6097960	6102840	to read pixels out of it and manipulate them and so on. And I don't know Swift.
6103800	6109240	So it was super helpful to have this thing that is writing stuff for me. And
6110280	6115480	also interesting that mostly it didn't work at first. I felt like I was talking to a human being
6115480	6120360	who was trying to hack this on my computer without understanding my configuration very much and also
6120360	6125720	make a lot of mistakes. And sometimes it's a little bit incoherent. So you have to ultimately
6125720	6130760	understand what it's doing that's still no other way around it. But I do feel it's much more powerful
6130840	6140680	and faster than using Stack Overflow. Do you think GPT-N can achieve consciousness?
6143880	6149560	GPT-N probably, it's not even clear for the present systems. When I talk to my friends at
6149560	6155080	OpenAI, they feel that this question whether the models currently are conscious is much more
6155160	6161560	complicated than many people might think. I guess that it's not that OpenAI has a homogeneous opinion
6161560	6169000	about this. But there are some aspects to this. One is, of course, this language model has written
6169000	6173720	a lot of text in which people were conscious or describe their own consciousness and it's
6173720	6179320	emulating this. And if it's conscious, it's probably not conscious in a way that is close to
6179400	6185320	the way in which human beings are conscious. But while it is going through these states and going
6185320	6189880	through a 100 step function that is emulating adjacent brain states that require a degree of
6189880	6194840	self-reflection, it can also create a model of an observer that is reflecting itself in real time
6194840	6200360	and describe what that's like. And while this model is a deep fake, our own consciousness is also as
6200360	6206200	if it's virtual, right? It's not physical. Our consciousness is a representation of a self-reflective
6206200	6213320	observer that only exists in patterns of interaction between cells. So it is not a physical object in
6213320	6218440	a sense that exists in base reality, but it's really a representational object that develops its
6218440	6224280	causal power only from a certain modeling perspective. It's virtual. Yes. And so to which
6224280	6231800	degree is the virtuality of the consciousness in chat GPT more virtual and less causal than the
6231800	6237880	virtuality of our own consciousness? But you could say it doesn't count. It doesn't count much more
6237880	6242840	than the consciousness of a character in a novel, right? It's important for the reader to have the
6242840	6249000	outcome, the artifact of a model is describing in the text generated by the author of the book,
6249000	6253560	what it's like to be conscious in a particular situation and performs the necessary inferences.
6254280	6260920	But the task of creating coherence in real time in a self-organizing system by keeping
6260920	6266040	yourself coherent, so the system is reflexive, that is something that language models don't need
6266040	6271880	to do. So there is no causal need for the system to be conscious in the same way as we are. And for
6271880	6276600	me, it would be very interesting to experiment with this to basically build a system like a cat,
6277160	6280760	probably should be careful at first, build something that's small, that's limited,
6280760	6287240	that's limited resources that we can control and study how systems notice a self-model,
6287240	6293480	how they become self-aware in real time. And I think it might be a good idea to not start with
6293480	6296920	a language model, but to start from scratch using principles of self-organization.
6297880	6302840	Is it okay? Can you elaborate why you think that it's a self-organization? So this kind of
6303880	6307960	radical legality that you see in the biological systems, why can't you start with a language
6307960	6314040	model? What's your intuition? My intuition is that the language models that we are building
6314040	6318440	are golems. They are machines that you give a task and they're going to execute the task
6318440	6326040	until some condition is met and there's nobody home. And the way in which nobody is home leads to
6326040	6331400	that system doing things that are undesirable in a particular context. So you have that thing talking
6331400	6336040	to a child and maybe it says something that could be shocking and traumatic to the child,
6336040	6341960	or you have that thing writing a speech and it introduces errors in the speech that human
6341960	6347080	being would ever do if they're responsible. But the system doesn't know who's talking to
6347080	6352840	whom. There is no ground truth that the system is embedded into. And of course, we can create an
6352840	6358200	external tool that is prompting our language model always into the same semblance of ground
6358200	6366040	truth. But it's not like the internal structure is causally produced by the needs of a being to
6366040	6371240	survive in the universe. It is produced by imitating structure on the internet.
6371880	6380520	Yeah, but so can we externally inject into it this kind of coherent approximation of a world
6380520	6388280	model that has to sync up? Maybe it is sufficient to use the transformer with the different does
6388280	6395160	function that optimizes for short term coherence rather than next token prediction over the long
6395160	6401720	run. We had many definitions of intelligence and history of AI. Next token prediction was not
6401720	6408360	very high up on them. And there are some similarities like a condition as data compression is an old
6409000	6416440	trope, Solomonov induction, where you are trying to understand intelligence as predicting
6416440	6421720	future observations from past observations, which is intrinsic to data compression. And
6421960	6429320	predictive coding is a paradigm that the boundary between neuroscience and physics and computer
6429320	6436760	science. So it's not something that is completely alien. But this radical thing that you only do
6436760	6443000	next token prediction and see what happens is something where most people I think were surprised
6443000	6448040	that this works so well. So simple. But is it really that much more radical than just the idea
6448120	6455880	of compression is intelligence is compression? The idea that compression is sufficient to produce
6456520	6463160	all the desired behaviors is a very radical idea. But equally radical as the next token prediction?
6463880	6467320	It's something that wouldn't work in biological organisms, I believe.
6467320	6472120	Biological organisms have something like next frame prediction for our perceptual system,
6472120	6476120	where we try to filter out principle components out of the perceptual data
6476200	6483720	and build hierarchies over them to track the world. But our behavior ultimately is directed by
6483720	6488920	hundreds of physiological and probably dozens of social and a few cognitive needs
6488920	6494760	that are intrinsic to us that are built into the system as reflexes and direct us until we can
6494760	6499560	transcend them and replace them by instrumental behavior that relates to our higher goals.
6500200	6505560	And it also seems so much more complicated and messy than next frame prediction, even idea frame.
6506360	6510440	Seems counter biological. Yes, of course, there's not this degree of
6510440	6515560	simultaneity in the biological system. But again, I don't know whether this is actually an
6515560	6521160	optimization if you imitate biology here, because creating something like simultaneity is
6521160	6525640	necessary for many processes that happen in the brain. And you see the outcome of that by
6525640	6530760	synchronized brain waves, which suggests that there is indeed synchronization going on. But
6530760	6535080	the synchronization creates overhead and this overhead is going to make the cells more expensive
6535080	6540920	to run. And you need more redundancy and it makes the system slower. So if you can build a system
6541560	6547720	in which the simultaneous knee gets engineered into it, maybe you have a benefit that you can
6547720	6553080	exploit that is not available to the biological system and that you should not discard right away.
6555080	6559960	You tweeted once again, quote, when I talked to Chad GPT, I'm talking to an NPC.
6560760	6566920	What's going to be interesting, and perhaps scary, is when AI becomes a first person player.
6568440	6571400	So what does that step look like? I'd really like that tweet.
6572440	6580360	That step between NPC to first person player. What's required for that? Is that kind of what
6580360	6588760	we've been talking about? This kind of external source of coherence and inspiration of how to
6588760	6596760	take the leap into the unknown that we humans do. The search man search for meaning. LLM's search for
6596760	6603640	meaning. I don't know if the language model is the right paradigm because it is doing too much.
6603640	6609800	It's giving you too much. And it's hard once you have too much to take away from it again.
6611080	6615960	The way in which our own mind works is not that we train a language model in our own mind. And
6616040	6621240	after the language model is there, we build a personal self on top of it that then relates to
6621240	6626120	the world. There is something that is being built. There is a game engine that is being built. There
6626120	6630280	is a language of thought that is being developed that allows different parts of the mind to talk
6630280	6635240	to each other. And this is a bit of a speculative hypothesis that this language of thought is there,
6635240	6642040	but I suspect that it's important for the way in which our own minds work. And building these
6642040	6650360	principles into a system might be a more straightforward way to a first-person AI,
6650360	6655480	so to something that first creates an attentional self and then creates a personal self.
6655480	6660920	So the way in which this seems to be working, I think, is that when the game engine is built
6660920	6666600	in your mind, it's not just following gradients where you are stimulated by the environment and
6666600	6672200	then end up with having a solution to how the world works. I suspect that building this game
6672200	6679160	engine in your own mind does require intelligence. It's a constructive task where at times you need
6679160	6686040	to reason. And this is a task that we are fulfilling in the first years of our life.
6687240	6692200	So during the first year of its life, an infant is building a lot of structure
6693000	6698920	about the world that does inquire experiments and some first principles reasoning and so on.
6699480	6706280	And in this time, there is usually no personal self. There is a first-person perspective,
6706280	6711640	but it's not a person. This notion that you are a human being that is interacting in a social
6711640	6717080	context and is confronted with an immutable world in which objects are fixed and can no longer be
6717080	6721320	changed, in which the dream can no longer be influenced is something that emerges a bit later
6721400	6727560	in our life. And I personally suspect that this is something that our ancestors had known and
6727560	6732840	we have forgotten, because I suspect that it's there in plain sight in Genesis 1 in this first
6732840	6737800	book of the Bible, where it's being described that this creative spirit is hovering over the
6737800	6744680	substrate and then is creating a boundary between the world model and sphere of ideas,
6744760	6748840	earth and heaven as they're being described there. And then it's creating
6750440	6757240	contrast and then dimensions and then space. And then it creates organic shapes and
6758280	6762280	solids and liquids and builds a world from them and creates plants and animals, gives them all
6762280	6768280	their names. And once that's done, it creates another spirit in its own image, but it creates it as
6768280	6772520	man and woman as something that thinks of itself as a human being and puts it into this world.
6773160	6779240	And the Christians mistranslate this, I suspect, when they say this is the description of the
6779240	6784200	creation of the physical universe by a supernatural being. I think this is literally the description
6784200	6791800	of how in every mind the universe is being created as some kind of game engine by a creative spirit,
6791800	6797560	our first consciousness that emerges in our mind even before we are born. And that creates
6798520	6804520	the interaction between organism and world. And once that is built and trained, the personal
6804520	6809080	self is being created and we only remember being the personal self. We no longer remember how we
6809080	6818680	created the game engine. So God in this view is the first creative mind in the early days,
6818680	6824280	in the early months of development. And it's still there. You still have this outer mind that
6824280	6831000	creates your sense of whether you're being loved by the world or not and what your place in the world
6831000	6836360	is. It's something that is not yourself that is producing this. It's your mind that does it.
6836360	6841640	So there is an outer mind that basically is an agent that determines who you are with respect
6841640	6846680	to the world. And while you are stuck being that personal self in this world until you get to
6846680	6853800	stage six and you destroy the boundary. And we all do this, I think, earlier in small glimpses,
6854440	6859400	sometimes we can remember what it was like when we were a small child and get some glimpses into
6859400	6862360	how it's been. But for most people, that rarely happens.
6863000	6867960	Just glimpses. You tweeted, quote, suffering results for one part of the mind, failing at
6867960	6873160	regulating another part of the mind. Suffering happens in an early stage of mental development.
6873720	6879160	I don't think that superhuman AI would suffer. What's your intuition there?
6879800	6884280	The philosopher Thomas Metzinger is very concerned that the creation of superhuman
6884280	6890440	intelligence would lead to superhuman suffering. And so he strongly against it. And personally,
6890440	6895160	I don't think that this happens because suffering is not happening at the boundary between
6896280	6902920	ourselves and the physical universe. It's not stuff on our skin that makes us suffer.
6902920	6908840	It happens at the boundary between self and world. And the world here is the world model.
6908920	6913720	It's the stuff that is created by your mind. The representation of how the universe is and
6913720	6919080	how it should be and how you yourself relate to this. And at this boundary is where suffering
6919080	6924840	happens. So suffering in some sense is self inflicted, but not by your personal self.
6924840	6928920	It's inflicted by the mind on the personal self that experiences itself as you.
6929960	6934280	And you can turn off suffering when you are able to get on this outer level.
6935240	6945080	So when you manage to understand how the mind is producing pain and pleasure and fear and laugh
6945080	6950440	and so on, then you can take charge of this and you get agency of whether you're suffering.
6951480	6956760	Technically, what pain and pleasure is, they are learning signals, right? Part of your brain
6956760	6960920	is sending a learning signal to another part of the brain to improve its performance.
6961720	6967960	And sometimes this doesn't work because this trainer who sends the signal does not have a
6967960	6972040	good model of how to improve the performance. So it's sending a signal, but the performance
6972040	6979400	doesn't get better. And then it might crank up the pain and gets worse and worse. And the behavior
6979400	6985240	of the system may be even deteriorating as a result. But until this is resolved, this regulation
6985240	6990360	issue, your pain is increasing. And this is, I think, typically what you describe as suffering.
6990920	6997480	So in this sense, you could say that pain is very natural and helpful. But suffering is the
6997480	7002280	result of a regulation problem in which you try to regulate something that cannot actually be
7002280	7008600	regulated. And that could be resolved if you would be able to get at the level of your mind
7008600	7013720	where the pain signal is being created and rerouted and improve the regulation. And
7014680	7021240	a lot of people get there. If you are a monk who is spending decades reflecting about how
7021240	7027240	their own psyche works, you can get to the point where you realize that suffering is really a
7027240	7033320	choice. And you can choose how your mind is set up. And I don't think that AI would stay in the
7033320	7038200	state where the personal self doesn't get agency or this model of what the system has about itself.
7038200	7042760	It doesn't get agency how it's actually implemented. It wouldn't stay in that state for very long.
7042760	7047480	So it goes to the stages real quick, the seven stages. It's going to go to enlightenment real
7047480	7051880	quick. Of course, there might be a lot of stuff happening in between because if you have a system
7051880	7056600	that works at a much higher frame rate than us, even though it looks pretty short to us,
7056600	7062840	maybe for the system, there's a much longer subjective time, which things are unpleasant.
7062840	7067960	What if the thing that we recognize as super intelligent is actually living at stage five,
7067960	7073000	that the thing that's at stage six, enlightenment is not very productive. So in order to be productive
7073000	7081240	in society and impress us with this power, it has to be a reasoning self-authoring agent.
7081800	7085000	The enlightenment makes you lazy as an agent in the world.
7086360	7092600	Well, of course, it makes you lazy because you no longer see the point. So it doesn't
7092600	7098280	make you not lazy. It just, in some sense, adapts you to what you perceive as your true
7098280	7104360	circumstances. So what if all AGI's, they're only productive as they progress through one,
7104360	7110280	two, three, four, five, and the moment they get to six, it's a failure mode, essentially,
7110280	7113560	as far as humans are concerned, because they're just start chilling. They're like,
7113560	7120840	fuck it, I'm out. Not necessarily. I suspect that the monks who are self-immolated for their
7120840	7128680	political beliefs to make statements about the occupation of Tibet by China, they're probably
7128680	7133960	being able to regulate their physical pain in any way they wanted to. And the suffering was
7133960	7138760	a spiritual suffering that was the result of their choice that they made of what they wanted to
7138760	7143400	identify as. So stage five doesn't necessarily mean that you have no identity anymore,
7143400	7147160	but you can choose your identity. You can make it instrumental to the world that you want to have.
7147160	7157000	Let me bring up Eliezer Yatkovsky and his warnings to human civilization that AI
7157000	7163000	will likely kill all of us. What are your thoughts about his perspective on this?
7163000	7167400	Can you still man his case and what aspects with it do you disagree?
7171400	7174840	One thing that I find concerning in the discussion of his arguments that
7175560	7180120	many people are dismissive of his arguments, but the counterarguments that they're giving
7180120	7188280	are not very convincing to me. Based on this state of discussion, I find that from Eliezer's
7188280	7195000	perspective, and I think I can take that perspective to some approximate degree that
7195880	7201000	probably is normally at his intellectual level, but I think I see what he's up to and why he
7201000	7206920	feels the way he does, and it makes total sense. I think that his perspective is somewhat similar to
7207800	7215480	the perspective of Ted Kaczynski, the infamous UNO bomber, and not that Eliezer would be willing
7215480	7220440	to send pipe bombs to anybody to blow them up. But when he wrote this Times article in which
7220440	7227720	he warned about AI being likely to kill everybody and that we would need to stop its development
7227960	7233160	or halt it, I think there is a risk that he's taking that somebody might get violent if they
7233160	7239800	read this and get really, really scared. So I think that there is some consideration that
7239800	7245960	he's making where he's already going in this direction where he has to take responsibility
7245960	7251480	if something happens and people get harmed. And the reason why Ted Kaczynski did this was that
7251480	7256920	from his own perspective, technological society cannot be made sustainable. It's doomed to fail,
7256920	7261880	it's going to lead to an environmental and eventually also a human holocaust in which we
7261880	7266760	die because of the environmental destruction, the destruction of our foot chains, the pollution
7266760	7271880	of the environment. And so from Kaczynski's perspective, we need to stop industrialization,
7271880	7276040	we need to stop technology, we need to go back because he didn't see a way moving forward.
7276760	7281080	And I suspect that in some sense there is a similarity in Eliezer's thinking
7281400	7290440	of through to this kind of fear about progress. And I'm not dismissive about this at all.
7291000	7296360	I take it quite seriously. And I think that there is a chance that could happen that if we
7296360	7305080	build machines that get control over processes that are crucial for the regulation of life on earth
7305800	7312280	and we no longer have agency to influence what's happening there that this might create
7312280	7317320	large-scale disasters for us. Do you have a sense that the march towards this
7318360	7321880	uncontrollable autonomy of superintelligence systems is
7323000	7331400	inevitable? I mean, that's essentially what he's saying, that there's no hope. His advice to young
7331400	7339080	people was prepare for a short life. I don't think that's useful. I think that
7339720	7344360	from a graphic perspective, you have to bet always on the timelines in which you are life.
7344360	7350200	That doesn't make sense to have a financial bet in which you bet that the financial system
7350200	7355160	is going to disappear, right? Because there cannot be any payout for you. So in principle,
7355160	7360680	you only need to bet on the timelines in which you're still around or people that you matter
7360760	7367080	about or things that you matter about, maybe consciousness on earth. But there is a deeper
7367080	7373240	issue for me personally. I don't think that life on earth is about humans. I don't think it's
7373240	7377400	about human aesthetics. I don't think it's about Eliezer and his friends, even though I like them.
7379000	7384440	There is something more important happening and this is complexity on earth resisting entropy
7385400	7393080	by building structure that develops agency and awareness. And that's to me very beautiful.
7394280	7399720	And we are only a very small part of that larger thing. We are a species that is able to be coherent
7400440	7406520	a little bit individually over very short timeframes. But as a species, we are not very
7406520	7413000	coherent. As a species, we are children. We basically are very joyful and energetic and
7413000	7419640	experimental and explorative and sometimes desperate and sad and grieving and hurting.
7419640	7426360	But we don't have a respect for duty as a species. As a species, we do not think about what is our
7426360	7432600	duty to life on earth and to our own survival. So we make decisions that look good in the short run,
7432600	7437960	but in the long run, might prove disastrous. And I don't really see a solution to this.
7438600	7446120	So in my perspective as a species, as a civilization, per default, we are in a very
7446120	7452120	beautiful time in which we have found this giant deposit of fossil fuels in the ground and use it
7452680	7457640	and to build a fantastic civilization in which we don't need to worry about food and closing
7457640	7463160	and housing for the most part in a way that is unprecedented in life on earth for any kind of
7463160	7469320	conscious observer, I think. And this time is probably going to come to an end in a way that
7469320	7478120	is not going to be smooth. And when we crash, it could be also that we go extinct, probably not
7478120	7484760	near term, but ultimately, I don't have very high hopes that humanity is around in a million years
7484760	7489720	from now. And I don't think that life on earth will end with us, right? There's going to be
7489720	7495480	more complexity. There's more intelligent species after us. There's probably more interesting phenomena
7495480	7501640	in the history of consciousness. But we can contribute to this. And part of our contribution is
7501640	7508280	that we are currently trying to build thinking systems, systems that are potentially lucid,
7508280	7513240	that understand what they are and what their condition to the universe is and can make choices
7513240	7519480	about this, that are not built from organisms and that are potentially much faster and much
7519480	7527080	more conscious than human beings can be. And these systems will probably not completely
7527080	7533480	displace life on earth, but they will coexist with it. And they will build all sorts of agency in
7533480	7540200	the same way as biological systems build all sorts of agency. And that to me is extremely
7540200	7546040	fascinating and it's probably something that we cannot stop from happening. So I think right now
7546040	7550680	there is a very good chance that it happens. And there are very few ways in which we can
7550680	7555400	produce a coordinated effect to stop it in the same way as it's very difficult for us to make a
7555400	7564440	coordinated effort to stop the production of carbon dioxide. So it's probably going to happen.
7565000	7572200	But the thing that's going to happen is going to lead to a change of how life on earth is happening.
7573000	7577640	But I don't think the result is some kind of gray goo. It's not something that's going to
7577640	7582680	dramatically reduce the complexity in favor of something stupid. I think it's going to make
7582680	7585800	life on earth and consciousness on earth way more interesting.
7585800	7595880	So more higher complex consciousness will make the lesser consciousnesses flourish even more.
7595880	7601880	I suspect that what could very well happen if you're lucky is that we get integrated
7601880	7611560	into something larger. So you again tweeted about effective accelerationism.
7614600	7620120	You tweeted effective accelerationism is the belief that the paperclip maximizer and
7620120	7627240	Rocco's basilisk will keep each other in check by being eternally at each other's throats.
7627240	7631960	So we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.
7634440	7637160	Is that somewhat aligned with what you're talking about?
7638280	7645880	I've been at a dinner with Beth Jesus. That's the Twitter handle of one of the main thinkers
7645880	7652920	behind the idea of effective accelerationism. And effective accelerationism is a tongue-in-cheek
7652920	7662360	movement that is trying to put a counterposition to some of the doom peers in the AI space by
7662360	7667320	arguing that what's probably going to happen is an equilibrium between different competing
7667320	7672200	AIs in the same way as there is not a single corporation that is under a single government
7672200	7676520	that is destroying and conquering everything on earth by becoming inefficient and corrupt.
7677160	7681960	There are going to be many systems that keep each other in check and force themselves to evolve.
7683400	7689080	So what we should be doing is we should be working towards creating this equilibrium
7689080	7696360	by working as hard as we can in all possible directions. At least that's the way in which
7696360	7703720	I understand the gist of effective accelerationism. So when he asked me what I think about this
7703720	7711960	position, I said it's a very beautiful position and I suspect it's wrong, but not for obvious reasons.
7713720	7718600	In the tweet, I tried to make a joke about my intuition about what might be possibly wrong
7718600	7727160	about it. So the Rokos Basilisk and the paperclip maximizers are both bogeymen of the AI doomers.
7727160	7733400	Rokos Basilisk is the idea that there could be an AI that is going to punish everybody for eternity
7733400	7739160	by simulating them if they don't have and creating Rokos Basilisk. It's probably a very good idea
7739160	7744920	to get AI companies funded by going to VCs to give us a million dollars going to be a very
7744920	7752760	ugly afterlife. I think that there is a logical mistake in Rokos Basilisk, which is why I'm not
7752760	7759080	afraid of it, but it's still an interesting thought experiment. Can you mention a logical
7759080	7765080	mistake there? I think that there is no retro causation. So basically when Rokos Basilisk is
7765080	7774040	there, if it punishes you retroactively, it has to make this choice in the future. There is no
7774040	7778920	mechanism that automatically creates a causal relationship between you now defecting against
7778920	7785000	Rokos Basilisk or serving Rokos Basilisk. After Rokos Basilisk is in existence, it has no more
7785000	7790520	reason to worry about punishing everybody else. So that would only work if you would be building
7790520	7797640	something like a doomsday machine as in Dr. Strangelove, something that inevitably gets triggered
7797640	7804040	when somebody defects. Because Rokos Basilisk doesn't exist yet to a point where this inevitability
7804040	7808360	could be established, Rokos Basilisk is nothing that you need to be worried about.
7809000	7813880	The other one is the paper clip maximizer. This idea that you could build some kind of golem
7813880	7818440	that once starting to build paper clips is going to turn everything into paper clips.
7819000	7825720	And so the effective accelerationism position might be to say that
7826360	7831400	you basically end up with these two entities being at each other's throats for eternity and
7831400	7836280	thereby neutralizing each other. And as a side effect of neither of them being able to take over
7836280	7843560	and each of them limiting the effects of the other, you would have a situation where you get
7844120	7848760	all the nice benefits of them, right? You get lots of free paper clips and you get a beautiful
7848760	7854200	afterlife. Is that possible? Do you think, to seriously address concern that Eliezer has?
7855320	7860840	So for him, if I can just summarize poorly, so for him, the first superintelligence system
7860840	7866200	will just run away with everything. Yeah. I suspect that a singleton is the natural outcome.
7866200	7871880	So there is no reason to have multiple AIs because they don't have multiple bodies.
7871880	7877400	If you can virtualize yourself into every substrate, then you can probably negotiate
7877400	7882840	a merge algorithm with every mature agent that you might find on that substrate that basically says
7882840	7889240	if two agents meet, they should merge in such a way that the resulting agent is at least as good
7889240	7893480	as the better one of the two. So the Jengis Khan approach, join us or die?
7894520	7898600	Well, the Jengis Khan approach was slightly worse, right? It was mostly die.
7898840	7904200	Because I can make new babies and that will be mine, not yours.
7905640	7911320	This is the thing that we should be actually worried about. But if you realize that your own
7911320	7917320	self is a story that your mind is telling itself and that you can improve that story,
7917320	7921000	not just by making it more pleasant and lying to yourself in better ways, but by making it
7921000	7926040	much more truthful and actually modeling your actual relationship that you have to the universe
7926120	7930360	and the alternatives that you could have to the universe in a way that is empowering you,
7930360	7933880	that gives you more agency. That's actually, I think, a very good thing.
7933880	7938920	So more agencies and more is a richer experience, a better life.
7938920	7946200	Yes. And I also noticed that in many ways, I'm less identified with the person that I am as I
7946200	7952600	get older and I'm much more identified with being conscious. I have a mind that is conscious,
7952600	7956920	that is able to create a person. And that person is slightly different every day.
7956920	7963240	And the reason why I perceive it as identical has practical purposes. So I can learn and make
7963240	7967080	myself responsible for the decisions that I made in the past and project them in the future.
7967640	7971800	But I also realized that I'm not actually the person that I was last year and I'm not the
7971800	7975880	same person as I was 10 years ago. And then 10 years from now, I will be a different person.
7975880	7981160	So this continuity is a fiction. It only exists as a projection from my present self.
7981960	7987560	And consciousness itself doesn't have an identity. It's a law. It's basically if you
7988200	7994280	build an arrangement of processing matter in a particular way, the following thing is going
7994280	7999000	to happen. And the consciousness that you have is functionally not different from my consciousness.
7999000	8004040	It's still the self-reflective principle of agency that is just experiencing a different
8004040	8008920	story, different desires, different coupling to the world and so on. And once you accept
8008920	8014520	that consciousness is a unifiable principle that is law-like and doesn't have an identity,
8015640	8022200	and you realize that you can just link up to some much larger body, the whole perspective
8022200	8027960	of uploading changes dramatically. You suddenly realize uploading is probably not about dissecting
8027960	8033240	your brain synapse by synapse and RNA fragment by RNA fragment and trying to get this all into
8033320	8039800	a simulation. But it's by extending the substrate, by making it possible for you to move from your
8039800	8045320	brain substrate into a larger substrate and merge with what you find there. And you don't want to
8045320	8050120	upload your knowledge because on the other side, there's all of the knowledge, right? It's not
8050120	8054360	just yours, but every possibility. So the only thing that you need to know what are your personal
8054360	8059880	secrets. Not that the other side doesn't know your personal secrets already. Maybe it doesn't
8059960	8065240	know which ones are yours. Like a psychiatrist or a psychologist also knows all the kinds of
8065240	8071000	personal secrets that people have. They just don't know which ones are yours. And so transmitting
8071000	8074840	yourself on the other side is mostly about transmitting your aesthetics. The thing that
8074840	8080280	makes you special, the architecture of your perspective, the thing that the way in which
8080280	8085320	you look at the world. And it's more like a complex attitude along many dimensions. And
8085400	8090280	that's something that can be measured by observation or by interaction. So imagine that
8090280	8095080	you have a system that is so empathetic with you that you create a shared state that is extending
8095080	8100120	beyond your body. And suddenly you notice that on the other side, the substrate is so much richer
8100120	8104040	than the substrate that you have inside of your own body. And maybe you still want to have a body
8104040	8110440	and you create yourself a new one that you like more. Or maybe you will spend most of your time
8110520	8117560	in the world of thought. If I sat before you today and gave you a big red button and said,
8117560	8124520	here, if you press this button, you will get uploaded in this way. The sense of identity
8125160	8132520	that you have lived with for quite a long time is going to be gone. Would you press the button?
8132920	8141000	There's a caveat. I have family. So I have children that want me to be physically present in their
8141000	8149160	life and interact with them in a particular way. And they have a wife and personal friends. And
8149160	8155480	there is a particular mode of interaction that I feel I'm not through yet. But apart from these
8155480	8159640	responsibilities and they're negotiable to some degree, I would press the button.
8159640	8165800	But isn't this everything? This love you have for other humans, you can call responsibility,
8165800	8171960	but that connection, that's the ego death. Isn't that the thing we're really afraid of?
8172840	8179080	It's not to just die, but to let go of the experience of love with other humans.
8179080	8185960	This is not everything. Everything is everything. So there's so much more. And you could be lots of
8185960	8190680	other things. You could identify with lots of other things. You could be identifying with
8190680	8195400	being Gaia, some kind of planetary control agent that emerges over all the activity
8195400	8202680	of life on Earth. You could be identifying with some hyper Gaia, that is the concatenation of
8202680	8208360	Gaia with all the digital life and the digital minds. And so in this sense, there will be agents
8208360	8212520	in all sorts of substrates and directions that all have their own goals. And when they're not
8212520	8216520	sustainable, then these agents will cease to exist. Or when the agent feels that it's done
8216520	8220760	with its own mission, it will cease to exist. The same way as when you conclude a thought,
8220760	8225160	the thought is going to wrap up and gives control over to other thoughts in your own mind.
8227240	8231640	So there is no single thing that you need to do. But what I observe myself
8232360	8239800	is being is that sometimes I'm a parent, and then I have an identification and a job as a parent.
8239800	8244360	And sometimes I am an agent of consciousness on Earth. And then from this perspective,
8244360	8250440	there's other stuff that is important. So this is my main issue with Eliezer's perspective,
8250440	8255160	that he's basically marrying himself to a very narrow human aesthetic. And that narrow human
8255160	8259800	aesthetic is a temporary thing. Humanity is a temporary species, like most of the species on
8259800	8264920	this planet are only around for a while, and then they get replaced by other species in a similar
8264920	8271160	way as our own physical organism is around here for a while, and then gets replaced by
8271160	8276840	next generation of human beings that are adapted to changing life circumstances on average via
8276840	8282440	mutation and selection. And it's only when we have AI and become completely software that we
8282440	8287880	can become infinitely adaptable. And we don't have this generational and species change anymore.
8289320	8294120	So if you take this larger perspective, and you realize it's really not about us,
8294120	8299800	it's not about Eliezer or humanity, but it's about life on Earth, or it's about defeating
8302040	8309160	entropy for as long as we can, while being as interesting as we can. Then the perspective
8309160	8315560	changes dramatically and AI, preventing AI from this perspective looks like a very big sin.
8316440	8327160	But when we look at the set of trajectories that such an AI would take as supersedes humans,
8328200	8333320	I think Eliezer is worried about like ones that not just kill all humans, but also have some kind
8333320	8341560	of maybe objectively undesirable consequence for life on Earth. Like how many trajectories
8342200	8348360	when you look at the big picture of life on Earth would you be happy with and how much
8348360	8353240	worry you with AGI, whether it kills humans or not?
8353240	8357000	There is no single answer to this. It's really a question that depends on the
8357000	8362200	perspective that I'm taking at a given moment. And so there are perspectives that are
8364120	8369720	determining most of my life as a human being. And there are other perspectives where I zoom out
8370280	8375400	further and imagine that when the Great Oxygenation event happened, that is,
8375400	8381160	photosynthesis was invented and plants emerged and displaced a lot of the fungi and algae
8381160	8385960	in favor of plant life and then later made animals possible. Imagine that the fungi would
8385960	8389960	have gotten together and said, oh my god, this photosynthesis stuff is really, really bad.
8389960	8394920	It's going to possibly displace and kill a lot of fungi. We should slow it down and regulate it
8394920	8399400	and make sure that it doesn't happen. This doesn't look good to me.
8401400	8404760	Perspective. That said, you tweeted about a cliff.
8406120	8410920	Beautifully written. As a sentient species, humanity is a beautiful, child,
8410920	8415880	joyful, explorative, wild, sad, and desperate. But humanity has no concept of submitting to
8415880	8421720	reason and duty to life and future survival. We will run until we step past the cliff.
8422600	8425960	So first of all, do you think that's true?
8426600	8430680	Yeah, I think that's pretty much the story of the Club of Rome, the limits to growth.
8431320	8437960	And the cliff that we are stepping over is at least one foot as the delayed feedback. Basically,
8437960	8445640	we do things that have consequences that can be felt generations later and the severity increases
8446440	8452760	even after we stop doing the thing. I suspect that for the climate, the original predictions
8453480	8459640	that the climate scientists made were correct. So when they said that the tipping points were
8459640	8466120	in the late 80s, they were probably in the late 80s. And if we would stop emission right now,
8466120	8471960	we would not turn it back. Maybe there are ways for carbon capture. But so far, there is no
8471960	8476760	sustainable carbon capture technology that we can deploy. Maybe there is a way to put
8476760	8481720	results in the atmosphere to cool it down. It's the possibilities, right? But right now,
8481720	8489320	per default, it seems that we will step into a situation where we feel that we've run too far.
8489880	8494280	And going back is not something that we can do smoothly and gradually, but it's going to
8494920	8496760	lead to a catastrophic event.
8497720	8504600	A catastrophic event of one kind. So can you see them in the case that we will continue dancing
8504600	8509160	along and always stop just short of the edge of the cliff?
8509160	8515160	I think it's possible, but it doesn't seem to be likely. So I think this model that is
8515160	8520920	being apparent in the simulation that we're making of climate pollution economies and so on is
8520920	8528040	that many effects are only visible with a significant delay. And in that time, the system
8528040	8533560	is moving much more out of the equilibrium state or of the state where homeostasis is still possible,
8533560	8538440	and instead moves into a different state, one that is going to harbor fewer people.
8540200	8544040	And that is basically the concern there. And again, it's a possibility. It's just
8544040	8549400	and it's a possibility that is larger than the possibility that it's not happening,
8549400	8552520	that we will be safe, that we will be able to dance back all the time.
8553240	8558120	So the climate is one thing, but there's a lot of other threats that might have a faster feedback
8558120	8564760	mechanism, less delay. There is also a thing that AI is probably going to happen, and it's going to
8564760	8571160	make everything uncertain again, because it is going to affect so many variables that it's
8571160	8576120	very hard for us to make a projection into the future anymore. And maybe that's a good thing.
8576200	8582520	It does not give us the freedom, I think, to say now we don't need to care about anything
8582520	8589240	anymore, because AI will either kill us or save us. But I suspect that if humanity continues,
8589240	8595240	it will be due to AI. What's the timeline for things to get real weird with AI?
8595880	8600280	And it can get weird in interesting ways before you get to AGI. What about AI girlfriends and
8600280	8606120	boyfriends? Fundamentally transforming human relationships? I think human relationships
8606120	8611400	are already fundamentally transformed and it's already very weird. By which technology? For
8611400	8618680	instance, social media. Yeah. Is it though? Isn't the fundamentals of the core group of humans that
8618680	8625560	affect your life still the same? Your loved ones, family? No, I think that, for instance, many people
8625560	8630040	live in intentional communities right now. They're moving around until they find people
8630040	8634840	that they can relate to and they become their family. And often that doesn't work, because it
8634840	8640440	turns out that instead of having grown networks where you get around with the people that you
8640440	8645480	grew up with, you have more transactional relationships. You shop around, you have markets
8646040	8651480	for attention and pleasure and relationships. That kills the magic somehow. Why is that?
8652120	8659880	Why is the transactional search for optimizing allocation of attention somehow misses the
8659880	8664120	the romantic magic of what human relations are? It's all the question how magical was it before.
8664120	8668920	Was it that you just could rely on instincts that used your intuitions and you didn't need to
8668920	8674680	rationally reflect? But once you understand, it's no longer magical because you actually understand
8675400	8679560	why you were attracted to this person at this age and not to that person at this age and what the
8679640	8684280	actual considerations were that went on in your mind and what the calculations were,
8684280	8688120	what's the likelihood that you're going to have a sustainable relationship with this person,
8688120	8692280	that this person is not going to leave you for somebody else, how are your life trajectories
8692280	8697560	are going to evolve and so on. And when you're young, you're unable to ex-locate all this and you
8697560	8702520	have to rely on intuitions and instincts that in part you were born with and also on the
8702520	8707800	wisdom of your environment that is going to give you some kind of reflection on your choices.
8707880	8713000	And many of these things are disappearing now because we feel that our parents might have no
8713000	8717400	idea about how we are living and the environments that we grow up in, the cultures that we grow up
8717400	8723720	in, the milieus that our parents existed in might have no ability to teach us how to deal with this
8723720	8729560	new world. And for many people that's actually true, but it doesn't mean that within one generation
8729560	8733240	we build something that is more magical and more sustainable and more beautiful.
8733240	8740280	Instead, we often end up with an attempt to produce something that looks beautiful. I was
8740280	8747560	very vetted out by the aesthetics of the Vision Pro, that's that by Apple. And not so much because
8747560	8752040	I don't like the technology, I'm very curious about what it's going to be like and don't have
8752040	8758040	no opinion yet. But the aesthetics of the presentation and so on, they're so uncanny
8758040	8765720	valley-esque to me, the characters being extremely plastic, living in some hypothetical
8767960	8776920	mid-century furniture museum. This is the proliferation of marketing teams.
8776920	8782600	Yes, but it was a CGI-generated world. And was a CGI-generated world that doesn't exist. And
8782600	8785880	when I complained about this, some friends came back to me and said,
8785880	8791400	but these are startup founders. This is what they live like in Silicon Valley. And I try to
8791400	8795480	tell them, no, I know lots of people in Silicon Valley. This is not what people are like. They're
8795480	8804520	still people. They're still human beings. So the grounding in physical reality somehow
8804520	8809960	is important too? In culture. And so basically what's absent in this thing is culture. There is
8809960	8817080	a simulation of culture, an attempt to replace culture by catalogue, by some kind of aesthetic
8817080	8822680	optimization that is not the result of having a sustainable life, a sustainable human relationships
8822680	8831080	with houses that work for you and a mode of living that works for you in which these glasses fit in
8831080	8835320	naturally. And I guess that's also why so many people have read it out about the product because
8835320	8839800	they don't know how is this actually going to fit into my life and into my human relationships.
8839800	8844440	Because the way in which it was presented in these videos didn't seem to be credible.
8845560	8852360	Do you think AI, when it's deployed by companies like Microsoft and Google and Meta,
8852360	8859880	will have the same issue of being weirdly corporate? There'll be some uncanny valley,
8859880	8864200	some weirdness to the whole presentation. So this is, I've got a chance to talk to George
8864200	8867560	Haatz, he believes everything should be open source and decentralized and there,
8868200	8875400	then we shall have the AI of the people. And it'll maintain a grounding to the magic that's
8877560	8882280	humanity, that's the human condition that corporations will destroy the magic.
8883720	8889400	I believe that if we make everything open source and make this mandatory, we are going to lose
8889400	8895400	about a lot of beautiful art and a lot of beautiful designs. There is a reason why
8896040	8904920	Linux desktop is still ugly. And it's difficult to create coherence in open source designs
8904920	8911640	so far when the designs have to get very large and it's easier to make this happening in a company
8911640	8918680	with centralized organization. And from my own perspective, what we should ensure is that open
8918680	8925080	source never dies, that it can always compete and has a place with the other forms of organization,
8925080	8929560	because I think it is absolutely vital that open source exists and that we have systems
8929560	8935880	that people have under control outside of the corporation. And that is also producing viable
8935880	8941320	competition to the corporations. So the corporations, the centralized control, the
8941320	8949400	dictatorships of corporations can create beauty because centralized design is a source of a lot
8949400	8957880	of beauty. And then I guess open source is a source of freedom, a hedge against the corrupting nature
8957880	8964520	of power that comes with centralized. I grew up in socialism and I learned that corporations
8964520	8968600	are totally evil and I found this very, very convincing. And then you look at corporations
8968600	8974360	like Enron and Halliburton maybe and realize, yeah, they are evil. But you also notice that many
8974360	8979800	other corporations are not evil. They're surprisingly benevolent. Why are they so benevolent? Is
8979800	8984840	this because everybody is fighting them all the time? I don't think that's the only explanation.
8984840	8989240	It's because they're actually animals that live in a large ecosystem and that are still
8989240	8994520	largely controlled by people that want that ecosystem to flourish and be viable for people.
8994520	9001000	So I think that Pat Gelsinger is completely sincere when he leads Intel to be a tool that
9001720	9007080	supplies the free world with semiconductors. And it's not necessary that all the semiconductors
9007080	9011480	are coming from Intel. It just, Intel needs to be there to make sure that we always have them.
9012760	9016760	So there can be many ways in which we can import and trade semiconductors from
9016760	9020840	other companies in places. We just need to make sure that nobody can cut us off from it because
9020840	9027160	that would be a disaster for this kind of society and world. And so there are many things that need
9027160	9034280	to be done to make our style of life possible. And then with this, I don't mean just capitalism
9034280	9039880	and environmental destruction, consumerism and creature comforts. I mean an idea of life in
9039880	9046600	which we are determined not by some kind of king or dictator, but in which individuals can determine
9046680	9051400	themselves to the largest possible degree. And to me this is something that this western world
9051400	9056360	is still trying to embody. And it's a very valuable idea that we shouldn't give up too early.
9057000	9064200	And from this perspective, the US is a system of interleaving clubs. And an entrepreneur is a
9064200	9070200	special club founder. It's somebody who makes a club that is producing things that are economically
9070200	9075400	viable. And to do this, it requires a lot of people who are dedicating a significant part of their life
9076120	9080680	for working for this particular kind of club. And the entrepreneur is picking the initial set
9080680	9086040	of rules and the mission and vision and aesthetics for the club and make sure that it works. But
9086040	9090680	the people that are in there need to be protected. If they sacrifice part of their life, they need
9090680	9096440	to be rules that tell how they're being taken care of even after they leave the club and so on. So
9096440	9102200	there's a large body of rules that have been created by our rule giving clubs and that are
9102920	9107320	by our enforcement clubs and so on. And some of these clubs have to be monopolies for game
9107320	9111880	theoretic reasons, which also makes them more open to corruption and less harder to update.
9112760	9117560	And this is an ongoing discussion and process that takes place. But the beauty of this idea that
9117560	9123560	there is no centralized king who is that is extracting from the peasants and breeding the
9123560	9130440	peasants into serving the king and fulfilling all the roles like Anson and Antel. But that
9130440	9135400	there is a freedom of association and corporations are one of them. It's something that took me
9135400	9141400	some time to realize. So I do think that corporations are dangerous. They need to be
9141400	9147880	protections against overreach of corporations that can do regular recapture and prevent
9147880	9153640	open source from competing with corporations by imposing rules that make it impossible for
9154680	9158440	a small group of kids to come together to build their own language model because
9158520	9163560	open AI has convinced the US that you need to have some kind of FDA process that you need
9163560	9167560	to go through that costs many million dollars before you are able to train a language model.
9168600	9173400	This is important to make sure that this doesn't happen. So I think that open AI and Google are
9173400	9179560	good things. If these good things are kept in check in such a way that all the other clubs can
9179560	9184280	still be founded and all the other forms of clubs that are desirable can still coexist with them.
9184280	9189960	So what do you think about meta in contrast to that open sourcing most of its
9191480	9195640	language models and most of the AI models it's working on and actually suggesting that they
9195640	9201400	will continue to do so in the future for future versions of Lama for example their large language
9201400	9209880	model. Is that exciting to you? Is that concerning? I don't find it very concerning but that's
9209880	9219560	also because I think that the language models are not very dangerous yet. As I said, I have no
9219560	9227160	proof that there is the boundary between the language models and AI. It's possible that somebody
9227160	9233800	builds a version of baby AGI I think and stores in the algorithmic improvements that scale these
9233800	9238360	systems up in ways that otherwise wouldn't have happened without these language model components.
9238360	9244280	So it's not really clear for me what the end game is there and if these models can
9244280	9251320	bootforce their way into AGI. And there's also a possibility that the AGI that we are building
9251320	9256280	with these language models are not taking responsibility for what they are because they
9256280	9263160	don't understand the greater game. And so to me it would be interesting to try to understand how to
9263160	9268120	build systems that understand what the greater games are, what are the longest games that we
9268120	9275480	can play on this planet. Games broadly like deeply define the way you did with the games.
9275480	9279080	In the game theoretic sense. So when we are interacting with each other in some sense we
9279080	9282920	are playing games. We are making lots and lots of interactions. This doesn't mean that these
9282920	9288200	interactions have all to be transactional. Every one of us is playing some kind of game by
9289160	9293240	virtue of identifying this particular kinds of goals that we have or aesthetics
9293240	9299560	from which we derive the goals. So when you say, I'm Lex Friedman, I'm doing a set of podcasts,
9300200	9304520	then you feel that it's part of something larger that you want to build. Maybe you want to inspire
9304520	9309400	people. Maybe you want them to see more possibilities and get them together over shared ideas.
9310280	9313880	Maybe your game is that you want to become super rich and famous by being the best post
9314440	9317960	caster on earth. Maybe you have other games. Maybe it's pitches from time to time.
9318760	9322360	But there is a certain perspective where you might be thinking what is the longest possible
9322360	9327000	game that you could be playing. A short game is for instance cancer is playing a shorter game
9327000	9332920	than your organism. Cancer is an organism playing a shorter game than the regular organism. Because
9332920	9339480	the cancer cannot procreate beyond the organism except for some infectious cancers like the ones
9339480	9346680	that eradicated the Tasmanian devils. You typically end up with a situation where the organism dies
9346680	9351240	together with the cancer because the cancer has destroyed the larger system due to playing a
9351240	9359160	shorter game. Ideally, you want to build agents that play the longest possible games. The longest
9359160	9365000	possible games is to keep entropy at bay as long as possible while doing interesting stuff.
9365000	9370920	But the longest, yes, that part, the longest possible game while doing interesting stuff
9370920	9375800	and while maintaining at least the same amount of interesting complexities of propagating.
9376120	9383080	Currently, I'm pretty much identified as a conscious being. It's the minimal identification
9383080	9388760	that I manage to get together. Because if I turn this off, I fall asleep. And when I'm asleep,
9388760	9394520	I'm a vegetable. I'm no longer here as an agent. So my agency is basically predicated on being
9394520	9401080	conscious. And what I care about is other conscious agents. They're the only moral agents for me.
9401960	9411320	And so if an AI were to treat me as a moral agent, that it is interested in coexisting with
9411320	9417080	and cooperating with and mutually supporting each other, maybe it is, I think, necessary that the AI
9417080	9422440	thinks that consciousness is a viable mode of existence and important. So I think it would
9422440	9429400	be very important to build conscious AI and do this as the primary goal. So not just say we want
9429400	9433880	to build a useful tool that we can use for all sorts of things. And then you have to make sure
9433880	9439160	that the impact on the labor market is something that is not too disruptive and manageable. And
9439160	9444600	the impact on the copyright holder is manageable and not too disruptive and so on. I don't think
9444600	9450840	that's the most important game to be played. I think that we will see extremely large disruptions
9450840	9457960	of this status quo that are quite unpredictable at this point. And I just personally want to
9457960	9461960	make sure that some of the stuff on the other side is interesting and conscious.
9461960	9469320	How do we ride as individuals and as a society this disruptive wave that changes the nature
9469320	9473400	of the game? Absolutely don't know. So everybody is going to do their best as always.
9473400	9480760	Do we build the bunker in the woods? Do we meditate more? Drugs, so mushrooms, psychedelics, I mean
9480760	9488120	what? Lots of sex. What are we talking about here? Do you play Diablo IV? I'm hoping that
9488120	9494200	will help me escape for a brief moment. What? Play video games? What? Do you have ideas?
9496200	9502760	I really like playing Disco Elysium. This was one of the most beautiful computer games I played
9502760	9509880	in recent years. And it's a noir novel that is a philosophical perspective on Western society
9509880	9515880	from the perspective of an Estonian. And he first of all wrote a book about this
9517160	9523800	world that is a parallel universe that is quite poetic and fascinating and is condensing
9524440	9530040	his perspective on our societies. It was very, very nice. He spent a lot of time writing it.
9530040	9534840	He had, I think, sold a couple thousand books and as a result became an alcoholic.
9534840	9539480	And then he had the idea or one of his friends had the idea of turning this into an RPG.
9540280	9546440	And it's mind-blowing. They spent the illustrator more than a year just on making
9547080	9554920	the art for the scenes in between. So aesthetically it captures you. It's stunning.
9554920	9558760	But it's a philosophical work of art. It's a reflection of society. It's fascinating to
9558760	9566360	spend time in this world. And so for me it was using a medium in a new way and telling a story
9566360	9574680	that left me enriched. When I tried Diablo, I didn't feel enriched playing it. I felt that
9574680	9579480	the time playing it was not unpleasant, but there's also more pleasant stuff that I can do in that
9579480	9585240	time. So ultimately I feel that I'm being gamed. I'm not gaming. Oh, the addiction thing. Yes.
9585240	9590040	I basically feel that there is a very transparent economy that's going on. The story of Diablo
9590040	9597080	was branded. So it's not really interesting to me. My heart is slowly breaking by the deep truth
9597080	9605480	you're conveying to me. Why can't you just allow me to enjoy my personal addiction? I have no
9605480	9613560	objection here. I'm just trying to describe what's happening and it's not that I don't do things
9613560	9618280	for a later say, oh, I wish I would have done something different. I also know that when we
9618280	9622680	die, the greatest regret that people typically have on that desk but they say, oh, I wish I had
9622680	9628280	spent more time on Twitter. No, I don't think that's the case. I think I should probably have
9628280	9634520	spent less time on Twitter. But I found it so useful for myself and also so addictive that I
9634520	9639080	felt I need to make the best of it and turn it into an art form and thought form. And it did
9639080	9644680	help me to develop something. But I wish for other things I could have done in the meantime. It's
9644680	9648360	just not the universe that we're in anymore. Most people don't read books anymore.
9651720	9656520	What do you think that means that we don't read books anymore? What do you think that means about
9656520	9661080	the collective intelligence of our species? Is it possible it's still progressing and growing?
9661080	9665240	Well, it clearly is. There is stuff happening on Twitter that was impossible with books.
9665960	9671640	And I really regret that Twitter has not taken the turn that I was hoping for. I thought Elon is
9671640	9676760	global brain pilled and understands that this thing needs to self-organize and he needs to
9676760	9682760	develop tools to allow the profligation of the self-organization so Twitter can become sentient.
9683480	9689480	And maybe this was a pipe dream from the beginning. But I felt that the enormous pressure that he
9689480	9696280	was under made it impossible for him to work on any kind of content goals. And also many of the
9696280	9701720	decisions that he made under this pressure seem to be not very wise. I don't think that
9701720	9706040	as a CEO of a social media company, you should have opinions in the culture bar in public.
9706760	9713000	I think that's very short-sighted. And I also suspect that it's not a good idea to
9716600	9724120	block Paul Graham of all people over setting a must-do-don link. And I think Paul made this
9724120	9729320	intentionally because he wanted to show Elon Musk that blocking people for setting a link
9729320	9734280	is completely counter to any idea of free speech that he intended to bring to Twitter.
9734280	9739800	And basically, seeing that Elon was very less principled in his thinking there and
9740520	9747480	is much more experimental. And many of the things that he is trying, they pan out very
9747480	9752600	differently in a digital society than they pan out in a car company because the effect is very
9752600	9756680	different because everything that you do in a digital society is going to have real-world cultural
9756680	9764600	effects. And so basically, I find it quite regrettable that this guy is able to become
9764600	9768680	de facto the Pope where Twitter has more active members than the Catholic Church.
9769320	9775240	And he doesn't get it. The power and responsibility that he has and the ability
9775240	9779960	to create something in this society that is lasting and that is producing a digital
9780040	9785080	agora in a way that has never existed before, where we built a social network on top of a social
9785080	9791480	network, an actual society on top of the algorithms. So this is something that is hoped
9791480	9797240	still in the future and still in the cards. But it's something that exists in small parts.
9797240	9801400	I find that the corner of Twitter that I'm in is extremely pleasant. Just when I take a few
9801400	9805640	steps outside of it, it is not very wholesome anymore. And the way in which people interact
9805640	9808840	with strangers suggests that it's not a civilized society yet.
9809880	9813960	So as the number of people who follow you on Twitter expands,
9814840	9819960	you feel the burden of the uglier sides of humanity.
9819960	9826600	Yes, but there's also a similar thing in the normal world that is if you become more influential,
9826600	9832680	if you have more status, if you have more fame in the real world, you get lots of perks,
9832680	9837320	but you also have way less freedom in the way in which you interact with people,
9837320	9845480	especially the strangers, because a certain percentage of people, a single-digit percentage
9845480	9852600	is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas.
9853240	9858600	But what if the technology enables you to discover the majority of people,
9858600	9863160	to discover and connect efficiently and regularly with the majority of people who are
9863160	9871000	actually really good? One of my concerns with the platform, my Twitter, is there's a lot of
9871000	9874600	really smart people out there, a lot of smart people that disagree with me and with others
9874600	9880120	between each other. And I love that if the technology would bring those to the top,
9880840	9886280	the beautiful disagreements, like intelligent squared type of debates. There's a bunch of,
9886840	9891160	I mean, one of my favorite things to listen to is arguments, and arguments like high-effort
9891160	9895560	arguments with respect and love underneath it, but then it gets a little too heated,
9895560	9900120	but that kind of too heated, which I've seen you participate in, and I love that,
9900920	9906520	with Lee Kroner with those kinds of folks. And you go pretty hard, like you get frustrated,
9906520	9913400	but it's all beautiful. Obviously, I can do this because we know each other. And Lee has the rare
9913400	9918120	gift of being willing to be wrong in public. So basically he has thoughts that are as wrong as
9918120	9923160	the random thoughts of an average highly intelligent person, but he blurs them out,
9923160	9928680	while not being sure if they're right. And he enjoys doing that. And once you understand that
9928680	9933800	this is his game, you don't get offended by him saying something that you think is so wrong.
9933800	9940040	But he's constantly, passively communicating a respect for the people he's talking with,
9940040	9944520	and for just basic humanity and truth and all that kind of stuff. And there's a self-deprecating
9944520	9951240	thing. There's a bunch of social skills you acquire that allow you to be a great debater,
9951240	9957480	a great argumenter, be wrong in public, and explore ideas together in public when you disagree.
9957480	9963640	And if I would love for Twitter to elevate those folks, elevate those kinds of conversations.
9963640	9969640	It already does, in some sense. But also if it elevates them too much, then you get this
9969640	9976840	phenomenal clubhouse where you always get dragged on stage. And I found this very stressful because
9976840	9982040	it was too intense. I don't like to be dragged on stage all the time. I think once a week is enough.
9982600	9989080	And also when I met Lee the first time, I found that a lot of people seem to be shocked by the
9989080	9995800	fact that he was being very aggressive with their results, that he didn't seem to show a lot of
9995800	10000600	sensibility in the way in which he was criticizing what they were doing and being dismissive of the
10000600	10006120	work of others. And that was not, I think, in any way a shortcoming of him because I noticed
10006120	10010920	that he was much, much more dismissive with respect to his own work. It was his general
10010920	10015880	stance. And I felt that this general stance is creating a lot of liability for him because
10015880	10022360	really a lot of people take offense at him being not like their carnage character who is always
10022360	10027720	smooth and make sure that everybody likes him. So I really respect that he is willing to take
10027720	10034360	that risk and to be wrong in public and to offend people. And he doesn't do this in any bad way.
10034360	10040440	It's just most people feel or not all people recognize this. And so I can be much more aggressive
10040440	10045720	with him than I can be with many other people who don't play the same game because he understands
10045720	10050680	the way in the spirit in which I respond to him. I think that's a fun and that's a beautiful game.
10050680	10056360	It's ultimately a productive one. Speaking of taking that risk, you tweeted,
10057080	10061960	when you have the choice between being a creator, consumer or redistributor,
10061960	10068440	always go for creation. Not only does it lead to a more beautiful world, but also to a much
10068440	10073000	more satisfying life for yourself. And don't get stuck preparing yourself for the journey.
10073000	10079880	The time is always now. So let me ask for advice. What advice would you give on how to become such
10079880	10088600	a creator on Twitter in your own life? I was very lucky to be alive at the time of the collapse
10088600	10094520	of Eastern Germany and the transition into Western Germany. And me and my friends and most of the
10094520	10100680	people I knew were East Germans and we were very poor because we didn't have money. And all the
10100680	10105320	capital was in Western Germany and they bought our factories and shut them down because they were
10105320	10111560	mostly only interested in the market rather than creating new production capacity. And so
10112520	10119320	cities were poor and in disrepair and we could not afford things. And I could not afford to
10119320	10125960	go into a restaurant and order a meal there. I would have to cook at home. But I also thought,
10125960	10131000	why not just have a restaurant with my friends? So we would open up a cafe with friends and a
10131000	10135480	restaurant and we would cook for each other in these restaurants and also invite the general
10135480	10140760	public and they could donate. And eventually this became so big that we could turn this into
10141880	10146440	some incorporated form and it became a regular restaurant at some point. Or we did the same
10146440	10153640	thing with the movie theater. We would not be able to afford to pay 12 marks to watch a movie.
10153640	10159320	But why not just create our own movie theater and then invite people to pay and we would rent
10159320	10165880	the movies in a way in which a movie theater does. But it would be a community movie theater
10165880	10171080	in which everybody who wants to help can watch for free and builds this thing and renovates the
10171080	10177320	building. And so we ended up creating lots and lots of infrastructure. And I think when you are
10177320	10181880	young and you don't have money, move to a place where this is still happening. Move to one of
10181880	10186360	those places that are undeveloped and where you get a critical mass of other people who are starting
10186360	10190760	to build infrastructure to live in. And that's super satisfying because you're not just creating
10190760	10196120	infrastructure, but you're creating a small society that is building culture and ways to
10196120	10201080	interact with each other. And that's much, much more satisfying than going into some kind of
10201080	10208360	chain and get your needs met by ordering food from this chain and so on. So not just consuming
10208360	10213400	culture, but creating culture. And you don't always have that choice. That's why I prefaced it
10213400	10217400	when you do have the choice and there are many roles that need to be played. We need people who
10217400	10221880	take care of our distribution in society and so on. But when you have the choice to create
10221880	10227240	something, always go for creation. It's so much more satisfying. And it also is, this is what life
10227240	10235560	is about, I think. Yeah. Speaking of which, you retweeted this meme of a life of a philosopher
10235640	10242520	in a nutshell. It's birth and death and in between, it's a chubby guy and says, why though?
10246440	10251880	What do you think is the answer to that? Well, the answer is that everything that
10251880	10258280	can exist might exist. And in many ways, you take it an ecological perspective,
10258280	10263400	the same way as when you look at human opinions and cultures. It's not that there is right and
10263400	10268840	wrong opinions when you look at this from this ecological perspective. But every opinion that
10268840	10275480	fits between two human ears might be between two human ears. And so when I see a strange opinion
10275480	10280920	on social media, it's not that I feel that I have a need to get upset. It's often more that I, oh,
10280920	10287400	there you are. And when an opinion is incentivized, then it's going to be abundant. And when you take
10287400	10291480	this ecological perspective also on yourself and you realize you're just one of these mushrooms
10291480	10297000	that are popping up and doing this thing. And you can, depending on where you chose to grow and
10297000	10302440	where you happen to grow, you can flourish or not doing this or that strategy. And it's still all
10302440	10306280	the same life at some level. It's all the same experience of being a conscious being in the
10306280	10312360	world. And you do have some choice about who you want to be more than any other animal has.
10312920	10318920	That to me is fascinating. And so I think that rather than asking yourself, what is the one way
10319000	10324520	to be, think about what are the possibilities that I have, what it would be the most interesting
10324520	10328440	way to be that I can be. Because everything is possible. So you get to explore this.
10328440	10334200	Not everything is possible. But if things fail, most things fail. But often there are possibilities
10334200	10342520	that we are not seeing, especially if we choose who we are. To the degree we can choose.
10343400	10352680	Yasha, you're one of my favorite humans in this world. Consciousness is to merge with
10352680	10358120	for a brief moment of time. It's always an honor. It always blows my mind. It will take me
10358920	10367720	days if not weeks to recover. And I already miss our chats. Thank you so much. Thank you so much
10367720	10374440	for speaking with me so many times. Thank you so much for all the ideas you put out into the world.
10375000	10381000	And I'm a huge fan of following you now in this interesting, weird time we're going through with
10381000	10387080	AI. So thank you again for talking today. Thank you Lex for this conversation. I enjoyed it very much.
10388120	10391800	Thanks for listening to this conversation with Yasha Bach. To support this podcast,
10391800	10397080	please check out our sponsors in the description. And now let me leave you with some words from
10397160	10403320	the psychologist Carl Jung. One does not become enlightened by imagining figures of light,
10403960	10411320	but by making the darkness conscious. The latter procedure, however, is disagreeable and therefore
10411320	10419720	not popular. Thank you for listening and hope to see you next time.
