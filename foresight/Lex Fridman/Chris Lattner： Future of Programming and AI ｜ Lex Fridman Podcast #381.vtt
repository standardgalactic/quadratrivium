WEBVTT

00:00.000 --> 00:04.080
On one axis, you have more hardware coming in. On the other hand, you have an explosion of

00:04.080 --> 00:08.800
innovation in AI. And so what happened with both TensorFlow and PyTorch is that the explosion

00:08.800 --> 00:13.680
of innovation in AI has led to, it's not just about matrix multiplication and convolution,

00:13.680 --> 00:18.160
these things have now like 2,000 different operators. And on the other hand, you have,

00:18.160 --> 00:21.120
I don't know how many pieces of hardware there are out there, it's a lot.

00:21.120 --> 00:25.600
Part of my thesis, part of my belief of where computing goes, if you look at 10 years from now,

00:26.160 --> 00:30.160
is it's not going to get simpler. Physics isn't going back to where we came from.

00:30.720 --> 00:35.920
It's only going to get weirder from here on out. And so to me, the exciting part about what we're

00:35.920 --> 00:42.320
building is it's about building that universal platform, which the world can continue to get

00:42.320 --> 00:47.600
weird, because again, I don't think it's avoidable, it's physics. But we can help lift people scale,

00:47.600 --> 00:50.480
do things with it, and they don't have to rewrite their code every time a new device comes out.

00:51.040 --> 00:52.160
And I think that's pretty cool.

00:52.320 --> 00:59.440
The following is a conversation with Chris Latner, his third time on this podcast.

00:59.440 --> 01:04.720
As I've said many times before, he's one of the most brilliant engineers in modern computing,

01:04.720 --> 01:10.160
having created LLM Compiler Infrastructure Project, the Klang Compiler, the Swift programming

01:10.160 --> 01:14.720
language, a lot of key contributions to TensorFlow and TPUs as part of Google.

01:14.720 --> 01:20.800
He served as vice president of autopilot software at Tesla, was a software innovator

01:20.800 --> 01:27.680
and leader at Apple, and now he co-created a new full stack AI infrastructure for distributed

01:27.680 --> 01:33.920
training, inference, and deployment on all kinds of hardware called Modular, and a new

01:33.920 --> 01:39.920
programming language called Mojo, that is a superset of Python, giving you all the usability of

01:39.920 --> 01:47.120
Python, but with the performance of C++. In many cases, Mojo code has demonstrated over

01:47.760 --> 01:54.480
30,000 x speed up over Python. If you love machine learning, if you love Python,

01:54.480 --> 02:00.160
you should definitely give Mojo a try. This programming language, this new AI framework,

02:00.160 --> 02:06.400
and infrastructure, and this conversation with Chris is mind blowing. I love it.

02:07.280 --> 02:12.400
It gets pretty technical at times, so I hope you hang on for the ride. This is the Lex

02:12.400 --> 02:16.640
Friedman podcast. To support it, please check out our sponsors in the description,

02:16.640 --> 02:22.800
and now, dear friends, here's Chris Lattner. It's been, I think, two years since we last

02:22.800 --> 02:29.040
talked, and in that time, you somehow went and co-created a new programming language called Mojo.

02:29.840 --> 02:35.360
So it's optimized for AI. It's a superset of Python. Let's look at the big picture. What is

02:35.360 --> 02:42.000
the vision for Mojo? For Mojo? Well, I think you have to zoom out. So I've been working on a lot

02:42.000 --> 02:46.800
of related technologies for many, many years. So I've worked on LVM, and a lot of things, and

02:46.800 --> 02:52.160
mobile, and servers, and things like this. But the world's changing. And what's happened with

02:52.160 --> 02:57.920
AI is we have new GPUs, and new machine learning accelerators, and other ASICs, and things like

02:57.920 --> 03:03.280
that that make AI go real fast. At Google, I worked on TPUs. That's one of the biggest,

03:03.280 --> 03:09.280
largest scale deployed systems that exist for AI. And really what you see is if you look across

03:09.280 --> 03:12.000
all of the things that are happening in the industry, there's this new compute platform

03:12.000 --> 03:18.880
coming. And it's not just about CPUs, or GPUs, or TPUs, or NPUs, or IPUs, or whatever,

03:18.880 --> 03:25.920
all the PUs. It's about how do we program these things. And so for software folks like us,

03:26.960 --> 03:30.240
it doesn't do us any good if there's this amazing hardware that we can't use.

03:31.040 --> 03:35.760
And one of the things you find out really quick is that having the theoretical capability of

03:35.760 --> 03:41.040
programming something, and then having the world's power and the innovation of all the

03:41.040 --> 03:45.680
smart people in the world get unleashed on something can be quite different. And so really

03:45.680 --> 03:50.880
where Mojo came from was starting from a problem of we need to be able to take machine learning,

03:50.880 --> 03:54.720
take the infrastructure underneath it, and make it way more accessible, way more usable,

03:54.720 --> 03:59.520
way more understandable by normal people and researchers and other folks that are not

03:59.520 --> 04:04.240
themselves like experts in GPUs and things like this. And then through that journey,

04:04.240 --> 04:06.880
we realize, hey, we need syntax for this, we need to do a program language.

04:07.440 --> 04:14.480
So one of the main features of the language, I say so fully in jest, is that it allows you to have

04:14.480 --> 04:25.280
the file extension to be an emoji, or the fire emoji, which is one of the first emojis used

04:25.280 --> 04:29.680
as a file extension I've ever seen in my life. And then you ask yourself the question, why in

04:29.680 --> 04:36.400
the 21st century, are we not using Unicode for file extensions? This I mean, it's an epic decision.

04:36.400 --> 04:41.040
I think clearly the most important decision you made the most, but you could also just use Mojo

04:41.040 --> 04:44.800
as the file extension. Well, so okay, so take a step back. I mean, come on, Lex, do you think that

04:44.800 --> 04:48.720
the world's ready for this? This is a big moment in the world, right? This is we're releasing this

04:48.720 --> 04:55.200
onto the world. This is innovation. I mean, it really is kind of brilliant. Emojis are such a

04:55.200 --> 05:01.600
big part of our daily lives. Why isn't it not in programming? Well, and like you take a step back

05:01.600 --> 05:06.880
and look at what file extensions are, right? They're basically metadata, right? And so why are

05:06.880 --> 05:11.120
we spending all the screen space on them and all this stuff? Also, you know, you have them stacked

05:11.120 --> 05:15.120
up next to text files and PDF files and whatever else, like, if you're gonna do something cool,

05:15.120 --> 05:19.840
you want to stand out, right? Emojis are colorful, they're visual, they're beautiful, right?

05:19.840 --> 05:25.360
What's been the response so far from, is there support on like Windows on operating systems

05:25.360 --> 05:30.160
in displaying like File Explorer? Yeah, the one problem I've seen is that Git doesn't escape it

05:30.160 --> 05:34.560
right? And so it thinks that the Fire Emoji is unprintable. And so it like prints out weird

05:34.560 --> 05:39.120
hex things if you use the command line Git tool. But everything else as far as I'm aware works

05:39.120 --> 05:45.600
fine. And I have faith that Git can be improved. So GitHub is fine. GitHub is fine. Yep. GitHub is

05:45.600 --> 05:50.160
fine. Visual Studio Code, Windows, like all this stuff totally ready, because people have

05:50.160 --> 05:55.520
internationalization in their normal part of their paths. So this is just like taking the next step,

05:55.520 --> 06:02.480
right? Somewhere between, oh, wow, that makes sense. Cool. I like new things too. Oh my god,

06:02.480 --> 06:06.160
you're killing my baby. Like, what are you talking about? This can never be like, I can never hand

06:06.160 --> 06:11.120
it and list how am I going to type this like all these things. And so this is something where I

06:11.120 --> 06:14.880
think that the world will get there. We don't have to bet the whole farm on this. I think we can

06:15.440 --> 06:21.440
provide both paths. But I think it'll be great. When can we have emojis as part of the code? I

06:21.440 --> 06:26.400
wonder. Yeah, so I mean, lots of languages provide that. So I think that we have partial support

06:26.400 --> 06:30.800
for that. It's probably not fully done yet. But but yeah, you can you can do that. For example,

06:30.800 --> 06:37.280
in Swift, you can do that for sure. So an example we give gave it Apple was the dog cow. Yeah,

06:37.280 --> 06:41.520
so that's a classical Mac heritage thing. And so you use the dog and the cow emoji together.

06:41.520 --> 06:44.800
And that could be your variable name. But of course, the internet went and made

06:44.800 --> 06:49.200
pile of poop for everything. Yeah. So you know, if you want to name your function pile of poop,

06:49.200 --> 06:52.080
then you can totally go to town and see how that gets through code review.

06:54.240 --> 07:01.120
Okay, so let me just ask a bunch of random questions. So is Mojo primarily designed for

07:01.120 --> 07:06.880
AIs? Or is it a general purpose program? Good question. So it's AI first. And so AI is driving

07:06.960 --> 07:12.960
a lot of the requirements. And so modular is building and designing and driving Mojo forward.

07:12.960 --> 07:18.080
And it's not because it's an interesting project theoretically to build, it's because we need it.

07:19.200 --> 07:23.840
And so modular, we're really tackling the AI infrastructure landscape and the big problems

07:23.840 --> 07:29.280
in AI, and the reasons that it is so difficult to use and scale and adopt and deploy and like all

07:29.280 --> 07:34.800
these big problems in AI. And so we're coming out from that perspective. Now, when you do that,

07:34.800 --> 07:40.240
when you start tackling these problems, you realize that the solution to these problems

07:40.240 --> 07:44.640
isn't actually an AI specific solution. And so while we're doing this, we're building Mojo to

07:44.640 --> 07:51.040
be a fully general programming language. And that means that you can obviously tackle GPUs and CPUs

07:51.040 --> 07:56.160
and like these AI things, but it's also a really great way to build NumPy and other things like

07:56.160 --> 08:01.040
that or you know, just if you look at what many Python libraries are today, often they're a layer

08:01.040 --> 08:07.200
of Python for the API, and they end up being C and C++ code underneath them. That's very true in AI,

08:07.200 --> 08:10.480
that's true in lots of other demands as well. And so anytime you see this pattern,

08:10.480 --> 08:14.800
that's an opportunity for Mojo to help simplify the world and help people have one thing.

08:16.000 --> 08:22.240
To optimize through simplification, by having one thing. So you mentioned modular. Mojo is

08:22.240 --> 08:27.120
the programming language, modular is the whole software stack. So just over a year ago, we started

08:27.200 --> 08:32.400
this company called modular. What modular is about is it's about taking AI and up leveling it

08:32.960 --> 08:39.360
into the next generation. And so if you take a step back, what's gone on in the last five, six,

08:39.360 --> 08:44.240
seven, eight years is that we've had things like TensorFlow and PyTorch and these other systems

08:44.240 --> 08:49.520
come in, you've used them, you know this. And what's happened is these things have grown like crazy,

08:49.520 --> 08:54.400
and they get tons of users, it's in production deployment scenarios, it's being used to power

08:54.400 --> 09:00.240
so many systems. AI is all around us now. It used to be controversial years ago, but now it's a

09:00.240 --> 09:07.040
thing. But the challenge with these systems is that they haven't always been thought out with

09:07.040 --> 09:13.920
current demands in mind. So you think about it, where were LLMs eight years ago? Well, they didn't

09:13.920 --> 09:18.320
exist, right? AI has changed so much. And a lot of what people are doing today are very different

09:18.320 --> 09:22.720
than when these systems were built. And meanwhile, the hardware side of this has gotten into a huge

09:22.720 --> 09:27.200
mess. There's tons of new chips and accelerators and every big company's announcing a new chip every

09:27.200 --> 09:34.240
day it feels like. And so between that, you have like this moving system on one side, moving system

09:34.240 --> 09:37.920
on the other side, and it just turns into this gigantic mess, which makes it very difficult for

09:37.920 --> 09:42.800
people to actually use AI, particularly in production deployment scenarios. And it's what

09:42.800 --> 09:46.880
modular students were helping build out that software stack to help solve some of those problems.

09:46.880 --> 09:50.240
So then people can be more productive and get more AI research into production.

09:50.880 --> 09:55.840
Now, what Mojo does is it's a really, really, really important piece of that. And so that is,

09:56.400 --> 10:00.560
you know, part of that engine and part of the technology that allows us to solve these problems.

10:00.560 --> 10:06.960
So Mojo is a programming language that allows you to do a high level program and the low level

10:06.960 --> 10:12.880
programming, they do all kinds of programming in that spectrum that gets you closer and closer

10:12.880 --> 10:16.320
to the hardware. So take a step back. So Lex, what do you love about Python?

10:16.960 --> 10:23.600
Oh boy. Where do I begin? What is love? What do I love about Python?

10:23.600 --> 10:28.400
You're a guy who knows love. I know this. Yes. How intuitive it is.

10:30.960 --> 10:33.520
How it feels like I'm writing natural language, English.

10:36.320 --> 10:42.160
How when I can not just write but read other people's code somehow I can understand it faster.

10:42.160 --> 10:48.880
It's more condensed than other languages like ones I'm really familiar with like C++

10:49.520 --> 10:56.480
and C. There's a bunch of sexy little features. Yeah. We'll probably talk about some of them,

10:56.480 --> 11:02.560
but list comprehensions and stuff like this. Also, and don't forget the entire ecosystem

11:02.560 --> 11:06.160
of all the packages. Oh yeah, that's probably huge. Because there's always something. If you want to do

11:06.160 --> 11:12.160
anything, there's always a package. Yeah. So it's not just the ecosystem of the packages

11:12.160 --> 11:17.520
and the ecosystem of the humans that do it. That's a really, that's an interesting dynamic.

11:17.520 --> 11:24.000
That's good. Because I think something about the usability and the ecosystem makes the thing viral.

11:24.000 --> 11:28.480
It grows and then it's a virtuous cycle, I think. Well, there's many things that went into that.

11:28.480 --> 11:32.960
Like, so I think that ML was very good for Python. And so I think that TensorFlow and

11:33.040 --> 11:39.360
PyTorch and these systems embracing Python really took and helped Python grow. But I think that the

11:39.360 --> 11:44.640
major thing underlying it is that Python is like the universal connector. It really helps bring

11:44.640 --> 11:48.400
together lots of different systems so you can compose them and build out larger systems without

11:48.400 --> 11:53.920
having to understand how it works. But then what is the problem with Python? Well, I guess you

11:53.920 --> 11:58.560
could say several things, but probably that it's slow. I think that's usually what people complain

11:58.640 --> 12:04.800
about. And so other people complain about tabs in spaces versus curly braces or whatever. But

12:05.680 --> 12:09.760
those people are just wrong because it is actually just better to use an indentation.

12:11.200 --> 12:16.240
Wow, strong words. So actually, I'm a small tangent. Let's actually take that. Let's take

12:16.240 --> 12:19.200
all kinds of tangents. Oh, come on, Lex. You can push me on it. I could take it.

12:19.200 --> 12:26.720
Design. Listen, I've recently left Emacs for VS Code. The kind of hate mail I had to receive.

12:26.720 --> 12:32.960
Because on the way to doing that, I also said I've considered Vim and chose not to and went with

12:32.960 --> 12:39.280
VS Code. You're touching on deep religions, right? Anyway, tabs is an interesting design decision.

12:39.280 --> 12:45.680
And so you've really written a new programming language here. Yes, it is a superset of Python,

12:45.680 --> 12:49.840
but you can make a bunch of different interesting decisions here. Totally. And you chose actually

12:49.840 --> 12:57.040
to stick with Python in terms of some of the syntax. So let me explain why. So

12:58.480 --> 13:04.480
I mean, you can explain this in many rational ways. I think that the indentation is beautiful,

13:04.480 --> 13:08.800
but that's not a rational explanation. But I can defend it rationally. So first of all,

13:09.440 --> 13:15.200
Python 1 has millions of programmers. It's huge. It's everywhere. It owns machine learning. So

13:16.000 --> 13:21.840
factually, it is the thing, right? Second of all, if you look at it, C codes, C++ code, Java,

13:21.840 --> 13:27.920
whatever, Swift, curly brace languages also run through formatting tools and get indented.

13:29.040 --> 13:33.040
And so if they're not indented correctly, first of all, it will twist your brain around.

13:34.000 --> 13:38.720
It can lead to bugs. There's notorious bugs that have happened across time where the indentation

13:38.720 --> 13:43.440
was wrong or misleading and it wasn't formatted, right? And so it turned into an issue, right?

13:43.440 --> 13:48.320
And so what ends up happening in modern large-scale code bases is people run automatic formatters.

13:49.040 --> 13:54.000
So now what you end up with is indentation and curly braces. Well, if you're going to have

13:56.320 --> 14:01.360
the notion of grouping, why not have one thing, right? And get rid of all the clutter and have

14:01.360 --> 14:04.480
a more beautiful thing, right? Also, you look at many of these languages, it's like, okay, well,

14:04.480 --> 14:08.880
you can have curly braces or you can omit them if there's one statement or you just enter this

14:08.880 --> 14:13.840
entire world of complicated design space that objectively you don't need if you have Python

14:13.840 --> 14:18.320
style indentation. So yeah, I would love to actually see statistics on errors made because

14:18.320 --> 14:24.880
of indentation. Like how many errors are made in Python versus in C++ that have to do with basic

14:24.880 --> 14:28.880
formatting, all that kind of stuff. I would love to see. I think it's probably pretty minor because

14:28.880 --> 14:34.080
once you get like, you use VS code, I do too. So if you get VS code set up, it does the indentation

14:34.080 --> 14:37.920
for you generally. Right. And so you don't, you know, it's actually really nice to not have to

14:38.560 --> 14:43.680
fight it. And then what you can see is the editor is telling you how your code will work by indenting

14:43.680 --> 14:51.280
it, which I think is pretty cool. I honestly don't think I've ever, I don't remember having an error

14:51.280 --> 14:55.600
in Python because I indented stuff wrong. So I mean, I think that there's, again, this is a religious

14:55.600 --> 15:01.200
thing. And so I can joke about it. And I love, I love to kind of, you know, I realize that this is

15:01.200 --> 15:05.520
such a polarizing thing and everybody wants to argue about it. And so I like poking at the bear

15:05.520 --> 15:10.320
a little bit, right? But, but frankly, right, come back to the first point, Python one,

15:10.320 --> 15:15.120
like it's huge, it's an AI, it's the right thing. For us, like we see mojo as being an incredible

15:15.120 --> 15:20.320
part of the Python ecosystem, we're not looking to break Python or change it or quote unquote,

15:20.320 --> 15:25.200
fix it. We love Python for what it is. Our view is that Python is just not done yet.

15:26.240 --> 15:29.360
And so if you look at, you know, you mentioned Python being slow, well, there's a couple of

15:29.360 --> 15:32.960
different things that go into that, which we can talk about if you want. But one of them is it just

15:32.960 --> 15:38.480
doesn't have those features that you would use to do C like programming. And so if you say, okay,

15:38.480 --> 15:43.760
well, I'm forced out of Python into C for certain use cases. Well, then what we're doing is we're

15:43.760 --> 15:48.640
saying, okay, well, why, why is that? Can we just add those features that are missing from Python back

15:48.640 --> 15:52.880
up to mojo? And then you can have everything that's great about Python, all the things you're talking

15:52.880 --> 15:59.040
about the love, plus not be forced out of it when you do something a little bit more computationally

15:59.120 --> 16:02.320
intense or weird or hardwarey or whatever it is that you're doing.

16:02.880 --> 16:07.600
Well, a million questions. I want to ask what high level again, is it compiled or is it an

16:07.600 --> 16:12.240
interpretive language? So Python is just in time compilation. What's, what's mojo?

16:13.840 --> 16:18.320
So mojo, the complicated answer does all the things. So it's interpreted, it's just compiled

16:18.320 --> 16:26.000
and it's statically compiled. And so this is for a variety of reasons. So one of the things that

16:26.000 --> 16:31.760
makes Python beautiful is that it's very dynamic. And because it's dynamic, one of the things they

16:31.760 --> 16:36.320
added is that it has this powerful metaprogramming feature. And so if you look at something like

16:36.320 --> 16:43.040
PyTorch or TensorFlow, or, or, I mean, even a simple, simple use case, like you'd find a class

16:43.040 --> 16:48.720
that has the plus method, right, you can overload the Dunder methods like Dunder add, for example,

16:48.720 --> 16:52.880
and then the plus method works on your class. And so it has very nice and very expressive,

16:53.680 --> 16:58.800
dynamic metaprogramming features. In mojo, we want all those features come in. Like,

16:58.800 --> 17:02.800
we don't want to break Python, we want it all to work. But the problem is, is you can't run those

17:02.800 --> 17:10.160
super dynamic features on an embedded processor, or on a GPU, right? Or if you could, you probably

17:10.160 --> 17:14.560
don't want to just because of the performance. And so we entered this question of saying,

17:14.560 --> 17:20.880
okay, how do you get the power of this dynamic metaprogramming into a language that has to be

17:20.880 --> 17:25.760
super efficient in specific cases? And so what we did was we said, okay, we'll take that interpreter,

17:25.760 --> 17:30.080
Python has an interpreter in it, right, take that interpreter and allow it to run it compile time.

17:31.360 --> 17:35.360
And so now what you get is you get compile time metaprogramming. And so this is super

17:35.360 --> 17:40.880
interesting, super powerful, because one of the big advantages you get is you get Python style

17:40.880 --> 17:45.840
expressive APIs, you get the ability to have overloaded operators. And if you look at what

17:45.840 --> 17:49.840
happens inside of like PyTorch, for example, with automatic differentiation and eager mode,

17:49.840 --> 17:54.000
and like all these things, they're using these really dynamic and powerful features at runtime.

17:54.560 --> 17:57.600
But we can take those features and lift them so that they run at compile time.

17:58.160 --> 18:05.280
So you're, because C++ has metaprogramming with templates, but it's really messy.

18:05.280 --> 18:10.560
It's super messy. It's always, it was accidentally, I mean, different people have different

18:10.560 --> 18:16.080
interpretations. My interpretation is that it was made accidentally powerful. It was not designed

18:16.080 --> 18:20.480
to be terrain complete, for example, but that was discovered kind of along the way accidentally.

18:21.360 --> 18:26.000
And so there have been a number of languages in the space. And so they usually have templates

18:26.560 --> 18:29.440
or code instantiation, code copying features of various sorts.

18:30.880 --> 18:35.360
Some more modern languages, or some more newer newer languages, let's say, like, you know,

18:35.360 --> 18:42.640
they're fairly unknown, like zig, for example, says, okay, well, let's take all of those types

18:42.640 --> 18:47.120
so you can run it, all those things you can do at runtime and allow them to happen at compile time.

18:48.160 --> 18:53.440
And so one of the problems with C++, I mean, which is one of one of the problems with C++

18:54.000 --> 18:57.040
Here we go. Wrong words. We're going to offend everybody today.

18:57.040 --> 19:00.480
Oh, it's okay. I mean, everybody hates me for a variety of reasons. Anyways, I'm sure, right?

19:01.520 --> 19:06.000
I've written enough the way they show love. I've written enough C++ code to earn a little bit

19:06.000 --> 19:11.600
of grumpyness with C++. But, but one of the problems with it is that the metaprogramming

19:11.600 --> 19:17.440
system templates is just a completely different universe from the normal runtime programming

19:17.440 --> 19:21.280
world. And so if you do metaprogramming and programming, it's just like a different universe,

19:21.280 --> 19:26.320
different syntax, different concepts, different stuff going on. And so again, one of our goals

19:26.320 --> 19:31.200
with Mojo is to make things really easy to use, easy to learn. And so there's a natural stepping

19:31.200 --> 19:36.320
stone. And so as you do this, you say, okay, well, I have to do programming at runtime,

19:36.400 --> 19:40.400
after you're programming at compile time. Why are these different things?

19:41.200 --> 19:45.920
How hard is that to pull it out? Because that sounds to me as a fan of metaprogramming in C++

19:45.920 --> 19:51.040
even. How hard is it to pull that off? That sounds really, really exciting, because you can do the

19:51.040 --> 19:55.360
same style programming at compile time and at runtime. That's really, really exciting.

19:55.360 --> 20:01.280
Yep. And so I mean, in terms of the compiler implementation details, it's hard. I won't be

20:01.280 --> 20:05.840
shy about that. It's super hard. It requires, I mean, what Mojo has underneath the covers is a

20:05.840 --> 20:10.640
completely new approach to the design of the compiler itself. And so this builds on these

20:10.640 --> 20:15.600
technologies like MLIR that you mentioned, that also includes other like caching and other

20:16.400 --> 20:19.120
interpreters and jit compilers and other stuff like that.

20:19.120 --> 20:20.560
Do you have like an interpreter inside the compiler?

20:20.560 --> 20:28.800
Within the compiler, yes. And so it really takes the standard model of programming languages and

20:28.800 --> 20:34.080
kind of twists it and unifies it with the runtime model, right, which I think is really cool. And

20:34.080 --> 20:38.080
to me, the value of that is that, again, many of these languages have metaprogramming features,

20:38.080 --> 20:40.800
like they grow macros or something, right? You list, right?

20:41.760 --> 20:42.240
Yes.

20:42.240 --> 20:48.320
I know your roots, right? And this is a powerful thing, right? And so if you go back to list,

20:48.320 --> 20:52.560
one of the most powerful things about it is that it said that the metaprogramming and the programming

20:52.560 --> 20:57.040
are the same, right? And so that made it way simpler, way more consistent, way easier to

20:57.040 --> 21:00.880
understand reason about, and it made it more composable. So if you build a library, you can use

21:00.960 --> 21:04.240
it both at runtime and compile time, which is pretty cool.

21:04.240 --> 21:10.560
Yeah. And for machine learning, I think metaprogramming, I think we could generally say is extremely

21:10.560 --> 21:17.200
useful. And so you get features, I mean, I'll jump around, but there's the feature of auto-tuning

21:17.200 --> 21:20.320
and adaptive compilation just blows my mind.

21:20.320 --> 21:21.920
Yeah. Well, so, okay, so let's come back to that.

21:21.920 --> 21:22.640
Okay, all right.

21:22.640 --> 21:26.480
So what is machine learning? Like, what is a machine learning model? Like,

21:26.480 --> 21:30.800
you take a PyTorch model off there, right? It's really interesting to me because what

21:31.360 --> 21:35.520
PyTorch and what TensorFlow and all these frameworks are kind of pushing compute into,

21:35.520 --> 21:40.800
is they're pushing into like this abstract specification of a compute problem,

21:40.800 --> 21:43.280
which then gets mapped in a whole bunch of different ways, right?

21:43.280 --> 21:46.800
And so this is why it became a metaprogramming problem, is that you want to be able to say,

21:46.800 --> 21:54.400
cool, I have this neural net, now run with batch size 1000, right? Do a mapping across batch,

21:54.400 --> 21:59.520
or okay, I want to take this problem now running across 1000 CPUs or GPUs, right?

21:59.520 --> 22:05.280
And so like, this problem of like, describe the compute and then map it and do things and

22:05.280 --> 22:09.200
transform it are like, actually, it's very profound. And that's one of the things that

22:09.200 --> 22:11.200
makes machine learning systems really special.

22:12.080 --> 22:16.720
Maybe can you describe auto-tuning and how do you pull off? I mean, I guess adaptive

22:16.720 --> 22:19.440
compilation is what we're talking about as metaprogramming.

22:19.440 --> 22:19.600
Yeah.

22:19.600 --> 22:23.840
How do you pull off auto-tuning? I mean, is that as profound as I think it is? It just seems like

22:23.840 --> 22:30.080
I really like, you know, we'll mention list comprehensions to me, from a quick glance at

22:30.080 --> 22:37.440
Mojo, which by the way, I have to absolutely like dive in. As I realize how amazing this is,

22:37.440 --> 22:43.120
I absolutely must dive in. That looks like just an incredible feature for machine learning people.

22:43.120 --> 22:47.680
Yeah. Well, so what is auto-tuning? So take a step back. Auto-tuning is a feature in Mojo.

22:47.680 --> 22:52.320
It's not, so very little of what we're doing is actually research. Like many of these ideas

22:52.880 --> 22:56.240
have existed in other systems and other places. And so what we're doing is we're pulling together

22:56.240 --> 23:00.800
good ideas, remixing them, and making them into hopefully a beautiful system, right?

23:01.440 --> 23:08.080
And so auto-tuning, the observation is that it turns out hardware systems, algorithms are really

23:08.080 --> 23:12.080
complicated. It turns out maybe you don't actually want to know how the hardware works,

23:13.120 --> 23:17.440
right? A lot of people don't, right? And so there are lots of really smart hardware people.

23:17.440 --> 23:22.960
I know a lot of them, where they know everything about, okay, that the cache size is this and

23:22.960 --> 23:26.480
the number of registers is that. And if you use this, what length of vector, it's going to be

23:26.480 --> 23:29.920
super efficient because it maps directly onto what it can do. And like all this kind of stuff,

23:29.920 --> 23:34.400
or the GPU has SMs and it has a warp size of whatever, right? All the stuff that goes into

23:34.400 --> 23:41.920
these things or the tile size of a TPU is 128, like these factoids, right? My belief is that

23:41.920 --> 23:45.920
most normal people, and I love hardware people also, I'm not trying to offend literally everybody

23:45.920 --> 23:52.000
on the internet, but most programmers actually don't want to know this stuff, right? And so if

23:52.000 --> 23:56.480
you come at it from the perspective of how do we allow people to build both more abstracted,

23:56.480 --> 24:01.200
but also more portable code, because, you know, could be that the vector length changes or the

24:01.200 --> 24:04.960
cache size changes, or it could be that the tile size of your matrix changes or the number,

24:04.960 --> 24:09.920
you know, an A100 versus an H100 versus a Volta versus a whatever GPU have different

24:09.920 --> 24:15.040
characteristics, right? A lot of the algorithms that you run are actually the same, but the

24:15.040 --> 24:19.440
parameters, these magic numbers you have to fill in end up being really fiddly numbers that an

24:19.440 --> 24:24.560
expert has to go figure out. And so what autotuning does, it says, okay, well, guess what? There's

24:24.560 --> 24:29.600
a lot of compute out there, right? So instead of having humans go randomly try all the things or

24:29.600 --> 24:34.560
do a grid search or go search some complicated multi-dimensional space, how about we have

24:34.560 --> 24:39.040
computers do that, right? And so what autotuning does is you can say, hey, here's my algorithm.

24:39.920 --> 24:44.240
If it's a matrix operation or something like that, you can say, okay, I'm going to

24:44.320 --> 24:49.840
carve it up into blocks. I'm going to do those blocks in parallel. And I want this with 128 things

24:49.840 --> 24:54.000
that I'm running on, I want to cut it this way or that way or whatever. And you can say, hey, go see

24:54.000 --> 24:59.360
which one's actually empirically better on the system. And then the result of that, you cache for

24:59.360 --> 25:06.000
that system. Yep. You save it. And so come back to twisting your compiler brain, right? So not only

25:06.000 --> 25:10.800
does the compiler have an interpreter that's used to do metaprogramming, that compiler that

25:10.800 --> 25:15.360
interpreter that metaprogramming now has to actually take your code and go run it on a target

25:15.360 --> 25:21.200
machine. See which one likes the best and then stitch it in and then keep going, right? So part

25:21.200 --> 25:25.680
of the compilation is machine specific. Yeah. Well, so I mean, this is an optional feature, right?

25:25.680 --> 25:30.400
So you don't have to use it for everything. But yeah, if you're, so one of, one of the things

25:30.400 --> 25:35.440
that we're in the quest of is ultimate performance. Yes. Right. And ultimate performance is important

25:35.440 --> 25:39.280
for a couple of reasons, right? So if you're an enterprise, you're looking to save cost and compute

25:39.280 --> 25:44.080
and things like this, ultimate performance translates to, you know, fewer servers. Like,

25:44.080 --> 25:49.280
if you care about the environment, hey, better performance leads to more efficiency. Right?

25:49.280 --> 25:52.800
I mean, you could joke and say like, you know, Python's bad for the environment.

25:53.760 --> 25:57.760
Right. And so if you move to Mojo, it's like at least 10x better just out of the box and

25:57.760 --> 26:03.120
keep going, right? But, but performance is also interesting because it leads to better products.

26:03.760 --> 26:07.840
And so in the space of machine learning, right, if you reduce the latency of a model,

26:08.480 --> 26:12.640
so it runs faster. So every time you query the server running the model, it takes less time.

26:12.640 --> 26:16.880
Well, then the product team can go and make the model bigger. Well, that's actually makes it,

26:16.880 --> 26:21.360
so you have a better experience as a customer. And so a lot of people care about that.

26:21.360 --> 26:26.320
So for auto tuning, for like tile size, you mentioned 128 for TPU, you would specify like a

26:26.320 --> 26:32.160
bunch of options to try. Just in the code. It's just a simple statement. And then you just set

26:32.160 --> 26:36.720
and forget and know, depending on where it compiles, it'll actually be the fastest.

26:36.960 --> 26:40.080
And yeah, exactly. And the beauty of this is that it helps you in a whole bunch of different

26:40.080 --> 26:44.240
ways, right? So if you're building, so often what'll happen is that, you know, you've written a

26:44.240 --> 26:47.840
bunch of software yourself, right? You, you wake up one day, you say, I have an idea,

26:47.840 --> 26:53.760
I'm going to go code up some code. I get to work. I forget about it. I move on with life. I come

26:53.760 --> 26:57.360
back six months or a year or two years or three years later, you dust it off and you go use it

26:57.360 --> 27:02.320
again in a new environment. And maybe your GPU is different. Maybe you're running on a server

27:02.320 --> 27:07.280
instead of a laptop, maybe whatever, right? And so the problem now is you say, okay, well,

27:07.280 --> 27:10.400
I mean, again, not everybody cares about performance. But if you do, you say, okay,

27:10.400 --> 27:14.320
well, I want to take advantage of all these new features. I don't want to break the old thing,

27:14.320 --> 27:20.400
though. Right. And so the typical way of handling this kind of stuff before is, you know, if you're

27:20.400 --> 27:25.360
talking about C++ templates, or you're talking about C with macros, you end up with if deaths,

27:25.360 --> 27:29.440
you get like all these weird things get layered in, make the code super complicated. And then how

27:29.520 --> 27:34.400
do you test it? Right? Because this crazy complexity, multi-dimensional space you have to

27:34.400 --> 27:40.160
worry about. And, you know, that just doesn't scale very well. Actually, let me just jump around

27:40.160 --> 27:45.280
before I go to some specific features. Like the increase in performance here that we're talking

27:45.280 --> 27:55.280
about can be just insane. You write that Moja can provide a 35,000 x speed up over Python.

27:55.920 --> 28:03.840
How does it do that? Yeah, so it can even do more. But we'll get to that. So first of all,

28:03.840 --> 28:08.240
when we say that we're talking about what's called C Python, it's the default Python that

28:08.240 --> 28:13.200
everybody uses when you type Python three, that's like typically the one you use, right? C Python is

28:13.200 --> 28:19.280
an interpreter. And so interpreters, they have an extra layer of like byte codes and things like this

28:19.280 --> 28:23.360
that they have to go read, parse, interpret and make some kind of slow from that perspective.

28:23.440 --> 28:28.560
And so one of the first things we do is we move to a compiler. And so I'm just moving to a compiler

28:28.560 --> 28:33.360
getting the interpreter out of the loop is two to five to 10 x speed up depending on the code.

28:33.360 --> 28:40.480
So just out of the gate, just using more modern techniques, right? Now, if you do that, one of

28:40.480 --> 28:46.320
the things you can do is you can start to look at how C Python started to lay out data. And so one

28:46.320 --> 28:51.760
of the things that C Python did, and this isn't part of the Python spec necessarily, but this is

28:52.160 --> 28:59.120
sets of decisions, is that if you take an integer, for example, it'll put it in an object. In Python,

28:59.120 --> 29:05.040
everything's an object. And so they do the very logical thing of keeping the memory representation

29:05.040 --> 29:10.720
of all objects the same. So all objects have a header, they have like payload data. And what this

29:10.720 --> 29:14.320
means is that every time you pass around an object, you're passing around a pointer to the data.

29:15.360 --> 29:20.160
Well, this has overhead. It turns out that modern computers don't like chasing pointers very much

29:20.160 --> 29:24.320
in things like this. It means that you have to allocate the data. It means you have to reference

29:24.320 --> 29:28.720
count it, which is another way that Python uses to keep track of memory. And so this has a lot

29:28.720 --> 29:36.000
of overhead. And so if you say, okay, let's try to get that out of the heap, out of a box, out of

29:36.000 --> 29:43.520
an indirection, and into the registers. That's that's another 10 x. So it adds up if you if

29:43.520 --> 29:48.320
you're reference counting every single every single thing you create that adds up. Yep. And

29:48.320 --> 29:51.920
if you look at, you know, people complain about the Python Gil, this is one of the things that

29:51.920 --> 29:57.440
hurts parallelism. That's because the reference counting. Right. And so the Gil and reference

29:57.440 --> 30:01.040
counting are very tightly intertwined in Python. It's not the only thing, but it's very tightly

30:01.040 --> 30:05.600
intertwined. And so then you lean into this and you say, okay, cool, well, modern computers, they

30:05.600 --> 30:09.760
can do more than one operation at a time. And so they have vectors. What is a vector? Well, a vector

30:09.760 --> 30:13.600
allows you to take one, instead of taking one piece of data doing an ad or a multiply and then

30:14.400 --> 30:19.200
pick up the next one, you can now do four or eight or 16 or 32 at a time. Right. Well, Python

30:19.200 --> 30:23.200
doesn't expose that because of reasons. And so now you can say, okay, well, you can adopt that.

30:23.920 --> 30:27.360
Now you have threads. Now you have like additional things like you can control memory

30:27.360 --> 30:31.120
hierarchy. And so what mojo allows you to do is it allows you to start taking advantage of

30:31.120 --> 30:34.800
all these powerful things have been built into the hardware over time. And it gives

30:35.440 --> 30:41.520
the library gives very nice features. So you can say, just parallelize, let's do this in parallel.

30:41.920 --> 30:48.160
So it's very, very powerful weapons against slowness, which is why people have been I think

30:48.160 --> 30:52.400
having fun like just taking code and making go fast because it's just kind of an adrenaline rush

30:52.400 --> 30:55.920
to see like how fast you can get things. Before I talk about some of the interesting

30:55.920 --> 31:00.240
stuff with parallelization, all that, let's first talk about like the basics. We talked

31:00.240 --> 31:05.920
about indentation, right? So this thing looks like Python. It's sexy and beautiful like Python,

31:05.920 --> 31:10.720
as I mentioned. Is it a typed language? So what's the role of types?

31:10.720 --> 31:17.280
Yeah, good question. So Python has types. It has strings as integers, it has dictionaries and

31:17.280 --> 31:22.560
like all that stuff. But they all live at runtime. Right. And so because all those types live at

31:22.560 --> 31:28.000
runtime and Python, you never, you don't have to spell them. Python also has like this whole

31:28.000 --> 31:31.680
typing thing going on now. And a lot of people use it. Yeah, I'm not talking about that. That's

31:31.680 --> 31:35.200
kind of a different thing. We can go back to that if you want. But, but typically the,

31:35.840 --> 31:40.800
you know, you just say I take, I have a def and my def takes two parameters. I'm going to call them

31:40.800 --> 31:47.120
A and B and I don't have to write a type. Okay. So that is great. But what that does is that forces

31:47.120 --> 31:51.680
what's called a consistent representation. So these things have to be a pointer to an object

31:51.680 --> 31:56.320
with the object header, and they all have to look the same. And then when you dispatch a method,

31:56.320 --> 32:00.400
you go through all the same different paths, no matter what the receiver or whatever that type

32:00.400 --> 32:05.760
is. So what Mojo does is it allows you to have more than one kind of type. And so what it does

32:05.760 --> 32:10.080
is allows you to say, okay, cool, I have, I have an object and objects behave like Python does. And

32:10.080 --> 32:14.480
so it's fully dynamic and that's all great. And for many things classes, like that's all very

32:14.480 --> 32:19.760
powerful and very important. But if you want to say, Hey, it's an integer, and it's 32 bits or 64

32:19.760 --> 32:25.200
bits or whatever it is, or it's a floating point value, it's 64 bits. Well, then the compiler can

32:25.200 --> 32:29.680
take that and it can use that to do way better optimization. And it turns out again, getting

32:29.680 --> 32:34.160
rid of the interactions, that's huge, means you can get better code completion because you have,

32:34.800 --> 32:39.440
because compiler knows what the type is. And so it knows what operations work on it. And so that's

32:39.440 --> 32:46.400
actually pretty huge. And so what Mojo does allows you to progressively adopt types into your program.

32:46.400 --> 32:50.800
And so you can start again, it's compatible with Python. And so then you can add however many types

32:50.800 --> 32:54.000
you want, wherever you want them. And if you don't want to deal with it, you don't have to deal with

32:54.000 --> 33:00.880
it. Right. And so one of one of, you know, our opinions on this is it's not that types are the

33:00.880 --> 33:04.240
right thing or the wrong thing. It's that they're a useful thing.

33:05.360 --> 33:09.200
Which was kind of optional. It's not strict typing, you don't have to specify type.

33:09.200 --> 33:14.400
Exactly. Okay, so starting from the thing that Python is kind of reaching towards right now with

33:15.040 --> 33:19.680
trying to inject types into it. Yeah, with a very different approach. But yes.

33:20.080 --> 33:22.800
What's the different approach? I'm actually one of the people

33:24.320 --> 33:26.720
that have not been using types very much in Python.

33:26.720 --> 33:28.480
That's okay. Why did you say?

33:29.520 --> 33:36.800
It just, well, because I know the importance it's like adults use strict typing. And so I refuse

33:36.800 --> 33:43.600
to grow up in that sense. It's a kind of rebellion. But I just know that it probably reduces the

33:43.600 --> 33:47.680
amount of errors even just for forget about performance improvements, it probably reduces

33:47.680 --> 33:51.040
errors when you do strict typing. Yeah, so I mean, I think it's interesting if you look at that,

33:51.040 --> 33:57.600
right? And the reason I'm giving a hard time is that there's this cultural norm, this pressure,

33:57.600 --> 34:01.600
this like, there has to be a right way to do things. Like, you know, grown-ups only do it one

34:01.600 --> 34:05.520
way. And if you don't do that, you should feel bad. Right. Like some people feel like Python's a

34:05.520 --> 34:09.120
guilty pleasure or something. And it's like, when it gets serious, I need to go rewrite it.

34:11.120 --> 34:14.400
I mean, cool. I understand history and I understand kind of where this comes from. But

34:15.040 --> 34:19.120
I don't think it has to be guilty pleasure. Yeah. So if you look at that, you say,

34:19.120 --> 34:22.880
why do you have to rewrite it? Well, you have to rewrite it to deploy. Well, why do you want to

34:22.880 --> 34:27.680
deploy? Well, you care about performance, you care about productivity, or you want, you know,

34:27.680 --> 34:31.120
a tiny thing on the server that has no dependencies, or, you know, you have

34:31.120 --> 34:36.720
objectives that you're trying to attain. So what if Python can achieve those objectives?

34:37.520 --> 34:40.320
So if you want types, well, maybe you want types because you want to make sure you're

34:40.320 --> 34:45.680
passing the right thing. Sure, you can add a type. If you don't care, you're prototyping some stuff,

34:45.680 --> 34:48.880
you're hacking some things out, you're like pulling some MAM code off the internet,

34:48.880 --> 34:54.240
it should just work. Right. And you shouldn't be like pressured. You shouldn't feel bad

34:54.240 --> 34:58.720
about doing the right thing or the thing that feels good. Now, if you're in a team, right,

34:58.720 --> 35:03.680
you're working at some massive internet company and you have 400 million lines of Python code,

35:03.680 --> 35:07.760
well, they may have a house rule that you use types. Yeah. Right. Because it makes it easier

35:07.760 --> 35:11.920
for different humans to talk to each other and understand what's going on and bugs at scale.

35:11.920 --> 35:16.880
Right. And so there are lots of good reasons why you might want to use types. But that doesn't

35:16.880 --> 35:20.480
mean that everybody should use them all the time. Right. So what Mojo does is it says, cool, well,

35:21.200 --> 35:25.600
allow people to use types. And if you use types, you get nice things out of it. Right. You get

35:25.600 --> 35:32.160
better performance and things like this. Right. But Mojo is a full compatible superset of Python.

35:32.960 --> 35:38.400
Right. And so that means it has to work without types. It has to support all the dynamic things,

35:38.400 --> 35:43.200
has to support all the packages, has to support for comprehension, list comprehensions and things

35:43.200 --> 35:47.680
like this. Right. And so that starting point, I think, is really important. And I think that,

35:48.800 --> 35:52.560
again, you can look at why it cares so much about this. And there's many different aspects of that,

35:52.560 --> 35:57.520
one of which is the world went through a very challenging migration from Python 2 to Python 3.

35:58.400 --> 36:03.920
Right. And this migration took many years. And it was very painful for many teams. Right.

36:03.920 --> 36:09.600
And there's a lot of things that went on in that. I'm not an expert in all the details. I honestly

36:09.600 --> 36:14.480
don't want to be. I don't want the world to have to go through that. Right. And people can ignore

36:14.480 --> 36:18.400
Mojo. And if it's not their thing, that's cool. But if they want to use Mojo, I don't want them

36:18.400 --> 36:22.160
to have to rewrite all their code. Yeah. I mean, this, okay, the superset part is,

36:23.120 --> 36:27.600
it's just, I mean, there's so much brilliant stuff here. That definitely is incredible.

36:28.880 --> 36:32.240
We'll talk about that. Yeah. First of all, how's the typing implemented differently

36:32.960 --> 36:39.440
in Python versus Mojo? Yeah. So this heterogeneous flexibility,

36:39.440 --> 36:43.760
you said, is definitely implemented. Yeah. So I'm not a full expert in the whole

36:43.760 --> 36:47.600
backstory on types in Python. So I'll give you that. I can give you my understanding.

36:47.760 --> 36:54.400
My understanding is basically like many dynamic languages, the ecosystem went through a phase

36:54.400 --> 37:01.200
where people went from ranked scripts to ranked large scale, huge code bases in Python. And at

37:01.200 --> 37:05.600
scale, it kind of helps have types. Yeah. People want to be able to reason about interfaces,

37:05.600 --> 37:10.080
what do you expect to string or an int or like, what are these basic things, right?

37:10.080 --> 37:14.720
And so what the Python community started doing is it started saying, okay, let's have tools on the

37:14.720 --> 37:21.280
side, checker tools, right? The go and like enforce and variance, check for bugs, try to

37:21.280 --> 37:25.840
identify things. These are called static analysis tools generally. And so these tools run over

37:25.840 --> 37:29.680
your code and try to look for bugs. What ended up happening is there's so many of these things,

37:29.680 --> 37:33.520
so many different weird patterns and different approaches on specifying the types and different

37:33.520 --> 37:37.840
things going on that the Python community realized and recognized, hey, hey, hey, there's a thing here.

37:38.720 --> 37:42.720
And so what they started to do is they started to standardize the syntax for adding types to Python.

37:43.360 --> 37:46.960
Now, one of the challenges that they had is that they're coming from kind of this fragmented

37:46.960 --> 37:50.640
world where there's lots of different tools, they have different trade-offs and interpretations

37:50.640 --> 37:54.880
and the types mean different things. And so if you look at types in Python, according to the

37:54.880 --> 38:01.360
Python spec, the types are ignored, right? So according to the Python spec, you can write

38:01.360 --> 38:09.280
pretty much anything in a type position, okay? And technically, you can write any expression,

38:09.280 --> 38:14.480
okay? Now, that's beautiful because you can extend it, you can do cool things, you can

38:14.480 --> 38:18.720
write, build your own tools, you can build your own house, linter or something like that, right?

38:18.720 --> 38:24.160
But it's also a problem because any existing Python program may be using different tools

38:24.160 --> 38:28.720
and they have different interpretations. And so if you adopt somebody's package into your ecosystem,

38:28.720 --> 38:32.880
try around the tool you prefer, it may throw out tons of weird errors and warnings and problems

38:32.880 --> 38:37.520
just because it's incompatible with how these things work. Also because they're added late

38:37.520 --> 38:41.120
and they're not checked by the Python interpreter, it's always kind of more of a hint than it is a

38:41.120 --> 38:47.280
requirement. Also, the C Python implementation can't use them for performance. And so it's really

38:47.280 --> 38:51.360
that's a big one, right? So you can't utilize the for the compilation for the just entire

38:51.360 --> 38:55.200
compilation. Okay, exactly. And this all comes back to the design principle of it's,

38:55.760 --> 38:59.200
it's kind of, they're kind of hints, they're kind of the definition is a little bit murky,

38:59.200 --> 39:03.280
it's unclear exactly the interpretation in a bunch of cases. And so because of that, you can't

39:03.280 --> 39:08.240
actually, even if you want to, it's really difficult to use them to say like it is going

39:08.240 --> 39:12.240
to be an int. And if it's not, it's a problem, right? A lot of code would break if you did that.

39:12.960 --> 39:17.040
So, so in mojo, right, so you can still use those kind of type annotations, it's fine.

39:17.040 --> 39:22.960
But in mojo, if you declare a type and you use it, then it means it is going to be that type.

39:22.960 --> 39:28.080
And the compiler helps you check that and force it and it's safe. And it's not it's not a like

39:29.040 --> 39:34.240
best effort hint kind of a thing. So if you try to shove a string type thing into a integer,

39:34.240 --> 39:41.840
you get an error from the compiler, compile time. Nice. Okay, what kind of basic types are there?

39:41.840 --> 39:49.200
Yeah, so mojo is pretty hardcore in terms of what it tries to do in the language,

39:49.760 --> 39:56.320
which is the philosophy there is that we, again, if you, if you look at Python, right,

39:56.320 --> 40:00.880
Python's beautiful language because it's so extensible, right? And so all of the different

40:00.880 --> 40:04.480
things in Python like for loops and plus and like all these things can be

40:05.040 --> 40:10.240
accessed through these underbar and bar methods. Okay, so you have to say, okay,

40:10.240 --> 40:12.960
if I make something that is super fast, I can go all the way down to the metal.

40:13.600 --> 40:15.760
Why do I need to have integers built into the language?

40:16.960 --> 40:20.720
Right. And so what mojo does is it says, okay, well, we can have this notion of structs. So

40:20.800 --> 40:26.160
we have classes in Python, now you can have structs. Classes are dynamic, structs are static.

40:27.040 --> 40:31.440
Cool, we can get high performance, we can write C++ kind of code with structs if you want.

40:31.440 --> 40:35.680
These things mix and work beautifully together. But what that means is that you can go and

40:35.680 --> 40:40.560
implement strings and ints and floats and arrays and all that kind of stuff in the language.

40:41.360 --> 40:49.280
Right. And so that's really cool because, you know, to me as a ideal, idealizing compiler language

40:49.280 --> 40:53.360
type of person, what I want to do is I want to get magic out of the compiler and put in the

40:53.360 --> 40:57.760
libraries. Because if somebody can, you know, if we can build an integer that's beautiful and it

40:57.760 --> 41:02.400
has an amazing API and does all the things you'd expect an integer to do, but you don't like it,

41:03.040 --> 41:06.880
maybe you want a big integer, maybe you want like sideways integer, I don't know, like what

41:06.880 --> 41:13.280
all the space of integers are, then you can do that and it's not a second class citizen.

41:13.520 --> 41:19.680
And so if you look at certain other languages like C++, one I also love and use a lot,

41:21.040 --> 41:28.640
int is hard code in the language, but complex is not. And so it's kind of weird that, you know,

41:28.640 --> 41:34.960
you have this std complex class, but you have int and complex tries to look like a natural

41:34.960 --> 41:40.240
numeric type and things like this. But integers and floating point have these like special promotion

41:40.240 --> 41:43.680
rules and other things like that that are magic and they're hacked into the compiler.

41:43.680 --> 41:46.560
And because of that, you can't actually make something that works like the built-in types.

41:47.520 --> 41:52.960
Is there something provided as a standard because, you know, because it's AI first,

41:53.760 --> 41:58.560
you know, numerical types are so important here. So is there something like a nice

41:59.200 --> 42:03.280
standard implementation of integer and float? Yeah, so we're still building all this stuff out. So we

42:03.280 --> 42:07.200
provide integers and floats and all that kind of stuff. We also provide like buffers and tensors

42:07.200 --> 42:12.560
and things like that that you'd expect in an ML context. Honestly, we need to keep designing and

42:12.560 --> 42:15.280
redesigning and working with the community to build that out and make that better. That's not

42:15.280 --> 42:19.520
our strength right now. Give us six months or a year and I think it'll be way better. But

42:20.720 --> 42:24.800
the power of putting in the library means that we can have teams of experts that aren't compiler

42:24.800 --> 42:30.160
engineers that can help us design and refine and drive us forward. So one of the exciting things

42:30.160 --> 42:38.640
we should mention here is that this is new and fresh. This cake is unbaked. It's almost baked.

42:38.640 --> 42:44.240
You can tell it's delicious, but it's not fully ready to be consumed. Yep, that's very fair. It is

42:44.240 --> 42:48.080
very useful, but it's very useful if you're a super low-level programmer right now. And what

42:48.080 --> 42:51.680
we're doing is we're working our way up the stack. And so the way I would look at Mojo

42:52.160 --> 43:00.240
today in May and 2023 is that it's like a 0.1. So I think that a year from now,

43:00.240 --> 43:05.360
it's going to be way more interesting to a variety of people. But what we're doing is we

43:05.360 --> 43:09.040
decided to release it early so that people can get access to it and play with it. We can build

43:09.040 --> 43:15.520
it with the community. We have a big roadmap fully published, being transparent about this,

43:15.520 --> 43:19.040
and a lot of people are involved in this stuff. And so what we're doing is we're really optimizing

43:19.040 --> 43:23.920
for building this thing the right way. And building it the right way is kind of interesting

43:23.920 --> 43:30.880
working with the community because everybody wants it yesterday. And so sometimes there's

43:30.880 --> 43:35.440
some dynamics there, but I think it's the right thing. So there's a discord also,

43:35.440 --> 43:40.080
so the dynamics is pretty interesting. Sometimes the community probably can be very chaotic

43:41.600 --> 43:47.760
and introduce a lot of stress. Guido famously quit over the stress of the Walrus operator.

43:49.040 --> 43:54.720
Broke, straw the brook with camels there. Exactly. And so it could be very stressful to

43:54.720 --> 44:02.800
develop. But can you just add tangent upon a tangent? Is it stressful to work through the

44:02.800 --> 44:07.120
design of various features here given that the community is so racially involved?

44:07.120 --> 44:12.720
Well, so I've been doing open development and community stuff for decades now. Somehow this

44:12.720 --> 44:17.680
has happened to me. So I've learned some tricks. But the thing that always gets me is I want to

44:17.680 --> 44:24.160
make people happy. And so this is maybe not all people all happy all the time. But generally,

44:24.160 --> 44:29.760
I want people to be happy. And so the challenge is that, again, we're tapping into some long,

44:30.800 --> 44:36.480
some deep-seated long tensions and pressures both in the Python world, but also in the AI world,

44:36.480 --> 44:40.000
in the hardware world, and things like this. And so people just want us to move faster.

44:40.960 --> 44:47.440
And so, again, our decision was let's release this early. Let's get people used to it or access to

44:47.440 --> 44:54.800
and play with it. And let's build in the open, which we could have had the language monk sitting

44:54.800 --> 45:00.400
in the cloister up on the hilltop bevaring away trying to build something. But in my experience,

45:00.400 --> 45:02.640
you get something that's way better if you work with the community.

45:04.160 --> 45:07.440
And so, yes, it can be frustrating. It can be challenging for lots of people involved. And

45:08.800 --> 45:13.200
if you mention our Discord, we have over 10,000 people on the Discord, 11,000 people or something.

45:13.200 --> 45:21.120
Keep in mind, we released Mojo like two weeks ago. So it's very cool. But what that means is that

45:22.640 --> 45:28.320
10, 11,000 people all will want something different. And so what we've done is we've tried to say,

45:28.320 --> 45:34.320
okay, cool, here's our roadmap. And the roadmap isn't completely arbitrary. It's based on,

45:34.320 --> 45:38.160
here's the logical order in which to build these features or add these capabilities and

45:38.160 --> 45:42.960
things like that. And what we've done is we've spun really fast on bug fixes. And so we actually

45:42.960 --> 45:48.400
have very few bugs, which is cool. I mean, actually for projects in the state. But then

45:48.400 --> 45:51.120
what we're doing is we're dropping in features very deliberately.

45:51.120 --> 45:56.080
I mean, this is fun to watch because you got the two gigantic communities of like hardware,

45:56.080 --> 46:02.000
like systems engineers. And then you have the machine learning Python people that are like

46:02.000 --> 46:09.760
higher level. And it's just too like army, like they've been at war. Yeah, they've been at war.

46:10.480 --> 46:14.480
Right. And so here's a Tolkien novel or something. Okay, so here's the test. Again,

46:14.480 --> 46:18.720
like it's super funny for something that's only been out for two weeks, right? People are so

46:18.720 --> 46:24.640
impatient, right? But okay, cool. Let's fast forward a year. Like any year's time, Mojo will be

46:24.640 --> 46:30.240
actually quite amazing and solve tons of problems and be very good. People still have these problems.

46:31.040 --> 46:35.680
Right. And so you look at this and you say, and the way I look at this at least is to say,

46:35.680 --> 46:42.640
okay, well, we're solving big longstanding problems. To me, I, again, working on many

46:42.640 --> 46:46.400
different problems, I want to make sure we do it right. Right? There's like a responsibility you

46:46.400 --> 46:51.600
feel because if you mess it up, right? There's very few opportunities to do projects like this

46:51.600 --> 46:56.000
and have them really have impact on the world. If we do it right, then maybe we can take those

46:56.000 --> 47:00.880
feuding armies and actually heal some of those wounds. Yeah, this is like, this feels, this

47:00.880 --> 47:05.760
feels like a speech by George Washington or Abraham Lincoln or something. And you look at

47:05.760 --> 47:09.760
this and it's like, okay, well, how different are we? Yeah. We all want beautiful things. We all

47:09.760 --> 47:12.640
want something that's nice. We all want to be able to work together. We all want our stuff to be

47:12.640 --> 47:18.000
used, right? And so if we can help heal that, now I'm not optimistic that all people will use Mojo

47:18.000 --> 47:22.720
and they'll stop using C++. Like that's not my goal, right? But if we can heal some of that,

47:22.720 --> 47:27.600
I think that'd be pretty cool. Yeah. And we start by putting the people who like braces into the

47:27.600 --> 47:35.360
gulag. No. So there are proposals for adding braces to Mojo. We just tell them no. Okay.

47:37.440 --> 47:41.920
Politely. Yeah. Anyway, so there's a lot of amazing features on the roadmap and those ready

47:41.920 --> 47:48.080
to implement it. It'd be awesome. I can just ask you a few things. So the other performance

47:48.080 --> 47:53.920
improvement comes from immutability. So what's the what's this var and this let thing that we got

47:54.000 --> 48:01.200
going on? What's immutability? Yeah. So one of the things that is useful and it's not always

48:01.200 --> 48:04.800
required, but it's useful is knowing whether something can change out from underneath you.

48:05.440 --> 48:10.640
Right. And so in Python, you have a pointer to an array, right? And so you pass that pointer

48:10.640 --> 48:16.480
to an array around to things. If you pass into a function, maybe take that and scroll away in

48:16.480 --> 48:21.040
some other data structure. And so you get your array back and you go to use it. Now somebody else

48:21.040 --> 48:24.880
is like putting stuff in your array. How do you reason about that? Because to be very

48:25.760 --> 48:30.640
complicated, at least a lot of bugs, right? And so one of the things that, you know, again,

48:30.640 --> 48:34.720
this is not something Mojo forces on you, but something that Mojo enables is a thing called

48:34.720 --> 48:42.080
value semantics. And what value semantics do is they take collections like arrays, like dictionaries,

48:42.880 --> 48:48.240
also tensors and strings and things like this that are much higher level and make them behave

48:48.320 --> 48:53.600
like proper values. And so it makes it look like if you pass these things around, you get a logical

48:53.600 --> 48:58.560
copy of all the data. And so if I pass you an array, sure array, you can go do what you want

48:58.560 --> 49:03.680
to it. You're not going to hurt my array. Now, that is an interesting and very powerful design

49:03.680 --> 49:07.840
principle. It defines the way a ton of bugs. You have to be careful to implement it in an efficient

49:07.840 --> 49:14.480
way. Yeah, is there a performance hit that's significant? Generally not, if you implement it

49:14.480 --> 49:19.840
the right way. But it requires a lot of very low level, getting the language right bits.

49:20.560 --> 49:24.480
I assume there'll be a huge performance hit, because it's a really nice, the benefit is really

49:24.480 --> 49:28.560
nice, because you don't get into the complex. Absolutely. Well, the trick is, is you can't do

49:28.560 --> 49:36.240
copies. So you have to provide the behavior of copying without doing the copy. Yeah. How do you

49:36.240 --> 49:42.240
do that? How do you do that? It's not magic. It's just, it's actually pretty cool. Well,

49:42.240 --> 49:46.000
so first, before we talk about how that works, let's talk about how it works in Python, right?

49:46.000 --> 49:51.200
So in Python, you define a person class, or maybe a person class is a bad idea. You define a

49:51.200 --> 49:55.360
database class, right? And database class has an array of records, something like that, right?

49:55.360 --> 50:00.720
And so the problem is that if you pass in a record or a class instance into the database,

50:00.720 --> 50:06.720
it'll take a hold of that object. And then it assumes it has it. And if you're passing an object in,

50:06.720 --> 50:10.720
you have to know that that database is going to take, take it. And therefore you shouldn't change

50:10.800 --> 50:13.920
it after you put in the database, right? This is, this is kind of have to know that you just

50:13.920 --> 50:18.400
have to kind of know that, right? And so you roll out version one of the database, you just kind

50:18.400 --> 50:22.720
of have to know that. Of course, Lex uses his own database, right? Yeah, right? Because you built

50:22.720 --> 50:26.960
it, you understand this works, right? Somebody else joins the team, they don't know this. Yes.

50:26.960 --> 50:31.680
Right. And so now they suddenly get bugs, you're having to maintain the database, you shake your

50:31.680 --> 50:36.560
fist, you argue the 10th time this happens, you're like, okay, we have to do something different.

50:36.560 --> 50:40.000
Right. And so what you do is you go change your Python code, and you change your database

50:40.000 --> 50:45.440
class to copy the record every time you add it. And so what ends up happening is you say, okay,

50:45.440 --> 50:50.320
I will do what's called a defensive copy inside the database. And then that way,

50:50.320 --> 50:55.440
if somebody passes something in, I will have my own copy of it. And they can go do whatever,

50:55.440 --> 51:00.480
and they're not going to break my thing. Okay, this is usually the, the two design patterns.

51:00.480 --> 51:04.880
If you look in PyTorch, for example, this is cloning a tensor, like there's a specific thing,

51:04.880 --> 51:06.800
and you have to know where to call it. And if you don't call in the right place,

51:06.880 --> 51:12.240
you get these bugs, and this is state of the art. Right. So a different approach. So it's used in

51:12.240 --> 51:17.520
many languages. So I worked with it in Swift, as you say, okay, well, let's provide value semantics.

51:17.520 --> 51:23.440
And so we want to provide the view that you get a logically independent copy. But we want to do

51:23.440 --> 51:29.360
that lazily. And so what we do is you say, okay, if you pass something into a function, it doesn't

51:29.360 --> 51:33.440
actually make a copy. What it actually does is it just increments a reference to it. And if you

51:33.440 --> 51:38.240
pass it around, you stick in your database, you can go into the database, you own it. And then

51:38.240 --> 51:42.320
you come back out of the stack, nobody's copied anything, you come back out of the stack, and

51:42.320 --> 51:47.440
then the caller, let's go of it. Well, then you've just handed it off to the database,

51:47.440 --> 51:52.880
you've transferred it, and there's no copies made. Now, on the other hand, if, you know,

51:52.880 --> 51:57.360
your coworker goes and hands you a record, and you pass it in, you stick it in the database,

51:57.360 --> 52:02.160
and then you go to town, and you start modifying it, what happens is you get a copy lazily

52:02.800 --> 52:07.120
on demand. And so what this does, this gives you copies only when you need them.

52:07.680 --> 52:11.760
And it also, so it defines the way the bugs, but it also generally reduces the number of copies

52:11.760 --> 52:17.440
in practice. And so the implementation details are tricky here. Yes. So this is, yes, something

52:17.440 --> 52:24.080
with reference counting, but to make it performant across the number of different kinds of

52:25.120 --> 52:30.000
objects. Yeah, so you need a couple of things. And so there's many, so this concept has existed

52:30.000 --> 52:36.160
in many different worlds. And so, again, it's not novel research at all, right? The magic is

52:36.160 --> 52:40.000
getting the design right so that you can do this in a reasonable way, right? And so there's a number

52:40.000 --> 52:45.040
of components that go into this. One is when you're passing around, so we're talking about

52:45.040 --> 52:49.200
Python and reference counting at the expense of doing that, when you're passing values around,

52:49.200 --> 52:52.720
you don't want to do extra reference counting for no good reason. And so you have to make

52:52.720 --> 52:57.200
sure that you're efficient and you transfer ownership instead of duplicating references

52:57.200 --> 53:02.400
and things like that, which is a very low level problem. You also have to adopt this and you have

53:02.400 --> 53:07.680
to build these data structures. And so if you say, you know, Mojo has to be compatible with Python.

53:07.680 --> 53:13.200
So of course, the default list is a reference semantic list that works the way you'd expect

53:13.200 --> 53:17.680
in Python. But then you have to design a value semantic list. And so you just have to implement

53:17.680 --> 53:22.480
that and then you implement the logic within. And so the role of the language here is to provide

53:22.480 --> 53:28.080
all the low level hooks that allow the author of the type to be able to get and express this

53:28.080 --> 53:32.800
behavior without forcing it into all cases or hard coding this into the language itself.

53:32.800 --> 53:37.040
But there's ownership. So you're constantly transferring, you're tracking who owns the thing.

53:37.040 --> 53:41.760
Yes. And so there's a whole system called ownership. And so this is related to work done

53:41.760 --> 53:45.600
in the Rust community. Also the Swift community has done a bunch of work. And there's a bunch of

53:45.600 --> 53:50.720
different other languages that evolve kind of C++ actually has copy constructors and destructors

53:50.720 --> 53:55.520
and things like that. And so I mean, C++ has everything. So it has move constructors and

53:55.520 --> 54:01.760
has like this whole world of things. And so this is a body of work that's kind of been developing

54:01.760 --> 54:07.360
for many, many years now. And so Mojo takes some of the best ideas out of all these systems and

54:07.360 --> 54:12.960
remixes it in a nice way so that you get the power of something like the Rust programming language.

54:12.960 --> 54:17.200
But you don't have to deal with it when you don't want to, which is a major thing in terms of

54:17.200 --> 54:19.760
teaching and learning and being able to use and scale these systems.

54:20.880 --> 54:25.440
How does that play with argument conventions? What are they? Why are they important?

54:25.440 --> 54:29.840
How does the value semantics? How does the transfer ownership work with the arguments

54:29.840 --> 54:34.160
when they're passed into functions? So if you go deep into systems programming land,

54:34.160 --> 54:37.840
so this isn't again, this is not something for everybody, but if you go deep into systems

54:37.840 --> 54:42.640
programming land, what you encounter is you encounter these types that get weird.

54:43.600 --> 54:47.200
So if you're used to Python, you think about everything, I can just copy it around,

54:47.200 --> 54:50.560
I can go change it and mutate it and do these things. And it's all cool.

54:52.080 --> 54:56.560
If you get into systems programming land, you get into these things like I have an atomic number,

54:56.560 --> 55:03.680
or I have a mutex, or I have a uniquely owned database handle, things like this, right?

55:03.680 --> 55:07.760
So these types, you can't necessarily copy. Sometimes you can't necessarily even move them

55:07.760 --> 55:12.720
to a different address. And so what Mojo allows you to do is it allows you to express,

55:12.720 --> 55:17.440
hey, I don't want to get a copy of this thing. I want to actually just get a reference to it.

55:18.080 --> 55:22.000
And by doing that, well, you can say, as you can say, okay, if I'm defining something weird,

55:22.000 --> 55:29.440
like a atomic number or something, it has to be, so an atomic number is an area in memory

55:29.440 --> 55:37.200
that multiple threads can access at a time without locks. And so the definition of atomic

55:37.200 --> 55:40.720
numbers, multiple different things have to be poking it. Therefore, they have to agree on where

55:40.720 --> 55:45.680
it is. And so you can't just move it out from underneath one because it kind of breaks what

55:45.680 --> 55:51.360
it means. And so that's an example of a type that you can't copy, you can't move. Once you create,

55:51.360 --> 55:57.520
it has to be where it was. Now, if you look at many other examples, like a database handle,

55:57.520 --> 56:02.880
so okay, well, what happens, how do you copy a database handle? Do you copy the whole database?

56:02.960 --> 56:08.400
That's not something you necessarily want to do. There's a lot of types like that

56:08.400 --> 56:14.000
where you want to be able to say that they are uniquely owned. So there's always one of this

56:14.000 --> 56:21.200
thing. And or if I create a thing, I don't copy it. And so what Mojo allows you to do is it allows

56:21.200 --> 56:25.440
you to say, hey, I want to pass around a reference to this thing without copying it. And so it has

56:26.000 --> 56:31.760
borrowed conventions. So you can say, you can use it, but you don't get to change it. You can pass

56:31.840 --> 56:36.320
it by mutable reference. And so if you do that, then you can, you get a reference to it, but

56:36.320 --> 56:42.080
you can change it. And so it manages all that kind of stuff. So it's just a really nice implementation

56:42.080 --> 56:50.080
of like C++ has, you know, the different kinds of pointers, different kinds of applications,

56:50.080 --> 56:54.880
smart pointers that you can explicitly define this logic. But you're saying that's more like

56:55.600 --> 57:00.000
the weird case versus the common case. Well, it depends on where, I mean, I mean,

57:00.480 --> 57:03.760
I don't think I'm a normal person. So I mean, I'm not one to call other people weird.

57:05.280 --> 57:10.640
But the, but, you know, if you talk to a normal Python, a typical Python programmer,

57:10.640 --> 57:14.000
you're typically not thinking about this, right? This is a lower level of abstraction. Now,

57:14.000 --> 57:18.240
if you talk to a C++ programmer, certainly if you talk to a Rust programmer, again, they're

57:18.240 --> 57:23.200
not weird, they're delightful, like these are all good people, right? Those folks will think about

57:23.200 --> 57:28.640
all the time. Right. And so I look at this as there's a spectrum between very deep low level

57:28.640 --> 57:32.400
systems. I'm going to go poke the bits and care about how they're laid out in memory all the

57:32.400 --> 57:37.120
way up to application and scripting and other things like this. And so it's not that anybody's

57:37.120 --> 57:43.680
right or wrong. It's about how do we build one system that scales? By the way, the idea of an

57:43.680 --> 57:51.680
atomic number has been something that always brought me deep happiness. Because the flip side

57:51.680 --> 58:01.840
of that, the idea that threads can just modify stuff asynchronously, just the whole idea of

58:01.840 --> 58:06.640
concurrent programming is a source of infinite stress for me. Well, so this is where you jump into,

58:08.640 --> 58:12.160
you know, again, you zoom out and get out of programming languages or compilers and you just

58:12.160 --> 58:17.600
look at what the industry has done. My mind is constantly blown by this, right? And you look

58:17.600 --> 58:22.800
at what, you know, Moore's law, Moore's law has this idea that like computers for a long time,

58:23.360 --> 58:26.400
single thread performance has got faster and faster and faster and faster for free.

58:27.040 --> 58:32.400
But then physics and other things intervened and power consumption, like other things started

58:32.400 --> 58:37.280
to matter. And so what ended up happening is we went from single core computers to multi core,

58:37.280 --> 58:41.680
then we went to accelerators, right? And this trend towards specialization of hardware

58:41.680 --> 58:48.480
is only going to continue. And so for years, us programming language nerds and compiler people

58:48.480 --> 58:52.640
have been saying, okay, well, how do we tackle multi core, right? For a while, it was like,

58:52.640 --> 58:56.720
multi core is the future, we have to get on top of this thing. And then it was multi cores to default.

58:56.720 --> 59:00.720
What are we doing with this thing? And then it's like, there's chips with hundreds of cores in them.

59:01.520 --> 59:07.680
What happened, right? And so I'm super inspired by the fact that, you know, in the face of this,

59:08.160 --> 59:13.600
you know, those machine learning people invented this idea of a tensor, right? And what is a tensor?

59:13.600 --> 59:20.160
A tensor isn't like an arithmetic and algebraic concept, it's like an abstraction around a

59:20.160 --> 59:25.440
gigantic parallelizable data set, right? And because of that, and because of things like

59:25.440 --> 59:30.800
TensorFlow and PyTorch, we're able to say, okay, we'll express the math of the system.

59:31.360 --> 59:35.120
This enables you to do automatic differentiations, enables you to do like all these cool things.

59:35.120 --> 59:41.360
And it's an abstract representation. Because you have that abstract representation,

59:41.360 --> 59:46.960
you can now map it onto these parallel machines without having to control, okay, put that right

59:46.960 --> 59:51.680
here, put that right there, put that right there. And this has enabled an explosion in terms of AI,

59:51.680 --> 59:56.240
compute, accelerators, like all the stuff. And so that's super, super excited.

59:56.240 --> 01:00:03.040
What about the deployment, the execution across multiple machines? So you write that

01:00:03.040 --> 01:00:08.240
the modular compute platform dynamically partitions models with billions of parameters

01:00:08.240 --> 01:00:14.400
and distributes their execution across multiple machines, enabling unparalleled efficiency.

01:00:15.360 --> 01:00:20.240
By the way, the use of unparalleled in that sentence, anyway, enabling unparalleled efficiency

01:00:20.240 --> 01:00:28.880
scale and reliability for the largest workloads. So how do you do this abstraction of distributed

01:00:28.880 --> 01:00:33.040
deployment of large models? Yeah, so one of the really interesting

01:00:33.920 --> 01:00:37.920
tensions. So there's a whole bunch of stuff that goes into that. I'll pick a random walkthrough.

01:00:38.800 --> 01:00:43.120
If you go back and replay the history of machine learning, right? I mean, the brief,

01:00:43.120 --> 01:00:46.480
the most recent history of machine learning, because this is, as you know, very deep.

01:00:48.160 --> 01:00:57.520
I knew Lex when he had an AI podcast. So if you look at just TensorFlow and PyTorch,

01:00:57.520 --> 01:01:02.320
which is pretty recent history in the big picture, right? But TensorFlow is all about graphs.

01:01:02.960 --> 01:01:08.080
PyTorch, I think, pretty unarguably ended up winning. And why did it win? Mostly because

01:01:08.080 --> 01:01:12.400
of usability, right? And the usability of PyTorch is, I think, huge. And I think, again,

01:01:12.400 --> 01:01:18.560
that's a huge testament to the power of taking abstract theoretical technical concepts and bring

01:01:18.560 --> 01:01:24.400
it to the masses, right? Now, the challenge with what the TensorFlow versus the PyTorch

01:01:24.560 --> 01:01:30.400
design points was that TensorFlow is kind of difficult to use for researchers, but it was

01:01:30.400 --> 01:01:34.320
actually pretty good for deployment. PyTorch is really good for researchers. It kind of

01:01:34.320 --> 01:01:40.080
not super great for deployment, right? And so I think that we as an industry have been struggling.

01:01:40.080 --> 01:01:44.560
And if you look at what deploying a machine learning model today means is that you'll have

01:01:44.560 --> 01:01:50.160
researchers who are, I mean, wicked smart, of course, but they're wicked smart at model architecture

01:01:50.160 --> 01:01:56.400
and data and calculus. They're wicked smart in various domains. They don't want to know anything

01:01:56.400 --> 01:02:00.800
about the hardware or deployment or C++ or things like this, right? And so what's happened is you

01:02:00.800 --> 01:02:05.200
get people who train the model, they throw it over the fence, and then you have people that

01:02:05.200 --> 01:02:12.640
try to deploy the model. Well, every time you have a team A does X, they throw it over the fence,

01:02:12.640 --> 01:02:19.840
and team B does Y, you have a problem. Because, of course, it never works the first time.

01:02:20.000 --> 01:02:24.000
And so you throw it over the fence, they figure out, okay, it's too slow, won't fit,

01:02:24.560 --> 01:02:30.800
doesn't use the right operator, the tool crashes, whatever the problem is, then they have to throw

01:02:30.800 --> 01:02:35.520
it back over the fence. And every time you throw a thing over a fence, it takes three weeks of

01:02:35.520 --> 01:02:40.400
project managers and meetings and things like this. And so what we've seen today is that getting

01:02:40.400 --> 01:02:45.280
models in production can take weeks or months. Like it's not atypical, right? I talked to lots

01:02:45.280 --> 01:02:50.480
of people and you talk about like VP of software at some internet company trying to deploy a model,

01:02:50.480 --> 01:02:56.480
and they're like, why do I need a team of 45 people? It's so easy to train a model, why can't I

01:02:56.480 --> 01:03:03.120
deploy it, right? And if you dig into this, every layer is problematic. So if you look at the language

01:03:03.120 --> 01:03:07.600
piece, I mean, this is tip of the iceberg. It's a very exciting tip of the iceberg for folks, but

01:03:08.160 --> 01:03:13.520
you've got Python on one side and C++ on the other side. Python doesn't really deploy. I mean,

01:03:13.600 --> 01:03:17.680
can theoretically, technically in some cases, but often a lot of production teams will want to get

01:03:17.680 --> 01:03:21.680
things out of Python because they get their performance and control and whatever else. So

01:03:21.680 --> 01:03:28.080
Mojo can help with that. If you look at serving, so you talk about gigantic models, well, a gigantic

01:03:28.080 --> 01:03:34.640
model won't fit on one machine, right? And so now you have this model, it's written Python, it has

01:03:34.640 --> 01:03:39.120
to be rewritten in C++. Now it also has to be carved up so that half of it runs on one machine,

01:03:39.120 --> 01:03:45.280
half of it runs on another machine, or maybe it runs on 10 machines. So now suddenly, the complexity

01:03:45.280 --> 01:03:51.360
is exploding, right? And the reason for this is that if you look into TensorFlow, PyTorps, these

01:03:51.360 --> 01:03:56.320
systems, they weren't really designed for this world, right? They were designed for, you know,

01:03:56.320 --> 01:04:01.360
back in the day when we were starting and doing things where it was a different, much simpler

01:04:01.360 --> 01:04:06.560
world, like you want to run ResNet 50 or some ancient model architecture like this. It was just a,

01:04:06.560 --> 01:04:08.000
it was a completely different world.

01:04:08.000 --> 01:04:10.000
Trained on 1GPU. Exactly.

01:04:10.000 --> 01:04:11.360
Doing some 1GPU.

01:04:11.360 --> 01:04:18.080
Yeah, AlexNet, right? The major breakthrough. And the world has changed, right? And so now the

01:04:18.080 --> 01:04:21.920
challenge is that TensorFlow, PyTorps, these systems, they weren't actually designed for

01:04:21.920 --> 01:04:28.400
LLMs. That was not a thing. And so where TensorFlow actually has amazing power in terms of scale and

01:04:28.400 --> 01:04:33.040
deployment and things like that. And I think Google is, I mean, maybe not unmatched, but they're

01:04:33.280 --> 01:04:40.160
incredible in terms of their capabilities and gigantic scale. Many researchers using PyTorps,

01:04:40.160 --> 01:04:43.440
right? And so PyTorps doesn't have those same capabilities. And so what Modular can do is

01:04:43.440 --> 01:04:48.000
it can help with that. Now, if you take a step back and say like, what is Modular doing, right?

01:04:48.000 --> 01:04:54.400
So Modular has like a bitter enemy that we're fighting against in the industry. And it's one

01:04:54.400 --> 01:05:00.160
of these things where everybody knows it, but nobody is usually willing to talk about it.

01:05:00.800 --> 01:05:02.240
The bitter enemy.

01:05:02.240 --> 01:05:06.960
The bitter thing that we have to destroy, that we're all struggling with, and it's like fish

01:05:06.960 --> 01:05:12.960
can't see water, is complexity. Sure. Yes. It's complexity. That was very close.

01:05:14.880 --> 01:05:18.640
And so if you look at it, yes, it is on the hardware side. Yes.

01:05:18.640 --> 01:05:22.160
All these accelerators, all these software stacks that go with the accelerator,

01:05:22.160 --> 01:05:27.840
all these massive complexity over there. You look at what's happening on the modeling side,

01:05:28.480 --> 01:05:31.680
massive amount of complexity. Like things are changing all the time. People are inventing,

01:05:31.680 --> 01:05:35.840
turns out the research is not done, right? And so people want to be able to move fast.

01:05:35.840 --> 01:05:40.560
Transformers are amazing, but there's a ton of diversity even within transformers. And what's

01:05:40.560 --> 01:05:46.800
the next transformer, right? And you look into serving also huge amounts of complexity. It turns

01:05:46.800 --> 01:05:52.080
out that all the cloud providers, right, have all their very weird, but very cool hardware for

01:05:52.080 --> 01:05:56.160
networking and all this kind of stuff. And it's all very complicated. People aren't using that.

01:05:56.240 --> 01:06:01.360
You look at classical serving, right? There's this whole world of people who know how to write

01:06:01.360 --> 01:06:05.280
high-performance servers with zero-copy networking and like all this fancy,

01:06:06.160 --> 01:06:10.480
asynchronous I.O. and like all these fancy things in the serving community,

01:06:11.280 --> 01:06:15.680
very little that has pervaded into the machine learning world, right? And why is that? Well,

01:06:15.680 --> 01:06:20.640
it's because, again, these systems have been built up over many years. They haven't been

01:06:20.640 --> 01:06:25.040
rethought. There hasn't been a first principles approach to this. And so what Modular's doing is

01:06:25.040 --> 01:06:30.720
we're saying, okay, we've built many of these things. So I've worked on TensorFlow and TPUs

01:06:30.720 --> 01:06:35.440
and things like that. Other folks on our team have worked on PyTorch core. We've worked on

01:06:35.440 --> 01:06:41.040
Onyx one time. We've worked on many of these other systems. And so systems like the Apple

01:06:41.040 --> 01:06:46.480
accelerators and all that kind of stuff, our team is quite amazing. And so one of the things that

01:06:47.120 --> 01:06:51.600
roughly everybody at Modular's grumpy about is that when you're working on one of these projects,

01:06:51.680 --> 01:06:57.440
you have a first order goal, get the hardware to work, get the system to enable one more model,

01:06:57.440 --> 01:07:02.880
get this product out the door, enable this specific workload or solve this problem for

01:07:02.880 --> 01:07:07.840
this product team, right? And nobody's been given a chance to actually do that step back.

01:07:07.840 --> 01:07:12.320
And so we as an industry, we didn't take two steps forward. We took like 18 steps forward

01:07:12.320 --> 01:07:16.480
in terms of all this really cool technology across compilers and systems and runtimes and

01:07:16.480 --> 01:07:19.840
heterogeneous computing, like all this kind of stuff. And like all this technology has been,

01:07:20.720 --> 01:07:25.760
you know, I wouldn't say beautifully designed, but it's been proven in different quadrants.

01:07:25.760 --> 01:07:31.920
Like, you know, you look at Google with TPUs, massive, huge exoflops of compute strapped

01:07:31.920 --> 01:07:36.240
together into machines that researchers are programming in Python in a notebook.

01:07:36.880 --> 01:07:40.960
That's huge. That's amazing. That's incredible, right? It's incredible. And so you look at the

01:07:40.960 --> 01:07:46.400
technology that goes into that. And the algorithms are actually quite general. And so

01:07:47.120 --> 01:07:51.040
lots of other hardware out there and lots of other teams out there don't have the sophistication

01:07:51.040 --> 01:07:56.960
or maybe the years working on it or the budget or whatever that Google does, right? And so

01:07:56.960 --> 01:08:00.240
they should be getting access to the same algorithms, but they just don't have that, right?

01:08:00.240 --> 01:08:05.920
And so what Modular's doing is we're saying, cool, this is not research anymore. Like, we've built

01:08:05.920 --> 01:08:10.720
auto tuning in many systems. We've built programming languages, right? And so like have,

01:08:10.720 --> 01:08:14.960
have, you know, implemented C++ have implemented Swift have implemented many of these things.

01:08:14.960 --> 01:08:21.680
And so, you know, it's hard, but it's not research. And you look at accelerators. Well,

01:08:21.680 --> 01:08:26.400
we know there's a bunch of different weird kind of accelerators, but they actually cluster together,

01:08:27.040 --> 01:08:31.360
right? And you look at GPUs. Well, there's a couple of major vendors of GPUs, and they maybe

01:08:31.360 --> 01:08:36.080
don't always get along, but their architectures are very similar. You look at CPUs. CPUs are

01:08:36.080 --> 01:08:40.720
still super important for the deployment side of things. And you see new, new architectures coming

01:08:40.720 --> 01:08:44.160
out from all the cloud providers and things like this, and they're all super important

01:08:44.160 --> 01:08:49.040
to the world, right? But they don't have the 30 years of development that the entrenched people

01:08:49.040 --> 01:08:54.880
do, right? And so what Modular can do is we're saying, okay, all this complexity, like, it's not,

01:08:54.880 --> 01:09:01.280
it's not bad complexity. It's actually innovation, right? And so it's innovation that's happening.

01:09:01.280 --> 01:09:06.640
And it's for good reasons. But I have sympathy for the poor software people, right? I mean, again,

01:09:06.640 --> 01:09:11.120
I'm generally a software person too, I love hardware. But software people want to build

01:09:11.120 --> 01:09:16.560
applications and products and solutions that scale over many years. They don't want to build a

01:09:16.560 --> 01:09:21.360
solution for one generation of hardware with one vendor's tools. Right? And because of this,

01:09:21.360 --> 01:09:26.480
they need something that scales with them, they need something that works on cloud and mobile,

01:09:27.600 --> 01:09:31.600
right? Because, you know, their product manager said, Hey, I want to be at have lower latency,

01:09:32.160 --> 01:09:36.800
it's better for personalization or whatever they decide, right? Products evolve. And so

01:09:37.440 --> 01:09:40.880
the challenge with the machine learning technology and the infrastructure we have today,

01:09:40.880 --> 01:09:45.680
in the industry, is that it's all these point solutions. And because they're all these point

01:09:45.680 --> 01:09:49.280
solutions, it means that as your product evolves, you have to like switch different technology

01:09:49.280 --> 01:09:53.280
stacks or switch to different vendor. And what that does is that slows down progress.

01:09:54.080 --> 01:10:01.760
So basically, a lot of the things we've developed in those little silos for machine learning tasks,

01:10:01.760 --> 01:10:06.000
you want to make that the first class citizen of a general purpose programming language,

01:10:06.000 --> 01:10:08.560
they can then be compiled across all these kinds of hardware.

01:10:08.560 --> 01:10:11.920
Well, so it's not really about a programming language. I mean, the program language is a

01:10:11.920 --> 01:10:17.200
component of the mission, right? And the mission is are not literal, but our joking mission is to

01:10:17.200 --> 01:10:23.840
save the world from terrible AI software. Excellent. Okay. So, so, you know, if you look at this

01:10:23.840 --> 01:10:30.240
mission, you need a syntax. So that's the so yeah, she need a program language, right? And and like,

01:10:30.240 --> 01:10:34.480
we wouldn't have to build the programming language if one existed. Right? So if Python was already

01:10:34.480 --> 01:10:38.720
good enough, then cool, we would just used it, right? We're not just doing very large scale

01:10:38.720 --> 01:10:43.680
expensive engineering projects for the sake of it, like, it's to solve a problem, right? It's also

01:10:43.680 --> 01:10:51.280
about accelerators. It's also about exotic numerics and b-float 16 and matrix multiplications and

01:10:51.280 --> 01:10:56.400
convolutions and like this, this kind of stuff. Within the stack, there are things like kernel

01:10:56.400 --> 01:11:02.000
fusion. It's a esoteric but really important thing that leads to much better performance

01:11:02.000 --> 01:11:08.960
and much more general research hackability together, right? And that's enabled by the ASICS,

01:11:08.960 --> 01:11:12.480
that's enabled by certain hardware. So it's like, where's the dance between

01:11:14.480 --> 01:11:17.760
I mean, there's several questions here, like, how do you add a piece of hardware to this stack?

01:11:18.320 --> 01:11:24.800
Yeah. If you need pieces, like if I have this genius invention of a specialized accelerator,

01:11:24.800 --> 01:11:29.920
how do I add that to the modular framework? And also, how does modular as a standard

01:11:30.640 --> 01:11:35.040
start to define the kind of hardware that should be developed?

01:11:35.040 --> 01:11:41.120
Yeah. So let me take a step back and talk about status quo. Okay. And so if you go back to TensorFlow

01:11:41.120 --> 01:11:47.360
1, PyTorch 1, this kind of timeframe, and these have all evolved and gotten way more

01:11:47.360 --> 01:11:52.720
complicated. So let's go back to the glorious simple days, right? These things basically were CPUs and

01:11:52.720 --> 01:11:59.040
CUDA. And so what you do is you say, go do a dense layer and a dense layer has a matrix

01:11:59.040 --> 01:12:03.360
multiplication, right? And so when you say that, you say, go do this big operation,

01:12:03.360 --> 01:12:09.200
a matrix multiplication. And if it's on a GPU, kick off CUDA kernel, if it's on a CPU, go do

01:12:10.640 --> 01:12:13.760
like an Intel algorithm or something like that with the Intel MKL. Okay.

01:12:14.560 --> 01:12:21.120
Now, that's really cool. If you're either video or Intel, right? But then more hardware comes in.

01:12:22.160 --> 01:12:26.640
Right. And on one axis, you have more hardware coming in. On the other hand, you have

01:12:26.640 --> 01:12:31.840
an explosion of innovation in AI. And so what happened with both TensorFlow and PyTorch is that

01:12:31.840 --> 01:12:36.640
the explosion of innovation in AI has led to, it's not just about matrix multiplication and

01:12:36.640 --> 01:12:41.360
convolution. These things have now like 2,000 different operators. And on the other hand,

01:12:41.360 --> 01:12:44.400
you have, I don't know how many pieces of hardware there are there, it's a lot.

01:12:45.440 --> 01:12:51.760
It's not even hundreds, it's probably thousands. Okay. And across all the edge and across all the

01:12:51.760 --> 01:12:57.520
different things that are used at scale. Yeah, exactly. I mean, it's not just like everywhere.

01:12:57.520 --> 01:13:03.040
Yeah. It's not a handful of TPU alternatives. Correct. It's every phone, often with many

01:13:03.040 --> 01:13:10.000
different chips inside of it from different vendors. Right. Like it's, AI is everywhere.

01:13:10.000 --> 01:13:13.760
It's a thing, right? Why are they all making their own chips? Like, why is everybody making

01:13:13.760 --> 01:13:18.880
their own thing? Well, so because, was that a good thing? First of all, so Chris's philosophy on

01:13:18.880 --> 01:13:25.440
hardware. Yeah. Right. So my philosophy is that there isn't one right solution. Right. And so I

01:13:25.440 --> 01:13:30.400
think that, again, we're at the end of Moore's Law, specialization happens. Yeah. If you're

01:13:30.400 --> 01:13:37.280
building, if you're training GPT-5, he wants some crazy supercomputer data center thingy.

01:13:37.920 --> 01:13:42.800
If you're making a smart camera that runs on batteries, you want something that looks very

01:13:42.800 --> 01:13:46.240
different. If you're building a phone, you want something that looks very different. If you have

01:13:46.320 --> 01:13:51.040
something like a laptop, you want something that looks maybe similar, but a different scale. Right.

01:13:51.040 --> 01:13:56.560
And so AI ends up touching all of our lives, robotics. Right. And like, lots of different

01:13:56.560 --> 01:14:01.440
things. And so as you look into this, these have different power envelopes. There's different

01:14:01.440 --> 01:14:05.600
trade-offs in terms of the algorithms. There's new innovations in sparsity and other data formats

01:14:05.600 --> 01:14:10.880
and things like that. And so hardware innovation, I think is a really good thing. Right. And what

01:14:10.880 --> 01:14:14.640
I'm interested in is unlocking that innovation. There's also like analog and quantum and like,

01:14:14.640 --> 01:14:20.720
although the really weird stuff. Right. And so if somebody can come up with a chip that uses

01:14:20.720 --> 01:14:25.440
analog computing and it's 100x more power efficient, I think what that would mean in terms of the

01:14:25.440 --> 01:14:32.080
daily impact on the products we use, that'd be huge. Now, if you're building an analog computer,

01:14:32.080 --> 01:14:37.120
you may not be a compiler specialist. Right. These are different skill sets. Right. And so

01:14:37.120 --> 01:14:41.200
you can hire some compiler people if you're running a big company, maybe. But it turns out

01:14:41.920 --> 01:14:47.920
these are really like exotic new generation of compilers. Like this is a different thing. Right.

01:14:47.920 --> 01:14:52.640
And so if you take a step back out and come back to it, what is the status quo? The status quo is

01:14:52.640 --> 01:14:58.000
that if you're Intel or you're Nvidia, you continue to keep up with the industry and you chase and,

01:14:58.000 --> 01:15:02.960
okay, there's 1900 now. There's 2000 now. There's 2100. And you have a huge team of people that

01:15:02.960 --> 01:15:07.840
are like trying to keep up and tune and optimize. And even when one of the big guys comes out with

01:15:07.840 --> 01:15:12.560
a new generation of their chip, they have to go back and rewrite all these things. Right. So really,

01:15:12.560 --> 01:15:17.120
it's only powered by having hundreds of people that are all like frantically trying to keep up.

01:15:17.120 --> 01:15:21.120
And what that does is that keeps out the little guys. And sometimes they're not so little guys,

01:15:21.120 --> 01:15:28.000
the big guys that are also just not in those dominant positions. And so what has been happening,

01:15:28.000 --> 01:15:32.560
and so a lot of you talk about the rise of new exotic crazy accelerators is people have been

01:15:32.560 --> 01:15:37.520
trying to turn this from a let's go write lots of special kernels problem into a compiler problem.

01:15:38.560 --> 01:15:43.760
And so we and I contributed to this as well. We as an industry went into it like let's go make

01:15:43.760 --> 01:15:49.200
this compiler problem phase, let's call it. And much of the industry is still in this phase,

01:15:49.200 --> 01:15:53.920
by the way. So I wouldn't say this phase is over. And so the idea is to say, look, okay,

01:15:54.640 --> 01:15:58.160
what a compiler does is it provides a much more general, extensible,

01:16:00.000 --> 01:16:07.360
hackable interface for dealing with the general case. Right. And so within machine

01:16:07.360 --> 01:16:11.600
learning algorithms, for example, people figured out that, hey, if I do a matrix multiplication,

01:16:11.600 --> 01:16:19.440
I do a value, right, the classic activation function, it is way faster to do one pass over

01:16:19.440 --> 01:16:24.400
the data and then do the value on the output, where I'm writing out the data, because really,

01:16:24.400 --> 01:16:30.800
it's just a maximum operation, right, max is zero. And so it's an amazing optimization, take

01:16:30.800 --> 01:16:36.400
map more value, squish together one operation, now I have map more value. Well, wait a second,

01:16:36.400 --> 01:16:40.160
if I do that, now I just went from having, you know, two operators to three.

01:16:40.800 --> 01:16:44.000
But now I figure out, okay, well, there's a lot of activation functions. What about

01:16:45.680 --> 01:16:50.720
leaky value? What about like a million things that are out there, right. And so as I start fusing

01:16:50.720 --> 01:16:55.120
these in, now I get permutations of all these algorithms, right. And so what the compiler

01:16:55.120 --> 01:16:59.280
people said is they said, hey, cool, I will go enumerate all the algorithms and I will enumerate

01:16:59.280 --> 01:17:04.000
all the pairs and I will actually generate a kernel for you. And I think that this has been very,

01:17:04.000 --> 01:17:07.280
very useful for the industry. This is one of the things that powers Google TPUs,

01:17:08.000 --> 01:17:12.800
PyTorch 2s, like rolling out really cool compiler stuff with Triton, this other technology and

01:17:12.800 --> 01:17:17.440
things like this. And so the compiler people are kind of coming into their fore and saying like,

01:17:17.440 --> 01:17:22.720
awesome, this is a compiler problem, we'll compiler it. Here's the problem. Not everybody's

01:17:22.720 --> 01:17:27.040
a compiler person. I love compiler people, trust me, right, but not everybody can or should be a

01:17:27.040 --> 01:17:31.760
compiler person. It turns out that there are people that know analog computers really well,

01:17:31.840 --> 01:17:37.600
or they know some GPU internal architecture thing really well, or they know some crazy, sparse,

01:17:37.600 --> 01:17:43.520
numeric, interesting algorithm that is the cusp of research, but they're not compiler people.

01:17:43.520 --> 01:17:47.600
And so one of the challenges with this new wave of technology trying to turn everything into a

01:17:47.600 --> 01:17:53.760
compiler is again, it is excluded a ton of people. And so you look at what does Mojo do, what does

01:17:53.760 --> 01:17:59.440
the modular stack do is brings programmability back into this world, like it enables, I wouldn't

01:17:59.440 --> 01:18:04.880
say normal people, but a different kind of delightful nerd that cares about numerics or

01:18:04.880 --> 01:18:08.880
cares about hardware or cares about things like this to be able to express that in the stack and

01:18:08.880 --> 01:18:14.800
extend the stack without having to actually go hack the compiler itself. So extend the stack on the

01:18:14.800 --> 01:18:20.560
algorithm side, and then on the hardware side. Yeah, so again, go back to the simplest example

01:18:20.560 --> 01:18:26.560
of int. And so both Swift and Mojo and other things like this did is we said, okay, pull magic out of

01:18:26.560 --> 01:18:30.960
the compiler and put it in the standard library. And so what modular is doing with the engine that

01:18:30.960 --> 01:18:36.080
we're providing and like this, this very deep technology stack, right, which goes into heterogeneous

01:18:36.080 --> 01:18:42.560
runtimes and like a whole bunch of really cool, really cool things. This whole stack allows that

01:18:42.560 --> 01:18:48.160
stack to be extended and hacked and changed by researchers and by hardware innovators and by

01:18:48.160 --> 01:18:53.280
people who know things that we don't know, because you know, modular has some smart people, but we

01:18:53.280 --> 01:19:00.720
don't have all the smart people, it turns out. What are heterogeneous runtimes? Yeah, so what is

01:19:00.720 --> 01:19:05.520
heterogeneous, right? So heterogeneous means many different kinds of things together. And so

01:19:05.520 --> 01:19:11.360
the simplest example you might come up with is a CPU and a GPU. And so it's a simple heterogeneous

01:19:11.360 --> 01:19:16.720
computer to say, I will run my data loading and preprocessing and other algorithms on the CPU.

01:19:16.720 --> 01:19:20.480
And then once I get it into the right shape, I shove it into the GPU, I do a lot of matrix

01:19:20.480 --> 01:19:26.400
multiplications and convolutions and things like this. And I get it back out and I do some reductions

01:19:26.400 --> 01:19:31.200
and summaries and they shove it across the wire to across the network to another machine, right?

01:19:31.200 --> 01:19:38.320
And so you've got now what are effectively two computers, a CPU and a GPU talking to each other,

01:19:38.320 --> 01:19:46.160
working together in a heterogeneous system. But that was 10 years ago. Okay, look at a modern

01:19:46.160 --> 01:19:51.920
cell phone. Modern cell phone, you've got CPUs. And they're not just CPUs, there's like big dot

01:19:51.920 --> 01:19:56.240
little CPUs. And so there's multiple different kinds of CPUs are working together. They're

01:19:56.240 --> 01:20:02.880
multi core. You've got GPUs, you've got neural network accelerators, you got dedicated hardware

01:20:02.880 --> 01:20:07.760
blocks for for media. So for video decode and JPEG decode and things like this. And so you've

01:20:07.760 --> 01:20:11.920
got this massively complicated system. And this isn't just cell phones, every laptop these days is

01:20:11.920 --> 01:20:19.280
doing the same thing. And all these blocks can run at the same time and need to be choreographed,

01:20:19.280 --> 01:20:23.360
right? And so again, one of the cool things about machine learning is it's moving things to like

01:20:23.360 --> 01:20:28.720
data flow graphs and higher level of abstractions and tensors and these things that it doesn't specify.

01:20:28.720 --> 01:20:33.440
Here's how to do the algorithm. It gives the system a lot more flexibility in terms of how to

01:20:33.440 --> 01:20:38.320
translate or map or compile it onto the system that you have. And so what you need, you know,

01:20:38.320 --> 01:20:43.360
at the bottomest part of the layer there is a way for all these devices to talk to each other.

01:20:43.360 --> 01:20:47.760
And so this is one thing that, you know, I'm very passionate about. I mean, you know, I'm a nerd,

01:20:47.760 --> 01:20:53.600
but, but all these, all these machines and all these systems are effectively parallel computers

01:20:53.600 --> 01:20:58.160
running at the same time, sending messages to each other. And so they're all fully asynchronous.

01:20:59.040 --> 01:21:02.560
Well, this is actually a small version of the same problem you have in a data center,

01:21:03.280 --> 01:21:07.520
right? In a data center, you now have multiple different machines, sometimes very specialized,

01:21:07.520 --> 01:21:12.720
sometimes with GPUs or TPs and one node and sometimes with disks and other nodes. And so you

01:21:12.720 --> 01:21:17.520
get a much larger scale, heterogeneous computer. And so what ends up happening is you have this

01:21:17.520 --> 01:21:23.840
like multi-layer abstraction of hierarchical parallelism, hierarchical asynchronous communication

01:21:24.400 --> 01:21:30.560
and making that again, the enemy, my enemy is complexity by getting that away from being

01:21:30.560 --> 01:21:34.640
different specialized systems at every different part of the stack and having more consistency

01:21:34.640 --> 01:21:39.600
and uniformity. I think we can help lift the world and make it much simpler and actually get used.

01:21:39.600 --> 01:21:43.520
But how do you leverage like the strengths of the different specialized systems? So we're looking

01:21:43.520 --> 01:21:48.560
inside the smartphone. Yeah. Like there's just what I don't know, five, six computers essentially

01:21:48.560 --> 01:21:58.080
inside a smartphone. How do you, without trying to minimize the explicit, making it explicit,

01:21:58.080 --> 01:22:00.480
which, which computer is supposed to be used for which operation?

01:22:00.480 --> 01:22:04.400
Yeah. So there's, there's a pretty well known algorithm. And what you're doing is you're looking

01:22:04.480 --> 01:22:08.960
at two, two factors. You're looking at the factor of sending data from one thing to another.

01:22:08.960 --> 01:22:12.000
Right. So it takes time to get it from that side of the chip to that side of the chip

01:22:12.000 --> 01:22:15.840
and things like this. And then you're looking at what is the time it takes to do

01:22:15.840 --> 01:22:22.880
an operation on a particular block. So take CPUs. CPUs are fully general. They can do anything.

01:22:22.880 --> 01:22:27.280
Right. But then you have a neural net accelerator that's really good at matrix multiplications.

01:22:27.280 --> 01:22:31.120
Okay. And so you say, okay, well, if my workload is all matrix multiplications,

01:22:31.680 --> 01:22:36.080
I start up, I send the data over the neural net thing, it goes and does matrix multiplications,

01:22:36.080 --> 01:22:40.560
when it's done, it sends me back the result, all is good. Right. And so the simplest thing is just

01:22:40.560 --> 01:22:46.400
saying, do matrix, do matrix operations over there. Right. But then you realize you get a little bit

01:22:46.400 --> 01:22:50.160
more complicated because you can do matrix multiplications on a GPU, you can do it on

01:22:51.520 --> 01:22:56.080
a neural net accelerator, you can do it on CPU, and they'll have different tradeoffs and costs.

01:22:56.080 --> 01:23:00.320
And it's not just matrix multiplication. And so what you actually look at is you look at,

01:23:00.400 --> 01:23:06.240
I have generally a graph of compute. I want to do a partitioning. I want to look at the communication,

01:23:06.960 --> 01:23:10.960
the bisection bandwidth and like the overhead and the sending of all these different things and

01:23:11.680 --> 01:23:15.840
build a model for this and then decide, okay, it's an optimization problem. Where do I want to

01:23:15.840 --> 01:23:22.720
place this compute? So the old school theoretical computer science problem of scheduling. And then

01:23:22.720 --> 01:23:29.120
how does presumably it's possible to somehow magically include auto tune into this?

01:23:30.400 --> 01:23:36.320
Absolutely. So I mean, in my opinion, this is an opinion, this is not, not everybody would agree

01:23:36.320 --> 01:23:41.920
with this, but in my opinion, the world benefits from simple and predictable systems at the bottom

01:23:41.920 --> 01:23:47.600
that you can control. But then once you have a predictable execution layer, you can build

01:23:47.600 --> 01:23:51.440
lots of different policies on top of it. Right. And so one policy can be that

01:23:52.480 --> 01:23:57.600
the human programmer says, do that here, do that here, do that here, do that here and like

01:23:57.600 --> 01:24:03.280
fully manually controls everything. And the systems just do it. Right. Then you quickly

01:24:03.280 --> 01:24:07.440
get in the mode of like, I don't want to have to tell it to do it. Yeah. And so the next logical

01:24:07.440 --> 01:24:12.160
step that people typically take, because they write some terrible heuristic, if it's a major

01:24:12.160 --> 01:24:15.360
small location, do it over there. Or if it's floating point, do it on the GPU, if it's integer,

01:24:15.360 --> 01:24:20.720
do it on the CPU, like something like that. Right. And, and then you then get into this

01:24:20.720 --> 01:24:23.280
mode of like people care more and more and more and you say, okay, well, let's actually

01:24:24.160 --> 01:24:30.560
like make the heuristic better. Let's get into auto tint. Let's actually do a search of the space

01:24:31.120 --> 01:24:36.880
to decide, well, what is actually better? Right. Well, then you get into this problem where you

01:24:36.880 --> 01:24:42.880
realize this is not a small space. This is a many dimensional, hyper dimensional space that you

01:24:42.880 --> 01:24:47.840
cannot exhaustively search. So do you know of any algorithms that are good at searching very

01:24:47.840 --> 01:24:53.120
complicated spaces for? Don't tell me you're going to turn this into a machine learning problem.

01:24:53.360 --> 01:24:57.440
So then you turn into a machine learning problem. And then you have a space of generic algorithms

01:24:57.440 --> 01:25:02.000
and reinforcement learning and like all these, all these, can you include that into the stack,

01:25:02.000 --> 01:25:06.320
into the, into the module stack? Yeah. Yeah. And where does it sit? Where does it live?

01:25:06.320 --> 01:25:10.320
Is it a separate thing or is it part of the compilation? So you start from simple and

01:25:10.320 --> 01:25:15.600
predictable models. And so you can have full control and you can have coarse grain knobs

01:25:15.600 --> 01:25:20.080
that like nudge, nudge systems, you don't have to do this. But if you really care about getting

01:25:20.160 --> 01:25:25.200
the best, you know, the last ounce out of a problem, then you can use additional tools.

01:25:25.200 --> 01:25:28.960
And they're the cool thing is you don't want to do this every time you run a model. You want to

01:25:28.960 --> 01:25:33.120
figure out the right answer and then cash it. And once you do that, you can get,

01:25:33.120 --> 01:25:38.880
you can say, okay, cool, I can get up and running very quickly. I can get good execution out of my

01:25:38.880 --> 01:25:43.360
system. I can decide if something's important. And if it's important, I can go throw a bunch of

01:25:43.360 --> 01:25:47.680
machines at it and do a big expensive search over the space using whatever technique I feel like

01:25:47.680 --> 01:25:52.080
it's probably up to the problem. And then when I get the right answer, cool, I can just start using

01:25:52.080 --> 01:25:58.000
it. And so you can get out of this, this trade off between, okay, am I going to like spend forever

01:25:58.000 --> 01:26:02.240
doing a thing or do I get up and running quickly? And as a quality result, like these, these are

01:26:02.240 --> 01:26:08.720
actually not in contention with each other if the system's designed to scale. You started and did

01:26:08.720 --> 01:26:16.960
a little bit of a whirlwind overview of how you get the 35,000 X speed up or more over Python.

01:26:17.840 --> 01:26:22.320
Jeremy Howard did a really great presentation about sort of the basic, like looking at the code,

01:26:22.320 --> 01:26:26.800
here's how you get the speed up. Like you said, that's something we could probably developers

01:26:26.800 --> 01:26:32.400
can do for their own code to see how you can get these gigantic speed up. But can you maybe speak

01:26:32.400 --> 01:26:36.000
to the machine learning tasks in general? How do you, how do you make some of this code fast,

01:26:36.000 --> 01:26:45.440
some specifics like what would you say is the main bottleneck for machine learning tasks? So are we

01:26:45.440 --> 01:26:50.240
talking about metmall, matrix multiplication, how do you make that fast?

01:26:50.240 --> 01:26:54.960
So I mean, if you just look at the Python problem, right, you can say, how do I make Python faster?

01:26:55.840 --> 01:26:59.840
There's been a lot of people that have been working on the, okay, how do I make Python 2x faster,

01:26:59.840 --> 01:27:03.360
10x faster or something like that, right? And there've been a ton of projects in that vein,

01:27:03.360 --> 01:27:09.680
right? Mojo started from the, what can the hardware do? Like what is the limit of physics?

01:27:09.680 --> 01:27:13.440
Yeah, what is the speed of light? What is it? Like how fast can this thing go? And then

01:27:14.080 --> 01:27:18.880
how do I express that? Yeah, right. And so it wasn't, it wasn't anchored relatively on

01:27:18.880 --> 01:27:22.720
make Python a little bit faster. It's saying, cool, I know what the hardware can do. Let's

01:27:22.720 --> 01:27:29.120
unlock that, right? Now, when you, wait, and just say how, how gutsy that is to be in the meeting,

01:27:29.120 --> 01:27:33.040
and as opposed to trying to see how do we get the improvement? It's like, what can the physics do?

01:27:34.000 --> 01:27:38.560
I mean, maybe I'm a special kind of nerd, but you look at that, what is the limit of physics,

01:27:38.560 --> 01:27:43.280
how fast can these things go, right? When you start looking at that, typically,

01:27:43.280 --> 01:27:48.560
it ends up being a memory problem, right? And so today, particularly with these specialized

01:27:48.560 --> 01:27:54.160
accelerators, the problem is that you can do a lot of math within them, but yet you get bottleneck

01:27:54.160 --> 01:28:00.240
sending data back and forth to memory, whether it be local memory or distant memory or disk or

01:28:00.240 --> 01:28:05.840
whatever it is. And that bottleneck, particularly as the training sizes get large, as you start

01:28:05.840 --> 01:28:10.560
doing tons of inferences all over the place, like that becomes a huge bottleneck for people,

01:28:10.560 --> 01:28:16.000
right? So again, what happened is we went through a phase of many years where people

01:28:16.000 --> 01:28:20.080
took the special case and hand tuned it and tweaked it and tricked it out and they knew

01:28:20.080 --> 01:28:22.960
exactly how the hardware worked and they knew the model and they made it, they made it fast.

01:28:23.920 --> 01:28:29.440
Didn't generalize. And so you can make, you know, ResNet 50 or some, or AlexNet or something,

01:28:29.440 --> 01:28:34.000
Inception V1, like you can, you can do that, right? Because the models are small, they fit in your

01:28:34.000 --> 01:28:39.280
head, right? But as the models get bigger, more complicated, as the machines get more complicated,

01:28:39.280 --> 01:28:44.800
it stops working, right? And so this is where things like kernel fusion come in. So what is

01:28:44.800 --> 01:28:49.760
kernel fusion? This is this idea of saying, let's avoid going to memory. And let's do that by building

01:28:49.760 --> 01:28:58.160
a new hybrid kernel and a numerical algorithm that actually keeps things in the accelerator

01:28:58.160 --> 01:29:02.800
instead of having to write it all the way out to memory. What's happened with these accelerators

01:29:02.800 --> 01:29:06.880
now is you get multiple levels of memory. Like in a GPU, for example, you'll have global memory

01:29:06.880 --> 01:29:13.600
and local memory and like all these things. If you zoom way into how hardware works,

01:29:13.600 --> 01:29:19.600
the register file is actually a memory. So the registers are like an L0 cache. And so

01:29:19.600 --> 01:29:25.760
a lot of taking advantage of the hardware ends up being fully utilizing the full power

01:29:26.720 --> 01:29:31.680
in all of its capability. And this has a number of problems, right? One of which is,

01:29:31.680 --> 01:29:36.240
again, the complexity disaster, right? There's too much hardware. Even if you just say, let's look at

01:29:37.040 --> 01:29:40.960
the chips from one line of vendor like Apple or Intel or whatever it is,

01:29:41.760 --> 01:29:46.160
each version of the chip comes out with new features. And they change things so that it

01:29:46.160 --> 01:29:49.920
takes more time or less time to do different things. And you can't rewrite all the software

01:29:49.920 --> 01:29:54.400
whenever a new chip comes in, right? And so this is where you need a much more scalable approach.

01:29:54.400 --> 01:29:59.520
And this is what Mojo and what the modular stack provides is it provides this infrastructure and

01:29:59.520 --> 01:30:04.080
the system for factoring all this complexity and then allowing people to express algorithms.

01:30:04.080 --> 01:30:09.040
You talk about auto tuning, for example, express algorithms in a more portable way

01:30:09.040 --> 01:30:12.400
so that when a new chip comes out, you don't have to rewrite it all.

01:30:13.440 --> 01:30:18.400
So to me, like, you know, I kind of joke like, what is a compiler? Well, there's many ways to

01:30:18.400 --> 01:30:23.520
explain that. You convert thing A into thing B, and you convert source code to machine code.

01:30:23.520 --> 01:30:30.000
Like you can talk about many, many things that compilers do. But to me, it's about a bag of tricks.

01:30:30.640 --> 01:30:36.320
It's about a system and a framework that you can hang complexity. It's a system that can then

01:30:36.320 --> 01:30:39.840
generalize and it can work on problems that are bigger than fit in one human's head,

01:30:40.960 --> 01:30:45.680
right? And so what that means, what a good stack and what the modular stack provides is

01:30:46.240 --> 01:30:50.080
the ability to walk up to it with a new problem and it'll generally work quite well.

01:30:50.880 --> 01:30:53.760
And that's something that a lot of machine learning infrastructure and tools and

01:30:53.760 --> 01:30:58.560
technologies don't have. Typical state of the art today is you walk up, particularly if you're

01:30:58.560 --> 01:31:02.560
deploying, if you walk up with a new model, you try to push it through the converter and the converter

01:31:02.560 --> 01:31:11.280
crashes. That's crazy. The state of ML tooling today is not anything that a C programmer would

01:31:11.280 --> 01:31:16.560
ever accept, right? And it's always been this kind of flaky set of tooling that's never been

01:31:17.200 --> 01:31:22.880
integrated well and it's been never worked together because it's not designed together.

01:31:22.880 --> 01:31:26.240
It's built by different teams. It's built by different hardware vendors. It's built by different

01:31:26.240 --> 01:31:29.760
systems. It's built by different internet companies that are trying to solve their

01:31:29.760 --> 01:31:34.800
problems, right? And so that means that we get this fragmented, terrible mess of complexity.

01:31:35.840 --> 01:31:40.640
So, I mean, the specifics of, I mean, Jeremy showed this. There's the vectorized function,

01:31:40.720 --> 01:31:49.360
which I guess is built into Mojo. Vectorized as he showed is built into the library.

01:31:49.360 --> 01:31:55.760
Into the library, instead of the library. Vectorized, parallelized, which vectorizes more

01:31:55.760 --> 01:32:00.800
low level, parallelizes higher level. There's the tiling thing, which is how he demonstrated the

01:32:02.400 --> 01:32:09.520
autotune, I think. So, think about this in like levels, hierarchical levels of abstraction, right?

01:32:09.520 --> 01:32:14.160
And so, at the very, if you zoom all the way into a compute problem, you have one floating

01:32:14.160 --> 01:32:18.720
point number, right? And so, then you say, okay, I want to be, I can do things one at a time

01:32:18.720 --> 01:32:24.800
in an interpreter. It's pretty slow, right? So, I can get to doing one at a time in a compiler,

01:32:24.800 --> 01:32:31.120
I can see. Then I can get to doing four or eight or 16 at a time with vectors. That's called

01:32:31.120 --> 01:32:36.400
vectorization. Then you can say, hey, I have a whole bunch of different, you know, what a

01:32:36.400 --> 01:32:41.920
multi-core computer is, it's basically a bunch of computers, right? So, they're all independent

01:32:41.920 --> 01:32:46.560
computers that can talk to each other and they share memory. And so, now what parallelized does,

01:32:46.560 --> 01:32:51.520
it says, okay, run multiple instances on different computers. And now they can all work together

01:32:51.520 --> 01:32:55.680
on a problem, right? And so, what you're doing is you're saying, keep going out to the next level

01:32:55.680 --> 01:33:02.240
out. And as you do that, how do I take advantage of this? So, tiling is a memory optimization,

01:33:02.240 --> 01:33:06.720
right? It says, okay, let's make sure that we're keeping the data close to the compute

01:33:06.720 --> 01:33:12.080
part of the problem, instead of sending it all back and forth through memory every, every time I

01:33:12.080 --> 01:33:17.120
load a block. And the size of the block, size is all, that's how you get to the autotune to make

01:33:17.120 --> 01:33:20.720
sure it's optimized. Right. Yeah. Well, so all of these, the details matter so much to get good

01:33:20.720 --> 01:33:25.840
performance. This is another funny thing about machine learning and high performance computing

01:33:25.840 --> 01:33:31.680
that is very different than C compilers we all grew up with, where, you know, if you get a new

01:33:31.680 --> 01:33:36.240
version of GCC or a new version of Clang or something like that, you know, maybe something

01:33:36.240 --> 01:33:42.880
will go 1% faster, right? And so compiler insurers will work really, really, really hard to get half

01:33:42.880 --> 01:33:48.960
a percent out of your C code, something like that. But when you're talking about an accelerator or

01:33:48.960 --> 01:33:54.240
an AI application, or you're talking about these kinds of algorithms, and these are things people

01:33:54.240 --> 01:34:00.080
used to write in Fortran, for example, right? If you get it wrong, it's not 5% or 1%. It could

01:34:00.080 --> 01:34:07.440
be 2x or 10x. Right. If you think about it, you really want to make use of the full memory you

01:34:07.440 --> 01:34:11.920
have the cache, for example. But if you use too much space, it doesn't fit in the cache. Now you're

01:34:11.920 --> 01:34:17.440
going to be thrashing all the way back out to main memory. And these can be 2x, 10x, major

01:34:17.440 --> 01:34:21.840
performance differences. And so this is where getting these magic numbers and these things right

01:34:21.840 --> 01:34:27.280
is really actually quite important. So you mentioned that Moji is a superset of Python.

01:34:27.360 --> 01:34:42.160
Can you run Python code as if it's Mojo code? Yes. Yes. And this has two sides of it. So Mojo's not

01:34:42.160 --> 01:34:46.320
done yet. So I'll give you a disclaimer. Mojo's not done yet. But already we see people that take

01:34:46.880 --> 01:34:52.640
small pieces of Python code, move it over. They don't change it. And you can get 12x speedups.

01:34:52.720 --> 01:34:56.800
Somebody was just tweeting about that yesterday, which is pretty cool. And again,

01:34:56.800 --> 01:35:03.760
interpreters, compilers. And so without changing any code, also this is not JIT compiling or do

01:35:03.760 --> 01:35:10.000
anything fancy. This is just basic stuff. Move it straight over. Now Mojo will continue to grow

01:35:10.000 --> 01:35:14.640
out. And as it grows out, it will have more and more and more features. And our North Star is to be

01:35:14.640 --> 01:35:19.200
a full superset of Python. And so you can bring over basically arbitrary Python code and have it

01:35:19.200 --> 01:35:25.760
just work. And it may not always be 12x faster, but it should be at least as fast and way faster

01:35:25.760 --> 01:35:32.000
in many cases. This is cool. Right. Now, it will take time to do that. And Python is a complicated

01:35:32.000 --> 01:35:37.120
language. There's not just the obvious things, but there's also non-obvious things that are

01:35:37.120 --> 01:35:41.760
complicated. Like we have to be able to talk to CPython packages that talk to the C API.

01:35:41.760 --> 01:35:47.440
And there's a bunch of pieces to this. So you have to, I mean, just to make explicit,

01:35:47.440 --> 01:35:53.440
the obvious may not be so obvious until you think about it. So to run Python code, that means you

01:35:53.440 --> 01:36:02.480
have to run all the Python packages and libraries. So that means what? What's the relationship between

01:36:02.480 --> 01:36:09.360
Mojo and CPython, the interpreter that presumably would be tasked with getting those packages to

01:36:09.360 --> 01:36:15.440
work? So in the fullness of time, Mojo will solve for all the problems and you'll be able to move

01:36:15.440 --> 01:36:20.720
Python packages over and run them in Mojo. Without the CPython. Without CPython. Someday.

01:36:21.280 --> 01:36:25.760
Yeah. Right. It's not today, but someday. And that'll be a beautiful day because then you'll get

01:36:25.760 --> 01:36:28.960
a whole bunch of advantages and you'll get massive speedups and things like this.

01:36:28.960 --> 01:36:31.520
But you can do that one at a time, right? You can move packages one at a time.

01:36:31.520 --> 01:36:36.800
Exactly. But we're not willing to wait for that. Python is too important. The ecosystem is too

01:36:36.800 --> 01:36:42.640
broad. We want to both be able to build Mojo out. We also want to do it the right way without time,

01:36:43.200 --> 01:36:48.480
without intense time pressure. We're obviously moving fast. And so what we do is we say, okay,

01:36:48.480 --> 01:36:54.640
well, let's make it so you can import an arbitrary existing package, arbitrary,

01:36:55.680 --> 01:36:59.760
including you write your own on your local disk or whatever. It's not like a standard

01:36:59.760 --> 01:37:05.680
like an arbitrary package. And import that using CPython. Because CPython already runs all the

01:37:05.680 --> 01:37:11.360
packages. And so what we do is we built an integration layer where we can actually use

01:37:11.360 --> 01:37:17.760
CPython. Again, I'm practical to actually just load and use all the existing packages as they are.

01:37:18.400 --> 01:37:21.280
The downside of that is you don't get the benefits of Mojo for those packages.

01:37:21.760 --> 01:37:25.360
Right. And so they run as fast as they do in the traditional CPython way.

01:37:26.480 --> 01:37:30.480
But what that does is that gives you an incremental migration path. And so if you say,

01:37:30.480 --> 01:37:35.840
hey, cool, well, here's a, you know, the Python ecosystem is vast. I want all of it to just work.

01:37:35.840 --> 01:37:39.680
But there's certain things that are really important. And so if I, if I'm doing weather

01:37:39.680 --> 01:37:44.320
forecasting or something, well, I want to be able to load all the data. I want to be able to work

01:37:44.320 --> 01:37:48.560
with it. And then I have my own crazy algorithm inside of it. Well, normally I'd write that in

01:37:48.560 --> 01:37:54.880
C++. If I can write in Mojo and have one system that scales, well, that's way easier to work with.

01:37:54.880 --> 01:38:00.880
Is it hard to do that to have that layer that's running CPython? Because is there some

01:38:00.880 --> 01:38:06.160
communication back and forth? Yes, it's complicated. I mean, this is what we do. So I mean, we make it

01:38:06.160 --> 01:38:13.280
look easy, but it is, it is complicated. But what we do is we use the CPython existing interpreter.

01:38:13.280 --> 01:38:16.480
So it's running its own byte codes, and that's how it provides full compatibility.

01:38:17.120 --> 01:38:23.920
And then it gives us CPython objects. And we use those objects as is. And so that way,

01:38:23.920 --> 01:38:29.440
we're fully compatible with all the CPython objects and all the, you know, it's not just the

01:38:29.440 --> 01:38:33.600
Python part, it's also the C packages, the C libraries underneath them, because they're often

01:38:33.600 --> 01:38:38.000
hybrid. And so we can fully run and we're fully compatible with all that. And the way we do that

01:38:38.000 --> 01:38:43.040
is that we have to play by the rules, right? And so we keep objects in that representation

01:38:43.040 --> 01:38:47.280
when they're coming from that world. What's the representation that's being used in memory?

01:38:47.280 --> 01:38:53.200
We'd have to know a lot about how the CPython interpreter works. It has, for example, reference

01:38:53.200 --> 01:38:57.840
counting, but also different rules on how to pass pointers around and things like this. Super

01:38:57.840 --> 01:39:03.440
low level fiddly. And it's not like Python, it's like how the interpreter works. Okay. And so that

01:39:03.440 --> 01:39:08.000
gets all exposed out. And then you have to define wrappers around the low level C code.

01:39:08.560 --> 01:39:15.360
Right. And so what this means is you have to know not only C, which is a different world from Python,

01:39:15.360 --> 01:39:20.560
obviously, not only Python, but the wrappers, but the interpreter and the wrappers and the

01:39:20.560 --> 01:39:24.880
implementation details and the conventions. And it's just this really complicated mess.

01:39:24.880 --> 01:39:28.080
And when you do that, now suddenly you have a debugger that debugs Python,

01:39:28.640 --> 01:39:35.520
they can't step into C code. So you have this two world problem, right? And so by pulling this all

01:39:35.520 --> 01:39:41.200
into Mojo, what you get is you get one world. You get the ability to say, cool, I have untyped,

01:39:41.200 --> 01:39:46.560
very dynamic, beautiful, simple code. Okay, I care about performance for whatever reason, right?

01:39:46.560 --> 01:39:51.760
There's lots of reasons you could, you might care. And so then you add types, you can parallelize

01:39:51.760 --> 01:39:56.080
things, you can vectorize things, you can use these techniques, which are general techniques to

01:39:56.080 --> 01:40:02.000
solve a problem. And then you can do that by staying in the system. And if you're, you have

01:40:02.000 --> 01:40:05.920
that one Python package is really important to you, you can move it to Mojo, you get massive

01:40:05.920 --> 01:40:10.880
performance benefits on that. And other advantages, you know, if you like SAC types, it's nice if

01:40:10.880 --> 01:40:15.600
they're enforced. Some people like that, right, rather than being hints. So there's other advantages

01:40:15.600 --> 01:40:20.240
too. And then, and then you can do that incrementally as you go.

01:40:22.240 --> 01:40:30.880
So one different perspective on this will be why Mojo instead of making C Python faster,

01:40:30.880 --> 01:40:36.080
redesigning C Python. Yeah, well, I mean, you can argue Mojo is redesigning C Python,

01:40:36.080 --> 01:40:41.440
but, but, but why not make C Python faster and better and other things like that. There's lots

01:40:41.440 --> 01:40:46.640
of people working on that. So actually, there's a team at Microsoft that is really improving,

01:40:46.640 --> 01:40:52.320
I think C Python 3.11 came out in October or something like that. And it was, you know,

01:40:52.320 --> 01:40:59.680
15% faster, 20% faster across the board, which is pretty huge, given how mature Python is and

01:40:59.680 --> 01:41:07.840
things like this. And so that's awesome. I love it. Doesn't run on GPU. It doesn't do AI stuff,

01:41:07.840 --> 01:41:15.200
like it doesn't do vectors, doesn't do things. I'm 20% good, 35,000 times is better. Right. So

01:41:15.200 --> 01:41:19.600
like they're, they're, they're, they're definitely, I'm a huge fan of that work, by the way, and it

01:41:19.600 --> 01:41:23.520
composes well with what we're doing. And so it's not, it's not like we're fighting or anything

01:41:23.520 --> 01:41:27.520
like that. It's actually just general, it's goodness for the world. But it's just a different path.

01:41:27.520 --> 01:41:32.320
Right. And again, we're not working forwards from making Python a little bit better, we're working

01:41:32.880 --> 01:41:38.880
backwards from what is the limit of physics. What's the process of porting Python code to Mojo? Is

01:41:38.880 --> 01:41:46.880
there, what's involved in that, in the process? Is there tooling for that? Not yet. So we're missing

01:41:46.880 --> 01:41:50.720
some basic features right now. And so we're continuing to drop out new features, like on a

01:41:50.720 --> 01:41:57.920
weekly basis. But, you know, at the fullness of time, give us a year and a half, maybe two years.

01:41:57.920 --> 01:42:03.440
Is it an automatable process? So when we're ready, it will be very automatable. Yes.

01:42:03.440 --> 01:42:06.400
Is it automatable? Like is it possible to automate

01:42:07.680 --> 01:42:12.080
in the general case, the Python to Mojo conversion? Yeah. Well, you're saying it's possible.

01:42:12.080 --> 01:42:15.760
Well, so, and this is why, I mean, among other reasons why we use tabs.

01:42:16.560 --> 01:42:19.760
Yes. Right. So first of all, by being a superset,

01:42:19.760 --> 01:42:24.320
yeah, you can, it's like C versus C plus plus. Can you move C code to C plus plus?

01:42:24.480 --> 01:42:29.840
Yes. Yeah. Right. And you move, you can move C code to C plus plus. And

01:42:31.280 --> 01:42:35.520
then you can adopt classes, you can add, adopt templates, you can adopt other references or

01:42:35.520 --> 01:42:39.920
whatever C plus plus features you want. After you move C to C code to C plus plus,

01:42:39.920 --> 01:42:44.800
like you can't use templates in C. Right. And so if you leave it to C, fine, you can't use the

01:42:44.800 --> 01:42:48.800
cool features, but it still works. Right. And C and C plus plus could work together.

01:42:48.880 --> 01:42:58.080
And so that's the analogy. Right. Now, here, right, you, you, there's not a Python is bad and

01:42:58.080 --> 01:43:03.040
then Mojo is good. Right. Mojo just gives you superpowers. Right. And so if you want to stay

01:43:03.040 --> 01:43:08.960
with Python, that's cool. But the tooling should be actually very beautiful and simple

01:43:08.960 --> 01:43:14.560
because we're doing the hard work of defining a superset. Right. So you're right. So there's

01:43:14.640 --> 01:43:18.880
several things to say there, but also the conversion tooling should probably give you hints

01:43:18.880 --> 01:43:22.480
as to like how you can improve the code. And then exactly once you're in the new world,

01:43:22.480 --> 01:43:26.000
then you can build all kinds of cool tools to say like, Hey, should you adopt this feature?

01:43:26.000 --> 01:43:29.840
Or like, and we haven't built those tools yet, but I fully expect those tools will exist. And

01:43:29.840 --> 01:43:33.760
then you can like, you know, quote unquote modernize your code or however you want to look at it.

01:43:33.760 --> 01:43:37.680
Right. So I mean, one of the things that I think is really interesting about Mojo is that

01:43:38.320 --> 01:43:41.680
there have been a lot of projects to improve Python over the years.

01:43:42.640 --> 01:43:46.480
Everything from, you know, getting Python run on the Java virtual machine,

01:43:47.520 --> 01:43:51.360
PyPy, which is a JIT compiler, there's tons of these projects out there that have been working

01:43:51.360 --> 01:43:57.440
on improving Python in various ways. They've fallen to one of two camps. So PyPy is a great

01:43:57.440 --> 01:44:02.960
example of a camp that is trying to be compatible with Python. Even there, not really doesn't work

01:44:02.960 --> 01:44:08.160
with all the C packages and stuff like that. But but they're trying to be compatible with Python.

01:44:08.160 --> 01:44:12.240
There's also another category of these things where they're saying, well, Python is too complicated.

01:44:13.280 --> 01:44:19.040
And, you know, I'm going to cheat on the edges. And, you know, like integers in Python can be

01:44:19.040 --> 01:44:25.200
an arbitrary size integer. If you care about it fitting in a going fast on a register and a computer,

01:44:25.200 --> 01:44:30.480
that's really annoying. Right. And so you can, you can choose to pass on that. Right. You can say,

01:44:30.480 --> 01:44:34.400
well, people don't really use big integers that often. Therefore, I'm going to just not do it.

01:44:34.400 --> 01:44:40.800
And it will be fine. Not not a Python superset. Or you can do the hard thing and say, okay,

01:44:40.800 --> 01:44:47.600
this is Python. You can't be a superset of Python without being a superset of Python. And that's

01:44:47.600 --> 01:44:53.360
a really hard technical problem. But it's, in my opinion, worth it. Right. And it's worth it because

01:44:54.080 --> 01:44:58.960
it's not about anyone packages about this ecosystem. It's about what Python means for the world. And

01:44:58.960 --> 01:45:03.600
it also means we don't want to repeat the Python 2 to Python 3 transition. Like we want,

01:45:03.680 --> 01:45:08.800
we want people to be able to adopt this stuff quickly. And so by doing that work, we can help

01:45:08.800 --> 01:45:13.360
lift people. Yeah, the challenge, it's really interesting technical philosophical challenge of

01:45:14.800 --> 01:45:17.920
really making a language a superset of another language.

01:45:19.680 --> 01:45:24.240
That's breaking my brain a little bit. Well, it paints you into corners. So again,

01:45:24.240 --> 01:45:29.040
I'm very happy with Python. So joking, all joking aside, I think that the indentation thing is not

01:45:29.760 --> 01:45:35.280
the actual important part of the problem. Right. But the fact that Python has amazing

01:45:35.280 --> 01:45:39.680
dynamic metaprogramming features, and they translate to beautiful static metaprogramming

01:45:39.680 --> 01:45:45.280
features, I think is profound. I think that's huge. Right. And so Python, I've talked with Guido

01:45:45.280 --> 01:45:50.800
about this. It's like, it was not designed to do what we're doing. That was not the reason they

01:45:50.800 --> 01:45:54.400
built it this way. But because they really cared and they were very thoughtful about how they designed

01:45:54.400 --> 01:45:59.360
the language, it scales very elegantly in the space. But if you look at other languages,

01:45:59.360 --> 01:46:05.920
for example, C and C++, right, if you're building a superset, you get stuck with the

01:46:05.920 --> 01:46:13.760
design decisions of the subset. Right. And so, you know, C++ is way more complicated because

01:46:13.760 --> 01:46:18.400
of C in the legacy than it would have been if they would have theoretically designed a from

01:46:18.400 --> 01:46:24.160
scratch thing. And there's lots of people right now that are trying to make C++ better and

01:46:24.160 --> 01:46:28.560
re-syntax C++. It's going to be great. We'll just change all the syntax. But if you do that,

01:46:28.560 --> 01:46:34.080
now suddenly you have zero packages. You don't have compatibility. So what are the, if you could

01:46:34.080 --> 01:46:39.920
just linger on that, what are the biggest challenges of keeping that superset status?

01:46:41.120 --> 01:46:44.720
What are the things just struggling with? Is it all boiled down to having a big integer?

01:46:45.600 --> 01:46:50.480
No, I mean, what are the other things like? Usually it's the, it's a long tail of weird

01:46:50.480 --> 01:46:57.120
things. So let me, let me give you a war story. So war story in the space is you go way back in

01:46:57.120 --> 01:47:04.960
time. Project I worked on is called Clang. Clang, what it is, is a C C++ parser, right. And when

01:47:04.960 --> 01:47:11.200
I started working on Clang, it must have been like 2006 or something was when I, 2007, 2006,

01:47:11.200 --> 01:47:18.560
when I first started working on it, right? It's funny how time flies. I started that project

01:47:18.560 --> 01:47:25.440
and I'm like, okay, well, I want to build a C parser, C++ parser for LLVM. It's going to be

01:47:26.080 --> 01:47:32.880
the word GCC is yucky. You know, this is me in earlier times. It's yucky. It's unprincipled.

01:47:32.880 --> 01:47:38.320
It has all these weird features, like all these bugs, like it's yucky. So I'm going to build

01:47:38.320 --> 01:47:43.920
a standard compliant C and C++ parser. It's going to be beautiful. It'll be amazing. Well,

01:47:43.920 --> 01:47:48.000
engineered, all the cool things an engineer wants to do. And so I start implementing building it

01:47:48.320 --> 01:47:52.160
out, building it out, building it out. And then I got to include standard IO.h.

01:47:54.000 --> 01:47:57.120
And all of the headers in the world use all the GCC stuff.

01:47:59.920 --> 01:48:08.080
So again, come back away from theory back to reality, right? I was at a fork on the road.

01:48:08.080 --> 01:48:12.080
I could have built an amazingly beautiful academic thing that nobody would ever use.

01:48:12.400 --> 01:48:20.800
Or I could say, well, it's yucky in various ways. All these design mistakes, accents of history,

01:48:20.800 --> 01:48:26.880
the legacy at that point, GCC was like over 20 years old, which, by the way, now LLVM is over

01:48:26.880 --> 01:48:33.040
20 years old. So it's funny how time catches up to you, right? And so you say, okay, well,

01:48:34.320 --> 01:48:39.200
what is easier, right? I mean, as an engineer, it's actually much easier for me to go implement

01:48:39.840 --> 01:48:44.640
long tail compatibility weird features, even if they're distasteful, and just do the hard work

01:48:44.640 --> 01:48:48.640
and like figure it out, reverse engineer, understand what it is, write a bunch of test

01:48:48.640 --> 01:48:53.680
cases, like try to understand behavior. It's way easier to do all that work as an engineer

01:48:53.680 --> 01:48:57.360
than it is to go talk to all C programmers and get, argue with them and try to get them to

01:48:57.360 --> 01:49:04.320
rewrite their code. Yeah. Right. And because that breaks a lot more things. Yeah. And you have

01:49:04.320 --> 01:49:08.480
realities like nobody actually even understands how the code works, because it was written by

01:49:08.480 --> 01:49:16.320
the person who quit 10 years ago, right? And so this software is kind of frustrating that way,

01:49:16.320 --> 01:49:20.480
but it's, that's how the world works. Yeah. Unfortunately, it can never be this

01:49:21.360 --> 01:49:26.080
perfect, beautiful thing. Well, there are, there are occasions in which you get to build,

01:49:26.080 --> 01:49:30.240
like, you know, you invent a new data structure or something like that, or there's this beautiful

01:49:30.240 --> 01:49:35.040
algorithm that just like makes you super happy. I love that moment. But when you're working with

01:49:35.040 --> 01:49:39.520
people, you're working with code and dusty that code bases and things like this, right?

01:49:40.560 --> 01:49:44.480
It's not about what's theoretically beautiful, it's about what's practical, what's real, what

01:49:44.480 --> 01:49:49.520
people will actually use. And I don't meet a lot of people that say, I want to rewrite all my code

01:49:50.560 --> 01:49:54.720
just for the sake of it. By the way, there could be interesting possibilities and we'll probably

01:49:54.720 --> 01:50:00.320
talk about it where AI can help rewrite some code that might be farther out future, but it's a

01:50:00.320 --> 01:50:08.000
really interesting one, how that could create more, be a tool in the battle against this monster

01:50:08.000 --> 01:50:17.280
of complexity that you mentioned. You mentioned Guido, the benevolent dictator for life of Python.

01:50:17.280 --> 01:50:20.320
What does he think about Mojo? Have you talked to him much about it?

01:50:21.120 --> 01:50:25.200
I have talked with him about it. He found it very interesting. We actually talked with Guido

01:50:25.200 --> 01:50:29.440
before it launched. And so he was aware of it before it went public. I have a ton of respect

01:50:29.440 --> 01:50:35.600
for Guido for a bunch of different reasons. You talk about Waller's operator and Guido is pretty

01:50:35.600 --> 01:50:44.880
amazing in terms of steering such a huge and diverse community and driving it forward. And

01:50:44.880 --> 01:50:51.360
I think Python is what it is thanks to him. And so to me, it was really important starting to work

01:50:51.360 --> 01:50:58.080
on Mojo to get his feedback and get his input and get his eyes on this. Now, a lot of what Guido

01:50:58.960 --> 01:51:04.320
was and is, I think, and thought about is, have we not fragment the community? We don't want to

01:51:04.320 --> 01:51:09.760
Python 2 to Python 3 thing. That was really painful for everybody involved. And so we spent

01:51:09.760 --> 01:51:13.440
quite a bit of time talking about that and some of the tricks I learned from Swift, for example.

01:51:13.440 --> 01:51:20.400
So in the migration from Swift, we managed to not just convert Objective-C into a slightly

01:51:20.400 --> 01:51:26.400
prettier Objective-C, which we did. We then converted not entirely, but almost an entire

01:51:26.480 --> 01:51:31.920
community to a completely different language. And so there's a bunch of tricks that you learn

01:51:31.920 --> 01:51:36.480
along the way that are directly relevant to what we do. And so this is where, for example,

01:51:37.600 --> 01:51:43.840
you leverage C Python while bringing up the new thing. That approach is, I think, proven and

01:51:43.840 --> 01:51:48.960
comes from experience. And so Guido is very interested in, like, okay, cool. I think that

01:51:48.960 --> 01:51:53.440
Python is really his legacy. It's his baby. I have tons of respect for that. Incidentally,

01:51:53.520 --> 01:51:57.600
I see Mojo as a member of the Python family. We're not trying to take Python away from Guido

01:51:57.600 --> 01:52:04.560
and from the Python community. And so to me, it's really important that we're a good member

01:52:04.560 --> 01:52:09.120
of that community. And so I think that, again, you would have to ask Guido this, but I think

01:52:09.120 --> 01:52:14.000
that he was very interested in this notion of, like, cool, Python gets beaten up for being slow.

01:52:14.560 --> 01:52:22.800
So maybe there's a path out of that, right? And that, you know, if the future is Python,

01:52:22.800 --> 01:52:29.920
right? I mean, look at the far outside case on this, right? And I'm not saying this is Guido's

01:52:29.920 --> 01:52:34.560
perspective, but, you know, there's this path of saying, like, okay, well, suddenly Python can

01:52:34.560 --> 01:52:39.360
suddenly go all the places it's never been able to go before. Right. And that means that Python

01:52:39.360 --> 01:52:43.360
can go even further and can have even more impact on the world. So in some sense,

01:52:44.800 --> 01:52:50.640
Mojo could be seen as Python 4.0. I would not say that. I think that would drive a lot of people

01:52:50.640 --> 01:52:56.240
really crazy. Because of the PTSD of the 3.02. I'm willing to annoy people about Emax versus VIM

01:52:56.240 --> 01:52:59.840
or about text versus spaces. That's that one. I don't know. That might be a little bit far

01:52:59.840 --> 01:53:05.040
even for me. Like my skin may not be that thick. But the point is the step to being a super set

01:53:05.040 --> 01:53:10.800
and allowing all of these capabilities, I think, is the evolution of a language. It feels like

01:53:10.800 --> 01:53:16.800
an evolution of a language. So he he's interested by the ideas that you're playing with, but also

01:53:16.800 --> 01:53:21.520
concerned about the fragmentation. So how, what are the ideas you've learned? What are you thinking

01:53:21.520 --> 01:53:30.480
about? How do we avoid fragmenting the community? Where the the Pythonistas and the, I don't know

01:53:30.480 --> 01:53:38.800
what to call the Mojo people. Magicians. I like it. Can coexist happily and share code and basically

01:53:38.800 --> 01:53:46.080
just have these big code bases that are using C Python and more and more moving towards Mojo.

01:53:46.080 --> 01:53:50.880
Well, so again, these are lessons I learned from Swift. And here we face very similar problems,

01:53:50.880 --> 01:53:59.280
right? In Swift, you have Objective C, Super Dynamic. They're very different syntax, right?

01:53:59.840 --> 01:54:05.280
But you're talking to people who have large scale code bases. I mean, Apple's got the biggest,

01:54:05.280 --> 01:54:10.080
largest scale code base of Objective C code, right? And so, you know, none of the companies,

01:54:10.080 --> 01:54:13.360
none of the iOS developers, none of the other developers want to rewrite everything all at

01:54:13.360 --> 01:54:17.760
once. And so you want to be able to adopt things piece at a time. And so a thing that I found that

01:54:17.760 --> 01:54:22.640
worked very well in the Swift community was saying, okay, cool. And this is when Swift was very

01:54:22.640 --> 01:54:29.280
young. As you say, okay, you have a million line of code Objective C app. Don't rewrite it all.

01:54:29.280 --> 01:54:34.160
But when you implement a new feature, go implement that new class using Swift.

01:54:35.040 --> 01:54:39.520
Right. And so now this turns out is a very wonderful thing for an app developer.

01:54:40.320 --> 01:54:44.960
But it's a huge challenge for this compiler team and the systems people that are implementing.

01:54:44.960 --> 01:54:49.280
That's right. And this comes back to what is this trade off between doing the hard thing that

01:54:50.080 --> 01:54:55.600
enables scale versus doing the theoretically pure and ideal thing, right? And so Swift had

01:54:55.600 --> 01:55:00.160
adopted and built a lot of different machinery to deeply integrate with the Objective C runtime.

01:55:00.160 --> 01:55:04.800
And we're doing the same thing with Python, right? Now, what happened in the case of Swift is that

01:55:05.680 --> 01:55:11.520
Swift's language got more and more mature over time, right? And incidentally, Mojo is a much

01:55:11.520 --> 01:55:15.840
simpler language than Swift in many ways. And so I think that Mojo will develop way faster than Swift

01:55:15.840 --> 01:55:20.560
for a variety of reasons. But as the language gets more mature and parallel with that, you have

01:55:20.560 --> 01:55:26.000
new people starting new projects, right? And so when the language is mature and somebody

01:55:26.000 --> 01:55:29.520
is starting a new project, that's when they say, okay, cool, I'm not dealing with a million lines

01:55:29.520 --> 01:55:34.560
of code. I'll just start and use the new thing for my whole stack. Now, the problem is, again,

01:55:34.560 --> 01:55:40.320
you come back to where communities and where people that work together, you build new subsystem or

01:55:40.320 --> 01:55:46.640
new feature or new thing in Swift or you build new thing in Mojo, then you want to be end up being

01:55:46.640 --> 01:55:51.920
used on the other side, right? And so then you need to work on integration back the other way.

01:55:52.720 --> 01:55:56.640
And so it's not just Mojo talking to Python, it's also Python talking to Mojo,

01:55:57.680 --> 01:56:01.360
right? And so what I would love to see, and I don't want to see this next month, right? But

01:56:01.360 --> 01:56:05.760
what I want to see over the course of time is I would love to see people that are building these

01:56:05.760 --> 01:56:14.080
packages, like NumPy or TensorFlow or these packages that are half Python, half C++.

01:56:15.040 --> 01:56:22.000
And if you say, okay, cool, I want to get out of this Python C++ world into a unified world,

01:56:22.000 --> 01:56:29.040
and so I can move to Mojo, but I can't give up all my Python clients because these libraries

01:56:29.040 --> 01:56:35.120
get used by everybody and they're not all going to switch all once and maybe never, right? Well,

01:56:35.120 --> 01:56:39.760
so the way we should do that is we should vend Python interfaces to the Mojo types.

01:56:40.880 --> 01:56:44.640
And that's what we did in Swift and worked great. I mean, it was a huge implementation challenge

01:56:44.640 --> 01:56:49.680
for the compiler people, right? But there's only a dozen of those compiler people and there are

01:56:49.680 --> 01:56:56.800
millions of users. And so it's a very expensive, capital intensive, like skill set intensive

01:56:56.800 --> 01:57:01.200
problem. But once you solve that problem, it really helps adoption and really helps the community

01:57:01.200 --> 01:57:05.760
progressively adopt technologies. And so I think that this approach will work quite well with the

01:57:05.760 --> 01:57:11.600
Python and the Mojo world. So for a package ported to Mojo and then create a Python interface?

01:57:11.600 --> 01:57:19.520
Yep. So how do you just to link on these packages, NumPy, PyTorch, and TensorFlow?

01:57:19.520 --> 01:57:25.040
Yeah. How do they play nicely together? So is Mojo supposed to be, let's talk about the machine

01:57:25.040 --> 01:57:33.360
learning ones. Is Mojo kind of vision to replace PyTorch and TensorFlow to incorporate it? What's

01:57:33.360 --> 01:57:39.200
the relationship in this? All right. So let's dance. So take a step back. So I wear many hats.

01:57:40.320 --> 01:57:46.240
So you're angling it on the Mojo side. Mojo is a programming language. And so it can help solve

01:57:46.880 --> 01:57:52.560
the C++ Python feud that's happening. The fire Mojo got me. I'm sorry. We should be talking

01:57:53.040 --> 01:58:00.160
modular. Yes. Yes. Okay. So the fire emoji is amazing. I love it. It's a big deal. The other

01:58:00.160 --> 01:58:06.080
side of this is the fire emoji is in service of solving some big AI problems. And so the big AI

01:58:06.080 --> 01:58:12.800
problems are again, this fragmentation, this hardware nightmare, this explosion of new potential,

01:58:12.800 --> 01:58:18.480
but that's not getting felt by the industry. And so when you look at how does the modular engine

01:58:18.480 --> 01:58:24.400
help TensorFlow and PyTorch, it's not replacing them. In fact, when I talk to people, again,

01:58:24.400 --> 01:58:28.480
they don't like to rewrite all their code, you have people that are using a bunch of PyTorch,

01:58:28.480 --> 01:58:33.200
a bunch of TensorFlow. They have models that they've been building over the course of many years.

01:58:33.200 --> 01:58:37.840
And when I talk to them, there's a few exceptions, but generally they don't want to rewrite all their

01:58:37.840 --> 01:58:42.880
code. And so what we're doing is we're saying, okay, well, you don't have to rewrite all your code.

01:58:42.880 --> 01:58:47.200
What happens is the modular engine goes in there and goes underneath TensorFlow and PyTorch.

01:58:47.280 --> 01:58:51.200
It's fully compatible. And it just provides better performance, better predictability,

01:58:51.200 --> 01:58:56.160
better tooling. It's a better experience that helps lift TensorFlow and PyTorch and make them even

01:58:56.160 --> 01:59:01.280
better. I love Python. I love TensorFlow. I love PyTorch, right? This is about making the world

01:59:01.280 --> 01:59:07.520
better, because we need AI to go further. But if I have a process that trains a model and I have a

01:59:07.520 --> 01:59:13.920
process that performs inference on that model, and I have the model itself, what should I do with that

01:59:13.920 --> 01:59:21.600
in the long arc of history in terms of if I use PyTorch to train it? Should I rewrite stuff in

01:59:21.600 --> 01:59:27.200
Mojo? Would that, if I care about performance? Oh, so I mean, again, it depends. So if you care

01:59:27.200 --> 01:59:31.120
about performance, then writing in Mojo is going to be way better than writing in Python. But if

01:59:31.120 --> 01:59:37.200
you look at LLM companies, for example, if you look at OpenAI, rumored, and you look at many of

01:59:37.200 --> 01:59:43.760
the other folks that are working on many of these LLMs and other innovative machine learning models,

01:59:44.320 --> 01:59:48.560
on the one hand, they're innovating in the data collection and the model billions of parameters

01:59:48.560 --> 01:59:54.960
and the model architecture and the RLE or HF and the like all the all the cool things that people

01:59:54.960 --> 02:00:01.040
are talking about. But on the other hand, they're spending a lot of time writing CUDA curls, right?

02:00:01.840 --> 02:00:06.240
And so you say, wait a second, how much faster could all this progress go if they were not having

02:00:06.240 --> 02:00:10.320
to handwrite all these CUDA curls? Right. And so there are a few technologies that are out there

02:00:10.320 --> 02:00:15.120
and people have been working on this problem for a while. And they're trying to solve subsets to

02:00:15.120 --> 02:00:19.600
the problem again, kind of fragmenting the space. And so what Mojo provides for these kinds of companies

02:00:19.600 --> 02:00:25.200
is the ability to say, cool, I can have a unifying theory. Right. And again, the better

02:00:25.200 --> 02:00:29.360
together the unifying theory, the the two world problem or the three world problem or the n world

02:00:29.360 --> 02:00:34.000
problem, like this is the thing that is slowing people down. And so as we help solve this problem,

02:00:34.000 --> 02:00:39.120
I think it'll be very helpful for making this whole cycle go faster. So obviously, we talked

02:00:39.120 --> 02:00:45.840
about the transition from Objective C to Swift, if design this programming language. And you've

02:00:45.840 --> 02:00:54.080
also talked quite a bit about the use of Swift for machine learning context. Why have you decided

02:00:54.080 --> 02:01:01.280
to move away from maybe an intense focus on Swift for the machine learning context versus sort of

02:01:02.000 --> 02:01:06.160
designing a new programming language that happens to be a super surprise.

02:01:06.160 --> 02:01:08.640
You're saying this is an irrational set of life choices I make?

02:01:10.480 --> 02:01:17.280
Did you go to the desert? And did you meditate on it? Okay. All right. No, it was bold and needed.

02:01:17.280 --> 02:01:22.880
And I think, I mean, it's just bold and sometimes to take those leaps is a difficult leap to take.

02:01:22.880 --> 02:01:25.680
Yeah. Well, so okay, I mean, I think there's a couple of different things. So

02:01:26.720 --> 02:01:33.840
actually, I left Apple back in 2017, like January 2017. So it's been a number of years that I left

02:01:33.840 --> 02:01:41.920
Apple. And the reason I left Apple was to do AI. Okay. So and again, I won't come on Apple and AI,

02:01:41.920 --> 02:01:48.400
but at the time, right, I wanted to get into and understand and understand the technology,

02:01:48.400 --> 02:01:52.560
understand the applications, the workloads. And so, okay, I'm going to go dive deep into

02:01:52.560 --> 02:01:58.640
applied and AI and then the technology underneath it. Right. I found myself at Google.

02:01:59.280 --> 02:02:02.560
And that was like when TPUs were waking up.

02:02:02.560 --> 02:02:09.120
Exactly. And so I found myself at Google and Jeff Dean, who's a rock star, as you know, right?

02:02:09.120 --> 02:02:15.760
And in 2017, TensorFlow is like really taking off and doing incredible things. And I was

02:02:15.760 --> 02:02:19.760
attracted to Google to help them with the TPUs, right? And TPUs are an innovative hardware

02:02:19.760 --> 02:02:25.360
accelerator platform have now, I mean, I think proven massive scale and like done incredible

02:02:25.360 --> 02:02:30.960
things, right? And so one of the things that this led into is a bunch of different projects,

02:02:30.960 --> 02:02:36.240
which I'll skip over, right? One of which was this Swift for TensorFlow project, right? And so

02:02:36.240 --> 02:02:41.600
that project was a research project. And so the idea of that is say, okay, well, let's look at

02:02:41.600 --> 02:02:46.320
innovative new programming models, where we can get a fast programming language, we can get

02:02:47.120 --> 02:02:51.360
automatic differentiation into language, let's push the boundaries of these things in a research

02:02:51.360 --> 02:02:58.160
setting, right? Now, that project, I think lasted two, three years. There's some really cool outcomes

02:02:58.160 --> 02:03:04.480
of that. So one of the things that's really interesting is I published a talk at an LLVM

02:03:04.480 --> 02:03:10.480
conference in 2018. And this seems like so long ago about graph program abstraction, which is

02:03:10.480 --> 02:03:15.200
basically the thing that's in PyTorch 2. And so PyTorch 2 with all this Dynamo real thing,

02:03:15.200 --> 02:03:19.760
it's all about this graph program abstraction thing from Python bytecodes. And so a lot of the

02:03:19.840 --> 02:03:25.680
research that was done ended up pursuing and going out through the industry and influencing

02:03:25.680 --> 02:03:30.000
things. And I think it's super exciting and awesome to see that. But the Swift for TensorFlow project

02:03:30.000 --> 02:03:34.080
itself did not work out super well. And so there's a couple of different problems with that,

02:03:34.080 --> 02:03:40.400
one of which is that you may have noticed Swift is not Python. There's a few people

02:03:40.400 --> 02:03:46.400
that write Python code. Yes. And so it turns out that all of ML is pretty happy with Python.

02:03:46.400 --> 02:03:50.080
It's actually a problem that other programming languages have as well,

02:03:50.080 --> 02:03:54.400
that they're not Python. We'll probably maybe briefly talk about Julia,

02:03:54.400 --> 02:03:58.400
who's a very interesting, beautiful programming language, but it's not Python.

02:03:58.400 --> 02:04:03.600
Exactly. Well, and so like if you're saying, I'm going to solve a machine learning problem

02:04:03.600 --> 02:04:08.160
where all the programmers are Python programmers. And you say the first thing you have to do is

02:04:08.160 --> 02:04:13.200
switch to a different language. Well, your new thing may be good or bad or whatever,

02:04:13.200 --> 02:04:16.800
but if it's a new thing, the adoption barrier is massive.

02:04:17.440 --> 02:04:18.400
It's still possible.

02:04:18.400 --> 02:04:22.080
Still possible. Yeah, absolutely. The world changes and evolves. And there's definitely

02:04:22.080 --> 02:04:28.240
room for new and good ideas, but it just makes it so much harder. And so lesson learned,

02:04:28.240 --> 02:04:32.480
Swift is not Python. And people are not always in search of learning a new thing for the sake

02:04:32.480 --> 02:04:36.000
of learning a new thing. And if you want to be compatible with all the world's code, it turns

02:04:36.000 --> 02:04:43.200
out, meet the world where it is. Right. Second thing is that, you know, a lesson learned is that

02:04:44.080 --> 02:04:49.920
Swift as a very fast and efficient language, kind of like Mojo, but a different take on it still

02:04:51.920 --> 02:04:57.200
really worked well with eager mode. And so eager mode is something that PyTorch does,

02:04:57.200 --> 02:05:03.440
and it proved out really well, and it enables really expressive and dynamic and easy to debug

02:05:03.520 --> 02:05:07.200
programming. TensorFlow at the time was not set up for that.

02:05:08.320 --> 02:05:11.600
Let's say that was not the timing is also important in this world.

02:05:11.600 --> 02:05:16.240
Yeah. Yeah. And TensorFlow is a good thing and it has many, many strengths, but

02:05:18.320 --> 02:05:21.760
you could say Swift for TensorFlow is a good idea, except for the Swift and except for the

02:05:21.760 --> 02:05:28.080
TensorFlow part. So because it's not Python and TensorFlow because it's not wasn't set up for

02:05:28.400 --> 02:05:34.720
eager mode at the time. Yeah. That is 1.0. Exactly. And so one of the things about that is in the

02:05:34.720 --> 02:05:39.600
context of it being a research project, I'm very happy with the fact that we built a lot of really

02:05:39.600 --> 02:05:43.440
cool technology. We learned a lot of things. I think the ideas went on to have influence

02:05:43.440 --> 02:05:47.360
and other systems like PyTorch. A few people use that right here. Right. And so I think that's

02:05:47.360 --> 02:05:52.320
super cool. And for me personally, I learned so much from it. Right. And I think a lot of the

02:05:52.320 --> 02:05:56.560
engineers that worked on it also learned a tremendous amount. And so, you know, I think that

02:05:57.440 --> 02:06:01.600
that's just really exciting to see. And, you know, I'm sorry that the project didn't work out. I

02:06:01.600 --> 02:06:08.640
wish it did, of course. Right. But, you know, it's a research project and so you're there to learn

02:06:08.640 --> 02:06:16.720
from it. Well, it's interesting to think about the evolution of programming as we come up with these

02:06:17.440 --> 02:06:22.880
whole new set of algorithms in machine learning and artificial intelligence and what's going to

02:06:22.880 --> 02:06:29.280
win out. Because it could be a new programming language. Yeah. It could be, I mean, I just

02:06:29.280 --> 02:06:38.000
mentioned Julia. I think there's a lot of ideas behind Julia that Mojo shares. What are your

02:06:38.000 --> 02:06:45.360
thoughts about Julia in general? So, I will have to say that when we launched Mojo, one of the

02:06:45.360 --> 02:06:51.120
biggest things I didn't predict was the response from the Julia community. And so, I was not,

02:06:51.120 --> 02:06:56.000
I mean, I've, okay, let me take a step back. I've known the Julia folks for a really long time.

02:06:56.000 --> 02:07:01.040
They were an adopter of LLVM a long time ago. They've been pushing state of the art in a bunch

02:07:01.040 --> 02:07:06.640
of different ways. Julia is a really cool system. I had always thought of Julia as being mostly a

02:07:06.640 --> 02:07:14.480
scientific computing focused environment. And I thought that was its focus. I neglected to

02:07:14.480 --> 02:07:19.200
understand that one of their missions is to like help make Python work end to end.

02:07:20.160 --> 02:07:24.000
And so, I think that was my error for not understanding that. And so, I could have been

02:07:24.000 --> 02:07:28.880
maybe more sensitive to that. But there's major differences between what Mojo is doing

02:07:28.880 --> 02:07:34.240
and what Julia is doing. So, as you say, Julia is not Python. And so, one of the things that

02:07:34.800 --> 02:07:40.000
a lot of the Julia people came out and said is like, okay, well, if we put a ton of more energy

02:07:40.000 --> 02:07:46.080
and ton more money or engineering or whatever into Julia, maybe that would be better than

02:07:46.160 --> 02:07:51.360
starting Mojo, right? Well, I mean, maybe that's true, but it still wouldn't make Julia into Python.

02:07:52.400 --> 02:07:57.280
So, if you've worked backwards from the goal of let's build something for Python programmers

02:07:57.280 --> 02:08:04.480
without requiring them to relearn syntax, then Julia just isn't there, right? I mean,

02:08:04.480 --> 02:08:09.920
that's a different thing, right? And so, if you anchor on, I love Julia and I want Julia to go

02:08:09.920 --> 02:08:14.800
further, then you can look at it from a different lens. But the lens we were coming at was, hey,

02:08:14.800 --> 02:08:20.160
everybody is using Python. Python isn't, syntax isn't broken. Let's take what's great about Python

02:08:20.160 --> 02:08:24.000
and make it even better. And so, it's just a different starting point. So, I think Julia is

02:08:24.000 --> 02:08:27.440
a great language. The community is a lovely community. They're doing really cool stuff,

02:08:27.440 --> 02:08:33.840
but it's just a slightly different angle. But it does seem that Python is quite sticky. Is there

02:08:33.840 --> 02:08:40.560
some philosophical almost thing you could say about why Python, by many measures, seems to be

02:08:40.560 --> 02:08:44.800
the most popular programming language in the world? Well, I can tell you things I love about it.

02:08:44.800 --> 02:08:50.480
Maybe that's one way to answer the question, right? So, huge package ecosystem. Super lightweight and

02:08:50.480 --> 02:08:56.720
easy to integrate. It has very low startup time. So, what startup time? You mean like learning curve

02:08:56.720 --> 02:09:02.080
or what? Yeah, so, if you look at certain other languages, you say like, go. And it just takes

02:09:02.080 --> 02:09:07.840
a, like Java, for example, takes a long time to compile all the things. And then the VM starts

02:09:07.840 --> 02:09:11.440
up and the garbage clusters kicks in and then it revs its engines and then it can plow through a

02:09:11.440 --> 02:09:17.840
lot of internet stuff or whatever, right? Python is like scripting. It just goes, right? Python

02:09:17.840 --> 02:09:22.240
has very low compile time. So, you're not sitting there waiting. Python integrates into notebooks

02:09:22.240 --> 02:09:28.480
in a very elegant way that makes exploration super interactive and it's awesome, right? Python is also

02:09:29.120 --> 02:09:35.360
it's like almost the glue of computing because it has such a simple object representation,

02:09:35.360 --> 02:09:39.520
a lot of things plug into it. That dynamic metaprogramming thing we were talking about also

02:09:39.520 --> 02:09:43.760
enables really expressive and beautiful APIs, right? So, there's lots of reasons that you can

02:09:44.400 --> 02:09:49.520
look at technical things that Python has done and say like, okay, wow, this is actually a pretty

02:09:49.520 --> 02:09:56.320
amazing thing and any one of those you can neglect. People all just talk about indentation and ignore

02:09:56.320 --> 02:10:00.880
like the fundamental things. But then you also look at the community side, right? So, Python

02:10:00.880 --> 02:10:05.760
owns machine learning. Machine learning is pretty big. Yeah, and it's growing. It's growing, right?

02:10:05.760 --> 02:10:09.760
And it's growing in importance, right? And so, and there's a reputation of prestige to machine

02:10:09.760 --> 02:10:13.680
learning to where like, if you're a new programmer, you're thinking about like,

02:10:14.480 --> 02:10:18.960
which programming language do I use? Well, I should probably care about machine learning. Therefore,

02:10:18.960 --> 02:10:24.160
let me try Python and kind of builds and builds and builds. And you can go back before that,

02:10:24.160 --> 02:10:29.600
like my kids learn Python, right? Not because I'm telling them to learn Python, but because

02:10:29.680 --> 02:10:33.760
what they were buying against you or what? Well, no, right? Well, they also learned Scratch,

02:10:33.760 --> 02:10:37.760
right? And things like this too. But it's because Python is taught everywhere, right? Because it's

02:10:37.760 --> 02:10:43.680
easy to learn, right? And because it's pervasive, right? Back to my day, we learned Java and C++.

02:10:45.600 --> 02:10:50.800
I'll pale both directions. But yes, I guess Python is the main language of teaching software

02:10:50.800 --> 02:10:55.920
engineering in schools now. Yeah. Well, and if you look at this, there's these growth cycles,

02:10:56.160 --> 02:11:00.800
right? If you look at what causes things to become popular, and then gain in popularity,

02:11:00.800 --> 02:11:04.880
there's reinforcing feedback loops and things like this. And I think Python has done,

02:11:04.880 --> 02:11:08.720
again, the whole community has done a really good job of building those growth loops and help

02:11:08.720 --> 02:11:12.720
propel the ecosystem. And I think that again, you look at what you can get done with just a few

02:11:12.720 --> 02:11:20.720
lines of code, it's amazing. So this kind of self building loop, it's interesting to understand

02:11:20.720 --> 02:11:27.440
because when you look at Mojo, what it stands for some of the features, it seems sort of clear that

02:11:28.080 --> 02:11:32.880
this is a good direction for programming languages to evolve in the machine learning community.

02:11:33.440 --> 02:11:39.280
But it's still not obvious that it will, because of this, whatever the engine of popularity,

02:11:39.280 --> 02:11:45.520
of virality, is there something you could speak to like how, how do you get people to switch?

02:11:45.520 --> 02:11:50.080
Yeah, well, I mean, I think that the viral growth loop is to switch people to Unicode.

02:11:51.120 --> 02:11:54.400
I think the Unicode file extensions are what I'm betting on. I think that's going to be the thing.

02:11:55.920 --> 02:11:59.040
Tell the kids that you could use the fire emoji and they'd be like, what?

02:11:59.040 --> 02:12:05.120
Exactly. Well, in all seriousness, I mean, I think there's really, I'll give you two

02:12:05.680 --> 02:12:12.080
opposite answers. One is, I hope if it's useful, if it solves problems and people care about those

02:12:12.080 --> 02:12:18.560
problems being solved, they'll adopt the tech. That's kind of the simple answer. And when you're

02:12:18.560 --> 02:12:24.000
looking to get tech adopted, the question is, is it solving an important problem people need solved?

02:12:24.000 --> 02:12:29.200
And is the adoption cost low enough that they're willing to make the switch and

02:12:29.840 --> 02:12:35.200
cut over and do the pain up front so that they can actually do it? And so hopefully,

02:12:35.200 --> 02:12:41.120
Mojo will be that for a bunch of people and people building these hybrid packages are suffering.

02:12:41.120 --> 02:12:45.040
It's really painful. And so I think that we have a good shot of helping people.

02:12:45.040 --> 02:12:50.000
But the other side is, it's okay if people don't use Mojo. It's not my job to say,

02:12:50.000 --> 02:12:53.520
everybody should do this. I'm not saying Python is bad. I hope Python,

02:12:53.520 --> 02:12:57.200
see Python, like all these implementations, because Python ecosystem is not just see Python.

02:12:57.200 --> 02:13:01.360
It's also a bunch of different implementations with different tradeoffs. And this ecosystem is

02:13:01.360 --> 02:13:06.800
really powerful and exciting, as are other programming languages. It's not like TypeScript

02:13:06.800 --> 02:13:12.560
or something is going to go away. And so there's not a winner take all thing. And so I hope that

02:13:12.560 --> 02:13:16.000
Mojo is exciting and useful to people. But if it's not, that's also fine.

02:13:16.000 --> 02:13:24.800
But I also wonder what the use case for why you should try Mojo would be. So practically speaking.

02:13:25.840 --> 02:13:31.840
It seems like, so there's entertainment. There's a dopamine hit of saying, holy

02:13:31.840 --> 02:13:37.840
shit, this is 10 times faster. This little piece of code is 10 times faster in Mojo.

02:13:38.160 --> 02:13:42.800
Box before he gets to 35,000. Exactly. I mean, just even that, I mean,

02:13:42.800 --> 02:13:50.560
that's the dopamine hit that every programmer sort of dreams of is the optimization. It's also the

02:13:50.560 --> 02:13:57.680
drug that can pull you in and have you waste way too much of your life optimizing and over

02:13:57.680 --> 02:14:04.320
optimizing, right? But so what would you see it would be like comedy. It's very hard to predict,

02:14:04.320 --> 02:14:11.120
of course. But if you look 10 years from now, Mojo is super successful. What do you think

02:14:11.120 --> 02:14:17.840
would be the thing where people try it and then use it regularly and it kind of grows and grows

02:14:17.840 --> 02:14:23.600
and grows and grows? So you talk about dopamine hit. And so again, humans are not one thing.

02:14:24.240 --> 02:14:28.480
And some people love rewriting their code and learning new things and throwing themselves

02:14:28.480 --> 02:14:33.760
in the deep end and trying out a new thing. In my experience, most people don't. Like,

02:14:33.760 --> 02:14:39.600
they're too busy. They have other things going on. By number, most people don't like this. I want

02:14:39.600 --> 02:14:47.600
to rewrite all my code. But even those people, the two busy people, the people that don't actually

02:14:47.600 --> 02:14:52.000
care about the language that just care about getting stuff done, those people do like learning new

02:14:52.000 --> 02:14:57.280
things, right? And so you talk about the dopamine rush of 10x faster. Wow, that's cool. I want to

02:14:57.280 --> 02:15:01.600
do that again. Well, it's also like, here's a thing I've heard about in a different domain.

02:15:01.600 --> 02:15:05.840
And I don't have to rewrite all my code. I can learn a new trick, right? Well, that's called

02:15:05.840 --> 02:15:12.400
growth. And so one thing that I think is cool about Mojo, and again, those will take a little bit

02:15:12.400 --> 02:15:17.040
of time for, for example, the blog posts and the books and like all that kind of stuff to develop

02:15:17.040 --> 02:15:21.200
and the language needs to get further along. But what we're doing, you talk about types,

02:15:21.200 --> 02:15:25.680
like you can say, look, you can start with the world you already know, and you can progressively

02:15:25.680 --> 02:15:31.200
learn new things and adopt them where it makes sense. If you never do that, that's cool. You're

02:15:31.200 --> 02:15:35.920
not a bad person. If you, if you get really excited about it, want to go all the way in the deep end

02:15:35.920 --> 02:15:40.480
and want to rewrite everything and like whatever, that's cool, right? But I think the middle path

02:15:40.480 --> 02:15:46.400
is actually the more likely one where it's, you know, you come out with a new, a new idea and

02:15:46.400 --> 02:15:50.960
you discover, wow, that makes my code way simpler, way more beautiful, way faster, way whatever.

02:15:50.960 --> 02:15:56.160
And I think that's what people like. Now, if you fast forward and you said like 10 years out,

02:15:56.720 --> 02:16:00.400
right? I can give you a very different answer on that, which is, I mean,

02:16:01.360 --> 02:16:06.480
if you go back and look at what computers looked like 20 years ago, every 18 months, they got

02:16:06.480 --> 02:16:12.480
faster for free, right? 2x faster every 18 months, it was like clockwork, it was, it was free,

02:16:12.480 --> 02:16:18.000
right? You go back 10 years ago, and we entered in this world where suddenly we had multicore CPUs

02:16:18.000 --> 02:16:24.480
and we had GPUs. And if you squint and turn your head, what are GPUs? It's just a many core,

02:16:24.480 --> 02:16:31.360
very simple CPU thing kind of, right? And so, and 10 years ago, it was CPUs and GPUs and graphics.

02:16:34.000 --> 02:16:41.360
Today, we have CPUs, GPUs, graphics, and AI, because it's so important because the compute

02:16:41.360 --> 02:16:45.680
is so demanding because of the smart cameras and the watches and all the different places

02:16:45.760 --> 02:16:51.120
that AI needs to work in our lives, it's caused this explosion of hardware. And so,

02:16:51.120 --> 02:16:55.520
part of my thesis, part of my belief of where computing goes, if you look at 10 years from now,

02:16:56.160 --> 02:17:00.080
is it's not going to get simpler. Physics isn't going back to where we came from.

02:17:00.720 --> 02:17:05.440
It's only going to get weirder from here on out, right? And so, to me, the exciting part about

02:17:05.440 --> 02:17:11.280
what we're building is it's about building that universal platform, which the world can

02:17:11.280 --> 02:17:14.720
continue to get weird, because again, I don't think it's avoidable, it's physics,

02:17:15.360 --> 02:17:19.280
but we can help lift people scale, do things with it, and they don't have to rewrite their code

02:17:19.280 --> 02:17:23.600
every time a new device comes out. And I think that's pretty cool. And so, if Mojo can help with

02:17:23.600 --> 02:17:27.760
that problem, then I think that it will be hopefully quite interesting and quite useful to

02:17:27.760 --> 02:17:32.800
a wide range of people because there's so much potential and like there's so, you know, maybe

02:17:32.800 --> 02:17:37.040
analog computers will become a thing or something, right? And we need to be able to get into a mode

02:17:37.040 --> 02:17:41.840
where we can move this programming model forward, but do so in a way where we're lifting people

02:17:41.840 --> 02:17:46.640
and growing them instead of forcing them to rewrite all their code and exploding them.

02:17:46.640 --> 02:17:50.720
Do you think there'll be a few major libraries that go Mojo first?

02:17:53.680 --> 02:17:58.560
Well, so, I mean, the modular engine is all Mojo. So, again, come back to like, we're not

02:17:58.560 --> 02:18:02.640
building Mojo because it's fun, we're building Mojo because we had to dissolve these accelerators.

02:18:02.640 --> 02:18:05.680
That's the origin story. But I mean, ones that are currently in Python.

02:18:05.680 --> 02:18:09.200
Yeah. So, I think that a number of these projects will. And so, one of the things, again, this is

02:18:09.200 --> 02:18:13.680
just my best guess. Like, each of the package maintainers also has, I'm sure, plenty of other

02:18:13.680 --> 02:18:17.440
things going on. People don't like really don't like rewriting code just for the sake of rewriting

02:18:17.440 --> 02:18:23.840
code. But sometimes, like, people are excited about like adopting a new idea.

02:18:23.840 --> 02:18:29.360
Yeah. And it turns out that while rewriting code is generally not people's first thing,

02:18:29.360 --> 02:18:34.560
turns out that redesigning something while you rewrite it and using a rewrite as an excuse to

02:18:34.560 --> 02:18:42.480
redesign can lead to the 2.0 of your thing that's way better than the 1.0. And so, I have no idea.

02:18:42.480 --> 02:18:47.040
I can't predict that. But there's a lot of these places where, again, if you have a package that

02:18:47.040 --> 02:18:52.640
is half C and half Python, right, you just solve the pain, make it easier to move things faster,

02:18:52.640 --> 02:18:57.760
make it easier to debug and evolve your tech. Adopting Mojo kind of makes sense to start with.

02:18:57.760 --> 02:19:00.080
And then it gives you this opportunity to rethink these things.

02:19:00.080 --> 02:19:09.120
So the two big gains are that there's a performance gain and then there's the portability to all kinds

02:19:09.120 --> 02:19:14.960
of different devices. And there's safety, right? So you talk about real types. I mean, not saying

02:19:14.960 --> 02:19:20.160
this is for everybody, but that's actually a pretty big thing, right? And so there's a bunch of

02:19:20.160 --> 02:19:24.960
different aspects of what value Mojo provides. And so, I mean, it's funny for me. I've been working

02:19:24.960 --> 02:19:32.000
on these kinds of technologies and tools for too many years now. But you look at Swift, right?

02:19:32.000 --> 02:19:35.280
And we talked about Swift for TensorFlow, but Swift as a programming language, right?

02:19:36.400 --> 02:19:44.400
Swift's now 13 years old from when I started it. So, because I started in 2010, if I remember.

02:19:44.400 --> 02:19:51.200
And so, that project, and I was involved with it for 12 years or something, right? That project

02:19:51.200 --> 02:19:55.360
has gone through its own really interesting story arc, right? And it's a mature, successful,

02:19:55.360 --> 02:20:00.720
used by millions of people's system, right? Certainly not dead yet, right? But also,

02:20:00.720 --> 02:20:04.160
going through that story arc, I learned a tremendous amount about building languages,

02:20:04.160 --> 02:20:08.320
about building compilers, about working with community, and things like this. And so,

02:20:08.320 --> 02:20:13.440
that experience, like I'm helping channel and bring directly in Mojo. And other systems,

02:20:13.440 --> 02:20:17.840
same thing. Apparently, I like building and iterating and evolving things. And so, you look

02:20:17.840 --> 02:20:23.360
at this LLVM thing I worked on 20 years ago, and you look at MLIR, right? And so, a lot of the

02:20:23.360 --> 02:20:28.640
lessons learned in LLVM got fed into MLIR. And I think that MLIR is a way better system than

02:20:28.640 --> 02:20:34.960
LLVM was. And Swift is a really good system. And it's amazing. But I hope that Mojo will take

02:20:34.960 --> 02:20:43.440
the next step forward in terms of design. In terms of running Mojo, people can play with it.

02:20:43.440 --> 02:20:49.200
What's Mojo Playground? Yeah. And from the interface perspective,

02:20:49.200 --> 02:20:53.920
and from the hardware perspective, what's this incredible thing running on?

02:20:54.480 --> 02:21:00.080
Yeah. So, right now, so here we are two weeks after launch. We decided that, okay, we have this

02:21:00.080 --> 02:21:04.640
incredible set of technology that we think might be good, but we have not given it to

02:21:05.360 --> 02:21:09.840
lots of people yet. And so, we were very conservative and said, let's put it in a workbook

02:21:09.840 --> 02:21:13.280
so that if it crashes, we can do something about it. We can monitor and track that.

02:21:13.280 --> 02:21:19.360
Right. And so, again, things are still super early, but we're having one person a minute

02:21:20.080 --> 02:21:26.000
sign up with over 70,000 people two weeks in. It's kind of crazy.

02:21:26.000 --> 02:21:30.720
So, you can sign up to Mojo Playground and you can use it in the cloud.

02:21:30.720 --> 02:21:33.760
Yeah. In your browser. And so, what that's running on a workbook?

02:21:33.760 --> 02:21:39.520
Yeah. What that's running on is, that's running on cloud VMs. And so, you share a machine with a

02:21:39.520 --> 02:21:43.760
bunch of other people, but it turns out there's a bunch of them now because there's a lot of people.

02:21:43.760 --> 02:21:46.720
And so, what you're doing is you're getting free compute and you're getting to play with

02:21:46.720 --> 02:21:51.120
this thing in kind of a limited controlled way so that we can make sure that it doesn't

02:21:52.160 --> 02:21:55.360
totally crash and be embarrassing. Right? Yeah.

02:21:55.360 --> 02:21:58.720
So, now a lot of the feedback we've gotten is people want to download it around locally.

02:21:58.720 --> 02:22:02.880
So, we're working on that right now. So, that's the goal to be able to download locally?

02:22:02.880 --> 02:22:05.840
Yeah. Yeah. That's what everybody expects. And so, we're working on that right now.

02:22:05.840 --> 02:22:07.680
And so, we just want to make sure that we do it right.

02:22:07.680 --> 02:22:11.680
And I think this is one of the lessons I learned from Swift also, by the way.

02:22:12.480 --> 02:22:16.800
Is it when we launched Swift? Gosh, it feels like forever ago. It was 2014.

02:22:17.360 --> 02:22:23.760
And we, I mean, it was super exciting. I and we, the team had worked on Swift for a number of years

02:22:23.760 --> 02:22:31.040
in secrecy. Okay. And we, four years into this development, roughly, of working on this thing,

02:22:31.920 --> 02:22:36.480
at that point, about 250 people at Apple knew about it. Okay. So, it was secret.

02:22:36.480 --> 02:22:41.440
Apple's good at secrecy. And it was a secret project. And so, we launched this at WWDC,

02:22:41.440 --> 02:22:45.520
a bunch of hoopla and excitement, and said, developers, you're going to be able to develop

02:22:45.520 --> 02:22:51.360
and submit apps to the App Store in three months. Okay. Well, several interesting things happened,

02:22:51.360 --> 02:22:57.360
right? So, first of all, we learned that, A, it had a lot of bugs. It was not actually production

02:22:57.360 --> 02:23:03.120
quality. And it was extremely stressful in terms of like, trying to get it working for a bunch of

02:23:03.120 --> 02:23:07.840
people. And so, what happened was we went from zero to, you know, I don't know how many developers,

02:23:07.840 --> 02:23:12.800
Apple had at the time, but a lot of developers overnight, and they ran into a lot of bugs,

02:23:12.800 --> 02:23:16.800
and it was really embarrassing. And it was very stressful for everybody involved, right? It was

02:23:16.800 --> 02:23:21.040
also very exciting because everybody was excited about that. The other thing I learned is that,

02:23:21.040 --> 02:23:25.600
when that happened, roughly every software engineer who did not know about the project at Apple,

02:23:25.600 --> 02:23:30.080
their head exploded when it was launched, because they didn't know it was coming. And so, they're

02:23:30.080 --> 02:23:33.840
like, wait, what is this? I signed up to work for Apple because I love Objective C. Why is there a

02:23:33.840 --> 02:23:42.240
new thing, right? And so, now, what that meant practically is that the push from launch to,

02:23:42.240 --> 02:23:48.880
first of all, the fall, but then to 2.0 and 3.0 and like, all the way forward was super painful

02:23:48.880 --> 02:23:54.560
for the engineering team and myself. It was very stressful. The developer community was very grumpy

02:23:54.560 --> 02:23:58.000
about it because they're like, okay, well, wait a second, you're changing and breaking my code and

02:23:58.480 --> 02:24:03.600
we have to fix the bugs. And it was just a lot of tension and friction on all sides.

02:24:04.960 --> 02:24:09.440
There's a lot of technical debt in the compiler because we have to run really fast. You have to

02:24:09.440 --> 02:24:13.040
go implement the thing and unblock the use case and do the thing. And you know it's not right,

02:24:13.040 --> 02:24:17.600
but you never have time to go back and do it, right? And I'm very proud of the Swift team because

02:24:17.600 --> 02:24:25.600
they've come, I mean, we, but they came so far and made so much progress over this time since

02:24:25.600 --> 02:24:30.160
launch. It's pretty incredible and Swift is a very, very good thing, but I just don't want to do

02:24:30.160 --> 02:24:36.480
that again, right? And so, iterate more through the development process. And so, what we're doing is

02:24:36.480 --> 02:24:41.600
we're not launching it when it's hopefully 0.9 with no testers. We're launching it and saying it's

02:24:41.600 --> 02:24:46.400
0.1, right? And so, we're saying expectations of saying like, okay, well, don't use this for

02:24:46.400 --> 02:24:51.920
production, right? If you're interested in what we're doing, we'll do it in an open way and we

02:24:51.920 --> 02:24:56.640
can do it together, but don't use it in production yet. Like, we'll get there, but let's do it the

02:24:56.640 --> 02:25:02.880
right way. And I'm also saying we're not in a race. The thing that I want to do is build the

02:25:02.880 --> 02:25:08.640
world's best thing, right? Because if you do it right and it lifts the industry, it doesn't matter

02:25:08.640 --> 02:25:14.080
if it takes an extra two months. Like, two months is worth waiting. And so, doing it right and not

02:25:14.080 --> 02:25:20.320
being overwhelmed with technical debt and things like this is like, again, war wounds, lessons

02:25:20.320 --> 02:25:24.480
learned, whatever you want to say, I think is absolutely the right thing to do. Even though,

02:25:24.480 --> 02:25:29.040
right now, people are very frustrated that you can't download it or it doesn't have feature X

02:25:29.040 --> 02:25:36.880
or something like this. What have you learned in a little bit of time since it's been released

02:25:36.880 --> 02:25:42.480
into the wild that people have been complaining about feature X or Y or Z? What have they been

02:25:42.480 --> 02:25:48.720
complaining about? What have they been excited about? Like, almost like detailed things versus

02:25:48.720 --> 02:25:52.800
a big vision. I think everyone would be very excited about the big vision.

02:25:52.800 --> 02:25:56.480
Yeah. Yeah. Well, so, I mean, I've been very pleased. In fact, I mean, we've been massively

02:25:56.480 --> 02:26:01.680
overwhelmed with response, which is a good problem to have. It's kind of like a success

02:26:01.680 --> 02:26:09.040
disaster in a sense, right? And so, I mean, if you go back in time, when we started Modular,

02:26:09.040 --> 02:26:14.480
which is just not yet a year and a half ago, so it's still a pretty new company, new team,

02:26:15.040 --> 02:26:21.040
small but very good team of people, like we started with extreme conviction that there's a set of

02:26:21.040 --> 02:26:24.800
problems that we need to solve. And if we solve it, then people will be interested in what we're

02:26:24.800 --> 02:26:30.720
doing, right? But again, you're building in basically secret, right? You're trying to figure

02:26:30.720 --> 02:26:35.840
it out. Creation is a messy process. You're having to go through different paths and understand what

02:26:35.840 --> 02:26:39.840
you want to do and how to explain it. Often, when you're doing disruptive and new kinds of things,

02:26:40.800 --> 02:26:46.160
just knowing how to explain it is super difficult, right? And so, when we launched,

02:26:46.160 --> 02:26:51.680
we hoped people would be excited. But, you know, I'm an optimist, but I'm also like,

02:26:51.680 --> 02:26:55.520
don't want to get ahead of myself. And so, when people found out about Mojo,

02:26:55.520 --> 02:27:01.120
I think their heads exploded a little bit, right? And, you know, here's, I think, a pretty credible

02:27:01.120 --> 02:27:05.280
team that has built some languages and some tools before. And so, they have some lessons learned

02:27:06.000 --> 02:27:10.480
and are tackling some of the deep problems in the Python ecosystem and giving it the love

02:27:10.480 --> 02:27:14.240
and attention that it should be getting. And I think people got very excited about that. And

02:27:14.240 --> 02:27:18.320
so, if you look at that, I mean, I think people are excited about ownership and taking a step

02:27:18.320 --> 02:27:21.280
beyond Rust, right? And there's people that are very excited about that. And there's people that

02:27:21.280 --> 02:27:28.320
are excited about, you know, just like, I made Game of Life go 400 times faster, right? And things

02:27:28.320 --> 02:27:31.680
like that. And that's really cool. There are people that are really excited about the, okay,

02:27:31.680 --> 02:27:34.480
I really hate writing stuff in C++. Save me.

02:27:34.480 --> 02:27:37.760
Well, like systems in your, they're like stepping up like, oh, yes.

02:27:37.760 --> 02:27:44.400
So, that's me, by the way. Also, I really want to stop writing C++. But the,

02:27:45.120 --> 02:27:51.120
I get third-person excitement when people tweet, hey, I made this code, Game of Life,

02:27:51.120 --> 02:27:54.000
or whatever, faster. And you're like, yeah.

02:27:54.000 --> 02:28:01.520
Yeah. And also, like, I would also say that, let me cast blame out to people who deserve

02:28:01.600 --> 02:28:02.480
it. Sure.

02:28:02.480 --> 02:28:05.760
These terrible people who convinced me to do some of this.

02:28:05.760 --> 02:28:06.560
Yes.

02:28:06.560 --> 02:28:07.440
Jeremy Howard.

02:28:07.440 --> 02:28:08.000
Yes.

02:28:08.000 --> 02:28:08.560
That guy.

02:28:09.520 --> 02:28:11.280
Well, he's been pushing for this kind of thing.

02:28:11.280 --> 02:28:13.040
He's been pushing for more years.

02:28:13.040 --> 02:28:14.400
Yeah, he's wanted this for a long, long time.

02:28:14.400 --> 02:28:15.920
He's wanted this for years.

02:28:15.920 --> 02:28:19.520
For people who don't know Jeremy Howard, he's like one of the most legit people in the machine

02:28:19.520 --> 02:28:25.840
learning community. He's a grassroots. He really teaches, he's an incredible educator,

02:28:25.840 --> 02:28:30.800
he's an incredible teacher, but also legit in terms of a machine learning engineer himself.

02:28:31.040 --> 02:28:36.720
He's been running the fast.ai and looking, I think, for exactly what you've done.

02:28:36.720 --> 02:28:37.280
Exactly.

02:28:37.280 --> 02:28:44.640
And so, I mean, the first time, so I met Jeremy pretty early on, but the first time I sat up

02:28:44.640 --> 02:28:50.640
and I'm like, this guy is ridiculous is when I was at Google and we were bringing up TPUs and

02:28:50.640 --> 02:28:57.120
we had a whole team of people and where there was this competition called Don Bench of who can

02:28:57.120 --> 02:29:00.720
train ImageNet fastest.

02:29:01.600 --> 02:29:08.800
And Jeremy and one of his researchers crushed Google by not through sheer force of the amazing

02:29:08.800 --> 02:29:13.600
amount of compute and the number of TPUs and stuff like that, that he just decided that progressive

02:29:13.600 --> 02:29:17.760
imagery sizing was the right way to train the model and if you were epochs faster and

02:29:18.320 --> 02:29:20.720
make the whole thing go go vroom, right?

02:29:20.720 --> 02:29:23.440
And I'm like, this guy is incredible.

02:29:24.000 --> 02:29:28.000
So you can say, anyways, come back to where's Mojo coming from.

02:29:28.640 --> 02:29:30.320
Chris finally listened to Jeremy.

02:29:32.080 --> 02:29:33.040
It's all his fault.

02:29:33.040 --> 02:29:40.800
But there's a kind of very refreshing, pragmatic view that he has about machine learning that

02:29:42.400 --> 02:29:49.760
I don't know if it's this mix of a desire for efficiency, but ultimately grounded and

02:29:49.840 --> 02:29:53.680
desired to make machine learning more accessible to a lot of people.

02:29:53.680 --> 02:29:54.560
I don't know what that is.

02:29:54.560 --> 02:30:00.240
I guess that's coupled with efficiency and performance, but it's not just obsessed about

02:30:00.240 --> 02:30:01.200
performance.

02:30:01.200 --> 02:30:06.480
So a lot of AI and AI research ends up being that it has to go fast enough to get scale.

02:30:07.200 --> 02:30:10.800
So a lot of people don't actually care about performance, particularly on the research side,

02:30:10.800 --> 02:30:14.000
until it allows them to have a bigger data set, right?

02:30:14.000 --> 02:30:18.560
And so suddenly now you care about distributed compute and like all these exotic HPC,

02:30:18.560 --> 02:30:20.160
like you don't actually want to know about that.

02:30:20.160 --> 02:30:24.960
You just want to be able to do more experiments faster and do so with bigger data sets, right?

02:30:24.960 --> 02:30:27.840
And so Jeremy has been really pushing the limits.

02:30:27.840 --> 02:30:31.520
And one of the things I'll say about Jeremy, and there's many things I could say about Jeremy,

02:30:31.520 --> 02:30:35.680
because I'm a fanboy of his, but he fits in his head.

02:30:36.720 --> 02:30:41.360
And Jeremy actually takes the time where many people don't to really dive deep into

02:30:42.080 --> 02:30:46.320
why is the beta parameter of the atom optimizer equal to this, right?

02:30:46.320 --> 02:30:51.200
And he'll go survey and understand what are all the activation functions in the trade-offs

02:30:51.200 --> 02:30:55.680
and why is it that everybody that does this model pick that thing.

02:30:55.680 --> 02:31:00.640
So the why, not just trying different values, like really what is going on here.

02:31:00.640 --> 02:31:01.120
Right.

02:31:01.120 --> 02:31:06.800
And so as a consequence of that, he's always, again, he makes time, but he spends time

02:31:06.800 --> 02:31:09.600
to understand things at a depth that a lot of people don't.

02:31:09.600 --> 02:31:12.320
And as you say, he then brings it and teaches people.

02:31:12.880 --> 02:31:18.640
And his mission is to help lift, his website says, making AI uncool again.

02:31:18.640 --> 02:31:22.480
Like, it's about, like, forget about the hype, it's actually practical and useful.

02:31:22.480 --> 02:31:24.080
Let's teach people how to do this, right?

02:31:24.720 --> 02:31:28.480
Now, the problem Jeremy struggled with is that he's pushing the envelope, right?

02:31:28.480 --> 02:31:33.360
Research isn't about doing the thing that is staying on the happy path or the well-paid road,

02:31:33.360 --> 02:31:34.080
right?

02:31:34.080 --> 02:31:38.640
And so a lot of the systems today have been these really fragile, fragmented things or

02:31:38.640 --> 02:31:40.160
special case in this happy path.

02:31:40.160 --> 02:31:43.440
And if you fall off the happy path, you get eaten by an alligator.

02:31:45.280 --> 02:31:52.000
So what about, so Python has this giant ecosystem of packages

02:31:52.880 --> 02:31:54.640
and is a package repository.

02:31:54.640 --> 02:31:57.520
Do you have ideas of how to do that well for Mojo?

02:31:58.320 --> 02:31:58.560
Yeah.

02:31:58.560 --> 02:32:00.640
How to do a repository of packages?

02:32:00.640 --> 02:32:04.000
Well, so that's another really interesting problem that I knew about,

02:32:04.000 --> 02:32:06.960
but I didn't understand how big of a problem it was.

02:32:06.960 --> 02:32:11.040
Python packaging, a lot of people have very big pain points

02:32:11.040 --> 02:32:12.800
and a lot of scars with Python packaging.

02:32:12.800 --> 02:32:14.880
Oh, you mean, so there's several things to say.

02:32:14.880 --> 02:32:19.840
Building and distributing and managing dependencies and versioning and all this stuff.

02:32:19.840 --> 02:32:23.040
So from the perspective of if you want to create your own package.

02:32:23.040 --> 02:32:23.600
Yes.

02:32:23.600 --> 02:32:26.800
And then, or you want to build on top of a bunch of other people's packages

02:32:26.800 --> 02:32:28.480
and then they get updated and things like this.

02:32:29.040 --> 02:32:33.440
Now, I'm not an expert in this, so I don't know the answer.

02:32:33.440 --> 02:32:36.640
I think this is one of the reasons why it's great that we work as a team and

02:32:36.960 --> 02:32:39.040
there's other really good and smart people involved.

02:32:40.800 --> 02:32:45.440
But one of the things I've heard from smart people who've done a lot of this

02:32:45.440 --> 02:32:50.080
is that the packaging becomes a huge disaster when you get the Python and C together.

02:32:51.040 --> 02:32:55.840
And so if you have this problem where you have code split between Python and C,

02:32:55.840 --> 02:32:59.200
now not only do you have to package the C code, you have to build the C code.

02:33:00.160 --> 02:33:02.480
C doesn't have a package manager, right?

02:33:02.480 --> 02:33:05.920
C doesn't have a dependency versioning management system, right?

02:33:05.920 --> 02:33:09.040
And so I'm not experienced in the state of the art

02:33:09.040 --> 02:33:12.480
and all the different Python package managers,

02:33:12.480 --> 02:33:15.840
but my understanding is that's a massive part of the problem.

02:33:15.840 --> 02:33:18.720
And I think Mojo solves that part of the problem directly heads on.

02:33:19.280 --> 02:33:21.680
Now, one of the things I think we'll do with the community,

02:33:21.680 --> 02:33:25.120
and this isn't, again, we're not solving all the world's problems at once,

02:33:25.120 --> 02:33:27.360
we have to be kind of focused to start with,

02:33:27.360 --> 02:33:32.080
is that I think that we will have an opportunity to reevaluate packaging, right?

02:33:32.080 --> 02:33:33.680
And so I think that we can come back and say,

02:33:33.680 --> 02:33:36.160
okay, well, given the new tools and technologies

02:33:36.160 --> 02:33:38.000
and the cool things we have that we've built up,

02:33:38.000 --> 02:33:39.760
because we have not just syntax,

02:33:39.760 --> 02:33:42.720
we have an entirely new compiler stack that works in a new way,

02:33:42.720 --> 02:33:44.960
maybe there's other innovations we can bring together

02:33:44.960 --> 02:33:46.960
and maybe we can help solve that problem.

02:33:46.960 --> 02:33:50.480
So almost that tangent to that question from the user perspective of packages,

02:33:51.840 --> 02:33:58.160
it was always surprising to me that it was not easier to sort of explore and find packages.

02:33:59.120 --> 02:34:06.000
With PIP install, it feels, it's an incredible ecosystem.

02:34:06.000 --> 02:34:09.280
It's just interesting that it wasn't made,

02:34:09.840 --> 02:34:13.120
it's still, I think, not made easier to discover packages to do,

02:34:13.840 --> 02:34:19.760
like search and discovery, as YouTube calls it.

02:34:19.760 --> 02:34:23.120
Well, I mean, it's kind of funny because this is one of the challenges of these

02:34:24.160 --> 02:34:27.200
intentionally decentralized communities.

02:34:27.280 --> 02:34:29.360
And so I don't know what the right answer is for Python.

02:34:29.360 --> 02:34:32.320
I mean, there are many people that were,

02:34:32.320 --> 02:34:33.680
I don't even know the right answer for Mojo.

02:34:35.120 --> 02:34:38.480
So there are many people that would have much more informed opinions than I do,

02:34:38.480 --> 02:34:40.480
but it's interesting if you look at this, right?

02:34:40.480 --> 02:34:43.680
Open source communities, you know, there's Git,

02:34:44.320 --> 02:34:46.080
Git is a fully decentralized,

02:34:46.080 --> 02:34:47.360
and they can do it any way they want,

02:34:47.360 --> 02:34:49.360
but then there's GitHub, right?

02:34:49.360 --> 02:34:53.120
And GitHub centralized, commercial in that case, right?

02:34:53.120 --> 02:34:56.880
Thing, really help pull together and help solve some of the discovery problems

02:34:56.880 --> 02:35:00.240
and help build a more consistent community.

02:35:00.240 --> 02:35:03.040
And so maybe there's opportunities for something like a GitHub.

02:35:04.160 --> 02:35:06.480
Although even GitHub, I might be wrong on this,

02:35:06.480 --> 02:35:10.480
but the search and discovery for GitHub is not that great.

02:35:10.480 --> 02:35:12.160
Like I still use Google search.

02:35:13.040 --> 02:35:16.800
Yeah, well, I mean, maybe that's because GitHub doesn't want to replace Google search,

02:35:17.760 --> 02:35:18.000
right?

02:35:18.000 --> 02:35:22.480
And I think there is room for specialized solutions to specific problems.

02:35:23.360 --> 02:35:25.280
I don't know, I don't know the right answer for GitHub either.

02:35:25.280 --> 02:35:27.680
That's, they can go figure that out.

02:35:28.720 --> 02:35:30.960
But the point is to have an interface that's usable,

02:35:30.960 --> 02:35:33.760
that's accessible to people of all different skill levels and so on.

02:35:33.760 --> 02:35:36.160
Well, and again, like what are the benefit of standards, right?

02:35:36.160 --> 02:35:39.280
Standards allow you to build these next level up ecosystem,

02:35:39.280 --> 02:35:42.000
the next level up infrastructure, the next level up things.

02:35:42.000 --> 02:35:45.600
And so again, come back to, I hate complexity.

02:35:47.120 --> 02:35:48.640
C plus Python is complicated.

02:35:49.200 --> 02:35:51.280
It makes everything more difficult to deal with.

02:35:51.280 --> 02:35:54.640
It makes it difficult to port, move code around, work with.

02:35:54.640 --> 02:35:56.000
All these things get more complicated.

02:35:56.000 --> 02:35:59.680
And so, I mean, I'm not an expert, but maybe Mojo can help a little bit

02:35:59.680 --> 02:36:02.640
by helping reduce the amount of C in this ecosystem

02:36:02.640 --> 02:36:03.760
and make it therefore scale better.

02:36:03.760 --> 02:36:06.880
So when you kind of package this, the hybrid in nature

02:36:06.880 --> 02:36:09.440
would be a natural fit to move to Mojo.

02:36:09.440 --> 02:36:10.880
Which is a lot of them, by the way.

02:36:12.560 --> 02:36:15.600
A lot of them, especially they're doing some interesting stuff computation-wise.

02:36:16.960 --> 02:36:18.320
Let me ask you about some features.

02:36:18.800 --> 02:36:19.600
Yeah.

02:36:19.600 --> 02:36:23.840
So we talked about, obviously, the indentation that it's the type language

02:36:23.840 --> 02:36:25.120
or optionally typed.

02:36:25.920 --> 02:36:27.120
Is that the right way to say it?

02:36:27.120 --> 02:36:28.720
It's either optionally or progressively.

02:36:28.720 --> 02:36:29.600
Progressively.

02:36:29.600 --> 02:36:33.280
I think, so people have very strong opinions on the right word to use.

02:36:34.320 --> 02:36:34.960
I don't know.

02:36:34.960 --> 02:36:36.400
I look forward to your letters.

02:36:37.760 --> 02:36:39.920
So there's the var versus let.

02:36:39.920 --> 02:36:41.200
But let is for constants.

02:36:42.560 --> 02:36:43.520
Var is an optional.

02:36:44.320 --> 02:36:47.040
Yeah, var makes it mutable, so you can reassign.

02:36:47.120 --> 02:36:52.480
Okay, then there's function overloading.

02:36:52.480 --> 02:36:53.360
Oh, okay, yeah.

02:36:54.320 --> 02:36:56.320
I mean, there's a lot of source of happiness for me,

02:36:56.320 --> 02:37:03.280
but function overloading that's, I guess, is that for performance?

02:37:03.280 --> 02:37:05.920
Or is that, why does Python not have function overloading?

02:37:07.040 --> 02:37:08.080
So I can speculate.

02:37:08.080 --> 02:37:10.400
So Python is a dynamic language.

02:37:10.400 --> 02:37:15.200
The way it works is that Python and Objective-C

02:37:15.200 --> 02:37:19.840
are actually very similar worlds if you ignore syntax.

02:37:20.880 --> 02:37:25.760
And so Objective-C is straight line derived from Smalltalk,

02:37:26.880 --> 02:37:31.760
a really venerable, interesting language that much of the world has forgotten about,

02:37:31.760 --> 02:37:34.240
but the people that remember it, love it, generally.

02:37:35.040 --> 02:37:38.400
And the way that Smalltalk works is that every object has a dictionary in it,

02:37:38.960 --> 02:37:43.280
and the dictionary maps from the name of a function or the name of a value within an object

02:37:43.840 --> 02:37:44.880
to its implementation.

02:37:45.600 --> 02:37:48.400
And so the way you call a method in Objective-C is you say,

02:37:49.040 --> 02:37:52.000
go look up, the way I call foo is I go look up foo,

02:37:52.000 --> 02:37:53.840
I get a pointer to the function back, and then I call it.

02:37:54.400 --> 02:37:56.000
Okay, that's how Python works.

02:37:56.640 --> 02:37:58.480
Right, and so now the problem with that is that

02:37:59.360 --> 02:38:02.480
the dictionary within a Python object, all the keys are strings,

02:38:03.520 --> 02:38:06.480
and it's a dictionary, so you can only have one entry per name.

02:38:06.480 --> 02:38:07.920
You think it's as simple as that?

02:38:07.920 --> 02:38:09.280
I think it's as simple as that.

02:38:09.280 --> 02:38:12.880
And so now, why do they never fix this?

02:38:12.880 --> 02:38:14.720
Like, why do they not change it to not be a dictionary?

02:38:15.680 --> 02:38:16.960
Like, do other things.

02:38:17.920 --> 02:38:21.520
Well, you don't really have to in Python because it's dynamic.

02:38:21.520 --> 02:38:23.440
And so you can say, I get into the function,

02:38:24.160 --> 02:38:27.120
now if I got past an integer, do some dynamic test for it,

02:38:27.120 --> 02:38:29.120
if it's a string, go do another thing.

02:38:30.080 --> 02:38:31.840
There's another additional challenge, which is,

02:38:31.840 --> 02:38:33.840
even if you did support overloading, you're saying,

02:38:33.840 --> 02:38:37.360
okay, well, here's a version of a function for integers and a function for strings.

02:38:38.000 --> 02:38:40.240
Well, you'd have, even if you could put it in that dictionary,

02:38:40.240 --> 02:38:42.320
you'd have to have the caller do the dispatch.

02:38:42.960 --> 02:38:44.800
And so every time you call the function, you'd have to say,

02:38:44.800 --> 02:38:46.400
like, is an integer a string?

02:38:46.400 --> 02:38:48.160
And so you'd have to figure out where to do that test.

02:38:48.720 --> 02:38:54.080
And so in a dynamic language, overloading is something you don't have to have.

02:38:55.920 --> 02:38:57.920
But now you get into a typed language.

02:38:57.920 --> 02:39:01.760
And in Python, if you subscript with an integer,

02:39:02.640 --> 02:39:06.080
then you get typically one element out of a collection.

02:39:06.080 --> 02:39:09.440
If you subscript with a range, you get a different thing out.

02:39:10.160 --> 02:39:14.160
Right? And so often in typed languages, you'll want to be able to express the fact that,

02:39:14.160 --> 02:39:19.040
cool, I have different behavior depending on what I actually pass into this thing.

02:39:19.040 --> 02:39:23.040
If you can model that, it can make it safer and more predictable and faster and like all these things.

02:39:23.680 --> 02:39:28.000
It somehow feels safe for yes, but also feels empowering.

02:39:28.000 --> 02:39:32.400
Make it in terms of clarity, like you don't have to design whole different functions.

02:39:32.400 --> 02:39:38.560
Yeah. Well, this is also one of the challenges with the existing Python typing systems,

02:39:38.560 --> 02:39:43.280
is that in practice, like you take subscript, in practice, a lot of these functions,

02:39:43.280 --> 02:39:45.760
they don't have one signature.

02:39:45.760 --> 02:39:47.680
They actually have different behavior in different cases.

02:39:47.680 --> 02:39:52.400
And so this is why it's difficult to retrofit this into existing Python code and make it

02:39:53.760 --> 02:39:57.440
play well with typing. You kind of have to design for that.

02:39:57.440 --> 02:40:02.640
Okay. So there's an interesting distinction that people that program Python might be interested in

02:40:02.640 --> 02:40:07.680
is def versus fn. So it's two different ways to define a function.

02:40:08.960 --> 02:40:15.600
And fn is a stricter version of def. What's the coolness that comes from the strictness?

02:40:16.160 --> 02:40:19.120
So here you get into what is the trade off with the superset?

02:40:19.760 --> 02:40:20.000
Yes.

02:40:21.120 --> 02:40:24.960
So superset, you have to, or you really want to be compatible.

02:40:25.680 --> 02:40:30.000
If you're doing a superset, you've decided compatibility with existing code

02:40:30.000 --> 02:40:33.760
is the important thing, even if some of the decisions they made were maybe not what you'd

02:40:33.760 --> 02:40:38.320
choose. Okay. So that means you put a lot of time in compatibility,

02:40:38.320 --> 02:40:40.800
and it means that you get locked into decisions of the past,

02:40:41.840 --> 02:40:47.360
even if they may not have been a good thing. Now, systems programmers typically like to control

02:40:47.360 --> 02:40:54.000
things. And they want to make sure that, not in all cases, of course, and even systems programmers

02:40:54.000 --> 02:40:59.520
are not one thing, but often you want predictability. And so one of the things that Python has,

02:40:59.520 --> 02:41:03.360
for example, as you know, is that if you define a variable, you just say x equals four.

02:41:04.000 --> 02:41:10.480
I have a variable name to x. Now I say some long, some long name equals 17.

02:41:11.280 --> 02:41:17.280
Print out some long name. Oops, I typoed it. Right. Well, the compiler, the Python compiler

02:41:17.280 --> 02:41:22.560
doesn't know, in all cases, what you're defining and what you're using. And did you typo the use

02:41:22.560 --> 02:41:29.360
of it or the definition? Right. And so for people coming from type languages, again, I'm not saying

02:41:29.360 --> 02:41:33.280
the right or wrong, but that drives them crazy because they want the compiler to tell them you

02:41:33.280 --> 02:41:38.160
typoed the name of this thing. Right. And so what fn does is it turns on, as you say, it's a strict

02:41:38.160 --> 02:41:42.080
mode. And so it says, okay, well, you have to actually declare, intentionally declare your

02:41:42.080 --> 02:41:46.640
variables before you use them. That gives you more predictability, more error checking and

02:41:46.640 --> 02:41:54.960
things like this. But you don't have to use it. And this is a way that Mojo is both compatible

02:41:54.960 --> 02:41:58.800
because devs work the same way that devs have already always worked. But it provides a new

02:41:58.800 --> 02:42:02.640
alternative that gives you more control and allows certain kinds of people to have a different

02:42:02.640 --> 02:42:08.240
philosophy to be able to express that and get that. But usually, if you're writing Mojo code

02:42:08.240 --> 02:42:14.160
from scratch, you'll be using fn. It depends. Again, it depends on your mentality. It's not

02:42:14.160 --> 02:42:20.400
that dev is Python and fn is Mojo. Mojo has both and it loves both. It really depends on...

02:42:20.400 --> 02:42:25.040
Time is just strict. Yeah, exactly. Are you playing around and scripting something out?

02:42:25.040 --> 02:42:30.960
Is it a one off throwaway script? Cool. Python is great at that. I will still be using fn, but yeah.

02:42:31.680 --> 02:42:37.360
I love strictness. Control, power. You also like suffering, right?

02:42:38.000 --> 02:42:45.600
Yes. You go hand in hand. How many pull-ups? I've lost count at this point.

02:42:46.320 --> 02:42:50.240
And that's cool. I love you for that. And I love other people who like strict things,

02:42:50.240 --> 02:42:55.120
right? But I don't want to say that that's the right thing because Python is also very beautiful

02:42:55.120 --> 02:42:59.520
for hacking around and doing stuff and research and these other cases where you may not want that.

02:42:59.520 --> 02:43:03.920
You see, I just feel like... Maybe I'm wrong with that, but it feels like strictness

02:43:03.920 --> 02:43:09.920
leads to faster debugging. So in terms of going from... Even on a small project from zero to

02:43:09.920 --> 02:43:14.320
completion, it just... I guess it depends how many bugs you generate usually.

02:43:14.880 --> 02:43:18.400
Well, so I mean, it's again lessons learned and looking at the ecosystem. It's really...

02:43:19.280 --> 02:43:24.160
I mean, I think it's... If you study some of these languages over time, like the Ruby community,

02:43:24.160 --> 02:43:28.480
for example. Now, Ruby is a pretty well-developed, pretty established community,

02:43:28.480 --> 02:43:33.920
but along their path, they really invested in unit testing. So I think that the Ruby community is

02:43:33.920 --> 02:43:38.480
really pushed forward the state-of-the-art of testing because they didn't have a type system

02:43:38.480 --> 02:43:43.120
that caught a lot of bugs at compile time. And so you can have the best of both worlds. You

02:43:43.120 --> 02:43:47.360
can have good testing and good types and things like this. But I thought that it was really

02:43:47.360 --> 02:43:51.120
interesting to see how certain challenges get solved. And in Python, for example,

02:43:51.920 --> 02:43:55.440
the interactive notebook kind of experiences and stuff like this are really amazing.

02:43:55.440 --> 02:43:59.680
And if you typo something, it doesn't matter. It just tells you. That's fine, right? And so

02:43:59.680 --> 02:44:04.640
I think that the tryouts are very different if you're building a large-scale production system

02:44:04.640 --> 02:44:09.200
versus you're building and exploring in a notebook. And speaking of control, the hilarious thing, if

02:44:09.200 --> 02:44:14.240
you look at code, I write just for myself for fun. It's like littered with asserts everywhere.

02:44:16.240 --> 02:44:18.240
It's a kind of... Yeah, you'd like that.

02:44:18.480 --> 02:44:25.920
Yes. It's basically saying in a dictatorial way, this should be true now. Otherwise,

02:44:25.920 --> 02:44:33.520
everything stops. And that is the sign. I can't... I love you, man. But that is the sign of somebody

02:44:33.520 --> 02:44:38.800
who likes control. And so, yes, I think that you'll like... And I think you'll like mojo.

02:44:38.800 --> 02:44:46.080
Therapy session. Yes, I definitely will. Speaking of asserts, exceptions are called errors.

02:44:46.160 --> 02:44:52.320
Why is it called errors? So, I mean, we use the same... We're the same as Python, right? But we

02:44:52.320 --> 02:44:57.600
implement it a very different way. And so, if you look at other languages, like we'll pick on C++,

02:44:57.600 --> 02:45:04.400
our favorite, right? C++ has a thing called zero-cost exception handling. Okay. And this is,

02:45:05.680 --> 02:45:11.520
in my opinion, something to learn lessons from. It's a nice polite way of saying it.

02:45:11.520 --> 02:45:18.560
And so, zero-cost exception handling, the way it works is that it's called zero-cost because

02:45:19.440 --> 02:45:25.440
if you don't throw an exception, there's supposed to be no overhead for the non-error code. And so,

02:45:25.440 --> 02:45:33.760
it takes the error path out of the common path. It does this by making throwing an error extremely

02:45:33.760 --> 02:45:39.120
expensive. And so, if you actually throw an error with a C++ compiler using exceptions,

02:45:39.200 --> 02:45:42.960
let's go look up in tables on the side and do all this stuff. And so, throwing an error could be

02:45:42.960 --> 02:45:49.200
like 10,000 times more expensive than returning from a function, right? Also, it's called zero-cost

02:45:49.200 --> 02:45:53.840
exceptions, but it's not zero-cost. By any stretch of the imagination, because it massively blows

02:45:53.840 --> 02:45:59.600
out your code, your binary, it also adds a whole bunch of different paths because of

02:45:59.600 --> 02:46:03.760
destructors and other things like that that exist in C++. And it reduces the number of

02:46:03.760 --> 02:46:08.240
optimizations. It adds like all these effects. And so, this thing that was called zero-cost

02:46:08.240 --> 02:46:17.280
exceptions, it really ain't. Okay. Now, if you fast forward to newer languages, and this includes

02:46:17.280 --> 02:46:24.400
Swift and Rust and Go and now Mojo, well, and Python's a little bit different because it's

02:46:24.400 --> 02:46:27.920
interpreted. And so, it's got a little bit of a different thing going on. But if you look at

02:46:27.920 --> 02:46:35.680
compiled languages, many newer languages say, okay, well, let's not do that zero-cost exception

02:46:35.680 --> 02:46:43.840
handling thing. Let's actually treat throwing an error the same as returning a variant, returning

02:46:43.840 --> 02:46:50.720
either the normal result or an error. Now, programmers generally don't want to deal with

02:46:50.720 --> 02:46:56.240
all the typing machinery and like pushing around a variant. And so, you use all the syntax that

02:46:56.240 --> 02:47:01.440
Python gives us, for example, try and catch, you know, functions that raise and things like this,

02:47:01.440 --> 02:47:06.640
you can put a raises, decorator on your functions, stuff like this. And if you want to control that,

02:47:06.640 --> 02:47:12.480
and then the language can provide syntax for it. But under the hood, the way the computer executes it,

02:47:12.480 --> 02:47:15.520
throwing an error is basically as fast as returning something.

02:47:15.520 --> 02:47:19.040
I think so it's exactly the same way from a compiled perspective.

02:47:19.040 --> 02:47:24.960
And so, this is actually, I mean, it's a fairly nerdy thing, right? Which is why I love it. But

02:47:25.920 --> 02:47:33.280
this has a huge impact on the way you design your APIs, right? So in C++, huge communities turn

02:47:33.280 --> 02:47:40.320
off exceptions, because the cost is just so high, right? And so the zero cost cost is so high, right?

02:47:40.320 --> 02:47:47.520
And so that means you can't actually use exceptions in many libraries, right? And even for the people

02:47:47.520 --> 02:47:53.440
that do use it, well, okay, how and when do you want to pay the cost? If I try to open a file,

02:47:53.440 --> 02:47:58.400
should I throw an error? Well, what if I'm probing around looking for something, right?

02:47:58.400 --> 02:48:02.400
I'm looking it up in many different paths. Well, if it's really slow to do that, maybe I'll add

02:48:02.400 --> 02:48:07.600
another function that doesn't throw an error returns an error code instead. And I have two

02:48:07.600 --> 02:48:13.040
different versions the same thing. And so it causes you to fork your APIs. And so, you know,

02:48:13.040 --> 02:48:17.520
one of the things I learned from Apple and I so love is the art of API design is actually

02:48:17.520 --> 02:48:21.680
really profound. I think this is something that Python's also done a pretty good job at in terms

02:48:21.680 --> 02:48:26.640
of building out this large scale package ecosystem, it's about having standards and things like this.

02:48:26.640 --> 02:48:31.920
And so, you know, we wouldn't want to enter a mode where, you know, there's this theoretical feature

02:48:31.920 --> 02:48:36.720
that exists in language, but people don't use it in practice. Now, I'll also say one of the other

02:48:36.720 --> 02:48:40.800
really cool things about this implementation approach is that it can run on GPUs and it can run

02:48:40.800 --> 02:48:46.080
accelerators and things like this. And that standard zero cost exception thing would never

02:48:46.080 --> 02:48:50.800
work on an accelerator. And so this is also part of how Mojo can scale all the way down to like

02:48:50.800 --> 02:48:54.080
little embedded systems and to running on GPUs and things like that.

02:48:54.640 --> 02:49:01.920
Can you actually say about the maybe is there some high level way to describe the challenge of

02:49:02.800 --> 02:49:09.120
exceptions and how they work in code during compilation? So just this idea of percolating

02:49:09.120 --> 02:49:15.680
up a thing, an error. Yeah. Yeah. So the way the way to think about it is think about a function

02:49:15.680 --> 02:49:22.000
that doesn't return anything. Just as a simple case, right? And so you have function one calls

02:49:22.000 --> 02:49:27.040
function two calls function three calls function four, along that call stack that are tri blocks.

02:49:27.760 --> 02:49:31.680
Right. And so if you have function one calls function two function two has a tri block,

02:49:31.680 --> 02:49:36.160
and then within it, it calls function three, right? Well, what happens if function three throws?

02:49:37.840 --> 02:49:41.760
Well, actually start simpler. What happens if it returns? Well, if it returns, it's supposed to

02:49:41.760 --> 02:49:45.600
go back out and continue executing and then fall off the bottom of the tri block and keep going

02:49:45.600 --> 02:49:50.480
and it all's good. If the function throws, you're supposed to exit the current function

02:49:51.200 --> 02:49:55.760
and then get into the accept clause, right? And then do whatever codes there and then keep

02:49:55.760 --> 02:50:01.760
following on and going on. And so the way that a compiler like Mojo works is that the call to

02:50:01.760 --> 02:50:06.720
that function, which happens in the accept block calls a function and then instead of returning

02:50:06.720 --> 02:50:14.160
nothing, it actually returns, you know, a variant between nothing and an error. And so if you return

02:50:14.160 --> 02:50:20.080
normally off the bottom or do return, you return nothing. And if you throw through an error, you

02:50:21.360 --> 02:50:26.400
return the variant that is I'm an error, right? So when you get to the call, you say, okay, cool,

02:50:26.400 --> 02:50:32.240
I called a function. Hey, I know locally I'm in a tri block. Right. And so I, I call the function

02:50:32.240 --> 02:50:36.560
and then I check to see what it returns. A half is that error thing jump to the accept block.

02:50:37.200 --> 02:50:41.360
And that's all done for you behind the scenes. Exactly. And so the compiler does all this for

02:50:41.360 --> 02:50:45.440
you. And I mean, one of the things if you dig into how this stuff works in Python,

02:50:45.440 --> 02:50:50.160
it gets a little bit more complicated because you have finally blocks, which now need, you need to

02:50:50.160 --> 02:50:57.120
go into do some stuff. And then those can also throw and return. Wait, what? Like the stuff matters

02:50:57.200 --> 02:51:02.960
compatibility. Like there's, there's nest them. There's with clauses. And so with clauses are

02:51:02.960 --> 02:51:07.040
kind of like finally blocks of some special stuff going on. And so there's nesting in general,

02:51:07.040 --> 02:51:14.080
nesting of anything nesting of functions should be illegal. It just feels like it adds a level

02:51:14.080 --> 02:51:21.520
of complexity. I'm merely an implementer. And so this is again, one of the trade offs you get

02:51:21.520 --> 02:51:26.400
when you decide to build a super set is you get to implement a full fidelity implementation of the

02:51:26.400 --> 02:51:34.000
thing that you decided is good. And so, yeah, I mean, we can, we can complain about the reality

02:51:34.000 --> 02:51:39.200
of the world and shake our fists, but it always feels like you shouldn't be a lot to do that,

02:51:39.200 --> 02:51:45.360
like to declare functions and sudden functions inside functions. Wait, wait, wait, what happened

02:51:45.360 --> 02:51:51.440
to Lex the Lisp guy? No, I understand that. But Lisp is what I used to do in college.

02:51:52.400 --> 02:51:53.360
So now you've grown up.

02:51:54.720 --> 02:52:00.080
You know, we've all done things in college. We're not part of, no, I love Lisp. I love Lisp.

02:52:00.080 --> 02:52:03.200
Okay. Yeah, I was going to say, you're afraid of me. You're taking the whole internet.

02:52:05.200 --> 02:52:10.640
It's, it's, uh, it worked. It worked as a joke in my head. So nested functions are

02:52:10.640 --> 02:52:14.720
joking aside, actually really great. And for certain things, right? And so these are also

02:52:14.720 --> 02:52:19.440
called closures. Closures are pretty cool. And you can pass callbacks. There's a lot of good

02:52:19.440 --> 02:52:26.320
patterns. And so, uh, so speaking of which, I don't think you have, uh, nested functions

02:52:26.320 --> 02:52:33.360
implemented yet in Mojo. Uh, we don't have Lambda syntax, but we do have, uh, there's a few things

02:52:33.360 --> 02:52:38.400
on the roadmap that you have that it'd be cool to sort of just fly through. Cause it's interesting

02:52:38.400 --> 02:52:44.800
to see, you know, how many features there are in a language, small and big, they have to implement.

02:52:44.800 --> 02:52:49.120
Yeah. So first of all, there's tuple support and that has to do with some very specific

02:52:49.120 --> 02:52:53.440
aspect of it. Like the parentheses are not parentheses that. Yeah. This is just a totally

02:52:53.440 --> 02:52:57.760
a syntactic thing. A syntactic thing. Okay. There's, but it's cool. It's still, uh,

02:52:59.040 --> 02:53:03.120
so keyword arguments and functions. Yeah. So this is where in Python, you can say

02:53:03.680 --> 02:53:08.560
call a function x equals four. Yeah. And x is the name of the argument. That's a nice sort of

02:53:08.560 --> 02:53:13.040
documenting self-documenting feature. Yeah. I mean, and again, this isn't rocket science to

02:53:13.040 --> 02:53:18.000
implement. That's just the laundry. It's just on the list. Uh, the bigger features are things

02:53:18.000 --> 02:53:24.640
like traits. So traits are when you want to define abstract. So when you get into typed languages,

02:53:25.200 --> 02:53:29.360
you need the ability to write generics. And so you want to say, I want to write this function.

02:53:29.360 --> 02:53:34.240
And now I want to work on all things that are arithmetic like. Well, what does arithmetic

02:53:34.240 --> 02:53:39.920
like mean? Well, arithmetic like is a categorization of a bunch of types. And so it's,

02:53:40.480 --> 02:53:43.600
again, you can define many different ways and I'm not going to go into ring theory or something.

02:53:44.640 --> 02:53:48.160
But the, uh, you know, you can say it's arithmetic like if you can add the track

02:53:48.160 --> 02:53:51.600
multiply, divide it, for example. Right. And so what you're saying is you're saying

02:53:52.240 --> 02:53:59.280
there's a set of traits that apply to a broad variety of types. And so there, all these types

02:53:59.280 --> 02:54:03.840
are arithmetic like all these tensors and floating point integer. And like there's this category

02:54:03.840 --> 02:54:09.520
of types. And then I can define on an orthogonal access algorithms that then work against

02:54:09.520 --> 02:54:15.920
types that have those properties. And so this is a, again, it's a widely known thing. It's been

02:54:15.920 --> 02:54:22.480
implemented in Swift and Rust and many languages. So it's not Haskell, which is where everybody

02:54:22.480 --> 02:54:28.480
learns, learns their tricks from. But the, but we need to implement that and that'll enable a new

02:54:28.480 --> 02:54:35.200
level of expressivity. So classes. Yeah, classes are a big deal. It's a big deal still to be

02:54:35.200 --> 02:54:42.320
implemented. Um, like you said, a Lambda syntax, and there's like detail stuff like whole module

02:54:42.320 --> 02:54:49.920
import, um, support for top level code at file scope. So, and then global variables also.

02:54:51.600 --> 02:54:55.600
So being able to have variables outside of a top level. Well, and so this comes back to the

02:54:55.600 --> 02:55:01.280
where module came from and the fact that this is your point one, right? And so we're building,

02:55:01.280 --> 02:55:06.000
so modular is building an AI stack, right? And an AI stack has a bunch of problems working with

02:55:06.000 --> 02:55:10.560
hardware and writing high performance kernels and doing this kernel fusion thing I was talking about

02:55:10.560 --> 02:55:15.680
and getting the most out of the hardware. And so we've really prioritized and built Mojo to solve

02:55:15.680 --> 02:55:21.760
modules problem, right? Now our North Star is build out and support all the things. And so we're

02:55:21.760 --> 02:55:26.880
making incredible progress. By the way, Mojo is only like seven months old. So that's another

02:55:26.880 --> 02:55:30.480
interesting thing. I mean, part of the reason I wanted to mention some of these things is like,

02:55:30.560 --> 02:55:37.120
there's a lot to do and it's pretty cool how you just kind of, sometimes you take for granted how

02:55:37.120 --> 02:55:40.640
much there is in a programming language, how many cool features you kind of rely on. And this is

02:55:40.640 --> 02:55:46.320
kind of a nice reminder when you lay it as a to do list. Yeah. And so I mean, but also you look into,

02:55:47.040 --> 02:55:54.080
it's amazing how much is also there. And you take it for granted that a value, if you define it,

02:55:54.080 --> 02:55:59.680
it will get destroyed automatically. Like that little feature itself is actually really complicated,

02:55:59.760 --> 02:56:04.480
given the way the ownership system has to work. And the way that works within Mojo is a huge step

02:56:04.480 --> 02:56:08.720
forward from what Rust and Swift have done. But can you say that again, when a value, when you

02:56:08.720 --> 02:56:12.400
define it gets destroyed on the map? Yeah. So like say you have a string, right? So you just find a

02:56:12.400 --> 02:56:18.160
string on the stack or whatever that means, like in your local function, right? And so you say,

02:56:19.040 --> 02:56:24.640
like, whether it be in a def, and so you just say x equals hello world, right? Well, if your

02:56:24.640 --> 02:56:30.480
string type requires you to allocate memory, then when it's destroyed, you have to deallocate it.

02:56:30.480 --> 02:56:35.600
So in Python and Mojo, you define that with the Dell method, right? Where does that get run?

02:56:38.800 --> 02:56:46.160
Well, it gets run sometime between the last use of the value and the end of the program.

02:56:47.120 --> 02:56:50.960
Like in this, you now get into garbage collection, you get into like all these

02:56:51.040 --> 02:56:57.120
long debated, you talk about religions and tradeoffs and things like this. This is a hugely

02:56:57.120 --> 02:57:04.000
hotly contested world. If you look at C++, the way this works is that if you define a variable,

02:57:04.000 --> 02:57:10.640
or a set of variables within a function, they get destroyed in a last in first out order.

02:57:10.640 --> 02:57:16.640
So it's like nesting. This has a huge problem because if you define, you have a big scope,

02:57:16.640 --> 02:57:20.640
and you define a whole bunch of values at the top, and then you use them, and then you do a whole

02:57:20.640 --> 02:57:24.640
bunch of code that doesn't use them, they don't get destroyed until the very end of that scope.

02:57:25.680 --> 02:57:30.880
And so this also destroys tail calls, so good functional programming, right? This has a bunch

02:57:30.880 --> 02:57:35.600
of different impacts on, you talk about reference counting optimizations and things like this,

02:57:35.600 --> 02:57:40.880
a bunch of very low level things. And so what Mojo does is it has a different approach on that

02:57:40.880 --> 02:57:46.720
from any language I'm familiar with, where it destroys them as soon as possible. And by doing

02:57:46.720 --> 02:57:51.120
that, you get better memory use, you get better predictability, you get tail calls that work,

02:57:51.120 --> 02:57:54.720
like you get a bunch of other things, you get better ownership tracking, there's a bunch of

02:57:54.720 --> 02:58:01.280
these very simple things that are very fundamental, that are already built in there in Mojo today,

02:58:01.280 --> 02:58:05.200
that are the things that nobody talks about generally, but when they don't work right,

02:58:05.200 --> 02:58:08.960
you find out and you have to complain about. Is it trivial to know

02:58:10.640 --> 02:58:13.920
what's the soonest possible to delete a thing that's not going to be used again?

02:58:13.920 --> 02:58:18.400
Yeah, well, I mean, it's generally trivial, it's after the last use of it. So if you just find x

02:58:18.400 --> 02:58:21.760
as a string, and then you have some use of x somewhere in your code.

02:58:21.760 --> 02:58:25.120
Within that scope? You mean within the scope that is accessible?

02:58:25.120 --> 02:58:29.120
It's, yeah, exactly. So you can only use something within its scope. And so then

02:58:29.120 --> 02:58:34.160
it doesn't wait until the end of the scope to delete it. It destroys it after the last use.

02:58:34.160 --> 02:58:38.240
So there's kind of some very ego machine that's just sitting there and deleting.

02:58:38.240 --> 02:58:41.120
Yeah, and it's all in the compiler, so it's not at runtime, which is also cool.

02:58:41.840 --> 02:58:47.440
And so, yeah, and so what, and this is actually non-trivial because you have control flow.

02:58:48.480 --> 02:58:51.440
And so it gets complicated pretty quickly. And so like getting this right was not,

02:58:51.440 --> 02:58:54.240
Oh, so you have to insert delete like in a lot of places?

02:58:54.240 --> 02:58:58.240
Potentially, yeah, exactly. So the compiler has to reason about this. And this is where,

02:58:58.240 --> 02:59:01.840
again, it's experience building languages and not getting this right. So again,

02:59:01.840 --> 02:59:05.600
you get another chance to do it and you get basic things like this, right?

02:59:05.600 --> 02:59:09.840
But it's extremely powerful when you do that, right? And so there's a bunch of things like that

02:59:09.840 --> 02:59:15.280
that kind of combine together. And this comes back to the, you get a chance to do it the right way,

02:59:15.280 --> 02:59:18.800
do it the right way and make sure that every brick you put down is really good,

02:59:18.800 --> 02:59:22.560
so that when you put more bricks on top of it, they stack up to something that's beautiful.

02:59:22.560 --> 02:59:30.000
Well, there's also like, how many design discussions do there have to be about particular

02:59:30.000 --> 02:59:35.920
details like implementation of particular small features? Because the features that seem small,

02:59:36.400 --> 02:59:42.560
I bet some of them might be like really require really big design decisions.

02:59:42.560 --> 02:59:46.720
Yeah. Well, so, I mean, let me give you another example of this. Python has a feature called

02:59:46.720 --> 02:59:54.080
async await. So it's a new feature, I mean, in the long arc of history, it's a relatively new

02:59:54.080 --> 03:00:00.640
feature, right? That allows way more expressive asynchronous programming. Okay. Again, this is

03:00:00.640 --> 03:00:05.360
a Python's a beautiful thing and they did things that are great for Mojo for completely different

03:00:05.440 --> 03:00:11.440
reasons. The reason the async await got added to Python, as far as I know, is because Python doesn't

03:00:11.440 --> 03:00:17.520
support threads. Okay. And so Python doesn't support threads, but you want to work with

03:00:18.080 --> 03:00:21.840
networking and other things like that that can block. I mean, Python does support threads,

03:00:21.840 --> 03:00:28.240
it's just not its strength. And so they added this feature called async await. It's also seen

03:00:28.240 --> 03:00:34.400
in other languages like Swift and JavaScript and many other places as well. Async await in Mojo

03:00:34.400 --> 03:00:38.480
is amazing. Because we have a high-performance heterogeneous compute runtime underneath the

03:00:38.480 --> 03:00:46.560
covers that then allows non-blocking IO, so you get full use of your accelerator. That's huge,

03:00:46.560 --> 03:00:51.120
turns out. It's actually really an important part of fully utilizing the machine. You talk about

03:00:51.120 --> 03:00:56.000
design discussions. That took a lot of discussions, right? And it probably will require more

03:00:56.000 --> 03:01:00.720
iteration. And so my philosophy with Mojo is that, you know, we have a small team of really

03:01:00.800 --> 03:01:05.760
good people that are pushing forward, and they're very good at the extremely deep knowing how the

03:01:05.760 --> 03:01:11.680
compiler and runtime and all the low-level stuff works together. But they're not perfect. Same

03:01:11.680 --> 03:01:16.800
thing as the Swift team, right? And this is where one of the reasons we released Mojo much earlier

03:01:16.800 --> 03:01:19.920
is so we can get feedback. And we've already renamed a keyword

03:01:20.720 --> 03:01:27.120
due to a community feedback. We use an ampersand, and now it's named in and out. We're not

03:01:27.120 --> 03:01:31.680
renaming existing Python keywords because that breaks compatibility. We're naming things we're

03:01:31.680 --> 03:01:37.280
adding and making sure that they are designed well. We get usage experience. We iterate and work

03:01:37.280 --> 03:01:41.040
with the community because, again, if you scale something really fast and everybody writes all

03:01:41.040 --> 03:01:44.960
their code and they start using it in production, then it's impossible to change. And so you want

03:01:44.960 --> 03:01:49.280
to learn from people. You want to iterate and work on that early on. And this is where design

03:01:49.280 --> 03:01:55.040
discussions, it's actually quite important. Could you incorporate an emoji into the language,

03:01:55.040 --> 03:01:58.880
into the main language? Do you have a favorite one?

03:01:59.520 --> 03:02:05.440
Why really inters the humor, like rawful, whatever, rolling on the floor laughing?

03:02:06.240 --> 03:02:11.760
So that could be like, what would that be, the use case for that? Like throw an exception

03:02:11.760 --> 03:02:18.400
of some sort? You should totally file a feature request. Or maybe a hard one. It has to be a

03:02:18.400 --> 03:02:23.360
hard one. People have told me that I'm insane. I'm liking this.

03:02:24.320 --> 03:02:29.440
I'm going to use the viral nature of the internet to actually get this past.

03:02:30.160 --> 03:02:33.120
I mean, it's funny you come back to the flame emoji, file extension, right?

03:02:35.440 --> 03:02:41.040
We have the option to use the flame emoji, which just even that concept cause, for example,

03:02:41.040 --> 03:02:43.280
the people at GitHub to say, now I've seen everything.

03:02:45.600 --> 03:02:52.720
Yeah, there's something, it's reinvigorating. It's like, oh, that's possible. That's really

03:02:52.720 --> 03:02:56.400
cool that for some reason that makes everything else seem really exciting.

03:02:56.400 --> 03:02:59.920
I think the world is ready for this stuff, right? And so, you know, when we have a package manager,

03:02:59.920 --> 03:03:04.080
we'll clearly have to innovate by having the compiled package saying be the little

03:03:04.080 --> 03:03:08.640
box with the bow on it, right? I mean, it has to be done.

03:03:08.640 --> 03:03:12.240
It has to be done. Is there some stuff on the roadmap that you're particularly

03:03:12.880 --> 03:03:15.920
stressed about or excited about that you're thinking about a lot?

03:03:15.920 --> 03:03:21.120
I mean, as a today snapshot, which will be obsolete tomorrow, the lifetime stuff is really

03:03:21.120 --> 03:03:27.040
exciting. And so lifetimes give you safe references to memory without dangling pointers.

03:03:27.680 --> 03:03:30.720
And so this has been done in languages like Rust before. And so we have a new approach,

03:03:30.720 --> 03:03:34.800
which is really cool. I'm very excited about that. That'll be out to the community very soon.

03:03:35.520 --> 03:03:41.040
The traits feature is really a big deal. And so that's blocking a lot of API design.

03:03:41.040 --> 03:03:43.280
And so there's that. I think that's really exciting.

03:03:45.200 --> 03:03:47.760
A lot of it is these kind of table stakes features.

03:03:48.720 --> 03:03:52.160
One of the things that is, again, also lessons learned with Swift

03:03:53.840 --> 03:03:57.680
is that programmers in general like to add syntactic sugar.

03:03:58.880 --> 03:04:03.200
And so it's like, oh, well, this annoying thing, like in Python, you have to spell

03:04:03.200 --> 03:04:09.280
unbar unbar add. Why can't I just use plus? Def plus, come on. Why can't I just do that, right?

03:04:09.280 --> 03:04:13.920
And so trivial bit of syntactic sugar, it makes sense. It's beautiful. It's obvious.

03:04:13.920 --> 03:04:20.560
We're trying not to do that. And so for two different reasons, one of which is that, again,

03:04:20.560 --> 03:04:26.720
lesson learned with Swift. Swift has a lot of syntactic sugar, which may be a good thing,

03:04:26.720 --> 03:04:31.760
maybe not. I don't know. But because it's such an easy and addictive thing to do,

03:04:31.760 --> 03:04:37.680
sugar, like make sure blood get crazy, right? Like the community will really dig into that and

03:04:37.680 --> 03:04:41.360
want to do a lot of that. And I think it's very distracting from building the core abstractions.

03:04:41.920 --> 03:04:44.240
The second is we want to be a good member of the Python community,

03:04:46.240 --> 03:04:51.920
right? And so we want to work with the broader Python community. And yeah, we're pushing forward

03:04:51.920 --> 03:04:55.280
a bunch of systems programming features, and we need to build them out to understand them.

03:04:55.280 --> 03:04:59.600
But once we get a long ways forward, I want to make sure that we go back to the Python community

03:04:59.600 --> 03:05:02.720
and say, okay, let's do some design reviews. Let's actually talk about this stuff. Let's figure

03:05:02.720 --> 03:05:07.280
out how we want this stuff all to work together. And syntactic sugar just makes all that more

03:05:07.280 --> 03:05:13.760
complicated. And yeah, list comprehension is like yet to be implemented. And my favorite,

03:05:13.760 --> 03:05:21.360
I mean, dictionaries. Yeah, there's some basic zero point one, zero point one. But nonetheless,

03:05:21.360 --> 03:05:25.680
it's actually still quite interesting and useful. As you mentioned, modular is very new.

03:05:27.120 --> 03:05:34.240
Mojo is very new. It's a relatively small team. Yeah, that's building up this gigantic stack.

03:05:34.960 --> 03:05:38.960
This incredible stack that's going to perhaps define the future of

03:05:40.000 --> 03:05:45.040
development of our AI overlords. We just hope it will be useful.

03:05:46.720 --> 03:05:54.400
As do all of us. So what, what have you learned from this process of building up a team? Maybe

03:05:54.400 --> 03:06:01.440
one question is, how do you hire? Yeah, great programmers, great people that operate in this

03:06:02.400 --> 03:06:11.520
compiler, hardware, machine learning, software, interface design space. And maybe you're a

03:06:11.520 --> 03:06:17.440
little bit fluid in what they can do. So okay, so language design too. So building a company is

03:06:17.440 --> 03:06:23.120
just as interesting in different ways as building a language, like different skill sets, different

03:06:23.120 --> 03:06:26.720
things, but super interesting. And I've built a lot of teams in a lot of different places.

03:06:27.680 --> 03:06:30.400
If you zoom in from the big problem into recruiting,

03:06:31.520 --> 03:06:36.400
well, so here's our problem. Okay, I'll just, I'll be very straightforward about this.

03:06:36.400 --> 03:06:40.880
We started modular with a lot of conviction about we understand the problems, we understand the

03:06:40.880 --> 03:06:45.920
customer pain points, we need to work backwards from the suffering in the industry. And if we

03:06:45.920 --> 03:06:50.640
solve those problems, we think it'll be useful for people. But the problem is, is that the people

03:06:50.640 --> 03:06:55.920
we need to hire, as you say, are all these super specialized people that have jobs at big tech

03:06:57.280 --> 03:07:03.040
big tech worlds, right? And, you know, we, I don't think we have product market fit in the way that

03:07:03.040 --> 03:07:08.480
a normal startup does, we don't have product market fit challenges, because right now,

03:07:08.480 --> 03:07:12.720
everybody's using AI and so many of them are suffering and they want help. And so again,

03:07:12.720 --> 03:07:17.520
we started with strong conviction. Now, again, you have to hire and recruit the best and the

03:07:17.520 --> 03:07:22.080
best all have jobs. And so what we've done is we said, okay, well, let's build an amazing culture.

03:07:23.040 --> 03:07:26.960
Start with that. That's usually not something a company starts with. Usually you hire a bunch

03:07:26.960 --> 03:07:31.680
of people and then people start fighting and it turns into a gigantic mess. And then you try to

03:07:31.680 --> 03:07:35.760
figure out how to improve your culture later. My co-founder, Tim, in particular, is super

03:07:35.760 --> 03:07:40.240
passionate about making sure that that's right. And we've spent a lot of time early on to make

03:07:40.240 --> 03:07:44.640
sure that we can scale. Can you comment, sorry, before we get to the second, what makes for a

03:07:44.640 --> 03:07:49.920
good culture? So I mean, there's many different cultures. And I have learned many things from

03:07:50.880 --> 03:07:56.560
several very unique, almost famously unique cultures. And some of them I learned what to do

03:07:56.560 --> 03:08:04.800
and some of them I learned what not to do. And so we want an inclusive culture. I believe in

03:08:06.560 --> 03:08:11.360
amazing people working together. And so I've seen cultures where people, you have amazing people

03:08:11.360 --> 03:08:16.640
and they're fighting each other. I see amazing people and they're told what to do. Like,

03:08:16.640 --> 03:08:20.400
doubt, shout, line up and do what I say. It doesn't matter if it's the right thing. Do it.

03:08:21.520 --> 03:08:25.760
And neither of these, and I've seen people that have no direction. They're just kind of floating

03:08:25.760 --> 03:08:30.480
in different places. And they want to be amazing. They just don't know how. And so a lot of it starts

03:08:30.480 --> 03:08:37.040
with have a clear vision. And so we have a clear vision of what we're doing. And so I kind of grew

03:08:37.040 --> 03:08:44.000
up at Apple in my engineering life. And so a lot of the Apple DNA rubbed off on me. My co-founder,

03:08:44.080 --> 03:08:49.120
Tim, also is like a strong product guy. And so what we learned is, you know, I decided Apple that

03:08:49.120 --> 03:08:54.320
you don't work from building cool technology. You don't work from, like, come up with a cool

03:08:54.320 --> 03:08:57.600
product and think about the features you'll have in the big checkboxes and stuff like this.

03:08:58.240 --> 03:09:00.960
Because if you go talk to customers, they don't actually care about your product.

03:09:01.520 --> 03:09:05.040
They don't care about your technology. What they care about is their problems.

03:09:06.000 --> 03:09:10.480
Right? And if your product can help solve their problems, well, hey, they might be interested

03:09:10.560 --> 03:09:14.000
in that. And so if you speak to them about their problems, if you understand and you

03:09:14.000 --> 03:09:18.000
have compassion, you understand what people are working with, then you can work backwards to

03:09:18.000 --> 03:09:21.680
building an amazing product. So the vision starts by defining the problem.

03:09:21.680 --> 03:09:25.920
And then you can work backwards in solving technology. And at Apple, like it's, I think,

03:09:25.920 --> 03:09:31.680
pretty famously said that, you know, for every, you know, there's 100 no's for every yes.

03:09:32.880 --> 03:09:38.320
I would refine that to say that there's 100 not yet for every yes. But famously, if you go back

03:09:38.320 --> 03:09:42.800
to the iPhone, for example, right, the iPhone one, I read, I mean, many people laughed at it

03:09:42.800 --> 03:09:45.200
because it didn't have 3G. It didn't have copy and paste.

03:09:46.560 --> 03:09:51.840
Right. And then a year later, okay, finally, it has 3G, but it still doesn't have copy and paste.

03:09:51.840 --> 03:09:54.880
It's a joke. Nobody will ever use this product, blah, blah, blah, blah, blah, blah, blah,

03:09:54.880 --> 03:09:59.600
blah, right? Well, your three had copy and paste and people stopped talking about it.

03:09:59.600 --> 03:10:04.960
Right. And so, and so being laser focused and having conviction and understanding

03:10:04.960 --> 03:10:08.880
what the core problems are and giving the team the space to be able to build the right tech

03:10:09.440 --> 03:10:14.560
is really important. Also, I mean, you come back to recruiting, you have to pay well.

03:10:15.600 --> 03:10:18.560
Right. So we have to pay industry leading salaries and have good benefits and things

03:10:18.560 --> 03:10:23.600
like this. That's a big piece. We're a remote first company. And so we have to,

03:10:26.320 --> 03:10:32.960
so remote first has a very strong set of pros and cons. On the one hand, you can hire people

03:10:33.040 --> 03:10:36.800
from wherever they are and you can attract amazing talent, even if they live in

03:10:36.800 --> 03:10:40.880
strange places or unusual places. On the other hand, you have time zones.

03:10:42.000 --> 03:10:47.040
On the other hand, you have like everybody on the internet will fight if they don't understand

03:10:47.040 --> 03:10:51.440
each other. And so we've had to learn how to like have a system where we actually fly people in

03:10:51.440 --> 03:10:55.600
and we get the whole company together periodically and then we get work groups together and we plan

03:10:55.600 --> 03:10:59.840
and execute together. And there's like an intimacy to the in-person brainstorming.

03:11:00.560 --> 03:11:04.560
Yeah, I guess you lose, but maybe you don't. Maybe if you get to know each other well and

03:11:04.560 --> 03:11:08.240
you trust each other, maybe you can do that. Yeah. Well, so when the pandemic first hit,

03:11:08.240 --> 03:11:12.640
I mean, I'm curious about your experience too. The first thing I missed was having whiteboards.

03:11:12.640 --> 03:11:19.040
Yeah. Right. Those design discussions are like, I can high intensity work through things, get

03:11:19.040 --> 03:11:22.880
things done, work through the problem of the day, understand where you're on, figure out and solve

03:11:22.880 --> 03:11:29.360
the problem and move forward. But we figured out ways to work around that now with

03:11:30.080 --> 03:11:34.480
all these screen sharing and other things like that that we do. The thing I miss now

03:11:34.480 --> 03:11:41.600
is sitting down at a lunch table with the team, the spontaneous things like the coffee bar

03:11:41.600 --> 03:11:46.400
things and the bumping into each other and getting to know people outside of the transactional

03:11:46.960 --> 03:11:53.360
solve a problem over Zoom thing. And I think there's just a lot of stuff that I'm not an expert

03:11:53.360 --> 03:11:57.680
at this. I don't know who is, hopefully there's some people, but there's stuff that somehow is

03:11:57.680 --> 03:12:04.240
missing on Zoom. Even with the whiteboard, if you look at that, if you have a room with one

03:12:04.240 --> 03:12:11.120
person at the whiteboard and there's like three other people at a table, there's a, first of all,

03:12:11.120 --> 03:12:15.680
there's a social aspect of that where you're just shooting the shit a little bit, almost like.

03:12:15.680 --> 03:12:22.320
Yeah. As people just kind of coming in and yeah, that, but also while like it's a breakout

03:12:22.320 --> 03:12:28.240
discussion that happens for like seconds at a time, maybe an inside joke or it's like this

03:12:28.240 --> 03:12:32.240
interesting dynamic that happens that Zoom. And you're bonding. Yeah. You're bonding. You're

03:12:32.240 --> 03:12:36.960
bonding, but through that bonding, you get the excitement. There's certain ideas that are like

03:12:37.600 --> 03:12:43.200
complete bullshit and you'll see that in the faces of others that you won't see necessarily on Zoom.

03:12:44.160 --> 03:12:50.640
And like something, it feels like that should be possible to do without being in person.

03:12:50.640 --> 03:12:56.320
Well, I mean, being in person is a very different thing. It's worth it, but you can't always do it.

03:12:56.320 --> 03:13:02.240
And so again, we're still learning and we're also learning as like humanity with this new reality,

03:13:02.240 --> 03:13:07.200
right? But what we found is that getting people together, whether it be a team or the whole

03:13:07.200 --> 03:13:11.760
company or whatever, is worth the expense because people work together and are happier

03:13:12.640 --> 03:13:17.920
after that. Like there's a massive period of time where you go out and things start getting

03:13:17.920 --> 03:13:22.560
frayed, pull people together, and then you realize that we're all working together. We see things the

03:13:22.560 --> 03:13:26.240
same way. We work through the disagreement or the misunderstanding. We're talking across each other

03:13:26.240 --> 03:13:30.640
and then you work much better together. And so things like that, I think are really quite important.

03:13:30.640 --> 03:13:35.840
What about people that are kind of specialized in very different aspects of the stack working

03:13:35.840 --> 03:13:39.600
together? What are some interesting challenges there? Yeah. Well, so I mean, I mean, there's

03:13:39.600 --> 03:13:42.720
lots of interesting people, as you can tell, I'm, you know, hard to deal with too.

03:13:43.440 --> 03:13:50.080
You're one of the most lovable people. So one of the, so there's different

03:13:50.080 --> 03:13:55.920
philosophies in building teams. For me, and so some people say, hire 10x programmers,

03:13:55.920 --> 03:14:00.480
and that's the only thing that whatever that means, right? What I believe in is building

03:14:00.480 --> 03:14:06.640
well balanced teams. Teams that have people that are different in them. Like if you have all generals

03:14:06.640 --> 03:14:12.240
and no troops, or all troops and no generals, or you have all people that think in one way,

03:14:12.240 --> 03:14:16.400
and not the other way, what you get is you get a very biased and skewed and weird situation where

03:14:16.400 --> 03:14:20.720
people end up being unhappy. And so what I like to do is I like to build teams of people where

03:14:20.720 --> 03:14:26.160
they're not all the same. You know, we do have teams that are focused on like runtime or compiler,

03:14:26.160 --> 03:14:31.760
GPU or whatever the specialty is, but people bring a different take and have a different

03:14:31.760 --> 03:14:36.320
perspective. And I look for people that complement each other. And particularly if you look at

03:14:36.320 --> 03:14:40.960
leadership teams and things like this, you don't want everybody thinking the same way. You want

03:14:40.960 --> 03:14:45.360
people bringing different perspectives and experiences. And so I think that's really important.

03:14:45.360 --> 03:14:50.960
That's team, but what about building a company as ambitious as modular? So what are some

03:14:50.960 --> 03:14:57.440
interesting questions there? Oh, I mean, so many. Like, so one of the things I love about, okay, so

03:14:57.440 --> 03:15:05.520
modular is the first company I built from scratch. One of the first things that was profound was I'm

03:15:05.520 --> 03:15:10.880
not cleaning up somebody else's mess. Right. And so if you look at that's liberating to some degree.

03:15:10.880 --> 03:15:17.520
It's super liberating. And also, many of the projects I've built in the past have not been

03:15:17.520 --> 03:15:26.160
core to the product of the company. Swift is not Apple's product, right? MLIR is not Google's

03:15:26.160 --> 03:15:31.280
revenue machine or whatever, right? It's not, it's important. But it's like working on the

03:15:31.280 --> 03:15:37.760
accounting software for, you know, the retail giant or something, right? It's like enabling

03:15:37.760 --> 03:15:44.400
infrastructure and technology. And so at modular, the tech we're building is here to solve people's

03:15:44.400 --> 03:15:49.120
problems. Like it is directly the thing we're giving to people. And so this is a really big

03:15:49.120 --> 03:15:53.680
difference. And what it means for me as a leader, but also for many of our engineers is they're

03:15:53.680 --> 03:15:58.560
working on the thing that matters. And that's actually pretty, I mean, again, for compiler

03:15:58.560 --> 03:16:03.440
people and things like that, that's usually not the case, right? And so that's also pretty exciting

03:16:03.440 --> 03:16:10.400
and quite nice. But one of the ways that this manifests is it makes it easier to make decisions.

03:16:11.200 --> 03:16:14.720
And so one of the challenges I've had in other worlds is it's like, okay, well,

03:16:15.440 --> 03:16:21.040
community matters somehow for the goodness of the world, like, or open-source matters

03:16:21.040 --> 03:16:27.040
theoretically, but I don't want to pay for a t-shirt, right? Or some swag. Like, well,

03:16:27.040 --> 03:16:32.800
t-shirts cost $10 each. You can have 100 t-shirts for $1,000 to a mega-corp. $1,000 is

03:16:33.680 --> 03:16:39.120
uncountably, can't count that low, right? But justifying it and getting a t-shirt,

03:16:39.120 --> 03:16:41.040
by the way, if you'd like a t-shirt, I can give you a t-shirt.

03:16:41.040 --> 03:16:45.120
Well, I would 100% like a t-shirt. Are you joking?

03:16:45.120 --> 03:16:50.720
You can have a fire emoji t-shirt. I will treasure this.

03:16:50.720 --> 03:16:53.120
Is that a good thing? I will pass it down to my grandchildren.

03:16:53.120 --> 03:16:57.200
And so it's very liberating to be able to decide, I think that Lex should have a t-shirt,

03:16:58.800 --> 03:17:02.080
right? And it becomes very simple because I like Lex.

03:17:04.800 --> 03:17:11.840
This is awesome. So I have to ask you about the...

03:17:13.840 --> 03:17:16.720
One of the interesting developments with large language models

03:17:16.960 --> 03:17:23.760
is that they're able to generate code recently really well.

03:17:25.040 --> 03:17:25.600
Yes.

03:17:25.600 --> 03:17:31.760
To a degree that maybe I don't know if you understand, but I have... I struggle to

03:17:31.760 --> 03:17:36.720
understand because it forces me to ask questions about the nature of programming,

03:17:36.720 --> 03:17:43.360
of the nature of thought, because the language models are able to predict the kind of code

03:17:43.360 --> 03:17:48.960
I was about to write so well that it makes me wonder how unique my brain is and where the

03:17:48.960 --> 03:17:56.560
valuable ideas actually come from. How much do I contribute in terms of ingenuity, innovation,

03:17:57.120 --> 03:18:03.120
to code, I write, or design, and that kind of stuff. When you stand on the shoulders of giants,

03:18:03.120 --> 03:18:08.400
are you really doing anything? And what LLMs are helping you do is they help you stand on

03:18:08.400 --> 03:18:12.560
the shoulders of giants in your program. There's mistakes. They're interesting that you learned

03:18:12.560 --> 03:18:19.280
from, but I would love to get your opinion first high-level of what you think about this

03:18:19.280 --> 03:18:24.080
impact of large language models when they do program synthesis, when they generate code.

03:18:27.040 --> 03:18:33.280
I don't know where it all goes. I'm an optimist and I'm a human optimist. I think that

03:18:34.000 --> 03:18:38.000
things I've seen are that a lot of the LLMs are really good at crushing leak code projects,

03:18:38.640 --> 03:18:42.880
and they can reverse the link list like crazy. Well, it turns out there's a lot of

03:18:43.920 --> 03:18:47.920
instances of that on the internet, and it's a pretty stock thing. And so if you want to see

03:18:48.960 --> 03:18:52.800
standard questions answered, LLMs can memorize all the answers, and that can be amazing.

03:18:52.800 --> 03:18:58.480
And also, they do generalize out from that, and so there's good work on that. But I think that

03:18:59.280 --> 03:19:03.680
in my experience, building things, building something like you talk about mojo or you talk

03:19:03.760 --> 03:19:08.640
about these things or you talk about building an applied solution to a problem, it's also about

03:19:08.640 --> 03:19:12.400
working with people. It's about understanding the problem. What is the product that you want to

03:19:12.400 --> 03:19:16.240
build? What are the use case? What are the customers? You can't just go survey all the

03:19:16.240 --> 03:19:20.720
customers because they'll tell you that they want a faster horse. Maybe they need a car.

03:19:21.440 --> 03:19:26.800
And so a lot of it comes into, I don't feel like we have to compete with LLMs. I think they'll

03:19:26.800 --> 03:19:32.080
help automate a ton of the mechanical stuff out of the way. And just like, I think we all try

03:19:32.080 --> 03:19:37.040
to scale through delegation and things like this. Delegating wrote things to an LLM, I think,

03:19:37.040 --> 03:19:42.240
because it's extremely valuable and approach that will help us all scale and be more productive.

03:19:42.240 --> 03:19:46.480
But I think it's a fascinating companion. But I'd say I don't think that that means that we're

03:19:46.480 --> 03:19:54.000
going to be done with coding. Sure. But there's power in it as a companion. And from there,

03:19:54.000 --> 03:20:00.480
I would love to zoom in on to mojo a little bit. Do you think about that? Do you think about

03:20:00.480 --> 03:20:08.000
LLMs generating mojo code and helping sort of like, we design new programming language, it almost

03:20:08.000 --> 03:20:15.360
seems like, man, it would be nice to sort of, almost as a way to learn how I'm supposed to use

03:20:15.360 --> 03:20:22.160
this thing for them to be trained on some of the mojo code. So I do lead an AI company. So maybe

03:20:22.160 --> 03:20:29.280
there'll be a mojo LLM at some point. But if your question is like, how do we make a language to be

03:20:29.280 --> 03:20:38.240
suitable for LLMs? I think the cool thing about LLMs is you don't have to. And so if you look at

03:20:38.240 --> 03:20:42.400
what is English or any of these other terrible languages that we as humans deal with on a

03:20:42.400 --> 03:20:47.440
continuous basis, they're never designed for machines. And yet, they're the intermediate

03:20:47.440 --> 03:20:52.640
representation, they're the exchange format that we humans use to get stuff done. And so these

03:20:52.640 --> 03:20:57.440
programming languages, they're an intermediate representation between the human and the computer

03:20:57.440 --> 03:21:03.520
or the human and the compiler, roughly, right? And so I think the LLMs will have no problem learning

03:21:04.240 --> 03:21:08.560
whatever keyword we pick. Maybe the phi emoji is going to... Maybe that's going to break it,

03:21:08.560 --> 03:21:13.760
it doesn't tokenize. No, the reverse of that, it will actually enable it because one of the issues

03:21:13.760 --> 03:21:19.600
I could see with being a superset of Python is there would be confusion by the gray area. So it

03:21:19.600 --> 03:21:25.920
would be mixing stuff. But... Well, I'm a human optimist, I'm also an LLM optimist. I think that

03:21:25.920 --> 03:21:34.320
we'll solve that problem. But you look at that and you say, okay, well, reducing the rote thing,

03:21:34.320 --> 03:21:38.480
right? Turns out compilers are very particular and they really want things, they really want the

03:21:38.480 --> 03:21:42.000
indentation to be right. They really want the colon to be there on your else or else that will

03:21:42.000 --> 03:21:48.240
complain, right? I mean, compilers can do better at this, but LLMs can totally help solve that

03:21:48.240 --> 03:21:53.040
problem. And so I'm very happy about the new predictive coding and co-pilot type features

03:21:53.040 --> 03:21:55.840
and things like this because I think it will all just make us more productive.

03:21:55.840 --> 03:22:01.440
It's still messy and fuzzy and uncertain, unpredictable, so... But is there a future you

03:22:01.440 --> 03:22:08.880
see given how big of a leap GPT-4 was, where you start to see something like LLMs inside

03:22:09.520 --> 03:22:14.400
a compiler or no? I mean, you could do that. Yeah, absolutely. I mean, I think that would be

03:22:14.400 --> 03:22:21.200
interesting. Is that wise? Well, I mean, it would be very expensive. So compilers run fast and they're

03:22:21.200 --> 03:22:25.360
very efficient and LLMs are currently very expensive. There's on-device LLMs and there's

03:22:25.360 --> 03:22:30.240
other things going on and so maybe there's an answer there. I think that one of the things that I

03:22:30.240 --> 03:22:37.600
haven't seen enough of is that... So LLMs to me are amazing when you tap into the creative potential

03:22:37.600 --> 03:22:43.920
of the hallucinations, right? And so if you're doing creative brainstorming or creative writing

03:22:43.920 --> 03:22:49.600
or things like that, the hallucinations work in your favor. If you're writing code that has to be

03:22:49.600 --> 03:22:52.720
correct because you're going to ship it in production, then maybe that's not actually a feature.

03:22:53.840 --> 03:22:57.920
And so I think that there has been research and there has been work on building

03:22:58.640 --> 03:23:04.240
algebraic reasoning systems and figuring out more things that feel like proofs.

03:23:04.960 --> 03:23:08.000
And so I think that there could be interesting work in terms of building more

03:23:08.640 --> 03:23:13.040
reliable at scale systems and that could be interesting. But if you chase that rabbit hole

03:23:13.040 --> 03:23:17.440
down, the question then becomes how do you express your intent to the machine? And so maybe you want

03:23:17.440 --> 03:23:23.840
LLMs to provide the spec, but you have a different kind of net that then actually implements the code.

03:23:23.840 --> 03:23:30.400
Right. So it's used as documentation and inspiration versus the actual implementation.

03:23:30.400 --> 03:23:39.040
Yeah, potentially. Since a successful modular will be the thing that runs, I say so jokingly,

03:23:39.040 --> 03:23:46.560
are AI overlords. But AI systems that are used across... I know it's a cliche term, but in

03:23:46.640 --> 03:23:52.080
a lot of things. So across... So I'll joke and say like AGI should be written in Mojo.

03:23:52.080 --> 03:23:56.960
Yeah, AGI should be written in Mojo. You're joking, but it's also possible that it's not a joke.

03:23:58.640 --> 03:24:05.440
That a lot of the ideas behind Mojo is seems like the natural set of ideas that would enable

03:24:05.440 --> 03:24:13.120
at scale training and inference of AI systems. So I just have to ask you about the big philosophical

03:24:13.120 --> 03:24:19.040
question about human civilization. So folks like Eliezer Yatkowski are really concerned about the

03:24:19.040 --> 03:24:29.600
threat of AI. Do you think about the good and the bad that can happen at scale deployment of AI systems?

03:24:29.600 --> 03:24:33.920
Well, so I've thought a lot about it and there's a lot of different parts to this problem,

03:24:33.920 --> 03:24:39.520
everything from job displacement to sky nut, things like this. And so you can zoom in to

03:24:39.520 --> 03:24:47.360
sub parts of this problem. I'm not super optimistic about AGI being solved next year.

03:24:48.320 --> 03:24:54.000
I don't think that's going to happen personally. So you have a kind of zen like calm about. Is

03:24:54.000 --> 03:25:01.360
there's a nervousness because the leap of GBT4 seemed so big. Sure. It's like we're almost...

03:25:02.000 --> 03:25:06.400
There's some kind of transition era period. You're thinking... Well, so I mean,

03:25:06.400 --> 03:25:11.760
there's a couple of things going on there. One is I'm sure GPT5 and 7 and 19 will be

03:25:11.760 --> 03:25:17.200
also huge leaps. They're also getting much more expensive to run. And so there may be a limiting

03:25:17.200 --> 03:25:22.560
function in terms of just expense on one hand and train. That could be a limiter that slows things

03:25:22.560 --> 03:25:29.360
down. But I think the bigger limiter outside of sky nut takes over and I don't spend any time thinking

03:25:29.360 --> 03:25:32.720
about that because if sky nut takes over and kills us all, then I'll be dead. So I don't worry about

03:25:32.720 --> 03:25:40.080
that. Other things worry about, I'll just focus on. I'll focus and not worry about that one.

03:25:41.280 --> 03:25:47.760
But I think that the other thing I'd say is that AI moves quickly, but humans move slowly and we

03:25:47.760 --> 03:25:54.800
adapt slowly. And so what I expect to happen is just like any technology diffusion, the promise

03:25:54.800 --> 03:26:01.120
and then the application takes time to roll out. And so I think that I'm not even too worried about

03:26:01.760 --> 03:26:05.920
autonomous cars defining away all the taxi drivers. Remember, autonomy is supposed to be

03:26:05.920 --> 03:26:13.600
solved by 2020? Boy, do I remember. And so I think that on the one hand we can see amazing

03:26:13.600 --> 03:26:19.040
progress, but on the other hand we can see that the reality is a little bit more complicated

03:26:19.040 --> 03:26:23.840
and it may take longer to roll out than you might expect. Well, that's in the physical space. I do

03:26:23.840 --> 03:26:29.520
think in the digital space is the stuff that's built on top of LLMs that runs

03:26:31.120 --> 03:26:36.160
millions of apps that could be built on top of them. And that could be run on millions of devices,

03:26:36.160 --> 03:26:44.880
millions of types of devices. I just think that the rapid effect it has on human civilization could

03:26:44.880 --> 03:26:53.760
be truly transformative to it. And there I think it depends on are you an optimist or a pessimist

03:26:53.760 --> 03:27:02.080
or a masochist? Just to clarify, optimist about human civilization. Me too. And so I look at that

03:27:02.080 --> 03:27:06.880
as saying, okay, cool, what will AI do? And so some people say, oh my god, is it going to destroy

03:27:06.880 --> 03:27:11.760
us all? How do we prevent that? I kind of look at it from a, is it going to unlock us all?

03:27:12.640 --> 03:27:15.520
You talk about coding, is it going to make so I don't have to do all the repetitive stuff?

03:27:16.560 --> 03:27:21.600
Well, suddenly that's a very optimistic way to look at it. And you look at what a lot of these

03:27:21.600 --> 03:27:25.360
technologies have done to improve our lives. And I want that to go faster.

03:27:27.120 --> 03:27:31.120
What do you think the future of programming looks like in the next 10, 20, 30, 50 years

03:27:32.160 --> 03:27:40.720
with LLMs and with Mojo with modular, like your vision for devices, the hardware to the

03:27:40.720 --> 03:27:45.520
compilers to this, to the different stacks of software. Yeah. Well, so what I want, I mean,

03:27:45.920 --> 03:27:53.120
coming back to my arch nemesis, it's complexity. So again, me being the optimist, if we drive down

03:27:53.120 --> 03:27:58.000
complexity, we can make these tools, these technologies, these cool hardware widgets

03:27:58.000 --> 03:28:02.560
accessible to way more people. And so what I'd love to see is more personalized experiences,

03:28:02.560 --> 03:28:07.280
more things, the research getting into production instead of being lost at NeurIPS.

03:28:08.240 --> 03:28:15.760
Right. And like these things that impact people's lives by entering products. And so one of the

03:28:15.760 --> 03:28:21.360
things that I'm a little bit concerned about is right now, the big companies are investing huge

03:28:21.360 --> 03:28:26.720
amounts of money and are driving the top line of AI capability forward really quickly. But if it

03:28:26.720 --> 03:28:33.120
means that you have to have $100 million to train a model or more $100 billion, right? Well, that's

03:28:33.120 --> 03:28:37.840
going to make it very concentrated with very few people in the world that can actually do this

03:28:37.840 --> 03:28:44.160
stuff. I would much rather see lots of people across the industry be able to participate and use

03:28:44.160 --> 03:28:48.080
this, right? And you look at this, you know, I mean, a lot of great research has been done

03:28:48.640 --> 03:28:55.040
in the health world and looking at like detecting pathologies and doing radiology with AI and like

03:28:55.040 --> 03:28:59.680
doing all these things. Well, the problem today is that to deploy and build these systems, you have

03:28:59.680 --> 03:29:06.880
to be an expert in radiology and an expert in AI. And if we can break down the barriers so that more

03:29:06.880 --> 03:29:13.440
people can use AI techniques, it's more like programming Python, which roughly everybody

03:29:13.440 --> 03:29:17.600
can do if they want to, right? Then I think that we'll get a lot more practical application of

03:29:17.600 --> 03:29:23.040
these techniques and a lot more niche year, cool, but narrower demands. And I think that's

03:29:23.040 --> 03:29:27.520
that's going to be really cool. Do you think we'll have more or less programmers in the world than

03:29:27.520 --> 03:29:32.720
now? Well, so I think we'll have more more programmers, but they may not consider themselves

03:29:32.720 --> 03:29:36.080
to be programmers. That'd be a different name for you, right? I mean, do you consider somebody

03:29:36.080 --> 03:29:41.760
that uses, you know, I think that arguably the most popular programming language is Excel?

03:29:42.640 --> 03:29:48.400
Yeah. Right? Yep. And so do they consider themselves to be programmers? Maybe not. I mean,

03:29:48.400 --> 03:29:55.440
some of them make crazy macros and stuff like that. But but but what what you mentioned, Steve

03:29:55.440 --> 03:30:02.160
Jobs, is it's the bicycle for the mind that allows you to go faster, right? And so I think that as

03:30:02.160 --> 03:30:07.280
we look forward, right? What is AI? I look at it as hopefully a new programming paradigm. It's like

03:30:07.280 --> 03:30:11.520
object-oriented programming, right? If you want to write a cat to texture, you don't use for loops.

03:30:12.320 --> 03:30:16.560
Turns out that's not the right tool for the job, right? And so right now, unfortunately,

03:30:16.560 --> 03:30:20.640
because I mean, it's not unfortunate, but it's just kind of where where things are. AI is this

03:30:20.640 --> 03:30:25.840
weird, different thing that's not integrated into programming languages and normal tool chains and

03:30:25.840 --> 03:30:30.720
all the technology is really weird and doesn't work right. And you have to babysit it. And

03:30:30.720 --> 03:30:35.040
every time you switch hardware, it's different. It shouldn't be that way. When you change that,

03:30:35.040 --> 03:30:39.360
when you fix that, suddenly, again, the tools technologies can be way easier to use. You

03:30:39.360 --> 03:30:42.960
can start using them for many more things. And so that's that's why I would be excited about.

03:30:43.680 --> 03:30:48.160
What kind of advice could you give to somebody in high school right now or maybe early college

03:30:48.160 --> 03:30:55.440
who's curious about programming and feeling like the world is changing really quickly here?

03:30:55.440 --> 03:31:00.960
Yeah. Well, what kind of stuff to learn? What kind of stuff to work on? Should they finish college?

03:31:00.960 --> 03:31:05.440
Should they go work at a company? Should they build a thing? What do you think?

03:31:05.440 --> 03:31:10.000
Well, so I mean, one of the things I'd say is that you'll be most successful if you work on

03:31:10.000 --> 03:31:16.640
something you're excited by. And so don't get the book and read the book cover to cover and study

03:31:16.640 --> 03:31:21.520
and memorize and recite and flashcard and go build something. Like go solve a problem. Go

03:31:21.520 --> 03:31:28.000
build the thing that you want to exist. Go build an app. Go train a model. Like go build something

03:31:28.000 --> 03:31:32.400
and actually use it and set a goal for yourself. And if you do that, then you'll, you know,

03:31:32.400 --> 03:31:36.720
there's a success. There's the adrenaline rush. There's the achievement. There's the unlock that

03:31:36.720 --> 03:31:40.720
I think is where, you know, if you keep setting goals and you keep doing things and building

03:31:40.720 --> 03:31:45.760
things, learning by building is really powerful. In terms of career advice, I mean,

03:31:45.760 --> 03:31:51.680
everybody's different. It's very hard to give generalized advice. I'll speak as a compiler

03:31:51.680 --> 03:31:58.880
nerd. If everybody's going left, sometimes it's pretty cool to go right. And so just because

03:31:58.880 --> 03:32:03.840
everybody's doing a thing, it doesn't mean you have to do the same thing and follow the herd.

03:32:03.840 --> 03:32:10.560
In fact, I think that sometimes the most exciting paths through life lead to being curious about

03:32:10.560 --> 03:32:16.480
things that nobody else actually focuses on, right? And turns out that understanding deeply

03:32:16.480 --> 03:32:21.280
parts of the problem that people want to take for granted makes you extremely valuable and

03:32:21.280 --> 03:32:26.720
specialized in ways that the herd is not. And so again, I mean, there's lots of rooms for

03:32:26.720 --> 03:32:31.040
specialization, lots of rooms for generalists. There's lots of room for different kinds and

03:32:31.040 --> 03:32:36.080
parts of the problem. But I think that it's, you know, just because everybody's doing one thing

03:32:36.160 --> 03:32:41.440
doesn't mean you should necessarily do it. And now the herd is using Python. So if you want to

03:32:41.440 --> 03:32:49.200
be a rebel, go check out Mojo and help Chris and the rest of the world fight the arch nemesis

03:32:49.200 --> 03:32:54.080
of complexity, because simple is beautiful. There you go. Because you're an incredible person.

03:32:54.080 --> 03:32:59.040
You've been so kind to me ever since we met. You've been extremely supportive. I'm forever

03:32:59.040 --> 03:33:04.320
grateful for that. Thank you for being who you are, for being legit, for being kind, for fighting

03:33:04.320 --> 03:33:12.400
this really interesting problem of how to make AI accessible to a huge number of people, a huge

03:33:12.400 --> 03:33:17.680
number of devices. Yeah. Well, so Lex, you're a pretty special person too, right? And so I think

03:33:17.680 --> 03:33:22.160
that, you know, one of the funny things about you is that besides being curious and pretty damn

03:33:22.160 --> 03:33:27.600
smart, you're actually willing to push on things. And I think that you've got an agenda to like

03:33:27.600 --> 03:33:33.200
make the world think, which I think is a pretty good agenda. It's a pretty good one. Thank you so

03:33:33.200 --> 03:33:38.000
much for talking, Chris. Yeah, thanks, Lex. Thanks for listening to this conversation with Chris

03:33:38.000 --> 03:33:43.200
Ladner. To support this podcast, please check out our sponsors in the description. And now,

03:33:43.200 --> 03:33:50.160
let me leave you some words from Isaac Asimov. I do not fear computers. I fear the lack of them.

03:33:51.600 --> 03:33:54.480
Thank you for listening and hope to see you next time.

