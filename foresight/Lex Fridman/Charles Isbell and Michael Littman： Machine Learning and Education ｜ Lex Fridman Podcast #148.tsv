start	end	text
0	3760	The following is a conversation with Charles Isbell and Michael Litman.
3760	7200	Charles is the Dean of the College of Computing at Georgia Tech
7200	10720	and Michael is a computer science professor at Brown University.
10720	14800	I've spoken with each of them individually on this podcast
14800	18960	and since they are good friends in real life we all thought it would be fun
18960	23280	to have a conversation together. Quick mention of each sponsor
23280	26960	followed by some thoughts related to the episode. Thank you to
26960	30800	Athletic Greens, the only one drink that I start every day with
30800	35840	to cover all my nutritional bases. AteSleep, a mattress that cools itself
35840	39760	and gives me yet another reason to enjoy sleep. Masterclass,
39760	43520	online courses from some of the most amazing humans in history
43520	47280	and Cash App, the app I use to send money to friends.
47280	50800	Please check out the sponsors in the description to get a discount
50800	54800	and to support this podcast. As a side note, let me say that
54800	58880	having two guests on the podcast is an experiment that I've been meaning to do
58880	62560	for a while. In particular because down the road I
62560	66640	would like to occasionally be a kind of moderator for debates
66640	70480	between people that may disagree in some interesting ways.
70480	74880	If you have suggestions for who you would like to see debate on this podcast,
74880	78480	let me know. As with all experiments of this kind,
78480	83520	it is a learning process. Both the video and the audio might need improvement.
83600	87360	I realized I think I should probably do three or more cameras next time as
87360	91680	opposed to just two and also try different ways to mount the microphone
91680	96960	for the third person. Also, after recording this intro, I'm
96960	101120	going to have to go figure out the thumbnail for the video version of the
101120	105600	podcast since I usually put the guest's head on the thumbnail
105600	109680	and now there's two heads and two names
109680	115120	to try to fit into the thumbnail. It's a kind of a bin packing problem
115120	122160	which in theoretical computer science happens to be an NP-hard problem.
122160	125520	Whatever I come up with, if you have better ideas for the thumbnail, let me
125520	128560	know as well. And in general, I always welcome ideas
128560	132640	how this thing can be improved. If you enjoy it, subscribe on YouTube,
132640	136240	review it with Five Stars Napa podcast, follow on Spotify,
136240	141040	support on Patreon, or connect with me on Twitter at Lex Friedman.
141040	144800	And now here's my conversation with Charles Isbell
144800	150240	and Michael Littman. You'll probably disagree about this question
150240	153440	but what is your biggest, would you say, disagreement
153440	158640	about either something profound and very important or something completely not
158640	161200	important at all? I don't think you have any disagreements at all.
161920	165680	I'm not sure that's true. We walked into that one, didn't we?
165680	170320	So one thing that you sometimes mention is that, and we did this one on
170320	173920	air too, as it were, whether or not machine learning is
173920	177760	computational statistics. It's not. But it is.
177760	182000	Well, it's not. And in particular, and more importantly, it is not just computational
182000	184400	statistics. So what's missing in the picture?
184400	188400	All the rest of it. What's missing? That which is missing.
189120	191440	Well, you can't be wrong now. Well, it's not just the statistics.
191440	194160	He doesn't even believe this. We've had this conversation before.
194160	198000	If it were just the statistics, then we would be happy with where we are.
198720	201040	But it's not just the statistics. That's why it's computational
201040	202560	statistics. Or if it were just the computational.
202560	204560	I agree that machine learning is not just statistics.
204560	206320	It is not just statistics. We can agree on that.
206320	209200	Nor is it just computational statistics. It's computational statistics.
209200	211360	It is computational. What is the computational and
211360	215040	computational statistics? Does this take us into the realm of computing?
215040	222240	It does. But I think perhaps the way I can get him to admit that he's wrong is that it's about rules.
223200	225920	It's about rules. It's about symbols. It's about all these other things.
225920	228800	But statistics is not about rules? I'm going to say statistics is about rules.
228800	231680	It's not just the statistics. It's not just a random variable that you choose
231680	234480	and you have a probability. I think you have a narrow view of statistics.
234480	237840	Okay. Well, then what would be the broad view of statistics that would still allow it to be
237840	242880	statistics and not say history that would make computational statistics okay?
242880	248400	Well, okay. So I had my first sort of research mentor, a guy named Tom Landauer,
249440	252400	taught me to do some statistics, right? Sure.
252400	256800	And I was annoyed all the time because the statistics would say that what I was doing
256800	263680	was not statistically significant. And I was like, but and basically what he said to me is,
263680	268800	statistics is how you're going to keep from lying to yourself, which I thought was really deep.
269520	273920	It is a way to keep yourself honest in a particular way. I agree with that.
273920	278640	Yeah. And so you're trying to find rules. I'm just going to bring it back to rules.
278640	283440	Wait, wait, wait. Could you possibly try to define rules?
284000	287680	Even regular statisticians, non-computational statisticians,
287680	292640	do spend some of their time evaluating rules, right? Applying statistics to try to understand,
292640	295520	does this rule capture this? Does this not capture that?
295520	297520	You mean like hypothesis testing kind of thing? Sure.
297520	302480	Or like confidence intervals? I think more like hypothesis. I feel like the word
302480	306640	statistic literally means like a summary, like a number that summarizes other numbers.
306640	311280	But I think the field of statistics actually applies that idea to things like rules,
311280	316560	to understand whether or not a rule is valid. Do software engineering statistics?
318160	320000	No. Programming languages statistics?
320800	325360	No. Because I think it's useful to think about a lot of what AI machine learning is,
325360	329200	or certainly should be, as software engineering, as programming languages.
330480	335360	If to put it in language that you might understand, the hyperparameters beyond the problem.
335360	337600	The hyperparameters has too many syllables for me to understand.
337600	340080	The hyperparameters. That's better.
340080	342800	That goes around it, right? It's the decisions you choose to make.
342800	345600	It's the metrics you choose to use. It's the loss function.
345600	350000	You want to say the practice of machine learning is different than the practice of statistics.
350000	353360	Like the things you have to worry about and how you worry about them are different.
353360	354480	Therefore, they're different.
354480	358960	Right. At the very least, it's that much is true.
358960	362240	It doesn't mean that statistics computational and otherwise aren't important.
362240	365520	I think they are. I mean, I do a lot of that, for example.
365520	369920	But I think it goes beyond that. I think we could think about game theory in terms of statistics,
369920	373920	but I don't think it's very as useful to do. I mean, the way I would think about it,
373920	378640	or a way I would think about it, is this way. Chemistry is just physics.
378720	379840	Hmm.
379840	383200	But I don't think it's as useful to think about chemistry as being just physics.
383200	387120	It's useful to think about it as chemistry. The level of abstraction really matters here.
387120	390240	So I think there are contexts in which it is useful.
390240	390560	Yes.
390560	391200	I think it's that way, right?
391200	391520	No, that is.
391520	393040	So finding that connection is actually helpful.
393040	396080	And I think that's when I emphasize the computational statistics thing.
396080	401760	I think I want to befriend statistics and not absorb them.
401760	404720	Here's the a way to think about it beyond what I just said, right?
404720	408640	So what would you say, and I want you to think back to a conversation I had a very
408640	413760	long time ago, what would you say is the difference between, say, the early 2000s,
413760	418320	ICML and what we used to call NIPS, NURPS. Is there a difference?
418320	420880	A lot of it, particularly on the machine learning that was done there?
420880	422800	ICML was around that long.
422800	423440	Oh, yeah.
423440	425600	So I clear as the new conference, new-ish.
426720	427360	Yeah, I guess so.
427360	429440	And ICML was around the 2000.
430000	431200	Oh, ICML predates that.
432160	434720	I think my most cited ICML papers from 94.
435440	437920	Michael knows this better than me because, of course, he's significantly older than I am.
437920	444320	But the point is, what is the difference between ICML and NURPS in the late 90s, early 2000s?
444320	448000	I don't know what everyone else's perspective would be, but I had a particular perspective
448000	454720	at that time, which is I felt like ICML was more of a computer science place and that NURPS,
454720	459840	NURPS was more of an engineering place, like the kind of math that happened at the two places.
460480	463680	As a computer scientist, I felt more comfortable with the ICML math,
464400	467920	and the NURPS people would say that that's because I'm dumb.
468800	470880	And that's such an engineering thing to say.
470880	473280	So I agree with that part of it, but I do a little different.
473280	478080	We actually had a nice conversation with Tom Dietrich about this on Twitter just a couple
478080	483600	days ago. I put it a little differently, which is that ICML was machine learning done by computer
483600	490640	scientists, and NURPS was machine learning done by computer scientists trying to impress statisticians,
492800	497120	which was weird because it was the same people, at least by the time I started paying attention.
497120	501360	But it just felt very, very different. And I think that that perspective of whether you're
501360	504560	trying to impress the statisticians or you're trying to impress the programmers is actually
504560	510560	very different and has real impact on what you choose to worry about and what kind of
510560	512560	outcomes you come to. So I think it really matters.
512560	515680	I think computer statistics is a means to an end. It is not an end in some sense.
516800	520640	And I think that really matters here in the same way that I don't think computer science
520640	523040	is just engineering or just science or just math or whatever.
523040	526240	Okay. So I'd have to now agree that now we agree on everything.
526240	531600	Yes. Yes. The important thing here is that my opinions may have changed,
531600	534480	but not the fact that I'm right, I think is what we just came to.
534480	537280	Right. And my opinions may have changed and not the fact that I'm wrong.
537280	541600	That's right. I lost me. I think I lost myself there too.
541840	542960	But anyway, we're back.
542960	546080	We're back. This happens sometimes. We're sorry.
546080	550400	How does neural networks change this, just to even linger on this topic,
551040	559120	change this idea of statistics, how big of a pie statistics is within the machine learning thing?
559120	563520	Like, because it sounds like hyperparameters and also just the role of data.
564240	567680	You know, this people are starting to use this terminology of software 2.0,
568320	571440	which is like the act of programming as a,
574400	578160	like you're a designer in the hyperparameter space of neural networks,
578160	583360	and you're also the collector and the organizer and the cleaner of the data.
583920	585600	And that's part of the programming.
586960	591280	So how did, on the NeurIPS versus ICML topic,
592000	597040	what's the role of neural networks in redefining the size and the role of machine learning?
597680	600960	I can't wait to hear what Michael thinks about this, but I would add one.
600960	601360	But you will.
602720	604240	That's true. I will force myself to.
604240	607280	I think there's one other thing I would add to your description,
607280	610800	which is the kind of software engineering part of what does it mean to debug, for example.
610800	615520	But this is a difference between the kind of computational statistics view of machine learning
615520	618560	and the computational view of machine learning, which is, I think,
618560	622960	one is worried about the equation as it were. And by the way, this is not a value judgment.
622960	626320	I just think it's about perspective. But the kind of questions you would ask,
626320	629600	when you start asking yourself what does it mean to program and develop and build the system,
629600	634160	is a very computer sciencey view of the problem. I mean, when, if you get on
634800	641520	Data Science Twitter and Econ Twitter, you actually hear this a lot with the economist
641520	646160	and the data scientist complaining about the machine learning people. Well, it's just statistics.
646160	649200	And I don't know why they don't see this, but they're not even asking the same questions.
649200	652960	They're not thinking about it as a kind of programming problem.
652960	655760	And I think that that really matters, just asking this question.
655840	661040	I actually think it's a little different from programming and hyperparameters space and sort
661040	667440	of collecting the data. But I do think that that immersion really matters. So I'll give you a quick
667440	670560	example of the way I think about this. So I teach machine learning. Michael and I have
670560	674800	co-taught a machine learning class, which has now reached, I don't know, 10,000 people at least
674800	680240	over the last several years, or somewhere there's abouts. And my machine learning assignments
680240	685040	are of this form. So the super, the first one is something like implement these five algorithms,
685360	691840	K and N and SVMs and boosting and decision trees and neural networks. And maybe that's it,
691840	695920	I can't remember. And when I say implement, I mean, steal the code. I am completely uninterested.
695920	700080	You get zero points for getting the thing to work. And then once you're spending your time
700080	705680	worrying about getting the corner case right of what happens when you are trying to normalize
705680	709120	distances and the points on the thing. And so you divide by zero. I'm not interested in that,
709120	716080	right? Steal the code. However, you're going to run those algorithms on two data sets. The data
716080	719920	sets have to be interesting. What does it mean to be interesting? Well, data sets interesting if
719920	724400	it reveals differences between algorithms, which presumably are all the same, because they can
724400	728560	represent whatever they can represent. And two data sets are interesting together if they show
728560	732640	different differences as it were. And you have to analyze them. You have to justify their
732640	736400	interestingness and you have to analyze them a whole bunch of ways. But all I care about is the
736400	740640	data in your analysis, not the programming. And I occasionally end up in these long discussions
740640	745360	with students. Well, I don't really, I copy and paste the things that I've said the other 15,000
745360	750800	times it's come up, which is they go, but the only way to learn, really understand is to code them
750800	755840	up, which is a very programmer software engineering view of the world. If you don't program it,
755840	760960	you don't understand it, which is, by the way, I think is wrong in a very specific way. But
760960	764720	it is a way that you come to understand because then you have to wrestle with the algorithm.
764720	768160	But the thing about machine learning is it's not just sorting numbers, where in some sense,
768160	771760	the data doesn't matter. What matters is, well, does the algorithm work on these abstract things
771760	776080	upon the list of the other? In machine learning, the data matters. It matters more than almost
776080	782000	anything. And not everything, but almost anything. And so as a result, you have to live with the data
782000	787760	and don't get distracted by the algorithm per se. And I think that that focus on the data
787760	792400	and what it can tell you and what question it's actually answering for you, as opposed to the
792400	796960	question you thought you were asking, is a key and important thing about machine learning and is
796960	801920	a way that computationalists, as opposed to statisticians, bring a particular view about
801920	807840	how to think about the process. The statisticians, by contrast, bring, I think I'd be willing to say,
807840	813120	a better view about the kind of formal math that's behind it and what an actual number,
813840	817760	ultimately, is saying about the data. And those are both important, but they're also different.
818480	824320	I didn't really think of it this way, is to build intuition about the role of data,
824320	828080	the different characteristics of data by having two data sets that are different,
828080	832080	and they reveal the differences and the differences. That's a really fascinating,
832080	837360	that's a really interesting educational approach. The students love it, but not right away.
837360	840800	No, they love it at the end. They love it at the end. Not at the beginning.
842400	847440	Not even immediately after. I feel like there's a deep, profound lesson about education there.
848400	854800	That you can't listen to students about whether what you're doing is the right or the wrong thing.
856000	861280	Well, as a wise, Michael Lippmann once said to me about children, which I think applies to
861280	866320	teaching, is you have to give them what they need without bending to their will.
866960	869840	And students are like that. You have to figure out what they need. You're a curator. Your whole
869840	874560	job is to curate and to present, because on their own, they're not going to necessarily know where
874560	880000	to search. So you're providing pushes in some direction and learn space. And you have to give
880000	886160	them what they need in a way that keeps them engaged enough so that they eventually discover
886160	888800	what they want, and they get the tools they need to go and learn other things.
890000	895520	What's your view, let me put on my Russian hat, which believes that life is like-
895520	898000	I like Russian hats, by the way. If you have one, I would like this.
898000	899120	Those are ridiculous. Yes.
900240	901760	But in a delightful way, but sure.
901760	907600	What do you think is the role of- we talked about balance a little bit.
908320	915200	What do you think is the role of hardship and education? I think the biggest things I've learned,
916720	923920	like what made me fall in love with math, for example, is by being bad at it until I got good
923920	931040	at it. So like struggling with a problem, which increased the level of joy I felt
931040	937840	when I finally figured it out. And it always felt with me, with teachers, especially modern
937840	944160	discussions of education, how can we make education more fun, more engaging, more all those things?
944720	951120	Well, from my perspective, it's like you may be missing the point that education, that life is
951120	957920	suffering. Education is supposed to be hard, and that actually what increases the joy you feel when
957920	963760	you actually learn something. Is that ridiculous? Do you like to see your students suffer?
964320	969200	Okay, so this may be a point where we differ. I suspect not. I'm going to do go on.
970000	971840	Well, what would your answer be? I want to hear you first.
971840	974080	Okay, well, I was going to not answer the question.
975760	978000	Because you don't want the students to know you and hear them suffer?
978080	983680	No, no, no, no, no. I was going to say that there's, I think there's a distinction that you can make in
983680	990160	the kind of suffering. So, I think you can be in a mode where you're suffering in a hopeless way,
990160	994400	versus you're suffering in a hopeful way, where you're like, you can see
996160	1002640	that you still have, you can still imagine getting to the end. And as long as people are
1002640	1004400	where in that mindset, where they're struggling,
1004400	1007440	but it's not a hopeless kind of struggling.
1007440	1009040	That's productive.
1009040	1010520	I think that's really helpful.
1010520	1013640	But it's struggling, like if you break their will,
1013640	1016120	if you leave them hopeless.
1016120	1018640	No, sure, some people are gonna,
1018640	1020480	whatever, lift themselves up by their bootstraps,
1020480	1021920	but like mostly you give up
1021920	1023520	and certainly it takes the joy out of it.
1023520	1025720	And you're not gonna spend a lot of time
1025720	1027840	on something that brings you no joy.
1027840	1030360	So it is a bit of a delicate balance, right?
1030360	1032920	You have to thwart people in a way
1032920	1036200	that they still believe that there's a way through.
1037040	1040000	Right, so that's a, we strongly agree actually.
1040000	1041120	So I think, well, first off,
1041120	1044080	struggling and suffering aren't the same thing, right?
1044080	1045320	Yeah, it's being poetic.
1045320	1047680	Oh no, I actually appreciate the poetry.
1047680	1049720	And one of the reasons I appreciate it
1049720	1051880	is that they are often the same thing
1051880	1052880	and often quite different, right?
1052880	1054560	So you can struggle without suffering.
1054560	1057280	You can certainly suffer pretty easily.
1057280	1058840	You don't necessarily have to struggle to suffer.
1058840	1061880	So I think that you want people to struggle,
1061880	1062960	but that hope matters.
1062960	1064640	You have to, they have to understand
1064640	1066520	that they're gonna get through it on the other side.
1066520	1068760	And it's very easy to confuse the two.
1070080	1072600	I actually think Brown University has a very,
1072600	1075440	just philosophically has a very different take
1075440	1076800	on the relationship with their students,
1076800	1078280	particularly undergrads from say,
1078280	1079840	a place like Georgia Tech, which is-
1079840	1081800	Which university's better?
1081800	1083360	Well, I have my opinions on that.
1083360	1085240	I mean, remember, Charles said,
1085240	1087480	it doesn't matter what the facts are, I'm always right.
1087480	1088320	The correct answer-
1088520	1091000	Is that it doesn't matter, they're different,
1091000	1093200	but clearly answers to that.
1093200	1096920	Well, he went to a school like the school
1096920	1098480	where he is as an undergrad.
1098480	1101080	I went to a school, specifically the same school,
1101080	1103520	though it was changed a bit in the intervening years.
1103520	1104360	Brown or Georgia Tech?
1104360	1105200	No, I was talking about Georgia Tech.
1105200	1108240	And I went to an undergrad place
1108240	1109840	that's a lot like the place where I work now.
1109840	1112400	And so it does seem like we're more familiar
1112400	1113320	with these models.
1113320	1115560	There's a similarity between Brown and Yale?
1115560	1118080	Yeah, I think they're quite similar.
1118400	1119320	And Duke?
1119320	1120960	Duke has some similarities too,
1120960	1122960	but it's got a little Southern draw.
1122960	1125560	You've kind of worked at universities
1125560	1128840	that are like the places where you learned.
1130040	1132200	And the same would be true for me.
1132200	1136160	Are you uncomfortable venturing outside the box?
1136160	1137320	Is that what you're saying?
1137320	1138160	Journey out?
1138160	1139000	Is that what I'm saying?
1139000	1140080	Yeah, Charles is definitely.
1140080	1143000	He only goes to places that have Institute in the name.
1143000	1144120	It has worked out that way.
1144120	1146240	Well, academic places anyway.
1146240	1148280	Well, no, I was a visiting scientist at U-Pen
1148280	1151160	or visiting something at U-Pen.
1151160	1152000	Oh, wow.
1152000	1154160	I just understood your joke.
1154160	1155000	Which one?
1155000	1158080	Five minutes later.
1158080	1160040	I like to set the sort of time bomb.
1160040	1162120	The Institute is in the,
1162120	1164520	that Charles only goes to places that have Institute
1164520	1165840	in the name.
1165840	1167640	So I guess Georgia,
1167640	1170760	I forget that Georgia Tech is Georgia Institute of Technology.
1170760	1172480	The number of people who refer to it
1172480	1175720	as Georgia Tech University is large and incredibly ear-to-ear.
1176920	1177880	It's one of the few things
1177880	1179280	that genuinely gets under my skin.
1179280	1181240	But like schools like Georgia Tech and MIT
1181240	1182840	have as part of the ethos,
1182840	1183960	like there is,
1183960	1187720	I wanna say there's an abbreviation that someone taught me,
1187720	1189760	like IHTFP, something like that.
1189760	1191360	Like there's an expression,
1191360	1192200	which is basically,
1192200	1193520	I hate being here,
1193520	1195640	which they say so proudly.
1195640	1198040	And that is definitely not the ethos at Brown.
1198040	1198880	Like Brown is,
1198880	1202360	there's a little more pampering and empowerment and stuff.
1202360	1203840	And it's not like we're gonna crush you
1203840	1205040	and you're gonna love it.
1205040	1206400	So yeah, I think there's a,
1206400	1209400	I think the ethoses are different.
1209400	1210360	That's interesting, yeah.
1210360	1212160	We had Drownproofing.
1212160	1213000	What's that?
1213000	1213840	Drownproofing.
1213840	1214680	In order to graduate from Georgia Tech,
1214680	1215520	this is a true thing,
1215520	1217000	feel free to look it up.
1217000	1217840	If you-
1217840	1219280	A lot of schools have this, by the way.
1219280	1220120	No.
1220120	1220960	Actually Georgia Tech was barely the first.
1220960	1222000	Brandeis has it.
1222000	1223320	Had it.
1223320	1225800	I feel like Georgia Tech was the first in a lot of things.
1225800	1227520	Georgia Tech was the first in a lot of things.
1227520	1228960	It was the first in a lot of things.
1228960	1230680	Had the first Master's degree in-
1230680	1231520	Stop that.
1232360	1234400	First Masters in Computer Science, actually.
1234600	1235680	Online Masters.
1235680	1237840	Well, that too, but way back in the 60s.
1237840	1238880	NSF, yeah, yeah.
1238880	1240000	You're the first information
1240000	1242840	in Computer Science Masters degree in the country.
1242840	1246600	But the Georgia Tech, it used to be the case
1246600	1248360	that in order to graduate from Georgia Tech,
1248360	1250040	you had to take a Drownproofing class,
1250040	1253080	where effectively they threw you a water to hide you up.
1253080	1254720	If you didn't drown, you got to graduate.
1254720	1255800	Hide you up?
1255800	1256640	I believe so.
1256640	1257480	No.
1257480	1258520	Basically, there were certainly versions of it,
1258520	1260480	but I mean, luckily they ended it
1260480	1261640	just before I had to graduate
1261640	1263200	because otherwise I would have never graduated.
1263200	1264040	It wasn't gonna happen.
1264040	1268080	I want to say 84, 83, someone around them, they ended it,
1268080	1271520	but yeah, it used to have to prove you could tread water
1271520	1273200	for some ridiculous amount of time.
1273200	1274040	Are you two minutes?
1274040	1274880	Congratulations.
1274880	1275720	No, it was more than two minutes.
1275720	1276560	I bet it was two minutes.
1276560	1277400	Okay, well, we'll look at it.
1277400	1278400	And it was in a bathtub.
1280400	1281520	It was in a pool, but it was a real thing.
1281520	1283480	But that idea that, you know, push you-
1283480	1284320	Fully clothed.
1284320	1285280	Yeah, fully clothed.
1285280	1287440	I don't think, I bet it was that and not tied up.
1287440	1288720	Because like, who needs to learn
1288720	1290400	how to swim when you're tied?
1290400	1292520	Nobody, but who needs to learn to swim
1292520	1294200	when you're actually falling into the water dressed.
1294200	1295040	That's a real thing.
1295040	1296680	I think your facts are getting in the way
1296680	1297520	with a good story.
1297520	1298360	Oh, that's fair.
1298360	1299200	That's fair.
1299200	1300040	I didn't mean to.
1300040	1300880	All right, so they tie you up.
1300880	1301960	Sometimes the narrative matters.
1301960	1303280	But whatever it was, you had to,
1303280	1304800	it was called drown proofing for a reason.
1304800	1308160	The point of the story, Michael, is-
1308160	1309000	Struggle.
1309000	1310680	It's, well, no, but that's good.
1310680	1312320	It doesn't bring it back to struggle.
1312320	1314960	That's a part of what Georgia Tech has always been.
1314960	1316720	And we struggle with that, by the way,
1316720	1319880	about what we want to be, particularly as things go.
1319880	1324880	But you sort of, how much can you be pushed
1325480	1326640	without breaking?
1326640	1328920	And you come out of the other end stronger, right?
1328920	1329840	There's this saying we used to have
1329840	1331680	when I was an undergrad there, which was Georgia Tech,
1331680	1333640	building tomorrow the night before.
1333640	1334480	Right?
1334480	1337040	And it was just kind of, kind of idea
1337040	1339480	that give me something impossible to do
1339480	1340920	and I'll do it in a couple of days
1340920	1343080	because that's what I just spent the last four or five
1343080	1344120	or six.
1344120	1346880	That ethos definitely stuck to you.
1346880	1349000	Having now done a number of projects with you,
1349040	1350520	you definitely will do it the night before.
1350520	1351360	That's not entirely true.
1351360	1353640	There's nothing wrong with waiting until the last minute.
1353640	1355680	The secret is knowing when the last minute is.
1355680	1358280	Right, that's brilliantly put.
1358280	1361720	Yeah, that is a definite Charles statement
1361720	1363400	that I am trying not to embrace.
1364880	1365720	Well, I appreciate that
1365720	1367720	because you helped move my last minute back.
1367720	1370360	That's the social construct where you converge
1370360	1372600	together what the definition of last minute is.
1372600	1374720	And we figure that all together.
1374720	1378600	In fact, MIT, I'm sure a lot of universities have this,
1378600	1380400	but MIT has like MIT time
1380400	1383760	that everyone has always agreed together
1383760	1385560	that there is such a concept
1385560	1388760	and everyone just keeps showing up like 10 to 15 to 20
1388760	1391440	depending on the department late to everything.
1391440	1394000	So there's like a weird drift that happens.
1394000	1394840	It's kind of fascinating.
1394840	1396040	Yeah, we're five minutes.
1396040	1396880	We're five minutes.
1396880	1398600	In fact, the classes will say,
1398600	1400400	well, this is no longer true actually,
1400400	1402600	but it used to be a class that started eight
1402600	1404160	but actually started eight or five.
1404160	1406480	It ends at nine, actually it ends at eight, 55.
1406480	1407480	Everything's five minutes off
1407480	1409480	and nobody expects anything to start until five minutes
1409480	1411640	after the half hour, whatever it is.
1411640	1412480	It still exists.
1412480	1413320	That hurts my head.
1413320	1417920	Well, let's rewind the clock back to the 50s and 60s
1417920	1419000	when you guys met.
1419000	1420880	How did you, I'm just kidding, I don't know.
1420880	1423160	But what, can you tell the story of how you met?
1423160	1425960	So you've, like the internet and the world kind of
1425960	1430240	knows you as connected in some ways
1430240	1433160	in terms of education of teaching the world.
1433160	1434800	That's like the public facing thing,
1434800	1436800	but how did you as human beings
1436800	1440760	and as collaborators meet?
1440760	1441840	I think there's two stories.
1441840	1443640	One is how we met
1443640	1446440	and the other is how we got to know each other.
1446440	1448320	I'm not gonna say fall, I'm not gonna say fell in love.
1448320	1451200	I'm gonna say that we came to understand that we...
1451200	1453680	Had some common something.
1453680	1455360	Yeah, it's funny, because on the surface
1455360	1457360	I think we're different in a lot of ways,
1457360	1460560	but there's something that's just consonant.
1461800	1462640	There you go.
1462640	1463480	Afternoon.
1463480	1466000	So I will tell the story of how we met
1466040	1468000	and I'll let Michael tell the story of how we met.
1468000	1468840	Okay, all right.
1468840	1470200	Okay, so here's how we met.
1470200	1473040	I was already at that point it was AT&T Labs.
1473040	1474240	There's a long interesting story there,
1474240	1478880	but anyway, I was there and Michael was coming to interview.
1478880	1480400	He was a professor at Duke at the time,
1480400	1484200	but decided for reasons that he wanted to be in New Jersey.
1485240	1488960	And so that would mean Bell Labs slash AT&T Labs.
1488960	1489800	And we were doing interviews,
1489800	1491720	interviews are very much like academic interviews.
1491720	1493320	And so I had to be there.
1493320	1496320	We all had to meet with him afterwards and so on, one-on-one.
1496320	1499480	But it was obvious to me that he was gonna be hired.
1499480	1501120	Like no matter what, because everyone loved him.
1501120	1503320	They were just talking about all the great stuff he did.
1503320	1504320	Oh, he did this great thing.
1504320	1506480	And you had just won something at AAAI, I think,
1506480	1508560	or maybe you got 18 papers in AAAI that year.
1508560	1511400	I got the best paper award at AAAI for the crossword stuff.
1511400	1512240	Right, exactly.
1512240	1514000	So that had all happened and everyone was going on
1514000	1514840	and on and on about it.
1514840	1516600	Actually, Satinder was saying incredibly nice things
1516600	1517440	about you.
1517440	1518280	Really?
1518280	1519120	Yes, so.
1519120	1519960	He can be very grumpy.
1519960	1520800	Yes.
1520800	1521640	That's nice to hear.
1521640	1522480	He was grumpily saying very nice things.
1522480	1523480	Oh, that makes sense.
1523480	1524320	Yeah, it does make sense.
1524320	1526000	So, you know, so it was gonna come.
1526000	1528120	So why were we, why was I meeting him?
1528120	1529120	I had something else I had to do.
1529120	1529960	I can't remember what it was.
1529960	1530800	Yeah.
1530800	1531640	Probably involved comic books.
1531640	1534240	So he remembers meeting me as inconveniencing his afternoon.
1534240	1536200	So he came, so eventually came to my office.
1536200	1537160	I was in the middle of trying to do something.
1537160	1538000	I can't remember what.
1538000	1539080	And he came and he sat down.
1539080	1541240	And for reasons that are purely accidental,
1541240	1542640	despite what Michael thinks,
1542640	1545400	my desk at the time was set up in such a way
1545400	1546720	that had sort of an L shape.
1546720	1548800	And the chair on the outside was always lower
1548800	1550440	than the chair that I was in.
1550440	1552680	And, you know, the kind of point was to...
1552680	1554480	The only reason I think that it was on purpose
1554480	1556240	is because you told me it was on purpose.
1556240	1557080	I don't remember that.
1557080	1559040	Anyway, the thing is that, you know, it kind of gives...
1559040	1560320	His guest chair was really low
1560320	1562960	so that he could look down at everybody.
1562960	1565000	The idea was just to simply create a nice environment
1565000	1566280	that you were asking for a mortgage.
1566280	1568360	And I was gonna say, no, that was the point.
1568360	1569560	It was a very simple idea here.
1569560	1572320	Anyway, so we sat there and we just talked for a little while.
1572320	1574520	And I think he got the impression that I didn't like him.
1574520	1575360	It wasn't true.
1575360	1576200	He strongly got that impression.
1576200	1577040	The talk was really good.
1577040	1578720	The talk, by the way, was terrible.
1579240	1581160	Right after the talk, I said to my host,
1581160	1583880	Michael Kearns, who ultimately was my boss.
1583880	1585840	I'm a friend and a huge fan of Michael, yeah.
1585840	1588160	Yeah, he is a remarkable person.
1589680	1591200	After my talk, I went into the...
1591200	1592520	He would take a little basketball.
1592520	1593360	I went...
1593360	1594200	Racquetball, he's good at everything.
1594200	1595040	No, basketball.
1595040	1596000	No, but basketball, racquetball too.
1596000	1596840	Squash.
1596840	1597680	Squash, squash, squash.
1597680	1598520	Not racquetball, that's right.
1598520	1600040	Yeah, squash, which is not...
1600040	1601440	Racquetball, yes.
1601440	1602280	Squash, no.
1602280	1604080	And I hope you hear that, Michael.
1604080	1606040	Oh, Michael Kearns.
1606040	1607640	As a game, not his skill level.
1607640	1610080	Because I'm pretty sure he's...
1610080	1611640	All right, there's some competitiveness there.
1611640	1614400	But the point is that it was like the middle of the day.
1614400	1615800	I had full day of interviews.
1615800	1616680	Like, I've met with people,
1616680	1619000	but then in the middle of the day, I gave a job talk.
1619000	1621600	And then there was gonna be more interviews.
1621600	1624960	But I pulled Michael aside and I said,
1624960	1627280	I think it's in both of our best interests
1627280	1628800	if I just leave now.
1628800	1632600	Because that was so bad that it'd just be embarrassing
1632600	1634120	if I have to talk to any more people.
1634120	1636240	Like, you look bad for having invited me.
1636240	1639600	Like, it's just, let's just forget this ever happened.
1639600	1641800	So I don't think the talk went well.
1641800	1643640	That's one of the most Michael Lippman set of sentences
1643640	1644560	I think I've ever heard.
1644560	1645400	He did great.
1645400	1647200	Or at least everyone knew he was great.
1647200	1648200	So maybe it didn't matter.
1648200	1649920	I was there, I remember the talk.
1649920	1651720	And I remember him being very much
1651720	1653960	the way I remember him now in any given week.
1653960	1654800	So it was good.
1654800	1656640	And we met and we talked about stuff.
1656640	1657960	He thinks I didn't like him, but...
1657960	1659320	Because he was so grumpy.
1659320	1660720	Must've been the chair thing.
1660720	1662720	The chair thing and the low voice, I think.
1662720	1663800	Like, he obviously was happy with me.
1663800	1667000	And that slight skeptical look.
1667000	1668560	Yes.
1668560	1670600	I have no idea what you're talking about.
1670600	1671960	Well, I probably didn't have any idea
1671960	1673880	what you were talking about.
1673880	1674840	Anyway, I liked him.
1674840	1675680	He asked me questions.
1675680	1676520	I answered questions.
1676520	1677360	I felt bad about myself.
1677360	1678680	It was a normal day.
1678680	1680680	What's a normal day?
1680680	1681520	And then he left.
1681520	1682360	And then he left.
1682360	1683200	And that's how we met.
1683200	1684040	Can we take a...
1684040	1685880	And then I got hired and I was in the group.
1685880	1689160	Can we take a slight tangent on this topic of,
1689160	1691560	it sounds like, maybe you could speak
1691560	1692600	through the bigger picture.
1692640	1695120	It sounds like you're quite self-critical.
1695120	1695960	Who, Charles?
1695960	1696800	No, you.
1696800	1697640	Oh.
1697640	1698480	I think I can do better.
1698480	1699320	I can do better.
1699320	1700160	Try me again.
1700160	1701000	I'll do better.
1701000	1703600	I'll be self-critical, I won't, I won't, I won't.
1703600	1706640	Yeah, that was like a three out of 10 response.
1708040	1710800	Let's try to work it up to five and six.
1710800	1715200	I remember Marvin Minsky said, on a video interview,
1715200	1718840	something that the key to success in academic research
1718840	1720440	is to hate everything you do.
1723600	1724440	For some reason...
1724440	1725280	I think I followed that
1725280	1726880	because I hate everything he's done.
1728880	1729760	That's a good line.
1729760	1731080	That's a six.
1732640	1733480	Maybe that's a keeper.
1733480	1737680	But do you find that resonance with you at all
1737680	1739760	in how you think about talks and so on?
1739760	1740880	I would say it differently.
1740880	1741720	It's not that...
1741720	1742560	No, not really.
1742560	1744440	That's such an MIT view of the world, though.
1744440	1748480	So I remember talking about this one as a student.
1748480	1750960	You were basically told I will clean it up
1750960	1752360	for the purpose of the podcast.
1753640	1754960	My work is crap, my work is crap,
1754960	1756200	my work is crap, my work is crap.
1756200	1757720	Then you go to a conference or something
1757720	1759080	and you're like, everybody else's work is crap.
1759080	1760040	Everybody else's work is crap.
1760040	1762240	And you feel better and better about it,
1762240	1763320	relatively speaking.
1763320	1765120	And then you sort of keep working on it.
1765120	1766840	I don't hate my work.
1766840	1767680	That resonates with me.
1767680	1768920	Yes, I've never hated my work,
1768920	1773520	but I have been dissatisfied with it.
1773520	1776040	And I think being dissatisfied,
1776040	1777360	being okay with the fact
1777360	1778680	that you've taken a positive step,
1778680	1780400	the derivative's positive.
1780440	1782400	Maybe even the second derivative's positive.
1782400	1785160	That's important because that's a part of the hope, right?
1785160	1787360	But you have to, but I haven't gotten there yet.
1787360	1789960	If that's not there, that I haven't gotten there yet,
1789960	1793520	then it's hard to move forward, I think.
1793520	1795200	So I buy that, which is a little different
1795200	1796480	from hating everything that you do.
1796480	1799400	Yeah, I mean, there's things that I've done
1799400	1801320	that I like better than I like myself.
1801320	1804120	So it's separating me from the work, essentially.
1804120	1806880	So I think I am very critical of myself,
1806880	1808800	but sometimes the work I'm really excited about.
1808800	1810360	And sometimes I think it's kind of good.
1810360	1811200	Does that happen right away?
1811200	1815400	So I found the work that I've liked, that I've done,
1815400	1818480	most of it, I liked it in retrospect
1818480	1821280	more when I was far away from it in time.
1821280	1824440	I have to be fairly excited about it to get done.
1824440	1825440	No, excited at the time,
1825440	1826960	but then happy with the result.
1826960	1828800	But years later, or even I might go back,
1828800	1831200	you know what, that actually turned out to matter.
1831200	1832040	That turned out to matter.
1832040	1834240	Oh gosh, it turns out I've been thinking about that.
1834240	1835400	It's actually influenced all the work
1835400	1837920	that I've done since without realizing it.
1837960	1839280	But that guy was smart.
1839280	1841200	Yeah, that guy had a future.
1841200	1843400	Yeah, yeah.
1843400	1844920	He's going places.
1844920	1847160	I think there's, so yeah, so I think there's something to it.
1847160	1848720	I think there's something to the idea of you gotta,
1848720	1850400	you know, hate what you do, but it's not quite hate.
1850400	1852680	It's just being unsatisfied.
1852680	1854400	And different people motivate themselves differently.
1854400	1856800	I don't happen to motivate myself with self-loathing.
1856800	1858960	I happen to motivate myself with something else.
1858960	1861960	So you're able to sit back and be proud
1861960	1864840	of in retrospect of the work you've done.
1864840	1866600	Well, and it's easier when you can connect it
1866600	1868920	with other people, because then you can be proud of them.
1868920	1870240	I'm proud of the people, yeah.
1870240	1871080	And then the question is.
1871080	1872480	No, you can still safely hate yourself.
1872480	1873800	Yeah, that's right.
1873800	1876160	It's win-win, Michael, or at least win-lose,
1876160	1878480	which is what you're looking for.
1878480	1882240	Oh wow, there's so many brothers and brothers in this.
1882240	1883600	There's levels.
1883600	1886040	So how did you actually meet, meet?
1886040	1886880	Yeah, Michael.
1886880	1888560	So the way I think about it is,
1888560	1892520	because we didn't do much research together at H&T,
1892520	1894560	but then we all got laid off.
1894560	1896480	So that was-
1896480	1897960	By the way, sorry to interrupt,
1897960	1900560	but that was like one of the most magical places,
1900560	1902400	historically speaking.
1902400	1904360	They did not appreciate what they had.
1905760	1906760	And how do we-
1906760	1910240	I feel like there's a profile lesson in there too.
1910240	1911400	How do we get it?
1911400	1913120	Like, why was it so magical?
1913120	1914960	Is it just a coincidence of history,
1914960	1916280	or is there something special about-
1916280	1917760	There were some really good managers
1917760	1920520	and people who really believed in machine learning
1920520	1923120	as this is gonna be important.
1923120	1925640	Let's get the people who are thinking about this
1925640	1928080	in creative and insightful ways
1928080	1930320	and put them in one place and stir.
1930320	1931880	Yeah, but even beyond that, right?
1931880	1935560	It was Bell Labs at its heyday.
1935560	1937040	And even when we were there,
1937040	1937880	which I think was past its heyday.
1937880	1939720	And to be clear, he's gotten to be at Bell Labs.
1939720	1941080	I never got to be at Bell Labs.
1941080	1942320	I joined after that.
1942320	1944640	Yeah, I should have been 91 as a grad student.
1944640	1948000	So I was there for a long time, every summer,
1948000	1948840	except for two.
1948840	1949680	So twice I worked for companies
1949680	1951880	that had just stopped being Bell Labs.
1951880	1953640	Bell Corps and then AT&T Labs.
1953640	1956000	So Bell Labs was several locations
1956000	1957800	or for the researchers, or is it one?
1957800	1958800	Like, is that- Definitely sevens.
1958800	1961080	Like, Jersey's involved somehow.
1961080	1961920	They're all in Jersey.
1961920	1962760	Yeah, they're all over the place.
1962760	1964120	But they were in a couple places in Jersey.
1964120	1967480	Murray Hill was the Bell Labs place.
1967480	1969840	So you had an office at Murray Hill
1969840	1971120	at one point in your career?
1971120	1973400	Yeah, I played Ultimate Frisbee
1973400	1976360	on the cricket pitch at Bell Labs at Murray Hill.
1976360	1978360	And then it became AT&T Labs when it split off
1978360	1980960	with Luce during what we called Trivestiture,
1981040	1983680	the better than Michael Korn's at Ultimate Frisbee.
1983680	1984600	Yeah. Oh, yeah.
1984600	1985440	Okay.
1985440	1986640	But I think that one's not boasting.
1986640	1988600	I think that, I think Charles plays a lot of Ultimate.
1988600	1989600	And I don't think Mike-
1989600	1992120	No, I was, yes, but that wasn't the point.
1992120	1992960	The point is yes.
1992960	1994640	I'm sorry. Oh, yes, yes, sorry, sorry.
1994640	1997440	Okay, I have played on a championship-winning
1997440	1999440	Ultimate Frisbee team, or whatever,
1999440	2000800	Ultimate team with Charles.
2000800	2002680	So I know how good he is.
2002680	2003520	He's really good.
2003520	2004640	How good I was anyway when I was younger.
2004640	2005480	But the thing is-
2005480	2006920	I know how young he was when he was younger.
2006920	2007760	That's true.
2007760	2008880	So much younger than now.
2008880	2009840	He's older now.
2010520	2011520	Michael was a much,
2011520	2013160	was a much better basketball player than I was.
2013160	2014400	Michael Korn's.
2014400	2016240	Yes, no, not Michael Korn.
2016240	2017080	Let's be very clear about that.
2017080	2018800	To be clear, I've not played basketball with you.
2018800	2020480	So you don't know how terrible I am,
2020480	2022360	but you have a probably pretty good guess.
2022360	2024320	That you're not as good as Michael Korn.
2024320	2025800	He's tall and athletic.
2025800	2026640	And he cared about it.
2026640	2027960	He's very athletic, very good.
2027960	2028800	And probably competitive.
2028800	2030280	I love hanging out with Michael.
2030280	2031680	Anyway, but we were talking about something else,
2031680	2032960	although I no longer remember what it was.
2032960	2033800	What were we talking about?
2033800	2035160	Honey, that's all Bell Labs.
2035160	2036000	But also Labs.
2036000	2039720	So this was kind of cool about what was magical about it.
2040240	2041360	The first thing you have to know
2041360	2043520	is that Bell Labs was an arm of the government, right?
2043520	2045360	Because AT&T was an arm of the government.
2045360	2046520	It was a monopoly.
2047440	2049840	And you know, every month you paid a little thing
2049840	2052040	on your phone bill, which turned out was a tax
2052040	2054360	for like all the research that Bell Labs was doing.
2054360	2056720	And you know, they invented transistors and the laser
2056720	2057560	and whatever else is that they did.
2057560	2060600	The big bang or whatever the cosmic background radiation.
2060600	2061440	Yeah, they did all that stuff.
2061440	2063440	They had some amazing stuff with directional microphones.
2063440	2065560	By the way, I got to go in this room
2065560	2068000	where they had all these panels and everything
2068000	2069000	and we would talk.
2069040	2070880	And one another and he'd lose some panels around
2070880	2073640	and then he'd have me step two steps to the left
2073640	2075160	and I couldn't hear a thing he was saying
2075160	2077160	because nothing was bouncing off the walls.
2077160	2078520	And then he would shut it all down
2078520	2080320	and you could hear your heartbeat.
2080320	2083400	Which is deeply disturbing to hear your heartbeat.
2083400	2084240	You can feel it.
2084240	2085080	I mean, you can feel it now.
2085080	2086680	So there's so much all this sort of noise around.
2086680	2088360	Anyway, Bell Labs is about pure research.
2088360	2090480	It was a university in some sense,
2090480	2093740	the purest sense of a university, but without students.
2093740	2096480	So it was all the faculty working with one another
2096480	2097920	and students would come in to learn.
2097920	2099320	They would come in for three or four months
2099320	2100960	during the summer and they would go away.
2100960	2102920	But it was just this kind of wonderful experience
2102920	2104800	I could walk out my door.
2104800	2106640	In fact, I would often have to walk out my door
2106640	2108760	and deal with Rich Sutton and Michael Kearns yelling
2108760	2111520	at each other about whatever it is they were yelling
2111520	2114720	about the proper way to prove something or another.
2114720	2116720	And I could just do that and Dave McAllister
2116720	2119840	and Peter Stone and all of these other people
2119840	2122720	including Satinder and then eventually Michael.
2122720	2125320	And it was just a place where you could think thoughts
2125320	2128680	and it was okay because so long as once every 25 years
2128680	2130800	or so somebody invented a transistor,
2130800	2131840	it paid for everything else.
2131840	2134160	You could afford to take the risk.
2134160	2136480	And then when that all went away,
2136480	2139400	it became harder and harder and harder to justify it
2139400	2141560	as far as the folks who were very far away were concerned.
2141560	2143600	And there was such a fast turnaround
2143600	2146440	among middle management on the AT&T side
2146440	2148400	that you never had a chance to really build a relationship.
2148400	2149880	At least people like us didn't have a chance
2149880	2151520	to build a relationship.
2151520	2155040	So when the diaspora happened, it was amazing, right?
2155560	2157720	Everybody left and I think everybody ended up
2157720	2159760	at a great place and made a huge,
2159760	2162760	made a continue to do really good work with machine learning.
2162760	2165040	But it was a wonderful place and people will ask me,
2165040	2167080	what's the best job you've ever had?
2167080	2171160	And as a professor, anyway, the answer that I would give is,
2171160	2176160	well, probably Bell Labs in some very real sense
2176160	2177680	and I would never have a job like that again
2177680	2179400	because Bell Labs doesn't exist anymore.
2179400	2182320	And Microsoft research is great and Google does good stuff
2182320	2184200	and you can pick IBM, you can tell everyone to,
2184200	2185880	but Bell Labs was magical.
2185880	2188040	It was around for, it was an important time
2188040	2192120	and it represents a high watermark in basic research
2192120	2192960	in the US.
2192960	2193800	Is there something you could say
2193800	2196680	about the physical proximity and the chance collisions?
2196680	2199400	Like we live in this time of the pandemic
2199400	2203800	where everyone is maybe trying to see the silver lining
2203800	2206960	and accepting the remote nature of things.
2206960	2210400	Is there one of the things that people like faculty
2211160	2215640	that I talk to miss is the procrastination.
2217040	2220000	Like the chance to make everything is about meetings
2220000	2221000	that are supposed to be,
2221000	2224120	there's not a chance to just talk about comic book
2224120	2227240	or whatever, like go into discussion that's totally pointless.
2227240	2228240	So it's funny you say this
2228240	2231160	because that's how we met, met is exactly that.
2231160	2232000	So I'll let Michael say that,
2232000	2232840	but I'll just add one thing,
2232840	2236520	which is just that research is a social process
2236520	2240200	and it helps to have random social interactions
2240200	2241600	even if they don't feel social at the time.
2241600	2242440	That's how you get things done.
2242440	2245200	Have one of the great things about the ad lab
2245200	2246040	when I was there,
2246040	2247920	I don't quite know what it looks like now
2247920	2248840	once they move buildings,
2248840	2250880	but we had entire walls that were whiteboards
2250880	2251880	and people would just get up there
2251880	2252720	and they were just right
2252720	2254480	and people would walk up and you'd have arguments
2254480	2256160	and you'd explain things to one another
2256160	2259640	and you got so much out of the freedom to do that.
2259640	2263000	You had to be okay with people challenging
2263000	2264480	every freaking word you said,
2264480	2267240	which I would sometimes find deeply irritating,
2267240	2269640	but most of the time it was quite useful,
2269640	2272040	but the sort of pointlessness and the interaction
2272040	2274820	was in some sense the point, at least for me.
2274820	2277120	Yeah, I mean, I think offline yesterday
2277120	2279680	I mentioned Josh Titanbaum and he's very much,
2279680	2284680	he's such an inspiration in the child-like way
2286240	2287920	that he pulls you in on any topic.
2287920	2290440	He doesn't even have to be about machine learning
2290440	2291680	or the brain.
2291680	2295920	He'll just pull you into a closest writable surface,
2295920	2298320	which is still, you can find whiteboards
2298320	2299760	at MIT everywhere.
2299760	2303960	And just like basically cancel all meetings
2303960	2306960	and talk for a couple hours about some aimless thing
2306960	2308840	and it feels like the whole world,
2308840	2310840	the time, space continuum kind of warps
2310840	2312760	and that becomes the most important thing.
2312760	2317080	And then it's just, it's definitely something worth
2317080	2320160	missing in this world where everything's remote.
2320160	2323000	There's some magic to the physical presence.
2323000	2325400	Whenever I wonder myself whether MIT really is as great
2325400	2328280	as I remember it, I just go talk to Josh.
2328280	2330680	Yeah, you know, that's funny is there's a few people
2330680	2334360	in this world that carry the best
2334360	2336440	of what particular institutions stand for, right?
2336440	2337280	And it's-
2337280	2338120	It's Josh.
2338120	2341000	I mean, I don't, my guess is he's unaware of this.
2341000	2341840	That's the point.
2342840	2345760	The masters are not aware of their mastery.
2346720	2347480	So-
2347480	2348320	How did you meet?
2349880	2352400	Yes, but first the tangent, no.
2353720	2354760	How did you meet me?
2354760	2356160	So I'm not sure what you were thinking,
2356160	2359720	but when it started to dawn on me that maybe
2359720	2364040	we had a longer term bond was after we all got laid off
2364040	2368480	and you had decided at that point that we were still paid.
2368480	2371000	We were given an opportunity to like do job search
2371000	2373040	and kind of make a transition,
2373040	2375280	but it was clear that we were done.
2375280	2378440	And I would go to my office to work
2378440	2381360	and you would go to my office to keep me from working.
2381360	2383520	That was my recollection of it.
2383520	2385240	You had decided that there was really no point
2385240	2386600	in working for the company
2386600	2389800	because our relationship with the company was done.
2389800	2391320	Yeah, but remember I felt that way beforehand.
2391320	2392280	It wasn't about the company,
2392280	2394320	it was about the set of people there doing really cool things
2394320	2395880	and it always always been that way.
2395880	2397560	But we were working on something together.
2397560	2398400	Oh yeah, yeah, yeah, yeah.
2398400	2399240	That's right.
2399240	2400360	So at the very end, we all got laid off,
2400360	2404200	but then our boss came to, our boss's boss came to us
2404200	2405640	because our boss was Michael Kearns
2405640	2409040	and he had jumped ship brilliantly, like perfect timing,
2409040	2412120	like things like right before the ship was about to sink.
2412120	2414240	He was like, gotta go.
2414240	2418200	And landed perfectly because Michael Kearns.
2418200	2419040	Because Michael Kearns.
2419040	2423600	And leaving the rest of us to go like, this is fine.
2423600	2425800	And then it was clear that it wasn't fine
2425800	2427440	and we were all toast.
2427440	2429200	So we had this sort of long period of time.
2429200	2430880	But then our boss figured out, okay, wait,
2430880	2433680	maybe we can save a couple of these people
2433680	2436440	if we can have them do something really useful.
2437280	2440680	And the useful thing was we were gonna make
2440680	2442280	basically an automated assistant
2442280	2443920	that could help you with your calendar.
2443920	2445720	You could like tell it things
2445720	2447880	and it would respond appropriately.
2447880	2449720	It would just kind of integrate across
2449720	2453600	all sorts of your personal information.
2453600	2456760	And so me and Charles and Peter Stone
2456760	2460880	were set up as the crack team to actually solve this problem.
2460880	2463440	Other people maybe were too theoretical that they thought
2463440	2465680	and but we could actually get something done.
2465680	2467280	So we sat down to get something done
2467280	2470080	and there wasn't time and it wouldn't have saved us anyway.
2470080	2472080	And so it all kind of went downhill.
2472080	2475440	But the interesting, I think, coda to that
2475440	2478920	is that our boss's boss is a guy named Ron Brockman.
2478920	2483920	And when he left AT&T, because we were all laid off,
2483920	2487280	he went to DARPA, started up a program there
2487280	2490200	that became KLO, which is the program
2490200	2494120	from which Siri sprung, which is a digital assistant
2494120	2495320	that helps you with your calendar
2495320	2496720	and a bunch of other things.
2497720	2500920	It really, in some ways got its start
2500920	2503920	with me and Charles and Peter trying to implement
2503920	2505600	this vision that Ron Brockman had
2505600	2507760	that he ultimately got implemented
2507760	2509400	through his role at DARPA.
2509400	2511440	So when I'm trying to feel less bad
2511440	2513720	about having been laid off from what is possibly
2513720	2516680	the greatest job of all time, I think about,
2516680	2520120	well, we kind of help birth Siri.
2520120	2520960	That's something.
2521880	2523160	And he did other things too.
2523160	2526680	But we got to spend a lot of time in his office
2526680	2527840	and talk about-
2527840	2530400	We got to spend a lot of time in my office, yeah.
2531080	2533520	And so then we went on our merry way.
2533520	2535360	Everyone went to different places.
2535360	2536560	Charles landed at Georgia Tech,
2536560	2540320	which was what he always dreamed he would do.
2540320	2542720	And so that worked out well.
2543760	2545400	I came up with a saying at the time,
2545400	2548000	which is luck favors the Charles.
2548000	2550560	It's kind of like luck favors the prepared.
2550560	2552960	But Charles, he wished something
2552960	2555480	and then it would basically happen just the way he wanted.
2555480	2558520	It was inspirational to see things go that way.
2558520	2559360	Things worked out.
2559360	2560200	And we stayed in touch
2560200	2563760	and then I think it really helped
2563760	2566120	when you were working on,
2566120	2568280	I mean, you'd kept me in the loop for things like threads
2568280	2569800	and the work that you were doing at Georgia Tech.
2569800	2571000	But then when they were starting
2571000	2572880	their online master's program,
2572880	2574000	he knew that I was really excited
2574000	2576120	about MOOCs and online teaching.
2576120	2577960	And he's like, I have a plan.
2577960	2578920	And I'm like, tell me your plan.
2578920	2580680	He's like, I can't tell you the plan yet.
2580680	2583000	Cause they were deep in negotiations
2583000	2585560	between Georgia Tech and Udacity to make this happen.
2585560	2587360	And they didn't want it to leak.
2587360	2589280	So Charles would kept teasing me about it,
2589280	2590760	but wouldn't tell me what was actually going on.
2590760	2593040	And eventually it was announced and he said,
2593040	2595080	I would like you to teach the machine learning course
2595080	2595920	with me.
2595920	2598360	I'm like, that can't possibly work.
2598360	2600960	But it was a great idea and it was, it was super fun.
2600960	2602160	It was a lot of work to put together,
2602160	2604040	but it was, it was really great and...
2604040	2606040	Was that the first time you thought about,
2606040	2607720	first of all, was it the first time
2607720	2610160	you got seriously into teaching?
2610160	2612960	I mean, you know, I'm trying to get the professor right.
2612960	2615520	This was already after you jumped to,
2615520	2618760	so like there's a little bit of jumping around in time.
2618760	2619600	Yeah, sorry about that.
2619600	2620560	There's a pretty big jump in time.
2620560	2622600	So like the MOOCs thing is...
2622600	2624280	So Charles got to Georgia Tech and he,
2624280	2626120	I mean, maybe Charles, maybe this is a Charles story.
2626120	2627080	I got to Georgia Tech in 2002.
2627080	2629280	He got to Georgia Tech in 2002.
2629280	2632840	And worked on things like revamping the curriculum,
2632840	2633800	the undergraduate curriculum,
2633800	2637840	so that it had some kind of semblance of modular structure
2637840	2640640	because computer science was at the time moving
2640640	2643680	from a fairly narrow specific set of topics
2643680	2648360	to touching a lot of other parts of intellectual life
2648360	2650840	and the curriculum was supposed to reflect that.
2650840	2655520	And so Charles played a big role in kind of redesigning that.
2655520	2656360	And then the...
2656360	2660720	And for my, my labors, I ended up as associate dean.
2660720	2662440	Right, he got to become associate dean
2662440	2664840	of a charge of educational stuff.
2664840	2666720	Well, that would be a valuable lesson
2666720	2668960	if you're good at something,
2670320	2673760	they will give you responsibility to do more of that thing.
2673760	2675640	Well, don't show competence.
2675640	2677280	Don't show competence if you...
2677280	2680720	Well, you know what they say, here's what they say.
2680720	2683360	The reward for good work is more work.
2683360	2685360	The reward for bad work is less work,
2687080	2689000	which I don't know, depending on what you're trying
2689000	2691320	to do that week, one of those is better than the other.
2691320	2692840	Well, one of the problems with the word work
2692840	2697640	sorry to interrupt is that it seems to be an antonym
2697640	2699280	in this particular language
2699280	2701840	we have the opposite of happiness.
2701840	2703640	But it seems like they're,
2704640	2707440	that's one of, you know, we talked about balance.
2707440	2709680	It's always like work-life balance.
2709680	2712920	So it was rubbing me the wrong way as a terminology.
2712920	2713920	I know it's just words.
2713920	2715480	Right, the opposite of work is play,
2715480	2717920	but ideally work is play.
2717920	2720360	Oh, I can't tell you how much time I'd spend.
2720360	2721800	Certainly not as a Bell Labs,
2721800	2723760	except for a few very key moments.
2723760	2725160	As a professor, I would do this too.
2725160	2726520	I was just saying, I cannot believe they're
2726520	2727440	paying me to do this.
2727440	2729400	Because it's fun.
2729400	2732120	It's something that I would do for a hobby
2732200	2734960	if I could anyway.
2734960	2735800	So that sort of worked out.
2735800	2736840	Are you sure you want to be saying that
2736840	2738920	when this is being recorded?
2738920	2740320	As a dean, that is not true at all.
2740320	2741880	I need a raise.
2741880	2745440	But I think here with this, even though a lot of time passed
2745440	2747600	Michael and I talked almost every, well, we texted
2747600	2749920	almost every day during the period.
2749920	2754200	Charles at one point took me, there was the ICML conference
2754200	2757360	the machine learning conference was in Atlanta.
2757360	2760440	I was the chair, the general chair of the conference.
2760440	2763440	Charles was my publicity chair or something like that
2763440	2765280	or fundraising chair.
2765280	2766120	Fundraising chair.
2766120	2766960	Yeah.
2766960	2768040	But he decided it'd be really funny
2768040	2769720	if he didn't actually show up for the conference
2769720	2771680	in his own home city.
2771680	2772520	So he didn't.
2772520	2774600	But he did at one point pick me up at the conference
2774600	2779200	in his Tesla and drove me to the Atlanta mall
2779200	2782120	and forced me to buy an iPhone
2782120	2785720	because he didn't like how it was to text with me
2785720	2788400	and thought it would be better for him if I had an iPhone,
2788400	2790400	the text would be somehow smoother.
2790400	2791240	And it was.
2791240	2792080	And it was.
2792080	2792920	And it is, and his life is better.
2792920	2793760	And my life is better.
2793760	2794600	And so, yeah.
2794600	2798240	But it was, yeah, Charles forced me to get an iPhone
2798240	2800360	so that he could text me more efficiently.
2800360	2802000	I thought that was an interesting moment.
2802000	2802840	It works for me.
2802840	2804120	Anyway, so we kept talking the whole time
2804120	2806440	and then eventually we did the teaching thing.
2806440	2807280	And it was great.
2807280	2808840	And there's a couple of reasons for that, by the way.
2808840	2811480	One is I really wanted to do something different.
2811480	2813240	Like you've got this medium here.
2813240	2814520	People claim it can change things.
2814520	2816960	What's a thing that you could do in this medium
2816960	2820360	that you could not do otherwise besides edit?
2820360	2821240	Right, I mean, what could you do?
2821240	2823240	And being able to do something
2823240	2824560	with another person was that kind of thing.
2824560	2825400	It's very hard.
2825400	2827440	I mean, you can take turns, but teaching together,
2827440	2829040	having conversations is very hard, right?
2829040	2830280	So that was a cool thing.
2830280	2831400	The second thing, if you'd be excused
2831400	2832480	to do more stuff with him.
2832480	2835720	Yeah, I always thought, he makes it sound brilliant.
2835720	2837240	And it is, I guess.
2837240	2839320	But at the time, it really felt like
2840160	2842760	I've got a lot to do, Charles is saying.
2842760	2845800	And it would be great if Michael could teach the course
2845800	2847280	and I could just.
2847280	2848120	Hang out.
2848120	2849520	Yeah, just kind of coast on that.
2849520	2851600	Well, that's what the second class was more like that.
2851600	2853440	Because the second class was explicit.
2853440	2855440	The first class, it was at least half.
2856320	2857160	Yeah, but I knew all the stuff.
2857160	2858000	So the structure that we came up with.
2858000	2860000	I think you were once again letting the facts
2860000	2860840	get in the way.
2860840	2861680	It's a good story.
2861680	2862960	A good story.
2862960	2864760	I should just let Charles talk to us.
2864760	2865880	But that's the facts that he saw,
2865880	2868600	but so that was kind of true for 72.
2868600	2870240	Yeah, that was sort of true for 7642,
2870240	2871400	which is the reinforcement learning class
2871400	2872600	because that was really his class.
2872600	2873880	You started with reinforcement learning?
2873880	2876040	No, we started with, I did the intro machine learning,
2876040	2879280	7641, which is supervised learning
2880280	2882040	and reinforcement learning and decision making
2882040	2883040	and cram all that in there.
2883040	2884960	Kind of assignments that we talked about earlier.
2884960	2886520	And then eventually about a year later,
2886520	2888560	we did a follow on 7642,
2888560	2890840	which is reinforcement learning and decision making.
2890840	2892360	The first class was based on something
2892360	2894520	I'd been teaching at that point for well over a decade.
2894520	2895920	And the second class was based on something
2895920	2897480	Michael had been teaching.
2897480	2898840	Actually, I learned quite a bit
2898840	2900480	teaching that class with him.
2900480	2901600	But he drove most of that.
2901600	2903840	But the first one I drove most of it was all my material.
2903840	2905560	Although I had stolen that material
2905560	2908000	originally from slides I found online
2908040	2910600	from Michael, who had originally stolen that material
2910600	2912200	from I guess slides he found online,
2912200	2913280	probably from Andrew Moore,
2913280	2914680	because the jokes were the same anyway.
2914680	2916680	At least some of the, at least when I found the slide,
2916680	2917840	some of the stuff was there.
2917840	2919520	Yes, every machine learning class
2919520	2921960	taught an early 2000s stole from Andrew Moore.
2921960	2924040	A particular joke or two.
2924040	2924960	At least the structure.
2924960	2927240	Now I did, and he did actually a lot more
2927240	2929000	with reinforcement learning and such
2929000	2930400	and game theory and those kinds of things.
2930400	2931440	But you know, we all sort of-
2931440	2932920	You mean in the research world?
2932920	2933760	No, no, no, in that class.
2933760	2934880	No, I mean in teaching that class.
2934880	2937600	The coverage was different than what other people started.
2937600	2939040	Most people were just doing supervised learning
2939040	2941800	and maybe a little bit of clustering and whatnot.
2941800	2942920	But we took it all the way to-
2942920	2944880	A lot of it just comes from Tom Mitchell's book.
2944880	2946600	Oh no, yeah, except, well, half of it
2946600	2948040	comes from Tom Mitchell's book, right?
2948040	2950120	But the other half doesn't.
2950120	2952560	This is why it's all readings, right?
2952560	2954000	Because certain things weren't invented when Tom Mitchell's-
2954000	2954840	Yeah, okay, that's true.
2954840	2955880	Right?
2955880	2957760	But it was quite good.
2957760	2960000	But there's a reason for that besides, you know,
2960000	2961120	just I wanted to do it.
2961120	2961960	I wanted to do something new
2961960	2963460	and I wanted to do something with him,
2963460	2964680	which is a realization,
2964680	2967480	which is despite what you might believe,
2967480	2969520	he's an introvert and I'm an introvert
2969520	2972200	or I'm on the edge of being an introvert anyway.
2972200	2977000	But both of us, I think, enjoy the energy of the crowd,
2977000	2977840	right?
2977840	2979760	There's something about talking to people
2979760	2982000	and bringing them into whatever we find interesting
2982000	2985520	that is empowering, energizing or whatever.
2985520	2990520	And I found the idea of staring alone at a computer screen
2990600	2992720	and then talking off of materials
2992720	2995280	less inspiring than I wanted it to be.
2995360	2999240	And I had in fact done a MOOC for Udacity on algorithms
2999240	3003160	and it was a week in a dark room,
3003160	3007080	talking at the screen, writing on the little pad.
3007080	3009360	And I didn't know this was happening,
3009360	3012480	but they had watched the crew had watched some of the videos
3012480	3013760	while, you know, like in the middle of this
3013760	3015800	and they're like, something's wrong.
3015800	3019560	You're sort of shutting down.
3019560	3022480	And I think a lot of it was I'll make jokes
3022480	3024280	and no one would laugh.
3024280	3026560	And I felt like the crowd hated me.
3026560	3027880	Now, of course, there was no crowd.
3027880	3030840	So like it wasn't rational, but it's little.
3030840	3032960	Each time I tried it and I got no reaction,
3032960	3037320	it just was taking the energy out of my performance,
3037320	3038640	out of my presentation.
3038640	3040440	Such a fantastic metaphor for grad school.
3040440	3042680	Anyway, by working together,
3042680	3044680	we could play off each other and have it.
3044680	3048040	Keep the energy up because you can't let your guard down
3048040	3051120	for a moment with Charles, he'll just overpower you.
3051120	3052240	I have no idea what you're talking about.
3052240	3053720	But we would work really well together.
3053720	3054880	I thought and we knew each other.
3054880	3056640	So I knew that we could sort of make it work.
3056640	3057760	Plus I was the associate dean.
3057760	3060080	So they had to do what I told them to do.
3060080	3060920	We had to do that.
3060920	3061760	We had to make it work.
3061760	3062720	And so it worked out very well.
3062720	3064960	I thought well enough that we
3064960	3066560	with great power comes great power.
3066560	3067400	That's right.
3067400	3069360	And we became smooth and curly.
3069360	3074360	And that's when we did the overfitting thriller video.
3075720	3076560	Yeah.
3076560	3077400	Yeah.
3077400	3078240	That's it.
3078240	3080920	Can we just like smooth and curly?
3080920	3081760	What were that?
3081760	3083480	So it happened.
3083480	3084720	It was completely spontaneous.
3084720	3085880	These are nicknames you go by.
3085880	3086720	Yeah.
3086720	3088640	So it's what the students call us.
3088640	3090320	He was lecturing.
3090320	3092040	So the way that we structured the lectures
3092040	3093440	is one of us is the lecturer
3093440	3095400	and one of us is basically the student.
3095400	3097480	And so he was lecturing on.
3097480	3099080	The lecturer prepares all the materials,
3099080	3100480	comes up with the quizzes,
3100480	3103160	and then the student comes in not knowing anything.
3103160	3105480	So it was just like being on campus.
3105480	3108120	And I was doing game theory in particular,
3108120	3108960	the prisoner's dilemma.
3108960	3109800	Prisoner's dilemma.
3109800	3112240	We needed to set up a little prisoner's dilemma grid.
3112240	3114400	So he drew it and I could see what he was drawing.
3114400	3117560	And the prisoner's dilemma consists of two players,
3117560	3118400	two parties.
3118400	3120160	So he decided he would make little cartoons
3120160	3121280	of the two of us.
3121280	3124880	And so there was two criminals, right?
3124880	3127980	That were deciding whether or not to rat each other out.
3127980	3131160	One of them, he drew as a circle with a smiley face
3131160	3134160	and a kind of goatee thing, smooth head.
3134160	3136440	And the other one with all sorts of curly hair.
3136440	3138480	And he said, this is smooth and curly.
3138480	3139760	I said smooth and curly.
3139760	3141640	He said, no, no, smooth with a V.
3141640	3143640	It's very important that it have a V.
3143640	3147280	And then the students really took to that.
3147280	3149240	Like they found that relatable.
3149240	3151280	He started singing in smooth criminal by Michael Jackson.
3151280	3152120	Yeah, yeah, yeah.
3152120	3153640	And those names stuck.
3153640	3157120	So we now have a video series that an episode,
3157120	3160000	our kind of first actual episode should be coming out today,
3161080	3163320	smooth and curly on video,
3163320	3167400	where the two of us discuss episodes of Westworld.
3167400	3168960	We watch Westworld and we're like,
3168960	3171920	huh, what does this say about computer science and AI?
3171920	3173960	And we've never, we did not watch it.
3173960	3175800	I mean, I know it's on season three or whatever we have.
3175800	3177760	As of this recording, it's on season three.
3177760	3180000	And watch now two episodes total.
3180000	3181280	Yeah, I think I watched three.
3181280	3182720	What do you think about Westworld?
3182720	3183560	Two episodes in.
3183560	3186000	So I can tell you so far,
3186000	3188200	I'm just guessing what's gonna happen next.
3188200	3190200	It seems like bad things are gonna happen
3190200	3191320	with the robots uprising.
3191320	3192160	It's a lot of.
3192160	3194640	So I have not, I mean, you know,
3194640	3196240	I vaguely remember a movie existing.
3196240	3198640	So I assume it's related to that, but.
3198640	3200280	That was more my time than your time, Charles.
3200280	3201600	That's right, cause you're much older than I am.
3201600	3204960	I think the important thing here is that it's narrative,
3204960	3205800	right?
3205800	3206620	It's all about telling a story.
3206620	3207460	That's the whole driving thing.
3207460	3209760	But the idea that they would give these reveries,
3209760	3211440	that they would make people,
3211440	3214560	they would make them remember the awful things that happened.
3214560	3215400	How horrible things that happened.
3215400	3217880	Who could possibly think that was a good, I gotta,
3217880	3218720	I mean, I don't know.
3218720	3219680	I've only seen the first two episodes
3219680	3220520	or maybe the third one.
3220520	3221360	I think I've only seen the first one.
3221360	3222200	You know what it was?
3222200	3223040	Do you know what the problem is?
3223040	3223880	What?
3223880	3225560	That the robots were actually designed by Hannibal Lecter.
3225560	3226400	That's true.
3226400	3227400	They weren't.
3227440	3229800	So like, what do you think's gonna happen?
3229800	3230640	Bad thing.
3230640	3231880	It's clear that things are happening
3231880	3233000	and characters being introduced
3233000	3234280	and we don't yet know anything.
3234280	3237840	But still, I was just struck by how it's all driven
3237840	3238680	by narrative and story.
3238680	3241300	And there's all these implied things like programming hap,
3241300	3243920	the programming interface is talking to them
3243920	3245680	about what's going on in their heads,
3245680	3248600	which is both, I mean, artistically,
3248600	3250160	it's probably useful to film it that way.
3250160	3251600	But think about how it would work in real life.
3251600	3252520	That just seems very great.
3252520	3254320	But there was, we saw on the second episode,
3254320	3255720	there's a screen you could see things.
3255720	3256560	They were wearing like clothes.
3257320	3260400	It was quite interesting to just kind of ask this question
3260400	3261240	so far.
3261240	3262960	I mean, I assume it veers off into Never Never Land
3262960	3263800	at some point.
3263800	3265920	So we don't know, we can't answer that question.
3265920	3268720	I'm also a fan of a guy named Alex Garland.
3268720	3270440	He's a director of Ex Machina.
3271320	3274020	And he is the first,
3274020	3276160	I wonder if Kubrick was like this actually,
3276160	3280160	is he like studies what would it take
3280160	3281760	to program in AI systems?
3281760	3284760	Like he's curious enough to go into that direction.
3284800	3286480	On the Westworld side,
3286480	3289360	I felt there was more emphasis on the narratives
3289360	3292520	than like actually asking like computer science questions.
3292520	3294680	Like, how would you build this?
3294680	3297840	How would you, and how would you debug it?
3297840	3301000	I still, to me, that's the key issue.
3301000	3302320	They were terrible debuggers.
3302320	3303160	Yeah.
3303160	3305040	Well, they said specifically, so we make a change
3305040	3306440	and we put it out in the world and that's bad
3306440	3307840	because something terrible could happen.
3307840	3309600	Like, if you're putting things out of the world
3309600	3311160	and you're not sure whether something terrible
3311160	3313320	is going to happen, your process is probably.
3313320	3314800	I just feel like there should have been someone
3314800	3316720	who's sole job it was was to walk around
3316720	3317920	and poke his head at it and say,
3317920	3319200	what could possibly go wrong?
3319200	3320680	Just over and over again.
3320680	3322280	I would have loved if there was an,
3322280	3324840	and I did watch a lot more and I'm not giving anything away.
3324840	3327120	I would have loved it if there was like an episode
3327120	3330000	where like the new intern is like debugging
3330000	3332760	a new model or something and like it just keeps failing
3332760	3334160	and they're like, all right.
3334160	3337600	And then more turns into like a episode of Silicon Valley
3337600	3341980	or something like that versus like this ominous AI systems
3341980	3345660	that are constantly like threatening the fabric
3345660	3347380	of this world that's been created.
3347380	3348220	Yeah.
3348220	3351180	And you know, this reminds me of something that,
3351180	3352020	so I agree with that.
3352020	3352860	That should be very cool.
3352860	3354780	At least well, for the small percentage of people
3354780	3356740	who care about debugging systems.
3356740	3357740	But the other thing is.
3357740	3359660	Debugging the series.
3359660	3362180	It falls into the thing of the sequels, fear of the debugger.
3362180	3363020	Oh my gosh.
3363020	3364580	And anyway, so.
3364580	3365700	It's a nightmare show.
3365700	3367420	It's a horror movie.
3367420	3368900	I think that's where we lose people, by the way,
3368900	3370700	early on as the people who either decide
3370740	3372900	either figure out debugging or think debugging is terrible.
3372900	3374860	This is where we lose people in computer science.
3374860	3377060	This is part of the struggle versus suffering, right?
3377060	3379660	You get through it and you kind of get the skills of it
3379660	3380980	or you just like, this is dumb.
3380980	3382340	This is a dumb way to do anything.
3382340	3383540	I think that's when we lose people.
3383540	3386780	But, well, I'll leave it at that.
3386780	3391580	But I think that there's something really,
3391580	3394220	really neat about framing it that way.
3394220	3397620	But what I don't like about all of these things.
3397620	3399060	And I love Tex Mockingham, by the way.
3399060	3401300	Although the ending was very depressing.
3402980	3406380	One of the things I have to talk to Alex about,
3406380	3409980	he says that the thing that nobody noticed he put in
3409980	3413940	is at the end, spoiler alert,
3413940	3418940	the robot turns and looks at the camera and smiles,
3419140	3420180	very briefly.
3420180	3425180	And to him, he thought that his definition of passing
3425780	3428620	the general version of the Torrentiaster,
3428620	3432460	the consciousness test, is smiling for no one.
3437900	3440580	It's like the Chinese room kind of experiment.
3440580	3442820	It's not always trying to act for others,
3442820	3446340	but just on your own, being able to have a relationship
3446340	3449900	with the actual experience and just like take it in.
3449900	3450740	I don't know.
3450740	3452780	He said like nobody noticed the magic of it.
3452780	3455060	I have this vague feeling that I remember the smile,
3455060	3457140	but now you've just put the memory in my head.
3457140	3460180	So probably not, but I do think that that's interesting.
3460180	3461980	Although by looking at the camera,
3461980	3463660	you are smiling for the audience, right?
3463660	3465020	You're breaking the fourth wall.
3465020	3468260	It seems, I mean, well, that's a limitation in the medium,
3468260	3469700	but I like that idea.
3469700	3471580	But here's the problem I have with all of those movies,
3471580	3474780	all of them, is that, but I know why it's this way.
3474780	3476420	And I enjoy those movies.
3476420	3481420	And Westworld is, it sets up the problem of AI as succeeding
3483020	3485500	and then having something we cannot control.
3485500	3488500	But it's not the bad part of AI.
3488500	3490980	The bad part of AI is the stuff we're living through now,
3490980	3491820	right?
3491820	3493820	It's using the data to make decisions that are terrible.
3493820	3495900	It's not the intelligence that's gonna go out there
3495900	3498060	and surpass us and take over the world
3498060	3501720	or lock us into a room to starve to death slowly
3501720	3502780	over multiple days.
3502780	3506220	It's instead the tools that we're building
3506220	3510420	that are allowing us to make the terrible decisions
3510420	3513020	we would have less efficiently made before, right?
3513020	3515740	Computers are very good at making us more efficient,
3515740	3517940	including being more efficient at doing terrible things.
3517940	3520300	And that's the part of the AI we have to worry about.
3520300	3522980	It's not the, you know, true intelligence
3522980	3525300	that we're gonna build sometime in the future,
3525300	3527000	probably long after we're around.
3528140	3532180	But, you know, I just, I think that whole framing of it
3532180	3536060	sort of misses the point, even though it is inspiring.
3536060	3537820	And I was inspired by those ideas, right?
3537820	3539140	I got into this in part
3539140	3540860	because I wanted to build something like that.
3540860	3542180	Philosophical questions are interesting to me,
3542860	3544820	but, you know, that's not where the terror comes from.
3544820	3546220	The terror comes from the everyday.
3546220	3548020	And you can construct the situation.
3548020	3550420	It's in the subtlety of the interaction between AI
3550420	3554180	and the human, like with social networks,
3554180	3555220	all the stuff you're doing
3555220	3557860	with interactive artificial intelligence.
3557860	3560460	But, you know, I feel like how 9,000
3560460	3561820	came a little bit closer to that
3561820	3564460	when it's in 2001 Space Odyssey,
3564460	3568740	because it felt like a personal assistant.
3568740	3570660	You know, it felt like closer to the AI systems
3570660	3571500	you have today.
3571500	3575940	And the real things we might actually encounter,
3575940	3580940	which is over-relying in some fundamental way
3581540	3584940	on our, like, DOM assistance or on social networks,
3584940	3589940	like over-offloading too much of us onto, you know,
3590140	3595140	onto things that require internet and power and so on.
3595260	3599620	And thereby becoming powerless as a standalone entity.
3599740	3602340	And then when that thing starts to misbehave
3602340	3605660	in some subtle way, it creates a lot of problems.
3605660	3608500	And those problems are dramatized when you're in space,
3608500	3611380	because you don't have a way to walk away.
3611380	3612860	Well, as the man said,
3612860	3615340	once we started making the decisions for you,
3615340	3617260	it stopped being your world, right?
3617260	3620460	That's the matrix, Michael, in case you don't remember.
3620460	3622820	But on the other hand, I could say,
3622820	3625660	no, because isn't that what we do with people anyway?
3625660	3627180	You know, just kind of the shared intelligence
3627220	3630260	that is humanity is relying on other people constantly.
3630260	3633460	I mean, we hyper-specialize, right, as individuals.
3633460	3634700	We're still generally intelligent.
3634700	3636140	We make our own decisions in a lot of ways,
3636140	3637700	but we leave most of this up to other people.
3637700	3639940	And that's perfectly fine.
3639940	3643300	And by the way, everyone does necessarily share our goals.
3643300	3645180	Sometimes they seem to be quite against us.
3645180	3647020	Sometimes we make decisions
3647020	3649180	that others would see as against our own interests.
3649180	3651460	And yet we somehow manage it, manage and survive.
3651460	3655900	I'm not entirely sure why an AI would actually make that worse.
3657820	3659420	Or even different, really.
3660300	3662180	You mentioned the matrix.
3662180	3664420	Do you think we're living in a simulation?
3664420	3668100	It does feel like a thought game
3668100	3670780	more than a real scientific question.
3670780	3671620	Well, I'll tell you why,
3671620	3673540	like I think it's an interesting thought experiment.
3673540	3676180	See what you think from a computer science perspective.
3676180	3680180	It's a good experiment of how difficult would it be
3680180	3682900	to create a sufficiently realistic world
3682900	3685020	that us humans would enjoy being in.
3686020	3687700	That's almost like a competition.
3687700	3689140	If we're living in a simulation,
3689140	3691620	then I don't believe that we were put in the simulation.
3691620	3694220	I believe that it's just physics playing out
3694220	3696420	and we came out of that.
3696420	3699260	Like, I don't think.
3699260	3700940	So you think you have to build the universe
3700940	3701780	kind of all the time?
3701780	3702620	I think the universe itself,
3702620	3703820	we can think of that as a simulation.
3703820	3706820	And in fact, sometimes I try to think about
3706820	3709580	to understand what it's like for a computer
3709580	3712700	to start to think about the world.
3712700	3714380	I try to think about the world.
3715100	3716820	Things like quantum mechanics
3716820	3719580	where it doesn't feel very natural to me at all.
3720460	3722860	And it really strikes me as,
3722860	3725220	I don't understand this thing that we're living in.
3725220	3727660	It has, there's weird things happening in it
3727660	3729700	that don't feel natural to me at all.
3729700	3733100	Now, if you want to call that as the result of a simulator.
3733100	3734300	Okay, I'm fine with that.
3734300	3735140	But like I don't-
3735140	3736980	There's the bugs in the simulation.
3736980	3737820	There's the bugs.
3737820	3739580	I mean, the interesting thing about simulation
3739580	3741300	is that it might have bugs.
3741300	3743060	I mean, that's the thing that I-
3743060	3745180	But there would be bugs for the people in the simulation.
3745180	3747140	They're just, that's just reality.
3747140	3749340	Unless you were hard enough to know that there was a bug.
3749340	3750340	But I think-
3750340	3751460	Back to the matrix.
3751460	3752340	Yeah, the way you put the question-
3752340	3755340	I don't think that we live in a simulation created for us.
3755340	3756380	Okay, I would say that.
3756380	3757220	I think that's interesting.
3757220	3758140	I've actually never thought about it that way.
3758140	3760180	I mean, the way you asked the question though is,
3760180	3763060	could you create a world that is enough for us humans?
3763060	3765500	It's an interestingly sort of self-referential question
3765500	3769940	because the beings that created the simulation
3769940	3771500	probably have not created a simulation
3771500	3773380	that's realistic for them.
3773380	3776260	But we're in the simulation and so it's realistic for us.
3776260	3778300	So we could create a simulation
3778300	3782220	that is fine for the people in the simulation, as it were.
3782220	3783740	That would not necessarily be fine for us
3783740	3785220	as the creators of the simulation.
3785220	3787540	But, well, you can forget.
3787540	3788780	I mean, when you go into the,
3788780	3791380	if you play video games of virtual reality,
3791380	3795420	you can, if it was some suspension of disbelief or whatever.
3796420	3797500	It becomes a world.
3797500	3800140	It becomes a world even like in brief moments.
3800140	3802340	You forget that another world exists.
3802340	3804260	I mean, that's what good stories do.
3804260	3805300	They pull you in.
3805300	3808500	And the question is, is it possible to pull,
3808500	3809420	our brains are limited.
3809420	3811300	Is it possible to pull the brain in
3811300	3812740	to where we actually stay in that world
3812740	3814820	longer and longer and longer and longer?
3814820	3819020	And not only that, but we don't want to leave.
3819020	3821540	And so, especially, this is the key thing
3821540	3823900	about the developing brain,
3823900	3828180	is if we journey into that world early on in life, often.
3828180	3829780	How would you even know, yeah?
3830780	3833180	But from a video game design perspective,
3833180	3834980	from a Westworld perspective,
3834980	3837580	I think it's an important thing
3837580	3840860	for even computer scientists to think about,
3840860	3844580	because it's clear that video games are getting much better.
3844580	3848460	And virtual reality, although it's been ups and downs,
3848460	3849860	just like artificial intelligence,
3849860	3854820	it feels like virtual reality will be here
3854820	3856340	in a very impressive form
3856340	3859100	if we were to fast forward 100 years into the future
3859100	3862140	in a way that might change society fundamentally.
3862140	3864100	Like, if I were to, I'm very limited
3864100	3866580	in predicting the future, as all of us are.
3866580	3868660	But if I were to try to predict,
3870420	3872580	like, in which way I'd be surprised
3872580	3876060	to see the world 100 years from now,
3876060	3879540	it'd be that, or impressed,
3879540	3881940	it'd be that we're all no longer
3881940	3883380	living in this physical world,
3883380	3885020	that we're all living in a virtual world.
3885020	3889060	You really need to be calculating God by Sawyer.
3891140	3893100	It's a, he'll read it in a night.
3893100	3894300	It's a very easy read,
3894300	3896180	but it's a, I was assuming you were that kind of reader,
3896180	3899700	but it's a good story, and it's kind of about this,
3899700	3901420	but not in a way that it appears.
3901420	3905820	And I really enjoyed the thought experiment.
3907020	3908260	Yeah, I think it's pretty sure it's Robert Sawyer.
3908260	3910140	But anyway, he's apparently
3910140	3912380	Canadian's top science fiction writer,
3912420	3915100	which is why the story mostly takes place in Toronto.
3915100	3917060	But it's a very good,
3917060	3921260	it's a very good sort of story that sort of imagines this.
3921260	3924420	Very different kind of simulation hypothesis
3924420	3928340	sort of thing from, say, the egg, for example.
3928340	3930460	You know, I'm talking about the short story.
3932140	3933740	By the guy who did the Martian.
3934900	3936300	Who wrote the Martian?
3936300	3937140	You know, I'm talking about.
3937140	3938260	Matt Damon.
3938260	3939780	No, the book.
3939780	3941460	So we had this whole discussion
3941500	3945740	that Michael doesn't partake in this exercise of reading.
3945740	3946780	Yeah, he doesn't seem to like it,
3946780	3948180	which seems very strange to me,
3948180	3950100	considering how much he has to read.
3950100	3951020	I read all the time.
3951020	3953380	I used to read 10 books every week
3953380	3955340	when I was in sixth grade or whatever.
3955340	3957060	It was a lot of it's science fiction,
3957060	3959980	a lot of it, a lot of it's history, but I love to read.
3959980	3961780	But anyway, you should recalculate in God.
3961780	3965020	I think you'll, it's very easy read, like I said,
3965020	3968700	and I think you'll enjoy sort of the ideas that it presents.
3968700	3971540	Yeah, I think the thought experiment is quite interesting.
3972740	3975700	One thing I've noticed about people growing up now,
3975700	3977260	I mean, we'll talk about social media,
3977260	3980260	but video games is a much bigger, bigger and bigger
3980260	3981700	and bigger part of their lives.
3981700	3984220	And the video games have become much more realistic.
3984220	3989220	I think it's possible that the three of us are not,
3991140	3992860	and maybe the two of you are not familiar
3992860	3995620	exactly with the numbers we're talking about here.
3995620	3997180	I think the number of people.
3997180	3998500	It's bigger than movies, right?
3999260	4000100	It's huge.
4000100	4002940	I used to do a lot of the computational narrative stuff.
4002940	4005700	I understand that economists can actually see
4005700	4008700	the impact of video games on the labor market.
4008700	4013700	That there's fewer young men of a certain age
4014460	4019260	participating in like paying jobs than you'd expect.
4019260	4021300	And that they trace it back to video games.
4021300	4022900	I mean, the problem with Star Trek
4022900	4026340	was not warp drive or teleportation.
4026340	4027980	It was the holodeck.
4027980	4032060	Like if you have the holodeck, that's it.
4032060	4033620	That's it, you go in the holodeck, you never come out.
4033620	4036180	I mean, it just never made,
4036180	4037980	once I saw that I thought, okay, well,
4037980	4040060	so this is the end of humanity, right?
4040060	4041740	They've been in the holodeck.
4041740	4043180	Because that feels like the singularity,
4043180	4045060	not some AGI or whatever.
4045060	4048220	It's some possibly to go into another world
4048220	4051060	that can be artificially made better than this one.
4052380	4054180	And slowing it down so you live forever
4054180	4055740	or speeding it up so you appear to live forever
4056340	4058140	or making the decision of when to die.
4059060	4062340	And then most of us will just be old people on the porch
4062340	4065500	yelling at the kids these days in their virtual reality.
4065500	4067340	Worlds.
4067340	4069900	But they won't hear us because they've got headphones on.
4069900	4073700	So, I mean, rewinding back to MOOCs,
4073700	4077500	is there lessons that you've speaking to kids these days?
4077500	4078820	There you go.
4078820	4079660	That was a transition.
4079660	4080500	That was, right there.
4080500	4083260	I'll fix it in post.
4084260	4086420	That's Charles' favorite phrase.
4086420	4087260	Fix it in post.
4087260	4088100	Fix it in post.
4088100	4090620	He said, when we were recording all the time,
4090620	4092900	whenever the editor didn't like something or whatever,
4092900	4094420	I would say, we'll fix it in post.
4094420	4095900	He hated that.
4095900	4096860	He hated that more than anything.
4096860	4097980	Because it was Charles' way of saying,
4097980	4099300	I'm not gonna do it again.
4100460	4102300	You know, you're on your own for this one.
4102300	4104060	But it always got fixed in post.
4104060	4104900	Exactly.
4104900	4108340	So, is there something you've learned about,
4108340	4109820	I mean, it's interesting to talk about MOOCs,
4109820	4111420	is there something you've learned about the process
4111420	4115820	of education, about thinking about the present?
4115820	4118780	I think there's two lines of conversation to be had here,
4118780	4121580	is the future of education in general,
4121580	4122860	that you've learned about.
4122860	4126700	And more, pressurantly,
4126700	4130300	is the education at times of COVID.
4131260	4132540	The second thing, in some ways,
4132540	4134060	matters more than the first,
4134060	4135900	for at least in my head,
4135900	4137100	not just because it's happening now,
4137100	4140620	but because I think it's reminded us of a lot of things.
4140620	4142140	Coincidentally, today,
4142140	4144580	there's an article out by a good friend of mine,
4144580	4146140	who's also a professor at Georgia Tech,
4146140	4147940	but more importantly, a writer and editor
4147940	4150740	at the Atlantic, kind of Ian Bogos.
4150740	4153100	And the title is something like,
4153100	4156580	Americans will sacrifice anything for the college experience.
4157500	4160300	And it's about why we went back to college,
4160300	4162420	and why people wanted us to go back to college.
4162420	4164580	And it's not greedy presidents
4164580	4166300	trying to get the last dollar from someone.
4166300	4167980	It's because they want to go to college.
4167980	4169860	And what they're paying for is not the classes,
4169860	4172180	what they're paying for is the college experience.
4172180	4173580	It's not the education, it's being there.
4173580	4175580	I've believed this for a long time,
4175580	4177940	that we continually make this mistake
4177940	4180660	of people want to go back to college
4180660	4182340	as being people want to go back to class.
4182340	4183460	They don't, they want to go back to campus.
4183460	4184460	They want to move away from home.
4184460	4187260	They want to do all those things that people experience.
4187260	4188140	It's a rite of passage.
4188140	4193140	It's an identity, if I can steal some of Ian's words here.
4193740	4194780	And I think that's right.
4194780	4197900	And I think what we've learned through COVID is,
4198900	4200860	it has made it, the disaggregation
4200860	4202860	was not the disaggregation of the education
4202860	4205060	from the place, the university place,
4205060	4207020	and that you can get the best anywhere you want to.
4207020	4208060	In terms of there's lots of reasons
4208060	4210180	why that is not necessarily true.
4210180	4213180	The disaggregation is having it shoved in our faces
4213180	4214900	that the reason to go, again,
4214900	4216620	that the reason to go to college
4216620	4218220	is not necessarily to learn.
4218220	4220100	It's to have the college experience.
4220100	4221740	And that's very difficult for us to accept,
4221740	4223740	even though we behave that way,
4223740	4226540	most of us, when we were undergrads, you know.
4226620	4228780	A lot of us didn't go to every single class.
4228780	4230700	We learned and we got it and we look back on it
4230700	4232340	and we're happy we had the learning experience as well.
4232340	4233420	Obviously, particularly us,
4233420	4235420	because this is the kind of thing that we do.
4235420	4238380	And my guess is that's true of the vast majority
4238380	4239420	of your audience.
4239420	4241620	But that doesn't mean the,
4241620	4243380	I'm standing in front of you telling you this
4243380	4247420	is the thing that people are excited about.
4247420	4249060	And that's why they want to be there,
4249060	4250900	primarily why they want to be there.
4250900	4254420	So to me, that's what COVID has forced us to deal with,
4254460	4257100	even though I think we're still all in deep denial about it
4257100	4259980	and hoping that it'll go back to that.
4259980	4261580	And I think about 85% of it will.
4261580	4263460	We'll be able to pretend that that's really the way it is,
4263460	4265380	again, and we'll forget the lessons of this.
4265380	4267540	But technically what will come out of it,
4267540	4269100	or technologically what will come out of it,
4269100	4272740	is a way of providing a more dispersed experience
4272740	4275420	through online education and these kinds of remote things
4275420	4276260	that we've learned.
4276260	4279100	And we'll have to come up with new ways to engage them
4279100	4280580	in the experience of college,
4280580	4282100	which includes not just the parties
4282100	4283620	or the whatever kids do,
4283620	4286580	but the learning part of it so that they actually come out
4286580	4288140	four or five or six years later
4288140	4290900	with having actually learned something.
4290900	4294100	So I think the world will be radically different afterwards.
4294100	4296220	And I think technology will matter for that,
4296220	4298460	just not in the way that the people
4298460	4300700	who were building the technology originally
4300700	4302140	imagined it would be.
4302140	4305260	And I think this would have been true even without COVID,
4305260	4307820	but COVID has accelerated that reality.
4307820	4310180	So it's happening in two or three years or five years
4310180	4312180	as opposed to 10 or 15.
4312180	4315380	That was an amazing answer that I did not understand.
4316220	4318180	So it was passionate and meaningful.
4318180	4319180	Shots fired.
4319180	4320380	But I don't know, I just didn't,
4320380	4321460	no, I'm not trying to criticize it.
4321460	4323260	I think I don't think I'm getting it.
4323260	4325460	So you mentioned disaggregation.
4325460	4326420	So what's that?
4326420	4329500	Well, so the power of technology
4329500	4331620	that if you go on the West Coast and hang out long enough
4331620	4333620	is all about we're gonna disaggregate these things together,
4333620	4335940	the books from the bookstore, that kind of a thing.
4335940	4337860	And then suddenly Amazon controls the universe,
4337860	4339540	and technology is a disruptor.
4339540	4340860	And people have been predicting that
4341460	4342900	for a higher education for a long time,
4342900	4343740	but certainly in the...
4343740	4345660	So is this the sort of idea like
4346740	4350180	students can aggregate on a campus some place
4350180	4353580	and then take classes over the network anywhere?
4353580	4354940	Yeah, this is what people thought was gonna happen,
4354940	4357100	or at least people claimed it was gonna happen, right?
4357100	4358980	Because my daughter is essentially doing that now.
4358980	4361100	She's on one campus, but learning in a different campus.
4361100	4363580	Sure, and COVID makes that possible, right?
4363580	4365300	Or COVID makes that...
4365300	4366140	Legal.
4366140	4367460	All but avoidable, right?
4367460	4369500	But the idea originally was that,
4369500	4371220	you and I were gonna create this machine learning class
4371220	4372060	and it was gonna be great,
4372060	4373820	and then no one else would be the machine learning class
4373820	4374900	everyone changed, right?
4374900	4376100	That was never gonna happen,
4376100	4377460	but something like that you could see happen.
4377460	4378700	But I feel like you didn't address that.
4378700	4380820	So why is it that...
4380820	4381700	Why Q?
4381700	4382540	Why?
4382540	4384220	I don't think that will be the thing that happens.
4384220	4385340	So the college experience,
4385340	4387220	maybe I missed what the college experience was.
4387220	4390140	I thought it was peers, like people hanging around.
4390140	4391660	A large part of it is peers.
4391660	4393620	Well, it's peers and independence.
4393620	4395060	Yeah, but none of that...
4395060	4397340	You can do classes online for all of that.
4397340	4398460	No, no, no, no.
4398500	4400860	Because we're social people, right?
4400860	4402300	So one would take the classes,
4402300	4405260	that also has to be part of an experience.
4405260	4407420	It's in a context, and the context is the university.
4407420	4409660	And by the way, it actually matters
4409660	4412140	that Georgia Tech really is different from Brown.
4413340	4416180	I see, because then students can choose
4416180	4417260	the kind of experience they think
4417260	4418380	is gonna be best for them.
4418380	4420420	Okay, I think we're giving too much agency
4420420	4422540	to the students in making an informed decision.
4422540	4423380	Okay.
4423380	4425540	But yes, they will make choices
4425540	4426860	and they will have different experiences.
4426860	4428700	And some of those choices will be made for them.
4428700	4430060	Some of them will be choices they're making
4430060	4431700	because they think it's this, that, or the other.
4431700	4432780	I just don't want to say...
4432780	4433620	I don't want to give the idea...
4433620	4435140	It's not homogeneous.
4435140	4437020	Yes, it's certainly not homogeneous, right?
4437020	4439500	I mean, Georgia Tech is different from Brown.
4439500	4442340	Brown is different from pick your favorite
4442340	4444340	state school in Iowa.
4444340	4445860	Iowa State, okay?
4445860	4447980	Which I guess is my favorite state school in Iowa.
4447980	4449740	But these are all different.
4449740	4450780	They have different contexts.
4450780	4452260	And a lot of those contexts are,
4452260	4453620	they're about history, yes,
4453620	4456060	but they're also about the location of where you are.
4456060	4458300	They're about the larger group of people who are around you,
4458300	4460620	whether you're in Athens, Georgia,
4460620	4463180	and you're basically the only thing that's there
4463180	4465420	as a university, you're responsible for all the jobs,
4465420	4467180	or whether you're at Georgia State University,
4467180	4469060	which is an urban campus,
4469060	4471940	where you're surrounded by six million people
4471940	4473980	in your campus where it ends and begins in the city,
4473980	4475620	ends and begins, we don't know.
4475620	4477380	It actually matters whether you're a small campus
4477380	4478220	or a large campus.
4478220	4479060	I mean, these things matter.
4479060	4481660	Why is it that if you go to Georgia Tech,
4481660	4484940	you're forever proud of that?
4484940	4489460	And you say that to people at dinner bars and whatever.
4489460	4494460	And if you get a degree at an online university somewhere,
4496100	4499020	you don't, that's not a thing that comes up at a bar.
4499020	4499860	Well, it's funny you say that.
4499860	4502820	So the students who take our online masters
4503780	4506660	by several measures are more loyal
4506660	4507900	than the students who come on campus,
4507900	4509380	certainly for the master's degree.
4509380	4510980	The reason for that, I think,
4510980	4511900	and you'd have to ask them,
4511900	4513980	but based on my conversations with them,
4513980	4515540	I feel comfortable saying this,
4515540	4518180	is because this didn't exist before.
4518180	4519780	I mean, we talk about this online masters
4519780	4522140	and that it's reaching 11,000 students
4522140	4523060	and that's an amazing thing.
4523060	4525140	And we're admitting everyone we believe we can succeed.
4525140	4526700	We got a 60% acceptance rate.
4526700	4527900	It's amazing, right?
4527900	4529740	It's also a $6,600 degree.
4529740	4532100	The entire degree costs $6,600 or $7,000,
4532100	4533780	depending on how long you take.
4533780	4535700	Dollar degree, as opposed to the $46,000
4535700	4537940	that cost you to come on campus.
4537940	4540620	So that feels, and I can do it while I'm working full time
4540620	4542260	and I've got a family and a mortgage
4542260	4543420	and all these other things.
4543420	4546260	So it's an opportunity to do something you wanted to do
4546260	4547780	but you didn't think was possible
4547780	4550380	without giving up two years of your life
4550380	4551980	as well as all the money and everything else,
4551980	4553220	the life that you had built.
4553220	4557020	So I think we created something that's had an impact,
4557020	4559700	but importantly, we gave a set of people opportunities
4559700	4560900	they otherwise didn't feel they had.
4560900	4562940	So I think people feel very loyal about that
4562940	4564260	and my biggest piece of evidence for that
4564260	4566980	besides the surveys is that we have somewhere
4566980	4570060	north of 80 students, might be 100 at this point,
4570100	4575100	who graduated but come back in TA for this class
4575100	4576860	for basically minimum wage,
4576860	4578060	even though they're working full time
4578060	4582020	because they believe in sort of having that opportunity
4582020	4583420	and they wanna be a part of something.
4583420	4586060	Now, will generation three feel this way?
4586060	4588100	15 years from now, will people have that same sense?
4588100	4591180	I don't know, but right now, they kind of do.
4591180	4592940	And so it's not the online,
4592940	4596380	it's a matter of feeling as if you're a part of something.
4596380	4597620	We're all very tribal.
4597940	4602140	And I think there's something very tribal
4602140	4604300	about being a part of something like that.
4604300	4605900	Being on campus makes that easier.
4605900	4608260	Going through a shared experience makes that easier.
4608260	4609740	It's harder to have that shared experience
4609740	4612060	if you're alone looking at a computer screen.
4612060	4613340	We can create ways to make that.
4613340	4614340	Is it possible?
4614340	4615260	It is possible.
4615260	4618380	The question is, it still is the intuition to me.
4618380	4621460	And it was at the beginning when I saw something
4621460	4624620	like the online master's program
4624620	4628020	is that this is gonna replace universities.
4628020	4629460	And I won't replace universities, but it won't.
4629460	4631140	But like, why is it, why?
4631140	4633660	Because it's living in a different part of the ecosystem,
4633660	4634500	right?
4634500	4635700	The people who are taking it are already adults.
4635700	4638780	They've gone through their undergrad experience.
4638780	4641940	I think their goals have shifted from when they were 17.
4641940	4643460	They have other things that are going.
4643460	4645580	But it does do something really important,
4645580	4648420	something very social and very important, right?
4648420	4650260	You know this whole thing about,
4650260	4652100	don't build the sidewalks, just leave the grass
4652100	4653700	and the students or the people will walk
4653700	4655380	and you put the sidewalks where they create paths.
4655380	4656220	This is kind of a thing.
4656220	4657620	That's interesting, yeah.
4657620	4659100	Their architects apparently believe
4659100	4660780	that's the right way to do things.
4660780	4665300	The metaphor here is that we created this environment.
4665300	4668700	We didn't quite know how to think about the social aspect,
4668700	4671140	but we didn't have time to solve all,
4671140	4673140	do all the social engineering, right?
4673140	4674260	The students did it themselves.
4674260	4678420	They created these groups, like on Google+,
4678420	4680820	they were like 30-something groups created in the first year
4680860	4684300	because somebody had these Google+,
4684300	4685740	and they created these groups
4685740	4687460	and they divided up in ways that made sense.
4687460	4688340	We live in the same state
4688340	4689340	or we're working on the same things
4689340	4690620	or we have the same background or whatever,
4690620	4692140	and they created these social things.
4692140	4695660	We sent them t-shirts and we have all these great pictures
4695660	4697420	of students putting on their t-shirts
4697420	4698420	as they travel around the world.
4698420	4699380	I climbed to this mountain top,
4699380	4701340	I'm putting this t-shirt on, I'm a part of this.
4701340	4702180	They were part of them.
4702180	4704740	They created the social environment
4704740	4706820	on top of the social network and the social media
4706820	4709460	that existed to create this sense of belonging
4709460	4710580	and being a part of something.
4710580	4712780	They found a way to do it, right?
4712780	4716260	And I think they had other,
4716260	4718180	it scratched an itch that they had,
4718180	4720220	but they had scratched some of that itch
4720220	4721580	that might have required to be physically
4721580	4724500	in the same place long before, right?
4724500	4727300	So I think, yes, it's possible,
4727300	4729740	and it's more than possible, it's necessary,
4729740	4734300	but I don't think it's going to replace the university
4734300	4735260	as we know it.
4735260	4737700	The university as we know it will change,
4737700	4739260	but there's just a lot of power
4739260	4740500	and a kind of rite of passage
4740500	4741580	and kind of going off to yourself.
4741580	4743180	Now, maybe there'll be some other rite of passage
4743180	4746140	that'll happen that'll drive us somewhere else.
4746140	4751220	So the university is such a fascinating mess of things.
4751220	4754740	So just even the faculty position is a fascinating mess.
4754740	4755940	Like it doesn't make any sense.
4755940	4758380	It stabilized itself,
4758380	4762180	but like why are the world-class researchers
4762180	4765300	spending a huge amount of time,
4765300	4768060	or their time teaching and service?
4768060	4770260	Like you're doing like three jobs.
4770260	4775060	And I mean, it turns out it's maybe an accident of history
4775060	4776380	or human evolution, I don't know.
4776380	4778540	It seems like the people who are really good at teaching
4778540	4780500	are often really good at research.
4780500	4782820	There seems to be a parallel there,
4782820	4784540	but like it doesn't make any sense
4784540	4785540	that you should be doing that.
4785540	4788820	At the same time, it also doesn't seem to make sense
4788820	4792140	that your place where you party
4793940	4796420	is the same place where you go to learn calculus
4796420	4799340	or whatever, but it's a safe space.
4799340	4800580	Safe space for everything.
4800580	4802420	Yeah, relatively speaking, it's a safe space.
4802420	4805340	No, by the way, I feel the need very strongly
4805340	4807220	to point out that we are living
4807220	4809540	in a very particular weird bubble, right?
4809540	4810900	Most people don't go to college.
4810900	4812900	And by the way, the ones who do go to college,
4812900	4814380	they're not 18 years old, right?
4814380	4815540	They're like 25 or something.
4815540	4817180	I forget the numbers.
4817180	4819980	The places where we've been, where we are,
4820980	4822420	they look like whatever we think
4822420	4825540	the traditional movie version of universities are,
4825580	4827500	but for most people, it's not that way at all.
4827500	4828980	By the way, most people who drop out of college,
4828980	4831660	it's entirely for financial reasons, right?
4831660	4835380	So, you know, we were talking about a particular experience.
4836780	4840700	And so for that set of people, which is very small,
4840700	4843980	but larger than it was a decade or two or three or four,
4843980	4847220	certainly, ago, I don't think that will change.
4847220	4850500	My concern, which I think is kind of implicit
4850500	4852140	in some of these questions is that
4852140	4854420	somehow we will divide the world up further.
4855420	4857020	Into the people who get to have this experience
4857020	4859300	and get to have the network and they sort of benefit from it
4859300	4861900	and everyone else while increasingly requiring
4861900	4863140	that they have more and more credentials
4863140	4865900	in order to get a job as a barista, right?
4865900	4866980	You got to have a master's degree
4866980	4869020	in order to work at Starbucks.
4869020	4870700	We're gonna force people to do these things,
4870700	4872460	but they're not gonna get to have that experience.
4872460	4873820	And there'll be a small group of people who do,
4873820	4875700	who will continue to, you know, positive feedback,
4875700	4876940	like, et cetera, et cetera, et cetera.
4876940	4878220	I worry a lot about that,
4878220	4881500	which is why for me, and by the way,
4881500	4882940	here's an answer to your question about faculty,
4882980	4884860	which is why to me that you have to focus on
4884860	4886100	access in the mission.
4886100	4888220	I think the reason, whether it's good, bad, or strange,
4888220	4889780	I mean, I agree, it's strange.
4889780	4892220	But I think it's useful to have the faculty member,
4892220	4893900	particularly at large R1 universities
4893900	4896620	where we've all had experiences,
4896620	4901100	that you tie what they get to do
4901100	4903940	and with the fundamental mission of the university
4903940	4905100	and let the mission drive.
4905100	4907100	What I hear when I talk to faculty is
4907100	4908380	they love their PhD students
4908380	4910500	because they're creating, they're reproducing,
4910500	4911340	basically, right?
4911340	4913740	Let's them do their research and multiply.
4913740	4917380	But they understand that the mission is the undergrads,
4917380	4920420	and so they will do it without complaint, mostly,
4920420	4922500	because it's a part of the mission and why they're here,
4922500	4924180	and they have experiences with it themselves.
4924180	4927500	And it was important to get them where they were going.
4927500	4928740	The people who tend to get squeezed in that,
4928740	4930420	by the way, are the master students, right?
4930420	4932260	Who are neither the PhDs who are like us,
4932260	4934860	nor the undergrads, we have already bought into the idea
4934860	4936540	that we have to teach, though.
4936540	4938260	That's increasingly changing.
4938260	4941100	Anyway, I think tying that mission in really matters,
4941100	4944220	and it gives you a way to unify people around
4944220	4946140	making it an actual higher calling.
4946140	4948140	Education feels like more of a higher calling to me
4948140	4949740	than even research.
4950820	4953900	Because education, you cannot treat it as a hobby
4953900	4955220	if you're going to do it well.
4955220	4958420	But that's the pushback on this whole system,
4958420	4963420	is that you should, education, be a full-time job, right?
4964500	4969060	And almost like research is a distraction from that.
4969340	4971340	Although, I think most of our colleagues,
4971340	4973340	many of our colleagues would say that research is the job
4973340	4975140	and education is the distraction.
4975140	4976660	Right, but that's the beautiful dance.
4976660	4981420	It seems to be that tension in itself seems to work,
4981420	4985860	seems to bring out the best in the faculty,
4985860	4987300	or like the ones I've done.
4987300	4988340	But I will point out two things.
4988340	4989260	One thing I'm going to point out,
4989260	4990740	and the other thing I want Michael to point out,
4990740	4993540	because I think Michael is much closer to the,
4993540	4997300	to sort of the ideal professor in some sense than I am.
4997660	4999660	You're the platonic sense of a professor.
4999660	5000900	I don't know what he meant by that,
5000900	5003380	but he is a dean, so he has a different experience.
5003380	5006260	I'm giving him time to think of the profound thing
5006260	5007100	he's gonna say. That's good.
5007100	5008580	But let me point this out,
5008580	5012020	which is that we have lecturers in the college
5012020	5013940	of computing where I am.
5013940	5015700	There's 10 or 12 of them, depending on your count,
5015700	5019180	as opposed to the 90 or so tenure track faculty.
5019180	5021180	Those 10 lecturers who only teach,
5021180	5022900	well, they don't only teach, they also do service.
5022900	5026600	Some of them do research as well, but primarily they teach.
5026640	5029680	They teach 50%, over 50% of our credit hours,
5029680	5031320	and we teach everybody.
5031320	5034160	So they're doing not just,
5034160	5036360	they're doing more than eight times the work
5036360	5039000	of the tenure track faculty,
5039000	5041680	just if you're closer to nine or 10.
5041680	5043080	And that's including our grad courses, right?
5043080	5045160	So they're doing this, they're teaching more,
5045160	5047160	they're touching more than anyone,
5047160	5049560	and they're beloved for it.
5049560	5051720	So we recently had a survey, we do these alumni,
5051720	5052960	everyone does these alumni surveys,
5052960	5054320	you hire someone from the outside to do whatever,
5054320	5056000	and I was really struck by something.
5056040	5057240	I saw all these really cool numbers,
5057240	5058320	I'm not gonna talk about it,
5058320	5059960	because it's all internal, confidential stuff.
5059960	5061200	But one thing I will talk about
5061200	5063160	is there was a single question we asked our alum,
5063160	5064480	and these are people who graduated,
5064480	5065880	born in the 30s and 40s,
5065880	5068520	all the way up to people who graduated last week, right?
5069560	5070560	Well, last semester.
5070560	5071400	Okay, good.
5072520	5073360	Time flies.
5073360	5074720	Yeah, time flies.
5074720	5076440	And it was the question,
5076440	5079760	name a single person who had a strong,
5079760	5082120	positive impact on you, something like that.
5082120	5084400	I think it was special impact?
5084400	5085640	Yeah, special impact on you.
5085640	5087280	And then, so they got all the answers from people,
5087280	5089080	and they created a word cloud.
5089080	5090600	Those clear word clouds created by people
5090600	5092240	who don't do word clouds for a living,
5092240	5094800	because they had one person whose name appeared
5094800	5097920	like nine different times, like Phillip, Phil,
5097920	5099400	Dr. Phil, you know, but whatever.
5099400	5100240	But they got all this.
5100240	5102400	And I looked at it, and I noticed something really cool.
5102400	5106760	The five people from the college of computing,
5106760	5109280	I recognized, were in that cloud.
5109280	5113840	And four of them were lecturers,
5113840	5115280	the people who teach.
5115280	5117360	Two of them, relatively modern.
5117360	5119880	Both were chairs of our division of computing instruction.
5119880	5122160	One retired, one is gonna retire soon.
5122160	5126480	And the other two were lecturers I remembered from the 1980s.
5126480	5128120	Two of those four actually have-
5128120	5129760	Despite the way the fifth person was Charles.
5129760	5130600	That's not important.
5130600	5132960	The thing is, I don't tell people that.
5132960	5135240	But the two of those people are teaching awards
5135240	5136080	are named after.
5136080	5136920	Thank you, Michael.
5136920	5139720	Two of those are teaching awards are named after, right?
5139720	5141760	So when you ask students, alumni,
5141760	5144520	people who are now 60, 70 years old even,
5144520	5145360	who touch them?
5145360	5146680	They say the dean of students.
5146680	5148280	They say the big teachers who taught
5148280	5150280	the big introductory classes, they got me into it.
5150280	5152320	There's a guy named Richard Barker's on there
5152320	5155360	who's known as a great teacher.
5155360	5157000	The Phil Adler guy who,
5158520	5160080	I probably just said his last name wrong,
5160080	5161120	but I know the first name's Phil
5161120	5163120	because he kept showing up over and over again.
5163120	5163960	Famous-
5163960	5164800	Adler is what it said.
5164800	5165640	Okay, good.
5165640	5166800	But different people spelled it differently.
5166800	5167920	So he appeared multiple times.
5167920	5168760	Right.
5168880	5170520	He was a, clearly,
5170520	5173040	he was a professor in the business school,
5174200	5175840	but when you read about him,
5175840	5176680	I went to read about himself,
5176680	5177720	I was curious who he was.
5177720	5178680	It's all about his teaching
5178680	5180080	and the students that he touched, right?
5180080	5182320	So whatever it is that we're doing,
5182320	5183440	and we think we're doing that's important,
5183440	5185360	or why we think the university's function,
5185360	5187760	the people who go through it,
5187760	5189520	they remember the people who were kind to them,
5189520	5191360	the people who taught them something,
5191360	5192480	and they do remember it.
5192480	5193480	They remember it later.
5193480	5195840	I think that's important.
5195840	5197200	That's what the mission matters.
5197600	5201920	Not to completely lose track of the fundamental problem
5201920	5206920	of how do we replace the party aspect of universities.
5208120	5211360	Before we go to what makes the Platonic professor,
5213480	5214440	do you think,
5215760	5217960	what in your sense is the role of MOOCs
5217960	5220040	in this whole picture during COVID?
5221000	5224200	Are we, should we desperately be clamoring
5224200	5225920	to get back on campus?
5225920	5228960	Or is this a stable place to be for a little while?
5228960	5229800	I don't know.
5229800	5232640	I know that it's the online teaching experience
5232640	5236000	and learning experience has been really rough.
5236000	5238320	I think that people find it to be a struggle
5238320	5242040	in a way that's not a happy positive struggle.
5242040	5243160	That when you got through it,
5243160	5244840	you just feel like glad that it's over
5244840	5247840	as opposed to I've achieved something.
5247840	5249720	So, I worry about that,
5249720	5253880	but I worry about just even before this happened,
5253880	5255400	I worry about lecture teaching
5255400	5258760	as how well is that actually really working
5258760	5260720	as far as a way to do education,
5260720	5263640	as a way to inspire people.
5263640	5267120	I mean, all the data that I'm aware of seems to indicate,
5267120	5269720	and this kind of fits I think with Charles' story,
5269720	5274560	is that people respond to connection, right?
5274560	5275920	They actually feel,
5275920	5279200	if they feel connected to the person teaching the class,
5279200	5280720	they're more likely to go along with it.
5280720	5283040	They're more able to retain information.
5283040	5285600	They're more motivated to be involved in the class
5285600	5290200	in some way, and that really matters.
5290200	5292240	You mean to the human themselves?
5292240	5293080	Yeah.
5293080	5294200	Can't you do that?
5294200	5298400	Actually, perhaps more effectively online,
5298400	5300280	like you mentioned science communication.
5300280	5303680	So, I literally, I think,
5303680	5306520	learned linear algebra from Gilbert Strang
5306520	5309920	by watching MIT OpenCourseWare when I was in drugs.
5309920	5311080	And he was a personality,
5311080	5313160	he was a bit like a tiny,
5313160	5315200	in this tiny little world of math,
5315200	5316600	there's a bit of a rock star, right?
5316600	5320760	So, you kind of look up to that person.
5320760	5324920	Can't that replace the in-person education?
5324920	5325760	It can help.
5325760	5326680	I will point out something.
5326680	5327560	I can't share the numbers,
5327560	5330040	but we have surveyed our students,
5330040	5331480	and even though they have feelings
5331480	5334440	about what I would interpret as connection,
5334440	5338480	I like that word, in the different modes of classrooms,
5338520	5340920	there's no difference between how well
5340920	5342640	they think they're learning.
5342640	5345760	For them, the thing that makes them unhappy
5345760	5347040	is the situation they're in.
5347040	5348760	And I think the last lack of connection,
5348760	5350640	it's not whether they're learning anything.
5350640	5353440	They seem to think they're learning something anyway, right?
5353440	5354440	In fact, they seem to think
5354440	5357000	they're learning it equally well,
5357000	5360720	presumably because the faculty are putting in,
5360720	5363040	or the instructors, more generally speaking,
5363040	5365920	are putting in the energy and effort
5365920	5367160	to try to make certain
5368000	5369800	what they've curated can be expressed to them
5369800	5370720	in a useful way.
5370720	5371840	But the connection is missing,
5371840	5374200	and so there's huge differences in what they prefer,
5374200	5375040	and as far as I can tell,
5375040	5377400	what they prefer is more connection, not less.
5377400	5379480	That connection just doesn't have to be physically
5379480	5380320	in a classroom.
5380320	5383520	I mean, look, I used to teach 348 students
5383520	5384840	on my machine learning class on campus.
5384840	5385680	Do you know why?
5385680	5387440	That was the biggest classroom on campus.
5388640	5389800	They're sitting in theaters,
5389800	5390840	they're sitting in theater seats.
5390840	5394400	I'm literally on a stage looking down on them
5394400	5396640	and talking to them, right?
5397640	5399600	I mean, we're not sitting down
5399600	5401360	having a one-on-one conversation,
5401360	5402720	reading each other's body language,
5402720	5403680	trying to communicate,
5403680	5405360	and going, we're not doing any of that.
5405360	5407480	So if you're past the third row,
5407480	5408760	it might as well be online anyway,
5408760	5410280	is the kind of thing that people have said,
5410280	5412920	Daphne has actually said some version of this,
5412920	5414440	that online starts on the third row,
5414440	5415600	or something like that.
5415600	5417560	And I think that's not,
5417560	5420320	yeah, I like it, I think it captures something important.
5420320	5422120	But people still came, by the way.
5422120	5423880	Even the people who had access to our material
5423880	5425240	would still come to class.
5425280	5426480	I mean, there's a certain element
5426480	5428600	about looking to the person next to you.
5428600	5430320	It's just like their presence there,
5430320	5435040	their boredom, and like when the parts are boring,
5435040	5438040	and their excitement when the parts are exciting,
5438040	5439640	like, and sharing in that,
5439640	5443720	like unspoken kind of, yeah, communication.
5443720	5446720	In part, the connection is with the other people in the room.
5446720	5451720	Watching the circus on TV alone is not really,
5452400	5453480	they've ever been to a movie theater
5453480	5455320	and been the only one there at a comedy.
5455320	5458240	It's not as funny as when you're in a room
5458240	5460120	full of people all laughing.
5460120	5462520	Well, you need, maybe you need just another person.
5462520	5464680	It's like, as opposed to many.
5464680	5466160	Maybe there's some kind of-
5466160	5467840	Well, there's different kinds of connection, right?
5467840	5469680	And there's different kinds of comedy.
5471720	5472560	Well, in the sense that-
5472560	5473720	As we're learning today.
5475000	5476240	I wasn't sure if that was gonna land,
5476240	5480920	but just the idea that different jokes,
5480920	5483120	I've now done a little bit of stand-up.
5483120	5486560	And so different jokes work in different sized crowds too.
5486560	5487400	No, it's true.
5487400	5490320	Where sometimes if it's a big enough crowd,
5490320	5493640	then even a really subtle joke can take root someplace,
5493640	5494920	and then that cues other people,
5494920	5498720	and it kind of, there's a whole statistics of,
5498720	5500240	I did this terrible thing to my brother.
5500240	5501440	So when I was really young,
5501440	5504800	I decided that my brother was only laughing
5504800	5506560	as it comes when I laughed.
5506560	5508240	Like he was taking cues from me.
5508240	5511160	So I like purposely didn't laugh, just to see if I was right.
5511160	5512400	And did you laugh at non-funny things?
5512680	5513720	I really wanted to do both sides.
5513720	5515000	I did both sides.
5515000	5518440	And at the end of it, I told him what I did.
5518440	5520040	He was very upset about this.
5520040	5521600	And from that day on.
5521600	5523040	He lost his sense of humor.
5523040	5523880	No, no, no, no.
5523880	5525720	Well, yes, but from that day on,
5525720	5527720	he laughed on his own.
5527720	5529280	He stopped taking cues from me.
5529280	5531760	So I wanna say that it was a good thing that I did,
5531760	5532920	but it was mostly mean.
5532920	5534080	You saved that man's life.
5534080	5535960	Yes, but it was mostly mean, but it's true though.
5535960	5536800	It's true, right?
5536800	5539360	That people, I think you're right.
5539360	5540880	But okay, so where does that get us?
5540880	5543080	That gets us the idea that,
5543080	5546240	I mean, certainly movie theaters are a thing, right?
5546240	5548320	Where people like to be watching together,
5548320	5550480	even though the people on the screen
5550480	5553080	aren't really co-present with the people in the audience.
5553080	5555040	The audience is co-present with themselves.
5555040	5556240	By the way, and that point,
5556240	5558640	it's an open question that's being raised by this,
5558640	5561000	whether movies will no longer be a thing
5561000	5563760	because Netflix's audience is growing.
5563760	5567200	So that's a very parallel question for education.
5567200	5570120	Will movie theaters still be a thing in 2021?
5570720	5573160	I think the argument is that there is a feeling
5573160	5576080	of being in the crowd that isn't replicated
5576080	5577520	by being at home watching it,
5577520	5579280	and that there's value in that.
5579280	5580120	And then I think just-
5580120	5581440	But.
5581440	5582280	But.
5582280	5583280	It scales better online.
5583280	5586880	But I feel like we're having a conversation
5586880	5589360	about whether concerts will still exist
5589360	5593080	after the invention of the record or the CD
5593080	5594040	or wherever it is, right?
5594040	5594880	They won't.
5594880	5596920	You're right, concerts are dead.
5596920	5599600	Well, okay, I think the joke is only funny
5599600	5601480	if you say it before now.
5601480	5603200	Right, yeah, that's true.
5603200	5604040	We'll fix it in post.
5604040	5604880	It's like three years ago.
5604880	5605720	It's like, well, no, obviously,
5605720	5606560	concerts are still-
5606560	5608680	I'll wait to publish this until we have a vaccine.
5608680	5610400	No, we'll fix it in post.
5610400	5613160	But I think the important thing is-
5613160	5614440	Fix the virus first.
5614440	5616120	Concert's changed, right?
5617000	5617840	Concert's changed.
5617840	5619560	First off, movie theaters weren't this way, right?
5619560	5621960	In like the 60s and 70s, they weren't like this.
5621960	5624040	Like blockbusters were basically what?
5624040	5627040	What, Jaws and Star Wars created blockbusters, right?
5627040	5627880	Before then, there weren't.
5627960	5630840	The whole shared summer experience didn't exist
5630840	5632320	in our lifetimes, right?
5632320	5633800	Certainly, you were well into adulthood
5633800	5634960	by the time this was true, right?
5634960	5637160	So it's just a very different, it's very different.
5637160	5639520	So what we've been experiencing in the last 10 years
5639520	5641800	is not like the majority of human history,
5641800	5643520	but more importantly, concerts, right?
5643520	5644680	Concerts mean something different.
5644680	5647680	Most people don't go to concerts anymore.
5647680	5649680	Like there's an age where you care about it.
5649680	5650520	You sort of stop doing it.
5650520	5652240	You keep listening to music or whatever
5652240	5653840	and da, da, da, da, da, da.
5653840	5658320	So I think that's a painful way of saying
5658320	5662560	that it will change.
5662560	5663880	It was not the same thing as it going away.
5663880	5667000	Replace is too strong of a word, but it will change.
5667000	5667840	It has to.
5667840	5669800	I actually, like to push back, I wonder
5669800	5671920	because I think you're probably just throwing
5671920	5673200	that you're intuition out.
5673200	5674200	Oh, absolutely.
5674200	5677280	And it's possible that concerts,
5677280	5679640	more people go to concerts now,
5679640	5682760	but obviously much more people listen to,
5683400	5686120	dumb, than before there was records.
5686960	5691680	It's possible to argue that if you look at the data
5691680	5693560	that it just expanded the pie
5693560	5696000	of what music listening means.
5696000	5698040	So it's possible that like universities grow
5698040	5700720	in the parallel or the theaters grow,
5700720	5702640	but also more people get to watch movies,
5702640	5705680	more people get to be educated.
5705680	5707080	Yeah, I hope that.
5707080	5709720	Yeah, and to the extent that we can grow the pie
5709720	5712000	and have education be not just something you do
5712000	5716440	for four years when you're done with your other education,
5716440	5719120	but it'd be a more lifelong thing,
5719120	5720640	that would have tremendous benefits,
5720640	5724320	especially as the economy and the world change rapidly.
5724320	5727200	Like people need opportunities to stay abreast
5727200	5728920	of these changes.
5728920	5733520	And so, I don't know, that's all part of the ecosystem.
5733520	5734360	It's all to the good.
5734360	5736920	I mean, you know, I'm not gonna have an argument
5736920	5739320	about whether we lost fidelity when we went
5739320	5743040	from laser discs to DVDs or record players to CDs.
5743040	5745600	I mean, I'm willing to grant that that is true,
5745600	5750600	but convenience matters and the ability to do something
5750840	5751760	that you couldn't do otherwise
5751760	5753800	because that convenience matters.
5753800	5756160	And you can tell me I'm only getting 90% of the experience,
5756160	5757760	but I'm getting the experience.
5757760	5760120	I wasn't getting it before or wasn't lasting as long
5760120	5760960	or it wasn't as easy.
5760960	5763640	I mean, this just seems straightforward to me.
5763640	5765520	It's gonna, it's going to change.
5765520	5768320	It is for the good that more people get access.
5768360	5770520	And it is our job to do two separate things.
5770520	5773480	One, to educate them and make access available.
5773480	5774720	That's our mission.
5774720	5777080	But also for very simple selfish reasons,
5777080	5778320	we need to figure out how to do it better
5778320	5780160	so that we individually stay in business.
5780160	5781880	We can do both of those things at the same time.
5781880	5784400	They are not in, they may be intention,
5784400	5786760	but they are not mutually exclusive.
5788040	5792100	So you've educated some scary number of people.
5792700	5797420	So you've seen a lot of people succeed,
5797420	5799620	find their path through life.
5799620	5804260	Is there a device that you can give to a young person today
5805340	5809020	about computer science education,
5809020	5813380	about education in general, about life,
5813380	5818380	about whatever the journey that one takes in there,
5819380	5822620	maybe in their teens, in their early 20s,
5822620	5825100	sort of in those underground years,
5825100	5828140	as you try to go through the essential process
5828140	5830780	of partying and not go into classes.
5830780	5832980	And yet somehow try to get a degree.
5832980	5836460	If you get to the point where you're far enough up
5836460	5838900	in the hierarchy of needs
5838900	5841900	that you can actually make decisions like this,
5841900	5844500	then find the thing that you're passionate about
5844500	5845740	and pursue it.
5845740	5847860	And sometimes it's the thing that drives your life
5847900	5849100	and sometimes it's secondary.
5849100	5851660	And you'll do other things because you've got to eat, right?
5851660	5852860	You've got to family, you've got to feed,
5852860	5854540	you've got people you have to help or whatever, right?
5854540	5856420	And I understand that and it's not easy for everyone,
5856420	5860980	but always take a moment or two to pursue the things
5860980	5864580	that you love, the things that bring passion
5864580	5865420	and happiness to your life.
5865420	5866820	And if you don't, I know that sounds corny,
5866820	5868020	but I genuinely believe it.
5868020	5869900	And if you don't have such a thing,
5869900	5871420	then you're lying to yourself.
5871420	5873500	You have such a thing, you just have to find it.
5873500	5876020	And it's okay if it takes you a long time to get there.
5876020	5880380	Rodney Dangerfield became a comedian in his 50s, I think.
5880380	5881820	It certainly wasn't his 20s.
5881820	5883700	And lots of people failed for a very long time
5883700	5885700	before getting to where they were going.
5886700	5888580	I try to have hope.
5888580	5889780	And it wasn't obvious.
5889780	5893180	I mean, you and I talked about the experience
5893180	5897500	that I had a long time ago with a particular police officer.
5897500	5900940	Was it my first one and was it my last one?
5900940	5904180	But in my view, I wasn't supposed to be here after that
5904180	5905940	and I'm here, so it's all gravy.
5905940	5909020	So you might as well go ahead and grab life as you can
5909020	5909860	because of that.
5909860	5911260	That's sort of how I see it.
5911260	5914540	While recognizing, again, the delusion matters, right?
5914540	5915940	Allow yourself to be deluded.
5915940	5918100	Allow yourself to believe that it's all gonna work out.
5918100	5921740	Just don't be so deluded that you missed the obvious.
5921740	5923500	And you're gonna be fine.
5923500	5924900	It's gonna be there.
5924900	5925740	It's gonna be there.
5925740	5926660	It's gonna work out.
5926660	5928020	What do you think?
5928020	5930140	I like to say, choose your parents wisely
5931180	5933100	because that has a big impact on your life.
5933100	5934580	It's different.
5934580	5937420	Yeah, I mean, there's a whole lot of things
5937420	5938540	that you don't get to pick.
5938540	5942980	And whether you get to have one kind of life
5942980	5945140	or a different kind of life can depend a lot
5945140	5946900	on things out of your control.
5946900	5950020	But I really do believe in the passion and excitement thing.
5950020	5951980	I was talking to my mom on the phone the other day
5951980	5956980	and essentially what came out is that computer science
5959900	5962140	is really popular right now.
5962380	5965900	And I get to be a professor teaching something
5965900	5968860	that's very attractive to people.
5968860	5973540	And she was like trying to give me some appreciation
5973540	5977700	for how foresightful I was for choosing this line of work
5977700	5979980	as if somehow I knew that this is what was gonna happen
5979980	5980940	in 2020.
5982180	5984020	But that's not how it went for me at all.
5984020	5985540	Like I studied computer science
5985540	5987900	because I was just interested.
5987900	5989620	It was just so interesting to me.
5989620	5994580	I didn't think it would be particularly lucrative.
5994580	5996460	And I've done everything I can to keep it
5996460	5998380	as un-lucrative as possible.
5999500	6003380	Some of my friends and colleagues have not done that.
6003380	6007900	And I pride myself on my ability to remain un-rich.
6007900	6012900	But I do believe that, like I'm glad,
6013300	6015260	I mean, I'm glad that it worked out for me.
6015260	6016100	It could have been like,
6016100	6017940	oh, what I was really fascinated by
6017940	6019300	is this particular kind of engraving
6019300	6020660	that nobody cares about.
6020660	6022780	But so I got lucky and the thing that I cared about
6022780	6024140	happened to be a thing that other people
6024140	6025340	eventually cared about.
6026300	6028060	But I don't think I would have had a fun time
6028060	6029180	choosing anything else.
6029180	6031860	Like this was the thing that kept me interested
6031860	6032700	and engaged.
6032700	6034700	Well, one thing that people tell me,
6034700	6038220	especially around early on the graduate
6038220	6041580	and the internet is part of the problem here
6041580	6044860	is they say they're passionate about so many things.
6044860	6046540	How do I choose a thing?
6046540	6050300	Which is a harder thing for me to know what to do with.
6050300	6051380	Is there any?
6051380	6054460	I mean, don't you know, which, I mean, you know, look.
6055660	6057740	A long time ago, I walked down a hallway
6057740	6059020	and I took a left turn.
6059020	6059860	Yeah.
6059860	6061340	I could have taken a right turn.
6061340	6063820	And my world could be better or it could be worse.
6063820	6064660	I have no idea.
6064660	6065500	I have no way of knowing.
6065500	6067100	Is there anything about this particular hallway
6067100	6069100	that's relevant or are you just in general choices?
6069100	6069940	Yeah, you were on the left.
6069940	6071900	It sounds like you regret not taking the right turn.
6071900	6072740	Oh, no, not at all.
6072740	6073940	Well, you brought it up.
6073940	6076460	Well, because it was a turn there.
6076460	6078100	On the left was Michael Liman's office, right?
6078100	6080100	I mean, these sorts of things happen, right?
6080100	6080940	But here's the thing.
6080940	6083180	On the right, by the way, there was just a blank wall.
6083180	6084500	It wasn't a huge choice.
6084500	6085340	It would have really hurt.
6085340	6086260	He tried first.
6086260	6087660	No, but it's true, right?
6087660	6089860	That, you know, I think about Ron Brockman, right?
6089860	6093340	I went, I took a trip I wasn't supposed to take
6093340	6098100	and I ended up talking to Ron about this
6098100	6100740	and I ended up going down this entire path
6100740	6102820	that allowed me to, I think, get tenure.
6102820	6105820	But by the way, I decided to say yes to something
6105820	6106740	that didn't make any sense
6106740	6108260	and I went down this educational path.
6108260	6110500	But it would have been, you know, who knows, right?
6110500	6112140	Maybe if I hadn't done that,
6112140	6114300	I would be a billionaire right now.
6114300	6115300	I'd be Elon Musk.
6115300	6117020	My life could be so much better.
6117020	6119540	My life could also be so much worse.
6119540	6120860	You know, you just gotta feel
6120860	6123020	that sometimes you have decisions you're gonna make.
6123020	6124220	You cannot know what's gonna do.
6124220	6125580	You should think about it, right?
6125580	6127540	Some things are clearly smarter than other things.
6127540	6129580	You gotta play the odds a little bit.
6129580	6131580	But in the end, if you've got multiple choices
6131580	6132820	or lots of things you think you might love,
6132820	6134420	go with the thing that you actually love,
6134420	6135900	the thing that jumps out at you
6135900	6137260	and sort of pursue it for a little while.
6137260	6138180	The worst thing that'll happen
6138180	6140060	is you took a left turn instead of a right turn
6140060	6141660	and you ended up merely happy.
6142660	6143580	Beautiful.
6143580	6147780	So accepting, so taking the step and just accepting,
6147780	6150460	accepting that that don't like question,
6150460	6151300	question the choice.
6151300	6153100	I like to think that life is long
6153100	6156580	and there's time to actually pursue.
6156580	6158500	Every once in a while,
6158500	6161140	you have to put on a leather suit
6161220	6163060	and make a thriller video.
6163060	6164340	Every once in a while.
6164340	6166620	If I ever get a chance to put on a leather suit,
6166620	6167460	I'm doing it.
6167460	6169140	Yeah.
6169140	6171020	I was told that you actually danced,
6171020	6173620	but that part was edited out.
6173620	6174460	I don't dance.
6175820	6179220	There was a thing where we did do the zombie thing.
6179220	6180740	We did do the zombie thing.
6180740	6182020	That wasn't edited out.
6182020	6184300	It just wasn't put into the final thing.
6185540	6186380	I'm quite happy.
6186380	6187540	There was a reason for that too, right?
6187540	6189540	Like I wasn't wearing something right.
6189540	6190380	There was a reason for that.
6190980	6192420	No leather suit.
6192420	6193260	Is that what it was?
6193260	6194100	I can't remember.
6194100	6196100	Anyway, the right thing happened.
6196100	6196940	Exactly.
6196940	6199660	You took the left turn and ended up being the right thing.
6199660	6203180	So a lot of people ask me that are a little bit
6203180	6206540	tangential to the programming, the computing world,
6206540	6208300	and they're interested to learn programming,
6208300	6210380	like all kinds of disciplines that are outside
6210380	6213260	of the particular discipline of computer science.
6213260	6216140	What advice do you have for people
6216140	6218100	that want to learn how to program
6218140	6223140	or want to either taste this little skill set
6223620	6227300	or discipline or try to see if it can be used somehow
6227300	6228940	in their own life?
6228940	6230540	What stage of life are they in?
6232220	6235100	It feels, well, one of the magic things about the internet
6235100	6238180	of the people that write me is I don't know.
6238180	6240060	Cause my answer is different for,
6240060	6242540	my daughter is taking AP computer science right now.
6242540	6243620	Hi, Johnny.
6243620	6246380	She's amazing in doing amazing things
6246380	6248100	and my son's beginning to get interested
6248100	6250340	and I'll be really curious where he takes it.
6250340	6252460	I think his mind actually works very well
6252460	6254740	for this sort of thing and she's doing great.
6254740	6257180	But one of the things I have to tell her all the time
6257180	6259940	is she points, well, I want to make a rhythm game.
6259940	6263380	So I want to go for two weeks and then build a rhythm game,
6263380	6266820	show me how to build a rhythm game and start small,
6266820	6268980	learn the building blocks and how to take the time,
6268980	6271180	have patience, eventually you'll build a rhythm game.
6271180	6274180	I was in grad school when I suddenly woke up one day
6274220	6277260	over the Royal East and I thought, wait a minute,
6277260	6278100	I'm a computer scientist.
6278100	6279820	I should be able to write Pac-Man in an afternoon.
6279820	6282140	And I did, not with great graphics.
6282140	6283180	It was actually a very cool game.
6283180	6285180	I had to figure out how the ghost moved and everything.
6285180	6288900	And I did it in an afternoon and Pascal on an old Apple 2GS.
6289980	6292500	But if I had started out trying to build Pac-Man,
6292500	6295140	I think it probably would have ended very poorly for me.
6295140	6298220	Luckily back then there weren't these magical devices
6298220	6300260	we call phones and software everywhere
6300260	6302460	to give me this illusion that I could create something
6302460	6305820	by myself from the basics inside of a weekend like that.
6305820	6309580	I mean, that was a culmination of years and years and years
6309580	6312220	before I decided I should be able to write this and I could.
6312220	6316980	So my advice if you're early on is you've got the internet.
6316980	6318900	There are lots of people there to give you the information.
6318900	6320620	Find someone who cares about this.
6320620	6322700	Remember they've been doing it for a very long time.
6322700	6324820	Take it slow, learn the little pieces,
6324820	6327180	get excited about it and then keep the big projects
6327180	6328580	you want to build in mind.
6328580	6329700	You'll get there soon enough
6329700	6332860	because as a wise man once said, life is long.
6332860	6335700	Sometimes it doesn't seem that long, but it is long
6335700	6339100	and you'll have enough time to build it all out.
6339100	6342100	All the information is out there, but start small.
6343300	6344740	Generative and object numbers.
6344740	6348700	That's not exciting, but it'll get you a programming language.
6348700	6350980	Well, there's only one programming language, it's Lisp.
6350980	6353580	But if you have to pick a programming language,
6353580	6355500	I guess in today's, what would I do?
6355500	6356820	I guess I'd do-
6356820	6360580	Python is basically Lisp, but with better syntax.
6360580	6361420	Blast for me.
6361420	6363780	Yeah, with C syntax, how about that?
6363780	6365300	So you're going to argue that C syntax
6365300	6367100	is better than anything?
6367100	6370220	Anyway, I'm going to answer Python despite what he said.
6370220	6372540	Tell your story about somebody's dissertation
6372540	6374540	that had a Lisp program in it.
6374540	6375380	It was so funny.
6375380	6377900	This is Dave's, Dave's dissertation was like
6377900	6380140	Dave McAllister who was a professor at MIT for a while
6380140	6384740	and then he came to our lab and now he's at technology,
6384780	6386380	technicals to Chicago.
6386380	6388940	A brilliant guy, such an interesting guy.
6388940	6393940	Anyway, his thesis, it was a theorem prover
6393980	6398460	and he decided to have as an appendix his actual code,
6398460	6399700	which of course was already in Lisp
6399700	6400940	because of course it was.
6400940	6403820	And like the last 20 pages are just right parentheses.
6403820	6406460	It's just wonderful.
6406460	6408460	It's like, that's programming right there.
6408460	6411060	Just pages upon pages of right parentheses.
6411060	6412900	Anyway, Lisp is the only real language,
6412900	6414460	but I understand that that's not necessarily
6414500	6416020	the place where you start.
6416020	6417740	Python is just fine.
6417740	6419060	Python is good.
6419060	6421380	If you're of a certain age, if you're really young
6421380	6423220	and trying to figure out graphical languages
6423220	6424940	that let you kind of see how the thing works
6424940	6426500	and that's fine too, they're all fine.
6426500	6427860	It almost doesn't matter, but there are people
6427860	6429940	who spend a lot of time thinking about
6429940	6433100	how to build languages that get people in.
6433100	6434860	The questions are you trying to get in
6434860	6437340	and figure out what it is or do you already know
6437340	6438860	what you want and that's why I asked you
6438860	6439940	what stage of life people are in
6439940	6441260	because if you're different stages of life,
6441260	6443700	you would attack it differently.
6443700	6445420	The answer to that question of which language
6445420	6447980	keeps changing, I mean, there's some value
6447980	6452780	to exploring a lot of people write to me about Julia.
6452780	6455300	There's these like more modern languages
6455300	6458620	that keep being invented, Rust and Kotlin.
6458620	6462340	There's stuff that, for people who love
6462340	6464340	functional languages like Lisp,
6465420	6466940	apparently there's echoes of that,
6466940	6469500	but much better in the modern languages.
6469500	6473380	It's worthwhile to, especially when you're learning languages,
6473380	6475380	it feels like it's okay to try one
6475380	6477900	that's not like the popular one.
6477900	6479100	Oh yeah, but you want something simple.
6479100	6482220	And I think you get that way of thinking
6482220	6484540	almost no matter what language
6484540	6487980	and if you push far enough, like it can be assembly language,
6487980	6489580	but you need to push pretty far
6489580	6491540	before you start to hit the really deep concepts
6491540	6493420	that you would get sooner in other languages.
6493420	6496660	But like, I don't know, computation is kind of computation
6496660	6499540	is kind of touring equivalent is kind of computation.
6499540	6502260	And so it matters how you express things,
6502260	6504500	but you have to build out that mental structure
6504500	6505540	in your mind.
6505540	6508860	And I don't think it's super matters which language.
6508860	6510020	I mean, it matters a little
6510020	6511740	because some things are just at the wrong level
6511740	6512580	of abstraction.
6512580	6513900	I think assembly is at the wrong level abstract
6513900	6516020	for someone coming in new.
6516020	6517340	I think that if you start it from-
6517340	6518500	For someone coming in new.
6518500	6522700	Yes, for frameworks, big frameworks are quite a bit.
6522700	6523740	You know, you got to get to the point
6523740	6525180	where I want to learn any language means
6525180	6526260	I just pick up a reference book
6526260	6527580	and I think of a project
6527580	6529340	and I go through it in a weekend.
6529340	6530380	Right, you got to get there.
6530380	6531420	You're right though.
6531420	6532780	The languages that are designed for that
6532780	6534980	or it almost doesn't matter.
6534980	6537900	Pick the ones that people have built tutorials
6537900	6539140	and infrastructure around to help you
6539140	6540900	get kind of kind of ease into it.
6540900	6541740	Cause it's hard.
6541740	6543500	I mean, I did this little experiment with.
6545380	6548620	I was teaching intro to CS in the summer as a favor.
6551140	6551980	Which is, anyway.
6551980	6555260	I was teaching intro to CS as a favor.
6555260	6557060	And it was very funny cause I'd go in every single time
6557060	6558860	and I would think to myself,
6558860	6561580	how am I possibly going to fill up an hour and a half
6561580	6563180	talking about for loops, right?
6563180	6565300	And there wasn't enough time.
6565300	6566700	Took me a while to realize this, right?
6566700	6567940	There are only three things, right?
6567940	6569140	There's reading from a variable,
6569140	6571620	writing to a variable and conditional branching.
6571620	6574140	Everything else is syntactic sugar, right?
6574140	6576140	The syntactic sugar matters, but that's it.
6576140	6578980	And when I say that's it, I don't mean it's simple.
6578980	6580180	I mean, it's hard.
6580180	6583540	Like conditional branching, loops, variable.
6583540	6585260	Those are really hard concepts.
6585260	6587300	So you shouldn't be discouraged by this.
6587300	6588780	Here's the simple experiment I'm going to ask you
6588780	6590780	a question now, you ready?
6590780	6591740	X equals three.
6591740	6592580	Okay.
6593460	6595420	Y equals four.
6595420	6597140	What is X?
6597140	6597980	Three.
6597980	6599100	What is Y?
6599100	6599940	Four.
6599940	6600780	Y equals S.
6600780	6601620	I'm going to mess this up.
6601620	6602660	Oh, it's easier.
6602660	6604060	Y equals X.
6604060	6604900	Y equals X.
6604900	6605620	What is Y?
6607900	6608740	Three.
6608740	6609580	That's right.
6609580	6610340	X equals seven.
6611420	6612580	What is Y?
6612580	6614940	That's one of the trickiest things to get
6614940	6617500	for programmers that there's a memory
6617540	6619300	and the variables are pointing
6619300	6621100	to a particular thing in memory.
6621100	6623340	And sometimes the languages hide that from you
6623340	6624420	and they bring it closer
6624420	6626700	to the way you think mathematics works.
6626700	6627540	Right.
6627540	6629260	So in fact, Mark Gustav, who worries
6629260	6630140	about these sorts of things
6630140	6632540	or used to worry about these sorts of things anyway,
6632540	6635980	had this kind of belief that actually people
6635980	6637020	when they see these statements,
6637020	6639620	X equals something Y equals something Y equals X,
6639620	6642980	that you have now made a mathematical statement
6642980	6644300	that Y and X are the same.
6645660	6646780	Which you can if you just put like
6646780	6648140	an anchor in front of it.
6648140	6649940	Yes, but people, that's not what you're doing.
6649940	6650780	Yeah.
6650780	6651620	Right.
6651620	6654100	I thought, and I kind of asked the question
6654100	6655580	and I think had some evidence for this.
6655580	6656660	I'm sorry, they study.
6656660	6659300	Is that most of the people who didn't know the answer
6659300	6660380	weren't sure about the answer.
6660380	6661700	They had used spreadsheets.
6663540	6668540	And so it's by reference or by name really, right?
6671020	6673380	And so depending upon what you think they are,
6673380	6674820	you get completely different answers.
6674820	6677940	The fact that I could go or one could go
6677940	6680180	two thirds of the way through a semester
6680180	6682620	and people still hadn't figured out in their heads
6682620	6685180	when you say Y equals X, what that meant,
6685180	6687180	tells you it's actually hard
6687180	6689180	because all those answers are possible.
6689180	6690100	And in fact, when you said,
6690100	6691900	oh, if you just put an ampersand in front of it,
6691900	6693740	I mean, that doesn't make any sense for an intro class.
6693740	6694780	And of course, a lot of language
6694780	6696300	don't even give you the ability to think about it
6696300	6697380	in terms of ampersand.
6697380	6698980	Do we want to have a 45 minute discussion
6698980	6702380	about the difference between equal EQ and equal in Lisp?
6702380	6703220	Yeah.
6703220	6704060	I know you do.
6704900	6707300	But you know, you could do that.
6707300	6709180	It's just actually really hard stuff.
6709180	6712380	So you shouldn't be, it's not too hard, we all do it,
6712380	6713940	but you shouldn't be discouraged.
6713940	6715340	It's why you should start small
6715340	6716620	so that you can figure out these things
6716620	6718380	so you have the right model in your head
6718380	6719980	so that when you write the language,
6719980	6722020	you can execute it and build the machine
6722020	6723260	that you want to build, right?
6723260	6725180	Yeah, the funny thing about programming
6725180	6729100	on those very basic things is the very basics
6729100	6731140	are not often made explicit,
6731140	6733900	which is actually what drives everybody away
6733900	6735300	from basically any discipline,
6735300	6737020	but programming is just another one.
6737020	6739340	Like even a simpler version of the equal sign
6739340	6743740	that I kind of forget is in mathematics,
6743740	6745460	equals is not assignment.
6745460	6746500	Yeah.
6746500	6750260	Like, I think basically every single programming language
6750260	6755140	with just a few handful of exceptions equals is assignment.
6755140	6758820	You have some other operator for equality.
6758820	6762540	And you know, even that, like everyone kind of knows it.
6762620	6765020	Once you started doing it,
6765020	6767140	but like you need to say that explicitly
6767140	6770980	or you just realize it like yourself.
6770980	6773220	Otherwise you might be stuck for,
6773220	6774660	you said like half a semester,
6774660	6777180	you could be stuck for quite a long time.
6777180	6782060	And I think also part of the programming is being okay
6782060	6784500	in that state of confusion for a while.
6784500	6786740	It's to the debugging point.
6786740	6789820	It's like, I just wrote two lines of code.
6789820	6791020	Why doesn't this work?
6791060	6793420	And staring at that for like hours
6794700	6795860	and trying to figure out,
6795860	6797020	and then every once in a while,
6797020	6798540	you just have to restart your computer
6798540	6799620	and everything works again.
6799620	6804260	And then you just kind of stare into the void
6804260	6806660	with the tears slowly rolling down your eye.
6806660	6808260	By the way, the fact that they didn't get this
6808260	6810100	actually had no impact on,
6810100	6812460	I mean, they were still able to redo their assignments.
6812460	6815140	Because it turns out their misunderstanding
6815140	6817660	wasn't being revealed to them
6817660	6820380	by the problems that we were giving them.
6821340	6824380	I wrote a program a long time ago,
6824380	6826340	actually for my master's thesis,
6826340	6829380	and in C++ I think, or C, I guess it was C.
6829380	6831740	And it was all memory management and terrible.
6832700	6835420	And it wouldn't work for a while.
6836300	6837500	And it was some kind of,
6837500	6839660	it was clear to me that it was overwriting memory.
6839660	6840980	And I just couldn't,
6840980	6843340	I was like, look, I got a paper done, time for this.
6843340	6846540	So I basically declared a variable
6846540	6850140	at the front in the main that was like 400K,
6850180	6852500	just an array, and it worked.
6852500	6854380	Because wherever I was scribbling over memory,
6854380	6857180	it would scribble into that space and it didn't matter.
6857180	6859700	And so I never figured out what the bug was,
6859700	6861860	but I did create something to sort of deal with it.
6861860	6862780	To work around it.
6862780	6865660	And it, you know, that's crazy, that's crazy.
6865660	6867300	It was okay, because that's what I wanted.
6867300	6869380	But I knew enough about memory management to go,
6869380	6870940	you know, management to go, you know,
6870940	6872260	I'm just gonna create an empty array here
6872260	6874820	and hope that that deals with the scribbling memory problem.
6874820	6877020	And it did, that takes a long time to figure out.
6877020	6878580	And by the way, the language you first learned
6878580	6879820	probably does garbage collection anyway,
6879860	6881100	so you're not even gonna come across,
6881100	6883540	you're not gonna come across that problem.
6883540	6886060	So we talked about the Minsky idea
6886060	6889620	of hating everything you do and hating yourself.
6889620	6892660	So let's end on a question
6892660	6894780	that's gonna make both of you very uncomfortable.
6894780	6895620	Okay.
6895620	6898020	Which is what is your, Charles,
6898020	6901900	what's your favorite thing that you're grateful for
6901900	6905300	about Michael and Michael?
6905300	6906700	What is your favorite thing
6906700	6909700	that you're grateful for about Charles?
6909700	6912140	Well, that answer is actually quite easy.
6912140	6912980	His friendship.
6914500	6915820	He stole the easy answer.
6915820	6917500	Yeah, I can tell you what I hate about Charles.
6917500	6919500	He steals my good answers.
6919500	6921140	The thing I like most about Charles,
6921140	6925140	he sees the world in a similar enough but different way
6925140	6928900	that it's sort of like having another life.
6928900	6931460	It's sort of like I get to experience things
6931460	6932940	that I wouldn't otherwise get to experience
6932940	6936060	because I would not naturally gravitate to them that way.
6936060	6939100	And so he just shows me a whole other world.
6939140	6939980	That's awesome.
6939980	6944100	Yeah, the inner product is not zero for sure.
6944100	6947540	It's not quite one, 0.7 maybe.
6947540	6949340	Just enough that you can learn.
6950740	6953060	Just enough that you can learn.
6953060	6954380	That's the definition of friendship.
6954380	6955740	The inner product is 0.7.
6955740	6956700	Yeah, I think so.
6956700	6958140	That's the answer to life really.
6958140	6959380	Charles sometimes believes in me
6959380	6961060	when I have not believed in me.
6961060	6964380	He also sometimes works as an outboard confidence
6964380	6968780	that he has so much, so much confidence and self,
6968820	6971380	I don't know, comfortableness.
6971380	6973020	Okay, let's go with that.
6973020	6976140	That I feel better a little bit.
6976140	6977700	If he thinks I'm okay,
6977700	6980260	then maybe I'm not as bad as I think I am.
6980260	6983260	At the end of the day, luck favors the Charles.
6984620	6986740	It's a huge honor to talk with you.
6986740	6989340	Thank you so much for taking this time,
6989340	6990740	wasting your time with me.
6990740	6992180	It was an awesome conversation.
6992180	6995260	You guys are an inspiration to a huge number of people
6995260	6997260	and to me, so really enjoyed this.
6997260	6998100	Thanks for talking to me.
6998260	6999100	Thank you so much.
6999100	7000460	And by the way, if luck favors the Charles,
7000460	7001420	then it's certainly the case
7001420	7003860	that I've been very lucky to tell you.
7003860	7005140	I'm gonna end that part out.
7005140	7005980	Yeah.
7007860	7009380	Thanks for listening to this conversation
7009380	7011540	with Charles Isbo and Michael Littman.
7011540	7013940	And thank you to our sponsors,
7013940	7017180	Athletic Greens, Super Nutritional Drink,
7017180	7020380	Aidsleep, Self-Cooling Mattress,
7020380	7022980	Masterclass Online Courses
7022980	7025900	from some of the most amazing humans in history,
7025900	7027020	and Cash App.
7027060	7029940	The app I use to send money to friends.
7029940	7032500	Please check out the sponsors in the description
7032500	7036180	to get a discount and to support this podcast.
7036180	7038540	If you enjoy this thing, subscribe on YouTube,
7038540	7040780	review it with Five Stars Napa Podcast,
7040780	7043580	follow on Spotify, support it on Patreon,
7043580	7046820	connect with me on Twitter, Alex Freedman.
7046820	7048500	And now, let me leave you with some words
7048500	7049780	from Desmond Tutu.
7050780	7052540	Don't raise your voice.
7052540	7054180	Improve your argument.
7054180	7057900	Thank you for listening and hope to see you next time.
